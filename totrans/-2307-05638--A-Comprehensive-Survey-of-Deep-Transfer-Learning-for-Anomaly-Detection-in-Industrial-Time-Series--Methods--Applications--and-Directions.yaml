- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:38:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:38:05
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2307.05638] A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2307.05638] 工业时间序列异常检测的深度迁移学习综合调查：方法、应用与方向'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2307.05638](https://ar5iv.labs.arxiv.org/html/2307.05638)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2307.05638](https://ar5iv.labs.arxiv.org/html/2307.05638)
- en: 'A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 工业时间序列异常检测的深度迁移学习综合调查：方法、应用与方向
- en: '[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Peng Yan](https://orcid.org/0009-0006-0236-4707)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) 彭彦](https://orcid.org/0009-0006-0236-4707)'
- en: Centre for Artificial Intelligence
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能中心
- en: ZHAW School of Engineering
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ZHAW 工程学院
- en: Winterthur, ZH, Switzerland
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士
- en: yanp@zhaw.ch
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: yanp@zhaw.ch
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Ahmed Abdulkadir](https://orcid.org/0000-0003-4679-8081)'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Ahmed Abdulkadir](https://orcid.org/0000-0003-4679-8081)'
- en: Centre for Artificial Intelligence
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能中心
- en: ZHAW School of Engineering
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ZHAW 工程学院
- en: Winterthur, ZH, Switzerland
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士
- en: abdk@zhaw.ch
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: abdk@zhaw.ch
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Paul-Philipp
    Luley](https://orcid.org/0009-0007-0851-665X)'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Paul-Philipp Luley](https://orcid.org/0009-0007-0851-665X)'
- en: Centre for Artificial Intelligence
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能中心
- en: ZHAW School of Engineering
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: ZHAW 工程学院
- en: Winterthur, ZH, Switzerland
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士
- en: lule@zhaw.ch
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: lule@zhaw.ch
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Matthias
    Rosenthal](https://orcid.org/0000-0002-7577-783X)'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Matthias Rosenthal](https://orcid.org/0000-0002-7577-783X)'
- en: Institute of Embedded Systems
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 嵌入系统研究所
- en: ZHAW School of Engineering
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: ZHAW 工程学院
- en: Winterthur, ZH, Switzerland
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士
- en: rosn@zhaw.ch
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: rosn@zhaw.ch
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Gerrit A.
    Schatte](https://orcid.org/0009-0002-5760-9346)'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Gerrit A. Schatte](https://orcid.org/0009-0002-5760-9346)'
- en: Innovation Lab
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 创新实验室
- en: Kistler Instrumente AG
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: Kistler Instrumente AG
- en: Winterthur, ZH, Switzerland
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士
- en: gerrit.schatte@kistler.com
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: gerrit.schatte@kistler.com
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Benjamin
    F. Grewe](https://orcid.org/0000-0001-8560-2120)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Benjamin F. Grewe](https://orcid.org/0000-0001-8560-2120)'
- en: Institute of Neuroinformatics
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 神经信息学研究所
- en: ETH & University of Zürich
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: ETH & 苏黎世大学
- en: Zürich, ZH, Switzerland
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 苏黎世，ZH，瑞士
- en: benjamin.grewe@uzh.ch
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: benjamin.grewe@uzh.ch
- en: '&[![[Uncaptioned image]](img/7a09d23cafced365573573ca376a29c3.png) Thilo Stadelmann](https://orcid.org/0000-0002-3784-0420)'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: '&[![[未标注的图片]](img/7a09d23cafced365573573ca376a29c3.png) Thilo Stadelmann](https://orcid.org/0000-0002-3784-0420)'
- en: ZHAW Centre for Artificial Intelligence & European Centre for Living Technology
    (ECLT)
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: ZHAW 人工智能中心 & 欧洲生活技术中心（ECLT）
- en: Winterthur, ZH, Switzerland & Venice, Veneto, Italy
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 温特图尔，ZH，瑞士 & 威尼斯，威尼托，意大利
- en: stdm@zhaw.ch
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: stdm@zhaw.ch
- en: Abstract
  id: totrans-41
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Automating the monitoring of industrial processes has the potential to enhance
    efficiency and optimize quality by promptly detecting abnormal events and thus
    facilitating timely interventions. Deep learning, with its capacity to discern
    non-trivial patterns within large datasets, plays a pivotal role in this process.
    Standard deep learning methods are suitable to solve a specific task given a specific
    type of data. During training, deep learning demands large volumes of labeled
    data. However, due to the dynamic nature of the industrial processes and environment,
    it is impractical to acquire large-scale labeled data for standard deep learning
    training for every slightly different case anew. Deep transfer learning offers
    a solution to this problem. By leveraging knowledge from related tasks and accounting
    for variations in data distributions, the transfer learning framework solves new
    tasks with little or even no additional labeled data. The approach bypasses the
    need to retrain a model from scratch for every new setup and dramatically reduces
    the labeled data requirement. This survey first provides an in-depth review of
    deep transfer learning, examining the problem settings of transfer learning and
    classifying the prevailing deep transfer learning methods. Moreover, we delve
    into applications of deep transfer learning in the context of a broad spectrum
    of time series anomaly detection tasks prevalent in primary industrial domains,
    e.g., manufacturing process monitoring, predictive maintenance, energy management,
    and infrastructure facility monitoring. We discuss the challenges and limitations
    of deep transfer learning in industrial contexts and conclude the survey with
    practical directions and actionable suggestions to address the need to leverage
    diverse time series data for anomaly detection in an increasingly dynamic production
    environment.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化监控工业过程具有提高效率和优化质量的潜力，通过及时检测异常事件来促进及时干预。深度学习由于能够识别大数据集中的非平凡模式，在这一过程中发挥了关键作用。标准的深度学习方法适用于特定类型数据下的特定任务。在训练过程中，深度学习需要大量标记数据。然而，由于工业过程和环境的动态性质，为每一个稍有不同的案例重新获取大规模标记数据对于标准深度学习训练来说是不切实际的。深度迁移学习提供了这一问题的解决方案。通过利用相关任务的知识并考虑数据分布的变化，迁移学习框架可以用很少甚至没有额外的标记数据解决新任务。这种方法绕过了每次新设置都需要从头开始重新训练模型的需求，并大幅减少了对标记数据的需求。本调查首先对深度迁移学习进行深入审查，探讨迁移学习的问题设置并分类现有的深度迁移学习方法。此外，我们*深入探讨*了深度迁移学习在各种时间序列异常检测任务中的应用，这些任务在主要工业领域中普遍存在，例如制造过程监控、预测性维护、能源管理和基础设施设施监控。我们讨论了深度迁移学习在工业环境中的挑战和局限性，并在调查的最后提出了实际方向和可操作的建议，以应对在日益动态的生产环境中利用多样化时间序列数据进行异常检测的需求。
- en: 1 Introduction
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 1.1 motivation and contribution
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 动机与贡献
- en: The fourth industrial revolution – Industry 4.0 [[1](#bib.bib1)], that is characterized
    by increasing efficiency through the digitization of production, automation, and
    horizontal integration across companies [[2](#bib.bib2)], and the advent of connected
    cyber-physical systems – referred to as internet of things [[3](#bib.bib3), [4](#bib.bib4),
    [5](#bib.bib5)], increases the need for autonomous and intelligent process monitoring.
    This can be exemplified by the use case of a smart factory in which industrial
    processes are transformed to be more flexible, intelligent, and dynamic [[6](#bib.bib6)],
    or the use case of decentralized energy production with wind and solar [[7](#bib.bib7)].
    In these examples, AI-powered anomaly detection integrates the analysis of time
    series data to detect unusual patterns in the recorded data. To achieve this,
    a deep learning architecture is modeled to capture indicators of normal and abnormal
    operation. The learning process involves the analysis of historic time series
    sensor data of normal and possibly abnormal operations. This data is for example
    used for representation- or reconstruction-based learning. After training, the
    deep learning model represents or reconstructs normal data in a certain way. The
    model is designed in a way that abnormal data–because it is different–is either
    represented differently from the normal data or reconstructed poorly and thus
    recognized as an anomaly. By identifying operational parameters that fall outside
    a window of normal interval, operators can trigger interventions and adjustments
    to ensure high product quality and safe operations. To achieve this, physical
    properties such as pressure or temperature are monitored and analyzed in real-time
    applications. Changes in these variables capture drifting and abrupt faults caused
    by process failures or malfunctions [[8](#bib.bib8)]. The production process must
    adapt quickly to changes in production and the environment to meet the requirements
    for flexibility and dynamics. Further use cases exist in a wide range of diverse
    fields, such as manufacturing monitoring including automatic quality control [[9](#bib.bib9),
    [10](#bib.bib10)], predictive maintenance of goods and services [[11](#bib.bib11),
    [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)],
    infrastructure monitoring of building systems [[17](#bib.bib17), [18](#bib.bib18)]
    and power plant [[19](#bib.bib19)], digital agriculture [[20](#bib.bib20)], petrochemical
    process optimization [[21](#bib.bib21)], computer network intrusion detection
    [[22](#bib.bib22)], or aircraft flight monitoring [[23](#bib.bib23)], to name
    a few.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 第四次工业革命——工业4.0 [[1](#bib.bib1)]，其特点是通过生产的数字化、自动化以及公司之间的横向集成来提高效率 [[2](#bib.bib2)]，以及互联的网络物理系统的出现——即物联网
    [[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5)]，增加了对自主和智能过程监控的需求。这可以通过智能工厂的用例来举例说明，其中工业过程被转变为更灵活、智能和动态
    [[6](#bib.bib6)]，或者通过风能和太阳能的分散能源生产的用例 [[7](#bib.bib7)]。在这些示例中，基于AI的异常检测将时间序列数据的分析集成起来，以检测记录数据中的异常模式。为实现这一点，构建了深度学习架构来捕捉正常和异常操作的指标。学习过程涉及对正常和可能异常操作的历史时间序列传感器数据的分析。这些数据例如用于基于表示或重建的学习。训练后，深度学习模型以某种方式表示或重建正常数据。模型的设计使得异常数据——因为它不同——与正常数据的表示方式不同，或重建效果差，因此被识别为异常。通过识别超出正常区间窗口的操作参数，操作员可以触发干预和调整，以确保高产品质量和安全操作。为实现这一点，实时应用中监控和分析压力或温度等物理属性。这些变量的变化捕捉到由于过程故障或故障引起的漂移和突发故障
    [[8](#bib.bib8)]。生产过程必须迅速适应生产和环境的变化，以满足灵活性和动态性的要求。还存在各种领域的进一步应用实例，例如包括自动质量控制的制造监控
    [[9](#bib.bib9), [10](#bib.bib10)]，商品和服务的预测性维护 [[11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16)]，建筑系统 [[17](#bib.bib17),
    [18](#bib.bib18)] 和电厂 [[19](#bib.bib19)] 的基础设施监控，数字农业 [[20](#bib.bib20)]，石油化工过程优化
    [[21](#bib.bib21)]，计算机网络入侵检测 [[22](#bib.bib22)]，或飞机飞行监控 [[23](#bib.bib23)]，仅举几例。
- en: Artificial Intelligence, particularly deep learning, provides competent frameworks
    with underlying deep neural networks to automate intelligent monitoring and provide
    valuable assistance to operators and high-level control systems. Leveraging the
    power of deep learning, informative features of the data – technically referred
    to as representations [[24](#bib.bib24)] – can be captured in a machine-learned
    model and thereby enable a detailed understanding of variations in standard operations.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 人工智能，特别是深度学习，提供了基于深度神经网络的高效框架，用于自动化智能监控并为操作员和高级控制系统提供宝贵的帮助。通过深度学习的力量，数据的有用特征——在技术上称为表示[[24](#bib.bib24)]——可以被捕获在机器学习模型中，从而实现对标准操作变化的详细理解。
- en: However, the task or underlying data may change under non-trivial and non-stationary
    conditions. For instance, the monitoring system of a milling machine may be assigned
    the task of identifying a blunt tool based on vibration in one scenario, and in
    a different scenario, it may utilize the same vibration measurements to detect
    insufficient cooling lubricant. Knowledge acquired to solve one task in one setting
    with a given tool, machined part, and type of machine may be transferred to solve
    the same or similar task in another setting with a different tool, machined part,
    or type of machine. Slowly changing conditions (drifts), abrupt mode changes (for
    instance, due to tool change), and new tasks (such as the detection of another
    failure mode) may require adjustments to the deep learning model. In these cases,
    it is desirable to adjust the analysis model without retraining from scratch,
    as it is costly or impractical to acquire sufficient training data to learn the
    full manifold [[25](#bib.bib25)].
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，在非平稳和非平凡条件下，任务或底层数据可能会发生变化。例如，在某种情况下，铣床的监控系统可能会被指派通过振动识别钝化工具，而在不同的情况下，它可能会利用相同的振动测量来检测冷却润滑剂不足。为了在另一种设置中解决相同或类似的任务，使用不同的工具、加工零件或机器类型的知识可能会被转移。在这些情况下，深度学习模型可能需要进行调整，以适应缓慢变化的条件（漂移）、突然的模式变化（例如，由于工具更换）和新任务（如检测其他故障模式）。在这些情况下，最好调整分析模型而不是从头开始重新训练，因为获取足够的训练数据以学习完整的流形是昂贵或不切实际的[[25](#bib.bib25)]。
- en: 'Transfer learning is a machine learning framework to achieve this [[26](#bib.bib26),
    [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30)]. As depicted
    in Fig. [1](#S1.F1 "Figure 1 ‣ 1.1 motivation and contribution ‣ 1 Introduction
    ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions"), data and algorithms from
    one task may be leveraged in a new related one. By accounting for changes in data
    distributions and tasks or leveraging existing models, knowledge learned from
    related tasks can be used to improve performance on new tasks instead of retraining
    a model for each individual application from scratch. This transfer-learning-boosted
    modeling forms the basis for identifying anomalies that deviate from established
    patterns in a non-trivial manner without full re-training.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '迁移学习是实现这一目标的机器学习框架[[26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29),
    [30](#bib.bib30)]。如图[1](#S1.F1 "Figure 1 ‣ 1.1 motivation and contribution ‣ 1
    Introduction ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions")所示，来自一个任务的数据和算法可以在新的相关任务中利用。通过考虑数据分布和任务的变化或利用现有模型，学习到的知识可以用来改善新任务的表现，而无需为每个应用从头开始重新训练模型。这种迁移学习增强的建模基础用于识别在非平凡方式下偏离既定模式的异常，而无需完全重新训练。'
- en: '![Refer to caption](img/7e973cde2724a466d1583ce05cc8b78c.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7e973cde2724a466d1583ce05cc8b78c.png)'
- en: 'Figure 1: Transfer learning is useful when changes in production take place
    and sufficient data for full retraining is not available as shown here for a hypothetical
    production of two types of gears. In the production of gear A, a lot of data is
    available to train a deep learning model that helps improve production. In the
    production of gear B, data is more limited, and the traditionally trained deep
    learning model fails to improve production. With suitable transfer learning methods,
    however, data and algorithms acquired during the production of gear A can be leveraged
    to support improving the production of gear B because the data and tasks in the
    production of both gears are related.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：当生产过程中发生变化且没有足够数据进行全面再训练时，迁移学习是有用的，如图所示为假设的两种齿轮生产。在齿轮 A 的生产中，有大量数据可用于训练深度学习模型，从而帮助改善生产。在齿轮
    B 的生产中，数据较为有限，传统训练的深度学习模型未能改善生产。然而，通过合适的迁移学习方法，可以利用在齿轮 A 生产过程中获得的数据和算法来支持改善齿轮
    B 的生产，因为两种齿轮的生产数据和任务是相关的。
- en: 'Deep transfer learning [[29](#bib.bib29), [31](#bib.bib31)] extends the transfer
    learning paradigm by leveraging deep learning. In industrial contexts, it ensures
    optimal production even as production conditions shift. This dynamic adaptability
    is key in maintaining the effectiveness of anomaly detection systems in the dynamic
    environment that characterizes industrial applications including the broad categories
    of manufacturing process monitoring, predictive maintenance, energy management,
    and infrastructure facility monitoring as detailed in Section [4](#S4 "4 Industrial
    applications ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions").'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 深度迁移学习 [[29](#bib.bib29), [31](#bib.bib31)] 通过利用深度学习扩展了迁移学习范式。在工业背景下，即使生产条件发生变化，它也能确保最佳生产。这种动态适应性是保持异常检测系统在动态工业环境中有效性的关键，工业应用包括制造过程监控、预测性维护、能源管理和基础设施设施监控等广泛类别，详见第
    [4](#S4 "4 工业应用 ‣ 深度迁移学习在工业时间序列异常检测中的全面调查：方法、应用和方向") 节。
- en: 'This survey is a non-systematic yet application-oriented review with a narrow
    focus on deep transfer learning for anomaly detection in time series in the industry.
    Our main contributions are as follows:'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述是一篇非系统性的但以应用为导向的评述，重点关注工业中时间序列异常检测的深度迁移学习。我们的主要贡献如下：
- en: •
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We categorize transfer learning problem settings and then systematically summarize
    deep transfer learning approaches into four categories. With the foundations of
    deep transfer learning, we equip the reader with a working knowledge of the main
    principles and intuitions.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将迁移学习问题设置进行分类，并系统地将深度迁移学习方法总结为四类。在深度迁移学习的基础上，我们使读者掌握主要原理和直觉的实用知识。
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We analyze the recent literature and provide a comprehensive overview of the
    current state of the art of deep transfer learning approaches for time series
    anomaly detection for main industrial applications.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们分析了最新文献，并对深度迁移学习方法在时间序列异常检测中的现状进行了全面概述，特别是针对主要工业应用。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We discuss potential challenges and limitations and then give directions for
    future work with actionable recommendations for AI practitioners and decision-makers.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们讨论了潜在的挑战和局限性，然后为未来的工作提供了方向，并提出了针对 AI 从业人员和决策者的可操作性建议。
- en: To our knowledge, this is the first survey of deep transfer learning in the
    narrow context of industrial time series anomaly detection. The review describes
    the underlying methodological principles and methods within a generic taxonomy
    and discusses practical implications for AI practitioners to make informed decisions.
    We cover multiple areas of application, including manufacturing monitoring, maintenance
    prediction, and infrastructure monitoring.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，这是第一篇在狭义的工业时间序列异常检测背景下的深度迁移学习综述。该综述描述了通用分类法中的基本方法论原则和方法，并讨论了对 AI 从业人员做出明智决策的实际意义。我们涵盖了多个应用领域，包括制造监控、维护预测和基础设施监控。
- en: 'The rest of the paper is organized as follows. First, we provide an overview
    of transfer learning by introducing a taxonomy of transfer learning problem settings
    and further categorizing deep transfer learning approaches (Section [2](#S2 "2
    Deep transfer learning ‣ A Comprehensive Survey of Deep Transfer Learning for
    Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions")).
    Then, we describe the task of anomaly detection in time series (Section [3](#S3
    "3 Time series anomaly detection in industry ‣ A Comprehensive Survey of Deep
    Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications,
    and Directions")) in selected industrial applications (Section [4](#S4 "4 Industrial
    applications ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions")). To conclude,
    we discuss current challenges, limitations, and future research directions (Sections
    [5](#S5 "5 Discussion ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions")–[6](#S6
    "6 Conclusions ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions"))
    in the field.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '论文的其余部分组织如下。首先，我们通过介绍转移学习问题设置的分类法并进一步对深度转移学习方法进行分类，提供转移学习的概述（第[2](#S2 "2 Deep
    transfer learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions")节）。接着，我们描述时间序列中的异常检测任务（第[3](#S3
    "3 Time series anomaly detection in industry ‣ A Comprehensive Survey of Deep
    Transfer Learning for Anomaly Detection in Industrial Time Series: Methods, Applications,
    and Directions")节）以及在选定工业应用中的应用（第[4](#S4 "4 Industrial applications ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions")节）。最后，我们讨论该领域的当前挑战、局限性和未来研究方向（第[5](#S5
    "5 Discussion ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions")–[6](#S6 "6
    Conclusions ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions")节）。'
- en: 1.2 Survey methodology
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 调查方法
- en: 'We seek to identify application-oriented peer-reviewed literature in the intersection
    of transfer learning as the learning framework, time series as the data domain,
    and anomaly detection as the task (Fig. [2](#S1.F2 "Figure 2 ‣ 1.2 Survey methodology
    ‣ 1 Introduction ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions")).
    To execute the selection process of literature, we search related terms on Google
    Scholar, Scopus, Elsevier, and IEEE databases. Based on the title, we pick those
    papers that may fit the narrow topic into a pre-selection list. Eventually, we
    included publications matching the topic according to the abstract and screening
    of the content.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '我们旨在识别转移学习作为学习框架、时间序列作为数据领域以及异常检测作为任务交集中的应用导向的同行评审文献（图[2](#S1.F2 "Figure 2
    ‣ 1.2 Survey methodology ‣ 1 Introduction ‣ A Comprehensive Survey of Deep Transfer
    Learning for Anomaly Detection in Industrial Time Series: Methods, Applications,
    and Directions")）。为了执行文献选择过程，我们在 Google Scholar、Scopus、Elsevier 和 IEEE 数据库中搜索相关术语。根据标题，我们将那些可能符合狭窄主题的论文挑选入预选列表。最终，我们根据摘要和内容筛选，纳入了与主题匹配的出版物。'
- en: 'Along the reviewed topical papers, we include contextually relevant papers
    such as deep learning approaches that are agnostic to data types and tasks. For
    deep transfer learning in general, we searched the keywords “transfer learning”
    and “deep transfer learning”. Specifically, we focus more on deep transfer learning
    approaches. Then, we switch to the application-oriented cases where deep transfer
    learning is applied to tackle time series anomaly detection in the main industrial
    applications. To achieve this, we search queries like “deep transfer learning
    for time series anomaly detection” and “deep transfer learning for predictive
    maintenance”. After searching in the database, we carefully check and screen out
    the most relevant literature based on the following inclusion/exclusion criteria:
    (1) We only include the applications that utilize deep transfer learning approaches,
    instead of traditional transfer learning; (2) We only include publications after
    2013; (3) We cover all three main topics in Fig. [2](#S1.F2 "Figure 2 ‣ 1.2 Survey
    methodology ‣ 1 Introduction ‣ A Comprehensive Survey of Deep Transfer Learning
    for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions")
    (highlighted with cycles), but we specifically focus on the intersection of the
    three aforementioned domains. After carefully screening out, we select 45 papers
    for deep transfer learning in general and 37 papers for deep transfer learning
    for anomaly detection in industrial time series.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在审查的专题论文中，我们包括了与数据类型和任务无关的深度学习方法。对于一般的深度迁移学习，我们搜索了“迁移学习”和“深度迁移学习”的关键词。具体来说，我们更关注深度迁移学习方法。然后，我们转向以应用为导向的案例，其中深度迁移学习应用于解决主要工业应用中的时间序列异常检测。为此，我们搜索了类似“时间序列异常检测的深度迁移学习”和“预测性维护的深度迁移学习”的查询。在数据库中搜索后，我们根据以下纳入/排除标准仔细检查并筛选出最相关的文献：(1)
    我们只包括利用深度迁移学习方法的应用，而不是传统的迁移学习；(2) 我们只包括2013年之后的出版物；(3) 我们涵盖图 [2](#S1.F2 "图 2 ‣
    1.2 调查方法 ‣ 1 引言 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用与方向") 中的所有三个主要主题（用圆圈突出显示），但我们特别关注上述三个领域的交集。经过仔细筛选，我们选择了45篇关于深度迁移学习的一般论文和37篇关于工业时间序列异常检测的深度迁移学习论文。
- en: 'Fig. [3](#S1.F3 "Figure 3 ‣ 1.2 Survey methodology ‣ 1 Introduction ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions") illustrates the taxonomy in this survey
    to categorize reviewed studies based on different aspects, including deep transfer
    learning, time series anomaly detection, industrial applications, current challenges,
    and future directions.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [3](#S1.F3 "图 3 ‣ 1.2 调查方法 ‣ 1 引言 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用与方向") 展示了本调查中的分类法，用于根据不同方面对审查的研究进行分类，包括深度迁移学习、时间序列异常检测、工业应用、当前挑战和未来方向。
- en: '![Refer to caption](img/104478d9b28ccdef199b64415502bc41.png)'
  id: totrans-65
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/104478d9b28ccdef199b64415502bc41.png)'
- en: 'Figure 2: Venn diagram of this survey’s focus on the intersection of transfer
    learning, anomaly detection, and time series analysis.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：本调查关注迁移学习、异常检测和时间序列分析的交集的维恩图。
- en: '![Refer to caption](img/dfee53653f6feaef11aa5c1cb44f5ee1.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/dfee53653f6feaef11aa5c1cb44f5ee1.png)'
- en: 'Figure 3: A generic taxonomy in this paper to analyze deep transfer learning
    for industrial time series anomaly detection.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：本文中用于分析工业时间序列异常检测的深度迁移学习的一般分类法。
- en: 2 Deep transfer learning
  id: totrans-69
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度迁移学习
- en: 2.1 Overview of the field
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 领域概述
- en: \change
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: \change
- en: '[]Transfer learning in a deep learning setting aims to increase the efficiency,
    performance, and generalization of deep learning models by transferring knowledge
    from one dataset and task to a new one. Transfer learning in the setting of industrial
    time series analysis for anomaly detection is a tool to increase the flexibility
    of autonomous process monitoring. It addresses the challenge of adapting the algorithm,
    and thus the decision process, to a related but previously unseen setting where
    limited training data is available. \changeThisThe transfer eliminates the need
    to train a deep learning model from scratch, which in turn reduces the amount
    of necessary data and compute required to solve a new task or \addadjust to a
    new data domain. In either case, knowledge is transferred from a source to a target
    domain, as \changedefineddescribed below. The transfer learning problem settings
    can be categorized as inductive or transductive transfer depending on the data
    and task conditions. \change, while weWe categorize deep learning-based transfer
    learning approaches into instance transfer, parameter transfer, mapping transfer
    and domain-adversarial transfer. We illustrate them by using two intuitive examples
    in Fig. [4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field ‣ 2 Deep transfer learning
    ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions"), with more details being
    elaborated in the following sections.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习环境下，**迁移学习**旨在通过将知识从一个数据集和任务转移到新的数据集和任务，从而提高深度学习模型的效率、性能和泛化能力。在工业时间序列异常检测的背景下，迁移学习是一种提高自主过程监控灵活性的工具。它解决了将算法及其决策过程适应于一个相关但之前未见过的环境的挑战，其中训练数据有限。迁移学习消除了从头开始训练深度学习模型的需要，这反过来减少了为解决新任务或适应新数据领域所需的数据和计算量。在这两种情况下，知识从源领域转移到目标领域，如下文所述。迁移学习问题设置可以根据数据和任务条件分为**归纳性迁移**或**传导性迁移**。同时，我们将基于深度学习的迁移学习方法分类为实例迁移、参数迁移、映射迁移和领域对抗迁移。我们通过图
    [4](#S2.F4 "图 4 ‣ 2.1 领域概述 ‣ 2 深度迁移学习 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用和方向")中的两个直观示例来说明这些方法，更多细节将在后续章节中详细介绍。
- en: '![Refer to caption](img/c796f2f166be5b9ef2b3f9f385e325df.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c796f2f166be5b9ef2b3f9f385e325df.png)'
- en: 'Figure 4: Taxonomy of transfer learning problem settings (left; see Section
    [2.2](#S2.SS2 "2.2 Formal description of deep transfer learning ‣ 2 Deep transfer
    learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions") for the definition
    of terms) and corresponding examples using deep transfer learning approaches (right).
    On the left, we classify transfer learning problems as inductive or transductive
    transfer settings Correspondingly, we provide two examples using deep transfer
    learning methods: In the inductive transfer setting, we collect time series data
    from screw production and wrench production. Labeled screw data (A1) is used to
    detect collective anomalies (a set of data points behaving differently compared
    to the entire time series [[32](#bib.bib32), [33](#bib.bib33)], further explained
    in Section [3](#S3 "3 Time series anomaly detection in industry ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions")). Then, parameter transfer (Section [2.3.2](#S2.SS3.SSS2
    "2.3.2 Parameter transfer ‣ 2.3 Deep transfer learning approaches ‣ 2 Deep transfer
    learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions")) is applied
    to transfer knowledge by fine-tuning the pre-trained model from labeled screw
    data to detect point anomalies (further explained in Section [3](#S3 "3 Time series
    anomaly detection in industry ‣ A Comprehensive Survey of Deep Transfer Learning
    for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions"))
    on labeled wrench data (A2). For the transductive transfer setting in the lower
    panel, we present a different situation for contextual anomaly detection (further
    explained in Section [3](#S3 "3 Time series anomaly detection in industry ‣ A
    Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions")). In this case, we have two
    datasets, B1 and B2, analyzed using the same model. However, the data in B2 significantly
    differs in appearance from the data in B1\. To address this problem, instance
    transfer (further explained in Section [2.3.1](#S2.SS3.SSS1 "2.3.1 Instance transfer
    ‣ 2.3 Deep transfer learning approaches ‣ 2 Deep transfer learning ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions")) is used. Through this learning process,
    the data in B2 is transformed in a way that makes it compatible with the model
    that has been trained exclusively on data from B1\. Transfer learning, in this
    case, is thus achieved by adapting the data to fit the model through domain adaptation
    rather than adjusting the model to fit new data.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：迁移学习问题设置的分类（左；见[2.2](#S2.SS2 "2.2 深度迁移学习的形式描述 ‣ 2 深度迁移学习 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")中术语的定义）以及使用深度迁移学习方法的相应示例（右）。在左侧，我们将迁移学习问题分类为归纳迁移或传导迁移设置。相应地，我们提供了两个使用深度迁移学习方法的示例：在归纳迁移设置中，我们收集了来自螺丝生产和扳手生产的时间序列数据。标记的螺丝数据（A1）用于检测集体异常（与整个时间序列相比行为不同的一组数据点[[32](#bib.bib32),
    [33](#bib.bib33)]，进一步解释见[3](#S3 "3 工业时间序列异常检测 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")）。然后，应用参数迁移（[2.3.2](#S2.SS3.SSS2
    "2.3.2 参数迁移 ‣ 2.3 深度迁移学习方法 ‣ 2 深度迁移学习 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")）通过微调从标记的螺丝数据预训练模型来检测点异常（在[3](#S3
    "3 工业时间序列异常检测 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")中进一步解释），在标记的扳手数据（A2）上进行。对于下面板中的传导迁移设置，我们展示了一个不同的背景异常检测情况（在[3](#S3
    "3 工业时间序列异常检测 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")中进一步解释）。在这种情况下，我们有两个数据集B1和B2，使用相同的模型进行分析。然而，B2中的数据在外观上与B1中的数据显著不同。为了解决这个问题，使用实例迁移（在[2.3.1](#S2.SS3.SSS1
    "2.3.1 实例迁移 ‣ 2.3 深度迁移学习方法 ‣ 2 深度迁移学习 ‣ 工业时间序列异常检测的深度迁移学习的全面调查：方法、应用和方向")中进一步解释）。通过这个学习过程，B2中的数据被转化为与仅在B1数据上训练的模型兼容的方式。因此，这种情况下的迁移学习是通过领域适应将数据调整以适应模型，而不是调整模型以适应新数据。
- en: 2.2 Formal description of deep transfer learning
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 深度迁移学习的形式描述
- en: Domain $\mathcal{D}$ includes the domain feature space $\mathcal{X}$ and marginal
    data distribution $P(X)$ as $\mathcal{D}=\{\mathcal{X},P(X)\}$, where $X$ is the
    domain data, $X=\left\{x_{1},\ldots,x_{n}\right\}\in\mathcal{X}$. Similarly, a
    learning task is defined as $\mathcal{T}=\{\mathcal{Y},f_{\mathcal{T}}(\cdot)\}$,
    where $\mathcal{Y}$ denotes the task space and usually represents class label.
    For anomaly detection tasks, $\mathcal{Y}$ is the set of the two classes “normal”
    and “abnormal”. The function $f_{\mathcal{T}}(\cdot)$ can be used to predict the
    corresponding label of a new instance $x_{i}$. The objective predictive function
    $f_{\mathcal{T}}(\cdot)$ learned from domain data can be interpreted as a form
    of conditional probability. Thus, the learning task can be rewritten as $\mathcal{T}=\{\mathcal{Y},P(Y|X)\}$,
    where $P(Y|X)$ is used as a likelihood measure to determine how well a given data
    set $X$ fits with a corresponding class label set $Y$.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 领域$\mathcal{D}$包括领域特征空间$\mathcal{X}$和边际数据分布$P(X)$，即$\mathcal{D}=\{\mathcal{X},P(X)\}$，其中$X$是领域数据，$X=\left\{x_{1},\ldots,x_{n}\right\}\in\mathcal{X}$。类似地，学习任务定义为$\mathcal{T}=\{\mathcal{Y},f_{\mathcal{T}}(\cdot)\}$，其中$\mathcal{Y}$表示任务空间，通常表示类别标签。对于异常检测任务，$\mathcal{Y}$是“正常”和“异常”这两个类别的集合。函数$f_{\mathcal{T}}(\cdot)$可用于预测新实例$x_{i}$的相应标签。从领域数据中学习到的目标预测函数$f_{\mathcal{T}}(\cdot)$可以解释为条件概率的一种形式。因此，学习任务可以重写为$\mathcal{T}=\{\mathcal{Y},P(Y|X)\}$，其中$P(Y|X)$用作可能性度量，以确定给定数据集$X$与相应类别标签集$Y$的拟合程度。
- en: In the surveyed literature on transfer learning for anomaly detection in industrial
    applications, transfer learning methods from other fields, such as computer vision
    and natural language processing, were adopted. We therefore use a generic classification
    scheme for transfer learning methods. We largely follow the definition of transfer
    learning in literature [[27](#bib.bib27), [28](#bib.bib28)]. Given a source domain
    $\mathcal{D}_{S}$ and learning task $\mathcal{T}_{S}$, as well as a target domain
    $\mathcal{D}_{T}$ and learning task $\mathcal{T}_{T}$, transfer learning aims
    to improve the performance of the predictive function $f_{\mathcal{T}}(\cdot)$
    in $\mathcal{D}_{T}$ by transferring knowledge from $\mathcal{D}_{S}$ and $\mathcal{T}_{S}$,
    where $\mathcal{D}_{S}\neq\mathcal{D}_{T}$ and/or $\mathcal{T}_{S}\neq\mathcal{T}_{T}$.
    Usually, the size of source dataset is much smaller than target dataset.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在对工业应用中异常检测的迁移学习文献调查中，采用了来自其他领域如计算机视觉和自然语言处理的迁移学习方法。因此，我们使用通用的迁移学习方法分类方案。我们大致遵循文献中的迁移学习定义[[27](#bib.bib27),
    [28](#bib.bib28)]。给定源领域$\mathcal{D}_{S}$和学习任务$\mathcal{T}_{S}$，以及目标领域$\mathcal{D}_{T}$和学习任务$\mathcal{T}_{T}$，迁移学习旨在通过从$\mathcal{D}_{S}$和$\mathcal{T}_{S}$转移知识，提升目标领域$\mathcal{D}_{T}$中预测函数$f_{\mathcal{T}}(\cdot)$的性能，其中$\mathcal{D}_{S}\neq\mathcal{D}_{T}$和/或$\mathcal{T}_{S}\neq\mathcal{T}_{T}$。通常，源数据集的规模远小于目标数据集。
- en: This definition of transfer learning can be broadened, i.e., the target task
    can benefit from multiple source domains. Transfer learning is thus the idea of
    making the best use of related source domains to solve new tasks. In contrast,
    traditional machine learning (ML) methods learn each task separately from scratch,
    and each respective model can only be applied to the corresponding task.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 这种迁移学习的定义可以扩展，即目标任务可以受益于多个源领域。因此，迁移学习的理念是充分利用相关的源领域来解决新任务。相比之下，传统的机器学习（ML）方法将每个任务单独从头学习，每个模型仅能应用于对应的任务。
- en: 'We define a taxonomy of transfer learning problem settings as shown in Fig.
    [4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field ‣ 2 Deep transfer learning ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions") mainly depending on the label
    availability in the two domains to be easily applicable to the requirements of
    a case at hand (compare different definitions for other purposes in the literature
    [[27](#bib.bib27)] – [[29](#bib.bib29)]).'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '我们定义了迁移学习问题设置的分类，如图[4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field ‣ 2 Deep
    transfer learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions")所示，主要依赖于两个领域中的标签可用性，以便于满足具体案例的要求（对比文献中的其他定义[[27](#bib.bib27)]
    – [[29](#bib.bib29)]）。'
- en: 'We differentiate it into inductive and transductive transfer learning [[28](#bib.bib28)].
    Inductive transfer learning is applied when the target task is different from
    the source task, i.e., $\mathcal{T}_{S}\neq\mathcal{T}_{T}$ (meaning that $\{\mathcal{Y_{S}}\neq\mathcal{Y_{T}}\}$
    or $\{P(Y_{S}|X_{S})\neq P(Y_{T}|X_{T})\}$). The conditional probability distribution
    is induced with labeled training data in the target domain [[34](#bib.bib34)].
    A corresponding example is illustrated as Scenario A in Fig. [4](#S2.F4 "Figure
    4 ‣ 2.1 Overview of the field ‣ 2 Deep transfer learning ‣ A Comprehensive Survey
    of Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods,
    Applications, and Directions"), where the learning tasks are different and the
    goal of transfer learning is to recognize point anomaly from the collective anomaly
    task. Related areas of inductive transfer learning are multi-task learning [[35](#bib.bib35),
    [36](#bib.bib36)] and sequential learning, depending on whether tasks are learned
    simultaneously or sequentially.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '我们将其分为归纳性和传导性迁移学习 [[28](#bib.bib28)]。归纳性迁移学习应用于目标任务与源任务不同的情况，即 $\mathcal{T}_{S}\neq\mathcal{T}_{T}$（意味着
    $\{\mathcal{Y_{S}}\neq\mathcal{Y_{T}}\}$ 或 $\{P(Y_{S}|X_{S})\neq P(Y_{T}|X_{T})\}$）。条件概率分布通过目标领域中的标记训练数据进行推断
    [[34](#bib.bib34)]。图 [4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field ‣ 2 Deep
    transfer learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions") 中的场景
    A 是一个对应的例子，其中学习任务不同，迁移学习的目标是从集体异常任务中识别点异常。归纳性迁移学习的相关领域包括多任务学习 [[35](#bib.bib35),
    [36](#bib.bib36)] 和顺序学习，具体取决于任务是同时学习还是顺序学习。'
- en: 'Transductive transfer learning is applied when the source and target tasks
    are the same, while the source and target domain are different, i.e., $\mathcal{T}_{S}=\mathcal{T}_{T}$
    and $\mathcal{D}_{S}\neq\mathcal{D}_{T}$ (meaning that $\{\mathcal{X_{S}}\neq\mathcal{X_{T}}\}$
    or $\{P(X_{S})\neq P(X_{T})\}$. A subcategory is domain adaptation [[37](#bib.bib37)]
    when the feature space of source and target data are the same but the corresponding
    marginal distributions are different (i.e., $\{\mathcal{X_{S}=X_{T}}\}$ and $\{P(X_{S})\neq
    P(X_{T})\}$). Scenario B in Fig. [4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field
    ‣ 2 Deep transfer learning ‣ A Comprehensive Survey of Deep Transfer Learning
    for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions")
    is an example of transductive transfer learning where the learning tasks are identical,
    and the goal of transfer learning is to recognize contextual anomalies in an unlabelled
    data set.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '传导性迁移学习应用于源任务和目标任务相同，但源领域和目标领域不同的情况，即 $\mathcal{T}_{S}=\mathcal{T}_{T}$ 和 $\mathcal{D}_{S}\neq\mathcal{D}_{T}$（意味着
    $\{\mathcal{X_{S}}\neq\mathcal{X_{T}}\}$ 或 $\{P(X_{S})\neq P(X_{T})\}$）。当源数据和目标数据的特征空间相同但边际分布不同时（即
    $\{\mathcal{X_{S}=X_{T}}\}$ 和 $\{P(X_{S})\neq P(X_{T})\}$），它是一种领域适应 [[37](#bib.bib37)]。图
    [4](#S2.F4 "Figure 4 ‣ 2.1 Overview of the field ‣ 2 Deep transfer learning ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions") 中的场景 B 是传导性迁移学习的一个例子，其中学习任务相同，迁移学习的目标是在未标记的数据集中识别上下文异常。'
- en: 2.3 Deep transfer learning approaches
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 深度迁移学习方法
- en: Since deep neural networks (DNNs) can learn useful feature representations from
    large amounts of data through back-propagation [[24](#bib.bib24)], they have been
    widely adopted for tackling complex problems in practice [[38](#bib.bib38), [39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41)], which involve large-scale and high-dimensional
    data. Deep transfer learning methods implement transfer learning principles within
    DNN and, among other things, enable deep learning based analysis pipelines to
    be applied to new datasets.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 由于深度神经网络（DNNs）能够通过反向传播从大量数据中学习有用的特征表示 [[24](#bib.bib24)]，因此它们已被广泛应用于解决实际中的复杂问题
    [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41)]，这些问题涉及大规模和高维数据。深度迁移学习方法在
    DNN 中实现迁移学习原理，并且，除了其他功能外，还使得基于深度学习的分析管道能够应用于新的数据集。
- en: 'Based on the transferring techniques in the surveyed literature, we access
    how knowledge is shared across domains and help increase the performance in the
    target task or domain. we divide deep transfer learning approaches further into
    $4$ categories: instance transfer, parameter transfer, mapping transfer, and domain-adversarial
    transfer, as illustrated in Table [1](#S2.T1 "Table 1 ‣ 2.3 Deep transfer learning
    approaches ‣ 2 Deep transfer learning ‣ A Comprehensive Survey of Deep Transfer
    Learning for Anomaly Detection in Industrial Time Series: Methods, Applications,
    and Directions"). Furthermore, instance transfer, mapping transfer, and domain-adversarial
    transfer can be described as data-driven approaches. They focus on transferring
    knowledge by leveraging a large amount of data. It usually involves transforming
    and adjusting the data instances or manipulating data from different domains by
    feature alignment, feature mapping, etc. On the other hand, parameter transfer
    is a model-driven approach, which places more emphasis on understanding the underlying
    structure and dynamics of the data. It usually involves transferring the parameters
    of pre-trained model from source domain to target domain.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '基于调查文献中的迁移技术，我们探讨了知识如何在不同领域间共享，并帮助提高目标任务或领域的性能。我们进一步将深度迁移学习方法分为 $4$ 类：实例迁移、参数迁移、映射迁移和领域对抗迁移，如表
    [1](#S2.T1 "Table 1 ‣ 2.3 Deep transfer learning approaches ‣ 2 Deep transfer
    learning ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions") 所示。此外，实例迁移、映射迁移和领域对抗迁移可以被描述为数据驱动的方法。它们通过利用大量数据来转移知识。通常涉及通过特征对齐、特征映射等方式转化和调整数据实例或操控来自不同领域的数据。另一方面，参数迁移是一种模型驱动的方法，更强调理解数据的潜在结构和动态。通常涉及将预训练模型的参数从源领域迁移到目标领域。'
- en: 'Table 1: Overview of deep transfer learning approaches with references.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 深度迁移学习方法概述及参考文献。'
- en: '| Deep transfer learning approach | Short description | References |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 深度迁移学习方法 | 简短描述 | 参考文献 |'
- en: '| --- | --- | --- |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Instance transfer | Augmenting target data by transforming data instance
    from the source domain to the target domain | [[42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44)] |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 实例迁移 | 通过将源领域的数据实例转换到目标领域来扩充目标数据 | [[42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44)]
    |'
- en: '| Parameter transfer | Transfering learned parameters of a pre-trained model
    from source domain and adapting the model for target domain | [[45](#bib.bib45),
    [46](#bib.bib46), [47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50),
    [17](#bib.bib17), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53)] |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 参数迁移 | 迁移源领域的预训练模型的学习参数并调整模型以适应目标领域 | [[45](#bib.bib45), [46](#bib.bib46),
    [47](#bib.bib47), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50), [17](#bib.bib17),
    [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53)] |'
- en: '| Mapping transfer | Reducing feature discrepancies between source and target
    domains by minimizing the distance between mapped features in the latent space
    | [[27](#bib.bib27), [54](#bib.bib54), [55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57),
    [58](#bib.bib58), [59](#bib.bib59)] |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 映射迁移 | 通过最小化映射特征在潜在空间中的距离来减少源领域和目标领域之间的特征差异 | [[27](#bib.bib27), [54](#bib.bib54),
    [55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]
    |'
- en: '| Domain-adversarial transfer | Extracting an indiscriminative feature representation
    between source and target domain through adversarial training | [[60](#bib.bib60),
    [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65)]
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 领域对抗迁移 | 通过对抗训练提取源领域和目标领域之间的不可区分特征表示 | [[60](#bib.bib60), [61](#bib.bib61),
    [62](#bib.bib62), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65)] |'
- en: 2.3.1 Instance transfer
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1 实例迁移
- en: The intuition of instance transfer is that although source and target domains
    differ, it is still possible to transform and reuse source data together with
    a few labeled target samples. A typical approach is to re-create some labeled
    data from the source domain. For example, He et al. propose an instance-based
    deep transfer learning model with an attention mechanism to predict stock movement
    [[42](#bib.bib42)]. They first create new samples from the source dataset that
    are similar to the target samples by using an attention network and then train
    another network on the created samples and target training samples for prediction
    tasks. Since two networks are trained separately for different tasks, it needs
    further investigation to what extent the generated samples can contribute to the
    prediction task. Amirain et al. introduce an innovative instance transfer method
    for domain adaptation [[43](#bib.bib43)]. They propose an effective auto-encoder
    model with a pseudo-label classifier to reconstruct new data instances that obtain
    general features across different datasets for medical image analysis. Taking
    another avenue, Wang et al. exclude the source data that negatively impacts training
    target data. Specifically, they choose a pre-trained model from a source domain,
    estimate the impact of all training samples in the target domain, and remove samples
    that lower the model’s performance. Then, the optimized training data is used
    for fine-tuning. The experiments are conducted on large image datasets [[44](#bib.bib44)].
    Instead of transferring the data, the approach excludes certain samples based
    on the pre-trained model’s predictions. Additional validation is required in industrial
    environments, especially when only a few data are available in some industrial
    settings.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 实例转移的直观概念是，尽管源领域和目标领域不同，但仍然可以通过少量标记的目标样本来转换和重用源数据。一个典型的方法是从源领域重新创建一些标记的数据。例如，He等人提出了一种基于实例的深度转移学习模型，该模型结合了注意力机制来预测股票走势[[42](#bib.bib42)]。他们首先利用注意力网络从源数据集中创建出与目标样本相似的新样本，然后在这些创建的样本和目标训练样本上训练另一个网络以进行预测任务。由于两个网络分别针对不同的任务进行训练，因此需要进一步研究生成样本在预测任务中的贡献程度。Amirain等人提出了一种创新的实例转移方法用于领域适应[[43](#bib.bib43)]。他们提出了一种有效的自编码器模型，配合伪标签分类器来重建新的数据实例，以获取跨不同数据集的一般特征，用于医学图像分析。另一种方法是，Wang等人排除了对训练目标数据产生负面影响的源数据。具体来说，他们选择了一个来自源领域的预训练模型，评估了目标领域中所有训练样本的影响，并移除那些降低模型性能的样本。然后，优化后的训练数据用于微调。这些实验在大型图像数据集上进行[[44](#bib.bib44)]。与其转移数据，这种方法根据预训练模型的预测排除某些样本。在工业环境中需要额外的验证，尤其是在某些工业设置中只有少量数据的情况下。
- en: 2.3.2 Parameter transfer
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2 参数转移
- en: Parameter transfer adapts the learned parameters of a pre-trained model to a
    new model. This assumes that DNNs can get similar feature representations from
    similar domains. Thus, through transferring parts of the DNN layers together with
    pre-trained parameters and/or hyperparameters, the pre-trained model is used as
    a base model to further train on target domain data and solve different learning
    tasks. Particularly, parameter transfer has gained popularity in computer vision
    and natural language processing, where large models are pre-trained on large datasets
    [[45](#bib.bib45)]. In natural language processing, for example, BERT [[46](#bib.bib46)]
    and GPT-3 [[53](#bib.bib53)] are based on the Transformer architecture [[48](#bib.bib48)]
    which can be fine-tuned for a variety of downstream tasks, including content generation
    [[49](#bib.bib49)], language translation [[66](#bib.bib66)], question answering
    [[67](#bib.bib67)], and summarization [[50](#bib.bib50)]. In computer vision,
    Yosinski et al. investigate the general transferability of CNNs in image recognition
    [[30](#bib.bib30)]. They analyze the transferring effect by fine-tuning or freezing
    a certain amount of layers in the networks. Experimental results show that transferring
    features from source to target domain improves network generalization compared
    to those trained solely on the target dataset. Additionally, they quantify the
    model performance by assessing how features at what layers transfer from one task
    to another. It is surprising to find that transferring a pre-trained network from
    any number of layers can produce a boost for fine-tuning on a new dataset. However,
    the experiments are only conducted on certain image datasets, and Tuggener *et
    al.* show [[68](#bib.bib68)] the limits of parameter transfer when the chosen
    architecture is overfitted on the particularities of certain large-scale datasets.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 参数转移将预训练模型的学习参数适配到新模型中。这假设深度神经网络（DNNs）可以从相似的领域中获取类似的特征表示。因此，通过转移部分 DNN 层及预训练的参数和/或超参数，预训练模型作为基础模型用于进一步在目标领域数据上训练，并解决不同的学习任务。特别地，参数转移在计算机视觉和自然语言处理领域越来越受欢迎，其中大规模模型在大数据集上预训练[[45](#bib.bib45)]。在自然语言处理领域，例如，BERT
    [[46](#bib.bib46)]和GPT-3 [[53](#bib.bib53)]基于可以针对各种下游任务进行微调的Transformer架构[[48](#bib.bib48)]，这些任务包括内容生成[[49](#bib.bib49)]、语言翻译[[66](#bib.bib66)]、问答[[67](#bib.bib67)]和摘要[[50](#bib.bib50)]。在计算机视觉中，Yosinski
    等人研究了卷积神经网络（CNNs）在图像识别中的通用转移性[[30](#bib.bib30)]。他们通过微调或冻结网络中的一定层数来分析转移效果。实验结果表明，与仅在目标数据集上训练的网络相比，将特征从源领域转移到目标领域可以提高网络的泛化能力。此外，他们通过评估在什么层次上从一个任务转移到另一个任务的特征来量化模型性能。令人惊讶的是，从任意层次的预训练网络进行转移可以为新数据集上的微调带来提升。然而，实验仅在某些图像数据集上进行，Tuggener
    *et al.* 表示[[68](#bib.bib68)] 当所选择的架构在某些大规模数据集的特性上过拟合时，参数转移的限制。
- en: Unlike the typical way of fine-tuning a pre-trained model, Guo et al. propose
    an adaptive fine-tuning approach SpotTune to find the optimal fine-tuning strategy
    for the target task [[51](#bib.bib51)]. Specifically, a policy network is used
    to make routing decisions on whether to pass the target instance through the pre-trained
    model. The results show SpotTune is effective in most cases by using a hybrid
    of parameter and instance transfer. Sager et al. propose an unsupervised domain
    adaptation for vertebrae detection in 3D CT volumes by transferring knowledge
    across domains during the training process [[52](#bib.bib52)].
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 与典型的微调预训练模型的方法不同，Guo 等人提出了一种自适应微调方法 SpotTune，以寻找目标任务的最佳微调策略[[51](#bib.bib51)]。具体来说，使用一个策略网络来决定是否将目标实例通过预训练模型进行处理。结果表明，SpotTune
    在大多数情况下通过使用参数和实例转移的混合方法是有效的。Sager 等人提出了一种无监督领域适应方法，用于在3D CT体积中进行椎骨检测，通过在训练过程中跨领域转移知识[[52](#bib.bib52)]。
- en: 2.3.3 Mapping transfer
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.3 映射转移
- en: Mapping transfer refers to learning a related feature representation for the
    target domain by feature transformation, which includes feature alignment, feature
    mapping, and feature encoding [[27](#bib.bib27)]. The goal is to reduce feature
    discrepancies between source and target domains by minimizing the distance between
    the distribution of latent feature representation. There are various criteria
    to measure the distribution difference, including Wasserstein distance [[69](#bib.bib69)],
    Kullback-Leibler Divergence [[70](#bib.bib70)], etc. Among them, Maximum Mean
    Discrepancy (MMD) [[55](#bib.bib55)] is most frequently adopted in mapping transfer
    from the surveyed papers. The MMD is calculated as the difference between the
    mean embeddings of the samples in a reproducing kernel Hilbert space associated
    with a chosen kernel function. Added to the target loss function, it serves as
    a powerful tool for comparing the similarity of complex, high-dimensional datasets
    using a wide variety of kernel functions.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 映射迁移是指通过特征变换学习目标领域的相关特征表示，包括特征对齐、特征映射和特征编码[[27](#bib.bib27)]。其目标是通过最小化潜在特征表示分布之间的距离，减少源领域和目标领域之间的特征差异。有多种标准来衡量分布差异，包括Wasserstein距离[[69](#bib.bib69)]、Kullback-Leibler散度[[70](#bib.bib70)]等。其中，最大均值差异（MMD）[[55](#bib.bib55)]在调查的文献中被最频繁地采用。MMD计算的是与选定的核函数相关的再生核希尔伯特空间中样本均值嵌入之间的差异。将其添加到目标损失函数中，它作为一种强大的工具，利用多种核函数比较复杂的高维数据集的相似性。
- en: Previous work has focused on transferred feature extraction/dimensionality reduction
    using MMD. Wang et al. focus more on the subdomain of the same subcategory instead
    of the alignment of the global distribution between source and target domain [[54](#bib.bib54)].
    Specifically, they first use the attention mechanism to extract discriminative
    features that are most related to the fault signal. Then, local MMD is applied
    to transfer knowledge to adjust the distribution of related subdomains under the
    same category. Long et al. propose their Joint Adaptation Network [[56](#bib.bib56)]
    based on MMD, in which the joint distributions of multiple domain-specific layers
    across domains are aligned. In addition, an adversarial training version was adopted
    to make distributions of the source and target domains more distinguishable. Similarly,
    Long et al. adopt multi-layer adaptation and proposed Deep Adaptation Networks
    (DAN) [[57](#bib.bib57)]. The first three convolutional layers are used in DAN
    models to extract general features. For the last three layers, multi-kernel MMD
    bridges the cross-domain discrepancy and learns transferable features. Zhang et
    al. propose a Deep Transfer Network in which two types of layers are used to obtain
    domain invariant features across domains by adding MMD loss. The shared feature
    extraction layers learn a shared feature subspace between the source and the target
    samples, and the discrimination layer is then used to match conditional distributions
    by classifier transduction [[58](#bib.bib58)]. Venkateswara et al. propose Deep
    Adaptation Hash network [[59](#bib.bib59)], which is fine-tuned from the VGG-F
    [[71](#bib.bib71)] network. Multi-kernel MMD loss is employed to train the Deep
    Adaptation Hash network to learn feature representations that align the source
    and target domains.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 以往的工作主要集中在使用MMD进行迁移特征提取/降维。Wang等人更关注于同一子类别的子域，而不是源领域和目标领域之间全局分布的对齐[[54](#bib.bib54)]。具体而言，他们首先使用注意力机制提取与故障信号最相关的区分特征。然后，应用局部MMD进行知识迁移，以调整同一类别下相关子域的分布。Long等人提出了基于MMD的联合适应网络[[56](#bib.bib56)]，在该网络中，多个领域特定层的联合分布在不同领域之间对齐。此外，采用了对抗训练版本，使源领域和目标领域的分布更具可区分性。类似地，Long等人采用了多层适应，并提出了深度适应网络（DAN）[[57](#bib.bib57)]。DAN模型中的前三个卷积层用于提取一般特征。对于最后三层，多核MMD弥合了跨领域差异并学习可迁移特征。Zhang等人提出了一种深度迁移网络，其中使用了两种类型的层，通过添加MMD损失来获得跨领域的领域不变特征。共享特征提取层学习源样本和目标样本之间的共享特征子空间，然后使用判别层通过分类器传递来匹配条件分布[[58](#bib.bib58)]。Venkateswara等人提出了深度适应哈希网络[[59](#bib.bib59)]，该网络是从VGG-F[[71](#bib.bib71)]网络微调而来的。多核MMD损失被用于训练深度适应哈希网络，以学习对齐源领域和目标领域的特征表示。
- en: 2.3.4 Domain-adversarial transfer
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.4 域对抗迁移
- en: Inspired by Generative Adversarial Networks (GANs) [[72](#bib.bib72), [73](#bib.bib73)],
    the goal of domain-adversarial transfer is to extract a transferable feature representation
    that is indiscriminative between source and target domain through adversarial
    training. Adversarial transfer is primarily concerned with addressing domain adaptation
    problems.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 受到生成对抗网络（GANs）[[72](#bib.bib72), [73](#bib.bib73)]的启发，领域对抗迁移的目标是通过对抗训练提取一个在源领域和目标领域之间不可区分的可迁移特征表示。对抗迁移主要关注于解决领域适应问题。
- en: Soleimani and Nazerfard utilize the GANs framework to perform cross-subject
    transfer learning [[60](#bib.bib60)]. The generator is used to generate samples
    that are similar to the target data. Meanwhile, the discriminator distinguishes
    the fake samples from the target samples. The classifier is trained to discriminate
    the labeled source data and fake samples to learn generalized features invariant
    to source and target domains. It is important to note that in real-world applications,
    training GANs can be unstable due to mode collapse, especially in the case when
    the source data and target data are unbalanced, and the generator may fail to
    generate fake samples that can confuse the discriminator. Tzeng et al. adopt a
    domain confusion loss across the source and target domains to learn a domain invariant
    representation [[61](#bib.bib61)]. Ganin et al. propose a new domain adaptation
    architecture by adding a domain classifier after feature extraction layers [[63](#bib.bib63)].
    A gradient reversal layer is used to ensure the similarity of the feature distributions
    over source and target domains. Similarly, Ozyurt et al. develop a novel framework
    for unsupervised domain adaptation of time series data by using contrastive learning
    and domain-adversarial transfer learning [[62](#bib.bib62)]. A domain classification
    loss is applied to extract domain invariant features. The drawback is that the
    experiments are designed in a way that the source and target data sizes are similar,
    whereas in practice, the target data is usually much fewer than the source data.
    Ajakan et al. propose a domain adversarial DNN in which a domain regressor is
    applied to learn a domain invariant feature representation [[64](#bib.bib64)].
    Tzeng et al. use an unsupervised domain adaptation method that combines adversarial
    learning with discriminative feature learning [[65](#bib.bib65)].
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Soleimani 和 Nazerfard 利用 GANs 框架进行跨主题迁移学习 [[60](#bib.bib60)]。生成器用于生成与目标数据相似的样本。与此同时，判别器区分假样本和目标样本。分类器被训练以区分标记的源数据和假样本，从而学习对源领域和目标领域不变的特征。需要注意的是，在实际应用中，由于模式崩溃，GANs
    的训练可能不稳定，尤其是当源数据和目标数据不平衡时，生成器可能无法生成足以混淆判别器的假样本。Tzeng 等人采用领域混淆损失来学习领域不变表示 [[61](#bib.bib61)]。Ganin
    等人通过在特征提取层之后添加领域分类器来提出一种新的领域适应架构 [[63](#bib.bib63)]。使用梯度反转层来确保源领域和目标领域之间特征分布的相似性。同样，Ozyurt
    等人通过使用对比学习和领域对抗迁移学习来开发了一种用于时间序列数据的无监督领域适应的新框架 [[62](#bib.bib62)]。应用领域分类损失来提取领域不变特征。其缺点是实验设计时源数据和目标数据的规模相似，而在实际应用中，目标数据通常远少于源数据。Ajakan
    等人提出了一种领域对抗深度神经网络（DNN），其中应用了领域回归器以学习领域不变的特征表示 [[64](#bib.bib64)]。Tzeng 等人使用了一种将对抗学习与判别特征学习相结合的无监督领域适应方法
    [[65](#bib.bib65)]。
- en: 2.4 Related learning paradigms
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 相关学习范式
- en: Besides the dedicated transfer learning approaches discussed above, there are
    methods that represent alternative ways to solve tasks across domains or are complementary
    to the native transfer learning methods.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述讨论的专用迁移学习方法，还有一些方法代表了跨领域解决任务的替代方式或与本地迁移学习方法互补的方式。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Multi-task learning is a machine learning technique where a single model is
    trained on multiple tasks simultaneously. The idea is to improve the performance
    of the model by learning a shared representation that captures the features between
    all tasks. Because the network learns to solve multiple tasks, it may generalize
    better to new data and tasks.
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多任务学习是一种机器学习技术，其中一个模型同时在多个任务上进行训练。其理念是通过学习一个共享的表示来捕捉所有任务之间的特征，从而提高模型的性能。由于网络学习解决多个任务，它可能会更好地推广到新的数据和任务上。
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Continuous learning [[74](#bib.bib74)] is a learning process where the model
    continuously learns new tasks from previous tasks over time without forgetting
    how to solve previous tasks. To some extent, continuous learning can be seen as
    a sequential transfer learning process, with the constraint to preserve the performance
    of the previous tasks, which leads to an accumulation of knowledge over time.
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 连续学习[[74](#bib.bib74)]是一种学习过程，其中模型随着时间的推移不断从以前的任务中学习新任务，同时不忘记如何解决以前的任务。在某种程度上，连续学习可以被视为一种顺序转移学习过程，其约束是保持之前任务的性能，从而导致知识的积累。
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Few-shot learning [[75](#bib.bib75)] is a type of machine learning where a model
    can learn and perform well on a new task with only a limited number of labeled
    samples. In extreme cases, the model can learn with one label [[76](#bib.bib76)]
    and without any label [[77](#bib.bib77)]. Whereas, transfer learning usually involves
    reusing the model from relevant tasks and continuing training on the target dataset.
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 少样本学习[[75](#bib.bib75)]是一种机器学习类型，其中模型可以仅通过有限数量的标记样本来学习并在新任务上表现良好。在极端情况下，模型可以通过一个标签[[76](#bib.bib76)]甚至没有标签[[77](#bib.bib77)]来学习。而转移学习通常涉及重新使用相关任务中的模型，并继续在目标数据集上进行训练。
- en: •
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Domain generalization[[78](#bib.bib78), [79](#bib.bib79)] focuses on developing
    a generalized model from one or multiple distinct domains to detect unseen target
    domain data. The main goal is to overcome the domain shift problem. Domain generalization
    and transfer learning are both applied to transfer knowledge from source domain
    to target domain. The major difference between transfer learning and domain generalization
    lies in the utilization of target domain data. Transfer learning leverages knowledge
    from source domain and target domain. In contrast, domain generalization solely
    learns from source domain, without access to the target data.
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 域泛化[[78](#bib.bib78), [79](#bib.bib79)]专注于从一个或多个不同领域开发一个泛化模型，以检测未见的目标领域数据。主要目标是克服领域转移问题。域泛化和转移学习都用于将知识从源领域转移到目标领域。转移学习和域泛化的主要区别在于目标领域数据的利用。转移学习利用来自源领域和目标领域的知识。相比之下，域泛化仅从源领域学习，而不接触目标数据。
- en: •
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Meta-learning [[80](#bib.bib80), [81](#bib.bib81)] is known as “learning to
    learn”. For meta-learning, models are trained on a different set of tasks instead
    of a set of data in the traditional machine learning setting. In this sense, meta-learning
    can be seen as a form of transfer learning because it involves transferring knowledge
    from task to task.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 元学习[[80](#bib.bib80), [81](#bib.bib81)]被称为“学习如何学习”。在元学习中，模型是在一组不同的任务上进行训练，而不是传统机器学习中的数据集。从这个意义上说，元学习可以被视为一种转移学习，因为它涉及将知识从任务转移到任务。
- en: •
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Knowledge distillation [[82](#bib.bib82)] effectively learns a small model trained
    to mimic the behavior of a larger, more complex model. The knowledge learned by
    the larger model can be transferred to the smaller model, which can then be used
    for the target task.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 知识蒸馏[[82](#bib.bib82)]有效地学习一个小模型，以模仿较大、更复杂模型的行为。较大模型学到的知识可以转移到较小模型中，从而可以用于目标任务。
- en: •
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Self-supervised learning [[83](#bib.bib83), [84](#bib.bib84)] involves training
    a model to predict some aspect of the input data without any external supervision.
    The learned representations can be used for various downstream tasks, including
    those that involve transferring knowledge from one domain to another.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自监督学习[[83](#bib.bib83), [84](#bib.bib84)]涉及训练一个模型以预测输入数据的某些方面，而无需任何外部监督。所学的表示可以用于各种下游任务，包括涉及将知识从一个领域转移到另一个领域的任务。
- en: 3 Time series anomaly detection in industry
  id: totrans-119
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 工业中的时间序列异常检测
- en: 'Time series anomaly detection encompasses statistical techniques to analyze
    and interpret sequential temporal data. In the context of industrial processes,
    time series anomaly detection plays a crucial role in automating monitoring, effectively
    scheduling maintenance, and controlling the efficiency, quality, and performance
    of these processes. For example, after the detection of an anomaly, another model
    that captures the relationship between time course and different failure modes
    or drifts may be exploited for predictive maintenance. For example, in injection
    molding process monitoring, anomaly detection models are used to analyze recorded
    sensor data from injection molding machines to detect bad parts and identify the
    root cause of anomalies [[85](#bib.bib85)]. There are two basic ways to detect
    anomalies: for supervised anomaly detection, labels (normal/abnormal) are needed
    per time series to build a binary classifier [[86](#bib.bib86)]. For unsupervised
    anomaly detection, an anomaly score or confidence value that is conditioned purely
    on normal data can be used to differentiate abnormal from normal instances [[87](#bib.bib87)]
    –[[88](#bib.bib88)].'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列异常检测涵盖了用于分析和解释顺序时间数据的统计技术。在工业过程中，时间序列异常检测在自动化监控、有效安排维护以及控制这些过程的效率、质量和性能方面发挥了至关重要的作用。例如，在检测到异常后，可以利用另一个模型，该模型捕捉时间过程与不同故障模式或漂移之间的关系，用于预测性维护。例如，在注塑过程监控中，异常检测模型用于分析来自注塑机的记录传感器数据，以检测不良零件并识别异常的根本原因[[85](#bib.bib85)]。检测异常有两种基本方法：对于有监督的异常检测，需要每个时间序列的标签（正常/异常）来建立一个二分类器[[86](#bib.bib86)]。对于无监督的异常检测，可以使用基于正常数据的异常评分或置信值来区分异常与正常实例[[87](#bib.bib87)]
    –[[88](#bib.bib88)]。
- en: 3.1 Anomaly types
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 异常类型
- en: 'According to the literature [[89](#bib.bib89)], an outlier is an observation
    that deviates significantly from other observations in a way that it is likely
    that it was generated by a different mechanism. In this survey, we focus on time
    series data collected from machine sensor readings in the context of industrial
    applications, either univariate (only one variable is recorded over time) or multivariate
    (several simultaneously recorded measurements). Time series anomalies might occur
    for various reasons, including internal factors (e.g., temporary sensor error,
    machinery malfunction) and external factors (e.g. human error, ambient temperature).
    They can be divided into three categories [[32](#bib.bib32)], [[33](#bib.bib33)]:
    point anomalies, contextual anomalies, and collective anomalies. Point anomalies
    are isolated samples that deviate significantly from the normal behavior of that
    time series, which can be seen on the left of Fig. [5](#S3.F5 "Figure 5 ‣ 3.1
    Anomaly types ‣ 3 Time series anomaly detection in industry ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions"), e.g., a sudden spike in a pressure reading
    from a manufacturing machine sensor. These point anomalies can be caused by temporal
    sensor error, human error, or abnormal machinery operations. Contextual anomalies
    represent data points that deviate from normal ones only in their current context,
    and an example can be seen in the middle of Fig. [5](#S3.F5 "Figure 5 ‣ 3.1 Anomaly
    types ‣ 3 Time series anomaly detection in industry ‣ A Comprehensive Survey of
    Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods,
    Applications, and Directions"). Collective anomalies are a set of data points
    that in their entirety (but not individually) are abnormal with respect to the
    entire time series, as shown on the right of Fig. [5](#S3.F5 "Figure 5 ‣ 3.1 Anomaly
    types ‣ 3 Time series anomaly detection in industry ‣ A Comprehensive Survey of
    Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods,
    Applications, and Directions").'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '根据文献[[89](#bib.bib89)]，离群点是指那些显著偏离其他观测值的观测结果，这种偏离方式表明其可能是由不同机制生成的。在本调查中，我们重点关注在工业应用环境中从机器传感器读取的数据时间序列，这些数据可以是单变量（只记录一个变量的时间变化）或多变量（同时记录多个测量值）。时间序列异常可能由于各种原因发生，包括内部因素（例如，临时传感器错误、机械故障）和外部因素（例如，人为错误、环境温度）。这些异常可以分为三类[[32](#bib.bib32)]、[[33](#bib.bib33)]：点异常、上下文异常和集合异常。点异常是指那些明显偏离该时间序列正常行为的孤立样本，可以在图[5](#S3.F5
    "Figure 5 ‣ 3.1 Anomaly types ‣ 3 Time series anomaly detection in industry ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions")的左侧看到，例如，制造机传感器中的压力读数突然激增。这些点异常可能由临时传感器错误、人为错误或机械操作异常引起。上下文异常表示在当前上下文中偏离正常数据点的数据点，示例可以在图[5](#S3.F5
    "Figure 5 ‣ 3.1 Anomaly types ‣ 3 Time series anomaly detection in industry ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions")的中间部分看到。集合异常是一组数据点，在整体上（而非单独）相对于整个时间序列是不正常的，如图[5](#S3.F5
    "Figure 5 ‣ 3.1 Anomaly types ‣ 3 Time series anomaly detection in industry ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions")的右侧所示。'
- en: '![Refer to caption](img/c48a928c1fcb98ef7b00fa9607d3b047.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c48a928c1fcb98ef7b00fa9607d3b047.png)'
- en: 'Figure 5: Three time series anomaly types. Gray lines represent recorded time
    series signals, and dashed green lines are a priori set thresholds of normal operations.
    The red dots and the red line indicate anomalies. Point anomalies are single values
    that fall outside of a pre-set range (left panel). Contextual anomalies are samples
    that deviate from the current context (middle panel). Collective anomalies are
    defined as a series of data points that all fall within the range of operation
    but jointly are not expected (right panel).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：三种时间序列异常类型。灰色线条表示记录的时间序列信号，绿色虚线是预先设定的正常操作阈值。红点和红线表示异常。点异常是落在预设范围之外的单个值（左侧面板）。上下文异常是指偏离当前上下文的样本（中间面板）。集合异常被定义为一系列数据点，这些数据点都落在操作范围内，但整体上不符合预期（右侧面板）。
- en: 3.2 Challenges
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 挑战
- en: 'Challenges regarding detecting time series anomalies persist due to two specific
    properties: (1) The complexity of time series data. As the automation level of
    industrial processes and the complexity of industrial systems increases, univariate
    time series data become insufficient and inefficient in representing any industrial
    process in its entirety. Hence, more sensors are installed to monitor the whole
    process, making it necessary to detect anomalies from multivariate time series,
    which poses particular challenges since it requires consideration of temporal
    dependencies and relationships between variables and modalities. Many researchers
    work on discovering generalized patterns from spatial and temporal correlated
    multivariate time series data. Zhang et al. propose a Deep Convolutional Autoencoding
    Memory network [[87](#bib.bib87)], where they build an autoencoder to capture
    spatial dependency of multi-variant data using MMD to distinguish noisy, normal
    and abnormal data. Zhu et al. propose an interpretable model agnostic multivariate
    time-series anomaly detection method for applications of cyber physical systems
    [[90](#bib.bib90)]. The new method considers both the temporal and feature dimensions
    through an adaptive mask based series saliency module to produce accurate anomaly
    detection results and reasonable interpretations in the form of a mask matrix.
    (2) The dynamic variability in industrial processes. Industrial processes often
    have high dynamic variability and can be affected by a wide range of conditions,
    such as changes in temperature, pressure, and humidity. These conditions can cause
    fluctuations in the process outputs, which leads to data shift and domain shift.
    This can make it challenging to detect anomalies and maintain control over the
    industrial process.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 检测时间序列异常面临的挑战源于两个特定的属性：（1）时间序列数据的复杂性。随着工业过程的自动化水平和工业系统的复杂性增加，单变量时间序列数据在整体上表示任何工业过程变得不足和低效。因此，需要安装更多传感器以监测整个过程，使得从多变量时间序列中检测异常成为必要，这带来了特别的挑战，因为这需要考虑时间依赖性和变量及模态之间的关系。许多研究者致力于从空间和时间相关的多变量时间序列数据中发现泛化模式。张等人提出了一种深度卷积自编码记忆网络[[87](#bib.bib87)]，他们构建了一个自编码器，利用MMD捕捉多变量数据的空间依赖性，以区分噪声、正常和异常数据。朱等人提出了一种可解释的模型无关多变量时间序列异常检测方法，应用于网络物理系统[[90](#bib.bib90)]。该新方法通过基于自适应掩码的系列显著性模块考虑时间和特征维度，以生成准确的异常检测结果和以掩码矩阵形式呈现的合理解释。（2）工业过程中的动态变异性。工业过程通常具有高动态变异性，并且可能受到温度、压力和湿度等多种条件的影响。这些条件可能导致过程输出的波动，从而导致数据偏移和领域偏移。这使得检测异常和维持工业过程控制变得具有挑战性。
- en: 3.3 Anomaly detection methods
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 异常检测方法
- en: 'Time series anomaly detection has been investigated for decades, and various
    types of methods have been proposed [[91](#bib.bib91)]. This paper exclusively
    discusses the time series anomaly detection techniques using deep learning, leveraging
    its robust representation learning capabilities. Current deep learning methods
    can be mainly divided into reconstruction-based, forecasting-based, and other
    methods. Fig. [6](#S3.F6 "Figure 6 ‣ 3.3 Anomaly detection methods ‣ 3 Time series
    anomaly detection in industry ‣ A Comprehensive Survey of Deep Transfer Learning
    for Anomaly Detection in Industrial Time Series: Methods, Applications, and Directions")
    illustrates the two main methods. In deep reconstruction-based anomaly detection,
    the reconstructed sequence is used to compare with the actual sequence. Differently,
    in deep forecasting-based anomaly detection, only the forecasted sequence is used
    to assess the similarity to the ground truth.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 时间序列异常检测已经研究了几十年，提出了各种方法[[91](#bib.bib91)]。本文专门讨论了使用深度学习进行时间序列异常检测的技术，利用其强大的表示学习能力。当前的深度学习方法主要可以分为基于重建的方法、基于预测的方法和其他方法。图[6](#S3.F6
    "图 6 ‣ 3.3 异常检测方法 ‣ 3 时间序列异常检测在工业中的应用 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用和方向") 说明了这两种主要方法。在深度重建异常检测中，重建序列用于与实际序列进行比较。而在深度预测异常检测中，仅使用预测序列来评估与真实值的相似度。
- en: '![Refer to caption](img/ddaf4d222b9bc5abb1dbcb700f602505.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ddaf4d222b9bc5abb1dbcb700f602505.png)'
- en: 'Figure 6: Illustration of deep learning-based anomaly detection (top row) with
    reconstruction-based (center row) and forecasting-based (bottom row) anomaly detection
    in time series. The first column represents two time series. The second column
    shows the reconstructed (top) and forecasted (bottom) time series. The third column
    shows the difference between reconstructed/forecasted time series. Deviations
    from the reconstructed or forecasted time series are indicative of an anomaly.
    In deep reconstruction-based anomaly detection, the entire sequence is reconstructed
    in a decoder-encoder architecture, and the reconstructed sequence is used to compare
    with the actual sequence. In deep forecasting-based anomaly detection, the end
    of a sequence is predicted using the start of the sequence and only the forecasted
    sequence is used to assess the similarity to the ground truth. In this example,
    the red time series has a likely anomaly at about 1.5 seconds. (Best viewed in
    color.)'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：深度学习基础的异常检测（顶行）的示意图，包括基于重建的方法（中行）和基于预测的方法（底行）在时间序列中的异常检测。第一列表示两个时间序列。第二列显示了重建的（顶部）和预测的（底部）时间序列。第三列显示了重建/预测时间序列之间的差异。从重建或预测时间序列中的偏差指示异常。在深度重建基础的异常检测中，整个序列在解码器-编码器结构中被重建，重建序列用于与实际序列进行比较。在深度预测基础的异常检测中，序列的末端是通过序列的开始进行预测的，只有预测序列用于评估与实际情况的相似性。在这个例子中，红色时间序列在大约1.5秒处有可能的异常。（最佳效果请使用彩色显示。）
- en: Reconstruction-based methods
  id: totrans-131
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于重建的方法
- en: Reconstruction-based methods aim to learn the data distribution of the normal
    time series and differentiate the abnormalities from the normal ones by computing
    the reconstruction errors. Audibert et al. propose a fast and stable method –
    Unsupervised anomaly detection for multivariate time series [[92](#bib.bib92)],
    based on adversely trained autoencoders. The encoder-decoder architecture within
    an adversarial training framework combines the advantages of autoencoders and
    adversarial training while compensating for the limitations of each technique.
    After training two autoencoders, the anomaly score is defined by balancing the
    reconstructed errors from the two autoencoders with two hyperparameters. However,
    the challenge arises in selecting these two hyperparameters of the anomaly score
    when the testing dataset is unavailable.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 基于重建的方法旨在学习正常时间序列的数据分布，并通过计算重建误差来区分异常和正常情况。Audibert 等人提出了一种快速而稳定的方法——针对多变量时间序列的无监督异常检测
    [[92](#bib.bib92)]，基于对抗训练的自编码器。对抗训练框架中的编码器-解码器架构结合了自编码器和对抗训练的优点，同时弥补了每种技术的局限性。经过训练两个自编码器后，异常评分通过平衡两个自编码器的重建误差以及两个超参数来定义。然而，当测试数据集不可用时，选择这些异常评分的两个超参数是一个挑战。
- en: Malhotra et al. also formulate an anomaly score based on reconstruction error
    [[93](#bib.bib93)]. They first train the LSTM encoder-decoder model to reconstruct
    the normal time series. Subsequently, they leverage the reconstruction errors
    to calculate the probability by using Maximum Likelihood Estimation to detect
    a specific point within a time series as an anomaly. They set a window to detect
    anomalies. The window will be labeled as anomalous if the probability exceeds
    a threshold. Similarly, Wei et al. also propose an LSTM-based encoder-decoder
    model to detect multivariant time series sequences based on the reconstruction
    error [[94](#bib.bib94)]. The major difference is the anomaly detection criteria.
    They assume the reconstruction error of train/test data follows the normal distribution
    and detect anomalies by using the 2-sigma rule of the normal distribution as a
    threshold. Zeng et al. propose an adversarial transformer structure to detect
    multivariate time series anomalies effectively [[95](#bib.bib95)]. Here, two-stage
    adversarial training is applied for the transformer. In the first stage, two transformers
    are trained by minimizing the reconstruction error to capture the temporal trends
    in the time series. In the second stage, the reconstruction error serves as prior
    knowledge in the adversarial training process, enabling the model to distinguish
    anomalies from normal time series. Then, an anomaly score is defined by combining
    the anomaly probability and reconstruction error. Again, a threshold has been
    chosen to differentiate anomalies from normal ones.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: Malhotra 等人还基于重建误差制定了一种异常分数 [[93](#bib.bib93)]。他们首先训练 LSTM 编码器-解码器模型来重建正常时间序列。随后，他们利用重建误差通过最大似然估计计算概率，以检测时间序列中的特定点是否为异常。他们设置了一个窗口来检测异常。如果概率超过阈值，窗口将被标记为异常。同样，Wei
    等人也提出了一种基于 LSTM 的编码器-解码器模型，通过重建误差检测多变量时间序列序列 [[94](#bib.bib94)]。主要区别在于异常检测标准。他们假设训练/测试数据的重建误差遵循正态分布，并通过使用正态分布的
    2-sigma 规则作为阈值来检测异常。Zeng 等人提出了一种对抗性变换器结构来有效地检测多变量时间序列异常 [[95](#bib.bib95)]。这里，对变换器应用了两阶段的对抗训练。在第一阶段，通过最小化重建误差来训练两个变换器，以捕捉时间序列中的时间趋势。在第二阶段，重建误差作为对抗训练过程中的先验知识，使模型能够区分异常与正常时间序列。然后，通过将异常概率和重建误差结合来定义异常分数。再次选择一个阈值来区分异常和正常情况。
- en: GANs, as effective unsupervised learning methods, have been used in time series
    anomaly detection. Anomaly detection methods based on GANs focus on extracting
    features by adversarial training on normal samples. Consequently, features from
    the abnormal samples diverge from those of the normal ones, reflecting in reconstruction
    error and discrimination value. Li et al. use LSTM-RNN as a base model for building
    generator and discriminator in GAN[[96](#bib.bib96)]. The proposed framework considers
    multiple variables to capture the temporal correlation of multi-time series distributions.
    Additionally, they proposed a novel anomaly score, which can detect anomalies
    through discrimination and reconstruction. More specifically, the score is a combination
    of the reconstruction difference between generated data and original data and
    the discrimination results from the discriminator. Similarly, Niu et al. and Bashar
    et al. both propose an LSTM-based VAE-GAN for time series anomaly detection, where
    LSTM networks are used as the generator, and discriminator [[97](#bib.bib97),
    [98](#bib.bib98)]. When it comes to anomaly scores, setting an optimal threshold
    is usually a critical step. However, using a small portion of the test set to
    decide the optimal threshold may not be practical in real-world scenarios [[97](#bib.bib97)].
    Additionally, it is important to note that the method has been only tested for
    point anomaly detection, further investigation is required when they are applied
    to detect other anomaly types.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 作为有效的无监督学习方法，GAN已被应用于时间序列异常检测。基于GAN的异常检测方法侧重于通过对正常样本进行对抗性训练来提取特征。因此，异常样本的特征与正常样本的特征发生偏离，体现在重建误差和判别值上。Li等人使用LSTM-RNN作为GAN中生成器和判别器的基础模型[[96](#bib.bib96)]。提出的框架考虑了多个变量，以捕捉多时间序列分布的时间相关性。此外，他们提出了一种新颖的异常分数，通过判别和重建来检测异常。更具体地说，该分数是生成数据与原始数据之间的重建差异与来自判别器的判别结果的组合。同样，Niu等人和Bashar等人也提出了基于LSTM的VAE-GAN用于时间序列异常检测，其中LSTM网络作为生成器和判别器[[97](#bib.bib97),
    [98](#bib.bib98)]。在异常分数方面，设置最佳阈值通常是关键步骤。然而，在实际场景中，使用测试集的一小部分来确定最佳阈值可能不太现实[[97](#bib.bib97)]。此外，值得注意的是，该方法仅在点异常检测中进行了测试，当用于检测其他类型的异常时，需要进一步研究。
- en: Forecasting-based methods
  id: totrans-135
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于预测的方法
- en: Forecasting-based methods predict the value of the following timestamps and
    predict temporal anomalies according to the prediction error. Kim et al. propose
    a forecasting-based unsupervised time-series anomaly detection method using transformer
    architecture [[99](#bib.bib99)]. The idea is to train a transformer-like model
    by forecasting a fixed-length time series based on the previous timestamps. The
    trained model is used to predict time series with an anomaly score such that an
    instance where the anomaly score is larger than a static threshold is defined
    as an anomaly. A dynamic thresholding technique is also mentioned but not explicitly
    discussed in the paper.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 基于预测的方法预测后续时间戳的值，并根据预测误差预测时间异常。Kim等人提出了一种基于预测的无监督时间序列异常检测方法，该方法使用transformer架构[[99](#bib.bib99)]。其思想是通过基于之前的时间戳预测固定长度的时间序列来训练类似transformer的模型。训练好的模型用于预测时间序列，并计算异常分数，当异常分数大于静态阈值时，定义为异常。文中还提到了动态阈值技术，但没有明确讨论。
- en: Deng and Hooi propose a novel attention-based graph neural network approach
    [[100](#bib.bib100)] that learns a graph of dependence relationships between multi-variant
    time series signals by forecasting the behavior based on past time series. Then,
    a graph deviation scoring is defined for each sensor to detect and explain anomalies.
    Tang et al. propose an interpretable multivariate time series anomaly detection
    method based on graph neural networks and gated recurrent units [[101](#bib.bib101)].
    The feature representation is learned through forecasting the future time series
    segment. An abnormal score is set for each time series to detect anomalies. The
    feature embedding is then used for 2D visualization through t-SNE plots to interpret
    the clusters within time series from different sensors.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 邓和胡提出了一种新颖的基于注意力机制的图神经网络方法[[100](#bib.bib100)]，该方法通过基于过去的时间序列预测行为来学习多变时间序列信号之间的依赖关系图。然后，为每个传感器定义了一个图偏差评分，以检测和解释异常。唐等人提出了一种基于图神经网络和门控递归单元的可解释多变量时间序列异常检测方法[[101](#bib.bib101)]。通过预测未来时间序列段来学习特征表示。为每个时间序列设置一个异常评分以检测异常。然后，利用特征嵌入通过t-SNE图进行二维可视化，以解释来自不同传感器的时间序列中的簇。
- en: Other methods
  id: totrans-138
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 其他方法
- en: Ding et al. propose a joint network to integrate the advantages of reconstruction
    and forecasting/prediction [[102](#bib.bib102)]. First, they propose a multimodal
    graph attention network to tackle the spatial-temporal dependencies for multimodal
    time series. Further, they optimize the reconstruction and prediction modules
    simultaneously to predict anomalies. Himeur et al. take advantage of annotated
    data and directly use a DNN as a classifier to classify normal and abnormal energy
    consumption types [[103](#bib.bib103)]. The enormous imbalance of real anomaly
    patterns is one concern in the approach. Thus, a normalized technique of power
    consumption data is applied to deal with this problem. The normalized data represent
    the difference in power consumption rates of each current time sample and the
    previous one. It can provide information on how fast the consumption reacts to
    the time evolution. However, any further evaluation of this technique is not discussed,
    and it is still an open problem regarding anomaly detection for other datasets.
    Yang et al. propose a contrastive learning structure with dual attention to learn
    a permutation invariant representation of the data with superior discrimination
    characteristics between normal points and anomalies [[104](#bib.bib104)]. Unlike
    most reconstruction-based models, their model is a self-supervised framework based
    on representation learning. The new method achieves state-of-the-art comparable
    performance on six multivariate and one univariate time series anomaly detection
    benchmark datasets. However, the extensive framework with two multi-head-attention
    blocks may be prone to overfitting. This concern is amplified by the absence of
    training details, leaving only evaluation details disclosed.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 丁等人提出了一种联合网络，以整合重建和预测/预报的优势[[102](#bib.bib102)]。首先，他们提出了一种多模态图注意力网络，以解决多模态时间序列的时空依赖关系。进一步地，他们同时优化重建和预测模块，以预测异常。希穆尔等人利用标注数据，并直接使用深度神经网络作为分类器来分类正常和异常的能耗类型[[103](#bib.bib103)]。实际异常模式的巨大不平衡是该方法的一大担忧。因此，应用了一种规范化的能耗数据技术来解决这个问题。规范化数据表示每个当前时间样本和前一个时间样本的能耗率差异。它可以提供有关能耗如何迅速响应时间演变的信息。然而，关于这种技术的进一步评估尚未讨论，且对于其他数据集的异常检测仍然是一个未解的问题。杨等人提出了一种对比学习结构与双重注意力机制，以学习具有优越区分特性的排列不变数据表示[[104](#bib.bib104)]。与大多数基于重建的模型不同，他们的模型是一个基于表示学习的自监督框架。该新方法在六个多变量和一个单变量时间序列异常检测基准数据集上取得了与现有最先进技术相当的表现。然而，具有两个多头注意力块的广泛框架可能容易过拟合。由于缺乏训练细节，这一担忧得到进一步放大，仅披露了评估细节。
- en: In principle, these anomaly detection approaches are applicable to all types
    of anomalies. Reconstruction-based methods are typically applied to the entire
    or a portion of the time series. Long-time series are commonly segmented into
    subsequences using a predefined sliding window. In the case of detecting context/collective
    anomalies, the reconstructed loss of the time series sequence is evaluated within
    the predefined sliding window, if the reconstruction loss is larger than an acceptable
    threshold, then that time series sequence is classified as an anomaly. In the
    case of point anomalies, reconstruction is performed at each single time stamp,
    akin to a regression problem, and then the reconstruction loss of each single
    timestamp is evaluated to determine whether the single timestamp is anomalous
    or not. It is also applied to forecasting-based anomaly detection methods, instead
    of computing reconstruction error, forecasting-based methods predict the value
    in the next time stamp for point anomalies or the next time series sequence for
    context/collective anomalies. The anomalies will be detected based on the deviation
    between the predicted value and the normal value. Other anomaly detection approaches
    usually combine the reconstruction-based and foresting-based methods.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 原则上，这些异常检测方法适用于所有类型的异常。基于重建的方法通常应用于整个或部分时间序列。长时间序列通常使用预定义的滑动窗口进行分段。在检测上下文/集体异常的情况下，时间序列序列的重建损失在预定义的滑动窗口内进行评估，如果重建损失大于可接受的阈值，则该时间序列序列被分类为异常。在点异常的情况下，重建在每个单独的时间戳上进行，类似于回归问题，然后评估每个单独时间戳的重建损失，以确定该时间戳是否异常。它也适用于基于预测的异常检测方法，基于预测的方法预测下一个时间戳的值用于点异常，或预测下一个时间序列序列用于上下文/集体异常。异常将基于预测值与正常值之间的偏差来检测。其他异常检测方法通常将基于重建和基于预测的方法结合起来。
- en: To sum up, these methods are applicable to each type of anomaly. However, the
    effectiveness of these anomaly detection approaches may vary depending on the
    anomaly detection tasks at hand, which are characterized by the granularity at
    which the time series data is observed and analyzed.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，这些方法适用于每种类型的异常。然而，这些异常检测方法的有效性可能会因具体的异常检测任务而异，这些任务的特征在于观察和分析时间序列数据的粒度。
- en: 4 Industrial applications
  id: totrans-142
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 工业应用
- en: 4.1 Overview
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 概述
- en: 'Deep transfer learning techniques have gained prominence in computer vision
    and natural language processing, primarily due to the abundance of available datasets.
    However, their adoption in the context of industrial time series data has been
    comparatively limited. This hesitancy can be attributed to the limited public
    availability of such datasets and the unique domain-specific characteristics they
    possess, which complicate generalized advancements. Encouragingly, there has been
    a recent uptick in the application of deep transfer learning for anomaly detection
    within the industry such as fault diagnosis [[105](#bib.bib105)], quality management
    [[106](#bib.bib106)], manufacturing process monitoring [[85](#bib.bib85)], network/software
    security [[107](#bib.bib107)], and infrastructure monitoring [[108](#bib.bib108)].
    These can be mapped onto the core industrial domains of manufacturing process
    and infrastructure monitoring, predictive maintenance, and energy management.
    Table [2](#S4.T2 "Table 2 ‣ 4.1 Overview ‣ 4 Industrial applications ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions") presents a compact comparison of the related
    works using deep transfer learning approaches to solve these tasks.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '深度迁移学习技术在计算机视觉和自然语言处理领域已获得显著关注，主要由于可用数据集的丰富。然而，它们在工业时间序列数据中的应用相对有限。这种犹豫可以归因于此类数据集的公共可用性有限以及其特有的领域特征，这些特征使得通用进展变得复杂。令人鼓舞的是，最近在工业领域的异常检测中，如故障诊断[[105](#bib.bib105)]、质量管理[[106](#bib.bib106)]、制造过程监控[[85](#bib.bib85)]、网络/软件安全[[107](#bib.bib107)]和基础设施监控[[108](#bib.bib108)]，应用深度迁移学习的情况有所增加。这些可以映射到制造过程和基础设施监控、预测性维护和能源管理的核心工业领域。表[2](#S4.T2
    "Table 2 ‣ 4.1 Overview ‣ 4 Industrial applications ‣ A Comprehensive Survey of
    Deep Transfer Learning for Anomaly Detection in Industrial Time Series: Methods,
    Applications, and Directions")展示了使用深度迁移学习方法解决这些任务的相关工作的简洁比较。'
- en: 'Fig. [7](#S4.F7 "Figure 7 ‣ 4.1 Overview ‣ 4 Industrial applications ‣ A Comprehensive
    Survey of Deep Transfer Learning for Anomaly Detection in Industrial Time Series:
    Methods, Applications, and Directions") illustrates the Sankey diagram of the
    connections between industrial applications and the deep transfer learning approaches
    based on our literature survey. The diagram shows every path that connects the
    four dimensions of the methodology-problem-landscape within the surveyed literature.
    The broader the path is, the more papers are related to the linked topics. The
    goal is to give an overview of how deep transfer learning is applied to industrial
    problems in the recent literature and specifically show with these four dimensions:
    (1) which deep transfer learning approaches are actually used in practice; (2)
    what the main industrial domains for time series anomaly detection are; (3) what
    deep transfer learning category these domains belong to; (4) what labels are available
    in source and target domain.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7](#S4.F7 "图 7 ‣ 4.1 概述 ‣ 4 工业应用 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用与方向") 展示了基于我们文献调查的工业应用与深度迁移学习方法之间联系的桑基图。该图显示了调查文献中方法论-问题-背景四个维度之间的每一条连接路径。路径越宽，相关的论文越多。目的是提供一个深度迁移学习如何应用于工业问题的概述，并具体展示这四个维度：（1）实际使用了哪些深度迁移学习方法；（2）时间序列异常检测的主要工业领域是什么；（3）这些领域属于深度迁移学习的哪个类别；（4）源领域和目标领域中有哪些标签可用。
- en: 'Key observations from Fig. [7](#S4.F7 "Figure 7 ‣ 4.1 Overview ‣ 4 Industrial
    applications ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection
    in Industrial Time Series: Methods, Applications, and Directions") are: (1) parameter
    transfer is much more frequently used than any other deep transfer learning approach
    across all surveyed industrial applications since fine-tuning a pre-trained model
    on target data is more straightforward to implement by taking advantage of the
    pre-trained model on the source dataset and usually without fundamental modification
    on the model architecture. It is noteworthy that instance transfer and adversarial
    transfer do not appear in the diagram. Apparently, these two deep transfer learning
    approaches are not considered effective in time series anomaly detection tasks
    in industry. The difficulty lies in implementing and training these scarcely researched
    approaches in the industrial field, as indicated by the findings. (2) Hybrid approaches
    of parameter and mapping transfer can be seen in predictive maintenance. (3) Most
    industrial applications use inductive transfer learning, indicating they focus
    on leveraging labeled source and target data to solve the target task, i.e., use
    supervised learning.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [7](#S4.F7 "图 7 ‣ 4.1 概述 ‣ 4 工业应用 ‣ 深度迁移学习在工业时间序列异常检测中的综合调查：方法、应用与方向") 的关键观察结果是：（1）参数迁移在所有调查的工业应用中比任何其他深度迁移学习方法使用得要频繁得多，因为在目标数据上对预训练模型进行微调比利用源数据集上的预训练模型进行实现更为直接，通常无需对模型架构进行根本性修改。值得注意的是，实例迁移和对抗迁移在图中没有出现。显然，这两种深度迁移学习方法在工业时间序列异常检测任务中被认为效果不佳。这些鲜有研究的迁移学习方法在工业领域实施和训练的难度较大，这是研究结果所表明的。（2）在预测维护中可以看到参数迁移和映射迁移的混合方法。（3）大多数工业应用使用归纳迁移学习，表明它们侧重于利用标记的源数据和目标数据来解决目标任务，即使用监督学习。
- en: '![Refer to caption](img/c3d0caa6c9bbd0faa7e2ce2237ec6fb4.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c3d0caa6c9bbd0faa7e2ce2237ec6fb4.png)'
- en: 'Figure 7: Overview of Sankey diagram of transfer learning problem setting,
    deep transfer learning approach categories, and label availability in the surveyed
    industrial domains.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：调查的工业领域中迁移学习问题设置、深度迁移学习方法类别和标签可用性的桑基图概述。
- en: 'Table 2: A compact overview of industrial applications that used deep transfer
    learning for time series anomaly detection.'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：使用深度迁移学习进行时间序列异常检测的工业应用的简要概述。
- en: '| Reference | Industrial task | Industrial domain | Deep transfer learning
    approach | Transfer learning problem setting | Deep learning framework | Source
    type | Source label | Target label |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 工业任务 | 工业领域 | 深度迁移学习方法 | 迁移学习问题设置 | 深度学习框架 | 源类型 | 源标签 | 目标标签 |'
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
- en: '| [[11](#bib.bib11)] | Industrial metal forming anomaly detection | Predictive
    maintenance | Parameter transfer | Inductive | CNN | Multiple | ✓ | ✓ |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| [[11](#bib.bib11)] | 工业金属成形异常检测 | 预测性维护 | 参数转移 | 归纳 | CNN | 多重 | ✓ | ✓ |'
- en: '| [[12](#bib.bib12)] | Monitoring systems Anomaly detection | Predictive maintenance
    | Parameter transfer | Inductive | U-Net | Multiple | ✓ | ✓ |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| [[12](#bib.bib12)] | 监控系统异常检测 | 预测性维护 | 参数转移 | 归纳 | U-Net | 多重 | ✓ | ✓ |'
- en: '| [[13](#bib.bib13)] | Car body-side production line fault diagnosis | Predictive
    maintenance | Parameter transfer | Inductive | SAE | Multiple | ✓ | ✓ |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| [[13](#bib.bib13)] | 汽车车身侧生产线故障诊断 | 预测性维护 | 参数转移 | 归纳 | SAE | 多重 | ✓ | ✓
    |'
- en: '| [[14](#bib.bib14)] | Rotation bearings fault detection | Predictive maintenance
    | Mapping transfer | Transductive | Auto-encoder | Multiple | ✓ | ✗ |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| [[14](#bib.bib14)] | 旋转轴承故障检测 | 预测性维护 | 映射转移 | 迁移性 | 自编码器 | 多重 | ✓ | ✗ |'
- en: '| [[15](#bib.bib15)] | Industrial control systems anomaly detection | Predictive
    maintenance | Parameter transfer | Inductive | ResNet8 | Single | ✓ | ✓ |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| [[15](#bib.bib15)] | 工业控制系统异常检测 | 预测性维护 | 参数转移 | 归纳 | ResNet8 | 单一 | ✓ |
    ✓ |'
- en: '| [[16](#bib.bib16)] | Service elevator fault detection | Predictive maintenance
    | Parameter transfer | Inductive | CNN, RNN | Multiple | ✓ | ✓ |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| [[16](#bib.bib16)] | 服务电梯故障检测 | 预测性维护 | 参数转移 | 归纳 | CNN, RNN | 多重 | ✓ | ✓
    |'
- en: '| [[19](#bib.bib19)] | Nuclear power plants fault detection | Predictive maintenance
    | Parameter transfer | Inductive | CNN | Multiple | ✓ | ✓ |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| [[19](#bib.bib19)] | 核电站故障检测 | 预测性维护 | 参数转移 | 归纳 | CNN | 多重 | ✓ | ✓ |'
- en: '| [[109](#bib.bib109)] | Building energy systems fault diagnosis | Predictive
    maintenance | Parameter transfer | Inductive | CNN | Multiple | ✓ | ✓ |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| [[109](#bib.bib109)] | 建筑能源系统故障诊断 | 预测性维护 | 参数转移 | 归纳 | CNN | 多重 | ✓ | ✓
    |'
- en: '| [[110](#bib.bib110)] | Press machine production prediction | Predictive maintenance
    | Parameter transfer | Inductive | CNN | Single | ✓ | ✓ |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| [[110](#bib.bib110)] | 压力机生产预测 | 预测性维护 | 参数转移 | 归纳 | CNN | 单一 | ✓ | ✓ |'
- en: '| [[111](#bib.bib111)] | Wind turbine fault detection | Predictive maintenance
    | Parameter transfer | Inductive | CNN | Single | ✓ | ✓ |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| [[111](#bib.bib111)] | 风力涡轮机故障检测 | 预测性维护 | 参数转移 | 归纳 | CNN | 单一 | ✓ | ✓ |'
- en: '| [[112](#bib.bib112)] | Industrial machine operating fault detection | Predictive
    maintenance | Parameter transfer | Inductive | CNN, LSTM | Single | ✓ | ✓ |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| [[112](#bib.bib112)] | 工业机器操作故障检测 | 预测性维护 | 参数转移 | 归纳 | CNN, LSTM | 单一 |
    ✓ | ✓ |'
- en: '| [[9](#bib.bib9)] | Machine turning operations classification | Manufacturing
    process monitoring | Parameter transfer | Inductive | VGG, ResNet | Single | ✓
    | ✓ |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| [[9](#bib.bib9)] | 机器车削操作分类 | 制造过程监控 | 参数转移 | 归纳 | VGG, ResNet | 单一 | ✓ |
    ✓ |'
- en: '| [[10](#bib.bib10)] | Injection molding process quality control | Manufacturing
    process monitoring | Parameter transfer | Inductive | FCN | Multiple | ✓ | ✓ |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| [[10](#bib.bib10)] | 注塑成型过程质量控制 | 制造过程监控 | 参数转移 | 归纳 | FCN | 多重 | ✓ | ✓ |'
- en: '| [[85](#bib.bib85)] | Injection molding process quality control | Manufacturing
    process monitoring | Parameter transfer | Inductive | FCN | Single | ✓ | ✓ |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| [[85](#bib.bib85)] | 注塑成型过程质量控制 | 制造过程监控 | 参数转移 | 归纳 | FCN | 单一 | ✓ | ✓ |'
- en: '| [[113](#bib.bib113)] | Injection molding process anomaly detection | Manufacturing
    process monitoring | Parameter transfer | Inductive | FCN | Multiple | ✓ | ✓ |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| [[113](#bib.bib113)] | 注塑成型过程异常检测 | 制造过程监控 | 参数转移 | 归纳 | FCN | 多重 | ✓ | ✓
    |'
- en: '| [[114](#bib.bib114)] | Injection molding process anomaly detection | Manufacturing
    process monitoring | Parameter transfer | Inductive | FCN | Multiple | ✓ | ✓ |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| [[114](#bib.bib114)] | 注塑成型过程异常检测 | 制造过程监控 | 参数转移 | 归纳 | FCN | 多重 | ✓ | ✓
    |'
- en: '| [[115](#bib.bib115)] | Aluminum gravity die casting quality prediction |
    Manufacturing process monitoring | Parameter transfer | Inductive | FCN | Single
    | ✓ | ✓ |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| [[115](#bib.bib115)] | 铝合金重力铸造质量预测 | 制造过程监控 | 参数转移 | 归纳 | FCN | 单一 | ✓ |
    ✓ |'
- en: '| [[20](#bib.bib20)] | Agriculture/manufacturing systems anomaly detection
    | Manufacturing process monitoring | Parameter transfer | Inductive | LSTM | Single
    | ✓ | ✓ |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| [[20](#bib.bib20)] | 农业/制造系统异常检测 | 制造过程监控 | 参数转移 | 归纳 | LSTM | 单一 | ✓ | ✓
    |'
- en: '| [[116](#bib.bib116)] | Manufacturing testbeds anomaly detection | Manufacturing
    process monitoring | Parameter transfer | Inductive | LSTM, RNN | Single | ✓ |
    ✓ |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| [[116](#bib.bib116)] | 制造测试床异常检测 | 制造过程监控 | 参数转移 | 归纳 | LSTM, RNN | 单一 |
    ✓ | ✓ |'
- en: '| [[117](#bib.bib117)] | Industrial metal (pump) forming anomaly detection
    | Manufacturing process monitoring | Parameter transfer | Inductive | LSTM | Single
    | ✓ | ✓ |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| [[117](#bib.bib117)] | 工业金属（泵）成型异常检测 | 生产过程监测 | 参数传递 | 归纳法 | LSTM | 单一 |
    ✓ | ✓ |'
- en: '| [[118](#bib.bib118)] | Industrial control systems anomaly detection | Manufacturing
    process monitoring | Parameter transfer | Inductive | Auto-encoder | Single |
    ✓ | ✓ |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| [[118](#bib.bib118)] | 工业控制系统异常检测 | 生产过程监测 | 参数传递 | 归纳法 | 自编码器 | 单一 | ✓ |
    ✓ |'
- en: '| [[21](#bib.bib21)] | Petrochemical production process anomaly detection |
    Energy saving | Parameter transfer | Inductive | LSTM, CNN | Single | ✓ | ✓ |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| [[21](#bib.bib21)] | 石化生产过程异常检测 | 节能 | 参数传递 | 归纳法 | LSTM, CNN | 单一 | ✓ |
    ✓ |'
- en: '| [[119](#bib.bib119)] | Electricity consumption anomaly detection | Energy
    saving | Parameter transfer | Inductive | FCN | Single | ✗ | ✓ |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| [[119](#bib.bib119)] | 电力消耗异常检测 | 节能 | 参数传递 | 归纳法 | FCN | 单一 | ✗ | ✓ |'
- en: '| [[120](#bib.bib120)] | Building’s energy consumption anomaly detection |
    Energy saving | Parameter transfer | Inductive | AlexNet-40 | Single | ✓ | ✓ |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| [[120](#bib.bib120)] | 建筑物能源消耗异常检测 | 节能 | 参数传递 | 归纳法 | AlexNet-40 | 单一 |
    ✓ | ✓ |'
- en: '| [[121](#bib.bib121)] | Power consumption anomaly detection | Energy saving
    | Mapping transfer | Transductive | DAN | Single | ✓ | ✗ |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| [[121](#bib.bib121)] | 电力消耗异常检测 | 节能 | 映射传递 | 传导法 | DAN | 单一 | ✓ | ✗ |'
- en: '| [[122](#bib.bib122)] | Building’s power consumption anomaly detection | Energy
    saving | Parameter transfer | Inductive | LSTM | Single | ✓ | ✓ |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| [[122](#bib.bib122)] | 建筑物电力消耗异常检测 | 节能 | 参数传递 | 归纳法 | LSTM | 单一 | ✓ | ✓
    |'
- en: '| [[23](#bib.bib23)] | Aircraft flight anomaly detection | Infrastructure facilities
    monitoring | Parameter transfer | Inductive | LSTM | Single | ✓ | ✓ |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| [[23](#bib.bib23)] | 飞机飞行异常检测 | 基础设施监测 | 参数传递 | 归纳法 | LSTM | 单一 | ✓ | ✓ |'
- en: '| [[108](#bib.bib108)] | Anomaly identification for bridge groups | Infrastructure
    facilities monitoring | Parameter transfer | Inductive | CNN | Single | ✓ | ✓
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| [[108](#bib.bib108)] | 桥梁组异常识别 | 基础设施监测 | 参数传递 | 归纳法 | CNN | 单一 | ✓ | ✓ |'
- en: '| [[22](#bib.bib22)] | Network intrusion detection | Infrastructure facilities
    monitoring | Parameter transfer | Inductive | CNN, LSTM | Single | ✓ | ✓ |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| [[22](#bib.bib22)] | 网络入侵检测 | 基础设施监测 | 参数传递 | 归纳法 | CNN, LSTM | 单一 | ✓ |
    ✓ |'
- en: '| [[17](#bib.bib17)] | Building occupation detection | Infrastructure facilities
    monitoring | Parameter transfer | Inductive | CNN | Single | ✓ | ✓ |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| [[17](#bib.bib17)] | 建筑物占用检测 | 基础设施监测 | 参数传递 | 归纳法 | CNN | 单一 | ✓ | ✓ |'
- en: '| [[18](#bib.bib18)] | Building occupation detection | Infrastructure facilities
    monitoring | Parameter transfer | Inductive | CNN | Single | ✓ | ✓ |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| [[18](#bib.bib18)] | 建筑物占用检测 | 基础设施监测 | 参数传递 | 归纳法 | CNN | 单一 | ✓ | ✓ |'
- en: 4.2 Manufacturing process monitoring
  id: totrans-183
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 生产过程监测
- en: Manufacturing process monitoring is crucial to ensure high-quality products
    and low rejection rates. For example, in injection molding machines, sensors are
    installed to detect molding conditions in the cavities, such as cavity pressure
    and temperature. These signals are used to analyze particularly the mold filling
    and solidification process for each produced part. Such cyclic processing data
    can also be seen in metal machining (cutting force signal) or joining of parts
    (joining force signal). Currently, parameter transfer is predominantly used for
    manufacturing processes [[10](#bib.bib10), [85](#bib.bib85), [113](#bib.bib113),
    [114](#bib.bib114), [11](#bib.bib11), [20](#bib.bib20), [116](#bib.bib116), [123](#bib.bib123),
    [117](#bib.bib117)].
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 生产过程监测对于确保高质量产品和低拒绝率至关重要。例如，在注塑机中，安装传感器以检测模具腔体中的成型条件，如腔体压力和温度。这些信号用于分析每个生产部件的模具填充和固化过程。这种循环处理数据也可以在金属加工（切削力信号）或部件连接（连接力信号）中看到。目前，制造过程主要使用参数传递[[10](#bib.bib10),
    [85](#bib.bib85), [113](#bib.bib113), [114](#bib.bib114), [11](#bib.bib11), [20](#bib.bib20),
    [116](#bib.bib116), [123](#bib.bib123), [117](#bib.bib117)]。
- en: Park et al. propose a transfer learning technique to detect time series anomalies
    for different industrial control systems [[118](#bib.bib118)]. First, they apply
    principal components analysis to reduce the dimension of source and target data.
    A DNN model is then trained on the compressed source data, and after a reasonable
    mapping algorithm is adopted to map the features of source to target domain, the
    pre-trained model is further trained on the target data. The model achieves good
    performance even when a model is retrained with only a proportion of target data.
    For the experiments, they only test on two comparatively larger datasets and fail
    to show that the transferred model performs better than the one without retraining
    for one dataset. Further investigation needs to explain the negative transfer.
    Additionally, even when they only take a small proportion of target data for transfer
    learning purposes, the sample size still exceeds $5000$, which exceeds most industrial
    applications. Abdallah et al. apply parameter transfer to monitor the operation
    status of manufacturing testbeds with vibration sensor data [[20](#bib.bib20),
    [116](#bib.bib116)]. Hsieh et al. transfer knowledge across three chambers in
    a production line to detect anomalous time series data [[123](#bib.bib123)]. Results
    show reduced training time and improved detection accuracy through transfer learning.
    In injection molding, parameter transfer is applied to transfer the knowledge
    from one or more source domains to solve tasks in a target domain [[10](#bib.bib10),
    [113](#bib.bib113), [114](#bib.bib114)]. Specifically, they employ simple fully
    connected neural networks and transfer knowledge from one product to another by
    freezing the first few layers and fine-tuning only the last few layers. Instead
    of evaluating the time series data directly from sensors, they represent the industrial
    process by the parameters of the machine settings. However, they can still provide
    useful insight for the case of the time-series data. Tercan et al. build a bridge
    between simulated data and real data using parameter transfer in injection molding
    [[85](#bib.bib85)]. Here, a fully connected neural network is trained on simulated
    data and then partially or fully reused to further train on real data. Results
    show that the transferred model performs better than a network trained from scratch
    on real experimental data. In manufacturing processes, a simulation model/process
    hence can play a critical role, but deeper analysis is needed to further understand
    and reduce the gap between simulation and real data. Additionally, Lockner et
    al. explore the impact of transfer learning with varying amounts of source data
    and assess how performance is influenced by different configurations of frozen
    layers [[114](#bib.bib114)]. Maschler et al. compare different DNNs for anomaly
    detection tasks on metal forming datasets [[11](#bib.bib11)]. Further, they propose
    a deep transfer learning framework aiming to transfer knowledge between tasks.
    However, the proposed architecture is not validated by experiments. Later, Maschler
    et al. apply continuous learning on the same dataset by transferring knowledge
    from several source tasks to a target task to train a deep learning algorithm
    capable of solving both source and target tasks [[117](#bib.bib117)]. Specifically,
    they use regularization approaches using altered loss functions to solve related
    tasks that appear best suited.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: Park 等人提出了一种迁移学习技术，用于检测不同工业控制系统中的时间序列异常 [[118](#bib.bib118)]。首先，他们应用主成分分析来减少源数据和目标数据的维度。然后在压缩后的源数据上训练
    DNN 模型，采用合理的映射算法将源领域的特征映射到目标领域，之后在目标数据上进一步训练预训练模型。即使模型只用一部分目标数据进行重新训练，模型仍能取得良好的性能。在实验中，他们仅在两个较大的数据集上进行测试，并未证明迁移模型比未重新训练的模型在一个数据集上表现更好。需要进一步调查以解释负迁移。此外，即使他们仅使用小部分目标数据进行迁移学习，样本量仍超过
    $5000$，这超出了大多数工业应用的范围。Abdallah 等人应用参数迁移监控制造测试台的运行状态，使用振动传感器数据 [[20](#bib.bib20),
    [116](#bib.bib116)]。Hsieh 等人将知识迁移到生产线的三个工位，以检测异常的时间序列数据 [[123](#bib.bib123)]。结果显示，通过迁移学习减少了训练时间并提高了检测准确性。在注塑成型中，应用参数迁移将知识从一个或多个源领域转移到目标领域，以解决目标领域中的任务
    [[10](#bib.bib10), [113](#bib.bib113), [114](#bib.bib114)]。具体来说，他们采用简单的全连接神经网络，通过冻结前几层并仅对最后几层进行微调，将知识从一个产品转移到另一个产品。与直接从传感器评估时间序列数据不同，他们通过机器设置的参数来表示工业过程。然而，他们仍然可以为时间序列数据的案例提供有用的见解。Tercan
    等人使用参数迁移在注塑成型中建立了模拟数据与真实数据之间的桥梁 [[85](#bib.bib85)]。在这里，首先在模拟数据上训练全连接神经网络，然后部分或完全重用该网络以进一步训练真实数据。结果显示，迁移模型比从头开始训练的真实实验数据网络表现更好。在制造过程中，仿真模型/过程可以发挥关键作用，但需要更深入的分析以进一步理解和减少仿真数据与真实数据之间的差距。此外，Lockner
    等人探讨了不同来源数据量的迁移学习对性能的影响，并评估了不同冻结层配置对性能的影响 [[114](#bib.bib114)]。Maschler 等人比较了不同
    DNN 在金属成型数据集上的异常检测任务 [[11](#bib.bib11)]。此外，他们提出了一个深度迁移学习框架，旨在任务之间转移知识。然而，所提出的架构尚未通过实验验证。后来，Maschler
    等人通过将来自几个源任务的知识迁移到目标任务，在相同数据集上应用了持续学习，以训练一种能够解决源任务和目标任务的深度学习算法 [[117](#bib.bib117)]。具体来说，他们使用了通过调整损失函数的正则化方法来解决最适合的相关任务。
- en: 4.3 Predictive maintenance
  id: totrans-186
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 预测性维护
- en: Predictive maintenance aims to predict the necessity of maintenance before production
    is negatively impacted by a failure. Tasks involve monitoring equipment to anticipate
    maintenance requirements (i.e., predict probable future failure) to optimize maintenance
    schedules [[124](#bib.bib124)]. Time series anomaly detection is often used in
    respective systems to identify abnormal behaviors in operation that may indicate
    the need for maintenance, such as increasing noise, vibrations, etc.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性维护的目标是预测在生产受到故障负面影响之前的维护需求。任务包括监控设备，以预测维护需求（即预测可能的未来故障），以优化维护计划[[124](#bib.bib124)]。时间序列异常检测通常在相应系统中使用，以识别操作中的异常行为，这些行为可能表明需要维护，例如噪声、振动等增加。
- en: Mao et al. use mapping transfer with a Sparse Auto-Encoder (SAE) for motor vibration
    anomaly detection [[14](#bib.bib14)]. A transformation from the source and target
    data to a common latent feature space is learned with MMD loss to make the feature
    distribution of two domains as identical as possible. Similarly, Wen et al. also
    use mapping transfer with an SAE architecture for fault detection of rotation
    bearings, using an MMD regularizer to extract a common feature representation
    [[125](#bib.bib125)]. Subsequently, they propose a new MU-Net architecture to
    detect multivariate time series anomalies [[12](#bib.bib12)]. First, they pre-train
    a U-Net [[126](#bib.bib126)] on a large time series dataset for an anomaly detection
    task. Then, they propose a new model MU-Net, which is built upon U-Net. In MU-Net,
    each channel can leverage a pre-trained U-Net through fine-tuning to transfer
    knowledge for multivariate time series anomaly detection.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 毛等人使用稀疏自编码器（SAE）进行映射迁移，以检测电机振动异常[[14](#bib.bib14)]。通过MMD损失学习源数据和目标数据到一个共同的潜在特征空间的变换，以使两个领域的特征分布尽可能相同。类似地，文等人也使用SAE架构进行旋转轴承的故障检测，使用MMD正则化器提取共同的特征表示[[125](#bib.bib125)]。随后，他们提出了一种新的MU-Net架构，用于检测多变量时间序列异常[[12](#bib.bib12)]。首先，他们在大规模时间序列数据集上预训练了一个U-Net[[126](#bib.bib126)]，用于异常检测任务。然后，他们提出了一种新的MU-Net模型，该模型基于U-Net构建。在MU-Net中，每个通道可以通过微调利用预训练的U-Net，将知识转移到多变量时间序列异常检测中。
- en: In a different application, parameter transfer is used to predict the remaining
    useful life for tools in manufacturing [[127](#bib.bib127)]. An SAE network is
    first trained to predict the remaining useful life of a cutting tool on retrospectively
    acquired data in an offline process. The trained network is then transferred to
    production with a new tool for online remaining useful life prediction. The result
    shows that transfer-learning based hybrid deep learning significantly reduces
    the training time and is highly suitable for real-time industrial fault diagnosis/prediction
    in various environments. Similarly, parameter transfer is implemented to reduce
    the gap between different industrial environments [[112](#bib.bib112), [13](#bib.bib13)].
    Xu et al. use a stacked SAE to extract general features from source data and a
    digital-twin-assisted fault diagnosis approach is presented to transfer knowledge
    from virtual space to physical space for real-time use [[13](#bib.bib13)]. Here,
    a DNN model is first fully trained in virtual space and then migrated to the physical
    space using parameter transfer for real-time use.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一种应用中，参数转移用于预测制造工具的剩余使用寿命[[127](#bib.bib127)]。首先，在离线过程中使用回顾性获得的数据训练SAE网络，以预测切削工具的剩余使用寿命。然后，将训练好的网络转移到生产中，利用新工具进行在线剩余使用寿命预测。结果表明，基于迁移学习的混合深度学习显著减少了训练时间，并且非常适合于各种环境下的实时工业故障诊断/预测。类似地，参数转移也被用于缩小不同工业环境之间的差距[[112](#bib.bib112),
    [13](#bib.bib13)]。徐等人使用堆叠的SAE从源数据中提取通用特征，并提出了一种数字双胞胎辅助的故障诊断方法，将知识从虚拟空间转移到物理空间以实现实时使用[[13](#bib.bib13)]。在这里，DNN模型首先在虚拟空间中完全训练，然后使用参数转移迁移到物理空间以进行实时使用。
- en: The above-mentioned literature proves that deep transfer learning is a research
    field that could simplify the life cycle of predictive maintenance systems and
    facilitate DNN model reusability by reducing the required data and training time,
    helping adapt them to solve similar tasks.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 上述文献证明，深度迁移学习是一个研究领域，它可以简化预测性维护系统的生命周期，并通过减少所需的数据和训练时间来促进DNN模型的重用，帮助使其适应解决类似任务。
- en: 4.4 Energy management
  id: totrans-191
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 能源管理
- en: Energy management deals with systems that detect abnormal excessive consumption
    caused by end-users’ unusual behavior or malfunction of faulty devices or systems
    [[120](#bib.bib120)]. The goal is to develop automatic, quick-responding, accurate,
    and reliable fault detection to save energy and build environmentally friendly
    systems. Energy anomaly detection systems monitor data during energy generation,
    transmission, and utilization, to ensure normal energy consumption.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 能源管理涉及那些能够检测由于终端用户异常行为或设备、系统故障导致的过度消耗的系统 [[120](#bib.bib120)]。其目标是开发自动化、快速响应、准确可靠的故障检测系统，以节约能源并建立环保系统。能源异常检测系统监控能源生成、传输和利用过程中的数据，以确保正常的能源消耗。
- en: Xu et al. design a cluster-based deep adaptation layer to improve a deep adaptation
    network, effectively reducing the mismatch in transfer learning of spinning power
    consumption anomaly detection [[121](#bib.bib121)]. The basic architecture consists
    of five convolutional layers and three fully connected layers. The weight parameters
    of the convolutional layers are shared between source and target domains. The
    cluster-based deep adaptation layer is designed across the feature layers of two
    networks to cluster feature representations of the source and target domains respectively.
    The proposed method shows superiority over fine-tuning and DAN because the adaptation
    layer can minimize the distance between the nearest neighbor clusters across the
    source and target domains to match the most similar distribution of feature representations.
    It is important to note that the anomalies are defined and tagged by human experts
    as different types, thus the problem becomes a classification task. However, in
    real-world industrial applications, it’s almost impossible to enumerate unknown
    anomaly types because of the highly dynamic environment. Liang et al. successfully
    build an electricity consumption time series anomaly detection method in aluminum
    extrusion [[119](#bib.bib119)]. Parameter transfer is applied to transfer domain
    knowledge from another data-sufficient domain. First, they train on sufficient
    extruding machine data in an unsupervised way and then use only a few data samples
    from different extruding machines to adapt the model by transfer learning. It
    is important to note that when the target data is already sufficient, transferring
    knowledge can be detrimental as it can decrease prediction accuracy on the final
    task. Copiaco et al. aims to detect anomalies for building energy consumption
    via transfer learning from pre-trained CNN models [[128](#bib.bib128)]. First,
    they convert 1D time series signals to 2D image representations. These serve as
    inputs for pre-trained vision models to capture inherent spatially invariant features.
    In the end, a SVM is applied to classify anomaly types. The SVM classifier obtained
    optimal results when operating upon a pre-trained ALexNet model with normalized
    grayscale graphical representations. However, a deeper discussion regarding the
    effect of the different pre-trained models is not presented. Additionally, converting
    1D time series to 2D images by creating a matrix representation of the sensor
    readings may lead to information loss during the transformation process, which
    should be further investigated.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Xu等人设计了一种基于集群的深度适应层，以改进深度适应网络，有效减少旋转功耗异常检测中的迁移学习不匹配[[121](#bib.bib121)]。基本架构由五层卷积层和三层全连接层组成。卷积层的权重参数在源域和目标域之间共享。集群基深度适应层设计跨越两个网络的特征层，以分别对源域和目标域的特征表示进行集群。该方法优于微调和DAN，因为适应层可以最小化源域和目标域之间最近邻集群的距离，以匹配最相似的特征表示分布。需要注意的是，异常由人工专家定义并标记为不同类型，因此问题变成了分类任务。然而，在现实工业应用中，由于环境高度动态，几乎不可能列举未知异常类型。Liang等人成功构建了一种用于铝挤压中的电力消耗时间序列异常检测方法[[119](#bib.bib119)]。应用参数转移将领域知识从另一个数据充足的领域转移过来。他们首先在充足的挤压机数据上进行无监督训练，然后仅使用少量来自不同挤压机的数据样本，通过迁移学习来调整模型。需要注意的是，当目标数据已经足够时，转移知识可能会有害，因为这可能会降低最终任务的预测准确性。Copiaco等人旨在通过从预训练CNN模型迁移学习来检测建筑能耗异常[[128](#bib.bib128)]。首先，他们将1D时间序列信号转换为2D图像表示。这些图像作为预训练视觉模型的输入，以捕捉固有的空间不变特征。最后，应用SVM对异常类型进行分类。当在预训练的ALexNet模型上使用标准化的灰度图像表示时，SVM分类器获得了最佳结果。然而，对于不同预训练模型的效果没有进行更深入的讨论。此外，将1D时间序列转换为2D图像，创建传感器读数的矩阵表示，可能在转换过程中导致信息丢失，这需要进一步研究。
- en: 4.5 Infrastructure facilities monitoring
  id: totrans-194
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 基础设施设施监控
- en: Infrastructure facilities monitoring refers to monitoring and maintaining the
    conditions of infrastructure facilities, such as bridges, buildings[[129](#bib.bib129)],
    and networks. This can include detecting potential problems or failures. The goal
    is to minimize the impact of failures on the public or the environment. This application
    commonly uses parameter transfer to transfer knowledge from facility to facility
    to take advantage of similar data and tasks.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 基础设施设施监测是指监测和维护基础设施设施的条件，例如桥梁、建筑物[[129](#bib.bib129)]和网络。这可以包括检测潜在的问题或故障。其目标是最小化故障对公众或环境的影响。这种应用通常使用参数转移，将知识从一个设施转移到另一个设施，以利用相似的数据和任务。
- en: Dhillon et al. present a parameter transfer approach towards building a network
    intrusion detection system based on CNN and LSTM [[22](#bib.bib22)]. Specifically,
    They extract and learn patterns by mapping the input data into a lower dimensional
    representation by convolutional layers. Then, they employ the LSTM layer to enhance
    learning and recognizing patterns across time. In the end, a fully connected layer
    is used as a classifier to predict normal and malicious data. To do the parameter
    transfer, they reuse the model architecture and freeze most weight parameters
    for the target domain so that they do not need a large training dataset to retrain
    the model. However, they do not mention implementation details, like which layers
    are frozen in the transfer learning stage. Observing how transfer learning performs
    with different frozen layers would be interesting. Pan et al. apply parameter
    transfer to fully use the similarity of the anomalous patterns across different
    bridges [[108](#bib.bib108)]. They train a CNN model on one bridge data, then
    transfer the knowledge obtained by the CNN model to a small part of the target
    data. They update the last three fully connected layers while keeping the convolutional
    layers intact. The experimental results show transfer learning achieves higher
    accuracy anomaly detection across bridges. Weber et al. takes advantage of simulation
    data by training on synthetic environmental data, then fine-tunes the pre-trained
    model and transfers the knowledge from simulation data for real-time online building
    occupancy detection [[17](#bib.bib17)]. Although the results show the effectiveness
    of transfer learning, the availability, and reliability of the simulation data
    for other industrial applications is still an open issue. Sayed et al. adapt parameter
    transfer using pre-trained CNN models, such as AlexNet and GoogLeNet, pre-trained
    on ImageNet [[18](#bib.bib18)]. The pre-trained model is then further used for
    downstream tasks. The results show the pre-trained models outperform their customed
    CNN model, which is not pre-trained. However, it is important to note that the
    transfer effect may not be entirely convincing due to the fact that the customer
    CNN model is not pre-trained on the same dataset.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: Dhillon 等人提出了一种基于 CNN 和 LSTM 的网络入侵检测系统的参数转移方法[[22](#bib.bib22)]。具体来说，他们通过卷积层将输入数据映射到低维表示，从而提取和学习模式。然后，他们利用
    LSTM 层来增强时间序列中的模式学习和识别。最后，使用全连接层作为分类器来预测正常数据和恶意数据。为了进行参数转移，他们重用模型架构，并冻结目标领域的大部分权重参数，这样就不需要大量的训练数据集来重新训练模型。然而，他们没有提及实现细节，例如在迁移学习阶段冻结了哪些层。观察不同冻结层下迁移学习的表现将会很有趣。Pan
    等人将参数转移应用于充分利用不同桥梁之间异常模式的相似性[[108](#bib.bib108)]。他们在一个桥梁的数据上训练 CNN 模型，然后将 CNN
    模型获得的知识转移到目标数据的一个小部分。他们更新了最后三层全连接层，同时保持卷积层不变。实验结果表明，迁移学习在不同桥梁之间的异常检测中取得了更高的准确率。Weber
    等人通过在合成环境数据上进行训练，利用模拟数据，然后对预训练模型进行微调，并将模拟数据中的知识转移到实时在线建筑物占用检测中[[17](#bib.bib17)]。尽管结果显示了迁移学习的有效性，但模拟数据在其他工业应用中的可用性和可靠性仍然是一个未解的问题。Sayed
    等人通过使用预训练的 CNN 模型（如 AlexNet 和 GoogLeNet），在 ImageNet 上进行预训练，来适应参数转移[[18](#bib.bib18)]。然后，进一步使用预训练模型来完成下游任务。结果表明，预训练模型优于他们定制的未经过预训练的
    CNN 模型。然而，需要注意的是，由于客户的 CNN 模型没有在相同的数据集上进行预训练，迁移效果可能并不完全令人信服。
- en: 4.6 Application-independent considerations
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 应用无关的考虑
- en: \add
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: \add
- en: Data scarcity, as well as domain shift, stand out as the two main common problems
    independent of the industrial field of application. The same problems have originally
    prompted the use of transfer learning in general, and respectively, general techniques
    are applied widely across domains. Regarding data scarcity, this un-surprisingly
    involves leveraging pre-trained models as a starting point for further training.
    Regarding domain shift, mapping transfer and parameter transfer are the most often-used
    approaches. Unlike parameter transfer, mapping transfer incorporates the source
    and target data in the training process. Instance transfer and domain-adversarial
    transfer learning were not employed in the surveyed literature – researchers seem
    to not see huge value in these methods for the surveyed fields.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 数据稀缺以及领域迁移，作为两个主要的共性问题，与工业应用领域无关。这些问题最初促使了转移学习的使用，通常在各个领域广泛应用通用技术。关于数据稀缺，这通常涉及利用预训练模型作为进一步训练的起点。关于领域迁移，映射转移和参数转移是最常用的方法。与参数转移不同，映射转移在训练过程中包含源数据和目标数据。实例转移和领域对抗转移学习在调查的文献中未被采用——研究人员似乎认为这些方法在调查的领域中价值不大。
- en: 'Another common aspect across time series anomaly detection applications is
    the choices of model architecture to facilitate the training process by capturing
    temporal dependencies and recognizing patterns over varying time scales: Favourite
    architectures include CNNs, LSTMs, and auto-encoders that have sets of assumptions
    (inductive biases) about the data they analyze that make them excel in understanding
    the sequential nature of time series data. CNNs assume local (in time) connectivity,
    stationary statistics, and hierarchical structure, and induce certain translation-invariance.
    LSTMs are still given preference in many applications over the more modern deep
    learning architecture of choice for sequence learning, the transformer. The reason
    is their stronger inductive bias, leading to less data (and compute) hunger. Both
    CNN and LSTM networks can be built as e.g. classifiers, but also auto-encoders.
    These latter architectures have the advantage of learning low-dimensional representations
    of the high-dimensional time series with minimal loss of signal in an unsupervised
    way. The analysis of the data in the low-dimensional latent space facilitates
    anomaly detection. The concrete choice of architecture does not depend on the
    field of application but on the data and task, and thus the most suitable inductive
    bias.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在时间序列异常检测应用中，一个常见的方面是模型架构的选择，这有助于通过捕捉时间依赖关系和识别不同时间尺度上的模式来促进训练过程：常见的架构包括 CNN、LSTM
    和自编码器，它们对分析的数据有一定的假设（归纳偏置），使它们在理解时间序列数据的序列特性方面表现出色。CNN 假设局部（在时间上）连接、平稳统计和层次结构，并引入某种平移不变性。LSTM
    在许多应用中仍然比现代的序列学习深度学习架构——变换器更受青睐。原因在于它们更强的归纳偏置，导致对数据（和计算）的需求较少。CNN 和 LSTM 网络可以构建为分类器，也可以作为自编码器。这些后者的架构有一个优点，即以无监督的方式学习高维时间序列的低维表示，并且信号损失最小。数据在低维潜在空间中的分析有助于异常检测。具体的架构选择不依赖于应用领域，而是取决于数据和任务，因此最适合的归纳偏置。
- en: As an interim conclusion, the most striking application-independent finding
    is that across the surveyed literature, predominantly simple, tried-and-tested
    design patterns for transfer learning are used in industry. The field of deep
    transfer learning would offer a much wider variety of approaches.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一个过渡结论，最引人注目的应用独立发现是，在调查的文献中，主要使用简单、经过验证的转移学习设计模式。深度转移学习领域将提供更多样化的方法。
- en: 5 Discussion
  id: totrans-202
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 讨论
- en: 5.1 Potential
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 潜力
- en: The automation of industrial process monitoring stands as a transformative step
    toward increasing efficiency and optimizing quality. While standard deep learning
    training is sufficient in discerning intricate patterns from vast datasets, its
    application in the dynamic industrial landscape is not without challenges. Chief
    among them is the impracticality of continuously obtaining large-scale labeled
    data to train models afresh for every nuanced variation in processes. Deep transfer
    learning has shown promise with its adaptive capabilities. By mitigating the need
    for extensive labeled data and eliminating the necessity to train models from
    scratch for every distinct setup. However, adopting deep transfer learning beyond
    simple parameter transfer is still a challenge.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 工业过程监控的自动化是提升效率和优化质量的变革性步骤。虽然标准的深度学习训练足以从庞大的数据集中识别复杂的模式，但其在动态工业环境中的应用并非没有挑战。其中最主要的问题是难以持续获得大规模的标记数据，以便为每个工艺的细微变化重新训练模型。深度迁移学习凭借其适应能力展现了前景，通过减少对大量标记数据的需求，并消除了为每个不同设置从头开始训练模型的必要性。然而，超越简单参数迁移的深度迁移学习仍然面临挑战。
- en: 5.2 Challenges
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 挑战
- en: Domain shift
  id: totrans-206
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 领域转移
- en: 'Different from the i.i.d assumption in most machine learning problem settings,
    many industrial processes suffer from substantial domain shift due to dynamic
    changes in industrial settings, e.g., change of products or measuring sensors.
    Domain shift lies at the heart of the deep transfer learning problem. Particularly,
    the dynamic changes in many industrial processes, up to an apparent dissimilarity
    of source and target data, make the transfer learning task particularly challenging.
    Here we list the key challenges associated with domain shift:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 与大多数机器学习问题设置中的独立同分布假设不同，许多工业过程由于工业环境中的动态变化而遭受显著的领域转移，例如，产品或测量传感器的变化。领域转移是深度迁移学习问题的核心。特别是，许多工业过程中的动态变化，直到源数据和目标数据的显著差异，使得迁移学习任务特别具有挑战性。以下是与领域转移相关的主要挑战：
- en: •
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Covariate shift occurs when the marginal distribution of the features changes
    from source domain to target domain. The distribution mismatch poses challenges
    in transferring the knowledge from source to target domain.
  id: totrans-209
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 协变量转移发生在特征的边际分布从源领域变化到目标领域时。这种分布不匹配给从源领域到目标领域的知识转移带来了挑战。
- en: •
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Concept shift refers to the changes in the relationships between features and
    labels. The relationship can change from source domain to target domain, leading
    to bias and error in the model.
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 概念转移指的是特征与标签之间关系的变化。关系可以从源领域变化到目标领域，从而导致模型中的偏差和错误。
- en: •
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Label shift refers to the label distribution in the target domain that can be
    different from the source domain, whether the marginal distribution changes or
    not.
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标签转移指的是目标领域的标签分布可能与源领域不同，无论边际分布是否发生变化。
- en: Label availability and reliability
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 标签的可用性和可靠性
- en: Deep transfer learning is built upon deep learning, which usually requires a
    large amount of labeled data, the more data a model has available for training,
    the better it can generalize to new examples. In real-world industrial time series
    anomaly detection tasks, collecting data is probably easy, but collecting labels
    is much more expensive and time-consuming, sometimes prohibitively so, leading
    to the unavailability of sufficient labeled data. Self-supervised learning can
    be used to re-label a large amount of unlabeled data and thus anomaly detection
    models usually need to learn in an unsupervised or semi-supervised mode [[130](#bib.bib130)].
    In industrial cases, another significant concern is to ensure the data quality.
    Due to the high cost associated with obtaining reliable and precise labels, usually
    self-supervised learning is applied to create pseudo labels or relabel the unlabeled
    data, thus facilitating the transfer learning process. Additionally, a data-centric
    process with humans in the loop can be involved in improving label reliability.
    However, unreliable labels can still affect the transfer learning training process.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 深度迁移学习建立在深度学习基础上，通常需要大量的标记数据，模型可用的训练数据越多，越能对新示例进行更好的泛化。在现实世界的工业时间序列异常检测任务中，数据的收集可能比较容易，但收集标签则要昂贵得多且耗时，有时甚至禁止，导致没有足够的标记数据。自监督学习可以用于重新标记大量未标记的数据，因此异常检测模型通常需要以无监督或半监督模式进行学习[[130](#bib.bib130)]。在工业案例中，另一个重要问题是确保数据质量。由于获取可靠和准确标签的高成本，通常应用自监督学习来创建伪标签或重新标记未标记数据，从而促进迁移学习过程。此外，可以通过人类参与的数据中心过程来提高标签的可靠性。然而，不可靠的标签仍然可能影响迁移学习的训练过程。
- en: Missing relevant data information
  id: totrans-216
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 缺失相关数据
- en: Missing relevant data poses significant challenges for transfer learning since
    it can affect the model’s ability to generalize and transfer knowledge from source
    to target domain.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 缺失相关数据对迁移学习构成了重大挑战，因为它可能影响模型从源领域到目标领域的知识迁移和泛化能力。
- en: •
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Imbalanced data: Even if the labels can be collected, anomalies can be extremely
    rare by design, which poses the risk of training with extremely imbalanced data.
    A practical problem for anomaly detection in industry is the extremely imbalanced
    data distribution, in which normal samples dominate in data and abnormal samples
    only share a small percentage in the whole dataset. Prior research has proven
    that the effect of class imbalance on classification performance by using deep
    learning is detrimental [[131](#bib.bib131)]. However, most research studies still
    ignore such problems, which can result in poor performance regarding the minority
    class, i.e., abnormal data are misclassified as normal.'
  id: totrans-219
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不平衡数据：即使标签可以被收集，由于设计上的原因，异常情况可能非常稀少，这就带来了用极其不平衡的数据进行训练的风险。工业中异常检测的一个实际问题是数据分布极度不平衡，其中正常样本占据主导地位，而异常样本在整个数据集中只占很小的比例。先前的研究已经证明，使用深度学习时类别不平衡对分类性能的影响是有害的[[131](#bib.bib131)]。然而，大多数研究仍然忽视了这些问题，这可能导致对少数类的性能差，即异常数据被误分类为正常。
- en: •
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Information loss: missing data can lead to lost important features. For example,
    some information that has a significant effect on the process from case to case
    is not even recorded or is too complex to record (i.e. part geometry, machine
    geometry, or environmental conditions in injection molding processes).'
  id: totrans-221
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 信息丢失：缺失的数据可能导致重要特征的丧失。例如，一些对案例过程有显著影响的信息甚至没有被记录或过于复杂以至于无法记录（即部件几何形状、机器几何形状或注塑过程中的环境条件）。
- en: Various approaches have been developed to address these challenges to reduce
    the domain gap between the source and target domains, aiming at mitigating domain
    shift. These techniques involve domain generalization, contrastive learning, and
    adversarial examples. The domain shift problem is far from being solved. To tackle
    this problem, transfer learning requires a deep understanding of the target data’s
    characteristics and appropriate transferable strategies to effectively bridge
    the gap between the source and target domains.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战，已经开发了各种方法，以减少源领域和目标领域之间的领域差距，旨在缓解领域漂移。这些技术包括领域泛化、对比学习和对抗性示例。领域漂移问题远未解决。为了应对这一问题，迁移学习需要深入理解目标数据的特征，并采用适当的可迁移策略，以有效弥合源领域和目标领域之间的差距。
- en: Effectiveness of deep transfer learning
  id: totrans-223
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 深度迁移学习的有效性
- en: The general effectiveness of deep transfer learning is limited by the difficulty
    of determining which knowledge or to what extent the knowledge should be transferred
    from source to target task. Unlike natural language processing, pre-training a
    language model on a large corpus of text data can help the model learn the statistical
    patterns and semantic and syntactic representations of words and sentences, which
    can be used for new natural language processing tasks with a few or even without
    data. Due to data privacy, large available public datasets usually do not exist
    for industrial time series, or they can not be used because of a large domain
    gap between different datasets and tasks. In this case, transferring all of the
    knowledge may not be beneficial, as it may be irrelevant. In the worst case, this
    can lead to negative transfer [[28](#bib.bib28), [132](#bib.bib132)], in which
    the extracted knowledge harms the new task-learning. This requires assessing how
    source and target tasks are related, carefully selecting the knowledge to be transferred,
    and selecting the proper means to implement this transfer. Glorot et al. attempt
    to analyze and quantify the gained knowledge from source to target domain [[133](#bib.bib133)].
    For example, they define transfer error, transfer loss, transfer ratio, and in-domain
    ratio, which provide metrics to interpret the transferring performance.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 深度迁移学习的一般有效性受到确定从源任务到目标任务应该转移哪些知识或转移到何种程度的困难的限制。与自然语言处理不同，预训练一个大规模语料库上的语言模型可以帮助模型学习单词和句子的统计模式以及语义和句法表示，这些可以用于新的自然语言处理任务，甚至在没有数据的情况下。由于数据隐私，工业时间序列通常没有大型的公共数据集可用，或者由于不同数据集和任务之间的大领域差距，这些数据集无法使用。在这种情况下，转移所有知识可能不会带来好处，因为它可能无关紧要。在最坏的情况下，这可能会导致负迁移[[28](#bib.bib28),
    [132](#bib.bib132)]，其中提取的知识对新任务学习造成伤害。这要求评估源任务和目标任务之间的关系，仔细选择要转移的知识，并选择适当的方法来实现这种转移。Glorot等人尝试分析和量化从源领域到目标领域获得的知识[[133](#bib.bib133)]。例如，他们定义了转移误差、转移损失、转移比例和领域内比例，这些指标提供了解释转移性能的度量标准。
- en: 5.3 Directions for anomaly detection solution design
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 异常检测解决方案设计方向
- en: Data preprocessing
  id: totrans-226
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据预处理
- en: How data preprocessing should be conducted is an open question. For industrial
    applications, some researchers contend that using raw time series data directly
    as input for training may not be the most efficient. Hence, they propose deriving
    or selecting features from time series data by statistical methods or human experience.
    This can significantly decrease the complexity of the dataset. On the other hand,
    this crops a lot of potentially useful information, e.g., the time series trend.
    To reduce the dimensionality, some researchers use machine parameters as features
    in the manufacturing process instead of the processing data collected by sensors
    [[85](#bib.bib85), [10](#bib.bib10), [113](#bib.bib113), [114](#bib.bib114)].
    Others try different transformations of raw time series data, a common way being
    to transform 1D time series data to 2D image data [[9](#bib.bib9), [15](#bib.bib15),
    [112](#bib.bib112)] or transforming time domain signals otherwise into the frequency
    domain [[39](#bib.bib39)]. However, as large-scale computation power and storage
    become cheaper and more accessible, it is becoming increasingly common to use
    deep learning techniques to process time series data directly [[13](#bib.bib13),
    [11](#bib.bib11)].
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理应该如何进行仍然是一个悬而未决的问题。对于工业应用，一些研究人员认为直接使用原始时间序列数据作为训练输入可能不是最有效的。因此，他们建议通过统计方法或人工经验从时间序列数据中提取或选择特征。这可以显著减少数据集的复杂性。另一方面，这会裁剪掉大量潜在有用的信息，例如时间序列趋势。为了降低维度，一些研究人员使用机器参数作为制造过程中的特征，而不是传感器收集的处理数据[[85](#bib.bib85),
    [10](#bib.bib10), [113](#bib.bib113), [114](#bib.bib114)]。其他人尝试对原始时间序列数据进行不同的变换，常见的方法是将1D时间序列数据转化为2D图像数据[[9](#bib.bib9),
    [15](#bib.bib15), [112](#bib.bib112)]，或将时间域信号转化为频域[[39](#bib.bib39)]。然而，随着大规模计算能力和存储变得更便宜和更易获取，直接使用深度学习技术处理时间序列数据变得越来越普遍[[13](#bib.bib13),
    [11](#bib.bib11)]。
- en: Data augmentation by generative AI
  id: totrans-228
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 通过生成式人工智能进行数据增强
- en: Data augmentation is useful for deep learning models because it can help to
    prevent overfitting. For deep transfer learning, when a model becomes too closely
    adapted to the specifics of the source domain, it may not be able to generalize
    well to some examples in the task domain. One important technique is to acquire
    effective synthetic data, e.g., using a simulation process or model to explore
    potential anomalous conditions by simulating industrial processes under parameters
    that cannot yet be experienced in the real world. High fidelity and reliable simulation
    data can provide training data at low cost and mitigate the problem of insufficient
    samples for deep transfer learning [[13](#bib.bib13)]. Another way to generate
    effective synthetic data is to use generative models, such as GANs. GANs are only
    trained on normal data to generate indistinguishable normal samples so that abnormal
    samples can be distinguished during the testing stage of the overarching anomaly
    detection system, as they deviate from the normal data distribution [[134](#bib.bib134)].
    To increase the number of anomalous samples and thus the robustness of the anomaly
    detection model, the technique of adversarial perturbation known from computer
    vision [[135](#bib.bib135)] can be used.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强对深度学习模型非常有用，因为它可以帮助防止过拟合。对于深度迁移学习，当模型过于贴合源领域的具体特征时，它可能无法很好地推广到任务领域中的一些示例。一个重要的技术是获取有效的合成数据，例如，使用模拟过程或模型通过在现实世界中尚未经历的参数下模拟工业过程来探索潜在的异常条件。高保真度和可靠的模拟数据可以以低成本提供训练数据，并缓解深度迁移学习中的样本不足问题[[13](#bib.bib13)]。另一种生成有效合成数据的方法是使用生成模型，如GANs。GANs仅在正常数据上进行训练，以生成不可区分的正常样本，从而在整体异常检测系统的测试阶段中能够区分异常样本，因为它们偏离了正常数据分布[[134](#bib.bib134)]。为了增加异常样本的数量，从而提高异常检测模型的鲁棒性，可以使用计算机视觉中已知的对抗扰动技术[[135](#bib.bib135)]。
- en: Dealing with data imbalance
  id: totrans-230
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 处理数据不平衡
- en: DNNs perform well when they are trained on balanced datasets. However, in practice,
    it is difficult to get sufficient anomalous data for anomaly detection tasks.
    For example, the manufacturing process is usually in a healthy state due to the
    pre-designed and optimized operation. Several ways exist to address the imbalanced
    dataset for time series anomaly detection. One way is to oversample the minority
    class, e.g., by randomly replicating samples from the minority class to equalize
    the number of samples from each class in each batch. The Synthetic Minority Over-sampling
    Technique is an advanced method that creates synthetic samples to force the decision
    region of the minority class to become more general [[136](#bib.bib136)]. This
    technique is widely used in anomaly detection tasks in industry [[137](#bib.bib137),
    [138](#bib.bib138)]. Apart from oversampling, resampling strategies are frequently
    used to assign a higher probability to abnormal samples and evenly select the
    same amount of samples from both classes in each batch. Moreover, a weighted loss
    can be implemented to balance the loss between the abnormal and normal class in
    supervised anomaly detection [[131](#bib.bib131)].
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: DNN在平衡数据集上表现良好。然而，在实践中，很难获得足够的异常数据用于异常检测任务。例如，由于预先设计和优化的操作，制造过程通常处于健康状态。有几种方法可以解决时间序列异常检测中的不平衡数据集问题。一种方法是过采样少数类，例如，通过随机复制少数类样本来平衡每个批次中每个类的样本数量。合成少数类过采样技术是一种高级方法，它创建合成样本以使少数类的决策区域变得更加通用[[136](#bib.bib136)]。这种技术在工业中的异常检测任务中被广泛使用[[137](#bib.bib137),
    [138](#bib.bib138)]。除了过采样，重采样策略也常用于赋予异常样本更高的概率，并在每个批次中均匀选择来自两个类别的相同数量的样本。此外，可以实现加权损失以平衡监督异常检测中的异常类和正常类之间的损失[[131](#bib.bib131)]。
- en: 5.4 Directions for deep transfer learning implementation
  id: totrans-232
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 深度迁移学习实施的方向
- en: When shall deep transfer learning be used?
  id: totrans-233
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 什么时候应该使用深度迁移学习？
- en: '(1) \change[]Limited data availability: If the data available for a specific
    task is limited, pre-training on related source data can learn general features
    that can be transferred to the specific learning task in the target domain. Limited
    data availability: It poses a significant challenge in machine learning, particularly
    when aiming to train models for specific tasks. Pre-training a model on a larger
    or more diverse dataset, even if unrelated to the specific task at hand, enables
    the acquisition of generalizable features and representations. These generalized
    features, learned from a broader context, can then be effectively transferred
    to analyze the target domain with limited data. This can effectively provide a
    practical solution to the challenges posed by data scarcity. (2) Similar domains:
    Deep transfer learning is well suited when tackling source and target domains
    with a high degree of similarity. \add[]In such instances, knowledge can be derived
    either from a model pre-trained on a similar dataset or one trained on both source
    and target data. In both cases, the model can efficiently transfer relevant features
    and representations within the domain, facilitating a more robust adaptation to
    the target dataset, and ultimately optimizing the model’s ability to discern and
    detect patterns within the target domain. (3) \change[]Limited resources (time
    and compute): In cases where resources are constrained, it is recommended to employ
    parameter transfer, especially if a pre-trained model is readily available. Limited
    resources (encompassing both time and computational power): When faced with resource
    constraints, it is recommended to employ parameter transfer, especially if a pre-trained
    model is readily available. As described in [[34](#bib.bib34)], \add[]the transfer
    might improve learning in three distinct ways: (a) a higher performance at the
    very beginning of learning, (b) a steeper slope in the learning curve, or (c)
    a higher asymptotic performance. Parameter transfer leverages the learned parameters
    and weights of a pre-trained model, often trained on a larger dataset. By doing
    so, the resource-intensive process of training a model from the ground up is circumvented,
    and the computational burden is significantly alleviated.'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: (1) \change[]有限的数据可用性：如果某个特定任务的数据有限，通过在相关源数据上进行预训练，可以学习到一般特征，这些特征可以迁移到目标领域的特定学习任务中。有限的数据可用性：这是机器学习中的一个重大挑战，尤其是在为特定任务训练模型时。即便是与当前任务无关的更大或更多样化的数据集上的预训练，也能使模型获得可泛化的特征和表示。这些从更广泛背景中学习到的特征，可以有效迁移到目标领域，以应对数据稀缺带来的挑战，从而提供切实的解决方案。
    (2) 相似领域：当源领域和目标领域具有高度相似性时，深度迁移学习特别适用。 \add[]在这种情况下，知识可以来源于在类似数据集上预训练的模型，或者同时在源数据和目标数据上训练的模型。在这两种情况下，模型都能有效地迁移领域内的相关特征和表示，促进对目标数据集的更稳健的适应，并最终优化模型在目标领域内识别和检测模式的能力。
    (3) \change[]有限的资源（时间和计算）：当资源受限时，建议使用参数迁移，特别是当已有预训练模型时。有限的资源（包括时间和计算能力）：当面临资源限制时，建议使用参数迁移，特别是当已有预训练模型时。如
    [[34](#bib.bib34)] 所述，\add[]这种迁移可能以三种不同方式提高学习效果：（a）学习初期的高性能，（b）学习曲线的陡峭度，或（c）较高的渐近性能。参数迁移利用了预训练模型的学习参数和权重，这些模型通常是在更大的数据集上训练的。通过这样做，可以避免从头开始训练模型的资源密集型过程，从而显著减轻计算负担。
- en: When not to use deep transfer learning?
  id: totrans-235
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 什么时候不使用深度迁移学习？
- en: '(1) Irrelevant data: If the target data is vastly different from the source
    data, deep transfer learning may not be appropriate, sometimes even leading to
    negative transfer. For example, if one wants to train a model for natural language
    processing on a new dataset, using a pre-trained model that has been trained on
    image data may not yield meaningful results. This is due to the vast dissimilarity
    in data modalities and features between images and text. \add[](2) Task-specific
    models: In scenarios where the target task is well-defined and specific, and pre-trained
    models do not align closely with the task requirements, it is usually more effective
    to build a task-specific model from scratch. (3) High domain shift: If there is
    a large difference between the source and the target domain, deep transfer learning
    may not be effective. This can happen when the data distributions, features, or
    labels are vastly different. (4) Abundance of labeled data available for target
    task: If there are enough data for the new task, it may be more effective to train
    a model from scratch [[119](#bib.bib119)].'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 不相关的数据：如果目标数据与源数据差异极大，深度迁移学习可能不适用，有时甚至会导致负迁移。例如，如果要在新的数据集上训练一个自然语言处理模型，使用一个在图像数据上训练的预训练模型可能不会产生有意义的结果。这是由于图像和文本之间的数据模态和特征的巨大差异。
    \add[](2 任务特定模型：在目标任务明确且具体的情况下，如果预训练模型与任务要求不匹配，通常从头开始构建一个任务特定的模型会更有效。 (3) 高领域转移：如果源领域和目标领域之间存在较大差异，深度迁移学习可能无效。这种情况可能发生在数据分布、特征或标签差异极大的情况下。
    (4) 目标任务有大量标注数据可用：如果新任务有足够的数据，可能从头开始训练一个模型会更有效 [[119](#bib.bib119)]。
- en: What model architecture to choose?
  id: totrans-237
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 选择什么模型架构？
- en: We recommend choosing the model architecture mainly based on data size and label
    availability, starting from a relatively small network and moving gradually to
    more complex DNNs. CNNs also effectively extract time series features [[19](#bib.bib19),
    [111](#bib.bib111)]. For semi-supervised settings, CNN-based auto-encoders are
    trained to reconstruct the original data [[110](#bib.bib110)]. It is important
    to effectively capture the temporal dependencies and extract features of time
    series data. LSTMs are extensively employed for this purpose, as they excel in
    detecting temporal dependencies in time series data [[112](#bib.bib112), [21](#bib.bib21),
    [23](#bib.bib23)].
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 我们建议主要根据数据大小和标签可用性选择模型架构，从相对较小的网络开始，逐渐过渡到更复杂的深度神经网络。卷积神经网络（CNN）也能有效提取时间序列特征
    [[19](#bib.bib19), [111](#bib.bib111)]。对于半监督设置，基于CNN的自编码器被训练来重建原始数据 [[110](#bib.bib110)]。有效捕捉时间依赖性并提取时间序列数据特征是非常重要的。长短期记忆网络（LSTM）被广泛应用于此目的，因为它们在检测时间序列数据中的时间依赖性方面表现出色
    [[112](#bib.bib112), [21](#bib.bib21), [23](#bib.bib23)]。
- en: \add
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: \add
- en: '[] Exploring hybrid architectures that combine the advantages of CNNs, RNNs,
    and LSTMs for tasks involving both spatial and temporal dependencies can be beneficial.
    Cao et al. \add[]propose a multi-head CNN–RNN architecture for multi-time series
    anomaly detection [[16](#bib.bib16)]. \add[]A CNN is used to extract meaningful
    features from raw data and then an RNN is applied to learn temporal patterns simultaneously.
    Similarly, Dhillon et al. utilize LSTM layers to model the time series signals
    after obtaining the features from a CNN. An alternative way to benefit from different
    models is the use of ensemble approaches, combining the strengths of different
    model architectures to enhance performance, especially in situations where the
    target task requires capturing diverse features. In the future, we expect more
    applications to use transformer-based approaches as pre-trained models become
    available and public datasets get open-sourced.'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '[] 探索结合CNN、RNN和LSTM优势的混合架构，对涉及空间和时间依赖性的任务可能会有所帮助。Cao等人 \add[] 提出了一个用于多时间序列异常检测的多头CNN–RNN架构
    [[16](#bib.bib16)]。 \add[] CNN用于从原始数据中提取有意义的特征，然后应用RNN同时学习时间模式。同样，Dhillon等人利用LSTM层在从CNN获得特征后对时间序列信号进行建模。利用不同模型的另一种方法是使用集成方法，将不同模型架构的优势结合起来以提升性能，特别是在目标任务需要捕捉多样特征的情况下。未来，我们期望随着预训练模型的出现和公共数据集的开源，更多应用将采用基于变换器的方法。'
- en: Beyond transfer learning
  id: totrans-241
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 超越迁移学习
- en: 'Foundation models like SAM [[139](#bib.bib139)] or others, using for example
    transformer architectures [[48](#bib.bib48)] or diffusion models [[140](#bib.bib140)],
    demonstrate emerging properties such as in-context learning [[53](#bib.bib53)]
    and complex cross-modality conditioning. This is achieved by training complex
    and often auto-regressive models with massive amounts of data, although the precise
    mechanisms that lead to this are not well understood. Some of those models generalize
    to new settings and tasks, without an explicit element of transfer learning. Thus,
    the application of foundation models in industrial time series analysis has the
    potential to reduce and eventually eliminate the need to explicitly account for
    changes in the domain within the modeling, by instead having the foundation model
    provide the transfer capability (see examples in Sec. [6](#S6 "6 Conclusions ‣
    A Comprehensive Survey of Deep Transfer Learning for Anomaly Detection in Industrial
    Time Series: Methods, Applications, and Directions")-b). To not only detect anomalies
    but also identify failure modes, analyze root causes, and elicit an appropriate
    intervention, AI systems must implicitly or explicitly model causal relations.
    Counterfactual inference incorporates causal relations between observations and
    interventions, which allows predictions of outcomes never seen during training
    [[141](#bib.bib141)].'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '像SAM [[139](#bib.bib139)] 这样的基础模型，或者使用例如变换器架构[[48](#bib.bib48)] 或扩散模型[[140](#bib.bib140)]，展现了诸如上下文学习[[53](#bib.bib53)]
    和复杂的跨模态条件等新兴特性。这是通过用大量数据训练复杂且通常是自回归的模型来实现的，尽管导致这些特性的具体机制尚不完全明了。部分模型能够推广到新的设置和任务中，而无需显式的迁移学习元素。因此，基础模型在工业时间序列分析中的应用有可能减少并最终消除在建模过程中显式考虑领域变化的需要，而是让基础模型提供迁移能力（见第[6节](#S6
    "6 Conclusions ‣ A Comprehensive Survey of Deep Transfer Learning for Anomaly
    Detection in Industrial Time Series: Methods, Applications, and Directions")-b）。为了不仅检测异常，还要识别故障模式、分析根本原因并采取适当的干预，AI系统必须隐式或显式地建模因果关系。反事实推理结合了观察与干预之间的因果关系，这允许预测在训练过程中从未见过的结果[[141](#bib.bib141)]。'
- en: Another aspect of deep learning implementations is the limited computing power
    of hardware platforms, such as embedded systems in industry. Sensor data are typically
    acquired using resource-constrained edge processing devices that struggle with
    computationally intensive tasks, especially when training a DNN model. Federated
    learning stands out as a leading solution, with its ability to utilize data while
    preserving privacy [[142](#bib.bib142), [143](#bib.bib143)]. The technology enables
    a more collaborative approach to ML while preserving user privacy by storing data
    decentralized on distributed devices rather than on a central server. Combining
    deep transfer learning with federated learning is a promising and powerful combination
    in the abovementioned industrial applications.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习实施的另一个方面是硬件平台的计算能力有限，例如工业中的嵌入式系统。传感器数据通常通过资源受限的边缘处理设备获取，这些设备在进行计算密集型任务时尤其吃力，特别是在训练DNN模型时。联邦学习作为一种领先的解决方案脱颖而出，因为它能够在保护隐私的同时利用数据[[142](#bib.bib142),
    [143](#bib.bib143)]。该技术通过将数据分散存储在分布式设备上，而不是集中在中央服务器上，来实现更具协作性的机器学习方法，同时保护用户隐私。将深度迁移学习与联邦学习结合起来，在上述工业应用中是一个有前景且强大的组合。
- en: 6 Conclusions
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this survey, we presented a comprehensive overview of deep transfer learning
    by defining transfer learning problem settings and categorizing the state-of-the-art
    deep transfer learning approaches based on the surveyed papers. Then, we review
    and emphasize on investigating deep transfer learning approaches for time series
    anomaly detection in different industrial settings. Equipped with this foundation,
    we selected representative examples of the landscape of fielded applications to
    provide practitioners with a guide to the field and possibilities of industrial
    time series anomaly detection.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项调查中，我们通过定义迁移学习问题设置并基于调研文献对最先进的深度迁移学习方法进行分类，提供了深度迁移学习的全面概述。然后，我们回顾并强调了在不同工业环境下对时间序列异常检测的深度迁移学习方法进行研究。以此为基础，我们选择了代表性的实际应用案例，以便为从业者提供有关该领域及工业时间序列异常检测的指南和可能性。
- en: The main finding of this survey is that only a limited variety of deep transfer
    learning methods are employed in anomaly detection in industrial time series analysis
    – mainly simple ones. Almost all applications employ parameter transfer, arguably
    the most straightforward transfer approach. In its simplest implementation, it
    only involves fine-tuning a pre-trained model. Accordingly, the employed network
    architectures are simple, none of the reviewed research papers used advanced DNN
    building blocks like Transformer, which are common in computer vision and language
    modeling. We expect this type of architecture with suitable modifications and/or
    pre-trained parameters to spread to more niche fields. Despite this, the survey
    suggests that deep transfer learning approaches have huge potential and promise
    for solving more complex and dynamic anomaly detection tasks in industry. As the
    field is still in an early stage, more R&D is expected to fully realize the potential
    of deep transfer learning in increasingly complex settings.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的主要发现是，工业时间序列分析中的异常检测中只采用了有限种类的深度迁移学习方法——主要是简单的方法。几乎所有应用都采用了参数迁移，这无疑是最简单的迁移方法。在最简单的实现中，它只涉及微调一个预训练模型。因此，所采用的网络架构都很简单，审查的研究论文中没有使用诸如Transformer这样的高级DNN构建模块，这些模块在计算机视觉和语言建模中很常见。我们预计这种架构在经过适当修改和/或预训练参数后，将扩展到更多专业领域。尽管如此，调查表明，深度迁移学习方法在解决更复杂和动态的工业异常检测任务方面具有巨大的潜力和前景。由于该领域仍处于早期阶段，预计更多的研发将全面实现深度迁移学习在日益复杂环境中的潜力。
- en: 'In the end, we highlight the importance of considering feasibility, reliability,
    explainability, and real-time data stream when designing a transfer learning system
    for time series anomaly detection. After carefully discussing open challenges,
    we gave practical directions for time series anomaly detection solution design
    and deep transfer learning implementation. In our view, the following directions
    hold the greatest potential for future work:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们强调在设计时间序列异常检测的迁移学习系统时，考虑可行性、可靠性、解释性和实时数据流的重要性。在详细讨论了开放挑战后，我们为时间序列异常检测解决方案设计和深度迁移学习实现提供了实际方向。我们认为，以下方向具有最大的未来工作潜力：
- en: Automatic selection of transferable features [[57](#bib.bib57)]
  id: totrans-248
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 自动选择可转移特征 [[57](#bib.bib57)]
- en: It refers to methods for selecting and transferring only the relevant knowledge
    for the new tasks from the base model. This could involve the use of techniques
    such as selective fine-tuning and distillation to identify the most important
    features learned from source domains [[30](#bib.bib30), [144](#bib.bib144)].
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是从基础模型中选择和转移仅与新任务相关的知识的方法。这可能涉及使用诸如选择性微调和蒸馏等技术，以识别从源领域学习到的最重要特征 [[30](#bib.bib30),
    [144](#bib.bib144)]。
- en: Investing into advanced deep transfer learning schemes and DNN models
  id: totrans-250
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 投资于先进的深度迁移学习方案和DNN模型
- en: The conceptionally simplest parameter transfer approach has the advantage of
    being readily applicable by interdisciplinary teams without ML research experience.
    However, it seems promising to invest in testing more sophisticated deep transfer
    learning approaches according to different use cases, such as mapping transfer,
    adversarial transfer, etc. The same applies to testing diverse DNN models besides
    straightforward ones. \add[]Recently, large models have been used in time series
    anomaly detection. \add[]For example, Xu et al. propose the Anomaly Transformer
    with a new anomaly-attention mechanism to compute the association discrepancy
    [[145](#bib.bib145)]. \add[]A minimax strategy is devised to amplify the normal-abnormal
    distinguishability of the association discrepancy. On the other hand, Pintilie
    et al. leverage diffusion models for multivariate time series anomaly detection
    [[146](#bib.bib146)]. \add[]They train two diffusion-based models that outperform
    strong transformer-based methods on synthetic datasets and are competitive on
    real-world data. Additionally, their DiffusionAE model is more robust to different
    levels and the number of anomaly types. These large models have proven to be effective
    and advantageous given certain data and tasks. It’s important to note that their
    effectiveness also depends on the characteristics of the time series data and
    the requirements of the anomaly detection task. Additionally, model computational
    efficiency and interpretability should be considered, especially in real-time
    or resource-constrained industrial applications.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 概念上最简单的参数迁移方法的优势在于可以被没有机器学习研究经验的跨学科团队直接应用。然而，投资于根据不同用例测试更复杂的深度迁移学习方法，如映射迁移、对抗迁移等，看起来是有前景的。同样，测试除了直接模型之外的多种深度神经网络模型也适用。
    \add[]最近，大型模型已被用于时间序列异常检测。 \add[]例如，Xu等人提出了具有新异常注意机制的异常变换器来计算关联差异[[145](#bib.bib145)]。
    \add[]制定了一种极小极大策略来放大关联差异的正常-异常区分性。另一方面，Pintilie等人利用扩散模型进行多变量时间序列异常检测[[146](#bib.bib146)]。
    \add[]他们训练的两种基于扩散的模型在合成数据集上优于强大的变换器方法，并在实际数据中具有竞争力。此外，他们的DiffusionAE模型对不同的异常水平和类型数量更为鲁棒。鉴于某些数据和任务，这些大型模型已被证明有效且具有优势。需要注意的是，它们的有效性也取决于时间序列数据的特征和异常检测任务的要求。此外，模型的计算效率和可解释性也应考虑，特别是在实时或资源受限的工业应用中。
- en: Data-centric approach to real-time anomaly detection
  id: totrans-252
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实时异常检测的数据驱动方法
- en: The data-centric approach focuses on improving ML models by ensuring high-quality
    labeled data [[147](#bib.bib147)] using techniques such as re-labeling, re-weighting,
    or data augmentation [[148](#bib.bib148)]. Currently, a human-in-the-loop solution
    is still needed. Frameworks have been proposed to assist annotators with graph-based
    algorithms such as nearest neighbor graphs [[84](#bib.bib84)], decision trees
    [[149](#bib.bib149)], or factor graphs [[150](#bib.bib150)]. Although these methods
    have proven to be effective, a more automated process is a goal for future research.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 数据驱动的方法专注于通过确保高质量标注数据[[147](#bib.bib147)]来改进机器学习模型，采用的技术包括重新标注、重新加权或数据增强[[148](#bib.bib148)]。目前，仍然需要人类参与的解决方案。已经提出了框架来辅助标注员，使用图形算法如最近邻图[[84](#bib.bib84)]、决策树[[149](#bib.bib149)]或因子图[[150](#bib.bib150)]。尽管这些方法已被证明有效，但更自动化的过程仍是未来研究的最终目标。
- en: Leveraging generative AI
  id: totrans-254
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 利用生成式人工智能
- en: Generative models like GANs and diffusion models can generate synthetic time
    series data, making them valuable for data augmentation. Augmenting the original
    data with synthetic samples can enhance the deep learning models’ robustness,
    especially in real-world applications where target data are limited. These models
    can also be leveraged to examine anomalies and generate anomalies to help alleviate
    the imbalance within the data [[151](#bib.bib151)].
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型如GANs和扩散模型可以生成合成时间序列数据，使其在数据增强中非常有价值。用合成样本增强原始数据可以提升深度学习模型的鲁棒性，尤其是在目标数据有限的实际应用中。这些模型还可以被用来检查异常和生成异常，帮助缓解数据中的不平衡问题[[151](#bib.bib151)]。
- en: Integration with other ML methods
  id: totrans-256
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 与其他机器学习方法的集成
- en: To develop robust AI solutions for time series anomaly detection in the industry,
    relying solely on transfer learning is insufficient. Future strategies should
    integrate other ML approaches, including continuous learning, meta-learning, and
    federated learning.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在工业中开发强健的时间序列异常检测AI解决方案，单靠迁移学习是不够的。未来的策略应整合其他机器学习方法，包括持续学习、元学习和联邦学习。
- en: References
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Henning Kagermann, Wolf-Dieter Lukas, and Wolfgang Wahlster. Industrie
    4.0: Mit dem internet der dinge auf dem weg zur 4\. industriellen revolution.
    VDI Nachrichten, 13(1):2–3, 2011.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Henning Kagermann、Wolf-Dieter Lukas 和 Wolfgang Wahlster. 工业4.0：通过物联网迈向第四次工业革命。VDI
    Nachrichten, 13(1):2–3，2011年。'
- en: '[2] Vasja Roblek, Maja Meško, and Alojz Krapež. A complex view of industry
    4.0. SAGE Open, 6(2), April 2016.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Vasja Roblek、Maja Meško 和 Alojz Krapež. 对工业4.0的复杂视角。SAGE Open, 6(2)，2016年4月。'
- en: '[3] Lihui Wang, Martin Törngren, and Mauro Onori. Current status and advancement
    of cyber-physical systems in manufacturing. J. Manuf. Syst., 37:517–527, October
    2015.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Lihui Wang、Martin Törngren 和 Mauro Onori. 制造中网络物理系统的现状和进展。J. Manuf. Syst.,
    37:517–527，2015年10月。'
- en: '[4] Sabina Jeschke, Christian Brecher, Tobias Meisen, Denis Özdemir, and Tim
    Eschert. Industrial internet of things and cyber manufacturing systems. In Industrial
    Internet of Things: Cybermanufacturing Systems, pages 3–19\. Springer, 2017.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Sabina Jeschke、Christian Brecher、Tobias Meisen、Denis Özdemir 和 Tim Eschert.
    工业物联网与网络制造系统。发表于《工业物联网：网络制造系统》，页码3–19。Springer，2017年。'
- en: '[5] Lucas Santos Dalenogare, Guilherme Brittes Benitez, Néstor Fabián Ayala,
    and Alejandro Germán Frank. The expected contribution of Industry 4.0 technologies
    for industrial performance. Int. J. Prod. Econ., 204:383–394, October 2018.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] Lucas Santos Dalenogare、Guilherme Brittes Benitez、Néstor Fabián Ayala 和
    Alejandro Germán Frank. 工业4.0技术对工业绩效的预期贡献。Int. J. Prod. Econ., 204:383–394，2018年10月。'
- en: '[6] Henning Kagermann. Chancen von Industrie 4.0 nutzen. In Handbuch Industrie
    4.0 Bd.4: Allgemeine Grundlagen, pages 237–248\. Springer, Berlin, Heidelberg,
    2017.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Henning Kagermann. 利用工业4.0的机会。发表于《工业4.0手册 第4卷：一般基础》，页码237–248。Springer，柏林，海德堡，2017年。'
- en: '[7] S. M. Abu Adnan Abir, Adnan Anwar, Jinho Choi, and A. S. M. Kayes. IoT-Enabled
    smart energy grid: Applications and challenges. IEEE Access, 9:50961–50981, 2021.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] S. M. Abu Adnan Abir、Adnan Anwar、Jinho Choi 和 A. S. M. Kayes. 基于物联网的智能能源网：应用与挑战。IEEE
    Access, 9:50961–50981，2021年。'
- en: '[8] You-Jin Park, Shu-Kai S. Fan, and Chia-Yu Hsu. A review on fault detection
    and process diagnostics in industrial processes. Processes, 8(9):1123, September
    2020.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] You-Jin Park、Shu-Kai S. Fan 和 Chia-Yu Hsu. 关于工业过程中的故障检测和过程诊断的综述。Processes,
    8(9):1123，2020年9月。'
- en: '[9] Yabin Liao, Ihab Ragai, Ziyun Huang, and Scott Kerner. Manufacturing process
    monitoring using time-frequency representation and transfer learning of deep neural
    networks. J. Manuf. Processes, 68:231–248, August 2021.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Yabin Liao、Ihab Ragai、Ziyun Huang 和 Scott Kerner. 使用时间频率表示和深度神经网络迁移学习进行制造过程监控。J.
    Manuf. Processes, 68:231–248，2021年8月。'
- en: '[10] Yannik Lockner and Christian Hopmann. Induced network-based transfer learning
    in injection molding for process modelling and optimization with artificial neural
    networks. IJAMT, 112(11):3501–3513, February 2021.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Yannik Lockner 和 Christian Hopmann. 注射成型中基于网络的迁移学习用于过程建模和优化，采用人工神经网络。IJAMT,
    112(11):3501–3513，2021年2月。'
- en: '[11] Benjamin Maschler, Tim Knodel, and Michael Weyrich. Towards deep industrial
    transfer learning for anomaly detection on time series data. In Proc. 26th IEEE
    ETFA, pages 01–08, September 2021.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Benjamin Maschler、Tim Knodel 和 Michael Weyrich. 针对时间序列数据的异常检测的深度工业迁移学习。发表于第26届IEEE
    ETFA会议，页码01–08，2021年9月。'
- en: '[12] Tailai Wen and Roy Keyes. Time series anomaly detection using convolutional
    neural networks and transfer learning, May 2019. arXiv:1905.13628.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Tailai Wen 和 Roy Keyes. 使用卷积神经网络和迁移学习进行时间序列异常检测，2019年5月。arXiv:1905.13628。'
- en: '[13] Yan Xu, Yanming Sun, Xiaolong Liu, and Yonghua Zheng. A digital-twin-assisted
    fault diagnosis using deep transfer learning. IEEE Access, 7:19990–19999, 2019.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Yan Xu、Yanming Sun、Xiaolong Liu 和 Yonghua Zheng. 基于深度迁移学习的数字双胞胎辅助故障诊断。IEEE
    Access, 7:19990–19999，2019年。'
- en: '[14] Wentao Mao, Di Zhang, Siyu Tian, and Jiamei Tang. Robust detection of
    bearing early fault based on deep transfer learning. Electronics, 9(2):323, February
    2020.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Wentao Mao、Di Zhang、Siyu Tian 和 Jiamei Tang. 基于深度迁移学习的轴承早期故障鲁棒检测。Electronics,
    9(2):323，2020年2月。'
- en: '[15] Weiping Wang, Zhaorong Wang, Zhanfan Zhou, Haixia Deng, Weiliang Zhao,
    Chunyang Wang, and Yongzhen Guo. Anomaly detection of industrial control systems
    based on transfer learning. Tsinghua Sci. Technol., 26(6):821–832, December 2021.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] Weiping Wang、Zhaorong Wang、Zhanfan Zhou、Haixia Deng、Weiliang Zhao、Chunyang
    Wang 和 Yongzhen Guo. 基于迁移学习的工业控制系统异常检测。清华科学技术, 26(6):821–832，2021年12月。'
- en: '[16] Mikel Canizo, Isaac Triguero, Angel Conde, and Enrique Onieva. Multi-head
    CNN–RNN for multi-time series anomaly detection: An industrial case study. Neurocomputing,
    363:246–260, October 2019.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Mikel Canizo、Isaac Triguero、Angel Conde 和 Enrique Onieva. 多头CNN–RNN用于多时间序列异常检测：一个工业案例研究。Neurocomputing,
    363:246–260，2019年10月。'
- en: '[17] Manuel Weber, Christoph Doblander, and Peter Mandl. Towards the detection
    of building occupancy with synthetic environmental data, October 2020. arXiv:2010.04209.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Manuel Weber、Christoph Doblander 和 Peter Mandl. 利用合成环境数据进行建筑物占用检测的探索，2020年10月。arXiv:2010.04209。'
- en: '[18] Aya Nabil Sayed, Yassine Himeur, and Faycal Bensaali. From time-series
    to 2D images for building occupancy prediction using deep transfer learning. EAAI,
    119:105786, March 2023.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Aya Nabil Sayed、Yassine Himeur 和 Faycal Bensaali. 利用深度迁移学习将时间序列转换为二维图像进行建筑物占用预测。EAAI,
    119:105786, 2023年3月。'
- en: '[19] Y Yao, D Ge, J Yu, and M Xie. Model-based deep transfer learning method
    to fault detection and diagnosis in nuclear power plants. Front. Energy Res.,
    10, 2022.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Y Yao、D Ge、J Yu 和 M Xie. 基于模型的深度迁移学习方法用于核电站故障检测和诊断。Front. Energy Res.,
    10, 2022年。'
- en: '[20] Mustafa Abdallah, Wo Jae Lee, Nithin Raghunathan, Charilaos Mousoulis,
    John W. Sutherland, and Saurabh Bagchi. Anomaly detection through transfer learning
    in agriculture and manufacturing IoT systems, February 2021. arXiv:2102.05814.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Mustafa Abdallah、Wo Jae Lee、Nithin Raghunathan、Charilaos Mousoulis、John
    W. Sutherland 和 Saurabh Bagchi. 农业和制造业物联网系统中的异常检测通过迁移学习，2021年2月。arXiv:2102.05814。'
- en: '[21] Chanin Panjapornpon, Santi Bardeeniz, Mohamed Azlan Hussain, and Patamawadee
    Chomchai. Explainable deep transfer learning for energy efficiency prediction
    based on uncertainty detection and identification. Energy and AI, 12:100224, April
    2023.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Chanin Panjapornpon、Santi Bardeeniz、Mohamed Azlan Hussain 和 Patamawadee
    Chomchai. 基于不确定性检测和识别的可解释深度迁移学习用于能源效率预测。Energy and AI, 12:100224, 2023年4月。'
- en: '[22] Harsh Dhillon and Anwar Haque. Towards network traffic monitoring using
    deep transfer learning. In Proc. IEEE 19th TrustCom, pages 1089–1096, December
    2020.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Harsh Dhillon 和 Anwar Haque. 通过深度迁移学习进行网络流量监控的探索。在 Proc. IEEE 19th TrustCom，页码
    1089–1096，2020年12月。'
- en: '[23] Peng Xiong, Yonxin Zhu, Zhanrui Sun, Zihao Cao, Menglin Wang, and Yu Zheng.
    Application of transfer learning in continuous time series for anomaly detection
    in commercial aircraft flight data. In Proc. IEEE SmartCloud, pages 13–18, September
    2018.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Peng Xiong、Yonxin Zhu、Zhanrui Sun、Zihao Cao、Menglin Wang 和 Yu Zheng. 迁移学习在连续时间序列中的应用，用于商业飞机飞行数据的异常检测。在
    Proc. IEEE SmartCloud，页码 13–18，2018年9月。'
- en: '[24] Yoshua Bengio, Aaron Courville, and Pascal Vincent. Representation learning:
    A review and new perspectives. IEEE TPAMI, 35(8):1798–1828, August 2013.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Yoshua Bengio、Aaron Courville 和 Pascal Vincent. 表示学习：综述与新视角。IEEE TPAMI,
    35(8):1798–1828, 2013年8月。'
- en: '[25] Benjamin Maschler, Hannes Vietz, Hasan Tercan, Christian Bitter, Tobias
    Meisen, and Michael Weyrich. Insights and example use cases on industrial transfer
    learning. Procedia CIRP, 107:511–516, 2022.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Benjamin Maschler、Hannes Vietz、Hasan Tercan、Christian Bitter、Tobias Meisen
    和 Michael Weyrich. 工业迁移学习的见解与示例应用案例。Procedia CIRP, 107:511–516, 2022年。'
- en: '[26] Benjamin Maschler and Michael Weyrich. Deep transfer learning for industrial
    automation: A review and discussion of new techniques for data-driven machine
    learning. IEEE Ind. Electron. Mag., 15(2):65–75, 2021.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Benjamin Maschler 和 Michael Weyrich. 工业自动化中的深度迁移学习：数据驱动机器学习新技术的综述与讨论。IEEE
    Ind. Electron. Mag., 15(2):65–75, 2021年。'
- en: '[27] Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun Zhu, Hengshu
    Zhu, Hui Xiong, and Qing He. A comprehensive survey on transfer learning. Proc.
    IEEE, 109(1):43–76, January 2021.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Fuzhen Zhuang、Zhiyuan Qi、Keyu Duan、Dongbo Xi、Yongchun Zhu、Hengshu Zhu、Hui
    Xiong 和 Qing He. 迁移学习的综合调查。Proc. IEEE, 109(1):43–76, 2021年1月。'
- en: '[28] Sinno Jialin Pan and Qiang Yang. A survey on transfer learning. IEEE Trans.
    Knowl. Data Eng., 22(10):1345–1359, October 2010.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Sinno Jialin Pan 和 Qiang Yang. 迁移学习的调查。IEEE Trans. Knowl. Data Eng., 22(10):1345–1359,
    2010年10月。'
- en: '[29] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang, and Chunfang
    Liu. A survey on deep transfer learning. In Proc. ICANN 2018, pages 270–279, 2018.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Chuanqi Tan、Fuchun Sun、Tao Kong、Wenchang Zhang、Chao Yang 和 Chunfang Liu.
    深度迁移学习的调查。在 Proc. ICANN 2018，页码 270–279，2018年。'
- en: '[30] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson. How transferable
    are features in deep neural networks? In Proc. NeurIPS, volume 27, 2014.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Jason Yosinski、Jeff Clune、Yoshua Bengio 和 Hod Lipson. 深度神经网络中的特征可迁移性如何？在
    Proc. NeurIPS, volume 27, 2014年。'
- en: '[31] Fuchao Yu, Xianchao Xiu, and Yunhui Li. A survey on deep transfer learning
    and beyond. Mathematics, 10(19):3619, January 2022.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Fuchao Yu、Xianchao Xiu 和 Yunhui Li. 深度迁移学习及其扩展的调查。Mathematics, 10(19):3619,
    2022年1月。'
- en: '[32] Kukjin Choi, Jihun Yi, Changhwa Park, and Sungroh Yoon. Deep learning
    for anomaly detection in time-series data: review, analysis, and guidelines. IEEE
    Access, 9:120043–120065, 2021.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Kukjin Choi、Jihun Yi、Changhwa Park 和 Sungroh Yoon. 针对时间序列数据的异常检测的深度学习：综述、分析与指导。IEEE
    Access, 9:120043–120065, 2021年。'
- en: '[33] Raghavendra Chalapathy and Sanjay Chawla. Deep learning for anomaly detection:
    A survey, January 2019. arXiv:1901.03407.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Raghavendra Chalapathy 和 Sanjay Chawla. 异常检测的深度学习：综述，2019年1月。arXiv:1901.03407。'
- en: '[34] L. Torrey and J. Shavlik. Transfer learning. Handbook of Research on Machine
    Learning Applications, January 2009.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] L. Torrey 和 J. Shavlik. 迁移学习。机器学习应用研究手册，2009年1月。'
- en: '[35] Rich Caruana. Multitask learning. Mach. Learn., 28(1):41–75, 1997.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Rich Caruana. 多任务学习。机器学习，28(1):41–75，1997年。'
- en: '[36] Sebastian Ruder. An overview of multi-task learning in deep neural networks,
    June 2017. arXiv:1706.05098.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Sebastian Ruder. 深度神经网络中的多任务学习概述，2017年6月。arXiv:1706.05098。'
- en: '[37] Wouter M. Kouw and Marco Loog. An introduction to domain adaptation and
    transfer learning, January 2019. arXiv:1812.11806.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Wouter M. Kouw 和 Marco Loog. 域适应和迁移学习简介，2019年1月。arXiv:1812.11806。'
- en: '[38] Jürgen Schmidhuber. Deep learning in neural networks: An overview. Neural
    Networks, 61:85–117, January 2015.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Jürgen Schmidhuber. 神经网络中的深度学习：概述。神经网络，61:85–117，2015年1月。'
- en: '[39] Yanick Lukic, Carlo Vogt, Oliver Dürr, and Thilo Stadelmann. Speaker identification
    and clustering using convolutional neural networks. In Proc. 26th IEEE MLSP, pages
    1–6, September 2016.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Yanick Lukic, Carlo Vogt, Oliver Dürr 和 Thilo Stadelmann. 使用卷积神经网络进行说话人识别和聚类。发表于第26届IEEE
    MLSP会议，页码1–6，2016年9月。'
- en: '[40] Thilo Stadelmann, Mohammadreza Amirian, Ismail Arabaci, Marek Arnold,
    Gilbert François Duivesteijn, Ismail Elezi, Melanie Geiger, Stefan Lörwald, Benjamin Bruno
    Meier, Katharina Rombach, and Lukas Tuggener. Deep learning in the wild. In Proc.
    8th ANNPR, pages 17–38, 2018.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Thilo Stadelmann, Mohammadreza Amirian, Ismail Arabaci, Marek Arnold,
    Gilbert François Duivesteijn, Ismail Elezi, Melanie Geiger, Stefan Lörwald, Benjamin
    Bruno Meier, Katharina Rombach 和 Lukas Tuggener. 实际环境中的深度学习。发表于第8届ANNPR会议，页码17–38，2018年。'
- en: '[41] Juergen Schmidhuber. Annotated history of modern AI and deep learning,
    December 2022. arXiv:2212.11279.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] Juergen Schmidhuber. 现代AI和深度学习的注释历史，2022年12月。arXiv:2212.11279。'
- en: '[42] Qi-Qiao He, Shirley Weng In Siu, and Yain-Whar Si. Instance-based deep
    transfer learning with attention for stock movement prediction. Appl. Intell.,
    53(6):6887–6908, July 2022.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Qi-Qiao He, Shirley Weng In Siu 和 Yain-Whar Si. 带有注意力机制的基于实例的深度迁移学习用于股票运动预测。应用智能，53(6):6887–6908，2022年7月。'
- en: '[43] Mohammadreza Amirian, Javier A. Montoya-Zegarra, Jonathan Gruss, Yves D.
    Stebler, Ahmet Selman Bozkir, Marco Calandri, Friedhelm Schwenker, and Thilo Stadelmann.
    PrepNet: A convolutional auto-encoder to homogenize CT scans for cross-dataset
    medical image analysis. In Proc. 14th CISP-BMEI, pages 1–7, October 2021.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Mohammadreza Amirian, Javier A. Montoya-Zegarra, Jonathan Gruss, Yves
    D. Stebler, Ahmet Selman Bozkir, Marco Calandri, Friedhelm Schwenker 和 Thilo Stadelmann.
    PrepNet：一种卷积自编码器，用于跨数据集医学图像分析的CT扫描均化。发表于第14届CISP-BMEI会议，页码1–7，2021年10月。'
- en: '[44] Tianyang Wang, Jun Huan, and Michelle Zhu. Instance-based deep transfer
    learning. In Proc. IEEE WACV, pages 367–375, January 2019.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Tianyang Wang, Jun Huan 和 Michelle Zhu. 基于实例的深度迁移学习。发表于IEEE WACV会议，页码367–375，2019年1月。'
- en: '[45] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora,
    Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill,
    Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji,
    Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa
    Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei,
    Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby
    Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel E.
    Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky,
    Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab,
    Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal
    Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen
    Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell,
    Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen
    Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel
    Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher
    Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo
    Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam,
    Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian
    Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael
    Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang,
    Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, and Percy Liang. On the opportunities
    and risks of foundation models, July 2022. arXiv:2108.07258.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, Russ Altman, Simran Arora,
    Sydney von Arx, Michael S. Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill,
    Erik Brynjolfsson, Shyamal Buch, Dallas Card, Rodrigo Castellon, Niladri Chatterji,
    Annie Chen, Kathleen Creel, Jared Quincy Davis, Dora Demszky, Chris Donahue, Moussa
    Doumbouya, Esin Durmus, Stefano Ermon, John Etchemendy, Kawin Ethayarajh, Li Fei-Fei,
    Chelsea Finn, Trevor Gale, Lauren Gillespie, Karan Goel, Noah Goodman, Shelby
    Grossman, Neel Guha, Tatsunori Hashimoto, Peter Henderson, John Hewitt, Daniel
    E. Ho, Jenny Hong, Kyle Hsu, Jing Huang, Thomas Icard, Saahil Jain, Dan Jurafsky,
    Pratyusha Kalluri, Siddharth Karamcheti, Geoff Keeling, Fereshte Khani, Omar Khattab,
    Pang Wei Koh, Mark Krass, Ranjay Krishna, Rohith Kuditipudi, Ananya Kumar, Faisal
    Ladhak, Mina Lee, Tony Lee, Jure Leskovec, Isabelle Levent, Xiang Lisa Li, Xuechen
    Li, Tengyu Ma, Ali Malik, Christopher D. Manning, Suvir Mirchandani, Eric Mitchell,
    Zanele Munyikwa, Suraj Nair, Avanika Narayan, Deepak Narayanan, Ben Newman, Allen
    Nie, Juan Carlos Niebles, Hamed Nilforoshan, Julian Nyarko, Giray Ogut, Laurel
    Orr, Isabel Papadimitriou, Joon Sung Park, Chris Piech, Eva Portelance, Christopher
    Potts, Aditi Raghunathan, Rob Reich, Hongyu Ren, Frieda Rong, Yusuf Roohani, Camilo
    Ruiz, Jack Ryan, Christopher Ré, Dorsa Sadigh, Shiori Sagawa, Keshav Santhanam,
    Andy Shih, Krishnan Srinivasan, Alex Tamkin, Rohan Taori, Armin W. Thomas, Florian
    Tramèr, Rose E. Wang, William Wang, Bohan Wu, Jiajun Wu, Yuhuai Wu, Sang Michael
    Xie, Michihiro Yasunaga, Jiaxuan You, Matei Zaharia, Michael Zhang, Tianyi Zhang,
    Xikun Zhang, Yuhui Zhang, Lucia Zheng, Kaitlyn Zhou, 和 Percy Liang。关于基础模型的机遇与风险，2022年7月。arXiv:2108.07258。'
- en: '[46] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT:
    Pre-training of deep bidirectional transformers for language understanding. In
    Proc. NAACL-HLT 2019, pages 4171–4186, June 2019.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] Jacob Devlin, Ming-Wei Chang, Kenton Lee, 和 Kristina Toutanova。BERT: 深度双向变换器的预训练用于语言理解。在
    Proc. NAACL-HLT 2019, 第4171–4186页, 2019年6月。'
- en: '[47] Kuan Zhang, Shuchen Wang, Saijin Wang, and Qizhi Xu. Anomaly detection
    of control moment gyroscope based on working condition classification and transfer
    learning. Applied Sciences, 13(7):4259, January 2023.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Kuan Zhang, Shuchen Wang, Saijin Wang, 和 Qizhi Xu。基于工作条件分类和迁移学习的控制力矩陀螺仪异常检测。《应用科学》，13(7):4259,
    2023年1月。'
- en: '[48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need.
    In Proc. NeurIPS, volume 30, 2017.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N Gomez, Lukasz Kaiser, 和 Illia Polosukhin。注意力机制就是你所需要的。在 Proc. NeurIPS,
    第30卷, 2017年。'
- en: '[49] Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, and Yejin
    Choi. Is GPT-3 text indistinguishable from human text? Scarecrow: A framework
    for scrutinizing machine text. In Proc. 60th Annu. Meeting. ACL, pages 7250–7274,
    May 2022.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A. Smith, 和 Yejin
    Choi。GPT-3的文本是否无法与人类文本区分？Scarecrow: 一种审查机器文本的框架。在 Proc. 60th Annu. Meeting. ACL,
    第7250–7274页, 2022年5月。'
- en: '[50] Nikolich Alexandr, Osliakova Irina, Kudinova Tatyana, Kappusheva Inessa,
    and Puchkova Arina. Fine-tuning GPT-3 for Russian text summarization. In Proc.
    Data Science and Intelligent Systems, pages 748–757, 2021.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Nikolich Alexandr, Osliakova Irina, Kudinova Tatyana, Kappusheva Inessa,
    和 Puchkova Arina。针对俄语文本总结的GPT-3微调。在 Proc. Data Science and Intelligent Systems,
    第748–757页, 2021年。'
- en: '[51] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing,
    and Rogerio Feris. SpotTune: Transfer learning through adaptive fine-tuning. In
    Proc. CVPR, pages 4800–4809, June 2019.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Yunhui Guo, Honghui Shi, Abhishek Kumar, Kristen Grauman, Tajana Rosing,
    和 Rogerio Feris。SpotTune：通过自适应微调进行迁移学习。发表于 CVPR，页 4800–4809，2019年6月。'
- en: '[52] Pascal Sager, Sebastian Salzmann, Felice Burn, and Thilo Stadelmann. Unsupervised
    domain adaptation for vertebrae detection and identification in 3D CT volumes
    using a domain sanity loss. J. Imaging, 8(8), 2022.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Pascal Sager, Sebastian Salzmann, Felice Burn, 和 Thilo Stadelmann。使用领域理智损失进行脊椎检测和识别的无监督领域适应。J.
    Imaging，8(8)，2022年。'
- en: '[53] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
    Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child,
    Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen,
    Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher
    Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language
    models are few-shot learners. In Proc. NeurIPS, volume 33, pages 1877–1901, 2020.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
    Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
    Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child,
    Aditya Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen,
    Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher
    Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, 和 Dario Amodei。语言模型是少样本学习者。发表于
    NeurIPS，卷 33，页 1877–1901，2020年。'
- en: '[54] Yanxin Wang, Jing Yan, Xinyu Ye, Qianzhen Jing, Jianhua Wang, and Yingsan
    Geng. Few-shot transfer learning with attention mechanism for high-voltage rircuit
    breaker fault diagnosis. IEEE Trans. Ind. Appl., 58(3):3353–3360, May 2022.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Yanxin Wang, Jing Yan, Xinyu Ye, Qianzhen Jing, Jianhua Wang, 和 Yingsan
    Geng。用于高压断路器故障诊断的关注机制少样本迁移学习。IEEE Trans. Ind. Appl., 58(3):3353–3360，2022年5月。'
- en: '[55] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell.
    Deep domain confusion: Maximizing for domain invariance, December 2014. arXiv:1412.3474.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, 和 Trevor Darrell。深度领域混淆：最大化领域不变性，2014年12月。arXiv:1412.3474。'
- en: '[56] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer
    learning with joint adaptation networks. In Proc. ICML, pages 2208–2217, July
    2017.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Mingsheng Long, Han Zhu, Jianmin Wang, 和 Michael I Jordan。带有联合适应网络的深度迁移学习。发表于
    ICML，页 2208–2217，2017年7月。'
- en: '[57] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan. Learning transferable
    features with deep adaptation networks. In Proc. ICML, volume 37, pages 97–105,
    July 2015.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Mingsheng Long, Yue Cao, Jianmin Wang, 和 Michael Jordan。通过深度适应网络学习可迁移特征。发表于
    ICML，卷 37，页 97–105，2015年7月。'
- en: '[58] Xu Zhang, Felix Xinnan Yu, Shih-Fu Chang, and Shengjin Wang. Deep transfer
    network: Unsupervised domain adaptation, March 2015. arXiv:1503.00591.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Xu Zhang, Felix Xinnan Yu, Shih-Fu Chang, 和 Shengjin Wang。深度迁移网络：无监督领域适应，2015年3月。arXiv:1503.00591。'
- en: '[59] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, and Sethuraman
    Panchanathan. Deep hashing network for unsupervised domain adaptation. In Proc.
    CVPR, pages 5385–5394, July 2017.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Hemanth Venkateswara, Jose Eusebio, Shayok Chakraborty, 和 Sethuraman Panchanathan。用于无监督领域适应的深度哈希网络。发表于
    CVPR，页 5385–5394，2017年7月。'
- en: '[60] Elnaz Soleimani and Ehsan Nazerfard. Cross-subject transfer learning in
    human activity recognition systems using generative adversarial networks. Neurocomputing,
    426:26–34, February 2021.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Elnaz Soleimani 和 Ehsan Nazerfard。利用生成对抗网络进行人体活动识别系统中的跨主体迁移学习。神经计算，426:26–34，2021年2月。'
- en: '[61] Eric Tzeng, Judy Hoffman, Trevor Darrell, and Kate Saenko. Simultaneous
    deep transfer across domains and tasks. In Proc. ICCV, pages 4068–4076, December
    2015.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Eric Tzeng, Judy Hoffman, Trevor Darrell, 和 Kate Saenko。跨领域和任务的同时深度迁移。发表于
    ICCV，页 4068–4076，2015年12月。'
- en: '[62] Yilmazcan Ozyurt, Stefan Feuerriegel, and Ce Zhang. Contrastive learning
    for unsupervised domain adaptation of time series, February 2023. arXiv:2206.06243.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Yilmazcan Ozyurt, Stefan Feuerriegel, 和 Ce Zhang。时间序列的无监督领域适应对比学习，2023年2月。arXiv:2206.06243。'
- en: '[63] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle,
    François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial
    training of neural networks. In Domain Adaptation in Computer Vision Applications,
    pages 189–209\. Springer, 2017.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle,
    François Laviolette, Mario Marchand, 和 Victor Lempitsky。神经网络的领域对抗训练。发表于《计算机视觉应用中的领域适应》，页
    189–209。Springer，2017年。'
- en: '[64] Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, and
    Mario Marchand. Domain-adversarial neural networks, February 2015. arXiv:1412.4446.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, 和 Mario
    Marchand. 域对抗神经网络, 2015年2月。arXiv:1412.4446。'
- en: '[65] Eric Tzeng, Judy Hoffman, Kate Saenko, and Trevor Darrell. Adversarial
    discriminative domain adaptation. In Proc. CVPR, pages 7167–7176, July 2017.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Eric Tzeng, Judy Hoffman, Kate Saenko, 和 Trevor Darrell. 对抗性判别域适应。在 Proc.
    CVPR, 页码 7167–7176, 2017年7月。'
- en: '[66] Zewei Sun, Mingxuan Wang, and Lei Li. Multilingual translation via grafting
    pre-trained language models. In Proc. EMNLP 2021, pages 2735–2747, November 2021.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Zewei Sun, Mingxuan Wang, 和 Lei Li. 通过移植预训练语言模型进行多语言翻译。在 Proc. EMNLP 2021,
    页码 2735–2747, 2021年11月。'
- en: '[67] Michael Glass, Alfio Gliozzo, Rishav Chakravarti, Anthony Ferritto, Lin
    Pan, G P Shrivatsa Bhargav, Dinesh Garg, and Avi Sil. Span selection pre-training
    for question answering. In Proc. 58th Annu. Meeting. ACL, pages 2773–2782, July
    2020.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Michael Glass, Alfio Gliozzo, Rishav Chakravarti, Anthony Ferritto, Lin
    Pan, G P Shrivatsa Bhargav, Dinesh Garg, 和 Avi Sil. 问答的跨度选择预训练。在 Proc. 第58届年会
    ACL, 页码 2773–2782, 2020年7月。'
- en: '[68] Lukas Tuggener, Jürgen Schmidhuber, and Thilo Stadelmann. Is it enough
    to optimize CNN architectures on ImageNet? Frontiers in Computer Science, 4, 2022.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] Lukas Tuggener, Jürgen Schmidhuber, 和 Thilo Stadelmann. 在 ImageNet 上优化
    CNN 架构是否足够？计算机科学前沿, 4, 2022。'
- en: '[69] Jian Shen, Yanru Qu, Weinan Zhang, and Yong Yu. Wasserstein distance guided
    representation learning for domain adaptation. In Proc. AAAI, pages 4058–4065,
    February 2018.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Jian Shen, Yanru Qu, Weinan Zhang, 和 Yong Yu. 基于 Wasserstein 距离的表征学习用于领域适应。在
    Proc. AAAI, 页码 4058–4065, 2018年2月。'
- en: '[70] Wenyuan Dai, Gui-Rong Xue, Qiang Yang, and Yong Yu. Co-clustering based
    classification for out-of-domain documents. In Proc. 13th ACM SIGKDD, KDD ’07,
    pages 210–219, August 2007.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Wenyuan Dai, Gui-Rong Xue, Qiang Yang, 和 Yong Yu. 基于共聚类的外域文档分类。在 Proc.
    第13届 ACM SIGKDD, KDD ’07, 页码 210–219, 2007年8月。'
- en: '[71] Ken Chatfield, Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Return
    of the devil in the details: Delving deep into convolutional nets. In Proc. BMVC
    2014, pages 6.1–6.12, 2014.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Ken Chatfield, Karen Simonyan, Andrea Vedaldi, 和 Andrew Zisserman. 细节中的魔鬼归来：深入卷积网络。在
    Proc. BMVC 2014, 页码 6.1–6.12, 2014年。'
- en: '[72] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.
    In Proc. NeurIPS, volume 27, 2014.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, 和 Yoshua Bengio. 生成对抗网络。在 Proc. NeurIPS, 第27卷,
    2014。'
- en: '[73] Jürgen Schmidhuber. Generative Adversarial Networks are special cases
    of Artificial Curiosity (1990) and also closely related to Predictability Minimization
    (1991). Neural Networks, 127:58–66, 2020.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Jürgen Schmidhuber. 生成对抗网络是人工好奇心（1990年）和预测最小化（1991年）的特殊情况，并且与之密切相关。神经网络,
    127:58–66, 2020年。'
- en: '[74] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, and
    Stefan Wermter. Continual lifelong learning with neural networks: A review. Neural
    Networks, 113:54–71, May 2019.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan, 和 Stefan
    Wermter. 通过神经网络进行持续的终身学习：综述。神经网络, 113:54–71, 2019年5月。'
- en: '[75] Yaqing Wang, Quanming Yao, James T Kwok, and Lionel M Ni. Generalizing
    from a few examples: A survey on few-shot learning. ACM Comput. Surv., 53(3):63:1–63:34,
    June 2020.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Yaqing Wang, Quanming Yao, James T Kwok, 和 Lionel M Ni. 从少量示例中推广：少样本学习的综述。ACM
    Comput. Surv., 53(3):63:1–63:34, 2020年6月。'
- en: '[76] Li Fei-Fei, R. Fergus, and P. Perona. One-shot learning of object categories.
    IEEE TPAMI, 28(4):594–611, April 2006.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Li Fei-Fei, R. Fergus, 和 P. Perona. 对象类别的单次学习。IEEE TPAMI, 28(4):594–611,
    2006年4月。'
- en: '[77] Christoph H Lampert, Hannes Nickisch, and Stefan Harmeling. Learning to
    detect unseen object classes by between-class attribute transfer. In Proc. CVPR,
    pages 951–958, June 2009.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Christoph H Lampert, Hannes Nickisch, 和 Stefan Harmeling. 通过类别间属性转移学习检测未见物体类别。在
    Proc. CVPR, 页码 951–958, 2009年6月。'
- en: '[78] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, and Chen Change Loy. Domain
    generalization: A survey. IEEE TPAMI, 45(4):4396–4415, April 2023.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Kaiyang Zhou, Ziwei Liu, Yu Qiao, Tao Xiang, 和 Chen Change Loy. 域泛化：综述。IEEE
    TPAMI, 45(4):4396–4415, 2023年4月。'
- en: '[79] Gilles Blanchard, Gyemin Lee, and Clayton Scott. Generalizing from several
    related classification tasks to a new unlabeled sample. In Proc. NeurIPS, volume 24,
    2011.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Gilles Blanchard, Gyemin Lee, 和 Clayton Scott. 从多个相关分类任务推广到新的未标记样本。在 Proc.
    NeurIPS, 第24卷, 2011。'
- en: '[80] Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning
    for fast adaptation of deep networks. In Proc. 34th ICML, pages 1126–1135\. PMLR,
    July 2017.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] Chelsea Finn, Pieter Abbeel, 和 Sergey Levine. 面向深度网络快速适应的模型无关元学习。在 Proc.
    第34届 ICML, 页码 1126–1135, PMLR, 2017年7月。'
- en: '[81] Timothy Hospedales, Antreas Antoniou, Paul Micaelli, and Amos Storkey.
    Meta-learning in neural networks: A survey. IEEE TPAMI, 44(09):5149–5169, September
    2022.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Timothy Hospedales、Antreas Antoniou、Paul Micaelli 和 Amos Storkey. 神经网络中的元学习：综述。《IEEE
    TPAMI》, 44(09):5149–5169, 2022年9月。'
- en: '[82] Jianping Gou, Baosheng Yu, Stephen J. Maybank, and Dacheng Tao. Knowledge
    distillation: A survey. Int. J. Comput. Vision, 129(6):1789–1819, June 2021.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Jianping Gou、Baosheng Yu、Stephen J. Maybank 和 Dacheng Tao. 知识蒸馏：综述。《计算机视觉国际期刊》,
    129(6):1789–1819, 2021年6月。'
- en: '[83] Xiao Liu, Fanjin Zhang, Zhenyu Hou, Li Mian, Zhaoyu Wang, Jing Zhang,
    and Jie Tang. Self-supervised learning: Generative or contrastive. IEEE Trans.
    Knowl. Data Eng., 35(1):857–876, January 2023.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Xiao Liu、Fanjin Zhang、Zhenyu Hou、Li Mian、Zhaoyu Wang、Jing Zhang 和 Jie
    Tang. 自监督学习：生成性还是对比性。《IEEE 知识与数据工程汇刊》, 35(1):857–876, 2023年1月。'
- en: '[84] Haoping Bai, Meng Cao, Ping Huang, and Jiulong Shan. Self-supervised semi-supervised
    learning for data labeling and quality evaluation. In NeuIPS. Workshop, November
    2021.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Haoping Bai、Meng Cao、Ping Huang 和 Jiulong Shan. 用于数据标注和质量评估的自监督半监督学习。
    在《NeuIPS》. 研讨会, 2021年11月。'
- en: '[85] Hasan Tercan, Alexandro Guajardo, Julian Heinisch, Thomas Thiele, Christian
    Hopmann, and Tobias Meisen. Transfer-learning: Bridging the gap between real and
    simulation data for machine learning in injection molding. Procedia CIRP, 72:185–190,
    January 2018.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Hasan Tercan、Alexandro Guajardo、Julian Heinisch、Thomas Thiele、Christian
    Hopmann 和 Tobias Meisen. 转移学习：弥合注塑机中真实数据和模拟数据的差距。《CIRP 程序》, 72:185–190, 2018年1月。'
- en: '[86] Nico Görnitz, Marius Kloft, Konrad Rieck, and Ulf Brefeld. Toward supervised
    anomaly detection. JAIR, 46:235–262, February 2013.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] Nico Görnitz、Marius Kloft、Konrad Rieck 和 Ulf Brefeld. 朝着监督式异常检测迈进。《JAIR》,
    46:235–262, 2013年2月。'
- en: '[87] Yuxin Zhang, Yiqiang Chen, Jindong Wang, and Zhiwen Pan. Unsupervised
    deep anomaly detection for multi-sensor time-series signals. IEEE Trans. Knowl.
    Data Eng., 35(2):2118–2132, February 2023.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Yuxin Zhang、Yiqiang Chen、Jindong Wang 和 Zhiwen Pan. 无监督深度异常检测用于多传感器时间序列信号。《IEEE
    知识与数据工程汇刊》, 35(2):2118–2132, 2023年2月。'
- en: '[88] Thilo Stadelmann, Vasily Tolkachev, Beate Sick, Jan Stampfli, and Oliver
    Dürr. Beyond ImageNet: Deep learning in industrial practice. In Applied Data Science:
    Lessons Learned for the Data-Driven Business, pages 205–232\. Springer, 2019.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Thilo Stadelmann、Vasily Tolkachev、Beate Sick、Jan Stampfli 和 Oliver Dürr.
    超越ImageNet：工业实践中的深度学习。在《应用数据科学：数据驱动业务的经验教训》, 页205–232。Springer, 2019年。'
- en: '[89] Douglas M Hawkins. Identification of outliers, volume 11. Springer Netherlands,
    Dordrecht, 1980.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Douglas M Hawkins. 异常值识别，第11卷。Springer 荷兰, 多德雷赫特, 1980年。'
- en: '[90] Haiqi Zhu, Chunzhi Yi, Seungmin Rho, Shaohui Liu, and Feng Jiang. An interpretable
    multivariate time-series anomaly detection method in cyber-physical systems based
    on adaptive mask. IEEE Internet Things J., pages 1–1, 2023.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Haiqi Zhu、Chunzhi Yi、Seungmin Rho、Shaohui Liu 和 Feng Jiang. 基于自适应掩膜的网络物理系统中可解释的多变量时间序列异常检测方法。《IEEE互联网事物期刊》,
    页1–1, 2023年。'
- en: '[91] Sebastian Schmidl, Phillip Wenig, and Thorsten Papenbrock. Anomaly detection
    in time series: A comprehensive evaluation. Proc. VLDB Endow., 15(9):1779–1797,
    May 2022.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Sebastian Schmidl、Phillip Wenig 和 Thorsten Papenbrock. 时间序列中的异常检测：全面评估。《VLDB
    期刊》, 15(9):1779–1797, 2022年5月。'
- en: '[92] Julien Audibert, Pietro Michiardi, Frédéric Guyard, Sébastien Marti, and
    Maria A. Zuluaga. USAD: Unsupervised anomaly detection on multivariate time series.
    In Proc. 26th ACM SIGKDD, KDD ’20, pages 3395–3404, 2020.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Julien Audibert、Pietro Michiardi、Frédéric Guyard、Sébastien Marti 和 Maria
    A. Zuluaga. USAD：多变量时间序列的无监督异常检测。 在《第26届ACM SIGKDD会议论文集》, KDD ’20, 页3395–3404,
    2020年。'
- en: '[93] Pankaj Malhotra, Anusha Ramakrishnan, Gaurangi Anand, Lovekesh Vig, Puneet
    Agarwal, and Gautam Shroff. LSTM-based encoder-decoder for multi-sensor anomaly
    detection, July 2016. arXiv:1607.00148.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Pankaj Malhotra、Anusha Ramakrishnan、Gaurangi Anand、Lovekesh Vig、Puneet
    Agarwal 和 Gautam Shroff. 基于LSTM的编码器-解码器用于多传感器异常检测, 2016年7月。arXiv:1607.00148。'
- en: '[94] Yuanyuan Wei, Julian Jang-Jaccard, Wen Xu, Fariza Sabrina, Seyit Camtepe,
    and Mikael Boulic. LSTM-autoencoder-based anomaly detection for indoor air quality
    time-series data. IEEE Sens. J., 23(4):3787–3800, February 2023.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] Yuanyuan Wei、Julian Jang-Jaccard、Wen Xu、Fariza Sabrina、Seyit Camtepe 和
    Mikael Boulic. 基于LSTM自编码器的室内空气质量时间序列数据异常检测。《IEEE 传感器期刊》, 23(4):3787–3800, 2023年2月。'
- en: '[95] Fanyu Zeng, Mengdong Chen, Cheng Qian, Yanyang Wang, Yijun Zhou, and Wenzhong
    Tang. Multivariate time series anomaly detection with adversarial transformer
    architecture in the Internet of Things. Future Gener. Comput. Syst., 144:244–255,
    July 2023.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] Fanyu Zeng、Mengdong Chen、Cheng Qian、Yanyang Wang、Yijun Zhou 和 Wenzhong
    Tang. 在物联网中使用对抗性变换器架构的多变量时间序列异常检测。《未来计算系统》, 144:244–255, 2023年7月。'
- en: '[96] Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh, and See-Kiong
    Ng. MAD-GAN: Multivariate anomaly detection for time series data with generative
    adversarial networks. In Proc. ICANN 2019, pages 703–716, 2019.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] Dan Li, Dacheng Chen, Baihong Jin, Lei Shi, Jonathan Goh 和 See-Kiong Ng.
    MAD-GAN: 使用生成对抗网络进行多变量时间序列数据的异常检测。见于 ICANN 2019 会议论文集，第 703–716 页，2019 年。'
- en: '[97] Zijian Niu, Ke Yu, and Xiaofei Wu. LSTM-based VAE-GAN for time-series
    anomaly detection. Sensors, 20(13):3738, January 2020.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] Zijian Niu, Ke Yu 和 Xiaofei Wu. 基于 LSTM 的 VAE-GAN 用于时间序列异常检测。Sensors,
    20(13):3738, 2020 年 1 月。'
- en: '[98] Md Abul Bashar and Richi Nayak. TAnoGAN: Time series anomaly detection
    with generative adversarial networks. In Proc. IEEE SSCI, pages 1778–1785, December
    2020.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] Md Abul Bashar 和 Richi Nayak. TAnoGAN: 使用生成对抗网络进行时间序列异常检测。见于 IEEE SSCI
    会议论文集，第 1778–1785 页，2020 年 12 月。'
- en: '[99] Jina Kim, Hyeongwon Kang, and Pilsung Kang. Time-series anomaly detection
    with stacked Transformer representations and 1D convolutional network. EAAI, 120:105964,
    April 2023.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] Jina Kim, Hyeongwon Kang 和 Pilsung Kang. 基于堆叠 Transformer 表示和 1D 卷积网络的时间序列异常检测。EAAI,
    120:105964, 2023 年 4 月。'
- en: '[100] Ailin Deng and Bryan Hooi. Graph neural network-based anomaly detection
    in multivariate time series. Proc. AAAI, 35(5):4027–4035, May 2021.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] Ailin Deng 和 Bryan Hooi. 基于图神经网络的多变量时间序列异常检测。Proc. AAAI, 35(5):4027–4035,
    2021 年 5 月。'
- en: '[101] Chaofan Tang, Lijuan Xu, Bo Yang, Yongwei Tang, and Dawei Zhao. GRU-based
    interpretable multivariate time series anomaly detection in industrial control
    system. Comput. Secur., 127:103094, April 2023.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] Chaofan Tang, Lijuan Xu, Bo Yang, Yongwei Tang 和 Dawei Zhao. 基于 GRU 的可解释多变量时间序列异常检测在工业控制系统中的应用。Comput.
    Secur., 127:103094, 2023 年 4 月。'
- en: '[102] Chaoyue Ding, Shiliang Sun, and Jing Zhao. MST-GAT: A multimodal spatial–temporal
    graph attention network for time series anomaly detection. Inf. Fusion, 89:527–536,
    January 2023.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Chaoyue Ding, Shiliang Sun 和 Jing Zhao. MST-GAT: 一种用于时间序列异常检测的多模态时空图注意网络。Inf.
    Fusion, 89:527–536, 2023 年 1 月。'
- en: '[103] Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali, and Abbes Amira.
    A novel approach for detecting anomalous energy consumption based on micro-moments
    and deep neural networks. Cognit. Comput., 12(6):1381–1401, November 2020.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] Yassine Himeur, Abdullah Alsalemi, Faycal Bensaali 和 Abbes Amira. 一种基于微时刻和深度神经网络的异常能耗检测新方法。Cognit.
    Comput., 12(6):1381–1401, 2020 年 11 月。'
- en: '[104] Yiyuan Yang, Chaoli Zhang, Tian Zhou, Qingsong Wen, and Liang Sun. DCdetector:
    Dual attention contrastive representation learning for time series anomaly detection.
    In Proc. 29th ACM SIGKDD, KDD ’23, pages 3033–3045, August 2023.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] Yiyuan Yang, Chaoli Zhang, Tian Zhou, Qingsong Wen 和 Liang Sun. DCdetector:
    双重注意力对比表示学习用于时间序列异常检测。见于第 29 届 ACM SIGKDD 会议，KDD ’23，第 3033–3045 页，2023 年 8 月。'
- en: '[105] Weihua Li, Ruyi Huang, Jipu Li, Yixiao Liao, Zhuyun Chen, Guolin He,
    Ruqiang Yan, and Konstantinos Gryllias. A perspective survey on deep transfer
    learning for fault diagnosis in industrial scenarios: Theories, applications and
    challenges. Mech. Syst. Signal Process., 167:108487, March 2022.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] Weihua Li, Ruyi Huang, Jipu Li, Yixiao Liao, Zhuyun Chen, Guolin He,
    Ruqiang Yan 和 Konstantinos Gryllias. 关于工业场景中故障诊断的深度迁移学习的视角调查：理论、应用与挑战。Mech. Syst.
    Signal Process., 167:108487, 2022 年 3 月。'
- en: '[106] Jun Ma, Jack CP Cheng, Changqing Lin, Yi Tan, and Jingcheng Zhang. Improving
    air quality prediction accuracy at larger temporal resolutions using deep learning
    and transfer learning techniques. Atmos. Environ., 214:116885, October 2019.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] Jun Ma, Jack CP Cheng, Changqing Lin, Yi Tan 和 Jingcheng Zhang. 使用深度学习和迁移学习技术提高大时间分辨率下的空气质量预测准确性。Atmos.
    Environ., 214:116885, 2019 年 10 月。'
- en: '[107] Ishai Rosenberg, Guillaume Sicard, and Eli David. End-to-end deep neural
    networks and transfer learning for automatic analysis of nation-state malware.
    Entropy, 20(5):390, May 2018.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Ishai Rosenberg, Guillaume Sicard 和 Eli David. 端到端深度神经网络和迁移学习用于国家级恶意软件的自动分析。Entropy,
    20(5):390, 2018 年 5 月。'
- en: '[108] Qiuyue Pan, Yuequan Bao, and Hui Li. Transfer learning-based data anomaly
    detection for structural health monitoring. Struct. Health Monit., 22(5):3077–3091,
    January 2023.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Qiuyue Pan, Yuequan Bao 和 Hui Li. 基于迁移学习的数据异常检测用于结构健康监测。Struct. Health
    Monit., 22(5):3077–3091, 2023 年 1 月。'
- en: '[109] Guannan Li, Liang Chen, Jiangyan Liu, and Xi Fang. Comparative study
    on deep transfer learning strategies for cross-system and cross-operation-condition
    building energy systems fault diagnosis. Energy, 263:125943, January 2023.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Guannan Li, Liang Chen, Jiangyan Liu 和 Xi Fang. 深度迁移学习策略在跨系统和跨操作条件建筑能量系统故障诊断中的比较研究。Energy,
    263:125943, 2023 年 1 月。'
- en: '[110] Oscar Serradilla, Ekhi Zugasti, Julian Ramirez de Okariz, Jon Rodriguez,
    and Urko Zurutuza. Adaptable and explainable predictive maintenance: Semi-supervised
    deep learning for anomaly detection and diagnosis in press machine data. Applied
    Sciences, 11(16):7376, January 2021.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Oscar Serradilla, Ekhi Zugasti, Julian Ramirez de Okariz, Jon Rodriguez
    和 Urko Zurutuza。可适应且可解释的预测性维护：用于压机数据的半监督深度学习进行异常检测和诊断。Applied Sciences, 11(16):7376,
    2021年1月。'
- en: '[111] Jannik Zgraggen, Markus Ulmer, Eskil Jarlskog, Gianmarco Pizza, and Lilach Goren
    Huber. Transfer learning approaches for wind turbine fault detection using deep
    learning. PHME 2021, 6(1):12–12, June 2021.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Jannik Zgraggen, Markus Ulmer, Eskil Jarlskog, Gianmarco Pizza 和 Lilach
    Goren Huber。使用深度学习的风力涡轮机故障检测的迁移学习方法。PHME 2021, 6(1):12–12, 2021年6月。'
- en: '[112] Mahe Zabin, Ho-Jin Choi, and Jia Uddin. Hybrid deep transfer learning
    architecture for industrial fault diagnosis using Hilbert transform and DCNN–LSTM.
    J. Supercomput., 79(5):5181–5200, March 2023.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] Mahe Zabin, Ho-Jin Choi 和 Jia Uddin。用于工业故障诊断的混合深度迁移学习架构，结合Hilbert变换和DCNN–LSTM。J.
    Supercomput., 79(5):5181–5200, 2023年3月。'
- en: '[113] Hasan Tercan, Alexandro Guajardo, and Tobias Meisen. Industrial transfer
    learning: Boosting machine learning in production. In Proc. IEEE 17th INDIN, volume 1,
    pages 274–279, July 2019.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] Hasan Tercan, Alexandro Guajardo 和 Tobias Meisen。工业迁移学习：提升生产中的机器学习。在
    Proc. IEEE 17th INDIN, volume 1, 页码 274–279, 2019年7月。'
- en: '[114] Yannik Lockner, Christian Hopmann, and Weibo Zhao. Transfer learning
    with artificial neural networks between injection molding processes and different
    polymer materials. J. Manuf. Processes, 73:395–408, January 2022.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Yannik Lockner, Christian Hopmann 和 Weibo Zhao。使用人工神经网络在注塑工艺和不同聚合物材料之间进行迁移学习。J.
    Manuf. Processes, 73:395–408, 2022年1月。'
- en: '[115] Sebastian Gellrich, Marc-André Filz, Anna-Sophia Wilde, Thomas Beganovic,
    Alexander Mattheus, Tim Abraham, and Christoph Herrmann. Deep transfer learning
    for improved product quality prediction: A case study of Aluminum gravity die
    casting. Procedia CIRP, 104:912–917, January 2021.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Sebastian Gellrich, Marc-André Filz, Anna-Sophia Wilde, Thomas Beganovic,
    Alexander Mattheus, Tim Abraham 和 Christoph Herrmann。用于改进产品质量预测的深度迁移学习：以铝合金重力铸造为例。Procedia
    CIRP, 104:912–917, 2021年1月。'
- en: '[116] Mustafa Abdallah, Byung-Gun Joung, Wo Jae Lee, Charilaos Mousoulis, Nithin
    Raghunathan, Ali Shakouri, John W. Sutherland, and Saurabh Bagchi. Anomaly detection
    and inter-sensor transfer learning on smart manufacturing datasets. Sensors, 23(1):486,
    January 2023.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Mustafa Abdallah, Byung-Gun Joung, Wo Jae Lee, Charilaos Mousoulis, Nithin
    Raghunathan, Ali Shakouri, John W. Sutherland 和 Saurabh Bagchi。智能制造数据集上的异常检测和传感器间迁移学习。Sensors,
    23(1):486, 2023年1月。'
- en: '[117] Benjamin Maschler, Thi Thu Huong Pham, and Michael Weyrich. Regularization-based
    continual learning for anomaly detection in discrete manufacturing. Procedia CIRP,
    104:452–457, January 2021.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Benjamin Maschler, Thi Thu Huong Pham 和 Michael Weyrich。基于正则化的持续学习用于离散制造中的异常检测。Procedia
    CIRP, 104:452–457, 2021年1月。'
- en: '[118] Jeongyong Park, Bedeuro Kim, and Hyoungshick Kim. MENDEL: Time series
    anomaly detection using transfer learning for industrial control systems. In Proc.
    IEEE BigComp, pages 261–268, February 2023.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] Jeongyong Park, Bedeuro Kim 和 Hyoungshick Kim。MENDEL：使用迁移学习进行工业控制系统的时间序列异常检测。在
    Proc. IEEE BigComp, 页码 261–268, 2023年2月。'
- en: '[119] Peng Liang, Hai-Dong Yang, Wen-Si Chen, Si-Yuan Xiao, and Zhao-Ze Lan.
    Transfer learning for aluminium extrusion electricity consumption anomaly detection
    via deep neural networks. Int. J. Comput. Integr. Manuf., 31(4-5):396–405, April
    2018.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] Peng Liang, Hai-Dong Yang, Wen-Si Chen, Si-Yuan Xiao 和 Zhao-Ze Lan。通过深度神经网络进行铝挤压电力消耗异常检测的迁移学习。Int.
    J. Comput. Integr. Manuf., 31(4-5):396–405, 2018年4月。'
- en: '[120] Abigail Copiaco, Yassine Himeur, Abbes Amira, Wathiq Mansoor, Fodil Fadli,
    Shadi Atalla, and Shahab Saquib Sohail. An innovative deep anomaly detection of
    building energy consumption using energy time-series images. EAAI, 119:105775,
    March 2023.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Abigail Copiaco, Yassine Himeur, Abbes Amira, Wathiq Mansoor, Fodil Fadli,
    Shadi Atalla 和 Shahab Saquib Sohail。使用能源时间序列图像进行建筑能源消费的创新深度异常检测。EAAI, 119:105775,
    2023年3月。'
- en: '[121] Chuqiao Xu, Junliang Wang, Jie Zhang, and Xiaoou Li. Anomaly detection
    of power consumption in yarn spinning using transfer learning. Comput. Ind. Eng.,
    152:107015, February 2021.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] Chuqiao Xu, Junliang Wang, Jie Zhang 和 Xiaoou Li。使用迁移学习对纱线纺纱中的电力消耗进行异常检测。Comput.
    Ind. Eng., 152:107015, 2021年2月。'
- en: '[122] Francesco Di Simone and Francesco Amigoni. Analysis of machine learning
    methods for anomaly detection of power consumption in buildings. Master’s thesis,
    Politecnico di Milano, 2021. Available: https://www.politesi.polimi.it/handle/10589/183344.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] Francesco Di Simone 和 Francesco Amigoni. 用于建筑物电力消耗异常检测的机器学习方法分析。硕士论文，米兰理工大学，2021年。可用:
    [https://www.politesi.polimi.it/handle/10589/183344](https://www.politesi.polimi.it/handle/10589/183344)。'
- en: '[123] Ruei-Jie Hsieh, Jerry Chou, and Chih-Hsiang Ho. Unsupervised online anomaly
    detection on multivariate sensing time series data for smart manufacturing. In
    Proc. IEEE 12th SOCA, pages 90–97, November 2019.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] Ruei-Jie Hsieh, Jerry Chou 和 Chih-Hsiang Ho. 基于多变量传感时间序列数据的无监督在线异常检测用于智能制造。见
    Proc. IEEE 12th SOCA, 页码 90–97, 2019年11月。'
- en: '[124] Oscar Serradilla, Ekhi Zugasti, Jon Rodriguez, and Urko Zurutuza. Deep
    learning models for predictive maintenance: a survey, comparison, challenges and
    prospects. Appl. Intell., 52(10):10934–10964, August 2022.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] Oscar Serradilla, Ekhi Zugasti, Jon Rodriguez 和 Urko Zurutuza. 用于预测维护的深度学习模型：综述、比较、挑战与前景。Appl.
    Intell., 52(10):10934–10964, 2022年8月。'
- en: '[125] Long Wen, Liang Gao, and Xinyu Li. A new deep transfer learning based
    on sparse auto-encoder for fault diagnosis. IEEE Trans. Syst. Man Cybern. Syst.,
    49(1):136–144, January 2019.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] Long Wen, Liang Gao 和 Xinyu Li. 一种基于稀疏自编码器的新深度迁移学习方法用于故障诊断。IEEE Trans.
    Syst. Man Cybern. Syst., 49(1):136–144, 2019年1月。'
- en: '[126] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional
    networks for biomedical image segmentation. In Proc. MICCAI, pages 234–241, 2015.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] Olaf Ronneberger, Philipp Fischer 和 Thomas Brox. U-net: 用于生物医学图像分割的卷积网络。见
    Proc. MICCAI, 页码 234–241, 2015年。'
- en: '[127] Chuang Sun and others. Deep transfer learning based on sparse autoencoder
    for remaining useful life prediction of tool in manufacturing. IEEE Trans. Ind.
    Inf., 15(4):2416–2425, April 2019.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] Chuang Sun 等。基于稀疏自编码器的深度迁移学习用于制造业工具的剩余使用寿命预测。IEEE Trans. Ind. Inf., 15(4):2416–2425,
    2019年4月。'
- en: '[128] Abigail Copiaco, Yassine Himeur, Abbes Amira, Wathiq Mansoor, Fodil Fadli,
    and Shadi Atalla. Exploring deep time-series imaging for anomaly detection of
    building energy consumption. In Proc. IEEE CSDE, pages 1–5, December 2022.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] Abigail Copiaco, Yassine Himeur, Abbes Amira, Wathiq Mansoor, Fodil Fadli
    和 Shadi Atalla. 探索用于建筑能源消耗异常检测的深度时间序列成像。见 Proc. IEEE CSDE, 页码 1–5, 2022年12月。'
- en: '[129] Aya Nabil Sayed, Yassine Himeur, and Faycal Bensaali. Deep and transfer
    learning for building occupancy detection: A review and comparative analysis.
    EAAI, 115:105254, October 2022.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] Aya Nabil Sayed, Yassine Himeur 和 Faycal Bensaali. 用于建筑占用检测的深度学习和迁移学习：综述与比较分析。EAAI,
    115:105254, 2022年10月。'
- en: '[130] Markus Goldstein and Seiichi Uchida. A comparative evaluation of unsupervised
    anomaly detection algorithms for multivariate data. PloS one, 11(4):1–31, April
    2016.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] Markus Goldstein 和 Seiichi Uchida. 对多变量数据的无监督异常检测算法的比较评估。PloS one, 11(4):1–31,
    2016年4月。'
- en: '[131] Mateusz Buda, Atsuto Maki, and Maciej A. Mazurowski. A systematic study
    of the class imbalance problem in convolutional neural networks. Neural Networks,
    106:249–259, October 2018.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Mateusz Buda, Atsuto Maki 和 Maciej A. Mazurowski. 卷积神经网络中的类别不平衡问题的系统研究。Neural
    Networks, 106:249–259, 2018年10月。'
- en: '[132] Kimberly A Smith-Jentsch, Eduardo Salas, and Michael T Brannick. To transfer
    or not to transfer? Investigating the combined effects of trainee characteristics,
    team leader support, and team climate. J. Appl. Psychol, 86:279–92, May 2001.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] Kimberly A Smith-Jentsch, Eduardo Salas 和 Michael T Brannick. 转移还是不转移？研究受训者特征、团队领导支持和团队气候的综合影响。J.
    Appl. Psychol, 86:279–92, 2001年5月。'
- en: '[133] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. Domain adaptation for
    large-scale sentiment classification: a deep learning approach. In Proc. 28th
    ICML, pages 513–520, June 2011.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Xavier Glorot, Antoine Bordes 和 Yoshua Bengio. 大规模情感分类的领域适应：一种深度学习方法。见
    Proc. 28th ICML, 页码 513–520, 2011年6月。'
- en: '[134] Wenqian Jiang, Yang Hong, Beitong Zhou, Xin He, and Cheng Cheng. A GAN-based
    anomaly detection approach for imbalanced industrial time series. IEEE Access,
    7:143608–143619, 2019.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Wenqian Jiang, Yang Hong, Beitong Zhou, Xin He 和 Cheng Cheng. 一种基于GAN的用于不平衡工业时间序列的异常检测方法。IEEE
    Access, 7:143608–143619, 2019年。'
- en: '[135] Ian J. Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining
    and harnessing adversarial examples. In Proc. ICLR, 2015.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Ian J. Goodfellow, Jonathon Shlens 和 Christian Szegedy. 解释和利用对抗样本。见 Proc.
    ICLR, 2015年。'
- en: '[136] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. SMOTE:
    Synthetic minority over-sampling technique. JAIR, 16:321–357, June 2002.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] N. V. Chawla, K. W. Bowyer, L. O. Hall 和 W. P. Kegelmeyer. SMOTE: 合成少数过采样技术。JAIR,
    16:321–357, 2002年6月。'
- en: '[137] Muhammad Fazal Ijaz, Ganjar Alfian, Muhammad Syafrudin, and Jongtae Rhee.
    Hybrid prediction model for type 2 diabetes and hypertension using DBSCAN-based
    outlier detection, synthetic minority over sampling technique (SMOTE), and random
    forest. Applied Sciences, 8(8):1325, August 2018.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] 穆罕默德·法扎尔·伊贾兹、甘贾尔·阿尔菲安、穆罕默德·谢夫鲁丁 和 钟泰·李。使用基于 DBSCAN 的异常检测、合成少数类过采样技术（SMOTE）和随机森林的
    2 型糖尿病和高血压混合预测模型。《应用科学》，8(8):1325，2018 年 8 月。'
- en: '[138] Sohrab Mokhtari, Alireza Abbaspour, Kang K Yen, and Arman Sargolzaei.
    A machine learning approach for anomaly detection in industrial control systems
    based on measurement data. Electronics, 10(4):407, January 2021.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] 索赫拉布·莫赫塔里、阿里雷扎·阿巴斯普尔、康·K·燕 和 阿尔曼·萨戈尔扎伊。基于测量数据的工业控制系统异常检测的机器学习方法。《电子学》，10(4):407，2021
    年 1 月。'
- en: '[139] Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland,
    Laura Gustafson, Tete Xiao, Spencer Whitehead, Alexander C. Berg, Wan-Yen Lo,
    Piotr Dollar, and Ross Girshick. Segment anything. In Proc. ICCV, pages 4015–4026,
    2023.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] 亚历山大·基里洛夫、埃里克·敏顿、尼基拉·拉维、汉子·毛、克洛伊·罗朗、劳拉·古斯塔夫森、特特·肖、斯宾塞·怀特黑德、亚历山大·C·伯格、罗万·洛、皮奥特·美元
    和 罗斯·吉尔希克。随便分割。在 ICCV 会议论文集中，页码 4015–4026，2023 年。'
- en: '[140] Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and
    Björn Ommer. High-resolution image synthesis with latent diffusion models. In
    Proc. CVPR, pages 10684–10695, June 2022.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] 罗宾·隆巴赫、安德烈亚斯·布拉特曼、多米尼克·洛伦茨、帕特里克·埃瑟 和 比约恩·奥默。使用潜在扩散模型进行高分辨率图像合成。在 CVPR
    会议论文集中，页码 10684–10695，2022 年 6 月。'
- en: '[141] Athanasios Vlontzos, Bernhard Kainz, and Ciarán M. Gilligan-Lee. Estimating
    categorical counterfactuals via deep twin networks. Nat. Mach. Intell., 5(2):159–168,
    February 2023.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] 阿塔纳西奥斯·弗隆佐斯、伯恩哈德·凯因茨 和 西阿兰·M·吉利根-李。通过深度双胞胎网络估计类别反事实。《自然·机器智能》，5(2):159–168，2023
    年 2 月。'
- en: '[142] Shiqiang Wang, Tiffany Tuor, Theodoros Salonidis, Kin K. Leung, Christian
    Makaya, Ting He, and Kevin Chan. When edge meets learning: Adaptive control for
    resource-constrained distributed machine learning. In Proc. IEEE INFOCOM 2018,
    pages 63–71, April 2018.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] 王世强、蒂芙尼·图尔、泰奥多罗斯·萨隆尼斯、金·K·梁、克里斯蒂安·马克雅、廷·赫 和 凯文·陈。当边缘遇上学习：资源受限的分布式机器学习的自适应控制。在
    IEEE INFOCOM 2018 会议论文集中，页码 63–71，2018 年 4 月。'
- en: '[143] Mohammad Mohammadi Amiri and Deniz Gündüz. Machine learning at the wireless
    edge: Distributed stochastic gradient descent over-the-air. In Proc. IEEE ISIT,
    pages 1432–1436, July 2019.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] 穆罕默德·穆罕默迪·阿米里 和 丹尼斯·君杜兹。无线边缘的机器学习：空中分布式随机梯度下降。在 IEEE ISIT 会议论文集中，页码 1432–1436，2019
    年 7 月。'
- en: '[144] Weifeng Ge and Yizhou Yu. Borrowing treasures from the wealthy: Deep
    transfer learning through selective joint fine-tuning. In Proc. IEEE CVPR, pages
    10–19, July 2017.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] 魏峰·格 和 余轶舟。从富人那里借来宝贵资源：通过选择性联合微调进行深度迁移学习。在 IEEE CVPR 会议论文集中，页码 10–19，2017
    年 7 月。'
- en: '[145] Jiehui Xu, Haixu Wu, Jianmin Wang, and Mingsheng Long. Anomaly Transformer:
    Time series anomaly detection with association discrepancy. In ICLR, October 2021.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] 谢辉、吴海旭、王建民 和 龙铭生。异常变换器：具有关联差异的时间序列异常检测。在 ICLR 会议上，2021 年 10 月。'
- en: '[146] Ioana Pintilie, Andrei Manolache, and Florin Brad. Time series anomaly
    detection using diffusion-based models, November 2023. arXiv:2311.01452.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] 伊欧娜·平提利、安德烈·马诺拉切 和 弗洛林·布拉德。使用基于扩散的模型进行时间序列异常检测，2023 年 11 月。arXiv:2311.01452。'
- en: '[147] Thilo Stadelmann, Tino Klamt, and Philipp H Merkt. Data centrism and
    the core of Data Science as a scientific discipline. Archives of Data Science,
    Series A, 8(2), March 2022.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] 提洛·斯塔德尔曼、蒂诺·克拉姆特 和 菲利普·H·梅尔克特。数据中心主义与数据科学核心作为科学学科。《数据科学档案》，系列 A，8(2)，2022
    年 3 月。'
- en: '[148] Paul-Philipp Luley, Jan Milan Deriu, Peng Yan, Gerrit A. Schatte, and
    Thilo Stadelmann. From concept to implementation: the data-centric development
    process for AI in industry. In Proc. 10th IEEE SDS, 2023.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] 保罗·菲利普·卢雷、扬·米兰·德里乌、彭岩、杰里特·A·沙特 和 提洛·斯塔德尔曼。从概念到实施：行业中 AI 的数据中心开发过程。在第十届
    IEEE SDS 会议论文集中，2023 年。'
- en: '[149] Zac Yung-Chun Liu, Shoumik Roychowdhury, Scott Tarlow, Akash Nair, Shweta
    Badhe, and Tejas Shah. AutoDC: Automated data-centric processing. In NeuIPS. Workshop,
    November 2021. Available: https://nips.cc/virtual/2021/38244.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] 扎克·永春·刘、肖米克·罗伊乔杜里、斯科特·塔洛、阿卡什·奈尔、什韦塔·巴德 和 提贾斯·沙。AutoDC：自动化数据中心处理。在 NeuIPS
    研讨会，2021 年 11 月。可用网址： https://nips.cc/virtual/2021/38244。'
- en: '[150] Daniel Kang, Nikos Arechiga, Sudeep Pillai, Peter D. Bailis, and Matei
    Zaharia. Finding label and model errors in perception data with learned observation
    assertions. In Proc. ACM SIGMOD, pages 496–505, June 2022.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] 丹尼尔·康、尼科斯·阿雷希加、苏迪普·皮莱、彼得·D·贝利斯 和 马特伊·扎哈里亚。在感知数据中通过学习观察断言来发现标签和模型错误。在
    ACM SIGMOD 会议论文集中，页码 496–505，2022 年 6 月。'
- en: '[151] Milad Salem, Shayan Taheri, and Jiann Shiun Yuan. Anomaly generation
    using generative adversarial networks in host-based intrusion detection. In Proc.
    IEEE UEMCON, pages 683–687, November 2018.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] Milad Salem, Shayan Taheri 和 Jiann Shiun Yuan。使用生成对抗网络进行基于主机的入侵检测中的异常生成。发表于
    IEEE UEMCON 会议，页面 683–687，2018 年 11 月。'
