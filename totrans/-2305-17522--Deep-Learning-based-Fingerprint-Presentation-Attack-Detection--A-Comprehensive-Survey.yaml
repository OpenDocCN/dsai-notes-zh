- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:39:25'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2305.17522] Deep Learning based Fingerprint Presentation Attack Detection:
    A Comprehensive Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.17522](https://ar5iv.labs.arxiv.org/html/2305.17522)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning based Fingerprint Presentation Attack Detection: A Comprehensive
    Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hailin Li [hailin.li@ntnu.no](mailto:hailin.li@ntnu.no) [1234-5678-9012](https://orcid.org/1234-5678-9012
    "ORCID identifier")  and  Raghavendra Ramachandra [0000-0003-0484-3956](https://orcid.org/0000-0003-0484-3956
    "ORCID identifier") [raghavendra.ramachandra@ntnu.no](mailto:raghavendra.ramachandra@ntnu.no)
    Institute of Information Security and Communication Technology (IIK), Norwegian
    University of Science and Technology (NTNU)GjøvikNorway2816(2018; 20 February
    2007; 12 March 2009; 5 June 2009)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The vulnerabilities of fingerprint authentication systems have raised security
    concerns when adapting them to highly secure access-control applications. Therefore,
    Fingerprint Presentation Attack Detection (FPAD) methods are essential for ensuring
    reliable fingerprint authentication. Owing to the lack of generation capacity
    of traditional handcrafted based approaches, deep learning-based FPAD has become
    mainstream and has achieved remarkable performance in the past decade. Existing
    reviews have focused more on hand-cratfed rather than deep learning-based methods,
    which are outdated. To stimulate future research, we will concentrate only on
    recent deep-learning-based FPAD methods. In this paper, we first briefly introduce
    the most common Presentation Attack Instruments (PAIs) and publicly available
    fingerprint Presentation Attack (PA) datasets. We then describe the existing deep-learning
    FPAD by categorizing them into contact, contactless, and smartphone-based approaches.
    Finally, we conclude the paper by discussing the open challenges at the current
    stage and emphasizing the potential future perspective.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning, fingerprint presentation attack detection^†^†copyright: acmcopyright^†^†journalyear:
    2018^†^†doi: XXXXXXX.XXXXXXX^†^†conference: Make sure to enter the correct conference
    title from your rights confirmation emai; June 03–05, 2018; Woodstock, NY^†^†price:
    15.00^†^†isbn: 978-1-4503-XXXX-X/18/06^†^†ccs: Computing methodologies Biometrics'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Biometric verification is widely deployed in numerous access control applications,
    including border control, forensic science, smartphone access, attendance systems,
    etc. Biometric systems can be designed using either physiological (e.g. fingerprint,
    face, iris), behavioral (e.g. gait, keystroke, voice) or a combination of both.
    Among various physiological traits, the face, iris, and fingerprint have dominated
    the majority of applications because of their reliability and accuracy in performance,
    which can be attributed to the uniqueness of these biometric characteristics.
    However, the fingerprint biometrics is one of the traditional biometric characteristics
    in various application considering the reliability of finger patterns over long
    period of time and the representation and matching of the features that can achieve
    billion fingerprint comparison in a single second with high accuracy (AFI, [2003](#bib.bib2)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/093fe68cdb31b3817d8538e3e46f5d59.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1\. Publications of FPAD in recent years obtained through Google scholar
    search with keywords: “fingerprint spoof detection”, “fingerprint presentation
    attack detection”, and “fingerprint liveness detection”.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fingerprint images are captured using contact and contactless sensing among
    which the contact-based sensing is used predominantly. Contact-based fingerprint
    sensing includes optical, capacitive, and ultrasonic sensors that are available
    as standalone devices and/or integrated devices in smartphones. Optical fingerprint
    scanners are the oldest type of capturing fingerprint patterns. These sensors
    typically have a very high number of diodes per inch to capture the fine details
    of the finger and the optical camera comes with a finite resolution. Capacitive
    sensors use arrays of small capacitor circuits to capture the fingerprint data.
    Since capacitors store electrical charges, connecting them to conductive plates
    on the scanner’s surface allows them to track the details of a fingerprint. Recently,
    ultrasonic sensors have been introduced to scan fingerprints, particularly in
    smartphones. These sensors employ an ultrasonic transmitter that can send the
    pulse against the finger and record the echoes used to construct the fingerprint.
    Further, Scanning for extended periods allows for additional depth data to be
    captured, resulting in a 3D fingerprint. There are two types of contactless sensing:
    (a) use of custom industrial cameras (b) off-the-shelf smartphone cameras used
    to capture finger photos. The use of custom cameras for contactless capture will
    allow designers to include multi-spectral cameras and other sophisticated cameras
    to ensure reliable verification with resilience to presentation attacks. However,
    fingerprint capture using contactless sensing introduces additional challenges,
    such as uncontrolled poses, low-quality fingerprints, environmental noises, and
    degraded performance.'
  prefs: []
  type: TYPE_NORMAL
- en: The widespread deployment of the Fingerprint Recognition System (FRS) has raised
    concerns about the system being attacked, and the attacker may maliciously gain
    access to the fingerprint system. FRS can be attacked in two ways (a) direct attack
    and (b) indirect attacks. Direct attacks typically target the sensors of the FRS
    such that a Presentation Attack Instrument (PAI) is presented to the sensor to
    gain access. An indirect attack aims to attack the biometric subsystem components
    to modify the functionality. Compared to direct attacks, indirect attacks require
    special skills and knowledge of the biometric system to successfully gain access
    to the FRS. Therefore, direct attacks on FRS have been used extensively in real-life
    scenarios. One real-life example of hacking the FRS using direct attacks, mainly
    on the national population registry, was reported in (Hac, [2022](#bib.bib5)).
    The Aadhaar-enabled Payment System (AePS) is spoofed to withdraw money from various
    victims. Attackers achieved this by collecting the fingerprints of the victims
    from registry papers that have ink-prints of fingerprints. The attackers then
    created a polymer fingerprint attack instrument that was used to withdraw money
    through the AePS. Therefore, the detection of presentation attacks is of paramount
    importance in ensuring the security of the FRS system to facilitate reliable verification.
  prefs: []
  type: TYPE_NORMAL
- en: '| Paper Title / Reference | Year | Deep Learning included | Modality & Hardware
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Survey on fingerprint liveness detection (Al-Ajlan, [2013](#bib.bib6)) |
    2013 | No | Contact based |'
  prefs: []
  type: TYPE_TB
- en: '| Presentation attack detection methods for fingerprint recognition systems:
    a survey (Sousedik and Busch, [2014](#bib.bib111)) | 2014 | No | Contact based
    |'
  prefs: []
  type: TYPE_TB
- en: '| A Survey on Antispoofing Schemes for Fingerprint Recognition Systems (Marasco
    and Ross, [2014](#bib.bib75)) | 2014 | No | Contact based |'
  prefs: []
  type: TYPE_TB
- en: '| Survey on Fingerprint Spoofing, Detection Techniques and Databases(Kulkarni
    and Patil, [2015](#bib.bib63)) | 2015 | No | Contact based |'
  prefs: []
  type: TYPE_TB
- en: '| Security and Accuracy of Fingerprint-Based Biometrics: A Review (Yang et al.,
    [2019](#bib.bib122)) | 2019 | Few | Contact based |'
  prefs: []
  type: TYPE_TB
- en: '| A Survey on Unknown Presentation Attack Detection for Fingerprint (Singh
    et al., [2021](#bib.bib110)) | 2021 | Few | Contact based, SWIR, LSCI |'
  prefs: []
  type: TYPE_TB
- en: '| Robust anti-spoofing techniques for fingerprint liveness detection: A Survey
    (Habib and Selwal, [2021](#bib.bib40)) | 2021 | Few | Contact based |'
  prefs: []
  type: TYPE_TB
- en: '| FinPAD: State-of-the-art of fingerprint presentation attack detection mechanisms,
    taxonomy and future perspectives (Sharma and Selwal, [2021](#bib.bib108)) | 2021
    | Yes,¡30 | Contact based, SWIR |'
  prefs: []
  type: TYPE_TB
- en: '| Fingerprint Liveness Detection Schemes: A Review on Presentation Attack (Ametefe
    et al., [2022](#bib.bib7)) | 2022 | Yes, ¡30 | Contact based, SWIR, LSCI, smartphone
    |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Learning for Fingerprint Presentation Attack Detection: A Survey (Ours)
    | 2023 | Comprehensive (¿50) | Contact based, SWIR, LSCI, FTIR, OCT, smartphone
    |'
  prefs: []
  type: TYPE_TB
- en: Table 1\. A summary of existing surveys in FPAD
  prefs: []
  type: TYPE_NORMAL
- en: 'Presentation Attack Detection (PAD), a.k.a anti-spoofing method, has been widely
    investigated for fingerprint biometrics, resulting in several PAD techniques.
    The progress of Fingerprint PAD (FPAD) techniques is shown in Figure [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Deep Learning based Fingerprint Presentation Attack
    Detection: A Comprehensive Survey") which illustrates the increased interest of
    researchers in developing FPAD techniques. Early works on developing FPAD techniques
    were based on hand-crafted features, in which texture-based features (Local Binary
    Patterns (LBP), Binarized Statistical Image Features (BSIF), etc.) were widely
    employed in designing FPAD. However, owing to the limitations of the texture features
    to generalize across different types of PAIs, researchers have started to investigate
    FPAD using deep learning. Further, the importance of FPAD also resulted in the
    development of the competition platform LivDet (Liv, [2022](#bib.bib4)) which
    allows participants to submit FPAD algorithms for independent evaluation.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The exponential growth of the FPAD algorithms over the years has resulted in
    several survey papers, as listed in Table [1](#S1.T1 "Table 1 ‣ 1\. Introduction
    ‣ Deep Learning based Fingerprint Presentation Attack Detection: A Comprehensive
    Survey"). However, existing surveys are limited to non-deep learning approaches
    and thus do not consider the recent progress in which deep learning approaches
    are prominent. Hence, in this paper, we are motivated to present a comprehensive
    review of deep learning-based fingerprint presentation attack detection, in which
    we discuss recent progress, competition, performance evaluation metrics, and future
    work. The main contributions of this study are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We present the comprehensive survey on deep-learning based FPAD techniques for
    both contact and contact less fingerprint. Comprehensive literature survey together
    with the taxonomy and compare these approaches on the different attributes of
    design.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We present a comprehensive survey on the PAI that are widely employed in both
    contact and contactless fingerprint biometrics.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We outline the main challenges and the potential future work for reliable fingerprint
    detection.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of the paper is organized as follows. Section [2](#S2 "2\. Fingerprint
    Recognition Systems (FRS) ‣ Deep Learning based Fingerprint Presentation Attack
    Detection: A Comprehensive Survey") presents the pipeline of a fingerprint recognition
    system and indicates how the FPAD system can be adjusted in the overall system.
    Section [3](#S3 "3\. Fingerprint Presentation Attack Instrument (PAI) ‣ Deep Learning
    based Fingerprint Presentation Attack Detection: A Comprehensive Survey") provides
    a comprehensive report on the different types of PAIs for both contact and contactless
    fingerprints. Section [4](#S4 "4\. Existing Datasets for Fingerprint PAD ‣ Deep
    Learning based Fingerprint Presentation Attack Detection: A Comprehensive Survey")
    introduces the most common publicly available FPAD dataset. Section [5](#S5 "5\.
    Deep learning based Fingerprint presentation attack detection ‣ Deep Learning
    based Fingerprint Presentation Attack Detection: A Comprehensive Survey") presents
    a comprehensive survey of fingerprint presentation attack detection based on deep
    learning. Then, Section [6](#S6 "6\. Performance Evaluation Metrics ‣ Deep Learning
    based Fingerprint Presentation Attack Detection: A Comprehensive Survey") includes
    the most common PAD performance evaluation metrics from the ISO standard and the
    LivDet competition. Section [7](#S7 "7\. Future Work ‣ Deep Learning based Fingerprint
    Presentation Attack Detection: A Comprehensive Survey") discusses the open challenges
    and the potential future research directions. Finally, we conclude this review
    in section [8](#S8 "8\. Conclusion ‣ Deep Learning based Fingerprint Presentation
    Attack Detection: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Fingerprint Recognition Systems (FRS)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/150fdca0bcd88ded4db1011e9b301f48.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Block diagram of fingerprint verification system with PAD
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [2](#S2.F2 "Figure 2 ‣ 2\. Fingerprint Recognition Systems (FRS) ‣ Deep
    Learning based Fingerprint Presentation Attack Detection: A Comprehensive Survey")
    shows the block diagram of the fingerprint verification system. Given a fingerprint
    image, the signal processing unit performs various operations, including data
    preprocessing, quality checking, feature extraction, and template creation. Fingerprint
    feature extraction techniques can be level 1 (pattern), level 2 (minutiae points),
    and level 3 (pores and ridge shape). The common and successful fingerprint features
    that are widely deployed in commercial applications are based on Level 2 features.
    Final decisions are made using a comparator that can compare the enrolled fingerprint
    with the probe fingerprint image to output the comparison score. The comparison
    score was then compared with the preset threshold to make the final decision.
    The PAD system can be integrated into a fingerprint recognition system, either
    parallel or serial to the fingerprint comparator. In a parallel system, both the
    PAD and comparator perform processing independently to obtain the decisions that
    are combined to make the final decision. However, in a serial system, the PAD
    and fingerprint comparator work in a sequential manner in which the fingerprint
    is first processed through the PAD unit. If the output of the PAD unit indicates
    a bona fide, then the fingerprint template is passed through the comparator to
    make the final decision. For more detailed information on the fingerprint systems,
    readers can refer to (Maltoni et al., [2009](#bib.bib74)) (Maltoni et al., [2022](#bib.bib73)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Fingerprint Presentation Attack Instrument (PAI)
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The success of a presentation attack on fingerprint systems depends on the
    high-quality generation of PAI. Figure [3](#S3.F3 "Figure 3 ‣ 3\. Fingerprint
    Presentation Attack Instrument (PAI) ‣ Deep Learning based Fingerprint Presentation
    Attack Detection: A Comprehensive Survey") shows the taxonomy of the existing
    PAI types commonly studied in the fingerprint literature (Maltoni et al., [2009](#bib.bib74)).
    Available PAI can be broadly categorized into two main types: (a) digital generation
    and (b) artificial fabrication. Digital attack generation is performed using a
    computer program in which the attacks are synthetically generated using deep learning
    methods (Karras et al., [2019](#bib.bib55)) or the custom algorithms (Bontrager
    et al., [2018](#bib.bib11)) (Gajawada et al., [2019](#bib.bib27)) (Engelsma et al.,
    [2022](#bib.bib22)) (Kim et al., [2019](#bib.bib56)). Digital attacks can be used
    as injection attacks and/or to generate physical artifacts that can be used as
    presentation attacks. Examples of digital attacks include synthetic fingerprint
    attacks (Grosz and Jain, [2022](#bib.bib38)), master print (Roy et al., [2018](#bib.bib101))
    and morphing attacks (Makrushin et al., [2021](#bib.bib72)) (Ferrara et al., [2016](#bib.bib25)).
    The artificial fabrication method uses the target fingerprint impression top to
    generate a physical artifact that can be used as a presentation attack. Artificial
    fabrication methods can be broadly categorized into 2D/3D printing and gummy fingers.
    The 2D/3D print, in which the physical artifacts are printed fingerprints, can
    be used as presentation attacks (Espinoza et al., [2011](#bib.bib24)) (Kanich
    et al., [2018](#bib.bib53)) (Prabakaran and Pillay, [2020](#bib.bib95)). The gummy
    fingerprints are made of various materials (Gelatin, Play-doh, Silicone, etc.)
    that may contain a specific fingerprint template and have shown potential risks
    to the FRS (Chugh and Jain, [2019](#bib.bib18)). Table [2](#S3.T2 "Table 2 ‣ 3\.
    Fingerprint Presentation Attack Instrument (PAI) ‣ Deep Learning based Fingerprint
    Presentation Attack Detection: A Comprehensive Survey") lists the different features
    of the Digital and Artificial fabrication types of PAI generation.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/29f2d213d1957b92b3307da369c23b22.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. Taxonomy of fingerprint Presentation Attack Instrument (PAI)
  prefs: []
  type: TYPE_NORMAL
- en: '| Digital PAI | Artificial Fabrication PAI |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Generate high-quality attack instrument | Generate near high-quality attack
    instrument |'
  prefs: []
  type: TYPE_TB
- en: '| High attack potential | Moderate attack potential |'
  prefs: []
  type: TYPE_TB
- en: '| Able to attack multiple identities in single | Mostly designed to attack
    single identity |'
  prefs: []
  type: TYPE_TB
- en: '| Requires more technical knowledge | No need of more technical knowledge |'
  prefs: []
  type: TYPE_TB
- en: '| High-computation cost | Low computation cost |'
  prefs: []
  type: TYPE_TB
- en: '| Low-cost generation | High-cost generation |'
  prefs: []
  type: TYPE_TB
- en: '| Very challenging to detect | Easy to detect particularly with the multi-spectral
    sensors |'
  prefs: []
  type: TYPE_TB
- en: Table 2\. Comparison of different PAI generation techniques
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/127e278fe32708ab0b23fb732eace8d4.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Examples of PAIs (taken from (Chugh and Jain, [2019](#bib.bib18)))
  prefs: []
  type: TYPE_NORMAL
- en: 'The common PAI examples are shown in figure [4](#S3.F4 "Figure 4 ‣ 3\. Fingerprint
    Presentation Attack Instrument (PAI) ‣ Deep Learning based Fingerprint Presentation
    Attack Detection: A Comprehensive Survey"). In accordance with the experiments
    under the fingerprint verification application, the digital synthetic fingerprint
    shows the high attack potential against the FRS.'
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Existing Datasets for Fingerprint PAD
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'A large-scale dataset is required to achieve better results when using deep-learning-based
    methods during both the training and testing phases. In this section, we summarize
    the publicly available FPAD datasets containing the data amount, subject numbers,
    bona fide/attack amount, and used PAI species. The most common datasets were from
    the Fingerprint Liveness Detection Competition (LivDet) series from 2009 to 2021\.
    Readers can refer to a review of the LivDet series (Micheletto et al., [2022](#bib.bib81))
    for detailed information on the LivDet challenge. In the first edition of the
    LivDet 2009 dataset, three optical scanners, Crossmatch, Identix, and Biometrika,
    were included with gelatin, silicone, and play-doh as spoof materials. In LivDet
    2011, four sub-datasets were based on four different optical scanners: Biometrika,
    Digital Persona, ItalData, and Sagem. In addition, more PAIs such as Silgum, Ecoflex,
    Wood Glue, and Latex are included than LivDet 2009\. The first non-optical scanner
    was introduced in the competition, in which the spoof materials were replenished
    with body doubling and modasil. In LivDet 2015, with the raised concern of FPAD
    methods against unseen attacks, the competition included some unknown materials
    for evaluation in the test dataset. Additionally, liquid Ecoflex and a two-component
    silicone rubber(RTV) are included in the Green Bit, Biometrika, and Digital Persona
    datasets, whereas the silicone rubber OOMOO is included in the Crossmatch dataset.
    In LivDet 2017, the competition focused on the impact of the FPAD based on user-specific
    effects and operator skills in fabricating replicas. In the training set, the
    spoofing is made of wood glue, Ecoflex, and body double, whereas gelatin, latex,
    and liquid Ecoflex compose the test set in order to stimulate the completely unseen
    scenario. Furthermore, two sets of people with different manufacturing spoofing
    abilities were involved in spoofing. In contrast to the previous editions, some
    subjects were included in the training and testing datasets to explore the impact
    of user-specific effects. LivDet 2019 utilized the same scanners as in the previous
    edition, but presented multi-material combinations, both of different consistency
    and of different nature for the first time. LivDet 2021 only consists of two scanners,
    GreenBit and Dermalog, in which the consensual approach and the new pseudo-consensual
    method, ScreenSpoof, are included. Novel materials RProFast, Elmers glue, gls20,
    and RPro30\. were chosen for the fakes. In the most recent LivDet 2023, four datasets
    correspond to two known sensors, Green Bit and Dermalog, and two unknown capture
    devices.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides LivDet datasets, there are also many proposed methods that include
    custom datasets which is publicly available. In Tsinghua dataset (Jia et al.,
    [2007](#bib.bib49)), the Capacitive device Veridicom is utilized as the capture
    device and the attack samples are created using Silicone. The samples are acquired
    from 15 volunteers from Tsinghua University. Two fingers are captured for each
    participant and ten image sequences are recorded for each real finger. 47 fake
    finger are manufactured with ten image sequences for each finger. BSL dataset
    (Antonelli et al., [2006](#bib.bib9)) are collected at the Biometric System Laboratory
    of the University of Bologna which contains more subjects and samples using four
    different PAIs. For each of 45 volunteers, the thumb and forefinger of the right
    hand with 10 image sequences are recorded. Instead of making whole 3D fingers,
    the obtained manufactures are focused on the fingertip area. ATVS dataset utilize
    slilicone and play-Doh as materials and involved 17 subjects. Two scanners are
    used in Precise Biometrics dataset comprised of 100 subjects and 500 attack samples
    produced using five different materials. In Precise Biometrics Spoof-Kit(PBSKD)
    (Chugh et al., [2018](#bib.bib17)), 900 spoof fingerprint images are fabricated
    using 10 different types of spoof materials. Another dataset MSU-FPAD is also
    proposed in (Chugh et al., [2018](#bib.bib17)), there are up to 9000 live samples
    and 10500 spoof samples included using these two readers and 4 different spoof
    fabrication materials. Recently, Kolberg et.al (Kolberg et al., [2023](#bib.bib60))
    publish a new dataset COLFISPOOF based on contactless fingerphoto which contains
    72 different PAI species. All the fingerprints for the PAIs are generated using
    fingerprint synthetic algorithms. The details of each dataset are demonstrated
    in Table [3](#S4.T3 "Table 3 ‣ 4\. Existing Datasets for Fingerprint PAD ‣ Deep
    Learning based Fingerprint Presentation Attack Detection: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | No. of Subjects | Bona fide samples | Attack samples | PAI type
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Tsinghua (Jia et al., [2007](#bib.bib49)) | 15 | 300 | 470 | Silicone |'
  prefs: []
  type: TYPE_TB
- en: '| BSL (Antonelli et al., [2006](#bib.bib9)) | 45 | 900 | 400 | Silicone, gelatin,
    latex, wood glue |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2009 (Marcialis et al., [2009](#bib.bib78)) | 254 | 5500 | 5500 |
    Gelatine, Silicone and Play-Doh |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2011 (Yambay et al., [2012](#bib.bib121)) | 200 | 3000 | 3000 | Gelatine,
    Silgum, Ecoflex, Wood Glue, Play-Doh, Silicone and Latex |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2013 (Ghiani et al., [2013b](#bib.bib33)) | 225 | 8000 | 8000 | Gelatine,
    Wood Glue, Latex, Ecoflex and Modasil |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2015 (Mura et al., [2015](#bib.bib83)) | 100 | 4500 | 5948 | Body
    Double, EcoFlex, Play-Doh, Gelatine, Latex, Wood Glue and Liquid Ecoflex |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2017 (Mura et al., [2018](#bib.bib84)) | 150 | 8099 | 9685 | Gelatine,
    Wood Glue, Latex, Ecoflex, Body Double and Liquid Ecoflex |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2019 (Orrù et al., [2019](#bib.bib89)) | NA | 6029 | 6936 | Gelatine,
    Wood Glue, Latex, Ecoflex, Body Double and Liquid Ecoflex |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2021 (Casula et al., [2021a](#bib.bib13)) | 66 | 10700 | 11740 | GLS20,
    Body Double, Mix 1, ElmersGlue, and RFast30 |'
  prefs: []
  type: TYPE_TB
- en: '| LivDet 2023 | 25 | 5000 | 3000 | NA |'
  prefs: []
  type: TYPE_TB
- en: '| ATVS-FFp (Galbally et al., [2011](#bib.bib28)) | 17 | 816 | 816 | Silicone,
    Play-Doh |'
  prefs: []
  type: TYPE_TB
- en: '| Precise Biometrics Spoof-Kit (Chugh et al., [2018](#bib.bib17)) | NA | 1000
    | 900 | Ecoflex, Gelatine, Latex, Crayola, Wood glue, 2D print |'
  prefs: []
  type: TYPE_TB
- en: '| MSU-FPAD (Chugh et al., [2018](#bib.bib17)) | NA | 9000 | 10500 | Ecoflex,
    2D Print-Matte Paper, Play-Doh and 2D Print (Transparency) |'
  prefs: []
  type: TYPE_TB
- en: '| COLFISPOOF (Kolberg et al., [2023](#bib.bib60)) | NA | NA | 7200 | Print
    out and Replay |'
  prefs: []
  type: TYPE_TB
- en: Table 3\. Most utilized and publicly available datasets
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Deep learning based Fingerprint presentation attack detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss the Fingerprint PAD (FPAD) algorithms that are presented
    for contact, contactless, and smartphone-based fingerprint sensing. The FPAD aims
    to detect whether the given fingerprint image is bona fide or a presentation attack.
    FPAD techniques can be broadly classified into two main categories (a) Hardware-based
    approaches and (b) Software-based approaches. The hardware-based approaches are
    designed to extract the liveness cues that require explicit (or dedicated) sensors
    to be integrated into the conventional contact fingerprint biometric system. Some
    of the widely used liveness measures include the capture of blood flow (Drahansky
    et al., [2006](#bib.bib21)), Electro-tactile (Yau et al., [2008](#bib.bib123)),
    and pulse Oximetry (Reddy et al., [2008](#bib.bib99)) to detect whether the fingerprint
    is live or not. Over the past few years, new expensive sensors like optical coherence
    tomography (OCT) have evolved. OCT is an imaging technique that allows some of
    the subsurface characteristics of the skin to be imaged and extracts relevant
    features of multi-layered tissues up to a maximum depth of 3 mm (Cheng and Larin,
    [2007](#bib.bib15)) (Bossen et al., [2010](#bib.bib12)) (Liu and Buma, [2010](#bib.bib69)).
    Further, several contactless fingerprint capture devices like multi-spectral and
    3D capture devices can also inherently capture the signature of liveness.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Software-based approach refers to algorithms to detect whether the presented
    fingerprint is bona fide or a presentation attack, irrespective of the capture
    device. Software-based FPAD can be further divided broadly into two types handcrafted-based
    and deep learning. Handcrafted-based method refers to the conventional feature
    representation that includes techniques used to extract features like gradients,
    texture, micro-textures, etc. The handcrafted-based approach is applied to contact-based
    fingerprint images mostly. From the fingerprint images, micro-textural features
    that can be computed using Scale-invariant feature transform (SIFT) (Lowe, [1999](#bib.bib70)),
    Binarized Statistical Image Features (BSIF) (Kannala and Rahtu, [2012](#bib.bib54)),
    Local Binary Pattern (LBP) (Guo et al., [2010](#bib.bib39)), Local Phase Quantization
    (LPQ) (Ojansivu and Heikkilä, [2008](#bib.bib88)). Many hand-crafted based approaches
    like (Ghiani et al., [2012](#bib.bib32)) (Ghiani et al., [2013a](#bib.bib31))
    (Gragnaniello et al., [2013](#bib.bib36)) (Zhang et al., [2014](#bib.bib127))
    (Gragnaniello et al., [2015](#bib.bib37)) achieved promised performance in recent
    years. However, handcrafted-based approaches may have a limitation in that the
    extraction process becomes difficult due to variations in the acquired fingerprint
    image quality. These challenges are tackled using Deep Neural Network (DNN) terms
    such as deep learning, which hierarchically learns deep-level features from the
    images. With the rapid development of graphical processing units training a large-scale
    model has become achievable. In 2012, Krizhevsky et al. (Krizhevsky et al., [2012](#bib.bib62))
    trained a network to classify the 1.2 million high-resolution images in the ImageNet
    LSVRC-2010 contest into 1000 different classes which achieved a huge success,
    which started a revolution in the computer vision field. Afterward, training a
    deep convolutional neural network (CNN) has dominated the image classification
    tasks in various applications. Figure [5](#S5.F5 "Figure 5 ‣ 5\. Deep learning
    based Fingerprint presentation attack detection ‣ Deep Learning based Fingerprint
    Presentation Attack Detection: A Comprehensive Survey") shows the taxonomy of
    the deep learning based algorithms that are developed for fingerprint PAD on three
    different types of sensing that are discussed below:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/781e6b5b9ecabd4774281a3eb866fd29.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Taxonomy of deep learning based fingerprint presentation attack detection
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Contact based FPAD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Benefited from the rapid development of robust CNN architectures (Simonyan
    and Zisserman, [2014](#bib.bib109)) (He et al., [2016](#bib.bib41)) (Huang et al.,
    [2017](#bib.bib43)) as well as the advanced regularization techniques (Srivastava
    et al., [2014](#bib.bib113)) (Ioffe and Szegedy, [2015](#bib.bib46)), researchers
    have paid more attention to employing deep neural networks to detect fingerprint
    attacks reliably. Instead of extracting texture features through handcrafted-based
    descriptors, deep-learning-based approaches can learn deep features that directly
    map fingerprint inputs to spoof detection. The traditional CNN architecture comprises
    convolutional layers and a pooling layer that convolves several filters to map
    the input images to deep-learnable features. The extracted features can be further
    fed into a fully connected layer for classification tasks. As shown in Figure
    [5](#S5.F5 "Figure 5 ‣ 5\. Deep learning based Fingerprint presentation attack
    detection ‣ Deep Learning based Fingerprint Presentation Attack Detection: A Comprehensive
    Survey"), deep-learning-based methods can be generally divided into two categories.
    Supervised learning is a straightforward way to determine bona fide and PA as
    a binary classification task. However, these approaches may not be generalizable
    to unseen domain attacks (i.e., unknown presentation attacks). Many researchers
    have considered generalized deep-learning models that can achieve domain generalization
    to enhance the generalization capacity against unseen PA types.'
  prefs: []
  type: TYPE_NORMAL
- en: Initially, Nogueira et al. (Nogueira et al., [2014](#bib.bib86)) first introduced
    a conventional network for fingerprint feature extraction. They trained a Support
    Vector Machine (SVM) classifier to detect presentation attacks based on CNN deep
    features and LBP features. To improve the classifier’s performance, several data
    augmentation techniques such as frequency filtering, contrast equalization, and
    Region Of Interest (ROI) filtering have been applied. Through comparison, the
    experiments indicate high classification accuracy of CNN model which leads to
    a new direction that inspires more researchers to concentrate on using Deep learning
    based approaches on FPAD tasks. However, the feature extraction and classification
    tasks are designed into two different parts so that the model is not optimized
    simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/047c8c0d5b703467e052a62233ba9b98.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. Deep learning frameworks for Contact based FPAD. (a) End to end deep
    learning model using cross-entropy loss. (b) Transfer learning/fine tuning based
    FPAD approach. (c) FPAD using generalized deep learning model
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.1\. End-to-end deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As shown in figure [6](#S5.F6 "Figure 6 ‣ 5.1\. Contact based FPAD ‣ 5\. Deep
    learning based Fingerprint presentation attack detection ‣ Deep Learning based
    Fingerprint Presentation Attack Detection: A Comprehensive Survey"), end-to-end
    deep learning models were trained to automatically outperform classification tasks.
    The feature representation of the fingerprint image was extracted from the convolutional
    layer and passed into the fully connected layer to calculate the liveness probability
    using the softmax function. Table LABEL:tab:end_to_end_DL presents a short description
    of existing end-to-end deep learning techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: In 2015, Wang et al. (Wang et al., [2015](#bib.bib119)) divide the input labeled
    fingerprint images into $32\times 32$ pixel nonoverlapped patches and pass them
    into the CNN model for training. Then, the authors adopt a voting strategy to
    integrate the labels of all the patches to finally determine the result. Similarly,
    Park et al. (Park et al., [2016](#bib.bib92)) propose extending Wang’s work to
    reduce the processing time. Instead of extracting patches from the entire image,
    the authors indicate that it is more efficient to extract patches from the effective
    fingerprint area. Thus, after extracting patches with normal probability positions
    of segmented fingerprint regions, the authors train those patches with CNN and
    make the decision using a voting strategy to make the classification. Menotti
    et al. (Menotti et al., [2015](#bib.bib80))evaluate the effectiveness of the proposed
    newly Derived CNN architecture for spoofing detection terms using SpoofNet. Kim
    et.al (Kim et al., [2016](#bib.bib57)) present an FPAD method based on a Deep
    Belief Network (DBN) with a series of constrained Boltzmann machines connected,
    which learns features from training samples and determines the liveness of fingerprints.
    The DBN is trained in two steps. Firstly, it is trained on a set of examples without
    supervision from the first layer to the penultimate layer to learn the reconstruction
    probabilistically of its inputs. Then the model will be further trained using
    labeled data to perform the classification.
  prefs: []
  type: TYPE_NORMAL
- en: With an increasing number of publicly datasets set released, Chugh et.al (Chugh
    et al., [2017](#bib.bib16)) utilize Inception-v3 CNN (Szegedy et al., [2016](#bib.bib114))
    model implemented using TF-Slim library with a replacement from multiple-class
    softmax layer to two-unit layer for the two-class problem. Then, the model is
    trained with local patches extracted around the fingerprint minutiae since local
    patches around these minutiae are able to provide significant cues to distinguish
    a spoof fingerprint from live fingerprints. Along with score-level average fusion,
    this method evaluates several experiments such as intra-sensors and the same material,
    intra-sensor and cross-material, cross-sensor, and cross-dataset scenarios to
    consider both known and unknown attacks, which demonstrated a good average classification
    error (ACE). In the next work, Chugh et al. (Chugh et al., [2018](#bib.bib17))
    further presented a Fingerprint Spoof Buster based on the MobileNet-v1 (Howard
    et al., [2017](#bib.bib42)) model trained using local patches that are centered
    and aligned around minutia points, and defined a global Spoofness Score to integrate
    the local Spoofness Score to determine the PA.
  prefs: []
  type: TYPE_NORMAL
- en: However, FPAD methods based on CNN suffer from generalization and high computational
    costs. The selection of PA materials used in training (known PAs) directly affects
    the performance against unknown PAs. Some materials (e.g. EcoFlex) has been reported
    to be easier to detect than others (e.g. Silgum) (Chugh et al., [2018](#bib.bib17)).
    Hence, to further investigate the better representation of different PA materials,
    a new dataset namely MSU-FPAD v2.0 which combines the MSU-FPAD v1.0 and Precise
    Biometrics Spoof kit (Chugh et al., [2018](#bib.bib17)) was presented in (Chugh
    and Jain, [2019](#bib.bib18)). Specifically, the database is constructed using
    12 different PAIs. Then, the leave-one-out protocol is adopted; one PAI is excluded
    from the training set at every iteration and utilizes the 3D t-SNE technique to
    visualize the characteristics. Through experiments, Silicone, 2D Paper, Play Doh,
    Gelatin, Latex Body Paint, and Monster Liquid Latex are observed to cover the
    entire feature space around the Bona fide. Furthermore, it is considered a challenge
    to integrate existing deep learning-based algorithms with millions of parameters
    into an embedded or mobile device. Nguyen et.al (Nguyen et al., [2018](#bib.bib85))
    present the FPAD technique following the architecture of the Fire module of SqueezeNet
    (Iandola et al., [2016](#bib.bib45)) and introduce the Gram Matrix (Gatys et al.,
    [2015](#bib.bib29)) to form the structure of the basis of the proposed fPADnet.
    This model only contains 0.3 million parameters, which is 2.4 times smaller than
    that of the original SqueezeNet. Similarly, Park et al. (Park et al., [2019](#bib.bib91))
    introduced a fully convolutional neural network that uses the fire module of SqueezeNet
    as the foundation. The model can interfere with images of any size since it has
    no fully connected layer. The model takes the patch extracted from the input image
    as input and outputs three values that show the probabilities of the classes (live,
    false, and background) to which the patch belongs. Additional experiments with
    different input patch sizes at $32\times 32$, $48\times 48$, where $32\times 32$
    and $64\times 64$ are evaluated to identify the optimum patch size to achieve
    the highest detection accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4\. Existing contact based FPAD using end to end deep learning
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| Nogueira et.al (Nogueira et al., [2014](#bib.bib86)) | 2014 | CNN | SVM |
    Extract the deep features using CNN and trained the SVM to classify the liveness
    |'
  prefs: []
  type: TYPE_TB
- en: '| Wang et.al (Wang et al., [2015](#bib.bib119)) | 2015 | CNN | Binary CE loss
    | Patch based method with voting strategy |'
  prefs: []
  type: TYPE_TB
- en: '| Menotti et.al (Menotti et al., [2015](#bib.bib80)) | 2015 | CNN | Binary
    CE loss | Propose a Derived CNN terms as SpoofNet |'
  prefs: []
  type: TYPE_TB
- en: '| Kim et.al (Kim et al., [2016](#bib.bib57)) | 2016 | Deep Belief Network (DBN)
    | Mean squared error loss | Propose a DBN based method for liveness detection
    |'
  prefs: []
  type: TYPE_TB
- en: '| Park et.al (Park et al., [2016](#bib.bib92)) | 2016 | CNN | Binary CE loss
    | Extract the patches from the effective fingerprint area to train the CNN model
    |'
  prefs: []
  type: TYPE_TB
- en: '| Lazimul and Binoy (Lazimul and Binoy, [2017](#bib.bib64)) | 2017 | CNN |
    Binary CE loss | Enhance the fingerprint image through several steps and train
    with CNN model |'
  prefs: []
  type: TYPE_TB
- en: '| Jang et.al (Jang et al., [2017](#bib.bib48)) | 2017 | CNN | Binary CE loss
    | Utilize the histogram equalization for contrast enhancement and train the CNN
    model with divided blocks |'
  prefs: []
  type: TYPE_TB
- en: '| Chugh et.al (Chugh et al., [2017](#bib.bib16)) | 2017 | Inception-v3 CNN
    | Binary CE loss | Use local patches extracted around fingerprint minutiae to
    train the Inception-v3 model with a slightly modification of last layer |'
  prefs: []
  type: TYPE_TB
- en: '| Chugh et.al (Chugh et al., [2018](#bib.bib17)) | 2018 | MobileNet-v1 | Binary
    CE loss | Define a global Spoofness Score to integrate the local patch based on
    minutia points to determine the liveness |'
  prefs: []
  type: TYPE_TB
- en: '| Pala (Pala and Bhanu, [2017](#bib.bib90)) | 2017 | CNN | Triples loss | A
    triplet convolutional network is proposed |'
  prefs: []
  type: TYPE_TB
- en: '| Jung and Heo (Jung and Heo, [2018](#bib.bib51)) | 2018 | CNN | Squared Regression
    Error(SRE) | Employ SRE layer instead of CE loss layer as loss function |'
  prefs: []
  type: TYPE_TB
- en: '| Nguyen et.al (Nguyen et al., [2018](#bib.bib85)) | 2018 | SqueezeNet | Binary
    CE loss | A lightweight model which optimize the SqueezeNet using designed Gram-Matrix
    |'
  prefs: []
  type: TYPE_TB
- en: '| Chugh and Jain (Chugh and Jain, [2019](#bib.bib18)) | 2019 | CNN | Binary
    CE loss | Adopte leave-one-out protocol to exclude one PAI out of 12 from the
    training set every iteration to visualize the characteristics and find out which
    PAI achieves similar feature space as bona fide |'
  prefs: []
  type: TYPE_TB
- en: '| Park et.al (Park et al., [2019](#bib.bib91)) | 2019 | SqueezeNet | Three
    class CE loss | A Tiny Fully Convolutional Network without fully connected layer
    which can fit any size of input |'
  prefs: []
  type: TYPE_TB
- en: '| Yuan et.al (Yuan et al., [2019a](#bib.bib124)) | 2019 | CNN | Binary CE loss
    | Between the last convolutional layer and the fully connected layer, an extra
    Image Scale Equalization(ISE) layer is added to preserve the texture information
    and maintain image resolution |'
  prefs: []
  type: TYPE_TB
- en: '| Jung et.al (Jung et al., [2019](#bib.bib52)) | 2019 | CNN | Binary CE loss
    | Design a Livness Map CNN (LM-CNN) to map the probe and template images to a
    stacked feature vector and use a Template-Probe CNN to decide the spoofness |'
  prefs: []
  type: TYPE_TB
- en: '| Yuan et.al (Yuan et al., [2019b](#bib.bib125)) | 2019 | ResNet | Binary CE
    loss | Introduce the ResNet with adaptive learning to tackle the gradient disappearance
    issue |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et.al (Zhang et al., [2019](#bib.bib129)) | 2019 | ResNet | Binary
    CE loss | Propose a lightweight framework that makes use of the specifically designed
    robust Residual block against fingerprint spoofing |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et.al (Zhang et al., [2020](#bib.bib128)) | 2020 | DenseNet | Binary
    CE loss | Adopt the attention mechanism instead of Global Average Pooling (GAP)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Jian et.al (Jian et al., [2020](#bib.bib50)) | 2020 | DenseNet | Binary CE
    loss | Introduce the genetic algorithm to find the optimal DenseNet structure
    for fingerprint liveness detection |'
  prefs: []
  type: TYPE_TB
- en: '| Liu et.al (Liu et al., [2021b](#bib.bib68)) | 2021 | Mobile Net V3 | Binary
    CE loss | Global–local model-based with rethinking strategy |'
  prefs: []
  type: TYPE_TB
- en: '| Rai et.al (Rai et al., [2023](#bib.bib97)) | 2023 | MoblieNet V1 | Support
    Vector Classifier (SVC) | Use MoblieNet V1 network for feature extraction and
    trained with loss from SVC |'
  prefs: []
  type: TYPE_TB
- en: 'Image enhancement before detection has been well studied in deep-learning-based
    FPAD. Jang et al. (Jang et al., [2017](#bib.bib48)) utilized histogram equalization
    for contrast enhancement to improve the recognition rate of fingerprint images.
    The fingerprint image is divided into several non-overlapped blocks and trained
    with a CNN model for classification. The Majority Voting System (MVS) is applied
    to totalize the votes of all sub-blocks and make the final decision. Similarly,
    Lazimul and Binoy (Lazimul and Binoy, [2017](#bib.bib64)) propose to enhance a
    fingerprint image through six steps: Image Segmentation, Image Local Normalization,
    Orientation Estimation, Ridge frequency Estimation, Gabor Filtering, Image Binarization/thinning.
    Subsequently, a CNN model is used to train the data. Typically, cross-entropy
    is the most common loss function used to measure the difference between two probability
    distributions and is widely applied in classification tasks. Pala (Pala and Bhanu,
    [2017](#bib.bib90)) introduces a triplet loss (Schroff et al., [2015](#bib.bib106))
    that encourages dissimilar pairs to be distant from any similar pair by at least
    a certain margin value. A triplet network takes two patches of one class and one
    patch of the other to measure the inter- and intra-class distances supervised
    by triplet loss. Furthermore, Jung and Heo (Jung and Heo, [2018](#bib.bib51))
    introduce a new CNN architecture that employs a Squared Regression Error(SRE)
    layer instead of a cross-entropy loss layer. This method allows setting a threshold
    as a liveness probability to adjust the model, which provides an accuracy trade-off
    option to fit different application scenarios. Furthermore, Jung et al. (Jung
    et al., [2019](#bib.bib52)) extend their previous work by introducing two CNNs
    terms as Livness Map CNN (LM-CNN) and Template-Probe CNN (TP-CNN). The LM-CNN
    performs pre-computation during fingerprint registration to map the fingerprint
    image to a $32\times 32$ feature map. Then, the output map from the probe fingerprint
    and template fingerprint will be stacked as a $2\times 32\times 32$ liveness map,
    which will be fed into the TP-CNN for the final decision. Most CNN models require
    a fixed length of input images because of the restriction of the fully connected
    layer. Thus, the fingerprint dataset requires additional preprocessing such as
    cropping or scaling, which leads to information loss. To address this problem,
    Yuan et al. (Yuan et al., [2019a](#bib.bib124)) propose an improved DCNN model
    with Image Scale Equalization (ISE) to preserve texture information and maintain
    image resolution. Between the last convolutional layer and the fully connected
    layer, an extra ISE layer is added to obtain the feature map from the convolutional
    layer and convert the image of any scale into a fixed-length vector to fix the
    fully connected layer.'
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, Yuan et.al (Yuan et al., [2019b](#bib.bib125)) first introduced
    the Deep Residual Network (He et al., [2016](#bib.bib41)) for FPAD. The authors
    designed a novel ROI extraction technique to remove the noise caused by background
    noise. Then, the gradient disappearance in the DCNN and learning parameters falling
    into local optimal value issues are tackled by applying a Deep Residual Network
    with adaptive learning. Owing to the concern of potential low generalization capability
    against unknown attack detection, a texture enhancement based on a Local Gradient
    Pattern (LGP) is introduced to highlight the difference between a bona fide sample
    and an attack sample to achieve a better generalization. Zhang et.al (Zhang et al.,
    [2019](#bib.bib129)) proposed a lightweight framework that makes use of the specifically
    designed robust Residual block (He et al., [2016](#bib.bib41)) against fingerprint
    spoofing. Silm-ResCNN consists of nine modified residual blocks. The authors make
    some changes by inserting a dropout layer into each pair of convolutional layers
    and removing the activation function (ReLU) of the second convolutional kernel
    to make the model more generalized. In another specific type, the $1\times 1$
    convolutional layer is replaced with max pooling, along with a padding zero channel.
    Therefore, the overall structure of The Slim-ResCNN consists of Conv1, Conv2,
    Conv3 (Conv3$\_$1, Conv3$\_$2), and Conv4 (Conv4$\_$1, Conv4$\_$2), followed by
    global average pooling (Avg$\_$Pool) and a final classification layer. The model
    will take the extracted local patches as input and the cross-entropy is used as
    the loss function. It should be noted that this method achieves the top performance
    in the Fingerprint Liveness Detection Competition 2017 (Mura et al., [2018](#bib.bib84)),
    with an overall accuracy of 95.25%. Zhang et.al (Zhang et al., [2020](#bib.bib128))
    discussed the limitation of Global Average Pooling against fingerprint spoofing
    and overcome it by adopting the attention mechanism. A lightweight model with
    only 0.48 million parameters was designed. Its blocks are designed where the residual
    path and densely connected path are incorporated, which benefits from DenseNet
    (Huang et al., [2017](#bib.bib43)) and ResNet (He et al., [2016](#bib.bib41)).
    Jian et al. (Jian et al., [2020](#bib.bib50)) point out the limitations of DenseNet
    based architecture (Zhang et al., [2020](#bib.bib128)) and optimize the model
    by adopting the genetic algorithm (Xie and Yuille, [2017](#bib.bib120)). Liu et.al
    (Liu et al., [2021b](#bib.bib68)) proposed a framework based on the rethinking
    strategy. The model consists of three modules, a global PAD module, a rethinking
    module, and a local PAD module. Firstly, the global PAD module receives the entire
    image as input and then predicts the global spoofness score. The rethinking module
    then takes the activation map to highlight the important regions for PAD through
    class activation mapping(CAM). Finally, these regions will be cropped and passed
    into the local PAD module to refine the prediction of the global PAD module. Recently,
    Rai et.al (Rai et al., [2023](#bib.bib97)) adopt MoblieNet V1 as a feature extractor
    due to the capacity of utilizing depth-wise separable convolution operation instead
    of traditional convolution operation, then the network is trained by the loss
    obtained from SVC. Furthermore, a comprehensive comparison among many existing
    approaches indicates that the proposed method, namely MoSFPAD, achieved state-of-the-art
    results.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.2\. FPAD using transfer learning/fine tuning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'However, end-to-end deep learning-based FPAD achieved a notable improvement
    in classification accuracy. The size of the public fingerprint training set is
    insufficient to optimize a CNN model, which typically requires a large number
    of samples for training. On one hand, many researchers include data augmentation
    to apply small variations to the original data to extend the dataset. On the other
    hand, transfer learning and fine-tuning are normal ways to tackle the issue of
    small datasets. As shown in figure [6](#S5.F6 "Figure 6 ‣ 5.1\. Contact based
    FPAD ‣ 5\. Deep learning based Fingerprint presentation attack detection ‣ Deep
    Learning based Fingerprint Presentation Attack Detection: A Comprehensive Survey"),
    transfer learning/fine-tuning is a technique that does not train a deep learning
    model from scratch. Instead, transfer learning uses the representations learned
    by a pre-trained model to extract meaningful features and outperform classification
    with a new classifier. Differently, fine tuning technique is to unfreeze the weights
    corresponding to the top few layers of a pre-trained model based on general sets
    of images and ”fine-tune” the higher-order feature to make them more relevant
    for the specific task. Table [8](#S5.T8 "Table 8 ‣ 5.2.1\. Anomaly detection ‣
    5.2\. Contactless based FPAD ‣ 5\. Deep learning based Fingerprint presentation
    attack detection ‣ Deep Learning based Fingerprint Presentation Attack Detection:
    A Comprehensive Survey") presents a quick overview of the existing transfer-learning-based
    FPAD.'
  prefs: []
  type: TYPE_NORMAL
- en: Nogueira et al. (Nogueira et al., [2016](#bib.bib87)) extend their work (Nogueira
    et al., [2014](#bib.bib86)) by utilizing transfer learning on a pre-trained VGG
    (Simonyan and Zisserman, [2014](#bib.bib109)) and AlexNet (Krizhevsky et al.,
    [2012](#bib.bib62)) model and fine-tuned it using a fingerprint liveness detection
    dataset. By comparing four different models (two CNN models pre-trained with natural
    images and fine-tuned with fingerprint images, one CNN-Random model that uses
    only random filter weights drawn from a Gaussian distribution, and a traditional
    LBP-SVM model), the authors elaborate on the superiority of pre-trained CNNs on
    FPAD fields. Furthermore, Toosi et al. (Toosi et al., [2017b](#bib.bib118)) extract
    a set of small-sized patches that contain foreground pixels only, and pass those
    patches into a pre-trained AlexNet (Krizhevsky et al., [2012](#bib.bib62)) with
    a further training step that exploits features from fingerprint datasets. Similarly,
    Toosi et al. (Toosi et al., [2017a](#bib.bib117)) extract small-sized foreground
    patches of raw images and fine-tuned pre-trained AlexNet (Krizhevsky et al., [2012](#bib.bib62))
    and VGG19 (Simonyan and Zisserman, [2014](#bib.bib109)) models. Similarly, Ametefe
    et al. (S Ametefe et al., [2021](#bib.bib102)) utilize transfer learning using
    DenseNet(DenseNet201) (Huang et al., [2017](#bib.bib43)) which also achieves promising
    results compared with VGG and AlexNet features.
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Nogueira et.al (Nogueira et al., [2016](#bib.bib87)) | 2016 | AlexNet, VGG
    | Binary CE loss | Utilize pre-trained model and fine-tuned using fingerprint
    liveness detection dataset |'
  prefs: []
  type: TYPE_TB
- en: '| Toosi et.al (Toosi et al., [2017b](#bib.bib118)) | 2017 | AlexNet | Binary
    CE loss | Extract a set of small-sized patches containing only foreground pixels
    to fine-tune a pre-trained model |'
  prefs: []
  type: TYPE_TB
- en: '| Toosi et.al (Toosi et al., [2017a](#bib.bib117)) | 2017 | AlexNet, VGG19
    | Binary CE loss | Utilize transfer learning on two pre-trained CNN models |'
  prefs: []
  type: TYPE_TB
- en: '| Ametefe et.al (S Ametefe et al., [2021](#bib.bib102)) | 2021 | DenseNet |
    Binary CE loss | Utilize deep transfer learning on densenet201 network |'
  prefs: []
  type: TYPE_TB
- en: Table 5\. Existing contact based FPAD methods using transfer learning/fine-tuning
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.3\. Generalized deep learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To improve the generalization capacity of the model, many researchers have
    considered applying a generalized model to transfer one domain to another using
    an adversarial learning-based model. The goal here is to address the generalizability
    of the FPAD techniques by performing domain transformation between the PAI and
    bona fide samples. Table [6](#S5.T6 "Table 6 ‣ 5.1.3\. Generalized deep learning
    ‣ 5.1\. Contact based FPAD ‣ 5\. Deep learning based Fingerprint presentation
    attack detection ‣ Deep Learning based Fingerprint Presentation Attack Detection:
    A Comprehensive Survey") presents a quick overview of existing generalizable FPAD
    techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Pereira et.al (Pereira et al., [2020](#bib.bib93)) proposed a novel model based
    on adversarial training, which consists of three subnetworks: (i) an encoder network
    that maps the input image into a latent space, (ii) a task-classifier network
    that maps the latent representation to the corresponding attack and bona fide
    probabilities, (iii) a species-classifier network that aims to predict the PAI
    species according to the attack latent representation. The species classifier
    is trained to minimize classification loss among the PAI species, whereas the
    task classifier and encoder are trained to minimize the classification loss between
    attacks and bona fide samples while trying to keep the PAI species classification
    close to random guessing. To further improve the generalization performance of
    the detector against spoofs made from materials that were not seen during training.
    A style-transfer-based wrapper, namely, a Universal Material Generator (UMG) is
    proposed to reliably detect the FPAD (Chugh and Jain, [2020](#bib.bib19)). The
    UMG is able to generate synthetic spoof images corresponding to unknown spoof
    materials by transferring the style (texture) characteristics between fingerprint
    images of known spoofing materials. Then, the synthesized images provide the model
    with more generalization capability to detect spoofs made of unknown materials.
    Sandouka et al. (Sandouka et al., [2021a](#bib.bib105)) propose a Unified Generative
    Adversarial Networks(UGAN) that can translate a single generator learning mapping
    across multiple domains. Subsequently, a share-weighted fusion layer acts as a
    classifier that fuses the output from all translated domains to determine the
    detection result. Similarly, Sandouka et al. (Sandouka et al., [2021b](#bib.bib104))
    further utilize a CycleGAN (Zhu et al., [2017](#bib.bib131)) network for domain
    adoption, which transforms the source domain to the target domain. In contrast
    to their previous work, a transformer model is employed to take a sequence of
    patches of the feature map as the input. The outputs are then concatenated and
    projected linearly to obtain a final output that is further fed into a fully connected
    layer for the classification task. This work further improved the performance
    rather than (Sandouka et al., [2021a](#bib.bib105)). Furthermore, Lee et al. (Lee
    et al., [2022](#bib.bib65)) proposed a generalization improvement method that
    utilizes style transfer to transfer the material styles between fingerprints.
    Liu et al. (Liu et al., [2022](#bib.bib66)) recently proposed a channel-wise feature
    denoising model. They extract the ’noise’ channels from the feature map by evaluating
    each channel of the image. Then, the interference from those channels is suppressed,
    and a PA-adaptation loss is designed to align the feature domain of the fingerprint.
    This method achieves promising results on the LivDet 2017 (Mura et al., [2018](#bib.bib84))
    dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Pereira et.al (Pereira et al., [2020](#bib.bib93)) | 2020 | Species-invariant
    neural network | Adversarial loss, species-transfer loss | An adversarial learning
    approach to improve the capacity to detect the unseen attack |'
  prefs: []
  type: TYPE_TB
- en: '| Chugh and Jain (Chugh and Jain, [2020](#bib.bib19)) | 2020 | Universal Material
    Generator (UMG) | Adversarial loss, style loss, content loss | A style transfer
    based approach that transfer texture characteristics between fingerprint images
    of known materials to unknown materials |'
  prefs: []
  type: TYPE_TB
- en: '| Sandouka et.al (Sandouka et al., [2021a](#bib.bib105)) | 2021 | Generative
    Adversarial Networks, EfficientNet V2 (Tan and Le, [2021](#bib.bib115)) | Adversarial
    loss, reconstruction loss, domain classification loss | A Unified Generative Adversarial
    Networks(UGAN) that can translate a single generator learning the mapping across
    multiple domains |'
  prefs: []
  type: TYPE_TB
- en: '| Sandouka et.al (Sandouka et al., [2021b](#bib.bib104)) | 2021 | Transformers
    and CycleGAN | Adversarial loss, cycle consistency loss | Utilize a CycleGAN to
    transform from the source domain to the target domain |'
  prefs: []
  type: TYPE_TB
- en: '| Lee et.al (Lee et al., [2022](#bib.bib65)) | 2022 | CycleGAN and CNN | Adversarial
    loss, binary CE loss | Transform fingerprint image from an untrained material
    style to a trained material style using CycleGAN |'
  prefs: []
  type: TYPE_TB
- en: '| Liu et.al (Liu et al., [2022](#bib.bib66)) | 2022 | MoblieNet V2 | PA-Adaptation
    loss, binary CE loss | Propose a channel-wise feature denoising model |'
  prefs: []
  type: TYPE_TB
- en: Table 6\. Existing Generalized deep learning FPAD methods
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Contactless based FPAD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2a5e1c14e99e3904acdac6f369e93b4a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. Examples of contactless based fingerprint system using sensor-specific
    approaches
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional fingerprint images suffer from presentation attacks since the texture
    features of spoofing are typically inconspicuous. Additionally, the development
    of new synthetic materials brings more challenges to the generalization ability
    of the current models. However, the texture of the spoofing fingerprint surface
    can be visible through a multi-spectrum capture device or even a smartphone camera.
    A demonstration of multi-spectrum capture device is shown in Figure [7](#S5.F7
    "Figure 7 ‣ 5.2\. Contactless based FPAD ‣ 5\. Deep learning based Fingerprint
    presentation attack detection ‣ Deep Learning based Fingerprint Presentation Attack
    Detection: A Comprehensive Survey"). Hussein et.al (Hussein et al., [2018](#bib.bib44))
    propose a patch-based CNN model that takes multi-spectral short-wave infrared
    (SWIR) imaging and laser speckle contrast imaging (LSCI) images as input to classify
    the skin or no skin. Furthermore, Mirzaalian et al. (Mirzaalian et al., [2019](#bib.bib82))
    utilize LSCI images and evaluate four different models: the model proposed by
    (Hussein et al., [2018](#bib.bib44)) terms as baseN, adding residual connections
    between every two 2D convolution layers of the BaseN terms as ResN, introducing
    inception module terms as IncpN, and a double-layer long short-term memory (LSTM)-based
    network. The obtained result shows that LSTM based approach achieves the best
    performance. Kolberg et al. (Kolberg et al., [2020](#bib.bib61)) analyze the long
    short-term memory (LSTM) network in comparison with different CNN models on a
    fingerprint image captured by a 1310 nm laser device. The obtained experimental
    results indicate the advancement of the LSTM model compared with the CNN models.
    Furthermore, Spinoulas et al. (Spinoulas et al., [2021](#bib.bib112)) evaluate
    FPAD performance under different sensing modalities using a fully convolutional
    neural network (FCN). The evaluation experiments are carried under fingerprint
    images captured from Visible (VIS), near-infrared (NIR), SWIR, LSCI and Near-infrared
    back-illumination domains.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Hussein et.al (Hussein et al., [2018](#bib.bib44)) | 2016 | CNN | Binary
    CE loss | A patch-based CNN based on SWIR and LSCI images |'
  prefs: []
  type: TYPE_TB
- en: '| Mirzaalian et.al (Mirzaalian et al., [2019](#bib.bib82)) | 2019 | CNN | Binary
    CE loss | Compare four different models |'
  prefs: []
  type: TYPE_TB
- en: '| Kolberg et.al (Kolberg et al., [2020](#bib.bib61)) | 2020 | Long short-term
    memory (LSTM) network and CNN | Binary CE loss | Compare the performance among
    LSTM, LRCN (long-term recurrent convolutional network) and CNN models |'
  prefs: []
  type: TYPE_TB
- en: '| Spinoulas et.al (Spinoulas et al., [2021](#bib.bib112)) | 2021 | fully-convolutional
    neural network (FCN) | Binary CE loss | Evaluate the performance with images captured
    from Visible (VIS), near-infrared (NIR), SWIR, LSCI and Near-infrared back-illumination
    |'
  prefs: []
  type: TYPE_TB
- en: Table 7\. Existing State-Of-The-Art contactless based FPAD methods
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1\. Anomaly detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Most previous deep learning models formulate FPAD as a close-set problem to
    detect various predefined PAs, which require large-scale training data to cover
    as many attacks as possible. In addition, the training data must be labeled prior
    to training. However, this leads to an overfitting issue in that the model is
    highly sensitive to the PAs already included in the training dataset but lacks
    generalization capability against unseen attacks. An increasing number of novel
    materials have been developed to produce gummy fingers to deceive FRS easily (Saguy
    et al., [2022](#bib.bib103)). The unknown FPAD method has become an open issue
    and has attracted increasing attention in recent years. Compared with the most
    common binary classifier, the one-class classifier only learns the representation
    of a live fingerprint and does not use spoof impressions of any specific material.
    Then, the unseen attack is detected as an anomaly, which is performed as an outlier
    compared with the bona fide samples. Figure [8](#S5.F8 "Figure 8 ‣ 5.2.1\. Anomaly
    detection ‣ 5.2\. Contactless based FPAD ‣ 5\. Deep learning based Fingerprint
    presentation attack detection ‣ Deep Learning based Fingerprint Presentation Attack
    Detection: A Comprehensive Survey") shows the difference between the binary classifier
    and anomaly detection-based approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3cb9d692ff4e7536c955eed36ee9fab1.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. An example of binary classifier and anomaly detection
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Engelsma and Jain (Engelsma and Jain, [2019](#bib.bib23)) | 2019 | Generative
    Adversarial Networks (GANS) | Adversarial loss | Train three GANS respectively
    on raw FTIR images, processed FTIR images, and direct-view images |'
  prefs: []
  type: TYPE_TB
- en: '| Rohrer and Kolberg (Rohrer and Kolberg, [2021](#bib.bib100)) | 2021 | Wasserstein
    GAN and AutoEncoder | Reconstruction loss | Utilize pre-trained WGAN weight on
    AutoEncoder network |'
  prefs: []
  type: TYPE_TB
- en: '| kolberg et.al (Kolberg et al., [2021b](#bib.bib59)) | 2021 | Three AutoEncoders
    | Reconstruction loss | Three AutoEncoder are proposed |'
  prefs: []
  type: TYPE_TB
- en: '| Liu et.al (Liu et al., [2021a](#bib.bib67)) | 2021 | AutoEncoder | Reconstruction
    loss | AutoEncoder based on TOptical Coherence Technology (OCT) images |'
  prefs: []
  type: TYPE_TB
- en: Table 8\. Existing State-Of-The-Art anomaly detection based FPAD methods
  prefs: []
  type: TYPE_NORMAL
- en: Engelsma and Jain (Engelsma and Jain, [2019](#bib.bib23)) propose a fingerprint
    spoof detector on only the live fingerprints through training multiple generative
    adversarial network (GANS) (Goodfellow et al., [2014](#bib.bib35)) for live fingerprint
    images. Three GAN models were trained on raw FTIR images from RaspiReader, processed
    FTIR images, and direct-view images. For each GAN, the generator attempts to synthesize
    live fingerprint images, where the discriminator uses the generated samples as
    well as the true samples from the dataset to distinguish them. Thus, through long
    iteration training, the generator is trained to generate high-quality images where
    the discriminator is able to separate the liveness sample from the generated sample.
    After the training phase, the generator is discarded, and the discriminator can
    be used as an FPAD module to detect attacks. Finally, fusion of the scores output
    by all three discriminators constitutes the final spoofness score of an input
    fingerprint sample. Rohrer and Kolberg (Rohrer and Kolberg, [2021](#bib.bib100))
    first utilize the Wasserstein GAN (Arjovsky et al., [2017](#bib.bib10)) as a pretrained
    model trained with LivDet2021 (Casula et al., [2021a](#bib.bib13)) Dermalog Sensor
    dataset from scratch. The GANs discriminator weights are transferred to the AutoEncoder’s(AE)
    encoder, whereas the generator weights are transferred to the decoder. A convolutional
    layer is added between the encoder and decoder to connect them. The AE learns
    to minimize reconstruction loss (Géron, [2022](#bib.bib30)) so that the model
    can reconstruct the input image with minimal reconstruction error. The PA will
    be detected with a large reconstruction error.
  prefs: []
  type: TYPE_NORMAL
- en: Kolberg et al. (Kolberg et al., [2021b](#bib.bib59)) propose a new PAD technique
    based on autoencoders (AE) trained only on bona fide samples captured in the short-wave
    infrared domain, which converts the two-class classification problem into a one-class
    domain. The authors introduced three AE architectures for Conv-AE, Pooling-AE,
    and Dense-AE, and compared the results with other state-of-the-art one-class PAD.
    In addition, Liu et al. (Liu et al., [2021a](#bib.bib67)) proposes a novel One-Class
    PAD (OCPAD) method for Optical Coherence Technology (OCT) images that provides
    an internal representation of the fingertip skin rather than a simple feature.
    The proposed PAD framework consists of auto-encoder network-based reference bona
    fide modeling and spoofness score-based PA detection.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3\. Smartphone based FPAD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The rapid development of smartphone-based authentication applications has achieved
    high verification accuracy (Ramachandra and Li, [2023](#bib.bib98)), which raised
    concerns about the smartphone-based system being easily spoofed. Zhang et.al (Zhang
    et al., [2016](#bib.bib130)) proposes a 2D smartphone based approach that combines
    the features of two local descriptors (LBP and LPQ) with deep features extracted
    from a CNN model. The CNN model is optimized by integrating global average pooling
    and batch normalization. Due to the lack of publicly available datasets, a self
    obtained bona fide samples and 2D attack samples made of wood glue, electrosol
    from PCB, or printed by special conductive ink are built. By fusing the results
    of the two descriptors and the CNN, the final decision can be output. Fujio et.al.
    (Fujio et al., [2018](#bib.bib26)) compare the performance of using hand-crafted
    based method(LBP, LPQ) and deep learning based method. The obtained results indicate
    that the DCNN (AlexNet) can achieve a stable accuracy when the intensity of the
    blurring noise increases. Marasco and Vurity (Marasco and Vurity, [2021](#bib.bib76))
    explored detection performance by training the IIITD database using various CNN
    architectures (AlexNet (Krizhevsky et al., [2012](#bib.bib62)) and ResNet18 (He
    et al., [2016](#bib.bib41))). The comparison results demonstrate that AlexNet
    achieved a robust performance against unseen attacks. The authors further propose
    a novel method (Marasco et al., [2022](#bib.bib77)) that explores the detection
    effectiveness of different CNN models on different color spaces. The raw image
    is converted into RGB, YCBCr, HSV, LAB, and XYZ color spaces, then the five images
    are then further fed into five pre-trained CNN models(AlexNet (Krizhevsky et al.,
    [2012](#bib.bib62)), DenseNet201 (Huang et al., [2017](#bib.bib43)), DenseNet121,
    ResNet18 (He et al., [2016](#bib.bib41)), ResNet34, and MobileNet-V2(Howard et al.,
    [2017](#bib.bib42))). The Best network is selected, and the score of the five
    color spaces is fused to obtain the final decision. Recently, to address the lack
    of publicly available fingerphoto presentation attack detection datasets, Purnapatra
    et al.. al (Purnapatra et al., [2023](#bib.bib96)) propose a new dataset comprised
    of six different PAIs. The FPAD methods use the state-of-the-art CNN models DenseNet
    121 and NASNet (Zoph et al., [2018](#bib.bib132)) which achieve promising PAD
    accuracy on the proposed dataset.
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Description |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et.al (Zhang et al., [2016](#bib.bib130)) | 2016 | CNN | Binary CE
    loss | Two handcrafted-features trained by SVM integrate with CNN. |'
  prefs: []
  type: TYPE_TB
- en: '| Fujio et.al. (Fujio et al., [2018](#bib.bib26)) | 2018 | AlexNet | Binary
    CE loss | Compared with handcrafted based method |'
  prefs: []
  type: TYPE_TB
- en: '| Marasco and Vurity (Marasco and Vurity, [2021](#bib.bib76)) | 2021 | AlexNet,
    ResNet18 | Binary CE loss | Evaluate the different CNNs on the IIITD database
    with spoof data including printout and various display attacks. |'
  prefs: []
  type: TYPE_TB
- en: '| Marasco et.al (Marasco et al., [2022](#bib.bib77)) | 2022 | AlexNet, DenseNet201,
    DenseNet121, ResNet18, ResNet34, MobileNet-V2 | Binary CE loss | Explore the effectiveness
    of deep representations derived from various color spaces based on the best model
    of six CNN models. |'
  prefs: []
  type: TYPE_TB
- en: '| Purnapatra et. al (Purnapatra et al., [2023](#bib.bib96)) | 2023 | DenseNet
    121 and NASNet (Zoph et al., [2018](#bib.bib132)) | Binary CE loss | Develop a
    new fingerphoto PAD dataset and utilize DenseNet and NASNet for testing detection
    accuracy |'
  prefs: []
  type: TYPE_TB
- en: Table 9\. Existing smartphone based FPAD methods
  prefs: []
  type: TYPE_NORMAL
- en: 5.4\. FPAD using hybrid feature extraction methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The hybrid method refers to combining more than one type of feature (handcrafted
    features, deep features, and multi-spectrum features). etc.) to detect the PAIs.
    The hybrid features can be used with all types of fingerprint capture devices
    and have been demonstrated to achieve higher detection accuracy at the cost of
    computation. Table [10](#S5.T10 "Table 10 ‣ 5.4\. FPAD using hybrid feature extraction
    methods ‣ 5\. Deep learning based Fingerprint presentation attack detection ‣
    Deep Learning based Fingerprint Presentation Attack Detection: A Comprehensive
    Survey") briefly discusses the state-of-the-art hybrid FPAD methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Jomaa et.al (M. Jomaa et al., [2020](#bib.bib71)) utilize electrocardiogram
    (ECG) signals as well as the deep features to jointly make the decision. Furthermore,
    Tolosana et al. (Tolosana et al., [2018](#bib.bib116)) propose a multi-model-based
    approach that utilizes four deep features respectively extracted from 5-layer
    residual network, pre-trained Moblie-Net-based network, pre-trained VGG 19 based
    network and CNN model, and combined the deep features with a spectral signal from
    a short-wave infrared (SWIR) spectrum capture device to jointly determine the
    liveness. Gomez et.al (Gomez-Barrero et al., [2019](#bib.bib34)) analysis the
    surface of a finger within the SWIR spectrum and inside the finger using laser
    speckle contrast imaging (LSCI) technology. The SWIR feature is extracted by the
    ResNet and VGG19 network combined with the handcrafted feature extracted from
    the LSCI using BSIF, HOG, and LBP descriptors. Then, the fusion of the results
    obtained from the above techniques determines the final liveness score. Plesh
    et al. (Plesh et al., [2019](#bib.bib94)) proposes a novel approach that combines
    dynamic time-series features with static features extracted by the Inception-V3
    (Szegedy et al., [2016](#bib.bib114)) CNN model. Then the final result will be
    obtained by the fusion of two feature sets. The experiments demonstrated that
    the fusion of two feature sets achieves a better performance than the individual
    features. Kolberg et al. (Kolberg et al., [2021a](#bib.bib58)) also include SWIR
    and laser techniques to analyze spoofing. In contrast to (Gomez-Barrero et al.,
    [2019](#bib.bib34)), they select a long-term recurrent convolutional network (LRCN)
    (Donahue et al., [2015](#bib.bib20)), a pre‐trained CNN model, and an autoencoder
    network to independently obtain a liveness score from the laser image. Meanwhile,
    the CNN and AutoEncoder models process the image from the SWIR. Finally, subsequent
    score-fusion was applied to obtain the final score for classification.
  prefs: []
  type: TYPE_NORMAL
- en: '| Author | Year | Backbone | Loss function | Result |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Tolosana et.al (Tolosana et al., [2018](#bib.bib116)) | 2018 | RenNet, MobileNet,
    VGG19, CNN | Binary CE loss | A multi-model approach that utilizes four deep features
    and SWIR image features |'
  prefs: []
  type: TYPE_TB
- en: '| Gomez et.al (Gomez-Barrero et al., [2019](#bib.bib34)) | 2019 | ResNet and
    VGG | Binary CE loss | SWIR features extracted by ResNet and VGG model and LSCI
    features extracted by handcrafted-based methods |'
  prefs: []
  type: TYPE_TB
- en: '| Plesh et.al (Plesh et al., [2019](#bib.bib94)) | 2019 | Inception-V3 | Binary
    CE loss | Dynamic time-series feature with static feature extracted by Inception-V3
    model |'
  prefs: []
  type: TYPE_TB
- en: '| Jomaa et.al (M. Jomaa et al., [2020](#bib.bib71)) | 2020 | Mobilenet-v2 |
    Binary CE loss | Electrocardiogram(ECG) features and deep features |'
  prefs: []
  type: TYPE_TB
- en: '| Kolberg et.al (Kolberg et al., [2021a](#bib.bib58)) | 2021 | Long‐term recurrent
    convolutional network(LRCN), CNN and AutoEncoder | Binary CE loss, reconstruction
    loss | Combine the liveness score obtained from laser image and SWIR images |'
  prefs: []
  type: TYPE_TB
- en: Table 10\. State-of-the-art hybrid FPAD methods
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Performance Evaluation Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss different evaluation metrics that are widely used
    in the fingerprint PAD literature. First, we present the metrics used in LivDet
    competitions (Marcialis et al., [2009](#bib.bib78)) followed by ISO/IEC using
    ISO/IEC 30107- 3 (ISO/IEC JTC1 SC37 Biometrics, [2017](#bib.bib47)) metrics.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Evaluation metrics from LivDet competitions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'since the first edition of Fingerprint Liveness Detection competition (LivDet)
    in 2009 (Marcialis et al., [2009](#bib.bib78)), the following performance evaluation
    metrics are used to benchmark the performance of the FPAD algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Frej: Rate of failure to enroll.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fcorrlive: Rate of the live fingerprint to be classified correctly.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fcorrfake: Rate of the fake fingerprint to be classified correctly.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferrlive: Rate of the live fingerprint to be misclassified.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferrfake: Rate of the fake fingerprint to be misclassified.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Additional evaluation metrics such as average classification error (ACE) are
    defined in (Chugh et al., [2017](#bib.bib16)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $ACE=\frac{Fcorrlive+Fcorrfake}{2}$ |  |'
  prefs: []
  type: TYPE_TB
- en: Starting from LivDet 2021 competition, evaluation metrics are defined according
    to the ISO/IEC 30107–1 standard presented below.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. ISO/IEC Metrics for PAD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'International Standard Organization (ISO/IEC 30107–1:2016) (ISO, [2016](#bib.bib3))
    has described the general framework to present the attack detection performance
    results. The ISO/IEC 30107–1 framework defined following metrics:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liveness Accuracy: Rate of samples correctly classified by the PAD system.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'APCER (Attack Presentation Classification Error Rate): Rate of fake fingerprints
    to be misclassified. The APCER for a given presentation attack instrument species(PAIS)
    is defined as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (2) |  | $APCER_{PAIS}=1-(\frac{1}{N_{PAIS}})\sum_{i=1}^{N_{PAIS}}RES_{i}$
    |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: $N_{PAIS}$ indicates the number of attack presentations for the given PAI species,
    $RES_{i}$ takes the value 1 if the $i^{th}$ presentation is classified as an attack
    presentation, and value 0 if classified as a bona fide presentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BPCER (Bona fide Presentation Classification Error Rate): Rate of the live
    fingerprint to be classified correctly. BPCER shall be calculated as:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (3) |  | $BPCER=\frac{\sum_{i=1}^{N_{BF}}RES_{i}}{N_{BF}}$ |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: where $N_{BF}$ indicates the number of bona fide presentations. $RES_{i}$ takes
    the value 1 if the $i^{th}$ presentation is classified as an attack presentation
    and value 0 if classified as a bona fide presentation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'D-EER (Detection Equal Error Rate) indicates that the APCER is equal to the
    BPCER. Normally, D-EER is valuable which stands for the performance of a biometric
    system. To further evaluate the performance of the integrated system, additional
    metrics are also defined:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FNMR (False Non-Match Rate): Rate of genuine fingerprints to be classified
    as an impostor.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FMR (False Match Rate): Rate of zero-effort impostors classified as genuine.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IAPMR (Impostor Attack Presentation Match Rate): Rate of impostor attack presentations
    classified as genuine.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Integrated Matching Accuracy: Rate of samples correctly classified by the integrated
    system.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7\. Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the revolution of deep learning, training deep neural networks (DNN) has
    dominated the field of image classification and object recognition. This technique
    was further extended to FPAD methods, and achieved notable improvements in the
    detection of fabricated fingerprint replicas. However, there are still some limitations
    that can be considered and discussed. In this section, we introduce the major
    challenges of current research and future perspectives.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Generalization to unknown attack detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Normally, a deep learning-based FPAD model takes both bona fide and attack samples
    for training so that the classifier can distinguish liveness based on the probability
    score calculated corresponding to the labels. However, these methods suffer from
    low generalization ability against PAIs not included in the training set. Another
    type of method is anomaly detection, which trains a one-class classifier based
    on only the bona fide samples to represent the real fingerprint images better
    to detect anomalies that achieve acceptable results against unknown attacks to
    some extent. In (Sandouka et al., [2021a](#bib.bib105)), the authors proposed
    a domain-adaptation approach that can generate mappings across sensors to reduce
    the distribution shift between different fingerprint representations. Based on
    this approach as a starting point, it is worth exploring how to make the model
    learn the mapping from a source domain to an unseen domain to achieve a general
    representation of the fake fingerprint.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2\. Interpretability to fingerprint presentation attack detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The widely deployed AI application raised the interpretability issue of how
    to make the deep learning model explainable. Therefore, it is important to build
    ’Transparent’ models that have the ability to explain why they predict what they
    predict. In order to provide an analysis of the interpretation of FPAD methods
    using visualization techniques. Techniques such as (Zeiler and Fergus, [2014](#bib.bib126))
    (Selvaraju et al., [2017](#bib.bib107)) (Ancona et al., [2017](#bib.bib8)) can
    be used to highlight the region of an image that affects the final decision. Lie
    et.al (Liu et al., [2022](#bib.bib66)) include Grad-CAM to visualize the important
    regions related to the given label. It will be interesting to consider applying
    visualization, especially to images captured by multi-spectrum devices.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3\. Light-weight models for finger photo presentation attack detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the rapid development of smartphone cameras, high-resolution fingerphotos
    can be captured efficiently and directly from a mobile device to aid reliable
    biometric authentication. Because mobile devices mostly do not have a high-computation
    environment, a lightweight deep learning model with fewer parameters and focus
    on only a small region of the fingerprint images would be an optimal solution.
    Hence, another perspective could be the presentation attack detection of smartphone-based
    approaches.
  prefs: []
  type: TYPE_NORMAL
- en: 7.4\. Lack of large-scale publicly available dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As deep learning has shown a significant impact on the image classification
    domain, research on FPAD methods has concentrated on training a large-scale neural
    network to detect spoofing. Because of the requirement of the large scale of both
    bonafide and attack sample data using a deep learning model, there have been plenty
    of publicly available datasets published using different capture devices and spoofing
    materials. However, datasets comprising a large number of samples are still lacking.
    Especially in contactless finger photos, there is currently a lack of datasets
    containing bonafide and spoofing samples. A further perspective could be to produce
    large-scale finger photo presentation attack datasets comprised of various presentation
    attack instruments materials.
  prefs: []
  type: TYPE_NORMAL
- en: 7.5\. Potential adversarial presentation attack
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An adversarial attack generates adversarial samples by purpose in order to mislead
    the image classification result of a machine learning model. One simple way to
    generate adversarial examples is to add a perturbation of some pixels so that
    the output image looks no different from the input image, but the classification
    result will be changed. Another notable observation was proposed by Casula et
    al. (Casula et al., [2021b](#bib.bib14)), who produce high-quality spoofs through
    the snapshot picture of a smartphone to obtain the fingerprint latent. Through
    digital processing, the spoof was fabricated using a transparent sheet. The experiment
    indicated that this ScreenSpoof presents a threat at the same level as a normal
    presentation attack. Hence, Marrone et al. (Marrone et al., [2021](#bib.bib79))
    investigate the feasibility of adopting an adversarial attack on a physical domain
    by materially realizing a fake image based on an adversarial fingerprint example.
    The evaluation of the attack indicates that printed adversarial images exhibit
    a high attack rate with multiple attacks and fairly good results with a one-shot
    attack. According to this, it should be considered that with adversarial examples
    targeting the FPAD module, it is possible to combine other digital attacks(Masterprint,
    morphing. etc.) as well as adversarial perturbation to fool the FPAD system to
    perform more dangerous attacks on the FRS system. Hence, it is interesting to
    exploring countermeasures against emerging adversarial attacks.
  prefs: []
  type: TYPE_NORMAL
- en: 8\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article provides a comprehensive overview on the common fingerprint presentation
    attack instruments and presentation attack detection techniques that are widely
    employed in both contact and contactless fingerprint biometrics. A brief introduction
    to publicly available databases and relevant standards regarding FPAD evaluation
    metrics are presented. Then a comprehensive literature review of the existing
    state-of-the-art deep-learning-based FPAD methods is presented, which covers contact,
    contactless, and smartphone-based approaches. Finally, potential future perspectives
    are discussed to motivate future research. Overall, this study provides an intuitive
    guide to researchers interested in this area.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: This work is supported by OFFPAD project funded by the Research Council of Norway.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: AFI (2003) 2003. Automated Fingerprint Identification System. [https://www.innovatrics.com/glossary/afis-automated-fingerprint-identification-system/](https://www.innovatrics.com/glossary/afis-automated-fingerprint-identification-system/).
    Innovatrics.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ISO (2016) 2016. *Information technology — Biometric presentation attack detection
    — Part 1: Framework*. Standard ISO/IEC 30107-1:2016. International Organization
    for Standardization, Geneva, CH. [https://www.iso.org/standard/53227.html](https://www.iso.org/standard/53227.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liv (2022) 2022. LIVDET. [https://livdet.diee.unica.it](https://livdet.diee.unica.it).
    Spoofing Adhaar.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hac (2022) 2022. Spoofing Adhaar. [http://timesofindia.indiatimes.com/articleshow/83324403.cms?utm_source=contentofinterest&utm_medium=text&utm_campaign=cppst/](http://timesofindia.indiatimes.com/articleshow/83324403.cms?utm_source=contentofinterest&utm_medium=text&utm_campaign=cppst/).
    Spoofing Adhaar.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Al-Ajlan (2013) Amani Al-Ajlan. 2013. Survey on fingerprint liveness detection.
    In *2013 International Workshop on Biometrics and Forensics (IWBF)*. IEEE, 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ametefe et al. (2022) DS Ametefe, SS Sarnin, DM Ali, and MZ Zaheer. 2022. Fingerprint
    Liveness Detection Schemes: A Review on Presentation Attack. *Computer Methods
    in Biomechanics and Biomedical Engineering: Imaging & Visualization* 10, 2 (2022),
    217–240.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ancona et al. (2017) Marco Ancona, Enea Ceolini, Cengiz Öztireli, and Markus
    Gross. 2017. Towards better understanding of gradient-based attribution methods
    for deep neural networks. *arXiv preprint arXiv:1711.06104* (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Antonelli et al. (2006) Athos Antonelli, Raffaele Cappelli, Dario Maio, and
    Davide Maltoni. 2006. Fake finger detection by skin distortion analysis. *IEEE
    Transactions on Information Forensics and Security* 1, 3 (2006), 360–373.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arjovsky et al. (2017) Martin Arjovsky, Soumith Chintala, and Léon Bottou. 2017.
    Wasserstein generative adversarial networks. In *International conference on machine
    learning*. PMLR, 214–223.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bontrager et al. (2018) Philip Bontrager, Aditi Roy, Julian Togelius, Nasir
    Memon, and Arun Ross. 2018. Deepmasterprints: Generating masterprints for dictionary
    attacks via latent variable evolution. In *2018 IEEE 9th International Conference
    on Biometrics Theory, Applications and Systems (BTAS)*. IEEE, 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bossen et al. (2010) Anke Bossen, Roland Lehmann, and Christoph Meier. 2010.
    Internal fingerprint identification with optical coherence tomography. *IEEE photonics
    technology letters* 22, 7 (2010), 507–509.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Casula et al. (2021a) Roberto Casula, Marco Micheletto, Giulia Orrù, Rita Delussu,
    Sara Concas, Andrea Panzino, and Gian Luca Marcialis. 2021a. LivDet 2021 fingerprint
    liveness detection competition-into the unknown. In *2021 IEEE International Joint
    Conference on Biometrics (IJCB)*. IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Casula et al. (2021b) Roberto Casula, Giulia Orrù, Daniele Angioni, Xiaoyi Feng,
    Gian Luca Marcialis, and Fabio Roli. 2021b. Are spoofs from latent fingerprints
    a real threat for the best state-of-art liveness detectors?. In *2020 25th International
    Conference on Pattern Recognition (ICPR)*. IEEE, 3412–3418.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng and Larin (2007) Yezeng Cheng and Kirill V Larin. 2007. In vivo two-and
    three-dimensional imaging of artificial and real fingerprints with optical coherence
    tomography. *IEEE Photonics Technology Letters* 19, 20 (2007), 1634–1636.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chugh et al. (2017) Tarang Chugh, Kai Cao, and Anil K Jain. 2017. Fingerprint
    spoof detection using minutiae-based local patches. In *2017 IEEE International
    Joint Conference on Biometrics (IJCB)*. IEEE, 581–589.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chugh et al. (2018) Tarang Chugh, Kai Cao, and Anil K Jain. 2018. Fingerprint
    spoof buster: Use of minutiae-centered patches. *IEEE Transactions on Information
    Forensics and Security* 13, 9 (2018), 2190–2202.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chugh and Jain (2019) Tarang Chugh and Anil K Jain. 2019. Fingerprint spoof
    generalization. *arXiv preprint arXiv:1912.02710* (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chugh and Jain (2020) Tarang Chugh and Anil K Jain. 2020. Fingerprint spoof
    detector generalization. *IEEE Transactions on Information Forensics and Security*
    16 (2020), 42–55.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Donahue et al. (2015) Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama,
    Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. 2015.
    Long-term recurrent convolutional networks for visual recognition and description.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*.
    2625–2634.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Drahansky et al. (2006) Martin Drahansky, Ralf Notzel, and Wolfgang Funk. 2006.
    Liveness detection based on fine movements of the fingertip surface. In *2006
    IEEE Information Assurance Workshop*. IEEE, 42–47.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Engelsma et al. (2022) Joshua J Engelsma, Steven A Grosz, and Anil K Jain.
    2022. PrintsGAN: synthetic fingerprint generator. *arXiv preprint arXiv:2201.03674*
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Engelsma and Jain (2019) Joshua J Engelsma and Anil K Jain. 2019. Generalizing
    fingerprint spoof detector: Learning a one-class classifier. In *2019 International
    Conference on Biometrics (ICB)*. IEEE, 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Espinoza et al. (2011) Marcela Espinoza, Christophe Champod, and Pierre Margot.
    2011. Vulnerabilities of fingerprint reader to fake fingerprints attacks. *Forensic
    science international* 204, 1-3 (2011), 41–49.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferrara et al. (2016) Matteo Ferrara, Raffaele Cappelli, and Davide Maltoni.
    2016. On the feasibility of creating double-identity fingerprints. *IEEE Transactions
    on Information Forensics and Security* 12, 4 (2016), 892–900.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fujio et al. (2018) Masakazu Fujio, Yosuke Kaga, Takao Murakami, Tetsushi Ohki,
    and Kenta Takahashi. 2018. Face/Fingerphoto Spoof Detection under Noisy Conditions
    by using Deep Convolutional Neural Network.. In *BIOSIGNALS*. 54–62.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gajawada et al. (2019) Rohit Gajawada, Additya Popli, Tarang Chugh, Anoop Namboodiri,
    and Anil K Jain. 2019. Universal material translator: Towards spoof fingerprint
    generalization. In *2019 International Conference on Biometrics (ICB)*. IEEE,
    1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Galbally et al. (2011) Javier Galbally, Julian Fierrez, Fernando Alonso-Fernandez,
    and Marcos Martinez-Diaz. 2011. Evaluation of direct attacks to fingerprint verification
    systems. *Telecommunication Systems* 47 (2011), 243–254.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gatys et al. (2015) Leon A Gatys, Alexander S Ecker, and Matthias Bethge. 2015.
    A neural algorithm of artistic style. *arXiv preprint arXiv:1508.06576* (2015).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Géron (2022) Aurélien Géron. 2022. *Hands-on machine learning with Scikit-Learn,
    Keras, and TensorFlow*. ” O’Reilly Media, Inc.”.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghiani et al. (2013a) Luca Ghiani, Abdenour Hadid, Gian Luca Marcialis, and
    Fabio Roli. 2013a. Fingerprint liveness detection using binarized statistical
    image features. In *2013 IEEE sixth international conference on biometrics: theory,
    applications and systems (BTAS)*. IEEE, 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ghiani et al. (2012) Luca Ghiani, Gian Luca Marcialis, and Fabio Roli. 2012.
    Fingerprint liveness detection by local phase quantization. In *Proceedings of
    the 21st international conference on pattern recognition (ICPR2012)*. IEEE, 537–540.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ghiani et al. (2013b) Luca Ghiani, David Yambay, Valerio Mura, Simona Tocco,
    Gian Luca Marcialis, Fabio Roli, and Stephanie Schuckcrs. 2013b. Livdet 2013 fingerprint
    liveness detection competition 2013\. In *2013 International Conference on Biometrics
    (ICB)*. IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gomez-Barrero et al. (2019) Marta Gomez-Barrero, Jascha Kolberg, and Christoph
    Busch. 2019. Multi-modal fingerprint presentation attack detection: Analysing
    the surface and the inside. In *2019 International Conference on Biometrics (ICB)*.
    IEEE, 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014.
    Generative adversarial nets. *Advances in neural information processing systems*
    27 (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gragnaniello et al. (2013) Diego Gragnaniello, Giovanni Poggi, Carlo Sansone,
    and Luisa Verdoliva. 2013. Fingerprint liveness detection based on weber local
    image descriptor. In *2013 IEEE workshop on biometric measurements and systems
    for security and medical applications*. IEEE, 46–50.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gragnaniello et al. (2015) Diego Gragnaniello, Giovanni Poggi, Carlo Sansone,
    and Luisa Verdoliva. 2015. Local contrast phase descriptor for fingerprint liveness
    detection. *Pattern Recognition* 48, 4 (2015), 1050–1058.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Grosz and Jain (2022) Steven A Grosz and Anil K Jain. 2022. Spoofgan: Synthetic
    fingerprint spoof images. *IEEE Transactions on Information Forensics and Security*
    18 (2022), 730–743.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2010) Zhenhua Guo, Lei Zhang, and David Zhang. 2010. A completed
    modeling of local binary pattern operator for texture classification. *IEEE transactions
    on image processing* 19, 6 (2010), 1657–1663.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Habib and Selwal (2021) A Habib and A Selwal. 2021. Robust anti-spoofing techniques
    for fingerprint liveness detection: A Survey. In *IOP Conference Series: Materials
    Science and Engineering*, Vol. 1033\. IOP Publishing, 012026.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition*. 770–778.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Howard et al. (2017) Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko,
    Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. Mobilenets:
    Efficient convolutional neural networks for mobile vision applications. *arXiv
    preprint arXiv:1704.04861* (2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2017) Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. 2017. Densely connected convolutional networks. In *Proceedings of
    the IEEE conference on computer vision and pattern recognition*. 4700–4708.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hussein et al. (2018) Mohamed E Hussein, Leonidas Spinoulas, Fei Xiong, and
    Wael Abd-Almageed. 2018. Fingerprint presentation attack detection using a novel
    multi-spectral capture device and patch-based convolutional neural networks. In
    *2018 IEEE international workshop on information forensics and security (WIFS)*.
    IEEE, 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iandola et al. (2016) Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid
    Ashraf, William J Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy
    with 50x fewer parameters and¡ 0.5 MB model size. *arXiv preprint arXiv:1602.07360*
    (2016).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy (2015) Sergey Ioffe and Christian Szegedy. 2015. Batch normalization:
    Accelerating deep network training by reducing internal covariate shift. In *International
    conference on machine learning*. PMLR, 448–456.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ISO/IEC JTC1 SC37 Biometrics (2017) ISO/IEC JTC1 SC37 Biometrics. 2017. *ISO/IEC
    30107-3\. Information Technology - Biometric presentation attack detection - Part
    3: Testing and Reporting*. International Organization for Standardization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jang et al. (2017) Han-Ul Jang, Hak-Yeol Choi, Dongkyu Kim, Jeongho Son, and
    Heung-Kyu Lee. 2017. Fingerprint spoof detection using contrast enhancement and
    convolutional neural networks. In *International Conference on Information Science
    and Applications*. Springer, 331–338.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jia et al. (2007) Jia Jia, Lianhong Cai, Kaifu Zhang, and Dawei Chen. 2007.
    A new approach to fake finger detection based on skin elasticity analysis. In
    *Advances in Biometrics: International Conference, ICB 2007, Seoul, Korea, August
    27-29, 2007\. Proceedings*. Springer, 309–318.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jian et al. (2020) WEN Jian, Yujie Zhou, and Hongming Liu. 2020. Densely connected
    convolutional network optimized by genetic algorithm for fingerprint liveness
    detection. *IEEE Access* 9 (2020), 2229–2243.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jung and Heo (2018) HY Jung and YS Heo. 2018. Fingerprint liveness map construction
    using convolutional neural network. *Electronics Letters* 54, 9 (2018), 564–566.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jung et al. (2019) Ho Yub Jung, Yong Seok Heo, and Soochahn Lee. 2019. Fingerprint
    liveness detection by a template-probe convolutional neural network. *IEEE Access*
    7 (2019), 118986–118993.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kanich et al. (2018) Ondřej Kanich, Martin Drahanskỳ, and Martin Mézl. 2018.
    Use of creative materials for fingerprint spoofs. In *2018 International Workshop
    on Biometrics and Forensics (IWBF)*. IEEE, 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kannala and Rahtu (2012) Juho Kannala and Esa Rahtu. 2012. Bsif: Binarized
    statistical image features. In *Proceedings of the 21st international conference
    on pattern recognition (ICPR2012)*. IEEE, 1363–1366.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karras et al. (2019) Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based
    generator architecture for generative adversarial networks. In *Proceedings of
    the IEEE/CVF conference on computer vision and pattern recognition*. 4401–4410.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2019) Hakil Kim, Xuenan Cui, Man-Gyu Kim, and Thi Hai Binh Nguyen.
    2019. Fingerprint generation and presentation attack detection using deep neural
    networks. In *2019 IEEE Conference on Multimedia Information Processing and Retrieval
    (MIPR)*. IEEE, 375–378.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2016) Soowoong Kim, Bogun Park, Bong Seop Song, and Seungjoon Yang.
    2016. Deep belief network based statistical feature learning for fingerprint liveness
    detection. *Pattern Recognition Letters* 77 (2016), 58–65.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolberg et al. (2021a) Jascha Kolberg, Marta Gomez-Barrero, and Christoph Busch.
    2021a. On the generalisation capabilities of fingerprint presentation attack detection
    methods in the short wave infrared domain. *IET Biometrics* 10, 4 (2021), 359–373.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolberg et al. (2021b) Jascha Kolberg, Marcel Grimmer, Marta Gomez-Barrero,
    and Christoph Busch. 2021b. Anomaly detection with convolutional autoencoders
    for fingerprint presentation attack detection. *IEEE Transactions on Biometrics,
    Behavior, and Identity Science* 3, 2 (2021), 190–202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kolberg et al. (2023) Jascha Kolberg, Jannis Priesnitz, Christian Rathgeb,
    and Christoph Busch. 2023. COLFISPOOF: A New Database for Contactless Fingerprint
    Presentation Attack Detection Research. In *Proceedings of the IEEE/CVF Winter
    Conference on Applications of Computer Vision*. 653–661.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kolberg et al. (2020) Jascha Kolberg, Alexandru-Cosmin Vasile, Marta Gomez-Barrero,
    and Christoph Busch. 2020. Analysing the performance of LSTMs and CNNs on 1310
    nm laser data for fingerprint presentation attack detection. In *2020 IEEE International
    Joint Conference on Biometrics (IJCB)*. IEEE, 1–7.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    2012. ImageNet Classification with Deep Convolutional Neural Networks. In *Advances
    in Neural Information Processing Systems 25*, F. Pereira, C. J. C. Burges, L. Bottou,
    and K. Q. Weinberger (Eds.). Curran Associates, Inc., 1097–1105.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kulkarni and Patil (2015) Samruddhi S Kulkarni and Hemprasad Y Patil. 2015.
    Survey on fingerprint spoofing detection techniques and databases. *International
    Journal of Computer Applications* 975 (2015), 8887.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lazimul and Binoy (2017) Limnd TP Lazimul and DL Binoy. 2017. Fingerprint liveness
    detection using convolutional neural network and fingerprint image enhancement.
    In *2017 International Conference on Energy, Communication, Data Analytics and
    Soft Computing (ICECDS)*. IEEE, 731–735.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2022) Soo-Hyun Lee, Min Young Lim, Seong Hee Park, Hwa Jung Yoo,
    and Youn Kyu Lee. 2022. Towards Cross-materials: Fingerprint Liveness Detection
    based on Style Transfer. In *2022 13th International Conference on Information
    and Communication Technology Convergence (ICTC)*. IEEE, 1332–1334.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022) Feng Liu, Zhe Kong, Haozhe Liu, Wentian Zhang, and Linlin
    Shen. 2022. Fingerprint Presentation Attack Detection by Channel-Wise Feature
    Denoising. *IEEE Transactions on Information Forensics and Security* 17 (2022),
    2963–2976.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021a) Feng Liu, Haozhe Liu, Wentian Zhang, Guojie Liu, and Linlin
    Shen. 2021a. One-class fingerprint presentation attack detection using auto-encoder
    network. *IEEE Transactions on Image Processing* 30 (2021), 2394–2407.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021b) Haozhe Liu, Wentian Zhang, Feng Liu, Haoqian Wu, and Linlin
    Shen. 2021b. Fingerprint presentation attack detector using global-local model.
    *IEEE Transactions on Cybernetics* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Buma (2010) Mengyang Liu and Takashi Buma. 2010. Biometric mapping of
    fingertip eccrine glands with optical coherence tomography. *IEEE Photonics Technology
    Letters* 22, 22 (2010), 1677–1679.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lowe (1999) D.G. Lowe. 1999. Object recognition from local scale-invariant features.
    In *Proceedings of the Seventh IEEE International Conference on Computer Vision*,
    Vol. 2. 1150–1157 vol.2. [https://doi.org/10.1109/ICCV.1999.790410](https://doi.org/10.1109/ICCV.1999.790410)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: M. Jomaa et al. (2020) Rami M. Jomaa, Hassan Mathkour, Yakoub Bazi, and Md Saiful
    Islam. 2020. End-to-end deep learning fusion of fingerprint and electrocardiogram
    signals for presentation attack detection. *Sensors* 20, 7 (2020), 2085.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Makrushin et al. (2021) Andrey Makrushin, Mark Trebeljahr, Stefan Seidlitz,
    and Jana Dittmann. 2021. On feasibility of GAN-based fingerprint morphing. In
    *2021 IEEE 23rd International Workshop on Multimedia Signal Processing (MMSP)*.
    IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maltoni et al. (2022) Davide Maltoni, Dario Maio, Anil K Jain, and Jianjiang
    Feng. 2022. *Handbook of Fingerprint Recognition*. Springer Nature.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maltoni et al. (2009) Davide Maltoni, Dario Maio, Anil K Jain, Salil Prabhakar,
    et al. 2009. *Handbook of fingerprint recognition*. Vol. 2. Springer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marasco and Ross (2014) Emanuela Marasco and Arun Ross. 2014. A survey on antispoofing
    schemes for fingerprint recognition systems. *ACM Computing Surveys (CSUR)* 47,
    2 (2014), 1–36.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marasco and Vurity (2021) Emanuela Marasco and Anudeep Vurity. 2021. Fingerphoto
    Presentation Attack Detection: Generalization in Smartphones. In *2021 IEEE International
    Conference on Big Data (Big Data)*. IEEE, 4518–4523.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marasco et al. (2022) Emanuela Marasco, Anudeep Vurity, and Asem Otham. 2022.
    Deep Color Spaces for Fingerphoto Presentation Attack Detection in Mobile Devices.
    In *International Conference on Computer Vision and Image Processing*. Springer,
    351–362.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marcialis et al. (2009) Gian Luca Marcialis, Aaron Lewicke, Bozhao Tan, Pietro
    Coli, Dominic Grimberg, Alberto Congiu, Alessandra Tidu, Fabio Roli, and Stephanie
    Schuckers. 2009. First international fingerprint liveness detection competition—LivDet
    2009\. In *Image Analysis and Processing–ICIAP 2009: 15th International Conference
    Vietri sul Mare, Italy, September 8-11, 2009 Proceedings 15*. Springer, 12–23.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marrone et al. (2021) Stefano Marrone, Roberto Casula, Giulia Orrù, Gian Luca
    Marcialis, and Carlo Sansone. 2021. Fingerprint adversarial presentation attack
    in the physical domain. In *Pattern Recognition. ICPR International Workshops
    and Challenges: Virtual Event, January 10–15, 2021, Proceedings, Part VI*. Springer,
    530–543.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Menotti et al. (2015) David Menotti, Giovani Chiachia, Allan Pinto, William Robson
    Schwartz, Helio Pedrini, Alexandre Xavier Falcao, and Anderson Rocha. 2015. Deep
    representations for iris, face, and fingerprint spoofing detection. *IEEE Transactions
    on Information Forensics and Security* 10, 4 (2015), 864–879.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Micheletto et al. (2022) Marco Micheletto, Giulia Orrù, Roberto Casula, David
    Yambay, Gian Luca Marcialis, and Stephanie C Schuckers. 2022. Review of the Fingerprint
    Liveness Detection (LivDet) competition series: from 2009 to 2021. *arXiv preprint
    arXiv:2202.07259* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mirzaalian et al. (2019) Hengameh Mirzaalian, Mohamed Hussein, and Wael Abd-Almageed.
    2019. On the effectiveness of laser speckle contrast imaging and deep neural networks
    for detecting known and unknown fingerprint presentation attacks. In *2019 International
    Conference on Biometrics (ICB)*. IEEE, 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mura et al. (2015) Valerio Mura, Luca Ghiani, Gian Luca Marcialis, Fabio Roli,
    David A. Yambay, and Stephanie A. Schuckers. 2015. LivDet 2015 fingerprint liveness
    detection competition 2015\. In *2015 IEEE 7th International Conference on Biometrics
    Theory, Applications and Systems (BTAS)*. 1–6. [https://doi.org/10.1109/BTAS.2015.7358776](https://doi.org/10.1109/BTAS.2015.7358776)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mura et al. (2018) Valerio Mura, Giulia Orrù, Roberto Casula, Alessandra Sibiriu,
    Giulia Loi, Pierluigi Tuveri, Luca Ghiani, and Gian Luca Marcialis. 2018. LivDet
    2017 fingerprint liveness detection competition 2017\. In *2018 International
    Conference on Biometrics (ICB)*. IEEE, 297–302.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. (2018) Thi Hai Binh Nguyen, Eunsoo Park, Xuenan Cui, Van Huan
    Nguyen, and Hakil Kim. 2018. fPADnet: Small and efficient convolutional neural
    network for presentation attack detection. *Sensors* 18, 8 (2018), 2532.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nogueira et al. (2014) Rodrigo Frassetto Nogueira, Roberto de Alencar Lotufo,
    and Rubens Campos Machado. 2014. Evaluating software-based fingerprint liveness
    detection using convolutional networks and local binary patterns. In *2014 IEEE
    workshop on biometric measurements and systems for security and medical applications
    (BIOMS) Proceedings*. IEEE, 22–29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nogueira et al. (2016) Rodrigo Frassetto Nogueira, Roberto de Alencar Lotufo,
    and Rubens Campos Machado. 2016. Fingerprint liveness detection using convolutional
    neural networks. *IEEE transactions on information forensics and security* 11,
    6 (2016), 1206–1213.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ojansivu and Heikkilä (2008) Ville Ojansivu and Janne Heikkilä. 2008. Blur insensitive
    texture classification using local phase quantization. In *International conference
    on image and signal processing*. Springer, 236–243.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Orrù et al. (2019) Giulia Orrù, Roberto Casula, Pierluigi Tuveri, Carlotta Bazzoni,
    Giovanna Dessalvi, Marco Micheletto, Luca Ghiani, and Gian Luca Marcialis. 2019.
    Livdet in action-fingerprint liveness detection competition 2019\. In *2019 International
    Conference on Biometrics (ICB)*. IEEE, 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pala and Bhanu (2017) Federico Pala and Bir Bhanu. 2017. Deep triplet embedding
    representations for liveness detection. In *Deep Learning for Biometrics*. Springer,
    287–307.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Park et al. (2019) Eunsoo Park, Xuenan Cui, Thi Hai Binh Nguyen, and Hakil Kim.
    2019. Presentation attack detection using a tiny fully convolutional network.
    *IEEE Transactions on Information Forensics and Security* 14, 11 (2019), 3016–3025.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Park et al. (2016) Eunsoo Park, Weonjin Kim, Qiongxiu Li, Jungmin Kim, and Hakil
    Kim. 2016. Fingerprint liveness detection using CNN features of random sample
    patches. In *2016 International Conference of the Biometrics Special Interest
    Group (BIOSIG)*. IEEE, 1–4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pereira et al. (2020) Joao Afonso Pereira, Ana F Sequeira, Diogo Pernes, and
    Jaime S Cardoso. 2020. A robust fingerprint presentation attack detection method
    against unseen attacks through adversarial learning. In *2020 International Conference
    of the Biometrics Special Interest Group (BIOSIG)*. IEEE, 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plesh et al. (2019) Richard Plesh, Keivan Bahmani, Ganghee Jang, David Yambay,
    Ken Brownlee, Timothy Swyka, Peter Johnson, Arun Ross, and Stephanie Schuckers.
    2019. Fingerprint presentation attack detection utilizing time-series, color fingerprint
    captures. In *2019 International Conference on Biometrics (ICB)*. IEEE, 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prabakaran and Pillay (2020) Eswaran Prabakaran and Kriveshini Pillay. 2020.
    Synthesis and characterization of fluorescent N-CDs/ZnONPs nanocomposite for latent
    fingerprint detection by using powder brushing method. *Arabian Journal of Chemistry*
    13, 2 (2020), 3817–3835.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Purnapatra et al. (2023) Sandip Purnapatra, Conor Miller-Lynch, Stephen Miner,
    Yu Liu, Keivan Bahmani, Soumyabrata Dey, and Stephanie Schuckers. 2023. Presentation
    Attack Detection with Advanced CNN Models for Noncontact-based Fingerprint Systems.
    *arXiv preprint arXiv:2303.05459* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rai et al. (2023) Anuj Rai, Somnath Dey, Pradeep Patidar, and Prakhar Rai.
    2023. MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector Classifier
    for Fingerprint Presentation Attack Detection. *arXiv preprint arXiv:2303.01465*
    (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ramachandra and Li (2023) Raghavendra Ramachandra and Hailin Li. 2023. Finger-NestNet:
    Interpretable Fingerphoto Verification on Smartphone using Deep Nested Residual
    Network. In *Proceedings of the IEEE/CVF Winter Conference on Applications of
    Computer Vision*. 693–700.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reddy et al. (2008) P Venkata Reddy, Ajay Kumar, SMK Rahman, and Tanvir Singh
    Mundra. 2008. A new antispoofing approach for biometric devices. *IEEE transactions
    on biomedical circuits and systems* 2, 4 (2008), 328–337.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rohrer and Kolberg (2021) Tobias Rohrer and Jascha Kolberg. 2021. GAN pretraining
    for deep convolutional autoencoders applied to Software-based Fingerprint Presentation
    Attack Detection. *arXiv preprint arXiv:2105.10213* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roy et al. (2018) Aditi Roy, Nasir Memon, Julian Togelius, and Arun Ross. 2018.
    Evolutionary methods for generating synthetic masterprint templates: Dictionary
    attack in fingerprint recognition. In *2018 International Conference on Biometrics
    (ICB)*. IEEE, 39–46.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: S Ametefe et al. (2021) Divine S Ametefe, Suzi S Seroja, and Darmawaty M Ali.
    2021. Fingerprint presentation attack detection using deep transfer learning and
    densenet201 network/Divine S. Ametefe, Suzi S. Seroja, and Darmawaty M. Ali. *Journal
    of Electrical and Electronic Systems Research (JEESR)* 19 (2021), 95–105.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saguy et al. (2022) Michel Saguy, Joseph Almog, Daniel Cohn, and Christophe
    Champod. 2022. Proactive forensic science in biometrics: Novel materials for fingerprint
    spoofing. *Journal of Forensic Sciences* 67, 2 (2022), 534–542.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sandouka et al. (2021b) Soha B Sandouka, Yakoub Bazi, and Naif Alajlan. 2021b.
    Transformers and generative adversarial networks for liveness detection in multitarget
    fingerprint sensors. *Sensors* 21, 3 (2021), 699.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sandouka et al. (2021a) Soha B Sandouka, Yakoub Bazi, Haikel Alhichri, and Naif
    Alajlan. 2021a. Unified Generative Adversarial Networks for Multidomain Fingerprint
    Presentation Attack Detection. *Entropy* 23, 8 (2021), 1089.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schroff et al. (2015) Florian Schroff, Dmitry Kalenichenko, and James Philbin.
    2015. Facenet: A unified embedding for face recognition and clustering. In *Proceedings
    of the IEEE conference on computer vision and pattern recognition*. 815–823.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Selvaraju et al. (2017) Ramprasaath R Selvaraju, Michael Cogswell, Abhishek
    Das, Ramakrishna Vedantam, Devi Parikh, and Dhruv Batra. 2017. Grad-cam: Visual
    explanations from deep networks via gradient-based localization. In *Proceedings
    of the IEEE international conference on computer vision*. 618–626.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sharma and Selwal (2021) Deepika Sharma and Arvind Selwal. 2021. FinPAD: State-of-the-art
    of fingerprint presentation attack detection mechanisms, taxonomy and future perspectives.
    *Pattern Recognition Letters* 152 (2021), 225–252.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) Karen Simonyan and Andrew Zisserman. 2014. Very
    deep convolutional networks for large-scale image recognition. *arXiv preprint
    arXiv:1409.1556* (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021) Jag Mohan Singh, Ahmed Madhun, Guoqiang Li, and Raghavendra
    Ramachandra. 2021. A survey on unknown presentation attack detection for fingerprint.
    In *International Conference on Intelligent Technologies and Applications*. Springer,
    189–202.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sousedik and Busch (2014) Ctirad Sousedik and Christoph Busch. 2014. Presentation
    attack detection methods for fingerprint recognition systems: a survey. *Iet Biometrics*
    3, 4 (2014), 219–233.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spinoulas et al. (2021) Leonidas Spinoulas, Hengameh Mirzaalian, Mohamed E
    Hussein, and Wael AbdAlmageed. 2021. Multi-modal fingerprint presentation attack
    detection: Evaluation on a new dataset. *IEEE Transactions on Biometrics, Behavior,
    and Identity Science* 3, 3 (2021), 347–364.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. (2014) Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
    Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: a simple way to prevent
    neural networks from overfitting. *The journal of machine learning research* 15,
    1 (2014), 1929–1958.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2016) Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
    Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer
    vision. In *Proceedings of the IEEE conference on computer vision and pattern
    recognition*. 2818–2826.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Le (2021) Mingxing Tan and Quoc Le. 2021. Efficientnetv2: Smaller models
    and faster training. In *International conference on machine learning*. PMLR,
    10096–10106.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tolosana et al. (2018) Ruben Tolosana, Marta Gomez-Barrero, Jascha Kolberg,
    Aythami Morales, Christoph Busch, and Javier Ortega-Garcia. 2018. Towards fingerprint
    presentation attack detection based on convolutional neural networks and short
    wave infrared imaging. In *2018 International Conference of the Biometrics Special
    Interest Group (BIOSIG)*. IEEE, 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Toosi et al. (2017a) Amirhosein Toosi, Sandro Cumani, and Andrea Bottino. 2017a.
    Assessing transfer learning on convolutional neural networks for patch-based fingerprint
    liveness detection. In *International Joint Conference on Computational Intelligence*.
    Springer, 263–279.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Toosi et al. (2017b) Amirhosein Toosi, Sandro Cumani, and Andrea Bottino. 2017b.
    CNN Patch-Based Voting for Fingerprint Liveness Detection.. In *IJCCI*. 158–165.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2015) Chenggang Wang, Ke Li, Zhihong Wu, and Qijun Zhao. 2015.
    A DCNN based fingerprint liveness detection algorithm with voting strategy. In
    *Chinese Conference on Biometric Recognition*. Springer, 241–249.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie and Yuille (2017) Lingxi Xie and Alan Yuille. 2017. Genetic cnn. In *Proceedings
    of the IEEE international conference on computer vision*. 1379–1388.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yambay et al. (2012) David Yambay, Luca Ghiani, Paolo Denti, Gian Luca Marcialis,
    Fabio Roli, and S Schuckers. 2012. LivDet 2011—Fingerprint liveness detection
    competition 2011\. In *2012 5th IAPR international conference on biometrics (ICB)*.
    IEEE, 208–215.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Wencheng Yang, Song Wang, Jiankun Hu, Guanglou Zheng, and
    Craig Valli. 2019. Security and accuracy of fingerprint-based biometrics: A review.
    *Symmetry* 11, 2 (2019), 141.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yau et al. (2008) Wei-Yun Yau, Hai-Linh Tran, and Eam-Khwang Teoh. 2008. Fake
    finger detection using an electrotactile display system. In *2008 10th International
    Conference on Control, Automation, Robotics and Vision*. IEEE, 962–966.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2019a) Chengsheng Yuan, Zhihua Xia, Leqi Jiang, Yi Cao, QM Jonathan
    Wu, and Xingming Sun. 2019a. Fingerprint liveness detection using an improved
    CNN with image scale equalization. *IEEE Access* 7 (2019), 26953–26966.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yuan et al. (2019b) Chengsheng Yuan, Zhihua Xia, Xingming Sun, and QM Jonathan
    Wu. 2019b. Deep residual network with adaptive learning framework for fingerprint
    liveness detection. *IEEE Transactions on Cognitive and Developmental Systems*
    12, 3 (2019), 461–473.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler and Fergus (2014) Matthew D Zeiler and Rob Fergus. 2014. Visualizing
    and understanding convolutional networks. In *European conference on computer
    vision*. Springer, 818–833.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2014) Yongliang Zhang, Shanshan Fang, Yu Xie, and Tingting Xu.
    2014. Fake fingerprint detection based on wavelet analysis and local binary pattern.
    In *Chinese Conference on Biometric Recognition*. Springer, 191–198.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2020) Yongliang Zhang, Shengyi Pan, Xiaosi Zhan, Zhiwei Li, Minghua
    Gao, and Chenhao Gao. 2020. FLDNet: light dense CNN for fingerprint liveness detection.
    *IEEE Access* 8 (2020), 84141–84152.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019) Yongliang Zhang, Daqiong Shi, Xiaosi Zhan, Di Cao, Keyi
    Zhu, and Zhiwei Li. 2019. Slim-ResCNN: A deep residual convolutional neural network
    for fingerprint liveness detection. *IEEE Access* 7 (2019), 91476–91487.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2016) Yongliang Zhang, Bing Zhou, Hongtao Wu, and Conglin Wen.
    2016. 2D fake fingerprint detection based on improved CNN and local descriptors
    for smart phone. In *Chinese Conference on Biometric Recognition*. Springer, 655–662.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2017) Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    2017. Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *Proceedings of the IEEE international conference on computer vision*. 2223–2232.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zoph et al. (2018) Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V
    Le. 2018. Learning transferable architectures for scalable image recognition.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*.
    8697–8710.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
