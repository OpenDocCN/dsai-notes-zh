- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '分类: 未分类'
- en: 'date: 2024-09-06 19:41:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:41:57'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2302.06611] Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2302.06611] 深度学习与医学影像在COVID-19诊断中的应用: 综合调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2302.06611](https://ar5iv.labs.arxiv.org/html/2302.06611)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2302.06611](https://ar5iv.labs.arxiv.org/html/2302.06611)
- en: 'Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '深度学习与医学影像在COVID-19诊断中的应用: 综合调查'
- en: Song Wu [SongWu.uestc@outlook.com](mailto:SongWu.uestc@outlook.com) [0000-0003-0147-1907](https://orcid.org/0000-0003-0147-1907
    "ORCID identifier") ,  Yazhou Ren [yazhou.ren@uestc.edu.cn](mailto:yazhou.ren@uestc.edu.cn)
    ,  Aodi Yang [aodi.yang@outlook.com](mailto:aodi.yang@outlook.com) ,  Xinyue Chen
    [martinachen2580@gmail.com](mailto:martinachen2580@gmail.com) ,  Xiaorong Pu [puxiaor@uestc.edu.cn](mailto:puxiaor@uestc.edu.cn)
    School of Computer Science and Engineering, Shenzhen Institute for Advanced Study,
    University of Electronic Science and Technology of ChinaChina ,  Jing He [lotusjing@gmail.com](mailto:lotusjing@gmail.com)
    Nuffield Department of Clinical Neurosciences, University of OxfordUK ,  Liqiang
    Nie [nieliqiang@gmail.com](mailto:nieliqiang@gmail.com) School of Computer Science
    and Technology, Harbin Institute of Technology (Shenzhen)China  and  Philip S.
    Yu [psyu@uic.edu](mailto:psyu@uic.edu) Department of Computer Science, University
    of Illinois at ChicagoUSA(2023)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 宋武 [SongWu.uestc@outlook.com](mailto:SongWu.uestc@outlook.com) [0000-0003-0147-1907](https://orcid.org/0000-0003-0147-1907
    "ORCID identifier") ，  任亚洲 [yazhou.ren@uestc.edu.cn](mailto:yazhou.ren@uestc.edu.cn)
    ，  杨傲迪 [aodi.yang@outlook.com](mailto:aodi.yang@outlook.com) ，  陈心悦 [martinachen2580@gmail.com](mailto:martinachen2580@gmail.com)
    ，  蒲晓荣 [puxiaor@uestc.edu.cn](mailto:puxiaor@uestc.edu.cn) 计算机科学与工程学院，深圳高级研究院，中国电子科技大学中国
    ，  何晶 [lotusjing@gmail.com](mailto:lotusjing@gmail.com) 牛津大学临床神经科学系英国 ，  聂李强 [nieliqiang@gmail.com](mailto:nieliqiang@gmail.com)
    计算机科学与技术学院，哈尔滨工业大学（深圳）中国  及  余平 [psyu@uic.edu](mailto:psyu@uic.edu) 伊利诺伊大学芝加哥分校计算机科学系美国（2023）
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: COVID-19 (Coronavirus disease 2019) has been quickly spreading since its outbreak,
    impacting financial markets and healthcare systems globally. Countries all around
    the world have adopted a number of extraordinary steps to restrict the spreading
    virus, where early COVID-19 diagnosis is essential. Medical images such as X-ray
    images and Computed Tomography scans are becoming one of the main diagnostic tools
    to combat COVID-19 with the aid of deep learning-based systems. In this survey,
    we investigate the main contributions of deep learning applications using medical
    images in fighting against COVID-19 from the aspects of image classification,
    lesion localization, and severity quantification, and review different deep learning
    architectures and some image preprocessing techniques for achieving a preciser
    diagnosis. We also provide a summary of the X-ray and CT image datasets used in
    various studies for COVID-19 detection. The key difficulties and potential applications
    of deep learning in fighting against COVID-19 are finally discussed. This work
    summarizes the latest methods of deep learning using medical images to diagnose
    COVID-19, highlighting the challenges and inspiring more studies to keep utilizing
    the advantages of deep learning to combat COVID-19.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: COVID-19（2019冠状病毒病）自爆发以来迅速传播，对全球金融市场和医疗系统产生了影响。世界各国已采取多项非常措施以限制病毒传播，其中早期COVID-19诊断至关重要。医学影像，如X光片和计算机断层扫描，正成为对抗COVID-19的主要诊断工具之一，借助深度学习系统的帮助。在这项调查中，我们从图像分类、病灶定位和严重程度量化等方面探讨了深度学习应用于医学影像在抗击COVID-19中的主要贡献，并回顾了不同的深度学习架构以及一些图像预处理技术，以实现更精确的诊断。我们还总结了用于COVID-19检测的X光和CT图像数据集。最后讨论了深度学习在抗击COVID-19中的关键困难和潜在应用。这项工作总结了使用医学影像进行COVID-19诊断的最新深度学习方法，突出了挑战，并激励更多的研究继续利用深度学习的优势来对抗COVID-19。
- en: 'Deep learning, Medical image, COVID-19^†^†copyright: acmcopyright^†^†journalyear:
    2023^†^†doi: XXXXXXX.XXXXXXX^†^†ccs: Computing methodologies Artificial intelligence^†^†ccs:
    Applied computing Life and medical sciences^†^†ccs: General and reference Surveys
    and overviews'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习、医学影像、COVID-19^†^†版权: acmcopyright^†^†期刊年份: 2023^†^†doi: XXXXXXX.XXXXXXX^†^†ccs:
    计算方法 人工智能^†^†ccs: 应用计算 生命和医学科学^†^†ccs: 一般和参考 调查与概述'
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: 'COVID-19 (Coronavirus Disease 2019), an acute respiratory infection caused
    by a novel coronavirus, was first reported in Wuhan, China, in December 2019 (Qin
    et al., [2020](#bib.bib139); Kannan et al., [2020](#bib.bib79)). It is highly
    contagious and the World Health Organization (WHO) declared that the outbreak
    was a Public Health Emergency of International Concern (PHEIC) on January 30,
    2020 and one and a half month later, a pandemic. The number of confirmed and death
    cases has increased rapidly since its outbreak as shown in Figure [1](#S1.F1 "Figure
    1 ‣ 1\. Introduction ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis:
    A Comprehensive Survey") (WHO, [2022](#bib.bib200)). As of July 31, 2022, more
    than 574 million confirmed cases and more than 6.3 million fatalities had been
    documented, severely impacting people’s daily lives. The healthcare systems of
    many countries are perilously close to collapse, and the world financial market
    is suffered a negative impact (Torales et al., [2020](#bib.bib188); Pak et al.,
    [2020](#bib.bib129); Nicola et al., [2020](#bib.bib127); Shorten et al., [2021](#bib.bib168)).
    To break the viral cycle of transmission, early screening and severity evaluation
    for COVID-19 patients are essential (Tayarani, [2020](#bib.bib186); Das et al.,
    [2022](#bib.bib37); Farhat et al., [2020](#bib.bib48)).'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 'COVID-19（2019冠状病毒病），一种由新型冠状病毒引起的急性呼吸道感染，首次于2019年12月在中国武汉报告（Qin et al., [2020](#bib.bib139);
    Kannan et al., [2020](#bib.bib79)）。它具有高度传染性，世界卫生组织（WHO）于2020年1月30日宣布此次疫情为国际关注的公共卫生紧急事件（PHEIC），一个半月后，宣布为全球大流行。从疫情爆发以来，确诊和死亡病例迅速增加，如图[1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Deep Learning and Medical Imaging for COVID-19
    Diagnosis: A Comprehensive Survey")所示（WHO, [2022](#bib.bib200)）。截至2022年7月31日，已记录超过5.74亿例确诊病例和超过630万例死亡病例，对人们的日常生活造成了严重影响。许多国家的医疗系统濒临崩溃，全球金融市场也遭受了负面影响（Torales
    et al., [2020](#bib.bib188); Pak et al., [2020](#bib.bib129); Nicola et al., [2020](#bib.bib127);
    Shorten et al., [2021](#bib.bib168)）。为了打破病毒传播的循环，早期筛查和COVID-19患者的严重性评估是至关重要的（Tayarani,
    [2020](#bib.bib186); Das et al., [2022](#bib.bib37); Farhat et al., [2020](#bib.bib48)）。'
- en: '![Refer to caption](img/ef06652579fed25cfa8d4ebd0941107a.png)'
  id: totrans-13
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ef06652579fed25cfa8d4ebd0941107a.png)'
- en: Figure 1\. The number of infections and deaths in the world, and the top 10
    infected countries (October 22, 2022).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 全球感染和死亡人数，以及前10个感染国家（2022年10月22日）。
- en: RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is a technology that
    combines reverse transcription (RT) of RNA and polymerase chain reaction (PCR)
    of cDNA (Mak et al., [2020](#bib.bib110); He et al., [2020](#bib.bib59)). Due
    to its high sensitivity, wide dynamic range, and accurate detection, the RT-PCR
    is widely used in identifying COVID-19 subjects (Singanayagam et al., [2020](#bib.bib172);
    Wu et al., [2020](#bib.bib201); Huggett et al., [2005](#bib.bib69)). It, however,
    has a lot of limitations. First, the quality of sample collection has a significant
    impact on RT-PCR results, and the false negative rate is extremely high (Shah
    et al., [2021a](#bib.bib155); Wang et al., [2020](#bib.bib198); Zhou et al., [2021c](#bib.bib228);
    Mukherjee et al., [2021](#bib.bib123)). Second, the reaction time for RT-PCR is
    generally lengthy, and the standards for testing certification are rather high
    (Rahman et al., [2021b](#bib.bib143)). Third, the suspected patients are vulnerable
    to cross-infection during the RT-PCR test, which will exacerbate the spreading
    virus (Alafif et al., [2021](#bib.bib9)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: RT-PCR（逆转录聚合酶链反应）是一种结合RNA的逆转录（RT）和cDNA的聚合酶链反应（PCR）技术（Mak et al., [2020](#bib.bib110);
    He et al., [2020](#bib.bib59)）。由于其高灵敏度、宽动态范围和准确检测，RT-PCR在识别COVID-19患者中被广泛使用（Singanayagam
    et al., [2020](#bib.bib172); Wu et al., [2020](#bib.bib201); Huggett et al., [2005](#bib.bib69)）。然而，它也有很多局限性。首先，样本采集质量对RT-PCR结果有显著影响，假阴性率极高（Shah
    et al., [2021a](#bib.bib155); Wang et al., [2020](#bib.bib198); Zhou et al., [2021c](#bib.bib228);
    Mukherjee et al., [2021](#bib.bib123)）。其次，RT-PCR的反应时间通常较长，测试认证标准相当高（Rahman et
    al., [2021b](#bib.bib143)）。第三，疑似患者在RT-PCR检测过程中容易交叉感染，这将加剧病毒传播（Alafif et al., [2021](#bib.bib9)）。
- en: To solve the above problem, medical imaging is an available diagnostic method,
    which can be regarded as an important complement to RT-PCR in COVID-19 detection.
    It can signal lesion manifestations of different infected levels, aiding doctors
    to make an appropriate diagnosis(Mei et al., [2020](#bib.bib112); Pascual et al.,
    [2021](#bib.bib130)). Meanwhile, many studies attempt to use deep learning technologies
    and medical imaging for COVID-19 early screening, which can greatly prevent the
    further spread of the epidemic. And the DL-based diagnostic methods have shown
    great potential in image classification, lesion localization and severity evaluation
    (Srivastava, [2022](#bib.bib178); Polat et al., [2021](#bib.bib135); Rahman et al.,
    [2021b](#bib.bib143); Alyasseri et al., [2022](#bib.bib11); Agrawal et al., [2022](#bib.bib5)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，医学成像是一种可用的诊断方法，可以被视为 COVID-19 检测中 RT-PCR 的重要补充。它可以显示不同感染程度的病变表现，帮助医生做出适当的诊断（Mei
    等，[2020](#bib.bib112)；Pascual 等，[2021](#bib.bib130)）。与此同时，许多研究尝试使用深度学习技术和医学成像进行
    COVID-19 的早期筛查，这可以大大防止疫情的进一步传播。而基于深度学习的诊断方法在图像分类、病变定位和严重程度评估方面显示出了巨大的潜力（Srivastava，[2022](#bib.bib178)；Polat
    等，[2021](#bib.bib135)；Rahman 等，[2021b](#bib.bib143)；Alyasseri 等，[2022](#bib.bib11)；Agrawal
    等，[2022](#bib.bib5)）。
- en: There are some surveys about using deep learning and medical imaging to fight
    against COVID-19 (Bhattacharya et al., [2021](#bib.bib26); Hryniewska et al.,
    [2021](#bib.bib64); Liu et al., [2022](#bib.bib102); Soomro et al., [2021](#bib.bib177)).
    Bhattacharya et al. (Bhattacharya et al., [2021](#bib.bib26)) summarize recent
    studies related to the applications of deep learning based on medical image processing
    and discuss their potential to combat COVID-19\. Hryniewska et al. (Hryniewska
    et al., [2021](#bib.bib64)) summarize the deep neural network methods using medical
    images for COVID-19 diagnosis and show how to use interpretable AI techniques
    in these models. Soomro et al. (Soomro et al., [2021](#bib.bib177)) perform the
    image analysis based on CT and X-rays images from both traditional image system
    and AI-system directions, and summarize the various applications of AI in COVID-19
    diagnosis. Liu et al. (Liu et al., [2022](#bib.bib102)) review existing deep learning
    models and medical image analysis methods for COVID-19 diagnosis, relating them
    to hot issues in deep learning research, including interpretable deep learning,
    and fair deep learning. While most of these surveys focus on the various applications
    of deep learning using medical images in fighting against COVID-19, there is a
    lack of discussion on how to utilize deep learning technologies to achieve a preciser
    diagnosis. Therefore, it is meaningful to summarize recent studies using deep
    learning and medical imaging to diagnose COVID-19, and explore how to utilize
    existing deep learning models to achieve more accurate diagnosis.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 关于使用深度学习和医学成像来对抗 COVID-19 的调查有一些（Bhattacharya 等，[2021](#bib.bib26)；Hryniewska
    等，[2021](#bib.bib64)；Liu 等，[2022](#bib.bib102)；Soomro 等，[2021](#bib.bib177)）。Bhattacharya
    等（Bhattacharya 等，[2021](#bib.bib26)）总结了与基于医学图像处理的深度学习应用相关的近期研究，并讨论了它们对抗 COVID-19
    的潜力。Hryniewska 等（Hryniewska 等，[2021](#bib.bib64)）总结了使用医学图像进行 COVID-19 诊断的深度神经网络方法，并展示了如何在这些模型中使用可解释的人工智能技术。Soomro
    等（Soomro 等，[2021](#bib.bib177)）基于 CT 和 X 射线图像进行图像分析，涵盖了传统图像系统和人工智能系统方向，并总结了人工智能在
    COVID-19 诊断中的各种应用。Liu 等（Liu 等，[2022](#bib.bib102)）回顾了现有的深度学习模型和医学图像分析方法，用于 COVID-19
    诊断，并将其与深度学习研究中的热点问题相关联，包括可解释的深度学习和公平的深度学习。虽然这些调查大多数集中于使用医学图像进行深度学习在抗击 COVID-19
    中的各种应用，但关于如何利用深度学习技术实现更精确的诊断的讨论仍然不足。因此，总结最近使用深度学习和医学成像来诊断 COVID-19 的研究，并探索如何利用现有的深度学习模型实现更准确的诊断是有意义的。
- en: 'The contributions of this paper are summarized as follows:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的贡献总结如下：
- en: $\bullet$
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: First, we gather open source medical image datasets used in various studies,
    which mainly contain CT and X-ray images, to assist new studies in finding relevant
    and reliable medical images quickly.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 首先，我们收集了在各种研究中使用的开源医学图像数据集，这些数据集主要包含 CT 和 X 射线图像，以帮助新研究快速找到相关和可靠的医学图像。
- en: $\bullet$
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Second, we systematically summarize various applications of deep learning using
    medical images for COVID-19 diagnosis. Different deep learning architectures and
    the methods used to improve the performance of deep models are reviewed.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第二，我们系统地总结了使用医学图像进行 COVID-19 诊断的各种深度学习应用。回顾了不同的深度学习架构以及用于提高深度模型性能的方法。
- en: $\bullet$
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Third, we discuss the limitations and future work of using deep learning techniques
    to diagnose COVID-19\. And we hope that deep learning can play a crucial role
    in fighting against COVID-19 in the future.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第三，我们讨论了使用深度学习技术诊断COVID-19的局限性和未来工作。我们希望深度学习在未来对抗COVID-19中能发挥关键作用。
- en: 2\. COVID-19 Dataset and Medical Image Manifestations
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. COVID-19数据集及医学图像表现
- en: Deep learning (DL) has demonstrated extraordinary capabilities in medical image
    processing. The performance of deep learning models, however, is significantly
    influenced by the quality of annotated data (Ker et al., [2017](#bib.bib83); Chen
    et al., [2021](#bib.bib34); Naudé, [2020](#bib.bib126)). A large amount of well-annotated
    data can improve network performance and avoid overfitting (Bhattacharya et al.,
    [2021](#bib.bib26); Zhou et al., [2021b](#bib.bib225)). Due to the sudden outbreak
    of the epidemic, the available datasets are limited and still in the development
    stage (Kim et al., [2021](#bib.bib87)). Hence, it is a difficult but significant
    work to collect open source medical image datasets. In this section, we summarize
    various medical image datasets used for COVID-19 diagnosis in different papers,
    mainly containing CT and X-ray images. Additionally, we describe the manifestations
    of CT and X-ray images as well as the lesion information provided by these images.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）在医学图像处理方面展示了卓越的能力。然而，深度学习模型的表现受注释数据质量的显著影响（Ker等，[2017](#bib.bib83)；Chen等，[2021](#bib.bib34)；Naudé，[2020](#bib.bib126)）。大量优质注释数据可以提高网络性能并避免过拟合（Bhattacharya等，[2021](#bib.bib26)；Zhou等，[2021b](#bib.bib225)）。由于疫情的突然爆发，现有的数据集有限且仍处于开发阶段（Kim等，[2021](#bib.bib87)）。因此，收集开源医学图像数据集是一项困难但重要的工作。在本节中，我们总结了不同论文中用于COVID-19诊断的各种医学图像数据集，主要包含CT和X光图像。此外，我们描述了CT和X光图像的表现及这些图像提供的病变信息。
- en: 2.1\. CT manifestations of COVID-19 and resource description
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1. COVID-19的CT表现及资源描述
- en: 'Computed tomography (CT) is one of the landmark advances in medical technology,
    providing radiologists with a useful imaging tool. Some pathological manifestations,
    such as ground glass opacity (GGO) and consolidation (C), are typically presenting
    in COVID-19 patients (Ye et al., [2020](#bib.bib209); Kwee and Kwee, [2020](#bib.bib96)).
    Additionally, chest CT images may show diverse radiological characteristics or
    patterns as the state of COVID-19 patients evolves. In the early stage of the
    disease, the lesions mainly are presented as ground glass opacity (GGO) and thickened
    small blood vessels. Consolidation may have occurred in some cases (Bao et al.,
    [2020](#bib.bib23)). The patients with severe disease start to develop into a
    reticular pattern with interlobular septal thickening, and consolidation shadows
    will appear in peripheral and central regions of their lungs (Li et al., [2021b](#bib.bib98)).
    When the patient’s condition deteriorates further, the white lung is visible in
    CT images and the lesions display multiple diffuse GGO and consolidation. Typical
    CT manifestations of COVID-19 patients are shown in Figure [2](#S2.F2 "Figure
    2 ‣ 2.1\. CT manifestations of COVID-19 and resource description ‣ 2\. COVID-19
    Dataset and Medical Image Manifestations ‣ Deep Learning and Medical Imaging for
    COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '计算机断层扫描（CT）是医学技术中的一项标志性进展，为放射科医师提供了有用的成像工具。一些病理表现，如“磨玻璃样”影（GGO）和实变（C），通常在COVID-19患者中出现（Ye等，[2020](#bib.bib209)；Kwee和Kwee，[2020](#bib.bib96)）。此外，胸部CT图像可能会随着COVID-19患者病情的发展显示出不同的放射特征或模式。在疾病的早期，病变主要表现为“磨玻璃样”影（GGO）和小血管的增厚。在某些情况下可能会发生实变（Bao等，[2020](#bib.bib23)）。严重的患者开始发展成网状模式，伴有肺叶间隔增厚，实变影将出现在肺部的外围和中央区域（Li等，[2021b](#bib.bib98)）。当患者的病情进一步恶化时，CT图像中可见白肺，病变表现为多发性弥漫性GGO和实变。COVID-19患者的典型CT表现见图[2](#S2.F2
    "Figure 2 ‣ 2.1\. CT manifestations of COVID-19 and resource description ‣ 2\.
    COVID-19 Dataset and Medical Image Manifestations ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey")。'
- en: Many studies attempt to diagnose COVID-19 using CT images because of the rich
    pathological manifestations they provide, and deep learning models based on CT
    images have demonstrated outstanding performance on COVID-19 diagnosis (Shi et al.,
    [2021b](#bib.bib163); Kiruthika et al., [2021](#bib.bib89); Shi et al., [2021a](#bib.bib164)).
    To explore these CT images, Nivetha et al. (Nivetha and Inbarani, [2022](#bib.bib128))
    use a public COVID-19 CT scan dataset, which contains 349 positive COVID-19 cases
    and 397 negative chest CT images. Their proposed NRNN model achieves the accuracy
    of 0.98, 0.92, 1.00, 1.00 respectively in the experiment. Choudhary et al. (Choudhary
    et al., [2022](#bib.bib35)) use a publicly available SARS-CoV2 CT-scan dataset,
    which consists of 1,252 positive COVID-19 cases and 1,230 negative chest CT images.
    Their pruned ResNet-34 model reaches 0.9547 accuracy, 0.9216 sensitivity, 0.9567
    F-score, and 0.9942 specificity. Ahrabi et al. (Sarv Ahrabi et al., [2022](#bib.bib149))
    establish a training dataset composed of 4,000 CT images of COVID-19 cases collected
    from more than 500 patients. Their proposed approach reaches 0.9712 accuracy,
    0.9741 precision, 0.9659 recall and 0.9696 F-score.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究尝试使用 CT 图像来诊断 COVID-19，因为这些图像提供了丰富的病理表现，而基于 CT 图像的深度学习模型在 COVID-19 诊断方面表现出色（Shi
    等， [2021b](#bib.bib163)；Kiruthika 等，[2021](#bib.bib89)；Shi 等，[2021a](#bib.bib164)）。为了探索这些
    CT 图像，Nivetha 等（Nivetha 和 Inbarani，[2022](#bib.bib128)）使用了一个公共的 COVID-19 CT 扫描数据集，其中包含
    349 个 COVID-19 阳性病例和 397 张阴性胸部 CT 图像。他们提出的 NRNN 模型在实验中分别达到了 0.98、0.92、1.00、1.00
    的准确率。Choudhary 等（Choudhary 等，[2022](#bib.bib35)）使用了一个公开的 SARS-CoV2 CT 扫描数据集，该数据集包含
    1,252 个 COVID-19 阳性病例和 1,230 张阴性胸部 CT 图像。他们修剪过的 ResNet-34 模型达到了 0.9547 的准确率、0.9216
    的灵敏度、0.9567 的 F-score 和 0.9942 的特异性。Ahrabi 等（Sarv Ahrabi 等，[2022](#bib.bib149)）建立了一个包含
    4,000 张 COVID-19 病例 CT 图像的训练数据集，这些图像来自 500 多名患者。他们提出的方法达到了 0.9712 的准确率、0.9741
    的精确度、0.9659 的召回率和 0.9696 的 F-score。
- en: '![Refer to caption](img/6ed66de528b4f0b09c169ae685806753.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6ed66de528b4f0b09c169ae685806753.png)'
- en: Figure 2\. Typical CT image manifestations of COVID-19 patients, including (a)
    GGO (b) Consolidation (c) Reticular pattern (d) Crazy paving pattern.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. COVID-19 患者的典型 CT 图像表现，包括 (a) GGO (b) 实变 (c) 网状模式 (d) 疯狂铺砖模式。
- en: 'Additionally, some of the most popular datasets come from authoritative hospitals.
    Song et al. (Song et al., [2021](#bib.bib176)) collect their dataset from three
    hospitals, i.e., Renmin Hospital of Wuhan University, and two affiliated hospitals
    of the Sun Yat-sen University in Guangzhou. Shi et al. (Shi et al., [2021b](#bib.bib163))
    build their dataset from three hospitals, i.e., Tongji Hospital of Huazhong University
    of Science and Technology, Shanghai Public Health Clinical Center of Fudan University,
    and China–Japan Union Hospital of Jilin University. In order to make it easier
    for new studies to obtain available and authoritative COVID-19 CT datasets, various
    datasets used in different papers are gathered and listed in Table [1](#S2.T1
    "Table 1 ‣ 2.1\. CT manifestations of COVID-19 and resource description ‣ 2\.
    COVID-19 Dataset and Medical Image Manifestations ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，一些最受欢迎的数据集来自权威医院。Song 等（Song 等，[2021](#bib.bib176)）从三家医院收集他们的数据集，即武汉大学人民医院和广州中山大学的两家附属医院。Shi
    等（Shi 等，[2021b](#bib.bib163)）从三家医院建立了他们的数据集，即华中科技大学同济医院、复旦大学上海公共卫生临床中心和吉林大学中日友好医院。为了方便新的研究获取可用和权威的
    COVID-19 CT 数据集，各种论文中使用的数据集被收集并列在表 [1](#S2.T1 "Table 1 ‣ 2.1\. CT manifestations
    of COVID-19 and resource description ‣ 2\. COVID-19 Dataset and Medical Image
    Manifestations ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey") 中。'
- en: Table 1\. A Summary of different datasets used in the papers for COVID-19 detection.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 用于 COVID-19 检测的不同数据集总结。
- en: '| Type | Dataset name | Dataset source | Papers |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 类型 | 数据集名称 | 数据集来源 | 论文 |'
- en: '| CT | SARS-COV-2 Ct-Scan Dataset | [https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset](https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset)
    | (Soares et al., [2020](#bib.bib175)) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| CT | SARS-COV-2 Ct-Scan 数据集 | [https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset](https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset)
    | (Soares 等，[2020](#bib.bib175)) |'
- en: '| CT | COVID-CT | [https://github.com/UCSD-AI4H/COVID-CT](https://github.com/UCSD-AI4H/COVID-CT)
    | (Yang et al., [2020](#bib.bib206)) |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| CT | COVID-CT | [https://github.com/UCSD-AI4H/COVID-CT](https://github.com/UCSD-AI4H/COVID-CT)
    | (Yang 等，[2020](#bib.bib206)) |'
- en: '| CT | COVIDx CT | [https://www.kaggle.com/datasets/hgunraj/covidxct](https://www.kaggle.com/datasets/hgunraj/covidxct)
    | (Gunraj et al., [2020](#bib.bib53)) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| CT | COVIDx CT | [https://www.kaggle.com/datasets/hgunraj/covidxct](https://www.kaggle.com/datasets/hgunraj/covidxct)
    | (Gunraj 等，[2020](#bib.bib53)) |'
- en: '| CT | Chest CT-Scan images Dataset | [https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images)
    | (Sarv Ahrabi et al., [2022](#bib.bib149)) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| CT | 胸部 CT 扫描图像数据集 | [https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images)
    | (Sarv Ahrabi 等，[2022](#bib.bib149)) |'
- en: '| CT | COVID-19 CT segmentation dataset | [http://medicalsegmentation.com/COVID19/](http://medicalsegmentation.com/COVID19/)
    | (Zhou et al., [2020](#bib.bib226)) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| CT | COVID-19 CT 分割数据集 | [http://medicalsegmentation.com/COVID19/](http://medicalsegmentation.com/COVID19/)
    | (Zhou 等，[2020](#bib.bib226)) |'
- en: '| CT | COVID-19 | [https://radiopaedia.org/articles/covid-19-3](https://radiopaedia.org/articles/covid-19-3)
    | (Apostolopoulos et al., [2020](#bib.bib16)) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| CT | COVID-19 | [https://radiopaedia.org/articles/covid-19-3](https://radiopaedia.org/articles/covid-19-3)
    | (Apostolopoulos 等，[2020](#bib.bib16)) |'
- en: '| CT | NSCC | [https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact](https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact)
    | (Wang et al., [2021a](#bib.bib197)) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| CT | NSCC | [https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact](https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact)
    | (Wang 等，[2021a](#bib.bib197)) |'
- en: '| X-ray | COVID-19 X rays | [https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays](https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays)
    | (Apostolopoulos and Bessiana, [2020](#bib.bib17)) |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | COVID-19 X 射线 | [https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays](https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays)
    | (Apostolopoulos 和 Bessiana，[2020](#bib.bib17)) |'
- en: '| X-ray | COVID-chestxray-dataset | [https://github.com/ieee8023/covid-chestxray-dataset](https://github.com/ieee8023/covid-chestxray-dataset)
    | (Yasar and Ceylan, [2021b](#bib.bib208); Cohen et al., [2020](#bib.bib36)) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | COVID 胸部 X 射线数据集 | [https://github.com/ieee8023/covid-chestxray-dataset](https://github.com/ieee8023/covid-chestxray-dataset)
    | (Yasar 和 Ceylan，[2021b](#bib.bib208); Cohen 等，[2020](#bib.bib36)) |'
- en: '| X-ray | Chest X-ray Images (Pneumonia) | [https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
    | (Miao et al., [2021](#bib.bib115)) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | 胸部 X 射线图像（肺炎） | [https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
    | (Miao 等，[2021](#bib.bib115)) |'
- en: '| X-ray | COVID-19 Radiography Database | [https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database)
    | (Al-Antari et al., [2021](#bib.bib8)) |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | COVID-19 放射数据库 | [https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database)
    | (Al-Antari 等，[2021](#bib.bib8)) |'
- en: '| X-ray | Open Source COVID-19 | [https://github.com/WeileiZeng/Open-Source-COVID-19](https://github.com/WeileiZeng/Open-Source-COVID-19)
    | (Shuja et al., [2021](#bib.bib169)) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | 开源 COVID-19 | [https://github.com/WeileiZeng/Open-Source-COVID-19](https://github.com/WeileiZeng/Open-Source-COVID-19)
    | (Shuja 等，[2021](#bib.bib169)) |'
- en: '| X-ray | RSNA Pneumonia Detection Challenge | [https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data)
    | (Dev et al., [2021](#bib.bib40)) |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | RSNA 肺炎检测挑战 | [https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data)
    | (Dev 等，[2021](#bib.bib40)) |'
- en: '| X-ray | ActualMed COVID-19 chest X-ray dataset | [https://github.com/agchung/Actualmed-COVID-chestxray-dataset](https://github.com/agchung/Actualmed-COVID-chestxray-dataset)
    | (Farooq and Hafeez, [2020](#bib.bib49)) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | ActualMed COVID-19 胸部 X 射线数据集 | [https://github.com/agchung/Actualmed-COVID-chestxray-dataset](https://github.com/agchung/Actualmed-COVID-chestxray-dataset)
    | (Farooq 和 Hafeez，[2020](#bib.bib49)) |'
- en: '| X-ray | COVID-19 database | [https://www.sirm.org/category/senza-categoria/COVID-19/](https://www.sirm.org/category/senza-categoria/COVID-19/)
    | (Hall et al., [2020](#bib.bib55)) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | COVID-19 数据库 | [https://www.sirm.org/category/senza-categoria/COVID-19/](https://www.sirm.org/category/senza-categoria/COVID-19/)
    | (Hall 等，[2020](#bib.bib55)) |'
- en: '| X-ray | COVID-CAPS | [https://github.com/ShahinSHH/COVID-CAPS](https://github.com/ShahinSHH/COVID-CAPS)
    | (Heidarian et al., [2021](#bib.bib62)) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | COVID-CAPS | [https://github.com/ShahinSHH/COVID-CAPS](https://github.com/ShahinSHH/COVID-CAPS)
    | (Heidarian 等，[2021](#bib.bib62)) |'
- en: '| X-ray | NIH Chest X-rays | [https://www.kaggle.com/datasets/nih-chest-xrays/data](https://www.kaggle.com/datasets/nih-chest-xrays/data)
    | (Basu et al., [2020](#bib.bib25)) |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| X-ray | NIH 胸部 X 射线 | [https://www.kaggle.com/datasets/nih-chest-xrays/data](https://www.kaggle.com/datasets/nih-chest-xrays/data)
    | (Basu 等，[2020](#bib.bib25)) |'
- en: '| X-ray | COVID-19 | [https://github.com/muhammedtalo/COVID-19](https://github.com/muhammedtalo/COVID-19)
    | (Brunese et al., [2020](#bib.bib28)) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| X 射线 | COVID-19 | [https://github.com/muhammedtalo/COVID-19](https://github.com/muhammedtalo/COVID-19)
    | (Brunese et al., [2020](#bib.bib28)) |'
- en: 2.2\. X-ray manifestations of COVID-19 and resource description
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. COVID-19 的 X 射线表现和资源描述
- en: 'Even though CT scans provide radiologists with more information about lesions,
    they are more expensive and expose the patients to more radiation. The normal
    and COVID-19 X-ray images are shown in Figure [3](#S2.F3 "Figure 3 ‣ 2.2\. X-ray
    manifestations of COVID-19 and resource description ‣ 2\. COVID-19 Dataset and
    Medical Image Manifestations ‣ Deep Learning and Medical Imaging for COVID-19
    Diagnosis: A Comprehensive Survey"). The peripheral lung opacity (PLO) and ground
    glass opacity (GGO) are two of these abnormalities (Kim et al., [2020](#bib.bib88);
    Jacobi et al., [2020](#bib.bib73)). The chest X-ray images of COVID-19 patients
    may seem normal in the early or mild stage. About 10 to 12 days later, symptoms
    become more obvious. The lesions are generally distributed among the lower, peripheral,
    and bilateral regions (Weinstock et al., [2020](#bib.bib199); Yoon et al., [2020](#bib.bib211)).
    In reference (Nagarajan et al., [2021](#bib.bib125)), they retrospectively evaluate
    X-ray images of 593 patients admitted to hospital with COVID-19\. The experiments
    demonstrate that abnormalities are mostly found in the middle and lower regions
    (88% of cases), and ground glass opacity (GGO) is the most common finding in abnormal
    X-rays (75% of cases). The next most common findings are peripheral lung opacity
    (PLO) and confluent consolidation, which generally indicate more severe symptoms.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管 CT 扫描为放射科医生提供了更多关于病变的信息，但它们更昂贵，并且让患者接触更多的辐射。正常与 COVID-19 的 X 射线图像见图 [3](#S2.F3
    "Figure 3 ‣ 2.2\. X-ray manifestations of COVID-19 and resource description ‣
    2\. COVID-19 Dataset and Medical Image Manifestations ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey")。外周肺部不透明（PLO）和磨玻璃样不透明（GGO）是这些异常表现中的两种（Kim
    et al., [2020](#bib.bib88); Jacobi et al., [2020](#bib.bib73)）。COVID-19 患者的胸部
    X 射线图像在早期或轻度阶段可能看起来正常。大约 10 到 12 天后，症状变得更加明显。病变通常分布在下部、外周和双侧区域（Weinstock et al.,
    [2020](#bib.bib199); Yoon et al., [2020](#bib.bib211)）。在参考文献 (Nagarajan et al.,
    [2021](#bib.bib125)) 中，他们回顾性地评估了 593 名 COVID-19 患者的 X 射线图像。实验表明，异常大多出现在中下部区域（88%
    的病例），磨玻璃样不透明（GGO）是异常 X 射线中最常见的发现（75% 的病例）。其次常见的发现是外周肺部不透明（PLO）和融合性实变，这通常表示症状较为严重。'
- en: '![Refer to caption](img/e1f61fdf8014ecf36acf73bf8b99f97c.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/e1f61fdf8014ecf36acf73bf8b99f97c.png)'
- en: Figure 3\. The representative X-ray images of COVID-19 cases and the normal
    cases.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. COVID-19 病例的代表性 X 射线图像与正常病例的比较。
- en: 'The X-ray image datasets are more available than CT image datasets because
    capturing X-ray images is more convenient and less expensive than CT images. Hence,
    many studies attempt to use X-ray images rather than CT scans to diagnose COVID-19
    (Shi et al., [2021a](#bib.bib164); Tang et al., [2021a](#bib.bib184)). Regarding
    these X-ray images, Dev et al. (Dev et al., [2021](#bib.bib40)) use the COVIDx
    dataset, which consists of 55,328 normal cases, 8,066 bacterial pneumonia cases
    and 358 COVID-19 cases. Their HCN-FM and HCN-DML reach 95.33% accuracy and 96.67%
    accuracy, respectively. Annavarapu et al. (Annavarapu et al., [2021](#bib.bib14))
    use a publicly accessible COVID-19 chest X-ray dataset, which consists of 2,905
    images. Their model obtains 95% accuracy and 97% specificity. Turkoglu (Turkoglu,
    [2021](#bib.bib190)) collects 6,092 X-ray images from a combination of public
    datasets. Their proposed model reaches 99.18% accuracy, surpassing most previous
    studies. Miao et al. (Miao et al., [2021](#bib.bib115)) use three public COVID-19
    X-ray datasets and other pneumonia datasets to construct two experimental datasets.
    Jain et al. (Jain et al., [2021](#bib.bib75)) collect 6,432 chest X-ray images
    from the Kaggle repository. Various COVID-19 X-ray datasets used in different
    papers are listed in Table [1](#S2.T1 "Table 1 ‣ 2.1\. CT manifestations of COVID-19
    and resource description ‣ 2\. COVID-19 Dataset and Medical Image Manifestations
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey")
    to facilitate new studies to quickly find available resources.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 'X 光图像数据集比 CT 图像数据集更易获取，因为拍摄 X 光图像比 CT 图像更方便且成本更低。因此，许多研究尝试使用 X 光图像而不是 CT 扫描来诊断
    COVID-19（Shi 等人，[2021a](#bib.bib164)；Tang 等人，[2021a](#bib.bib184)）。关于这些 X 光图像，Dev
    等人（Dev 等人，[2021](#bib.bib40)）使用 COVIDx 数据集，其中包含 55,328 个正常病例、8,066 个细菌性肺炎病例和 358
    个 COVID-19 病例。他们的 HCN-FM 和 HCN-DML 分别达到 95.33% 和 96.67% 的准确率。Annavarapu 等人（Annavarapu
    等人，[2021](#bib.bib14)）使用一个公开的 COVID-19 胸部 X 光数据集，该数据集包含 2,905 张图像。他们的模型获得了 95%
    的准确率和 97% 的特异性。Turkoglu（Turkoglu，[2021](#bib.bib190)）从多个公共数据集中收集了 6,092 张 X 光图像。他们提出的模型达到了
    99.18% 的准确率，超越了大多数先前的研究。Miao 等人（Miao 等人，[2021](#bib.bib115)）使用三个公开的 COVID-19 X
    光数据集和其他肺炎数据集构建了两个实验数据集。Jain 等人（Jain 等人，[2021](#bib.bib75)）从 Kaggle 仓库收集了 6,432
    张胸部 X 光图像。不同论文中使用的各种 COVID-19 X 光数据集列在表 [1](#S2.T1 "Table 1 ‣ 2.1\. CT manifestations
    of COVID-19 and resource description ‣ 2\. COVID-19 Dataset and Medical Image
    Manifestations ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey") 中，以便新的研究能够快速找到可用的资源。'
- en: 3\. Image Preprocessing Technologies
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3\. 图像预处理技术
- en: Most COVID-19 datasets contain some blurry, repetitive, and unrelated images,
    which will degrade the performance of deep model (Shah et al., [2021a](#bib.bib155)).
    Image preprocessing is generally the first step in diagnosing COVID-19 using deep
    learning technologies. It eliminates irrelevant information in the image and recovers
    useful and real information, thereby improving the reliability and performance
    of diagnostic algorithms (Loew, [2022](#bib.bib104); Heidari et al., [2020](#bib.bib61)).
    Nivetha et al. (Nivetha and Inbarani, [2022](#bib.bib128)) use the median filter
    for the CT images of COVID-19 patients from a publicly accessible dataset. In
    this manner, the quality of COVID images is improved, and the noise is reduced
    without losing important information. Joshi et al. (Joshi et al., [2022](#bib.bib78))
    resize all images to 224×224 to maintain data consistency. And four types of transformation
    are employed to preprocess images. Ahrabi et al. (Sarv Ahrabi et al., [2022](#bib.bib149))
    use 4,000 CT images of COVID-19 cases from two publicly accessible datasets. All
    the images are cropped and resized to remove irrelevant regions. In this section,
    we will discuss extensively utilized image preprocessing technologies and their
    characteristics.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数 COVID-19 数据集包含一些模糊、重复且无关的图像，这会降低深度模型的性能（Shah 等人，[2021a](#bib.bib155)）。图像预处理通常是利用深度学习技术诊断
    COVID-19 的第一步。它消除图像中的无关信息，恢复有用的真实信息，从而提高诊断算法的可靠性和性能（Loew，[2022](#bib.bib104)；Heidari
    等人，[2020](#bib.bib61)）。Nivetha 等人（Nivetha 和 Inbarani，[2022](#bib.bib128)）使用中值滤波器处理来自公开数据集的
    COVID-19 患者的 CT 图像。通过这种方式，COVID 图像的质量得到改善，噪声减少，同时重要信息没有丢失。Joshi 等人（Joshi 等人，[2022](#bib.bib78)）将所有图像调整为
    224×224 以保持数据一致性，并采用四种类型的变换来预处理图像。Ahrabi 等人（Sarv Ahrabi 等人，[2022](#bib.bib149)）使用来自两个公开数据集的
    4,000 张 COVID-19 CT 图像。所有图像都被裁剪和调整大小以去除无关区域。在这一部分，我们将深入讨论广泛使用的图像预处理技术及其特点。
- en: $\bullet$
  id: totrans-60
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Resizing
  id: totrans-61
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调整大小
- en: Resizing is an essential step for image preprocessing phase in the applications
    of deep learning. It uniforms the size of images from different datasets. Tao
    et al. (Zhou et al., [2021c](#bib.bib228)) resize all CT images to a uniform size
    (64×64) to build the COVID-19 dataset for model training. Shah et al. (Shah et al.,
    [2021b](#bib.bib156)) resize CT images from COVID-19 cases to 128×128×3 or 224×224×3
    to suit the input size of different deep models. Garain et al. (Garain et al.,
    [2021](#bib.bib50)) resize each image to a dimension of 32×32 and the images are
    converted to greyscale.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调整大小是深度学习应用中图像预处理阶段的一个重要步骤。它统一了来自不同数据集的图像大小。Tao 等人（Zhou et al., [2021c](#bib.bib228)）将所有
    CT 图像调整为统一大小（64×64），以建立用于模型训练的 COVID-19 数据集。Shah 等人（Shah et al., [2021b](#bib.bib156)）将
    COVID-19 病例的 CT 图像调整为 128×128×3 或 224×224×3，以适应不同深度模型的输入大小。Garain 等人（Garain et
    al., [2021](#bib.bib50)）将每张图像调整为 32×32 的尺寸，并将图像转换为灰度图。
- en: $\bullet$
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Flipping and Rotating
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 翻转和旋转
- en: Flipping and rotating are the commonly used data augmentation methods, which
    can guarantee that the deep learning model is trained with images at any angle
    and thus can make better prediction (Annavarapu et al., [2021](#bib.bib14)). And
    the sufficient images can also help deep model avoid overfitting. Sedik et al.
    (Sedik et al., [2022](#bib.bib152)) use a dataset consisting of 288 COVID-19 cases
    and 288 normal cases. The dataset is augmented by several rotations and scaling
    operations. Keles et al. (Keles et al., [2021](#bib.bib82)) employ three augmentation
    methods, including horizontal/vertical flipping, rotation and shifting. Ahuja
    et al. (Ahuja et al., [2021](#bib.bib6)) randomly rotate the training data between
    range [-90°, 90°] to resolve the overfitting problem.
  id: totrans-65
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 翻转和旋转是常用的数据增强方法，这可以确保深度学习模型以任何角度的图像进行训练，从而能够做出更好的预测（Annavarapu et al., [2021](#bib.bib14)）。充足的图像也可以帮助深度模型避免过拟合。Sedik
    等人（Sedik et al., [2022](#bib.bib152)）使用一个包含 288 例 COVID-19 病例和 288 例正常病例的数据集。数据集通过若干旋转和缩放操作进行增强。Keles
    等人（Keles et al., [2021](#bib.bib82)）采用了三种增强方法，包括水平/垂直翻转、旋转和移动。Ahuja 等人（Ahuja et
    al., [2021](#bib.bib6)）随机旋转训练数据，旋转范围在[-90°, 90°]之间，以解决过拟合问题。
- en: $\bullet$
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Cropping
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 裁剪
- en: Cropping refers to cropping the given image to remove irrelevant regions. It
    greatly reduces the interference of irrelevant information and largely increases
    the performance and robustness of deep learning models. Balaha et al. (Balaha
    et al., [2022](#bib.bib22)) preprocess the image data to a suitable format for
    CNN to further learn the latent features. The images are cropped using a bounding
    rectangle to reserve the region of interest. Madaan et al. (Madaan et al., [2021](#bib.bib107))
    use two chest X-ray image datasets in their model. Cropping is employed to reduce
    the noise and all images are resized. Zhang et al. (Zhang et al., [2021b](#bib.bib218))
    crop the rulers on the right side of the image and texts on the bottom of the
    image, which are irrelevant information and can impair the model performance.
  id: totrans-68
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 裁剪是指裁剪给定的图像以去除无关区域。它大大减少了无关信息的干扰，并大幅提高了深度学习模型的性能和鲁棒性。Balaha 等人（Balaha et al.,
    [2022](#bib.bib22)）将图像数据预处理为适合 CNN 的格式，以进一步学习潜在特征。图像使用边界矩形裁剪，以保留感兴趣区域。Madaan 等人（Madaan
    et al., [2021](#bib.bib107)）在其模型中使用了两个胸部 X 射线图像数据集。采用裁剪来减少噪声，并且所有图像都被调整大小。Zhang
    等人（Zhang et al., [2021b](#bib.bib218)）裁剪了图像右侧的标尺和底部的文字，这些都是无关信息，会影响模型性能。
- en: $\bullet$
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Contrast adjusting
  id: totrans-70
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对比度调整
- en: Medical images may have poor contrast during imaging process and data acquisition.
    It is essential to enhance image contrast to help deep models extract meaningful
    information from the region of interest. Dhaka et al. (Dhaka et al., [2021](#bib.bib41))
    propose that changing the contrast of X-ray images is capable of improving the
    performance of deep model. Tahir et al. (Tahir et al., [2022](#bib.bib181)) use
    contrast limited adaptive histogram equalization (CLAHE) to enhance the contrast
    of the original X-ray image. The produced images are more natural compared with
    other contrast enhancement methods. Habib et al. (Habib et al., [2022](#bib.bib54))
    use histogram equalization (HE) and CLAHE to enhance the contrast.
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 医学图像在成像过程和数据采集过程中可能对比度较差。增强图像对比度对于帮助深度模型从感兴趣区域提取有意义的信息至关重要。Dhaka 等人（Dhaka et
    al., [2021](#bib.bib41)）提出，通过改变 X 射线图像的对比度可以提高深度模型的性能。Tahir 等人（Tahir et al., [2022](#bib.bib181)）使用对比度限制自适应直方图均衡化（CLAHE）来增强原始
    X 射线图像的对比度。与其他对比度增强方法相比，产生的图像更自然。Habib 等人（Habib et al., [2022](#bib.bib54)）使用直方图均衡化（HE）和
    CLAHE 来增强对比度。
- en: $\bullet$
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Denoising
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 去噪
- en: Image noise means the unnecessary or unwanted interference information that
    exists in an image. Noise can seriously affect the quality of images. Hence, it
    is necessary to do denoising before the downstream image processing task. Mahendran
    et al. (Mahendran and Kavitha, [2022](#bib.bib109)) use DnCNN Algorithm to denoise
    CT Images before image classification. Balaha et al. (Balaha et al., [2022](#bib.bib22))
    convert all images to grayscale images and apply Gaussian blurring to eliminate
    unnecessary noise. Mishra et al. (Mishra, [2021](#bib.bib120)) use a Gaussian
    filter to smooth the image and the background noise can be eliminated via a two-dimensional
    median filter.
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像噪声指的是存在于图像中的不必要或不需要的干扰信息。噪声会严重影响图像的质量。因此，在下游图像处理任务之前，进行去噪是必要的。Mahendran 等（Mahendran
    和 Kavitha，[2022](#bib.bib109)）使用 DnCNN 算法在图像分类之前对 CT 图像进行去噪。Balaha 等（Balaha 等，[2022](#bib.bib22)）将所有图像转换为灰度图像，并应用高斯模糊以消除不必要的噪声。Mishra
    等（Mishra，[2021](#bib.bib120)）使用高斯滤波器对图像进行平滑处理，背景噪声可以通过二维中值滤波器进行消除。
- en: 'Applying appropriate preprocessing methods needs to consider multiple factors
    such as the size of the dataset, image quality, input of the model, and the application
    scenarios. We investigate various papers using deep learning and medical imaging
    to diagnose COVID over the past three years. We summarize the representative preprocessing
    technologies in Table [2](#S3.T2 "Table 2 ‣ 3\. Image Preprocessing Technologies
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 应用适当的预处理方法需要考虑多个因素，例如数据集的大小、图像质量、模型的输入以及应用场景。我们调查了过去三年中使用深度学习和医学成像来诊断 COVID
    的各种论文。我们在表 [2](#S3.T2 "表 2 ‣ 3\. 图像预处理技术 ‣ COVID-19 诊断的深度学习和医学成像：全面调查")中总结了具有代表性的预处理技术。
- en: Table 2\. A summary of various preprocessing techniques used in different papers.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2\. 各种预处理技术在不同论文中的总结。
- en: '| Preprocessing Method | Papers | Count |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 预处理方法 | 论文 | 数量 |'
- en: '| Resizing | (Nivetha and Inbarani, [2022](#bib.bib128); Khurana and Soni,
    [2022](#bib.bib86); Sarv Ahrabi et al., [2022](#bib.bib149); Kumari and Jagadesh,
    [2022](#bib.bib94); Balaha et al., [2022](#bib.bib22); Madaan et al., [2021](#bib.bib107);
    Zhou et al., [2021c](#bib.bib228); Shah et al., [2021b](#bib.bib156); Garain et al.,
    [2021](#bib.bib50); Mishra, [2021](#bib.bib120); Ravi et al., [2022](#bib.bib145);
    Annavarapu et al., [2021](#bib.bib14); Yasar and Ceylan, [2021a](#bib.bib207);
    Singh et al., [2021b](#bib.bib173); Zhang et al., [2021b](#bib.bib218); Abraham
    and Nair, [2022](#bib.bib2); Tan et al., [2021](#bib.bib183); Elpeltagy and Sallam,
    [2021](#bib.bib46); Dhaka et al., [2021](#bib.bib41); Ahuja et al., [2021](#bib.bib6);
    Zhang et al., [2021c](#bib.bib215); Shiri et al., [2022](#bib.bib166); Hasan et al.,
    [2021](#bib.bib58); Akbarimajd et al., [2022](#bib.bib7); Kogilavani et al., [2022](#bib.bib90);
    Baghdadi et al., [2022](#bib.bib21); Zhang et al., [2022b](#bib.bib216); Zhao
    et al., [2021b](#bib.bib221)) | 28 |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 调整大小 | (Nivetha 和 Inbarani，[2022](#bib.bib128)；Khurana 和 Soni，[2022](#bib.bib86)；Sarv
    Ahrabi 等，[2022](#bib.bib149)；Kumari 和 Jagadesh，[2022](#bib.bib94)；Balaha 等，[2022](#bib.bib22)；Madaan
    等，[2021](#bib.bib107)；Zhou 等，[2021c](#bib.bib228)；Shah 等，[2021b](#bib.bib156)；Garain
    等，[2021](#bib.bib50)；Mishra，[2021](#bib.bib120)；Ravi 等，[2022](#bib.bib145)；Annavarapu
    等，[2021](#bib.bib14)；Yasar 和 Ceylan，[2021a](#bib.bib207)；Singh 等，[2021b](#bib.bib173)；Zhang
    等，[2021b](#bib.bib218)；Abraham 和 Nair，[2022](#bib.bib2)；Tan 等，[2021](#bib.bib183)；Elpeltagy
    和 Sallam，[2021](#bib.bib46)；Dhaka 等，[2021](#bib.bib41)；Ahuja 等，[2021](#bib.bib6)；Zhang
    等，[2021c](#bib.bib215)；Shiri 等，[2022](#bib.bib166)；Hasan 等，[2021](#bib.bib58)；Akbarimajd
    等，[2022](#bib.bib7)；Kogilavani 等，[2022](#bib.bib90)；Baghdadi 等，[2022](#bib.bib21)；Zhang
    等，[2022b](#bib.bib216)；Zhao 等，[2021b](#bib.bib221)) | 28 |'
- en: '| Flipping and Rotating | (Joshi et al., [2022](#bib.bib78); Madaan et al.,
    [2021](#bib.bib107); Sedik et al., [2022](#bib.bib152); Mishra, [2021](#bib.bib120);
    Annavarapu et al., [2021](#bib.bib14); Heidarian et al., [2021](#bib.bib62); Zhang
    et al., [2021b](#bib.bib218); Keles et al., [2021](#bib.bib82); Jangam et al.,
    [2022](#bib.bib76); Huang et al., [2021a](#bib.bib68); Ahuja et al., [2021](#bib.bib6);
    Aslan et al., [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90); Baghdadi
    et al., [2022](#bib.bib21); Zhao et al., [2021b](#bib.bib221)) | 15 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 翻转与旋转 | (Joshi 等，[2022](#bib.bib78)；Madaan 等，[2021](#bib.bib107)；Sedik 等，[2022](#bib.bib152)；Mishra，[2021](#bib.bib120)；Annavarapu
    等，[2021](#bib.bib14)；Heidarian 等，[2021](#bib.bib62)；Zhang 等，[2021b](#bib.bib218)；Keles
    等，[2021](#bib.bib82)；Jangam 等，[2022](#bib.bib76)；Huang 等，[2021a](#bib.bib68)；Ahuja
    等，[2021](#bib.bib6)；Aslan 等，[2022](#bib.bib18)；Kogilavani 等，[2022](#bib.bib90)；Baghdadi
    等，[2022](#bib.bib21)；Zhao 等，[2021b](#bib.bib221)) | 15 |'
- en: '| Cropping | (Sarv Ahrabi et al., [2022](#bib.bib149); Balaha et al., [2022](#bib.bib22);
    Madaan et al., [2021](#bib.bib107); Mishra, [2021](#bib.bib120); Zhang et al.,
    [2021b](#bib.bib218); Jangam et al., [2022](#bib.bib76); Shiri et al., [2022](#bib.bib166);
    Aslan et al., [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90); Zhang
    et al., [2022b](#bib.bib216); Lian et al., [2022](#bib.bib100)) | 11 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| 裁剪 | (Sarv Ahrabi et al., [2022](#bib.bib149); Balaha et al., [2022](#bib.bib22);
    Madaan et al., [2021](#bib.bib107); Mishra, [2021](#bib.bib120); Zhang et al.,
    [2021b](#bib.bib218); Jangam et al., [2022](#bib.bib76); Shiri et al., [2022](#bib.bib166);
    Aslan et al., [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90); Zhang
    et al., [2022b](#bib.bib216); Lian et al., [2022](#bib.bib100)) | 11 |'
- en: '| Contrast adjusting | (Tahir et al., [2022](#bib.bib181); Habib et al., [2022](#bib.bib54);
    Mishra, [2021](#bib.bib120); Dhaka et al., [2021](#bib.bib41); Baghdadi et al.,
    [2022](#bib.bib21)) | 5 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 对比度调整 | (Tahir et al., [2022](#bib.bib181); Habib et al., [2022](#bib.bib54);
    Mishra, [2021](#bib.bib120); Dhaka et al., [2021](#bib.bib41); Baghdadi et al.,
    [2022](#bib.bib21)) | 5 |'
- en: '| Denoising | (Nivetha and Inbarani, [2022](#bib.bib128); Mahendran and Kavitha,
    [2022](#bib.bib109); Balaha et al., [2022](#bib.bib22); Mishra, [2021](#bib.bib120);
    Zhang et al., [2022b](#bib.bib216)) | 5 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 去噪 | (Nivetha and Inbarani, [2022](#bib.bib128); Mahendran and Kavitha, [2022](#bib.bib109);
    Balaha et al., [2022](#bib.bib22); Mishra, [2021](#bib.bib120); Zhang et al.,
    [2022b](#bib.bib216)) | 5 |'
- en: 4\. Image Segmentation
  id: totrans-83
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 图像分割
- en: Accurate segmentation of lung and infection in medical images of COVID-19 patients
    plays a crucial role in the diagnosis of COVID-19 patients (Ma et al., [2021](#bib.bib106);
    Shiri et al., [2022](#bib.bib166)). In specific, image segmentation identifies
    the region of interest (RoI) from given medical images and divides the medical
    image into several parts (Liu et al., [2021](#bib.bib103); Zhao et al., [2019](#bib.bib222)).
    The segmented region can aid doctors and deep learning models more comfortably
    to understand lung disease type and severity (Ter-Sarkisov, [2022](#bib.bib187);
    Khan et al., [2022](#bib.bib84); Shi et al., [2020](#bib.bib162)). Punn et al.
    (Punn and Agarwal, [2022](#bib.bib138)) propose a deep learning based semantic
    hierarchical segmenter (CHS-Net) to identify the COVID-19 infected regions from
    chest CT images. They apply a residual inception U-Net model with spectral spatial
    and depth attention network (SSD) to effectively encode and decode the semantic
    and varying image information, and finally segment the COVID-19 infected regions
    in the lungs. Wang et al. (Wang et al., [2021b](#bib.bib196)) propose a lesion
    edge detection model (COVID Edge-Net), which consists of one edge detection backbone
    and two novel modules, i.e., the multi-scale residual dual attention (MSRDA) module
    and the Canny operator module. The MSRDA module can capture rich contextual associations
    to generate enhanced feature representations, which are then merged with Canny
    features learned from the Canny operator module to extract more accurate, clearer,
    and sharper edges.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在COVID-19患者的医疗图像中，肺部及感染的准确分割在COVID-19的诊断中起着至关重要的作用（Ma et al., [2021](#bib.bib106);
    Shiri et al., [2022](#bib.bib166)）。具体来说，图像分割从给定的医疗图像中识别感兴趣区域（RoI），并将医疗图像划分为多个部分（Liu
    et al., [2021](#bib.bib103); Zhao et al., [2019](#bib.bib222)）。分割出的区域可以帮助医生和深度学习模型更好地理解肺部疾病的类型和严重程度（Ter-Sarkisov,
    [2022](#bib.bib187); Khan et al., [2022](#bib.bib84); Shi et al., [2020](#bib.bib162)）。Punn
    et al.（Punn and Agarwal, [2022](#bib.bib138)）提出了一种基于深度学习的语义层次分割器（CHS-Net），用于从胸部CT图像中识别COVID-19感染区域。他们应用了一个带有光谱空间和深度注意力网络（SSD）的残差Inception
    U-Net模型，以有效地编码和解码语义和变化的图像信息，最终分割出肺部的COVID-19感染区域。Wang et al.（Wang et al., [2021b](#bib.bib196)）提出了一种病灶边缘检测模型（COVID
    Edge-Net），它由一个边缘检测骨干网和两个新颖模块组成，即多尺度残差双重注意力（MSRDA）模块和Canny算子模块。MSRDA模块可以捕捉丰富的上下文关联，生成增强的特征表示，然后与从Canny算子模块中学习到的Canny特征合并，以提取更准确、更清晰、更锐利的边缘。
- en: Chen et al. (Chen et al., [2022](#bib.bib33)) propose a segmentation network
    based on unsupervised domain adaptation (UDA) to improve the segmentation performance
    of the infected regions in CT images. The generalization ability of the segmentation
    network is significantly enhanced by a novel domain adaption module that aligns
    the two domains. Their proposed method achieves high performance in lung segmentation,
    and it is proved that their proposed model is also suitable for large-area organs
    or tissues. Lashchenova et al. (Lashchenova et al., [2021](#bib.bib97)) argue
    that an important factor affecting the real performance of the segmentation model
    is that the model segments the puncta (connected components) of lung and the lung
    lesions outside the real lung. To detect this, connected components are computed
    for every class and for each component to found whether it has interception with
    ground-truth lungs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: Chen等（Chen et al., [2022](#bib.bib33)）提出了一种基于无监督领域适应（UDA）的分割网络，以提高CT图像中感染区域的分割性能。通过一种新颖的领域适应模块，该网络显著提高了分割网络的泛化能力，使两个领域对齐。他们提出的方法在肺部分割中表现出色，并证明他们提出的模型也适用于大面积器官或组织。Lashchenova等（Lashchenova
    et al., [2021](#bib.bib97)）认为，影响分割模型实际性能的一个重要因素是模型将肺部和真实肺部之外的肺病灶分割开来。为检测这一点，需要计算每个类别的连通组件，并检查每个组件是否与真实肺部有交集。
- en: 4.1\. U-net Architecture
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. U-net架构
- en: 'U-net is a popular image segmentation network which is developed primarily
    for medical image segmentation. It is built based on Convolutional Neural Network
    (CNN) and is upgraded to achieve better segmentation performance (Shirato et al.,
    [2020](#bib.bib165); Minaee et al., [2022](#bib.bib119); Siddique et al., [2021](#bib.bib170)).
    As shown in Figure [4](#S4.F4 "Figure 4 ‣ 4.1\. U-net Architecture ‣ 4\. Image
    Segmentation ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey"), the U-Net (Ronneberger et al., [2015](#bib.bib146)) network is U-shaped,
    mainly including the downsampling layer on the left and the upsampling process
    on the right. The structure is symmetrical from left to right. Additionally, the
    encoder-decoder structure and skip connection used by U-Net are core designs to
    achieve a more effective combination of contextual information to make precise
    pixel-level judgments.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: U-net 是一个流行的图像分割网络，主要用于医学图像分割。它基于卷积神经网络（CNN）构建，并进行了升级，以实现更好的分割性能（Shirato et
    al., [2020](#bib.bib165); Minaee et al., [2022](#bib.bib119); Siddique et al.,
    [2021](#bib.bib170)）。如图[4](#S4.F4 "图 4 ‣ 4.1\. U-net 架构 ‣ 4\. 图像分割 ‣ COVID-19
    诊断的深度学习与医学影像：综合调查")所示，U-Net（Ronneberger et al., [2015](#bib.bib146)）网络呈U形，主要包括左侧的下采样层和右侧的上采样过程。结构从左到右对称。此外，U-Net
    使用的编码器-解码器结构和跳跃连接是核心设计，用于实现上下文信息的更有效组合，以进行精确的像素级判断。
- en: Alirr (Alirr, [2022](#bib.bib10)) designs a lung image segmentation method to
    extract the region of interest, which modifies U-net with upgraded residual block
    including concatenation skip connection. Additionally, the segmented region employs
    edge enhancing diffusion filtering (EED) to improve the infection area’s contrast.
    Their proposed method achieves Dice overlapping score of 96.1% and 78.0% for lung
    and infection areas segmentation. Diniz et al. (Diniz et al., [2021](#bib.bib42))
    seek to automatically identify infections caused by COVID-19 and evaluate quantitative
    score of the infected region. They propose a model by modifying the traditional
    U-net architecture via batch normalization, leaky ReLU, dropout, and residual
    block techniques. Their model yields an average Dice value of 77.1% and an average
    specificity of 99.8%.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: Alirr（Alirr, [2022](#bib.bib10)）设计了一种肺部图像分割方法，以提取感兴趣区域，该方法通过升级的残差块和连接跳跃连接修改了U-net。此外，分割区域采用边缘增强扩散滤波（EED）来提高感染区域的对比度。他们提出的方法在肺部和感染区域分割中的Dice重叠评分分别为96.1%和78.0%。Diniz等（Diniz
    et al., [2021](#bib.bib42)）旨在自动识别COVID-19引起的感染并评估感染区域的定量分数。他们通过批归一化、泄漏ReLU、dropout和残差块技术修改了传统的U-net架构，提出了一个模型。该模型的平均Dice值为77.1%，平均特异性为99.8%。
- en: '![Refer to caption](img/1636f17858c3e1e4c731453036d7f97e.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/1636f17858c3e1e4c731453036d7f97e.png)'
- en: Figure 4\. Representative U-net architecture for image segmentation task (Ronneberger
    et al., [2015](#bib.bib146)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 用于图像分割任务的代表性U-net架构（Ronneberger et al., [2015](#bib.bib146)）。
- en: Zhao et al. (Zhao et al., [2021b](#bib.bib221)) propose a novel dilated dual
    attention U-Net (D2A U-Net) with the dual attention strategy and hybrid dilated
    convolutions to segment COVID-19 lesion region. The former dual attention strategy,
    which contains two attention modules, is used to enhance feature maps and reduce
    the semantic gap among diverse levels of feature maps. The latter hybrid dilated
    convolutions are used for achieving larger receptive fields. Their proposed method
    achieves 0.73 Dice score and 0.71 recall score. Lian et al. (Lian et al., [2022](#bib.bib100))
    propose an end-to-end DRD U-Net (dilated residual and deeply supervised U-Net)
    network to segment the lung lesions. They add residual modules to each layer of
    channel to accelerate convergence and avoid gradient disappearance. To extract
    richer feature information, the extended convolution unit is utilized to increase
    the receptive field without increasing the number of parameters. In the experiments,
    their proposed model shows impressive segmentation performance and the error can
    be significantly reduced compared with the original U-Net.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 赵等人(Zhao等人，[2021b](#bib.bib221)) 提出了一种新颖的扩张双重注意力U-Net(D2A U-Net)来分割COVID-19病灶区域，采用双重注意力策略和混合扩张卷积。前述的双重注意力策略包含两个注意力模块，用于增强特征图并减小不同级别特征图之间的语义差异。后者的混合扩张卷积用于获得更大的感受野。他们的方法达到了0.73的Dice分数和0.71的召回分数。Lian等人(Lian等人，[2022](#bib.bib100))
    提出了一种端对端DRD U-Net(扩张残差和深度监督U-Net)网络，用于分割肺部病变。他们在每个通道层添加了残差模块以加速收敛和避免梯度消失。为了提取更丰富的特征信息，他们利用扩展卷积单元来增加感受野而不增加参数数量。在实验中，他们的模型表现出令人印象深刻的分割性能，与原始U-Net相比，错误显著减少。
- en: 'U-net has shown great potential in the field of image segmentation. Some variants
    that follow the core idea of U-net have been proposed, including attention U-net
    (Schlemper et al., [2019](#bib.bib151)), and Residual U-net (Das et al., [2019](#bib.bib38)),
    to complete more complex segmentation tasks. In addition to U-Net architecture,
    other segmentation methods such as V-Net, ResU-Net, Dense-Net, and DeepLab, are
    also used for the segmentation of COVID-19 infected region in different papers.
    Table [3](#S4.T3 "Table 3 ‣ 4.1\. U-net Architecture ‣ 4\. Image Segmentation
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey")
    displays the various segmentation techniques employed by different papers.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 'U-net在图像分割领域展现了巨大的潜力。一些遵循U-net核心思想的变体已经被提出，包括注意力U-net(Schlemper等人，[2019](#bib.bib151))和残差U-net(Das等人，[2019](#bib.bib38))，用于完成更复杂的分割任务。除了U-Net架构外，其他分割方法，如V-Net、ResU-Net、Dense-Net和DeepLab，也被用于不同论文中COVID-19感染区域的分割。表[3](#S4.T3
    "Table 3 ‣ 4.1\. U-net Architecture ‣ 4\. Image Segmentation ‣ Deep Learning and
    Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey")显示了不同论文采用的各种分割技术。'
- en: Table 3\. A summary of various segmentation methods used in different papers.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 表3。不同论文中使用的各种分割方法总结。
- en: '| Segmentation methods | Papers | Count |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 分割方法 | 论文 | 数量 |'
- en: '| U-Net | (Ma et al., [2021](#bib.bib106); Lashchenova et al., [2021](#bib.bib97);
    Diniz et al., [2021](#bib.bib42); Xiao et al., [2022](#bib.bib202); Voulodimos
    et al., [2021a](#bib.bib194); Jadhav et al., [2021](#bib.bib74); Avetisian et al.,
    [2021](#bib.bib20); Punn and Agarwal, [2022](#bib.bib138); Alirr, [2022](#bib.bib10);
    Zhou et al., [2021a](#bib.bib227); Elharrouss et al., [2022](#bib.bib45); Kuchana
    et al., [2021](#bib.bib93); Trivizakis et al., [2020](#bib.bib189); Shan et al.,
    [2021](#bib.bib158); Tahir et al., [2022](#bib.bib181); Saood, [2021](#bib.bib148);
    Lian et al., [2022](#bib.bib100); Voulodimos et al., [2021b](#bib.bib195)) | 18
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| U-Net | (马等人，[2021](#bib.bib106); Lashchenova等人，[2021](#bib.bib97); Diniz等人，[2021](#bib.bib42);
    萧等人，[2022](#bib.bib202); Voulodimos等人，[2021a](#bib.bib194); Jadhav等人，[2021](#bib.bib74);
    Avetisian等人，[2021](#bib.bib20); Punn和Agarwal，[2022](#bib.bib138); Alirr，[2022](#bib.bib10);
    周等人，[2021a](#bib.bib227); Elharrouss等人，[2022](#bib.bib45); Kuchana等人，[2021](#bib.bib93);
    Trivizakis等人，[2020](#bib.bib189); Shan等人，[2021](#bib.bib158); Tahir等人，[2022](#bib.bib181);
    Saood，[2021](#bib.bib148); Lian等人，[2022](#bib.bib100); Voulodimos等人，[2021b](#bib.bib195))
    | 18 |'
- en: '| V-Net | (Voulodimos et al., [2021a](#bib.bib194); Zhao et al., [2021a](#bib.bib220);
    Milletari et al., [2016](#bib.bib118)) | 3 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| V-Net | (Voulodimos等人，[2021a](#bib.bib194); 赵等人，[2021a](#bib.bib220); Milletari等人，[2016](#bib.bib118))
    | 3 |'
- en: '| ResU-Net | (Diniz et al., [2021](#bib.bib42); Jadhav et al., [2021](#bib.bib74);
    Avetisian et al., [2021](#bib.bib20)) | 3 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| ResU-Net | (Diniz等人，[2021](#bib.bib42); Jadhav等人，[2021](#bib.bib74); Avetisian等人，[2021](#bib.bib20))
    | 3 |'
- en: '| Dense-Net | (Al-Antari et al., [2021](#bib.bib8); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| Dense-Net | (Al-Antari等人，[2021](#bib.bib8); Elharrouss等人，[2022](#bib.bib45))
    | 2 |'
- en: '| UNet++ | (Zhou et al., [2021a](#bib.bib227); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| UNet++ | (Zhou et al., [2021a](#bib.bib227); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
- en: '| Deeplab | (Diniz et al., [2021](#bib.bib42); Amin et al., [2022](#bib.bib13))
    | 2 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| Deeplab | (Diniz et al., [2021](#bib.bib42); Amin et al., [2022](#bib.bib13))
    | 2 |'
- en: '| Attention-UNet | (Zhao et al., [2021b](#bib.bib221); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Attention-UNet | (Zhao et al., [2021b](#bib.bib221); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
- en: '| SAUNet++ | (Xiao et al., [2022](#bib.bib202)) | 1 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| SAUNet++ | (Xiao et al., [2022](#bib.bib202)) | 1 |'
- en: '| COVSeg-NET | (Zhang et al., [2021c](#bib.bib215)) | 1 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| COVSeg-NET | (Zhang et al., [2021c](#bib.bib215)) | 1 |'
- en: 4.2\. Loss Function
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2. 损失函数
- en: The loss function is another important component of the segmentation model.
    It can guide the segmentation model to learn towards a specific direction and
    segment the wanted infected area. Xiao et al. (Xiao et al., [2022](#bib.bib202))
    use focal Tversky loss (FTL) and the generalized Dice loss (GDL). The GDL can
    reduce the correlation between lesion size and Dice loss, and can effectively
    guide the model in segmenting small regions. Elharrouss et al. (Elharrouss et al.,
    [2022](#bib.bib45)) use binary cross entropy as loss function and their model
    reaches 78.6% for Dice, 71.1% for sensitivity metric, 99.3% for specificity, and
    85.6% for precision. Alirr (Alirr, [2022](#bib.bib10)) uses Dice loss as loss
    function and averages the DSC of each class to generate the final score. Diniz
    et al. (Diniz et al., [2021](#bib.bib42)) use Dice loss as loss function and their
    proposed model reaches 77.1% for Dice, and 99.76% for average specificity. This
    section will introduce several representative loss functions commonly used in
    the medical image segmentation task.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 损失函数是分割模型的另一个重要组成部分。它可以指导分割模型朝特定方向学习，并分割所需的感染区域。Xiao et al. (Xiao et al., [2022](#bib.bib202))
    使用了聚焦 Tversky 损失 (FTL) 和广义 Dice 损失 (GDL)。GDL 可以减少病变大小与 Dice 损失之间的相关性，并有效指导模型分割小区域。Elharrouss
    et al. (Elharrouss et al., [2022](#bib.bib45)) 使用二元交叉熵作为损失函数，他们的模型在 Dice 上达到了
    78.6%，在敏感度指标上达到了 71.1%，在特异性上达到了 99.3%，在精度上达到了 85.6%。Alirr (Alirr, [2022](#bib.bib10))
    使用 Dice 损失作为损失函数，并平均每个类别的 DSC 以生成最终得分。Diniz et al. (Diniz et al., [2021](#bib.bib42))
    使用 Dice 损失作为损失函数，他们提出的模型在 Dice 上达到了 77.1%，在平均特异性上达到了 99.76%。本节将介绍几种在医学图像分割任务中常用的具有代表性的损失函数。
- en: A. Binary Cross Entropy
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: A. 二元交叉熵
- en: 'The pixel level cross entropy loss is commonly used in image segmentation task.
    For a given random variable, this loss function will examine each pixel individually
    and compare the difference between two probability distributions. Binary cross
    entropy is defined as (Yi-de et al., [2004](#bib.bib210)):'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 像素级交叉熵损失通常用于图像分割任务。对于给定的随机变量，这个损失函数将逐个像素检查，并比较两个概率分布之间的差异。二元交叉熵定义为 (Yi-de et
    al., [2004](#bib.bib210))：
- en: '| (1) |  | $L_{CE}(y,\hat{y})=-\left(y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $L_{CE}(y,\hat{y})=-\left(y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
- en: where $y$ and $\hat{y}$ represent the ground truth value and predicted value
    respectively.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $y$ 和 $\hat{y}$ 分别表示真实值和预测值。
- en: B. Weighted Binary Cross Entropy
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: B. 加权二元交叉熵
- en: 'Weighted binary cross entropy (WCE) (Pihur et al., [2007](#bib.bib134)) is
    a variant of binary cross entropy, which aims to solve the problem of uneven distribution
    of lesion information in medical image. WCE is defined as:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 加权二元交叉熵 (WCE) (Pihur et al., [2007](#bib.bib134)) 是二元交叉熵的一种变体，旨在解决医学图像中病变信息分布不均的问题。WCE
    定义为：
- en: '| (2) |  | $L_{WCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $L_{WCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
- en: where $\beta$ is used to tune false negative and false positive. If we want
    to decrease the number of false negative, set $\beta$¿1\. In contrast, setting
    $\beta$¡1 can decrease the number of false positive.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\beta$ 用于调整假阴性和假阳性。如果我们想减少假阴性的数量，可以将 $\beta$ 设置为 >1。相反，将 $\beta$ 设置为 <1
    可以减少假阳性的数量。
- en: C.Balanced Cross Entropy
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: C. 平衡交叉熵
- en: 'Balanced cross entropy (BCE) (Xie and Tu, [2015](#bib.bib203)) is similar with
    WCE, which appropriately weights positive examples and negative examples. Balanced
    cross entropy is defined as:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 平衡交叉熵 (BCE) (Xie and Tu, [2015](#bib.bib203)) 与 WCE 类似，它对正例和负例进行适当加权。平衡交叉熵定义为：
- en: '| (3) |  | $L_{BCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+(1-\beta)\left(1-y\right)\log\left(1-\hat{y}\right)\right).$
    |  |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $L_{BCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+(1-\beta)\left(1-y\right)\log\left(1-\hat{y}\right)\right).$
    |  |'
- en: D. Focal Loss
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: D. 聚焦损失
- en: 'Focal loss (Lin et al., [2017](#bib.bib101)) is often used to deal with unbalanced
    sample classification. It focuses on weighting loss to the sample according to
    the difficulty of sample discrimination. For medical images presenting small lesion
    information, focal loss assigns a larger weight to positive pixels and can achieve
    excellent performance. It is defined as:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Focal 损失（Lin 等，[2017](#bib.bib101)）常用于处理样本分类不平衡的问题。它通过根据样本区分难度来加权损失。对于呈现小病灶信息的医学图像，focal
    损失为正像素分配更大的权重，可以取得优异的表现。其定义为：
- en: '| (4) |  | $L_{fl}=-\alpha_{t}\left(1-p_{t}\right)^{\gamma}\log\left(p_{t}\right),$
    |  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $L_{fl}=-\alpha_{t}\left(1-p_{t}\right)^{\gamma}\log\left(p_{t}\right),$
    |  |'
- en: 'where $\gamma$ is a regulatory parameter and $\gamma$¿0\. $\alpha_{t}$ generally
    ranges from [0,1], which is used to deal with class imbalance. Focal loss defines
    $p_{t}$ as:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\gamma$ 是一个调节参数，且 $\gamma > 0$。$\alpha_{t}$ 通常范围在 [0,1] 之间，用于处理类别不平衡。Focal
    损失定义 $p_{t}$ 为：
- en: '| (5) |  | $p_{t}=\begin{cases}\hat{p}&amp;\text{ if }y=1\\ 1-\hat{p}&amp;\text{
    otherwise }\end{cases},$ |  |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| (5) |  | $p_{t}=\begin{cases}\hat{p}&\text{ if }y=1\\ 1-\hat{p}&\text{ otherwise
    }\end{cases},$ |  |'
- en: where $\hat{p}$ represents the predicted value of pixel classification and $y$
    denotes the ground truth value.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\hat{p}$ 表示像素分类的预测值，$y$ 表示真实值。
- en: E. Dice Loss
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: E. Dice 损失
- en: 'Dice loss (Sudre et al., [2017](#bib.bib179)) is designed to calculate the
    similarity between two images and is utilized to guide the training process of
    image segmentation methods. Dice loss is defined as:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: Dice 损失（Sudre 等，[2017](#bib.bib179)）用于计算两幅图像之间的相似性，并用于指导图像分割方法的训练过程。Dice 损失定义为：
- en: '| (6) |  | $DL(y,\hat{p})=1-\frac{2y\hat{p}+1}{y+\hat{p}+1}.$ |  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $DL(y,\hat{p})=1-\frac{2y\hat{p}+1}{y+\hat{p}+1}.$ |  |'
- en: Here, 1 is added in numerator and denominator to ensure that the function is
    not undefined in edge case scenarios where $y=\hat{p}=0$.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 在分子和分母中添加 1 以确保在 $y=\hat{p}=0$ 的边界情况下函数不至于未定义。
- en: F. Generalized Dice Loss
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: F. 广义 Dice 损失
- en: 'Dice loss is unsuitable to predict small targets. When some pixels of small
    targets are predicted incorrectly, Dice coefficient may greatly fluctuate. To
    solve these problems, GDL uses weights inversely proportional to lesion region,
    in order to better segment small regions (Xiao et al., [2022](#bib.bib202)). When
    the number of classes is 2, Generalized Dice loss is defined as:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Dice 损失不适合预测小目标。当小目标的一些像素被错误预测时，Dice 系数可能会大幅波动。为了解决这些问题，GDL 使用与病灶区域成反比的权重，以更好地分割小区域（Xiao
    等，[2022](#bib.bib202)）。当类别数为 2 时，广义 Dice 损失定义为：
- en: '| (7) |  | $GDL=1-2\frac{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}p_{l_{n}}}{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}+p_{l_{n}}},$
    |  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $GDL=1-2\frac{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}p_{l_{n}}}{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}+p_{l_{n}}},$
    |  |'
- en: 'where $r_{ln}\in\{0,1\}$ and $p_{l_{n}}\in[0,1]$ denote the true voxel values
    of $n$-th position and the related probability predicted as class $l$. $w_{l}$
    represents the weight of class $l$ and is defined as:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $r_{ln}\in\{0,1\}$ 和 $p_{l_{n}}\in[0,1]$ 分别表示第 $n$ 个位置的真实体素值和预测为类别 $l$ 的相关概率。$w_{l}$
    代表类别 $l$ 的权重，定义为：
- en: '| (8) |  | $w_{l}=\frac{1}{\left(\sum_{n=1}^{N}r_{ln}\right)^{2}+\varepsilon},$
    |  |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| (8) |  | $w_{l}=\frac{1}{\left(\sum_{n=1}^{N}r_{ln}\right)^{2}+\varepsilon},$
    |  |'
- en: where $N$ is the total number of pixels, and $\varepsilon$ is often set as $10^{-5}$
    to prevent the loss function from dividing by 0.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $N$ 是像素的总数，$\varepsilon$ 通常设置为 $10^{-5}$ 以防止损失函数除以 0。
- en: G. Tversky Loss
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: G. Tversky 损失
- en: 'Tversky loss (Salehi et al., [2017](#bib.bib147)) is considered as a generalization
    of Dice loss, where the coefficient $\beta$ is a hyperparameter that controls
    the balance between false negative (FN) and false positive (FP). Tversky loss
    is defined as:'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Tversky 损失（Salehi 等，[2017](#bib.bib147)）被认为是 Dice 损失的一个推广，其中系数 $\beta$ 是一个超参数，用于控制假阴性
    (FN) 和假阳性 (FP) 之间的平衡。Tversky 损失定义为：
- en: '| (9) |  | $TL(p,\hat{p})=\frac{p\hat{p}}{p\hat{p}+\beta(1-p)\hat{p}+(1-\beta)p(1-\hat{p})},$
    |  |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| (9) |  | $TL(p,\hat{p})=\frac{p\hat{p}}{p\hat{p}+\beta(1-p)\hat{p}+(1-\beta)p(1-\hat{p})},$
    |  |'
- en: where $p$ and $\hat{p}$ denote the ground truth value and predicted value respectively.
    When $\beta$ = 0.5, it can be solved into regular Dice coefficient.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p$ 和 $\hat{p}$ 分别表示真实值和预测值。当 $\beta$ = 0.5 时，可以化简为常规的 Dice 系数。
- en: H. Focal Tversky Loss
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: H. Focal Tversky 损失
- en: 'Similar to focal loss, focal Tversky loss (Abraham and Khan, [2019](#bib.bib3))
    is proposed to deal with class imbalance. It focuses on learning hard samples
    with the help of coefficient $\gamma$. Focal Tversky loss is often used to segment
    small regions and is defined as:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于焦点损失，焦点Tversky损失（Abraham and Khan, [2019](#bib.bib3)）被提出用于处理类别不平衡。它利用系数$\gamma$来专注于学习困难样本。焦点Tversky损失常用于小区域的分割，其定义为：
- en: '| (10) |  | $FTL=\sum_{c}\left(1-TI_{c}\right)^{\gamma},$ |  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| (10) |  | $FTL=\sum_{c}\left(1-TI_{c}\right)^{\gamma},$ |  |'
- en: 'where the hyperparameter $\gamma$ can range from [1,3], and $TI_{c}$ (Tversky
    index) is defined as:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其中超参数$\gamma$的范围可以是[1,3]，$TI_{c}$（Tversky指数）定义为：
- en: '| (11) |  | $TI_{c}=\frac{\sum_{i=1}^{N}p_{ic}g_{ic}}{\sum_{i=1}^{N}p_{ic}g_{ic}+\alpha\sum_{i=1}^{N}p_{i\bar{c}}g_{ic}+\beta\sum_{i=1}^{N}p_{ic}g_{i\bar{c}}},$
    |  |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| (11) |  | $TI_{c}=\frac{\sum_{i=1}^{N}p_{ic}g_{ic}}{\sum_{i=1}^{N}p_{ic}g_{ic}+\alpha\sum_{i=1}^{N}p_{i\bar{c}}g_{ic}+\beta\sum_{i=1}^{N}p_{ic}g_{i\bar{c}}},$
    |  |'
- en: where $p_{ic}$ and $p_{i\bar{c}}$ are probabilities that pixel $i$ belongs to
    the lesion class $c$ and non-lesion class $\bar{c}$, respectively. $g_{ic}$ and
    $g_{i\bar{c}}$ represent probabilities for another class. $N$ is the total number
    of pixels.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$p_{ic}$和$p_{i\bar{c}}$分别是像素$i$属于病灶类别$c$和非病灶类别$\bar{c}$的概率。$g_{ic}$和$g_{i\bar{c}}$表示另一类别的概率。$N$是像素的总数。
- en: 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 基于深度学习的COVID-19诊断方法的总体分析
- en: Manual detection of COVID-19 (RT-PCR), which has extremely high accuracy and
    specificity, is always regarded as the gold standard for COVID-19 detection (Pu
    et al., [2022](#bib.bib137); Rabaan et al., [2021](#bib.bib141)). However, RT-PCR
    is time-consuming, and the spread risk and susceptibility of the disease are greatly
    increased during detection (Rahman et al., [2021b](#bib.bib143); Peng et al.,
    [2022](#bib.bib133)). Hence, many studies are focusing on diagnosing COVID-19
    using medical images, attempting to find a diagnostic method that can guarantee
    high accuracy and significantly minimize human contact during detection (Krishnamoorthy
    et al., [2021](#bib.bib91); Xu et al., [2022](#bib.bib204); Ibrahim et al., [2021](#bib.bib71);
    Shorfuzzaman, [2021](#bib.bib167)). Among the many inspection methods, the deep
    learning models using medical images have shown excellent performance. And they
    are thus extensively utilized in image classification, lesion segmentation, and
    severity quantification to fight against COVID-19, such as Convolutional Neural
    Network (CNN) (Singh et al., [2021a](#bib.bib174); Pouyanfar et al., [2018](#bib.bib136);
    Rahman et al., [2021a](#bib.bib142)), Generative Adversarial Network (GAN) (Bargshady
    et al., [2022](#bib.bib24); Kim et al., [2021](#bib.bib87)), and Long Short-Term
    Memory (LSTM) (Demir, [2021](#bib.bib39); Naeem and Bin-Salem, [2021](#bib.bib124);
    Sheykhivand et al., [2021](#bib.bib161)). In this section, we will introduce the
    different applications of deep learning models in diagnosing COVID-19.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: COVID-19的手动检测（RT-PCR），具有极高的准确性和特异性，始终被认为是COVID-19检测的金标准（Pu et al., [2022](#bib.bib137);
    Rabaan et al., [2021](#bib.bib141)）。然而，RT-PCR检测过程耗时较长，并且在检测过程中疾病的传播风险和易感性大大增加（Rahman
    et al., [2021b](#bib.bib143); Peng et al., [2022](#bib.bib133)）。因此，许多研究专注于使用医学影像进行COVID-19诊断，试图找到一种可以保证高准确性并显著减少检测过程中人为接触的诊断方法（Krishnamoorthy
    et al., [2021](#bib.bib91); Xu et al., [2022](#bib.bib204); Ibrahim et al., [2021](#bib.bib71);
    Shorfuzzaman, [2021](#bib.bib167)）。在众多检测方法中，使用医学影像的深度学习模型表现出色，因此广泛应用于图像分类、病灶分割和严重程度量化，以对抗COVID-19，例如卷积神经网络（CNN）（Singh
    et al., [2021a](#bib.bib174); Pouyanfar et al., [2018](#bib.bib136); Rahman et
    al., [2021a](#bib.bib142)）、生成对抗网络（GAN）（Bargshady et al., [2022](#bib.bib24); Kim
    et al., [2021](#bib.bib87)）和长短期记忆网络（LSTM）（Demir, [2021](#bib.bib39); Naeem and
    Bin-Salem, [2021](#bib.bib124); Sheykhivand et al., [2021](#bib.bib161)）。在本节中，我们将介绍深度学习模型在COVID-19诊断中的不同应用。
- en: 5.1\. CNN models for COVID-19 diagnosis
  id: totrans-145
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. COVID-19诊断中的CNN模型
- en: 'Convolutional Neural Network (CNN) is a multi-layer supervised neural network,
    in which the hidden convolutional and pooling layers are the core modules to realize
    the feature extraction function (Anwar et al., [2018](#bib.bib15); Alzubaidi et al.,
    [2021](#bib.bib12)). CNN uses the gradient descent method to minimize the loss
    function and error back propagation (BP) is employed to reversely adjust the weight
    parameters in the network layer by layer (Mishra and Kane, [2022](#bib.bib121)).
    CNN models have demonstrated great potential in medical image processing and become
    a popular approach for identifying COVID-19 and localizing lesion. As Figure [5](#S5.F5
    "Figure 5 ‣ 5.1\. CNN models for COVID-19 diagnosis ‣ 5\. Overall Analysis of
    DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical Imaging for
    COVID-19 Diagnosis: A Comprehensive Survey") depicts, a representative CNN model
    for COVID-19 diagnosis generally includes input, convolutional layers, pooling
    layers, fully connected layer, and output (Bhattacharya et al., [2021](#bib.bib26)).
    Additionally, we try to record some deep learning methods and model evaluation
    metrics used in high quality studies and more detailed information is shown in
    Table [4](#S5.T4 "Table 4 ‣ 5.1\. CNN models for COVID-19 diagnosis ‣ 5\. Overall
    Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是一种多层有监督的神经网络，其中隐藏的卷积层和池化层是实现特征提取功能的核心模块（Anwar et al., [2018](#bib.bib15);
    Alzubaidi et al., [2021](#bib.bib12)）。CNN 使用梯度下降法来最小化损失函数，并采用误差反向传播（BP）逐层调整网络层中的权重参数（Mishra
    and Kane, [2022](#bib.bib121)）。CNN 模型在医学图像处理方面展现了巨大潜力，成为识别 COVID-19 和定位病变的流行方法。如图
    [5](#S5.F5 "图 5 ‣ 5.1\. CNN 模型用于 COVID-19 诊断 ‣ 5\. 基于 DL 的 COVID-19 诊断方法的整体分析
    ‣ 深度学习与医学影像用于 COVID-19 诊断：综合调查") 所示，代表性的 CNN 模型用于 COVID-19 诊断通常包括输入、卷积层、池化层、全连接层和输出（Bhattacharya
    et al., [2021](#bib.bib26)）。此外，我们尝试记录一些高质量研究中使用的深度学习方法和模型评估指标，更多详细信息见表 [4](#S5.T4
    "表 4 ‣ 5.1\. CNN 模型用于 COVID-19 诊断 ‣ 5\. 基于 DL 的 COVID-19 诊断方法的整体分析 ‣ 深度学习与医学影像用于
    COVID-19 诊断：综合调查")。
- en: Wang et al. (Wang et al., [2020](#bib.bib198)) design a deep learning-based
    method for automatic COVID-19 diagnosis. Their model uses a pre-trained U-Net
    to segment the lung region. The segmented 3D lung region is input into the 3D
    deep neural network to predict the possibility of infection. Finally, the activation
    regions in the classification network and the unsupervised connected components
    are together used to localize the COVID-19 lesions. Their proposed method obtains
    an accuracy of 0.90, a positive predictive value of 0.84, and a high negative
    predictive value of 0.98\. Turkoglu (Turkoglu, [2021](#bib.bib190)) proposes an
    expert-designed system named COVIDetectioNet, which is consisted of three basic
    components. First, deep features are obtained from the pre-trained AlexNet architecture.
    Second, the relief selection algorithm is employed to select the most efficient
    features from the pre-learned deep features. Third, the support vector machine
    (SVM) method is used for final classification. Their proposed model is validated
    by classifying 6,092 X-ray images as normal (healthy), COVID-19, and pneumonia
    cases, respectively. In the experimental results, their proposed model achieves
    99.18% accuracy and 97.1% sensitivity.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: Wang 等（Wang et al., [2020](#bib.bib198)）设计了一种基于深度学习的自动 COVID-19 诊断方法。他们的模型使用预训练的
    U-Net 对肺部区域进行分割。分割后的 3D 肺部区域输入到 3D 深度神经网络中，以预测感染的可能性。最后，分类网络中的激活区域与无监督的连通组件一起用于定位
    COVID-19 病变。他们提出的方法获得了 0.90 的准确率，0.84 的阳性预测值，以及 0.98 的高阴性预测值。Turkoglu（Turkoglu,
    [2021](#bib.bib190)）提出了一种名为 COVIDetectioNet 的专家设计系统，该系统由三个基本组件组成。首先，从预训练的 AlexNet
    架构中获得深度特征。其次，采用 relief 选择算法从预先学习的深度特征中选择最有效的特征。第三，使用支持向量机（SVM）方法进行最终分类。他们提出的模型通过将
    6,092 张 X 射线图像分类为正常（健康）、COVID-19 和肺炎病例来进行验证。在实验结果中，他们提出的模型达到了 99.18% 的准确率和 97.1%
    的灵敏度。
- en: '![Refer to caption](img/b090ca312d9291b7b5c80108c9239f61.png)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b090ca312d9291b7b5c80108c9239f61.png)'
- en: Figure 5\. A representative workflow of using CNN model to identify COVID-19
    cases from normal cases.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 使用 CNN 模型识别 COVID-19 与正常病例的代表性工作流程。
- en: Singh et al. (Singh et al., [2021a](#bib.bib174)) propose an automated COVID-19
    screening model. It employs some pre-trained CNN models such as DenseNet201, ResNet152V2,
    and VGG16, for early detection of COVID-19 patients. The predicted outputs are
    fed into the ensemble DCCNs, which are designed for diagnosing the suspected objects
    into four classes, including COVID-19 cases, tuberculosis, pneumonia, and healthy
    subjects. Their proposed model achieves 98.94% accuracy, 98.94% sensitivity and
    98.93% specificity, which is superior to the competitive models. Moreover, Aslan
    et al. (Aslan et al., [2022](#bib.bib18)) firstly use ANN-based automated segmentation
    method to extract region of interest in the X-ray images. Second, various CNNs
    are used for feature extraction after data augmentation stage. Third, the features
    learned from each CNN model are input to four different machine learning (ML)
    algorithms for classification. The hyperparameters of each ML algorithm are determined
    by Bayesian optimization. Finally, the highest performance is obtained by the
    DenseNet201 model with SVM algorithm.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: Singh 等人 (Singh et al., [2021a](#bib.bib174)) 提出了一个自动化的 COVID-19 筛查模型。该模型采用一些预训练的
    CNN 模型，如 DenseNet201、ResNet152V2 和 VGG16，用于早期检测 COVID-19 患者。预测输出被输入到集成 DCCNs 中，这些
    DCCNs 设计用于将怀疑对象诊断为四个类别，包括 COVID-19 病例、结核病、肺炎和健康受试者。他们提出的模型达到了 98.94% 的准确率、98.94%
    的敏感性和 98.93% 的特异性，优于竞争模型。此外，Aslan 等人 (Aslan et al., [2022](#bib.bib18)) 首次使用基于
    ANN 的自动分割方法来提取 X 射线图像中的感兴趣区域。其次，在数据增强阶段后使用各种 CNN 进行特征提取。最后，将每个 CNN 模型学到的特征输入到四种不同的机器学习
    (ML) 算法中进行分类。每种 ML 算法的超参数通过贝叶斯优化确定。最终，DenseNet201 模型与 SVM 算法获得了最高性能。
- en: Kogilavani et al. (Kogilavani et al., [2022](#bib.bib90)) explore the performance
    of a variety of convolutional neural network (CNN) models in detecting COVID-19,
    attempting to find the suitable deep models, including VGG16, DeseNet121, MobileNet,
    NASNet, Xception, and EfficientNet. Accuracy obtained for VGG16 is 97.68%, DenseNet121
    is 97.53%, MobileNet is 96.38%, NASNet is 89.51%, Xception is 92.47%, and EfficientNet
    is 80.19%, respectively. Based on the performance analyses, it is demonstrated
    that the VGG16 architecture reaches the best accuracy compared to other architectures.
    Akbarimajd et al. (Akbarimajd et al., [2022](#bib.bib7)) propose a novel CNN approach
    applying adaptive convolution, which intends to enhance COVID-19 identification
    in noisy X-ray images without reducing noise. Specifically, the impulse noise-map
    layer and the adaptive resizing layer are added on the traditional CNN framework.
    A learning-to-augment strategy which uses noisy X-ray images is designed to improve
    the generalization of deep model. Some pre-trained networks such as SqueezeNet,
    ResNet18, and ResNet50 are modified to increase their robustness for impulse noise.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: Kogilavani 等人 (Kogilavani et al., [2022](#bib.bib90)) 探讨了各种卷积神经网络 (CNN) 模型在检测
    COVID-19 中的表现，尝试找到合适的深度模型，包括 VGG16、DenseNet121、MobileNet、NASNet、Xception 和 EfficientNet。VGG16
    的准确率为 97.68%，DenseNet121 为 97.53%，MobileNet 为 96.38%，NASNet 为 89.51%，Xception
    为 92.47%，而 EfficientNet 为 80.19%。根据性能分析，VGG16 架构相较于其他架构达到了最佳准确率。Akbarimajd 等人
    (Akbarimajd et al., [2022](#bib.bib7)) 提出了一个新颖的 CNN 方法，应用自适应卷积，旨在提升噪声 X 射线图像中的
    COVID-19 识别能力，而不减少噪声。具体来说，在传统 CNN 框架上添加了冲击噪声图层和自适应调整图层。设计了一种利用噪声 X 射线图像的学习增强策略，以改善深度模型的泛化能力。一些预训练的网络如
    SqueezeNet、ResNet18 和 ResNet50 被修改以提高对冲击噪声的鲁棒性。
- en: Table 4\. Deep learning methods and result evaluation for diagnosing COVID-19
    using CNN models.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4\. 使用 CNN 模型诊断 COVID-19 的深度学习方法及结果评估。
- en: '| Reference | Data | Deep Learning Methods | Classification | Acc | Sn | Sp
    |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 数据 | 深度学习方法 | 分类 | 准确率 | 敏感性 | 特异性 |'
- en: '| Tang et al. (Tang et al., [2021a](#bib.bib184)) | X-ray | Ensemble learning,
    COVID-Net | Multiclass | 95.0% | 96.0% | — |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Tang 等人 (Tang et al., [2021a](#bib.bib184)) | X 射线 | 集成学习，COVID-Net | 多类别
    | 95.0% | 96.0% | — |'
- en: '| Yamaç et al. (Yamaç et al., [2021](#bib.bib205)) | X-ray | CheXNet, CSEN
    | Multiclass | 95.9% | 98.5% | 95.7% |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| Yamaç 等人 (Yamaç et al., [2021](#bib.bib205)) | X 射线 | CheXNet, CSEN | 多类别
    | 95.9% | 98.5% | 95.7% |'
- en: '| Pathak et al. (Pathak et al., [2020](#bib.bib131)) | CT | CNN, Transfer learning
    | Binary | 93.0% | 91.5% | 94.9% |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Pathak 等人 (Pathak et al., [2020](#bib.bib131)) | CT | CNN，迁移学习 | 二分类 | 93.0%
    | 91.5% | 94.9% |'
- en: '| Rathinasamy et al. (R et al., [2022](#bib.bib140)) | X-ray | CNN, Ensemble
    learning | Binary | 99.0% | — | — |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Rathinasamy 等人 (R et al., [2022](#bib.bib140)) | X 射线 | CNN，集成学习 | 二分类 |
    99.0% | — | — |'
- en: '| Khan et al. (Khan et al., [2021](#bib.bib85)) | X-ray | COVID-RENet, SVM
    | Binary | 98.5% | 99.0% | — |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Khan 等人（Khan et al., [2021](#bib.bib85)） | X射线 | COVID-RENet、SVM | 二分类 |
    98.5% | 99.0% | — |'
- en: '| Wang et al. (Wang et al., [2020](#bib.bib198)) | CT | DeCoVNet, U-net | Binary
    | 90.1% | 90.7% | 91.1% |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人（Wang et al., [2020](#bib.bib198)） | CT | DeCoVNet、U-net | 二分类 | 90.1%
    | 90.7% | 91.1% |'
- en: '| Zhou et al. (Zhou et al., [2021c](#bib.bib228)) | CT | AlexNet, GoogleNet,
    ResNet, Ensemble learning | Multiclass | 99.1% | 99.1% | 99.6% |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人（Zhou et al., [2021c](#bib.bib228)） | CT | AlexNet、GoogleNet、ResNet、集成学习
    | 多类别 | 99.1% | 99.1% | 99.6% |'
- en: '| Zheng et al. (Zheng et al., [2022](#bib.bib223)) | CT | ResNet50, MAB, FAB
    | Binary | 98.2% | 98.8% | 97.3% |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Zheng 等人（Zheng et al., [2022](#bib.bib223)） | CT | ResNet50、MAB、FAB | 二分类
    | 98.2% | 98.8% | 97.3% |'
- en: '| Choudhary et al. (Choudhary et al., [2022](#bib.bib35)) | CT | VGG16, ResNet34
    | Binary | 95.5% | 92.2% | 99.4% |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| Choudhary 等人（Choudhary et al., [2022](#bib.bib35)） | CT | VGG16、ResNet34
    | 二分类 | 95.5% | 92.2% | 99.4% |'
- en: '| Singh et al. (Singh et al., [2021a](#bib.bib174)) | CT | CNN, Ensemble learning,
    Transfer learning | Multiclass | 98.8% | 98.8% | 98.8% |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Singh 等人（Singh et al., [2021a](#bib.bib174)） | CT | CNN、集成学习、迁移学习 | 多类别 |
    98.8% | 98.8% | 98.8% |'
- en: '| Balaha et al. (Balaha et al., [2022](#bib.bib22)) | CT | CNN, Transfer learning,
    GAN | Binary | 98.7% | — | — |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| Balaha 等人（Balaha et al., [2022](#bib.bib22)） | CT | CNN、迁移学习、GAN | 二分类 |
    98.7% | — | — |'
- en: '| Turkoglu (Turkoglu, [2021](#bib.bib190)) | X-ray | AlexNet, Transfer learning,
    SVM | Multiclass | 99.2% | 97.1% | — |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Turkoglu（Turkoglu, [2021](#bib.bib190)） | X射线 | AlexNet、迁移学习、SVM | 多类别 |
    99.2% | 97.1% | — |'
- en: '| Aslan et al. (Aslan et al., [2022](#bib.bib18)) | X-ray | CNN, Transfer learning,
    Bayesian Optimization | Multiclass | 96.3% | 96.4% | 98.1% |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Aslan 等人（Aslan et al., [2022](#bib.bib18)） | X射线 | CNN、迁移学习、贝叶斯优化 | 多类别 |
    96.3% | 96.4% | 98.1% |'
- en: '| Zhang et al. (Zhang et al., [2022b](#bib.bib216)) | CT | CNN, Transfer learning,
    Bayesian Optimization | Binary | 92.1% | — | 91.2% |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等人（Zhang et al., [2022b](#bib.bib216)） | CT | CNN、迁移学习、贝叶斯优化 | 二分类
    | 92.1% | — | 91.2% |'
- en: 'Some existing convolutional neural network architectures have been proven to
    be vital in medical image feature extraction, such as ResNet (He et al., [2016](#bib.bib60)),
    AlexNet (Krizhevsky et al., [2017](#bib.bib92)), SqueezeNet (Iandola et al., [2016](#bib.bib70)),
    Inception (Szegedy et al., [2015](#bib.bib180)), DenseNet (Huang et al., [2017](#bib.bib65)),
    VGG (Simonyan and Zisserman, [2014](#bib.bib171)), and EfficientNet (Tan and Le,
    [2019](#bib.bib182)). Various CNN models used in different papers for COVID-19
    diagnosis are listed in Table [5](#S5.T5 "Table 5 ‣ 5.2\. Transfer learning for
    COVID-19 diagnosis ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").
    The ResNet is the most popular network model to detect COVID-19 and 34 papers
    use ResNet as backbone network. Besides, the DenseNet and the VGG are also used
    by many studies to detect COVID-19\. In conclusion, it is significant for us to
    select an appropriate CNN model as backbone network to diagnose COVID-19 by considering
    data type, actual scale, application scenarios and other factors.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '一些现有的卷积神经网络架构已被证明在医学图像特征提取中至关重要，例如 ResNet（He et al., [2016](#bib.bib60)）、AlexNet（Krizhevsky
    et al., [2017](#bib.bib92)）、SqueezeNet（Iandola et al., [2016](#bib.bib70)）、Inception（Szegedy
    et al., [2015](#bib.bib180)）、DenseNet（Huang et al., [2017](#bib.bib65)）、VGG（Simonyan
    and Zisserman, [2014](#bib.bib171)）和 EfficientNet（Tan and Le, [2019](#bib.bib182)）。表
    [5](#S5.T5 "Table 5 ‣ 5.2\. Transfer learning for COVID-19 diagnosis ‣ 5\. Overall
    Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey") 列出了用于 COVID-19 诊断的不同论文中使用的各种
    CNN 模型。ResNet 是检测 COVID-19 的最流行网络模型，有 34 篇论文使用 ResNet 作为骨干网络。此外，DenseNet 和 VGG
    也被许多研究用于检测 COVID-19。总之，选择合适的 CNN 模型作为骨干网络对 COVID-19 诊断至关重要，需要考虑数据类型、实际规模、应用场景等因素。'
- en: 5.2\. Transfer learning for COVID-19 diagnosis
  id: totrans-169
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 迁移学习用于 COVID-19 诊断
- en: 'Transfer learning is a machine learning technique that can transfer existing
    knowledge from one domain (source domain) to another (target domain) (Zhuang et al.,
    [2020](#bib.bib229)). The source domain generally has sufficient annotated data
    and many existing models have learned excellent feature extraction capabilities.
    The target domain lacks large-scale annotated samples and the cost of obtaining
    annotated samples is too high (Guan and Liu, [2021](#bib.bib52); Morid et al.,
    [2021](#bib.bib122)). Transfer learning aims to use knowledge learned from the
    source domain to help the target learner achieve better performance. The closer
    the relationship between the target domain and the source domain, the better transfer
    learning can be achieved (Das et al., [2022](#bib.bib37)). Otherwise, it may be
    more difficult and even has negative transfer to bring harmful effects. As shown
    in Figure [6](#S5.F6 "Figure 6 ‣ 5.2\. Transfer learning for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey"), the pre-trained
    model has obtained excellent generalization performance in the source domain and
    then it is fine-tuned by using small-scale data from the target domain (Chen et al.,
    [2021](#bib.bib34)). Due to the expensive cost of capturing CT or X-ray images
    of COVID-19 patients, various pre-trained deep learning models have been employed
    for COVID-19 diagnosis.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移学习是一种机器学习技术，可以将现有知识从一个领域（源领域）转移到另一个领域（目标领域）（Zhuang et al., [2020](#bib.bib229)）。源领域通常有足够的标注数据，许多现有模型已经学习了出色的特征提取能力。目标领域缺乏大规模的标注样本，获得标注样本的成本过高（Guan
    和 Liu, [2021](#bib.bib52)；Morid 等人，[2021](#bib.bib122)）。迁移学习旨在利用从源领域学习到的知识帮助目标学习者实现更好的性能。目标领域和源领域之间的关系越接近，迁移学习的效果越好（Das
    et al., [2022](#bib.bib37)）。否则，迁移学习可能会更困难，甚至会有负迁移，带来有害的影响。如图 [6](#S5.F6 "图6 ‣
    5.2. COVID-19 诊断的迁移学习 ‣ 5. COVID-19 诊断的基于深度学习的方法的总体分析 ‣ COVID-19 诊断的深度学习和医学影像：综合调查")
    所示，预训练模型在源领域获得了出色的泛化性能，然后使用来自目标领域的小规模数据进行微调（Chen et al., [2021](#bib.bib34)）。由于捕获
    COVID-19 患者 CT 或 X 光图像的成本高昂，已经采用了各种预训练的深度学习模型来进行 COVID-19 诊断。
- en: Kabe et al. (Kashala Kabe et al., [2021](#bib.bib81)) propose a novel domain
    transfer learning model for classifying COVID-19 cases, named feature fusion,
    decompose and transfer (FFDT). Their proposed FFDT gains feature enhancement by
    combining far-off features taken from far-off domains into a single feature space
    where the distribution mismatch is reduced. Additionally, they adopt modified
    convolutional neural network (MCNN) to extract features and the class reconstruction
    is used to unravel the local structure of the data distribution. Their model achieves
    the classification accuracy of 94.5%. Lu et al. (Lu et al., [2021](#bib.bib105))
    suggest that transfer learning can be used to extract features from chest CT images
    because it is of high complexity to train a CNN model from scratch. The pre-trained
    ResNet-18 and ResNet-50 models are chosen as the backbone to extract features
    from the CT images. To create refined image features, the retrieved features are
    combined using discriminant correlation analysis. Finally, in order to get a more
    reliable classification performance, three randomized neural networks are trained
    using the improved features and their predictions are combined.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: Kabe 等人（Kashala Kabe et al., [2021](#bib.bib81)）提出了一种新型的领域迁移学习模型，用于分类 COVID-19
    病例，名为特征融合、分解和迁移（FFDT）。他们提出的 FFDT 通过将来自远离领域的特征组合到一个特征空间中，从而获得特征增强，并减少了分布不匹配。此外，他们采用了改进的卷积神经网络（MCNN）来提取特征，并使用类别重构来揭示数据分布的局部结构。他们的模型实现了94.5%的分类准确率。Lu
    等人（Lu et al., [2021](#bib.bib105)）建议，迁移学习可以用来从胸部 CT 图像中提取特征，因为从头训练一个 CNN 模型复杂度很高。预训练的
    ResNet-18 和 ResNet-50 模型被选为提取 CT 图像特征的骨干。为了创建精细的图像特征，使用判别相关分析结合检索到的特征。最后，为了获得更可靠的分类性能，使用改进的特征训练了三个随机神经网络，并将它们的预测结果结合起来。
- en: '![Refer to caption](img/f4de81860439eea5ecc6879871b7342a.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f4de81860439eea5ecc6879871b7342a.png)'
- en: Figure 6\. The application of deep learning using transfer learning method for
    COVID-19 diagnosis.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图6. 使用迁移学习方法进行 COVID-19 诊断的深度学习应用。
- en: Vogado et al. (Vogado et al., [2021](#bib.bib193)) evaluate transfer learning
    techniques in five pre-trained CNN architectures (VGG-16, VGG-19, ResNet-50, Xception
    and DenseNet-121). In specific, they train CNNs using 1,436 images associated
    with COVID-19 cases, 1,932 healthy images, and 3,651 images of other pathologies.
    The pre-trained ResNet50 obtains the best performance for extracting deep features,
    and the MLP classifier has shown the best results when using the features derived
    by ResNet50\. Makris et al. (Makris et al., [2020](#bib.bib111)) use a combination
    of publicly available X-ray images from patients with confirmed COVID-19 cases,
    common bacterial pneumonia and healthy cases. Transfer learning is used for mitigating
    the issue of insufficient samples. In order to classify images, VGG16, VGG19,
    MobileNet V2, Inception V3, Xception, InceptionResNet V2, DenseNet201, and ResNet152
    V2 are employed and compared to explore the best model for COVID-19 diagnosis.
    Specifically, VGG16 and VGG19 perform the best and achieve an overall accuracy
    of 95%.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: Vogado等（Vogado et al., [2021](#bib.bib193)）评估了五种预训练CNN架构（VGG-16, VGG-19, ResNet-50,
    Xception 和 DenseNet-121）中的迁移学习技术。具体而言，他们使用1,436张与COVID-19病例相关的图像、1,932张健康图像和3,651张其他病理图像进行训练。预训练的ResNet50在提取深层特征方面表现最佳，而MLP分类器在使用ResNet50提取的特征时显示了最佳结果。Makris等（Makris
    et al., [2020](#bib.bib111)）使用了一组公开的X光图像，这些图像来自确诊COVID-19病例、常见细菌性肺炎和健康病例。迁移学习用于解决样本不足的问题。为了对图像进行分类，使用了VGG16、VGG19、MobileNet
    V2、Inception V3、Xception、InceptionResNet V2、DenseNet201和ResNet152 V2，并进行了比较以探索COVID-19诊断的最佳模型。具体而言，VGG16和VGG19表现最佳，总体准确率达到95%。
- en: Pathak et al. (Pathak et al., [2020](#bib.bib131)) employ a deep transfer learning
    technique to classify COVID-19 infected patients. The ResNet-50 is chosen as backbone
    network and transfer learning is employed to adjust the initial parameters of
    the deep layers. The pre-trained model, which is fine-tuned by a small number
    of training samples, can extract correct deep features from chest CT images to
    detect COVID-19 infected patients. Their proposed model achieves training and
    testing accuracy up to 96.23% and 93.02% respectively, which is superior to the
    compared deep models. To detect COVID-19 by medical images, Shamsi et al. (Shamsi
    et al., [2021](#bib.bib157)) propose a novel deep uncertainty-aware transfer learning
    framework. The pre-trained CNNs are used to extract features from chest X-ray
    and CT images. The extracted features are subsequently used to identify COVID-19
    cases using various machine learning and statistical modeling techniques. It has
    been found that CT images can produce superior diagnosis because they contain
    more information than X-ray images.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: Pathak等（Pathak et al., [2020](#bib.bib131)）采用深度迁移学习技术对COVID-19感染患者进行分类。选择ResNet-50作为骨干网络，并使用迁移学习调整深层的初始参数。经过少量训练样本微调的预训练模型能够从胸部CT图像中提取正确的深层特征以检测COVID-19感染患者。他们提出的模型在训练和测试中的准确率分别达到了96.23%和93.02%，优于比较的深度模型。为了通过医学图像检测COVID-19，Shamsi等（Shamsi
    et al., [2021](#bib.bib157)）提出了一种新颖的深度不确定性感知迁移学习框架。预训练的CNN用于从胸部X光片和CT图像中提取特征。提取的特征随后用于通过各种机器学习和统计建模技术识别COVID-19病例。研究发现，CT图像可以提供更优的诊断，因为它们比X光图像包含更多的信息。
- en: Table 5\. A summary of various CNN models used by different papers for COVID-19
    detection.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 表5\. 各种CNN模型在COVID-19检测中的应用总结。
- en: '| CNN model | Papers | Count |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| CNN模型 | 论文 | 数量 |'
- en: '| ResNet | (Zheng et al., [2022](#bib.bib223); Khurana and Soni, [2022](#bib.bib86);
    Tahir et al., [2022](#bib.bib181); Canayaz et al., [2022](#bib.bib29); Habib et al.,
    [2022](#bib.bib54); Balaha et al., [2022](#bib.bib22); Dev et al., [2021](#bib.bib40);
    Zhou et al., [2021c](#bib.bib228); Madhavan et al., [2021](#bib.bib108); Shorfuzzaman,
    [2021](#bib.bib167); Shah et al., [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174);
    Annavarapu et al., [2021](#bib.bib14); Ilhan et al., [2022](#bib.bib72); Huang
    et al., [2021b](#bib.bib67); Keles et al., [2021](#bib.bib82); Elpeltagy and Sallam,
    [2021](#bib.bib46); Jangam et al., [2022](#bib.bib76); Ahuja et al., [2021](#bib.bib6);
    Jain et al., [2021](#bib.bib75); Turkoglu, [2021](#bib.bib190); Huang, [2020](#bib.bib66);
    Hira et al., [2021](#bib.bib63); Wang et al., [2020](#bib.bib198); Zhang et al.,
    [2021a](#bib.bib217); Pathak et al., [2020](#bib.bib131); Sen et al., [2021](#bib.bib153);
    Chakraborty et al., [2021](#bib.bib30); Zebin and Rezvy, [2021](#bib.bib212);
    Song et al., [2021](#bib.bib176); Kundu et al., [2022](#bib.bib95); Paul et al.,
    [2022](#bib.bib132); Akbarimajd et al., [2022](#bib.bib7); Aslan et al., [2022](#bib.bib18))
    | 34 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
- en: '| DenseNet | (Tahir et al., [2022](#bib.bib181); Habib et al., [2022](#bib.bib54);
    Dev et al., [2021](#bib.bib40); Shorfuzzaman, [2021](#bib.bib167); Shah et al.,
    [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174); Mishra, [2021](#bib.bib120);
    Zhang et al., [2021b](#bib.bib218); Jangam et al., [2022](#bib.bib76); Hira et al.,
    [2021](#bib.bib63); Sen et al., [2021](#bib.bib153); Kundu et al., [2022](#bib.bib95);
    Paul et al., [2022](#bib.bib132); Hasan et al., [2021](#bib.bib58); Aslan et al.,
    [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90)) | 16 |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
- en: '| VGG | (Khurana and Soni, [2022](#bib.bib86); Balaha et al., [2022](#bib.bib22);
    Shah et al., [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174); Ilhan et al.,
    [2022](#bib.bib72); Tan et al., [2021](#bib.bib183); Jangam et al., [2022](#bib.bib76);
    Vidyun et al., [2021](#bib.bib192); Turkoglu, [2021](#bib.bib190); Huang, [2020](#bib.bib66);
    Sen et al., [2021](#bib.bib153); Chakraborty et al., [2021](#bib.bib30); Zebin
    and Rezvy, [2021](#bib.bib212); Paul et al., [2022](#bib.bib132); Karacı, [2022](#bib.bib80);
    Kogilavani et al., [2022](#bib.bib90)) | 16 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
- en: '| MobileNet | (Canayaz et al., [2022](#bib.bib29); Mahendran and Kavitha, [2022](#bib.bib109);
    Balaha et al., [2022](#bib.bib22); Mishra, [2021](#bib.bib120); Ilhan et al.,
    [2022](#bib.bib72); Abraham and Nair, [2022](#bib.bib2); Yasar and Ceylan, [2021b](#bib.bib208);
    Akbarimajd et al., [2022](#bib.bib7); Aslan et al., [2022](#bib.bib18); Kogilavani
    et al., [2022](#bib.bib90); Baghdadi et al., [2022](#bib.bib21); Zhang et al.,
    [2022b](#bib.bib216)) | 12 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| Inception | (Tahir et al., [2022](#bib.bib181); Balaha et al., [2022](#bib.bib22);
    Shah et al., [2021b](#bib.bib156); Ilhan et al., [2022](#bib.bib72); Jain et al.,
    [2021](#bib.bib75); Turkoglu, [2021](#bib.bib190); Hira et al., [2021](#bib.bib63);
    Sen et al., [2021](#bib.bib153); Kundu et al., [2022](#bib.bib95); Paul et al.,
    [2022](#bib.bib132); Aslan et al., [2022](#bib.bib18)) | 11 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Inception | (Tahir et al., [2022](#bib.bib181); Balaha et al., [2022](#bib.bib22);
    Shah et al., [2021b](#bib.bib156); Ilhan et al., [2022](#bib.bib72); Jain et al.,
    [2021](#bib.bib75); Turkoglu, [2021](#bib.bib190); Hira et al., [2021](#bib.bib63);
    Sen et al., [2021](#bib.bib153); Kundu et al., [2022](#bib.bib95); Paul et al.,
    [2022](#bib.bib132); Aslan et al., [2022](#bib.bib18)) | 11 |'
- en: '| AlexNet | (Zhang et al., [2022a](#bib.bib214); Zhou et al., [2021c](#bib.bib228);
    Ibrahim et al., [2021](#bib.bib71); Hira et al., [2021](#bib.bib63); Wang et al.,
    [2020](#bib.bib198); Yasar and Ceylan, [2021b](#bib.bib208); Chakraborty et al.,
    [2021](#bib.bib30); Aslan et al., [2022](#bib.bib18)) | 8 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| AlexNet | (Zhang et al., [2022a](#bib.bib214); Zhou et al., [2021c](#bib.bib228);
    Ibrahim et al., [2021](#bib.bib71); Hira et al., [2021](#bib.bib63); Wang et al.,
    [2020](#bib.bib198); Yasar and Ceylan, [2021b](#bib.bib208); Chakraborty et al.,
    [2021](#bib.bib30); Aslan et al., [2022](#bib.bib18)) | 8 |'
- en: '| GoolgeNet | (Dev et al., [2021](#bib.bib40); Zhou et al., [2021c](#bib.bib228);
    Hira et al., [2021](#bib.bib63); Zhang et al., [2021a](#bib.bib217); Chakraborty
    et al., [2021](#bib.bib30); Akbarimajd et al., [2022](#bib.bib7); Aslan et al.,
    [2022](#bib.bib18)) | 7 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| GoolgeNet | (Dev et al., [2021](#bib.bib40); Zhou et al., [2021c](#bib.bib228);
    Hira et al., [2021](#bib.bib63); Zhang et al., [2021a](#bib.bib217); Chakraborty
    et al., [2021](#bib.bib30); Akbarimajd et al., [2022](#bib.bib7); Aslan et al.,
    [2022](#bib.bib18)) | 7 |'
- en: '| Xception | (Balaha et al., [2022](#bib.bib22); Shorfuzzaman, [2021](#bib.bib167);
    Ilhan et al., [2022](#bib.bib72); Abraham and Nair, [2022](#bib.bib2); Jain et al.,
    [2021](#bib.bib75); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Xception | (Balaha et al., [2022](#bib.bib22); Shorfuzzaman, [2021](#bib.bib167);
    Ilhan et al., [2022](#bib.bib72); Abraham and Nair, [2022](#bib.bib2); Jain et
    al., [2021](#bib.bib75); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
- en: '| EfficientNet | (Khurana and Soni, [2022](#bib.bib86); Balaha et al., [2022](#bib.bib22);
    Ravi et al., [2022](#bib.bib145); Abraham and Nair, [2022](#bib.bib2); Zebin and
    Rezvy, [2021](#bib.bib212); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| EfficientNet | (Khurana and Soni, [2022](#bib.bib86); Balaha et al., [2022](#bib.bib22);
    Ravi et al., [2022](#bib.bib145); Abraham and Nair, [2022](#bib.bib2); Zebin and
    Rezvy, [2021](#bib.bib212); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
- en: '| SqueezeNet | (Tahir et al., [2022](#bib.bib181); Dev et al., [2021](#bib.bib40);
    Akbarimajd et al., [2022](#bib.bib7)) | 3 |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| SqueezeNet | (Tahir et al., [2022](#bib.bib181); Dev et al., [2021](#bib.bib40);
    Akbarimajd et al., [2022](#bib.bib7)) | 3 |'
- en: '| Darknet | (Dev et al., [2021](#bib.bib40); Abraham and Nair, [2022](#bib.bib2))
    | 2 |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Darknet | (Dev et al., [2021](#bib.bib40); Abraham and Nair, [2022](#bib.bib2))
    | 2 |'
- en: 5.3\. Ensemble learning for COVID-19 diagnosis
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. COVID-19 诊断的集成学习
- en: 'Ensemble learning is a machine learning method that combines multiple learners
    to complete complex learning tasks (Dong et al., [2020](#bib.bib43); Mienye and
    Sun, [2022](#bib.bib116)). It trains multiple base learners and combines them
    to obtain improved generalization ability than the individual base learners (Mienye
    et al., [2020](#bib.bib117)). Currently, the common methods to generate base learners
    can be divided into two categories: one is to apply different types of learning
    models in the same size but different samples, which are generated from the same
    dataset (Zhang et al., [2018](#bib.bib219)). The base learners which are generated
    by this method are called heterogeneous learners. The other is to apply the same
    learning model on different training sets. The base learners which are generated
    by this method are called homogeneous learners. Besides, the combined strategy
    of base learners mainly includes simple average method, weighted average method,
    majority voting, plurality voting, and weighted voting. Figure [7](#S5.F7 "Figure
    7 ‣ 5.3\. Ensemble learning for COVID-19 diagnosis ‣ 5\. Overall Analysis of DL-based
    Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical Imaging for COVID-19
    Diagnosis: A Comprehensive Survey") illustrates a representative application of
    ensemble learning for COVID-19 diagnosis. Multiple base models learn to diagnose
    COVID-19 from the medical images and output classification results. The ensemble
    classifier receives input from base models to make the final decision.'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '集成学习是一种机器学习方法，它将多个学习者结合起来完成复杂的学习任务（Dong 等，[2020](#bib.bib43)；Mienye 和 Sun，[2022](#bib.bib116)）。它训练多个基础学习者并将它们结合起来，以获得比单个基础学习者更好的泛化能力（Mienye
    等，[2020](#bib.bib117)）。目前，生成基础学习者的常用方法可以分为两类：一类是应用不同类型的学习模型在相同大小但不同样本的情况下，这些样本来自同一数据集（Zhang
    等，[2018](#bib.bib219)）。通过这种方法生成的基础学习者称为异质学习者。另一类是对不同的训练集应用相同的学习模型。通过这种方法生成的基础学习者称为同质学习者。此外，基础学习者的组合策略主要包括简单平均法、加权平均法、主要投票、多数投票和加权投票。图
    [7](#S5.F7 "Figure 7 ‣ 5.3\. Ensemble learning for COVID-19 diagnosis ‣ 5\. Overall
    Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey") 展示了集成学习在 COVID-19 诊断中的代表性应用。多个基础模型通过医学图像学习诊断
    COVID-19 并输出分类结果。集成分类器接收基础模型的输入以做出最终决策。'
- en: Chaudhary et al. (Chaudhary and Qiang, [2021](#bib.bib32)) train three base
    models (two Efficient-Net with different initial pre-trained weights and SE-ResNext),
    which can classify X-ray images into COVID-19, pneumonia, and normal cases. The
    final results are calculated by averaging the classification outcomes produced
    by the three different models individually. Their proposed method achieves excellent
    performance with an accuracy of 0.9592, a sensitivity of 0.9592, and a specificity
    of 0.9597\. It is proven that the ensemble model’s accuracy is greater than that
    of three separately trained models. Tang et al. (Tang et al., [2021a](#bib.bib184))
    propose the EDL-COVID model using deep learning and ensemble learning. It trains
    several base models to overcome the shortcomings of single model by combining
    their predicted outputs. A deep learning network generates several model snapshots
    in one training run by snapshotting. Additionally, several model snapshots are
    integrated to produce a preciser model and the final classification is made using
    the weighted average method. Their EDL-COVID model achieves 95% accuracy.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: Chaudhary 等人（Chaudhary 和 Qiang，[2021](#bib.bib32)）训练了三个基础模型（两个具有不同初始预训练权重的 Efficient-Net
    和 SE-ResNext），这些模型可以将 X 射线图像分类为 COVID-19、肺炎和正常情况。最终结果通过对这三个不同模型分别产生的分类结果进行平均来计算。他们提出的方法在准确率为
    0.9592、敏感性为 0.9592 和特异性为 0.9597 的情况下，表现出色。已证明集成模型的准确性大于三个单独训练模型的准确性。Tang 等人（Tang
    等，[2021a](#bib.bib184)）提出了 EDL-COVID 模型，该模型使用深度学习和集成学习。它训练多个基础模型，通过组合它们的预测输出来克服单一模型的不足。深度学习网络通过快照生成多个模型快照，并将多个模型快照整合以产生更精确的模型，最终分类是使用加权平均方法进行的。他们的
    EDL-COVID 模型实现了 95% 的准确率。
- en: Abraham et al. (Abraham and Nair, [2022](#bib.bib2)) use five pre-trained CNNs
    (MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0) to extract
    features. Then the features are combined, and the ensemble classifier kernel support
    vector machine is used to diagnose COVID-19 cases. Their proposed model achieves
    0.916 accuracy, 0.8305 kappa score, 0.91 F-score, 0.917 sensitivity, and positive
    predictive value of 0.904\. Zhou et al. (Zhou et al., [2021c](#bib.bib228)) employ
    three deep pre-trained models (AlexNet, GoogleNet, and ResNet) as base learners.
    Then the predicted outputs from three pre-trained models are input into the ensemble
    classifier EDL-COVID, and relative majority voting is used to determine the final
    outcome. Finally, by comparing the ensemble classifier with three component classifiers
    in some specific performance metrics, it is demonstrated that the ensemble model
    obtains more effective performance than three deep pre-trained models.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Abraham 等人（Abraham 和 Nair, [2022](#bib.bib2)）使用了五种预训练的卷积神经网络（MobilenetV2、Shufflenet、Xception、Darknet53
    和 EfficientnetB0）来提取特征。然后将这些特征进行组合，并使用集成分类器内核支持向量机来诊断 COVID-19 病例。他们提出的模型实现了 0.916
    的准确率、0.8305 的 Kappa 评分、0.91 的 F 值、0.917 的灵敏度以及 0.904 的阳性预测值。Zhou 等人（Zhou 等人, [2021c](#bib.bib228)）使用了三种深度预训练模型（AlexNet、GoogleNet
    和 ResNet）作为基学习器。然后将三种预训练模型的预测结果输入到集成分类器 EDL-COVID 中，并使用相对多数投票来确定最终结果。最终，通过将集成分类器与三种组件分类器在一些特定性能指标上进行比较，证明了集成模型比三种深度预训练模型获得了更有效的性能。
- en: '![Refer to caption](img/346c87520abc8f3c1bbc6da676214b55.png)'
  id: totrans-193
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/346c87520abc8f3c1bbc6da676214b55.png)'
- en: Figure 7\. The application of deep learning using ensemble learning method for
    COVID-19 diagnosis.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. 使用集成学习方法进行 COVID-19 诊断的深度学习应用。
- en: 5.4\. GAN model for COVID-19 diagnosis
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. 用于 COVID-19 诊断的 GAN 模型
- en: 'One of the main causes for poor performance and underfitting is the insufficient
    amount of annotated COVID-19 images (Rahman et al., [2021b](#bib.bib143); Chen
    et al., [2021](#bib.bib34)). And the cost of collecting COVID-19 infected images
    is too expensive. To solve these problems, Generative Adversarial Network (GAN)
    is employed by many studies to generate fake COVID-19 infected images to tackle
    data insufficiency (Saxena and Cao, [2021](#bib.bib150); Acar et al., [2021](#bib.bib4)).
    GAN mainly consists of two systems: a generator and a discriminator, as shown
    in Figure [8](#S5.F8 "Figure 8 ‣ 5.4\. GAN model for COVID-19 diagnosis ‣ 5\.
    Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and
    Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 性能差和欠拟合的主要原因之一是标注的 COVID-19 图像数量不足（Rahman 等人, [2021b](#bib.bib143)；Chen 等人,
    [2021](#bib.bib34)）。而且收集 COVID-19 感染图像的成本过于昂贵。为了解决这些问题，许多研究采用了生成对抗网络（GAN）来生成假
    COVID-19 感染图像，以应对数据不足的问题（Saxena 和 Cao, [2021](#bib.bib150)；Acar 等人, [2021](#bib.bib4)）。GAN
    主要由两个系统组成：生成器和判别器，如图 [8](#S5.F8 "图 8 ‣ 5.4\. 用于 COVID-19 诊断的 GAN 模型 ‣ 5\. 基于深度学习的方法总体分析
    ‣ 深度学习和医疗影像在 COVID-19 诊断中的综合调查") 所示。
- en: $\bullet$
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Generator network: Generator takes noise samples from a particular distribution
    (uniform distribution and Gaussian distribution) and generates results similar
    to the real training data. It tries to generate fake images to successfully trick
    the discriminator after training.'
  id: totrans-198
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成器网络：生成器从特定分布（均匀分布和高斯分布）中提取噪声样本，并生成类似于真实训练数据的结果。它试图生成假图像，以便在训练后成功欺骗判别器。
- en: $\bullet$
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: 'Discriminator network: Real data and generated data are mixed and input into
    the discriminator. The discriminator distinguishes whether a sample belongs to
    real data or generated data. If it comes from real data, then the high probability
    will appear to be output, otherwise the probability is low.'
  id: totrans-200
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 判别网络：将真实数据和生成的数据混合并输入判别器。判别器区分样本是否属于真实数据或生成的数据。如果样本来自真实数据，则输出的概率较高，否则概率较低。
- en: Jiang et al. (Jiang et al., [2021](#bib.bib77)) construct a public COVID-19
    CT dataset, including 1,186 CT images synthesized from a large-scale lung cancer
    CT dataset using CycleGAN. Their proposed model can learn the GGO style of COVID-19
    so that the synthetic images are closely resembled to the real distribution. Goel
    et al. (Goel et al., [2021](#bib.bib51)) employ generative adversarial network
    (GAN) to generate synthetic chest CT images during data augmentation phase. The
    Whale Optimization Algorithm (WOA) is used to optimize the hyperparameters of
    GAN. Their proposed model using GAN reaches 99.22% accuracy.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 姜等人（Jiang et al., [2021](#bib.bib77)）构建了一个公共COVID-19 CT数据集，包括1,186张通过CycleGAN从大规模肺癌CT数据集中合成的CT图像。他们提出的模型能够学习COVID-19的GGO风格，使得合成图像与真实分布紧密相似。Goel等人（Goel
    et al., [2021](#bib.bib51)）在数据增强阶段使用生成对抗网络（GAN）生成合成的胸部CT图像。鲸鱼优化算法（WOA）用于优化GAN的超参数。他们提出的基于GAN的模型达到了99.22%的准确率。
- en: Bargshady et al. (Bargshady et al., [2022](#bib.bib24)) apply generative adversarial
    network (GAN) and semi-supervised CycleGAN (SSA-CycleGAN) to augment the training
    dataset of X-ray images. Their proposed Inception-CycleGAN model achieves 94.2%
    accuracy, and 92.2% area under cure. Serte et al. (Serte et al., [2022](#bib.bib154))
    augment the number of available CT images by using generative adversarial network
    (GAN). By comparing the traditional deep learning methods with their proposed
    method using data-efficient method (GAN), it is demonstrated that their proposed
    data-efficient model outperforms all other traditional deep learning models. The
    ResNet-18 and MobileNetV2 obtain the best performance.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: Bargshady等人（Bargshady et al., [2022](#bib.bib24)）应用生成对抗网络（GAN）和半监督CycleGAN（SSA-CycleGAN）来增强X光图像的训练数据集。他们提出的Inception-CycleGAN模型达到了94.2%的准确率和92.2%的曲线下面积。Serte等人（Serte
    et al., [2022](#bib.bib154)）通过使用生成对抗网络（GAN）增加了可用的CT图像数量。通过将传统深度学习方法与他们提出的使用数据高效方法（GAN）进行比较，结果表明，他们提出的数据高效模型优于所有其他传统深度学习模型。ResNet-18和MobileNetV2获得了最佳性能。
- en: '![Refer to caption](img/42fcbbf84609864f11d1853d1ee2e1b9.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/42fcbbf84609864f11d1853d1ee2e1b9.png)'
- en: Figure 8\. The typical architecture of the GAN. The generator generates synthetic
    data from a given input, the discriminator distinguishes the output of the generator
    from the real data.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 图8\. GAN的典型架构。生成器从给定输入生成合成数据，判别器将生成器的输出与真实数据区分开来。
- en: In addition to its popularity in data augmentation, GAN is also employed in
    other fields based on its adversarial training characteristics. Bhattacharyya
    et al. (Bhattacharyya et al., [2022](#bib.bib27)) use C-GAN to segment the COVID-19
    chest X-ray images. The X-ray images as input are fed into the generator and the
    generator network tries to produce the mask images. The discriminator tries to
    distinguish fake image pair (Input X-ray images and generated mask images) from
    the real one. Besides, Doraiswami et al. (Doraiswami et al., [2022](#bib.bib44))
    propose an effective prediction mechanism, where local ternary pattern (LTP) is
    used for feature extraction, and prediction of COVID-19 patients is performed
    by their proposed Jaya-TSA based GAN after acquiring features. Their proposed
    method reaches the accuracy of 0.87, the sensitivity of 0.85 and the specificity
    of 0.89.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在数据增强中的流行，GAN还基于其对抗训练特性应用于其他领域。Bhattacharyya等人（Bhattacharyya et al., [2022](#bib.bib27)）使用C-GAN对COVID-19胸部X光图像进行分割。X光图像作为输入被送入生成器，生成器网络尝试生成掩膜图像。判别器则尝试区分假图像对（输入X光图像和生成的掩膜图像）与真实图像对。此外，Doraiswami等人（Doraiswami
    et al., [2022](#bib.bib44)）提出了一种有效的预测机制，在提取特征时使用局部三值模式（LTP），并在获得特征后通过他们提出的Jaya-TSA基于GAN的模型进行COVID-19患者的预测。他们提出的方法达到了0.87的准确率、0.85的敏感性和0.89的特异性。
- en: 'Some of the applications of deep learning based on GAN model and their result
    are demonstrated in Table [6](#S5.T6 "Table 6 ‣ 5.4\. GAN model for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey"). In most
    of the studies, GAN is generally employed for data augmentation before model training
    to greatly increase the training sample space, thereby significantly improve the
    performance of the model (Menon et al., [2020](#bib.bib113); Li et al., [2021a](#bib.bib99);
    Serte et al., [2022](#bib.bib154)). In reference (Menon et al., [2020](#bib.bib113)),
    the quantitative analysis shows that their proposed MTT-GAN greatly improves the
    accuracy of binary classifier and multiclass classifier. In reference (Li et al.,
    [2021a](#bib.bib99)), the original CNN models with Generative Adversarial Network
    (GAN) increase the accuracy by 2% to 3%, the recall by 2% to 4%, and the precision
    by 1% to 3%.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '基于 GAN 模型的深度学习应用及其结果如表 [6](#S5.T6 "Table 6 ‣ 5.4\. GAN model for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey") 所示。在大多数研究中，GAN
    通常用于模型训练前的数据增强，以大幅增加训练样本空间，从而显著提高模型的性能（Menon et al., [2020](#bib.bib113)；Li et
    al., [2021a](#bib.bib99)；Serte et al., [2022](#bib.bib154)）。在参考文献（Menon et al.,
    [2020](#bib.bib113)）中，定量分析表明他们提出的 MTT-GAN 显著提高了二分类器和多分类器的准确性。在参考文献（Li et al.,
    [2021a](#bib.bib99)）中，原始 CNN 模型与生成对抗网络（GAN）结合后，准确率提高了 2% 到 3%，召回率提高了 2% 到 4%，精确率提高了
    1% 到 3%。'
- en: Table 6\. Deep learning methods and result evaluation for diagnosing COVID-19
    using GAN models.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6\. 使用 GAN 模型诊断 COVID-19 的深度学习方法及结果评估。
- en: '| Reference | Data | Methods | Function | Acc | Sn | Sp |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 数据 | 方法 | 功能 | 准确率 | 召回率 | 精确率 |'
- en: '| Zhang et al. (Zhang et al., [2021d](#bib.bib213)) | CT | GAN, U-net | Segmentation
    | 93.2% | 69.8% | — |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 等（Zhang et al., [2021d](#bib.bib213)） | CT | GAN, U-net | 分割 | 93.2%
    | 69.8% | — |'
- en: '| Bargshady et al. (Bargshady et al., [2022](#bib.bib24)) | X-ray | CycleGAN,
    Inception V3 | Classification | 94.2% | 95.5% | 91.4% |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| Bargshady 等（Bargshady et al., [2022](#bib.bib24)） | X-ray | CycleGAN, Inception
    V3 | 分类 | 94.2% | 95.5% | 91.4% |'
- en: '| Acar et al. (Acar et al., [2021](#bib.bib4)) | CT | GAN,CNN | Classification
    | 95.0% | 94.2% | 95.3% |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| Acar 等（Acar et al., [2021](#bib.bib4)） | CT | GAN, CNN | 分类 | 95.0% | 94.2%
    | 95.3% |'
- en: '| Goel et al. (Goel et al., [2021](#bib.bib51)) | CT | GAN, WOA, ResNet-50
    | Classification | 99.2% | 99.8% | 97.8% |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| Goel 等（Goel et al., [2021](#bib.bib51)） | CT | GAN, WOA, ResNet-50 | 分类 |
    99.2% | 99.8% | 97.8% |'
- en: '| Menon et al. (Menon et al., [2020](#bib.bib113)) | X-ray | GAN, CNN, transfer
    learning | Classification | 96.3% | 100.0% | 93.2% |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| Menon 等（Menon et al., [2020](#bib.bib113)） | X-ray | GAN, CNN, 迁移学习 | 分类
    | 96.3% | 100.0% | 93.2% |'
- en: '| Li et al. (Li et al., [2021a](#bib.bib99)) | CT | GAN, DenseNet | Classification
    | 93.0% | 96.0% | — |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| Li 等（Li et al., [2021a](#bib.bib99)） | CT | GAN, DenseNet | 分类 | 93.0% |
    96.0% | — |'
- en: '| Serte et al. (Serte et al., [2022](#bib.bib154)) | CT | GAN, CNN, Transfer
    learning | Classification | 74.0% | 88.0% | 68.0% |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| Serte 等（Serte et al., [2022](#bib.bib154)） | CT | GAN, CNN, 迁移学习 | 分类 | 74.0%
    | 88.0% | 68.0% |'
- en: '| Bhattacharyya et al. (Bhattacharyya et al., [2022](#bib.bib27)) | X-ray |
    C-GAN, CNN, ML | Segmentation | 96.6% | 95.0% | 97.4% |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| Bhattacharyya 等（Bhattacharyya et al., [2022](#bib.bib27)） | X-ray | C-GAN,
    CNN, ML | 分割 | 96.6% | 95.0% | 97.4% |'
- en: 5.5\. LSTM model for COVID-19 diagnosis
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5\. 用于 COVID-19 诊断的 LSTM 模型
- en: 'Long Short-Term Memory (LSTM) is a powerful recurrent neural network, which
    is proposed to address the substantial limitation of neural networks when dealing
    with sequential data (Hasan et al., [2020](#bib.bib57)). For the issue that traditional
    RNN structure has poor performance on long sequences, the LSTM model is capable
    of greatly alleviating the gradient disappearance problem, thereby supporting
    long-term dependence in dealing with sequential data (Sherstinsky, [2020](#bib.bib160);
    Meraihi et al., [2022](#bib.bib114)). And it has been extensively utilized to
    diagnose COVID-19 and predict the prognosis of COVID-19 patients. In this section,
    we will introduce the application of LSTM model in detecting COVID-19, and some
    high quality studies using the LSTM model for COVID-19 diagnosis are listed in
    Table [7](#S6.T7 "Table 7 ‣ 6\. Quantify the Severity of COVID-19 Patients ‣ Deep
    Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 长短期记忆（LSTM）是一种强大的递归神经网络，旨在解决神经网络处理序列数据时的重大局限性（Hasan et al., [2020](#bib.bib57)）。针对传统
    RNN 结构在处理长序列时表现不佳的问题，LSTM 模型能够大大缓解梯度消失问题，从而支持处理序列数据时的长期依赖（Sherstinsky, [2020](#bib.bib160);
    Meraihi et al., [2022](#bib.bib114)）。它已被广泛应用于 COVID-19 诊断和预测 COVID-19 患者的预后。在本节中，我们将介绍
    LSTM 模型在 COVID-19 检测中的应用，并列出一些使用 LSTM 模型进行 COVID-19 诊断的高质量研究，这些研究列在表 [7](#S6.T7
    "表 7 ‣ 6\. 量化 COVID-19 患者的严重性 ‣ 深度学习和医疗影像在 COVID-19 诊断中的应用：综合调查") 中。
- en: '![Refer to caption](img/22f7272f0622c327932c2581a1bc6561.png)'
  id: totrans-219
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/22f7272f0622c327932c2581a1bc6561.png)'
- en: Figure 9\. The application of deep learning using LSTM model for COVID-19 diagnosis.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9\. 使用 LSTM 模型进行 COVID-19 诊断的深度学习应用。
- en: 'Patients with COVID-19 tend to have a dynamic condition. The information obtained
    from one CT image or X-ray is generally limited. Conversely, CT or X-ray sequences
    are capable of providing more medical information, assisting models or doctors
    to make a preciser diagnosis for COVID-19 patients (Xu et al., [2022](#bib.bib204)).
    Consequently, many studies apply the LSTM model and image sequences to diagnose
    COVID-19\. The typical architecture of the LSTM model for COVID-19 diagnosis is
    shown in Figure [9](#S5.F9 "Figure 9 ‣ 5.5\. LSTM model for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey") (Demir, [2021](#bib.bib39)).
    Er (Er, [2022](#bib.bib47)) proposes a hybrid approach for COVID-19 classification
    that combines long short-term memory (LSTM) with some pre-trained deep networks.
    The contrast enhancing method is firstly applied to X-ray images in preprocessing
    phase. Then the pre-trained CNNs and LSTM model are used to learn features from
    the contrast enhanced chest X-rays. Finally, COVID-19, normal (healthy), and pneumonia
    cases are classified by softmax. Their proposed model reaches 98.97% accuracy,
    98.80% precision, and 98.70% sensitivity.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 患有 COVID-19 的患者往往情况动态变化。从一张 CT 图像或 X 光片中获得的信息通常有限。相反，CT 或 X 光序列能够提供更多的医疗信息，帮助模型或医生对
    COVID-19 患者进行更精确的诊断（Xu et al., [2022](#bib.bib204)）。因此，许多研究应用 LSTM 模型和图像序列来诊断
    COVID-19。图 [9](#S5.F9 "图 9 ‣ 5.5\. COVID-19 诊断的 LSTM 模型 ‣ 5\. 基于 DL 方法的 COVID-19
    诊断整体分析 ‣ 深度学习和医疗影像在 COVID-19 诊断中的应用：综合调查") 展示了用于 COVID-19 诊断的 LSTM 模型的典型架构（Demir,
    [2021](#bib.bib39)）。Er（Er, [2022](#bib.bib47)）提出了一种混合方法，将长短期记忆（LSTM）与一些预训练的深度网络相结合，用于
    COVID-19 分类。在预处理阶段首先将对比度增强方法应用于 X 光图像。然后，利用预训练的 CNN 和 LSTM 模型从对比度增强的胸部 X 光图像中学习特征。最后，通过
    softmax 对 COVID-19、正常（健康）和肺炎病例进行分类。他们提出的模型达到了 98.97% 的准确率、98.80% 的精确率和 98.70%
    的灵敏度。
- en: Hasan et al. (Hasan et al., [2020](#bib.bib57)) preprocess the CT images to
    reduce the effect of intensity variations. Then, histogram thresholding is used
    to segment the CT lung region. Each CT image is extracted feature using Q-Deformed
    entropy (QDE) and convolutional neural network (CNN). Then the obtained features
    are fused and fed into a long short-term memory (LSTM) classifier to identify
    COVID-19 cases. The highest accuracy for classifying the collected dataset is
    99.68%. Sheykhivand et al. (Sheykhivand et al., [2021](#bib.bib161)) propose an
    efficient deep neural network for COVID-19 automatic detection. First, the GAN
    model is used to generate sufficient train samples for augmenting data. Later,
    the pre-trained model (Inception) obtains a feature vector from the X-ray images.
    Then the feature vector is split into shorter vector sequences for the input of
    LSTM model to identify COVID-19\. Their proposed model achieves more than 90%
    accuracy for most scenarios and the accuracy of 99% for separating COVID-19 from
    healthy group.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Hasan 等人（Hasan et al., [2020](#bib.bib57)）对 CT 图像进行预处理，以减少强度变化的影响。然后，使用直方图阈值分割
    CT 肺部区域。每个 CT 图像使用 Q-变形熵（QDE）和卷积神经网络（CNN）提取特征。然后，将获得的特征进行融合，并输入长短期记忆（LSTM）分类器以识别
    COVID-19 案例。对收集的数据集进行分类的最高准确率为 99.68%。Sheykhivand 等人（Sheykhivand et al., [2021](#bib.bib161)）提出了一种高效的深度神经网络用于
    COVID-19 自动检测。首先，使用 GAN 模型生成足够的训练样本以增强数据。随后，预训练模型（Inception）从 X 射线图像中获得特征向量。然后，将特征向量拆分为较短的向量序列，作为
    LSTM 模型的输入，以识别 COVID-19。所提出的模型在大多数场景下的准确率超过 90%，并在区分 COVID-19 和健康组时准确率达到 99%。
- en: Xu et al. (Xu et al., [2022](#bib.bib204)) develop a three dimensional algorithm
    that combines multi-instance learning with the LSTM architecture (3DMTM) to identify
    COVID-19 from community acquired pneumonia (CAP). The 3DMTM model employs a lesion
    instance generator based on a pneumonia segmentation model to generate many lesion
    instances, which are then combined with clinical information and input into LSTM
    for final classification. Their proposed model achieves 0.956 AUC, 0.862 and 0.98
    specificity under the condition of relatively large data. Demir (Demir, [2021](#bib.bib39))
    proposes a novel LSTM-based model to automatically identify COVID-19 cases using
    X-ray images. Their proposed model is trained from scratch. In particular, the
    sobel gradient and marker-controlled watershed segmentation operations are firstly
    applied to raw images. The processed images are then converted to sequence data,
    which is fed into LSTM layer to generate the feature vector. The feature vector
    is finally input into softmax layer to identify COVID-19 cases. In the experiment,
    regarding the accuracy, sensitivity, specificity, and F-score, the proposed method
    achieves excellent performance.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Xu 等人（Xu et al., [2022](#bib.bib204)）开发了一种结合多实例学习和 LSTM 架构（三维多实例学习模型，3DMTM）的三维算法，用于从社区获得性肺炎（CAP）中识别
    COVID-19。3DMTM 模型使用基于肺炎分割模型的病变实例生成器生成许多病变实例，然后将这些实例与临床信息结合并输入 LSTM 进行最终分类。所提出的模型在相对较大数据的条件下，取得了
    0.956 的 AUC、0.862 的灵敏度和 0.98 的特异性。Demir（Demir, [2021](#bib.bib39)）提出了一种新型的基于 LSTM
    的模型，用于自动识别 COVID-19 案例，使用 X 射线图像。所提出的模型是从零开始训练的。特别地，首先对原始图像应用 Sobel 梯度和标记控制的分水岭分割操作。然后，将处理后的图像转换为序列数据，输入到
    LSTM 层中以生成特征向量。最后，将特征向量输入到 Softmax 层中以识别 COVID-19 案例。在实验中，所提出的方法在准确率、灵敏度、特异性和
    F 分数方面表现出色。
- en: 6\. Quantify the Severity of COVID-19 Patients
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 量化 COVID-19 患者的严重程度
- en: Early identifying COVID-19 from the patient’s CT images or X-ray images is the
    first and crucial step in COVID-19 diagnosis. After that, a large number of confirmed
    and suspected cases need to be managed properly and given appropriate treatment,
    which is an enormous challenge to medical resource distribution (Tang et al.,
    [2021b](#bib.bib185); Sheela and Arun, [2022](#bib.bib159); Vasilev et al., [2022](#bib.bib191)).
    To solve these problems, quantifying the severity of COVID-19 patients is another
    crucial component for COVID-19 diagnosis, which can help doctors have a better
    grasp of the patient’s infected condition and make the most reasonable treatment,
    thereby maximizing the rational distribution of medical resources.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 从患者的 CT 图像或 X 光图像中早期识别 COVID-19 是 COVID-19 诊断中的首要且关键的步骤。之后，需要妥善管理大量确认和疑似病例，并给予适当治疗，这对医疗资源分配是一个巨大的挑战
    (Tang et al., [2021b](#bib.bib185); Sheela 和 Arun, [2022](#bib.bib159); Vasilev
    et al., [2022](#bib.bib191))。为了解决这些问题，量化 COVID-19 患者的严重程度是 COVID-19 诊断的另一个关键环节，这可以帮助医生更好地掌握患者的感染情况，制定最合理的治疗方案，从而最大限度地合理分配医疗资源。
- en: Rana et al. (Rana et al., [2022](#bib.bib144)) design a severity estimation
    SSD network, which uses the images collected from the detection experiment as
    the training set. Based on the COVID-19 positive images, their proposed model
    predicts different feature classes and bounding box coordinates. Then the evaluation
    module uses the top 36 predicted classes, ignoring the background classes, to
    derive severity estimates. In the end, three classifications are created based
    on the severity of COVID-19 patients, mainly including initial type, intermediate
    type, and severe type.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: Rana 等人 (Rana et al., [2022](#bib.bib144)) 设计了一种严重程度估计 SSD 网络，使用从检测实验中收集的图像作为训练集。基于
    COVID-19 阳性图像，他们提出的模型预测不同的特征类别和边界框坐标。然后，评估模块使用前 36 个预测类别（忽略背景类别）来推导严重程度估计。最后，根据
    COVID-19 患者的严重程度创建了三种分类，主要包括初期型、中期型和重型。
- en: Shan et al. (Shan et al., [2021](#bib.bib158)) develop a DL-based segmentation
    method using VB-Net to segment COVID-19 infection regions in CT images. Each training
    case’s automatic annotation is improved using the suggested HIMI (human involved
    model iterations). The chest CT scans are first fed into the proposed segmentation
    model. Then, quantitative metrics, e.g., infection volumes and POIs in the entire
    lung, lung lobes, and bronchopulmonary segments, are estimated to characterize
    the infection locations in the CT image.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: Shan 等人 (Shan et al., [2021](#bib.bib158)) 开发了一种基于深度学习的分割方法，使用 VB-Net 来分割 CT
    图像中的 COVID-19 感染区域。通过建议的 HIMI（人工参与模型迭代）改进每个训练案例的自动标注。胸部 CT 扫描首先被输入到提议的分割模型中。然后，利用定量指标，例如整个肺部、肺叶和支气管肺段中的感染体积和
    POI，来估计 CT 图像中感染的位置。
- en: Chamberlin et al. (Chamberlin et al., [2022](#bib.bib31)) try to evaluate a
    previously trained interpretable deep learning algorithm for the diagnosis and
    prognosis of COVID-19\. Three radiologists with cardiothoracic fellowship training
    systematically evaluate each chest radiograph and generated a severity score based
    on the region of airspace disease. And the evaluation results are compared with
    the identical score produced by artificial intelligence. It shows that the anticipated
    severity scores are compatible with professional evaluation and AI model correctly
    forecasts crucial clinical consequences.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: Chamberlin 等人 (Chamberlin et al., [2022](#bib.bib31)) 试图评估一个先前训练过的可解释深度学习算法，用于
    COVID-19 的诊断和预后。三位接受过心胸科培训的放射科医师系统性地评估每张胸部 X 光片，并根据气道疾病区域生成严重程度评分。然后将评估结果与人工智能生成的相同评分进行比较。结果显示，预期的严重程度评分与专业评估相符，AI
    模型正确预测了关键的临床后果。
- en: Zhou et al. (Zhou et al., [2022](#bib.bib224)) propose a multi-modality feature
    learning and fusion model for COVID-19 patient severity prediction. The CT images
    and electronic medical record (EMR) are used for multi-modality feature extraction.
    The High-order Factorization Network (HoFN) is proposed to learn the impact of
    a set of clinical features from an electronic medical record (EMR). Finally, the
    features are concatenated as the input of fully connected layer to evaluate a
    patient’s severity. In general, according to clinical symptoms and medical image
    data, their proposed model classifies patients’ severity as mild, moderate, severe,
    or fatal.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: Zhou等人（Zhou et al., [2022](#bib.bib224)）提出了一种多模态特征学习和融合模型，用于预测COVID-19患者的严重程度。该模型使用CT图像和电子病历（EMR）进行多模态特征提取。提出了高阶分解网络（HoFN）以学习来自电子病历（EMR）的一组临床特征的影响。最后，这些特征被连接起来作为全连接层的输入，以评估患者的严重程度。总体而言，根据临床症状和医学图像数据，他们提出的模型将患者的严重程度分类为轻度、中度、重度或致命。
- en: Table 7\. Deep learning methods and result evaluation for diagnosing COVID-19
    using LSTM models.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表7\. 使用LSTM模型进行COVID-19诊断的深度学习方法及结果评估。
- en: '| Reference | Data | Methods | Acc | Sn | Sp |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 数据 | 方法 | 准确率 | 灵敏度 | 特异性 |'
- en: '| Naeem et al. (Naeem and Bin-Salem, [2021](#bib.bib124)) | CT and X-ray |
    CNN, LSTM | 98.9% | 99.0% | — |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| Naeem等人（Naeem and Bin-Salem, [2021](#bib.bib124)) | CT和X射线 | CNN, LSTM |
    98.9% | 99.0% | — |'
- en: '| Aslan et al. (Aslan et al., [2020](#bib.bib19)) | X-ray | AlexNet, LSTM |
    98.7% | 98.8% | 99.3% |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| Aslan等人（Aslan et al., [2020](#bib.bib19)) | X射线 | AlexNet, LSTM | 98.7% |
    98.8% | 99.3% |'
- en: '| Hamza et al. (Hamza et al., [2022](#bib.bib56)) | X-ray | Efficient Net,
    LSTM | 93.4% | 93.3% | — |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| Hamza等人（Hamza et al., [2022](#bib.bib56)) | X射线 | Efficient Net, LSTM | 93.4%
    | 93.3% | — |'
- en: '| Demir (Demir, [2021](#bib.bib39)) | X-ray | LSTM | 97.6% | 100.0% | 96.0%
    |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Demir（Demir, [2021](#bib.bib39)) | X射线 | LSTM | 97.6% | 100.0% | 96.0% |'
- en: '| Sheykhivand et al. (Sheykhivand et al., [2021](#bib.bib161)) | X-ray | CNNs,
    GAN, LSTM | 99.5% | 100.0% | 99.0% |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| Sheykhivand等人（Sheykhivand et al., [2021](#bib.bib161)) | X射线 | CNNs, GAN,
    LSTM | 99.5% | 100.0% | 99.0% |'
- en: '| Hasan et al. (Hasan et al., [2020](#bib.bib57)) | CT | LSTM, Q-Deformed Entropy
    | 99.7% | — | — |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| Hasan等人（Hasan et al., [2020](#bib.bib57)) | CT | LSTM, Q-变形熵 | 99.7% | —
    | — |'
- en: '| Xu et al. (Xu et al., [2022](#bib.bib204)) | X-ray | LSTM, SVM | 95.3% |
    86.2% | 98.0% |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| Xu等人（Xu et al., [2022](#bib.bib204)) | X射线 | LSTM, SVM | 95.3% | 86.2% |
    98.0% |'
- en: '| Er (Er, [2022](#bib.bib47)) | X-ray | CNN,LSTM | 99.0% | 98.7% | — |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Er（Er, [2022](#bib.bib47)) | X射线 | CNN,LSTM | 99.0% | 98.7% | — |'
- en: 7\. Challenges and Future Work
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 挑战与未来工作
- en: Deep learning technologies have been proven to have great potential in fighting
    against COVID-19 and are widely used for diagnosis and quantification. However,
    the applications of deep learning for COVID-19 diagnosis are still in their infancy
    with many shortcomings. In this section, we will detail the challenges and future
    work when applying deep learning technologies to diagnose COVID-19.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术已被证明在抗击COVID-19方面具有巨大潜力，并被广泛用于诊断和量化。然而，深度学习在COVID-19诊断中的应用仍处于起步阶段，存在许多不足之处。在本节中，我们将详细说明在应用深度学习技术进行COVID-19诊断时面临的挑战和未来的工作。
- en: 7.1\. Challenges
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1\. 挑战
- en: 'At present, the applications of deep learning based on medical images for diagnosing
    COVID-19 mainly face eight challenges:'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，基于医学图像的深度学习应用于COVID-19诊断主要面临八个挑战：
- en: $\bullet$
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Accuracy in multiclass classification. Although the deep learning model based
    on medical images can identify COVID-19 from normal cases, it is still challenging
    to distinguish COVID-19 through different types of pneumonia, which is far less
    accurate than RT-PCR.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多类别分类的准确性。虽然基于医学图像的深度学习模型可以从正常病例中识别COVID-19，但通过不同类型的肺炎区分COVID-19仍然具有挑战性，这远不如RT-PCR准确。
- en: $\bullet$
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Unavailability of large-scale annotated data. The performance of most deep learning
    methods depends on large-scale annotated data. Although some studies propose their
    own datasets, the available data is still insufficient. Additionally, annotating
    data is time-consuming and requires many professional medical people.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大规模注释数据的不可用性。大多数深度学习方法的性能依赖于大规模的注释数据。尽管一些研究提出了自己的数据集，但可用的数据仍然不足。此外，数据注释费时且需要许多专业医疗人员。
- en: $\bullet$
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Data imbalance. Due to the rapid outbreak of the epidemic, the positive COVID-19
    samples are far smaller than the normal samples. This data imbalance will affect
    the performance of deep learning models in COVID-19 diagnosis.
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据不平衡。由于疫情的迅速爆发，阳性COVID-19样本远少于正常样本。这种数据不平衡会影响深度学习模型在COVID-19诊断中的表现。
- en: $\bullet$
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Image quality. Artifacts and noise often appear in datasets or imaging methods
    or in the devices used to capture images, which may interfere with the learning
    direction of the deep models to make incorrect judgments. Therefore, more effective
    noise reduction methods and dataset cleaning technologies need to be studied.
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of multi-modality based system. Most studies employ only one of medical
    images (CT or X-ray images) to diagnose COVID-19, which is insufficient in complex
    infection situations. A multi-modality based system can take the advantages of
    all modalities and meet more complex requirement of diagnosis.
  id: totrans-253
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of research on 3D images. With the development of medical imaging, 3D images
    have been used with richer medical information. However, most advanced deep learning
    models are trained on 2D images, which may ignore many important features.
  id: totrans-255
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intersection of computer science and medicine fields. The applications of
    deep learning in the fight against COVID-19 require deep collaboration in computer
    science, medical imaging, bioinformatics, virology and many other related fields.
  id: totrans-257
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data privacy. Facing the outbreak of COVID-19, most studies require a series
    of data such as personal information, image, and clinical record of patients.
    A question worth thinking is how to effectively protect the privacy and human
    rights of patients in the fight against COVID-19 based on deep learning.
  id: totrans-259
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7.2\. Future Work
  id: totrans-260
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to make better use of medical images and deep learning to fight against
    COVID-19, future studies can study the COVID-19 diagnosis from the following different
    perspectives.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiclass classification. To better fight against COVID-19 and meet the complex
    infection situation, the future diagnostic model should consider the direction
    of multiclass classification. Only if the deep learning technology has a very
    high accuracy in multiclass classification, can it possibly outperform the existing
    RT-PCR.
  id: totrans-263
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-contact detection. During CXR and CT image inspection, the non-contact image
    acquisition can significantly decrease the infection risk between radiologists
    and patients in the COVID-19 pandemic.
  id: totrans-265
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data fusion. Numerous annotated samples are required by deep learning models
    and different hospitals and institutions, which have different data collection
    protocols. The types and formats of collected data can be significantly different
    from each other. Hence, a very meaningful direction is to use data fusion methods
    to build a large-scale dataset.
  id: totrans-267
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning. Most studies employ a small-scale dataset, which is likely
    to lead to model underfitting and poor performance. Transfer learning is worth
    studying to speed up the training of models and improve the performance by transferring
    knowledge from similar domains.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incremental learning. In almost all areas of the fight against COVID-19, the
    dataset and new studies are growing steadily. One question worth noticing is how
    to improve the ability to optimize old knowledge while absorbing new knowledge.
    Thus we suggest all the models should be implemented in an incremental way.
  id: totrans-271
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 增量学习。在抗击COVID-19的几乎所有领域中，数据集和新研究稳步增长。值得注意的一个问题是如何在吸收新知识的同时提高优化旧知识的能力。因此，我们建议所有模型应以增量方式实现。
- en: $\bullet$
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Multi-modality. A single-modality based prediction systems generally have limited
    predictive performance. In the future, we can consider integrating multiple image
    information, and even combine with clinical information, which will greatly improve
    the performance of model and interpretability.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多模态。基于单一模态的预测系统通常具有有限的预测性能。未来，我们可以考虑整合多个图像信息，甚至结合临床信息，这将大大提高模型的性能和可解释性。
- en: $\bullet$
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Optimization. Many problems in deep learning are optimization problems, and
    existing methods such as gradient descent tend to fall into local optimum. It
    is an interesting future direction to use global search algorithms to train the
    deep learning models for COVID-19 diagnosis.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 优化。深度学习中的许多问题都是优化问题，现有方法如梯度下降往往会陷入局部最优。利用全局搜索算法来训练用于COVID-19诊断的深度学习模型是一个有趣的未来方向。
- en: $\bullet$
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Interpretability. Deep learning has achieved excellent performance in diagnosing
    COVID-19\. However, it is a black box, and it is difficult to understand the cause
    of certain predictions. Hence, explainable deep learning models are worth studying
    and are the key to making AI techniques truly effective.
  id: totrans-277
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性。深度学习在诊断COVID-19方面取得了优异的表现。然而，它仍然是一个黑箱，很难理解某些预测的原因。因此，可解释的深度学习模型值得研究，是使AI技术真正有效的关键。
- en: 8\. Conclusion
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8\. 结论
- en: Coronavirus disease 2019 (COVID-19) has significantly influenced healthcare
    systems and finical markets around the world since its outbreak. To interrupt
    the spreading virus, medical imaging has proven to be an important tool in early
    COVID-19 detection and severity evaluation. In this survey, we investigate the
    main scope and contribution of deep learning applications based on medical imaging
    in diagnosing COVID-19\. Although deep learning model based on medical images
    cannot replace existing RT-PCR test at current stage, it has shown great potential
    in diagnosing COVID-19 and has become an important complement to RT-PCR. Meanwhile,
    we gather available datasets for diagnosing COVID-19 and point out that appropriate
    image preprocessing techniques can improve the generalization performance of the
    model. Later, we introduce the existing deep learning applications for diagnosing
    COVID-19, including lesion segmentation, image classification and severity quantification.
    Meanwhile, some methods used to improve the performance of deep model are discussed.
    Finally, we discuss some challenges and future directions for using deep learning
    technologies and medical image processing to diagnose COVID-19\. We believe that
    with the help of deep learning and image processing technologies, and many other
    disciplines, the outbreak of COVID-19 will be better managed. We sincerely hope
    that this paper will be a good reference and will drive more new studies on deep
    learning and medical imaging to fight against COVID-19 epidemic and future outbreak
    on respiratory disease.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 自2019年冠状病毒病（COVID-19）爆发以来，它对全球医疗系统和金融市场产生了重大影响。为了遏制病毒传播，医学影像已被证明是早期COVID-19检测和严重性评估的重要工具。在这项调查中，我们研究了基于医学影像的深度学习应用在诊断COVID-19方面的主要范围和贡献。虽然基于医学影像的深度学习模型在当前阶段无法替代现有的RT-PCR检测，但它在诊断COVID-19方面显示出了巨大潜力，并成为RT-PCR的重要补充。同时，我们汇总了用于诊断COVID-19的可用数据集，并指出适当的图像预处理技术可以提高模型的泛化性能。随后，我们介绍了现有的用于诊断COVID-19的深度学习应用，包括病灶分割、图像分类和严重性量化。同时，讨论了用于提高深度模型性能的一些方法。最后，我们讨论了使用深度学习技术和医学图像处理技术来诊断COVID-19的一些挑战和未来方向。我们相信，借助深度学习和图像处理技术以及许多其他学科，COVID-19的爆发将得到更好的管理。我们真诚地希望这篇论文能成为一个良好的参考，并推动更多关于深度学习和医学影像的新研究，以应对COVID-19疫情和未来的呼吸道疾病爆发。
- en: References
  id: totrans-280
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Abraham and Nair (2022) Bejoy Abraham and Madhu S Nair. 2022. Computer-aided
    detection of COVID-19 from CT scans using an ensemble of CNNs and KSVM classifier.
    *Signal, Image and Video Processing* 16, 3 (2022), 587–594.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abraham and Khan (2019) Nabila Abraham and Naimul Mefraz Khan. 2019. A novel
    focal tversky loss function with improved attention u-net for lesion segmentation.
    In *2019 IEEE 16th international symposium on biomedical imaging (ISBI 2019)*.
    IEEE, 683–687.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acar et al. (2021) Erdi Acar, Engin Şahin, and İhsan Yılmaz. 2021. Improving
    effectiveness of different deep learning-based models for detecting COVID-19 from
    computed tomography (CT) images. *Neural Computing and Applications* 33, 24 (2021),
    17589–17609.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agrawal et al. (2022) Shrishtee Agrawal, Abhishek Singh, Abhishek Tiwari, Anushri
    Mishra, and Abhinandan Tripathi. 2022. A Systematic Survey on COVID 19 Detection
    and Diagnosis by Utilizing Deep Learning Techniques and Modalities of Radiology.
    In *Proceedings of the 2022 Fourteenth International Conference on Contemporary
    Computing*. 446–452.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ahuja et al. (2021) Sakshi Ahuja, Bijaya Ketan Panigrahi, Nilanjan Dey, Venkatesan
    Rajinikanth, and Tapan Kumar Gandhi. 2021. Deep transfer learning-based automated
    detection of COVID-19 from lung CT scan slices. *Applied Intelligence* 51, 1 (2021),
    571–585.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akbarimajd et al. (2022) Adel Akbarimajd, Nicolas Hoertel, Mohammad Arafat Hussain,
    Ali Asghar Neshat, Mahmoud Marhamati, Mahdi Bakhtoor, and Mohammad Momeny. 2022.
    Learning-to-augment incorporated noise-robust deep CNN for detection of COVID-19
    in noisy X-ray images. *Journal of Computational Science* 63 (2022), 101763 –
    101763.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Al-Antari et al. (2021) Mugahed A Al-Antari, Cam-Hao Hua, Jaehun Bang, and Sungyoung
    Lee. 2021. Fast deep learning computer-aided diagnosis of COVID-19 based on digital
    chest x-ray images. *Applied Intelligence* 51, 5 (2021), 2890–2907.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alafif et al. (2021) Tarik Alafif, Abdul Muneeim Tehame, Saleh Bajaba, Ahmed
    Barnawi, and Saad Zia. 2021. Machine and deep learning towards COVID-19 diagnosis
    and treatment: survey, challenges, and future directions. *International journal
    of environmental research and public health* 18, 3 (2021), 1117.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alirr (2022) Omar Ibrahim Alirr. 2022. Automatic deep learning system for COVID-19
    infection quantification in chest CT. *Multimedia Tools and Applications* 81,
    1 (2022), 527–541.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alyasseri et al. (2022) Zaid Abdi Alkareem Alyasseri, Mohammed Azmi Al-Betar,
    Iyad Abu Doush, Mohammed A Awadallah, Ammar Kamal Abasi, Sharif Naser Makhadmeh,
    Osama Ahmad Alomari, Karrar Hameed Abdulkareem, Afzan Adam, Robertas Damasevicius,
    et al. 2022. Review on COVID-19 diagnosis models based on machine learning and
    deep learning approaches. *Expert systems* 39, 3 (2022), e12759.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alzubaidi et al. (2021) Laith Alzubaidi, Jinglan Zhang, Amjad J Humaidi, Ayad
    Al-Dujaili, Ye Duan, Omran Al-Shamma, José Santamaría, Mohammed A Fadhel, Muthana
    Al-Amidie, and Laith Farhan. 2021. Review of deep learning: Concepts, CNN architectures,
    challenges, applications, future directions. *Journal of big Data* 8, 1 (2021),
    1–74.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amin et al. (2022) Javeria Amin, Muhammad Almas Anjum, Muhammad Sharif, Amjad
    Rehman, Tanzila Saba, and Rida Zahra. 2022. Microscopic segmentation and classification
    of COVID-19 infection with ensemble convolutional neural network. *Microscopy
    research and technique* 85, 1 (2022), 385–397.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annavarapu et al. (2021) Chandra Sekhara Rao Annavarapu et al. 2021. Deep learning-based
    improved snapshot ensemble technique for COVID-19 chest X-ray classification.
    *Applied Intelligence* 51, 5 (2021), 3104–3120.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Anwar et al. (2018) Syed Muhammad Anwar, Muhammad Majid, Adnan Qayyum, Muhammad
    Awais, Majdi Alnowami, and Muhammad Khurram Khan. 2018. Medical image analysis
    using convolutional neural networks: a review. *Journal of medical systems* 42,
    11 (2018), 1–13.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apostolopoulos et al. (2020) Ioannis D. Apostolopoulos, Sokratis Aznaouridis,
    and Mpesiana Tzani. 2020. Extracting Possibly Representative COVID-19 Biomarkers
    from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary
    Diseases. *Journal of Medical and Biological Engineering* 40 (2020), 462 – 469.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apostolopoulos and Bessiana (2020) Ioannis D. Apostolopoulos and Tzani Bessiana.
    2020. Covid-19: automatic detection from X-ray images utilizing transfer learning
    with convolutional neural networks. *Physical and Engineering Sciences in Medicine*
    43 (2020), 635 – 640.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aslan et al. (2022) Muhammet Fatih Aslan, Kadir Sabanci, Akif Durdu, and Muhammed Fahri
    Unlersen. 2022. COVID-19 diagnosis using state-of-the-art CNN architecture features
    and Bayesian Optimization. *Computers in Biology and Medicine* 142 (2022), 105244
    – 105244.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aslan et al. (2020) Muhammet Fatih Aslan, Muhammed Fahri Unlersen, Kadir Sabanci,
    and Akif Durdu. 2020. CNN-based transfer learning–BiLSTM network: A novel approach
    for COVID-19 infection detection. *Applied Soft Computing* 98 (2020), 106912 –
    106912.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avetisian et al. (2021) Manvel Avetisian, Ilya Burenko, Konstantin Egorov,
    Vladimir Kokh, Aleksandr Nesterov, Aleksandr Nikolaev, Alexander Ponomarchuk,
    Elena Sokolova, Alex Tuzhilin, and Dmitry Umerenkov. 2021. CoRSAI: A system for
    robust interpretation of CT scans of COVID-19 patients using deep learning. *ACM
    Transactions on Management Information Systems (TMIS)* 12, 4 (2021), 1–16.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baghdadi et al. (2022) Nadiah A Baghdadi, Amer Malki, Sally F. Abdelaliem, Hossam Magdy
    Balaha, Mahmoud Mohammed Badawy, and Mostafa A. Elhosseini. 2022. An automated
    diagnosis and classification of COVID-19 from chest CT images using a transfer
    learning-based convolutional neural network. *Computers in Biology and Medicine*
    144 (2022), 105383 – 105383.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balaha et al. (2022) Hossam Magdy Balaha, Eman M El-Gendy, and Mahmoud M Saafan.
    2022. A complete framework for accurate recognition and prognosis of COVID-19
    patients based on deep transfer learning and feature classification approach.
    *Artificial Intelligence Review* (2022), 1–46.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bao et al. (2020) Cuiping Bao, Xuehuan Liu, Han Zhang, Yiming Li, and Jun Liu.
    2020. Coronavirus disease 2019 (COVID-19) CT findings: a systematic review and
    meta-analysis. *Journal of the American college of radiology* 17, 6 (2020), 701–709.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bargshady et al. (2022) Ghazal Bargshady, Xujuan Zhou, Prabal Datta Barua, Raj
    Gururajan, Yuefeng Li, and U Rajendra Acharya. 2022. Application of CycleGAN and
    transfer learning techniques for automated detection of COVID-19 using X-ray images.
    *Pattern Recognition Letters* 153 (2022), 67–74.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basu et al. (2020) Sanhita Basu, Sushmita Mitra, and Nilanjan Saha. 2020. Deep
    Learning for Screening COVID-19 using Chest X-Ray Images. *2020 IEEE Symposium
    Series on Computational Intelligence (SSCI)* (2020), 2521–2527.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhattacharya et al. (2021) Sweta Bhattacharya, Praveen Kumar Reddy Maddikunta,
    Quoc-Viet Pham, Thippa Reddy Gadekallu, Chiranji Lal Chowdhary, Mamoun Alazab,
    Md Jalil Piran, et al. 2021. Deep learning and medical image processing for coronavirus
    (COVID-19) pandemic: A survey. *Sustainable cities and society* 65 (2021), 102589.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bhattacharyya et al. (2022) Abhijit Bhattacharyya, Divyanshu Bhaik, Sunil Kumar,
    Prayas Thakur, Rahul Sharma, and Ram Bilas Pachori. 2022. A deep learning based
    approach for automatic detection of COVID-19 cases using chest X-ray images. *Biomedical
    Signal Processing and Control* 71 (2022), 103182.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brunese et al. (2020) Luca Brunese, Francesco Mercaldo, Alfonso Reginelli, and
    Antonella Santone. 2020. Explainable Deep Learning for Pulmonary Disease and Coronavirus
    COVID-19 Detection from X-rays. *Computer Methods and Programs in Biomedicine*
    196 (2020), 105608 – 105608.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canayaz et al. (2022) Murat Canayaz, Sanem Şehribanoğlu, Recep Özdağ, and Murat
    Demir. 2022. COVID-19 diagnosis on CT images with Bayes optimization-based deep
    neural networks and machine learning algorithms. *Neural Computing and Applications*
    34, 7 (2022), 5349–5365.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chakraborty et al. (2021) Mainak Chakraborty, Sunita Vikrant Dhavale, and Jitendra
    Ingole. 2021. Corona-Nidaan: lightweight deep convolutional neural network for
    chest X-Ray based COVID-19 infection detection. *Applied Intelligence* 51, 5 (2021),
    3026–3043.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chamberlin et al. (2022) Jordan H Chamberlin, Gilberto Aquino, Sophia Nance,
    Andrew Wortham, Nathan Leaphart, Namrata Paladugu, Sean Brady, Henry Baird, Matthew
    Fiegel, Logan Fitzpatrick, et al. 2022. Automated diagnosis and prognosis of COVID-19
    pneumonia from initial ER chest X-rays using deep learning. *BMC Infectious Diseases*
    22, 1 (2022), 1–13.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaudhary and Qiang (2021) Suman Chaudhary and Yan Qiang. 2021. Ensemble deep
    learning method for Covid-19 detection via chest X-rays. In *2021 Ethics and Explainability
    for Responsible Data Science (EE-RDS)*. IEEE, 1–3.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2022) Han Chen, Yifan Jiang, Murray Loew, and Hanseok Ko. 2022.
    Unsupervised domain adaptation based COVID-19 CT infection segmentation network.
    *Applied Intelligence (Dordrecht, Netherlands)* 52 (2022), 6340 – 6353.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021) Jianguo Chen, Kenli Li, Zhaolei Zhang, Keqin Li, and Philip S
    Yu. 2021. A survey on applications of artificial intelligence in fighting against
    COVID-19. *ACM Computing Surveys (CSUR)* 54, 8 (2021), 1–32.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choudhary et al. (2022) Tejalal Choudhary, Shubham Gujar, Anurag Goswami, Vipul
    Mishra, and Tapas Badal. 2022. Deep learning-based important weights-only transfer
    learning approach for COVID-19 CT-scan classification. *Applied Intelligence*
    (2022), 1–15.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cohen et al. (2020) Joseph Paul Cohen, Paul Morrison, and Lan Dao. 2020. COVID-19
    Image Data Collection. *ArXiv* abs/2003.11597 (2020).
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Das et al. (2022) Dolly Das, Saroj Kumar Biswas, and Sivaji Bandyopadhyay.
    2022. Perspective of AI system for COVID-19 detection using chest images: a review.
    *Multimedia Tools and Applications* (2022), 1–31.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Das et al. (2019) Sushmita Das, Ankur Deka, Yuji Iwahori, Manas Kamal Bhuyan,
    Takashi Iwamoto, and Jun Ueda. 2019. Contour-Aware Residual W-Net for Nuclei Segmentation.
    In *International Conference on Knowledge-Based Intelligent Information & Engineering
    Systems*.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demir (2021) Fatih Demir. 2021. DeepCoroNet: A deep LSTM approach for automated
    detection of COVID-19 cases from chest X-ray images. *Applied Soft Computing*
    103 (2021), 107160.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dev et al. (2021) Kapal Dev, Sunder Ali Khowaja, Ankur Singh Bist, Vaibhav Saini,
    and Surbhi Bhatia. 2021. Triage of potential COVID-19 patients from chest X-ray
    images using hierarchical convolutional networks. *Neural Computing and Applications*
    (2021), 1–16.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhaka et al. (2021) Vijaypal Singh Dhaka, Geeta Rani, Meet Ganpatlal Oza, Tarushi
    Sharma, and Ankit Misra. 2021. A deep learning model for mass screening of COVID-19.
    *International journal of imaging systems and technology* 31, 2 (2021), 483–498.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diniz et al. (2021) João OB Diniz, Darlan BP Quintanilha, Antonino C Santos Neto,
    Giovanni LF da Silva, Jonnison L Ferreira, Stelmo Netto, José DL Araújo, Luana B
    Da Cruz, Thamila FB Silva, Caio M da S Martins, et al. 2021. Segmentation and
    quantification of COVID-19 infections in CT using pulmonary vessels extraction
    and deep learning. *Multimedia Tools and Applications* 80, 19 (2021), 29367–29399.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2020) Xibin Dong, Zhiwen Yu, Wenming Cao, Yifan Shi, and Qianli
    Ma. 2020. A survey on ensemble learning. *Frontiers of Computer Science* 14, 2
    (2020), 241–258.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Doraiswami et al. (2022) Palanivel Rajan Doraiswami, Velliangiri Sarveshwaran,
    Iwin Thanakumar Joseph Swamidason, and Sona Chandra Devadass Sorna. 2022. Jaya-tunicate
    swarm algorithm based generative adversarial network for COVID-19 prediction with
    chest computed tomography images. *Concurrency and Computation: Practice and Experience*
    (2022), e7211.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elharrouss et al. (2022) Omar Elharrouss, Nandhini Subramanian, and Somaya Al-Maadeed.
    2022. An encoder–decoder-based method for segmentation of COVID-19 lung infection
    in CT images. *SN Computer Science* 3, 1 (2022), 1–12.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elpeltagy and Sallam (2021) Marwa Elpeltagy and Hany Sallam. 2021. Automatic
    prediction of COVID- 19 from chest images using modified ResNet50. *Multimedia
    tools and applications* 80, 17 (2021), 26451–26463.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Er (2022) Mehmet Bilal Er. 2022. COVID‐19 detection based on pre‐trained deep
    networks and LSTM model using X‐ray images enhanced contrast with artificial bee
    colony algorithm. *Expert Systems* (2022).
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Farhat et al. (2020) Hanan Farhat, George E Sakr, and Rima Kilany. 2020. Deep
    learning applications in pulmonary medical imaging: recent updates and insights
    on COVID-19. *Machine vision and applications* 31, 6 (2020), 1–42.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Farooq and Hafeez (2020) Muhammad Shoaib Farooq and Abdul Hafeez. 2020. COVID-ResNet:
    A Deep Learning Framework for Screening of COVID19 from Radiographs. *ArXiv* abs/2003.14395
    (2020).'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Garain et al. (2021) Avishek Garain, Arpan Basu, Fabio Giampaolo, Juan D Velasquez,
    and Ram Sarkar. 2021. Detection of COVID-19 from CT scan images: A spiking neural
    network-based approach. *Neural Computing and Applications* 33, 19 (2021), 12591–12604.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goel et al. (2021) Tripti Goel, R Murugan, Seyedali Mirjalili, and Deba Kumar
    Chakrabartty. 2021. Automatic screening of covid-19 using an optimized generative
    adversarial network. *Cognitive computation* (2021), 1–16.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guan and Liu (2021) Hao Guan and Mingxia Liu. 2021. Domain adaptation for medical
    image analysis: a survey. *IEEE Transactions on Biomedical Engineering* 69, 3
    (2021), 1173–1185.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gunraj et al. (2020) Hayden Gunraj, Linda Wang, and Alexander Wong. 2020. COVIDNet-CT:
    A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19
    Cases From Chest CT Images. *Frontiers in Medicine* 7 (2020).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Habib et al. (2022) Mohammed Habib, Muhammad Ramzan, and Sajid Ali Khan. 2022.
    A Deep Learning and Handcrafted Based Computationally Intelligent Technique for
    Effective COVID-19 Detection from X-ray/CT-scan Imaging. *Journal of Grid Computing*
    20, 3 (2022), 1–20.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hall et al. (2020) Lawrence O. Hall, Rahul Paul, Dmitry B. Goldgof, and Gregory M.
    Goldgof. 2020. Finding Covid-19 from Chest X-rays using Deep Learning on a Small
    Dataset. *ArXiv* abs/2004.02060 (2020).
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hamza et al. (2022) Ameer Hamza, Muhammad Attique Khan, Shuihua Wang, Abdullah
    Alqahtani, Shtwai Alsubai, Adel Binbusayyis, Hany S. Hussein, Thomas Martinetz,
    and Hammam A. Alshazly. 2022. COVID-19 classification using chest X-ray images:
    A framework of CNN-LSTM and improved max value moth flame optimization. *Frontiers
    in Public Health* 10 (2022).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hasan et al. (2020) Ali M Hasan, Mohammed M Al-Jawad, Hamid A Jalab, Hadil Shaiba,
    Rabha W Ibrahim, and Ala’a R AL-Shamasneh. 2020. Classification of Covid-19 coronavirus,
    pneumonia and healthy lungs in CT scans using Q-deformed entropy and deep learning
    features. *Entropy* 22, 5 (2020), 517.
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hasan et al. (2021) Najmul Hasan, Yukun Bao, Ashadullah Shawon, and Yanmei Huang.
    2021. DenseNet convolutional neural networks application for predicting COVID-19
    using CT image. *SN computer science* 2, 5 (2021), 1–11.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) Jian-Long He, Lin Luo, Zhen-Dong Luo, Jian-Xun Lyu, Ming-Yen
    Ng, Xin-Ping Shen, and Zhibo Wen. 2020. Diagnostic performance between CT and
    initial real-time RT-PCR for clinically suspected 2019 coronavirus disease (COVID-19)
    patients outside Wuhan, China. *Respiratory medicine* 168 (2020), 105980.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition*. 770–778.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heidari et al. (2020) Morteza Heidari, Seyedehnafiseh Mirniaharikandehei, Abolfazl Zargari
    Khuzani, Gopichandh Danala, Yuchen Qiu, Bin Zheng School of Electrical, Computer
    Engineering, University of Oklahoma, Norman Usa, Department of Electrical, University
    of California at Santa Cruz, Santa Cruz, and Usa. 2020. Improving the performance
    of CNN to predict the likelihood of COVID-19 using chest X-ray images with preprocessing
    algorithms. *International Journal of Medical Informatics* 144 (2020), 104284
    – 104284.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heidarian et al. (2021) Shahin Heidarian, Parnian Afshar, Nastaran Enshaei,
    Farnoosh Naderkhani, Moezedin Javad Rafiee, Faranak Babaki Fard, Kaveh Samimi,
    S Farokh Atashzar, Anastasia Oikonomou, Konstantinos N Plataniotis, et al. 2021.
    Covid-fact: A fully-automated capsule network-based framework for identification
    of covid-19 cases from chest ct scans. *Frontiers in Artificial Intelligence*
    4 (2021), 598932.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hira et al. (2021) Swati Hira, Anita Bai, and Sanchit Hira. 2021. An automatic
    approach based on CNN architecture to detect Covid-19 disease from chest X-ray
    images. *Applied Intelligence* 51, 5 (2021), 2864–2889.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hryniewska et al. (2021) Weronika Hryniewska, Przemyslaw Bombinski, Patryk Szatkowski,
    Paulina Tomaszewska, Artur Przelaskowski, and Przemysław Biecek. 2021. Checklist
    for responsible deep learning modeling of medical images based on COVID-19 detection
    studies. *Pattern Recognition* 118 (2021), 108035 – 108035.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2017) Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. 2017. Densely connected convolutional networks. In *Proceedings of
    the IEEE conference on computer vision and pattern recognition*. 4700–4708.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang (2020) Huishi Huang. 2020. COVID-19 CT Image Recognition Based on Multi-stage
    Transfer Learning. In *Proceedings of the 2020 International Conference on Aviation
    Safety and Information Technology*. 682–688.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2021b) Ling Huang, Su Ruan, and Thierry Denoeux. 2021b. Covid-19
    classification with deep neural network and belief functions. In *The Fifth International
    Conference on Biological Information and Biomedical Engineering*. 1–4.
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2021a) Zhenxing Huang, Xinfeng Liu, Rongpin Wang, Mudan Zhang,
    Xianchun Zeng, Jun Liu, Yongfeng Yang, Xin Liu, Hairong Zheng, Dong Liang, et al.
    2021a. FaNet: fast assessment network for the novel coronavirus (COVID-19) pneumonia
    based on 3D CT imaging and clinical symptoms. *Applied Intelligence* 51, 5 (2021),
    2838–2849.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huggett et al. (2005) J Huggett, K Dheda, S Bustin, and A Zumla. 2005. Real-time
    RT-PCR normalisation; strategies and considerations. *Genes & Immunity* 6, 4 (2005),
    279–284.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iandola et al. (2016) Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid
    Ashraf, William J Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy
    with 50x fewer parameters and¡ 0.5 MB model size. *arXiv preprint arXiv:1602.07360*
    (2016).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ibrahim et al. (2021) Abdullahi Umar Ibrahim, Mehmet Ozsoz, Sertan Serte, Fadi
    Al-Turjman, and Polycarp Shizawaliyi Yakoi. 2021. Pneumonia classification using
    deep learning from chest X-ray images during COVID-19. *Cognitive Computation*
    (2021), 1–13.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ilhan et al. (2022) Hamza Osman Ilhan, Gorkem Serbes, and Nizamettin Aydin.
    2022. Decision and feature level fusion of deep features extracted from public
    COVID-19 data-sets. *Applied Intelligence* 52, 8 (2022), 8551–8571.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jacobi et al. (2020) Adam Jacobi, Michael Chung, Adam Bernheim, and Corey Eber.
    2020. Portable chest X-ray in coronavirus disease-19 (COVID-19): A pictorial review.
    *Clinical imaging* 64 (2020), 35–42.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jadhav et al. (2021) Shreeraj Jadhav, Gaofeng Deng, Marlene Zawin, and Arie E
    Kaufman. 2021. COVID-view: Diagnosis of COVID-19 using Chest CT. *IEEE transactions
    on visualization and computer graphics* 28, 1 (2021), 227–237.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jain et al. (2021) Rachna Jain, Meenu Gupta, Soham Taneja, and D Jude Hemanth.
    2021. Deep learning based detection and analysis of COVID-19 on chest X-ray images.
    *Applied Intelligence* 51, 3 (2021), 1690–1700.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jangam et al. (2022) Ebenezer Jangam, Aaron Antonio Dias Barreto, and Chandra
    Sekhara Rao Annavarapu. 2022. Automatic detection of COVID-19 from chest CT scan
    and chest X-Rays images using deep learning, transfer learning and stacking. *Applied
    Intelligence* 52, 2 (2022), 2243–2259.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2021) Hao Jiang, Shiming Tang, Weihuang Liu, and Yang Zhang.
    2021. Deep learning for COVID-19 chest CT (computed tomography) image analysis:
    A lesson from lung cancer. *Computational and Structural Biotechnology Journal*
    19 (2021), 1391–1399.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joshi et al. (2022) Amogh Manoj Joshi, Deepak Ranjan Nayak, Dibyasundar Das,
    and Yu-Dong Zhang. 2022. LiMS-Net: A Lightweight Multi-Scale CNN for COVID-19
    Detection from Chest CT Scans. *ACM Transactions on Management Information Systems
    (TMIS)* (2022).'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kannan et al. (2020) SPAS Kannan, P Shaik Syed Ali, A Sheeza, and K Hemalatha.
    2020. COVID-19 (Novel Coronavirus 2019)-recent trends. *Eur Rev Med Pharmacol
    Sci* 24, 4 (2020), 2006–2011.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Karacı (2022) Abdulkadir Karacı. 2022. VGGCOV19-NET: automatic detection of
    COVID-19 cases from X-ray images using modified VGG19 CNN architecture and YOLO
    algorithm. *Neural Computing and Applications* 34, 10 (2022), 8253–8274.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kashala Kabe et al. (2021) Gedeon Kashala Kabe, Yuqing Song, and Zhe Liu. 2021.
    Novel Distant Domain Transfer Learning Method for COVID-19 Classification from
    X-rays Images. In *2021 The 5th International Conference on Algorithms, Computing
    and Systems*. 127–134.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keles et al. (2021) Ayturk Keles, Mustafa Berk Keles, and Ali Keles. 2021.
    COV19-CNNet and COV19-ResNet: diagnostic inference Engines for early detection
    of COVID-19. *Cognitive Computation* (2021), 1–11.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ker et al. (2017) Justin Ker, Lipo Wang, Jai Rao, and Tchoyoson Lim. 2017. Deep
    learning applications in medical image analysis. *Ieee Access* 6 (2017), 9375–9389.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2022) Azrin Khan, Rachael Garner, Marianna La Rocca, Sana Salehi,
    and Dominique Duncan. 2022. A Novel Threshold-Based Segmentation Method for Quantification
    of COVID-19 Lung Abnormalities. *Signal, Image and Video Processing* (2022), 1–8.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2021) Saddam Hussain Khan, Anabia Sohail, Asifullah Khan, Mehdi
    Hassan, Yeon Soo Lee, Jamshed Alam, Abdul Basit, and Saima Zubair. 2021. COVID-19
    detection in chest X-ray images using deep boosted hybrid learning. *Computers
    in Biology and Medicine* 137 (2021), 104816. [https://doi.org/10.1016/j.compbiomed.2021.104816](https://doi.org/10.1016/j.compbiomed.2021.104816)
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khurana and Soni (2022) Yashika Khurana and Umang Soni. 2022. Leveraging deep
    learning for COVID-19 diagnosis through chest imaging. *Neural Computing and Applications*
    (2022), 1–10.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2021) Ga Young Kim, Jae Yong Kim, Chae Hyeon Kim, and Sung Min
    Kim. 2021. Evaluation of deep learning for COVID-19 diagnosis: impact of image
    dataset organization. *Journal of Applied Clinical Medical Physics* 22, 7 (2021),
    297–305.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2020) Hyunjoong W Kim, KM Capaccione, Gen Li, Lyndon Luk, Reginald S
    Widemon, Ozair Rahman, Volkan Beylergil, Ryan Mitchell, Belinda M D’Souza, Jay S
    Leb, et al. 2020. The role of initial chest X-ray in triaging patients with suspected
    COVID-19 during the pandemic. *Emergency radiology* 27, 6 (2020), 617–621.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kiruthika et al. (2021) S Kiruthika, V Masilamani, and Pratik Joshi. 2021. Fusion
    of image quality assessment and transfer learning for COVID19 detection using
    CT scan image. In *12th Indian Conference on Computer Vision, Graphics and Image
    Processing, ICVGIP 2021*.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kogilavani et al. (2022) Shanmuga Vadivel Kogilavani, J. Prabhu, Raman Sandhiya,
    M. Sandeep Kumar, Umashankar Subramaniam, Alagar Karthick, Muhammad Muhibbullah,
    and Sharmila Banu Sheik Imam. 2022. COVID-19 Detection Based on Lung Ct Scan Using
    Deep Learning Techniques. *Computational and Mathematical Methods in Medicine*
    2022 (2022).
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krishnamoorthy et al. (2021) Sabitha Krishnamoorthy, Sudhakar Ramakrishnan,
    Lanson Brijesh Colaco, Akshay Dias, Indu K Gopi, Gautham AG Gowda, KC Aishwarya,
    Veena Ramanan, and Manju Chandran. 2021. Comparing a deep learning model’s diagnostic
    performance to that of radiologists to detect Covid-19 features on chest radiographs.
    *Indian Journal of Radiology and Imaging* 31, S 01 (2021), S53–S60.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2017) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    2017. Imagenet classification with deep convolutional neural networks. *Commun.
    ACM* 60, 6 (2017), 84–90.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuchana et al. (2021) Maheshwar Kuchana, Amritesh Srivastava, Ronald Das, Justin
    Mathew, Atul Mishra, and Kiran Khatter. 2021. AI aiding in diagnosing, tracking
    recovery of COVID-19 using deep learning on Chest CT scans. *Multimedia tools
    and applications* 80, 6 (2021), 9161–9175.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumari and Jagadesh (2022) L Kanya Kumari and B Naga Jagadesh. 2022. A Deep
    Convolutional Neural Network for COVID-19 Chest CT-Scan Image Classification.
    In *High Performance Computing and Networking*. Springer, 603–612.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kundu et al. (2022) Rohit Kundu, Pawan Kumar Singh, Massimiliano Ferrara, Ali
    Ahmadian, and Ram Sarkar. 2022. ET-NET: an ensemble of transfer learning models
    for prediction of COVID-19 infection through chest CT-scan images. *Multimedia
    Tools and Applications* 81, 1 (2022), 31–50.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kwee and Kwee (2020) Thomas C Kwee and Robert M Kwee. 2020. Chest CT in COVID-19:
    what the radiologist needs to know. *Radiographics* 40, 7 (2020), 1848.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lashchenova et al. (2021) D Lashchenova, A Gromov, Anton Konushin, and A Mesheryakova.
    2021. The Improvement of Segmentation of Lung Pathologies and Pleural Effusion
    on CT-scans of Patients with Covid-19. *Programming and Computer Software* 47,
    4 (2021), 327–333.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021b) Xue-Ying Li, Yang Zhou, Zi-Xuan Kong, Mei-Dan Hou, Ning Luo,
    Wei-Hang Sun, Nan Huang, Chao Yang, Ao-Dan Zhang, and Yu-Shi Li. 2021b. Exploration
    of CT manifestations of different clinical types of novel coronavirus pneumonia.
    *Ann Palliat Med* 10 (2021), 37–44.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021a) Zonggui Li, Junhua Zhang, Bo Li, Xiaoying Gu, and Xudong Luo.
    2021a. COVID‐19 diagnosis on CT scan images using a generative adversarial network
    and concatenated feature pyramid network with an attention mechanism. *Medical
    Physics* 48 (2021), 4334 – 4349.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lian et al. (2022) Luoyu Lian, Xin Luo, Canyu Pan, Jinlong Huang, Wen juan Hong,
    and Zhendong Xu. 2022. Lung image segmentation based on DRD U-Net and combined
    WGAN with Deep Neural Network. *Computer Methods and Programs in Biomedicine*
    226 (2022), 107097 – 107097.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2017) Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
    Piotr Dollár. 2017. Focal loss for dense object detection. In *Proceedings of
    the IEEE international conference on computer vision*. 2980–2988.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022) Tianming Liu, Eliot Siegel, and Dinggang Shen. 2022. Deep
    Learning and Medical Image Analysis for COVID-19 Diagnosis and Prediction. *Annual
    review of biomedical engineering* (2022).
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021) Xiangbin Liu, Liping Song, Shuai Liu, and Yudong Zhang. 2021.
    A Review of Deep-Learning-Based Medical Image Segmentation Methods. *Sustainability*
    (2021).
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loew (2022) Murray H Loew. 2022. Brief history of Image Processing at SPIE Medical
    Imaging. *Journal of Medical Imaging* 9, S1 (2022), S12209.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2021) Siyuan Lu, Di Wu, Zheng Zhang, and Shui-Hua Wang. 2021. An
    explainable framework for diagnosis of COVID-19 pneumonia via transfer learning
    and discriminant correlation analysis. *ACM Transactions on Multimedia Computing,
    Communications, and Applications (TOMM)* 17, 3s (2021), 1–16.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2021) Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen,
    Qiongjie Zhu, Guoqiang Dong, Jian He, Zhiqiang He, et al. 2021. Toward data-efficient
    learning: A benchmark for COVID-19 CT lung and infection segmentation. *Medical
    physics* 48, 3 (2021), 1197–1210.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madaan et al. (2021) Vishu Madaan, Aditya Roy, Charu Gupta, Prateek Agrawal,
    Anand Sharma, Cristian Bologa, and Radu Prodan. 2021. XCOVNet: chest X-ray image
    classification for COVID-19 early detection using convolutional neural networks.
    *New Generation Computing* 39, 3 (2021), 583–597.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madhavan et al. (2021) Mangena Venu Madhavan, Aditya Khamparia, Deepak Gupta,
    Sagar Pande, Prayag Tiwari, and M Shamim Hossain. 2021. Res-CovNet: An internet
    of medical health things driven COVID-19 framework using transfer learning. *Neural
    Computing and Applications* (2021), 1–14.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mahendran and Kavitha (2022) N Mahendran and S Kavitha. 2022. A MobileNet-V2
    COVID-19: Multi-class Classification of the COVID-19 by Using CT/CXR Images. In
    *Advances in Electrical and Computer Technologies*. Springer, 727–738.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mak et al. (2020) Gannon CK Mak, Peter KC Cheng, Stephen SY Lau, Kitty KY Wong,
    CS Lau, Edman TK Lam, Rickjason CW Chan, and Dominic NC Tsang. 2020. Evaluation
    of rapid antigen test for detection of SARS-CoV-2 virus. *Journal of Clinical
    Virology* 129 (2020), 104500.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Makris et al. (2020) Antonios Makris, Ioannis Kontopoulos, and Konstantinos
    Tserpes. 2020. COVID-19 detection from chest X-Ray images using Deep Learning
    and Convolutional Neural Networks. In *11th hellenic conference on artificial
    intelligence*. 60–66.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mei et al. (2020) Xueyan Mei, Hao-Chih Lee, Kai-yue Diao, Mingqian Huang, Bin
    Lin, Chenyu Liu, Zongyu Xie, Yixuan Ma, Philip M Robson, Michael Chung, et al.
    2020. Artificial intelligence–enabled rapid diagnosis of patients with COVID-19.
    *Nature medicine* 26, 8 (2020), 1224–1228.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Menon et al. (2020) Sumeet Menon, Joshua Galita, David Chapman, Aryya Gangopadhyay,
    Jayalakshmi Mangalagiri, Phuong Nguyen, Yaacov Yesha, Yelena Yesha, Babak Saboury,
    and Michael Morris. 2020. Generating Realistic COVID19 X-rays with a Mean Teacher
    + Transfer Learning GAN. *ArXiv* abs/2009.12478 (2020).
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Meraihi et al. (2022) Yassine Meraihi, Asma Benmessaoud Gabis, Seyedali Mirjalili,
    Amar Ramdane-Cherif, and Fawaz E Alsaadi. 2022. Machine Learning-Based Research
    for COVID-19 Detection, Diagnosis, and Prediction: A Survey. *SN Computer Science*
    3, 4 (2022), 1–35.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miao et al. (2021) Rui Miao, Xin Dong, Sheng-Li Xie, Yong Liang, and Sio-Long
    Lo. 2021. UMLF-COVID: an unsupervised meta-learning model specifically designed
    to identify X-ray images of COVID-19 patients. *BMC medical imaging* 21, 1 (2021),
    1–16.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mienye and Sun (2022) Ibomoiye Domor Mienye and Yanxia Sun. 2022. A Survey
    of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects. *IEEE
    Access* 10 (2022), 99129–99149.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mienye et al. (2020) Ibomoiye Domor Mienye, Yanxia Sun, and Zenghui Wang. 2020.
    Improved predictive sparse decomposition method with densenet for prediction of
    lung cancer. *Int. J. Comput* 1 (2020), 533–541.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Milletari et al. (2016) Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi.
    2016. V-net: Fully convolutional neural networks for volumetric medical image
    segmentation. In *2016 fourth international conference on 3D vision (3DV)*. IEEE,
    565–571.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minaee et al. (2022) Shervin Minaee, Yuri Boykov, Fatih Murat Porikli, Antonio J.
    Plaza, Nasser Kehtarnavaz, and Demetri Terzopoulos. 2022. Image Segmentation Using
    Deep Learning: A Survey. *IEEE Transactions on Pattern Analysis and Machine Intelligence*
    44 (2022), 3523–3542.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mishra (2021) Shreyas Mishra. 2021. Deep Transfer Learning-Based Framework for
    COVID-19 Diagnosis Using Chest CT Scans and Clinical Information. *SN Computer
    Science* 2, 5 (2021), 1–11.
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mishra and Kane (2022) Vidyanand Mishra and Lalit Kane. 2022. A survey of designing
    convolutional neural network using evolutionary algorithms. *Artificial Intelligence
    Review* (2022), 1–38.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morid et al. (2021) Mohammad Amin Morid, Alireza Borjali, and Guilherme Del Fiol.
    2021. A scoping review of transfer learning research on medical image analysis
    using ImageNet. *Computers in biology and medicine* 128 (2021), 104115.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mukherjee et al. (2021) Himadri Mukherjee, Subhankar Ghosh, Ankita Dhar, Sk Md
    Obaidullah, KC Santosh, and Kaushik Roy. 2021. Deep neural network to detect COVID-19:
    one architecture for both CT Scans and Chest X-rays. *Applied Intelligence* 51,
    5 (2021), 2777–2789.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naeem and Bin-Salem (2021) Hamad Naeem and Ali Abdulqader Bin-Salem. 2021. A
    CNN-LSTM network with multi-level feature extraction-based approach for automated
    detection of coronavirus from CT scan and X-ray images. *Applied Soft Computing*
    113 (2021), 107918.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nagarajan et al. (2021) Bhagyam Nagarajan, Gayatri Autkar, Aarav Monga, and
    Nikhil Toshniwal. 2021. Lung Manifestations of COVID-19 on Chest Radiographs—Indian
    Experience in a High-Volume Dedicated COVID center. *SN Comprehensive Clinical
    Medicine* 3, 1 (2021), 16–21.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Naudé (2020) Wim Naudé. 2020. Artificial intelligence vs COVID-19: limitations,
    constraints and pitfalls. *AI & society* 35, 3 (2020), 761–765.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nicola et al. (2020) Maria Nicola, Zaid Alsafi, Catrin Sohrabi, Ahmed Kerwan,
    Ahmed Al-Jabir, Christos Iosifidis, Maliha Agha, and Riaz Agha. 2020. The socio-economic
    implications of the coronavirus pandemic (COVID-19): A review. *International
    journal of surgery* 78 (2020), 185–193.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nivetha and Inbarani (2022) S Nivetha and H Hannah Inbarani. 2022. Neighborhood
    Rough Neural Network Approach for COVID-19 Image Classification. *Neural processing
    letters* (2022), 1–23.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pak et al. (2020) Anton Pak, Oyelola A Adegboye, Adeshina I Adekunle, Kazi M
    Rahman, Emma S McBryde, and Damon P Eisen. 2020. Economic consequences of the
    COVID-19 outbreak: the need for epidemic preparedness. *Frontiers in public health*
    8 (2020), 241.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pascual et al. (2021) Elisa Aguirre Pascual, David Coca Robinot, C. Gallego
    Herrero, María Navallas Irujo, Miguel Rasero Ponferrada, and M. Pont Vilalta.
    2021. Pediatric chest X-rays during the COVID-19 pandemic. *Radiologia* (2021).
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pathak et al. (2020) Yadunath Pathak, Prashant Kumar Shukla, Akhilesh Tiwari,
    Shalini Stalin, and Saurabh Singh. 2020. Deep transfer learning based classification
    model for COVID-19 disease. *Irbm* (2020).
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paul et al. (2022) Ashis Paul, Arpan Basu, Mufti Mahmud, M Shamim Kaiser, and
    Ram Sarkar. 2022. Inverted bell-curve-based ensemble of deep learning models for
    detection of COVID-19 from chest X-rays. *Neural Computing and Applications* (2022),
    1–15.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2022) Yong Peng, Enbin Liu, Shanbi Peng, Qikun Chen, Dangjian
    Li, and Dianpeng Lian. 2022. Using artificial intelligence technology to fight
    COVID-19: a review. *Artificial Intelligence Review* (2022), 1–37.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pihur et al. (2007) Vasyl Pihur, Susmita Datta, and Somnath Datta. 2007. Weighted
    rank aggregation of cluster validation measures: a monte carlo cross-entropy approach.
    *Bioinformatics* 23, 13 (2007), 1607–1615.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polat et al. (2021) Hasan Polat, Mehmet Siraç Özerdem, Faysal Ekici, and Veysi
    Akpolat. 2021. Automatic detection and localization of COVID-19 pneumonia using
    axial computed tomography images and deep convolutional neural networks. *International
    Journal of Imaging Systems and Technology* 31, 2 (2021), 509–524.
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pouyanfar et al. (2018) Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian,
    Yudong Tao, Maria Presa Reyes, Mei-Ling Shyu, Shu-Ching Chen, and S. S. Iyengar.
    2018. A Survey on Deep Learning: Algorithms, Techniques, and Applications. *ACM
    Comput. Surv.* 51, 5, Article 92 (sep 2018), 36 pages. [https://doi.org/10.1145/3234150](https://doi.org/10.1145/3234150)'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pu et al. (2022) Ruiyang Pu, Sha Liu, Xiaoyu Ren, Dian Shi, Yupei Ba, Yanbei
    Huo, Wenling Zhang, Lingling Ma, Yanyan Liu, Yan Yang, et al. 2022. The screening
    value of RT-LAMP and RT-PCR in the diagnosis of COVID-19: Systematic review and
    meta-analysis. *Journal of virological methods* 300 (2022), 114392.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Punn and Agarwal (2022) Narinder Singh Punn and Sonali Agarwal. 2022. Chs-net:
    A deep learning approach for hierarchical segmentation of covid-19 via ct images.
    *Neural Processing Letters* (2022), 1–22.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2020) Chuan Qin, MD PhD Luoqi Zhou MD Ziwei, Sheng Yang MD Yu Tao,
    PhD Cuihong Xie MD PhD Ke, and Ma MD PhD Ke Shang. 2020. Dysregulation of immune
    response in patients with COVID-19 in Wuhan, China; Clinical Infectious Diseases;
    Oxford Academic. *Clinical Infectious Diseases* (2020).
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R et al. (2022) Sakthivel R, I. Sumaiya Thaseen, Vanitha M, Deepa M, Angulakshmi
    M, Mangayarkarasi R, Anand Mahendran, Waleed Alnumay, and Puspita Chatterjee.
    2022. An efficient hardware architecture based on an ensemble of deep learning
    models for COVID -19 prediction. *Sustainable Cities and Society* 80 (2022), 103713.
    [https://doi.org/10.1016/j.scs.2022.103713](https://doi.org/10.1016/j.scs.2022.103713)
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rabaan et al. (2021) Ali A Rabaan, Raghavendra Tirupathi, Anupam A Sule, Jehad
    Aldali, Abbas Al Mutair, Saad Alhumaid, Nitin Gupta, Thoyaja Koritala, Ramesh
    Adhikari, Muhammad Bilal, et al. 2021. Viral dynamics and real-time RT-PCR Ct
    values correlation with disease severity in COVID-19. *Diagnostics* 11, 6 (2021),
    1091.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rahman et al. (2021a) Md Rahman, Ahashan Habib Niloy, Shammi Akhter Shiba,
    SM Fahim, Faizun Nahar Faria, Emtiaz Hussain, Mohammad Zavid Parvez, et al. 2021a.
    CoroPy: A Deep Learning Based Comparison Between X-Ray and CT Scan Images in Covid-19
    Detection and Classification. In *International Conference on Bioengineering and
    Biomedical Signal and Image Processing*. Springer, 392–404.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rahman et al. (2021b) Sejuti Rahman, Sujan Sarker, Md Abdullah Al Miraj, Ragib Amin
    Nihal, AKM Nadimul Haque, and Abdullah Al Noman. 2021b. Deep learning–driven automated
    detection of Covid-19 from radiography images: A comparative analysis. *Cognitive
    Computation* (2021), 1–30.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rana et al. (2022) Ashish Rana, Harpreet Singh, Ravimohan Mavuduru, Smita Pattanaik,
    and Prashant Singh Rana. 2022. Quantifying prognosis severity of COVID-19 patients
    from deep learning based analysis of CT chest images. *Multimedia Tools and Applications*
    81, 13 (2022), 18129–18153.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravi et al. (2022) Vinayakumar Ravi, Harini Narasimhan, Chinmay Chakraborty,
    and Tuan D Pham. 2022. Deep learning-based meta-classifier approach for COVID-19
    classification using CT scan and chest X-ray images. *Multimedia systems* 28,
    4 (2022), 1401–1415.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronneberger et al. (2015) Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
    2015. U-Net: Convolutional Networks for Biomedical Image Segmentation. *ArXiv*
    abs/1505.04597 (2015).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salehi et al. (2017) Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour.
    2017. Tversky loss function for image segmentation using 3D fully convolutional
    deep networks. In *International workshop on machine learning in medical imaging*.
    Springer, 379–387.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saood (2021) Adnan Saood. 2021. COVID-19 lung CT image segmentation using deep
    learning methods: U-Net versus SegNet. *BMC Medical Imaging* 21 (2021).'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarv Ahrabi et al. (2022) Sima Sarv Ahrabi, Lorenzo Piazzo, Alireza Momenzadeh,
    Michele Scarpiniti, and Enzo Baccarelli. 2022. Exploiting probability density
    function of deep convolutional autoencoders’ latent space for reliable COVID-19
    detection on CT scans. *The Journal of Supercomputing* 78, 9 (2022), 12024–12045.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saxena and Cao (2021) Divya Saxena and Jiannong Cao. 2021. Generative adversarial
    networks (GANs) challenges, solutions, and future directions. *ACM Computing Surveys
    (CSUR)* 54, 3 (2021), 1–42.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schlemper et al. (2019) Jo Schlemper, Ozan Oktay, Michiel Schaap, Mattias P.
    Heinrich, Bernhard Kainz, Ben Glocker, and Daniel Rueckert. 2019. Attention Gated
    Networks: Learning to Leverage Salient Regions in Medical Images. *Medical image
    analysis* 53 (2019), 197 – 207.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sedik et al. (2022) Ahmed Sedik, Mohamed Hammad, Abd El-Samie, E Fathi, Brij B
    Gupta, Abd El-Latif, and A Ahmed. 2022. Efficient deep learning approach for augmented
    detection of Coronavirus disease. *Neural Computing and Applications* 34, 14 (2022),
    11423–11440.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sen et al. (2021) Shibaprasad Sen, Soumyajit Saha, Somnath Chatterjee, Seyedali
    Mirjalili, and Ram Sarkar. 2021. A bi-stage feature selection approach for COVID-19
    prediction using chest CT images. *Applied Intelligence* 51, 12 (2021), 8985–9000.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serte et al. (2022) Sertan Serte, Mehmet Alp Dirik, and Fadi Al-Turjman. 2022.
    Deep Learning Models for COVID-19 Detection. *Sustainability* 14, 10 (2022). [https://doi.org/10.3390/su14105820](https://doi.org/10.3390/su14105820)
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shah et al. (2021a) Faisal Muhammad Shah, Sajib Kumar Saha Joy, Farzad Ahmed,
    Tonmoy Hossain, Mayeesha Humaira, Amit Saha Ami, Shimul Paul, Md Abidur Rahman Khan
    Jim, and Sifat Ahmed. 2021a. A comprehensive survey of COVID-19 detection using
    medical images. *SN Computer Science* 2, 6 (2021), 1–22.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shah et al. (2021b) Vruddhi Shah, Rinkal Keniya, Akanksha Shridharani, Manav
    Punjabi, Jainam Shah, and Ninad Mehendale. 2021b. Diagnosis of COVID-19 using
    CT scan images and deep learning techniques. *Emergency radiology* 28, 3 (2021),
    497–505.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shamsi et al. (2021) Afshar Shamsi, Hamzeh Asgharnezhad, Shirin Shamsi Jokandan,
    Abbas Khosravi, Parham Mohsenzadeh Kebria, Darius Nahavandi, Saeid Nahavandi,
    and Dipti Srinivasan. 2021. An Uncertainty-Aware Transfer Learning-Based Framework
    for COVID-19 Diagnosis. *IEEE Transactions on Neural Networks and Learning Systems*
    32 (2021), 1408–1417.
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shan et al. (2021) Fei Shan, Yaozong Gao, Jun Wang, Weiya Shi, Nannan Shi, Miaofei
    Han, Zhong Xue, Dinggang Shen, and Yuxin Shi. 2021. Abnormal lung quantification
    in chest CT images of COVID-19 patients with deep learning and its application
    to severity prediction. *Medical physics* 48, 4 (2021), 1633–1645.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sheela and Arun (2022) M. Sahaya Sheela and Chintamani Atish Arun. 2022. Hybrid
    PSO–SVM algorithm for Covid-19 screening and quantification. *International Journal
    of Information Technology* 14 (2022), 2049 – 2056.
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sherstinsky (2020) Alex Sherstinsky. 2020. Fundamentals of recurrent neural
    network (RNN) and long short-term memory (LSTM) network. *Physica D: Nonlinear
    Phenomena* 404 (2020), 132306.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sheykhivand et al. (2021) Sobhan Sheykhivand, Zohreh Mousavi, Sina Mojtahedi,
    Tohid Yousefi Rezaii, Ali Farzamnia, Saeed Meshgini, and Ismail Saad. 2021. Developing
    an efficient deep neural network for automatic detection of COVID-19 using chest
    X-ray images. *Alexandria Engineering Journal* 60, 3 (2021), 2885–2903.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2020) Feng Shi, Jun Wang, Jun Shi, Ziyan Wu, Qian Wang, Zhenyu Tang,
    Kelei He, Yinghuan Shi, and Dinggang Shen. 2020. Review of artificial intelligence
    techniques in imaging data acquisition, segmentation, and diagnosis for COVID-19.
    *IEEE reviews in biomedical engineering* 14 (2020), 4–15.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2021b) Feng Shi, Liming Xia, Fei Shan, Bin Song, Dijia Wu, Ying
    Wei, Huan Yuan, Huiting Jiang, Yichu He, Yaozong Gao, et al. 2021b. Large-scale
    screening to distinguish between COVID-19 and community-acquired pneumonia using
    infection size-aware classification. *Physics in medicine & Biology* 66, 6 (2021),
    065031.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2021a) Wenqi Shi, Mitali S Gupte, and May D Wang. 2021a. Learning
    from Heterogeneous Data via Contrastive Learning: An Application in Multi-Source
    COVID-19 Radiography. In *2021 IEEE EMBS International Conference on Biomedical
    and Health Informatics (BHI)*. IEEE, 1–4.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shirato et al. (2020) Kazuya Shirato, Naganori Nao, Harutaka Katano, Ikuyo Takayama,
    Shinji Saito, Fumihiro Kato, Hiroshi Katoh, Masafumi Sakata, Yuichiro Nakatsu,
    Yoshio Mori, et al. 2020. Development of genetic diagnostic methods for novel
    coronavirus 2019 (nCoV-2019) in Japan. *Japanese journal of infectious diseases*
    (2020), JJID–2020.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shiri et al. (2022) Isaac Shiri, Hossein Arabi, Yazdan Salimi, Amirhossein
    Sanaat, Azadeh Akhavanallaf, Ghasem Hajianfar, Dariush Askari, Shakiba Moradi,
    Zahra Mansouri, Masoumeh Pakbin, et al. 2022. COLI-Net: Deep learning-assisted
    fully automated COVID-19 lung and infection pneumonia lesion detection and segmentation
    from chest computed tomography images. *International journal of imaging systems
    and technology* 32, 1 (2022), 12–25.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shorfuzzaman (2021) Mohammad Shorfuzzaman. 2021. IoT-enabled stacked ensemble
    of deep neural networks for the diagnosis of COVID-19 using chest CT scans. *Computing*
    (2021), 1–22.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shorten et al. (2021) Connor Shorten, Taghi M Khoshgoftaar, and Borko Furht.
    2021. Deep Learning applications for COVID-19. *Journal of big Data* 8, 1 (2021),
    1–54.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuja et al. (2021) Junaid Shuja, Eisa A. Alanazi, Waleed S. Alasmary, and
    Abdulaziz S. Alashaikh. 2021. COVID-19 open source data sets: a comprehensive
    survey. *Applied Intelligence (Dordrecht, Netherlands)* 51 (2021), 1296 – 1325.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Siddique et al. (2021) Nahian Alam Siddique, Sidike Paheding, Colin P. Elkin,
    and Vijay Kumar Devabhaktuni. 2021. U-Net and Its Variants for Medical Image Segmentation:
    A Review of Theory and Applications. *IEEE Access* 9 (2021), 82031–82057.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) Karen Simonyan and Andrew Zisserman. 2014. Very
    deep convolutional networks for large-scale image recognition. *arXiv preprint
    arXiv:1409.1556* (2014).
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singanayagam et al. (2020) Anika Singanayagam, Monika Patel, André Charlett,
    Jamie Lopez Bernal, Vanessa Saliba, Joanna Ellis, Shamez N. Ladhani, Maria Zambon,
    and Robin Gopal. 2020. Duration of infectiousness and correlation with RT-PCR
    cycle threshold values in cases of COVID-19, England, January to May 2020. *Eurosurveillance*
    25 (2020).
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021b) Asu Kumar Singh, Anupam Kumar, Mufti Mahmud, M Shamim Kaiser,
    and Akshat Kishore. 2021b. COVID-19 infection detection from chest X-ray images
    using hybrid social group optimization and support vector classifier. *Cognitive
    Computation* (2021), 1–13.
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021a) Dilbag Singh, Vijay Kumar, and Manjit Kaur. 2021a. Densely
    connected convolutional networks-based COVID-19 screening model. *Applied Intelligence*
    51, 5 (2021), 3044–3051.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Soares et al. (2020) Eduardo A. Soares, Plamen P. Angelov, Sarah Biaso, Michele Higa
    Froes, and Daniel Kanda Abe. 2020. SARS-CoV-2 CT-scan dataset:A large dataset
    of real patients CT scans for SARS-CoV-2 identification. *medRxiv* (2020).
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2021) Ying Song, Shuangjia Zheng, Liang Li, Xiang Zhang, Xiaodong
    Zhang, Ziwang Huang, Jianwen Chen, Ruixuan Wang, Huiying Zhao, Yutian Chong, et al.
    2021. Deep learning enables accurate diagnosis of novel coronavirus (COVID-19)
    with CT images. *IEEE/ACM transactions on computational biology and bioinformatics*
    18, 6 (2021), 2775–2780.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Soomro et al. (2021) Toufique A Soomro, Lihong Zheng, Ahmed J Afifi, Ahmed
    Ali, Ming Yin, and Junbin Gao. 2021. Artificial intelligence (AI) for medical
    imaging to combat coronavirus disease (COVID-19): a detailed review with direction
    for future research. *Artificial Intelligence Review* (2021), 1–31.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Srivastava (2022) Varad Srivastava. 2022. Diagnosing Covid-19 using AI based
    Medical Image Analysis. In *5th Joint International Conference on Data Science
    & Management of Data (9th ACM IKDD CODS and 27th COMAD)*. 204–212.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sudre et al. (2017) Carole H Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin,
    and M Jorge Cardoso. 2017. Generalised dice overlap as a deep learning loss function
    for highly unbalanced segmentations. In *Deep learning in medical image analysis
    and multimodal learning for clinical decision support*. Springer, 240–248.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2015) Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
    Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
    2015. Going deeper with convolutions. In *Proceedings of the IEEE conference on
    computer vision and pattern recognition*. 1–9.
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tahir et al. (2022) Anas M Tahir, Yazan Qiblawey, Amith Khandakar, Tawsifur
    Rahman, Uzair Khurshid, Farayi Musharavati, MT Islam, Serkan Kiranyaz, Somaya
    Al-Maadeed, and Muhammad EH Chowdhury. 2022. Deep learning for reliable classification
    of COVID-19, MERS, and SARS from chest X-ray images. *Cognitive Computation* (2022),
    1–21.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Le (2019) Mingxing Tan and Quoc Le. 2019. Efficientnet: Rethinking
    model scaling for convolutional neural networks. In *International conference
    on machine learning*. PMLR, 6105–6114.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan et al. (2021) Wenjun Tan, Pan Liu, Xiaoshuo Li, Yao Liu, Qinghua Zhou, Chao
    Chen, Zhaoxuan Gong, Xiaoxia Yin, and Yanchun Zhang. 2021. Classification of COVID-19
    pneumonia from chest CT images based on reconstructed super-resolution images
    and VGG neural network. *Health Information Science and Systems* 9, 1 (2021),
    1–12.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. (2021a) Shanjiang Tang, Chunjiang Wang, Jiangtian Nie, Neeraj Kumar,
    Yang Zhang, Zehui Xiong, and Ahmed Barnawi. 2021a. EDL-COVID: Ensemble deep learning
    for COVID-19 case detection from chest X-ray images. *IEEE Transactions on Industrial
    Informatics* 17, 9 (2021), 6539–6549.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2021b) Zhenyu Tang, Wei Zhao, Xingzhi Xie, Zheng Zhong, Feng Shi,
    Tianmin Ma, Jun Liu, and Dinggang Shen. 2021b. Severity assessment of COVID-19
    using CT image features and laboratory indices. *Physics in Medicine & Biology*
    66, 3 (2021), 035015.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tayarani (2020) Mohammad Tayarani. 2020. Applications of artificial intelligence
    in battling against covid-19: A literature review. *Chaos, Solitons & Fractals*
    (2020).'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ter-Sarkisov (2022) Aram Ter-Sarkisov. 2022. Covid-ct-mask-net: Prediction
    of covid-19 from ct scans using regional features. *Applied Intelligence* (2022),
    1–12.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Torales et al. (2020) Julio Torales, Marcelo O’Higgins, João Mauricio Castaldelli-Maia,
    and Antonio Ventriglio. 2020. The outbreak of COVID-19 coronavirus and its impact
    on global mental health. *International journal of social psychiatry* 66, 4 (2020),
    317–320.
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trivizakis et al. (2020) Eleftherios Trivizakis, Nikos Tsiknakis, Evangelia E
    Vassalou, Georgios Z Papadakis, Demetrios A Spandidos, Dimosthenis Sarigiannis,
    Aristidis Tsatsakis, Nikolaos Papanikolaou, Apostolos H Karantanas, and Kostas
    Marias. 2020. Advancing COVID-19 differentiation with a robust preprocessing and
    integration of multi-institutional open-repository computer tomography datasets
    for deep learning analysis. *Experimental and therapeutic medicine* 20, 5 (2020),
    1–1.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turkoglu (2021) Muammer Turkoglu. 2021. COVIDetectioNet: COVID-19 diagnosis
    system based on X-ray images using features selected from pre-learned deep features
    ensemble. *Applied Intelligence* 51, 3 (2021), 1213–1226.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vasilev et al. (2022) IA Vasilev, MI Petrovskiy, IV Mashechkin, and LL Pankratyeva.
    2022. Predicting COVID-19-Induced Lung Damage Based on Machine Learning Methods.
    *Programming and Computer Software* 48, 4 (2022), 243–255.
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vidyun et al. (2021) AS Vidyun, B Srinivasa Rao, and J Harikiran. 2021. Automated
    Detection and Classification of COVID-19 Based on CT Images Using Deep Learning
    Model. In *Applications of Artificial Intelligence and Machine Learning*. Springer,
    419–426.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vogado et al. (2021) Luis Vogado, Pablo Vieira, Pedro Santos Neto, Lucas Lopes,
    Gleison Silva, Flávio Araújo, and Rodrigo Veras. 2021. Detection of COVID-19 in
    chest X-ray images using transfer learning with deep convolutional neural network.
    In *Proceedings of the 36th Annual ACM Symposium on Applied Computing*. 629–636.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voulodimos et al. (2021a) Athanasios Voulodimos, Eftychios Protopapadakis, Iason
    Katsamenis, Anastasios Doulamis, and Nikolaos Doulamis. 2021a. Deep learning models
    for COVID-19 infected area segmentation in CT images. In *the 14th PErvasive technologies
    related to assistive environments conference*. 404–411.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voulodimos et al. (2021b) Athanasios Voulodimos, Eftychios E. Protopapadakis,
    Iason Katsamenis, Anastasios D. Doulamis, and Nikolaos D. Doulamis. 2021b. A Few-Shot
    U-Net Deep Learning Model for COVID-19 Infected Area Segmentation in CT Images.
    *Sensors (Basel, Switzerland)* 21 (2021).
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2021b) Kang Wang, Yang Zhao, Yong Dou, Dong Wen, and Zikai Gao.
    2021b. COVID Edge-Net: Automated COVID-19 Lung Lesion Edge Detection in Chest
    CT Images. In *ECML/PKDD*.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021a) Shuai Wang, Bo Kang, Jinlu Ma, Xianjun Zeng, Mingming Xiao,
    Jia Guo, Meng Cai, Jingyi Yang, Yaodong Li, Xiangfei Meng, and Bo Xu. 2021a. A
    deep learning algorithm using CT images to screen for Corona virus disease (COVID-19).
    *European Radiology* 31 (2021), 6096 – 6104.
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020) Xinggang Wang, Xianbo Deng, Qing Fu, Qiang Zhou, Jiapei Feng,
    Hui Ma, Wenyu Liu, and Chuansheng Zheng. 2020. A weakly-supervised framework for
    COVID-19 classification and lesion localization from chest CT. *IEEE transactions
    on medical imaging* 39, 8 (2020), 2615–2625.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weinstock et al. (2020) Michael B Weinstock, ANA Echenique, JW Russell, ARI
    Leib, J Miller, D Cohen, Stephen Waite, A Frye, and F Illuzzi. 2020. Chest x-ray
    findings in 636 ambulatory patients with COVID-19 presenting to an urgent care
    center: a normal chest x-ray is no guarantee. *J Urgent Care Med* 14, 7 (2020),
    13–18.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WHO (2022) WHO. 2022. Coronavirus disease 2019 (covid-19). [https://www.worldometers.info/coronavirus/](https://www.worldometers.info/coronavirus/).
    Last accessed on 21.10.22.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2020) Jianguo Wu, Jiasheng Liu, Shijun Li, Zhiyang Peng, Zhe man
    Xiao, Xufeng Wang, Ruicheng Yan, and Jianfei Luo. 2020. Detection and analysis
    of nucleic acid in various biological samples of COVID-19 patients. *Travel Medicine
    and Infectious Disease* 37 (2020), 101673 – 101673.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2022) Hanguang Xiao, Zhiqiang Ran, Shingo Mabu, Yuewei Li, and
    Li Li. 2022. SAUNet++: an automatic segmentation model of COVID-19 lesion from
    CT slices. *The Visual Computer* (2022), 1–14.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie and Tu (2015) Saining Xie and Zhuowen Tu. 2015. Holistically-nested edge
    detection. In *Proceedings of the IEEE international conference on computer vision*.
    1395–1403.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2022) Fangyi Xu, Kaihua Lou, Chao Chen, Qingqing Chen, Dawei Wang,
    Jiangfen Wu, Wenchao Zhu, Weixiong Tan, Yong Zhou, Yongjiu Liu, et al. 2022. An
    original deep learning model using limited data for COVID-19 discrimination: A
    multicenter study. *Medical Physics* (2022).'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yamaç et al. (2021) Mehmet Yamaç, Mete Ahishali, Aysen Degerli, Serkan Kiranyaz,
    Muhammad E. H. Chowdhury, and Moncef Gabbouj. 2021. Convolutional Sparse Support
    Estimator-Based COVID-19 Recognition From X-Ray Images. *IEEE Transactions on
    Neural Networks and Learning Systems* 32, 5 (2021), 1810–1820. [https://doi.org/10.1109/TNNLS.2021.3070467](https://doi.org/10.1109/TNNLS.2021.3070467)
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2020) Xingyi Yang, Jinyu Zhao, Yichen Zhang, Xuehai He, and Pengtao
    Xie. 2020. COVID-CT-Dataset: A CT Scan Dataset about COVID-19. *ArXiv* abs/2003.13865
    (2020).'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yasar and Ceylan (2021a) Huseyin Yasar and Murat Ceylan. 2021a. Deep Learning–Based
    Approaches to Improve Classification Parameters for Diagnosing COVID-19 from CT
    Images. *Cognitive Computation* (2021), 1–28.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yasar and Ceylan (2021b) Huseyin Yasar and Murat Ceylan. 2021b. A novel comparative
    study for detection of Covid-19 on CT lung images using texture analysis, machine
    learning, and deep learning methods. *Multimedia Tools and Applications* 80, 4
    (2021), 5423–5447.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ye et al. (2020) Zheng Ye, Yun Zhang, Yi Wang, Zixiang Huang, and Bin Song.
    2020. Chest CT manifestations of new coronavirus disease 2019 (COVID-19): a pictorial
    review. *European radiology* 30, 8 (2020), 4381–4389.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yi-de et al. (2004) Ma Yi-de, Liu Qing, and Qian Zhi-Bai. 2004. Automated image
    segmentation using improved PCNN model based on cross-entropy. In *Proceedings
    of 2004 International Symposium on Intelligent Multimedia, Video and Speech Processing,
    2004.* IEEE, 743–746.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yoon et al. (2020) Soon Ho Yoon, Kyung Hee Lee, Jin Yong Kim, Young Kyung Lee,
    Hongseok Ko, Ki Hwan Kim, Chang Min Park, and Yun-Hyeon Kim. 2020. Chest radiographic
    and CT findings of the 2019 novel coronavirus disease (COVID-19): analysis of
    nine patients treated in Korea. *Korean journal of radiology* 21, 4 (2020), 494–500.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zebin and Rezvy (2021) Tahmina Zebin and Shahadate Rezvy. 2021. COVID-19 detection
    and disease progression visualization: Deep learning on chest X-rays for classification
    and coarse localization. *Applied Intelligence* 51, 2 (2021), 1010–1021.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021d) Ju Zhang, Lunduan Yu, Decheng Chen, Weidong Pan, Chao Shi,
    Yan Niu, Xinwei Yao, Xiaobin Xu, and Yun Cheng. 2021d. Dense GAN and multi-layer
    attention based lesion segmentation method for COVID-19 CT images. *Biomedical
    Signal Processing and Control* 69 (2021), 102901. [https://doi.org/10.1016/j.bspc.2021.102901](https://doi.org/10.1016/j.bspc.2021.102901)
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022a) Xin Zhang, Siyuan Lu, Shui-Hua Wang, Xiang Yu, Su-Jing
    Wang, Lun Yao, Yi Pan, and Yu-Dong Zhang. 2022a. Diagnosis of COVID-19 pneumonia
    via a novel deep learning architecture. *Journal of computer science and technology*
    37, 2 (2022), 330–343.
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2021c) XiaoQing Zhang, GuangYu Wang, and Shu-Guang Zhao. 2021c.
    COVSeg-NET: A deep convolution neural network for COVID-19 lung CT image segmentation.
    *International Journal of Imaging Systems and Technology* 31, 3 (2021), 1071–1086.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022b) Xiaorui Zhang, Jie Zhou, Wei Sun, and Sunil Kumar Jha.
    2022b. A Lightweight CNN Based on Transfer Learning for COVID-19 Diagnosis. *Computers,
    Materials & Continua* (2022).
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021a) Yu-Dong Zhang, Suresh Chandra Satapathy, Shuaiqi Liu, and
    Guang-Run Li. 2021a. A five-layer deep convolutional neural network with stochastic
    pooling for chest CT-based COVID-19 diagnosis. *Machine vision and applications*
    32, 1 (2021), 1–13.
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021b) Yu-Dong Zhang, Suresh Chandra Satapathy, Xin Zhang, and
    Shui-Hua Wang. 2021b. Covid-19 diagnosis via DenseNet and optimization of transfer
    learning setting. *Cognitive computation* (2021), 1–17.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2018) Zhen Zhang, Yibing Li, Chao Wang, Meiyu Wang, Ya Tu, and
    Jin Wang. 2018. An ensemble learning method for wireless multimedia device identification.
    *Security and communication networks* 2018 (2018).
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2021a) Chen Zhao, Yan Xu, Zhuo He, Jinshan Tang, Yijun Zhang, Jungang
    Han, Yuxin Shi, and Weihua Zhou. 2021a. Lung segmentation and automatic detection
    of COVID-19 using radiomic features from chest CT images. *Pattern Recognition*
    119 (2021), 108071 – 108071.
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021b) Xiangyu Zhao, Peng Zhang, Fan Song, Guangda Fan, Yangyang
    Sun, Yujia Wang, Zheyuan Tian, Luqi Zhang, and Guanglei Zhang. 2021b. D2A U-Net:
    Automatic segmentation of COVID-19 CT slices based on dual attention and hybrid
    dilated convolution. *Computers in Biology and Medicine* 135 (2021), 104526 –
    104526.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2019) Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu.
    2019. Object detection with deep learning: A review. *IEEE transactions on neural
    networks and learning systems* 30, 11 (2019), 3212–3232.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2022) BingBing Zheng, Yu Zhu, Qin Shi, Dawei Yang, Yanmei Shao,
    and Tao Xu. 2022. MA-Net: Mutex attention network for COVID-19 diagnosis on CT
    images. *Applied Intelligence* (2022), 1–16.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2022) Jinzhao Zhou, Xingming Zhang, Ziwei Zhu, Xiangyuan Lan, Lunkai
    Fu, Haoxiang Wang, and Hanchun Wen. 2022. Cohesive Multi-Modality Feature Learning
    and Fusion for COVID-19 Patient Severity Prediction. *IEEE Transactions on Circuits
    and Systems for Video Technology* 32 (2022), 2535–2549.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2021b) S Kevin Zhou, Hayit Greenspan, Christos Davatzikos, James S
    Duncan, Bram Van Ginneken, Anant Madabhushi, Jerry L Prince, Daniel Rueckert,
    and Ronald M Summers. 2021b. A review of deep learning in medical imaging: Imaging
    traits, technology trends, case studies with progress highlights, and future promises.
    *Proc. IEEE* 109, 5 (2021), 820–838.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2020) Tongxue Zhou, Stéphane Canu, and Su Ruan. 2020. An automatic
    COVID-19 CT segmentation based on U-Net with attention mechanism. *arXiv: Image
    and Video Processing* (2020).'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2021a) Tongxue Zhou, Stéphane Canu, and Su Ruan. 2021a. Automatic
    COVID-19 CT segmentation using U-Net integrated spatial and channel attention
    mechanism. *International Journal of Imaging Systems and Technology* 31, 1 (2021),
    16–27.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2021c) Tao Zhou, Huiling Lu, Zaoli Yang, Shi Qiu, Bingqiang Huo,
    and Yali Dong. 2021c. The ensemble deep learning model for novel COVID-19 on CT
    images. *Applied soft computing* 98 (2021), 106885.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2020) Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun
    Zhu, Hengshu Zhu, Hui Xiong, and Qing He. 2020. A comprehensive survey on transfer
    learning. *Proc. IEEE* 109, 1 (2020), 43–76.
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
