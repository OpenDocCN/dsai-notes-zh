- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:41:57'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2302.06611] Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2302.06611](https://ar5iv.labs.arxiv.org/html/2302.06611)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Song Wu [SongWu.uestc@outlook.com](mailto:SongWu.uestc@outlook.com) [0000-0003-0147-1907](https://orcid.org/0000-0003-0147-1907
    "ORCID identifier") ,  Yazhou Ren [yazhou.ren@uestc.edu.cn](mailto:yazhou.ren@uestc.edu.cn)
    ,  Aodi Yang [aodi.yang@outlook.com](mailto:aodi.yang@outlook.com) ,  Xinyue Chen
    [martinachen2580@gmail.com](mailto:martinachen2580@gmail.com) ,  Xiaorong Pu [puxiaor@uestc.edu.cn](mailto:puxiaor@uestc.edu.cn)
    School of Computer Science and Engineering, Shenzhen Institute for Advanced Study,
    University of Electronic Science and Technology of ChinaChina ,  Jing He [lotusjing@gmail.com](mailto:lotusjing@gmail.com)
    Nuffield Department of Clinical Neurosciences, University of OxfordUK ,  Liqiang
    Nie [nieliqiang@gmail.com](mailto:nieliqiang@gmail.com) School of Computer Science
    and Technology, Harbin Institute of Technology (Shenzhen)China  and  Philip S.
    Yu [psyu@uic.edu](mailto:psyu@uic.edu) Department of Computer Science, University
    of Illinois at ChicagoUSA(2023)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: COVID-19 (Coronavirus disease 2019) has been quickly spreading since its outbreak,
    impacting financial markets and healthcare systems globally. Countries all around
    the world have adopted a number of extraordinary steps to restrict the spreading
    virus, where early COVID-19 diagnosis is essential. Medical images such as X-ray
    images and Computed Tomography scans are becoming one of the main diagnostic tools
    to combat COVID-19 with the aid of deep learning-based systems. In this survey,
    we investigate the main contributions of deep learning applications using medical
    images in fighting against COVID-19 from the aspects of image classification,
    lesion localization, and severity quantification, and review different deep learning
    architectures and some image preprocessing techniques for achieving a preciser
    diagnosis. We also provide a summary of the X-ray and CT image datasets used in
    various studies for COVID-19 detection. The key difficulties and potential applications
    of deep learning in fighting against COVID-19 are finally discussed. This work
    summarizes the latest methods of deep learning using medical images to diagnose
    COVID-19, highlighting the challenges and inspiring more studies to keep utilizing
    the advantages of deep learning to combat COVID-19.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning, Medical image, COVID-19^†^†copyright: acmcopyright^†^†journalyear:
    2023^†^†doi: XXXXXXX.XXXXXXX^†^†ccs: Computing methodologies Artificial intelligence^†^†ccs:
    Applied computing Life and medical sciences^†^†ccs: General and reference Surveys
    and overviews'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'COVID-19 (Coronavirus Disease 2019), an acute respiratory infection caused
    by a novel coronavirus, was first reported in Wuhan, China, in December 2019 (Qin
    et al., [2020](#bib.bib139); Kannan et al., [2020](#bib.bib79)). It is highly
    contagious and the World Health Organization (WHO) declared that the outbreak
    was a Public Health Emergency of International Concern (PHEIC) on January 30,
    2020 and one and a half month later, a pandemic. The number of confirmed and death
    cases has increased rapidly since its outbreak as shown in Figure [1](#S1.F1 "Figure
    1 ‣ 1\. Introduction ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis:
    A Comprehensive Survey") (WHO, [2022](#bib.bib200)). As of July 31, 2022, more
    than 574 million confirmed cases and more than 6.3 million fatalities had been
    documented, severely impacting people’s daily lives. The healthcare systems of
    many countries are perilously close to collapse, and the world financial market
    is suffered a negative impact (Torales et al., [2020](#bib.bib188); Pak et al.,
    [2020](#bib.bib129); Nicola et al., [2020](#bib.bib127); Shorten et al., [2021](#bib.bib168)).
    To break the viral cycle of transmission, early screening and severity evaluation
    for COVID-19 patients are essential (Tayarani, [2020](#bib.bib186); Das et al.,
    [2022](#bib.bib37); Farhat et al., [2020](#bib.bib48)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ef06652579fed25cfa8d4ebd0941107a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. The number of infections and deaths in the world, and the top 10
    infected countries (October 22, 2022).
  prefs: []
  type: TYPE_NORMAL
- en: RT-PCR (Reverse Transcription-Polymerase Chain Reaction) is a technology that
    combines reverse transcription (RT) of RNA and polymerase chain reaction (PCR)
    of cDNA (Mak et al., [2020](#bib.bib110); He et al., [2020](#bib.bib59)). Due
    to its high sensitivity, wide dynamic range, and accurate detection, the RT-PCR
    is widely used in identifying COVID-19 subjects (Singanayagam et al., [2020](#bib.bib172);
    Wu et al., [2020](#bib.bib201); Huggett et al., [2005](#bib.bib69)). It, however,
    has a lot of limitations. First, the quality of sample collection has a significant
    impact on RT-PCR results, and the false negative rate is extremely high (Shah
    et al., [2021a](#bib.bib155); Wang et al., [2020](#bib.bib198); Zhou et al., [2021c](#bib.bib228);
    Mukherjee et al., [2021](#bib.bib123)). Second, the reaction time for RT-PCR is
    generally lengthy, and the standards for testing certification are rather high
    (Rahman et al., [2021b](#bib.bib143)). Third, the suspected patients are vulnerable
    to cross-infection during the RT-PCR test, which will exacerbate the spreading
    virus (Alafif et al., [2021](#bib.bib9)).
  prefs: []
  type: TYPE_NORMAL
- en: To solve the above problem, medical imaging is an available diagnostic method,
    which can be regarded as an important complement to RT-PCR in COVID-19 detection.
    It can signal lesion manifestations of different infected levels, aiding doctors
    to make an appropriate diagnosis(Mei et al., [2020](#bib.bib112); Pascual et al.,
    [2021](#bib.bib130)). Meanwhile, many studies attempt to use deep learning technologies
    and medical imaging for COVID-19 early screening, which can greatly prevent the
    further spread of the epidemic. And the DL-based diagnostic methods have shown
    great potential in image classification, lesion localization and severity evaluation
    (Srivastava, [2022](#bib.bib178); Polat et al., [2021](#bib.bib135); Rahman et al.,
    [2021b](#bib.bib143); Alyasseri et al., [2022](#bib.bib11); Agrawal et al., [2022](#bib.bib5)).
  prefs: []
  type: TYPE_NORMAL
- en: There are some surveys about using deep learning and medical imaging to fight
    against COVID-19 (Bhattacharya et al., [2021](#bib.bib26); Hryniewska et al.,
    [2021](#bib.bib64); Liu et al., [2022](#bib.bib102); Soomro et al., [2021](#bib.bib177)).
    Bhattacharya et al. (Bhattacharya et al., [2021](#bib.bib26)) summarize recent
    studies related to the applications of deep learning based on medical image processing
    and discuss their potential to combat COVID-19\. Hryniewska et al. (Hryniewska
    et al., [2021](#bib.bib64)) summarize the deep neural network methods using medical
    images for COVID-19 diagnosis and show how to use interpretable AI techniques
    in these models. Soomro et al. (Soomro et al., [2021](#bib.bib177)) perform the
    image analysis based on CT and X-rays images from both traditional image system
    and AI-system directions, and summarize the various applications of AI in COVID-19
    diagnosis. Liu et al. (Liu et al., [2022](#bib.bib102)) review existing deep learning
    models and medical image analysis methods for COVID-19 diagnosis, relating them
    to hot issues in deep learning research, including interpretable deep learning,
    and fair deep learning. While most of these surveys focus on the various applications
    of deep learning using medical images in fighting against COVID-19, there is a
    lack of discussion on how to utilize deep learning technologies to achieve a preciser
    diagnosis. Therefore, it is meaningful to summarize recent studies using deep
    learning and medical imaging to diagnose COVID-19, and explore how to utilize
    existing deep learning models to achieve more accurate diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: 'The contributions of this paper are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First, we gather open source medical image datasets used in various studies,
    which mainly contain CT and X-ray images, to assist new studies in finding relevant
    and reliable medical images quickly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Second, we systematically summarize various applications of deep learning using
    medical images for COVID-19 diagnosis. Different deep learning architectures and
    the methods used to improve the performance of deep models are reviewed.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Third, we discuss the limitations and future work of using deep learning techniques
    to diagnose COVID-19\. And we hope that deep learning can play a crucial role
    in fighting against COVID-19 in the future.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2\. COVID-19 Dataset and Medical Image Manifestations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning (DL) has demonstrated extraordinary capabilities in medical image
    processing. The performance of deep learning models, however, is significantly
    influenced by the quality of annotated data (Ker et al., [2017](#bib.bib83); Chen
    et al., [2021](#bib.bib34); Naudé, [2020](#bib.bib126)). A large amount of well-annotated
    data can improve network performance and avoid overfitting (Bhattacharya et al.,
    [2021](#bib.bib26); Zhou et al., [2021b](#bib.bib225)). Due to the sudden outbreak
    of the epidemic, the available datasets are limited and still in the development
    stage (Kim et al., [2021](#bib.bib87)). Hence, it is a difficult but significant
    work to collect open source medical image datasets. In this section, we summarize
    various medical image datasets used for COVID-19 diagnosis in different papers,
    mainly containing CT and X-ray images. Additionally, we describe the manifestations
    of CT and X-ray images as well as the lesion information provided by these images.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. CT manifestations of COVID-19 and resource description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Computed tomography (CT) is one of the landmark advances in medical technology,
    providing radiologists with a useful imaging tool. Some pathological manifestations,
    such as ground glass opacity (GGO) and consolidation (C), are typically presenting
    in COVID-19 patients (Ye et al., [2020](#bib.bib209); Kwee and Kwee, [2020](#bib.bib96)).
    Additionally, chest CT images may show diverse radiological characteristics or
    patterns as the state of COVID-19 patients evolves. In the early stage of the
    disease, the lesions mainly are presented as ground glass opacity (GGO) and thickened
    small blood vessels. Consolidation may have occurred in some cases (Bao et al.,
    [2020](#bib.bib23)). The patients with severe disease start to develop into a
    reticular pattern with interlobular septal thickening, and consolidation shadows
    will appear in peripheral and central regions of their lungs (Li et al., [2021b](#bib.bib98)).
    When the patient’s condition deteriorates further, the white lung is visible in
    CT images and the lesions display multiple diffuse GGO and consolidation. Typical
    CT manifestations of COVID-19 patients are shown in Figure [2](#S2.F2 "Figure
    2 ‣ 2.1\. CT manifestations of COVID-19 and resource description ‣ 2\. COVID-19
    Dataset and Medical Image Manifestations ‣ Deep Learning and Medical Imaging for
    COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Many studies attempt to diagnose COVID-19 using CT images because of the rich
    pathological manifestations they provide, and deep learning models based on CT
    images have demonstrated outstanding performance on COVID-19 diagnosis (Shi et al.,
    [2021b](#bib.bib163); Kiruthika et al., [2021](#bib.bib89); Shi et al., [2021a](#bib.bib164)).
    To explore these CT images, Nivetha et al. (Nivetha and Inbarani, [2022](#bib.bib128))
    use a public COVID-19 CT scan dataset, which contains 349 positive COVID-19 cases
    and 397 negative chest CT images. Their proposed NRNN model achieves the accuracy
    of 0.98, 0.92, 1.00, 1.00 respectively in the experiment. Choudhary et al. (Choudhary
    et al., [2022](#bib.bib35)) use a publicly available SARS-CoV2 CT-scan dataset,
    which consists of 1,252 positive COVID-19 cases and 1,230 negative chest CT images.
    Their pruned ResNet-34 model reaches 0.9547 accuracy, 0.9216 sensitivity, 0.9567
    F-score, and 0.9942 specificity. Ahrabi et al. (Sarv Ahrabi et al., [2022](#bib.bib149))
    establish a training dataset composed of 4,000 CT images of COVID-19 cases collected
    from more than 500 patients. Their proposed approach reaches 0.9712 accuracy,
    0.9741 precision, 0.9659 recall and 0.9696 F-score.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6ed66de528b4f0b09c169ae685806753.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Typical CT image manifestations of COVID-19 patients, including (a)
    GGO (b) Consolidation (c) Reticular pattern (d) Crazy paving pattern.
  prefs: []
  type: TYPE_NORMAL
- en: 'Additionally, some of the most popular datasets come from authoritative hospitals.
    Song et al. (Song et al., [2021](#bib.bib176)) collect their dataset from three
    hospitals, i.e., Renmin Hospital of Wuhan University, and two affiliated hospitals
    of the Sun Yat-sen University in Guangzhou. Shi et al. (Shi et al., [2021b](#bib.bib163))
    build their dataset from three hospitals, i.e., Tongji Hospital of Huazhong University
    of Science and Technology, Shanghai Public Health Clinical Center of Fudan University,
    and China–Japan Union Hospital of Jilin University. In order to make it easier
    for new studies to obtain available and authoritative COVID-19 CT datasets, various
    datasets used in different papers are gathered and listed in Table [1](#S2.T1
    "Table 1 ‣ 2.1\. CT manifestations of COVID-19 and resource description ‣ 2\.
    COVID-19 Dataset and Medical Image Manifestations ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. A Summary of different datasets used in the papers for COVID-19 detection.
  prefs: []
  type: TYPE_NORMAL
- en: '| Type | Dataset name | Dataset source | Papers |'
  prefs: []
  type: TYPE_TB
- en: '| CT | SARS-COV-2 Ct-Scan Dataset | [https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset](https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset)
    | (Soares et al., [2020](#bib.bib175)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | COVID-CT | [https://github.com/UCSD-AI4H/COVID-CT](https://github.com/UCSD-AI4H/COVID-CT)
    | (Yang et al., [2020](#bib.bib206)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | COVIDx CT | [https://www.kaggle.com/datasets/hgunraj/covidxct](https://www.kaggle.com/datasets/hgunraj/covidxct)
    | (Gunraj et al., [2020](#bib.bib53)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | Chest CT-Scan images Dataset | [https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images](https://www.kaggle.com/datasets/mohamedhanyyy/chest-ctscan-images)
    | (Sarv Ahrabi et al., [2022](#bib.bib149)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | COVID-19 CT segmentation dataset | [http://medicalsegmentation.com/COVID19/](http://medicalsegmentation.com/COVID19/)
    | (Zhou et al., [2020](#bib.bib226)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | COVID-19 | [https://radiopaedia.org/articles/covid-19-3](https://radiopaedia.org/articles/covid-19-3)
    | (Apostolopoulos et al., [2020](#bib.bib16)) |'
  prefs: []
  type: TYPE_TB
- en: '| CT | NSCC | [https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact](https://ai.nscc-tj.cn/thai/deploy/public/pneumoniact)
    | (Wang et al., [2021a](#bib.bib197)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-19 X rays | [https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays](https://www.kaggle.com/datasets/andrewmvd/convid19-x-rays)
    | (Apostolopoulos and Bessiana, [2020](#bib.bib17)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-chestxray-dataset | [https://github.com/ieee8023/covid-chestxray-dataset](https://github.com/ieee8023/covid-chestxray-dataset)
    | (Yasar and Ceylan, [2021b](#bib.bib208); Cohen et al., [2020](#bib.bib36)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | Chest X-ray Images (Pneumonia) | [https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia)
    | (Miao et al., [2021](#bib.bib115)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-19 Radiography Database | [https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database](https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database)
    | (Al-Antari et al., [2021](#bib.bib8)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | Open Source COVID-19 | [https://github.com/WeileiZeng/Open-Source-COVID-19](https://github.com/WeileiZeng/Open-Source-COVID-19)
    | (Shuja et al., [2021](#bib.bib169)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | RSNA Pneumonia Detection Challenge | [https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data](https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data)
    | (Dev et al., [2021](#bib.bib40)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | ActualMed COVID-19 chest X-ray dataset | [https://github.com/agchung/Actualmed-COVID-chestxray-dataset](https://github.com/agchung/Actualmed-COVID-chestxray-dataset)
    | (Farooq and Hafeez, [2020](#bib.bib49)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-19 database | [https://www.sirm.org/category/senza-categoria/COVID-19/](https://www.sirm.org/category/senza-categoria/COVID-19/)
    | (Hall et al., [2020](#bib.bib55)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-CAPS | [https://github.com/ShahinSHH/COVID-CAPS](https://github.com/ShahinSHH/COVID-CAPS)
    | (Heidarian et al., [2021](#bib.bib62)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | NIH Chest X-rays | [https://www.kaggle.com/datasets/nih-chest-xrays/data](https://www.kaggle.com/datasets/nih-chest-xrays/data)
    | (Basu et al., [2020](#bib.bib25)) |'
  prefs: []
  type: TYPE_TB
- en: '| X-ray | COVID-19 | [https://github.com/muhammedtalo/COVID-19](https://github.com/muhammedtalo/COVID-19)
    | (Brunese et al., [2020](#bib.bib28)) |'
  prefs: []
  type: TYPE_TB
- en: 2.2\. X-ray manifestations of COVID-19 and resource description
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Even though CT scans provide radiologists with more information about lesions,
    they are more expensive and expose the patients to more radiation. The normal
    and COVID-19 X-ray images are shown in Figure [3](#S2.F3 "Figure 3 ‣ 2.2\. X-ray
    manifestations of COVID-19 and resource description ‣ 2\. COVID-19 Dataset and
    Medical Image Manifestations ‣ Deep Learning and Medical Imaging for COVID-19
    Diagnosis: A Comprehensive Survey"). The peripheral lung opacity (PLO) and ground
    glass opacity (GGO) are two of these abnormalities (Kim et al., [2020](#bib.bib88);
    Jacobi et al., [2020](#bib.bib73)). The chest X-ray images of COVID-19 patients
    may seem normal in the early or mild stage. About 10 to 12 days later, symptoms
    become more obvious. The lesions are generally distributed among the lower, peripheral,
    and bilateral regions (Weinstock et al., [2020](#bib.bib199); Yoon et al., [2020](#bib.bib211)).
    In reference (Nagarajan et al., [2021](#bib.bib125)), they retrospectively evaluate
    X-ray images of 593 patients admitted to hospital with COVID-19\. The experiments
    demonstrate that abnormalities are mostly found in the middle and lower regions
    (88% of cases), and ground glass opacity (GGO) is the most common finding in abnormal
    X-rays (75% of cases). The next most common findings are peripheral lung opacity
    (PLO) and confluent consolidation, which generally indicate more severe symptoms.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e1f61fdf8014ecf36acf73bf8b99f97c.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. The representative X-ray images of COVID-19 cases and the normal
    cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'The X-ray image datasets are more available than CT image datasets because
    capturing X-ray images is more convenient and less expensive than CT images. Hence,
    many studies attempt to use X-ray images rather than CT scans to diagnose COVID-19
    (Shi et al., [2021a](#bib.bib164); Tang et al., [2021a](#bib.bib184)). Regarding
    these X-ray images, Dev et al. (Dev et al., [2021](#bib.bib40)) use the COVIDx
    dataset, which consists of 55,328 normal cases, 8,066 bacterial pneumonia cases
    and 358 COVID-19 cases. Their HCN-FM and HCN-DML reach 95.33% accuracy and 96.67%
    accuracy, respectively. Annavarapu et al. (Annavarapu et al., [2021](#bib.bib14))
    use a publicly accessible COVID-19 chest X-ray dataset, which consists of 2,905
    images. Their model obtains 95% accuracy and 97% specificity. Turkoglu (Turkoglu,
    [2021](#bib.bib190)) collects 6,092 X-ray images from a combination of public
    datasets. Their proposed model reaches 99.18% accuracy, surpassing most previous
    studies. Miao et al. (Miao et al., [2021](#bib.bib115)) use three public COVID-19
    X-ray datasets and other pneumonia datasets to construct two experimental datasets.
    Jain et al. (Jain et al., [2021](#bib.bib75)) collect 6,432 chest X-ray images
    from the Kaggle repository. Various COVID-19 X-ray datasets used in different
    papers are listed in Table [1](#S2.T1 "Table 1 ‣ 2.1\. CT manifestations of COVID-19
    and resource description ‣ 2\. COVID-19 Dataset and Medical Image Manifestations
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey")
    to facilitate new studies to quickly find available resources.'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Image Preprocessing Technologies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Most COVID-19 datasets contain some blurry, repetitive, and unrelated images,
    which will degrade the performance of deep model (Shah et al., [2021a](#bib.bib155)).
    Image preprocessing is generally the first step in diagnosing COVID-19 using deep
    learning technologies. It eliminates irrelevant information in the image and recovers
    useful and real information, thereby improving the reliability and performance
    of diagnostic algorithms (Loew, [2022](#bib.bib104); Heidari et al., [2020](#bib.bib61)).
    Nivetha et al. (Nivetha and Inbarani, [2022](#bib.bib128)) use the median filter
    for the CT images of COVID-19 patients from a publicly accessible dataset. In
    this manner, the quality of COVID images is improved, and the noise is reduced
    without losing important information. Joshi et al. (Joshi et al., [2022](#bib.bib78))
    resize all images to 224×224 to maintain data consistency. And four types of transformation
    are employed to preprocess images. Ahrabi et al. (Sarv Ahrabi et al., [2022](#bib.bib149))
    use 4,000 CT images of COVID-19 cases from two publicly accessible datasets. All
    the images are cropped and resized to remove irrelevant regions. In this section,
    we will discuss extensively utilized image preprocessing technologies and their
    characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Resizing
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Resizing is an essential step for image preprocessing phase in the applications
    of deep learning. It uniforms the size of images from different datasets. Tao
    et al. (Zhou et al., [2021c](#bib.bib228)) resize all CT images to a uniform size
    (64×64) to build the COVID-19 dataset for model training. Shah et al. (Shah et al.,
    [2021b](#bib.bib156)) resize CT images from COVID-19 cases to 128×128×3 or 224×224×3
    to suit the input size of different deep models. Garain et al. (Garain et al.,
    [2021](#bib.bib50)) resize each image to a dimension of 32×32 and the images are
    converted to greyscale.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Flipping and Rotating
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Flipping and rotating are the commonly used data augmentation methods, which
    can guarantee that the deep learning model is trained with images at any angle
    and thus can make better prediction (Annavarapu et al., [2021](#bib.bib14)). And
    the sufficient images can also help deep model avoid overfitting. Sedik et al.
    (Sedik et al., [2022](#bib.bib152)) use a dataset consisting of 288 COVID-19 cases
    and 288 normal cases. The dataset is augmented by several rotations and scaling
    operations. Keles et al. (Keles et al., [2021](#bib.bib82)) employ three augmentation
    methods, including horizontal/vertical flipping, rotation and shifting. Ahuja
    et al. (Ahuja et al., [2021](#bib.bib6)) randomly rotate the training data between
    range [-90°, 90°] to resolve the overfitting problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cropping
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Cropping refers to cropping the given image to remove irrelevant regions. It
    greatly reduces the interference of irrelevant information and largely increases
    the performance and robustness of deep learning models. Balaha et al. (Balaha
    et al., [2022](#bib.bib22)) preprocess the image data to a suitable format for
    CNN to further learn the latent features. The images are cropped using a bounding
    rectangle to reserve the region of interest. Madaan et al. (Madaan et al., [2021](#bib.bib107))
    use two chest X-ray image datasets in their model. Cropping is employed to reduce
    the noise and all images are resized. Zhang et al. (Zhang et al., [2021b](#bib.bib218))
    crop the rulers on the right side of the image and texts on the bottom of the
    image, which are irrelevant information and can impair the model performance.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Contrast adjusting
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Medical images may have poor contrast during imaging process and data acquisition.
    It is essential to enhance image contrast to help deep models extract meaningful
    information from the region of interest. Dhaka et al. (Dhaka et al., [2021](#bib.bib41))
    propose that changing the contrast of X-ray images is capable of improving the
    performance of deep model. Tahir et al. (Tahir et al., [2022](#bib.bib181)) use
    contrast limited adaptive histogram equalization (CLAHE) to enhance the contrast
    of the original X-ray image. The produced images are more natural compared with
    other contrast enhancement methods. Habib et al. (Habib et al., [2022](#bib.bib54))
    use histogram equalization (HE) and CLAHE to enhance the contrast.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Denoising
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Image noise means the unnecessary or unwanted interference information that
    exists in an image. Noise can seriously affect the quality of images. Hence, it
    is necessary to do denoising before the downstream image processing task. Mahendran
    et al. (Mahendran and Kavitha, [2022](#bib.bib109)) use DnCNN Algorithm to denoise
    CT Images before image classification. Balaha et al. (Balaha et al., [2022](#bib.bib22))
    convert all images to grayscale images and apply Gaussian blurring to eliminate
    unnecessary noise. Mishra et al. (Mishra, [2021](#bib.bib120)) use a Gaussian
    filter to smooth the image and the background noise can be eliminated via a two-dimensional
    median filter.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Applying appropriate preprocessing methods needs to consider multiple factors
    such as the size of the dataset, image quality, input of the model, and the application
    scenarios. We investigate various papers using deep learning and medical imaging
    to diagnose COVID over the past three years. We summarize the representative preprocessing
    technologies in Table [2](#S3.T2 "Table 2 ‣ 3\. Image Preprocessing Technologies
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2\. A summary of various preprocessing techniques used in different papers.
  prefs: []
  type: TYPE_NORMAL
- en: '| Preprocessing Method | Papers | Count |'
  prefs: []
  type: TYPE_TB
- en: '| Resizing | (Nivetha and Inbarani, [2022](#bib.bib128); Khurana and Soni,
    [2022](#bib.bib86); Sarv Ahrabi et al., [2022](#bib.bib149); Kumari and Jagadesh,
    [2022](#bib.bib94); Balaha et al., [2022](#bib.bib22); Madaan et al., [2021](#bib.bib107);
    Zhou et al., [2021c](#bib.bib228); Shah et al., [2021b](#bib.bib156); Garain et al.,
    [2021](#bib.bib50); Mishra, [2021](#bib.bib120); Ravi et al., [2022](#bib.bib145);
    Annavarapu et al., [2021](#bib.bib14); Yasar and Ceylan, [2021a](#bib.bib207);
    Singh et al., [2021b](#bib.bib173); Zhang et al., [2021b](#bib.bib218); Abraham
    and Nair, [2022](#bib.bib2); Tan et al., [2021](#bib.bib183); Elpeltagy and Sallam,
    [2021](#bib.bib46); Dhaka et al., [2021](#bib.bib41); Ahuja et al., [2021](#bib.bib6);
    Zhang et al., [2021c](#bib.bib215); Shiri et al., [2022](#bib.bib166); Hasan et al.,
    [2021](#bib.bib58); Akbarimajd et al., [2022](#bib.bib7); Kogilavani et al., [2022](#bib.bib90);
    Baghdadi et al., [2022](#bib.bib21); Zhang et al., [2022b](#bib.bib216); Zhao
    et al., [2021b](#bib.bib221)) | 28 |'
  prefs: []
  type: TYPE_TB
- en: '| Flipping and Rotating | (Joshi et al., [2022](#bib.bib78); Madaan et al.,
    [2021](#bib.bib107); Sedik et al., [2022](#bib.bib152); Mishra, [2021](#bib.bib120);
    Annavarapu et al., [2021](#bib.bib14); Heidarian et al., [2021](#bib.bib62); Zhang
    et al., [2021b](#bib.bib218); Keles et al., [2021](#bib.bib82); Jangam et al.,
    [2022](#bib.bib76); Huang et al., [2021a](#bib.bib68); Ahuja et al., [2021](#bib.bib6);
    Aslan et al., [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90); Baghdadi
    et al., [2022](#bib.bib21); Zhao et al., [2021b](#bib.bib221)) | 15 |'
  prefs: []
  type: TYPE_TB
- en: '| Cropping | (Sarv Ahrabi et al., [2022](#bib.bib149); Balaha et al., [2022](#bib.bib22);
    Madaan et al., [2021](#bib.bib107); Mishra, [2021](#bib.bib120); Zhang et al.,
    [2021b](#bib.bib218); Jangam et al., [2022](#bib.bib76); Shiri et al., [2022](#bib.bib166);
    Aslan et al., [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90); Zhang
    et al., [2022b](#bib.bib216); Lian et al., [2022](#bib.bib100)) | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| Contrast adjusting | (Tahir et al., [2022](#bib.bib181); Habib et al., [2022](#bib.bib54);
    Mishra, [2021](#bib.bib120); Dhaka et al., [2021](#bib.bib41); Baghdadi et al.,
    [2022](#bib.bib21)) | 5 |'
  prefs: []
  type: TYPE_TB
- en: '| Denoising | (Nivetha and Inbarani, [2022](#bib.bib128); Mahendran and Kavitha,
    [2022](#bib.bib109); Balaha et al., [2022](#bib.bib22); Mishra, [2021](#bib.bib120);
    Zhang et al., [2022b](#bib.bib216)) | 5 |'
  prefs: []
  type: TYPE_TB
- en: 4\. Image Segmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Accurate segmentation of lung and infection in medical images of COVID-19 patients
    plays a crucial role in the diagnosis of COVID-19 patients (Ma et al., [2021](#bib.bib106);
    Shiri et al., [2022](#bib.bib166)). In specific, image segmentation identifies
    the region of interest (RoI) from given medical images and divides the medical
    image into several parts (Liu et al., [2021](#bib.bib103); Zhao et al., [2019](#bib.bib222)).
    The segmented region can aid doctors and deep learning models more comfortably
    to understand lung disease type and severity (Ter-Sarkisov, [2022](#bib.bib187);
    Khan et al., [2022](#bib.bib84); Shi et al., [2020](#bib.bib162)). Punn et al.
    (Punn and Agarwal, [2022](#bib.bib138)) propose a deep learning based semantic
    hierarchical segmenter (CHS-Net) to identify the COVID-19 infected regions from
    chest CT images. They apply a residual inception U-Net model with spectral spatial
    and depth attention network (SSD) to effectively encode and decode the semantic
    and varying image information, and finally segment the COVID-19 infected regions
    in the lungs. Wang et al. (Wang et al., [2021b](#bib.bib196)) propose a lesion
    edge detection model (COVID Edge-Net), which consists of one edge detection backbone
    and two novel modules, i.e., the multi-scale residual dual attention (MSRDA) module
    and the Canny operator module. The MSRDA module can capture rich contextual associations
    to generate enhanced feature representations, which are then merged with Canny
    features learned from the Canny operator module to extract more accurate, clearer,
    and sharper edges.
  prefs: []
  type: TYPE_NORMAL
- en: Chen et al. (Chen et al., [2022](#bib.bib33)) propose a segmentation network
    based on unsupervised domain adaptation (UDA) to improve the segmentation performance
    of the infected regions in CT images. The generalization ability of the segmentation
    network is significantly enhanced by a novel domain adaption module that aligns
    the two domains. Their proposed method achieves high performance in lung segmentation,
    and it is proved that their proposed model is also suitable for large-area organs
    or tissues. Lashchenova et al. (Lashchenova et al., [2021](#bib.bib97)) argue
    that an important factor affecting the real performance of the segmentation model
    is that the model segments the puncta (connected components) of lung and the lung
    lesions outside the real lung. To detect this, connected components are computed
    for every class and for each component to found whether it has interception with
    ground-truth lungs.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. U-net Architecture
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'U-net is a popular image segmentation network which is developed primarily
    for medical image segmentation. It is built based on Convolutional Neural Network
    (CNN) and is upgraded to achieve better segmentation performance (Shirato et al.,
    [2020](#bib.bib165); Minaee et al., [2022](#bib.bib119); Siddique et al., [2021](#bib.bib170)).
    As shown in Figure [4](#S4.F4 "Figure 4 ‣ 4.1\. U-net Architecture ‣ 4\. Image
    Segmentation ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive
    Survey"), the U-Net (Ronneberger et al., [2015](#bib.bib146)) network is U-shaped,
    mainly including the downsampling layer on the left and the upsampling process
    on the right. The structure is symmetrical from left to right. Additionally, the
    encoder-decoder structure and skip connection used by U-Net are core designs to
    achieve a more effective combination of contextual information to make precise
    pixel-level judgments.'
  prefs: []
  type: TYPE_NORMAL
- en: Alirr (Alirr, [2022](#bib.bib10)) designs a lung image segmentation method to
    extract the region of interest, which modifies U-net with upgraded residual block
    including concatenation skip connection. Additionally, the segmented region employs
    edge enhancing diffusion filtering (EED) to improve the infection area’s contrast.
    Their proposed method achieves Dice overlapping score of 96.1% and 78.0% for lung
    and infection areas segmentation. Diniz et al. (Diniz et al., [2021](#bib.bib42))
    seek to automatically identify infections caused by COVID-19 and evaluate quantitative
    score of the infected region. They propose a model by modifying the traditional
    U-net architecture via batch normalization, leaky ReLU, dropout, and residual
    block techniques. Their model yields an average Dice value of 77.1% and an average
    specificity of 99.8%.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1636f17858c3e1e4c731453036d7f97e.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. Representative U-net architecture for image segmentation task (Ronneberger
    et al., [2015](#bib.bib146)).
  prefs: []
  type: TYPE_NORMAL
- en: Zhao et al. (Zhao et al., [2021b](#bib.bib221)) propose a novel dilated dual
    attention U-Net (D2A U-Net) with the dual attention strategy and hybrid dilated
    convolutions to segment COVID-19 lesion region. The former dual attention strategy,
    which contains two attention modules, is used to enhance feature maps and reduce
    the semantic gap among diverse levels of feature maps. The latter hybrid dilated
    convolutions are used for achieving larger receptive fields. Their proposed method
    achieves 0.73 Dice score and 0.71 recall score. Lian et al. (Lian et al., [2022](#bib.bib100))
    propose an end-to-end DRD U-Net (dilated residual and deeply supervised U-Net)
    network to segment the lung lesions. They add residual modules to each layer of
    channel to accelerate convergence and avoid gradient disappearance. To extract
    richer feature information, the extended convolution unit is utilized to increase
    the receptive field without increasing the number of parameters. In the experiments,
    their proposed model shows impressive segmentation performance and the error can
    be significantly reduced compared with the original U-Net.
  prefs: []
  type: TYPE_NORMAL
- en: 'U-net has shown great potential in the field of image segmentation. Some variants
    that follow the core idea of U-net have been proposed, including attention U-net
    (Schlemper et al., [2019](#bib.bib151)), and Residual U-net (Das et al., [2019](#bib.bib38)),
    to complete more complex segmentation tasks. In addition to U-Net architecture,
    other segmentation methods such as V-Net, ResU-Net, Dense-Net, and DeepLab, are
    also used for the segmentation of COVID-19 infected region in different papers.
    Table [3](#S4.T3 "Table 3 ‣ 4.1\. U-net Architecture ‣ 4\. Image Segmentation
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey")
    displays the various segmentation techniques employed by different papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 3\. A summary of various segmentation methods used in different papers.
  prefs: []
  type: TYPE_NORMAL
- en: '| Segmentation methods | Papers | Count |'
  prefs: []
  type: TYPE_TB
- en: '| U-Net | (Ma et al., [2021](#bib.bib106); Lashchenova et al., [2021](#bib.bib97);
    Diniz et al., [2021](#bib.bib42); Xiao et al., [2022](#bib.bib202); Voulodimos
    et al., [2021a](#bib.bib194); Jadhav et al., [2021](#bib.bib74); Avetisian et al.,
    [2021](#bib.bib20); Punn and Agarwal, [2022](#bib.bib138); Alirr, [2022](#bib.bib10);
    Zhou et al., [2021a](#bib.bib227); Elharrouss et al., [2022](#bib.bib45); Kuchana
    et al., [2021](#bib.bib93); Trivizakis et al., [2020](#bib.bib189); Shan et al.,
    [2021](#bib.bib158); Tahir et al., [2022](#bib.bib181); Saood, [2021](#bib.bib148);
    Lian et al., [2022](#bib.bib100); Voulodimos et al., [2021b](#bib.bib195)) | 18
    |'
  prefs: []
  type: TYPE_TB
- en: '| V-Net | (Voulodimos et al., [2021a](#bib.bib194); Zhao et al., [2021a](#bib.bib220);
    Milletari et al., [2016](#bib.bib118)) | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| ResU-Net | (Diniz et al., [2021](#bib.bib42); Jadhav et al., [2021](#bib.bib74);
    Avetisian et al., [2021](#bib.bib20)) | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Dense-Net | (Al-Antari et al., [2021](#bib.bib8); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| UNet++ | (Zhou et al., [2021a](#bib.bib227); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Deeplab | (Diniz et al., [2021](#bib.bib42); Amin et al., [2022](#bib.bib13))
    | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| Attention-UNet | (Zhao et al., [2021b](#bib.bib221); Elharrouss et al., [2022](#bib.bib45))
    | 2 |'
  prefs: []
  type: TYPE_TB
- en: '| SAUNet++ | (Xiao et al., [2022](#bib.bib202)) | 1 |'
  prefs: []
  type: TYPE_TB
- en: '| COVSeg-NET | (Zhang et al., [2021c](#bib.bib215)) | 1 |'
  prefs: []
  type: TYPE_TB
- en: 4.2\. Loss Function
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The loss function is another important component of the segmentation model.
    It can guide the segmentation model to learn towards a specific direction and
    segment the wanted infected area. Xiao et al. (Xiao et al., [2022](#bib.bib202))
    use focal Tversky loss (FTL) and the generalized Dice loss (GDL). The GDL can
    reduce the correlation between lesion size and Dice loss, and can effectively
    guide the model in segmenting small regions. Elharrouss et al. (Elharrouss et al.,
    [2022](#bib.bib45)) use binary cross entropy as loss function and their model
    reaches 78.6% for Dice, 71.1% for sensitivity metric, 99.3% for specificity, and
    85.6% for precision. Alirr (Alirr, [2022](#bib.bib10)) uses Dice loss as loss
    function and averages the DSC of each class to generate the final score. Diniz
    et al. (Diniz et al., [2021](#bib.bib42)) use Dice loss as loss function and their
    proposed model reaches 77.1% for Dice, and 99.76% for average specificity. This
    section will introduce several representative loss functions commonly used in
    the medical image segmentation task.
  prefs: []
  type: TYPE_NORMAL
- en: A. Binary Cross Entropy
  prefs: []
  type: TYPE_NORMAL
- en: 'The pixel level cross entropy loss is commonly used in image segmentation task.
    For a given random variable, this loss function will examine each pixel individually
    and compare the difference between two probability distributions. Binary cross
    entropy is defined as (Yi-de et al., [2004](#bib.bib210)):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $L_{CE}(y,\hat{y})=-\left(y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $y$ and $\hat{y}$ represent the ground truth value and predicted value
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: B. Weighted Binary Cross Entropy
  prefs: []
  type: TYPE_NORMAL
- en: 'Weighted binary cross entropy (WCE) (Pihur et al., [2007](#bib.bib134)) is
    a variant of binary cross entropy, which aims to solve the problem of uneven distribution
    of lesion information in medical image. WCE is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $L_{WCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+\left(1-y\right)\log\left(1-\hat{y}\right)\right),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\beta$ is used to tune false negative and false positive. If we want
    to decrease the number of false negative, set $\beta$¿1\. In contrast, setting
    $\beta$¡1 can decrease the number of false positive.
  prefs: []
  type: TYPE_NORMAL
- en: C.Balanced Cross Entropy
  prefs: []
  type: TYPE_NORMAL
- en: 'Balanced cross entropy (BCE) (Xie and Tu, [2015](#bib.bib203)) is similar with
    WCE, which appropriately weights positive examples and negative examples. Balanced
    cross entropy is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $L_{BCE}(y,\hat{y})=-\left(\beta*y\log\left(\hat{y}\right)+(1-\beta)\left(1-y\right)\log\left(1-\hat{y}\right)\right).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: D. Focal Loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Focal loss (Lin et al., [2017](#bib.bib101)) is often used to deal with unbalanced
    sample classification. It focuses on weighting loss to the sample according to
    the difficulty of sample discrimination. For medical images presenting small lesion
    information, focal loss assigns a larger weight to positive pixels and can achieve
    excellent performance. It is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (4) |  | $L_{fl}=-\alpha_{t}\left(1-p_{t}\right)^{\gamma}\log\left(p_{t}\right),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\gamma$ is a regulatory parameter and $\gamma$¿0\. $\alpha_{t}$ generally
    ranges from [0,1], which is used to deal with class imbalance. Focal loss defines
    $p_{t}$ as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (5) |  | $p_{t}=\begin{cases}\hat{p}&amp;\text{ if }y=1\\ 1-\hat{p}&amp;\text{
    otherwise }\end{cases},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\hat{p}$ represents the predicted value of pixel classification and $y$
    denotes the ground truth value.
  prefs: []
  type: TYPE_NORMAL
- en: E. Dice Loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Dice loss (Sudre et al., [2017](#bib.bib179)) is designed to calculate the
    similarity between two images and is utilized to guide the training process of
    image segmentation methods. Dice loss is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $DL(y,\hat{p})=1-\frac{2y\hat{p}+1}{y+\hat{p}+1}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: Here, 1 is added in numerator and denominator to ensure that the function is
    not undefined in edge case scenarios where $y=\hat{p}=0$.
  prefs: []
  type: TYPE_NORMAL
- en: F. Generalized Dice Loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Dice loss is unsuitable to predict small targets. When some pixels of small
    targets are predicted incorrectly, Dice coefficient may greatly fluctuate. To
    solve these problems, GDL uses weights inversely proportional to lesion region,
    in order to better segment small regions (Xiao et al., [2022](#bib.bib202)). When
    the number of classes is 2, Generalized Dice loss is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (7) |  | $GDL=1-2\frac{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}p_{l_{n}}}{\sum_{l=1}^{2}w_{l}\sum_{n}r_{ln}+p_{l_{n}}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $r_{ln}\in\{0,1\}$ and $p_{l_{n}}\in[0,1]$ denote the true voxel values
    of $n$-th position and the related probability predicted as class $l$. $w_{l}$
    represents the weight of class $l$ and is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (8) |  | $w_{l}=\frac{1}{\left(\sum_{n=1}^{N}r_{ln}\right)^{2}+\varepsilon},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $N$ is the total number of pixels, and $\varepsilon$ is often set as $10^{-5}$
    to prevent the loss function from dividing by 0.
  prefs: []
  type: TYPE_NORMAL
- en: G. Tversky Loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Tversky loss (Salehi et al., [2017](#bib.bib147)) is considered as a generalization
    of Dice loss, where the coefficient $\beta$ is a hyperparameter that controls
    the balance between false negative (FN) and false positive (FP). Tversky loss
    is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (9) |  | $TL(p,\hat{p})=\frac{p\hat{p}}{p\hat{p}+\beta(1-p)\hat{p}+(1-\beta)p(1-\hat{p})},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $p$ and $\hat{p}$ denote the ground truth value and predicted value respectively.
    When $\beta$ = 0.5, it can be solved into regular Dice coefficient.
  prefs: []
  type: TYPE_NORMAL
- en: H. Focal Tversky Loss
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to focal loss, focal Tversky loss (Abraham and Khan, [2019](#bib.bib3))
    is proposed to deal with class imbalance. It focuses on learning hard samples
    with the help of coefficient $\gamma$. Focal Tversky loss is often used to segment
    small regions and is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (10) |  | $FTL=\sum_{c}\left(1-TI_{c}\right)^{\gamma},$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where the hyperparameter $\gamma$ can range from [1,3], and $TI_{c}$ (Tversky
    index) is defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (11) |  | $TI_{c}=\frac{\sum_{i=1}^{N}p_{ic}g_{ic}}{\sum_{i=1}^{N}p_{ic}g_{ic}+\alpha\sum_{i=1}^{N}p_{i\bar{c}}g_{ic}+\beta\sum_{i=1}^{N}p_{ic}g_{i\bar{c}}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $p_{ic}$ and $p_{i\bar{c}}$ are probabilities that pixel $i$ belongs to
    the lesion class $c$ and non-lesion class $\bar{c}$, respectively. $g_{ic}$ and
    $g_{i\bar{c}}$ represent probabilities for another class. $N$ is the total number
    of pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Manual detection of COVID-19 (RT-PCR), which has extremely high accuracy and
    specificity, is always regarded as the gold standard for COVID-19 detection (Pu
    et al., [2022](#bib.bib137); Rabaan et al., [2021](#bib.bib141)). However, RT-PCR
    is time-consuming, and the spread risk and susceptibility of the disease are greatly
    increased during detection (Rahman et al., [2021b](#bib.bib143); Peng et al.,
    [2022](#bib.bib133)). Hence, many studies are focusing on diagnosing COVID-19
    using medical images, attempting to find a diagnostic method that can guarantee
    high accuracy and significantly minimize human contact during detection (Krishnamoorthy
    et al., [2021](#bib.bib91); Xu et al., [2022](#bib.bib204); Ibrahim et al., [2021](#bib.bib71);
    Shorfuzzaman, [2021](#bib.bib167)). Among the many inspection methods, the deep
    learning models using medical images have shown excellent performance. And they
    are thus extensively utilized in image classification, lesion segmentation, and
    severity quantification to fight against COVID-19, such as Convolutional Neural
    Network (CNN) (Singh et al., [2021a](#bib.bib174); Pouyanfar et al., [2018](#bib.bib136);
    Rahman et al., [2021a](#bib.bib142)), Generative Adversarial Network (GAN) (Bargshady
    et al., [2022](#bib.bib24); Kim et al., [2021](#bib.bib87)), and Long Short-Term
    Memory (LSTM) (Demir, [2021](#bib.bib39); Naeem and Bin-Salem, [2021](#bib.bib124);
    Sheykhivand et al., [2021](#bib.bib161)). In this section, we will introduce the
    different applications of deep learning models in diagnosing COVID-19.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. CNN models for COVID-19 diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Convolutional Neural Network (CNN) is a multi-layer supervised neural network,
    in which the hidden convolutional and pooling layers are the core modules to realize
    the feature extraction function (Anwar et al., [2018](#bib.bib15); Alzubaidi et al.,
    [2021](#bib.bib12)). CNN uses the gradient descent method to minimize the loss
    function and error back propagation (BP) is employed to reversely adjust the weight
    parameters in the network layer by layer (Mishra and Kane, [2022](#bib.bib121)).
    CNN models have demonstrated great potential in medical image processing and become
    a popular approach for identifying COVID-19 and localizing lesion. As Figure [5](#S5.F5
    "Figure 5 ‣ 5.1\. CNN models for COVID-19 diagnosis ‣ 5\. Overall Analysis of
    DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical Imaging for
    COVID-19 Diagnosis: A Comprehensive Survey") depicts, a representative CNN model
    for COVID-19 diagnosis generally includes input, convolutional layers, pooling
    layers, fully connected layer, and output (Bhattacharya et al., [2021](#bib.bib26)).
    Additionally, we try to record some deep learning methods and model evaluation
    metrics used in high quality studies and more detailed information is shown in
    Table [4](#S5.T4 "Table 4 ‣ 5.1\. CNN models for COVID-19 diagnosis ‣ 5\. Overall
    Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical
    Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Wang et al. (Wang et al., [2020](#bib.bib198)) design a deep learning-based
    method for automatic COVID-19 diagnosis. Their model uses a pre-trained U-Net
    to segment the lung region. The segmented 3D lung region is input into the 3D
    deep neural network to predict the possibility of infection. Finally, the activation
    regions in the classification network and the unsupervised connected components
    are together used to localize the COVID-19 lesions. Their proposed method obtains
    an accuracy of 0.90, a positive predictive value of 0.84, and a high negative
    predictive value of 0.98\. Turkoglu (Turkoglu, [2021](#bib.bib190)) proposes an
    expert-designed system named COVIDetectioNet, which is consisted of three basic
    components. First, deep features are obtained from the pre-trained AlexNet architecture.
    Second, the relief selection algorithm is employed to select the most efficient
    features from the pre-learned deep features. Third, the support vector machine
    (SVM) method is used for final classification. Their proposed model is validated
    by classifying 6,092 X-ray images as normal (healthy), COVID-19, and pneumonia
    cases, respectively. In the experimental results, their proposed model achieves
    99.18% accuracy and 97.1% sensitivity.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b090ca312d9291b7b5c80108c9239f61.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. A representative workflow of using CNN model to identify COVID-19
    cases from normal cases.
  prefs: []
  type: TYPE_NORMAL
- en: Singh et al. (Singh et al., [2021a](#bib.bib174)) propose an automated COVID-19
    screening model. It employs some pre-trained CNN models such as DenseNet201, ResNet152V2,
    and VGG16, for early detection of COVID-19 patients. The predicted outputs are
    fed into the ensemble DCCNs, which are designed for diagnosing the suspected objects
    into four classes, including COVID-19 cases, tuberculosis, pneumonia, and healthy
    subjects. Their proposed model achieves 98.94% accuracy, 98.94% sensitivity and
    98.93% specificity, which is superior to the competitive models. Moreover, Aslan
    et al. (Aslan et al., [2022](#bib.bib18)) firstly use ANN-based automated segmentation
    method to extract region of interest in the X-ray images. Second, various CNNs
    are used for feature extraction after data augmentation stage. Third, the features
    learned from each CNN model are input to four different machine learning (ML)
    algorithms for classification. The hyperparameters of each ML algorithm are determined
    by Bayesian optimization. Finally, the highest performance is obtained by the
    DenseNet201 model with SVM algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Kogilavani et al. (Kogilavani et al., [2022](#bib.bib90)) explore the performance
    of a variety of convolutional neural network (CNN) models in detecting COVID-19,
    attempting to find the suitable deep models, including VGG16, DeseNet121, MobileNet,
    NASNet, Xception, and EfficientNet. Accuracy obtained for VGG16 is 97.68%, DenseNet121
    is 97.53%, MobileNet is 96.38%, NASNet is 89.51%, Xception is 92.47%, and EfficientNet
    is 80.19%, respectively. Based on the performance analyses, it is demonstrated
    that the VGG16 architecture reaches the best accuracy compared to other architectures.
    Akbarimajd et al. (Akbarimajd et al., [2022](#bib.bib7)) propose a novel CNN approach
    applying adaptive convolution, which intends to enhance COVID-19 identification
    in noisy X-ray images without reducing noise. Specifically, the impulse noise-map
    layer and the adaptive resizing layer are added on the traditional CNN framework.
    A learning-to-augment strategy which uses noisy X-ray images is designed to improve
    the generalization of deep model. Some pre-trained networks such as SqueezeNet,
    ResNet18, and ResNet50 are modified to increase their robustness for impulse noise.
  prefs: []
  type: TYPE_NORMAL
- en: Table 4\. Deep learning methods and result evaluation for diagnosing COVID-19
    using CNN models.
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Data | Deep Learning Methods | Classification | Acc | Sn | Sp
    |'
  prefs: []
  type: TYPE_TB
- en: '| Tang et al. (Tang et al., [2021a](#bib.bib184)) | X-ray | Ensemble learning,
    COVID-Net | Multiclass | 95.0% | 96.0% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Yamaç et al. (Yamaç et al., [2021](#bib.bib205)) | X-ray | CheXNet, CSEN
    | Multiclass | 95.9% | 98.5% | 95.7% |'
  prefs: []
  type: TYPE_TB
- en: '| Pathak et al. (Pathak et al., [2020](#bib.bib131)) | CT | CNN, Transfer learning
    | Binary | 93.0% | 91.5% | 94.9% |'
  prefs: []
  type: TYPE_TB
- en: '| Rathinasamy et al. (R et al., [2022](#bib.bib140)) | X-ray | CNN, Ensemble
    learning | Binary | 99.0% | — | — |'
  prefs: []
  type: TYPE_TB
- en: '| Khan et al. (Khan et al., [2021](#bib.bib85)) | X-ray | COVID-RENet, SVM
    | Binary | 98.5% | 99.0% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Wang et al. (Wang et al., [2020](#bib.bib198)) | CT | DeCoVNet, U-net | Binary
    | 90.1% | 90.7% | 91.1% |'
  prefs: []
  type: TYPE_TB
- en: '| Zhou et al. (Zhou et al., [2021c](#bib.bib228)) | CT | AlexNet, GoogleNet,
    ResNet, Ensemble learning | Multiclass | 99.1% | 99.1% | 99.6% |'
  prefs: []
  type: TYPE_TB
- en: '| Zheng et al. (Zheng et al., [2022](#bib.bib223)) | CT | ResNet50, MAB, FAB
    | Binary | 98.2% | 98.8% | 97.3% |'
  prefs: []
  type: TYPE_TB
- en: '| Choudhary et al. (Choudhary et al., [2022](#bib.bib35)) | CT | VGG16, ResNet34
    | Binary | 95.5% | 92.2% | 99.4% |'
  prefs: []
  type: TYPE_TB
- en: '| Singh et al. (Singh et al., [2021a](#bib.bib174)) | CT | CNN, Ensemble learning,
    Transfer learning | Multiclass | 98.8% | 98.8% | 98.8% |'
  prefs: []
  type: TYPE_TB
- en: '| Balaha et al. (Balaha et al., [2022](#bib.bib22)) | CT | CNN, Transfer learning,
    GAN | Binary | 98.7% | — | — |'
  prefs: []
  type: TYPE_TB
- en: '| Turkoglu (Turkoglu, [2021](#bib.bib190)) | X-ray | AlexNet, Transfer learning,
    SVM | Multiclass | 99.2% | 97.1% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Aslan et al. (Aslan et al., [2022](#bib.bib18)) | X-ray | CNN, Transfer learning,
    Bayesian Optimization | Multiclass | 96.3% | 96.4% | 98.1% |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et al. (Zhang et al., [2022b](#bib.bib216)) | CT | CNN, Transfer learning,
    Bayesian Optimization | Binary | 92.1% | — | 91.2% |'
  prefs: []
  type: TYPE_TB
- en: 'Some existing convolutional neural network architectures have been proven to
    be vital in medical image feature extraction, such as ResNet (He et al., [2016](#bib.bib60)),
    AlexNet (Krizhevsky et al., [2017](#bib.bib92)), SqueezeNet (Iandola et al., [2016](#bib.bib70)),
    Inception (Szegedy et al., [2015](#bib.bib180)), DenseNet (Huang et al., [2017](#bib.bib65)),
    VGG (Simonyan and Zisserman, [2014](#bib.bib171)), and EfficientNet (Tan and Le,
    [2019](#bib.bib182)). Various CNN models used in different papers for COVID-19
    diagnosis are listed in Table [5](#S5.T5 "Table 5 ‣ 5.2\. Transfer learning for
    COVID-19 diagnosis ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis
    ‣ Deep Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").
    The ResNet is the most popular network model to detect COVID-19 and 34 papers
    use ResNet as backbone network. Besides, the DenseNet and the VGG are also used
    by many studies to detect COVID-19\. In conclusion, it is significant for us to
    select an appropriate CNN model as backbone network to diagnose COVID-19 by considering
    data type, actual scale, application scenarios and other factors.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Transfer learning for COVID-19 diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Transfer learning is a machine learning technique that can transfer existing
    knowledge from one domain (source domain) to another (target domain) (Zhuang et al.,
    [2020](#bib.bib229)). The source domain generally has sufficient annotated data
    and many existing models have learned excellent feature extraction capabilities.
    The target domain lacks large-scale annotated samples and the cost of obtaining
    annotated samples is too high (Guan and Liu, [2021](#bib.bib52); Morid et al.,
    [2021](#bib.bib122)). Transfer learning aims to use knowledge learned from the
    source domain to help the target learner achieve better performance. The closer
    the relationship between the target domain and the source domain, the better transfer
    learning can be achieved (Das et al., [2022](#bib.bib37)). Otherwise, it may be
    more difficult and even has negative transfer to bring harmful effects. As shown
    in Figure [6](#S5.F6 "Figure 6 ‣ 5.2\. Transfer learning for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey"), the pre-trained
    model has obtained excellent generalization performance in the source domain and
    then it is fine-tuned by using small-scale data from the target domain (Chen et al.,
    [2021](#bib.bib34)). Due to the expensive cost of capturing CT or X-ray images
    of COVID-19 patients, various pre-trained deep learning models have been employed
    for COVID-19 diagnosis.'
  prefs: []
  type: TYPE_NORMAL
- en: Kabe et al. (Kashala Kabe et al., [2021](#bib.bib81)) propose a novel domain
    transfer learning model for classifying COVID-19 cases, named feature fusion,
    decompose and transfer (FFDT). Their proposed FFDT gains feature enhancement by
    combining far-off features taken from far-off domains into a single feature space
    where the distribution mismatch is reduced. Additionally, they adopt modified
    convolutional neural network (MCNN) to extract features and the class reconstruction
    is used to unravel the local structure of the data distribution. Their model achieves
    the classification accuracy of 94.5%. Lu et al. (Lu et al., [2021](#bib.bib105))
    suggest that transfer learning can be used to extract features from chest CT images
    because it is of high complexity to train a CNN model from scratch. The pre-trained
    ResNet-18 and ResNet-50 models are chosen as the backbone to extract features
    from the CT images. To create refined image features, the retrieved features are
    combined using discriminant correlation analysis. Finally, in order to get a more
    reliable classification performance, three randomized neural networks are trained
    using the improved features and their predictions are combined.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f4de81860439eea5ecc6879871b7342a.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. The application of deep learning using transfer learning method for
    COVID-19 diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: Vogado et al. (Vogado et al., [2021](#bib.bib193)) evaluate transfer learning
    techniques in five pre-trained CNN architectures (VGG-16, VGG-19, ResNet-50, Xception
    and DenseNet-121). In specific, they train CNNs using 1,436 images associated
    with COVID-19 cases, 1,932 healthy images, and 3,651 images of other pathologies.
    The pre-trained ResNet50 obtains the best performance for extracting deep features,
    and the MLP classifier has shown the best results when using the features derived
    by ResNet50\. Makris et al. (Makris et al., [2020](#bib.bib111)) use a combination
    of publicly available X-ray images from patients with confirmed COVID-19 cases,
    common bacterial pneumonia and healthy cases. Transfer learning is used for mitigating
    the issue of insufficient samples. In order to classify images, VGG16, VGG19,
    MobileNet V2, Inception V3, Xception, InceptionResNet V2, DenseNet201, and ResNet152
    V2 are employed and compared to explore the best model for COVID-19 diagnosis.
    Specifically, VGG16 and VGG19 perform the best and achieve an overall accuracy
    of 95%.
  prefs: []
  type: TYPE_NORMAL
- en: Pathak et al. (Pathak et al., [2020](#bib.bib131)) employ a deep transfer learning
    technique to classify COVID-19 infected patients. The ResNet-50 is chosen as backbone
    network and transfer learning is employed to adjust the initial parameters of
    the deep layers. The pre-trained model, which is fine-tuned by a small number
    of training samples, can extract correct deep features from chest CT images to
    detect COVID-19 infected patients. Their proposed model achieves training and
    testing accuracy up to 96.23% and 93.02% respectively, which is superior to the
    compared deep models. To detect COVID-19 by medical images, Shamsi et al. (Shamsi
    et al., [2021](#bib.bib157)) propose a novel deep uncertainty-aware transfer learning
    framework. The pre-trained CNNs are used to extract features from chest X-ray
    and CT images. The extracted features are subsequently used to identify COVID-19
    cases using various machine learning and statistical modeling techniques. It has
    been found that CT images can produce superior diagnosis because they contain
    more information than X-ray images.
  prefs: []
  type: TYPE_NORMAL
- en: Table 5\. A summary of various CNN models used by different papers for COVID-19
    detection.
  prefs: []
  type: TYPE_NORMAL
- en: '| CNN model | Papers | Count |'
  prefs: []
  type: TYPE_TB
- en: '| ResNet | (Zheng et al., [2022](#bib.bib223); Khurana and Soni, [2022](#bib.bib86);
    Tahir et al., [2022](#bib.bib181); Canayaz et al., [2022](#bib.bib29); Habib et al.,
    [2022](#bib.bib54); Balaha et al., [2022](#bib.bib22); Dev et al., [2021](#bib.bib40);
    Zhou et al., [2021c](#bib.bib228); Madhavan et al., [2021](#bib.bib108); Shorfuzzaman,
    [2021](#bib.bib167); Shah et al., [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174);
    Annavarapu et al., [2021](#bib.bib14); Ilhan et al., [2022](#bib.bib72); Huang
    et al., [2021b](#bib.bib67); Keles et al., [2021](#bib.bib82); Elpeltagy and Sallam,
    [2021](#bib.bib46); Jangam et al., [2022](#bib.bib76); Ahuja et al., [2021](#bib.bib6);
    Jain et al., [2021](#bib.bib75); Turkoglu, [2021](#bib.bib190); Huang, [2020](#bib.bib66);
    Hira et al., [2021](#bib.bib63); Wang et al., [2020](#bib.bib198); Zhang et al.,
    [2021a](#bib.bib217); Pathak et al., [2020](#bib.bib131); Sen et al., [2021](#bib.bib153);
    Chakraborty et al., [2021](#bib.bib30); Zebin and Rezvy, [2021](#bib.bib212);
    Song et al., [2021](#bib.bib176); Kundu et al., [2022](#bib.bib95); Paul et al.,
    [2022](#bib.bib132); Akbarimajd et al., [2022](#bib.bib7); Aslan et al., [2022](#bib.bib18))
    | 34 |'
  prefs: []
  type: TYPE_TB
- en: '| DenseNet | (Tahir et al., [2022](#bib.bib181); Habib et al., [2022](#bib.bib54);
    Dev et al., [2021](#bib.bib40); Shorfuzzaman, [2021](#bib.bib167); Shah et al.,
    [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174); Mishra, [2021](#bib.bib120);
    Zhang et al., [2021b](#bib.bib218); Jangam et al., [2022](#bib.bib76); Hira et al.,
    [2021](#bib.bib63); Sen et al., [2021](#bib.bib153); Kundu et al., [2022](#bib.bib95);
    Paul et al., [2022](#bib.bib132); Hasan et al., [2021](#bib.bib58); Aslan et al.,
    [2022](#bib.bib18); Kogilavani et al., [2022](#bib.bib90)) | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| VGG | (Khurana and Soni, [2022](#bib.bib86); Balaha et al., [2022](#bib.bib22);
    Shah et al., [2021b](#bib.bib156); Singh et al., [2021a](#bib.bib174); Ilhan et al.,
    [2022](#bib.bib72); Tan et al., [2021](#bib.bib183); Jangam et al., [2022](#bib.bib76);
    Vidyun et al., [2021](#bib.bib192); Turkoglu, [2021](#bib.bib190); Huang, [2020](#bib.bib66);
    Sen et al., [2021](#bib.bib153); Chakraborty et al., [2021](#bib.bib30); Zebin
    and Rezvy, [2021](#bib.bib212); Paul et al., [2022](#bib.bib132); Karacı, [2022](#bib.bib80);
    Kogilavani et al., [2022](#bib.bib90)) | 16 |'
  prefs: []
  type: TYPE_TB
- en: '| MobileNet | (Canayaz et al., [2022](#bib.bib29); Mahendran and Kavitha, [2022](#bib.bib109);
    Balaha et al., [2022](#bib.bib22); Mishra, [2021](#bib.bib120); Ilhan et al.,
    [2022](#bib.bib72); Abraham and Nair, [2022](#bib.bib2); Yasar and Ceylan, [2021b](#bib.bib208);
    Akbarimajd et al., [2022](#bib.bib7); Aslan et al., [2022](#bib.bib18); Kogilavani
    et al., [2022](#bib.bib90); Baghdadi et al., [2022](#bib.bib21); Zhang et al.,
    [2022b](#bib.bib216)) | 12 |'
  prefs: []
  type: TYPE_TB
- en: '| Inception | (Tahir et al., [2022](#bib.bib181); Balaha et al., [2022](#bib.bib22);
    Shah et al., [2021b](#bib.bib156); Ilhan et al., [2022](#bib.bib72); Jain et al.,
    [2021](#bib.bib75); Turkoglu, [2021](#bib.bib190); Hira et al., [2021](#bib.bib63);
    Sen et al., [2021](#bib.bib153); Kundu et al., [2022](#bib.bib95); Paul et al.,
    [2022](#bib.bib132); Aslan et al., [2022](#bib.bib18)) | 11 |'
  prefs: []
  type: TYPE_TB
- en: '| AlexNet | (Zhang et al., [2022a](#bib.bib214); Zhou et al., [2021c](#bib.bib228);
    Ibrahim et al., [2021](#bib.bib71); Hira et al., [2021](#bib.bib63); Wang et al.,
    [2020](#bib.bib198); Yasar and Ceylan, [2021b](#bib.bib208); Chakraborty et al.,
    [2021](#bib.bib30); Aslan et al., [2022](#bib.bib18)) | 8 |'
  prefs: []
  type: TYPE_TB
- en: '| GoolgeNet | (Dev et al., [2021](#bib.bib40); Zhou et al., [2021c](#bib.bib228);
    Hira et al., [2021](#bib.bib63); Zhang et al., [2021a](#bib.bib217); Chakraborty
    et al., [2021](#bib.bib30); Akbarimajd et al., [2022](#bib.bib7); Aslan et al.,
    [2022](#bib.bib18)) | 7 |'
  prefs: []
  type: TYPE_TB
- en: '| Xception | (Balaha et al., [2022](#bib.bib22); Shorfuzzaman, [2021](#bib.bib167);
    Ilhan et al., [2022](#bib.bib72); Abraham and Nair, [2022](#bib.bib2); Jain et al.,
    [2021](#bib.bib75); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| EfficientNet | (Khurana and Soni, [2022](#bib.bib86); Balaha et al., [2022](#bib.bib22);
    Ravi et al., [2022](#bib.bib145); Abraham and Nair, [2022](#bib.bib2); Zebin and
    Rezvy, [2021](#bib.bib212); Kogilavani et al., [2022](#bib.bib90)) | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| SqueezeNet | (Tahir et al., [2022](#bib.bib181); Dev et al., [2021](#bib.bib40);
    Akbarimajd et al., [2022](#bib.bib7)) | 3 |'
  prefs: []
  type: TYPE_TB
- en: '| Darknet | (Dev et al., [2021](#bib.bib40); Abraham and Nair, [2022](#bib.bib2))
    | 2 |'
  prefs: []
  type: TYPE_TB
- en: 5.3\. Ensemble learning for COVID-19 diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Ensemble learning is a machine learning method that combines multiple learners
    to complete complex learning tasks (Dong et al., [2020](#bib.bib43); Mienye and
    Sun, [2022](#bib.bib116)). It trains multiple base learners and combines them
    to obtain improved generalization ability than the individual base learners (Mienye
    et al., [2020](#bib.bib117)). Currently, the common methods to generate base learners
    can be divided into two categories: one is to apply different types of learning
    models in the same size but different samples, which are generated from the same
    dataset (Zhang et al., [2018](#bib.bib219)). The base learners which are generated
    by this method are called heterogeneous learners. The other is to apply the same
    learning model on different training sets. The base learners which are generated
    by this method are called homogeneous learners. Besides, the combined strategy
    of base learners mainly includes simple average method, weighted average method,
    majority voting, plurality voting, and weighted voting. Figure [7](#S5.F7 "Figure
    7 ‣ 5.3\. Ensemble learning for COVID-19 diagnosis ‣ 5\. Overall Analysis of DL-based
    Methods for COVID‑19 Diagnosis ‣ Deep Learning and Medical Imaging for COVID-19
    Diagnosis: A Comprehensive Survey") illustrates a representative application of
    ensemble learning for COVID-19 diagnosis. Multiple base models learn to diagnose
    COVID-19 from the medical images and output classification results. The ensemble
    classifier receives input from base models to make the final decision.'
  prefs: []
  type: TYPE_NORMAL
- en: Chaudhary et al. (Chaudhary and Qiang, [2021](#bib.bib32)) train three base
    models (two Efficient-Net with different initial pre-trained weights and SE-ResNext),
    which can classify X-ray images into COVID-19, pneumonia, and normal cases. The
    final results are calculated by averaging the classification outcomes produced
    by the three different models individually. Their proposed method achieves excellent
    performance with an accuracy of 0.9592, a sensitivity of 0.9592, and a specificity
    of 0.9597\. It is proven that the ensemble model’s accuracy is greater than that
    of three separately trained models. Tang et al. (Tang et al., [2021a](#bib.bib184))
    propose the EDL-COVID model using deep learning and ensemble learning. It trains
    several base models to overcome the shortcomings of single model by combining
    their predicted outputs. A deep learning network generates several model snapshots
    in one training run by snapshotting. Additionally, several model snapshots are
    integrated to produce a preciser model and the final classification is made using
    the weighted average method. Their EDL-COVID model achieves 95% accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Abraham et al. (Abraham and Nair, [2022](#bib.bib2)) use five pre-trained CNNs
    (MobilenetV2, Shufflenet, Xception, Darknet53, and EfficientnetB0) to extract
    features. Then the features are combined, and the ensemble classifier kernel support
    vector machine is used to diagnose COVID-19 cases. Their proposed model achieves
    0.916 accuracy, 0.8305 kappa score, 0.91 F-score, 0.917 sensitivity, and positive
    predictive value of 0.904\. Zhou et al. (Zhou et al., [2021c](#bib.bib228)) employ
    three deep pre-trained models (AlexNet, GoogleNet, and ResNet) as base learners.
    Then the predicted outputs from three pre-trained models are input into the ensemble
    classifier EDL-COVID, and relative majority voting is used to determine the final
    outcome. Finally, by comparing the ensemble classifier with three component classifiers
    in some specific performance metrics, it is demonstrated that the ensemble model
    obtains more effective performance than three deep pre-trained models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/346c87520abc8f3c1bbc6da676214b55.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. The application of deep learning using ensemble learning method for
    COVID-19 diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4\. GAN model for COVID-19 diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the main causes for poor performance and underfitting is the insufficient
    amount of annotated COVID-19 images (Rahman et al., [2021b](#bib.bib143); Chen
    et al., [2021](#bib.bib34)). And the cost of collecting COVID-19 infected images
    is too expensive. To solve these problems, Generative Adversarial Network (GAN)
    is employed by many studies to generate fake COVID-19 infected images to tackle
    data insufficiency (Saxena and Cao, [2021](#bib.bib150); Acar et al., [2021](#bib.bib4)).
    GAN mainly consists of two systems: a generator and a discriminator, as shown
    in Figure [8](#S5.F8 "Figure 8 ‣ 5.4\. GAN model for COVID-19 diagnosis ‣ 5\.
    Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning and
    Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Generator network: Generator takes noise samples from a particular distribution
    (uniform distribution and Gaussian distribution) and generates results similar
    to the real training data. It tries to generate fake images to successfully trick
    the discriminator after training.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Discriminator network: Real data and generated data are mixed and input into
    the discriminator. The discriminator distinguishes whether a sample belongs to
    real data or generated data. If it comes from real data, then the high probability
    will appear to be output, otherwise the probability is low.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Jiang et al. (Jiang et al., [2021](#bib.bib77)) construct a public COVID-19
    CT dataset, including 1,186 CT images synthesized from a large-scale lung cancer
    CT dataset using CycleGAN. Their proposed model can learn the GGO style of COVID-19
    so that the synthetic images are closely resembled to the real distribution. Goel
    et al. (Goel et al., [2021](#bib.bib51)) employ generative adversarial network
    (GAN) to generate synthetic chest CT images during data augmentation phase. The
    Whale Optimization Algorithm (WOA) is used to optimize the hyperparameters of
    GAN. Their proposed model using GAN reaches 99.22% accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Bargshady et al. (Bargshady et al., [2022](#bib.bib24)) apply generative adversarial
    network (GAN) and semi-supervised CycleGAN (SSA-CycleGAN) to augment the training
    dataset of X-ray images. Their proposed Inception-CycleGAN model achieves 94.2%
    accuracy, and 92.2% area under cure. Serte et al. (Serte et al., [2022](#bib.bib154))
    augment the number of available CT images by using generative adversarial network
    (GAN). By comparing the traditional deep learning methods with their proposed
    method using data-efficient method (GAN), it is demonstrated that their proposed
    data-efficient model outperforms all other traditional deep learning models. The
    ResNet-18 and MobileNetV2 obtain the best performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/42fcbbf84609864f11d1853d1ee2e1b9.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8\. The typical architecture of the GAN. The generator generates synthetic
    data from a given input, the discriminator distinguishes the output of the generator
    from the real data.
  prefs: []
  type: TYPE_NORMAL
- en: In addition to its popularity in data augmentation, GAN is also employed in
    other fields based on its adversarial training characteristics. Bhattacharyya
    et al. (Bhattacharyya et al., [2022](#bib.bib27)) use C-GAN to segment the COVID-19
    chest X-ray images. The X-ray images as input are fed into the generator and the
    generator network tries to produce the mask images. The discriminator tries to
    distinguish fake image pair (Input X-ray images and generated mask images) from
    the real one. Besides, Doraiswami et al. (Doraiswami et al., [2022](#bib.bib44))
    propose an effective prediction mechanism, where local ternary pattern (LTP) is
    used for feature extraction, and prediction of COVID-19 patients is performed
    by their proposed Jaya-TSA based GAN after acquiring features. Their proposed
    method reaches the accuracy of 0.87, the sensitivity of 0.85 and the specificity
    of 0.89.
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the applications of deep learning based on GAN model and their result
    are demonstrated in Table [6](#S5.T6 "Table 6 ‣ 5.4\. GAN model for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey"). In most
    of the studies, GAN is generally employed for data augmentation before model training
    to greatly increase the training sample space, thereby significantly improve the
    performance of the model (Menon et al., [2020](#bib.bib113); Li et al., [2021a](#bib.bib99);
    Serte et al., [2022](#bib.bib154)). In reference (Menon et al., [2020](#bib.bib113)),
    the quantitative analysis shows that their proposed MTT-GAN greatly improves the
    accuracy of binary classifier and multiclass classifier. In reference (Li et al.,
    [2021a](#bib.bib99)), the original CNN models with Generative Adversarial Network
    (GAN) increase the accuracy by 2% to 3%, the recall by 2% to 4%, and the precision
    by 1% to 3%.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 6\. Deep learning methods and result evaluation for diagnosing COVID-19
    using GAN models.
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Data | Methods | Function | Acc | Sn | Sp |'
  prefs: []
  type: TYPE_TB
- en: '| Zhang et al. (Zhang et al., [2021d](#bib.bib213)) | CT | GAN, U-net | Segmentation
    | 93.2% | 69.8% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Bargshady et al. (Bargshady et al., [2022](#bib.bib24)) | X-ray | CycleGAN,
    Inception V3 | Classification | 94.2% | 95.5% | 91.4% |'
  prefs: []
  type: TYPE_TB
- en: '| Acar et al. (Acar et al., [2021](#bib.bib4)) | CT | GAN,CNN | Classification
    | 95.0% | 94.2% | 95.3% |'
  prefs: []
  type: TYPE_TB
- en: '| Goel et al. (Goel et al., [2021](#bib.bib51)) | CT | GAN, WOA, ResNet-50
    | Classification | 99.2% | 99.8% | 97.8% |'
  prefs: []
  type: TYPE_TB
- en: '| Menon et al. (Menon et al., [2020](#bib.bib113)) | X-ray | GAN, CNN, transfer
    learning | Classification | 96.3% | 100.0% | 93.2% |'
  prefs: []
  type: TYPE_TB
- en: '| Li et al. (Li et al., [2021a](#bib.bib99)) | CT | GAN, DenseNet | Classification
    | 93.0% | 96.0% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Serte et al. (Serte et al., [2022](#bib.bib154)) | CT | GAN, CNN, Transfer
    learning | Classification | 74.0% | 88.0% | 68.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Bhattacharyya et al. (Bhattacharyya et al., [2022](#bib.bib27)) | X-ray |
    C-GAN, CNN, ML | Segmentation | 96.6% | 95.0% | 97.4% |'
  prefs: []
  type: TYPE_TB
- en: 5.5\. LSTM model for COVID-19 diagnosis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Long Short-Term Memory (LSTM) is a powerful recurrent neural network, which
    is proposed to address the substantial limitation of neural networks when dealing
    with sequential data (Hasan et al., [2020](#bib.bib57)). For the issue that traditional
    RNN structure has poor performance on long sequences, the LSTM model is capable
    of greatly alleviating the gradient disappearance problem, thereby supporting
    long-term dependence in dealing with sequential data (Sherstinsky, [2020](#bib.bib160);
    Meraihi et al., [2022](#bib.bib114)). And it has been extensively utilized to
    diagnose COVID-19 and predict the prognosis of COVID-19 patients. In this section,
    we will introduce the application of LSTM model in detecting COVID-19, and some
    high quality studies using the LSTM model for COVID-19 diagnosis are listed in
    Table [7](#S6.T7 "Table 7 ‣ 6\. Quantify the Severity of COVID-19 Patients ‣ Deep
    Learning and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/22f7272f0622c327932c2581a1bc6561.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 9\. The application of deep learning using LSTM model for COVID-19 diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Patients with COVID-19 tend to have a dynamic condition. The information obtained
    from one CT image or X-ray is generally limited. Conversely, CT or X-ray sequences
    are capable of providing more medical information, assisting models or doctors
    to make a preciser diagnosis for COVID-19 patients (Xu et al., [2022](#bib.bib204)).
    Consequently, many studies apply the LSTM model and image sequences to diagnose
    COVID-19\. The typical architecture of the LSTM model for COVID-19 diagnosis is
    shown in Figure [9](#S5.F9 "Figure 9 ‣ 5.5\. LSTM model for COVID-19 diagnosis
    ‣ 5\. Overall Analysis of DL-based Methods for COVID‑19 Diagnosis ‣ Deep Learning
    and Medical Imaging for COVID-19 Diagnosis: A Comprehensive Survey") (Demir, [2021](#bib.bib39)).
    Er (Er, [2022](#bib.bib47)) proposes a hybrid approach for COVID-19 classification
    that combines long short-term memory (LSTM) with some pre-trained deep networks.
    The contrast enhancing method is firstly applied to X-ray images in preprocessing
    phase. Then the pre-trained CNNs and LSTM model are used to learn features from
    the contrast enhanced chest X-rays. Finally, COVID-19, normal (healthy), and pneumonia
    cases are classified by softmax. Their proposed model reaches 98.97% accuracy,
    98.80% precision, and 98.70% sensitivity.'
  prefs: []
  type: TYPE_NORMAL
- en: Hasan et al. (Hasan et al., [2020](#bib.bib57)) preprocess the CT images to
    reduce the effect of intensity variations. Then, histogram thresholding is used
    to segment the CT lung region. Each CT image is extracted feature using Q-Deformed
    entropy (QDE) and convolutional neural network (CNN). Then the obtained features
    are fused and fed into a long short-term memory (LSTM) classifier to identify
    COVID-19 cases. The highest accuracy for classifying the collected dataset is
    99.68%. Sheykhivand et al. (Sheykhivand et al., [2021](#bib.bib161)) propose an
    efficient deep neural network for COVID-19 automatic detection. First, the GAN
    model is used to generate sufficient train samples for augmenting data. Later,
    the pre-trained model (Inception) obtains a feature vector from the X-ray images.
    Then the feature vector is split into shorter vector sequences for the input of
    LSTM model to identify COVID-19\. Their proposed model achieves more than 90%
    accuracy for most scenarios and the accuracy of 99% for separating COVID-19 from
    healthy group.
  prefs: []
  type: TYPE_NORMAL
- en: Xu et al. (Xu et al., [2022](#bib.bib204)) develop a three dimensional algorithm
    that combines multi-instance learning with the LSTM architecture (3DMTM) to identify
    COVID-19 from community acquired pneumonia (CAP). The 3DMTM model employs a lesion
    instance generator based on a pneumonia segmentation model to generate many lesion
    instances, which are then combined with clinical information and input into LSTM
    for final classification. Their proposed model achieves 0.956 AUC, 0.862 and 0.98
    specificity under the condition of relatively large data. Demir (Demir, [2021](#bib.bib39))
    proposes a novel LSTM-based model to automatically identify COVID-19 cases using
    X-ray images. Their proposed model is trained from scratch. In particular, the
    sobel gradient and marker-controlled watershed segmentation operations are firstly
    applied to raw images. The processed images are then converted to sequence data,
    which is fed into LSTM layer to generate the feature vector. The feature vector
    is finally input into softmax layer to identify COVID-19 cases. In the experiment,
    regarding the accuracy, sensitivity, specificity, and F-score, the proposed method
    achieves excellent performance.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Quantify the Severity of COVID-19 Patients
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Early identifying COVID-19 from the patient’s CT images or X-ray images is the
    first and crucial step in COVID-19 diagnosis. After that, a large number of confirmed
    and suspected cases need to be managed properly and given appropriate treatment,
    which is an enormous challenge to medical resource distribution (Tang et al.,
    [2021b](#bib.bib185); Sheela and Arun, [2022](#bib.bib159); Vasilev et al., [2022](#bib.bib191)).
    To solve these problems, quantifying the severity of COVID-19 patients is another
    crucial component for COVID-19 diagnosis, which can help doctors have a better
    grasp of the patient’s infected condition and make the most reasonable treatment,
    thereby maximizing the rational distribution of medical resources.
  prefs: []
  type: TYPE_NORMAL
- en: Rana et al. (Rana et al., [2022](#bib.bib144)) design a severity estimation
    SSD network, which uses the images collected from the detection experiment as
    the training set. Based on the COVID-19 positive images, their proposed model
    predicts different feature classes and bounding box coordinates. Then the evaluation
    module uses the top 36 predicted classes, ignoring the background classes, to
    derive severity estimates. In the end, three classifications are created based
    on the severity of COVID-19 patients, mainly including initial type, intermediate
    type, and severe type.
  prefs: []
  type: TYPE_NORMAL
- en: Shan et al. (Shan et al., [2021](#bib.bib158)) develop a DL-based segmentation
    method using VB-Net to segment COVID-19 infection regions in CT images. Each training
    case’s automatic annotation is improved using the suggested HIMI (human involved
    model iterations). The chest CT scans are first fed into the proposed segmentation
    model. Then, quantitative metrics, e.g., infection volumes and POIs in the entire
    lung, lung lobes, and bronchopulmonary segments, are estimated to characterize
    the infection locations in the CT image.
  prefs: []
  type: TYPE_NORMAL
- en: Chamberlin et al. (Chamberlin et al., [2022](#bib.bib31)) try to evaluate a
    previously trained interpretable deep learning algorithm for the diagnosis and
    prognosis of COVID-19\. Three radiologists with cardiothoracic fellowship training
    systematically evaluate each chest radiograph and generated a severity score based
    on the region of airspace disease. And the evaluation results are compared with
    the identical score produced by artificial intelligence. It shows that the anticipated
    severity scores are compatible with professional evaluation and AI model correctly
    forecasts crucial clinical consequences.
  prefs: []
  type: TYPE_NORMAL
- en: Zhou et al. (Zhou et al., [2022](#bib.bib224)) propose a multi-modality feature
    learning and fusion model for COVID-19 patient severity prediction. The CT images
    and electronic medical record (EMR) are used for multi-modality feature extraction.
    The High-order Factorization Network (HoFN) is proposed to learn the impact of
    a set of clinical features from an electronic medical record (EMR). Finally, the
    features are concatenated as the input of fully connected layer to evaluate a
    patient’s severity. In general, according to clinical symptoms and medical image
    data, their proposed model classifies patients’ severity as mild, moderate, severe,
    or fatal.
  prefs: []
  type: TYPE_NORMAL
- en: Table 7\. Deep learning methods and result evaluation for diagnosing COVID-19
    using LSTM models.
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Data | Methods | Acc | Sn | Sp |'
  prefs: []
  type: TYPE_TB
- en: '| Naeem et al. (Naeem and Bin-Salem, [2021](#bib.bib124)) | CT and X-ray |
    CNN, LSTM | 98.9% | 99.0% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Aslan et al. (Aslan et al., [2020](#bib.bib19)) | X-ray | AlexNet, LSTM |
    98.7% | 98.8% | 99.3% |'
  prefs: []
  type: TYPE_TB
- en: '| Hamza et al. (Hamza et al., [2022](#bib.bib56)) | X-ray | Efficient Net,
    LSTM | 93.4% | 93.3% | — |'
  prefs: []
  type: TYPE_TB
- en: '| Demir (Demir, [2021](#bib.bib39)) | X-ray | LSTM | 97.6% | 100.0% | 96.0%
    |'
  prefs: []
  type: TYPE_TB
- en: '| Sheykhivand et al. (Sheykhivand et al., [2021](#bib.bib161)) | X-ray | CNNs,
    GAN, LSTM | 99.5% | 100.0% | 99.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Hasan et al. (Hasan et al., [2020](#bib.bib57)) | CT | LSTM, Q-Deformed Entropy
    | 99.7% | — | — |'
  prefs: []
  type: TYPE_TB
- en: '| Xu et al. (Xu et al., [2022](#bib.bib204)) | X-ray | LSTM, SVM | 95.3% |
    86.2% | 98.0% |'
  prefs: []
  type: TYPE_TB
- en: '| Er (Er, [2022](#bib.bib47)) | X-ray | CNN,LSTM | 99.0% | 98.7% | — |'
  prefs: []
  type: TYPE_TB
- en: 7\. Challenges and Future Work
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning technologies have been proven to have great potential in fighting
    against COVID-19 and are widely used for diagnosis and quantification. However,
    the applications of deep learning for COVID-19 diagnosis are still in their infancy
    with many shortcomings. In this section, we will detail the challenges and future
    work when applying deep learning technologies to diagnose COVID-19.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'At present, the applications of deep learning based on medical images for diagnosing
    COVID-19 mainly face eight challenges:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Accuracy in multiclass classification. Although the deep learning model based
    on medical images can identify COVID-19 from normal cases, it is still challenging
    to distinguish COVID-19 through different types of pneumonia, which is far less
    accurate than RT-PCR.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Unavailability of large-scale annotated data. The performance of most deep learning
    methods depends on large-scale annotated data. Although some studies propose their
    own datasets, the available data is still insufficient. Additionally, annotating
    data is time-consuming and requires many professional medical people.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data imbalance. Due to the rapid outbreak of the epidemic, the positive COVID-19
    samples are far smaller than the normal samples. This data imbalance will affect
    the performance of deep learning models in COVID-19 diagnosis.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Image quality. Artifacts and noise often appear in datasets or imaging methods
    or in the devices used to capture images, which may interfere with the learning
    direction of the deep models to make incorrect judgments. Therefore, more effective
    noise reduction methods and dataset cleaning technologies need to be studied.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of multi-modality based system. Most studies employ only one of medical
    images (CT or X-ray images) to diagnose COVID-19, which is insufficient in complex
    infection situations. A multi-modality based system can take the advantages of
    all modalities and meet more complex requirement of diagnosis.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lack of research on 3D images. With the development of medical imaging, 3D images
    have been used with richer medical information. However, most advanced deep learning
    models are trained on 2D images, which may ignore many important features.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The intersection of computer science and medicine fields. The applications of
    deep learning in the fight against COVID-19 require deep collaboration in computer
    science, medical imaging, bioinformatics, virology and many other related fields.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data privacy. Facing the outbreak of COVID-19, most studies require a series
    of data such as personal information, image, and clinical record of patients.
    A question worth thinking is how to effectively protect the privacy and human
    rights of patients in the fight against COVID-19 based on deep learning.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 7.2\. Future Work
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In order to make better use of medical images and deep learning to fight against
    COVID-19, future studies can study the COVID-19 diagnosis from the following different
    perspectives.
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multiclass classification. To better fight against COVID-19 and meet the complex
    infection situation, the future diagnostic model should consider the direction
    of multiclass classification. Only if the deep learning technology has a very
    high accuracy in multiclass classification, can it possibly outperform the existing
    RT-PCR.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Non-contact detection. During CXR and CT image inspection, the non-contact image
    acquisition can significantly decrease the infection risk between radiologists
    and patients in the COVID-19 pandemic.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Data fusion. Numerous annotated samples are required by deep learning models
    and different hospitals and institutions, which have different data collection
    protocols. The types and formats of collected data can be significantly different
    from each other. Hence, a very meaningful direction is to use data fusion methods
    to build a large-scale dataset.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transfer learning. Most studies employ a small-scale dataset, which is likely
    to lead to model underfitting and poor performance. Transfer learning is worth
    studying to speed up the training of models and improve the performance by transferring
    knowledge from similar domains.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Incremental learning. In almost all areas of the fight against COVID-19, the
    dataset and new studies are growing steadily. One question worth noticing is how
    to improve the ability to optimize old knowledge while absorbing new knowledge.
    Thus we suggest all the models should be implemented in an incremental way.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Multi-modality. A single-modality based prediction systems generally have limited
    predictive performance. In the future, we can consider integrating multiple image
    information, and even combine with clinical information, which will greatly improve
    the performance of model and interpretability.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization. Many problems in deep learning are optimization problems, and
    existing methods such as gradient descent tend to fall into local optimum. It
    is an interesting future direction to use global search algorithms to train the
    deep learning models for COVID-19 diagnosis.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Interpretability. Deep learning has achieved excellent performance in diagnosing
    COVID-19\. However, it is a black box, and it is difficult to understand the cause
    of certain predictions. Hence, explainable deep learning models are worth studying
    and are the key to making AI techniques truly effective.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 8\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Coronavirus disease 2019 (COVID-19) has significantly influenced healthcare
    systems and finical markets around the world since its outbreak. To interrupt
    the spreading virus, medical imaging has proven to be an important tool in early
    COVID-19 detection and severity evaluation. In this survey, we investigate the
    main scope and contribution of deep learning applications based on medical imaging
    in diagnosing COVID-19\. Although deep learning model based on medical images
    cannot replace existing RT-PCR test at current stage, it has shown great potential
    in diagnosing COVID-19 and has become an important complement to RT-PCR. Meanwhile,
    we gather available datasets for diagnosing COVID-19 and point out that appropriate
    image preprocessing techniques can improve the generalization performance of the
    model. Later, we introduce the existing deep learning applications for diagnosing
    COVID-19, including lesion segmentation, image classification and severity quantification.
    Meanwhile, some methods used to improve the performance of deep model are discussed.
    Finally, we discuss some challenges and future directions for using deep learning
    technologies and medical image processing to diagnose COVID-19\. We believe that
    with the help of deep learning and image processing technologies, and many other
    disciplines, the outbreak of COVID-19 will be better managed. We sincerely hope
    that this paper will be a good reference and will drive more new studies on deep
    learning and medical imaging to fight against COVID-19 epidemic and future outbreak
    on respiratory disease.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abraham and Nair (2022) Bejoy Abraham and Madhu S Nair. 2022. Computer-aided
    detection of COVID-19 from CT scans using an ensemble of CNNs and KSVM classifier.
    *Signal, Image and Video Processing* 16, 3 (2022), 587–594.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abraham and Khan (2019) Nabila Abraham and Naimul Mefraz Khan. 2019. A novel
    focal tversky loss function with improved attention u-net for lesion segmentation.
    In *2019 IEEE 16th international symposium on biomedical imaging (ISBI 2019)*.
    IEEE, 683–687.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acar et al. (2021) Erdi Acar, Engin Şahin, and İhsan Yılmaz. 2021. Improving
    effectiveness of different deep learning-based models for detecting COVID-19 from
    computed tomography (CT) images. *Neural Computing and Applications* 33, 24 (2021),
    17589–17609.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agrawal et al. (2022) Shrishtee Agrawal, Abhishek Singh, Abhishek Tiwari, Anushri
    Mishra, and Abhinandan Tripathi. 2022. A Systematic Survey on COVID 19 Detection
    and Diagnosis by Utilizing Deep Learning Techniques and Modalities of Radiology.
    In *Proceedings of the 2022 Fourteenth International Conference on Contemporary
    Computing*. 446–452.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ahuja et al. (2021) Sakshi Ahuja, Bijaya Ketan Panigrahi, Nilanjan Dey, Venkatesan
    Rajinikanth, and Tapan Kumar Gandhi. 2021. Deep transfer learning-based automated
    detection of COVID-19 from lung CT scan slices. *Applied Intelligence* 51, 1 (2021),
    571–585.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akbarimajd et al. (2022) Adel Akbarimajd, Nicolas Hoertel, Mohammad Arafat Hussain,
    Ali Asghar Neshat, Mahmoud Marhamati, Mahdi Bakhtoor, and Mohammad Momeny. 2022.
    Learning-to-augment incorporated noise-robust deep CNN for detection of COVID-19
    in noisy X-ray images. *Journal of Computational Science* 63 (2022), 101763 –
    101763.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Al-Antari et al. (2021) Mugahed A Al-Antari, Cam-Hao Hua, Jaehun Bang, and Sungyoung
    Lee. 2021. Fast deep learning computer-aided diagnosis of COVID-19 based on digital
    chest x-ray images. *Applied Intelligence* 51, 5 (2021), 2890–2907.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alafif et al. (2021) Tarik Alafif, Abdul Muneeim Tehame, Saleh Bajaba, Ahmed
    Barnawi, and Saad Zia. 2021. Machine and deep learning towards COVID-19 diagnosis
    and treatment: survey, challenges, and future directions. *International journal
    of environmental research and public health* 18, 3 (2021), 1117.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alirr (2022) Omar Ibrahim Alirr. 2022. Automatic deep learning system for COVID-19
    infection quantification in chest CT. *Multimedia Tools and Applications* 81,
    1 (2022), 527–541.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alyasseri et al. (2022) Zaid Abdi Alkareem Alyasseri, Mohammed Azmi Al-Betar,
    Iyad Abu Doush, Mohammed A Awadallah, Ammar Kamal Abasi, Sharif Naser Makhadmeh,
    Osama Ahmad Alomari, Karrar Hameed Abdulkareem, Afzan Adam, Robertas Damasevicius,
    et al. 2022. Review on COVID-19 diagnosis models based on machine learning and
    deep learning approaches. *Expert systems* 39, 3 (2022), e12759.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alzubaidi et al. (2021) Laith Alzubaidi, Jinglan Zhang, Amjad J Humaidi, Ayad
    Al-Dujaili, Ye Duan, Omran Al-Shamma, José Santamaría, Mohammed A Fadhel, Muthana
    Al-Amidie, and Laith Farhan. 2021. Review of deep learning: Concepts, CNN architectures,
    challenges, applications, future directions. *Journal of big Data* 8, 1 (2021),
    1–74.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amin et al. (2022) Javeria Amin, Muhammad Almas Anjum, Muhammad Sharif, Amjad
    Rehman, Tanzila Saba, and Rida Zahra. 2022. Microscopic segmentation and classification
    of COVID-19 infection with ensemble convolutional neural network. *Microscopy
    research and technique* 85, 1 (2022), 385–397.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Annavarapu et al. (2021) Chandra Sekhara Rao Annavarapu et al. 2021. Deep learning-based
    improved snapshot ensemble technique for COVID-19 chest X-ray classification.
    *Applied Intelligence* 51, 5 (2021), 3104–3120.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Anwar et al. (2018) Syed Muhammad Anwar, Muhammad Majid, Adnan Qayyum, Muhammad
    Awais, Majdi Alnowami, and Muhammad Khurram Khan. 2018. Medical image analysis
    using convolutional neural networks: a review. *Journal of medical systems* 42,
    11 (2018), 1–13.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Apostolopoulos et al. (2020) Ioannis D. Apostolopoulos, Sokratis Aznaouridis,
    and Mpesiana Tzani. 2020. Extracting Possibly Representative COVID-19 Biomarkers
    from X-ray Images with Deep Learning Approach and Image Data Related to Pulmonary
    Diseases. *Journal of Medical and Biological Engineering* 40 (2020), 462 – 469.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Apostolopoulos and Bessiana (2020) Ioannis D. Apostolopoulos and Tzani Bessiana.
    2020. Covid-19: automatic detection from X-ray images utilizing transfer learning
    with convolutional neural networks. *Physical and Engineering Sciences in Medicine*
    43 (2020), 635 – 640.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aslan et al. (2022) Muhammet Fatih Aslan, Kadir Sabanci, Akif Durdu, and Muhammed Fahri
    Unlersen. 2022. COVID-19 diagnosis using state-of-the-art CNN architecture features
    and Bayesian Optimization. *Computers in Biology and Medicine* 142 (2022), 105244
    – 105244.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aslan et al. (2020) Muhammet Fatih Aslan, Muhammed Fahri Unlersen, Kadir Sabanci,
    and Akif Durdu. 2020. CNN-based transfer learning–BiLSTM network: A novel approach
    for COVID-19 infection detection. *Applied Soft Computing* 98 (2020), 106912 –
    106912.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avetisian et al. (2021) Manvel Avetisian, Ilya Burenko, Konstantin Egorov,
    Vladimir Kokh, Aleksandr Nesterov, Aleksandr Nikolaev, Alexander Ponomarchuk,
    Elena Sokolova, Alex Tuzhilin, and Dmitry Umerenkov. 2021. CoRSAI: A system for
    robust interpretation of CT scans of COVID-19 patients using deep learning. *ACM
    Transactions on Management Information Systems (TMIS)* 12, 4 (2021), 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baghdadi et al. (2022) Nadiah A Baghdadi, Amer Malki, Sally F. Abdelaliem, Hossam Magdy
    Balaha, Mahmoud Mohammed Badawy, and Mostafa A. Elhosseini. 2022. An automated
    diagnosis and classification of COVID-19 from chest CT images using a transfer
    learning-based convolutional neural network. *Computers in Biology and Medicine*
    144 (2022), 105383 – 105383.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balaha et al. (2022) Hossam Magdy Balaha, Eman M El-Gendy, and Mahmoud M Saafan.
    2022. A complete framework for accurate recognition and prognosis of COVID-19
    patients based on deep transfer learning and feature classification approach.
    *Artificial Intelligence Review* (2022), 1–46.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bao et al. (2020) Cuiping Bao, Xuehuan Liu, Han Zhang, Yiming Li, and Jun Liu.
    2020. Coronavirus disease 2019 (COVID-19) CT findings: a systematic review and
    meta-analysis. *Journal of the American college of radiology* 17, 6 (2020), 701–709.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bargshady et al. (2022) Ghazal Bargshady, Xujuan Zhou, Prabal Datta Barua, Raj
    Gururajan, Yuefeng Li, and U Rajendra Acharya. 2022. Application of CycleGAN and
    transfer learning techniques for automated detection of COVID-19 using X-ray images.
    *Pattern Recognition Letters* 153 (2022), 67–74.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basu et al. (2020) Sanhita Basu, Sushmita Mitra, and Nilanjan Saha. 2020. Deep
    Learning for Screening COVID-19 using Chest X-Ray Images. *2020 IEEE Symposium
    Series on Computational Intelligence (SSCI)* (2020), 2521–2527.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhattacharya et al. (2021) Sweta Bhattacharya, Praveen Kumar Reddy Maddikunta,
    Quoc-Viet Pham, Thippa Reddy Gadekallu, Chiranji Lal Chowdhary, Mamoun Alazab,
    Md Jalil Piran, et al. 2021. Deep learning and medical image processing for coronavirus
    (COVID-19) pandemic: A survey. *Sustainable cities and society* 65 (2021), 102589.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bhattacharyya et al. (2022) Abhijit Bhattacharyya, Divyanshu Bhaik, Sunil Kumar,
    Prayas Thakur, Rahul Sharma, and Ram Bilas Pachori. 2022. A deep learning based
    approach for automatic detection of COVID-19 cases using chest X-ray images. *Biomedical
    Signal Processing and Control* 71 (2022), 103182.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brunese et al. (2020) Luca Brunese, Francesco Mercaldo, Alfonso Reginelli, and
    Antonella Santone. 2020. Explainable Deep Learning for Pulmonary Disease and Coronavirus
    COVID-19 Detection from X-rays. *Computer Methods and Programs in Biomedicine*
    196 (2020), 105608 – 105608.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Canayaz et al. (2022) Murat Canayaz, Sanem Şehribanoğlu, Recep Özdağ, and Murat
    Demir. 2022. COVID-19 diagnosis on CT images with Bayes optimization-based deep
    neural networks and machine learning algorithms. *Neural Computing and Applications*
    34, 7 (2022), 5349–5365.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chakraborty et al. (2021) Mainak Chakraborty, Sunita Vikrant Dhavale, and Jitendra
    Ingole. 2021. Corona-Nidaan: lightweight deep convolutional neural network for
    chest X-Ray based COVID-19 infection detection. *Applied Intelligence* 51, 5 (2021),
    3026–3043.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chamberlin et al. (2022) Jordan H Chamberlin, Gilberto Aquino, Sophia Nance,
    Andrew Wortham, Nathan Leaphart, Namrata Paladugu, Sean Brady, Henry Baird, Matthew
    Fiegel, Logan Fitzpatrick, et al. 2022. Automated diagnosis and prognosis of COVID-19
    pneumonia from initial ER chest X-rays using deep learning. *BMC Infectious Diseases*
    22, 1 (2022), 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaudhary and Qiang (2021) Suman Chaudhary and Yan Qiang. 2021. Ensemble deep
    learning method for Covid-19 detection via chest X-rays. In *2021 Ethics and Explainability
    for Responsible Data Science (EE-RDS)*. IEEE, 1–3.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2022) Han Chen, Yifan Jiang, Murray Loew, and Hanseok Ko. 2022.
    Unsupervised domain adaptation based COVID-19 CT infection segmentation network.
    *Applied Intelligence (Dordrecht, Netherlands)* 52 (2022), 6340 – 6353.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021) Jianguo Chen, Kenli Li, Zhaolei Zhang, Keqin Li, and Philip S
    Yu. 2021. A survey on applications of artificial intelligence in fighting against
    COVID-19. *ACM Computing Surveys (CSUR)* 54, 8 (2021), 1–32.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choudhary et al. (2022) Tejalal Choudhary, Shubham Gujar, Anurag Goswami, Vipul
    Mishra, and Tapas Badal. 2022. Deep learning-based important weights-only transfer
    learning approach for COVID-19 CT-scan classification. *Applied Intelligence*
    (2022), 1–15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cohen et al. (2020) Joseph Paul Cohen, Paul Morrison, and Lan Dao. 2020. COVID-19
    Image Data Collection. *ArXiv* abs/2003.11597 (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Das et al. (2022) Dolly Das, Saroj Kumar Biswas, and Sivaji Bandyopadhyay.
    2022. Perspective of AI system for COVID-19 detection using chest images: a review.
    *Multimedia Tools and Applications* (2022), 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Das et al. (2019) Sushmita Das, Ankur Deka, Yuji Iwahori, Manas Kamal Bhuyan,
    Takashi Iwamoto, and Jun Ueda. 2019. Contour-Aware Residual W-Net for Nuclei Segmentation.
    In *International Conference on Knowledge-Based Intelligent Information & Engineering
    Systems*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Demir (2021) Fatih Demir. 2021. DeepCoroNet: A deep LSTM approach for automated
    detection of COVID-19 cases from chest X-ray images. *Applied Soft Computing*
    103 (2021), 107160.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dev et al. (2021) Kapal Dev, Sunder Ali Khowaja, Ankur Singh Bist, Vaibhav Saini,
    and Surbhi Bhatia. 2021. Triage of potential COVID-19 patients from chest X-ray
    images using hierarchical convolutional networks. *Neural Computing and Applications*
    (2021), 1–16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhaka et al. (2021) Vijaypal Singh Dhaka, Geeta Rani, Meet Ganpatlal Oza, Tarushi
    Sharma, and Ankit Misra. 2021. A deep learning model for mass screening of COVID-19.
    *International journal of imaging systems and technology* 31, 2 (2021), 483–498.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Diniz et al. (2021) João OB Diniz, Darlan BP Quintanilha, Antonino C Santos Neto,
    Giovanni LF da Silva, Jonnison L Ferreira, Stelmo Netto, José DL Araújo, Luana B
    Da Cruz, Thamila FB Silva, Caio M da S Martins, et al. 2021. Segmentation and
    quantification of COVID-19 infections in CT using pulmonary vessels extraction
    and deep learning. *Multimedia Tools and Applications* 80, 19 (2021), 29367–29399.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2020) Xibin Dong, Zhiwen Yu, Wenming Cao, Yifan Shi, and Qianli
    Ma. 2020. A survey on ensemble learning. *Frontiers of Computer Science* 14, 2
    (2020), 241–258.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Doraiswami et al. (2022) Palanivel Rajan Doraiswami, Velliangiri Sarveshwaran,
    Iwin Thanakumar Joseph Swamidason, and Sona Chandra Devadass Sorna. 2022. Jaya-tunicate
    swarm algorithm based generative adversarial network for COVID-19 prediction with
    chest computed tomography images. *Concurrency and Computation: Practice and Experience*
    (2022), e7211.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elharrouss et al. (2022) Omar Elharrouss, Nandhini Subramanian, and Somaya Al-Maadeed.
    2022. An encoder–decoder-based method for segmentation of COVID-19 lung infection
    in CT images. *SN Computer Science* 3, 1 (2022), 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elpeltagy and Sallam (2021) Marwa Elpeltagy and Hany Sallam. 2021. Automatic
    prediction of COVID- 19 from chest images using modified ResNet50. *Multimedia
    tools and applications* 80, 17 (2021), 26451–26463.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Er (2022) Mehmet Bilal Er. 2022. COVID‐19 detection based on pre‐trained deep
    networks and LSTM model using X‐ray images enhanced contrast with artificial bee
    colony algorithm. *Expert Systems* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Farhat et al. (2020) Hanan Farhat, George E Sakr, and Rima Kilany. 2020. Deep
    learning applications in pulmonary medical imaging: recent updates and insights
    on COVID-19. *Machine vision and applications* 31, 6 (2020), 1–42.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Farooq and Hafeez (2020) Muhammad Shoaib Farooq and Abdul Hafeez. 2020. COVID-ResNet:
    A Deep Learning Framework for Screening of COVID19 from Radiographs. *ArXiv* abs/2003.14395
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Garain et al. (2021) Avishek Garain, Arpan Basu, Fabio Giampaolo, Juan D Velasquez,
    and Ram Sarkar. 2021. Detection of COVID-19 from CT scan images: A spiking neural
    network-based approach. *Neural Computing and Applications* 33, 19 (2021), 12591–12604.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goel et al. (2021) Tripti Goel, R Murugan, Seyedali Mirjalili, and Deba Kumar
    Chakrabartty. 2021. Automatic screening of covid-19 using an optimized generative
    adversarial network. *Cognitive computation* (2021), 1–16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guan and Liu (2021) Hao Guan and Mingxia Liu. 2021. Domain adaptation for medical
    image analysis: a survey. *IEEE Transactions on Biomedical Engineering* 69, 3
    (2021), 1173–1185.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gunraj et al. (2020) Hayden Gunraj, Linda Wang, and Alexander Wong. 2020. COVIDNet-CT:
    A Tailored Deep Convolutional Neural Network Design for Detection of COVID-19
    Cases From Chest CT Images. *Frontiers in Medicine* 7 (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Habib et al. (2022) Mohammed Habib, Muhammad Ramzan, and Sajid Ali Khan. 2022.
    A Deep Learning and Handcrafted Based Computationally Intelligent Technique for
    Effective COVID-19 Detection from X-ray/CT-scan Imaging. *Journal of Grid Computing*
    20, 3 (2022), 1–20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hall et al. (2020) Lawrence O. Hall, Rahul Paul, Dmitry B. Goldgof, and Gregory M.
    Goldgof. 2020. Finding Covid-19 from Chest X-rays using Deep Learning on a Small
    Dataset. *ArXiv* abs/2004.02060 (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hamza et al. (2022) Ameer Hamza, Muhammad Attique Khan, Shuihua Wang, Abdullah
    Alqahtani, Shtwai Alsubai, Adel Binbusayyis, Hany S. Hussein, Thomas Martinetz,
    and Hammam A. Alshazly. 2022. COVID-19 classification using chest X-ray images:
    A framework of CNN-LSTM and improved max value moth flame optimization. *Frontiers
    in Public Health* 10 (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hasan et al. (2020) Ali M Hasan, Mohammed M Al-Jawad, Hamid A Jalab, Hadil Shaiba,
    Rabha W Ibrahim, and Ala’a R AL-Shamasneh. 2020. Classification of Covid-19 coronavirus,
    pneumonia and healthy lungs in CT scans using Q-deformed entropy and deep learning
    features. *Entropy* 22, 5 (2020), 517.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hasan et al. (2021) Najmul Hasan, Yukun Bao, Ashadullah Shawon, and Yanmei Huang.
    2021. DenseNet convolutional neural networks application for predicting COVID-19
    using CT image. *SN computer science* 2, 5 (2021), 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) Jian-Long He, Lin Luo, Zhen-Dong Luo, Jian-Xun Lyu, Ming-Yen
    Ng, Xin-Ping Shen, and Zhibo Wen. 2020. Diagnostic performance between CT and
    initial real-time RT-PCR for clinically suspected 2019 coronavirus disease (COVID-19)
    patients outside Wuhan, China. *Respiratory medicine* 168 (2020), 105980.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition*. 770–778.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heidari et al. (2020) Morteza Heidari, Seyedehnafiseh Mirniaharikandehei, Abolfazl Zargari
    Khuzani, Gopichandh Danala, Yuchen Qiu, Bin Zheng School of Electrical, Computer
    Engineering, University of Oklahoma, Norman Usa, Department of Electrical, University
    of California at Santa Cruz, Santa Cruz, and Usa. 2020. Improving the performance
    of CNN to predict the likelihood of COVID-19 using chest X-ray images with preprocessing
    algorithms. *International Journal of Medical Informatics* 144 (2020), 104284
    – 104284.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heidarian et al. (2021) Shahin Heidarian, Parnian Afshar, Nastaran Enshaei,
    Farnoosh Naderkhani, Moezedin Javad Rafiee, Faranak Babaki Fard, Kaveh Samimi,
    S Farokh Atashzar, Anastasia Oikonomou, Konstantinos N Plataniotis, et al. 2021.
    Covid-fact: A fully-automated capsule network-based framework for identification
    of covid-19 cases from chest ct scans. *Frontiers in Artificial Intelligence*
    4 (2021), 598932.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hira et al. (2021) Swati Hira, Anita Bai, and Sanchit Hira. 2021. An automatic
    approach based on CNN architecture to detect Covid-19 disease from chest X-ray
    images. *Applied Intelligence* 51, 5 (2021), 2864–2889.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hryniewska et al. (2021) Weronika Hryniewska, Przemyslaw Bombinski, Patryk Szatkowski,
    Paulina Tomaszewska, Artur Przelaskowski, and Przemysław Biecek. 2021. Checklist
    for responsible deep learning modeling of medical images based on COVID-19 detection
    studies. *Pattern Recognition* 118 (2021), 108035 – 108035.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2017) Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. 2017. Densely connected convolutional networks. In *Proceedings of
    the IEEE conference on computer vision and pattern recognition*. 4700–4708.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang (2020) Huishi Huang. 2020. COVID-19 CT Image Recognition Based on Multi-stage
    Transfer Learning. In *Proceedings of the 2020 International Conference on Aviation
    Safety and Information Technology*. 682–688.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2021b) Ling Huang, Su Ruan, and Thierry Denoeux. 2021b. Covid-19
    classification with deep neural network and belief functions. In *The Fifth International
    Conference on Biological Information and Biomedical Engineering*. 1–4.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2021a) Zhenxing Huang, Xinfeng Liu, Rongpin Wang, Mudan Zhang,
    Xianchun Zeng, Jun Liu, Yongfeng Yang, Xin Liu, Hairong Zheng, Dong Liang, et al.
    2021a. FaNet: fast assessment network for the novel coronavirus (COVID-19) pneumonia
    based on 3D CT imaging and clinical symptoms. *Applied Intelligence* 51, 5 (2021),
    2838–2849.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huggett et al. (2005) J Huggett, K Dheda, S Bustin, and A Zumla. 2005. Real-time
    RT-PCR normalisation; strategies and considerations. *Genes & Immunity* 6, 4 (2005),
    279–284.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iandola et al. (2016) Forrest N Iandola, Song Han, Matthew W Moskewicz, Khalid
    Ashraf, William J Dally, and Kurt Keutzer. 2016. SqueezeNet: AlexNet-level accuracy
    with 50x fewer parameters and¡ 0.5 MB model size. *arXiv preprint arXiv:1602.07360*
    (2016).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ibrahim et al. (2021) Abdullahi Umar Ibrahim, Mehmet Ozsoz, Sertan Serte, Fadi
    Al-Turjman, and Polycarp Shizawaliyi Yakoi. 2021. Pneumonia classification using
    deep learning from chest X-ray images during COVID-19. *Cognitive Computation*
    (2021), 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ilhan et al. (2022) Hamza Osman Ilhan, Gorkem Serbes, and Nizamettin Aydin.
    2022. Decision and feature level fusion of deep features extracted from public
    COVID-19 data-sets. *Applied Intelligence* 52, 8 (2022), 8551–8571.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jacobi et al. (2020) Adam Jacobi, Michael Chung, Adam Bernheim, and Corey Eber.
    2020. Portable chest X-ray in coronavirus disease-19 (COVID-19): A pictorial review.
    *Clinical imaging* 64 (2020), 35–42.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jadhav et al. (2021) Shreeraj Jadhav, Gaofeng Deng, Marlene Zawin, and Arie E
    Kaufman. 2021. COVID-view: Diagnosis of COVID-19 using Chest CT. *IEEE transactions
    on visualization and computer graphics* 28, 1 (2021), 227–237.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jain et al. (2021) Rachna Jain, Meenu Gupta, Soham Taneja, and D Jude Hemanth.
    2021. Deep learning based detection and analysis of COVID-19 on chest X-ray images.
    *Applied Intelligence* 51, 3 (2021), 1690–1700.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jangam et al. (2022) Ebenezer Jangam, Aaron Antonio Dias Barreto, and Chandra
    Sekhara Rao Annavarapu. 2022. Automatic detection of COVID-19 from chest CT scan
    and chest X-Rays images using deep learning, transfer learning and stacking. *Applied
    Intelligence* 52, 2 (2022), 2243–2259.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2021) Hao Jiang, Shiming Tang, Weihuang Liu, and Yang Zhang.
    2021. Deep learning for COVID-19 chest CT (computed tomography) image analysis:
    A lesson from lung cancer. *Computational and Structural Biotechnology Journal*
    19 (2021), 1391–1399.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Joshi et al. (2022) Amogh Manoj Joshi, Deepak Ranjan Nayak, Dibyasundar Das,
    and Yu-Dong Zhang. 2022. LiMS-Net: A Lightweight Multi-Scale CNN for COVID-19
    Detection from Chest CT Scans. *ACM Transactions on Management Information Systems
    (TMIS)* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kannan et al. (2020) SPAS Kannan, P Shaik Syed Ali, A Sheeza, and K Hemalatha.
    2020. COVID-19 (Novel Coronavirus 2019)-recent trends. *Eur Rev Med Pharmacol
    Sci* 24, 4 (2020), 2006–2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Karacı (2022) Abdulkadir Karacı. 2022. VGGCOV19-NET: automatic detection of
    COVID-19 cases from X-ray images using modified VGG19 CNN architecture and YOLO
    algorithm. *Neural Computing and Applications* 34, 10 (2022), 8253–8274.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kashala Kabe et al. (2021) Gedeon Kashala Kabe, Yuqing Song, and Zhe Liu. 2021.
    Novel Distant Domain Transfer Learning Method for COVID-19 Classification from
    X-rays Images. In *2021 The 5th International Conference on Algorithms, Computing
    and Systems*. 127–134.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keles et al. (2021) Ayturk Keles, Mustafa Berk Keles, and Ali Keles. 2021.
    COV19-CNNet and COV19-ResNet: diagnostic inference Engines for early detection
    of COVID-19. *Cognitive Computation* (2021), 1–11.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ker et al. (2017) Justin Ker, Lipo Wang, Jai Rao, and Tchoyoson Lim. 2017. Deep
    learning applications in medical image analysis. *Ieee Access* 6 (2017), 9375–9389.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2022) Azrin Khan, Rachael Garner, Marianna La Rocca, Sana Salehi,
    and Dominique Duncan. 2022. A Novel Threshold-Based Segmentation Method for Quantification
    of COVID-19 Lung Abnormalities. *Signal, Image and Video Processing* (2022), 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2021) Saddam Hussain Khan, Anabia Sohail, Asifullah Khan, Mehdi
    Hassan, Yeon Soo Lee, Jamshed Alam, Abdul Basit, and Saima Zubair. 2021. COVID-19
    detection in chest X-ray images using deep boosted hybrid learning. *Computers
    in Biology and Medicine* 137 (2021), 104816. [https://doi.org/10.1016/j.compbiomed.2021.104816](https://doi.org/10.1016/j.compbiomed.2021.104816)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khurana and Soni (2022) Yashika Khurana and Umang Soni. 2022. Leveraging deep
    learning for COVID-19 diagnosis through chest imaging. *Neural Computing and Applications*
    (2022), 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2021) Ga Young Kim, Jae Yong Kim, Chae Hyeon Kim, and Sung Min
    Kim. 2021. Evaluation of deep learning for COVID-19 diagnosis: impact of image
    dataset organization. *Journal of Applied Clinical Medical Physics* 22, 7 (2021),
    297–305.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2020) Hyunjoong W Kim, KM Capaccione, Gen Li, Lyndon Luk, Reginald S
    Widemon, Ozair Rahman, Volkan Beylergil, Ryan Mitchell, Belinda M D’Souza, Jay S
    Leb, et al. 2020. The role of initial chest X-ray in triaging patients with suspected
    COVID-19 during the pandemic. *Emergency radiology* 27, 6 (2020), 617–621.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kiruthika et al. (2021) S Kiruthika, V Masilamani, and Pratik Joshi. 2021. Fusion
    of image quality assessment and transfer learning for COVID19 detection using
    CT scan image. In *12th Indian Conference on Computer Vision, Graphics and Image
    Processing, ICVGIP 2021*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kogilavani et al. (2022) Shanmuga Vadivel Kogilavani, J. Prabhu, Raman Sandhiya,
    M. Sandeep Kumar, Umashankar Subramaniam, Alagar Karthick, Muhammad Muhibbullah,
    and Sharmila Banu Sheik Imam. 2022. COVID-19 Detection Based on Lung Ct Scan Using
    Deep Learning Techniques. *Computational and Mathematical Methods in Medicine*
    2022 (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krishnamoorthy et al. (2021) Sabitha Krishnamoorthy, Sudhakar Ramakrishnan,
    Lanson Brijesh Colaco, Akshay Dias, Indu K Gopi, Gautham AG Gowda, KC Aishwarya,
    Veena Ramanan, and Manju Chandran. 2021. Comparing a deep learning model’s diagnostic
    performance to that of radiologists to detect Covid-19 features on chest radiographs.
    *Indian Journal of Radiology and Imaging* 31, S 01 (2021), S53–S60.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2017) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    2017. Imagenet classification with deep convolutional neural networks. *Commun.
    ACM* 60, 6 (2017), 84–90.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuchana et al. (2021) Maheshwar Kuchana, Amritesh Srivastava, Ronald Das, Justin
    Mathew, Atul Mishra, and Kiran Khatter. 2021. AI aiding in diagnosing, tracking
    recovery of COVID-19 using deep learning on Chest CT scans. *Multimedia tools
    and applications* 80, 6 (2021), 9161–9175.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumari and Jagadesh (2022) L Kanya Kumari and B Naga Jagadesh. 2022. A Deep
    Convolutional Neural Network for COVID-19 Chest CT-Scan Image Classification.
    In *High Performance Computing and Networking*. Springer, 603–612.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kundu et al. (2022) Rohit Kundu, Pawan Kumar Singh, Massimiliano Ferrara, Ali
    Ahmadian, and Ram Sarkar. 2022. ET-NET: an ensemble of transfer learning models
    for prediction of COVID-19 infection through chest CT-scan images. *Multimedia
    Tools and Applications* 81, 1 (2022), 31–50.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kwee and Kwee (2020) Thomas C Kwee and Robert M Kwee. 2020. Chest CT in COVID-19:
    what the radiologist needs to know. *Radiographics* 40, 7 (2020), 1848.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lashchenova et al. (2021) D Lashchenova, A Gromov, Anton Konushin, and A Mesheryakova.
    2021. The Improvement of Segmentation of Lung Pathologies and Pleural Effusion
    on CT-scans of Patients with Covid-19. *Programming and Computer Software* 47,
    4 (2021), 327–333.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021b) Xue-Ying Li, Yang Zhou, Zi-Xuan Kong, Mei-Dan Hou, Ning Luo,
    Wei-Hang Sun, Nan Huang, Chao Yang, Ao-Dan Zhang, and Yu-Shi Li. 2021b. Exploration
    of CT manifestations of different clinical types of novel coronavirus pneumonia.
    *Ann Palliat Med* 10 (2021), 37–44.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021a) Zonggui Li, Junhua Zhang, Bo Li, Xiaoying Gu, and Xudong Luo.
    2021a. COVID‐19 diagnosis on CT scan images using a generative adversarial network
    and concatenated feature pyramid network with an attention mechanism. *Medical
    Physics* 48 (2021), 4334 – 4349.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lian et al. (2022) Luoyu Lian, Xin Luo, Canyu Pan, Jinlong Huang, Wen juan Hong,
    and Zhendong Xu. 2022. Lung image segmentation based on DRD U-Net and combined
    WGAN with Deep Neural Network. *Computer Methods and Programs in Biomedicine*
    226 (2022), 107097 – 107097.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2017) Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
    Piotr Dollár. 2017. Focal loss for dense object detection. In *Proceedings of
    the IEEE international conference on computer vision*. 2980–2988.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022) Tianming Liu, Eliot Siegel, and Dinggang Shen. 2022. Deep
    Learning and Medical Image Analysis for COVID-19 Diagnosis and Prediction. *Annual
    review of biomedical engineering* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2021) Xiangbin Liu, Liping Song, Shuai Liu, and Yudong Zhang. 2021.
    A Review of Deep-Learning-Based Medical Image Segmentation Methods. *Sustainability*
    (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Loew (2022) Murray H Loew. 2022. Brief history of Image Processing at SPIE Medical
    Imaging. *Journal of Medical Imaging* 9, S1 (2022), S12209.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2021) Siyuan Lu, Di Wu, Zheng Zhang, and Shui-Hua Wang. 2021. An
    explainable framework for diagnosis of COVID-19 pneumonia via transfer learning
    and discriminant correlation analysis. *ACM Transactions on Multimedia Computing,
    Communications, and Applications (TOMM)* 17, 3s (2021), 1–16.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2021) Jun Ma, Yixin Wang, Xingle An, Cheng Ge, Ziqi Yu, Jianan Chen,
    Qiongjie Zhu, Guoqiang Dong, Jian He, Zhiqiang He, et al. 2021. Toward data-efficient
    learning: A benchmark for COVID-19 CT lung and infection segmentation. *Medical
    physics* 48, 3 (2021), 1197–1210.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madaan et al. (2021) Vishu Madaan, Aditya Roy, Charu Gupta, Prateek Agrawal,
    Anand Sharma, Cristian Bologa, and Radu Prodan. 2021. XCOVNet: chest X-ray image
    classification for COVID-19 early detection using convolutional neural networks.
    *New Generation Computing* 39, 3 (2021), 583–597.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madhavan et al. (2021) Mangena Venu Madhavan, Aditya Khamparia, Deepak Gupta,
    Sagar Pande, Prayag Tiwari, and M Shamim Hossain. 2021. Res-CovNet: An internet
    of medical health things driven COVID-19 framework using transfer learning. *Neural
    Computing and Applications* (2021), 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mahendran and Kavitha (2022) N Mahendran and S Kavitha. 2022. A MobileNet-V2
    COVID-19: Multi-class Classification of the COVID-19 by Using CT/CXR Images. In
    *Advances in Electrical and Computer Technologies*. Springer, 727–738.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mak et al. (2020) Gannon CK Mak, Peter KC Cheng, Stephen SY Lau, Kitty KY Wong,
    CS Lau, Edman TK Lam, Rickjason CW Chan, and Dominic NC Tsang. 2020. Evaluation
    of rapid antigen test for detection of SARS-CoV-2 virus. *Journal of Clinical
    Virology* 129 (2020), 104500.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Makris et al. (2020) Antonios Makris, Ioannis Kontopoulos, and Konstantinos
    Tserpes. 2020. COVID-19 detection from chest X-Ray images using Deep Learning
    and Convolutional Neural Networks. In *11th hellenic conference on artificial
    intelligence*. 60–66.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mei et al. (2020) Xueyan Mei, Hao-Chih Lee, Kai-yue Diao, Mingqian Huang, Bin
    Lin, Chenyu Liu, Zongyu Xie, Yixuan Ma, Philip M Robson, Michael Chung, et al.
    2020. Artificial intelligence–enabled rapid diagnosis of patients with COVID-19.
    *Nature medicine* 26, 8 (2020), 1224–1228.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Menon et al. (2020) Sumeet Menon, Joshua Galita, David Chapman, Aryya Gangopadhyay,
    Jayalakshmi Mangalagiri, Phuong Nguyen, Yaacov Yesha, Yelena Yesha, Babak Saboury,
    and Michael Morris. 2020. Generating Realistic COVID19 X-rays with a Mean Teacher
    + Transfer Learning GAN. *ArXiv* abs/2009.12478 (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Meraihi et al. (2022) Yassine Meraihi, Asma Benmessaoud Gabis, Seyedali Mirjalili,
    Amar Ramdane-Cherif, and Fawaz E Alsaadi. 2022. Machine Learning-Based Research
    for COVID-19 Detection, Diagnosis, and Prediction: A Survey. *SN Computer Science*
    3, 4 (2022), 1–35.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miao et al. (2021) Rui Miao, Xin Dong, Sheng-Li Xie, Yong Liang, and Sio-Long
    Lo. 2021. UMLF-COVID: an unsupervised meta-learning model specifically designed
    to identify X-ray images of COVID-19 patients. *BMC medical imaging* 21, 1 (2021),
    1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mienye and Sun (2022) Ibomoiye Domor Mienye and Yanxia Sun. 2022. A Survey
    of Ensemble Learning: Concepts, Algorithms, Applications, and Prospects. *IEEE
    Access* 10 (2022), 99129–99149.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mienye et al. (2020) Ibomoiye Domor Mienye, Yanxia Sun, and Zenghui Wang. 2020.
    Improved predictive sparse decomposition method with densenet for prediction of
    lung cancer. *Int. J. Comput* 1 (2020), 533–541.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Milletari et al. (2016) Fausto Milletari, Nassir Navab, and Seyed-Ahmad Ahmadi.
    2016. V-net: Fully convolutional neural networks for volumetric medical image
    segmentation. In *2016 fourth international conference on 3D vision (3DV)*. IEEE,
    565–571.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Minaee et al. (2022) Shervin Minaee, Yuri Boykov, Fatih Murat Porikli, Antonio J.
    Plaza, Nasser Kehtarnavaz, and Demetri Terzopoulos. 2022. Image Segmentation Using
    Deep Learning: A Survey. *IEEE Transactions on Pattern Analysis and Machine Intelligence*
    44 (2022), 3523–3542.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mishra (2021) Shreyas Mishra. 2021. Deep Transfer Learning-Based Framework for
    COVID-19 Diagnosis Using Chest CT Scans and Clinical Information. *SN Computer
    Science* 2, 5 (2021), 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mishra and Kane (2022) Vidyanand Mishra and Lalit Kane. 2022. A survey of designing
    convolutional neural network using evolutionary algorithms. *Artificial Intelligence
    Review* (2022), 1–38.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Morid et al. (2021) Mohammad Amin Morid, Alireza Borjali, and Guilherme Del Fiol.
    2021. A scoping review of transfer learning research on medical image analysis
    using ImageNet. *Computers in biology and medicine* 128 (2021), 104115.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mukherjee et al. (2021) Himadri Mukherjee, Subhankar Ghosh, Ankita Dhar, Sk Md
    Obaidullah, KC Santosh, and Kaushik Roy. 2021. Deep neural network to detect COVID-19:
    one architecture for both CT Scans and Chest X-rays. *Applied Intelligence* 51,
    5 (2021), 2777–2789.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naeem and Bin-Salem (2021) Hamad Naeem and Ali Abdulqader Bin-Salem. 2021. A
    CNN-LSTM network with multi-level feature extraction-based approach for automated
    detection of coronavirus from CT scan and X-ray images. *Applied Soft Computing*
    113 (2021), 107918.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nagarajan et al. (2021) Bhagyam Nagarajan, Gayatri Autkar, Aarav Monga, and
    Nikhil Toshniwal. 2021. Lung Manifestations of COVID-19 on Chest Radiographs—Indian
    Experience in a High-Volume Dedicated COVID center. *SN Comprehensive Clinical
    Medicine* 3, 1 (2021), 16–21.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Naudé (2020) Wim Naudé. 2020. Artificial intelligence vs COVID-19: limitations,
    constraints and pitfalls. *AI & society* 35, 3 (2020), 761–765.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nicola et al. (2020) Maria Nicola, Zaid Alsafi, Catrin Sohrabi, Ahmed Kerwan,
    Ahmed Al-Jabir, Christos Iosifidis, Maliha Agha, and Riaz Agha. 2020. The socio-economic
    implications of the coronavirus pandemic (COVID-19): A review. *International
    journal of surgery* 78 (2020), 185–193.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nivetha and Inbarani (2022) S Nivetha and H Hannah Inbarani. 2022. Neighborhood
    Rough Neural Network Approach for COVID-19 Image Classification. *Neural processing
    letters* (2022), 1–23.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pak et al. (2020) Anton Pak, Oyelola A Adegboye, Adeshina I Adekunle, Kazi M
    Rahman, Emma S McBryde, and Damon P Eisen. 2020. Economic consequences of the
    COVID-19 outbreak: the need for epidemic preparedness. *Frontiers in public health*
    8 (2020), 241.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pascual et al. (2021) Elisa Aguirre Pascual, David Coca Robinot, C. Gallego
    Herrero, María Navallas Irujo, Miguel Rasero Ponferrada, and M. Pont Vilalta.
    2021. Pediatric chest X-rays during the COVID-19 pandemic. *Radiologia* (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pathak et al. (2020) Yadunath Pathak, Prashant Kumar Shukla, Akhilesh Tiwari,
    Shalini Stalin, and Saurabh Singh. 2020. Deep transfer learning based classification
    model for COVID-19 disease. *Irbm* (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paul et al. (2022) Ashis Paul, Arpan Basu, Mufti Mahmud, M Shamim Kaiser, and
    Ram Sarkar. 2022. Inverted bell-curve-based ensemble of deep learning models for
    detection of COVID-19 from chest X-rays. *Neural Computing and Applications* (2022),
    1–15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2022) Yong Peng, Enbin Liu, Shanbi Peng, Qikun Chen, Dangjian
    Li, and Dianpeng Lian. 2022. Using artificial intelligence technology to fight
    COVID-19: a review. *Artificial Intelligence Review* (2022), 1–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pihur et al. (2007) Vasyl Pihur, Susmita Datta, and Somnath Datta. 2007. Weighted
    rank aggregation of cluster validation measures: a monte carlo cross-entropy approach.
    *Bioinformatics* 23, 13 (2007), 1607–1615.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Polat et al. (2021) Hasan Polat, Mehmet Siraç Özerdem, Faysal Ekici, and Veysi
    Akpolat. 2021. Automatic detection and localization of COVID-19 pneumonia using
    axial computed tomography images and deep convolutional neural networks. *International
    Journal of Imaging Systems and Technology* 31, 2 (2021), 509–524.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pouyanfar et al. (2018) Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian,
    Yudong Tao, Maria Presa Reyes, Mei-Ling Shyu, Shu-Ching Chen, and S. S. Iyengar.
    2018. A Survey on Deep Learning: Algorithms, Techniques, and Applications. *ACM
    Comput. Surv.* 51, 5, Article 92 (sep 2018), 36 pages. [https://doi.org/10.1145/3234150](https://doi.org/10.1145/3234150)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pu et al. (2022) Ruiyang Pu, Sha Liu, Xiaoyu Ren, Dian Shi, Yupei Ba, Yanbei
    Huo, Wenling Zhang, Lingling Ma, Yanyan Liu, Yan Yang, et al. 2022. The screening
    value of RT-LAMP and RT-PCR in the diagnosis of COVID-19: Systematic review and
    meta-analysis. *Journal of virological methods* 300 (2022), 114392.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Punn and Agarwal (2022) Narinder Singh Punn and Sonali Agarwal. 2022. Chs-net:
    A deep learning approach for hierarchical segmentation of covid-19 via ct images.
    *Neural Processing Letters* (2022), 1–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2020) Chuan Qin, MD PhD Luoqi Zhou MD Ziwei, Sheng Yang MD Yu Tao,
    PhD Cuihong Xie MD PhD Ke, and Ma MD PhD Ke Shang. 2020. Dysregulation of immune
    response in patients with COVID-19 in Wuhan, China; Clinical Infectious Diseases;
    Oxford Academic. *Clinical Infectious Diseases* (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: R et al. (2022) Sakthivel R, I. Sumaiya Thaseen, Vanitha M, Deepa M, Angulakshmi
    M, Mangayarkarasi R, Anand Mahendran, Waleed Alnumay, and Puspita Chatterjee.
    2022. An efficient hardware architecture based on an ensemble of deep learning
    models for COVID -19 prediction. *Sustainable Cities and Society* 80 (2022), 103713.
    [https://doi.org/10.1016/j.scs.2022.103713](https://doi.org/10.1016/j.scs.2022.103713)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rabaan et al. (2021) Ali A Rabaan, Raghavendra Tirupathi, Anupam A Sule, Jehad
    Aldali, Abbas Al Mutair, Saad Alhumaid, Nitin Gupta, Thoyaja Koritala, Ramesh
    Adhikari, Muhammad Bilal, et al. 2021. Viral dynamics and real-time RT-PCR Ct
    values correlation with disease severity in COVID-19. *Diagnostics* 11, 6 (2021),
    1091.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rahman et al. (2021a) Md Rahman, Ahashan Habib Niloy, Shammi Akhter Shiba,
    SM Fahim, Faizun Nahar Faria, Emtiaz Hussain, Mohammad Zavid Parvez, et al. 2021a.
    CoroPy: A Deep Learning Based Comparison Between X-Ray and CT Scan Images in Covid-19
    Detection and Classification. In *International Conference on Bioengineering and
    Biomedical Signal and Image Processing*. Springer, 392–404.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rahman et al. (2021b) Sejuti Rahman, Sujan Sarker, Md Abdullah Al Miraj, Ragib Amin
    Nihal, AKM Nadimul Haque, and Abdullah Al Noman. 2021b. Deep learning–driven automated
    detection of Covid-19 from radiography images: A comparative analysis. *Cognitive
    Computation* (2021), 1–30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rana et al. (2022) Ashish Rana, Harpreet Singh, Ravimohan Mavuduru, Smita Pattanaik,
    and Prashant Singh Rana. 2022. Quantifying prognosis severity of COVID-19 patients
    from deep learning based analysis of CT chest images. *Multimedia Tools and Applications*
    81, 13 (2022), 18129–18153.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravi et al. (2022) Vinayakumar Ravi, Harini Narasimhan, Chinmay Chakraborty,
    and Tuan D Pham. 2022. Deep learning-based meta-classifier approach for COVID-19
    classification using CT scan and chest X-ray images. *Multimedia systems* 28,
    4 (2022), 1401–1415.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronneberger et al. (2015) Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
    2015. U-Net: Convolutional Networks for Biomedical Image Segmentation. *ArXiv*
    abs/1505.04597 (2015).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salehi et al. (2017) Seyed Sadegh Mohseni Salehi, Deniz Erdogmus, and Ali Gholipour.
    2017. Tversky loss function for image segmentation using 3D fully convolutional
    deep networks. In *International workshop on machine learning in medical imaging*.
    Springer, 379–387.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saood (2021) Adnan Saood. 2021. COVID-19 lung CT image segmentation using deep
    learning methods: U-Net versus SegNet. *BMC Medical Imaging* 21 (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarv Ahrabi et al. (2022) Sima Sarv Ahrabi, Lorenzo Piazzo, Alireza Momenzadeh,
    Michele Scarpiniti, and Enzo Baccarelli. 2022. Exploiting probability density
    function of deep convolutional autoencoders’ latent space for reliable COVID-19
    detection on CT scans. *The Journal of Supercomputing* 78, 9 (2022), 12024–12045.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saxena and Cao (2021) Divya Saxena and Jiannong Cao. 2021. Generative adversarial
    networks (GANs) challenges, solutions, and future directions. *ACM Computing Surveys
    (CSUR)* 54, 3 (2021), 1–42.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schlemper et al. (2019) Jo Schlemper, Ozan Oktay, Michiel Schaap, Mattias P.
    Heinrich, Bernhard Kainz, Ben Glocker, and Daniel Rueckert. 2019. Attention Gated
    Networks: Learning to Leverage Salient Regions in Medical Images. *Medical image
    analysis* 53 (2019), 197 – 207.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sedik et al. (2022) Ahmed Sedik, Mohamed Hammad, Abd El-Samie, E Fathi, Brij B
    Gupta, Abd El-Latif, and A Ahmed. 2022. Efficient deep learning approach for augmented
    detection of Coronavirus disease. *Neural Computing and Applications* 34, 14 (2022),
    11423–11440.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sen et al. (2021) Shibaprasad Sen, Soumyajit Saha, Somnath Chatterjee, Seyedali
    Mirjalili, and Ram Sarkar. 2021. A bi-stage feature selection approach for COVID-19
    prediction using chest CT images. *Applied Intelligence* 51, 12 (2021), 8985–9000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serte et al. (2022) Sertan Serte, Mehmet Alp Dirik, and Fadi Al-Turjman. 2022.
    Deep Learning Models for COVID-19 Detection. *Sustainability* 14, 10 (2022). [https://doi.org/10.3390/su14105820](https://doi.org/10.3390/su14105820)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shah et al. (2021a) Faisal Muhammad Shah, Sajib Kumar Saha Joy, Farzad Ahmed,
    Tonmoy Hossain, Mayeesha Humaira, Amit Saha Ami, Shimul Paul, Md Abidur Rahman Khan
    Jim, and Sifat Ahmed. 2021a. A comprehensive survey of COVID-19 detection using
    medical images. *SN Computer Science* 2, 6 (2021), 1–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shah et al. (2021b) Vruddhi Shah, Rinkal Keniya, Akanksha Shridharani, Manav
    Punjabi, Jainam Shah, and Ninad Mehendale. 2021b. Diagnosis of COVID-19 using
    CT scan images and deep learning techniques. *Emergency radiology* 28, 3 (2021),
    497–505.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shamsi et al. (2021) Afshar Shamsi, Hamzeh Asgharnezhad, Shirin Shamsi Jokandan,
    Abbas Khosravi, Parham Mohsenzadeh Kebria, Darius Nahavandi, Saeid Nahavandi,
    and Dipti Srinivasan. 2021. An Uncertainty-Aware Transfer Learning-Based Framework
    for COVID-19 Diagnosis. *IEEE Transactions on Neural Networks and Learning Systems*
    32 (2021), 1408–1417.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shan et al. (2021) Fei Shan, Yaozong Gao, Jun Wang, Weiya Shi, Nannan Shi, Miaofei
    Han, Zhong Xue, Dinggang Shen, and Yuxin Shi. 2021. Abnormal lung quantification
    in chest CT images of COVID-19 patients with deep learning and its application
    to severity prediction. *Medical physics* 48, 4 (2021), 1633–1645.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sheela and Arun (2022) M. Sahaya Sheela and Chintamani Atish Arun. 2022. Hybrid
    PSO–SVM algorithm for Covid-19 screening and quantification. *International Journal
    of Information Technology* 14 (2022), 2049 – 2056.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sherstinsky (2020) Alex Sherstinsky. 2020. Fundamentals of recurrent neural
    network (RNN) and long short-term memory (LSTM) network. *Physica D: Nonlinear
    Phenomena* 404 (2020), 132306.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sheykhivand et al. (2021) Sobhan Sheykhivand, Zohreh Mousavi, Sina Mojtahedi,
    Tohid Yousefi Rezaii, Ali Farzamnia, Saeed Meshgini, and Ismail Saad. 2021. Developing
    an efficient deep neural network for automatic detection of COVID-19 using chest
    X-ray images. *Alexandria Engineering Journal* 60, 3 (2021), 2885–2903.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2020) Feng Shi, Jun Wang, Jun Shi, Ziyan Wu, Qian Wang, Zhenyu Tang,
    Kelei He, Yinghuan Shi, and Dinggang Shen. 2020. Review of artificial intelligence
    techniques in imaging data acquisition, segmentation, and diagnosis for COVID-19.
    *IEEE reviews in biomedical engineering* 14 (2020), 4–15.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2021b) Feng Shi, Liming Xia, Fei Shan, Bin Song, Dijia Wu, Ying
    Wei, Huan Yuan, Huiting Jiang, Yichu He, Yaozong Gao, et al. 2021b. Large-scale
    screening to distinguish between COVID-19 and community-acquired pneumonia using
    infection size-aware classification. *Physics in medicine & Biology* 66, 6 (2021),
    065031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2021a) Wenqi Shi, Mitali S Gupte, and May D Wang. 2021a. Learning
    from Heterogeneous Data via Contrastive Learning: An Application in Multi-Source
    COVID-19 Radiography. In *2021 IEEE EMBS International Conference on Biomedical
    and Health Informatics (BHI)*. IEEE, 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shirato et al. (2020) Kazuya Shirato, Naganori Nao, Harutaka Katano, Ikuyo Takayama,
    Shinji Saito, Fumihiro Kato, Hiroshi Katoh, Masafumi Sakata, Yuichiro Nakatsu,
    Yoshio Mori, et al. 2020. Development of genetic diagnostic methods for novel
    coronavirus 2019 (nCoV-2019) in Japan. *Japanese journal of infectious diseases*
    (2020), JJID–2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shiri et al. (2022) Isaac Shiri, Hossein Arabi, Yazdan Salimi, Amirhossein
    Sanaat, Azadeh Akhavanallaf, Ghasem Hajianfar, Dariush Askari, Shakiba Moradi,
    Zahra Mansouri, Masoumeh Pakbin, et al. 2022. COLI-Net: Deep learning-assisted
    fully automated COVID-19 lung and infection pneumonia lesion detection and segmentation
    from chest computed tomography images. *International journal of imaging systems
    and technology* 32, 1 (2022), 12–25.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shorfuzzaman (2021) Mohammad Shorfuzzaman. 2021. IoT-enabled stacked ensemble
    of deep neural networks for the diagnosis of COVID-19 using chest CT scans. *Computing*
    (2021), 1–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shorten et al. (2021) Connor Shorten, Taghi M Khoshgoftaar, and Borko Furht.
    2021. Deep Learning applications for COVID-19. *Journal of big Data* 8, 1 (2021),
    1–54.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuja et al. (2021) Junaid Shuja, Eisa A. Alanazi, Waleed S. Alasmary, and
    Abdulaziz S. Alashaikh. 2021. COVID-19 open source data sets: a comprehensive
    survey. *Applied Intelligence (Dordrecht, Netherlands)* 51 (2021), 1296 – 1325.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Siddique et al. (2021) Nahian Alam Siddique, Sidike Paheding, Colin P. Elkin,
    and Vijay Kumar Devabhaktuni. 2021. U-Net and Its Variants for Medical Image Segmentation:
    A Review of Theory and Applications. *IEEE Access* 9 (2021), 82031–82057.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) Karen Simonyan and Andrew Zisserman. 2014. Very
    deep convolutional networks for large-scale image recognition. *arXiv preprint
    arXiv:1409.1556* (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singanayagam et al. (2020) Anika Singanayagam, Monika Patel, André Charlett,
    Jamie Lopez Bernal, Vanessa Saliba, Joanna Ellis, Shamez N. Ladhani, Maria Zambon,
    and Robin Gopal. 2020. Duration of infectiousness and correlation with RT-PCR
    cycle threshold values in cases of COVID-19, England, January to May 2020. *Eurosurveillance*
    25 (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021b) Asu Kumar Singh, Anupam Kumar, Mufti Mahmud, M Shamim Kaiser,
    and Akshat Kishore. 2021b. COVID-19 infection detection from chest X-ray images
    using hybrid social group optimization and support vector classifier. *Cognitive
    Computation* (2021), 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021a) Dilbag Singh, Vijay Kumar, and Manjit Kaur. 2021a. Densely
    connected convolutional networks-based COVID-19 screening model. *Applied Intelligence*
    51, 5 (2021), 3044–3051.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Soares et al. (2020) Eduardo A. Soares, Plamen P. Angelov, Sarah Biaso, Michele Higa
    Froes, and Daniel Kanda Abe. 2020. SARS-CoV-2 CT-scan dataset:A large dataset
    of real patients CT scans for SARS-CoV-2 identification. *medRxiv* (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2021) Ying Song, Shuangjia Zheng, Liang Li, Xiang Zhang, Xiaodong
    Zhang, Ziwang Huang, Jianwen Chen, Ruixuan Wang, Huiying Zhao, Yutian Chong, et al.
    2021. Deep learning enables accurate diagnosis of novel coronavirus (COVID-19)
    with CT images. *IEEE/ACM transactions on computational biology and bioinformatics*
    18, 6 (2021), 2775–2780.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Soomro et al. (2021) Toufique A Soomro, Lihong Zheng, Ahmed J Afifi, Ahmed
    Ali, Ming Yin, and Junbin Gao. 2021. Artificial intelligence (AI) for medical
    imaging to combat coronavirus disease (COVID-19): a detailed review with direction
    for future research. *Artificial Intelligence Review* (2021), 1–31.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Srivastava (2022) Varad Srivastava. 2022. Diagnosing Covid-19 using AI based
    Medical Image Analysis. In *5th Joint International Conference on Data Science
    & Management of Data (9th ACM IKDD CODS and 27th COMAD)*. 204–212.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sudre et al. (2017) Carole H Sudre, Wenqi Li, Tom Vercauteren, Sebastien Ourselin,
    and M Jorge Cardoso. 2017. Generalised dice overlap as a deep learning loss function
    for highly unbalanced segmentations. In *Deep learning in medical image analysis
    and multimodal learning for clinical decision support*. Springer, 240–248.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2015) Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
    Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
    2015. Going deeper with convolutions. In *Proceedings of the IEEE conference on
    computer vision and pattern recognition*. 1–9.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tahir et al. (2022) Anas M Tahir, Yazan Qiblawey, Amith Khandakar, Tawsifur
    Rahman, Uzair Khurshid, Farayi Musharavati, MT Islam, Serkan Kiranyaz, Somaya
    Al-Maadeed, and Muhammad EH Chowdhury. 2022. Deep learning for reliable classification
    of COVID-19, MERS, and SARS from chest X-ray images. *Cognitive Computation* (2022),
    1–21.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Le (2019) Mingxing Tan and Quoc Le. 2019. Efficientnet: Rethinking
    model scaling for convolutional neural networks. In *International conference
    on machine learning*. PMLR, 6105–6114.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan et al. (2021) Wenjun Tan, Pan Liu, Xiaoshuo Li, Yao Liu, Qinghua Zhou, Chao
    Chen, Zhaoxuan Gong, Xiaoxia Yin, and Yanchun Zhang. 2021. Classification of COVID-19
    pneumonia from chest CT images based on reconstructed super-resolution images
    and VGG neural network. *Health Information Science and Systems* 9, 1 (2021),
    1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. (2021a) Shanjiang Tang, Chunjiang Wang, Jiangtian Nie, Neeraj Kumar,
    Yang Zhang, Zehui Xiong, and Ahmed Barnawi. 2021a. EDL-COVID: Ensemble deep learning
    for COVID-19 case detection from chest X-ray images. *IEEE Transactions on Industrial
    Informatics* 17, 9 (2021), 6539–6549.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2021b) Zhenyu Tang, Wei Zhao, Xingzhi Xie, Zheng Zhong, Feng Shi,
    Tianmin Ma, Jun Liu, and Dinggang Shen. 2021b. Severity assessment of COVID-19
    using CT image features and laboratory indices. *Physics in Medicine & Biology*
    66, 3 (2021), 035015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tayarani (2020) Mohammad Tayarani. 2020. Applications of artificial intelligence
    in battling against covid-19: A literature review. *Chaos, Solitons & Fractals*
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ter-Sarkisov (2022) Aram Ter-Sarkisov. 2022. Covid-ct-mask-net: Prediction
    of covid-19 from ct scans using regional features. *Applied Intelligence* (2022),
    1–12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Torales et al. (2020) Julio Torales, Marcelo O’Higgins, João Mauricio Castaldelli-Maia,
    and Antonio Ventriglio. 2020. The outbreak of COVID-19 coronavirus and its impact
    on global mental health. *International journal of social psychiatry* 66, 4 (2020),
    317–320.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trivizakis et al. (2020) Eleftherios Trivizakis, Nikos Tsiknakis, Evangelia E
    Vassalou, Georgios Z Papadakis, Demetrios A Spandidos, Dimosthenis Sarigiannis,
    Aristidis Tsatsakis, Nikolaos Papanikolaou, Apostolos H Karantanas, and Kostas
    Marias. 2020. Advancing COVID-19 differentiation with a robust preprocessing and
    integration of multi-institutional open-repository computer tomography datasets
    for deep learning analysis. *Experimental and therapeutic medicine* 20, 5 (2020),
    1–1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turkoglu (2021) Muammer Turkoglu. 2021. COVIDetectioNet: COVID-19 diagnosis
    system based on X-ray images using features selected from pre-learned deep features
    ensemble. *Applied Intelligence* 51, 3 (2021), 1213–1226.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vasilev et al. (2022) IA Vasilev, MI Petrovskiy, IV Mashechkin, and LL Pankratyeva.
    2022. Predicting COVID-19-Induced Lung Damage Based on Machine Learning Methods.
    *Programming and Computer Software* 48, 4 (2022), 243–255.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vidyun et al. (2021) AS Vidyun, B Srinivasa Rao, and J Harikiran. 2021. Automated
    Detection and Classification of COVID-19 Based on CT Images Using Deep Learning
    Model. In *Applications of Artificial Intelligence and Machine Learning*. Springer,
    419–426.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vogado et al. (2021) Luis Vogado, Pablo Vieira, Pedro Santos Neto, Lucas Lopes,
    Gleison Silva, Flávio Araújo, and Rodrigo Veras. 2021. Detection of COVID-19 in
    chest X-ray images using transfer learning with deep convolutional neural network.
    In *Proceedings of the 36th Annual ACM Symposium on Applied Computing*. 629–636.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voulodimos et al. (2021a) Athanasios Voulodimos, Eftychios Protopapadakis, Iason
    Katsamenis, Anastasios Doulamis, and Nikolaos Doulamis. 2021a. Deep learning models
    for COVID-19 infected area segmentation in CT images. In *the 14th PErvasive technologies
    related to assistive environments conference*. 404–411.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voulodimos et al. (2021b) Athanasios Voulodimos, Eftychios E. Protopapadakis,
    Iason Katsamenis, Anastasios D. Doulamis, and Nikolaos D. Doulamis. 2021b. A Few-Shot
    U-Net Deep Learning Model for COVID-19 Infected Area Segmentation in CT Images.
    *Sensors (Basel, Switzerland)* 21 (2021).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2021b) Kang Wang, Yang Zhao, Yong Dou, Dong Wen, and Zikai Gao.
    2021b. COVID Edge-Net: Automated COVID-19 Lung Lesion Edge Detection in Chest
    CT Images. In *ECML/PKDD*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021a) Shuai Wang, Bo Kang, Jinlu Ma, Xianjun Zeng, Mingming Xiao,
    Jia Guo, Meng Cai, Jingyi Yang, Yaodong Li, Xiangfei Meng, and Bo Xu. 2021a. A
    deep learning algorithm using CT images to screen for Corona virus disease (COVID-19).
    *European Radiology* 31 (2021), 6096 – 6104.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020) Xinggang Wang, Xianbo Deng, Qing Fu, Qiang Zhou, Jiapei Feng,
    Hui Ma, Wenyu Liu, and Chuansheng Zheng. 2020. A weakly-supervised framework for
    COVID-19 classification and lesion localization from chest CT. *IEEE transactions
    on medical imaging* 39, 8 (2020), 2615–2625.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weinstock et al. (2020) Michael B Weinstock, ANA Echenique, JW Russell, ARI
    Leib, J Miller, D Cohen, Stephen Waite, A Frye, and F Illuzzi. 2020. Chest x-ray
    findings in 636 ambulatory patients with COVID-19 presenting to an urgent care
    center: a normal chest x-ray is no guarantee. *J Urgent Care Med* 14, 7 (2020),
    13–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: WHO (2022) WHO. 2022. Coronavirus disease 2019 (covid-19). [https://www.worldometers.info/coronavirus/](https://www.worldometers.info/coronavirus/).
    Last accessed on 21.10.22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2020) Jianguo Wu, Jiasheng Liu, Shijun Li, Zhiyang Peng, Zhe man
    Xiao, Xufeng Wang, Ruicheng Yan, and Jianfei Luo. 2020. Detection and analysis
    of nucleic acid in various biological samples of COVID-19 patients. *Travel Medicine
    and Infectious Disease* 37 (2020), 101673 – 101673.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2022) Hanguang Xiao, Zhiqiang Ran, Shingo Mabu, Yuewei Li, and
    Li Li. 2022. SAUNet++: an automatic segmentation model of COVID-19 lesion from
    CT slices. *The Visual Computer* (2022), 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie and Tu (2015) Saining Xie and Zhuowen Tu. 2015. Holistically-nested edge
    detection. In *Proceedings of the IEEE international conference on computer vision*.
    1395–1403.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2022) Fangyi Xu, Kaihua Lou, Chao Chen, Qingqing Chen, Dawei Wang,
    Jiangfen Wu, Wenchao Zhu, Weixiong Tan, Yong Zhou, Yongjiu Liu, et al. 2022. An
    original deep learning model using limited data for COVID-19 discrimination: A
    multicenter study. *Medical Physics* (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yamaç et al. (2021) Mehmet Yamaç, Mete Ahishali, Aysen Degerli, Serkan Kiranyaz,
    Muhammad E. H. Chowdhury, and Moncef Gabbouj. 2021. Convolutional Sparse Support
    Estimator-Based COVID-19 Recognition From X-Ray Images. *IEEE Transactions on
    Neural Networks and Learning Systems* 32, 5 (2021), 1810–1820. [https://doi.org/10.1109/TNNLS.2021.3070467](https://doi.org/10.1109/TNNLS.2021.3070467)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2020) Xingyi Yang, Jinyu Zhao, Yichen Zhang, Xuehai He, and Pengtao
    Xie. 2020. COVID-CT-Dataset: A CT Scan Dataset about COVID-19. *ArXiv* abs/2003.13865
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yasar and Ceylan (2021a) Huseyin Yasar and Murat Ceylan. 2021a. Deep Learning–Based
    Approaches to Improve Classification Parameters for Diagnosing COVID-19 from CT
    Images. *Cognitive Computation* (2021), 1–28.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yasar and Ceylan (2021b) Huseyin Yasar and Murat Ceylan. 2021b. A novel comparative
    study for detection of Covid-19 on CT lung images using texture analysis, machine
    learning, and deep learning methods. *Multimedia Tools and Applications* 80, 4
    (2021), 5423–5447.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ye et al. (2020) Zheng Ye, Yun Zhang, Yi Wang, Zixiang Huang, and Bin Song.
    2020. Chest CT manifestations of new coronavirus disease 2019 (COVID-19): a pictorial
    review. *European radiology* 30, 8 (2020), 4381–4389.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yi-de et al. (2004) Ma Yi-de, Liu Qing, and Qian Zhi-Bai. 2004. Automated image
    segmentation using improved PCNN model based on cross-entropy. In *Proceedings
    of 2004 International Symposium on Intelligent Multimedia, Video and Speech Processing,
    2004.* IEEE, 743–746.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yoon et al. (2020) Soon Ho Yoon, Kyung Hee Lee, Jin Yong Kim, Young Kyung Lee,
    Hongseok Ko, Ki Hwan Kim, Chang Min Park, and Yun-Hyeon Kim. 2020. Chest radiographic
    and CT findings of the 2019 novel coronavirus disease (COVID-19): analysis of
    nine patients treated in Korea. *Korean journal of radiology* 21, 4 (2020), 494–500.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zebin and Rezvy (2021) Tahmina Zebin and Shahadate Rezvy. 2021. COVID-19 detection
    and disease progression visualization: Deep learning on chest X-rays for classification
    and coarse localization. *Applied Intelligence* 51, 2 (2021), 1010–1021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021d) Ju Zhang, Lunduan Yu, Decheng Chen, Weidong Pan, Chao Shi,
    Yan Niu, Xinwei Yao, Xiaobin Xu, and Yun Cheng. 2021d. Dense GAN and multi-layer
    attention based lesion segmentation method for COVID-19 CT images. *Biomedical
    Signal Processing and Control* 69 (2021), 102901. [https://doi.org/10.1016/j.bspc.2021.102901](https://doi.org/10.1016/j.bspc.2021.102901)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022a) Xin Zhang, Siyuan Lu, Shui-Hua Wang, Xiang Yu, Su-Jing
    Wang, Lun Yao, Yi Pan, and Yu-Dong Zhang. 2022a. Diagnosis of COVID-19 pneumonia
    via a novel deep learning architecture. *Journal of computer science and technology*
    37, 2 (2022), 330–343.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2021c) XiaoQing Zhang, GuangYu Wang, and Shu-Guang Zhao. 2021c.
    COVSeg-NET: A deep convolution neural network for COVID-19 lung CT image segmentation.
    *International Journal of Imaging Systems and Technology* 31, 3 (2021), 1071–1086.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022b) Xiaorui Zhang, Jie Zhou, Wei Sun, and Sunil Kumar Jha.
    2022b. A Lightweight CNN Based on Transfer Learning for COVID-19 Diagnosis. *Computers,
    Materials & Continua* (2022).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021a) Yu-Dong Zhang, Suresh Chandra Satapathy, Shuaiqi Liu, and
    Guang-Run Li. 2021a. A five-layer deep convolutional neural network with stochastic
    pooling for chest CT-based COVID-19 diagnosis. *Machine vision and applications*
    32, 1 (2021), 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021b) Yu-Dong Zhang, Suresh Chandra Satapathy, Xin Zhang, and
    Shui-Hua Wang. 2021b. Covid-19 diagnosis via DenseNet and optimization of transfer
    learning setting. *Cognitive computation* (2021), 1–17.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2018) Zhen Zhang, Yibing Li, Chao Wang, Meiyu Wang, Ya Tu, and
    Jin Wang. 2018. An ensemble learning method for wireless multimedia device identification.
    *Security and communication networks* 2018 (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2021a) Chen Zhao, Yan Xu, Zhuo He, Jinshan Tang, Yijun Zhang, Jungang
    Han, Yuxin Shi, and Weihua Zhou. 2021a. Lung segmentation and automatic detection
    of COVID-19 using radiomic features from chest CT images. *Pattern Recognition*
    119 (2021), 108071 – 108071.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021b) Xiangyu Zhao, Peng Zhang, Fan Song, Guangda Fan, Yangyang
    Sun, Yujia Wang, Zheyuan Tian, Luqi Zhang, and Guanglei Zhang. 2021b. D2A U-Net:
    Automatic segmentation of COVID-19 CT slices based on dual attention and hybrid
    dilated convolution. *Computers in Biology and Medicine* 135 (2021), 104526 –
    104526.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2019) Zhong-Qiu Zhao, Peng Zheng, Shou-tao Xu, and Xindong Wu.
    2019. Object detection with deep learning: A review. *IEEE transactions on neural
    networks and learning systems* 30, 11 (2019), 3212–3232.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng et al. (2022) BingBing Zheng, Yu Zhu, Qin Shi, Dawei Yang, Yanmei Shao,
    and Tao Xu. 2022. MA-Net: Mutex attention network for COVID-19 diagnosis on CT
    images. *Applied Intelligence* (2022), 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2022) Jinzhao Zhou, Xingming Zhang, Ziwei Zhu, Xiangyuan Lan, Lunkai
    Fu, Haoxiang Wang, and Hanchun Wen. 2022. Cohesive Multi-Modality Feature Learning
    and Fusion for COVID-19 Patient Severity Prediction. *IEEE Transactions on Circuits
    and Systems for Video Technology* 32 (2022), 2535–2549.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2021b) S Kevin Zhou, Hayit Greenspan, Christos Davatzikos, James S
    Duncan, Bram Van Ginneken, Anant Madabhushi, Jerry L Prince, Daniel Rueckert,
    and Ronald M Summers. 2021b. A review of deep learning in medical imaging: Imaging
    traits, technology trends, case studies with progress highlights, and future promises.
    *Proc. IEEE* 109, 5 (2021), 820–838.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2020) Tongxue Zhou, Stéphane Canu, and Su Ruan. 2020. An automatic
    COVID-19 CT segmentation based on U-Net with attention mechanism. *arXiv: Image
    and Video Processing* (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2021a) Tongxue Zhou, Stéphane Canu, and Su Ruan. 2021a. Automatic
    COVID-19 CT segmentation using U-Net integrated spatial and channel attention
    mechanism. *International Journal of Imaging Systems and Technology* 31, 1 (2021),
    16–27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2021c) Tao Zhou, Huiling Lu, Zaoli Yang, Shi Qiu, Bingqiang Huo,
    and Yali Dong. 2021c. The ensemble deep learning model for novel COVID-19 on CT
    images. *Applied soft computing* 98 (2021), 106885.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2020) Fuzhen Zhuang, Zhiyuan Qi, Keyu Duan, Dongbo Xi, Yongchun
    Zhu, Hengshu Zhu, Hui Xiong, and Qing He. 2020. A comprehensive survey on transfer
    learning. *Proc. IEEE* 109, 1 (2020), 43–76.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
