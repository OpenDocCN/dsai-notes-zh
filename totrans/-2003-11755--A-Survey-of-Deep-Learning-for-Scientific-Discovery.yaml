- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 20:01:56'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:01:56'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2003.11755] A Survey of Deep Learning for Scientific Discovery'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2003.11755] 深度学习在科学发现中的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2003.11755](https://ar5iv.labs.arxiv.org/html/2003.11755)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2003.11755](https://ar5iv.labs.arxiv.org/html/2003.11755)
- en: A Survey of Deep Learning for Scientific Discovery
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在科学发现中的调查
- en: Maithra Raghu^(1,2)   Eric Schmidt^(1,3)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Maithra Raghu^(1,2)   Eric Schmidt^(1,3)
- en: ¹ Google
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 谷歌
- en: ² Cornell University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ² 康奈尔大学
- en: ³ Schmidt Futures Correspondence to maithrar@gmail.com
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³ Schmidt Futures Correspondence to maithrar@gmail.com
- en: Abstract
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Over the past few years, we have seen fundamental breakthroughs in core problems
    in machine learning, largely driven by advances in deep neural networks. At the
    same time, the amount of data collected in a wide array of scientific domains
    is dramatically increasing in both size and complexity. Taken together, this suggests
    many exciting opportunities for deep learning applications in scientific settings.
    But a significant challenge to this is simply knowing where to start. The sheer
    breadth and diversity of different deep learning techniques makes it difficult
    to determine what scientific problems might be most amenable to these methods,
    or which specific combination of methods might offer the most promising first
    approach. In this survey, we focus on addressing this central issue, providing
    an overview of many widely used deep learning models, spanning visual, sequential
    and graph structured data, associated tasks and different training methods, along
    with techniques to use deep learning with less data and better interpret these
    complex models — two central considerations for many scientific use cases. We
    also include overviews of the full design process, implementation tips, and links
    to a plethora of tutorials, research summaries and open-sourced deep learning
    pipelines and pretrained models, developed by the community. We hope that this
    survey will help accelerate the use of deep learning across different scientific
    domains.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，我们在机器学习的核心问题上取得了根本性的突破，这主要得益于深度神经网络的进展。与此同时，各种科学领域收集的数据量在规模和复杂性上都在显著增加。这些因素结合在一起，暗示了深度学习在科学环境中应用的许多令人兴奋的机会。但一个重要的挑战是如何开始。不同深度学习技术的广泛性和多样性使得确定哪些科学问题最适合这些方法，或哪种特定的方法组合可能提供最有前景的初步解决方案变得困难。在这项调查中，我们专注于解决这一核心问题，提供了许多广泛使用的深度学习模型的概述，涵盖视觉、序列和图结构数据，相关任务和不同训练方法，以及使用少量数据的深度学习技术和更好地解释这些复杂模型的技术——这是许多科学应用中的两个核心考虑因素。我们还包括了完整设计过程的概述、实施技巧和大量教程、研究总结及开源深度学习管道和预训练模型的链接，这些都是由社区开发的。我们希望这项调查能加速深度学习在不同科学领域的应用。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: The past few years have witnessed extraordinary advances in machine learning
    using deep neural networks. Driven by the rapid increase in available data and
    computational resources, these neural network models and algorithms have seen
    remarkable developments, and are a staple technique in tackling fundamental tasks
    ranging from speech recognition [[70](#bib.bib70), [167](#bib.bib167)], to complex
    tasks in computer vision such as image classification, (instance) segmentation,
    action recognition [[117](#bib.bib117), [78](#bib.bib78), [240](#bib.bib240)],
    and central problems in natural language, including question answering, machine
    translation and summarization [[186](#bib.bib186), [172](#bib.bib172), [233](#bib.bib233),
    [197](#bib.bib197)]. Many of these fundamental tasks (with appropriate reformulation)
    are relevant to a much broader array of domains, and in particular have tremendous
    potential in aiding the investigation of central scientific questions.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几年见证了使用深度神经网络的机器学习领域的非凡进展。这些神经网络模型和算法在可用数据和计算资源迅速增加的推动下取得了显著发展，并且成为解决从语音识别
    [[70](#bib.bib70), [167](#bib.bib167)] 到计算机视觉中复杂任务如图像分类、（实例）分割、动作识别 [[117](#bib.bib117),
    [78](#bib.bib78), [240](#bib.bib240)] 以及自然语言中的核心问题，包括问答、机器翻译和总结 [[186](#bib.bib186),
    [172](#bib.bib172), [233](#bib.bib233), [197](#bib.bib197)] 的基本技术。许多这些核心任务（经过适当重新表述）与更广泛的领域相关，特别是在帮助调查核心科学问题方面具有巨大潜力。
- en: However, a significant obstacle in beginning to use deep learning is simply
    knowing where to start. The vast research literature, coupled with the enormous
    number of underlying models, tasks and training methods makes it very difficult
    to identify which techniques might be most appropriate to try, or the best way
    to start implementing them.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，开始使用深度学习的一个重大障碍就是不知道从何开始。大量的研究文献，加上众多的基础模型、任务和训练方法，使得确定哪些技术可能最适合尝试或如何开始实施变得非常困难。
- en: 'The goal of this survey is to help address this central challenge. In particular,
    it has the following attributes:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查的目标是帮助解决这一核心挑战。具体而言，它具有以下特点：
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The survey overviews a highly diverse set of deep learning concepts, from deep
    neural network models for varied data modalities (CNNs for visual data, graph
    neural networks, RNNs and Transformers for sequential data) to the many different
    key tasks (image segmentation, super-resolution, sequence to sequence mappings
    and many others) to the multiple ways of training deep learning systems.
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调查概述了一组高度多样化的深度学习概念，从适用于各种数据模态的深度神经网络模型（用于视觉数据的CNN、图神经网络、用于序列数据的RNN和Transformers）到许多不同的关键任务（图像分割、超分辨率、序列到序列映射等）以及多种训练深度学习系统的方法。
- en: •
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: But the explanation of these techniques is relatively high level and concise,
    to ensure the core ideas are accessible to a broad audience, and so that the entire
    survey can be read end to end easily.
  id: totrans-20
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 但这些技术的解释相对较高层次且简洁，以确保核心思想对广泛受众可及，并且整份调查报告可以轻松阅读。
- en: •
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: From the perspective of aiding scientific applications, the survey describes
    in detail (i) methods to use deep learning with less data (self-supervision, semi-supervised
    learning, and others) and (ii) techniques for interpretability and representation
    analysis (for going beyond predictive tasks). These are two exciting and rapidly
    developing research areas, and are also of particular significance to possible
    scientific use cases.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从支持科学应用的角度来看，调查详细描述了（i）使用较少数据进行深度学习的方法（自监督学习、半监督学习等）和（ii）可解释性和表示分析的技术（超越预测任务）。这两个领域是令人兴奋且迅速发展的研究领域，对潜在的科学应用案例也具有重要意义。
- en: •
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The survey also focuses on helping quickly ramp up implementation, and in addition
    to overviews of the entire deep learning design process and a section on implementation
    tips (Section [9](#S9 "9 Implementation Tips ‣ A Survey of Deep Learning for Scientific
    Discovery")), the survey has a plethora of open-sourced code, research summaries
    and tutorial references developed by the community throughout the text, including
    a full section (Section [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey
    of Deep Learning for Scientific Discovery")) dedicated to this.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调查还侧重于帮助快速上手实施，除了对整个深度学习设计过程的概述和一节关于实施技巧的内容（第[9](#S9 "9 Implementation Tips
    ‣ A Survey of Deep Learning for Scientific Discovery")节），调查中还包含了大量开源代码、研究总结和社区开发的教程参考，包括专门为此设置的完整章节（第[3](#S3
    "3 Deep Learning Libraries and Resources ‣ A Survey of Deep Learning for Scientific
    Discovery")节）。
- en: Who is this survey for? We hope this survey will be especially helpful for those
    with a basic understanding of machine learning, interested in (i) getting a comprehensive
    but accessible overview of many fundamental deep learning concepts and (ii) references
    and guidance in helping ramp up implementation. Beyond the core areas of deep
    learning, the survey focuses on methods to develop deep learning systems with
    less data, and techniques for interpreting these models, which we hope will be
    of particular use for those interested in applying these techniques in scientific
    problems. However, these topics and many others presented, along with the many
    code/tutorial/paper references may be helpful to anyone looking to learn about
    and implement deep learning.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 这份调查报告的目标受众是谁？我们希望这份调查报告对那些有基本机器学习知识的人尤其有帮助，他们感兴趣于（i）获得对许多基础深度学习概念的全面但易于理解的概述，以及（ii）参考和指导以帮助加快实施。除了深度学习的核心领域外，调查还重点关注在较少数据下开发深度学习系统的方法，以及解释这些模型的技术，我们希望这些对那些希望将这些技术应用于科学问题的人特别有用。然而，这些主题及其他许多内容，以及众多代码/教程/论文参考，可能对任何希望学习和实施深度学习的人都有帮助。
- en: 1.1 Outline of Survey
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 调查大纲
- en: 'The survey is structured as follows:'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 调查报告的结构如下：
- en: •
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [2](#S2 "2 High Level Considerations for Deep Learning ‣ A Survey of
    Deep Learning for Scientific Discovery") starts with some high level considerations
    for using deep learning. Specifically, we first discuss some template ways in
    which deep learning might be applied in scientific domains, followed by a general
    overview of the entire deep learning design process, and conclude with a brief
    discussion of other central machine learning techniques that may be better suited
    to some problems. The first part may be of particular interest to those considering
    scientific applications, while the latter two parts may be of general interest.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[2](#S2 "2 深度学习的高层次考虑 ‣ 深度学习在科学发现中的调查")节从使用深度学习的一些高层次考虑开始。具体而言，我们首先讨论深度学习在科学领域的应用模板方式，然后是对整个深度学习设计过程的概述，最后简要讨论其他可能更适合某些问题的核心机器学习技术。第一部分可能对那些考虑科学应用的读者特别感兴趣，而后两部分则可能具有一般兴趣。
- en: •
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey of Deep
    Learning for Scientific Discovery") provides references to tutorials, open-sourced
    code model/algorithm implementations, and websites with research paper summaries,
    all developed by the deep learning community. This section should be very helpful
    for many readers and we encourage skimming through the links provided.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[3](#S3 "3 深度学习库和资源 ‣ 深度学习在科学发现中的调查")节提供了教程、开源代码模型/算法实现的参考，以及由深度学习社区开发的包含研究论文摘要的网站。此节对许多读者非常有帮助，我们鼓励浏览提供的链接。
- en: •
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [4](#S4 "4 Standard Neural Network Models and Tasks ‣ A Survey of Deep
    Learning for Scientific Discovery") then overviews many of the standard tasks
    and models in deep learning, covering convolutional networks and their many uses,
    graph neural networks, sequence models (RNNs, Transformers) and the many associated
    sequence tasks.
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[4](#S4 "4 标准神经网络模型与任务 ‣ 深度学习在科学发现中的调查")节概述了深度学习中的许多标准任务和模型，包括卷积网络及其多种用途、图神经网络、序列模型（RNNs、Transformers）以及许多相关的序列任务。
- en: •
  id: totrans-34
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [5](#S5 "5 Key (Supervised Learning) Methods ‣ A Survey of Deep Learning
    for Scientific Discovery") looks at some key variants of the supervised learning
    training process, such as transfer learning, domain adaptation and multitask learning.
    These are central to many successful applications of deep learning.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[5](#S5 "5 关键（监督学习）方法 ‣ 深度学习在科学发现中的调查")节探讨了一些关键的监督学习训练过程变体，如迁移学习、领域适应和多任务学习。这些方法对许多成功的深度学习应用至关重要。
- en: •
  id: totrans-36
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [6](#S6 "6 Doing More with Less Data ‣ A Survey of Deep Learning for
    Scientific Discovery") considers ways to improve the data efficiency for developing
    deep neural network models, which has been a rapidly evolving area of research,
    and a core consideration for many applications, including scientific domains.
    It covers the many variants of self-supervision and semi-supervised learning,
    as well as data augmentation and data denoising.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[6](#S6 "6 用更少的数据做更多的事 ‣ 深度学习在科学发现中的调查")节考虑了提高开发深度神经网络模型的数据效率的方法，这是一个快速发展的研究领域，也是许多应用，包括科学领域的核心考虑因素。该节涵盖了自监督和半监督学习的多种变体，以及数据增强和数据去噪。
- en: •
  id: totrans-38
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Section [7](#S7 "7 Interpretability, Model Inspection and Representation Analysis
    ‣ A Survey of Deep Learning for Scientific Discovery") overviews advances in interpretability
    and representational analysis, a set of techniques focused on gaining insights
    into the internals of the end-to-end system: identifying important features in
    the data, understanding its effect on model outputs and discovering properties
    of model hidden representations. These are very important for many scientific
    problems which emphasise understanding over predictive accuracy, and may be of
    broader interest for e.g. aiding model debugging and preemptively identifying
    failure modes.'
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[7](#S7 "7 可解释性、模型检查和表示分析 ‣ 深度学习在科学发现中的调查")节概述了在可解释性和表示分析方面的进展，这是一组技术，专注于深入了解端到端系统的内部：识别数据中的重要特征、理解其对模型输出的影响以及发现模型隐藏表示的属性。这些对许多强调理解而非预测准确性的科学问题非常重要，也可能对例如帮助模型调试和预先识别故障模式等更广泛的应用感兴趣。
- en: •
  id: totrans-40
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [8](#S8 "8 Advanced Deep Learning Methods ‣ A Survey of Deep Learning
    for Scientific Discovery") provides a brief overview of more advanced deep learning
    methods, specifically generative modelling and reinforcement learning.
  id: totrans-41
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[8](#S8 "8 Advanced Deep Learning Methods ‣ A Survey of Deep Learning for Scientific
    Discovery")节简要概述了更先进的深度学习方法，特别是生成建模和强化学习。
- en: •
  id: totrans-42
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Section [9](#S9 "9 Implementation Tips ‣ A Survey of Deep Learning for Scientific
    Discovery") concludes with some key implementation tips when putting together
    an end-to-end deep learning system, which we encourage a quick read through!
  id: totrans-43
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 第[9](#S9 "9 Implementation Tips ‣ A Survey of Deep Learning for Scientific Discovery")节总结了构建端到端深度学习系统时的一些关键实施技巧，我们建议快速浏览一下！
- en: 2 High Level Considerations for Deep Learning
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的高层次考虑因素
- en: In this section we first discuss some high level considerations for deep learning
    techniques. We start with overviews of template ways in which deep learning might
    be applied in scientific settings, followed by a discussion of the end-to-end
    design process and some brief highlights of alternate machine learning methods
    which may be more suited to some problems.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们首先讨论深度学习技术的一些高层次考虑因素。我们从深度学习在科学环境中应用的模板方式概述开始，接着讨论端到端设计过程，并简要介绍一些可能更适合某些问题的其他机器学习方法。
- en: 2.1 Templates for Deep Learning in Scientific Settings
  id: totrans-46
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 科学环境中的深度学习模板
- en: 'What are the general ways in which we might apply deep learning techniques
    in scientific settings? At a very high level, we can offer a few templates of
    ways in which deep learning might be used in such problems:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可能在科学环境中应用深度学习技术的一般方式有哪些？从非常高的层次来看，我们可以提供一些深度学习可能应用于这些问题的模板：
- en: (1)
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Prediction Problems Arguably the most straightforward way to apply deep learning
    is to use it to tackle important prediction problems: mapping inputs to predicted
    outputs. This predictive use case of deep learning is typically how it is also
    used in core problems in computing and machine learning. For example, the input
    might be a biopsy image, and the model must output a prediction of whether the
    imaged tissue shows signs of cancer. We can also think of this predictive use
    case as getting the model to learn a target function, in our example, mapping
    from input visual features to the cancer/no cancer output. Using deep learning
    in this way also encapsulates settings where the target function is very complex,
    with no mathematical closed form or logical set of rules that describe how to
    go from input to output. For instance, we might use a deep learning model to (black-box)
    simulate a complex process (e.g. climate modelling), that is very challenging
    to explicitly model [[101](#bib.bib101)].'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预测问题 无疑，应用深度学习的最直接方式是用它来解决重要的预测问题：将输入映射到预测输出。这种预测性使用案例通常也是深度学习在计算和机器学习核心问题中的使用方式。例如，输入可能是一张活检图像，模型必须输出是否该图像中的组织显示出癌症迹象的预测。我们也可以将这种预测使用案例看作是让模型学习一个目标函数，在我们的例子中，就是将输入视觉特征映射到癌症/无癌症的输出。以这种方式使用深度学习还涵盖了目标函数非常复杂的情况，没有数学封闭形式或逻辑规则来描述如何从输入到输出。例如，我们可能使用深度学习模型来（黑箱）模拟一个复杂的过程（例如气候建模），这个过程很难明确建模[[101](#bib.bib101)]。
- en: (2)
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (2)
- en: From Predictions to Understanding One fundamental difference between scientific
    questions and core machine learning problems is the emphasis in the former on
    understanding the underlying mechanisms. Oftentimes, outputting an accurate prediction
    alone is not enough. Instead, we want to gain interpretable insights into what
    properties of the data or the data generative process led to the observed prediction
    or outcome. To gain these kinds of insights, we can turn to interpretability and
    representation analysis methods in deep learning, which focus on determining how
    the neural network model makes a specific prediction. There has been significant
    work on both tools to understand what features of the input are most critical
    to the output prediction, as well as techniques to directly analyze the hidden
    representations of the neural network models, which can reveal important properties
    of the underlying data.
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从预测到理解 科学问题和核心机器学习问题之间的一个根本区别在于前者强调理解基础机制。单独输出准确的预测往往是不够的。相反，我们希望深入了解数据或数据生成过程的哪些属性导致了观察到的预测或结果。为了获得这些洞察，我们可以借助深度学习中的可解释性和表示分析方法，这些方法关注于确定神经网络模型如何做出特定预测。已经有大量工作致力于理解输入特征对输出预测的关键性，以及直接分析神经网络模型的隐藏表示的技术，这些技术可以揭示基础数据的重要属性。
- en: (3)
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (3)
- en: Complex Transformations of Input Data In many scientific domains, the amount
    of generated data, particularly visual data (e.g. fluorescence microscopy, spatial
    sequencing, specimen videos [[177](#bib.bib177), [97](#bib.bib97)]) has grown
    dramatically, and there is an urgent need for efficient analysis and automated
    processing. Deep learning techniques, which are capable of many complex transformations
    of data, can be highly effective for such settings, for example, using a deep
    neural network based segmentation model to automatically identify the nuclei in
    images of cells, or a pose estimation system to rapidly label behaviors seen in
    videos of mice for neuroscience analysis.
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入数据的复杂变换 在许多科学领域，生成的数据量，特别是视觉数据（例如荧光显微镜、空间测序、标本视频[[177](#bib.bib177), [97](#bib.bib97)]）急剧增加，迫切需要高效的分析和自动化处理。深度学习技术能够对数据进行多种复杂变换，适用于这些场景。例如，可以使用基于深度神经网络的分割模型自动识别细胞图像中的细胞核，或者使用姿态估计系统快速标记小鼠视频中的行为，以进行神经科学分析。
- en: 2.2 Deep Learning Workflow
  id: totrans-54
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 深度学习工作流程
- en: With these examples of templates for deep learning applications in science,
    we next look at the end to end workflow for designing a deep learning system.
    Figure [1](#S2.F1 "Figure 1 ‣ 2.2 Deep Learning Workflow ‣ 2 High Level Considerations
    for Deep Learning ‣ A Survey of Deep Learning for Scientific Discovery") illustrates
    what a typical workflow might look like.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些深度学习应用科学的模板示例之后，我们接下来查看设计深度学习系统的端到端工作流程。图 [1](#S2.F1 "图 1 ‣ 2.2 深度学习工作流程
    ‣ 2 高级考虑事项 ‣ 科学发现的深度学习调查") 说明了典型工作流程的可能样子。
- en: '![Refer to caption](img/a254e2aa4b62ba2c310b990dcd5f9ca2.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a254e2aa4b62ba2c310b990dcd5f9ca2.png)'
- en: 'Figure 1: Schematic of a typical deep learning workflow. A typical development
    process for deep learning applications can be viewed as consisting of three sequential
    stages (i) data related steps (ii) the learning component (iii) validation and
    analysis. Each one of these stages has several substeps and techniques associated
    with it, also depicted in the figure. In the survey we will overview most techniques
    in the learning component, as well as some techniques in the data and validation
    stages. Note that while a natural sequence is to first complete steps in the data
    stage, followed by learning and then validation, standard development will likely
    result in multiple different iterations where the techniques used or choices made
    in one stage are revisited based off of results of a later stage.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：典型深度学习工作流程的示意图。深度学习应用的典型开发过程可以分为三个连续阶段：(i) 数据相关步骤 (ii) 学习组件 (iii) 验证和分析。这些阶段中的每一个都有多个子步骤和相关技术，如图中所示。在本调查中，我们将概述学习组件中的大多数技术，以及数据和验证阶段的一些技术。请注意，尽管自然的顺序是首先完成数据阶段的步骤，然后是学习阶段，最后是验证阶段，但标准开发过程通常会导致多个不同的迭代，其中一个阶段使用的技术或做出的选择会基于后续阶段的结果进行调整。
- en: 'Having selected the overarching (predictive) problem of interest, we can broadly
    think of having three stages for designing and using the deep learning system:
    (i) data related steps, such as collection, labelling, preprocessing, visualization,
    etc (ii) learning focused steps, such as choice of deep neural network model,
    the task and method used to train the model (iii) validation and analysis steps,
    where performance evaluations are conducted on held out data, as well as analysis
    and interpretation of hidden representations and ablation studies of the overall
    methods.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 选择了感兴趣的总体（预测）问题后，我们可以大致将深度学习系统的设计和使用分为三个阶段：（i）数据相关步骤，例如收集、标注、预处理、可视化等；（ii）学习集中步骤，例如深度神经网络模型的选择、任务及训练模型的方法；（iii）验证和分析步骤，其中对保留数据进行性能评估，以及对隐藏表示的分析和整体方法的消融研究。
- en: These three stages are naturally sequential. However, almost all of the time,
    the first attempt at building an end-to-end deep learning system will result in
    some kind of failure mode. To address these, it is important to keep in mind the
    iterative nature of the design process, with results from the different stages
    informing the redesign and rerunning of other stages.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 这三个阶段自然是顺序进行的。然而，几乎所有情况下，首次构建端到端深度学习系统时都会出现某种失败模式。为了解决这些问题，重要的是要牢记设计过程的迭代性质，不同阶段的结果将指导其他阶段的重新设计和重新运行。
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2.2 Deep Learning Workflow ‣ 2 High Level Considerations
    for Deep Learning ‣ A Survey of Deep Learning for Scientific Discovery") provides
    some examples of common iterations with the backward connecting arrows: (i) the
    Iterate (1) arrow, corresponding to iterations on the data collection process,
    e.g. having performed some data visualization, the labelling process for the raw
    instances might require adjusting — the first labelling mechanism might be too
    noisy, or not capture the objective of interest (ii) the Iterate (2) arrow, corresponding
    to iterations on the learning setup, due to e.g. deciding that a different task
    or method might be more appropriate, or decomposing the learning process into
    multiple steps — first performing self-supervision followed by supervised learning
    (iii) the Iterate (3) arrow, changing the data related steps based off of the
    results of the learning step (iv) the Iterate (4) arrow, redesigning the learning
    process informed by the validation results e.g. finding out the model has overfit
    on the training data at validation and hence reducing training time or using a
    simpler model (v) the Iterate (5) arrow, adapting the data steps based off the
    validation/analysis results, e.g. finding that the model is relying on spurious
    attributes of the data, and improving data collection/curation to mitigate this.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S2.F1 "图 1 ‣ 2.2 深度学习工作流 ‣ 2 高层次深度学习考虑 ‣ 科学发现的深度学习调查") 提供了一些常见迭代的示例，带有向后的连接箭头：（i）迭代（1）箭头，对应于数据收集过程中的迭代，例如在进行一些数据可视化后，原始实例的标注过程可能需要调整——初始标注机制可能过于嘈杂，或未能捕捉到感兴趣的目标；（ii）迭代（2）箭头，对应于学习设置的迭代，例如决定不同的任务或方法可能更为合适，或将学习过程分解为多个步骤——首先进行自监督学习，然后进行监督学习；（iii）迭代（3）箭头，根据学习步骤的结果更改数据相关步骤；（iv）迭代（4）箭头，基于验证结果重新设计学习过程，例如发现模型在验证时过拟合训练数据，因此减少训练时间或使用更简单的模型；（v）迭代（5）箭头，根据验证/分析结果调整数据步骤，例如发现模型依赖于数据的虚假属性，从而改善数据收集/策划以减轻此问题。
- en: Focus of Survey and Nomenclature
  id: totrans-61
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 调查重点和术语
- en: In this survey, we provide a comprehensive overview of many of the techniques
    in the learning stage, along with some techniques (e.g. data augmentation, interpretability
    and representation analysis, Section [7](#S7 "7 Interpretability, Model Inspection
    and Representation Analysis ‣ A Survey of Deep Learning for Scientific Discovery"))
    in the data and validation stages.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本次调查中，我们提供了学习阶段许多技术的全面概述，以及一些数据和验证阶段的技术（例如数据增强、可解释性和表示分析，见 [7](#S7 "7 可解释性、模型检查和表示分析
    ‣ 科学发现的深度学习调查")）。
- en: For the learning stage, we look at popular models, tasks and methods. By models
    (also sometimes referred to as architecture), we mean the actual structure of
    the deep neural network — how many layers, of what type, and how many neurons,
    etc. By tasks, we mean the kind of prediction problem, specifically, the type
    of input and output. For example, in an image classification task, the input consists
    of images and the output a probability distribution over a (discrete) set of different
    categories (called classes). By methods, we refer to the type of learning process
    used to train the system. For example, supervised learning is a very general learning
    process, consisting of the neural network being given data instances with corresponding
    labels, with the labels providing supervision.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 在学习阶段，我们会查看流行的模型、任务和方法。模型（有时也称为架构）指的是深度神经网络的实际结构——有多少层、哪种类型以及多少个神经元等。任务指的是预测问题的类型，具体来说，输入和输出的类型。例如，在图像分类任务中，输入由图像组成，输出是对一组（离散的）不同类别（称为类别）的概率分布。方法指的是用于训练系统的学习过程类型。例如，监督学习是一种非常通用的学习过程，神经网络被提供数据实例及其对应的标签，这些标签提供了监督。
- en: Unlike different models and tasks, methods can be subsets of other methods.
    For example, self-supervision, a method where the neural network is trained on
    data instances and labels, but the labels automatically created from the data
    instance, can also be considered a type of supervised learning. This can be a
    little confusing! But it suffices to keep in mind the general notions of models,
    tasks and methods.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 与不同的模型和任务不同，方法可以是其他方法的子集。例如，自监督学习是一种方法，其中神经网络在数据实例和标签上进行训练，但标签是从数据实例自动生成的，这也可以被视为一种监督学习。这可能有点混乱！但记住模型、任务和方法的一般概念就足够了。
- en: 2.3 Deep Learning or Not?
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 深度学习还是其他方法？
- en: As a final note before diving into the different deep learning techniques, when
    formulating a problem, it is important to consider whether deep learning provides
    the right set of tools to solve it. The powerful underlying neural network models
    offer many sophisticated functionalities, such learned complex image transforms.
    However, in many settings, deep learning may not be the best technique to start
    with or best suited to the problem. Below we very briefly overview some of the
    most ubiquitous machine learning methods, particularly in scientific contexts.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入不同的深度学习技术之前，最后一点要说明的是，在制定问题时，考虑深度学习是否提供了合适的工具来解决问题是非常重要的。强大的基础神经网络模型提供了许多复杂的功能，比如学习复杂的图像变换。然而，在许多情况下，深度学习可能不是开始时的最佳技术，也可能不最适合这个问题。下面我们非常简要地回顾一些最常见的机器学习方法，特别是在科学背景下。
- en: Dimensionality Reduction and Clustering
  id: totrans-67
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 降维与聚类
- en: In scientific settings, the ultimate goal of data analysis is often understanding
    — identifying the underlying mechanisms that give rise to patterns in the data.
    When this is the goal, dimensionality reduction, and/or clustering are simple
    (unsupervised) but highly effective methods to reveal hidden properties in the
    data. They are often very useful in the important first step of exploring and
    visualizing the data (even if more complex methods are applied later.)
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学环境中，数据分析的最终目标通常是理解——识别导致数据中模式的潜在机制。当目标是这个时，降维和/或聚类是简单（无监督）但非常有效的方法，可以揭示数据中的隐藏属性。它们在探索和可视化数据的关键第一步中非常有用（即使后面可能会应用更复杂的方法）。
- en: 'Dimensionality Reduction: Dimensionality reduction methods are either linear,
    relying on a linear transformation to reduce data dimensionality, or non-linear,
    reducing dimensionality while approximately preserving the non-linear (manifold)
    structure of the data. Popular linear dimensionality reduction methods include
    PCA and non-negative matrix factorization, with some popular non-linear methods
    including t-SNE [[141](#bib.bib141)] and UMAP [[148](#bib.bib148)]. Most dimensionality
    reduction methods have high-quality implementations in packages like scikit-learn
    or on github, e.g. [https://github.com/oreillymedia/t-SNE-tutorial](https://github.com/oreillymedia/t-SNE-tutorial)
    or [https://github.com/lmcinnes/umap](https://github.com/lmcinnes/umap).'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 降维：降维方法分为线性和非线性两种。线性方法依赖于线性变换来减少数据的维度，而非线性方法则在近似保留数据的非线性（流形）结构的同时减少维度。流行的线性降维方法包括PCA和非负矩阵分解，一些流行的非线性方法包括t-SNE
    [[141](#bib.bib141)]和UMAP [[148](#bib.bib148)]。大多数降维方法在scikit-learn或github等软件包中有高质量的实现，例如[https://github.com/oreillymedia/t-SNE-tutorial](https://github.com/oreillymedia/t-SNE-tutorial)或[https://github.com/lmcinnes/umap](https://github.com/lmcinnes/umap)。
- en: 'Clustering: Often used in combination with dimensionality reduction, clustering
    methods provide a powerful, unsupervised way to identify similarities and differences
    across the data population. Commonly used clustering methods include k-means (particularly
    the k-means++ variant), Gaussian Mixture Models (GMMs), hierarchical clustering
    and spectral clustering. Like dimensionality reduction techniques, these clustering
    methods have robust implementations in packages like scikit-learn.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类：通常与降维方法结合使用，聚类方法提供了一种强大的无监督方式来识别数据群体中的相似性和差异。常用的聚类方法包括k均值（特别是k均值++变体）、高斯混合模型（GMMs）、层次聚类和谱聚类。像降维技术一样，这些聚类方法在scikit-learn等软件包中有可靠的实现。
- en: In Section [7.2.2](#S7.SS2.SSS2 "7.2.2 Dimensionality Reduction on Neural Network
    Hidden Representations ‣ 7.2 Model Inspection and Representational Analysis ‣
    7 Interpretability, Model Inspection and Representation Analysis ‣ A Survey of
    Deep Learning for Scientific Discovery"), we discuss how dimensionality reduction
    and clustering can be used on the hidden representations of neural networks.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[7.2.2节](#S7.SS2.SSS2 "7.2.2 Dimensionality Reduction on Neural Network Hidden
    Representations ‣ 7.2 Model Inspection and Representational Analysis ‣ 7 Interpretability,
    Model Inspection and Representation Analysis ‣ A Survey of Deep Learning for Scientific
    Discovery")中，我们讨论了如何在神经网络的隐藏表示上使用降维和聚类。
- en: Linear Regression, Logistic Regression (and variants!)
  id: totrans-72
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 线性回归、逻辑回归（及其变体！）
- en: Arguably the most fundamental techniques for supervised problems like classification
    and regression, linear and logistic regression, and their variants (e.g. Lasso,
    Ridge Regression) may be particularly useful when there is limited data, and a
    clear set of (possibly preprocessed) features (such as in tabular data.) These
    methods also often provide a good way to sanity check the overarching problem
    formulation, and may be a good starting point to test out a very simple version
    of the full problem. Due to their simplicity, linear and logistic regression are
    highly interpretable, and provide straightforward ways to perform feature attribution.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，对于像分类和回归这样的监督问题，线性回归和逻辑回归及其变体（例如Lasso、Ridge回归）是最基本的技术。当数据有限且有一组明确的（可能已预处理的）特征（如表格数据）时，这些方法可能特别有用。这些方法还经常提供一个良好的方法来检查整体问题的制定，并可能是测试全问题非常简单版本的良好起点。由于其简单性，线性回归和逻辑回归具有很高的可解释性，并提供了直接的特征归因方式。
- en: Decision Trees, Random Forests and Gradient Boosting
  id: totrans-74
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 决策树、随机森林和梯度提升
- en: Another popular class of methods are decision trees, random forests and gradient
    boosting. These methods can also work with regression/classification tasks, and
    are well suited to model non-linear relations between the input features and output
    predictions. Random forests, which ensemble decision trees, can often be preferred
    to deep learning methods in settings where the data has a low signal-to-noise
    ratio. These methods can typically be less interpretable than linear/logistic
    regression, but recent work [[160](#bib.bib160)] has looked at developing software
    libraries [https://github.com/interpretml/interpret](https://github.com/interpretml/interpret)
    to address this challenge.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 另一类流行的方法是决策树、随机森林和梯度提升。这些方法也适用于回归/分类任务，并且非常适合建模输入特征和输出预测之间的非线性关系。随机森林，作为决策树的集成，常常在数据噪声比信号高的情况下优于深度学习方法。这些方法通常比线性/逻辑回归更难以解释，但最近的工作[[160](#bib.bib160)]关注于开发软件库
    [https://github.com/interpretml/interpret](https://github.com/interpretml/interpret)
    来应对这一挑战。
- en: 'Other Methods and Resources:'
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 其他方法和资源：
- en: Both the aforementioned techniques and many other popular methods such as graphical
    models, Gaussian processes, Bayesian optimization are overviewed in detail in
    excellent course notes such as [University of Toronto‘s Machine Learning Course](http://www.cs.toronto.edu/~rgrosse/courses/csc411_f18/)
    or [Stanford‘s CS229](http://cs229.stanford.edu/syllabus.html), detailed articles
    at [https://towardsdatascience.com/](https://towardsdatascience.com/) and even
    interactive textbooks such as [https://d2l.ai/index.html](https://d2l.ai/index.html)
    (called Dive into Deep Learning [[267](#bib.bib267)]) and [https://github.com/rasbt/python-machine-learning-book-2nd-edition](https://github.com/rasbt/python-machine-learning-book-2nd-edition).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 前述技术以及许多其他流行的方法，如图模型、高斯过程、贝叶斯优化，在优秀的课程笔记中都有详细概述，如 [多伦多大学的机器学习课程](http://www.cs.toronto.edu/~rgrosse/courses/csc411_f18/)
    或 [斯坦福大学的CS229](http://cs229.stanford.edu/syllabus.html)，详细文章在 [https://towardsdatascience.com/](https://towardsdatascience.com/)
    ，甚至有交互式教材如 [https://d2l.ai/index.html](https://d2l.ai/index.html)（称为《深入深度学习》[[267](#bib.bib267)]）和
    [https://github.com/rasbt/python-machine-learning-book-2nd-edition](https://github.com/rasbt/python-machine-learning-book-2nd-edition)。
- en: 3 Deep Learning Libraries and Resources
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 个深度学习库和资源
- en: A remarkable aspect of advances in deep learning so far is the enormous number
    of resources developed and shared by the community. These range from tutorials,
    to overviews of research papers, to open sourced code. Throughout this survey,
    we will reference some of these materials in the topic specific sections, but
    we first list here a few general very useful frameworks and resources.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，深度学习的进展一个显著方面是社区开发和分享的资源数量之庞大。这些资源包括教程、研究论文概述、开源代码。在本调查中，我们将在特定主题的部分中引用一些这些材料，但我们首先列出一些通用的非常有用的框架和资源。
- en: 'Software Libraries for Deep Learning:'
  id: totrans-80
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 深度学习的软件库：
- en: Arguably the two most popular code libraries for deep learning are [PyTorch](https://pytorch.org/)
    (with a high level API called [Lightning](https://github.com/PyTorchLightning/pytorch-lightning))
    and [TensorFlow](https://www.tensorflow.org/) (which also offers [Keras](https://keras.io/)
    as a high level API.) Developing and training deep neural network models critically
    relies on fast, parallelized matrix and tensor operations (sped up through the
    use of Graphical Processing Units) and performing automatic differentiation for
    computing gradients and optimization (known as autodiff.) Both PyTorch and TensorFlow
    offer these core utilities, as well as many other functions. Other frameworks
    include [Chainer](https://chainer.org/), [ONNX](https://onnx.ai/), [MXNET](https://mxnet.apache.org/)
    and [JAX](https://github.com/google/jax). Choosing the best framework has been
    the source of significant debate. For ramping up quickly, programming experiences
    closest to native Python, and being able to use many existing code repositories,
    PyTorch (or TensorFlow with the Keras API) may be two of the best choices.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，深度学习领域最受欢迎的两个代码库是 [PyTorch](https://pytorch.org/)（带有一个名为 [Lightning](https://github.com/PyTorchLightning/pytorch-lightning)
    的高级 API）和 [TensorFlow](https://www.tensorflow.org/)（它也提供 [Keras](https://keras.io/)
    作为高级 API）。开发和训练深度神经网络模型关键在于快速、并行的矩阵和张量操作（通过图形处理单元加速）以及进行自动微分以计算梯度和优化（称为 autodiff）。PyTorch
    和 TensorFlow 都提供了这些核心工具及许多其他功能。其他框架包括 [Chainer](https://chainer.org/)、[ONNX](https://onnx.ai/)、[MXNET](https://mxnet.apache.org/)
    和 [JAX](https://github.com/google/jax)。选择最佳框架一直是激烈讨论的焦点。为了快速上手、拥有最接近原生 Python
    的编程体验，并能够使用许多现有的代码库，PyTorch（或使用 Keras API 的 TensorFlow）可能是两个最佳选择。
- en: 'Tutorials:'
  id: totrans-82
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 教程：
- en: (i) [https://course.fast.ai/](https://course.fast.ai/) fast.ai provides a free,
    coding-first course on the most important deep learning techniques as well as
    an intuitive and easy to use code library, [https://github.com/fastai/fastai](https://github.com/fastai/fastai),
    for model design and development. (ii) [https://towardsdatascience.com/](https://towardsdatascience.com/)
    contains some fantastic tutorials on almost every deep learning topic imaginable,
    crowd sourced from many contributors. (iii) Many graduate deep learning courses
    have excellent videos and lecture notes available online, such as [http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/](http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/)
    for Deep Learning and Neural Networks, or the more topic specific [Stanford‘s
    CS224N NLP with Deep Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z).
    A nice collection of some of these topic specific lectures is provided at [https://github.com/Machine-Learning-Tokyo/AI_Curriculum](https://github.com/Machine-Learning-Tokyo/AI_Curriculum).
    There are also some basic interactive deep learning courses online, such as [https://github.com/leriomaggio/deep-learning-keras-tensorflow](https://github.com/leriomaggio/deep-learning-keras-tensorflow).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: (i) [https://course.fast.ai/](https://course.fast.ai/) fast.ai 提供了一门免费的、以编码为主的课程，涵盖了最重要的深度学习技术，并且提供了一个直观且易于使用的代码库
    [https://github.com/fastai/fastai](https://github.com/fastai/fastai) 用于模型设计和开发。
    (ii) [https://towardsdatascience.com/](https://towardsdatascience.com/) 包含了一些出色的教程，涵盖几乎所有深度学习主题，由许多贡献者众包提供。
    (iii) 许多研究生深度学习课程在网上提供了优秀的视频和讲义，例如 [http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/](http://www.cs.toronto.edu/~rgrosse/courses/csc421_2019/)
    的深度学习与神经网络课程，或更具主题性的 [Stanford‘s CS224N NLP with Deep Learning](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z)。这些主题特定讲座的一些精彩集合可以在
    [https://github.com/Machine-Learning-Tokyo/AI_Curriculum](https://github.com/Machine-Learning-Tokyo/AI_Curriculum)
    找到。此外，还有一些基础的互动深度学习课程在线上，如 [https://github.com/leriomaggio/deep-learning-keras-tensorflow](https://github.com/leriomaggio/deep-learning-keras-tensorflow)。
- en: 'Research Overviews, Code, Discussion:'
  id: totrans-84
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 研究概述、代码、讨论：
- en: (i) [https://paperswithcode.com/](https://paperswithcode.com/) This excellent
    site keeps track of new research papers and their corresponding opensourced code,
    trending directions and displays state of the art results ([https://paperswithcode.com/sota](https://paperswithcode.com/sota))
    across many standard benchmarks. (ii) Discussion of deep learning research is
    very active on Twitter. [http://www.arxiv-sanity.com/top](http://www.arxiv-sanity.com/top)
    keeps track of some of the top most discussed papers and comments. (iii) [https://www.reddit.com/r/MachineLearning/](https://www.reddit.com/r/MachineLearning/)
    is also a good forum for research and general project discussion. (iv) [https://www.paperdigest.org/conference-paper-digest/](https://www.paperdigest.org/conference-paper-digest/)
    contains snippets of all the papers in many different top machine learning conferences.
    (v) IPAM (Institute for Pure and Applied Mathematics) has a few programs e.g.
    [https://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule](https://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule)
    and [https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule](https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule)
    with videos overviewing deep learning applications in science.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: (i) [https://paperswithcode.com/](https://paperswithcode.com/) 这个优秀的网站跟踪新研究论文及其相应的开源代码，流行趋势，并展示许多标准基准上的最新成果
    ([https://paperswithcode.com/sota](https://paperswithcode.com/sota))。 (ii) 深度学习研究在Twitter上讨论非常活跃。[http://www.arxiv-sanity.com/top](http://www.arxiv-sanity.com/top)
    跟踪一些最热门的讨论论文和评论。 (iii) [https://www.reddit.com/r/MachineLearning/](https://www.reddit.com/r/MachineLearning/)
    也是一个讨论研究和一般项目的好论坛。 (iv) [https://www.paperdigest.org/conference-paper-digest/](https://www.paperdigest.org/conference-paper-digest/)
    包含了许多顶级机器学习会议上所有论文的摘录。 (v) IPAM（纯数学与应用数学研究所）有一些项目，例如 [https://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule](https://www.ipam.ucla.edu/programs/workshops/new-deep-learning-techniques/?tab=schedule)
    和 [https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule](https://www.ipam.ucla.edu/programs/workshops/deep-learning-and-medical-applications/?tab=schedule)
    提供了有关深度学习在科学应用中的视频概述。
- en: 'Models, Training Code and Pretrained Models:'
  id: totrans-86
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 模型、训练代码和预训练模型：
- en: 'As we discuss later in the survey, publicly available models, training code
    and pretrained models are very useful for techniques such as transfer learning.
    There are many good sources of these, here are a few that are especially comprehensive
    and/or accessible:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 如我们在调查中后面讨论的那样，公开可用的模型、训练代码和预训练模型对于转移学习等技术非常有用。这里有一些特别全面和/或可访问的良好资源：
- en: (i)
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (i)
- en: Pytorch and TensorFlow have a collection of pretrained models, found at [https://github.com/tensorflow/models](https://github.com/tensorflow/models)
    and [https://pytorch.org/docs/stable/torchvision/models.html](https://pytorch.org/docs/stable/torchvision/models.html).
  id: totrans-89
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Pytorch 和 TensorFlow 提供了一系列预训练模型，网址为 [https://github.com/tensorflow/models](https://github.com/tensorflow/models)
    和 [https://pytorch.org/docs/stable/torchvision/models.html](https://pytorch.org/docs/stable/torchvision/models.html)。
- en: (ii)
  id: totrans-90
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (ii)
- en: '[https://github.com/huggingface](https://github.com/huggingface) Hugging Face
    (yes, that really is the name), offers a huge collection of both pretrained neural
    networks and the code used to train them. Particularly impressive is their library
    of Transformer models, a one-stop-shop for sequential or language applications.'
  id: totrans-91
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/huggingface](https://github.com/huggingface) Hugging Face（没错，这就是名字）提供了大量预训练神经网络及其训练代码。他们的Transformer模型库特别令人印象深刻，是处理序列或语言应用的一站式商店。'
- en: (iii)
  id: totrans-92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (iii)
- en: '[https://github.com/rasbt/deeplearning-models](https://github.com/rasbt/deeplearning-models)
    offers many standard neural network architectures, including multilayer perceptrons,
    convolutional neural networks, GANs and Recurrent Neural Networks.'
  id: totrans-93
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/rasbt/deeplearning-models](https://github.com/rasbt/deeplearning-models)
    提供了许多标准的神经网络架构，包括多层感知机、卷积神经网络、生成对抗网络和递归神经网络。'
- en: (iv)
  id: totrans-94
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (iv)
- en: '[https://github.com/hysts/pytorch_image_classification](https://github.com/hysts/pytorch_image_classification)
    does a deep dive into image classification architectures, with training code,
    highly popular data augmentation techniques such as cutout, and careful speed
    and accuracy benchmarking. See their page for some object detection architectures
    also.'
  id: totrans-95
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/hysts/pytorch_image_classification](https://github.com/hysts/pytorch_image_classification)
    深入探讨了图像分类架构，提供了训练代码、广受欢迎的数据增强技术（如cutout），以及细致的速度和准确性基准测试。请查看他们的页面以获取一些目标检测架构。'
- en: (v)
  id: totrans-96
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (v)
- en: '[https://github.com/openai/baselines](https://github.com/openai/baselines)
    provides implementations of many popular RL algorithms.'
  id: totrans-97
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/openai/baselines](https://github.com/openai/baselines)
    提供了许多流行RL算法的实现。'
- en: (vi)
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (vi)
- en: '[https://modelzoo.co/](https://modelzoo.co/) is a little like paperswithcode,
    but for models, linking to implementations of neural network architectures for
    many different standard problems.'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://modelzoo.co/](https://modelzoo.co/) 有点像paperswithcode，但针对模型，链接到许多不同标准问题的神经网络架构实现。'
- en: (vii)
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (vii)
- en: '[https://github.com/rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric).
    Implementations and paper links for many graph neural network architectures.'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '[https://github.com/rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric)。许多图形神经网络架构的实现和论文链接。'
- en: 'Data Collection, Curation and Labelling Resources:'
  id: totrans-102
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 数据收集、整理和标注资源：
- en: A crucial step in applying deep learning to a problem is collecting, curating
    and labelling data. This is a very important, time-intensive and often highly
    intricate task (e.g. labelling object boundaries in an image for segmentation.)
    Luckily, there are some resources and libraries to help with this, for example
    [https://github.com/tzutalin/labelImg](https://github.com/tzutalin/labelImg),
    [https://github.com/wkentaro/labelme](https://github.com/wkentaro/labelme), [https://rectlabel.com/](https://rectlabel.com/)
    for images and [https://github.com/doccano/doccano](https://github.com/doccano/doccano)
    for text/sequential data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 将深度学习应用于问题的一个关键步骤是收集、整理和标注数据。这是一个非常重要、耗时且通常复杂的任务（例如，为图像分割标注对象边界）。幸运的是，有一些资源和库可以提供帮助，例如[https://github.com/tzutalin/labelImg](https://github.com/tzutalin/labelImg)、[https://github.com/wkentaro/labelme](https://github.com/wkentaro/labelme)、[https://rectlabel.com/](https://rectlabel.com/)用于图像，[https://github.com/doccano/doccano](https://github.com/doccano/doccano)用于文本/序列数据。
- en: 'Visualization, Analysis and Compute Resources:'
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 可视化、分析和计算资源：
- en: When training deep neural network models, it is critical to visualize important
    metrics such as loss and accuracy while the model is training. Tensorboard [https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)
    (which works with Pytorch and TensorFlow) is a very popular framework for doing
    this. Related is the colab effort [https://colab.research.google.com/notebooks/welcome.ipynb](https://colab.research.google.com/notebooks/welcome.ipynb),
    which, aside from providing a user-friendly, interactive way for model development
    and analysis (very similar to [jupyter notebooks](https://jupyter.org/)) also
    provides some (free!) compute resources.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练深度神经网络模型时，关键是要在模型训练过程中可视化重要的指标，如损失和准确度。Tensorboard [https://www.tensorflow.org/tensorboard](https://www.tensorflow.org/tensorboard)（可与Pytorch和TensorFlow配合使用）是一个非常流行的框架。相关的是colab
    [https://colab.research.google.com/notebooks/welcome.ipynb](https://colab.research.google.com/notebooks/welcome.ipynb)的努力，除了提供一种用户友好、互动的模型开发和分析方式（非常类似于[jupyter
    notebooks](https://jupyter.org/)），还提供一些（免费的！）计算资源。
- en: 4 Standard Neural Network Models and Tasks
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 标准神经网络模型及任务
- en: In this section, we overview the standard neural network models and the kinds
    of tasks they can be used for, from convolutional networks for image predictions
    and transformations to transformer models for sequential data to graph neural
    networks for chemistry applications.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们概述了标准神经网络模型及其应用任务，从用于图像预测和变换的卷积网络，到用于序列数据的变换器模型，再到用于化学应用的图形神经网络。
- en: 4.1 Supervised Learning
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 监督学习
- en: '![Refer to caption](img/7bd4daf5fd3a2f37f3be1bb74583aad9.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7bd4daf5fd3a2f37f3be1bb74583aad9.png)'
- en: 'Figure 2: The Supervised Learning process for training neural networks. The
    figure illustrates the supervised learning process for neural networks. Data instances
    (in this case images) and corresponding labels are collected. During the training
    step, the parameters of the neural network are optimized so that when input a
    data instance, the neural network outputs the corresponding label. During evaluation,
    the neural network is given unseen data instances as input, and if trained successfully,
    will output a meaningful label (prediction).'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：训练神经网络的监督学习过程。该图说明了神经网络的监督学习过程。收集数据实例（在这种情况下是图像）和相应标签。在训练阶段，优化神经网络的参数，以便当输入数据实例时，神经网络输出相应的标签。在评估阶段，神经网络会接收未见过的数据实例作为输入，如果训练成功，将输出有意义的标签（预测）。
- en: Before diving into the details of the different deep neural network models,
    it is useful to briefly discuss supervised learning, the most standard method
    to train these models. In the supervised learning framework, we are given data
    instances and an associated label for each data instance, i.e. (data instance,
    label) pairs. For example, the data instances might comprise of chest x-ray images,
    and the labels (one for each chest x-ray image) a binary yes/no to whether it
    shows the symptoms of pneumonia. Training the neural network model then consists
    of finding values for its parameters so that when it is fed in a data instance
    (chest x-ray) as input, it correctly outputs the corresponding label (yes/no on
    whether the chest x-ray has pneumonia.) To find these parameter values, we perform
    iterative optimization to guide the neural network parameters to appropriate values,
    using the given labels to provide supervision. Figure [2](#S4.F2 "Figure 2 ‣ 4.1
    Supervised Learning ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of
    Deep Learning for Scientific Discovery") shows a schematic of the supervised learning
    setup for deep learning.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 在深入探讨不同的深度神经网络模型之前，简要讨论一下监督学习是有益的，这是训练这些模型的最标准方法。在监督学习框架中，我们获得数据实例和与每个数据实例相关联的标签，即（数据实例，标签）对。例如，数据实例可能包括胸部X光图像，而标签（每个胸部X光图像一个）则是是否显示肺炎症状的二元是/否。然后，训练神经网络模型的过程就是寻找其参数的值，以便当输入一个数据实例（胸部X光图像）时，能正确输出相应的标签（胸部X光图像是否有肺炎的是/否）。为了找到这些参数值，我们进行迭代优化，引导神经网络参数到适当的值，使用给定的标签进行监督。图[2](#S4.F2
    "Figure 2 ‣ 4.1 Supervised Learning ‣ 4 Standard Neural Network Models and Tasks
    ‣ A Survey of Deep Learning for Scientific Discovery")显示了深度学习监督学习设置的示意图。
- en: Supervised learning is the most basic yet most critical method for training
    deep neural networks. As will be seen through the subsequent sections, there can
    be significant diversity in the kinds of (data, label) pairs used. Even in settings
    where clear (data, label) pairs are not possible to collect (Sections [6](#S6
    "6 Doing More with Less Data ‣ A Survey of Deep Learning for Scientific Discovery"),
    [6.2](#S6.SS2 "6.2 Semi-Supervised Learning ‣ 6 Doing More with Less Data ‣ A
    Survey of Deep Learning for Scientific Discovery")), the training problem is often
    reformulated and recast into a supervised learning framework.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习是训练深度神经网络最基本却最关键的方法。正如在后续章节中所见，使用的（数据，标签）对的种类可能会有显著的多样性。即使在无法收集明确（数据，标签）对的环境中（章节[6](#S6
    "6 Doing More with Less Data ‣ A Survey of Deep Learning for Scientific Discovery")，[6.2](#S6.SS2
    "6.2 Semi-Supervised Learning ‣ 6 Doing More with Less Data ‣ A Survey of Deep
    Learning for Scientific Discovery")），训练问题通常会重新表述并转化为监督学习框架。
- en: 4.2 Multilayer Perceptrons
  id: totrans-113
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 多层感知机
- en: The first and most basic kind of deep neural network is the multilayer perceptron.
    These models consist of a stack of fully connected layers (matrix multiplications)
    interleaved with a nonlinear transform.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种也是最基本的深度神经网络类型是多层感知机。这些模型由一系列完全连接的层（矩阵乘法）与非线性变换交替组成。
- en: Despite their simplicity, they are useful for problems where the data might
    consist of a set of distinct, (possibly categorical) features, for example, tabular
    data. These models have more expressive power than logistic/linear regression,
    though those methods would be a good first step to try. One way to apply these
    models might be to first preprocess the data to compute the distinct set of features
    likely to be important, and use this as input. [https://github.com/rasbt/deeplearning-models](https://github.com/rasbt/deeplearning-models)
    provides some implementations of some example multilayer perceptron architectures.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管它们简单，但对于数据可能由一组不同的（可能是分类的）特征组成的问题来说非常有用，例如表格数据。这些模型比逻辑回归/线性回归具有更强的表达能力，尽管这些方法作为第一步尝试是一个不错的选择。应用这些模型的一种方法是首先对数据进行预处理，以计算可能重要的不同特征集，并将其用作输入。[https://github.com/rasbt/deeplearning-models](https://github.com/rasbt/deeplearning-models)提供了一些示例多层感知机架构的实现。
- en: Scientific Examples
  id: totrans-116
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学实例
- en: One recent scientific example is given by the use of simple MLPs for pharamaceutical
    formulation [[256](#bib.bib256)], developing variants of a drug that is stable
    and safe for patient use.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 一个最近的科学例子是使用简单的MLP来进行药物配方[[256](#bib.bib256)]，开发一种稳定且对患者安全的药物变体。
- en: 4.3 Convolutional Neural Networks
  id: totrans-118
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 卷积神经网络
- en: These are arguably the most well known family of neural networks, and are very
    useful in working with any kind of image data. They are characterized by having
    convolutional layers, which allow the neural network to reuse parameters across
    different spatial locations of an image. This is a highly useful inductive bias
    for image data, and helping with efficiently learning good features, some, like
    Gabor filters, which correspond to traditional computer vision techniques. Convolutional
    neural networks (CNNs) have so many possible uses that we overview some of the
    most ubiquitous tasks separately below.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 这些可以说是最知名的神经网络系列，非常适合处理任何类型的图像数据。它们的特点是拥有卷积层，这使得神经网络能够在图像的不同空间位置重用参数。这是图像数据的一个非常有用的归纳偏差，有助于有效学习良好的特征，一些特征，如Gabor滤波器，对应于传统的计算机视觉技术。卷积神经网络（CNNs）有许多可能的用途，下面我们单独概述一些最常见的任务。
- en: 4.3.1 Image Classification
  id: totrans-120
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 图像分类
- en: This is arguably the simplest and most well known application of convolutional
    neural networks. The model is given an input image, and wants to output a class
    — one of a (typically) mutually exclusive set of labels for that image. The earlier
    example, of mapping a chest x-ray image to a binary disease label, is precisely
    image classification.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 这可以说是卷积神经网络中最简单和最知名的应用。模型接收一个输入图像，并希望输出一个类别 —— 这是该图像的一个（通常是）互斥的标签集合中的一个。之前的例子中，将胸部X光图像映射到一个二进制疾病标签，正是图像分类的典型例子。
- en: 'Convolutional neural networks for image classification is an extremely common
    application of deep learning. There many different types of CNN models for classification:
    VGG — a simple stack of convolutional layers followed by a fully connected layer
    [[214](#bib.bib214)], ResNets — which are a family of convolutional networks of
    different sizes and depths and skip connections [[79](#bib.bib79)], DenseNets
    — another family of models where unlike standard neural networks, every layer
    in a "block" is connected to every other layer [[94](#bib.bib94)]. More recent,
    complex models include ResNeXt [[253](#bib.bib253)] and recently EfficientNets,
    which have separate scaling factors for network depth, width and the spatial resolution
    of the input image [[223](#bib.bib223)]. Tutorials, implementations and pretrained
    versions of many of these models can be found in the references given in Section
    [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey of Deep Learning for
    Scientific Discovery").'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络用于图像分类是深度学习中极其常见的应用。分类的CNN模型有许多不同类型：VGG — 一个简单的卷积层堆叠，后接一个全连接层 [[214](#bib.bib214)]，ResNets
    — 这是一个不同大小和深度的卷积网络系列，具有跳跃连接 [[79](#bib.bib79)]，DenseNets — 另一个模型系列，其中“块”中的每一层都与其他所有层相连
    [[94](#bib.bib94)]。更新的复杂模型包括 ResNeXt [[253](#bib.bib253)] 和最近的 EfficientNets，这些模型为网络深度、宽度和输入图像的空间分辨率设置了不同的缩放因子
    [[223](#bib.bib223)]。许多这些模型的教程、实现和预训练版本可以在第 [3](#S3 "3 Deep Learning Libraries
    and Resources ‣ A Survey of Deep Learning for Scientific Discovery") 节中的参考文献中找到。
- en: 'Scientific Examples:'
  id: totrans-123
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学例子：
- en: Image classification has found many varied scientific applications, such as
    in analyzing cryoEM data [[226](#bib.bib226)] (with associated code [https://github.com/cramerlab/boxnet](https://github.com/cramerlab/boxnet)).
    An especially large body of work has looked at medical imaging uses of image classification,
    specifically, using CNNs to predict disease labels. Examples range from ophthalmology
    [[72](#bib.bib72)], radiology (2D x-rays and 3D CT scans) [[258](#bib.bib258),
    [5](#bib.bib5), [185](#bib.bib185)], pathology [[135](#bib.bib135), [55](#bib.bib55)],
    analyzing brain scans (PET, fMRI) [[202](#bib.bib202), [45](#bib.bib45)]. An excellent
    survey of the numerous papers in this area is given by [[228](#bib.bib228)].
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类已经在许多不同的科学应用中找到了用武之地，例如分析冷冻电镜数据 [[226](#bib.bib226)]（相关代码见 [https://github.com/cramerlab/boxnet](https://github.com/cramerlab/boxnet)）。特别大量的工作集中在医学影像的图像分类应用上，具体来说，是利用卷积神经网络（CNNs）来预测疾病标签。例子包括眼科学
    [[72](#bib.bib72)]、放射学（二维X射线和三维CT扫描） [[258](#bib.bib258), [5](#bib.bib5), [185](#bib.bib185)]、病理学
    [[135](#bib.bib135), [55](#bib.bib55)]、脑扫描分析（PET，fMRI） [[202](#bib.bib202), [45](#bib.bib45)]。关于这一领域众多论文的优秀综述见
    [[228](#bib.bib228)]。
- en: 4.3.2 Object Detection
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 目标检测
- en: '![Refer to caption](img/e9c875f3fc0318363d0584bb252e1086.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e9c875f3fc0318363d0584bb252e1086.png)'
- en: 'Figure 3: Differences between Image Classification, Object Detection, Semantic
    Segmentation and Instance Segmentation tasks. Image source [[1](#bib.bib1)] The
    figure illustrates the differences between classification, object detection, semantic
    segmentation and instance segmentation. In classification, the whole image gets
    a single label (balloons), while in object detection, each balloon is also localized
    with a bounding box. In semantic segmentation, all the pixels corresponding to
    balloon are identified, while in instance segmentation, each individual balloon
    is identified separately.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：图像分类、目标检测、语义分割和实例分割任务的差异。图片来源 [[1](#bib.bib1)] 该图说明了分类、目标检测、语义分割和实例分割之间的差异。在分类中，整张图片获得一个标签（气球），而在目标检测中，每个气球还会被定位一个边界框。在语义分割中，所有对应于气球的像素被识别，而在实例分割中，每个单独的气球会被单独识别。
- en: Image classification can be thought of as a global summary of the image. Object
    detection dives into some of the lower level details of the image, and looks at
    identifying and localizing different objects in the image. For example, given
    an input image of an outdoor scene having a dog, a person and a tree, object detection
    would look at both identifying the presence of the dog, person and tree and ‘circle
    their location’ in the image — specifically, put a bounding box around each of
    them. The supervised learning task is thus to take an input image and output the
    coordinates of these bounding boxes, as well as categorizing the kind of object
    they contain.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类可以看作是对图像的整体总结。目标检测则深入到图像的一些较低级别的细节，识别并定位图像中的不同对象。例如，给定一张户外场景的输入图片，包含一只狗、一位人和一棵树，目标检测将不仅识别出狗、人和树的存在，还会在图像中‘圈出它们的位置’——具体来说，为它们每个加上一个边界框。因此，监督学习任务是接受一张输入图像并输出这些边界框的坐标，以及对其包含的对象进行分类。
- en: Like image classification, there are many high performing and well established
    convolutional architectures for object detection. Because of the intricacy of
    the output task, these models tend to be more complex with a backbone component
    (using an image classification model) and a region proposal component for bounding
    box proposals. But there are still many pretrained models available to download.
    One of the most successful early models was Faster R-CNN [[192](#bib.bib192)],
    which significantly sped up the slow bounding box proposal component. Since then
    there have been many improved models, including YOLOv3 [[191](#bib.bib191)], and
    most recently EfficientDets [[224](#bib.bib224)]. Arguably the most popular recent
    architecture however has been Mask R-CNN and its variants [[78](#bib.bib78), [248](#bib.bib248)].
    Mask R-CNN performs some segmentation as well as object detection (see below).
    Besides some of the resources mentioned in Section [3](#S3 "3 Deep Learning Libraries
    and Resources ‣ A Survey of Deep Learning for Scientific Discovery"), a good source
    of code and models is [https://github.com/rbgirshick](https://github.com/rbgirshick),
    one of the key authors in a long line of these object detection models. (Note
    though that there are many other popular implementations, such as [https://github.com/matterport/Mask_RCNN](https://github.com/matterport/Mask_RCNN).)
    This in depth article [towardsdatascience object detection Faster R-CNN](https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a)
    offers a detailed tutorial on downloading, setting up and training an object detection
    model, including helpful pointers to data collection and annotation (the latter
    using [https://rectlabel.com/](https://rectlabel.com/).) Most recently the Detectron2
    system [https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)
    [[248](#bib.bib248)] builds on Mask R-CNN and offers many varied image task functionalities.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于图像分类，物体检测也有许多高性能且成熟的卷积架构。由于输出任务的复杂性，这些模型通常更复杂，包含一个骨干组件（使用图像分类模型）和一个区域提议组件用于边界框提议。但仍有许多预训练模型可供下载。其中一个早期最成功的模型是Faster
    R-CNN [[192](#bib.bib192)]，它显著加快了缓慢的边界框提议组件。从那时起，出现了许多改进的模型，包括YOLOv3 [[191](#bib.bib191)]，以及最近的EfficientDets
    [[224](#bib.bib224)]。然而，近年来最受欢迎的架构可能是Mask R-CNN及其变体[[78](#bib.bib78), [248](#bib.bib248)]。Mask
    R-CNN不仅执行分割，还进行物体检测（见下文）。除了第[3](#S3 "3 Deep Learning Libraries and Resources ‣
    A Survey of Deep Learning for Scientific Discovery")节中提到的一些资源外，一个很好的代码和模型来源是[https://github.com/rbgirshick](https://github.com/rbgirshick)，这是这些物体检测模型长期系列中的关键作者之一。（不过请注意，还有许多其他流行的实现，例如[https://github.com/matterport/Mask_RCNN](https://github.com/matterport/Mask_RCNN)。）这篇深入的文章[towardsdatascience
    object detection Faster R-CNN](https://towardsdatascience.com/faster-r-cnn-object-detection-implemented-by-keras-for-custom-data-from-googles-open-images-125f62b9141a)提供了一个详细的教程，讲解如何下载、设置和训练一个物体检测模型，包括数据收集和注释（后者使用[https://rectlabel.com/](https://rectlabel.com/)）的有用指引。最近，Detectron2系统[https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2)
    [[248](#bib.bib248)]基于Mask R-CNN，并提供了许多多样的图像任务功能。
- en: 'Scientific Examples:'
  id: totrans-130
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例：
- en: Object detection has also gained significant attention across different scientific
    applications. It has been used in many medical settings to localize features of
    interest, for example, tumor cells across different imaging modalities [[125](#bib.bib125),
    [269](#bib.bib269)] or fractures in radiology [[199](#bib.bib199), [227](#bib.bib227)].
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测在不同的科学应用中也引起了广泛关注。它已被应用于许多医学场景中，用于定位感兴趣的特征，例如不同影像模态下的肿瘤细胞[[125](#bib.bib125),
    [269](#bib.bib269)]或放射学中的骨折[[199](#bib.bib199), [227](#bib.bib227)]。
- en: 4.3.3 Semantic Segmentation and Instance Segmentation
  id: totrans-132
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.3 语义分割与实例分割
- en: Segmentation dives into the lowest possible level of detail — categorizing every
    single image pixel. In semantic segmentation, we want to categorize pixels according
    to the high level group they belong to. For example, suppose we are given an image
    of a street, with a road, different vehicles, pedestrians, etc. We would like
    to determine if a pixel is part of any pedestrian, part of any vehicle or part
    of the road — i.e. label the image pixels as either pedestrian, vehicle or road.
    Instance segmentation is even more intricate, where not only do we want to categorize
    each pixel in this way, but do so separately for each instance (and provide instance
    specific bounding boxes like in object detection). The differences are illustrated
    in Figure [3](#S4.F3 "Figure 3 ‣ 4.3.2 Object Detection ‣ 4.3 Convolutional Neural
    Networks ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning
    for Scientific Discovery") (sourced from [[1](#bib.bib1)].) Returning to the example
    of the image of the street, suppose the image has three pedestrians. In semantic
    segmentation, all of the pixels making up these three pedestrians would fall under
    the same category – pedestrian. In instance segmentation, these pixels would be
    further subdivided into those belonging to pedestrian one, pedestrian two or pedestrian
    three.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 分割技术深入到可能的最细节层次——对每个图像像素进行分类。在语义分割中，我们希望根据像素所属的高级组别对像素进行分类。例如，假设我们有一张街道的图像，其中包含道路、不同的车辆、行人等。我们希望确定一个像素是否属于任何行人、任何车辆或道路——即将图像像素标记为行人、车辆或道路。实例分割则更为复杂，我们不仅要以这种方式对每个像素进行分类，还要对每个实例分别进行分类（并提供像目标检测中的实例特定的边界框）。这些差异在图[3](#S4.F3
    "Figure 3 ‣ 4.3.2 Object Detection ‣ 4.3 Convolutional Neural Networks ‣ 4 Standard
    Neural Network Models and Tasks ‣ A Survey of Deep Learning for Scientific Discovery")中有所说明（来源于[[1](#bib.bib1)]）。回到街道图像的例子，假设图像中有三位行人。在语义分割中，构成这三位行人的所有像素将被归入同一类别——行人。在实例分割中，这些像素将进一步细分为属于行人一、行人二或行人三的像素。
- en: Because segmentation models must categorize every pixel, their output is not
    just a single class label, or a bounding box, but a full image. As a result, the
    neural network architectures for segmentation have a slightly different structure
    that helps them better preserve spatial information about the image. A highly
    popular and successful architecture, particularly for scientific applications,
    has been the U-net [[196](#bib.bib196)], which also has a 3d volumetric variant
    [[33](#bib.bib33)]. Other architectures include FCNs (Fully Convolutional Networks)
    [[136](#bib.bib136)], SegNet [[9](#bib.bib9)] and the more recent Object Contextual
    Representations [[260](#bib.bib260)]. A couple of nice surveys on semantic segmentation
    methods are given by [towardsdatascience Semantic Segementation with Deep Learning](https://towardsdatascience.com/semantic-segmentation-with-deep-learning-a-guide-and-code-e52fc8958823)
    and [https://sergioskar.github.io/Semantic_Segmentation/](https://sergioskar.github.io/Semantic_Segmentation/).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 由于分割模型必须对每个像素进行分类，它们的输出不仅仅是单一的类别标签或边界框，而是完整的图像。因此，分割的神经网络架构具有略微不同的结构，以帮助更好地保留图像的空间信息。一种特别受欢迎且成功的架构，尤其适用于科学应用，是
    U-net [[196](#bib.bib196)]，它还有一个 3d 体积变体 [[33](#bib.bib33)]。其他架构包括 FCNs（全卷积网络）
    [[136](#bib.bib136)]、SegNet [[9](#bib.bib9)] 和最近的 Object Contextual Representations
    [[260](#bib.bib260)]。关于语义分割方法的一些很好的综述可以参考 [towardsdatascience Semantic Segmentation
    with Deep Learning](https://towardsdatascience.com/semantic-segmentation-with-deep-learning-a-guide-and-code-e52fc8958823)
    和 [https://sergioskar.github.io/Semantic_Segmentation/](https://sergioskar.github.io/Semantic_Segmentation/)。
- en: For instance segmentation, Mask R-CNN [[78](#bib.bib78)] and its variants [[248](#bib.bib248)]
    have been extremely popular. This tutorial [Mask R-CNN tutorial with code](https://towardsdatascience.com/mask-r-cnn-for-ship-detection-segmentation-a1108b5a083)
    provides a step by step example application. The recent Detectron2 package [[248](#bib.bib248)]
    ([https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2))
    also offers this functionality.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 对于实例分割，Mask R-CNN [[78](#bib.bib78)] 及其变体 [[248](#bib.bib248)] 一直非常受欢迎。这个教程
    [Mask R-CNN tutorial with code](https://towardsdatascience.com/mask-r-cnn-for-ship-detection-segmentation-a1108b5a083)
    提供了一个逐步的示例应用。最近的 Detectron2 包 [[248](#bib.bib248)] ([https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2))
    也提供了这一功能。
- en: 'Scientific Examples:'
  id: totrans-136
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学实例：
- en: Out of all of the different types of imaging prediction problems, segmentation
    methods have been especially useful for (bio)medical applications. Examples include
    segmenting brain MR images [[156](#bib.bib156), [236](#bib.bib236)], identifying
    key regions of cells in different tissues [[254](#bib.bib254), [217](#bib.bib217)]
    and even studying bone structure [[129](#bib.bib129)].
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在所有不同类型的成像预测问题中，分割方法对于（生物）医学应用特别有用。示例包括分割脑部 MRI 图像 [[156](#bib.bib156), [236](#bib.bib236)]、识别不同组织中细胞的关键区域
    [[254](#bib.bib254), [217](#bib.bib217)]，甚至研究骨骼结构 [[129](#bib.bib129)]。
- en: 4.3.4 Super-Resolution
  id: totrans-138
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.4 超分辨率
- en: Super resolution is a technique for transforming low resolution images to high
    resolution images. This problem has been tackled both using convolutional neural
    networks and supervised learning, as well as generative models.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率是一种将低分辨率图像转换为高分辨率图像的技术。这个问题已经通过卷积神经网络和监督学习以及生成模型来解决。
- en: 'Super resolution formally defined is an underdetermined problem, as there may
    be many possible high resolution mappings for a low resolution image. Traditional
    techniques imposed constraints such as sparsity to find a solution. One of the
    first CNNs for super resolution, SRCNN [[50](#bib.bib50)] outlines the correspondences
    between sparse coding approaches and convolutional neural networks. More recently,
    Residual Dense Networks [[270](#bib.bib270)] have been a popular approach for
    super-resolution on standard benchmarks (with code available [https://github.com/yulunzhang/RDN](https://github.com/yulunzhang/RDN)),
    as well as Predictive Filter Flow [[114](#bib.bib114)], (code: [https://github.com/aimerykong/predictive-filter-flow](https://github.com/aimerykong/predictive-filter-flow))
    which has also looked at image denoising and deblurring. In some of the scientific
    applications below, U-nets have also been successful for super resolution.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率形式上被定义为一个欠定问题，因为对于低分辨率图像，可能存在许多高分辨率的映射。传统技术通过施加稀疏性等约束来寻找解决方案。超分辨率的第一个 CNN
    之一 SRCNN [[50](#bib.bib50)] 概述了稀疏编码方法与卷积神经网络之间的对应关系。最近，Residual Dense Networks
    [[270](#bib.bib270)] 在标准基准测试中成为超分辨率的流行方法（代码可用 [https://github.com/yulunzhang/RDN](https://github.com/yulunzhang/RDN)），以及
    Predictive Filter Flow [[114](#bib.bib114)]（代码：[https://github.com/aimerykong/predictive-filter-flow](https://github.com/aimerykong/predictive-filter-flow)），该方法也涉及图像去噪和去模糊。在下面的一些科学应用中，U-net
    也在超分辨率方面取得了成功。
- en: 'Scientific Examples:'
  id: totrans-141
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例：
- en: 'Super resolution is arguably even more useful for scientific settings than
    standard natural image benchmarks. Two recent papers look at U-nets for super-resolution
    of fluorescence microscopy [[245](#bib.bib245)] (code: [https://csbdeep.bioimagecomputing.com/](https://csbdeep.bioimagecomputing.com/))
    and electron microscopy [[56](#bib.bib56)]. Other examples include super resolution
    of chest CT scans [[231](#bib.bib231)] and Brain MRIs [[31](#bib.bib31)].'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 超分辨率在科学环境中可能比标准自然图像基准更有用。两篇最近的论文探讨了 U-net 在荧光显微镜 [[245](#bib.bib245)]（代码：[https://csbdeep.bioimagecomputing.com/](https://csbdeep.bioimagecomputing.com/)）和电子显微镜
    [[56](#bib.bib56)] 超分辨率中的应用。其他示例包括胸部 CT 扫描 [[231](#bib.bib231)] 和脑部 MRI [[31](#bib.bib31)]
    的超分辨率。
- en: 4.3.5 Image Registration
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.5 图像配准
- en: Image registration considers the problem of aligning two input images to each
    other. Particularly relevant to scientific applications, the two input images
    might be from different imaging modalities (e.g. a 3D scan and a 2D image), or
    mapping a moving image to a canonical template image (such as in MRIs.) The alignment
    enables better identification and analysis of features of interest.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准考虑了将两张输入图像对齐的问题。特别是在科学应用中，两张输入图像可能来自不同的成像模式（例如，3D 扫描和 2D 图像），或者将移动图像映射到标准模板图像（例如
    MRI）。这种对齐可以更好地识别和分析感兴趣的特征。
- en: The potential of image registration is primarily demonstrated through different
    scientific applications. At the heart of the technique is a convolutional neural
    network, often with an encoder-decoder structure (similar to the U-net [[196](#bib.bib196)])
    to guide the alignment of two images. Note that while this underlying model is
    trained through supervised learning, many registration methods do not require
    explicit labels, using similarity functions and smoothness constraints to provide
    supervision. For example, [[12](#bib.bib12)] develop an unsupervised method to
    perform alignment for Brain MRIs. The code for this and several followup papers
    [[13](#bib.bib13), [39](#bib.bib39)] provides a helpful example for building off
    of and applying these methods [https://github.com/voxelmorph/voxelmorph](https://github.com/voxelmorph/voxelmorph).
    Other useful resources include [https://github.com/ankurhanda/gvnn](https://github.com/ankurhanda/gvnn)
    (with corresponding paper [[75](#bib.bib75)]) a library for learning common parametric
    image transformations.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准的潜力主要通过不同的科学应用来展示。该技术的核心是卷积神经网络，通常采用编码器-解码器结构（类似于 U-net [[196](#bib.bib196)]），以指导两幅图像的对齐。请注意，虽然这个基础模型是通过监督学习进行训练的，但许多配准方法不需要显式标签，而是使用相似性函数和光滑性约束来提供监督。例如，[[12](#bib.bib12)]
    开发了一种无监督方法来对齐脑部MRI。这些方法的代码以及几篇后续论文 [[13](#bib.bib13), [39](#bib.bib39)] 提供了一个很好的例子，可用于构建和应用这些方法
    [https://github.com/voxelmorph/voxelmorph](https://github.com/voxelmorph/voxelmorph)。其他有用的资源包括
    [https://github.com/ankurhanda/gvnn](https://github.com/ankurhanda/gvnn)（对应论文
    [[75](#bib.bib75)]）用于学习常见的参数化图像变换的库。
- en: 4.3.6 Pose Estimation
  id: totrans-146
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.6 姿态估计
- en: '![Refer to caption](img/6ea8b5ae71622c92c3526fd300d4fa61.png)'
  id: totrans-147
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6ea8b5ae71622c92c3526fd300d4fa61.png)'
- en: 'Figure 4: Pose Estimation. Image source [[218](#bib.bib218)] The task of pose
    estimation, specifically multi-person 2D (human) pose-estimation is depicted in
    the figure. The neural network model predicts the positions of the main joints
    (keypoints), which are combined with a body model to get the stick-figure like
    approximations of pose overlaid on the multiple humans in the image. Variants
    of these techniques have been used to study animal behaviors in scientific settings.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 姿态估计。图片来源 [[218](#bib.bib218)] 图中展示了姿态估计的任务，特别是多人人体2D姿态估计。神经网络模型预测主要关节（关键点）的位置，这些位置与人体模型结合，得到覆盖在图像中多个人体上的类似棒人图的姿态近似。这些技术的变体已被用于科学环境下的动物行为研究。'
- en: Pose estimation, and most popularly human pose estimation, studies the problem
    of predicting the pose of a human in a given image. In particular, a deep neural
    network model is trained to identify the location of the main joints, the keypoints
    (e.g. knees, elbows, head) of the person in the image. These predictions are combined
    with existing body models to get the full stick-figure-esque output summarizing
    the pose. (See Figure [4](#S4.F4 "Figure 4 ‣ 4.3.6 Pose Estimation ‣ 4.3 Convolutional
    Neural Networks ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep
    Learning for Scientific Discovery"), sourced from [[218](#bib.bib218)], for an
    illustration.)
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 姿态估计，特别是人体姿态估计，研究了预测给定图像中人体姿态的问题。具体而言，深度神经网络模型被训练以识别图像中主要关节的位置，即关键点（如膝盖、肘部、头部）。这些预测与现有的身体模型结合，得到完整的类似棒人图的输出，以总结姿态。（参见图
    [4](#S4.F4 "Figure 4 ‣ 4.3.6 Pose Estimation ‣ 4.3 Convolutional Neural Networks
    ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning for Scientific
    Discovery")，来源 [[218](#bib.bib218)]，以作说明。）
- en: (2D) Human pose estimation is a core problem in computer vision with multiple
    benchmark datasets, and has seen numerous convolutional architectures developed
    to tackle it. Some of the earlier models include a multi-stage neural network
    introduced by [[244](#bib.bib244)], and a stacked hourglass model [[158](#bib.bib158)]
    that alternatingly combines high and low resolutions of the intermediate representations.
    More recently, HRNet [[218](#bib.bib218)], which keeps a high resolution representation
    throughout the model is a top performing architecture (code at [https://github.com/leoxiaobin/deep-high-resolution-net.pytorch](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)).
    Also of interest might be [[24](#bib.bib24)] provides an end-to-end system for
    multiperson pose detection in the corresponding code repository [https://github.com/CMU-Perceptual-Computing-Lab/openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: (2D) 人体姿势估计是计算机视觉中的一个核心问题，拥有多个基准数据集，并且已经出现了许多卷积架构来解决它。一些早期的模型包括由[[244](#bib.bib244)]介绍的多阶段神经网络，以及一个堆叠沙漏模型[[158](#bib.bib158)]，该模型交替地结合了中间表示的高分辨率和低分辨率。最近，HRNet[[218](#bib.bib218)]，它在整个模型中保持高分辨率表示，是一种表现优异的架构（代码见[https://github.com/leoxiaobin/deep-high-resolution-net.pytorch](https://github.com/leoxiaobin/deep-high-resolution-net.pytorch)）。另一个值得关注的可能是[[24](#bib.bib24)]提供了一个用于多人的姿势检测的端到端系统，其代码库为[https://github.com/CMU-Perceptual-Computing-Lab/openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose)。
- en: 'Scientific Examples:'
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例：
- en: Pose estimation has gained significant interest in neuroscience settings, where
    videos of animals are recorded, and automatically predicting poses in the image
    can help identify important behaviors. An example is given by [[146](#bib.bib146),
    [147](#bib.bib147)], with associated code [http://www.mousemotorlab.org/deeplabcut](http://www.mousemotorlab.org/deeplabcut).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 姿势估计在神经科学领域引起了广泛关注，其中记录了动物的视频，自动预测图像中的姿势有助于识别重要行为。相关的示例由[[146](#bib.bib146)、[147](#bib.bib147)]给出，并附有代码[http://www.mousemotorlab.org/deeplabcut](http://www.mousemotorlab.org/deeplabcut)。
- en: 4.3.7 Other Tasks with Convolutional Neural Networks
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.7 卷积神经网络的其他任务
- en: In the preceding sections, we have overviewed some of the most common tasks
    for which convolutional neural networks are used. However, there are many additional
    use cases of these models that we have not covered, including video prediction
    [[57](#bib.bib57)], action recognition [[52](#bib.bib52)] and style transfer [[64](#bib.bib64)].
    We hope that the provided references and resources enable future investigation
    into some of these methods also.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们概述了一些最常见的卷积神经网络应用任务。然而，这些模型还有许多额外的应用场景，我们未曾涉及，包括视频预测[[57](#bib.bib57)]、动作识别[[52](#bib.bib52)]和风格迁移[[64](#bib.bib64)]。我们希望提供的参考文献和资源能促进对这些方法的进一步研究。
- en: 4.4 Graph Neural Networks
  id: totrans-155
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 图神经网络
- en: Many datasets, such as (social) network data and chemical molecules have a graph
    structure to them, consisting of vertices connected by edges. An active area of
    research, graph neural networks, has looked at developing deep learning methods
    to work well with this kind of data. The input graph consists of nodes $v$ having
    some associated feature vector $h_{v}$, and sometimes edges $e_{uv}$ also having
    associated features $z_{e_{uv}}$. For example, nodes $v$ might correspond to different
    atoms, and the edges $e_{uv}$ to the different kinds of chemical bonds between
    atoms. At a high level, most graph neural networks compute useful information
    from the data by (i) using the feature vectors of the neighbors of each vertex
    $v$ to compute information on the input graph instance (ii) using this information
    to update the feature vector of $v$. This process, which respects the connectivity
    of the graph, is often applied iteratively, with the final output either at the
    vertex level (Are meaningful vertex feature vectors computed?) or at the level
    of the full input graph (Is some global property of the entire graph correctly
    identified?)
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 许多数据集，例如（社交）网络数据和化学分子，都具有图结构，由顶点通过边连接组成。一个活跃的研究领域是图神经网络，它致力于开发深度学习方法，以便更好地处理这种数据。输入图由具有一些相关特征向量
    $h_{v}$ 的节点 $v$ 组成，有时边 $e_{uv}$ 也具有相关特征 $z_{e_{uv}}$。例如，节点 $v$ 可能对应不同的原子，边 $e_{uv}$
    对应原子之间的不同化学键。在高级层面，大多数图神经网络通过（i）使用每个顶点 $v$ 的邻居的特征向量来计算输入图实例的信息，（ii）利用这些信息更新 $v$
    的特征向量，从数据中计算出有用的信息。这个过程尊重图的连通性，通常会迭代应用，最终输出可能是在顶点级别（是否计算了有意义的顶点特征向量？）或整个输入图的级别（是否正确识别了整个图的某些全局属性？）
- en: Application Characteristics
  id: totrans-157
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 应用特性
- en: Problems where the data has an inherent graph structure, and the goal is to
    learn some function on this graph structure — either at the per vertex level or
    a global property of the entire graph. There are also spatio-temporal graph neural
    networks — performing predictions on graph structures evolving over time.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这些问题中，数据具有固有的图结构，目标是学习该图结构上的某些函数——无论是在每个顶点级别还是整个图的全局属性。还有时空图神经网络——对随时间演变的图结构进行预测。
- en: Technical References
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 技术参考
- en: Although most graph neural networks follow the high level structure of aggregating
    information from vertex neighbors and using this information to update feature
    vectors, there are many many different architectural variants, with connections
    to other neural network models such as convolutional nets and recurrent models.
    Recent work has also looked at spatio-temporal graph networks for problems like
    action recognition in video [[124](#bib.bib124)]. A nice unification of many of
    the first popular methods, such as [[53](#bib.bib53), [15](#bib.bib15), [127](#bib.bib127)],
    is given by [[67](#bib.bib67)]. A more recent survey paper [[250](#bib.bib250)],
    provides an extremely comprehensive overview of the different kinds of architectures,
    problems, benchmark datasets and open source resources. Some useful code repositories
    include [https://github.com/rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric),
    [https://github.com/deepmind/graph_nets](https://github.com/deepmind/graph_nets)
    and [https://github.com/dmlc/dgl](https://github.com/dmlc/dgl), which together
    cover most of the popular deep learning frameworks.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管大多数图神经网络遵循从顶点邻居汇总信息并使用这些信息更新特征向量的高级结构，但存在许多不同的架构变体，并与卷积网络和递归模型等其他神经网络模型有关。近期的研究还探讨了时空图网络在视频动作识别等问题上的应用
    [[124](#bib.bib124)]。对许多第一个流行方法的良好统一，例如 [[53](#bib.bib53), [15](#bib.bib15), [127](#bib.bib127)]，由
    [[67](#bib.bib67)] 给出。一个更近期的调查论文 [[250](#bib.bib250)] 提供了对不同架构、问题、基准数据集和开源资源的极其全面的概述。一些有用的代码库包括
    [https://github.com/rusty1s/pytorch_geometric](https://github.com/rusty1s/pytorch_geometric)、[https://github.com/deepmind/graph_nets](https://github.com/deepmind/graph_nets)
    和 [https://github.com/dmlc/dgl](https://github.com/dmlc/dgl)，它们涵盖了大多数流行的深度学习框架。
- en: Scientific Examples
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例
- en: Graph neural networks have been very popular for several chemistry tasks, such
    as predicting molecular properties [[53](#bib.bib53), [93](#bib.bib93), [67](#bib.bib67),
    [103](#bib.bib103)], determining protein interfaces [[60](#bib.bib60), [229](#bib.bib229)]
    and even generating candidate molecules [[41](#bib.bib41), [21](#bib.bib21)].
    A useful library for many of these chemistry tasks is [https://github.com/deepchem](https://github.com/deepchem),
    which also has an associated benchmark task [[249](#bib.bib249)]. A detailed tutorial
    of different graph neural networks and their use in molecule generation can be
    seen at [https://www.youtube.com/watch?v=VXNjCAmb6Zw](https://www.youtube.com/watch?v=VXNjCAmb6Zw).
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图神经网络在多个化学任务中非常受欢迎，比如预测分子属性 [[53](#bib.bib53), [93](#bib.bib93), [67](#bib.bib67),
    [103](#bib.bib103)]、确定蛋白质界面 [[60](#bib.bib60), [229](#bib.bib229)]，甚至生成候选分子 [[41](#bib.bib41),
    [21](#bib.bib21)]。对于这些化学任务，[https://github.com/deepchem](https://github.com/deepchem)
    是一个有用的库，它还具有相关的基准任务 [[249](#bib.bib249)]。关于不同图神经网络及其在分子生成中的应用的详细教程可以在 [https://www.youtube.com/watch?v=VXNjCAmb6Zw](https://www.youtube.com/watch?v=VXNjCAmb6Zw)
    查看。
- en: 4.5 Neural Networks for Sequence Data
  id: totrans-163
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 序列数据的神经网络
- en: A very common attribute for data is to have a sequential structure. This might
    be frames in a video, amino acid sequences for a protein or words in a sentence.
    Developing neural network models to work with sequence data has been one of the
    most extensive areas of research in the past few years. A large fraction of this
    has been driven by progress on tasks in natural language processing, which focuses
    on getting computers to work with the language used by people to communicate.
    Two popular tasks in this area, which have seen significant advances, have been
    machine translation — developing deep learning models to translate from one language
    to another and question answering — taking as input a (short) piece of text and
    answering a question about it. In the following sections, we first overview some
    of the main NLP tasks that have driven forward sequence modelling and then the
    neural network models designed to solve these tasks.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 数据的一个非常常见的属性是具有序列结构。这可能是视频中的帧、蛋白质的氨基酸序列或句子中的单词。开发能够处理序列数据的神经网络模型是过去几年中最广泛的研究领域之一。这在很大程度上是受到自然语言处理任务进展的推动，自然语言处理专注于使计算机能够处理人们用来交流的语言。在这个领域，有两个受到显著进展的热门任务，分别是机器翻译——开发深度学习模型以将一种语言翻译成另一种语言，以及问答——以（短）文本为输入并回答有关它的问题。在接下来的章节中，我们首先概述了一些推动序列建模的主要自然语言处理任务，然后介绍了解决这些任务的神经网络模型。
- en: 4.5.1 Language Modelling (Next Token Prediction)
  id: totrans-165
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.1 语言建模（下一个词预测）
- en: Language modelling is a training method where the deep learning model takes
    as input the tokens of the sequence up to time/position $t$, and then uses these
    to predict token $t+1$. This is in fact a self-supervised training method (see
    Section [6](#S6 "6 Doing More with Less Data ‣ A Survey of Deep Learning for Scientific
    Discovery")), where the data provides a natural set of labels without additional
    labelling needed. In the NLP context, the neural network is fed in a sequence
    of words, corresponding to a sentence or passage of text, and it tries to predict
    the next word. For example, given a sentence, "The cat sat on the roof", the network
    would first be given as input "The" and asked to predict "cat", then be fed in
    "The cat" and asked to predict "sat", and so on. (There are some additional details
    in implementation, but this is the high level idea.) Because of the easy availability
    of data/labels, and the ability to use language modelling at different levels
    — for words and even for characters, it has been a popular benchmark in natural
    language, and also for capturing sequence dependencies in scientific applications,
    such as protein function prediction [[77](#bib.bib77), [80](#bib.bib80)], and
    using the hidden representations as part of a larger pipeline for protein structure
    prediction in AlphaFold [[205](#bib.bib205)] (with opensourced code [https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13](https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13).)
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 语言建模是一种训练方法，其中深度学习模型以序列中到时间/位置 $t$ 的令牌为输入，然后使用这些令牌预测令牌 $t+1$。这实际上是一种自监督训练方法（见第
    [6](#S6 "6 使用更少数据做更多事 ‣ 深度学习在科学发现中的调查") 节），数据自然提供了一组标签，而无需额外标记。在自然语言处理（NLP）上下文中，神经网络接收一个词序列，即句子或文本段落，并尝试预测下一个词。例如，给定一个句子“The
    cat sat on the roof”，网络会首先接收输入“The”并预测“cat”，然后接收“The cat”并预测“sat”，依此类推。（实现中还有一些附加细节，但这是总体思路。）由于数据/标签的易得性以及在不同层级（如词汇甚至字符）中使用语言建模的能力，它已成为自然语言处理中的一个流行基准，也用于捕捉科学应用中的序列依赖，例如蛋白质功能预测
    [[77](#bib.bib77), [80](#bib.bib80)]，并在 AlphaFold 中将隐藏表示作为蛋白质结构预测的更大管道的一部分 [[205](#bib.bib205)]（开源代码
    [https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13](https://github.com/deepmind/deepmind-research/tree/master/alphafold_casp13)）。
- en: 4.5.2 Sequence to Sequence
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.2 序列到序列
- en: '![Refer to caption](img/ca889b190cea5a0065e9f841da8ec67a.png)'
  id: totrans-168
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ca889b190cea5a0065e9f841da8ec67a.png)'
- en: 'Figure 5: Illustration of the Sequence to Sequence prediction task. Image source
    [[267](#bib.bib267)] The figure shows an illustration of a Sequence to Sequence
    task, translating an input sentence (sequence of tokens) in English to an output
    sentence in German. Note the encoder-decoder structure of the underlying neural
    network, with the encoder taking in the input, and the decoder generating the
    output, informed by the encoder representations and the previously generated output
    tokens. In this figure, the input tokens are fed in one by one, and the output
    is also generated one at a time, which is the paradigm when using Recurrent Neural
    Networks as the underlying model. With Transformer models, which are now extremely
    popular for sequence to sequence tasks, the sequence is input all at once, significantly
    speeding up use.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：序列到序列预测任务的示意图。图像来源 [[267](#bib.bib267)] 该图展示了一个序列到序列任务的示意图，将英语的输入句子（令牌序列）翻译成德语的输出句子。请注意底层神经网络的编码器-解码器结构，其中编码器接收输入，解码器生成输出，并受到编码器表示和先前生成的输出令牌的影响。在此图中，输入令牌一个接一个地输入，同时输出也是逐一生成，这在使用递归神经网络作为底层模型时是常见的模式。使用当前非常流行的
    Transformer 模型时，序列一次性输入，显著加快了处理速度。
- en: Another very popular task for sequence data is sequence to sequence — transforming
    one sequence to another. This is precisely the setup for machine translation,
    where the model gets an input sentence (sequence) in say English, and must translate
    it to German, which forms the output sentence (sequence). Some of the first papers
    framing this task and tackling it in this way are [[10](#bib.bib10), [221](#bib.bib221),
    [234](#bib.bib234)]. Sequence to sequence tasks typically rely on neural network
    models that have an encoder-decoder structure, with the encoder neural network
    taking in the input sequence and learning to extract the important features, which
    is then used by the decoder neural network to produce the target output. Figure
    [5](#S4.F5 "Figure 5 ‣ 4.5.2 Sequence to Sequence ‣ 4.5 Neural Networks for Sequence
    Data ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning
    for Scientific Discovery")(sourced from [[267](#bib.bib267)]) shows an example
    of this. This paradigm has also found some scientific applications as varied as
    biology [[23](#bib.bib23)] and energy forcasting [[145](#bib.bib145)]. Sequence
    to sequence models critically rely on a technique called attention, which we overview
    below. For more details on this task, we recommend looking at some of the tutorials
    and course notes highlighted in Section [3](#S3 "3 Deep Learning Libraries and
    Resources ‣ A Survey of Deep Learning for Scientific Discovery").
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个非常流行的序列数据任务是序列到序列——将一个序列转换为另一个序列。这正是机器翻译的设置，其中模型接收一个输入句子（序列），比如英语，并将其翻译成德语，形成输出句子（序列）。一些最早定义并以这种方式处理该任务的论文包括
    [[10](#bib.bib10), [221](#bib.bib221), [234](#bib.bib234)]。序列到序列任务通常依赖于具有编码器-解码器结构的神经网络模型，编码器神经网络接收输入序列并学习提取重要特征，然后解码器神经网络利用这些特征生成目标输出。图
    [5](#S4.F5 "Figure 5 ‣ 4.5.2 Sequence to Sequence ‣ 4.5 Neural Networks for Sequence
    Data ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning
    for Scientific Discovery")(来源于 [[267](#bib.bib267)]) 展示了一个示例。这一范式还在生物学 [[23](#bib.bib23)]
    和能源预测 [[145](#bib.bib145)] 等多种科学应用中找到了应用。序列到序列模型关键依赖于一种称为注意力的技术，我们将在下面概述。有关该任务的更多细节，建议查阅第
    [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey of Deep Learning for
    Scientific Discovery") 节中突出介绍的一些教程和课程笔记。
- en: 4.5.3 Question Answering
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.3 问答
- en: One other popular benchmark for sequence data has been question answering. Here,
    a neural network model is given a paragraph of text (as context) and a specific
    question to answer on this context as input. It must then output the part of the
    paragraph that answers the question. Some of the standard benchmarks for this
    task are [[83](#bib.bib83), [186](#bib.bib186)], with [http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture10-QA.pdf](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture10-QA.pdf)
    providing an excellent overview of the tasks and common methodologies. Question
    answering critically relies on the neural network model understanding the relevance
    and similarity of different sets of sequences (e.g. how relevant is this part
    of the context to the question of interest?). This general capability (with appropriate
    reformulation) has the potential to be broadly useful, both for determining similarity
    and relevance on other datasets, and for question answering in specialized domains
    [[61](#bib.bib61)].
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个流行的序列数据基准是问答任务。在这种情况下，神经网络模型接收一段文本（作为上下文）和一个特定问题作为输入。模型必须输出回答问题的那部分文本段落。一些标准的基准包括
    [[83](#bib.bib83), [186](#bib.bib186)]，并且 [http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture10-QA.pdf](http://web.stanford.edu/class/cs224n/slides/cs224n-2019-lecture10-QA.pdf)
    提供了关于任务和常见方法的优秀概述。问答任务关键在于神经网络模型理解不同序列集的相关性和相似性（例如，这部分上下文与感兴趣的问题的相关性如何？）。这种通用能力（通过适当的重构）有潜力在确定其他数据集的相似性和相关性方面，以及在特定领域的问答任务中广泛应用
    [[61](#bib.bib61)]。
- en: 4.5.4 Recurrent Neural Networks
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.4 循环神经网络
- en: '![Refer to caption](img/68b438718665679c1e903da5f4c373d3.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/68b438718665679c1e903da5f4c373d3.png)'
- en: 'Figure 6: Diagram of a Recurrent Neural Network model, specifically a LSTM
    (Long-Short Term Network). Image source [[163](#bib.bib163)] The figure illustrates
    an LSTM network, a type of Recurrent Neural Network. We see that the input $x_{t}$
    at each timestep also inform the internal network state in the next timestep (hence
    a recurrent neural network) through a gating mechanism. This gating mechanism
    is called an LSTM, and consists of sigmoid and tanh functions, which transform
    and recombine the input for an updated internal state, and also emit an output.
    The mechanics of this gating process are shown in the middle cell of the figure.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：递归神经网络模型的示意图，具体为LSTM（长短期记忆网络）。图片来源 [[163](#bib.bib163)] 图示展示了LSTM网络，一种递归神经网络。我们看到每个时间步的输入$x_{t}$通过一个门控机制也会影响下一时间步的内部网络状态（因此是一种递归神经网络）。这个门控机制被称为LSTM，由sigmoid和tanh函数组成，用于转换和重新组合输入，以更新内部状态，同时也发出输出。这个门控过程的机制在图的中间单元格中显示。
- en: Having seen some of the core tasks in deep learning for sequence data, these
    next few sections look at some of the key neural network models.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 在了解了一些序列数据深度学习中的核心任务后，接下来的几个部分将探讨一些关键的神经网络模型。
- en: Recurrent neural networks (RNNs) were the first kind of deep learning model
    successfully used on many of the aforementioned tasks. Their distinguishing feature,
    compared to CNNs or MLPs (which are feedforward neural networks, mapping input
    straight to output), is that there are feedback connections, enabling e.g. the
    output at each timestep to become the input for the next timestep, and the preservation
    and modification of an internal state across timesteps. When RNNs are used for
    sequential data tasks, sequences are input token by token, with each token causing
    an update of the internal cell state of the RNN, and also making the RNN emit
    a token output. Note that this enables these models to work with variable length
    data — often a defining characteristic of sequence data. How the input is processed,
    cell state updated and output emitted are controlled by gating functions — see
    the technical references!
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 递归神经网络（RNNs）是第一种在许多上述任务中成功使用的深度学习模型。与CNNs或MLPs（这些是前馈神经网络，直接将输入映射到输出）相比，其显著特点是具有反馈连接，使得例如每个时间步的输出可以成为下一个时间步的输入，并在时间步之间保持和修改内部状态。当RNN用于序列数据任务时，序列按令牌逐个输入，每个令牌导致RNN的内部单元状态更新，并使RNN发出令牌输出。请注意，这使得这些模型能够处理可变长度的数据——通常是序列数据的一个定义特征。输入如何处理、单元状态如何更新和输出如何发出由门控函数控制——请参阅技术参考！
- en: 'Application Characteristics:'
  id: totrans-178
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 应用特点：
- en: Problems where the data has a sequential nature (with different sequences of
    varying length), and prediction problems such as determining the next sequence
    token, transforming one sequence to another, or determining sequence similarities
    are important tasks.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 数据具有序列性质的问题（具有不同长度的不同序列）以及预测问题，如确定下一个序列令牌、将一个序列转换为另一个序列或确定序列相似性，都是重要任务。
- en: 'Technical References:'
  id: totrans-180
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 技术参考：
- en: Research on sequence models and RNNs has evolved dramatically in just the past
    couple of years. The most successful and popular kind of RNN is a bi-LSTM with
    Attention, where LSTM (Long-Short Term Memory) [[88](#bib.bib88)] refers to the
    kind of gating function that controls updates in the network, bi refers to bidirectional
    (the neural network is run forwards and backwards on the sequence) and Attention
    is a very important technique that we overview separately below. (Some example
    papers [[149](#bib.bib149), [150](#bib.bib150)] and code resources [https://github.com/salesforce/awd-lstm-lm](https://github.com/salesforce/awd-lstm-lm).)
    This excellent post [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)
    provides a great overview of RNNs and LSTMs in detail. (Figure [6](#S4.F6 "Figure
    6 ‣ 4.5.4 Recurrent Neural Networks ‣ 4.5 Neural Networks for Sequence Data ‣
    4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning for Scientific
    Discovery") shows a diagram from the post revealing the details of the gating
    mechanisms in LSTMs.) The post also describes a small variant of LSTMs, Gated
    Recurrent Units (GRUs) which are also popular in practice [[127](#bib.bib127)].
    While RNNs (really bi-LSTMs) have been very successful, they are often tricky
    to develop and train, due to their recursiveness presenting challenges with optimization
    (the vanishing/exploding gradients problem [[87](#bib.bib87), [170](#bib.bib170),
    [76](#bib.bib76)]), with performing fast model training (due to generating targets
    token by token), and challenges learning long term sequential dependencies. A
    new type of feedforward neural network architecture, the Transformer (overviewed
    below), was proposed to alleviate the first two of these challenges.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几年中，序列模型和RNN的研究发生了显著变化。最成功和流行的RNN类型是带有注意力机制的双向LSTM，其中LSTM（长短期记忆）[[88](#bib.bib88)]指的是控制网络更新的门控功能，bi指的是双向（神经网络在序列上前向和后向运行），而注意力机制是一个我们在下面单独概述的重要技术。（一些示例论文[[149](#bib.bib149),
    [150](#bib.bib150)]和代码资源[https://github.com/salesforce/awd-lstm-lm](https://github.com/salesforce/awd-lstm-lm)。）这篇出色的帖子[https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)提供了对RNN和LSTM的详细概述。（图[6](#S4.F6
    "图 6 ‣ 4.5.4 循环神经网络 ‣ 4.5 序列数据的神经网络 ‣ 4 标准神经网络模型和任务 ‣ 科学发现的深度学习综述")展示了来自该帖子的图解，揭示了LSTM中门控机制的细节。）帖子还描述了一种小型LSTM变体，即门控循环单元（GRU），这种变体在实践中也很流行[[127](#bib.bib127)]。尽管RNN（实际上是双向LSTM）已经非常成功，但由于其递归特性导致优化（梯度消失/爆炸问题[[87](#bib.bib87),
    [170](#bib.bib170), [76](#bib.bib76)]）、快速模型训练（由于逐步生成目标）、以及学习长期序列依赖关系的挑战，因此开发和训练起来往往比较棘手。为了解决前两个问题，提出了一种新的前馈神经网络架构，即Transformer（下面会概述）。
- en: 'Scientific Examples:'
  id: totrans-182
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例：
- en: RNNs have found several scientific applications for data with sequential structure,
    such as in genomics and proteomics [[175](#bib.bib175), [132](#bib.bib132), [111](#bib.bib111)].
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: RNN在具有序列结构的数据的科学应用中找到了几个应用，例如基因组学和蛋白质组学[[175](#bib.bib175), [132](#bib.bib132),
    [111](#bib.bib111)]。
- en: 4.5.5 Attention
  id: totrans-184
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.5 注意力机制
- en: A significant problem in using RNNs and working with sequential data is the
    difficulty in capturing long range dependencies. Long range dependencies are when
    tokens in the sequence that are very far apart from each other must be processed
    together to inform the correct output. RNNs process sequences in order, token
    by token, which means they must remember all of the important information from
    the earlier tokens until much later in the sequence — very challenging as the
    memory of these architectures is far from perfect. Attention [[32](#bib.bib32),
    [11](#bib.bib11)] is a very important technique that introduces shortcut connections
    to earlier tokens, which alleviates the necessity to remember important features
    for the duration of the entire sequence. Instead it provides a direct way to model
    long term dependencies — the neural network has the ability to look back and attend
    to what it deems relevant information (through learning) earlier in the input.
    A very nice overview of attention is provided by [https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html).
    A variant of attention, self-attention, which can be used to help predictions
    on a single input sequence, is the core building block of Transformer models.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 RNNs 处理序列数据的一个重大问题是捕捉长期依赖关系的困难。长期依赖关系指的是序列中相距很远的标记必须一起处理以提供正确的输出。RNNs 按顺序逐步处理序列，这意味着它们必须记住早期标记中的所有重要信息，直到序列的很后面——由于这些架构的记忆远非完美，这非常具有挑战性。注意力
    [[32](#bib.bib32), [11](#bib.bib11)] 是一种非常重要的技术，它引入了与早期标记的快捷连接，减少了记住整个序列的必要性。相反，它提供了一种直接建模长期依赖关系的方法——神经网络能够回顾并关注其认为在输入早期相关的信息（通过学习）。关于注意力的一个很好的概述可以参考
    [https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html)。注意力的一个变体，自注意力，可以帮助对单个输入序列进行预测，是
    Transformer 模型的核心构建块。
- en: 4.5.6 Transformers
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.6 Transformer
- en: '![Refer to caption](img/6ca20da0f8bf5ff59ddb821509f96133.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6ca20da0f8bf5ff59ddb821509f96133.png)'
- en: 'Figure 7: Image of a couple of layers from a Transformer network. Image source
    [[3](#bib.bib3)] The figure depicts the core sequence of layers that are fundamental
    to Transformer neural networks, a self-attention layer (sometimes called a self-attention
    head) followed by fully connected layers. Note that when working with sequence
    data, transformers take the entire input sequence all at once, along with positional
    information (in this case the input sequence being "Thinking Machines".)'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：Transformer 网络中几层的图像。图片来源 [[3](#bib.bib3)] 该图描绘了 Transformer 神经网络的核心层序列，一个自注意力层（有时称为自注意力头），随后是全连接层。请注意，在处理序列数据时，Transformer
    一次性接收整个输入序列，以及位置嵌入（在此情况下输入序列为“Thinking Machines”）。
- en: While attention helped with challenges in long range dependencies, RNNs still
    remained slow to train and tricky to design (due to optimization challenges with
    vanishing/exploding gradients.) These challenges were inherent to their recurrent,
    token-by-token nature, prompting the proposal of a new feedforward neural network
    to work with sequential data, the Transformer [[233](#bib.bib233)], which critically
    relies on attentional mechanisms (the paper is in fact titled Attention is All
    you Need.) During training transformers take in the entire sequence as input all
    at once, but have positional embeddings that respects the sequential nature of
    the data. Transformers have been exceptionally popular, becoming the dominant
    approach to many natural language tasks and sequential tasks.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管注意力机制帮助解决了长期依赖问题，RNNs 训练速度依然较慢，且设计复杂（由于消失/爆炸梯度的优化挑战）。这些挑战是其递归、逐步处理的本质所固有的，因此提出了一种新的前馈神经网络——Transformer
    [[233](#bib.bib233)]，其关键依赖于注意力机制（论文实际上名为《Attention is All you Need》）。在训练过程中，Transformer
    一次性接收整个序列作为输入，但具有尊重数据序列性质的位置嵌入。Transformer 由于其卓越的性能，已成为许多自然语言任务和序列任务的主流方法。
- en: 'Application Characteristics:'
  id: totrans-190
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 应用特性：
- en: Problems where the data has a sequential nature and long range dependencies
    that need to be modelled. Given the large number of pretrained transformer models,
    they can also be very useful in settings where pretrained models on standard benchmarks
    can be quickly adapted to the target problem.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 适用于数据具有序列性质和需要建模长距离依赖关系的问题。考虑到大量预训练的变换器模型，它们在预训练模型可以快速适应目标问题的设置中也非常有用。
- en: 'Technical References:'
  id: totrans-192
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 技术参考：
- en: The original transformer paper [[233](#bib.bib233)] provides a nice overview
    of the motivations and the neural network architecture. The model was designed
    with machine translation tasks in mind, and so consists of an encoder neural network
    and a decoder neural network. With transformers being adopted for tasks very different
    to machine translation, the encoder and decoder are often used in stand-alone
    fashions for different tasks — for example, the encoder alone is used for question
    answering, while the decoder is important for text generation. Two very accessible
    step by step tutorials on the transformer are [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
    and [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/).
    A nice example of some of the language modelling capabilities of this models is
    given by [[180](#bib.bib180)].
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 原始的变换器论文 [[233](#bib.bib233)] 对动机和神经网络架构进行了很好的概述。该模型设计时考虑了机器翻译任务，因此包含了一个编码器神经网络和一个解码器神经网络。随着变换器被用于与机器翻译截然不同的任务，编码器和解码器往往被单独用于不同的任务——例如，编码器单独用于问答系统，而解码器则对文本生成至关重要。关于变换器的两个非常易于理解的逐步教程是
    [The Annotated Transformer](https://nlp.seas.harvard.edu/2018/04/03/attention.html)
    和 [The Illustrated Transformer](http://jalammar.github.io/illustrated-transformer/)。该模型语言建模能力的一个很好的例子见
    [[180](#bib.bib180)]。
- en: Since the development of the transformer, there has been considerable research
    looking at improving the training of these models, adjusting the self-attention
    mechanism and other variants. A very important result using the transformer has
    been BERT (Pretraining of deep Bi-directional Transformers for Language understanding)
    [[43](#bib.bib43)]. This paper demonstrates that performing transfer learning
    (see Section [5.1](#S5.SS1 "5.1 Transfer Learning ‣ 5 Key (Supervised Learning)
    Methods ‣ A Survey of Deep Learning for Scientific Discovery")) using a transformer
    neural network can be extremely successful for many natural language tasks. (Some
    of the first papers showing the potential of transfer learning in this area were
    [[92](#bib.bib92), [180](#bib.bib180)], and since BERT, there have been followups
    which extend the model capabilities [[257](#bib.bib257)].) From a practical perspective,
    the development of transformers, BERT and transfer learning mean that there are
    many resources available online for getting hold of code and pretrained models.
    We refer to some of these in Section [3](#S3 "3 Deep Learning Libraries and Resources
    ‣ A Survey of Deep Learning for Scientific Discovery"), but of particular note
    is [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)
    which has an excellent library for transformer models. A good overview of BERT
    and transfer learning in NLP is given in [http://jalammar.github.io/illustrated-bert/](http://jalammar.github.io/illustrated-bert/).
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 自变换器开发以来，已经进行了大量研究，旨在改进这些模型的训练、调整自注意力机制以及其他变体。使用变换器的一个非常重要的成果是 BERT（深度双向变换器预训练用于语言理解）
    [[43](#bib.bib43)]。这篇论文表明，使用变换器神经网络进行迁移学习（见 [5.1](#S5.SS1 "5.1 Transfer Learning
    ‣ 5 Key (Supervised Learning) Methods ‣ A Survey of Deep Learning for Scientific
    Discovery")）在许多自然语言任务中可以极为成功。（一些最早展示迁移学习潜力的论文是 [[92](#bib.bib92), [180](#bib.bib180)]，自
    BERT 以来，已经有扩展模型能力的后续研究 [[257](#bib.bib257)]。）从实际角度来看，变换器、BERT 和迁移学习的发展意味着有许多在线资源可以获取代码和预训练模型。我们在
    [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey of Deep Learning for
    Scientific Discovery") 节中提到了一些，但特别值得注意的是 [https://github.com/huggingface/transformers](https://github.com/huggingface/transformers)，它提供了一个优秀的变换器模型库。关于
    BERT 和 NLP 中迁移学习的一个很好的概述见 [http://jalammar.github.io/illustrated-bert/](http://jalammar.github.io/illustrated-bert/)。
- en: 'Scientific Examples:'
  id: totrans-195
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 科学示例：
- en: There have been several interesting examples of transformers used in scientific
    settings, such as training on protein sequences to find representations encoding
    meaningful biological properties [[195](#bib.bib195)], protein generation via
    language modelling [[142](#bib.bib142)], bioBERT [[121](#bib.bib121)] for text
    mining in biomedical data (with [pretrained model](https://github.com/naver/biobert-pretrained)
    and [training code](https://github.com/dmis-lab/biobert)), embeddings of scientific
    text [[18](#bib.bib18)] (with code [https://github.com/allenai/scibert](https://github.com/allenai/scibert))
    and medical question answering [[237](#bib.bib237)].
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 在科学环境中使用变换器的几个有趣示例包括：在蛋白质序列上进行训练以寻找编码有意义生物属性的表示[[195](#bib.bib195)]，通过语言建模生成蛋白质[[142](#bib.bib142)]，用于生物医学数据文本挖掘的bioBERT[[121](#bib.bib121)]（包括[预训练模型](https://github.com/naver/biobert-pretrained)和[训练代码](https://github.com/dmis-lab/biobert)），科学文本的嵌入[[18](#bib.bib18)]（包括代码[https://github.com/allenai/scibert](https://github.com/allenai/scibert)）以及医疗问题回答[[237](#bib.bib237)]。
- en: 4.5.7 Other Tasks with Sequence Data
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.5.7 其他序列数据任务
- en: In the previous sections, we’ve given an overview of some of the important benchmark
    tasks for sequential data, and the types of deep learning models available to
    tackle them. As with convolutional networks, this is not a comprehensive overview,
    but hopefully thorough enough to help with generating ideas on possible applications
    and offering pointers to other useful related areas. A few other sequential data
    tasks that might be of interest are structured prediction, where the predicted
    output has some kind of structure, from tree structures (in e.g. parsing) [[28](#bib.bib28),
    [246](#bib.bib246)] to short, executable computer program structure [[271](#bib.bib271)]
    and summarization, where passages of text are summarized by a neural network [[130](#bib.bib130),
    [273](#bib.bib273)]. We’ll also discuss word embeddings later in the survey.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们概述了一些重要的序列数据基准任务，以及可以解决这些任务的深度学习模型类型。与卷积网络一样，这不是一个全面的概述，但希望足够详尽，以帮助生成关于可能应用的想法，并提供指向其他有用相关领域的指引。可能感兴趣的其他序列数据任务包括结构化预测，其中预测的输出具有某种结构，从树结构（例如解析）[[28](#bib.bib28),
    [246](#bib.bib246)]到短的、可执行的计算机程序结构[[271](#bib.bib271)]，以及文本摘要，其中神经网络总结文本片段[[130](#bib.bib130),
    [273](#bib.bib273)]。我们稍后将在调查中讨论词嵌入。
- en: 4.6 Section Summary
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.6 节摘要
- en: In this section, we have overviewed supervised learning, some of the core neural
    network models and the kinds of important tasks they can be used for. As previously
    discussed, these topics span an extremely large area of research, so there are
    some areas, e.g. deep neural networks for set structured data [[262](#bib.bib262),
    [113](#bib.bib113)], modelling different invariances — invariances to specified
    Lie groups for application to molecular property prediction [[58](#bib.bib58)],
    spherical invariances [[35](#bib.bib35), [36](#bib.bib36)] not covered. But we
    hope the material and references presented help inspire novel contributions to
    these very exciting and rapidly evolving research directions.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们概述了监督学习、一些核心神经网络模型以及它们可以用于的重要任务。正如之前讨论的，这些主题涵盖了一个非常广泛的研究领域，因此有些领域，比如用于分子性质预测的指定李群的深度神经网络[[262](#bib.bib262),
    [113](#bib.bib113)]，建模不同的不变性——例如球面不变性[[35](#bib.bib35), [36](#bib.bib36)]等，都没有涉及。但我们希望所提供的材料和参考文献能够激发对这些非常令人兴奋和迅速发展的研究方向的新贡献。
- en: 5 Key (Supervised Learning) Methods
  id: totrans-201
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 关键（监督学习）方法
- en: In the previous section we saw different kinds of neural network models, and
    the many different types of tasks they could be used for. To train the models
    for these tasks, we typically rely on the supervised learning methodology — optimize
    model parameters to correctly output given labels (the supervision) on a set of
    training data examples.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一节中，我们介绍了不同类型的神经网络模型，以及它们可以用于的各种任务。为了训练这些模型以完成这些任务，我们通常依赖监督学习方法——优化模型参数以在一组训练数据示例上正确输出给定标签（即监督）。
- en: In more detail, the standard supervised learning method for deep neural networks
    consists of (i) collecting data instances (e.g. images) (ii) collecting labels
    for the data instances (e.g. is the image a cat or a dog) (iii) splitting the
    set of collected (data instance, label) into a training set, validation set and
    test set (iv) randomly initializing neural network parameters (iv) optimizing
    parameters so the network outputs the correct corresponding label given an input
    data instance on the training set (v) further tuning and validating on the validation
    and test sets.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 更详细地说，深度神经网络的标准监督学习方法包括 (i) 收集数据实例（例如图像） (ii) 收集数据实例的标签（例如图像是猫还是狗） (iii) 将收集的（数据实例，标签）集分为训练集、验证集和测试集
    (iv) 随机初始化神经网络参数 (v) 优化参数，使网络在训练集上的输入数据实例上输出正确的对应标签 (vi) 在验证集和测试集上进一步调优和验证。
- en: In this section we overview methods that use variants of this process, for example
    initializing the neural network parameters differently or dealing with shifts
    between the training data and the test sets. In Section [6](#S6 "6 Doing More
    with Less Data ‣ A Survey of Deep Learning for Scientific Discovery"), we look
    at variants that reduce the dependence on collecting labels.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们概述了使用该过程变体的方法，例如以不同的方式初始化神经网络参数或处理训练数据与测试集之间的差异。在第 [6](#S6 "6 用更少的数据做更多的事
    ‣ 深度学习在科学发现中的调查")节中，我们将探讨减少对标签收集依赖的变体。
- en: 5.1 Transfer Learning
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 迁移学习
- en: '![Refer to caption](img/cb29863060b64235ae84e924ebd93656.png)'
  id: totrans-206
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cb29863060b64235ae84e924ebd93656.png)'
- en: 'Figure 8: The Transfer Learning process for deep neural networks. Transfer
    learning is a two step process for training a deep neural network. Instead of
    intializing parameters randomly and directly training on the target task, we first
    perform a pretraining step, on some diverse, generic task. This results in the
    neural network parameters converging to a set of values, known as the pretrained
    weights. If the pretraining task is diverse enough, these pretrained weights will
    contain useful features that can be leveraged to learn the target task more efficiently.
    Starting from the pretrained weights, we then train the network on the target
    task, known as finetuning, giving us the final model.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：深度神经网络的迁移学习过程。迁移学习是训练深度神经网络的一个两步过程。我们不是随机初始化参数并直接在目标任务上进行训练，而是首先在一些多样的、通用的任务上进行预训练。这将使神经网络参数收敛到一组称为预训练权重的值。如果预训练任务足够多样，这些预训练权重将包含有用的特征，可以用来更高效地学习目标任务。从预训练权重开始，我们接着在目标任务上训练网络，这称为微调，最终得到模型。
- en: Through the preceding sections, we’ve made references to using pretrained models.
    This is in fact referring to a very important method for training deep neural
    networks, known as transfer learning. Transfer learning is a two step process
    for training a deep neural network model, a pretraining step, followed by a finetuning
    step, where the model in trained on the target task. More specifically, we take
    a neural network with parameters randomly initialized, and first train it on a
    standard, generic task — the pretraining step. For example, in image based tasks,
    a common pretraining task is ImageNet [[42](#bib.bib42)], which is an image classification
    task on a large dataset of natural images. With an appropriate pretraining task
    that is generic and complex enough, the pretraining step allows the neural network
    to learn useful features, stored in its parameters, which can then be reused for
    the second step, finetuning. In finetuning, the pretrained neural network is further
    trained (with maybe some minor modifications to its output layer) on the true
    target task of interest. This process is illustrated in Figure [8](#S5.F8 "Figure
    8 ‣ 5.1 Transfer Learning ‣ 5 Key (Supervised Learning) Methods ‣ A Survey of
    Deep Learning for Scientific Discovery"). But being able to use the features it
    learned during pretraining often leads to boosts in performance and convergence
    speed of the target task, as well as needing less labelled data.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的章节中，我们提到过使用预训练模型。这实际上是指一种训练深度神经网络的非常重要的方法，称为迁移学习。迁移学习是训练深度神经网络模型的一个两步过程，包括预训练步骤和微调步骤，其中模型在目标任务上进行训练。更具体地说，我们首先用随机初始化的参数训练一个神经网络，首先在一个标准的、通用的任务上进行训练——即预训练步骤。例如，在基于图像的任务中，常见的预训练任务是ImageNet
    [[42](#bib.bib42)]，这是一个大规模自然图像数据集上的图像分类任务。通过一个合适的、足够复杂的通用预训练任务，预训练步骤允许神经网络学习有用的特征，这些特征存储在其参数中，可以在第二步微调中重复使用。在微调过程中，预训练的神经网络会在真正的目标任务上进一步训练（可能对其输出层进行一些小的修改）。这一过程在[8图](#S5.F8
    "Figure 8 ‣ 5.1 Transfer Learning ‣ 5 Key (Supervised Learning) Methods ‣ A Survey
    of Deep Learning for Scientific Discovery")中进行了说明。但能够利用其在预训练过程中学到的特征，通常会导致目标任务性能和收敛速度的提升，并且需要较少的标记数据。
- en: Because of these considerable benefits, transfer learning has been extraordinarily
    useful in many settings, particularly in computer vision [[95](#bib.bib95)], which
    had many early successful applications. As overviewed in Section [4.5.6](#S4.SS5.SSS6
    "4.5.6 Transformers ‣ 4.5 Neural Networks for Sequence Data ‣ 4 Standard Neural
    Network Models and Tasks ‣ A Survey of Deep Learning for Scientific Discovery"),
    the recent development of models like ULMFiT [[92](#bib.bib92)] and especially
    BERT [[43](#bib.bib43)] has also made transfer learning extremely successful in
    natural language and sequential data settings, with recent work making the transfer
    learning process even more efficient [[90](#bib.bib90), [201](#bib.bib201)]. Most
    importantly, the ready availability of standard neural network architectures pretrained
    on standard benchmarks through many open sourced code repositories on GitHub (examples
    given in Section [3](#S3 "3 Deep Learning Libraries and Resources ‣ A Survey of
    Deep Learning for Scientific Discovery")) has meant that downloading and finetuning
    a standard pretrained model has become the de-facto standard for most new deep
    learning applications.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 由于这些显著的好处，迁移学习在许多领域中极为有用，特别是在计算机视觉[[95](#bib.bib95)]中，早期有很多成功的应用。如[4.5.6节](#S4.SS5.SSS6
    "4.5.6 Transformers ‣ 4.5 Neural Networks for Sequence Data ‣ 4 Standard Neural
    Network Models and Tasks ‣ A Survey of Deep Learning for Scientific Discovery")中概述的那样，最近像ULMFiT
    [[92](#bib.bib92)]和特别是BERT [[43](#bib.bib43)]这样的模型的开发，也使得迁移学习在自然语言和序列数据领域极为成功，近期的研究使迁移学习过程变得更加高效[[90](#bib.bib90),
    [201](#bib.bib201)]。最重要的是，标准神经网络架构在标准基准上进行预训练的现成可用性，通过许多开源代码库在GitHub上（[3节](#S3
    "3 Deep Learning Libraries and Resources ‣ A Survey of Deep Learning for Scientific
    Discovery")中给出了示例），意味着下载和微调标准预训练模型已成为大多数新深度学习应用的事实标准。
- en: Typically, performing transfer learning is an excellent way to start work on
    a new problem of interest. There is the benefit of using a well-tested, standard
    neural network architecture, aside from the knowledge reuse, stability and convergence
    boosts offered by pretrained weights. Note however that the precise effects of
    transfer learning are not yet fully understood, and an active research area [[116](#bib.bib116),
    [184](#bib.bib184), [266](#bib.bib266), [159](#bib.bib159), [143](#bib.bib143),
    [181](#bib.bib181), [235](#bib.bib235)] looks at investigating its exact properties.
    For transfer learning in vision [[116](#bib.bib116), [266](#bib.bib266), [112](#bib.bib112)]
    may be of particular interest for their large scale studies and pretraining recommendations.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，进行迁移学习是开始处理新问题的一个绝佳方式。除了知识重用、稳定性和预训练权重带来的收敛性提升外，还有使用经过充分测试的标准神经网络架构的好处。然而，请注意，迁移学习的具体效果尚未完全理解，且一个活跃的研究领域[[116](#bib.bib116),
    [184](#bib.bib184), [266](#bib.bib266), [159](#bib.bib159), [143](#bib.bib143),
    [181](#bib.bib181), [235](#bib.bib235)] 正在研究其确切属性。对于视觉中的迁移学习[[116](#bib.bib116),
    [266](#bib.bib266), [112](#bib.bib112)]，由于其大规模研究和预训练建议，可能特别值得关注。
- en: 5.2 Domain Adaptation
  id: totrans-211
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 领域自适应
- en: Related to transfer learning is the task of domain adaptation. In (unsupervised)
    domain adaptation, we have training data and labels in a source domain, but want
    to develop a deep learning model that will also work on a target domain, where
    the data instances may look different to those in the source domain, but the high
    level task is the same. For instance, our source domain many consist of images
    of handwritten digits (zero to nine) which we wish to classify as the correct
    number. But the target domain many have photographs of house numbers (from zero
    to nine), that we also wish to classify as the correct number. Domain adaptation
    techniques help build a model on the source domain that can also work (reasonably)
    well out-of-the-box on the shifted target domain.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 与迁移学习相关的是领域自适应任务。在（无监督）领域自适应中，我们在源领域有训练数据和标签，但希望开发一个在目标领域也能工作的深度学习模型，其中数据实例可能与源领域中的不同，但高层任务相同。例如，我们的源领域可能包括手写数字（零到九）的图像，我们希望将其分类为正确的数字。但目标领域可能包含房号的照片（从零到九），我们也希望将其分类为正确的数字。领域自适应技术有助于构建一个在源领域上构建的模型，该模型在转移的目标领域也能（合理地）表现良好。
- en: The most dominant approach to domain adaptation in deep learning is to build
    a model that can (i) perform well on the source domain task, and (ii) learns features
    that are as invariant to the domain shift as possible. This is achieved through
    jointly optimizing for both of these goals. Returning to our example on handwritten
    digits and house number photographs, (i) corresponds to the standard supervised
    learning classification problem of doing well on the (source) task of identifying
    handwritten digits correctly while (ii) is more subtle, and typically involves
    explicitly optimizing for the hidden layer representations of handwritten digits
    and house number photographs to look the same as each other — domain invariance.
    Some popular ways to implement this include gradient reversal [[62](#bib.bib62)],
    minimizing a distance function on the hidden representations [[137](#bib.bib137)],
    and even adversarial training [[63](#bib.bib63), [211](#bib.bib211)]. More recently,
    [[219](#bib.bib219)] look at using self-supervision (see Section [6](#S6 "6 Doing
    More with Less Data ‣ A Survey of Deep Learning for Scientific Discovery")) to
    jointly train on the source and target domains, enabling better adaptation.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习中，领域自适应的最主要方法是构建一个模型，该模型能够（i）在源领域任务上表现良好，并且（ii）学习对领域转移尽可能不变的特征。这通过共同优化这两个目标来实现。回到我们关于手写数字和房号照片的示例，（i）对应于在识别手写数字的（源）任务上表现良好的标准监督学习分类问题，而（ii）则更为微妙，通常涉及明确优化手写数字和房号照片的隐藏层表示，使其彼此看起来相同——领域不变性。一些流行的实现方式包括梯度反转[[62](#bib.bib62)]、在隐藏表示上最小化距离函数[[137](#bib.bib137)]，甚至对抗训练[[63](#bib.bib63),
    [211](#bib.bib211)]。最近，[[219](#bib.bib219)] 研究了使用自监督（见第[6](#S6 "6 用更少的数据做更多的事
    ‣ 深度学习在科学发现中的应用")节）来共同训练源领域和目标领域，从而实现更好的适应性。
- en: Other approaches to domain adaptation include translating data instances from
    the source to the target domain, and bootstrapping/co-training approaches (see
    Section [6.2](#S6.SS2 "6.2 Semi-Supervised Learning ‣ 6 Doing More with Less Data
    ‣ A Survey of Deep Learning for Scientific Discovery")). Some of these methods
    are overviewed in tutorials such as [Deep Domain Adaptation in Computer Vision](https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 领域适应的其他方法包括将数据实例从源领域转换到目标领域，以及自举/共同训练方法（见第[6.2节](#S6.SS2 "6.2 半监督学习 ‣ 6 用更少的数据做更多的事
    ‣ 科学发现中的深度学习概述")）。一些这些方法在教程中进行了概述，例如[计算机视觉中的深度领域适应](https://towardsdatascience.com/deep-domain-adaptation-in-computer-vision-8da398d3167f)。
- en: 5.3 Multitask Learning
  id: totrans-215
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 多任务学习
- en: In many supervised learning applications, ranging from machine translation [[2](#bib.bib2)]
    to scientific settings [[187](#bib.bib187), [176](#bib.bib176)], neural networks
    are trained in a multitask way – predicting several different outputs for a single
    input. For example, in image classification, given an input medical image, we
    might train the network not only to predict a disease of interest, but patient
    age, history of other related disease, etc. This often has beneficial effects
    even if there is only one prediction of interest, as it provides the neural network
    with useful additional feedback that can guide it in learning the most important
    data features. (This can be so useful that sometimes auxiliary prediction targets
    are defined solely for this purpose.) Additionally, the prediction of multiple
    targets can mean that more data is available to train the model (only a subset
    of the data has the target labels of interest, but many more data instances have
    other auxiliary labels.) The most extreme version of this is to simultaneously
    train on two entirely different datasets. For example, instead of performing a
    pretraining/finetuing step, the model could be trained on both ImageNet and a
    medical imaging dataset at the same time.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多监督学习应用中，从机器翻译[[2](#bib.bib2)]到科学领域[[187](#bib.bib187), [176](#bib.bib176)]，神经网络以多任务的方式进行训练——为单一输入预测多个不同的输出。例如，在图像分类中，给定一张医学图像，我们可能会训练网络不仅预测感兴趣的疾病，还预测患者的年龄、其他相关疾病的病史等。即使只对一个预测感兴趣，这种做法通常也会产生有益的效果，因为它为神经网络提供了有用的额外反馈，指导其学习最重要的数据特征。（这种方法有时会如此有用，以至于辅助预测目标仅为此目的而定义。）此外，预测多个目标意味着有更多的数据可用于训练模型（只有一部分数据具有感兴趣的目标标签，但更多的数据实例具有其他辅助标签。）这种方法的最极端版本是同时在两个完全不同的数据集上进行训练。例如，模型可以同时在ImageNet和医学影像数据集上进行训练，而不是进行预训练/微调步骤。
- en: 'Multitask learning is usually implemented in practice by giving the neural
    network multiple heads. The head of a neural network refers to its output layer,
    and a neural network with multiple heads has one head for each predictive task
    (e.g. one head for predicting age, one for predicting the disease of interest)
    but shares all of the other features and parameters, across these different predictive
    tasks. This is where the benefit of multitask learning comes from — the shared
    features, which comprise of most of the network, get many different sources of
    feedback. Implementing multitask learning often also requires careful choice of
    the way to weight the training objectives for these different tasks. A nice survey
    of some popular methods for multitask learning is given by [https://ruder.io/multi-task/index.html#fn4](https://ruder.io/multi-task/index.html#fn4),
    and a tutorial on some of the important considerations in [http://hazyresearch.stanford.edu/multi-task-learning](http://hazyresearch.stanford.edu/multi-task-learning).
    One package for implementing multitask learning is found in [https://github.com/SenWu/emmental](https://github.com/SenWu/emmental)
    and step-by-step example with code excerpts in [towardsdatascience Multitask Learning:
    teach your AI more to make it better](https://towardsdatascience.com/multitask-learning-teach-your-ai-more-to-make-it-better-dde116c2cd40).'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 多任务学习通常通过为神经网络提供多个头部来实现。神经网络的头部指的是其输出层，而具有多个头部的神经网络为每个预测任务（例如，一个头部用于预测年龄，一个用于预测感兴趣的疾病）设有一个头部，但在这些不同的预测任务中共享所有其他特征和参数。这就是多任务学习的好处所在——共享特征（占据了大部分网络）可以获得许多不同来源的反馈。实现多任务学习通常还需要仔细选择如何权衡这些不同任务的训练目标。一些流行的多任务学习方法的良好调查可以参考[https://ruder.io/multi-task/index.html#fn4](https://ruder.io/multi-task/index.html#fn4)，有关一些重要考虑因素的教程可以参考[http://hazyresearch.stanford.edu/multi-task-learning](http://hazyresearch.stanford.edu/multi-task-learning)。实现多任务学习的一个包可以在[https://github.com/SenWu/emmental](https://github.com/SenWu/emmental)找到，并且有[《towardsdatascience
    多任务学习：教你的AI更多以使其更好》](https://towardsdatascience.com/multitask-learning-teach-your-ai-more-to-make-it-better-dde116c2cd40)中的逐步示例和代码片段。
- en: 5.4 Weak Supervision (Distant Supervision)
  id: totrans-218
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4 弱监督（远程监督）
- en: Suppose it is very difficult to collect high quality labels for the target task
    of interest, and neither is there an existing, standard, related dataset and corresponding
    pretrained model to perform transfer learning from. How might one provide the
    deep learning model with enough supervision during the training process? While
    high quality labels might be hard to obtain, noisy labels might be relatively
    easy to collect. Weak supervision refers to the method of training a model on
    a dataset with these noisy labels (typically for future finetuning), where the
    noisy labels are often generated in an automatic process.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 假设很难为目标任务收集高质量的标签，并且没有现成的、标准的相关数据集和相应的预训练模型来进行迁移学习。如何在训练过程中为深度学习模型提供足够的监督？虽然高质量标签可能难以获得，但噪声标签可能相对容易收集。弱监督指的是在一个带有这些噪声标签的数据集上训练模型的方法（通常用于未来的微调），这些噪声标签通常是在自动化过程中生成的。
- en: 'In computer vision (image based) tasks, some examples are: taking an image
    level label (for classification) and automatically inferring pixel level labels
    for segmentation [[171](#bib.bib171)], clustering hidden representations computed
    by a pretrained network as pseudo-labels [[255](#bib.bib255)], or taking Instagram
    tags as labels [[143](#bib.bib143)] for pretraining. In language tasks, examples
    are given by [[153](#bib.bib153), [89](#bib.bib89), [264](#bib.bib264)], which
    provide noisy supervision by assuming all sentences mentioning two entities of
    interest express a particular relation (also known as distant supervision). A
    nice overview of weak supervision and its connection to other areas is given in
    [https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html](https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html),
    with a related post looking specifically at medical and scientific applications
    [http://hazyresearch.stanford.edu/ws4science](http://hazyresearch.stanford.edu/ws4science).'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉（基于图像）的任务中，一些示例包括：获取图像级标签（用于分类），并自动推断像素级标签以进行分割 [[171](#bib.bib171)]，对预训练网络计算的隐藏表示进行聚类作为伪标签
    [[255](#bib.bib255)]，或将 Instagram 标签作为标签 [[143](#bib.bib143)] 用于预训练。在语言任务中，示例由
    [[153](#bib.bib153), [89](#bib.bib89), [264](#bib.bib264)] 提供，这些示例通过假设提及两个感兴趣实体的所有句子表达特定关系（也称为远程监督）来提供噪声监督。有关弱监督及其与其他领域的连接的良好概述，请参见
    [https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html](https://hazyresearch.github.io/snorkel/blog/ws_blog_post.html)，有关医疗和科学应用的相关帖子请参见
    [http://hazyresearch.stanford.edu/ws4science](http://hazyresearch.stanford.edu/ws4science)。
- en: 5.5 Section Summary
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.5 小节总结
- en: In this section, we have overviewed some of the central supervised learning
    based methodologies for developing deep learning models. This is just a sampling
    of the broad collection of existing methods, and again, we hope that the descriptions
    and references will help facilitate further exploration of other approaches. One
    method not covered that might be of particular interest is multimodal learning,
    where neural networks are simultaneously trained on data from different modalities,
    such as images and text [[139](#bib.bib139), [238](#bib.bib238), [102](#bib.bib102)].
    Multimodal learning also provides a good example of the fact that it is often
    difficult to precisely categorize deep learning techniques as only being useful
    for a specific task or training regime. For example, we looked at language modelling
    for sequence tasks in this supervised learning section, but language modelling
    is also an example of self-supervision (Section [6](#S6 "6 Doing More with Less
    Data ‣ A Survey of Deep Learning for Scientific Discovery")) and generative models
    (Section [8.1](#S8.SS1 "8.1 Generative Models ‣ 8 Advanced Deep Learning Methods
    ‣ A Survey of Deep Learning for Scientific Discovery")). There are many rich combinations
    of the outlined methods in both this section and subsequent sections, which can
    prove very useful in the development of an end to end system.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们概述了一些基于监督学习的核心方法，用于开发深度学习模型。这只是现有方法广泛集合的一部分，我们希望这些描述和参考文献能帮助进一步探索其他方法。一个未涵盖但可能特别感兴趣的方法是多模态学习，其中神经网络同时在来自不同模态的数据上进行训练，如图像和文本
    [[139](#bib.bib139), [238](#bib.bib238), [102](#bib.bib102)]。多模态学习也很好地体现了这样一个事实：精确地将深度学习技术分类为仅对特定任务或训练模式有用通常是困难的。例如，我们在这一节中研究了序列任务的语言建模，但语言建模也是自监督（第[6](#S6
    "6 用更少的数据做更多的事 ‣ 科学发现的深度学习概述")节）和生成模型（第[8.1](#S8.SS1 "8.1 生成模型 ‣ 8 高级深度学习方法 ‣
    科学发现的深度学习概述")节）的一个例子。这一节和后续章节中描述的方法有许多丰富的组合，这些组合在开发端到端系统中可能非常有用。
- en: 6 Doing More with Less Data
  id: totrans-223
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 用更少的数据做更多的事
- en: '![Refer to caption](img/28b41cd7d1db7e8d755c6a19375ec2c7.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/28b41cd7d1db7e8d755c6a19375ec2c7.png)'
- en: 'Figure 9: Training neural networks with Self-Supervision. The figure illustrates
    one example of a self-supervision setup. In self-supervision, we typically have
    a collection of unlabelled data instances, in this case images. We define a pretext
    task, that will automatically generate labels for the data instances. In this
    case, the pretext task is rotation — we randomly rotate the images by some amount
    and label them by the degree of rotation. During training, the neural network
    is given this rotated image and must predict the degree of rotation. Doing so
    also requires the neural network learn useful hidden representations of the image
    data in general, so after training with self-supervision, this neural network
    can then be successfully and efficiently finetuned on a downstream task.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：使用自监督训练神经网络。该图示例了一个自监督设置的例子。在自监督学习中，我们通常有一组未标记的数据实例，这里是图像。我们定义一个预任务，它会自动为数据实例生成标签。在这种情况下，预任务是旋转——我们随机旋转图像，并按旋转角度进行标记。在训练过程中，神经网络会接收到这些旋转后的图像，并必须预测旋转的角度。这样做还要求神经网络学习图像数据的一般有用隐藏表示，因此，在自监督学习训练后，这个神经网络可以成功而高效地在下游任务中进行微调。
- en: Supervised learning methods, and specific variants such as transfer learning
    and multitask learning have been highly successful in training deep neural network
    models. However, a significant limitation to their use, and thus the use of deep
    learning, is the dependence on large amounts of labelled data. In many specialized
    domains, such as medicine, collecting a large number of high quality, reliable
    labels can be prohibitively expensive.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 监督学习方法，以及迁移学习和多任务学习等具体变体，在训练深度神经网络模型方面取得了很大成功。然而，它们使用的一个显著限制，以及深度学习的使用，是对大量标记数据的依赖。在许多专业领域，如医学，收集大量高质量、可靠的标签可能是极其昂贵的。
- en: Luckily, in just the past few years, we’ve seen remarkable advances in methods
    that reduce this dependence, particularly self-supervision and semi-supervised
    learning. These approaches still follow the paradigm of training a neural network
    to map raw data instances to a specified label, but critically, these labels are
    not collected separately, but automatically defined via a pretext task. For example,
    we might take a dataset of images, rotate some of them, and then define the label
    as the degree of rotation, which is the prediction target for the neural network.
    This enables the use of unlabelled data in training the deep neural network. In
    this section, we cover both self-supervision and semi-supervised learning as well
    as other methods such as data augmentation and denoising, all of which enable
    us to do more with less data.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 幸运的是，近年来我们在减少这种依赖的方法上取得了显著进展，特别是自监督学习和半监督学习。这些方法仍然遵循将神经网络训练为将原始数据实例映射到指定标签的范式，但关键的是，这些标签不是单独收集的，而是通过预任务自动定义的。例如，我们可以取一个图像数据集，旋转其中一些图像，然后将标签定义为旋转的角度，这就是神经网络的预测目标。这使得在训练深度神经网络时可以使用未标记的数据。在本节中，我们将介绍自监督学习和半监督学习以及其他方法，如数据增强和去噪，这些方法使我们能够用更少的数据做更多的事情。
- en: 6.1 Self-Supervised Learning
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 自监督学习
- en: In self-supervision, a pretext task is defined such that labels can be automatically
    calculated directly from the raw data instances. For example, on images, we could
    rotate the image by some amount, label it by how much it was rotated, and train
    a neural network to predict the degree of rotation [[66](#bib.bib66)] — this setup
    is illustrated in Figure [9](#S6.F9 "Figure 9 ‣ 6 Doing More with Less Data ‣
    A Survey of Deep Learning for Scientific Discovery"). This pretext task is defined
    without needing any labelling effort, but can be used to teach the network good
    representations. These representations can then be used as is or maybe with a
    little additional data for downstream problems. Arguably the biggest success of
    self-supervision has been language modelling for sequential data and specifically
    natural language problems, which we overviewed in Section [4.5.1](#S4.SS5.SSS1
    "4.5.1 Language Modelling (Next Token Prediction) ‣ 4.5 Neural Networks for Sequence
    Data ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning
    for Scientific Discovery"). Below we outline some of the most popular and successful
    self-supervision examples for both image and sequential data. (A comprehensive
    list of self-supervision methods can also be found on this page [https://github.com/jason718/awesome-self-supervised-learning](https://github.com/jason718/awesome-self-supervised-learning).)
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 在自监督中，定义了一个预任务，使得标签可以直接从原始数据实例中自动计算。例如，在图像上，我们可以将图像旋转一定角度，以旋转角度为标签，并训练神经网络预测旋转的度数[[66](#bib.bib66)]——这一设置如图[9](#S6.F9
    "图 9 ‣ 用更少的数据做更多的事 ‣ 科学发现中的深度学习调查")所示。这个预任务的定义不需要任何标注工作，但可以用来教会网络良好的表征。这些表征可以原封不动地使用，或者在下游任务中可能需要一些额外的数据。自监督最大的成功可能是在顺序数据，尤其是自然语言问题上的语言建模，这一点我们在第[4.5.1](#S4.SS5.SSS1
    "4.5.1 语言建模（下一个令牌预测） ‣ 4.5 顺序数据的神经网络 ‣ 4 标准神经网络模型和任务 ‣ 科学发现中的深度学习调查")节中概述了。下面我们概述一些在图像和顺序数据中最受欢迎和成功的自监督示例。（自监督方法的全面列表也可以在此页面找到
    [https://github.com/jason718/awesome-self-supervised-learning](https://github.com/jason718/awesome-self-supervised-learning)。）
- en: 6.1.1 Self-Supervised Learning for Images
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 自监督学习用于图像
- en: A recent, popular and simple self-supervised task for images is to predict image
    rotations [[66](#bib.bib66)]. Each image instance is transformed with one of four
    possible rotations and the deep learning model must classify the rotation correctly.
    Despite its simplicity, multiple studies have shown its success in learning good
    representations [[266](#bib.bib266), [265](#bib.bib265), [112](#bib.bib112)].
    Another popular method examined in those studies is exemplar [[51](#bib.bib51)],
    which proposes a self-supervision task relying on invariance to image transformations.
    For example, we might take a source image of a cat, and perform a sequence of
    transformations, such as rotation, adjusting contrast, flipping the image horizontally,
    etc. We get multiple images of the cat by choosing many such sequences, and train
    the neural network to recognize these all as the same image.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一个流行且简单的自监督任务是预测图像的旋转[[66](#bib.bib66)]。每个图像实例都经过四种可能旋转中的一种进行转换，深度学习模型必须正确分类这些旋转。尽管这个任务很简单，但多个研究表明，它在学习良好表征方面取得了成功[[266](#bib.bib266)、[265](#bib.bib265)、[112](#bib.bib112)]。这些研究中探讨的另一种流行方法是示例法[[51](#bib.bib51)]，它提出了一种依赖于图像变换不变性的自监督任务。例如，我们可以以一张猫的源图像为例，进行一系列变换，如旋转、调整对比度、水平翻转等。通过选择多个这样的变换序列，我们可以得到多张猫的图像，并训练神经网络将这些图像识别为同一张图像。
- en: Other methods look at using image patches as context to learn about the global
    image structure and important features. For example, [[48](#bib.bib48)] defines
    a pretext task where the relative locations of pairs of image patches must be
    determined, while [[161](#bib.bib161)] teaches a neural network to solve jigsaw
    puzzles. This latter task has been shown to be effective at large scales [[69](#bib.bib69)],
    with nice implementations and benchmarking provided by [https://github.com/facebookresearch/fair_self_supervision_benchmark](https://github.com/facebookresearch/fair_self_supervision_benchmark).
    A recent line of work has looked at using mutual information inspired metrics
    as a way to provide supervision on the relatedness of different image patches
    [[84](#bib.bib84), [169](#bib.bib169), [7](#bib.bib7), [154](#bib.bib154)], but
    these may be more intricate to implement. Many of these mutual information based
    metrics also rely on contrastive losses [[30](#bib.bib30)], which, at a high level,
    provides supervision to the network by making representations of a pair of similar
    inputs more similar than representations of a pair of different inputs. Very recently,
    a new self-supervision method, SimCLR [[29](#bib.bib29)], uses this to achieve
    high performance (one implementation at [https://github.com/sthalles/SimCLR](https://github.com/sthalles/SimCLR).)
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 其他方法通过使用图像补丁作为上下文来学习全局图像结构和重要特征。例如，[[48](#bib.bib48)] 定义了一个前置任务，其中必须确定一对图像补丁的相对位置，而
    [[161](#bib.bib161)] 则教会神经网络解决拼图任务。这后一任务已在大规模应用中证明有效 [[69](#bib.bib69)]，并由 [https://github.com/facebookresearch/fair_self_supervision_benchmark](https://github.com/facebookresearch/fair_self_supervision_benchmark)
    提供了出色的实现和基准测试。近期的研究方向探讨了使用互信息启发的度量作为提供不同图像补丁相关性监督的方法 [[84](#bib.bib84), [169](#bib.bib169),
    [7](#bib.bib7), [154](#bib.bib154)]，但这些方法可能更复杂。许多基于互信息的度量还依赖于对比损失 [[30](#bib.bib30)]，这种损失从高层次上讲，通过使一对相似输入的表示比一对不同输入的表示更相似来为网络提供监督。最近，一种新的自监督方法
    SimCLR [[29](#bib.bib29)] 利用这一点实现了高性能（一个实现可以在 [https://github.com/sthalles/SimCLR](https://github.com/sthalles/SimCLR)
    找到）。
- en: Note that some of the image registration examples given in Section [4.3.5](#S4.SS3.SSS5
    "4.3.5 Image Registration ‣ 4.3 Convolutional Neural Networks ‣ 4 Standard Neural
    Network Models and Tasks ‣ A Survey of Deep Learning for Scientific Discovery")
    are also examples of self-supervised learning, where some kind of domain specific
    similarity function can be automatically computed to assess the quality of the
    output. Such approaches may be relevant to other domains, and are useful to explore.
    A great set of open-sourced implementations of many of self-supervision methods
    is provided by [https://github.com/google/revisiting-self-supervised](https://github.com/google/revisiting-self-supervised).
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，第 [4.3.5](#S4.SS3.SSS5 "4.3.5 图像配准 ‣ 4.3 卷积神经网络 ‣ 4 标准神经网络模型和任务 ‣ 深度学习在科学发现中的调查")
    节中给出的一些图像配准示例也是自监督学习的示例，其中可以自动计算某种领域特定的相似性函数来评估输出质量。这些方法可能与其他领域相关，值得探索。许多自监督方法的开源实现由
    [https://github.com/google/revisiting-self-supervised](https://github.com/google/revisiting-self-supervised)
    提供。
- en: 6.1.2 Self-Supervised Learning for Sequential (Natural Language) Data
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 自监督学习用于序列（自然语言）数据
- en: While research on self-supervision techniques for images has been extremely
    active, the strongest successes of this framework have arguably been with sequential
    data, particularly text and natural language. The sequential structure immediately
    gives rise to effective self-supervision pretext tasks. Two dominant classes of
    pretext tasks operate by either (i) using neighboring tokens of the sequence as
    input context for predicting a target token (ii) taking in all tokens up to a
    particular position and predicting the next token. The latter of these is language
    modelling, which was overviewed in Section [4.5.1](#S4.SS5.SSS1 "4.5.1 Language
    Modelling (Next Token Prediction) ‣ 4.5 Neural Networks for Sequence Data ‣ 4
    Standard Neural Network Models and Tasks ‣ A Survey of Deep Learning for Scientific
    Discovery"). The former is the principle behind word embeddings.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对图像的自监督技术的研究极为活跃，但该框架的最强成功案例无疑是在序列数据，特别是文本和自然语言方面。这种序列结构立即引发了有效的自监督前置任务。两类主要的前置任务通过以下方式进行操作：（i）使用序列的相邻标记作为预测目标标记的输入上下文，（ii）接收所有标记直到特定位置并预测下一个标记。这后一种是语言建模，已在第[4.5.1节](#S4.SS5.SSS1
    "4.5.1 语言建模（下一个标记预测） ‣ 4.5 序列数据的神经网络 ‣ 4 标准神经网络模型和任务 ‣ 深度学习在科学发现中的综述")中概述。前一种则是词嵌入的原理。
- en: Word embeddings have been critical to solving many natural language problems.
    Before the recent successes of full fledged transfer learning in language (Section
    [5.1](#S5.SS1 "5.1 Transfer Learning ‣ 5 Key (Supervised Learning) Methods ‣ A
    Survey of Deep Learning for Scientific Discovery")) this simple self-supervised
    paradigm was where knowledge reuse was concentrated, and formed a highly important
    component of any deep learning system for natural language (sequential) data.
    From a scientific perspective, learning word embeddings for sequential data has
    the potential to identify previously unknown similarities in the data instances.
    It has already found interesting uses in aiding with the automatic analysis of
    scientific texts, such as drug name recognition systems [[131](#bib.bib131)],
    biomedical named entity recognition [[73](#bib.bib73)], identifying important
    concepts in materials science [[230](#bib.bib230)] and even detecting chemical-protein
    interactions [[37](#bib.bib37)].
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入对解决许多自然语言问题至关重要。在语言领域全面迁移学习的最新成功之前（第[5.1节](#S5.SS1 "5.1 迁移学习 ‣ 5 关键（监督学习）方法
    ‣ 深度学习在科学发现中的综述")），这种简单的自监督范式是知识重用的集中点，形成了任何自然语言（序列）数据深度学习系统的重要组成部分。从科学角度看，学习序列数据的词嵌入有可能识别数据实例中以前未知的相似性。它已经在辅助自动分析科学文本方面找到了有趣的应用，例如药物名称识别系统[[131](#bib.bib131)]、生物医学命名实体识别[[73](#bib.bib73)]、材料科学中的重要概念识别[[230](#bib.bib230)]，甚至化学-蛋白质相互作用的检测[[37](#bib.bib37)]。
- en: The key fundamental ideas of word embeddings are captured in the word2vec framework
    [[152](#bib.bib152), [151](#bib.bib151)], the original framework relying on either
    a Continuous-Bag-of-Words (CBOW) neural network or a Skip-Gram neural network.
    Actually, both of these models are less neural networks and more two simple matrix
    multiplications, with the first matrix acting as a projection, and giving the
    desired embedding. In CBOW, the context — defined as the neighborhood words —
    are input, and the model must correctly identify the target output word. In Skip-Gram,
    this is reversed, with the center word being input, and the context being predicted.
    For example, given a sentence "There is a cat on the roof", with the target word
    being cat, CBOW would take in the vector representations of (There, is, a, on,
    the, roof) and output "cat", while Skip-Gram would roughly swap the inputs and
    outputs. The simplicity of these methods may make them more suitable for many
    tasks compared to language modelling. Two nice overviews of the these methods
    are given by [Introduction to Word Embeddings and word2vec](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa),
    and [https://ruder.io/word-embeddings-1/](https://ruder.io/word-embeddings-1/).
    Other embedding methods include [[173](#bib.bib173), [123](#bib.bib123)].
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 词嵌入的关键基础思想体现在word2vec框架中[[152](#bib.bib152), [151](#bib.bib151)]，该框架最初依赖于连续词袋（CBOW）神经网络或Skip-Gram神经网络。实际上，这两种模型更像是两个简单的矩阵乘法，而不是神经网络，其中第一个矩阵作为投影，并给出所需的嵌入。在CBOW中，定义为邻域词的上下文被输入，模型必须正确识别目标输出词。在Skip-Gram中，这一过程被反转，中心词被输入，而上下文被预测。例如，给定句子"There
    is a cat on the roof"，目标词是cat，CBOW将输入（There, is, a, on, the, roof）的向量表示，并输出"cat"，而Skip-Gram则大致交换输入和输出。这些方法的简单性可能使它们相比语言建模更适合许多任务。有关这些方法的两个优秀概述可以参考[词嵌入和word2vec介绍](https://towardsdatascience.com/introduction-to-word-embedding-and-word2vec-652d0c2060fa)和[https://ruder.io/word-embeddings-1/](https://ruder.io/word-embeddings-1/)。其他嵌入方法包括[[173](#bib.bib173),
    [123](#bib.bib123)]。
- en: 6.1.3 Self-Supervision Summary
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3 自监督总结
- en: In this section we have outlined many of the interesting developments in self-supervised
    learning, a very successful way to make use of unlabelled data to learn meaningful
    representations, either for analysis or other downstream tasks. Self-supervision
    can be effectively used along with other techniques. For example, in the language
    modelling application, we saw it used for transfer learning (Section [5.1](#S5.SS1
    "5.1 Transfer Learning ‣ 5 Key (Supervised Learning) Methods ‣ A Survey of Deep
    Learning for Scientific Discovery")), where a deep learning model is first pretrained
    using the language modelling self supervision objective, and then finetuned on
    the target task of interest. In the following section, we will other ways of combining
    self-supervision with labelled data.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们概述了自监督学习的许多有趣进展，这是一种非常成功的利用未标注数据学习有意义表示的方法，无论是用于分析还是其他下游任务。自监督可以与其他技术有效结合。例如，在语言建模应用中，我们看到它被用于迁移学习（第[5.1节](#S5.SS1
    "5.1 迁移学习 ‣ 5种关键（监督学习）方法 ‣ 深度学习在科学发现中的应用概述")），其中深度学习模型首先使用语言建模自监督目标进行预训练，然后在目标任务上进行微调。在接下来的部分，我们将讨论其他将自监督与标注数据结合的方法。
- en: 6.2 Semi-Supervised Learning
  id: totrans-240
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 半监督学习
- en: While collecting large labelled datasets can be prohibitively expensive, it
    is often possible to collect a smaller amount of labelled data. When assembling
    a brand new dataset, a typical situation is having a small amount of labelled
    data and a (sometimes significantly) larger number of data instances with no labels.
    Semi-supervised learning looks at precisely this setting, proposing techniques
    that enable effective learning on labelled and unlabelled data. Below we overview
    some of the popular methods for semi-supervised learning.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然收集大量标注数据集可能代价高昂，但通常可以收集较少量的标注数据。在组建全新的数据集时，典型的情况是拥有少量的标注数据和（有时显著更多的）无标注数据实例。半监督学习正是关注这种情况，提出了在标注数据和未标注数据上进行有效学习的技术。以下我们概述了一些流行的半监督学习方法。
- en: 6.2.1 Self-Supervision with Semi-Supervised Learning
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.1 自监督与半监督学习
- en: Following on from the previous section, one natural way to make use of the unlabelled
    data is to use a self-supervised pretext task. To combine this with the labelled
    data, we can design a neural network that has two different outputs heads (exactly
    as in multitask learning, see Section [5.3](#S5.SS3 "5.3 Multitask Learning ‣
    5 Key (Supervised Learning) Methods ‣ A Survey of Deep Learning for Scientific
    Discovery")), with one output head being used for the labelled data, and the other
    for the self-supervised objective on the unlabelled data. Importantly, this means
    that the features learned by the neural network are shared between the labelled
    and unlabelled data, leading to better representations. This simple approach has
    been shown to be very effective [[266](#bib.bib266), [265](#bib.bib265)].
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 从上一节继续，一个自然的方法是使用自监督的预训练任务来利用未标注的数据。为了将其与标注数据结合，我们可以设计一个具有两个不同输出头的神经网络（正如在多任务学习中所见，见[5.3节](#S5.SS3
    "5.3 Multitask Learning ‣ 5 Key (Supervised Learning) Methods ‣ A Survey of Deep
    Learning for Scientific Discovery")），一个输出头用于标注数据，另一个用于未标注数据上的自监督目标。重要的是，这意味着神经网络学习到的特征在标注数据和未标注数据之间是共享的，从而产生更好的表示。这种简单的方法已被证明非常有效[[266](#bib.bib266),
    [265](#bib.bib265)]。
- en: 6.2.2 Self-Training (Bootstrapping)
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.2 自训练（引导）
- en: Self-training, sometimes also referred to as bootstrapping or pseudo-labels,
    is an iterative method where a deep neural network is first developed in a supervised
    fashion on the labelled data. This neural network is then used to provide (pseudo)
    labels to the unlabelled data, which can then be used in conjunction with the
    labelled data to train a new, more accurate neural network. This approach often
    works well and can even be repeated to get further improvements. There are a couple
    of common details in implementation — often when adding the neural network pseudo-labelled
    data, we only keep the most confidently pseudo-labelled examples. These pseudo-labelled
    examples may also be used for training with a different objective function compared
    to the labelled data. One of the early papers proposing this method was [[120](#bib.bib120)],
    with a more recent paper [[252](#bib.bib252)] demonstrating significant successes
    at large scale. Other variants, including mean teacher [[225](#bib.bib225)], temporal
    ensembling [[119](#bib.bib119)] and the recent MixMatch [[19](#bib.bib19)] also
    primarily use the self-training approach, but incorporate elements of consistency
    (see below). There are nice open sourced implementations of these methods, such
    as [https://github.com/CuriousAI/mean-teacher](https://github.com/CuriousAI/mean-teacher)
    for mean teacher and [https://github.com/google-research/mixmatch](https://github.com/google-research/mixmatch)
    and [https://github.com/YU1ut/MixMatch-pytorch](https://github.com/YU1ut/MixMatch-pytorch)
    for MixMatch.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 自训练，有时也称为引导或伪标签，是一种迭代方法，其中深度神经网络首先在标注数据上以监督方式开发。然后，这个神经网络被用来为未标注的数据提供（伪）标签，这些标签可以与标注数据一起用于训练一个新的、更准确的神经网络。这种方法通常效果良好，甚至可以重复使用以获得进一步的改进。实现中有几个常见的细节——通常在添加神经网络伪标注的数据时，我们只保留最具信心的伪标注样本。这些伪标注样本也可以用于与标注数据不同的目标函数的训练。早期提出这种方法的论文之一是[[120](#bib.bib120)]，更近期的论文[[252](#bib.bib252)]则展示了在大规模下的显著成功。其他变体，包括均值教师[[225](#bib.bib225)]、时间集成[[119](#bib.bib119)]和最近的MixMatch[[19](#bib.bib19)]，也主要使用自训练方法，但结合了一致性元素（见下文）。这些方法有很好的开源实现，例如均值教师的[https://github.com/CuriousAI/mean-teacher](https://github.com/CuriousAI/mean-teacher)以及MixMatch的[https://github.com/google-research/mixmatch](https://github.com/google-research/mixmatch)和[https://github.com/YU1ut/MixMatch-pytorch](https://github.com/YU1ut/MixMatch-pytorch)。
- en: 6.2.3 Enforcing Consistency (Smoothness)
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.3 强化一致性（平滑性）
- en: An important theme in many semi-supervised methods has been to provide supervision
    on the unlabelled data through enforcing consistency. If a human was given two
    images A and B, where B was a slightly perturbed version of A (maybe blurred,
    maybe some pixels obscured or blacked out), they would give these images the same
    label — consistency. We can also apply this principle to provide feedback to our
    neural network on the unlabelled data, combining it with the labelled data predictions
    as in multitask learning (Section [5.3](#S5.SS3 "5.3 Multitask Learning ‣ 5 Key
    (Supervised Learning) Methods ‣ A Survey of Deep Learning for Scientific Discovery"))
    to form a semi-supervised learning algorithm. A popular method on enforcing consistency
    is virtual adversarial training [[155](#bib.bib155)], which enforces consistency
    across carefully chosen image perturbations. Another paper, unsupervised data
    augmentation [[251](#bib.bib251)], uses standard data augmentation techniques
    such as cutout [[44](#bib.bib44)] for images and back translation for text [[206](#bib.bib206)]
    to perturb images and enforces consistency across them. [[265](#bib.bib265)] uses
    consistency constraints along with other semi-supervised and self-supervised techniques
    in its full algorithm.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 许多半监督方法中的一个重要主题是通过强制一致性来对未标记数据提供监督。如果一个人被给出两张图像 A 和 B，其中 B 是 A 的略微扰动版本（可能是模糊的，或者有些像素被遮挡或黑掉），他们会给这些图像相同的标签——一致性。我们也可以应用这一原则，对未标记数据的神经网络提供反馈，将其与标记数据预测结合起来，如多任务学习（第
    [5.3](#S5.SS3 "5.3 Multitask Learning ‣ 5 Key (Supervised Learning) Methods ‣
    A Survey of Deep Learning for Scientific Discovery") 节）中所述，以形成半监督学习算法。一个流行的强制一致性的方法是虚拟对抗训练
    [[155](#bib.bib155)]，它在精心选择的图像扰动之间强制一致性。另一篇论文，无监督数据增强 [[251](#bib.bib251)]，使用标准的数据增强技术，如图像的
    cutout [[44](#bib.bib44)] 和文本的反向翻译 [[206](#bib.bib206)]，来扰动图像并强制在这些扰动之间保持一致。[[265](#bib.bib265)]
    在其完整算法中使用了一致性约束以及其他半监督和自监督技术。
- en: 6.2.4 Co-training
  id: totrans-248
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.4 协同训练
- en: Another way to provide feedback on unlabelled data is to train two (many) neural
    network models, each on a different view of the raw data. For example, with text
    data, each model might see a different part of the input sentence. These models
    can then be given feedback to be maximally consistent with each other, or with
    a different model which sees all of the data, or even used for self-training,
    with each different model providing pseudo labels on the instances it is most
    confident on. This post [https://ruder.io/semi-supervised/](https://ruder.io/semi-supervised/)
    gives a nice overview of different co-training schemes, and [[34](#bib.bib34),
    [179](#bib.bib179), [74](#bib.bib74)] are some recent papers implementing this
    in text and images.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种对未标记数据提供反馈的方法是训练两个（或多个）神经网络模型，每个模型处理原始数据的不同视图。例如，对于文本数据，每个模型可能会看到输入句子的不同部分。这些模型可以被反馈以使彼此之间或与一个可以看到所有数据的不同模型之间保持最大的一致性，甚至可以用于自我训练，每个不同的模型对其最有信心的实例提供伪标签。这个帖子
    [https://ruder.io/semi-supervised/](https://ruder.io/semi-supervised/) 给出了不同协同训练方案的简要概述，[[34](#bib.bib34),
    [179](#bib.bib179), [74](#bib.bib74)] 是一些最近在文本和图像中实现这一方法的论文。
- en: 6.2.5 Semi-Supervised Learning Summary
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.2.5 半监督学习总结
- en: Semi-supervised learning is a powerful way to reduce the need for labelled data
    and can significantly boost the efficacy of deep learning models. Semi-supervised
    learning can be applied in any situation where a meaningful task can be created
    on the unlabelled data. In this section we have overviewed some natural ways to
    define such tasks, but there may be many creative alternatives depending on the
    domain of interest. We hope the references will provide a helpful starting point
    for implementation and further exploration!
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是一种强大的方法，可以减少对标记数据的需求，并显著提升深度学习模型的效能。半监督学习可以应用于任何可以在未标记数据上创建有意义任务的情境。在本节中，我们概述了一些定义这些任务的自然方法，但根据感兴趣的领域，可能还会有许多创造性的替代方案。我们希望这些参考文献能为实施和进一步探索提供一个有益的起点！
- en: 6.3 Data Augmentation
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 数据增强
- en: As depicted in Figure [1](#S2.F1 "Figure 1 ‣ 2.2 Deep Learning Workflow ‣ 2
    High Level Considerations for Deep Learning ‣ A Survey of Deep Learning for Scientific
    Discovery"), data augmentation is an important part of the deep learning workflow.
    Data augmentation refers to the process of artificially increasing the size and
    diversity of the training data by applying a variety of transformations to the
    raw data instances. For example, if the raw instances were to consist of images,
    we might artificially pad out the image borders and then perform an off center
    (random) crop to give us the final augmented image instance. Aside from increasing
    the size and diversity of the data, data augmentation offers the additional benefit
    of encouraging the neural network to be robust to certain kinds of common transformations
    of data instances. In this section, we overview some of the most popular data
    augmentation techniques for image and sequential data. These techniques will typically
    already be part of many open sourced deep learning pipelines, or easy to invoke
    in any mainstream deep learning software package. There are also some specific
    libraries written for augmentations, for example imgaug [https://github.com/aleju/imgaug](https://github.com/aleju/imgaug),
    nlpaug [https://github.com/makcedward/nlpaug](https://github.com/makcedward/nlpaug)
    and albumentations [https://github.com/albumentations-team/albumentations](https://github.com/albumentations-team/albumentations).
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [1](#S2.F1 "图 1 ‣ 2.2 深度学习工作流程 ‣ 2 高层次的深度学习考虑 ‣ 科学发现中的深度学习综述") 所示，数据增强是深度学习工作流程中的一个重要部分。数据增强指的是通过对原始数据实例应用各种变换，人工增加训练数据的大小和多样性。例如，如果原始实例由图像组成，我们可能会人工扩展图像边界，然后执行一个偏离中心（随机）的裁剪，以获得最终的增强图像实例。除了增加数据的大小和多样性外，数据增强还有助于鼓励神经网络对某些常见数据实例变换具有鲁棒性。在本节中，我们将概述一些用于图像和序列数据的最流行的数据增强技术。这些技术通常已经是许多开源深度学习管道的一部分，或者可以在任何主流深度学习软件包中轻松调用。还有一些专门为增强编写的库，例如
    imgaug [https://github.com/aleju/imgaug](https://github.com/aleju/imgaug)、nlpaug
    [https://github.com/makcedward/nlpaug](https://github.com/makcedward/nlpaug) 和
    albumentations [https://github.com/albumentations-team/albumentations](https://github.com/albumentations-team/albumentations)。
- en: 6.3.1 Data Augmentation for Image Data
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.1 图像数据的数据增强
- en: '![Refer to caption](img/203fa1a59c489ae538394ba51f9c00ea.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/203fa1a59c489ae538394ba51f9c00ea.png)'
- en: 'Figure 10: An illustration of the Mixup data augmentation technique. Image
    source [[40](#bib.bib40)] The figure provides an example of the Mixup data augmentation
    method — an image of a cat and an image of a dog are linearly combined, with $0.4$
    weight on the cat and $0.6$ weight on the dog, to give a new input image shown
    in the bottom with a smoothed label of $0.4$ weight on cat and $0.6$ weight on
    dog. Mixup has been a very popular and successful data augmentation method for
    image tasks.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：Mixup 数据增强技术的示意图。图像来源 [[40](#bib.bib40)] 该图展示了 Mixup 数据增强方法的一个示例——一只猫的图像和一只狗的图像被线性组合，其中猫的权重为
    $0.4$，狗的权重为 $0.6$，生成了底部显示的新输入图像，并且标签平滑，猫的权重为 $0.4$，狗的权重为 $0.6$。Mixup 已成为图像任务中非常流行和成功的数据增强方法。
- en: Simple augmentations for image data consider transformations such as horizontal
    flips or random crops (padding the image borders and taking an off center crop.)
    Inspired by these simple methods are two very successful image augmentation strategies,
    cutout [[44](#bib.bib44)], which removes a patch from the input image, and RICAP
    [[222](#bib.bib222)], which combines patches from four different input image to
    create a new image (with new label a combination of the original labels.) This
    somewhat surprising latter technique of combining images has in fact shown to
    be very successful in mixup [[268](#bib.bib268)], another data augmentation strategy
    where linear combinations of images (instead of patches) are used. (This strategy
    has also been combined with cutout in the recently proposed cutmix augmentation
    strategy [[261](#bib.bib261)], with code [https://github.com/clovaai/CutMix-PyTorch](https://github.com/clovaai/CutMix-PyTorch).)
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像数据的简单增强考虑诸如水平翻转或随机裁剪（填充图像边框并进行偏心裁剪）等变换。受到这些简单方法启发的是两种非常成功的图像增强策略：cutout
    [[44](#bib.bib44)]，它从输入图像中移除一个补丁，和RICAP [[222](#bib.bib222)]，它将四个不同输入图像的补丁组合成一个新图像（新标签为原始标签的组合）。这一令人惊讶的图像组合技术在mixup
    [[268](#bib.bib268)]中表现得非常成功，mixup是一种数据增强策略，其中使用图像的线性组合（而不是补丁）。这一策略还与cutout结合在最近提出的cutmix增强策略中[[261](#bib.bib261)]，代码见[https://github.com/clovaai/CutMix-PyTorch](https://github.com/clovaai/CutMix-PyTorch)。
- en: Other useful augmentation strategies include TANDA [[188](#bib.bib188)] which
    learns a model to compose data augmentations, the related randaugment [[38](#bib.bib38)],
    choosing a random subset of different possible augmentations, population based
    augmentation [[85](#bib.bib85)] which randomly searches over different augmentation
    policies, [[91](#bib.bib91)] applying color distortions to the image and the recently
    proposed augmix [[82](#bib.bib82)] (code [https://github.com/google-research/augmix](https://github.com/google-research/augmix).)
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 其他有用的增强策略包括TANDA [[188](#bib.bib188)]，它学习一个模型来组合数据增强，相关的randaugment [[38](#bib.bib38)]，选择不同可能增强的随机子集，基于种群的增强
    [[85](#bib.bib85)]，它在不同的增强策略上随机搜索，以及[[91](#bib.bib91)]，对图像应用颜色失真，还有最近提出的augmix
    [[82](#bib.bib82)]（代码见[https://github.com/google-research/augmix](https://github.com/google-research/augmix)）。
- en: 6.3.2 Data Augmentation for Sequence Data
  id: totrans-259
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.3.2 顺序数据的增强
- en: Data augmentation for sequential data typically falls into either (i) directly
    modifying the input sequence, or (ii) in the case of sequence to sequence tasks
    (Section [4.5.2](#S4.SS5.SSS2 "4.5.2 Sequence to Sequence ‣ 4.5 Neural Networks
    for Sequence Data ‣ 4 Standard Neural Network Models and Tasks ‣ A Survey of Deep
    Learning for Scientific Discovery")), increasing the number of input-output sequences
    through noisy translation with the neural network. When directly modifying the
    input sequence, common perturbations include randomly deleting a sequence token
    (comparable to the masking approach used in [[43](#bib.bib43)]), swapping sets
    of sequence tokens, and replacing a token with its synonym. This latter strategy
    is usually guided by word embeddings [[239](#bib.bib239)] or contextualized word
    embeddings [[110](#bib.bib110)]. Examples of combining these transformations are
    given by [[243](#bib.bib243), [98](#bib.bib98)], with code repositories such as
    [https://github.com/makcedward/nlpaug](https://github.com/makcedward/nlpaug) providing
    some simple implementations.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 顺序数据的增强通常分为（i）直接修改输入序列，或（ii）在序列到序列任务的情况下（第 [4.5.2](#S4.SS5.SSS2 "4.5.2 Sequence
    to Sequence ‣ 4.5 Neural Networks for Sequence Data ‣ 4 Standard Neural Network
    Models and Tasks ‣ A Survey of Deep Learning for Scientific Discovery") 节），通过神经网络的噪声翻译增加输入输出序列的数量。直接修改输入序列时，常见的扰动包括随机删除序列标记（类似于[[43](#bib.bib43)]中使用的掩码方法）、交换序列标记的集合，以及用同义词替换标记。后一种策略通常由词嵌入[[239](#bib.bib239)]或上下文化词嵌入[[110](#bib.bib110)]指导。这些转换的组合示例由[[243](#bib.bib243),
    [98](#bib.bib98)]给出，代码库如[https://github.com/makcedward/nlpaug](https://github.com/makcedward/nlpaug)提供了一些简单的实现。
- en: The other dominant approach to data augmentation of sequences is using sequence-to-sequence
    models to generate new data instances, known as back-translation [[206](#bib.bib206),
    [54](#bib.bib54)]. Concretely, suppose we have a model to translate from English
    sequences to German sequences. We can take the output German sequence and use
    existing tools/noisy heuristics to translate it back to English. This gives us
    an additional English-German sequence pair.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个主流的数据增强方法是使用序列到序列模型生成新的数据实例，这被称为反向翻译[[206](#bib.bib206), [54](#bib.bib54)]。具体来说，假设我们有一个从英文序列翻译到德文序列的模型。我们可以将输出的德文序列翻译回英文，使用现有工具/噪声启发式方法。这将为我们提供一个额外的英文-德文序列对。
- en: 6.4 Data (Image) Denoising
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 数据（图像）去噪
- en: 'When measuring and collecting high dimensional data, noise can easily be introduced
    to the raw instances, be they images or single-cell data. As a result there has
    been significant interest and development of deep learning techniques to denoise
    the data. Many of these recent methods work even without paired noisy and clean
    data samples, and many be applicable in a broad range of settings. For instance,
    Noise2Noise [[122](#bib.bib122)] uses a U-net neural network architecture to denoise
    images given multiple noisy copies. The recent Noise2Self [[14](#bib.bib14)] (with
    code: [https://github.com/czbiohub/noise2self](https://github.com/czbiohub/noise2self))
    frames denoising as a self-supervision problem, using different subsets of features
    (with assumed independent noise properties) to perform denoising, applying it
    to both images as well as other high dimensional data.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在测量和收集高维数据时，噪声很容易被引入到原始实例中，无论是图像还是单细胞数据。因此，深度学习去噪技术引起了广泛的兴趣和发展。许多这些最新方法即使在没有配对的噪声和清晰数据样本的情况下也能工作，并且适用于广泛的场景。例如，Noise2Noise
    [[122](#bib.bib122)] 使用 U-net 神经网络架构给定多个噪声副本以去噪图像。最近的 Noise2Self [[14](#bib.bib14)]（代码：[https://github.com/czbiohub/noise2self](https://github.com/czbiohub/noise2self)）将去噪框架视为自我监督问题，利用不同特征子集（具有假定独立的噪声属性）进行去噪，适用于图像以及其他高维数据。
- en: 7 Interpretability, Model Inspection and Representation Analysis
  id: totrans-264
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 解释性、模型检查和表示分析
- en: Many standard applications of deep learning (and machine learning more broadly)
    focus on prediction — learning to output specific target values given an input.
    Scientific applications, on the other hand, are often focused on understanding
    — identifying underlying mechanisms giving rise to observed patterns in the data.
    When applying deep learning in scientific settings, we can use these observed
    phenomena as prediction targets, but the ultimate goal remains to understand what
    attributes give rise to these observations. For example, the core scientific question
    might be on how certain amino acid sequences (encoding a protein) give rise to
    particular kinds of protein function. While we might frame this as a prediction
    problem, training a deep neural network to take as input an amino acid sequence
    and output the predicted properties of the protein, we would ideally like to understand
    how that amino acid sequence resulted in the observed protein function.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（以及更广泛的机器学习）的许多标准应用专注于预测——学习在给定输入的情况下输出特定的目标值。另一方面，科学应用通常专注于理解——识别引发数据中观察到的模式的潜在机制。在科学环境中应用深度学习时，我们可以将这些观察到的现象用作预测目标，但**终极**目标仍然是理解是什么属性导致了这些观察结果。例如，核心科学问题可能是某些氨基酸序列（编码蛋白质）如何导致特定的蛋白质功能。虽然我们可以将其框定为预测问题，训练一个深度神经网络以氨基酸序列作为输入，输出预测的蛋白质属性，但我们理想的目标是理解氨基酸序列如何导致观察到的蛋白质功能。
- en: To answer these kinds of questions, we can turn to interpretability techniques.
    Interpretability methods are sometimes equated to a fully understandable, step-by-step
    explanation of the model’s decision process. Such detailed insights can often
    be intractable, especially for complex deep neural network models. Instead, research
    in interpretability focuses on a much broader suite of techniques that can provide
    insights ranging from (rough) feature attributions — determining what input features
    matter the most, to model inspection — determining what causes certain neurons
    in the network to fire. In fact, these two examples also provide a rough split
    in the type of interpretability method.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 为了回答这些问题，我们可以转向解释性技术。解释性方法有时被等同于对模型决策过程的完全可理解的逐步解释。这种详细的洞察往往难以实现，尤其是对于复杂的深度神经网络模型。相反，解释性研究集中于一系列更广泛的技术，提供从（粗略的）特征归因——确定哪些输入特征最为重要，到模型检查——确定导致网络中某些神经元激活的原因的见解。实际上，这两个例子也大致区分了解释性方法的类型。
- en: One large set of methods (which we refer to as Feature Attribution and Per Example
    Interpretability) concentrates on taking a specific input along with a trained
    deep neural network, and determining what features of the input are most important.
    The other broad class of techniques looks at taking a trained model, and a set
    of inputs, to determine what different parts of the network have learned (referred
    to as Model Inspection and Representational Analysis). This latter set of methods
    can be very useful in revealing important, hidden patterns in the data that the
    model has implicitly learned through being trained on the predictive task. For
    example, in [[118](#bib.bib118)], which looks at machine translation, representation
    analysis techniques are used to illustrate latent linguistic structure learned
    by the model. We overview both sets of methods below.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 一大类方法（我们称之为特征归因与每例解释性）集中于获取一个特定输入和一个训练好的深度神经网络，并确定输入的哪些特征最为重要。另一类广泛的技术则着眼于获取一个训练好的模型和一组输入，来确定网络的不同部分学到了什么（称为模型检查与表征分析）。后一类方法在揭示模型通过预测任务隐含学习的重要数据模式方面非常有用。例如，在[[118](#bib.bib118)]中，涉及机器翻译的研究使用表征分析技术来展示模型所学习的潜在语言结构。我们将在下文概述这两类方法。
- en: 7.1 Feature Attribution and Per Example Interpretability
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 特征归因与每例解释性
- en: 'We start off by overviewing some of the popular techniques used to provide
    feature attribution at a per example level, answering questions such as which
    parts of an input image are most important for a particular model prediction.
    These techniques can be further subcategorized as follows:'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先概述一些流行的技术，用于在每个示例级别提供特征归因，回答诸如哪些输入图像的部分对于特定模型预测最重要等问题。这些技术可以进一步细分如下：
- en: 7.1.1 Saliency Maps and Input Masks
  id: totrans-270
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.1 显著性图和输入掩码
- en: '![Refer to caption](img/7a143494b454fbb2dcbbbd4104dd0cc9.png)'
  id: totrans-271
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7a143494b454fbb2dcbbbd4104dd0cc9.png)'
- en: 'Figure 11: The output of SmoothGrad, a type of saliency map. Image source [[215](#bib.bib215)]
    The figure shows the original input image (left), raw gradients (middle), which
    are often too noisy for reliable feature attributions, and SmoothGrad (right),
    a type of saliency map that averages over perturbations to produce a more coherent
    feature attribution visualization the input. In particular, we can clearly see
    that the monument in the picture is important for the model output.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：SmoothGrad的输出，一种显著性图。图像来源[[215](#bib.bib215)]。该图展示了原始输入图像（左），原始梯度（中间），这些通常对于可靠的特征归因来说噪声过多，以及SmoothGrad（右），一种显著性图，通过对扰动进行平均以生成更连贯的特征归因可视化。特别是，我们可以清晰地看到图中的纪念碑对模型输出的重要性。
- en: At a high level, saliency maps take the gradient of the output prediction with
    respect to the input. This gives a mask over the input, highlighting which regions
    have large gradients (most important for the prediction) and which have smaller
    gradients. First introduced by [[213](#bib.bib213)], there are many variants of
    saliency maps, such as Grad-CAM [[204](#bib.bib204)], SmoothGrad [[215](#bib.bib215)],
    IntGrad [[220](#bib.bib220)], which make the resulting feature attributions more
    robust. These and other methods are implemented in [https://github.com/PAIR-code/saliency](https://github.com/PAIR-code/saliency).
    Note that while these methods can be extremely useful, their predictions are not
    perfect [[105](#bib.bib105)], and must be validated further.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 从高层次来看，显著性图取输出预测相对于输入的梯度。这会在输入上给出一个掩码，突出显示哪些区域具有较大的梯度（对预测最重要）以及哪些区域具有较小的梯度。首次由[[213](#bib.bib213)]介绍，显著性图有许多变体，如Grad-CAM
    [[204](#bib.bib204)]、SmoothGrad [[215](#bib.bib215)]、IntGrad [[220](#bib.bib220)]，这些变体使得结果特征归因更加稳健。这些方法及其他方法已在
    [https://github.com/PAIR-code/saliency](https://github.com/PAIR-code/saliency)
    实现。请注意，虽然这些方法可能非常有用，但它们的预测并不完美[[105](#bib.bib105)]，需要进一步验证。
- en: Closely related to these saliency methods is [[166](#bib.bib166)], which provides
    the ability to inspect the kinds of features causing neurons across different
    hidden layers to fire. The full, interactive paper can be read at [https://distill.pub/2018/building-blocks/](https://distill.pub/2018/building-blocks/)
    with code and tutorials available at [https://github.com/tensorflow/lucid](https://github.com/tensorflow/lucid).
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 与这些显著性方法密切相关的是[[166](#bib.bib166)]，它提供了检查不同隐藏层中的神经元触发特征的能力。完整的交互式论文可以在 [https://distill.pub/2018/building-blocks/](https://distill.pub/2018/building-blocks/)
    阅读，代码和教程可在 [https://github.com/tensorflow/lucid](https://github.com/tensorflow/lucid)
    获取。
- en: Many other techniques look at computing some kind of input mask, several of
    them using deconvolutional layers, first proposed by [[263](#bib.bib263)] and
    built on by [[106](#bib.bib106)] and [[20](#bib.bib20)]. Other work looks at directly
    optimizing to find a sparse mask that will highlight the most important input
    features [[59](#bib.bib59)] (with associated code [https://github.com/jacobgil/pytorch-explain-black-box](https://github.com/jacobgil/pytorch-explain-black-box))
    or finding such a mask through an iterative algorithm [[25](#bib.bib25)].
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 许多其他技术着眼于计算某种输入掩码，其中一些使用了去卷积层，这些层最早由[[263](#bib.bib263)]提出，并由[[106](#bib.bib106)]和[[20](#bib.bib20)]进一步构建。其他工作则直接优化以找到一个稀疏的掩码，这个掩码将突出最重要的输入特征[[59](#bib.bib59)]（相关代码
    [https://github.com/jacobgil/pytorch-explain-black-box](https://github.com/jacobgil/pytorch-explain-black-box)）或通过迭代算法找到这样的掩码[[25](#bib.bib25)]。
- en: 7.1.2 Feature Ablations and Perturbations
  id: totrans-276
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.1.2 特征消融和扰动
- en: Related to some of masking approaches above, but with enough differences to
    categorize separately are several methods that isolate the crucial features of
    the input either by performing feature ablations or computing perturbations of
    the input and using these perturbations along with the original input to inform
    the importance of different features.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述一些掩码方法相关，但有足够的区别以便单独分类的是几种方法，这些方法通过执行特征消融或计算输入的扰动来隔离输入的关键特征，并使用这些扰动与原始输入一起指示不同特征的重要性。
- en: 'Arguably the most well known of the ablation based approaches is the notion
    of a Shapely value, first introduced in [[207](#bib.bib207)]. This estimates the
    importance of a particular feature $x_{0}$ in the input by computing the predictive
    power of a subset of input features containing $x_{0}$ and averaging over all
    possible such subsets. While Shapely values may be expensive to compute naively
    for deep learning, follow on work [[140](#bib.bib140)] has proposed more efficient
    (and expressive) variants, with highly popular opensourced implementation: [https://github.com/slundberg/shap](https://github.com/slundberg/shap).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，基于消融的方法中最为人熟知的是Shapley值的概念，最早由[[207](#bib.bib207)]介绍。这通过计算包含特定特征$x_{0}$的输入特征子集的预测能力，并对所有可能的子集进行平均，来估计输入中特定特征$x_{0}$的重要性。虽然对于深度学习而言，Shapley值的计算可能非常昂贵，但后续工作[[140](#bib.bib140)]提出了更高效（且更具表达力）的变体，具有高度受欢迎的开源实现：[https://github.com/slundberg/shap](https://github.com/slundberg/shap)。
- en: The shap opensourced implementation above also unifies some related approaches
    that use perturbations to estimate feature values. One such approach is LIME [[194](#bib.bib194)],
    which uses multiple local perturbations to enable learning an interpretable local
    model. Another is DeepLIFT, which uses a reference input to compare activation
    differences [[210](#bib.bib210)], and yet another approach, Layer-wise Relevance
    Propagation [[6](#bib.bib6)] looks at computing relevance scores in a layerwise
    manner.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 上述 shap 开源实现也统一了一些相关方法，这些方法使用扰动来估计特征值。其中一种方法是 LIME [[194](#bib.bib194)]，它使用多种局部扰动来学习一个可解释的局部模型。另一种是
    DeepLIFT，它使用参考输入来比较激活差异 [[210](#bib.bib210)]，还有一种方法是逐层相关传播 [[6](#bib.bib6)]，它关注于逐层计算相关性分数。
- en: Other work performing ablations to estimate feature importance includes [[275](#bib.bib275)]
    (with code [https://github.com/lmzintgraf/DeepVis-PredDiff](https://github.com/lmzintgraf/DeepVis-PredDiff)),
    while [[59](#bib.bib59)], described in Section [7.1.1](#S7.SS1.SSS1 "7.1.1 Saliency
    Maps and Input Masks ‣ 7.1 Feature Attribution and Per Example Interpretability
    ‣ 7 Interpretability, Model Inspection and Representation Analysis ‣ A Survey
    of Deep Learning for Scientific Discovery") has elements of using input perturbations.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 其他进行消融实验以估计特征重要性的工作包括 [[275](#bib.bib275)]（代码 [https://github.com/lmzintgraf/DeepVis-PredDiff](https://github.com/lmzintgraf/DeepVis-PredDiff)），而
    [[59](#bib.bib59)]，在第 [7.1.1](#S7.SS1.SSS1 "7.1.1 Saliency Maps and Input Masks
    ‣ 7.1 Feature Attribution and Per Example Interpretability ‣ 7 Interpretability,
    Model Inspection and Representation Analysis ‣ A Survey of Deep Learning for Scientific
    Discovery") 节中描述，具有使用输入扰动的元素。
- en: 7.2 Model Inspection and Representational Analysis
  id: totrans-281
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 模型检查和表征分析
- en: In this second class of interpretability methods, the focus is on gaining insights
    not at a single input example level, but using a set of examples (sometimes implicitly
    through the trained network) to understand the salient properties of the data.
    We overview some different approaches below.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 在第二类可解释性方法中，重点不是在单个输入示例级别获得见解，而是使用一组示例（有时通过训练的网络隐含地）来理解数据的显著属性。我们在下面概述了一些不同的方法。
- en: 7.2.1 Probing and Activating Hidden Neurons
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.1 探测和激活隐藏神经元
- en: '![Refer to caption](img/74be6601687e6afd1634c9f08c6582ab.png)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/74be6601687e6afd1634c9f08c6582ab.png)'
- en: 'Figure 12: Visualization of the kinds of features hidden neurons have learned
    to detect. Image source [[165](#bib.bib165)] This figure, from [[165](#bib.bib165)],
    illustrates the result of optimizing inputs to show what features hidden neurons
    have learned to recognize. In this example, the hidden neuron has learned to detect
    (especially) soccer balls, tennis balls, baseballs, and even the legs of soccer
    players.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：隐藏神经元学会检测的特征类型的可视化。图像来源 [[165](#bib.bib165)] 本图，来自 [[165](#bib.bib165)]，展示了优化输入以显示隐藏神经元学会识别的特征的结果。在这个例子中，隐藏神经元学会了检测（特别是）足球、网球、棒球，甚至足球运动员的腿。
- en: A large class of interpretability methods looks at either (i) probing hidden
    neurons in the neural network — understanding what kinds of inputs it activates
    for (ii) directly optimizing the input to activate a hidden neuron. Both of these
    techniques can provide useful insights into what the neural network has chosen
    to pay attention to, which in turn corresponds to important properties of the
    data.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 大量可解释性方法关注于 (i) 探测神经网络中的隐藏神经元——理解其对何种输入的激活 (ii) 直接优化输入以激活隐藏神经元。这两种技术都能提供有用的见解，了解神经网络选择关注的内容，这反过来对应于数据的重要属性。
- en: Several papers falls into the probing category [[259](#bib.bib259), [272](#bib.bib272)],
    with an especially thorough study given by Network Dissection [[17](#bib.bib17)].
    Here here hidden neurons are categorized by the kinds of features they respond
    to. The paper website [http://netdissect.csail.mit.edu/](http://netdissect.csail.mit.edu/)
    contains method details as well as links to the code and data.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 几篇论文属于探测类别 [[259](#bib.bib259), [272](#bib.bib272)]，其中网络解剖的研究尤为详细 [[17](#bib.bib17)]。在这里，隐藏神经元按其响应的特征类型进行分类。论文网站
    [http://netdissect.csail.mit.edu/](http://netdissect.csail.mit.edu/) 包含了方法细节以及代码和数据的链接。
- en: 'The other broad category of methods take a neural network, fix its parameters,
    and optimize the input to find the kinds of features that makes some hidden neuron
    activate. There are several papers using this approach, but of particular note
    is Feature Visualization [[165](#bib.bib165)], with an interactive article and
    code at: [https://distill.pub/2017/feature-visualization/](https://distill.pub/2017/feature-visualization/).
    Followup work, Activation Atlases [[26](#bib.bib26)] (with page [https://distill.pub/2019/activation-atlas/](https://distill.pub/2019/activation-atlas/)),
    does this across many different concepts, providing a full mapping of the features
    learned by the neural network. More recently [[164](#bib.bib164)] has used this
    as a building block to further understand how certain computations are performed
    in a neural network. Also related is [[104](#bib.bib104)], which looks at finding
    linear combinations of hidden neurons that correspond to interpretable concepts.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 另一类方法是使用神经网络，固定其参数，并优化输入以发现激活某些隐藏神经元的特征。这种方法有几篇论文使用，但特别值得注意的是特征可视化 [[165](#bib.bib165)]，有一个互动文章和代码，网址是：[https://distill.pub/2017/feature-visualization/](https://distill.pub/2017/feature-visualization/)。后续工作，激活图谱
    [[26](#bib.bib26)]（页面：[https://distill.pub/2019/activation-atlas/](https://distill.pub/2019/activation-atlas/)），对许多不同概念进行了处理，提供了神经网络所学习特征的完整映射。最近的研究
    [[164](#bib.bib164)] 将此作为构建模块，以进一步理解神经网络中如何执行某些计算。另一个相关的研究是 [[104](#bib.bib104)]，它关注于寻找与可解释概念对应的隐藏神经元的线性组合。
- en: '![Refer to caption](img/2ed5c052cdef2fa08de8fa4f1fe9c581.png)'
  id: totrans-289
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2ed5c052cdef2fa08de8fa4f1fe9c581.png)'
- en: 'Figure 13: Clustering neural network hidden representations to reveal linguistic
    structures. Image source [[118](#bib.bib118)] In work on analyzing multilingual
    translation systems [[118](#bib.bib118)], representational analysis techniques
    are used to compute similarity of neural network (Transformer) hidden representations
    across different languages. Performing clustering on the result reveals grouping
    of different language representations (each language a point on the plot) according
    to language families, which affect linguistic structure. Importantly, this analysis
    uses the neural network to identify key properties of the underlying data, a mode
    of investigation that might be very useful in scientific domains.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：聚类神经网络隐藏表示以揭示语言结构。图像来源 [[118](#bib.bib118)] 在分析多语言翻译系统的研究 [[118](#bib.bib118)]
    中，使用表示分析技术来计算不同语言的神经网络（Transformer）隐藏表示的相似性。对结果进行聚类可以揭示不同语言表示的分组（每种语言在图上表示为一个点），这些分组按照语言家族进行排列，从而影响语言结构。重要的是，这种分析利用神经网络识别基础数据的关键属性，这种调查模式在科学领域可能非常有用。
- en: 7.2.2 Dimensionality Reduction on Neural Network Hidden Representations
  id: totrans-291
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.2 神经网络隐藏表示的降维
- en: In many standard scientific settings, e.g. analyzing single cell data, dimensionality
    reduction methods such as PCA, t-SNE [[141](#bib.bib141)], UMAP [[148](#bib.bib148)]
    are very useful in revealing important factors of variation and critical differences
    in the data subpopulations e.g. tumor cells vs healthy cells. Such methods can
    also be used on the hidden activations (over some input dataset) of a neural network.
    Through the process of being trained on some predictive task, the neural network
    may implicitly learn these important data attributes in its hidden representations,
    which can then be extracted through dimensionality reduction methods.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多标准科学设置中，例如分析单细胞数据，降维方法如 PCA、t-SNE [[141](#bib.bib141)]、UMAP [[148](#bib.bib148)]
    对揭示数据变异的重要因素和关键差异（例如肿瘤细胞与健康细胞）非常有用。这些方法也可以用于神经网络的隐藏激活（对某些输入数据集）。通过在某些预测任务上进行训练，神经网络可能会在其隐藏表示中隐式学习这些重要的数据属性，这些属性随后可以通过降维方法提取出来。
- en: 7.2.3 Representational Comparisons and Similarity
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 7.2.3 表示比较和相似性
- en: Related to more standard approaches of dimensionality reduction and clustering,
    a line of work has studied comparing hidden representations across different neural
    network models. Early work applied matching algorithms [[126](#bib.bib126)] with
    follow on approaches using canonical correlation analysis [[183](#bib.bib183),
    [157](#bib.bib157)] (with associated code [https://github.com/google/svcca](https://github.com/google/svcca).)
    This latter approach has been used to identify and understand many representational
    properties in natural language applications [[118](#bib.bib118), [16](#bib.bib16),
    [235](#bib.bib235)] and even in modelling the mouse visual cortex as an artificial
    neural network [[208](#bib.bib208)]. Another recent technique uses a kernel based
    approach to perform similarity comparisons [[115](#bib.bib115)] (with code [https://colab.sandbox.google.com/github/google-research/google-research/blob/master/representation_similarity/Demo.ipynb](https://colab.sandbox.google.com/github/google-research/google-research/blob/master/representation_similarity/Demo.ipynb).)
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 Technical References
  id: totrans-295
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The preceding sections contain many useful pointers to techniques and associated
    open sourced code references. One additional reference of general interest may
    be [https://christophm.github.io/interpretable-ml-book/](https://christophm.github.io/interpretable-ml-book/)
    a fully open sourced book on interpretable machine learning. This focuses slightly
    more on more traditional interpretability methods, but has useful overlap with
    some of the techniques presented above and may suggest promising open directions.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
- en: 8 Advanced Deep Learning Methods
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The methods and tasks overviewed in the survey so far — supervised learning,
    fundamental neural network architectures (and their many different tasks), different
    paradigms like transfer learning as well as ways to reduce labelled data dependence
    such as self-supervision and semi-supervised learning — are an excellent set of
    first approaches for any problem amenable to deep learning. In most such problems,
    these approaches will also suffice in finding a good solution.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Occasionally however, it might be useful to turn to more advanced methods in
    deep learning, specifically generative models and reinforcement learning. We term
    these methods advanced as they are often more intricate to implement, and may
    require specific properties of the problem to be useful, for example an excellent
    environment model/simulator for reinforcement learning. We provide a brief overview
    of these methods below.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 Generative Models
  id: totrans-300
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: At a high level, generative modelling has two fundamental goals. Firstly, it
    seeks to model and enable sampling from high dimensional data distributions, such
    as natural images. Secondly, it looks to learn low(er) dimensional latent encodings
    of the data that capture key properties of interest.
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: To achieve the first goal, generative models take samples of the high dimensional
    distribution as input, for example, images of human faces, and learn some task
    directly on these data instances (e.g. encoding and then decoding the instance
    or learning to generate synthetic instances indistinguishable from the given data
    samples or generating values per-pixel using neighboring pixels as context). If
    generative modelling achieved perfect success at this first goal, it would make
    it possible to continuously sample ‘free’ data instances! Such perfect success
    is extremely challenging, but the past few years has seen enormous progress in
    the diversity and fidelity of samples from the data distribution.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 为了实现第一个目标，生成模型将高维分布的样本作为输入，例如人脸图像，并直接在这些数据实例上学习某些任务（例如，对实例进行编码然后解码，或学习生成与给定数据样本无法区分的合成实例，或使用邻近像素作为上下文生成每像素值）。如果生成建模在这个第一个目标上取得完美成功，它将使得能够持续采样“免费”的数据实例！这种完美的成功非常具有挑战性，但过去几年在数据分布样本的多样性和逼真性方面取得了巨大进展。
- en: For the second goal, learning latent encodings of the data with different encoding
    dimensions correspond to meaningful factors of variation, having an explicit encoder-decoder
    structure in the model can be helpful in encouraging learning such representations.
    This is the default structure for certain kinds of generative models such as variational
    autoencoders [[109](#bib.bib109)] but has also been adopted into other models,
    such as BigBiGAN [[49](#bib.bib49)], a type of generative adversarial network.
    In the following sections we overview some of these main types of generative models.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 对于第二个目标，学习具有不同编码维度的数据潜在编码，并将其与有意义的变化因素对应，在模型中具有明确的编码器-解码器结构可以有助于促进这种表示的学习。这是某些类型生成模型的默认结构，如变分自编码器[[109](#bib.bib109)]，但也已被应用于其他模型，如BigBiGAN[[49](#bib.bib49)]，一种生成对抗网络。以下部分我们将概述一些主要的生成模型类型。
- en: 8.1.1 Generative Adversarial Networks
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.1 生成对抗网络
- en: '![Refer to caption](img/efffc23125f0e23bdebc28a4609736bc.png)'
  id: totrans-305
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/efffc23125f0e23bdebc28a4609736bc.png)'
- en: 'Figure 14: Human faces generated from scratch by StyleGAN2\. Image source [[100](#bib.bib100)]
    The figure shows multiple human face samples from StyleGAN2 [[100](#bib.bib100)].
    While perfectly modelling and capture full diversity of complex data distributions
    like human faces remains challenging, the quality and fidelity of samples from
    recent generative models is very high.'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：由StyleGAN2从零开始生成的人脸。图像来源[[100](#bib.bib100)] 图中展示了多个由StyleGAN2[[100](#bib.bib100)]生成的人脸样本。虽然完全建模并捕捉复杂数据分布如人脸的全面多样性仍然具有挑战性，但最近生成模型的样本质量和逼真性非常高。
- en: 'Arguably the most well known of all different types of generative models, Generative
    Adversarial Networks, commonly known as GANs, consist of two neural networks,
    a generator and a discriminator, which are pitted in a game against each other.
    The generator takes as input a random noise vector and tries to output samples
    that look like the data distribution (e.g. synthesize images of peoples faces),
    while the discriminator tries to distinguish between true samples of the data,
    and those synthesized by the generator. First proposed in [[68](#bib.bib68)],
    GANs have been an exceptionally popular research area, with the most recent variations,
    such as BigGAN [[22](#bib.bib22)] (code: [https://github.com/ajbrock/BigGAN-PyTorch](https://github.com/ajbrock/BigGAN-PyTorch)),
    BigBiGAN [[49](#bib.bib49)] and StyleGAN(2) [[100](#bib.bib100)] (code: [https://github.com/NVlabs/stylegan2](https://github.com/NVlabs/stylegan2))
    able to generate incredibly realistic images.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 可以说，所有不同类型的生成模型中最著名的就是生成对抗网络，通常称为GAN。GAN由两个神经网络组成，一个生成器和一个判别器，它们彼此对抗。生成器将随机噪声向量作为输入，并尝试输出看起来像数据分布的样本（例如，合成面部图像），而判别器则尝试区分数据的真实样本和生成器合成的样本。GAN首次提出于[[68](#bib.bib68)]，在研究领域中非常受欢迎，最近的变体如BigGAN[[22](#bib.bib22)]（代码：[https://github.com/ajbrock/BigGAN-PyTorch](https://github.com/ajbrock/BigGAN-PyTorch)），BigBiGAN[[49](#bib.bib49)]和StyleGAN(2)
    [[100](#bib.bib100)]（代码：[https://github.com/NVlabs/stylegan2](https://github.com/NVlabs/stylegan2)）能够生成极其逼真的图像。
- en: Unconditional GANs vs Conditional GANs
  id: totrans-308
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 无条件GAN与条件GAN
- en: 'The examples given above are all unconditional GANs, where the data is generated
    with only a random noise vector as input. A popular and highly useful variant
    are conditional GANs, where generation is conditioned on additional information,
    such as a label, or a ‘source’ image, which might be translated to a different
    style. Examples include pix2pix [[96](#bib.bib96)] (code: [https://phillipi.github.io/pix2pix/](https://phillipi.github.io/pix2pix/)),
    cycleGAN [[274](#bib.bib274)], and applications of these to videos [[27](#bib.bib27)].'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '上述示例都是无条件 GAN，其中数据是以随机噪声向量作为输入生成的。一个流行且非常有用的变体是条件 GAN，其中生成是基于额外的信息，比如标签或“源”图像，这些图像可能会被转换为不同的风格。示例包括
    pix2pix [[96](#bib.bib96)]（代码: [https://phillipi.github.io/pix2pix/](https://phillipi.github.io/pix2pix/)）、cycleGAN
    [[274](#bib.bib274)]，以及这些应用于视频的情况 [[27](#bib.bib27)]。'
- en: GANs have found many scientific applications, from performing data augmentation
    in medical image settings [[65](#bib.bib65)] to protein generation [[193](#bib.bib193)].
    The ‘adversarial’ loss objective of GANs can make them somewhat tricky to train,
    and useful implementation advice is given in [https://www.fast.ai/2019/05/03/decrappify/](https://www.fast.ai/2019/05/03/decrappify/),
    and (for conditional GANs) is included in [https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify).
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: GAN 在许多科学应用中找到了用武之地，从在医学图像设置中执行数据增强 [[65](#bib.bib65)] 到蛋白质生成 [[193](#bib.bib193)]。GAN
    的“对抗性”损失目标可能使其训练变得有些棘手，有用的实现建议见于 [https://www.fast.ai/2019/05/03/decrappify/](https://www.fast.ai/2019/05/03/decrappify/)，而（针对条件
    GAN 的）建议则包含在 [https://github.com/jantic/DeOldify](https://github.com/jantic/DeOldify)
    中。
- en: 8.1.2 Variational Autoencoders
  id: totrans-311
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.2 变分自编码器
- en: Another type of generative model is given by the variational autoencoder, first
    proposed by [[109](#bib.bib109)]. VAEs have an encoder decoder structure, and
    thus an explicit latent encoding, which can capture useful properties of the data
    distribution. They also enable estimation of the likelihood of a sampled datapoint
    — the probability of its occurrence in the data distribution. VAEs have also been
    extremely popular, with many variations and extensions proposed [[216](#bib.bib216),
    [99](#bib.bib99), [107](#bib.bib107), [71](#bib.bib71)]. Because of the explicit
    latent encoding and the ability to estimate likelihoods, they have also found
    use cases in various scientific settings, such as for modelling gene expression
    in single-cell RNA sequencing [[138](#bib.bib138)].
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种生成模型是变分自编码器，这一模型首次由 [[109](#bib.bib109)] 提出。变分自编码器具有编码器-解码器结构，从而具有显式的潜在编码，可以捕捉数据分布的有用特性。它们还能够估计样本数据点的可能性——即其在数据分布中出现的概率。变分自编码器也非常受欢迎，提出了许多变体和扩展
    [[216](#bib.bib216), [99](#bib.bib99), [107](#bib.bib107), [71](#bib.bib71)]。由于显式的潜在编码和估计可能性的能力，它们还在各种科学环境中找到了应用，例如用于建模单细胞
    RNA 测序中的基因表达 [[138](#bib.bib138)]。
- en: 8.1.3 Autoregressive Models
  id: totrans-313
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.3 自回归模型
- en: 'Yet another type of generative model is autoregressive models, which take in
    inputs sequentially and use those to generate an appropriate output. For instance,
    such models may take in a sequence of pixel values (some of them generated at
    a previous timestep) and use these to generate a new pixel value for a specific
    spatial location. Autoregressive models such as PixelRNN [[168](#bib.bib168)],
    PixelCNN (and variants) [[232](#bib.bib232), [200](#bib.bib200)] and the recently
    proposed VQ-VAE(2) [[189](#bib.bib189)] (code: [https://github.com/rosinality/vq-vae-2-pytorch](https://github.com/rosinality/vq-vae-2-pytorch))
    offer very high generation quality.'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '另一种生成模型是自回归模型，这些模型顺序地接收输入，并利用这些输入生成适当的输出。例如，这些模型可能接收一系列像素值（其中一些是在先前时间步生成的），并利用这些生成特定空间位置的新像素值。像
    PixelRNN [[168](#bib.bib168)]、PixelCNN（及其变体）[[232](#bib.bib232), [200](#bib.bib200)]
    和最近提出的 VQ-VAE(2) [[189](#bib.bib189)]（代码: [https://github.com/rosinality/vq-vae-2-pytorch](https://github.com/rosinality/vq-vae-2-pytorch)）提供了非常高的生成质量。'
- en: 8.1.4 Flow Models
  id: totrans-315
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.1.4 流模型
- en: A relatively new class of generative models, flow models, looks at performing
    generation using a sequence of invertible transformations, which enables the computation
    of exact likelihoods. First proposed in [[46](#bib.bib46), [47](#bib.bib47)],
    performing an expressive but tractable sequence of invertible transformations
    is an active area of research [[108](#bib.bib108), [86](#bib.bib86)]. A nice introduction
    to normalizing flows is given in this short video tutorial [https://www.youtube.com/watch?v=i7LjDvsLWCg&feature=youtu.be](https://www.youtube.com/watch?v=i7LjDvsLWCg&feature=youtu.be).
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Reinforcement Learning
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Reinforcement learning has quite a different framing to the techniques and methods
    introduced so far, aiming to solve the sequential decision making problem. It
    is typically introduced with the notions of an environment and an agent. The agent
    can take a sequence of actions in the environment, each of which affect the environment
    state in some way, and also result in possible rewards (feedback) — ‘positive’
    for good sequences of actions resulting in a ‘good’ state and ‘negative’ for bad
    sequences of actions leading to a ‘bad’ state. For example, in a game like chess,
    the state is the current position of all pieces in play (the game state), an action
    the moving of a piece, with a good sequence of actions resulting in a win, a bad
    sequence of actions in a loss and the reward might be one or zero depending on
    having a win or loss respectively.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: With this being the setup, the goal of reinforcement learning is to learn, through
    interaction with the environment, good sequences of actions (typically referred
    to as a policy). Unlike supervised learning, feedback (the reward) is typically
    given only after performing the entire sequence of actions. Specifically, feedback
    is sparse and time delayed. There are a variety of different reinforcement learning
    use cases depending on the specifics of the problem.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.1 RL with an Environment Model/Simulator
  id: totrans-320
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Some of the most striking results with RL, such as AlphaGoZero [[212](#bib.bib212)],
    critically use an environment model/simulator. In such a setting, a variety of
    learning algorithms [[242](#bib.bib242), [203](#bib.bib203), [128](#bib.bib128)]
    (some code: [https://github.com/openai/baselines](https://github.com/openai/baselines))
    can help the agent learn a good sequence of actions, often through simultaneously
    learning a value function — a function that determines whether a particular environment
    state is beneficial or not. Because the benefit of an environment state may depend
    on the entire sequence of actions (some still in the future), RL is very important
    in properly assessing the value of the environment state, through implicitly accounting
    for possible future actions. Combining value functions with traditional search
    algorithms has been a very powerful way to use RL, and may be broadly applicable
    to many domains.'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, if developing a solution to the problem is multistep in nature,
    with even a noisy validation possible in simulation, using RL to learn a good
    value function and combining that with search algorithms may lead to discovering
    new and more effective parts of the search space. Approaches like these have gained
    traction in considering RL applications to fundamental problems in both computer
    systems, with [[144](#bib.bib144)] providing a survey and a new benchmark, and
    machine learning systems [[174](#bib.bib174)], in designing task-specific neural
    network models. The latter has recently also resulted in scientific use cases
    — designing neural networks to emulate complex processes across astronomy, chemistry,
    physics, climate modelling and others [[101](#bib.bib101)].
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，如果解决问题的过程是多步骤的，即使在模拟中可能有噪声验证，使用强化学习来学习一个好的价值函数，并将其与搜索算法结合，可能会发现搜索空间中的新且更有效的部分。像这样的研究在考虑强化学习应用于计算机系统的基本问题时已获得关注，其中[[144](#bib.bib144)]提供了调查和新的基准，而在设计任务特定的神经网络模型方面也获得了进展[[174](#bib.bib174)]。后者最近也导致了科学用例——设计神经网络以模拟跨越天文学、化学、物理、气候建模等复杂过程[[101](#bib.bib101)]。
- en: 8.2.2 RL without Simulators
  id: totrans-323
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 8.2.2 无需模拟器的强化学习
- en: In other settings, we don’t have access to an environment model/simulator, and
    may simply have records of sequences of actions (and the ensuing states and rewards).
    This is the offline setting. In this case, we may still try to teach an agent
    a good policy, using the observed sequences of actions/states/rewards in conjunction
    with off-policy methods [[209](#bib.bib209), [182](#bib.bib182), [134](#bib.bib134)],
    but thorough validation and evaluation can be challenging. Evaluation in off-policy
    settings often uses a statistical technique known as off-policy policy evaluation
    (example algorithms include [[178](#bib.bib178), [133](#bib.bib133)]). In robotics,
    reinforcement learning literature has looked at performing transfer learning between
    policies learned in simulation and policies learned on real data [[198](#bib.bib198)].
    A thorough overview of deep reinforcement learning is given in [http://rail.eecs.berkeley.edu/deeprlcourse/](http://rail.eecs.berkeley.edu/deeprlcourse/).
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 在其他环境中，我们没有访问环境模型/模拟器的权限，可能仅有一系列动作记录（以及随之而来的状态和奖励）。这就是离线环境。在这种情况下，我们仍然可以尝试使用观察到的动作/状态/奖励序列结合离线策略方法[[209](#bib.bib209),
    [182](#bib.bib182), [134](#bib.bib134)]来教导智能体一个好的策略，但彻底的验证和评估可能会很具挑战性。在离线策略环境中，评估通常使用一种称为离线策略评估的统计技术（例如算法包括[[178](#bib.bib178),
    [133](#bib.bib133)]）。在机器人学中，强化学习文献研究了在模拟中学习的策略与在真实数据中学习的策略之间的迁移学习[[198](#bib.bib198)]。深度强化学习的全面概述可以参考[http://rail.eecs.berkeley.edu/deeprlcourse/](http://rail.eecs.berkeley.edu/deeprlcourse/)。
- en: 9 Implementation Tips
  id: totrans-325
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 实施提示
- en: In this section, we highlight some useful tips for implementing these models.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，我们强调了一些实现这些模型的有用提示。
- en: Explore Your Data
  id: totrans-327
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 探索你的数据
- en: Before starting with steps in the learning phase (see Figure [1](#S2.F1 "Figure
    1 ‣ 2.2 Deep Learning Workflow ‣ 2 High Level Considerations for Deep Learning
    ‣ A Survey of Deep Learning for Scientific Discovery")), make sure to perform
    a thorough exploration of your data. What are the results of simple dimensionality
    reduction methods or clustering? Are the labels reliable? Is there imbalance amongst
    different classes? Are different subpopulations appropriately represented?
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 在开始学习阶段的步骤之前（见图[1](#S2.F1 "Figure 1 ‣ 2.2 Deep Learning Workflow ‣ 2 High Level
    Considerations for Deep Learning ‣ A Survey of Deep Learning for Scientific Discovery")），务必对你的数据进行彻底探索。简单的降维方法或聚类结果如何？标签是否可靠？不同类别之间是否存在不平衡？不同的子群体是否得到适当表示？
- en: Try Simple Methods
  id: totrans-329
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 尝试简单的方法
- en: When starting off with a completely new problem, it is useful to try the simplest
    version possible. (It might even be worthwhile starting with no learning at all
    — how does the naive majority baseline perform? For datasets with large imbalances,
    it may be quite strong!) If the dataset is very large, is there some smaller subsampled/downscaled
    version that can be used for faster preliminary testing? What is the simplest
    model that might work well? How does a majority baseline perform? (This ties in
    settings where the data has class imbalance.) Does the model (as expected) overfit
    to very small subsets of the data?
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
- en: Where possible, start with well tested models/tasks/methods
  id: totrans-331
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: With the plethora of standard models (many of them pretrained), data augmentation,
    and optimization methods readily available (Section [3](#S3 "3 Deep Learning Libraries
    and Resources ‣ A Survey of Deep Learning for Scientific Discovery")), most new
    problems will be amenable to some standard set of these choices. Start with this!
    Debugging the dataset and objective function associated with a new problem at
    the same time as debugging the neural network model, task choice, optimization
    algorithm, etc is very challenging.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, many of the standard model/task/method choices are very well benchmarked,
    and exploring performance in these settings is an excellent first step in understanding
    the inherent challenges of the new problem. Wherever possible, the easiest way
    to get starting with the learning phase is to clone an appropriate github repository
    that has the models and training code needed, and make the minimal edits needed
    to work with the new dataset and objective function.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: First Steps in Debugging Poor Performance
  id: totrans-334
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Having put together an end-to-end system, you observe that it is not performing
    well on the validation data. What is the reason? Before getting into more subtle
    design questions on hyperparameter choice (below), some first things to look at
    might be (i) Is the model overfitting? If so, more regularization, data augmentation,
    early stopping, smaller model may help. (ii) Is there a distribution shift between
    the training and validation data? (iii) Is the model underfitting? If so, check
    the optimization process by seeing if the model overfits when trained on a smaller
    subset of the training data. Test out a simpler task. Check for noise in the labels
    or data instances and for distribution shift. (iv) Look at the instances on which
    the model makes errors. Is there some pattern? For imbalanced datasets, loss function
    reweighting or more augmentation on the rarer classes can help. (v) How stable
    is the model performance across multiple random reruns? (vi) What are gradient
    and intermediate representation norms through the training process?
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: Which hyperparameters matter most?
  id: totrans-336
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: A big challenge in improving deep learning performance is the multitude of hyperparameters
    it is possible to change. In practice, some of the simplest hyperparameters often
    affect performance the most, such as learning rate and learning rate schedule.
    Picking an optimizer with subtleties such as weight decay correctly implemented
    can also be very important, see this excellent article on a very popular optimizer,
    AdamW [https://www.fast.ai/2018/07/02/adam-weight-decay/](https://www.fast.ai/2018/07/02/adam-weight-decay/).
    It might also be very useful to visualize the contributions to total loss from
    the main objective function vs different regularizers such as weight decay.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: 'Other hyperparameters that can be explored include batch size and data preprocessing,
    though if standard setups are used for these, varying learning rate related hyperparameters
    is likely to be the first most useful aspect to explore. To test different hyperparameter
    settings, it can be very useful to cross-validate: hold out a portion of the training
    data, train different hyperparameter settings on the remaining data, pick whichever
    hyperparameter setting does best when evaluated on the held out data, and then
    finally retrain that hyperparameter setting on the full training dataset.'
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
- en: Validate your model thoroughly!
  id: totrans-339
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deep learning models are notorious for relying on spurious correlations in the
    data to perform their predictions [[8](#bib.bib8), [162](#bib.bib162), [247](#bib.bib247)].
    By spurious correlation, we mean features in the data instances that happen to
    co-occur with a specific label, but will not result in a robust, generalizable
    model. For example, suppose we have data from different chest x-ray machines (corresponding
    to different hospitals) that we put together to train a deep learning model. It
    might be the case that one of these machines, so happens to scan many sick patients.
    The deep learning model might then implicitly learn about the chest x-ray machine
    instead of the features of the illness. One of the best tests for ensuring the
    model is learning in a generalizable way is to evaluate the model on data collected
    separately from the training data, which will introduce some natural distribution
    shift and provide a more robust estimate of its accuracy. Some recent interesting
    papers exploring these questions include [[81](#bib.bib81), [190](#bib.bib190)].
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: Relatedly, deep neural networks will also pick up on any biases in the data,
    for example, learning to pay attention to gender (a sensitive attribute) when
    made to predict age due to class imbalances leading to spurious correlations.
    This can pose significant challenges for generalizable conclusions in scientific
    settings where data may be collected from one population, but the predictions
    must be accurate across all populations. It is therefore important to perform
    postprocessing analysis on the model representations to identify the presence
    of such biases. A line of active research studies how to debias these representations
    [[4](#bib.bib4), [241](#bib.bib241)].
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
- en: Implementation References
  id: totrans-342
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Some of the general design considerations when coming to implementation (along
    with factors affecting larger scale deployment, not explored in this survey) are
    discussed in this overview [https://github.com/chiphuyen/machine-learning-systems-design/blob/master/build/build1/consolidated.pdf](https://github.com/chiphuyen/machine-learning-systems-design/blob/master/build/build1/consolidated.pdf).
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: For specific points on training and debugging deep learning systems, two excellent
    guides are given by [http://josh-tobin.com/assets/pdf/troubleshooting-deep-neural-networks-01-19.pdf](http://josh-tobin.com/assets/pdf/troubleshooting-deep-neural-networks-01-19.pdf)
    and [http://karpathy.github.io/2019/04/25/recipe/](http://karpathy.github.io/2019/04/25/recipe/).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: 10 Conclusion
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: As the amount of data collected across many diverse scientific domains continues
    to increase in both sheer amount and complexity, deep learning methods offer many
    exciting possibilities for both fundamental predictive problems as well as revealing
    subtle properties of the underlying data generation process. In this survey, we
    overviewed many of the highly successful deep learning models, tasks and methodologies,
    with references to the remarkably comprehensive open-sourced resources developed
    by the community. We hope that both the overviews and the references serve to
    accelerate applications of deep learning to many varied scientific problems!
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The authors would like to thank Jon Kleinberg, Samy Bengio, Yann LeCun, Chiyuan
    Zhang, Quoc Le, Arun Chaganty, Simon Kornblith, Aniruddh Raghu, John Platt, Richard
    Murray, Stu Feldman and Guy Gur-Ari for feedback and comments on earlier versions.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-349
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Waleed Abdulla. Splash of Color: Instance Segmentation with Mask R-CNN
    and TensorFlow, 2018. [https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46](https://engineering.matterport.com/splash-of-color-instance-segmentation-with-mask-r-cnn-and-tensorflow-7c761e238b46).'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Roee Aharoni, Melvin Johnson, and Orhan Firat. Massively multilingual neural
    machine translation. arXiv preprint arXiv:1903.00089, 2019.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Jay Alammar. The Illustrated Transformer, 2018. [http://jalammar.github.io/illustrated-transformer/](http://jalammar.github.io/illustrated-transformer/).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Mohsan Alvi, Andrew Zisserman, and Christoffer Nellåker. Turning a blind
    eye: Explicit removal of biases and variation from deep neural network embeddings.
    In Proceedings of the European Conference on Computer Vision (ECCV), pages 0–0,
    2018.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Marios Anthimopoulos, Stergios Christodoulidis, Lukas Ebner, Andreas Christe,
    and Stavroula Mougiakakou. Lung pattern classification for interstitial lung diseases
    using a deep convolutional neural network. IEEE transactions on medical imaging,
    35(5):1207–1216, 2016.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen,
    Klaus-Robert Müller, and Wojciech Samek. On pixel-wise explanations for non-linear
    classifier decisions by layer-wise relevance propagation. PloS one, 10(7):e0130140,
    2015.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Philip Bachman, R Devon Hjelm, and William Buchwalter. Learning representations
    by maximizing mutual information across views. arXiv preprint arXiv:1906.00910,
    2019.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Marcus A Badgeley, John R Zech, Luke Oakden-Rayner, Benjamin S Glicksberg,
    Manway Liu, William Gale, Michael V McConnell, Bethany Percha, Thomas M Snyder,
    and Joel T Dudley. Deep learning predicts hip fracture using confounding patient
    and healthcare variables. npj Digital Medicine, 2(1):31, 2019.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. Segnet: A deep
    convolutional encoder-decoder architecture for image segmentation. IEEE transactions
    on pattern analysis and machine intelligence, 39(12):2481–2495, 2017.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation
    by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Dzmitry Bahdanau, Jan Chorowski, Dmitriy Serdyuk, Philemon Brakel, and
    Yoshua Bengio. End-to-end attention-based large vocabulary speech recognition.
    In 2016 IEEE international conference on acoustics, speech and signal processing
    (ICASSP), pages 4945–4949\. IEEE, 2016.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Guha Balakrishnan, Amy Zhao, Mert R Sabuncu, John Guttag, and Adrian V
    Dalca. An unsupervised learning model for deformable medical image registration.
    In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 9252–9260, 2018.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Guha Balakrishnan, Amy Zhao, Mert R Sabuncu, John Guttag, and Adrian V
    Dalca. Voxelmorph: a learning framework for deformable medical image registration.
    IEEE transactions on medical imaging, 2019.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Joshua Batson and Loic Royer. Noise2self: Blind denoising by self-supervision.
    arXiv preprint arXiv:1901.11365, 2019.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende,
    et al. Interaction networks for learning about objects, relations and physics.
    In Advances in neural information processing systems, pages 4502–4510, 2016.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Anthony Bau, Yonatan Belinkov, Hassan Sajjad, Nadir Durrani, Fahim Dalvi,
    and James Glass. Identifying and controlling important neurons in neural machine
    translation. arXiv preprint arXiv:1811.01157, 2018.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba.
    Network dissection: Quantifying interpretability of deep visual representations.
    In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pages 6541–6549, 2017.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Iz Beltagy, Arman Cohan, and Kyle Lo. Scibert: Pretrained contextualized
    embeddings for scientific text. arXiv preprint arXiv:1903.10676, 2019.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] David Berthelot, Nicholas Carlini, Ian Goodfellow, Nicolas Papernot, Avital
    Oliver, and Colin Raffel. Mixmatch: A holistic approach to semi-supervised learning.
    arXiv preprint arXiv:1905.02249, 2019.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Mariusz Bojarski, Anna Choromanska, Krzysztof Choromanski, Bernhard Firner,
    Larry Jackel, Urs Muller, and Karol Zieba. Visualbackprop: visualizing cnns for
    autonomous driving. arXiv preprint arXiv:1611.05418, 2, 2016.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Xavier Bresson and Thomas Laurent. A two-step graph convolutional decoder
    for molecule generation. arXiv preprint arXiv:1906.03412, 2019.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training
    for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Renzhi Cao, Colton Freitas, Leong Chan, Miao Sun, Haiqing Jiang, and Zhangxin
    Chen. Prolango: protein function prediction using neural machine translation based
    on a recurrent neural network. Molecules, 22(10):1732, 2017.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei, and Yaser Sheikh. OpenPose:
    realtime multi-person 2D pose estimation using Part Affinity Fields. In arXiv
    preprint arXiv:1812.08008, 2018.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Brandon Carter, Jonas Mueller, Siddhartha Jain, and David Gifford. What
    made you do this? understanding black-box decisions with sufficient input subsets.
    arXiv preprint arXiv:1810.03805, 2018.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Shan Carter, Zan Armstrong, Ludwig Schubert, Ian Johnson, and Chris Olah.
    Activation atlas. Distill, 2019. https://distill.pub/2019/activation-atlas.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei A Efros. Everybody
    dance now. In Proceedings of the IEEE International Conference on Computer Vision,
    pages 5933–5942, 2019.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Danqi Chen and Christopher Manning. A fast and accurate dependency parser
    using neural networks. In Proceedings of the 2014 conference on empirical methods
    in natural language processing (EMNLP), pages 740–750, 2014.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Ting Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A simple
    framework for contrastive learning of visual representations. arXiv preprint arXiv:2002.05709,
    2020.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Ting Chen, Yizhou Sun, Yue Shi, and Liangjie Hong. On sampling strategies
    for neural network-based collaborative filtering. In Proceedings of the 23rd ACM
    SIGKDD International Conference on Knowledge Discovery and Data Mining, pages
    767–776, 2017.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Yuhua Chen, Yibin Xie, Zhengwei Zhou, Feng Shi, Anthony G Christodoulou,
    and Debiao Li. Brain mri super resolution using 3d deep densely connected neural
    networks. In 2018 IEEE 15th International Symposium on Biomedical Imaging (ISBI
    2018), pages 739–742\. IEEE, 2018.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Jan K Chorowski, Dzmitry Bahdanau, Dmitriy Serdyuk, Kyunghyun Cho, and
    Yoshua Bengio. Attention-based models for speech recognition. In Advances in neural
    information processing systems, pages 577–585, 2015.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Özgün Çiçek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, and Olaf
    Ronneberger. 3d u-net: learning dense volumetric segmentation from sparse annotation.
    In International conference on medical image computing and computer-assisted intervention,
    pages 424–432\. Springer, 2016.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] Kevin Clark, Minh-Thang Luong, Christopher D Manning, and Quoc V Le. Semi-supervised
    sequence modeling with cross-view training. arXiv preprint arXiv:1809.08370, 2018.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Taco Cohen and Max Welling. Group equivariant convolutional networks.
    In International conference on machine learning, pages 2990–2999, 2016.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Taco S Cohen, Mario Geiger, Jonas Köhler, and Max Welling. Spherical cnns.
    arXiv preprint arXiv:1801.10130, 2018.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Peter Corbett and John Boyle. Improving the learning of chemical-protein
    interactions from literature using transfer learning and specialized word embeddings.
    Database, 2018, 2018.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Ekin D Cubuk, Barret Zoph, Jonathon Shlens, and Quoc V Le. Randaugment:
    Practical data augmentation with no separate search. arXiv preprint arXiv:1909.13719,
    2019.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Adrian Dalca, Marianne Rakic, John Guttag, and Mert Sabuncu. Learning
    conditional deformable templates with convolutional networks. In Advances in neural
    information processing systems, pages 804–816, 2019.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Yann Dauphin. mixup: Beyond Empirical Risk Minimization Image, 2017. [https://www.dauphin.io/](https://www.dauphin.io/).'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Nicola De Cao and Thomas Kipf. Molgan: An implicit generative model for
    small molecular graphs. arXiv preprint arXiv:1805.11973, 2018.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
    Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on
    computer vision and pattern recognition, pages 248–255\. Ieee, 2009.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert:
    Pre-training of deep bidirectional transformers for language understanding. arXiv
    preprint arXiv:1810.04805, 2018.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Terrance DeVries and Graham W Taylor. Improved regularization of convolutional
    neural networks with cutout. arXiv preprint arXiv:1708.04552, 2017.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Yiming Ding, Jae Ho Sohn, Michael G Kawczynski, Hari Trivedi, Roy Harnish,
    Nathaniel W Jenkins, Dmytro Lituiev, Timothy P Copeland, Mariam S Aboian, Carina
    Mari Aparici, et al. A deep learning model to predict a diagnosis of alzheimer
    disease by using 18f-fdg pet of the brain. Radiology, 290(2):456–464, 2018.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Laurent Dinh, David Krueger, and Yoshua Bengio. Nice: Non-linear independent
    components estimation. arXiv preprint arXiv:1410.8516, 2014.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio. Density estimation
    using real nvp. arXiv preprint arXiv:1605.08803, 2016.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Carl Doersch, Abhinav Gupta, and Alexei A Efros. Unsupervised visual representation
    learning by context prediction. In Proceedings of the IEEE International Conference
    on Computer Vision, pages 1422–1430, 2015.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Jeff Donahue and Karen Simonyan. Large scale adversarial representation
    learning. In Advances in Neural Information Processing Systems, pages 10541–10551,
    2019.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Image super-resolution
    using deep convolutional networks. IEEE transactions on pattern analysis and machine
    intelligence, 38(2):295–307, 2015.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] Alexey Dosovitskiy, Jost Tobias Springenberg, Martin Riedmiller, and Thomas
    Brox. Discriminative unsupervised feature learning with convolutional neural networks.
    In Advances in neural information processing systems, pages 766–774, 2014.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Yong Du, Wei Wang, and Liang Wang. Hierarchical recurrent neural network
    for skeleton based action recognition. In Proceedings of the IEEE conference on
    computer vision and pattern recognition, pages 1110–1118, 2015.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell,
    Timothy Hirzel, Alán Aspuru-Guzik, and Ryan P Adams. Convolutional networks on
    graphs for learning molecular fingerprints. In Advances in neural information
    processing systems, pages 2224–2232, 2015.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Sergey Edunov, Myle Ott, Michael Auli, and David Grangier. Understanding
    back-translation at scale. arXiv preprint arXiv:1808.09381, 2018.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Andre Esteva, Brett Kuprel, Roberto A Novoa, Justin Ko, Susan M Swetter,
    Helen M Blau, and Sebastian Thrun. Dermatologist-level classification of skin
    cancer with deep neural networks. Nature, 542(7639):115, 2017.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Linjing Fang, Fred Monroe, Sammy Weiser Novak, Lyndsey Kirk, Cara R Schiavon,
    B Yu Seungyoon, Tong Zhang, Melissa Wu, Kyle Kastner, Yoshiyuki Kubota, et al.
    Deep learning-based point-scanning super-resolution imaging. bioRxiv, page 740548,
    2019.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Chelsea Finn, Ian Goodfellow, and Sergey Levine. Unsupervised learning
    for physical interaction through video prediction. In Advances in neural information
    processing systems, pages 64–72, 2016.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Marc Finzi, Samuel Stanton, Pavel Izmailov, and Andrew Gordon Wilson.
    Generalizing convolutional neural networks for equivariance to lie groups on arbitrary
    continuous data. arXiv preprint arXiv:2002.12880, 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Ruth C Fong and Andrea Vedaldi. Interpretable explanations of black boxes
    by meaningful perturbation. In Proceedings of the IEEE International Conference
    on Computer Vision, pages 3429–3437, 2017.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] Alex Fout, Jonathon Byrd, Basir Shariat, and Asa Ben-Hur. Protein interface
    prediction using graph convolutional networks. In Advances in Neural Information
    Processing Systems, pages 6530–6539, 2017.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Ferenc Galkó and Carsten Eickhoff. Biomedical question answering via weighted
    neural network passage retrieval. In European Conference on Information Retrieval,
    pages 523–528\. Springer, 2018.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Yaroslav Ganin and Victor Lempitsky. Unsupervised domain adaptation by
    backpropagation. arXiv preprint arXiv:1409.7495, 2014.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle,
    François Laviolette, Mario Marchand, and Victor Lempitsky. Domain-adversarial
    training of neural networks. The Journal of Machine Learning Research, 17(1):2096–2030,
    2016.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Image style transfer
    using convolutional neural networks. In Proceedings of the IEEE conference on
    computer vision and pattern recognition, pages 2414–2423, 2016.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] Amirata Ghorbani, Vivek Natarajan, David Coz, and Yuan Liu. Dermgan: Synthetic
    generation of clinical skin images with pathology. arXiv preprint arXiv:1911.08716,
    2019.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Spyros Gidaris, Praveer Singh, and Nikos Komodakis. Unsupervised representation
    learning by predicting image rotations. arXiv preprint arXiv:1803.07728, 2018.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and
    George E Dahl. Neural message passing for quantum chemistry. In Proceedings of
    the 34th International Conference on Machine Learning-Volume 70, pages 1263–1272\.
    JMLR. org, 2017.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.
    In Advances in neural information processing systems, pages 2672–2680, 2014.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Priya Goyal, Dhruv Mahajan, Abhinav Gupta, and Ishan Misra. Scaling and
    benchmarking self-supervised visual representation learning. arXiv preprint arXiv:1905.01235,
    2019.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton. Speech recognition
    with deep recurrent neural networks. In 2013 IEEE international conference on
    acoustics, speech and signal processing, pages 6645–6649\. IEEE, 2013.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] Aditya Grover, Aaron Zweig, and Stefano Ermon. Graphite: Iterative generative
    modeling of graphs. arXiv preprint arXiv:1803.10459, 2018.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] Varun Gulshan, Lily Peng, Marc Coram, Martin C Stumpe, Derek Wu, Arunachalam
    Narayanaswamy, Subhashini Venugopalan, Kasumi Widner, Tom Madams, Jorge Cuadros,
    et al. Development and validation of a deep learning algorithm for detection of
    diabetic retinopathy in retinal fundus photographs. Jama, 316(22):2402–2410, 2016.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Maryam Habibi, Leon Weber, Mariana Neves, David Luis Wiegandt, and Ulf
    Leser. Deep learning with word embeddings improves biomedical named entity recognition.
    Bioinformatics, 33(14):i37–i48, 2017.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang,
    and Masashi Sugiyama. Co-teaching: Robust training of deep neural networks with
    extremely noisy labels. In Advances in neural information processing systems,
    pages 8527–8537, 2018.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Ankur Handa, Michael Bloesch, Viorica Pătrăucean, Simon Stent, John McCormac,
    and Andrew Davison. gvnn: Neural network library for geometric computer vision.
    In European Conference on Computer Vision, pages 67–82. Springer, 2016.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Boris Hanin. Which neural net architectures give rise to exploding and
    vanishing gradients? In Advances in Neural Information Processing Systems, pages
    582–591, 2018.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] Jack Hanson, Yuedong Yang, Kuldip Paliwal, and Yaoqi Zhou. Improving protein
    disorder prediction by deep bidirectional long short-term memory recurrent neural
    networks. Bioinformatics, 33(5):685–692, 2016.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick. Mask r-cnn.
    In Proceedings of the IEEE international conference on computer vision, pages
    2961–2969, 2017.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning
    for image recognition. In Proceedings of the IEEE conference on computer vision
    and pattern recognition, pages 770–778, 2016.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Rhys Heffernan, Yuedong Yang, Kuldip Paliwal, and Yaoqi Zhou. Capturing
    non-local interactions by long short-term memory bidirectional recurrent neural
    networks for improving prediction of protein secondary structure, backbone angles,
    contact numbers and solvent accessibility. Bioinformatics, 33(18):2842–2849, 2017.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness
    to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Dan Hendrycks, Norman Mu, Ekin D Cubuk, Barret Zoph, Justin Gilmer, and
    Balaji Lakshminarayanan. Augmix: A simple data processing method to improve robustness
    and uncertainty. arXiv preprint arXiv:1912.02781, 2019.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt,
    Will Kay, Mustafa Suleyman, and Phil Blunsom. Teaching machines to read and comprehend.
    In Advances in neural information processing systems, pages 1693–1701, 2015.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] R Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Phil
    Bachman, Adam Trischler, and Yoshua Bengio. Learning deep representations by mutual
    information estimation and maximization. arXiv preprint arXiv:1808.06670, 2018.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] Daniel Ho, Eric Liang, Ion Stoica, Pieter Abbeel, and Xi Chen. Population
    based augmentation: Efficient learning of augmentation policy schedules. arXiv
    preprint arXiv:1905.05393, 2019.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] Jonathan Ho, Xi Chen, Aravind Srinivas, Yan Duan, and Pieter Abbeel. Flow++:
    Improving flow-based generative models with variational dequantization and architecture
    design. arXiv preprint arXiv:1902.00275, 2019.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] Sepp Hochreiter. The vanishing gradient problem during learning recurrent
    neural nets and problem solutions. International Journal of Uncertainty, Fuzziness
    and Knowledge-Based Systems, 6(02):107–116, 1998.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] Sepp Hochreiter and Jürgen Schmidhuber. Long short-term memory. Neural
    computation, 9(8):1735–1780, 1997.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S
    Weld. Knowledge-based weak supervision for information extraction of overlapping
    relations. In Proceedings of the 49th Annual Meeting of the Association for Computational
    Linguistics: Human Language Technologies-Volume 1, pages 541–550\. Association
    for Computational Linguistics, 2011.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin
    De Laroussilhe, Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. Parameter-efficient
    transfer learning for nlp. arXiv preprint arXiv:1902.00751, 2019.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Andrew G Howard. Some improvements on deep convolutional neural network
    based image classification. arXiv preprint arXiv:1312.5402, 2013.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] Jeremy Howard and Sebastian Ruder. Universal language model fine-tuning
    for text classification. arXiv preprint arXiv:1801.06146, 2018.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay
    Pande, and Jure Leskovec. Pre-training graph neural networks. arXiv preprint arXiv:1905.12265,
    2019.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger.
    Densely connected convolutional networks. In Proceedings of the IEEE conference
    on computer vision and pattern recognition, pages 4700–4708, 2017.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Minyoung Huh, Pulkit Agrawal, and Alexei A Efros. What makes imagenet
    good for transfer learning? arXiv preprint arXiv:1608.08614, 2016.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image
    translation with conditional adversarial networks. In Proceedings of the IEEE
    conference on computer vision and pattern recognition, pages 1125–1134, 2017.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] Na Ji. Adaptive optical fluorescence microscopy. Nature methods, 14(4):374,
    2017.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Robin Jia and Percy Liang. Data recombination for neural semantic parsing.
    arXiv preprint arXiv:1606.03622, 2016.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] Matthew Johnson, David K Duvenaud, Alex Wiltschko, Ryan P Adams, and Sandeep R
    Datta. Composing graphical models with neural networks for structured representations
    and fast inference. In Advances in neural information processing systems, pages
    2946–2954, 2016.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture
    for generative adversarial networks. In Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition, pages 4401–4410, 2019.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] MF Kasim, D Watson-Parris, L Deaconu, S Oliver, P Hatfield, DH Froula,
    G Gregori, M Jarvis, S Khatiwala, J Korenaga, et al. Up to two billion times acceleration
    of scientific simulations with deep neural architecture search. arXiv preprint
    arXiv:2001.08055, 2020.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Jeremy Kawahara, Sara Daneshvar, Giuseppe Argenziano, and Ghassan Hamarneh.
    Seven-point checklist and skin lesion classification using multitask multimodal
    neural nets. IEEE journal of biomedical and health informatics, 23(2):538–546,
    2018.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Steven Kearnes, Kevin McCloskey, Marc Berndl, Vijay Pande, and Patrick
    Riley. Molecular graph convolutions: moving beyond fingerprints. Journal of computer-aided
    molecular design, 30(8):595–608, 2016.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler,
    Fernanda Viegas, and Rory Sayres. Interpretability beyond feature attribution:
    Quantitative testing with concept activation vectors (tcav). arXiv preprint arXiv:1711.11279,
    2017.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] Pieter-Jan Kindermans, Sara Hooker, Julius Adebayo, Maximilian Alber,
    Kristof T Schütt, Sven Dähne, Dumitru Erhan, and Been Kim. The (un) reliability
    of saliency methods. In Explainable AI: Interpreting, Explaining and Visualizing
    Deep Learning, pages 267–280\. Springer, 2019.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] Pieter-Jan Kindermans, Kristof T Schütt, Maximilian Alber, Klaus-Robert
    Müller, Dumitru Erhan, Been Kim, and Sven Dähne. Learning how to explain neural
    networks: Patternnet and patternattribution. arXiv preprint arXiv:1705.05598,
    2017.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] D Kingma, Tim Salimans, R Josefowicz, Xi Chen, Ilya Sutskever, Max Welling,
    et al. Improving variational autoencoders with inverse autoregressive flow. 2017.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] Durk P Kingma and Prafulla Dhariwal. Glow: Generative flow with invertible
    1x1 convolutions. In Advances in Neural Information Processing Systems, pages
    10215–10224, 2018.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] Durk P Kingma, Shakir Mohamed, Danilo Jimenez Rezende, and Max Welling.
    Semi-supervised learning with deep generative models. In Advances in neural information
    processing systems, pages 3581–3589, 2014.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] Sosuke Kobayashi. Contextual augmentation: Data augmentation by words
    with paradigmatic relations. arXiv preprint arXiv:1805.06201, 2018.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] Kaname Kojima, Shu Tadaka, Fumiki Katsuoka, Gen Tamiya, Masayuki Yamamoto,
    and Kengo Kinoshita. A recurrent neural network based method for genotype imputation
    on phased genotype data. bioRxiv, page 821504, 2019.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] Alexander Kolesnikov, Xiaohua Zhai, and Lucas Beyer. Revisiting self-supervised
    visual representation learning. arXiv preprint arXiv:1901.09005, 2019.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] Patrick T Komiske, Eric M Metodiev, and Jesse Thaler. Energy flow networks:
    deep sets for particle jets. Journal of High Energy Physics, 2019(1):121, 2019.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] Shu Kong and Charless Fowlkes. Image reconstruction with predictive filter
    flow. arXiv preprint arXiv:1811.11482, 2018.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] Simon Kornblith, Mohammad Norouzi, Honglak Lee, and Geoffrey Hinton.
    Similarity of neural network representations revisited. arXiv preprint arXiv:1905.00414,
    2019.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] Simon Kornblith, Jonathon Shlens, and Quoc V Le. Do better imagenet models
    transfer better? In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pages 2661–2671, 2019.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
    with deep convolutional neural networks. In Advances in neural information processing
    systems, pages 1097–1105, 2012.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] Sneha Reddy Kudugunta, Ankur Bapna, Isaac Caswell, Naveen Arivazhagan,
    and Orhan Firat. Investigating multilingual nmt representations at scale. arXiv
    preprint arXiv:1909.02197, 2019.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning.
    arXiv preprint arXiv:1610.02242, 2016.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised
    learning method for deep neural networks. In Workshop on Challenges in Representation
    Learning, ICML, volume 3, page 2, 2013.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho
    So, and Jaewoo Kang. Biobert: pre-trained biomedical language representation model
    for biomedical text mining. arXiv preprint arXiv:1901.08746, 2019.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras,
    Miika Aittala, and Timo Aila. Noise2noise: Learning image restoration without
    clean data. arXiv preprint arXiv:1803.04189, 2018.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] Omer Levy and Yoav Goldberg. Neural word embedding as implicit matrix
    factorization. In Advances in neural information processing systems, pages 2177–2185,
    2014.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] Chaolong Li, Zhen Cui, Wenming Zheng, Chunyan Xu, and Jian Yang. Spatio-temporal
    graph convolution for skeleton based action recognition. In Thirty-Second AAAI
    Conference on Artificial Intelligence, 2018.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Hailiang Li, Jian Weng, Yujian Shi, Wanrong Gu, Yijun Mao, Yonghua Wang,
    Weiwei Liu, and Jiajie Zhang. An improved deep learning approach for detection
    of thyroid papillary cancer in ultrasound images. Scientific reports, 8(1):6600,
    2018.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] Yixuan Li, Jason Yosinski, Jeff Clune, Hod Lipson, and John E Hopcroft.
    Convergent learning: Do different neural networks learn the same representations?
    In Iclr, 2016.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] Yujia Li, Daniel Tarlow, Marc Brockschmidt, and Richard Zemel. Gated
    graph sequence neural networks. arXiv preprint arXiv:1511.05493, 2015.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] Timothy P Lillicrap, Jonathan J Hunt, Alexander Pritzel, Nicolas Heess,
    Tom Erez, Yuval Tassa, David Silver, and Daan Wierstra. Continuous control with
    deep reinforcement learning. arXiv preprint arXiv:1509.02971, 2015.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] Fang Liu, Zhaoye Zhou, Hyungseok Jang, Alexey Samsonov, Gengyan Zhao,
    and Richard Kijowski. Deep convolutional neural network and 3d deformable approach
    for tissue segmentation in musculoskeletal magnetic resonance imaging. Magnetic
    resonance in medicine, 79(4):2379–2391, 2018.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] Peter J Liu, Mohammad Saleh, Etienne Pot, Ben Goodrich, Ryan Sepassi,
    Lukasz Kaiser, and Noam Shazeer. Generating wikipedia by summarizing long sequences.
    arXiv preprint arXiv:1801.10198, 2018.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] Shengyu Liu, Buzhou Tang, Qingcai Chen, and Xiaolong Wang. Effects of
    semantic features on machine learning-based drug name recognition systems: word
    embeddings vs. manually constructed dictionaries. Information, 6(4):848–865, 2015.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] Xueliang Liu. Deep recurrent neural network for protein function prediction
    from sequence. arXiv preprint arXiv:1701.08318, 2017.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] Yao Liu, Omer Gottesman, Aniruddh Raghu, Matthieu Komorowski, Aldo A
    Faisal, Finale Doshi-Velez, and Emma Brunskill. Representation balancing mdps
    for off-policy policy evaluation. In Advances in Neural Information Processing
    Systems, pages 2644–2653, 2018.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] Yao Liu, Adith Swaminathan, Alekh Agarwal, and Emma Brunskill. Off-policy
    policy gradient with state distribution correction. arXiv preprint arXiv:1904.08473,
    2019.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] Yun Liu, Krishna Gadepalli, Mohammad Norouzi, George E Dahl, Timo Kohlberger,
    Aleksey Boyko, Subhashini Venugopalan, Aleksei Timofeev, Philip Q Nelson, Greg S
    Corrado, et al. Detecting cancer metastases on gigapixel pathology images. arXiv
    preprint arXiv:1703.02442, 2017.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional
    networks for semantic segmentation. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 3431–3440, 2015.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan. Deep transfer
    learning with joint adaptation networks. In Proceedings of the 34th International
    Conference on Machine Learning-Volume 70, pages 2208–2217\. JMLR. org, 2017.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] Romain Lopez, Jeffrey Regier, Michael Cole, Michael Jordan, and Nir Yosef.
    A deep generative model for gene expression profiles from single-cell rna sequencing.
    arXiv preprint arXiv:1709.02082, 2017.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] Donghuan Lu, Karteek Popuri, Gavin Weiguang Ding, Rakesh Balachandar,
    and Mirza Faisal Beg. Multimodal and multiscale deep neural networks for the early
    diagnosis of alzheimer’s disease using structural mr and fdg-pet images. Scientific
    reports, 8(1):5697, 2018.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] Scott M Lundberg and Su-In Lee. A unified approach to interpreting model
    predictions. In Advances in Neural Information Processing Systems, pages 4765–4774,
    2017.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] Laurens van der Maaten and Geoffrey Hinton. Visualizing data using t-sne.
    Journal of machine learning research, 9(Nov):2579–2605, 2008.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] Ali Madani, Bryan McCann, Nikhil Naik, Nitish Shirish Keskar, Namrata
    Anand, Raphael R Eguchi, Possu Huang, and Richard Socher. Progen: Language modeling
    for protein generation. bioRxiv, 2020.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] Dhruv Mahajan, Ross Girshick, Vignesh Ramanathan, Kaiming He, Manohar
    Paluri, Yixuan Li, Ashwin Bharambe, and Laurens van der Maaten. Exploring the
    limits of weakly supervised pretraining. In Proceedings of the European Conference
    on Computer Vision (ECCV), pages 181–196, 2018.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] Hongzi Mao, Parimarjan Negi, Akshay Narayan, Hanrui Wang, Jiacheng Yang,
    Haonan Wang, Ryan Marcus, Ravichandra Addanki, Mehrdad Khani, Songtao He, et al.
    Park: An open platform for learning augmented computer systems. 2019.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] Daniel L Marino, Kasun Amarasinghe, and Milos Manic. Building energy
    load forecasting using deep neural networks. In IECON 2016-42nd Annual Conference
    of the IEEE Industrial Electronics Society, pages 7046–7051\. IEEE, 2016.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] Alexander Mathis, Pranav Mamidanna, Kevin M Cury, Taiga Abe, Venkatesh N
    Murthy, Mackenzie Weygandt Mathis, and Matthias Bethge. Deeplabcut: markerless
    pose estimation of user-defined body parts with deep learning. Nature neuroscience,
    21(9):1281, 2018.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] Mackenzie Weygandt Mathis and Alexander Mathis. Deep learning tools for
    the measurement of animal behavior in neuroscience. Current Opinion in Neurobiology,
    60:1–11, 2020.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] Leland McInnes, John Healy, and James Melville. Umap: Uniform manifold
    approximation and projection for dimension reduction. arXiv preprint arXiv:1802.03426,
    2018.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] Stephen Merity, Nitish Shirish Keskar, and Richard Socher. Regularizing
    and Optimizing LSTM Language Models. arXiv preprint arXiv:1708.02182, 2017.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] Stephen Merity, Nitish Shirish Keskar, and Richard Socher. An Analysis
    of Neural Language Modeling at Multiple Scales. arXiv preprint arXiv:1803.08240,
    2018.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efficient estimation
    of word representations in vector space. arXiv preprint arXiv:1301.3781, 2013.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean.
    Distributed representations of words and phrases and their compositionality. In
    Advances in neural information processing systems, pages 3111–3119, 2013.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. Distant supervision
    for relation extraction without labeled data. In Proceedings of the Joint Conference
    of the 47th Annual Meeting of the ACL and the 4th International Joint Conference
    on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011.
    Association for Computational Linguistics, 2009.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] Ishan Misra and Laurens van der Maaten. Self-supervised learning of pretext-invariant
    representations, 2019.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, and Shin Ishii. Virtual
    adversarial training: a regularization method for supervised and semi-supervised
    learning. IEEE transactions on pattern analysis and machine intelligence, 41(8):1979–1993,
    2018.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] Pim Moeskops, Max A Viergever, Adriënne M Mendrik, Linda S de Vries,
    Manon JNL Benders, and Ivana Išgum. Automatic segmentation of mr brain images
    with a convolutional neural network. IEEE transactions on medical imaging, 35(5):1252–1261,
    2016.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] Ari Morcos, Maithra Raghu, and Samy Bengio. Insights on representational
    similarity in neural networks with canonical correlation. In Advances in Neural
    Information Processing Systems, pages 5727–5736, 2018.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] Alejandro Newell, Kaiyu Yang, and Jia Deng. Stacked hourglass networks
    for human pose estimation. In European conference on computer vision, pages 483–499.
    Springer, 2016.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] Jiquan Ngiam, Daiyi Peng, Vijay Vasudevan, Simon Kornblith, Quoc V Le,
    and Ruoming Pang. Domain adaptive transfer learning with specialist models. arXiv
    preprint arXiv:1811.07056, 2018.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] Harsha Nori, Samuel Jenkins, Paul Koch, and Rich Caruana. Interpretml:
    A unified framework for machine learning interpretability. arXiv preprint arXiv:1909.09223,
    2019.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] Mehdi Noroozi and Paolo Favaro. Unsupervised learning of visual representations
    by solving jigsaw puzzles. In European Conference on Computer Vision, pages 69–84.
    Springer, 2016.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] Luke Oakden-Rayner, Jared Dunnmon, Gustavo Carneiro, and Christopher
    Ré. Hidden stratification causes clinically meaningful failures in machine learning
    for medical imaging. arXiv preprint arXiv:1909.12475, 2019.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] Chris Olah. Understanding LSTM Networks, 2015. [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] Chris Olah, Nick Cammarata, Ludwig Schubert, Gabriel Goh, Michael Petrov,
    and Shan Carter. Zoom in: An introduction to circuits. Distill, 5(3):e00024–001,
    2020.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] Chris Olah, Alexander Mordvintsev, and Ludwig Schubert. Feature visualization.
    Distill, 2017. https://distill.pub/2017/feature-visualization.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Chris Olah, Arvind Satyanarayan, Ian Johnson, Shan Carter, Ludwig Schubert,
    Katherine Ye, and Alexander Mordvintsev. The building blocks of interpretability.
    Distill, 2018. https://distill.pub/2018/building-blocks.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] Aaron van den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol
    Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
    Wavenet: A generative model for raw audio. arXiv preprint arXiv:1609.03499, 2016.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent
    neural networks. arXiv preprint arXiv:1601.06759, 2016.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] Aaron van den Oord, Yazhe Li, and Oriol Vinyals. Representation learning
    with contrastive predictive coding. arXiv preprint arXiv:1807.03748, 2018.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] Razvan Pascanu, Tomas Mikolov, and Yoshua Bengio. Understanding the exploding
    gradient problem. CoRR, abs/1211.5063, 2, 2012.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] Deepak Pathak, Philipp Krahenbuhl, and Trevor Darrell. Constrained convolutional
    neural networks for weakly supervised segmentation. In Proceedings of the IEEE
    international conference on computer vision, pages 1796–1804, 2015.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model
    for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] Jeffrey Pennington, Richard Socher, and Christopher Manning. Glove: Global
    vectors for word representation. In Proceedings of the 2014 conference on empirical
    methods in natural language processing (EMNLP), pages 1532–1543, 2014.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] Hieu Pham, Melody Y Guan, Barret Zoph, Quoc V Le, and Jeff Dean. Efficient
    neural architecture search via parameter sharing. arXiv preprint arXiv:1802.03268,
    2018.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] Gianluca Pollastri, Darisz Przybylski, Burkhard Rost, and Pierre Baldi.
    Improving the prediction of protein secondary structure in three and eight classes
    using recurrent neural networks and profiles. Proteins: Structure, Function, and
    Bioinformatics, 47(2):228–235, 2002.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] Ryan Poplin, Avinash V Varadarajan, Katy Blumer, Yun Liu, Michael V McConnell,
    Greg S Corrado, Lily Peng, and Dale R Webster. Prediction of cardiovascular risk
    factors from retinal fundus photographs via deep learning. Nature Biomedical Engineering,
    2(3):158, 2018.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] Rory M Power and Jan Huisken. A guide to light-sheet fluorescence microscopy
    for multiscale imaging. Nature methods, 14(4):360, 2017.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] Doina Precup. Eligibility traces for off-policy policy evaluation. Computer
    Science Department Faculty Publication Series, page 80, 2000.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] Siyuan Qiao, Wei Shen, Zhishuai Zhang, Bo Wang, and Alan Yuille. Deep
    co-training for semi-supervised image recognition. In Proceedings of the European
    Conference on Computer Vision (ECCV), pages 135–152, 2018.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and
    Ilya Sutskever. Language models are unsupervised multitask learners. OpenAI Blog,
    1(8), 2019.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang,
    Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. Exploring the limits of transfer
    learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683,
    2019.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] Aniruddh Raghu, Matthieu Komorowski, Leo Anthony Celi, Peter Szolovits,
    and Marzyeh Ghassemi. Continuous state-space models for optimal sepsis treatment-a
    deep reinforcement learning approach. arXiv preprint arXiv:1705.08422, 2017.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] Maithra Raghu, Justin Gilmer, Jason Yosinski, and Jascha Sohl-Dickstein.
    Svcca: Singular vector canonical correlation analysis for deep learning dynamics
    and interpretability. In Advances in Neural Information Processing Systems, pages
    6076–6085, 2017.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] Maithra Raghu, Chiyuan Zhang, Jon Kleinberg, and Samy Bengio. Transfusion:
    Understanding transfer learning for medical imaging. In Advances in Neural Information
    Processing Systems, pages 3342–3352, 2019.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] Pranav Rajpurkar, Jeremy Irvin, Kaylie Zhu, Brandon Yang, Hershel Mehta,
    Tony Duan, Daisy Ding, Aarti Bagul, Curtis Langlotz, Katie Shpanskaya, et al.
    Chexnet: Radiologist-level pneumonia detection on chest x-rays with deep learning.
    arXiv preprint arXiv:1711.05225, 2017.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad:
    100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250,
    2016.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] Bharath Ramsundar, Steven Kearnes, Patrick Riley, Dale Webster, David
    Konerding, and Vijay Pande. Massively multitask networks for drug discovery. arXiv
    preprint arXiv:1502.02072, 2015.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] Alexander Ratner, Stephen H Bach, Henry Ehrenberg, Jason Fries, Sen Wu,
    and Christopher Ré. Snorkel: Rapid training data creation with weak supervision.
    Proceedings of the VLDB Endowment, 11(3):269–282, 2017.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] Ali Razavi, Aaron van den Oord, and Oriol Vinyals. Generating diverse
    high-fidelity images with vq-vae-2. arXiv preprint arXiv:1906.00446, 2019.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar.
    Do imagenet classifiers generalize to imagenet? arXiv preprint arXiv:1902.10811,
    2019.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] Joseph Redmon and Ali Farhadi. Yolov3: An incremental improvement. arXiv
    preprint arXiv:1804.02767, 2018.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn:
    Towards real-time object detection with region proposal networks. In Advances
    in neural information processing systems, pages 91–99, 2015.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] Donatas Repecka, Vykintas Jauniskis, Laurynas Karpus, Elzbieta Rembeza,
    Jan Zrimec, Simona Poviloniene, Irmantas Rokaitis, Audrius Laurynenas, Wissam
    Abuajwa, Otto Savolainen, et al. Expanding functional protein sequence space using
    generative adversarial networks. bioRxiv, page 789719, 2019.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] Marco Tulio Ribeiro, Sameer Singh, and Carlos Guestrin. Why should i
    trust you?: Explaining the predictions of any classifier. In Proceedings of the
    22nd ACM SIGKDD international conference on knowledge discovery and data mining,
    pages 1135–1144\. ACM, 2016.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] Alexander Rives, Siddharth Goyal, Joshua Meier, Demi Guo, Myle Ott, C Lawrence
    Zitnick, Jerry Ma, and Rob Fergus. Biological structure and function emerge from
    scaling unsupervised learning to 250 million protein sequences. bioRxiv, page
    622803, 2019.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] Olaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional
    networks for biomedical image segmentation. In International Conference on Medical
    image computing and computer-assisted intervention, pages 234–241\. Springer,
    2015.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] Alexander M Rush, Sumit Chopra, and Jason Weston. A neural attention
    model for abstractive sentence summarization. arXiv preprint arXiv:1509.00685,
    2015.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] Andrei A Rusu, Mel Vecerik, Thomas Rothörl, Nicolas Heess, Razvan Pascanu,
    and Raia Hadsell. Sim-to-real robot learning from pixels with progressive nets.
    arXiv preprint arXiv:1610.04286, 2016.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] Ruhan Sa, William Owens, Raymond Wiegand, Mark Studin, Donald Capoferri,
    Kenneth Barooha, Alexander Greaux, Robert Rattray, Adam Hutton, John Cintineo,
    et al. Intervertebral disc detection in x-ray images using faster r-cnn. In 2017
    39th Annual International Conference of the IEEE Engineering in Medicine and Biology
    Society (EMBC), pages 564–567\. IEEE, 2017.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] Tim Salimans, Andrej Karpathy, Xi Chen, and Diederik P Kingma. Pixelcnn++:
    Improving the pixelcnn with discretized logistic mixture likelihood and other
    modifications. arXiv preprint arXiv:1701.05517, 2017.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. Distilbert,
    a distilled version of bert: smaller, faster, cheaper and lighter. arXiv preprint
    arXiv:1910.01108, 2019.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] Saman Sarraf, Ghassem Tofighi, et al. Deepad: Alzheimer disease classification
    via deep convolutional neural networks using mri and fmri. BioRxiv, page 070441,
    2016.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg
    Klimov. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347,
    2017.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna
    Vedantam, Devi Parikh, and Dhruv Batra. Grad-cam: Visual explanations from deep
    networks via gradient-based localization. In Proceedings of the IEEE International
    Conference on Computer Vision, pages 618–626, 2017.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] Andrew W Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent
    Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander WR Nelson, Alex Bridgland,
    et al. Improved protein structure prediction using potentials from deep learning.
    Nature, pages 1–5, 2020.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] Rico Sennrich, Barry Haddow, and Alexandra Birch. Improving neural machine
    translation models with monolingual data. arXiv preprint arXiv:1511.06709, 2015.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] Lloyd S Shapley. A value for n-person games. Contributions to the Theory
    of Games, 2(28):307–317, 1953.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] Jianghong Shi, Eric Shea-Brown, and Michael Buice. Comparison against
    task driven artificial neural networks reveals functional properties in mouse
    visual cortex. In Advances in Neural Information Processing Systems, pages 5765–5775,
    2019.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] Susan M Shortreed, Eric Laber, Daniel J Lizotte, T Scott Stroup, Joelle
    Pineau, and Susan A Murphy. Informing sequential clinical decision-making through
    reinforcement learning: an empirical study. Machine learning, 84(1-2):109–136,
    2011.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. Learning important
    features through propagating activation differences. In Proceedings of the 34th
    International Conference on Machine Learning-Volume 70, pages 3145–3153\. JMLR.
    org, 2017.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] Rui Shu, Hung H Bui, Hirokazu Narui, and Stefano Ermon. A dirt-t approach
    to unsupervised domain adaptation. arXiv preprint arXiv:1802.08735, 2018.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou,
    Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton,
    et al. Mastering the game of go without human knowledge. nature, 550(7676):354–359,
    2017.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. Deep inside convolutional
    networks: Visualising image classification models and saliency maps. arXiv preprint
    arXiv:1312.6034, 2013.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks
    for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin
    Wattenberg. Smoothgrad: removing noise by adding noise. arXiv preprint arXiv:1706.03825,
    2017.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] Casper Kaae Sønderby, Tapani Raiko, Lars Maaløe, Søren Kaae Sønderby,
    and Ole Winther. Ladder variational autoencoders. In Advances in neural information
    processing systems, pages 3738–3746, 2016.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] Youyi Song, Ling Zhang, Siping Chen, Dong Ni, Baopu Li, Yongjing Zhou,
    Baiying Lei, and Tianfu Wang. A deep learning based framework for accurate segmentation
    of cervical cytoplasm and nuclei. In 2014 36th Annual International Conference
    of the IEEE Engineering in Medicine and Biology Society, pages 2903–2906\. IEEE,
    2014.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] Ke Sun, Bin Xiao, Dong Liu, and Jingdong Wang. Deep high-resolution representation
    learning for human pose estimation. In Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, pages 5693–5703, 2019.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] Yu Sun, Eric Tzeng, Trevor Darrell, and Alexei A Efros. Unsupervised
    domain adaptation through self-supervision. arXiv preprint arXiv:1909.11825, 2019.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. Axiomatic attribution
    for deep networks. In Proceedings of the 34th International Conference on Machine
    Learning-Volume 70, pages 3319–3328\. JMLR. org, 2017.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] I Sutskever, O Vinyals, and QV Le. Sequence to sequence learning with
    neural networks. Advances in NIPS, 2014.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] Ryo Takahashi, Takashi Matsubara, and Kuniaki Uehara. Data augmentation
    using random image cropping and patching for deep cnns. IEEE Transactions on Circuits
    and Systems for Video Technology, 2019.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] Mingxing Tan and Quoc V Le. Efficientnet: Rethinking model scaling for
    convolutional neural networks. arXiv preprint arXiv:1905.11946, 2019.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] Mingxing Tan, Ruoming Pang, and Quoc V Le. Efficientdet: Scalable and
    efficient object detection. arXiv preprint arXiv:1911.09070, 2019.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] Antti Tarvainen and Harri Valpola. Mean teachers are better role models:
    Weight-averaged consistency targets improve semi-supervised deep learning results.
    In Advances in neural information processing systems, pages 1195–1204, 2017.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] Dimitry Tegunov and Patrick Cramer. Real-time cryo-em data pre-processing
    with warp. BioRxiv, page 338558, 2018.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] Yee Liang Thian, Yiting Li, Pooja Jagmohan, David Sia, Vincent Ern Yao
    Chan, and Robby T Tan. Convolutional neural networks for automated fracture detection
    and localization on wrist radiographs. Radiology: Artificial Intelligence, 1(1):e180001,
    2019.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] Eric J Topol. High-performance medicine: the convergence of human and
    artificial intelligence. Nature medicine, 25(1):44–56, 2019.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] Raphael Townshend, Rishi Bedi, Patricia Suriana, and Ron Dror. End-to-end
    learning on 3d protein structure for interface prediction. In Advances in Neural
    Information Processing Systems, pages 15616–15625, 2019.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] Vahe Tshitoyan, John Dagdelen, Leigh Weston, Alexander Dunn, Ziqin Rong,
    Olga Kononova, Kristin A Persson, Gerbrand Ceder, and Anubhav Jain. Unsupervised
    word embeddings capture latent knowledge from materials science literature. Nature,
    571(7763):95–98, 2019.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] Kensuke Umehara, Junko Ota, and Takayuki Ishida. Application of super-resolution
    convolutional neural network for enhancing image resolution in chest ct. Journal
    of digital imaging, 31(4):441–450, 2018.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] Aaron Van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals,
    Alex Graves, et al. Conditional image generation with pixelcnn decoders. In Advances
    in neural information processing systems, pages 4790–4798, 2016.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. Attention is all you need.
    In Advances in neural information processing systems, pages 5998–6008, 2017.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] Oriol Vinyals and Quoc Le. A neural conversational model. arXiv preprint
    arXiv:1506.05869, 2015.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] Elena Voita, Rico Sennrich, and Ivan Titov. The bottom-up evolution of
    representations in the transformer: A study with machine translation and language
    modeling objectives. arXiv preprint arXiv:1909.01380, 2019.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] Christian Wachinger, Martin Reuter, and Tassilo Klein. Deepnat: Deep
    convolutional neural network for segmenting neuroanatomy. NeuroImage, 170:434–445,
    2018.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] Kun Wang, Bite Yang, Guohai Xu, and Xiaofeng He. Medical question retrieval
    based on siamese neural network and transfer learning method. In International
    Conference on Database Systems for Advanced Applications, pages 49–64\. Springer,
    2019.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] Nancy XR Wang, Ali Farhadi, Rajesh PN Rao, and Bingni W Brunton. Ajile
    movement prediction: Multimodal deep learning for natural human neural recordings
    and video. In Thirty-Second AAAI Conference on Artificial Intelligence, 2018.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] William Yang Wang and Diyi Yang. That’s so annoying!!!: A lexical and
    frame-semantic embedding based data augmentation approach to automatic categorization
    of annoying behaviors using# petpeeve tweets. In Proceedings of the 2015 Conference
    on Empirical Methods in Natural Language Processing, pages 2557–2563, 2015.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] Xiaolong Wang, Ross Girshick, Abhinav Gupta, and Kaiming He. Non-local
    neural networks. In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pages 7794–7803, 2018.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] Zeyu Wang, Klint Qinami, Yannis Karakozis, Kyle Genova, Prem Nair, Kenji
    Hata, and Olga Russakovsky. Towards fairness in visual recognition: Effective
    strategies for bias mitigation. arXiv preprint arXiv:1911.11834, 2019.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] Ziyu Wang, Victor Bapst, Nicolas Heess, Volodymyr Mnih, Remi Munos, Koray
    Kavukcuoglu, and Nando de Freitas. Sample efficient actor-critic with experience
    replay. arXiv preprint arXiv:1611.01224, 2016.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] Jason W Wei and Kai Zou. Eda: Easy data augmentation techniques for boosting
    performance on text classification tasks. arXiv preprint arXiv:1901.11196, 2019.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] Shih-En Wei, Varun Ramakrishna, Takeo Kanade, and Yaser Sheikh. Convolutional
    pose machines. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 4724–4732, 2016.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] Martin Weigert, Uwe Schmidt, Tobias Boothe, Andreas Müller, Alexandr
    Dibrov, Akanksha Jain, Benjamin Wilhelm, Deborah Schmidt, Coleman Broaddus, Siân
    Culley, et al. Content-aware image restoration: pushing the limits of fluorescence
    microscopy. Nature methods, 15(12):1090, 2018.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] David Weiss, Chris Alberti, Michael Collins, and Slav Petrov. Structured
    training for neural network transition-based parsing. arXiv preprint arXiv:1506.06158,
    2015.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] Julia K Winkler, Christine Fink, Ferdinand Toberer, Alexander Enk, Teresa
    Deinlein, Rainer Hofmann-Wellenhof, Luc Thomas, Aimilios Lallas, Andreas Blum,
    Wilhelm Stolz, et al. Association between surgical skin markings in dermoscopic
    images and diagnostic performance of a deep learning convolutional neural network
    for melanoma recognition. JAMA dermatology, 155(10):1135–1141, 2019.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, and Ross Girshick.
    Detectron2. [https://github.com/facebookresearch/detectron2](https://github.com/facebookresearch/detectron2),
    2019.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse,
    Aneesh S Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular
    machine learning. Chemical science, 9(2):513–530, 2018.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and
    Philip S Yu. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596,
    2019.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] Qizhe Xie, Zihang Dai, Eduard Hovy, Minh-Thang Luong, and Quoc V Le.
    Unsupervised data augmentation. arXiv preprint arXiv:1904.12848, 2019.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] Qizhe Xie, Eduard Hovy, Minh-Thang Luong, and Quoc V Le. Self-training
    with noisy student improves imagenet classification. arXiv preprint arXiv:1911.04252,
    2019.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Saining Xie, Ross Girshick, Piotr Dollár, Zhuowen Tu, and Kaiming He.
    Aggregated residual transformations for deep neural networks. In Proceedings of
    the IEEE conference on computer vision and pattern recognition, pages 1492–1500,
    2017.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] Jun Xu, Xiaofei Luo, Guanhao Wang, Hannah Gilmore, and Anant Madabhushi.
    A deep convolutional neural network for segmenting and classifying epithelial
    and stromal regions in histopathological images. Neurocomputing, 191:214–223,
    2016.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] Xueting Yan, Ishan Misra, Abhinav Gupta, Deepti Ghadiyaram, and Dhruv
    Mahajan. Clusterfit: Improving generalization of visual representations. arXiv
    preprint arXiv:1912.03330, 2019.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] Yilong Yang, Zhuyifan Ye, Yan Su, Qianqian Zhao, Xiaoshan Li, and Defang
    Ouyang. Deep learning for in vitro prediction of pharmaceutical formulations.
    Acta pharmaceutica sinica B, 9(1):177–185, 2019.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov,
    and Quoc V Le. Xlnet: Generalized autoregressive pretraining for language understanding.
    arXiv preprint arXiv:1906.08237, 2019.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] Koichiro Yasaka, Hiroyuki Akai, Osamu Abe, and Shigeru Kiryu. Deep learning
    with convolutional neural network for differentiation of liver masses at dynamic
    contrast-enhanced ct: a preliminary study. Radiology, 286(3):887–896, 2017.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] Jason Yosinski, Jeff Clune, Anh Nguyen, Thomas Fuchs, and Hod Lipson.
    Understanding neural networks through deep visualization. arXiv preprint arXiv:1506.06579,
    2015.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Yuhui Yuan, Xilin Chen, and Jingdong Wang. Object-contextual representations
    for semantic segmentation. arXiv preprint arXiv:1909.11065, 2019.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] Sangdoo Yun, Dongyoon Han, Seong Joon Oh, Sanghyuk Chun, Junsuk Choe,
    and Youngjoon Yoo. Cutmix: Regularization strategy to train strong classifiers
    with localizable features. In Proceedings of the IEEE International Conference
    on Computer Vision, pages 6023–6032, 2019.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Russ R
    Salakhutdinov, and Alexander J Smola. Deep sets. In Advances in neural information
    processing systems, pages 3391–3401, 2017.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] Matthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional
    networks. In European conference on computer vision, pages 818–833. Springer,
    2014.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] Daojian Zeng, Kang Liu, Yubo Chen, and Jun Zhao. Distant supervision
    for relation extraction via piecewise convolutional neural networks. In Proceedings
    of the 2015 Conference on Empirical Methods in Natural Language Processing, pages
    1753–1762, 2015.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] Xiaohua Zhai, Avital Oliver, Alexander Kolesnikov, and Lucas Beyer. S4l:
    Self-supervised semi-supervised learning. arXiv preprint arXiv:1905.03670, 2019.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] Xiaohua Zhai, Joan Puigcerver, Alexander Kolesnikov, Pierre Ruyssen,
    Carlos Riquelme, Mario Lucic, Josip Djolonga, Andre Susano Pinto, Maxim Neumann,
    Alexey Dosovitskiy, et al. The visual task adaptation benchmark. arXiv preprint
    arXiv:1910.04867, 2019.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] Aston Zhang, Zachary C Lipton, Mu Li, and Alexander J Smola. Dive into
    deep learning. Unpublished draft. Retrieved, 3:319, 2019.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup:
    Beyond empirical risk minimization. arXiv preprint arXiv:1710.09412, 2017.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Junkang Zhang, Haigen Hu, Shengyong Chen, Yujiao Huang, and Qiu Guan.
    Cancer cells detection in phase-contrast microscopy images based on faster r-cnn.
    In 2016 9th International Symposium on Computational Intelligence and Design (ISCID),
    volume 1, pages 363–367\. IEEE, 2016.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. Residual
    dense network for image super-resolution. In Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pages 2472–2481, 2018.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] Victor Zhong, Caiming Xiong, and Richard Socher. Seq2sql: Generating
    structured queries from natural language using reinforcement learning. arXiv preprint
    arXiv:1709.00103, 2017.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba.
    Object detectors emerge in deep scene cnns. arXiv preprint arXiv:1412.6856, 2014.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang, Ming Zhou, and Tiejun
    Zhao. Neural document summarization by jointly learning to score and select sentences.
    arXiv preprint arXiv:1807.02305, 2018.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired
    image-to-image translation using cycle-consistent adversarial networks. In Proceedings
    of the IEEE international conference on computer vision, pages 2223–2232, 2017.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] Luisa M Zintgraf, Taco S Cohen, Tameem Adel, and Max Welling. Visualizing
    deep neural network decisions: Prediction difference analysis. arXiv preprint
    arXiv:1702.04595, 2017.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
