- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:04:36'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:04:36
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1909.11573] Deep Learning for Deepfakes Creation and Detection: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1909.11573] 深度学习在深度伪造创建与检测中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1909.11573](https://ar5iv.labs.arxiv.org/html/1909.11573)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1909.11573](https://ar5iv.labs.arxiv.org/html/1909.11573)
- en: 'Deep Learning for Deepfakes Creation and Detection: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在深度伪造创建与检测中的应用：综述
- en: Thanh Thi Nguyen Quoc Viet Hung Nguyen Dung Tien Nguyen Duc Thanh Nguyen Thien Huynh-The
    Saeid Nahavandi Thanh Tam Nguyen Quoc-Viet Pham Cuong M. Nguyen
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Thanh Thi Nguyen Quoc Viet Hung Nguyen Dung Tien Nguyen Duc Thanh Nguyen Thien
    Huynh-The Saeid Nahavandi Thanh Tam Nguyen Quoc-Viet Pham Cuong M. Nguyen
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning has been successfully applied to solve various complex problems
    ranging from big data analytics to computer vision and human-level control. Deep
    learning advances however have also been employed to create software that can
    cause threats to privacy, democracy and national security. One of those deep learning-powered
    applications recently emerged is deepfake. Deepfake algorithms can create fake
    images and videos that humans cannot distinguish them from authentic ones. The
    proposal of technologies that can automatically detect and assess the integrity
    of digital visual media is therefore indispensable. This paper presents a survey
    of algorithms used to create deepfakes and, more importantly, methods proposed
    to detect deepfakes in the literature to date. We present extensive discussions
    on challenges, research trends and directions related to deepfake technologies.
    By reviewing the background of deepfakes and state-of-the-art deepfake detection
    methods, this study provides a comprehensive overview of deepfake techniques and
    facilitates the development of new and more robust methods to deal with the increasingly
    challenging deepfakes.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已成功应用于解决各种复杂问题，从大数据分析到计算机视觉和人类级控制。然而，深度学习的进展也被用于创建可能威胁隐私、民主和国家安全的软件。其中之一就是深度伪造。深度伪造算法可以创建假图像和视频，人们无法将其与真实的图像区分开。因此，提出能够自动检测和评估数字视觉媒体完整性的技术至关重要。本文综述了用于创建深度伪造的算法，及至今文献中提出的深度伪造检测方法。我们对深度伪造技术相关的挑战、研究趋势和方向进行了广泛讨论。通过回顾深度伪造的背景和最先进的深度伪造检测方法，本研究提供了对深度伪造技术的全面概述，并促进了应对日益复杂的深度伪造问题的新方法的发展。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: deepfakes , face manipulation , artificial intelligence , deep learning , autoencoders
    , GAN , forensics , survey\affiliation
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: deepfakes，面部操控，人工智能，深度学习，自编码器，生成对抗网络（GAN），取证，调查\affiliation
- en: '[inst1]organization=School of Information Technology, Deakin University,state=Victoria,
    country=Australia'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst1]组织=信息技术学院，迪肯大学，省=维多利亚，国家=澳大利亚'
- en: \affiliation
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst2]organization=School of Information and Communication Technology, Griffith
    University, state=Queensland, country=Australia'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst2]组织=信息与通信技术学院，格里菲斯大学，省=昆士兰，国家=澳大利亚'
- en: \affiliation
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst3]organization=ICT Convergence Research Center, Kumoh National Institute
    of Technology, state=Gyeongbuk, country=Republic of Korea'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst3]组织=信息通信技术融合研究中心，金五国立科技大学，省=庆北，国家=韩国'
- en: \affiliation
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst4]organization=Institute for Intelligent Systems Research and Innovation,
    Deakin University, state=Victoria, country=Australia'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst4]组织=智能系统研究与创新学院，迪肯大学，省=维多利亚，国家=澳大利亚'
- en: \affiliation
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst5]organization=Faculty of Information Technology, Ho Chi Minh City University
    of Technology (HUTECH), state=Ho Chi Minh City, country=Vietnam'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst5]组织=信息技术学院，胡志明市科技大学（HUTECH），省=胡志明市，国家=越南'
- en: \affiliation
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst6]organization=Korean Southeast Center for the 4th Industrial Revolution
    Leader Education, Pusan National University, state=Busan, country=Republic of
    Korea'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst6]组织=韩国东南4.0工业革命领导者教育中心，釜山国立大学，省=釜山，国家=韩国'
- en: \affiliation
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: \affiliation
- en: '[inst7]organization=LAMIH UMR CNRS 8201, Universite Polytechnique Hauts-de-France,
    state=Valenciennes, country=France'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: '[inst7]组织=LAMIH UMR CNRS 8201，高法兰西理工大学，省=瓦朗谢讷，国家=法国'
- en: 1 Introduction
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: In a narrow definition, deepfakes (stemming from “deep learning” and “fake”)
    are created by techniques that can superimpose face images of a target person
    onto a video of a source person to make a video of the target person doing or
    saying things the source person does. This constitutes a category of deepfakes,
    namely *face-swap*. In a broader definition, deepfakes are artificial intelligence-synthesized
    content that can also fall into two other categories, i.e., *lip-sync* and *puppet-master*.
    Lip-sync deepfakes refer to videos that are modified to make the mouth movements
    consistent with an audio recording. Puppet-master deepfakes include videos of
    a target person (puppet) who is animated following the facial expressions, eye
    and head movements of another person (master) sitting in front of a camera [[1](#bib.bib1)].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在狭义上，深度伪造（源于“深度学习”和“伪造”）是通过技术创建的，这些技术可以将目标人物的面部图像叠加到源人物的视频上，使目标人物在视频中做或说源人物所做的事。这构成了深度伪造的一类，即*面部替换*。在广义上，深度伪造是人工智能合成的内容，也可以分为另外两类，即*口型同步*和*木偶大师*。口型同步深度伪造指的是修改视频以使口部动作与音频录音一致。木偶大师深度伪造包括目标人物（木偶）的动画视频，该人物根据另一位坐在摄像机前的人的面部表情、眼睛和头部动作进行动画制作[[1](#bib.bib1)]。
- en: While some deepfakes can be created by traditional visual effects or computer-graphics
    approaches, the recent common underlying mechanism for deepfake creation is deep
    learning models such as autoencoders and generative adversarial networks (GANs),
    which have been applied widely in the computer vision domain [[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. These models are used to examine facial expressions and movements
    of a person and synthesize facial images of another person making analogous expressions
    and movements [[9](#bib.bib9)]. Deepfake methods normally require a large amount
    of image and video data to train models to create photo-realistic images and videos.
    As public figures such as celebrities and politicians may have a large number
    of videos and images available online, they are initial targets of deepfakes.
    Deepfakes were used to swap faces of celebrities or politicians to bodies in porn
    images and videos. The first deepfake video emerged in 2017 where face of a celebrity
    was swapped to the face of a porn actor. It is threatening to world security when
    deepfake methods can be employed to create videos of world leaders with fake speeches
    for falsification purposes [[10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12)].
    Deepfakes therefore can be abused to cause political or religion tensions between
    countries, to fool public and affect results in election campaigns, or create
    chaos in financial markets by creating fake news [[13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15)]. It can be even used to generate fake satellite images of the
    Earth to contain objects that do not really exist to confuse military analysts,
    e.g., creating a fake bridge across a river although there is no such a bridge
    in reality. This can mislead a troop who have been guided to cross the bridge
    in a battle [[16](#bib.bib16), [17](#bib.bib17)].
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些深度伪造（deepfake）可以通过传统的视觉效果或计算机图形方法创建，但最近用于深度伪造生成的共同基础机制是深度学习模型，如自动编码器和生成对抗网络（GANs），这些模型在计算机视觉领域得到了广泛应用[[2](#bib.bib2)、[3](#bib.bib3)、[4](#bib.bib4)、[5](#bib.bib5)、[6](#bib.bib6)、[7](#bib.bib7)、[8](#bib.bib8)]。这些模型用于检查一个人的面部表情和动作，并合成另一个人具有类似表情和动作的面部图像[[9](#bib.bib9)]。深度伪造方法通常需要大量的图像和视频数据来训练模型，以创建逼真的图像和视频。由于公众人物如名人和政治家的视频和图像数量可能很大，他们成为深度伪造的首要目标。深度伪造被用于将名人或政治家的面部替换到色情图像和视频中的身体上。第一个深度伪造视频出现在2017年，其中名人的面部被替换成色情演员的面部。当深度伪造方法被用于创建世界领导人的虚假演讲视频以进行伪造时，这对全球安全构成威胁[[10](#bib.bib10)、[11](#bib.bib11)、[12](#bib.bib12)]。因此，深度伪造可能被滥用于造成国家间的政治或宗教紧张局势，欺骗公众并影响选举活动的结果，或者通过制造假新闻在金融市场上制造混乱[[13](#bib.bib13)、[14](#bib.bib14)、[15](#bib.bib15)]。它甚至可以用来生成假的地球卫星图像，包含实际上不存在的物体，以混淆军事分析人员，例如，创建一个假桥梁穿越河流，尽管现实中并不存在这样的桥梁。这可能误导被指引去过桥的部队在战斗中[[16](#bib.bib16)、[17](#bib.bib17)]。
- en: As the democratization of creating realistic digital humans has positive implications,
    there is also positive use of deepfakes such as their applications in visual effects,
    digital avatars, snapchat filters, creating voices of those who have lost theirs
    or updating episodes of movies without reshooting them [[18](#bib.bib18)]. Deepfakes
    can have creative or productive impacts in photography, video games, virtual reality,
    movie productions, and entertainment, e.g., realistic video dubbing of foreign
    films, education through the reanimation of historical figures, virtually trying
    on clothes while shopping, and so on [[19](#bib.bib19), [20](#bib.bib20)]. However,
    the number of malicious uses of deepfakes largely dominates that of the positive
    ones. The development of advanced deep neural networks and the availability of
    large amount of data have made the forged images and videos almost indistinguishable
    to humans and even to sophisticated computer algorithms. The process of creating
    those manipulated images and videos is also much simpler today as it needs as
    little as an identity photo or a short video of a target individual. Less and
    less effort is required to produce a stunningly convincing tempered footage. Recent
    advances can even create a deepfake with just a still image [[21](#bib.bib21)].
    Deepfakes therefore can be a threat affecting not only public figures but also
    ordinary people. For example, a voice deepfake was used to scam a CEO out of $243,000
    [[22](#bib.bib22)]. A recent release of a software called DeepNude shows more
    disturbing threats as it can transform a person to a non-consensual porn [[23](#bib.bib23)].
    Likewise, the Chinese app Zao has gone viral lately as less-skilled users can
    swap their faces onto bodies of movie stars and insert themselves into well-known
    movies and TV clips [[24](#bib.bib24)]. These forms of falsification create a
    huge threat to violation of privacy and identity, and affect many aspects of human
    lives.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然创造逼真的数字人类具有积极的意义，但深度伪造也有其积极用途，如在视觉效果、数字头像、Snapchat滤镜中应用，创建失声者的声音或更新电影情节而不需要重新拍摄[[18](#bib.bib18)]。深度伪造在摄影、视频游戏、虚拟现实、电影制作和娱乐领域可能产生创造性或生产性的影响，例如，为外国影片进行逼真的视频配音，通过复活历史人物进行教育，购物时虚拟试衣等[[19](#bib.bib19),
    [20](#bib.bib20)]。然而，恶意使用深度伪造的情况远远超过了积极用途。先进的深度神经网络的发展以及大量数据的可用性使得伪造的图像和视频几乎无法被人类甚至复杂的计算机算法区分。如今，创建这些被操控的图像和视频的过程也变得更加简单，只需要一张身份证照片或一个目标个体的短视频即可。生产令人信服的伪造镜头所需的努力越来越少。最近的技术进展甚至可以仅用一张静态图像创建深度伪造[[21](#bib.bib21)]。因此，深度伪造可能对公众人物和普通人都构成威胁。例如，一种声音深度伪造被用来骗取一位首席执行官243,000美元[[22](#bib.bib22)]。最近发布的DeepNude软件显示了更令人不安的威胁，因为它可以将一个人转换为未经同意的色情内容[[23](#bib.bib23)]。同样，中国应用程序Zao最近也引起了广泛关注，因为技术水平较低的用户可以将自己的面孔换到电影明星的身体上，并将自己插入知名电影和电视片段中[[24](#bib.bib24)]。这些伪造形式对隐私和身份的侵犯构成了巨大的威胁，并影响到人们生活的许多方面。
- en: '![Refer to caption](img/128d6827701974df74f2d217f70fd0ec.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/128d6827701974df74f2d217f70fd0ec.png)'
- en: 'Figure 1: Number of papers related to deepfakes in years from 2016 to 2021,
    obtained from https://app.dimensions.ai at the end of 2021 with the search keyword
    “deepfake” applied to full text of scholarly papers.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：2016年至2021年与深度伪造相关的论文数量，数据来源于 https://app.dimensions.ai ，在2021年底时使用关键词“deepfake”对学术论文全文进行搜索得到的结果。
- en: 'Finding the truth in digital domain therefore has become increasingly critical.
    It is even more challenging when dealing with deepfakes as they are majorly used
    to serve malicious purposes and almost anyone can create deepfakes these days
    using existing deepfake tools. Thus far, there have been numerous methods proposed
    to detect deepfakes [[25](#bib.bib25), [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28),
    [29](#bib.bib29)]. Most of them are based on deep learning, and thus a battle
    between malicious and positive uses of deep learning methods has been arising.
    To address the threat of face-swapping technology or deepfakes, the United States
    Defense Advanced Research Projects Agency (DARPA) initiated a research scheme
    in media forensics (named Media Forensics or MediFor) to accelerate the development
    of fake digital visual media detection methods [[30](#bib.bib30)]. Recently, Facebook
    Inc. teaming up with Microsoft Corp and the Partnership on AI coalition have launched
    the Deepfake Detection Challenge to catalyse more research and development in
    detecting and preventing deepfakes from being used to mislead viewers [[31](#bib.bib31)].
    Data obtained from https://app.dimensions.ai at the end of 2021 show that the
    number of deepfake papers has increased significantly in recent years (Fig. [1](#S1.F1
    "Figure 1 ‣ 1 Introduction ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey")). Although the obtained numbers of deepfake papers may be lower than
    actual numbers but the research trend of this topic is obviously increasing.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
- en: 'There have been existing survey papers about creating and detecting deepfakes,
    presented in [[32](#bib.bib32), [20](#bib.bib20), [19](#bib.bib19)]. For example,
    Mirsky and Lee [[19](#bib.bib19)] focused on reenactment approaches (i.e., to
    change a target’s expression, mouth, pose, gaze or body), and replacement approaches
    (i.e., to replace a target’s face by swap or transfer methods). Verdoliva [[20](#bib.bib20)]
    separated detection approaches into conventional methods (e.g., blind methods
    without using any external data for training, one-class sensor-based and model-based
    methods, and supervised methods with handcrafted features) and deep learning-based
    approaches (e.g., CNN models). Tolosana et al. [[32](#bib.bib32)] categorized
    both creation and detection methods based on the way deepfakes are created, including
    entire face synthesis, identity swap, attribute manipulation, and expression swap.
    On the other hand, we carry out the survey with a different perspective and taxonomy.
    We categorize the deepfake detection methods based on the data type, i.e., images
    or videos, as presented in Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Learning
    for Deepfakes Creation and Detection: A Survey"). With fake image detection methods,
    we focus on the features that are used, i.e., whether they are handcrafted features
    or deep features. With fake video detection methods, two main subcategories are
    identified based on whether the method uses temporal features across frames or
    visual artifacts within a video frame. We also discuss extensively the challenges,
    research trends and directions on deepfake detection and multimedia forensics
    problems.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 已有关于深度伪造创建和检测的综述文献，如[[32](#bib.bib32)、[20](#bib.bib20)、[19](#bib.bib19)]。例如，Mirsky
    和 Lee [[19](#bib.bib19)] 关注了重现方法（即更改目标的表情、嘴巴、姿势、注视或身体）和替换方法（即通过交换或转移方法替换目标的面部）。Verdoliva
    [[20](#bib.bib20)] 将检测方法分为传统方法（例如，不使用任何外部数据进行训练的盲目方法、一类传感器方法和基于模型的方法，以及使用手工特征的监督方法）和基于深度学习的方法（例如，CNN
    模型）。Tolosana 等人 [[32](#bib.bib32)] 根据深度伪造的创建方式对创建和检测方法进行了分类，包括整个面部合成、身份交换、属性操控和表情交换。另一方面，我们从不同的视角和分类法来进行调查。我们根据数据类型，即图像或视频，对深度伪造检测方法进行分类，如图[2](#S1.F2
    "图2 ‣ 1 引言 ‣ 深度学习在深度伪造创建和检测中的应用：综述")所示。对于假图像检测方法，我们关注所使用的特征，即这些特征是手工特征还是深度特征。对于假视频检测方法，根据方法是否使用跨帧的时间特征或视频帧中的视觉伪影，识别出两个主要子类别。我们还广泛讨论了深度伪造检测和多媒体取证问题的挑战、研究趋势和方向。
- en: '![Refer to caption](img/42bdb910e34de12c9daaa0a9c3e53d65.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/42bdb910e34de12c9daaa0a9c3e53d65.png)'
- en: 'Figure 2: Categories of reviewed papers relevant to deepfake detection methods
    where we divide papers into two major groups, i.e., fake image detection and face
    video detection.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：与深度伪造检测方法相关的文献分类，我们将文献分为两个主要类别，即假图像检测和面部视频检测。
- en: 2 Deepfake Creation
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度伪造创建
- en: 'Deepfakes have become popular due to the quality of tampered videos and also
    the easy-to-use ability of their applications to a wide range of users with various
    computer skills from professional to novice. These applications are mostly developed
    based on deep learning techniques. Deep learning is well known for its capability
    of representing complex and high-dimensional data. One variant of the deep networks
    with that capability is deep autoencoders, which have been widely applied for
    dimensionality reduction and image compression [[33](#bib.bib33), [34](#bib.bib34),
    [35](#bib.bib35)]. The first attempt of deepfake creation was FakeApp, developed
    by a Reddit user using autoencoder-decoder pairing structure [[36](#bib.bib36),
    [37](#bib.bib37)]. In that method, the autoencoder extracts latent features of
    face images and the decoder is used to reconstruct the face images. To swap faces
    between source images and target images, there is a need of two encoder-decoder
    pairs where each pair is used to train on an image set, and the encoder’s parameters
    are shared between two network pairs. In other words, two pairs have the same
    encoder network. This strategy enables the common encoder to find and learn the
    similarity between two sets of face images, which are relatively unchallenging
    because faces normally have similar features such as eyes, nose, mouth positions.
    Fig. [3](#S2.F3 "Figure 3 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey") shows a deepfake creation process where the
    feature set of face A is connected with the decoder B to reconstruct face B from
    the original face A. This approach is applied in several works such as DeepFaceLab
    [[38](#bib.bib38)], DFaker [[39](#bib.bib39)], DeepFake_tf (tensorflow-based deepfakes)
    [[40](#bib.bib40)].'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造因其篡改视频的质量和应用程序的易用性而变得流行，这些应用程序适用于各种计算机技能水平的用户，从专业到新手。这些应用程序主要基于深度学习技术开发。深度学习因其表示复杂和高维数据的能力而闻名。具有这种能力的深度网络的一种变体是深度自编码器，这些自编码器已广泛应用于降维和图像压缩[[33](#bib.bib33),
    [34](#bib.bib34), [35](#bib.bib35)]。深度伪造创建的首次尝试是FakeApp，由一个Reddit用户开发，使用自编码器-解码器配对结构[[36](#bib.bib36),
    [37](#bib.bib37)]。在这种方法中，自编码器提取人脸图像的潜在特征，解码器用于重建人脸图像。为了在源图像和目标图像之间交换人脸，需要两个编码器-解码器对，每对用于训练一个图像集，并且编码器的参数在两个网络对之间共享。换句话说，这两个对具有相同的编码器网络。这种策略使得共同的编码器能够找到并学习两组人脸图像之间的相似性，这些人脸通常具有相似的特征，如眼睛、鼻子、嘴巴位置。图[3](#S2.F3
    "图3 ‣ 2 深度伪造创建 ‣ 深度学习在深度伪造创建和检测中的应用：综述")展示了一个深度伪造创建过程，其中人脸A的特征集与解码器B连接，以从原始人脸A重建人脸B。这种方法应用于多个工作中，如DeepFaceLab[[38](#bib.bib38)]、DFaker[[39](#bib.bib39)]、DeepFake_tf（基于tensorflow的深度伪造）[[40](#bib.bib40)]。
- en: 'Table 1: Summary of notable deepfake tools'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：主要深度伪造工具的总结
- en: '| Tools | Links | Key Features |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 工具 | 链接 | 关键特性 |'
- en: '| Faceswap | https://github.com/deepfakes/faceswap | - Using two encoder-decoder
    pairs. - Parameters of the encoder are shared. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Faceswap | https://github.com/deepfakes/faceswap | - 使用两个编码器-解码器对。 - 编码器的参数共享。
    |'
- en: '| Faceswap-GAN | https://github.com/shaoanlu/faceswap-GAN | Adversarial loss
    and perceptual loss (VGGface) are added to an auto-encoder architecture. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Faceswap-GAN | https://github.com/shaoanlu/faceswap-GAN | 在自编码器架构中添加了对抗损失和感知损失（VGGface）。
    |'
- en: '| Few-Shot Face Translation | https://github.com/shaoanlu/fewshot-face-translation-GAN
    | - Use a pre-trained face recognition model to extract latent embeddings for
    GAN processing. - Incorporate semantic priors obtained by modules from FUNIT [[41](#bib.bib41)]
    and SPADE [[42](#bib.bib42)]. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 少量样本人脸翻译 | https://github.com/shaoanlu/fewshot-face-translation-GAN | - 使用预训练的人脸识别模型提取潜在嵌入以进行GAN处理。
    - 结合通过FUNIT[[41](#bib.bib41)]和SPADE[[42](#bib.bib42)]模块获得的语义先验。 |'
- en: '| DeepFaceLab | https://github.com/iperov/DeepFaceLab | - Expand from the Faceswap
    method with new models, e.g. H64, H128, LIAEF128, SAE [[43](#bib.bib43)]. - Support
    multiple face extraction modes, e.g. S3FD, MTCNN, dlib, or manual [[43](#bib.bib43)].
    |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| DeepFaceLab | https://github.com/iperov/DeepFaceLab | - 从Faceswap方法扩展，包含新模型，如H64、H128、LIAEF128、SAE[[43](#bib.bib43)]。
    - 支持多种人脸提取模式，如S3FD、MTCNN、dlib或手动[[43](#bib.bib43)]。 |'
- en: '| DFaker | https://github.com/dfaker/df | - DSSIM loss function [[44](#bib.bib44)]
    is used to reconstruct face. - Implemented based on Keras library. |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| DFaker | https://github.com/dfaker/df | - 使用DSSIM损失函数[[44](#bib.bib44)]重建人脸。
    - 基于Keras库实现。 |'
- en: '| DeepFake_tf | https://github.com/StromWine/DeepFake_tf | Similar to DFaker
    but implemented based on tensorflow. |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| DeepFake_tf | https://github.com/StromWine/DeepFake_tf | 类似于DFaker，但基于tensorflow实现。
    |'
- en: '| AvatarMe | https://github.com/lattas/AvatarMe | - Reconstruct 3D faces from
    arbitrary “in-the-wild” images. - Can reconstruct authentic 4K by 6K-resolution
    3D faces from a single low-resolution image [[45](#bib.bib45)]. |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| AvatarMe | https://github.com/lattas/AvatarMe | - 从任意“野外”图像中重建3D面孔。 - 可以从单张低分辨率图像中重建真实的4K
    x 6K分辨率3D面孔 [[45](#bib.bib45)]。 |'
- en: '| MarioNETte | https://hyperconnect.github.io/MarioNETte | - A few-shot face
    reenactment framework that preserves the target identity. - No additional fine-tuning
    phase is needed for identity adaptation [[46](#bib.bib46)]. |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| MarioNETte | https://hyperconnect.github.io/MarioNETte | - 一种几-shot面部重演框架，保持目标身份。
    - 无需额外的微调阶段来进行身份适配 [[46](#bib.bib46)]。 |'
- en: '| DiscoFaceGAN | https://github.com/microsoft/DiscoFaceGAN | - Generate face
    images of virtual people with independent latent variables of identity, expression,
    pose, and illumination. - Embed 3D priors into adversarial learning [[47](#bib.bib47)].
    |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| DiscoFaceGAN | https://github.com/microsoft/DiscoFaceGAN | - 生成具有独立潜在变量（身份、表情、姿态和光照）的虚拟人物面部图像。
    - 将3D先验嵌入对抗学习中 [[47](#bib.bib47)]。'
- en: '| StyleRig | https://gvv.mpi-inf.mpg.de/projects/StyleRig | - Create portrait
    images of faces with a rig-like control over a pretrained and fixed StyleGAN via
    3D morphable face models. - Self-supervised without manual annotations [[48](#bib.bib48)].
    |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| StyleRig | https://gvv.mpi-inf.mpg.de/projects/StyleRig | - 通过3D可变形面部模型，使用预训练的固定StyleGAN创建面部肖像图像，并进行类似于机架的控制。
    - 无需人工标注，进行自监督 [[48](#bib.bib48)]。 |'
- en: '| FaceShifter | https://lingzhili.com/FaceShifterPage | - Face swapping in
    high-fidelity by exploiting and integrating the target attributes. - Can be applied
    to any new face pairs without requiring subject specific training [[49](#bib.bib49)].
    |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| FaceShifter | https://lingzhili.com/FaceShifterPage | - 通过利用和整合目标属性进行高保真面孔交换。
    - 可以应用于任何新的面孔对，而无需特定的受试者训练 [[49](#bib.bib49)]。 |'
- en: '| FSGAN | https://github.com/YuvalNirkin/fsgan | - A face swapping and reenactment
    model that can be applied to pairs of faces without requiring training on those
    faces. - Adjust to both pose and expression variations [[50](#bib.bib50)]. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| FSGAN | https://github.com/YuvalNirkin/fsgan | - 一种面孔交换和重演模型，可以应用于面孔对，而无需对这些面孔进行训练。
    - 调整面孔的姿态和表情变化 [[50](#bib.bib50)]。 |'
- en: '| StyleGAN | https://github.com/NVlabs/stylegan | - A new generator architecture
    for GANs is proposed based on style transfer literature. - The new architecture
    leads to automatic, unsupervised separation of high-level attributes and enables
    intuitive, scale-specific control of the synthesis of images [[51](#bib.bib51)].
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| StyleGAN | https://github.com/NVlabs/stylegan | - 基于风格迁移文献提出了一种新的GAN生成器架构。
    - 新架构实现了高层次属性的自动、无监督分离，并支持直观、特定尺度的图像合成控制 [[51](#bib.bib51)]。 |'
- en: '| Face2Face | https://justusthies.github.io/posts/face2face/ | - Real-time
    facial reenactment of monocular target video sequence, e.g. Youtube video. - Animate
    the facial expressions of the target video by a source actor and re-render the
    manipulated output video in a photo-realistic fashion [[52](#bib.bib52)]. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| Face2Face | https://justusthies.github.io/posts/face2face/ | - 实时的单目目标视频序列面部重演，例如YouTube视频。
    - 通过源演员动画化目标视频中的面部表情，并以照片现实的方式重新渲染操作后的视频 [[52](#bib.bib52)]。 |'
- en: '| Neural Textures | https://github.com/SSRSGJYD/NeuralTexture | - Feature maps
    that are learned as part of the scene capture process and stored as maps on top
    of 3D mesh proxies. - Can coherently re-render or manipulate existing video content
    in both static and dynamic environments at real-time rates [[53](#bib.bib53)].
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| Neural Textures | https://github.com/SSRSGJYD/NeuralTexture | - 在场景捕捉过程中作为特征图进行学习，并作为映射存储在3D网格代理上。
    - 能够在静态和动态环境中以实时速率一致地重新渲染或操作现有视频内容 [[53](#bib.bib53)]。 |'
- en: '| Transformable Bottleneck Networks | https://github.com/kyleolsz/TB-Networks
    | - A method for fine-grained 3D manipulation of image content. - Apply spatial
    transformations in CNN models using a transformable bottleneck framework [[54](#bib.bib54)].
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| Transformable Bottleneck Networks | https://github.com/kyleolsz/TB-Networks
    | - 一种图像内容的细粒度3D操作方法。 - 使用可变形瓶颈框架在CNN模型中应用空间变换 [[54](#bib.bib54)]。 |'
- en: '| “Do as I Do” Motion Transfer | github.com/carolineec/EverybodyDanceNow |
    - Automatically transfer the motion from a source to a target person by learning
    a video-to-video translation. - Can create a motion-synchronized dancing video
    with multiple subjects [[55](#bib.bib55)]. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| “Do as I Do” Motion Transfer | github.com/carolineec/EverybodyDanceNow |
    - 通过学习视频到视频的转换自动将动作从源对象转移到目标对象。 - 可以创建多个主体的动作同步舞蹈视频 [[55](#bib.bib55)]。 |'
- en: '| Neural Voice Puppetry | https://justusthies.github.io/posts/neural-voice-puppetry
    | - A method for audio-driven facial video synthesis. - Synthesize videos of a
    talking head from an audio sequence of another person using 3D face representation.
    [[56](#bib.bib56)]. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/9907b7e31a2986374bd296789a04f03b.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: A deepfake creation model using two encoder-decoder pairs. Two networks
    use the same encoder but different decoders for training process (top). An image
    of face A is encoded with the common encoder and decoded with decoder B to create
    a deepfake (bottom). The reconstructed image (in the bottom) is the face B with
    the mouth shape of face A. Face B originally has the mouth of an upside-down heart
    while the reconstructed face B has the mouth of a conventional heart.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: By adding adversarial loss and perceptual loss implemented in VGGFace [[57](#bib.bib57)]
    to the encoder-decoder architecture, an improved version of deepfakes based on
    the generative adversarial network [[4](#bib.bib4)], i.e., faceswap-GAN, was proposed
    in [[58](#bib.bib58)]. The VGGFace perceptual loss is added to make eye movements
    to be more realistic and consistent with input faces and help to smooth out artifacts
    in segmentation mask, leading to higher quality output videos. This model facilitates
    the creation of outputs with 64x64, 128x128, and 256x256 resolutions. In addition,
    the multi-task convolutional neural network (CNN) from the FaceNet implementation
    [[59](#bib.bib59)] is used to make face detection more stable and face alignment
    more reliable. The CycleGAN [[60](#bib.bib60)] is utilized for generative network
    implementation in this model.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c8adbcfdfc2352a144fc95b8e3d3da64.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The GAN architecture consisting of a generator and a discriminator,
    and each can be implemented by a neural network. The entire system can be trained
    with backpropagation that allows both networks to improve their capabilities.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: 'A conventional GAN model comprises two neural networks: a generator and a discriminator
    as depicted in Fig. [4](#S2.F4 "Figure 4 ‣ 2 Deepfake Creation ‣ Deep Learning
    for Deepfakes Creation and Detection: A Survey"). Given a dataset of real images
    $x$ having a distribution of $p_{data}$, the aim of the generator $G$ is to produce
    images $G(z)$ similar to real images $x$ with $z$ being noise signals having a
    distribution of $p_{z}$. The aim of the discriminator $G$ is to correctly classify
    images generated by $G$ and real images $x$. The discriminator $D$ is trained
    to improve its classification capability, i.e., to maximize $D(x)$, which represents
    the probability that $x$ is a real image rather than a fake image generated by
    $G$. On the other hand, $G$ is trained to minimize the probability that its outputs
    are classified by $D$ as synthetic images, i.e., to minimize $1-D(G(z))$. This
    is a minimax game between two players $D$ and $G$ that can be described by the
    following value function [[4](#bib.bib4)]:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{G}\max_{D}V(D,G)=\operatorname{\mathbb{E}}_{x\sim p_{data}(x)}[\log
    D(x)]\\ +\operatorname{\mathbb{E}}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]$ |  | (1)
    |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '|  | $\min_{G}\max_{D}V(D,G)=\operatorname{\mathbb{E}}_{x\sim p_{data}(x)}[\log
    D(x)]\\ +\operatorname{\mathbb{E}}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]$ |  | (1)
    |'
- en: After sufficient training, both networks improve their capabilities, i.e., the
    generator $G$ is able to produce images that are really similar to real images
    while the discriminator $D$ is highly capable of distinguishing fake images from
    real ones.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 经过充分训练后，两种网络都提升了其能力，即生成器$G$能够生成与真实图像非常相似的图像，而鉴别器$D$则能够高度区分虚假图像和真实图像。
- en: 'Table [1](#S2.T1 "Table 1 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey") presents a summary of popular deepfake tools
    and their typical features. Among them, a prominent method for face synthesis
    based on a GAN model, namely StyleGAN, was introduced in [[51](#bib.bib51)]. StyleGAN
    is motivated by style transfer [[61](#bib.bib61)] with a special generator network
    architecture that is able to create realistic face images. In a traditional GAN
    model, e.g., the progressive growing of GAN (PGGAN) [[62](#bib.bib62)], the signal
    noise (latent code) is fed to the input layer of a feedforward network that represents
    the generator. In StyleGAN, there are two networks constructed and linked together,
    a mapping network $f$ and a synthesis network $g$. The latent code $z\in Z$ is
    first converted to $w\in W$ (where $W$ is an intermediate latent space) through
    a non-linear function $f:Z\rightarrow W$, which is characterized by a neural network
    (i.e., the mapping network) consisting of several fully connected layers. Using
    an affine tranformation, the intermediate representation $w$ is specialized to
    styles $y=(y_{s},y_{b})$ that will be fed to the adaptive instance normalization
    (AdaIN) operations, specified as:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](#S2.T1 "Table 1 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation
    and Detection: A Survey")展示了流行的deepfake工具及其典型特性的总结。其中，基于GAN模型的一个突出的人脸合成方法，即StyleGAN，在[[51](#bib.bib51)]中进行了介绍。StyleGAN受风格迁移[[61](#bib.bib61)]的启发，具有特殊的生成器网络架构，能够创建逼真的面部图像。在传统的GAN模型中，例如渐进式GAN（PGGAN）[[62](#bib.bib62)]，信号噪声（潜在代码）被输入到表示生成器的前馈网络的输入层中。在StyleGAN中，构建了两个相互连接的网络，一个是映射网络$f$，另一个是合成网络$g$。潜在代码$z\in
    Z$首先通过非线性函数$f:Z\rightarrow W$转换为$w\in W$（其中$W$是一个中间潜在空间），该函数由包含多个全连接层的神经网络（即映射网络）构成。通过仿射变换，中间表示$w$被专业化为风格$y=(y_{s},y_{b})$，将被输入到自适应实例归一化（AdaIN）操作中，如下所示：'
- en: '|  | $\mathrm{AdaIN}(x_{i},y)=y_{s,i}\frac{x_{i}-\mu(x_{i})}{\sigma(x_{i})}+y_{b,i}$
    |  | (2) |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathrm{AdaIN}(x_{i},y)=y_{s,i}\frac{x_{i}-\mu(x_{i})}{\sigma(x_{i})}+y_{b,i}$
    |  | (2) |'
- en: 'where each feature map $x_{i}$ is normalized separately. The StyleGAN generator
    architecture allows controlling the image synthesis by modifying the styles via
    different scales. In addition, instead of using one random latent code during
    training, this method uses two latent codes to generate a given proportion of
    images. More specifically, two latent codes $z_{1}$ and $z_{2}$ are fed to the
    mapping network to create respectively $w_{1}$ and $w_{2}$ that control the styles
    by applying $w_{1}$ before and $w_{2}$ after the crossover point. Fig. [5](#S2.F5
    "Figure 5 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey") demonstrates examples of images created by mixing two latent codes
    at three different scales where each subset of styles controls separate meaningful
    high-level attributes of the image. In other words, the generator architecture
    of StyleGAN is able to learn separation of high-level attributes (e.g., pose and
    identity when trained on human faces) and enables intuitive, scale-speciﬁc control
    of the face synthesis.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '其中每个特征图$x_{i}$是单独标准化的。StyleGAN生成器架构允许通过不同尺度的风格修改来控制图像合成。此外，这种方法在训练期间不使用一个随机潜在代码，而是使用两个潜在代码来生成给定比例的图像。更具体地说，将两个潜在代码$z_{1}$和$z_{2}$输入到映射网络中，分别创建$w_{1}$和$w_{2}$，通过在交叉点前应用$w_{1}$和在交叉点后应用$w_{2}$来控制风格。图[5](#S2.F5
    "Figure 5 ‣ 2 Deepfake Creation ‣ Deep Learning for Deepfakes Creation and Detection:
    A Survey")展示了在三个不同尺度下混合两个潜在代码生成的图像示例，其中每个风格子集控制图像的不同高层次属性。换句话说，StyleGAN的生成器架构能够学习高层次属性的分离（例如，当在面部图像上训练时，姿势和身份），并实现直观的、特定尺度的面部合成控制。'
- en: '![Refer to caption](img/8c0b982c233bf90f257b5c47b85d1b1e.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8c0b982c233bf90f257b5c47b85d1b1e.png)'
- en: 'Figure 5: Examples of mixing styles using StyleGAN: the output images are generated
    by copying a specified subset of styles from source B and taking the rest from
    source A. a) Copying coarse styles from source B will generate images that have
    high-level aspects from source B and all colors and finer facial features from
    source A; b) if copying the styles of middle resolutions from B, the output images
    will have smaller scale facial features from B and preserve the pose, general
    face shape, and eyeglasses from A; c) if copying the fine styles from source B,
    the generated images will have the color scheme and microstructure of source B
    [[51](#bib.bib51)].'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：使用 StyleGAN 混合风格的示例：输出图像是通过从源 B 复制指定子集的风格并从源 A 获取其余部分生成的。a) 从源 B 复制粗糙风格将生成具有源
    B 高级特征和源 A 的所有颜色及更细面部特征的图像；b) 如果从源 B 复制中等分辨率的风格，输出图像将具有源 B 的较小尺度面部特征，同时保留源 A 的姿势、一般面部形状和眼镜；c)
    如果从源 B 复制细节风格，生成的图像将具有源 B 的色彩方案和微观结构 [[51](#bib.bib51)]。
- en: 3 Deepfake Detection
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 深度伪造检测
- en: Deepfake detection is normally deemed a binary classification problem where
    classifiers are used to classify between authentic videos and tampered ones. This
    kind of methods requires a large database of real and fake videos to train classification
    models. The number of fake videos is increasingly available, but it is still limited
    in terms of setting a benchmark for validating various detection methods. To address
    this issue, Korshunov and Marcel [[63](#bib.bib63)] produced a notable deepfake
    dataset consisting of 620 videos based on the GAN model using the open source
    code Faceswap-GAN [[58](#bib.bib58)]. Videos from the publicly available VidTIMIT
    database [[64](#bib.bib64)] were used to generate low and high quality deepfake
    videos, which can effectively mimic the facial expressions, mouth movements, and
    eye blinking. These videos were then used to test various deepfake detection methods.
    Test results show that the popular face recognition systems based on VGG [[65](#bib.bib65)]
    and Facenet [[59](#bib.bib59), [66](#bib.bib66)] are unable to detect deepfakes
    effectively. Other methods such as lip-syncing approaches [[67](#bib.bib67), [68](#bib.bib68),
    [69](#bib.bib69)] and image quality metrics with support vector machine (SVM)
    [[70](#bib.bib70)] produce very high error rate when applied to detect deepfake
    videos from this newly produced dataset. This raises concerns about the critical
    need of future development of more robust methods that can detect deepfakes from
    genuine.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 深度伪造检测通常被视为二分类问题，其中分类器用于区分真实视频和篡改视频。这种方法需要一个大量的真实和伪造视频数据库来训练分类模型。伪造视频的数量越来越多，但在为各种检测方法设定基准方面仍然有限。为解决这一问题，Korshunov
    和 Marcel [[63](#bib.bib63)] 制作了一个重要的深度伪造数据集，包含 620 个基于 GAN 模型的视频，使用开源代码 Faceswap-GAN
    [[58](#bib.bib58)]。使用公开的 VidTIMIT 数据库 [[64](#bib.bib64)] 中的视频生成了低质量和高质量的深度伪造视频，这些视频能有效模拟面部表情、嘴部动作和眼睛眨动。这些视频随后被用于测试各种深度伪造检测方法。测试结果显示，基于
    VGG [[65](#bib.bib65)] 和 Facenet [[59](#bib.bib59), [66](#bib.bib66)] 的流行面部识别系统无法有效检测深度伪造。其他方法，如唇同步方法
    [[67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69)] 和支持向量机（SVM） [[70](#bib.bib70)]
    的图像质量指标在检测来自这个新生成的数据集的深度伪造视频时产生了非常高的错误率。这引发了对未来发展更强大方法的迫切需求，以便能够从真实视频中检测深度伪造。
- en: 'This section presents a survey of deepfake detection methods where we group
    them into two major categories: fake image detection methods and fake video detection
    ones (Fig. [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Deep Learning for Deepfakes
    Creation and Detection: A Survey")). The latter is distinguished into two smaller
    groups: *visual artifacts* within single video frame-based methods and *temporal
    features* across frames-based ones. Whilst most of the methods based on temporal
    features use deep learning *recurrent* classification models, the methods use
    visual artifacts within video frame can be implemented by either deep or shallow
    classifiers.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了深度伪造检测方法的调查，我们将其分为两个主要类别：伪造图像检测方法和伪造视频检测方法（图[2](#S1.F2 "图 2 ‣ 1 引言 ‣ 深度学习在深度伪造创建和检测中的应用：综述")）。后者又分为两个小组：基于单帧视频中的*视觉伪影*的方法和基于跨帧的*时间特征*的方法。虽然大多数基于时间特征的方法使用深度学习*递归*分类模型，但使用视频帧中的视觉伪影的方法可以通过深度或浅层分类器实现。
- en: 3.1 Fake Image Detection
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 伪造图像检测
- en: Deepfakes are increasingly detrimental to privacy, society security and democracy
    [[71](#bib.bib71)]. Methods for detecting deepfakes have been proposed as soon
    as this threat was introduced. Early attempts were based on handcrafted features
    obtained from artifacts and inconsistencies of the fake image synthesis process.
    Recent methods, e.g., [[72](#bib.bib72), [73](#bib.bib73)], have commonly applied
    deep learning to automatically extract salient and discriminative features to
    detect deepfakes.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Handcrafted Features-based Methods
  id: totrans-75
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Most works on detection of GAN generated images do not consider the generalization
    capability of the detection models although the development of GAN is ongoing,
    and many new extensions of GAN are frequently introduced. Xuan et al. [[74](#bib.bib74)]
    used an image preprocessing step, e.g., Gaussian blur and Gaussian noise, to remove
    low level high frequency clues of GAN images. This increases the pixel level statistical
    similarity between real images and fake images and allows the forensic classifier
    to learn more intrinsic and meaningful features, which has better generalization
    capability than previous image forensics methods [[75](#bib.bib75), [76](#bib.bib76)]
    or image steganalysis networks [[77](#bib.bib77)].
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
- en: Zhang et al. [[78](#bib.bib78)] used the bag of words method to extract a set
    of compact features and fed it into various classifiers such as SVM [[79](#bib.bib79)],
    random forest (RF) [[80](#bib.bib80)] and multi-layer perceptrons (MLP) [[81](#bib.bib81)]
    for discriminating swapped face images from the genuine. Among deep learning-generated
    images, those synthesised by GAN models are probably most difficult to detect
    as they are realistic and high-quality based on GAN’s capability to learn distribution
    of the complex input data and generate new outputs with similar input distribution.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, Agarwal and Varshney [[82](#bib.bib82)] cast the GAN-based
    deepfake detection as a hypothesis testing problem where a statistical framework
    was introduced using the information-theoretic study of authentication [[83](#bib.bib83)].
    The minimum distance between distributions of legitimate images and images generated
    by a particular GAN is defined, namely the oracle error. The analytic results
    show that this distance increases when the GAN is less accurate, and in this case,
    it is easier to detect deepfakes. In case of high-resolution image inputs, an
    extremely accurate GAN is required to generate fake images that are hard to detect
    by this method.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Deep Features-based Methods
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Face swapping has a number of compelling applications in video compositing,
    transfiguration in portraits, and especially in identity protection as it can
    replace faces in photographs by ones from a collection of stock images. However,
    it is also one of the techniques that cyber attackers employ to penetrate identification
    or authentication systems to gain illegitimate access. The use of deep learning
    such as CNN and GAN has made swapped face images more challenging for forensics
    models as it can preserve pose, facial expression and lighting of the photographs
    [[84](#bib.bib84)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 面孔交换在视频合成、肖像变形以及特别是在身份保护方面有许多引人注目的应用，因为它可以用库存图像中的面孔替换照片中的面孔。然而，它也是网络攻击者用来渗透身份识别或认证系统以获取非法访问的技术之一。深度学习的使用，如
    CNN 和 GAN，使得交换的面孔图像对取证模型来说更具挑战性，因为它可以保留照片的姿势、面部表情和光照 [[84](#bib.bib84)]。
- en: Hsu et al. [[85](#bib.bib85)] introduced a two-phase deep learning method for
    detection of deepfake images. The first phase is a feature extractor based on
    the common fake feature network (CFFN) where the Siamese network architecture
    presented in [[86](#bib.bib86)] is used. The CFFN encompasses several dense units
    with each unit including different numbers of dense blocks [[61](#bib.bib61)]
    to improve the representative capability for the input images. Discriminative
    features between the fake and real images are extracted through the CFFN learning
    process based on the use of pairwise information, which is the label of each pair
    of two input images. If the two images are of the same type, i.e., fake-fake or
    real-real, the pairwise label is $1$. In contrast, if they are of different types,
    i.e., fake-real, the pairwise label is $0$. The CFFN-based discriminative features
    are then fed to a neural network classifier to distinguish deceptive images from
    genuine. The proposed method is validated for both fake face and fake general
    image detection. On the one hand, the face dataset is obtained from CelebA [[87](#bib.bib87)],
    containing 10,177 identities and 202,599 aligned face images of various poses
    and background clutter. Five GAN variants are used to generate fake images with
    size of 64x64, including deep convolutional GAN (DCGAN) [[88](#bib.bib88)], Wasserstein
    GAN (WGAN) [[89](#bib.bib89)], WGAN with gradient penalty (WGAN-GP) [[90](#bib.bib90)],
    least squares GAN [[91](#bib.bib91)], and PGGAN [[62](#bib.bib62)]. A total of
    385,198 training images and 10,000 test images of both real and fake ones are
    obtained for validating the proposed method. On the other hand, the general dataset
    is extracted from the ILSVRC12 [[92](#bib.bib92)]. The large scale GAN training
    model for high fidelity natural image synthesis (BIGGAN) [[93](#bib.bib93)], self-attention
    GAN [[94](#bib.bib94)] and spectral normalization GAN [[95](#bib.bib95)] are used
    to generate fake images with size of 128x128\. The training set consists of 600,000
    fake and real images whilst the test set includes 10,000 images of both types.
    Experimental results show the superior performance of the proposed method against
    its competing methods such as those introduced in [[96](#bib.bib96), [97](#bib.bib97),
    [98](#bib.bib98), [99](#bib.bib99)].
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: Hsu 等人 [[85](#bib.bib85)] 提出了一个用于检测深度伪造图像的两阶段深度学习方法。第一阶段是基于常见伪造特征网络（CFFN）的特征提取器，其中使用了
    [[86](#bib.bib86)] 中提出的 Siamese 网络架构。CFFN 包含多个密集单元，每个单元包括不同数量的密集块 [[61](#bib.bib61)]，以提高对输入图像的表征能力。通过
    CFFN 学习过程，基于成对信息（即每对输入图像的标签）提取伪造图像和真实图像之间的判别特征。如果两幅图像类型相同，即伪造-伪造或真实-真实，则成对标签为
    $1$。相反，如果它们类型不同，即伪造-真实，则成对标签为 $0$。基于 CFFN 的判别特征随后被输入到神经网络分类器中，以区分欺骗性图像和真实图像。所提方法在伪造面孔和伪造一般图像检测中得到了验证。一方面，面孔数据集来自
    CelebA [[87](#bib.bib87)]，包含 10,177 个身份和 202,599 张不同姿势和背景杂乱的对齐面孔图像。使用了五种 GAN 变体生成
    64x64 尺寸的伪造图像，包括深度卷积 GAN (DCGAN) [[88](#bib.bib88)]、Wasserstein GAN (WGAN) [[89](#bib.bib89)]、带有梯度惩罚的
    WGAN (WGAN-GP) [[90](#bib.bib90)]、最小二乘 GAN [[91](#bib.bib91)] 和 PGGAN [[62](#bib.bib62)]。总共获得了
    385,198 张训练图像和 10,000 张真实与伪造图像用于验证所提方法。另一方面，通用数据集来自 ILSVRC12 [[92](#bib.bib92)]。大规模
    GAN 训练模型用于高保真自然图像合成 (BIGGAN) [[93](#bib.bib93)]、自注意力 GAN [[94](#bib.bib94)] 和谱归一化
    GAN [[95](#bib.bib95)] 用于生成 128x128 尺寸的伪造图像。训练集包括 600,000 张伪造和真实图像，而测试集包括 10,000
    张这两种类型的图像。实验结果显示，所提方法在性能上优于竞争方法，如 [[96](#bib.bib96)、[97](#bib.bib97)、[98](#bib.bib98)、[99](#bib.bib99)]
    中介绍的那些方法。
- en: 'Likewise, Guo et al. [[100](#bib.bib100)] proposed a CNN model, namely SCnet,
    to detect deepfake images, which are generated by the Glow-based facial forgery
    tool [[101](#bib.bib101)]. The fake images synthesized by the Glow model [[101](#bib.bib101)]
    have the facial expression maliciously tampered. These images are hyper-realistic
    with perfect visual qualities, but they still have subtle or noticeable manipulation
    traces, which are exploited by the SCnet. The SCnet is able to automatically learn
    high-level forensics features of image data thanks to a hierarchical feature extraction
    block, which is formed by stacking four convolutional layers. Each layer learns
    a new set of feature maps from the previous layer, with each convolutional operation
    is defined by:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，郭等人 [[100](#bib.bib100)] 提出了一个名为 SCnet 的 CNN 模型，用于检测由 Glow 基面部伪造工具 [[101](#bib.bib101)]
    生成的深伪图像。由 Glow 模型 [[101](#bib.bib101)] 合成的伪造图像具有恶意篡改的面部表情。这些图像高度逼真，视觉效果完美，但仍然有微妙或明显的操控痕迹，这些痕迹被
    SCnet 利用。得益于一个由四个卷积层堆叠形成的层次特征提取块，SCnet 能够自动学习图像数据的高级取证特征。每个层学习来自前一层的新特征图，每次卷积操作的定义为：
- en: '|  | $f_{j}^{(n)}=\sum_{i=1}^{i}f_{i}^{(n-1)}*\omega_{ij}^{(n)}+b_{j}^{(n)}$
    |  | (3) |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '|  | $f_{j}^{(n)}=\sum_{i=1}^{i}f_{i}^{(n-1)}*\omega_{ij}^{(n)}+b_{j}^{(n)}$
    |  | (3) |'
- en: where $f_{j}^{(n)}$ is the $j^{th}$ feature map of the $n^{th}$ layer, $\omega_{ij}^{(n)}$
    is the weight of the $i^{th}$ channel of the $j^{th}$ convolutional kernel in
    the $n^{th}$ layer, and $b_{j}^{(n)}$ is the bias term of the $j^{th}$ convolutional
    kernel in the $n^{th}$ layer. The proposed approach is evaluated using a dataset
    consisting of 321,378 face images, which are created by applying the Glow model
    [[101](#bib.bib101)] to the CelebA face image dataset [[87](#bib.bib87)]. Evaluation
    results show that the SCnet model obtains higher accuracy and better generalization
    than the Meso-4 model proposed in [[102](#bib.bib102)].
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $f_{j}^{(n)}$ 是第 $n^{th}$ 层的第 $j^{th}$ 特征图，$\omega_{ij}^{(n)}$ 是第 $n^{th}$
    层第 $j^{th}$ 卷积核的第 $i^{th}$ 通道的权重，$b_{j}^{(n)}$ 是第 $n^{th}$ 层第 $j^{th}$ 卷积核的偏置项。所提出的方法使用包含
    321,378 张面部图像的数据集进行评估，这些图像是通过将 Glow 模型 [[101](#bib.bib101)] 应用于 CelebA 面部图像数据集
    [[87](#bib.bib87)] 创建的。评估结果显示，SCnet 模型比 [[102](#bib.bib102)] 中提出的 Meso-4 模型具有更高的准确性和更好的泛化能力。
- en: '![Refer to caption](img/1429dcf5780882393df19011f7ad3557.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1429dcf5780882393df19011f7ad3557.png)'
- en: 'Figure 6: A two-step process for face manipulation detection where the preprocessing
    step aims to detect, crop and align faces on a sequence of frames and the second
    step distinguishes manipulated and authentic face images by combining convolutional
    neural network (CNN) and recurrent neural network (RNN) [[103](#bib.bib103)].'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一个面部操控检测的两步过程，其中预处理步骤旨在检测、裁剪和对齐一系列帧中的面部，第二步通过结合卷积神经网络（CNN）和递归神经网络（RNN）来区分操控过的面部图像和真实的面部图像
    [[103](#bib.bib103)]。
- en: Recently, Zhao et al. [[104](#bib.bib104)] proposed a method for deepfake detection
    using self-consistency of local source features, which are content-independent,
    spatially-local information of images. These features could come from either imaging
    pipelines, encoding methods or image synthesis approaches. The hypothesis is that
    a modified image would have different source features at different locations,
    while an original image will have the same source features across locations. These
    source features, represented in the form of down-sampled feature maps, are extracted
    by a CNN model using a special representation learning method called pairwise
    self-consistency learning. This learning method aims to penalize pairs of feature
    vectors that refer to locations from the same image for having a low cosine similarity
    score. At the same time, it also penalizes the pairs from different images for
    having a high similarity score. The learned feature maps are then fed to a classification
    method for deepfake detection. This proposed approach is evaluated on seven popular
    datasets, including FaceForensics++ [[105](#bib.bib105)], DeepfakeDetection [[106](#bib.bib106)],
    Celeb-DF-v1 & Celeb-DF-v2 [[107](#bib.bib107)], Deepfake Detection Challenge (DFDC)
    [[108](#bib.bib108)], DFDC Preview [[109](#bib.bib109)], and DeeperForensics-1.0
    [[110](#bib.bib110)]. Experimental results demonstrate that the proposed approach
    is superior to state-of-the-art methods. It however may have a limitation when
    dealing with fake images that are generated by methods that directly output the
    whole images whose source features are consistent across all positions within
    each image.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，赵等人[[104](#bib.bib104)] 提出了一个利用局部源特征自一致性进行深度伪造检测的方法，这些特征是图像的内容独立的空间局部信息。这些特征可以来自成像管道、编码方法或图像合成方法。假设是，修改过的图像在不同位置会有不同的源特征，而原始图像在各个位置的源特征是相同的。这些源特征以降采样特征图的形式表示，通过使用称为成对自一致性学习的特殊表示学习方法的CNN模型提取。该学习方法旨在惩罚来自同一图像的特征向量对的余弦相似度得分低，同时也惩罚来自不同图像的特征对的相似度得分高。然后将学习到的特征图输入到深度伪造检测分类方法中。该方法在七个流行的数据集上进行了评估，包括
    FaceForensics++ [[105](#bib.bib105)]、DeepfakeDetection [[106](#bib.bib106)]、Celeb-DF-v1
    & Celeb-DF-v2 [[107](#bib.bib107)]、深度伪造检测挑战（DFDC）[[108](#bib.bib108)]、DFDC 预览
    [[109](#bib.bib109)] 和 DeeperForensics-1.0 [[110](#bib.bib110)]。实验结果表明，该方法优于最先进的方法，但在处理由直接输出整个图像的方法生成的假图像时可能存在局限性，这些假图像的源特征在每个图像内的所有位置是一致的。
- en: 3.2 Fake Video Detection
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 假视频检测
- en: 'Most image detection methods cannot be used for videos because of the strong
    degradation of the frame data after video compression [[102](#bib.bib102)]. Furthermore,
    videos have temporal characteristics that are varied among sets of frames and
    they are thus challenging for methods designed to detect only still fake images.
    This subsection focuses on deepfake video detection methods and categorizes them
    into two smaller groups: methods that employ temporal features and those that
    explore visual artifacts within frames.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数图像检测方法不能用于视频，因为视频压缩后帧数据的强烈退化[[102](#bib.bib102)]。此外，视频具有时间特性，在帧组之间变化，因此对于仅设计用于检测静态假图像的方法来说，这些视频具有挑战性。本小节关注深度伪造视频检测方法，并将其分为两个较小的组：利用时间特征的方法和探索帧内视觉伪影的方法。
- en: 3.2.1 Temporal Features across Video Frames
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 视频帧中的时间特征
- en: 'Based on the observation that temporal coherence is not enforced effectively
    in the synthesis process of deepfakes, Sabir et al. [[103](#bib.bib103)] leveraged
    the use of spatio-temporal features of video streams to detect deepfakes. Video
    manipulation is carried out on a frame-by-frame basis so that low level artifacts
    produced by face manipulations are believed to further manifest themselves as
    temporal artifacts with inconsistencies across frames. A recurrent convolutional
    model (RCN) was proposed based on the integration of the convolutional network
    DenseNet [[61](#bib.bib61)] and the gated recurrent unit cells [[111](#bib.bib111)]
    to exploit temporal discrepancies across frames (see Fig. [6](#S3.F6 "Figure 6
    ‣ 3.1.2 Deep Features-based Methods ‣ 3.1 Fake Image Detection ‣ 3 Deepfake Detection
    ‣ Deep Learning for Deepfakes Creation and Detection: A Survey")). The proposed
    method is tested on the FaceForensics++ dataset, which includes 1,000 videos [[105](#bib.bib105)],
    and shows promising results.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 基于观察到在深伪合成过程中时间一致性未能有效强制实施的情况，Sabir 等人 [[103](#bib.bib103)] 利用视频流的时空特征来检测深伪。视频处理是逐帧进行的，因此由面部操作产生的低级伪影被认为会进一步表现为帧间不一致的时间伪影。基于卷积网络
    DenseNet [[61](#bib.bib61)] 和门控递归单元（GRU） [[111](#bib.bib111)] 的集成，提出了一种递归卷积模型（RCN），以利用帧间的时间差异（参见图
    [6](#S3.F6 "图 6 ‣ 3.1.2 基于深度特征的方法 ‣ 3.1 假图像检测 ‣ 3 深伪检测 ‣ 深度学习在深伪创建与检测中的应用综述")）。该方法在包括
    1,000 个视频的 FaceForensics++ 数据集上进行了测试 [[105](#bib.bib105)]，显示了有希望的结果。
- en: 'Likewise, Güera and Delp [[112](#bib.bib112)] highlighted that deepfake videos
    contain intra-frame inconsistencies and temporal inconsistencies between frames.
    They then proposed the temporal-aware pipeline method that uses CNN and long short
    term memory (LSTM) to detect deepfake videos. CNN is employed to extract frame-level
    features, which are then fed into the LSTM to create a temporal sequence descriptor.
    A fully-connected network is finally used for classifying doctored videos from
    real ones based on the sequence descriptor as illustrated in Fig. [7](#S3.F7 "Figure
    7 ‣ 3.2.1 Temporal Features across Video Frames ‣ 3.2 Fake Video Detection ‣ 3
    Deepfake Detection ‣ Deep Learning for Deepfakes Creation and Detection: A Survey").
    An accuracy of greater than 97% was obtained using a dataset of 600 videos, including
    300 deepfake videos collected from multiple video-hosting websites and 300 pristine
    videos randomly selected from the Hollywood human actions dataset in [[113](#bib.bib113)].'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，Güera 和 Delp [[112](#bib.bib112)] 强调了深伪视频中存在帧内不一致性和帧间时间不一致性。然后，他们提出了一种时间感知管道方法，该方法使用
    CNN 和长短期记忆（LSTM）来检测深伪视频。CNN 用于提取帧级特征，这些特征随后被输入到 LSTM 中以创建时间序列描述符。最后，使用全连接网络根据序列描述符对伪造视频和真实视频进行分类，如图
    [7](#S3.F7 "图 7 ‣ 3.2.1 视频帧间时间特征 ‣ 3.2 假视频检测 ‣ 3 深伪检测 ‣ 深度学习在深伪创建与检测中的应用综述") 所示。使用包含
    600 个视频的数据集（包括 300 个从多个视频托管网站收集的深伪视频和 300 个从 [[113](#bib.bib113)] 的好莱坞人类动作数据集中随机选择的原始视频），获得了超过
    97% 的准确率。
- en: '![Refer to caption](img/e01a1e6ea1cb5d8f433adf89204f0344.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e01a1e6ea1cb5d8f433adf89204f0344.png)'
- en: 'Figure 7: A deepfake detection method using convolutional neural network (CNN)
    and long short term memory (LSTM) to extract temporal features of a given video
    sequence, which are represented via the sequence descriptor. The detection network
    consisting of fully-connected layers is employed to take the sequence descriptor
    as input and calculate probabilities of the frame sequence belonging to either
    authentic or deepfake class [[112](#bib.bib112)].'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：一种使用卷积神经网络（CNN）和长短期记忆（LSTM）提取给定视频序列时间特征的深伪检测方法，这些特征通过序列描述符表示。检测网络由全连接层组成，用于将序列描述符作为输入并计算帧序列属于真实或深伪类别的概率
    [[112](#bib.bib112)]。
- en: On the other hand, the use of a physiological signal, eye blinking, to detect
    deepfakes was proposed in Li et al. [[114](#bib.bib114)] based on the observation
    that a person in deepfakes has a lot less frequent blinking than that in untampered
    videos. A healthy adult human would normally blink somewhere between 2 to 10 seconds,
    and each blink would take 0.1 and 0.4 seconds. Deepfake algorithms, however, often
    use face images available online for training, which normally show people with
    open eyes, i.e., very few images published on the internet show people with closed
    eyes. Thus, without having access to images of people blinking, deepfake algorithms
    do not have the capability to generate fake faces that can blink normally. In
    other words, blinking rates in deepfakes are much lower than those in normal videos.
    To discriminate real and fake videos, Li et al. [[114](#bib.bib114)] crop eye
    areas in the videos and distribute them into long-term recurrent convolutional
    networks (LRCN) [[115](#bib.bib115)] for dynamic state prediction. The LRCN consists
    of a feature extractor based on CNN, a sequence learning based on long short term
    memory (LSTM), and a state prediction based on a fully connected layer to predict
    probability of eye open and close state. The eye blinking shows strong temporal
    dependencies and thus the implementation of LSTM helps to capture these temporal
    patterns effectively.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Li等人提出了利用生理信号——眼睛眨动来检测深度伪造视频的方案[[114](#bib.bib114)]。这一方案基于观察到的事实，即深度伪造视频中的人眨眼频率远低于未被篡改的视频。健康的成年人通常每2到10秒眨一次眼，每次眨眼持续时间为0.1到0.4秒。然而，深度伪造算法通常使用在线获取的面部图像进行训练，这些图像通常显示的是睁开的眼睛，即互联网上很少有闭眼的图像。因此，由于没有闭眼的图像，深度伪造算法无法生成可以正常眨眼的伪造面孔。换句话说，深度伪造视频中的眨眼率远低于正常视频。为了区分真实和伪造视频，Li等人[[114](#bib.bib114)]将视频中的眼睛区域裁剪出来，并将其输入到长短期记忆网络（LRCN）[[115](#bib.bib115)]中进行动态状态预测。LRCN包括一个基于CNN的特征提取器，一个基于长短期记忆（LSTM）的序列学习模块，以及一个基于全连接层的状态预测模块，以预测眼睛开合的概率。眼睛眨动表现出强烈的时间依赖性，因此LSTM的实现有助于有效捕捉这些时间模式。
- en: Recently, Caldelli et al. [[116](#bib.bib116)] proposed the use of optical flow
    to gauge the information along the temporal axis of a frame sequence for video
    deepfake detection. The optical flow is a vector field calculated on two temporal-distinct
    frames of a video that can describe the movement of objects in a scene. The optical
    flow fields are expected to be different between synthetically created frames
    and naturally generated ones [[117](#bib.bib117)]. Unnatural movements of lips,
    eyes, or of the entire faces inserted into deepfake videos would introduce distinctive
    motion patterns when compared with pristine ones. Based on this assumption, features
    consisting of optical flow fields are fed into a CNN model for discriminating
    between deepfakes and original videos. More specifically, the ResNet50 architecture
    [[118](#bib.bib118)] is implemented as a CNN model for experiments. The results
    obtained using the FaceForensics++ dataset [[105](#bib.bib105)] show that this
    approach is comparable with state-of-the-art methods in terms of classification
    accuracy. A combination of this kind of feature with frame-based features is also
    experimented, which results in an improved deepfake detection performance. This
    demonstrates the usefulness of optical flow fields in capturing the inconsistencies
    on the temporal axis of video frames for deepfake detection.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Caldelli等人[[116](#bib.bib116)]提出了利用光流来衡量视频帧序列在时间轴上的信息，以检测视频深度伪造。光流是计算在两个时间上不同的帧上的向量场，能够描述场景中物体的运动。光流场在合成创建的帧和自然生成的帧之间应该有所不同[[117](#bib.bib117)]。与原始视频相比，插入到深度伪造视频中的嘴唇、眼睛或整个面部的非自然运动会引入独特的运动模式。基于这一假设，包含光流场的特征被输入到CNN模型中，用于区分深度伪造视频和原始视频。更具体地说，ResNet50架构[[118](#bib.bib118)]被作为CNN模型进行实验。使用FaceForensics++数据集[[105](#bib.bib105)]获得的结果表明，这种方法在分类准确性方面与最先进的方法相当。还实验了将这种特征与基于帧的特征相结合，结果提高了深度伪造检测性能。这表明光流场在捕捉视频帧时间轴上的不一致性方面非常有用。
- en: 3.2.2 Visual Artifacts within Video Frame
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 视频帧中的视觉伪影
- en: As can be noticed in the previous subsection, the methods using temporal patterns
    across video frames are mostly based on deep recurrent network models to detect
    deepfake videos. This subsection investigates the other approach that normally
    decomposes videos into frames and explores visual artifacts within single frames
    to obtain discriminant features. These features are then distributed into either
    a deep or shallow classifier to differentiate between fake and authentic videos.
    We thus group methods in this subsection based on the types of classifiers, i.e.
    either deep or shallow.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: Deep classifiers
  id: totrans-99
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deepfake videos are normally created with limited resolutions, which require
    an affine face warping approach (i.e., scaling, rotation and shearing) to match
    the configuration of the original ones. Because of the resolution inconsistency
    between the warped face area and the surrounding context, this process leaves
    artifacts that can be detected by CNN models such as VGG16 [[119](#bib.bib119)],
    ResNet50, ResNet101 and ResNet152 [[118](#bib.bib118)]. A deep learning method
    to detect deepfakes based on the artifacts observed during the face warping step
    of the deepfake generation algorithms was proposed in [[120](#bib.bib120)]. The
    proposed method is evaluated on two deepfake datasets, namely the UADFV and DeepfakeTIMIT.
    The UADFV dataset [[121](#bib.bib121)] contains 49 real videos and 49 fake videos
    with 32,752 frames in total. The DeepfakeTIMIT dataset [[69](#bib.bib69)] includes
    a set of low quality videos of 64 x 64 size and another set of high quality videos
    of 128 x 128 with totally 10,537 pristine images and 34,023 fabricated images
    extracted from 320 videos for each quality set. Performance of the proposed method
    is compared with other prevalent methods such as two deepfake detection MesoNet
    methods, i.e. Meso-4 and MesoInception-4 [[102](#bib.bib102)], HeadPose [[121](#bib.bib121)],
    and the face tampering detection method two-stream NN [[122](#bib.bib122)]. Advantage
    of the proposed method is that it needs not to generate deepfake videos as negative
    examples before training the detection models. Instead, the negative examples
    are generated dynamically by extracting the face region of the original image
    and aligning it into multiple scales before applying Gaussian blur to a scaled
    image of random pick and warping back to the original image. This reduces a large
    amount of time and computational resources compared to other methods, which require
    deepfakes are generated in advance.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 'Nguyen et al. [[123](#bib.bib123)] proposed the use of capsule networks for
    detecting manipulated images and videos. The capsule network was initially introduced
    to address limitations of CNNs when applied to inverse graphics tasks, which aim
    to find physical processes used to produce images of the world [[124](#bib.bib124)].
    The recent development of capsule network based on dynamic routing algorithm [[125](#bib.bib125)]
    demonstrates its ability to describe the hierarchical pose relationships between
    object parts. This development is employed as a component in a pipeline for detecting
    fabricated images and videos as demonstrated in Fig. [8](#S3.F8 "Figure 8 ‣ Deep
    classifiers ‣ 3.2.2 Visual Artifacts within Video Frame ‣ 3.2 Fake Video Detection
    ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes Creation and Detection: A
    Survey"). A dynamic routing algorithm is deployed to route the outputs of the
    three capsules to the output capsules through a number of iterations to separate
    between fake and real images. The method is evaluated through four datasets covering
    a wide range of forged image and video attacks. They include the well-known Idiap
    Research Institute replay-attack dataset [[126](#bib.bib126)], the deepfake face
    swapping dataset created by Afchar et al. [[102](#bib.bib102)], the facial reenactment
    FaceForensics dataset [[127](#bib.bib127)], produced by the Face2Face method [[52](#bib.bib52)],
    and the fully computer-generated image dataset generated by Rahmouni et al. [[128](#bib.bib128)].
    The proposed method yields the best performance compared to its competing methods
    in all of these datasets. This shows the potential of the capsule network in building
    a general detection system that can work effectively for various forged image
    and video attacks.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/87549fa482a980002ce51113a4973ba0.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Capsule network takes features obtained from the VGG-19 network [[119](#bib.bib119)]
    to distinguish fake images or videos from the real ones (top). The pre-processing
    step detects face region and scales it to the size of 128x128 before VGG-19 is
    used to extract latent features for the capsule network, which comprises three
    primary capsules and two output capsules, one for real and one for fake images
    (bottom). The statistical pooling constitutes an important part of capsule network
    that deals with forgery detection [[123](#bib.bib123)].'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: Shallow classifiers
  id: totrans-104
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deepfake detection methods mostly rely on the artifacts or inconsistency of
    intrinsic features between fake and real images or videos. Yang et al. [[121](#bib.bib121)]
    proposed a detection method by observing the differences between 3D head poses
    comprising head orientation and position, which are estimated based on 68 facial
    landmarks of the central face region. The 3D head poses are examined because there
    is a shortcoming in the deepfake face generation pipeline. The extracted features
    are fed into an SVM classifier to obtain the detection results. Experiments on
    two datasets show the great performance of the proposed approach against its competing
    methods. The first dataset, namely UADFV, consists of 49 deep fake videos and
    their respective real videos [[121](#bib.bib121)]. The second dataset comprises
    241 real images and 252 deep fake images, which is a subset of data used in the
    DARPA MediFor GAN Image/Video Challenge [[129](#bib.bib129)]. Likewise, a method
    to exploit artifacts of deepfakes and face manipulations based on visual features
    of eyes, teeth and facial contours was studied in [[130](#bib.bib130)]. The visual
    artifacts arise from lacking global consistency, wrong or imprecise estimation
    of the incident illumination, or imprecise estimation of the underlying geometry.
    For deepfakes detection, missing reflections and missing details in the eye and
    teeth areas are exploited as well as texture features extracted from the facial
    region based on facial landmarks. Accordingly, the eye feature vector, teeth feature
    vector and features extracted from the full-face crop are used. After extracting
    the features, two classifiers including logistic regression and small neural network
    are employed to classify the deepfakes from real videos. Experiments carried out
    on a video dataset downloaded from YouTube show the best result of 0.851 in terms
    of the area under the receiver operating characteristics curve. The proposed method
    however has a disadvantage that requires images meeting certain prerequisite such
    as open eyes or visual teeth.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: The use of photo response non uniformity (PRNU) analysis was proposed in [[131](#bib.bib131)]
    to detect deepfakes from authentic ones. PRNU is a component of sensor pattern
    noise, which is attributed to the manufacturing imperfection of silicon wafers
    and the inconsistent sensitivity of pixels to light because of the variation of
    the physical characteristics of the silicon wafers. The PRNU analysis is widely
    used in image forensics [[132](#bib.bib132), [133](#bib.bib133), [134](#bib.bib134),
    [135](#bib.bib135), [136](#bib.bib136)] and advocated to use in [[131](#bib.bib131)]
    because the swapped face is supposed to alter the local PRNU pattern in the facial
    area of video frames. The videos are converted into frames, which are cropped
    to the questioned facial region. The cropped frames are then separated sequentially
    into eight groups where an average PRNU pattern is computed for each group. Normalised
    cross correlation scores are calculated for comparisons of PRNU patterns among
    these groups. A test dataset was created, consisting of 10 authentic videos and
    16 manipulated videos, where the fake videos were produced from the genuine ones
    by the DeepFaceLab tool [[38](#bib.bib38)]. The analysis shows a significant statistical
    difference in terms of mean normalised cross correlation scores between deepfakes
    and the genuine. This analysis therefore suggests that PRNU has a potential in
    deepfake detection although a larger dataset would need to be tested.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: When seeing a video or image with suspicion, users normally want to search for
    its origin. However, there is currently no feasibility for such a tool. Hasan
    and Salah [[137](#bib.bib137)] proposed the use of blockchain and smart contracts
    to help users detect deepfake videos based on the assumption that videos are only
    real when their sources are traceable. Each video is associated with a smart contract
    that links to its parent video and each parent video has a link to its child in
    a hierarchical structure. Through this chain, users can credibly trace back to
    the original smart contract associated with pristine video even if the video has
    been copied multiple times. An important attribute of the smart contract is the
    unique hashes of the interplanetary file system, which is used to store video
    and its metadata in a decentralized and content-addressable manner [[138](#bib.bib138)].
    The smart contract’s key features and functionalities are tested against several
    common security challenges such as distributed denial of services, replay and
    man in the middle attacks to ensure the solution meeting security requirements.
    This approach is generic, and it can be extended to other types of digital content,
    e.g., images, audios and manuscripts.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Summary of prominent deepfake detection methods'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: '| Methods | Classifiers/ Techniques | Key Features | Dealing with | Datasets
    Used |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
- en: '| Eye blinking [[114](#bib.bib114)] | LRCN | - Use LRCN to learn the temporal
    patterns of eye blinking. - Based on the observation that blinking frequency of
    deepfakes is much smaller than normal. | Videos | Consist of 49 interview and
    presentation videos, and their corresponding generated deepfakes. |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
- en: '| Intra-frame and temporal inconsistencies [[112](#bib.bib112)] | CNN and LSTM
    | CNN is employed to extract frame-level features, which are distributed to LSTM
    to construct sequence descriptor useful for classification. | Videos | A collection
    of 600 videos obtained from multiple websites. |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
- en: '| Using face warping artifacts [[120](#bib.bib120)] | VGG16 [[119](#bib.bib119)],
    ResNet models [[118](#bib.bib118)] | Artifacts are discovered using CNN models
    based on resolution inconsistency between the warped face area and the surrounding
    context. | Videos | - UADFV [[121](#bib.bib121)], containing 49 real videos and
    49 fake videos with 32752 frames in total. - DeepfakeTIMIT [[69](#bib.bib69)]
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
- en: '| MesoNet [[102](#bib.bib102)] | CNN | - Two deep networks, i.e. Meso-4 and
    MesoInception-4 are introduced to examine deepfake videos at the mesoscopic analysis
    level. - Accuracy obtained on deepfake and FaceForensics datasets are 98% and
    95% respectively. | Videos | Two datasets: deepfake one constituted from online
    videos and the FaceForensics one created by the Face2Face approach [[52](#bib.bib52)].
    |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
- en: '| Eye, teach and facial texture [[130](#bib.bib130)] | Logistic regression
    and neural network (NN) | - Exploit facial texture differences, and missing reflections
    and details in eye and teeth areas of deepfakes. - Logistic regression and NN
    are used for classifying. | Videos | A video dataset downloaded from YouTube.
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
- en: '| Spatio-temporal features with RCN [[103](#bib.bib103)] | RCN | Temporal discrepancies
    across frames are explored using RCN that integrates convolutional network DenseNet
    [[61](#bib.bib61)] and the gated recurrent unit cells [[111](#bib.bib111)] | Videos
    | FaceForensics++ dataset, including 1,000 videos [[105](#bib.bib105)]. |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
- en: '| Spatio-temporal features with LSTM [[139](#bib.bib139)] | Convolutional bidirectional
    recurrent LSTM network | - An XceptionNet CNN is used for facial feature extraction
    while audio embeddings are obtained by stacking multiple convolution modules.
    - Two loss functions, i.e. cross-entropy and Kullback-Leibler divergence, are
    used. | Videos | FaceForensics++ [[105](#bib.bib105)] and Celeb-DF (5,639 deepfake
    videos) [[107](#bib.bib107)] datasets and the ASVSpoof 2019 Logical Access audio
    dataset [[140](#bib.bib140)]. |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
- en: '| Analysis of PRNU [[131](#bib.bib131)] | PRNU | - Analysis of noise patterns
    of light sensitive sensors of digital cameras due to their factory defects. -
    Explore the differences of PRNU patterns between the authentic and deepfake videos
    because face swapping is believed to alter the local PRNU patterns. | Videos |
    Created by the authors, including 10 authentic and 16 deepfake videos using DeepFaceLab
    [[38](#bib.bib38)]. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| Phoneme-viseme mismatches [[141](#bib.bib141)] | CNN | - Exploit the mismatches
    between the dynamics of the mouth shape, i.e. visemes, with a spoken phoneme.
    - Focus on sounds associated with the M, B and P phonemes as they require complete
    mouth closure while deepfakes often incorrectly synthesize it. | Videos | Four
    in-the-wild lip-sync deepfakes from Instagram and YouTube (www.instagram.com/bill_posters_uk
    and youtu.be/VWMEDacz3L4) and others are created using synthesis techniques, i.e.
    Audio-to-Video (A2V) [[68](#bib.bib68)] and Text-to-Video (T2V) [[142](#bib.bib142)].
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| Using attribution-based confidence (ABC) metric [[143](#bib.bib143)] | ResNet50
    model [[118](#bib.bib118)], pre-trained on VGGFace2 [[144](#bib.bib144)] | - The
    ABC metric [[145](#bib.bib145)] is used to detect deepfake videos without accessing
    to training data. - ABC values obtained for original videos are greater than 0.94
    while those of deepfakes have low ABC values. | Videos | VidTIMIT and two other
    original datasets obtained from the COHFACE (https://www.idiap.ch/dataset/cohface)
    and from YouTube. datasets from COHFACE [[146](#bib.bib146)] and YouTube are used
    to generate two deepfake datasets by commercial website https://deepfakesweb.com
    and another deepfake dataset is DeepfakeTIMIT [[147](#bib.bib147)]. |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '| Using appearance and behaviour [[148](#bib.bib148)] | Rules based on facial
    and behavioural features. | Temporal, behavioral biometric based on facial expressions
    and head movements are learned using ResNet-101 [[118](#bib.bib118)] while static
    facial biometric is obtained using VGG [[65](#bib.bib65)]. | Videos | The world
    leaders dataset [[1](#bib.bib1)], FaceForensics++ [[105](#bib.bib105)], Google/Jigsaw
    deepfake detection dataset [[106](#bib.bib106)], DFDC [[109](#bib.bib109)] and
    Celeb-DF [[107](#bib.bib107)]. |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| FakeCatcher [[149](#bib.bib149)] | CNN | Extract biological signals in portrait
    videos and use them as an implicit descriptor of authenticity because they are
    not spatially and temporally well-preserved in deepfakes. | Videos | UADFV [[121](#bib.bib121)],
    FaceForensics [[127](#bib.bib127)], FaceForensics++ [[105](#bib.bib105)], Celeb-DF
    [[107](#bib.bib107)], and a new dataset of 142 videos, independent of the generative
    model, resolution, compression, content, and context. |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: '| Emotion audio-visual affective cues [[150](#bib.bib150)] | Siamese network
    [[86](#bib.bib86)] | Modality and emotion embedding vectors for the face and speech
    are extracted for deepfake detection. | Videos | DeepfakeTIMIT [[147](#bib.bib147)]
    and DFDC [[109](#bib.bib109)]. |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| Head poses [[121](#bib.bib121)] | SVM | - Features are extracted using 68
    landmarks of the face region. - Use SVM to classify using the extracted features.
    | Videos/ Images | - UADFV consists of 49 deep fake videos and their respective
    real videos. - 241 real images and 252 deep fake images from DARPA MediFor GAN
    Image/Video Challenge. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: '| Capsule-forensics [[123](#bib.bib123)] | Capsule networks | - Latent features
    extracted by VGG-19 network [[119](#bib.bib119)] are fed into the capsule network
    for classification. - A dynamic routing algorithm [[125](#bib.bib125)] is used
    to route the outputs of three convolutional capsules to two output capsules, one
    for fake and another for real images, through a number of iterations. | Videos/
    Images | Four datasets: the Idiap Research Institute replay-attack [[126](#bib.bib126)],
    deepfake face swapping by [[102](#bib.bib102)], facial reenactment FaceForensics
    [[127](#bib.bib127)], and fully computer-generated image set using [[128](#bib.bib128)].
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
- en: '| Methods | Classifiers/ Techniques | Key Features | Dealing with | Datasets
    Used |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: '| Preprocessing combined with deep network [[74](#bib.bib74)] | DCGAN, WGAN-GP
    and PGGAN. | - Enhance generalization ability of deep learning models to detect
    GAN generated images. - Remove low level features of fake images.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: '- Force deep networks to focus more on pixel level similarity between fake
    and real images to improve generalization ability. | Images | - Real dataset:
    CelebA-HQ [[62](#bib.bib62)], including high quality face images of 1024x1024
    resolution. - Fake datasets: generated by DCGAN [[88](#bib.bib88)], WGAN-GP [[90](#bib.bib90)]
    and PGGAN [[62](#bib.bib62)]. |'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
- en: '| Analyzing convolutional traces [[151](#bib.bib151)] | KNN, SVM, and linear
    discriminant analysis (LDA) | Using expectation-maximization algorithm to extract
    local features pertaining to convolutional generative process of GAN-based image
    deepfake generators. | Images | Authentic images from CelebA and corresponding
    deepfakes are created by five different GANs (group-wise deep whitening-and-coloring
    transformation GDWCT [[152](#bib.bib152)], StarGAN [[153](#bib.bib153)], AttGAN
    [[154](#bib.bib154)], StyleGAN [[51](#bib.bib51)], StyleGAN2 [[155](#bib.bib155)]).
    |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
- en: '| Bag of words and shallow classifiers [[78](#bib.bib78)] | SVM, RF, MLP |
    Extract discriminant features using bag of words method and feed these features
    into SVM, RF and MLP for binary classification: innocent vs fabricated. | Images
    | The well-known LFW face database [[156](#bib.bib156)], containing 13,223 images
    with resolution of 250x250. |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
- en: '| Pairwise learning [[85](#bib.bib85)] | CNN concatenated to CFFN | Two-phase
    procedure: feature extraction using CFFN based on the Siamese network architecture
    [[86](#bib.bib86)] and classification using CNN. | Images | - Face images: real
    ones from CelebA [[87](#bib.bib87)], and fake ones generated by DCGAN [[88](#bib.bib88)],
    WGAN [[89](#bib.bib89)], WGAN-GP [[90](#bib.bib90)], least squares GAN [[91](#bib.bib91)],
    and PGGAN [[62](#bib.bib62)]. - General images: real ones from ILSVRC12 [[92](#bib.bib92)],
    and fake ones generated by BIGGAN [[93](#bib.bib93)], self-attention GAN [[94](#bib.bib94)]
    and spectral normalization GAN [[95](#bib.bib95)]. |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
- en: '| Defenses against adversarial perturbations in deepfakes [[157](#bib.bib157)]
    | VGG [[65](#bib.bib65)] and ResNet [[118](#bib.bib118)] | - Introduce adversarial
    perturbations to enhance deepfakes and fool deepfake detectors. - Improve accuracy
    of deepfake detectors using Lipschitz regularization and deep image prior techniques.
    | Images | 5,000 real images from CelebA [[87](#bib.bib87)] and 5,000 fake images
    created by the “Few-Shot Face Translation GAN” method [[158](#bib.bib158)]. |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
- en: '| Face X-ray [[159](#bib.bib159)] | CNN | - Try to locate the blending boundary
    between the target and original faces instead of capturing the synthesized artifacts
    of specific manipulations. - Can be trained without fake images. | Images | FaceForensics++
    [[105](#bib.bib105)], DeepfakeDetection (DFD) [[106](#bib.bib106)], DFDC [[109](#bib.bib109)]
    and Celeb-DF [[107](#bib.bib107)]. |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
- en: '| Using common artifacts of CNN-generated images [[160](#bib.bib160)] | ResNet-50
    [[118](#bib.bib118)] pre-trained with ImageNet [[92](#bib.bib92)] | Train the
    classifier using a large number of fake images generated by a high-performing
    unconditional GAN model, i.e., PGGAN [[62](#bib.bib62)] and evaluate how well
    the classifier generalizes to other CNN-synthesized images. | Images | A new dataset
    of CNN-generated images, namely ForenSynths, consisting of synthesized images
    from 11 models such as StyleGAN [[51](#bib.bib51)], super-resolution methods [[161](#bib.bib161)]
    and FaceForensics++ [[105](#bib.bib105)]. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
- en: '| Using convolutional traces on GAN-based images [[162](#bib.bib162)] | KNN,
    SVM, and LDA | Training the expectation-maximization algorithm [[163](#bib.bib163)]
    to detect and extract discriminative features via a fingerprint that represents
    the convolutional traces left by GANs during image generation. | Images | A dataset
    of images generated by ten GAN models, including CycleGAN [[164](#bib.bib164)],
    StarGAN [[153](#bib.bib153)], AttGAN [[154](#bib.bib154)], GDWCT [[152](#bib.bib152)],
    StyleGAN [[51](#bib.bib51)], StyleGAN2 [[155](#bib.bib155)], PGGAN [[62](#bib.bib62)],
    FaceForensics++ [[105](#bib.bib105)], IMLE [[165](#bib.bib165)], and SPADE [[42](#bib.bib42)].
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
- en: '| Using deep features extracted by CNN [[100](#bib.bib100)] | A new CNN model,
    namely SCnet | The CNN-based SCnet is able to automatically learn high-level forensics
    features of image data thanks to a hierarchical feature extraction block, which
    is formed by stacking four convolutional layers. | Images | A dataset of 321,378
    face images, created by applying the Glow model [[101](#bib.bib101)] to the CelebA
    face image dataset [[87](#bib.bib87)]. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
- en: 4 Discussions and Future Research Directions
  id: totrans-136
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the support of deep learning, deepfakes can be created easier than ever
    before. The spread of these fake contents is also quicker thanks to the development
    of social media platforms [[166](#bib.bib166)]. Sometimes deepfakes do not need
    to be spread to massive audience to cause detrimental effects. People who create
    deepfakes with malicious purpose only need to deliver them to target audiences
    as part of their sabotage strategy without using social media. For example, this
    approach can be utilized by intelligence services trying to influence decisions
    made by important people such as politicians, leading to national and international
    security threats [[167](#bib.bib167)]. Catching the deepfake alarming problem,
    research community has focused on developing deepfake detection algorithms and
    numerous results have been reported. This paper has reviewed the state-of-the-art
    methods and a summary of typical approaches is provided in Table [2](#S3.T2 "Table
    2 ‣ Shallow classifiers ‣ 3.2.2 Visual Artifacts within Video Frame ‣ 3.2 Fake
    Video Detection ‣ 3 Deepfake Detection ‣ Deep Learning for Deepfakes Creation
    and Detection: A Survey"). It is noticeable that a battle between those who use
    advanced machine learning to create deepfakes with those who make effort to detect
    deepfakes is growing.'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: Deepfakes’ quality has been increasing and the performance of detection methods
    needs to be improved accordingly. The inspiration is that what AI has broken can
    be fixed by AI as well [[168](#bib.bib168)]. Detection methods are still in their
    early stage and various methods have been proposed and evaluated but using fragmented
    datasets. An approach to improve performance of detection methods is to create
    a growing updated benchmark dataset of deepfakes to validate the ongoing development
    of detection methods. This will facilitate the training process of detection models,
    especially those based on deep learning, which requires a large training set [[108](#bib.bib108)].
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: Improving performance of deepfake detection methods is important, especially
    in cross-forgery and cross-dataset scenarios. Most detection models are designed
    and evaluated in the same-forgery and in-dataset experiments, which do not ensure
    their generalization capability. Some previous studies have addressed this issue,
    e.g., in [[160](#bib.bib160), [116](#bib.bib116), [104](#bib.bib104), [169](#bib.bib169),
    [170](#bib.bib170)], but more work needs to be done in this direction. A model
    trained on a specific forgery needs to be able to work against another unknown
    one because potential deepfake types are not normally known in the real-world
    scenarios. Likewise, current detection methods mostly focus on drawbacks of the
    deepfake generation pipelines, i.e., finding weakness of the competitors to attack
    them. This kind of information and knowledge is not always available in adversarial
    environments where attackers commonly attempt not to reveal such deepfake creation
    technologies. Recent works on adversarial perturbation attacks to fool DNN-based
    detectors make the deepfake detection task more difficult [[157](#bib.bib157),
    [171](#bib.bib171), [172](#bib.bib172), [173](#bib.bib173), [174](#bib.bib174)].
    These are real challenges for detection method development and a future study
    needs to focus on introducing more robust, scalable and generalizable methods.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: Another research direction is to integrate detection methods into distribution
    platforms such as social media to increase its effectiveness in dealing with the
    widespread impact of deepfakes. The screening or filtering mechanism using effective
    detection methods can be implemented on these platforms to ease the deepfakes
    detection [[167](#bib.bib167)]. Legal requirements can be made for tech companies
    who own these platforms to remove deepfakes quickly to reduce its impacts. In
    addition, watermarking tools can also be integrated into devices that people use
    to make digital contents to create immutable metadata for storing originality
    details such as time and location of multimedia contents as well as their untampered
    attestment [[167](#bib.bib167)]. This integration is difficult to implement but
    a solution for this could be the use of the disruptive blockchain technology.
    The blockchain has been used effectively in many areas and there are very few
    studies so far addressing the deepfake detection problems based on this technology.
    As it can create a chain of unique unchangeable blocks of metadata, it is a great
    tool for digital provenance solution. The integration of blockchain technologies
    to this problem has demonstrated certain results [[137](#bib.bib137)] but this
    research direction is far from mature.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: Using detection methods to spot deepfakes is crucial, but understanding the
    real intent of people publishing deepfakes is even more important. This requires
    the judgement of users based on social context in which deepfake is discovered,
    e.g. who distributed it and what they said about it [[175](#bib.bib175)]. This
    is critical as deepfakes are getting more and more photorealistic and it is highly
    anticipated that detection software will be lagging behind deepfake creation technology.
    A study on social context of deepfakes to assist users in such judgement is thus
    worth performing.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: Videos and photographics have been widely used as evidences in police investigation
    and justice cases. They may be introduced as evidences in a court of law by digital
    media forensics experts who have background in computer or law enforcement and
    experience in collecting, examining and analysing digital information. The development
    of machine learning and AI technologies might have been used to modify these digital
    contents and thus the experts’ opinions may not be enough to authenticate these
    evidences because even experts are unable to discern manipulated contents. This
    aspect needs to take into account in courtrooms nowadays when images and videos
    are used as evidences to convict perpetrators because of the existence of a wide
    range of digital manipulation methods [[176](#bib.bib176)]. The digital media
    forensics results therefore must be proved to be valid and reliable before they
    can be used in courts. This requires careful documentation for each step of the
    forensics process and how the results are reached. Machine learning and AI algorithms
    can be used to support the determination of the authenticity of digital media
    and have obtained accurate and reliable results, e.g., [[177](#bib.bib177), [178](#bib.bib178)],
    but most of these algorithms are unexplainable. This creates a huge hurdle for
    the applications of AI in forensics problems because not only the forensics experts
    oftentimes do not have expertise in computer algorithms, but the computer professionals
    also cannot explain the results properly as most of these algorithms are black
    box models [[179](#bib.bib179)]. This is more critical as the most recent models
    with the most accurate results are based on deep learning methods consisting of
    many neural network parameters. Researchers have recently attempted to create
    white box and explainable detection methods. An example is the approach proposed
    by Giudice et al. [[180](#bib.bib180)] in which they use discrete cosine transform
    statistics to detect so-called specific GAN frequencies to differentiate between
    real images and deepfakes. Through the analysis of particular frequency statistics,
    that method can be used to mathematically explain whether a multimedia content
    is a deepfake and why it is. More research must be conducted in this area and
    explainable AI in computer vision therefore is a research direction that is needed
    to promote and utilize the advances and advantages of AI and machine learning
    in digital media forensics.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusions
  id: totrans-143
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deepfakes have begun to erode trust of people in media contents as seeing them
    is no longer commensurate with believing in them. They could cause distress and
    negative effects to those targeted, heighten disinformation and hate speech, and
    even could stimulate political tension, inflame the public, violence or war. This
    is especially critical nowadays as the technologies for creating deepfakes are
    increasingly approachable and social media platforms can spread those fake contents
    quickly. This survey provides a timely overview of deepfake creation and detection
    methods and presents a broad discussion on challenges, potential trends, and future
    directions in this area. This study therefore will be valuable for the artificial
    intelligence research community to develop effective methods for tackling deepfakes.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Declaration of Competing Interest
  id: totrans-145
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Authors declare no conflict of interest.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Agarwal et al. [2019] Shruti Agarwal, Hany Farid, Yuming Gu, Mingming He, Koki
    Nagano, and Hao Li. Protecting world leaders against deep fakes. In *Computer
    Vision and Pattern Recognition Workshops*, volume 1, pages 38–45, 2019.
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. [2008] Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine
    Manzagol. Extracting and composing robust features with denoising autoencoders.
    In *Proceedings of the 25th International Conference on Machine learning*, pages
    1096–1103, 2008.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma and Welling [2013] Diederik P Kingma and Max Welling. Auto-encoding variational
    Bayes. *arXiv preprint arXiv:1312.6114*, 2013.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. [2014] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing
    Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative
    adversarial nets. *Advances in Neural Information Processing Systems*, 27:2672–2680,
    2014.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Makhzani et al. [2015] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian
    Goodfellow, and Brendan Frey. Adversarial autoencoders. *arXiv preprint arXiv:1511.05644*,
    2015.
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tewari et al. [2018] Ayush Tewari, Michael Zollhoefer, Florian Bernard, Pablo
    Garrido, Hyeongwoo Kim, Patrick Perez, and Christian Theobalt. High-fidelity monocular
    face reconstruction based on an unsupervised model-based face autoencoder. *IEEE
    Transactions on Pattern Analysis and Machine Intelligence*, 42(2):357–370, 2018.
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. [2021] Jiacheng Lin, Yang Li, and Guanci Yang. FPGAN: Face de-identification
    method with generative adversarial networks for social robots. *Neural Networks*,
    133:132–147, 2021.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2021] Ming-Yu Liu, Xun Huang, Jiahui Yu, Ting-Chun Wang, and Arun
    Mallya. Generative adversarial networks for image and video synthesis: Algorithms
    and applications. *Proceedings of the IEEE*, 109(5):839–862, 2021.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lyu [2018] Siwei Lyu. Detecting ’deepfake’ videos in the blink of an eye. [http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072](http://theconversation.com/detecting-deepfake-videos-in-the-blink-of-an-eye-101072),
    August 2018.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bloomberg [2018] Bloomberg. How faking videos became easy and why that’s so
    scary. [https://fortune.com/2018/09/11/deep-fakes-obama-video/](https://fortune.com/2018/09/11/deep-fakes-obama-video/),
    September 2018.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chesney and Citron [2019] Robert Chesney and Danielle Citron. Deepfakes and
    the new disinformation war: The coming age of post-truth geopolitics. *Foreign
    Affairs*, 98:147, 2019.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hwang [2020] T. Hwang. Deepfakes: A grounded threat assessment. Technical report,
    Centre for Security and Emerging Technologies, Georgetown University, 2020.'
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou and Zafarani [2020] Xinyi Zhou and Reza Zafarani. A survey of fake news:
    Fundamental theories, detection methods, and opportunities. *ACM Computing Surveys
    (CSUR)*, 53(5):1–40, 2020.'
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kaliyar et al. [2021] Rohit Kumar Kaliyar, Anurag Goswami, and Pratik Narang.
    Deepfake: improving fake news detection using tensor decomposition-based deep
    neural network. *The Journal of Supercomputing*, 77(2):1015–1037, 2021.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guo et al. [2020] Bin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu.
    The future of false information detection on social media: New perspectives and
    trends. *ACM Computing Surveys (CSUR)*, 53(4):1–36, 2020.'
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tucker [2019] Patrick Tucker. The newest AI-enabled weapon: ‘deep-faking’ photos
    of the earth. [https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/](https://www.defenseone.com/technology/2019/03/next-phase-ai-deep-faking-whole-world-and-china-ahead/155944/),
    March 2019.'
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fish [2019] T Fish. Deep fakes: AI-manipulated media will be ‘weaponised’ to
    trick military. [https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china](https://www.express.co.uk/news/science/1109783/deep-fakes-ai-artificial-intelligence-photos-video-weaponised-china),
    April 2019.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marr [2019] B Marr. The best (and scariest) examples of AI-enabled deepfakes.
    [https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/](https://www.forbes.com/sites/bernardmarr/2019/07/22/the-best-and-scariest-examples-of-ai-enabled-deepfakes/),
    July 2019.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mirsky and Lee [2021] Yisroel Mirsky and Wenke Lee. The creation and detection
    of deepfakes: A survey. *ACM Computing Surveys (CSUR)*, 54(1):1–41, 2021.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Verdoliva [2020] Luisa Verdoliva. Media forensics and deepfakes: an overview.
    *IEEE Journal of Selected Topics in Signal Processing*, 14(5):910–932, 2020.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zakharov et al. [2019] Egor Zakharov, Aliaksandra Shysheya, Egor Burkov, and
    Victor Lempitsky. Few-shot adversarial learning of realistic neural talking head
    models. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    pages 9459–9468, 2019.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Damiani [2019] J Damiani. A voice deepfake was used to scam a ceo out of $243,000.
    [https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/](https://www.forbes.com/sites/jessedamiani/2019/09/03/a-voice-deepfake-was-used-to-scam-a-ceo-out-of-243000/),
    September 2019.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Samuel [2019] S Samuel. A guy made a deepfake app to turn photos of women into
    nudes. it didn’t go well. [https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn](https://www.vox.com/2019/6/27/18761639/ai-deepfake-deepnude-app-nude-women-porn),
    June 2019.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Guardian [2019] The Guardian. Chinese deepfake app Zao sparks privacy row
    after going viral. [https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral](https://www.theguardian.com/technology/2019/sep/02/chinese-face-swap-app-zao-triggers-privacy-fears-viral),
    September 2019.
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lyu [2020] Siwei Lyu. Deepfake detection: Current challenges and next steps.
    In *IEEE International Conference on Multimedia & Expo Workshops (ICMEW)*, pages
    1–6\. IEEE, 2020.'
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guarnera et al. [2020a] Luca Guarnera, Oliver Giudice, Cristina Nastasi, and
    Sebastiano Battiato. Preliminary forensics analysis of deepfake images. In *AEIT
    International Annual Conference (AEIT)*, pages 1–6. IEEE, 2020a.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jafar et al. [2020] Mousa Tayseer Jafar, Mohammad Ababneh, Mohammad Al-Zoube,
    and Ammar Elhassan. Forensics and analysis of deepfake videos. In *The 11th International
    Conference on Information and Communication Systems (ICICS)*, pages 053–058\.
    IEEE, 2020.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trinh et al. [2021] Loc Trinh, Michael Tsang, Sirisha Rambhatla, and Yan Liu.
    Interpretable and trustworthy deepfake detection via dynamic prototypes. In *Proceedings
    of the IEEE/CVF Winter Conference on Applications of Computer Vision*, pages 1973–1983,
    2021.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Younus and Hasan [2020] Mohammed Akram Younus and Taha Mohammed Hasan. Effective
    and fast deepfake detection method based on haar wavelet transform. In *International
    Conference on Computer Science and Software Engineering (CSASE)*, pages 186–190\.
    IEEE, 2020.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turek [2019] M Turek. Media Forensics (MediFor). [https://www.darpa.mil/program/media-forensics](https://www.darpa.mil/program/media-forensics),
    January 2019.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schroepfer [2019] M Schroepfer. Creating a data set and a challenge for deepfakes.
    [https://ai.facebook.com/blog/deepfake-detection-challenge](https://ai.facebook.com/blog/deepfake-detection-challenge),
    September 2019.
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tolosana et al. [2020] Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez,
    Aythami Morales, and Javier Ortega-Garcia. Deepfakes and beyond: A survey of face
    manipulation and fake detection. *Information Fusion*, 64:131–148, 2020.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Punnappurath and Brown [2019] Abhijith Punnappurath and Michael S Brown. Learning
    raw image reconstruction-aware deep image compressors. *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, 42(4):1013–1019, 2019.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. [2019] Zhengxue Cheng, Heming Sun, Masaru Takeuchi, and Jiro Katto.
    Energy compaction-based image compression using convolutional autoencoder. *IEEE
    Transactions on Multimedia*, 22(4):860–873, 2019.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chorowski et al. [2019] Jan Chorowski, Ron J Weiss, Samy Bengio, and Aäron van den
    Oord. Unsupervised speech representation learning using WaveNet autoencoders.
    *IEEE/ACM Transactions on Audio, Speech, and Language Processing*, 27(12):2041–2053,
    2019.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Faceswap: Deepfakes software for all. [https://github.com/deepfakes/faceswap](https://github.com/deepfakes/faceswap).'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] FakeApp 2.2.0. [https://www.malavida.com/en/soft/fakeapp/](https://www.malavida.com/en/soft/fakeapp/).'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dee [a] DeepFaceLab. [https://github.com/iperov/DeepFaceLab](https://github.com/iperov/DeepFaceLab),
    a.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] DFaker. [https://github.com/dfaker/df](https://github.com/dfaker/df).'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dee [b] DeepFake_tf: Deepfake based on tensorflow. [https://github.com/StromWine/DeepFake_tf](https://github.com/StromWine/DeepFake_tf),
    b.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019] Ming-Yu Liu, Xun Huang, Arun Mallya, Tero Karras, Timo Aila,
    Jaakko Lehtinen, and Jan Kautz. Few-shot unsupervised image-to-image translation.
    In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    pages 10551–10560, 2019.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Park et al. [2019] Taesung Park, Ming-Yu Liu, Ting-Chun Wang, and Jun-Yan Zhu.
    Semantic image synthesis with spatially-adaptive normalization. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    2337–2346, 2019.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] DeepFaceLab: Explained and usage tutorial. [https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial](https://mrdeepfakes.com/forums/thread-deepfacelab-explained-and-usage-tutorial).'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] DSSIM. [https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py](https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/dssim.py).'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lattas et al. [2020] Alexandros Lattas, Stylianos Moschoglou, Baris Gecer,
    Stylianos Ploumpis, Vasileios Triantafyllou, Abhijeet Ghosh, and Stefanos Zafeiriou.
    AvatarMe: Realistically renderable 3D facial reconstruction “in-the-wild”. In
    *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 760–769, 2020.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ha et al. [2020] Sungjoo Ha, Martin Kersner, Beomsu Kim, Seokjun Seo, and Dongyoung
    Kim. Marionette: Few-shot face reenactment preserving identity of unseen targets.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, volume 34,
    pages 10893–10900, 2020.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng et al. [2020] Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, and Xin Tong.
    Disentangled and controllable face image generation via 3D imitative-contrastive
    learning. In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition*, pages 5154–5163, 2020.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tewari et al. [2020] Ayush Tewari, Mohamed Elgharib, Gaurav Bharaj, Florian
    Bernard, Hans-Peter Seidel, Patrick Pérez, Michael Zollhofer, and Christian Theobalt.
    StyleRig: Rigging StyleGAN for 3D control over portrait images. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    6142–6151, 2020.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2019a] Lingzhi Li, Jianmin Bao, Hao Yang, Dong Chen, and Fang Wen.
    FaceShifter: Towards high fidelity and occlusion aware face swapping. *arXiv preprint
    arXiv:1912.13457*, 2019a.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nirkin et al. [2019] Yuval Nirkin, Yosi Keller, and Tal Hassner. FSGAN: Subject
    agnostic face swapping and reenactment. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, pages 7184–7193, 2019.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karras et al. [2019] Tero Karras, Samuli Laine, and Timo Aila. A style-based
    generator architecture for generative adversarial networks. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages 4401–4410,
    2019.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thies et al. [2016] Justus Thies, Michael Zollhofer, Marc Stamminger, Christian
    Theobalt, and Matthias Nießner. Face2Face: Real-time face capture and reenactment
    of RGB videos. In *Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition*, pages 2387–2395, 2016.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thies et al. [2019] Justus Thies, Michael Zollhöfer, and Matthias Nießner.
    Deferred neural rendering: Image synthesis using neural textures. *ACM Transactions
    on Graphics (TOG)*, 38(4):1–12, 2019.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Olszewski et al. [2019] Kyle Olszewski, Sergey Tulyakov, Oliver Woodford, Hao
    Li, and Linjie Luo. Transformable bottleneck networks. In *Proceedings of the
    IEEE/CVF International Conference on Computer Vision*, pages 7648–7657, 2019.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chan et al. [2019] Caroline Chan, Shiry Ginosar, Tinghui Zhou, and Alexei A
    Efros. Everybody dance now. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, pages 5933–5942, 2019.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thies et al. [2020] Justus Thies, Mohamed Elgharib, Ayush Tewari, Christian
    Theobalt, and Matthias Nießner. Neural voice puppetry: Audio-driven facial reenactment.
    In *European Conference on Computer Vision*, pages 716–731. Springer, 2020.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Keras-VGGFace: VGGFace implementation with Keras framework. [https://github.com/rcmalli/keras-vggface](https://github.com/rcmalli/keras-vggface).'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fac [a] Faceswap-GAN. [https://github.com/shaoanlu/faceswap-GAN](https://github.com/shaoanlu/faceswap-GAN),
    a.
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fac [b] FaceNet. [https://github.com/davidsandberg/facenet](https://github.com/davidsandberg/facenet),
    b.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] CycleGAN. [https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix).'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2017] Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. Densely connected convolutional networks. In *Proceedings of the IEEE
    Conference on Computer Vision and Pattern Recognition*, pages 4700–4708, 2017.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karras et al. [2017] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen.
    Progressive growing of GANs for improved quality, stability, and variation. *arXiv
    preprint arXiv:1710.10196*, 2017.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korshunov and Marcel [2019] Pavel Korshunov and Sébastien Marcel. Vulnerability
    assessment and detection of deepfake videos. In *2019 International Conference
    on Biometrics (ICB)*, pages 1–6\. IEEE, 2019.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] VidTIMIT database. [http://conradsanderson.id.au/vidtimit/](http://conradsanderson.id.au/vidtimit/).'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parkhi et al. [2015] Omkar M Parkhi, Andrea Vedaldi, and Andrew Zisserman. Deep
    face recognition. In *Proceedings of the British Machine Vision Conference (BMVC)*,
    pages 41.1–41.12, 2015.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schroff et al. [2015] Florian Schroff, Dmitry Kalenichenko, and James Philbin.
    FaceNet: A unified embedding for face recognition and clustering. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, pages 815–823,
    2015.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chung et al. [2017] Joon Son Chung, Andrew Senior, Oriol Vinyals, and Andrew
    Zisserman. Lip reading sentences in the wild. In *2017 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR)*, pages 3444–3453\. IEEE, 2017.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Suwajanakorn et al. [2017] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman.
    Synthesizing Obama: learning lip sync from audio. *ACM Transactions on Graphics
    (ToG)*, 36(4):1–13, 2017.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korshunov and Marcel [2018a] Pavel Korshunov and Sébastien Marcel. Speaker inconsistency
    detection in tampered video. In *The 26th European Signal Processing Conference
    (EUSIPCO)*, pages 2375–2379\. IEEE, 2018a.
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Galbally and Marcel [2014] Javier Galbally and Sébastien Marcel. Face anti-spoofing
    based on general image quality assessment. In *The 22nd International Conference
    on Pattern Recognition*, pages 1173–1178\. IEEE, 2014.
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chesney and Citron [2018a] Robert Chesney and Danielle Keats Citron. Deep fakes:
    A looming challenge for privacy, democracy, and national security. *Democracy,
    and National Security*, 107, 2018a.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Lima et al. [2020] Oscar de Lima, Sean Franklin, Shreshtha Basu, Blake Karwoski,
    and Annet George. Deepfake detection using spatiotemporal convolutional networks.
    *arXiv preprint arXiv:2006.14749*, 2020.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amerini and Caldelli [2020] Irene Amerini and Roberto Caldelli. Exploiting prediction
    error inconsistencies through LSTM-based classifiers to detect deepfake videos.
    In *Proceedings of the 2020 ACM Workshop on Information Hiding and Multimedia
    Security*, pages 97–102, 2020.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xuan et al. [2019] Xinsheng Xuan, Bo Peng, Wei Wang, and Jing Dong. On the generalization
    of GAN image forensics. In *Chinese Conference on Biometric Recognition*, pages
    134–141\. Springer, 2019.
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2016] Pengpeng Yang, Rongrong Ni, and Yao Zhao. Recapture image
    forensics based on laplacian convolutional neural networks. In *International
    Workshop on Digital Watermarking*, pages 119–128\. Springer, 2016.
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bayar and Stamm [2016] Belhassen Bayar and Matthew C Stamm. A deep learning
    approach to universal image manipulation detection using a new convolutional layer.
    In *Proceedings of the 4th ACM Workshop on Information Hiding and Multimedia Security*,
    pages 5–10, 2016.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian et al. [2015] Yinlong Qian, Jing Dong, Wei Wang, and Tieniu Tan. Deep learning
    for steganalysis via convolutional neural networks. In *Media Watermarking, Security,
    and Forensics*, volume 9409, page 94090J, 2015.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2017] Ying Zhang, Lilei Zheng, and Vrizlynn LL Thing. Automated
    face swapping and its detection. In *The 2nd International Conference on Signal
    and Image Processing (ICSIP)*, pages 15–19\. IEEE, 2017.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2017] Xin Wang, Nicolas Thome, and Matthieu Cord. Gaze latent support
    vector machine for image classification improved by weakly supervised region selection.
    *Pattern Recognition*, 72:59–71, 2017.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai [2017] Shuang Bai. Growing random forest on deep convolutional neural networks
    for scene categorization. *Expert Systems with Applications*, 71:279–287, 2017.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. [2016] Lilei Zheng, Stefan Duffner, Khalid Idrissi, Christophe
    Garcia, and Atilla Baskurt. Siamese multi-layer perceptrons for dimensionality
    reduction and face identification. *Multimedia Tools and Applications*, 75(9):5055–5073,
    2016.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Agarwal and Varshney [2019] Sakshi Agarwal and Lav R Varshney. Limits of deepfake
    detection: A robust estimation viewpoint. *arXiv preprint arXiv:1905.03493*, 2019.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maurer [2000] Ueli M Maurer. Authentication theory and hypothesis testing. *IEEE
    Transactions on Information Theory*, 46(4):1350–1356, 2000.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Korshunova et al. [2017] Iryna Korshunova, Wenzhe Shi, Joni Dambre, and Lucas
    Theis. Fast face-swap using convolutional neural networks. In *Proceedings of
    the IEEE International Conference on Computer Vision*, pages 3677–3685, 2017.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hsu et al. [2020] Chih-Chung Hsu, Yi-Xiu Zhuang, and Chia-Yen Lee. Deep fake
    image detection based on pairwise learning. *Applied Sciences*, 10(1):370, 2020.
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chopra et al. [2005] Sumit Chopra, Raia Hadsell, and Yann LeCun. Learning a
    similarity metric discriminatively, with application to face verification. In
    *IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR’05)*,
    volume 1, pages 539–546\. IEEE, 2005.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2015] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep
    learning face attributes in the wild. In *Proceedings of the IEEE International
    Conference on Computer Vision*, pages 3730–3738, 2015.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. [2015] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised
    representation learning with deep convolutional generative adversarial networks.
    *arXiv preprint arXiv:1511.06434*, 2015.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arjovsky et al. [2017] Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein
    generative adversarial networks. In *International Conference on Machine Learning*,
    pages 214–223\. PMLR, 2017.
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gulrajani et al. [2017] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent
    Dumoulin, and Aaron Courville. Improved training of Wasserstein GANs. *arXiv preprint
    arXiv:1704.00028*, 2017.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mao et al. [2017] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang,
    and Stephen Paul Smolley. Least squares generative adversarial networks. In *Proceedings
    of the IEEE International Conference on Computer Vision*, pages 2794–2802, 2017.
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. [2015] Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
    Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
    Bernstein, et al. ImageNet large scale visual recognition challenge. *International
    Journal of Computer Vision*, 115(3):211–252, 2015.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brock et al. [2018] Andrew Brock, Jeff Donahue, and Karen Simonyan. Large scale
    GAN training for high fidelity natural image synthesis. *arXiv preprint arXiv:1809.11096*,
    2018.
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2019] Han Zhang, Ian Goodfellow, Dimitris Metaxas, and Augustus
    Odena. Self-attention generative adversarial networks. In *International Conference
    on Machine Learning*, pages 7354–7363\. PMLR, 2019.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miyato et al. [2018] Takeru Miyato, Toshiki Kataoka, Masanori Koyama, and Yuichi
    Yoshida. Spectral normalization for generative adversarial networks. *arXiv preprint
    arXiv:1802.05957*, 2018.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Farid [2009] Hany Farid. Image forgery detection. *IEEE Signal Processing Magazine*,
    26(2):16–25, 2009.
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mo et al. [2018] Huaxiao Mo, Bolin Chen, and Weiqi Luo. Fake faces identification
    via convolutional neural network. In *Proceedings of the 6th ACM Workshop on Information
    Hiding and Multimedia Security*, pages 43–47, 2018.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marra et al. [2018] Francesco Marra, Diego Gragnaniello, Davide Cozzolino, and
    Luisa Verdoliva. Detection of GAN-generated fake images over social networks.
    In *2018 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)*,
    pages 384–389\. IEEE, 2018.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hsu et al. [2018] Chih-Chung Hsu, Chia-Yen Lee, and Yi-Xiu Zhuang. Learning
    to detect fake face images in the wild. In *2018 International Symposium on Computer,
    Consumer and Control (IS3C)*, pages 388–391\. IEEE, 2018.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. [2021] Zhiqing Guo, Lipin Hu, Ming Xia, and Gaobo Yang. Blind detection
    of glow-based facial forgery. *Multimedia Tools and Applications*, 80(5):7687–7710,
    2021.
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kingma and Dhariwal [2018] Diederik P Kingma and Prafulla Dhariwal. Glow: generative
    flow with invertible 1$\times$ 1 convolutions. In *Proceedings of the 32nd International
    Conference on Neural Information Processing Systems*, pages 10236–10245, 2018.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Afchar et al. [2018] Darius Afchar, Vincent Nozick, Junichi Yamagishi, and
    Isao Echizen. MesoNet: a compact facial video forgery detection network. In *2018
    IEEE International Workshop on Information Forensics and Security (WIFS)*, pages
    1–7\. IEEE, 2018.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sabir et al. [2019] Ekraam Sabir, Jiaxin Cheng, Ayush Jaiswal, Wael AbdAlmageed,
    Iacopo Masi, and Prem Natarajan. Recurrent convolutional strategies for face manipulation
    detection in videos. *Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition Workshops*, 3(1):80–87, 2019.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. [2021] Tianchen Zhao, Xiang Xu, Mingze Xu, Hui Ding, Yuanjun Xiong,
    and Wei Xia. Learning self-consistency for deepfake detection. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*, pages 15023–15033,
    2021.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rossler et al. [2019] Andreas Rossler, Davide Cozzolino, Luisa Verdoliva, Christian
    Riess, Justus Thies, and Matthias Nießner. FaceForensics++: Learning to detect
    manipulated facial images. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*, pages 1–11, 2019.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dufour and Gully [2019] Nick Dufour and Andrew Gully. Contributing data to deepfake
    detection research. [https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html](https://ai.googleblog.com/2019/09/contributing-data-to-deepfake-detection.html),
    September 2019.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2020a] Yuezun Li, Xin Yang, Pu Sun, Honggang Qi, and Siwei Lyu.
    Celeb-DF: A large-scale challenging dataset for deepfake forensics. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    3207–3216, 2020a.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dolhansky et al. [2020] Brian Dolhansky, Joanna Bitton, Ben Pflaum, Jikuo Lu,
    Russ Howes, Menglin Wang, and Cristian Canton Ferrer. The deepfake detection challenge
    dataset. *arXiv preprint arXiv:2006.07397*, 2020.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dolhansky et al. [2019] Brian Dolhansky, Russ Howes, Ben Pflaum, Nicole Baram,
    and Cristian Canton Ferrer. The deepfake detection challenge (DFDC) preview dataset.
    *arXiv preprint arXiv:1910.08854*, 2019.
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. [2020] Liming Jiang, Ren Li, Wayne Wu, Chen Qian, and Chen Change
    Loy. DeeperForensics-1.0: A large-scale dataset for real-world face forgery detection.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 2889–2898, 2020.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. [2014] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry
    Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations
    using RNN encoder-decoder for statistical machine translation. *arXiv preprint
    arXiv:1406.1078*, 2014.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Güera and Delp [2018] David Güera and Edward J Delp. Deepfake video detection
    using recurrent neural networks. In *15th IEEE International Conference on Advanced
    Video and Signal based Surveillance (AVSS)*, pages 1–6\. IEEE, 2018.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laptev et al. [2008] Ivan Laptev, Marcin Marszalek, Cordelia Schmid, and Benjamin
    Rozenfeld. Learning realistic human actions from movies. In *IEEE Conference on
    Computer Vision and Pattern Recognition*, pages 1–8\. IEEE, 2008.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. [2018] Yuezun Li, Ming-Ching Chang, and Siwei Lyu. In ictu oculi:
    Exposing ai created fake videos by detecting eye blinking. In *2018 IEEE International
    Workshop on Information Forensics and Security (WIFS)*, pages 1–7\. IEEE, 2018.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Donahue et al. [2015] Jeffrey Donahue, Lisa Anne Hendricks, Sergio Guadarrama,
    Marcus Rohrbach, Subhashini Venugopalan, Kate Saenko, and Trevor Darrell. Long-term
    recurrent convolutional networks for visual recognition and description. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition*, pages 2625–2634,
    2015.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caldelli et al. [2021] Roberto Caldelli, Leonardo Galteri, Irene Amerini, and
    Alberto Del Bimbo. Optical flow based CNN for detection of unlearnt deepfake manipulations.
    *Pattern Recognition Letters*, 146:31–37, 2021.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amerini et al. [2019] Irene Amerini, Leonardo Galteri, Roberto Caldelli, and
    Alberto Del Bimbo. Deepfake video detection through optical flow based CNN. In
    *Proceedings of the IEEE/CVF International Conference on Computer Vision Workshops*,
    pages 1205–1207, 2019.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. [2016] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep
    residual learning for image recognition. In *Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition*, pages 770–778, 2016.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman [2014] Karen Simonyan and Andrew Zisserman. Very deep
    convolutional networks for large-scale image recognition. *arXiv preprint arXiv:1409.1556*,
    2014.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Lyu [2018] Yuezun Li and Siwei Lyu. Exposing deepfake videos by detecting
    face warping artifacts. *arXiv preprint arXiv:1811.00656*, 2018.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2019] Xin Yang, Yuezun Li, and Siwei Lyu. Exposing deep fakes using
    inconsistent head poses. In *IEEE International Conference on Acoustics, Speech
    and Signal Processing (ICASSP)*, pages 8261–8265\. IEEE, 2019.
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. [2017] Peng Zhou, Xintong Han, Vlad I Morariu, and Larry S Davis.
    Two-stream neural networks for tampered face detection. In *IEEE Conference on
    Computer Vision and Pattern Recognition Workshops (CVPRW)*, pages 1831–1839\.
    IEEE, 2017.
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nguyen et al. [2019] Huy H Nguyen, Junichi Yamagishi, and Isao Echizen. Capsule-forensics:
    Using capsule networks to detect forged images and videos. In *IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*, pages 2307–2311\.
    IEEE, 2019.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. [2011] Geoffrey E Hinton, Alex Krizhevsky, and Sida D Wang. Transforming
    auto-encoders. In *International Conference on Artificial Neural Networks*, pages
    44–51\. Springer, 2011.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sabour et al. [2017] Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic
    routing between capsules. In *Proceedings of the 31st International Conference
    on Neural Information Processing Systems*, pages 3859–3869, 2017.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chingovska et al. [2012] Ivana Chingovska, André Anjos, and Sébastien Marcel.
    On the effectiveness of local binary patterns in face anti-spoofing. In *Proceedings
    of the International Conference of Biometrics Secial Interest Group (BIOSIG)*,
    pages 1–7\. IEEE, 2012.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rössler et al. [2018] Andreas Rössler, Davide Cozzolino, Luisa Verdoliva, Christian
    Riess, Justus Thies, and Matthias Nießner. FaceForensics: A large-scale video
    dataset for forgery detection in human faces. *arXiv preprint arXiv:1803.09179*,
    2018.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rahmouni et al. [2017] Nicolas Rahmouni, Vincent Nozick, Junichi Yamagishi,
    and Isao Echizen. Distinguishing computer graphics from natural images using convolution
    neural networks. In *IEEE Workshop on Information Forensics and Security (WIFS)*,
    pages 1–6\. IEEE, 2017.
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guan et al. [2019] Haiying Guan, Mark Kozak, Eric Robertson, Yooyoung Lee,
    Amy N Yates, Andrew Delgado, Daniel Zhou, Timothee Kheyrkhah, Jeff Smith, and
    Jonathan Fiscus. MFC datasets: Large-scale benchmark datasets for media forensic
    challenge evaluation. In *IEEE Winter Applications of Computer Vision Workshops
    (WACVW)*, pages 63–72\. IEEE, 2019.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matern et al. [2019] Falko Matern, Christian Riess, and Marc Stamminger. Exploiting
    visual artifacts to expose deepfakes and face manipulations. In *IEEE Winter Applications
    of Computer Vision Workshops (WACVW)*, pages 83–92\. IEEE, 2019.
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Koopman et al. [2018] Marissa Koopman, Andrea Macarulla Rodriguez, and Zeno
    Geradts. Detection of deepfake video manipulation. In *The 20th Irish Machine
    Vision and Image Processing Conference (IMVIP)*, pages 133–136, 2018.
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rosenfeld and Sencar [2009] Kurt Rosenfeld and Husrev Taha Sencar. A study of
    the robustness of PRNU-based camera identification. In *Media Forensics and Security*,
    volume 7254, page 72540M, 2009.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Li [2011] Chang-Tsun Li and Yue Li. Color-decoupled photo response non-uniformity
    for digital image forensics. *IEEE Transactions on Circuits and Systems for Video
    Technology*, 22(2):260–271, 2011.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin and Li [2016] Xufeng Lin and Chang-Tsun Li. Large-scale image clustering
    based on camera fingerprints. *IEEE Transactions on Information Forensics and
    Security*, 12(4):793–808, 2016.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Scherhag et al. [2019] Ulrich Scherhag, Luca Debiasi, Christian Rathgeb, Christoph
    Busch, and Andreas Uhl. Detection of face morphing attacks based on PRNU analysis.
    *IEEE Transactions on Biometrics, Behavior, and Identity Science*, 1(4):302–317,
    2019.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Phan et al. [2018] Quoc-Tin Phan, Giulia Boato, and Francesco GB De Natale.
    Accurate and scalable image clustering based on sparse representation of camera
    fingerprint. *IEEE Transactions on Information Forensics and Security*, 14(7):1902–1916,
    2018.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hasan and Salah [2019] Haya R Hasan and Khaled Salah. Combating deepfake videos
    using blockchain and smart contracts. *IEEE Access*, 7:41596–41606, 2019.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] IPFS powers the distributed web. [https://ipfs.io/](https://ipfs.io/).'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chintha et al. [2020] Akash Chintha, Bao Thai, Saniat Javid Sohrawardi, Kartavya
    Bhatt, Andrea Hickerson, Matthew Wright, and Raymond Ptucha. Recurrent convolutional
    structures for audio spoof and video deepfake detection. *IEEE Journal of Selected
    Topics in Signal Processing*, 14(5):1024–1037, 2020.
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Todisco et al. [2019] Massimiliano Todisco, Xin Wang, Ville Vestman, Md Sahidullah,
    Héctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen,
    and Kong Aik Lee. ASVspoof 2019: Future horizons in spoofed and fake audio detection.
    *arXiv preprint arXiv:1904.05441*, 2019.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agarwal et al. [2020a] Shruti Agarwal, Hany Farid, Ohad Fried, and Maneesh Agrawala.
    Detecting deep-fake videos from phoneme-viseme mismatches. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    pages 660–661, 2020a.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fried et al. [2019] Ohad Fried, Ayush Tewari, Michael Zollhöfer, Adam Finkelstein,
    Eli Shechtman, Dan B Goldman, Kyle Genova, Zeyu Jin, Christian Theobalt, and Maneesh
    Agrawala. Text-based editing of talking-head video. *ACM Transactions on Graphics
    (TOG)*, 38(4):1–14, 2019.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fernandes et al. [2020] Steven Fernandes, Sunny Raj, Rickard Ewetz, Jodh Singh
    Pannu, Sumit Kumar Jha, Eddy Ortiz, Iustina Vintila, and Margaret Salter. Detecting
    deepfake videos using attribution-based confidence metric. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops*,
    pages 308–309, 2020.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cao et al. [2018] Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and Andrew
    Zisserman. VGGFace2: A dataset for recognising faces across pose and age. In *The
    13th IEEE International Conference on Automatic Face & Gesture Recognition (FG
    2018)*, pages 67–74\. IEEE, 2018.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jha et al. [2019] Susmit Jha, Sunny Raj, Steven Fernandes, Sumit K Jha, Somesh
    Jha, Brian Jalaian, Gunjan Verma, and Ananthram Swami. Attribution-based confidence
    metric for deep neural networks. *Advances in Neural Information Processing Systems*,
    32:11826–11837, 2019.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fernandes et al. [2019] Steven Fernandes, Sunny Raj, Eddy Ortiz, Iustina Vintila,
    Margaret Salter, Gordana Urosevic, and Sumit Jha. Predicting heart rate variations
    of deepfake videos using neural ODE. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops*, pages 1721–1729, 2019.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Korshunov and Marcel [2018b] Pavel Korshunov and Sébastien Marcel. Deepfakes:
    a new threat to face recognition? assessment and detection. *arXiv preprint arXiv:1812.08685*,
    2018b.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Agarwal et al. [2020b] Shruti Agarwal, Hany Farid, Tarek El-Gaaly, and Ser-Nam
    Lim. Detecting deep-fake videos from appearance and behavior. In *IEEE International
    Workshop on Information Forensics and Security (WIFS)*, pages 1–6\. IEEE, 2020b.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ciftci et al. [2020] Umur Aybars Ciftci, Ilke Demir, and Lijun Yin. FakeCatcher:
    Detection of synthetic portrait videos using biological signals. *IEEE Transactions
    on Pattern Analysis and Machine Intelligence*, 2020.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mittal et al. [2020] Trisha Mittal, Uttaran Bhattacharya, Rohan Chandra, Aniket
    Bera, and Dinesh Manocha. Emotions don’t lie: A deepfake detection method using
    audio-visual affective cues. *arXiv preprint arXiv:2003.06711*, 3, 2020.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guarnera et al. [2020b] Luca Guarnera, Oliver Giudice, and Sebastiano Battiato.
    Deepfake detection by analyzing convolutional traces. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition Workshops*, pages 666–667,
    2020b.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. [2019] Wonwoong Cho, Sungha Choi, David Keetae Park, Inkyu Shin,
    and Jaegul Choo. Image-to-image translation via group-wise deep whitening-and-coloring
    transformation. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*, pages 10639–10647, 2019.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi et al. [2018] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun
    Kim, and Jaegul Choo. StarGAN: Unified generative adversarial networks for multi-domain
    image-to-image translation. In *Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition*, pages 8789–8797, 2018.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. [2019] Zhenliang He, Wangmeng Zuo, Meina Kan, Shiguang Shan, and
    Xilin Chen. AttGAN: Facial attribute editing by only changing what you want. *IEEE
    Transactions on Image Processing*, 28(11):5464–5478, 2019.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karras et al. [2020] Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten,
    Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 8110–8119, 2020.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. [2007] Gary B. Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller.
    Labeled faces in the wild: A database for studying face recognition in unconstrained
    environments. Technical Report 07-49, University of Massachusetts, Amherst, October
    2007.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gandhi and Jain [2020] Apurva Gandhi and Shomik Jain. Adversarial perturbations
    fool deepfake detectors. In *IEEE International Joint Conference on Neural Networks
    (IJCNN)*, pages 1–8\. IEEE, 2020.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] Few-shot face translation GAN. [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN).'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2020b] Lingzhi Li, Jianmin Bao, Ting Zhang, Hao Yang, Dong Chen,
    Fang Wen, and Baining Guo. Face X-ray for more general face forgery detection.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 5001–5010, 2020b.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2020] Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens,
    and Alexei A Efros. CNN-generated images are surprisingly easy to spot… for now.
    In *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    pages 8695–8704, 2020.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dai et al. [2019] Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, and Lei
    Zhang. Second-order attention network for single image super-resolution. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, pages
    11065–11074, 2019.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guarnera et al. [2020c] Luca Guarnera, Oliver Giudice, and Sebastiano Battiato.
    Fighting deepfake by exposing the convolutional traces on images. *IEEE Access*,
    8:165085–165098, 2020c.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moon [1996] Todd K Moon. The expectation-maximization algorithm. *IEEE Signal
    Processing Magazine*, 13(6):47–60, 1996.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2017] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *Proceedings of the IEEE international conference on computer vision*, pages
    2223–2232, 2017.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2019b] Ke Li, Tianhao Zhang, and Jitendra Malik. Diverse image synthesis
    from semantic layouts via conditional imle. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*, pages 4220–4229, 2019b.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zubiaga et al. [2018] Arkaitz Zubiaga, Ahmet Aker, Kalina Bontcheva, Maria
    Liakata, and Rob Procter. Detection and resolution of rumours in social media:
    A survey. *ACM Computing Surveys (CSUR)*, 51(2):1–36, 2018.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chesney and Citron [2018b] R. Chesney and D. K. Citron. Disinformation on steroids:
    The threat of deep fakes. [https://www.cfr.org/report/deep-fake-disinformation-steroids](https://www.cfr.org/report/deep-fake-disinformation-steroids),
    October 2018b.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Floridi [2018] Luciano Floridi. Artificial intelligence, deepfakes and a future
    of ectypes. *Philosophy & Technology*, 31(3):317–321, 2018.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cozzolino et al. [2018] Davide Cozzolino, Justus Thies, Andreas Rössler, Christian
    Riess, Matthias Nießner, and Luisa Verdoliva. ForensicTransfer: Weakly-supervised
    domain adaptation for forgery detection. *arXiv preprint arXiv:1812.02510*, 2018.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marra et al. [2019] Francesco Marra, Cristiano Saltori, Giulia Boato, and Luisa
    Verdoliva. Incremental learning for the detection and classification of gan-generated
    images. In *2019 IEEE International Workshop on Information Forensics and Security
    (WIFS)*, pages 1–6\. IEEE, 2019.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hussain et al. [2021] Shehzeen Hussain, Paarth Neekhara, Malhar Jere, Farinaz
    Koushanfar, and Julian McAuley. Adversarial deepfakes: Evaluating vulnerability
    of deepfake detectors to adversarial examples. In *Proceedings of the IEEE/CVF
    Winter Conference on Applications of Computer Vision*, pages 3348–3357, 2021.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carlini and Farid [2020] Nicholas Carlini and Hany Farid. Evading deepfake-image
    detectors with white-and black-box attacks. In *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops*, pages 658–659, 2020.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2021] Chaofei Yang, Leah Ding, Yiran Chen, and Hai Li. Defending
    against gan-based deepfake attacks via transformation-aware adversarial faces.
    In *IEEE International Joint Conference on Neural Networks (IJCNN)*, pages 1–8\.
    IEEE, 2021.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yeh et al. [2020] Chin-Yuan Yeh, Hsi-Wen Chen, Shang-Lun Tsai, and Sheng-De
    Wang. Disrupting image-translation-based deepfake algorithms with adversarial
    attacks. In *Proceedings of the IEEE/CVF Winter Conference on Applications of
    Computer Vision Workshops*, pages 53–62, 2020.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Read [2019] M. Read. Can you spot a deepfake? does it matter? [http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html](http://nymag.com/intelligencer/2019/06/how-do-you-spot-a-deepfake-it-might-not-matter.html),
    June 2019.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maras and Alexandrou [2019] Marie-Helen Maras and Alex Alexandrou. Determining
    authenticity of video evidence in the age of artificial intelligence and in the
    wake of deepfake videos. *The International Journal of Evidence & Proof*, 23(3):255–262,
    2019.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. [2017] Lichao Su, Cuihua Li, Yuecong Lai, and Jianmei Yang. A fast
    forgery detection algorithm based on exponential-Fourier moments for video region
    duplication. *IEEE Transactions on Multimedia*, 20(4):825–840, 2017.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Iuliani et al. [2018] Massimo Iuliani, Dasara Shullani, Marco Fontani, Saverio
    Meucci, and Alessandro Piva. A video forensic framework for the unsupervised analysis
    of MP4-like file container. *IEEE Transactions on Information Forensics and Security*,
    14(3):635–645, 2018.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Malolan et al. [2020] Badhrinarayan Malolan, Ankit Parekh, and Faruk Kazi. Explainable
    deep-fake detection using visual interpretability methods. In *The 3rd International
    Conference on Information and Computer Technologies (ICICT)*, pages 289–293\.
    IEEE, 2020.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Giudice et al. [2021] Oliver Giudice, Luca Guarnera, and Sebastiano Battiato.
    Fighting deepfakes by detecting GAN DCT anomalies. *arXiv preprint arXiv:2101.09781*,
    2021.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
