- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:33:45'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:33:45
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2403.17561] A Survey on Deep Learning and State-of-the-art Applications'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2403.17561] 深度学习与最前沿应用的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2403.17561](https://ar5iv.labs.arxiv.org/html/2403.17561)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2403.17561](https://ar5iv.labs.arxiv.org/html/2403.17561)
- en: '[type=editor, orcid=0000-0002-3300-3270]'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '[type=editor, orcid=0000-0002-3300-3270]'
- en: \cormark
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[1]'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: \fnmark
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: \fnmark
- en: '[1]'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: \credit
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: \credit
- en: Conceptualization of this study, writing - original draft, writing - review
    and editing, funding acquisition
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究的概念化，写作 - 原始草稿，写作 - 审阅与编辑，资金获取
- en: 1]organization=School of Computer Sciences, Universiti Sains Malaysia, postcode=11800,
    state=Pulau Pinang, country=Malaysia
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 1]组织机构=马来西亚槟城大学计算机科学学院，邮政编码=11800，省=槟城，国家=马来西亚
- en: '[type=editor, orcid=0000-0001-5155-9304]'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '[type=editor, orcid=0000-0001-5155-9304]'
- en: \fnmark
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: \fnmark
- en: '[2]'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: \credit
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: \credit
- en: Writing - original draft
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 写作 - 原始草稿
- en: 2]organization=Department of Computer Science, Adekunle Ajasin University, city=Akungba-Akoko,
    postcode=P.M.B 001, state=Ondo State, country=Nigeria
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 2]组织机构=阿德库莱·阿贾辛大学计算机科学系，城市=阿昆巴-阿科科，邮政编码=P.M.B 001，省=翁多州，国家=尼日利亚
- en: \cortext
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: \cortext
- en: '[cor1]Corresponding author'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[cor1]通讯作者'
- en: A Survey on Deep Learning and State-of-the-art Applications
  id: totrans-22
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习与最前沿应用的调查
- en: Mohd Halim Mohd Noor halimnoor@usm.my [    Ayokunle Olalekan Ige ayo.ige@aaua.edu.ng
    [
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: Mohd Halim Mohd Noor halimnoor@usm.my [    Ayokunle Olalekan Ige ayo.ige@aaua.edu.ng
    [
- en: Abstract
  id: totrans-24
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Deep learning, a branch of artificial intelligence, is a computational model
    that uses multiple layers of interconnected units (neurons) to learn intricate
    patterns and representations directly from raw input data. Empowered by this learning
    capability, it has become a powerful tool for solving complex problems and is
    the core driver of many groundbreaking technologies and innovations. Building
    a deep learning model is a challenging task due to the algorithm’s complexity
    and the dynamic nature of real-world problems. Several studies have reviewed deep
    learning concepts and applications. However, the studies mostly focused on the
    types of deep learning models and convolutional neural network architectures,
    offering limited coverage of the state-of-the-art of deep learning models and
    their applications in solving complex problems across different domains. Therefore,
    motivated by the limitations, this study aims to comprehensively review the state-of-the-art
    deep learning models in computer vision, natural language processing, time series
    analysis and pervasive computing. We highlight the key features of the models
    and their effectiveness in solving the problems within each domain. Furthermore,
    this study presents the fundamentals of deep learning, various deep learning model
    types and prominent convolutional neural network architectures. Finally, challenges
    and future directions in deep learning research are discussed to offer a broader
    perspective for future researchers.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习，作为人工智能的一个分支，是一种计算模型，它使用多个相互连接的单元（神经元）层来直接从原始输入数据中学习复杂的模式和表示。凭借这一学习能力，深度学习已成为解决复杂问题的强大工具，并且是许多开创性技术和创新的核心驱动力。构建深度学习模型是一项具有挑战性的任务，因为算法的复杂性和现实世界问题的动态特性。虽然已有一些研究回顾了深度学习的概念和应用，但这些研究主要集中在深度学习模型类型和卷积神经网络架构上，对深度学习模型的最前沿状态及其在解决不同领域复杂问题中的应用覆盖有限。因此，本研究旨在全面回顾计算机视觉、自然语言处理、时间序列分析和普适计算中的最前沿深度学习模型。我们突出展示模型的关键特征及其在解决各领域问题中的有效性。此外，本研究还介绍了深度学习的基本原理、各种深度学习模型类型及显著的卷积神经网络架构。最后，讨论了深度学习研究中的挑战和未来方向，为未来研究者提供更广泛的视角。
- en: 'keywords:'
  id: totrans-26
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Deep Learning \sepConvolutional Neural Network \sepComputer Vision \sepNatural
    Language Processing \sepTime Series Analysis\sepPervasive Computing
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习 \sep卷积神经网络 \sep计算机视觉 \sep自然语言处理 \sep时间序列分析\sep普适计算
- en: 1 Introduction
  id: totrans-28
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Deep learning has revolutionized many applications across a variety of industries
    and research. The application of deep learning can be found in healthcare Shamshirband
    et al. ([2021](#bib.bib215)), smart manufacturing Wang et al. ([2018b](#bib.bib261)),
    robotics Pierson and Gashler ([2017](#bib.bib193)), cybersecurity Dixit and Silakari
    ([2021](#bib.bib50)) etc., solving challenging and complex problems such as disease
    diagnosis, anomaly detection, object detection and malware attack detection. Deep
    learning is a subset of machine learning that learns from data using artificial
    neural networks. An artificial neural network is a computational model that imitates
    the working principles of a human brain. The computational models are composed
    of an input layer which receives the input data, multiple processing layers that
    learn the representation of data and the output layer which produces the output
    of the model.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在许多行业和研究领域中引发了革命。深度学习的应用可以在医疗保健 Shamshirband 等人（[2021](#bib.bib215)）、智能制造
    Wang 等人（[2018b](#bib.bib261)）、机器人技术 Pierson 和 Gashler（[2017](#bib.bib193)）、网络安全
    Dixit 和 Silakari（[2021](#bib.bib50)）等领域找到，解决了疾病诊断、异常检测、物体检测和恶意软件攻击检测等挑战性和复杂的问题。深度学习是机器学习的一个子集，它通过人工神经网络从数据中学习。人工神经网络是一种模仿人脑工作原理的计算模型。这些计算模型由一个接收输入数据的输入层、多层处理层（用于学习数据的表示）以及产生模型输出的输出层组成。
- en: Prior to the reintroduction of deep learning (DL) into the research trend, pattern
    recognition tasks involved a transformation of the raw input data such as pixel
    values of an image into a feature vector that represents the internal representation
    of the data. The feature vector can be used by a machine learning model to detect
    or classify patterns in the data. This process requires feature engineering and
    considerable domain knowledge to design a suitable feature representation. With
    deep learning, this cumbersome process can be performed automatically whereby
    at each processing layer known as hidden layers, the internal representation of
    the input data is learned or extracted in a hierarchical manner. The first layer
    learns the presence of basic primitive features such as edges, dots, lines etc.
    The second layer learns patterns or motifs by recognizing the combinations of
    the edges, dots and lines, and the subsequent layers combine the motifs to produce
    more sophisticated features that correspond to the input data. This feature learning
    process takes place in the sequence of hidden layers until the prediction is finally
    produced.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习（DL）重新成为研究趋势之前，模式识别任务涉及将原始输入数据（例如图像的像素值）转换为特征向量，以表示数据的内部表示。特征向量可以被机器学习模型用来检测或分类数据中的模式。这个过程需要特征工程和相当的领域知识来设计合适的特征表示。通过深度学习，这一繁琐的过程可以自动完成，在每个处理层（称为隐藏层）中，以层级方式学习或提取输入数据的内部表示。第一层学习基本的原始特征，如边缘、点、线等。第二层通过识别边缘、点和线的组合来学习模式或图案，随后的层将这些图案组合起来，生成与输入数据对应的更复杂的特征。这一特征学习过程在隐藏层的序列中进行，直到最终产生预测结果。
- en: Several studies have been conducted to discuss the concept and application of
    deep learning in the last few years, as listed in Table 1\. The studies addressed
    or focused on several aspects of deep learning, such as types of deep learning
    models, learning approaches and strategies, convolutional neural network (CNN)
    architectures, deep learning applications and challenges. In Dong et al. ([2021](#bib.bib51)),
    the authors provided fundamentals of deep learning and highlighted different types
    of deep learning models, such as convolutional neural networks, autoencoder and
    generative adversarial networks. Then, the applications of deep learning in various
    domains are discussed, and some challenges associated with deep learning applications
    are presented. Another survey Talaei Khoei et al. ([2023](#bib.bib243)) provided
    a comprehensive analysis of supervised, unsupervised and reinforcement learning
    approaches and compared the different learning strategies such as online, federated
    and transfer learning. Finally, the current challenges of deep learning and future
    direction are discussed.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来进行了一些研究来讨论深度学习的概念和应用，具体见表 1。这些研究涉及或关注了深度学习的多个方面，如深度学习模型的类型、学习方法和策略、卷积神经网络（CNN）架构、深度学习的应用和挑战。在
    Dong 等人 ([2021](#bib.bib51)) 的研究中，作者介绍了深度学习的基本原理，并突出了不同类型的深度学习模型，如卷积神经网络、自编码器和生成对抗网络。随后，讨论了深度学习在各个领域的应用，并提出了一些与深度学习应用相关的挑战。另一项综述由
    Talaei Khoei 等人 ([2023](#bib.bib243)) 提供，全面分析了监督式、无监督式和强化学习方法，并比较了在线学习、联邦学习和迁移学习等不同学习策略。最后，讨论了深度学习的当前挑战和未来方向。
- en: In Alzubaidi et al. ([2021](#bib.bib11)), the authors provided a comprehensive
    review of the popular CNN architectures used in computer vision tasks, highlighting
    their key features and advantages. Then, the applications of deep learning in
    medical imaging and the challenges are discussed. A similar survey is reported
    in Alom et al. ([2019](#bib.bib7)), where the different supervised and unsupervised
    deep learning models are highlighted, and the popular CNN architectures are compared
    and discussed. In another survey Pouyanfar et al. ([2018](#bib.bib194)), the authors
    focused on the applications of deep learning in computer vision, natural language
    processing and speech and audio processing. The different types of deep learning
    models are also discussed. In Sarker ([2021](#bib.bib212)), the authors focused
    on the different types of deep learning models and provided a summary of deep
    learning applications in various domains.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Alzubaidi 等人 ([2021](#bib.bib11)) 的研究中，作者提供了对计算机视觉任务中常用的 CNN 架构的全面综述，突出了它们的主要特性和优势。随后，讨论了深度学习在医学成像中的应用及其面临的挑战。在
    Alom 等人 ([2019](#bib.bib7)) 的类似综述中，重点介绍了不同的监督式和无监督式深度学习模型，并对流行的 CNN 架构进行了比较和讨论。在另一项由
    Pouyanfar 等人 ([2018](#bib.bib194)) 进行的综述中，作者专注于深度学习在计算机视觉、自然语言处理以及语音和音频处理中的应用。同时也讨论了不同类型的深度学习模型。在
    Sarker ([2021](#bib.bib212)) 的研究中，作者关注于不同类型的深度学习模型，并总结了深度学习在各个领域的应用。
- en: Despite the existing surveys on deep learning that offer valuable insights,
    the increasing amount of deep learning applications and the existing limitations
    in the current studies motivated us to explore this topic in depth. In general,
    to the best of our knowledge, no survey paper focuses on the emerging trends in
    state-of-the-art applications and the current challenges associated with deep
    learning. Furthermore, the surveys do not discuss the issues and how deep learning
    addresses them by highlighting the key features and components in the models.
    Also, most surveys either ignore or provide minimal coverage of the fundamentals
    of deep learning, which is crucial for understanding the state-of-the-art models.
    The main objective of this paper is to present the most important aspects of deep
    learning, making it accessible to a wide audience and facilitating researchers
    and practitioners in advancing and leveraging its capabilities to solve complex
    problems across diverse domains. Specifically, we present the fundamentals of
    deep learning and the various types of deep learning models, including popular
    deep learning architectures. Then, we discuss the progress of deep learning in
    state-of-the-art applications, highlighting the key features of the models and
    their problem-solving approaches. Finally, we discuss the challenges faced by
    deep learning and the future research directions.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管现有的深度学习综述提供了宝贵的见解，但深度学习应用的不断增加以及当前研究中的局限性促使我们深入探讨这一主题。一般来说，据我们了解，没有综述论文专注于最前沿应用中的新兴趋势以及深度学习的当前挑战。此外，这些综述未讨论问题以及深度学习如何通过突出模型中的关键特征和组件来解决这些问题。此外，大多数综述要么忽略，要么仅提供对深度学习基础知识的最小覆盖，这对理解最先进的模型至关重要。本文的主要目的是呈现深度学习的最重要方面，使其易于为广泛的受众所理解，并帮助研究人员和从业者在各个领域利用其能力解决复杂问题。具体而言，我们介绍了深度学习的基础知识和各种深度学习模型，包括流行的深度学习架构。然后，我们讨论了深度学习在最前沿应用中的进展，突出模型的关键特征及其解决问题的方法。最后，我们讨论了深度学习面临的挑战和未来的研究方向。
- en: 'Table 1: Summary of related works.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：相关工作的总结。
- en: '| Reference | Focus | Concepts not covered |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 重点 | 未覆盖的概念 |'
- en: '| Dong et al. ([2021](#bib.bib51)) | A short review of the fundamentals of
    DL networks and discusses different types of neural networks, DL applications
    and challenges. | Lack of analysis of CNN architectures and limited coverage of
    deep learning fundamentals. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| Dong等 ([2021](#bib.bib51)) | 简要回顾了深度学习网络的基础知识，并讨论了不同类型的神经网络、深度学习应用及挑战。 |
    缺乏对CNN架构的分析，以及对深度学习基础知识的覆盖有限。 |'
- en: '| Talaei Khoei et al. ([2023](#bib.bib243)) | Discusses the learning approaches
    (supervised, unsupervised and reinforcement learnings), learning strategies, and
    DL challenges | Lack of fundamentals of deep learning, CNN architectures and DL
    applications. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| Talaei Khoei等 ([2023](#bib.bib243)) | 讨论了学习方法（监督学习、无监督学习和强化学习）、学习策略和深度学习挑战
    | 缺乏深度学习基础知识、CNN架构和深度学习应用的内容。 |'
- en: '| Alzubaidi et al. ([2021](#bib.bib11)) | Discusses different types of DL networks,
    CNN fundamentals and architectures, DL challenges and medical imaging applications
    | Limited discussion on DL applications such as natural language processing and
    time series analysis. |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Alzubaidi等 ([2021](#bib.bib11)) | 讨论了不同类型的深度学习网络、CNN基础和架构、深度学习挑战及医学成像应用 |
    对深度学习应用如自然语言处理和时间序列分析讨论有限。 |'
- en: '| Alom et al. ([2019](#bib.bib7)) | A short review of the fundamentals of neural
    networks and discusses different types of DL networks, CNN architectures and applications.
    | Limited discussion on DL applications and no discussion of DL challenges. |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| Alom等 ([2019](#bib.bib7)) | 简要回顾了神经网络的基础知识，并讨论了不同类型的深度学习网络、CNN架构和应用。 | 对深度学习应用的讨论有限，没有讨论深度学习挑战。
    |'
- en: '| Pouyanfar et al. ([2018](#bib.bib194)) | Discusses different types of DL
    networks and DL applications and challenges | Lack of analysis of CNN architectures
    and limited coverage of deep learning fundamentals. |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| Pouyanfar等 ([2018](#bib.bib194)) | 讨论了不同类型的深度学习网络及其应用和挑战 | 缺乏对CNN架构的分析，以及对深度学习基础知识的覆盖有限。
    |'
- en: '| Sarker ([2021](#bib.bib212)) | Discusses different types of DL networks and
    provides a summary of DL applications | Lack of fundamentals of deep learning,
    analysis of CNN architectures and limited discussion on DL applications. |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| Sarker ([2021](#bib.bib212)) | 讨论了不同类型的深度学习网络，并总结了深度学习应用 | 缺乏深度学习基础知识、CNN架构分析，以及对深度学习应用的讨论有限。
    |'
- en: 'The remainder of this paper is organized as follows: Section 2 describes the
    fundamentals of deep learning which includes layers and attention mechanisms,
    activation functions, model optimization and loss functions, and regularization
    methods. Section 3 presents the types of deep learning models, including the CNN
    architectures. Section 4 discusses the state-of-the-art applications of deep learning.
    Section 5 discusses the challenges and future directions in the field of deep
    learning. The conclusion is given in Section 6.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下：第2节描述了深度学习的基础，包括层和注意机制、激活函数、模型优化和损失函数以及正则化方法。第3节介绍了深度学习模型的类型，包括CNN架构。第4节讨论了深度学习的最新应用。第5节讨论了深度学习领域的挑战和未来方向。第6节给出了结论。
- en: 2 Fundamentals of Deep Learning
  id: totrans-43
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度学习基础
- en: This section describes the fundamental concepts such as layer types, activation
    functions, training algorithms and regularization methods to provide a comprehensive
    understanding of the underlying principles in advancing the field of deep learning.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述了诸如层类型、激活函数、训练算法和正则化方法等基础概念，以提供对推动深度学习领域发展的基本原理的全面理解。
- en: 2.1 Layers
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 层
- en: A deep learning model is characterized by having numerous hidden layers. The
    hidden layers are responsible for learning and extracting complex features from
    the input data. A hidden layer is composed of an arbitrary number of neurons which
    serves as the fundamental building block of a neural network as shown in Fig.
    [1](#S2.F1 "Figure 1 ‣ 2.1 Layers ‣ 2 Fundamentals of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications"). A neuron consists of an
    arbitrary number of inputs, each associated with a weight, which controls the
    flow of information into the neuron during the forward pass. The flow of information,
    or forward pass, involves the computation of summation of the weighted input,
    followed by the application of a transformation function to the weighted sum.
    Consider a neuron $z_{i}$ at layer $l$, receives an input vector $a_{j}^{(}l-1)$,
    the computation of the neuron is defined as
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型的特点是具有多个隐藏层。隐藏层负责从输入数据中学习和提取复杂特征。一个隐藏层由任意数量的神经元组成，这些神经元作为神经网络的基本构建块，如图[1](#S2.F1
    "Figure 1 ‣ 2.1 Layers ‣ 2 Fundamentals of Deep Learning ‣ A Survey on Deep Learning
    and State-of-the-art Applications")所示。一个神经元包含任意数量的输入，每个输入都与一个权重相关联，该权重控制信息在前向传递过程中的流动。信息流动或前向传递包括加权输入的求和计算，然后将变换函数应用于加权和。考虑在层
    $l$ 上的神经元 $z_{i}$，它接收一个输入向量 $a_{j}^{(}l-1)$，神经元的计算定义为
- en: $z_{i}^{l}=\sum_{j=0}^{d}w_{i,j}^{l-1}\cdot a_{j}^{l-1}$
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: $z_{i}^{l}=\sum_{j=0}^{d}w_{i,j}^{l-1}\cdot a_{j}^{l-1}$
- en: $a_{i}^{l}=g(z_{i}^{l})$
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: $a_{i}^{l}=g(z_{i}^{l})$
- en: where $w_{ij}$ is the set of weights connecting the inputs to the neuron and
    g is the transformation function also known as activation function. A hidden layer
    wherein each neuron is connected to all neurons of the previous layer is known
    as fully-connected layer.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $w_{ij}$ 是连接输入到神经元的权重集合，g 是变换函数，也称为激活函数。一个隐藏层，其中每个神经元都连接到前一层的所有神经元，称为全连接层。
- en: '![Refer to caption](img/ba076d2ae09f88e15bddd8557ff3e3f3.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ba076d2ae09f88e15bddd8557ff3e3f3.png)'
- en: 'Figure 1: A graphical representation of a neuron.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：神经元的图示表示。
- en: The key aspect of deep learning lies in its ability to automatically extract
    hierarchical features from the input data. This automatic feature extraction is
    performed by two specialized layers called convolutional and pooling layers. In
    a convolutional layer, each neuron is connected only to a local region of the
    input data, and the weights are shared across the input data. The weight-sharing
    not only significantly reduces the number of parameters of the neural network,
    but also allows the network to learn the same features across different spatial
    locations in the input LeCun et al. ([2015](#bib.bib124)). Fig. [2](#S2.F2 "Figure
    2 ‣ 2.1 Layers ‣ 2 Fundamentals of Deep Learning ‣ A Survey on Deep Learning and
    State-of-the-art Applications") illustrates a convolutional layer applies $3\times
    3$ filter on two-dimensional image consisting of $9\times 9$ pixels. The layer
    convolves the input data by moving the filter across the whole input pixels, producing
    a set of output values called feature map. The computation of a convolutional
    layer $l$ is defined as
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的关键之处在于其能够从输入数据中自动提取层次化特征。这种自动特征提取是通过两个专门的层进行的，分别是卷积层和池化层。在卷积层中，每个神经元只与输入数据的一个局部区域相连，并且权重在输入数据中共享。权重共享不仅显著减少了神经网络的参数数量，而且还允许网络在输入的不同空间位置学习相同的特征（LeCun
    et al.，[2015](#bib.bib124)）。图[2](#S2.F2 "图2 ‣ 2.1 层 ‣ 2 深度学习的基础知识 ‣ 深度学习和最先进应用的调查")展示了一个卷积层在由$9\times
    9$像素组成的二维图像上应用了$3\times 3$的滤波器。该层通过将滤波器在整个输入像素上移动来卷积输入数据，生成一组称为特征图（feature map）的输出值。卷积层$l$的计算定义为
- en: $z_{i,j,d}^{l}=\sum_{m=0}^{k_{1}}\sum_{n=0}^{k_{2}}w_{m,n,d}^{l-1}\cdot a_{i+m,j+n,d}^{l-1}$
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: $z_{i,j,d}^{l}=\sum_{m=0}^{k_{1}}\sum_{n=0}^{k_{2}}w_{m,n,d}^{l-1}\cdot a_{i+m,j+n,d}^{l-1}$
- en: $a_{i,j,d}^{l}=g(z_{i,j,d}^{l})$
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: $a_{i,j,d}^{l}=g(z_{i,j,d}^{l})$
- en: where $w_{m,n,d}$ is the weight of $k_{1}\times k_{2}$ filter and $a_{i,j,d}^{l-1}$
    is the input pixel.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$w_{m,n,d}$表示$k_{1}\times k_{2}$滤波器的权重，$a_{i,j,d}^{l-1}$是输入像素。
- en: '![Refer to caption](img/be98101642e05eab009e5976e9dacbfb.png)'
  id: totrans-56
  prefs: []
  type: TYPE_IMG
  zh: '![查看图片说明](img/be98101642e05eab009e5976e9dacbfb.png)'
- en: 'Figure 2: A neuron is connected to a local region of the input data.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：神经元与输入数据的局部区域相连。
- en: Pooling layers are commonly applied after successive convolutional layers to
    progressively reduce the spatial dimensions of the feature maps. The spatial reduction
    is performed by computing the summary of the local regions in the feature maps.
    Two common pooling operations are computing the maximum and the average of the
    local regions. This reduces the number of parameters while providing translation-invariant
    features LeCun et al. ([2015](#bib.bib124)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 在连续的卷积层之后常常应用池化层，逐渐降低特征图的空间维度。空间降维通过计算特征图中的局部区域的摘要来实现。常用的两种池化操作是计算局部区域的最大值和平均值。这样既减少了参数数量，又提供了平移不变的特征（LeCun
    et al.，[2015](#bib.bib124)）。
- en: 2.2 Attention Mechanisms
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 注意机制
- en: One of the important concepts in pattern recognition is the ability to attend
    and neglect certain parts of the input data based on their importance. This is
    because not all parts of the input hold equal importance for making the prediction.
    Certain features exhibit a stronger correlation with the output while others are
    less relevant. In convolutional layers, all extracted features are treated uniformly,
    without consideration of the varying degree of the importance of the different
    parts of the input data. This limitation is addressed by the introduction of attention
    mechanism, which can dynamically assign varying levels of significance (weights)
    to the different features. This flexibility enables the deep learning models to
    prioritize the more relevant aspects of the input data, enhancing its ability
    to capture the intricate dependencies for accurate prediction. Given an input
    data $x$, the process of attending to the important components of the input is
    given as
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 在模式识别中一个重要的概念是根据其重要性来关注和忽略输入数据的某些部分。这是因为并非所有输入的各个部分在进行预测时都具有相同的重要性。某些特征与输出之间存在较强的关联性，而其他特征则不太相关。在卷积层中，所有提取的特征都被一视同仁，没有考虑输入数据不同部分的重要性差异。为了解决这个限制，引入了注意机制（attention
    mechanism），该机制可以动态地分配不同特征的重要性（权重）。这种灵活性使得深度学习模型能够优先考虑输入数据中更相关的方面，增强其捕捉精确预测所需的复杂依赖关系的能力。给定输入数据$x$，处理重要输入组件的过程如下所示：
- en: $A=f(g(x),x)$
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: $A=f(g(x),x)$
- en: where $g$ is a composite function that performs a sequence of operations to
    generate the attention or the weights and f applies the generated attention $g(x)$
    on the input $x$, $f=g(x)x$.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $g$ 是一个复合函数，执行一系列操作以生成注意力或权重，$f$ 应用生成的注意力 $g(x)$ 到输入 $x$ 上，即 $f=g(x)x$。
- en: For instance, the squeeze-and-excitation (SE) attention generates the attention
    through five consecutive operations Hu et al. ([2019](#bib.bib94)). First, the
    input is vectorized using global average pooling. Then the vector is passed to
    two fully-connected layers, where the first one with ReLU activation and the second
    one with sigmoid activation. SE attention was a pioneer in channel attention.
    The attention module assigns varying weights to the channels of the feature maps.
    SE attention suffers from computational cost and the use of global average which
    may cause information loss at the spatial level. Several efforts have been made
    to improve SE attention. GSoP attention performs $1\times 1$ convolution on the
    feature maps to reduce the number of channels, and then computes the pairwise
    channel correlation which is used to generate the weights Gao et al. ([2018](#bib.bib64)).
    ECA attention replaced the fully-connected layers with 1d convolution to reduce
    the number of parameters and the computational cost Wang et al. ([2020a](#bib.bib265)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，压缩-激励（SE）注意力通过五个连续的操作生成注意力 Hu 等人 ([2019](#bib.bib94))。首先，输入通过全局平均池化进行向量化。然后，该向量传递给两个全连接层，第一个层使用
    ReLU 激活，第二个层使用 sigmoid 激活。SE 注意力在通道注意力方面是一个先驱。注意力模块为特征图的通道分配不同的权重。SE 注意力存在计算成本高和使用全局平均可能导致空间级别信息丢失的问题。已经做出了若干努力来改进
    SE 注意力。GSoP 注意力对特征图进行 $1\times 1$ 卷积以减少通道数量，然后计算成对通道相关性，并用其生成权重 Gao 等人 ([2018](#bib.bib64))。ECA
    注意力用 1d 卷积替代了全连接层，以减少参数数量和计算成本 Wang 等人 ([2020a](#bib.bib265))。
- en: Temporal attention is an attention module that focuses on specific time steps
    in a sequence of data such time series and video (sequence of images). In video
    processing such as recognizing human actions, temporal attention is used to focus
    on key frames at different point in time that contains crucial information for
    predicting the ongoing activity. Temporal adaptive module (TAM) is a temporal
    attention that can focus on short-term (local) information and global context
    information of the data Liu et al. ([2021b](#bib.bib151)). The composite function
    consists of local branch for generating attention weights and global branch for
    generating channel-wise adaptive kernel. First, the input feature map is squeezed
    using global average pooling to reduce the computational cost. Subsequently, the
    local branch executes two 1D convolution operations, with the first convolution
    using ReLU, and sigmoid activation for the second to generate the local weights.
    The local weights are then multiplied with the featuremap. Meanwhile, the global
    branch is composed of two fully-connected layers, with the first layer using ReLU
    and second layer employing softmax function to generate the adaptive kernel (weights).
    Self-attention is a form of temporal attention, initially proposed for machine
    translation to enable the deep learning models to attend different words in a
    sequence relative to other words Vaswani et al. ([2023](#bib.bib257)). The attention
    module has become a fundamental building block in various natural language processing
    applications. To generate the attention weights, the input (word embeddings) is
    transformed by linear projection to compute query, key and value. Then, dot product
    between query and key is computed, and the resultant is normalized by the square
    root of the size of the key. Finally, the attention weights are obtained by applying
    the softmax function. Self-attention is the fundamental building block of the
    Transformer architecture, a key deep learning model in natural language processing.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 时间注意力是一种关注序列数据中特定时间步的注意力模块，例如时间序列和视频（图像序列）。在视频处理如识别人类动作时，时间注意力用于关注不同时间点上的关键帧，这些帧包含预测正在进行的活动所需的重要信息。时间自适应模块（TAM）是一种时间注意力，可以关注数据的短期（局部）信息和全局上下文信息
    Liu et al. ([2021b](#bib.bib151))。复合函数包括用于生成注意力权重的局部分支和用于生成通道级自适应核的全局分支。首先，输入特征图通过全局平均池化进行压缩，以降低计算成本。随后，局部分支执行两次一维卷积操作，第一次卷积使用
    ReLU，第二次卷积使用 sigmoid 激活函数以生成局部权重。然后，局部权重与特征图相乘。同时，全局分支由两层全连接层组成，第一层使用 ReLU，第二层采用
    softmax 函数以生成自适应核（权重）。自注意力是一种时间注意力，最初为机器翻译提出，以使深度学习模型能够关注序列中不同的词相对于其他词 Vaswani
    et al. ([2023](#bib.bib257))。注意力模块已成为各种自然语言处理应用中的基本构建块。为了生成注意力权重，输入（词嵌入）通过线性投影转换以计算查询、键和值。然后，计算查询和键之间的点积，结果通过键的大小的平方根进行归一化。最后，通过应用
    softmax 函数获得注意力权重。自注意力是 Transformer 架构的基本构建块，Transformer 是自然语言处理中的关键深度学习模型。
- en: Spatial attention focuses on specific regions or spatial location of the input
    data, enabling the deep learning models to selectively emphasize and ignore certain
    features. In the context of computer vision, spatial attention is crucial in capturing
    the spatial relationships and context within an image for accurate prediction.
    Attention gate is a spatial attention that can identify and focus the salient
    regions and suppress feature responses of the insignificant ones. The composite
    function consists of ReLU activation followed by $1\times 1$ convolution to reduce
    channel dimension of the feature maps to a singular feature map. Finally, sigmoid
    is applied to the feature map to generate attention weights Oktay et al. ([2018](#bib.bib184)).
    The self-attention in the standard Transformer is not effective in handling image
    data due to its inherent sequential processing nature and lacks the ability to
    capture spatial dependencies and local patterns. To address this limitation, the
    Vision Transformer (ViT) treats images as a sequence of non-overlapping patches.
    A similar computational pipeline is used to generate the attention weights, the
    sequence of patches is transformed by linear projection to compute the query,
    key and value Dosovitskiy et al. ([2021](#bib.bib52)). The same operations are
    employed to generate the attention weights. Self-attention is computationally
    costly due to its quadratic complexity especially dealing with image data. To
    reduce the complexity, two learnable linear layers, independent of the input data
    are adopted as the key and value vectors Guo et al. ([2023](#bib.bib74)).
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 空间注意力关注输入数据的特定区域或空间位置，使得深度学习模型能够选择性地强调和忽略某些特征。在计算机视觉的背景下，空间注意力在捕捉图像中的空间关系和上下文以实现准确预测方面至关重要。注意力门是一种空间注意力，可以识别并关注显著区域，并抑制不重要区域的特征响应。复合函数包括
    ReLU 激活，随后是 $1\times 1$ 卷积，以将特征图的通道维度减少到单一特征图。最后，应用 sigmoid 函数到特征图上以生成注意力权重 Oktay
    等人（[2018](#bib.bib184)）。标准 Transformer 中的自注意力由于其固有的序列处理性质，对图像数据处理效果不佳，缺乏捕捉空间依赖和局部模式的能力。为了解决这个限制，Vision
    Transformer (ViT) 将图像视作一系列不重叠的块。类似的计算流程被用来生成注意力权重，这些块的序列通过线性投影来计算查询、键和值 Dosovitskiy
    等人（[2021](#bib.bib52)）。相同的操作用于生成注意力权重。自注意力由于其二次复杂度在处理图像数据时计算成本高。为了减少复杂度，采用了两个与输入数据独立的可学习线性层作为键和值向量
    Guo 等人（[2023](#bib.bib74)）。
- en: 2.3 Activation Functions
  id: totrans-66
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 激活函数
- en: The role of the activation function is to transform the weighted sum into a
    more classifiable form. This is crucial to the learning behaviour of the deep
    learning model, generating non-linear relationships between the input and the
    output of the model. The activation function, combined with many hidden layers
    allow the neural network to approximate highly complex, non-linear functions.
    Many activation functions are available for use in neural networks, and some of
    the functions are shown in Fig. [3](#S2.F3 "Figure 3 ‣ 2.3 Activation Functions
    ‣ 2 Fundamentals of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications") - Fig [5](#S2.F5 "Figure 5 ‣ 2.3 Activation Functions ‣ 2 Fundamentals
    of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    The figures show the plot of the three popular activation functions. The sigmoid
    is a classic example of activation function which is used in logistic regression.
    Sigmoid activation function maps the weighted sum to a value in the range of 0
    and 1 which can be used for classification. Hyperbolic tangent is another popular
    choice of bounded activation function which produces an output between -1 and
    1\. Hyperbolic tangent has a stronger gradient, hence the neural network training
    often converges faster than sigmoid LeCun et al. ([2012](#bib.bib126)). For many
    years, sigmoid and hyperbolic tangent are the commonly used activation functions.
    Nevertheless, the activation functions suffer from vanishing gradient problem,
    hindering the efficient training of deep neural networks with many layers Hochreiter
    et al. ([2001](#bib.bib90)).
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 激活函数的作用是将加权和转换为更易分类的形式。这对于深度学习模型的学习行为至关重要，它在模型的输入和输出之间生成非线性关系。激活函数结合多个隐藏层使神经网络能够近似高度复杂的非线性函数。神经网络中可以使用多种激活函数，部分函数如图
    [3](#S2.F3 "图 3 ‣ 2.3 激活函数 ‣ 2 深度学习基础 ‣ 深度学习及其前沿应用综述") 和图 [5](#S2.F5 "图 5 ‣ 2.3
    激活函数 ‣ 2 深度学习基础 ‣ 深度学习及其前沿应用综述") 所示。图中展示了三种流行激活函数的图示。Sigmoid 是一个经典的激活函数示例，广泛用于逻辑回归。Sigmoid
    激活函数将加权和映射到 0 和 1 的范围内，这个值可以用于分类。双曲正切是另一种流行的有界激活函数，它产生的输出在 -1 和 1 之间。双曲正切具有更强的梯度，因此神经网络训练通常比
    sigmoid 更快收敛 LeCun 等人 ([2012](#bib.bib126))。多年来，sigmoid 和双曲正切一直是常用的激活函数。然而，这些激活函数存在梯度消失问题，阻碍了多层深度神经网络的高效训练
    Hochreiter 等人 ([2001](#bib.bib90))。
- en: It was shown that neural networks with unbounded activation functions have the
    universal approximation property and reduce the vanishing gradient problem. Over
    the past years, numerous unbounded activation functions were proposed for neural
    networks, with softplus Dugas et al. ([2000](#bib.bib55)) and rectified linear
    unit (ReLU) Glorot et al. ([2011](#bib.bib70)) activation function being the notable
    examples. These activation functions especially ReLU has pivotal role in improving
    the training and performance of deep learning models. ReLU has been a cornerstone
    of deep learning models due to its computational efficiency and effectiveness
    in addressing the vanishing gradient problem. Since then, several variants of
    ReLU were proposed including Leaky ReLU Maas et al. ([2013](#bib.bib163)), sigmoid
    linear unit Misra ([2020](#bib.bib167)) and exponential linear unit Clevert et al.
    ([2016](#bib.bib39)), each offering unique advantages for building deep learning-based
    applications.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 研究表明，具有无界激活函数的神经网络具有通用逼近特性，并减少了梯度消失问题。在过去几年中，提出了许多无界激活函数用于神经网络，其中 softplus Dugas
    等人 ([2000](#bib.bib55)) 和整流线性单元（ReLU） Glorot 等人 ([2011](#bib.bib70)) 激活函数是值得注意的例子。这些激活函数，特别是
    ReLU，在提高深度学习模型的训练和性能方面起到了关键作用。由于其计算效率和解决梯度消失问题的有效性，ReLU 成为了深度学习模型的基石。从那时起，提出了几种
    ReLU 的变体，包括 Leaky ReLU Maas 等人 ([2013](#bib.bib163))、sigmoid 线性单元 Misra ([2020](#bib.bib167))
    和指数线性单元 Clevert 等人 ([2016](#bib.bib39))，每种变体在构建基于深度学习的应用中都提供了独特的优势。
- en: '![Refer to caption](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
- en: 'Figure 3: Sigmoid activation function.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：Sigmoid 激活函数。
- en: '![Refer to caption](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
- en: 'Figure 4: Hyperbolic tangent activation function.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：双曲正切激活函数。
- en: '![Refer to caption](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/dfe21bdcbfe2f5118124d07fd7101f09.png)'
- en: 'Figure 5: Rectified linear unit activation function.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：整流线性单元激活函数。
- en: 2.4 Parameter Learning and Loss Functions
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 参数学习和损失函数
- en: The weights (parameters) of deep learning models are optimized using an optimization
    algorithm called gradient descent. However, it has to be noted that gradient descent
    is a generic algorithm which can be used to solve a wide range of optimization
    problems. In general, gradient descent finds the optimal weights by iteratively
    updating the weights such that the weights will result in a minimum prediction
    error over all instances in the training set. The prediction error is quantified
    by a loss function. For classification problems, the commonly used loss function
    is the negative log-likelihood loss or cross entropy loss, while the square loss
    and absolute loss are used for regression problems Wang et al. ([2022](#bib.bib264)).
    The weight update is defined as
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型的权重（参数）是通过一种称为梯度下降的优化算法进行优化的。然而，需要注意的是，梯度下降是一种通用算法，可以用于解决各种优化问题。通常，梯度下降通过迭代更新权重来找到最佳权重，从而使权重在训练集的所有实例中产生最小的预测误差。预测误差由损失函数量化。对于分类问题，常用的损失函数是负对数似然损失或交叉熵损失，而平方损失和绝对损失则用于回归问题
    Wang et al. ([2022](#bib.bib264))。权重更新定义为
- en: $w_{i,j}^{l}=w_{i,j}^{l}-\alpha\nabla_{w_{i,j}}$
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: $w_{i,j}^{l}=w_{i,j}^{l}-\alpha\nabla_{w_{i,j}}$
- en: where $\alpha$ is a hyperparameter called learning rate and $\nabla_{w_{i,j}}$
    is the gradient or the derivative of the loss function $J$ with respect to the
    weight $\frac{\partial J}{\partial w_{i,j}^{l}}$.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\alpha$ 是称为学习率的超参数，而 $\nabla_{w_{i,j}}$ 是损失函数 $J$ 关于权重 $\frac{\partial J}{\partial
    w_{i,j}^{l}}$ 的梯度或导数。
- en: The gradient can be computed across all instances of the training set, an approach
    known as batch gradient descent. However, this approach may not guarantee a convergence
    to the optimal solution as the gradient is the same for every weight update. An
    alternative approach is to perform the weight update on the basis of a single
    instance, but the approach results in a noisy gradient and becomes computationally
    intensive due to the frequent weight update. A more commonly used approach is
    to perform the weight update over a set of training instances, known as mini-batch
    gradient descent. This approach strikes a balance, providing a less noisy gradient
    and a more stable training process.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 梯度可以在训练集的所有实例上计算，这种方法称为批量梯度下降。然而，这种方法可能无法保证收敛到最佳解，因为每次权重更新的梯度都是相同的。另一种方法是基于单个实例进行权重更新，但这种方法会导致梯度噪声较大，并且由于频繁的权重更新而变得计算上较为密集。更常用的方法是对一组训练实例进行权重更新，这称为小批量梯度下降。这种方法在提供较少噪声的梯度和更稳定的训练过程之间达到了平衡。
- en: Several efforts have been made to improve the efficiency of gradient descent.
    One of the earlier efforts is the inclusion of past rate of change in the weight
    update to speed up the training of deep learning models, the algorithm is called
    gradient descent with momentum Qian ([1999](#bib.bib198)). Another effort is to
    improve the training convergence by adapting the learning rate based on the occurrence
    of the features Duchi et al. ([2011](#bib.bib54)). A more recent work utilizes
    both adaptive learning rate and momentum to improve the training efficiency and
    convergence of deep learning models Kingma and Ba ([2017](#bib.bib118)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高梯度下降的效率，已经做了几项努力。其中一个早期的努力是将过去的变化率纳入权重更新中，以加速深度学习模型的训练，这种算法被称为带动量的梯度下降 Qian
    ([1999](#bib.bib198))。另一个努力是通过根据特征的出现情况调整学习率来改善训练收敛性 Duchi et al. ([2011](#bib.bib54))。一个较新的工作则利用自适应学习率和动量来提高深度学习模型的训练效率和收敛性
    Kingma 和 Ba ([2017](#bib.bib118))。
- en: 2.5 Regularization Methods
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5 正则化方法
- en: Regularization methods are employed to prevent overfitting in deep learning
    models and improve their generalization performance. Early stopping is a method
    that can detect the onset of overfitting during training by continuously monitoring
    the validation error. The model is considered overfitting if the validation error
    starts to increase at some point of the training while the training error is decreasing.
    However, detecting the onset of overfitting during the training of deep learning
    models is challenging due to the inherent stochasticity and the presence of noisy
    data. Several stopping criteria can be considered such as using a threshold to
    check if the decrease of (average) validation error is significant and count the
    number of successive increases of validation error Prechelt ([2012](#bib.bib197)).
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化方法用于防止深度学习模型的过拟合，并提高其泛化性能。早期停止是一种方法，它通过持续监控验证误差来检测训练过程中过拟合的开始。如果验证误差在训练过程中开始增加，而训练误差在下降，则模型被认为是过拟合。然而，由于固有的随机性和噪声数据的存在，检测深度学习模型训练过程中的过拟合开始是具有挑战性的。可以考虑几种停止标准，例如使用阈值检查（平均）验证误差的减少是否显著，并计算验证误差的连续增加次数
    Prechelt ([2012](#bib.bib197))。
- en: Dropout is a regularization method that randomly switching off some neurons
    in the hidden layers during training with a predefined drop probability (dropout
    rate) Srivastava et al. ([2014](#bib.bib230)). Dropout has the effect of training
    and evaluating exponentially many different deep learning models. The dropout
    rate is a hyperparameter that needs to be carefully tuned to balance regularization
    and model capacity. Different ranges of dropout rate have been suggested. The
    original author suggested a dropout rate between 0.5 and 0.8 Srivastava et al.
    ([2014](#bib.bib230)) while others recommended a lower dropout rate between 0.1
    and 0.3 Park and Kwak ([2017](#bib.bib190)). Also, it has been suggested a low
    dropout rate due to the exponential increase in the volume of training data Liu
    et al. ([2023b](#bib.bib152)).
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: Dropout 是一种正则化方法，通过在训练过程中以预定义的丢弃概率（dropout rate）随机关闭隐藏层中的一些神经元 Srivastava 等
    ([2014](#bib.bib230))。Dropout 使得训练和评估了指数多的不同深度学习模型。丢弃率是一个超参数，需要仔细调整以平衡正则化和模型容量。建议了不同范围的丢弃率。原作者建议的丢弃率在
    0.5 和 0.8 之间 Srivastava 等 ([2014](#bib.bib230))，而其他人推荐的丢弃率较低，在 0.1 和 0.3 之间 Park
    和 Kwak ([2017](#bib.bib190))。此外，由于训练数据量的指数增加，也建议了较低的丢弃率 Liu 等 ([2023b](#bib.bib152))。
- en: Parameter norm penalty is a regularization method that adds a penalty term consisting
    of the network’s weights to the loss function. During the training, the penalty
    term discourages large weight values and hence, constraining the model’s capacity
    and reducing the chance of overfitting. The common penalty terms are $L^{1}$ norm
    penalty Tibshirani ([1996](#bib.bib250)), $L^{2}$ norm penalty, also known as
    weight decay and a combination of $L^{1}$ and $L^{2}$ Zou and Hastie ([2005](#bib.bib308)).
    An adaptive weight decay is proposed allowing the regularization strength for
    each weight to be dynamically adjusted Nakamura and Hong ([2019](#bib.bib176)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 参数范数惩罚是一种正则化方法，它将包含网络权重的惩罚项添加到损失函数中。在训练过程中，惩罚项会抑制较大的权重值，从而约束模型的容量并减少过拟合的可能性。常见的惩罚项包括
    $L^{1}$ 范数惩罚 Tibshirani ([1996](#bib.bib250))，$L^{2}$ 范数惩罚，也称为权重衰减，以及 $L^{1}$
    和 $L^{2}$ 的组合 Zou 和 Hastie ([2005](#bib.bib308))。提出了一种自适应权重衰减方法，允许动态调整每个权重的正则化强度
    Nakamura 和 Hong ([2019](#bib.bib176))。
- en: Despite the advantages of the mini-batch gradient descent, each mini-batch may
    comprise data from different distributions. Furthermore, the data distribution
    may change after each weight update, which could slow down the training process.
    Batch normalization overcomes this issue by normalizing the summed input to a
    neuron over a mini batch of training instances Ioffe and Szegedy ([2015](#bib.bib104)).
    An alternative method is to perform normalization across the neurons instead of
    the mini batch, a method known as layer normalization Ba et al. ([2016](#bib.bib15)).
    Layer normalization is applicable in recurrent neural network and overcomes the
    dependencies on the mini batch size.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管迷你批量梯度下降有其优势，但每个迷你批量可能包含来自不同分布的数据。此外，每次权重更新后数据分布可能发生变化，这可能会减慢训练过程。批量归一化通过对每个迷你批量的神经元输入进行归一化来解决这个问题
    Ioffe 和 Szegedy ([2015](#bib.bib104))。另一种方法是对神经元进行归一化，而不是对迷你批量进行，这种方法被称为层归一化 Ba
    等 ([2016](#bib.bib15))。层归一化适用于递归神经网络，并克服了对迷你批量大小的依赖。
- en: 3 Types of Deep Learning
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 种深度学习
- en: Deep learning models can be categorized into deep supervised learning and deep
    unsupervised learning.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型可以分为深度监督学习和深度无监督学习。
- en: 3.1 Deep Supervised Learning
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 深度监督学习
- en: Deep supervised models are trained with a labelled dataset. The learning process
    of these models involve calculating the prediction error through a loss function
    and utilizing the error to adjust the weights iteratively until the prediction
    error is minimized. Among the deep supervised models, three important models are
    identified namely multilayer perceptron, convolutional neural network and recurrent
    neural network.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 深度监督模型使用标记数据集进行训练。这些模型的学习过程涉及通过损失函数计算预测误差，并利用误差迭代调整权重，直到预测误差最小化。在深度监督模型中，确定了三种重要的模型，即多层感知器、卷积神经网络和递归神经网络。
- en: Multilayer perceptron is a neural network model with one or more hidden fully-connected
    layers stacked between the input and output layers as shown in Fig. [6](#S3.F6
    "Figure 6 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications"). The width (number of neurons)
    of the hidden layers and the depth (number of layers) of the network influence
    the model’s ability to learn patterns in the data. Specifically, the width determines
    the model’s ability to learn complex features while the depth allows the model
    to learn hierarchical representations of the data. Nevertheless, studies showed
    that a multilayer perceptron with a single hidden layer can approximate any continuous
    function Cybenko ([1989](#bib.bib41)), Hornik et al. ([1989](#bib.bib92)). Multilayer
    perceptron is effective in various industries and applications from healthcare
    to finance Widrow et al. ([1994](#bib.bib271)). However, multilayer perceptron
    requires the input data to be structured in a one-dimensional format e.g. tabular
    data, making it less suitable for unstructured data such as image, text and speech.
    To leverage multilayer perceptron for unstructured data, a feature extraction
    or transformation into structured data is necessary.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知器是一种神经网络模型，其输入层和输出层之间堆叠有一个或多个隐藏的全连接层，如图[6](#S3.F6 "Figure 6 ‣ 3.1 Deep Supervised
    Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications")所示。隐藏层的宽度（神经元的数量）和网络的深度（层数）影响模型学习数据模式的能力。具体而言，宽度决定了模型学习复杂特征的能力，而深度则使模型能够学习数据的层次表示。然而，研究表明，具有单一隐藏层的多层感知器可以近似任何连续函数
    Cybenko ([1989](#bib.bib41))，Hornik 等 ([1989](#bib.bib92))。多层感知器在从医疗保健到金融等各个行业和应用中都非常有效
    Widrow 等 ([1994](#bib.bib271))。然而，多层感知器要求输入数据以一维格式结构化，例如表格数据，这使得它不太适用于图像、文本和语音等非结构化数据。为了利用多层感知器处理非结构化数据，需要进行特征提取或转换为结构化数据。
- en: '![Refer to caption](img/6a042be0ee4e3f0b0684a94b2cee22b2.png)'
  id: totrans-91
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6a042be0ee4e3f0b0684a94b2cee22b2.png)'
- en: 'Figure 6: A fully-connected neural network.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一个全连接神经网络。
- en: Recurrent Neural Network is a neural network model that leverages the sequential
    information and memory through the use of recurrent connections, allowing it to
    effectively process data such as time series, text, speech and other sequential
    patterns. As shown in Fig. [7](#S3.F7 "Figure 7 ‣ 3.1 Deep Supervised Learning
    ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications"),
    a recurrent neural network is characterized by the recurrent connection which
    enables the network to loop back and use internal state from previous time step
    to the next time step. The internal state is parameterized by a set of weights
    which is shared across the sequence of the data. The training of recurrent neural
    networks suffers from the issue of vanishing gradient due to the challenges of
    propagation of gradients over a long sequence of data. Variants of recurrent neural
    networks are introduced to overcome the problem of vanishing gradient such as
    long short-term memory Hochreiter and Schmidhuber ([1997](#bib.bib91)) and gated
    recurrent memory Cho et al. ([2014](#bib.bib38)). The improved recurrent neural
    networks introduce memory cell and gating mechanisms to retain and discard information
    in every time step, allowing for more effective learning dependencies in long
    sequence. The network architecture can be built using fully-connected and convolutional
    layers Shi et al. ([2015](#bib.bib221)).
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 循环神经网络是一种通过使用递归连接来利用序列信息和记忆的神经网络模型，使其能够有效地处理时间序列、文本、语音和其他序列模式的数据。如图[7](#S3.F7
    "Figure 7 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications")所示，循环神经网络的特点是递归连接，这使得网络能够回溯并使用来自前一个时间步的内部状态到下一个时间步。内部状态由一组权重参数化，这些权重在数据序列中是共享的。循环神经网络的训练面临梯度消失的问题，因为在长序列数据上梯度传播的挑战。为了克服梯度消失的问题，引入了循环神经网络的变体，例如长短期记忆（LSTM）Hochreiter和Schmidhuber（[1997](#bib.bib91)）和门控递归记忆（GRU）Cho等（[2014](#bib.bib38)）。改进后的循环神经网络引入了记忆单元和门控机制，以保留和丢弃每个时间步的信息，从而在长序列中实现更有效的学习依赖。网络架构可以使用全连接层和卷积层来构建Shi等（[2015](#bib.bib221)）。
- en: '![Refer to caption](img/30f2be459d35aa7d20777db55b1b8a30.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/30f2be459d35aa7d20777db55b1b8a30.png)'
- en: 'Figure 7: A neural network with recurrent connection.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：具有递归连接的神经网络。
- en: Convolutional Neural Network (CNN) is a neural network model that preserves
    and leverages the spatial local information in the data through the use of convolutional
    layers. Fig. [8](#S3.F8 "Figure 8 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of
    Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications")
    shows a typical architecture of convolutional neural network which comprises of
    convolutional, pooling and fully-connected layers. The convolutional and pooling
    layers are stacked alternately to automatically extract salient features in a
    hierarchical manner. The extracted features are then fed to fully-connected layers
    to predict the outputs. The final feature maps need to be converted to one-dimensional
    vector before they are fed to the fully-connected layers. The conversion can be
    performed by flattening the feature maps. CNN architecture is crucial in increasing
    the performance of the prediction, as it is designed to efficiently extract the
    feature representation of the input data, enabling more accurate and robust pattern
    recognition. Over the last decade, several CNN architectures have been proposed,
    whereby the focus of the improvements has been on enhancing the feature learning
    capabilities and addressing challenges such as vanishing gradient and diminishing
    feature reuse.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）是一种通过使用卷积层来保持和利用数据中的空间局部信息的神经网络模型。图[8](#S3.F8 "Figure 8 ‣ 3.1 Deep
    Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning and
    State-of-the-art Applications")展示了卷积神经网络的典型架构，包括卷积层、池化层和全连接层。卷积层和池化层交替堆叠，以分层方式自动提取显著特征。提取的特征随后输入全连接层以预测输出。最终的特征图需要在输入全连接层之前转换为一维向量，这可以通过展平特征图来完成。CNN架构在提高预测性能方面至关重要，因为它旨在高效提取输入数据的特征表示，从而实现更准确和鲁棒的模式识别。在过去十年中，提出了几种CNN架构，改进的重点是增强特征学习能力，并解决如梯度消失和特征重用减少等挑战。
- en: '![Refer to caption](img/6e0c29248edf84679fb5ff09b7016d4d.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6e0c29248edf84679fb5ff09b7016d4d.png)'
- en: 'Figure 8: A neural network with convolutional and pooling layers followed by
    fully-connected layers.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：一个包含卷积和池化层的神经网络，随后是全连接层。
- en: AlexNet is among the first CNN models that gained widespread recognition and
    success, marking a significant achievement in the field of deep learning for computer
    vision tasks Krizhevsky et al. ([2012](#bib.bib120)). The model consists of five
    convolutional layers with max-pooling operation performed after the first and
    second convolutional layers, followed by three fully-connected layers. The first
    and second convolutional layers utilize a filter size of 11×11 and 5×5 respectively,
    and $3\times 3$ filter size is used for the remaining convolutional layers. ReLU
    activation function is used to mitigate the vanishing gradient.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: AlexNet 是最早获得广泛认可和成功的 CNN 模型之一，标志着计算机视觉任务深度学习领域的一个重要成就 Krizhevsky 等人 ([2012](#bib.bib120))。该模型由五个卷积层组成，在第一个和第二个卷积层后执行最大池化操作，然后是三个全连接层。第一和第二个卷积层使用
    11×11 和 5×5 的滤波器尺寸，剩余卷积层使用 $3\times 3$ 的滤波器尺寸。ReLU 激活函数用于缓解梯度消失。
- en: VGG-16 attempts to improve the CNN architecture by adding more convolutional
    layers, specifically up to 19 layers to capture more intricate feature representation
    from input data, followed by three fully-connected layers Simonyan and Zisserman
    ([2015](#bib.bib224)). ReLU activation function is used to reduce vanishing gradient.
    Unlike AlexNet, all convolutional layers utilize a small fix filter size of $3\times
    3$ and max-pooling layer is added after a stack of two or three convolutional
    layers. This configuration allows the model to extract more discriminative features
    and decreases the number of parameters.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: VGG-16 通过添加更多卷积层来改进 CNN 架构，特别是多达 19 层，以从输入数据中捕捉更复杂的特征表示，之后是三个全连接层 Simonyan 和
    Zisserman ([2015](#bib.bib224))。使用 ReLU 激活函数来减少梯度消失。与 AlexNet 不同，所有卷积层均使用小的固定滤波器尺寸
    $3\times 3$，并且在两到三层卷积层堆叠后添加了最大池化层。这种配置使模型能够提取更具判别性的特征，并减少了参数数量。
- en: ZFNet is a classic CNN model which has a similar architectural principle as
    AlexNet, featuring five convolutional layers with max-pooling layers after the
    first and second convolution, followed by three fully-connected layers Zeiler
    and Fergus ([2013](#bib.bib291)). The significant differences are the use of smaller
    filter size and stride in the convolutional layers and contrast normalization
    of the feature maps which allows the model to capture better features and improving
    the overall performance.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: ZFNet 是一个经典的 CNN 模型，其架构原理与 AlexNet 相似，具有五个卷积层，其中第一个和第二个卷积层后面跟有最大池化层，然后是三个全连接层
    Zeiler 和 Fergus ([2013](#bib.bib291))。主要区别在于卷积层使用了更小的滤波器尺寸和步幅，以及对特征图进行对比度归一化，这使得模型能够捕捉到更好的特征，从而提升整体性能。
- en: Network-in-network introduces two innovative concepts to enhance the performance
    of the model Lin et al. ([2014](#bib.bib139)). The first was introducing a block
    of convolutional layers consisting of k×k convolution followed by two $1\times
    1$ convolution operations. The pointwise convolutions are similar to applying
    multilayer perceptron on the feature maps, allowing the model to approximate more
    abstract feature representation. In the preceding models, the final feature maps
    are vectorized by flattening operation for classification by the fully-connected
    layers. Instead of flattening, network-in-network model calculates the spatial
    average of each feature map, and the resulting vector is fed to softmax function
    for classification. This approach is parameter-less, significantly reducing the
    number of parameters.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: Network-in-network 引入了两个创新概念以增强模型性能 Lin 等人 ([2014](#bib.bib139))。第一个是引入了一个卷积层块，包括
    k×k 卷积，之后是两个 $1\times 1$ 卷积操作。点卷积类似于在特征图上应用多层感知机，使模型能够近似更抽象的特征表示。在前述模型中，最终的特征图通过展平操作向量化，由全连接层进行分类。Network-in-network
    模型则计算每个特征图的空间平均值，将结果向量送入 softmax 函数进行分类。这种方法是无参数的，显著减少了参数数量。
- en: GoogleNet leverages the fact that visual data can be represented at different
    scales by incorporating a module which consists of multiple convolutional pipelines
    with different filter sizes Szegedy et al. ([2014](#bib.bib239)). The module known
    as inception utilizes three kernel sizes ($5\times 5$, $3\times 3$, $1\times 1$)
    to capture spatial and channel information at different scales of resolution as
    shown in Fig. [9](#S3.F9 "Figure 9 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of
    Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    This configuration enables a more effective feature extraction at both fine-grained
    and coarse-grained information from input data. The model architecture utilizes
    the inception module at the higher layers while the traditional convolution and
    max-pooling block is used to extract primitive and basic features. The inception
    modules are stacked upon each other with maximum pooling operation is performed
    occasionally to reduce the spatial resolution of the feature maps. GoogleNet utilizes
    global average pooling to vectorize the final feature maps before passing it to
    a fully-connected layer for classification.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: GoogleNet 利用视觉数据可以在不同尺度下表示的事实，通过引入一个由多个具有不同滤波器尺寸的卷积管道组成的模块，Szegedy 等人 ([2014](#bib.bib239))。这个被称为
    inception 的模块利用三种核大小（$5\times 5$、$3\times 3$、$1\times 1$）来捕捉不同分辨率尺度的空间和通道信息，如图
    [9](#S3.F9 "Figure 9 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning
    ‣ A Survey on Deep Learning and State-of-the-art Applications") 所示。这种配置能够更有效地从输入数据中提取细粒度和粗粒度的信息。模型架构在较高层使用
    inception 模块，而传统的卷积和最大池化块则用于提取原始和基本特征。Inception 模块相互堆叠，偶尔进行最大池化操作，以减少特征图的空间分辨率。GoogleNet
    使用全局平均池化来将最终的特征图向量化，然后传递给全连接层进行分类。
- en: '![Refer to caption](img/66b59193bdf18abc2d17bc9a71d9a666.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/66b59193bdf18abc2d17bc9a71d9a666.png)'
- en: 'Figure 9: The inception module.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '图 9: Inception 模块。'
- en: Increasing the number of layers enhances the model performance, mainly for solving
    complex tasks. However, training a very deep neural network is challenging due
    to the vanishing gradient problem, where the gradients that are used to update
    the network become insignificant or extremely small as they are backpropagated
    from the output layer to the earlier layers. A model called Highway Network overcomes
    this issue by introducing a gating mechanism that regulates the information flow
    of the layers, enabling the flow of information from the earlier layers to the
    later layers Srivastava et al. ([2015](#bib.bib232)). Consequently, this not only
    mitigates the vanishing gradient problem, but also renders the gradient-based
    training more tractable, enabling the training of very deep neural networks consisting
    as many as 100 layers.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 增加层数可以提升模型性能，尤其是解决复杂任务。然而，训练一个非常深的神经网络是具有挑战性的，因为梯度消失问题，即用于更新网络的梯度在从输出层反向传播到早期层时变得微不足道或极小。一个叫做
    Highway Network 的模型通过引入一个门控机制来调节层之间的信息流，从而克服了这个问题，使信息能够从早期层流向后期层，Srivastava 等人
    ([2015](#bib.bib232))。因此，这不仅缓解了梯度消失问题，还使基于梯度的训练更具可操作性，使得训练深达 100 层的神经网络成为可能。
- en: The gating mechanism of Highway Network increases the number of parameters for
    regulating the information flow. ResNet is a CNN architecture that incorporates
    residual (skip) connection that allows information to bypass certain layers, mitigating
    the vanishing gradient problem He et al. ([2015](#bib.bib81)). ResNet architecture
    stacks residual blocks, which consists of two or three of convolutional layers
    with batch normalization and ReLU, and a skip connection which adds the input
    to the output of the final convolutional layer as shown in Fig. [10](#S3.F10 "Figure
    10 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep
    Learning and State-of-the-art Applications"). If the input dimension does not
    match with the residual output dimension, a linear projection is performed by
    the residual connection to match the dimensions. In comparison to the gating mechanism
    of Highway Network, the residual connection is parameter-free, and thus does not
    incur additional computational costs. Furthermore, the connections are never closed
    whereby all information is always passed through the layers. This innovative concept
    enables the training of very deep neural networks boasting as many as 152 layers.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 高速公路网络的门控机制增加了调节信息流的参数数量。ResNet 是一种 CNN 架构，包含残差（跳跃）连接，使信息可以绕过某些层，从而缓解消失梯度问题
    He 等人（[2015](#bib.bib81)）。ResNet 架构堆叠了残差块，其中包括两个或三个卷积层，配有批量归一化和 ReLU，以及一个跳跃连接，该连接将输入添加到最终卷积层的输出，如图
    [10](#S3.F10 "Figure 10 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning
    ‣ A Survey on Deep Learning and State-of-the-art Applications") 所示。如果输入维度与残差输出维度不匹配，残差连接将通过线性投影来匹配维度。与高速公路网络的门控机制相比，残差连接是无参数的，因此不会增加额外的计算成本。此外，连接从未关闭，因此所有信息始终通过层。这一创新概念使得训练非常深的神经网络成为可能，网络深度可达
    152 层。
- en: '![Refer to caption](img/75f41ba3ade1e268df8e1ce6607cfb6d.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/75f41ba3ade1e268df8e1ce6607cfb6d.png)'
- en: 'Figure 10: A residual connection.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：残差连接。
- en: DenseNet is another CNN architecture that overcomes the vanishing gradient problem.
    DenseNet follows the same approach as ResNet and Highway Network, utilizing skip
    connection to allow information flow from the earlier layers to later layers.
    However, DenseNet takes this concept one step further, by introducing a dense
    block consisting of multiple convolution functions (layers) with each convolution
    function performs batch normalization followed by ReLU and $3\times 3$ convolution.
    Each convolutional layer in the dense block receives feature maps from all its
    preceding layers, hence the connection is referred to as dense connection Huang
    et al. ([2017](#bib.bib95)). This configuration as shown in Fig. [11](#S3.F11
    "Figure 11 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications") maximizes information flow
    and preserves the feed-forward nature of the network. Dense blocks can become
    computationally expensive due to the increasing number of feature maps. To reduce
    the computational costs, a block of $1\times 1$ convolutional with batch normalization
    and max-pooling layers known as transition block is used to reduce the spatial
    dimension of the feature maps. The model architecture integrates these dense and
    transition blocks, stacking them alternately. The network depth can reach up to
    264 layers.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: DenseNet 是另一种克服消失梯度问题的 CNN 架构。DenseNet 采用与 ResNet 和高速公路网络相同的方法，利用跳跃连接允许信息从早期层流向后期层。然而，DenseNet
    更进一步，引入了一个密集块，该块由多个卷积函数（层）组成，每个卷积函数执行批量归一化，随后是 ReLU 和 $3\times 3$ 卷积。密集块中的每个卷积层接收来自所有前置层的特征图，因此该连接称为密集连接
    Huang 等人（[2017](#bib.bib95)）。如图 [11](#S3.F11 "Figure 11 ‣ 3.1 Deep Supervised
    Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications") 所示，这种配置最大化了信息流并保持了网络的前馈特性。由于特征图数量的增加，密集块可能变得计算成本高昂。为了减少计算成本，使用了一个称为过渡块的
    $1\times 1$ 卷积层，配有批量归一化和最大池化层，以减少特征图的空间维度。模型架构将这些密集块和过渡块集成在一起，交替堆叠。网络深度可以达到 264
    层。
- en: '![Refer to caption](img/5051d4550d55e900302fa06badeade75.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5051d4550d55e900302fa06badeade75.png)'
- en: 'Figure 11: A dense block.'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：密集块。
- en: Although skip connections in ResNet effectively mitigate the vanishing gradient
    problem, a new challenge arises in the form of diminishing feature reuse as the
    network becomes deeper. Diminishing feature reuse refers to the diminishing effectiveness
    of the previously learned feature maps in subsequent layers, impacting the final
    prediction. WideResNet is a CNN architecture that is based on ResNet with the
    aim to mitigate diminishing feature reuse problem. Instead of making the network
    deeper, WideResNet makes the network wider by increasing the number of channels
    by k factor Zagoruyko and Komodakis ([2017](#bib.bib290)). The increased width
    allows the model to capture a more diverse features, enhancing its ability to
    learn complex relationships in the input data.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管ResNet中的跳跃连接有效缓解了梯度消失问题，但随着网络变得更深，出现了一个新的挑战，即特征重用的减少。特征重用减少指的是在后续层中，之前学习到的特征图的效果逐渐减弱，从而影响最终的预测。WideResNet是一种基于ResNet的CNN架构，旨在缓解特征重用减少的问题。WideResNet不是通过加深网络，而是通过将通道数量增加$k$因子来加宽网络
    Zagoruyko 和 Komodakis ([2017](#bib.bib290))。增加的宽度使模型能够捕捉到更多样的特征，从而增强了其学习输入数据中复杂关系的能力。
- en: ResNext addresses the diminishing feature reuse by capturing more efficient
    and diverse features of the input data. ResNext introduces a concept of cardinality
    which is loosely based on the inception module as shown in Fig. [12](#S3.F12 "Figure
    12 ‣ 3.1 Deep Supervised Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep
    Learning and State-of-the-art Applications"). The cardinality refers to the number
    of independent and identical paths, where each path performs transformation of
    the input data, divided along the channel dimension Xie et al. ([2017](#bib.bib280)).
    In other words, instead of solely relying on increasing the depth of the model,
    ResNext enhances the feature learning by parallelizing the feature extraction
    through this cardinal path. In the proposed architecture, each path configuration
    is similar to the residual block of ResNet. The output from each path is then
    aggregated to form a comprehensive and diverse representation of the input data.
    The skip connection is used to mitigate the vanishing gradient problem. WideResNet
    is a CNN architecture that is based on ResNet with the aim to mitigate diminishing
    feature reuse problem. Instead of making the network deeper, WideResNet makes
    the network wider by increasing the number of channels by $k$ factor Zagoruyko
    and Komodakis ([2017](#bib.bib290)). The increased width allows the model to capture
    a more diverse features, enhancing its ability to learn complex relationships
    in the input data.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: ResNext通过捕捉输入数据的更高效和多样的特征来解决特征重用减少的问题。ResNext引入了一个基数的概念，这一概念大致基于图 [12](#S3.F12
    "图 12 ‣ 3.1 深度监督学习 ‣ 3 种深度学习 ‣ 深度学习及其前沿应用的调查")中展示的Inception模块。基数指的是独立且相同路径的数量，每条路径对输入数据进行变换，沿通道维度划分
    Xie 等 ([2017](#bib.bib280))。换句话说，ResNext通过这种基数路径来并行化特征提取，从而增强特征学习，而不仅仅依赖于增加模型的深度。在提议的架构中，每个路径配置类似于ResNet的残差块。然后，将每个路径的输出聚合以形成输入数据的全面而多样的表示。跳跃连接用于缓解梯度消失问题。WideResNet是一种基于ResNet的CNN架构，旨在缓解特征重用减少的问题。WideResNet不是通过加深网络，而是通过将通道数量增加$k$因子来加宽网络
    Zagoruyko 和 Komodakis ([2017](#bib.bib290))。增加的宽度使模型能够捕捉到更多样的特征，从而增强了其学习输入数据中复杂关系的能力。
- en: '![Refer to caption](img/65eb220f120e4fb290dd4a605d14aa1e.png)'
  id: totrans-115
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/65eb220f120e4fb290dd4a605d14aa1e.png)'
- en: 'Figure 12: A cardinal block.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：一个基数块。
- en: 3.2 Deep Unsupervised Learning
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 深度无监督学习
- en: Deep unsupervised models are trained with an unlabelled dataset. The learning
    process of these models involve calculating the prediction error through a loss
    function and utilizing the error to adjust the weights iteratively until the prediction
    error is minimized. Among the deep supervised models, three important models are
    identified namely multilayer perceptron, convolutional neural network and recurrent
    neural network.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 深度无监督模型使用未标记的数据集进行训练。这些模型的学习过程涉及通过损失函数计算预测误差，并利用误差迭代调整权重，直到预测误差最小化。在深度监督模型中，有三个重要的模型被识别出来，即多层感知机、卷积神经网络和递归神经网络。
- en: Restricted Boltzmann Machine is a generative neural network model that learns
    a probability distribution based on a set of inputs. The model consists of a visible
    (input) layer and a hidden layer with symmetrically weighted connections as shown
    in Fig. [13](#S3.F13 "Figure 13 ‣ 3.2 Deep Unsupervised Learning ‣ 3 Types of
    Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    The input layer represents the input data with each node corresponding to a feature
    or variable while the hidden layer learns the abstract representation of the input
    data. Restricted Boltzmann machine model is trained using contrastive divergence,
    an algorithm that is based on a modified form of gradient descent, utilizing a
    sampling-based approach to estimate the gradient Hinton ([2012](#bib.bib88)).
    It has found success in solving combinative problems such as dimensionality reduction,
    collaborative filtering and topic modelling.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机是一种生成神经网络模型，它根据一组输入学习概率分布。该模型由一个可见（输入）层和一个隐藏层组成，连接具有对称权重，如图[13](#S3.F13
    "Figure 13 ‣ 3.2 Deep Unsupervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications")所示。输入层表示输入数据，每个节点对应一个特征或变量，而隐藏层学习输入数据的抽象表示。限制玻尔兹曼机模型使用对比散度进行训练，这是一种基于梯度下降修改形式的算法，利用基于采样的方法来估计梯度Hinton
    ([2012](#bib.bib88))。它在解决组合问题如降维、协同过滤和主题建模方面取得了成功。
- en: '![Refer to caption](img/6629de2d6c8cd6240487a6029f1e81a6.png)'
  id: totrans-120
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/6629de2d6c8cd6240487a6029f1e81a6.png)'
- en: 'Figure 13: A restricted Boltzmann machine.'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：限制玻尔兹曼机。
- en: Deep Belief Network can be viewed as a stack of restricted Boltzmann machines,
    comprising a visible layer and multiple hidden layers Hinton et al. ([2006](#bib.bib89))
    as shown in Fig. [14](#S3.F14 "Figure 14 ‣ 3.2 Deep Unsupervised Learning ‣ 3
    Types of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    Deep belief network has two training phases. The initial phase is known as pretraining
    in which the network is trained layer by layer, with each layer serves as a pretraining
    layer of the subsequent layers. This sequential learning allows the hidden layers
    learn complex hierarchical feature representation of the data. The second phase
    is called fine-tuning whereby the deep belief network model can be further trained
    with supervision to perform tasks such as classification and regression Hinton
    ([2009](#bib.bib87)).
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 深度信念网络可以看作是限制玻尔兹曼机的堆叠，包括一个可见层和多个隐藏层Hinton et al. ([2006](#bib.bib89))，如图[14](#S3.F14
    "Figure 14 ‣ 3.2 Deep Unsupervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications")所示。深度信念网络有两个训练阶段。初始阶段称为预训练，其中网络逐层训练，每一层作为后续层的预训练层。这种序列学习使得隐藏层能够学习数据的复杂层次特征表示。第二阶段称为微调，此时深度信念网络模型可以通过监督进一步训练，以执行分类和回归等任务Hinton
    ([2009](#bib.bib87))。
- en: '![Refer to caption](img/c0cb26ae6c79e859b470d62eccef4878.png)'
  id: totrans-123
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c0cb26ae6c79e859b470d62eccef4878.png)'
- en: 'Figure 14: A deep belief network.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：深度信念网络。
- en: Autoencoder is a generative neural network model that learns to encode the input
    data into a compressed representation and then reconstructs the original data
    from this representation. The layers that encode the input data is known as encoder
    while the layers that responsible for the reconstruction is referred to as the
    decoder as shown in Fig. [15](#S3.F15 "Figure 15 ‣ 3.2 Deep Unsupervised Learning
    ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    The encoded data (hidden layer) represents the abstract features of the input
    data also known as latent space or encoding. The decoder can be removed from the
    autoencoder, creating a standalone model that can be used for data compression
    and dimensionality reduction Romero et al. ([2017](#bib.bib209)), Li et al. ([2020c](#bib.bib136)).
    The decoder can also be replaced with predictive layers for classification task
    Mohd Noor ([2021](#bib.bib169)). The network architecture can be built using fully-connected
    and convolutional layers Li et al. ([2023](#bib.bib133)).
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 自编码器是一种生成神经网络模型，它学习将输入数据编码为压缩表示，然后从该表示中重建原始数据。编码输入数据的层称为编码器，而负责重建的层则称为解码器，如图[15](#S3.F15
    "Figure 15 ‣ 3.2 Deep Unsupervised Learning ‣ 3 Types of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications")所示。编码的数据（隐藏层）表示输入数据的抽象特征，也称为潜在空间或编码。可以从自编码器中移除解码器，创建一个独立模型，用于数据压缩和维度降低
    Romero et al. ([2017](#bib.bib209)), Li et al. ([2020c](#bib.bib136))。解码器也可以用预测层替换，用于分类任务
    Mohd Noor ([2021](#bib.bib169))。网络架构可以使用全连接层和卷积层构建 Li et al. ([2023](#bib.bib133))。
- en: '![Refer to caption](img/16acf73e7c726db9351054489dca6116.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/16acf73e7c726db9351054489dca6116.png)'
- en: 'Figure 15: An autoencoder.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '图15: 一个自编码器。'
- en: Several autoencoder variants have been introduced to improve the autoencoder’s
    ability to capture better feature representation. Some introduced penalty terms
    to the loss function such as sparsity penalty (sparse autoencoder) Ng and others
    ([2011](#bib.bib179)) to encourage sparse representation and Jacobian Frobenius
    norm (contractive autoencoder) Rifai et al. ([2011](#bib.bib206)) to be less sensitive
    to small and insignificant variations in the input data while encoding the feature
    representation. Others trained the autoencoder to recover original data from corrupted
    data with noise Vincent et al. ([2008](#bib.bib258)). An improved denoising autoencoder
    knowns marginalized denoising autoencoder has been proposed which marginalizes
    the noise by adding a term that is linked to the encoding layer Chen et al. ([2012](#bib.bib35)).
    Variational autoencoder is a variant of autoencoder that has similar architecture
    i.e. encoder, latent space and decoder. Despite the similarity, instead of learning
    a fixed encoding, variational autoencoder learns the probability distribution
    of the input data in the latent space Kingma and Welling ([2013](#bib.bib119)).
    The model can be used to generate data by sampling from the learned probability
    distribution. The network architecture can be built by stacking more than one
    fully-connected layer and convolutional layer.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高自编码器捕获更好特征表示的能力，已经引入了几种自编码器变体。一些引入了惩罚项到损失函数中，如稀疏惩罚（稀疏自编码器）Ng 和其他人 ([2011](#bib.bib179))，以鼓励稀疏表示，以及雅可比
    Frobenius 范数（收缩自编码器）Rifai et al. ([2011](#bib.bib206))，以在编码特征表示时对输入数据中的小而不重要的变化不那么敏感。其他的则训练自编码器从带噪声的损坏数据中恢复原始数据
    Vincent et al. ([2008](#bib.bib258))。一种改进的去噪自编码器，称为边际去噪自编码器，已经被提出，它通过添加一个与编码层相关的项来边际化噪声
    Chen et al. ([2012](#bib.bib35))。变分自编码器是自编码器的一种变体，具有类似的结构，即编码器、潜在空间和解码器。尽管有相似之处，变分自编码器学习的是输入数据在潜在空间中的概率分布
    Kingma 和 Welling ([2013](#bib.bib119))，而不是学习固定编码。该模型可以通过从学习到的概率分布中采样来生成数据。网络架构可以通过堆叠多个全连接层和卷积层来构建。
- en: Generative Adversarial Network (GAN) is another generative neural network model
    that is designed for generating data that adheres closely to the distribution
    of the original training set. The model consists of two different neural networks
    namely generator and discriminator as shown in Fig. [16](#S3.F16 "Figure 16 ‣
    3.2 Deep Unsupervised Learning ‣ 3 Types of Deep Learning ‣ A Survey on Deep Learning
    and State-of-the-art Applications"). The generator learns to imitate the distribution
    of the training set given a noise vector, effectively outsmarting the discriminator.
    Simultaneously during the training, the discriminator is trained to differentiate
    between the real data from the training set and synthetic data generated by the
    generator Goodfellow et al. ([2014](#bib.bib71)). This intricate dynamic between
    the networks drives an iterative learning process whereby the generator continually
    refines its ability to create synthetic data that closely resembles the real data
    while the discriminator enhances its ability to distinguish between authentic
    and fake data.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 生成对抗网络（GAN）是另一种生成神经网络模型，旨在生成与原始训练集的分布紧密相符的数据。该模型由两个不同的神经网络组成，即生成器和鉴别器，如图 [16](#S3.F16
    "图16 ‣ 3.2 深度无监督学习 ‣ 3 种深度学习 ‣ 深度学习及其最先进应用的调查") 所示。生成器学习模仿训练集的分布，给定一个噪声向量，能够有效地超越鉴别器。在训练期间，鉴别器则被训练以区分来自训练集的真实数据和生成器生成的合成数据
    Goodfellow 等人 ([2014](#bib.bib71))。这种网络间的复杂动态推动了一个迭代学习过程，其中生成器不断完善其生成与真实数据相似的合成数据的能力，而鉴别器则提升其区分真实与虚假数据的能力。
- en: '![Refer to caption](img/157d32ed19ececca5317c41965b59d95.png)'
  id: totrans-130
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/157d32ed19ececca5317c41965b59d95.png)'
- en: 'Figure 16: A generative adversarial network.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：生成对抗网络。
- en: The model can be extended by providing the labels to both generator and discriminator
    in which the model known as conditional GAN, capable of generating 1000 image
    classes Odena et al. ([2017](#bib.bib183)). Conditional GANs require a labelled
    dataset which might limit its application. InfoGAN is similar to conditional GAN,
    but the labels are substituted with latent codes, which allows the model to be
    trained in an unsupervised manner Chen et al. ([2016](#bib.bib36)). GANs often
    suffer from mode collapse whereby the model can only generate a single or small
    set of outputs. Wasserstein GAN improves the training by utilizing Wasserstein
    loss function which measures the difference between the real and synthesized data
    distribution Weng ([2019](#bib.bib270)). ProGAN tackles the training instability
    of GAN by progressively growing the generator and discriminator. The idea is that
    the model is scaled up gradually, starting with the simplest form of the problem
    and little by little the problem’s complexity is increased as the training progresses
    Karras et al. ([2018](#bib.bib112)). StyleGAN leverages the progressive GAN’s
    approach and neural style transfer to improve quality of the generated data Karras
    et al. ([2019](#bib.bib113)). The model is characterized by the independent manipulation
    of both style and content, allowing it to generate diverse styles and high quality
    data.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该模型可以通过向生成器和鉴别器提供标签来扩展，称为条件 GAN，该模型能够生成1000个图像类别 Odena 等人 ([2017](#bib.bib183))。条件
    GAN 需要一个标记数据集，这可能限制了其应用。InfoGAN 类似于条件 GAN，但标签被潜在编码替代，这使得模型能够以无监督的方式进行训练 Chen 等人
    ([2016](#bib.bib36))。GAN 经常遭遇模式崩溃，即模型只能生成单一或少量的输出。Wasserstein GAN 通过利用 Wasserstein
    损失函数来改进训练，该函数衡量真实数据与合成数据分布之间的差异 Weng ([2019](#bib.bib270))。ProGAN 通过逐步增长生成器和鉴别器来解决
    GAN 的训练不稳定性。其理念是模型逐渐扩大，从最简单的形式开始，随着训练的进展，问题的复杂性逐渐增加 Karras 等人 ([2018](#bib.bib112))。StyleGAN
    利用渐进 GAN 的方法和神经风格迁移来提高生成数据的质量 Karras 等人 ([2019](#bib.bib113))。该模型的特点是独立操作风格和内容，使其能够生成多样化风格和高质量的数据。
- en: 4 Applications of Deep Learning
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习的应用
- en: As discussed in the previous section, the application of deep learning ranges
    from computer vision Tan et al. ([2020a](#bib.bib245)), natural language processing
    Otter et al. ([2021](#bib.bib185)), healthcare Esteva et al. ([2019](#bib.bib59)),
    robotics Soori et al. ([2023](#bib.bib228)), education Hernández-Blanco et al.
    ([2019](#bib.bib86)), and many others. This section presents the applications
    of deep learning across several areas.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 正如前一节所讨论的，深度学习的应用范围从计算机视觉 Tan 等（[2020a](#bib.bib245)）、自然语言处理 Otter 等（[2021](#bib.bib185)）、医疗健康
    Esteva 等（[2019](#bib.bib59)）、机器人技术 Soori 等（[2023](#bib.bib228)）、教育 Hernández-Blanco
    等（[2019](#bib.bib86)）以及许多其他领域。本节介绍了深度学习在多个领域的应用。
- en: 4.1 Computer Vision
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 计算机视觉
- en: Computer vision is an essential field in artificial intelligence. It is a field
    of study that focuses on enabling computers to acquire, analyze and interpret
    visual inputs to derive meaningful information. The visual inputs can take many
    forms such as digital images, sequence of images or video and point cloud, and
    the source of these inputs can be camera, LiDaR, medical scanning machine etc.
    Deep learning, specifically CNN models have been widely used in real-world computer
    vision applications including image classification, object detection and image
    segmentation. This section discusses more details about the recent advancements
    in deep learning models that have been achieved over the past few years.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机视觉是人工智能中的一个重要领域。它是一个研究领域，专注于使计算机能够获取、分析和解释视觉输入，从而得出有意义的信息。这些视觉输入可以有多种形式，如数字图像、图像序列或视频和点云，这些输入的来源可以是相机、LiDaR、医疗扫描仪等。深度学习，特别是CNN模型，已广泛应用于现实世界的计算机视觉任务，包括图像分类、物体检测和图像分割。本节讨论了近年来深度学习模型取得的最新进展。
- en: 4.1.1 Image Classification
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 图像分类
- en: Image classification is a fundamental task in computer vision which involves
    categorizing an image into one of predefined classes based on the visual content.
    The objective of image classification is to enable computers or machines to differentiate
    between objects within images, in a manner similar to how humans interpret visual
    information. Image classification is a crucial component in various applications
    such as robotics, manufacturing and healthcare. LeNet-5, introduced in 1998, is
    one of the earliest convolutional neural networks that was successfully trained
    to classify handwritten digits. The model underwent a series of improvements,
    including the use of tanh and average pooling which enhanced its ability to extract
    hierarchical features, ultimately improving overall performance. The model architecture
    comprises two convolutional layers, each with an average pooling layer, followed
    by two fully-connected layers, including the output layer Lecun et al. ([1998](#bib.bib125)).
    Since then, numerous CNN models have been proposed based on LeNet-5 for image
    classification Simard et al. ([2003](#bib.bib223)); Matsugu et al. ([2003](#bib.bib165))
    but the most significant one is AlexNet in 2012 which saw a transformative breakthrough
    in deep learning. AlexNet is considered the first CNN model with a large number
    of parameters that significantly improved the performance of image classification
    on a very large dataset (ImageNet). The model won first place in ILSVRC 2012,
    improving the test error from the previous year by almost 10% Krizhevsky et al.
    ([2012](#bib.bib120)). Numerous significant CNN models have been introduced in
    subsequent ILSVRC competitions including ZFNet, VGG16, GoogleNet, ResNet and ResNext.
    In general, the research focused on increasing the number of layers, addressing
    the problem of vanishing gradient and diminishing of feature reuse.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类是计算机视觉中的一项基础任务，涉及将图像根据视觉内容分类到预定义的类别中。图像分类的目标是使计算机或机器能够区分图像中的物体，类似于人类如何解读视觉信息。图像分类在机器人、制造业和医疗保健等各种应用中都是一个关键组件。LeNet-5，1998年推出，是最早成功训练以分类手写数字的卷积神经网络之一。该模型经历了一系列改进，包括使用tanh和平均池化，增强了提取层次特征的能力，*最终*提高了整体性能。该模型架构包括两个卷积层，每个卷积层后面跟一个平均池化层，然后是两个全连接层，包括输出层Lecun等（[1998](#bib.bib125)）。从那时起，基于LeNet-5的众多CNN模型被提出用于图像分类Simard等（[2003](#bib.bib223)）；Matsugu等（[2003](#bib.bib165)），但最重要的是2012年的AlexNet，它在深度学习中取得了变革性的突破。AlexNet被认为是第一个具有大量参数的CNN模型，它显著提升了在非常大数据集（ImageNet）上的图像分类性能。该模型在ILSVRC
    2012中获得第一名，将测试错误率比前一年提高了近10% Krizhevsky等（[2012](#bib.bib120)）。随后，在ILSVRC比赛中介绍了许多重要的CNN模型，包括ZFNet、VGG16、GoogleNet、ResNet和ResNext。总体而言，研究集中在增加层数、解决梯度消失问题和特征重用的减少上。
- en: Research in image classification continues to evolve with a focus on addressing
    key challenges to improve the classification performance. One notable trend is
    the formulation of the loss function to address problems such as neglecting well-classified
    instances and imbalance distribution of class labels. In a particular study, an
    additive term is introduced to the cross-entropy loss to reward the models for
    the correctly classified instances. This formulation encourages the models to
    also pay attention to well-classified instances while focusing on the bad-classified
    ones Zhao et al. ([2022](#bib.bib300)). Another study proposes an asymmetric polynomial
    loss function using the Taylor series expansion. The loss function allows the
    training to selectively prioritize contributions of positive instances to mitigate
    the issue of imbalance between negative and positive classes Huang et al. ([2023b](#bib.bib98)).
    The asymmetric polynomial loss requires a large number of parameters to be fine-tuned
    and may lead to overfitting. A robust asymmetric loss is formulated by introducing
    a multiplicative term to control the contribution of the negative gradient and
    making it less sensitive to parameter optimization Park et al. ([2023](#bib.bib191)).
    Combining multiple deep learning models improves the overall performance by leveraging
    the diverse strengths of individual models. However, identifying the optimal combination
    is non-trivial due to the large number of hyperparameters. A straightforward method
    is to employ the weighted sum rule Nanni et al. ([2023](#bib.bib177)). To enhance
    the overall performance, an algorithm, named greedy soups, adds a model based
    on the validation accuracy Wortsman et al. ([2022](#bib.bib272)). The final prediction
    is produced via averaging. Multi-symmetry ensembles framework improves the building
    of diverse deep learning models by utilizing contrastive learning Loh et al. ([2023](#bib.bib154)).
    Then, the diverse models are sequentially combined based on their validation accuracy.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分类研究不断发展，重点是解决关键挑战以提高分类性能。一个显著的趋势是损失函数的制定，以解决诸如忽视已分类实例和类别标签分布不平衡等问题。在某项研究中，引入了一个附加项到交叉熵损失中，以奖励正确分类的实例。这种公式鼓励模型在关注分类错误的实例时，也要关注已分类正确的实例（Zhao
    et al. ([2022](#bib.bib300))）。另一项研究提出了使用泰勒级数展开的非对称多项式损失函数。该损失函数允许训练时选择性地优先考虑正实例的贡献，以缓解负类和正类之间的不平衡问题（Huang
    et al. ([2023b](#bib.bib98))）。非对称多项式损失需要大量参数进行微调，可能导致过拟合。通过引入一个乘法项来控制负梯度的贡献，并使其对参数优化的敏感度降低，制定了一种鲁棒的非对称损失（Park
    et al. ([2023](#bib.bib191))）。结合多个深度学习模型通过利用各个模型的多样化优势来提高整体性能。然而，由于超参数众多，确定最佳组合并非易事。一种直接的方法是采用加权和规则（Nanni
    et al. ([2023](#bib.bib177))）。为了增强整体性能，名为贪婪模型的算法基于验证准确性添加模型（Wortsman et al. ([2022](#bib.bib272))）。最终的预测是通过平均值产生的。多对称集合框架通过利用对比学习来改善多样化深度学习模型的构建（Loh
    et al. ([2023](#bib.bib154))）。然后，根据其验证准确性，依次组合这些多样化的模型。
- en: 'Vision transformers (ViT) offers an alternative to convolutional neural networks
    that have long been the dominant architecture for image classification, by leveraging
    self-attention mechanisms for scalable representation learning. Despite its effectiveness,
    ViT is sensitive to hyperparameter optimization and substandard performance on
    smaller datasets Xiao et al. ([2021](#bib.bib278)). Furthermore, ViT lacks the
    ability to leverage local spatial features which is inherent in convolutional
    neural networks Wu et al. ([2021](#bib.bib273)). Therefore, several studies attempt
    to incorporate convolutional layers into ViT architecture to improve its performance
    and robustness. In particular, conformer is a network architecture with two branches:
    CNN branch and a transformer branch to extract local and global features respectively
    Peng et al. ([2023](#bib.bib192)). Both branches are connected by two “bridges”
    of $1\times 1$ convolution and up or down sampling operations, allowing the branches
    to share their features and enhance the feature representation. Both branches
    output predictions which are combined to produce the final prediction. A hybrid
    architecture, named MaxViT, combines convolutional networks and vision transformer
    to address the lack of scalability issues of self-attention mechanisms when the
    model is trained on large input size Tu et al. ([2022](#bib.bib255)). The improved
    vision transformer is composed of two modules whereby the first module attends
    local features in non-overlapping image patches and the global features are attended
    by processing a grid of sparse and uniform pixels. The transformer is stacked
    with a block of convolutional layers to extract local spatial features. The architecture
    of MaxViT is shown in Figure [17](#S4.F17 "Figure 17 ‣ 4.1.1 Image Classification
    ‣ 4.1 Computer Vision ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning
    and State-of-the-art Applications"). Another study proposes a convolutional transformer
    network, introducing the depthwise convolutional block into the ViT Ma et al.
    ([2024](#bib.bib162)). This configuration allows the model to exploit the ability
    of convolutional networks to extract local spatial features while the ViT attends
    the extracted local features to focus on relevant information, enhancing the model’s
    ability to capture complex patterns and relationships.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 视觉变换器（ViT）提供了一种替代卷积神经网络（CNN）的方案，后者长期以来一直是图像分类的主导架构，通过利用自注意力机制实现可扩展的表示学习。尽管其有效性，ViT
    对超参数优化非常敏感，并且在较小的数据集上表现不佳 Xiao 等人（[2021](#bib.bib278)）。此外，ViT 缺乏利用局部空间特征的能力，而这正是卷积神经网络固有的
    Wu 等人（[2021](#bib.bib273)）。因此，许多研究尝试将卷积层整合到 ViT 架构中，以提升其性能和鲁棒性。特别是，conformer 是一种具有两个分支的网络架构：CNN
    分支和变换器分支，分别提取局部和全局特征 Peng 等人（[2023](#bib.bib192)）。两个分支通过两个 $1\times 1$ 卷积和上采样或下采样操作的“桥梁”连接，允许分支共享其特征并增强特征表示。两个分支的输出预测被结合起来生成最终预测。名为
    MaxViT 的混合架构结合了卷积网络和视觉变换器，以解决自注意力机制在大输入尺寸下训练模型时缺乏可扩展性的问题 Tu 等人（[2022](#bib.bib255)）。改进后的视觉变换器由两个模块组成，其中第一个模块关注于非重叠图像块中的局部特征，而全局特征则通过处理稀疏且均匀的像素网格来关注。变换器与一个卷积层块堆叠在一起，以提取局部空间特征。MaxViT
    的架构如图 [17](#S4.F17 "图 17 ‣ 4.1.1 图像分类 ‣ 4.1 计算机视觉 ‣ 4 深度学习应用 ‣ 深度学习及其前沿应用综述")
    所示。另一项研究提出了一种卷积变换器网络，将深度卷积块引入 ViT Ma 等人（[2024](#bib.bib162)）。这一配置使模型能够利用卷积网络提取局部空间特征，同时
    ViT 关注提取的局部特征以聚焦相关信息，从而增强模型捕捉复杂模式和关系的能力。
- en: '![Refer to caption](img/923f6720e106a765965b953111a0aa59.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/923f6720e106a765965b953111a0aa59.png)'
- en: 'Figure 17: The architecture of MaxViT Tu et al. ([2022](#bib.bib255)).'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：MaxViT Tu 等人（[2022](#bib.bib255)）的架构。
- en: 4.1.2 Object Detection
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 目标检测
- en: 'Deep learning plays a major role in significantly advancing the state-of-the-art
    in object detection performance. Region-based CNN (R-CNN) is the first breakthrough
    in object detection that combines CNN with selective region proposals Girshick
    et al. ([2014](#bib.bib69)). The region proposals are the candidate bounding boxes
    serving as the potential region of interests (objects) within the input image,
    and the CNN are used to extract features from the region proposals and classify
    the regions for object detection. An improved model, named Fast R-CNN introduces
    two prediction branches: object classification and bounding box regression which
    improves the overall performance of object detection Girshick ([2015](#bib.bib68)).
    However, R-CNN and Fast R-CNN models are computationally expensive and slow, thus
    practically infeasible for real-time applications. Addressing this issue, Fast
    R-CNN is integrated with a region proposal network, referred to as Faster R-CNN
    Ren et al. ([2015](#bib.bib205)). The region proposal network (RPN) is used to
    efficiently generate region proposals for object detection. RPN takes an input
    image and output a set of rectangle object proposals, each with a confidence score
    to indicate the likelihood of an object’s presence. To this end, RPN introduces
    the concept of anchor boxes whereby multiple bounding boxes of different aspect
    ratios are defined over the feature maps produced by the convolutional networks.
    These anchor boxes are then regressed over the feature maps to localize the objects,
    contributing to the improved speed and effectiveness of Faster R-CNN. The training
    of Faster R-CNN is divided into two stages. First the RPN is pre-trained to generate
    the region proposals and then, the Fast R-CNN is trained using the region proposals
    generated by the RPN for object detection. The backbone network responsible for
    extracting the features for Faster R-CNN is either ZFNet or VGG16.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习在显著提升目标检测性能的最前沿技术中发挥了重要作用。基于区域的CNN（R-CNN）是目标检测中的首次突破，它将CNN与选择性区域提议相结合（Girshick
    et al. ([2014](#bib.bib69))）。区域提议是候选的边界框，作为输入图像中潜在兴趣区域（目标），CNN用于从这些区域提议中提取特征并进行分类以进行目标检测。一个改进模型，名为Fast
    R-CNN，引入了两个预测分支：目标分类和边界框回归，这提高了目标检测的整体性能（Girshick ([2015](#bib.bib68))）。然而，R-CNN和Fast
    R-CNN模型计算开销大且速度慢，因此在实时应用中实际上不可行。为解决此问题，Fast R-CNN与区域提议网络集成，称为Faster R-CNN（Ren
    et al. ([2015](#bib.bib205))）。区域提议网络（RPN）用于高效生成目标检测的区域提议。RPN接收输入图像并输出一组矩形对象提议，每个提议都有一个置信度分数以指示目标存在的可能性。为此，RPN引入了锚框的概念，即在卷积网络生成的特征图上定义多个不同纵横比的边界框。这些锚框随后在特征图上回归以定位目标，从而提高了Faster
    R-CNN的速度和有效性。Faster R-CNN的训练分为两个阶段。首先，预训练RPN以生成区域提议，然后使用RPN生成的区域提议训练Fast R-CNN以进行目标检测。负责提取Faster
    R-CNN特征的骨干网络可以是ZFNet或VGG16。
- en: In two-stage object detectors, the region proposals are generated first, and
    then used for object detection. The two-stage process is computationally intensive
    and infeasible for real-time object detection applications. You Only Look Once
    or YOLO proposes a one-stage detection by directly predicting bounding boxes and
    object’s confidence score in a single forward pass through the neural network
    Redmon et al. ([2016](#bib.bib203)). This single pass architecture significantly
    reduces the computational complexity, making YOLO suitable for real-time object
    detection applications. In YOLO, the input image is divided into S×S grids, each
    grid cell is responsible for detecting the objects present in the cell. Specifically,
    each grid cell predicts multiple bounding boxes and associated object’s confidence
    score, enabling simultaneous object detection across the entire image. Subsequent
    enhancements such as YOLOv3 Redmon and Farhadi ([2018](#bib.bib204)) and YOLOv4
    Bochkovskiy et al. ([2020](#bib.bib21)) are proposed, improving the model’s capability
    and accuracy. Single Shot Multibox Detector (SSD) is another one-stage detector,
    aims to address the issue of real-time object detection Liu et al. ([2016](#bib.bib147)).
    SSD also eliminates the region proposal generation and directly predicts bounding
    boxes and confidence scores, reducing the computational complexity. To improve
    the overall performance, SSD produces the predictions from different levels of
    feature maps, allowing detection of objects of different sizes in the input image.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在两阶段目标检测器中，首先生成区域提议，然后用于目标检测。这种两阶段过程计算密集，对于实时目标检测应用是不切实际的。You Only Look Once
    或 YOLO 提出了通过在神经网络的单次前向传递中直接预测边界框和对象的置信度得分来进行一阶段检测 Redmon et al. ([2016](#bib.bib203))。这种单次传递的架构显著降低了计算复杂度，使
    YOLO 适用于实时目标检测应用。在 YOLO 中，输入图像被划分为 S×S 网格，每个网格单元负责检测单元中的对象。具体而言，每个网格单元预测多个边界框和相关对象的置信度得分，从而实现对整个图像的同时目标检测。后续的改进如
    YOLOv3 Redmon 和 Farhadi ([2018](#bib.bib204)) 和 YOLOv4 Bochkovskiy et al. ([2020](#bib.bib21))
    提高了模型的能力和准确性。Single Shot Multibox Detector (SSD) 是另一种一阶段检测器，旨在解决实时目标检测的问题 Liu
    et al. ([2016](#bib.bib147))。SSD 还消除了区域提议生成，直接预测边界框和置信度得分，从而降低计算复杂度。为了提高整体性能，SSD
    从不同级别的特征图中产生预测，使得可以检测输入图像中不同尺寸的对象。
- en: A common issue in object detection problems is the extremely imbalanced ratio
    of foreground to background classes. Addressing this issue, RetinaNet introduces
    a loss function that is based on the cross entropy called focal loss. Focal loss
    reduces the loss contribution of easily classified objects, allowing the model
    training to focus on the difficult objects Lin et al. ([2020](#bib.bib141)). RetinaNet
    adopts the Feature Pyramid Network (FPN) Lin et al. ([2017a](#bib.bib140)) with
    ResNet as the backbone network for extracting the feature maps. FPN is a network
    architecture with a pyramid structure that efficiently captures multiscale feature
    representation, facilitating object detection across various sizes. To further
    improve the overall performance, EfficientDet introduces bi-directional FPN which
    incorporates multi-level feature fusion to better capture multiscale feature representation
    Tan et al. ([2020b](#bib.bib246)). Also, the model utilizes EfficientNet Tan and
    Le ([2019](#bib.bib244)) as the backbone network to achieve a balance between
    computational efficiency and accuracy.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 在目标检测问题中，一个常见的问题是前景类与背景类的极度不平衡。为了解决这个问题，RetinaNet 引入了一种基于交叉熵的损失函数，称为焦点损失（focal
    loss）。焦点损失减少了对易于分类对象的损失贡献，使得模型训练能够集中在难以分类的对象上 Lin et al. ([2020](#bib.bib141))。RetinaNet
    采用了 Feature Pyramid Network (FPN) Lin et al. ([2017a](#bib.bib140))，以 ResNet 作为提取特征图的主干网络。FPN
    是一种具有金字塔结构的网络架构，可以高效地捕捉多尺度特征表示，从而促进各种尺寸的目标检测。为了进一步提高整体性能，EfficientDet 引入了双向 FPN，这种网络结构结合了多层特征融合，以更好地捕捉多尺度特征表示
    Tan et al. ([2020b](#bib.bib246))。此外，该模型利用 EfficientNet Tan 和 Le ([2019](#bib.bib244))
    作为主干网络，以实现计算效率与准确性之间的平衡。
- en: Object detection performance relies on a post-processing step called non-maximum
    suppression (NMS) to eliminate duplicate detections and select the most relevant
    bounding boxes. Specifically, NMS sorts all detection boxes based on their confidence
    scores, selects a box with the maximum score and discards the other boxes with
    a significant overlap with the selected box. This process is repeated on the remaining
    detection boxes. However, due to the inconsistency between the confidence score
    and the quality of object localization, NMS retains poorly localized bounding
    boxes with high confidence score while discarding more accurate predictions with
    poor confidence score. To mitigate this limitation, instead of discarding the
    neighboring boxes with significant overlap, soft-NMS applies Gaussian function
    to lower their confidence scores Bodla et al. ([2017](#bib.bib22)). The idea is
    not to discard the neighboring bounding boxes, but gradually decline their scores
    based on the extend of the overlap with the selected box. This results in a smoother
    suppression, preserving the better-localized bounding boxes. Adaptive NMS introduces
    an adaptive threshold for the suppression of bounding boxes Liu et al. ([2019a](#bib.bib145)).
    The algorithm dynamically adjusts the threshold based on the level of overlapping
    of the selected box with the other bounding boxes.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 物体检测性能依赖于一个称为非极大值抑制（NMS）的后处理步骤，以消除重复检测并选择最相关的边界框。具体而言，NMS根据置信度分数对所有检测框进行排序，选择具有最高分数的框，并丢弃与所选框有显著重叠的其他框。这个过程会在剩余的检测框上重复进行。然而，由于置信度分数与物体定位质量之间的不一致，NMS保留了置信度分数高但定位差的边界框，同时丢弃了置信度分数低但更准确的预测。为了缓解这一限制，soft-NMS不再丢弃重叠显著的邻近框，而是应用高斯函数来降低它们的置信度分数（Bodla
    et al. [2017](#bib.bib22)）。这个方法的思想是逐渐降低邻近边界框的分数，而不是直接丢弃它们，降低的幅度根据与所选框的重叠程度来决定。这种方法使抑制过程更加平滑，保留了定位更好的边界框。自适应NMS引入了一种自适应阈值来抑制边界框（Liu
    et al. [2019a](#bib.bib145)）。该算法根据所选框与其他边界框的重叠程度动态调整阈值。
- en: Detection Transformer (DeTR) is an end-to-end trainable object detection model
    that leverages the transformer architecture to eliminates the need for handcrafted
    components such as anchor boxes and non-maximum suppression Carion et al. ([2020](#bib.bib28)).
    The self-attention mechanism of the transformer captures the global context and
    relationships between different parts of the image, allowing it to localize the
    objects and remove duplicate predictions. The model is trained with a set of loss
    functions that perform bipartite matching between the predicted and ground truth
    objects. DeTR uses ResNet as backbone network. Despite the success of DeTR in
    simplifying and improving object detection tasks, DeTR suffers from a long training
    time and low performance at detecting small objects due to its reliance on self-attention
    mechanism of the transformer, which lacks a multiscale feature representation.
    To mitigate this limitation, Deformable DeTR introduces a multiscale deformable
    attention module which can effectively capture feature representation at different
    scales Zhu et al. ([2020](#bib.bib305)). Furthermore, the attention module leverages
    deformable convolution, allowing the model to adapt to spatial variation and capture
    more informative features in the input data. Dynamic DeTR addresses the same issues
    by utilizing a deformable convolution-based FPN to learn multiscale feature representation
    Dai et al. ([2021](#bib.bib43)). Moreover, the model replaces the transformer
    encoder with a convolution-based encoder to attend to various spatial features
    and channels. This modification allows the model to effectively detect small objects
    and converge faster during training. The architecture of dynamic DeTR is shown
    in Figure [18](#S4.F18 "Figure 18 ‣ 4.1.2 Object Detection ‣ 4.1 Computer Vision
    ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications"). A training scheme known as Teach-DeTR is proposed to improve the
    overall performance of DeTR Huang et al. ([2023a](#bib.bib97)). The training scheme
    leverages the predicted bounding boxes by other object detection models during
    the training by calculating the loss of one-to-one matching between the object
    queries and the predicted boxes.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 检测变换器（DeTR）是一个端到端可训练的目标检测模型，利用变换器架构消除了对手工制作组件的需求，例如锚点框和非极大值抑制 Carion et al.
    ([2020](#bib.bib28))。变换器的自注意力机制捕捉了图像的全局上下文和不同部分之间的关系，使其能够定位目标并去除重复预测。该模型通过一组损失函数进行训练，执行预测对象和真实对象之间的二分匹配。DeTR使用ResNet作为骨干网络。尽管DeTR在简化和改进目标检测任务方面取得了成功，但由于依赖于变换器的自注意力机制，缺乏多尺度特征表示，DeTR在检测小物体时表现不佳且训练时间较长。为了缓解这一限制，Deformable
    DeTR引入了一个多尺度可变形注意力模块，能够有效捕捉不同尺度的特征表示 Zhu et al. ([2020](#bib.bib305))。此外，该注意力模块利用了可变形卷积，使模型能够适应空间变化并捕捉输入数据中的更多信息特征。Dynamic
    DeTR通过利用基于可变形卷积的FPN学习多尺度特征表示来解决相同的问题 Dai et al. ([2021](#bib.bib43))。此外，该模型用基于卷积的编码器替代了变换器编码器，以关注各种空间特征和通道。这一修改使模型能够有效检测小物体，并在训练期间更快收敛。dynamic
    DeTR的架构如图 [18](#S4.F18 "Figure 18 ‣ 4.1.2 Object Detection ‣ 4.1 Computer Vision
    ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications")所示。提出了一种称为Teach-DeTR的训练方案，以提高DeTR的整体性能 Huang et al. ([2023a](#bib.bib97))。该训练方案在训练过程中利用其他目标检测模型预测的边界框，通过计算目标查询与预测框之间的一对一匹配损失。
- en: '![Refer to caption](img/08af40c870cb092d40d615ddccd75cab.png)'
  id: totrans-149
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08af40c870cb092d40d615ddccd75cab.png)'
- en: 'Figure 18: The architecture of dynamic DeTR Dai et al. ([2021](#bib.bib43)).'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '图18: dynamic DeTR的架构 Dai et al. ([2021](#bib.bib43))。'
- en: 4.1.3 Image Segmentation
  id: totrans-151
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 图像分割
- en: 'Image segmentation is another important task in which deep learning has a significant
    impact. One of the earliest deep learning models for image segmentation is the
    fully convolutional network Long et al. ([2015](#bib.bib155)). A fully convolutional
    network consists of only convolutional layers which accepts an input of an arbitrary
    size and produce the predicted segmentation map of the same size. The authors
    adopt the AlexNet, VGG16 and GoogleNet, replace their fully connected layers with
    convolutional layers and append a 1×1 convolutional layer, followed by bilinear
    up-sampling to match the size of the input. The model was considered a significant
    milestone in image segmentation, demonstrating the feasibility of deep learning
    for semantic segmentation trained in end-to-end manner. Deconvolution network
    is another popular deep learning model for semantic segmentation Noh et al. ([2015](#bib.bib182)).
    The model architecture consists of two parts: encoder and decoder. The encoder
    takes an input image and uses the convolutional layers to generate the feature
    maps. The feature maps are fed to the decoder composed of un-sampling and deconvolutional
    layers to predict the segmentation map. SegNet is another encoder-decoder model
    for semantic segmentation Badrinarayanan et al. ([2017](#bib.bib16)). The encoder
    is a sequence of convolutional (with ReLU) and max-pooling blocks which is analogous
    to a convolutional neural network. The decoder is composed of up-sampling layers
    which up-samples the inputs using the memorized pooled indices generated in the
    encoder phase, and convolutional layers without non-linearity. The encoder progressively
    reduces the resolution of the input data while extracting abstract features through
    a series of convolutional and pooling layers. This process causes the loss of
    fine-grained information, degrading the overall performance of segmentation. LinkNet
    mitigates this limitation by passing the feature maps at several stages generated
    by the encoder to the decoder, hence reducing information loss Chaurasia and Culurciello
    ([2017](#bib.bib30)). The model architecture of LinkNet is similar to SegNet,
    but utilizes ResNet as the encoder.'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 图像分割是另一个深度学习产生重要影响的任务之一。最早的图像分割深度学习模型之一是完全卷积网络 Long 等人 ([2015](#bib.bib155))。完全卷积网络只包含卷积层，它接受任意大小的输入，并生成相同大小的预测分割图。作者采用了
    AlexNet、VGG16 和 GoogleNet，将它们的全连接层替换为卷积层，并添加了一个 1×1 卷积层，随后进行双线性上采样以匹配输入的大小。该模型被认为是图像分割领域的重要里程碑，展示了深度学习在端到端训练的语义分割中的可行性。反卷积网络是另一个流行的语义分割深度学习模型
    Noh 等人 ([2015](#bib.bib182))。该模型架构由两个部分组成：编码器和解码器。编码器接受输入图像，并使用卷积层生成特征图。特征图被送到由上采样和反卷积层组成的解码器中，以预测分割图。SegNet
    是另一个用于语义分割的编码器-解码器模型 Badrinarayanan 等人 ([2017](#bib.bib16))。编码器是一个卷积（使用 ReLU）和最大池化块的序列，类似于卷积神经网络。解码器由上采样层组成，这些上采样层利用在编码器阶段生成的记忆池化索引对输入进行上采样，以及没有非线性的卷积层。编码器通过一系列卷积和池化层逐步减少输入数据的分辨率，同时提取抽象特征。这一过程导致细粒度信息的丢失，从而降低了分割的整体性能。LinkNet
    通过将编码器生成的几个阶段的特征图传递给解码器，从而减少了信息丢失，缓解了这一限制 Chaurasia 和 Culurciello ([2017](#bib.bib30))。LinkNet
    的模型架构类似于 SegNet，但使用 ResNet 作为编码器。
- en: While Faster R-CNN is a significant approach in object detection task, it has
    been extended to perform instance segmentation task. One such extension is Mask
    R-CNN which is based on Faster R-CNN, introduces an additional branch for predicting
    the segmentation mask He et al. ([2017](#bib.bib80)). Similar to Faster R-CNN,
    Mask R-CNN utilizes the RPN to generate region proposals and then the region of
    interest alignment is applied to extract more accurate features from the proposed
    regions. Mask R-CNN does not leverage the multiscale feature representation which
    may degrade the overall performance of segmentation. To overcome this limitation,
    Path Aggregation Network (PANet) incorporates the FPN and introduces a bottom-up
    pathway to facilitate the propagation of the low-level information Liu et al.
    ([2018](#bib.bib146)). The pathway takes the feature maps of the previous stage
    as input and performs 3×3 convolution with stride 2 to reduce the spatial size
    of the feature maps. The generated feature maps are then fused with the feature
    maps from the FPN through the lateral connection. The model adopts the three branches
    as in Mask R-CNN. MaskLab is an instance segmentation model based on Faster R-CNN,
    consisting of object detection, segmentation and instance (object) center direction
    prediction branches Chen et al. ([2018](#bib.bib34)). The direction prediction
    provides useful information to distinguish instances of the same semantic label,
    allowing the model to further refine the instance segmentation results.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Faster R-CNN 是一个在目标检测任务中具有重要意义的方法，但它已经扩展到执行实例分割任务。其中一种扩展是 Mask R-CNN，它基于
    Faster R-CNN，引入了一个额外的分支用于预测分割掩膜 He 等人 ([2017](#bib.bib80))。与 Faster R-CNN 相似，Mask
    R-CNN 利用 RPN 生成区域建议，然后应用兴趣区域对齐从建议的区域中提取更准确的特征。Mask R-CNN 不利用多尺度特征表示，这可能会降低分割的整体性能。为了解决这一限制，Path
    Aggregation Network (PANet) 结合了 FPN，并引入了一个自下而上的路径，以促进低级信息的传播 Liu 等人 ([2018](#bib.bib146))。该路径将前一阶段的特征图作为输入，并执行
    3×3 卷积，步幅为 2，以减少特征图的空间大小。生成的特征图随后通过横向连接与 FPN 的特征图融合。该模型采用了与 Mask R-CNN 相同的三个分支。MaskLab
    是一个基于 Faster R-CNN 的实例分割模型，包括目标检测、分割和实例（对象）中心方向预测分支 Chen 等人 ([2018](#bib.bib34))。方向预测提供了有用的信息来区分相同语义标签的实例，使模型能够进一步优化实例分割结果。
- en: 'Attention mechanisms have been integrated into the segmentation models to learn
    the weights of multiscale features at each pixel location. A multistage context
    refinement network introduces a context attention refinement module that is composed
    of two parts, context feature extraction and context feature refinement Liu et al.
    ([2023a](#bib.bib144)). The context feature extraction captures both local and
    global context information, fuses both contextual information and passes it to
    the context feature refinement while the context feature refinement removes redundant
    information and generates a refined feature representation, improving the utilization
    of contextual information. The context attention is added to the skip connection
    between the encoder and the decoder. Handcrafted features are often abandoned
    for automatic feature extraction using convolutional networks. However, it is
    argued that the interpretability and domain-specific knowledge embedded in handcrafted
    features can provide valuable insights. To this end, an attention module based
    on the covariance statistic is introduced to model the dependencies between local
    and global context of the input image Liu et al. ([2022](#bib.bib149)). Two types
    of attention are introduced: spatial covariance attention focuses on the spatial
    distribution and channel covariance attention attends to the important channels.
    Furthermore, the covariance attention does not require feature shape conversion,
    hence significantly reducing the space and time complexity of the model.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制已经被集成到分割模型中，以学习每个像素位置的多尺度特征权重。一个多阶段上下文精炼网络引入了一个上下文注意力精炼模块，该模块由两个部分组成：上下文特征提取和上下文特征精炼
    Liu 等人 ([2023a](#bib.bib144))。上下文特征提取捕获局部和全局上下文信息，融合这些上下文信息并将其传递给上下文特征精炼，同时上下文特征精炼去除冗余信息，生成精炼的特征表示，从而提高上下文信息的利用率。上下文注意力被添加到编码器和解码器之间的跳跃连接中。手工特征通常被自动特征提取的卷积网络所取代。然而，有人认为手工特征中嵌入的可解释性和领域特定知识可以提供有价值的见解。为此，引入了基于协方差统计的注意力模块来建模输入图像的局部和全局上下文之间的依赖关系
    Liu 等人 ([2022](#bib.bib149))。引入了两种类型的注意力：空间协方差注意力关注空间分布，而通道协方差注意力关注重要的通道。此外，协方差注意力不需要特征形状转换，因此显著降低了模型的空间和时间复杂度。
- en: The convolutional layers use local receptive fields to process input data which
    can be effective for exploiting spatial patterns and hierarchical features but
    may find it difficult to capture global relationships across the entire image.
    The ViT has been leveraged to mitigate this issue in semantic segmentation Strudel
    et al. ([2021](#bib.bib235)). Specifically, the input image is divided into patches
    and treated as input to the transformer to capture the global relationship between
    the patches, significantly improving the prediction of the segmentation map. Global
    context ViT aims to address the lack of ViT’s ability to leverage local spatial
    features Hatamizadeh et al. ([2023](#bib.bib79)). As shown in Figure [19](#S4.F19
    "Figure 19 ‣ 4.1.3 Image Segmentation ‣ 4.1 Computer Vision ‣ 4 Applications of
    Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications"),
    the transformer consists of local and global self-attention modules. The role
    of global self-attention is to capture the global contextual information from
    different image regions while the short-range information is captured by the local
    self-attention. Multiscale feature representation is crucial for accurate semantic
    segmentation. However, the transformer often combines the features without considering
    their appropriate (optimal) scales, thus affecting the segmentation accuracy.
    Transformer scale gate is a module proposed to address the issue of selecting
    an appropriate scale based on the correlation between patch-query pairs Huang
    et al. ([2023a](#bib.bib97)). The transformer takes attention (correlation) maps
    as input and calculates the weights of the multi-scale features for each image
    patch, allowing the model to adaptively choose the optimal scale for each patch.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积层使用局部感受野处理输入数据，这对于利用空间模式和层次特征可能很有效，但可能难以捕捉整个图像的全局关系。ViT 已被用来缓解这一问题，在语义分割中
    Strudel 等人 ([2021](#bib.bib235))。具体来说，输入图像被划分为若干补丁，并作为输入提供给变换器，以捕捉补丁之间的全局关系，从而显著提高分割图的预测。全球上下文
    ViT 旨在解决 ViT 无法利用局部空间特征的问题 Hatamizadeh 等人 ([2023](#bib.bib79))。如图 [19](#S4.F19
    "Figure 19 ‣ 4.1.3 Image Segmentation ‣ 4.1 Computer Vision ‣ 4 Applications of
    Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications")
    所示，变换器由局部和全局自注意力模块组成。全局自注意力的作用是从不同的图像区域捕捉全局上下文信息，而局部自注意力则捕捉短距离信息。多尺度特征表示对于准确的语义分割至关重要。然而，变换器通常在不考虑适当（最佳）尺度的情况下组合特征，从而影响分割精度。变换器尺度门是一个旨在解决基于补丁查询对之间的相关性选择适当尺度问题的模块
    Huang 等人 ([2023a](#bib.bib97))。变换器将注意力（相关性）图作为输入，计算每个图像补丁的多尺度特征的权重，从而使模型能够自适应地选择每个补丁的最佳尺度。
- en: '![Refer to caption](img/904502c7e47696511165a6d5acb77878.png)'
  id: totrans-156
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/904502c7e47696511165a6d5acb77878.png)'
- en: 'Figure 19: The architecture of global context ViT Hatamizadeh et al. ([2023](#bib.bib79)).'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 图 19：全球上下文 ViT 的架构 Hatamizadeh 等人 ([2023](#bib.bib79))。
- en: 4.1.4 Image Generation
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.4 图像生成
- en: Image generation refers to the process of creating images based on input texts.
    Generally, the task can be divided into three stages. The first stage is extracting
    features from the input text, followed by generating the image and finally controlling
    the image generation process to ensure the output meets specific criteria and
    constraints. This section focuses on the progress made in the development of deep
    learning models of the second stage (image generation) since it directly impacts
    the quality of the generated images. Variational autoencoder is one of the earliest
    deep learning models that is capable of generating images Kingma and Welling ([2013](#bib.bib119)).
    Variational autoencoder learns to generate data by capturing the underlying (Gaussian)
    distribution of the training data. During the generation process, the distribution
    parameters are sampled and passed to the decoder to generate the output image.
    Although the generated images are blurry and unsatisfactory, it has shown a lot
    of potential in image generation tasks. The introduction of GAN significantly
    improved the quality of generated images. GAN consists of two connected neural
    networks, a generator and a discriminator that are trained simultaneously in a
    competitive manner Goodfellow et al. ([2014](#bib.bib71)). The generator learns
    to generate realistic images to fool the discriminator, while the discriminator
    learns to distinguish between fake and real images. The generated images are less
    blurry and more realistic. Several enhanced models have been proposed to improve
    its usability and overall performance such as CGAN Odena et al. ([2017](#bib.bib183))
    which allows us to tell what image to be generated, and the deep convolutional
    GAN (DCGAN) Radford et al. ([2015](#bib.bib199)) which provides a more stable
    structure for image generation. DCGAN is the basis of many subsequent improvements
    in GANs.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图像生成是指基于输入文本创建图像的过程。通常，这项任务可以分为三个阶段。第一阶段是从输入文本中提取特征，接着生成图像，最后控制图像生成过程以确保输出符合特定的标准和约束。本节重点关注第二阶段（图像生成）的深度学习模型的发展进展，因为它直接影响生成图像的质量。变分自编码器是最早能够生成图像的深度学习模型之一
    Kingma 和 Welling ([2013](#bib.bib119))。变分自编码器通过捕捉训练数据的潜在（高斯）分布来学习生成数据。在生成过程中，分布参数被采样并传递给解码器以生成输出图像。虽然生成的图像模糊且不令人满意，但在图像生成任务中显示了很大的潜力。生成对抗网络（GAN）的引入显著提高了生成图像的质量。GAN由两个连接的神经网络组成，一个生成器和一个鉴别器，它们以竞争的方式同时训练
    Goodfellow 等人 ([2014](#bib.bib71))。生成器学习生成逼真的图像以欺骗鉴别器，而鉴别器学习区分虚假图像和真实图像。生成的图像较少模糊，更加逼真。为了提高其可用性和整体性能，提出了几个增强模型，如
    CGAN Odena 等人 ([2017](#bib.bib183))，它允许我们指定要生成的图像，以及深度卷积 GAN (DCGAN) Radford 等人
    ([2015](#bib.bib199))，它提供了更稳定的图像生成结构。DCGAN 是许多后续 GAN 改进的基础。
- en: StackGAN divides the process of image generation into two stages Zhang et al.
    ([2017](#bib.bib292)). Stage-I generates a low-resolution image by creating basic
    shapes and colors and the background layout using the random noise vector. Stage-II
    completes the details of the image and produces a high-resolution photo-realistic
    image. StackGAN++ is the enhanced model of StackGAN whereby it consists of multiple
    generators with shared parameters to generate multiscale images Zhang et al. ([2018a](#bib.bib293)).
    The generators have a progressive goal with the intermediate generators generating
    images of varying sizes and the deepest generator producing the photo-realistic
    image. HDGAN is a generative model featuring a single-stream generator with hierarchically
    nested discriminators at intermediate layers Zhang et al. ([2018b](#bib.bib299)).
    These layers, each connected to a discriminator, generate multiscale images. The
    lower resolution outputs are used to learn semantic image structures while the
    higher resolution outputs are used to learn fine-grained details of the image.
    StackGAN heavily relies on the quality of the generated image in Stage-I. DM-GAN
    incorporates a memory network for image refinement to cope with badly generated
    images in Stage-I Zhu et al. ([2019b](#bib.bib303)). The memory network dynamically
    selects the words that are relevant to the generated image, and then refines the
    details to produce better photo-realistic images.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: StackGAN 将图像生成过程分为两个阶段 Zhang et al. ([2017](#bib.bib292))。第一阶段通过使用随机噪声向量创建基本形状、颜色和背景布局来生成低分辨率图像。第二阶段完成图像的细节并生成高分辨率的真实感图像。StackGAN++
    是 StackGAN 的增强模型，其中包含多个共享参数的生成器，用于生成多尺度图像 Zhang et al. ([2018a](#bib.bib293))。这些生成器具有渐进的目标，中间生成器生成不同大小的图像，而最深的生成器生成真实感图像。HDGAN
    是一种生成模型，具有单流生成器和在中间层具有层次嵌套判别器 Zhang et al. ([2018b](#bib.bib299))。这些层与判别器相连，生成多尺度图像。较低分辨率的输出用于学习语义图像结构，而较高分辨率的输出用于学习图像的细节。StackGAN
    在第一阶段严重依赖于生成图像的质量。DM-GAN 结合了用于图像细化的记忆网络，以应对第一阶段生成的糟糕图像 Zhu et al. ([2019b](#bib.bib303))。记忆网络动态选择与生成图像相关的词汇，然后细化细节以生成更好的真实感图像。
- en: AttnGAN is the first to incorporate attention mechanisms into the multiple generators
    to focus on words that are relevant to the generated image Xu et al. ([2018](#bib.bib282)).
    To this end, in addition to encoding the whole sentence into a global sentence
    vector, the text encoder encodes each word into a word vector as shown in Figure
    [20](#S4.F20 "Figure 20 ‣ 4.1.4 Image Generation ‣ 4.1 Computer Vision ‣ 4 Applications
    of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications").
    Then, the image vector is used to attend to the word vector using the attention
    modules at each stage of the multistage generators. Furthermore, AttnGAN introduces
    a loss function to compute the similarity between the generated image and the
    associated sentence, improving the performance of image generation. A similar
    work is reported whereby the model known as ResFPA-GAN, incorporates attention
    modules into the multiple generators Sun et al. ([2019](#bib.bib236)). Specifically,
    a feature pyramid attention module is proposed to capture high semantic information
    and fuse the multiscale feature, enhancing the overall performance of the model.
    DualAttn-GAN improves AttnGAN by incorporating visual attention modules to focus
    on important features along both spatial and channel dimensions Cai et al. ([2019](#bib.bib26)).
    This allows the model to better understand and capture both the context of the
    input sentence and the fine details of the image, resulting in more realistic
    image generation.
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: AttnGAN 是第一个将注意力机制融入到多个生成器中，以关注与生成图像相关的词汇的模型 Xu et al. ([2018](#bib.bib282))。为此，除了将整个句子编码为全局句子向量外，文本编码器还将每个词编码为词向量，如图
    [20](#S4.F20 "Figure 20 ‣ 4.1.4 Image Generation ‣ 4.1 Computer Vision ‣ 4 Applications
    of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art Applications")
    所示。然后，图像向量用于在多阶段生成器的每个阶段使用注意力模块关注词向量。此外，AttnGAN 引入了一个损失函数来计算生成的图像与相关句子之间的相似性，从而提高图像生成的性能。类似的工作是
    ResFPA-GAN，其中模型将注意力模块融入到多个生成器中 Sun et al. ([2019](#bib.bib236))。具体而言，提出了一种特征金字塔注意力模块，以捕捉高语义信息并融合多尺度特征，从而提升模型的整体性能。DualAttn-GAN
    通过将视觉注意力模块引入以关注空间和通道维度上的重要特征，从而改进了 AttnGAN Cai et al. ([2019](#bib.bib26))。这使得模型能够更好地理解和捕捉输入句子的上下文以及图像的细节，从而生成更真实的图像。
- en: '![Refer to caption](img/ff41aef1c0d54f3f8acc55fac46c4381.png)'
  id: totrans-162
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ff41aef1c0d54f3f8acc55fac46c4381.png)'
- en: 'Figure 20: The architecture of AttnGAN Xu et al. ([2018](#bib.bib282)).'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 图 20：AttnGAN Xu 等人的架构 ([2018](#bib.bib282))。
- en: Although multistage generators improve image generation performance by leveraging
    multiscale representation, the generated images may contain fuzzy shapes with
    coarse features. DF-GAN replaces the multistage generators with a single-stage
    deep generator featuring residual connections and trained with hinge loss Tao
    et al. ([2022](#bib.bib247)). Furthermore, DF-GAN introduces a regularization
    strategy on the discriminator that applies a gradient penalty on real images with
    matching text, allowing the model to generate more text-matching images. DMF-GAN
    an improved DF-GAN, incorporates three novel components designed to leverage semantic
    coherence between the input text and the generated image Yang et al. ([2024](#bib.bib284)).
    The first component is the recurrent semantic fusion module, which models long
    range dependencies between the fusion blocks. The second component is the multi-head
    attention module which is placed towards the end of the generator to leverage
    the word features, forcing the generator to generate images conditioned on the
    relevant words. The last component is the word-level discriminator which provides
    fine-grained feedback to the generator, facilitating the learning process and
    improving the overall quality of the generated images. Figure [21](#S4.F21 "Figure
    21 ‣ 4.1.4 Image Generation ‣ 4.1 Computer Vision ‣ 4 Applications of Deep Learning
    ‣ A Survey on Deep Learning and State-of-the-art Applications") shows the architecture
    of DMF-GAN. The process of image generation involves feeding a noise vector to
    the generator at the very beginning of the network. However, as the generator
    goes deeper, the noise effect may be diminished, affecting the diversity of the
    image generation results. To mitigate this issue, DE-GAN incorporates a dual injection
    module into the single-stage generator Jiang et al. ([2024](#bib.bib109)). The
    dual injection module consists of two text fusion layers followed by a noise broadcast
    operation. The text fusion layer takes the sentence embedding and fuses it with
    the input feature map using the fully-connected layer. Then noise is injected
    into the output feature map to retain the randomness in the generation process,
    improving diversity and generalization of the model.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管多阶段生成器通过利用多尺度表示来提升图像生成性能，但生成的图像可能包含模糊的形状和粗糙的特征。DF-GAN 用一个具有残差连接的单阶段深度生成器替代了多阶段生成器，并采用了带有铰链损失的训练方法
    Tao 等人 ([2022](#bib.bib247))。此外，DF-GAN 在判别器上引入了一种正则化策略，对匹配文本的真实图像施加梯度惩罚，使模型能够生成更多与文本匹配的图像。DMF-GAN
    是对 DF-GAN 的改进，融入了三个新颖的组件，旨在利用输入文本与生成图像之间的语义一致性 Yang 等人 ([2024](#bib.bib284))。第一个组件是递归语义融合模块，它建模了融合块之间的长程依赖关系。第二个组件是多头注意力模块，放置在生成器的末端，以利用词汇特征，迫使生成器生成基于相关词汇的图像。最后一个组件是词级判别器，它为生成器提供了细粒度的反馈，促进了学习过程，提高了生成图像的整体质量。图
    [21](#S4.F21 "图 21 ‣ 4.1.4 图像生成 ‣ 4.1 计算机视觉 ‣ 4 深度学习应用 ‣ 深度学习及前沿应用综述") 显示了 DMF-GAN
    的架构。图像生成的过程涉及在网络最初阶段向生成器输入噪声向量。然而，随着生成器的深入，噪声效应可能会减弱，影响图像生成结果的多样性。为了解决这个问题，DE-GAN
    在单阶段生成器中加入了双重注入模块 Jiang 等人 ([2024](#bib.bib109))。双重注入模块由两个文本融合层和一个噪声广播操作组成。文本融合层将句子嵌入与输入特征图融合，使用全连接层。然后将噪声注入输出特征图中，以保持生成过程中的随机性，从而提高模型的多样性和泛化能力。
- en: '![Refer to caption](img/cbc3742f5afc62bb0fbb9d344a271d2a.png)'
  id: totrans-165
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cbc3742f5afc62bb0fbb9d344a271d2a.png)'
- en: 'Figure 21: The architecture of DMF-GAN Yang et al. ([2024](#bib.bib284)).'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 图 21：DMF-GAN Yang 等人的架构 ([2024](#bib.bib284))。
- en: 4.2 Time Series and Pervasive Computing
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 时间序列与普适计算
- en: Pervasive computing, often referred to as ubiquitous computing, is the process
    of integrating computer technology into everyday objects and surroundings so that
    they become intelligent, networked, and able to communicate with one another to
    offer improved services and functionalities Weiser ([1991](#bib.bib269)). According
    to He et al He et al. ([2020b](#bib.bib83)), the role of pervasive computing is
    foremost in the field where it provides the ability to distribute computational
    services to the surroundings where people work, leading to trust, privacy, and
    identity. Examples of pervasive computing applications include smart homes with
    connected appliances, wearable devices that monitor health and fitness, smart
    cities with sensor networks for traffic management, and industrial applications
    that utilize the Internet of Things (IoT) for monitoring and control. Generally,
    the continuous interaction of interconnected devices in pervasive computing often
    result in time series data, which captures the evolution of various parameters
    over time.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 泛在计算，通常被称为无处不在的计算，是将计算机技术集成到日常物品和环境中的过程，使其变得智能化、联网，并能够彼此通信以提供改进的服务和功能 [Weiser
    ([1991](#bib.bib269))]。根据He等人 He et al. ([2020b](#bib.bib83))，泛在计算在该领域的作用首要体现在它提供了将计算服务分配到人们工作环境的能力，从而促进了信任、隐私和身份。泛在计算应用的例子包括具有连接电器的智能家居、监测健康和健身的可穿戴设备、具有交通管理传感器网络的智能城市，以及利用物联网（IoT）进行监控和控制的工业应用。一般而言，泛在计算中互联设备的持续互动通常会产生时间序列数据，这些数据捕捉了各种参数随时间的演变。
- en: For instance, medical sensors, such as electrocardiograms (ECG) and electroencephalograms
    (EEG), generate time series data that contain critical diagnostic information,
    which deep learning can use to detect anomalies, predict diseases, and classify
    medical conditions with improved accuracy. Also, devices such as accelerometers,
    magnetometers and gyroscopes, among others can be used to capture human activity
    signals, which are often represented as time series of state changes Ige and Noor
    ([2022](#bib.bib101)). In traditional machine learning, features such as mean,
    variance and others are manually extracted from times series of state changes
    before human activity classification. However, deep learning models automatically
    extract features Mohd Noor ([2021](#bib.bib169)). Also, in other fields such as
    finance, which entail time series data, deep learning has been instrumental in
    stock price prediction Singh and Srivastava ([2017](#bib.bib226)), fraud detection
    Zhang et al. ([2021](#bib.bib298)), and algorithmic trading Lei et al. ([2020](#bib.bib127)),
    among others. Generally, deep learning networks excel at capturing intricate temporal
    relationships within time-series data, enabling more precise predictions and improved
    decision-making. Based on this, several deep learning models have been employed
    for feature learning across various time series and pervasive computing domains.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，医疗传感器，如心电图（ECG）和脑电图（EEG），生成包含关键诊断信息的时间序列数据，深度学习可以利用这些数据检测异常、预测疾病，并以更高的准确性分类医疗状况。此外，诸如加速度计、磁力计和陀螺仪等设备可以用于捕捉人类活动信号，这些信号通常表现为状态变化的时间序列
    [Ige and Noor ([2022](#bib.bib101))]。在传统的机器学习中，特征如均值、方差等在进行人类活动分类之前需要从状态变化的时间序列中手动提取。然而，深度学习模型可以自动提取特征
    [Mohd Noor ([2021](#bib.bib169))]。此外，在涉及时间序列数据的其他领域，如金融，深度学习在股票价格预测 [Singh and
    Srivastava ([2017](#bib.bib226))]、欺诈检测 [Zhang et al. ([2021](#bib.bib298))] 和算法交易
    [Lei et al. ([2020](#bib.bib127))] 等方面发挥了重要作用。一般而言，深度学习网络擅长捕捉时间序列数据中的复杂时间关系，从而实现更精确的预测和改进的决策。基于此，多个深度学习模型已被应用于各个时间序列和泛在计算领域的特征学习。
- en: 4.2.1 Human Activity Recognition
  id: totrans-170
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 人类活动识别
- en: Human activity recognition (HAR) finds application across various domains including
    intelligent video surveillance, environmental home monitoring, video storage and
    retrieval, intelligent human-machine interfaces, and identity recognition, among
    many others. It includes various research fields, including the detection of humans
    in video, estimating human poses, tracking humans, and analyzing and understanding
    time series data Zhang et al. ([2019a](#bib.bib294)). Despite the advancements
    in vision-based HAR, there exist inherent limitations. Generally, vision-based
    approaches heavily rely on camera systems, which may have restricted views or
    be affected by lighting conditions, occlusions, and complex backgrounds Ige and
    Noor ([2022](#bib.bib101)). Additionally, vision-based HAR struggles with identifying
    actions that occur beyond the range of the camera or actions that are visually
    similar.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 人类活动识别（HAR）在多个领域中有广泛的应用，包括智能视频监控、环境家庭监测、视频存储和检索、智能人机界面和身份识别等。它包括各种研究领域，如视频中的人类检测、人体姿态估计、跟踪人类以及分析和理解时间序列数据
    Zhang et al. ([2019a](#bib.bib294))。尽管视觉基础的HAR有了进步，但仍存在固有的局限性。一般来说，视觉基础的方法严重依赖摄像系统，这些系统可能具有受限的视角，或受到光照条件、遮挡和复杂背景的影响
    Ige and Noor ([2022](#bib.bib101))。此外，视觉基础的HAR在识别超出摄像机范围或视觉上类似的动作时面临挑战。
- en: Wearable sensors offer a promising alternative to overcome these limitations.
    By directly capturing data from the individual, wearable sensors provide more
    comprehensive and accurate information about human activities. The signals obtained
    from wearable sensors typically represent time series data reflecting state changes
    in activities. Deep learning models can effectively learn from these signals,
    allowing for robust and accurate recognition of human activities. Moreover, wearable
    sensors offer the advantage of mobility, enabling activity recognition in various
    environments and situations where vision-based systems may be impractical or ineffective
    Dang et al. ([2020](#bib.bib44)). Generally, the time series nature of signals
    from wearable sensors presents an excellent opportunity for deep learning models
    to excel in recognizing human activities with high accuracy and reliability.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 可穿戴传感器提供了一种有前途的替代方案来克服这些限制。通过直接从个人那里捕捉数据，可穿戴传感器提供了关于人类活动更全面和准确的信息。 从可穿戴传感器获得的信号通常代表反映活动状态变化的时间序列数据。
    深度学习模型可以有效地从这些信号中学习，从而实现对人类活动的强健和准确的识别。此外，可穿戴传感器具有机动性优势，使得在各种环境和情况中进行活动识别成为可能，而这些环境和情况中基于视觉的系统可能不切实际或效果不佳
    Dang et al. ([2020](#bib.bib44))。一般而言，可穿戴传感器信号的时间序列特性为深度学习模型在高精度和高可靠性地识别人类活动提供了绝佳的机会。
- en: Several researchers have proposed the use of CNN, RNN, and Hybrid models for
    deep learning based feature learning in wearable sensor HAR. For instance, using
    two-dimensional CNN (Conv2D), several researchers, as seen in Gao et al. ([2021a](#bib.bib62)),
    Gupta ([2021](#bib.bib75)) and Erdaş and Güney ([2021](#bib.bib57)), among others,
    have developed deep learning models for wearable sensor HAR, despite the time
    series nature of the data. This is often done by treating the time series signals
    from wearable sensors as 2D images by reshaping them appropriately. To achieve
    this, researchers often organize each time series signal into a matrix format,
    with time along one axis and sensor dimensions along the other, before creating
    a pseudo-image representation, which allows the matrix to be be fed into Conv2D
    layers for feature extraction. Conv2D layers excel at capturing spatial patterns
    and relationships within images, and by treating the time series data as images,
    these layers can learn relevant spatial features that contribute to activity recognition.
    The convolution operation performed by Conv2D filters across both the time and
    sensor dimensions, allowing the network to identify patterns and features that
    may be indicative of specific activities.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究人员提出了使用 CNN、RNN 和混合模型进行基于深度学习的可穿戴传感器 HAR 特征学习。例如，通过使用二维 CNN (Conv2D)，如 Gao
    等 ([2021a](#bib.bib62))、Gupta ([2021](#bib.bib75)) 和 Erdaş 和 Güney ([2021](#bib.bib57))
    等研究人员，尽管数据具有时间序列特性，但仍开发了用于可穿戴传感器 HAR 的深度学习模型。这通常通过将来自可穿戴传感器的时间序列信号视为 2D 图像并适当重塑它们来实现。为了达到这一点，研究人员通常将每个时间序列信号组织成矩阵格式，一轴为时间，另一轴为传感器维度，然后创建伪图像表示，从而将矩阵输入
    Conv2D 层进行特征提取。Conv2D 层擅长捕捉图像中的空间模式和关系，通过将时间序列数据视为图像，这些层可以学习有助于活动识别的相关空间特征。Conv2D
    过滤器在时间和传感器维度上执行卷积操作，使网络能够识别可能表明特定活动的模式和特征。
- en: Even though Conv2D can effectively capture spatial dependencies within the data,
    it often struggles to capture temporal dependencies inherent in time series data.
    Since Conv2D processes data in a grid-like fashion, it does not fully leverage
    the sequential nature of the time series, potentially leading to less effective
    feature extraction for wearable sensor HAR tasks. For this reason, recent HAR
    architectures have leveraged one-dimensional CNN (Conv1D) and other RNNs for automatic
    feature extraction. Conv1D layers are specifically designed to capture temporal
    dependencies within sequential data. They operate directly on the time series
    data without reshaping it into a 2D format, allowing them to capture temporal
    patterns more effectively. Conv1D layers are better suited for extracting features
    from time series data, making them a more natural choice for wearable sensor HAR
    Mohd Noor ([2021](#bib.bib169)).
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 Conv2D 能有效捕捉数据中的空间依赖关系，但它往往难以捕捉时间序列数据中固有的时间依赖关系。由于 Conv2D 以网格状的方式处理数据，它未能充分利用时间序列的顺序特性，可能导致在可穿戴传感器
    HAR 任务中特征提取效果不佳。因此，最近的 HAR 架构采用了一维 CNN (Conv1D) 和其他 RNN 来进行自动特征提取。Conv1D 层专门设计用于捕捉顺序数据中的时间依赖关系。它们直接对时间序列数据进行操作，而不将其重塑为
    2D 格式，从而更有效地捕捉时间模式。Conv1D 层更适合从时间序列数据中提取特征，因此是可穿戴传感器 HAR 的更自然选择 Mohd Noor ([2021](#bib.bib169))。
- en: For instance, Ragab et al. Ragab et al. ([2020](#bib.bib201)) proposed a random
    search Conv1D model, and evaluated the performance of the model on UCI-HAR dataset.
    The result showed that the model achieved a recognition accuracy of 95.40% when
    classifying the six activities in the dataset. However, the model exhibited extended
    training times due to the dynamic nature of some activities within the dataset.
    To address this, Banjarey et al. ([2022](#bib.bib20)) proposed the use of varying
    kernel sizes in Conv1D layers to recognize various activities, including sitting,
    standing, walking, sleeping, reading, and tilting. Also, a few Conv1D layers were
    stacked in order to streamline the time optimization process for training the
    neural network. Also, some researchers have proposed models that combine machine
    learning algorithms with Conv1D in HAR, as seen in Shuvo et al. Shuvo et al. ([2020](#bib.bib222)).
    Their work presented a two-stage learning process to improve HAR by classifying
    activities into static and dynamic using Random Forest, before using Support Vector
    Machine to identify each static activity, and Conv1D to recognize dynamic activities.
    The result showed that the method achieved an accuracy of 97.71% on the UCI-HAR
    dataset.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Ragab 等人 ([2020](#bib.bib201)) 提出了一个随机搜索 Conv1D 模型，并评估了该模型在 UCI-HAR 数据集上的表现。结果显示，该模型在对数据集中六项活动进行分类时，达到了
    95.40% 的识别准确率。然而，由于数据集中某些活动的动态性质，该模型表现出较长的训练时间。为了解决这个问题，Banjarey 等人 ([2022](#bib.bib20))
    提出了在 Conv1D 层中使用不同的卷积核尺寸，以识别各种活动，包括坐、站、走、睡、读和倾斜。此外，还堆叠了一些 Conv1D 层，以简化神经网络训练的时间优化过程。此外，一些研究人员提出了将机器学习算法与
    Conv1D 结合使用的模型，如 Shuvo 等人 ([2020](#bib.bib222)) 所示。他们的工作提出了一个两阶段学习过程，通过使用随机森林将活动分类为静态和动态，以改善
    HAR，然后使用支持向量机识别每个静态活动，并使用 Conv1D 识别动态活动。结果表明，该方法在 UCI-HAR 数据集上达到了 97.71% 的准确率。
- en: Following these advancements, several researchers have further explored Conv1D
    architectures with various modifications, to enhance feature learning in activity
    recognition systems. For example, Han et al. Han et al. ([2022](#bib.bib76)) developed
    a two-stream CNN architecture as a plug-and-play module to encode contextual information
    of sensor time series from different receptive field sizes. The module was integrated
    into existing deep models for HAR at no extra computation cost. Experiments on
    OPPORTUNITY, PAMAP2, UCI-HAR and USC-HAD datasets showed that the module improved
    feature learning capabilities. A similar research reported in Ige and Noor ([2023](#bib.bib102))
    proposed the WSense module to address the issue of differences in the quality
    of features learnt, regardless of the size of the sliding window segmentation,
    and experimented on PAMAP2 and WISDM datasets. The results showed that by plugging
    the WSense module into Conv1D architectures, improved activity features can be
    learned from wearable sensor data for human activity recognition.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 随着这些进展，几位研究人员进一步探讨了具有各种修改的 Conv1D 架构，以增强活动识别系统中的特征学习。例如，Han 等人 ([2022](#bib.bib76))
    开发了一种双流 CNN 架构作为插拔式模块，以编码来自不同感受野大小的传感器时间序列的上下文信息。该模块被集成到现有的深度模型中进行 HAR，而无需额外的计算成本。对
    OPPORTUNITY、PAMAP2、UCI-HAR 和 USC-HAD 数据集的实验表明，该模块提高了特征学习能力。Ige 和 Noor ([2023](#bib.bib102))
    报告中的类似研究提出了 WSense 模块，以解决滑动窗口分割大小无论如何都会导致特征学习质量差异的问题，并在 PAMAP2 和 WISDM 数据集上进行了实验。结果表明，通过将
    WSense 模块插入 Conv1D 架构中，可以从可穿戴传感器数据中学习到改进的活动特征，以进行人类活动识别。
- en: Similarly, some researchers have also proposed the use of standalone RNNs in
    HAR, and a hybrid of Conv1D architectures with RNNs such as LSTMs Deep and Zheng
    ([2019](#bib.bib46)), BiLSTMs Luwe et al. ([2022](#bib.bib160)); Shi et al. ([2023](#bib.bib220)),
    GRUs Dua et al. ([2023](#bib.bib53)) and BiGRUs Imran et al. ([2023](#bib.bib103));
    Chen et al. ([2022b](#bib.bib32)) in order to fully harness the feature learning
    capabilities of both CNN and RNNs. For instance, Nafea et al. Nafea et al. ([2021](#bib.bib175)),
    leveraged Bi-LSTM and Conv1D with increasing kernel sizes to learn features at
    various resolutions. Human activity features were extracted using the stacked
    convolutional layers with a Bi-LSTM layer, before including a flattening layer
    and a fully connected layer for subsequent classification. However, the model
    had issues extracting quality features of dynamic activities compared to static
    activities. To address such issues, some research works have incorporated attention
    mechanisms in Conv1D-based architectures to improve feature learning of dynamic
    and complex activities from time series signals obtained from wearable sensors.
    For example, Khan and Ahmad Khan and Ahmad ([2021](#bib.bib116)) designed three
    lightweight convolutional heads, with each specialized in feature extraction from
    wearable sensor data. Each head comprised stacked layers of Conv1Ds, along with
    embedded attention mechanisms to augment feature learning. The results demonstrated
    that integrating multiple 1D-CNN heads with attention mechanisms can enhance feature
    learning for Human Activity Recognition (HAR). These diverse modifications and
    adaptations showcase the versatility and potential of deep learning models in
    achieving state-of-the-art in HAR systems.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 类似地，一些研究人员还提出了在 HAR 中使用独立 RNN 的方法，以及 Conv1D 架构与 RNN（如 LSTMs Deep 和 Zheng（[2019](#bib.bib46)），BiLSTMs
    Luwe 等（[2022](#bib.bib160)）；Shi 等（[2023](#bib.bib220）），GRUs Dua 等（[2023](#bib.bib53)），以及
    BiGRUs Imran 等（[2023](#bib.bib103））；Chen 等（[2022b](#bib.bib32)）的混合体，以充分利用 CNN
    和 RNN 的特征学习能力。例如，Nafea 等人 Nafea 等（[2021](#bib.bib175)）利用 Bi-LSTM 和 Conv1D，并使用不同大小的核学习各种分辨率下的特征。通过堆叠卷积层和
    Bi-LSTM 层提取人体活动特征，然后包括一个平铺层和一个全连接层进行后续分类。然而，该模型在提取动态活动的优质特性方面存在问题，而在静态活动方面则没有出现这种问题。为了解决这些问题，一些研究工作在基于
    Conv1D 的架构中结合注意力机制，以改善从可穿戴传感器获得的时间序列信号中动态和复杂活动的特征学习。例如，Khan 和 Ahmad Khan 和 Ahmad（[2021](#bib.bib116））设计了三个轻量级卷积头，每个头都专门用于从可穿戴传感器数据中提取特征。每个头包括
    Conv1D 的堆叠层，以及嵌入的注意力机制来增强特征学习。结果表明，将多个 1D-CNN 头与注意力机制结合起来，可以增强人体活动识别（HAR）的特征学习。这些多样的修改和调整展示了深度学习模型在实现
    HAR 系统最新技术水平方面的多样性和潜力。
- en: '![Refer to caption](img/8022b6c5921effc29f8b055f5b1fcead.png)'
  id: totrans-178
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8022b6c5921effc29f8b055f5b1fcead.png)'
- en: 'Figure 22: The architecture of multi-head CNN model Khan and Ahmad ([2021](#bib.bib116)).'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 图 22：Khan 和 Ahmad（[2021](#bib.bib116)）的多头 CNN 模型架构。
- en: 4.2.2 Speech Recognition
  id: totrans-180
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 语音识别
- en: Speech, as the primary mode of human communication, has captivated researchers
    for over five decades, especially since the inception of artificial intelligence
    Nassif et al. ([2019](#bib.bib178)). From the earliest endeavors to understand
    and replicate the complexities of human speech, to contemporary advancements leveraging
    cutting-edge technologies, the quest for accurate and efficient speech recognition
    systems has been relentless. In recent years, the emergence of deep learning techniques
    has revolutionized the speech recognition field. Deep learning has demonstrated
    unparalleled success in processing and extracting intricate patterns from vast
    amount of data. When applied to the realm of speech recognition, deep learning
    have surpassed traditional approaches by learning intricate features directly
    from raw audio signals, circumventing the need for handcrafted features and complex
    preprocessing pipelines. This paradigm shift has significantly advanced the state-of-the-art
    in speech recognition, enabling systems to achieve unprecedented levels of accuracy
    and robustness across various languages, accents, and environmental conditions.
    Generally, deep learning has been extended to other essential applications of
    speech recognition, such as speaker identification Tirumala and Shahamiri ([2016](#bib.bib251));
    Ye and Yang ([2021](#bib.bib287)), emotion recognition Khalil et al. ([2019](#bib.bib115)),
    language identification Singh et al. ([2021](#bib.bib225)), accent recognition
    Jiao et al. ([2016](#bib.bib111)), age recognition Sánchez-Hevia et al. ([2022](#bib.bib211))
    and gender recognition Alnuaim et al. ([2022](#bib.bib6)), among many others.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 语言作为人类交流的主要方式，已经吸引了研究人员超过五十年的关注，特别是自人工智能Nassif等人（[2019](#bib.bib178)）问世以来。从最早期理解和复制人类语言复杂性的尝试，到利用前沿技术的现代进展，对准确且高效的语言识别系统的追求一直不懈。近年来，深度学习技术的出现彻底改变了语言识别领域。深度学习在处理和提取大量数据中的复杂模式方面展示了无与伦比的成功。当应用于语言识别领域时，深度学习通过直接从原始音频信号中学习复杂特征，超越了传统方法，绕过了手工特征和复杂的预处理管道的需要。这一范式转变显著推动了语言识别技术的前沿，使系统能够在各种语言、口音和环境条件下实现前所未有的准确性和鲁棒性。一般来说，深度学习已被扩展到语言识别的其他重要应用中，如说话人识别Tirumala和Shahamiri（[2016](#bib.bib251)）；Ye和Yang（[2021](#bib.bib287)），情感识别Khalil等人（[2019](#bib.bib115)），语言识别Singh等人（[2021](#bib.bib225)），口音识别Jiao等人（[2016](#bib.bib111)），年龄识别Sánchez-Hevia等人（[2022](#bib.bib211)）和性别识别Alnuaim等人（[2022](#bib.bib6)），等等。
- en: Prior to the adoption of deep learning in speech recognition, the foundation
    of traditional speech recognition systems was the use of Gaussian Mixture Models
    (GMMs), which are often combined with Hidden Markov Models (HMMs) to represent
    speech signals Srivastava and Pandey ([2022](#bib.bib231)). This is because a
    speech signal can be thought of as a short-term stationary signal. The spectral
    representation of the sound wave is modelled by each HMM using a mixture of Gaussian.
    However, they are considered statistically inefficient for modelling non-linear
    or near non-linear functions Padmanabhan and Premkumar ([2015](#bib.bib187));
    Nassif et al. ([2019](#bib.bib178)). This is because HMMs rely on a set of predefined
    states and transition probabilities, making assumptions about the linearity and
    stationarity of the underlying data. While suitable for modelling certain aspects
    of speech, HMMs often fall short when tasked with representing the intricate nonlinearities
    and variability present in speech signals. Speech, by nature, exhibits nonlinear
    and dynamic characteristics, with features such as intonation, rhythm, and phonetic
    variations challenging the simplistic assumptions of traditional statistical models
    like HMMs. In other words, GMM-HMM approach had limitations in capturing complex
    acoustic patterns and long-term dependencies in speech Mukhamadiyev et al. ([2022](#bib.bib170)).
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习被应用于语音识别之前，传统语音识别系统的基础是使用高斯混合模型（GMMs），这些模型通常与隐马尔可夫模型（HMMs）结合，以表示语音信号 Srivastava
    和 Pandey ([2022](#bib.bib231))。这是因为语音信号可以被视为一个短期平稳信号。每个HMM使用高斯混合来建模声音波的谱表示。然而，它们在建模非线性或接近非线性的函数时被认为是统计效率低的
    Padmanabhan 和 Premkumar ([2015](#bib.bib187))；Nassif 等 ([2019](#bib.bib178))。这是因为HMM依赖于一组预定义的状态和转移概率，对基础数据的线性和稳态性做出假设。虽然HMM在建模语音的某些方面时适用，但当任务是表示语音信号中复杂的非线性和变异性时，HMM往往力不从心。语音本质上表现出非线性和动态特征，如语调、节奏和语音变异等，这些特征对传统统计模型如HMM的简化假设提出了挑战。换句话说，GMM-HMM方法在捕捉语音中的复杂声学模式和长期依赖性方面存在局限性
    Mukhamadiyev 等 ([2022](#bib.bib170))。
- en: In recent times, CNN and RNNs have been leveraged for automatic speech recognition
    in order to consider a longer or variable temporal window for context information
    extraction Lu et al. ([2020](#bib.bib156)). Generally, CNNs are well-suited for
    capturing local patterns and hierarchical features in data, making them effective
    for modelling acoustic features in speech. By directly learning features from
    raw speech signals, CNNs bypassed the need for handcrafted features used in traditional
    GMM-HMM systems. Additionally, CNNs can capture long-range dependencies in the
    data, which is crucial for understanding the context of speech. Likewise, the
    RNNs are suitable choice for exploring extended temporal context information in
    one processing level for feature extraction and modelling.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，CNN和RNN被用于自动语音识别，以考虑更长或可变的时间窗口进行上下文信息提取 Lu 等 ([2020](#bib.bib156))。通常，CNN非常适合捕捉数据中的局部模式和层次特征，使其在建模语音中的声学特征时非常有效。通过直接从原始语音信号中学习特征，CNN绕过了传统GMM-HMM系统中使用的手工特征的需求。此外，CNN可以捕捉数据中的长期依赖性，这对于理解语音的上下文至关重要。同样，RNN在一个处理层次中探索扩展的时间上下文信息以进行特征提取和建模也是合适的选择。
- en: Based on this, several researchers have proposed the use of both CNN and variants
    of RNNs for automatic speech recognition and for other speech related tasks. For
    instance, Hema and Garcia Marquez ([2023](#bib.bib84)), used CNN to classify speech
    emotions and benchmarked on a dataset consisting of seven classes (anger, disgust,
    fear, happiness, neutral, sadness and surprise). However, CNN lack the ability
    to model temporal dependencies explicitly. In speech recognition, understanding
    the temporal context of speech is essential for accurate transcription. Also,
    speech signals are inherently sequential, and information from previous time steps
    is crucial for understanding the current speech segment. CNNs, by design, do not
    inherently capture this sequential nature. For this reason, variants of RNNs have
    been leveraged to collect extended contexts in speeches. This is because RNNs
    are designed to model sequential data by maintaining hidden states that capture
    information from previous time steps. This allows them to capture temporal dependencies
    effectively, making them well-suited for ASR tasks. In Shewalkar et al. ([2019](#bib.bib219)),
    the authors evaluated the performance of RNN, LSTM, and GRU on a popular benchmark
    speech dataset (ED-LIUM). The results showed that LSTM achieved the best word
    error rate while the GRU optimization was faster and achieved word error rate
    close to that of LSTM.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 基于此，几位研究人员提出了同时使用CNN和RNN变体来进行
- en: However, RNN architectures process input sequences sequentially, which limits
    their ability to capture global context information effectively. As a result,
    they may struggle to understand the entire context of a spoken utterance, leading
    to lower transcription accuracy, particularly in tasks requiring understanding
    beyond local dependencies. Also, most CNN and RNN automatic speech recognition
    systems comprise of separate acoustic, pronunciation, and language modelling components
    that are trained independently. Usually, the acoustic model bootstraps from an
    existing model that is used for alignment in order to train it to recognise context
    dependent (CD) states or phonemes. The pronunciation model, curated by expert
    linguists, maps the sequences of phonemes produced by the acoustic model into
    word sequences. For this reason, Sequence-to-Sequence (Seq2Seq) models are being
    proposed in automatic speech recognition to train the acoustic, pronunciation,
    and language modelling components jointly in a single system Prabhavalkar et al.
    ([2017](#bib.bib196)). Seq2Seq methods in automatic speech recognition are a class
    of models that aim to directly transcribe an input sequence of acoustic features
    such as speech spectrograms or Mel-frequency cepstral coefficients into a sequence
    of characters or words representing the recognized speech. There have been a variety
    of sequence-to-sequence models explored in the literature, including Recurrent
    Neural Network Transducer (RNN-T) Graves ([2012](#bib.bib72)), Listen, Attend
    and Spell (LAS) Chan et al. ([2015](#bib.bib29)), Neural Transducer Jaitly et al.
    ([2016](#bib.bib108)), Monotonic Alignments Raffel et al. ([2017](#bib.bib200))
    and Recurrent Neural Aligner (RNA) Sak et al. ([2017](#bib.bib210)).
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，RNN 架构按顺序处理输入序列，这限制了它们有效捕捉全局上下文信息的能力。因此，它们可能难以理解口语表达的整体上下文，从而导致转录准确性降低，特别是在需要超越局部依赖的任务中。此外，大多数
    CNN 和 RNN 自动语音识别系统由独立训练的声学、发音和语言建模组件组成。通常，声学模型从现有模型启动，该模型用于对齐，以便训练识别上下文相关（CD）状态或音素。发音模型由专家语言学家策划，将声学模型产生的音素序列映射到单词序列中。因此，自动语音识别中正在提出
    Sequence-to-Sequence（Seq2Seq）模型，以在单一系统中联合训练声学、发音和语言建模组件 Prabhavalkar 等人 ([2017](#bib.bib196))。Seq2Seq
    方法在自动语音识别中是一类模型，旨在将输入的声学特征序列（如语音谱图或 Mel 频率倒谱系数）直接转录为表示识别语音的字符或单词序列。文献中探索了多种序列到序列模型，包括递归神经网络变换器（RNN-T）Graves
    ([2012](#bib.bib72))、听、关注和拼写（LAS）Chan 等人 ([2015](#bib.bib29))、神经变换器 Jaitly 等人
    ([2016](#bib.bib108))、单调对齐 Raffel 等人 ([2017](#bib.bib200)) 和递归神经对齐器（RNA）Sak 等人
    ([2017](#bib.bib210))。
- en: '![Refer to caption](img/57c85e10110a03573f0ed18171e0b26c.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/57c85e10110a03573f0ed18171e0b26c.png)'
- en: 'Figure 23: Sequence-to-Sequence'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '图 23: 序列到序列'
- en: As shown in Figure [23](#S4.F23 "Figure 23 ‣ 4.2.2 Speech Recognition ‣ 4.2
    Time Series and Pervasive Computing ‣ 4 Applications of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications"), the encoder component takes
    the input sequence of acoustic features and processes it to create a fixed-dimensional
    representation, often called the context vector. This representation captures
    the essential information from the input sequence and serves as the basis for
    generating the output sequence. The decoder component takes the context vector
    produced by the encoder and generates the output sequence. In ASR, this output
    sequence consists of characters or words representing the recognized speech. The
    decoder is typically implemented as a recurrent neural network (RNN), such as
    a Long Short-Term Memory (LSTM) or Gated Recurrent Unit (GRU) network, or it could
    be a transformer-based architecture. During training, the model learns to map
    input sequences to their corresponding output sequences by minimizing a suitable
    loss function, such as cross-entropy loss. This is typically done using techniques
    like backpropagation through time (BPTT) or teacher forcing, where the model is
    trained to predict the next token in the output sequence given the previous tokens.
    Thereafter, the trained model is used to transcribe unseen speech input. The encoder
    processes the input sequence to produce the context vector, which is then fed
    into the decoder to generate the output sequence. In some cases, beam search Szűcs
    and Huszti ([2019](#bib.bib241)); Li et al. ([2018](#bib.bib137)) or other decoding
    strategies may be used to improve the quality of the generated output.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[23](#S4.F23 "Figure 23 ‣ 4.2.2 Speech Recognition ‣ 4.2 Time Series and Pervasive
    Computing ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications")所示，编码器组件接收声学特征的输入序列，并将其处理以创建一个固定维度的表示，通常称为上下文向量。该表示捕获了输入序列中的关键信息，并作为生成输出序列的基础。解码器组件接收编码器生成的上下文向量并生成输出序列。在自动语音识别（ASR）中，这个输出序列由表示识别语音的字符或单词组成。解码器通常实现为递归神经网络（RNN），如长短期记忆（LSTM）或门控递归单元（GRU）网络，或者它可能是基于变换器的架构。在训练过程中，模型通过最小化适当的损失函数（如交叉熵损失）来学习将输入序列映射到其对应的输出序列。这通常通过时间反向传播（BPTT）或教师强制等技术完成，其中模型被训练以预测给定先前标记的输出序列中的下一个标记。之后，训练好的模型用于转录未见的语音输入。编码器处理输入序列以生成上下文向量，然后将其输入到解码器中以生成输出序列。在某些情况下，可能会使用束搜索
    Szűcs 和 Huszti ([2019](#bib.bib241)); Li 等 ([2018](#bib.bib137)) 或其他解码策略来提高生成输出的质量。
- en: In Chiu et al. ([2018](#bib.bib37)), the authors explored various structural
    and optimization enhancements to their LAS Sequence to Sequence model, resulting
    in significant performance improvements. They introduce several structural enhancements,
    including the utilization of word piece models instead of graphemes and the incorporation
    of a multi-head attention architecture, which outperforms the commonly used single-head
    attention mechanism. Additionally, they investigate optimization techniques such
    as synchronous training, scheduled sampling, label smoothing, and minimum word
    error rate optimization, all of which demonstrate improvements in accuracy. The
    authors present experimental results utilizing a unidirectional LSTM encoder for
    streaming recognition. On a 12,500-hour voice search task, they observe a decrease
    in Word Error Rate (WER) from 9.2% to 5.6% with the proposed changes, while the
    best-performing conventional system achieves a WER of 6.7%. Moreover, on a dictation
    task, their model achieves a WER of 4.1%, compared to 5% for the conventional
    system. Similarly, the work of Prabhavalkar et al. Prabhavalkar et al. ([2017](#bib.bib196))
    investigated a number of sequence-to-sequence methods in automatic speech recognition.
    These included the RNN transducer (RNN-T), attention-based models, a new model
    that augments the RNN-T with attention, and a Connectionist Temporal Classification
    (CTC) trained system that directly outputs grapheme sequences. According to their
    research, sequence-to-sequence approaches can compete on dictation test sets against
    state-of-the-art when trained on a large volume of training data. Even though
    deep learning has achieved state-of-the-art in speech recognition, an area that
    still calls for attention is speech-to-speech translation. This is because the
    present deep learning based speech-to-speech translation systems operate by translating
    sentences individually, disregarding any contextual information from preceding
    sentences. While research on contextual understanding has been ongoing for years,
    challenges persist regarding its practicality and processing efficiency, since
    translation typically relies on the surrounding words for context.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Chiu 等人（[2018](#bib.bib37)）的研究中，作者探索了对其 LAS 序列到序列模型的各种结构和优化增强，取得了显著的性能提升。他们引入了多种结构改进，包括使用词片模型而非字素模型，以及采用多头注意力架构，该架构优于常用的单头注意力机制。此外，他们还研究了优化技术，如同步训练、计划采样、标签平滑和最小词错误率优化，这些技术均表现出准确率的提升。作者展示了使用单向
    LSTM 编码器进行流式识别的实验结果。在 12,500 小时的语音搜索任务中，他们观察到所提出的改动使词错误率（WER）从 9.2% 降至 5.6%，而最佳传统系统的
    WER 为 6.7%。此外，在听写任务中，他们的模型取得了 4.1% 的 WER，而传统系统为 5%。类似地，Prabhavalkar 等人（[2017](#bib.bib196)）研究了多种自动语音识别的序列到序列方法。这些方法包括
    RNN 变换器（RNN-T）、基于注意力的模型、一种增强 RNN-T 的注意力模型以及直接输出字素序列的连接时序分类（CTC）训练系统。根据他们的研究，序列到序列的方法在大规模训练数据上可以与最先进的技术竞争。尽管深度学习在语音识别领域已达到最先进水平，但仍需关注语音到语音翻译领域。这是因为目前基于深度学习的语音到语音翻译系统通常通过逐句翻译来操作，而忽略了前句的上下文信息。尽管关于上下文理解的研究已进行多年，但在其实用性和处理效率方面仍面临挑战，因为翻译通常依赖于周围的词语来提供上下文。
- en: 4.2.3 Electrocardiogram (ECG) Classification
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 心电图（ECG）分类
- en: Disorders pertaining to the heart or blood vessels are collectively referred
    to as Cardiovascular Diseases (CVD) Liu et al. ([2021a](#bib.bib148)). According
    to the American Heart Association’s 2023 statistics, CVD has emerged as the leading
    cause of death worldwide. In 2020, 19.05 million deaths were recorded from CVD
    globally, which signifies an increase of 18.71% from 2010, and it is believed
    that this number will rise to 23.6 million by 2030 Tsao et al. ([2023](#bib.bib254)).
    Blood clots and vascular blockages caused by CVDs can cause myocardial infarction,
    stroke or even death Liu et al. ([2021a](#bib.bib148)). Generally, early diagnosis
    has been shown to reduce the mortality rate of CVDs, and Electrocardiogram (ECG)
    signals play a crucial role in diagnosing various cardiac abnormalities and monitoring
    heart health. However, ECG signal has characteristics of high noise and high complexity,
    making it time-consuming and labor-intensive to identify certain diseases using
    traditional methods. The traditional approach is tedious and requires the expertise
    of a medical specialist. Over the past decades, the task of Long-term ECG recording
    classification has been significantly facilitated for cardiologists through the
    adoption of computerized ECG recognition practices. Throughout this period, feature
    extraction methods have predominantly relied on manual techniques, encompassing
    diverse approaches such as wave shape functions Llamedo and Martínez ([2011](#bib.bib153)),
    wavelet-based features Mathews et al. ([2018](#bib.bib164)), ECG morphology zhu
    et al. ([2019](#bib.bib304)), hermite polynomials Desai et al. ([2021](#bib.bib48)),
    and Karhunen-Loeve expansion of ECG morphology Crippa et al. ([2015](#bib.bib40)),
    among others. These extracted features are subsequently subjected to classification
    using various machine learning algorithms.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 心脏或血管相关的疾病统称为心血管疾病（CVD）（刘等，[2021a](#bib.bib148)）。根据美国心脏协会2023年的统计数据，CVD已经成为全球首要的死亡原因。在2020年，全球因CVD死亡的人数达到了190.5万，比2010年增长了18.71%，预计到2030年这一数字将上升到2360万（曹等，[2023](#bib.bib254)）。CVD引起的血栓和血管堵塞可能导致心肌梗塞、中风甚至死亡（刘等，[2021a](#bib.bib148)）。通常，早期诊断已被证明能够降低CVD的死亡率，而心电图（ECG）信号在诊断各种心脏异常和监测心脏健康方面发挥了关键作用。然而，ECG信号具有高噪声和高复杂性的特点，使得使用传统方法识别某些疾病既耗时又费力。传统方法繁琐且需要医疗专家的专业知识。在过去几十年里，通过采用计算机化ECG识别技术，心脏病专家在长期ECG记录分类任务中获得了显著的便利。在此期间，特征提取方法主要依赖于手动技术，包括波形函数（Llamedo和Martínez，[2011](#bib.bib153)）、基于小波的特征（Mathews等，[2018](#bib.bib164)）、ECG形态（朱等，[2019](#bib.bib304)）、厄尔密多项式（Desai等，[2021](#bib.bib48)）以及ECG形态的Karhunen-Loeve展开（Crippa等，[2015](#bib.bib40)）等。这些提取的特征随后通过各种机器学习算法进行分类。
- en: More recently, the advent of deep learning has revolutionized the field by enabling
    automatic feature learning directly from ECG signals. This advancement holds significant
    promise in the realm of automated ECG classification, offering clinicians a tool
    for swift and accurate diagnosis. Based on this, several deep learning architectures
    have been proposed for feature learning of ECG signals. For instance, Acharya
    et al. Acharya et al. ([2017](#bib.bib3)) developed a 9-layer CNN model to automatically
    identify five categories of heartbeats in ECG signals. A similar model was also
    developed in Baloglu et al. ([2019](#bib.bib18)), However, ECG signals often vary
    significantly in length, as they may contain different numbers of heartbeats.
    CNNs typically require fixed-length inputs, which may necessitate preprocessing
    steps such as padding or truncation, potentially losing important temporal information.
    For this reason, several architectures have leveraged RNN in ECG classification,
    as seen in Singh et al. ([2018](#bib.bib227)), Prabhakararao and Dandapat ([2020](#bib.bib195))
    and Wang et al. ([2023b](#bib.bib263)), among others. While RNNs are capable of
    handling sequential data, they also have limitations in capturing local patterns
    or short-term dependencies effectively. In ECG signals, local features such as
    specific waveforms or intervals can be crucial for classification. For this reason,
    recent works have proposed hybrid models which combine the strengths of both CNNs
    and RNNs to overcome some of these limitations Sowmya and Jose ([2022](#bib.bib229)).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，深度学习的出现彻底改变了该领域，使得可以直接从 ECG 信号中自动学习特征。这一进展在自动 ECG 分类领域具有重要的前景，为临床医生提供了快速准确诊断的工具。基于此，已经提出了几种深度学习架构用于
    ECG 信号的特征学习。例如，Acharya 等人 ([2017](#bib.bib3)) 开发了一个 9 层 CNN 模型来自动识别 ECG 信号中的五类心跳。类似的模型也在
    Baloglu 等人 ([2019](#bib.bib18)) 中开发。然而，ECG 信号的长度通常会有显著变化，因为它们可能包含不同数量的心跳。CNN 通常需要固定长度的输入，这可能需要进行诸如填充或截断的预处理步骤，从而可能丢失重要的时间信息。因此，几个架构在
    ECG 分类中利用了 RNN，如 Singh 等人 ([2018](#bib.bib227))、Prabhakararao 和 Dandapat ([2020](#bib.bib195))
    和 Wang 等人 ([2023b](#bib.bib263)) 等。尽管 RNN 能够处理序列数据，但它们在有效捕捉局部模式或短期依赖方面也存在局限性。在
    ECG 信号中，局部特征如特定波形或间隔对于分类可能至关重要。因此，近期的工作提出了结合 CNN 和 RNN 优势的混合模型，以克服这些局限性，如 Sowmya
    和 Jose ([2022](#bib.bib229)) 中所示。
- en: The work of Rai et al. Rai and Chatterjee ([2022](#bib.bib202)) developed a
    hybrid CNN-LSTM network to evaluate the optimum performing model for myocardial
    infarction detection using ECG signals. The authors then experimented on 123,998
    ECG beats obtained from the PTB diagnostic database (PTBDB) and MIT-BIH arrhythmia
    database (MITDB), and the result showed that by combining the capabilities of
    both CNN and LSTM, improved classification accuracy can be achieved. Also, in
    Banerjee et al. ([2020](#bib.bib19)), a CNN architecture was developed to extract
    morphological features from ECG signals. For the purpose of determining the degree
    of heart rate variability, another composite structure was designed using LSTM
    and a collection of manually created statistical features. Following that, a hybrid
    CNN-LSTM architecture is built using the two independent biomarkers to classify
    cardiovascular artery diseases, and experiments were carried out on two distinct
    datasets. The first is a partly noisy in-house dataset collected using an inexpensive
    ECG sensor, and the other is a corpus taken from the MIMIC II waveform dataset.
    The hybrid model proposed in the work achieved an overall classification accuracy
    of 88% and 93%, respectively, which surpasses the performance of standalone architectures.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Rai 等人 ([2022](#bib.bib202)) 的研究开发了一个混合 CNN-LSTM 网络，用于评估最佳心肌梗塞检测模型，使用 ECG 信号。作者在
    PTB 诊断数据库 (PTBDB) 和 MIT-BIH 心律失常数据库 (MITDB) 中实验了 123,998 个 ECG 心跳，结果表明，通过结合 CNN
    和 LSTM 的能力，可以实现改进的分类准确性。此外，在 Banerjee 等人 ([2020](#bib.bib19)) 中，开发了一种 CNN 架构来提取
    ECG 信号中的形态特征。为了确定心率变异性的程度，还设计了一个复合结构，使用 LSTM 和一组手动创建的统计特征。随后，建立了一个混合 CNN-LSTM
    架构，利用这两个独立的生物标志物来分类心血管动脉疾病，并在两个不同的数据集上进行了实验。第一个是使用便宜的 ECG 传感器收集的部分噪声的内部数据集，另一个是取自
    MIMIC II 波形数据集的语料库。该工作中提出的混合模型分别实现了 88% 和 93% 的整体分类准确率，超过了单一架构的性能。
- en: An automated diagnosis method based on Deep CNN and LSTM architecture was presented
    in Kusuma and Jothi ([2022](#bib.bib122)) to identify Congestive Heart Failure
    (CHF) from ECG signals. Specifically, CNN was used to extract deep features, and
    LSTM was employed to exploit the extracted features to achieve the CHF detection
    goal. The model was tested using real-time ECG signal datasets, and the results
    showed that the AUC was 99.9%, the sensitivity was 99.31%, the specificity was
    99.28%, the F-Score was 98.94%, and the accuracy was 99.52%. However, since ECG
    signals can vary in length due to differences in recording durations or patient
    conditions. LSTMs are capable of handling variable-length sequences, but traditional
    CNNs typically require fixed-length inputs. Therefore, fusing these features effectively
    in a hybrid model can be challenging. Also, Hybrid CNN-RNN models can be computationally
    intensive, especially when processing long ECG sequences or large datasets. For
    this reason, recent research works have proposed the use of attention mechanisms
    to reduce the computational burden by enabling the model to selectively attend
    to informative features, focusing computational resources where they are most
    needed. Likewise, attention mechanisms can enable the model to attend to informative
    segments of the ECG signal, regardless of their length, allowing for more flexible
    processing of variable-length sequences.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: Kusuma 和 Jothi ([2022](#bib.bib122)) 提出了一种基于深度 CNN 和 LSTM 架构的自动诊断方法，用于从 ECG
    信号中识别充血性心力衰竭（CHF）。具体来说，CNN 被用来提取深层特征，而 LSTM 被用来利用提取的特征以实现 CHF 检测目标。该模型使用实时 ECG
    信号数据集进行了测试，结果显示 AUC 为 99.9%，灵敏度为 99.31%，特异性为 99.28%，F-Score 为 98.94%，准确率为 99.52%。然而，由于
    ECG 信号的长度可能由于记录时间或患者状况的不同而有所变化，LSTM 能够处理变长序列，但传统的 CNN 通常需要固定长度的输入。因此，在混合模型中有效融合这些特征可能具有挑战性。此外，混合
    CNN-RNN 模型在处理长 ECG 序列或大数据集时可能会计算密集。为此，最近的研究工作提议使用注意力机制，通过使模型能够选择性地关注信息特征，从而减少计算负担，将计算资源集中在最需要的地方。同样，注意力机制可以使模型关注
    ECG 信号中有信息的片段，无论其长度如何，从而允许对变长序列进行更灵活的处理。
- en: Several researchers have leveraged attention mechanisms in standalone and hybrid
    architectures for improved performance. For instance, in the work of Chun-Yen
    et al. Chen et al. ([2022a](#bib.bib31)), CNN layers were used to extract main
    features, while LSTM and attention were included to enhance the model’s feature
    learning capabilities. Experiments on a 12-lead KMUH ECG dataset showed that the
    model had high recognition rates in classifying normal and abnormal ECG signals,
    compared to hybrid models without attention mechanisms. Wang et al. Wang et al.
    ([2021](#bib.bib262)) presented a 33-layer CNN architecture with non-local convolutional
    block attention module (NCBAM). To extract the spatial and channel information,
    preprocessed ECG signals were first fed into the CNN architecture. A non-local
    attention further captured long-range dependencies of representative features
    along spatial and channel axes. Similarly, a spatio-temporal attention-based convolutional
    recurrent neural network (STA-CRNN) was presented in Zhang et al. ([2020a](#bib.bib295))
    with the aim of concentrating on representative features in both the spatial and
    temporal dimensions. The CNN subnetwork, spatiotemporal attention modules, and
    RNN subnetwork made up the STA-CRNN and according to findings, the STA-CRNN model
    was able to classify eight different forms of arrhythmias and normal rhythm with
    an average F1 score of 0.835.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究人员在独立和混合架构中利用了注意力机制以提高性能。例如，在 Chun-Yen 等人 Chen 等人 ([2022a](#bib.bib31))
    的工作中，CNN 层被用来提取主要特征，同时包含 LSTM 和注意力以增强模型的特征学习能力。在 12 导联 KMUH ECG 数据集上的实验显示，该模型在分类正常和异常
    ECG 信号方面的识别率较高，相较于没有注意力机制的混合模型。Wang 等人 Wang 等人 ([2021](#bib.bib262)) 提出了一个 33
    层 CNN 架构，具有非局部卷积块注意力模块（NCBAM）。为了提取空间和通道信息，预处理过的 ECG 信号首先被输入到 CNN 架构中。非局部注意力进一步捕捉了代表性特征在空间和通道轴上的长距离依赖关系。类似地，Zhang
    等人 ([2020a](#bib.bib295)) 提出了基于时空注意力的卷积递归神经网络（STA-CRNN），旨在集中处理空间和时间维度的代表性特征。STA-CRNN
    由 CNN 子网络、时空注意力模块和 RNN 子网络组成，根据研究结果，STA-CRNN 模型能够将八种不同形式的心律失常和正常节律进行分类，平均 F1 分数为
    0.835。
- en: Combining hybrid deep learning models with attention mechanisms for ECG feature
    learning is a promising approach that has already shown potential in ECG feature
    learning, according to reviewed literature. Future research can further explore
    semi-supervised and self-supervised learning techniques to leverage large amounts
    of unlabeled ECG data. This could involve pre-training models on large-scale unlabeled
    datasets using self-supervised learning objectives. Also, deep learning models
    have been leveraged in the generation of synthetic ECG signals to augment real
    signals, as seen in Zhu et al. ([2019a](#bib.bib302)) where a GAN model was developed
    to generate ECG signals that correspond with available clinical data. The GAN
    model used two layers of BiLSTM networks for the generator and CNN for the discriminator,
    and trained using the 48 ECG recordings of different users from the MIT-BIH dataset.
    The authors then compared their model with a Recurrent neural network autoencoder
    (RNN-AE) model and a recurrent neural network variational autoencoder (RNN-VAE)
    model, and the results showed that their model exhibited the fastest convergence
    of its loss function to zero. Future research can also incorporate attention mechanisms
    into hybrid GAN architectures to improve the quality of generated signals. Likewise,
    real-time detection of heart diseases is paramount, future work can develop efficient
    algorithms for real-time processing of ECG data. This could involve optimizing
    existing architectures and leveraging hardware acceleration techniques to enable
    real-time inference on resource-constrained devices such as wearable sensors and
    implantable devices.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 将混合深度学习模型与注意力机制结合用于ECG特征学习是一种有前途的方法，已有文献表明其在ECG特征学习中展现了潜力。未来的研究可以进一步探索半监督和自监督学习技术，以利用大量未标记的ECG数据。这可能涉及使用自监督学习目标在大规模未标记数据集上进行预训练模型。此外，深度学习模型已被用于生成合成ECG信号，以增强真实信号，正如Zhu等人（[2019a](#bib.bib302)）所示，他们开发了一个GAN模型来生成与现有临床数据相对应的ECG信号。GAN模型使用了两层BiLSTM网络作为生成器，CNN作为判别器，并使用MIT-BIH数据集中的48个不同用户的ECG记录进行训练。作者将他们的模型与递归神经网络自编码器（RNN-AE）模型和递归神经网络变分自编码器（RNN-VAE）模型进行了比较，结果表明他们的模型在其损失函数收敛到零的速度上最快。未来的研究还可以将注意力机制融入混合GAN架构中，以提高生成信号的质量。同样，实时检测心脏疾病至关重要，未来的工作可以开发高效的算法以实现ECG数据的实时处理。这可能涉及优化现有架构和利用硬件加速技术，以便在资源受限的设备如可穿戴传感器和植入设备上实现实时推断。
- en: 4.2.4 Electroencephalography (EEG) Classification
  id: totrans-197
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.4 脑电图（EEG）分类
- en: Three-dimensional scalp surface electrode readings provide a dynamic time series
    that is called Electroencephalogram (EEG) signal Schirrmeister et al. ([2017](#bib.bib214)).
    Brain waves obtained from an EEG can effectively depict both the psychological
    and pathological states of a human. The human brain is acknowledged to be a fascinating
    and incredibly complicated structure. Numerous brain signals, including functional
    magnetic resonance imaging (fMRI), near-infrared spectroscopy (NIRS), electroencephalograms
    (EEGs), and functional near-infrared spectroscopy (fNIR), among others have been
    collected and used to study the brain Gao et al. ([2021b](#bib.bib63)). Due to
    the EEG’s non-invasive, affordable, accessible, and excellent temporal resolution
    characteristics, it has become the most utilised approach. However, the signal-to-noise
    ratio of EEG signal is low, meaning that sources with no task-relevant information
    frequently have a stronger effect on the EEG signal than those that do. These
    characteristics often make end-to-end feature learning for EEG data substantially
    more challenging Schirrmeister et al. ([2017](#bib.bib214)). Based on this, several
    methods have been leveraged for improved feature extraction in EEG signals across
    several domains including Motor imagery Ang and Guan ([2017](#bib.bib12)), anxiety
    disorder Shen et al. ([2022](#bib.bib218)), epileptic seizure detection Boonyakitanont
    et al. ([2020](#bib.bib23)), sleep pattern analysis and disorder detection Sharma
    et al. ([2021](#bib.bib216)); Vaquerizo-Villar et al. ([2023](#bib.bib256)), and
    Alzheimer’s disease detection Modir et al. ([2023](#bib.bib168)), and many others.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 三维头皮表面电极读数提供了一种动态时间序列，称为脑电图（EEG）信号 Schirrmeister 等 ([2017](#bib.bib214))。从 EEG
    获得的脑波可以有效地描绘出人类的心理和病理状态。人脑被公认为是一个令人着迷且极其复杂的结构。包括功能性磁共振成像（fMRI）、近红外光谱（NIRS）、脑电图（EEG）和功能性近红外光谱（fNIR）在内的众多脑信号已被收集并用于研究大脑
    Gao 等 ([2021b](#bib.bib63))。由于 EEG 具有非侵入性、经济实惠、易于获得和优良的时间分辨率等特点，它已成为最常用的方法。然而，EEG
    信号的信噪比低，这意味着没有任务相关信息的来源通常对 EEG 信号的影响比有任务相关信息的来源更强。这些特点使得对 EEG 数据进行端到端的特征学习变得更加具有挑战性
    Schirrmeister 等 ([2017](#bib.bib214))。基于此，已在多个领域采用了几种方法来改进 EEG 信号的特征提取，包括运动想象
    Ang 和 Guan ([2017](#bib.bib12))、焦虑症 Shen 等 ([2022](#bib.bib218))、癫痫发作检测 Boonyakitanont
    等 ([2020](#bib.bib23))、睡眠模式分析和失调检测 Sharma 等 ([2021](#bib.bib216)); Vaquerizo-Villar
    等 ([2023](#bib.bib256))，以及阿尔茨海默病检测 Modir 等 ([2023](#bib.bib168))，还有许多其他领域。
- en: EEG Motor Imagery (MI) is a technique used to study brain activity associated
    with the imagination of movement. It involves recording electrical activity generated
    by the brain through electrodes placed on the scalp. MI tasks typically involve
    imagining performing a specific motor action, such as moving a hand or foot, without
    physically executing the movement, and has been leveraged in smart healthcare
    applications such as post-stroke rehabilitation and mobile assistive robots, among
    others Altaheri et al. ([2023](#bib.bib10)). Prior to the advent of deep learning,
    motor imagery EEG data are passed through various steps before classification
    using traditional ML techniques. Pre-processing, feature extraction, and classification
    are the three primary stages that traditional approaches usually take while processing
    MI-EEG signals. Pre-processing includes a number of operations, including signal
    filtering (choosing the most valuable frequency range for MI tasks), channel selection
    (identifying the most valuable EEG channels for MI tasks), signal normalisation
    (normalising each EEG channel around the time axis), and artefact removal (removing
    noise from MI-EEG signals). Independent component analysis (ICA) is the most often
    utilised technique for removing artefacts Brunner et al. ([2007](#bib.bib24));
    Delorme et al. ([2007](#bib.bib47)); Jafarifarmand and Badamchizadeh ([2019](#bib.bib106)).
    In contrast to the traditional approach, deep learning architectures can automatically
    extract complex features from raw MI-EEG data without the need for laborious feature
    extraction and pre-processing. Based on this, several deep learning architectures
    have been proposed for MI-EEG feature learning, as seen in Zhang et al. ([2019b](#bib.bib296)),
    Kumar et al. ([2016](#bib.bib121)) and Tibrewal et al. ([2022](#bib.bib249)),
    among others. For instance Schirrmeister et al. ([2017](#bib.bib214)), categorized
    MI-EEG signals using three CNNs with varying architectures, and the number of
    convolutional layers varied from two layers to a five-layer deep ConvNet to a
    thirty-one-layer residual network.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: EEG运动想象（MI）是一种用于研究与运动想象相关的大脑活动的技术。它涉及通过放置在头皮上的电极记录大脑生成的电活动。MI任务通常包括想象执行特定的运动动作，如移动手或脚，而不实际执行这些动作，并且已被用于智能医疗应用，如中风后康复和移动辅助机器人等
    Altaheri 等人 ([2023](#bib.bib10))。在深度学习出现之前，运动想象EEG数据在使用传统机器学习技术进行分类之前会经过多个步骤。预处理、特征提取和分类是传统方法处理MI-EEG信号时通常采取的三个主要阶段。预处理包括多个操作，包括信号过滤（选择最有价值的频率范围用于MI任务）、通道选择（识别用于MI任务的最有价值的EEG通道）、信号归一化（在时间轴上归一化每个EEG通道）以及伪影去除（从MI-EEG信号中去除噪声）。独立成分分析（ICA）是去除伪影时最常用的技术
    Brunner 等人 ([2007](#bib.bib24)); Delorme 等人 ([2007](#bib.bib47)); Jafarifarmand
    和 Badamchizadeh ([2019](#bib.bib106))。与传统方法相比，深度学习架构可以自动从原始MI-EEG数据中提取复杂特征，而无需繁琐的特征提取和预处理。基于此，已经提出了几种用于MI-EEG特征学习的深度学习架构，如
    Zhang 等人 ([2019b](#bib.bib296))、Kumar 等人 ([2016](#bib.bib121)) 和 Tibrewal 等人 ([2022](#bib.bib249))
    等。例如，Schirrmeister 等人 ([2017](#bib.bib214)) 使用三种具有不同架构的CNN对MI-EEG信号进行分类，卷积层的数量从两层到五层深的ConvNet，再到三十一层的残差网络。
- en: In Dai et al. Dai et al. ([2019](#bib.bib42)), the authors proposed an approach
    for classifying MI-EEG signals which blend variational autoencoder with CNN architecture.
    The VAE decoder was used to fit the Gaussian distribution of EEG signals, and
    the time, frequency, and channel information from the EEG signal were combined
    to create a novel representation of input, and the proposed CNN-VAE method was
    optimised for the input. Experiments showed that by combining both deep learning
    architectures, improved features were learnt, which led to a high classification
    performance on the BCI Competition IV dataset 2b. Li et al. Li et al. ([2017](#bib.bib132))
    employed optimal wavelet packet transform (OWPT) for the generation of feature
    vectors from MI-EEG signals. These vectors were then utilized to train an LSTM
    network which demonstrated satisfactory performance on dataset III from the BCI
    Competition 2003\. However, the model has excessively intricate structure. To
    address this, Feng et al. Li et al. ([2020a](#bib.bib129)) introduced a technique
    that merges continuous wavelet transform (CWT) with a simplified convolutional
    neural network to enhance the accuracy of recognizing MI-EEG signals. By employing
    CWT, MI-EEG signals were converted into time-frequency image representations.
    Subsequently, these image representations were fed into the SCNN for feature extraction
    and classification. Experiments on the BCI Competition IV Dataset 2b demonstrate
    that, on average, the classification accuracy across nine subjects reached 83.2%.
    However, the computational complexity of the model was quite high, due to the
    processing of time-frequency image representations. The conversion of MI-EEG signals
    into time-frequency images using CWT requires significant computational resources.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 在Dai等人（[2019](#bib.bib42)）的研究中，作者提出了一种将变分自编码器与CNN架构结合用于分类MI-EEG信号的方法。VAE解码器被用来拟合EEG信号的高斯分布，同时将EEG信号的时间、频率和通道信息结合起来，以创建输入的全新表示，所提出的CNN-VAE方法针对输入进行了优化。实验表明，通过结合这两种深度学习架构，学习到的特征得到了改进，从而在BCI
    Competition IV数据集2b上达到了较高的分类性能。Li等人（[2017](#bib.bib132)）采用了最优小波包变换（OWPT）来生成MI-EEG信号的特征向量。这些向量随后被用于训练LSTM网络，并在BCI
    Competition 2003数据集III上表现出令人满意的性能。然而，该模型的结构过于复杂。为了解决这个问题，Feng等人（[2020a](#bib.bib129)）引入了一种将连续小波变换（CWT）与简化卷积神经网络相结合的技术，以提高识别MI-EEG信号的准确性。通过使用CWT，MI-EEG信号被转换为时频图像表示。随后，这些图像表示被输入到SCNN中进行特征提取和分类。对BCI
    Competition IV数据集2b的实验表明，平均而言，九个受试者的分类准确率达到了83.2%。然而，由于处理时频图像表示，模型的计算复杂性较高。使用CWT将MI-EEG信号转换为时频图像需要大量的计算资源。
- en: The authors in Hwang et al. ([2023](#bib.bib99)) introduced a classification
    framework based on Long Short-Term Memory (LSTM) to improve the accuracy of classifying
    four-class motor imagery signals from EEG. The authors sliding window technique
    to capture time-varying EEG signal data, and employed an overlapping-band-based
    Filter Bank Common Spatial Patterns (FBCSP) method to extract subject-specific
    spatial features. Experiments on the BCI Competition IV dataset 2a, showed that
    their model achieved an average accuracy of 97%, compared to existing methods.
    Also, in the classification of Alzheimer’s disease, Zhao et al. Zhao and He ([2015](#bib.bib301))
    employed a deep learning network to analyse EEG data. The deep learning model
    was evaluated on a dataset that consist of fifteen (15) patients with clinically
    confirmed Alzheimer’s disease and fifteen (15) healthy individuals, and results
    showed that improved features were learnt and compared the results to the traditional
    methods. This has prompted the use of deep learning in Alzheimer’s disease detection,
    as seen in Xia et al. ([2023](#bib.bib277)), where the authors used CNN for diagnosing
    Alzheimer’s Disease. To address challenges posed by limited data and overfitting
    in deep learning models designed for Alzheimer’s Disease detection, the authors
    explored the use of overlapping sliding windows to augment the EEG data collected
    from 100 subjects (comprising 49 AD patients, 37 mild cognitive impairment patients,
    and 14 healthy controls subjects). After assembling the augmented dataset, a modified
    Deep Pyramid Convolutional Neural Network (DPCNN) was used to classify the enhanced
    EEG signals. In epilepsy detection, Hermawan et al. ([2024](#bib.bib85)) developed
    three deep learning architectures (CNN, LSTM, and hybrid CNN-LSTM), with each
    model chosen for its effectiveness in handling the intricate characteristics of
    EEG data. Each architecture offers distinct advantages, with CNN excelling in
    spatial feature extraction, LSTM in capturing temporal dynamics, and the hybrid
    model combining these strengths. The CNN model, consisting of 31 layers, attained
    the highest accuracy, achieving 91% on the first benchmark dataset and 82% on
    the second dataset using a 30-second threshold, selected for its clinical significance.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Hwang等人（[2023](#bib.bib99)）引入了一种基于长短期记忆（LSTM）的分类框架，以提高从EEG中分类四类运动想象信号的准确性。作者使用滑动窗口技术捕捉时间变化的EEG信号数据，并采用基于重叠带的滤波器组公共空间模式（FBCSP）方法提取特定于受试者的空间特征。对BCI竞赛IV数据集2a的实验表明，他们的模型实现了97%的平均准确率，相较于现有方法也有所提升。此外，在阿尔茨海默病的分类中，赵等人（[2015](#bib.bib301)）使用深度学习网络分析EEG数据。该深度学习模型在一个包含15名临床确诊阿尔茨海默病患者和15名健康个体的数据集上进行了评估，结果表明改进的特征已被学习，并与传统方法进行了比较。这促使了深度学习在阿尔茨海默病检测中的应用，正如Xia等人（[2023](#bib.bib277)）所示，作者使用CNN诊断阿尔茨海默病。为了应对深度学习模型在阿尔茨海默病检测中面临的有限数据和过拟合挑战，作者探索了使用重叠滑动窗口来增强从100名受试者（包括49名AD患者、37名轻度认知障碍患者和14名健康对照）收集的EEG数据。在组装增强数据集后，使用了修改版的深度金字塔卷积神经网络（DPCNN）来分类增强的EEG信号。在癫痫检测方面，Hermawan等人（[2024](#bib.bib85)）开发了三种深度学习架构（CNN、LSTM和混合CNN-LSTM），每种模型都因其在处理EEG数据复杂特征中的有效性而被选择。每种架构都有不同的优势，CNN在空间特征提取上表现出色，LSTM在捕捉时间动态上表现优异，而混合模型则结合了这些优点。CNN模型由31层组成，在第一个基准数据集上达到了91%的最高准确率，在第二个数据集上使用30秒阈值达到了82%的准确率，这一阈值被选为其临床意义。
- en: In the work of Abdulwahhab et al. Abdulwahhab et al. ([2024](#bib.bib1)), EEG
    waves’ time-frequency image and raw EEG waves served as input elements for CNN
    and LSTM models. Two signal processing methods, namely Short-Time Fourier Transform
    (STFT) and CWT, were employed to generate spectrogram and scalogram images, sized
    at 77 × 75 and 32 × 32, respectively. The experimental findings demonstrated detection
    accuracies of 99.57% and 99.26% for CNN inputs using CWT Scalograms on the Bonn
    University dataset and 99.57% and 97.12% using STFT spectrograms on the CHB-MIT
    dataset. Similarly, in emotion recognition, several deep learning models have
    been leveraged with EEG signals. For instance, in Pandey and Seeja ([2022](#bib.bib189)),
    a subject-independent emotion recognition model was proposed, which utilizes Variational
    Mode Decomposition (VMD) for feature extraction and DNN as the classifier. Evaluation
    against the benchmark DEAP dataset demonstrates superior performance of this approach
    compared to other techniques in subject-independent emotion recognition from EEG
    signals. Also, some researchers have also combined EEG signals with facial expression
    and speech in emotion recognition, as seen in Hassouneh et al. ([2020](#bib.bib78)),
    Pan et al. ([2023](#bib.bib188)), and Wang et al. ([2023c](#bib.bib267)), among
    others. However, EEG signals can vary significantly across individuals, making
    it challenging to generalize models across different subjects. Future models could
    explore methods for adapting or personalizing models to account for inter-subject
    variability and improve performance on individual subjects. Also, EEG electrodes
    cover only a fraction of the brain’s surface, resulting in limited coverage of
    neural activity. Deep learning models could investigate strategies to infer activity
    from unobserved brain regions or integrate information from multiple modalities
    to provide more comprehensive coverage. These areas can still be further explored.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在Abdulwahhab等人的研究中，Abdulwahhab等人（[2024](#bib.bib1)）使用脑电图（EEG）波的时间-频率图像和原始EEG波作为CNN和LSTM模型的输入元素。采用了两种信号处理方法，即短时傅里叶变换（STFT）和连续小波变换（CWT），生成了尺寸分别为77
    × 75和32 × 32的谱图和小波图。实验结果显示，在使用CWT小波图进行CNN输入时，Bonn大学数据集的检测准确率为99.57%和99.26%，而使用STFT谱图进行CNN输入时，CHB-MIT数据集的准确率为99.57%和97.12%。类似地，在情感识别中，多个深度学习模型已经利用EEG信号。例如，在Pandey和Seeja（[2022](#bib.bib189)）的研究中，提出了一种独立于受试者的情感识别模型，该模型利用变分模态分解（VMD）进行特征提取，并使用DNN作为分类器。与基准DEAP数据集的比较评估表明，该方法在从EEG信号中进行独立于受试者的情感识别方面，比其他技术表现更优。此外，一些研究者还将EEG信号与面部表情和语音结合用于情感识别，如Hassouneh等人（[2020](#bib.bib78)）、Pan等人（[2023](#bib.bib188)）和Wang等人（[2023c](#bib.bib267)）等。然而，EEG信号在个体之间可能存在显著差异，这使得在不同受试者之间推广模型变得具有挑战性。未来的模型可以探索适应或个性化模型的方法，以应对个体间的差异，并提高对个体受试者的性能。此外，EEG电极仅覆盖大脑表面的一部分，导致神经活动的覆盖范围有限。深度学习模型可以研究从未观测的大脑区域推断活动的策略，或整合来自多种模态的信息，以提供更全面的覆盖。这些领域仍然可以进一步探索。
- en: 4.2.5 Finance
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.5 财务
- en: 'Over the past few decades, computational intelligence in finance has been a
    hot issue in both academia and the financial sector Ozbayoglu et al. ([2020](#bib.bib186)).
    Deep learning, especially RNN models have gained significant traction in the field
    of finance due to its ability to handle sequential data, since financial data
    often exhibit sequential dependencies, such as time series data for stock prices
    or historical transaction data. Within the financial industry, researchers have
    developed deep learning models for stock market forecasting Singh and Srivastava
    ([2017](#bib.bib226)), algorithmic trading Lei et al. ([2020](#bib.bib127)), credit
    risk assessment Shen et al. ([2021](#bib.bib217)), portfolio allocation Wang et al.
    ([2020b](#bib.bib268)), asset pricing Chen et al. ([2024](#bib.bib33)), and derivatives
    markets Ahnouch et al. ([2023](#bib.bib4)), among others and these models are
    intended to offer real-time operational solutions. In exchange rate prediction,
    Sun et al. Sun et al. ([2020](#bib.bib237)) developed an ensemble deep learning
    technique known as LSTM-B by combining a bagging ensemble learning algorithm with
    a long-short term memory (LSTM) neural network to increase the profitability of
    exchange rate trading and produce accurate exchange rate forecasting results.
    In comparison to previous methodologies, the authors’ estimates proved to be more
    accurate when they looked at the potential financial profitability of exchange
    rates between the US dollar (USD) and four other major currencies: GBP, JPY, EUR,
    and CNY.'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 过去几十年中，金融领域的计算智能一直是学术界和金融部门的热门话题（Ozbayoglu 等，[2020](#bib.bib186)）。深度学习，尤其是RNN模型，由于其处理序列数据的能力，已在金融领域获得显著关注，因为金融数据通常表现出序列依赖性，如股票价格的时间序列数据或历史交易数据。在金融行业内，研究人员已开发出用于股票市场预测的深度学习模型（Singh
    和 Srivastava，[2017](#bib.bib226)）、算法交易（Lei 等，[2020](#bib.bib127)）、信用风险评估（Shen
    等，[2021](#bib.bib217)）、投资组合配置（Wang 等，[2020b](#bib.bib268)）、资产定价（Chen 等，[2024](#bib.bib33)）和衍生品市场（Ahnouch
    等，[2023](#bib.bib4)）等，这些模型旨在提供实时操作解决方案。在汇率预测方面，Sun 等（[2020](#bib.bib237)）开发了一种名为LSTM-B的集成深度学习技术，通过将集成学习算法与长短期记忆（LSTM）神经网络相结合，以提高汇率交易的盈利能力并生成准确的汇率预测结果。与以前的方法相比，作者的估计在评估美元（USD）与四种主要货币：GBP、JPY、EUR
    和 CNY 之间的潜在金融盈利性时证明更为准确。
- en: The authors in Abedin et al. ([2021](#bib.bib2)) proposed a Bi-LSTM-BR technique,
    which combined Bagging Ridge (BR) regression with Bi-LSTM as base regressors.
    The pre-COVID-19 and COVID-19 exchange rates of 21 currencies against the USD
    were predicted using the Bi-LSTM BR, and experiments showed that the proposed
    method outperformed ML algorithms such as DT and SVM. However, exchange rate data
    can be noisy and subject to non-stationarity, which can pose challenges for predictive
    modelling. While bagging techniques can help mitigate the effects of noise to
    some extent, they may struggle to capture long-term trends or sudden shifts in
    the data distribution, leading to suboptimal performance. To address this, Wang
    et al. Wang et al. ([2023a](#bib.bib260)) presented an approach for one-day ahead
    of time exchange rate prediction that concurrently considers both supervised and
    unsupervised deep representation features to enhance Random Subspace. Two crucial
    phases in the SUDF-RS technique are feature extraction and model building. First,
    LSTM and deep belief networks, respectively, extract the supervised and unsupervised
    deep representation features. To produce high-quality feature subsets, an enhanced
    random subspace approach was created that integrates a random forest-based feature
    weighting mechanism. Then, the matching base learner is trained using each feature
    subset, and the final outcomes are generated by averaging the outcomes of each
    base learner. Experiments on EUR/USD, GBP/USD and USD/JPY showed that improved
    accuracy was achieved using the model.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: Abedin 等人（[2021](#bib.bib2)）提出了一种 Bi-LSTM-BR 技术，该技术将 Bagging Ridge (BR) 回归与
    Bi-LSTM 结合作为基础回归器。使用 Bi-LSTM BR 预测了 21 种货币对美元的疫情前和疫情期间的汇率，实验表明，该方法优于如 DT 和 SVM
    等机器学习算法。然而，汇率数据可能会嘈杂且受到非平稳性的影响，这可能会给预测建模带来挑战。虽然 bagging 技术可以在一定程度上减轻噪声的影响，但它们可能难以捕捉数据分布中的长期趋势或突然变化，从而导致次优性能。为了解决这个问题，Wang
    等人（[2023a](#bib.bib260)）提出了一种考虑有监督和无监督深度表示特征以增强随机子空间的前瞻性汇率预测方法。SUDF-RS 技术中的两个关键阶段是特征提取和模型构建。首先，LSTM
    和深度置信网络分别提取有监督和无监督的深度表示特征。为了生成高质量的特征子集，创建了一种改进的随机子空间方法，该方法整合了基于随机森林的特征加权机制。然后，使用每个特征子集训练匹配基础学习器，并通过平均每个基础学习器的结果来生成最终结果。对
    EUR/USD、GBP/USD 和 USD/JPY 的实验表明，该模型实现了更高的准确性。
- en: In stock market prediction, several deep learning architectures have been proposed
    in the literature. For instance, Nikou et al. ([2019](#bib.bib181)), conducted
    a comparative study between the ANN, SVR, RF and an LSTM model. As compared to
    the other models discussed in the study, the LSTM model outperformed the others
    in predicting the closing prices of iShares MSCI United Kingdom. Similarly, using
    stock market historical data and financial news, Cai et al. Cai et al. ([2018](#bib.bib25))
    used CNN and LSTM forecasting methods to generate seven prediction models. The
    seven models were then combined into a single ensemble model in accordance with
    the ensemble learning approach to create an aggregated model. However, the accuracy
    of all the models’ predictions was low. Gudelek et al. Gudelek et al. ([2017](#bib.bib73))
    proposed a CNN model which used a sliding window technique and created pictures
    by capturing daily snapshots within the window’s bounds. With 72% accuracy, the
    model was able to forecast the prices for the following day and was able to generate
    5 times the starting capital. In Eapen et al. Eapen et al. ([2019](#bib.bib56)),
    a CNN and Bi-LSTM model with numerous pipelines was proposed, utilising an SVM
    regressor model on the S&P 500 Grand Challenge dataset, and results showed enhanced
    prediction performance by over a factor of 6% compared to baseline models. As
    presented, deep learning has undeniably achieved state-of-the-art performance
    across various domains within finance. However, due to the sensitive nature of
    financial research, future work can focus on enhancing the interpretability of
    deep learning models in financial predictions. Researchers should explore techniques
    to explain the predictions of models, to improve trust and understanding of model
    decisions, which is essential for adoption in finance.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 在股票市场预测中，文献中提出了几种深度学习架构。例如，Nikou 等人 ([2019](#bib.bib181)) 进行了一个比较研究，比较了 ANN、SVR、RF
    和 LSTM 模型。与研究中讨论的其他模型相比，LSTM 模型在预测 iShares MSCI 英国的收盘价格方面表现优于其他模型。同样，利用股票市场历史数据和金融新闻，Cai
    等人 ([2018](#bib.bib25)) 使用 CNN 和 LSTM 预测方法生成了七个预测模型。这七个模型随后根据集成学习方法被组合成一个单一的集成模型，以创建一个聚合模型。然而，所有模型的预测准确性都较低。Gudelek
    等人 ([2017](#bib.bib73)) 提出了一个 CNN 模型，该模型使用滑动窗口技术，通过捕捉窗口范围内的每日快照来创建图片。该模型具有 72%
    的准确率，能够预测第二天的价格，并且可以产生 5 倍的初始资本。在 Eapen 等人 ([2019](#bib.bib56)) 的研究中，提出了一个 CNN
    和 Bi-LSTM 模型，具有多个管道，利用 SVM 回归模型在 S&P 500 Grand Challenge 数据集上进行预测，结果显示预测性能比基准模型提高了超过
    6%。如上所述，深度学习在金融领域各个领域无疑已实现了最先进的性能。然而，由于金融研究的敏感性，未来的工作可以集中在提高深度学习模型在金融预测中的可解释性。研究人员应探索解释模型预测的技术，以提高对模型决策的信任和理解，这对金融领域的采纳至关重要。
- en: 4.3 Natural Language Processing
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 自然语言处理
- en: Natural language processing (NLP) refers to the field of artificial intelligence
    that concerns with enabling computers to process, analyze and interpret human
    languages to extract useful information. Some of the common tasks in NLP are machine
    translation, text classification and text generation. Deep learning has been widely
    applied to solve real-world NLP problems. This section presents the recent advancements
    in deep learning models that have been designed for NLP over the past few years.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 自然语言处理（NLP）是人工智能的一个领域，涉及使计算机处理、分析和解释人类语言以提取有用信息。一些常见的 NLP 任务包括机器翻译、文本分类和文本生成。深度学习已广泛应用于解决实际的
    NLP 问题。本节介绍了近年来为 NLP 设计的深度学习模型的最新进展。
- en: 4.3.1 Text Classification
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 文本分类
- en: Text classification known as text categorization, is a task that involves assigning
    predefined categories or labels to a piece of text based on its content. The task
    is commonly used in various applications such as document classification, sentiment
    analysis and spam filtering. Numerous deep learning models have been proposed
    for text classification in the past few decades, and multilayer perceptron is
    one of the earliest architectures adopted to classify documents Calvo and Ceccatto
    ([2000](#bib.bib27)); Yu et al. ([2008](#bib.bib289)). The model typically has
    a single hidden layer with a number of units between 15 and 150\. Text data is
    inherently sequential, as it is composed of a series of words and symbols arranged
    in a specific order. This property makes RNN and its variants particularly well-suited
    for processing and analyzing text data. In Arevian ([2007](#bib.bib14)), RNN with
    two hidden layers, each with 6 units is used to classify news documents into eight
    classes. A study was conducted to investigate the variants of RNN i.e. LSTM and
    GRU for text classification Huang and Feng ([2020](#bib.bib96)). The input to
    the model is a sequence of words of fixed length. The input sequence is also sliced
    into smaller subsequences of fixed length and passed to an independent model for
    parallelization. A convolutional layer can extract local features, allowing the
    model to leverage hierarchical temporal information in textual data. A hybrid
    model of convolutional and LSTM architecture is proposed for text classification
    Wang et al. ([2019](#bib.bib266)). Two parallel convolutional layers are used
    to extract features from word embeddings, followed by max-pooling layers to reduce
    the feature dimensions. The reduced features are then concatenated and passed
    to LSTM for prediction.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 文本分类，也称为文本归类，是一个涉及根据内容将预定义的类别或标签分配给一段文本的任务。这个任务在各种应用中很常见，如文档分类、情感分析和垃圾邮件过滤。在过去几十年中，已经提出了许多深度学习模型用于文本分类，多层感知机是最早用于文档分类的架构之一
    Calvo 和 Ceccatto ([2000](#bib.bib27)); Yu 等 ([2008](#bib.bib289))。该模型通常具有一个隐藏层，层中单元的数量介于
    15 和 150 之间。文本数据本质上是顺序的，因为它由按特定顺序排列的一系列单词和符号组成。这一特性使得 RNN 及其变体特别适合处理和分析文本数据。在
    Arevian ([2007](#bib.bib14)) 中，使用具有两个隐藏层（每层 6 个单元）的 RNN 将新闻文档分类为八类。一项研究调查了 RNN
    的变体，即 LSTM 和 GRU，用于文本分类 Huang 和 Feng ([2020](#bib.bib96))。模型的输入是固定长度的单词序列。输入序列还被切分成固定长度的子序列，并传递给独立模型以实现并行化。卷积层可以提取局部特征，使模型能够利用文本数据中的层次时间信息。Wang
    等 ([2019](#bib.bib266)) 提出了一个卷积和 LSTM 架构的混合模型用于文本分类。两个并行卷积层用于从词嵌入中提取特征，随后是最大池化层以减少特征维度。然后，将减少的特征连接在一起，并传递给
    LSTM 进行预测。
- en: Although CNN and RNN provide excellent results on text classification tasks,
    the models lack the ability to attend to specific words based on their importance
    and context. To address this limitation, attention mechanism is incorporated into
    the model to focus on the important features, enhancing the text classification
    accuracy. In Liu and Guo ([2019](#bib.bib143)), two attention modules are introduced
    to capture the contextual information of the feature sequence extracted by bi-directional
    LSTM. The first attention module attends the sequence in forward direction while
    the backward sequence is attended by the second attention module. The convolutional
    layers are used before the bi-directional LSTM to extract features from the word
    embedding. The attention modules require sequential processing using RNN-based
    architecture such as LSTM and GRU which may lead to information loss and distorted
    representations, particularly in long sequence. Furthermore, the attention modules
    focus on inter-sequence relationships between the input sequence and the target,
    ignoring the intra-sequence relationships or the dependencies between the words.
    In Lin et al. ([2017b](#bib.bib142)), the deep learning model is integrated with
    self-attention to capture the intra-sequence relationships between the features
    in the sequence. A multilayer of bi-directional LSTMs is utilized to extract feature
    sequence from the word embedding before the self-attention module attends the
    feature sequence to compute the attention weights. To further improve the overall
    performance, a multichannel features consisting of three input pipelines is introduced
    Li et al. ([2020b](#bib.bib134)). Each pipeline concatenates the word vector with
    a feature vector derived from the input sequence such as the word position, part-of-speech
    and word dependency parsing. The input pipeline is connected to bi-directional
    LSTM, followed by a self-attention module to learn the dependencies between the
    features in the sequence.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 CNN 和 RNN 在文本分类任务中提供了出色的结果，但这些模型缺乏根据词汇的重要性和上下文来关注特定词汇的能力。为了解决这个问题，注意力机制被引入模型中，以关注重要特征，从而提高文本分类的准确性。在刘和郭（[2019](#bib.bib143)）中，引入了两个注意力模块，以捕捉由双向
    LSTM 提取的特征序列的上下文信息。第一个注意力模块关注序列的正向，而第二个注意力模块则关注反向序列。卷积层用于双向 LSTM 之前，从词嵌入中提取特征。注意力模块需要使用基于
    RNN 的架构，如 LSTM 和 GRU 进行顺序处理，这可能导致信息丢失和表示失真，特别是在长序列中。此外，注意力模块关注输入序列与目标之间的序列间关系，而忽略了序列内部的关系或词汇之间的依赖性。在林等（[2017b](#bib.bib142)）中，深度学习模型集成了自注意力，以捕捉序列中特征之间的内部关系。在自注意力模块关注特征序列计算注意力权重之前，利用多层双向
    LSTM 从词嵌入中提取特征序列。为了进一步提高整体性能，李等（[2020b](#bib.bib134)）引入了一个由三个输入管道组成的多通道特征。每个管道将词向量与从输入序列中得出的特征向量（如词的位置、词性和词依赖解析）连接。输入管道连接到双向
    LSTM，然后是一个自注意力模块，以学习序列中特征之间的依赖关系。
- en: The transformer is a deep learning architecture that transforms sequential data
    using self-attention mechanisms, allowing long-range dependencies and complex
    patterns to be captured. The architecture is the basis of various advanced deep
    learning models and the Bi-directional Encoder Representations from Transformers
    popularly known as BERT is one of the examples that leverage transformer for pre-training
    on large scale textual data Devlin et al. ([2018](#bib.bib49)). BERT is a bi-directional
    transformer encoder that is designed for various NLP tasks, capable of capturing
    the contextual information from both preceding and succeeding words in the input
    sequence. Several improvements have been made to BERT to enhance its overall performance
    such as ALBERT Lan et al. ([2019](#bib.bib123)), RoBERTa Liu et al. ([2019b](#bib.bib150))
    and DeBERTa He et al. ([2020a](#bib.bib82)). The improvements are centered around
    refining the pre-training approaches such as dynamic masking of the training instances,
    training with a block of sentences and representing each input word using two
    vectors, both content and position of the word. Most of the recent works leverage
    BERT and its variants to capture effective feature representation of the input
    sequence. In Rodrawangpai and Daungjaiboon ([2022](#bib.bib208)), BERT and its
    variants are leveraged to capture the long-range dependencies of the input tokens.
    The features are then passed to a layer normalization and a linear fully-connected
    layer with dropout for classification. Similar work is reported in Murfi et al.
    ([2024](#bib.bib173)) whereby BERT is used to extract the features and the features
    are then passed to a hybrid of convolutional and recurrent neural networks. The
    traditional machine learning algorithms have been used to classify the features
    extracted by BERT Hao et al. ([2023](#bib.bib77)). The study shows machine learning
    algorithms can effectively leverage the rich contextual features extracted by
    BERT for downstream classification tasks.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: Transformer 是一种深度学习架构，它使用自注意力机制来转换序列数据，从而捕捉长程依赖关系和复杂模式。该架构是各种先进深度学习模型的基础，其中双向编码器表示的变换器，通常被称为
    BERT，是利用 Transformer 在大规模文本数据上进行预训练的一个例子 Devlin et al. ([2018](#bib.bib49))。BERT
    是一个双向 Transformer 编码器，设计用于各种 NLP 任务，能够捕捉输入序列中前后词语的上下文信息。为了提高 BERT 的整体性能，已经进行了若干改进，例如
    ALBERT Lan et al. ([2019](#bib.bib123))、RoBERTa Liu et al. ([2019b](#bib.bib150))
    和 DeBERTa He et al. ([2020a](#bib.bib82))。这些改进主要集中在优化预训练方法上，例如动态掩码训练实例、使用句块进行训练以及用两个向量表示每个输入词语，包括词语的内容和位置。大多数最近的研究工作利用
    BERT 及其变体来捕捉输入序列的有效特征表示。在 Rodrawangpai 和 Daungjaiboon ([2022](#bib.bib208)) 中，BERT
    及其变体被用来捕捉输入标记的长程依赖关系。然后，这些特征会传递给一个层归一化和一个带有 dropout 的线性全连接层进行分类。类似的工作在 Murfi et
    al. ([2024](#bib.bib173)) 中也有报道，其中 BERT 被用来提取特征，提取的特征随后被传递给一个卷积和递归神经网络的混合模型。传统的机器学习算法被用来分类
    BERT 提取的特征 Hao et al. ([2023](#bib.bib77))。研究表明，机器学习算法可以有效地利用 BERT 提取的丰富上下文特征来进行下游分类任务。
- en: 'In text classification, the text labels can help in capturing the words relevant
    to the classification. The label-embedding attentive model is one of the earliest
    attempts to joint learn the label and word embeddings in the same latent space
    and measure the compatibility between labels and words using cosine similarity
    Wang et al. ([2018a](#bib.bib259)). The joint embedding allows the model to capture
    more effective text representations, increasing the overall performance of the
    model. LANTRN is a deep learning model that leverages label embedding extracted
    by BERT and entity information e.g. person name and organization name for text
    classification Yan et al. ([2023](#bib.bib283)). The entity recognition module
    is based on bi-directional LSTM and conditional random field layers to calculate
    the probability of each word in each entity label. The model introduces a label
    embedding bi-directional attention to learn the attention weights of token-label
    and sequence-label pairs. Furthermore, a transformer is introduced to learn local
    short-term dependencies of multiple short text sequences and long-term dependencies
    of the input sequence. Aspect refers to a specific attribute of an entity within
    the text and incorporating this information enhances the model’s understanding
    of the nuances of the text. BERT-MSL is a multi-semantic deep learning model with
    aspect-aware enhancement and four input pipelines: left sequence, right sequence,
    global sequence and aspect target Zhu et al. ([2023](#bib.bib306)). The aspect-aware
    enhancement module takes the features extracted by BERT, and performs average
    pooling followed by a linear transform. Then the output is concatenated with the
    outputs produced by the local and global semantic learning modules. The concatenated
    features are then jointly attended by a multi-head attention for text classification.
    Figure [24](#S4.F24 "Figure 24 ‣ 4.3.1 Text Classification ‣ 4.3 Natural Language
    Processing ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications") shows the architecture of BERT-MSL.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 在文本分类中，文本标签有助于捕捉与分类相关的词汇。标签嵌入注意力模型是最早尝试在同一潜在空间中联合学习标签和词嵌入并使用余弦相似度测量标签与词汇之间兼容性的尝试之一
    Wang et al. ([2018a](#bib.bib259))。联合嵌入使模型能够捕捉更有效的文本表示，从而提高模型的整体性能。LANTRN 是一种深度学习模型，利用
    BERT 提取的标签嵌入和实体信息，例如人名和组织名，用于文本分类 Yan et al. ([2023](#bib.bib283))。实体识别模块基于双向
    LSTM 和条件随机场层计算每个实体标签中每个词的概率。该模型引入了标签嵌入双向注意力来学习标记-标签和序列-标签对的注意力权重。此外，引入了变换器以学习多个短文本序列的局部短期依赖关系和输入序列的长期依赖关系。方面指的是文本中实体的特定属性，融入这一信息能增强模型对文本细微差别的理解。BERT-MSL
    是一种具有方面感知增强的多语义深度学习模型，具有四个输入管道：左序列、右序列、全局序列和方面目标 Zhu et al. ([2023](#bib.bib306))。方面感知增强模块提取
    BERT 提取的特征，并进行平均池化，然后进行线性变换。接着，输出与局部和全局语义学习模块产生的输出连接在一起。连接的特征然后通过多头注意力机制共同用于文本分类。图
    [24](#S4.F24 "图 24 ‣ 4.3.1 文本分类 ‣ 4.3 自然语言处理 ‣ 4 深度学习应用 ‣ 深度学习及其最先进应用调查") 显示了
    BERT-MSL 的架构。
- en: '![Refer to caption](img/d1e0f488a644e1d58e0edcd2e5ed2ed4.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/d1e0f488a644e1d58e0edcd2e5ed2ed4.png)'
- en: 'Figure 24: The architecture of BERT-MSL Zhu et al. ([2023](#bib.bib306)).'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 24：BERT-MSL 的架构 Zhu et al. ([2023](#bib.bib306)).
- en: 4.3.2 Neural Machine Translation
  id: totrans-216
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2 神经机器翻译
- en: Neural machine translation (NMT) refers to the automated process of translating
    text from one language to another language. Numerous deep learning models have
    been proposed for NMT which can be categorized into RNN-based and CNN-based models.
    One of the first successful RNN-based models is the encoder-decoder Cho et al.
    ([2014](#bib.bib38)); Sutskever et al. ([2014](#bib.bib238)). The model consists
    of two connected subnetworks (the encoder and the decoder) for modelling the translation
    process as shown in Figure [25](#S4.F25 "Figure 25 ‣ 4.3.2 Neural Machine Translation
    ‣ 4.3 Natural Language Processing ‣ 4 Applications of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications"). The encoder reads the source
    sentence word by word and produces a fixed-length context vector (final hidden
    state). This process is known as source sentence encoding as shown in the figure.
    Given the context vector, the decoder generates the target sentence (translation)
    word by word. This modelling of the translation can be seen as a mapping between
    the source sentence to the target sentence via the intermediate context vector
    in the semantic space. The context vector represents the summary of the input
    sequence’s semantic meaning, providing a compressed representation that captures
    the essence of the source sentence. However, the compression process can sometimes
    result in the loss of information especially those early in the sequence. Bi-directional
    RNN may mitigate the loss of information by modelling the sequence in reverse
    order. However, the problem can still persist, particularly in cases where the
    input is a long sequence.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 神经机器翻译（NMT）是指将文本从一种语言自动翻译成另一种语言的过程。已经提出了众多深度学习模型用于NMT，这些模型可以分为基于RNN的模型和基于CNN的模型。第一个成功的基于RNN的模型之一是编码器-解码器模型（Cho等，[2014](#bib.bib38)；Sutskever等，[2014](#bib.bib238)）。该模型由两个连接的子网络（编码器和解码器）组成，用于建模翻译过程，如图[25](#S4.F25
    "Figure 25 ‣ 4.3.2 Neural Machine Translation ‣ 4.3 Natural Language Processing
    ‣ 4 Applications of Deep Learning ‣ A Survey on Deep Learning and State-of-the-art
    Applications")所示。编码器逐字读取源句子并生成一个固定长度的上下文向量（最终隐藏状态）。这一过程被称为源句子编码，如图中所示。给定上下文向量，解码器逐字生成目标句子（翻译）。这种翻译建模可以看作是通过中间上下文向量在语义空间中将源句子映射到目标句子的过程。上下文向量表示输入序列语义意义的摘要，提供了一个压缩表示，捕捉了源句子的精髓。然而，压缩过程有时可能导致信息丢失，特别是序列中的早期信息。双向RNN可以通过反向建模序列来缓解信息丢失的问题。然而，这个问题仍然存在，特别是在输入是长序列的情况下。
- en: '![Refer to caption](img/4d7d4afe950b7d8d5c521c1c3745131a.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/4d7d4afe950b7d8d5c521c1c3745131a.png)'
- en: 'Figure 25: The architecture of an encoder-decoder Stahlberg ([2020](#bib.bib233)).'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图25：编码器-解码器的架构（Stahlberg，[2020](#bib.bib233)）。
- en: Attention mechanism was introduced to solve the problem of learning long input
    sequences Bahdanau et al. ([2014](#bib.bib17)). Attention alleviates this issue
    by attending on different words of the input sequences when predicting the target
    sequences at each time step. Unlike the standard encoder-decoder model, attention
    derives the context vector from the hidden states of both the encoder and decoder,
    and the alignment between the source and target. This mechanism allows the model
    to focus on the important words, increasing the overall accuracy of the translation.
    Several alignment score functions have been proposed for calculating the attention
    weights. Some of the popular functions are additive Bahdanau et al. ([2014](#bib.bib17)),
    dot-product, location-based Luong et al. ([2015](#bib.bib158)), and scaled dot-product
    Vaswani et al. ([2023](#bib.bib257)). The attention weights are calculated by
    attending to the entire hidden states of the encoder. This attention, also known
    as global attention, is computationally expensive. Instead of attending to all
    hidden states, local attention attends to a subset of hidden states, thus reducing
    the computational cost Luong et al. ([2015](#bib.bib158)). Google Neural Machine
    Translation is a popular encoder-decoder model with an attention mechanism that
    significantly improves the accuracy of machine translation Wu et al. ([2016](#bib.bib276)).
    As shown in Figure [26](#S4.F26 "Figure 26 ‣ 4.3.2 Neural Machine Translation
    ‣ 4.3 Natural Language Processing ‣ 4 Applications of Deep Learning ‣ A Survey
    on Deep Learning and State-of-the-art Applications"), the model consists of a
    multilayer of LSTMs with eight encoder and decoder layers and an attention connection
    between the bottom layer of the decoder to the top layer of the encoder. Furthermore,
    to deal with the challenging words to predict, a word is tokenized into subwords
    e.g. feud is broken down into fe and ud, allowing the model to generalize well
    to new and uncommon words. A year later, the self-attention mechanism was proposed,
    significantly improving the overall accuracy of machine translation Vaswani et al.
    ([2023](#bib.bib257)). Self-attention, also known as intra-attention, allows the
    deep learning model to capture the dependencies between the input words. The self-attention
    mechanism is the fundamental building block of the transformer model, which has
    since become a cornerstone in natural language processing and other domains.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力机制的引入是为了解决学习长输入序列的问题（Bahdanau et al. ([2014](#bib.bib17))）。通过在每个时间步预测目标序列时关注输入序列中的不同单词，注意力机制缓解了这一问题。与标准的编码器-解码器模型不同，注意力从编码器和解码器的隐藏状态以及源和目标之间的对齐中推导上下文向量。这一机制使模型能够集中于重要的单词，从而提高了翻译的整体准确性。几种对齐评分函数被提出用于计算注意力权重。其中一些流行的函数包括加法（Bahdanau
    et al. ([2014](#bib.bib17))）、点积、基于位置的（Luong et al. ([2015](#bib.bib158))）和缩放点积（Vaswani
    et al. ([2023](#bib.bib257))）。注意力权重通过关注编码器的整个隐藏状态来计算。这种注意力，也被称为全局注意力，计算开销较大。局部注意力则关注隐藏状态的子集，从而降低计算成本（Luong
    et al. ([2015](#bib.bib158))）。谷歌神经机器翻译是一个流行的编码器-解码器模型，配备有注意力机制，显著提高了机器翻译的准确性（Wu
    et al. ([2016](#bib.bib276))）。如图[26](#S4.F26 "Figure 26 ‣ 4.3.2 Neural Machine
    Translation ‣ 4.3 Natural Language Processing ‣ 4 Applications of Deep Learning
    ‣ A Survey on Deep Learning and State-of-the-art Applications")所示，该模型由多层LSTM组成，具有八个编码器和解码器层，并且解码器的底层与编码器的顶层之间存在注意力连接。此外，为了处理难以预测的单词，一个单词会被分词为子词，例如，feud被分解为fe和ud，这使模型能够更好地对新词和不常见词进行泛化。一年后，自注意力机制的提出显著提高了机器翻译的整体准确性（Vaswani
    et al. ([2023](#bib.bib257))）。自注意力，也称为内在注意力，使深度学习模型能够捕捉输入单词之间的依赖关系。自注意力机制是变换器模型的基本构建块，该模型自此成为自然语言处理及其他领域的基石。
- en: '![Refer to caption](img/8949af4d7ee546c453992f4de1a28ea9.png)'
  id: totrans-221
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/8949af4d7ee546c453992f4de1a28ea9.png)'
- en: 'Figure 26: The architecture of Google Neural Machine Translation Wu et al.
    ([2016](#bib.bib276)).'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 图26：谷歌神经机器翻译的架构（Wu et al. ([2016](#bib.bib276))）。
- en: Despite the success of transformer, the model falls short in capturing nuances
    of human language and struggles with tasks requiring deeper understanding of context.
    This can be especially challenging when the tasks involve formality, colloquialism,
    and subtle cultural references that may not directly equivalent in the target
    language, resulting in inaccurate translation or losing the original meaning.
    One of the approaches to include context into the input sequence is concatenating
    the current source sentence with the previous (context) sentences and feeding
    the whole input to the transformer Lupo et al. ([2023](#bib.bib159)). The model
    is trained to predict the translated sentence including the context translation.
    At inference time, only the translation is considered while the context translation
    is discarded. Furthermore, the approach encodes the sentence position and segment-shifted
    position to improve the distinction between current sentences and context sentences.
    In Rippeth et al. ([2023](#bib.bib207)), the source sentence is prefixed with
    the summary of the document to contextualize the input sentence. The summary is
    the set of salient words that represents the essence of the document, resolving
    ambiguity associated with the translation. A study was conducted to determine
    the optimal technique of aggregating contextual features Wu et al. ([2022](#bib.bib275)).
    Three techniques were studied namely concatenation mode, flat mode and hierarchical
    mode, and the experimental results show that concatenation mode achieved the best
    results. In Kim et al. ([2023](#bib.bib117)), a training method is introduced
    to train the deep learning machine translation model to generate translation involving
    honorific words. The training method indicates the honorific context in the target
    sentence using an honorific classifier to guide the model to attend to the related
    tokens. Unlike other studies where the context features are included by concatenation,
    the training method assigns weights to the context tokens indicated by the honorific
    classifier. This allows the model to generate a more accurate translation with
    honorifics. Finally, the performance of transformer relies on large-scale training
    data. However, for the vast majority of languages, only limited amounts of training
    data exist. To mitigate this problem, recent studies introduce shallow transformer
    architectures Gezmu and Nürnberger ([2022](#bib.bib65)), explore the effect of
    hyperparameter finetuning Araabi and Monz ([2020](#bib.bib13)), exploiting monolingual
    corpus to enhance the bilingual dataset for model training Li et al. ([2024](#bib.bib128))
    and leveraging visual input as contextual information for the translation task
    Meetei et al. ([2023](#bib.bib166)).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管变换器（transformer）取得了成功，但模型在捕捉人类语言的细微差别方面仍显不足，并且在需要深入理解上下文的任务中表现不佳。这在涉及正式语体、口语化以及可能在目标语言中没有直接对应的细微文化参考时尤其具有挑战性，可能导致翻译不准确或丧失原意。将当前源句与前面的（上下文）句子连接起来并将整个输入喂入变换器是将上下文纳入输入序列的一种方法
    Lupo 等人 ([2023](#bib.bib159))。该模型被训练预测包括上下文翻译的翻译句子。在推断时，仅考虑翻译，而上下文翻译被丢弃。此外，该方法对句子位置和段落偏移位置进行编码，以提高当前句子和上下文句子之间的区分。在
    Rippeth 等人 ([2023](#bib.bib207)) 中，源句前加上了文档摘要以对输入句子进行上下文化。摘要是一组突出词，代表文档的本质，解决翻译中的歧义问题。一项研究旨在确定聚合上下文特征的最佳技术
    Wu 等人 ([2022](#bib.bib275))。研究了三种技术，即连接模式、平面模式和层次模式，实验结果显示连接模式取得了最佳结果。在 Kim 等人
    ([2023](#bib.bib117)) 中，介绍了一种训练方法，以训练深度学习机器翻译模型生成包含敬语的翻译。该训练方法使用敬语分类器指示目标句中的敬语上下文，以指导模型关注相关的标记。与其他研究通过连接包含上下文特征不同，该训练方法为敬语分类器指示的上下文标记分配权重。这使得模型能够生成更准确的包含敬语的翻译。最后，变换器的性能依赖于大规模的训练数据。然而，对于绝大多数语言，仅存在有限的训练数据。为了解决这个问题，最近的研究引入了浅层变换器架构
    Gezmu 和 Nürnberger ([2022](#bib.bib65))，探讨了超参数微调的效果 Araabi 和 Monz ([2020](#bib.bib13))，利用单语语料库来增强双语数据集以进行模型训练
    Li 等人 ([2024](#bib.bib128))，并利用视觉输入作为翻译任务的上下文信息 Meetei 等人 ([2023](#bib.bib166))。
- en: 4.3.3 Text Generation
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.3 文本生成
- en: Text generation refers to the process of creating texts based on a given input
    whereby the input can be in the form of texts, images, graphs, tables or even
    tabular data. Due to the various forms of inputs, text generation has a wide range
    of applications, including creative writing, image captioning and music generation.
    This section focuses on the progress made in text-to-text generation tasks such
    as question answering, dialogue generation and text summarization. The recurrent
    neural network and its variants play an important role in text generation tasks
    for their strong ability to model sequential data. One of the earliest works on
    question answering is based on the RNN-based encoder-decoder model whereby the
    encoder takes the question embedding and processes it using bi-directional LSTM,
    and the decoder generates the corresponding answer Nie et al. ([2017](#bib.bib180)).
    Additionally, to prevent semantic loss and enable the model to focus on the important
    words in the input sequence, a convolution operation is applied to the word embedding,
    and an attention mechanism is then used to attend to the output of the convolution
    operation. Similar work is reported in Yin et al. ([2015](#bib.bib288)) in which
    a knowledge-based module is introduced to calculate the relevance score between
    the question and the relevant facts in the knowledge base. This improves the text
    (answer) generation by the decoder. Another work is described in Li et al. ([2016](#bib.bib130))
    where an encoder-decoder with attention for dialogue generation is optimized using
    reinforcement learning. The model is first trained in supervised learning manner
    and then improved using the policy gradient method to diversify the responses.
    Ambiguous content in question answering sentences is a challenge in text generation
    and can lead to incorrect and uncertain responses. Cross-sentence context aware
    bi-directional model introduces a parallel attention module to compute the co-attention
    weights at the sentence level, accounting for the relationships and similarities
    in the question and the answer Wu et al. ([2020](#bib.bib274)).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 文本生成指的是根据给定的输入创建文本的过程，输入可以是文本、图像、图表、表格或甚至表格数据。由于输入形式多样，文本生成具有广泛的应用，包括创意写作、图像描述和音乐生成。本节重点讨论在文本到文本生成任务中的进展，例如问答、对话生成和文本摘要。递归神经网络及其变体在文本生成任务中发挥了重要作用，因为它们对顺序数据建模能力很强。关于问答的早期研究之一基于RNN编码器-解码器模型，其中编码器接收问题嵌入并使用双向LSTM处理，解码器则生成相应的答案
    Nie 等人 ([2017](#bib.bib180))。此外，为了防止语义丢失并使模型专注于输入序列中的重要词语，应用了卷积操作到词嵌入上，然后使用注意力机制来关注卷积操作的输出。类似的工作在
    Yin 等人 ([2015](#bib.bib288)) 中报道，其中引入了基于知识的模块来计算问题与知识库中相关事实之间的相关性评分。这改善了解码器生成的文本（答案）。另一个工作在
    Li 等人 ([2016](#bib.bib130)) 中描述，其中一个用于对话生成的编码器-解码器模型通过强化学习进行优化。该模型首先以监督学习的方式进行训练，然后使用策略梯度方法进行改进，以多样化响应。问答句中的模糊内容是文本生成中的一个挑战，可能导致不正确和不确定的回应。跨句上下文感知的双向模型引入了一个并行注意力模块，以计算句子级别的共注意力权重，考虑问题和答案中的关系和相似性
    Wu 等人 ([2020](#bib.bib274))。
- en: The transformer has been leveraged for text generation tasks. An incremental
    transformer-based encoder is proposed to incrementally encode the historical sequence
    of conversations Li et al. ([2019b](#bib.bib138)). The decoder is a two-pass decoder
    that is based on the deliberation network, generates the next sentence. The first
    pass focuses on contextual coherence of the conversations while the second pass
    refines the output of the first pass. BERT and ALBERT have been used as pre-trained
    models for question answering task Alrowili and Vijay-Shanker ([2021](#bib.bib8)).
    The study found that the performance of the models is sensitive to random assignment
    of the initial weights especially on small datasets Alrowili and Vijay-Shanker
    ([2022](#bib.bib9)). T-BERTSum is a model based on BERT, designed to address the
    challenge of long text dependence and leveraging latent topic mapping in text
    summarization Ma et al. ([2021](#bib.bib161)). The mode integrates a neural topic
    module to infer topics and guide summarization, uses a transformer network to
    capture long-range dependencies and incorporates multilayers of LSTM for information
    filtering. Exploiting domain knowledge is essential in reducing the semantic gap
    between the deep learning models and the text corpus. KeBioSum is a knowledge
    infusion framework to inject domain knowledge into the pre-trained BERTs for text
    summarization Xie et al. ([2022](#bib.bib279)). In the framework, the relevant
    information is detected and extracted from the domain knowledge, generating label
    sequences of the sentences. The label data is then used to train the text summarization
    model using discriminative and generative training approaches, infusing the knowledge
    into the model.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 变换器已被用于文本生成任务。提出了一种增量变换器编码器，以增量方式对历史对话序列进行编码 Li et al. ([2019b](#bib.bib138))。解码器是一个基于审议网络的双通道解码器，用于生成下一句。第一通道关注对话的上下文连贯性，而第二通道则对第一通道的输出进行细化。BERT
    和 ALBERT 已被用作问题回答任务的预训练模型 Alrowili 和 Vijay-Shanker ([2021](#bib.bib8))。研究发现，模型的表现对初始权重的随机分配特别敏感，尤其是在小数据集上
    Alrowili 和 Vijay-Shanker ([2022](#bib.bib9))。T-BERTSum 是基于 BERT 的模型，旨在解决长文本依赖问题，并在文本摘要中利用潜在话题映射
    Ma et al. ([2021](#bib.bib161))。该模型整合了一个神经话题模块以推断话题并指导摘要，使用变换器网络捕捉长程依赖，并结合了多层
    LSTM 进行信息过滤。利用领域知识对于减少深度学习模型与文本语料库之间的语义差距至关重要。KeBioSum 是一个知识注入框架，将领域知识注入到预训练的
    BERT 模型中，用于文本摘要 Xie et al. ([2022](#bib.bib279))。在该框架中，从领域知识中检测并提取相关信息，生成句子的标签序列。然后使用判别性和生成性训练方法训练文本摘要模型，将知识注入到模型中。
- en: 5 Challenges and Future Directions
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 挑战与未来方向
- en: 5.0.1 Availability and Quality
  id: totrans-228
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.0.1 可用性和质量
- en: Building and employing deep learning models face several challenges. The training
    of deep learning requires a large number of instances (examples) to achieve high
    accuracy and generalization Munappy et al. ([2022](#bib.bib172)). Furthermore,
    the complexity of deep neural networks may lead to overfitting, where the model
    performs well on training data but fails to generalize on new, unseen data. This
    phenomenon frequently arises when the models is trained on insufficient data,
    highlighting the importance of diverse and extensive datasets. However, the data
    collection and annotation are time consuming and often require domain experts,
    specialized training and standardization Luca et al. ([2022](#bib.bib157)). Moreover,
    this process is prone to error and has the risk of introducing biases into the
    dataset which can significantly impact the performance of the trained model. One
    of the approaches to address this issue is transfer learning. Transfer learning
    involves the use of a deep learning model (known as pre-trained model) that is
    trained on a large dataset for solving a specific task (with a small dataset)
    Zhuang et al. ([2020](#bib.bib307)). The pre-trained model serves as a basis for
    the model training by fine-tuning the weights of the pre-trained model and adapting
    it to the new prediction task. This approach helps to mitigate the lack of training
    data in the target domain. Furthermore, transfer learning reduces computational
    resources required to train the model and helps faster convergence.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 建立和使用深度学习模型面临多个挑战。深度学习的训练需要大量实例（示例）才能实现高准确性和泛化能力 Munappy 等人 ([2022](#bib.bib172))。此外，深度神经网络的复杂性可能导致过拟合，即模型在训练数据上表现良好，但在新出现的数据上无法泛化。这种现象通常发生在模型训练的数据不足时，这突显了多样化和广泛数据集的重要性。然而，数据收集和注释是耗时的，通常需要领域专家、专业培训和标准化
    Luca 等人 ([2022](#bib.bib157))。此外，这一过程容易出错，并有可能引入偏差到数据集中，从而显著影响训练模型的性能。解决这一问题的一种方法是迁移学习。迁移学习涉及使用一个在大数据集上训练的深度学习模型（称为预训练模型）来解决特定任务（使用小数据集）
    Zhuang 等人 ([2020](#bib.bib307))。预训练模型作为模型训练的基础，通过微调预训练模型的权重并将其适应于新的预测任务。这种方法有助于缓解目标领域训练数据的不足。此外，迁移学习减少了训练模型所需的计算资源，并帮助更快地收敛。
- en: Another approach that can be employed to address the lack of data is data augmentation.
    Data augmentation is a convenient method that increases the number of instances
    by performing transformation functions on the existing instances without changing
    the labels Mumuni and Mumuni ([2022](#bib.bib171)). In the domain of computer
    vision, image transformation such as rotation, translation and cropping. However,
    it is important to consider the output of the transformation because the resultant
    may not represent the actual data. For example, flipping or adding noise to a
    signal may introduce distortion or changing the characteristics (trend, seasonality
    and cyclic variations) of the signal. Thus, careful consideration must be given
    to ensure that the generated instances still accurately represent the underlying
    patterns present in the data. Data augmentation can also be realized by generating
    synthetic data to supplement the training set. Synthetic data is artificially
    created data that resembles real data but is generated using statistical methods
    or deep generative models Hu et al. ([2023](#bib.bib93)); Murtaza et al. ([2023](#bib.bib174)).
    The generated data can complement the less-diverse, limited datasets, providing
    a broader range of examples for the model to learn from. However, generating synthetic
    data that accurately reflects the characteristics of the real-world data is challenging.
    Careful consideration must be given to the choice of models and parameters used
    to ensure the synthetic data is realistic and representative of the real-world
    data.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种可以解决数据不足的方法是数据增强。数据增强是一种方便的方法，通过对现有实例进行转换函数处理而不改变标签来增加实例数量 Mumuni 和 Mumuni
    ([2022](#bib.bib171))。在计算机视觉领域，图像转换如旋转、平移和裁剪。然而，重要的是要考虑转换的输出，因为结果可能无法代表实际数据。例如，翻转或给信号添加噪声可能会引入失真或改变信号的特征（趋势、季节性和周期变化）。因此，必须仔细考虑以确保生成的实例仍能准确地代表数据中存在的潜在模式。数据增强还可以通过生成合成数据来补充训练集。合成数据是人工创建的数据，虽然类似于真实数据，但使用统计方法或深度生成模型生成
    Hu 等人 ([2023](#bib.bib93))；Murtaza 等人 ([2023](#bib.bib174))。生成的数据可以补充那些多样性较少、有限的数据集，为模型提供更多的学习例子。然而，生成能够准确反映现实数据特征的合成数据是具有挑战性的。必须仔细考虑所使用的模型和参数选择，以确保合成数据是现实的，并且能代表真实世界的数据。
- en: 5.0.2 Interpretability and Explainability
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.0.2 可解释性和解释性
- en: Interpretability and explainability is crucial for building trust and understanding
    how predictive models make decisions especially in high-stake applications such
    as healthcare and medical image analysis Tonekaboni et al. ([2019](#bib.bib253)).
    However, as deep learning models become more intricate and complex with numerous
    layers, subnetworks and a large number of parameters, the models are often perceived
    as a “black box” and difficult to explain in terms of decision-making processes.
    Therefore, it is crucial for the researchers to focus on methods that provide
    insights into how a deep learning model performs the prediction and how its decisions
    are influenced by the input data, making it more transparent and trustworthy.
    Numerous methods have been proposed for interpreting and explaining the decisions
    of deep learning models which can be categorized into visualization (feature attribution),
    model distillation and intrinsic (explainable by itself). Visualization methods
    involve the use of scientific visualization such as saliency maps or heatmaps
    to express the explanation by highlighting the degree of association between the
    inputs and the predictions Tjoa et al. ([2023](#bib.bib252)). The heatmaps identify
    the saliency of the input features influencing the model’s predictions. The visualization
    approach is simple and intuitive and can be applied to tabular data and image
    data. Furthermore, it can be used to identify and debug issues in deep learning
    models, leading to improved performance and robustness.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 可解释性和可解释性对于建立信任以及理解预测模型如何做出决策至关重要，尤其是在医疗保健和医学图像分析等高风险应用中（Tonekaboni et al. ([2019](#bib.bib253))）。然而，随着深度学习模型变得越来越复杂，具有多个层次、子网络和大量参数，这些模型通常被视为“黑箱”，难以解释其决策过程。因此，研究人员必须关注那些提供深入了解深度学习模型如何进行预测及其决策如何受到输入数据影响的方法，使其更加透明和可信。已经提出了许多解释和说明深度学习模型决策的方法，这些方法可以分为可视化（特征归因）、模型蒸馏和内在（自我解释）。可视化方法涉及使用科学可视化工具，如显著性图或热图，通过突出输入和预测之间的关联程度来表达解释（Tjoa
    et al. ([2023](#bib.bib252))）。热图识别影响模型预测的输入特征的显著性。可视化方法简单直观，可以应用于表格数据和图像数据。此外，它还可以用于识别和调试深度学习模型中的问题，从而提高性能和鲁棒性。
- en: Model distillation is an approach to approximating a complex model by fitting
    a simpler model using the training set. The simpler model is built typically using
    a simpler or interpretable algorithm such as linear regression, decision tree
    or rule-based methods Li and Shen ([2024](#bib.bib135)). In this approach, the
    simpler model is trained to resemble the predictive behavior of the complex model.
    Then, the simpler model may serve as the proxy or surrogate model for explaining
    the complex model. Model distillation can be used together with visualization
    to further enhance the interpretability of the complex model Termritthikun et al.
    ([2023](#bib.bib248)). Model distillation seeks explanations of the models that
    were never designed to be explainable. Ideally, the explanation of a deep learning
    model’s prediction should be included as part of the model output, or the explanation
    can be derived from the architecture of the model. This is because an intrinsic
    model can learn not only the mapping between the input and output, but also generate
    an explanation of the prediction that is faithful to the model’s behavior. Attention
    mechanisms are the key to this approach, providing a form of attention weights
    that can be used to explain why the model made a particular decision Xiong et al.
    ([2022](#bib.bib281)). Another type of intrinsic approach is to train the model
    to simultaneously perform the prediction task and generate the explanation for
    its predictions Fernandes et al. ([2023](#bib.bib60)). This “additional task”
    can be in the form of a text explanation or model prototype which embeds the semantic
    meaning of the prediction. However, the intrinsic approach is more difficult to
    apply because the user needs additional knowledge and understanding of the model’s
    architecture and inner workings.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 模型蒸馏是一种通过使用训练集来拟合更简单的模型，以近似复杂模型的方法。这个简单模型通常是通过更简单或可解释的算法构建的，如线性回归、决策树或基于规则的方法
    Li 和 Shen ([2024](#bib.bib135))。在这种方法中，简单模型被训练成类似于复杂模型的预测行为。然后，简单模型可以作为解释复杂模型的代理模型或替代模型。模型蒸馏可以与可视化一起使用，以进一步增强复杂模型的可解释性
    Termritthikun 等人 ([2023](#bib.bib248))。模型蒸馏寻求对那些从未设计为可解释的模型的解释。理想情况下，深度学习模型预测的解释应作为模型输出的一部分，或者可以从模型的架构中推导出来。这是因为内在模型不仅可以学习输入与输出之间的映射，还可以生成对预测的解释，这些解释忠实于模型的行为。注意力机制是这一方法的关键，它提供了一种注意力权重，可以用来解释模型为何做出特定决策
    Xiong 等人 ([2022](#bib.bib281))。另一种内在方法是训练模型同时执行预测任务和生成其预测解释 Fernandes 等人 ([2023](#bib.bib60))。这种“附加任务”可以是文本解释或嵌入预测语义意义的模型原型。然而，内在方法更难应用，因为用户需要额外的知识和对模型架构及内部机制的理解。
- en: 5.0.3 Ethics and Fairness
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.0.3 伦理与公平
- en: Deep learning models are increasingly being deployed in making high-stake decision
    including recruitment Freire and de Castro ([2021](#bib.bib61)), criminal justice
    Dass et al. ([2023](#bib.bib45)) and credit scoring Gicić et al. ([2023](#bib.bib66)).
    There are several advantages of deep learning-based systems in which, unlike humans,
    machines are able to process vast amounts of data and applications quickly and
    consistently. However, deep learning-based systems have the risk of being prone
    to biases present in the data used for training which can lead to unfairness and
    injustice. Numerous efforts have been made to mitigate this issue which can be
    categorized into modelling bias detection and modelling bias mitigation. Detection
    of modelling bias refers to the process of identifying and quantifying biases
    that may present in predictive models. This approach involves the use of statistical
    analysis, fairness metrics, counterfactual testing and human review to detect
    bias in the models. For instance, visualization-based methods such as attribution
    maps are used to indicate which regions are significant to the predictions Schaaf
    et al. ([2021](#bib.bib213)). This in turn can be used to detect and quantify
    bias using metrics such as Relevance Mass Accuracy, Relevance Rank Accuracy Accuracy
    and or Area over the perturbation curve (AOPC). In Giloni et al. ([2022](#bib.bib67)),
    two modules are presented for estimating bias in predictive models. The first
    module utilizes an unsupervised deep neural network with a custom loss function
    to generate hidden representation of the input data called bias vectors, revealing
    the underlying bias of each feature. The second module combines these bias vectors
    into a single vector representing the bias estimation of each feature, achieved
    by aggregating them using the absolute averaging operation. Bias mitigation refers
    to the process of reducing the presence of bias in predictive models, which can
    be done in three stages. The first stage combats bias by modifying the training
    data, either relabeling the labels or perturbing the feature values Iosifidis
    et al. ([2019](#bib.bib105)); Kehrenberg et al. ([2020](#bib.bib114)). The second
    stage addresses bias during the training of the model by applying regularization
    terms to the loss function to penalize discrimination. In Jain et al. ([2023](#bib.bib107)),
    a loss function based on bias parity score (BPS) is introduced to measure the
    degree of similarity of a statistical measure such as accuracy across different
    subgroups. The BPS term is added to the loss function as a regularizer to the
    original prediction task. The last stage mitigates bias after the predictive models
    have been successfully trained. This stage applies post-processing approaches
    such as reinforcement learning to obtain a fairer model Yang et al. ([2023](#bib.bib286)).
    For instance, the detection of minority classes is rewarded to prevent bias towards
    the majority class. This allows the model the generalize well across different
    patient demographics.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型越来越多地被应用于高风险决策中，包括招聘Freire和de Castro（[2021](#bib.bib61)）、刑事司法Dass等（[2023](#bib.bib45)）和信用评分Gicić等（[2023](#bib.bib66)）。深度学习系统有几个优势，与人类不同，机器能够快速且一致地处理大量数据和应用。然而，深度学习系统存在着因训练数据中存在的偏见而导致不公平和不公正的风险。为缓解这一问题，已做出了许多努力，这些努力可以分为建模偏见检测和建模偏见缓解两类。建模偏见检测是指识别和量化预测模型中可能存在的偏见的过程。这一方法包括使用统计分析、公平性指标、反事实测试和人工审查来检测模型中的偏见。例如，基于可视化的方法如归因图被用来指示哪些区域对预测具有重要意义Schaaf等（[2021](#bib.bib213)）。这反过来可以用来使用诸如相关性质量准确度、相关性排名准确度或扰动曲线下的面积（AOPC）等指标来检测和量化偏见。在Giloni等（[2022](#bib.bib67)）中，提出了两个模块来估计预测模型中的偏见。第一个模块利用一个无监督的深度神经网络和一个自定义的损失函数来生成输入数据的隐藏表示，称为偏见向量，从而揭示每个特征的潜在偏见。第二个模块将这些偏见向量结合成一个单一向量，代表每个特征的偏见估计，通过使用绝对平均操作来聚合它们。偏见缓解是指减少预测模型中偏见的过程，这可以分为三个阶段。第一阶段通过修改训练数据来对抗偏见，无论是重新标记标签还是扰动特征值Iosifidis等（[2019](#bib.bib105)）；Kehrenberg等（[2020](#bib.bib114)）。第二阶段在模型训练过程中通过向损失函数中应用正则化项来解决偏见，以惩罚歧视。在Jain等（[2023](#bib.bib107)）中，引入了一种基于偏见平等分数（BPS）的损失函数，用于测量不同子群体之间统计度量（如准确性）的相似度。BPS项被添加到损失函数中作为对原始预测任务的正则化。最后阶段在预测模型成功训练后缓解偏见。这个阶段应用后处理方法如强化学习来获得一个更公平的模型Yang等（[2023](#bib.bib286)）。例如，检测少数类的行为会获得奖励，以防止对多数类的偏见。这使得模型在不同的患者人群中具有良好的泛化能力。
- en: 5.0.4 Lightweight Deep Learning Models
  id: totrans-236
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.0.4 轻量级深度学习模型
- en: Even though deep learning architectures have achieved state-of-the-art across
    various computer vision tasks, they often come with large model parameters Ige
    and Mohd Noor ([2023](#bib.bib100)). The architecture and complexity of a deep
    learning network determine the number of model parameters. The deeper the network,
    the larger the number of model parameters. However, deep learning models with
    large parameters often suffer limitations when deploying on end devices. For instance,
    a deep learning model developed for security monitoring by analyzing video data
    using 3D-CNNs might suffer deployment issues when deploying such models on low-resourced
    systems like smartphones or small-scale IoT devices. Model training and inference
    for deep learning models with large parameters demands substantial processing
    power. As the number of parameters increases, so does the computational complexity,
    resulting in longer model training duration and more hardware needs. Also, large
    parameter sizes translate to increased memory requirements, limiting their deployment
    on end devices. This is because these end devices often have battery, processor
    or memory capacity limitations. To address these challenges, it is important to
    develop sophisticated but lightweight architectures that can achieve state-of-the-art
    with few model parameters. Such lightweight models will be characterized by their
    ability to deliver competitive performance while mitigating computational complexity
    and memory requirements, making them well-suited for deployment on resource-constrained
    devices. An approach would be to develop novel lightweight plug-and-play modules
    that can be plugged to few layered deep learning architectures to improve feature
    learning without incurring additional model complexity. Other approaches could
    involve leveraging model compression techniques to reduce the size and computational
    complexity of deep learning models. Researchers can focus on improving pruning
    methods Li et al. ([2019a](#bib.bib131)), which can identify and eliminate redundant
    parameters or connections, thereby reducing the model’s footprint without compromising
    performance. Also, quantization techniques Yang et al. ([2019](#bib.bib285)) can
    be further explored to reduce the precision of weights and activations, therefore,
    enabling efficient representation with lower memory requirements. Also, knowledge
    distillation techniques Stanton et al. ([2021](#bib.bib234)) can be further investigated
    to facilitate the transfer of knowledge from a complex teacher model to a simpler
    student model, therefore, enabling compact yet effective representations. These
    areas are still open to contributions.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习架构在各种计算机视觉任务中已实现了最先进的成果，但它们通常具有大量的模型参数 Ige 和 Mohd Noor ([2023](#bib.bib100))。深度学习网络的架构和复杂性决定了模型参数的数量。网络越深，模型参数的数量就越大。然而，具有大量参数的深度学习模型在部署到终端设备时常常面临限制。例如，通过使用
    3D-CNN 分析视频数据来开发的用于安全监控的深度学习模型，在将这些模型部署到资源有限的系统如智能手机或小型物联网设备时可能会遇到部署问题。对于具有大量参数的深度学习模型，模型训练和推理需要大量的处理能力。随着参数数量的增加，计算复杂性也增加，导致模型训练时间更长，硬件需求更多。此外，大的参数规模也意味着增加的内存需求，从而限制了它们在终端设备上的部署。这是因为这些终端设备通常有电池、处理器或内存容量的限制。为了解决这些挑战，开发复杂但轻量的架构以实现最先进的性能而只需少量模型参数是重要的。这些轻量级模型的特点是能够在减轻计算复杂性和内存需求的同时提供具有竞争力的性能，使其非常适合部署在资源受限的设备上。一种方法是开发新型的轻量级即插即用模块，这些模块可以插入到少层的深度学习架构中，以改善特征学习而不增加额外的模型复杂性。其他方法可以涉及利用模型压缩技术来减少深度学习模型的大小和计算复杂性。研究人员可以专注于改进剪枝方法
    Li 等 ([2019a](#bib.bib131))，这种方法可以识别并消除冗余的参数或连接，从而在不影响性能的情况下减少模型的占用空间。此外，量化技术
    Yang 等 ([2019](#bib.bib285)) 可以进一步探索，以减少权重和激活的精度，从而实现低内存需求的高效表示。此外，知识蒸馏技术 Stanton
    等 ([2021](#bib.bib234)) 可以进一步研究，以促进从复杂的教师模型到简单的学生模型的知识转移，从而实现紧凑而有效的表示。这些领域仍然开放于进一步的贡献。
- en: 5.0.5 Adversarial Attack and Defense
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.0.5 对抗攻击与防御
- en: Adversarial attacks and defense mechanisms in deep learning represent a critical
    area of research and development, particularly as deep learning models become
    increasingly integrated into various applications. Adversarial attacks involves
    the deliberate manipulation of input data to mislead or deceive deep learning
    models, leading to incorrect predictions or behavior Akhtar and Mian ([2018](#bib.bib5)).
    Szegedy et al. Szegedy et al. ([2013](#bib.bib240)) was the first to identify
    this intriguing shortcoming of deep neural networks in image classification. They
    showed that even with their great accuracy, deep learning models are surprisingly
    vulnerable to adversarial attacks that take the form of tiny image changes that
    are (almost) invisible to human vision systems. A neural network classifier may
    radically alter its prediction about an image as a result of such an attack. Also,
    such a model can indicate high confidence in wrong predictions, which can be catastrophic
    for deep learning models deployed in medical or security fields, among many others.
    In generative models, several studies have investigated how adversarial attacks
    affect autoencoders and GANs, as seen in Tabacof et al. Tabacof et al. ([2016](#bib.bib242))
    where a method to manipulate input images in a way that deceives variational autoencoders
    into reconstructing a totally different image was introduced. In recent times,
    the focus of adversarial attack research has been on images, but studies has shown
    that adversarial attacks are not limited to image data; they can also affect other
    types of data such as text, signals, audio, and video Zhang et al. ([2020b](#bib.bib297));
    Jiang et al. ([2019](#bib.bib110)); Esmaeilpour et al. ([2019](#bib.bib58)). Future
    research can focus on exploring adversarial attacks in these domains and developing
    tailored defense mechanisms. Also, researchers can further investigate the practical
    implications of adversarial attacks in real-world scenarios, such as in autonomous
    vehicles, medical imaging, and cybersecurity. Understanding the potential impact
    of adversarial attacks in these applications can inform the development of more
    robust and secure systems.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗攻击和深度学习中的防御机制是一个关键的研究与开发领域，特别是随着深度学习模型越来越多地融入各种应用。对抗攻击涉及故意操纵输入数据，以误导或欺骗深度学习模型，导致错误的预测或行为（Akhtar
    和 Mian ([2018](#bib.bib5))）。Szegedy 等人 ([2013](#bib.bib240)) 首次识别出深度神经网络在图像分类中这一引人注目的缺陷。他们展示了即使在高精度的情况下，深度学习模型也意外地容易受到对抗攻击，这些攻击表现为对人类视觉系统几乎不可见的微小图像变化。这样的攻击可能会彻底改变神经网络分类器对图像的预测。此外，这样的模型可能对错误的预测表现出高度的自信，这对于在医疗或安全等领域部署的深度学习模型来说，可能是灾难性的。在生成模型中，一些研究探讨了对抗攻击如何影响自编码器和生成对抗网络（GANs），如在
    Tabacof 等人 ([2016](#bib.bib242)) 的研究中，介绍了一种操控输入图像的方法，以欺骗变分自编码器重建完全不同的图像。近年来，对抗攻击研究的重点是图像，但研究表明，对抗攻击并不限于图像数据；它们也可以影响其他类型的数据，如文本、信号、音频和视频（Zhang
    等人 ([2020b](#bib.bib297)); Jiang 等人 ([2019](#bib.bib110)); Esmaeilpour 等人 ([2019](#bib.bib58))）。未来的研究可以专注于探索这些领域中的对抗攻击，并开发量身定制的防御机制。同时，研究人员可以进一步探讨对抗攻击在实际场景中的影响，如自动驾驶汽车、医疗成像和网络安全。理解这些应用中对抗攻击的潜在影响可以为开发更为稳健和安全的系统提供指导。
- en: 6 Conclusions
  id: totrans-240
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: Deep learning has become the prominent data-driven approach in various state-of-the-art
    applications. Its importance lies in its ability to revolutionize many aspects
    of research and industries and tackle complex problems which were once impossible
    to overcome. Numerous surveys have been published on deep learning, reviewing
    the concepts, model architectures and applications. However, the studies do not
    discuss the emerging trends in the state-of-the-art applications of deep learning
    and emphasise the important traits and elements in the models. This paper presents
    a structured and comprehensive survey of deep learning, focusing on the latest
    trends and advancements in state-of-the-art applications such as computer vision,
    natural language processing, time series analysis and pervasive computing. The
    survey explores key elements and traits in modern deep learning models, highlighting
    their significance in addressing complex challenges across diverse domains. Furthermore,
    this paper presents a comprehensive review of the deep learning fundamentals,
    which is essential for understanding the core principles behind modern deep learning
    models. The survey finishes by discussing the critical challenges and future directions
    in deep learning.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已经成为各种尖端应用中的主流数据驱动方法。其重要性在于其能够彻底改变许多研究和行业的各个方面，并解决曾经难以克服的复杂问题。已经发布了大量关于深度学习的调查，回顾了概念、模型架构和应用。然而，这些研究并未讨论深度学习在尖端应用中的新兴趋势，也未强调模型中的重要特征和元素。本文提供了深度学习的结构化和全面的调查，重点关注计算机视觉、自然语言处理、时间序列分析和普适计算等尖端应用中的最新趋势和进展。调查探讨了现代深度学习模型中的关键元素和特征，突出其在应对各领域复杂挑战中的重要性。此外，本文还对深度学习基础进行了全面回顾，这对于理解现代深度学习模型的核心原理至关重要。调查最后讨论了深度学习中的关键挑战和未来方向。
- en: Acknowledgement
  id: totrans-242
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: 'This work has been supported in part by the Ministry of Higher Education Malaysia
    for Fundamental Research Grant Scheme with Project Code: FRGS/1/2023/ICT02/USM/02/2.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作部分得到了马来西亚高等教育部基础研究资助计划的支持，项目代码：FRGS/1/2023/ICT02/USM/02/2。
- en: Declaration of competing interest
  id: totrans-244
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 竞争利益声明
- en: The authors declare that they have no known competing financial interests or
    personal relationships that could have appeared to influence the work reported
    in this paper.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 作者声明，他们没有已知的财务竞争利益或个人关系，这些可能会影响本文报告的工作。
- en: Data availability
  id: totrans-246
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 数据可用性
- en: No data was used for the research described in the article.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中描述的研究未使用任何数据。
- en: \printcredits
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: \printcredits
- en: References
  id: totrans-249
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abdulwahhab et al. (2024) Abdulwahhab, A.H., Abdulaal, A.H., Thary Al-Ghrairi,
    A.H., Mohammed, A.A., Valizadeh, M., 2024. Detection of epileptic seizure using
    eeg signals analysis based on deep learning techniques. Chaos, Solitons and Fractals
    181, 114700. URL: [https://www.sciencedirect.com/science/article/pii/S0960077924002522](https://www.sciencedirect.com/science/article/pii/S0960077924002522),
    doi:[https://doi.org/10.1016/j.chaos.2024.114700](https:/doi.org/https://doi.org/10.1016/j.chaos.2024.114700).'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abdulwahhab 等人（2024）Abdulwahhab, A.H., Abdulaal, A.H., Thary Al-Ghrairi, A.H.,
    Mohammed, A.A., Valizadeh, M., 2024. 基于深度学习技术的脑电信号分析用于癫痫发作检测。Chaos, Solitons and
    Fractals 181, 114700. URL: [https://www.sciencedirect.com/science/article/pii/S0960077924002522](https://www.sciencedirect.com/science/article/pii/S0960077924002522),
    doi:[https://doi.org/10.1016/j.chaos.2024.114700](https:/doi.org/https://doi.org/10.1016/j.chaos.2024.114700)。'
- en: Abedin et al. (2021) Abedin, M.Z., Moon, M.H., Hassan, M.K., Hajek, P., 2021.
    Deep learning-based exchange rate prediction during the covid-19 pandemic. Annals
    of Operations Research , 1–52.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abedin 等人（2021）Abedin, M.Z., Moon, M.H., Hassan, M.K., Hajek, P., 2021. 基于深度学习的汇率预测在
    COVID-19 大流行期间的表现。运筹学年刊, 1–52。
- en: Acharya et al. (2017) Acharya, U.R., Oh, S.L., Hagiwara, Y., Tan, J.H., Adam,
    M., Gertych, A., San Tan, R., 2017. A deep convolutional neural network model
    to classify heartbeats. Computers in biology and medicine 89, 389–396.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Acharya 等人（2017）Acharya, U.R., Oh, S.L., Hagiwara, Y., Tan, J.H., Adam, M.,
    Gertych, A., San Tan, R., 2017. 一个深度卷积神经网络模型用于心跳分类。生物医学计算机 89, 389–396。
- en: 'Ahnouch et al. (2023) Ahnouch, M., Elaachak, L., Ghadi, A., 2023. Model risk
    in financial derivatives and the transformative impact of deep learning: A systematic
    review, in: The Proceedings of the International Conference on Smart City Applications,
    Springer. pp. 155–165.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahnouch 等人（2023）Ahnouch, M., Elaachak, L., Ghadi, A., 2023. 财务衍生品中的模型风险及深度学习的变革性影响：系统评审，见于《国际智慧城市应用会议论文集》，Springer出版社。第155–165页。
- en: 'Akhtar and Mian (2018) Akhtar, N., Mian, A., 2018. Threat of adversarial attacks
    on deep learning in computer vision: A survey. IEEE Access 6, 14410–14430. doi:[10.1109/ACCESS.2018.2807385](https:/doi.org/10.1109/ACCESS.2018.2807385).'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akhtar 和 Mian（2018）Akhtar, N., Mian, A., 2018. 深度学习在计算机视觉中的对抗攻击威胁：调查。IEEE Access
    6, 14410–14430. doi:[10.1109/ACCESS.2018.2807385](https:/doi.org/10.1109/ACCESS.2018.2807385)。
- en: Alnuaim et al. (2022) Alnuaim, A.A., Zakariah, M., Shashidhar, C., Hatamleh,
    W.A., Tarazi, H., Shukla, P.K., Ratna, R., 2022. Speaker gender recognition based
    on deep neural networks and resnet50. Wireless Communications and Mobile Computing
    2022, 1–13.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alnuaim 等人（2022）Alnuaim, A.A., Zakariah, M., Shashidhar, C., Hatamleh, W.A.,
    Tarazi, H., Shukla, P.K., Ratna, R., 2022. 基于深度神经网络和 resnet50 的说话人性别识别。Wireless
    Communications and Mobile Computing 2022, 1–13。
- en: 'Alom et al. (2019) Alom, M.Z., Taha, T.M., Yakopcic, C., Westberg, S., Sidike,
    P., Nasrin, M.S., Hasan, M., Van Essen, B.C., Awwal, A.A., Asari, V.K., 2019.
    A state-of-the-art survey on deep learning theory and architectures. electronics
    8, 292. Publisher: Multidisciplinary Digital Publishing Institute.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alom 等人（2019）Alom, M.Z., Taha, T.M., Yakopcic, C., Westberg, S., Sidike, P.,
    Nasrin, M.S., Hasan, M., Van Essen, B.C., Awwal, A.A., Asari, V.K., 2019. 深度学习理论和架构的最前沿调查。electronics
    8, 292。出版商：Multidisciplinary Digital Publishing Institute。
- en: 'Alrowili and Vijay-Shanker (2021) Alrowili, S., Vijay-Shanker, K., 2021. BioM-transformers:
    building large biomedical language models with BERT, ALBERT and ELECTRA, in: Proceedings
    of the 20th workshop on biomedical language processing, pp. 221–227.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alrowili 和 Vijay-Shanker（2021）Alrowili, S., Vijay-Shanker, K., 2021. BioM-transformers：使用
    BERT、ALBERT 和 ELECTRA 构建大型生物医学语言模型，见：第 20 届生物医学语言处理研讨会论文集，第 221–227 页。
- en: 'Alrowili and Vijay-Shanker (2022) Alrowili, S., Vijay-Shanker, K., 2022. Exploring
    Biomedical Question Answering with BioM-Transformers At BioASQ10B challenge: Findings
    and Techniques., in: CLEF (Working Notes), pp. 222–234.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alrowili 和 Vijay-Shanker（2022）Alrowili, S., Vijay-Shanker, K., 2022. 在 BioASQ10B
    挑战中使用 BioM-Transformers 探索生物医学问答：发现与技术，见：CLEF（工作笔记），第 222–234 页。
- en: 'Altaheri et al. (2023) Altaheri, H., Muhammad, G., Alsulaiman, M., Amin, S.U.,
    Altuwaijri, G.A., Abdul, W., Bencherif, M.A., Faisal, M., 2023. Deep learning
    techniques for classification of electroencephalogram (eeg) motor imagery (mi)
    signals: A review. Neural Computing and Applications 35, 14681–14722.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Altaheri 等人（2023）Altaheri, H., Muhammad, G., Alsulaiman, M., Amin, S.U., Altuwaijri,
    G.A., Abdul, W., Bencherif, M.A., Faisal, M., 2023. 用于电生理图（eeg）运动意象（mi）信号分类的深度学习技术：综述。Neural
    Computing and Applications 35, 14681–14722。
- en: 'Alzubaidi et al. (2021) Alzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili,
    A., Duan, Y., Al-Shamma, O., Santamaría, J., Fadhel, M.A., Al-Amidie, M., Farhan,
    L., 2021. Review of deep learning: concepts, CNN architectures, challenges, applications,
    future directions. Journal of big Data 8, 1–74. Publisher: Springer.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alzubaidi 等人（2021）Alzubaidi, L., Zhang, J., Humaidi, A.J., Al-Dujaili, A., Duan,
    Y., Al-Shamma, O., Santamaría, J., Fadhel, M.A., Al-Amidie, M., Farhan, L., 2021.
    深度学习综述：概念、CNN 架构、挑战、应用及未来方向。Journal of big Data 8, 1–74。出版商：Springer。
- en: Ang and Guan (2017) Ang, K.K., Guan, C., 2017. Eeg-based strategies to detect
    motor imagery for control and rehabilitation. IEEE Transactions on Neural Systems
    and Rehabilitation Engineering 25, 392–401. doi:[10.1109/TNSRE.2016.2646763](https:/doi.org/10.1109/TNSRE.2016.2646763).
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ang 和 Guan（2017）Ang, K.K., Guan, C., 2017. 基于 EEG 的策略检测运动意象用于控制和康复。IEEE Transactions
    on Neural Systems and Rehabilitation Engineering 25, 392–401. doi:[10.1109/TNSRE.2016.2646763](https:/doi.org/10.1109/TNSRE.2016.2646763)。
- en: 'Araabi and Monz (2020) Araabi, A., Monz, C., 2020. Optimizing Transformer for
    Low-Resource Neural Machine Translation, in: Scott, D., Bel, N., Zong, C. (Eds.),
    Proceedings of the 28th International Conference on Computational Linguistics,
    International Committee on Computational Linguistics, Barcelona, Spain (Online).
    pp. 3429–3435. URL: [https://aclanthology.org/2020.coling-main.304](https://aclanthology.org/2020.coling-main.304),
    doi:[10.18653/v1/2020.coling-main.304](https:/doi.org/10.18653/v1/2020.coling-main.304).'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Araabi 和 Monz（2020）Araabi, A., Monz, C., 2020. 针对低资源神经机器翻译优化 Transformer，见：Scott,
    D., Bel, N., Zong, C.（主编），第 28 届国际计算语言学会议论文集，国际计算语言学委员会，西班牙巴塞罗那（在线）。第 3429–3435
    页。URL: [https://aclanthology.org/2020.coling-main.304](https://aclanthology.org/2020.coling-main.304)，doi:[10.18653/v1/2020.coling-main.304](https:/doi.org/10.18653/v1/2020.coling-main.304)。'
- en: 'Arevian (2007) Arevian, G., 2007. Recurrent Neural Networks for Robust Real-World
    Text Classification, in: IEEE/WIC/ACM International Conference on Web Intelligence
    (WI’07), pp. 326–329. URL: [https://ieeexplore.ieee.org/abstract/document/4427112](https://ieeexplore.ieee.org/abstract/document/4427112),
    doi:[10.1109/WI.2007.126](https:/doi.org/10.1109/WI.2007.126).'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arevian (2007) Arevian, G., 2007. 用于稳健的现实世界文本分类的递归神经网络，发表于：IEEE/WIC/ACM 国际网页智能会议
    (WI’07)，第326–329页。网址：[https://ieeexplore.ieee.org/abstract/document/4427112](https://ieeexplore.ieee.org/abstract/document/4427112)，doi：[10.1109/WI.2007.126](https:/doi.org/10.1109/WI.2007.126)。
- en: 'Ba et al. (2016) Ba, J., Kiros, J., Hinton, G.E., 2016. Layer Normalization.
    ArXiv URL: [https://www.semanticscholar.org/paper/Layer-Normalization-Ba-Kiros/97fb4e3d45bb098e27e0071448b6152217bd35a5](https://www.semanticscholar.org/paper/Layer-Normalization-Ba-Kiros/97fb4e3d45bb098e27e0071448b6152217bd35a5).'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ba et al. (2016) Ba, J., Kiros, J., Hinton, G.E., 2016. 层归一化。ArXiv 网址：[https://www.semanticscholar.org/paper/Layer-Normalization-Ba-Kiros/97fb4e3d45bb098e27e0071448b6152217bd35a5](https://www.semanticscholar.org/paper/Layer-Normalization-Ba-Kiros/97fb4e3d45bb098e27e0071448b6152217bd35a5)。
- en: 'Badrinarayanan et al. (2017) Badrinarayanan, V., Kendall, A., Cipolla, R.,
    2017. Segnet: A deep convolutional encoder-decoder architecture for image segmentation.
    IEEE transactions on pattern analysis and machine intelligence 39, 2481–2495.
    Publisher: IEEE.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Badrinarayanan et al. (2017) Badrinarayanan, V., Kendall, A., Cipolla, R., 2017.
    Segnet：一种用于图像分割的深度卷积编码器-解码器架构。IEEE模式分析与机器智能期刊 39, 2481–2495。出版社：IEEE。
- en: Bahdanau et al. (2014) Bahdanau, D., Cho, K., Bengio, Y., 2014. Neural machine
    translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473
    .
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bahdanau et al. (2014) Bahdanau, D., Cho, K., Bengio, Y., 2014. 通过联合学习对齐和翻译进行神经机器翻译。arXiv预印本
    arXiv:1409.0473。
- en: Baloglu et al. (2019) Baloglu, U.B., Talo, M., Yildirim, O., San Tan, R., Acharya,
    U.R., 2019. Classification of myocardial infarction with multi-lead ecg signals
    and deep cnn. Pattern recognition letters 122, 23–30.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baloglu et al. (2019) Baloglu, U.B., Talo, M., Yildirim, O., San Tan, R., Acharya,
    U.R., 2019. 利用多导联ECG信号和深度CNN进行心肌梗死分类。模式识别快报 122, 23–30。
- en: 'Banerjee et al. (2020) Banerjee, R., Ghose, A., Muthana Mandana, K., 2020.
    A hybrid cnn-lstm architecture for detection of coronary artery disease from ecg,
    in: 2020 International Joint Conference on Neural Networks (IJCNN), pp. 1–8. doi:[10.1109/IJCNN48605.2020.9207044](https:/doi.org/10.1109/IJCNN48605.2020.9207044).'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerjee et al. (2020) Banerjee, R., Ghose, A., Muthana Mandana, K., 2020. 一种用于检测冠状动脉疾病的混合cnn-lstm架构，发表于：2020年国际神经网络联合会议
    (IJCNN)，第1–8页。doi：[10.1109/IJCNN48605.2020.9207044](https:/doi.org/10.1109/IJCNN48605.2020.9207044)。
- en: 'Banjarey et al. (2022) Banjarey, K., Sahu, S.P., Dewangan, D.K., 2022. Human
    activity recognition using 1d convolutional neural network, in: Sentimental Analysis
    and Deep Learning: Proceedings of ICSADL 2021, Springer. pp. 691–702.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banjarey et al. (2022) Banjarey, K., Sahu, S.P., Dewangan, D.K., 2022. 使用1d卷积神经网络进行人类活动识别，发表于：情感分析与深度学习：ICSADL
    2021论文集，Springer，第691–702页。
- en: 'Bochkovskiy et al. (2020) Bochkovskiy, A., Wang, C.Y., Liao, H.Y.M., 2020.
    Yolov4: Optimal speed and accuracy of object detection. arXiv preprint arXiv:2004.10934
    .'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bochkovskiy et al. (2020) Bochkovskiy, A., Wang, C.Y., Liao, H.Y.M., 2020. Yolov4：最佳的目标检测速度和准确性。arXiv预印本
    arXiv:2004.10934。
- en: 'Bodla et al. (2017) Bodla, N., Singh, B., Chellappa, R., Davis, L.S., 2017.
    Soft-NMS–improving object detection with one line of code, in: Proceedings of
    the IEEE international conference on computer vision, pp. 5561–5569.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bodla et al. (2017) Bodla, N., Singh, B., Chellappa, R., Davis, L.S., 2017.
    Soft-NMS—用一行代码改进目标检测，发表于：IEEE国际计算机视觉会议论文集，第5561–5569页。
- en: Boonyakitanont et al. (2020) Boonyakitanont, P., Lek-Uthai, A., Chomtho, K.,
    Songsiri, J., 2020. A review of feature extraction and performance evaluation
    in epileptic seizure detection using eeg. Biomedical Signal Processing and Control
    57, 101702.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boonyakitanont et al. (2020) Boonyakitanont, P., Lek-Uthai, A., Chomtho, K.,
    Songsiri, J., 2020. 癫痫发作检测中的特征提取与性能评估综述。生物医学信号处理与控制 57, 101702。
- en: Brunner et al. (2007) Brunner, C., Naeem, M., Leeb, R., Graimann, B., Pfurtscheller,
    G., 2007. Spatial filtering and selection of optimized components in four class
    motor imagery eeg data using independent components analysis. Pattern recognition
    letters 28, 957–964.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brunner et al. (2007) Brunner, C., Naeem, M., Leeb, R., Graimann, B., Pfurtscheller,
    G., 2007. 在四类运动意象脑电数据中使用独立成分分析的空间滤波和优化成分选择。模式识别快报 28, 957–964。
- en: 'Cai et al. (2018) Cai, S., Feng, X., Deng, Z., Ming, Z., Shan, Z., 2018. Financial
    news quantization and stock market forecast research based on cnn and lstm, in:
    Smart Computing and Communication: Third International Conference, SmartCom 2018,
    Tokyo, Japan, December 10–12, 2018, Proceedings 3, Springer. pp. 366–375.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等 (2018) Cai, S., Feng, X., Deng, Z., Ming, Z., Shan, Z., 2018. 基于 CNN 和
    LSTM 的金融新闻量化与股票市场预测研究，见于：智能计算与通信：第三届国际会议，SmartCom 2018，东京，日本，2018年12月10–12日，会议录
    3，Springer. 页码 366–375。
- en: 'Cai et al. (2019) Cai, Y., Wang, X., Yu, Z., Li, F., Xu, P., Li, Y., Li, L.,
    2019. Dualattn-GAN: Text to Image Synthesis With Dual Attentional Generative Adversarial
    Network. IEEE Access 7, 183706–183716. URL: [https://ieeexplore.ieee.org/document/8930532?denied=](https://ieeexplore.ieee.org/document/8930532?denied=),
    doi:[10.1109/ACCESS.2019.2958864](https:/doi.org/10.1109/ACCESS.2019.2958864).
    conference Name: IEEE Access.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai 等 (2019) Cai, Y., Wang, X., Yu, Z., Li, F., Xu, P., Li, Y., Li, L., 2019.
    Dualattn-GAN：具有双重注意力生成对抗网络的文本到图像合成。IEEE Access 7, 183706–183716。网址：[https://ieeexplore.ieee.org/document/8930532?denied=](https://ieeexplore.ieee.org/document/8930532?denied=)，doi：[10.1109/ACCESS.2019.2958864](https:/doi.org/10.1109/ACCESS.2019.2958864)。会议名称：IEEE
    Access。
- en: 'Calvo and Ceccatto (2000) Calvo, R.A., Ceccatto, H.A., 2000. Intelligent document
    classification. Intelligent Data Analysis 4, 411–420. URL: [https://content.iospress.com/articles/intelligent-data-analysis/ida00028](https://content.iospress.com/articles/intelligent-data-analysis/ida00028),
    doi:[10.3233/IDA-2000-4503](https:/doi.org/10.3233/IDA-2000-4503). publisher:
    IOS Press.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Calvo 和 Ceccatto (2000) Calvo, R.A., Ceccatto, H.A., 2000. 智能文档分类。智能数据分析 4,
    411–420。网址：[https://content.iospress.com/articles/intelligent-data-analysis/ida00028](https://content.iospress.com/articles/intelligent-data-analysis/ida00028)，doi：[10.3233/IDA-2000-4503](https:/doi.org/10.3233/IDA-2000-4503)。出版商：IOS
    Press。
- en: 'Carion et al. (2020) Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov,
    A., Zagoruyko, S., 2020. End-to-End Object Detection with Transformers, in: Vedaldi,
    A., Bischof, H., Brox, T., Frahm, J.M. (Eds.), Computer Vision – ECCV 2020, Springer
    International Publishing, Cham. pp. 213–229. doi:[10.1007/978-3-030-58452-8_13](https:/doi.org/10.1007/978-3-030-58452-8_13).'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Carion 等 (2020) Carion, N., Massa, F., Synnaeve, G., Usunier, N., Kirillov,
    A., Zagoruyko, S., 2020. 基于变换器的端到端目标检测，见于：Vedaldi, A., Bischof, H., Brox, T.,
    Frahm, J.M. (编)，计算机视觉 – ECCV 2020，Springer 国际出版，Cham. 页码 213–229。doi：[10.1007/978-3-030-58452-8_13](https:/doi.org/10.1007/978-3-030-58452-8_13)。
- en: Chan et al. (2015) Chan, W., Jaitly, N., Le, Q.V., Vinyals, O., 2015. Listen,
    attend and spell. arXiv preprint arXiv:1508.01211 .
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan 等 (2015) Chan, W., Jaitly, N., Le, Q.V., Vinyals, O., 2015. 听、关注与拼写。arXiv
    预印本 arXiv:1508.01211。
- en: 'Chaurasia and Culurciello (2017) Chaurasia, A., Culurciello, E., 2017. Linknet:
    Exploiting encoder representations for efficient semantic segmentation, in: 2017
    IEEE visual communications and image processing (VCIP), IEEE. pp. 1–4.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chaurasia 和 Culurciello (2017) Chaurasia, A., Culurciello, E., 2017. Linknet:
    利用编码器表示进行高效语义分割，见于：2017 IEEE视觉通信与图像处理（VCIP），IEEE. 页码 1–4。'
- en: 'Chen et al. (2022a) Chen, C.Y., Lin, Y.T., Lee, S.J., Tsai, W.C., Huang, T.C.,
    Liu, Y.H., Cheng, M.C., Dai, C.Y., 2022a. Automated ecg classification based on
    1d deep learning network. Methods 202, 127–135. URL: [https://www.sciencedirect.com/science/article/pii/S1046202321001134](https://www.sciencedirect.com/science/article/pii/S1046202321001134),
    doi:[https://doi.org/10.1016/j.ymeth.2021.04.021](https:/doi.org/https://doi.org/10.1016/j.ymeth.2021.04.021).
    machine Learning Methods for Bio-Medical Image and Signal Processing: Recent Advances.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022a) Chen, C.Y., Lin, Y.T., Lee, S.J., Tsai, W.C., Huang, T.C., Liu,
    Y.H., Cheng, M.C., Dai, C.Y., 2022a. 基于 1D 深度学习网络的自动化 ECG 分类。方法 202, 127–135。网址：[https://www.sciencedirect.com/science/article/pii/S1046202321001134](https://www.sciencedirect.com/science/article/pii/S1046202321001134)，doi：[https://doi.org/10.1016/j.ymeth.2021.04.021](https:/doi.org/https://doi.org/10.1016/j.ymeth.2021.04.021)。机器学习方法用于生物医学图像和信号处理：近期进展。
- en: Chen et al. (2022b) Chen, D., Yongchareon, S., Lai, E.M.K., Yu, J., Sheng, Q.Z.,
    Li, Y., 2022b. Transformer with bidirectional gru for nonintrusive, sensor-based
    activity recognition in a multiresident environment. IEEE Internet of Things Journal
    9, 23716–23727.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2022b) Chen, D., Yongchareon, S., Lai, E.M.K., Yu, J., Sheng, Q.Z.,
    Li, Y., 2022b. 基于双向 GRU 的变换器用于多居民环境中的非侵入式传感器活动识别。IEEE 物联网杂志 9, 23716–23727。
- en: Chen et al. (2024) Chen, L., Pelger, M., Zhu, J., 2024. Deep learning in asset
    pricing. Management Science 70, 714–750.
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2024) Chen, L., Pelger, M., Zhu, J., 2024. 资产定价中的深度学习。管理科学 70, 714–750。
- en: 'Chen et al. (2018) Chen, L.C., Hermans, A., Papandreou, G., Schroff, F., Wang,
    P., Adam, H., 2018. MaskLab: Instance segmentation by refining object detection
    with semantic and direction features, in: Proceedings of the IEEE conference on
    computer vision and pattern recognition, pp. 4013–4022.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2018) Chen, L.C., Hermans, A., Papandreou, G., Schroff, F., Wang, P.,
    Adam, H., 2018. MaskLab：通过细化目标检测与语义和方向特征进行实例分割，在：IEEE计算机视觉与模式识别会议，第 4013–4022
    页。
- en: 'Chen et al. (2012) Chen, M., Xu, Z., Weinberger, K.Q., Sha, F., 2012. Marginalized
    denoising autoencoders for domain adaptation, in: Proceedings of the 29th International
    Coference on International Conference on Machine Learning, Omnipress, Madison,
    WI, USA. pp. 1627–1634.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2012) Chen, M., Xu, Z., Weinberger, K.Q., Sha, F., 2012. 用于领域适应的边际去噪自编码器，在：第29届国际机器学习大会，Omnipress,
    Madison, WI, USA，第 1627–1634 页。
- en: 'Chen et al. (2016) Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever,
    I., Abbeel, P., 2016. InfoGAN: Interpretable Representation Learning by Information
    Maximizing Generative Adversarial Nets. URL: [http://arxiv.org/abs/1606.03657](http://arxiv.org/abs/1606.03657),
    doi:[10.48550/arXiv.1606.03657](https:/doi.org/10.48550/arXiv.1606.03657). arXiv:1606.03657
    [cs, stat] version: 1.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等 (2016) Chen, X., Duan, Y., Houthooft, R., Schulman, J., Sutskever, I.,
    Abbeel, P., 2016. InfoGAN：通过信息最大化生成对抗网络的可解释表示学习。URL: [http://arxiv.org/abs/1606.03657](http://arxiv.org/abs/1606.03657)，doi:[10.48550/arXiv.1606.03657](https:/doi.org/10.48550/arXiv.1606.03657)。arXiv:1606.03657
    [cs, stat] 版本: 1。'
- en: 'Chiu et al. (2018) Chiu, C.C., Sainath, T.N., Wu, Y., Prabhavalkar, R., Nguyen,
    P., Chen, Z., Kannan, A., Weiss, R.J., Rao, K., Gonina, E., Jaitly, N., Li, B.,
    Chorowski, J., Bacchiani, M., 2018. State-of-the-art speech recognition with sequence-to-sequence
    models, in: 2018 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP), pp. 4774–4778. doi:[10.1109/ICASSP.2018.8462105](https:/doi.org/10.1109/ICASSP.2018.8462105).'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiu 等 (2018) Chiu, C.C., Sainath, T.N., Wu, Y., Prabhavalkar, R., Nguyen, P.,
    Chen, Z., Kannan, A., Weiss, R.J., Rao, K., Gonina, E., Jaitly, N., Li, B., Chorowski,
    J., Bacchiani, M., 2018. 先进的语音识别与序列到序列模型，在：2018 IEEE国际声学、语音与信号处理会议 (ICASSP)，第
    4774–4778 页。doi:[10.1109/ICASSP.2018.8462105](https:/doi.org/10.1109/ICASSP.2018.8462105)。
- en: 'Cho et al. (2014) Cho, K., van Merriënboer, B., Gulcehre, C., Bahdanau, D.,
    Bougares, F., Schwenk, H., Bengio, Y., 2014. Learning Phrase Representations using
    RNN Encoder–Decoder for Statistical Machine Translation, in: Moschitti, A., Pang,
    B., Daelemans, W. (Eds.), Proceedings of the 2014 Conference on Empirical Methods
    in Natural Language Processing (EMNLP), Association for Computational Linguistics,
    Doha, Qatar. pp. 1724–1734. URL: [https://aclanthology.org/D14-1179](https://aclanthology.org/D14-1179),
    doi:[10.3115/v1/D14-1179](https:/doi.org/10.3115/v1/D14-1179).'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cho 等 (2014) Cho, K., van Merriënboer, B., Gulcehre, C., Bahdanau, D., Bougares,
    F., Schwenk, H., Bengio, Y., 2014. 使用 RNN 编码器–解码器进行短语表示学习用于统计机器翻译，在：Moschitti,
    A., Pang, B., Daelemans, W. (编辑)，2014年自然语言处理实证方法会议 (EMNLP) 论文集，计算语言学协会，多哈，卡塔尔，第
    1724–1734 页。URL: [https://aclanthology.org/D14-1179](https://aclanthology.org/D14-1179)，doi:[10.3115/v1/D14-1179](https:/doi.org/10.3115/v1/D14-1179)。'
- en: 'Clevert et al. (2016) Clevert, D.A., Unterthiner, T., Hochreiter, S., 2016.
    Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). URL:
    [http://arxiv.org/abs/1511.07289](http://arxiv.org/abs/1511.07289), doi:[10.48550/arXiv.1511.07289](https:/doi.org/10.48550/arXiv.1511.07289).
    arXiv:1511.07289 [cs].'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Clevert 等 (2016) Clevert, D.A., Unterthiner, T., Hochreiter, S., 2016. 通过指数线性单元
    (ELUs) 实现快速而准确的深度网络学习。URL: [http://arxiv.org/abs/1511.07289](http://arxiv.org/abs/1511.07289)，doi:[10.48550/arXiv.1511.07289](https:/doi.org/10.48550/arXiv.1511.07289)。arXiv:1511.07289
    [cs]。'
- en: Crippa et al. (2015) Crippa, P., Curzi, A., Falaschetti, L., Turchetti, C.,
    et al., 2015. Multi-class ecg beat classification based on a gaussian mixture
    model of karhunen-loève transform. Int. J. Simul. Syst. Sci. Technol 16, 2–1.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Crippa 等 (2015) Crippa, P., Curzi, A., Falaschetti, L., Turchetti, C., 等，2015.
    基于卡尔霍嫩-洛埃夫变换的高斯混合模型的多类心电图节拍分类。国际模拟系统科学与技术杂志 16, 2–1。
- en: 'Cybenko (1989) Cybenko, G., 1989. Approximation by superpositions of a sigmoidal
    function. Mathematics of Control, Signals and Systems 2, 303–314. URL: [https://doi.org/10.1007/BF02551274](https://doi.org/10.1007/BF02551274),
    doi:[10.1007/BF02551274](https:/doi.org/10.1007/BF02551274).'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cybenko (1989) Cybenko, G., 1989. 通过对称函数的叠加进行逼近。控制、信号与系统数学 2, 303–314。URL:
    [https://doi.org/10.1007/BF02551274](https://doi.org/10.1007/BF02551274)，doi:[10.1007/BF02551274](https:/doi.org/10.1007/BF02551274)。'
- en: Dai et al. (2019) Dai, M., Zheng, D., Na, R., Wang, S., Zhang, S., 2019. Eeg
    classification of motor imagery using a novel deep learning framework. Sensors
    19, 551.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai 等 (2019) Dai, M., Zheng, D., Na, R., Wang, S., Zhang, S., 2019. 使用新型深度学习框架的脑电图运动想象分类。传感器
    19, 551。
- en: 'Dai et al. (2021) Dai, X., Chen, Y., Yang, J., Zhang, P., Yuan, L., Zhang,
    L., 2021. Dynamic DETR: End-to-End Object Detection With Dynamic Attention, pp.
    2988–2997. URL: [https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com](https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com).'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai等（2021）Dai, X., Chen, Y., Yang, J., Zhang, P., Yuan, L., Zhang, L., 2021.
    动态DETR：具有动态注意力的端到端目标检测，第2988–2997页。网址：[https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com](https://openaccess.thecvf.com/content/ICCV2021/html/Dai_Dynamic_DETR_End-to-End_Object_Detection_With_Dynamic_Attention_ICCV_2021_paper.html?ref=https://githubhelp.com)。
- en: 'Dang et al. (2020) Dang, L.M., Min, K., Wang, H., Piran, M.J., Lee, C.H., Moon,
    H., 2020. Sensor-based and vision-based human activity recognition: A comprehensive
    survey. Pattern Recognition 108, 107561.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dang等（2020）Dang, L.M., Min, K., Wang, H., Piran, M.J., Lee, C.H., Moon, H.,
    2020. 基于传感器和视觉的人类活动识别：全面综述。模式识别 108, 107561。
- en: 'Dass et al. (2023) Dass, R.K., Petersen, N., Omori, M., Lave, T.R., Visser,
    U., 2023. Detecting racial inequalities in criminal justice: towards an equitable
    deep learning approach for generating and interpreting racial categories using
    mugshots. AI & SOCIETY 38, 897–918. Publisher: Springer.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dass等（2023）Dass, R.K., Petersen, N., Omori, M., Lave, T.R., Visser, U., 2023.
    识别刑事司法中的种族不平等：朝着一种公平的深度学习方法生成和解释种族类别。AI与社会 38, 897–918。出版商：Springer。
- en: 'Deep and Zheng (2019) Deep, S., Zheng, X., 2019. Hybrid model featuring cnn
    and lstm architecture for human activity recognition on smartphone sensor data,
    in: 2019 20th international conference on parallel and distributed computing,
    applications and technologies (PDCAT), IEEE. pp. 259–264.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deep和Zheng（2019）Deep, S., Zheng, X., 2019. 具有CNN和LSTM架构的混合模型用于智能手机传感器数据上的人类活动识别，见于：2019年第20届国际并行与分布计算、应用与技术会议（PDCAT），IEEE.
    第259–264页。
- en: Delorme et al. (2007) Delorme, A., Sejnowski, T., Makeig, S., 2007. Enhanced
    detection of artifacts in eeg data using higher-order statistics and independent
    component analysis. Neuroimage 34, 1443–1449.
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Delorme等（2007）Delorme, A., Sejnowski, T., Makeig, S., 2007. 使用高阶统计量和独立成分分析增强EEG数据中伪影的检测。神经影像
    34, 1443–1449。
- en: Desai et al. (2021) Desai, M.P., Caffarena, G., Jevtic, R., Márquez, D.G., Otero,
    A., 2021. A low-latency, low-power fpga implementation of ecg signal characterization
    using hermite polynomials. Electronics 10, 2324.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Desai等（2021）Desai, M.P., Caffarena, G., Jevtic, R., Márquez, D.G., Otero, A.,
    2021. 使用Hermite多项式的低延迟、低功耗FPGA实现ECG信号特征提取。电子学 10, 2324。
- en: 'Devlin et al. (2018) Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018.
    BERT: Pre-training of deep bidirectional transformers for language understanding.
    arXiv preprint arXiv:1810.04805 .'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin等（2018）Devlin, J., Chang, M.W., Lee, K., Toutanova, K., 2018. BERT：用于语言理解的深度双向变换器的预训练。arXiv预印本
    arXiv:1810.04805。
- en: 'Dixit and Silakari (2021) Dixit, P., Silakari, S., 2021. Deep Learning Algorithms
    for Cybersecurity Applications: A Technological and Status Review. Computer Science
    Review 39, 100317. URL: [https://www.sciencedirect.com/science/article/pii/S1574013720304172](https://www.sciencedirect.com/science/article/pii/S1574013720304172),
    doi:[10.1016/j.cosrev.2020.100317](https:/doi.org/10.1016/j.cosrev.2020.100317).'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dixit和Silakari（2021）Dixit, P., Silakari, S., 2021. 用于网络安全应用的深度学习算法：技术和现状综述。计算机科学评论
    39, 100317。网址：[https://www.sciencedirect.com/science/article/pii/S1574013720304172](https://www.sciencedirect.com/science/article/pii/S1574013720304172)，doi:[10.1016/j.cosrev.2020.100317](https:/doi.org/10.1016/j.cosrev.2020.100317)。
- en: 'Dong et al. (2021) Dong, S., Wang, P., Abbas, K., 2021. A survey on deep learning
    and its applications. Computer Science Review 40, 100379. Publisher: Elsevier.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等（2021）Dong, S., Wang, P., Abbas, K., 2021. 深度学习及其应用的综述。计算机科学评论 40, 100379。出版商：Elsevier。
- en: 'Dosovitskiy et al. (2021) Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn,
    D., Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly,
    S., Uszkoreit, J., Houlsby, N., 2021. An Image is Worth 16x16 Words: Transformers
    for Image Recognition at Scale. URL: [http://arxiv.org/abs/2010.11929](http://arxiv.org/abs/2010.11929),
    doi:[10.48550/arXiv.2010.11929](https:/doi.org/10.48550/arXiv.2010.11929). arXiv:2010.11929
    [cs].'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dosovitskiy等（2021）Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D.,
    Zhai, X., Unterthiner, T., Dehghani, M., Minderer, M., Heigold, G., Gelly, S.,
    Uszkoreit, J., Houlsby, N., 2021. 一张图片值16x16个词：用于大规模图像识别的变换器。网址：[http://arxiv.org/abs/2010.11929](http://arxiv.org/abs/2010.11929)，doi:[10.48550/arXiv.2010.11929](https:/doi.org/10.48550/arXiv.2010.11929)。arXiv:2010.11929
    [cs]。
- en: Dua et al. (2023) Dua, N., Singh, S.N., Semwal, V.B., Challa, S.K., 2023. Inception
    inspired cnn-gru hybrid network for human activity recognition. Multimedia Tools
    and Applications 82, 5369–5403.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dua 等人 (2023) Dua, N., Singh, S.N., Semwal, V.B., Challa, S.K., 2023. 受启发的 CNN-GRU
    混合网络用于人类活动识别。多媒体工具与应用 82, 5369–5403。
- en: 'Duchi et al. (2011) Duchi, J., Hazan, E., Singer, Y., 2011. Adaptive Subgradient
    Methods for Online Learning and Stochastic Optimization. Journal of Machine Learning
    Research 12, 2121–2159. URL: [http://jmlr.org/papers/v12/duchi11a.html](http://jmlr.org/papers/v12/duchi11a.html).'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Duchi 等人 (2011) Duchi, J., Hazan, E., Singer, Y., 2011. 用于在线学习和随机优化的自适应子梯度方法。机器学习研究期刊
    12, 2121–2159。网址: [http://jmlr.org/papers/v12/duchi11a.html](http://jmlr.org/papers/v12/duchi11a.html)。'
- en: 'Dugas et al. (2000) Dugas, C., Bengio, Y., Bélisle, F., Nadeau, C., Garcia,
    R., 2000. Incorporating Second-Order Functional Knowledge for Better Option Pricing,
    in: Advances in Neural Information Processing Systems, MIT Press. URL: [https://papers.nips.cc/paper_files/paper/2000/hash/44968aece94f667e4095002d140b5896-Abstract.html](https://papers.nips.cc/paper_files/paper/2000/hash/44968aece94f667e4095002d140b5896-Abstract.html).'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dugas 等人 (2000) Dugas, C., Bengio, Y., Bélisle, F., Nadeau, C., Garcia, R.,
    2000. 通过引入二阶功能知识改进期权定价，见：神经信息处理系统进展，MIT Press。网址: [https://papers.nips.cc/paper_files/paper/2000/hash/44968aece94f667e4095002d140b5896-Abstract.html](https://papers.nips.cc/paper_files/paper/2000/hash/44968aece94f667e4095002d140b5896-Abstract.html)。'
- en: 'Eapen et al. (2019) Eapen, J., Bein, D., Verma, A., 2019. Novel deep learning
    model with cnn and bi-directional lstm for improved stock market index prediction,
    in: 2019 IEEE 9th annual computing and communication workshop and conference (CCWC),
    IEEE. pp. 0264–0270.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eapen 等人 (2019) Eapen, J., Bein, D., Verma, A., 2019. 具有 CNN 和双向 LSTM 的新型深度学习模型用于改进股票市场指数预测，见：2019
    IEEE 第九届年度计算与通信研讨会暨会议 (CCWC)，IEEE。第 0264–0270 页。
- en: Erdaş and Güney (2021) Erdaş, Ç.B., Güney, S., 2021. Human activity recognition
    by using different deep learning approaches for wearable sensors. Neural Processing
    Letters 53, 1795–1809.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Erdaş 和 Güney (2021) Erdaş, Ç.B., Güney, S., 2021. 使用不同深度学习方法进行可穿戴传感器的人类活动识别。神经处理信件
    53, 1795–1809。
- en: Esmaeilpour et al. (2019) Esmaeilpour, M., Cardinal, P., Koerich, A.L., 2019.
    A robust approach for securing audio classification against adversarial attacks.
    IEEE Transactions on information forensics and security 15, 2147–2159.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esmaeilpour 等人 (2019) Esmaeilpour, M., Cardinal, P., Koerich, A.L., 2019. 一种用于保护音频分类免受对抗性攻击的鲁棒方法。IEEE
    信息取证与安全期刊 15, 2147–2159。
- en: Esteva et al. (2019) Esteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V.,
    DePristo, M., Chou, K., Cui, C., Corrado, G., Thrun, S., Dean, J., 2019. A guide
    to deep learning in healthcare. Nature medicine 25, 24–29.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Esteva 等人 (2019) Esteva, A., Robicquet, A., Ramsundar, B., Kuleshov, V., DePristo,
    M., Chou, K., Cui, C., Corrado, G., Thrun, S., Dean, J., 2019. 医疗保健中的深度学习指南。自然医学
    25, 24–29。
- en: 'Fernandes et al. (2023) Fernandes, L., Fernandes, J.N., Calado, M., Pinto,
    J.R., Cerqueira, R., Cardoso, J.S., 2023. Intrinsic Explainability for End-to-End
    Object Detection. IEEE Access Publisher: IEEE.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fernandes 等人 (2023) Fernandes, L., Fernandes, J.N., Calado, M., Pinto, J.R.,
    Cerqueira, R., Cardoso, J.S., 2023. 面向端到端目标检测的内在可解释性。IEEE Access 出版商：IEEE。
- en: 'Freire and de Castro (2021) Freire, M.N., de Castro, L.N., 2021. e-Recruitment
    recommender systems: a systematic review. Knowledge and Information Systems 63,
    1–20. Publisher: Springer.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Freire 和 de Castro (2021) Freire, M.N., de Castro, L.N., 2021. 电子招聘推荐系统：系统评审。知识与信息系统
    63, 1–20。出版商：Springer。
- en: 'Gao et al. (2021a) Gao, W., Zhang, L., Teng, Q., He, J., Wu, H., 2021a. Danhar:
    Dual attention network for multimodal human activity recognition using wearable
    sensors. Applied Soft Computing 111, 107728.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等人 (2021a) Gao, W., Zhang, L., Teng, Q., He, J., Wu, H., 2021a. Danhar:
    用于多模态人类活动识别的双重注意力网络，使用可穿戴传感器。应用软计算 111, 107728。'
- en: Gao et al. (2021b) Gao, Z., Dang, W., Wang, X., Hong, X., Hou, L., Ma, K., Perc,
    M., 2021b. Complex networks and deep learning for eeg signal analysis. Cognitive
    Neurodynamics 15, 369–388.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等人 (2021b) Gao, Z., Dang, W., Wang, X., Hong, X., Hou, L., Ma, K., Perc,
    M., 2021b. 复杂网络和深度学习用于 EEG 信号分析。认知神经动力学 15, 369–388。
- en: 'Gao et al. (2018) Gao, Z., Xie, J., Wang, Q., Li, P., 2018. Global Second-order
    Pooling Convolutional Networks. URL: [http://arxiv.org/abs/1811.12006](http://arxiv.org/abs/1811.12006),
    doi:[10.48550/arXiv.1811.12006](https:/doi.org/10.48550/arXiv.1811.12006). arXiv:1811.12006
    [cs] version: 2.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao 等人 (2018) Gao, Z., Xie, J., Wang, Q., Li, P., 2018. 全球二阶池化卷积网络。网址: [http://arxiv.org/abs/1811.12006](http://arxiv.org/abs/1811.12006)，doi:[10.48550/arXiv.1811.12006](https:/doi.org/10.48550/arXiv.1811.12006)。arXiv:1811.12006
    [cs] 版本: 2。'
- en: 'Gezmu and Nürnberger (2022) Gezmu, A.M., Nürnberger, A., 2022. Transformers
    for Low-resource Neural Machine Translation., in: ICAART (1), pp. 459–466.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gezmu 和 Nürnberger (2022) Gezmu, A.M., Nürnberger, A., 2022. 用于低资源神经机器翻译的 Transformers，见：ICAART
    (1)，pp. 459–466。
- en: 'Gicić et al. (2023) Gicić, A., Donko, D., Subasi, A., 2023. Intelligent credit
    scoring using deep learning methods. Concurrency and Computation: Practice and
    Experience 35, e7637.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gicić 等 (2023) Gicić, A., Donko, D., Subasi, A., 2023. 使用深度学习方法的智能信用评分。并发与计算：实践与经验
    35, e7637。
- en: 'Giloni et al. (2022) Giloni, A., Grolman, E., Hagemann, T., Fromm, R., Fischer,
    S., Elovici, Y., Shabtai, A., 2022. BENN: Bias Estimation Using a Deep Neural
    Network. IEEE Transactions on Neural Networks and Learning Systems Publisher:
    IEEE.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Giloni 等 (2022) Giloni, A., Grolman, E., Hagemann, T., Fromm, R., Fischer,
    S., Elovici, Y., Shabtai, A., 2022. BENN: 使用深度神经网络的偏差估计。IEEE 神经网络与学习系统汇刊：IEEE。'
- en: 'Girshick (2015) Girshick, R., 2015. Fast R-CNN, in: 2015 IEEE International
    Conference on Computer Vision (ICCV), pp. 1440–1448. URL: [https://ieeexplore.ieee.org/document/7410526](https://ieeexplore.ieee.org/document/7410526),
    doi:[10.1109/ICCV.2015.169](https:/doi.org/10.1109/ICCV.2015.169). iSSN: 2380-7504.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Girshick (2015) Girshick, R., 2015. 快速 R-CNN，见：2015 IEEE 国际计算机视觉大会 (ICCV)，pp.
    1440–1448。URL: [https://ieeexplore.ieee.org/document/7410526](https://ieeexplore.ieee.org/document/7410526)，doi:[10.1109/ICCV.2015.169](https:/doi.org/10.1109/ICCV.2015.169)。iSSN:
    2380-7504。'
- en: 'Girshick et al. (2014) Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014.
    Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation,
    pp. 580–587. URL: [https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html](https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Girshick 等 (2014) Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014.
    准确目标检测和语义分割的丰富特征层次，pp. 580–587。URL: [https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html](https://openaccess.thecvf.com/content_cvpr_2014/html/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.html)。'
- en: 'Glorot et al. (2011) Glorot, X., Bordes, A., Bengio, Y., 2011. Deep Sparse
    Rectifier Neural Networks, in: Proceedings of the Fourteenth International Conference
    on Artificial Intelligence and Statistics, JMLR Workshop and Conference Proceedings.
    pp. 315–323. URL: [https://proceedings.mlr.press/v15/glorot11a.html](https://proceedings.mlr.press/v15/glorot11a.html).
    iSSN: 1938-7228.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Glorot 等 (2011) Glorot, X., Bordes, A., Bengio, Y., 2011. 深度稀疏修正神经网络，见：第十四届人工智能与统计国际会议论文集，JMLR
    工作坊和会议论文集。pp. 315–323。URL: [https://proceedings.mlr.press/v15/glorot11a.html](https://proceedings.mlr.press/v15/glorot11a.html)。iSSN:
    1938-7228。'
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., Bengio, Y., 2014. Generative adversarial
    nets. Advances in neural information processing systems 27.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A., Bengio, Y., 2014. 生成对抗网络。神经信息处理系统进展 27。
- en: Graves (2012) Graves, A., 2012. Sequence transduction with recurrent neural
    networks. arXiv preprint arXiv:1211.3711 .
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Graves (2012) Graves, A., 2012. 使用递归神经网络的序列转导。arXiv 预印本 arXiv:1211.3711。
- en: 'Gudelek et al. (2017) Gudelek, M.U., Boluk, S.A., Ozbayoglu, A.M., 2017. A
    deep learning based stock trading model with 2-d cnn trend detection, in: 2017
    IEEE symposium series on computational intelligence (SSCI), IEEE. pp. 1–8.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gudelek 等 (2017) Gudelek, M.U., Boluk, S.A., Ozbayoglu, A.M., 2017. 基于深度学习的股票交易模型，使用
    2-D CNN 趋势检测，见：2017 IEEE 计算智能研讨会系列 (SSCI)，IEEE。pp. 1–8。
- en: 'Guo et al. (2023) Guo, M.H., Liu, Z.N., Mu, T.J., Hu, S.M., 2023. Beyond Self-Attention:
    External Attention Using Two Linear Layers for Visual Tasks. IEEE Transactions
    on Pattern Analysis and Machine Intelligence 45, 5436–5447. URL: [https://ieeexplore.ieee.org/document/9912362](https://ieeexplore.ieee.org/document/9912362),
    doi:[10.1109/TPAMI.2022.3211006](https:/doi.org/10.1109/TPAMI.2022.3211006). conference
    Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guo 等 (2023) Guo, M.H., Liu, Z.N., Mu, T.J., Hu, S.M., 2023. 超越自注意力：用于视觉任务的外部注意力，采用两个线性层。IEEE
    模式分析与机器智能汇刊 45, 5436–5447。URL: [https://ieeexplore.ieee.org/document/9912362](https://ieeexplore.ieee.org/document/9912362)，doi:[10.1109/TPAMI.2022.3211006](https:/doi.org/10.1109/TPAMI.2022.3211006)。会议名称：IEEE
    模式分析与机器智能汇刊。'
- en: Gupta (2021) Gupta, S., 2021. Deep learning based human activity recognition
    (har) using wearable sensor data. International Journal of Information Management
    Data Insights 1, 100046.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta (2021) Gupta, S., 2021. 基于深度学习的人体活动识别（HAR），使用可穿戴传感器数据。国际信息管理数据洞察期刊 1,
    100046。
- en: Han et al. (2022) Han, C., Zhang, L., Tang, Y., Huang, W., Min, F., He, J.,
    2022. Human activity recognition using wearable sensors by heterogeneous convolutional
    neural networks. Expert Systems with Applications 198, 116764.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han等（2022）Han, C., Zhang, L., Tang, Y., Huang, W., Min, F., He, J., 2022. 利用异构卷积神经网络的可穿戴传感器进行人类活动识别。专家系统与应用
    198, 116764。
- en: 'Hao et al. (2023) Hao, S., Zhang, P., Liu, S., Wang, Y., 2023. Sentiment recognition
    and analysis method of official document text based on BERT–SVM model. Neural
    Computing and Applications 35, 24621–24632. URL: [https://doi.org/10.1007/s00521-023-08226-4](https://doi.org/10.1007/s00521-023-08226-4),
    doi:[10.1007/s00521-023-08226-4](https:/doi.org/10.1007/s00521-023-08226-4).'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao等（2023）Hao, S., Zhang, P., Liu, S., Wang, Y., 2023. 基于BERT–SVM模型的官方文件文本情感识别与分析方法。神经计算与应用
    35, 24621–24632。网址：[https://doi.org/10.1007/s00521-023-08226-4](https://doi.org/10.1007/s00521-023-08226-4)，doi：[10.1007/s00521-023-08226-4](https:/doi.org/10.1007/s00521-023-08226-4)。
- en: Hassouneh et al. (2020) Hassouneh, A., Mutawa, A., Murugappan, M., 2020. Development
    of a real-time emotion recognition system using facial expressions and eeg based
    on machine learning and deep neural network methods. Informatics in Medicine Unlocked
    20, 100372.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hassouneh等（2020）Hassouneh, A., Mutawa, A., Murugappan, M., 2020. 基于机器学习和深度神经网络方法的实时情感识别系统的开发。医学信息学解锁
    20, 100372。
- en: 'Hatamizadeh et al. (2023) Hatamizadeh, A., Yin, H., Heinrich, G., Kautz, J.,
    Molchanov, P., 2023. Global context vision transformers, in: International Conference
    on Machine Learning, PMLR. pp. 12633–12646.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hatamizadeh等（2023）Hatamizadeh, A., Yin, H., Heinrich, G., Kautz, J., Molchanov,
    P., 2023. 全球上下文视觉变换器，发表于：国际机器学习会议，PMLR，第12633–12646页。
- en: 'He et al. (2017) He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask
    R-CNN, in: Proceedings of the IEEE international conference on computer vision,
    pp. 2961–2969.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等（2017）He, K., Gkioxari, G., Dollár, P., Girshick, R., 2017. Mask R-CNN，发表于：IEEE国际计算机视觉会议论文集，第2961–2969页。
- en: 'He et al. (2015) He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep Residual Learning
    for Image Recognition. URL: [http://arxiv.org/abs/1512.03385](http://arxiv.org/abs/1512.03385),
    doi:[10.48550/arXiv.1512.03385](https:/doi.org/10.48550/arXiv.1512.03385). arXiv:1512.03385
    [cs].'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等（2015）He, K., Zhang, X., Ren, S., Sun, J., 2015. 深度残差学习用于图像识别。网址：[http://arxiv.org/abs/1512.03385](http://arxiv.org/abs/1512.03385)，doi：[10.48550/arXiv.1512.03385](https:/doi.org/10.48550/arXiv.1512.03385)。arXiv:1512.03385
    [cs]。
- en: 'He et al. (2020a) He, P., Liu, X., Gao, J., Chen, W., 2020a. DeBERTa: Decoding-enhanced
    bert with disentangled attention. arXiv preprint arXiv:2006.03654 .'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等（2020a）He, P., Liu, X., Gao, J., Chen, W., 2020a. DeBERTa：解码增强的BERT与解耦注意力。arXiv预印本
    arXiv:2006.03654。
- en: He et al. (2020b) He, Y., Nazir, S., Nie, B., Khan, S., Zhang, J., 2020b. Developing
    an efficient deep learning-based trusted model for pervasive computing using an
    lstm-based classification model. Complexity 2020, 1–6.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等（2020b）He, Y., Nazir, S., Nie, B., Khan, S., Zhang, J., 2020b. 基于LSTM分类模型的高效深度学习可信模型开发用于普适计算。复杂性
    2020, 1–6。
- en: 'Hema and Garcia Marquez (2023) Hema, C., Garcia Marquez, F.P., 2023. Emotional
    speech recognition using cnn and deep learning techniques. Applied Acoustics 211,
    109492. URL: [https://www.sciencedirect.com/science/article/pii/S0003682X23002906](https://www.sciencedirect.com/science/article/pii/S0003682X23002906),
    doi:[https://doi.org/10.1016/j.apacoust.2023.109492](https:/doi.org/https://doi.org/10.1016/j.apacoust.2023.109492).'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hema和Garcia Marquez（2023）Hema, C., Garcia Marquez, F.P., 2023. 使用CNN和深度学习技术进行情感语音识别。应用声学
    211, 109492。网址：[https://www.sciencedirect.com/science/article/pii/S0003682X23002906](https://www.sciencedirect.com/science/article/pii/S0003682X23002906)，doi：[https://doi.org/10.1016/j.apacoust.2023.109492](https:/doi.org/https://doi.org/10.1016/j.apacoust.2023.109492)。
- en: Hermawan et al. (2024) Hermawan, A.T., Zaeni, I.A.E., Wibawa, A.P., Gunawan,
    G., Hendrawan, W.H., Kristian, Y., 2024. A multi representation deep learning
    approach for epileptic seizure detection. Journal of Robotics and Control (JRC)
    5, 187–204.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hermawan等（2024）Hermawan, A.T., Zaeni, I.A.E., Wibawa, A.P., Gunawan, G., Hendrawan,
    W.H., Kristian, Y., 2024. 一种多重表示的深度学习方法用于癫痫发作检测。机器人与控制杂志 (JRC) 5, 187–204。
- en: Hernández-Blanco et al. (2019) Hernández-Blanco, A., Herrera-Flores, B., Tomás,
    D., Navarro-Colorado, B., et al., 2019. A systematic review of deep learning approaches
    to educational data mining. Complexity 2019.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hernández-Blanco等（2019）Hernández-Blanco, A., Herrera-Flores, B., Tomás, D.,
    Navarro-Colorado, B., 等，2019. 深度学习方法在教育数据挖掘中的系统性综述。复杂性 2019。
- en: 'Hinton (2009) Hinton, G.E., 2009. Deep belief networks. Scholarpedia 4, 5947.
    URL: [http://www.scholarpedia.org/article/Deep_belief_networks](http://www.scholarpedia.org/article/Deep_belief_networks),
    doi:[10.4249/scholarpedia.5947](https:/doi.org/10.4249/scholarpedia.5947).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton（2009）Hinton, G.E., 2009. 深度信念网络。Scholarpedia 4, 5947。网址：[http://www.scholarpedia.org/article/Deep_belief_networks](http://www.scholarpedia.org/article/Deep_belief_networks)，doi:[10.4249/scholarpedia.5947](https:/doi.org/10.4249/scholarpedia.5947)。
- en: 'Hinton (2012) Hinton, G.E., 2012. A Practical Guide to Training Restricted
    Boltzmann Machines, in: Montavon, G., Orr, G.B., Müller, K.R. (Eds.), Neural Networks:
    Tricks of the Trade: Second Edition. Springer, Berlin, Heidelberg. Lecture Notes
    in Computer Science, pp. 599–619. URL: [https://doi.org/10.1007/978-3-642-35289-8_32](https://doi.org/10.1007/978-3-642-35289-8_32),
    doi:[10.1007/978-3-642-35289-8_32](https:/doi.org/10.1007/978-3-642-35289-8_32).'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton（2012）Hinton, G.E., 2012. 限制玻尔兹曼机训练实用指南，见：Montavon, G., Orr, G.B., Müller,
    K.R.（编），《神经网络：实用技巧：第二版》。施普林格出版社，柏林，海德堡。计算机科学讲义，页码 599–619。网址：[https://doi.org/10.1007/978-3-642-35289-8_32](https://doi.org/10.1007/978-3-642-35289-8_32)，doi:[10.1007/978-3-642-35289-8_32](https:/doi.org/10.1007/978-3-642-35289-8_32)。
- en: 'Hinton et al. (2006) Hinton, G.E., Osindero, S., Teh, Y.W., 2006. A Fast Learning
    Algorithm for Deep Belief Nets. Neural Computation 18, 1527–1554. URL: [https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527),
    doi:[10.1162/neco.2006.18.7.1527](https:/doi.org/10.1162/neco.2006.18.7.1527).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton 等人（2006）Hinton, G.E., Osindero, S., Teh, Y.W., 2006. 深度信念网络的快速学习算法。神经计算
    18, 1527–1554。网址：[https://doi.org/10.1162/neco.2006.18.7.1527](https://doi.org/10.1162/neco.2006.18.7.1527)，doi:[10.1162/neco.2006.18.7.1527](https:/doi.org/10.1162/neco.2006.18.7.1527)。
- en: 'Hochreiter et al. (2001) Hochreiter, S., Bengio, Y., Frasconi, P., Schmidhuber,
    J., others, 2001. Gradient flow in recurrent nets: the difficulty of learning
    long-term dependencies, in: A Field Guide to Dynamical Recurrent Networks. A field
    guide to dynamical recurrent neural networks. IEEE Press In.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter 等人（2001）Hochreiter, S., Bengio, Y., Frasconi, P., Schmidhuber, J.,
    其他人，2001. 循环网络中的梯度流：学习长期依赖的难度，见：动态递归网络的实地指南。动态递归神经网络的实地指南。IEEE出版社。
- en: 'Hochreiter and Schmidhuber (1997) Hochreiter, S., Schmidhuber, J., 1997. Long
    Short-Term Memory. Neural Computation 9, 1735–1780. URL: [https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735),
    doi:[10.1162/neco.1997.9.8.1735](https:/doi.org/10.1162/neco.1997.9.8.1735).'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter 和 Schmidhuber（1997）Hochreiter, S., Schmidhuber, J., 1997. 长短期记忆。神经计算
    9, 1735–1780。网址：[https://doi.org/10.1162/neco.1997.9.8.1735](https://doi.org/10.1162/neco.1997.9.8.1735)，doi:[10.1162/neco.1997.9.8.1735](https:/doi.org/10.1162/neco.1997.9.8.1735)。
- en: 'Hornik et al. (1989) Hornik, K., Stinchcombe, M., White, H., 1989. Multilayer
    feedforward networks are universal approximators. Neural Networks 2, 359–366.
    URL: [https://www.sciencedirect.com/science/article/pii/0893608089900208](https://www.sciencedirect.com/science/article/pii/0893608089900208),
    doi:[10.1016/0893-6080(89)90020-8](https:/doi.org/10.1016/0893-6080(89)90020-8).'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hornik 等人（1989）Hornik, K., Stinchcombe, M., White, H., 1989. 多层前馈网络是通用近似器。神经网络
    2, 359–366。网址：[https://www.sciencedirect.com/science/article/pii/0893608089900208](https://www.sciencedirect.com/science/article/pii/0893608089900208)，doi:[10.1016/0893-6080(89)90020-8](https:/doi.org/10.1016/0893-6080(89)90020-8)。
- en: 'Hu et al. (2023) Hu, C., Sun, Z., Li, C., Zhang, Y., Xing, C., 2023. Survey
    of Time Series Data Generation in IoT. Sensors 23, 6976. URL: [https://www.mdpi.com/1424-8220/23/15/6976](https://www.mdpi.com/1424-8220/23/15/6976),
    doi:[10.3390/s23156976](https:/doi.org/10.3390/s23156976). number: 15 Publisher:
    Multidisciplinary Digital Publishing Institute.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2023）Hu, C., Sun, Z., Li, C., Zhang, Y., Xing, C., 2023. 物联网中的时间序列数据生成调查。传感器
    23, 6976。网址：[https://www.mdpi.com/1424-8220/23/15/6976](https://www.mdpi.com/1424-8220/23/15/6976)，doi:[10.3390/s23156976](https:/doi.org/10.3390/s23156976)。期号：15
    出版社：多学科数字出版机构。
- en: 'Hu et al. (2019) Hu, J., Shen, L., Albanie, S., Sun, G., Wu, E., 2019. Squeeze-and-Excitation
    Networks. URL: [http://arxiv.org/abs/1709.01507](http://arxiv.org/abs/1709.01507),
    doi:[10.48550/arXiv.1709.01507](https:/doi.org/10.48550/arXiv.1709.01507). arXiv:1709.01507
    [cs] version: 4.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2019）Hu, J., Shen, L., Albanie, S., Sun, G., Wu, E., 2019. 压缩与激励网络。网址：[http://arxiv.org/abs/1709.01507](http://arxiv.org/abs/1709.01507)，doi:[10.48550/arXiv.1709.01507](https:/doi.org/10.48550/arXiv.1709.01507)。arXiv:1709.01507
    [cs] 版本：4。
- en: 'Huang et al. (2017) Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.,
    2017. Densely connected convolutional networks, in: Proceedings of the IEEE conference
    on computer vision and pattern recognition, pp. 4700–4708.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人（2017）Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q., 2017.
    稠密连接卷积网络，见：IEEE计算机视觉与模式识别会议论文集，页码 4700–4708。
- en: 'Huang and Feng (2020) Huang, J., Feng, Y., 2020. Optimization of Recurrent
    Neural Networks on Natural Language Processing, in: Proceedings of the 2019 8th
    International Conference on Computing and Pattern Recognition, Association for
    Computing Machinery, New York, NY, USA. pp. 39–45. URL: [https://dl.acm.org/doi/10.1145/3373509.3373573](https://dl.acm.org/doi/10.1145/3373509.3373573),
    doi:[10.1145/3373509.3373573](https:/doi.org/10.1145/3373509.3373573).'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2023a) Huang, L., Lu, K., Song, G., Wang, L., Liu, S., Liu, Y.,
    Li, H., 2023a. Teach-DETR: Better Training DETR With Teachers. IEEE Transactions
    on Pattern Analysis and Machine Intelligence 45, 15759–15771. URL: [https://ieeexplore.ieee.org/document/10264211](https://ieeexplore.ieee.org/document/10264211),
    doi:[10.1109/TPAMI.2023.3319387](https:/doi.org/10.1109/TPAMI.2023.3319387). conference
    Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2023b) Huang, Y., Qi, J., Wang, X., Lin, Z., 2023b. Asymmetric
    Polynomial Loss for Multi-Label Classification, in: ICASSP 2023-2023 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE. pp. 1–5.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hwang et al. (2023) Hwang, J., Park, S., Chi, J., 2023. Improving multi-class
    motor imagery eeg classification using overlapping sliding window and deep learning
    model. Electronics 12. URL: [https://www.mdpi.com/2079-9292/12/5/1186](https://www.mdpi.com/2079-9292/12/5/1186),
    doi:[10.3390/electronics12051186](https:/doi.org/10.3390/electronics12051186).'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ige and Mohd Noor (2023) Ige, A.O., Mohd Noor, M.H., 2023. A deep local-temporal
    architecture with attention for lightweight human activity recognition. Applied
    Soft Computing 149, 110954. URL: [https://www.sciencedirect.com/science/article/pii/S1568494623009729](https://www.sciencedirect.com/science/article/pii/S1568494623009729),
    doi:[https://doi.org/10.1016/j.asoc.2023.110954](https:/doi.org/https://doi.org/10.1016/j.asoc.2023.110954).'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ige and Noor (2022) Ige, A.O., Noor, M.H.M., 2022. A survey on unsupervised
    learning for wearable sensor-based activity recognition. Applied Soft Computing
    , 109363.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ige and Noor (2023) Ige, A.O., Noor, M.H.M., 2023. Wsense: A robust feature
    learning module for lightweight human activity recognition. arXiv preprint arXiv:2303.17845
    .'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Imran et al. (2023) Imran, H.A., Riaz, Q., Hussain, M., Tahir, H., Arshad,
    R., 2023. Smart-wearable sensors and cnn-bigru model: A powerful combination for
    human activity recognition. IEEE Sensors Journal .'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ioffe and Szegedy (2015) Ioffe, S., Szegedy, C., 2015. Batch normalization:
    accelerating deep network training by reducing internal covariate shift, in: Proceedings
    of the 32nd International Conference on International Conference on Machine Learning
    - Volume 37, JMLR.org, Lille, France. pp. 448–456.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Iosifidis et al. (2019) Iosifidis, V., Tran, T.N.H., Ntoutsi, E., 2019. Fairness-enhancing
    interventions in stream classification, in: Database and Expert Systems Applications:
    30th International Conference, DEXA 2019, Linz, Austria, August 26–29, 2019, Proceedings,
    Part I 30, Springer. pp. 261–276.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iosifidis等人（2019）Iosifidis, V., Tran, T.N.H., Ntoutsi, E., 2019. 在流分类中增强公平性的干预措施，见：数据库与专家系统应用：第30届国际会议，DEXA
    2019，奥地利林茨，2019年8月26–29日，论文集，第I部分 30, Springer。页261–276。
- en: Jafarifarmand and Badamchizadeh (2019) Jafarifarmand, A., Badamchizadeh, M.A.,
    2019. Eeg artifacts handling in a real practical brain–computer interface controlled
    vehicle. IEEE Transactions on Neural Systems and Rehabilitation Engineering 27,
    1200–1208.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jafarifarmand 和 Badamchizadeh（2019）Jafarifarmand, A., Badamchizadeh, M.A., 2019.
    在实际的脑–机接口控制的车辆中处理脑电图伪影。IEEE《神经系统与康复工程学报》27, 1200–1208。
- en: 'Jain et al. (2023) Jain, B., Huber, M., Elmasri, R., 2023. Increasing Fairness
    in Predictions Using Bias Parity Score Based Loss Function Regularization. The
    International FLAIRS Conference Proceedings 36. URL: [https://journals.flvc.org/FLAIRS/article/view/133311](https://journals.flvc.org/FLAIRS/article/view/133311),
    doi:[10.32473/flairs.36.133311](https:/doi.org/10.32473/flairs.36.133311).'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jain等人（2023）Jain, B., Huber, M., Elmasri, R., 2023. 使用基于偏差平衡分数的损失函数正则化提高预测公平性。《国际FLAIRS会议论文集》36。URL:
    [https://journals.flvc.org/FLAIRS/article/view/133311](https://journals.flvc.org/FLAIRS/article/view/133311),
    doi:[10.32473/flairs.36.133311](https:/doi.org/10.32473/flairs.36.133311)。'
- en: Jaitly et al. (2016) Jaitly, N., Le, Q.V., Vinyals, O., Sutskever, I., Sussillo,
    D., Bengio, S., 2016. An online sequence-to-sequence model using partial conditioning.
    Advances in Neural Information Processing Systems 29.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaitly等人（2016）Jaitly, N., Le, Q.V., Vinyals, O., Sutskever, I., Sussillo, D.,
    Bengio, S., 2016. 使用部分条件的在线序列到序列模型。《神经信息处理系统进展》29。
- en: 'Jiang et al. (2024) Jiang, B., Zeng, W., Yang, C., Wang, R., Zhang, B., 2024.
    DE-GAN: Text-to-image synthesis with dual and efficient fusion model. Multimedia
    Tools and Applications 83, 23839–23852. URL: [https://doi.org/10.1007/s11042-023-16377-8](https://doi.org/10.1007/s11042-023-16377-8),
    doi:[10.1007/s11042-023-16377-8](https:/doi.org/10.1007/s11042-023-16377-8).'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jiang等人（2024）Jiang, B., Zeng, W., Yang, C., Wang, R., Zhang, B., 2024. DE-GAN：具有双重和高效融合模型的文本到图像合成。《多媒体工具与应用》83,
    23839–23852。URL: [https://doi.org/10.1007/s11042-023-16377-8](https://doi.org/10.1007/s11042-023-16377-8),
    doi:[10.1007/s11042-023-16377-8](https:/doi.org/10.1007/s11042-023-16377-8)。'
- en: 'Jiang et al. (2019) Jiang, L., Ma, X., Chen, S., Bailey, J., Jiang, Y.G., 2019.
    Black-box adversarial attacks on video recognition models, in: Proceedings of
    the 27th ACM International Conference on Multimedia, pp. 864–872.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang等人（2019）Jiang, L., Ma, X., Chen, S., Bailey, J., Jiang, Y.G., 2019. 对视频识别模型的黑盒对抗攻击，见：第27届ACM国际多媒体会议论文集，页864–872。
- en: 'Jiao et al. (2016) Jiao, Y., Tu, M., Berisha, V., Liss, J.M., 2016. Accent
    identification by combining deep neural networks and recurrent neural networks
    trained on long and short term features., in: Interspeech, pp. 2388–2392.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiao等人（2016）Jiao, Y., Tu, M., Berisha, V., Liss, J.M., 2016. 通过结合深度神经网络和在长短期特征上训练的递归神经网络进行口音识别，见：Interspeech，页2388–2392。
- en: 'Karras et al. (2018) Karras, T., Aila, T., Laine, S., Lehtinen, J., 2018. Progressive
    Growing of GANs for Improved Quality, Stability, and Variation. URL: [http://arxiv.org/abs/1710.10196](http://arxiv.org/abs/1710.10196),
    doi:[10.48550/arXiv.1710.10196](https:/doi.org/10.48550/arXiv.1710.10196). arXiv:1710.10196
    [cs, stat] version: 3.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karras等人（2018）Karras, T., Aila, T., Laine, S., Lehtinen, J., 2018. 《GAN的渐进生长以提高质量、稳定性和变异性》。URL:
    [http://arxiv.org/abs/1710.10196](http://arxiv.org/abs/1710.10196), doi:[10.48550/arXiv.1710.10196](https:/doi.org/10.48550/arXiv.1710.10196).
    arXiv:1710.10196 [cs, stat] 版本: 3。'
- en: 'Karras et al. (2019) Karras, T., Laine, S., Aila, T., 2019. A Style-Based Generator
    Architecture for Generative Adversarial Networks. URL: [http://arxiv.org/abs/1812.04948](http://arxiv.org/abs/1812.04948),
    doi:[10.48550/arXiv.1812.04948](https:/doi.org/10.48550/arXiv.1812.04948). arXiv:1812.04948
    [cs, stat] version: 3.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Karras等人（2019）Karras, T., Laine, S., Aila, T., 2019. 一种基于风格的生成对抗网络生成器架构。URL:
    [http://arxiv.org/abs/1812.04948](http://arxiv.org/abs/1812.04948), doi:[10.48550/arXiv.1812.04948](https:/doi.org/10.48550/arXiv.1812.04948).
    arXiv:1812.04948 [cs, stat] 版本: 3。'
- en: 'Kehrenberg et al. (2020) Kehrenberg, T., Chen, Z., Quadrianto, N., 2020. Tuning
    fairness by balancing target labels. Frontiers in artificial intelligence 3, 33.
    Publisher: Frontiers Media SA.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kehrenberg等人（2020）Kehrenberg, T., Chen, Z., Quadrianto, N., 2020. 通过平衡目标标签来调整公平性。《人工智能前沿》3,
    33。出版商：Frontiers Media SA。
- en: 'Khalil et al. (2019) Khalil, R.A., Jones, E., Babar, M.I., Jan, T., Zafar,
    M.H., Alhussain, T., 2019. Speech emotion recognition using deep learning techniques:
    A review. IEEE Access 7, 117327–117345. doi:[10.1109/ACCESS.2019.2936124](https:/doi.org/10.1109/ACCESS.2019.2936124).'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Khalil 等人 (2019) Khalil, R.A., Jones, E., Babar, M.I., Jan, T., Zafar, M.H.,
    Alhussain, T., 2019. 使用深度学习技术的语音情感识别: 综述. IEEE Access 7, 117327–117345. doi:[10.1109/ACCESS.2019.2936124](https:/doi.org/10.1109/ACCESS.2019.2936124).'
- en: Khan and Ahmad (2021) Khan, Z.N., Ahmad, J., 2021. Attention induced multi-head
    convolutional neural network for human activity recognition. Applied soft computing
    110, 107671.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 和 Ahmad (2021) Khan, Z.N., Ahmad, J., 2021. 基于注意力的多头卷积神经网络用于人类活动识别. 应用软计算
    110, 107671.
- en: 'Kim et al. (2023) Kim, D., Baek, Y., Yang, S., Choo, J., 2023. Towards Formality-Aware
    Neural Machine Translation by Leveraging Context Information, in: Findings of
    the Association for Computational Linguistics: EMNLP 2023, pp. 7384–7392.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 等人 (2023) Kim, D., Baek, Y., Yang, S., Choo, J., 2023. 通过利用上下文信息迈向形式感知的神经机器翻译,
    在: 计算语言学协会年会：EMNLP 2023, 页码 7384–7392.'
- en: 'Kingma and Ba (2017) Kingma, D.P., Ba, J., 2017. Adam: A Method for Stochastic
    Optimization. URL: [http://arxiv.org/abs/1412.6980](http://arxiv.org/abs/1412.6980),
    doi:[10.48550/arXiv.1412.6980](https:/doi.org/10.48550/arXiv.1412.6980). arXiv:1412.6980
    [cs].'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma 和 Ba (2017) Kingma, D.P., Ba, J., 2017. Adam: 一种随机优化方法. URL: [http://arxiv.org/abs/1412.6980](http://arxiv.org/abs/1412.6980),
    doi:[10.48550/arXiv.1412.6980](https:/doi.org/10.48550/arXiv.1412.6980). arXiv:1412.6980
    [cs].'
- en: Kingma and Welling (2013) Kingma, D.P., Welling, M., 2013. Auto-encoding variational
    bayes. arXiv preprint arXiv:1312.6114 .
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling (2013) Kingma, D.P., Welling, M., 2013. 自编码变分贝叶斯. arXiv 预印本
    arXiv:1312.6114.
- en: 'Krizhevsky et al. (2012) Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012.
    ImageNet Classification with Deep Convolutional Neural Networks, in: Advances
    in Neural Information Processing Systems, Curran Associates, Inc. URL: [https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html](https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Krizhevsky 等人 (2012) Krizhevsky, A., Sutskever, I., Hinton, G.E., 2012. 使用深度卷积神经网络进行
    ImageNet 分类, 在: 神经信息处理系统进展, Curran Associates, Inc. URL: [https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html](https://proceedings.neurips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html).'
- en: 'Kumar et al. (2016) Kumar, S., Sharma, A., Mamun, K., Tsunoda, T., 2016. A
    deep learning approach for motor imagery eeg signal classification, in: 2016 3rd
    Asia-Pacific World Congress on Computer Science and Engineering (APWC on CSE),
    IEEE. pp. 34–39.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kumar 等人 (2016) Kumar, S., Sharma, A., Mamun, K., Tsunoda, T., 2016. 一种用于运动意象
    EEG 信号分类的深度学习方法, 在: 2016 第三届亚太世界计算机科学与工程大会 (APWC on CSE), IEEE. 页码 34–39.'
- en: Kusuma and Jothi (2022) Kusuma, S., Jothi, K., 2022. Ecg signals-based automated
    diagnosis of congestive heart failure using deep cnn and lstm architecture. Biocybernetics
    and Biomedical Engineering 42, 247–257.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kusuma 和 Jothi (2022) Kusuma, S., Jothi, K., 2022. 基于 ECG 信号的充血性心力衰竭自动诊断，使用深度
    CNN 和 LSTM 架构. 生物控制与生物医学工程 42, 247–257.
- en: 'Lan et al. (2019) Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut,
    R., 2019. ALBERT: A lite bert for self-supervised learning of language representations.
    arXiv preprint arXiv:1909.11942 .'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lan 等人 (2019) Lan, Z., Chen, M., Goodman, S., Gimpel, K., Sharma, P., Soricut,
    R., 2019. ALBERT: 一种用于自监督学习语言表示的轻量 BERT. arXiv 预印本 arXiv:1909.11942.'
- en: 'LeCun et al. (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning.
    Nature 521, 436–444. URL: [https://www.nature.com/articles/nature14539](https://www.nature.com/articles/nature14539),
    doi:[10.1038/nature14539](https:/doi.org/10.1038/nature14539). number: 7553 Publisher:
    Nature Publishing Group.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LeCun 等人 (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. 深度学习. 自然 521, 436–444.
    URL: [https://www.nature.com/articles/nature14539](https://www.nature.com/articles/nature14539),
    doi:[10.1038/nature14539](https:/doi.org/10.1038/nature14539). 编号: 7553 出版社: Nature
    Publishing Group.'
- en: 'Lecun et al. (1998) Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998. Gradient-based
    learning applied to document recognition. Proceedings of the IEEE 86, 2278–2324.
    URL: [https://ieeexplore.ieee.org/document/726791](https://ieeexplore.ieee.org/document/726791),
    doi:[10.1109/5.726791](https:/doi.org/10.1109/5.726791). conference Name: Proceedings
    of the IEEE.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lecun 等人 (1998) Lecun, Y., Bottou, L., Bengio, Y., Haffner, P., 1998. 基于梯度的学习应用于文档识别.
    IEEE 会议记录 86, 2278–2324. URL: [https://ieeexplore.ieee.org/document/726791](https://ieeexplore.ieee.org/document/726791),
    doi:[10.1109/5.726791](https:/doi.org/10.1109/5.726791). 会议名称: IEEE 会议记录.'
- en: 'LeCun et al. (2012) LeCun, Y.A., Bottou, L., Orr, G.B., Müller, K.R., 2012.
    Efficient BackProp, in: Montavon, G., Orr, G.B., Müller, K.R. (Eds.), Neural Networks:
    Tricks of the Trade: Second Edition. Springer, Berlin, Heidelberg. Lecture Notes
    in Computer Science, pp. 9–48. URL: [https://doi.org/10.1007/978-3-642-35289-8_3](https://doi.org/10.1007/978-3-642-35289-8_3),
    doi:[10.1007/978-3-642-35289-8_3](https:/doi.org/10.1007/978-3-642-35289-8_3).'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun等（2012）LeCun, Y.A., Bottou, L., Orr, G.B., Müller, K.R., 2012. 高效的BackProp，见：Montavon,
    G., Orr, G.B., Müller, K.R.（编），《神经网络：实用技巧：第二版》。Springer, Berlin, Heidelberg。计算机科学讲义，第9–48页。网址：[https://doi.org/10.1007/978-3-642-35289-8_3](https://doi.org/10.1007/978-3-642-35289-8_3)，doi：[10.1007/978-3-642-35289-8_3](https:/doi.org/10.1007/978-3-642-35289-8_3)。
- en: 'Lei et al. (2020) Lei, Y., Peng, Q., Shen, Y., 2020. Deep learning for algorithmic
    trading: enhancing macd strategy, in: Proceedings of the 2020 6th International
    Conference on Computing and Artificial Intelligence, pp. 51–57.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei等（2020）Lei, Y., Peng, Q., Shen, Y., 2020. 算法交易中的深度学习：增强MACD策略，见：2020年第六届计算与人工智能国际会议论文集，第51–57页。
- en: 'Li et al. (2024) Li, B., Weng, Y., Xia, F., Deng, H., 2024. Towards better
    Chinese-centric neural machine translation for low-resource languages. Computer
    Speech & Language 84, 101566. Publisher: Elsevier.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2024）Li, B., Weng, Y., Xia, F., Deng, H., 2024. 为低资源语言提供更好的中文中心神经机器翻译。计算机语音与语言
    84, 101566。出版社：Elsevier。
- en: Li et al. (2020a) Li, F., He, F., Wang, F., Zhang, D., Xia, Y., Li, X., 2020a.
    A novel simplified convolutional neural network classification algorithm of motor
    imagery eeg signals based on deep learning. Applied Sciences 10, 1605.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2020a）Li, F., He, F., Wang, F., Zhang, D., Xia, Y., Li, X., 2020a. 基于深度学习的运动意象脑电信号的简化卷积神经网络分类算法。应用科学
    10, 1605。
- en: Li et al. (2016) Li, J., Monroe, W., Ritter, A., Galley, M., Gao, J., Jurafsky,
    D., 2016. Deep reinforcement learning for dialogue generation. arXiv preprint
    arXiv:1606.01541 .
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2016）Li, J., Monroe, W., Ritter, A., Galley, M., Gao, J., Jurafsky, D.,
    2016. 用于对话生成的深度强化学习。arXiv预印本 arXiv:1606.01541。
- en: 'Li et al. (2019a) Li, L., Zhu, J., Sun, M.T., 2019a. Deep learning based method
    for pruning deep neural networks, in: 2019 IEEE International Conference on Multimedia
    and Expo Workshops (ICMEW), pp. 312–317. doi:[10.1109/ICMEW.2019.00-68](https:/doi.org/10.1109/ICMEW.2019.00-68).'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2019a）Li, L., Zhu, J., Sun, M.T., 2019a. 基于深度学习的方法用于修剪深度神经网络，见：2019年IEEE国际多媒体与扩展研讨会（ICMEW），第312–317页。doi：[10.1109/ICMEW.2019.00-68](https:/doi.org/10.1109/ICMEW.2019.00-68)。
- en: 'Li et al. (2017) Li, M., Zhu, W., Zhang, M., Sun, Y., Wang, Z., 2017. The novel
    recognition method with optimal wavelet packet and lstm based recurrent neural
    network, in: 2017 IEEE International Conference on Mechatronics and Automation
    (ICMA), pp. 584–589. doi:[10.1109/ICMA.2017.8015882](https:/doi.org/10.1109/ICMA.2017.8015882).'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2017）Li, M., Zhu, W., Zhang, M., Sun, Y., Wang, Z., 2017. 基于最优小波包和LSTM的递归神经网络的新颖识别方法，见：2017年IEEE国际机电一体化与自动化会议（ICMA），第584–589页。doi：[10.1109/ICMA.2017.8015882](https:/doi.org/10.1109/ICMA.2017.8015882)。
- en: 'Li et al. (2023) Li, P., Pei, Y., Li, J., 2023. A comprehensive survey on design
    and application of autoencoder in deep learning. Applied Soft Computing 138, 110176.
    URL: [https://www.sciencedirect.com/science/article/pii/S1568494623001941](https://www.sciencedirect.com/science/article/pii/S1568494623001941),
    doi:[10.1016/j.asoc.2023.110176](https:/doi.org/10.1016/j.asoc.2023.110176).'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2023）Li, P., Pei, Y., Li, J., 2023. 自动编码器在深度学习中的设计与应用综述。应用软计算 138, 110176。网址：[https://www.sciencedirect.com/science/article/pii/S1568494623001941](https://www.sciencedirect.com/science/article/pii/S1568494623001941)，doi：[10.1016/j.asoc.2023.110176](https:/doi.org/10.1016/j.asoc.2023.110176)。
- en: 'Li et al. (2020b) Li, W., Qi, F., Tang, M., Yu, Z., 2020b. Bidirectional LSTM
    with self-attention mechanism and multi-channel features for sentiment classification.
    Neurocomputing 387, 63–77. URL: [https://www.sciencedirect.com/science/article/pii/S0925231220300254](https://www.sciencedirect.com/science/article/pii/S0925231220300254),
    doi:[10.1016/j.neucom.2020.01.006](https:/doi.org/10.1016/j.neucom.2020.01.006).'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li等（2020b）Li, W., Qi, F., Tang, M., Yu, Z., 2020b. 带有自注意力机制和多通道特征的双向LSTM用于情感分类。神经计算
    387, 63–77。网址：[https://www.sciencedirect.com/science/article/pii/S0925231220300254](https://www.sciencedirect.com/science/article/pii/S0925231220300254)，doi：[10.1016/j.neucom.2020.01.006](https:/doi.org/10.1016/j.neucom.2020.01.006)。
- en: 'Li and Shen (2024) Li, X., Shen, Q., 2024. A hybrid framework based on knowledge
    distillation for explainable disease diagnosis. Expert Systems with Applications
    238, 121844. Publisher: Elsevier.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li和Shen（2024）Li, X., Shen, Q., 2024. 基于知识蒸馏的可解释疾病诊断混合框架。专家系统与应用 238, 121844。出版社：Elsevier。
- en: 'Li et al. (2020c) Li, X., Zhang, T., Zhao, X., Yi, Z., 2020c. Guided autoencoder
    for dimensionality reduction of pedestrian features. Applied Intelligence 50,
    4557–4567. URL: [https://doi.org/10.1007/s10489-020-01813-1](https://doi.org/10.1007/s10489-020-01813-1),
    doi:[10.1007/s10489-020-01813-1](https:/doi.org/10.1007/s10489-020-01813-1).'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2020c) Li, X., Zhang, T., Zhao, X., Yi, Z., 2020c. 引导自动编码器用于行人特征的降维。Applied
    Intelligence 50, 4557–4567. URL: [https://doi.org/10.1007/s10489-020-01813-1](https://doi.org/10.1007/s10489-020-01813-1)，doi:[10.1007/s10489-020-01813-1](https:/doi.org/10.1007/s10489-020-01813-1)。'
- en: 'Li et al. (2018) Li, Z., Cai, J., He, S., Zhao, H., 2018. Seq2seq dependency
    parsing, in: Proceedings of the 27th International Conference on Computational
    Linguistics, pp. 3203–3214.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li et al. (2018) Li, Z., Cai, J., He, S., Zhao, H., 2018. Seq2seq 依赖解析，见: 第
    27 届国际计算语言学会议论文集，第 3203–3214 页。'
- en: Li et al. (2019b) Li, Z., Niu, C., Meng, F., Feng, Y., Li, Q., Zhou, J., 2019b.
    Incremental transformer with deliberation decoder for document grounded conversations.
    arXiv preprint arXiv:1907.08854 .
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li et al. (2019b) Li, Z., Niu, C., Meng, F., Feng, Y., Li, Q., Zhou, J., 2019b.
    带有深思解码器的增量变换器用于文档基础对话。arXiv 预印本 arXiv:1907.08854。
- en: 'Lin et al. (2014) Lin, M., Chen, Q., Yan, S., 2014. Network In Network. URL:
    [http://arxiv.org/abs/1312.4400](http://arxiv.org/abs/1312.4400), doi:[10.48550/arXiv.1312.4400](https:/doi.org/10.48550/arXiv.1312.4400).
    arXiv:1312.4400 [cs] version: 3.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin et al. (2014) Lin, M., Chen, Q., Yan, S., 2014. 网络中的网络。URL: [http://arxiv.org/abs/1312.4400](http://arxiv.org/abs/1312.4400)，doi:[10.48550/arXiv.1312.4400](https:/doi.org/10.48550/arXiv.1312.4400)。arXiv:1312.4400
    [cs] 版本: 3。'
- en: 'Lin et al. (2017a) Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan,
    B., Belongie, S., 2017a. Feature pyramid networks for object detection, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, pp. 2117–2125.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin et al. (2017a) Lin, T.Y., Dollár, P., Girshick, R., He, K., Hariharan,
    B., Belongie, S., 2017a. 用于目标检测的特征金字塔网络，见: IEEE 计算机视觉与模式识别会议论文集，第 2117–2125 页。'
- en: 'Lin et al. (2020) Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2020.
    Focal Loss for Dense Object Detection. IEEE Transactions on Pattern Analysis and
    Machine Intelligence 42, 318–327. URL: [https://ieeexplore.ieee.org/document/8417976](https://ieeexplore.ieee.org/document/8417976),
    doi:[10.1109/TPAMI.2018.2858826](https:/doi.org/10.1109/TPAMI.2018.2858826). conference
    Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin et al. (2020) Lin, T.Y., Goyal, P., Girshick, R., He, K., Dollár, P., 2020.
    用于密集目标检测的焦点损失。IEEE 交易模式分析与机器智能 42, 318–327. URL: [https://ieeexplore.ieee.org/document/8417976](https://ieeexplore.ieee.org/document/8417976)，doi:[10.1109/TPAMI.2018.2858826](https:/doi.org/10.1109/TPAMI.2018.2858826)。会议名称:
    IEEE 交易模式分析与机器智能。'
- en: Lin et al. (2017b) Lin, Z., Feng, M., Santos, C.N.d., Yu, M., Xiang, B., Zhou,
    B., Bengio, Y., 2017b. A structured self-attentive sentence embedding. arXiv preprint
    arXiv:1703.03130 .
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin et al. (2017b) Lin, Z., Feng, M., Santos, C.N.d., Yu, M., Xiang, B., Zhou,
    B., Bengio, Y., 2017b. 结构化自注意句子嵌入。arXiv 预印本 arXiv:1703.03130。
- en: 'Liu and Guo (2019) Liu, G., Guo, J., 2019. Bidirectional LSTM with attention
    mechanism and convolutional layer for text classification. Neurocomputing 337,
    325–338. URL: [https://www.sciencedirect.com/science/article/pii/S0925231219301067](https://www.sciencedirect.com/science/article/pii/S0925231219301067),
    doi:[10.1016/j.neucom.2019.01.078](https:/doi.org/10.1016/j.neucom.2019.01.078).'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu and Guo (2019) Liu, G., Guo, J., 2019. 带有注意机制和卷积层的双向 LSTM 用于文本分类。Neurocomputing
    337, 325–338. URL: [https://www.sciencedirect.com/science/article/pii/S0925231219301067](https://www.sciencedirect.com/science/article/pii/S0925231219301067)，doi:[10.1016/j.neucom.2019.01.078](https:/doi.org/10.1016/j.neucom.2019.01.078)。'
- en: 'Liu et al. (2023a) Liu, Q., Dong, Y., Li, X., 2023a. Multi-stage context refinement
    network for semantic segmentation. Neurocomputing 535, 53–63. URL: [https://www.sciencedirect.com/science/article/pii/S0925231223002254](https://www.sciencedirect.com/science/article/pii/S0925231223002254),
    doi:[10.1016/j.neucom.2023.03.006](https:/doi.org/10.1016/j.neucom.2023.03.006).'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2023a) Liu, Q., Dong, Y., Li, X., 2023a. 多阶段上下文精炼网络用于语义分割。Neurocomputing
    535, 53–63. URL: [https://www.sciencedirect.com/science/article/pii/S0925231223002254](https://www.sciencedirect.com/science/article/pii/S0925231223002254)，doi:[10.1016/j.neucom.2023.03.006](https:/doi.org/10.1016/j.neucom.2023.03.006)。'
- en: 'Liu et al. (2019a) Liu, S., Huang, D., Wang, Y., 2019a. Adaptive NMS: Refining
    pedestrian detection in a crowd, in: Proceedings of the IEEE/CVF conference on
    computer vision and pattern recognition, pp. 6459–6468.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu et al. (2019a) Liu, S., Huang, D., Wang, Y., 2019a. 自适应 NMS: 在人群中精炼行人检测，见:
    IEEE/CVF 计算机视觉与模式识别会议论文集，第 6459–6468 页。'
- en: 'Liu et al. (2018) Liu, S., Qi, L., Qin, H., Shi, J., Jia, J., 2018. Path aggregation
    network for instance segmentation, in: Proceedings of the IEEE conference on computer
    vision and pattern recognition, pp. 8759–8768.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2018）Liu, S., Qi, L., Qin, H., Shi, J., Jia, J., 2018. 实例分割的路径聚合网络，见：IEEE
    计算机视觉与模式识别会议论文集，页码 8759–8768。
- en: 'Liu et al. (2016) Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S.,
    Fu, C.Y., Berg, A.C., 2016. SSD: Single Shot MultiBox Detector, in: Leibe, B.,
    Matas, J., Sebe, N., Welling, M. (Eds.), Computer Vision – ECCV 2016, Springer
    International Publishing, Cham. pp. 21–37. doi:[10.1007/978-3-319-46448-0_2](https:/doi.org/10.1007/978-3-319-46448-0_2).'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2016）Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C.Y.,
    Berg, A.C., 2016. SSD：单次检测多框检测器，见：Leibe, B., Matas, J., Sebe, N., Welling, M.（编辑），计算机视觉
    – ECCV 2016，Springer 国际出版，Cham. 页码 21–37。doi：[10.1007/978-3-319-46448-0_2](https:/doi.org/10.1007/978-3-319-46448-0_2)。
- en: 'Liu et al. (2021a) Liu, X., Wang, H., Li, Z., Qin, L., 2021a. Deep learning
    in ecg diagnosis: A review. Knowledge-Based Systems 227, 107187. URL: [https://www.sciencedirect.com/science/article/pii/S0950705121004494](https://www.sciencedirect.com/science/article/pii/S0950705121004494),
    doi:[https://doi.org/10.1016/j.knosys.2021.107187](https:/doi.org/https://doi.org/10.1016/j.knosys.2021.107187).'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2021a）Liu, X., Wang, H., Li, Z., Qin, L., 2021a. 深度学习在心电图诊断中的应用：综述。知识基础系统
    227, 107187。网址：[https://www.sciencedirect.com/science/article/pii/S0950705121004494](https://www.sciencedirect.com/science/article/pii/S0950705121004494)，doi：[https://doi.org/10.1016/j.knosys.2021.107187](https:/doi.org/https://doi.org/10.1016/j.knosys.2021.107187)。
- en: 'Liu et al. (2022) Liu, Y., Chen, Y., Lasang, P., Sun, Q., 2022. Covariance
    Attention for Semantic Segmentation. IEEE Transactions on Pattern Analysis and
    Machine Intelligence 44, 1805–1818. URL: [https://ieeexplore.ieee.org/document/9206128](https://ieeexplore.ieee.org/document/9206128),
    doi:[10.1109/TPAMI.2020.3026069](https:/doi.org/10.1109/TPAMI.2020.3026069). conference
    Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2022）Liu, Y., Chen, Y., Lasang, P., Sun, Q., 2022. 用于语义分割的协方差注意力。IEEE
    模式分析与机器智能学报 44, 1805–1818。网址：[https://ieeexplore.ieee.org/document/9206128](https://ieeexplore.ieee.org/document/9206128)，doi：[10.1109/TPAMI.2020.3026069](https:/doi.org/10.1109/TPAMI.2020.3026069)。会议名称：IEEE
    模式分析与机器智能学报。
- en: 'Liu et al. (2019b) Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D.,
    Levy, O., Lewis, M., Zettlemoyer, L., Stoyanov, V., 2019b. RoBERTa: A robustly
    optimized bert pretraining approach. arXiv preprint arXiv:1907.11692 .'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2019b）Liu, Y., Ott, M., Goyal, N., Du, J., Joshi, M., Chen, D., Levy,
    O., Lewis, M., Zettlemoyer, L., Stoyanov, V., 2019b. RoBERTa：一种稳健优化的 BERT 预训练方法。arXiv
    预印本 arXiv:1907.11692。
- en: 'Liu et al. (2021b) Liu, Z., Wang, L., Wu, W., Qian, C., Lu, T., 2021b. TAM:
    Temporal Adaptive Module for Video Recognition. URL: [http://arxiv.org/abs/2005.06803](http://arxiv.org/abs/2005.06803),
    doi:[10.48550/arXiv.2005.06803](https:/doi.org/10.48550/arXiv.2005.06803). arXiv:2005.06803
    [cs].'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2021b）Liu, Z., Wang, L., Wu, W., Qian, C., Lu, T., 2021b. TAM：用于视频识别的时间自适应模块。网址：[http://arxiv.org/abs/2005.06803](http://arxiv.org/abs/2005.06803)，doi：[10.48550/arXiv.2005.06803](https:/doi.org/10.48550/arXiv.2005.06803)。arXiv:2005.06803
    [cs]。
- en: 'Liu et al. (2023b) Liu, Z., Xu, Z., Jin, J., Shen, Z., Darrell, T., 2023b.
    Dropout reduces underfitting, in: Proceedings of the 40th International Conference
    on Machine Learning, JMLR.org, Honolulu, Hawaii, USA. pp. 22233–22248.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人（2023b）Liu, Z., Xu, Z., Jin, J., Shen, Z., Darrell, T., 2023b. Dropout
    减少欠拟合，见：第 40 届国际机器学习会议论文集，JMLR.org，檀香山，夏威夷，美国。页码 22233–22248。
- en: Llamedo and Martínez (2011) Llamedo, M., Martínez, J.P., 2011. Heartbeat classification
    using feature selection driven by database generalization criteria. IEEE Transactions
    on Biomedical Engineering 58, 616–625. doi:[10.1109/TBME.2010.2068048](https:/doi.org/10.1109/TBME.2010.2068048).
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Llamedo 和 Martínez（2011）Llamedo, M., Martínez, J.P., 2011. 使用特征选择驱动的数据库泛化标准进行心跳分类。IEEE
    生物医学工程学报 58, 616–625。doi：[10.1109/TBME.2010.2068048](https:/doi.org/10.1109/TBME.2010.2068048)。
- en: 'Loh et al. (2023) Loh, C., Han, S., Sudalairaj, S., Dangovski, R., Xu, K.,
    Wenzel, F., Soljacic, M., Srivastava, A., 2023. Multi-Symmetry Ensembles: Improving
    Diversity and Generalization via Opposing Symmetries. arXiv preprint arXiv:2303.02484
    .'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Loh 等人（2023）Loh, C., Han, S., Sudalairaj, S., Dangovski, R., Xu, K., Wenzel,
    F., Soljacic, M., Srivastava, A., 2023. 多重对称集：通过对立对称性提高多样性和泛化能力。arXiv 预印本 arXiv:2303.02484。
- en: 'Long et al. (2015) Long, J., Shelhamer, E., Darrell, T., 2015. Fully convolutional
    networks for semantic segmentation, in: Proceedings of the IEEE conference on
    computer vision and pattern recognition, pp. 3431–3440.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Long 等人（2015）Long, J., Shelhamer, E., Darrell, T., 2015. 用于语义分割的全卷积网络，见：IEEE
    计算机视觉与模式识别会议论文集，页码 3431–3440。
- en: Lu et al. (2020) Lu, X., Li, S., Fujimoto, M., 2020. Automatic speech recognition.
    Speech-to-speech translation , 21–38.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Luca et al. (2022) Luca, A.R., Ursuleanu, T.F., Gheorghe, L., Grigorovici,
    R., Iancu, S., Hlusneac, M., Grigorovici, A., 2022. Impact of quality, type and
    volume of data used by deep learning models in the analysis of medical images.
    Informatics in Medicine Unlocked 29, 100911. URL: [https://www.sciencedirect.com/science/article/pii/S2352914822000612](https://www.sciencedirect.com/science/article/pii/S2352914822000612),
    doi:[10.1016/j.imu.2022.100911](https:/doi.org/10.1016/j.imu.2022.100911).'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luong et al. (2015) Luong, M.T., Pham, H., Manning, C.D., 2015. Effective approaches
    to attention-based neural machine translation. arXiv preprint arXiv:1508.04025
    .
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lupo et al. (2023) Lupo, L., Dinarelli, M., Besacier, L., 2023. Encoding Sentence
    Position in Context-Aware Neural Machine Translation with Concatenation. arXiv
    preprint arXiv:2302.06459 .
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Luwe et al. (2022) Luwe, Y.J., Lee, C.P., Lim, K.M., 2022. Wearable sensor-based
    human activity recognition with hybrid deep learning model, in: Informatics, MDPI.
    p. 56.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2021) Ma, T., Pan, Q., Rong, H., Qian, Y., Tian, Y., Al-Nabhan,
    N., 2021. T-BERTSum: Topic-aware text summarization based on bert. IEEE Transactions
    on Computational Social Systems 9, 879–890. Publisher: IEEE.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2024) Ma, Y., Wang, R., Zong, M., Ji, W., Wang, Y., Ye, B., 2024.
    Convolutional transformer network for fine-grained action recognition. Neurocomputing
    569, 127027. URL: [https://www.sciencedirect.com/science/article/pii/S0925231223011505](https://www.sciencedirect.com/science/article/pii/S0925231223011505),
    doi:[10.1016/j.neucom.2023.127027](https:/doi.org/10.1016/j.neucom.2023.127027).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Maas et al. (2013) Maas, A.L., Hannun, A.Y., Ng, A.Y., others, 2013. Rectifier
    nonlinearities improve neural network acoustic models, in: Proc. icml, Atlanta,
    GA. p. 3. Issue: 1.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathews et al. (2018) Mathews, S.M., Kambhamettu, C., Barner, K.E., 2018. A
    novel application of deep learning for single-lead ecg classification. Computers
    in Biology and Medicine 99, 53–62. URL: [https://www.sciencedirect.com/science/article/pii/S0010482518301264](https://www.sciencedirect.com/science/article/pii/S0010482518301264),
    doi:[https://doi.org/10.1016/j.compbiomed.2018.05.013](https:/doi.org/https://doi.org/10.1016/j.compbiomed.2018.05.013).'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matsugu et al. (2003) Matsugu, M., Mori, K., Mitari, Y., Kaneda, Y., 2003. Subject
    independent facial expression recognition with robust face detection using a convolutional
    neural network. Neural Networks 16, 555–559. doi:[10.1016/S0893-6080(03)00115-1](https:/doi.org/10.1016/S0893-6080(03)00115-1).
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Meetei et al. (2023) Meetei, L.S., Singh, A., Singh, T.D., Bandyopadhyay, S.,
    2023. Do cues in a video help in handling rare words in a machine translation
    system under a low-resource setting? Natural Language Processing Journal 3, 100016.
    Publisher: Elsevier.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Misra (2020) Misra, D., 2020. Mish: A Self Regularized Non-Monotonic Activation
    Function. URL: [http://arxiv.org/abs/1908.08681](http://arxiv.org/abs/1908.08681),
    doi:[10.48550/arXiv.1908.08681](https:/doi.org/10.48550/arXiv.1908.08681). arXiv:1908.08681
    [cs, stat].'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Modir et al. (2023) Modir, A., Shamekhi, S., Ghaderyan, P., 2023. A systematic
    review and methodological analysis of eeg-based biomarkers of alzheimer’s disease.
    Measurement , 113274.
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mohd Noor (2021) Mohd Noor, M.H., 2021. Feature learning using convolutional
    denoising autoencoder for activity recognition. Neural Computing and Applications
    33, 10909–10922. URL: [https://doi.org/10.1007/s00521-020-05638-4](https://doi.org/10.1007/s00521-020-05638-4),
    doi:[10.1007/s00521-020-05638-4](https:/doi.org/10.1007/s00521-020-05638-4).'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mukhamadiyev et al. (2022) Mukhamadiyev, A., Khujayarov, I., Djuraev, O., Cho,
    J., 2022. Automatic speech recognition method based on deep learning approaches
    for uzbek language. Sensors 22, 3683. doi:[https://doi.org/10.3390/s22103683](https:/doi.org/https://doi.org/10.3390/s22103683).
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mumuni and Mumuni (2022) Mumuni, A., Mumuni, F., 2022. Data augmentation: A
    comprehensive survey of modern approaches. Array 16, 100258. URL: [https://www.sciencedirect.com/science/article/pii/S2590005622000911](https://www.sciencedirect.com/science/article/pii/S2590005622000911),
    doi:[10.1016/j.array.2022.100258](https:/doi.org/10.1016/j.array.2022.100258).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Munappy et al. (2022) Munappy, A.R., Bosch, J., Olsson, H.H., Arpteg, A., Brinne,
    B., 2022. Data management for production quality deep learning models: Challenges
    and solutions. Journal of Systems and Software 191, 111359. URL: [https://www.sciencedirect.com/science/article/pii/S0164121222000905](https://www.sciencedirect.com/science/article/pii/S0164121222000905),
    doi:[10.1016/j.jss.2022.111359](https:/doi.org/10.1016/j.jss.2022.111359).'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Murfi et al. (2024) Murfi, H., Syamsyuriani, Gowandi, T., Ardaneswari, G.,
    Nurrohmah, S., 2024. BERT-based combination of convolutional and recurrent neural
    network for indonesian sentiment analysis. Applied Soft Computing 151, 111112.
    URL: [https://www.sciencedirect.com/science/article/pii/S1568494623011304](https://www.sciencedirect.com/science/article/pii/S1568494623011304),
    doi:[10.1016/j.asoc.2023.111112](https:/doi.org/10.1016/j.asoc.2023.111112).'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Murtaza et al. (2023) Murtaza, H., Ahmed, M., Khan, N.F., Murtaza, G., Zafar,
    S., Bano, A., 2023. Synthetic data generation: State of the art in health care
    domain. Computer Science Review 48, 100546. URL: [https://www.sciencedirect.com/science/article/pii/S1574013723000138](https://www.sciencedirect.com/science/article/pii/S1574013723000138),
    doi:[10.1016/j.cosrev.2023.100546](https:/doi.org/10.1016/j.cosrev.2023.100546).'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nafea et al. (2021) Nafea, O., Abdul, W., Muhammad, G., Alsulaiman, M., 2021.
    Sensor-based human activity recognition with spatio-temporal deep learning. Sensors
    21, 2141.
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakamura and Hong (2019) Nakamura, K., Hong, B.W., 2019. Adaptive Weight Decay
    for Deep Neural Networks. IEEE Access 7, 118857–118865. URL: [https://ieeexplore.ieee.org/document/8811458](https://ieeexplore.ieee.org/document/8811458),
    doi:[10.1109/ACCESS.2019.2937139](https:/doi.org/10.1109/ACCESS.2019.2937139).
    conference Name: IEEE Access.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nanni et al. (2023) Nanni, L., Loreggia, A., Barcellona, L., Ghidoni, S., 2023.
    Building Ensemble of Deep Networks: Convolutional Networks and Transformers. IEEE
    Access 11, 124962–124974. URL: [https://ieeexplore.ieee.org/document/10309107](https://ieeexplore.ieee.org/document/10309107),
    doi:[10.1109/ACCESS.2023.3330442](https:/doi.org/10.1109/ACCESS.2023.3330442).
    conference Name: IEEE Access.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nassif et al. (2019) Nassif, A.B., Shahin, I., Attili, I., Azzeh, M., Shaalan,
    K., 2019. Speech recognition using deep neural networks: A systematic review.
    IEEE Access 7, 19143–19165. doi:[10.1109/ACCESS.2019.2896880](https:/doi.org/10.1109/ACCESS.2019.2896880).'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ng and others (2011) Ng, A., others, 2011. Sparse autoencoder. CS294A Lecture
    notes 72, 1–19.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nie et al. (2017) Nie, Y.p., Han, Y., Huang, J.m., Jiao, B., Li, A.p., 2017.
    Attention-based encoder-decoder model for answer selection in question answering.
    Frontiers of Information Technology & Electronic Engineering 18, 535–544. Publisher:
    Springer.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nikou et al. (2019) Nikou, M., Mansourfar, G., Bagherzadeh, J., 2019. Stock
    price prediction using deep learning algorithm and its comparison with machine
    learning algorithms. Intelligent Systems in Accounting, Finance and Management
    26, 164–174.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Noh et al. (2015) Noh, H., Hong, S., Han, B., 2015. Learning deconvolution
    network for semantic segmentation, in: Proceedings of the IEEE international conference
    on computer vision, pp. 1520–1528.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Odena et al. (2017) Odena, A., Olah, C., Shlens, J., 2017. Conditional image
    synthesis with auxiliary classifier gans, in: International conference on machine
    learning, PMLR. pp. 2642–2651.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Oktay et al. (2018) Oktay, O., Schlemper, J., Folgoc, L.L., Lee, M., Heinrich,
    M., Misawa, K., Mori, K., McDonagh, S., Hammerla, N.Y., Kainz, B., Glocker, B.,
    Rueckert, D., 2018. Attention U-Net: Learning Where to Look for the Pancreas.
    URL: [http://arxiv.org/abs/1804.03999](http://arxiv.org/abs/1804.03999), doi:[10.48550/arXiv.1804.03999](https:/doi.org/10.48550/arXiv.1804.03999).
    arXiv:1804.03999 [cs].'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Otter et al. (2021) Otter, D.W., Medina, J.R., Kalita, J.K., 2021. A survey
    of the usages of deep learning for natural language processing. IEEE Transactions
    on Neural Networks and Learning Systems 32, 604–624. doi:[10.1109/TNNLS.2020.2979670](https:/doi.org/10.1109/TNNLS.2020.2979670).
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ozbayoglu et al. (2020) Ozbayoglu, A.M., Gudelek, M.U., Sezer, O.B., 2020.
    Deep learning for financial applications: A survey. Applied soft computing 93,
    106384.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Padmanabhan and Premkumar (2015) Padmanabhan, J., Premkumar, M.J.J., 2015.
    Machine learning in automatic speech recognition: A survey. IETE Technical Review
    32, 240–251. doi:[10.1080/02564602.2015.1010611](https:/doi.org/10.1080/02564602.2015.1010611).'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan et al. (2023) Pan, J., Fang, W., Zhang, Z., Chen, B., Zhang, Z., Wang, S.,
    2023. Multimodal emotion recognition based on facial expressions, speech, and
    eeg. IEEE Open Journal of Engineering in Medicine and Biology , 1–8doi:[10.1109/OJEMB.2023.3240280](https:/doi.org/10.1109/OJEMB.2023.3240280).
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pandey and Seeja (2022) Pandey, P., Seeja, K., 2022. Subject independent emotion
    recognition from eeg using vmd and deep learning. Journal of King Saud University
    - Computer and Information Sciences 34, 1730–1738. URL: [https://www.sciencedirect.com/science/article/pii/S1319157819309991](https://www.sciencedirect.com/science/article/pii/S1319157819309991),
    doi:[https://doi.org/10.1016/j.jksuci.2019.11.003](https:/doi.org/https://doi.org/10.1016/j.jksuci.2019.11.003).'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park and Kwak (2017) Park, S., Kwak, N., 2017. Analysis on the Dropout Effect
    in Convolutional Neural Networks, in: Lai, S.H., Lepetit, V., Nishino, K., Sato,
    Y. (Eds.), Computer Vision – ACCV 2016, Springer International Publishing, Cham.
    pp. 189–204. doi:[10.1007/978-3-319-54184-6_12](https:/doi.org/10.1007/978-3-319-54184-6_12).'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2023) Park, W., Park, I., Kim, S., Ryu, J., 2023. Robust Asymmetric
    Loss for Multi-Label Long-Tailed Learning, pp. 2711–2720. URL: [https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/html/Park_Robust_Asymmetric_Loss_for_Multi-Label_Long-Tailed_Learning_ICCVW_2023_paper.html](https://openaccess.thecvf.com/content/ICCV2023W/CVAMD/html/Park_Robust_Asymmetric_Loss_for_Multi-Label_Long-Tailed_Learning_ICCVW_2023_paper.html).'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Peng et al. (2023) Peng, Z., Guo, Z., Huang, W., Wang, Y., Xie, L., Jiao, J.,
    Tian, Q., Ye, Q., 2023. Conformer: Local Features Coupling Global Representations
    for Recognition and Detection. IEEE Transactions on Pattern Analysis and Machine
    Intelligence 45, 9454–9468. URL: [https://ieeexplore.ieee.org/document/10040235](https://ieeexplore.ieee.org/document/10040235),
    doi:[10.1109/TPAMI.2023.3243048](https:/doi.org/10.1109/TPAMI.2023.3243048). conference
    Name: IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pierson and Gashler (2017) Pierson, H.A., Gashler, M.S., 2017. Deep learning
    in robotics: a review of recent research. Advanced Robotics 31, 821–835. URL:
    [https://doi.org/10.1080/01691864.2017.1365009](https://doi.org/10.1080/01691864.2017.1365009),
    doi:[10.1080/01691864.2017.1365009](https:/doi.org/10.1080/01691864.2017.1365009).
    publisher: Taylor & Francis _eprint: https://doi.org/10.1080/01691864.2017.1365009.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pouyanfar et al. (2018) Pouyanfar, S., Sadiq, S., Yan, Y., Tian, H., Tao, Y.,
    Reyes, M.P., Shyu, M.L., Chen, S.C., Iyengar, S.S., 2018. A survey on deep learning:
    Algorithms, techniques, and applications. ACM Computing Surveys (CSUR) 51, 1–36.
    Publisher: ACM New York, NY, USA.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prabhakararao and Dandapat (2020) Prabhakararao, E., Dandapat, S., 2020. Attentive
    rnn-based network to fuse 12-lead ecg and clinical features for improved myocardial
    infarction diagnosis. IEEE Signal Processing Letters 27, 2029–2033.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prabhavalkar et al. (2017) Prabhavalkar, R., Rao, K., Sainath, T.N., Li, B.,
    Johnson, L., Jaitly, N., 2017. A comparison of sequence-to-sequence models for
    speech recognition., in: Interspeech, pp. 939–943.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prechelt (2012) Prechelt, L., 2012. Early Stopping — But When?, in: Montavon,
    G., Orr, G.B., Müller, K.R. (Eds.), Neural Networks: Tricks of the Trade: Second
    Edition. Springer, Berlin, Heidelberg. Lecture Notes in Computer Science, pp.
    53–67. URL: [https://doi.org/10.1007/978-3-642-35289-8_5](https://doi.org/10.1007/978-3-642-35289-8_5),
    doi:[10.1007/978-3-642-35289-8_5](https:/doi.org/10.1007/978-3-642-35289-8_5).'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qian (1999) Qian, N., 1999. On the momentum term in gradient descent learning
    algorithms. Neural Networks 12, 145–151. URL: [https://www.sciencedirect.com/science/article/pii/S0893608098001166](https://www.sciencedirect.com/science/article/pii/S0893608098001166),
    doi:[10.1016/S0893-6080(98)00116-6](https:/doi.org/10.1016/S0893-6080(98)00116-6).'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2015) Radford, A., Metz, L., Chintala, S., 2015. Unsupervised
    representation learning with deep convolutional generative adversarial networks.
    arXiv preprint arXiv:1511.06434 .
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Raffel et al. (2017) Raffel, C., Luong, M.T., Liu, P.J., Weiss, R.J., Eck,
    D., 2017. Online and linear-time attention by enforcing monotonic alignments,
    in: International conference on machine learning, PMLR. pp. 2837–2846.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ragab et al. (2020) Ragab, M.G., Abdulkadir, S.J., Aziz, N., 2020. Random search
    one dimensional cnn for human activity recognition, in: 2020 International Conference
    on Computational Intelligence (ICCI), IEEE. pp. 86–91.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rai and Chatterjee (2022) Rai, H.M., Chatterjee, K., 2022. Hybrid cnn-lstm deep
    learning model and ensemble technique for automatic detection of myocardial infarction
    using big ecg data. Applied Intelligence 52, 5366–5384.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon et al. (2016) Redmon, J., Divvala, S., Girshick, R., Farhadi, A., 2016.
    You Only Look Once: Unified, Real-Time Object Detection, pp. 779–788. URL: [https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Redmon_You_Only_Look_CVPR_2016_paper.html).'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon and Farhadi (2018) Redmon, J., Farhadi, A., 2018. Yolov3: An incremental
    improvement. arXiv preprint arXiv:1804.02767 .'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster R-CNN:
    Towards Real-Time Object Detection with Region Proposal Networks, in: Advances
    in Neural Information Processing Systems, Curran Associates, Inc. URL: [https://proceedings.neurips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html](https://proceedings.neurips.cc/paper_files/paper/2015/hash/14bfa6bb14875e45bba028a21ed38046-Abstract.html).'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rifai et al. (2011) Rifai, S., Mesnil, G., Vincent, P., Muller, X., Bengio,
    Y., Dauphin, Y., Glorot, X., 2011. Higher Order Contractive Auto-Encoder, in:
    Gunopulos, D., Hofmann, T., Malerba, D., Vazirgiannis, M. (Eds.), Machine Learning
    and Knowledge Discovery in Databases, Springer, Berlin, Heidelberg. pp. 645–660.
    doi:[10.1007/978-3-642-23783-6_41](https:/doi.org/10.1007/978-3-642-23783-6_41).'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rippeth et al. (2023) Rippeth, E., Carpuat, M., Duh, K., Post, M., 2023. Improving
    Word Sense Disambiguation in Neural Machine Translation with Salient Document
    Context. arXiv preprint arXiv:2311.15507 .
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rodrawangpai and Daungjaiboon (2022) Rodrawangpai, B., Daungjaiboon, W., 2022.
    Improving text classification with transformers and layer normalization. Machine
    Learning with Applications 10, 100403. URL: [https://www.sciencedirect.com/science/article/pii/S2666827022000792](https://www.sciencedirect.com/science/article/pii/S2666827022000792),
    doi:[10.1016/j.mlwa.2022.100403](https:/doi.org/10.1016/j.mlwa.2022.100403).'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Romero et al. (2017) Romero, J., Olson, J.P., Aspuru-Guzik, A., 2017. Quantum
    autoencoders for efficient compression of quantum data. Quantum Science and Technology
    2, 045001. URL: [https://dx.doi.org/10.1088/2058-9565/aa8072](https://dx.doi.org/10.1088/2058-9565/aa8072),
    doi:[10.1088/2058-9565/aa8072](https:/doi.org/10.1088/2058-9565/aa8072). publisher:
    IOP Publishing.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sak et al. (2017) Sak, H., Shannon, M., Rao, K., Beaufays, F., 2017. Recurrent
    neural aligner: An encoder-decoder neural network model for sequence to sequence
    mapping., in: Interspeech, pp. 1298–1302.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sánchez-Hevia et al. (2022) Sánchez-Hevia, H.A., Gil-Pita, R., Utrilla-Manso,
    M., Rosa-Zurera, M., 2022. Age group classification and gender recognition from
    speech with temporal convolutional neural networks. Multimedia Tools and Applications
    81, 3535–3552.
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sarker (2021) Sarker, I.H., 2021. Deep learning: a comprehensive overview on
    techniques, taxonomy, applications and research directions. SN Computer Science
    2, 420. Publisher: Springer.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schaaf et al. (2021) Schaaf, N., de Mitri, O., Kim, H.B., Windberger, A., Huber,
    M.F., 2021. Towards measuring bias in image classification, in: Artificial Neural
    Networks and Machine Learning–ICANN 2021: 30th International Conference on Artificial
    Neural Networks, Bratislava, Slovakia, September 14–17, 2021, Proceedings, Part
    III 30, Springer. pp. 433–445.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schirrmeister et al. (2017) Schirrmeister, R.T., Springenberg, J.T., Fiederer,
    L.D.J., Glasstetter, M., Eggensperger, K., Tangermann, M., Hutter, F., Burgard,
    W., Ball, T., 2017. Deep learning with convolutional neural networks for eeg decoding
    and visualization. Human Brain Mapping 38, 5391–5420. URL: [https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23730](https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23730),
    doi:[https://doi.org/10.1002/hbm.23730](https:/doi.org/https://doi.org/10.1002/hbm.23730).'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shamshirband et al. (2021) Shamshirband, S., Fathi, M., Dehzangi, A., Chronopoulos,
    A.T., Alinejad-Rokny, H., 2021. A review on deep learning approaches in healthcare
    systems: Taxonomies, challenges, and open issues. Journal of Biomedical Informatics
    113, 103627. URL: [https://www.sciencedirect.com/science/article/pii/S1532046420302550](https://www.sciencedirect.com/science/article/pii/S1532046420302550),
    doi:[10.1016/j.jbi.2020.103627](https:/doi.org/10.1016/j.jbi.2020.103627).'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma et al. (2021) Sharma, M., Tiwari, J., Patel, V., Acharya, U.R., 2021.
    Automated identification of sleep disorder types using triplet half-band filter
    and ensemble machine learning techniques with eeg signals. Electronics 10, 1531.
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shen et al. (2021) Shen, F., Zhao, X., Kou, G., Alsaadi, F.E., 2021. A new deep
    learning ensemble credit risk evaluation model with an improved synthetic minority
    oversampling technique. Applied Soft Computing 98, 106852.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shen et al. (2022) Shen, Z., Li, G., Fang, J., Zhong, H., Wang, J., Sun, Y.,
    Shen, X., 2022. Aberrated multidimensional eeg characteristics in patients with
    generalized anxiety disorder: A machine-learning based analysis framework. Sensors
    22, 5420.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shewalkar et al. (2019) Shewalkar, A., Nyavanandi, D., Ludwig, S.A., 2019.
    Performance evaluation of deep neural networks applied to speech recognition:
    Rnn, lstm and gru. Journal of Artificial Intelligence and Soft Computing Research
    9, 235–245.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2023) Shi, L.F., Liu, Z.Y., Zhou, K.J., Shi, Y., Jing, X., 2023.
    Novel deep learning network for gait recognition using multimodal inertial sensors.
    Sensors 23, 849.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2015) Shi, X., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.k., Woo,
    W.c., 2015. Convolutional LSTM Network: A Machine Learning Approach for Precipitation
    Nowcasting. URL: [http://arxiv.org/abs/1506.04214](http://arxiv.org/abs/1506.04214),
    doi:[10.48550/arXiv.1506.04214](https:/doi.org/10.48550/arXiv.1506.04214). arXiv:1506.04214
    [cs] version: 2.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuvo et al. (2020) Shuvo, M.M.H., Ahmed, N., Nouduri, K., Palaniappan, K.,
    2020. A hybrid approach for human activity recognition with support vector machine
    and 1d convolutional neural network, in: 2020 IEEE Applied Imagery Pattern Recognition
    Workshop (AIPR), IEEE. pp. 1–5.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simard et al. (2003) Simard, P., Steinkraus, D., Platt, J., 2003. Best practices
    for convolutional neural networks applied to visual document analysis, in: Seventh
    International Conference on Document Analysis and Recognition, 2003\. Proceedings.,
    pp. 958–963. URL: [https://ieeexplore.ieee.org/document/1227801](https://ieeexplore.ieee.org/document/1227801),
    doi:[10.1109/ICDAR.2003.1227801](https:/doi.org/10.1109/ICDAR.2003.1227801).'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simonyan and Zisserman (2015) Simonyan, K., Zisserman, A., 2015. Very Deep
    Convolutional Networks for Large-Scale Image Recognition. URL: [http://arxiv.org/abs/1409.1556](http://arxiv.org/abs/1409.1556),
    doi:[10.48550/arXiv.1409.1556](https:/doi.org/10.48550/arXiv.1409.1556). arXiv:1409.1556
    [cs] version: 6.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2021) Singh, G., Sharma, S., Kumar, V., Kaur, M., Baz, M., Masud,
    M., et al., 2021. Spoken language identification using deep learning. Computational
    Intelligence and Neuroscience 2021.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh and Srivastava (2017) Singh, R., Srivastava, S., 2017. Stock prediction
    using deep learning. Multimedia Tools and Applications 76, 18569–18584.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2018) Singh, S., Pandey, S.K., Pawar, U., Janghel, R.R., 2018.
    Classification of ecg arrhythmia using recurrent neural networks. Procedia computer
    science 132, 1290–1297.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Soori et al. (2023) Soori, M., Arezoo, B., Dastres, R., 2023. Artificial intelligence,
    machine learning and deep learning in advanced robotics, a review. Cognitive Robotics
    .
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sowmya and Jose (2022) Sowmya, S., Jose, D., 2022. Contemplate on ecg signals
    and classification of arrhythmia signals using cnn-lstm deep learning model. Measurement:
    Sensors 24, 100558.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. (2014) Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever,
    I., Salakhutdinov, R., 2014. Dropout: A Simple Way to Prevent Neural Networks
    from Overfitting. Journal of Machine Learning Research 15, 1929–1958. URL: [http://jmlr.org/papers/v15/srivastava14a.html](http://jmlr.org/papers/v15/srivastava14a.html).'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava and Pandey (2022) Srivastava, R., Pandey, D., 2022. Speech recognition
    using hmm and soft computing. Materials Today: Proceedings 51, 1878–1883. doi:[https://doi.org/10.1016/j.matpr.2021.10.097](https:/doi.org/https://doi.org/10.1016/j.matpr.2021.10.097).'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. (2015) Srivastava, R.K., Greff, K., Schmidhuber, J., 2015.
    Highway Networks. URL: [http://arxiv.org/abs/1505.00387](http://arxiv.org/abs/1505.00387),
    doi:[10.48550/arXiv.1505.00387](https:/doi.org/10.48550/arXiv.1505.00387). arXiv:1505.00387
    [cs].'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stahlberg (2020) Stahlberg, F., 2020. Neural machine translation: A review.
    Journal of Artificial Intelligence Research 69, 343–418.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stanton et al. (2021) Stanton, S., Izmailov, P., Kirichenko, P., Alemi, A.A.,
    Wilson, A.G., 2021. Does knowledge distillation really work?, in: Ranzato, M.,
    Beygelzimer, A., Dauphin, Y., Liang, P., Vaughan, J.W. (Eds.), Advances in Neural
    Information Processing Systems, Curran Associates, Inc.. pp. 6906–6919. URL: [https://proceedings.neurips.cc/paper_files/paper/2021/file/376c6b9ff3bedbbea56751a84fffc10c-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2021/file/376c6b9ff3bedbbea56751a84fffc10c-Paper.pdf).'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Strudel et al. (2021) Strudel, R., Garcia, R., Laptev, I., Schmid, C., 2021.
    Segmenter: Transformer for semantic segmentation, in: Proceedings of the IEEE/CVF
    international conference on computer vision, pp. 7262–7272.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2019) Sun, J., Zhou, Y., Zhang, B., 2019. ResFPA-GAN: Text-to-image
    synthesis with generative adversarial network based on residual block feature
    pyramid attention, in: 2019 IEEE International Conference on Advanced Robotics
    and its Social Impacts (ARSO), IEEE. pp. 317–322.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2020) Sun, S., Wang, S., Wei, Y., 2020. A new ensemble deep learning
    approach for exchange rates forecasting and trading. Advanced Engineering Informatics
    46, 101160. URL: [https://www.sciencedirect.com/science/article/pii/S1474034620301312](https://www.sciencedirect.com/science/article/pii/S1474034620301312),
    doi:[https://doi.org/10.1016/j.aei.2020.101160](https:/doi.org/https://doi.org/10.1016/j.aei.2020.101160).'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sutskever et al. (2014) Sutskever, I., Vinyals, O., Le, Q.V., 2014. Sequence
    to sequence learning with neural networks. Advances in neural information processing
    systems 27.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. (2014) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
    Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2014. Going Deeper with
    Convolutions. URL: [http://arxiv.org/abs/1409.4842](http://arxiv.org/abs/1409.4842),
    doi:[10.48550/arXiv.1409.4842](https:/doi.org/10.48550/arXiv.1409.4842). arXiv:1409.4842
    [cs] version: 1.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2013) Szegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan,
    D., Goodfellow, I., Fergus, R., 2013. Intriguing properties of neural networks.
    arXiv preprint arXiv:1312.6199 .
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szűcs and Huszti (2019) Szűcs, G., Huszti, D., 2019. Seq2seq deep learning
    method for summary generation by lstm with two-way encoder and beam search decoder,
    in: 2019 IEEE 17th International Symposium on Intelligent Systems and Informatics
    (SISY), pp. 221–226. doi:[10.1109/SISY47553.2019.9111502](https:/doi.org/10.1109/SISY47553.2019.9111502).'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tabacof et al. (2016) Tabacof, P., Tavares, J., Valle, E., 2016. Adversarial
    images for variational autoencoders. arXiv preprint arXiv:1612.00155 .
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Talaei Khoei et al. (2023) Talaei Khoei, T., Ould Slimane, H., Kaabouch, N.,
    2023. Deep learning: Systematic review, models, challenges, and research directions.
    Neural Computing and Applications 35, 23103–23124. Publisher: Springer.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Le (2019) Tan, M., Le, Q., 2019. EfficientNet: Rethinking model scaling
    for convolutional neural networks, in: International conference on machine learning,
    PMLR. pp. 6105–6114.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan et al. (2020a) Tan, M., Pang, R., Le, Q.V., 2020a. Efficientdet: Scalable
    and efficient object detection, in: Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition (CVPR).'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan et al. (2020b) Tan, M., Pang, R., Le, Q.V., 2020b. Efficientdet: Scalable
    and efficient object detection, in: Proceedings of the IEEE/CVF conference on
    computer vision and pattern recognition, pp. 10781–10790.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tao et al. (2022) Tao, M., Tang, H., Wu, F., Jing, X.Y., Bao, B.K., Xu, C.,
    2022. DF-GAN: A simple and effective baseline for text-to-image synthesis, in:
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    pp. 16515–16525.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Termritthikun et al. (2023) Termritthikun, C., Umer, A., Suwanwimolkul, S.,
    Xia, F., Lee, I., 2023. Explainable knowledge distillation for on-device chest
    x-ray classification. IEEE/ACM Transactions on Computational Biology and Bioinformatics
    Publisher: IEEE.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tibrewal et al. (2022) Tibrewal, N., Leeuwis, N., Alimardani, M., 2022. Classification
    of motor imagery eeg using deep learning increases performance in inefficient
    bci users. Plos one 17, e0268880.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tibshirani (1996) Tibshirani, R., 1996. Regression Shrinkage and Selection
    via the Lasso. Journal of the Royal Statistical Society. Series B (Methodological)
    58, 267–288. URL: [https://www.jstor.org/stable/2346178](https://www.jstor.org/stable/2346178).
    publisher: [Royal Statistical Society, Wiley].'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tirumala and Shahamiri (2016) Tirumala, S.S., Shahamiri, S.R., 2016. A review
    on deep learning approaches in speaker identification, in: Proceedings of the
    8th International Conference on Signal Processing Systems, Association for Computing
    Machinery, New York, NY, USA. p. 142–147. URL: [https://doi.org/10.1145/3015166.3015210](https://doi.org/10.1145/3015166.3015210),
    doi:[10.1145/3015166.3015210](https:/doi.org/10.1145/3015166.3015210).'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tjoa et al. (2023) Tjoa, E., Khok, H.J., Chouhan, T., Guan, C., 2023. Enhancing
    the confidence of deep learning classifiers via interpretable saliency maps. Neurocomputing
    562, 126825. Publisher: Elsevier.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tonekaboni et al. (2019) Tonekaboni, S., Joshi, S., McCradden, M.D., Goldenberg,
    A., 2019. What clinicians want: contextualizing explainable machine learning for
    clinical end use, in: Machine learning for healthcare conference, PMLR. pp. 359–380.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tsao et al. (2023) Tsao, C.W., Aday, A.W., Almarzooq, Z.I., Anderson, C.A.,
    Arora, P., Avery, C.L., Baker-Smith, C.M., Beaton, A.Z., Boehme, A.K., Buxton,
    A.E., et al., 2023. Heart disease and stroke statistics—2023 update: a report
    from the american heart association. Circulation 147, e93–e621.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tu et al. (2022) Tu, Z., Talebi, H., Zhang, H., Yang, F., Milanfar, P., Bovik,
    A., Li, Y., 2022. MaxViT: Multi-axis Vision Transformer, in: Avidan, S., Brostow,
    G., Cissé, M., Farinella, G.M., Hassner, T. (Eds.), Computer Vision – ECCV 2022,
    Springer Nature Switzerland, Cham. pp. 459–479. doi:[10.1007/978-3-031-20053-3_27](https:/doi.org/10.1007/978-3-031-20053-3_27).'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaquerizo-Villar et al. (2023) Vaquerizo-Villar, F., Gutiérrez-Tobal, G.C.,
    Calvo, E., Álvarez, D., Kheirandish-Gozal, L., Del Campo, F., Gozal, D., Hornero,
    R., 2023. An explainable deep-learning model to stage sleep states in children
    and propose novel eeg-related patterns in sleep apnea. Computers in Biology and
    Medicine 165, 107419.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaswani et al. (2023) Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J.,
    Jones, L., Gomez, A.N., Kaiser, L., Polosukhin, I., 2023. Attention Is All You
    Need. URL: [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762),
    doi:[10.48550/arXiv.1706.03762](https:/doi.org/10.48550/arXiv.1706.03762). arXiv:1706.03762
    [cs].'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vincent et al. (2008) Vincent, P., Larochelle, H., Bengio, Y., Manzagol, P.A.,
    2008. Extracting and composing robust features with denoising autoencoders, in:
    Proceedings of the 25th international conference on Machine learning, Association
    for Computing Machinery, New York, NY, USA. pp. 1096–1103. URL: [https://doi.org/10.1145/1390156.1390294](https://doi.org/10.1145/1390156.1390294),
    doi:[10.1145/1390156.1390294](https:/doi.org/10.1145/1390156.1390294).'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2018a) Wang, G., Li, C., Wang, W., Zhang, Y., Shen, D., Zhang,
    X., Henao, R., Carin, L., 2018a. Joint embedding of words and labels for text
    classification. arXiv preprint arXiv:1805.04174 .
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2023a) Wang, G., Ma, J., Wang, Y., Tao, T., Ren, G., Zhu, H.,
    2023a. Sudf-rs: A new foreign exchange rate prediction method considering the
    complementarity of supervised and unsupervised deep representation features. Expert
    Systems with Applications 214, 119152. URL: [https://www.sciencedirect.com/science/article/pii/S0957417422021704](https://www.sciencedirect.com/science/article/pii/S0957417422021704),
    doi:[https://doi.org/10.1016/j.eswa.2022.119152](https:/doi.org/https://doi.org/10.1016/j.eswa.2022.119152).'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2018b) Wang, J., Ma, Y., Zhang, L., Gao, R.X., Wu, D., 2018b.
    Deep learning for smart manufacturing: Methods and applications. Journal of Manufacturing
    Systems 48, 144–156. URL: [https://www.sciencedirect.com/science/article/pii/S0278612518300037](https://www.sciencedirect.com/science/article/pii/S0278612518300037),
    doi:[10.1016/j.jmsy.2018.01.003](https:/doi.org/10.1016/j.jmsy.2018.01.003).'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021) Wang, J., Qiao, X., Liu, C., Wang, X., Liu, Y., Yao, L.,
    Zhang, H., 2021. Automated ecg classification using a non-local convolutional
    block attention module. Computer Methods and Programs in Biomedicine 203, 106006.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023b) Wang, M., Rahardja, S., Fränti, P., Rahardja, S., 2023b.
    Single-lead ecg recordings modeling for end-to-end recognition of atrial fibrillation
    with dual-path rnn. Biomedical Signal Processing and Control 79, 104067.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2022) Wang, Q., Ma, Y., Zhao, K., Tian, Y., 2022. A Comprehensive
    Survey of Loss Functions in Machine Learning. Annals of Data Science 9, 187–212.
    URL: [https://doi.org/10.1007/s40745-020-00253-5](https://doi.org/10.1007/s40745-020-00253-5),
    doi:[10.1007/s40745-020-00253-5](https:/doi.org/10.1007/s40745-020-00253-5).'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020a) Wang, Q., Wu, B., Zhu, P., Li, P., Zuo, W., Hu, Q., 2020a.
    ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks. URL:
    [http://arxiv.org/abs/1910.03151](http://arxiv.org/abs/1910.03151), doi:[10.48550/arXiv.1910.03151](https:/doi.org/10.48550/arXiv.1910.03151).
    arXiv:1910.03151 [cs].'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019) Wang, R., Li, Z., Cao, J., Chen, T., Wang, L., 2019. Convolutional
    Recurrent Neural Networks for Text Classification, in: 2019 International Joint
    Conference on Neural Networks (IJCNN), pp. 1–6. URL: [https://ieeexplore.ieee.org/document/8852406](https://ieeexplore.ieee.org/document/8852406),
    doi:[10.1109/IJCNN.2019.8852406](https:/doi.org/10.1109/IJCNN.2019.8852406). iSSN:
    2161-4407.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023c) Wang, S., Qu, J., Zhang, Y., Zhang, Y., 2023c. Multimodal
    emotion recognition from eeg signals and facial expressions. IEEE Access 11, 33061–33068.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020b) Wang, W., Li, W., Zhang, N., Liu, K., 2020b. Portfolio formation
    with preselection using deep learning from long-term financial data. Expert Systems
    with Applications 143, 113042.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weiser (1991) Weiser, M., 1991. The computer for the 21 st century. Scientific
    american 265, 94–105.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weng (2019) Weng, L., 2019. From GAN to WGAN. URL: [http://arxiv.org/abs/1904.08994](http://arxiv.org/abs/1904.08994),
    doi:[10.48550/arXiv.1904.08994](https:/doi.org/10.48550/arXiv.1904.08994). arXiv:1904.08994
    [cs, stat].'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Widrow et al. (1994) Widrow, B., Rumelhart, D.E., Lehr, M.A., 1994. Neural
    networks: applications in industry, business and science. Communications of the
    ACM 37, 93–105. URL: [https://dl.acm.org/doi/10.1145/175247.175257](https://dl.acm.org/doi/10.1145/175247.175257),
    doi:[10.1145/175247.175257](https:/doi.org/10.1145/175247.175257).'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wortsman et al. (2022) Wortsman, M., Ilharco, G., Gadre, S.Y., Roelofs, R.,
    Gontijo-Lopes, R., Morcos, A.S., Namkoong, H., Farhadi, A., Carmon, Y., Kornblith,
    S., others, 2022. Model soups: averaging weights of multiple fine-tuned models
    improves accuracy without increasing inference time, in: International Conference
    on Machine Learning, PMLR. pp. 23965–23998.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2021) Wu, H., Xiao, B., Codella, N., Liu, M., Dai, X., Yuan, L.,
    Zhang, L., 2021. CvT: Introducing Convolutions to Vision Transformers, in: 2021
    IEEE/CVF International Conference on Computer Vision (ICCV), pp. 22–31. URL: [https://ieeexplore.ieee.org/document/9710031?denied=](https://ieeexplore.ieee.org/document/9710031?denied=),
    doi:[10.1109/ICCV48922.2021.00009](https:/doi.org/10.1109/ICCV48922.2021.00009).
    iSSN: 2380-7504.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2020) Wu, J., Mu, T., Thiyagalingam, J., Goulermas, J.Y., 2020.
    Building interactive sentence-aware representation based on generative language
    model for community question answering. Neurocomputing 389, 93–107. Publisher:
    Elsevier.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2022) Wu, X., Xia, Y., Zhu, J., Wu, L., Xie, S., Qin, T., 2022.
    A study of BERT for context-aware neural machine translation. Machine Learning
    111, 917–935. Publisher: Springer.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2016) Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey,
    W., Krikun, M., Cao, Y., Gao, Q., Macherey, K., others, 2016. Google’s neural
    machine translation system: Bridging the gap between human and machine translation.
    arXiv preprint arXiv:1609.08144 .'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xia et al. (2023) Xia, W., Zhang, R., Zhang, X., Usman, M., 2023. A novel method
    for diagnosing alzheimer’s disease using deep pyramid cnn based on eeg signals.
    Heliyon 9.
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiao et al. (2021) Xiao, T., Singh, M., Mintun, E., Darrell, T., Dollár, P.,
    Girshick, R., 2021. Early convolutions help transformers see better. Advances
    in neural information processing systems 34, 30392–30400.
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. (2022) Xie, Q., Bishop, J.A., Tiwari, P., Ananiadou, S., 2022. Pre-trained
    language models with domain knowledge for biomedical extractive summarization.
    Knowledge-Based Systems 252, 109460. Publisher: Elsevier.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. (2017) Xie, S., Girshick, R., Dollár, P., Tu, Z., He, K., 2017.
    Aggregated Residual Transformations for Deep Neural Networks. URL: [http://arxiv.org/abs/1611.05431](http://arxiv.org/abs/1611.05431),
    doi:[10.48550/arXiv.1611.05431](https:/doi.org/10.48550/arXiv.1611.05431). arXiv:1611.05431
    [cs].'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiong et al. (2022) Xiong, W., Xiong, Z., Cui, Y., 2022. An Explainable Attention
    Network for Fine-Grained Ship Classification Using Remote-Sensing Images. IEEE
    Transactions on Geoscience and Remote Sensing 60, 1–14. URL: [https://ieeexplore.ieee.org/abstract/document/9741720](https://ieeexplore.ieee.org/abstract/document/9741720),
    doi:[10.1109/TGRS.2022.3162195](https:/doi.org/10.1109/TGRS.2022.3162195). conference
    Name: IEEE Transactions on Geoscience and Remote Sensing.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2018) Xu, T., Zhang, P., Huang, Q., Zhang, H., Gan, Z., Huang, X.,
    He, X., 2018. AttnGAN: Fine-grained text to image generation with attentional
    generative adversarial networks, in: Proceedings of the IEEE conference on computer
    vision and pattern recognition, pp. 1316–1324.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yan et al. (2023) Yan, Y., Liu, F., Zhuang, X., Ju, J., 2023. An R-Transformer_bilstm
    Model Based on Attention for Multi-label Text Classification. Neural Processing
    Letters 55, 1293–1316. URL: [https://doi.org/10.1007/s11063-022-10938-y](https://doi.org/10.1007/s11063-022-10938-y),
    doi:[10.1007/s11063-022-10938-y](https:/doi.org/10.1007/s11063-022-10938-y).'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2024) Yang, B., Xiang, X., Kong, W., Zhang, J., Peng, Y., 2024.
    DMF-GAN: Deep Multimodal Fusion Generative Adversarial Networks for Text-to-Image
    Synthesis. IEEE Transactions on Multimedia , 1–13URL: [https://ieeexplore.ieee.org/document/10413630](https://ieeexplore.ieee.org/document/10413630),
    doi:[10.1109/TMM.2024.3358086](https:/doi.org/10.1109/TMM.2024.3358086). conference
    Name: IEEE Transactions on Multimedia.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Yang, J., Shen, X., Xing, J., Tian, X., Li, H., Deng, B.,
    Huang, J., Hua, X.s., 2019. Quantization networks, in: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition (CVPR).'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2023) Yang, J., Soltan, A.A., Eyre, D.W., Clifton, D.A., 2023.
    Algorithmic fairness and bias mitigation for clinical machine learning with deep
    reinforcement learning. Nature Machine Intelligence 5, 884–894. Publisher: Nature
    Publishing Group UK London.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ye and Yang (2021) Ye, F., Yang, J., 2021. A deep neural network model for
    speaker identification. Applied Sciences 11. URL: [https://www.mdpi.com/2076-3417/11/8/3603](https://www.mdpi.com/2076-3417/11/8/3603),
    doi:[10.3390/app11083603](https:/doi.org/10.3390/app11083603).'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yin et al. (2015) Yin, J., Jiang, X., Lu, Z., Shang, L., Li, H., Li, X., 2015.
    Neural generative question answering. arXiv preprint arXiv:1512.01337 .
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2008) Yu, B., Xu, Z.b., Li, C.h., 2008. Latent semantic analysis
    for text categorization using neural network. Knowledge-Based Systems 21, 900–904.
    URL: [https://www.sciencedirect.com/science/article/pii/S0950705108000993](https://www.sciencedirect.com/science/article/pii/S0950705108000993),
    doi:[10.1016/j.knosys.2008.03.045](https:/doi.org/10.1016/j.knosys.2008.03.045).'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zagoruyko and Komodakis (2017) Zagoruyko, S., Komodakis, N., 2017. Wide Residual
    Networks. URL: [http://arxiv.org/abs/1605.07146](http://arxiv.org/abs/1605.07146),
    doi:[10.48550/arXiv.1605.07146](https:/doi.org/10.48550/arXiv.1605.07146). arXiv:1605.07146
    [cs] version: 4.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler and Fergus (2013) Zeiler, M.D., Fergus, R., 2013. Visualizing and Understanding
    Convolutional Networks. URL: [http://arxiv.org/abs/1311.2901](http://arxiv.org/abs/1311.2901),
    doi:[10.48550/arXiv.1311.2901](https:/doi.org/10.48550/arXiv.1311.2901). arXiv:1311.2901
    [cs] version: 3.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2017) Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang,
    X., Metaxas, D.N., 2017. StackGAN: Text to photo-realistic image synthesis with
    stacked generative adversarial networks, in: Proceedings of the IEEE international
    conference on computer vision, pp. 5907–5915.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2018a) Zhang, H., Xu, T., Li, H., Zhang, S., Wang, X., Huang,
    X., Metaxas, D.N., 2018a. StackGAN++: Realistic image synthesis with stacked generative
    adversarial networks. IEEE transactions on pattern analysis and machine intelligence
    41, 1947–1962. Publisher: IEEE.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019a) Zhang, H.B., Zhang, Y.X., Zhong, B., Lei, Q., Yang, L.,
    Du, J.X., Chen, D.S., 2019a. A comprehensive survey of vision-based human action
    recognition methods. Sensors 19, 1005.
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020a) Zhang, J., Liu, A., Gao, M., Chen, X., Zhang, X., Chen,
    X., 2020a. Ecg-based multi-class arrhythmia detection using spatio-temporal attention-based
    convolutional recurrent neural network. Artificial Intelligence in Medicine 106,
    101856.
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019b) Zhang, R., Zong, Q., Dou, L., Zhao, X., 2019b. A novel
    hybrid deep learning scheme for four-class motor imagery classification. Journal
    of neural engineering 16, 066004.
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2020b) Zhang, W.E., Sheng, Q.Z., Alhazmi, A., Li, C., 2020b.
    Adversarial attacks on deep-learning models in natural language processing: A
    survey. ACM Transactions on Intelligent Systems and Technology (TIST) 11, 1–41.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2021) Zhang, X., Han, Y., Xu, W., Wang, Q., 2021. Hoba: A novel
    feature engineering methodology for credit card fraud detection with a deep learning
    architecture. Information Sciences 557, 302–316.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2018b) Zhang, Z., Xie, Y., Yang, L., 2018b. Photographic text-to-image
    synthesis with a hierarchically-nested adversarial network, in: Proceedings of
    the IEEE conference on computer vision and pattern recognition, pp. 6199–6208.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2022) Zhao, G., Yang, W., Ren, X., Li, L., Wu, Y., Sun, X., 2022.
    Well-classified examples are underestimated in classification with deep neural
    networks, in: Proceedings of the AAAI Conference on Artificial Intelligence, pp.
    9180–9189. Issue: 8.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao and He (2015) Zhao, Y., He, L., 2015. Deep learning in the eeg diagnosis
    of alzheimer’s disease, in: Computer Vision-ACCV 2014 Workshops: Singapore, Singapore,
    November 1-2, 2014, Revised Selected Papers, Part I 12, Springer. pp. 340–353.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2019a) Zhu, F., Ye, F., Fu, Y., Liu, Q., Shen, B., 2019a. Electrocardiogram
    generation with a bidirectional lstm-cnn generative adversarial network. Scientific
    reports 9, 6734.
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2019b) Zhu, M., Pan, P., Chen, W., Yang, Y., 2019b. DM-GAN: Dynamic
    memory generative adversarial networks for text-to-image synthesis, in: Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition, pp. 5802–5810.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: zhu et al. (2019) zhu, w., Chen, X., Wang, Y., Wang, L., 2019. Arrhythmia recognition
    and classification using ecg morphology and segment feature analysis. IEEE/ACM
    Transactions on Computational Biology and Bioinformatics 16, 131–138. doi:[10.1109/TCBB.2018.2846611](https:/doi.org/10.1109/TCBB.2018.2846611).
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2020) Zhu, X., Su, W., Lu, L., Li, B., Wang, X., Dai, J., 2020.
    Deformable DETR: Deformable transformers for end-to-end object detection. arXiv
    preprint arXiv:2010.04159 .'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2023) Zhu, X., Zhu, Y., Zhang, L., Chen, Y., 2023. A BERT-based
    multi-semantic learning model with aspect-aware enhancement for aspect polarity
    classification. Applied Intelligence 53, 4609–4623. URL: [https://doi.org/10.1007/s10489-022-03702-1](https://doi.org/10.1007/s10489-022-03702-1),
    doi:[10.1007/s10489-022-03702-1](https:/doi.org/10.1007/s10489-022-03702-1).'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhuang et al. (2020) Zhuang, F., Qi, Z., Duan, K., Xi, D., Zhu, Y., Zhu, H.,
    Xiong, H., He, Q., 2020. A comprehensive survey on transfer learning. Proceedings
    of the IEEE 109, 43–76. Publisher: IEEE.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zou and Hastie (2005) Zou, H., Hastie, T., 2005. Regularization and Variable
    Selection Via the Elastic Net. Journal of the Royal Statistical Society Series
    B: Statistical Methodology 67, 301–320. URL: [https://doi.org/10.1111/j.1467-9868.2005.00503.x](https://doi.org/10.1111/j.1467-9868.2005.00503.x),
    doi:[10.1111/j.1467-9868.2005.00503.x](https:/doi.org/10.1111/j.1467-9868.2005.00503.x).'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
