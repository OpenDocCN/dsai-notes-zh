- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:54:33'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2106.02533] Graph-based Deep Learning for Communication Networks: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2106.02533](https://ar5iv.labs.arxiv.org/html/2106.02533)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Graph-based Deep Learning for Communication Networks: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Weiwei Jiang Department of Electronic Engineering, Tsinghua University, Beijing
    100084, China
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Communication networks are important infrastructures in contemporary society.
    There are still many challenges that are not fully solved and new solutions are
    proposed continuously in this active research area. In recent years, to model
    the network topology, graph-based deep learning has achieved the state-of-the-art
    performance in a series of problems in communication networks. In this survey,
    we review the rapidly growing body of research using different graph-based deep
    learning models, e.g. graph convolutional and graph attention networks, in various
    problems from different types of communication networks, e.g. wireless networks,
    wired networks, and software defined networks. We also present a well-organized
    list of the problem and solution for each study and identify future research directions.
    To the best of our knowledge, this paper is the first survey that focuses on the
    application of graph-based deep learning methods in communication networks involving
    both wired and wireless scenarios. To track the follow-up research, a public GitHub
    repository is created, where the relevant papers will be updated continuously.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Graph , Deep Learning , Graph Neural Network , Communication Network , Software
    Defined Networking^†^†journal: Journal of LaTeX Templates'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Communication networks are ubiquitous in contemporary society, from the widely
    used Internet and 4G/5G cellular networks to the fast-growing Internet of Things
    (IoT) networks. The growing of communication networks has gone beyond the imagination
    of their designers. For example, based on Cisco Annual Internet Report (2018–2023)
    White Paper, nearly two-thirds of the global population will have Internet access
    by 2023 ¹¹1[https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html](https://www.cisco.com/c/en/us/solutions/collateral/executive-perspectives/annual-internet-report/white-paper-c11-741490.html).
    It would be very challenging to operate and manage such giant networks and new
    network types keep bringing new problems. For example, the manual configuration
    becomes infeasible or inefficient in modern networks. While the research for communication
    networks has a long history, it is still an active area with a steady stream of
    new ideas, e.g., Software Defined Networking (SDN) and Space-Air-Ground Integrated
    Network (SAGIN). The challenges may not only include the traditional ones, e.g.,
    routing and load balancing, power control and resource allocation, but also the
    emerging ones, e.g., virtual network embedding in SDN.
  prefs: []
  type: TYPE_NORMAL
- en: To solve these challenges, various solutions are introduced to the networking
    domain, especially deep learning [[1](#bib.bib1)]. Represented by deep neural
    networks, deep learning has achieved a great success in many problems, especially
    in image recognition, natural language processing, and time series problems [[2](#bib.bib2),
    [3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6)]. Deep learning
    models are also applied in various communication networks and are proven extremely
    useful for a series of problems, e.g., network design, traffic prediction, resource
    allocation, etc [[7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)].
    However, in these studies, the network topology structure is not fully utilized
    because most of the deep neural networks are designed for Euclidean structure
    data, e.g., images and videos. To amend this shortcoming, graph-based deep learning
    represented by Graph Neural Networks (GNNs) are proposed for non-Euclidean structure
    data in recent years [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14),
    [15](#bib.bib15), [16](#bib.bib16)]. More recently, GNNs are combined with deep
    reinforcement learning for making decisions in a series of problems, e.g., GNN
    is used for processing the graph information and improving the inter-coflow scheduling
    ability in distributed computing [[17](#bib.bib17)].
  prefs: []
  type: TYPE_NORMAL
- en: GNNs are suitable for problems in communication networks because of their strong
    learning ability to capture the spatial information hidden in the network topology
    and their generalization ability to be used in unseen topologies when the networks
    are dynamic. As to be discussed in this survey, GNN-based solutions are proven
    effective for a wide range of problems in different network scenarios and are
    worthy of being explored deeper in the future.
  prefs: []
  type: TYPE_NORMAL
- en: To the best of the authors’ knowledge, this paper presents the first literature
    survey of graph-based deep learning studies for problems in communication networks,
    covering a total of 81 papers ranging from 2016 to 2021 and involving both wired
    and wireless scenarios. Compared to a recent similar survey [[18](#bib.bib18)]
    which only covers the applications of GNNs in wireless networks, our survey has
    a broader coverage and contains almost all the surveyed studies from [[18](#bib.bib18)].
    The scope of communication networks used in this survey is broad, thus the surveyed
    papers are selected from a wide range of journals and conferences. Because it
    is still a very rapidly developing research topic of applying graph-based deep
    learning methods, we also include preprints that have not yet gone through the
    traditional peer review process (e.g., arXiv papers) to present the latest progress.
  prefs: []
  type: TYPE_NORMAL
- en: 'The surveyed papers are classified into three major scenarios, as organized
    in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Graph-based Deep Learning for
    Communication Networks: A Survey"). Some of the common problems are discussed
    in two or three scenarios, e.g., network modeling, routing, traffic prediction.
    The other problems are only mentioned in one of these scenarios. This kind of
    organization is not exclusive, because the idea of SDN can be applied for both
    the wireless and wired networks. Graph-based deep learning is being frequently
    used in the assumption of future softwarized networks, without a strict constraint
    about which type of substrate network is being used. By taking the SDN scenario
    as a separate section, the relevant discussion would be inspiring for both the
    future work in the wireless and wired scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ebd3b208fadb8acd0cb8ba153cd89957.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The organization of this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: In this survey, the problems to solve, the graph-based solutions and the specific
    GNN models used in each study are identified and summarized. We also attempt to
    point out the future directions of applying GNNs in communication networks. Our
    aim is to provide an up-to-date summary of related work and a useful starting
    point for new researchers interested in related topics. In addition to this paper,
    we have also created an open GitHub repository ²²2[https://github.com/jwwthu/GNN-Communication-Networks](https://github.com/jwwthu/GNN-Communication-Networks)
    to update new papers continuously.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our contributions are summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1) Comprehensive Review: We present the up-to-date comprehensive review of
    graph-based deep learning solutions for problems in various types of communication
    networks, in the past six years (2016-2021).'
  prefs: []
  type: TYPE_NORMAL
- en: '2) Well-organized Summary: We summarize the problem to solve, the graph-based
    solution and the GNNs used in each study in a unified format, which would be useful
    as a reference manual.'
  prefs: []
  type: TYPE_NORMAL
- en: '3) Future Directions: We propose several potential future directions for researchers
    interested in relevant topics.'
  prefs: []
  type: TYPE_NORMAL
- en: For reference, the list of the acronyms frequently used in this survey is summarized
    in Table LABEL:tab:acronyms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: The list of the acronyms used in this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Acronym | Full Name |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| BGP | Border Gateway Protocol |'
  prefs: []
  type: TYPE_TB
- en: '| DC-STGCN | Dual-Channel based Graph Convolutional Network |'
  prefs: []
  type: TYPE_TB
- en: '| DCRNN | Diffusion Convolutional Recurrent Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| DL | Deep Learning |'
  prefs: []
  type: TYPE_TB
- en: '| DQN | Deep Q Network |'
  prefs: []
  type: TYPE_TB
- en: '| DRL | Deep Reinforcement Learning |'
  prefs: []
  type: TYPE_TB
- en: '| FDS-MARL | Fully Decentralized Soft Multi-Agent Reinforcement Learning |'
  prefs: []
  type: TYPE_TB
- en: '| GASTN | Graph Attention Spatial-Temporal Network |'
  prefs: []
  type: TYPE_TB
- en: '| GAT | Graph Attention Network |'
  prefs: []
  type: TYPE_TB
- en: '| GCLR | GNN based Cross Layer optimization by Routing |'
  prefs: []
  type: TYPE_TB
- en: '| GCN | Graph Convolutional Network |'
  prefs: []
  type: TYPE_TB
- en: '| GE | Graph Embedding |'
  prefs: []
  type: TYPE_TB
- en: '| GGS-NN | Gated Graph Sequence Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| GIN | Graph Isomorphism Network |'
  prefs: []
  type: TYPE_TB
- en: '| GN | Graph Network |'
  prefs: []
  type: TYPE_TB
- en: '| GNN | Graph Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| HIGNN | Heterogeneous Interference Graph Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| HetGAT | Heterogeneous Graph Attention Network |'
  prefs: []
  type: TYPE_TB
- en: '| IGCNet | Interference Graph Convolutional Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| ML | Machine Learning |'
  prefs: []
  type: TYPE_TB
- en: '| MPGNNs | Message Passing Graph Neural Networks |'
  prefs: []
  type: TYPE_TB
- en: '| MPLS | Multiprotocol Label Switching |'
  prefs: []
  type: TYPE_TB
- en: '| MPNN | Message Passing Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| MSTNN | Multi-scale Spatial-Temporal Graph Neural Network |'
  prefs: []
  type: TYPE_TB
- en: '| NFV | Network Function Virtualization |'
  prefs: []
  type: TYPE_TB
- en: '| REGNNs | Random Edge Graph Neural Networks |'
  prefs: []
  type: TYPE_TB
- en: '| S-RNN | Structural-RNN |'
  prefs: []
  type: TYPE_TB
- en: '| SDN | Software Defined Networking |'
  prefs: []
  type: TYPE_TB
- en: '| SFC | Service Function Chaining |'
  prefs: []
  type: TYPE_TB
- en: '| SGCRN | Spatiotemporal Graph Convolutional Recurrent Network |'
  prefs: []
  type: TYPE_TB
- en: '| TCN | Temporal Convolutional Network |'
  prefs: []
  type: TYPE_TB
- en: '| TGCN | Temporal Graph Convolutional Network |'
  prefs: []
  type: TYPE_TB
- en: '| UWMMSE | Unfolded iterative Weighted Minimum Mean Squared Error |'
  prefs: []
  type: TYPE_TB
- en: '| VNE | Virtual Network Embedding |'
  prefs: []
  type: TYPE_TB
- en: '| VNF | Virtual Network Function |'
  prefs: []
  type: TYPE_TB
- en: 'The remainder of this paper is organized as follows. In Section [2](#S2 "2
    Survey Methodology ‣ Graph-based Deep Learning for Communication Networks: A Survey"),
    we introduce the progress of conducting literature search and selection. In Section [3](#S3
    "3 Graph-based Deep Learning Introduction ‣ Graph-based Deep Learning for Communication
    Networks: A Survey"), we introduce the GNNs used in the reviewed studies. In Section [4](#S4
    "4 Wireless Networks ‣ Graph-based Deep Learning for Communication Networks: A
    Survey"), we summarize the studies in wireless networks. In Section [5](#S5 "5
    Wired Networks ‣ Graph-based Deep Learning for Communication Networks: A Survey"),
    we summarize the studies in wired networks. In Section [6](#S6 "6 Software Defined
    Networks ‣ Graph-based Deep Learning for Communication Networks: A Survey"), we
    summarize the studies in software defined networks. In Section [7](#S7 "7 Future
    Directions ‣ Graph-based Deep Learning for Communication Networks: A Survey"),
    we point out future directions. In Section [8](#S8 "8 Conclusion ‣ Graph-based
    Deep Learning for Communication Networks: A Survey"), we draw the conclusion.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Survey Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To collect relevant studies, the literature is searched with various combinations
    of two groups of keywords. The first group is about the graph-based deep learning
    techniques, e.g., “Graph”, “Graph Embedding”, “Graph Neural Network”, “Graph Convolutional
    Network”, “Graph Attention Networks”, “GraphSAGE”, “Message Passing Neural Network”,
    “Graph Isomorphism Network”, etc. The second group is about the communication
    networks as well as specific problems, e.g., “Wireless Network”, “Cellular Network”,
    “Computer Network”, “Software Defined Networking”, “Traffic Prediction”, “Routing”,
    “Service Function Chaining”, “Virtual Network Function”, etc. The databases from
    major publishers are carefully covered one by one, e.g., ACM, Elsevier, IEEE,
    Springer, Wiley, etc. To track the citation relationship among these papers and
    avoid missing records from smaller publishers, Google Scholar is also leveraged
    in the literature search process.
  prefs: []
  type: TYPE_NORMAL
- en: 'A total of 81 papers are finally selected and covered in this survey, with
    the earliest one published in year 2016, as shown in Figure [2](#S2.F2 "Figure
    2 ‣ 2 Survey Methodology ‣ Graph-based Deep Learning for Communication Networks:
    A Survey"). Most of the surveyed papers are published in recent three years, i.e.,
    2019, 2020, and the first five months of 2021\. Compared with 14 papers in 2019,
    there is a 207% growth of papers in 2020, with a total of 43 papers. While there
    are only 20 papers in the first five months of 2021, it is expected that more
    relevant studies would be published or publicized in the remaining months with
    the growing impact of graph-based deep learning methods being applied in the networking
    domain. We also show the paper statistics for different network types in Figure [3](#S2.F3
    "Figure 3 ‣ 2 Survey Methodology ‣ Graph-based Deep Learning for Communication
    Networks: A Survey"). The wireless network scenario draws more attention than
    the other two and this trend may continue in 2021.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7148d9e37a18a56011fb8e92677b933d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: The paper count of different types annually.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3898d1aa2c564aa646f45546d9fee6e1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: The paper count of different network types annually.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a full coverage of relevant studies, workshop, conference, and journal
    papers as well as preprint papers are covered in this survey, to track the latest
    achievements as well as the on-going progress. The journal list (alphabetically)
    is shown in Table [2](#S2.T2 "Table 2 ‣ 2 Survey Methodology ‣ Graph-based Deep
    Learning for Communication Networks: A Survey"). The conference list (alphabetically)
    is shown in Table [3](#S2.T3 "Table 3 ‣ 2 Survey Methodology ‣ Graph-based Deep
    Learning for Communication Networks: A Survey"). And the workshop list (alphabetically)
    is shown in Table [4](#S2.T4 "Table 4 ‣ 2 Survey Methodology ‣ Graph-based Deep
    Learning for Communication Networks: A Survey"). All the preprint papers are from
    the arXiv platform ³³3[https://arxiv.org/](https://arxiv.org/). Since we cover
    a wide area with various communication networks, the papers are selected from
    various publications or conference proceedings, some of which may focus on telecommunications
    or related subjects and the others may be multidisciplinary. As an emerging topic
    which has not been widely adopted, graph-based deep learning appears in recent
    years for solving networking-related problems, with only one paper selected for
    most journals or conferences.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: List of source journals and the corresponding studies we cover in
    this study.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Journal Name | Studies |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Computer Networks | [[19](#bib.bib19), [20](#bib.bib20)] |'
  prefs: []
  type: TYPE_TB
- en: '| Electronics | [[21](#bib.bib21)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Access | [[22](#bib.bib22), [23](#bib.bib23)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Communications Letters | [[24](#bib.bib24), [25](#bib.bib25), [26](#bib.bib26),
    [27](#bib.bib27)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Internet of Things Journal | [[28](#bib.bib28)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Journal on Selected Areas in Communications | [[29](#bib.bib29), [30](#bib.bib30),
    [31](#bib.bib31), [32](#bib.bib32)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Systems Journal | [[33](#bib.bib33)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Industrial Informatics | [[34](#bib.bib34)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Information Forensics and Security | [[35](#bib.bib35)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Mobile Computing | [[36](#bib.bib36), [37](#bib.bib37)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Network Science and Engineering | [[38](#bib.bib38)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Network and Service Management | [[39](#bib.bib39)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Signal Processing | [[40](#bib.bib40)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Vehicular Technology | [[41](#bib.bib41)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Transactions on Wireless Communications | [[42](#bib.bib42), [43](#bib.bib43)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| International Journal of Network Management | [[44](#bib.bib44)] |'
  prefs: []
  type: TYPE_TB
- en: '| Performance Evaluation | [[45](#bib.bib45)] |'
  prefs: []
  type: TYPE_TB
- en: '| Sensors | [[46](#bib.bib46)] |'
  prefs: []
  type: TYPE_TB
- en: '| Transactions on Emerging Telecommunications Technologies | [[47](#bib.bib47)]
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: List of source conferences and the corresponding studies we cover
    in this study.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Conference Name | Studies |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ACM SIGCOMM conference | [[48](#bib.bib48)] |'
  prefs: []
  type: TYPE_TB
- en: '| ACM Symposium on SDN Research (SOSR) | [[49](#bib.bib49)] |'
  prefs: []
  type: TYPE_TB
- en: '| Asia-Pacific Network Operations and Management Symposium (APNOMS) | [[50](#bib.bib50),
    [51](#bib.bib51)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Annual Consumer Communications & Networking Conference (CCNC) | [[52](#bib.bib52)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Conference on Computer Communications (INFOCOM) | [[53](#bib.bib53)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Conference on Network Function Virtualization and Software Defined Networks
    (NFV-SDN) | [[54](#bib.bib54)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Global Communications Conference (GLOBECOM) | [[55](#bib.bib55), [56](#bib.bib56)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP) | [[57](#bib.bib57), [58](#bib.bib58)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE International Conference on Communications (ICC) | [[59](#bib.bib59),
    [60](#bib.bib60), [61](#bib.bib61), [62](#bib.bib62), [63](#bib.bib63)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Symposium on Computers and Communications (ISCC) | [[64](#bib.bib64)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Vehicular Technology Conference (VTC) | [[65](#bib.bib65)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Wireless Communications and Networking Conference (WCNC) | [[66](#bib.bib66),
    [67](#bib.bib67), [68](#bib.bib68)] |'
  prefs: []
  type: TYPE_TB
- en: '| IFIP Networking Conference (IFIP Networking) | [[69](#bib.bib69)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on Information Networking (ICOIN) | [[70](#bib.bib70),
    [71](#bib.bib71)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on Information and Communication Technology Convergence
    (ICTC) | [[72](#bib.bib72)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on Network and Service Management (CNSM) | [[73](#bib.bib73),
    [74](#bib.bib74), [75](#bib.bib75)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on Real-Time Networks and Systems (RTNS) | [[76](#bib.bib76)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on Wireless Communications and Signal Processing
    (WCSP) | [[77](#bib.bib77)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Conference on emerging Networking EXperiments and Technologies
    (CoNEXT) | [[78](#bib.bib78)] |'
  prefs: []
  type: TYPE_TB
- en: '| International Symposium on Networks, Computers and Communications (ISNCC)
    | [[79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '| Opto-Electronics and Communications Conference (OECC) | [[80](#bib.bib80)]
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: List of source workshops and the corresponding studies we cover in
    this study.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Workshop Name | Studies |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AutoML for Networking and Systems Workshop of MLSys Conference | [[81](#bib.bib81)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Globecom Workshops (GC Wkshps) | [[82](#bib.bib82)] |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE International Workshop on Signal Processing Advances in Wireless Communications
    (SPAWC) | [[83](#bib.bib83), [84](#bib.bib84)] |'
  prefs: []
  type: TYPE_TB
- en: '| Workshop on Big Data Analytics and Machine Learning for Data Communication
    Networks | [[85](#bib.bib85)] |'
  prefs: []
  type: TYPE_TB
- en: '| Workshop on Network Meets AI & ML | [[86](#bib.bib86), [87](#bib.bib87)]
    |'
  prefs: []
  type: TYPE_TB
- en: 3 Graph-based Deep Learning Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we first present some typical examples of the graph structures
    used in communication networks. Then we give a short introduction of the graph-based
    deep learning models, especially those used in the surveyed papers. Finally, we
    discuss the pros and cons of applying graph-based deep learning models in the
    networking domain.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Graphs in Communication Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: From the graph theory, a simple graph is defined as $G=(V,E)$, where $V$ is
    the set of nodes and $E$ is the set of edges between nodes. In communication networks,
    the edges can be either directed or undirected, depending on the specific problems.
    Both nodes and edges can be associated with some attributes as the features, either
    static or dynamic.
  prefs: []
  type: TYPE_NORMAL
- en: 'Two graph examples are given for the wired and wireless scenarios respectively.
    In Figure [4](#S3.F4 "Figure 4 ‣ 3.1 Graphs in Communication Networks ‣ 3 Graph-based
    Deep Learning Introduction ‣ Graph-based Deep Learning for Communication Networks:
    A Survey"), the communication graph from the Abilene network is presented, which
    consists of 11 nodes and 14 edges. Each node represents the physical backbone
    router and the node features include the inflow and outflow traffic volumes. Each
    edge represents the physical transmission link and the edge features include the
    transmission metrics, e.g., bandwidth and delay. Similar communication graphs
    are built from other network topologies, e.g., the Nobel, GÉANT, Germany50, and
    AT&T backbone networks, can be found in [[47](#bib.bib47), [59](#bib.bib59), [33](#bib.bib33)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/58e4ee86ee0b6997ef3dceaeeacadcec.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: An example of the communication graph from the Abilene network.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Figure [5](#S3.F5 "Figure 5 ‣ 3.1 Graphs in Communication Networks ‣ 3 Graph-based
    Deep Learning Introduction ‣ Graph-based Deep Learning for Communication Networks:
    A Survey"), the interference graph for a homogeneous ad-hoc network is presented,
    which consists of 3 nodes and 3 edges. Different from Figure [4](#S3.F4 "Figure
    4 ‣ 3.1 Graphs in Communication Networks ‣ 3 Graph-based Deep Learning Introduction
    ‣ Graph-based Deep Learning for Communication Networks: A Survey"), the nodes
    in Figure [5](#S3.F5 "Figure 5 ‣ 3.1 Graphs in Communication Networks ‣ 3 Graph-based
    Deep Learning Introduction ‣ Graph-based Deep Learning for Communication Networks:
    A Survey") are virtual nodes, each of which corresponds to a transceiver pair
    (Tx, Rx). The features of node $i$ include the direct channel state information
    (CSI) $\mathbf{h}_{ii}$ and other environmental information, e.g., the weight
    $\omega_{i}$ of node $i$ [[82](#bib.bib82)]. The undirected edge between node
    $i$ and node $j$ models the interference between two transceiver pairs and the
    edge features are the interference CSIs $\mathbf{h}_{ij}$ and $\mathbf{h}_{ji}$.
    The interference graph built for the heterogeneous ad-hoc network case can be
    further found in [[88](#bib.bib88)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/19461c0b4d94f0c0cd94d5875f9f1168.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: An example of the interference graph from [[82](#bib.bib82)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'An adjacency matrix $\mathbf{A}$ is introduced to incorporate the network topology
    information into the architecture of neural networks. Let $e_{ij}$ represents
    the edge between node $v_{i}$ and node $v_{j}$. Then the element of the adjacency
    matrix $A$ is defined as follows: $A_{ij}=1$ if $e_{ij}\in E$, otherwise, $A_{ij}=0$.
    Here the binary matrix $A$ only captures the connection relationship. If $\mathbf{A}$
    is symmetric, the graph is undirected, otherwise, the graph is directed. More
    complex adjacency matrices can be defined similarly, e.g., the distance matrix
    or the interference matrix.'
  prefs: []
  type: TYPE_NORMAL
- en: For defining the GNNs in the next part, more notations are introduced here.
    Based on the connection relationship, $\mathcal{N}(v_{i})$ represents the neighbor
    node set of $v_{i}$ and each element of the degree matrix $\mathbf{D}$ is $\mathbf{D}_{ii}=\|\mathcal{N}(v_{i})\|$.
    The Laplacian matrix of an undirected graph is introduced and defined as $\mathbf{L}=\mathbf{D}-\mathbf{A}$
    and the normalized Laplacian matrix is further defined as $\tilde{\mathbf{L}}=\mathbf{I}_{N}-\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}$,
    where $N$ is the number of nodes and $\mathbf{I}_{N}$ is the identity matrix with
    size $N$. The node feature matrix of a graph is defined as $\mathbf{X}\in{R}^{N\times
    d}$, where $d$ is the dimension of the node feature vector.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Graph-based Models in Communication Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Since the research for graph-based deep learning is still in a fast pace with
    new models appearing continuously, we have no intention of conducting a thorough
    literature search on the graph-based models. In this section, we would focus on
    a short introduction for the GNNs used in the surveyed studies. For those who
    are interested in the whole picture of graph neural networks and a deeper discussion
    of the technical details, recent surveys [[11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15)] are recommended. The relevant
    graph-based deep learning models are listed chronologically in Figure [6](#S3.F6
    "Figure 6 ‣ 3.2 Graph-based Models in Communication Networks ‣ 3 Graph-based Deep
    Learning Introduction ‣ Graph-based Deep Learning for Communication Networks:
    A Survey"). Please note that the listed conferences may be lagged behind the preprint
    versions, which could be released one or two years earlier.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/26ae978c57ec12cd5e94b536ebfc9595.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The relevant graph-based deep learning models of this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: As a pioneering study, GNN is introduced in [[89](#bib.bib89)], which extends
    the application of neural networks from Euclidean structure data to non-Euclidean
    structure data. GNN is based on the message passing mechanism, in which each node
    updates its state by exchanging information with each other until it reaches a
    certain stable state. Afterwards, various GNN variants are proposed, e.g., Graph
    Convolutional Network (GCN) and Graph Attention Networks (GAT).
  prefs: []
  type: TYPE_NORMAL
- en: We first introduce the Graph Embedding (GE) models. In mathematics, embedding
    is a mapping function $f:X\rightarrow Y$, in which a point in one space $X$ is
    mapped to another space $Y$. Embedding is usually performed from a high-dimensional
    abstract space to a low-dimensional space. Generally speaking, the representation
    mapped to the low-dimensional space is easier for neural networks to handle with.
    In the case of graphs, graph embedding is used to transform nodes, edges, and
    their features into the vector space, while preserving properties like graph structure
    and information as much as possible. For the studies covered in this survey, several
    graph embedding models are involved, including structure2vec [[90](#bib.bib90)],
    GraphSAGE [[91](#bib.bib91)], and GE [[92](#bib.bib92)]. In a transductive learning
    approach, Structure2vec [[90](#bib.bib90)] is based on the idea that if the two
    sequences composed of all the neighbors of two nodes are similar, then the two
    nodes are similar. GraphSAGE [[91](#bib.bib91)] is a representative of inductive
    learning. It does not directly learn the representation of each node, but learns
    the aggregation function instead. For the new node, its embedding representation
    is generated directly without the need to learn again. Furthermore, a novel adversarial
    regularized framework is proposed for graph embedding in [[92](#bib.bib92)].
  prefs: []
  type: TYPE_NORMAL
- en: Then we introduce the GCN models. GCN extends the convolution operation from
    traditional data (such as images) to graph data, inspired by the convolutional
    neural networks which are extremely successful for image-based tasks. The core
    idea is to learn a function mapping, through which a node can aggregate its own
    features and the features of its neighbors to generate the new representation.
    Generally speaking, there are two types of GCN models, namely, spectral-based
    and spatial-based.
  prefs: []
  type: TYPE_NORMAL
- en: Based on graph signal processing, spectral-based GCNs define the convolution
    operation in the spectral domain, e.g., the Fourier domain. To conduct the convolution
    operation, a graph signal is transformed to the spectral domain by the graph Fourier
    transform. Then the result after the convolution is transformed back by the inverse
    graph Fourier transform. Several spectral-based GCNs are used in the surveyed
    studies, e.g., GNN [[93](#bib.bib93)], ChebNet [[94](#bib.bib94)], and GCN [[95](#bib.bib95)],
    which improve the convolution operation with different techniques. By introducing
    a parameterization with smooth coefficients, GNN [[93](#bib.bib93)] attempts to
    make the spectral filters spatially localized. ChebNet [[94](#bib.bib94)] learns
    the diagonal matrix as an approximation of a truncated expansion in terms of Chebyshev
    polynomials up to $K$th order.
  prefs: []
  type: TYPE_NORMAL
- en: 'To avoid overfitting, $K=1$ is used in GCN [[95](#bib.bib95)]. More specifically,
    the graph convolution operation $*G$ in GCN is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{X}_{*G}=\mathbf{W}(\mathbf{I}_{N}+\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}})\mathbf{X}$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{W}$ is a learnable weight matrix, i.e., the model parameters.
    To alleviate the potential gradient explosion problem, the graph convolution operation
    is further transformed into:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{X}_{*G}=\mathbf{W}(\tilde{\mathbf{D}}^{-\frac{1}{2}}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-\frac{1}{2}})\mathbf{X}$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $\tilde{\mathbf{A}}=\mathbf{A}+\mathbf{I}_{N}$ and $\tilde{\mathbf{D}}_{ii}=\sum_{j}{\tilde{\mathbf{A}}_{ij}}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several spatial-based GCNs are also used in the surveyed studies, which defines
    the convolution operation directly on the graph based on the graph topology. To
    unify different spatial-based variants, Message Passing Neural Network (MPNN) [[96](#bib.bib96)]
    proposes the usage of message passing functions, which contain a message passing
    phase and a readout phase. The message passing phase is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{m}_{v_{i}}^{(t)}=\sum_{v_{j}\in\mathcal{N}{(v_{i})}}\mathcal{M}^{(t)}(\mathbf{X}_{i}^{(t-1)},\mathbf{X}_{j}^{(t-1)},\mathbf{e}_{ij})$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{m}_{v_{i}}^{(t)}$ is the message aggregated from the neighbors
    of node $v_{i}$, $\mathcal{M}^{(t)}(\cdot)$ is the aggregation function in the
    $t$-th iteration, $\mathbf{X}_{i}^{(t)}$ is the hidden state of node $v_{i}$ in
    the $t$-th iteration, and $\mathbf{e}_{ij}$ is the edge feature vector between
    node $v_{i}$ and node $v_{j}$. The readout phase is further defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{X}_{i}^{(t)}=\mathcal{U}^{(t)}(\mathbf{X}_{i}^{(t-1)},\mathbf{m}_{v_{i}}^{(t)})$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{U}^{(t)}(\cdot)$ is the readout function in the $t$-th iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'Graph Network (GN) [[97](#bib.bib97)] also unifies many GNN variants, by learning
    node-level, edge-level and graph-level representations. Graph Isomorphism Network
    (GIN) [[98](#bib.bib98)] takes a step further by pointing out that previous MPNN-based
    methods are incapable of distinguishing different graph structures based on the
    graph embedding they produce and adjusting the weight of the central node by a
    learnable parameter to amend this drawback. Attention-based GNN models can be
    categorized into the spatial-based type. GAT [[99](#bib.bib99)] incorporates the
    attention mechanism into the propagation step and further utilizes the multi-head
    attention mechanism to stabilize the learning process, which is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{X}_{i}^{(t)}=\&#124;_{k}\sigma(\sum_{j\in\mathcal{N}{(v_{i})}}\alpha^{k}(\mathbf{X}_{i}^{(t-1)},\mathbf{X}_{j}^{(t-1)})\mathbf{W}^{(t-1)}\mathbf{X}_{j}^{(t-1)})$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $\|$ is the concatenation operation, $\sigma$ is the activation method,
    $\alpha^{k}(\cdot)$ is the $k$-th attention mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Other than the convolution operation, the recurrent operation can also be applied
    in the propagation module of GNNs. The key difference is that the convolution
    operations use different weights while the recurrent operations share the same
    weights. For example, Gated Graph Sequence Neural Network (GGS-NN) [[100](#bib.bib100)]
    uses Gated Recurrent Units (GRU) in the propagation step.
  prefs: []
  type: TYPE_NORMAL
- en: In realistic networks, the network topology may change occasionally, e.g., with
    the addition or deletion of routers, which corresponds to the case of dynamic
    graphs, instead of static graphs. Several GNN variants are proposed for dealing
    with dynamic graphs. Diffusion Convolutional Recurrent Neural Network (DCRNN) [[101](#bib.bib101)]
    leverages GNNs to collect the spatial information, which is further used in sequence-to-sequence
    models. By extending the static graph structure with temporal connections, Structural-RNN
    (S-RNN) [[102](#bib.bib102)] can learn the spatial and temporal information simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: The last case to discuss is the heterogeneous graph, in which the nodes and
    edges are multi-typed or multi-modal. For this case, meta-path is introduced as
    a path scheme which determines the type of node in each position of the path,
    then one heterogeneous graph can be reduced to several homogeneous graphs to perform
    graph learning algorithms. To generate the final representation of nodes, graph
    attention is performed on the meta-path-based neighbors and a semantic attention
    is used over output embeddings of nodes under all meta-path schemes in Heterogeneous
    Graph Attention Network (HetGAT) [[103](#bib.bib103)].
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Pros and Cons of Graph-based Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Machine learning has emerged as a new paradigm to solve various networking problems
    and to automate network management [[50](#bib.bib50)]. Compared with traditional
    methods, ML models provide many benefits for solving the networking relevant problems.
    The first advantage is that machine learning models can automatically learn and
    improve from experiences without being explicitly programmed [[50](#bib.bib50)].
    Even though it takes some efforts to train a machine learning model, the inference
    time when applying a trained model is much smaller. These efforts are also inevitable
    when applying a traditional method based on various optimization techniques which
    may require a long iteration update process. The second advantage is that the
    machine learning models are more effective in learning wide and dynamically changing
    data than statistical and heuristic methods. Based on these advantages, machine
    learning models, especially the deep learning models, have been widely applied
    in the networking domain.
  prefs: []
  type: TYPE_NORMAL
- en: The story does not end here. While machine learning has achieved a great success
    in many research fields, e.g., computer vision, natural language processing and
    time series processing. Most of these fields use Euclidean domain data, for which
    the feed forward neural networks, CNNs and RNNs are enough. However, for other
    fields, e.g., chemistry and biology, these models are inadequate for learning
    the non-Euclidean graph data, which contain rich relational information between
    each pair of neighboring elements. Many kinds of graph structure data also exist
    in the communication networks as introduced earlier, which is beyond the ability
    of non-GNN machine learning models. Driven by the graph structure data, GNNs are
    preferable because GNNs can automatically learn a condensed representation of
    each node in the network that incorporates the information about the node, its
    neighbors, and their inter-connecting topology [[74](#bib.bib74)] and support
    relational reasoning and combinatorial generalization [[20](#bib.bib20)].
  prefs: []
  type: TYPE_NORMAL
- en: Besides the ability of handling graph structure, GNNs bring new opportunities
    for other challenges that have not been fully solved by previous machine learning
    models, e.g., the complexity in the network state and nonstationarity in networking,
    with a better generalization ability. Communication networks are complex and dynamic
    systems, and the overall networking performance may be affected by many factors,
    e.g., the latency metric affects networking efficiency by defeating network protocols [[33](#bib.bib33)].
    Traditional techniques, e.g., the open shortest path first protocol (OSPF) for
    routing, are not capable of coping with these challenges. When situations such
    as link failure and congestion happen, these traditional techniques would not
    be able to converge quickly with these previously unseen situations. The non-GNN
    machine learning models will no longer apply when the network topology changes,
    e.g., link disconnection, and new training data are needed [[20](#bib.bib20)].
    Since the topology of the network is usually dynamically changed, dynamic graphs
    are used in GNNs for the actual network. In other words, GNN is able to understand
    the complex relationship between topology, routing and traffic in networks, and
    generalizes trained NN parameters over arbitrary topologies, routing schemes and
    variable traffic intensity [[20](#bib.bib20)]. It is also proven that GNNs have
    a higher training efficiency than other neural networks, for example, GNNs converge
    $O(n\log n)$ times faster and their generalization error is $O(n)$ times lower
    theoretically, compared with multilayer perceptrons in a communication networks
    with $n$ nodes [[104](#bib.bib104)].
  prefs: []
  type: TYPE_NORMAL
- en: Even so, GNNs are not the panacea. There are still some concerns about applying
    GNNs in the networking domain and not all of them have been fully resolved. The
    first concern is about the collection of training data for GNNs (and other machine
    learning models too). Compared with the well-developed research areas with large-scale
    open benchmark datasets, e.g., ImageNet for computer vision, the training datasets
    are still rare (at least the open ones) for training the effective GNN models.
    Even for those already used in the existing studies, the data size is limited
    and is far from the need of being applied in the actual network.
  prefs: []
  type: TYPE_NORMAL
- en: The second concern is about the depth of GNN models. For other neural networks,
    e.g., CNNs, it has been proven effective to use a deeper structure, e.g., ResNet.
    However, similar benefits are not obvious for GNNs. It has been found that when
    using more than two GCN layers, the performance becomes worse with more GCN layers.
    This is because GNNs rely on the aggregation operation on the features of neighbor
    nodes, the results become too smooth and lack of differentiation after multiple
    layers. As the network continues to overlap, eventually all nodes will learn the
    same expression and GNNs fail to work. It is still questionable Whether the graph
    neural network needs a deep structure, or whether a deep network structure can
    be designed to avoid the problem of over-smoothness in the networking domain.
  prefs: []
  type: TYPE_NORMAL
- en: The third concern is about the stability of GNN models, both under the stochastic
    perturbations and adversarial attacks [[105](#bib.bib105), [106](#bib.bib106),
    [107](#bib.bib107)]. Stochastic perturbations appear in the communication networks
    in the situations when link failure and congestion happen. While the adversarial
    attacks appear when targeted attacks on the underlying networks happen. These
    problems already exist for other neural networks and more attack types can be
    designed by leveraging the node features or the graph structure. It has been found
    that the stability of GNNs is affected by multiple factors, e.g., the graph filter,
    nonlinearity, architecture width and depth, etc [[106](#bib.bib106)]. And massive
    efforts have been put to design GNNs which are robust to the perturbations or
    attacks. With the deeper involvement of GNNs with various networking problems,
    more potential vulnerable cases would appear which would require a design of more
    robust GNNs.
  prefs: []
  type: TYPE_NORMAL
- en: The last but not the least concern is about the explainability of GNNs for networking
    problems. The study for the explainability and visualization of deep learning
    models has a long story and deep learning has been criticized for its “black-box”
    property. The graph structure brings new challenges for the explainability problem.
    The development of post-processing techniques to explain the predictions made
    by GNNs has been made with some progresses, however, the explainability of GNNs
    in the networking domain has not yet been fully addressed [[108](#bib.bib108),
    [109](#bib.bib109)].
  prefs: []
  type: TYPE_NORMAL
- en: 4 Wireless Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we focus on the relevant studies in wireless network scenarios.
    For wireless networks, we refer to those transmitting information through wireless
    data connections without using a cable, including wireless local area network,
    cellular network, wireless ad hoc network, cognitive radio network, device-to-device
    (D2D) network, satellite network, vehicular network, etc. Some problems are ubiquitous
    in different formats of wireless networks, e.g., power control. We would first
    talk about these problems in general wireless network scenarios. Then we discuss
    the papers focusing on a specific wireless network scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 General Wireless Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared with other deep learning models, GNNs have the advantage of handling
    the topology information, which may not be leveraged in previous studies with
    Euclidean deep learning models. In densely deployed wireless local area networks,
    the channel resource is limited. To increase the system throughput, the channels
    must be allocated efficiently. The features of the channel vectors with the topology
    information are extracted in [[22](#bib.bib22)], with the GCN model. Then a deep
    reinforcement learning is developed for channel allocation, which utilizes the
    features extracted by GCN. Topology information is also used in [[110](#bib.bib110)]
    for wireless network optimization. Combining a GE unit and a deep feed-forward
    network, a two-stage topology-aware framework is proposed and validated for the
    network flow optimization problem, which achieves a trade-off between computation
    time and inference performance.
  prefs: []
  type: TYPE_NORMAL
- en: Compared with the wired communication, wireless transmission may be imperfect
    with more errors. While GNNs may be applied in wireless networks, the transmission
    uncertainty would deteriorate the robustness of GNNs. This challenge is considered
    in [[111](#bib.bib111)], in which decentralized GNN binary classifiers are used
    for multiple problems, e.g., power control or wireless link scheduling. To handle
    this situation, re-transmission mechanisms are proposed to enhance the robustness
    of GNN classifiers, for both uncoded and coded wireless communication systems.
  prefs: []
  type: TYPE_NORMAL
- en: Power allocation or control is an important topic in the wireless network scenario,
    in which the devices connected to the network may be powered by batteries with
    a limited energy storage. The transmission in the free space may also interference
    with each other if the power is not properly controlled. To handle this problem,
    multiple GNN-based solutions are proposed [[83](#bib.bib83), [58](#bib.bib58),
    [40](#bib.bib40), [57](#bib.bib57), [42](#bib.bib42), [112](#bib.bib112), [82](#bib.bib82),
    [32](#bib.bib32), [84](#bib.bib84)]. In a series of studies [[83](#bib.bib83),
    [58](#bib.bib58), [40](#bib.bib40), [112](#bib.bib112)], Random Edge Graph Neural
    Networks (REGNNs) are selected as the optimal solution for the power allocation
    and control optimization problem, with various system constraints. REGNNs outperform
    baselines with an essential permutation invariance property, which are desirable
    in networks of growing size. For the optimal power allocation in a single-hop
    ad hoc wireless network, an iterative weighted minimum mean squared error method
    named UWMMSE is proposed, in which GNNs are used to learn the model parameters [[57](#bib.bib57),
    [42](#bib.bib42)]. UWMMSE effectively reduces the computational complexity without
    harming the allocation performance, over the classic algorithm for power control.
    For solving the similar problem in an unsupervised approach, Interference Graph
    Convolutional Neural Network (IGCNet) is proposed and validated in [[82](#bib.bib82)],
    which is robust to imperfect Channel State Information (CSI). Beamforming is further
    considered in [[32](#bib.bib32)], in which Message Passing Graph Neural Networks
    (MPGNNs) are proposed to solve both the power control and beamforming problems.
    Similarly, in an unsupervised approach to learn optimal power allocation decisions,
    a primal-dual counterfactual optimization approach is proposed in [[84](#bib.bib84)],
    in which GNNs are used to handle the network topology.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in the general wireless network scenario are listed in
    Table [5](#S4.T5 "Table 5 ‣ 4.1 General Wireless Network ‣ 4 Wireless Networks
    ‣ Graph-based Deep Learning for Communication Networks: A Survey"). The target
    problem, proposed solution and the relevant GNN component(s) are also listed.
    The similar tabular format for the paper summary applies in the following sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: List of the papers in the wireless network scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Binary Classification | [[111](#bib.bib111)] | Decentralized GNN | GCN [[95](#bib.bib95)],
    GIN [[98](#bib.bib98)] |'
  prefs: []
  type: TYPE_TB
- en: '| Channel Allocation | [[22](#bib.bib22)] | DRL with GCN | ChebNet [[94](#bib.bib94)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Network Flow Optimization | [[110](#bib.bib110)] | Two-stage Topology-aware
    ML Framework | MPNN [[96](#bib.bib96)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Allocation | [[83](#bib.bib83), [58](#bib.bib58), [40](#bib.bib40)]
    | REGNN | GNN [[93](#bib.bib93)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Allocation | [[57](#bib.bib57), [42](#bib.bib42)] | UWMMSE Method |
    GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Control | [[112](#bib.bib112)] | REGNN | GNN [[93](#bib.bib93)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Control | [[82](#bib.bib82)] | IGCNet | GIN [[98](#bib.bib98)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Control and Beamforming | [[32](#bib.bib32)] | MPGNNs | GIN [[98](#bib.bib98)],
    GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| Power Control | [[84](#bib.bib84)] | Unsupervised Primal-dual Counterfactual
    Optimization | GNN [[93](#bib.bib93)] |'
  prefs: []
  type: TYPE_TB
- en: 4.2 Cellular Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Cellular networks are discussed separately in this part, not only because more
    than ten papers focus on this specific scenario, but also because the cellular
    network has a wide application. For example, there were 5.95 billion LTE subscriptions
    worldwide by the end of Q4 2020 ⁴⁴4[https://gsacom.com/paper/lte-and-5g-subscribers-march-2021-q4/](https://gsacom.com/paper/lte-and-5g-subscribers-march-2021-q4/).
    While the growing trend may be affected by COVID-19, cellular networks are still
    one of the major approach for accessing the Internet.
  prefs: []
  type: TYPE_NORMAL
- en: Driven by the huge demand, the research in the cellular network scenario keeps
    increasing, including those leveraging graph-based deep learning models for some
    traditional communication problems, e.g., resource allocation, power control and
    traffic prediction. Driven by the ideas from SDN, some new problems also appear
    in the cellular network scenario, e.g., network slicing and virtual network embedding.
    Both types of problems have been investigated in the surveyed papers.
  prefs: []
  type: TYPE_NORMAL
- en: To fully utilize the network resources, multipath TCP is considered for 5G networks,
    which transfer packets over multiple paths concurrently. However, network heterogeneity
    in 5G networks makes the multipath routing problem become more complex for the
    existing routing algorithms to handle. A GNN-based multipath routing model is
    proposed as the solution in [[23](#bib.bib23)]. The experiments under the SDN
    framework demonstrate that the GNN-based model can achieve a significant throughput
    improvement.
  prefs: []
  type: TYPE_NORMAL
- en: Traffic prediction is also considered in cellular networks, with GNN-based solutions
    being proposed in recent years [[56](#bib.bib56), [37](#bib.bib37), [21](#bib.bib21),
    [36](#bib.bib36)]. As a prediction problem, the temporal dependencies may be modeled
    by a recurrent neural network, e.g., Long Short Term Memory (LSTM) or GRU. Different
    attention mechanisms may also be incorporated. As an improvement over baselines,
    GNN is capable of modeling the spatial correlation between different nodes, e.g.,
    a cell tower or an access point. Different structures have been explored in existing
    studies, e.g., GAT in [[56](#bib.bib56), [37](#bib.bib37)], GCN in [[21](#bib.bib21)],
    and GraphSAGE in [[36](#bib.bib36)].
  prefs: []
  type: TYPE_NORMAL
- en: Energy consumption is another concern for 5G network, which is designed to enable
    a denser network with microcells, femtocells and picocells. To better control
    the transmission power, GNN-based power control solutions are proposed in [[66](#bib.bib66),
    [68](#bib.bib68)]. Heterogeneous GNNs (HetGNNs) with a novel parameter sharing
    scheme are proposed for power control in multi-user multi-cell networks [[66](#bib.bib66)].
    Take a step further, the joint optimization problem of user association and power
    control of the downlink is considered in [[68](#bib.bib68)], in which an unsupervised
    GNN is used for power allocation and the Spectral Clustering algorithm is used
    for user association.
  prefs: []
  type: TYPE_NORMAL
- en: Green network management is proposed to improve the energy efficiency. A specific
    problem, the Idle Time Windows (ITWs) prediction, is considered in [[29](#bib.bib29)].
    To capture the spatio-temporal features, a novel Temporal Graph Convolutional
    Network (TGCN) is proposed for learning the network representation, which improves
    the prediction performance. Also for the denser cell sites, the Integrated Access
    and Backhaul (IAB) architecture defined by the 3rd Generation Partnership Project
    (3GPP) is used in [[26](#bib.bib26)]. The IAB topology design is formulated as
    a graph optimization problem and a combination of deep reinforcement learning
    and graph embedding is proposed for solving this problem efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: The integration of satellite-terrestrial networks is proposed for the future
    6G network. In this direction, a High Altitude Platform Station (HAPS) is a network
    node that operates in the stratosphere at an altitude around 20 km and is instrumental
    for providing communication services [[113](#bib.bib113)]. For HAPS, GAT is firstly
    utilized for channel estimation in [[114](#bib.bib114), [62](#bib.bib62)], and
    the proposed GAT estimator outperforms the traditional least square method in
    full-duplex channel estimation and is also robust to hardware imperfections and
    changes in small-scale fading characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: As a softwarized concept, network slicing has been proposed for 5G network,
    using network virtualization to divide single network connection into multiple
    distinct virtual connections that provide services with different Quality-of-Service
    (QoS) requirements. However, the increasing network complexity is becoming a huge
    challenge for deploying network slicing. A scalable Digital Twin (DT) technology
    with GNN is developed in [[34](#bib.bib34)] for mirroring the network behavior
    and predicting the end-to-end latency, which can also be applied in unseen network
    situations. Take a step further, GAT is incorporated into Deep Q Network (DQN)
    for designing an intelligent resource management strategy in [[67](#bib.bib67)],
    which is proven effective through simulations.
  prefs: []
  type: TYPE_NORMAL
- en: Virtual Network Embedding (VNE) is also a softwarized concept, which can be
    used for modeling the resource allocation of 5G network slices. Since the VNE
    problem is NP-hard, heuristic methods and deep learning models are both being
    proposed for this specific problem. Deep Reinforcement Learning (DRL) and GCN
    are combined for solving this problem [[79](#bib.bib79), [52](#bib.bib52)], in
    which the episodic Markov Decision Process is solved by different GCN models.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in the cellular network scenario are listed in Table [6](#S4.T6
    "Table 6 ‣ 4.2 Cellular Network ‣ 4 Wireless Networks ‣ Graph-based Deep Learning
    for Communication Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 6: List of the papers in the cellular network scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Channel Estimation | [[114](#bib.bib114), [62](#bib.bib62)] | GAT-based Estimator
    | GAT [[99](#bib.bib99)] |'
  prefs: []
  type: TYPE_TB
- en: '| Idle Time Windows Prediction | [[29](#bib.bib29)] | TGCN | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Integrated Access and Backhaul Topology Design | [[26](#bib.bib26)] | DRL
    with Graph Embedding | structure2vec [[90](#bib.bib90)] |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling, Network Slicing | [[34](#bib.bib34)] | GNN-based Digital
    Twin | GraphSAGE [[91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '| Network Slicing | [[67](#bib.bib67)] | DQN with GAT | GAT [[99](#bib.bib99)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Power Control | [[66](#bib.bib66)] | Heterogeneous GNNs | HetGAT [[103](#bib.bib103)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Routing | [[23](#bib.bib23)] | GCLR | MPNN [[96](#bib.bib96)] |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[36](#bib.bib36)] | Graph-based TCN | GraphSAGE [[91](#bib.bib91)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[56](#bib.bib56), [37](#bib.bib37)] | GASTN | S-RNN [[102](#bib.bib102)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[21](#bib.bib21)] | DC-STGCN | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| User Association, Power Control | [[68](#bib.bib68)] | Unsupervised Graph
    Model | GraphSAGE [[91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNE | [[79](#bib.bib79), [52](#bib.bib52)] | DRL with GCN | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: 4.3 Other Wireless Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this part, we discuss the other formats of wireless networks, with their
    own challenges and solutions.
  prefs: []
  type: TYPE_NORMAL
- en: The first case is the cognitive radio network, which aims to increase the spectrum
    utilization by secondary users with an opportunistic use of the free spectrum
    that is not used by the primary users. In this scenario, the challenge is to improve
    the resource utilization, without degrading the quality of service (QoS) of primary
    users. To solve this challenge, a joint channel selection and power adaptation
    scheme is proposed in [[46](#bib.bib46)], in which GCN is leveraged to extract
    the crucial interference features. Based on the estimated CSI, a DRL-based framework
    is further used to allocate spectrum resources efficiently.
  prefs: []
  type: TYPE_NORMAL
- en: The second case is the Device-to-Device (D2D) network, which uses the direct
    communication between two users or devices, without traversing the base station
    or router. Without deploying additional infrastructure, D2D network is promising
    for provide communication services with an ultra-low latency. However, there are
    still many challenges for this objective to happen. To minimize the content fetching
    delay in D2D network, the joint optimization of cooperative caching and fetching
    is considered in [[41](#bib.bib41)] and a DRL-based algorithm is proposed. In
    the proposed algorithm, GAT is used for cooperative inter-agent coordination.
    For power control and beamforming in D2D network, an unsupervised learning-based
    framework is proposed in [[88](#bib.bib88)], in which heterogeneous graphs and
    GNNs are used for the characteristics of diversified link features and interference
    relations. Wireless link scheduling is also considered in a series of studies [[61](#bib.bib61),
    [43](#bib.bib43), [65](#bib.bib65)]. Graph embedding based method is proposed
    in [[61](#bib.bib61), [43](#bib.bib43)], in which the graph embedding process
    is based on the distances of both communication and interference links, without
    requiring the accurate CSI. The proposed method manages to reduce the computational
    complexity for the link scheduling problem significantly.
  prefs: []
  type: TYPE_NORMAL
- en: The third case is the Internet of Things (IoT) network, which is designed for
    connecting smart devices, e.g., smart meters, smart light bulbs, connected valves
    and pumps, etc. The application of IoT networks covers a wide range, e.g., smart
    factory, smart agriculture, smart city, etc. The wide application also arises
    a great number of challenges, e.g., resource utilization efficiency, battery limitation
    for computation and communication, and security concerns. Some of these challenges
    can be solved with graph-based methods. One example is the channel estimation
    problem considered in [[114](#bib.bib114)], in which Direct-to-satellite (DtS)
    communication is used for globally connected IoT networks and the high path loss
    must be considered. GAT is proposed as the solution and further used for the reconfigurable
    intelligent surfaces in the considered scenario. Another example is the network
    intrusion detection, which is drawing a growing attention in recent years. GraphSAGE
    is used in [[115](#bib.bib115)] for using the edge features and classifying the
    network flows into benign and attack types. The new solution is proven more effective
    than the state-of-the-art methods on six benchmark datasets. SDN concepts are
    also applied in IoT networks and can be combined with graph-based solutions. NFV-enabled
    Service Function Chain (SFC) is considered in [[28](#bib.bib28)], in which the
    challenge is that SFCs should be dynamically and adaptively reconfigured in order
    to achieve a lower resource consumption and a higher revenue. This problem is
    formulated as a discrete-time Markov decision process and a deep Dyna-Q (DDQ)
    approach is proposed as the solution, in which GNNs are used for predicting available
    virtual network functions (VNFs).
  prefs: []
  type: TYPE_NORMAL
- en: The fourth case is the satellite network, in which the communication between
    satellites are considered. With the growing Low Earth Orbit (LEO) satellites launched
    by commercial companies, e.g., Starlink and OneWeb, satellite networks are drawing
    more attention, with a potential application in both IoT and future 6G networks.
    The traffic prediction problem in the satellite network is considered in [[77](#bib.bib77)],
    in which the spatial dependency of the network topology is captured by GCN and
    the temporal dependency is captured by GRU. The simulation using the satellite
    network traffic shows the combination with GCN improves the performance of the
    single GRU model.
  prefs: []
  type: TYPE_NORMAL
- en: The last case is the vehicular network, which aims to connect the vehicle nodes.
    Vehicular network has been proposed for autonomous driving in future smart cities,
    as an important infrastructure. One challenge is to improve the spectrum allocation
    efficiency. The vehicle-to-everything (V2X) network is considered in [[55](#bib.bib55)],
    in which GNN is used to learn the low-dimensional feature and DRL is used to make
    spectrum allocation decisions. This kind of GNN-DRL combination has already been
    used in similar problems of other network types. Another challenge is to reduce
    the communication latency within vehicular networks, especially in the large-scale
    and fast-moving scenario. To model the communication latency between the vehicle
    and the infrastructure, a graph-based framework named SMART is proposed in [[116](#bib.bib116)],
    in which GCN is combined with a deep Q-networks algorithm to capture the spatial
    and temporal patterns within a limited observation zone. Then the latency performance
    is re-constructed for the whole geographical area.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in other wireless network scenarios are listed in Table [7](#S4.T7
    "Table 7 ‣ 4.3 Other Wireless Networks ‣ 4 Wireless Networks ‣ Graph-based Deep
    Learning for Communication Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 7: List of the papers specified in other wireless network scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Scenario | Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| Cognitive Radio Network | Resource Allocation | [[46](#bib.bib46)] | DRL
    with GCN | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| D2D Network | Cooperative Caching and Fetching | [[41](#bib.bib41)] | FDS-MARL
    | GAT [[99](#bib.bib99)] |'
  prefs: []
  type: TYPE_TB
- en: '| D2D Network | Power Control and Beamforming | [[88](#bib.bib88)] | HIGNN
    | GN [[97](#bib.bib97)] |'
  prefs: []
  type: TYPE_TB
- en: '| D2D Network | Wireless Link Scheduling | [[43](#bib.bib43), [61](#bib.bib61)]
    | Graph Embedding based Method | structure2vec [[90](#bib.bib90)] |'
  prefs: []
  type: TYPE_TB
- en: '| D2D Network | Wireless Link Scheduling | [[65](#bib.bib65)] | Graph Embedding
    based Method | structure2vec [[90](#bib.bib90)] |'
  prefs: []
  type: TYPE_TB
- en: '| IoT Network | Intrusion Detection | [[115](#bib.bib115)] | E-GraphSAGE |
    GraphSAGE [[91](#bib.bib91)] |'
  prefs: []
  type: TYPE_TB
- en: '| IoT Network | Service Function Chain Dynamic Reconfiguration | [[28](#bib.bib28)]
    | Deep Dyna-Q Approach | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| Satellite Network | Traffic Prediction | [[77](#bib.bib77)] | GCN-GRU | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Vehicular Network | Communication Latency Modeling | [[116](#bib.bib116)]
    | SMART Framework | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| Vehicular Network | Spectrum Allocation | [[55](#bib.bib55)] | DQN with GNN
    | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: 5 Wired Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For wired networks, we mainly refer to the computer networks that are connected
    with cables, such as laptop or desktop computers. A typical example is the Ethernet
    network. In this section, we first discuss the graph-based studies in the wired
    network scenario from five aspects, namely, network modeling, network configuration,
    network prediction, network management, and network security. Then three special
    cases are further discussed, i.e., blockchain platform, data center network, and
    optical network.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs are suitable for network modeling as the computer networks are often modeled
    as graphs. With the growing trend of contemporary Internet, it becomes more and
    more challenging to understand the overall network topology, the architecture
    and different elements of the networks, and their configurations. To solve this
    challenge, GNNs are proposed for network modeling. They are not only used to reconstruct
    the existing networks, but also used to model the non-existing networks, in order
    to provide an estimation of the unseen cases for network operators to make better
    network deployment decisions in the future. By modeling networks, the estimation
    of different end-to-end metrics are concerned in surveyed studies, given the input
    network topology, routing scheme and traffic matrices of the network, in a supervised [[48](#bib.bib48),
    [78](#bib.bib78), [117](#bib.bib117), [45](#bib.bib45)] or semi-supervised [[71](#bib.bib71)]
    way. Delay and jitter are considered in [[48](#bib.bib48), [78](#bib.bib78), [117](#bib.bib117),
    [71](#bib.bib71)], while the throughput of TCP flows and the end-to-end latency
    of UDP flows are considered in [[45](#bib.bib45)]. Different GNNs are used for
    the network modeling purpose, including GGS-NN in [[45](#bib.bib45)], MPNN in [[48](#bib.bib48),
    [78](#bib.bib78)], GN and GNN in [[117](#bib.bib117)], and GCN in [[71](#bib.bib71)].
    GNNs are also used for network calculus analysis in [[53](#bib.bib53), [38](#bib.bib38),
    [64](#bib.bib64)].
  prefs: []
  type: TYPE_NORMAL
- en: Based on the modeling ability of GNNs, they are further proposed for network
    configuration feasibility analysis or decision. Based on the prediction of ensemble
    GNN model, different network configurations are evaluated in [[76](#bib.bib76)],
    bound to the deadline constraints. Border Gateway Protocol (BGP) configuration
    synthesis is considered in [[86](#bib.bib86)], which is the standard inter-domain
    routing protocol to exchange reachability information among Wide Area Networks
    (WANs). GNN is adopted to represent the network topology with partial network
    configuration in a system named DeepBGP, which is further validated for both Huawei
    and Cisco devices while fulfilling operator requirements. Another relevant study
    is to use GNN for Multiprotocol Label Switching (MPLS) configuration analysis.
    A GNN-based solution named DeepMPLS is proposed in [[69](#bib.bib69)] to speed
    up the analysis of network properties as well as to suggest configuration changes
    in case a network property is not satisfied. The GNN-based solution manages to
    achieve low execution times and high accuracies in real-world network topologies.
  prefs: []
  type: TYPE_NORMAL
- en: GNNs can also be used for network prediction, e.g., delay prediction [[27](#bib.bib27)]
    and traffic prediction [[47](#bib.bib47), [59](#bib.bib59), [118](#bib.bib118)].
    The better prediction is the basis of proactive management. A case study of delay
    prediction in queuing networks is conducted in [[27](#bib.bib27)], which uses
    MPNN for topology representation and network operation. Several studies are concerned
    about data-driven traffic prediction, based on the real-world network traffic
    data and GNN-based solutions. A framework named Spatio-temporal Graph Convolutional
    Recurrent Network (SGCRN) is proposed in [[47](#bib.bib47)], which combines GCN
    and GRU and is validated on the network traffic data from four real IP backbone
    networks. Another framework named Multi-scale Spatial-temporal Graph Neural Network
    (MSTNN) is proposed for Origin-Destination Traffic Prediction (ODTP) and two real-world
    datasets are used for evaluation [[59](#bib.bib59)]. Inspired by the prediction
    model DCRNN [[101](#bib.bib101)] developed for road traffic, a nonautoregressive
    graph-based neural network is used in [[118](#bib.bib118)] for network traffic
    prediction and evaluated on the U.S. Department of Energy’s dedicated science
    network.
  prefs: []
  type: TYPE_NORMAL
- en: Network prediction results can be used further for network operation optimization
    and management [[119](#bib.bib119)], e.g., traffic engineering, load balancing,
    routing, etc. For the time point of preparing this survey, routing is considered
    with graph-based deep learning models [[85](#bib.bib85), [87](#bib.bib87)]. Instead
    of using reinforcement learning, a novel semi-supervised architecture named Graph-Query
    Neural Network is proposed in [[85](#bib.bib85)] for shortest path and max-min
    routing. Another graph-based framework named NGR is proposed in [[87](#bib.bib87)]
    for shortest-path routing and load balancing. These graph-based routing solutions
    are validated with use-cases and show high accuracies and resilience to packet
    loss.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not the least, graph-based deep learning solutions are used for network
    security problems in computer networks [[81](#bib.bib81), [24](#bib.bib24)]. Automatic
    detection for Botnets, which is the source of DDoS attacks and spam, is considered
    in [[81](#bib.bib81)]. GNN is used to detect the patterns hidden in the botnet
    connections and is proven more effective than non-learning methods. Their dataset
    is also made available for future studies. In another study, intrusion detection
    is considered [[24](#bib.bib24)]. A GCN-based framework named Alert-GCN is proposed
    to solve the intrusion alert problem as a node classification task. The alert
    graph is built with the alert information from farther neighbors, which is used
    as the input for the GCN module. The experiments demonstrate that Alert-GCN outperforms
    traditional classification models in correlating alerts.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in the wired network scenario are listed in Table [8](#S5.T8
    "Table 8 ‣ 5 Wired Networks ‣ Graph-based Deep Learning for Communication Networks:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 8: List of the papers in the wired network scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| BGP Configuration Synthesis | [[86](#bib.bib86)] | DeepBGP | GraphSAGE [[91](#bib.bib91)],
    GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| Botnet Detection | [[81](#bib.bib81)] | GNN Approach | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Communication Delay Estimation | [[71](#bib.bib71)] | GNNs with Semi-supervised
    Learning | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| Delay Prediction | [[27](#bib.bib27)] | Message-passing Neural Networks |
    MPNN [[96](#bib.bib96)] |'
  prefs: []
  type: TYPE_TB
- en: '| Intrusion Detection | [[24](#bib.bib24)] | Alert-GCN | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| MPLS Configuration Analysis | [[69](#bib.bib69)] | DeepMPLS | GNN [[89](#bib.bib89)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Network Calculus Analysis | [[53](#bib.bib53), [38](#bib.bib38), [64](#bib.bib64)]
    | DL-assisted Tandem Matching Analysis | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| Network Configuration Feasibility | [[76](#bib.bib76)] | Ensemble GNN Model
    | GN [[97](#bib.bib97)] |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling | [[48](#bib.bib48)] | RouteNet | MPNN [[96](#bib.bib96)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling | [[78](#bib.bib78)] | Extended RouteNet | MPNN [[96](#bib.bib96)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling | [[117](#bib.bib117)] | Graph-based DL | GN [[97](#bib.bib97)],
    GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling | [[45](#bib.bib45)] | DeepComNet | GGS-NN [[100](#bib.bib100)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Routing | [[85](#bib.bib85)] | Graph-Query Neural Network | GNN [[89](#bib.bib89)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Routing and Load Balancing | [[87](#bib.bib87)] | DL-based Distributed Routing
    | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[47](#bib.bib47)] | SGCRN | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[59](#bib.bib59)] | MSTNN | GAT [[99](#bib.bib99)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Prediction | [[118](#bib.bib118)] | Nonautoregressive Graph-based
    Neural Network | DCRNN [[101](#bib.bib101)] |'
  prefs: []
  type: TYPE_TB
- en: Other than the general computer network case, three specific network cases are
    discussed with graph-based methods.
  prefs: []
  type: TYPE_NORMAL
- en: The first case is the blockchain platform, which is well-known by the public
    thanks to Bitcoin, the most famous cryptocurrency. Generally speaking, the blockchain
    is a chain of blocks that store information with digital signatures in a decentralized
    and distributed network, which has a wide range of applications other than digital
    cryptocurrencies, e.g., financial and social services, risk management, healthcare
    facilities, etc [[120](#bib.bib120)]. A specific task of encrypted traffic classification
    is considered in [[35](#bib.bib35)] for Decentralized Applications (DApps). A
    GNN-based DApp fingerprinting method named GraphDApp is proposed for this task
    and a novel graph structure named Traffic Interaction Graph (TIG) is constructed
    as the representation of encrypted DApp flows as well as the input for GNNs. Real-world
    traffic datasets from 1,300 DApps with more than 169,000 flows are used for experiments,
    of which the result shows that GraphDApp is superior to the other state-of-the-art
    methods in terms of classification accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: The second case is the data center network, which connects all data centers
    to share data or computation abilities. Nowadays, data centers are heavily used
    for cloud services. In such circumstances, traffic engineering is becoming more
    and more important for the data center network to avoid traffic congestion and
    improve routing efficiency. However, this task is still challenging, especially
    when the network topology changes. In a recent study [[20](#bib.bib20)], the generalization
    ability of GNNs is used for predicting Flow Completion Time (FCT) and a GNN-based
    optimizer is further designed for flow routing, flow scheduling and topology management.
    The experiments demonstrate both the high inference accuracy and the FCT reduction
    ability of GNNs.
  prefs: []
  type: TYPE_NORMAL
- en: The last case is the optical network, which uses light signals, instead of electronic
    ones, to send information between two or more points. There are many unique problems
    when light signals are used for communication, e.g., wavelength assignment. The
    optimal resource allocation in a special network type, i.e., Free Space Optical
    (FSO) fronthaul network, is considered in [[121](#bib.bib121)] and GNNs are used
    for evaluating and choosing the resource allocation policy. The routing optimization
    for an Optical Transport Network (OTN) scenario is considered in [[122](#bib.bib122)]
    and the learning and generalization capabilities of GNNs are combined with DRL
    for routing in unseen network typologies. Similar to cellular and computer networks,
    traffic prediction is also considered in the optical network scenario [[80](#bib.bib80)],
    with the solution combined by GCN and GRU.
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in other wired network scenarios are listed in Table [9](#S5.T9
    "Table 9 ‣ 5 Wired Networks ‣ Graph-based Deep Learning for Communication Networks:
    A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 9: List of the papers specified in other wired network scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Scenario | Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| Blockchain Platform | Encrypted Traffic Classification | [[35](#bib.bib35)]
    | GNN-based DApps Fingerprinting | GIN [[98](#bib.bib98)] |'
  prefs: []
  type: TYPE_TB
- en: '| Data Center Network | Traffic Optimization | [[20](#bib.bib20)] | GNN-based
    Optimizer | GN [[97](#bib.bib97)] |'
  prefs: []
  type: TYPE_TB
- en: '| Optical Network | Resource Allocation | [[121](#bib.bib121)] | GNN | GNN [[93](#bib.bib93)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Optical Network | Routing | [[122](#bib.bib122)] | DRL with GNN | MPNN [[96](#bib.bib96)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Optical Network | Traffic Prediction | [[80](#bib.bib80)] | GCN-GRU | GCN [[95](#bib.bib95)]
    |'
  prefs: []
  type: TYPE_TB
- en: 6 Software Defined Networks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: SDN emerges as the most promising solution for bringing a revolution in how
    networks are built. Based on the white paper released by the Open Networking Foundation
    (ONF), the explosion of mobile devices and content, server virtualization, and
    advent of cloud services are among the trends driving the networking industry
    to reexamine traditional network architectures ⁵⁵5[https://opennetworking.org/sdn-resources/whitepapers/software-defined-networking-the-new-norm-for-networks/](https://opennetworking.org/sdn-resources/whitepapers/software-defined-networking-the-new-norm-for-networks/).
    While SDN was proposed back to 1996, its concept has gone through a lot of changes
    ever since then. Based on the a widely used definition in [[123](#bib.bib123)],
    in the SDN architecture, the control and data planes are decoupled, network intelligence
    and state are logically centralized, and the underlying network infrastructure
    is abstracted from the applications.
  prefs: []
  type: TYPE_NORMAL
- en: The central control ability of SDN becomes the basis of network optimization
    in many scenarios and arises several problems which are in the scope of graph-based
    deep learning methods. Based on the surveyed studies in this paper, there is a
    growing trend of using GNNs with SDN, or the SDN concept in specific network scenarios.
    The benefits of this combination are two-folds. For GNNs, SDN provides the ability
    of measuring network performance, which is used as the data for training GNNs.
    For SDN, GNNs act as the best option of using the network topology information
    in modeling and optimizing the networks. In recent years, many graph-based solutions
    are proposed for various problems with the SDN concept.
  prefs: []
  type: TYPE_NORMAL
- en: Based on topology, routing, and input traffic, MPNN-based network models are
    proven to produce accurate estimates of the per-source/destination per-packet
    delay distribution and loss, with a worst Mean Relative Error (MRE) of 15.4%,
    and the estimation can be further used for efficient routing optimization and
    network planning [[49](#bib.bib49), [30](#bib.bib30)]. The decoupling of the control
    plane and data plane gives more computing power for routing optimization. Based
    on this observation, an intelligent routing strategy based on graph-aware neural
    networks is designed in [[33](#bib.bib33)], in which a novel graph-aware convolution
    structure is constructed to learn topological information efficiently. In another
    study for routing optimization, a GN-based solution is proposed for maximum bandwidth
    utilization, which achieves a satisfactory accuracy and a prediction time 150
    times faster than Genetic Algorithm (GA) [[70](#bib.bib70)].
  prefs: []
  type: TYPE_NORMAL
- en: In SDN, network virtualization is a powerful way to efficient utilize the network
    infrastructure. Virtual Network Functions (VNFs) are virtualized network services
    running on physical resources. How to map VNFs into shared substrate networks
    has become a challenging problem in SDN, known as Virtual Network Embedding (VNE)
    or VNF placement, which is already proven to be NP-hard. To efficiently solve
    this problem, a bunch of heuristic algorithms are proposed in the literature.
    Recently, graph-based models have also been used for this problem [[75](#bib.bib75),
    [39](#bib.bib39), [73](#bib.bib73), [44](#bib.bib44), [74](#bib.bib74), [50](#bib.bib50),
    [25](#bib.bib25)], which can get near-optimal solutions in a short time. To predict
    future resource requirements for VNFs, a GNN-based algorithm using the VNF forwarding
    graph topology information is proposed in [[75](#bib.bib75), [39](#bib.bib39)].
    Deployed in a virtualized IP multimedia subsystem and tested with real VoIP traffic
    traces, the new algorithm achieves an average prediction accuracy of 90% and improves
    the call setup latency by over 29%, compared with the case without using GNNs.
    A parallelizable VNE solution based on spatial GNNs is proposed for accelerating
    the embedding process in [[74](#bib.bib74)], which improves the revenue-to-cost
    ratio by about 18%, compared to other simulated algorithms. Similarly, GNN-based
    algorithms are proposed for VNF resource prediction and management in a series
    of studies [[73](#bib.bib73), [44](#bib.bib44), [50](#bib.bib50)]. On another
    aspect, DRL is often combined with GNNs for automatic virtual network embedding [[54](#bib.bib54),
    [31](#bib.bib31), [60](#bib.bib60), [19](#bib.bib19)]. Asynchronous DRL enhanced
    GNN is proposed in [[54](#bib.bib54)] for topology-aware VNF resource prediction
    in dynamic environments. An efficient algorithm combining DRL with GCN is proposed
    in [[31](#bib.bib31)], with up to 39.6% and 70.6% improvement on acceptance ratio
    and average revenue, compared with the existing state-of-the-art solutions. A
    more specific problem, i.e., traffic flow migration among different network function
    instances, is considered in [[60](#bib.bib60), [19](#bib.bib19)], in which GNN
    is used for migration latency modeling and DRL is used for deploying dynamic and
    effective flow migration policies.
  prefs: []
  type: TYPE_NORMAL
- en: Last but not the least, Service Function Chaining (SFC) is considered in several
    studies [[124](#bib.bib124), [51](#bib.bib51), [72](#bib.bib72), [63](#bib.bib63)].
    SFC uses SDN’s programmability to create a service chain of connected virtual
    network services, resulting in a service function path that provides an end-to-end
    chain and traffic steering through them. Graph-structured properties of network
    topology can be extracted by GNNs, which outperforms DNNs for SFC [[51](#bib.bib51),
    [72](#bib.bib72)]. However, most of the existing studies for SFC use a supervised
    learning approach, which may not be suitable for dynamic VNF resources, various
    requests, and changes of topologies. To solve this problem, DRL is applied for
    training models on various network topologies with unlabeled data in [[124](#bib.bib124)]
    and achieves remarkable flexibility in new topologies without re-designing and
    re-training, while preserving a similar level of performance compared to the supervised
    learning method. DRL is also used for adaptive SFC placement to maximize the long-term
    average revenue [[63](#bib.bib63)].
  prefs: []
  type: TYPE_NORMAL
- en: 'To sum up, the papers in the SDN scenario are listed in Table [10](#S6.T10
    "Table 10 ‣ 6 Software Defined Networks ‣ Graph-based Deep Learning for Communication
    Networks: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 10: List of the papers in the SDN scenario.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Problem | Paper | Solution | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Network Modeling | [[49](#bib.bib49), [30](#bib.bib30)] | RouteNet | MPNN [[96](#bib.bib96)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Routing | [[33](#bib.bib33)] | Revised Graph-aware Neural Networks | A Novel
    Graph-aware Convolution Structure |'
  prefs: []
  type: TYPE_TB
- en: '| Routing Optimization, Bandwidth Utilization Maximization | [[70](#bib.bib70)]
    | GN-based Model | GN [[97](#bib.bib97)] |'
  prefs: []
  type: TYPE_TB
- en: '| SFC | [[124](#bib.bib124)] | DRL with GNN | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| SFC | [[51](#bib.bib51)] | GNN-based SFC | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| SFC Deployment, Traffic Steering | [[72](#bib.bib72)] | Knowledge-Defined
    Networking System with GNN | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| SFC Placement | [[63](#bib.bib63)] | DRL-SFCP | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| Traffic Flow Migration in NFV | [[60](#bib.bib60), [19](#bib.bib19)] | DRL
    with GNN | GN [[97](#bib.bib97)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNE | [[74](#bib.bib74)] | GraphViNE Solution | GraphSAGE [[91](#bib.bib91)],
    GE [[92](#bib.bib92)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNE | [[31](#bib.bib31)] | DRL with GCN | GCN [[95](#bib.bib95)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNF Deployment Prediction | [[73](#bib.bib73), [44](#bib.bib44)] | GNN-based
    Algorithm | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNF Management | [[50](#bib.bib50)] | GNN-based Algorithm | GNN [[89](#bib.bib89)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| VNF Placement | [[25](#bib.bib25)] | DRL with GNN | GN [[97](#bib.bib97)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| VNF Resource Prediction | [[54](#bib.bib54)] | Asynchronous DRL enhanced
    GNN | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: '| VNF Resource Prediction | [[75](#bib.bib75), [39](#bib.bib39)] | GNN-based
    Algorithm | GNN [[89](#bib.bib89)] |'
  prefs: []
  type: TYPE_TB
- en: 7 Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss some future directions for graph-based deep learning
    in communication networks. Even though different network scenarios and applications
    are already covered in this survey, there are still many open research opportunities
    for this topic.
  prefs: []
  type: TYPE_NORMAL
- en: The first research direction is the combination of GNNs and other artificial
    intelligence techniques. Some examples are already seen in this survey, e.g.,
    the combination of GNN and GRU for traffic prediction [[77](#bib.bib77), [80](#bib.bib80)],
    the combination of GNN and DRL for resource allocation [[46](#bib.bib46)], routing [[122](#bib.bib122)],
    and VNE [[31](#bib.bib31)]. The advantages of GNNs include its learning ability
    for topological dependencies and the generalization capability for unseen network
    typologies, but GNN is not a panacea. For example, for some cases which is lack
    of training data or is too expensive to collect real data, Generative Adversarial
    Nets (GANs) [[125](#bib.bib125)] is a possible solution. Even though GANs have
    been widely used in other fields, e.g., image and video, the combination of GANs
    and GNNs [[126](#bib.bib126)] has not been applied for communication networks,
    at least in the scope of this survey. Another example is the Automated Machine
    Learning (AutoML) technique [[127](#bib.bib127)], which can be used for optimizing
    the GNN parameters automatically.
  prefs: []
  type: TYPE_NORMAL
- en: Another research direction is to apply graph-based deep learning on larger networks.
    In most of the surveyed studies, the network topology is small, e.g., less than
    100 nodes, compared with contemporary networks. However, the modeling of larger
    networks would require huge computation requirements. Graph partitioning and parallel
    computing infrastructures are two possible solutions for this problem. A larger
    network may be decomposed into smaller ones that is within the computing capacity.
    However, the optimal divide-and-conquer approach remains unknown and may vary
    in different network scenarios. Another concern is that whether it is worthy of
    achieving narrow performance margins in the cost of the increased computation
    burden caused by graph-based models, compared with traditional methods.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, we believe this is still an early stage of the research about graph-based
    deep learning for communication networks. There are many opportunities of applying
    novel GNNs in traditional networking problems in a wider range of network scenarios,
    especially those who get little or no attention for now. The studies covered in
    this survey are only the beginning of this exciting research area. And we would
    keep track of this area and update the progress and new publications in the public
    Github repository.
  prefs: []
  type: TYPE_NORMAL
- en: 8 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this paper, a survey is presented for the application of graph-based deep
    learning in communication networks. The relevant studies are organized in three
    network scenarios, namely, wireless networks, wired networks, and software defined
    networks. For each study, the problem and GNN-based solution are listed in this
    survey. Future directions are further pointed out for the follow-up research.
    We hope this survey could be the milestone of summarizing the latest progresses
    and a reference manual for new-comers in this emerging research topic.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] I. Goodfellow, Y. Bengio, A. Courville, Y. Bengio, Deep learning, Vol. 1,
    MIT press Cambridge, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition,
    in: Proceedings of the IEEE conference on computer vision and pattern recognition,
    2016, pp. 770–778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] W. Jiang, L. Zhang, Geospatial data to images: A deep-learning framework
    for traffic forecasting, Tsinghua Science and Technology 24 (1) (2018) 52–64.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] T. Young, D. Hazarika, S. Poria, E. Cambria, Recent trends in deep learning
    based natural language processing, ieee Computational intelligenCe magazine 13 (3)
    (2018) 55–75.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] W. Jiang, Applications of deep learning in stock market prediction: recent
    progress, Expert Systems with Applications (2021) 115537.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] W. Jiang, Time series classification: Nearest neighbor versus deep learning
    models, SN Applied Sciences 2 (4) (2020) 1–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] A. Zappone, M. Di Renzo, M. Debbah, Wireless networks design in the era
    of deep learning: Model-based, ai-based, or both?, IEEE Transactions on Communications
    67 (10) (2019) 7331–7376.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] C. Zhang, P. Patras, H. Haddadi, Deep learning in mobile and wireless networking:
    A survey, IEEE Communications surveys & tutorials 21 (3) (2019) 2224–2287.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] J. Wang, C. Jiang, H. Zhang, Y. Ren, K.-C. Chen, L. Hanzo, Thirty years
    of machine learning: The road to pareto-optimal wireless networks, IEEE Communications
    Surveys & Tutorials 22 (3) (2020) 1472–1514.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] M. Abbasi, A. Shahraki, A. Taherkordi, Deep learning for network traffic
    monitoring and analysis (ntma): A survey, Computer Communications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, S. Y. Philip, A comprehensive
    survey on graph neural networks, IEEE Transactions on Neural Networks and Learning
    Systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] J. Zhou, G. Cui, S. Hu, Z. Zhang, C. Yang, Z. Liu, L. Wang, C. Li, M. Sun,
    Graph neural networks: A review of methods and applications, AI Open 1 (2020)
    57–81.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Z. Zhang, P. Cui, W. Zhu, Deep learning on graphs: A survey, IEEE Transactions
    on Knowledge and Data Engineering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] F. Xia, K. Sun, S. Yu, A. Aziz, L. Wan, S. Pan, H. Liu, Graph learning:
    A survey, IEEE Transactions on Artificial Intelligence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] L. Ruiz, F. Gama, A. Ribeiro, Graph neural networks: Architectures, stability,
    and transferability, Proceedings of the IEEE 109 (5) (2021) 660–682.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] W. Jiang, J. Luo, Graph neural network for traffic forecasting: A survey,
    arXiv preprint arXiv:2101.11174.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] P. Sun, Z. Guo, J. Wang, J. Li, J. Lan, Y. Hu, Deepweave: Accelerating
    job completion time with deep reinforcement learning-based coflow scheduling,
    in: Proceedings of the Twenty-Ninth International Conference on International
    Joint Conferences on Artificial Intelligence, 2021, pp. 3314–3320.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] S. He, S. Xiong, Y. Ou, J. Zhang, J. Wang, Y. Huang, Y. Zhang, An overview
    on the application of graph neural networks in wireless networks, IEEE Open Journal
    of the Communications Society 2 (2021) 2547–2565.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] P. Sun, J. Lan, J. Li, Z. Guo, Y. Hu, T. Hu, Efficient flow migration
    for nfv with graph-aware deep reinforcement learning, Computer Networks 183 (2020)
    107575.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] J. Li, P. Sun, Y. Hu, Traffic modeling and optimization in datacenters
    with graph neural network, Computer Networks 181 (2020) 107528.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] C. Pan, J. Zhu, Z. Kong, H. Shi, W. Yang, Dc-stgcn: Dual-channel based
    graph convolutional networks for network traffic forecasting, Electronics 10 (9)
    (2021) 1014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] K. Nakashima, S. Kamiya, K. Ohtsu, K. Yamamoto, T. Nishio, M. Morikura,
    Deep reinforcement learning-based channel allocation for wireless lans with graph
    convolutional networks, IEEE Access 8 (2020) 31823–31834.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] T. Zhu, X. Chen, L. Chen, W. Wang, G. Wei, Gclr: Gnn-based cross layer
    optimization for multipath tcp by routing, IEEE Access 8 (2020) 17060–17070.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Q. Cheng, C. Wu, S. Zhou, Discovering attack scenarios via intrusion alert
    correlation using graph convolutional networks, IEEE Communications Letters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] P. Sun, J. Lan, J. Li, Z. Guo, Y. Hu, Combining deep reinforcement learning
    with graph neural networks for optimal vnf placement, IEEE Communications Letters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] M. Simsek, O. Orhan, M. Nassar, O. Elibol, H. Nikopour, Iab topology design:
    A graph embedding and deep reinforcement learning approach, IEEE Communications
    Letters.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] K. Rusek, P. Chołda, Message-passing neural networks learn little’s law,
    IEEE Communications Letters 23 (2) (2018) 274–277.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Y. Liu, Y. Lu, X. Li, Z. Yao, D. Zhao, On dynamic service function chain
    reconfiguration in iot networks, IEEE Internet of Things Journal 7 (11) (2020)
    10969–10984.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] L. Fang, X. Cheng, H. Wang, L. Yang, Idle time window prediction in cellular
    networks with deep spatiotemporal modeling, IEEE Journal on Selected Areas in
    Communications 37 (6) (2019) 1441–1454.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] K. Rusek, J. Suárez-Varela, P. Almasan, P. Barlet-Ros, A. Cabellos-Aparicio,
    Routenet: Leveraging graph neural networks for network modeling and optimization
    in sdn, IEEE Journal on Selected Areas in Communications 38 (10) (2020) 2260–2270.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Z. Yan, J. Ge, Y. Wu, L. Li, T. Li, Automatic virtual network embedding:
    A deep reinforcement learning approach with graph convolutional networks, IEEE
    Journal on Selected Areas in Communications 38 (6) (2020) 1040–1057.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Y. Shen, Y. Shi, J. Zhang, K. B. Letaief, Graph neural networks for scalable
    radio resource management: Architecture design and theoretical analysis, IEEE
    Journal on Selected Areas in Communications 39 (1) (2020) 101–115.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Z. Zhuang, J. Wang, Q. Qi, H. Sun, J. Liao, Toward greater intelligence
    in route planning: A graph-aware deep learning approach, IEEE Systems Journal
    14 (2) (2019) 1658–1669.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] H. Wang, Y. Wu, G. Min, W. Miao, A graph neural network-based digital
    twin for network slicing management, IEEE Transactions on Industrial Informatics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] M. Shen, J. Zhang, L. Zhu, K. Xu, X. Du, Accurate decentralized application
    identification via encrypted traffic analysis using graph neural networks, IEEE
    Transactions on Information Forensics and Security 16 (2021) 2367–2380.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] F. Sun, P. Wang, J. Zhao, N. Xu, J. Zeng, J. Tao, K. Song, C. Deng, J. C.
    Lui, X. Guan, Mobile data traffic prediction by exploiting time-evolving user
    mobility patterns, IEEE Transactions on Mobile Computing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] K. He, X. Chen, Q. Wu, S. Yu, Z. Zhou, Graph attention spatial-temporal
    network with collaborative global-local learning for citywide mobile traffic prediction,
    IEEE Transactions on Mobile Computing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] F. Geyer, S. Bondorf, Graph-based deep learning for fast and tight network
    calculus analyses, IEEE Transactions on Network Science and Engineering.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] R. Mijumbi, S. Hasija, S. Davy, A. Davy, B. Jennings, R. Boutaba, Topology-aware
    prediction of virtual network function resource requirements, IEEE Transactions
    on Network and Service Management 14 (1) (2017) 106–120.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] M. Eisen, A. Ribeiro, Optimal wireless resource allocation with random
    edge graph neural networks, IEEE Transactions on Signal Processing 68 (2020) 2977–2991.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Y. Yan, B. Zhang, C. Li, C. Su, Cooperative caching and fetching in d2d
    communications-a fully decentralized multi-agent reinforcement learning approach,
    IEEE Transactions on Vehicular Technology 69 (12) (2020) 16095–16109.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] A. Chowdhury, G. Verma, C. Rao, A. Swami, S. Segarra, Unfolding wmmse
    using graph neural networks for efficient power allocation, IEEE Transactions
    on Wireless Communications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] M. Lee, G. Yu, G. Y. Li, Graph embedding based wireless link scheduling
    with few training samples, IEEE Transactions on Wireless Communications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] H.-G. Kim, S. Park, S. Lange, D. Lee, D. Heo, H. Choi, J.-H. Yoo, J. W.-K.
    Hong, Graph neural network-based virtual network function deployment optimization,
    International Journal of Network Management (2021) e2164.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] F. Geyer, Deepcomnet: Performance evaluation of network topologies using
    graph-based deep learning, Performance Evaluation 130 (2019) 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] D. Zhao, H. Qin, B. Song, B. Han, X. Du, M. Guizani, A graph convolutional
    network-based deep reinforcement learning approach for resource allocation in
    a cognitive radio network, Sensors 20 (18) (2020) 5216.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] J. Zhao, H. Qu, J. Zhao, H. Dai, D. Jiang, Spatiotemporal graph convolutional
    recurrent networks for traffic matrix prediction, Transactions on Emerging Telecommunications
    Technologies 31 (11) (2020) e4056.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] J. Suárez-Varela, S. Carol-Bosch, K. Rusek, P. Almasan, M. Arias, P. Barlet-Ros,
    A. Cabellos-Aparicio, Challenging the generalization capabilities of graph neural
    networks for network modeling, in: Proceedings of the ACM SIGCOMM 2019 Conference
    Posters and Demos, 2019, pp. 114–115.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] K. Rusek, J. Suárez-Varela, A. Mestres, P. Barlet-Ros, A. Cabellos-Aparicio,
    Unveiling the potential of graph neural networks for network modeling and optimization
    in sdn, in: Proceedings of the 2019 ACM Symposium on SDN Research, 2019, pp. 140–151.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] H.-G. Kim, S. Park, S. Lange, D. Lee, D. Heo, H. Choi, J.-H. Yoo, J. W.-K.
    Hong, Graph neural network-based virtual network function management, in: 2020
    21st Asia-Pacific Network Operations and Management Symposium (APNOMS), IEEE,
    2020, pp. 13–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] D. Heo, S. Lange, H.-G. Kim, H. Choi, Graph neural network based service
    function chaining for automatic network control, in: 2020 21st Asia-Pacific Network
    Operations and Management Symposium (APNOMS), IEEE, 2020, pp. 7–12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] A. Rkhami, Y. Hadjadj-Aoul, A. Outtagarts, Learn to improve: A novel deep
    reinforcement learning approach for beyond 5g network slicing, in: 2021 IEEE 18th
    Annual Consumer Communications & Networking Conference (CCNC), IEEE, 2021, pp.
    1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] F. Geyer, S. Bondorf, Deeptma: Predicting effective contention models
    for network calculus using graph neural networks, in: IEEE INFOCOM 2019-IEEE Conference
    on Computer Communications, IEEE, 2019, pp. 1009–1017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] N. Jalodia, S. Henna, A. Davy, Deep reinforcement learning for topology-aware
    vnf resource prediction in nfv environments, in: 2019 IEEE Conference on Network
    Function Virtualization and Software Defined Networks (NFV-SDN), IEEE, 2019, pp.
    1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Z. He, L. Wang, H. Ye, G. Y. Li, B.-H. F. Juang, Resource allocation based
    on graph neural networks in vehicular communications, in: GLOBECOM 2020-2020 IEEE
    Global Communications Conference, IEEE, 2020, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] K. He, Y. Huang, X. Chen, Z. Zhou, S. Yu, Graph attention spatial-temporal
    network for deep learning based mobile traffic prediction, in: 2019 IEEE Global
    Communications Conference (GLOBECOM), IEEE, 2019, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] A. Chowdhury, G. Verma, C. Rao, A. Swami, S. Segarra, Efficient power
    allocation using graph neural networks and deep algorithm unfolding, in: ICASSP
    2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP), IEEE, 2021, pp. 4725–4729.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M. Eisen, A. Ribeiro, Transferable policies for large scale wireless networks
    with graph neural networks, in: ICASSP 2020-2020 IEEE International Conference
    on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2020, pp. 5040–5044.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] C. Yang, Z. Zhou, H. Wen, L. Zhou, Mstnn: A graph learning based method
    for the origin-destination traffic prediction, in: ICC 2020-2020 IEEE International
    Conference on Communications (ICC), IEEE, 2020, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] P. Sun, J. Lan, Z. Guo, D. Zhang, X. Chen, Y. Hu, Z. Liu, Deepmigration:
    Flow migration for nfv with graph-based deep reinforcement learning, in: ICC 2020-2020
    IEEE International Conference on Communications (ICC), IEEE, 2020, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] M. Lee, G. Yu, G. Y. Li, Wireless link scheduling for d2d communications
    with graph embedding technique, in: ICC 2020-2020 IEEE International Conference
    on Communications (ICC), IEEE, 2020, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] K. Tekbıyık, G. K. Kurt, C. Huang, A. R. Ekti, H. Yanikomeroglu, Channel
    estimation for full-duplex ris-assisted haps backhauling with graph attention
    networks, in: ICC 2021-2021 IEEE International Conference on Communications (ICC),
    IEEE, 2021, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] T. Wang, Q. Fan, X. Li, X. Zhang, Q. Xiong, S. Fu, M. Gao, Drl-sfcp: Adaptive
    service function chains placement with deep reinforcement learning, in: ICC 2021-2021
    IEEE International Conference on Communications (ICC), IEEE, 2021, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] F. Geyer, S. Bondorf, On the robustness of deep learning-predicted contention
    models for network calculus, in: 2020 IEEE Symposium on Computers and Communications
    (ISCC), IEEE, 2020, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] J. Fu, N. Ma, M. Ye, M. Lee, G. Yu, Wireless d2d network link scheduling
    based on graph embedding, in: 2020 IEEE 92nd Vehicular Technology Conference (VTC2020-Fall),
    IEEE, 2020, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. Guo, C. Yang, Learning power control for cellular systems with heterogeneous
    graph neural network, in: 2021 IEEE Wireless Communications and Networking Conference
    (WCNC), IEEE, 2021, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] Y. Shao, R. Li, Z. Zhao, H. Zhang, Graph attention network-based drl for
    network slicing management in dense cellular networks, in: 2021 IEEE Wireless
    Communications and Networking Conference (WCNC), IEEE, 2021, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] K. Hou, Q. Xu, X. Zhang, Y. Huang, L. Yang, User association and power
    allocation based on unsupervised graph model in ultra-dense network, in: 2021
    IEEE Wireless Communications and Networking Conference (WCNC), IEEE, 2021, pp.
    1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] F. Geyer, S. Schmid, Deepmpls: fast analysis of mpls configurations using
    deep learning, in: 2019 IFIP Networking Conference (IFIP Networking), IEEE, 2019,
    pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] K. Sawada, D. Kotani, Y. Okabe, Network routing optimization based on
    machine learning using graph networks robust against topology change, in: 2020
    International Conference on Information Networking (ICOIN), IEEE, 2020, pp. 608–615.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] T. Suzuki, Y. Yasuda, R. Nakamura, H. Ohsaki, On estimating communication
    delays using graph convolutional networks with semi-supervised learning, in: 2020
    International Conference on Information Networking (ICOIN), IEEE, 2020, pp. 481–486.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] A. Rafiq, T. A. Khan, M. Afaq, W.-C. Song, Service function chaining and
    traffic steering in sdn using graph neural network, in: 2020 International Conference
    on Information and Communication Technology Convergence (ICTC), IEEE, 2020, pp.
    500–505.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] H.-G. Kim, S. Park, D. Heo, S. Lange, H. Choi, J.-H. Yoo, J. W.-K. Hong,
    Graph neural network-based virtual network function deployment prediction, in:
    2020 16th International Conference on Network and Service Management (CNSM), IEEE,
    2020, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] F. Habibi, M. Dolati, A. Khonsari, M. Ghaderi, Accelerating virtual network
    embedding with graph neural networks, in: 2020 16th International Conference on
    Network and Service Management (CNSM), IEEE, 2020, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] R. Mijumbi, S. Hasija, S. Davy, A. Davy, B. Jennings, R. Boutaba, A connectionist
    approach to dynamic resource management for virtualised network functions, in:
    2016 12th International Conference on Network and Service Management (CNSM), IEEE,
    2016, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] T. L. Mai, N. Navet, Improvements to deep-learning-based feasibility prediction
    of switched ethernet network configurations, in: The 29th International Conference
    on Real-Time Networks and Systems (RTNS2021), 2021, pp. 1–11.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] L. Yang, X. Gu, H. Shi, A noval satellite network traffic prediction method
    based on gcn-gru, in: 2020 International Conference on Wireless Communications
    and Signal Processing (WCSP), IEEE, 2020, pp. 718–723.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] A. Badia-Sampera, J. Suárez-Varela, P. Almasan, K. Rusek, P. Barlet-Ros,
    A. Cabellos-Aparicio, Towards more realistic network models based on graph neural
    networks, in: Proceedings of the 15th International Conference on emerging Networking
    EXperiments and Technologies, 2019, pp. 14–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] A. Rkhami, T. A. Q. Pham, Y. Hadjadj-Aoul, A. Outtagarts, G. Rubino, On
    the use of graph neural networks for virtual network embedding, in: 2020 International
    Symposium on Networks, Computers and Communications (ISNCC), IEEE, 2020, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Y. Gui, D. Wang, L. Guan, M. Zhang, Optical network traffic prediction
    based on graph convolutional neural networks, in: 2020 Opto-Electronics and Communications
    Conference (OECC), IEEE, 2020, pp. 1–3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] J. Zhou, Z. Xu, A. M. Rush, M. Yu, Automating botnet detection with graph
    neural networks, in: AutoML for Networking and Systems Workshop of MLSys 2020
    Conference, 2020, pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] Y. Shen, Y. Shi, J. Zhang, K. B. Letaief, A graph neural network approach
    for scalable wireless power control, in: 2019 IEEE Globecom Workshops (GC Wkshps),
    IEEE, 2019, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] M. Eisen, A. Ribeiro, Large scale wireless power allocation with graph
    neural networks, in: 2019 IEEE 20th International Workshop on Signal Processing
    Advances in Wireless Communications (SPAWC), IEEE, 2019, pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] N. Naderializadeh, M. Eisen, A. Ribeiro, Wireless power control via counterfactual
    optimization of graph neural networks, in: 2020 IEEE 21st International Workshop
    on Signal Processing Advances in Wireless Communications (SPAWC), IEEE, 2020,
    pp. 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] F. Geyer, G. Carle, Learning and generating distributed routing protocols
    using graph-based deep learning, in: Proceedings of the 2018 Workshop on Big Data
    Analytics and Machine Learning for Data Communication Networks, 2018, pp. 40–45.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] M. Bahnasy, F. Li, S. Xiao, X. Cheng, Deepbgp: A machine learning approach
    for bgp configuration synthesis, in: Proceedings of the Workshop on Network Meets
    AI & ML, 2020, pp. 48–55.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] S. Xiao, H. Mao, B. Wu, W. Liu, F. Li, Neural packet routing, in: Proceedings
    of the Workshop on Network Meets AI & ML, 2020, pp. 28–34.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] X. Zhang, H. Zhao, J. Xiong, L. Zhou, J. Wei, Scalable power control/beamforming
    in heterogeneous wireless networks with graph neural networks, in: GLOBECOM 2021-2021
    IEEE Global Communications Conference, IEEE, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] F. Scarselli, M. Gori, A. C. Tsoi, M. Hagenbuchner, G. Monfardini, The
    graph neural network model, IEEE Transactions on Neural Networks 20 (1) (2008)
    61–80.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] H. Dai, B. Dai, L. Song, Discriminative embeddings of latent variable
    models for structured data, in: International Conference on Machine Learning,
    PMLR, 2016, pp. 2702–2711.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] W. Hamilton, Z. Ying, J. Leskovec, Inductive representation learning on
    large graphs, in: Advances in Neural Information Processing Systems, 2017, pp.
    1024–1034.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] S. Pan, R. Hu, S.-f. Fung, G. Long, J. Jiang, C. Zhang, Learning graph
    embedding with adversarial training methods, IEEE Transactions on Cybernetics
    50 (6) (2019) 2475–2487.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] M. Henaff, J. Bruna, Y. LeCun, Deep convolutional networks on graph-structured
    data, arXiv preprint arXiv:1506.05163.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] M. Defferrard, X. Bresson, P. Vandergheynst, Convolutional neural networks
    on graphs with fast localized spectral filtering, in: Conference on Neural Information
    Processing Systems, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] T. N. Kipf, M. Welling, Semi-supervised classification with graph convolutional
    networks, in: International Conference on Learning Representations (ICLR ’17),
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, G. E. Dahl, Neural
    message passing for quantum chemistry, in: International Conference on Machine
    Learning, PMLR, 2017, pp. 1263–1272.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] P. W. Battaglia, J. B. Hamrick, V. Bapst, A. Sanchez-Gonzalez, V. Zambaldi,
    M. Malinowski, A. Tacchetti, D. Raposo, A. Santoro, R. Faulkner, et al., Relational
    inductive biases, deep learning, and graph networks, arXiv preprint arXiv:1806.01261.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] K. Xu, W. Hu, J. Leskovec, S. Jegelka, How powerful are graph neural networks?,
    in: International Conference on Learning Representations (ICLR ’19), 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Liò, Y. Bengio,
    Graph attention networks, in: International Conference on Learning Representations
    (ICLR ’18), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] Y. Li, D. Tarlow, M. Brockschmidt, R. Zemel, Gated graph sequence neural
    networks, in: International Conference on Learning Representations (ICLR ’16),
    2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] Y. Li, R. Yu, C. Shahabi, Y. Liu, Diffusion convolutional recurrent neural
    network: Data-driven traffic forecasting, in: International Conference on Learning
    Representations (ICLR ’18), 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] A. Jain, A. R. Zamir, S. Savarese, A. Saxena, Structural-rnn: Deep learning
    on spatio-temporal graphs, in: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, 2016, pp. 5308–5317.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, P. S. Yu, Heterogeneous
    graph attention network, in: The World Wide Web Conference, 2019, pp. 2022–2032.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] Y. Shen, J. Zhang, K. B. Letaief, How neural architectures affect deep
    learning for communication networks?, arXiv preprint arXiv:2111.02215.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] D. Zügner, A. Akbarnejad, S. Günnemann, Adversarial attacks on neural
    networks for graph data, in: Proceedings of the 24th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining, 2018, pp. 2847–2856.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] F. Gama, J. Bruna, A. Ribeiro, Stability properties of graph neural networks,
    IEEE Transactions on Signal Processing 68 (2020) 5680–5695.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] N. Keriven, A. Bietti, S. Vaiter, Convergence and stability of graph
    convolutional networks on large random graphs, in: Neural Information Processing
    Systems, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, H. Hoffmann, Explainability
    methods for graph convolutional neural networks, in: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, 2019, pp. 10772–10781.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] Z. Ying, D. Bourgeois, J. You, M. Zitnik, J. Leskovec, Gnnexplainer:
    Generating explanations for graph neural networks, in: Advances in neural information
    processing systems, 2019, pp. 9244–9255.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] S. Zhang, B. Yin, Y. Cheng, Topology aware deep learning for wireless
    network optimization, arXiv preprint arXiv:1912.08336.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] M. Lee, G. Yu, H. Dai, Decentralized inference with graph neural networks
    in wireless communication systems, IEEE Transactions on Mobile Computing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] I. Nikoloska, O. Simeone, Fast power control adaptation via meta-learning
    for random edge graph neural networks, arXiv preprint arXiv:2105.00459.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] G. K. Kurt, M. G. Khoshkholgh, S. Alfattani, A. Ibrahim, T. S. Darwish,
    M. S. Alam, H. Yanikomeroglu, A. Yongacoglu, A vision and framework for the high
    altitude platform station (haps) networks of the future, IEEE Communications Surveys
    & Tutorials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] K. Tekbıyık, G. K. Kurt, A. R. Ekti, H. Yanikomeroglu, Graph attention
    networks for channel estimation in ris-assisted satellite iot communications,
    arXiv preprint arXiv:2104.00735.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] W. W. Lo, S. Layeghy, M. Sarhan, M. Gallagher, M. Portmann, E-graphsage:
    A graph neural network based intrusion detection system, arXiv preprint arXiv:2103.16329.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] J. Liu, Y. Xiao, Y. Li, G. Shiyz, W. Saad, H. V. Poor, Spatio-temporal
    modeling for large-scale vehicular networks using graph convolutional networks,
    in: ICC 2021-2021 IEEE International Conference on Communications (ICC), IEEE,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] M. Ferriol-Galmés, J. Suárez-Varela, P. Barlet-Ros, A. Cabellos-Aparicio,
    Applying graph-based deep learning to realistic network scenarios, arXiv preprint
    arXiv:2010.06686.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] T. Mallick, M. Kiran, B. Mohammed, P. Balaprakash, Dynamic graph neural
    network for traffic forecasting in wide area networks, arXiv preprint arXiv:2008.12767.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] T. Otoshi, Y. Ohsita, M. Murata, Y. Takahashi, K. Ishibashi, K. Shiomoto,
    Traffic prediction for dynamic traffic engineering, Computer Networks 85 (2015)
    36–50.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] A. A. Monrat, O. Schelén, K. Andersson, A survey of blockchain from the
    perspectives of applications, challenges, and opportunities, IEEE Access 7 (2019)
    117134–117151.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] Z. Gao, M. Eisen, A. Ribeiro, Resource allocation via graph neural networks
    in free space optical fronthaul networks, arXiv preprint arXiv:2006.15005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] P. Almasan, J. Suárez-Varela, A. Badia-Sampera, K. Rusek, P. Barlet-Ros,
    A. Cabellos-Aparicio, Deep reinforcement learning meets graph neural networks:
    Exploring a routing optimization use case, arXiv preprint arXiv:1910.07421.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] S. Sezer, S. Scott-Hayward, P. K. Chouhan, B. Fraser, D. Lake, J. Finnegan,
    N. Viljoen, M. Miller, N. Rao, Are we ready for sdn? implementation challenges
    for software-defined networks, IEEE Communications Magazine 51 (7) (2013) 36–43.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] D. Heo, D. Lee, H.-G. Kim, S. Park, H. Choi, Reinforcement learning of
    graph neural networks for service function chaining, arXiv preprint arXiv:2011.08406.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
    S. Ozair, A. C. Courville, Y. Bengio, Generative adversarial nets, in: NIPS, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] H. Wang, J. Wang, J. Wang, M. Zhao, W. Zhang, F. Zhang, X. Xie, M. Guo,
    Graphgan: Graph representation learning with generative adversarial nets, in:
    Proceedings of the AAAI conference on artificial intelligence, Vol. 32, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] X. He, K. Zhao, X. Chu, Automl: A survey of the state-of-the-art, Knowledge-Based
    Systems 212 (2021) 106622.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] H. Cai, V. W. Zheng, K. C.-C. Chang, A comprehensive survey of graph
    embedding: Problems, techniques, and applications, IEEE Transactions on Knowledge
    and Data Engineering 30 (9) (2018) 1616–1637.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] X. Zhang, Z. Zhang, L. Yang, Joint user association and power allocation
    in heterogeneous ultra dense network via semi-supervised representation learning,
    arXiv preprint arXiv:2103.15367.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] Z. Wang, M. Eisen, A. Ribeiro, Unsupervised learning for asynchronous
    resource allocation in ad-hoc wireless networks, in: ICASSP 2021-2021 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2021, pp.
    8143–8147.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] Z. Wang, M. Eisen, A. Ribeiro, Learning decentralized wireless resource
    allocations with graph neural networks, arXiv preprint arXiv:2107.01489.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] T. Chen, X. Zhang, M. You, G. Zheng, S. Lambotharan, A gnn based supervised
    learning framework for resource allocation in wireless iot networks, IEEE Internet
    of Things Journal.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] Z. Zhao, G. Verma, C. Rao, A. Swami, S. Segarra, Distributed scheduling
    using graph neural networks, in: ICASSP 2021-2021 IEEE International Conference
    on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2021, pp. 4720–4724.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] S. He, S. Xiong, W. Zhang, Y. Yang, J. Ren, Y. Huang, Gblinks: Gnn-based
    beam selection and link activation for ultra-dense d2d mmwave networks, arXiv
    preprint arXiv:2107.02412.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] V. Ranasinghe, N. Rajatheva, M. Latva-aho, Graph neural network based
    access point selection for cell-free massive mimo systems, arXiv preprint arXiv:2107.02884.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] J. Dong, S. Chen, P. Y. J. Ha, Y. Li, S. Labi, A drl-based multiagent
    cooperative control framework for cav networks: a graphic convolution q network,
    arXiv preprint arXiv:2010.05437.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] S. Zhao, X. Jiang, G. Jacobson, R. Jana, W.-L. Hsu, R. Rustamov, M. Talasila,
    S. A. Aftab, Y. Chen, C. Borcea, Cellular network traffic prediction incorporating
    handover: A graph convolutional approach, in: 2020 17th Annual IEEE International
    Conference on Sensing, Communication, and Networking (SECON), IEEE, 2020, pp.
    1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] W. Yan, D. Jin, Z. Lin, F. Yin, Graph neural network for large-scale
    network localization, in: ICASSP 2021-2021 IEEE International Conference on Acoustics,
    Speech and Signal Processing (ICASSP), IEEE, 2021, pp. 5250–5254.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] P. Soto, M. Camelo, K. Mets, F. Wilhelmi, D. Góez, L. A. Fletscher, N. Gaviria,
    P. Hellinckx, J. F. Botero, S. Latré, Atari: A graph convolutional neural network
    approach for performance prediction in next-generation wlans, Sensors 21 (13)
    (2021) 4321.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] M. Liu, J. Li, H. Lu, Routing in small satellite networks: A gnn-based
    learning approach, arXiv preprint arXiv:2108.08523.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
