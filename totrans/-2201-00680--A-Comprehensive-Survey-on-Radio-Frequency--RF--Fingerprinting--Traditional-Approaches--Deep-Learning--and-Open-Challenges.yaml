- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:48:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:48:42
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2201.00680] A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2201.00680] 对射频 (RF) 指纹识别的全面调查：传统方法、深度学习和开放挑战'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2201.00680](https://ar5iv.labs.arxiv.org/html/2201.00680)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2201.00680](https://ar5iv.labs.arxiv.org/html/2201.00680)
- en: 'A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional
    Approaches, Deep Learning, and Open Challenges'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 对射频 (RF) 指纹识别的全面调查：传统方法、深度学习和开放挑战
- en: Anu Jagannath, Jithin Jagannath, and Prem Sagar Pattanshetty Vasanth Kumar Anu
    Jagannath is with Northeastern University and ANDRO’s Marconi-Rosenblatt AI/ML
    Innovation Laboratory.Jithin Jagannath is with University at Buffalo and ANDRO’s
    Marconi-Rosenblatt AI/ML Innovation Laboratory..Prem Sagar Pattanshetty Vasanth
    Kumar is with ANDRO’s Marconi-Rosenblatt AI/ML Innovation Laboratory.
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**Anu Jagannath**、**Jithin Jagannath** 和 **Prem Sagar Pattanshetty Vasanth
    Kumar**。Anu Jagannath 就职于东北大学和 ANDRO 的 Marconi-Rosenblatt AI/ML 创新实验室。Jithin Jagannath
    就职于布法罗大学和 ANDRO 的 Marconi-Rosenblatt AI/ML 创新实验室。Prem Sagar Pattanshetty Vasanth
    Kumar 就职于 ANDRO 的 Marconi-Rosenblatt AI/ML 创新实验室。'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Fifth generation (5G) network and beyond envision massive Internet of Things
    (IoT) rollout to support disruptive applications such as extended reality (XR),
    augmented/virtual reality (AR/VR), industrial automation, autonomous driving,
    and smart everything which brings together massive and diverse IoT devices occupying
    the radio frequency (RF) spectrum. Along with the spectrum crunch and throughput
    challenges, such a massive scale of wireless devices exposes unprecedented threat
    surfaces. RF fingerprinting is heralded as a candidate technology that can be
    combined with cryptographic and zero-trust security measures to ensure data privacy,
    confidentiality, and integrity in wireless networks. Motivated by the relevance
    of this subject in the future communication networks, in this work, we present
    a comprehensive survey of RF fingerprinting approaches ranging from a traditional
    view to the most recent deep learning (DL)-based algorithms. Existing surveys
    have mostly focused on a constrained presentation of the wireless fingerprinting
    approaches, however, many aspects remain untold. In this work, however, we mitigate
    this by addressing every aspect - background on signal intelligence (SIGINT),
    applications, relevant DL algorithms, systematic literature review of RF fingerprinting
    techniques spanning the past two decades, discussion on datasets, and potential
    research avenues - necessary to elucidate this topic to the reader in an encyclopedic
    manner.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 第五代 (5G) 网络及其之后的技术展望实现大规模物联网 (IoT) 部署，以支持如扩展现实 (XR)、增强/虚拟现实 (AR/VR)、工业自动化、自动驾驶和智能一切等颠覆性应用，这将汇集大量多样化的物联网设备，占据射频
    (RF) 频谱。除了频谱紧缩和吞吐量挑战，这样的大规模无线设备还暴露了前所未有的威胁面。射频指纹识别被誉为一种可以与加密和零信任安全措施结合的候选技术，以确保无线网络中的数据隐私、机密性和完整性。鉴于这一主题在未来通信网络中的相关性，本研究呈现了从传统视角到最新深度学习
    (DL) 算法的射频指纹识别方法的全面调查。现有的调查大多集中在无线指纹识别方法的有限展示上，然而，许多方面仍未被讨论。在本研究中，我们通过涵盖每一个方面
    - 信号情报 (SIGINT) 背景、应用、相关 DL 算法、过去二十年射频指纹识别技术的系统文献综述、数据集讨论以及潜在的研究方向 - 来阐明这一主题，以百科全书式的方式呈现给读者。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Radio Fingerprinting, Deep Learning, Signal Intelligence, Wireless Security,
    Emitter Identification, Signal and Modulation Classification.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 射频指纹识别、深度学习、信号情报、无线安全、发射源识别、信号和调制分类。
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Radio frequency (RF) fingerprinting - a form of signal intelligence - refers
    to the methodology whereby the hardware intrinsic characteristics of the transmitter
    which are unintentionally embedded in the transmitted waveform are extracted to
    aid the identification of the transmitter hardware by a passive receiver. Due
    to its unique ability to identify transmitting device, RF fingerprinting is envisioned
    as a key enabler for device authentication and access control to reduce the vulnerability
    of beyond 5G wireless networks to node forgery or insider attacks [[1](#bib.bib1)].
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 无线频率（RF）指纹识别——一种信号情报形式——是指通过提取发射机硬件内在特征，这些特征无意中嵌入到传输波形中，以帮助被动接收器识别发射机硬件的方法。由于其独特的识别发射设备的能力，RF指纹识别被设想为设备认证和访问控制的关键推动力，以减少超越5G无线网络对节点伪造或内部攻击的脆弱性[[1](#bib.bib1)]。
- en: With the proliferation of wireless devices and the increased adoption of Internet-of-Things
    (IoT) devices for smart home, industrial automation, smart metering, etc., the
    beyond 5G network is expected to support ultra-dense device connectivity which
    is $10\times$ that of 5G [[2](#bib.bib2)]. Moreover, with such overwhelming device
    density the threat surfaces of the network are bound to increase. Therefore, security
    and privacy are the crucial inevitable aspects beyond 5G (6G) will need to address.
    Especially the 6G enabling technologies such as ultra-massive multiple-input multiple-output
    (UM-MIMO), visible light communication (VLC), terahertz (THz) communication, among
    others, introduce new realm of security challenges. Even in 5G networks, the OpenFlow
    implementation of the software defined network (SDN) makes it vulnerable to attacks
    from malicious applications. Further, the network function virtualization (NFV)
    presents security risks as the function is being migrated from one platform to
    another [[3](#bib.bib3)]. With the envisioned device density of the beyond 5G
    network, such vulnerabilities will only increase. The security threats can perhaps
    be best attributed to two causes; massive device density and diversity with respect
    to the applications as well as the hardware.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着无线设备的普及和智能家居、工业自动化、智能计量等物联网（IoT）设备的增加，预计超越5G网络将支持超密集的设备连接，其密度是5G的$10\times$[[2](#bib.bib2)]。此外，随着设备密度的增加，网络的威胁面也必然增加。因此，安全性和隐私是超越5G（6G）必须解决的关键方面。尤其是6G启用的技术，如超大规模多输入多输出（UM-MIMO）、可见光通信（VLC）、太赫兹（THz）通信等，引入了新的安全挑战。即使在5G网络中，软件定义网络（SDN）的OpenFlow实现也使其容易受到恶意应用程序的攻击。此外，网络功能虚拟化（NFV）在功能从一个平台迁移到另一个平台时存在安全风险[[3](#bib.bib3)]。随着超越5G网络设备密度的预期增加，这些脆弱性只会增加。安全威胁或许可以归因于两个原因：巨大的设备密度和应用以及硬件的多样性。
- en: The hardware intrinsic features of device form the fingerprint or the signature
    unique to that device. RF fingerprinting is consequently viewed as the prospective
    enablers to address and mitigate the access control and device authentication
    challenges of the beyond 5G network. For the purpose of clarity, we define RF
    fingerprinting as a composite of three steps; feature identification, feature
    extraction, and device identification. It must be emphasized that these features
    are location-independent and ingrained to the chipset. Specifically, the imperfections
    in manufacturing the microcircuit parts such as power amplifiers, filters, clocks,
    etc., lead to broad variations in the phase offset, clock skew, among others.
    Another aspect that could serve as features are the vendor-specific implementations
    of wireless standards [[1](#bib.bib1)]. But such features could easily vary with
    firmware and software upgrades of the chipset. Clearly, the device-specific features
    would serve as a pronounced invariant feature set.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 设备的硬件内在特征构成了该设备特有的指纹或签名。因此，RF指纹识别被视为解决和缓解超越5G网络的访问控制和设备认证挑战的潜在推动力。为清晰起见，我们将RF指纹识别定义为三个步骤的综合：特征识别、特征提取和设备识别。必须强调，这些特征是位置独立的，并且内嵌在芯片组中。具体而言，制造微电路部件（如功率放大器、滤波器、时钟等）的缺陷会导致相位偏移、时钟偏差等的广泛变化。另一个可以作为特征的方面是无线标准的供应商特定实现[[1](#bib.bib1)]。但这些特征可能会因芯片组的固件和软件升级而变化。显然，设备特定特征将作为一个显著的不变特征集。
- en: Despite several device fingerprinting works, a comprehensive survey encompassing
    the evolution of fingerprinting algorithms from principled to deep learning based
    approaches is lacking. The contributions and scope of this article is discussed
    in detail here to portray its relevance in the present era of evolving wireless
    networks.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已有若干设备指纹识别研究，但缺乏涵盖从原理性到深度学习方法的指纹识别算法演变的全面综述。本文详细讨论了其贡献和范围，以展示其在当代不断发展的无线网络中的相关性。
- en: '![Refer to caption](img/0f6d61df01365919ffa456e122876f3a.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0f6d61df01365919ffa456e122876f3a.png)'
- en: 'Figure 1: Overview of the organization of the article'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：文章组织概述
- en: I-A Scope of the Article
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-A 文章范围
- en: 'The objective of this article is to present a comprehensive view of the state-of-the-art
    wireless device fingerprinting algorithms while also provide sufficient background
    on the subsidiary signal intelligence domains - modulation and wireless protocol
    classification. Although there has been numerous articles on deep learning for
    other RF signal intelligence approaches (modulation and wireless protocol classification)
    [[4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8),
    [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14)], a comprehensive presentation spanning conventional principled
    approaches as well as supervised deep learning for RF fingerprinting is lacking.
    We attempt to bridge this gap by discussing the following key aspects:'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目的是提供一个全面的现代无线设备指纹识别算法的视角，同时提供关于附属信号智能领域——调制和无线协议分类的充分背景。尽管已有许多关于其他射频信号智能方法（调制和无线协议分类）的深度学习文章[[4](#bib.bib4),
    [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]，但缺乏涵盖传统原理方法和监督深度学习的射频指纹识别的综合展示。我们尝试通过讨论以下关键方面来弥补这一空白：
- en: '1.'
  id: totrans-21
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: A succinct and categorized layout of the related research in the field of RF
    signal intelligence (SIGINT) to provide relevant background to the reader. Here,
    we present a preview of the various methods - spanning conventional and deep learning
    - for automatic modulation classification (AMC), wireless protocol recognition,
    before going to a illustrative discussion on the RF fingerprinting applications
    as well as approaches.
  id: totrans-22
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对射频信号智能（SIGINT）领域相关研究的简明且分类布局，以向读者提供相关背景。这里，我们展示了自动调制分类（AMC）、无线协议识别的各种方法的预览——涵盖传统方法和深度学习方法，然后进行射频指纹识别应用及方法的详细讨论。
- en: '2.'
  id: totrans-23
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Some of the key application domains of RF signal intelligence in this emerging
    revolutionary communication era where billions of wireless devices including diverse
    IoT emitters coexist. This aspect presents the viewer with critical wireless network
    application areas for a practical insight of the presented RF signal intelligence
    methods.
  id: totrans-24
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这个正在迅速发展的通信时代，射频信号智能的一些关键应用领域涉及到数十亿个包括各种物联网发射器的无线设备共存。这一方面为观众提供了射频信号智能方法在实际应用中的重要无线网络应用领域。
- en: '3.'
  id: totrans-25
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: A qualitative discussion on the traditional approaches for RF fingerprinting
    categorized into modulation, statistical, transient, wavelet, and other approaches.
  id: totrans-26
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对传统射频指纹识别方法的定性讨论，分类为调制、统计、瞬态、小波及其他方法。
- en: '4.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: A deep dive into the state-of-the-art deep learning methods for RF fingerprinting
    including an overview of the prominent deep learning approaches in order to assist
    researchers in applying them for RF signal intelligence.
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于射频指纹识别的最先进深度学习方法进行深入探讨，包括对主要深度学习方法的概述，以帮助研究人员将其应用于射频信号智能。
- en: '5.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: A detailed account of the various open-source datasets tailored to equip researchers
    with comprehensive knowledge to delve into applied RF fingerprinting research.
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对各种开源数据集的详细介绍，旨在为研究人员提供全面的知识，以深入应用射频指纹识别研究。
- en: '6.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: We motivate further research in this realm by presenting open research challenges
    and future directions.
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过提出开放研究挑战和未来方向，激励进一步研究。
- en: We emphasize here that unlike existing surveys, our article is comprehensive
    in presenting all aspects of RF fingerprinting comprising a glance into background
    on RF signal intelligence, the evolution towards deep learning approaches for
    RF fingerprinting including the progress on conventional principled methods. For
    completeness and to benefit beginners, we provide a tutorial of the relevant deep
    learning techniques.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在此强调，与现有的调查不同，我们的文章全面呈现了RF指纹识别的各个方面，包括对RF信号智能的背景概述、RF指纹识别中向深度学习方法的演变以及传统原则方法的进展。为了完整性并惠及初学者，我们提供了相关深度学习技术的教程。
- en: Most of the existing surveys related to RF fingerprinting presents only a narrow
    scope. Specifically, a qualitative analysis of all RF signal intelligence aspects
    including AMC, wireless protocol recognition, and a quantitative discussion on
    key deep learning approaches have not been widely investigated to date in the
    current literature. In [[15](#bib.bib15)], the various techniques of identifying
    a mobile phone by fingerprinting the built-in components, such as camera, micro-electro-mechanical
    systems, speakers, microphone, and RF frontends have been discussed. In contrast,
    we attempt to cover all RF emitters such as software-defined radios (SDRs), unmanned
    aerial vehicles (UAVs), and other consumer-off-the-shelf (COTS) devices including
    mobile phones. The survey in [[16](#bib.bib16)] presents a short account of the
    RF fingerprint extraction and authentication methods with an emphasis on device
    authenticity - legal or illicit. Another survey in [[17](#bib.bib17)] reviews
    spoofer detection methods that leverages RF fingerprinting with special emphasis
    on Global Navigation Satellite System (GNSS) emitters. Although this work presents
    a broader scope in contrast to [[15](#bib.bib15)] and [[16](#bib.bib16)], it lacks
    a thorough presentation of all aspects of RF signal intelligence. One other survey
    in [[18](#bib.bib18)] discusses the taxonomy of wireless device fingerprinting
    along with brief account on fingerprinting algorithms that are classical white-list
    and unsupervised learning-based. Our article goes beyond these works in providing
    the reader all aspects of RF signal intelligence including crossovers between
    traditional and deep learning based RF signal intelligence approaches. Unlike
    existing surveys which only provides a very brief (2-3 sentences) discussion on
    the reviewed articles, we dive into the reviewed works in the vast literature
    to provide a succinct excerpt on each. Further, the application scope of these
    signal intelligence techniques are not elaborated in any other existing surveys.
    The ultimate objective of this article is to provide an encyclopedic guide of
    RF fingerprinting that encompasses the basics of key supervised deep learning
    techniques as well as an extensive review of the state-of-the-art RF signal intelligence.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有与RF指纹识别相关的调查仅呈现了狭窄的范围。具体而言，涉及所有RF信号智能方面的定性分析，包括AMC、无线协议识别，以及对关键深度学习方法的定量讨论，至今尚未在当前文献中广泛探讨。在[[15](#bib.bib15)]中，讨论了通过指纹识别内置组件（如相机、微机电系统、扬声器、麦克风和RF前端）来识别手机的各种技术。相比之下，我们尝试覆盖所有RF发射器，例如软件定义无线电（SDR）、无人机（UAV）以及其他消费品（COTS）设备，包括手机。在[[16](#bib.bib16)]中，介绍了RF指纹提取和认证方法，并重点讨论了设备的真实性——合法或非法。另一项调查[[17](#bib.bib17)]回顾了利用RF指纹识别的伪造检测方法，特别强调了全球导航卫星系统（GNSS）发射器。尽管这项工作与[[15](#bib.bib15)]和[[16](#bib.bib16)]相比展示了更广泛的范围，但仍缺乏对RF信号智能所有方面的彻底介绍。另一项调查[[18](#bib.bib18)]讨论了无线设备指纹识别的分类法，并简要介绍了经典的白名单和无监督学习算法。我们的文章超越了这些工作，为读者提供了RF信号智能的所有方面，包括传统和基于深度学习的RF信号智能方法之间的交叉点。与现有调查仅提供对所评审文章的简要（2-3句）讨论不同，我们深入探讨了广泛文献中的评审工作，提供了每一项的简洁摘录。此外，这些信号智能技术的应用范围在其他现有调查中并未详细阐述。本文的最终目标是提供一个全面的RF指纹识别指南，包括关键监督深度学习技术的基础知识以及最先进的RF信号智能的广泛综述。
- en: I-B Survey Organization
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-B 调查组织
- en: 'We structure our article in an organized hierarchical manner: Section [II](#S2
    "II Glance into RF Signal Intelligence ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges")
    introduces the readers to the two subsidiary domains of RF signal intelligence
    and reviews the traditional as well as deep learning based automatic modulation
    and wireless protocol classification. The key application areas of the discussed
    RF fingerprinting methods are briefly discussed in section [III](#S3 "III Applications
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges") to supplement practical insight to the researchers
    and practitioners allowing them to explore the applicability. We begin the RF
    fingerprinting survey by elaborating on the principled approaches first in section
    [IV](#S4 "IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges"). We have categorized the traditional approaches based on
    the fingerprinted characteristics into modulation, statistical, transient, wavelet,
    and other miscellaneous methods to enable a sectioned and comparative discussion
    of the vast literature on traditional techniques. Next, we present an illustrative
    discussion on the state-of-the-art deep learning-based RF fingerprinting techniques
    in section [V](#S5 "V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges"). We have segmented this section into two where the first
    part reviews the key deep learning concepts to present contextual walk-through
    for the readers, followed by the second part which shows how these deep learning
    techniques are applied to the RF fingerprinting domain. Further, we educate the
    readers on the available open-source datasets for training deep learning models
    to perform RF fingerprinting. Finally, we aim to spur future research in this
    domain by summarizing a few open questions and challenges in section [VI](#S6
    "VI Research Challenges and Future Direction ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges"). We also layout the organization in a pictorial manner in Figure
    [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges").'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '我们以有组织的层次结构来构建我们的文章：部分[II](#S2 "II Glance into RF Signal Intelligence ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges")向读者介绍了RF信号智能的两个子领域，并回顾了基于传统方法和深度学习的自动调制和无线协议分类。讨论的RF指纹识别方法的关键应用领域在部分[III](#S3
    "III Applications ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges")中简要讨论，以补充实际洞察，帮助研究人员和从业人员探索其适用性。我们通过在部分[IV](#S4
    "IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges")中详细阐述原理性方法，开始RF指纹识别的调查。我们根据指纹特征将传统方法分为调制、统计、瞬态、小波和其他杂项方法，以便对传统技术的广泛文献进行分段和比较讨论。接下来，我们在部分[V](#S5
    "V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges")中呈现了最先进的基于深度学习的RF指纹识别技术的说明性讨论。我们将此部分分为两个部分，第一部分回顾了关键的深度学习概念，为读者提供背景介绍，第二部分展示了这些深度学习技术如何应用于RF指纹识别领域。此外，我们还向读者介绍了用于训练深度学习模型以进行RF指纹识别的开源数据集。最后，我们通过在部分[VI](#S6
    "VI Research Challenges and Future Direction ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges")中总结一些开放问题和挑战，旨在激发该领域的未来研究。我们还在图[1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges")中以图示方式展示了组织结构。'
- en: II Glance into RF Signal Intelligence
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II RF信号智能概述
- en: RF signal intelligence is defined as the field of research and application that
    focuses on extracting signal characteristics such as modulation, bandwidth, center
    frequency, protocols, emitter identity, among others from unknown RF signals in
    the spectrum of interest. This extraction can be performed under various levels
    of cooperation or prior knowledge based on the application at hand. The most challenging
    version is under the assumption of no prior information or cooperation which is
    often referred to as blind RF signal intelligence.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 射频信号智能被定义为专注于从感兴趣的频谱中的未知射频信号中提取诸如调制、带宽、中心频率、协议、发射器身份等信号特征的研究和应用领域。根据实际应用，这种提取可以在不同的合作或先验知识水平下进行。最具挑战性的版本是在没有任何先验信息或合作的假设下，这通常被称为盲射频信号智能。
- en: This area of research is further divided into different categories based on
    the task performed. Perhaps the most popular and widely researched task is that
    of AMC and then wireless signal/protocol classification. One common theme between
    these classification tasks are the fact that the signals itself are evidently
    different from each other in these classification tasks making them a relatively
    easier task compared to RF fingerprinting where identical devices could be transmitting
    same waveform with identical configurations. Here for the benefit of the readers,
    we provide the background information of the two most common signal intelligence
    classes (AMC and signal type classification). This is also for the readers to
    relate to the overall RF signal intelligence research domain while reviewing the
    more in-depth survey of RF fingerprinting approaches.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这一研究领域进一步分为不同的类别，基于所执行的任务。也许最受欢迎和广泛研究的任务是AMC以及无线信号/协议分类。这些分类任务之间的一个共同主题是信号本身在这些分类任务中明显不同，使得它们相对比射频指纹识别更容易，后者中相同的设备可能以相同的配置发送相同的波形。为了读者的方便，我们提供了两个最常见的信号智能类别（AMC和信号类型分类）的背景信息。这也是为了让读者在审阅射频指纹识别方法的更深入调查时与整体射频信号智能研究领域相关联。
- en: II-A Automatic modulation classification
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 自动调制分类
- en: 'As discussed earlier, due to the extensive attention this area of research
    has garnered, we organize this section based on the evolution seen in AMC techniques
    depicted in Figure [2](#S2.F2 "Figure 2 ‣ II-A Automatic modulation classification
    ‣ II Glance into RF Signal Intelligence ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges").'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '如前所述，由于这一研究领域获得了广泛关注，我们根据图 [2](#S2.F2 "Figure 2 ‣ II-A Automatic modulation
    classification ‣ II Glance into RF Signal Intelligence ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges") 中显示的AMC技术演变来组织这一部分内容。'
- en: '![Refer to caption](img/bb40d3bb18c8cc36b24975319372697a.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/bb40d3bb18c8cc36b24975319372697a.png)'
- en: 'Figure 2: Evolution of AMC Approaches'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：AMC 方法的演变
- en: 'Traditional Approaches: AMC can be broadly categorized into two classes; (i)
    likelihood-based methods [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21),
    [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24)] and (ii) feature-based [[25](#bib.bib25),
    [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28)]. There have been several
    attempts to combine the two approaches to possibly extract the benefits of both
    approaches [[29](#bib.bib29)]. Likelihood-based approaches can provide optimal
    performance in the Bayesian sense but are often computationally demanding [[29](#bib.bib29),
    [30](#bib.bib30)]. On the other hand, feature-based classifiers can provide near
    optimal performance while being computationally efficient if carefully designed.
    Note here that the requirement of being “carefully designed" is perhaps the weakness
    of traditional feature-based approaches. It is often possible to design the classifier
    which performs extremely well under certain assumptions in simulations or laboratory
    settings but fail under real-world scenarios or when the operational environment
    changes. In other words, for AMC to be suitable for real-world approaches, it
    is important for the classifiers to generalize well to various operating scenarios
    and environments.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 传统方法：AMC可以大致分为两类；（i）基于似然的方法[[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21),
    [22](#bib.bib22), [23](#bib.bib23), [24](#bib.bib24)]和（ii）基于特征的方法[[25](#bib.bib25),
    [26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28)]。有几个尝试将这两种方法结合起来，以期提取两者的优势[[29](#bib.bib29)]。基于似然的方法在贝叶斯意义上可以提供最佳性能，但通常计算需求较高[[29](#bib.bib29),
    [30](#bib.bib30)]。另一方面，基于特征的分类器如果设计得当，可以在计算效率上提供接近最佳的性能。值得注意的是，“精心设计”的要求可能是传统基于特征的方法的弱点。通常情况下，设计一个在仿真或实验室设置下表现极佳的分类器，但在现实世界场景或操作环境变化时可能会失效。换句话说，为了使AMC适合现实世界应用，分类器需要在各种操作场景和环境中具有良好的泛化能力。
- en: 'Neural network with expert-feature: Since the problem structure of feature-based
    classifiers are similar to the function approximation schema of the recently revitalized
    supervised machine learning, it was inevitable for these techniques to be leveraged
    for AMC. Consequently, in recent years, different machine learning techniques
    have been employed to determine the modulation format of the unknown signal via
    classification. During the initial stages of applying supervised learning for
    AMC, feature-engineered methodology was adopted as opposed to utilizing raw in-phase
    and quadrature (IQ) samples. This includes the use of support vector machines
    (SVMs) [[31](#bib.bib31)] and ANNs [[32](#bib.bib32), [33](#bib.bib33), [6](#bib.bib6)].
    In [[32](#bib.bib32)], the authors perform a twelve-class modulation classification
    with high accuracy over a wide range of signal-to-noise ratio (SNR) values using
    a multilayer perceptron (MLP). In [[33](#bib.bib33)], the authors evaluate two
    different ANN architectures trained by the backpropagation method using the standard
    gradient descent (GD) learning algorithm by using six features. Similarly, [[6](#bib.bib6)]
    achieves high accuracy under low SNR conditions in identifying eight modulation
    schemes. All these studies are limited to simulations and not evaluated on actual
    hardware. In [[30](#bib.bib30)], authors elaborate the confronted challenges while
    transitioning their solution from simulation to hardware implementation. In short,
    due to the assumptions and unanticipated signal distortions that are overlooked
    during simulations, over-the-air performance of AMC techniques may experience
    degradation in real deployment.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 专家特征的神经网络：由于基于特征的分类器的问题结构类似于最近复兴的监督机器学习的函数逼近模式，因此这些技术在自适应调制分类（AMC）中得到了不可避免的应用。因此，近年来采用了不同的机器学习技术来通过分类确定未知信号的调制格式。在应用监督学习进行AMC的初期，采用了特征工程的方法，而不是利用原始的同相和正交（IQ）样本。这包括使用支持向量机（SVMs）[[31](#bib.bib31)]和人工神经网络（ANNs）[[32](#bib.bib32),
    [33](#bib.bib33), [6](#bib.bib6)]。在[[32](#bib.bib32)]中，作者使用多层感知器（MLP）在广泛的信噪比（SNR）值范围内进行高准确度的十二类调制分类。在[[33](#bib.bib33)]中，作者使用六个特征通过标准梯度下降（GD）学习算法的反向传播方法评估了两种不同的ANN架构。同样，[[6](#bib.bib6)]在低SNR条件下实现了对八种调制方案的高准确度识别。所有这些研究均限于仿真，并未在实际硬件上进行评估。在[[30](#bib.bib30)]中，作者详细阐述了将解决方案从仿真转移到硬件实现过程中面临的挑战。简而言之，由于仿真过程中忽视的假设和意外信号失真，AMC技术在实际部署中可能会出现性能下降。
- en: The superior feature extraction capability of convolutional neural networks
    (CNNs) in contrast to ANNs led to several works leveraging CNNs for modulation
    or signal classification [[34](#bib.bib34), [35](#bib.bib35), [5](#bib.bib5),
    [36](#bib.bib36), [37](#bib.bib37), [9](#bib.bib9), [10](#bib.bib10)]. The authors
    of [[34](#bib.bib34)] evaluated the performance of CNNs - GoogLeNet [[38](#bib.bib38)]
    and AlexNet [[39](#bib.bib39)] architectures - in predicting modulation formats
    on a dataset comprising eight classes by feeding constellation images as input.
    However, the models demonstrated sensitivity to image preprocessing factors such
    as image resolution, cropping size, selected area, etc., and achieved an accuracy
    below 80% at 0 dB SNR. We profess and attribute that this could be due to the
    adoption of heavy architectures suited for computer vision problems rather than
    for the RF application. A feed-forward feature-based neural network [[40](#bib.bib40)]
    was shown to achieve a classification accuracy of 98% on seven modulations on
    a USRP software-defined radio testbed. Time-frequency images were used as input
    for a CNN architecture to identify seven radar waveform classes in [[41](#bib.bib41)].
    Along a similar trend, cyclic spectrum images were used as CNN input to obtain
    a seven-class modulation recognition accuracy of 95% at SNRs above 2 dB in [[35](#bib.bib35)].
    We would like to emphasize here that these works rely on handcrafted features
    to train the neural network which limits the generalization capability of the
    network as it could have from raw IQ samples.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNNs）相较于人工神经网络（ANNs）具有卓越的特征提取能力，这促使了若干研究利用CNN进行调制或信号分类[[34](#bib.bib34)、[35](#bib.bib35)、[5](#bib.bib5)、[36](#bib.bib36)、[37](#bib.bib37)、[9](#bib.bib9)、[10](#bib.bib10)]。[[34](#bib.bib34)]的作者评估了CNNs
    - GoogLeNet [[38](#bib.bib38)] 和 AlexNet [[39](#bib.bib39)] 架构 - 在预测调制格式上的表现，数据集包含八类，通过输入星座图像进行训练。然而，这些模型对图像预处理因素如图像分辨率、裁剪大小、选择区域等非常敏感，在0
    dB SNR下准确率低于80%。我们认为，这可能是因为这些模型采用了适用于计算机视觉问题的重型架构，而非RF应用的需求。一种前馈特征基础的神经网络[[40](#bib.bib40)]在USRP软件定义无线电测试台上对七种调制方式的分类准确率达到了98%。在[[41](#bib.bib41)]中，时间-频率图像被用作CNN架构的输入，用于识别七种雷达波形类别。沿着类似的趋势，[[35](#bib.bib35)]中使用循环谱图像作为CNN输入，在SNR高于2
    dB时获得了七类调制识别的95%准确率。我们在此强调，这些工作依赖于手工特征来训练神经网络，这限制了网络的泛化能力，而这种能力本可以通过原始IQ样本得到提升。
- en: 'Neural network with raw IQ: A CNN architecture which classifies $5$ communication
    waveforms by utilizing raw IQ samples was explored in [[4](#bib.bib4)]. Although
    the model achieves a $100\%$ accuracy it considers very limited number of waveforms
    of the same carrier frequency and bandwidth. The authors of [[5](#bib.bib5)] trained
    a CNN to achieve an accuracy of 83.4% at 18 dB in classifying 11 modulations by
    feeding raw IQ samples. In [[36](#bib.bib36)], a modified ResNet architecture
    was shown to achieve a 95.6% accuracy at 10 dB by learning from raw IQ samples
    in identifying 24 modulation classes.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 原始IQ的神经网络：在[[4](#bib.bib4)]中探讨了一种使用原始IQ样本对5种通信波形进行分类的CNN架构。尽管该模型达到了100%的准确率，但它考虑的相同载波频率和带宽的波形数量非常有限。[[5](#bib.bib5)]的作者训练了一种CNN，通过输入原始IQ样本，在18
    dB下实现了83.4%的准确率，用于分类11种调制方式。在[[36](#bib.bib36)]中，改进的ResNet架构通过从原始IQ样本中学习，在10 dB下实现了95.6%的准确率，识别了24种调制类别。
- en: II-B RF signal recognition
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B RF信号识别
- en: Wireless signal recognition is a signal (wireless standard or protocol) recognition
    method which involves identifying the wireless standard with which the RF waveform
    is generated. The authors of [[9](#bib.bib9)] studied wireless interference detection
    by performing a 15-class identification comprising three wireless standards -
    IEEE 802.11 b/g, IEEE 802.15.4, and IEEE 802.15.1 - occupying different frequency
    channels. In a similar sense, [[10](#bib.bib10)] adopted a CNN architecture to
    address the spectrum crunch in the industrial, scientific, and medical (ISM) band
    by classifying seven classes belonging to Zigbee, WiFi, Bluetooth, and their cross-interferences.
    However, the model required operation in a high SNR regime for a 93% accuracy.
    In [[42](#bib.bib42)], the authors use a distance-based support vector data description
    (SVDD) algorithm to recognize low, slow, and small unmanned aerial vehicles (LSSUAVs)
    among the signals in the 2.4 GHz band by generating a hash fingerprint. The proposed
    method recognized LSSUAV signals without any mistakes and falsely recognized IEEE
    802.11b and IEEE802.11n signals as LSSUAV $13.5\%$ and $0\%$ of the time respectively
    in an indoor environment. Similarly, the authors [[43](#bib.bib43)] investigate
    recognition of UAV video signals in the presence of WiFi interference. Using random
    forest classifier, the authors show that the method can recognize UAV video signal
    in presence of WiFi interference with an accuracy of $100\%$ indoors and $96.26\%$
    when the UAV is 2 km from the receiver. In [[7](#bib.bib7)], the authors implement
    a CNN model to identify the presence of radar signals in the radio spectrum with
    interference from LTE and WLAN signals. The authors achieve a classification accuracy
    of $99.6\%$ while using amplitude and phase shift components of the signals in
    the dataset. The authors in [[44](#bib.bib44)] train CNN classifiers using time
    domain features to recognize WiFi, Zigbee, and Bluetooth devices operating in
    the 2.4 GHz band. The results demonstrate that the proposed method is capable
    of recognizing with an accuracy $\geq 95\%$ for SNR greater then 5 dB.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 无线信号识别是一种信号（无线标准或协议）识别方法，涉及识别RF波形生成的无线标准。[[9](#bib.bib9)]的作者通过执行一个包含三种无线标准——IEEE
    802.11 b/g、IEEE 802.15.4和IEEE 802.15.1——的15类识别，研究了无线干扰检测，这些标准占据了不同的频率通道。在类似的研究中，[[10](#bib.bib10)]采用了CNN架构来解决工业、科学和医学（ISM）频段的频谱紧张问题，通过对Zigbee、WiFi、Bluetooth及其交叉干扰的七个类别进行分类。然而，该模型需要在高SNR条件下操作才能达到93%的准确率。在[[42](#bib.bib42)]中，作者使用基于距离的支持向量数据描述（SVDD）算法，通过生成哈希指纹来识别2.4
    GHz频段中的低速、小型无人机（LSSUAVs）信号。所提出的方法在室内环境中无误地识别了LSSUAV信号，同时将IEEE 802.11b和IEEE802.11n信号错误识别为LSSUAV的概率分别为$13.5\%$和$0\%$。类似地，[[43](#bib.bib43)]的作者研究了在WiFi干扰下识别无人机视频信号。使用随机森林分类器，作者展示了该方法在WiFi干扰下能够以$100\%$的准确率在室内识别无人机视频信号，并且在无人机距离接收器2公里时，准确率为$96.26\%$。在[[7](#bib.bib7)]中，作者实现了一个CNN模型，用于识别无线电频谱中受到LTE和WLAN信号干扰的雷达信号。作者使用信号数据集中的幅度和相位移分量，达到了$99.6\%$的分类准确率。在[[44](#bib.bib44)]中，作者使用时域特征训练CNN分类器，以识别在2.4
    GHz频段运行的WiFi、Zigbee和Bluetooth设备。结果表明，所提出的方法能够在SNR大于5 dB时以$\geq 95\%$的准确率进行识别。
- en: II-C Single model to extract more than modulation
  id: totrans-50
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 单模型提取超过调制
- en: A multi-task learning (MTL) model that can learn to recognize more than one
    task - modulation and signal (protocol) recognition - was proposed for the first
    time in [[45](#bib.bib45), [46](#bib.bib46)]. This was the first work to consider
    both radar and communication waveforms to address the diverse and heterogeneous
    signal types encountered in practical deployment. Here, the authors train a CNN
    to perform two related tasks based on a single raw IQ input. The two tasks are
    assigned weights to formulate the weighted sum loss function and the model was
    trained with backpropagation. The authors emphasize the significance of designing
    lightweight models from the inception and provide real-world experimental evaluation
    with over-the-air collected waveforms under varying signal strengths. The evaluations
    demonstrated high-speed inferences The lightweight MTL performs faster inferences
    at the rate of 8.4 ms on an Intel Core i5-3230M CPU, consuming up to 90.5% lesser
    memory requirement in contrast to the benchmark. Further, the model was further
    compressed by performing INT8 quantization to showcase the computational savings
    for resource-constrained edge deployment platforms. The uncompressed 32-bit floating
    point (FP32) model was compressed 11.8$\times$ by INT8 quantization with no significant
    accuracy loss to report.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 首次提出了一种多任务学习 (MTL) 模型，能够识别多个任务——调制和信号 (协议) 识别——[[45](#bib.bib45), [46](#bib.bib46)]。这是首个考虑雷达和通信波形以应对实际部署中遇到的多样化和异质信号类型的工作。这里，作者训练了一个
    CNN 来基于单一的原始 IQ 输入执行两个相关任务。这两个任务被分配权重，以形成加权和损失函数，并通过反向传播训练了模型。作者强调了从一开始就设计轻量级模型的重要性，并提供了在不同信号强度下通过无线电波形收集的实际实验评估。评估显示，轻量级
    MTL 在 Intel Core i5-3230M CPU 上的推理速度为 8.4 毫秒，比基准测试节省了高达 90.5% 的内存需求。此外，通过执行 INT8
    量化进一步压缩了模型，以展示资源受限边缘部署平台的计算节省。未压缩的 32 位浮点 (FP32) 模型通过 INT8 量化压缩了 11.8$\times$，且未报告显著的准确性损失。
- en: III Applications
  id: totrans-52
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 应用
- en: III-A RF Device Identification and Authentication
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A RF 设备识别与认证
- en: '![Refer to caption](img/0b561b853e9e34d7f8f79c6f39a15484.png)'
  id: totrans-54
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0b561b853e9e34d7f8f79c6f39a15484.png)'
- en: 'Figure 3: Flowgraph for Identification, Authentication and Authorization'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：识别、认证和授权的流程图
- en: 'Device identification and authentication are essential parts of managing wireless
    network. The proliferation of wireless devices in our environment is making this
    a daunting task due to the ever growing attack surfaces in the context of the
    burgeoning IoT economy. It is also often the case that identification and authentication
    are inaccurately used interchangeably causing further confusion [[47](#bib.bib47)].
    First, we provide definition for identification, authentication, and authorization
    along with Figure [3](#S3.F3 "Figure 3 ‣ III-A RF Device Identification and Authentication
    ‣ III Applications ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges") to encompass the
    overall process. Identification can be seen as a subtask of the overall authentication
    and authorization process. The definitions are provided below [[48](#bib.bib48)],'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 设备识别与认证是管理无线网络的关键部分。由于无线设备在环境中的普及，使得这一任务变得困难，因为不断增长的攻击面在蓬勃发展的物联网经济背景下愈加严重。通常，识别和认证被误用为同义词，造成进一步的混淆[[47](#bib.bib47)]。首先，我们提供了识别、认证和授权的定义，并结合图[3](#S3.F3
    "图 3 ‣ III-A RF 设备识别与认证 ‣ III 应用 ‣ 关于射频 (RF) 指纹识别的综合调查：传统方法、深度学习与开放挑战")以涵盖整体过程。识别可以看作是整体认证和授权过程的一个子任务。定义如下[[48](#bib.bib48)]，
- en: '1.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Identification is the ability to uniquely identify a user or device based on
    a unique ID such as MAC address, IMEI (International Mobile Equipment Identity)
    or MEID (Mobile Equipment Identifier) for phones.
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 识别是基于唯一的 ID（如 MAC 地址、IMEI（国际移动设备身份）或 MEID（移动设备标识符））唯一识别用户或设备的能力。
- en: '2.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Authentication is the ability to prove that a user/device is genuinely who that
    user or device claims to be.
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 认证是证明用户/设备确实是其声称的用户或设备的能力。
- en: '3.'
  id: totrans-61
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Authorization is the process of evaluating whether a authenticated user/device
    has legitimate permission to access a resource or service.
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 授权是评估已认证的用户/设备是否有合法权限访问资源或服务的过程。
- en: 'Traditionally, authentication involves handshake process between the device
    that intends to gain access and the network component that verifies the authentication
    message to grant access [[49](#bib.bib49)]. For example, using a secret key $S$,
    Alice may transmit a message to Bob using cryptography checksum which is a function
    of the message and the secret key. Bob can use the function and key to verify
    the authenticity of Alice while an intruder who tried to modify the message of
    the function will not be authenticated unless the secret key has been compromised.
    While this is not the sole method used in the industry for authentication, it
    is a typical representative example to demonstrate that the traditional authentication
    approach is active, i.e., it involves control message exchange and depends on
    secret keys. As one can imagine this leads to increased overhead due to the active
    nature of the authentication process. While secret keys are used for authentication
    process, it is still a point of vulnerability that could be compromised allowing
    illegitimate users gaining access to the network. Since the RF fingerprinting
    is hardware-specific and often unintentional characterization imparted at the
    analog component level, it is hard to mimic. Therefore, it could be argued that
    RF fingerprinting could be incorporated into more robust identification and authentication
    [[49](#bib.bib49)]. We explore the vulnerabilities of RF fingerprinting in section
    [VI](#S6 "VI Research Challenges and Future Direction ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges").'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '传统上，认证涉及意图访问的设备与验证认证消息以授予访问权限的网络组件之间的握手过程[[49](#bib.bib49)]。例如，使用秘密密钥$S$，Alice可能通过加密校验和将消息传输给Bob，这个校验和是消息和秘密密钥的函数。Bob可以使用该函数和密钥来验证Alice的真实性，而试图修改消息的入侵者除非秘密密钥被泄露，否则无法通过认证。虽然这不是行业中用于认证的唯一方法，但这是一个典型的代表性例子，说明传统认证方法是主动的，即它涉及控制消息交换并依赖秘密密钥。可以想象，这会导致由于认证过程的主动性质而增加开销。尽管秘密密钥用于认证过程，但它仍然是一个可能被破坏的脆弱点，从而允许不合法用户访问网络。由于RF指纹识别是特定于硬件的，并且通常是在模拟组件级别上无意间赋予的特征，很难模仿。因此，可以认为RF指纹识别可以纳入更稳健的身份识别和认证中[[49](#bib.bib49)]。我们在第[VI](#S6
    "VI Research Challenges and Future Direction ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges")节中探讨了RF指纹识别的脆弱性。'
- en: III-B Localization, Tracking, and Navigation
  id: totrans-64
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 定位、跟踪与导航
- en: As RF fingerprinting gains fidelity and robustness, it could be extended to
    or integrated with other applications such as assisting with outdoor or indoor
    localization, navigation, and even tracking of specific verified emitters. This
    could be highly beneficial for tactical applications, law enforcement, and first
    responders. For example, in search and rescue applications victims or rescue operators
    could be uniquely tracked based on the unique RF fingerprint emitted by their
    devices. There are several other examples of applications where such tracking
    can be highly beneficial. For example, there has been interest from the National
    Institute of Justice in using RF fingerprinting for contraband wireless devices
    tracking in correctional facilities [[50](#bib.bib50)]. Similarly, in most cases,
    it is useful to track the warfighters during the mission to monitor their progress,
    instantaneous location, and provide assistance when required. First responders
    often encounter tough situations but in most cases rely on wireless communication
    devices. Thus, if these communication signals can be used to identify and track
    the first responders, it can greatly enhance the efficiency and safety of these
    operations.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 随着RF指纹识别技术的精度和稳健性提高，它可以扩展到或与其他应用集成，例如辅助室内外定位、导航，甚至跟踪特定的已验证发射器。这对于战术应用、执法和急救人员非常有益。例如，在搜索和救援应用中，可以根据设备发出的独特RF指纹来唯一跟踪受害者或救援人员。还有许多其他应用实例，其中这种跟踪可以非常有益。例如，美国国家司法研究所对在矫正设施中使用RF指纹识别跟踪违禁无线设备表现出了兴趣[[50](#bib.bib50)]。类似地，在大多数情况下，跟踪作战人员在任务中的进展、即时位置并在需要时提供帮助是很有用的。急救人员经常遇到困难情况，但通常依赖无线通信设备。因此，如果这些通信信号可以用来识别和跟踪急救人员，它可以大大提高这些操作的效率和安全性。
- en: It is important to point out that there is an added advantage that no specific
    packets need to be emitted to help with the tracking since it can be done implicitly
    by overhearing the communication signals. This could decrease the overall overhead
    required for command and control of such operations. This technology like many
    others is a double-edged sword, one could imagine security vulnerabilities where
    modern devices could be identified by illegitimate entities and then used to track
    leading to privacy and security concerns. This implies there is a whole new emerging
    area of research and analysis that may aim at mitigating such security vulnerabilities.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 需要指出的是，另一个优势是无需发射特定的数据包来帮助跟踪，因为可以通过监听通信信号隐式地完成。这可以减少指挥和控制这类操作所需的整体开销。这项技术像许多其他技术一样是一把双刃剑，人们可以想象现代设备可能会被非法实体识别，然后用于跟踪，从而引发隐私和安全问题。这意味着有一个全新的新兴研究和分析领域，可能旨在缓解这些安全漏洞。
- en: III-C Intrusion detection
  id: totrans-67
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 入侵检测
- en: We discussed some of the security vulnerabilities that could arise from the
    misuse of RF fingerprinting but at the same time, it is a powerful tool to detect
    intrusions and/or imitation attacks. With the proliferation of wireless devices
    ranging from 5G mobile devices to low-cost IoT devices, it is becoming difficult
    to secure the ever-expanding threat surfaces. While there are millions of devices
    they all depend on a few wireless protocols or standards such as 5G, WiFi, BLE,
    LoRa, among others essentially implying that there will also be several devices
    that transmit the same kind of signals. Therefore, it is becoming imperative to
    have the ability to distinguish between legitimate and illegitimate users on-the-fly
    even if they transmit the same signals. More importantly, intruders often mimic
    or perform replay attacks. Just like traditional fingerprints enable some of the
    security systems to detect intruders, RF fingerprinting can serve the same purpose
    for commercial and tactical applications. For example, before a squadron is deployed
    into a mission, each of them could have RF fingerprint information of their fellow
    warfighters. In this way, each device will be able to alert the presence of an
    intruder who is not part of the signature database. There are many commercial
    buildings where unauthorized wireless devices are prohibited, in such commercial
    secure environments, the security officers could deploy a similar methodology
    where every approved device is registered using their RF fingerprint. Once the
    system is activated, the intruder detection system will be able to alert the operator
    of unauthorized transmission even if they resort to replay or imitation attacks.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 我们讨论了一些可能因误用射频指纹识别技术而产生的安全漏洞，但与此同时，它也是一个强大的工具，用于检测入侵和/或仿冒攻击。随着从5G移动设备到低成本物联网设备等无线设备的普及，确保不断扩展的威胁表面变得越来越困难。虽然有数百万个设备，但它们都依赖于少数几种无线协议或标准，如5G、WiFi、BLE、LoRa等，这基本上意味着也会有若干设备发射相同类型的信号。因此，具备实时区分合法用户和非法用户的能力变得至关重要，即使它们发射的是相同的信号。更重要的是，入侵者往往会模仿或进行重放攻击。就像传统的指纹能够帮助某些安全系统检测入侵者一样，射频指纹识别也可以在商业和战术应用中发挥相同的作用。例如，在一个编队被派往任务之前，他们每个人可以拥有其战斗伙伴的射频指纹信息。这样，每个设备都能够警告那些不在签名数据库中的入侵者的存在。许多商业建筑禁止未经授权的无线设备，在这样的商业安全环境中，安全人员可以部署类似的方法，将每个批准的设备通过其射频指纹进行注册。一旦系统启动，入侵检测系统就能够警告操作员未经授权的传输，即使入侵者采取重放或仿冒攻击。
- en: III-D Application Domains
  id: totrans-69
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 应用领域
- en: 'Beyond 5G network or 6G envisions revolutionary application domains [[51](#bib.bib51),
    [2](#bib.bib2), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54)]. However,
    with such immersive applications security and privacy of users as well as assets
    become paramount [[55](#bib.bib55), [56](#bib.bib56), [57](#bib.bib57), [58](#bib.bib58),
    [59](#bib.bib59)]. In this section, we shed some light on the envisioned applications
    for RF fingerprinting in the context of 6G as shown in Figure. [4](#S3.F4 "Figure
    4 ‣ III-D Application Domains ‣ III Applications ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges").'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  id: totrans-71
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Intelligent Telehealth*: Intelligent and real-time healthcare will witness
    a paradigm shift with the 6G network. Real-time health monitoring, hospital-to-hospital
    services, Internet-of-Medical-Things (IoMT) also known as Healthcare IoT will
    collectively present dynamic and responsive health services [[54](#bib.bib54),
    [60](#bib.bib60)]. Body area networks (BAN) with interconnected IoMT will advance
    and personalize telehealth monitoring and management. Remote health services with
    holographic teleconferencing with the ultra low latency 6G communication holds
    immense potential in democratizing healthcare services. Security and privacy for
    such an interconnected healthcare system that maintains the patient database and
    vital healthcare provider information is the backbone in realizing the tactile
    6G healthcare. Wireless device fingerprinting solutions that resides on edge IoMT
    devices will be key to the real-time secure 6G IoT-based healthcare. We foresee
    that such solutions in conjunction with distributed ledger based multifactor authentication
    can secure the integrity and privacy of the users from spoofing, denial-of-service
    (DoS), identity theft attacks, among others.'
  id: totrans-72
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  id: totrans-73
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Autonomous UAV and V2X*: Aerial base stations and swarms of UAV can revolutionize
    and democratize wireless connectivity. Especially, setting up infrastructureless
    networks can provide emergency response, healthcare services, etc., by connecting
    remote and austere locations. Such concepts have been explored in the past [[61](#bib.bib61)]
    and will be a potential 6G use case [[52](#bib.bib52), [53](#bib.bib53), [62](#bib.bib62)].
    Similarly, connected autonomous vehicles as in a V2X scenario would involve the
    vehicles communicating with nearby networks along its route. In these applications,
    handover from one network to another based on location and mobility is a necessity.
    Accordingly a robust, fast, and lightweight device authentication will be a key
    enabler to account for the diversity and mobility of devices accessing the network.
    RF fingerprinting which inherently involves no control overhead and merely uses
    hardware signatures embedded in the unintentional emissions will be an ideal candidate
    for such lightweight authentication schemes.'
  id: totrans-74
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  id: totrans-75
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*Smart Grid 2.0* Smart grids are IoT-based electrical network for remote monitoring
    and control of power systems. With the advent of 6G, the smart grids will be able
    to support higher density of IoT devices for ultra low latency and high reliability
    communication enabling real-time anomaly detection and mitigation over distributed
    grid lines and stations. Confidentiality of the information managed in these power
    grids pertaining to user information, power metering, electrical usage patterns,
    billing details, among others are indispensable and primary targets of cybersecurity
    attacks. Moreover, smart grid 2.0 envisions intelligent pricing, automated grid
    management including energy trading among unknown parties in a point-to-point
    manner which further exposes the threat surfaces [[52](#bib.bib52)]. Device fingerprinting
    based authentication and grid access for secure energy trading will therefore
    gain popularity to realize smart grid 2.0.'
  id: totrans-76
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*智能电网 2.0* 智能电网是基于物联网的电力网络，用于远程监控和控制电力系统。随着6G的到来，智能电网将能够支持更高密度的物联网设备，实现超低延迟和高可靠性的通信，从而实现对分布式电网线路和站点的实时异常检测和缓解。电网中涉及的用户信息、电力计量、电气使用模式、账单细节等信息的机密性是网络安全攻击的不可或缺且主要目标。此外，智能电网2.0设想了智能定价、自动化电网管理，包括在点对点的方式下进行的未知方之间的能源交易，这进一步暴露了威胁面[[52](#bib.bib52)]。因此，基于设备指纹的认证和安全能源交易的电网访问将获得越来越多的关注，以实现智能电网2.0。'
- en: '4.'
  id: totrans-77
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: '*Extended Reality*: Extended reality (XR) is a blanket term to refer all real
    and virtual environments including virtual reality (VR), augmented reality (AR),
    mixed reality, and everything in between [[63](#bib.bib63), [64](#bib.bib64)].
    6G will support advanced XR for various use cases such as military tactical training,
    video conferencing, online gaming, etc. In such applications along with meeting
    the latency and rate requirements, user privacy will be an equally necessary and
    challenging prerequisite. Consequently, user (device) authentication and access
    control will play a pivotal role here.'
  id: totrans-78
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '*扩展现实*：扩展现实（XR）是一个总括性术语，指代所有真实和虚拟环境，包括虚拟现实（VR）、增强现实（AR）、混合现实以及介于两者之间的所有形式[[63](#bib.bib63),
    [64](#bib.bib64)]。6G将支持先进的XR应用，如军事战术训练、视频会议、在线游戏等。在这些应用中，除了满足延迟和速率要求外，用户隐私将同样成为一个必要且具有挑战性的前提条件。因此，用户（设备）认证和访问控制将在这里发挥关键作用。'
- en: 'Figure 4: Application Domains for RF fingerprinting'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：无线射频指纹识别的应用领域
- en: IV Traditional Approaches for RF fingerprinting
  id: totrans-80
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 无线射频指纹识别的传统方法
- en: IV-A Modulation domain based Approach
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 基于调制域的方法
- en: IV-A1 PARADIS
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 PARADIS
- en: The authors in [[65](#bib.bib65)] propose a radiometric signature-based device
    identification called PARADIS (Passive RAdiometic Device Identification System).
    This approach is based on the concept of radiometric identity - taking advantage
    of minor variations of transmitter hardware leading to peculiar features in the
    transmitted signal - to identify the origin. The authors demonstrate the accuracy
    of PARADIS to be greater than $99\%$ for classifying more than $130$ 802.11 Network
    interface cards (NICs). The system quantifies the transmitter’s radiometric identity
    by comparing the signal with an ideal signal in the modulation domain on a frame-by-frame
    basis.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献[[65](#bib.bib65)]中的作者提出了一种基于辐射特征的设备识别方法，称为PARADIS（被动辐射设备识别系统）。该方法基于辐射特征概念——利用发射器硬件的微小变化导致传输信号中的独特特征——来识别来源。作者展示了PARADIS在分类超过$130$个802.11网络接口卡（NICs）时准确度超过$99\%$。该系统通过逐帧将信号与调制域中的理想信号进行比较，从而量化发射器的辐射特征。
- en: Modulation domain metrics such as frequency error, SYNC correlation, IQ offset,
    magnitude error, and phase error are used as the features for determining the
    radiometric identity of the device. The features resulting from hardware imperfections
    will be apparent over multiple frames. Therefore, calculating the statistical
    averages of these variations over multiple frames will magnify the artifacts caused
    by the hardware while at the same time reducing the effects of noise and channel.
    Following this, these five modulation domain metrics are classified using a classifier
    to identify the source. Two radiometric signature classifiers are implemented
    and evaluated, one using the SVM algorithm and the other using the k-nearest neighbors
    (k-NN) algorithm. The SVM classifier is built using LIBSVM [[66](#bib.bib66)],
    the model takes a single radiometric signature as input and outputs the most likely
    identity of the source with the measure of confidence. A k-NN classifier is implemented
    using a group of rankers, where each NIC has one ranker that calculates the similarity
    between a given signal and the template of its signature computed during training.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 调制域度量指标如频率误差、SYNC相关性、IQ偏移、幅度误差和相位误差被用作确定设备辐射身份的特征。由于硬件缺陷引起的特征在多个帧中会明显出现。因此，计算这些变化在多个帧中的统计平均值将放大由硬件引起的伪影，同时减少噪声和信道的影响。接下来，使用分类器对这五种调制域度量指标进行分类，以识别来源。实现并评估了两种辐射特征分类器，一种使用SVM算法，另一种使用k-近邻（k-NN）算法。SVM分类器使用LIBSVM[[66](#bib.bib66)]构建，模型以单一辐射特征作为输入，并输出最可能的来源身份及其置信度。k-NN分类器使用一组排名器实现，每个NIC有一个排名器，该排名器计算给定信号与在训练过程中计算的其特征模板之间的相似度。
- en: The authors evaluated PARADIS on the ORBIT indoor wireless testbed facility
    [[67](#bib.bib67)]. They collected data from 138 Atheros NICs configured as 802.11b
    access points on channel 1\. Agilent 89641S vector signal analyzer was used as
    the PARADIS sensor to capture the frames from the transmitters. Overall, PARADIS
    using the SVM algorithm had an error rate of $0.0034\%$, and the system using
    the k-NN algorithm had an error rate of $3\%$ in classifying $138$ identical NICs.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 作者在ORBIT室内无线测试平台[[67](#bib.bib67)]上评估了PARADIS。他们从配置为802.11b接入点的138个Atheros NIC中收集了数据。使用Agilent
    89641S矢量信号分析仪作为PARADIS传感器来捕获发射器发出的帧。总体而言，使用SVM算法的PARADIS的错误率为$0.0034\%$，而使用k-NN算法的系统在分类$138$个相同NIC时的错误率为$3\%$。
- en: IV-A2 IQ Imbalance
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 IQ不平衡
- en: In [[68](#bib.bib68)], the authors proposed a method to extract RF fingerprint
    features based on the IQ imbalance of the quadrature modulation signals. The IQ
    imbalance is caused due to the hardware imperfections in the IQ quadrature modulator.
    In the proposed method, the features are extracted by performing autocorrelation
    on the received signals. Real and imaginary parts of the autocorrelation form
    the RF fingerprint feature, and the SNR is estimated using the traditional least
    squares algorithm. To evaluate the method, the authors simulate five analog modulators
    (emitters) by varying the gain and orthogonal IQ imbalance and generate 400 signals
    from each emitter. The fingerprint feature vector is extracted using the proposed
    method and an SVM classifier is trained using half of the dataset. This method
    performs with an accuracy greater than $90\%$ for SNR $\geq 15$dB and greater
    than $99\%$ for SNR $\geq 20$dB.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[68](#bib.bib68)]中，作者提出了一种基于四相调制信号的IQ不平衡来提取射频指纹特征的方法。IQ不平衡是由于IQ四相调制器的硬件缺陷引起的。在提出的方法中，通过对接收信号进行自相关来提取特征。自相关的实部和虚部构成射频指纹特征，SNR使用传统的最小二乘法估算。为了评估该方法，作者通过改变增益和正交IQ不平衡来模拟了五种模拟调制器（发射器），并从每个发射器生成了400个信号。使用提出的方法提取了指纹特征向量，并用数据集的一半训练了SVM分类器。该方法在SNR
    $\geq 15$dB时的准确率超过$90\%$，在SNR $\geq 20$dB时的准确率超过$99\%$。
- en: IV-A3 Modulation shape and spectral features
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A3 调制形状和频谱特征
- en: The work in [[69](#bib.bib69)] proposes a method for identifying Radio Frequency
    Identification Devices (RFID) by extracting the RF fingerprint from modulation
    shape and spectral features of the signal emitted by the transponder when subjected
    to an RFID reader. The proposed method is able to identify $50$ identical RFID
    transponders from the same manufacturer with an error rate of $2.43\%$.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献[[69](#bib.bib69)]中提出了一种通过提取调制形状和信号发射的光谱特征来识别射频识别设备（RFID）的方法。该方法能够以$2.43\%$的错误率识别$50$个来自同一制造商的相同RFID应答器。
- en: The authors use a purpose-built RFID reader to transmit to the target transponder
    for capturing the signals. It consists of two signal generators for envelope and
    modulation generation and a PCB antenna to transmit to the RFID transponder. The
    response from the RFID transponder is captured using an antenna and oscilloscope.
    Using this setup, the authors collected data from 50 JCOP NXP 4.1 smart cards
    and 8 electronic passports via the following four methods;
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用了一个专门构建的RFID读写器来传输信号到目标应答器以捕捉信号。该设备包括两个信号发生器用于包络和调制生成，以及一个PCB天线用于传输到RFID应答器。使用天线和示波器捕捉RFID应答器的响应。使用此设置，作者通过以下四种方法收集了50个JCOP
    NXP 4.1智能卡和8个电子护照的数据；
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method 1: Capturing the response of the transponder when subjected to ISO/IEC
    14443 standard Type A and B protocols.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法1：在应答器暴露于ISO/IEC 14443标准A型和B型协议时捕捉其响应。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method 2 (Varied $F_{c}$): Capturing the response of the transponder when subjected
    to out of specification (carrier frequency only) ISO/IEC 14443 standard Type A
    and B protocols.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法2（变化的$F_{c}$）：在应答器暴露于不符合规范的（仅载波频率）ISO/IEC 14443标准A型和B型协议时捕捉其响应。
- en: •
  id: totrans-95
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method 3 (Burst): Capturing the response of the transponder when subjected
    to bursts of RF energy (10 cycles of non-modulated $5$ MHz carrier at $10$V peak-to-peak).'
  id: totrans-96
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法3（脉冲）：在应答器暴露于RF能量脉冲（$10$周期的非调制$5$ MHz载波，$10$V峰值-峰值）时捕捉其响应。
- en: •
  id: totrans-97
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Method 4 (Frequency sweep): Capturing the response of the transponder when
    subjected to linear sweep of a non-modulated carrier from $100$ Hz to $15$ MHz
    (at $10$ V peak-to-peak).'
  id: totrans-98
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 方法4（频率扫描）：在$100$ Hz到$15$ MHz（$10$ V峰值-峰值）线性扫描非调制载波时捕捉应答器的响应。
- en: Modulation-shape features for data captured using methods 1 and 2 and spectral
    principal component analysis (PCA) for methods 3 and 4 are extracted. Modulation-shape
    features are extracted by performing Hilbert transformation on the captured signals.
    The starting point of the modulation in the transformed signal is located using
    a variance-based threshold detection algorithm [[70](#bib.bib70)]. Standardized
    Euclidean distance is obtained by matching the extracted fingerprint feature with
    the reference fingerprint [[71](#bib.bib71)]. Similarly, the Mahalanobis distance
    is evaluated by matching the reference fingerprint features to the test features.
    The spectral PCA features are extracted using a modified PCA for higher dimension
    data [[72](#bib.bib72)].
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 使用方法1和方法2捕捉的数据提取了调制形状特征，而方法3和方法4则使用光谱主成分分析（PCA）。通过对捕捉到的信号进行Hilbert变换来提取调制形状特征。使用基于方差的阈值检测算法[[70](#bib.bib70)]来定位变换信号中的调制起点。通过将提取的指纹特征与参考指纹进行匹配来获得标准化的欧几里得距离[[71](#bib.bib71)]。类似地，通过将参考指纹特征与测试特征进行匹配来评估Mahalanobis距离。光谱PCA特征通过针对高维数据的改进PCA方法提取[[72](#bib.bib72)]。
- en: To evaluate the classification capabilities of the proposed techniques, the
    authors consider signals captured from 8 e-passports and 50 JCOP NXP 4.1 cards.
    Both classification techniques, one using modulation features and the other using
    spectral features, perform with an error rate of $0\%$ when classifying signals
    into three classes (two countries, JCOP NXP card). The authors evaluate the identification
    capabilities of the method by using data collected through methods 3 and 4 consisting
    of data from 50 identical JCOP NXP 4.1 cards. The proposed method performs with
    an accuracy of $95\%$ in identifying 50 RFID cards when spectral features from
    data collected through methods 3 and 4 are used individually. Finally, when the
    spectral features from data collected through methods 3 and 4 are combined, the
    accuracy increases to $97.5\%$.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 为评估所提出技术的分类能力，作者考虑了来自8个电子护照和50个JCOP NXP 4.1卡的信号。两种分类技术——一种使用调制特征，另一种使用谱特征——在将信号分类为三类（两个国家、JCOP
    NXP卡）时的误差率为$0\%$。作者通过使用方法3和4的数据（来自50张相同的JCOP NXP 4.1卡）来评估该方法的识别能力。所提出的方法在使用方法3和4的数据单独计算的光谱特征时，在识别50张RFID卡时的准确率为$95\%$。最后，当将通过方法3和4收集的数据的光谱特征结合起来时，准确率提高到$97.5\%$。
- en: IV-A4 Weighted Voting-Based Classification of Modulation Domain Signals
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A4 基于加权投票的调制域信号分类
- en: 'In [[73](#bib.bib73)], the authors propose the use of a committee of weak classifiers
    to provide a strong classification by using weighted voting to combine results
    of multiple weak classifiers. Physical characteristics of the radio like frequency
    offset, modulation phase offset, in-phase/quadrature-phase offset, and magnitude
    are extracted from signals generated by six different radios in Wireless Open-Access
    Research Platform (WARP). Differential Quadrature phase-shift keying (DQPSK) modulation
    signals are generated and transmitted by the six radio cards. A total of 14 ML
    classifiers are built using the following signal characteristics:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[73](#bib.bib73)]中，作者提出使用弱分类器的委员会，通过加权投票来结合多个弱分类器的结果，从而提供强分类。无线电的物理特征，如频率偏移、调制相位偏移、同相/正交相位偏移和幅度，都是从无线开放接入研究平台（WARP）中六个不同无线电生成的信号中提取的。六个无线电卡生成并传输差分正交相移键控（DQPSK）调制信号。总共建立了14个机器学习分类器，使用以下信号特征：
- en: •
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Frequency difference (1 classifier): The distance between the actual transmission
    and ideal carrier frequency.'
  id: totrans-104
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 频率差（1个分类器）：实际传输频率与理想载波频率之间的距离。
- en: •
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Magnitude difference (4 classifiers): The distance between the magnitude of
    transmitted and ideal carrier symbols.'
  id: totrans-106
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 幅度差（4个分类器）：传输符号与理想载波符号之间的幅度差。
- en: •
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Phase difference (4 classifiers): The angular distance between the transmitted
    and the ideal symbol in the IQ domain.'
  id: totrans-108
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 相位差（4个分类器）：在IQ域中，传输符号与理想符号之间的角距离。
- en: •
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Distance vector (4 classifiers): Vector distance between the transmitted and
    the ideal symbol.'
  id: totrans-110
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 距离向量（4个分类器）：传输符号与理想符号之间的向量距离。
- en: •
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'IQ origin offset (1 classifier): Distance between the origin of the ideal IQ
    plane and the origin of the transmitted symbol in the IQ domain.'
  id: totrans-112
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: IQ原点偏移（1个分类器）：理想IQ平面的原点与传输符号在IQ域中的原点之间的距离。
- en: The 14 classifiers are trained with the first 200 frames of 1844 random QPSK
    symbols from each board, then the outputs of the classifiers are combined using
    weighted voting to get the final radio identity. The weighted voting-based classifier
    has an average accuracy of $88\%$ in detecting six radio cards.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 14个分类器使用来自每个板的1844个随机QPSK符号的前200帧进行训练，然后使用加权投票将分类器的输出进行组合，以获得最终的无线电身份。基于加权投票的分类器在检测六个无线电卡时的平均准确率为$88\%$。
- en: IV-A5 Constellation Error Features
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A5 星座误差特征
- en: The authors in [[74](#bib.bib74)] propose an RF fingerprinting approach based
    on constellation error features. Transmitter imperfection that is reflected in
    error between the received constellation and the ideal constellation is used as
    the feature for RF fingerprinting. These features are extracted using subclass
    discriminant analysis (SDA). Burst QPSK modulated signals from seven TDMA satellite
    terminals are captured to construct the dataset for testing. The received signal
    is synchronized for time and frequency before building the modulation constellation,
    following which the constellation errors are computed. Feature vectors containing
    41 features are extracted and classified for each of the signals using SDA feature
    extraction. The proposed method performs with an accuracy greater than $95\%$
    for the bin size of the SDA feature extraction method greater than 12.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: 'As we conclude this section, we summarize the reviewed literature in Table
    [I](#S4.T1 "TABLE I ‣ IV-A5 Constellation Error Features ‣ IV-A Modulation domain
    based Approach ‣ IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges") for easy comparison for the reader.'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: '| Work | Radiometric Parameter | Classification technique | RF emitters | Performance
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '| *Brik et al.*[[65](#bib.bib65)] | frequency error, SYNC correlation, IQ offset,
    magnitude error, and phase error | k-NN & SVM | $138$ 802.11 NICs | SVM$\rightarrow
    99.9\%$ k-NN$\rightarrow 97\%$ |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
- en: '| *Zhuo et al.*[[68](#bib.bib68)] | IQ Imbalance | SVM | MATLAB simulated 5
    analog modulators | $\geq 90\%$ for SNR $\geq 15$dB |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |  |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| *Danev et al.*[[69](#bib.bib69)] | Modulation-shape and spectral PCA features
    | Mahalanobis distance | 8 e-passports and 5 JCOP NXP 4.1 cards | $100\%$ classification
    accuracy and $97.5\%$ identification accuracy. |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: '| *Candore et al.*[[73](#bib.bib73)] | frequency offset, modulation phase offset,
    in-phase/quadrature-phase offset, and magnitude | weighted voting-based classifier
    | Six WARP radio cards | 88% identification accuracy and 12.8% false alarm rate
    |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
- en: '| *Huang et al.* [[74](#bib.bib74)] | constellation-error | SDA feature extraction
    | seven TDMA satellite terminals | 95% identification accuracy |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
- en: 'TABLE I: Modulation-domain based RF fingerprinting works'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Statistical Approach
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: IV-B1 Non-Parametric Feature
  id: totrans-128
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[75](#bib.bib75)], the generation and use of non-parametric features like
    mean, median, mode, and linear model coefficients (slope and intercept are estimated
    by linear regression) for identifying ZigBee devices is proposed. Complex IQ signals
    from four Texas Instruments ZigBee CC2420 devices are captured using Agilent E3238S
    receiver. The phase variable of the received signal is generated and the preamble
    region of the phase variables is divided into 32 equal sized Regions of Interest
    (ROIs). Following this, the non-parametric features are generated for each ROI.
    The signals are classified using a random forest classifier with 1000 trees. Each
    of the four non-parametric features is used individually to classify the device.
    The results show that the classification accuracy for each of the non-parametric
    features is above $97\%$ for SNR$\geq 10$dB. At lower SNR, linear model coefficient
    features perform better than the other non-parametric features. The author also
    compares the performance of using the non-parametric features over parametric
    features by computing the parametric features (variance, skewness, and kurtosis)
    for each ROI. The same random forest classifier is used to classify the features
    individually. The non-parametric features show improvements by upto $9\%$ at SNR$=8$dB
    over the parametric features.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[75](#bib.bib75)]中，提出了通过生成和使用非参数特征如均值、中位数、众数以及线性模型系数（斜率和截距由线性回归估计）来识别ZigBee设备的方法。使用Agilent
    E3238S接收机捕获来自四个德州仪器ZigBee CC2420设备的复杂IQ信号。生成接收信号的相位变量，并将相位变量的前导区分为32个大小相等的兴趣区域（ROIs）。接下来，为每个ROI生成非参数特征。使用具有1000棵树的随机森林分类器对信号进行分类。每个非参数特征都单独用于设备分类。结果表明，对于SNR$\geq
    10$dB，每个非参数特征的分类准确率均超过$97\%$。在较低SNR下，线性模型系数特征的表现优于其他非参数特征。作者还通过计算每个ROI的参数特征（方差、偏度和峰度），比较了使用非参数特征与参数特征的性能。相同的随机森林分类器用于单独分类这些特征。非参数特征在SNR$=8$dB时，比参数特征提高了最多$9\%$的分类精度。
- en: IV-B2 RF-DNA based features
  id: totrans-130
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 基于RF-DNA的特征
- en: In [[76](#bib.bib76)], the authors propose a RF distinct native attribute (RF-DNA)
    based RF fingerprinting for identifying ultra-wideband (UWB) noise radar emitting
    devices. RF-DNA fingerprint features, including variance, skewness, and kurtosis,
    are extracted for the time-domain response of the signals. Additionally, the authors
    also extract normalized power spectral density (PSD) and discrete Gabor transform
    from the spectral-domain response of the signals. The signals are classified using
    multiple discriminant analysis with maximum likelihood (MDA/ML) classifier and
    generalized relevance learning vector quantization-improved (GRLVQI) classifiers.
    MDA/ML classifier is a combination of multiple discriminant analysis (MDA) that
    aims to reduce the dimensionality of a multi-dimensional dataset and maximum likelihood
    (ML) classifier. The GRLVQI classifier is a supervised machine learning method
    that enlarges generalized learning vector quantization (GLVQ) by adding weighting
    factors to the input dimensions [[77](#bib.bib77)]. These factors allow for appropriate
    scaling of the input dimensions according to their relevance and are adapted automatically
    during training according to the specific classification task.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[76](#bib.bib76)]中，作者提出了一种基于RF-DNA（射频独特本地属性）的RF指纹识别方法，用于识别超宽带（UWB）噪声雷达发射设备。RF-DNA指纹特征，包括方差、偏度和峰度，是从信号的时域响应中提取的。此外，作者还从信号的频域响应中提取了归一化的功率谱密度（PSD）和离散Gabor变换。信号使用最大似然的多重判别分析（MDA/ML）分类器和改进的广义相关学习向量量化（GRLVQI）分类器进行分类。MDA/ML分类器是多重判别分析（MDA）与最大似然（ML）分类器的组合，旨在降低多维数据集的维度。GRLVQI分类器是一种监督机器学习方法，通过向输入维度添加权重因子来扩展广义学习向量量化（GLVQ）[[77](#bib.bib77)]。这些因子允许根据输入维度的相关性进行适当的缩放，并在训练过程中根据具体的分类任务自动调整。
- en: The classification performance is evaluated on signals captured by transmitting
    UWB noise radar waveforms using a log-periodic antenna placed one meter from the
    receiver in an anechoic chamber. By varying the termination load of the transmitting
    antenna, three classes of waveforms are captured. Additionally, an attenuator
    is used to increase the number of classes. For the three-class case using only
    time-domain fingerprint features, the proposed method has a classification accuracy
    of $99.7\%$ and $98.25\%$ for MDA/ML and GRLVQI classifiers, respectively. In
    the case of the seven-class dataset using only time-domain fingerprint features,
    the proposed method has an average classification accuracy of $81\%$ and $75\%$
    for MDA/ML and GRLVQI classifiers, respectively. Similarly, for the three-class
    dataset using only spectrum-domain fingerprint features, the proposed method has
    a classification accuracy of $91.97\%$ and $94.47\%$ for MDA/ML and GRLVQI classifiers,
    respectively. Lastly, using a combination of time and frequency domain features,
    the classification accuracy for the three-class data is $97.65\%$ and $93,79\%$
    for MDA/ML and GRLVQI classifiers, respectively.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 分类性能在使用放置在接收器一米远的无回声室中的对数周期天线发射UWB噪声雷达波形捕获的信号上进行评估。通过改变发射天线的终端负载，捕获了三类波形。此外，还使用了一个衰减器来增加类别数。对于仅使用时域指纹特征的三类情况，所提出的方法在MDA/ML和GRLVQI分类器中的分类准确率分别为$99.7\%$和$98.25\%$。在仅使用时域指纹特征的七类数据集中，所提出的方法在MDA/ML和GRLVQI分类器中的平均分类准确率分别为$81\%$和$75\%$。类似地，对于仅使用频谱域指纹特征的三类数据集，所提出的方法在MDA/ML和GRLVQI分类器中的分类准确率分别为$91.97\%$和$94.47\%$。最后，使用时间域和频率域特征的组合，三类数据的分类准确率为$97.65\%$和$93.79\%$。
- en: IV-C Transient-based Approach
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 瞬态基础方法
- en: 'Transient-based approach involves identifying distinctive features present
    in the radio turn-on transients, which appear at the start of the transmission.
    The transient is the section of the signal where the amplitude rises from channel
    noise to signal amplitude. Identification of devices using this process consists
    of three steps: detection of transients, extraction of features, and classification.
    A brief overview of the two key approaches of transient detection: Threshold[[78](#bib.bib78)]
    and Bayesian step-change detector[[79](#bib.bib79)] is discussed in [[80](#bib.bib80)].
    Both of which exploit the amplitude characteristics of the signal for transient
    detection. They also propose a new approach for transient detection using the
    phase characteristic of the signal to improve performance when the transient gradient
    is gradual.'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 瞬态基础方法涉及识别无线电开启瞬态中的独特特征，这些瞬态出现在传输开始时。瞬态是信号的部分，其中幅度从通道噪声上升到信号幅度。使用此过程识别设备包括三个步骤：瞬态检测、特征提取和分类。[[80](#bib.bib80)]中讨论了瞬态检测的两个关键方法：阈值[[78](#bib.bib78)]和贝叶斯步进变化检测器[[79](#bib.bib79)]。这两种方法都利用信号的幅度特征进行瞬态检测。它们还提出了一种新的瞬态检测方法，使用信号的相位特征来改善瞬态梯度缓慢时的性能。
- en: IV-C1 Fast Fourier Transform (FFT)-based Fisher features
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 基于快速傅里叶变换（FFT）的Fisher特征
- en: The authors of [[81](#bib.bib81)] propose the use of FFT-based Fisher features
    to identify wireless nodes. In this approach, the RF fingerprint (feature template)
    of the signals is computed by first detecting the start point and extracting the
    transient of the signals using a variance-based threshold detection algorithm
    [[70](#bib.bib70)]. The relative difference between the adjacent FFT spectra is
    determined by applying a 1-D Fourier Transform on the transients. Following which
    the Fisher feature vector that forms the feature template is extracted using a
    Linear Discriminant Analysis (LDA) matrix. The LDA matrix is derived by a standard
    procedure based on scatter matrices [[82](#bib.bib82)]. Lastly, the fingerprint
    is matched by calculating the Mahalanobis distance between the reference and test
    signals feature template.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '[[81](#bib.bib81)]的作者提出使用基于FFT的Fisher特征来识别无线节点。在这种方法中，信号的RF指纹（特征模板）通过首先检测起始点并使用基于方差的阈值检测算法[[70](#bib.bib70)]提取信号的瞬态来计算。通过对瞬态应用一维傅里叶变换来确定相邻FFT谱之间的相对差异。接着，使用线性判别分析（LDA）矩阵提取形成特征模板的Fisher特征向量。LDA矩阵通过基于散布矩阵的标准程序[[82](#bib.bib82)]推导。最后，通过计算参考和测试信号特征模板之间的马氏距离来匹配指纹。'
- en: Over 600 IEEE 802.15.4 signal samples from 50 consumer-off-the-shelf (COTS)
    Tmote sky sensor nodes with the same manufacturer signature are collected to evaluate
    the proposed technique. The system identifies the 50 sensors with an accuracy
    higher than $99.5\%$. This work also investigates the effects of parameters such
    as distance, antenna polarization, and voltage on the performance of the system.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
- en: The results of these investigations suggest the system is robust against distance,
    multipath propagation, and voltage changes. But a change in the polarization of
    the signal alters the shape of the transient perturbing the frequency information
    present in the transient consequently leading to a drop in recognition accuracy.
    They also investigate the practicality of the system on attacks such as hill-climbing
    and DoS. Hill-climbing attack is a common impersonation attack where the attacker
    repeatedly submits data to the algorithm with slight modification. Modifications
    that improve or preserve the matching score are preserved. Over time, the attacker
    can achieve a score higher than the designed threshold resulting in a successful
    impersonation. The system can be vulnerable to an impersonation attack when the
    number of signals used to build the fingerprint feature template is low. This
    work investigates the vulnerability of the system to jamming-based DoS attacks.
    Due to the superposition of the original and the jamming signals, the system is
    unable to recognize the device. The authors suggest that this type of attack can
    be used as a security measure against an attacker.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: IV-C2 Hilbert-Huang transform-based time-frequency-energy distribution features
  id: totrans-139
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The authors propose a specific emitter identification (SEI) method based on
    the transient signal’s time-frequency-energy distribution (TFED) obtained by Hilbert-Huang
    transform (HHT) [[83](#bib.bib83)]. HHT is a self-adaptive signal analysis method
    it involves Empirical Mode Decomposition (EMD) and Hilbert transform [[84](#bib.bib84)].
    The EMD method decomposes a given signal into a set of a finite number of intrinsic
    mode functions (IMFs). Applying Hilbert transform on the IMFs yields the TFED.
    The start of the signal is detected using a phase-based method [[80](#bib.bib80)]
    and the endpoint is detected by forming the energy trajectory of the signal from
    TFED. Following thirteen features are extracted from the TFED:'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Three features from overall features: Sum of energy, duration of transient
    signal, and duration of the maximum energy point.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Four energy distribution features along the frequency-axis: entropy, kurtosis,
    skewness, and center.'
  id: totrans-144
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Four energy distribution features along the time-axis: entropy, kurtosis, skewness,
    and center.'
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Two energy distribution features of the overall time-frequency plane: entropy
    and center.'
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The authors use PCA to reduce the dimension of the feature vector and use an
    SVM to classify the devices. The authors collect transient signals from eight
    GSM mobile phones (four Nokia 5230, two Motorola Me525, and two Xiaomi-1) using
    a Leroy 8500A digital oscilloscope connected to a digital receiver with a Yagi
    antenna. The SVM classifier is trained with 50 transient signals from each device,
    and the system is tested with 100 transient signals from each device. The proposed
    method attains an accuracy of $100\%$ in classifying the eight mobile devices.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用PCA降维特征向量，并使用SVM对设备进行分类。作者使用连接到带有Yagi天线的数字接收器的Leroy 8500A数字示波器收集来自八部GSM手机（四部诺基亚5230，两部摩托罗拉Me525，两部小米-1）的瞬态信号。SVM分类器使用来自每个设备的50个瞬态信号进行训练，系统使用来自每个设备的100个瞬态信号进行测试。该方法在分类这八部移动设备时达到了$100\%$的准确率。
- en: IV-C3 Energy envelope features
  id: totrans-150
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C3 能量包络特征
- en: 'In [[85](#bib.bib85)], features extracted from the energy envelope of the transient
    signal are used as RF fingerprints to identify Bluetooth devices. The transients
    are extracted from the normalized signals using variance-based threshold method
    [[70](#bib.bib70)]. The energy envelope is then extracted using the spectrogram
    which is defined as the squared magnitude of Short-Time Fourier Transform (STFT).
    The spectrogram computes a three-dimensional TFED that is then sliced with respect
    to the instantaneous frequency at the maximum energy value to obtain the smoothed
    energy envelope curve. Finally, the RF fingerprint is formed by extracting the
    following features from the energy envelope curve:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[85](#bib.bib85)]中，从瞬态信号的能量包络中提取的特征被用作射频指纹以识别蓝牙设备。使用基于方差的阈值方法[[70](#bib.bib70)]从归一化信号中提取瞬态。然后使用定义为短时傅里叶变换（STFT）平方幅度的谱图来提取能量包络。谱图计算三维TFED，然后根据最大能量值的瞬时频率对其进行切片，以获得平滑的能量包络曲线。最后，通过从能量包络曲线中提取以下特征来形成射频指纹：
- en: •
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Area under the normalized curve.
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 归一化曲线下的面积。
- en: •
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Duration of transient.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 瞬态的持续时间。
- en: •
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Maximum slope of the curve.
  id: totrans-157
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 曲线的最大斜率。
- en: •
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Kurtosis of the curve.
  id: totrans-159
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 曲线的峰度。
- en: •
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Skewness of the curve.
  id: totrans-161
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 曲线的偏度。
- en: •
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Variance of the transient envelope.
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 瞬态包络的方差。
- en: Bluetooth device discovery mode signals from seven built-in Bluetooth transceivers
    of cell phones are captured using an oscilloscope and an Agilent spectrum analyzer.
    A total of 300 signals from each of the seven Bluetooth transceivers are captured
    and the RF fingerprint features are extracted. A k-NN classifier with $3$ nearest
    neighbors is used to classify the feature vector. Fifty signals from each of the
    seven devices are used to train the classifier, and the remaining 250 signals
    are used for testing. The proposed method classifies the devices with an accuracy
    of $99.9\%$. Further, the authors investigated the effect of sampling rate on
    classification accuracy. Because the energy envelope of the transient does not
    change with the sampling rate, the accuracy of identifying devices remains $99.9\%$
    for a sampling rate of 4 GSps, 1 GSps, 512 MSps, 256 MSps, 128 MSps, and 32 MSps.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 使用示波器和Agilent频谱分析仪捕获来自手机的七个内置蓝牙收发器的蓝牙设备发现模式信号。从每个蓝牙收发器捕获了总计300个信号，并提取了射频指纹特征。使用$3$个最近邻的k-NN分类器对特征向量进行分类。从每个设备的50个信号用于训练分类器，其余250个信号用于测试。该方法以$99.9\%$的准确率对设备进行分类。此外，作者调查了采样率对分类准确性的影响。由于瞬态的能量包络不随采样率变化，因此在4
    GSps、1 GSps、512 MSps、256 MSps、128 MSps和32 MSps的采样率下，设备识别的准确率保持在$99.9\%$。
- en: 'The above discussed transient-based RF fingerprinting literature are also summarized
    in Table [II](#S4.T2 "TABLE II ‣ IV-C3 Energy envelope features ‣ IV-C Transient-based
    Approach ‣ IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges").'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: '上述基于瞬态的射频指纹文献也在表[II](#S4.T2 "TABLE II ‣ IV-C3 Energy envelope features ‣ IV-C
    Transient-based Approach ‣ IV Traditional Approaches for RF fingerprinting ‣ A
    Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges")中总结。'
- en: '| Cited literature | Transient detection method | Classification technique
    | RF emitters | performance |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 引用文献 | 瞬态检测方法 | 分类技术 | 射频发射器 | 性能 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| *Danev et al.*[[81](#bib.bib81)] | Variance-based threshold | Mahalanobis
    distance | 50 COTS Tmote Sky sensor (IEEE 802.15.4) | $\geq 99.5\%$ |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| *Danev 等人*[[81](#bib.bib81)] | 基于方差的阈值 | 马哈拉诺比斯距离 | 50 个 COTS Tmote Sky 传感器
    (IEEE 802.15.4) | $\geq 99.5\%$ |'
- en: '|  |  |  |  |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |'
- en: '| *Yuan et al.*[[83](#bib.bib83)] | Phase-based method | SVM | 8 GSM Mobile
    phones | $100\%$ |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| *袁等人*[[83](#bib.bib83)] | 基于相位的方法 | 支持向量机 | 8 GSM 手机 | $100\%$ |'
- en: '|  |  |  |  |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |'
- en: '| *Rehman et al.*[[85](#bib.bib85)] | Variance-based threshold | k-NN | 7 built-in
    Bluetooth transceivers | $99.9\%$ |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| *Rehman 等人*[[85](#bib.bib85)] | 基于方差的阈值 | k-NN | 7 个内置蓝牙收发器 | $99.9\%$ |'
- en: 'TABLE II: Transient based RF fingerprinting works'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：基于瞬态的射频指纹识别工作
- en: IV-D Wavelet-based approach
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 基于小波的方法
- en: IV-D1 Dual-tree complex wavelet transform (DT-CWT)
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D1 双树复小波变换 (DT-CWT)
- en: A wavelet domain (WD) approach based on DT-CWT features extracted from the non-transient
    preamble response of 802.11a signals is proposed by the authors of [[86](#bib.bib86)].
    The effectiveness of WD fingerprinting is demonstrated using Fisher-based MDA/ML
    classification. Also, this work considers the effect of varying channel SNR, burst
    detection error, and dissimilar SNRs for MDA/ML training and classification. WD
    fingerprinting with DT-CWT features achieves classification accuracy of $80\%$
    for signals with SNR up to 8 dB and performs superior to time-domain RF fingerprinting.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 一种基于 DT-CWT 特征的波小波域 (WD) 方法由[[86](#bib.bib86)] 的作者提出，该特征从 802.11a 信号的非瞬态前导响应中提取。WD
    指纹识别的有效性通过 Fisher 基于 MDA/ML 分类进行验证。此外，该工作还考虑了变化的信道 SNR、突发检测误差和 MDA/ML 训练与分类中的不相似
    SNR 的影响。基于 DT-CWT 特征的 WD 指纹识别在 SNR 高达 8 dB 的信号中实现了 $80\%$ 的分类准确率，优于时域射频指纹识别。
- en: 'DT-CWT is an extension of discrete wavelet transform (DWT) which decomposes
    a time-domain signal into wavelets that are localized in frequency and time domain.
    DT-CWT addresses the necessity of shift-invariance that is not present in DWT.
    DT-CWT is implemented using two real-valued filter banks represented as *tree1*
    and *tree2* in Figure [5](#S4.F5 "Figure 5 ‣ IV-D1 Dual-tree complex wavelet transform
    (DT-CWT) ‣ IV-D Wavelet-based approach ‣ IV Traditional Approaches for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges") [[87](#bib.bib87)]. The wavelet and scaling
    functions for *tree1* filter banks - $\psi(t)$ and $\phi(t)$ - are given by,'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: DT-CWT 是离散小波变换 (DWT) 的扩展，它将时域信号分解为在频域和时域中局部化的小波。DT-CWT 解决了 DWT 中缺乏的平移不变性。DT-CWT
    采用两个实值滤波器组实现，在图 [5](#S4.F5 "图 5 ‣ IV-D1 双树复小波变换 (DT-CWT) ‣ IV-D 小波基础方法 ‣ IV 射频指纹识别的传统方法
    ‣ 射频 (RF) 指纹识别的综合调查：传统方法、深度学习和开放挑战") [[87](#bib.bib87)] 中表示为*tree1*和*tree2*。*tree1*滤波器组的波小波和尺度函数
    - $\psi(t)$ 和 $\phi(t)$ - 如下所示，
- en: '|  | $\psi(t)=\sqrt{2}\sum_{n}h_{1}(n)\phi(2t-n),$ |  | (1) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | $\psi(t)=\sqrt{2}\sum_{n}h_{1}(n)\phi(2t-n),$ |  | (1) |'
- en: '|  | $\phi(t)=\sqrt{2}\sum_{n}h_{0}(n)\phi(2t-n)$ |  | (2) |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | $\phi(t)=\sqrt{2}\sum_{n}h_{0}(n)\phi(2t-n)$ |  | (2) |'
- en: 'and the corresponding functions for *tree2* filter banks are Hilbert transforms
    of Equations ([1](#S4.E1 "In IV-D1 Dual-tree complex wavelet transform (DT-CWT)
    ‣ IV-D Wavelet-based approach ‣ IV Traditional Approaches for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges")) and ([2](#S4.E2 "In IV-D1 Dual-tree complex
    wavelet transform (DT-CWT) ‣ IV-D Wavelet-based approach ‣ IV Traditional Approaches
    for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges")) given by,'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 对应的*tree2*滤波器组的函数是方程式 ([1](#S4.E1 "在 IV-D1 双树复小波变换 (DT-CWT) ‣ IV-D 小波基础方法 ‣
    IV 射频指纹识别的传统方法 ‣ 射频 (RF) 指纹识别的综合调查：传统方法、深度学习和开放挑战")) 和 ([2](#S4.E2 "在 IV-D1 双树复小波变换
    (DT-CWT) ‣ IV-D 小波基础方法 ‣ IV 射频指纹识别的传统方法 ‣ 射频 (RF) 指纹识别的综合调查：传统方法、深度学习和开放挑战"))
    的希尔伯特变换给出，
- en: '|  | $\psi^{\prime}(t)=\sqrt{2}\sum_{n}h^{\prime}_{1}(n)\phi^{\prime}(2t-n),$
    |  | (3) |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  | $\psi^{\prime}(t)=\sqrt{2}\sum_{n}h^{\prime}_{1}(n)\phi^{\prime}(2t-n),$
    |  | (3) |'
- en: '|  | $\phi^{\prime}(t)=\sqrt{2}\sum_{n}h^{\prime}_{0}(n)\phi^{\prime}(2t-n).$
    |  | (4) |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | $\phi^{\prime}(t)=\sqrt{2}\sum_{n}h^{\prime}_{0}(n)\phi^{\prime}(2t-n).$
    |  | (4) |'
- en: The filter coefficients $h_{1}(n),h_{0}(n),h^{\prime}_{1}(n)$, and $h^{\prime}_{0}(n)$
    are implemented directly as analysis filters. For a real-valued input, the DT-CWT
    filter bank outputs a real-valued WD component $I_{WD}^{l}$ and an imaginary component
    $Q_{WD}^{l}$. From this, a complex WD signal can be expressed as,
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 滤波器系数 $h_{1}(n),h_{0}(n),h^{\prime}_{1}(n)$ 和 $h^{\prime}_{0}(n)$ 直接作为分析滤波器实现。对于实值输入，DT-CWT滤波器组输出实值WD分量
    $I_{WD}^{l}$ 和虚数分量 $Q_{WD}^{l}$。由此，复数WD信号可以表示为，
- en: '|  | $s_{WD}^{l}(n)=I_{WD}^{l}(n)+jQ_{WD}^{l}(n).$ |  | (5) |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | $s_{WD}^{l}(n)=I_{WD}^{l}(n)+jQ_{WD}^{l}(n).$ |  | (5) |'
- en: To mitigate the excessive need for computation time and data processing when
    using fundamental signal characteristics such as amplitude $\alpha(n)$, phase
    $\phi(n)$, and frequency$f(n)$, as the classification features. The authors propose
    to use the statistical properties of the fundamental signals for the classification
    of devices. These statistics include variance, skewness, and kurtosis.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少使用基础信号特性（如幅度 $\alpha(n)$、相位 $\phi(n)$ 和频率 $f(n)$）作为分类特征时对计算时间和数据处理的过度需求，作者提出使用基础信号的统计特性来进行设备分类。这些统计量包括方差、偏度和峭度。
- en: '![Refer to caption](img/8698ed767ec5b672fd6ffefe633a54c8.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8698ed767ec5b672fd6ffefe633a54c8.png)'
- en: 'Figure 5: Five level dual-tree complex wavelet transform'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：五级双树复数小波变换
- en: 'The authors collect the IQ samples from laptops with 802.11a Cisco personal
    computer memory card international association cards using an Agilent-based RF
    signal intercept and collection system in an anechoic chamber. To simulate the
    various SNR conditions, an "analysis signal" is generated by adding a random complex
    additive white Gaussian Noise (AWGN) signal to the collected complex signal. Before
    adding, the noise signal is filtered and power-scaled to achieve desired SNR for
    the analysis signal. Next, the starting location (sample number) of the RF burst
    is visually determined and is used to locate the preamble region. The analysis
    signals are divided into three subregions for fingerprint generation. A five-level
    DT-CWT is performed for each of these subregions, and the complex WD signal for
    each of the levels is computed for all the subregions using ([5](#S4.E5 "In IV-D1
    Dual-tree complex wavelet transform (DT-CWT) ‣ IV-D Wavelet-based approach ‣ IV
    Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges")), followed by the calculation of signal characteristics and statistical
    classification features resulting in a total of 135 features per analysis signal,
    which is then used for Fisher-based MDA/ML classification with Monte Carlo simulation
    and $K$-fold validation.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 作者使用Agilent-based RF信号拦截和收集系统在消声室中从配备802.11a Cisco个人计算机内存卡国际协会卡的笔记本电脑中收集IQ样本。为了模拟不同的SNR条件，通过将随机复数加性白噪声（AWGN）信号添加到收集到的复数信号中，生成“分析信号”。在添加之前，噪声信号经过滤波和功率缩放，以实现所需的分析信号SNR。接下来，视觉确定RF脉冲的起始位置（样本号），并用以定位前导区域。分析信号被分为三个子区域以生成指纹。对每个子区域进行五级DT-CWT变换，并计算所有子区域每一级的复数WD信号（见
    [5](#S4.E5 "在 IV-D1 双树复数小波变换（DT-CWT） ‣ IV-D 小波方法 ‣ IV RF指纹的传统方法 ‣ 关于射频（RF）指纹的全面调查：传统方法、深度学习及开放挑战")），接着计算信号特性和统计分类特征，最终每个分析信号生成135个特征，这些特征用于基于Fisher的MDA/ML分类、Monte
    Carlo仿真和$K$-折验证。
- en: To compare the proposed WD fingerprints with time-domain (TD) fingerprints,
    the authors generated WD and TD fingerprints for each analysis signal. The TD
    fingerprints are generated similarly to WD fingerprints but without performing
    DT-CWT, which consists of three signal characteristic features and three statistical
    features for each of the three subregions. For each analysis signal, TD fingerprints
    are composed of $27$ features, and WD fingerprints are composed of $135$ features.
    Both techniques performed identically for SNR $\geq 25$ dB and the WD technique
    was superior for $-2<$SNR$<24$ dB. WD fingerprints achieves an accuracy of $80\%$
    at SNR $\approx 11$ dB. This performance increase when using WD fingerprinting
    is a gain of approximately 7 dB with respect to equivalent TD fingerprinting.
    To evaluate whether the classifier takes advantage of the larger number of features
    in WD fingerprints, the authors decided to choose a subset of 27 selected WD features
    from the 135 features. Classification with 27-feature WD fingerprinting shows
    that the WD technique outperforms the 27-feature TD fingerprinting only for $0<$
    SNR $<20$ dB with a performance gain of approximately 2 dB relative to 27-feature
    TD fingerprinting. This increase in performance, given equal dimensionality, suggests
    that the classifier exploits the additional information present in DT-CWT features.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将所提议的 WD 指纹与时域（TD）指纹进行比较，作者为每个分析信号生成了 WD 和 TD 指纹。TD 指纹的生成方法类似于 WD 指纹，但未执行
    DT-CWT，它由三个信号特征和三个统计特征组成。对于每个分析信号，TD 指纹由 $27$ 个特征组成，而 WD 指纹由 $135$ 个特征组成。在 SNR
    $\geq 25$ dB 的情况下，两种技术的性能相同，而 WD 技术在 $-2<$SNR$<24$ dB 范围内表现更优。WD 指纹在 SNR $\approx
    11$ dB 时达到了 $80\%$ 的准确率。使用 WD 指纹时，性能提高约 7 dB，相较于等效的 TD 指纹。为了评估分类器是否利用了 WD 指纹中更多特征的优势，作者决定从
    135 个特征中选择一个包含 27 个选定 WD 特征的子集。使用 27 特征 WD 指纹的分类显示，WD 技术仅在 $0<$ SNR $<20$ dB 范围内优于
    27 特征 TD 指纹，并且相对于 27 特征 TD 指纹，性能提高了大约 2 dB。考虑到相同的维度，这种性能的提高表明分类器利用了 DT-CWT 特征中存在的额外信息。
- en: IV-D2 Dynamic wavelet
  id: totrans-190
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D2 动态小波
- en: 'A dynamic wavelet fingerprint method to identify unique RFID tags using supervised
    pattern classification techniques is presented in [[88](#bib.bib88)]. In this
    study, 146 individual RFID tags of three types: Avery-Dennison AD 612, Avery-Dennison
    Runway Gen 2, and Alien Omni-Squiggle, are used. RF signals from each of the tags
    are captured by writing the same code onto the tag using Thing Magic Mercury 5e
    RFID Reader and reading the response with an omnidirectional antenna through a
    vector signal analyzer. From the captured complex-valued signals, amplitude, phase,
    and instantaneous frequency are computed and used for extracting RF fingerprint
    feature vector. In this work, the authors propose using a feature vector that
    is a combination of features extracted from dynamic wavelet fingerprint (DWFP),
    wavelet packet decomposition (WPD), and higher-order statistics.'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 提出了一种动态小波指纹方法，通过监督模式分类技术来识别独特的 RFID 标签，详见 [[88](#bib.bib88)]。在这项研究中，使用了146个不同的
    RFID 标签，三种类型分别为 Avery-Dennison AD 612、Avery-Dennison Runway Gen 2 和 Alien Omni-Squiggle。通过使用
    Thing Magic Mercury 5e RFID Reader 将相同的代码写入标签，并通过向量信号分析仪用全向天线读取响应来捕获每个标签的 RF 信号。从捕获到的复值信号中计算出幅度、相位和瞬时频率，并用于提取
    RF 指纹特征向量。在这项工作中，作者提出使用一个特征向量，该向量结合了从动态小波指纹（DWFP）、小波包分解（WPD）和高阶统计量中提取的特征。
- en: 'The authors use the DWFP technique [[89](#bib.bib89)] that applies wavelet
    transform on the original TD signal and generates a "fingerprint-like" binary
    image. Image processing routines are performed on the binary image to extract
    signal’s RF fingerprint. Feature selection is performed on the features extracted
    by the image processing steps using Euclidean distance metric to indicate the
    most highly separable interclass distance. Next, fingerprint features are extracted
    by performing WPD [[90](#bib.bib90)], which is done by applying a wavelet packet
    transform (WPT) on the RF signal to generate a tree of coefficients. Wavelet packet
    energy is calculated for the terminal nodes of the WPT tree and the highest energy
    is selected as the feature. Finally, higher-order statistics are performed on
    the unfiltered waveform to extract the following features: mean of EPC, maximum
    cross-correlation with another EPC from the same tag, variance, Shannon entropy,
    second central moment, skewness, and kurtosis. A combination of the features extracted
    with the three methods is used as the feature vector for the classifier. The proposed
    feature vector is tested with four types of classifiers for identifying RFID tags:
    Linear and Quadratic discriminant classifiers (LDC and QDC), k-NN, and SVM. All
    of the four classifiers perform with an accuracy of $99\%$ in identifying the
    RFID tags.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 作者们使用了DWFP技术[[89](#bib.bib89)]，该技术在原始TD信号上应用小波变换，并生成一个“指纹式”的二值图像。对该二值图像进行图像处理操作以提取信号的RF指纹。特征选择在图像处理步骤提取的特征上进行，使用欧几里得距离度量来指示最具可分离性的类间距离。接下来，通过执行WPD[[90](#bib.bib90)]提取指纹特征，这一过程通过对RF信号应用小波包变换（WPT）来生成一个系数树。计算WPT树的终端节点的波小波包能量，并选择最高能量作为特征。最后，对未滤波的波形进行高阶统计量处理，以提取以下特征：EPC的均值、与同一标签的另一个EPC的最大互相关、方差、香农熵、第二中心矩、偏度和峰度。结合这三种方法提取的特征作为分类器的特征向量。提出的特征向量经过四种分类器的测试以识别RFID标签：线性和二次判别分类器（LDC和QDC）、k-NN和SVM。所有四种分类器在识别RFID标签时的准确率为$99\%$。
- en: IV-D3 Wavelet domain-based Bayes approach
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D3 基于小波域的贝叶斯方法
- en: 'In [[91](#bib.bib91)], the authors propose a WD-based Bayes approach to detect
    the presence of micro-UAVs and signal energy transient to identify the type of
    micro-UAV. The proposed detection method first converts the RF signals from the
    UAV controllers into WD using three-stage wavelet decomposition followed by differentiating
    noise (non-UAV signals) and micro-UAV signals using a naive Bayes approach based
    on the Markov model. The transformation of RF signals to the WD removes the bias
    and reduces the size of the data. If micro-UAV is detected using the proposed
    method, the classification of the signal is carried out. For the proposed classification
    method, the TD RF signal is first transformed into the energy-time-frequency domain
    and is represented as a spectrogram. The spectrogram is the squared magnitude
    of the discrete STFT of the signal. Energy transient is estimated by detecting
    the abrupt change in the energy trajectory from the spectrogram. The energy transient
    is then used to extract the statistical RF fingerprints (feature set) such as
    skewness, variance, energy spectral entropy, and kurtosis. The dimensionality
    of the feature set is reduced using Neighborhood Component Analysis (NCA). NCA
    is a supervised learning method for feature selection, transforming the primary
    data into a lower-dimensional space [[92](#bib.bib92)]. The reduced feature sets
    are used to train four machine learning algorithms: k-NN, discriminant analysis
    (DA), SVM, and neural networks (NN).'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[91](#bib.bib91)]中，作者们提出了一种基于WD的贝叶斯方法来检测微型无人机的存在及信号能量瞬变，以识别微型无人机的类型。提出的检测方法首先将无人机控制器的RF信号转换为WD，使用三阶段小波分解，然后通过基于马尔可夫模型的朴素贝叶斯方法区分噪声（非无人机信号）和微型无人机信号。将RF信号转换为WD可以去除偏差并减少数据大小。如果使用提出的方法检测到微型无人机，则进行信号分类。对于提出的分类方法，TD
    RF信号首先转换为能量-时间-频率域，并表示为谱图。谱图是信号离散STFT的平方幅度。通过检测谱图中能量轨迹的突然变化来估计能量瞬变。然后利用能量瞬变提取统计RF指纹（特征集），如偏度、方差、能量谱熵和峰度。使用邻域组件分析（NCA）减少特征集的维度。NCA是一种用于特征选择的监督学习方法，将原始数据转换为较低维度的空间[[92](#bib.bib92)]。减少后的特征集用于训练四种机器学习算法：k-NN、判别分析（DA）、SVM和神经网络（NN）。
- en: RF signals from 14 micro-UAV controllers operating at 2.4 GHz are captured indoors
    using Keysight MSOS604A oscilloscope. An omnidirectional antenna is used to capture
    the RF signal at a close distance and a grid antenna is used for far-field signal
    capture. A total of 100 RF signals is captured from each micro-UAV controller
    to form the dataset, which is split randomly with a ratio of 4:1 for training
    and testing. The authors show that the proposed detection method has an accuracy
    of $84\%$ in detecting the presence of micro-UAV for a given SNR of 10 dB and
    $100\%$ accuracy for SNR$\geq 12$ dB. Once the UAV is detected, the RF signal
    is classified to identify the UAV. The classification accuracy of k-NN, SVM, DA,
    and NN classification methods are $96.3\%$, $96.84\%$, $88.15\%$, and $58.49\%$,
    respectively. Accuracy of classification increases with an increase in SNR. The
    authors clearly state that the hyperparameters of the NN algorithm were not optimized
    in this work, leading to the poor performance of the NN algorithm. If the hyperparameters
    of the NN algorithm are optimized and tuned correctly, the NN algorithm could
    have a high classification accuracy.
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 从14个在2.4 GHz频率下工作的微型无人机控制器中捕获的RF信号使用Keysight MSOS604A示波器在室内捕获。使用全向天线在近距离捕获RF信号，使用网格天线用于远场信号捕获。每个微型无人机控制器捕获100个RF信号以形成数据集，该数据集随机分割，训练和测试的比例为4:1。作者表明，所提出的检测方法在给定的10
    dB SNR下检测微型无人机的准确率为$84\%$，在SNR $\geq 12$ dB下准确率为$100\%$。一旦检测到无人机，RF信号会被分类以识别无人机。k-NN、SVM、DA和NN分类方法的分类准确率分别为$96.3\%$、$96.84\%$、$88.15\%$和$58.49\%$。分类准确率随着SNR的增加而提高。作者明确指出，NN算法的超参数在此工作中未进行优化，这导致了NN算法的性能较差。如果对NN算法的超参数进行优化和调优，NN算法可能会有更高的分类准确率。
- en: 'These discussed wavelet-based approaches are tabulated in Table [III](#S4.T3
    "TABLE III ‣ IV-D3 Wavelet domain-based Bayes approach ‣ IV-D Wavelet-based approach
    ‣ IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey on
    Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and
    Open Challenges").'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '讨论过的基于小波的方法在表[III](#S4.T3 "TABLE III ‣ IV-D3 Wavelet domain-based Bayes approach
    ‣ IV-D Wavelet-based approach ‣ IV Traditional Approaches for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges")中列出了。'
- en: '| Work | Wavelet method | Classification technique | RF emitters | Performance
    |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 小波方法 | 分类技术 | RF发射器 | 性能 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| *Kelin et al*[[86](#bib.bib86)] | dual-tree complex wavelet transform (DT-CWT)
    | Fisher-based MDA/ML | 802.11a Cisco PCMCIA cards | $80\%$ at 11db SNR and $\geq
    98\%$ at SNR $\geq 25$dB |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| *Kelin et al*[[86](#bib.bib86)] | 双树复小波变换（DT-CWT） | 基于Fisher的MDA/ML | 802.11a
    Cisco PCMCIA卡 | 在11dB SNR下$80\%$，在SNR $\geq 25$dB下$\geq 98\%$ |'
- en: '|  |  |  |  |  |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |'
- en: '| *Bertoncini et al.*[[88](#bib.bib88)] | dynamic wavelet fingerprint (DWFP)[[89](#bib.bib89)],
    wavelet packet decomposition (WPD)[[90](#bib.bib90)] | LDC, QDC, k-NN and SVM
    | 50 Avery-Dennison AD 612, 50 Avery-Dennison Runway Gen 2, and 50 Alien Omni-Squiggle
    | $99\%$ |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| *Bertoncini et al.*[[88](#bib.bib88)] | 动态小波指纹（DWFP）[[89](#bib.bib89)]，小波包分解（WPD）[[90](#bib.bib90)]
    | LDC, QDC, k-NN和SVM | 50 Avery-Dennison AD 612，50 Avery-Dennison Runway Gen 2，以及50
    Alien Omni-Squiggle | $99\%$ |'
- en: '|  |  |  |  |  |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |'
- en: '| *Ezuma et al.*[[91](#bib.bib91)] | three-stage wavelet decomposition | k-NN,
    discriminant analysis (DA), SVM,and neural networks (NN) | 14 micro-UAV controllers
    | k-NN$\rightarrow 96.3\%$, SVM$\rightarrow 96.84\%$, DA$\rightarrow 88.15\%$,
    and NN$\rightarrow 58.49\%$ |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| *Ezuma et al.*[[91](#bib.bib91)] | 三阶段小波分解 | k-NN，判别分析（DA），SVM和神经网络（NN） |
    14个微型无人机控制器 | k-NN$\rightarrow 96.3\%$，SVM$\rightarrow 96.84\%$，DA$\rightarrow
    88.15\%$，NN$\rightarrow 58.49\%$ |'
- en: 'TABLE III: Wavelet-based RF fingerprinting methods'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '表 III: 基于小波的RF指纹识别方法'
- en: IV-E Other Approaches
  id: totrans-205
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 其他方法
- en: IV-E1 Steady State Frequency Domain Approach
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-E1 稳态频域方法
- en: The authors of [[93](#bib.bib93)] present a technique for radio transmitter
    identification based on frequency domain characteristics. This approach employs
    frequency domain analysis with a traditional discriminatory classifier - k-NN
    - for RF fingerprinting and device identification. This work demonstrates an accuracy
    of $97\%$ at $30$ dB SNR and $66\%$ accuracy at $0$ dB SNR in identifying eight
    identical USRP transmitters.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '[[93](#bib.bib93)]的作者提出了一种基于频域特征的无线电发射机识别技术。该方法采用频域分析与传统的判别分类器 - k-NN - 进行RF指纹识别和设备识别。该工作在$30$
    dB SNR下的识别准确率为$97\%$，在$0$ dB SNR下的准确率为$66\%$，识别了八台相同的USRP发射机。'
- en: For demonstration, the authors consider the Random Access Channel (RACH) preamble
    in UMTS. The IQ samples of the preamble are captured and down-converted from transmit
    band to baseband. The baseband signal is bandpass sampled by the analog-to-digital
    converter (ADC) at the Nyquist rate and downsampled using a sum of absolute values
    window function followed by carrier frequency offset correction and amplitude
    normalization. Spectral analysis of the entire preamble signal is performed using
    the FFT and is fed as the input for the k-NN classifier. The dataset is divided
    into training and testing sets. In the training step, the k-NN algorithm maps
    the training preamble signals set into a multidimensional feature space, divided
    into regions based on the class. During testing, the preamble is determined to
    belong to the class with the most frequent label among the k-nearest preambles
    from training.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the method UMTS RACH preamble are generated using MATLAB and transmitted
    using USRPs with identical specifications. An Anritsu Signature MS2781A spectrum
    analyzer is used to capture the IQ samples from eight USRPs individually and $300$
    preamble samples are captured from each of the eight USRPs. For training the k-NN
    algorithm, $150$ preamble samples from each USRP is used and the remaining is
    used for testing the system. The system achieves a classification accuracy of
    $97\%$ for preamble signals above $25$ dB SNR and accuracy of $66\%$ for $0$ dB
    SNR. The authors also test the effect of binning on classification accuracy by
    varying the number of bins used to determine the spectral energy features. At
    lower SNR, binning reduces the overall classification performance and the accuracy
    reaches its maximum at around $200$ bins for SNR $15$ dB - $30$ dB.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: IV-E2 Permutation Entropy
  id: totrans-210
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[94](#bib.bib94)], the authors propose a multidimensional permutation entropy-based
    RF fingerprinting method. Permutation entropy is the measure of complexity for
    a given time series. Accordingly, it can extract and amplify the minuscule changes
    in the given time signal. The proposed method involves first capturing the radio
    signals and extracting the envelopes of the signal, then calculating the multidimensional
    permutation entropy of the signal envelope to form the RF fingerprint feature
    vector. An SVM classifier with an radial basis function (RBF) kernel is used to
    classify the feature vector. To evaluate the method, the authors collect 100 sets
    of data from three AKDS700 radios using a digital receiver and an oscilloscope.
    Multidimensional permutation entropy is computed for all the signals captured
    using a multidimensional vector. The SVM trained for these features performs with
    an average accuracy of $90\%$ for SNR$\geq 10$ dB in recognizing the three radios.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '| Work | Radiometric Parameter | Classification technique | RF emitters | Performance
    |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
- en: '| *Kennedy et al.* [[93](#bib.bib93)] | FFT | k-NN | 8 USRPs | 97% identification
    accuracy at SNR>25 dB and 66% at 0 dB SNR |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
- en: '| *Deng et al.* [[94](#bib.bib94)] | multidimensional permutation entropy |
    SVM | 3 AKDS700 radios | 90% identification accuracy at SNR$\geq$10 dB |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
- en: '| *Yuan at al.* [[95](#bib.bib95)] | RSS, SSD, and HLF features | MFMCF | 7
    APs | probability of zero positioning error is 96.5%. |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
- en: '| *Baldini et al.* [[96](#bib.bib96)] | Permutation entropy and Dispersion
    entropy | k-NN, SVM, and decision tree | 9 nRF24LU1+ | k-NN up to 82.3%, SVM up
    to 82.1%, and Decision tree up to 81.4%. |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
- en: 'TABLE IV: Other traditional RF fingerprinting works'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: IV-E3 Received Signal Strength
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A Multi-Fingerprint and Multi-Classifier Fusion (MFMCF) localization method
    for RF fingerprinting is proposed in [[95](#bib.bib95)]. The proposed technique
    aims to increase the localization accuracy of WiFi Access Points (APs) by constructing
    composite fingerprints and combining multiple classifiers. The authors construct
    a composite fingerprint set (CFS) consisting of received signal strength (RSS),
    signal strength difference (SSD), and hyperbolic location fingerprint (HLF) features.
    In this method, a decision structure with three classifiers k-NN, SVM, and random
    forest is used to obtain a more accurate location estimate.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: The authors collect RSS data of seven APs at 35 points in an indoor location,
    each at least 1.2 meters apart. A total of 100 RSS data is recorded for each of
    the APs at each location. Grubbs method [[97](#bib.bib97)] based on the mean and
    standard deviation is used to detect outliers in RSS data. The outliers are replaced
    with a Gaussian random number generated using the mean and variance of the non-abnormal
    data. SSD and HLF fingerprints are constructed based on the collected RSS. SSD
    is the difference in RSS values observed by two APs, and HLF is the ratio of RSS
    between pairs of APs. The three fingerprints, RSS, SSD, and HLF are combined to
    form the CFS. Linear discriminant analysis is used to reduce the dimensions of
    CFS. Using the reduced CFS, the three classifiers (K-NN, SVM, and random forest)
    are trained. In the testing stage, the entropy of each of the classifiers is calculated
    and the classifier with the least entropy is used to estimate the location.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: To evaluate the proposed MFMCF technique, the authors use LDA to select 12 features
    from 49 features in CFS, which covers more than $95\%$ of the information. The
    probability of zero positioning error of MFMCF is $96.5\%$, which is an increase
    of $4.2\%$, $6.4\%$, and $7.7\%$ compared with RSS, SDD, and HLS, respectively,
    when used as independent fingerprint features for classification. To compare MFMCF
    with independent classifiers, CFS was used to train and test individual classifiers.
    The probability of zero positioning errors of MFMCF, RF, k-NN, and SVM were $96.5\%$,
    $90.2\%$, $92.9\%$, and $94.8\%$, respectively. The authors also show that the
    proposed MFMCF technique has the lowest average localization error of $0.14$m.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: IV-E4 Permutation entropy and Dispersion entropy
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors in [[96](#bib.bib96)] propose an RF fingerprinting method for identifying
    IoT devices using entropy-based statistical features called Permutation Entropy
    (PE) and Dispersion Entropy (DE). In this work, nine nRF24LU1+ IoT devices are
    used for evaluating the proposed method. The RF signals from these devices are
    captured using an N210 USRP with XCVR2450 frontend. All nine devices are configured
    to transmit fixed payloads based on MySensors specifications. MySensors [[98](#bib.bib98)]
    is a free and open-source software framework for DIY (do-it-yourself) wireless
    IoT devices that allows devices to communicate using radio transmitters. The real-valued
    IQ samples are captured using the USRP followed by synchronization and normalization
    to obtain the burst of traffic associated with the payload.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: 'The following statistical features are then computed for each received payload:
    variance, skewness, kurtosis, Shannon entropy, log entropy, PE (order=4, and delay=1),
    PE (order=5, and delay=1), DE (embedding dimension=3, classes=5, and delay=1),
    DE (embedding dimension=4, classes=5, and delay=1), and DE (embedding dimension=5,
    classes=5, and delay=1). The authors train three classifiers: k-NN, SVM, and decision
    tree with a subset of the ten features listed above. The authors show that the
    classifier trained using PE and DE features along with statistical features has
    an accuracy of $24\%$ to $30\%$ higher than the classifier trained with just statistical
    features (Shannon entropy and log entropy). Using just the PE feature along with
    statistical features leads to a good improvement in accuracy in contrast to using
    Shannon entropy and log entropy. Finally, the authors show that all three classifiers
    performed with similar classification accuracy when trained with PE and DE features
    along with statistical features.'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'The works discussed in this section are also condensed in a tabular form in
    Table [IV](#S4.T4 "TABLE IV ‣ IV-E2 Permutation Entropy ‣ IV-E Other Approaches
    ‣ IV Traditional Approaches for RF fingerprinting ‣ A Comprehensive Survey on
    Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and
    Open Challenges").'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
- en: V Deep Learning for RF fingerprinting
  id: totrans-227
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning based techniques have been slowly invading this field of research
    and becoming the state of the art. This is primarily due recent revival of machine
    learning fueled from rapid growth of computational capabilities and the availability
    of digital data. Keeping that in mind and for the benefit of reader who might
    be relatively new to deep learning, we provide a brief tutorial regarding the
    core techniques used for RF fingerprinting. For a more comprehensive review we
    recommend the readers to [[99](#bib.bib99)].
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
- en: V-A Overview on Supervised Deep Learning
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: V-A1 Feedforward Neural Networks
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Feedforward neural networks (FNN) also referred to as multilayer perceptrons
    are directed layered neural networks with no internal feedback connections. In
    the mathematical sense, an FNN maps input vector $\mathbf{x}$ to output $y$, i.e.,
    $f:\mathbf{x}\longrightarrow y$. An N-layered FNN is a composite function $y=f(\mathbf{x};\Gamma)=f_{N}(f_{N-1}(\cdots
    f_{1}(\mathbf{x})))$ mapping input vector $\mathbf{x}\in\mathbb{R}^{m}$ to a scalar
    output $y\in\mathbb{R}$. Here, $\Gamma$ represents the neural network parameters
    such as the weights and biases. Depth and width of the neural network are related
    to the number of layers in the neural network and number of neurons in the layers
    respectively. The layers in between the input and output layers for which the
    output does not show are collectively referred to as the *hidden* layers. A 3-layered
    FNN accepting a two-dimensional input vector $\mathbf{x}\in\mathbb{R}^{2}$ approximating
    it to a scalar output $y\in\mathbb{R}$ is illustrated in Figure [6](#S5.F6 "Figure
    6 ‣ V-A1 Feedforward Neural Networks ‣ V-A Overview on Supervised Deep Learning
    ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges").'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a9f06187ef62bbdf58c01a63683bb66e.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Three-layered FNN'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: Here, each node represents a neuron and each link between the nodes $i$ and
    $j$ are assigned a weight $w_{ij}$. The composite function of the 3-layered FNN
    is
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $y=f(\mathbf{x};\Gamma)=f_{3}(f_{2}(f_{1}(\mathbf{x})))$ |  | (6) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
- en: 'In other words, the 3-layer FNN in Figure [6](#S5.F6 "Figure 6 ‣ V-A1 Feedforward
    Neural Networks ‣ V-A Overview on Supervised Deep Learning ‣ V Deep Learning for
    RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges") is the directed acyclic
    graph equivalent of the composite function in equation ([6](#S5.E6 "In V-A1 Feedforward
    Neural Networks ‣ V-A Overview on Supervised Deep Learning ‣ V Deep Learning for
    RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges")). The subscript $n$
    of $f_{n}$ indicates the layer number. The mapping in the first layer is'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{L}_{1}=f_{1}(\mathbf{x})=\gamma_{1}(\mathbf{W}_{1}\mathbf{x}+\mathbf{b}_{1})$
    |  | (7) |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
- en: where $\gamma_{1}(\circ)$ is the activation function, $\mathbf{b}_{1}$ is the
    bias vector, and $\mathbf{W}_{1}$ represents the weight matrix between the neurons
    in the first and second layers. Here, the weight matrix $\mathbf{W}_{1}$ is defined
    as the link weights between the neurons in the input and second layer
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{W}_{1}=\begin{bmatrix}w_{ab}&amp;w_{db}\\ w_{ae}&amp;w_{de}\end{bmatrix}.$
    |  | (8) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
- en: Similarly, the second layer mapping can be represented as
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{L}_{2}=f_{2}(\mathbf{L}_{1})=\gamma_{2}(\mathbf{W}_{2}\mathbf{L}_{1}+\mathbf{b}_{2})$
    |  | (9) |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: Finally, the output is
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $y=f_{3}(\mathbf{L}_{2})=\gamma_{3}(\mathbf{W}_{3}\mathbf{L}_{2}+\mathbf{b}_{3})$
    |  | (10) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
- en: The weight matrices in the second and final layers are
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{W}_{2}=\begin{bmatrix}w_{bc}&amp;w_{ec}\\ w_{bf}&amp;w_{ef}\end{bmatrix}\text{
    and }\mathbf{W}_{3}=\begin{bmatrix}w_{co}&amp;w_{fo}\end{bmatrix}.$ |  |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: The neural network parameters $\Gamma=\{\mathbf{W}_{1},\mathbf{W}_{2},\mathbf{W}_{3},\mathbf{b}_{1},\mathbf{b}_{2},\mathbf{b}_{3}\}$
    comprise the weight matrices and bias vectors across the layers. The objective
    of the training algorithm is to learn the optimal $\Gamma^{*}$ to get the target
    composite function $f^{*}$ from the available samples of $\mathbf{x}$.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: V-A2 Convolutional Neural Networks
  id: totrans-247
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Convolutional networks or convolutional neural networks (CNNs) are a specialized
    type of feedforward neural network known for its spatial mapping capability. A
    CNN performs convolution operation in at least one of its layers. The *feature
    extraction* capability of CNNs mimics the neural activity of the animal visual
    cortex [[100](#bib.bib100)]. The convolution operation in CNNs emulates the scene
    perception characteristic of the brain’s visual cortex whereby they are sensitive
    to sub-regions of the perceived scene. Accordingly, CNNs have been widely used
    for computer vision problems [[101](#bib.bib101), [39](#bib.bib39), [102](#bib.bib102),
    [103](#bib.bib103), [104](#bib.bib104), [105](#bib.bib105), [106](#bib.bib106),
    [107](#bib.bib107), [108](#bib.bib108)]. The convolution is an efficient method
    of feature extraction that reduces the data dimension and consequently reduces
    the parameters of the network. Therefore, in contrast to its fully connected feedforward
    counterpart, CNNs are more efficient and easier to train.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'CNN architecture would often involve convolution, pooling, and output layers.
    The convolution layer convolve the input tensor $\mathbf{X}\in\mathbb{R}^{W\times
    H\times D}$ of width $W$, height $H$, and depth $D$ with the kernel (filter) $\mathbf{F}\in\mathbb{R}^{w\times
    h\times D}$ of width $w$, height $h$, and of the same depth as the input tensor
    to generate an output feature map $\mathbf{M}\in\mathbb{R}^{W_{1}\times H_{1}\times
    D_{1}}$. The dimension of the feature map is a function of the input as well as
    kernel dimensions, the number of kernels $N$, stride $S$, and the amount of zero
    padding $P$. Likewise, the feature map dimensions can be derived as $W_{1}=\left(W-w+2P\right)/S+1,\;H_{1}=\left(H-h+2P\right)/S+1,\;D_{1}=N$.
    In other words, there will be as many feature maps as the number of kernels. Kernel
    refers to the set of weights and biases. The kernel operates on the input slice
    in a sliding window manner based on the stride - the number of steps with which
    to slide the kernel along with the input slice. Hence, each depth slice of the
    input is treated with the same kernel or in other words, shares the same weights
    and biases - *parameter sharing*. A feature map illustration from a convolution
    operation on an input slice $\mathbf{x}$ by a kernel $\mathbf{f}$ is demonstrated
    in Figure [7](#S5.F7 "Figure 7 ‣ V-A2 Convolutional Neural Networks ‣ V-A Overview
    on Supervised Deep Learning ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges"). Here, $b$ represents the bias associated with the kernel
    slice and $\gamma\left(\circ\right)$ denotes a non-linear activation function.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: CNN架构通常涉及卷积、池化和输出层。卷积层将输入张量 $\mathbf{X}\in\mathbb{R}^{W\times H\times D}$（宽度为
    $W$、高度为 $H$、深度为 $D$）与核（滤波器）$\mathbf{F}\in\mathbb{R}^{w\times h\times D}$（宽度为 $w$、高度为
    $h$、与输入张量具有相同深度）进行卷积，以生成输出特征图 $\mathbf{M}\in\mathbb{R}^{W_{1}\times H_{1}\times
    D_{1}}$。特征图的维度是输入和核维度、核的数量 $N$、步幅 $S$ 以及零填充量 $P$ 的函数。同样，特征图的维度可以推导为 $W_{1}=\left(W-w+2P\right)/S+1,\;H_{1}=\left(H-h+2P\right)/S+1,\;D_{1}=N$。换句话说，特征图的数量与核的数量相同。核指的是权重和偏置的集合。核以滑动窗口的方式在输入切片上操作，步幅决定了滑动核沿输入切片的步数。因此，输入的每个深度切片都用相同的核处理，换句话说，共享相同的权重和偏置——*参数共享*。图[7](#S5.F7
    "图 7 ‣ V-A2 卷积神经网络 ‣ V-A 监督深度学习概述 ‣ V 射频指纹识别的深度学习 ‣ 射频（RF）指纹识别的全面调查：传统方法、深度学习和开放挑战")演示了通过核
    $\mathbf{f}$ 对输入切片 $\mathbf{x}$ 进行卷积操作的特征图示意图。这里，$b$ 表示与核切片相关的偏置，$\gamma\left(\circ\right)$
    表示非线性激活函数。
- en: '![Refer to caption](img/1169d3c6d5f61511c7757d2d9023cc3c.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1169d3c6d5f61511c7757d2d9023cc3c.png)'
- en: 'Figure 7: Convolution of input slice with kernel'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: 输入切片与核的卷积'
- en: 'The resulting output from the convolution operation is referred to as the *feature
    map*. Each element of the feature map can be visualized as the output of a neuron
    which focuses on a small region of the input - *receptive field*. The neural depiction
    of the convolution interaction is shown in Figure [8](#S5.F8 "Figure 8 ‣ V-A2
    Convolutional Neural Networks ‣ V-A Overview on Supervised Deep Learning ‣ V Deep
    Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF)
    Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges").'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积操作产生的输出被称为*特征图*。特征图的每个元素可以视为一个神经元的输出，该神经元关注输入的一个小区域——*感受野*。卷积交互的神经表征如图[8](#S5.F8
    "图 8 ‣ V-A2 卷积神经网络 ‣ V-A 监督深度学习概述 ‣ V 射频指纹识别的深度学习 ‣ 射频（RF）指纹识别的全面调查：传统方法、深度学习和开放挑战")所示。
- en: '![Refer to caption](img/f340a6fc188703a10e76ad014e77061b.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f340a6fc188703a10e76ad014e77061b.png)'
- en: 'Figure 8: Neural representation of convolution'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: 卷积的神经表征'
- en: 'It is evident that each neuron in a layer is connected locally to the neurons
    in the adjacent layer - *sparse connectivity*. Hence, each neuron is unaffected
    by variations outside of its receptive field while producing the strongest response
    for spatially local input pattern. The feature maps are propagated to subsequent
    layers until it reaches the output layer for a regression or classification task.
    *Pooling* is a typical operation in CNN to significantly reduce the dimensionality.
    It operates on a subregion of the input to map it to a single summary statistic
    depending on the type of pooling operation - max, mean, $L_{2}$-norm, weighted
    average, etc. In this way, pooling downsamples its input. A typical pooling dimension
    is $2\times 2$. Larger pooling dimensions might risk losing significant information.
    Figure [9](#S5.F9 "Figure 9 ‣ V-A2 Convolutional Neural Networks ‣ V-A Overview
    on Supervised Deep Learning ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges") shows max and mean pooling operations.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3d3a1001eade07306c8adcf47de7e41d.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Max and mean pooling on input slice with stride 1'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: A pooling layer of dimensions $W_{p}\times H_{p}$ upon operating over an input
    volume of size $W_{1}\times H_{1}\times D_{1}$ with a stride of $S_{1}$ will yield
    an output of volume $W_{2}=\left(W_{1}-W_{p}\right)/S_{1},\;H_{2}=\left(H_{1}-H_{p}\right)/S_{1},\;D_{2}=D_{1}$.
    Pooling imparts invariance to translation, i.e., if the input to the pooling layer
    is shifted by a small amount, the pooled output will largely be unaffected [[109](#bib.bib109)].
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: The three essential characteristics of CNNs that contribute to the statistical
    efficiency and trainability are parameter sharing, sparse connectivity, and dimensionality
    reduction. CNNs have demonstrated superior performance in computer vision tasks
    such as image classification, object detection, semantic scene classification,
    etc. Accordingly, CNNs are increasingly used for UAS imagery and navigation applications
    [[110](#bib.bib110)]. Most notable CNN architectures are LeNet-5 [[102](#bib.bib102)],
    AlexNet [[39](#bib.bib39)], VGG-16 [[103](#bib.bib103)], ResNet [[108](#bib.bib108)],
    Inception [[101](#bib.bib101)], and SqueezeNet [[104](#bib.bib104)].
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: V-A3 Recurrent Neural Networks
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recurrent Neural Network (RNN) [[111](#bib.bib111)] is a specialized feedforward
    neural network tailored to capture temporal dependencies from sequential data
    by leveraging internal memory states and recurrent connections. Consequently,
    RNNs are well suited to solve sequential problems by exploiting the temporal correlation
    of data rendering them suitable for image captioning, video processing, speech
    recognition, and natural language processing applications. Moreover, unlike CNN
    and traditional feedforward neural networks, RNNs can handle variable-length input
    sequences with the same model.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: RNNs operate on input sequence vectors at varying time steps $\mathbf{x}^{t}$
    and map it to output sequence vectors $\mathbf{y}^{t}$. The recurrence relation
    in an RNN parameterized by $\mathbf{\Gamma}$ can be expressed as
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathbf{h}^{t}=\mathcal{F}\Big{(}\mathbf{h}^{t-1},\mathbf{x}^{t};\mathbf{\Gamma}\Big{)}$
    |  | (11) |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
- en: 'where $\mathbf{h}^{t}$ represents the hidden state vector at time $t$. The
    recurrence relation represents a recursive dynamic system. By this comparison,
    RNN can be defined as *a recursive dynamic system that is driven by an external
    signal, i.e, input sequence $\mathbf{x}^{t}$*. The equation ([11](#S5.E11 "In
    V-A3 Recurrent Neural Networks ‣ V-A Overview on Supervised Deep Learning ‣ V
    Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges"))
    can be unfolded twice as'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathbf{h}^{t}$ | $\displaystyle=\mathcal{F}\Big{(}\mathbf{h}^{t-1},\mathbf{x}^{t};\mathbf{\Gamma}\Big{)}$
    |  | (12) |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\mathcal{F}\Big{(}\mathcal{F}\Big{(}\mathbf{h}^{t-2},\mathbf{x}^{t-1};\mathbf{\Gamma}\Big{)},\mathbf{x}^{t};\mathbf{\Gamma}\Big{)}$
    |  | (13) |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\mathcal{F}\Big{(}\mathcal{F}\Big{(}\mathcal{F}\Big{(}\mathbf{h}^{t-3},\mathbf{x}^{t-2};\mathbf{\Gamma}\Big{)},\mathbf{x}^{t-1};\mathbf{\Gamma}\Big{)},\mathbf{x}^{t};\mathbf{\Gamma}\Big{)}$
    |  | (14) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: 'The unfolded equations show how RNN processes the whole past sequences $\mathbf{x}^{t},\mathbf{x}^{t-1},$
    $\cdots,\mathbf{x}^{1}$ to produce the current hidden state $\mathbf{h}^{t}$.
    Another notable inference from the unfolded representation is the *parameter sharing*.
    Unlike CNN, where the parameters of a spatial locality are shared, in an RNN,
    the parameters are shared across different positions in time. For this reason,
    RNN can operate on variable-length sequences allowing the model to learn and generalize
    well to inputs of varying forms. On the other hand, traditional feedforward network
    does not share parameters and have a specific parameter per input feature preventing
    it from generalizing to an input form not seen during training. At the same time,
    CNN share parameter across a small spatial location but would not generalize to
    variable-length inputs as well as an RNN. A simple many-to-many RNN architecture
    which maps multiple input sequences to multiple output sequences is shown in Figure
    [10](#S5.F10 "Figure 10 ‣ V-A3 Recurrent Neural Networks ‣ V-A Overview on Supervised
    Deep Learning ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey
    on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges").'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ad2b4a753921bbff95698a4d8b126de6.png)'
  id: totrans-269
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Many-to-many RNN architecture'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: For a simple representation, let us assume the RNN is parameterized by $\mathbf{\Gamma}$
    and $\mathbf{\phi}$ with input-to-hidden, hidden-to-hidden, and hidden-to-output
    weight matrices being $\mathbf{W}_{ih},\mathbf{W}_{hh},$ and $\mathbf{W}_{ho}$
    respectively. The hidden state at time $t$ can be expressed as
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathbf{h}^{t}$ | $\displaystyle=\mathcal{F}\Big{(}\mathbf{h}^{t-1},\mathbf{x}^{t};\mathbf{\Gamma}\Big{)}$
    |  | (15) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\gamma_{h}\Big{(}\mathbf{W}_{hh}\mathbf{h}^{t-1}+\mathbf{W}_{ih}\mathbf{x}^{t}+\mathbf{b}_{h}\Big{)}.$
    |  | (16) |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: where $\gamma_{h}(\circ)$ is the activation function of the hidden unit and
    $\mathbf{b}_{h}$ is the bias vector. The output at time $t$ can be obtained as
    a function of the hidden state at time $t$,
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathbf{y}^{t}$ | $\displaystyle=\mathcal{G}\Big{(}\mathbf{h}^{t};\mathbf{\phi}\Big{)}$
    |  | (17) |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\gamma_{o}\Big{(}\mathbf{W}_{ho}\mathbf{h}^{t}+\mathbf{b}_{o}\Big{)}$
    |  | (18) |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
- en: 'where $\gamma_{o}(\circ)$ is the activation function of the output unit and
    $\mathbf{b}_{o}$ is the bias vector. RNN could take different forms such as many-to-one,
    one-to-many, and one-to-one as illustrated in Figure [11](#S5.F11 "Figure 11 ‣
    V-A3 Recurrent Neural Networks ‣ V-A Overview on Supervised Deep Learning ‣ V
    Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges").'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ecccba29aa76d8360fb738f02df8e94a.png)'
  id: totrans-278
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: RNN architectures. (a) Many-to-one, (b) One-to-many, and (c) One-to-one'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: The RNN architectures discussed here captures only hidden states from the past.
    Some applications would also require future states in addition to past. This can
    be accomplished by a bidirectional RNN [[112](#bib.bib112)]. In simple words,
    bidirectional RNN combines an RNN that depends on past states (*i.e.,* from $\mathbf{h}^{1},\mathbf{h}^{2},\mathbf{h}^{3},\cdots,\mathbf{h}^{t}$)
    with that of an RNN which looks at future states (*i.e.,* from $\mathbf{h}^{t},\mathbf{h}^{t-1},\mathbf{h}^{t-2},\cdots,\mathbf{h}^{1}$).
    In RF applications, RNNs may be used with time series data for spectrum forecasting,
    spectrum usage pattern analysis, anomaly detection, among others.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: V-A4 Generative Adversarial Networks (GANs)
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'GANs is a machine learning framework that consists of two neural networks that
    compete against each other [[113](#bib.bib113)]. The two networks are called the
    Generative network (Generator *G*) and Discriminative network (Discriminator *D*)
    as shown in Figure [12](#S5.F12 "Figure 12 ‣ V-A4 Generative Adversarial Networks
    (GANs) ‣ V-A Overview on Supervised Deep Learning ‣ V Deep Learning for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges"). The generator *G* generates samples from
    the model distribution and learns to deceive the discriminator *D*, while the
    discriminator learns to distinguish between samples from dataset and samples from
    generator. The generative model generates samples by passing random noise through
    an FNN, and the discriminative model is also built using an FNN and outputs a
    scalar $D(x)$ that represents the probability that the samples are from the dataset.
    Generative model *G* is represented by $G(z;\Gamma_{g})$, where $\theta_{g}$ is
    the FNN paremeters and $z$ is the input noise variable with probability distribution
    $p_{z}(z)$. The discriminator model *D* is represented as $D(x;\theta_{d})$ where
    $\theta_{d}$ is the FNN parameters and $x$ is the input data samples. *D* is trained
    to maximize the probability of assigning correct label to the samples from dataset
    and *G* is trained to minimize $\log(1-D(G(z)))$. The value function $V(G,D)$
    of this minimax game of *D* and *G* is given by,'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathop{\mathrm{min}}_{G}\mathop{\mathrm{max}}_{D}V(D,G)=\mathbb{E}_{x\sim
    p_{data}(x)}[\log D(x)]\\ +\mathbb{E}_{z\sim p_{data}(z)}[\log(1-D(G(z)))]$ |  |
    (19) |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
- en: In each training epoch, the discriminator is trained first for a fixed number
    of steps by inserting real and fake data samples, and update the discriminator
    by ascending the stochastic gradients by keeping the generator fixed. Once the
    discriminator is trained for a fixed number of steps, the generator is updated
    by descending its stochastic gradient while keeping its discriminator fixed and
    inserting fake data with fake labels to deceive the discriminator.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f5bc46191e59e4df63fbdc618a26fe3c.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Simple Generative Adversarial Networks (GANs) structure'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: V-B CNN based RF fingerprinting
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: V-B1 ORACLE
  id: totrans-288
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors propose a CNN framework for RF fingerprinting called ORACLE (Optimized
    Radio clAssification through Convolutional neuraL nEtworks) [[114](#bib.bib114)].
    This work provides one of the most extensive evaluations where they demonstrate
    up to $99\%$ classification accuracy on more than 100 consumer-of-the-shelf (COTS)
    WiFi devices. They also demonstrate similar results on 16 bit-similar USRP X310
    SDRs. Other key contributions of this work include the study of hardware-driven
    features occurring in the transmit chain that causes IQ sample variation. They
    study both static and dynamic channel environment. In the case of the dynamic
    channel, they explore how feedback-driven transmitter-side modifications that
    use channel estimation at the receiver can increase the differentiability for
    the CNN classifier. Essentially, introducing perturbations/imperfections on the
    transmitter-side to aid classification while minimizing the impact on bit error
    rates.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: Specifically, in the context of studying the effects of hardware driven RF impairments,
    the authors focus on IQ imbalance and DC offset. They use MATLAB Communications
    System Toolbox to generate IEEE 802.11a standard compliant packets. The transmitter
    in this case was a USRP X310 and the receiver was a USRP B210\. They also use
    an external database which consisted of raw IQ collected from 140 devices which
    included phones, tablets, laptops, and drones belonging to 122 manufacturers.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: For the case of static channel, the authors used the following architecture;
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Input: Raw IQ with length $128$. This was formatted into two-dimensional real
    value tensor of size $2\times 128$'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Network: Two convolutional layers and two fully connected layers each with
    256 and 80 neurons.'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kernels: 1st layer consists of $50$ $1\times 7$ filters, second layer consists
    $50$ $2\times 7$ filters'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Activation Function: Each convolution layer is followed by ReLU activation'
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Output: A softmax is used in the last layer for classification.'
  id: totrans-301
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This architecture provided a median classification accuracy of $99\%$ when up
    to 100 different devices were used and the performance dropped slightly to $96\%$
    for $140$ devices. For the dataset collected using 16 X310 radios, the accuracy
    was close to $98.6\%$.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: The authors clearly highlight the challenge put forth by dynamic channels and
    propose introducing controlled impairments to the transmitter as a solution to
    alleviate it. While this may work in a setting where one can make such impairments
    to the transmit chain, in many commercial and tactical applications this is not
    an option at the physical layer. It can be further argued at that point one is
    not exactly exploiting the "unique" RF fingerprint of the device but rather assigning
    the device an artificial tag/id/fingerprint. This is certainly an interesting
    area of research that may have its application and advantages but will also have
    limitations and disadvantages.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: V-B2 Unmanned Aerial Vehicles With Non-Standard Transmitter Waveforms
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors propose a multi-classifier-based RF fingerprinting for UAVs [[115](#bib.bib115)].
    This work aims to combine outputs of multiple deep neural networks trained on
    a different portion of the training set. The authors create a dataset by collecting
    signals from 7 identical DJI M100 UAVs using an USRP X310 equipped with a UBX
    160 daughterboard in an RF anechoic chamber. The IQ signals are captured by flying
    the UAVs at a distance of 6, 9, 12, and 15 feet from the receiver. They collect
    four bursts of  2 seconds, each burst containing $\sim$140 data sequences (examples)
    for all the UAVs at the four different distances individually. The authors use
    1D modified versions of AlexNet (AlexNet1D) and ResNet50 (ResNet1D) neural network
    architectures for classification. AlexNet1D is a forward CNN with five blocks
    (consisting of two 1D convolutional layers with 128 filters of sizes 7 and 5 respectively,
    followed by a MaxPooling layer) stacked on top of 2 fully connected layers of
    sizes 256 and 128 respectively.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: This work is the first to show the effect of aerial hovering of UAVs on the
    accuracy of DL-based RF fingerprinting. When the network is trained with all 4
    bursts of the UAVs dataset, the network performs well in identifying the UAVs.
    But when the network is trained using the first three bursts and tested on burst
    4, both the network architectures perform with an accuracy of  $50\%$. This drop
    in accuracy shows the effect of continuous channel variation and minute UAV movements
    when hovering. To overcome this effect, the authors propose a multi-classifier
    scheme in which the burst signals from the dataset are partitioned to form non-overlapping
    sets and each of these partitions is used as training sets for identical but independent
    AlexNet1D Neural Networks. The outputs of the neural networks are then combined
    using a two-level score-based aggregation method. They also propose an algorithm
    for determining the number of neural networks to be used in the multi-classifier
    scheme. To evaluate the proposed method, the authors choose to use 12 neural networks.
    The proposed multi-classifier technique improves the classification accuracy from
    $50\%$ when using a single classifier to $91\%$ when the network is trained using
    the first three bursts and tested using the fourth burst.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: The authors also propose a Data Augmentation (DA) scheme for training individual
    neural networks in the multi-classifier technique. DA is the method of expanding
    the training dataset by modifying the original samples in a proper manner [[116](#bib.bib116)],
    [[117](#bib.bib117)]. In this work, DA is performed by normalizing the training
    batch according to the mean and standard deviation of the whole dataset. The normalized
    dataset is then passed through the DA block where it is convolved with a block
    of multi-tap complex FIR filters. The use of DA improved the accuracy of the multi-classifier
    technique by up to $95\%$. This work also proposes a method for detecting new
    UAVs (UAVs not included in the training dataset). Using the proposed multi-classifier
    with a data augmentation scheme, the authors show an accuracy of $99\%$ in detecting
    new UAVs. The authors clearly state that the improvement in the accuracy when
    using the multi-classifier approach comes with no increase in model size compared
    to single ResNet1D architecture but at the cost of a longer testing/training process.
    However, one can claim that the data capture in an anechoic chamber eliminates
    the rich multipath propagation effects as in the real-world settings.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: V-B3 SEI using the bispectrum
  id: totrans-308
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[118](#bib.bib118)], the authors propose a deep learning-based SEI using
    the bispectrum of the received signal as the feature. The bispectrum is estimated
    by calculating the third-order cumulant of the RF signal. Further, the bispectrum
    dimensions are reduced (bispectrum compression) using the projection method in
    [[119](#bib.bib119)]. The reduced bispectrum is then fed into a CNN consisting
    of three convolution layers ($30$ kernels of size $3\times 3$), a fully connected
    layer with $128$ neurons, and a final softmax layer that maps the outputs to their
    respective classes.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: Signals are collected from five USRPs including, one E310, three B210, and one
    N210, and the authors show that the proposed method has an accuracy of $75\%$
    in identifying the five USRPs. They also collect signals from ten emitters modeled
    using a memory polynomial model that consists of multiple delays and nonlinear
    functions [[120](#bib.bib120)]. The proposed model has an accuracy of $85\%$ in
    identifying ten modeled emitters and $87\%$ in identifying five modeled emitters.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: V-B4 Differential Constellation Trace Figure (DCTF)
  id: totrans-311
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors of [[121](#bib.bib121)] propose the use of DCTF to extract RF fingerprint
    features and use a CNN to identify different devices using the DCTF features.
    The DCTF is a 2D representation of the differential relation of the time-series
    signal. DCTF-based feature extraction was first proposed in [[122](#bib.bib122)]
    where they used a minimum distance classifier to achieve an accuracy of $90\%$
    in identifying 16 CC2530 ZigBee modules at SNR$\geq 15$ dB. In this work, the
    authors aim to use CNN as a classifier to improve classification accuracy. The
    DCTF figure is highly influenced by the hardware imperfections that are related
    to the RF fingerprint features. These images are classified using a CNN to identify
    the devices. To evaluate the performance of the DCTF-CNN, the authors capture
    signals from 54 Texas Instruments CC2530 ZigBee modules using a USRP. The DCTF
    is computed for each of the signals and classified using a network consisting
    of three convolutional layers and one fully connected layer. The three convolutional
    layers are of sizes 16, 32, and 64, respectively, with a kernel size of $3\times
    3$. A $2\times 2$ max pooling is applied to each of the outputs of the convolutional
    layers.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: The performance of the DCTF-CNN method is evaluated for different DCTF image
    quality and SNR. DCTF image quality depends on the size of the DCTF size. Lower
    size DCTF images perform poorly because of blurring of features, whereas larger
    size DCTF images have better performance but with the drawback of requiring more
    samples and higher complexity. In this work, the best performance for the designed
    CNN is achieved by using a DCTF image of size 65x65\. Using the fixed DCTF image
    size, the authors further investigate the effect of SNR on performance. The DCTF-CNN
    achieves a classification accuracy of $93.8\%$ at SNR of 15dB and $99.1\%$ at
    SNR 30dB.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: V-B5 RF signal spectrum
  id: totrans-314
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[123](#bib.bib123)], the authors propose the use of a CNN to identify the
    devices from the RF signal spectrum. A dataset consisting of 10,000 signals from
    each of the five transmitters at an SNR of 20 dB generated by Monte Carlo experiments
    with random AWGN and multipath channels is used. The RF signals are processed
    by an STFT to convert the time domain signals to time-frequency domain thereby
    generating the RF signal spectrum. RF signal spectrum reflects the characteristics
    of the signal in the frequency domain and the change of the frequency domain of
    the signal over time. The RF signal spectrum is then fed into the CNN to classify
    the signal.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors use a modified version of the VGG-16 model to classify the signals.
    VGG-16 network model consists of thirteen convolution layers with a kernel of
    $3\times 3$ and two fully connected layers interlaced with five maxpool layers,
    as shown in Figure [13](#S5.F13 "Figure 13 ‣ V-B5 RF signal spectrum ‣ V-B CNN
    based RF fingerprinting ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges"). The output of the final layer is fed to a softmax layer
    to generate transmitter class tags distribution. The VGG-16 is modified by adding
    a Batch Normalization (BN) operation after each convolutional layer and a random
    dropout layer after the first two fully connected layers. BN helps in speeding
    up the model’s convergence during training, and the dropout layer discards random
    neurons leading to a more sparse feature map thereby helping in reducing overfitting.
    The network is trained with 1000 signals from each of the five transmitters using
    an Adam optimizer to minimize the loss. The proposed method achieves an accuracy
    of $99.7\%$ in identifying five devices.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ec3e49f2f7016d1f74d850ac02805b7c.png)'
  id: totrans-317
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: VGG-16 Network'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: V-B6 A Massive Experimental Study
  id: totrans-319
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A large-scale RF fingerprinting study on a DARPA dataset - 400 GB of WiFi and
    Automatic Dependent Surveillance-Broadcast (ADS-B) waveforms from 10,000 devices
    - is presented in [[124](#bib.bib124)]. This is the first large-scale study which
    elaborates the effect of device population, burst type, environmental, and channel
    effects on CNN-based RF fingerprinting architectures. The authors present two
    architectures: 1) A baseline model inspired by AlexNet comprising five stacks
    followed by four fully connected layers. Each stack is composed of two convolution
    layers (128 kernels each with kernel sizes $1\times 7$ and $1\times 5$ respectively)
    and a max pooling layer, 2) A ResNet-50-1D which is a modified ResNet-50 architecture
    such that it can accommodate one-dimensional time series IQ samples. The WiFi
    dataset include emissions from 5117 devices with 166 transmissions on average
    from each device while the ADS-B dataset contains 5000 emitters of 76 average
    emissions. The authors preprocess the WiFi dataset with band filtering and partial
    equalization and adopt a sliding window approach to transform signals in both
    datasets to a fixed form suitable for the CNNs.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors conduct an extensive RF fingerprinting study in parts by forming
    multiple learning tasks for the CNN classifiers. In order to ease the readers
    into these 22 learning tasks, we succinctly list the broad task categories below:'
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  id: totrans-322
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 1 - network performance with scaling device population grouped into four
    categories (A to D).
  id: totrans-323
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  id: totrans-324
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 1M - similar to Task 1 but under multiburst setting where each device may
    emit multiple transmissions for joint classification. Here again there are four
    subtasks (A to D).
  id: totrans-325
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  id: totrans-326
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 2 - effect of training set size on classifier performance. This task has
    three subtasks (A to C).
  id: totrans-327
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  id: totrans-328
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 3 - effect of channel by collecting captures under varying time frames
    and environmental conditions (indoor vs outdoor). This task has four subtasks
    (A to D).
  id: totrans-329
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  id: totrans-330
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 4 - assess the effect of SNR on classification accuracy by four subtasks
    (A to D).
  id: totrans-331
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '6.'
  id: totrans-332
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Task 5 - with 19 bitwise identical emitters.
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The dataset is grouped into different subsets to suit the aforementioned tasks.
    With the above task assessments, the authors reported that both baseline and ResNet-50-1D
    models scale gracefully on Task 1\. The multiburst predictions, i.e., Task 1M
    along with Task 5 demonstrated significantly higher accuracy. Task 2 evaluation
    indicated improvement in model accuracy with the inclusion of more transmissions
    in the training set. Finally, the Tasks 3 and 4 exhibited that the predictions
    were affected by environmental and channel conditions. The authors state that
    the ADS-B emitter classification manifested as a simpler classification problem
    in contrast to WiFi in light of the higher accuracy. Finally, the baseline model
    which is the modified AlexNet demonstrated superior performance in comparison
    to ResNet-50-1D in several of the learning tasks, indicating deeper is not always
    better. These results are also discussed in [[125](#bib.bib125)] where evaluation
    on a custom dataset collected by the authors in a laboratory setting is also presented.
    This custom dataset is a 7 TB dataset comprising emissions from 20 USRP radios.
    We elaborate on this dataset in section [V-F](#S5.SS6 "V-F Open RF Fingerprinting
    Dataset ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges").'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
- en: V-B7 Trust in 5G Open RANs
  id: totrans-335
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Reus-Muns et al. in [[126](#bib.bib126)] propose the use of CNNs augmented
    with triplet loss to detect specific emitters through RF fingerprinting. The authors
    aim to combat the adversarial impact of the wireless channel by using a neural
    network with a triplet-loss function. A dataset consisting of signals from Basestations
    that emit standards-compliant WiFi, LTE, and 5G New Radio (NR) waveforms is used
    to evaluate the proposed network. The dataset is described in detail in Section.[V-F6](#S5.SS6.SSS6
    "V-F6 RF Fingerprinting on the POWDER Platform with 4 emitters ‣ V-F Open RF Fingerprinting
    Dataset ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio
    Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open
    Challenges"). The dataset is used to train two CNN classifiers: baseline CNN and
    Triplet network. The baseline CNN architecture consists of four convolutional
    layers (with 40 filters of size $1\times 7$, $1\times 5$, $2\times 7$, and $2\times
    5$, respectively) followed by three fully connected layers and a final softmax
    classifier layer. The Triplet network architecture is similar to the baseline
    CNN except a triplet loss function is employed. The triplet loss [[127](#bib.bib127)]
    is designed to enforce class separation into embedding space and is trained on
    a series of triples - anchor, positive, and negative. The triplet loss function
    aims to train the neural network to maximize the separation between the anchor
    and the negative labels while minimizing the distance between the anchor and the
    positive classes.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
- en: The proposed baseline and triplet loss CNN are trained and tested with the WiFi
    transmissions from the dataset and the overall classification accuracy is $92.92\%$
    and $99.98\%$, respectively. Next, the authors propose three step algorithm that
    returns a quantitative measure of trust in a Base Station (BS). This approach
    assigns a trust category based on the softmax probability range of the chosen
    class. For softmax range $\leq 80\%$ the device is assigned *No Trust*, for the
    range $[80\%,\;99\%]$ the device is tagged as *Partial Trust*, and for $\geq 99\%$
    the device will fall under *Trusted* category.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: V-B8 Dilated Causal Convolutional Model
  id: totrans-338
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors propose an augmented dilated causal convolution (ADCC) network that
    combines a stack of dilated causal convolution layers with traditional convolutional
    layers to classify wireless devices based on their RF fingerprints [[14](#bib.bib14)].
    In this work, the authors train and evaluate the proposed model on transmissions
    from up to 10,000 devices consisting of WiFi (IEEE 802.11a and 802.11g) and ADS-B
    signals. The authors use the data provided by Radio-Frequency Machine Learning
    Systems (RFMLS) research program [[128](#bib.bib128)]. It consists of 103 million
    transmissions from over 53,000 WiFi devices and 3.5 million ADS-B transmissions
    from over 10,000 devices.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
- en: 'A dilated convolution is a type of convolution where the filter is applied
    over an area larger than its length by skipping input values with a certain step
    as shown in Figure [14](#S5.F14 "Figure 14 ‣ V-B8 Dilated Causal Convolutional
    Model ‣ V-B CNN based RF fingerprinting ‣ V Deep Learning for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges") [[129](#bib.bib129)].'
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d5dd7f33001cf18fde82f749b8015c31.png)'
  id: totrans-341
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: Dilated Causal Convolutional Network'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
- en: The proposed ADCC model consists of two main components, the residual blocks,
    and the traditional convolution, and pooling blocks. The model consisted of eight
    residual blocks in series, each made up of a gated convolution operation that
    is causal and dilated (GDCC) followed by a causal convolution layer with a kernel
    size of one. Before the first residual block, the input is passed through a DCC
    layer with dilation rate of one. Skip connections from each of the eight residual
    blocks are summed and used as the input for the traditional convolution and pooling
    blocks, consisting of three stacks of two convolution layers and a pooling layer
    each. The first 1600 IQ values are processed by the ADCC model to generate 2500
    features. To extract additional features from ID-specific information about the
    device, the authors propose to extract 2500 features from twenty subsequences
    of size 200 IQ values uniformly distributed throughout the rest of the signal.
    Each of the twenty subsequences is processed by two blocks with causal convolution
    and pooling layer, individually. The feature map from each of the twenty processes
    is then input to an average pooling resulting in 2500 features. The 2500 features
    from the ADCC block, and the 2500 features extracted from the twenty subsequences
    are concatenated together and passed as the input to the dense classification
    layer.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors evaluate the proposed method by conducting the learning tasks Task
    1 through Task 4 as in section [V-B6](#S5.SS2.SSS6 "V-B6 A Massive Experimental
    Study ‣ V-B CNN based RF fingerprinting ‣ V Deep Learning for RF fingerprinting
    ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges"). It was noted that for Task 1 the performance
    scaled linearly in the logarithm of the device population. The multiburst accuracy
    was shown to be better than single burst accuracy implying performance gains with
    coherent processing. Similar to the [[124](#bib.bib124)], the accuracy of ADS-B
    device fingerprinting was higher in contrast to WiFi which the authors state could
    be due to the open air propagation of ADS-B. The Task 2 experiments further revealed
    only 2% drop in accuracy when training size is reduced from 501 to 313 suggesting
    the network efficiency with small training size. The authors note drastically
    reduced performance under Task 3 evaluations when the channel differs between
    the training and validation sets implying the sensitivity of fingerprint features
    to the propagation effects. The evaluation in Task 4 exhibited lower accuracy
    when the training SNR was higher than the validation SNR, and higher accuracy
    when validation SNR was higher than the training SNR.'
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
- en: In a more recent work [[130](#bib.bib130)], the authors adopt a multi-burst
    approach towards improving the fingerprinting accuracy for large-scale fingerprinting
    involving greater population sizes. Specifically, the multi-burst processing utilizes
    multiple bursts of the signal from the same but unknown device (i.e., sharing
    same label) to drive the noise level down. The inference is performed on multiple
    bursts and the class probability vectors from the inference on each bursts are
    combined to derive a final class prediction. The authors report a prediction accuracy
    in upwards of 95% across different signal types (WiFi and ADS-B).
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
- en: 'To conclude this discussion on RF fingerprinting using CNNs, we have enlisted
    the reviewed works in a tabular form in Table [V](#S5.T5 "TABLE V ‣ V-B8 Dilated
    Causal Convolutional Model ‣ V-B CNN based RF fingerprinting ‣ V Deep Learning
    for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges") for easy reference.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
- en: '| Work | RFF feature | RF emitters | Performance |'
  id: totrans-347
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  id: totrans-348
  prefs: []
  type: TYPE_TB
- en: '| *Sankhe et al.*[[114](#bib.bib114)] | IQ imbalance & DC offset | 140 devices
    (phones, tablets, laptops, & drones) | $99\%$ up to 100 devices, $96\%$ up to
    140 devices & $98.6\%$ for dataset[[131](#bib.bib131)] |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-350
  prefs: []
  type: TYPE_TB
- en: '| *Soltani et al.*[[115](#bib.bib115)] | Multiple data bursts | 7 DJI M100
    UAVs | up to $99\%$ |'
  id: totrans-351
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-352
  prefs: []
  type: TYPE_TB
- en: '| *Ding et al.*[[118](#bib.bib118)] | Bispectrum | 1 E310, 3 B210s, & 1 N210
    | up to $87\%$ |'
  id: totrans-353
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-354
  prefs: []
  type: TYPE_TB
- en: '| *Peng et al.*[[121](#bib.bib121)] | DCTF | 54 Texas Instruments CC2530 ZigBee
    modules | $93.8\%$ at 15dB SNR and $99.1\%$ at 30dB SNR |'
  id: totrans-355
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-356
  prefs: []
  type: TYPE_TB
- en: '| *Zong et al.*[[123](#bib.bib123)] | RF signal spectrum | 5 simulated transmitters
    | $99.7\%$ |'
  id: totrans-357
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-358
  prefs: []
  type: TYPE_TB
- en: '| *Jian et al.* [[124](#bib.bib124)] | Time-domain RF Signal | 5117 WiFi devices
    and 5000 ADS-B devices | Per-transmission ADS-B accuracy of $91.9\%,\;76.8\%,\;92.5\%$
    with 100 devices for Task 1D, 2C, and 4F, respectively. |'
  id: totrans-359
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-360
  prefs: []
  type: TYPE_TB
- en: '| *Amani Al-Shawabka et al.*[[125](#bib.bib125)] | Time-domain RF Signal |
    20 National Instruments SDR (12 NI N210 and 8 NI X310) | Training and Testing
    on the same day $\geq 87.41\%$ |'
  id: totrans-361
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
- en: '| *Guillem Reus-Muns et al.*[[126](#bib.bib126)] | Time-domain RF Signal |
    4 BSs in the POWDER Platform[[132](#bib.bib132)] | $99.98\%$ for 10 slices using
    majority voting |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
- en: '| *Josh et al.*[[14](#bib.bib14)] | Time-domain RF Signal | 53k WiFi and 10k
    ADS-B devices | Top-five accuracy of $97\%,\;95\%,\;99\%,\;98\%$ with 100 devices
    for Task 1D, 2C, 3E, and 4F, respectively. |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
- en: 'TABLE V: CNN architectures for RF fingerprinting'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
- en: V-C Generative Adversarial Networks
  id: totrans-366
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: V-C1 Classification based on Auxiliary Classifier Wasserstein GANs
  id: totrans-367
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors propose a RF-based UAV classification system based on Auxiliary
    Classifier Wasserstein Generative Adversarial Networks (AC-WGAN) in [[133](#bib.bib133)].
    In this work, the authors collect wireless data from four different types of UAVs
    (including Phantom, Mi, Hubsan, and Xiro) using Agilent (DSO9404A) oscilloscope
    with antenna for indoor environment and USRP N210 with CBX daughterboard for an
    outdoor environment. The authors show the proposed system achieves an accuracy
    of $95\%$ for recognizing UAVs in an indoor environment.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
- en: In this work, the authors improve the discriminative network of the auxiliary
    classifier generative adversarial nets (AC-GAN) proposed in [[134](#bib.bib134)]
    to modify it to classify wireless signals collected from UAVs and also improve
    the AC-GAN model following the Wasserstein GAN (WGAN) [[135](#bib.bib135)] model
    to make the proposed model more stable during training. RMSProp is chosen as the
    loss function instead of Adam due to its better performance in nonstationary problems
    [[136](#bib.bib136)]. During training, samples (training samples) are fed to the
    generator and the discriminator networks to update the negative critic loss by
    ascending its stochastic gradient. Then, the testing samples are classified by
    the discriminator according to the value of negative critic loss.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
- en: The authors capture the wireless signals from the UAVs and apply a bandpass
    filter to get the wireless signal in the 2.4-2.5 GHz band, after which the start
    point of the signal is detected, and the amplitude envelope is extracted. To reduce
    the dimensionality of the UAV’s wireless signals, the authors propose to use a
    modified PCA. Using the signals captured indoors from the 4 UAVs and WiFi signal,
    the authors test the proposed model and show that the accuracy of classification
    of different UAVs is greater than $95\%$ at SNR of 5 dB. They also show that the
    proposed classification using AC-WGANs with PCA performs better than the standard
    SVM and AC-GAN models and are also suited for real-time classification over long
    distances in the range 10 m to 400 m.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
- en: V-C2 GANs with Adversarial learning
  id: totrans-371
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[137](#bib.bib137)], an adversarial learning technique for identifying RF
    transmitters is implemented using generative adversarial nets (GANs). The authors
    also implement a CNN and DNN based classifier that exploits the IQ imbalance present
    in the received signal to learn the unique fingerprint features for classifying
    the devices. The dataset used in this work consists of QPSK modulation signals
    from eight USRP B210s received using an RTL-SDR and are considered as signals
    from trusted transmitters. With the help of an adversary, the generator model
    generates random signals with noise and is passed to the discriminative model
    as input. The discriminative models of the GANs take input from both the generator
    model and trusted transmitters and improve the random signal to imitate the real
    data by giving feedback to the generator model for tuning the hyperparameters.
    The generator model network consists of two fully connected layers with 512 and
    1024 nodes, and the discriminative model network is made of three fully connected
    layers with 1024, 512, and 2 nodes with dropout layers between the first two fully
    connected layers. The GANs is modeled to identify if the signal is from a trusted
    transmitter. The proposed GANs model identifies the 8 trusted transmitters with
    an accuracy of $99.9\%$.
  id: totrans-372
  prefs: []
  type: TYPE_NORMAL
- en: 'To classify the signals to identify the transmitters, the authors design and
    implement a CNN and a DNN. The CNN as shown in Figure [15(a)](#S5.F15.sf1 "In
    Figure 15 ‣ V-C2 GANs with Adversarial learning ‣ V-C Generative Adversarial Networks
    ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges")
    has three Conv2D layers of size 1024, 512, and 256 filters with a kernel of size
    $2\times 3$, followed by three fully connected layers of 512, 256, and 8 nodes.
    A MaxPooling2D layer of size $2\times 2$ is applied after each of the three convolution
    layers and a dropout layer is applied after each of the convolution and fully
    connected layers. The DNN as shown in Figure [15(b)](#S5.F15.sf2 "In Figure 15
    ‣ V-C2 GANs with Adversarial learning ‣ V-C Generative Adversarial Networks ‣
    V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges")
    has three fully connected layers with 1024, 512, and 8 nodes with dropout layers
    between the first two fully connected layers. The proposed CNN and DNN have a
    classification accuracy of $89.07\%$ and $97.21\%$, respectively, for classifying
    four devices and $81.59\%$ and $96.6\%$, respectively, for eight USRP devices.
    The classification accuracy of DNN is improved to $99.9\%$ by using the proposed
    GANs model to distinguish trusted transmitters from fake ones before classifying
    them.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1a8f81cf2c3477f1a63fed21d4c6b1cc.png)'
  id: totrans-374
  prefs: []
  type: TYPE_IMG
- en: (a) CNN
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/27e8aeb33bdce1ee25c1423879ce0a6c.png)'
  id: totrans-376
  prefs: []
  type: TYPE_IMG
- en: (b) DNN
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 15: Proposed CNN and DNN networks to classify signals'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
- en: V-D Probabilistic Neural Network
  id: totrans-379
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: V-D1 Energy spectrum based approach
  id: totrans-380
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors in [[138](#bib.bib138)] propose a transient-based RF fingerprinting
    approach for extracting the unique characteristics of the wireless device from
    part of the energy spectrum of the transient signal. The work aims at reducing
    the computational complexity of feature extraction compared to techniques based
    on spectral fingerprinting. The proposed method is evaluated using data collected
    from eight IEEE 802.11b WiFi transceivers.
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: In this work, the instantaneous amplitudes of the captured signals are used
    to detect the transient. The starting point of the transient is estimated by using
    a Bayesian ramp change detector[[139](#bib.bib139)], and the endpoint is estimated
    by using a sliding window to calculate the average instantaneous amplitude of
    the samples. The first peak before the next steady state signal starts is chosen
    as the end point. Then the energy spectrum is obtained using discrete Fourier
    transform (DFT). By examining the frequency domain energy spectrum of these transients,
    the authors deduce that most of the information is concentrated in low-frequency
    components of the spectrum. Hinging on these observations, the authors propose
    that the number of energy spectral coefficients $(K)$ that carry the characteristic
    information can be calculated as,
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $K=\left[\frac{W}{\Delta f}\right]$ |  | (20) |'
  id: totrans-383
  prefs: []
  type: TYPE_TB
- en: where $[\cdot]$ denotes integer part of $K$, $W$ is the transmission bandwidth,
    and $\Delta f$ is frequency resolution of the DFT given by
  id: totrans-384
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\Delta f=\frac{1}{T_{d}}=\frac{1}{NT_{s}}=\frac{f_{s}}{N}$ |  | (21)
    |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
- en: where $N$ is the transient duration (in samples), $T_{d}$ is average transient
    duration in seconds, $T_{s}$ is sampling period, and $f_{s}$ is sampling frequency.
    Lastly, the classification is carried out by using a probabilistic neural network
    (PNN) classifier. A PNN is a feedforward neural network that estimates the probability
    density function (PDF) of each class using the Parzen window [[140](#bib.bib140)].
    Then, using the PDF of each class for the given input, the class with the highest
    posterior probability is estimated using Bayes’ rule.
  id: totrans-386
  prefs: []
  type: TYPE_NORMAL
- en: 'The classification performance of the proposed technique was carried out using
    a dataset collected from eight different IEEE 802.11b WiFi devices with 100 transmissions
    from each device. An average transient duration was calculated for the data in
    the training set for a sampling rate of $5$ GSps to determine the spectral feature
    length using equations ([20](#S5.E20 "In V-D1 Energy spectrum based approach ‣
    V-D Probabilistic Neural Network ‣ V Deep Learning for RF fingerprinting ‣ A Comprehensive
    Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches, Deep Learning,
    and Open Challenges")) and ([21](#S5.E21 "In V-D1 Energy spectrum based approach
    ‣ V-D Probabilistic Neural Network ‣ V Deep Learning for RF fingerprinting ‣ A
    Comprehensive Survey on Radio Frequency (RF) Fingerprinting: Traditional Approaches,
    Deep Learning, and Open Challenges")). The proposed method has a classification
    accuracy of $90\%$ and $97.91\%$ at $0$ dB and $25$ dB, respectively.'
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: V-D2 Effect of Sampling Rate on Transient-based fingerprinting
  id: totrans-388
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors in [[141](#bib.bib141)] investigate the effect of sampling rate
    on the classification performance of a transient-based RF fingerprinting method.
    A Bayesian ramp detector is employed to detect turn-on transient and amplitude
    features (instantaneous amplitude responses), and its dimensionality reduced PCA
    features are extracted and used as the input features to train a PNN classifier
    to identify devices. The authors collect data from eight different IEEE 802.11b
    WiFi transmitters at a sampling rate of 5 GSps. A total of 100 transmissions are
    captured from each of the eight transmitters. To study the effect of sampling
    rate, authors use the decimation process to downsample the 5 GSps to 2.5 GSps,
    1 GSps, 500 MSps, 200 MSps, 100 MSps, 50 MSps, and 28 MSps.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: The classification accuracy is evaluated by conducting two experiments. In the
    first experiment, downsampling was performed after detection of the transient
    at a higher sampling rate. In the second experiment, transient detection was performed
    after downsampling the original signal. The average classification accuracy of
    both amplitude and PCA features at all the sampling rates was $97.7\%$ and $97.5\%$
    for the first and second experiment, respectively, indicating that sampling rates
    have very little to no impact for transient based RF fingerprinting of WiFi transmitters.
  id: totrans-390
  prefs: []
  type: TYPE_NORMAL
- en: V-E Attentional Learning
  id: totrans-391
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Attention mechanism was first introduced for RF fingerprinting in [[142](#bib.bib142)].
    The authors adopt a cross-domain attentional architecture that extracts spatio-temporal,
    temporal, and time-frequency features from $1024\times 1$ raw IQ input samples.
    A 1D/2D CNN architecture in conjunction with gated recurrent units (GRUs) and
    STFT processing were adopted to extract the multiple domain features from the
    raw IQ samples. Further, the capability of the model to perform multiple tasks
    (emitter and protocol recognition) were demonstrated with the MTL version of the
    proposed architecture. The authors perform real-world experimental evaluation
    under single day train-test (TTSD) and mixed days train-test (TTMD) scenarios.
    Here, the authors consider real-world IoT devices such as Raspberry Pis and Lenovo
    laptops with combo chipsets (emitting Bluetooth and WiFi waveforms from a single
    chipset) and achieve a fingerprinting accuracy of 84.3% and 63.8% under the TTSD
    and TTMD scenarios respectively (while performing 100% protocol recognition) in
    identifying emissions from 10 COTS chipsets.
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
- en: A recent work in attentional learning for Bluetooth fingerprinting was reported
    in [[143](#bib.bib143)]. Here, the authors tuned into 2 MHz of the challenging
    frequency hopping Bluetooth spectrum for identifying 10 COTS Bluetooth emitters.
    A scalable, hybrid CNN-GRU architecture with ability to support input tensor length
    of up to 1 MS is proposed. The authors demonstrate the computational efficiency
    of the proposed architecture in contrast to the benchmark model and report a $16.9\times$
    fewer floating point operations (FLOPs) and $7.5\times$ lesser trainable parameters.
    The significance of processing greater sample lengths in identifying the challenging
    frequency hopping Bluetooth waveform was elaborately studied with reported accuracy
    of up to 91% in identifying 10 COTS emitters.
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: V-F Open RF Fingerprinting Dataset
  id: totrans-394
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A soaring issue in the applied AI/ML for RF realm, unlike other prominent fields
    such as computer vision and natural language processing, is the lack of availability
    and uniformity of diverse and large-scale datasets which can be integrated as
    well as easily ported to AI/ML frameworks such as Keras [[144](#bib.bib144)],
    PyTorch [[145](#bib.bib145)], TensorFlow [[146](#bib.bib146)], etc. A few datasets
    have been released recently to aid deep learning for wireless communications [[36](#bib.bib36),
    [147](#bib.bib147), [148](#bib.bib148), [149](#bib.bib149)] for modulation and
    protocol classification, however, due to the lack of momentum and a common standard
    to organize the datasets in contrast to computer vision and NLP in AI/ML, these
    are not integrated yet with such frameworks. Another factor contributing to the
    dataset inaccessibility is the obliviousness of practitioners in this field of
    the available datasets, although limited. Accordingly, here we present a summarized
    excerpt on each of the openly available RF fingerprinting dataset to educate the
    reader.
  id: totrans-395
  prefs: []
  type: TYPE_NORMAL
- en: V-F1 Large-scale Bluetooth dataset from 86 smartphones
  id: totrans-396
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[150](#bib.bib150)], the authors present an elaborate database comprising
    Bluetooth RF recordings from COTs smartphones of different makes and models captured
    at different sampling rates. The dataset contains recordings captured over the
    period of several months since the unique fingerprint from hardware impairments
    do not vary significantly over short time spans - days, weeks, or months. The
    smartphones were kept at a fixed distance of 30cm from the receiving antenna connected
    to a high sampling rate oscilloscope (Tektronix TDS7404) along with a low resolution
    8-bit ADC. Since the Bluetooth operate at the ISM2400 band, a COTS antenna operating
    in this frequency range was utilized. The edge detection mode of the oscilloscope
    was leveraged to record the samples of duration 10$\mu$s into a text format (.txt).
    The recorded samples are real-valued time series (voltage/times). The entire database
    is split into sub-datasets comprising Bluetooth signals sampled at 5 GSps, 10
    GSps, 20 GSps, and 250 MSps. Corresponding to each dataset,150 Bluetooth signals
    from each device was recorded yielding a total of 12,900 captures from 86 smartphones.
    The authors also note that the spur signals introduced by the oscilloscope were
    removed by band pass filtering. Moreover, the filtered samples are normalized
    such that the samples are in the range of -1 to +1.
  id: totrans-397
  prefs: []
  type: TYPE_NORMAL
- en: V-F2 Dataset containing RF signals from 17 drone remote controllers
  id: totrans-398
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The authors of [[151](#bib.bib151)] released a RF signal dataset to enable researchers
    to develop UAV identification techniques based on the signal captured from the
    remote controllers. The communication between UAV and the remote controller can
    enable AI/ML frameworks to effectively fingerprint UAVs. The captures were recorded
    by placing the drones in an idle state such that only the remote controller data
    is captured. The receiver frontend comprised a 6 GHz bandwidth Keysight MSOS604A
    oscilloscope, 2.4 GHz 24 dBi grid parabolic antenna, and a low-noise amplifier
    operating from 2 GHz to 2.6 GHz. The distance between the drone remote controller
    and the receiving antenna was varied from 1m to 5m. The RF signal is recorded
    as digitized voltage vs time samples at a sampling rate of 20 GSps with 5 Million
    samples per signal. The waveforms comprise emissions from 17 drone remote controllers
    from eight different manufacturers. The database is containerized in a MATLAB
    (.mat) format.
  id: totrans-399
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VI: Summary table of open RF fingerprinting datasets'
  id: totrans-400
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Waveform | Emitter count | Emitter type | Receiver | Dataset format
    | Generated / Real-world | Frequency |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
- en: '| [[150](#bib.bib150)] | Bluetooth | 86 | Smartphones | Tektronix TDS7404 |
    .txt | Real-world | 2.4 GHz |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
- en: '| [[151](#bib.bib151)] | Non-standard | 17 | Drone remote controllers | Keysight
     MSOS604A | .mat | Real-world | 2.4 GHz |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
- en: '| [[152](#bib.bib152)] | ADS-B | 100 | Commercial aircraft | BladeRF | .mat
    | Real-world | 1090 MHz |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
- en: '| [[153](#bib.bib153)] | ADS-B | $>140$ | Commercial aircraft | USRP B210 |
    .mat | Real-world | 1090 MHz |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
- en: '| [[131](#bib.bib131)] | IEEE 802.11a | 16 | USRP X310 | USRP B210 | SigMF
    | Generated | 2.45 GHz |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
- en: '| [[154](#bib.bib154)] | Non-standard | 7 | DJI M100 | USRP X310 | SigMF |
    Generated | 2.4065 GHz |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
- en: '| [[155](#bib.bib155)] | IEEE 802.11a, LTE, 5G-NR | 4 | USRP X310 | USRP B210
    | SigMF | Generated | 2.685 GHz |'
  id: totrans-409
  prefs: []
  type: TYPE_TB
- en: '| [[156](#bib.bib156)] | IEEE 802.11a/g | 20 | USRP X310 USRP N210 | USRP N210
    | SigMF | Generated | 2.432 GHz |'
  id: totrans-410
  prefs: []
  type: TYPE_TB
- en: V-F3 Real world ADS-B signals dataset from over 140 commercial aircrafts
  id: totrans-411
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A real world dataset containing ADS-B signal emissions from more than 140 commercial
    aircrafts to air traffic control (ATC) centers is provided by the authors of [[153](#bib.bib153),
    [157](#bib.bib157)]. Commercial aircrafts broadcast their geographical coordinates
    along with their unique International Civil Aviation Organization (ICAO) identifiers
    to the ATC centers using ADS-B standard. The ADS-B signals are captured with a
    USRP B210 receiver tuned to 1090 MHz and at a 8 MSps sampling rate over a period
    of 24 hours at the Daytona Beach international airport. The authors decoded the
    ADS-B messages to extract the aircraft identity codes and utilized the messages
    from over 140 most frequently seen aircrafts to form the dataset. The authors
    have another dataset of ADS-B waveforms from 100 aircrafts at [[152](#bib.bib152)]
    received with a BladeRF SDR. Both datasets are containerized into MATLAB (.mat)
    format.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: V-F4 ORACLE RF Fingerprinting Dataset of IEEE802.11a from 16 emitters
  id: totrans-413
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The authors of [[131](#bib.bib131)] present a WiFi IEEE 802.11a emitter dataset
    to detect unique radios using ORACLE RF fingerprinting approach. The dataset contains
    two sets: Dataset#1 and Dataset#2\. Dataset#1 consists of IEEE 802.11a standard
    Wireless Local Area Network (WLAN) frame IQ samples from 16 USRP X310 SDRs collected
    using a USRP B210 Radio sampling at a rate of 5 MSps at a center frequency of
    2.45 GHz. For each of the 16 transmitters, the IQ samples are captured at a varying
    transmitter-receiver distance from 2 ft - 62 ft in steps of 6 ft. Dataset#2 consists
    of demodulated IQ symbols with intentional impairment introduction such that the
    synthetic hardware impairments dominate the channel effects. Accordingly, the
    authors use the GNU Radio function *set_iq_balance* to introduce intentional IQ
    imbalance (16 IQ imbalance configurations corresponding to 16 emitters) to the
    transmit chain of the RF daughterboard. The recording are the demodulated IQ symbols
    after equalizing over-the-cable transmissions from USRP X310s collected using
    USRP B210 Radio. Both the datasets are formatted according to SigMF specifications
    wherein each data file in binary format is accompanied by a JSON metadata file.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: V-F5 Non-standard Waveforms from 7 Hovering Unmanned Aerial Vehicles (UAVs)
  id: totrans-415
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[154](#bib.bib154)], the authors create a dataset for RF fingerprinting
    of hovering UAVs. The dataset consists of signals collected from 7 identical DJI
    M100 UAVs in an RF anechoic chamber. Signals are captured using an USRP X310 with
    UBX 160 USRP daughterboard. The receiver is tuned to the 10 MHz of downlink channel
    centered at 2.4065 GHz. The signals are captured by flying the UAVs individually
    at distances of 6, 9, 12, and 15 ft from the receiver. Each capture consists of
    4 cycles of recording IQ samples for $\sim 2$ seconds and pausing for $\sim 10$
    seconds, resulting in 4 non-overlapping bursts with $\sim 140$ interleaved short
    periods of data and noise in each burst. Accordingly, with a total of 7 UAVs where
    each are flew at 4 distances with 4 bursts (each of $\sim$ 140 examples) at each
    distance, the dataset provides over 13k examples of $\sim$ 92k IQ samples per
    example. The dataset is in SigMF format with data of each capture stored in binary
    format accompanied by a JSON file with the metadata of the capture.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: V-F6 RF Fingerprinting on the POWDER Platform with 4 emitters
  id: totrans-417
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The authors of [[155](#bib.bib155)] provide a dataset from 4 different emitters
    transmitting waveforms belonging to 3 wireless standards to demonstrate and evaluate
    feasibility of RF fingerprinting of base stations with a large-scale over-the-air
    experimental POWDER platform [[132](#bib.bib132)]. Using a fixed endpoint (Humanties)
    USRP B210 receiver, IQ samples are collected from four emitters in the POWDER
    Platform: MEB, Browning, Beavioral, and Honors. The emitters are bit-similar USRP
    X310 radios which transmit standard compliant IEEE 802.11a, Long Term Evolution
    (LTE), or 5G New Radio (5G-NR) frames generated using WLAN, LTE, and 5G toolboxes
    from MATLAB, respectively. The USRP B210 receiver is tuned to record 2.685 GHz
    (Band 7) at a sampling rate of 5 MSps for WiFi and 7.69 MSps for LTE and 5G. On
    two independent days, five sets of 2 s of IQ samples are recorded from each of
    the links. Consequently, the dataset is organized into a Day-1 and Day-2 sets.
    The dataset follows the SigMF specifications.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
- en: V-F7 Exposing the Fingerprint Dataset
  id: totrans-419
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Al-Shawabka et al. create and share a dataset[[156](#bib.bib156)] for experimenting
    and evaluating radio fingerprinting algorithms. WiFi standard IEEE 802.11a/g signals
    are collected from 20 National Instruments SDR (12 NI N210 and 8 NI X310) running
    GNU Radio. Four datasets are created with three different channel conditions and
    two different environments. Dataset "Setup 1" consists of signals captured from
    20 transmitting SDRs with each transmitter using a dedicated Ettus VERT2450 antenna
    and varying distance from the receiver. The dataset collection process is repeated
    on ten days. Dataset "Setup 2" is captured similarly to "Setup 1", but all the
    SDR use a common Ettus VERT2450 antenna making all 20 devices equidistant from
    the receiver. This leads to all transmissions experiencing similar channel and
    multi-path conditions. The dataset collection process is repeated on two different
    days. Dataset "Setup 3" is collected by capturing the WiFi signals from 20 transmitters
    using a single coaxial RF SMA cable and a 5 dB attenuator. Thereby, all signals
    experience the same channel conditions and eliminate any multipath conditions.
    The dataset collection process is repeated on two different days. Datasets "Setup
    1", "Setup 2", and "Setup 3" are collected in an arena "in the wild" environment.
    Dataset "Setup 4" is collected similar to "Setup 2" but in an anechoic chamber
    with each transmitter connected to the same antenna. All the "Setup 4" IQ samples
    are collected on one day. The following three IQ samples are collected: Raw IQ
    before FFT, Raw IQ after FFT, and Equalized IQ for all the datasets. Each of the
    IQ sample files is labeled using SigMF and is accompanied by a JSON file containing
    the metadata of each of the transmission settings.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
- en: 'A tabular summary of the openly available RF fingerprinting datasets is presented
    in Table [VI](#S5.T6 "TABLE VI ‣ V-F2 Dataset containing RF signals from 17 drone
    remote controllers ‣ V-F Open RF Fingerprinting Dataset ‣ V Deep Learning for
    RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges") to allow the reader
    to contrast the distinguishing features. Although the datasets [[131](#bib.bib131),
    [155](#bib.bib155), [154](#bib.bib154), [156](#bib.bib156)] are synthetically
    generated, they follow the SigMF specifications allowing easy integration into
    AI/ML frameworks in contrast to the other discussed real-world datasets which
    would require specific import scripts requiring MATLAB or csv readers.'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: VI Research Challenges and Future Direction
  id: totrans-422
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In so far, we have seen the various wireless device fingerprinting approaches
    and how it plays a role in wireless security. For completeness of the presented
    subject, in this section, we motivate future research in this direction by identifying
    a few key open research problems and opportunities towards developing a robust
    radio frequency fingerprinting system (RFFS). These challenges are also illustrated
    in an IoT network setting in Figure [16](#S6.F16 "Figure 16 ‣ VI Research Challenges
    and Future Direction ‣ A Comprehensive Survey on Radio Frequency (RF) Fingerprinting:
    Traditional Approaches, Deep Learning, and Open Challenges") to ease the reader
    into the potential research avenues.'
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: '*Impact of receiver hardware:* Similar to how the transmitter hardware introduce
    unique distortions, the receiver hardware that captures and processes these emissions
    for fingerprinting can impact the fingerprinting approach. Specifically, the phase
    noise, clock offsets, filter distortions, IQ imbalance, etc., introduced by the
    receiver hardware could etch its own unique fingerprint to transform the transmitter
    fingerprint to appear as from a rogue or unidentified emitter. The ADC sampling
    rate as well as bandwidth of low pass filter (LPF) play an equally important role
    in retaining the fingerprint features that reside in the side lobes of the power
    spectrum density (PSD). Higher sampling rates were shown to retain the fingerprint
    features at a cost of increased noise using actual MicaZ sensors [[158](#bib.bib158)].
    Moreover, the effect of antenna polarization and orientation at the transmitter
    and receiver end can cause fluctuations in radiation pattern affecting the fingerprint
    extraction performance. The imperfection of emitter antenna hardware can also
    contribute to the fingerprint feature set enabling wireless emitter identification
    [[69](#bib.bib69)]. We argue here that the number of receiver antennas, type,
    their orientation, and polarization can impact the classification performance
    of the fingerprinting system.'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: One way to tackle this in a supervised learning setting would be to incorporate
    captures from multiple receiver hardwares corresponding to an emitter in the dataset.
    Such a larger distribution of training data would allow the model to generalize
    and differentiate the emitter fingerprint from the recorded waveforms. The independence
    of fingerprinting algorithm can be assessed by training on samples captured by
    a particular receiver hardware and evaluating the learned emitter features by
    testing on samples from another receiver hardware.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: '*Vulnerabilities of RFFS*: The broadcast nature of wireless emitters renders
    them exposed and susceptible to identity spoofing. Few such attacks are DoS, impersonation,
    bandwidth theft, etc. It is often overlooked that passive receiver threats can
    build up their own dataset of emissions from specific transmitters to build cognitive
    RFFS. Developing or perturbing the emitter fingerprint such that it cannot be
    extracted by passive listeners while allowing only legit receivers to extract
    or identify the signature is another interesting research problem to enhance wireless
    security. Generally, it is assumed that RF fingerprinting is robust to impersonation
    attacks due to the difficulty in reproducing the frontend impairments with replay
    attacks since that will introduce the hardware defects of the replaying device.
    This area is pristine and the research here is limited currently. In literature,
    it was shown that transient-based RF fingerprinting is more resilient to impersonation
    attacks in contrast to modulation-based RF fingerprinting [[159](#bib.bib159)].
    Another work in [[160](#bib.bib160)] analyzed the effect of several low-end receivers
    (manufactured with inexpensive analog components) on the resilience of modulation-based
    RF fingerprinting to impersonation attacks. Their evaluation revealed that the
    RF fingerprint from a specific transmitter varies across the receivers. The receiver’s
    hardware imperfections as we have discussed above contributes to the fingerprint
    feature set. Further, they exploit this fact to thwart the impersonation attacks
    and state that the impersonator would not be able to extract the fingerprint features
    contributed by the receiver hardware, rendering an even robust RFFS. Another threat
    that can disrupt the RFFS are jamming DoS attacks whereby the intruder can continuously
    transmit in the operating frequency. This area will require more analysis to evaluate
    the resiliency of RFFS to such DoS attacks.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: On the flip side, jamming can also be used as a defense strategy to mask the
    RF fingerprint of transmitters for covert and confidential operations. RF fingerprint
    obfuscation - such that the fingerprint can only be extracted by the legitimate
    receiver while remaining undetectable to others - was experimentally studied on
    WiFi signals in [[161](#bib.bib161)]. The authors achieve this by introducing
    randomized phase errors such that only the legitimate receivers with a preshared
    key and randomization index can decode the message as well as the fingerprint.
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: '*Robustness in realistic operation environment* The fingerprinting literature
    to date (at the time of writing this article) has only looked at the problem of
    identifying emitter signature when only one emitter is active. An even challenging
    problem would be when multiple emitters are active, this is typical of a real-world
    setting. Such a scenario would require the fingerprinting algorithm to separately
    distinguish and extract the signatures of each emitters from the received signal
    clutter. Another challenge involved in studying such a scenario would be the availability
    of a dataset that incorporates multiple active emitters. Each emitter transmission
    creates its own propagation path from the transmitting antenna to the radio frontend
    of the receiver hardware. The effect of multipath propagation effects and location
    of the emitter relative to the receiver is enough to create a unique signature
    which would vary with location and wireless channel effects. These dynamic fading
    and location effects due to its inherent randomness could mask the *pure* emitter
    signature leading to false alarms and misclassification.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: In [[158](#bib.bib158)] authors demonstrate the effect of small scale and large
    scale fading on the PSD. It was illustrated that the side lobes of the PSDs that
    carry the most identity information were significantly distorted due to multipath
    channel effects when the sensors were far apart than when they were in close proximity
    to the receiver. Equalization at the receiver that would compensate for the multipath
    effects without deteriorating the fingerprint features is still an open research
    problem.
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8cc638513d74f5563b82884ccd958a98.png)'
  id: totrans-430
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Wireless IoT fingerprinting challenges'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
- en: '*Simulation-reality gap*: An equally important point to consider is the realism
    in the generated or synthetic data. The generalization of deep learning models
    to actual radio emissions after being trained on synthetic data is difficult to
    achieve. Such a capability gap arises from the assumptions in terms of the transmitter
    hardware imperfections and fading channel while generating the synthetic dataset
    in contrast to the actual hardware and environmental effects.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: 'A towering issue that leads to generating synthetic data is the lack of or
    limited access to real-world data from actual IoT sensors and radios. This is
    not the case in more popular machine learning fields such as natural language
    processing (NLP) and computer vision (CV) where a plethora of large-scale datasets
    such as MNIST [[162](#bib.bib162)], Stanford sentiment [[163](#bib.bib163)], IMDb
    [[164](#bib.bib164)], Sentiment140 [[165](#bib.bib165)], etc., are readily available.
    As highlighted in section [V-F](#S5.SS6 "V-F Open RF Fingerprinting Dataset ‣
    V Deep Learning for RF fingerprinting ‣ A Comprehensive Survey on Radio Frequency
    (RF) Fingerprinting: Traditional Approaches, Deep Learning, and Open Challenges"),
    there are several recent efforts to mitigate this challenge. Further, the lack
    of a uniform standard for the dataset structure and organization stymies the adoption
    of existing datasets to different machine learning frameworks. We state here that
    training the neural networks with a larger distribution of data is the key to
    a generalized performance. Generalization is the first step to deployment-ready
    fingerprinting solutions.'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: VII Conclusion
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This article presented a systematic review of the RF fingerprinting approaches
    over the past two decades by first broadly classifying them into traditional and
    DL-based followed by dissecting each in a categorized manner. We first provided
    context to the reader by introducing and summarizing the three pillars of SIGINT
    - modulation recognition, protocol classification, and emitter identification.
    We present an invaluable and concise discussion on the diverse applications of
    RF fingerprinting to highlight the practical use cases of the subject under study.
    To elucidate and dilute the vast literature on traditional and DL-based fingerprinting
    approaches, we present a categorized and clear layout of each. We have also provided
    tabular comparative study of the reviewed works wherever applicable for summarizing
    in a straightforward manner. In order to equip the reader with the essential toolkit
    to delve into this topic, we reviewed the most relevant DL approaches in a tutorial
    manner prior to diving into the DL-based fingerprinting techniques. Since the
    knowledge of and access to openly available datasets are key to practice the reviewed
    approaches, we have provided an elaborate discussion on the most relevant RF fingerprinting
    datasets. Finally, in order to stimulate future research in this realm, we present
    a roadmap of potential research avenues in an illustrative manner.
  id: totrans-435
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-436
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Q. Xu, R. Zheng, W. Saad, and Z. Han, “Device fingerprinting in wireless
    networks: Challenges and opportunities,” *IEEE Communications Surveys Tutorials*,
    vol. 18, no. 1, pp. 94–104, 2016.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] A. Jagannath, J. Jagannath, and T. Melodia, “Redefining Wireless Communication
    for 6G: Signal Processing Meets Deep Learning with Deep Unfolding,” *IEEE Transaction
    on Artificial Intelligence*, 2021.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] M. Wang, T. Zhu, T. Zhang, J. Zhang, S. Yu, and W. Zhou, “Security and
    privacy in 6g networks: New areas and new challenges,” *Digital Communications
    and Networks*, vol. 6, no. 3, pp. 281–291, 2020\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S2352864820302431](https://www.sciencedirect.com/science/article/pii/S2352864820302431)'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Y. Xu, D. Li, Z. Wang, G. Liu, and H. Lv, “A deep learning method based
    on convolutional neural network for automatic modulation classification of wireless
    signals,” in *Machine Learning and Intelligent Communications*, X. Gu, G. Liu,
    and B. Li, Eds.   Cham: Springer International Publishing, 2018, pp. 373–381.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] A. P. Hermawan, R. R. Ginanjar, D. Kim, and J. Lee, “Cnn-based automatic
    modulation classification for beyond 5g communications,” *IEEE Communications
    Letters*, vol. 24, no. 5, pp. 1038–1041, 2020.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] J. J. Popoola and R. v. Olst, “Effect of training algorithms on performance
    of a developed automatic modulation classification using artificial neural network,”
    in *Proc. of IEEE AFRICON*, Pointe-Aux-Piments, Mauritius, Sept 2013.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] A. Selim, F. Paisana, J. A. Arokkiam, Y. Zhang, L. Doyle, and L. A. DaSilva,
    “Spectrum monitoring for radar bands using deep convolutional neural networks,”
    in *GLOBECOM 2017 - 2017 IEEE Global Communications Conference*, 2017, pp. 1–6.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] J. Jagannath, N. Polosky, A. Jagannath, F. Restuccia, and T. Melodia, “Neural
    Networks for Signal Intelligence: Theory and Practice,,” in *Machine Learning
    for Future Wireless Communications*, ser. Wiley - IEEE Series, F. Luo, Ed.   John
    Wiley & Sons, Limited, 2019\. [Online]. Available: [https://books.google.com/books?id=3EI2vAEACAAJ](https://books.google.com/books?id=3EI2vAEACAAJ)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] M. Schmidt, D. Block, and U. Meier, “Wireless interference identification
    with convolutional neural networks,” in *Proc. of the IEEE Intl. Conf. on Industrial
    Informatics (INDIN)*, 2017, pp. 180–185.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] N. Bitar, S. Muhammad, and H. H. Refai, “Wireless technology identification
    using deep convolutional neural networks,” in *Proc. of Intl Symp. on Personal,
    Indoor, and Mobile Radio Comms. (PIMRC)*, 2017, pp. 1–6.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] T. J. O’Shea, J. Corgan, and T. C. Clancy, “Convolutional radio modulation
    recognition networks,” *ArXiv*, vol. abs/1602.04105, 2016.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] J. Jagannath, N. Polosky, A. Jagannath, F. Restuccia, and T. Melodia,
    “Machine learning for wireless communications in the internet of things: A comprehensive
    survey,” *Ad Hoc Networks (Elsevier)*, vol. 93, p. 101913, 2019.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] A. Jagannath and J. Jagannath, “Multi-task Learning Approach for Automatic
    Modulation and Wireless Signal Classification,” in *Proc. of IEEE International
    Conference on Communications (ICC)*, Montreal, Canada, June 2021.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] J. Robinson, S. Kuzdeba, J. Stankowicz, and J. M. Carmack, “Dilated causal
    convolutional model for rf fingerprinting,” in *Proc. of 10th Annual Computing
    and Communication Workshop and Conference (CCWC)*, 2020, pp. 0157–0162.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] G. Baldini and G. Steri, “A survey of techniques for the identification
    of mobile phones using the physical fingerprints of the built-in components,”
    *IEEE Communications Surveys Tutorials*, vol. 19, no. 3, pp. 1761–1789, 2017.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] X. Guo, Z. Zhang, and J. Chang, “Survey of mobile device authentication
    methods based on rf fingerprint,” in *IEEE INFOCOM 2019 - IEEE Conference on Computer
    Communications Workshops (INFOCOM WKSHPS)*, 2019, pp. 1–6.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] W. Wang, I. Aguilar Sanchez, G. Caparra, A. McKeown, T. Whitworth, and
    E. S. Lohan, “A survey of spoofer detection techniques via radio frequency fingerprinting
    with focus on the gnss pre-correlation sampled data,” *Sensors*, vol. 21, no. 9,
    2021\. [Online]. Available: [https://www.mdpi.com/1424-8220/21/9/3012](https://www.mdpi.com/1424-8220/21/9/3012)'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Q. Xu, R. Zheng, W. Saad, and Z. Han, “Device fingerprinting in wireless
    networks: Challenges and opportunities,” *IEEE Communications Surveys Tutorials*,
    vol. 18, no. 1, pp. 94–104, 2016.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] F. Hameed, O. Dobre, and D. Popescu, “On the likelihood-based approach
    to modulation classification,” *IEEE Transactions on Wireless Communications*,
    vol. 8, no. 12, pp. 5884–5892, December 2009.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] J. Zheng and Y. Lv, “Likelihood-based automatic modulation classification
    in ofdm with index modulation,” *IEEE Transactions on Vehicular Technology*, vol. 67,
    no. 9, pp. 8192–8204, 2018.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] T. Wimalajeewa, J. Jagannath, P. K. Varshney, A. Drozd, and W. Su, “Distributed
    asynchronous modulation classification based on hybrid maximum likelihood approach,”
    in *Proc. of IEEE Military Communications Conference (MILCOM)*, Tampa, FL, Oct
    2015.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Y. Zhang, N. Ansari, and W. Su, “Optimal Decision Fusion Based Automatic
    Modulation Classification by Using Wireless Sensor Networks in Multipath Fading
    Channel,” in *Proc. of IEEE Global Telecommunications Conference (GLOBECOM)*,
    Houston, TX, Dec 2011.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] B. Dulek, O. Ozdemir, P. K. Varshney, and W. Su, “Distributed Maximum
    Likelihood Classification of Linear Modulations over Nonidentical Flat Block-Fading
    Gaussian Channels,” *IEEE Transactions on Wireless Communications*, vol. 14, no. 2,
    pp. 724–737, Feb 2015.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] O. Ozdemir, T. Wimalajeewa, B. Dulek, P. K. Varshney, and W. Su, “Asynchronous
    Linear Modulation Classification with Multiple Sensors via Generalized EM Algorithm,”
    *IEEE Transactions on Wireless Communications*, vol. 14, no. 11, pp. 6389–6400,
    Nov 2015.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] A. Hazza, M. Shoaib, S. AlShebeili, and A. Fahd, “Automatic modulation
    classification of digital modulations in presence of HF noise.” *EURASIP Journal
    on Adv. in Signal Processing*, vol. 2012, p. 238, 2012.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] D. C. Chang and P. K. Shih, “Cumulants-based modulation classification
    technique in multipath fading channels,” *IET Communications*, vol. 9, no. 6,
    pp. 828–835, 2015.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. Majhi, R. Gupta, W. Xiang, and S. Glisic, “Hierarchical hypothesis
    and feature-based blind modulation classification for linearly modulated signals,”
    *IEEE Transactions on Vehicular Technology*, vol. 66, no. 12, pp. 11 057–11 069,
    2017.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] L. Han, F. Gao, Z. Li, and O. Dobre, “Low Complexity Automatic Modulation
    Classification Based on Order-Statistics,” *IEEE Transactions on Wireless Communications*,
    vol. PP, no. 99, pp. 1–1, 2016.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] J. Jagannath, D. O’Connor, N. Polosky, B. Sheaffer, L. N. Theagarajan,
    S. Foulke, P. K. Varshney, and S. P. Reichhart, “Design and Evaluation of Hierarchical
    Hybrid Automatic Modulation Classifier using Software Defined Radios,” in *Proc.
    of IEEE Annual Computing and Communication Workshop and Conference (CCWC)*, Las
    Vegas, NV, USA, January 2017.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] S. Foulke, J. Jagannath, A. Drozd, T. Wimalajeewa, P. Varshney, and W. Su,
    “Multisensor Modulation Classification (MMC): Implementation Considerations –
    USRP Case Study,” in *Proc. of IEEE Military Communications Conference (MILCOM)*,
    Baltimore, MD, Oct 2014.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] H.-Y. Liu and J.-C. Sun, “A modulation type recognition method using wavelet
    support vector machines,” in *Proc. of IEEE Intl. Congress on Image and Signal
    Processing (CISP)*, Tianjin, China, Oct 2009.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] J. J. Popoola and R. v. Olst, “A novel modulation-sensing method,” *IEEE
    Vehicular Technology Magazine*, vol. 6, no. 3, pp. 60–69, Sept 2011.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] M. M. Roganovic, A. M. Neskovic, and N. J. Neskovic, “Application of artificial
    neural networks in classification of digital modulations for software defined
    radio,” in *Proc. of IEEE EUROCON*, St. Petersburg, Russia, May 2009.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] S. Peng, H. Jiang, H. Wang, H. Alwageed, Y. Zhou, M. M. Sebdani, and Y. Yao,
    “Modulation classification based on signal constellation diagrams and deep learning,”
    *IEEE Transactions on Neural Networks and Learning Systems*, vol. 30, no. 3, pp.
    718–727, 2019.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] R. Li, L. Li, S. Yang, and S. Li, “Robust automated vhf modulation recognition
    based on deep convolutional neural networks,” *IEEE Communications Letters*, vol. 22,
    no. 5, pp. 946–949, 2018.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] T. J. O’Shea, T. Roy, and T. C. Clancy, “Over-the-air deep learning based
    radio signal classification,” *IEEE Journal of Selected Topics in Signal Processing*,
    vol. 12, no. 1, pp. 168–179, 2018.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] A. Jagannath, J. Jagannath, Y. Wang, and T. Melodia, “Deep neural network
    goes lighter: a case study of deep compression techniques on automatic rf modulation
    recognition for beyond 5g networks,” in *Big Data IV: Learning, Analytics, and
    Applications*, vol. 12097.   SPIE, 2022, pp. 58–69.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] C. Szegedy, Wei Liu, Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov,
    D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in
    *Proc. of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*,
    2015, pp. 1–9.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” in *Proc. of the 25th International
    Conference on Neural Information Processing Systems - Volume 1*, ser. NIPS 12,
    Red Hook, NY, USA, 2012, pp. 1097–1105.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] J. Jagannath, N. Polosky, D. O. Connor, L. Theagarajan, B. Sheaffer, S. Foulke,
    and P. Varshney, “Artificial Neural Network based Automatic Modulation Classifier
    for Software Defined Radios,” in *Proc. of IEEE Intl, Conf. on Communications
    (ICC)*, Kansas City, USA, May 2018.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] C. Wang, J. Wang, and X. Zhang, “Automatic radar waveform recognition
    based on time-frequency analysis and convolutional neural network,” in *Proc.
    of IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)*,
    2017, pp. 2437–2441.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] Z. Shi, M. Huang, C. Zhao, L. Huang, X. Du, and Y. Zhao, “Detection of
    lssuav using hash fingerprint based svdd,” in *2017 IEEE International Conference
    on Communications (ICC)*, 2017, pp. 1–5.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] M. Zuo, S. Xie, X. Zhang, and M. Yang, “Recognition of uav video signal
    using rf fingerprints in the presence of wifi interference,” *IEEE Access*, vol. 9,
    pp. 88 844–88 851, 2021.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] M. Kulin, T. Kazaz, I. Moerman, and E. De Poorter, “End-to-end learning
    from spectrum data: A deep learning approach for wireless signal identification
    in spectrum monitoring applications,” *IEEE Access*, vol. 6, pp. 18 484–18 501,
    2018.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] A. Jagannath and J. Jagannath, “Multi-task Learning Approach for Automatic
    Modulation and Wireless Signal Classification,” in *Proc. of IEEE International
    Conference on Communications (ICC)*, Montreal, Canada, June 2021.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] ——, “Multi-task Learning Approach for Modulation and Wireless Signal Classification
    for 5G and Beyond: Edge Deployment via Model Compression,” *Physical Communications
    (Elsevier)*, vol. 54, p. 101793, 2022.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] P. E. Manning, “Device fingerprinting identification and authentication:
    A two-fold use in multi-factor access control schemes,” Ph.D. dissertation, Iowa
    State University, 2016.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] I. Corporation. Identification and authentication. [Online]. Available:
    [https://www.ibm.com/docs/en/ibm-mq/7.5?topic=mechanisms-identification-authentication](https://www.ibm.com/docs/en/ibm-mq/7.5?topic=mechanisms-identification-authentication)'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] J. Bassey, X. Li, and L. Qian, “Device authentication codes based on rf
    fingerprinting using deep learning,” *arXiv preprint arXiv:2004.08742*, 2020.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] “RF Fingerprinting for Contraband Wireless Devices Identification, Detection
    and Tracking in Correctional Facilities.” [https://nij.ojp.gov/funding/awards/2018-75-cx-k002](https://nij.ojp.gov/funding/awards/2018-75-cx-k002).'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] L. Mucchi, S. Jayousi, S. Caputo, E. Paoletti, P. Zoppi, S. Geli, and
    P. Dioniso, “How 6g technology can change the future wireless healthcare,” in
    *Proc. of 2nd 6G Wireless Summit (6G SUMMIT)*, 2020, pp. 1–6.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] P. Porambage, G. GÃ¼r, D. P. M. Osorio, M. Liyanage, A. Gurtov, and M. Ylianttila,
    “The roadmap to 6g security and privacy,” *IEEE Open Journal of the Communications
    Society*, vol. 2, pp. 1094–1122, 2021.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] M. Kishk, A. Bader, and M.-S. Alouini, “Aerial base station deployment
    in 6g cellular networks using tethered drones: The mobility and endurance tradeoff,”
    *IEEE Vehicular Technology Magazine*, vol. 15, no. 4, pp. 103–111, 2020.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] S. Nayak and R. Patgiri, “6g communication technology: A vision on intelligent
    healthcare,” *ArXiv*, vol. abs/2005.07532, 2021.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Y. Wu, A. Khisti, C. Xiao, G. Caire, K.-K. Wong, and X. Gao, “A survey
    of physical layer security techniques for 5g wireless networks and challenges
    ahead,” *IEEE Journal on Selected Areas in Communications*, vol. 36, no. 4, pp.
    679–695, 2018.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] K. Ramezanpour, J. Jagannath, and A. Jagannath, “Security and Privacy
    vulnerabilities of 5G/6G and WiFi 6: Survey and Research Directions from a Coexistence
    Perspective,” *arXiv preprint arXiv:2206.14997*, 2022.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] I. Ahmad, S. Shahabuddin, T. Kumar, J. Okwuibe, A. Gurtov, and M. Ylianttila,
    “Security for 5g and beyond,” *IEEE Communications Surveys & Tutorials*, vol. 21,
    no. 4, pp. 3682–3722, 2019.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] K. Ramezanpour and J. Jagannath, “Intelligent Zero Trust Architecture
    for 5G/6G Networks: Principles, Challenges, and the Role of Machine Learning in
    the context of O-RAN,” *arXiv preprint arXiv:2105.01478*, 2022.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] J. Jagannath, K. Ramezanpour, and A. Jagannath, “Digital Twin Virtualization
    with Machine Learning for IoT and Beyond 5G Networks: Research Directions for
    Security and Optimal Control,” in *Proc. of ACM Workshop on Wireless Security
    and Machine Learning (WiseML)*, San Antonio, Texas, USA, May 2022.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] I. D.P., S. S., and R. E.B, *SDN-Based Traffic Management for Personalized
    Ambient Assisted Living Healthcare System,*.   Springer  Singapore, 2020\. [Online].
    Available: [https://doi.org/10.1007/978-981-15-5285-4_38](https://doi.org/10.1007/978-981-15-5285-4_38)'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] J. Jagannath, S. Furman, A. Jagannath, L. Ling, A. Burger, and A. Drozd,
    “HELPER: Heterogeneous Efficient Low Power Radio for Enabling Ad Hoc Emergency
    Public Safety Networks,” *Ad Hoc Networks*, 2019.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] X. Jiang, M. Sheng, N. Zhao, C. Xing, W. Lu, and X. Wang, “Green uav communications
    for 6g: A survey,” *Chinese Journal of Aeronautics*, 2021\. [Online]. Available:
    [https://www.sciencedirect.com/science/article/pii/S1000936121001801](https://www.sciencedirect.com/science/article/pii/S1000936121001801)'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Y. Siriwardhana, P. Porambage, M. Liyanage, and M. Ylianttila, “A survey
    on mobile augmented reality with 5g mobile edge computing: Architectures, applications,
    and technical aspects,” *IEEE Communications Surveys Tutorials*, vol. 23, no. 2,
    pp. 1160–1192, 2021.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] F. Tariq, M. R. A. Khandaker, K.-K. Wong, M. A. Imran, M. Bennis, and
    M. Debbah, “A speculative study on 6g,” *IEEE Wireless Communications*, vol. 27,
    no. 4, pp. 118–125, 2020.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] V. Brik, S. Banerjee, M. Gruteser, and S. Oh, “Wireless device identification
    with radiometric signatures,” in *Proceedings of the 14th ACM International Conference
    on Mobile Computing and Networking*, 2008, pp. 116–127.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] C. chung Chang and C. jen Lin, “Libsvm : a library for support vector
    machines,” [http://www.csie.ntu.edu.tw/~cjlin/libsvm](http://www.csie.ntu.edu.tw/~cjlin/libsvm).'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] “Open-access research testbed for next-generation wireless networks (orbit),”
    [https://www.orbit-lab.org/](https://www.orbit-lab.org/).'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] F. zhuo, Y. Huang, and J. chen, “Radio frequency fingerprint extraction
    of radio emitter based on i/q imbalance,” *Procedia Computer Science*, vol. 107,
    pp. 472–477, 2017, advances in Information and Communication Technology: Proceedings
    of 7th International Congress of Information and Communication Technology (ICICT2017).
    [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S1877050917303678](https://www.sciencedirect.com/science/article/pii/S1877050917303678)'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] B. Danev, T. S. Heydt-Benjamin, and S. Capkun, “Physical-layer identification
    of rfid devices.” in *USENIX security symposium*, 2009, pp. 199–214.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] K. Bonne Rasmussen and S. Capkun, “Implications of radio fingerprinting
    on the security of sensor networks,” in *2007 Third International Conference on
    Security and Privacy in Communications Networks and the Workshops - SecureComm
    2007*, 2007, pp. 331–340.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] B. F. Manly and J. A. N. Alberto, *Multivariate statistical methods: a
    primer*.   Chapman and Hall/CRC, 2016.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] C. M. Bishop, *Pattern Recognition and Machine Learning*.   Springer,
    2006.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] A. Candore, O. Kocabas, and F. Koushanfar, “Robust stable radiometric
    fingerprinting for wireless devices,” in *2009 IEEE International Workshop on
    Hardware-Oriented Security and Trust*, 2009, pp. 43–49.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] Y. Huang and H. Zheng, “Radio frequency fingerprinting based on the constellation
    errors,” in *2012 18th Asia-Pacific Conference on Communications (APCC)*, 2012,
    pp. 900–905.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] H. Patel, “Non-parametric feature generation for rf-fingerprinting on
    zigbee devices,” in *2015 IEEE Symposium on Computational Intelligence for Security
    and Defense Applications (CISDA)*, 2015, pp. 1–5.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] M. Lukacs, P. Collins, and M. Temple, “Classification performance using
    ’rf-dna’ fingerprinting of ultra-wideband noise waveforms,” *Electronics Letters*,
    vol. 51, no. 10, pp. 787–789, 2015\. [Online]. Available: [https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/el.2015.0051](https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/el.2015.0051)'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] B. Hammer and T. Villmann, “Generalized relevance learning vector quantization,”
    *Neural Networks*, vol. 15, no. 8, pp. 1059–1068, 2002. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0893608002000795](https://www.sciencedirect.com/science/article/pii/S0893608002000795)'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] D. Shaw and W. Kinsner, “Multifractal modelling of radio transmitter transients
    for classification,” in *IEEE WESCANEX 97 Communications, Power and Computing.
    Conference Proceedings*, 1997, pp. 306–312.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] O. Ureten and N. Serinken, “Detection of radio transmitter turn-on transients,”
    *Electronics Letters*, vol. 35, no. 23, pp. 1996–1997, 1999.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] J. Hall, M. Barbeau, E. Kranakis *et al.*, “Detection of transient in
    radio frequency fingerprinting using signal phase,” *Wireless and Optical Communications*,
    pp. 13–18, 2003.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] B. Danev and S. Capkun, “Transient-based identification of wireless sensor
    nodes,” in *2009 International Conference on Information Processing in Sensor
    Networks*, 2009, pp. 25–36.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] A. Martinez and A. Kak, “Pca versus lda,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, vol. 23, no. 2, pp. 228–233, 2001.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] Y. Yuan, Z. Huang, H. Wu, and X. Wang, “Specific emitter identification
    based on hilbert-huang transform-based time-frequency-energy distribution features,”
    *IET Communications*, vol. 8, no. 13, pp. 2404–2412, 2014. [Online]. Available:
    [https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-com.2013.0865](https://ietresearch.onlinelibrary.wiley.com/doi/abs/10.1049/iet-com.2013.0865)'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] N. E. Huang, Z. Shen, S. R. Long, M. C. Wu, H. H. Shih, Q. Zheng, N.-C.
    Yen, C. C. Tung, and H. H. Liu, “The empirical mode decomposition and the hilbert
    spectrum for nonlinear and non-stationary time series analysis,” *Proceedings
    of the Royal Society of London. Series A: mathematical, physical and engineering
    sciences*, vol. 454, no. 1971, pp. 903–995, 1998.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] S. Ur Rehman, K. Sowerby, and C. Coghill, “Rf fingerprint extraction from
    the energy envelope of an instantaneous transient signal,” in *2012 Australian
    Communications Theory Workshop (AusCTW)*, 2012, pp. 90–95.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] R. W. Klein, M. A. Temple, and M. J. Mendenhall, “Application of wavelet-based
    rf fingerprinting to enhance wireless network security,” *Journal of Communications
    and Networks*, vol. 11, no. 6, pp. 544–555, 2009.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] I. Selesnick, R. Baraniuk, and N. Kingsbury, “The dual-tree complex wavelet
    transform,” *IEEE Signal Processing Magazine*, vol. 22, no. 6, pp. 123–151, 2005.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] C. Bertoncini, K. Rudd, B. Nousain, and M. Hinders, “Wavelet fingerprinting
    of radio-frequency identification (rfid) tags,” *IEEE Transactions on Industrial
    Electronics*, vol. 59, no. 12, pp. 4843–4850, 2012.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] J. Hou and M. K. Hinders, “Dynamic wavelet fingerprint identification
    of ultrasound signals,” *Materials evaluation*, vol. 60, no. 9, pp. 1089–1093,
    2002.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] R. E. Learned and A. S. Willsky, “A wavelet packet approach to transient
    signal classification,” *Applied and Computational Harmonic Analysis*, vol. 2,
    no. 3, pp. 265–278, 1995\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S1063520385710196](https://www.sciencedirect.com/science/article/pii/S1063520385710196)'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] M. Ezuma, F. Erden, C. K. Anjinappa, O. Ozdemir, and I. Guvenc, “Micro-uav
    detection and classification from rf fingerprints using machine learning techniques,”
    in *2019 IEEE Aerospace Conference*, 2019, pp. 1–13.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] J. Goldberger, G. E. Hinton, S. Roweis, and R. R. Salakhutdinov, “Neighbourhood
    components analysis,” *Advances in neural information processing systems*, vol. 17,
    2004.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] I. O. Kennedy, P. Scanlon, F. J. Mullany, M. M. Buddhikot, K. E. Nolan,
    and T. W. Rondeau, “Radio transmitter fingerprinting: A steady state frequency
    domain approach,” in *2008 IEEE 68th Vehicular Technology Conference*, 2008, pp.
    1–5.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] S. Deng, Z. Huang, X. Wang, and G. Huang, “Radio frequency fingerprint
    extraction based on multidimension permutation entropy,” *International Journal
    of Antennas and Propagation*, vol. 2017, 2017.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Y. Yuan, X. Liu, Z. Liu, and Z. Xu, “Mfmcf: A novel indoor location method
    combining multiple fingerprints and multiple classifiers,” in *2019 3rd International
    Symposium on Autonomous Systems (ISAS)*, 2019, pp. 216–221.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] G. Baldini, R. Giuliani, G. Steri, and R. Neisse, “Physical layer authentication
    of internet of things wireless devices through permutation and dispersion entropy,”
    in *2017 Global Internet of Things Summit (GIoTS)*, 2017, pp. 1–6.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] F. E. Grubbs, “Procedures for detecting outlying observations in samples,”
    *Technometrics*, vol. 11, no. 1, pp. 1–21, 1969.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] “MySensors,” [http://www.mysensors.org/](http://www.mysensors.org/).'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] J. Jagannath, A. Jagannath, S. Furman, and T. Gwin, “Deep learning and
    reinforcement learning for autonomous unmanned aerial systems: Roadmap for theory
    to deployment,” *arXiv preprint 2009.03349*, 2020.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] I. Kuzovkin, R. Vicente, M. Petton, J. Lachaux, M. Baciu, P. Kahane,
    S. Rheims, J. R. Vidal, and J. Aru, “Activations of deep convolutional neural
    networks are aligned with gamma band activity of human visual cortex,” *Communications
    Biology*, vol. 1, 2018.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] C. Szegedy, Wei Liu, Yangqing Jia, P. Sermanet, S. Reed, D. Anguelov,
    D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with convolutions,” in
    *Proc. of IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*,
    2015, pp. 1–9.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
    applied to document recognition,” *Proceedings of the IEEE*, vol. 86, no. 11,
    pp. 2278–2324, 1998.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale
    image recognition,” in *Proc. of 3rd International Conference on Learning Representations,
    ICLR*, Y. Bengio and Y. LeCun, Eds., 2015.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] F. N. Iandola, M. W. Moskewicz, K. Ashraf, S. Han, W. Dally, and K. Keutzer,
    “Squeezenet: Alexnet-level accuracy with 50x fewer parameters and $<$1mb model
    size,” *ArXiv*, vol. abs/1602.07360, 2017.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] Y. LeCun, K. Kavukcuoglu, and C. Farabet, “Convolutional networks and
    applications in vision,” in *Proc. of IEEE International Symposium on Circuits
    and Systems*, 2010, pp. 253–256.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] S. Ren, K. He, R. Girshick, and J. Sun, “Faster R-CNN: Towards Real-Time
    Object Detection with Region Proposal Networks,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, vol. 39, no. 6, pp. 1137–1149, 2017.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] F. Nasse, C. Thurau, and G. A. Fink, “Face detection using gpu-based
    convolutional neural networks,” in *Proc. of the 13th International Conference
    on Computer Analysis of Images and Patterns*, ser. CAIP ’09.   Berlin, Heidelberg:
    Springer-Verlag, 2009, pp. 83–90.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image
    Recognition,” in *Proc. of IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR)*, 2016, pp. 770–778.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] I. Goodfellow, Y. Bengio, and A. Courville, *Deep Learning*.   MIT Press,
    2016.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] A. Carrio, C. Sampedro, A. Rodriguez-Ramos, and P. Campoy, “A review
    of deep learning methods and applications for unmanned aerial vehicles,” *Journal
    of Sensors*, vol. 2017, 2017.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] D. E. Rumelhart, P. Smolensky, J. L. McClelland, and G. E. Hinton, “Schemata
    and sequential thought processes in pdp models,” in *Parallel Distributed Processing:
    Explorations in the Microstructure, Vol. 2: Psychological and Biological Models*.   Cambridge,
    MA, USA: MIT Press, 1986, pp. 7–57.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,”
    *IEEE Transactions on Signal Processing*, vol. 45, no. 11, pp. 2673–2681, 1997.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, “Generative adversarial nets,” *Advances in neural
    information processing systems*, vol. 27, 2014.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] K. Sankhe, M. Belgiovine, F. Zhou, S. Riyaz, S. Ioannidis, and K. Chowdhury,
    “Oracle: Optimized radio classification through convolutional neural networks,”
    in *IEEE INFOCOM 2019-IEEE Conference on Computer Communications*.   IEEE, 2019,
    pp. 370–378.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] N. Soltani, G. Reus-Muns, B. Salehi, J. Dy, S. Ioannidis, and K. Chowdhury,
    “Rf fingerprinting unmanned aerial vehicles with non-standard transmitter waveforms,”
    *IEEE Transactions on Vehicular Technology*, vol. 69, no. 12, pp. 15 518–15 531,
    2020.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] C. Shorten and T. M. Khoshgoftaar, “A survey on image data augmentation
    for deep learning,” *Journal of Big Data*, vol. 6, no. 1, pp. 1–48, 2019.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] N. Soltani, K. Sankhe, J. Dy, S. Ioannidis, and K. Chowdhury, “More is
    better: Data augmentation for channel-resilient rf fingerprinting,” *IEEE Communications
    Magazine*, vol. 58, no. 10, pp. 66–72, 2020.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] L. Ding, S. Wang, F. Wang, and W. Zhang, “Specific emitter identification
    via convolutional neural networks,” *IEEE Communications Letters*, vol. 22, no. 12,
    pp. 2591–2594, 2018.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] Y. Xu, G. Feng, and Y. Zhao, “One improvement to two-dimensional locality
    preserving projection method for use with face recognition,” *Neurocomputing*,
    vol. 73, no. 1, pp. 245–249, 2009\. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0925231209003348](https://www.sciencedirect.com/science/article/pii/S0925231209003348)'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] A. S. Sappal, “Simplified memory polynomial modelling of power amplifier,”
    in *2015 International Conference and Workshop on Computing and Communication
    (IEMCON)*, 2015, pp. 1–7.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] L. Peng, J. Zhang, M. Liu, and A. Hu, “Deep learning based rf fingerprint
    identification using differential constellation trace figure,” *IEEE Transactions
    on Vehicular Technology*, vol. 69, no. 1, pp. 1091–1095, 2020.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] L. Peng, A. Hu, Y. Jiang, Y. Yan, and C. Zhu, “A differential constellation
    trace figure based device identification method for zigbee nodes,” in *2016 8th
    International Conference on Wireless Communications Signal Processing (WCSP)*,
    2016, pp. 1–6.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] L. Zong, C. Xu, and H. Yuan, “A rf fingerprint recognition method based
    on deeply convolutional neural network,” in *Proc. of IEEE 5th Information Technology
    and Mechatronics Engineering Conference (ITOEC)*, 2020, pp. 1778–1781.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] T. Jian, B. C. Rendon, E. Ojuba, N. Soltani, Z. Wang, K. Sankhe, A. Gritsenko,
    J. Dy, K. Chowdhury, and S. Ioannidis, “Deep learning for rf fingerprinting: A
    massive experimental study,” *IEEE Internet of Things Magazine*, vol. 3, no. 1,
    pp. 50–57, 2020.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] A. Al-Shawabka, F. Restuccia, S. D’Oro, T. Jian, B. C. Rendon, N. Soltani,
    J. Dy, K. Chowdhury, S. Ioannidis, and T. Melodia, “Exposing the Fingerprint:
    Dissecting the Impact of the Wireless Channel on Radio Fingerprinting,” *Proc.
    of IEEE Conference on Computer Communications (INFOCOM)*, 2020.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] G. Reus-Muns, D. Jaisinghani, K. Sankhe, and K. Chowdhury, “Trust in
    5g open rans through machine learning: Rf fingerprinting on the powder pawr platform,”
    in *IEEE Globecom 2020-IEEE Global Communications Conference*.   IEEE, 2020.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] F. Schroff, D. Kalenichenko, and J. Philbin, “Facenet: A unified embedding
    for face recognition and clustering,” in *Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition (CVPR)*, June 2015.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] “Radio frequency machine learning systems (rfmls).” [Online]. Available:
    [https://www.darpa.mil/program/radio-frequency-machine-learning-systems](https://www.darpa.mil/program/radio-frequency-machine-learning-systems)'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] A. van den Oord, S. Dieleman, H. Zen, K. Simonyan, O. Vinyals, A. Graves,
    N. Kalchbrenner, A. Senior, and K. Kavukcuoglu, “Wavenet: A generative model for
    raw audio,” 2016.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] J. Robinson and S. Kuzdeba, “Riftnet: Radio frequency classification
    for large populations,” in *Proc. of IEEE 18th Annual Consumer Communications
    & Networking Conference (CCNC)*, 2021, pp. 1–6.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] “ORACLE RF Fingerprinting Dataset,” [https://genesys-lab.org/oracle](https://genesys-lab.org/oracle).'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] J. Breen, A. Buffmire, J. Duerig, K. Dutt, E. Eide, A. Ghosh, M. Hibler,
    D. Johnson, S. K. Kasera, E. Lewis, D. Maas, C. Martin, A. Orange, N. Patwari,
    D. Reading, R. Ricci, D. Schurig, L. B. Stoller, A. Todd, J. Van der Merwe, N. Viswanathan,
    K. Webb, and G. Wong, “Powder: Platform for open wireless data-driven experimental
    research,” *Computer Networks*, vol. 197, p. 108281, 2021\. [Online]. Available:
    [https://www.sciencedirect.com/science/article/pii/S1389128621003017](https://www.sciencedirect.com/science/article/pii/S1389128621003017)'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] C. Zhao, C. Chen, Z. Cai, M. Shi, X. Du, and M. Guizani, “Classification
    of small uavs based on auxiliary classifier wasserstein gans,” in *2018 IEEE Global
    Communications Conference (GLOBECOM)*, 2018, pp. 206–212.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] A. Odena, C. Olah, and J. Shlens, “Conditional image synthesis with auxiliary
    classifier GANs,” in *Proceedings of the 34th International Conference on Machine
    Learning*, ser. Proceedings of Machine Learning Research, vol. 70.   PMLR, 2017,
    pp. 2642–2651\. [Online]. Available: [https://proceedings.mlr.press/v70/odena17a.html](https://proceedings.mlr.press/v70/odena17a.html)'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] M. Arjovsky, S. Chintala, and L. Bottou, “Wasserstein generative adversarial
    networks,” in *Proceedings of the 34th International Conference on Machine Learning*,
    ser. Proceedings of Machine Learning Research, vol. 70.   PMLR, 06–11 Aug 2017,
    pp. 214–223\. [Online]. Available: [https://proceedings.mlr.press/v70/arjovsky17a.html](https://proceedings.mlr.press/v70/arjovsky17a.html)'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. Courville, “Improved
    training of wasserstein gans,” *arXiv preprint arXiv:1704.00028*, 2017.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] D. Roy, T. Mukherjee, M. Chatterjee, and E. Pasiliao, “Detection of rogue
    rf transmitters using generative adversarial nets,” in *2019 IEEE Wireless Communications
    and Networking Conference (WCNC)*, 2019, pp. 1–7.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] M. Köse, S. Taşcioğlu, and Z. Telatar, “Rf fingerprinting of iot devices
    based on transient energy spectrum,” *IEEE Access*, vol. 7, pp. 18 715–18 726,
    2019.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] O. Ureten and N. Serinken, “Bayesian detection of wi-fi transmitter rf
    fingerprints,” *Electronics Letters*, vol. 41, no. 6, pp. 373–374, 2005.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] R. O. Duda, P. E. Hart, and D. G. Stork, *Pattern classification, second
    edition*, 2nd ed., 2012.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] S. Taşcioğlu, M. Köse, and Z. Telatar, “Effect of sampling rate on transient
    based rf fingerprinting,” in *2017 10th International Conference on Electrical
    and Electronics Engineering (ELECO)*, 2017, pp. 1156–1160.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] A. Jagannath and Z. Kane and J. Jagannath, “RF Fingerprinting Needs Attention:
    Multi-task Approach for Real-World WiFi and Bluetooth,” in *Proc. of IEEE Global
    Communications Conference (GLOBECOM)*, Rio de Janeiro, Brazil, December 2022.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] A. Jagannath and J. Jagannath, “Embedding-assisted attentional deep learning
    for real-world rf fingerprinting of bluetooth,” 2022.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] K. Team. Keras Datasets. [Online]. Available: [https://keras.io/api/datasets/](https://keras.io/api/datasets/)'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] T. Contributors. TorchVision Datasets. [Online]. Available: [https://pytorch.org/vision/stable/datasets.html](https://pytorch.org/vision/stable/datasets.html)'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] T. Team. TensorFlow Datasets: a collection of ready-to-use datasets.
    [Online]. Available: [https://www.tensorflow.org/datasets](https://www.tensorflow.org/datasets)'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] M. Schmidt, D. Block, and U. Meier, “CRAWDAD dataset owl/interference
    (v. 2019-02-12),” Downloaded from https://crawdad.org/owl/interference/20190212,
    Feb. 2019.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] Tekbiyik, Kursat and Kececi, Cihat and Ekti, Ali Riza and Gorcin, Ali
    and Karabulut Kurt, Gunes, “HisarMod: A new challenging modulated signals dataset,”
    https://ieee-dataport.org/open-access/hisarmod-new-challenging-modulated-signals-dataset,
    2019.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] A. Jagannath and J. Jagannath, “Dataset for modulation classification
    and signal type classification for multi-task and single task learning,” *Computer
    Networks (Elseier)*, 2021.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] E. Uzundurukan, Y. Dalveren, and A. Kara, “A database for the radio frequency
    fingerprinting of bluetooth devices,” *Data*, vol. 5, no. 2, 2020. [Online]. Available:
    [https://www.mdpi.com/2306-5729/5/2/55](https://www.mdpi.com/2306-5729/5/2/55)'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] Ezuma, Martins and Erden, Fatih and Anjinappa, Chethan K. and Ozdemir,
    Ozgur and Guvenc, Ismail, “Drone Remote Controller RF Signal Dataset,” https://dx.doi.org/10.21227/ss99-8d56,
    2020.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] Liu, Yongxin and Wang, Jian and Niu, Shuteng and Song, Houbing, “ADS-B
    signals records for non-cryptographic identification and incremental learning.”
    https://dx.doi.org/10.21227/1bxc-ke87, 2021.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] Liu, Yongxin and Wang, Jian and Song, Houbing and Niu, Shuteng and Yang,
    Thomas, “A 24-hour signal recording dataset with labels for cybersecurity and
    IoT,” https://dx.doi.org/10.21227/gt9v-kz32, 2020.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] “on-standard Waveforms from Hovering Unmanned Aerial Vehicles (UAVs)
    Dataset,” [https://genesys-lab.org/hovering-uavs](https://genesys-lab.org/hovering-uavs).'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] “Datasets for RF Fingerprinting on the POWDER Platform,” [https://genesys-lab.org/powder](https://genesys-lab.org/powder).'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] “Datasets Release: An IEEE 802.11 a/g (WiFi) massive-scale and labeled
    datasets for Radio Fingerprinting,” [https://www.northeastern.edu/wiot/wp-content/uploads/2020/07/dataset_release.pdf](https://www.northeastern.edu/wiot/wp-content/uploads/2020/07/dataset_release.pdf).'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] Y. Liu, J. Wang, J. Li, H. Song, T. Yang, S. Niu, and Z. Ming, “Zero-bias
    deep learning for accurate identification of internet-of-things (iot) devices,”
    *IEEE Internet of Things Journal*, vol. 8, no. 4\. [Online]. Available: [https://par.nsf.gov/biblio/10213235](https://par.nsf.gov/biblio/10213235)'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] W. Wang, Z. Sun, S. Piao, B. Zhu, and K. Ren, “Wireless physical-layer
    identification: Modeling and validation,” *IEEE Transactions on Information Forensics
    and Security*, vol. 11, no. 9, pp. 2091–2106, 2016.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] B. Danev, H. Luecken, S. Capkun, and K. El Defrawy, “Attacks on physical-layer
    identification,” in *Proc. of the Third ACM Conference on Wireless Network Security*,
    ser. WiSec ’10.   New York, NY, USA: Association for Computing Machinery, 2010,
    pp. 89–98. [Online]. Available: [https://doi.org/10.1145/1741866.1741882](https://doi.org/10.1145/1741866.1741882)'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] S. U. Rehman, K. W. Sowerby, and C. Coghill, “Analysis of impersonation
    attacks on systems using rf fingerprinting and low-end receivers,” *Journal of
    Computer and System Sciences*, vol. 80, no. 3, pp. 591–601, 2014, special Issue
    on Wireless Network Intrusion. [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0022000013001220](https://www.sciencedirect.com/science/article/pii/S0022000013001220)'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] L. F. Abanto-Leon, A. Bäuml, G. H. A. Sim, M. Hollick, and A. Asadi,
    “Stay connected, leave no trace: Enhancing security and privacy in wifi via obfuscating
    radiometric fingerprints,” *Proc. ACM Meas. Anal. Comput. Syst.*, vol. 4, no. 3,
    nov 2020\. [Online]. Available: [https://doi.org/10.1145/3428329](https://doi.org/10.1145/3428329)'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] Y. LeCun and C. Cortes, “MNIST handwritten digit database,” 2010\. [Online].
    Available: [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] R. Socher, A. Perelygin, J. Wu, J. Chuang, C. D. Manning, A. Ng, and
    C. Potts, “Recursive deep models for semantic compositionality over a sentiment
    treebank,” in *Proc. of Empirical Methods in Natural Language Processing*, 2013.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] A. L. Maas, R. E. Daly, P. T. Pham, D. Huang, A. Y. Ng, and C. Potts,
    “Learning word vectors for sentiment analysis,” in *Proc. of the 49th Annual Meeting
    of the Association for Computational Linguistics: Human Language Technologies*.   Portland,
    Oregon, USA: Association for Computational Linguistics, June 2011, pp. 142–150\.
    [Online]. Available: [http://www.aclweb.org/anthology/P11-1015](http://www.aclweb.org/anthology/P11-1015)'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] A. Go, R. Bhayani, and L. Huang, “Twitter sentiment classification using
    distant supervision,” pp. 1–6, 2009\. [Online]. Available: [http://www.stanford.edu/~alecmgo/papers/TwitterDistantSupervision09.pdf](http://www.stanford.edu/~alecmgo/papers/TwitterDistantSupervision09.pdf)'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![[Uncaptioned image]](img/d66f4606075ef939185d70b3af2061a6.png) | Anu Jagannath
    currently serves as the Founding Associate Director of Marconi-Rosenblatt AI/ML
    Innovation Lab at ANDRO Computational Solutions, LLC. She received her MS degree
    from State University of New York at Buffalo in Electrical Engineering. She is
    also a part-time PhD candidate and is with the Institute for the Wireless Internet
    of Things at Northeastern University, USA. Her research focuses on MIMO communications,
    deep machine learning, reinforcement learning, adaptive signal processing, software
    defined radios, spectrum sensing, adaptive physical layer, and cross layer techniques,
    medium access control and routing protocols, underwater wireless sensor networks,
    and signal intelligence. She has rendered her reviewing service for several leading
    IEEE conferences and Journals. She is an IEEE Senior Member. She is the co-Principal
    Investigator (co-PI) and Technical Lead in multiple Rapid Innovation Fund (RIF)
    and SBIR/STTR efforts involving applied AI/ML for wireless communications. She
    is also the inventor on 6 US Patents (granted and pending). |'
  id: totrans-602
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/80dc5dff3ee947b7507f771d1b79a0d8.png) | Jithin
    Jagannath is the Chief Scientist of Technology and Founding Director of the Marconi-Rosenblatt
    AI/ML Innovation Lab at ANDRO Computational Solutions. He is also the Adjunct
    Assistant Professor in the Department of Electrical Engineering at the University
    at Buffalo, State University of New York. Dr. Jagannath received his B. Tech in
    Electronics and Communication from Kerala University; M.S. degree in Electrical
    Engineering from University at Buffalo, The State University of New York; and
    received his Ph.D. degree in Electrical Engineering from Northeastern University.
    Dr. Jagannath was the recipient of 2021 IEEE Region 1 Technological Innovation
    Award with the citation, "For innovative contributions in machine learning techniques
    for the wireless domain”. He is also the recipient of AFCEA International Meritorious
    Rising Star Award for achievement in engineering and AFCEA 40 Under 40 award.
    Dr. Jagannath heads several of the ANDRO’s research and development projects in
    the field of Beyond 5G, signal processing, RF signal intelligence, cognitive radio,
    cross-layer ad-hoc networks, Internet-of-Things, AI-enabled wireless, and machine
    learning. He has been the lead and Principal Investigator (PI) of several multi-million
    dollar research projects. This includes a Rapid Innovation Fund (RIF) and several
    Small Business Innovation Research (SBIR)s for several customers including the
    U.S. Army, U.S Navy, Department of Homeland Security (DHS), United States Special
    Operations Command (SOCOM). He is currently leading several teams developing commercial
    products such as SPEARLink™, DEEPSPEC™  among others. He is an IEEE Senior Member
    and serves on the IEEE Signal Processing Society’s Applied Signal Processing Systems
    Technical Committee. Dr. Jagannath’s recent research has led to several peer-reviewed
    journal and conference publications. He is the inventor of 12 U.S. Patents (granted
    and pending). He has been invited to give various talks including Keynote on the
    topic of machine learning and Beyond 5G wireless communication. He has been invited
    to serve on the Technical Program Committee for several leading technical conferences.
    |'
  id: totrans-603
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/f69eea0d3472c208fa00280d0e0b68cf.png) | Prem Sagar
    Pattanshetty Vasanth Kumar is an Associate Scientist/Engineer of Marconi-Rosenblatt
    AI/ML Innovation Lab at ANDRO Computational Solutions, LLC. He received his Bachelor
    of Engineering degree in Electronics and Communication from Visvesvaraya Technological
    University and a Master of Science degree in Electrical Engineering from State
    University of New York at Buffalo. His areas of research interests include machine
    learning, reinforcement learning, neural networks, software defined radios, physical
    layer, and wireless communications. |'
  id: totrans-604
  prefs: []
  type: TYPE_TB
