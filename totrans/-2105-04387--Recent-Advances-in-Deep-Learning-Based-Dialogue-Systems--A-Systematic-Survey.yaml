- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:55:12'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2105.04387] Recent Advances in Deep Learning Based Dialogue Systems: A Systematic
    Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2105.04387](https://ar5iv.labs.arxiv.org/html/2105.04387)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Jinjie Ni Nanyang Technological University, Singapore. {jinjie001, yang0552,
    fuzhao001}@e.ntu.edu.sg, {vlad.pandelea, cambria}@ntu.edu.sg Tom Young¹¹1Equal
    contribution Nanyang Technological University, Singapore. {jinjie001, yang0552,
    fuzhao001}@e.ntu.edu.sg, {vlad.pandelea, cambria}@ntu.edu.sg Vlad Pandelea¹¹footnotemark:
    1 Nanyang Technological University, Singapore. {jinjie001, yang0552, fuzhao001}@e.ntu.edu.sg,
    {vlad.pandelea, cambria}@ntu.edu.sg Fuzhao Xue Nanyang Technological University,
    Singapore. {jinjie001, yang0552, fuzhao001}@e.ntu.edu.sg, {vlad.pandelea, cambria}@ntu.edu.sg
    Erik Cambria³³3Corresponding author Nanyang Technological University, Singapore.
    {jinjie001, yang0552, fuzhao001}@e.ntu.edu.sg, {vlad.pandelea, cambria}@ntu.edu.sg'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Dialogue systems are a popular natural language processing (NLP) task as it
    is promising in real-life applications. It is also a complicated task since many
    NLP tasks deserving study are involved. As a result, a multitude of novel works
    on this task are carried out, and most of them are deep learning based due to
    the outstanding performance. In this survey, we mainly focus on the deep learning
    based dialogue systems. We comprehensively review state-of-the-art research outcomes
    in dialogue systems and analyze them from two angles: model type and system type.
    Specifically, from the angle of model type, we discuss the principles, characteristics,
    and applications of different models that are widely used in dialogue systems.
    This will help researchers acquaint these models and see how they are applied
    in state-of-the-art frameworks, which is rather helpful when designing a new dialogue
    system. From the angle of system type, we discuss task-oriented and open-domain
    dialogue systems as two streams of research, providing insight into the hot topics
    related. Furthermore, we comprehensively review the evaluation methods and datasets
    for dialogue systems to pave the way for future research. Finally, some possible
    research trends are identified based on the recent research outcomes. To the best
    of our knowledge, this survey is the most comprehensive and up-to-date one at
    present for deep learning based dialogue systems, extensively covering the popular
    techniques¹¹1The frameworks, topics, and datasets discussed are originated from
    the extensive literature review of state-of-the-art research. We have tried our
    best to cover all but may still omit some works. Readers are welcome to provide
    suggestions regarding the omissions and mistakes in this article. We also intend
    to update this article with time as and when new approaches or definitions are
    proposed and used by the community. We speculate that this work is a good starting
    point for academics who are new to the dialogue systems or those who want to quickly
    grasp up-to-date techniques in this area.'
  prefs: []
  type: TYPE_NORMAL
- en: Keywords  Dialogue systems, Chatbots, Conversational AI, Natural Language Processing,
    Deep learning
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Dialogue systems (or chatbots) are playing a bigger role in the world. People
    may still have a stereotype that chatbots are those rigid agents in their phone
    calls to a bank. However, thanks to the revival of artificial intelligence, the
    modern chatbots can converse with rich topics ranging from your birthday party
    to a speech given by Biden, and, if you want, they can even book a place for your
    party or play the speech video. At present, dialogue systems are one of the hot
    topics in NLP and are highly demanded in industry and daily life. The market size
    of chatbot is projected to grow from $2.6 billion in 2021 to $9.4 billion by 2024
    at a compound annual growth rate (CAGR) of 29.7% ²²2Statistic source: [https://markets.businessinsider.com](https://markets.businessinsider.com)
    and 80% of businesses are expected to be equipped with chatbot automation by the
    end of 2021 ³³3Statistic source: [https://outgrow.co](https://outgrow.co).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Dialogue systems perform chit-chat with human or serve as an assistant via
    conversations. By their applications, dialogue systems are commonly divided into
    two categories: task-oriented dialogue systems (TOD) and open-domain dialogue
    systems (OOD). Task-oriented dialogue systems solve specific problems in a certain
    domain such as movie ticket booking, restaurant table reserving, etc. Instead
    of focusing on task completion, open-domain dialogue systems aim to chat with
    users without the task and domain restrictions (Ritter et al., [2011](#bib.bib300)),
    which are usually fully data-driven. Both task-oriented and open-domain dialogue
    systems can be seen as a mapping $\varphi$ from user message $U=\{\mathrm{\mathbf{u}}^{(1)},\mathrm{\mathbf{u}}^{(2)},...,\mathrm{\mathbf{u}}^{(i)}\}$
    to agent response $R=\{\mathrm{\mathbf{r}}^{(1)},\mathrm{\mathbf{r}}^{(2)},...,\mathrm{\mathbf{r}}^{(j)}\}$:
    $R=\varphi(U)$, where $\mathrm{\mathbf{u}}^{(i)}$ and $\mathrm{\mathbf{r}}^{(j)}$
    denote the $i$th token of the user message and the $j$th token of the agent response
    respectively. In many open-domain and task-oriented dialogue systems, this mapping
    also considers a source of external knowledge/database $K$ as input: $R=\varphi(U,K)$.
    Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey") presents examples of inputs and
    outputs of task-oriented and open-domain dialogue systems. More specific details
    and works will be discussed in Section [3](#S3 "3 Task-oriented Dialogue Systems
    ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey")
    and [4](#S4 "4 Open-Domain Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Examples of inputs and outputs of task-oriented and open-domain dialogue
    systems in datasets. Some datasets provide external knowledge annotations for
    each dialogue pair, e.g., in task-oriented dialogue systems, the external knowledge
    can be retrieved from restaurant databases; in open-domain dialogue systems, it
    can be retrieved from commonsense knowledge graphs (KG).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Category | User message ($U$) | Agent response ($R$) | External Knowledge
    ($K$) |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Task-oriented | I need to find a nice restaurant in Madrid that serves expensive
    Thai food. | There is a restaurant called Bangkok City locating at 9 Red Ave.
    | restaurant database |'
  prefs: []
  type: TYPE_TB
- en: '| Open-domain | I love the grilled fish so much! | Yeah. it’s a famous Chinese
    dish. | commonsense KG |'
  prefs: []
  type: TYPE_TB
- en: 'Traditional task-oriented dialogue systems are organized in a pipeline structure
    and consist of four functional modules: Natural Language Understanding, Dialogue
    State Tracking, Policy Learning, and Natural Language Generation, which will be
    discussed in detail in Section [3](#S3 "3 Task-oriented Dialogue Systems ‣ Recent
    Advances in Deep Learning Based Dialogue Systems: A Systematic Survey"). Many
    state-of-the-art works design end-to-end task-oriented dialogue systems to achieve
    better optimization compared with pipeline methods. Open-domain dialogue systems
    are generally divided into three categories: generative systems, retrieval-based
    systems, and ensemble systems. Generative systems apply sequence-to-sequence models
    (see Section [2.2.5](#S2.SS2.SSS5 "2.2.5 Vanilla Sequence-to-sequence Models (Encoder-decoder
    Models) ‣ 2.2 Recurrent Neural Networks and Vanilla Sequence-to-sequence Models
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey")) to map the user message and dialogue
    history into a response sequence that may not appear in the training corpus. By
    contrast, retrieval-based systems try to select a pre-existing response from a
    certain response set. Ensemble systems combine generative methods and retrieval-based
    methods in two ways: retrieved responses can be compared with generated responses
    to choose the best among them; generative models can also be used to refine the
    retrieved responses (Zhu et al., [2018](#bib.bib466); Song et al., [2016](#bib.bib337);
    Qiu et al., [2017](#bib.bib284); Serban et al., [2017b](#bib.bib314)). Generative
    systems can produce flexible and dialogue context-related responses while sometimes
    they lack coherence ⁴⁴4The quality of being logical and consistent not only between
    words/subwords but also between responses of different timesteps. and tend to
    make dull responses (Serban et al., [2016](#bib.bib312); Vinyals and Le, [2015](#bib.bib379);
    Sordoni et al., [2015b](#bib.bib340)). Retrieval-based systems select responses
    from human response sets and thus are able to achieve better coherence in surface-level
    language. However, retrieval systems are restricted by the finiteness of the response
    sets and sometimes the responses retrieved show a weak correlation with the dialogue
    context (Zhu et al., [2018](#bib.bib466)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/183803d09e02867efd0cf03a24d4a201.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The overall diagram of this article'
  prefs: []
  type: TYPE_NORMAL
- en: For dialogue systems, existing surveys (Arora et al., [2013](#bib.bib7); Wang
    and Yuan, [2016](#bib.bib389); Mallios and Bourbakis, [2016](#bib.bib240); Chen
    et al., [2017a](#bib.bib39); Gao et al., [2018](#bib.bib98)) are either outdated
    or not comprehensive. Some definitions in these papers are no longer being used
    at present, and a lot of new works and topics are not covered. In addition, most
    of them lack a multi-angle analysis. Thus, in this survey, we comprehensively
    review high-quality works in recent years with a focus on deep learning-based
    approaches and provide insight into state-of-the-art research from both model
    angle and system angle. Moreover, this survey updates the definitions/names according
    to state-of-the-art research. E.g., we name "open-domain dialogue systems" instead
    of "chit-chat dialogue systems" because most of the articles (roughly 70% according
    to our survey) name them as the prior one. We also extensively cover the diverse
    hot topics in dialogue systems and extend some new topics that are popular in
    current research community (such as Domain Adaptation, Dialogue State Tracking
    Efficiency, End-to-end methods for task-oriented dialogue systems; Controllable
    Generation, Interactive Training, and Visual Dialogue for open-domain dialogue
    systems).
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional dialogue systems are mostly rule-based (Arora et al., [2013](#bib.bib7))
    and non-neural machine learning based systems. Rule-based systems are easy to
    implement and can respond naturally, which contributed to their popularity in
    earlier industry products. However, the dialogue flows of these systems are predetermined,
    which keeps the applications of the dialogue systems within certain scenarios.
    Non-neural machine learning based systems usually perform template filling to
    manage certain tasks. These systems are more flexible compared with rule-based
    systems because the dialogue flows are not predetermined. However, they cannot
    achieve high F1 scores (Powers, [2020](#bib.bib276)) in template filling⁵⁵5Template
    filling is an efficient approach to extract and structure complex information
    from text to fill in a pre-defined template. They are mostly used in task-oriented
    dialogue systems. and are also restricted in application scenarios and response
    diversity because of the fixed templates. Most if not all state-of-the-art dialogue
    systems are deep learning-based systems (neural systems). The rapid growth of
    deep learning improves the performance of dialogue systems (Chen et al., [2017a](#bib.bib39)).
    Deep learning can be viewed as representation learning with multilayer neural
    networks. Deep learning architectures are widely used in dialogue systems and
    their subtasks. Section [2](#S2 "2 Neural Models in Dialogue Systems ‣ Recent
    Advances in Deep Learning Based Dialogue Systems: A Systematic Survey") discusses
    various popular deep learning architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: Apart from dialogue systems, there are also many dialogue-related tasks in NLP,
    including but not limited to question answering, reading comprehension, dialogue
    disentanglement, visual dialogue, visual question answering, dialogue reasoning,
    conversational semantic parsing, dialogue relation extraction, dialogue sentiment
    analysis, hate speech detection, MISC detection, etc. In this survey, we also
    touch on some works tackling these dialogue-related tasks, since the design of
    dialogue systems can benefit from advances in these related areas.
  prefs: []
  type: TYPE_NORMAL
- en: 'We produced a diagram for this article to help readers familiarize the overall
    structure (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Recent Advances in Deep
    Learning Based Dialogue Systems: A Systematic Survey")). In this survey, Section [1](#S1
    "1 Introduction ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic
    Survey") briefly introduces dialogue systems and deep learning; Section [2](#S2
    "2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey") discusses the neural models popular in
    modern dialogue systems and the related work; Section [3](#S3 "3 Task-oriented
    Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems: A
    Systematic Survey") introduces the principles and related work of task-oriented
    dialogue systems and discusses the research challenges and hot topics; Section [4](#S4
    "4 Open-Domain Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey") briefly introduces the three kinds of systems and
    then focuses on hot topics in open-domain dialogue systems; Section [5](#S5 "5
    Evaluation Approaches ‣ Recent Advances in Deep Learning Based Dialogue Systems:
    A Systematic Survey") reviews the main evaluation methods for dialogue systems;
    Section [6](#S6 "6 Datasets ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey") comprehensively summarizes the datasets commonly
    used for dialogue systems; finally, Section [7](#S7 "7 Conclusions and Trends
    ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey")
    concludes the paper and provides some insight on research trends.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Neural Models in Dialogue Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we introduce neural models that are popular in state-of-the-art
    dialogue systems and related subtasks. We also discuss the applications of these
    models or their variants in modern dialogue systems research to provide readers
    with a picture from the model’s perspective. This will help researchers acquaint
    these models and see how they are applied in state-of-the-art frameworks, which
    is rather helpful when designing a new dialogue system. The models discussed include:
    Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Vanilla
    Sequence-to-sequence Models, Hierarchical Recurrent Encoder-Decoder (HRED), Memory
    Networks, Attention Networks, Transformer, Pointer Net and CopyNet, Deep Reinforcement
    Learning models, Generative Adversarial Networks (GANs), Knowledge Graph Augmented
    Neural Networks. We start from some classical models (e.g., CNNs and RNNs), and
    readers who are familiar with their principles and corresponding applications
    in dialogue systems can choose to read selectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Convolutional Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Deep neural networks have been considered as one of the most powerful models.
    ‘Deep’ refers to the fact that they are multilayer, which extracts features by
    stacking feed-forward layers. Feed-forward layers can be defined as: $y=\sigma(Wx+b)$.
    Where the $\sigma$ is an activation function; $W$ and $b$ are trainable parameters.
    The feed-forward layers are powerful due to the activation function, which makes
    the otherwise linear operation, non-linear. Whereas there exist some problems
    when using feed-forward layers. Firstly, the operations of feed-forward layers
    or multilayer neural networks are just template matching, where they do not consider
    the specific structure of data. Furthermore, the fully connected mechanism of
    traditional multilayer neural networks causes an explosion in the number of parameters
    and thus leads to generalization problems. LeCun et al. ([1998](#bib.bib182))
    proposed LeNet-5, an early CNN. The invention of CNNs mitigates the above problems
    to some extent.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0bc26bb5dea6d2ef981db472f8301895.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: A CNN architecture for text classification (Zhang and Wallace, [2017](#bib.bib450))'
  prefs: []
  type: TYPE_NORMAL
- en: 'CNNs (Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Convolutional Neural Networks ‣ 2 Neural
    Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems:
    A Systematic Survey")) usually consist of convolutional layers, pooling layers
    and feed-forward layers. Convolutional layers apply convolution kernels to perform
    the convolution operation:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $G(m,n)=(f*h)(m,n)=\sum_{j}\sum_{k}h(j,k)f(m-j,n-k)$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: Where $m$ and $n$ are respectively the indexes of rows and columns of the result
    matrix. $f$ denotes the input matrix and $h$ denotes the convolutional kernel.
    The pooling layers perform down-sampling on the result of convolutional layers
    to get a higher level of features and the feed-forward layers map them into a
    probability distribution to predict class scores.
  prefs: []
  type: TYPE_NORMAL
- en: A sliding window feature enables convolution layers to capture local features
    and the pooling layers can produce hierarchical features. These two mechanisms
    give CNNs the local perception and global perception ability, helping to capture
    some specific inner structures of data. The parameter sharing mechanism eases
    the parameter explosion problem and overfitting problem because the reduction
    of trainable parameters leads to less model complexity, improving the generalization
    ability.
  prefs: []
  type: TYPE_NORMAL
- en: Due to these good properties, CNNs have been widely applied in many works. Among
    them, the Computer Vision tasks benefit the most for that the Spatio-temporal
    data structures of images or videos are perfectly captured by CNNs. For more detailed
    mechanism illustrations and other variants of CNNs, readers can refer to these
    representative algorithm papers or surveys: (Krizhevsky et al., [2012](#bib.bib173);
    Zeiler and Fergus, [2014](#bib.bib444); Simonyan and Zisserman, [2014](#bib.bib328);
    Szegedy et al., [2015](#bib.bib355); He et al., [2016](#bib.bib126); Aloysius
    and Geetha, [2017](#bib.bib5); Rawat and Wang, [2017](#bib.bib295)). In this survey,
    we focus on dialogue systems.
  prefs: []
  type: TYPE_NORMAL
- en: Recent years have seen a dramatic increase in applications of CNNs in NLP. Many
    tasks take words as basic units. However, phrases, sentences, or even paragraphs
    are also useful to semantic representations. As a result, CNNs are an ideal tool
    for the hierarchical modeling of language (Conneau et al., [2016](#bib.bib57)).
  prefs: []
  type: TYPE_NORMAL
- en: CNNs are good textual feature extractors, but they may not be ideal sequential
    encoders. Some dialogue systems (Qiu et al., [2019](#bib.bib282); Bi et al., [2019](#bib.bib22);
    Ma et al., [2020a](#bib.bib235)) directly used CNNs as the encoder of utterances
    or knowledge, but most of the state-of-the-art dialogue systems such as Feng et al.
    ([2019](#bib.bib86)); Wu et al. ([2016](#bib.bib418)); Tao et al. ([2019](#bib.bib364));
    Wang et al. ([2019b](#bib.bib390)); Chauhan et al. ([2019](#bib.bib38)); Feldman
    and El-Yaniv ([2019](#bib.bib85)); Chen et al. ([2019c](#bib.bib45)); Lu et al.
    ([2019b](#bib.bib231)) and Coope et al. ([2020](#bib.bib58)) chose to use CNNs
    as a hierarchical feature extractor after encoding the text information, instead
    of directly applying them as encoders. This is due to the fixed input length and
    limited convolution span of CNNs. Generally, there are two main situations where
    CNNs are used to process encoded information in dialogue systems. The first situation
    is applying CNNs to extract features directly based on the feature vectors from
    the encoder (Wang et al., [2019b](#bib.bib390); Chauhan et al., [2019](#bib.bib38);
    Feldman and El-Yaniv, [2019](#bib.bib85); Chen et al., [2019c](#bib.bib45)) and Coope
    et al. ([2020](#bib.bib58)). Within the works above, Feldman and El-Yaniv ([2019](#bib.bib85))
    extracted features from character-level embeddings, illustrating the hierarchical
    extraction capability of CNNs. Another situation in which CNNs are used is extracting
    feature maps in response retrieval tasks. Some works built retrieval-based dialogue
    systems (Wu et al., [2016](#bib.bib418); Feng et al., [2019](#bib.bib86); Tao
    et al., [2019](#bib.bib364); Lu et al., [2019b](#bib.bib231)). They used separate
    encoders to encode dialogue context and candidate responses and then used a CNN
    as an extractor of the similarity matrix calculated from the encoded dialogue
    context and candidate responses. Their experiments showed that this method can
    achieve good performance in response retrieval tasks.
  prefs: []
  type: TYPE_NORMAL
- en: The main reason why more recent works do not choose CNNs as dialogue encoders
    is that they fail to extract the information across temporal sequence steps continuously
    and flexibly (Krizhevsky et al., [2012](#bib.bib173)). Some models introduced
    later do not process data points independently, which are desirable models for
    encoders.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Recurrent Neural Networks and Vanilla Sequence-to-sequence Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: NLP tasks including dialogue-related tasks try to process and analyze sequential
    language data points. Even though standard neural networks, as well as CNNs, are
    powerful learning models, they have two main limitations (Lipton et al., [2015](#bib.bib218)).
    One is that they assume the data points are independent of each other. While it
    is reasonable if the data points are produced independently, essential information
    can be missed when processing interrelated data points (e.g., text, audio, video).
    Additionally, their inputs are usually of fixed length, which is a limitation
    when processing sequential data varying in length. Thus, a sequential model being
    able to represent the sequential information flow is desirable.
  prefs: []
  type: TYPE_NORMAL
- en: Markov models like Hidden Markov Models (HMMs) are traditional sequential models,
    but due to the time complexity of the inference algorithm (Viterbi, [1967](#bib.bib380))
    and because the size of transition matrix grows significantly with the increase
    of the discrete state space, in practice they are not applicable in dealing with
    problems involving large possible hidden states. The property that the hidden
    states of Markov models are only affected by the immediate hidden states further
    limits the power of this model.
  prefs: []
  type: TYPE_NORMAL
- en: RNN models are not proposed recently, but they greatly solve the above problems
    and some variants can amazingly achieve state-of-the-art performance in dialogue-related
    tasks as well as many other NLP tasks. The inductive bias of recurrent models
    is non-replaceable in many scenarios, and many up-to-date models incorporate the
    recurrence.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1 Jordan-Type and Elman-Type RNNs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In 1982, Hopfield introduced an early family of RNNs to solve pattern recognition
    tasks (Hopfield, [1982](#bib.bib140)). Jordan ([1986](#bib.bib159)) and Elman
    ([1990](#bib.bib80)) introduced two kinds of RNN architectures respectively. Generally,
    modern RNNs can be classified into Jordan-type RNNs and Elman-type RNNs.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/129d8bcf18fd55212511419a63d52492.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Jordan-type RNNs
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8693660674db8944063456afc2f3cf42.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Elman-type RNNs
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Graphical models of two basic types of RNNs'
  prefs: []
  type: TYPE_NORMAL
- en: 'The Jordan-type RNNs are shown in Figure [3(a)](#S2.F3.sf1 "In Figure 3 ‣ 2.2.1
    Jordan-Type and Elman-Type RNNs ‣ 2.2 Recurrent Neural Networks and Vanilla Sequence-to-sequence
    Models ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey"). $x_{t}$, $h_{t}$, and $y_{t}$ are
    the inputs, hidden state, and output of time step $t$, respectively. $W_{h}$,
    $W_{y}$ and $U_{h}$ are weight matrixes. Each update of hidden state is decided
    by the current input and the output of last time step while each output is decided
    by current hidden state. Thus the hidden state and output of time step $t$ can
    be calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h_{t}=\sigma_{h}(W_{h}x_{t}+U_{h}y_{t-1}+b_{h})$ |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $y_{t}=\sigma_{y}(W_{y}h_{t}+b_{y})$ |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: Where $b_{h}$ and $b_{y}$ are biases. $\sigma_{h}$ and $\sigma_{y}$ are activation
    functions.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Elman-type RNNs are shown in Figure [3(b)](#S2.F3.sf2 "In Figure 3 ‣ 2.2.1
    Jordan-Type and Elman-Type RNNs ‣ 2.2 Recurrent Neural Networks and Vanilla Sequence-to-sequence
    Models ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey"). The difference is that each hidden
    state is decided by the current input and the hidden state of last time step.
    Thus the hidden state and output of time step $t$ can be calculated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h_{t}=\sigma_{h}(W_{h}x_{t}+U_{h}h_{t-1}+b_{h})$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $y_{t}=\sigma_{y}(W_{y}h_{t}+b_{y})$ |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: Simple RNNs can model long-term dependencies theoretically. But in practical
    training, long-range dependencies are difficult to learn (Bengio et al., [1994](#bib.bib20);
    Hochreiter et al., [2001](#bib.bib138)). When backpropagating errors over many
    time steps, simple RNNs suffer from problems known as gradient vanishing and gradient
    explosion (Hochreiter and Schmidhuber, [1997](#bib.bib137)). Some solutions were
    proposed to solve these problems (Williams and Zipser, [1989](#bib.bib410); Pascanu
    et al., [2013](#bib.bib271)), which led to the inventions of some variants of
    traditional recurrent networks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2 LSTM
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Hochreiter and Schmidhuber ([1997](#bib.bib137)) introduced gate mechanisms
    in LSTM mainly to address the gradient vanishing problem. Input gate, forget gate
    and output gate were introduced to decide how much information from new inputs
    and past memories should be reserved. The model can be described by the following
    equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{h}^{(t)}=tanh\left(W^{\hat{h}x}x^{(t)}+W^{\hat{h}h}h^{(t-1)}+b_{\hat{h}}\right)$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $i^{(t)}=\sigma\left(W^{ix}x^{(t)}+W^{ih}h^{(t-1)}+b_{i}\right)$ |  |
    (7) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $f^{(t)}=\sigma\left(W^{fx}x^{(t)}+W^{fh}h^{(t-1)}+b_{f}\right)$ |  |
    (8) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $o^{(t)}=\sigma\left(W^{ox}x^{(t)}+W^{oh}h^{(t-1)}+b_{o}\right)$ |  |
    (9) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $s^{(t)}=\hat{h}^{(t)}\odot i^{(t)}+s^{(t-1)}\odot f^{(t)}$ |  | (10)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | $h^{(t)}=tanh(s^{(t)})\odot o^{(t)}$ |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: Where $t$ represents time step $t$. $i$, $f$ and $o$ are gates, denoting input
    gate, forget gate and output gate respectively. $x$, $\hat{h}$, $s$ and $h$ are
    input, short-term memory, long-term memory and output respectively. $b$ is bias
    and $W$ is weight matrix. $\odot$ denotes element-wise multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: The intuition of the term “Long Short-Term Memory" is that the proposed model
    applies both long-term and short-term memory vectors to encode the sequential
    data, and uses gate mechanisms to control the information flow. The performance
    of LSTM is impressive since that it achieved state-of-the-art results in many
    NLP tasks as a backbone model although this model was proposed in 1997.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3 GRU
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Inspired by the gating mechanism, Cho et al. ([2014b](#bib.bib52)) proposed
    Gated Recurrent Unit (GRU), which can be modeled by the equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $z^{(t)}=\sigma\left(W^{z}x^{(t)}+U^{z}h^{(t-1)}+b_{z}\right)$ |  | (12)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | $r^{(t)}=\sigma\left(W^{r}x^{(t)}+U^{r}h^{(t-1)}+b_{r}\right)$ |  | (13)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\hat{h}^{(t)}=tanh\left(W^{h}x^{(t)}+U^{h}(r^{(t)}\odot h^{(t-1)})+b_{h}\right)$
    |  | (14) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $h^{(t)}=(1-z^{(t)})\odot h^{(t-1)}+z^{(t)}\odot\hat{h}^{(t)}$ |  | (15)
    |'
  prefs: []
  type: TYPE_TB
- en: Where $t$ represents time step $t$. $z$ and $r$ are gates, denoting update gate
    and reset gate respectively. $x$, $\hat{h}$ and $h$ are input, candidate activation
    vector and output respectively. $b$ is bias while $W$ and $U$ are weight matrixes.
    $\odot$ denotes element-wise multiplication.
  prefs: []
  type: TYPE_NORMAL
- en: LSTM and GRU, as two types of gating units, are very similar to each other (Chung
    et al., [2014](#bib.bib54)). The most prominent common point between them is that
    from time step $t$ to time step $t+1$, an additive component is introduced to
    update the state whereas simple RNNs always replace the activation. Both LSTM
    and GRU keep certain old components and mix them with new contents. This property
    enables the units to remember the information of history steps farther back and,
    more importantly, avoid gradient vanishing problems when backpropagating the error.
  prefs: []
  type: TYPE_NORMAL
- en: There also exist several differences between them. LSTM exposes its memory content
    under the control of the output gate, while the same content in GRU is in an uncontrolled
    manner. Additionally, different from LSTM, GRU does not independently gate the
    amount of new memory content being added. And if looking from experimental perspective,
    GRU has fewer parameters, which contributes to its faster convergence and better
    generalization ability. It has also been shown that GRU can achieve better performance
    in smaller datasets (Chung et al., [2014](#bib.bib54)). However, Gruber and Jockisch
    ([2020](#bib.bib113)) showed that LSTM cells exhibited consistently better performance
    in a large-scale analysis of Neural Machine Translation.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.4 Bidirectional Recurrent Neural Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In sequence learning, not only the past information is essential to the model
    inference, the future information should also be considered to achieve a better
    inference ability. Schuster and Paliwal ([1997](#bib.bib310)) proposed the bi-directional
    recurrent neural networks (BRNNs), which had two kinds of hidden layers: the first
    encoded information from past time steps while the second encoded information
    in a flipped direction. The model can be described using the equations:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $h^{(t)}=\sigma\left(W^{hx}x^{(t)}+W^{hh}h^{(t-1)}+b_{h}\right)$ |  |
    (16) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $z^{(t)}=\sigma\left(W^{zx}x^{(t)}+W^{zz}z^{(t+1)}+b_{z}\right)$ |  |
    (17) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\hat{y}^{(t)}=softmax\left(W^{yh}h^{(t)}+W^{yz}z^{(t)}+b_{y}\right)$
    |  | (18) |'
  prefs: []
  type: TYPE_TB
- en: Where $h$ and $z$ are the two hidden layers. Other variables are defined in
    the same way as in the case of LSTMs and GRUs.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.5 Vanilla Sequence-to-sequence Models (Encoder-decoder Models)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Sutskever et al. ([2014](#bib.bib352)) first proposed the sequence-to-sequence
    model to solve the machine translation tasks. The sequence-to-sequence model aimed
    to map an input sequence to an output sequence by first using an encoder to map
    the input sequence into an intermediate vector and a decoder further generated
    the output based on the intermediate vector and history generated by the decoder.
    The equations below illustrate the encoder-decoder model:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Encoder:h_{t}=E(h_{t-1},x_{t})$ |  | (19) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $Decoder:y_{t}=D(h_{t},y_{t-1})$ |  | (20) |'
  prefs: []
  type: TYPE_TB
- en: Where $t$ is the time step, $h$ is the hidden vector and $y$ is the output vector.
    $E$ and $D$ are the sequential cells used by the encoder and decoder respectively.
    The last hidden state of the encoder is the intermediate vector, and this vector
    is usually used to initialize the first hidden state of the decoder. At encoding
    time, each hidden state is decided by the hidden state of the previous time step
    and the input at the current time step, while at decoding time, each hidden state
    is decided by the current hidden state and the output of the previous time step.
  prefs: []
  type: TYPE_NORMAL
- en: This model is powerful because it is not restricted to fixed-length inputs and
    outputs. Instead, the length of the source sequence and target sequence can differ.
    Based on this model, many more advanced sequence-to-sequence models have been
    developed, which will be discussed in this and subsequent sections.
  prefs: []
  type: TYPE_NORMAL
- en: RNNs play an essential role in neural dialogue systems for their strong ability
    to encode sequential text information. RNNs and their variants are found in many
    dialogue systems. Task-oriented systems apply RNNs as encoders of dialogue context,
    dialogue state, knowledge base entries, and domain tags (Moon et al., [2019](#bib.bib257);
    Chen et al., [2019b](#bib.bib44); Wu et al., [2019b](#bib.bib415), [a](#bib.bib413)).
    Open-domain systems apply RNNs as dialogue history encoders (Sankar et al., [2019](#bib.bib304);
    Du and Black, [2019](#bib.bib76); Ji et al., [2020](#bib.bib155); Chen et al.,
    [2020b](#bib.bib46)), among which retrieval-based systems model dialogue history
    and candidate responses together (Zhu et al., [2018](#bib.bib466); Tang et al.,
    [2019](#bib.bib362); Feldman and El-Yaniv, [2019](#bib.bib85); Lu et al., [2019b](#bib.bib231)).
    In knowledge-grounded systems, RNNs are encoders of outside knowledge sources
    (e.g., background, persona, topic, etc.) (Shuster et al., [2019](#bib.bib324);
    Majumder et al., [2020b](#bib.bib239); Chen et al., [2020b](#bib.bib46); Cho and
    May, [2020](#bib.bib50)).
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, as the decoder of sequence-to-sequence models in dialogue systems (Huang
    et al., [2020c](#bib.bib150); Song et al., [2019](#bib.bib338); Liu et al., [2019](#bib.bib222);
    Lin et al., [2019](#bib.bib213)), RNNs usually decode the hidden state of utterance
    sequences by greedy search or beam search (Aubert et al., [1994](#bib.bib11)).
    These decoding mechanisms cause problems like generic responses, which will be
    discussed in later sections.
  prefs: []
  type: TYPE_NORMAL
- en: Some works (Liu et al., [2019](#bib.bib222); Mehri et al., [2019](#bib.bib244);
    Chen et al., [2019c](#bib.bib45); Ma et al., [2020a](#bib.bib235)) combined RNNs
    as a part of dialogue representation models to train dialogue embeddings and further
    improved the performance of dialogue-related tasks. These embedding models were
    trained on dialogue tasks and present more dialogue features. They consistently
    outperformed state-of-the-art contextual representation models (e.g., BERT, ELMo,
    and GPT) in some dialogue tasks when these contextual representation models were
    not fine-tuned for the specific tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Hierarchical Recurrent Encoder-Decoder (HRED)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Hierarchical Recurrent Encoder-Decoder (HRED) is a context-aware sequence-to-sequence
    model. It was first proposed by Sordoni et al. ([2015a](#bib.bib339)) to address
    the context-aware online query suggestion problem. It was designed to be aware
    of history queries and the proposed model can provide rare and high-quality results.
  prefs: []
  type: TYPE_NORMAL
- en: With the popularity of the sequence-to-sequence model, Serban et al. ([2016](#bib.bib312))
    extended HRED to the dialogue domain and built an end-to-end context-aware dialogue
    system. HRED achieved noticeable improvements in dialogue and end-to-end question
    answering. This work attracted even more attention than the original paper for
    that dialogue systems are a perfect setting for the application of HRED. Traditional
    dialogue systems (Ritter et al., [2011](#bib.bib300)) generated responses based
    on the single-turn messages, which sacrificed the information in the dialogue
    history. Sordoni et al. ([2015b](#bib.bib340)) combined dialogue history turns
    with a window size of 3 as the input of a sequence-to-sequence model for response
    generation, which is limited as well for that they encode the dialogue history
    only in token-level. The “turn-by-turn" characteristic of dialogue indicated that
    the turn-level information also matters. The HRED learned both token-level and
    turn-level representation, thus exhibiting promising dialogue context awareness.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1ace5d3a7d1f279b2018e6f3c1bad690.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The HRED model in a dialogue setting (Serban et al., [2016](#bib.bib312))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [4](#S2.F4 "Figure 4 ‣ 2.3 Hierarchical Recurrent Encoder-Decoder (HRED)
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey") represents the HRED in a dialogue setting.
    HRED models the token-level and turn-level sequences hierarchically with two levels
    of RNNs: a token-level RNN consisting of an encoder and a decoder, and a turn-level
    context RNN. The encoder RNN encodes the utterance of each turn token by token
    into a hidden state. This hidden state is then taken as the input of the context
    RNN at each turn-level time step. Thus the turn-level context RNN iteratively
    keeps track of the history utterances. The hidden state of context RNN at turn
    $t$ represents a summary of the utterances up to turn $t$ and is used to initialize
    the first hidden state of decoder RNN, which is similar to a standard decoder
    in sequence-to-sequence models (Sutskever et al., [2014](#bib.bib352)). All of
    the three RNNs described above apply GRU cells as the recurrent unit, and the
    parameters of encoder and decoder are shared for each utterance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Serban et al. ([2017a](#bib.bib313)) further proposed Latent Variable Hierarchical
    Recurrent Encoder-Decoder (VHRED) to model complex dependencies between sequences.
    Based on HRED, VHRED combined a latent variable into the decoder and turned the
    decoding process into a two-step generation process: sampling a latent variable
    at the first step and then generating the response conditionally. VHRED was trained
    with a variational lower bound on the log-likelihood and exhibited promising improvement
    in diversity, length, and quality of generated responses.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Many recent works in dialogue-related tasks apply HRED-based frameworks to
    capture hierarchical dialogue features. Zhang et al. ([2019a](#bib.bib446)) argued
    that standard HRED processed all contexts in dialogue history indiscriminately.
    Inspired by the architecture of Transformer (Vaswani et al., [2017](#bib.bib377)),
    they proposed ReCoSa, a self-attention-based hierarchical model. It first applied
    LSTM to encode token-level information into context hidden vectors and then calculated
    the self-attention for both the context vectors and masked response vectors. At
    the decoding stage, the encoder-decoder attention was calculated to facilitate
    the decoding. Shen et al. ([2019](#bib.bib321)) proposed a hierarchical model
    consisting of 3 hierarchies: the discourse-level which captures the global knowledge,
    the pair-level which captured the topic information in utterance pairs, and the
    utterance level which captured the content information. Such a multi-hierarchy
    structure contributed to its higher quality responses in terms of diversity, coherence,
    and fluency. Chauhan et al. ([2019](#bib.bib38)) applied HRED and VGG-19 as a
    multimodal HRED (MHRED). The HRED encoded hierarchical dialogue context while
    VGG-19 extracted visual features for all images in the corresponding turn. With
    the addition of a position-aware attention mechanism, the model showed more diverse
    and accurate responses in a visually grounded setting. Mehri et al. ([2019](#bib.bib244))
    learned dialogue context representations via four sub-tasks, three of which (next-utterance
    generation, masked-utterance retrieval, and inconsistency identification) made
    uses of HRED as the context encoder, and good performance was achieved. Cao et al.
    ([2019](#bib.bib35)) used HRED to encode the dialogue history between therapists
    and patients to categorize therapist and client MI behavioral codes and predict
    future codes. Qiu et al. ([2020](#bib.bib283)) applied an LSTM-based VHRED to
    address the two-agent and multi-agent dialogue structure induction problem in
    an unsupervised fashion. On top of that, they applied a Conditional Random Field
    model in two-agent dialogues and a non-projective dependency tree in multi-agent
    dialogues, both of them achieving better performance in dialogue structure modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 Memory Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Memory is a crucial component when addressing problems regarding past experiences
    or outside knowledge sources. The hippocampus of human brains and the hard disk
    of computers are the components that humans and computers depend on for reading
    and writing memories. Traditional models rarely have a memory component, thus
    lacking the ability of knowledge reusing and reasoning. RNNs iteratively pass
    history information across time steps, which, to some extent, can be viewed as
    a memory model. However, even for LSTM, which is a powerful variant of RNN equipped
    with a long-term and short-term memory, the memory module is too small and facts
    are not explicitly discriminated, thus not being able to compress specific knowledge
    facts and reuse them in tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Weston et al. ([2014](#bib.bib402)) proposed memory networks, a model that
    is endowed with a memory component. As described in their work, a memory network
    has five modules: a memory module which stores the representations of memory facts;
    an ‘I’ module which maps the input memory facts into embedded representations;
    a ‘G’ module which decides the update of the memory module; an ‘O’ module which
    generates the output conditioned on the input representation and memory representation;
    an ‘R’ module which organizes the final response based on the output of ‘O’ module.
    This model needs a strong supervision signal for each module and thus is not practical
    to train in an end-to-end fashion.'
  prefs: []
  type: TYPE_NORMAL
- en: Sukhbaatar et al. ([2015](#bib.bib349)) extended their prior work to an end-to-end
    memory network, which was commonly accepted as a standard memory network being
    easy to train and apply.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8d1b3c5df55f53ec6fe5135a7a769aab.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The structure of end-to-end memory networks (Sukhbaatar et al., [2015](#bib.bib349))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [5](#S2.F5 "Figure 5 ‣ 2.4 Memory Networks ‣ 2 Neural Models in Dialogue
    Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic
    Survey") represents the proposed end-to-end memory networks. Its architecture
    consists of three stages: weight calculation, memory selection, and final prediction.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Weight calculation. The model first converts the input memory set $\{x_{i}\}$
    into memory representations $\{m_{i}\}$ using a representation model $A$. Then
    it maps the input query into its embedding space using another representation
    model $B$, obtaining an embedding vector $u$. The final weights are calculated
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p_{i}=Softmax(u^{T}m_{i})$ |  | (21) |'
  prefs: []
  type: TYPE_TB
- en: Where $p_{i}$ is the weight corresponding to each input memory $x_{i}$ conditioned
    on the query.
  prefs: []
  type: TYPE_NORMAL
- en: 'Memory selection. Before generating the final prediction, a selected memory
    vector is generated by first encoding the input memory $x_{i}$ into an embedded
    vector $c_{i}$ using another representation model $C$, then calculating the weighted
    sum over the $\{c_{i}\}$ using the weights calculated in the previous stage:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $o=\sum_{i}p_{i}c_{i}$ |  | (22) |'
  prefs: []
  type: TYPE_TB
- en: Where o represents the selected memory vector. This vector cannot be found in
    memory representations. The soft memory selection facilitates differentiability
    in gradient computing, which makes the whole model end-to-end trainable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Final prediction. The final prediction is obtained by mapping the sum vector
    of the selected memory $o$ and the embedded query $u$ into a probability vector
    $\hat{a}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{\alpha}=Softmax(W(o+u))$ |  | (23) |'
  prefs: []
  type: TYPE_TB
- en: Many dialogue-related works incorporate memory networks into their framework,
    especially for tasks involving an external knowledge base like task-oriented dialogue
    systems, knowledge-grounded dialogue systems, and QA.
  prefs: []
  type: TYPE_NORMAL
- en: Memory networks for task-oriented dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Chen et al. ([2019c](#bib.bib45)) argued that state-of-the-art task-oriented
    dialogue systems tended to combine dialogue history and knowledge base entries
    in a single memory module, which influenced the response quality. They proposed
    a task-oriented system that consists of three memory modules: two long-term memory
    modules storing the dialogue history and the knowledge base respectively; a working
    memory module that memorizes two distributions and controls the final word prediction.
    He et al. ([2020a](#bib.bib128)) trained a task-oriented dialogue system with
    a “Two-teacher-one-student" framework to improve the knowledge retrieval and response
    quality of their memory networks. They first trained two teacher networks using
    reinforcement learning with complementary goal-specific reward functions respectively.
    Then with a GAN framework, they trained two discriminators to teach the student
    memory network to generate responses similar to those of the teachers, transferring
    the expert knowledge from the two teachers to the student. The advantage is that
    this training framework needs only weak supervision and the student network can
    benefit from the complementary targets of teacher networks. Kim et al. ([2019](#bib.bib170))
    solved the dialogue state tracking in task-oriented dialogue systems with a memory
    network that memorized the dialogue states. Different from other works, they did
    not update all dialogue states in the memory module from scratch. Instead, their
    model first predicted which states needed to be updated and then overwrote the
    target states. By selectively overwriting the memory module, they improved the
    efficiency of the dialogue state tracking task. Dai et al. ([2020](#bib.bib61))
    applied the MemN2N (Sukhbaatar et al., [2015](#bib.bib349)) as task-oriented utterance
    encoder, memorizing the existing responses and dialogue history. Then they used
    model-agnostic meta-learning (MAML) (Finn et al., [2017](#bib.bib92)) to train
    the framework to retrieve correct responses in a few-shot fashion.'
  prefs: []
  type: TYPE_NORMAL
- en: Memory networks for open-domain dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Tian et al. ([2019](#bib.bib369)) proposed a knowledge-grounded chit-chat system.
    A memory network was used to store query-response pairs and at the response generation
    stage, the generator produced the response conditioned on both the input query
    and memory pairs. It extracted key-value information from the query-response pairs
    in memory and combined them into token prediction. Xu et al. ([2019](#bib.bib425))
    proposed to use meta-words to generate responses in open-domain systems in a controllable
    way. Meta-words are phrases describing response attributes. Using a goal-tracking
    memory network, they memorized the meta-words and generated responses based on
    the user message while incorporating meta-words at the same time. Gan et al. ([2019](#bib.bib95))
    performed multi-step reasoning conditioned on a dialogue history memory module
    and a visual memory module. Two memory modules recurrently refined the representation
    to perform the next reasoning process. Experimental results illustrated the benefits
    of combining image and dialogue clues to improve the performance of visual dialogue
    systems. Han et al. ([2019](#bib.bib122)) trained a reinforcement learning agent
    to decide which memory vector can be replaced when the memory module is full to
    improve the accuracy and efficiency of the document-grounded question-answering
    task. They solved the scalability problem of memory networks by learning the query-specific
    value corresponding to each memory. Gao et al. ([2020c](#bib.bib102)) solved the
    same problem in a conversational machine reading task. They proposed an Explicit
    Memory Tracker (EMT) to decide whether the provided information in memory is enough
    for final prediction. Furthermore, a coarse-to-fine strategy was applied for the
    agent to make clarification questions to request additional information and refine
    the reasoning.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5 Attention and Transformer
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As introduced in Section [2.2](#S2.SS2 "2.2 Recurrent Neural Networks and Vanilla
    Sequence-to-sequence Models ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances
    in Deep Learning Based Dialogue Systems: A Systematic Survey"), traditional sequence-to-sequence
    models decode the token conditioning on the current hidden state and output vector
    of last time step, which is formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(y_{i}&#124;y_{1},...,y_{i-1},x)=g(y_{i-1},h_{i})$ |  | (24) |'
  prefs: []
  type: TYPE_TB
- en: Where g is a sequential model which maps the input vectors into a probability
    vector.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, such a decoding scheme is limited when the input sentence is long.
    RNNs are not able to encode all information into a fixed-length hidden vector.
    Cho et al. ([2014a](#bib.bib51)) proved via experiments that a sequence-to-sequence
    model performed worse when the input sequence got longer. Also, for the limited-expression
    ability of a fixed-length hidden vector, the performance of the decoding scheme
    in Equation ([24](#S2.E24 "In 2.5 Attention and Transformer ‣ 2 Neural Models
    in Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems:
    A Systematic Survey")) largely depends on the first few steps of decoding, and
    if the decoder fails to have a good start, the whole sequence would be negatively
    affected.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.1 Attention
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4640c9ae734ac0e18a2c70d3b119c417.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The attention model (Bahdanau et al., [2014](#bib.bib12))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Bahdanau et al. ([2014](#bib.bib12)) proposed the attention mechanism in the
    machine translation task. They described the method as “jointly align and translate",
    which illustrated the sequence-to-sequence translation model as an encoder-decoder
    model with attention. At the decoding stage, each decoding state would consider
    which parts of the encoded source sentence are correlated, instead of depending
    only on the immediate prior output token. The output probability distribution
    can be described as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(y_{i}&#124;y_{1},...,y_{i-1},x)=g(y_{i-1},s_{i},c_{i})$ |  | (25) |'
  prefs: []
  type: TYPE_TB
- en: 'Where $i$ denotes the $i^{th}$ time step; $y_{i}$ is the output token, $s_{i}$
    is the decoder hidden state and $c_{i}$ is the weighted source sentence:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $s_{i}=f(s_{i-1},y_{i-1},c_{i})$ |  | (26) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $c_{i}=\sum_{j=1}^{T_{x}}\alpha_{ij}h_{j}$ |  | (27) |'
  prefs: []
  type: TYPE_TB
- en: 'Where $\alpha_{ij}$ is the normalized weight score:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\alpha_{ij}=\frac{exp(e_{ij})}{\sum_{k=1}^{T_{x}}exp(e_{ik})}$ |  | (28)
    |'
  prefs: []
  type: TYPE_TB
- en: '$e_{ij}$ is the similarity score between $s_{i-1}$ and $j^{th}$ encoder hidden
    state $h_{j}$, where the score is predicted by the similarity model $a$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $e_{ij}=a(s_{i-1},h_{j})$ |  | (29) |'
  prefs: []
  type: TYPE_TB
- en: 'Figure [6](#S2.F6 "Figure 6 ‣ 2.5.1 Attention ‣ 2.5 Attention and Transformer
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey") illustrates the attention model, where
    t and T denote time steps of decoder and encoder respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: Memory networks are similar to attention networks in the way they operate, except
    for the choice of the similarity model. In memory networks, the encoded memory
    can be viewed as the encoded source sentence in attention. However, the memory
    model proposed by Sukhbaatar et al. ([2015](#bib.bib349)) chose cosine distance
    as the similarity model while the attention proposed by Bahdanau et al. ([2014](#bib.bib12))
    used a feed-forward network which is trainable together with the whole sequence-to-sequence
    model.
  prefs: []
  type: TYPE_NORMAL
- en: 2.5.2 Transformer
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Before transformers, most works combined attention with recurrent units, except
    for few works such as Parikh et al. ([2016](#bib.bib270)) and Gehring et al. ([2017](#bib.bib103)).
    Recurrent models condition each hidden state on the previous hidden state and
    the current input and are flexible in sequence length. However, due to their sequential
    nature, recurrent models cannot be trained in parallel, which severely undermines
    their potential. Vaswani et al. ([2017](#bib.bib377)) proposed Transformer, which
    entirely utilized attention mechanisms without any recurrent units and deployed
    more parallelization to speed up training. It applied self-attention and encoder-decoder
    attention to achieve local and global dependencies respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [7](#S2.F7 "Figure 7 ‣ 2.5.2 Transformer ‣ 2.5 Attention and Transformer
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey") represents the transformer. The following
    details its key mechanisms.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/16fcebf8315258eecbe42ceccafd7253.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The transformer model (Vaswani et al., [2017](#bib.bib377))'
  prefs: []
  type: TYPE_NORMAL
- en: Encoder-decoder
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The Transformer consists of an encoder and a decoder. The encoder maps the
    input sequence $(x_{1},\ldots,x_{n})$ into continuous hidden states $(z_{1},\ldots,z_{n})$.
    The decoder further generates the output sequence $(y_{1},\ldots,y_{n})$ based
    on the hidden states of the encoder. The probability model of the Transformer
    is in the same form as that of the vanilla sequence-to-sequence model introduced
    in Section [2.2.5](#S2.SS2.SSS5 "2.2.5 Vanilla Sequence-to-sequence Models (Encoder-decoder
    Models) ‣ 2.2 Recurrent Neural Networks and Vanilla Sequence-to-sequence Models
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey"). Vaswani et al. ([2017](#bib.bib377))
    stacked 6 identical encoder layers and 6 identical decoder layers. An encoder
    layer consists of a multi-head attention component and a simple feed-forward network,
    both of which apply residual structure. The structure of a decoder layer is almost
    the same as that of an encoder layer, except for an additional encoder-decoder
    attention layer, which computes the attention between decoder hidden states of
    the current time step and the encoder output vectors. The input of the decoder
    is partially masked to make sure that each prediction is based on the previous
    tokens, avoiding predicting with the presence of future information. Both inputs
    of encoder and decoder use a positional encoding mechanism.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-attention
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For an input sentence $x=(x_{1},\ldots,x_{n})$, each token $x_{i}$ corresponds
    to three vectors: query, key, and value. The self-attention computes the attention
    weight for every token $x_{i}$ against all other tokens in $x$ by multiplying
    the query of $x_{i}$ with the keys of all the remaining tokens one-by-one. For
    parallel computing, the query, key ,and value vectors of all tokens are combined
    into three matrices: Query (Q), Key (K) ,and Value (V). The self-attention of
    an input sentence $x$ is computed by the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Attention(Q,K,V)=softmax(\frac{QK^{T}}{\sqrt{d_{k}}})V$ |  | (30) |'
  prefs: []
  type: TYPE_TB
- en: Where $d_{k}$ is the dimension of queries or keys.
  prefs: []
  type: TYPE_NORMAL
- en: Multi-head attention
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'To jointly consider the information from different subspaces of embedding,
    query, key, and value vectors are mapped into $h$ vectors of identical shapes
    by using different linear transformations, where $h$ denotes the number of heads.
    Attention is computed on each of these vectors in parallel, and the results are
    concatenated and further projected. The multi-head attention can be described
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $MultiHead(Q,K,V)=Concat(head_{1},...,head_{h})W^{O}$ |  | (31) |'
  prefs: []
  type: TYPE_TB
- en: Where $head_{i}=Attention(QW_{i}^{Q},KW_{i}^{K},VW_{i}^{V})$ and $W$ denotes
    the linear transformations.
  prefs: []
  type: TYPE_NORMAL
- en: Positional encoding
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The proposed transformer architecture has no recurrent units, which means that
    the order information of sequence is dismissed. The positional encoding is added
    with input embeddings to provide positional information. The paper chooses cosine
    functions for positional encoding:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $PE_{(pos,2i)}=sin(pos/10000^{2i/d_{model}})$ |  | (32) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $PE_{(pos,2i+1)}=cos(pos/10000^{2i/d_{model}})$ |  | (33) |'
  prefs: []
  type: TYPE_TB
- en: Where $pos$ denotes the position of the target token and $i$ denotes the dimension,
    which means that each dimension of the positional matrix uses a different wavelength
    for encoding.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer-based pretrain models and Transformer variants
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Recently, many transformer-based pretrain models have been developed. Unlike
    Embeddings from Language Model (ELMo) proposed by Peters et al. ([2018](#bib.bib273)),
    which is an LSTM-based contextual embedding model, transformer-based pretrain
    models are more powerful. Two most popular models are GPT-2 ⁶⁶6https://openai.com/blog/better-language-models/
    and BERT (Devlin et al., [2018](#bib.bib70)). GPT-2 and BERT both consist of 12
    transformer blocks and BERT is further improved by making the training bi-directional.
    They are powerful due to their capability of adapting to new tasks after pretraining.
    This property helped achieve significant improvements in many NLP tasks. There
    also evolve many Transformer variants (Zaheer et al., [2020](#bib.bib442); Dai
    et al., [2019](#bib.bib62); Guo et al., [2019](#bib.bib115)), which are designed
    to reduce the model parameters/computational complexity, or improve performance
    of the original Transformer in diverse scenarios. Lin et al. ([2021](#bib.bib212))
    and Tay et al. ([2020](#bib.bib366)) systematically summarize the state-of-the-art
    Transformer variants for academics that are interested.
  prefs: []
  type: TYPE_NORMAL
- en: Attention for dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Attention is a mechanism to catch the importance of different parts in the target
    sequence. Zhu et al. ([2018](#bib.bib466)) applied a two-level attention to generate
    words. Given the user message and candidate responses selected by a retrieval
    system, the generator first computes word-level attention weights, then uses sentence-level
    attention to rescale the weights. This two-level attention helps the generator
    catch different importance given the encoded context. Liu et al. ([2019](#bib.bib222))
    used an attention-based recurrent architecture to generate responses. They designed
    a multi-level encoder-decoder of which the multi-level encoder tries to map raw
    words, low-level clusters, and high-level clusters into hierarchical embedded
    representations while the multi-level decoder leveraged the hierarchical representations
    using attention and then generated responses. At each decoding stage, the model
    calculated two attention weights for the output of the higher-level decoder and
    the hidden state of the current level’s encoder. Chen et al. ([2019b](#bib.bib44))
    computed multi-head self-attention for the outputs of a dialogue act predictor.
    Unlike the transformer, which concatenates the outputs of different heads, they
    passed the outputs directly to the next multi-head layer. The stacked multi-head
    layers then generated the responses with dialogue acts as the input.
  prefs: []
  type: TYPE_NORMAL
- en: Transformers for dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Transformers are powerful sequence-to-sequence models and meanwhile, their encoders
    also serve as good dialogue representation models. Henderson et al. ([2019b](#bib.bib136))
    built a transformer-based response retrieval model for task-oriented dialogue
    systems. A two-channel transformer encoder was designed for encoding user messages
    and responses, both of which were initially presented as unigrams and bigrams.
    A simple cosine distance was then applied to calculate the semantic similarity
    between the user message and the candidate response. Li et al. ([2019d](#bib.bib208))
    built multiple incremental transformer encoders to encode multi-turn conversations
    and their related document knowledge. The encoded utterance and related document
    of the previous turn were treated as a part of the input of the next turn’s transformer
    encoder. The pretrained model was adaptable to multiple domains with only a small
    amount of data from the target domain. Bao et al. ([2019b](#bib.bib17)) used stacked
    transformers for dialogue generation pretraining. Besides the response generation
    task, they also pretrained the model together with a latent act prediction task.
    A latent variable was applied to solve the “one-to-many" problem in response generation.
    The multi-task training scheme improved the performance of the proposed transformer
    pretraining model.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer-based pretrain models for dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Large transformer-based pretrain models are adaptable to many tasks and are
    thus popular in recent works. Golovanov et al. ([2019](#bib.bib107)) used GPT
    as a sequence-to-sequence model to directly generate utterances and compared the
    performances under single- and multi-input settings. Majumder et al. ([2020b](#bib.bib239))
    first used a probability model to retrieve related news corpus and then combined
    the news corpus and dialogue context as input of a GPT-2 generator for response
    generation. They proposed that by using discourse pattern recognition and interrogative
    type prediction as two subtasks for multi-task learning, the dialogue modeling
    could be further improved. Wu et al. ([2019c](#bib.bib417)) used BERT as an encoder
    of context and candidate responses in their goal-based response retrieval system
    while Zhong et al. ([2020](#bib.bib460)) built Co-BERT, a BERT-based response
    selection model, to retrieve empathetic responses given persona-based training
    corpus. Zhao et al. ([2020b](#bib.bib459)) built a knowledge-grounded dialogue
    system in a synthesized fashion. They used both BERT and GPT-2 to perform knowledge
    selection and response generation jointly, where BERT was for knowledge selection
    and GPT-2 generated responses based on dialogue context and the selected knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 2.6 Pointer Net and CopyNet
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2.6.1 Pointer Net
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In some NLP tasks like dialogue systems and question-answering, the agents
    sometimes need to directly quote from the user message. Pointer Net (Oriol et al.,
    [2015](#bib.bib265)) (Figure [8](#S2.F8 "Figure 8 ‣ 2.6.1 Pointer Net ‣ 2.6 Pointer
    Net and CopyNet ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep
    Learning Based Dialogue Systems: A Systematic Survey")) solved the problem of
    directly copying tokens from the input sentence.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6879a5e0268e8d55746d25c3e89cb18a.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Sequence-to-sequence
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f785125339c6d05f709a9fc9001cd772.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Pointer Net
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: (a) Sequence-to-sequence - The RNN (blue) processes the input sequence
    to produce a code vector, which is then used by the probability chain rule and
    another RNN to generate the output sequence (purple). The dimensionality of the
    problem determines the output dimensionality, which remains constant through training
    and inference. (b) Pointer Net - The input sequence is converted to a code (blue)
    by an encoding RNN, which is fed to the generating network (purple). The generating
    network generates a vector at each step that modulates a content-based attention
    process across inputs. The attention mechanism produces a softmax distribution
    with a dictionary size equal to the input length. (Oriol et al., [2015](#bib.bib265))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional sequence-to-sequence models (Sutskever et al., [2014](#bib.bib352);
    Graves et al., [2014](#bib.bib111)) with an encoder-decoder structure map a source
    sentence to a target sentence. Generally, these models first map source sentence
    into hidden state vectors with an encoder, and then predict the output sequence
    based on the hidden states. The sequence prediction is accomplished step-by-step,
    each step predicting one token using greedy search or beam search. The overall
    sequence-to-sequence model can be described by the following probability model:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(C^{P}&#124;P;\theta)=\prod_{i=1}^{m(P)}p(C_{i}&#124;C_{1},...,C_{i-1},P;\theta)$
    |  | (34) |'
  prefs: []
  type: TYPE_TB
- en: Where $(P,C_{p})$ constitutes a training pair, $P$ = $\{P_{1},...,P_{n}\}$ denotes
    the input sequence and $C_{p}$ = $\{C_{1},...,C_{m(p)}\}$ denotes the ground target
    sequence. $\theta$ is a decoder model.
  prefs: []
  type: TYPE_NORMAL
- en: 'The sequence-to-sequence models have the vanilla backbones and attention-based
    backbones. Vanilla models predict the target sequence based only on the last hidden
    state of the encoder and pass it across different decoder time steps. Such a mechanism
    restricts the information received by the decoder at each decoding stage. Attention-based
    models consider all hidden states of the encoder at each decoding step and calculate
    their importance when utilizing them. To compare the mechanism of Pointer Net
    and Attention, we present the equations explained in Section [2.2](#S2.SS2 "2.2
    Recurrent Neural Networks and Vanilla Sequence-to-sequence Models ‣ 2 Neural Models
    in Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems:
    A Systematic Survey") here again. The decoder predicts the token conditioned partially
    on the weighted sum of encoder hidden states $d_{i}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $d_{i}=\sum_{j=1}^{T_{x}}\alpha_{ij}h_{j}$ |  | (35) |'
  prefs: []
  type: TYPE_TB
- en: 'Where $\alpha_{ij}$ is the normalized weight score:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\alpha_{ij}=\frac{exp(e_{ij})}{\sum_{k=1}^{T_{x}}exp(e_{ik})}$ |  | (36)
    |'
  prefs: []
  type: TYPE_TB
- en: '$e_{ij}$ is the similarity score between $s_{i-1}$ and $jth$ encoder hidden
    state $h_{j}$, where the score is predicted by the similarity model $a$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $e_{ij}=a(s_{i-1},h_{j})$ |  | (37) |'
  prefs: []
  type: TYPE_TB
- en: 'At each decoding step, both vanilla and attention-based sequence-to-sequence
    models predict a distribution over a fixed dictionary $X=\{x_{1},...,x_{n}\}$,
    where $x_{i}$ denotes the tokens and $n$ denotes the total count of different
    tokens in the training corpus. However, when copying words from the input sentence,
    we do not need such a large dictionary. Instead, $n$ equals to the number of tokens
    in the input sequence (including repeated ones) and is not fixed since it changes
    according to the length of the input sequence. Pointer Net made a simple change
    to the attention-based sequence-to-sequence models: instead of predicting the
    token distribution based on the weighted sum of encoder hidden states $d_{i}$,
    it directly used the normalized weights $\alpha_{i}$ as predicted distribution:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(C_{i}&#124;C_{1},...,C_{i-1},P)=\alpha_{i}$ |  | (38) |'
  prefs: []
  type: TYPE_TB
- en: Where $\alpha_{i}$ is a set of probability numbers $\{\alpha_{i}^{1},...,\alpha_{i}^{j}\}$
    which represents the probability distribution over the tokens of the input sequence.
    Obviously, the token prediction problem is now transformed into position prediction
    problem, where the model only needs to predict a position in the input sequence.
    This mechanism is like a pointer that points to its target, hence the name “Pointer
    Net".
  prefs: []
  type: TYPE_NORMAL
- en: 2.6.2 CopyNet
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1264b992dafbcc189323d6c259383137.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: The overall architecture of CopyNet (Gu et al., [2016](#bib.bib114))'
  prefs: []
  type: TYPE_NORMAL
- en: 'In real-world applications, simply copying from the source message is not enough.
    Instead, in tasks like dialogue systems and QA, agents also require the ability
    to generate words that are not in the source sentence. CopyNet (Gu et al., [2016](#bib.bib114))
    (Figure [9](#S2.F9 "Figure 9 ‣ 2.6.2 CopyNet ‣ 2.6 Pointer Net and CopyNet ‣ 2
    Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey")) was proposed to incorporate the copy mechanism
    into traditional sequence-to-sequence models. The model decides at each decoding
    stage whether to copy from the source or generate a new token not in the source.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The encoder of CopyNet is the same as that of a traditional sequence-to-sequence
    model, whereas the decoder has some differences compared with a traditional attention-based
    decoder. When predicting the token at time step $t$, it combines the probabilistic
    models of generate-mode and copy-mode:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(y_{t}&#124;s_{t},y_{t-1},c_{t},M)=P_{g}(y_{t}&#124;s_{t},y_{t-1},c_{t},M)+P_{c}(y_{t}&#124;s_{t},y_{t-1},c_{t},M)$
    |  | (39) |'
  prefs: []
  type: TYPE_TB
- en: Where $t$ is the time step. $s_{t}$ is the decoder hidden state and $y_{t}$
    is the predicted token. $c_{t}$ and $M$ represent weighted sum of encoder hidden
    states and encoder hidden states respectively. $g$ and $c$ are generate-mode and
    copy-mode respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Besides, though it still uses $y_{t-1}$ and weighted attention vector $c_{t}$
    to update the decoder hidden state, $y_{t-1}$ is uniquely encoded with both its
    embedding and its location-specific hidden state; also, CopyNet combines attentive
    read and selective read to capture information from the encoder hidden states,
    where the selective read is the same method used in Pointer Net. Different from
    the Neural Turing Machines (Graves et al., [2014](#bib.bib111); Kurach et al.,
    [2015](#bib.bib176)), the CopyNet has a location-based mechanism that enables
    the model to be aware of some specific details in training data in a more subtle
    way.
  prefs: []
  type: TYPE_NORMAL
- en: Copy mechanism is suitable for dialogues involving terminologies or external
    knowledge sources, and it is popular in knowledge-grounded or task-oriented dialogue
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Copy mechanism for knowledge-grounded dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'For knowledge-grounded systems, external documents or dialogues are sources
    to copy from. Lin et al. ([2020a](#bib.bib214)) combined a recurrent knowledge
    interactive decoder with a knowledge-aware pointer network to achieve both knowledge-grounded
    generation and knowledge copy. In the proposed model, they first calculated the
    attention distribution over external knowledge, then used two pointers referring
    to dialogue context and knowledge source respectively to copy out-of-vocabulary
    (OOV) words. Wu et al. ([2020b](#bib.bib416)) applied a multi-class classifier
    to flexibly fuse three distributions: generated words, generated knowledge entities,
    and copied query words. They used Context-Knowledge Fusion and Flexible Mode Fusion
    to perform the knowledge retrieval, response generation, and copying jointly,
    making the generated responses precise, coherent, and knowledge-infused. Ji et al.
    ([2020](#bib.bib155)) proposed a Cross Copy Network to copy from internal utterance
    (dialogue history) and external utterance (similar cases) respectively. They first
    used pretrained language models for similar case retrieval, then combined the
    probability distribution of two pointers to make a prediction. They only experimented
    with court debate and customer service content generation tasks, where similar
    cases were easy to obtain.'
  prefs: []
  type: TYPE_NORMAL
- en: Copy mechanism for task-oriented dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Many dialogue state tracking tasks generate slots and slot values using a copy
    component (Wu et al., [2019a](#bib.bib413); Ouyang et al., [2020](#bib.bib266);
    Gangadharaiah and Narayanaswamy, [2020](#bib.bib97); Chen et al., [2020a](#bib.bib41);
    Zhang et al., [2020](#bib.bib452); Li et al., [2020d](#bib.bib207)). Among them Wu
    et al. ([2019a](#bib.bib413)), Ouyang et al. ([2020](#bib.bib266)) and Chen et al.
    ([2020a](#bib.bib41)) solved the problem of multi-domain dialogue state tracking.
    Wu et al. ([2019a](#bib.bib413)) proposed TRAnsferable Dialogue statE generator
    (TRADE), a copy-based dialogue state generator. The generator decoded the slot
    value multiple times for each possible (domain, slot) pair, then a slot gate was
    applied to decide which pair belonged to the dialogue. The output distribution
    was a copy of the slot values belonging to the selected (domain, slot) pairs from
    vocabulary and dialogue history. Chen et al. ([2020a](#bib.bib41)) used a different
    copy strategy from TRADE. Instead of using the whole dialogue history as the copy
    source, they copied state values from user utterances and system messages respectively,
    which took the slot-level context as input. Ouyang et al. ([2020](#bib.bib266))
    proposed slot connection mechanism to efficiently utilize existing states from
    other domains. Attention weights were calculated to measure the connection between
    the target slot and related slot-value tuples in other domains. Three distributions
    over token generation, dialogue context copying, and past state copying were finally
    gated and fused to predict the next token. Gangadharaiah and Narayanaswamy ([2020](#bib.bib97))
    combined a pointer network with a template-based tree decoder to fill the templates
    recursively and hierarchically. Copy mechanisms also alleviated the problem of
    expensive data annotation in end-to-end task-oriented dialogue systems. Copy-augmented
    dialogue generation models were proven to perform significantly better than strong
    baselines with limited domain-specific or multi-domain data (Zhang et al., [2020](#bib.bib452);
    Li et al., [2020d](#bib.bib207); Gao et al., [2020a](#bib.bib99)).
  prefs: []
  type: TYPE_NORMAL
- en: Copy mechanism for dialogue-related tasks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Pointer networks and CopyNet are also used to solve other dialogue-related tasks.
    Yu and Joty ([2020](#bib.bib441)) applied a pointer net for online conversation
    disentanglement. The pointer module pointed to the ancestor message to which the
    current message replies and a classifier predicted whether two messages belonged
    to the same thread. In dialogue parsing tasks, the pointer net is used as the
    backbone parsing model to construct discourse trees (Aghajanyan et al., [2020](#bib.bib2);
    Lin et al., [2019](#bib.bib213)). Tay et al. ([2019](#bib.bib365)) used a pointer-generator
    framework to perform machine reading comprehension over a long span, where the
    copy mechanism reduced the demand of including target answers in context.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7 Deep Reinforcement Learning Models and Generative Adversarial Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In recent years, two exciting approaches exhibit the potential of artificial
    intelligence. The first one is deep reinforcement learning, which outperforms
    humans in many complex problems such as large-scale games, conversations, and
    car-driving. Another technique is GAN, showing amazing capability in generation
    tasks. The data samples generated by GAN models like articles, paintings, and
    even videos, are sometimes indistinguishable from human creations.
  prefs: []
  type: TYPE_NORMAL
- en: AlphaGo (Silver et al., [2016](#bib.bib327)) stimulated the research interests
    again in reinforcement learning in recent years (Graves et al., [2016](#bib.bib112);
    Mnih et al., [2016](#bib.bib253); Wang et al., [2016](#bib.bib394); Tamar et al.,
    [2016](#bib.bib358); Jaderberg et al., [2016](#bib.bib152); Mirowski et al., [2016](#bib.bib251)).
    Reinforcement learning is a branch of machine learning aiming to train agents
    to perform appropriate actions while interacting with a certain environment. It
    is one of the three fundamental machine learning branches, with supervised learning
    and unsupervised learning being the other two. It can also be seen as an intermediate
    between supervised learning and unsupervised learning because it only needs weak
    signals for training (Wang et al., [2016](#bib.bib394)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/db8bbcf7bcb7e80032ef140aea094e73.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: The reinforcement learning framework'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [10](#S2.F10 "Figure 10 ‣ 2.7 Deep Reinforcement Learning Models and
    Generative Adversarial Networks ‣ 2 Neural Models in Dialogue Systems ‣ Recent
    Advances in Deep Learning Based Dialogue Systems: A Systematic Survey") illustrates
    the reinforcement learning framework, consisting of an agent and an environment.
    The framework is a Markov Decision Process (MDP) (Puterman, [2014](#bib.bib278)),
    which can be described by a five-tuple M = $\langle S,A,P,R,\gamma\rangle$. $S$
    denotes an infinite set of environment states; $A$ denotes a set of actions that
    agent chooses from conditioned on a given environment state $s$; $P$ is the transition
    probability matrix in MDP, denoting the probability of an environment state transfer
    after agent takes an action; $R$ is an average reward the agent receives from
    the environment after taking an action under state $s$; $\gamma$ is a discount
    factor. The flow of this framework is a loop of the following two steps: the agent
    first makes an observation on the current environment state $s_{t}$ and chooses
    an action based on its policy; then according to the transition probability matrix
    $P$, the environment’s state transfers to $s_{t+1}$, and simultaneously provides
    a reward $r_{t}$.'
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement learning is applicable to solve many challenges in dialogue systems
    because of the agent-environment nature of a dialogue system. A two-party dialogue
    system consists of an agent, which is an intelligent chatbot, and an environment,
    which is usually a user or a user simulator. Here we mainly discuss deep reinforcement
    learning.
  prefs: []
  type: TYPE_NORMAL
- en: Deep reinforcement learning means applying deep neural networks to model the
    value function or policy of the reinforcement learning framework. “Deep model"
    is in contrast to the “shallow model". The shallow model normally refers to traditional
    machine learning models like Decision Trees or KNN. Feature engineering, which
    is usually based on shallow models, is time and labor consuming, and also over-specified
    and incomplete. Different from that, deep neural models are easy to design and
    have a strong fitting capability, which contributes to many breakthroughs in recent
    research. Deep representation learning gets rid of human labor and exploits hierarchical
    features in data automatically, which strengthens the semantic expressiveness
    and domain correlations significantly.
  prefs: []
  type: TYPE_NORMAL
- en: 'We discuss two typical reinforcement models: Deep Q-Networks (Mnih et al.,
    [2015](#bib.bib252)) and REINFORCE (Williams, [1992](#bib.bib409); Sutton et al.,
    [1999](#bib.bib354)). They belong to Q-learning and policy gradient respectively,
    which are two families of reinforcement learning.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.1 Deep Q-Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'A Deep Q-Network is a value-based RL model. It determines the best policy according
    to the Q-function:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\pi^{*}(s)=arg\max_{a}Q^{*}(s,a)$ |  | (40) |'
  prefs: []
  type: TYPE_TB
- en: Where $Q^{*}(s,a)$ is an optimal Q-function and $\pi^{*}(s)$ is the corresponding
    optimal policy. In Deep Q-Networks, the Q function is modeled using a deep neural
    network, such as CNNs, RNNs, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'As in Gao et al. ([2018](#bib.bib98)), the parameters of the Q model are updated
    using the rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta\leftarrow\theta+\alpha\underbrace{\left(r_{t}+\gamma\max_{a_{t+1}}Q(s_{t+1},a_{t+1};\theta)-Q(s_{t},a_{t};\theta)\right)}_{\text{temporal\
    difference}}\bigtriangledown_{\theta}Q(s_{t},a_{t};\theta)$ |  | (41) |'
  prefs: []
  type: TYPE_TB
- en: Where the $(s_{t},a_{t},r_{t},s_{t+1})$ is an observed trajectory. $\alpha$
    denotes step-size and the parameter update is calculated using temporal difference (Sutton,
    [1988](#bib.bib353)). However, this update mechanism suffers from unstableness
    and demands a large number of training samples. There are two typical tricks for
    a more efficient and stable parameter update.
  prefs: []
  type: TYPE_NORMAL
- en: The first method is experience replay (Lin, [1992](#bib.bib211); Mnih et al.,
    [2015](#bib.bib252)). Instead of using one training sample at a time to update
    the parameters, it uses a buffer to store training samples, and iteratively retrieves
    training samples from the buffer pool to perform parameter updates. It avoids
    encountering training samples that change too fast in distribution during training
    time, which increases the learning stability; further, it uses each training sample
    multiple times, which improves the efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second is two-network implementation (Mnih et al., [2015](#bib.bib252)).
    This method uses two networks in Q-function optimization, one being the Q-network,
    another being a target network. The target network is used to calculate the temporal
    difference, and its parameters $\theta_{target}$ are frozen while training, aligning
    with $\theta$ periodically. The parameters are then updated with the following
    rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta\leftarrow\theta+\alpha\underbrace{\left(r_{t}+\gamma\max_{a_{t+1}}Q(s_{t+1},a_{t+1};\theta_{target})-Q(s_{t},a_{t};\theta)\right)}_{\text{temporal\
    difference\ with\ a\ target\ network}}\bigtriangledown_{\theta}Q(s_{t},a_{t};\theta)$
    |  | (42) |'
  prefs: []
  type: TYPE_TB
- en: Since $\theta_{target}$ does not change in a period of time, the target network
    calculates the temporal difference in a stable manner, which facilitates the convergence
    of training.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.2 REINFORCE
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'REINFORCE is a policy-based RL algorithm that has no value network. It optimizes
    the policy directly. The policy is parameterized by a policy network, whose output
    is a distribution over continuous or discrete actions. A long-term reward is computed
    for evaluation of the policy network by collecting trajectory samples of length
    $H$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $J(\theta)=E\left[\sum_{t=1}^{H}\gamma^{t-1}r_{t}&#124;a_{t}\sim\pi(s_{t};\theta)\right]$
    |  | (43) |'
  prefs: []
  type: TYPE_TB
- en: '$J(\theta)$ denotes a long-term reward and the goal is to optimize the policy
    network in order to maximize $J(\theta)$. Here stochastic gradient ascent⁷⁷7Stochastic
    gradient ascent simply uses the negated objective function of stochastic gradient
    descent. is used as an optimizer:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta\leftarrow\theta+\alpha\bigtriangledown_{\theta}J(\theta)$ |  |
    (44) |'
  prefs: []
  type: TYPE_TB
- en: 'Where $\bigtriangledown_{\theta}J(\theta)$ is computed by:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bigtriangledown_{\theta}J(\theta)=\sum_{t=1}^{H-1}\gamma^{t-1}\left(\bigtriangledown_{\theta}log\pi(a_{t}&#124;s_{t};\theta)\sum_{h=t}^{H}\gamma^{h-t}r_{h}\right)$
    |  | (45) |'
  prefs: []
  type: TYPE_TB
- en: 'Both models have their advantages: Deep Q-Networks are more sample efficient
    while REINFORCE is more stable (Li, [2017](#bib.bib205)). REINFORCE is more popular
    in recent works. Modern research involves larger action spaces, which means that
    value-based RL models like Deep Q-Networks are not suitable for problem-solving.
    Value-based methods “select an action to maximize the value", which means that
    their action sets should be discrete and moderate in scale; while policy gradient
    methods such as REINFORCE are different, they predict the action via policy networks
    directly, which sets no restriction on the action space. As a result, policy gradient
    methods are more suitable for tasks involving a larger action space.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Considering the respective benefits brought by the Q-learning and policy gradient,
    some work has been done combining the value- and policy-based methods. Actor-critic
    algorithm (Konda and Tsitsiklis, [2000](#bib.bib172); Sutton et al., [1999](#bib.bib354))
    was proposed to alleviate the severe variance problem when calculating the gradient
    in policy gradient methods. It estimates a value function for term $\sum_{h=t}^{H}\gamma^{h-t}r_{h}$
    in Equation ([45](#S2.E45 "In 2.7.2 REINFORCE ‣ 2.7 Deep Reinforcement Learning
    Models and Generative Adversarial Networks ‣ 2 Neural Models in Dialogue Systems
    ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey"))
    and incorporates it in policy optimization. Equation ([45](#S2.E45 "In 2.7.2 REINFORCE
    ‣ 2.7 Deep Reinforcement Learning Models and Generative Adversarial Networks ‣
    2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey")) is then transformed into the formula below:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\bigtriangledown_{\theta}J(\theta)=\sum_{t=1}^{H-1}\gamma^{t-1}\left(\bigtriangledown_{\theta}log\pi(a_{t}&#124;s_{t};\theta)\hat{Q}(s_{t},a_{t},h)\right)$
    |  | (46) |'
  prefs: []
  type: TYPE_TB
- en: Where $\hat{Q}(s_{t},a_{t},h)$ stands for the value function estimated.
  prefs: []
  type: TYPE_NORMAL
- en: 2.7.3 GANs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is easy to link the actor-critic model with another framework - GANs (Goodfellow
    et al., [2014](#bib.bib108); Zhang et al., [2018c](#bib.bib451); Feng et al.,
    [2020a](#bib.bib87)) because of their similar inner structure and logic (Pfau
    and Vinyals, [2016](#bib.bib274)). Actually, there are quite a few recent works
    in dialogue systems that train GANs with reinforcement learning framework (Zhu
    et al., [2018](#bib.bib466); Wu et al., [2019b](#bib.bib415); He et al., [2020a](#bib.bib128);
    Zhu et al., [2020](#bib.bib467); Qin et al., [2020](#bib.bib281)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/150fae7ed08922d0dd788e68bb1aea35.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: The GAN framework'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [11](#S2.F11 "Figure 11 ‣ 2.7.3 GANs ‣ 2.7 Deep Reinforcement Learning
    Models and Generative Adversarial Networks ‣ 2 Neural Models in Dialogue Systems
    ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey")
    represents the GAN consisting of a generator and a discriminator where the training
    process can be viewed as a competition between them: the generator tries to generate
    data distributions to fool the discriminator while the discriminator attempts
    to distinguish between real data (real) and generated data (fake). During training,
    the generator takes noise as input and generates data distribution while the discriminator
    takes real and fake data as input and the binary annotation as the label. The
    whole GAN model is trained end-to-end as a connection of generator and discriminator
    to minimize the following cross-entropy losses:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L_{1}(D,G)=-E_{\omega\sim P_{data}}[logD(\omega)]-E_{z\sim N(0,I)}[log(1-D(G(z)))]$
    |  | (47) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $L_{2}(D,G)=-E_{z\sim N(0,I)}[logD(G(z))]$ |  | (48) |'
  prefs: []
  type: TYPE_TB
- en: Where $L_{1}$ and $L_{2}$ denote a bilevel loss, where $D$ and $G$ being discriminator
    and generator respectively. $z\sim N(0,I)$ is the noise input of the generator
    and $w$ is the input of the discriminator.
  prefs: []
  type: TYPE_NORMAL
- en: Relationship between RL and GAN
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: GAN can be viewed as a special actor-critic (Pfau and Vinyals, [2016](#bib.bib274)).
    In the learning architecture of GAN, the generator acts as the actor and the discriminator
    acts as the critic or environment which gives the real/fake feedback as a reward.
    However, the actions taken by the actor cannot change the states of the environment,
    which means that the learning architecture of GAN is a stateless Markov decision
    process. Also, the actor has no access to the state of the environment and generates
    data distribution simply conditioned on Gaussian noise, which means that the generator
    in the GAN framework is a blind actor/agent. In a nutshell, GAN is a special actor-critic
    where the actor is blind and the whole process is a stateless MDP.
  prefs: []
  type: TYPE_NORMAL
- en: The interactive nature of dialogue systems motivates the wide application of
    reinforcement learning and GAN models in its research.
  prefs: []
  type: TYPE_NORMAL
- en: RL for task-oriented dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'One common application of reinforcement learning in dialogue systems is the
    reinforced dialogue management in task-oriented systems. Dialogue state tracking
    and policy learning are two typical modules of a dialogue manager. Huang et al.
    ([2020c](#bib.bib150)) and Li et al. ([2020d](#bib.bib207)) trained the dialogue
    state tracker with reinforcement learning. Both of them combined a reward manager
    into their tracker to enhance tracking accuracy. For the policy learning module,
    reinforcement learning seems to be the best choice since almost all recent related
    works learned policy with reinforcement learning (Zhang et al., [2019c](#bib.bib454);
    Wang et al., [2020d](#bib.bib387); Zhu et al., [2020](#bib.bib467); Wang et al.,
    [2020a](#bib.bib384); Takanobu et al., [2020](#bib.bib356); Huang et al., [2020b](#bib.bib149);
    Xu et al., [2020a](#bib.bib426)). The increasing preference of reinforcement learning
    in policy learning tasks attributes to the characteristic of them: in policy learning
    tasks, the model predicts a dialogue action (action) based on the states from
    the DST module (state), which perfectly accords with the function of the agent
    in the reinforcement learning framework.'
  prefs: []
  type: TYPE_NORMAL
- en: RL for open-domain dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Due to the huge action space needed to generate language directly, many open-domain
    dialogue systems trained with reinforcement learning framework do not generate
    responses but instead select responses. Retrieval-based systems have a limited
    action set and are suitable to be trained in a reinforcement learning scheme.
    Some works achieved promising performance in retrieval-based dialogue tasks (Bouchacourt
    and Baroni, [2019](#bib.bib27); Li et al., [2016a](#bib.bib192); Zhao and Eskenazi,
    [2016](#bib.bib455)). However, retrieval systems fail to generalize in all user
    messages and may give unrelated responses (Qiu et al., [2017](#bib.bib284)), which
    makes generation-based dialogue systems preferable. Still considering the action
    space problem, some works build their systems combining retrieval and generative
    methods (Zhu et al., [2018](#bib.bib466); Serban et al., [2017b](#bib.bib314)).
    Zhu et al. ([2018](#bib.bib466)) chose to first retrieve a set of n-best response
    candidates and then generated responses based on the retrieved results and user
    message. Comparatively, Serban et al. ([2017b](#bib.bib314)) first generated and
    retrieved candidate responses with different dialogue models and then trained
    a scoring model with online reinforcement learning to select responses from both
    generated and retrieved responses. Since training a generative dialogue agent
    using reinforcement learning from scratch is particularly difficult, first pretraining
    the agent with supervised learning to warm-start is a good choice. Wu et al. ([2019b](#bib.bib415)), He
    et al. ([2020a](#bib.bib128)), Williams and Zweig ([2016](#bib.bib407)) and Yao
    et al. ([2016](#bib.bib433)) applied this pretrain-and-finetune strategy on dialogue
    learning and achieved outstanding performance, which proved that the reinforcement
    learning can improve the response quality of data-driven chatbots. Similarly,
    pretrain-and-finetune was also applicable to domain transfer problems. Some works
    pretrained the model in a source domain and expanded the domain area with reinforcement
    training (Mo et al., [2018](#bib.bib254); Li et al., [2016d](#bib.bib195)).
  prefs: []
  type: TYPE_NORMAL
- en: RL for knowledge grounded dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Some systems use reinforcement learning to select from outside information like
    persona, document, knowledge graph, etc., and generate responses accordingly.
    Majumder et al. ([2020a](#bib.bib238)) and Jaques et al. ([2020](#bib.bib154))
    performed persona selection and persona-based response generation simultaneously
    and trained their agents with a reinforcement framework. Bao et al. ([2019a](#bib.bib16))
    and Zhao et al. ([2020b](#bib.bib459)) built document-grounded systems. Similarly,
    they used reinforcement learning to accomplish document selection and knowledge-grounded
    response generation. There were also some works combining knowledge graphs into
    the dialogue systems and treated them as outside knowledge source (Moon et al.,
    [2019](#bib.bib257); Xu et al., [2020a](#bib.bib426)). In a reinforced training
    framework, the agent chooses an edge based on the current node and state for each
    step and then combines the knowledge into the response generation process.
  prefs: []
  type: TYPE_NORMAL
- en: RL for dialogue related tasks
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Dialogue-related tasks like dialogue relation extraction (Li et al., [2019c](#bib.bib203)),
    question answering (Hua et al., [2020](#bib.bib146)) and machine reading comprehension (Guo
    et al., [2020](#bib.bib116)) benefit from reinforcement learning as well because
    of their interactive nature and the scarcity of annotated data.
  prefs: []
  type: TYPE_NORMAL
- en: GAN for dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The application of GAN in dialogue systems is divided into two streams. The
    first sees the GAN framework applied to enhance response generation (Li et al.,
    [2017a](#bib.bib196); Zhu et al., [2018](#bib.bib466); Wu et al., [2019b](#bib.bib415);
    He et al., [2020a](#bib.bib128); Zhu et al., [2020](#bib.bib467); Qin et al.,
    [2020](#bib.bib281)). The discriminator distinguishes generated responses from
    human responses, which incentivizes the agent, which is also the generator in
    GAN, to generate higher-quality responses. Another stream uses GAN as an evaluation
    tool of dialogue systems (Kannan and Vinyals, [2017](#bib.bib164); Bruni and Fernandez,
    [2017](#bib.bib29)). After training the generator and discriminator as a whole
    framework, the discriminator is used separately as a scorer to evaluate the performance
    of a dialogue agent and was shown to achieve a higher correlation with human evaluation
    compared with traditional reference-based metrics like BLEU, METEOR, ROUGE-L,
    etc. We discuss the evaluation of dialogue systems as a challenge in Section [5](#S5
    "5 Evaluation Approaches ‣ Recent Advances in Deep Learning Based Dialogue Systems:
    A Systematic Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 2.8 Knowledge Graph Augmented Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Supervised training with annotated data tries to learn the knowledge distribution
    of a dataset. However, a dataset is comparatively sparse and thus learning a reliable
    knowledge distribution needs a huge amount of annotated data (Annervaz et al.,
    [2018](#bib.bib6)).
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge Graph (KG) is attracting more and more research interests in recent
    years. KG is a structured knowledge source consisting of entities and their relationships (Ji
    et al., [2022](#bib.bib157)). In other words, KG is the knowledge facts presented
    in graph format.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cc06c397bbc31e22a1e21cb9ac8daa76.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Entities and relations in knowledge graph (Ji et al., [2022](#bib.bib157))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [12](#S2.F12 "Figure 12 ‣ 2.8 Knowledge Graph Augmented Neural Networks
    ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in Deep Learning Based
    Dialogue Systems: A Systematic Survey") shows an example of a KG consisting of
    entities and their relationships. A KG is stored in triples under the Resource
    Description Framework (RDF). For example, Albert Einstein, University of Zurich,
    and their relationship can be expressed as $(AlbertEinstein,GraduateFrom,UniversityofZurich)$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowledge graph augmented neural networks first represent the entities and
    their relations in a lower dimension space, then use a neural model to retrieve
    relevant facts (Ji et al., [2022](#bib.bib157)). Knowledge graph representation
    learning can be generally divided into two categories: structure-based representations
    and semantically-enriched representations. Structure-based representations use
    multi-dimensional vectors to represent entities and relations. Models such as
    TransE (Bordes et al., [2013](#bib.bib23)), TransR (Lin et al., [2015](#bib.bib215)),
    TransH (Wang et al., [2014](#bib.bib393)), TransD (Ji et al., [2015](#bib.bib156)),
    TransG (Xiao et al., [2015](#bib.bib420)), TransM (Fan et al., [2014](#bib.bib84)),
    HolE (Nickel et al., [2016](#bib.bib262)) and ProjE (Shi and Weninger, [2017](#bib.bib322))
    belong to this category. The semantically-enriched representation models like
    NTN (Socher et al., [2013](#bib.bib334)), SSP (Xiao et al., [2017](#bib.bib421))
    and DKRL (Xie et al., [2016](#bib.bib422)) combine semantic information into the
    representation of entities and relations. The neural retrieval models also have
    two main directions: distance-based matching model and semantic matching model.
    Distance-based matching models (Bordes et al., [2013](#bib.bib23)) consider the
    distance between projected entities while semantic matching models (Bordes et al.,
    [2014](#bib.bib24)) calculate the semantic similarity of entities and relations
    to retrieve facts.'
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graph augmented dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Knowledge-grounded dialogue systems benefit greatly from the structured knowledge
    format of KG, where facts are widely intercorrelated. Reasoning over a KG is an
    ideal approach for combining commonsense knowledge into response generation, resulting
    in accurate and informative responses (Young et al., [2018](#bib.bib438)). Jung
    et al. ([2020](#bib.bib160)) proposed AttnIO, a bi-directional graph exploration
    model for knowledge retrieval in knowledge-grounded dialogue systems. Attention
    weights were calculated at each traversing step, and thus the model could choose
    a broader range of knowledge paths instead of choosing only one node at a time.
    In such a scheme, the model could predict adequate paths even when only having
    the destination node as the label. Zhang et al. ([2019b](#bib.bib447)) built ConceptFlow,
    a dialogue agent that guided to more meaningful future conversations. It traversed
    in a commonsense knowledge graph to explore concept-level conversation flows.
    Finally, it used a gate to decide to generate among vocabulary words, central
    concept words, and outer concept words. Majumder et al. ([2020a](#bib.bib238))
    proposed to generate persona-based responses by first using COMET (Bosselut et al.,
    [2019](#bib.bib26)) to expand a persona sentence in context along 9 relation types
    and then applied a pretrained model to generate responses based on dialogue history
    and the persona variable. Yang et al. ([2020](#bib.bib429)) used knowledge graph
    as an external knowledge source in task-oriented dialogue systems to incorporate
    domain-specified knowledge in the response. First, the dialogue history was parsed
    as a dependency tree and encoded into a fixed-length vector. Then they applied
    multi-hop reasoning over the graph using the attention mechanism. The decoder
    finally predicted tokens either by copying from graph entities or generating vocabulary
    words. Moon et al. ([2019](#bib.bib257)) proposed DialKG Walker for the conversational
    reasoning task. They computed a zero-shot relevance score between predicted KG
    embedding and ground KG embedding to facilitate cross-domain predictions. Furthermore,
    they applied an attention-based graph walker to generate graph paths based on
    the relevance scores. Huang et al. ([2020a](#bib.bib147)) evaluated the dialogue
    systems by combining the utterance-level contextualized representation and topic-level
    graph representation. They first constructed the dialogue graph based on encoded
    (context, response) pairs and then reasoned over the graph to get a topic-level
    graph representation. The final score was calculated by passing the concatenated
    vector of contextualized representation and graph representation to a feed-forward
    network.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Task-oriented Dialogue Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section introduces task-oriented dialogue systems including modular and
    end-to-end systems. Task-oriented systems solve specific problems in a certain
    domain such as movie ticket booking, restaurant table reserving, etc. We focus
    on deep learning-based systems due to the outstanding performance. For readers
    who want to learn more about traditional rule-based and statistical models, there
    are several surveys to refer to (Theune, [2003](#bib.bib367); Lemon and Pietquin,
    [2007](#bib.bib189); Mallios and Bourbakis, [2016](#bib.bib240); Chen et al.,
    [2017a](#bib.bib39); Santhanam and Shaikh, [2019](#bib.bib305)).
  prefs: []
  type: TYPE_NORMAL
- en: This section is organized as follows. We first discuss modular and end-to-end
    systems respectively by introducing the principles and reviewing recent works.
    After that, we comprehensively discuss related challenges and hot topics for task-oriented
    dialogue systems in recent research to provide some important research directions.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4918f832683341a45125f7a76ec974f8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Structure of a task-oriented dialogue system in the task-completion
    pipeline'
  prefs: []
  type: TYPE_NORMAL
- en: 'A task-oriented dialogue system requires stricter response constraints because
    it aims to accurately handle the user message. Therefore, modular methods were
    proposed to generate responses in a more controllable way. The architecture of
    a modular-based system is depicted in Figure [13](#S3.F13 "Figure 13 ‣ 3 Task-oriented
    Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems: A
    Systematic Survey"). It consists of four modules:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Natural Language Understanding (NLU). This module converts the raw user message
    into semantic slots, together with classifications of domain and user intention.
    However, some recent modular systems omit this module and use the raw user message
    as the input of the next module, as shown in Figure [13](#S3.F13 "Figure 13 ‣
    3 Task-oriented Dialogue Systems ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey"). Such a design aims to reduce the propagation of
    errors between modules and alleviate the impact of the original error (Kim et al.,
    [2018](#bib.bib166)).'
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue State Tracking (DST). This module iteratively calibrates the dialogue
    states based on the current input and dialogue history. The dialogue state includes
    related user actions and slot-value pairs.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue Policy Learning. Based on the calibrated dialogue states from the DST
    module, this module decides the next action of a dialogue agent.
  prefs: []
  type: TYPE_NORMAL
- en: Natural Language Generation (NLG). This module converts the selected dialogue
    actions into surface-level natural language, which is usually the ultimate form
    of response.
  prefs: []
  type: TYPE_NORMAL
- en: Among them, Dialogue State Tracking and Dialogue Policy Learning constitute
    the Dialogue Manager (DM), the central controller of a task-oriented dialogue
    system. Usually, a task-oriented system also interacts with an external Knowledge
    Base (KB) to retrieve essential knowledge about the target task. For example,
    in a movie ticket booking task, after understanding the requirement of the user
    message, the agent interacts with the movie knowledge base to search for movies
    with specific constraints such as movie name, time, cinema, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Natural Language Understanding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'It has been proven that the NLU module impacts the whole system significantly
    in the term of response quality (Li et al., [2017b](#bib.bib201)). The NLU module
    converts the natural language message produced by the user into semantic slots
    and performs classification. Table [2](#S3.T2 "Table 2 ‣ 3.1 Natural Language
    Understanding ‣ 3 Task-oriented Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey") shows an example of the output format
    of the NLU module. The NLU module manages three tasks: domain classification,
    intent detection, and slot filling. Domain classification and intent detection
    are classification problems, which use classifiers to predict a mapping from the
    input language sequence to a predefined label set. In the given example, the predicted
    domain is “movie" and the intent is “find_movie". Slot filling is a tagging problem,
    which can be viewed as a sequence-to-sequence task. It maps a raw user message
    into a sequence of slot names. In the example, the NLU module reads the user message
    “Recommend a movie at Golden Village tonight." and outputs the corresponding tag
    sequence. It recognizes “Golden Village" as the place to go, which is tagged as
    “B_desti" and “I_desti" for the two words respectively. Similarly, the token “tonight"
    is converted into “B_time". ‘B’ represents the beginning of a chunk, and ‘I’ indicates
    that this tag is inside a target chunk. For those unrelated tokens, an ‘O’ is
    used indicating that this token is outside of any chunk of interest. This tagging
    method is called Inside-Outside-Beginning (IOB) tagging (Ramshaw and Marcus, [1999](#bib.bib290)),
    which is a common method in Named-Entity Recognition (NER) tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: The output example of an NLU module'
  prefs: []
  type: TYPE_NORMAL
- en: '| Sentence | Recommend | a | movie | at | Golden | Village | tonight |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Slots | O | O | O | O | B-desti | I-desti | B-time |'
  prefs: []
  type: TYPE_TB
- en: '| Intent |  |  |  | find_movie |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Domain |  |  |  | movie |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: Techniques for domain classification and intent detection
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Domain classification and intent detection belong to the same category of tasks.
    Deep learning methods are proposed to solve the classification problems of dialogue
    domain and intent. Deng et al. ([2012](#bib.bib67)) and Tur et al. ([2012](#bib.bib374))
    were the first who successfully improved the recognition accuracy of dialogue
    intent. They built deep convex networks to combine the predictions of a prior
    network and the current utterances as an integrated input of a current network.
    A deep learning framework was also used to classify the dialogue domain and intent
    in a semi-supervised fashion (Yann et al., [2014](#bib.bib430)). To solve the
    difficulty of training a deep neural network for domain and intent prediction,
    Restricted Boltzmann Machine (RBM) and Deep Belief Networks (DBNs) were applied
    to initialize the parameters of deep neural networks (Sarikaya et al., [2014](#bib.bib307)).
    To make use of the strengths of RNNs in sequence processing, some works used RNNs
    as utterance encoders and made predictions for intent and domain categories (Ravuri
    and Stolcke, [2015](#bib.bib293), [2016](#bib.bib294)). Hashemi et al. ([2016](#bib.bib124))
    used a CNN to extract hierarchical text features for intent detection and illustrated
    the sequence classification capabilities of CNNs. Lee and Dernoncourt ([2016](#bib.bib183))
    proposed a model for intent classification of short utterances. Short utterances
    are hard for intent detection because of the lack of information in a single dialogue
    turn. This paper used RNN and CNN architectures to incorporate the dialogue history,
    thus obtaining the context information as an additional input besides the current
    turn’s message. The model achieved promising performances on three intent classification
    datasets. More recently, Wu et al. ([2020a](#bib.bib414)) pretrained Task-Oriented
    Dialogue BERT (TOD-BERT) and significantly improved the accuracy in the intent
    detection sub-task. The proposed model also exhibited a strong capability of few-shot
    learning and could effectively alleviate the data insufficiency issue in a specific
    domain.
  prefs: []
  type: TYPE_NORMAL
- en: Techniques for slot filling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The slot filling problem is also called semantic tagging, a sequence classification
    problem. It is more challenging for that the model needs to predict multiple objects
    at a time. Deep Belief Nets (DBNs) exhibit promising capabilities in the learning
    of deep architectures and have been applied in many tasks including semantic tagging.
    Sarikaya et al. ([2011](#bib.bib306)) used a DBN-initialized neural network to
    complete slot filling in the call-routing task. Deoras and Sarikaya ([2013](#bib.bib68))
    built a DBN-based sequence tagger. In addition to the NER input features used
    in traditional taggers, they also combined part of speech (POS) and syntactic
    features as a part of the input. The recurrent architectures benefited the sequence
    tagging task in that they could keep track of the information along past timesteps
    to make the most of the sequential information. Yao et al. ([2013](#bib.bib431))
    first argued that instead of simply predicting words, RNN Language Models (RNN-LMs)
    could be applied in sequence tagging. On the output side of RNN-LMs, tag labels
    were predicted instead of normal vocabularies. Mesnil et al. ([2013](#bib.bib246))
    and Mesnil et al. ([2014](#bib.bib247)) further investigated the impact of different
    recurrent architectures in the slot filling task and found that all RNNs outperformed
    the Conditional Random Field (CRF) baseline. As a powerful recurrent model, LSTM
    showed promising tagging accuracy on the ATIS dataset owing to the memory control
    of its gate mechanism (Yao et al., [2014](#bib.bib432)). Gangadharaiah and Narayanaswamy
    ([2020](#bib.bib97)) argued that the shallow output representations of traditional
    semantic tagging lacked the ability to represent the structured dialogue information.
    To improve, they treated the slot filling task as a template-based tree decoding
    task by iteratively generating and filling in the templates. Different from traditional
    sequence tagging methods, Coope et al. ([2020](#bib.bib58)) tackled the slot filling
    task by treating it as a turn-based span extraction task. They applied the conversational
    pretrained model ConveRT and utilized the rich semantic information embedded in
    the pretrained vectors to solve the problem of in-domain data insufficiency. The
    inputs of ConveRT are the requested slots and the utterance, while the output
    is a span of interest as the slot value.
  prefs: []
  type: TYPE_NORMAL
- en: Unifying domain classification, intent detection, and slot filling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Some works choose to combine domain classification, intent detection, and slot
    filling into a multitask learning framework to jointly optimize the shared latent
    space. Hakkani-Tür et al. ([2016](#bib.bib120)) applied a bi-directional RNN-LSTM
    architecture to jointly perform three tasks. Liu and Lane ([2016](#bib.bib220))
    augmented the traditional RNN encoder-decoder model with an attention mechanism
    to manage intent detection and slot filling. The slot filling applied explicit
    alignment. Chen et al. ([2016](#bib.bib48)) proposed an end-to-end memory network
    and used a memory module to store user intent and slot values in history utterances.
    Attention was further applied to iteratively select relevant intent and slot values
    at the decoding stage. Multi-task learning of three NLU subtasks contributed to
    the domain scaling and facilitated the zero-shot or few-shot training when transferring
    to a new domain (Bapna et al., [2017](#bib.bib18); Lee and Jha, [2019](#bib.bib186)).
    Zhang et al. ([2018a](#bib.bib445)) captured the hierarchical structure of dialogue
    semantics in NLU multi-task learning by applying a capsule-based neural network.
    With a dynamic routing-by-agreement strategy, the proposed architecture raised
    the accuracy of both intent detection and slot filling on the SNIPS-NLU and ATIS
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Novel perspectives
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: More recently, some novel ideas appear in NLU research, which provides new possibilities
    for further improvements. Traditional NLU modules rely on the text converted from
    the audio message of the user using the Automatic Speech Recognition (ASR) module.
    However, Singla et al. ([2020](#bib.bib331)) jumped over the ASR module and directly
    used audio signals as the input of NLU. They found that by reducing the module
    numbers of a pipeline system, the predictions were more robust since fewer errors
    were broadcasted. Su et al. ([2019b](#bib.bib347)) argued that Natural Language
    Understanding (NLU) and Natural Language Generation (NLG) were reversed processes.
    Thus, their dual relationship could be exploited by training with a dual-supervised
    learning framework. The experiments exhibited improvement in both tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Dialogue State Tracking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dialogue State Tracking (DST) is the first module of a dialogue manager. It
    tracks the user’s goal and related details every turn based on the whole dialogue
    history to provide the information based on which the Policy Learning module (next
    module) decides the agent action to make.
  prefs: []
  type: TYPE_NORMAL
- en: Differences between NLU and DST
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The NLU and DST modules are closely related. Both NLU and DST perform slot
    filling for the dialogue. However, they actually play different roles. The NLU
    module tries to make classifications for the current user message such as the
    intent and domain category as well as the slot each message token belongs to.
    For example, given a user message “Recommend a movie at Golden Village tonight.",
    the NLU module will convert the raw message into “$inform(domain=movie;\ destination=GoldenVillage;\
    date=today;\ time=evening)$", where the slots are usually filled by tagging each
    word of the user message as described in Section [3.1](#S3.SS1 "3.1 Natural Language
    Understanding ‣ 3 Task-oriented Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey"). However, the DST module does not
    classify or tag the user message. Instead, it tries to find a slot value for each
    slot name in a pre-existing slot list based on the whole dialogue history. For
    example, there is a pre-existing slot list “$intent:\_;\ domain:\_;\ name:\_;\
    pricerange:\_;\ genre:\_;\ destination:\_;\ date:\_$", where the underscore behind
    the colon is a placeholder denoting that this place can be filled with a value.
    Every turn, the DST module will look up the whole dialogue history up to the current
    turn and decide which content can be filled in a specific slot in the slot list.
    If the user message “Recommend a movie at Golden Village tonight." is the only
    message in a dialogue, then the slot list can be filled as “$intent:inform;\ domain:movie;\
    name:None;\ pricerange:None;\ genre:None;\ destination:GoldenVillage;\ date:today$",
    where the slots unspecified by the user up to current turn can be filled with
    “$None$". To conclude, the NLU module tries to tag the user message while the
    DST module tries to find values from the user message to fill in a pre-existing
    form. Some dialogue systems took the output of the NLU module as the input of
    DST module (Williams et al., [2013](#bib.bib403); Henderson et al., [2014a](#bib.bib133),
    [b](#bib.bib134)), while others directly used raw user messages to track the state (Kim
    et al., [2019](#bib.bib170); Wang et al., [2020e](#bib.bib391); Hu et al., [2020](#bib.bib142)).'
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue State Tracking Challenges (DSTCs), a series of popular challenges in
    DST, provides benchmark datasets, standard evaluation frameworks, and test-beds
    for research (Williams et al., [2013](#bib.bib403); Henderson et al., [2014a](#bib.bib133),
    [b](#bib.bib134); Kim et al., [2016](#bib.bib168), [2017](#bib.bib169)). The DSTCs
    cover many domains such as restaurants, tourism, etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'A dialogue state contains all essential information to be conveyed in the response (Henderson,
    [2015](#bib.bib131)). As defined in DSTC2 (Henderson et al., [2014a](#bib.bib133)),
    the dialogue state of a given dialogue turn consists of informable slots Sinf
    and requestable slots Sreq. Informable slots are attributes specified by users
    to constrain the search of the database while requestable slots are attributes
    whose values are queried by the user. For example, the serial number of a movie
    ticket is usually a requestable slot because users seldom assign a specific serial
    number when booking a ticket. Specifically, the dialogue state has three components:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goal constraint corresponding with informable slots. The constraints can be
    specific values mentioned by the user in the dialogue or a special value. Special
    values include Dontcare indicating the user’s indifference about the slot and
    None indicating that the user has not specified the value in the conversation
    yet.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Requested slots. It can be a list of slot names queried by the user seeking
    answers from the agent.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Search method of current turn. It consists of values indicating the interaction
    categories. By constraints denotes that the user tries to specify constraint information
    in his requirement; by alternatives denotes that the user requires an alternative
    entity; finished indicates that the user intends to end the conversation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: However, considering the numerous challenges such as tracking efficiency, tracking
    accuracy, domain adaptability, and end-to-end training, many alternative representations
    have been proposed recently, which will be discussed later.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8fb282b87fcb7d57485f527c8ba737b8.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: An example of DST procedure (Henderson et al., [2014a](#bib.bib133))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [14](#S3.F14 "Figure 14 ‣ Differences between NLU and DST ‣ 3.2 Dialogue
    State Tracking ‣ 3 Task-oriented Dialogue Systems ‣ Recent Advances in Deep Learning
    Based Dialogue Systems: A Systematic Survey") is an example of the DST process
    for 4 dialogue turns in a restaurant table booking task. The first column includes
    the raw dialogue utterances, with $S$ denoting the system message and $U$ denoting
    the user message. The second column includes the N-best output lists of the NLU
    module and their corresponding confidence scores. The third column includes the
    labels of a turn, indicating the ground truth slot-value pairs. The fourth column
    includes the example DST outputs and their corresponding confidence scores. The
    fifth column indicates the correctness of the tracker output.'
  prefs: []
  type: TYPE_NORMAL
- en: Earlier works use hand-craft rules or statistical methods to solve DST tasks.
    While widely used in industry dialogue systems, rule-based DST methods (Goddeau
    et al., [1996](#bib.bib106)) have many restrictions such as limited generalization,
    high error rate, low domain adaptability, etc (Williams, [2014](#bib.bib406)).
    Statistical methods (Lee, [2013](#bib.bib184); Lee and Eskenazi, [2013](#bib.bib185);
    Ren et al., [2013](#bib.bib297); Williams, [2013](#bib.bib405), [2014](#bib.bib406))
    also suffer from noisy conditions and ambiguity (Young et al., [2010](#bib.bib437)).
  prefs: []
  type: TYPE_NORMAL
- en: Recently, many neural trackers have emerged. Neural trackers have multiple advantages
    over rule-based and statistical trackers. In general, they are categorized into
    two streams. The first stream has predefined slot names and values, and each turn
    the DST module tries to find the most appropriate slot-value pairs based on the
    dialogue history; the second stream does not have a fixed slot value list, so
    the DST module tries to find the values directly from the dialogue context or
    generate values based on the dialogue context. Obviously, the latter one is more
    flexible and in fact, more and more works are solving DST in the second way. We
    discuss the works of both categories here.
  prefs: []
  type: TYPE_NORMAL
- en: Neural trackers with predefined slot names and values
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The first stream can be viewed as a multi-class or multi-hop classification
    task. For multi-class classification DST, the tracker predicts the correct class
    from multiple values but this method suffers from high complexity when the value
    set grows large. On the other hand, for the multi-hop classification tasks, the
    tracker reads only one slot-value pair at a time and performs binary prediction.
    Working in this fashion reduces the model complexity but raises the system reaction
    time since for each slot there will be multiple tracking processes. Henderson
    et al. ([2013](#bib.bib132)) was the first who used a deep learning model in the
    DST tasks. They integrated many feature functions (e.g., SLU score, Rank score,
    Affirm score, etc.) as the input of a neural network, then predict the probability
    of each slot-value pair. Mrkšić et al. ([2015](#bib.bib259)) applied an RNN as
    a neural tracker to gain awareness on dialogue context. Mrkšić et al. ([2016](#bib.bib260))
    proposed a multi-hop neural tracker which took the system output and user utterances
    as the first two inputs (to model the dialogue context), and the candidate slot-value
    pairs as the third input. The tracker finally made a binary prediction on the
    current slot-value pair based on the dialogue history.
  prefs: []
  type: TYPE_NORMAL
- en: Neural trackers with unfixed slot names and values
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The second stream attracts more attention because it not only reduces the model
    and time complexity of DST tasks but also facilitates end-to-end training of task-oriented
    dialogue systems. Moreover, it is also flexible when the target domain changes.
    Lei et al. ([2018](#bib.bib188)) proposed belief span, a text span of the dialogue
    context corresponding to a specific slot. They built a two-stage CopyNet to copy
    and store slot values from the dialogue history. The slots were stored to prepare
    for neural response generation. The belief span facilitated the end-to-end training
    of dialogue systems and increased the tracking accuracy in out-of-vocabulary cases.
    Based on this, Lin et al. ([2020c](#bib.bib217)) proposed the minimal belief span
    and argued that it was not scalable to generate belief states from scratch when
    the system interacted with APIs from diverse domains. The proposed MinTL framework
    operated insertion (INS), deletion (DEL) and substitution (SUB) on the dialogue
    state of last turn based on the context and the minimal belief span. Wu et al.
    ([2019a](#bib.bib413)) proposed the TRADE model. The model also applied the copy
    mechanism and used a soft-gated pointer-generator to generate the slot value based
    on the domain-slot pair and encoded dialogue context. Quan and Xiong ([2020](#bib.bib285))
    argued that simply concatenating the dialogue context was not preferable. Alternatively,
    they used [sys] and [usr] to discriminate the system and user messages. This simple
    long context modeling method achieved a 7.03% improvement compared with the baseline.
    Cheng et al. ([2020](#bib.bib49)) proposed Tree Encoder-Decoder (TED) architecture
    which utilized a hierarchical tree structure to represent the dialogue states
    and system acts. The TED generated tree-structured dialogue states of the current
    turn based on the dialogue history, dialogue action, and dialogue state of the
    last turn. This approach led to a 20% improvement on the state-of-the-art DST
    baselines which represented dialogue states and user goals in a flat space. Chen
    et al. ([2020a](#bib.bib41)) built an interactive encoder to exploit the dependencies
    within a turn and between turns. Furthermore, they used the attention mechanism
    to construct the slot-level context for user and system respectively, which were
    embedding vectors based on which the generator copied values from the dialogue
    context. Shan et al. ([2020](#bib.bib317)) applied BERT to perform multi-task
    learning and generated the dialogue state. They first encoded word-level and turn-level
    contexts. Then they retrieved the relevant information for each slot from the
    context by applying both word-level and turn-level attention. Furthermore, the
    slot values were predicted based on the retrieved information. Similarly, Wang
    et al. ([2020e](#bib.bib391)) used BERT for slot value prediction. They performed
    Slot Attention (SA) to retrieve related spans and Value Normalization (VN) to
    convert the spans into final values. Huang et al. ([2020c](#bib.bib150)) proposed
    Meta-Reinforced MultiDomain State Generator (MERET), which was a dialogue state
    generator further finetuned with policy gradient reinforcement learning.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Policy Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The Policy learning module is the other module of a dialogue manager. This
    module controls which action will be taken by the system based on the output dialogue
    states from the DST module. Assuming that we have the dialogue state $S_{t}$ of
    the current turn and the action set $A=\{a_{1},...,a_{n}\}$, the task of this
    module is to learn a mapping function $f$: $S_{t}\to a_{i}\in A$. This module
    is comparatively simpler than other modules in the term of task definition but
    actually, the task itself is challenging (Peng et al., [2017](#bib.bib272)). For
    example, in the tasks of movie ticket and restaurant table booking, if the user
    books a two-hour movie slot and intends to go for dinner after that, then the
    agent should be aware that the time gap between movie slot and restaurant slot
    has to be more than two hours since the commuting time from the cinema to the
    restaurant should be considered.'
  prefs: []
  type: TYPE_NORMAL
- en: Supervised learning and reinforcement learning are mainstream training methods
    for dialogue policy learning (Chen et al., [2017a](#bib.bib39)). Policies learned
    in a supervised fashion exhibit great decision-making ability (Su et al., [2016](#bib.bib346);
    Dhingra et al., [2016](#bib.bib71); Williams et al., [2017](#bib.bib408); Liu
    and Lane, [2017](#bib.bib221)). In some specific tasks, the supervised policy
    model can complete tasks precisely, but the training process totally depends on
    the quality of training data. Moreover, the annotated datasets require intensive
    human labor, and the decision ability is restricted by the specific task and domain,
    showing weak transferring capability. With the prevalence of reinforcement learning
    methods, more and more task-oriented dialogue systems use reinforcement learning
    to learn the policy. The dialogue policy learning fits the reinforcement learning
    setting since the agent of reinforcement learning learns a policy to map environment
    states to actions as well.
  prefs: []
  type: TYPE_NORMAL
- en: Usually, the environment of reinforce policy learning is a user or a simulated
    user in which setting the training is called online learning. However, it is data-
    and time-consuming to learn a policy from scratch in the online learning scenario,
    so the warm-start method is needed to speed up the training process. Henderson
    et al. ([2008](#bib.bib130)) used expert data to restrict the initial action space
    exploration. Chen et al. ([2017b](#bib.bib42)) applied teacher-student learning
    framework to transfer the teacher expert knowledge to the target network in order
    to warm-start the system.
  prefs: []
  type: TYPE_NORMAL
- en: Reinforcement policy learning techniques
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Almost all recent dialogue policy learning works are based on reinforcement
    learning methods. Online learning is an ideal approach to get training samples
    iteratively for a reinforcement learning agent, but human labor is very limited.
    Zhang et al. ([2019c](#bib.bib454)) proposed Budget-Conscious Scheduling (BCS)
    to better utilize limited user interactions, where the user interaction is seen
    as the budget. The BCS used a probability scheduler to allocate the budget during
    training. Also, a controller decided whether to use real user interactions or
    simulated ones. Furthermore, a goal-based sampling model was applied to simulate
    the experiences for policy learning. Such a budget-controlling mechanism achieved
    ideal performance in the practical training process. Considering the difficulty
    of getting real online user interactions and the huge amount of annotated data
    required for training user simulators, Takanobu et al. ([2020](#bib.bib356)) proposed
    Multi-Agent Dialog Policy Learning, where they have two agents interacting with
    each other, performing both user and agent, learning the policy simultaneously.
    Furthermore, they incorporated a role-specific reward to facilitate role-based
    response generation. A High task completion rate was observed in experiments.
    Wang et al. ([2020d](#bib.bib387)) introduced Monte Carlo Tree Search with Double-q
    Dueling network (MCTS-DDU), where a decision-time planning was proposed instead
    of background planning. They used the Monte Carlo simulation to perform a tree
    search of the dialogue states. Gordon-Hall et al. ([2020](#bib.bib110)) trained
    expert demonstrators in a weakly supervised fashion to perform Deep Q-learning
    from Demonstrations (DQfD). Furthermore, Reinforced Fine-tune Learning was proposed
    to facilitate domain transfer. In reinforce dialogue policy learning, the agent
    usually receives feedback at the end of the dialogue, which is not efficient for
    learning. Huang et al. ([2020b](#bib.bib149)) proposed an innovative reward learning
    method that constrains the dialogue progress according to the expert demonstration.
    The expert demonstration could either be annotated or not, so the approach was
    not labor intensive. Wang et al. ([2020b](#bib.bib385)) proposed to co-generate
    the dialogue actions and responses to maintain the inherent semantic structures
    of dialogue. Similarly, Le et al. ([2020b](#bib.bib181)) proposed a unified framework
    to simultaneously perform dialogue state tracking, dialogue policy learning, and
    response generation. Experiments showed that unified frameworks have a better
    performance both in their sub-tasks and in their domain adaptability. Xu et al.
    ([2020a](#bib.bib426)) used a knowledge graph to provide prior knowledge of the
    action set and solved policy learning task in a graph-grounded fashion. By combining
    a knowledge graph, a long-term reward was obtained to provide the policy agent
    with a long-term vision while choosing actions. Also, the candidate actions were
    of higher quality due to prior knowledge. The policy learning was further performed
    in a more controllable way.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Natural Language Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Natural Language Generation (NLG) is the last module of a task-oriented dialogue
    system pipeline. It manages to convert the dialogue actions generated from the
    dialogue manager into a final natural language representation. E.g., Assuming
    “Inform (name = Wonder Woman; genre = Action; desti = Golden Village)" to be the
    dialogue action from policy learning module, then the NLG module converts it into
    language representations such as “There is an action movie named Wonder Woman
    at Golden Village."
  prefs: []
  type: TYPE_NORMAL
- en: 'Traditional NLG modules are pipeline systems. Defined by Siddharthan ([2001](#bib.bib326)),
    the standard pipeline of NLG consists of four components, as shown in Figure [15](#S3.F15
    "Figure 15 ‣ 3.4 Natural Language Generation ‣ 3 Task-oriented Dialogue Systems
    ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0e0556eda06576da7c8989b7bca0ecbc.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: The pipeline NLG system'
  prefs: []
  type: TYPE_NORMAL
- en: 'The core modules of this pipeline are Content Determination, Sentence Planning,
    and Surface Realization, as proposed by Reiter ([1994](#bib.bib296)). Cahill et al.
    ([1999](#bib.bib33)) further improved the NLG pipeline by adding three more components:
    lexicalization, referring expression generation, and aggregation. However, this
    model has a drawback that the input of the system is ambiguous.'
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end NLG techniques
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Deep learning methods were further applied to enhance the NLG performance and
    the pipeline is collapsed into a single module. End-to-end natural language generation
    has achieved promising improvements and is the most popular way to perform NLG
    in recent work. Wen et al. ([2015a](#bib.bib397)) argued that language generation
    should be fully data-driven and not depend on any expert rules. They proposed
    a statistical language model based on RNNs to learn response generation with semantic
    constraints and grammar trees. Additionally, they used a CNN reranker to further
    select better responses. Similarly, an LSTM model was used by Wen et al. ([2015b](#bib.bib398))
    to learn sentence planning and surface realization simultaneously. Tran and Nguyen
    ([2017](#bib.bib372)) further improved the generation quality on multiple domains
    using GRU. The proposed generator consistently generated high-quality responses
    on multiple domains. To improve the domain adaptability of recurrent models, Wen
    et al. ([2016b](#bib.bib400)) proposed to first train the recurrent language model
    on data synthesized from out-of-domain datasets, then finetune on a comparatively
    smaller in-domain dataset. This training strategy was proved effective in human
    evaluation. Context-awareness is important in dialogue response generation because
    only depending on the dialogue action of the current turn may cause illogical
    responses. Zhou et al. ([2016](#bib.bib461)) built an attention-based Context-Aware
    LSTM (CA-LSTM) combining target user questions, all semantic values, and dialogue
    actions as input to generate context-aware responses in QA. Likewise, Dušek and
    Jurčíček ([2016a](#bib.bib77)) concatenated the preceding user utterance with
    the dialogue action vector and fed it into an LSTM model. Dušek and Jurčíček ([2016b](#bib.bib78))
    put a syntax constraint upon their neural response generator. A two-stage sequence
    generation process was proposed. First, a syntax dependency tree was generated
    to have a structured representation of the dialogue utterance. The generator in
    the second stage integrated sentence planning and surface realization and produced
    natural language representations.
  prefs: []
  type: TYPE_NORMAL
- en: Robust natural language generation
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: More recent works have focused on the reliability and quality of generated responses.
    A tree-structured semantic representation was proposed by Balakrishnan et al.
    ([2019](#bib.bib14)) to achieve better content planning and surface realization
    performance. They further designed a novel beam search algorithm to improve the
    semantic correctness of the generated response. To avoid mistakes such as slot
    value missing or redundancy in generated responses, Li et al. ([2020d](#bib.bib207))
    proposed Iterative Rectification Network (IRN), a framework trained with supervised
    learning and finetuned with reinforcement learning. It iteratively rectified generated
    tokens by incorporating slot inconsistency penalty into its reward. Golovanov
    et al. ([2019](#bib.bib107)) applied large-scale pretrained models for NLG tasks.
    After comparing single-input and multi-input methods, they concluded that different
    types of input context will cause different inductive biases in generated responses
    and further proposed to utilize this characteristic to better adapt a pretrained
    model to a new task. Baheti et al. ([2020](#bib.bib13)) solved NLG reliability
    problem in conversational QA. Though with different pipeline structures, they
    used similar methods to increase the fluency and semantic correctness of the generated
    response. They proposed Syntactic Transformations (STs) to generate candidate
    responses and used a BERT to rank their qualities. These generated responses can
    be viewed as an augmentation of the original dataset to be further used in NLG
    model learning. Oraby et al. ([2019](#bib.bib264)) proposed a method to create
    datasets with rich style markups from easily available user reviews. They further
    trained multiple NLG models based on generated data to perform joint control of
    semantic correctness and language style. Similarly, Elder et al. ([2020](#bib.bib79))
    put forward a data augmentation approach which put a restriction on response generation.
    Though this restriction caused dull and less diverse responses, they argued that
    in task-oriented systems, reliability was more important than diversity.
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 End-to-end Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The modules discussed above can achieve good performance in their respective
    tasks, with the help of recent relevant advances. However, there exist two significant
    drawbacks in modular systems (Zhao and Eskenazi, [2016](#bib.bib455)): (1) Modules
    in many pipeline systems are sometimes not differentiable, which means that errors
    from the end are not able to be propagated back to each module. In real dialogue
    systems training, usually the only signal is the user response, while other supervised
    signals like dialogue states and dialogue actions are scarce. (2) Though the modules
    jointly contribute to the success of a dialogue system, the improvement of one
    module may not necessarily raise the response accuracy or quality of the whole
    system. This causes additional training of other modules, which is labor intensive
    and time-consuming. Additionally, due to the handcrafted features in pipeline
    task-oriented systems such as dialogue states, it is usually hard to transfer
    modular systems to another domain, since the predefined ontologies require modification.'
  prefs: []
  type: TYPE_NORMAL
- en: There exist two main methods for the end-to-end training of task-oriented dialogue
    systems. One is to make each module of a pipeline system differentiable, then
    the whole pipeline can be viewed as a large differentiable system and the parameters
    can be optimized by back-propagation in an end-to-end fashion (Le et al., [2020b](#bib.bib181)).
    Another way is to use only one end-to-end module to perform both knowledge base
    retrieval and response generation, which is usually a multi-task learning neural
    model.
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end trainable pipeline TOD
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The increasing applications of neural models have made it possible for modules
    to be differentiable. While many modules are easily differentiable, there remains
    one task that makes differentiation challenging: the knowledge base query. Many
    task-oriented dialogue systems require an external knowledge source to retrieve
    related knowledge facts required by the user. For example, in the restaurant table
    booking task, the knowledge fact can be an available slot of one specific restaurant.
    Traditional methods use a symbolic query to match entries based on their attributes.
    The system performs semantic parsing on the user message to represent a symbolic
    query according to the user goal (Li et al., [2017b](#bib.bib201); Williams and
    Zweig, [2016](#bib.bib407); Wen et al., [2016c](#bib.bib401)). However, this retrieval
    process is not differentiable, which prevents the whole framework from being end-to-end
    trainable. With the application of key-value memory networks (Miller et al., [2016](#bib.bib250)), Eric
    and Manning ([2017](#bib.bib81)) used the key-value retrieval mechanism to retrieve
    relevant facts. The proposed architecture was augmented with the attention mechanism
    to compute the relevance between utterance representations of dialogue and key
    representations of the knowledge base. Dhingra et al. ([2016](#bib.bib71)) presented
    a soft retrieval mechanism that uses a “soft" posterior distribution over the
    knowledge base to replace the symbolic queries. They further combined this soft
    retrieval mechanism into a reinforcement learning framework to achieve complete
    end-to-end training based on user feedback. Williams et al. ([2017](#bib.bib408))
    proposed Hybrid Code Networks (HCNs), which encoded domain-specific knowledge
    into software and system action templates, achieving the differentiability of
    the knowledge retrieval module. They did not explicitly model the dialogue states
    but instead learned the latent representation and optimized the HCN using supervised
    learning and reinforcement learning jointly. Ham et al. ([2020](#bib.bib121))
    used GPT-2 to form a neural pipeline and perform domain prediction, dialogue state
    tracking, policy learning, knowledge retrieval, and response generation in a pipeline
    fashion. The system could easily interact with external systems because it outputs
    explicit intermediate results from each module and thus being interpretable. Likewise, Hosseini-Asl
    et al. ([2020](#bib.bib141)) built a neural pipeline with GPT-2 and explicitly
    generated results for each neural module as well.'
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end trainable single module TOD
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: More recent works tend not to build their end-to-end systems in a pipeline fashion.
    Instead, they use complex neural models to implicitly represent the key functions
    and integrate the modules into one. Research in task-oriented end-to-end neural
    models focuses either on training methods or model architecture, which are the
    keys to response correctness and quality. Wang et al. ([2019a](#bib.bib388)) proposed
    an incremental learning framework to train their end-to-end task-oriented system.
    The main idea is to build an uncertainty estimation module to evaluate the confidence
    of appropriate responses generated. If the confidence score was higher than a
    threshold, then the response would be accepted, while a human response would be
    introduced if the confidence score was low. The agent could also learn from human
    responses using online learning. Dai et al. ([2020](#bib.bib61)) used model-agnostic
    meta-learning (MAML) to improve the adaptability and reliability jointly with
    only a handful of training samples in a real-life online service task. Similarly, Qian
    and Yu ([2019](#bib.bib280)) also trained the end-to-end neural model using MAML
    to facilitate the domain adaptation, which enables the model to first train on
    rich-resource tasks and then on new tasks with limited data. Lin et al. ([2020c](#bib.bib217))
    proposed Minimalist Transfer Learning (MinTL) to plug-and-play large-scale pretrained
    models for domain transfer in dialogue task completion. To maintain the sequential
    correctness of generated responses, Wu et al. ([2019b](#bib.bib415)) trained an
    inconsistent order detection module in an unsupervised fashion. This module detected
    whether an utterance pair is ordered or not to guide the task-completing agent
    towards generating more coherent responses. He et al. ([2020a](#bib.bib128)) proposed
    a “Two-Teacher One-Student" training framework. At the first stage, the two teacher
    models were trained in a reinforcement learning framework, with the objective
    of retrieving knowledge facts and generating human-like responses respectively.
    Then at the second stage, the student network was forced to mimic the output of
    the teacher networks. Thus, the expert knowledge of the two teacher networks was
    transferred to the student network. Balakrishnan et al. ([2019](#bib.bib14)) introduced
    a constrained decoding method to improve the semantic correctness of the responses
    generated by the proposed end-to-end system. Many end-to-end task-oriented systems
    used a memory module to store relevant knowledge facts and dialogue history. Chen
    et al. ([2019c](#bib.bib45)) argued that a single memory module was not enough
    for precise retrieval. They used two long-term memory modules to store the knowledge
    tuples and dialogue history respectively, and then a working memory was applied
    to control the token generation. Zhang et al. ([2020](#bib.bib452)) proposed LAtent
    BElief State (LABES) model, which treated the dialogue states as discrete latent
    variables to reduce the reliance on turn-level DST labels. To solve the data insufficiency
    problem in some tasks, Gao et al. ([2020a](#bib.bib99)) augmented the response
    generation model with a paraphrase model in their end-to-end system. The paraphrase
    model was jointly trained with the whole framework and it aimed to augment the
    training samples. Yang et al. ([2020](#bib.bib429)) leveraged the graph structure
    information of both a knowledge graph and the dialogue context-dependency tree.
    They proposed a recurrent cell architecture to learn representations on the graph
    and performed multi-hop reasoning to exploit the entity links in the knowledge
    graph. With the augmentation of graph information, consistent improvement was
    achieved on two task-oriented datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Research Challenges and Hot Topics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we review recent works in task-oriented dialogue systems and
    point out the frequently studied topics to provide some important research directions.
    This section can be seen as an augmentation of the literature review in previous
    sections discussing techniques developed for each module, and focuses more on
    some specific problems to be solved in the current research community.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.1 Pretrained Models for NLU
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Natural Language Understanding task converts the user message into a predefined
    format of semantic slots. A popular way to perform NLU is by finetuning large-scale
    pretrained language models. Wu and Xiong ([2020](#bib.bib412)) compared many pretrained
    language models including BERT-based and GPT-based systems in three subtasks of
    task-oriented dialogue systems - domain identification, intent detection, and
    slot tagging. This empirical paper is aimed to provide insights and guidelines
    in pretrained model selection and application for related research. Wu et al.
    ([2020a](#bib.bib414)) pretrained TOD-BERT and outperformed strong baselines in
    the intent detection task. The model proposed also had a strong few-shot learning
    ability to alleviate the data insufficiency problem. Coope et al. ([2020](#bib.bib58))
    proposed Span-ConveRT, which was a pretrained model designed for slot filling
    task. It viewed the slot filling task as a turn-based span extraction problem
    and also performed well in the few-shot learning scenario.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.2 Domain Transfer for NLU
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another challenge or hot topic in NLU research is the domain transfer problem,
    which is also the key issue of task-oriented dialogue systems. Hakkani-Tür et al.
    ([2016](#bib.bib120)) built an RNN-LSTM architecture for multitask learning of
    domain classification, intent detection, and slot-filling problem. Training samples
    from multiple domains were combined in a single model where respective domain
    data reinforces each other. Bapna et al. ([2017](#bib.bib18)) used a multi-task
    learning framework to leverage slot name encoding and slot description encoding,
    thus implicitly aligning the slot-filling model across domains. Likewise, Lee
    and Jha ([2019](#bib.bib186)) also applied slot description to exploit the similar
    semantic concepts between slots of different domains, which solved the sub-optimal
    concept alignment and long training time problems encountered in past works involving
    multi-domain slot-filling.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.3 Domain Transfer for DST
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Domain adaptability is also a significant topic for dialogue state trackers.
    The domain transfer in DST is challenging due to three main reasons (Ren et al.,
    [2018](#bib.bib298)): (1) Slot values in ontologies are different when the domain
    changes, which accounts for the incompatibility of models. (2) When the domain
    changes, the slot number will also change, causing different numbers of model
    parameters. (3) Hand-crafted lexicons make it difficult for generalization over
    domains. Mrkšić et al. ([2015](#bib.bib259)) used delexicalized n-gram features
    to solve the domain incompatibility problem by replacing all specified slot names
    and values with generic symbols. Lin et al. ([2020c](#bib.bib217)) introduced
    Levenshtein belief spans (Lev), which were short context spans relating to the
    user message. Different from previous methods which generated dialogue state from
    scratch, they performed substitution (SUB), deletion (DEL), and insertion (INS)
    based on past states to alleviate the dependency on annotated in-domain training
    samples. Huang et al. ([2020c](#bib.bib150)) applied model-agnostic meta-learning
    (MAML) to first learn on several source domains and then adapt on the target domain,
    while Campagna et al. ([2020](#bib.bib34)) improved the zero-shot transfer learning
    by synthesizing in-domain data using an abstract conversation model and the domain
    ontology. Ouyang et al. ([2020](#bib.bib266)) modeled explicit slot connections
    to exploit the existing slots appearing in other domains. Thus, the tracker could
    copy slot values from the connected slots directly, alleviating the burden of
    reasoning and learning. Wang et al. ([2020e](#bib.bib391)) proposed Value Normalization
    (VN) to convert supporting dialogue spans into state values and could achieve
    high accuracy with only 30% available ontology.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.4 Tracking Efficiency for DST
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Tracking efficiency is another hot topic in dialogue state tracking challenges.
    Usually, there are multiple states within a dialogue, so how to compute the slot
    values without any redundant steps becomes very significant when attempting to
    reduce the reaction time of a system. Kim et al. ([2019](#bib.bib170)) argued
    that predicting the dialogue state from scratch at every turn was not efficient.
    They proposed to first predict the operations to be taken on each of the slots
    (i.e., Carryover, Delete, Dontcare, Update), and then perform respective operations
    as predicted. Ouyang et al. ([2020](#bib.bib266)) used a slot connection mechanism
    to directly copy slot values from the source slot, which reduced the expense of
    reasoning. Hu et al. ([2020](#bib.bib142)) and Wang et al. ([2020e](#bib.bib391))
    proposed slot attention to calculate the relations between the slot and dialogue
    context, thus only focusing on the relevant slots at each turn.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.5 Training Environment for PL
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The environment of the Policy Learning framework has been a long-existing problem.
    Li et al. ([2017b](#bib.bib201)) built a user simulator to model the user feedback
    as the reward signal of an environment. They modeled a stack-like user agenda
    to iteratively change the user goal and thus shifting the dialogue states. While
    using a user simulator for environment modeling seems to be promising for that
    it involves less human interaction, Zhang et al. ([2019c](#bib.bib454)) argued
    that training a user simulator required a large amount of annotated data. Takanobu
    et al. ([2020](#bib.bib356)) proposed Multi-Agent Dialog Policy Learning, where
    they have two agents interact with each other, performing both user and agent,
    learning policy simultaneously. Furthermore, they incorporated a role-specific
    reward to facilitate role-based response generation and here both agents also
    acted as the environment of the other one.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.6 Response Consistency for NLG
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Response consistency in NLG is a challenging problem since it cannot be solved
    by simply augmenting the training samples. Instead, additional corrections or
    regulations should be designed. Wen et al. ([2015b](#bib.bib398)) proposed the
    Semantically Controlled LSTM (SC-LSTM) which used a semantic planning gate to
    control the retention or abandonment of dialogue actions thus ensuring the response
    consistency. Likewise, Tran and Nguyen ([2017](#bib.bib372)) also applied a gating
    mechanism to jointly perform sentence planning and surface realization where dialogue
    action features were gated before entering GRU cells. Li et al. ([2020d](#bib.bib207))
    proposed Iterative Rectification Network (IRN), which combined a slot inconsistency
    reward into the reinforcement learning framework. Thus, the model iteratively
    checked the correctness of slots and corresponding values.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.7 End-to-end Task-oriented Dialogue Systems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'End-to-end systems are usually fully data-driven, which contributes to their
    robust and natural responses. However, because of the finiteness of annotated
    training samples, a hot research topic is figuring out how to increase the response
    quality of end-to-end task-oriented dialogue systems with limited data. Using
    rule-based methods to constrain response generation is a way to improve response
    quality. Balakrishnan et al. ([2019](#bib.bib14)) used linearized tree-structured
    representation as input to obtain control over discourse-level and sentence-level
    semantic concepts. Kale and Rastogi ([2020](#bib.bib162)) used templates to improve
    the semantic correctness of generated responses. They broke down the response
    generation into a two-stage process: first generating semantically correct but
    possibly incoherent responses based on the slots, with the constraint of templates;
    then in the second stage, pretrained language models were applied to re-organize
    the generated utterances into coherent ones. Training the network with reinforcement
    learning was another strategy to alleviate the reliance on annotated data. He
    et al. ([2020a](#bib.bib128)) trained two teacher networks using a reinforcement
    learning framework with the objectives of knowledge retrieval and response generation
    respectively. Then the student network learns to produce responses by mimicking
    the output of teacher networks. Training the network in a supervised way, Dai
    et al. ([2020](#bib.bib61)) alternatively tried to optimize the learning strategy
    to improve the learning efficiency of models given limited data. They combined
    the meta-learning algorithm with human-machine interaction and achieved significant
    improvement compared with strong baselines not trained with the meta-learning
    algorithms. A more direct way to solve the data finiteness problem in supervised
    learning was augmenting the dataset (Elder et al., [2020](#bib.bib79)), which
    also improved the response quality to some extent. Additionally, pretraining large-scale
    models on common corpus and then applying them in a domain that lacks annotated
    data is a popular approach in recent years (Henderson et al., [2019b](#bib.bib136);
    Mehri et al., [2019](#bib.bib244); Bao et al., [2019b](#bib.bib17)).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.6.8 Retrieval Methods for Task-oriented Dialogue Systems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Retrieval-based methods are rare in task-oriented systems for the insufficiency
    of candidate entries to cover all possible responses which usually involve specific
    knowledge from external knowledge-base. However, Henderson et al. ([2019b](#bib.bib136))
    argued that in some situations not relating with specific knowledge facts, retrieval-based
    methods were more precise and effective. They first pretrained the response selection
    model on general domain corpora and then finetuned on small target domain data.
    Experiments on six datasets from different domains proved the effectiveness of
    the pretrained response selection model. Lu et al. ([2019b](#bib.bib231)) constructed
    Spatio-temporal context features to facilitate response selection, and achieved
    significant improvements on the Ubuntu IRC dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Open-Domain Dialogue Systems
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section discusses open-domain dialogue systems, which are also called chit-chat
    dialogue systems or non-task-oriented dialogue systems. Almost all state-of-the-art
    open-domain dialogue systems are based on neural methods. We organize this section
    by first briefly introducing the concepts of different branches of open-domain
    dialogue systems, and then we focus on different research challenges and hot topics.
    We view these challenges and hot topics as different research directions in open-domain
    dialogue systems.
  prefs: []
  type: TYPE_NORMAL
- en: 'Instead of managing to complete tasks, open-domain dialogue systems aim to
    perform chit-chat with users without the task and domain restriction (Ritter et al.,
    [2011](#bib.bib300)) and are usually fully data-driven. Open-domain dialogue systems
    are generally divided into three categories: generative systems, retrieval-based
    systems, and ensemble systems. Generative systems apply sequence-to-sequence models
    to map the user message and dialogue history into a response sequence that may
    not appear in the training corpus. By contrast, retrieval-based systems try to
    find a pre-existing response from a certain response set. Ensemble systems combine
    generative methods and retrieval-based methods in two ways: retrieved responses
    can be compared with generated responses to choose the best among them; generative
    models can also be used to refine the retrieved responses (Zhu et al., [2018](#bib.bib466);
    Song et al., [2016](#bib.bib337); Qiu et al., [2017](#bib.bib284); Serban et al.,
    [2017b](#bib.bib314)). Generative systems can produce flexible and dialogue context-related
    responses while sometimes they lack coherence and tend to make dull responses.
    Retrieval-based systems select responses from human response sets and thus are
    able to achieve better coherence in surface-level language. However, retrieval
    systems are restricted by the finiteness of the response sets and sometimes the
    responses retrieved show a weak correlation with the dialogue context (Zhu et al.,
    [2018](#bib.bib466)).'
  prefs: []
  type: TYPE_NORMAL
- en: In the next few subsections, we discuss some research challenges and hot topics
    in open-domain dialogue systems. We aim to to help researchers quickly grasp the
    current research trends via a systematic discussion on articles solving certain
    problems.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Context Awareness
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Dialogue context consists of user and system messages and is an important source
    of information for dialogue agents to generate responses because dialogue context
    decides the conversation topic and user goal (Serban et al., [2017a](#bib.bib313)).
    A context-aware dialogue agent responds not only depending on the current message
    but also based on the conversation history. The earlier deep learning-based systems
    added up all word representations in dialogue history or used a fixed-size window
    to focus on the recent context (Sordoni et al., [2015b](#bib.bib340); Li et al.,
    [2015](#bib.bib191)). Serban et al. ([2016](#bib.bib312)) proposed Hierarchical
    Recurrent Encoder-Decoder (HRED), which was ground-breaking in building context-awareness
    dialogue systems. They built a word-level encoder to encode utterances and a turn-level
    encoder to further summarize and deliver the topic information over past turns.
    Xing et al. ([2018](#bib.bib424)) augmented the hierarchical neural networks with
    the attention mechanism to help the model focus on more meaningful parts of dialogue
    history.
  prefs: []
  type: TYPE_NORMAL
- en: 'Both generative and retrieval-based systems rely heavily on dialogue context
    modeling. Shen et al. ([2019](#bib.bib321)) proposed Conversational Semantic Relationship
    RNN (CSRR) to model the dialogue context in three levels: utterance-level, pair-level,
    and discourse-level, capturing content information, user-system topic, and global
    topic respectively. Zhang et al. ([2019a](#bib.bib446)) argued that the hierarchical
    encoder-decoder does not lay enough emphasis on certain parts when the decoder
    interacted with dialogue contexts. Also, they claimed that attention-based HRED
    models also suffered from position bias and relevance assumption insufficiency
    problems. Therefore, they proposed ReCoSa, whose architecture was inspired by
    the transformer. The model first used a word-level LSTM to encode dialogue contexts,
    and then self-attention was applied to update the utterance representations. In
    the final stage, an encoder-decoder attention was computed to facilitate the response
    generation process. Additionally, Mehri et al. ([2019](#bib.bib244)) examined
    several applications of large-scale pretrained models in dialogue context learning,
    providing guidance for large-scale network selection in context modeling.'
  prefs: []
  type: TYPE_NORMAL
- en: Some works propose structured attention to improve context-awareness. Qiu et al.
    ([2020](#bib.bib283)) learned structured dialogue context by combining structured
    attention with a Variational Recurrent Neural Network (VRNN). Comparatively, Ferracane
    et al. ([2019](#bib.bib90)) examined the RST discourse tree model proposed by Liu
    and Lapata ([2018](#bib.bib226)) and observed little or even no discourse structures
    in the learned latent tree. Thus, they argued that structured attention did not
    benefit dialogue modeling and sometimes might even harm the performance.
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, Feng et al. ([2020b](#bib.bib88)) not only utilized dialogue
    history, but also future conversations. Considering that in real inference situations
    dialogue agents cannot be explicitly aware of future information, they first trained
    a scenario-based model jointly on past and future context and then used an imitation
    framework to transfer the scenario knowledge to a target network.
  prefs: []
  type: TYPE_NORMAL
- en: Better context modeling improves the response selection performance in retrieval-based
    dialogue systems (Jia et al., [2020](#bib.bib158)). Tao et al. ([2019](#bib.bib364))
    proposed Interaction-over-Interaction network (IoI), which consisted of multiple
    interaction blocks to perform deeper interactions between dialogue context and
    candidate responses. Jia et al. ([2020](#bib.bib158)) organized the dialogue history
    into conversation threads by performing classifications on their dependency relations.
    They further used a pretrained Transformer model to encode the threads and candidate
    responses to compute the matching score. Lin et al. ([2020b](#bib.bib216)) argued
    that response-retrieval datasets should not only be annotated with relevant or
    irrelevant responses. Instead, a greyscale metric should be used to measure the
    relevance degree of a response given the dialogue context, thus increasing the
    context-awareness ability of retrieval models.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue rewriting problem aims to convert several messages into a single message
    conveying the same information and dialogue context awareness is very crucial
    to this task (Xu et al., [2020b](#bib.bib427)). Su et al. ([2019a](#bib.bib343))
    modeled multi-turn dialogues via dialogue rewriting and benefited from the conciseness
    of rewritten utterances.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Response Coherence
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Coherence is one of the qualities that a good generator seeks (Stent et al.,
    [2005](#bib.bib342)). Coherence means maintaining logic and consistency in a dialogue,
    which is essential in an interaction process for that a response with weak consistency
    in logic and grammar is hard to understand. Coherence is a hot topic in generative
    systems but not in retrieval-based systems because candidate responses in retrieval
    methods are usually human responses, which are naturally coherent.
  prefs: []
  type: TYPE_NORMAL
- en: Refining the order or granularity of sentence functions is a popular strategy
    for improving the language coherence. Wu et al. ([2019b](#bib.bib415)) improved
    the response coherence via the task of inconsistent order detection. The dialogue
    systems learned response generation and order detection jointly, which was self-supervised
    multi-task learning. Xu et al. ([2019](#bib.bib425)) presented the concept of
    meta-words. Meta-words were diverse attributes describing the response. Learning
    dialogue based on meta-words helped promote response generation in a more controllable
    way. Liu et al. ([2019](#bib.bib222)) used three granularities of encoders to
    encode raw words, low-level clusters, and high-level clusters. The architecture
    was called Vocabulary Pyramid Network (VPN), which performed a multi-pass encoding
    and decoding process on hierarchical vocabularies to generate coherent responses.
    Shen et al. ([2019](#bib.bib321)) also built a three-level hierarchical dialogue
    model to capture richer features and improved the response quality. Ji et al.
    ([2020](#bib.bib155)) built Cross Copy Networks (CCN), which used a copy mechanism
    to copy from similar dialogues based on the current dialogue context. Thus, the
    system benefited from the pre-existing coherent responses, which alleviated the
    need of performing the reasoning process from scratch.
  prefs: []
  type: TYPE_NORMAL
- en: Many work employ strategies to achieve response coherence on a higher level,
    which improves the overall quality of the generated responses. Li et al. ([2019b](#bib.bib199))
    improved the logical consistency of generated utterances by incorporating an unlikelihood
    loss to control the distribution mismatches. Bao et al. ([2019a](#bib.bib16))
    proposed a Generation-Evaluation framework that evaluated the qualities, including
    coherence, of the generated response. The feedback was further seen as a reward
    signal in the reinforcement learning framework and guided to a better dialogue
    strategy via policy gradient, thus improving the response quality. Gao et al.
    ([2020b](#bib.bib101)) raised response quality by ranking generated responses
    based on user feedbacks like upvotes, downvotes, and comments on social networks.
    Zhu et al. ([2018](#bib.bib466)) built a retrieval-enhanced generation model,
    which enhanced the generated responses in two ways. First, a discriminator was
    trained with the help of a retrieval system, and then the generator was trained
    in a GAN framework under the supervision signal of a discriminator. Second, retrieved
    responses were also used as a part of the generator input to provide a coherent
    example for the generator. Xu et al. ([2020a](#bib.bib426)) achieved a global
    coherent dialogue by constructing a knowledge graph from corpora. They further
    performed graph walks to decide “what to say" and “how to say", thus improving
    the dialogue flow coherence. Mesgar et al. ([2019](#bib.bib245)) proposed an assessment
    approach for dialogue coherence evaluation by combining the dialogue act prediction
    in a multi-task learning framework and learned rich dialogue representations.
  prefs: []
  type: TYPE_NORMAL
- en: There also evolve some data-wise methods for better response coherence. Bi et al.
    ([2019](#bib.bib22)) proposed to annotate sentence functions in existing conversation
    datasets to improve the sentence logic and coherence of generated responses. Akama
    et al. ([2020](#bib.bib3)) focused on data effectiveness as well. They filtered
    out low-quality utterance pairs by scoring the relatedness and connectivity, which
    was proved to be effective in improving the response coherence. Akama et al. ([2020](#bib.bib3))
    presented a method for evaluating dataset utterance pairs’ quality in terms of
    connectedness and relatedness. The proposed scoring technique is based on research
    findings that have been widely disseminated in the conversation and linguistics
    communities. Lison and Bibauw ([2017](#bib.bib219)) included a weighting model
    in their neural architecture. The weighting model, which is based on conversation
    data, assigns a numerical weight to each training sample that reflects its intrinsic
    quality for dialogue modeling and achieved good result in experiments.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Response Diversity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The Bland and generic response is a long-existing problem in generative dialogue
    systems. Because of the high frequency of generic responses like “I don’t know"
    in training samples and the beam search decoding scheme of neural sequence-to-sequence
    models, generative dialogue systems tend to respond with universally acceptable
    but meaningless utterances (Serban et al., [2016](#bib.bib312); Vinyals and Le,
    [2015](#bib.bib379); Sordoni et al., [2015b](#bib.bib340)). For example, to respond
    to the user message “I really want to have a meal", the agent tends to choose
    simple responses like “It’s OK" instead of responding with more complicated sentences
    like recommendations and suggestions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Earlier works solve this challenge by modifying the decoding objective or adding
    a reranking process. Li et al. ([2015](#bib.bib191)) replaced the traditional
    likelihood objective $p(R|C)$ with mutual information. The optimization of mutual
    information objective aims to achieve a Maximum Mutual Information (MMI). Specifically,
    the task is to find a best response $R$ based on the dialogue context $C$, in
    order to maximize their mutual information:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\hat{R}&amp;=arg\max_{R}{log\frac{P(C,R)}{P(C)P(R)}}\\ &amp;=arg\max_{R}{logP(R&#124;C)-logP(R)}\end{split}$
    |  | (49) |'
  prefs: []
  type: TYPE_TB
- en: 'The objective $p(R|C)$ causes the model to choose responses with high probability
    even if the response is unconditionally frequent in the dataset, thus causing
    it to ignore the content of $C$. Maximizing the mutual information as Equation
    ([49](#S4.E49 "In 4.3 Response Diversity ‣ 4 Open-Domain Dialogue Systems ‣ Recent
    Advances in Deep Learning Based Dialogue Systems: A Systematic Survey")) solves
    this issue by achieving a trade-off between safety and relativity.'
  prefs: []
  type: TYPE_NORMAL
- en: With a similar intuition as described above, increasing response diversity by
    modifying the decoding scheme at inference time has been explored in earlier works. Vijayakumar
    et al. ([2016](#bib.bib378)) combined a dissimilarity term into the beam search
    objective and proposed Diverse Beam Search (DBS) to promote diversity. Similarly, Shao
    et al. ([2017](#bib.bib319)) proposed a stochastic beam search algorithm by performing
    stochastic sampling when choosing top-B responses. In the beam search algorithm,
    siblings sharing the same parent nodes tended to guide to similar sequences. Inspired
    by this, Li et al. ([2016c](#bib.bib194)) penalized siblings sharing the same
    parent nodes using an additional term in the beam search objective. This encouraged
    the algorithm to search more diverse paths by expanding from different parent
    nodes. Some works further added a reranking stage to select more diverse responses
    in the generated N-best list (Li et al., [2015](#bib.bib191); Sordoni et al.,
    [2015b](#bib.bib340); Shao et al., [2017](#bib.bib319)).
  prefs: []
  type: TYPE_NORMAL
- en: A user message can be mapped into multiple acceptable responses, which is also
    known as the one-to-many mapping problem. Qiu et al. ([2019](#bib.bib282)) considered
    the one-to-many mapping problem in open-domain dialogue systems and proposed a
    two-stage generation model to increase response diversity - the first stage extracting
    common features of multiple ground truth responses and the second stage extracting
    the distinctive ones. Ko et al. ([2020](#bib.bib171)) solved the one-to-many mapping
    problem via a classification task to learn latent semantic representations. So
    that given one example response, different ones could be generated by exploring
    the semantically close vectors in the latent space.
  prefs: []
  type: TYPE_NORMAL
- en: Different training strategies have been proposed to increase response diversity.
    Bao et al. ([2019a](#bib.bib16)) used human instinct or pre-defined objective
    as a reward signal in a reinforcement learning setting to prompt the agent to
    avoid generating dull responses. Still, in a reinforcement learning framework, Zhu
    et al. ([2020](#bib.bib467)) performed counterfactual reasoning to explore the
    potential response space. Given a pre-existing response, the model inferred another
    policy, which represented another possible response, thus increasing the response
    diversity. He and Glass ([2019](#bib.bib127)) used a negative training method
    to minimize the generation of bland responses. They first collected negative samples
    and then gave negative training signals based on these samples to fine-tune the
    model, impeding the model to generate bland responses. To achieve a better performance, Du
    and Black ([2019](#bib.bib76)) synthesized different dialogue models designed
    for response diversity based on boosting training. The ensemble model significantly
    outperformed each of its base models.
  prefs: []
  type: TYPE_NORMAL
- en: Utilizing external knowledge sources is another way to improve the diversity
    of generated responses because it can enrich the content. Wu et al. ([2020b](#bib.bib416))
    built a common-sense dialogue generation model which seeks highly related knowledge
    facts based on the dialogue history. Likewise, Su et al. ([2020](#bib.bib344))
    incorporated external knowledge sources to diversify the response generation,
    but the difference was that they utilized non-conversational texts like news articles
    as relevant knowledge facts, which were obviously easier to obtain. Tian et al.
    ([2019](#bib.bib369)) used a memory module to abstract and store useful information
    in the training corpus for generating diverse responses.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach to diversify the response generation is to make modifications
    to the training corpus. Csáky et al. ([2019](#bib.bib59)) solved the challenge
    by filtering out the generic responses in the dataset using an entropy-based algorithm,
    which was simple but effective. Augmented with human feedback data, Gao et al.
    ([2020b](#bib.bib101)) proposed that the generated responses could be reranked
    via a response ranking framework trained on the human feedback data and responses
    with higher quality including diversity were selected. Stasaski et al. ([2020](#bib.bib341))
    proposed to change the data collection pipeline by iteratively computing the diversity
    of responses from different human participants in dataset construction and selected
    those participants who tend to generate informative and diverse responses.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Speaker Consistency and Personality-based Response
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In open-domain dialogue systems, one big issue is that the responses are entirely
    learned from training data. The inconsistent response may be received when asking
    the system about some personal facts (e.g., age, hobbies). If the dataset contains
    multiple utterance pairs about the query of age, then the response generated tends
    to be shifting, which is unacceptable because personal facts are usually not random.
    Thus, for a data-driven chatbot, it is necessary to be aware of its role and respond
    based on a fixed persona.
  prefs: []
  type: TYPE_NORMAL
- en: Explicitly modeling the persona is the main strategy in recent works. Liu et al.
    ([2020b](#bib.bib225)) proposed a persona-based dialogue generator consisting
    of a Receiver and a Transmitter. The receiver was responsible for modeling the
    interlocutor’s persona through several turns’ chat while Transmitter generated
    utterances based on the persona of agent and interlocutor, together with conversation
    content. The proposed model supported conversations between two persona-based
    chatbots by modeling each other’s persona. Without training with additional Natural
    Language Inference labels, Kim et al. ([2020](#bib.bib167)) built an imaginary
    listener following a normal generator, which reasoned over the tokens generated
    by the generator and predicted a posterior distribution over the personas in a
    certain space. After that, a self-conscious speaker generated tokens aligned with
    the predicted persona. Likewise, Boyd et al. ([2020](#bib.bib28)) used an augmented
    GPT-2 to reason over the past conversations and model the target actor’s persona,
    conditioning on which persona consistency was achieved.
  prefs: []
  type: TYPE_NORMAL
- en: Responding with personas needs to condition on some persona descriptions. For
    example, to build a generous agent, descriptions like “I am a generous person"
    are needed as a part of the model input. However, these descriptions require hand-crafted
    feature design, which is labor intensive. Madotto et al. ([2019](#bib.bib237))
    proposed to use Model-Agnostic Meta-Learning (MAML) to adapt to new personas with
    only a few training samples and needed no persona description. Majumder et al.
    ([2020a](#bib.bib238)) relied on external knowledge sources to expand current
    persona descriptions so that richer persona descriptions were obtained, and the
    model could associate current descriptions with some commonsense facts.
  prefs: []
  type: TYPE_NORMAL
- en: Song et al. ([2020a](#bib.bib335)) argued that traditional persona-based systems
    were one-stage systems and the responses they generated still contain many persona
    inconsistent words. To tackle this issue, they proposed a three-stage architecture
    to ensure persona consistency. A generate-delete-rewrite mechanism was implemented
    to remove the unacceptable words generated in prototype responses and rewrite
    them.
  prefs: []
  type: TYPE_NORMAL
- en: 4.5 Empathetic Response
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Empathy means being able to sense other people’s feelings (Ma et al., [2020b](#bib.bib236)).
    An empathetic dialogue system can sense the user’s emotional changes and produce
    appropriate responses with a certain sentiment. This is an essential topic in
    chit-chat systems because it directly affects the user’s feeling and to some extent
    decides the response quality. Industry systems such as Microsoft’s Cortana, Facebook
    M, Google Assistant, and Amazon’s Alexa are all equipped with empathy modules (Wang
    et al., [2020g](#bib.bib395)).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two ways to generate utterances with emotion: one is to use explicit
    sentiment words as a part of input; another is to implicitly combine neural words (Song
    et al., [2019](#bib.bib338)). Song et al. ([2019](#bib.bib338)) proposed a unified
    framework that uses a lexicon-based attention to explicitly plugin emotional words
    and a sequence-level emotion classifier to classify the output sequence, implicitly
    guiding the generator to generate emotional responses through backpropagation.
    Zhong et al. ([2020](#bib.bib460)) used CoBERT for persona-based empathetic response
    selection and further investigated the impact of persona on empathetic responses.
    Smith et al. ([2020](#bib.bib333)) blended the skills of being knowledgeable,
    empathetic, and role-aware in one open-domain conversation model and overcame
    the bias issue when blending these skills.'
  prefs: []
  type: TYPE_NORMAL
- en: Since the available datasets for empathetic conversations are scarce, Rashkin
    et al. ([2018](#bib.bib291)) provided a new benchmark and dataset for empathetic
    dialogue systems. Oraby et al. ([2019](#bib.bib264)) constructed a dialogue dataset
    with rich emotional markups from user reviews and further proposed a novel way
    to generate similar datasets with rich markups.
  prefs: []
  type: TYPE_NORMAL
- en: 4.6 Controllable Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Controllable dialogue generation is an important line of work in open-domain
    dialogue systems since solely learning from data sample distributions causes many
    uncertain responses. Some of the dialogue systems are grounded on some external
    knowledge such as knowledge graph and documents. However, grounding alone without
    explicit control and semantic targeting may induce output that is accurate but
    vague.
  prefs: []
  type: TYPE_NORMAL
- en: We may get some inspirations from the prior work on language generation and
    machine translation since similarly to dialogue systems they are generation-based
    or seq-to-seq problems. Some related work aimed to enforce user-specified constraints,
    most notably using lexical constraints (Hokamp and Liu, [2017](#bib.bib139); Hu
    et al., [2019](#bib.bib143); Miao et al., [2019](#bib.bib248)). These methods
    exclusively use constraints at inference time. Constraints can be included into
    the latent space during training, resulting in better predictions. Other studies
    (See et al., [2019](#bib.bib311); Keskar et al., [2019](#bib.bib165); Tang et al.,
    [2019](#bib.bib362)) have looked at non-lexical constraints, but they haven’t
    looked into how they can help with grounding external knowledge. These publications
    also assume that the system can always be given (gold) constraints, which limits
    the ability to demonstrate larger benefits of the approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Controllable text generation has also been used to extract high-level style
    information from contextual information in text style transfer (Hu et al., [2017](#bib.bib144))
    and other tasks (Ficler and Goldberg, [2017](#bib.bib91); Dong et al., [2017](#bib.bib74);
    Gao et al., [2019](#bib.bib100)), allowing the former to be independently modified.
    Zhao et al. ([2018](#bib.bib457)) learns an interpretable representation for dialogue
    systems using discrete latent actions. While existing studies employ “style" descriptors
    (e.g., positive/negative, formal/informal) as control signals, Wu et al. ([2020c](#bib.bib419))
    use specific lexical constraints to regulate creation, allowing for finer semantic
    control. Content planned generation (Wiseman et al., [2017](#bib.bib411); Hua
    and Wang, [2019](#bib.bib145)) focuses response generation on a small number of
    essential words or table entries. This line of work, on the other hand, does not
    require consideration of the discourse context, which is critical for response
    generation.
  prefs: []
  type: TYPE_NORMAL
- en: 4.7 Conversation Topic
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Daily chats of people usually involve a topic or goal. Actually, a topic or
    goal is the key to keep each participant engaged in conversations and thus being
    essential to a chatbot. In real applications, a good topic model helps to retrieve
    related knowledge and guide the conversation instead of passively responding to
    the user’s message (Xing et al., [2017](#bib.bib423)). For example, if the user
    mentions “I like sunny days", a topic-aware system may reason over relevant external
    knowledge and produce responses like “I know there is a nice park near the seaside,
    have you ever been there before?". Thus, the agent pushes the conversation to
    a more engaging stage and enriches the dialogue content.
  prefs: []
  type: TYPE_NORMAL
- en: Almost all topic-aware dialogue agents need to model explicit topics, which
    can be entities from external knowledge-base, or topic embeddings that have some
    semantic meaning. Wu et al. ([2019c](#bib.bib417)) tried to change the traditional
    passive response fashion and radically pursue active guidance of conversation.
    The dialogue agent consists of a leader and a follower, where the leader reasons
    over a knowledge graph and decides the conversation topic. Likewise, a common-sense
    knowledge graph was used by Liu et al. ([2020c](#bib.bib227)) to lead the conversation
    topic and make recommendations. Tang et al. ([2019](#bib.bib362)) built a topic-aware
    retrieval-based chatbot. It aimed to guide the conversation topic to the target
    one step by step. It used a keyword predictor to predict turn-level keywords and
    selected the discourse-level keyword based on that. The discourse-level keyword
    was further fed into the retrieval model to retrieve responses regarding a certain
    topic. Chen and Yang ([2020](#bib.bib40)) built a multi-view sequence-to-sequence
    model to learn dialogue topics by first extracting dialogue structures of unstructured
    chit-chat dialogues, then generating topic summaries using BART decoder.
  prefs: []
  type: TYPE_NORMAL
- en: In some applications of certain scenarios the conversation topic is essential,
    and these are where the topic-aware dialogue agents can be applied to. Zhang and
    Danescu-Niculescu-Mizil ([2020](#bib.bib448)) studied the topic-aware chatbot
    in counseling conversations. In counseling conversations, the agent led the dialogue
    topic by deciding between empathetically addressing a situation within the current
    range and moving on to a new target resolution. Cao et al. ([2019](#bib.bib35))
    studied chatbots in the psychotherapy treatment area and built a topic prediction
    model to forecast the behavior codes for upcoming conversations, thus guiding
    the dialogue.
  prefs: []
  type: TYPE_NORMAL
- en: 4.8 Knowledge-Grounded System
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: External knowledge such as common-sense knowledge is a significant source of
    information when organizing an utterance. Humans associate current conversation
    context with their experiences and memories and produce meaningful related responses,
    such capability results in the gap between human and machine chit-chat systems.
    As discussed, the earlier chit-chat systems are simply variants of machine translation
    systems, which can be viewed as sequence-to-sequence language models. However,
    dialogue generation is much more complicated than machine translation because
    of the higher freedom and vaguer constraints. Thus, chit-chat systems cannot simply
    consist of a sequence-to-sequence mapping since appropriate and informative responses
    are always related to some external common-sense knowledge. Instead, there must
    be a module incorporating world knowledge.
  prefs: []
  type: TYPE_NORMAL
- en: 'Many researchers devoted their research efforts to building knowledge-grounded
    dialogue systems. A representative model is memory networks introduced in Section [2.4](#S2.SS4
    "2.4 Memory Networks ‣ 2 Neural Models in Dialogue Systems ‣ Recent Advances in
    Deep Learning Based Dialogue Systems: A Systematic Survey"). Knowledge grounded
    systems use Memory Networks to store external knowledge and the generator retrieves
    relevant knowledge facts from it at the generation stage (Ghazvininejad et al.,
    [2018](#bib.bib104); Vougiouklis et al., [2016](#bib.bib381); Yin et al., [2015](#bib.bib435)). Tian
    et al. ([2019](#bib.bib369)) built a memory-augmented conversation model. The
    proposed model abstracted from the training samples and stored useful ones in
    the memory module. Zhao et al. ([2020b](#bib.bib459)) built a knowledge-grounded
    dialogue generation system based on GPT-2\. They combined a knowledge selection
    module into the language model and learned knowledge selection and response generation
    simultaneously. Lin et al. ([2020a](#bib.bib214)) proposed Knowledge-Interaction
    and knowledge Copy (KIC). They performed recurrent knowledge interactions during
    the decoding phase to compute an attention distribution over the memory. Then
    they performed knowledge copy using a knowledge-aware pointer network to copy
    knowledge words according to the attention distribution computed.'
  prefs: []
  type: TYPE_NORMAL
- en: Documents contain large amount of knowledge facts, but they have a drawback
    that they are usually too long to retrieve useful information from (Li et al.,
    [2019d](#bib.bib208)). Li et al. ([2019d](#bib.bib208)) built a multi-turn document-grounded
    system. They used an incremental transformer to encode multi-turns’ dialogue context
    and respective documents retrieved. In the generation phase, they designed a two-stage
    generation scheme. The first stage took dialogue context as input and generated
    coherent responses; the second stage utilized both the utterance from the first
    stage and the document retrieved for the current turn for response generation.
    In this case, selecting knowledge based on both dialogue context and generated
    response was called posterior knowledge selection, while selecting knowledge with
    only dialogue context was called prior knowledge selection, which only utilized
    prior information. Wang et al. ([2020c](#bib.bib386)) built a document quotation
    model in online conversations and investigated the consistency between quoted
    sentences and latent dialogue topics.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge graph is another source of external information, which is becoming
    more and more popular in knowledge-grounded systems because of their structured
    nature. Jung et al. ([2020](#bib.bib160)) proposed a dialogue-conditioned graph
    traversal model for knowledge-grounded dialogue systems. The proposed model leveraged
    attention flows of two directions and fully made use of the structured information
    of knowledge graph to flexibly decide the expanding range of nodes and edges.
    Likewise, Zhang et al. ([2019b](#bib.bib447)) applied graph attention to traverse
    the concept space, which was a common-sense knowledge graph. The graph attention
    helped to move to more meaningful nodes conditioning on dialogue context. Xu et al.
    ([2020a](#bib.bib426)) applied knowledge graphs as an external source to control
    a coarse-level utterance generation. Thus, the conversation was supported by common-sense
    knowledge, and the agent guided the dialogue topic in a more reasonable way. Moon
    et al. ([2019](#bib.bib257)) built a retrieval system retrieving responses based
    on the graph reasoning task. They used a graph walker to traverse the graph conditioning
    on symbolic transitions of the dialogue context. Huang et al. ([2020a](#bib.bib147))
    proposed Graph-enhanced Representations for Automatic Dialogue Evaluation (GRADE),
    a novel evaluation metric for open-domain dialogue systems. This metric considered
    both contextualized representations and topic-level graph representations. The
    main idea was to use an external knowledge graph to model the conversation logic
    flow as a part of the evaluation criteria.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge-grounded datasets containing context-knowledge-response triples are
    scarce and hard to obtain. Cho and May ([2020](#bib.bib50)) collected a large
    dataset consisting of more than 26000 turns of improvised dialogues which were
    further grounded with a larger movie corpus as external knowledge. Also tackling
    the data insufficiency problem, Li et al. ([2020b](#bib.bib197)) proposed a method
    that did not require context-knowledge-response triples for training and was thus
    data-efficient. They viewed knowledge as a latent variable to bridge the context
    and response. The variational approach learned the parameters of the generator
    from both a knowledge corpus and a dialogue corpus which were independent of each
    other.
  prefs: []
  type: TYPE_NORMAL
- en: 4.9 Interactive Training
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Interactive training, also called human-in-loop training, is a unique training
    method for dialogue systems. Annotated data is fixed and limited, not being able
    to cover all dialogue settings. Also, it takes a long time to train a good system.
    But in some industrial products, the dialogue systems need not be perfect when
    accomplishing their tasks. Thus, interactive training is desirable because the
    dialogue systems can improve themselves via interactions with users anywhere and
    anytime, which is a more flexible and cheap way to finetune the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Training schemes with the above intuition have been developed in recent years. Li
    et al. ([2016a](#bib.bib192)) introduced a reinforcement learning-based online
    learning framework. The agent interacted with a human dialogue partner and the
    partner provided feedback as a reward signal. Asghar et al. ([2016](#bib.bib8))
    first trained the agent with two-stage supervised learning, and then used an interaction-based
    reinforcement learning to finetune. Every time the user chose the best one from
    K responses generated by the pretrained model and then responded to this selected
    response. Instead of learning through being passively graded, Li et al. ([2016b](#bib.bib193))
    proposed a model that actively asked questions to seek improvement. Active learning
    was applicable to both offline and online learning settings. Hancock et al. ([2019](#bib.bib123))
    argued that most conversation samples an agent saw happened after it was pretrained
    and deployed. Thus, they proposed a framework to train the agent from the real
    conversations it participated in. The agent evaluated the satisfaction score of
    the user from the user’s response of each turn and explicitly requested the user
    feedback when it thought that a mistake has been made. The user feedback was further
    used for learning. Bouchacourt and Baroni ([2019](#bib.bib27)) placed the interactive
    learning in a cooperative game and tried to learn a long-term implicit strategy
    via Reinforce algorithm. Some of these work has been adopted by industry products
    and is a very promising direction for study.
  prefs: []
  type: TYPE_NORMAL
- en: 4.10 Visual Dialogue
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'More and more researchers cast their eyes to a broader space and are not only
    restricted to NLP. The combination of CV and NLP giving rise to tasks like visual
    question answering attracted lots of interest. The VQA task is to answer a question
    based on the content of a picture or video. Recently, this has evolved into a
    more challenging task: visual dialogue, which conditions a dialogue on the visual
    information and dialogue history. The dialogue consists of a series of queries,
    and the query form is usually more informal, which is why it is more complicated
    than VQA.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ddf47cfe252263bfc7c80cf645895937.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: The architecture of VD-BERT, a state-of-the-art visual dialogue
    system (Wang et al., [2020f](#bib.bib392))'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a9dbdb2a0130c37be56b263a00a91347.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Three samples from the IMAGE-CHAT dataset (Shuster et al., [2020](#bib.bib325))'
  prefs: []
  type: TYPE_NORMAL
- en: 'Visual dialogue can be seen as a multi-step reasoning process over a series
    of questions (Gan et al., [2019](#bib.bib95)). Gan et al. ([2019](#bib.bib95))
    learned semantic representation of the question based on dialogue history and
    a given image, and recurrently updated the representation. Shuster et al. ([2019](#bib.bib324))
    proposed a set of image-based tasks and provided strong baselines. Wang et al.
    ([2020f](#bib.bib392)) employed R-CNN as an image encoder and fused the visual
    and dialogue modality with a VD-BERT. The proposed architecture achieved sufficient
    interactions between multi-turn dialogue and images. The proposed architecture
    is shown as an example model for Visual Dialogue tasks in Figure [16](#S4.F16
    "Figure 16 ‣ 4.10 Visual Dialogue ‣ 4 Open-Domain Dialogue Systems ‣ Recent Advances
    in Deep Learning Based Dialogue Systems: A Systematic Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Compared with image-grounded dialogue systems, video-grounded systems are more
    interesting but also more challenging. There are two main challenges of video
    dialogue, as claimed by Le and Hoi ([2020](#bib.bib178)). One is that both spatial
    and temporal features exist in the video, which increases the difficulty of feature
    extraction. Another is that video dialogue features span across multiple conversation
    turns and thus are more complicated. A GPT-2 model was applied by Le and Hoi ([2020](#bib.bib178)),
    being able to fuse multi-modality information over different levels. Likewise, Le
    et al. ([2019](#bib.bib179)) built a multi-modal transformer network to incorporate
    information from different modalities and further applied a query-aware attention
    to extract context-related features from non-text modalities. Le et al. ([2020a](#bib.bib180))
    proposed a Bi-directional Spatio-Temporal Learning (BiST) leveraging temporal-to-spatial
    and spatial-to-temporal reasoning process and could adapt to the dynamically evolving
    semantics in the video.
  prefs: []
  type: TYPE_NORMAL
- en: Some researchers hold different opinions on the effectiveness of dialogue history
    in visual dialogue. Takmaz et al. ([2020](#bib.bib357)) proposed that many expressions
    were already mentioned in previous turns and they built a visual dialogue model
    grounded on both image and conversation history. They further proved that better
    performance was achieved when grounding the model on dialogue context. However, Agarwal
    et al. ([2020](#bib.bib1)) argued that though with dialogue history the visual
    dialogue model could achieve better results, in fact only a small proportion of
    cases benefited from the history. Furthermore, they proved that existing evaluation
    metrics for visual dialogue promoted generic responses.
  prefs: []
  type: TYPE_NORMAL
- en: The visual dialogue task benefits a lot from the pretraining-based learning.
    The popularity of NLP pretraining sparked interest in multi-modal pretraining.
    VideoBERT (Sun et al., [2019b](#bib.bib351)) is widely recognized as the pioneering
    work in the field of multimodal pretraining. It’s a model that’s been pre-trained
    on video frame features and text. CBT (Sun et al., [2019a](#bib.bib350)), which
    is similarly pretrained on video-text pairs, is a contemporary work of VideoBERT.
    For video representation learning, Miech et al. ([2020](#bib.bib249)) used unlabeled
    narrated films. More researchers have focused their attention on visual-linguistic
    pretraining, inspired by the early work in multi-modal pretraining. For this objective,
    there are primarily two types of model designs. The single-stream model (Alberti
    et al., [2019](#bib.bib4); Chen et al., [2019d](#bib.bib47); Gan et al., [2020](#bib.bib96);
    Li et al., [2020a](#bib.bib190), [2019a](#bib.bib198), [c](#bib.bib204); Su et al.,
    [2019c](#bib.bib348); Zhou et al., [2020b](#bib.bib464)) is one example. (Li et al.,
    [2020a](#bib.bib190)) used a BERT model to process the concatenation of objects
    and words and pre-trained it with three standard tasks. Similar methods were proposed
    by Chen et al. ([2019d](#bib.bib47)) and Qi et al. ([2020](#bib.bib279)), but
    with more pretraining tasks and larger datasets. With an adversarial training
    technique, Gan et al. ([2020](#bib.bib96)) further enhanced the model. Su et al.
    ([2019c](#bib.bib348)) employed the same architecture, but incorporated single-modal
    data and pre-trained the object detector. Instead of using recognized objects,
    Huang et al. ([2020d](#bib.bib151)) sought to enter pixels directly. The object
    labels were used by Li et al. ([2020c](#bib.bib204)) to improve cross-modal alignment.
    Zhou et al. ([2020b](#bib.bib464)) suggested a single-stream model that learns
    both caption generation and VQA tasks at the same time. The two-stream model (Lu
    et al., [2019a](#bib.bib230), [2020](#bib.bib232); Tan and Bansal, [2019](#bib.bib359);
    Yu et al., [2020](#bib.bib440)) is another type of model architecture. Tan and
    Bansal ([2019](#bib.bib359)) suggested a two-stream model with co-attention and
    solely used in-domain data to train the model. Lu et al. ([2019a](#bib.bib230))
    introduced a similar architecture with a more complex co-attention model, which
    they pretrained with out-of-domain data, and Lu et al. ([2020](#bib.bib232)) improved
    VilBERT with multi-task learning. Yu et al. ([2020](#bib.bib440)) recently added
    the scene graph to the model, which improved performance. Aside from these studies,
    Singh et al. ([2020](#bib.bib329)) looked at the impact of pretraining dataset
    selection on downstream task performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The annotation of visual dialogue is laborious and thus the datasets are scarce.
    Recently, some researchers have tried to tackle the data insufficiency problem.
    Shuster et al. ([2020](#bib.bib325)) collected a dataset (IMAGE-CHAT, shown in
    Figure [17](#S4.F17 "Figure 17 ‣ 4.10 Visual Dialogue ‣ 4 Open-Domain Dialogue
    Systems ‣ Recent Advances in Deep Learning Based Dialogue Systems: A Systematic
    Survey")) of image-grounded human-human conversations in which speakers are asked
    to perform role-playing based on an emotional mood or style offered, since the
    usage of such characteristics is also a significant factor in engagingness. Kamezawa
    et al. ([2020](#bib.bib163)) constructed a visual-grounded dialogue dataset. Interestingly,
    it additionally annotated the eye-gaze locations of the interlocutor in the image
    to provide information on what the interlocutor was paying attention to. Cogswell
    et al. ([2020](#bib.bib56)) proposed a method to utilize the VQA data when adapting
    to a new task, minimizing the requirement of dialogue data which is expensive
    to annotate.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Evaluation Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Evaluation is an essential part of research in dialogue systems. It is not only
    a way to assess the performance of agents, but it can also be a part of the learning
    framework which provides signals to facilitate the learning (Bao et al., [2019a](#bib.bib16)).
    This section discusses the evaluation methods in task-oriented and open-domain
    dialogue systems.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Evaluation Methods for Task-oriented Dialogue Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Task-oriented systems aim to accomplish tasks and thus have more direct metrics
    evaluating their performance such as task completion rate and task completion
    cost. Some evaluation methods also involve metrics like BLEU to compare system
    responses with human responses, which will be discussed later. In addition, human-based
    evaluation and user simulators are able to provide real conversation samples.
  prefs: []
  type: TYPE_NORMAL
- en: Task Completion Rate is the rate of successful events in all task completion
    attempts. It measures the task completion ability of a dialogue system. For example,
    in movie ticket booking tasks, the Task Completion Rate is the fraction of dialogues
    that meet all requirements specified by the user, such as movie time, cinema location,
    movie genre, etc. The task completion rate was applied in many task-oriented dialogue
    systems (Walker et al., [1997](#bib.bib382); Williams, [2007](#bib.bib404); Peng
    et al., [2017](#bib.bib272)). Additionally, some works (Singh et al., [2002](#bib.bib330);
    Yih et al., [2015](#bib.bib434)) used partial success rate.
  prefs: []
  type: TYPE_NORMAL
- en: Task Completion Cost is the resources required when completing a task. Time
    efficiency is a significant metric belonging to Task Completion Cost. In dialogue-related
    tasks, the number of conversation turns is usually used to measure the time efficiency
    and dialogue with fewer turns is preferred when accomplishing the same task.
  prefs: []
  type: TYPE_NORMAL
- en: Human-based Evaluation provides user dialogues and user satisfaction scores
    for system evaluation. There are two main streams of human-based evaluation. One
    is to recruit human labor via crowdsourcing platforms to test-use a dialogue system.
    The crowdsource workers converse with the dialogue systems about predefined tasks
    and then metrics like Task Completion Rate and Task Completion Cost can be calculated.
    Another is computing the evaluation metrics in real user interactions, which means
    that evaluation is done after the system is deployed in real use.
  prefs: []
  type: TYPE_NORMAL
- en: User Simulator provides simulated user dialogues based on pre-defined rules
    or models. Since recruiting human labor is expensive and real user interactions
    are not available until a mature system is deployed, user simulators are able
    to provide task-oriented dialogues at a lower cost. There are two kinds of user
    simulators. One is agenda-based simulators (Schatzmann and Young, [2009](#bib.bib309);
    Li et al., [2016e](#bib.bib200); Ultes et al., [2017](#bib.bib375)), which only
    feed dialogue systems with the pre-defined user goal as a user message, without
    surface realization. Another is model-based simulators (Chandramohan et al., [2011](#bib.bib37);
    Asri et al., [2016](#bib.bib9)), which generate user utterances using language
    models given constraint information.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Evaluation Methods for Open-domain Dialogue Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Evaluation of open-domain dialogue systems has long been a challenging problem.
    Unlike task-oriented systems, there is no clear metric like task completion rate
    or task completion cost. Both human and automatic evaluation methods are developed
    for ODD during these years. Human evaluation has been adopted by many works (Ritter
    et al., [2011](#bib.bib300); Shang et al., [2015](#bib.bib318); Sordoni et al.,
    [2015b](#bib.bib340)) to converse with and rate dialogue agents. However, human
    evaluation is not an ideal approach for that human labor is expensive and the
    evaluation results are highly subjective, varying from person to person. Researchers
    tend to hire crowd source workers (Ritter et al., [2011](#bib.bib300); Shang et al.,
    [2015](#bib.bib318); Sordoni et al., [2015b](#bib.bib340)) or random people (Moon
    et al., [2019](#bib.bib257); Jung et al., [2020](#bib.bib160)) to conduct human
    evaluation, both of which have two main drawbacks: 1\. The evaluator group is
    highly random, and there exists huge gap between people with different knowledge
    levels or from different domains. 2\. Though individual bias could be weakened
    by increasing the number of evaluators, the evaluator group cannot be very large
    because of the limited budgets (in articles mentioned above the sizes of human
    evaluator groups are usually 5-20). Thus, automatic and objective metrics are
    desirable. In general, there are two categories of automatic metrics in recent
    research: word-overlap metrics and neural metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Word-overlap Metrics are widely used in Machine Translation and Summarization
    tasks, which calculate the similarity between the generated sequence and the ground
    truth sequence. Representative metrics like BLEU (Papineni et al., [2002](#bib.bib269))
    and ROUGE (Lin, [2004](#bib.bib210)) are n-gram matching metrics. METEOR (Banerjee
    and Lavie, [2005](#bib.bib15)) was further proposed with an improvement based
    on BLEU. It identified the paraphrases and synonyms between the generated sequence
    and the ground truth. Galley et al. ([2015](#bib.bib94)) extended the BLEU by
    exploiting numerical ratings of responses. Liu et al. ([2016](#bib.bib223)) argued
    that word-overlap metrics were not correlated well with human evaluation. These
    metrics are effective in Machine Translation because each source sentence has
    a ground truth to compare with, whereas in dialogues there may be many possible
    responses corresponding with one user message, and thus an acceptable response
    may receive a low score if simply computing word-overlap metrics.
  prefs: []
  type: TYPE_NORMAL
- en: Neural Metrics are metrics computed by neural models. Neural methods improve
    the evaluation effectiveness in terms of adaptability compared with word-overlap
    metrics, but they require an additional training process. Su et al. ([2015](#bib.bib345))
    used an RNN and a CNN model to extract turn-level features in a sequence and give
    the score. Tao et al. ([2018](#bib.bib363)) proposed Ruber, which was an automatic
    metric combining referenced and unreferenced components. The referenced one computed
    the similarity between generated response representations and ground truth representations,
    while the unreferenced one learned a scoring model to rate the query-response
    pairs. Lowe et al. ([2017](#bib.bib229)) learned representations of dialogue utterances
    using an RNN and then computed the dot-product between generated response and
    ground truth response as an evaluation score. Kannan and Vinyals ([2017](#bib.bib164))
    and Bruni and Fernandez ([2017](#bib.bib29)) used the discriminator of a GAN framework
    to distinguish the generated responses from human responses. If a generated response
    achieved a high confidence score, this was indicative of a human-like response,
    thus desirable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation of open-domain dialogue systems is a hot topic at present and many
    researchers cast their eyes on this task recently. Some papers introduce two or
    more custom evaluation metrics for better evaluation, such as response diversity,
    response consistency, naturalness, knowledgeability, understandability, etc.,
    to study "what to evaluate". Bao et al. ([2019a](#bib.bib16)) evaluated the generated
    responses by designing two metrics. One was the informativeness metric calculating
    information utilization over turns. Another was the coherence metric, which was
    predicted by GRUs, given the response, context, and background as input. Likewise, Akama
    et al. ([2020](#bib.bib3)) designed scoring functions to compute connectivity
    of utterance pairs and content relatedness as two evaluation metrics and used
    another fusion function to combine the metrics. Pang et al. ([2020](#bib.bib268))
    combined four metrics in their automatic evaluation framework: the context coherence
    metric based on GPT-2; phrase fluency metric based on GPT-2; diversity metric
    based on n-grams; logical self-consistency metric based on textual-entailment-inference.
    Mehri and Eskenazi ([2020](#bib.bib243)) proposed a reference-free evaluation
    metric. They annotated responses considering the following qualities: Understandable
    (0-1), Maintains Context (1-3), Natural (1-3), Uses Knowledge (0-1), Interesting
    (1-3), Overall Quality (1-5). Furthermore, a transformer was trained on these
    annotated dialogues to compute the score of quality.'
  prefs: []
  type: TYPE_NORMAL
- en: Apart from "what to evaluate", there are also a multitude of papers studying
    "how to evaluate", which focus more on refining the evaluation process. Liang
    et al. ([2020](#bib.bib209)) proposed a three-stage framework to denoise the self-rating
    process. They first performed dialogue flow anomaly detection via self-supervised
    representation learning, and then the model was fine-tuned with smoothed self-reported
    user ratings. Finally, they performed a denoising procedure by calculating the
    Shapley value and removed the samples with negative values. Zhao et al. ([2020a](#bib.bib458))
    trained RoBERTa as a response scorer to achieve reference-free and semi-supervised
    evaluation. Sato et al. ([2020](#bib.bib308)) constructed a test set by first
    generating several responses based on one user message and then human evaluation
    was performed to annotate each response with a score, where the response with
    the highest score was taken as a true response and the remainder taken as false
    responses. Dialogue systems were further evaluated by comparing the response selection
    accuracy on the test set, where a cross-entropy loss was calculated between the
    generated response and candidate responses to perform the selection operation.
    Likewise, Sinha et al. ([2020](#bib.bib332)) trained a BERT-based model to discriminate
    between true and false responses, where false responses were automatically generated.
    The model was further used to predict the evaluation score of a response based
    on dialogue context. Huang et al. ([2020a](#bib.bib147)) argued that responses
    should not be simply evaluated based on their surface-level features, and instead
    the topic-level features were more essential. They incorporated a common-sense
    graph in their evaluation framework to obtain topic-level graph representations.
    The topic-level graph representation and utterance-level representation were jointly
    considered to evaluate the coherence of responses generated by open-domain dialogue
    systems.
  prefs: []
  type: TYPE_NORMAL
- en: Ranking is also an approach that evaluates dialogue systems effectively. Gao
    et al. ([2020b](#bib.bib101)) leveraged large-scale human feedback data such as
    upvotes, downvotes, and replies to learn a GPT-2-based response ranker. Thus,
    responses were evaluated by their rankings given by the ranker. Deriu et al. ([2020](#bib.bib69))
    also evaluated the dialogue systems by ranking. They proposed a low-cost human-involved
    evaluation framework, in which different conversational agents conversed with
    each other and the human’s responsibility was to annotate whether the generated
    utterance was human-like or not. The systems were evaluated by comparing the number
    of turns their responses were judged as human-like responses.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The dataset is one of the most essential components in dialogue systems study.
    Nowadays the datasets are not enough no matter for task-oriented or open-domain
    dialogue systems, especially for those tasks requiring additional annotations
    (Novikova et al., [2017](#bib.bib263)). For task-oriented dialogue systems, data
    can be collected via two main methods. One is to recruit human labor via crowdsourcing
    platforms to produce dialogues in a given task. Another is to collect dialogues
    in real task completions like film ticket booking. For open-domain dialogue systems,
    apart from dialogues collected in real interactions, social media is also a significant
    source of data. Some social media companies such as Twitter and Reddit provide
    API access to a small proportion of posts, but these services are restricted by
    many legal terms which affect the reproducibility of research. As a result, many
    recent works in dialogue systems collect their own datasets for train and test.
  prefs: []
  type: TYPE_NORMAL
- en: In this section, we review and categorize these datasets and make a comprehensive
    summary. To our best knowledge, Table LABEL:Datasets_for_Task-oriented_dialogue_systems
    and LABEL:Datasets_for_Open-domain_dialogue_systems cover almost all available
    datasets used in recent task-oriented or open-domain dialogue systems.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Datasets for Task-oriented Dialogue Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 3: Datasets for Task-oriented dialogue systems'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Name | Description | Task | Origin |'
  prefs: []
  type: TYPE_TB
- en: '| Schema | A dataset mainly for dialogue state tracking. | Dialogue State Tracking
    | Rastogi et al. ([2020](#bib.bib292)) |'
  prefs: []
  type: TYPE_TB
- en: '| MetaLWOZ | Collected by crowdsourcing platforms, spanning over 227 tasks
    and 47 domains. This dataset is designed for learning in unseen domains. | Domain
    Transfer | Lee et al. ([2019](#bib.bib187)) |'
  prefs: []
  type: TYPE_TB
- en: '| E2E | A dataset for end-to-end dialogue generation in restaurant domain.
    Data is collected in crowdsourced fashion. | End-to-end Task-oriented Dialogue
    Systems | Novikova et al. ([2017](#bib.bib263)) |'
  prefs: []
  type: TYPE_TB
- en: '| MSR-E2E | Contain dialogues spanning over 3 domains: movie-ticket booking,
    restaurant reservation, and taxi booking. | End-to-end Task-oriented Dialogue
    Systems | Li et al. ([2018](#bib.bib202)) |'
  prefs: []
  type: TYPE_TB
- en: '| YELPNLG | A corpus consisting of utterances spanning over different restaurant
    attributes. | Natural Language Generation | Oraby et al. ([2019](#bib.bib264))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Clinical Conversation data set | It consists of conversations between physicians
    and participants. | Natural Language Understanding | Du et al. ([2019](#bib.bib75))
    |'
  prefs: []
  type: TYPE_TB
- en: '| OOS | A large-scale dataset for intent detection. | Natural Language Understanding
    | Larson et al. ([2019](#bib.bib177)) |'
  prefs: []
  type: TYPE_TB
- en: '| ATIS | A dataset consisting of voice calls from people who intend to make
    flight reservations. | Natural Language Understanding; Dialogue State Tracking
    | Tur et al. ([2010](#bib.bib373)) |'
  prefs: []
  type: TYPE_TB
- en: '| MultiWOZ | Human-human written conversations with rich annotations spanning
    over multi-domains. | Task-oriented Dialogue | Budzianowski et al. ([2018](#bib.bib30))
    |'
  prefs: []
  type: TYPE_TB
- en: '| SNIPS-NLU | Task-oriented dialogue dataset colleted in a crowdsourced fashion.
    It was used to train voice assistant agents. | Task-oriented Dialogue | [https://github.com/snipsco/nlubenchmark](https://github.com/snipsco/nlubenchmark)
    |'
  prefs: []
  type: TYPE_TB
- en: '| bAbI | Restaurant table reservation dialogues. | Task-oriented Dialogue |
    Bordes et al. ([2016](#bib.bib25)) |'
  prefs: []
  type: TYPE_TB
- en: '| JDC | A Chinese customer service dataset, consisting of context-response
    pairs. | Task-oriented Dialogue | [https://www.jddc.jd.com](https://www.jddc.jd.com)
    |'
  prefs: []
  type: TYPE_TB
- en: '| UbuntuV2 | It consists of dialogues collected via Ubuntu question-answering
    forum. | Task-oriented Dialogue | Lowe et al. ([2015](#bib.bib228)) |'
  prefs: []
  type: TYPE_TB
- en: '| MICROSOFT DIALOGUE CHALLENGE data set | A task-oriented dataset collected
    via Amazon Mechanical Turk. | Task-oriented Dialogue | Li et al. ([2018](#bib.bib202))
    |'
  prefs: []
  type: TYPE_TB
- en: '| WOZ | Task-oriented data collected in crowdsourced fashion. | Task-oriented
    Dialogue | Wen et al. ([2016c](#bib.bib401)) |'
  prefs: []
  type: TYPE_TB
- en: '| DSTC series | Multi-domain task-oriented dataset. | Task-oriented Dialogue
    | [https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/](https://www.microsoft.com/en-us/research/event/dialog-state-tracking-challenge/)
    |'
  prefs: []
  type: TYPE_TB
- en: '| SimDial | Simulated conversations spanning over multiple domains. | Task-oriented
    Dialogue | Zhao and Eskenazi ([2018](#bib.bib456)) |'
  prefs: []
  type: TYPE_TB
- en: '| SMD | Human-human dialogues in weather, navigation and scheduling domain.
    | Task-oriented Dialogue | Eric and Manning ([2017](#bib.bib81)) |'
  prefs: []
  type: TYPE_TB
- en: '| BANKING | Question-answer pairs with 77 categories in e-banking domain. |
    Task-oriented Dialogue | Henderson et al. ([2019b](#bib.bib136)) |'
  prefs: []
  type: TYPE_TB
- en: '| Weather forecast | A task-oriented dataset in the weather domain. | Task-oriented
    Dialogue | Balakrishnan et al. ([2019](#bib.bib14)) |'
  prefs: []
  type: TYPE_TB
- en: '| MedDialog-(EN,CN) | Large scale dataset in medical domain consisting of conversations
    between doctors and patients | Task-oriented Dialogue | He et al. ([2020b](#bib.bib129))
    |'
  prefs: []
  type: TYPE_TB
- en: '| CamRest | It consists of human-human multi-turn dialogues in restaurant domain.
    | Task-oriented Dialogue | Wen et al. ([2016a](#bib.bib399)) |'
  prefs: []
  type: TYPE_TB
- en: '| Taskmaster | Contain dialogues spanning over 6 domains. It has 22.9 average
    length of conversational turns. | Task-oriented Dialogue | Byrne et al. ([2019](#bib.bib32))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Frames | Conversational dataset with annotations of semantic frame tracking.
    | Task-oriented Dialogue | Asri et al. ([2017](#bib.bib10)) |'
  prefs: []
  type: TYPE_TB
- en: '| JDDC | A Chinese customer service dataset, consisting of context-response
    pairs. | Task-oriented Dialogue | Chen et al. ([2019a](#bib.bib43)) |'
  prefs: []
  type: TYPE_TB
- en: '| Court Debate Dataset | A task-oriented dataset in judicial field containing
    court debate conversations. | Task-oriented Dialogue | Ji et al. ([2020](#bib.bib155))
    |'
  prefs: []
  type: TYPE_TB
- en: '| TreeDST | A task-oriented dataset annotated with tree structured dialogue
    states and agent acts. | Task-oriented Dialogue | Cheng et al. ([2020](#bib.bib49))
    |'
  prefs: []
  type: TYPE_TB
- en: '| RiSAWOZ | Contain utterances for 12 domains, annotated with rich semantic
    information. | Task-oriented Dialogue | Quan et al. ([2020](#bib.bib286)) |'
  prefs: []
  type: TYPE_TB
- en: '| Cambridge Restaurant | A task-oriented dataset in restaurant booking field.
    | Task-oriented Dialogue | Wen et al. ([2016c](#bib.bib401)) |'
  prefs: []
  type: TYPE_TB
- en: '| SB-TOP | A task-oriented dataset with semantic parsing annotation. It spans
    over 4 domains: Reminder, Weather, Calling and Music. | Task-oriented Dialogue
    | Aghajanyan et al. ([2020](#bib.bib2)) |'
  prefs: []
  type: TYPE_TB
- en: '| GSIM | A machine-machine task-oriented dataset. It covers two domains: restaurant
    table booking and movie ticket booking. | Task-oriented Dialogue | Shah et al.
    ([2018](#bib.bib316)) |'
  prefs: []
  type: TYPE_TB
- en: '| SGD | A schema-guided dataset spanning over multiple domains. | Task-oriented
    Dialogue | Rastogi et al. ([2020](#bib.bib292)) |'
  prefs: []
  type: TYPE_TB
- en: '| cite-8K | A task-oriented dataset collected in restaurant booking calls.
    | Task-oriented Dialogue | Coope et al. ([2020](#bib.bib58)) |'
  prefs: []
  type: TYPE_TB
- en: 6.2 Datasets for Open-domain Dialogue Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table 4: Datasets for Open-domain dialogue systems'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Name | Description | Task | Origin |'
  prefs: []
  type: TYPE_TB
- en: '| Large-Scale Corpus for Conversation Disentanglement | A dataset consisting
    of messages annotated with reply-structure graphs for dialogue disentanglement.
    | Conversation Disentaglement | Kummerfeld et al. ([2018](#bib.bib174)) |'
  prefs: []
  type: TYPE_TB
- en: '| DuConv | Collected in conversations between a conversation leader and a conversation
    follower. | Conversation Topic | Wu et al. ([2019c](#bib.bib417)) |'
  prefs: []
  type: TYPE_TB
- en: '| PERSUASION FOR GOOD | A topic-oriented dataset annotated with persuasion
    strategies. | Conversation Topic | Wang et al. ([2019b](#bib.bib390)) |'
  prefs: []
  type: TYPE_TB
- en: '| MutualFriends | A topic-oriented dataset based on bot-bot stratigical conversations.
    | Conversation Topic | He et al. ([2017](#bib.bib125)) |'
  prefs: []
  type: TYPE_TB
- en: '| SAMSum | A large-scale dialogue summary dataset. | Conversation Topic | Gliwa
    et al. ([2019](#bib.bib105)) |'
  prefs: []
  type: TYPE_TB
- en: '| OpenDialKG | It consists conversations between two agents and each dialogue
    corresponds with a knowledge graph path annotation. | Conversation Topic; Dialogue
    Reasoning | Moon et al. ([2019](#bib.bib257)) |'
  prefs: []
  type: TYPE_TB
- en: '| doc2dial | A dataset consisting of conversations annotated with goals and
    accociated documents. | Conversation Topic; Knowledge-Grounded System | Feng et al.
    ([2020c](#bib.bib89)) |'
  prefs: []
  type: TYPE_TB
- en: '| DialEdit | A dataset constructed for image editing via conversational language
    instructions. | Conversational Image Editing | Manuvina-kurike et al. ([2018](#bib.bib241))
    |'
  prefs: []
  type: TYPE_TB
- en: '| CHART DIALOGS | A dataset containing dialogues describing matplotlib plot
    features. | Conversational Plotting | Shao and Nakashole ([2020](#bib.bib320))
    |'
  prefs: []
  type: TYPE_TB
- en: '| CONAN | A multilingual dataset for hate speech tackling. | Dialogue Classification
    | Chung et al. ([2019](#bib.bib55)) |'
  prefs: []
  type: TYPE_TB
- en: '| Dialogue NLI | A NLI dataset with sentences annotated with entailment (E),
    neutral (N), or contradiction (C). | Dialogue Inference | Welleck et al. ([2018](#bib.bib396))
    |'
  prefs: []
  type: TYPE_TB
- en: '| MuTual | A dialogue reasoning dataset containing English listening comprehension
    exams. | Dialogue Reasoning | Cui et al. ([2020](#bib.bib60)) |'
  prefs: []
  type: TYPE_TB
- en: '| RST-DT | It consists of samples from 385 news articles annotated with dialogue
    features. | Discourse Parsing | Carlson et al. ([2002](#bib.bib36)) |'
  prefs: []
  type: TYPE_TB
- en: '| NLPCC | A dataset consisting of emotional classification data. | Empathetic
    Response | [http://tcci.ccf.org.cn/nlpcc.php](http://tcci.ccf.org.cn/nlpcc.php)
    |'
  prefs: []
  type: TYPE_TB
- en: '| MELD | A multi-party conversational dataset with emotion annotations. | Empathetic
    Response | Poria et al. ([2019](#bib.bib275)) |'
  prefs: []
  type: TYPE_TB
- en: '| EMPATHETIC DIALOGUES | A dataset containing conversations annotated with
    emotion labels. | Empathetic Response | Rashkin et al. ([2018](#bib.bib291)) |'
  prefs: []
  type: TYPE_TB
- en: '| IEMOCAP | Contain multi-party dialogues. Each dialogue is annotated with
    an emotion label. | Empathetic Response | Busso et al. ([2008](#bib.bib31)) |'
  prefs: []
  type: TYPE_TB
- en: '| EmoryNLP | Collected from Friends’ TV series, annotated with emotion labels.
    | Empathetic Response | Zahiri and Choi ([2017](#bib.bib443)) |'
  prefs: []
  type: TYPE_TB
- en: '| MojiTalk | A largescale dataset collected from Twitter, including emojis.
    | Empathetic Response | Zhou and Wang ([2017](#bib.bib465)) |'
  prefs: []
  type: TYPE_TB
- en: '| CBET | A dialogue dataset annotated with nine emotion labels: surprise, anger,
    love, sadness, joy, fear, guilt, disgust and thankfulness | Empathetic Response
    | Yadollahi et al. ([2017](#bib.bib428)) |'
  prefs: []
  type: TYPE_TB
- en: '| Stanford Politeness Corpus | A conversational dataset annotated with politeness
    labels. | Empathetic Response | Danescu-Niculescu-Mizil et al. ([2013](#bib.bib65))
    |'
  prefs: []
  type: TYPE_TB
- en: '| AIT-2018 | Collected in SemEval-2018 Task 1: Affect in Tweets. | Empathetic
    Response | Mohammad et al. ([2018](#bib.bib256)) |'
  prefs: []
  type: TYPE_TB
- en: '| EMOTyDA | A dataset containing short videos about multi-party conversations,
    each annotated with respective emotion. | Empathetic Response; Visual Dialogue
    | Saha et al. ([2020](#bib.bib303)) |'
  prefs: []
  type: TYPE_TB
- en: '| Wizard of Wikipedia | A large-sclale dataset consisting of conversations
    grounded with Wikipedia knowledge. | Knowledge-Grounded System | Dinan et al.
    ([2018](#bib.bib72)) |'
  prefs: []
  type: TYPE_TB
- en: '| CMU DoG | A dataset consisting of conversations grounded with Wikipedia articles
    about popular movies. | Knowledge-Grounded System | Zhou et al. ([2018](#bib.bib463))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Holl-E | Contain dialogues grounded with documents. | Knowledge-Grounded
    System | Moghe et al. ([2018](#bib.bib255)) |'
  prefs: []
  type: TYPE_TB
- en: '| Interview | A dataset containing multi-party conversations in the form of
    interviews. | Knowledge-Grounded System | Majumder et al. ([2020b](#bib.bib239))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Curiosity | An open-domain dataset annotated with pre-existing user knowledge
    and dialogue acts, also grounding in Wikipedia. | Knowledge-Grounded System |
    Rodriguez et al. ([2020](#bib.bib301)) |'
  prefs: []
  type: TYPE_TB
- en: '| KdConv | A chinese knowledge-grounded dialogue dataset. | Knowledge-Grounded
    System | Zhou et al. ([2020a](#bib.bib462)) |'
  prefs: []
  type: TYPE_TB
- en: '| ELI5 | A QA dataset grounded with retrieved documents. | Knowledge-Grounded
    System | Fan et al. ([2019](#bib.bib83)) |'
  prefs: []
  type: TYPE_TB
- en: '| Topical Chat | A knowledge-grounded dataset where the knowledge spans over
    eight different topics. | Knowledge-Grounded System; Conversation Topic | Gopalakrishnan
    et al. ([2019](#bib.bib109)) |'
  prefs: []
  type: TYPE_TB
- en: '| WHERE ARE YOU? | A dialogue dataset annotated with localization information.
    | Localization Dialogue | Hahn et al. ([2020](#bib.bib119)) |'
  prefs: []
  type: TYPE_TB
- en: '| MMD | A multi-modal dataset consisting of dialogues between sales agents
    and shoppers. | Multi-modal Dialogue | Saha et al. ([2018](#bib.bib302)) |'
  prefs: []
  type: TYPE_TB
- en: '| OpenSubtitles | A multilingual dataset made up of movie captions, containing
    about 8 billion words. | Open-domain Dialogue | Tiedemann ([2012](#bib.bib370))
    |'
  prefs: []
  type: TYPE_TB
- en: '| NTCIR | A social media dataset collected from Sina Weibo. | Open-domain Dialogue
    | [http://research.nii.ac.jp/ntcir/data/data-en.html](http://research.nii.ac.jp/ntcir/data/data-en.html)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Twitter | A social media dataset collected from Twitter. | Open-domain Dialogue
    | [https://github.com/Marsan-Ma-zz/chatcorpus](https://github.com/Marsan-Ma-zz/chatcorpus)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Douban Conversation Corpus | A social media dataset collected from Douban.
    | Open-domain Dialogue | Zhang et al. ([2018d](#bib.bib453)) |'
  prefs: []
  type: TYPE_TB
- en: '| E-commerce Dialogue Corpus | It consists of conversations between customers
    and customer service staff on Taobao. | Open-domain Dialogue | Zhang et al. ([2018d](#bib.bib453))
    |'
  prefs: []
  type: TYPE_TB
- en: '| REDDIT | A social media dataset collected from REDDIT. | Open-domain Dialogue
    | Henderson et al. ([2019a](#bib.bib135)) |'
  prefs: []
  type: TYPE_TB
- en: '| STC-SeFun | A social media dataset collected from Tieba, Zhidao, Douban and
    Weibo. | Open-domain Dialogue | Bi et al. ([2019](#bib.bib22)) |'
  prefs: []
  type: TYPE_TB
- en: '| DailyDialog | A dataset consisting of daily dialogues, annotated with conversation
    intention and emotion information. | Open-domain Dialogue | Li et al. ([2017c](#bib.bib206))
    |'
  prefs: []
  type: TYPE_TB
- en: '| PDTB | Dialogue dataset annotated with discourse relations. | Open-domain
    Dialogue | Prasad et al. ([2008](#bib.bib277)) |'
  prefs: []
  type: TYPE_TB
- en: '| Luna | Dialogue dataset with Italian relation annotations. | Open-domain
    Dialogue | Tonelli et al. ([2010](#bib.bib371)) |'
  prefs: []
  type: TYPE_TB
- en: '| Edina-DR | Dialogue dataset with English relation annotations, which is based
    on Luna data set. | Open-domain Dialogue | Ma et al. ([2019](#bib.bib234)) |'
  prefs: []
  type: TYPE_TB
- en: '| Cornell Movie Dialog Corpus | A dialogue dataset collected via IMDB database.
    | Open-domain Dialogue | Danescu-Niculescu-Mizil and Lee ([2011](#bib.bib64))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Reddit Movie Dialogue Dataset | A movie dialogue dataset collected from Reddit.
    | Open-domain Dialogue | Liu et al. ([2020a](#bib.bib224)) |'
  prefs: []
  type: TYPE_TB
- en: '| LIGHT | A dialogue dataset with configurable text adventure environment.
    | Open-domain Dialogue | Urbanek et al. ([2019](#bib.bib376)) |'
  prefs: []
  type: TYPE_TB
- en: '| This American Life | A media dialogue dataset collected in long-form expository
    podcast episodes. | Open-domain Dialogue | Mao et al. ([2020](#bib.bib242)) |'
  prefs: []
  type: TYPE_TB
- en: '| RadioTalk | A media dialogue dataset collected from radio transcripts. |
    Open-domain Dialogue | Beeferman et al. ([2019](#bib.bib19)) |'
  prefs: []
  type: TYPE_TB
- en: '| French EPAC | A media dialogue dataset collected from news. | Open-domain
    Dialogue | Esteve et al. ([2010](#bib.bib82)) |'
  prefs: []
  type: TYPE_TB
- en: '| TREC Conversational Assistance | An open-domain dataset spanning 30 conversation
    topics. | Open-domain Dialogue | Dalton et al. ([2020](#bib.bib63)) |'
  prefs: []
  type: TYPE_TB
- en: '| Search as a Conversation | A dataset for conversations with search engines.
    | Open-domain Dialogue | Ren et al. ([2020](#bib.bib299)) |'
  prefs: []
  type: TYPE_TB
- en: '| Amazon Alexa Prize Competition | A dataset containing real-world conversations
    between Amazon Alexa customers and Gunrock, which is a champion chatbot. | Open-domain
    Dialogue | Ram et al. ([2018](#bib.bib288)) |'
  prefs: []
  type: TYPE_TB
- en: '| SwitchBoard | An open-domain dataset containing English phone conversations.
    | Open-domain Dialogue | Jurafsky ([1997](#bib.bib161)) |'
  prefs: []
  type: TYPE_TB
- en: '| Zhihu | A Chinese social media dataset with posts and comments. | Open-domain
    Dialogue | [https://www.zhihu.com](https://www.zhihu.com) |'
  prefs: []
  type: TYPE_TB
- en: '| SPOLIN | A dataset containing yes-and conversations. | Open-domain Dialogue
    | Cho and May ([2020](#bib.bib50)) |'
  prefs: []
  type: TYPE_TB
- en: '| CRD3 | A dataset collected in the role-playing game Dungeons and Dragons.
    | Open-domain Dialogue | Rameshkumar and Bailey ([2020](#bib.bib289)) |'
  prefs: []
  type: TYPE_TB
- en: '| Baidu Zhidao | A Chinese social media dataset with posts and comments. |
    Open-domain Dialogue | [https://zhidao.baidu.com/](https://zhidao.baidu.com/)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Webis Gmane Email Corpus 2019 | A conversational dataset collected from 153M
    emails. | Open-domain Dialogue | Bevendorff et al. ([2020](#bib.bib21)) |'
  prefs: []
  type: TYPE_TB
- en: '| LibreSpeech Corpus | Contain 500 hours’ speech produced by 1252 participants.
    | Open-domain Dialogue | Panayotov et al. ([2015](#bib.bib267)) |'
  prefs: []
  type: TYPE_TB
- en: '| Motivational Interviewing | A dialogue dataset about conversational psychotherapy.
    | Open-domain Dialogue | Tanana et al. ([2016](#bib.bib360)) |'
  prefs: []
  type: TYPE_TB
- en: '| SubTle Corpus | Contact Ameixa for data. | Open-domain Dialogue | Lubis et al.
    ([2018](#bib.bib233)) |'
  prefs: []
  type: TYPE_TB
- en: '| TED-LIUM | TED-talk monologues. | Open-domain Dialogue | Fung et al. ([2016](#bib.bib93))
    |'
  prefs: []
  type: TYPE_TB
- en: '| ECG NLPCC 2017 Data | Conversational dataset extracted from Weibo. | Open-domain
    Dialogue | Huang et al. ([2018](#bib.bib148)) |'
  prefs: []
  type: TYPE_TB
- en: '| SEMEVAL15 | QA dataset with answer quality annotations via Amazon Mechanical
    Turk. | Question Answering | Nakov et al. ([2019](#bib.bib261)) |'
  prefs: []
  type: TYPE_TB
- en: '| AMAZONQA | A QA dataset solving one-to-many problems. | Question Answering
    | Wan and McAuley ([2016](#bib.bib383)) |'
  prefs: []
  type: TYPE_TB
- en: '| TGIF-QA | A video-grounded QA dataset. | Question Answering | Jang et al.
    ([2017](#bib.bib153)) |'
  prefs: []
  type: TYPE_TB
- en: '| QuAC | A QA dataset with 14K QA dialogues. | Question Answering | Choi et al.
    ([2018](#bib.bib53)) |'
  prefs: []
  type: TYPE_TB
- en: '| SQuAD | A question-answering dataset collected in crowdsourced fashion. |
    Question Answering | Rajpurkar et al. ([2018](#bib.bib287)) |'
  prefs: []
  type: TYPE_TB
- en: '| LIF | A dataset constructed based on QuAC. | Question Answering | Kundu et al.
    ([2020](#bib.bib175)) |'
  prefs: []
  type: TYPE_TB
- en: '| Yelp | It consists of customer reviews from Yelp Dataset Challenge | Response
    Retrieval | Tang et al. ([2015](#bib.bib361)) |'
  prefs: []
  type: TYPE_TB
- en: '| Debates | The dataset consists of debates on Congerssional bills. | Response
    Retrieval | Thomas et al. ([2006](#bib.bib368)) |'
  prefs: []
  type: TYPE_TB
- en: '| PERSONACHAT | It provides profile information of the agents and background
    of users. | Speaker Consistency and Personality Response | Zhang et al. ([2018b](#bib.bib449))
    |'
  prefs: []
  type: TYPE_TB
- en: '| KvPI | Contain consistency annotations between response and corresponding
    key-value profiles. | Speaker Consistency and Personality Response | Song et al.
    ([2020b](#bib.bib336)) |'
  prefs: []
  type: TYPE_TB
- en: '| ConvAI2 | A dataset constructed on the base of Persona-Chat, each conversation
    having profiles from a set containing persona candidates. | Speaker Consistency
    and Personality Response | Dinan et al. ([2019](#bib.bib73)) |'
  prefs: []
  type: TYPE_TB
- en: '| PEC | An open-domain dataset annotated with persona labels. | Speaker Consistency
    and Personality Response; Empathetic Response | Zhong et al. ([2020](#bib.bib460))
    |'
  prefs: []
  type: TYPE_TB
- en: '| GuessWhat?! | A visual dialogue dataset for a two-player game about object
    recognition. | Visual Dialogue | De Vries et al. ([2017](#bib.bib66)) |'
  prefs: []
  type: TYPE_TB
- en: '| VisDial | A visual dialogue dataset whose images are obtained from COCO data
    set. | Visual Dialogue | [https://visualdialog.org/data](https://visualdialog.org/data)
    |'
  prefs: []
  type: TYPE_TB
- en: '| AVSD | A video-grounded dialogue dataset. | Visual Dialogue | Yoshino et al.
    ([2018](#bib.bib436)) |'
  prefs: []
  type: TYPE_TB
- en: '| VFD | A visual dialogue dataset annotated with unique eye-gaze locations.
    | Visual Dialogue | Kamezawa et al. ([2020](#bib.bib163)) |'
  prefs: []
  type: TYPE_TB
- en: '| PhotoBook | A dataset for task-oriented visual dialogues. | Visual Dialogue
    | Haber et al. ([2019](#bib.bib118)) |'
  prefs: []
  type: TYPE_TB
- en: '| IGC | A dataset containing conversations discussing a given image. | Visual
    Dialogue | Mostafazadeh et al. ([2017](#bib.bib258)) |'
  prefs: []
  type: TYPE_TB
- en: '| Image-Chat | Contain conversations grounded with images. The conversations
    are also annotated with personality. | Visual Dialogue; Speaker Consistency and
    Personality Response | Shuster et al. ([2018](#bib.bib323)) |'
  prefs: []
  type: TYPE_TB
- en: 7 Conclusions and Trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: More and more researchers are investigating conversational tasks. One factor
    contributing to the popularity of conversational tasks is the increasing demand
    for chatbots in industry and daily life. Industry agents like Apple’s Siri, Microsoft’s
    Cortana, Facebook M, Google Assistant, and Amazon’s Alexa have brought huge convenience
    to people’s lives. Another reason is that a considerable amount of natural language
    data is in the form of dialogues, which contributes to the efforts in dialogue
    research.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this paper we discuss dialogue systems from two perspectives: model and
    system type. Dialogue systems are a complicated but promising task because it
    involves the whole process of communication between agent and human. The works
    of recent years show an overwhelming preference towards neural methods, no matter
    in task-oriented or open-domain dialogue systems. Neural methods outperform traditional
    rule-based methods, statistical methods and machine learning methods for that
    neural models have the stronger fitting ability and require less hand-crafted
    feature engineering.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We systematically summarized and categorized the latest works in dialogue systems,
    and also in other dialogue-related tasks. We hope these discussions and insights
    provide a comprehensive picture of the state-of-the-art in this area and pave
    the way for further research. Finally, we discuss some possible research trends
    arising from the works reviewed:'
  prefs: []
  type: TYPE_NORMAL
- en: Multimodal dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The world is multimodal and humans observe it via multiple senses such as vision,
    hearing, smell, taste, and touch. In a conversational interaction, humans tend
    to make responses not only based on text, but also on what they see and hear.
    Thus, some researchers argue that chatbots should also have such abilities to
    blend information from different modalities. There are some recent works trying
    to build multimodal dialogue systems (Le et al., [2019](#bib.bib179); Chauhan
    et al., [2019](#bib.bib38); Saha et al., [2020](#bib.bib303); Singla et al., [2020](#bib.bib331);
    Young et al., [2020](#bib.bib439)), but these systems are still far from mature.
  prefs: []
  type: TYPE_NORMAL
- en: Multitask dialogue systems
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Dialogue systems are categorized into task-oriented and open-domain systems.
    Such a research boundary has existed for a long time because task-oriented dialogue
    systems involve dialogue states, which constrain the decoding process. However,
    works in end-to-end task-oriented dialogue systems and knowledge-grounded open-domain
    systems provide a possibility of blending these two categories into a single framework,
    or even a single model. Such blended dialogue systems perform as assistants and
    chatbots simultaneously.
  prefs: []
  type: TYPE_NORMAL
- en: Corpus exploration on Internet
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'In Section [6](#S6 "6 Datasets ‣ Recent Advances in Deep Learning Based Dialogue
    Systems: A Systematic Survey") we reviewed many datasets for dialogue systems
    training. However, data is still far from enough to train a perfect dialogue system.
    Many learning techniques are designed to alleviate this problem, such as reinforcement
    learning, meta-learning, transfer learning, and active learning. But many works
    ignore a significant source of information, which is the dialogue corpus on the
    Internet. There is a large volume of conversational corpus on the Internet but
    people have no access to the raw corpus because much of it is in a messy condition.
    In the future, dialogue agents should be able to explore useful corpus on the
    Internet in real-time for training. This can be achieved by standardizing online
    corpus access and their related legal terms. Moreover, real-time conversational
    corpus exploration can be an independent task that deserves study.'
  prefs: []
  type: TYPE_NORMAL
- en: User modeling
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: User modeling is a hot topic in both dialogue generation (Gür et al., [2018](#bib.bib117);
    Serras et al., [2019](#bib.bib315)) and dialogue systems evaluation (Kannan and
    Vinyals, [2017](#bib.bib164)). Basically, the user modeling module tries to simulate
    the real decisions and actions of a human user. It makes decisions based on the
    dialogue state or dialogue history. In dialogue generation tasks, modeling the
    user helps the agent converse more coherently, based on the background information
    or even speaking habits. Besides that, a mature user simulator can provide an
    interactive training environment, which reduces the reliance on annotated training
    samples when training a dialogue system. In dialogue systems evaluation tasks,
    a user simulator provides user messages to test a dialogue agent. More recent
    user simulators also give feedback concerning the responses generated by the dialogue
    agent. However, user modeling is a challenging task since no matter explicit user
    simulation or implicit user modeling is actually the same in difficulty as response
    generation. Since response generation systems are not perfect yet, user modeling
    can still be a topic worthy of study.
  prefs: []
  type: TYPE_NORMAL
- en: Dialogue generation with a long-term goal
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Most of our daily conversations are chitchats without any purpose. However,
    there are quite a few scenarios when we purposely guide the conversation content
    to achieve a specific goal. Current open-domain dialogue systems tend to model
    the conversation without a long-term goal, which does not exhibit enough intelligence.
    There are some recent works that apply reinforcement policy learning to model
    a long-term reward which encourages the agent to converse with a long-term goal,
    such as the work of Xu et al. ([2020a](#bib.bib426)). This topic will lead to
    strong artificial intelligence, which is useful in some real-life applications
    such as negotiation or story-telling chatbots.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This research/project is supported by A*STAR under its Industry Alignment Fund
    (LOA Award I1901E0046).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Agarwal et al. (2020) Agarwal S, Bui T, Lee JY, Konstas I, Rieser V (2020)
    History for visual dialog: Do we really need it? arXiv preprint arXiv:200507493'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aghajanyan et al. (2020) Aghajanyan A, Maillard J, Shrivastava A, Diedrick K,
    Haeger M, Li H, Mehdad Y, Stoyanov V, Kumar A, Lewis M, et al. (2020) Conversational
    semantic parsing. arXiv preprint arXiv:200913655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akama et al. (2020) Akama R, Yokoi S, Suzuki J, Inui K (2020) Filtering noisy
    dialogue corpora by connectivity and content relatedness. arXiv preprint arXiv:200414008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alberti et al. (2019) Alberti C, Ling J, Collins M, Reitter D (2019) Fusion
    of detected objects in text for visual question answering. arXiv preprint arXiv:190805054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aloysius and Geetha (2017) Aloysius N, Geetha M (2017) A review on deep convolutional
    neural networks. In: 2017 International Conference on Communication and Signal
    Processing (ICCSP), IEEE, pp 0588–0592'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Annervaz et al. (2018) Annervaz K, Chowdhury SBR, Dukkipati A (2018) Learning
    beyond datasets: Knowledge graph augmented neural networks for natural language
    processing. arXiv preprint arXiv:180205930'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arora et al. (2013) Arora S, Batra K, Singh S (2013) Dialogue system: A brief
    review. arXiv preprint arXiv:13064134'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asghar et al. (2016) Asghar N, Poupart P, Jiang X, Li H (2016) Deep active learning
    for dialogue generation. arXiv preprint arXiv:161203929
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Asri et al. (2016) Asri LE, He J, Suleman K (2016) A sequence-to-sequence model
    for user simulation in spoken dialogue systems. arXiv preprint arXiv:160700070
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Asri et al. (2017) Asri LE, Schulz H, Sharma S, Zumer J, Harris J, Fine E,
    Mehrotra R, Suleman K (2017) Frames: a corpus for adding memory to goal-oriented
    dialogue systems. arXiv preprint arXiv:170400057'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aubert et al. (1994) Aubert X, Dugast C, Ney H, Steinbiss V (1994) Large vocabulary
    continuous speech recognition of wall street journal data. In: Proceedings of
    ICASSP’94. IEEE International Conference on Acoustics, Speech and Signal Processing,
    IEEE, vol 2, pp II–129'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bahdanau et al. (2014) Bahdanau D, Cho K, Bengio Y (2014) Neural machine translation
    by jointly learning to align and translate. arXiv preprint arXiv:14090473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baheti et al. (2020) Baheti A, Ritter A, Small K (2020) Fluent response generation
    for conversational question answering. arXiv preprint arXiv:200510464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balakrishnan et al. (2019) Balakrishnan A, Rao J, Upasani K, White M, Subba
    R (2019) Constrained decoding for neural nlg from compositional representations
    in task-oriented dialogue. arXiv preprint arXiv:190607220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Banerjee and Lavie (2005) Banerjee S, Lavie A (2005) Meteor: An automatic metric
    for mt evaluation with improved correlation with human judgments. In: Proceedings
    of the acl workshop on intrinsic and extrinsic evaluation measures for machine
    translation and/or summarization, pp 65–72'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bao et al. (2019a) Bao S, He H, Wang F, Lian R, Wu H (2019a) Know more about
    each other: Evolving dialogue strategy via compound assessment. arXiv preprint
    arXiv:190600549'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bao et al. (2019b) Bao S, He H, Wang F, Wu H, Wang H (2019b) Plato: Pre-trained
    dialogue generation model with discrete latent variable. arXiv preprint arXiv:191007931'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bapna et al. (2017) Bapna A, Tur G, Hakkani-Tur D, Heck L (2017) Towards zero-shot
    frame semantic parsing for domain scaling. arXiv preprint arXiv:170702363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Beeferman et al. (2019) Beeferman D, Brannon W, Roy D (2019) Radiotalk: A large-scale
    corpus of talk radio transcripts. arXiv preprint arXiv:190707073'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio et al. (1994) Bengio Y, Simard P, Frasconi P (1994) Learning long-term
    dependencies with gradient descent is difficult. IEEE transactions on neural networks
    5(2):157–166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bevendorff et al. (2020) Bevendorff J, Al Khatib K, Potthast M, Stein B (2020)
    Crawling and preprocessing mailing lists at scale for dialog analysis. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    1151–1158'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bi et al. (2019) Bi W, Gao J, Liu X, Shi S (2019) Fine-grained sentence functions
    for short-text conversation. arXiv preprint arXiv:190710302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bordes et al. (2013) Bordes A, Usunier N, Garcia-Duran A, Weston J, Yakhnenko
    O (2013) Translating embeddings for modeling multi-relational data. In: Neural
    Information Processing Systems (NIPS), pp 1–9'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bordes et al. (2014) Bordes A, Glorot X, Weston J, Bengio Y (2014) A semantic
    matching energy function for learning with multi-relational data. Machine Learning
    94(2):233–259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bordes et al. (2016) Bordes A, Boureau YL, Weston J (2016) Learning end-to-end
    goal-oriented dialog. arXiv preprint arXiv:160507683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bosselut et al. (2019) Bosselut A, Rashkin H, Sap M, Malaviya C, Celikyilmaz
    A, Choi Y (2019) Comet: Commonsense transformers for automatic knowledge graph
    construction. arXiv preprint arXiv:190605317'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bouchacourt and Baroni (2019) Bouchacourt D, Baroni M (2019) Miss tools and
    mr fruit: Emergent communication in agents learning about object affordances.
    arXiv preprint arXiv:190511871'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boyd et al. (2020) Boyd A, Puri R, Shoeybi M, Patwary M, Catanzaro B (2020)
    Large scale multi-actor generative dialog modeling. arXiv preprint arXiv:200506114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bruni and Fernandez (2017) Bruni E, Fernandez R (2017) Adversarial evaluation
    for open-domain dialogue generation. In: Proceedings of the 18th Annual SIGdial
    Meeting on Discourse and Dialogue, pp 284–288'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Budzianowski et al. (2018) Budzianowski P, Wen TH, Tseng BH, Casanueva I, Ultes
    S, Ramadan O, Gašić M (2018) Multiwoz–a large-scale multi-domain wizard-of-oz
    dataset for task-oriented dialogue modelling. arXiv preprint arXiv:181000278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Busso et al. (2008) Busso C, Bulut M, Lee CC, Kazemzadeh A, Mower E, Kim S,
    Chang JN, Lee S, Narayanan SS (2008) Iemocap: Interactive emotional dyadic motion
    capture database. Language resources and evaluation 42(4):335–359'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Byrne et al. (2019) Byrne B, Krishnamoorthi K, Sankar C, Neelakantan A, Duckworth
    D, Yavuz S, Goodrich B, Dubey A, Cedilnik A, Kim KY (2019) Taskmaster-1: Toward
    a realistic and diverse dialog dataset. arXiv preprint arXiv:190905358'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cahill et al. (1999) Cahill L, Doran C, Evans R, Mellish C, Paiva D, Reape
    M, Scott D, Tipper N (1999) In search of a reference architecture for nlg systems.
    In: Proceedings of the 7th european workshop on natural language generation, Citeseer,
    pp 77–85'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Campagna et al. (2020) Campagna G, Foryciarz A, Moradshahi M, Lam MS (2020)
    Zero-shot transfer learning with synthesized data for multi-domain dialogue state
    tracking. arXiv preprint arXiv:200500891
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cao et al. (2019) Cao J, Tanana M, Imel ZE, Poitras E, Atkins DC, Srikumar
    V (2019) Observing dialogue in therapy: Categorizing and forecasting behavioral
    codes. arXiv preprint arXiv:190700326'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carlson et al. (2002) Carlson L, Okurowski ME, Marcu D (2002) RST discourse
    treebank. Linguistic Data Consortium, University of Pennsylvania
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chandramohan et al. (2011) Chandramohan S, Geist M, Lefevre F, Pietquin O (2011)
    User simulation in dialogue systems using inverse reinforcement learning. In:
    Twelfth Annual Conference of the International Speech Communication Association'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chauhan et al. (2019) Chauhan H, Firdaus M, Ekbal A, Bhattacharyya P (2019)
    Ordinal and attribute aware response generation in a multimodal dialogue system.
    In: Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics, pp 5437–5447'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2017a) Chen H, Liu X, Yin D, Tang J (2017a) A survey on dialogue
    systems: Recent advances and new frontiers. Acm Sigkdd Explorations Newsletter
    19(2):25–35'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and Yang (2020) Chen J, Yang D (2020) Multi-view sequence-to-sequence models
    with conversational structure for abstractive dialogue summarization. arXiv preprint
    arXiv:201001672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020a) Chen J, Zhang R, Mao Y, Xu J (2020a) Parallel interactive
    networks for multi-domain dialogue state generation. arXiv preprint arXiv:200907616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2017b) Chen L, Zhou X, Chang C, Yang R, Yu K (2017b) Agent-aware
    dropout dqn for safe and efficient on-line dialogue policy learning. In: Proceedings
    of the 2017 Conference on Empirical Methods in Natural Language Processing, pp
    2454–2464'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019a) Chen M, Liu R, Shen L, Yuan S, Zhou J, Wu Y, He X, Zhou
    B (2019a) The jddc corpus: A large-scale multi-turn chinese dialogue dataset for
    e-commerce customer service. arXiv preprint arXiv:191109969'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019b) Chen W, Chen J, Qin P, Yan X, Wang WY (2019b) Semantically
    conditioned dialog response generation via hierarchical disentangled self-attention.
    arXiv preprint arXiv:190512866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019c) Chen X, Xu J, Xu B (2019c) A working memory model for task-oriented
    dialog response generation. In: Proceedings of the 57th Annual Meeting of the
    Association for Computational Linguistics, pp 2687–2693'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2020b) Chen X, Meng F, Li P, Chen F, Xu S, Xu B, Zhou J (2020b)
    Bridging the gap between prior and posterior knowledge selection for knowledge-grounded
    dialogue generation. In: Proceedings of the 2020 Conference on Empirical Methods
    in Natural Language Processing (EMNLP), pp 3426–3437'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2019d) Chen YC, Li L, Yu L, El Kholy A, Ahmed F, Gan Z, Cheng
    Y, Liu J (2019d) Uniter: Learning universal image-text representations. ECCV'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2016) Chen YN, Hakkani-Tür D, Tür G, Gao J, Deng L (2016) End-to-end
    memory networks with knowledge carryover for multi-turn spoken language understanding.
    In: Interspeech, pp 3245–3249'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2020) Cheng J, Agrawal D, Alonso HM, Bhargava S, Driesen J, Flego
    F, Kaplan D, Kartsaklis D, Li L, Piraviperumal D, et al. (2020) Conversational
    semantic parsing for dialog state tracking. arXiv preprint arXiv:201012770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho and May (2020) Cho H, May J (2020) Grounding conversations with improvised
    dialogues. arXiv preprint arXiv:200409544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cho et al. (2014a) Cho K, Van Merriënboer B, Bahdanau D, Bengio Y (2014a) On
    the properties of neural machine translation: Encoder-decoder approaches. arXiv
    preprint arXiv:14091259'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cho et al. (2014b) Cho K, Van Merriënboer B, Gulcehre C, Bahdanau D, Bougares
    F, Schwenk H, Bengio Y (2014b) Learning phrase representations using rnn encoder-decoder
    for statistical machine translation. arXiv preprint arXiv:14061078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi et al. (2018) Choi E, He H, Iyyer M, Yatskar M, Yih Wt, Choi Y, Liang
    P, Zettlemoyer L (2018) Quac: Question answering in context. arXiv preprint arXiv:180807036'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chung et al. (2014) Chung J, Gulcehre C, Cho K, Bengio Y (2014) Empirical evaluation
    of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:14123555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chung et al. (2019) Chung YL, Kuzmenko E, Tekiroglu SS, Guerini M (2019) Conan–counter
    narratives through nichesourcing: a multilingual dataset of responses to fight
    online hate speech. arXiv preprint arXiv:191003270'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cogswell et al. (2020) Cogswell M, Lu J, Jain R, Lee S, Parikh D, Batra D (2020)
    Dialog without dialog data: Learning visual dialog agents from vqa data. arXiv
    preprint arXiv:200712750'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conneau et al. (2016) Conneau A, Schwenk H, Barrault L, Lecun Y (2016) Very
    deep convolutional networks for text classification. arXiv preprint arXiv:160601781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Coope et al. (2020) Coope S, Farghly T, Gerz D, Vulić I, Henderson M (2020)
    Span-convert: Few-shot span extraction for dialog with pretrained conversational
    representations. arXiv preprint arXiv:200508866'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Csáky et al. (2019) Csáky R, Purgai P, Recski G (2019) Improving neural conversational
    models with entropy-based data filtering. arXiv preprint arXiv:190505471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cui et al. (2020) Cui L, Wu Y, Liu S, Zhang Y, Zhou M (2020) Mutual: A dataset
    for multi-turn dialogue reasoning. arXiv preprint arXiv:200404494'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dai et al. (2020) Dai Y, Li H, Tang C, Li Y, Sun J, Zhu X (2020) Learning low-resource
    end-to-end goal-oriented dialog for fast and reliable system deployment. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    609–618'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dai et al. (2019) Dai Z, Yang Z, Yang Y, Carbonell J, Le QV, Salakhutdinov
    R (2019) Transformer-xl: Attentive language models beyond a fixed-length context.
    arXiv preprint arXiv:190102860'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dalton et al. (2020) Dalton J, Xiong C, Callan J (2020) Trec cast 2019: The
    conversational assistance track overview. arXiv preprint arXiv:200313624'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Danescu-Niculescu-Mizil and Lee (2011) Danescu-Niculescu-Mizil C, Lee L (2011)
    Chameleons in imagined conversations: A new approach to understanding coordination
    of linguistic style in dialogs. arXiv preprint arXiv:11063077'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Danescu-Niculescu-Mizil et al. (2013) Danescu-Niculescu-Mizil C, Sudhof M, Jurafsky
    D, Leskovec J, Potts C (2013) A computational approach to politeness with application
    to social factors. arXiv preprint arXiv:13066078
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'De Vries et al. (2017) De Vries H, Strub F, Chandar S, Pietquin O, Larochelle
    H, Courville A (2017) Guesswhat?! visual object discovery through multi-modal
    dialogue. In: Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pp 5503–5512'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2012) Deng L, Tur G, He X, Hakkani-Tur D (2012) Use of kernel
    deep convex networks and end-to-end learning for spoken language understanding.
    In: 2012 IEEE Spoken Language Technology Workshop (SLT), IEEE, pp 210–215'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deoras and Sarikaya (2013) Deoras A, Sarikaya R (2013) Deep belief network
    based semantic taggers for spoken language understanding. In: Interspeech, pp
    2713–2717'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deriu et al. (2020) Deriu J, Tuggener D, von Däniken P, Campos JA, Rodrigo
    A, Belkacem T, Soroa A, Agirre E, Cieliebak M (2020) Spot the bot: A robust and
    efficient framework for the evaluation of conversational dialogue systems. arXiv
    preprint arXiv:201002140'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2018) Devlin J, Chang MW, Lee K, Toutanova K (2018) Bert: Pre-training
    of deep bidirectional transformers for language understanding. arXiv preprint
    arXiv:181004805'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhingra et al. (2016) Dhingra B, Li L, Li X, Gao J, Chen YN, Ahmed F, Deng L
    (2016) Towards end-to-end reinforcement learning of dialogue agents for information
    access. arXiv preprint arXiv:160900777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dinan et al. (2018) Dinan E, Roller S, Shuster K, Fan A, Auli M, Weston J (2018)
    Wizard of wikipedia: Knowledge-powered conversational agents. arXiv preprint arXiv:181101241'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dinan et al. (2019) Dinan E, Logacheva V, Malykh V, Miller A, Shuster K, Urbanek
    J, Kiela D, Szlam A, Serban I, Lowe R, et al. (2019) The second conversational
    intelligence challenge (convai2). arXiv preprint arXiv:190200098
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. (2017) Dong L, Huang S, Wei F, Lapata M, Zhou M, Xu K (2017) Learning
    to generate product reviews from attributes. In: Proceedings of the 15th Conference
    of the European Chapter of the Association for Computational Linguistics: Volume
    1, Long Papers, pp 623–632'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Du et al. (2019) Du N, Chen K, Kannan A, Tran L, Chen Y, Shafran I (2019) Extracting
    symptoms and their status from clinical conversations. arXiv preprint arXiv:190602239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Du and Black (2019) Du W, Black AW (2019) Boosting dialog response generation.
    In: Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics, pp 38–43'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dušek and Jurčíček (2016a) Dušek O, Jurčíček F (2016a) A context-aware natural
    language generator for dialogue systems. arXiv preprint arXiv:160807076
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dušek and Jurčíček (2016b) Dušek O, Jurčíček F (2016b) Sequence-to-sequence
    generation for spoken dialogue via deep syntax trees and strings. arXiv preprint
    arXiv:160605491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Elder et al. (2020) Elder H, O’Connor A, Foster J (2020) How to make neural
    natural language generation as reliable as templates in task-oriented dialogue.
    In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP), pp 2877–2888'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elman (1990) Elman JL (1990) Finding structure in time. Cognitive science 14(2):179–211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eric and Manning (2017) Eric M, Manning CD (2017) Key-value retrieval networks
    for task-oriented dialogue. arXiv preprint arXiv:170505414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Esteve et al. (2010) Esteve Y, Bazillon T, Antoine JY, Béchet F, Farinas J
    (2010) The epac corpus: Manual and automatic annotations of conversational speech
    in french broadcast news. In: LREC, Citeseer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fan et al. (2019) Fan A, Jernite Y, Perez E, Grangier D, Weston J, Auli M (2019)
    Eli5: Long form question answering. arXiv preprint arXiv:190709190'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fan et al. (2014) Fan M, Zhou Q, Chang E, Zheng F (2014) Transition-based knowledge
    graph embedding with relational mapping properties. In: Proceedings of the 28th
    Pacific Asia conference on language, information and computing, pp 328–337'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feldman and El-Yaniv (2019) Feldman Y, El-Yaniv R (2019) Multi-hop paragraph
    retrieval for open-domain question answering. arXiv preprint arXiv:190606606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. (2019) Feng J, Tao C, Wu W, Feng Y, Zhao D, Yan R (2019) Learning
    a matching model with co-teaching for multi-turn response selection in retrieval-based
    dialogue systems. arXiv preprint arXiv:190604413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. (2020a) Feng S, Chen H, Li K, Yin D (2020a) Posterior-gan: Towards
    informative and coherent response generation with posterior generative adversarial
    network. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol 34,
    pp 7708–7715'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. (2020b) Feng S, Ren X, Chen H, Sun B, Li K, Sun X (2020b) Regularizing
    dialogue generation by imitating implicit scenarios. arXiv preprint arXiv:201001893
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. (2020c) Feng S, Wan H, Gunasekara C, Patel SS, Joshi S, Lastras
    LA (2020c) doc2dial: A goal-oriented document-grounded dialogue dataset. arXiv
    preprint arXiv:201106623'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferracane et al. (2019) Ferracane E, Durrett G, Li JJ, Erk K (2019) Evaluating
    discourse in structured text representations. arXiv preprint arXiv:190601472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ficler and Goldberg (2017) Ficler J, Goldberg Y (2017) Controlling linguistic
    style aspects in neural language generation. arXiv preprint arXiv:170702633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Finn et al. (2017) Finn C, Abbeel P, Levine S (2017) Model-agnostic meta-learning
    for fast adaptation of deep networks. In: International Conference on Machine
    Learning, PMLR, pp 1126–1135'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fung et al. (2016) Fung P, Dey A, Siddique FB, Lin R, Yang Y, Bertero D, Wan
    Y, Chan RHY, Wu CS (2016) Zara: a virtual interactive dialogue system incorporating
    emotion, sentiment and personality recognition. In: Proceedings of COLING 2016,
    the 26th International Conference on Computational Linguistics: System Demonstrations,
    pp 278–281'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Galley et al. (2015) Galley M, Brockett C, Sordoni A, Ji Y, Auli M, Quirk C,
    Mitchell M, Gao J, Dolan B (2015) deltableu: A discriminative metric for generation
    tasks with intrinsically diverse targets. arXiv preprint arXiv:150606863'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gan et al. (2019) Gan Z, Cheng Y, Kholy AE, Li L, Liu J, Gao J (2019) Multi-step
    reasoning via recurrent dual attention for visual dialog. arXiv preprint arXiv:190200579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gan et al. (2020) Gan Z, Chen YC, Li L, Zhu C, Cheng Y, Liu J (2020) Large-scale
    adversarial training for vision-and-language representation learning. arXiv preprint
    arXiv:200606195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gangadharaiah and Narayanaswamy (2020) Gangadharaiah R, Narayanaswamy B (2020)
    Recursive template-based frame generation for task oriented dialog. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    2059–2064'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2018) Gao J, Galley M, Li L (2018) Neural approaches to conversational
    ai. In: The 41st International ACM SIGIR Conference on Research & Development
    in Information Retrieval, pp 1371–1374'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2020a) Gao S, Zhang Y, Ou Z, Yu Z (2020a) Paraphrase augmented task-oriented
    dialog generation. arXiv preprint arXiv:200407462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2019) Gao X, Zhang Y, Lee S, Galley M, Brockett C, Gao J, Dolan
    B (2019) Structuring latent spaces for stylized response generation. arXiv preprint
    arXiv:190905361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2020b) Gao X, Zhang Y, Galley M, Brockett C, Dolan B (2020b) Dialogue
    response ranking training with large-scale human feedback data. arXiv preprint
    arXiv:200906978
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2020c) Gao Y, Wu CS, Joty S, Xiong C, Socher R, King I, Lyu M,
    Hoi SC (2020c) Explicit memory tracker with coarse-to-fine reasoning for conversational
    machine reading. In: Proceedings of the 58th Annual Meeting of the Association
    for Computational Linguistics, pp 935–945'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gehring et al. (2017) Gehring J, Auli M, Grangier D, Yarats D, Dauphin YN (2017)
    Convolutional sequence to sequence learning. In: International Conference on Machine
    Learning, PMLR, pp 1243–1252'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghazvininejad et al. (2018) Ghazvininejad M, Brockett C, Chang MW, Dolan B,
    Gao J, Yih Wt, Galley M (2018) A knowledge-grounded neural conversation model.
    In: Proceedings of the AAAI Conference on Artificial Intelligence, vol 32'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gliwa et al. (2019) Gliwa B, Mochol I, Biesek M, Wawer A (2019) Samsum corpus:
    A human-annotated dialogue dataset for abstractive summarization. arXiv preprint
    arXiv:191112237'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goddeau et al. (1996) Goddeau D, Meng H, Polifroni J, Seneff S, Busayapongchai
    S (1996) A form-based dialogue manager for spoken language applications. In: Proceeding
    of Fourth International Conference on Spoken Language Processing. ICSLP’96, IEEE,
    vol 2, pp 701–704'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Golovanov et al. (2019) Golovanov S, Kurbanov R, Nikolenko S, Truskovskyi K,
    Tselousov A, Wolf T (2019) Large-scale transfer learning for natural language
    generation. In: Proceedings of the 57th Annual Meeting of the Association for
    Computational Linguistics, pp 6053–6058'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow IJ, Pouget-Abadie J, Mirza M, Xu B, Warde-Farley
    D, Ozair S, Courville A, Bengio Y (2014) Generative adversarial networks. arXiv
    preprint arXiv:14062661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gopalakrishnan et al. (2019) Gopalakrishnan K, Hedayatnia B, Chen Q, Gottardi
    A, Kwatra S, Venkatesh A, Gabriel R, Hakkani-Tür D, AI AA (2019) Topical-chat:
    Towards knowledge-grounded open-domain conversations. In: INTERSPEECH, pp 1891–1895'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gordon-Hall et al. (2020) Gordon-Hall G, Gorinski PJ, Cohen SB (2020) Learning
    dialog policies from weak demonstrations. arXiv preprint arXiv:200411054
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graves et al. (2014) Graves A, Wayne G, Danihelka I (2014) Neural turing machines.
    arXiv preprint arXiv:14105401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graves et al. (2016) Graves A, Wayne G, Reynolds M, Harley T, Danihelka I, Grabska-Barwińska
    A, Colmenarejo SG, Grefenstette E, Ramalho T, Agapiou J, et al. (2016) Hybrid
    computing using a neural network with dynamic external memory. Nature 538(7626):471–476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gruber and Jockisch (2020) Gruber N, Jockisch A (2020) Are gru cells more specific
    and lstm cells more sensitive in motive classification of text? Frontiers in Artificial
    Intelligence 3(40):1–6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gu et al. (2016) Gu J, Lu Z, Li H, Li VO (2016) Incorporating copying mechanism
    in sequence-to-sequence learning. In: Proceedings of the 54th Annual Meeting of
    the Association for Computational Linguistics (Volume 1: Long Papers), Association
    for Computational Linguistics, Berlin, Germany, pp 1631–1640, DOI 10.18653/v1/P16-1154,
    URL [https://www.aclweb.org/anthology/P16-1154](https://www.aclweb.org/anthology/P16-1154)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2019) Guo Q, Qiu X, Liu P, Shao Y, Xue X, Zhang Z (2019) Star-transformer.
    arXiv preprint arXiv:190209113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2020) Guo X, Yu M, Gao Y, Gan C, Campbell M, Chang S (2020) Interactive
    fiction game playing as multi-paragraph reading comprehension with reinforcement
    learning. arXiv preprint arXiv:201002386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gür et al. (2018) Gür I, Hakkani-Tür D, Tür G, Shah P (2018) User modeling
    for task oriented dialogues. In: 2018 IEEE Spoken Language Technology Workshop
    (SLT), IEEE, pp 900–906'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Haber et al. (2019) Haber J, Baumgärtner T, Takmaz E, Gelderloos L, Bruni E,
    Fernández R (2019) The photobook dataset: Building common ground through visually-grounded
    dialogue. arXiv preprint arXiv:190601530'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hahn et al. (2020) Hahn M, Krantz J, Batra D, Parikh D, Rehg JM, Lee S, Anderson
    P (2020) Where are you? localization from embodied dialog. arXiv preprint arXiv:201108277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hakkani-Tür et al. (2016) Hakkani-Tür D, Tür G, Celikyilmaz A, Chen YN, Gao
    J, Deng L, Wang YY (2016) Multi-domain joint semantic frame parsing using bi-directional
    rnn-lstm. In: Interspeech, pp 715–719'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ham et al. (2020) Ham D, Lee JG, Jang Y, Kim KE (2020) End-to-end neural pipeline
    for goal-oriented dialogue systems using gpt-2\. In: Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics, pp 583–592'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Han et al. (2019) Han M, Kang M, Jung H, Hwang SJ (2019) Episodic memory reader:
    Learning what to remember for question answering from streaming data. arXiv preprint
    arXiv:190306164'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hancock et al. (2019) Hancock B, Bordes A, Mazare PE, Weston J (2019) Learning
    from dialogue after deployment: Feed yourself, chatbot! arXiv preprint arXiv:190105415'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hashemi et al. (2016) Hashemi HB, Asiaee A, Kraft R (2016) Query intent detection
    using convolutional neural networks. In: International Conference on Web Search
    and Data Mining, Workshop on Query Understanding'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2017) He H, Balakrishnan A, Eric M, Liang P (2017) Learning symmetric
    collaborative dialogue agents with dynamic knowledge graph embeddings. arXiv preprint
    arXiv:170407130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2016) He K, Zhang X, Ren S, Sun J (2016) Deep residual learning
    for image recognition. In: Proceedings of the IEEE conference on computer vision
    and pattern recognition, pp 770–778'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He and Glass (2019) He T, Glass J (2019) Negative training for neural dialogue
    response generation. arXiv preprint arXiv:190302134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2020a) He W, Yang M, Yan R, Li C, Shen Y, Xu R (2020a) Amalgamating
    knowledge from two teachers for task-oriented dialogue system with adversarial
    training. In: Proceedings of the 2020 Conference on Empirical Methods in Natural
    Language Processing (EMNLP), pp 3498–3507'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. (2020b) He X, Chen S, Ju Z, Dong X, Fang H, Wang S, Yang Y, Zeng
    J, Zhang R, Zhang R, et al. (2020b) Meddialog: Two large-scale medical dialogue
    datasets. arXiv e-prints pp arXiv–2004'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henderson et al. (2008) Henderson J, Lemon O, Georgila K (2008) Hybrid reinforcement/supervised
    learning of dialogue policies from fixed data sets. Computational Linguistics
    34(4):487–511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Henderson (2015) Henderson M (2015) Machine learning for dialog state tracking:
    A review. In: Proceedings of The First International Workshop on Machine Learning
    in Spoken Language Processing'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Henderson et al. (2013) Henderson M, Thomson B, Young S (2013) Deep neural
    network approach for the dialog state tracking challenge. In: Proceedings of the
    SIGDIAL 2013 Conference, pp 467–471'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Henderson et al. (2014a) Henderson M, Thomson B, Williams JD (2014a) The second
    dialog state tracking challenge. In: Proceedings of the 15th annual meeting of
    the special interest group on discourse and dialogue (SIGDIAL), pp 263–272'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Henderson et al. (2014b) Henderson M, Thomson B, Williams JD (2014b) The third
    dialog state tracking challenge. In: 2014 IEEE Spoken Language Technology Workshop
    (SLT), IEEE, pp 324–329'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henderson et al. (2019a) Henderson M, Budzianowski P, Casanueva I, Coope S,
    Gerz D, Kumar G, Mrkšić N, Spithourakis G, Su PH, Vulić I, et al. (2019a) A repository
    of conversational datasets. arXiv preprint arXiv:190406472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henderson et al. (2019b) Henderson M, Vulić I, Gerz D, Casanueva I, Budzianowski
    P, Coope S, Spithourakis G, Wen TH, Mrkšić N, Su PH (2019b) Training neural response
    selection for task-oriented dialogue systems. arXiv preprint arXiv:190601543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber (1997) Hochreiter S, Schmidhuber J (1997) Long short-term
    memory. Neural computation 9(8):1735–1780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hochreiter et al. (2001) Hochreiter S, Bengio Y, Frasconi P, Schmidhuber J,
    et al. (2001) Gradient flow in recurrent nets: the difficulty of learning long-term
    dependencies'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hokamp and Liu (2017) Hokamp C, Liu Q (2017) Lexically constrained decoding
    for sequence generation using grid beam search. arXiv preprint arXiv:170407138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hopfield (1982) Hopfield JJ (1982) Neural networks and physical systems with
    emergent collective computational abilities. Proceedings of the national academy
    of sciences 79(8):2554–2558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosseini-Asl et al. (2020) Hosseini-Asl E, McCann B, Wu CS, Yavuz S, Socher
    R (2020) A simple language model for task-oriented dialogue. arXiv preprint arXiv:200500796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2020) Hu J, Yang Y, Chen C, Yu Z, et al. (2020) Sas: Dialogue state
    tracking via slot attention and slot information sharing. In: Proceedings of the
    58th Annual Meeting of the Association for Computational Linguistics, pp 6366–6375'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2019) Hu JE, Rudinger R, Post M, Van Durme B (2019) Parabank: Monolingual
    bitext generation and sentential paraphrasing via lexically-constrained neural
    machine translation. In: Proceedings of the AAAI Conference on Artificial Intelligence,
    vol 33, pp 6521–6528'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hu et al. (2017) Hu Z, Yang Z, Liang X, Salakhutdinov R, Xing EP (2017) Toward
    controlled generation of text. In: International Conference on Machine Learning,
    PMLR, pp 1587–1596'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hua and Wang (2019) Hua X, Wang L (2019) Sentence-level content planning and
    style specification for neural text generation. arXiv preprint arXiv:190900734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hua et al. (2020) Hua Y, Li YF, Haffari G, Qi G, Wu T (2020) Few-shot complex
    knowledge base question answering via meta reinforcement learning. arXiv preprint
    arXiv:201015877
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2020a) Huang L, Ye Z, Qin J, Lin L, Liang X (2020a) Grade: Automatic
    graph-enhanced coherence metric for evaluating open-domain dialogue systems. arXiv
    preprint arXiv:201003994'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2018) Huang X, Jiang J, Zhao D, Feng Y, Hong Y (2018) Natural
    Language Processing and Chinese Computing: 6th CCF International Conference, NLPCC
    2017, Dalian, China, November 8–12, 2017, Proceedings, vol 10619\. Springer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2020b) Huang X, Qi J, Sun Y, Zhang R (2020b) Semi-supervised dialogue
    policy learning via stochastic reward estimation. arXiv preprint arXiv:200504379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2020c) Huang Y, Feng J, Hu M, Wu X, Du X, Ma S (2020c) Meta-reinforced
    multi-domain state generator for dialogue systems. In: Proceedings of the 58th
    Annual Meeting of the Association for Computational Linguistics, pp 7109–7118'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2020d) Huang Z, Zeng Z, Liu B, Fu D, Fu J (2020d) Pixel-bert:
    Aligning image pixels with text by deep multi-modal transformers. arXiv preprint
    arXiv:200400849'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaderberg et al. (2016) Jaderberg M, Mnih V, Czarnecki WM, Schaul T, Leibo JZ,
    Silver D, Kavukcuoglu K (2016) Reinforcement learning with unsupervised auxiliary
    tasks. arXiv preprint arXiv:161105397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jang et al. (2017) Jang Y, Song Y, Yu Y, Kim Y, Kim G (2017) Tgif-qa: Toward
    spatio-temporal reasoning in visual question answering. In: Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition, pp 2758–2766'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaques et al. (2020) Jaques N, Shen JH, Ghandeharioun A, Ferguson C, Lapedriza
    A, Jones N, Gu SS, Picard R (2020) Human-centric dialog training via offline reinforcement
    learning. arXiv preprint arXiv:201005848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ji et al. (2020) Ji C, Zhou X, Zhang Y, Liu X, Sun C, Zhu C, Zhao T (2020) Cross
    copy network for dialogue generation. arXiv preprint arXiv:201011539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ji et al. (2015) Ji G, He S, Xu L, Liu K, Zhao J (2015) Knowledge graph embedding
    via dynamic mapping matrix. In: Proceedings of the 53rd annual meeting of the
    association for computational linguistics and the 7th international joint conference
    on natural language processing (volume 1: Long papers), pp 687–696'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ji et al. (2022) Ji S, Pan S, Cambria E, Marttinen P, Yu PS (2022) A survey
    on knowledge graphs: Representation, acquisition and applications. IEEE Transactions
    on Neural Networks and Learning Systems 33(10)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jia et al. (2020) Jia Q, Liu Y, Ren S, Zhu KQ, Tang H (2020) Multi-turn response
    selection using dialogue dependency relations. arXiv preprint arXiv:201001502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jordan (1986) Jordan M (1986) Serial order: a parallel distributed processing
    approach. technical report, june 1985-march 1986\. Tech. rep., California Univ.,
    San Diego, La Jolla (USA). Inst. for Cognitive Science'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jung et al. (2020) Jung J, Son B, Lyu S (2020) Attnio: Knowledge graph exploration
    with in-and-out attention flow for knowledge-grounded dialogue. In: Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),
    pp 3484–3497'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jurafsky (1997) Jurafsky D (1997) Switchboard swbd-damsl shallow-discourse-function
    annotation coders manual. Institute of Cognitive Science Technical Report
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kale and Rastogi (2020) Kale M, Rastogi A (2020) Template guided text generation
    for task-oriented dialogue. In: Proceedings of the 2020 Conference on Empirical
    Methods in Natural Language Processing (EMNLP), Association for Computational
    Linguistics, Online, pp 6505–6520, DOI 10.18653/v1/2020.emnlp-main.527, URL [https://www.aclweb.org/anthology/2020.emnlp-main.527](https://www.aclweb.org/anthology/2020.emnlp-main.527)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kamezawa et al. (2020) Kamezawa H, Nishida N, Shimizu N, Miyazaki T, Nakayama
    H (2020) A visually-grounded first-person dialogue dataset with verbal and non-verbal
    responses. In: Proceedings of the 2020 Conference on Empirical Methods in Natural
    Language Processing (EMNLP), pp 3299–3310'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kannan and Vinyals (2017) Kannan A, Vinyals O (2017) Adversarial evaluation
    of dialogue models. arXiv preprint arXiv:170108198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keskar et al. (2019) Keskar NS, McCann B, Varshney LR, Xiong C, Socher R (2019)
    Ctrl: A conditional transformer language model for controllable generation. arXiv
    preprint arXiv:190905858'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2018) Kim A, Song HJ, Park SB, et al. (2018) A two-step neural dialog
    state tracker for task-oriented dialog processing. Computational intelligence
    and neuroscience 2018
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2020) Kim H, Kim B, Kim G (2020) Will i sound like me? improving
    persona consistency in dialogues through pragmatic self-consciousness. In: Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),
    pp 904–916'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2016) Kim S, D’Haro LF, Banchs RE, Williams JD, Henderson M, Yoshino
    K (2016) The fifth dialog state tracking challenge. In: 2016 IEEE Spoken Language
    Technology Workshop (SLT), IEEE, pp 511–517'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kim et al. (2017) Kim S, D’Haro LF, Banchs RE, Williams JD, Henderson M (2017)
    The fourth dialog state tracking challenge. In: Dialogues with Social Robots,
    Springer, pp 435–449'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2019) Kim S, Yang S, Kim G, Lee SW (2019) Efficient dialogue state
    tracking by selectively overwriting memory. arXiv preprint arXiv:191103906
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ko et al. (2020) Ko WJ, Ray A, Shen Y, Jin H (2020) Generating dialogue responses
    from a semantic latent space. arXiv preprint arXiv:201001658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Konda and Tsitsiklis (2000) Konda VR, Tsitsiklis JN (2000) Actor-critic algorithms.
    In: Advances in neural information processing systems, Citeseer, pp 1008–1014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Krizhevsky A, Sutskever I, Hinton GE (2012) Imagenet
    classification with deep convolutional neural networks. Advances in neural information
    processing systems 25:1097–1105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kummerfeld et al. (2018) Kummerfeld JK, Gouravajhala SR, Peper J, Athreya V,
    Gunasekara C, Ganhotra J, Patel SS, Polymenakos L, Lasecki WS (2018) A large-scale
    corpus for conversation disentanglement. arXiv preprint arXiv:181011118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kundu et al. (2020) Kundu S, Lin Q, Ng HT (2020) Learning to identify follow-up
    questions in conversational question answering. In: Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics, pp 959–968'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kurach et al. (2015) Kurach K, Andrychowicz M, Sutskever I (2015) Neural random-access
    machines. arXiv preprint arXiv:151106392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Larson et al. (2019) Larson S, Mahendran A, Peper JJ, Clarke C, Lee A, Hill
    P, Kummerfeld JK, Leach K, Laurenzano MA, Tang L, et al. (2019) An evaluation
    dataset for intent classification and out-of-scope prediction. arXiv preprint
    arXiv:190902027
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le and Hoi (2020) Le H, Hoi SC (2020) Video-grounded dialogues with pretrained
    generation language models. arXiv preprint arXiv:200615319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Le et al. (2019) Le H, Sahoo D, Chen NF, Hoi SC (2019) Multimodal transformer
    networks for end-to-end video-grounded dialogue systems. arXiv preprint arXiv:190701166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Le et al. (2020a) Le H, Sahoo D, Chen NF, Hoi SC (2020a) Bist: Bi-directional
    spatio-temporal reasoning for video-grounded dialogues. arXiv preprint arXiv:201010095'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Le et al. (2020b) Le H, Sahoo D, Liu C, Chen NF, Hoi SC (2020b) Uniconv: A
    unified conversational neural architecture for multi-domain task-oriented dialogues.
    arXiv preprint arXiv:200414307'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) LeCun Y, Bottou L, Bengio Y, Haffner P (1998) Gradient-based
    learning applied to document recognition. Proceedings of the IEEE 86(11):2278–2324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee and Dernoncourt (2016) Lee JY, Dernoncourt F (2016) Sequential short-text
    classification with recurrent and convolutional neural networks. arXiv preprint
    arXiv:160303827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee (2013) Lee S (2013) Structured discriminative model for dialog state tracking.
    In: Proceedings of the SIGDIAL 2013 Conference, pp 442–451'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee and Eskenazi (2013) Lee S, Eskenazi M (2013) Recipe for building robust
    spoken dialog state trackers: Dialog state tracking challenge system description.
    In: Proceedings of the SIGDIAL 2013 Conference, pp 414–422'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee and Jha (2019) Lee S, Jha R (2019) Zero-shot adaptive transfer for conversational
    language understanding. In: Proceedings of the AAAI Conference on Artificial Intelligence,
    vol 33, pp 6642–6649'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2019) Lee S, Schulz H, Atkinson A, Gao J, Suleman K, El Asri L,
    Adada M, Huang M, Sharma S, Tay W, et al. (2019) Multi-domain task-completion
    dialog challenge. Dialog system technology challenges 8:9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lei et al. (2018) Lei W, Jin X, Kan MY, Ren Z, He X, Yin D (2018) Sequicity:
    Simplifying task-oriented dialogue systems with single sequence-to-sequence architectures.
    In: Proceedings of the 56th Annual Meeting of the Association for Computational
    Linguistics (Volume 1: Long Papers), pp 1437–1447'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lemon and Pietquin (2007) Lemon O, Pietquin O (2007) Machine learning for spoken
    dialogue systems. In: Eighth Annual Conference of the International Speech Communication
    Association'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2020a) Li G, Duan N, Fang Y, Gong M, Jiang D (2020a) Unicoder-vl:
    A universal encoder for vision and language by cross-modal pre-training. In: Proceedings
    of the AAAI Conference on Artificial Intelligence, vol 34, pp 11336–11344'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2015) Li J, Galley M, Brockett C, Gao J, Dolan B (2015) A diversity-promoting
    objective function for neural conversation models. arXiv preprint arXiv:151003055
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2016a) Li J, Miller AH, Chopra S, Ranzato M, Weston J (2016a) Dialogue
    learning with human-in-the-loop. arXiv preprint arXiv:161109823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2016b) Li J, Miller AH, Chopra S, Ranzato M, Weston J (2016b) Learning
    through dialogue interactions by asking questions. arXiv preprint arXiv:161204936
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2016c) Li J, Monroe W, Jurafsky D (2016c) A simple, fast diverse
    decoding algorithm for neural generation. arXiv preprint arXiv:161108562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2016d) Li J, Monroe W, Ritter A, Galley M, Gao J, Jurafsky D (2016d)
    Deep reinforcement learning for dialogue generation. arXiv preprint arXiv:160601541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017a) Li J, Monroe W, Shi T, Jean S, Ritter A, Jurafsky D (2017a)
    Adversarial learning for neural dialogue generation. arXiv preprint arXiv:170106547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2020b) Li L, Xu C, Wu W, Zhao Y, Zhao X, Tao C (2020b) Zero-resource
    knowledge-grounded dialogue generation. arXiv preprint arXiv:200812918
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2019a) Li LH, Yatskar M, Yin D, Hsieh CJ, Chang KW (2019a) Visualbert:
    A simple and performant baseline for vision and language. arXiv preprint arXiv:190803557'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019b) Li M, Roller S, Kulikov I, Welleck S, Boureau YL, Cho K, Weston
    J (2019b) Don’t say that! making inconsistent dialogue unlikely with unlikelihood
    training. arXiv preprint arXiv:191103860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2016e) Li X, Lipton ZC, Dhingra B, Li L, Gao J, Chen YN (2016e) A
    user simulator for task-completion dialogues. arXiv preprint arXiv:161205688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2017b) Li X, Chen YN, Li L, Gao J, Celikyilmaz A (2017b) End-to-end
    task-completion neural dialogue systems. arXiv preprint arXiv:170301008
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2018) Li X, Wang Y, Sun S, Panda S, Liu J, Gao J (2018) Microsoft
    dialogue challenge: Building end-to-end task-completion dialogue systems. arXiv
    preprint arXiv:180711125'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019c) Li X, Yin F, Sun Z, Li X, Yuan A, Chai D, Zhou M, Li J (2019c)
    Entity-relation extraction as multi-turn question answering. arXiv preprint arXiv:190505529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2020c) Li X, Yin X, Li C, Zhang P, Hu X, Zhang L, Wang L, Hu H,
    Dong L, Wei F, et al. (2020c) Oscar: Object-semantics aligned pre-training for
    vision-language tasks. In: European Conference on Computer Vision, Springer, pp
    121–137'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li (2017) Li Y (2017) Deep reinforcement learning: An overview. arXiv preprint
    arXiv:170107274'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2017c) Li Y, Su H, Shen X, Li W, Cao Z, Niu S (2017c) Dailydialog:
    A manually labelled multi-turn dialogue dataset. arXiv preprint arXiv:171003957'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2020d) Li Y, Yao K, Qin L, Che W, Li X, Liu T (2020d) Slot-consistent
    nlg for task-oriented dialogue systems with iterative rectification network. In:
    Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,
    pp 97–106'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019d) Li Z, Niu C, Meng F, Feng Y, Li Q, Zhou J (2019d) Incremental
    transformer with deliberation decoder for document grounded conversations. arXiv
    preprint arXiv:190708854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liang et al. (2020) Liang W, Zou J, Yu Z (2020) Beyond user self-reported likert
    scale ratings: A comparison model for automatic dialog evaluation. arXiv preprint
    arXiv:200510716'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin (2004) Lin CY (2004) Rouge: A package for automatic evaluation of summaries.
    In: Text summarization branches out, pp 74–81'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin (1992) Lin LJ (1992) Self-improving reactive agents based on reinforcement
    learning, planning and teaching. Machine learning 8(3-4):293–321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2021) Lin T, Wang Y, Liu X, Qiu X (2021) A survey of transformers.
    arXiv preprint arXiv:210604554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2019) Lin X, Joty S, Jwalapuram P, Bari MS (2019) A unified linear-time
    framework for sentence-level discourse parsing. arXiv preprint arXiv:190505682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020a) Lin X, Jian W, He J, Wang T, Chu W (2020a) Generating informative
    conversational response using recurrent knowledge-interaction and knowledge-copy.
    In: Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics, pp 41–52'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2015) Lin Y, Liu Z, Sun M, Liu Y, Zhu X (2015) Learning entity
    and relation embeddings for knowledge graph completion. In: Proceedings of the
    AAAI Conference on Artificial Intelligence, vol 29'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020b) Lin Z, Cai D, Wang Y, Liu X, Zheng H, Shi S (2020b) The
    world is not binary: Learning to rank with grayscale data for dialogue response
    selection. In: Proceedings of the 2020 Conference on Empirical Methods in Natural
    Language Processing (EMNLP), pp 9220–9229'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lin et al. (2020c) Lin Z, Madotto A, Winata GI, Fung P (2020c) Mintl: Minimalist
    transfer learning for task-oriented dialogue systems. arXiv preprint arXiv:200912005'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lipton et al. (2015) Lipton ZC, Berkowitz J, Elkan C (2015) A critical review
    of recurrent neural networks for sequence learning. arXiv preprint arXiv:150600019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lison and Bibauw (2017) Lison P, Bibauw S (2017) Not all dialogues are created
    equal: Instance weighting for neural conversational models. arXiv preprint arXiv:170408966'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Lane (2016) Liu B, Lane I (2016) Attention-based recurrent neural network
    models for joint intent detection and slot filling. arXiv preprint arXiv:160901454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu and Lane (2017) Liu B, Lane I (2017) Iterative policy learning in end-to-end
    trainable task-oriented neural dialog models. In: 2017 IEEE Automatic Speech Recognition
    and Understanding Workshop (ASRU), IEEE, pp 482–489'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019) Liu C, He S, Liu K, Zhao J (2019) Vocabulary pyramid network:
    Multi-pass encoding and decoding with multi-level vocabularies for response generation.
    In: Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics, pp 3774–3783'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2016) Liu CW, Lowe R, Serban IV, Noseworthy M, Charlin L, Pineau
    J (2016) How not to evaluate your dialogue system: An empirical study of unsupervised
    evaluation metrics for dialogue response generation. arXiv preprint arXiv:160308023'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020a) Liu H, Wang W, Wang Y, Liu H, Liu Z, Tang J (2020a) Mitigating
    gender bias for neural dialogue generation with adversarial learning. arXiv preprint
    arXiv:200913028
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2020b) Liu Q, Chen Y, Chen B, Lou JG, Chen Z, Zhou B, Zhang D (2020b)
    You impress me: Dialogue generation via mutual persona perception. arXiv preprint
    arXiv:200405388'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Lapata (2018) Liu Y, Lapata M (2018) Learning structured text representations.
    Transactions of the Association for Computational Linguistics 6:63–75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020c) Liu Z, Wang H, Niu ZY, Wu H, Che W, Liu T (2020c) Towards
    conversational recommendation over multi-type dialogs. arXiv preprint arXiv:200503954
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lowe et al. (2015) Lowe R, Pow N, Serban I, Pineau J (2015) The ubuntu dialogue
    corpus: A large dataset for research in unstructured multi-turn dialogue systems.
    arXiv preprint arXiv:150608909'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lowe et al. (2017) Lowe R, Noseworthy M, Serban IV, Angelard-Gontier N, Bengio
    Y, Pineau J (2017) Towards an automatic turing test: Learning to evaluate dialogue
    responses. arXiv preprint arXiv:170807149'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2019a) Lu J, Batra D, Parikh D, Lee S (2019a) Vilbert: Pretraining
    task-agnostic visiolinguistic representations for vision-and-language tasks. arXiv
    preprint arXiv:190802265'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2019b) Lu J, Zhang C, Xie Z, Ling G, Zhou TC, Xu Z (2019b) Constructing
    interpretive spatio-temporal features for multi-turn responses selection. In:
    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,
    pp 44–50'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lu et al. (2020) Lu J, Goswami V, Rohrbach M, Parikh D, Lee S (2020) 12-in-1:
    Multi-task vision and language representation learning. In: Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp 10437–10446'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lubis et al. (2018) Lubis N, Sakti S, Yoshino K, Nakamura S (2018) Eliciting
    positive emotion through affect-sensitive dialogue response generation: A neural
    network approach. In: Proceedings of the AAAI Conference on Artificial Intelligence,
    vol 32, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2019) Ma MD, Bowden KK, Wu J, Cui W, Walker M (2019) Implicit discourse
    relation identification for open-domain dialogues. arXiv preprint arXiv:190703975
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2020a) Ma W, Cui Y, Liu T, Wang D, Wang S, Hu G (2020a) Conversational
    word embedding for retrieval-based dialog system. arXiv preprint arXiv:200413249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2020b) Ma Y, Nguyen KL, Xing FZ, Cambria E (2020b) A survey on empathetic
    dialogue systems. Information Fusion 64:50–70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madotto et al. (2019) Madotto A, Lin Z, Wu CS, Fung P (2019) Personalizing
    dialogue agents via meta-learning. In: Proceedings of the 57th Annual Meeting
    of the Association for Computational Linguistics, pp 5454–5459'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Majumder et al. (2020a) Majumder BP, Jhamtani H, Berg-Kirkpatrick T, McAuley
    J (2020a) Like hiking? you probably enjoy nature: Persona-grounded dialog with
    commonsense expansions. arXiv preprint arXiv:201003205'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Majumder et al. (2020b) Majumder BP, Li S, Ni J, McAuley J (2020b) Interview:
    Large-scale modeling of media dialog with discourse patterns and knowledge grounding.
    In: Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing (EMNLP), pp 8129–8141'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mallios and Bourbakis (2016) Mallios S, Bourbakis N (2016) A survey on human
    machine dialogue systems. In: 2016 7th international conference on information,
    intelligence, systems & applications (iisa), IEEE, pp 1–7'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Manuvina-kurike et al. (2018) Manuvina-kurike R, Brixey J, Bui T, Chang W,
    Artstein R, Georgila K (2018) Dialedit: Annotations for spoken conversational
    image editing. In: Proceedings 14th Joint ACL-ISO Workshop on Interoperable Semantic
    Annotation, pp 1–9'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mao et al. (2020) Mao HH, Li S, McAuley J, Cottrell G (2020) Speech recognition
    and multi-speaker diarization of long conversations. arXiv preprint arXiv:200508072
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mehri and Eskenazi (2020) Mehri S, Eskenazi M (2020) Usr: An unsupervised and
    reference free evaluation metric for dialog generation. arXiv preprint arXiv:200500456'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mehri et al. (2019) Mehri S, Razumovskaia E, Zhao T, Eskenazi M (2019) Pretraining
    methods for dialog context representation learning. arXiv preprint arXiv:190600414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mesgar et al. (2019) Mesgar M, Bücker S, Gurevych I (2019) Dialogue coherence
    assessment without explicit dialogue act labels. arXiv preprint arXiv:190808486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mesnil et al. (2013) Mesnil G, He X, Deng L, Bengio Y (2013) Investigation
    of recurrent-neural-network architectures and learning methods for spoken language
    understanding. In: Interspeech, pp 3771–3775'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mesnil et al. (2014) Mesnil G, Dauphin Y, Yao K, Bengio Y, Deng L, Hakkani-Tur
    D, He X, Heck L, Tur G, Yu D, et al. (2014) Using recurrent neural networks for
    slot filling in spoken language understanding. IEEE/ACM Transactions on Audio,
    Speech, and Language Processing 23(3):530–539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miao et al. (2019) Miao N, Zhou H, Mou L, Yan R, Li L (2019) Cgmh: Constrained
    sentence generation by metropolis-hastings sampling. In: Proceedings of the AAAI
    Conference on Artificial Intelligence, vol 33, pp 6834–6842'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miech et al. (2020) Miech A, Alayrac JB, Smaira L, Laptev I, Sivic J, Zisserman
    A (2020) End-to-end learning of visual representations from uncurated instructional
    videos. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp 9879–9889'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miller et al. (2016) Miller A, Fisch A, Dodge J, Karimi AH, Bordes A, Weston
    J (2016) Key-value memory networks for directly reading documents. arXiv preprint
    arXiv:160603126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mirowski et al. (2016) Mirowski P, Pascanu R, Viola F, Soyer H, Ballard AJ,
    Banino A, Denil M, Goroshin R, Sifre L, Kavukcuoglu K, et al. (2016) Learning
    to navigate in complex environments. arXiv preprint arXiv:161103673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mnih et al. (2015) Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare
    MG, Graves A, Riedmiller M, Fidjeland AK, Ostrovski G, et al. (2015) Human-level
    control through deep reinforcement learning. nature 518(7540):529–533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mnih et al. (2016) Mnih V, Badia AP, Mirza M, Graves A, Lillicrap T, Harley
    T, Silver D, Kavukcuoglu K (2016) Asynchronous methods for deep reinforcement
    learning. In: International conference on machine learning, PMLR, pp 1928–1937'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mo et al. (2018) Mo K, Zhang Y, Li S, Li J, Yang Q (2018) Personalizing a dialogue
    system with transfer reinforcement learning. In: Proceedings of the AAAI Conference
    on Artificial Intelligence, vol 32, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Moghe et al. (2018) Moghe N, Arora S, Banerjee S, Khapra MM (2018) Towards exploiting
    background knowledge for building conversation systems. arXiv preprint arXiv:180908205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mohammad et al. (2018) Mohammad S, Bravo-Marquez F, Salameh M, Kiritchenko
    S (2018) Semeval-2018 task 1: Affect in tweets. In: Proceedings of the 12th international
    workshop on semantic evaluation, pp 1–17'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moon et al. (2019) Moon S, Shah P, Kumar A, Subba R (2019) Opendialkg: Explainable
    conversational reasoning with attention-based walks over knowledge graphs. In:
    Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics,
    pp 845–854'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mostafazadeh et al. (2017) Mostafazadeh N, Brockett C, Dolan B, Galley M, Gao
    J, Spithourakis GP, Vanderwende L (2017) Image-grounded conversations: Multimodal
    context for natural question and response generation. arXiv preprint arXiv:170108251'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mrkšić et al. (2015) Mrkšić N, Séaghdha DO, Thomson B, Gašić M, Su PH, Vandyke
    D, Wen TH, Young S (2015) Multi-domain dialog state tracking using recurrent neural
    networks. arXiv preprint arXiv:150607190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mrkšić et al. (2016) Mrkšić N, Séaghdha DO, Wen TH, Thomson B, Young S (2016)
    Neural belief tracker: Data-driven dialogue state tracking. arXiv preprint arXiv:160603777'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nakov et al. (2019) Nakov P, Màrquez L, Magdy W, Moschitti A, Glass J, Randeree
    B (2019) Semeval-2015 task 3: Answer selection in community question answering.
    arXiv preprint arXiv:191111403'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nickel et al. (2016) Nickel M, Rosasco L, Poggio T (2016) Holographic embeddings
    of knowledge graphs. In: Proceedings of the AAAI Conference on Artificial Intelligence,
    vol 30, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Novikova et al. (2017) Novikova J, Dušek O, Rieser V (2017) The e2e dataset:
    New challenges for end-to-end generation. arXiv preprint arXiv:170609254'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Oraby et al. (2019) Oraby S, Harrison V, Ebrahimi A, Walker M (2019) Curate
    and generate: A corpus and method for joint control of semantics and style in
    neural nlg. arXiv preprint arXiv:190601334'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oriol et al. (2015) Oriol V, Meire F, Navdeep J (2015) Pointer networks. Advances
    in neural information processing systems 28:2692–2700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ouyang et al. (2020) Ouyang Y, Chen M, Dai X, Zhao Y, Huang S, Jiajun C (2020)
    Dialogue state tracking with explicit slot connection modeling. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    34–40'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Panayotov et al. (2015) Panayotov V, Chen G, Povey D, Khudanpur S (2015) Librispeech:
    an asr corpus based on public domain audio books. In: 2015 IEEE international
    conference on acoustics, speech and signal processing (ICASSP), IEEE, pp 5206–5210'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pang et al. (2020) Pang B, Nijkamp E, Han W, Zhou L, Liu Y, Tu K (2020) Towards
    holistic and automatic evaluation of open-domain dialogue generation. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    3619–3629'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Papineni et al. (2002) Papineni K, Roukos S, Ward T, Zhu WJ (2002) Bleu: a
    method for automatic evaluation of machine translation. In: Proceedings of the
    40th annual meeting of the Association for Computational Linguistics, pp 311–318'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parikh et al. (2016) Parikh AP, Täckström O, Das D, Uszkoreit J (2016) A decomposable
    attention model for natural language inference. arXiv preprint arXiv:160601933
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pascanu et al. (2013) Pascanu R, Mikolov T, Bengio Y (2013) On the difficulty
    of training recurrent neural networks. In: International conference on machine
    learning, PMLR, pp 1310–1318'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peng et al. (2017) Peng B, Li X, Li L, Gao J, Celikyilmaz A, Lee S, Wong KF
    (2017) Composite task-completion dialogue policy learning via hierarchical deep
    reinforcement learning. arXiv preprint arXiv:170403084
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peters et al. (2018) Peters ME, Neumann M, Iyyer M, Gardner M, Clark C, Lee
    K, Zettlemoyer L (2018) Deep contextualized word representations. arXiv preprint
    arXiv:180205365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pfau and Vinyals (2016) Pfau D, Vinyals O (2016) Connecting generative adversarial
    networks and actor-critic methods. arXiv preprint arXiv:161001945
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Poria et al. (2019) Poria S, Hazarika D, Majumder N, Naik G, Cambria E, Mihalcea
    R (2019) MELD: A multimodal multi-party dataset for emotion recognition in conversations.
    In: ACL, pp 527–536'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Powers (2020) Powers DMW (2020) Evaluation: from precision, recall and f-measure
    to roc, informedness, markedness and correlation. ArXiv abs/2010.16061'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Prasad et al. (2008) Prasad R, Dinesh N, Lee A, Miltsakaki E, Robaldo L, Joshi
    AK, Webber BL (2008) The penn discourse treebank 2.0\. In: LREC, Citeseer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Puterman (2014) Puterman ML (2014) Markov decision processes: discrete stochastic
    dynamic programming. John Wiley & Sons'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qi et al. (2020) Qi D, Su L, Song J, Cui E, Bharti T, Sacheti A (2020) Imagebert:
    Cross-modal pre-training with large-scale weak-supervised image-text data. arXiv
    preprint arXiv:200107966'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qian and Yu (2019) Qian K, Yu Z (2019) Domain adaptive dialog generation via
    meta learning. arXiv preprint arXiv:190603520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2020) Qin L, Xu X, Che W, Zhang Y, Liu T (2020) Dynamic fusion network
    for multi-domain end-to-end task-oriented dialog. arXiv preprint arXiv:200411019
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2019) Qiu L, Li J, Bi W, Zhao D, Yan R (2019) Are training samples
    correlated? learning to generate dialogue responses with multiple references.
    In: Proceedings of the 57th Annual Meeting of the Association for Computational
    Linguistics, pp 3826–3835'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiu et al. (2020) Qiu L, Zhao Y, Shi W, Liang Y, Shi F, Yuan T, Yu Z, Zhu SC
    (2020) Structured attention for unsupervised dialogue structure induction. arXiv
    preprint arXiv:200908552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qiu et al. (2017) Qiu M, Li FL, Wang S, Gao X, Chen Y, Zhao W, Chen H, Huang
    J, Chu W (2017) Alime chat: A sequence to sequence and rerank based chatbot engine.
    In: Proceedings of the 55th Annual Meeting of the Association for Computational
    Linguistics (Volume 2: Short Papers), pp 498–503'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quan and Xiong (2020) Quan J, Xiong D (2020) Modeling long context for task-oriented
    dialogue state generation. arXiv preprint arXiv:200414080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quan et al. (2020) Quan J, Zhang S, Cao Q, Li Z, Xiong D (2020) Risawoz: A
    large-scale multi-domain wizard-of-oz dataset with rich semantic annotations for
    task-oriented dialogue modeling. arXiv preprint arXiv:201008738'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rajpurkar et al. (2018) Rajpurkar P, Jia R, Liang P (2018) Know what you don’t
    know: Unanswerable questions for squad. arXiv preprint arXiv:180603822'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ram et al. (2018) Ram A, Prasad R, Khatri C, Venkatesh A, Gabriel R, Liu Q,
    Nunn J, Hedayatnia B, Cheng M, Nagar A, et al. (2018) Conversational ai: The science
    behind the alexa prize. arXiv preprint arXiv:180103604'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rameshkumar and Bailey (2020) Rameshkumar R, Bailey P (2020) Storytelling with
    dialogue: A critical role dungeons and dragons dataset. In: Proceedings of the
    58th Annual Meeting of the Association for Computational Linguistics, pp 5121–5134'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ramshaw and Marcus (1999) Ramshaw LA, Marcus MP (1999) Text chunking using
    transformation-based learning. In: Natural language processing using very large
    corpora, Springer, pp 157–176'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rashkin et al. (2018) Rashkin H, Smith EM, Li M, Boureau YL (2018) Towards
    empathetic open-domain conversation models: A new benchmark and dataset. arXiv
    preprint arXiv:181100207'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rastogi et al. (2020) Rastogi A, Zang X, Sunkara S, Gupta R, Khaitan P (2020)
    Towards scalable multi-domain conversational agents: The schema-guided dialogue
    dataset. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol
    34, no 5, pp 8689–8696'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ravuri and Stolcke (2015) Ravuri S, Stolcke A (2015) Recurrent neural network
    and lstm models for lexical utterance classification. In: Sixteenth Annual Conference
    of the International Speech Communication Association'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ravuri and Stolcke (2016) Ravuri S, Stolcke A (2016) A comparative study of
    recurrent neural network models for lexical domain classification. In: 2016 IEEE
    International Conference on Acoustics, Speech and Signal Processing (ICASSP),
    IEEE, pp 6075–6079'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rawat and Wang (2017) Rawat W, Wang Z (2017) Deep convolutional neural networks
    for image classification: A comprehensive review. Neural computation 29(9):2352–2449'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reiter (1994) Reiter E (1994) Has a consensus nl generation architecture appeared,
    and is it psycholinguistically plausible? arXiv preprint cmp-lg/9411032
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2013) Ren H, Xu W, Zhang Y, Yan Y (2013) Dialog state tracking
    using conditional random fields. In: Proceedings of the SIGDIAL 2013 Conference,
    pp 457–461'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ren et al. (2018) Ren L, Xie K, Chen L, Yu K (2018) Towards universal dialogue
    state tracking. arXiv preprint arXiv:181009587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ren et al. (2020) Ren P, Chen Z, Ren Z, Kanoulas E, Monz C, de Rijke M (2020)
    Conversations with search engines. arXiv preprint arXiv:200414162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ritter et al. (2011) Ritter A, Cherry C, Dolan WB (2011) Data-driven response
    generation in social media. In: Proceedings of the 2011 Conference on Empirical
    Methods in Natural Language Processing, pp 583–593'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rodriguez et al. (2020) Rodriguez P, Crook P, Moon S, Wang Z (2020) Information
    seeking in the spirit of learning: a dataset for conversational curiosity. arXiv
    preprint arXiv:200500172'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saha et al. (2018) Saha A, Khapra M, Sankaranarayanan K (2018) Towards building
    large scale multimodal domain-aware conversation systems. In: Proceedings of the
    AAAI Conference on Artificial Intelligence, vol 32, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saha et al. (2020) Saha T, Patra A, Saha S, Bhattacharyya P (2020) Towards
    emotion-aided multi-modal dialogue act classification. In: Proceedings of the
    58th Annual Meeting of the Association for Computational Linguistics, pp 4361–4372'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sankar et al. (2019) Sankar C, Subramanian S, Pal C, Chandar S, Bengio Y (2019)
    Do neural dialog systems use the conversation history effectively? an empirical
    study. arXiv preprint arXiv:190601603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santhanam and Shaikh (2019) Santhanam S, Shaikh S (2019) A survey of natural
    language generation techniques with a focus on dialogue systems-past, present
    and future directions. arXiv preprint arXiv:190600500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sarikaya et al. (2011) Sarikaya R, Hinton GE, Ramabhadran B (2011) Deep belief
    nets for natural language call-routing. In: 2011 IEEE International conference
    on acoustics, speech and signal processing (ICASSP), IEEE, pp 5680–5683'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarikaya et al. (2014) Sarikaya R, Hinton GE, Deoras A (2014) Application of
    deep belief networks for natural language understanding. IEEE/ACM Transactions
    on Audio, Speech, and Language Processing 22(4):778–784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sato et al. (2020) Sato S, Akama R, Ouchi H, Suzuki J, Inui K (2020) Evaluating
    dialogue generation systems via response selection. arXiv preprint arXiv:200414302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schatzmann and Young (2009) Schatzmann J, Young S (2009) The hidden agenda user
    simulation model. IEEE transactions on audio, speech, and language processing
    17(4):733–747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schuster and Paliwal (1997) Schuster M, Paliwal KK (1997) Bidirectional recurrent
    neural networks. IEEE transactions on Signal Processing 45(11):2673–2681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: See et al. (2019) See A, Roller S, Kiela D, Weston J (2019) What makes a good
    conversation? how controllable attributes affect human judgments. arXiv preprint
    arXiv:190208654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Serban et al. (2016) Serban I, Sordoni A, Bengio Y, Courville A, Pineau J (2016)
    Building end-to-end dialogue systems using generative hierarchical neural network
    models. In: Proceedings of the AAAI Conference on Artificial Intelligence, vol
    30, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Serban et al. (2017a) Serban I, Sordoni A, Lowe R, Charlin L, Pineau J, Courville
    A, Bengio Y (2017a) A hierarchical latent variable encoder-decoder model for generating
    dialogues. In: Proceedings of the AAAI Conference on Artificial Intelligence,
    vol 31, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Serban et al. (2017b) Serban IV, Sankar C, Germain M, Zhang S, Lin Z, Subramanian
    S, Kim T, Pieper M, Chandar S, Ke NR, et al. (2017b) A deep reinforcement learning
    chatbot. arXiv preprint arXiv:170902349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Serras et al. (2019) Serras M, Torres MI, del Pozo A (2019) Goal-conditioned
    user modeling for dialogue systems using stochastic bi-automata. In: ICPRAM, pp
    128–134'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shah et al. (2018) Shah P, Hakkani-Tür D, Tür G, Rastogi A, Bapna A, Nayak N,
    Heck L (2018) Building a conversational agent overnight with dialogue self-play.
    arXiv preprint arXiv:180104871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shan et al. (2020) Shan Y, Li Z, Zhang J, Meng F, Feng Y, Niu C, Zhou J (2020)
    A contextual hierarchical attention network with adaptive objective for dialogue
    state tracking. arXiv preprint arXiv:200601554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shang et al. (2015) Shang L, Lu Z, Li H (2015) Neural responding machine for
    short-text conversation. arXiv preprint arXiv:150302364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shao et al. (2017) Shao L, Gouws S, Britz D, Goldie A, Strope B, Kurzweil R
    (2017) Generating long and diverse responses with neural conversation models.
    ArXiv abs/1701.03185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shao and Nakashole (2020) Shao Y, Nakashole N (2020) Chartdialogs: Plotting
    from natural language instructions. In: Proceedings of the 58th Annual Meeting
    of the Association for Computational Linguistics, pp 3559–3574'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shen et al. (2019) Shen L, Feng Y, Zhan H (2019) Modeling semantic relationship
    in multi-turn conversations with hierarchical latent variables. arXiv preprint
    arXiv:190607429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi and Weninger (2017) Shi B, Weninger T (2017) Proje: Embedding projection
    for knowledge graph completion. In: Proceedings of the AAAI Conference on Artificial
    Intelligence, vol 31, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuster et al. (2018) Shuster K, Humeau S, Bordes A, Weston J (2018) Image
    chat: Engaging grounded conversations. arXiv preprint arXiv:181100945'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuster et al. (2019) Shuster K, Ju D, Roller S, Dinan E, Boureau YL, Weston
    J (2019) The dialogue dodecathlon: Open-domain knowledge and image grounded conversational
    agents. arXiv preprint arXiv:191103768'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shuster et al. (2020) Shuster K, Humeau S, Bordes A, Weston J (2020) Image-chat:
    Engaging grounded conversations. In: Proceedings of the 58th Annual Meeting of
    the Association for Computational Linguistics, Association for Computational Linguistics,
    Online, pp 2414–2429, DOI 10.18653/v1/2020.acl-main.219, URL [https://www.aclweb.org/anthology/2020.acl-main.219](https://www.aclweb.org/anthology/2020.acl-main.219)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Siddharthan (2001) Siddharthan A (2001) Ehud reiter and robert dale. building
    natural language generation systems. Natural Language Engineering 7(3):271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Silver et al. (2016) Silver D, Huang A, Maddison CJ, Guez A, Sifre L, Van Den Driessche
    G, Schrittwieser J, Antonoglou I, Panneershelvam V, Lanctot M, et al. (2016) Mastering
    the game of go with deep neural networks and tree search. nature 529(7587):484–489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) Simonyan K, Zisserman A (2014) Very deep convolutional
    networks for large-scale image recognition. arXiv preprint arXiv:14091556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2020) Singh A, Goswami V, Parikh D (2020) Are we pretraining it
    right? digging deeper into visio-linguistic pretraining. arXiv preprint arXiv:200408744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singh et al. (2002) Singh S, Litman D, Kearns M, Walker M (2002) Optimizing
    dialogue management with reinforcement learning: Experiments with the njfun system.
    Journal of Artificial Intelligence Research 16:105–133'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singla et al. (2020) Singla K, Chen Z, Atkins D, Narayanan S (2020) Towards
    end-2-end learning for predicting behavior codes from spoken utterances in psychotherapy
    conversations. In: Proceedings of the 58th Annual Meeting of the Association for
    Computational Linguistics, pp 3797–3803'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sinha et al. (2020) Sinha K, Parthasarathi P, Wang J, Lowe R, Hamilton WL, Pineau
    J (2020) Learning an unreferenced metric for online dialogue evaluation. arXiv
    preprint arXiv:200500583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Smith et al. (2020) Smith EM, Williamson M, Shuster K, Weston J, Boureau YL
    (2020) Can you put it all together: Evaluating conversational agents’ ability
    to blend skills. arXiv preprint arXiv:200408449'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Socher et al. (2013) Socher R, Chen D, Manning CD, Ng A (2013) Reasoning with
    neural tensor networks for knowledge base completion. In: Advances in neural information
    processing systems, Citeseer, pp 926–934'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2020a) Song H, Wang Y, Zhang WN, Liu X, Liu T (2020a) Generate,
    delete and rewrite: A three-stage framework for improving persona consistency
    of dialogue generation. arXiv preprint arXiv:200407672'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2020b) Song H, Wang Y, Zhang WN, Zhao Z, Liu T, Liu X (2020b) Profile
    consistency identification for open-domain dialogue agents. arXiv preprint arXiv:200909680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2016) Song Y, Yan R, Li X, Zhao D, Zhang M (2016) Two are better
    than one: An ensemble of retrieval-and generation-based dialog systems. arXiv
    preprint arXiv:161007149'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Song et al. (2019) Song Z, Zheng X, Liu L, Xu M, Huang XJ (2019) Generating
    responses with a specific emotion in dialog. In: Proceedings of the 57th Annual
    Meeting of the Association for Computational Linguistics, pp 3685–3695'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sordoni et al. (2015a) Sordoni A, Bengio Y, Vahabi H, Lioma C, Grue Simonsen
    J, Nie JY (2015a) A hierarchical recurrent encoder-decoder for generative context-aware
    query suggestion. In: Proceedings of the 24th ACM International on Conference
    on Information and Knowledge Management, pp 553–562'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sordoni et al. (2015b) Sordoni A, Galley M, Auli M, Brockett C, Ji Y, Mitchell
    M, Nie JY, Gao J, Dolan B (2015b) A neural network approach to context-sensitive
    generation of conversational responses. arXiv preprint arXiv:150606714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stasaski et al. (2020) Stasaski K, Yang GH, Hearst MA (2020) More diverse dialogue
    datasets via diversity-informed data collection. In: Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics, pp 4958–4968'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Stent et al. (2005) Stent A, Marge M, Singhai M (2005) Evaluating evaluation
    methods for generation in the presence of variation. In: international conference
    on intelligent text processing and computational linguistics, Springer, pp 341–351'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2019a) Su H, Shen X, Zhang R, Sun F, Hu P, Niu C, Zhou J (2019a)
    Improving multi-turn dialogue modelling with utterance rewriter. arXiv preprint
    arXiv:190607004
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2020) Su H, Shen X, Zhao S, Zhou X, Hu P, Zhong R, Niu C, Zhou J
    (2020) Diversifying dialogue generation with non-conversational text. arXiv preprint
    arXiv:200504346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Su et al. (2015) Su PH, Vandyke D, Gasic M, Kim D, Mrksic N, Wen TH, Young
    S (2015) Learning from real users: Rating dialogue success with neural networks
    for reinforcement learning in spoken dialogue systems. arXiv preprint arXiv:150803386'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2016) Su PH, Gasic M, Mrksic N, Rojas-Barahona L, Ultes S, Vandyke
    D, Wen TH, Young S (2016) Continuously learning neural dialogue management. arXiv
    preprint arXiv:160602689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2019b) Su SY, Huang CW, Chen YN (2019b) Dual supervised learning
    for natural language understanding and generation. arXiv preprint arXiv:190506196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Su et al. (2019c) Su W, Zhu X, Cao Y, Li B, Lu L, Wei F, Dai J (2019c) Vl-bert:
    Pre-training of generic visual-linguistic representations. arXiv preprint arXiv:190808530'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sukhbaatar et al. (2015) Sukhbaatar S, Szlam A, Weston J, Fergus R (2015) End-to-end
    memory networks. arXiv preprint arXiv:150308895
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2019a) Sun C, Baradel F, Murphy K, Schmid C (2019a) Learning video
    representations using contrastive bidirectional transformer. arXiv preprint arXiv:190605743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sun et al. (2019b) Sun C, Myers A, Vondrick C, Murphy K, Schmid C (2019b) Videobert:
    A joint model for video and language representation learning. In: Proceedings
    of the IEEE/CVF International Conference on Computer Vision, pp 7464–7473'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sutskever et al. (2014) Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence
    learning with neural networks. arXiv preprint arXiv:14093215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sutton (1988) Sutton RS (1988) Learning to predict by the methods of temporal
    differences. Machine learning 3(1):9–44
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sutton et al. (1999) Sutton RS, McAllester DA, Singh SP, Mansour Y, et al.
    (1999) Policy gradient methods for reinforcement learning with function approximation.
    In: NIPs, Citeseer, vol 99, pp 1057–1063'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. (2015) Szegedy C, Liu W, Jia Y, Sermanet P, Reed S, Anguelov
    D, Erhan D, Vanhoucke V, Rabinovich A (2015) Going deeper with convolutions. In:
    Proceedings of the IEEE conference on computer vision and pattern recognition,
    pp 1–9'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Takanobu et al. (2020) Takanobu R, Liang R, Huang M (2020) Multi-agent task-oriented
    dialog policy learning with role-aware reward decomposition. arXiv preprint arXiv:200403809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Takmaz et al. (2020) Takmaz E, Giulianelli M, Pezzelle S, Sinclair A, Fernández
    R (2020) Refer, reuse, reduce: Generating subsequent references in visual and
    conversational contexts. arXiv preprint arXiv:201104554'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tamar et al. (2016) Tamar A, Wu Y, Thomas G, Levine S, Abbeel P (2016) Value
    iteration networks. arXiv preprint arXiv:160202867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tan and Bansal (2019) Tan H, Bansal M (2019) Lxmert: Learning cross-modality
    encoder representations from transformers. arXiv preprint arXiv:190807490'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tanana et al. (2016) Tanana M, Hallgren KA, Imel ZE, Atkins DC, Srikumar V (2016)
    A comparison of natural language processing methods for automated coding of motivational
    interviewing. Journal of substance abuse treatment 65:43–50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tang et al. (2015) Tang D, Qin B, Liu T (2015) Learning semantic representations
    of users and products for document level sentiment classification. In: Proceedings
    of the 53rd Annual Meeting of the Association for Computational Linguistics and
    the 7th International Joint Conference on Natural Language Processing (Volume
    1: Long Papers), pp 1014–1023'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2019) Tang J, Zhao T, Xiong C, Liang X, Xing EP, Hu Z (2019) Target-guided
    open-domain conversation. arXiv preprint arXiv:190511553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tao et al. (2018) Tao C, Mou L, Zhao D, Yan R (2018) Ruber: An unsupervised
    method for automatic evaluation of open-domain dialog systems. In: Proceedings
    of the AAAI Conference on Artificial Intelligence, vol 32, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tao et al. (2019) Tao C, Wu W, Xu C, Hu W, Zhao D, Yan R (2019) One time of
    interaction may not be enough: Go deep with an interaction-over-interaction network
    for response selection in dialogues. In: Proceedings of the 57th annual meeting
    of the association for computational linguistics, pp 1–11'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tay et al. (2019) Tay Y, Wang S, Tuan LA, Fu J, Phan MC, Yuan X, Rao J, Hui
    SC, Zhang A (2019) Simple and effective curriculum pointer-generator networks
    for reading comprehension over long narratives. arXiv preprint arXiv:190510847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tay et al. (2020) Tay Y, Dehghani M, Bahri D, Metzler D (2020) Efficient transformers:
    A survey. arXiv preprint arXiv:200906732'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Theune (2003) Theune M (2003) Natural language generation for dialogue: system
    survey. Centre for Telematics and Information Technology, University of Twente'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Thomas et al. (2006) Thomas M, Pang B, Lee L (2006) Get out the vote: Determining
    support or opposition from congressional floor-debate transcripts. arXiv preprint
    cs/0607062'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tian et al. (2019) Tian Z, Bi W, Li X, Zhang NL (2019) Learning to abstract
    for memory-augmented conversational response generation. In: Proceedings of the
    57th Annual Meeting of the Association for Computational Linguistics, pp 3816–3825'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tiedemann (2012) Tiedemann J (2012) Parallel data, tools and interfaces in
    opus. In: Lrec, vol 2012, pp 2214–2218'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tonelli et al. (2010) Tonelli S, Riccardi G, Prasad R, Joshi AK (2010) Annotation
    of discourse relations for conversational spoken dialogs. In: LREC'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tran and Nguyen (2017) Tran VK, Nguyen LM (2017) Semantic refinement gru-based
    neural language generation for spoken dialogue systems. In: International Conference
    of the Pacific Association for Computational Linguistics, Springer, pp 63–75'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tur et al. (2010) Tur G, Hakkani-Tür D, Heck L (2010) What is left to be understood
    in atis? In: 2010 IEEE Spoken Language Technology Workshop, IEEE, pp 19–24'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tur et al. (2012) Tur G, Deng L, Hakkani-Tür D, He X (2012) Towards deeper
    understanding: Deep convex networks for semantic utterance classification. In:
    2012 IEEE international conference on acoustics, speech and signal processing
    (ICASSP), IEEE, pp 5045–5048'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ultes et al. (2017) Ultes S, Barahona LMR, Su PH, Vandyke D, Kim D, Casanueva
    I, Budzianowski P, Mrkšić N, Wen TH, Gasic M, et al. (2017) Pydial: A multi-domain
    statistical dialogue system toolkit. In: Proceedings of ACL 2017, System Demonstrations,
    pp 73–78'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Urbanek et al. (2019) Urbanek J, Fan A, Karamcheti S, Jain S, Humeau S, Dinan
    E, Rocktäschel T, Kiela D, Szlam A, Weston J (2019) Learning to speak and act
    in a fantasy text adventure game. arXiv preprint arXiv:190303094
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vaswani et al. (2017) Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L,
    Gomez AN, Kaiser Lu, Polosukhin I (2017) Attention is all you need. In: Guyon
    I, Luxburg UV, Bengio S, Wallach H, Fergus R, Vishwanathan S, Garnett R (eds)
    Advances in Neural Information Processing Systems, Curran Associates, Inc., vol 30,
    URL [https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf](https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vijayakumar et al. (2016) Vijayakumar AK, Cogswell M, Selvaraju RR, Sun Q,
    Lee S, Crandall D, Batra D (2016) Diverse beam search: Decoding diverse solutions
    from neural sequence models. arXiv preprint arXiv:161002424'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinyals and Le (2015) Vinyals O, Le Q (2015) A neural conversational model.
    arXiv preprint arXiv:150605869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viterbi (1967) Viterbi A (1967) Error bounds for convolutional codes and an
    asymptotically optimum decoding algorithm. IEEE transactions on Information Theory
    13(2):260–269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vougiouklis et al. (2016) Vougiouklis P, Hare J, Simperl E (2016) A neural
    network approach for knowledge-driven response generation. In: Proceedings of
    COLING 2016, the 26th International Conference on Computational Linguistics: Technical
    Papers, The COLING 2016 Organizing Committee, Osaka, Japan, pp 3370–3380, URL
    [https://www.aclweb.org/anthology/C16-1318](https://www.aclweb.org/anthology/C16-1318)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Walker et al. (1997) Walker MA, Litman DJ, Kamm CA, Abella A (1997) Paradise:
    A framework for evaluating spoken dialogue agents. arXiv preprint cmp-lg/9704004'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wan and McAuley (2016) Wan M, McAuley J (2016) Modeling ambiguity, subjectivity,
    and diverging viewpoints in opinion question answering systems. In: 2016 IEEE
    16th international conference on data mining (ICDM), IEEE, pp 489–498'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020a) Wang H, Peng B, Wong KF (2020a) Learning efficient dialogue
    policy from demonstrations through shaping. In: Proceedings of the 58th Annual
    Meeting of the Association for Computational Linguistics, pp 6355–6365'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020b) Wang K, Tian J, Wang R, Quan X, Yu J (2020b) Multi-domain
    dialogue acts and response co-generation. arXiv preprint arXiv:200412363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020c) Wang L, Li J, Zeng X, Zhang H, Wong KF (2020c) Continuity
    of topic, interaction, and query: Learning to quote in online conversations. In:
    Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing
    (EMNLP), pp 6640–6650'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020d) Wang S, Zhou K, Lai K, Shen J (2020d) Task-completion dialogue
    policy learning via Monte Carlo tree search with dueling network. In: Proceedings
    of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),
    Association for Computational Linguistics, Online, pp 3461–3471, DOI 10.18653/v1/2020.emnlp-main.278,
    URL [https://www.aclweb.org/anthology/2020.emnlp-main.278](https://www.aclweb.org/anthology/2020.emnlp-main.278)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019a) Wang W, Zhang J, Li Q, Hwang MY, Zong C, Li Z (2019a) Incremental
    learning from scratch for task-oriented dialogue systems. arXiv preprint arXiv:190604991
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang and Yuan (2016) Wang X, Yuan C (2016) Recent advances on human-computer
    dialogue. CAAI Transactions on Intelligence Technology 1(4):303–312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019b) Wang X, Shi W, Kim R, Oh Y, Yang S, Zhang J, Yu Z (2019b)
    Persuasion for good: Towards a personalized persuasive dialogue system for social
    good. arXiv preprint arXiv:190606725'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020e) Wang Y, Guo Y, Zhu S (2020e) Slot attention with value
    normalization for multi-domain dialogue state tracking. In: Proceedings of the
    2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp
    3019–3028'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020f) Wang Y, Joty S, Lyu M, King I, Xiong C, Hoi SC (2020f)
    VD-BERT: A Unified Vision and Dialog Transformer with BERT. In: Proceedings of
    the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP),
    Association for Computational Linguistics, Online, pp 3325–3338, DOI 10.18653/v1/2020.emnlp-main.269,
    URL [https://www.aclweb.org/anthology/2020.emnlp-main.269](https://www.aclweb.org/anthology/2020.emnlp-main.269)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2014) Wang Z, Zhang J, Feng J, Chen Z (2014) Knowledge graph embedding
    by translating on hyperplanes. In: Proceedings of the AAAI Conference on Artificial
    Intelligence, vol 28, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2016) Wang Z, Schaul T, Hessel M, Hasselt H, Lanctot M, Freitas
    N (2016) Dueling network architectures for deep reinforcement learning. In: International
    conference on machine learning, PMLR, pp 1995–2003'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020g) Wang Z, Ho S, Cambria E (2020g) A review of emotion sensing:
    Categorization models and algorithms. Multimedia Tools and Applications 79:35553–35582'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Welleck et al. (2018) Welleck S, Weston J, Szlam A, Cho K (2018) Dialogue natural
    language inference. arXiv preprint arXiv:181100671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen et al. (2015a) Wen TH, Gasic M, Kim D, Mrksic N, Su PH, Vandyke D, Young
    S (2015a) Stochastic language generation in dialogue using recurrent neural networks
    with convolutional sentence reranking. arXiv preprint arXiv:150801755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen et al. (2015b) Wen TH, Gasic M, Mrksic N, Su PH, Vandyke D, Young S (2015b)
    Semantically conditioned lstm-based natural language generation for spoken dialogue
    systems. arXiv preprint arXiv:150801745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen et al. (2016a) Wen TH, Gasic M, Mrksic N, Rojas-Barahona LM, Su PH, Ultes
    S, Vandyke D, Young S (2016a) Conditional generation and snapshot learning in
    neural dialogue systems. arXiv preprint arXiv:160603352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen et al. (2016b) Wen TH, Gasic M, Mrksic N, Rojas-Barahona LM, Su PH, Vandyke
    D, Young S (2016b) Multi-domain neural network language generation for spoken
    dialogue systems. arXiv preprint arXiv:160301232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wen et al. (2016c) Wen TH, Vandyke D, Mrksic N, Gasic M, Rojas-Barahona LM,
    Su PH, Ultes S, Young S (2016c) A network-based end-to-end trainable task-oriented
    dialogue system. arXiv preprint arXiv:160404562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weston et al. (2014) Weston J, Chopra S, Bordes A (2014) Memory networks. arXiv
    preprint arXiv:14103916
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams et al. (2013) Williams J, Raux A, Ramachandran D, Black A (2013) The
    dialog state tracking challenge. In: Proceedings of the SIGDIAL 2013 Conference,
    Association for Computational Linguistics, Metz, France, pp 404–413, URL [https://www.aclweb.org/anthology/W13-4065](https://www.aclweb.org/anthology/W13-4065)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams (2007) Williams JD (2007) Partially observable markov decision processes
    for spoken dialogue management. PhD thesis, University of Cambridge
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams (2013) Williams JD (2013) Multi-domain learning and generalization
    in dialog state tracking. In: Proceedings of the SIGDIAL 2013 Conference, pp 433–441'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams (2014) Williams JD (2014) Web-style ranking and slu combination for
    dialog state tracking. In: Proceedings of the 15th Annual Meeting of the Special
    Interest Group on Discourse and Dialogue (SIGDIAL), pp 282–291'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams and Zweig (2016) Williams JD, Zweig G (2016) End-to-end lstm-based
    dialog control optimized with supervised and reinforcement learning. arXiv preprint
    arXiv:160601269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Williams et al. (2017) Williams JD, Asadi K, Zweig G (2017) Hybrid code networks:
    practical and efficient end-to-end dialog control with supervised and reinforcement
    learning. arXiv preprint arXiv:170203274'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams (1992) Williams RJ (1992) Simple statistical gradient-following algorithms
    for connectionist reinforcement learning. Machine learning 8(3-4):229–256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Williams and Zipser (1989) Williams RJ, Zipser D (1989) A learning algorithm
    for continually running fully recurrent neural networks. Neural computation 1(2):270–280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wiseman et al. (2017) Wiseman S, Shieber SM, Rush AM (2017) Challenges in data-to-document
    generation. arXiv preprint arXiv:170708052
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu and Xiong (2020) Wu CS, Xiong C (2020) Probing task-oriented dialogue representation
    from language models. arXiv preprint arXiv:201013912
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019a) Wu CS, Madotto A, Hosseini-Asl E, Xiong C, Socher R, Fung
    P (2019a) Transferable multi-domain state generator for task-oriented dialogue
    systems. arXiv preprint arXiv:190508743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2020a) Wu CS, Hoi S, Socher R, Xiong C (2020a) Tod-bert: Pre-trained
    natural language understanding for task-oriented dialogues. arXiv preprint arXiv:200406871'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019b) Wu J, Wang X, Wang WY (2019b) Self-supervised dialogue learning.
    arXiv preprint arXiv:190700448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2020b) Wu S, Li Y, Zhang D, Zhou Y, Wu Z (2020b) Diverse and informative
    dialogue generation with context-specific commonsense knowledge awareness. In:
    Proceedings of the 58th annual meeting of the association for computational linguistics,
    pp 5811–5820'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019c) Wu W, Guo Z, Zhou X, Wu H, Zhang X, Lian R, Wang H (2019c)
    Proactive human-machine conversation with explicit conversation goals. arXiv preprint
    arXiv:190605572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2016) Wu Y, Wu W, Xing C, Zhou M, Li Z (2016) Sequential matching
    network: A new architecture for multi-turn response selection in retrieval-based
    chatbots. arXiv preprint arXiv:161201627'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2020c) Wu Z, Galley M, Brockett C, Zhang Y, Gao X, Quirk C, Koncel-Kedziorski
    R, Gao J, Hajishirzi H, Ostendorf M, et al. (2020c) A controllable model of grounded
    response generation. arXiv preprint arXiv:200500613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2015) Xiao H, Huang M, Hao Y, Zhu X (2015) Transg: A generative
    mixture model for knowledge graph embedding. arXiv preprint arXiv:150905488'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2017) Xiao H, Huang M, Meng L, Zhu X (2017) Ssp: semantic space
    projection for knowledge graph embedding with text descriptions. In: Proceedings
    of the AAAI Conference on Artificial Intelligence, vol 31, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xie et al. (2016) Xie R, Liu Z, Jia J, Luan H, Sun M (2016) Representation
    learning of knowledge graphs with entity descriptions. In: Proceedings of the
    AAAI Conference on Artificial Intelligence, vol 30, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xing et al. (2017) Xing C, Wu W, Wu Y, Liu J, Huang Y, Zhou M, Ma WY (2017)
    Topic aware neural response generation. In: Proceedings of the AAAI Conference
    on Artificial Intelligence, vol 31, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xing et al. (2018) Xing C, Wu Y, Wu W, Huang Y, Zhou M (2018) Hierarchical
    recurrent attention network for response generation. In: Proceedings of the AAAI
    Conference on Artificial Intelligence, vol 32, no 1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2019) Xu C, Wu W, Tao C, Hu H, Schuerman M, Wang Y (2019) Neural
    response generation with meta-words. arXiv preprint arXiv:190606050
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2020a) Xu J, Wang H, Niu ZY, Wu H, Che W, Liu T (2020a) Conversational
    graph grounded policy learning for open-domain conversation generation. In: Proceedings
    of the 58th Annual Meeting of the Association for Computational Linguistics, pp
    1835–1845'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2020b) Xu K, Tan H, Song L, Wu H, Zhang H, Song L, Yu D (2020b) Semantic
    role labeling guided multi-turn dialogue rewriter. arXiv preprint arXiv:201001417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yadollahi et al. (2017) Yadollahi A, Shahraki AG, Zaiane OR (2017) Current state
    of text sentiment analysis from opinion to emotion mining. ACM Computing Surveys
    (CSUR) 50(2):1–33
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2020) Yang S, Zhang R, Erfani S (2020) Graphdialog: Integrating
    graph knowledge into end-to-end task-oriented dialogue systems. arXiv preprint
    arXiv:201001447'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yann et al. (2014) Yann D, Tur G, Hakkani-Tur D, Heck L (2014) Zero-shot learning
    and clustering for semantic utterance classification using deep learning. In:
    International Conference on Learning Representations (cited on page 28)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2013) Yao K, Zweig G, Hwang MY, Shi Y, Yu D (2013) Recurrent neural
    networks for language understanding. In: Interspeech, pp 2524–2528'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2014) Yao K, Peng B, Zhang Y, Yu D, Zweig G, Shi Y (2014) Spoken
    language understanding using long short-term memory neural networks. In: 2014
    IEEE Spoken Language Technology Workshop (SLT), IEEE, pp 189–194'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2016) Yao K, Peng B, Zweig G, Wong KF (2016) An attentional neural
    conversation model with improved specificity. arXiv preprint arXiv:160601292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yih et al. (2015) Yih Wt, He X, Gao J (2015) Deep learning and continuous representations
    for natural language processing. In: Proceedings of the 2015 Conference of the
    North American Chapter of the Association for Computational Linguistics: Tutorial
    Abstracts, pp 6–8'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yin et al. (2015) Yin J, Jiang X, Lu Z, Shang L, Li H, Li X (2015) Neural generative
    question answering. arXiv preprint arXiv:151201337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoshino et al. (2018) Yoshino K, Hori C, Perez J, D’Haro LF, Polymenakos L,
    Gunasekara C, Lasecki WS, Kummerfeld J, Galley M, Brockett C, et al. (2018) The
    7th dialog system technology challenge. arXiv preprint
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Young et al. (2010) Young S, Gašić M, Keizer S, Mairesse F, Schatzmann J, Thomson
    B, Yu K (2010) The hidden information state model: A practical framework for pomdp-based
    spoken dialogue management. Computer Speech & Language 24(2):150–174'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Young et al. (2018) Young T, Cambria E, Chaturvedi I, Zhou H, Biswas S, Huang
    M (2018) Augmenting end-to-end dialogue systems with commonsense knowledge. In:
    AAAI, pp 4970–4977'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Young et al. (2020) Young T, Pandelea V, Poria S, Cambria E (2020) Dialogue
    systems with audio context. Neurocomputing 388:102–109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2020) Yu F, Tang J, Yin W, Sun Y, Tian H, Wu H, Wang H (2020) Ernie-vil:
    Knowledge enhanced vision-language representations through scene graph. arXiv
    preprint arXiv:200616934 1:12'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu and Joty (2020) Yu T, Joty S (2020) Online conversation disentanglement with
    pointer networks. arXiv preprint arXiv:201011080
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zaheer et al. (2020) Zaheer M, Guruganesh G, Dubey KA, Ainslie J, Alberti C,
    Ontanon S, Pham P, Ravula A, Wang Q, Yang L, et al. (2020) Big bird: Transformers
    for longer sequences. Advances in Neural Information Processing Systems 33:17283–17297'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zahiri and Choi (2017) Zahiri SM, Choi JD (2017) Emotion detection on tv show
    transcripts with sequence-based convolutional neural networks. arXiv preprint
    arXiv:170804299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zeiler and Fergus (2014) Zeiler MD, Fergus R (2014) Visualizing and understanding
    convolutional networks. In: European conference on computer vision, Springer,
    pp 818–833'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2018a) Zhang C, Li Y, Du N, Fan W, Yu PS (2018a) Joint slot filling
    and intent detection via capsule neural networks. arXiv preprint arXiv:181209471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019a) Zhang H, Lan Y, Pang L, Guo J, Cheng X (2019a) Recosa:
    Detecting the relevant contexts with self-attention for multi-turn dialogue generation.
    arXiv preprint arXiv:190705339'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019b) Zhang H, Liu Z, Xiong C, Liu Z (2019b) Grounded conversation
    generation as guided traverses in commonsense knowledge graphs. arXiv preprint
    arXiv:191102707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang and Danescu-Niculescu-Mizil (2020) Zhang J, Danescu-Niculescu-Mizil C
    (2020) Balancing objectives in counseling conversations: Advancing forwards or
    looking backwards. arXiv preprint arXiv:200504245'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2018b) Zhang S, Dinan E, Urbanek J, Szlam A, Kiela D, Weston
    J (2018b) Personalizing dialogue agents: I have a dog, do you have pets too? arXiv
    preprint arXiv:180107243'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang and Wallace (2017) Zhang Y, Wallace B (2017) A sensitivity analysis of
    (and practitioners’ guide to) convolutional neural networks for sentence classification.
    In: Proceedings of the Eighth International Joint Conference on Natural Language
    Processing (Volume 1: Long Papers), Asian Federation of Natural Language Processing,
    Taipei, Taiwan, pp 253–263, URL [https://www.aclweb.org/anthology/I17-1026](https://www.aclweb.org/anthology/I17-1026)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2018c) Zhang Y, Galley M, Gao J, Gan Z, Li X, Brockett C, Dolan
    B (2018c) Generating informative and diverse conversational responses via adversarial
    information maximization. arXiv preprint arXiv:180905972
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2020) Zhang Y, Ou Z, Wang H, Feng J (2020) A probabilistic end-to-end
    task-oriented dialog model with latent belief states towards semi-supervised learning.
    arXiv preprint arXiv:200908115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2018d) Zhang Z, Li J, Zhu P, Zhao H, Liu G (2018d) Modeling multi-turn
    conversation with deep utterance aggregation. arXiv preprint arXiv:180609102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2019c) Zhang Z, Li X, Gao J, Chen E (2019c) Budgeted policy learning
    for task-oriented dialogue systems. arXiv preprint arXiv:190600499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao and Eskenazi (2016) Zhao T, Eskenazi M (2016) Towards end-to-end learning
    for dialog state tracking and management using deep reinforcement learning. arXiv
    preprint arXiv:160602560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao and Eskenazi (2018) Zhao T, Eskenazi M (2018) Zero-shot dialog generation
    with cross-domain latent actions. arXiv preprint arXiv:180504803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2018) Zhao T, Lee K, Eskenazi M (2018) Unsupervised discrete sentence
    representation learning for interpretable neural dialog generation. arXiv preprint
    arXiv:180408069
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2020a) Zhao T, Lala D, Kawahara T (2020a) Designing precise and
    robust dialogue response evaluators. arXiv preprint arXiv:200404908
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2020b) Zhao X, Wu W, Xu C, Tao C, Zhao D, Yan R (2020b) Knowledge-grounded
    dialogue generation with pre-trained language models. arXiv preprint arXiv:201008824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhong et al. (2020) Zhong P, Zhang C, Wang H, Liu Y, Miao C (2020) Towards
    persona-based empathetic conversational models. In: Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP), pp 6556–6566, DOI 10.18653/v1/2020.emnlp-main.531'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2016) Zhou H, Huang M, Zhu X (2016) Context-aware natural language
    generation for spoken dialogue systems. In: Proceedings of COLING 2016, the 26th
    International Conference on Computational Linguistics: Technical Papers, pp 2032–2041'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2020a) Zhou H, Zheng C, Huang K, Huang M, Zhu X (2020a) Kdconv:
    a chinese multi-domain dialogue dataset towards multi-turn knowledge-driven conversation.
    arXiv preprint arXiv:200404100'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2018) Zhou K, Prabhumoye S, Black AW (2018) A dataset for document
    grounded conversations. arXiv preprint arXiv:180907358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. (2020b) Zhou L, Palangi H, Zhang L, Hu H, Corso J, Gao J (2020b)
    Unified vision-language pre-training for image captioning and vqa. In: Proceedings
    of the AAAI Conference on Artificial Intelligence, vol 34, pp 13041–13049'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou and Wang (2017) Zhou X, Wang WY (2017) Mojitalk: Generating emotional
    responses at scale. arXiv preprint arXiv:171104090'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2018) Zhu Q, Cui L, Zhang W, Wei F, Liu T (2018) Retrieval-enhanced
    adversarial training for neural response generation. arXiv preprint arXiv:180904276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2020) Zhu Q, Zhang W, Liu T, Wang WY (2020) Counterfactual off-policy
    training for neural dialogue generation. In: Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP), pp 3438–3448'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
