- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:03:42'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 20:03:42'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1912.05721] Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1912.05721] 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文的作者按字母顺序列出。'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1912.05721](https://ar5iv.labs.arxiv.org/html/1912.05721)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1912.05721](https://ar5iv.labs.arxiv.org/html/1912.05721)
- en: '¹¹affiliationtext: The Pennsylvania State University, United States²²affiliationtext:
    Pusan National University, Republic of Korea³³affiliationtext: Wuhan University
    of Technology, China'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '¹¹affiliationtext: 美国宾夕法尼亚州立大学²²affiliationtext: 韩国釜山国立大学³³affiliationtext:
    中国武汉理工大学'
- en: 'Using Deep Learning to Solve Computer Security Challenges: A Survey¹¹1The authors
    of this paper are listed in alphabetic order.'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用深度学习解决计算机安全挑战：一项调查¹¹1本文的作者按字母顺序列出。
- en: Yoon-Ho Choi Peng Liu Corresponding author: pxl20@psu.edu Zitong Shang Haizhou
    Wang Zhilong Wang Lan Zhang Junwei Zhou Qingtian Zou
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Yoon-Ho Choi Peng Liu 负责人：pxl20@psu.edu Zitong Shang Haizhou Wang Zhilong Wang
    Lan Zhang Junwei Zhou Qingtian Zou
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Although using machine learning techniques to solve computer security challenges
    is not a new idea, the rapidly emerging Deep Learning technology has recently
    triggered a substantial amount of interests in the computer security community.
    This paper seeks to provide a dedicated review of the very recent research works
    on using Deep Learning techniques to solve computer security challenges. In particular,
    the review covers eight computer security problems being solved by applications
    of Deep Learning: security-oriented program analysis, defending return-oriented
    programming (ROP) attacks, achieving control-flow integrity (CFI), defending network
    attacks, malware classification, system-event-based anomaly detection, memory
    forensics, and fuzzing for software security.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管使用机器学习技术解决计算机安全挑战并不是一个新想法，但快速发展的深度学习技术最近在计算机安全领域引发了大量兴趣。本文旨在专门回顾使用深度学习技术解决计算机安全挑战的最新研究成果。特别地，回顾涵盖了通过深度学习应用解决的八个计算机安全问题：以安全为导向的程序分析、防御返回导向编程（ROP）攻击、实现控制流完整性（CFI）、防御网络攻击、恶意软件分类、基于系统事件的异常检测、内存取证以及软件安全的模糊测试。
- en: 1 Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Using machine learning techniques to solve computer security challenges is not
    a new idea. For example, in the year of 1998, Ghosh and others in [[1](#bib.bib1)]
    proposed to train a (traditional) neural network based anomaly detection scheme(i.e.,
    detecting anomalous and unknown intrusions against programs); in the year of 2003,
    Hu and others in [[2](#bib.bib2)] and Heller and others in [[3](#bib.bib3)] applied
    Support Vector Machines to based anomaly detection scheme (e.g., detecting anomalous
    Windows registry accesses).
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 使用机器学习技术解决计算机安全挑战并不是一个新想法。例如，1998年，Ghosh等人[[1](#bib.bib1)]提出训练（传统）神经网络异常检测方案（即检测针对程序的异常和未知入侵）；2003年，Hu等人[[2](#bib.bib2)]和Heller等人[[3](#bib.bib3)]应用支持向量机进行基于异常的检测方案（例如，检测异常的Windows注册表访问）。
- en: The machine-learning-based computer security research investigations during
    1990-2010, however, have not been very impactful. For example, to the best of
    our knowledge, none of the machine learning applications proposed in [[1](#bib.bib1),
    [2](#bib.bib2), [3](#bib.bib3)] has been incorporated into a widely deployed intrusion-detection
    commercial product.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，1990-2010年的机器学习基础计算机安全研究调查并没有产生很大的影响。例如，据我们所知，[[1](#bib.bib1), [2](#bib.bib2),
    [3](#bib.bib3)]中提出的机器学习应用没有被纳入广泛部署的入侵检测商业产品中。
- en: 'Regarding why not very impactful, although researchers in the computer security
    community seem to have different opinions, the following remarks by Sommer and
    Paxson [[4](#bib.bib4)] (in the context of intrusion detection) have resonated
    with many researchers:'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关于为什么影响不大，虽然计算机安全领域的研究人员似乎有不同的看法，但Sommer和Paxson [[4](#bib.bib4)]（在入侵检测的背景下）以下的评论引起了许多研究人员的共鸣：
- en: •
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Remark A: “It is crucial to have a clear picture of what problem a system targets:
    what specifically are the attacks to be detected? The more narrowly one can define
    the target activity, the better one can tailor a detector to its specifics and
    reduce the potential for misclassifications.” [[4](#bib.bib4)]'
  id: totrans-16
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注A：“了解系统所针对的问题至关重要：具体要检测哪些攻击？定义目标活动越狭窄，越能将检测器量身定制到其特性，并减少误分类的可能性。”[[4](#bib.bib4)]
- en: •
  id: totrans-17
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Remark B: “If one cannot make a solid argument for the relation of the features
    to the attacks of interest, the resulting study risks foundering on serious flaws.”
    [[4](#bib.bib4)]'
  id: totrans-18
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 备注B：“如果无法对特征与感兴趣攻击之间的关系做出有力的论证，结果研究就有可能陷入严重缺陷。”[[4](#bib.bib4)]
- en: These insightful remarks, though well aligned with the machine learning techniques
    used by security researchers during 1990-2010, could become a less significant
    concern with Deep Learning (DL), a rapidly emerging machine learning technology,
    due to the following observations. First, Remark A implies that even if the same
    machine learning method is used, one algorithm employing a cost function that
    is based on a more specifically defined target attack activity could perform substantially
    better than another algorithm deploying a less specifically defined cost function.
    This could be a less significant concern with DL, since a few recent studies have
    shown that even if the target attack activity is not narrowly defined, a DL model
    could still achieve very high classification accuracy. Second, Remark B implies
    that if feature engineering is not done properly, the trained machine learning
    models could be plagued by serious flaws. This could be a less significant concern
    with DL, since many deep learning neural networks require less feature engineering
    than conventional machine learning techniques.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这些有见地的评论，尽管与1990-2010年期间安全研究人员使用的机器学习技术非常一致，但由于以下观察，它们在深度学习（DL）这一迅速发展的机器学习技术下可能变得不那么重要。首先，备注A意味着即使使用相同的机器学习方法，一个采用基于更具体定义目标攻击活动的成本函数的算法，可能比另一个使用成本函数定义较不具体的算法表现更好。对于DL来说，这可能是一个不那么重要的问题，因为一些近期研究表明，即使目标攻击活动没有狭窄定义，DL模型仍能实现非常高的分类准确率。其次，备注B意味着如果特征工程做得不够好，训练好的机器学习模型可能会存在严重缺陷。对于DL来说，这可能是一个不那么重要的问题，因为许多深度学习神经网络比传统机器学习技术需要更少的特征工程。
- en: As stated in [[5](#bib.bib5)], “DL is a statistical technique that exploits
    large quantities of data as training sets for a network with multiple hidden layers,
    called a deep neural network (DNN). A DNN is trained on a dataset, generating
    outputs, calculating errors, and adjusting its internal parameters. Then the process
    is repeated hundreds of thousands of times until the network achieves an acceptable
    level of performance. It has proven to be an effective technique for image classification,
    object detection, speech recognition, and natural language processing––problems
    that challenged researchers for decades. By learning from data, DNNs can solve
    some problems much more effectively, and also solve problems that were never solvable
    before.”
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 如[[5](#bib.bib5)]所述，“DL是一种统计技术，它利用大量数据作为训练集，用于训练一个具有多个隐藏层的网络，称为深度神经网络（DNN）。DNN在数据集上进行训练，生成输出、计算误差，并调整其内部参数。然后，这一过程会重复数十万次，直到网络达到可接受的性能水平。它已被证明是一种有效的技术，用于图像分类、目标检测、语音识别和自然语言处理——这些问题曾困扰研究人员几十年。通过从数据中学习，DNN可以更有效地解决某些问题，并解决以前无法解决的问题。”
- en: Now let’s take a high-level look at how DL could make it substantially easier
    to overcome the challenges identified by Sommer and Paxson [[4](#bib.bib4)]. First,
    one major advantage of DL is that it makes learning algorithms less dependent
    on feature engineering. This characteristic of DL makes it easier to overcome
    the challenge indicated by Remark B. Second, another major advantage of DL is
    that it could achieve high classification accuracy with minimum domain knowledge.
    This characteristic of DL makes it easier to overcome the challenge indicated
    by Remark A.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 现在让我们从高层次来看一下DL如何大大简化应对Sommer和Paxson所识别的挑战[[4](#bib.bib4)]。首先，DL的一个主要优势是它使学习算法对特征工程的依赖性降低。这一特点使得DL更容易克服备注B所指示的挑战。其次，DL的另一个主要优势是它可以在最小的领域知识下实现高分类准确率。这一特点使得DL更容易克服备注A所指示的挑战。
- en: Key observation. The above discussion indicates that DL could be a game changer
    in applying machine learning techniques to solving computer security challenges.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 关键观察。上述讨论表明，深度学习可能成为将机器学习技术应用于解决计算机安全挑战的变革者。
- en: Motivated by this observation, this paper seeks to provide a dedicated review
    of the very recent research works on using Deep Learning techniques to solve computer
    security challenges. It should be noticed that since this paper aims to provide
    a dedicated review, non-deep-learning techniques and their security applications
    are out of the scope of this paper.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 受此观察启发，本文旨在提供关于使用深度学习技术解决计算机安全挑战的最新研究工作的专门综述。需要注意的是，由于本文旨在提供专门综述，非深度学习技术及其安全应用不在本文范围之内。
- en: 'The remaining of the paper is organized as follows. In Section [2](#S2 "2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order."), we present
    a four-phase workflow framework which we use to summarize the existing works in
    a unified manner. In Section LABEL:sec:programanalysis-LABEL:sec:fuzzing, we provide
    a review of eight computer security problems being solved by applications of Deep
    Learning, respectively. In Section LABEL:sec:dis, we will discuss certain similarity
    and certain dissimilarity among the existing works. In Section LABEL:sec:fur,
    we mention four further areas of investigation. In Section LABEL:sec:con, we conclude
    the paper.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的剩余部分组织如下。在第[2](#S2 "2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1footnote
    11footnote 1本文的作者按字母顺序列出。")节中，我们介绍了一个四阶段的工作流程框架，用于以统一的方式总结现有工作。在LABEL:sec:programanalysis-LABEL:sec:fuzzing节中，我们分别提供了对八个通过应用深度学习解决的计算机安全问题的综述。在LABEL:sec:dis节中，我们将讨论现有工作之间的某些相似性和某些差异性。在LABEL:sec:fur节中，我们提到四个进一步研究的领域。在LABEL:sec:con节中，我们总结了本文。
- en: 2 A four-phase workflow framework can summarize the existing works in a unified
    manner
  id: totrans-25
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
- en: 'We found that a four-phase workflow framework can provide a unified way to
    summarize all the research works surveyed by us. In particular, we found that
    each work surveyed by us employs a particular workflow when using machine learning
    techniques to solve a computer security challenge, and we found that each workflow
    consists of two or more phases. By “a unified way”, we mean that every workflow
    surveyed by us is essentially an instantiation of a common workflow pattern which
    is shown in Figure [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣
    2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 我们发现，四阶段工作流程框架可以提供一种统一的方法来总结我们调查的所有研究工作。特别是，我们发现我们调查的每项工作在使用机器学习技术解决计算机安全挑战时采用了特定的工作流程，并且每个工作流程都包含两个或更多阶段。所谓“统一的方法”，是指我们调查的每个工作流程本质上都是一种通用工作流程模式的实例，如图[1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1footnote
    11footnote 1本文的作者按字母顺序列出。")所示。
- en: 2.1 Definitions of the four phases
  id: totrans-27
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 四个阶段的定义
- en: 'The four phases, shown in Figure [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of
    the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), are defined as follows. To make the definitions of the four phases more
    tangible, we use a running example to illustrate each of the four phases.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 如图[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1footnote
    11footnote 1本文的作者按字母顺序列出。")所示，四个阶段的定义如下。为了使四个阶段的定义更加具体，我们使用一个运行示例来说明这四个阶段。
- en: '![Refer to caption](img/c5890520fa682cfe790f529a0deafba2.png)'
  id: totrans-29
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c5890520fa682cfe790f529a0deafba2.png)'
- en: 'Figure 1: Overview of the four-phase workflow'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：四阶段工作流程概览
- en: Phase I.(Obtaining the Raw Data)
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 第一阶段（获取原始数据）
- en: In this phase, certain raw data are collected.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个阶段，收集了某些原始数据。
- en: 'Running Example: When Deep Learning is used to detect suspicious events in
    a Hadoop distributed file system (HDFS), the raw data are usually the events (e.g.,
    a block is allocated, read, written, replicated, or deleted) that have happened
    to each block. Since these events are recorded in Hadoop logs, the log files hold
    the raw data. Since each event is uniquely identified by a particular (block ID,
    timestamp) tuple, we could simply view the raw data as $n$ event sequences. Here
    $n$ is the total number of blocks in the HDFS. For example, the raw data collected
    in [[6](#bib.bib6)] in total consists of 11,197,954 events. Since 575,139 blocks
    were in the HDFS, there were 575,139 event sequences in the raw data, and on average
    each event sequence had 19 events. One such event sequence is shown as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 运行示例：当深度学习用于检测Hadoop分布式文件系统（HDFS）中的可疑事件时，原始数据通常是发生在每个块上的事件（例如，块被分配、读取、写入、复制或删除）。由于这些事件记录在Hadoop日志中，日志文件保存了原始数据。由于每个事件由特定的（块ID，时间戳）元组唯一标识，我们可以简单地将原始数据视为$n$个事件序列。这里的$n$是HDFS中块的总数。例如，[[6](#bib.bib6)]中收集的原始数据总共包含11,197,954个事件。由于HDFS中有575,139个块，所以原始数据中有575,139个事件序列，平均每个事件序列包含19个事件。以下是一个这样的事件序列：
- en: '[PRE0]'
  id: totrans-34
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: Phase II.(Data Preprocessing)
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 第二阶段（数据预处理）
- en: 'Both Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") and Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") aim to properly extract and represent
    the useful information held in the raw data collected in Phase I. Both Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") and Phase [1](#S2.F1 "Figure 1
    ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") are closely related to feature engineering. A key
    difference between Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") and Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") is that Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") is completely dedicated to representation
    learning, while Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") is focused
    on all the information extraction and data processing operations that are not
    based on representation learning.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注
    11脚注 1本文作者按字母顺序列出。") 和阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文作者按字母顺序列出。") 旨在正确提取和表示阶段 I 收集的原始数据中包含的有用信息。阶段 [1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文作者按字母顺序列出。")
    和阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注
    11脚注 1本文作者按字母顺序列出。") 都与特征工程密切相关。阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文作者按字母顺序列出。") 和阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义
    ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文作者按字母顺序列出。") 的一个关键区别在于，阶段 [1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文作者按字母顺序列出。")
    完全专注于表示学习，而阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注
    11脚注 1本文作者按字母顺序列出。") 则专注于所有不基于表示学习的信息提取和数据处理操作。
- en: 'Running Example: Let’s revisit the aforementioned HDFS. Each recorded event
    is described by unstructured text. In Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), the unstructured text is parsed to a data structure that shows the event
    type and a list of event variables in (name, value) pairs. Since there are 29
    types of events in the HDFS, each event is represented by an integer from 1 to
    29 according to its type. In this way, the aforementioned example event sequence
    can be transformed to:'
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 运行示例：让我们重新审视上述 HDFS。每个记录的事件都由非结构化文本描述。在阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2
    一个四阶段工作流程框架可以统一总结现有的工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1 本文的作者按字母顺序列出。")，非结构化文本被解析为显示事件类型和事件变量（名称，值）对的数据结构。由于
    HDFS 中有 29 种事件类型，每个事件根据其类型由从 1 到 29 的整数表示。这样，上述示例事件序列可以转换为：
- en: '[PRE1]'
  id: totrans-38
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: Phase III.(Representation Learning)
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 III.（表示学习）
- en: As stated in [[7](#bib.bib7)], “Learning representations of the data that make
    it easier to extract useful information when building classifiers or other predictors.”
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 如 [[7](#bib.bib7)] 所述，“学习数据的表示，使得在构建分类器或其他预测器时更容易提取有用的信息。”
- en: 'Running Example: Let’s revisit the same HDFS. Although DeepLog [[8](#bib.bib8)]
    directly employed one-hot vectors to represent the event types without representation
    learning, if we view an event type as a word in a structured language, one may
    actually use the word embedding technique to represent each event type. It should
    be noticed that the word embedding technique is a representation learning technique.'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 运行示例：让我们重新审视相同的 HDFS。尽管 DeepLog [[8](#bib.bib8)] 直接使用 one-hot 向量表示事件类型而未进行表示学习，但如果我们将事件类型视为结构化语言中的一个词，实际上可以使用词嵌入技术来表示每个事件类型。需要注意的是，词嵌入技术是一种表示学习技术。
- en: Phase IV.(Classifier Learning)
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 阶段 IV.（分类器学习）
- en: This phase aims to build specific classifiers or other predictors through Deep
    Learning.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 这一阶段旨在通过深度学习构建特定的分类器或其他预测器。
- en: 'Running Example: Let’s revisit the same HDFS. DeepLog [[8](#bib.bib8)] used
    Deep Learning to build a stacked LSTM neural network for anomaly detection. For
    example, let’s consider event sequence {22,5,5,5,11,9,11,9,11,9,26,26,26} in which
    each integer represents the event type of the corresponding event in the event
    sequence. Given a window size $h$ = 4, the input sample and the output label pairs
    to train DeepLog will be: {22,5,5,5 $\rightarrow$ 11 }, {5,5,5,11 $\rightarrow$
    9 }, {5,5,11,9 $\rightarrow$ 11 }, and so forth. In the detection stage, DeepLog
    examines each individual event. It determines if an event is treated as normal
    or abnormal according to whether the event’s type is predicted by the LSTM neural
    network, given the history of event types. If the event’s type is among the top
    $g$ predicted types, the event is treated as normal; otherwise, it is treated
    as abnormal.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 运行示例：让我们重新审视相同的 HDFS。DeepLog [[8](#bib.bib8)] 使用深度学习构建了一个堆叠 LSTM 神经网络用于异常检测。例如，考虑事件序列
    {22,5,5,5,11,9,11,9,11,9,26,26,26}，其中每个整数表示事件序列中相应事件的事件类型。给定窗口大小 $h$ = 4，用于训练
    DeepLog 的输入样本和输出标签对为：{22,5,5,5 $\rightarrow$ 11}，{5,5,5,11 $\rightarrow$ 9}，{5,5,11,9
    $\rightarrow$ 11}，等等。在检测阶段，DeepLog 检查每个单独的事件。它根据事件类型是否被 LSTM 神经网络预测来判断事件是否正常。如果事件类型位于前
    $g$ 个预测类型中，则该事件被视为正常；否则，视为异常。
- en: 2.2 Using the four-phase workflow framework to summarize some representative
    research works
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 使用四阶段工作流程框架总结一些代表性研究工作
- en: 'In this subsection, we use the four-phase workflow framework to summarize two
    representative works for each security problem. System security includes many
    sub research topics. However, not every research topics are suitable to adopt
    deep learning-based methods due to their intrinsic characteristics. For these
    security research subjects that can combine with deep-learning, some of them has
    undergone intensive research in recent years, others just emerging. We notice
    that there are 5 mainstream research directions in system security. This paper
    mainly focuses on system security, so the other mainstream research directions
    (e.g., deepfake) are out-of-scope. Therefore, we choose these 5 widely noticed
    research directions, and 3 emerging research direction in our survey:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们使用四阶段工作流框架来总结每个安全问题的两个代表性工作。系统安全包括许多子研究主题。然而，并不是所有的研究主题都适合采用基于深度学习的方法，这取决于它们的固有特性。对于可以结合深度学习的安全研究主题，有些在近年来已经进行了深入研究，而其他的则刚刚出现。我们注意到系统安全领域有5个主流研究方向。本文主要关注系统安全，因此其他主流研究方向（如深度伪造）不在讨论范围之内。因此，我们在调查中选择了这5个广受关注的研究方向，以及3个新兴研究方向：
- en: '1.'
  id: totrans-47
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: In security-oriented program analysis, malware classification (MC), system-event-based
    anomaly detection (SEAD), memory forensics (MF), and defending network attacks,
    deep learning based methods have already undergone intensive research.
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在安全导向的程序分析中，恶意软件分类（MC）、基于系统事件的异常检测（SEAD）、内存取证（MF）和防御网络攻击等领域，基于深度学习的方法已经进行了深入研究。
- en: '2.'
  id: totrans-49
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: In defending return-oriented programming (ROP) attacks, Control-flow integrity
    (CFI), and fuzzing, deep learning based methods are emerging research topics.
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在防御面向返回的编程（ROP）攻击、控制流完整性（CFI）和模糊测试方面，基于深度学习的方法正成为新兴的研究主题。
- en: 'We select two representative works for each research topic in our survey. Our
    criteria to select papers mainly include: 1) Pioneer (one of the first papers
    in this field); 2) Top (published on top conference or journal); 3) Novelty; 4)
    Citation (The citation of this paper is high); 5) Effectiveness (the result of
    this paper is pretty good); 6) Representative (the paper is a representative work
    for a branch of the research direction). Table [1](#S2.T1 "Table 1 ‣ 2.2 Using
    the four-phase workflow framework to summarize some representative research works
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") lists
    the reasons why we choose each paper, which is ordered according to their importance.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在调查中为每个研究主题选择了两个代表性工作。选择论文的标准主要包括：1) 开创者（该领域的早期论文之一）；2) 顶尖（发表在顶级会议或期刊上）；3)
    创新性；4) 引用（论文的引用量高）；5) 效果（论文的结果相当好）；6) 代表性（论文是该研究方向的代表性工作）。表 [1](#S2.T1 "表 1 ‣
    2.2 使用四阶段工作流框架总结一些代表性研究工作 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注
    11脚注 1本文作者按字母顺序列出。") 列出了我们选择每篇论文的原因，并按重要性排序。
- en: 'Table 1: List of criteria we used to choose representative work for each research
    topic.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：我们用来选择每个研究主题代表性工作的标准列表。
- en: '| <svg version="1.1" height="19.58" width="64.06" overflow="visible"><g transform="translate(0,19.58)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,10.93) scale(1,
    -1)"><foreignobject width="32.03" height="10.93" overflow="visible">Paper</foreignobject></g></g>
    <g  transform="translate(32.17,10.93)"><g transform="translate(0,8.65) scale(1,
    -1)"><foreignobject width="31.89" height="8.65" overflow="visible">Order</foreignobject></g></g></g></svg>
         | 1 | 2 | 3 | 4 |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| <svg version="1.1" height="19.58" width="64.06" overflow="visible"><g transform="translate(0,19.58)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,10.93) scale(1,
    -1)"><foreignobject width="32.03" height="10.93" overflow="visible">论文</foreignobject></g></g>
    <g  transform="translate(32.17,10.93)"><g transform="translate(0,8.65) scale(1,
    -1)"><foreignobject width="31.89" height="8.65" overflow="visible">订单</foreignobject></g></g></g></svg>
         | 1 | 2 | 3 | 4 |'
- en: '|  RFBNN [[9](#bib.bib9)]   | Pioneer | Top | Novelty | Citations |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  RFBNN [[9](#bib.bib9)]   | 开创者 | 顶尖 | 创新性 | 引用 |'
- en: '| EKLAVYA [[10](#bib.bib10)]   | Top | Novelty | Citation | N/A |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| EKLAVYA [[10](#bib.bib10)]   | 顶尖 | 创新性 | 引用 | 不适用 |'
- en: '| ROPNN [[11](#bib.bib11)]   | Pioneer | Novelty | Effectiveness | N/A |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| ROPNN [[11](#bib.bib11)]   | 开创者 | 创新性 | 效果 | 不适用 |'
- en: '| HeNet [[12](#bib.bib12)]   | Effectiveness | Novelty | Citation | N/A |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| HeNet [[12](#bib.bib12)]   | 效果 | 创新性 | 引用 | 不适用 |'
- en: '| Barnum [[13](#bib.bib13)]   | Pioneer | Novelty | N/A | N/A |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Barnum [[13](#bib.bib13)]   | 开创者 | 创新性 | 不适用 | 不适用 |'
- en: '| CFG-CNN [[14](#bib.bib14)]   | Representative | N/A | N/A | N/A |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| CFG-CNN [[14](#bib.bib14)]   | 代表性 | 不适用 | 不适用 | 不适用 |'
- en: '| 50b(yte)-CNN[[15](#bib.bib15)]   | Novelty | Effectiveness | N/A | N/A |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| 50b(yte)-CNN [[15](#bib.bib15)]   | 新颖性 | 有效性 | 不适用 | 不适用 |'
- en: '| PCNN [[16](#bib.bib16)]   | Novelty | Effectiveness | N/A | N/A |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| PCNN [[16](#bib.bib16)]   | 新颖性 | 有效性 | 不适用 | 不适用 |'
- en: '| Resenberg [[17](#bib.bib17)]   | Novelty | Effectiveness | Top | Representative
    |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| Resenberg [[17](#bib.bib17)]   | 新颖性 | 有效性 | 顶级 | 代表性 |'
- en: '| DeLaRosa [[18](#bib.bib18)]   | Novelty | Representative | N/A | N/A |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| DeLaRosa [[18](#bib.bib18)]   | 新颖性 | 代表性 | 不适用 | 不适用 |'
- en: '| DeepLog [[8](#bib.bib8)]   | Pioneer | Top | Citations | N/A |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| DeepLog [[8](#bib.bib8)]   | 先锋 | 顶级 | 引用 | 不适用 |'
- en: '| DeepMem [[19](#bib.bib19)]   | Pioneer | Top | N/A | N/A |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| DeepMem [[19](#bib.bib19)]   | 先锋 | 顶级 | 不适用 | 不适用 |'
- en: '| NeuZZ [[20](#bib.bib20)]   | Novelty | Top | Effectiveness | N/A |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| NeuZZ [[20](#bib.bib20)]   | 新颖性 | 顶级 | 有效性 | 不适用 |'
- en: '| Learn & Fuzz [[21](#bib.bib21)]   | Pioneer | Novelty | Top | N/A |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Learn & Fuzz [[21](#bib.bib21)]   | 先锋 | 新颖性 | 顶级 | 不适用 |'
- en: The summary for each paper we selected is shown in Table LABEL:Table:Summary.
    There are three columns in the table. In the first column, we listed eight security
    problems, including security-oriented program analysis, defending return-oriented
    programming (ROP) attacks, control-flow integrity (CFI), defending network attacks
    (NA), malware classification (MC), system-event-based anomaly detection (SEAD),
    memory forensics (MF), and fuzzing for software security. In the second column,
    we list the very recent two representative works for each security problem. From
    the $3$-th to $6$-th columns, we sequentially describe how the four phases are
    deployed at each work. In the “Summary” column, we sequentially describe how the
    four phases are deployed at each work, then, we list the evaluation results for
    each work in terms of accuracy (ACC), precision (PRC), recall (REC), F1 score
    (F1), false-positive rate (FPR), and false-negative rate (FNR), respectively.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 每篇我们选择的论文的摘要显示在表格 LABEL:Table:Summary中。表中有三列。在第一列中，我们列出了八个安全问题，包括安全导向的程序分析、抵御返回导向编程（ROP）攻击、控制流完整性（CFI）、抵御网络攻击（NA）、恶意软件分类（MC）、基于系统事件的异常检测（SEAD）、内存取证（MF）和软件安全模糊测试。在第二列中，我们列出了每个安全问题的两个最新代表性工作。从第$3$列到第$6$列，我们顺序描述了每项工作的四个阶段的部署情况。在“总结”列中，我们顺序描述了每项工作的四个阶段的部署情况，然后列出每项工作的评估结果，包括准确率（ACC）、精确度（PRC）、召回率（REC）、F1
    分数（F1）、假阳性率（FPR）和假阴性率（FNR）。
- en: '{ThreePartTable}{TableNotes}'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '{ThreePartTable}{TableNotes}'
- en: 'Deep Learning metrics are often not available in fuzzing papers. Typical fuzzing
    metrics used for evaluations are: code coverage, pass rate and bugs.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习指标通常在模糊测试论文中不可用。典型的模糊测试评估指标包括：代码覆盖率、通过率和缺陷。
- en: 'Table 2: Solutions using Deep Learning for eight security problems. The metrics
    in the Evaluation column include accuracy (ACC), precision (PRC), recall (REC),
    $F_{1}$ score ($F_{1}$), false positive rate (FPR), and false negative rate (FNR).'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：使用深度学习解决八个安全问题的方案。评估列中的指标包括准确率（ACC）、精确度（PRC）、召回率（REC）、$F_{1}$ 分数（$F_{1}$）、假阳性率（FPR）和假阴性率（FNR）。
- en: '|  |  |  |  |  |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  |  |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Security Problem | Works | Summary |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 安全问题 | 工作 | 总结 |'
- en: '| --- | --- | --- |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Security Oriented Program Analysis [[9](#bib.bib9), [10](#bib.bib10), [22](#bib.bib22),
    [23](#bib.bib23)] | RFBNN [[9](#bib.bib9)] | Phase I | Phase II |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 安全导向程序分析 [[9](#bib.bib9), [10](#bib.bib10), [22](#bib.bib22), [23](#bib.bib23)]
    | RFBNN [[9](#bib.bib9)] | 阶段 I | 阶段 II |'
- en: '|  |  | Dataset comes from previous paper [[24](#bib.bib24)], consisting of
    2200 separate binaries. 2064 of the binaries were for Linux, obtained from the
    coreutils, binutils, and findutils packages. The remaining 136 for Windows consist
    of binaries from popular open-source projects. Half of the binaries were for x86,
    and the other half for x86-64. | They extract fixed-length subsequences (1000-byte
    chunks) from code section of binaries, Then, use “one-hot encoding”, which converts
    a byte into a $\mathbb{Z}^{256}$ vector. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 数据集来自之前的论文 [[24](#bib.bib24)]，包括2200个独立的二进制文件。2064个二进制文件用于Linux，来源于coreutils、binutils和findutils软件包。剩余的136个二进制文件用于Windows，来自流行的开源项目。二进制文件中一半为x86，另一半为x86-64。
    | 他们从二进制文件的代码部分提取固定长度的子序列（1000字节块），然后使用“独热编码”，将字节转换为$\mathbb{Z}^{256}$向量。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | N/A | Bi-directional RNN |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 双向 RNN |'
- en: '&#124; ACC: &#124; 98.4% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 98.4% &#124;  &#124; 精确度: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; 0.97 &#124;  &#124; $F_{1}$: &#124; 0.98 &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 0.97 &#124;  &#124; $F_{1}$: &#124; 0.98 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 不适用 &#124;  &#124; FNR: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | EKLAVYA[[10](#bib.bib10)] | Phase I | Phase II |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '|  | EKLAVYA[[10](#bib.bib10)] | 阶段 I | 阶段 II |'
- en: '|  |  | They adopted source code from previous work [[9](#bib.bib9)] as their
    rawdata, then obtained two datasets by using two commonly used compilers: gcc
    and clang, with different optimization levels ranging from O0 to O3 for both x86
    and x64. They obtained the ground truth for the function arguments by parsing
    the DWARF debug information. Next, they extract functions from the binaries and
    remove functions which are duplicates of other functions in the dataset. Finally,
    they match caller snipper and callee body. | Tokenizing the hexadecimal value
    of each instruction. |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 他们采用了之前工作的源代码[[9](#bib.bib9)]作为他们的原始数据，然后使用两个常用编译器：gcc和clang，针对x86和x64进行了从O0到O3的不同优化级别。通过解析DWARF调试信息，他们获得了函数参数的真实值。接下来，从二进制文件中提取函数，并去除数据集中重复的函数。最后，匹配调用器代码片段和被调用者主体。
    | 对每条指令的十六进制值进行分词。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | Word2vec technique to compute word embeddings. | RNN |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 使用Word2vec技术计算词嵌入。 | RNN |'
- en: '&#124; ACC: &#124; 81.0% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; 81.0% &#124;  &#124; PRE: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; N/A &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 不适用 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 不适用 &#124;  &#124; FNR: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Defending Return Oriented Programming Attacks [[11](#bib.bib11), [12](#bib.bib12),
    [25](#bib.bib25)] | ROPNN [[11](#bib.bib11)] | Phase I | Phase II |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 防御返回导向编程攻击 [[11](#bib.bib11), [12](#bib.bib12), [25](#bib.bib25)] | ROPNN
    [[11](#bib.bib11)] | 阶段 I | 阶段 II |'
- en: '|  |  | The data is a set of gadget chains obtained from existing programs.
    A gadget searching tool, ROPGadget is used to find available gadgets. Gadgets
    are chained based on whether the produced gadget chain is executable on a CPU
    emulator. The raw data is represented in hexadecimal form of instruction sequences.
    | Form one-hot vector for bytes. |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 数据是一组从现有程序中获得的gadget链。使用gadget搜索工具ROPGadget来查找可用的gadget。根据产生的gadget链是否可以在CPU模拟器上执行来连接gadget。原始数据以指令序列的十六进制形式表示。
    | 为字节形成one-hot向量。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | N/A | 1-D CNN |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 1-D CNN |'
- en: '&#124; ACC: &#124; 99.9% &#124;  &#124; PRE: &#124; 0.99 &#124;'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; 99.9% &#124;  &#124; PRE: &#124; 0.99 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; 0.01 &#124;'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 0.01 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 不适用 &#124;  &#124; FNR: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | HeNet [[12](#bib.bib12)] | Phase I | Phase II |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|  | HeNet [[12](#bib.bib12)] | 阶段 I | 阶段 II |'
- en: '|  |  | Data is acquired from Intel PT, which is a processor trace tool that
    can log control flow data. Taken Not-Taken (TNT) packet and Target IP (TIP) packet
    are the two packets of interested. Logged as binary numbers, information of executed
    branches can be obtained from TNT, and binary executed can be obtained from TIP.
    Then the binary sequences are transferred into sequences of values between 0-255,
    called pixels, byte by byte. | Given the pixel sequences, slice the whole sequence
    and reshape to form sequences of images for neural network training. |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 数据来自Intel PT，这是一个处理器跟踪工具，可以记录控制流数据。感兴趣的两个数据包是Taken Not-Taken (TNT)包和Target
    IP (TIP)包。信息以二进制形式记录，从TNT中可以获取执行分支的信息，从TIP中可以获取二进制执行信息。然后将二进制序列转换为0到255之间的值序列，称为像素，逐字节处理。
    | 根据像素序列，将整个序列切片并重新调整形状，以形成图像序列用于神经网络训练。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | Word2vec technique to compute word embeddings. | DNN |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 使用Word2vec技术计算词嵌入。 | DNN |'
- en: '&#124; ACC: &#124; 98.1% &#124;  &#124; PRE: &#124; 0.99 &#124;'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; 98.1% &#124;  &#124; PRE: &#124; 0.99 &#124;'
- en: '&#124; REC: &#124; 0.96 &#124;  &#124; $F_{1}$: &#124; 0.97 &#124;'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 0.96 &#124;  &#124; $F_{1}$: &#124; 0.97 &#124;'
- en: '&#124; FPR: &#124; 0.01 &#124;  &#124; FNR: &#124; 0.04 &#124;'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 0.01 &#124;  &#124; FNR: &#124; 0.04 &#124;'
- en: '|'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Achieving Control Flow Integrity [[13](#bib.bib13), [14](#bib.bib14), [25](#bib.bib25)]
    | Barnum[[13](#bib.bib13)] | Phase I | Phase II |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 实现控制流完整性 [[13](#bib.bib13), [14](#bib.bib14), [25](#bib.bib25)] | Barnum[[13](#bib.bib13)]
    | 阶段 I | 阶段 II |'
- en: '|  |  | The raw data, which is the exact sequence of instructions executed,
    was generated by combining the program binary, get immediately before the program
    opens a document, and Intel^® PT trace. While Intel^® PT built-in filtering options
    are set to CR3 and current privilege level (CPL), which only traces the program
    activity in the user space. | The raw instruction sequences are summarized into
    Basic Blocks with IDs assigned and are then sliced into manageable subsequences
    with a fix window size 32, founded experimentally. Only sequences ending on indirect
    calls, jumps and returns are analyzed, since control-flow hijacking attacks always
    occur there. The label is the next BBID in the sequence. |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 原始数据，即执行的确切指令序列，是通过将程序二进制文件、程序打开文档前立即获取的内容和 Intel^® PT 跟踪结合生成的。虽然 Intel^®
    PT 内置的过滤选项设置为 CR3 和当前特权级别（CPL），仅跟踪用户空间中的程序活动。 | 原始指令序列被总结为带有 ID 的基本块，并且被切分为大小为
    32 的可管理子序列，这一大小通过实验确定。仅分析以间接调用、跳转和返回结束的序列，因为控制流劫持攻击总是在这些地方发生。标签是序列中的下一个 BBID。
    |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | LSTM |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | LSTM |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.98 &#124;'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率（ACC）： &#124; 不适用% &#124;  &#124; 精确率（PRE）： &#124; 0.98 &#124;'
- en: '&#124; REC: &#124; 1.00 &#124;  &#124; $F_{1}$: &#124; 0.98 &#124;'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 召回率（REC）： &#124; 1.00 &#124;  &#124; $F_{1}$: &#124; 0.98 &#124;'
- en: '&#124; FPR: &#124; 0.98 &#124;  &#124; FNR: &#124; 0.02 &#124;'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假阳性率（FPR）： &#124; 0.98 &#124;  &#124; 假阴性率（FNR）： &#124; 0.02 &#124;'
- en: '|'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | CFG-CNN [[14](#bib.bib14)] | Phase I | Phase II |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | CFG-CNN [[14](#bib.bib14)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | The raw data is instruction level control-flow graph constructed from
    program assembly code by an algorithm proposed by the authors. While in the CFG,
    one vertex corresponds to one instruction and one directed edge corresponds to
    an execution path from one instruction to another. The program sets for experiments
    are obtained from popular programming contest CodeChief. | Since each vertex of
    the CFG represents an instruction with complex information that could be viewed
    from different aspects, including instruction name, type, operands etc., a vertex
    is represented as the sum of a set of real valued vectors, corresponding to the
    number of views (e.g. addq 32,%rsp is converted to linear combination of randomly
    assigned vectors of addq value, reg). The CFG is then sliced by a set of fixed
    size windows sliding through the entire graph to extract local features on different
    levels. |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 原始数据是由作者提出的算法从程序汇编代码构建的指令级控制流图。在控制流图（CFG）中，一个顶点对应一个指令，一个有向边对应从一个指令到另一个指令的执行路径。实验用的程序集来自流行的编程竞赛平台
    CodeChief。 | 由于控制流图中的每个顶点表示一个包含复杂信息的指令，可以从不同的方面查看，包括指令名称、类型、操作数等，一个顶点被表示为一组实值向量的总和，这些向量对应于不同的视图（例如，addq
    32,%rsp 被转换为 addq 值和 reg 随机分配向量的线性组合）。然后，控制流图通过一组固定大小的窗口切片穿过整个图，以提取不同级别的局部特征。
    |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | DGCNN with different numbers of views and with or without operands
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | DGCNN 具有不同视图数量和是否有操作数 |'
- en: '&#124; ACC: &#124; 84.1% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率（ACC）： &#124; 84.1% &#124;  &#124; 精确率（PRE）： &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; N/A &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 召回率（REC）： &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 不适用 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假阳性率（FPR）： &#124; 不适用 &#124;  &#124; 假阴性率（FNR）： &#124; 不适用 &#124;'
- en: '|'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Defending Network Attacks [[15](#bib.bib15), [16](#bib.bib16), [26](#bib.bib26),
    [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30)] | 50b(yte)-CNN[[15](#bib.bib15)]
    | Phase I | Phase II |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 防御网络攻击 [[15](#bib.bib15), [16](#bib.bib16), [26](#bib.bib26), [27](#bib.bib27),
    [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30)] | 50b(yte)-CNN[[15](#bib.bib15)]
    | 第一阶段 | 第二阶段 |'
- en: '|  |  | Open dataset UNSW-NB15 is used. First, tcpdump tool is utilised to
    capture 100 GB of the raw traffic (i.e. PCAP files) containing benign activities
    and 9 types of attacks. The Argus, Bro-IDS (now called Zeek) analysis tools are
    then used and twelve algorithms are developed to generate totally 49 features
    with the class label. In the end, the total number of data samples is 2,540,044
    which are stored in CSV files. | The first 50 bytes of each network traffic flow
    are picked out and each is directly used as one feature input to the neural network.
    |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 使用开放数据集 UNSW-NB15。首先，利用 tcpdump 工具捕获 100 GB 的原始流量（即 PCAP 文件），包含正常活动和
    9 种攻击。然后使用 Argus、Bro-IDS（现称为 Zeek）分析工具，开发了十二种算法以生成总共 49 个特征和类别标签。最终，总的数据样本数量为
    2,540,044，存储在 CSV 文件中。 | 选取每个网络流量流的前 50 字节，每个字节直接作为一个特征输入到神经网络中。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | N/A | CNN with 2 hidden fully connected layers |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 具有 2 个隐藏全连接层的 CNN |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; 不适用% &#124;  &#124; PRE: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 不适用 &#124;  &#124; FNR: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | PCCN[[16](#bib.bib16)] | Phase I | Phase II |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|  | PCCN[[16](#bib.bib16)] | 阶段 I | 阶段 II |'
- en: '|  |  | Open dataset CICIDS2017, which contains benign and 14 types of attacks,
    is used. Background benign network traffics are generated by profiling the abstract
    behavior of human interactions. Raw data are provided as PCAP files, and the results
    of the network traffic analysis using CICFlowMeter are pvodided as CSV files.
    In the end the dataset contains 3,119,345 data samples and 83 features categorized
    into 15 classes (1 normal + 14 attacks). | Extract a total of 1,168,671 flow data,
    including 12 types of attack activities, from original dataset. Those flow data
    are then processed and visualized into grey-scale 2D graphs. The visualization
    method is not specified. |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 使用开放数据集 CICIDS2017，其中包含正常和 14 种攻击。通过对人类交互的抽象行为进行建模生成背景正常网络流量。原始数据提供为
    PCAP 文件，使用 CICFlowMeter 进行网络流量分析的结果提供为 CSV 文件。最终数据集包含 3,119,345 个数据样本和 83 个特征，分类为
    15 个类别（1 个正常 + 14 个攻击）。 | 从原始数据集中提取总计 1,168,671 个流数据，包括 12 种攻击活动。这些流数据随后被处理并可视化为灰度
    2D 图。可视化方法未指定。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 阶段 III | 阶段 IV | 评估 |'
- en: '|  |  | N/A | Parallel cross CNN. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 并行交叉 CNN。 |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.99 &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; 不适用% &#124;  &#124; PRE: &#124; 0.99 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; 0.99 &#124;'
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 0.99 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 不适用 &#124;  &#124; FNR: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Malware Classification [[18](#bib.bib18), [31](#bib.bib31), [32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38), [39](#bib.bib39), [17](#bib.bib17), [40](#bib.bib40)] | Rosenberg[[17](#bib.bib17)]
    | Phase I | Phase II |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 恶意软件分类 [[18](#bib.bib18), [31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33),
    [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37), [38](#bib.bib38),
    [39](#bib.bib39), [17](#bib.bib17), [40](#bib.bib40)] | Rosenberg[[17](#bib.bib17)]
    | 阶段 I | 阶段 II |'
- en: '|  |  | The android dataset has the latest malware families and their variants,
    each with the same number of samples. The samples are labeled by VirusTotal. Then
    Cuckoo Sandbox is used to extract dynamic features (API calls) and static features
    (string). To avoid some anti-forensic sample, they applied YARA rule and removed
    sequences with less than 15 API calls. After preprocessing and balance the benign
    samples number, the dataset has 400,000 valid samples. | Long sequences cause
    out of memory during training LSTM model. So they use sliding window with fixed
    size and pad shorter sequences with zeros. One-hot encoding is applied to API
    calls. For static features strings, they defined a vector of 20,000 Boolean values
    indicating the most frequent Strings in the entire dataset. If the sample contain
    one string, the corresponding value in the vector will be assigned as 1, otherwise,
    0. |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|  |  | Android 数据集包含最新的恶意软件家族及其变体，每个家族的样本数量相同。样本由 VirusTotal 标记。然后使用 Cuckoo
    Sandbox 提取动态特征（API 调用）和静态特征（字符串）。为了避免某些反取证样本，他们应用了 YARA 规则并去除 API 调用少于 15 次的序列。在预处理和样本数量平衡之后，数据集包含
    400,000 个有效样本。 | 长序列在训练 LSTM 模型时会导致内存溢出。因此，他们使用固定大小的滑动窗口，并用零填充较短的序列。对 API 调用应用了一位编码。对于静态特征字符串，他们定义了一个
    20,000 个布尔值的向量，表示数据集中最频繁的字符串。如果样本包含一个字符串，向量中相应的值将被设置为 1，否则为 0。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | They used RNN, BRNN, LSTM, Deep LSTM, BLSTM, Deep BLSTM, GRU,
    bi-directional GRU, Fully-connected DNN, 1D CNN in their experiments |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 他们在实验中使用了 RNN、BRNN、LSTM、Deep LSTM、BLSTM、Deep BLSTM、GRU、双向 GRU、全连接
    DNN 和 1D CNN |'
- en: '&#124; ACC: &#124; 98.3% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 98.3% &#124;  &#124; 精确率: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; N/A &#124;'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 召回率: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 不适用 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假阳性率: &#124; 不适用 &#124;  &#124; 假阴性率: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | DeLaRosa[[18](#bib.bib18)] | Phase I | Phase II |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|  | DeLaRosa[[18](#bib.bib18)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | The windows dataset is from Reversing Labs including XP, 7, 8, and
    10 for both 32-bit and 64-bit architectures and gathered over a span of twelve
    years (2006-2018). They selected nine malware families in their dataset and extracted
    static features in terms of bytes, basic, and assembly features. | For bytes-level
    features, they used a sliding window to get the histogram of the bytes and compute
    the associated entropy in a window; for basic features, they created a fixed-sized
    feature vector given either a list of ASCII strings, or extracted import and metadata
    information from the PE Header(Strings are hashed and calculate a histogram of
    these hashes by counting the occurrences of each value); for assembly features,
    the disassembled code generated by Radare2 can be parsed and transformed into
    graph-like data structures such as call graphs, control flow graph, and instruction
    flow graph. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|  |  | Windows 数据集来自 Reversing Labs，包括 XP、7、8 和 10 的 32 位和 64 位架构，并在十二年（2006-2018）的时间跨度内收集。数据集中选择了九个恶意软件家族，并提取了静态特征，包括字节、基本特征和汇编特征。
    | 对于字节级特征，他们使用滑动窗口获取字节的直方图，并计算窗口中的相关熵；对于基本特征，他们根据 ASCII 字符串列表创建了固定大小的特征向量，或者从
    PE 头中提取了导入和元数据（字符串被哈希并计算这些哈希的直方图，统计每个值的出现次数）；对于汇编特征，Radare2 生成的反汇编代码可以解析并转化为类似图的数据结构，如调用图、控制流图和指令流图。
    |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | N/A |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 不适用 |'
- en: '&#124; ACC: &#124; 90.1% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 90.1% &#124;  &#124; 精确率: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; N/A &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 召回率: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 不适用 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假阳性率: &#124; 不适用 &#124;  &#124; 假阴性率: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| System Event Based Anomaly Detection  [[8](#bib.bib8), [41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)] | DeepLog[[8](#bib.bib8)]
    | Phase I | Phase II |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 基于系统事件的异常检测 [[8](#bib.bib8), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44), [45](#bib.bib45)] | DeepLog[[8](#bib.bib8)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | More than 24 million raw log entries with the size of 2412 MB are recorded
    from the 203-node HDFS. Over 11 million log entries with 29 types are parsed,
    which are further grouped to 575,061 sessions according to block identifier. These
    sessions are manually labeled as normal and abnormal by HDFS experts. Finally,
    the constructed dataset HDFS 575,061 sessions of logs in the dataset, among which
    16,838 sessions were labeled as anomalous | The raw log entries are parsed to
    different log type using Spell[[46](#bib.bib46)] which is based a longest common
    subsequence. There are total 29 log types in HDFS dataset |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 从 203 节点 HDFS 中记录了超过 2400 万条原始日志条目，总大小为 2412 MB。解析了超过 1100 万条包含 29
    种类型的日志条目，这些条目根据块标识符进一步分组为 575,061 个会话。这些会话由 HDFS 专家手动标记为正常和异常。最终构建的数据集包括 575,061
    个 HDFS 会话日志，其中 16,838 个会话被标记为异常 | 原始日志条目使用基于最长公共子序列的 Spell[[46](#bib.bib46)] 解析为不同的日志类型。HDFS
    数据集中共有 29 种日志类型 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | DeepLog directly utilized one-hot vector to represent 29 log key without
    represent learning | A stacked LSTM with two hidden LSTM layers. |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  |  | DeepLog 直接利用 one-hot 向量表示 29 个日志关键字，而不进行表示学习 | 一个具有两个隐藏 LSTM 层的堆叠 LSTM。
    |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.95 &#124;'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.95 &#124;'
- en: '&#124; REC: &#124; 0.96 &#124;  &#124; $F_{1}$: &#124; 0.96 &#124;'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 0.96 &#124;  &#124; $F_{1}$: &#124; 0.96 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
- en: '|'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | LogAnom [[41](#bib.bib41)] | Phase I | Phase II |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '|  | LogAnom [[41](#bib.bib41)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | LogAnom also used HDFS dataset, which is same as DeepLog. | The raw
    log entries are parsed to different log templates using FT-Tree [[47](#bib.bib47)]
    according the frequent combinations of log words. There are total 29 log templates
    in HDFS dataset |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '|  |  | LogAnom 也使用了与 DeepLog 相同的 HDFS 数据集。 | 原始日志条目使用 FT-Tree [[47](#bib.bib47)]
    解析为不同的日志模板，依据是日志词的频繁组合。HDFS 数据集中共有 29 种日志模板 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | LogAnom employed Word2Vec to represent the extracted log templates
    with more semantic information | Two LSTM layers with 128 neurons |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '|  |  | LogAnom 使用 Word2Vec 表示提取的日志模板，增加了更多语义信息 | 两个具有 128 个神经元的 LSTM 层 |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.97 &#124;'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.97 &#124;'
- en: '&#124; REC: &#124; 0.94 &#124;  &#124; $F_{1}$: &#124; 0.96 &#124;'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 0.94 &#124;  &#124; $F_{1}$: &#124; 0.96 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
- en: '|'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Memory Forensics [[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)]
    | DeepMem[[19](#bib.bib19)] | Phase I | Phase II |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 内存取证 [[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)]
    | DeepMem[[19](#bib.bib19)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | 400 memory dumps are collected on Windows 7 x86 SP1 virtual machine
    with simulating various random user actions and forcing the OS to randomly allocate
    objects. The size of each dump is 1GB. | Construct memory graph from memory dumps,
    where each node represents a segment between two pointers and an edge is created
    if two nodes are neighbor |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 在 Windows 7 x86 SP1 虚拟机上收集了 400 个内存转储，通过模拟各种随机用户操作并强制操作系统随机分配对象。每个转储的大小为
    1GB。 | 从内存转储中构建内存图，其中每个节点表示两个指针之间的一个段，如果两个节点是邻居，则创建一条边 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | Each node is represented by a latent numeric vector from the embedding
    network. | Fully Connected Network (FCN) with ReLU layer. |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 每个节点由来自嵌入网络的潜在数值向量表示。 | 带有 ReLU 层的全连接网络 (FCN)。 |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.99 &#124;'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; 0.99 &#124;'
- en: '&#124; REC: &#124; 0.99 &#124;  &#124; $F_{1}$: &#124; 0.99 &#124;'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; REC: &#124; 0.99 &#124;  &#124; $F_{1}$: &#124; 0.99 &#124;'
- en: '&#124; FPR: &#124; 0.01 &#124;  &#124; FNR: &#124; 0.01 &#124;'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPR: &#124; 0.01 &#124;  &#124; FNR: &#124; 0.01 &#124;'
- en: '|'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | MDMF [[48](#bib.bib48)] | Phase I | Phase II |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | MDMF [[48](#bib.bib48)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | Create a dataset of benign host memory snapshots running normal, non-compromised
    software, including software that executes in many of the malicious snapshots.
    The benign snapshot is extracted from memory after ample time has passed for the
    chosen programs to open. By generating samples in parallel to the separate malicious
    environment, the benign memory snapshot dataset created. | Various representation
    for the memory snapshots including byte sequence and image, without relying on
    domain-knowledge of the OS. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 创建一个正常、未受损软件运行的良性主机内存快照数据集，包括在许多恶意快照中执行的软件。良性快照在选择的程序打开后经过足够时间从内存中提取。通过在独立的恶意环境中并行生成样本，创建了良性内存快照数据集。
    | 以各种方式表示内存快照，包括字节序列和图像，而不依赖于操作系统的领域知识。 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | Recurrent Neural Network with LSTM cells and Convolutional Neural
    Network composed of multiple layers, including pooling and fully connected layers.
    for image data |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 由多个层（包括池化层和全连接层）组成的 LSTM 单元的递归神经网络和卷积神经网络，用于图像数据 |'
- en: '&#124; ACC: &#124; 98.0% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 98.0% &#124;  &#124; 精确率: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; N/A &#124;'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 记录: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 不适用 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假正率: &#124; 不适用 &#124;  &#124; 假负率: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Fuzzing [[51](#bib.bib51), [20](#bib.bib20), [52](#bib.bib52), [21](#bib.bib21),
    [53](#bib.bib53)] | L-Fuzz[[21](#bib.bib21)] | Phase I | Phase II |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 模糊测试 [[51](#bib.bib51), [20](#bib.bib20), [52](#bib.bib52), [21](#bib.bib21),
    [53](#bib.bib53)] | L-Fuzz[[21](#bib.bib21)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | The raw data are about 63,000 non-binary PDF objects, sliced in fix
    size, extracted from 534 PDF files that are provided by Windows fuzzing team and
    are previously used for prior extended fuzzing of Edge PDF parser. | N/A |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 原始数据包括约 63,000 个非二进制 PDF 对象，按固定大小切割，提取自 534 个由 Windows 模糊测试团队提供的 PDF
    文件，这些文件先前用于 Edge PDF 解析器的扩展模糊测试。 | 不适用 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | Char-RNN |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | Char-RNN |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 不适用% &#124;  &#124; 精确率: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 记录: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假正率: &#124; 不适用 &#124;  &#124; 假负率: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '|  | NEUZZ[[20](#bib.bib20)] | Phase I | Phase II |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | NEUZZ[[20](#bib.bib20)] | 第一阶段 | 第二阶段 |'
- en: '|  |  | For each program tested, the raw data is collected by running AFL-2.52b
    on a single core machine for one hour. The training data are byte level input
    files generated by AFL, and the labels are bitmaps corresponding to input files.
    For experiments, NEUZZ is implemented on 10 real-world programs, the LAVA-M bug
    dataset, and the CGC dataset. | N/A |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 对每个测试的程序，原始数据是通过在单核机器上运行 AFL-2.52b 一小时收集的。训练数据是由 AFL 生成的字节级输入文件，标签是对应于输入文件的位图。在实验中，NEUZZ
    在 10 个真实世界程序、LAVA-M 错误数据集和 CGC 数据集上实现。 | 不适用 |'
- en: '|  |  | Phase III | Phase IV | Evaluation |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 第三阶段 | 第四阶段 | 评估 |'
- en: '|  |  | N/A | NN |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 不适用 | 神经网络 |'
- en: '&#124; ACC: &#124; N/A% &#124;  &#124; PRE: &#124; N/A &#124;'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 准确率: &#124; 不适用% &#124;  &#124; 精确率: &#124; 不适用 &#124;'
- en: '&#124; REC: &#124; N/A &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 记录: &#124; 不适用 &#124;  &#124; $F_{1}$: &#124; 0.93 &#124;'
- en: '&#124; FPR: &#124; N/A &#124;  &#124; FNR: &#124; N/A &#124;'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 假正率: &#124; 不适用 &#124;  &#124; 假负率: &#124; 不适用 &#124;'
- en: '|'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| \insertTableNotes |  |  |  |  |  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| \insertTableNotes |  |  |  |  |  |'
- en: '{TableNotes}'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '{TableNotes}'
- en: 'Deep Learning metrics are often not available in fuzzing papers. Typical fuzzing
    metrics used for evaluations are: code coverage, pass rate and bugs.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习指标在模糊测试论文中通常不可用。用于评估的典型模糊测试指标包括：代码覆盖率、通过率和缺陷。
- en: 2.3 Methodology for reviewing the existing works
  id: totrans-207
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 现有工作的评审方法
- en: Data representation (or feature engineering) plays an important role in solving
    security problems with Deep Learning. This is because data representation is a
    way to take advantage of human ingenuity and prior knowledge to extract and organize
    the discriminative information from the data. Many efforts in deploying machine
    learning algorithms in security domain actually goes into the design of preprocessing
    pipelines and data transformations that result in a representation of the data
    to support effective machine learning.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 数据表示（或特征工程）在解决深度学习中的安全问题中扮演着重要角色。这是因为数据表示是一种利用人类智慧和先验知识来提取和组织数据中区分性信息的方式。许多在安全领域部署机器学习算法的努力实际上都集中在预处理管道和数据转换的设计上，这些设计能够提供有效的机器学习数据表示。
- en: 'In order to expand the scope and ease of applicability of machine learning
    in security domain, it would be highly desirable to find a proper way to represent
    the data in security domain, which can entangle and hide more or less the different
    explanatory factors of variation behind the data. To let this survey adequately
    reflect the important role played by data representation, our review will focus
    on how the following three questions are answered by the existing works:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 为了扩展机器学习在安全领域的适用范围和便利性，找到一种合适的数据表示方法是非常理想的，这种方法可以或多或少地纠缠和隐藏数据背后的不同解释因素。为了使本调查充分反映数据表示的重要作用，我们的综述将重点关注现有工作如何回答以下三个问题：
- en: •
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Question 1: Is Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") pervasively
    done in the literature? When Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is skipped in a work, are there any particular reasons?'
  id: totrans-211
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题1：文献中是否广泛地进行了阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文作者按字母顺序列出。")？当在某项工作中跳过阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义
    ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文作者按字母顺序列出。")时，有没有特别的原因？
- en: •
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Question 2: Is Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") employed
    in the literature? When Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is skipped in a work, are there any particular reasons?'
  id: totrans-213
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题2：文献中是否采用了阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注
    11脚注 1本文作者按字母顺序列出。")？当在某项工作中跳过阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文作者按字母顺序列出。")时，有没有特别的原因？
- en: •
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Question 3: When solving different security problems, is there any commonality
    in terms of the (types of) classifiers learned in Phase[1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")? Among the works solving the same security problem,
    is there dissimilarity in terms of classifiers learned in Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.")?'
  id: totrans-215
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 问题 3：在解决不同的安全问题时，第一阶段学习的（类型的）分类器是否存在共性？在解决相同安全问题的工作中，第一阶段学习的分类器是否存在差异？
- en: '<svg   height="79.84" overflow="visible" version="1.1" width="361.7"><g transform="translate(0,79.84)
    matrix(1 0 0 -1 0 0) translate(0,30.02)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1.0 0.0 0.0 1.0 3.51 -6.24)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 6.255)"><g transform="matrix(1 0 0 1 0 9.36)"><g
    transform="matrix(1 0 0 -1 0 0)"><foreignobject width="45.9" height="12.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 138.75
    -24.02)" fill="#000000" stroke="#000000"><g  transform="matrix(1 0 0 -1 0 4.345)"><g  transform="matrix(1
    0 0 1 0 8.67)"><g transform="matrix(1 0 0 -1 0 0)"><foreignobject width="35.42"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">class 1</foreignobject></g></g></g></g><g
    transform="matrix(0.9824 -0.1868 0.1868 0.9824 52.97 -11.4)" fill="#000000" stroke="#000000"><foreignobject
    width="79.42" height="7.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">no
    consideration</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 322.78 -24.02)"
    fill="#000000" stroke="#000000"><g  transform="matrix(1 0 0 -1 0 4.345)"><g  transform="matrix(1
    0 0 1 0 8.67)"><g transform="matrix(1 0 0 -1 0 0)"><foreignobject width="35.42"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">class 4</foreignobject></g></g></g></g><g
    transform="matrix(0.9824 -0.1868 0.1868 0.9824 248.73 -15.55)" fill="#000000"
    stroke="#000000"><g transform="matrix(1 0 0 -1 0 4.795)" color="#000000"><g transform="matrix(1
    0 0 1 0 7.41)"><g transform="matrix(1 0 0 -1 0 0)"><foreignobject width="54.83"
    height="9.55" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">comparison</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 322.78 15.35)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.345)"><g transform="matrix(1 0 0 1 0 8.67)"><g
    transform="matrix(1 0 0 -1 0 0)"><foreignobject width="35.42" height="8.65" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">class 3</foreignobject></g></g></g></g><g transform="matrix(0.9824
    0.1868 -0.1868 0.9824 242.97 4.71)" fill="#000000" stroke="#000000"><g transform="matrix(1
    0 0 -1 0 4.795)" color="#000000"><g transform="matrix(1 0 0 1 0 7.41)"><g transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="70.2" height="9.55" transform="matrix(1 0 0
    -1 0 16.6)" overflow="visible">no comparison</foreignobject></g></g></g></g><g
    transform="matrix(0.97543 -0.22028 0.22028 0.97543 162.99 4.13)" fill="#000000"
    stroke="#000000"><foreignobject width="42.43" height="9.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">adoption</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 230.76 35.03)" fill="#000000" stroke="#000000"><g transform="matrix(1
    0 0 -1 0 4.345)"><g  transform="matrix(1 0 0 1 0 8.67)"><g  transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="35.42" height="8.65" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">class 2</foreignobject></g></g></g></g><g transform="matrix(0.9824
    0.1868 -0.1868 0.9824 157.04 25.56)" fill="#000000" stroke="#000000"><g transform="matrix(1
    0 0 -1 0 4.94)" color="#000000"><g transform="matrix(1 0 0 1 0 7.71)"><g transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="57.81" height="9.84" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">no adoption</foreignobject></g></g></g></g><g
    transform="matrix(0.97543 0.22028 -0.22028 0.97543 62.12 5.67)" fill="#000000"
    stroke="#000000"><foreignobject width="64.05" height="7.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">consideration</foreignobject></g></g></svg>'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 这段文本包含了 SVG 图形和嵌入的文字，是否需要对具体的图形部分进行详细解释，还是只关注文本翻译？
- en: 'To group the Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") methods
    at different applications of Deep Learning in solving the same security problem,
    we introduce a classification tree as shown in FigureLABEL:fig:dec. The classification
    tree categorizes the Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") methods in our selected survey works into four classes. First, class
    1 includes the Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") methods
    which do not consider representation learning. Second, class 2 includes the Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") methods which consider representation
    learning but, do not adopt it. Third, class 3 includes the Phase[1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") methods which consider and adopt representation
    learning but, do not compare the performance with other methods. Finally, class
    4 includes the Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") methods
    which consider and adopt representation learning and, compare the performance
    with other methods.'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '为了将不同应用场景中解决相同安全问题的Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法进行归类，我们引入了如图LABEL:fig:dec所示的分类树。该分类树将我们选择的调查研究中的Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.")方法分为四类。首先，类别1包括那些不考虑表示学习的Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法。其次，类别2包括那些考虑表示学习但不采用它的Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法。第三，类别3包括那些考虑并采用表示学习但未与其他方法进行性能比较的Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法。最后，类别4包括那些考虑并采用表示学习且与其他方法进行性能比较的Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法。'
- en: In the remaining of this paper, we take a closer look at how each of the eight
    security problems is being solved by applications of Deep Learning in the literature.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文的其余部分，我们将深入探讨文献中如何通过应用深度学习来解决八个安全问题。
- en: 3 A closer look at applications of Deep Learning in solving security-oriented
    program analysis challenges
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 深入探讨深度学习在解决面向安全的程序分析挑战中的应用
- en: 3.1 Introduction
  id: totrans-220
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 介绍
- en: Recent years, security-oriented program analysis is widely used in software
    security. For example, symbolic execution and taint analysis are used to discover,
    detect and analyze vulnerabilities in programs. Control flow analysis, data flow
    analysis and pointer/alias analysis are important components when enforcing many
    secure strategies, such as control flow integrity, data flow integrity and doling
    dangling pointer elimination. Reverse engineering was used by defenders and attackers
    to understand the logic of a program without source code.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，面向安全的程序分析在软件安全中被广泛应用。例如，符号执行和污点分析被用来发现、检测和分析程序中的漏洞。控制流分析、数据流分析以及指针/别名分析是实施许多安全策略的重要组成部分，如控制流完整性、数据流完整性和悬空指针消除。逆向工程被防御者和攻击者用来在没有源代码的情况下理解程序的逻辑。
- en: In the security-oriented program analysis, there are many open problems, such
    as precise pointer/alias analysis, accurate and complete reversing engineer, complex
    constraint solving, program de-obfuscation, and so on. Some problems have theoretically
    proven to be NP-hard, and others still need lots of human effort to solve. Either
    of them needs a lot of domain knowledge and experience from expert to develop
    better solutions. Essentially speaking, the main challenges when solving them
    through traditional approaches are due to the sophisticated rules between the
    features and labels, which may change in different contexts. Therefore, on the
    one hand, it will take a large quantity of human effort to develop rules to solve
    the problems, on the other hand, even the most experienced expert cannot guarantee
    completeness. Fortunately, the deep learning method is skillful to find relations
    between features and labels if given a large amount of training data. It can quickly
    and comprehensively find all the relations if the training samples are representative
    and effectively encoded.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 在面向安全的程序分析中，存在许多开放性问题，例如精确的指针/别名分析、准确完整的逆向工程、复杂约束求解、程序去混淆等。一些问题已经理论证明是NP难的，而其他问题仍然需要大量的人工努力来解决。无论是哪一种，都需要大量的领域知识和专家经验来开发更好的解决方案。
    从本质上讲，通过传统方法解决这些问题的主要挑战在于特征与标签之间复杂的规则，这些规则在不同的上下文中可能会变化。因此，一方面，需要大量的人工努力来制定规则以解决这些问题；另一方面，即使是最有经验的专家也无法保证解决方案的完整性。幸运的是，深度学习方法擅长在给定大量训练数据的情况下发现特征与标签之间的关系。如果训练样本具有代表性且有效编码，它可以快速而全面地发现所有关系。
- en: In this section, we will review the very recent four representative works that
    use Deep Learning for security-oriented program analysis. We observed that they
    focused on different goals. Shin, et al. designed a model [[9](#bib.bib9)] to
    identify the function boundary. EKLAVYA[[10](#bib.bib10)] was developed to learn
    the function type. Gemini[[23](#bib.bib23)] was proposed to detect similarity
    among functions. DEEPVSA[[22](#bib.bib22)] was designed to learn memory region
    of an indirect addressing from the code sequence. Among these works, we select
    two representative works[[9](#bib.bib9), [10](#bib.bib10)] and then, summarize
    the analysis results in TableLABEL:Table:Summary in detail.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾四项最新的代表性工作，这些工作使用深度学习进行面向安全的程序分析。我们观察到它们关注的目标各不相同。Shin等人设计了一个模型[[9](#bib.bib9)]以识别函数边界。EKLAVYA[[10](#bib.bib10)]被开发用来学习函数类型。Gemini[[23](#bib.bib23)]被提出用来检测函数之间的相似性。DEEPVSA[[22](#bib.bib22)]被设计用来从代码序列中学习间接寻址的内存区域。在这些工作中，我们选择了两个代表性的工作[[9](#bib.bib9),
    [10](#bib.bib10)]，然后在表LABEL:Table:Summary中详细总结了分析结果。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的综述将围绕第LABEL:threequestions节中描述的三个问题展开。在本节的其余部分，我们将首先提供一系列观察结果，然后提供相关指示。最后，我们提供一些一般性的评论。
- en: 3.2 Key findings from a closer look
  id: totrans-225
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 细致观察的关键发现
- en: 'From a close look at the very recent applications using Deep Learning for solving
    security-oriented program analysis challenges, we observed the followings:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对最近应用深度学习解决面向安全的程序分析挑战的工作进行详细观察，我们发现以下几点：
- en: Observation 3.1:   All of the works in our survey used binary files as their
    raw data.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察3.1：我们调查中的所有研究都使用了二进制文件作为原始数据。
- en: 'Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") in our survey had
    one similar and straightforward goal – extracting code sequences from the binary.
    Difference among them was that the code sequence was extracted directly from the
    binary file when solving problems in static program analysis, while it was extracted
    from the program execution when solving problems in dynamic program analysis.'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在我们的调查中，Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")有一个相似而直接的目标，即从二进制文件中提取代码序列。它们之间的区别在于，在静态程序分析中解决问题时，代码序列是直接从二进制文件中提取的，而在动态程序分析中解决问题时，代码序列是从程序执行中提取的。'
- en: ^∗Observation 3.2:   Most data representation methods generally took into account
    the domain knowledge.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^∗观察3.2：大多数数据表示方法通常考虑了领域知识。
- en: 'Most data representation methods generally took into the domain knowledge,
    i.e., what kind of information they wanted to reserve when processing their data.
    Note that the feature selection has a wide influence on Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") and Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), for example, embedding granularities, representation learning methods.
    Gemini [[23](#bib.bib23)] selected function level feature and other works in our
    survey selected instruction level feature. To be specifically, all the works except
    Gemini[[23](#bib.bib23)] vectorized code sequence on instruction level.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '大多数数据表示方法通常考虑了领域知识，即在处理数据时要保留哪种信息。请注意，特征选择对Phase[1](#S2.F1 "Figure 1 ‣ 2.1
    Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")和Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")产生广泛影响，例如，嵌入粒度和表示学习方法。Gemini[[23](#bib.bib23)]选择了函数级别的特征，而我们调查中的其他工作选择了指令级别的特征。具体来说，除了Gemini[[23](#bib.bib23)]，所有的工作都在指令级别上对代码序列进行了向量化。'
- en: Observation 3.3:   To better support data representation for high performance,
    some works adopted representation learning.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察3.3：为了更好地支持高性能的数据表示，一些工作采用了表示学习方法。
- en: 'For instance, DEEPVSA [[22](#bib.bib22)] employed a representation learning
    method, i.e., bi-directional LSTM, to learn data dependency within instructions.
    EKLAVYA[[10](#bib.bib10)] adopted representation learning method, i.e., word2vec
    technique, to extract inter-instruciton information. It is worth noting that Gemini[[23](#bib.bib23)]
    adopts the Structure2vec embedding network in its siamese architecture in Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") (see details in Observation 3.LABEL:obs:bi).
    The Structure2vec embedding network learned information from an attributed control
    flow graph.'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '例如，DEEPVSA[[22](#bib.bib22)]采用了一种表示学习方法，即双向LSTM，来学习指令内部的数据依赖关系。EKLAVYA[[10](#bib.bib10)]采用了一种表示学习方法，即word2vec技术，来提取指令间的信息。值得注意的是，Gemini[[23](#bib.bib23)]在其孪生结构的Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")中采用了Structure2vec嵌入网络（详见Observation 3.LABEL：obs:bi）。Structure2vec嵌入网络从带属性的控制流图中学习信息。'
- en: Observation 3.4:   According to our taxonomy, most works in our survey were
    classified into class 4.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察3.4：根据我们的分类法，我们调查中的大部分工作被归类为第4类。
- en: 'To compare the Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order."), we introduced
    a classification tree with three layers as shown in Figure LABEL:fig:dec to group
    different works into four categories. The decision tree grouped our surveyed works
    into four classes according to whether they considered representation learning
    or not, whether they adopted representation learning or not, and whether they
    compared their methods with others’, respectively, when designing their framework.
    According to our taxonomy, EKLAVYA[[10](#bib.bib10)], DEEPVSA [[22](#bib.bib22)]
    were grouped into class 4 shown in FigureLABEL:fig:dec. Also, Gemini’s work [[23](#bib.bib23)]
    and Shin, et al.’s work[[9](#bib.bib9)] belonged to class 1 and class 2 shown
    in FigureLABEL:fig:dec, respectively.'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了比较阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ 使用深度学习解决计算机安全挑战：一项调查1footnote
    11footnote 1本文作者按字母顺序列出。")，我们引入了一个三层的分类树，如图 LABEL:fig:dec 所示，将不同的工作分为四类。决策树根据设计框架时是否考虑了表示学习、是否采用了表示学习以及是否将他们的方法与其他方法进行了比较，将我们调查的工作分为四类。根据我们的分类法，EKLAVYA[[10](#bib.bib10)]，DEEPVSA
    [[22](#bib.bib22)] 被归入图 LABEL:fig:dec 中的第 4 类。此外，Gemini 的工作 [[23](#bib.bib23)]
    和 Shin 等人的工作 [[9](#bib.bib9)] 分别属于图 LABEL:fig:dec 中的第 1 类和第 2 类。
- en: Observation 3.5:   All the works in our survey explain why they adopted or did
    not adopt one of representation learning algorithms.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 3.5：我们调查中的所有工作都解释了他们为什么选择或不选择某种表示学习算法。
- en: 'Two works in our survey adopted representation learning for different reasons:
    to enhance model’s ability of generalization [[10](#bib.bib10)]; and to learn
    the dependency within instructions [[22](#bib.bib22)]. It is worth noting that
    Shin, et al. did not adopt representation learning because they wanted to preserve
    the “attractive” features of neural networks over other machine learning methods – simplicity.
    As they stated, “first, neural networks can learn directly from the original representation
    with minimal preprocessing (or “feature engineering”) needed.” and “second, neural
    networks can learn end-to-end, where each of its constituent stages are trained
    simultaneously in order to best solve the end goal.” Although Gemini [[23](#bib.bib23)]
    did not adopt representation learning when processing their raw data, the Deep
    Learning models in siamese structure consisted of two graph embedding networks
    and one cosine function.'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们调查中的两个工作采用了表示学习但理由不同：一个是为了提升模型的泛化能力 [[10](#bib.bib10)]; 另一个是为了学习指令中的依赖关系 [[22](#bib.bib22)]。值得注意的是，Shin
    等人没有采用表示学习，因为他们希望保留神经网络相对于其他机器学习方法的“吸引力”特征——简单性。正如他们所说，“首先，神经网络可以直接从原始表示中学习，所需的预处理（或‘特征工程’）最少。”以及“其次，神经网络可以端到端地学习，其中每个组成阶段同时训练，以最佳地解决最终目标。”虽然
    Gemini [[23](#bib.bib23)] 在处理原始数据时没有采用表示学习，但在 siamese 结构中的深度学习模型包含两个图嵌入网络和一个余弦函数。
- en: ^∗Observation 3.6:   The analysis results showed that a suitable representation
    learning method could improve accuracy of Deep Learning models.
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^∗观察 3.6：分析结果显示，合适的表示学习方法可以提高深度学习模型的准确性。
- en: DEEPVSA [[22](#bib.bib22)] designed a series of experiments to evaluate the
    effectiveness of its representative method. By combining with the domain knowledge,
    EKLAVYA[[10](#bib.bib10)] employed t-SNE plots and analogical reasoning to explain
    the effectiveness of their representation learning method in an intuitive way.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DEEPVSA [[22](#bib.bib22)] 设计了一系列实验来评估其代表性方法的有效性。通过结合领域知识，EKLAVYA [[10](#bib.bib10)]
    使用 t-SNE 图和类比推理以直观的方式解释了他们的表示学习方法的有效性。
- en: ^∗Observation 3.7:   Various Phase IV methods were used.
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^∗观察 3.7：使用了各种阶段 IV 方法。
- en: 'In Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order."), Gemini [[23](#bib.bib23)]
    adopted siamese architecture model which consisted of two Structure2vec embedding
    networks and one cosine function. The siamese architecture took two functions
    as its input, and produced the similarity score as the output. The other three
    works[[9](#bib.bib9), [10](#bib.bib10), [22](#bib.bib22)] adopted bi-directional
    RNN, RNN, bi-directional LSTM respectively. Shin, et al. adopted bi-directional
    RNN because they wanted to combine both the past and the future information in
    making a prediction for the present instruction[[9](#bib.bib9)]. DEEPVSA [[22](#bib.bib22)]
    adopted bi-directional RNN to enable their model to infer memory regions in both
    forward and backward ways.'
  id: totrans-240
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '在阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.")中，Gemini [[23](#bib.bib23)]
    采用了由两个Structure2vec嵌入网络和一个余弦函数组成的孪生网络模型。孪生网络接受两个函数作为输入，产生相似性得分作为输出。其他三个工作[[9](#bib.bib9),
    [10](#bib.bib10), [22](#bib.bib22)] 分别采用了双向RNN、RNN和双向LSTM。Shin等人采用双向RNN，因为他们希望结合过去和未来的信息，以预测当前指令[[9](#bib.bib9)]。DEEPVSA [[22](#bib.bib22)]
    采用双向RNN以使其模型能够在前向和后向方式中推断记忆区域。'
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎表明了以下指示：
- en: 'Indication 3.1:   Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is not always necessary.'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 3.1:   阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") 并非总是必要的。'
- en: Not all authors regard representation learning as a good choice even though
    some case experiments show that representation learning can improve the final
    results. They value more the simplicity of Deep Learning methods and suppose that
    the adoption of representation learning weakens the simplicity of Deep Learning
    methods.
  id: totrans-243
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 即便一些案例实验表明表示学习可以改善最终结果，并不是所有作者都将表示学习视为良好的选择。他们更看重深度学习方法的简单性，并认为采用表示学习会削弱深度学习方法的简单性。
- en: 'Indication 3.2:   Even though the ultimate objective of Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") in the four surveyed works is to train
    a model with better accuracy, they have different specific motivations as described
    in Observation 3.LABEL:obs:reason.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 3.2:   尽管在四项调查工作的阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") 的最终目标是训练一个具有更高准确度的模型，但它们有不同的具体动机，如观察 3.LABEL:obs:reason 所述。'
- en: When authors choose representation learning, they usually try to convince people
    the effectiveness of their choice by empirical or theoretical analysis.
  id: totrans-245
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 当作者选择表示学习时，他们通常通过实证或理论分析来试图说服人们他们选择的有效性。
- en: ^∗Indication 3.3:   3.LABEL:obs:bi indicates that authors usually refer to the
    domain knowledge when designing the architecture of Deep Learning model.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^∗指示 3.3:   3.LABEL:obs:bi 表示作者在设计深度学习模型架构时通常会参考领域知识。
- en: For instance, the works we reviewed commonly adopt bi-directional RNN when their
    prediction partly based on future information in data sequence.
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 例如，我们审阅的工作通常在其预测部分基于数据序列中的未来信息时采用双向RNN。
- en: 3.3 Discussion
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 讨论
- en: 'Despite the effectiveness and agility of deep learning-based methods, there
    are still some challenges in developing a scheme with high accuracy due to the
    hierarchical data structure, lots of noisy, and unbalanced data composition in
    program analysis. For instance, an instruction sequence, a typical data sample
    in program analysis, contains three-level hierarchy: sequence–instruction–opcode/operand.
    To make things worse, each level may contain many different structures, e.g.,
    one-operand instructions, multi-operand instructions, which makes it harder to
    encode the training data.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于深度学习的方法有效且灵活，但由于程序分析中的分层数据结构、大量噪声和不平衡的数据组成，开发高准确度的方案仍然面临一些挑战。例如，指令序列——程序分析中的典型数据样本——包含三级层次结构：序列–指令–操作码/操作数。更糟糕的是，每一层可能包含许多不同的结构，例如，单操作数指令、多操作数指令，这使得对训练数据进行编码变得更加困难。
- en: 4 A closer look at applications of Deep Learning in defending ROP attacks
  id: totrans-250
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 更深入地了解深度学习在防御 ROP 攻击中的应用
- en: 4.1 Introduction
  id: totrans-251
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 介绍
- en: Return-oriented programming (ROP) attack is one of the most dangerous code reuse
    attacks, which allows the attackers to launch control-flow hijacking attack without
    injecting any malicious code. Rather, It leverages particular instruction sequences
    (called “gadgets”) widely existing in the program space to achieve Turing-complete
    attacks [[54](#bib.bib54)]. Gadgets are instruction sequences that end with a
    RET instruction. Therefore, they can be chained together by specifying the return
    addresses on program stack. Many traditional techniques could be used to detect
    ROP attacks, such as control-flow integrity (CFI[[55](#bib.bib55)]), but many
    of them either have low detection rate or have high runtime overhead. ROP payloads
    do not contain any codes. In other words, analyzing ROP payload without the context
    of the program’s memory dump is meaningless. Thus, the most popular way of detecting
    and preventing ROP attacks is control-flow integrity. The challenge after acquiring
    the instruction sequences is that it is hard to recognize whether the control
    flow is normal. Traditional methods use the control flow graph (CFG) to identify
    whether the control flow is normal, but attackers can design the instruction sequences
    which follow the normal control flow defined by the CFG. In essence, it is very
    hard to design a CFG to exclude every single possible combination of instructions
    that can be used to launch ROP attacks. Therefore, using data-driven methods could
    help eliminate such problems.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 返回导向编程（ROP）攻击是最危险的代码重用攻击之一，它允许攻击者在不注入任何恶意代码的情况下发起控制流劫持攻击。相反，它利用程序空间中广泛存在的特定指令序列（称为“gadget”）来实现图灵完备的攻击
    [[54](#bib.bib54)]。Gadgets 是以 RET 指令结尾的指令序列。因此，它们可以通过指定程序栈上的返回地址链在一起。许多传统技术可以用来检测
    ROP 攻击，例如控制流完整性（CFI [[55](#bib.bib55)]），但许多技术要么检测率低，要么运行时开销高。ROP 有效载荷不包含任何代码。换句话说，分析
    ROP 有效载荷而不考虑程序内存转储的上下文是没有意义的。因此，检测和防止 ROP 攻击的最流行方法是控制流完整性。获取指令序列后的挑战是很难识别控制流是否正常。传统方法使用控制流图（CFG）来确定控制流是否正常，但攻击者可以设计遵循
    CFG 定义的正常控制流的指令序列。从本质上讲，很难设计一个 CFG 来排除所有可能用于发起 ROP 攻击的指令组合。因此，使用数据驱动的方法可以帮助消除这些问题。
- en: 'In this section, we will review the very recent three representative works
    that use Deep Learning for defending ROP attacks: ROPNN [[11](#bib.bib11)], HeNet
    [[12](#bib.bib12)] and DeepCheck [[25](#bib.bib25)]. ROPNN [[11](#bib.bib11)]
    aims to detect ROP attacks, HeNet [[12](#bib.bib12)] aims to detect malware using
    CFI, and DeepCheck [[25](#bib.bib25)] aims at detecting all kinds of code reuse
    attacks.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾三项最近的代表性工作，这些工作使用深度学习来防御 ROP 攻击：ROPNN [[11](#bib.bib11)]、HeNet [[12](#bib.bib12)]
    和 DeepCheck [[25](#bib.bib25)]。ROPNN [[11](#bib.bib11)] 旨在检测 ROP 攻击，HeNet [[12](#bib.bib12)]
    旨在使用 CFI 检测恶意软件，而 DeepCheck [[25](#bib.bib25)] 旨在检测各种代码重用攻击。
- en: Specifically, ROPNN is to protect one single program at a time, and its training
    data are generated from real-world programs along with their execution. Firstly,
    it generates its benign and malicious data by “chaining-up” the normally executed
    instruction sequences and “chaining-up” gadgets with the help of gadgets generation
    tool, respectively, after the memory dumps of programs are created. Each data
    sample is byte-level instruction sequence labeled as “benign” or “malicious”.
    Secondly, ROPNN will be trained using both malicious and benign data. Thirdly,
    the trained model is deployed to a target machine. After the protected program
    started, the executed instruction sequences will be traced and fed into the trained
    model, the protected program will be terminated once the model found the instruction
    sequences are likely to be malicious.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，ROPnn是一次保护一个单独的程序，其训练数据来自现实世界程序及其执行。首先，它通过“链式连接”正常执行的指令序列和使用工具生成的gadget的“链式连接”来生成其良性和恶意数据，分别在程序的内存转储创建后。每个数据样本是以字节级指令序列标记为“良性”或“恶意”。其次，ROPnn将使用恶意数据和良性数据进行训练。第三，训练好的模型被部署到目标机器上。在受保护的程序启动后，执行的指令序列将被跟踪并输入到训练好的模型中，一旦模型发现指令序列可能是恶意的，受保护的程序将被终止。
- en: HeNet is also proposed to protect a single program. Its malicious data and benign
    data are generated by collecting trace data through Intel PT from malware and
    normal software, respectively. Besides, HeNet preprocesses its dataset and shape
    each data sample in the format of image, so that they could implement transfer
    learning from a model pre-trained on ImageNet. Then, HeNet is trained and deployed
    on machines with features of Intel PT to collect and classify the program’s execution
    trace online.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: HeNet也是为了保护单个程序而提出的。它的恶意数据和良性数据分别通过从恶意软件和正常软件中通过Intel PT收集跟踪数据来生成。此外，HeNet预处理其数据集并将每个数据样本的格式调整为图像，以便能够从在ImageNet上预训练的模型中实现迁移学习。然后，HeNet在具有Intel
    PT特性的机器上进行训练和部署，以在线收集和分类程序的执行跟踪。
- en: The training data for DeepCheck are acquired from CFGs, which are constructed
    by dissembling the programs and using the information from Intel PT. After the
    CFG for a protected program is constructed, authors sample benign instruction
    sequences by chaining up basic blocks that are connected by edges, and sample
    malicious instruction sequences by chaining up those that are not connected by
    edges. Although a CFG is needed during training, there is no need to construct
    CFG after the training phase. After deployed, instruction sequences will be constructed
    by leveraging Intel PT on the protected program. Then the trained model will classify
    whether the instruction sequences are malicious or benign.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: DeepCheck的训练数据来自CFG，这些CFG是通过拆解程序并使用Intel PT的信息构建的。在构建受保护程序的CFG后，作者通过将由边连接的基本块“链式连接”来采样良性指令序列，并通过将那些不由边连接的指令序列“链式连接”来采样恶意指令序列。尽管在训练期间需要CFG，但训练阶段之后无需构建CFG。部署后，将通过在受保护程序上利用Intel
    PT来构建指令序列。然后，训练好的模型将对指令序列进行分类，判断其是否恶意或良性。
- en: 'We observed that none of the works considered Phase [1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order."), so all of them belong to class 1 according to our
    taxonomy as shown in Figure LABEL:fig:dec. The analysis results of ROPNN [[11](#bib.bib11)]
    and HeNet [[12](#bib.bib12)] are shown in Table LABEL:Table:Summary. Also, we
    observed that three works had different goals.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到所有考虑的工作都没有涉及到阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以统一总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文作者按字母顺序列出。")，因此它们都属于我们分类法中的第1类，如图LABEL:fig:dec所示。ROPnn
    [[11](#bib.bib11)]和HeNet [[12](#bib.bib12)]的分析结果见表LABEL:Table:Summary。此外，我们还观察到三个工作有不同的目标。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评审将围绕在第LABEL:threequestions节中描述的三个问题展开。在本节的其余部分，我们将首先提供一组观察结果，然后提供指示。最后，我们提供一些一般性的评论。
- en: 4.2 Key findings from a closer look
  id: totrans-259
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 进一步观察的关键发现
- en: 'From a close look at the very recent applications using Deep Learning for defending
    return-oriented programming attacks, we observed the followings:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 从对最近使用深度学习防御面向返回编程攻击的应用进行的深入观察中，我们发现了以下几点：
- en: Observation 4.1:   All the works[[11](#bib.bib11), [25](#bib.bib25), [12](#bib.bib12)]
    in this survey focused on data generation and acquisition.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 4.1：本次调查中所有的工作[[11](#bib.bib11), [25](#bib.bib25), [12](#bib.bib12)]都集中在数据生成和获取上。
- en: In ROPNN [[11](#bib.bib11)], both malicious samples (gadget chains) were generated
    using an automated gadget generator (i.e. ROPGadget [[56](#bib.bib56)]) and a
    CPU emulator (i.e. Unicorn [[57](#bib.bib57)]). ROPGadget was used to extract
    instruction sequences that could be used as gadgets from a program, and Unicorn
    was used to validate the instruction sequences. Corresponding benign sample (gadget-chain-like
    instruction sequences) were generated by disassembling a set of programs. In DeepCheck [[25](#bib.bib25)]
    refers to the key idea of control-flow integrity[[55](#bib.bib55)]. It generates
    program’s run-time control flow through new feature of Intel CPU (Intel Processor
    Tracing), then compares the run-time control flow with the program’s control-flow
    graph (CFG) that generates through static analysis. Benign instruction sequences
    are that with in the program’s CFG, and vice versa. In HeNet [[12](#bib.bib12)],
    program’s execution trace was extracted using the similar way as DeepCheck. Then,
    each byte was transformed into a pixel with an intensity between 0-255\. Known
    malware samples and benign software samples were used to generate malicious data
    benign data, respectively.
  id: totrans-262
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在ROPNN[[11](#bib.bib11)]中，恶意样本（小工具链）是使用自动化小工具生成器（即ROPGadget[[56](#bib.bib56)]）和CPU模拟器（即Unicorn[[57](#bib.bib57)]）生成的。ROPGadget用于从程序中提取可作为小工具的指令序列，而Unicorn用于验证这些指令序列。对应的良性样本（类似小工具链的指令序列）则是通过反汇编一组程序生成的。在DeepCheck[[25](#bib.bib25)]中提到了控制流完整性的关键思想[[55](#bib.bib55)]。它通过Intel
    CPU的新特性（Intel Processor Tracing）生成程序的运行时控制流，然后将运行时控制流与通过静态分析生成的程序控制流图（CFG）进行比较。良性指令序列是程序的CFG中的序列，反之亦然。在HeNet[[12](#bib.bib12)]中，程序的执行踪迹是通过类似于DeepCheck的方法提取的。然后，每个字节被转换为强度在0到255之间的像素。已知的恶意软件样本和良性软件样本分别用于生成恶意数据和良性数据。
- en: 'Observation 4.2:   None of the ROP works in this survey deployed Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.").'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 4.2：本调查中的ROPS工作中没有部署阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以统一总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文的作者按字母顺序列出。")。
- en: Both ROPNN[[11](#bib.bib11)] and DeepCheck[[25](#bib.bib25)] used binary instruction
    sequences for training. In ROPNN[[11](#bib.bib11)], one byte was used as the very
    basic element for data pre-processing. Bytes were formed into one-hot matrices
    and flattened for 1-dimensional convolutional layer. In DeepCheck [[25](#bib.bib25)],
    half-byte was used as the basic unit. Each half-byte (4 bits) was transformed
    to decimal form ranging from 0-15 as the basic element of the input vector, then
    was fed into a fully-connected input layer. On the other hand, HeNet [[12](#bib.bib12)]
    used different kinds of data. By the time this survey has been drafted, the source
    code of HeNet was not available to public and thus, the details of the data pre-processing
    was not be investigated. However, it is still clear that HeNet used binary branch
    information collected from Intel PT rather than binary instructions. In HeNet,
    each byte was converted to one decimal number ranging from 0 to 255\. Byte sequences
    was sliced and formed into image sequences (each pixel represented one byte) for
    a fully-connected input layer.
  id: totrans-264
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: ROPNN[[11](#bib.bib11)]和DeepCheck[[25](#bib.bib25)]都使用了二进制指令序列进行训练。在ROPNN[[11](#bib.bib11)]中，一个字节被用作数据预处理的基本元素。字节被形成一热编码矩阵，并展平以供一维卷积层使用。在DeepCheck[[25](#bib.bib25)]中，半字节被用作基本单元。每个半字节（4位）被转换为范围从0到15的十进制形式作为输入向量的基本元素，然后输入到全连接输入层。另一方面，HeNet[[12](#bib.bib12)]使用了不同类型的数据。在本调查草稿编写时，HeNet的源代码尚未公开，因此数据预处理的细节尚未调查。然而，仍然可以清楚地看出，HeNet使用了从Intel
    PT收集的二进制分支信息，而不是二进制指令。在HeNet中，每个字节被转换为范围从0到255的十进制数。字节序列被切片并形成图像序列（每个像素代表一个字节）以供全连接输入层使用。
- en: Observation 4.3:   Fully-connected neural network was widely used.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 4.3：全连接神经网络被广泛使用。
- en: Only ROPNN [[11](#bib.bib11)] used 1-dimensional convolutional neural network
    (CNN) when extracting features. Both HeNet [[12](#bib.bib12)] and DeepCheck[[25](#bib.bib25)]
    used fully-connected neural network (FCN). None of the works used recurrent neural
    network (RNN) and the variants.
  id: totrans-266
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 只有ROP网络[[11](#bib.bib11)]在特征提取时使用了一维卷积神经网络（CNN）。HeNet [[12](#bib.bib12)] 和 DeepCheck[[25](#bib.bib25)]则使用了全连接神经网络（FCN）。没有工作使用递归神经网络（RNN）及其变体。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 以上观察似乎表明了以下几点：
- en: •
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Indication 4.1:   It seems like that one of the most important factors in ROP
    problem is feature selection and data generation.
  id: totrans-269
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指示 4.1：ROP问题中的一个最重要因素似乎是特征选择和数据生成。
- en: All three works use very different methods to collect/generate data, and all
    the authors provide very strong evidences and/or arguments to justify their approaches.
    ROPNN [[11](#bib.bib11)] was trained by the malicious and benign instruction sequences.
    However, there is no clear boundary between benign instruction sequences and malicious
    gadget chains. This weakness may impair the performance when applying ROPNN to
    real world ROP attacks. As oppose to ROPNN, DeepCheck [[25](#bib.bib25)] utilizes
    CFG to generate training basic-block sequences. However, since the malicious basic-block
    sequences are generated by randomly connecting nodes without edges, it is not
    guaranteed that all the malicious basic-blocks are executable. HeNet [[12](#bib.bib12)]
    generates their training data from malware. Technically, HeNet could be used to
    detect any binary exploits, but their experiment focuses on ROP attack and achieves
    100% accuracy. This shows that the source of data in ROP problem does not need
    to be related to ROP attacks to produce very impressive results.
  id: totrans-270
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有三项工作使用了非常不同的方法来收集/生成数据，所有作者都提供了非常强有力的证据和/或论据来证明他们的方法。ROP网络[[11](#bib.bib11)]使用恶意和良性指令序列进行训练。然而，良性指令序列与恶意小
    gadget链之间没有明确的界限。这一弱点可能会影响ROP网络在现实世界ROP攻击中的性能。与ROP网络相对，DeepCheck [[25](#bib.bib25)]利用控制流图（CFG）生成训练基本块序列。然而，由于恶意基本块序列是通过随机连接没有边的节点生成的，因此不能保证所有恶意基本块都是可执行的。HeNet
    [[12](#bib.bib12)] 从恶意软件中生成训练数据。从技术上讲，HeNet可以用于检测任何二进制漏洞，但其实验专注于ROP攻击，并达到了100%的准确率。这表明ROP问题中的数据源不需要与ROP攻击相关，就能产生非常令人印象深刻的结果。
- en: •
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Indication 4.2:   Representation learning seems not critical when solving ROP
    problems using Deep Learning.
  id: totrans-272
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指示 4.2：在使用深度学习解决ROP问题时，表示学习似乎并不关键。
- en: Minimal process on data in binary form seems to be enough to transform the data
    into a representation that is suitable for neural networks. Certainly, it is also
    possible to represent the binary instructions at a higher level, such as opcodes,
    or use embedding learning. However, as stated in [[11](#bib.bib11)], it appears
    that the performance will not change much by doing so. The only benefit of representing
    input data to a higher level is to reduce irrelevant information, but it seems
    like neural network by itself is good enough at extracting features.
  id: totrans-273
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对二进制形式的数据进行最少处理似乎足以将数据转换为适合神经网络的表示形式。当然，也可以将二进制指令表示为更高级的形式，如操作码，或使用嵌入学习。然而，如[[11](#bib.bib11)]所述，进行这些操作似乎不会显著改变性能。将输入数据表示为更高级别的唯一好处是减少无关信息，但神经网络本身似乎足够擅长特征提取。
- en: •
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Indication 4.3:   Different Neural network architecture does not have much influence
    on the effectiveness of defending ROP attacks.
  id: totrans-275
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 指示 4.3：不同的神经网络架构对防御ROP攻击的效果影响不大。
- en: Both HeNet [[12](#bib.bib12)] and DeepCheck [[25](#bib.bib25)] utilizes standard
    DNN and achieved comparable results on ROP problems. One can infer that the input
    data can be easily processed by neural networks, and the features can be easily
    detected after proper pre-process.
  id: totrans-276
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: HeNet [[12](#bib.bib12)] 和 DeepCheck [[25](#bib.bib25)] 都利用了标准的深度神经网络（DNN），并在ROP问题上取得了可比的结果。可以推断，输入数据可以被神经网络轻松处理，经过适当的预处理后，特征可以被轻松检测到。
- en: It is not surprising that researchers are not very interested in representation
    learning for ROP problems as stated in Observation 4.LABEL:rop:obs1. Since ROP
    attack is focus on the gadget chains, it is straightforward for the researcher
    to choose the gadgets as their training data directly. It is easy to map the data
    into numerical representation with minimal processing. An example is that one
    can map binary executable to hexadecimal ASCII representation, which could be
    a good representation for neural network.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 正如观察4.LABEL:rop:obs1所述，研究人员对ROP问题的表示学习不太感兴趣也就不足为奇了。由于ROP攻击关注的是小工具链，因此研究人员可以直接选择小工具作为训练数据。将数据映射到数值表示形式相对简单，处理过程也很少。例如，可以将二进制可执行文件映射为十六进制ASCII表示，这可能是神经网络的一个良好表示。
- en: Instead, researchers focus more in data acquisition and generation. In ROP problems,
    the amount of data is very limited. Unlike malware and logs, ROP payloads normally
    only contain addresses rather than codes, which do not contain any information
    without providing the instructions in corresponding addresses. It is thus meaningless
    to collect all the payloads. At the best of our knowledge, all the previous works
    use pick instruction sequences rather than payloads as their training data, even
    though they are hard to collect.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，研究人员更多地关注数据获取和生成。在ROP（返回导向编程）问题中，数据量非常有限。与恶意软件和日志不同，ROP有效负载通常只包含地址，而不是代码，这些地址在没有提供相应指令的情况下并不包含任何信息。因此，收集所有的有效负载没有意义。据我们所知，所有的先前工作都使用了指令序列而不是有效负载作为训练数据，即使这些数据很难收集。
- en: 4.3 Discussion
  id: totrans-279
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 讨论
- en: Even though, Deep Learning based method does not face the challenge to design
    a very complex fine-grained CFG anymore, it suffers from a limited number of data
    sources. Generally, Deep Learning based method requires lots of training data.
    However, real-world malicious data for the ROP attack is very hard to find, because
    comparing with benign data, malicious data need to be carefully crafted and there
    is no existing database to collect all the ROP attacks. Without enough representative
    training set, the accuracy of the trained model cannot be guaranteed.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，基于深度学习的方法不再面临设计非常复杂的细粒度控制流图（CFG）的挑战，但它仍然受到数据源有限的困扰。一般来说，基于深度学习的方法需要大量的训练数据。然而，实际的ROP攻击恶意数据非常难以获得，因为与良性数据相比，恶意数据需要精心制作，并且没有现有的数据库来收集所有的ROP攻击。如果没有足够具有代表性的训练集，训练模型的准确性无法得到保证。
- en: 5 A closer look at applications of Deep Learning in achieving CFI
  id: totrans-281
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 深度学习在实现控制流完整性（CFI）中的应用
- en: 5.1 Introduction
  id: totrans-282
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 引言
- en: The basic ideas of control-flow integrity (CFI) techniques, proposed by Abadi
    in 2005[[55](#bib.bib55)], could be dated back to 2002, when Vladimir and his
    fellow researchers proposed an idea called program shepherding[[58](#bib.bib58)],
    a method of monitoring the execution flow of a program when it is running by enforcing
    some security policies. The goal of CFI is to detect and prevent control-flow
    hijacking attacks, by restricting every critical control flow transfers to a set
    that can only appear in correct program executions, according to a pre-built CFG.
    Traditional CFI techniques typically leverage some knowledge, gained from either
    dynamic or static analysis of the target program, combined with some code instrumentation
    methods, to ensure the program runs on a correct track.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: Abadi于2005年提出的控制流完整性（CFI）技术的基本理念[[55](#bib.bib55)]可以追溯到2002年，当时Vladimir和他的同事提出了一种叫做程序监护[[58](#bib.bib58)]的方法，这是一种通过强制执行某些安全策略来监控程序运行时执行流程的方法。CFI的目标是通过限制每个关键控制流转移到只能出现在正确程序执行中的集合来检测和防止控制流劫持攻击，这些集合是根据预先构建的控制流图（CFG）定义的。传统的CFI技术通常利用从目标程序的动态或静态分析中获得的一些知识，并结合一些代码插桩方法，以确保程序按照正确的轨道运行。
- en: 'However, the problems of traditional CFI are: (1) Existing CFI implementations
    are not compatible with some of important code features [[59](#bib.bib59)]; (2)
    CFGs generated by static, dynamic or combined analysis cannot always be precisely
    completed due to some open problems [[60](#bib.bib60)]; (3) There always exist
    certain level of compromises between accuracy and performance overhead and other
    important properties [[61](#bib.bib61), [62](#bib.bib62)]. Recent research has
    proposed to apply Deep Learning on detecting control flow violation. Their result
    shows that, compared with traditional CFI implementation, the security coverage
    and scalability were enhanced in such a fashion [[13](#bib.bib13)]. Therefore,
    we argue that Deep Learning could be another approach which requires more attention
    from CFI researchers who aim at achieving control-flow integrity more efficiently
    and accurately.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，传统 CFI 的问题包括：（1）现有的 CFI 实现与一些重要的代码特性不兼容 [[59](#bib.bib59)]；（2）由静态、动态或组合分析生成的控制流图（CFG）由于一些未解决的问题，不能总是准确完成 [[60](#bib.bib60)]；（3）在准确性与性能开销及其他重要属性之间总是存在某种程度的妥协 [[61](#bib.bib61),
    [62](#bib.bib62)]。最近的研究提出了将深度学习应用于检测控制流违规。他们的结果显示，与传统 CFI 实现相比，安全覆盖率和可扩展性得到了以这种方式增强 [[13](#bib.bib13)]。因此，我们认为深度学习可能是另一种需要
    CFI 研究人员更多关注的方法，以更高效、更准确地实现控制流完整性。
- en: In this section, we will review the very recent three representative papers
    that use Deep Learning for achieving CFI. Among the three, two representative
    papers[[13](#bib.bib13), [14](#bib.bib14)] are already summarized phase-by-phase
    in Table LABEL:Table:Summary. We refer to interested readers the Table LABEL:Table:Summary
    for a concise overview of those two papers.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾最近的三篇代表性论文，这些论文使用深度学习实现 CFI。在这三篇论文中，两篇代表性论文 [[13](#bib.bib13), [14](#bib.bib14)]
    已在表 LABEL:Table:Summary 中逐阶段总结。我们建议感兴趣的读者参阅表 LABEL:Table:Summary 以获得这两篇论文的简明概述。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评审将围绕第 LABEL:threequestions 节中描述的三个问题展开。在本节的其余部分，我们将首先提供一组观察结果，然后提供相关指示。最后，我们将提供一些一般性评论。
- en: 5.2 Key findings from a closer look
  id: totrans-287
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 更详细观察的主要发现
- en: 'From a close look at the very recent applications using Deep Learning for achieving
    control-flow integrity, we observed the followings:'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 从对使用深度学习实现控制流完整性的最新应用的详细观察中，我们发现以下几点：
- en: Observation 5.1:   None of the related works realize preventive²²2We refer readers
    to [[62](#bib.bib62)] which systemizes the knowledge of protections by CFI schemes.
    prevention of control flow violation.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 5.1：  相关的工作中没有任何一项实现了对控制流违规的预防。
- en: After doing a thorough literature search, we observed that security researchers
    are quite behind the trend of applying Deep Learning techniques to solve security
    problems. Only one paper has been founded by us, using Deep Learning techniques
    to directly enhance the performance of CFI [[13](#bib.bib13)]. This paper leveraged
    Deep Learning to detect document malware through checking program’s execution
    traces that generated by hardware. Specifically, the CFI violations were checked
    in an offline mode. So far, no works have realized Just-In-Time checking for program’s
    control flow.
  id: totrans-290
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在进行彻底的文献检索后，我们观察到安全研究人员在应用深度学习技术解决安全问题方面落后于趋势。我们找到的唯一一篇论文是使用深度学习技术直接提升 CFI 性能的 [[13](#bib.bib13)]。这篇论文利用深度学习通过检查由硬件生成的程序执行踪迹来检测文档恶意软件。具体来说，CFI
    违规是在离线模式下检查的。到目前为止，还没有工作实现程序控制流的即时检查。
- en: In order to provide more insightful results, in this section, we try not to
    narrow down our focus on CFI detecting attacks at run-time, but to extend our
    scope to papers that take good use of control flow related data, combined with
    Deep Learning techniques[[14](#bib.bib14), [63](#bib.bib63)]. In one work, researchers
    used self-constructed instruction-level CFG to detect program defection[[14](#bib.bib14)].
    In another work, researchers used lazy-binding CFG to detect sophisticated malware [[63](#bib.bib63)].
  id: totrans-291
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了提供更有洞察力的结果，在本节中，我们尝试不将焦点狭隘地集中在运行时的 CFI 攻击检测上，而是扩展到那些善于利用控制流相关数据并结合深度学习技术的论文
    [[14](#bib.bib14), [63](#bib.bib63)]。在一项工作中，研究人员使用自构建的指令级 CFG 来检测程序缺陷 [[14](#bib.bib14)]。在另一项工作中，研究人员使用惰性绑定
    CFG 来检测复杂的恶意软件 [[63](#bib.bib63)]。
- en: Observation 5.2:   Diverse raw data were used for evaluating CFI solutions.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 5.2：用于评估 CFI 解决方案的数据多样。
- en: 'In all surveyed papers, there are two kinds of control flow related data being
    used: program instruction sequences and CFGs. Barnum et al. [[13](#bib.bib13)]
    employed statically and dynamically generated instruction sequences acquired by
    program disassembling and Intel^® Processor Trace. CNNoverCFG[[14](#bib.bib14)]
    used self-designed algorithm to construct instruction level control-flow graph.
    Minh Hai Nguyen et al.[[63](#bib.bib63)] used proposed lazy-binding CFG to reflect
    the behavior of malware DEC.'
  id: totrans-293
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在所有调查的论文中，使用了两种与控制流相关的数据：程序指令序列和控制流图（CFG）。Barnum 等人[[13](#bib.bib13)] 使用了通过程序反汇编和英特尔®处理器跟踪获得的静态和动态生成的指令序列。CNNoverCFG[[14](#bib.bib14)]
    使用自设计的算法构建了指令级控制流图。Minh Hai Nguyen 等人[[63](#bib.bib63)] 使用了提议的懒绑定 CFG 来反映恶意软件
    DEC 的行为。
- en: 'Observation 5.3:   All the papers in our survey adopted Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.").'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 5.3：我们调查中的所有论文都采用了第[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 个四阶段工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")阶段。
- en: 'All the related papers in our survey employed Phase [1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") to process their raw data before sending them into
    Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order."). In Barnum [[13](#bib.bib13)],
    the instruction sequences from program run-time tracing were sliced into basic-blocks.
    Then, they assigned each basic-blocks with an unique basic-block ID (BBID). Finally,
    due to the nature of control-flow hijacking attack, they selected the sequences
    ending with indirect branch instruction (e.g., indirect call/jump, return and
    so on) as the training data. In CNNoverCFG [[14](#bib.bib14)], each of instructions
    in CFG were labeled with its attributes in multiple perspectives, such as opcode,
    operands, and the function it belongs to. The training data is generated are sequences
    generated by traversing the attributed control-flow graph. Nguyen and others [[63](#bib.bib63)]
    converted the lazy-binding CFG to corresponding adjacent matrix and treated the
    matrix as a image as their training data.'
  id: totrans-295
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们调查中的所有相关论文都采用了第[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 个四阶段工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")阶段来处理原始数据，然后再送入第[1](#S2.F1 "图 1 ‣
    2.1 四个阶段的定义 ‣ 2 个四阶段工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")阶段。在
    Barnum [[13](#bib.bib13)] 中，从程序运行时跟踪获得的指令序列被切分为基本块。然后，他们为每个基本块分配了一个唯一的基本块 ID（BBID）。最后，由于控制流劫持攻击的性质，他们选择了以间接分支指令（例如，间接调用/跳转、返回等）结束的序列作为训练数据。在
    CNNoverCFG [[14](#bib.bib14)] 中，控制流图中的每条指令都用多个视角的属性进行标注，如操作码、操作数和所属函数。训练数据是通过遍历标注的控制流图生成的序列。Nguyen
    等人[[63](#bib.bib63)] 将懒绑定 CFG 转换为相应的邻接矩阵，并将矩阵视为图像作为训练数据。
- en: 'Observation 5.4:   All the papers in our survey did not adopt Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.").'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 5.4：我们调查中的所有论文都没有采用第[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 个四阶段工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")阶段。
- en: 'We observed all the papers we surveyed did not adopted Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order."). Instead, they adopted the form of numerical
    representation directly as their training data. Specifically, Barnum[[13](#bib.bib13)]
    grouped the the instructions into basic-blocks, then represented basic-blocks
    with uniquely assigning IDs. In CNNoverCFG[[14](#bib.bib14)], each of instructions
    in the CFG was represented by a vector that associated with its attributes. Nguyen
    and others directly used the hashed value of bit string representation.'
  id: totrans-297
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们观察到所有我们调查的论文都没有采用 Phase [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文的作者按字母顺序列出。")。相反，他们直接采用了数值表示的形式作为他们的训练数据。具体来说，Barnum[[13](#bib.bib13)]
    将指令分组到基本块中，然后用唯一分配的 ID 表示基本块。在 CNNoverCFG[[14](#bib.bib14)] 中，CFG 中的每条指令都由与其属性相关联的向量表示。Nguyen
    等人直接使用了位字符串表示的哈希值。
- en: Observation 5.5:   Various Phase IV models were used.
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 5.5：使用了各种 Phase IV 模型。
- en: Barnum[[13](#bib.bib13)] utilized BBID sequence to monitor the execution flow
    of the target program, which is sequence-type data. Therefore, they chose LSTM
    architecture to better learn the relationship between instructions. While in the
    other two papers[[14](#bib.bib14), [63](#bib.bib63)], they trained CNN and directed
    graph-based CNN to extract information from control-flow graph and image, respectively.
  id: totrans-299
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Barnum[[13](#bib.bib13)] 利用 BBID 序列来监控目标程序的执行流，这是序列类型的数据。因此，他们选择了 LSTM 架构来更好地学习指令之间的关系。而在其他两篇论文[[14](#bib.bib14),
    [63](#bib.bib63)] 中，他们训练了 CNN 和基于有向图的 CNN，分别从控制流图和图像中提取信息。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎表明了以下指示：
- en: Indication 5.1:   All the existing works did not achieve Just-In-Time CFI violation
    detection.
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 5.1：所有现有的工作都未能实现及时 CFI 违规检测。
- en: It is still a challenge to tightly embed Deep Learning model in program execution.
    All existing work adopted lazy-checking – checking the program’s execution trace
    following its execution.
  id: totrans-302
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将深度学习模型紧密嵌入程序执行仍然是一个挑战。所有现有的工作都采用了懒惰检查——在程序执行后检查其执行轨迹。
- en: Indication 5.2:   There is no unified opinion on how to generate malicious sample.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 5.2：对于如何生成恶意样本，没有统一的意见。
- en: Data are hard to collect in control-flow hijacking attacks. The researchers
    must carefully craft malicious sample. It is not clear whether the “handcrafted”
    sample can reflect the nature the control-flow hijacking attack.
  id: totrans-304
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在控制流劫持攻击中，数据难以收集。研究人员必须精心制作恶意样本。目前尚不清楚“手工制作”的样本是否能反映控制流劫持攻击的本质。
- en: '^∗Indication 5.3:  The choice of methods in Phase [1](#S2.F1 "Figure 1 ‣ 2.1
    Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") are based on researchers’ security domain knowledge.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ^∗指示 5.3：Phase [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注 11脚注 1本文的作者按字母顺序列出。") 中方法的选择基于研究人员的安全领域知识。
- en: 5.3 Discussion
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 讨论
- en: The strength of using deep learning to solve CFI problems is that it can avoid
    the complicated processes of developing algorithms to build acceptable CFGs for
    the protected programs. Compared with the traditional approaches, the DL based
    method could prevent CFI designer from studying the language features of the targeted
    program and could also avoid the open problem (pointer analysis) in control flow
    analysis. Therefore, DL based CFI provides us a more generalized, scalable, and
    secure solution. However, since using DL in CFI problem is still at an early age,
    which kinds of control-flow related data are more effective is still unclear yet
    in this research area. Additionally, applying DL in real-time control-flow violation
    detection remains an untouched area and needs further research.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 使用深度学习解决CFI问题的优势在于它可以避免开发算法以构建接受的CFGs（控制流图）所涉及的复杂过程。与传统方法相比，基于深度学习的方法可以避免CFI设计者研究目标程序的语言特性，并且可以避免控制流分析中的开放问题（指针分析）。因此，基于深度学习的CFI为我们提供了更为通用、可扩展和安全的解决方案。然而，由于在CFI问题中使用深度学习仍处于初期阶段，哪种控制流相关数据更有效在该研究领域仍不清楚。此外，应用深度学习进行实时控制流违规检测仍是一个未涉足的领域，需要进一步研究。
- en: 6 A closer look at applications of Deep Learning in defending network attacks
  id: totrans-308
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 深度学习在防御网络攻击中的应用探讨
- en: 6.1 Introduction
  id: totrans-309
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 引言
- en: Network security is becoming more and more important as we depend more and more
    on networks for our daily lives, works and researches. Some common network attack
    types include probe, denial of service (DoS), Remote-to-local (R2L), etc. Traditionally,
    people try to detect those attacks using signatures, rules, and unsupervised anomaly
    detection algorithms. However, signature based methods can be easily fooled by
    slightly changing the attack payload; rule based methods need experts to regularly
    update rules; and unsupervised anomaly detection algorithms tend to raise lots
    of false positives. Recently, people are trying to apply Deep Learning methods
    for network attack detection.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 随着我们日常生活、工作和研究越来越依赖网络，网络安全变得愈加重要。一些常见的网络攻击类型包括探测、拒绝服务（DoS）、远程到本地（R2L）等。传统上，人们尝试使用签名、规则和无监督异常检测算法来检测这些攻击。然而，基于签名的方法很容易被稍微改变的攻击负载欺骗；基于规则的方法需要专家定期更新规则；而无监督异常检测算法往往会产生大量误报。最近，人们尝试将深度学习方法应用于网络攻击检测。
- en: In this section, we will review the very recent seven representative works that
    use Deep Learning for defending network attacks. [[15](#bib.bib15), [27](#bib.bib27),
    [29](#bib.bib29)] build neural networks for multi-class classification, whose
    class labels include one benign label and multiple malicious labels for different
    attack types. [[16](#bib.bib16)] ignores normal network activities and proposes
    parallel cross convolutional neural network (PCCN) to classify the type of malicious
    network activities. [[26](#bib.bib26)] applies Deep Learning to detecting a specific
    attack type, distributed denial of service (DDoS) attack. [[28](#bib.bib28), [30](#bib.bib30)]
    explores both binary classification and multi-class classification for benign
    and malicious activities. Among these seven works, we select two representative
    works[[15](#bib.bib15), [16](#bib.bib16)] and summarize the main aspects of their
    approaches regarding whether the four phases exist in their works, and what exactly
    do they do in the Phase if it exists. We direct interested readers to TableLABEL:Table:Summary
    for a concise overview of these two works.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾最近的七项代表性工作，这些工作使用深度学习来防御网络攻击。[[15](#bib.bib15), [27](#bib.bib27),
    [29](#bib.bib29)] 构建了用于多类分类的神经网络，其类别标签包括一个正常标签和多个不同攻击类型的恶意标签。[[16](#bib.bib16)]
    忽略正常网络活动，并提出了并行交叉卷积神经网络（PCCN）来分类恶意网络活动的类型。[[26](#bib.bib26)] 将深度学习应用于检测特定攻击类型——分布式拒绝服务（DDoS）攻击。[[28](#bib.bib28),
    [30](#bib.bib30)] 探索了对正常和恶意活动的二分类和多分类。在这七项工作中，我们选择了两个代表性工作[[15](#bib.bib15), [16](#bib.bib16)]，并总结了它们在其方法中是否存在四个阶段的主要方面，以及如果存在，该阶段的具体内容。我们引导感兴趣的读者参考TableLABEL:Table:Summary，以便简明概览这两项工作。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回顾将围绕第LABEL:threequestions节中描述的三个问题展开。在本节的剩余部分，我们将首先提供一组观察结果，然后提供指示。最后，我们将提供一些总体评论。
- en: 6.2 Key findings from a closer look
  id: totrans-313
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 进一步观察的关键发现
- en: 'From a close look at the very recent applications using Deep Learning for solving
    network attack challenges, we observed the followings:'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 从最近使用深度学习解决网络攻击挑战的应用中，我们观察到以下情况：
- en: Observation 6.1:   All the seven works in our survey used public datasets, such
    as UNSW-NB15 [[64](#bib.bib64)] and CICIDS2017 [[65](#bib.bib65)].
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 6.1：我们调查的七个工作都使用了公共数据集，如 UNSW-NB15 [[64](#bib.bib64)] 和 CICIDS2017 [[65](#bib.bib65)]。
- en: The public datasets were all generated in test-bed environments, with unbalanced
    simulated benign and attack activities. For attack activities, the dataset providers
    launched multiple types of attacks, and the numbers of malicious data for those
    attack activities were also unbalanced.
  id: totrans-316
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这些公共数据集均在测试环境中生成，具有不平衡的模拟良性和攻击活动。在攻击活动方面，数据集提供者发起了多种类型的攻击，并且这些攻击活动的恶意数据数量也不平衡。
- en: Observation 6.2:   The public datasets were given into one of two data formats,
    i.e., PCAP and CSV.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 6.2：公共数据集被给定为两种数据格式之一，即 PCAP 和 CSV。
- en: One was raw PCAP or parsed CSV format, containing network packet level features,
    and the other was also CSV format, containing network flow level features, which
    showed the statistic information of many network packets. Out of all the seven
    works, [[26](#bib.bib26), [27](#bib.bib27)] used packet information as raw inputs,
    [[28](#bib.bib28), [16](#bib.bib16), [29](#bib.bib29), [30](#bib.bib30)] used
    flow information as raw inputs, and [[15](#bib.bib15)] explored both cases.
  id: totrans-318
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一种是原始的 PCAP 或解析后的 CSV 格式，包含网络包级别的特征；另一种也是 CSV 格式，包含网络流级别的特征，展示了许多网络包的统计信息。在所有七个工作中，[[26](#bib.bib26),
    [27](#bib.bib27)] 使用了包信息作为原始输入，[[28](#bib.bib28), [16](#bib.bib16), [29](#bib.bib29),
    [30](#bib.bib30)] 使用了流信息作为原始输入，[[15](#bib.bib15)] 探索了这两种情况。
- en: Observation 6.3:   In order to parse the raw inputs, preprocessing methods,
    including one-hot vectors for categorical texts, normalization on numeric data,
    and removal of unused features/data samples, were commonly used.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 6.3：为了解析原始输入，常用的预处理方法包括对分类文本的独热编码、对数值数据的标准化以及移除未使用的特征/数据样本。
- en: Commonly removed features include IP addresses and timestamps. [[30](#bib.bib30)]
    also removed port numbers from used features. By doing this, they claimed that
    they could “avoid over-fitting and let the neural network learn characteristics
    of packets themselves”. One outlier was that, when using packet level features
    in one experiment, [[15](#bib.bib15)] blindly chose the first 50 bytes of each
    network packet without any feature extracting processes and fed them into neural
    network.
  id: totrans-320
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 常见的去除特征包括 IP 地址和时间戳。[[30](#bib.bib30)] 还从使用的特征中去除了端口号。通过这样做，他们声称能够“避免过拟合并让神经网络自行学习数据包的特征”。一个例外是，在一个实验中使用包级特征时，[[15](#bib.bib15)]
    盲目选择了每个网络包的前 50 个字节，没有任何特征提取过程，并将其输入到神经网络中。
- en: Observation 6.4:   Using image representation improved the performance of security
    solutions using Deep Learning.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 6.4：使用图像表示提高了使用深度学习的安全解决方案的性能。
- en: After preprocessing the raw data, while [[16](#bib.bib16)] transformed the data
    into image representation, [[26](#bib.bib26), [27](#bib.bib27), [30](#bib.bib30),
    [29](#bib.bib29), [28](#bib.bib28)] directly used the original vectors as an input
    data. Also, [[15](#bib.bib15)] explored both cases and reported better performance
    using image representation.
  id: totrans-322
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在预处理原始数据后，虽然 [[16](#bib.bib16)] 将数据转换为图像表示，[[26](#bib.bib26), [27](#bib.bib27),
    [30](#bib.bib30), [29](#bib.bib29), [28](#bib.bib28)] 直接使用原始向量作为输入数据。同时，[[15](#bib.bib15)]
    探索了这两种情况，并报告了使用图像表示的更好性能。
- en: Observation 6.5:   None of all the seven surveyed works considered representation
    learning.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 6.5：所有七个调查的工作中没有考虑表征学习。
- en: 'All the seven surveyed works belonged to class 1 shown in Figure LABEL:fig:dec.
    They either directly used the processed vectors to feed into the neural networks,
    or changed the representation without explanation. One research work [[15](#bib.bib15)]
    provided a comparison on two different representations (vectors and images) for
    the same type of raw input. However, the other works applied different preprocessing
    methods in Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order."). That
    is, since the different preprocessing methods generated different feature spaces,
    it was difficult to compare the experimental results.'
  id: totrans-324
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '所有七项调查的工作都属于图示LABEL:fig:dec中的类别1。它们要么直接使用处理后的向量输入神经网络，要么在没有解释的情况下改变表示方法。一项研究[[15](#bib.bib15)]
    对同一类型的原始输入提供了两种不同表示（向量和图像）的比较。然而，其他工作在阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")中采用了不同的预处理方法。也就是说，由于不同的预处理方法生成了不同的特征空间，导致难以比较实验结果。'
- en: Observation 6.6:   Binary classification model showed better results from most
    experiments.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察6.6：二分类模型在大多数实验中表现更好。
- en: Among all the seven surveyed works, [[26](#bib.bib26)] focused on one specific
    attack type and only did binary classification to classify whether the network
    traffic was benign or malicious. Also, [[15](#bib.bib15), [29](#bib.bib29), [16](#bib.bib16),
    [27](#bib.bib27)] included more attack types and did multi-class classification
    to classify the type of malicious activities, and [[28](#bib.bib28), [30](#bib.bib30)]
    explored both cases. As for multi-class classification, the accuracy for selective
    classes was good, while accuracy for other classes, usually classes with much
    fewer data samples, suffered by up to 20% degradation.
  id: totrans-326
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在所有七项调查的工作中，[[26](#bib.bib26)] 只关注了一种特定攻击类型，并且只进行了二分类，以判断网络流量是正常的还是恶意的。此外，[[15](#bib.bib15)、[29](#bib.bib29)、[16](#bib.bib16)、[27](#bib.bib27)]
    包含了更多的攻击类型，并进行了多类别分类，以识别恶意活动的类型，而[[28](#bib.bib28)、[30](#bib.bib30)] 则探索了这两种情况。对于多类别分类，选择类的准确性较高，而其他类的准确性通常下降了高达20%，尤其是样本数据较少的类。
- en: Observation 6.7:   Data representation influenced on choosing a neural network
    model.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察6.7：数据表示影响了神经网络模型的选择。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎指示了以下几种情况：
- en: 'Indication 6.1:   All works in our survey adopt a kind of preprocessing methods
    in Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order."), because raw data
    provided in the public datasets are either not ready for neural networks, or that
    the quality of data is too low to be directly used as data samples.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示6.1：我们调查中的所有工作在阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")中都采用了一种预处理方法，因为公开数据集中提供的原始数据要么不适合神经网络，要么数据质量过低，无法直接用作数据样本。'
- en: 'Preprocessing methods can help increase the neural network performance by improving
    the data samples’ qualities. Furthermore, by reducing the feature space, pre-processing
    can also improve the efficiency of neural network training and testing. Thus,
    Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") should not be skipped.
    If Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") is skipped, the performance
    of neural network is expected to go down considerably.'
  id: totrans-330
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 预处理方法可以通过改善数据样本的质量来提高神经网络的性能。此外，通过减少特征空间，预处理还可以提高神经网络训练和测试的效率。因此，不应跳过阶段 [1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注
    1本文的作者按字母顺序列出。")。如果跳过阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")，预计神经网络的性能将显著下降。
- en: 'Indication 6.2:   Although Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of
    the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is not employed in any of the seven surveyed works, none of them explains
    a reason for it. Also, they all do not take representation learning into consideration.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 6.2：尽管阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注
    11脚注 1本文的作者按字母顺序列出。") 在七项调查的工作中均未使用，但没有解释原因。此外，它们都没有考虑表示学习。
- en: Indication 6.3:   Because no work uses representation learning, the effectiveness
    are not well-studied.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 6.3：由于没有研究使用表示学习，因此其有效性尚未得到充分研究。
- en: Out of other factors, it seems that the choice of pre-processing methods has
    the largest impact, because it directly affects the data samples fed to the neural
    network.
  id: totrans-333
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在其他因素中，预处理方法的选择似乎有最大的影响，因为它直接影响到输入神经网络的数据样本。
- en: Indication 6.4:   There is no guarantee that CNN also works well on images converted
    from network features.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 6.4：没有保证 CNN 对从网络特征转换的图像也能有效。
- en: 'Some works that use image data representation use CNN in Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order."). Although CNN has been proven to work
    well on image classification problem in the recent years, there is no guarantee
    that CNN also works well on images converted from network features.'
  id: totrans-335
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一些使用图像数据表示的工作在阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。") 中使用了 CNN。虽然近年来 CNN 在图像分类问题上被证明效果良好，但不能保证
    CNN 对从网络特征转换的图像也有效。
- en: 'From the observations and indications above, we hereby present two recommendations:
    (1) Researchers can try to generate their own datasets for the specific network
    attack they want to detect. As stated, the public datasets have highly unbalanced
    number of data for different classes. Doubtlessly, such unbalance is the nature
    of real world network environment, in which normal activities are the majority,
    but it is not good for Deep Learning. [[27](#bib.bib27)] tries to solve this problem
    by oversampling the malicious data, but it is better to start with a balanced
    data set. (2) Representation learning should be taken into consideration. Some
    possible ways to apply representation learning include: (a) apply word2vec method
    to packet binaries, and categorical numbers and texts; (b) use K-means as one-hot
    vector representation instead of randomly encoding texts. We suggest that any
    change of data representation may be better justified by explanations or comparison
    experiments.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 根据以上观察和指示，我们在此提出两个建议：（1）研究人员可以尝试为他们想检测的特定网络攻击生成自己的数据集。如前所述，公共数据集在不同类别的数据量上高度不平衡。毫无疑问，这种不平衡是现实世界网络环境的本质，其中正常活动占多数，但这对深度学习并不有利。[[27](#bib.bib27)]尝试通过过采样恶意数据来解决此问题，但最好从一个平衡的数据集开始。（2）应考虑表示学习。一些应用表示学习的可能方法包括：（a）将word2vec方法应用于数据包二进制文件、分类数字和文本；（b）使用K-means作为一热编码表示，而不是随机编码文本。我们建议对任何数据表示的变化，应通过解释或比较实验更好地证明其合理性。
- en: 6.3 Discussion
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 讨论
- en: One critical challenge in this field is the lack of high-quality data set suitable
    for applying deep learning. Also, there is no agreement on how to apply domain
    knowledge into training deep learning models for network security problems. Researchers
    have been using different pre-processing methods, data representations and model
    types, but few of them have enough explanation on why such methods/representations/models
    are chosen, especially for data representation.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 该领域的一个关键挑战是缺乏适合应用深度学习的高质量数据集。此外，对于如何将领域知识应用于网络安全问题的深度学习模型训练上尚无一致意见。研究人员使用了不同的预处理方法、数据表示和模型类型，但很少有人对为何选择这些方法/表示/模型提供足够的解释，特别是在数据表示方面。
- en: 7 A closer look at applications of Deep Learning in malware classification
  id: totrans-339
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 深入了解深度学习在恶意软件分类中的应用
- en: 7.1 Introduction
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 介绍
- en: The goal of malware classification is to identify malicious behaviors in software
    with static and dynamic features like control-flow graph and system API calls.
    Malware and benign programs can be collected from open datasets and online websites.
    Both the industry and the academic communities have provided approaches to detect
    malware with static and dynamic analyses. Traditional methods such as behavior-based
    signatures, dynamic taint tracking, and static data flow analysis require experts
    to manually investigate unknown files. However, those hand-crafted signatures
    are not sufficiently effective because attackers can rewrite and reorder the malware.
    Fortunately, neural networks can automatically detect large-scale malware variants
    with superior classification accuracy.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 恶意软件分类的目标是通过静态和动态特征（如控制流图和系统 API 调用）来识别软件中的恶意行为。恶意软件和良性程序可以从公开数据集和在线网站中收集。业界和学术界都提供了通过静态和动态分析来检测恶意软件的方法。传统方法如基于行为的签名、动态污点跟踪和静态数据流分析需要专家手动检查未知文件。然而，这些手工制作的签名效果并不理想，因为攻击者可以重写和重新排序恶意软件。幸运的是，神经网络可以以卓越的分类准确性自动检测大规模恶意软件变体。
- en: 'In this section, we will review the very recent twelve representative works
    that use Deep Learning for malware classification [[18](#bib.bib18), [31](#bib.bib31),
    [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36),
    [37](#bib.bib37), [38](#bib.bib38), [39](#bib.bib39), [17](#bib.bib17), [40](#bib.bib40)].
    [[18](#bib.bib18)] selects three different kinds of static features to classify
    malware. [[31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33)] also use static
    features from the PE files to classify programs. [[34](#bib.bib34)] extracts behavioral
    feature images using RNN to represent the behaviors of original programs.[[35](#bib.bib35)]
    transforms malicious behaviors using representative learning without neural network.
    [[36](#bib.bib36)] explores RNN model with the API calls sequences as programs’
    features. [[38](#bib.bib38), [37](#bib.bib37)] skip Phase[1](#S2.F1 "Figure 1
    ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") by directly transforming the binary file to image
    to classify the file. [[39](#bib.bib39), [17](#bib.bib17)] applies dynamic features
    to analyze malicious features. [[40](#bib.bib40)] combines static features and
    dynamic features to represent programs’ features. Among these works, we select
    two representative works [[18](#bib.bib18), [17](#bib.bib17)] and identify four
    phases in their works shown as TableLABEL:Table:Summary.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们将回顾最近的十二个使用深度学习进行恶意软件分类的代表性工作 [[18](#bib.bib18), [31](#bib.bib31), [32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38), [39](#bib.bib39), [17](#bib.bib17), [40](#bib.bib40)]。[[18](#bib.bib18)]
    选择了三种不同的静态特征来分类恶意软件。[[31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33)] 也使用了来自
    PE 文件的静态特征来分类程序。[[34](#bib.bib34)] 使用 RNN 提取行为特征图像来表示原始程序的行为。[[35](#bib.bib35)]
    利用代表学习转换恶意行为，而不使用神经网络。[[36](#bib.bib36)] 探索了将 API 调用序列作为程序特征的 RNN 模型。[[38](#bib.bib38),
    [37](#bib.bib37)] 通过直接将二进制文件转换为图像来分类文件，跳过了 Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")。[[39](#bib.bib39), [17](#bib.bib17)] 应用动态特征来分析恶意特征。[[40](#bib.bib40)]
    结合静态特征和动态特征来表示程序特征。在这些工作中，我们选择了两个代表性工作 [[18](#bib.bib18), [17](#bib.bib17)]，并在其工作中识别出了四个阶段，如表
    TableLABEL:Table:Summary 所示。'
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的评审将围绕在 Section LABEL:threequestions 中描述的三个问题展开。在本节的其余部分，我们将首先提供一组观察结果，然后提供指示，最后提供一些一般性备注。
- en: 7.2 Key findings from a closer look
  id: totrans-344
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 通过更近距离观察得到的关键发现
- en: 'From a close look at the very recent applications using Deep Learning for solving
    malware classification challenges, we observed the followings:'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 从对使用深度学习解决恶意软件分类挑战的最新应用的深入观察中，我们注意到以下几点：
- en: 'Observation 7.1:   Features selected in malware classification were grouped
    into three categories: static features, dynamic features, and hybrid features.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 7.1：在恶意软件分类中选择的特征被分为三类：静态特征、动态特征和混合特征。
- en: 'Typical static features include metadata, PE import Features, Byte/Entorpy,
    String, and Assembly Opcode Features derived from the PE files [[32](#bib.bib32),
    [33](#bib.bib33), [31](#bib.bib31)]. De LaRosa, Kilgallon, et al.[[18](#bib.bib18)]
    took three kinds of static features: byte-level, basic-level ( strings in the
    file, the metadata table, and the import table of the PE header), and assembly
    features-level. Some works directly considered binary code as static features[[38](#bib.bib38),
    [37](#bib.bib37)].'
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 典型的静态特征包括来自 PE 文件的元数据、PE 导入特征、字节/熵、字符串和汇编操作码特征 [[32](#bib.bib32), [33](#bib.bib33),
    [31](#bib.bib31)]。De LaRosa、Kilgallon 等人 [[18](#bib.bib18)] 采用了三种静态特征：字节级、基本级（文件中的字符串、元数据表和
    PE 头部的导入表）和汇编特征级。某些工作直接将二进制代码视为静态特征 [[38](#bib.bib38), [37](#bib.bib37)]。
- en: Different from static features, dynamic features were extracted by executing
    the files to retrieve their behaviors during execution. The behaviors of programs,
    including the API function calls, their parameters, files created or deleted,
    websites and ports accessed, etc, were recorded by a sandbox as dynamic features[[39](#bib.bib39)].
    The process behaviors including operation name and their result codes were extracted
    [[34](#bib.bib34)]. The process memory, tri-grams of system API calls and one
    corresponding input parameter were chosen as dynamic features[[35](#bib.bib35)].
    An API calls sequence for an APK file was another representation of dynamic features [[36](#bib.bib36),
    [17](#bib.bib17)].
  id: totrans-348
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与静态特征不同，动态特征通过执行文件以检索其执行过程中的行为来提取。程序的行为，包括API函数调用、其参数、创建或删除的文件、访问的网站和端口等，均由沙箱记录为动态特征[[39](#bib.bib39)]。过程行为包括操作名称及其结果代码被提取[[34](#bib.bib34)]。选择了进程内存、系统API调用的三元组以及一个对应的输入参数作为动态特征[[35](#bib.bib35)]。APK文件的API调用序列是动态特征的另一种表示方式[[36](#bib.bib36),
    [17](#bib.bib17)]。
- en: Static features and dynamic features were combined as hybrid features [[40](#bib.bib40)].
    For static features, Xu and others in [[40](#bib.bib40)] used permissions, networks,
    calls, and providers, etc. For dynamic features, they used system call sequences.
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 静态特征和动态特征被组合为混合特征[[40](#bib.bib40)]。对于静态特征，Xu等人[[40](#bib.bib40)]使用了权限、网络、调用和提供者等。对于动态特征，他们使用了系统调用序列。
- en: 'Observation 7.2:   In most works, Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") was inevitable because extracted features needed to be vertorized for
    Deep Learning models.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 7.2：在大多数工作中，阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")是不可避免的，因为提取的特征需要被向量化以用于深度学习模型。'
- en: 'One-hot encoding approach was frequently used to vectorize features[[32](#bib.bib32),
    [33](#bib.bib33), [17](#bib.bib17), [34](#bib.bib34), [36](#bib.bib36)]. Bag-of-words
    (BoW) and n-gram were also considered to represent features [[36](#bib.bib36)].
    Some works brought the concepts of word frequency in NLP to convert the sandbox
    file to fixed-size inputs[[39](#bib.bib39)]. Hashing features into a fixed vector
    was used as an effective method to represent features[[31](#bib.bib31)]. Bytes
    histogram using the bytes analysis and bytes-entropy histogram with a sliding
    window method were considered [[18](#bib.bib18)]. In [[18](#bib.bib18)], De La
    Rosa and others embeded strings by hashing the ASCII strings to a fixed-size feature
    vector. For assembly features, they extracted four different levels of granularity:
    operation level (instruction-flow-graph), block level (control-flow-graph), function
    level (call-graph), and global level (graphs summarized). bigram, trigram and
    four-gram vectors and n-gram graph were used for the hybrid features [[40](#bib.bib40)].'
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一热编码方法经常用于特征向量化[[32](#bib.bib32), [33](#bib.bib33), [17](#bib.bib17), [34](#bib.bib34),
    [36](#bib.bib36)]。袋模型（BoW）和n-gram也被考虑用于表示特征[[36](#bib.bib36)]。一些工作引入了NLP中的词频概念，将沙箱文件转换为固定大小的输入[[39](#bib.bib39)]。将特征哈希到固定向量被用作一种有效的特征表示方法[[31](#bib.bib31)]。使用字节分析的字节直方图和滑动窗口方法的字节熵直方图也被考虑[[18](#bib.bib18)]。在[[18](#bib.bib18)]中，De
    La Rosa等人通过将ASCII字符串哈希到固定大小的特征向量来嵌入字符串。对于汇编特征，他们提取了四个不同的粒度级别：操作级（指令流图）、块级（控制流图）、函数级（调用图）和全局级（总结图）。bigram、trigram和四元组向量以及n-gram图被用于混合特征[[40](#bib.bib40)]。
- en: 'Observation 7.3:   Most Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") methods were classified into class 1.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 7.3：大多数阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")方法被归类为第1类。'
- en: Following the classification tree shown in Figure LABEL:fig:dec, most works
    were classified into class 1 shown in Figure LABEL:fig:dec except two works[[35](#bib.bib35),
    [34](#bib.bib34)], which belonged to class 3 shown in Figure LABEL:fig:dec. To
    reduce the input dimension, Dahl et al.[[35](#bib.bib35)] performed feature selection
    using mutual information and random projection. Tobiyama et al. generated behavioral
    feature images using RNN[[34](#bib.bib34)].
  id: totrans-353
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据图示中的分类树，如图 LABEL:fig:dec 所示，大多数工作被分类到图 LABEL:fig:dec 中的类别 1，除了两项工作[[35](#bib.bib35)、[34](#bib.bib34)]，它们属于图
    LABEL:fig:dec 中的类别 3。为减少输入维度，Dahl 等[[35](#bib.bib35)] 通过互信息和随机投影进行了特征选择。Tobiyama
    等使用 RNN[[34](#bib.bib34)] 生成了行为特征图像。
- en: 'Observation 4:  After extracting features, two kinds of neural network architectures,
    i.e., one single neural network and multiple neural networks with a combined loss
    function, were used.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 4：在提取特征后，使用了两种神经网络架构，即单个神经网络和具有组合损失函数的多个神经网络。
- en: Hierarchical structures, like convolutional layers, fully connected layers and
    classification layers, were used to classify programs [[33](#bib.bib33), [35](#bib.bib35),
    [36](#bib.bib36), [31](#bib.bib31), [34](#bib.bib34), [38](#bib.bib38), [37](#bib.bib37)].
    A deep stack of denoising autoencoders was also introduced to learn programs’
    behaviors [[39](#bib.bib39)]. De La Rosa and others[[18](#bib.bib18)] trained
    three different models with different features to compare which static features
    are relevant for the classification model. Some works investigated LSTM models
    for sequential features[[36](#bib.bib36), [17](#bib.bib17)].
  id: totrans-355
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采用了分层结构，如卷积层、全连接层和分类层，用于分类程序[[33](#bib.bib33)、[35](#bib.bib35)、[36](#bib.bib36)、[31](#bib.bib31)、[34](#bib.bib34)、[38](#bib.bib38)、[37](#bib.bib37)]。还引入了一个深层去噪自编码器来学习程序行为[[39](#bib.bib39)]。De
    La Rosa 等[[18](#bib.bib18)] 训练了三个不同特征的模型，以比较哪些静态特征对分类模型相关。一些工作调查了用于序列特征的 LSTM
    模型[[36](#bib.bib36)、[17](#bib.bib17)]。
- en: Two networks with different features as inputs were used for malware classification
    by combining their outputs with a dropout layer and an output layer[[32](#bib.bib32)].
    In [[32](#bib.bib32)], one network transformed PE Metadata and import features
    using feedforward neurons, another one leveraged convolutional network layers
    with opcode sequences. Lifan Xu et al.[[40](#bib.bib40)] constructed a few networks
    and combined them using a two-level multiple kernel learning algorithm.
  id: totrans-356
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过结合具有不同特征作为输入的两个网络的输出，使用了一个 dropout 层和一个输出层进行恶意软件分类[[32](#bib.bib32)]。在[[32](#bib.bib32)]中，一个网络使用前馈神经元转换
    PE 元数据和导入特征，另一个则利用卷积网络层处理操作码序列。Lifan Xu 等[[40](#bib.bib40)] 构建了几个网络，并使用两级多核学习算法将它们结合起来。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎指示了以下几点：
- en: Indication 7.1:   Except two works transform binary into images[[38](#bib.bib38),
    [37](#bib.bib37)], most works surveyed need to adapt methods to vectorize extracted
    features.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 7.1：除了将二进制转换为图像的两项工作[[38](#bib.bib38)、[37](#bib.bib37)]，大多数调查的工作需要调整方法以向量化提取的特征。
- en: The vectorization methods should not only keep syntactic and semantic information
    in features, but also consider the definition of the Deep Learning model.
  id: totrans-359
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 向量化方法不仅应保持特征中的语法和语义信息，还应考虑深度学习模型的定义。
- en: Indication 7.2:   Only limited works have shown how to transform features using
    representation learning.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 7.2：只有有限的工作展示了如何通过表征学习转换特征。
- en: Because some works assume the dynamic and static sequences, like API calls and
    instruction, and have similar syntactic and semantic structure as natural language,
    some representation learning techniques like word2vec may be useful in malware
    detection. In addition, for the control-flow graph, call graph and other graph
    representations, graph embedding is a potential method to transform those features.
  id: totrans-361
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于一些工作假设动态和静态序列，如 API 调用和指令，与自然语言具有类似的语法和语义结构，因此一些表征学习技术如 word2vec 可能在恶意软件检测中有用。此外，对于控制流图、调用图和其他图形表示，图嵌入是一种潜在的方法来转换这些特征。
- en: 7.3 Discussion
  id: totrans-362
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 讨论
- en: Though several pieces of research have been done in malware detection using
    Deep Learning, it’s hard to compare their methods and performances because of
    two uncertainties in their approaches. First, the Deep Learning model is a black-box,
    researchers cannot detail which kind of features the model learned and explain
    why their model works. Second, feature selection and representation affect the
    model’s performance. Because they do not use the same datasets, researchers cannot
    prove their approaches – including selected features and Deep Learning model – are
    better than others. The reason why few researchers use open datasets is that existing
    open malware datasets are out of data and limited. Also, researchers need to crawl
    benign programs from app stores, so their raw programs will be diverse.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管已有若干研究使用深度学习进行恶意软件检测，但由于其方法中存在两个不确定性，比较这些方法及其性能变得困难。首先，深度学习模型是一个黑箱，研究人员无法详细说明模型学到了哪种特征，也无法解释模型为何有效。其次，特征选择和表示会影响模型的性能。由于他们使用的数据集不同，研究人员无法证明他们的方法——包括所选特征和深度学习模型——优于其他方法。少数研究人员使用开放数据集的原因是现有的开放恶意软件数据集已经过时且有限。此外，研究人员需要从应用商店抓取良性程序，因此其原始程序将会多样化。
- en: 8 A closer look at applications of Deep Learning in system-event-based anomaly
    detection
  id: totrans-364
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 深度学习在基于系统事件的异常检测中的应用探讨
- en: 8.1 Introduction
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.1 引言
- en: System logs recorded significant events at various critical points, which can
    be used to debug the system’s performance issues and failures. Moreover, log data
    are available in almost all computer systems and are a valuable resource for understanding
    system status. There are a few challenges in anomaly detection based on system
    logs. Firstly, the raw log data are unstructured, while their formats and semantics
    can vary significantly. Secondly, logs are produced by concurrently running tasks.
    Such concurrency makes it hard to apply workflow-based anomaly detection methods.
    Thirdly, logs contain rich information and complexity types, including text, real
    value, IP address, timestamp, and so on. The contained information of each log
    is also varied. Finally, there are massive logs in every system. Moreover, each
    anomaly event usually incorporates a large number of logs generated in a long
    period.
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: 系统日志记录了在各种关键点发生的显著事件，这些事件可以用于调试系统的性能问题和故障。此外，日志数据几乎在所有计算机系统中都有，是了解系统状态的重要资源。在基于系统日志的异常检测中存在一些挑战。首先，原始日志数据是非结构化的，而其格式和语义可能有很大差异。其次，日志是由并发运行的任务生成的，这种并发性使得应用基于工作流的异常检测方法变得困难。第三，日志包含丰富的信息和复杂类型，包括文本、实值、IP
    地址、时间戳等。每条日志包含的信息也各不相同。最后，每个系统中都有大量的日志。此外，每个异常事件通常涉及在较长时间内生成的大量日志。
- en: Recently, a large number of scholars employed deep learning techniques [[8](#bib.bib8),
    [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]
    to detect anomaly events in the system logs and diagnosis system failures. The
    raw log data are unstructured, while their formats and semantics can vary significantly.
    To detect the anomaly event, the raw log usually should be parsed to structure
    data, the parsed data can be transformed into a representation that supports an
    effective deep learning model. Finally, the anomaly event can be detected by deep
    learning based classifier or predictor.
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，大量学者采用深度学习技术[[8](#bib.bib8), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44), [45](#bib.bib45)]来检测系统日志中的异常事件并诊断系统故障。原始日志数据是非结构化的，而其格式和语义可能有很大差异。为了检测异常事件，通常需要将原始日志解析成结构化数据，然后将解析后的数据转换成支持有效深度学习模型的表示。最后，可以通过基于深度学习的分类器或预测器检测异常事件。
- en: In this section, we will review the very recent six representative papers that
    use deep learning for system-event-based anomaly detection[[8](#bib.bib8), [41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]. DeepLog
    [[8](#bib.bib8)] utilizes LSTM to model the system log as a natural language sequence,
    which automatically learns log patterns from the normal event, and detects anomalies
    when log patterns deviate from the trained model. LogAnom[[41](#bib.bib41)] employs
    Word2vec to extract the semantic and syntax information from log templates. Moreover,
    it uses sequential and quantitative features simultaneously. Desh [[42](#bib.bib42)]
    uses LSTM to predict node failures that occur in super computing systems from
    HPC logs. Andy Brown et al. [[43](#bib.bib43)] presented RNN language models augmented
    with attention for anomaly detection in system logs. LogRobust [[44](#bib.bib44)]
    uses FastText to represent semantic information of log events, which can identify
    and handle unstable log events and sequences. Christophe Bertero et al.[[45](#bib.bib45)]
    map log word to a high dimensional metric space using Google’s word2vec algorithm
    and take it as features to classify. Among these six papers, we select two representative
    works [[8](#bib.bib8), [41](#bib.bib41)] and summarize the four phases of their
    approaches. We direct interested readers to TableLABEL:Table:Summary for a concise
    overview of these two works.
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 本节中，我们将回顾最近的六篇代表性论文，这些论文使用深度学习进行系统事件基异常检测[[8](#bib.bib8), [41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]。DeepLog
    [[8](#bib.bib8)]利用LSTM将系统日志建模为自然语言序列，自动学习来自正常事件的日志模式，并在日志模式偏离训练模型时检测异常。LogAnom[[41](#bib.bib41)]使用Word2vec从日志模板中提取语义和语法信息。此外，它同时使用顺序和定量特征。Desh
    [[42](#bib.bib42)]使用LSTM从HPC日志中预测超级计算系统中的节点故障。Andy Brown等人[[43](#bib.bib43)]提出了增强注意力机制的RNN语言模型，用于系统日志中的异常检测。LogRobust
    [[44](#bib.bib44)]使用FastText表示日志事件的语义信息，能够识别和处理不稳定的日志事件和序列。Christophe Bertero等人[[45](#bib.bib45)]使用Google的word2vec算法将日志词映射到高维度度量空间，并将其作为特征进行分类。在这六篇论文中，我们选择了两篇代表性工作[[8](#bib.bib8),
    [41](#bib.bib41)]，总结了它们方法的四个阶段。我们建议感兴趣的读者参见TableLABEL:Table:Summary，以获得这两项工作的简明概述。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回顾将围绕第LABEL:threequestions节中描述的三个问题展开。在本节的剩余部分，我们将首先提供一组观察结果，然后给出相关指示。最后，我们将提供一些总体评述。
- en: 8.2 Key findings from a closer look
  id: totrans-370
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.2 更深入的关键发现
- en: 'From a close look at the very recent applications using deep learning for solving
    security-event-based anomaly detection challenges, we observed the followings:'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 从对最近使用深度学习解决基于安全事件的异常检测挑战的应用进行深入观察，我们发现以下几点：
- en: Observation 8.1:   Most works of our surveyed papers evaluated their performance
    using public datasets.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察8.1：我们调查的论文中的大多数工作使用公共数据集评估了它们的性能。
- en: By the time we surveyed this paper, only two works in [[42](#bib.bib42), [45](#bib.bib45)]
    used their private datasets.
  id: totrans-373
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在我们调查这篇论文时，只有两个工作[[42](#bib.bib42), [45](#bib.bib45)]使用了他们的私有数据集。
- en: 'Observation 8.2:   Most works in this survey adopted Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") when parsing the raw log data.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察8.2：大多数本调查中的工作在解析原始日志数据时采用了阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")。'
- en: After reviewing the six works proposed recently, we found that five works[[8](#bib.bib8),
    [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44)] employed
    parsing technique, while only one work [[45](#bib.bib45)] did not.
  id: totrans-375
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在回顾了最近提出的六项工作后，我们发现五项工作[[8](#bib.bib8), [41](#bib.bib41), [42](#bib.bib42),
    [43](#bib.bib43), [44](#bib.bib44)]采用了解析技术，而只有一项工作[[45](#bib.bib45)]没有。
- en: DeepLog[[8](#bib.bib8)] parsed the raw log to different log type using Spell[[46](#bib.bib46)]
    which is based a longest common subsequence. Desh [[42](#bib.bib42)] parsed the
    raw log to constant message and variable component. Loganom[[41](#bib.bib41)]
    parsed the raw log to different log templates using FT-Tree [[47](#bib.bib47)]
    according to the frequent combinations of log words. Andy Brown et al. [[43](#bib.bib43)]
    parsed the raw log into word and character tokenization. LogRobust[[44](#bib.bib44)]
    extracted its log event by abstracting away the parameters in the message. Christophe
    Bertero et al.[[45](#bib.bib45)] considered logs as regular text without parsing.
  id: totrans-376
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepLog [[8](#bib.bib8)] 使用基于最长公共子序列的 Spell [[46](#bib.bib46)] 将原始日志解析为不同的日志类型。Desh
    [[42](#bib.bib42)] 将原始日志解析为常量消息和变量组件。Loganom [[41](#bib.bib41)] 根据日志词的频繁组合使用 FT-Tree
    [[47](#bib.bib47)] 将原始日志解析为不同的日志模板。Andy Brown 等 [[43](#bib.bib43)] 将原始日志解析为词和字符标记。LogRobust
    [[44](#bib.bib44)] 通过抽象消息中的参数来提取其日志事件。Christophe Bertero 等 [[45](#bib.bib45)]
    将日志视为普通文本而不进行解析。
- en: 'Observation 8.3:   Most works have considered and adopted Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.").'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 8.3: 大多数工作都考虑并采用了 Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.").'
- en: Among these six works, only DeepLog represented the parsed data using the one-hot
    vector without learning. Moreover, Loganom[[41](#bib.bib41)] compared their results
    with DeepLog. That is, DeepLog belongs to class 1 and Loganom belongs to class
    4 in Figure LABEL:fig:dec, while the other four works follow in class 3.
  id: totrans-378
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在这六项工作中，只有 DeepLog 使用 one-hot 向量表示解析后的数据而无需学习。此外，Loganom [[41](#bib.bib41)]
    将他们的结果与 DeepLog 进行了比较。即，DeepLog 属于图 LABEL:fig:dec 中的类别 1，而 Loganom 属于类别 4，而其他四项工作则属于类别
    3。
- en: The four works [[41](#bib.bib41), [42](#bib.bib42), [44](#bib.bib44), [45](#bib.bib45)]
    used word embedding techniques to represent the log data. Andy Brown et al. [[43](#bib.bib43)]
    employed attention vectors to represent the log messages.
  id: totrans-379
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 这四项工作 [[41](#bib.bib41), [42](#bib.bib42), [44](#bib.bib44), [45](#bib.bib45)]
    使用词嵌入技术来表示日志数据。Andy Brown 等 [[43](#bib.bib43)] 使用注意力向量来表示日志消息。
- en: DeepLog [[8](#bib.bib8)] employed the one-hot vector to represent the log type
    without learning. We have engaged an experiment replacing the one-hot vector with
    trained word embeddings.
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepLog [[8](#bib.bib8)] 使用 one-hot 向量来表示日志类型而无需学习。我们进行了一项实验，将 one-hot 向量替换为训练过的词嵌入。
- en: Observation 8.4:   Evaluation results were not compared using the same dataset.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 8.4: 评估结果未使用相同的数据集进行比较。'
- en: 'DeepLog [[8](#bib.bib8)] employed the one-hot vector to represent the log type
    without learning, which employed Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of
    the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") without Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order."). However,
    Christophe Bertero et al.[[45](#bib.bib45)] considered logs as regular text without
    parsing, and used Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") without
    Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order."). The precision of
    the two methods is very high, which is greater than 95%. Unfortunately, the evaluations
    of the two methods used different datasets.'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'DeepLog [[8](#bib.bib8)] 使用one-hot向量表示日志类型而没有学习，而使用了第一阶段[1](#S2.F1 "图1 ‣ 2.1
    四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列。")而没有使用第一阶段[1](#S2.F1
    "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")。然而，Christophe
    Bertero等人[[45](#bib.bib45)]认为日志是正常文本而不是解析，使用了第一阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义
    ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")而没有使用第一阶段[1](#S2.F1
    "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")。这两种方法的精确度非常高，大于95%。不幸的是，这两种方法的评估使用了不同的数据集。'
- en: 'Observation 8.5:   Most works empolyed LSTM in Phase [1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.").'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察8.5：大多数作品在第一阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")中使用了LSTM。'
- en: 'Five works including[[8](#bib.bib8), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43),
    [44](#bib.bib44)] employed LSTM in the Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), while Christophe Bertero et al.[[45](#bib.bib45)] tried different classifiers
    including naive Bayes, neural networks and random forest.'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '包括[[8](#bib.bib8), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44)]在内的五个作品在第一阶段[1](#S2.F1
    "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")中使用了LSTM，而Christophe
    Bertero等人[[45](#bib.bib45)]使用了不同的分类器，包括朴素贝叶斯、神经网络和随机森林。'
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察结果似乎表明以下几点：
- en: 'Indication 8.1:   Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") has a positive effect on accuracy if being well-designed.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示8.1：如果设计良好，第一阶段[1](#S2.F1 "图1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段的工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战: 一项调查1注脚11注脚1本文的作者按照字母顺序排列")对准确性有积极的影响。'
- en: 'Since Christophe Bertero et al. [[45](#bib.bib45)] considers logs as regular
    text without parsing, we can say that Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is not required. However, we can find that most of the scholars employed
    parsing techniques to extract structure information and remove the useless noise.'
  id: totrans-387
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '由于 Christophe Bertero 等人[[45](#bib.bib45)] 将日志视为未经解析的普通文本，因此我们可以说阶段[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") 并不是必需的。然而，我们可以发现大多数学者采用了解析技术来提取结构信息并去除无用噪声。'
- en: Indication 8.2:   Most of the recent works use trained representation to represent
    parsed data.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 8.2：最近的大多数工作使用训练过的表示来表示解析的数据。
- en: 'As shown in Table LABEL:tab:deeplog, we can find Phase [1](#S2.F1 "Figure 1
    ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") is very useful, which can improve detection accuracy.'
  id: totrans-389
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '如表 LABEL:tab:deeplog 所示，我们可以发现阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 非常有用，它可以提高检测准确率。'
- en: 'Indication 8.3:   Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") and Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣
    2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") cannot
    be skipped simultaneously.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 8.3：阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") 和阶段[1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") 不能同时跳过。'
- en: 'Both Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") and Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") are not required. However, all
    methods have employed Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") or Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.").'
  id: totrans-391
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注
    11脚注 1本文的作者按字母顺序列出。") 和阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。") 并不是必需的。然而，所有方法都采用了阶段[1](#S2.F1 "图
    1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")
    或阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 四阶段工作流框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注
    11脚注 1本文的作者按字母顺序列出。")。
- en: Indication 8.4:   Observation 8.LABEL:log:obs:3 indicates that the trained word
    embedding format can improve the anomaly detection accuracy as shown in Table LABEL:tab:deeplog.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 8.4:  观察 8.LABEL:log:obs:3 表明，训练的词嵌入格式可以提高异常检测的准确性，如表 LABEL:tab:deeplog
    所示。'
- en: '| Method | FP ¹ | FN ² | Precision | Recall | F1-measure |'
  id: totrans-393
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 方法 | FP ¹ | FN ² | 精确度 | 召回率 | F1 值 |'
- en: '| Word Embedding ³ | 680 | 219 | 96.069% | 98.699% | 97.366% |'
  id: totrans-394
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 词嵌入 ³ | 680 | 219 | 96.069% | 98.699% | 97.366% |'
- en: '| One-hot Vector ⁴ | 711 | 705 | 95.779% | 95.813% | 95.796% |'
  id: totrans-395
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| 一热向量 ⁴ | 711 | 705 | 95.779% | 95.813% | 95.796% |'
- en: '| DeepLog ⁵ | 833 | 619 | 95% | 96% | 96% |'
  id: totrans-396
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| DeepLog ⁵ | 833 | 619 | 95% | 96% | 96% |'
- en: –
  id: totrans-397
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: –
- en: '¹FP: false positive; ²FN: False negative;³Word Embedding: Log keys are embedded
    by Continuous Bag of words;⁴ One-hot Vector: We reproduced the results according
    to DeepLog;⁵ DeepLog: Orignial results presented in the paper [[8](#bib.bib8)].'
  id: totrans-398
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
  zh: '¹FP: 假阳性；²FN: 假阴性；³词嵌入: 通过连续词袋嵌入日志键；⁴ 一热向量: 我们根据 DeepLog 复制了结果；⁵ DeepLog: 论文中呈现的原始结果
    [[8](#bib.bib8)]。'
- en: Indication 8.5:   Observation 8.LABEL:log:obs:5 indicates that most of the works
    adopt LSTM to detect anomaly events.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 8.5:  观察 8.LABEL:log:obs:5 表明，大多数工作采用 LSTM 来检测异常事件。'
- en: We can find that most of the works adopt LSTM to detect anomaly event, since
    log data can be considered as sequence and there can be lags of unknown duration
    between important events in a time series. LSTM has feedback connections, which
    can not only process single data points, but also entire sequences of data.
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们可以发现，大多数工作采用 LSTM 来检测异常事件，因为日志数据可以被视为序列，并且在时间序列中的重要事件之间可能存在未知持续时间的滞后。LSTM
    具有反馈连接，这不仅可以处理单个数据点，还可以处理整个数据序列。
- en: 'As our consideration, neither Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") nor Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣
    2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") is required
    in system event-based anomaly detection. However, Phase[1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") can remove noise in raw data, and Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") can learn a proper representation
    of the data. Both Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") and Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") have a positive effect on anomaly
    detection accuracy. Since the event log is text data that we can’t feed the raw
    log data into deep learning model directly, Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") and Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣
    2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") can’t
    be skipped simultaneously.'
  id: totrans-401
  prefs: []
  type: TYPE_NORMAL
  zh: 根据我们的考虑，阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1脚注
    11脚注 1本文作者按字母顺序列出。") 和阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注 1本文作者按字母顺序列出。") 在系统事件基异常检测中并不是必需的。然而，阶段[1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注
    1本文作者按字母顺序列出。") 可以去除原始数据中的噪声，而阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注 1本文作者按字母顺序列出。") 可以学习数据的合适表示。阶段[1](#S2.F1 "图 1 ‣ 2.1
    四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注 1本文作者按字母顺序列出。")
    和阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1脚注
    11脚注 1本文作者按字母顺序列出。") 对异常检测的准确性有积极的影响。由于事件日志是文本数据，我们不能直接将原始日志数据输入深度学习模型，因此阶段[1](#S2.F1
    "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注
    1本文作者按字母顺序列出。") 和阶段[1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流程框架可以以统一的方式总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：综述1脚注 11脚注 1本文作者按字母顺序列出。") 不能同时被跳过。
- en: 8.3 Discussion
  id: totrans-402
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 8.3 讨论
- en: Deep learning can capture the potentially nonlinear and high dimensional dependencies
    among log entries from the training data that correspond to abnormal events. In
    that way, it can release the challenges mentioned above. However, it still suffers
    from several challenges. For example, how to represent the unstructured data accurately
    and automatically without human knowledge.
  id: totrans-403
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习可以捕捉训练数据中与异常事件相关的日志条目之间潜在的非线性和高维依赖关系。这样，它可以解决上述挑战。然而，它仍然面临若干挑战。例如，如何准确且自动地表示无结构数据而无需人工知识。
- en: 9 A closer look at applications of Deep Learning in solving memory forensics
    challenges
  id: totrans-404
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 9 深入了解深度学习在解决内存取证挑战中的应用
- en: 9.1 Introduction
  id: totrans-405
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 介绍
- en: In the field of computer security, memory forensics is security-oriented forensic
    analysis of a computer’s memory dump. Memory forensics can be conducted against
    OS kernels, user-level applications, as well as mobile devices. Memory forensics
    outperforms traditional disk-based forensics because although secrecy attacks
    can erase their footprints on disk, they would have to appear in memory [[19](#bib.bib19)].
    The memory dump can be considered as a sequence of bytes, thus memory forensics
    usually needs to extract security semantic information from raw memory dump to
    find attack traces.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机安全领域，内存取证是对计算机内存转储进行的以安全为导向的取证分析。内存取证可以针对操作系统内核、用户级应用程序以及移动设备进行。内存取证优于传统的基于磁盘的取证，因为尽管秘密攻击可以抹去其在磁盘上的痕迹，但它们仍必须出现在内存中[[19](#bib.bib19)]。内存转储可以被视为字节序列，因此内存取证通常需要从原始内存转储中提取安全语义信息，以寻找攻击痕迹。
- en: 'The traditional memory forensic tools fall into two categories: signature scanning
    and data structure traversal. These traditional methods usually have some limitations.
    Firstly, it needs expert knowledge on the related data structures to create signatures
    or traversing rules. Secondly, attackers may directly manipulate data and pointer
    values in kernel objects to evade detection, and then it becomes even more challenging
    to create signatures and traversing rules that cannot be easily violated by malicious
    manipulations, system updates, and random noise. Finally, the high-efficiency
    requirement often sacrifices high robustness. For example, an efficient signature
    scan tool usually skips large memory regions that are unlikely to have the relevant
    objects and relies on simple but easily tamperable string constants. An important
    clue may hide in this ignored region.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的内存取证工具分为两类：签名扫描和数据结构遍历。这些传统方法通常有一些局限性。首先，需要对相关数据结构具有专业知识，以创建签名或遍历规则。其次，攻击者可能直接操纵内核对象中的数据和指针值以规避检测，因此创建难以被恶意操作、系统更新和随机噪声轻易破坏的签名和遍历规则变得更加困难。最后，高效率的需求通常牺牲了高鲁棒性。例如，高效的签名扫描工具通常跳过不太可能包含相关对象的大内存区域，并依赖简单但容易篡改的字符串常量。一个重要的线索可能隐藏在被忽视的区域中。
- en: In this section, we will review the very recent four representative works that
    use Deep Learning for memory forensics[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)]. DeepMem[[19](#bib.bib19)] recognized the kernel objects from
    raw memory dumps by generating abstract representations of kernel objects with
    a graph-based Deep Learning approach. MDMF[[48](#bib.bib48)] detected OS and architecture-independent
    malware from memory snapshots with several pre-processing techniques, domain unaware
    feature selection, and a suite of machine learning algorithms. MemTri[[49](#bib.bib49)]
    predicts the likelihood of criminal activity in a memory image using a Bayesian
    network, based on evidence data artefacts generated by several applications. Dai
    et al. [[50](#bib.bib50)] monitor the malware process memory and classify malware
    according to memory dumps, by transforming the memory dump into grayscale images
    and adopting a multi-layer perception as the classifier.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾最近的四项代表性工作，这些工作使用深度学习进行内存取证[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)]。DeepMem[[19](#bib.bib19)]通过生成内核对象的抽象表示，采用基于图的深度学习方法识别来自原始内存转储的内核对象。MDMF[[48](#bib.bib48)]使用若干预处理技术、领域无关的特征选择和一套机器学习算法，从内存快照中检测操作系统和架构无关的恶意软件。MemTri[[49](#bib.bib49)]利用贝叶斯网络，基于由多个应用生成的证据数据伪影预测内存镜像中的犯罪活动可能性。Dai等人[[50](#bib.bib50)]通过将内存转储转换为灰度图像并采用多层感知器作为分类器，监控恶意软件进程内存并对恶意软件进行分类。
- en: Among these four works[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)], two representative works (i.e., [[19](#bib.bib19), [48](#bib.bib48)])
    are already summarized phase-by-phase in Table 1\. We direct interested readers
    to Table LABEL:Table:Summary for a concise overview of these two works.
  id: totrans-409
  prefs: []
  type: TYPE_NORMAL
  zh: 在这四项工作[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)]中，有两项代表性工作（即[[19](#bib.bib19),
    [48](#bib.bib48)]）已在表 1 中按阶段总结。我们建议有兴趣的读者查看表 LABEL:Table:Summary，以获取这两项工作的简要概述。
- en: Our review will be centered around the three questions raised in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的综述将围绕第 LABEL:threequestions 节提出的三个问题展开。在本节剩余部分，我们将首先提供一组观察结果，然后提供指示。最后，我们提供一些一般性评语。
- en: 9.2 Key findings from a closer look
  id: totrans-411
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 详细观察的主要发现
- en: 'From a close look at the very recent applications using Deep Learning for solving
    memory forensics challenges, we observed the followings:'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 通过对近期应用深度学习解决内存取证挑战的研究，我们观察到以下几点：
- en: Observation 9.1:   Most methods used their own datasets for performance evaluation,
    while none of them used a public dataset.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 9.1: 大多数方法使用了各自的数据集进行性能评估，而没有一个使用公共数据集。'
- en: DeepMem was evaluated on self-generated dataset by the authors, who collected
    a large number of diverse memory dumps, and labeled the kernel objects in them
    using existing memory forensics tools like Volatility. MDMF employed the MalRec
    dataset by Georgia Tech to generate malicious snapshots, while it created a dataset
    of benign memory snapshots running normal software. MemTri ran several Windows
    7 virtual machine instances with self-designed suspect activity scenarios to gather
    memory images. Dai et al. built the Procdump program in Cuckoo sandbox to extract
    malware memory dumps. We found that each of the four works in our survey generated
    their own datasets, while none was evaluated on a public dataset.
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepMem 在作者自生成的数据集上进行了评估，作者收集了大量不同的内存转储，并使用现有的内存取证工具如 Volatility 对其进行标注。MDMF
    使用了 Georgia Tech 提供的 MalRec 数据集来生成恶意快照，同时创建了一个运行正常软件的良性内存快照数据集。MemTri 运行了几个 Windows
    7 虚拟机实例，使用自设计的可疑活动场景来收集内存镜像。Dai 等人在 Cuckoo 沙箱中构建了 Procdump 程序来提取恶意软件内存转储。我们发现，调查中的四项工作都生成了自己的数据集，但没有一项在公共数据集上进行评估。
- en: 'Observation 9.2:   Among the four works[[19](#bib.bib19), [49](#bib.bib49),
    [48](#bib.bib48), [50](#bib.bib50)], two works [[19](#bib.bib19), [49](#bib.bib49)]
    employed Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") while
    the other two works [[48](#bib.bib48), [50](#bib.bib50)] did not employ.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察 9.2: 在这四项工作[[19](#bib.bib19), [49](#bib.bib49), [48](#bib.bib48), [50](#bib.bib50)]中，有两项工作[[19](#bib.bib19),
    [49](#bib.bib49)]采用了阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")，而另外两项工作[[48](#bib.bib48),
    [50](#bib.bib50)]则没有采用。'
- en: DeepMem [[19](#bib.bib19)] devised a graph representation for a sequence of
    bytes, taking into account both adjacency and points-to relations, to better model
    the contextual information in memory dumps. MemTri [[49](#bib.bib49)] firstly
    identified the running processes within the memory image that match the target
    applications, then employed regular expressions to locate evidence artefacts in
    a memory image. MDMF [[48](#bib.bib48)] and Dai et al. [[50](#bib.bib50)] transformed
    the memory dump into image directly.
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepMem [[19](#bib.bib19)] 为字节序列设计了一种图表示，考虑了邻接关系和指向关系，以更好地建模内存转储中的上下文信息。MemTri
    [[49](#bib.bib49)] 首先识别出内存镜像中与目标应用程序匹配的正在运行的进程，然后使用正则表达式定位内存镜像中的证据。MDMF [[48](#bib.bib48)]
    和 Dai 等 [[50](#bib.bib50)] 直接将内存转储转换为图像。
- en: 'Observation 9.3:   Among four works[[19](#bib.bib19), [49](#bib.bib49), [48](#bib.bib48),
    [50](#bib.bib50)], only DeepMem [[19](#bib.bib19)] employed Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") for which it used an embedding method
    to represent a memory graph.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '观察9.3：在四个研究[[19](#bib.bib19), [49](#bib.bib49), [48](#bib.bib48), [50](#bib.bib50)]中，只有DeepMem[[19](#bib.bib19)]使用了Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")，该方法采用了嵌入式方法来表示记忆图。'
- en: MDMF[[48](#bib.bib48)] directly fed the generated memory images into the training
    of a CNN model. Dai et al. [[50](#bib.bib50)] used HOG feature descriptor for
    detecting objects, while MemTri[[49](#bib.bib49)] extracted evidence artefacts
    as the input of Bayesian Network. In summary, DeepMem belonged to class 3 shown
    in FigureLABEL:fig:dec, while the other three works belonged to class 1 shown
    in Figure LABEL:fig:dec.
  id: totrans-418
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: MDMF[[48](#bib.bib48)]直接将生成的内存图像输入到CNN模型的训练中。Dai等人[[50](#bib.bib50)]使用HOG特征描述符进行物体检测，而MemTri[[49](#bib.bib49)]提取证据伪件作为贝叶斯网络的输入。总之，DeepMem属于图示LABEL:fig:dec中的类别3，而其他三个研究属于图示LABEL:fig:dec中的类别1。
- en: Observation 9.4:   All the four works[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)] have employed different classifiers even when the types of input
    data are the same.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察9.4：即使输入数据类型相同，这四个研究[[19](#bib.bib19), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)]使用了不同的分类器。
- en: DeepMem chose fully connected network (FCN) model that has multi-layered hidden
    neurons with ReLU activation functions, following by a softmax layer as the last
    layer. MDMF[[48](#bib.bib48)] evaluated their performance both on traditional
    machine learning algorithms and Deep Learning approach including CNN and LSTM.
    Their results showed the accuracy of different classifiers did not have a significant
    difference. MemTri employed a Bayesian network model that is designed with three
    layers, i.e., a hypothesis layer, a sub-hypothesis layer, and an evidence layer.
    Dai et al. used a multi-layer perception model including an input layer, a hidden
    layer and an output layer as the classifier.
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DeepMem选择了全连接网络（FCN）模型，该模型具有多层隐藏神经元并使用ReLU激活函数，最后一层是softmax层。MDMF[[48](#bib.bib48)]在传统机器学习算法和包括CNN和LSTM的深度学习方法上评估了其性能。他们的结果显示，不同分类器的准确性没有显著差异。MemTri使用了一个由三个层设计的贝叶斯网络模型，即假设层、子假设层和证据层。Dai等人使用了一个包含输入层、隐藏层和输出层的多层感知模型作为分类器。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎表明以下情况：
- en: Indication 9.1:   There lacks public datasets for evaluating the performance
    of different Deep Learning methods in memory forensics.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示9.1：缺乏公共数据集来评估不同深度学习方法在记忆取证中的表现。
- en: From Observation 9.LABEL:mem:obs1, we find that none of the four works surveyed
    was evaluated on public datasets.
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从观察9.LABEL:mem:obs1，我们发现这四个研究中没有一个是在公共数据集上进行评估的。
- en: 'Indication 9.2:   From Observation 9.LABEL:mem:obs2, we find that it is disputable
    whether one should employ Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") when solving memory forensics problems.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示9.2：从观察9.LABEL:mem:obs2，我们发现是否在解决记忆取证问题时应采用Phase [1](#S2.F1 "Figure 1 ‣ 2.1
    Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")是有争议的。'
- en: 'Since both [[48](#bib.bib48)] and [[50](#bib.bib50)] directly transformed a
    memory dump into an image, Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") is not required in these two works. However, since there is a large amount
    of useless information in a memory dump, we argue that appropriate prepossessing
    could improve the accuracy of the trained models.'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '由于 [[48](#bib.bib48)] 和 [[50](#bib.bib50)] 直接将内存转储转换为图像，因此这两个工作中不需要阶段 [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")。然而，由于内存转储中包含大量无用信息，我们认为适当的预处理可以提高训练模型的准确性。'
- en: 'Indication 9.3:   From Observation 9.LABEL:mem:obs3, we find that Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") is paid not much attention in
    memory forensics.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 9.3: 从观察 9.LABEL:mem:obs3 中，我们发现阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 在内存取证中并未受到太多关注。'
- en: 'Most works did not employ Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."). Among the four works, only DeepMem [[19](#bib.bib19)] employed Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") during which it used embeddings
    to represent a memory graph. The other three works [[48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50)] did not learn any representations before training a Deep Learning
    model.'
  id: totrans-427
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '大多数工作没有使用阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")。在四个工作中，只有
    DeepMem [[19](#bib.bib19)] 使用了阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")，其中使用了嵌入来表示内存图。其他三个工作 [[48](#bib.bib48), [49](#bib.bib49), [50](#bib.bib50)]
    在训练深度学习模型之前没有学习任何表示。'
- en: 'Indication 9.4:   For Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") in memory forensics, different classifiers can be employed.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '指示 9.4: 对于内存取证中的阶段 [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.")，可以使用不同的分类器。'
- en: Which kind of classifier to use seems to be determined by the features used
    and their data structures. From Observation 9.LABEL:mem:obs4, we find that the
    four works have actually employed different kinds of classifiers even the types
    of input data are the same. It is very interesting that MDMF obtained similar
    results with different classifiers including traditional machine learning and
    Deep Learning models. However, the other three works did not discuss why they
    chose a particular kind of classifier.
  id: totrans-429
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用哪种分类器似乎取决于所使用的特征及其数据结构。从观察 9.LABEL:mem:obs4 中，我们发现这四个工作实际上使用了不同种类的分类器，即使输入数据的类型相同。值得注意的是，MDMF
    使用了包括传统机器学习和深度学习模型在内的不同分类器获得了类似的结果。然而，其他三个工作没有讨论他们选择特定分类器的原因。
- en: 'Since a memory dump can be considered as a sequence of bytes, the data structure
    of a training data example is straightforward. If the memory dump is transformed
    into a simple form in Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), it can be directly fed into the training process of a Deep Learning
    model, and as a result Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") can be ignored. However, if the memory dump is transformed into a complicated
    form in Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order."), Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") could be quite useful in memory
    forensics.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
  zh: '由于内存转储可以被视为字节序列，训练数据示例的数据结构非常简单。如果内存转储在阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 被转化为简单形式，它可以直接输入深度学习模型的训练过程，因此可以忽略阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")。然而，如果内存转储在阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") 被转化为复杂形式，则阶段[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") 在内存取证中可能会非常有用。'
- en: 'Regarding the answer for Question 3 at Section LABEL:threequestions, it is
    very interesting that during Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") different classifiers can be employed in memory forensics. Moreover,
    MDMF [[48](#bib.bib48)] has shown that they can obtain similar results with different
    kinds of classifiers. Nevertheless, they also admit that with a larger amount
    of training data, the performance could be improved by Deep Learning.'
  id: totrans-431
  prefs: []
  type: TYPE_NORMAL
  zh: '关于第 LABEL:threequestions 节中问题 3 的答案，非常有趣的是在阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 内，可以在内存取证中使用不同的分类器。此外，MDMF [[48](#bib.bib48)] 已经展示了它们可以使用不同类型的分类器获得相似的结果。然而，他们也承认，随着训练数据量的增加，深度学习的性能可以得到改善。'
- en: 9.3 Discussion
  id: totrans-432
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.3 讨论
- en: An end-to-end manner deep learning model can learn the precise representation
    of memory dump automatically to release the requirement for expert knowledge.
    However, it still needs expert knowledge to represent data and attacker behavior.
    Attackers may also directly manipulate data and pointer values in kernel objects
    to evade detection.
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
  zh: 一种端到端的深度学习模型可以自动学习内存转储的精确表示，从而无需专家知识。然而，它仍然需要专家知识来表示数据和攻击者行为。攻击者也可能直接操控内核对象中的数据和指针值以逃避检测。
- en: 10 A closer look at applications of Deep Learning in security-oriented fuzzing
  id: totrans-434
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 深度学习在安全导向模糊测试中的应用
- en: 10.1 Introduction
  id: totrans-435
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.1 介绍
- en: 'Fuzzing of software security is one of the state of art techniques that people
    use to detect software vulnerabilities. The goal of fuzzing is to find all the
    vulnerabilities exist in the program by testing as much program code as possible.
    Due to the nature of fuzzing, this technique works best on finding vulnerabilities
    in programs that take in input files, like PDF viewers[[21](#bib.bib21)] or web
    browsers. A typical workflow of fuzzing can be concluded as: given several seed
    input files, the fuzzer will mutate or fuzz the seed inputs to get more input
    files, with the aim of expanding the overall code coverage of the target program
    as it executes the mutated files. Although there have already been various popular
    fuzzers[[66](#bib.bib66)], fuzzing still cannot bypass its problem of sometimes
    redundantly testing input files which cannot improve the code coverage rate[[20](#bib.bib20),
    [53](#bib.bib53)]. Some input files mutated by the fuzzer even cannot pass the
    well-formed file structure test[[21](#bib.bib21)]. Recent research has come up
    with ideas of applying Deep Learning in the process of fuzzing to solve these
    problems.'
  id: totrans-436
  prefs: []
  type: TYPE_NORMAL
  zh: 软件安全模糊测试是用于检测软件漏洞的先进技术之一。模糊测试的目标是通过尽可能多地测试程序代码来发现程序中存在的所有漏洞。由于模糊测试的特性，该技术最适用于发现需要输入文件的程序中的漏洞，如
    PDF 阅读器[[21](#bib.bib21)]或网络浏览器。模糊测试的典型工作流程可以总结为：给定若干个种子输入文件，模糊测试器将对种子输入进行变异或模糊，以获得更多的输入文件，目的是在执行变异后的文件时扩展目标程序的整体代码覆盖率。尽管已经有各种流行的模糊测试器[[66](#bib.bib66)]，但模糊测试仍然无法绕过有时重复测试输入文件这一问题，这无法提高代码覆盖率[[20](#bib.bib20),
    [53](#bib.bib53)]。一些由模糊测试器变异的输入文件甚至无法通过结构良好的文件结构测试[[21](#bib.bib21)]。最近的研究提出了在模糊测试过程中应用深度学习来解决这些问题的想法。
- en: In this section, we will review the very recent four representative works that
    use Deep Learning for fuzzing for software security. Among the three, two representative
    works[[21](#bib.bib21), [20](#bib.bib20)] are already summarized phase-by-phase
    in Table LABEL:Table:Summary. We direct interested readers to Table LABEL:Table:Summary
    for a concise overview of those two works.
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们将回顾最近的四项代表性工作，这些工作使用深度学习进行软件安全模糊测试。其中，三项代表性工作中的两项[[21](#bib.bib21), [20](#bib.bib20)]已经在表格LABEL:Table:Summary中逐阶段总结。我们建议感兴趣的读者查看表格LABEL:Table:Summary，以便对这两项工作有一个简明的概述。
- en: Our review will be centered around three questions described in Section LABEL:threequestions.
    In the remaining of this section, we will first provide a set of observations,
    and then we provide the indications. Finally, we provide some general remarks.
  id: totrans-438
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的回顾将围绕在部分LABEL:threequestions中描述的三个问题展开。在本节的其余部分，我们将首先提供一系列观察结果，然后提供指示。最后，我们提供一些总体评论。
- en: 10.2 Key findings from a closer look
  id: totrans-439
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.2 从更深入的观察中得出的关键发现
- en: 'From a close look at the very recent applications using Deep Learning for solving
    security-oriented program analysis challenges, we observed the followings:'
  id: totrans-440
  prefs: []
  type: TYPE_NORMAL
  zh: 通过仔细观察最近使用深度学习解决安全导向的程序分析挑战的应用，我们发现了以下几点：
- en: Observation 10.1:   Deep Learning has only been applied in mutation-based fuzzing.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 10.1：深度学习仅被应用于基于变异的模糊测试。
- en: 'Even though various of different fuzzing techniques, including symbolic execution
    based fuzzing [[67](#bib.bib67)], tainted analysis based fuzzing [[68](#bib.bib68)]
    and hybrid fuzzing[[69](#bib.bib69)] have been proposed so far, we observed that
    all the works we surveyed employed Deep Learning method to assist the primitive
    fuzzing – mutation-based fuzzing. Specifically, they adopted Deep Learning to
    assist fuzzing tool’s input mutation. We found that they commonly did it in two
    ways: 1) training Deep Learning models to tell how to efficiently mutate the input
    to trigger more execution path[[20](#bib.bib20), [53](#bib.bib53)]; 2) training
    Deep Learning models to tell how to keep the mutated files compliant with the
    program’s basic semantic requirement [[21](#bib.bib21)]. Besides, all three works
    trained different Deep Learning models for different programs, which means that
    knowledge learned from one programs cannot be applied to other programs.'
  id: totrans-442
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管迄今为止已经提出了各种模糊测试技术，包括基于符号执行的模糊测试[[67](#bib.bib67)]、基于污点分析的模糊测试[[68](#bib.bib68)]和混合模糊测试[[69](#bib.bib69)]，我们观察到所有我们调查的工作都采用了深度学习方法来辅助原始的模糊测试——基于变异的模糊测试。具体来说，他们采用深度学习来协助模糊测试工具的输入变异。我们发现他们通常通过两种方式实现这一点：1）训练深度学习模型来指导如何有效地变异输入以触发更多的执行路径[[20](#bib.bib20),
    [53](#bib.bib53)]; 2）训练深度学习模型来指导如何使变异后的文件符合程序的基本语义要求[[21](#bib.bib21)]。此外，这三项工作为不同程序训练了不同的深度学习模型，这意味着从一个程序中学到的知识不能应用于其他程序。
- en: Observation 10.2:   Similarity among all the works in our survey existed when
    choosing the training samples in Phase I.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察10.2：在第一阶段选择训练样本时，我们调查的所有工作之间存在相似性。
- en: The works in this survey had a common practice, i.e., using the input files
    directly as training samples of the Deep Learning model. Learn&Fuzz[[21](#bib.bib21)]
    used character-level PDF objects sequence as training samples. Neuzz[[20](#bib.bib20)]
    regarded input files directly as byte sequences and fed them into the neural network
    model. Mohit Rajpal et al.[[53](#bib.bib53)] also used byte level representations
    of input files as training samples.
  id: totrans-444
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 本次调查中的工作有一个共同的做法，即直接使用输入文件作为深度学习模型的训练样本。Learn&Fuzz[[21](#bib.bib21)] 使用字符级PDF对象序列作为训练样本。Neuzz[[20](#bib.bib20)]
    将输入文件直接视为字节序列，并将其输入神经网络模型。Mohit Rajpal等[[53](#bib.bib53)]也使用了输入文件的字节级表示作为训练样本。
- en: Observation 10.3:   Difference between all the works in our survey existed when
    assigning the training labels in Phase I.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察10.3：在第一阶段分配训练标签时，我们调查的所有工作之间存在差异。
- en: Despite the similarity of training samples researchers decide to use, there
    was a huge difference in the training labels that each work chose to use. Learn&Fuzz[[21](#bib.bib21)]
    directly used the character sequences of PDF objects as labels, same as training
    samples, but shifted by one position, which is a common generative model technique
    already broadly used in speech and handwriting recognition. Unlike Learn&Fuzz,
    Neuzz[[20](#bib.bib20)] and Rajpal’s work[[53](#bib.bib53)] used bitmap and heatmap
    respectively as training labels, with the bitmap demonstrating the code coverage
    status of a certain input, and the heatmap demonstrating the efficacy of flipping
    one or more bytes of the input file. Whereas, as a common terminology well-known
    among fuzzing researchers, bitmap was gathered directly from the results of AFL.
    Heatmap used by Rajpal et al. was generated by comparing the code coverage supported
    by the bitmap of one seed file and the code coverage supported by bitmaps of the
    mutated seed files. It was noted that if there is acceptable level of code coverage
    expansion when executing the mutated seed files, demonstrated by more “1”s, instead
    of “0”s in the corresponding bitmaps, the byte level differences among the original
    seed file and the mutated seed files will be highlighted. Since those bytes should
    be the focus of later on mutation, heatmap was used to denote the location of
    those bytes.
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 尽管研究人员决定使用相似的训练样本，但每篇工作选择使用的训练标签却存在巨大差异。Learn&Fuzz[[21](#bib.bib21)]直接使用PDF对象的字符序列作为标签，与训练样本相同，但位置相差一个，这是一种常见的生成模型技术，已经广泛应用于语音和手写识别。与Learn&Fuzz不同，Neuzz[[20](#bib.bib20)]和Rajpal的工作[[53](#bib.bib53)]分别将位图和热图用作训练标签，其中位图展示了特定输入的代码覆盖状态，而热图展示了翻转输入文件的一个或多个字节的有效性。而作为模糊研究人员之间常见的术语，位图直接从AFL的结果中收集而来。Rajpal等人使用的热图是通过比较一个种子文件的位图支持的代码覆盖和经过突变的种子文件的位图支持的代码覆盖生成的。值得注意的是，如果在执行经过突变的种子文件时，出现了可接受的代码覆盖扩展，即相应位图中出现了更多“1”而不是“0”，则原始种子文件与经过突变的种子文件之间的字节级差异将被突出显示。由于这些字节应该成为后续突变的焦点，因此热图用于表示这些字节的位置。
- en: Different labels usage in each work was actually due to the different kinds
    of knowledge each work wants to learn. For a better understanding, let us note
    that we can simply regard a Deep Learning model as a simulation of a “function”.
    Learn&Fuzz [[21](#bib.bib21)] wanted to learn valid mutation of a PDF file that
    was compliant with the syntax and semantic requirements of PDF objects. Their
    model could be seen as a simulation of $f(x,\theta)=y$, where $x$ denotes sequence
    of characters in PDF objects and $y$ represents a sequence that are obtained by
    shifting the input sequences by one position. They generated new PDF object character
    sequences given a starting prefix once the model was trained. In Neuzz[[20](#bib.bib20)],
    an NN(Neural Network) model was used to do program smoothing, which simultated
    a smooth surrogate function that approximated the discrete branching behaviors
    of the target program. $f(x,\theta)=y$, where $x$ denoted program’s byte level
    input and $y$ represented the corresponding edge coverage bitmap. In this way,
    the gradient of the surrogate function was easily computed, due to NN’s support
    of efficient computation of gradients and higher order derivatives. Gradients
    could then be used to guide the direction of mutation, in order to get greater
    code coverage. In Rajpal and others’ work[[53](#bib.bib53)], they designed a model
    to predict good (and bad) locations to mutate in input files based on the past
    mutations and corresponding code coverage information. Here, the $x$ variable
    also denoted program’s byte level input, but the $y$ variable represented the
    corresponding heatmap.
  id: totrans-447
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 每个工作的标签使用不同实际上是由于每个工作想要学习的知识类型不同。为了更好地理解，我们可以简单地将深度学习模型视为“函数”的模拟。Learn&Fuzz
    [[21](#bib.bib21)] 想要学习符合PDF对象语法和语义要求的PDF文件的有效变异。他们的模型可以看作是 $f(x,\theta)=y$ 的模拟，其中
    $x$ 表示PDF对象中的字符序列，$y$ 代表通过将输入序列移动一个位置获得的序列。模型训练完成后，他们生成了给定起始前缀的新PDF对象字符序列。在Neuzz[[20](#bib.bib20)]中，使用了一个NN（神经网络）模型来进行程序平滑，该模型模拟了一个平滑的替代函数，逼近目标程序的离散分支行为。$f(x,\theta)=y$，其中
    $x$ 表示程序的字节级输入，$y$ 代表相应的边缘覆盖位图。这样，由于NN支持高效的梯度和高阶导数计算，替代函数的梯度可以轻松计算。然后，可以使用梯度来指导变异的方向，以获得更大的代码覆盖率。在Rajpal等人的工作[[53](#bib.bib53)]中，他们设计了一个模型，根据过去的变异和相应的代码覆盖信息预测输入文件中好的（和坏的）变异位置。在这里，$x$
    变量也表示程序的字节级输入，而 $y$ 变量代表相应的热图。
- en: 'Observation 10.4:   Various lengths of input files were handled in Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.").'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察10.4：在阶段[1](#S2.F1 "图1 ‣ 2.1 四阶段定义 ‣ 2 四阶段工作流程框架可以以统一的方式总结现有工作 ‣ 使用深度学习解决计算机安全挑战：一项调查1脚注
    11脚注 1本文作者按字母顺序列出。")中处理了各种长度的输入文件。
- en: 'Deep Learning models typically accepted fixed length input, whereas the input
    files for fuzzers often held different lengths. Two different approaches were
    used among the three works we surveyed: splitting and padding. Learn&Fuzz [[21](#bib.bib21)]
    dealt with this mismatch by concatenating all the PDF objects character sequences
    together, and then splited the large character sequence into multiple training
    samples with a fixed size. Neuzz[[20](#bib.bib20)] solved this problem by setting
    a maximize input file threshold and then, padding the smaller-sized input files
    with null bytes. From additional experiments, they also found that a modest threshold
    gived them the best result, and enlarging the input file size did not grant them
    additional accuracy. Aside from preprocessing training samples, Neuzz also preprocessed
    training labels and reduced labels dimension by merging the edges that always
    appeared together into one edge, in order to prevent the multicollinearity problem,
    that could prevent the model from converging to a small loss value. Rajpal and
    others[[53](#bib.bib53)] used the similar splitting mechanism as Learn&Fuzz to
    split their input files into either 64-bit or 128-bit chunks. Their chunk size
    was determined empirically and was considered as a trainable parameter for their
    Deep Learning model, and their approach did not require sequence concatenating
    at the beginning.'
  id: totrans-449
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习模型通常接受固定长度的输入，而模糊测试器的输入文件往往长度不同。在我们调查的三项工作中使用了两种不同的方法：拆分和填充。Learn&Fuzz [[21](#bib.bib21)]
    通过将所有 PDF 对象的字符序列连接在一起，然后将大的字符序列拆分成多个固定大小的训练样本来处理这种不匹配。Neuzz [[20](#bib.bib20)]
    通过设置最大输入文件阈值并用空字节填充较小的输入文件来解决这个问题。通过额外的实验，他们还发现适度的阈值给他们带来了最佳结果，扩大输入文件大小并没有带来额外的准确性。除了预处理训练样本，Neuzz
    还预处理了训练标签，并通过将总是一起出现的边合并为一个边来减少标签维度，以防止多重共线性问题，这可能会阻碍模型收敛到较小的损失值。Rajpal 等人 [[53](#bib.bib53)]
    使用了与 Learn&Fuzz 类似的拆分机制，将输入文件拆分为 64 位或 128 位块。他们的块大小是通过经验确定的，并被视为他们深度学习模型的可训练参数，他们的方法在开始时不需要序列连接。
- en: 'Observation 10.5:   All the works in our survey skipped Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.").'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 观察 10.5：我们调查中的所有工作都跳过了阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流框架可以以统一的方式总结现有的工作
    ‣ 使用深度学习解决计算机安全挑战：调查1脚注 11脚注 1本文的作者按字母顺序列出。")。
- en: 'According to our definition of Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order."), all the works in our survey did not consider representation learning.
    Therefore, all the three works[[21](#bib.bib21), [20](#bib.bib20), [53](#bib.bib53)]
    fell into class 1 shown in FigureLABEL:fig:dec.While as in Rajpal and others’
    work, they considered the numerical representation of byte sequences. They claimed
    that since one byte binary data did not always represent the magnitude but also
    state, representing one byte in values ranging from 0 to 255 could be suboptimal.
    They used lower level 8-bit representation.'
  id: totrans-451
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 根据我们对阶段 [1](#S2.F1 "图 1 ‣ 2.1 四个阶段的定义 ‣ 2 一个四阶段工作流框架可以以统一的方式总结现有的工作 ‣ 使用深度学习解决计算机安全挑战：调查1脚注
    11脚注 1本文的作者按字母顺序列出。") 的定义，我们的调查中的所有工作都没有考虑表示学习。因此，所有三项工作[[21](#bib.bib21), [20](#bib.bib20),
    [53](#bib.bib53)] 都属于图LABEL:fig:dec 中显示的第 1 类。而在 Rajpal 等人的工作中，他们考虑了字节序列的数值表示。他们声称，由于一个字节的二进制数据不仅代表幅度还代表状态，因此将一个字节表示为从
    0 到 255 的值可能是次优的。他们使用了更低级别的 8 位表示。
- en: 'The above observations seem to indicate the following indications:'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
  zh: 上述观察似乎表明以下几点：
- en: Indication 10.1:   No alteration to the input files seems to be a correct approach.
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 10.1：对输入文件没有进行任何修改似乎是一种正确的方法。
- en: As far as we concerned, it is due to the nature of fuzzing. That is, since every
    bit of the input files matters, any slight alteration to the input files could
    either lose important information or add redundant information for the neural
    network model to learn.
  id: totrans-454
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 就我们而言，这是由于模糊测试的性质。也就是说，由于每一位输入文件都很重要，任何对输入文件的轻微修改可能会导致神经网络模型学习丢失重要信息或添加冗余信息。
- en: Indication 10.2:   Evaluation criteria should be chosen carefully when judging
    mutation.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 10.2：在判断变异时，评估标准应谨慎选择。
- en: 'Input files are always used as training samples regarding using Deep Learning
    technique in fuzzing problems. Through this similar action, researchers have a
    common desire to let the neural network mode learn how the mutated input files
    should look like. But the criterion of judging a input file actually has two levels:
    on the one hand, a good input file should be correct in syntax and semantics;
    on the other hand, a good input file should be the product of a useful mutation,
    which triggers the program to behave differently from previous execution path.
    This idea of a fuzzer that can generate semantically correct input file could
    still be a bad fuzzer at triggering new execution path was first brought up in
    Learn&Fuzz[[21](#bib.bib21)]. We could see later on works trying to solve this
    problem by using either different training labels[[53](#bib.bib53)] or use neural
    network to do program smoothing[[20](#bib.bib20)]. We encouraged fuzzing researchers,
    when using Deep Learning techniques, to keep this problem in mind, in order to
    get better fuzzing results.'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 输入文件通常被用作在模糊测试问题中使用深度学习技术的训练样本。通过这一类似的操作，研究人员希望让神经网络模型学习变异后的输入文件应有的样子。但判断输入文件的标准实际上有两个层次：一方面，好的输入文件在语法和语义上应是正确的；另一方面，好的输入文件应是有用变异的产物，这种变异会使程序的行为与先前执行路径不同。这个能够生成语义正确输入文件的模糊测试器仍可能在触发新执行路径时表现不佳的想法首次在
    Learn&Fuzz[[21](#bib.bib21)] 中提出。后来的一些研究尝试通过使用不同的训练标签[[53](#bib.bib53)]或使用神经网络进行程序平滑[[20](#bib.bib20)]来解决这个问题。我们鼓励模糊测试研究人员在使用深度学习技术时牢记这个问题，以获得更好的模糊测试结果。
- en: Indication 10.3:   Works in our survey only focus on local knowledge.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 指示 10.3：我们调查中的工作仅关注局部知识。
- en: In brief, some of the existing works [[20](#bib.bib20), [53](#bib.bib53)] leveraged
    the Deep Learning model to learn the relation between program’s input and its
    behavior and used the knowledge that learned from history to guide future mutation.
    For better demonstration, we defined the knowledge that only applied in one program
    as local knowledge. In other words, this indicates that the local knowledge cannot
    direct fuzzing on other programs.
  id: totrans-458
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 简言之，一些现有的工作[[20](#bib.bib20), [53](#bib.bib53)]利用深度学习模型学习程序输入与其行为之间的关系，并使用从历史中获得的知识来指导未来的变异。为了更好地展示这一点，我们将只应用于一个程序的知识定义为局部知识。换句话说，这意味着局部知识不能指导对其他程序的模糊测试。
- en: 10.3 Discussion
  id: totrans-459
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 10.3 讨论
- en: Corresponding to the problems conventional fuzzing has, the advantages of applying
    DL in fuzzing are that DL’s learning ability can ensure mutated input files follow
    the designated grammar rules better. The ways in which input files are generated
    are more directed, and will, therefore, guarantee the fuzzer to increase its code
    coverage by each mutation. However, even if the advantages can be clearly demonstrated
    by the two papers we discuss above, some challenges still exist, including mutation
    judgment challenges that are faced both by traditional fuzzing techniques and
    fuzzing with DL, and the scalability of fuzzing approaches.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 针对传统模糊测试所面临的问题，应用深度学习（DL）在模糊测试中的优势在于，深度学习的学习能力可以确保变异的输入文件更好地遵循指定的语法规则。输入文件的生成方式更加有针对性，因此可以保证模糊测试器通过每次变异增加代码覆盖率。然而，即使上述讨论的两篇论文可以清楚地展示这些优势，仍然存在一些挑战，包括传统模糊测试技术和深度学习模糊测试都面临的变异判断挑战，以及模糊测试方法的可扩展性问题。
- en: 'We would like to raise several interesting questions for the future researchers:
    1) Can the knowledge learned from the fuzzing history of one program be applied
    to direct testing on other programs? 2) If the answer to question one is positive,
    we can suppose that global knowledge across different programs exists? Then, can
    we train a model to extract the global knowledge? 3) Whether it is possible to
    combine global knowledge and local knowledge when fuzzing programs?'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想提出几个供未来研究者思考的有趣问题：1）从一个程序的模糊测试历史中学到的知识能否应用于其他程序的直接测试？2）如果第一个问题的答案是肯定的，我们是否可以假设存在跨程序的全球知识？那么，我们能否训练一个模型来提取全球知识？3）在对程序进行模糊测试时，是否可以将全球知识和本地知识结合起来？
- en: 11 Discussion
  id: totrans-462
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 11 讨论
- en: 'Using high-quality data in Deep Learning is important as much as using well-structured
    deep neural network architectures. That is, obtaining quality data must be an
    important step, which should not be skipped, even in resolving security problems
    using Deep Learning. So far, this study demonstrated how the recent security papers
    using Deep Learning have adopted data conversion (Phase [1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")) and data representation (Phase [1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.")) on different security problems. Our observations
    and indications showed a clear understanding of how security experts generate
    quality data when using Deep Learning.'
  id: totrans-463
  prefs: []
  type: TYPE_NORMAL
  zh: '在深度学习中使用高质量数据与使用结构良好的深度神经网络架构一样重要。也就是说，获得质量数据必须是一个重要步骤，即使在使用深度学习解决安全问题时也不能忽略。迄今为止，本研究展示了近期使用深度学习的安全论文如何在不同安全问题上采用数据转换（第[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")）和数据表示（第[1](#S2.F1 "Figure 1 ‣
    2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")）方法。我们的观察和指示清楚地显示了安全专家在使用深度学习时如何生成质量数据。'
- en: Since we did not review all the existing security papers using Deep Learning,
    the generality of observations and indications is somewhat limited. Note that
    our selected papers for review have been published recently at one of prestigious
    security and reliability conferences such as USENIX SECURITY, ACM CCS and so on [[9](#bib.bib9)]-[[42](#bib.bib42)], [[43](#bib.bib43),
    [44](#bib.bib44)], [[19](#bib.bib19), [48](#bib.bib48)], [[51](#bib.bib51)]-[[53](#bib.bib53)].
    Thus, our observations and indications help to understand how most security experts
    have used Deep Learning to solve the well-known eight security problems from program
    analysis to fuzzing.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
  zh: 由于我们没有审查所有使用深度学习的现有安全论文，因此观察和指示的普遍性有所限制。请注意，我们选定的审查论文最近发表在一些著名的安全与可靠性会议上，如USENIX
    SECURITY、ACM CCS等[[9](#bib.bib9)]-[[42](#bib.bib42)], [[43](#bib.bib43), [44](#bib.bib44)],
    [[19](#bib.bib19), [48](#bib.bib48)], [[51](#bib.bib51)]-[[53](#bib.bib53)]。因此，我们的观察和指示有助于了解大多数安全专家如何利用深度学习解决从程序分析到模糊测试的八大安全问题。
- en: 'Our observations show that we should transfer raw data to synthetic formats
    of data ready for resolving security problems using Deep Learning through data
    cleaning and data augmentation and so on. Specifically, we observe that Phases [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") and[1](#S2.F1 "Figure 1 ‣ 2.1
    Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") methods have mainly been used for the following
    purposes:'
  id: totrans-465
  prefs: []
  type: TYPE_NORMAL
  zh: '我们的观察显示，我们应该通过数据清洗和数据增强等方法，将原始数据转化为适合解决安全问题的合成数据格式。具体来说，我们观察到**阶段 [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")** 和 **[1](#S2.F1 "Figure 1 ‣ 2.1
    Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.")** 方法主要用于以下目的：'
- en: •
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To clean the raw data to make the neural network (NN) models easier to interpret
  id: totrans-467
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 清洗原始数据，使神经网络（NN）模型更容易解释
- en: •
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To reduce the dimensionality of data (e.g., principle component analysis (PCA),
    t-distributed stochastic neighbor embedding (t-SNE))
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 降低数据的维度（例如，主成分分析（PCA），t-分布随机邻域嵌入（t-SNE））
- en: •
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To scale input data (e.g., normalization)
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 扩展输入数据（例如，归一化）
- en: •
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To make NN models understand more complex relationships depending on security
    problems (e.g. memory graphs)
  id: totrans-473
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使NN模型能够理解依赖于安全问题的更复杂关系（例如，内存图）
- en: •
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To simply change various raw data formats into a vector format for NN models
    (e.g. one-hot encoding and word2vec embedding)
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 将各种原始数据格式转换为NN模型的向量格式（例如，独热编码和word2vec嵌入）
- en: 'In this following, we do further discuss the question, “What if Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") is skipped?”, rather than the
    question, “Is Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣
    2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") always
    necessary?”. This is because most of the selected papers do not consider Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") methods (76%), or adopt with no
    concrete reasoning (19%). Specifically, we demonstrate how Phase[1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") has been adopted according to eight security
    problems, different types of data, various models of NN and various outputs of
    NN models, in depth. Our key findings are summarized as follows:'
  id: totrans-476
  prefs: []
  type: TYPE_NORMAL
  zh: '在接下来的讨论中，我们将进一步探讨“如果跳过Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")会怎么样？”这个问题，而不是“Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")是否总是必要？”这个问题。这是因为大多数选定的论文并没有考虑Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法（76%），或者没有具体的理由（19%）。具体来说，我们详细展示了Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")如何根据八种安全问题、不同类型的数据、各种神经网络模型及其输出进行采用。我们的主要发现总结如下：'
- en: •
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to fit security domain knowledge into raw data has not been well-studied
    yet.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何将安全领域知识融入原始数据尚未得到很好的研究。
- en: •
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'While raw text data are commonly parsed after embedding, raw binary data are
    converted using various Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") methods.'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '尽管原始文本数据通常在嵌入后进行解析，原始二进制数据则通过各种Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法进行转换。'
- en: •
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Raw data are commonly converted into a vector format to fit well to a specific
    NN model using various Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") methods.'
  id: totrans-482
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '原始数据通常被转换为向量格式，以适应特定的神经网络模型，并使用各种Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法。'
- en: •
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Various Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") methods
    are used according to the relationship between output of security problem and
    output of NN models.'
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '根据安全问题的输出和NN模型的输出之间的关系，使用了各种阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 方法。'
- en: '11.1 What if Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") is skipped?'
  id: totrans-485
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '11.1 如果跳过了阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A
    four-phase workflow framework can summarize the existing works in a unified manner
    ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") 会怎样？'
- en: 'From the analysis results of our selected papers for review, we roughly classify
    Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") methods into the
    following four categories.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
  zh: '从我们选定的综述论文的分析结果来看，我们大致将阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 方法分类为以下四类。'
- en: •
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Embedding: The data conversion methods that intend to convert high-dimensional
    discrete variables into low-dimensional continuous vectors[[70](#bib.bib70)].'
  id: totrans-488
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 嵌入：旨在将高维离散变量转化为低维连续向量的数据转换方法[[70](#bib.bib70)]。
- en: •
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Parsing combined with embedding: The data conversion methods that constitute
    an input data into syntactic components in order to test conformability after
    embedding.'
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 解析结合嵌入：将输入数据转化为句法组件的数据转换方法，以便在嵌入后测试其符合性。
- en: •
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'One-hot encoding: A simple embedding where each data belonging to a specific
    category is mapped to a vector of $0$s and a single $1$. Here, the low-dimension
    transformed vector is not managed.'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一热编码：一种简单的嵌入方法，其中每个属于特定类别的数据被映射到一个由$0$s和一个$1$组成的向量。这里，低维转换向量未被管理。
- en: •
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Domain-specific data structures: A set of data conversion methods which generate
    data structures capturing domain-specific knowledge for different security problems,
    e.g., memory graphs[[19](#bib.bib19)].'
  id: totrans-494
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 特定领域的数据结构：一组生成捕获领域特定知识的数据结构的数据转换方法，适用于不同的安全问题，例如内存图[[19](#bib.bib19)]。
- en: 11.1.1 Findings on eight security problems
  id: totrans-495
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.1.1 关于八个安全问题的发现
- en: <svg   height="283.78" overflow="visible" version="1.1" width="479.8"><g transform="translate(0,283.78)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,94.69)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -6.52 179.25)" fill="#000000"
    stroke="#000000"><foreignobject width="13.05" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">PA</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 112.34 179.25)" fill="#000000" stroke="#000000"><foreignobject width="20.99"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">ROP</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 237.26 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="16.82" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CFI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 361.24 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="14.53" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">NA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -7.94 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">MC</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 109.52 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="26.64" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SEAD</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 238.07 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="15.2" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">MF</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 346.61 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="43.79" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FUZZING</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -73.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Embedding</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -91.46)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Parsing
    & Embedding</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 166.04
    -72.53)" fill="#000000" stroke="#000000"><g  transform="matrix(1 0 0 -1 0 3.365)"><g  transform="matrix(1
    0 0 1 0 6.73)"><g transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0
    0 -1 0 0)">One-hot</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    166.04 -90.47)" fill="#000000" stroke="#000000"><g transform="matrix(1 0 0 -1
    0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1 0 0 -1 0
    0)"><text transform="matrix(1 0 0 -1 0 0)">None</text></g></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 319.59 -72.53)" fill="#000000" stroke="#000000"><g transform="matrix(1
    0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Other</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g></g></svg>
  id: totrans-496
  prefs: []
  type: TYPE_NORMAL
  zh: <svg   height="283.78" overflow="visible" version="1.1" width="479.8"><g transform="translate(0,283.78)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,94.69)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -6.52 179.25)" fill="#000000"
    stroke="#000000"><foreignobject width="13.05" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">PA</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 112.34 179.25)" fill="#000000" stroke="#000000"><foreignobject width="20.99"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">ROP</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 237.26 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="16.82" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CFI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 361.24 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="14.53" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">NA</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -7.94 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">MC</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 109.52 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="26.64" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SEAD</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 238.07 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="15.2" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">MF</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 346.61 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="43.79" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">FUZZING</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -73.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">嵌入</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -91.46)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">解析与嵌入</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -72.53)" fill="#000000" stroke="#000000"><g  transform="matrix(1
    0 0 -1 0 3.365)"><g  transform="matrix(1 0 0 1 0 6.73)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">独热编码</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">无</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -72.53)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">其他</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform
- en: 'We observe that over 93% of the papers use one of the above-classified Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") methods. 7% of the papers do not
    use any of the above-classified methods, and these papers are mostly solving a
    software fuzzing problem. Specifically, we observe that 35% of the papers use
    a Category 1 (i.e. embedding) method; 30% of the papers use a Category 2 (i.e.
    parsing combined with embedding) method; 15% of the papers use a Category 3 (i.e.
    one-hot encoding) method; and 13% of the papers use a Category 4 (i.e. domain-specific
    data structures) method. Regarding why one-hot encoding is not widely used, we
    found that most security data include categorical input values, which are not
    directly analyzed by Deep Learning models.'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到，超过93%的论文使用了上述分类的 Phase [1](#S2.F1 "图 1 ‣ 2.1 四阶段定义 ‣ 2 四阶段工作流框架可以统一总结现有工作
    ‣ 使用深度学习解决计算机安全挑战：一项调查1footnote 11footnote 1本文作者按字母顺序列出。") 方法。7%的论文没有使用上述分类的方法，这些论文主要解决软件模糊测试问题。具体来说，我们观察到35%的论文使用了类别1（即嵌入）方法；30%的论文使用了类别2（即解析结合嵌入）方法；15%的论文使用了类别3（即独热编码）方法；而13%的论文使用了类别4（即领域特定数据结构）方法。关于为何独热编码不广泛使用，我们发现大多数安全数据包含分类输入值，这些值未被深度学习模型直接分析。
- en: 'From Figure  LABEL:fig:data2, we also observe that according to security problems,
    different Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2
    A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") methods
    are used. First, PA, ROP and CFI should convert raw data into a vector format
    using embedding because they commonly collect instruction sequence from binary
    data. Second, NA and SEAD use parsing combined with embedding because raw data
    such as the network traffic and system logs consist of the complex attributes
    with the different formats such as categorical and numerical input values. Third,
    we observe that MF uses various data structures because memory dumps from memory
    layout are unstructured. Fourth, fuzzing generally uses no data conversion since
    Deep Learning models are used to generate the new input data with the same data
    format as the original raw data. Finally, we observe that MC commonly uses one-hot
    encoding and embedding because malware binary and well-structured security log
    files include categorical, numerical and unstructured data in general. These observations
    indicate that type of data strongly influences on use of Phase[1](#S2.F1 "Figure
    1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can
    summarize the existing works in a unified manner ‣ Using Deep Learning to Solve
    Computer Security Challenges: A Survey1footnote 11footnote 1The authors of this
    paper are listed in alphabetic order.") methods. We also observe that only MF
    among eight security problems commonly transform raw data into well-structured
    data embedding a specialized security domain knowledge. This observation indicates
    that various conversion methods of raw data into well-structure data which embed
    various security domain knowledge are not yet studied in depth.'
  id: totrans-498
  prefs: []
  type: TYPE_NORMAL
  zh: '从图 LABEL:fig:data2 中，我们还观察到根据安全问题，使用了不同的阶段[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 方法。首先，PA、ROP 和 CFI 应将原始数据转换为向量格式，使用嵌入技术，因为它们通常从二进制数据中收集指令序列。其次，NA 和 SEAD
    结合使用解析和嵌入，因为网络流量和系统日志等原始数据具有不同格式的复杂属性，如类别型和数值型输入值。第三，我们观察到 MF 使用各种数据结构，因为内存转储来自内存布局的无结构数据。第四，模糊测试通常不使用数据转换，因为深度学习模型用于生成与原始数据格式相同的新输入数据。最后，我们观察到
    MC 通常使用独热编码和嵌入技术，因为恶意软件二进制文件和结构良好的安全日志文件通常包含类别型、数值型和无结构的数据。这些观察结果表明数据类型对阶段[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") 方法的使用有很大的影响。我们还观察到，在八种安全问题中，只有
    MF 常常将原始数据转换为嵌入特定安全领域知识的结构化数据。这一观察表明，将原始数据转换为嵌入各种安全领域知识的结构化数据的各种方法尚未被深入研究。'
- en: 11.1.2 Findings on different data types
  id: totrans-499
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.1.2 关于不同数据类型的发现
- en: <svg   height="198.98" overflow="visible" version="1.1" width="548.04"><g transform="translate(0,198.98)
    matrix(1 0 0 -1 0 0) translate(39.76,0) translate(0,22.48)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -39.76 -22.48)"><g  transform="matrix(1
    0 0 1 0 0) translate(98.34,0) translate(0,22.48)"><g stroke="#000000" fill="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -27.44 -17.1)" fill="#000000"
    stroke="#000000"><foreignobject width="54.58" height="9.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Embedding</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 46.53 -17.1)" fill="#000000" stroke="#000000"><foreignobject width="102.49"
    height="9.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Parsing &
    Embdding</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 175.6 -17.1)"
    fill="#000000" stroke="#000000"><foreignobject width="39.36" height="7.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">One-hot</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 280.47 -16.97)" fill="#000000" stroke="#000000"><foreignobject width="24.91"
    height="7.56" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">None</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 374.22 -17.1)" fill="#000000" stroke="#000000"><foreignobject
    width="32.69" height="7.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Others</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -67.62 -3.57)" fill="#000000" stroke="#000000"><foreignobject
    width="5.53" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 22.91)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 49.39)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 75.88)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$60$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 102.36)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$80$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -78.69 128.84)" fill="#000000" stroke="#000000"><foreignobject
    width="16.6" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -19.66 72.22)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$51.9$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 84.98 3.51)" fill="#3284A3" stroke="#3284A3" color="#3284A3"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 175.63 33.03)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$22.3$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 273.27 23.23)" fill="#3284A3" stroke="#3284A3" color="#3284A3"><foreignobject
    width="18.83" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.9$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 370.91 18.33)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$11.2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 7.82 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.46 125.85)" fill="#F5C85F" stroke="#F5C85F"
    color="#F5C85F"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$92.4$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 203.1 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 296.17 13.57)" fill="#F5C85F" stroke="#F5C85F"
    color="#F5C85F"><foreignobject width="13.99" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$7.6$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 398.39 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -87.85 23.73)" fill="#000000" stroke="#000000"><foreignobject
    width="87.37" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">PERCENTAGE
    (%)</foreignobject></g><g fill="#FFFFFF" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 380.89 144.35)"><g  transform="matrix(1 0 0 -1 0 21.825)"><g  transform="matrix(1
    0 0 1 0 7.28)"><g transform="matrix(1 0 0 -1 13.01 0) translate(12.23,0) matrix(1.0
    0.0 0.0 1.0 3.04 -3.06)" fill="#000000" stroke="#000000"><foreignobject width="32.78"
    height="9.72" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Binary</foreignobject></g></g><g
    transform="matrix(1 0 0 1 0 21.83)"><g transform="matrix(1 0 0 -1 13.01 0) translate(12.23,0)
    matrix(1.0 0.0 0.0 1.0 3.04 -3.06)" fill="#000000" stroke="#000000"><foreignobject
    width="22.14" height="7.56" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Text</foreignobject></g></g></g></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g></g></svg>
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
  zh: <svg   height="198.98" overflow="visible" version="1.1" width="548.04"><g transform="translate(0,198.98)
    matrix(1 0 0 -1 0 0) translate(39.76,0) translate(0,22.48)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -39.76 -22.48)"><g  transform="matrix(1
    0 0 1 0 0) translate(98.34,0) translate(0,22.48)"><g stroke="#000000" fill="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -27.44 -17.1)" fill="#000000"
    stroke="#000000"><foreignobject width="54.58" height="9.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">嵌入</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 46.53 -17.1)" fill="#000000" stroke="#000000"><foreignobject width="102.49"
    height="9.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">解析与嵌入</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 175.6 -17.1)" fill="#000000" stroke="#000000"><foreignobject
    width="39.36" height="7.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">一热编码</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 280.47 -16.97)" fill="#000000" stroke="#000000"><foreignobject
    width="24.91" height="7.56" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">无</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 374.22 -17.1)" fill="#000000" stroke="#000000"><foreignobject
    width="32.69" height="7.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">其他</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -67.62 -3.57)" fill="#000000" stroke="#000000"><foreignobject
    width="5.53" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 22.91)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 49.39)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 75.88)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$60$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.16 102.36)" fill="#000000" stroke="#000000"><foreignobject
    width="11.07" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$80$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -78.69 128.84)" fill="#000000" stroke="#000000"><foreignobject
    width="16.6" height="7.13" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -19.66 72.22)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$51.9$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 84.98 3.51)" fill="#3284A3" stroke="#3284A3" color="#3284A3"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 175.63 33.03)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$22.3$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 273.27 23.23)" fill="#3284A3" stroke="#3284A3" color="#3284A3"><foreignobject
    width="18.83" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.9$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 370.91 18.33)" fill="#3284A3" stroke="#3284A3"
    color="#3284A3"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$11.2$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 7.82 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.46 125.85)" fill="#F5C85F" stroke="#F5C85F"
    color="#F5C85F"><foreignobject width="18.83" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$92.4$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 203.1 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$0$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 296.17 13.57)" fill="#F5C85F" stroke="#F5C85F"
    color="#F5C85F"><foreignobject width="13.99" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$7.6$</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 398.39 3.51)" fill="#F5C85F" stroke="#F5C85F" color="#F5C85F"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$
- en: 'Note that according to types of data, a NN model works better than the others.
    For example, CNN works well with images but does not work with text. From Figure
     LABEL:fig:data1-2 for raw binary data, we observe that 51.9%, 22.3% and 11.2%
    of security papers use embedding, one-hot encoding and $Others$, respectively.
    Only 14.9% of security papers, especially related to fuzzing, do not use one of
    Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") methods. This observation
    indicates that binary input data which have various binary formats should be converted
    into an input data type which works well with a specific NN model. From FigureLABEL:fig:data1-2
    for raw text data, we also observe that 92.4% of papers use parsing with embedding
    as the Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") method. Note that
    compared with raw binary data whose formats are unstructured, raw text data generally
    have the well-structured format. Raw text data collected from network traffics
    may also have various types of attribute values. Thus, raw text data are commonly
    parsed after embedding to reduce redundancy and dimensionality of data.'
  id: totrans-501
  prefs: []
  type: TYPE_NORMAL
  zh: '注意到根据数据类型，神经网络（NN）模型的效果优于其他模型。例如，卷积神经网络（CNN）在处理图像时效果良好，但在处理文本时效果较差。从图 LABEL:fig:data1-2
    中的原始二进制数据，我们观察到51.9%、22.3%和11.2%的安全论文分别使用了嵌入、独热编码和$Others$。只有14.9%的安全论文，特别是与模糊测试相关的论文，没有使用Phase
    [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow
    framework can summarize the existing works in a unified manner ‣ Using Deep Learning
    to Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法。这一观察结果表明，具有各种二进制格式的二进制输入数据应转换为适合特定神经网络模型的输入数据类型。从图LABEL:fig:data1-2
    中的原始文本数据，我们还观察到92.4%的论文使用了带有嵌入的解析作为Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法。注意到，与格式不结构化的原始二进制数据相比，原始文本数据通常具有良好的结构化格式。从网络流量中收集的原始文本数据也可能具有各种类型的属性值。因此，原始文本数据通常在嵌入后进行解析，以减少数据的冗余和维度。'
- en: 11.1.3 Findings on various models of NN
  id: totrans-502
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.1.3 各种神经网络模型的发现
- en: <svg   height="159.95" overflow="visible" version="1.1" width="561.7"><g transform="translate(0,159.95)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,93.7)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -23.47 56.3)" fill="#000000"
    stroke="#000000"><foreignobject width="46.68" height="8.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Embdeeing</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 65.2 56.3)" fill="#000000" stroke="#000000"><foreignobject width="94.52"
    height="8.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Parsing &
    Embddding</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 207.98 56.3)"
    fill="#000000" stroke="#000000"><foreignobject width="34.44" height="6.73" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">One-hot</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 326.9 56.41)" fill="#000000" stroke="#000000"><foreignobject width="21.79"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">None</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 436.09 56.3)" fill="#000000" stroke="#000000"><foreignobject
    width="28.6" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Others</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">DNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">CNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">RNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">LSTM</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">GNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">SNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 421.95 -72.53)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Combination</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 421.95 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">DBN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.14 0.86)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$42.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4 -27.82)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$28.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 9.74 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.67 25.01)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4.72 32.25)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 84.6 17.34)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.83 -4.88)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.75 -30.21)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 124.26 -17.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.72 29.78)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.83 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 210.18 -30.39)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.6 -4.56)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.55 17.5)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 -25.51)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g></g></svg><svg
    height="283.78" overflow="visible" version="1.1" width="444.18"><g transform="translate(0,283.78)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,94.69)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -10.96 179.25)" fill="#000000"
    stroke="#000000"><foreignobject width="21.93" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">DNN</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 101.84 179.25)" fill="#000000" stroke="#000000"><foreignobject width="21.52"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 214.37 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="21.66" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">RNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 324.14 179.25)" fill="#000000" stroke="#000000"><foreignobject
    width="27.31" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">LSTM</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -11.06 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="22.13" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">GNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 102.64 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="19.91" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SNN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 197.89 56.3)" fill="#000000" stroke="#000000"><foreignobject
    width="54.89" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Combination</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 327.03 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.52" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">DBN</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -73.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Embedding</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -91.46)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Parsing
    & Embddding</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 166.04
    -73.47)" fill="#000000" stroke="#000000"><g  transform="matrix(1 0 0 -1 0 4.305)"><g  transform="matrix(1
    0 0 1 0 6.73)"><g transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0
    0 -1 0 0)">One-hot encoding</text></g></g></g></g><g transform="matrix(1.0 0.0
    0.0 1.0 166.04 -90.47)" fill="#000000" stroke="#000000"><g transform="matrix(1
    0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1 0
    0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">None</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -72.53)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Others</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.14 0.86)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$42.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4 -27.82)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$28.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 9.74 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.67 25.01)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4.72 32.25)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 84.6 17.34)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.83 -4.88)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.75 -30.21)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 124.26 -17.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.72 29.78)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.83 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 210.18 -30.39)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.6 -4.56)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.55 17.5)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 -25.51)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.51 114.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$54.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 4.22 101.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 8.04 128.78)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -3.26 151.11)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$9.1\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.87 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.61 118.11)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.69 140.26)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 306.12 137.59)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$22.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.51 94.04)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 332.78 146.83)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$11.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -36.2 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 14.98 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 76.4 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 127.58 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 324.77 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g></g></svg>
  id: totrans-503
  prefs: []
  type: TYPE_NORMAL
  zh: <svg   height="159.95" overflow="visible" version="1.1" width="561.7"><g transform="translate(0,159.95)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,93.7)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -23.47 56.3)" fill="#000000"
    stroke="#000000"><foreignobject width="46.68" height="8.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">嵌入</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 65.2 56.3)" fill="#000000" stroke="#000000"><foreignobject width="94.52"
    height="8.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">解析和嵌入</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 207.98 56.3)" fill="#000000" stroke="#000000"><foreignobject
    width="34.44" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">单热编码</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 326.9 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.79" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">无</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 436.09 56.3)" fill="#000000" stroke="#000000"><foreignobject
    width="28.6" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">其他</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">DNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">CNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">RNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">LSTM</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">GNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 319.59 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">SNN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 421.95 -72.53)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">组合</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 421.95 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">DBN</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.14 0.86)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$42.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4 -27.82)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$28.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 9.74 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.67 25.01)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4.72 32.25)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 84.6 17.34)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.83 -4.88)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.75 -30.21)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 124.26 -17.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.72 29.78)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.83 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 210.18 -30.39)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.6 -4.56)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.55 17.5)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 -25.51)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0
- en: 'According to types of the converted data, a specific NN model works better
    than the others. For example, CNN works well with images but does not work with
    raw text. From Figure  LABEL:fig:data1-3, we observe that use of embedding for
    DNN (42.9%), RNN (28.6%) and LSTM (14.3%) models approximates to 85%. This observation
    indicates that embedding methods are commonly used to generate sequential input
    data for DNN, RNN and LSTM models. Also, we observe that one-hot encoded data
    are commonly used as input data for DNN (33.4%), CNN (33.4%) and LSTM (16.7%)
    models. This observation indicates that one-hot encoding is one of common Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") methods to generate numerical
    values for image and sequential input data because many raw input data for security
    problems commonly have the categorical features. We observe that the CNN (66.7%)
    model uses the converted input data using the $Others$ methods to express the
    specific domain knowledge into the input data structure of NN networks. This is
    because general vector formats including graph, matrix and so on can also be used
    as an input value of the CNN model.'
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
  zh: 根据转换数据的类型，某些神经网络（NN）模型比其他模型表现更好。例如，卷积神经网络（CNN）在图像处理上效果很好，但对原始文本不适用。从图 LABEL:fig:data1-3中，我们观察到嵌入方法在DNN（42.9%）、RNN（28.6%）和LSTM（14.3%）模型中的使用接近85%。这一观察结果表明，嵌入方法通常用于生成DNN、RNN和LSTM模型的序列输入数据。此外，我们还观察到独热编码数据常作为DNN（33.4%）、CNN（33.4%）和LSTM（16.7%）模型的输入数据。这表明，独热编码是生成图像和序列输入数据的常见方法之一，因为许多安全问题的原始输入数据通常具有分类特征。我们还观察到CNN（66.7%）模型使用$Others$方法转换的输入数据将特定领域知识表达到神经网络的输入数据结构中。这是因为包括图、矩阵等在内的一般向量格式也可以作为CNN模型的输入值。
- en: <svg   height="142.96" overflow="visible" version="1.1" width="561.7"><g transform="translate(0,142.96)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,76.7)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -24.01 56.3)" fill="#000000"
    stroke="#000000"><foreignobject width="47.76" height="8.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Embedding</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 65.2 56.3)" fill="#000000" stroke="#000000"><foreignobject width="94.52"
    height="8.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Parsing &
    Embddding</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 187.66 56.3)"
    fill="#000000" stroke="#000000"><foreignobject width="74.8" height="8.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">One-hot encoding</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 326.9 56.41)" fill="#000000" stroke="#000000"><foreignobject width="21.79"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">None</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 436.09 56.3)" fill="#000000" stroke="#000000"><foreignobject
    width="28.6" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Others</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 12.5 -72.48)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Data Generation</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 166.04 -73.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Object
    Detection</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 319.59 -72.53)"
    fill="#000000" stroke="#000000"><g  transform="matrix(1 0 0 -1 0 3.365)"><g  transform="matrix(1
    0 0 1 0 6.73)"><g transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0
    0 -1 0 0)">Classification</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0
    1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject width="26.06"
    height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.14 0.86)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$42.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4 -27.82)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$28.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 9.74 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.67 25.01)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4.72 32.25)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 84.6 17.34)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.83 -4.88)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.75 -30.21)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 124.26 -17.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.72 29.78)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.83 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 210.18 -30.39)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.6 -4.56)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.55 17.5)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 -25.51)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.51 114.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$54.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 4.22 101.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 8.04 128.78)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -3.26 151.11)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$9.1\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.87 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.61 118.11)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.69 140.26)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 306.12 137.59)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$22.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.51 94.04)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 332.78 146.83)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$11.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -36.2 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 14.98 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 76.4 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 127.58 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 324.77 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 72.69 -11.4)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$58.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 122.14 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 302.85 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$60\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g></g></svg><svg
    height="160.95" overflow="visible" version="1.1" width="329.22"><g transform="translate(0,160.95)
    matrix(1 0 0 -1 0 0) translate(52.01,0) translate(0,94.69)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -28.17 56.3)" fill="#000000"
    stroke="#000000"><foreignobject width="56.34" height="6.73" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Classification</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 76.21 56.3)" fill="#000000" stroke="#000000"><foreignobject width="72.24"
    height="8.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Object Detection</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 189.7 56.41)" fill="#000000" stroke="#000000"><foreignobject
    width="70.99" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Data
    Generation</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -13.09 -73.47)"
    fill="#000000" stroke="#000000"><g transform="matrix(1 0 0 -1 0 4.305)"><g  transform="matrix(1
    0 0 1 0 6.73)"><g  transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1
    0 0 -1 0 0)">Embedding</text></g></g></g></g><g transform="matrix(1.0 0.0 0.0
    1.0 -13.09 -91.46)" fill="#000000" stroke="#000000"><g transform="matrix(1 0 0
    -1 0 4.305)"><g transform="matrix(1 0 0 1 0 6.73)"><g transform="matrix(1 0 0
    -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Parsing & Embddding</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 114.86 -73.47)" fill="#000000" stroke="#000000"><g  transform="matrix(1
    0 0 -1 0 4.305)"><g  transform="matrix(1 0 0 1 0 6.73)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">One-hot encoding</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 114.86 -90.47)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.31)"><g transform="matrix(1 0 0 1 0 6.62)"><g transform="matrix(1
    0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">None</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 217.22 -72.53)" fill="#000000" stroke="#000000"><g
    transform="matrix(1 0 0 -1 0 3.365)"><g transform="matrix(1 0 0 1 0 6.73)"><g
    transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1 0 0 -1 0 0)">Others</text></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 85.5 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 129.76 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 208.34 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 252.6 130.92)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 355.47 92.44)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -39.91 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 2.97 -22.84)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -2.5 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 94.9 -26.99)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$83.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.33 17.42)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 232.64 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.13 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 375.55 -17.48)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.14 0.86)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$42.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4 -27.82)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$28.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 9.74 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.67 25.01)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -4.72 32.25)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$7.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 84.6 17.34)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 71.83 -4.88)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 74.75 -30.21)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 124.26 -17.41)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.72 29.78)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$8.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.83 7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 210.18 -30.39)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.6 -4.56)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.55 17.5)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 312.15 -25.51)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$40\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.51 114.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$54.6\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 4.22 101.35)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 8.04 128.78)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -3.26 151.11)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$9.1\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 83.9 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 99.94)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.09 136.13)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$25\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.87 105.21)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 235.61 118.11)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 222.69 140.26)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$16.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 306.12 137.59)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$22.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 331.51 94.04)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 332.78 146.83)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$11.2\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -36.2 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 14.98 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 76.4 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 127.58 -4.8)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$50\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 324.77 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -13.03 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 72.69 -11.4)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$58.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 122.14 1.79)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$41.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 302.85 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$60\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 351.53 -12.71)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 342.23 15.9)" fill="#000000" stroke="#000000"><foreignobject
    width="21.22" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$20\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 413.06 -17.62)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$66.7\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 457.32 8.08)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$33.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -40.29 0.15)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$43.8\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -7.66 -29.26)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$21.9\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 10.41 -4.64)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$18.8\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 8.49 21.56)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$9.4\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -5.47 34.09)" fill="#000000" stroke="#000000"><foreignobject
    width="25.52" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$6.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 77.44 -20.8)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$71.5\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 122.34 1.01)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 108.38 18.32)" fill="#000000" stroke="#000000"><foreignobject
    width="30.36" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$14.3\%$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 212.17 -30.4)" fill="#000000" stroke="#000000"><foreignobject
    width="26.06" height="11.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$100\%$</foreignobject></g></g></svg>
  id: totrans-505
  prefs: []
  type: TYPE_NORMAL
- en: 'From Figure  LABEL:fig:data1-4, we observe that DNN, RNN and LSTM models commonly
    use embedding, one-hot encoding and parsing combined with embedding. For example,
    we observe security papers of 54.6%, 18.2% and 18.2% models use embedding, one-hot
    encoding and parsing combined with embedding, respectively. We also observe that
    the CNN model is used with various Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") methods because any vector formats such as image can generally be used
    as an input data of the CNN model.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
  zh: '从图 LABEL:fig:data1-4中，我们观察到DNN、RNN和LSTM模型通常使用嵌入、独热编码和与嵌入结合的解析。例如，我们观察到54.6%、18.2%和18.2%的安全论文模型分别使用嵌入、独热编码和与嵌入结合的解析。我们还观察到CNN模型与各种Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法一起使用，因为任何向量格式，如图像，通常可以用作CNN模型的输入数据。'
- en: 11.1.4 Findings on output of NN models
  id: totrans-507
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 11.1.4 神经网络模型输出的发现
- en: 'According to the relationship between output of security problem and output
    of NN, we may use a specific Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the
    four phases ‣ 2 A four-phase workflow framework can summarize the existing works
    in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") method. For example, if output of security problem is given into a class
    (e.g., normal or abnormal), output of NN should also be given into classification.'
  id: totrans-508
  prefs: []
  type: TYPE_NORMAL
  zh: '根据安全问题的输出与神经网络输出之间的关系，我们可以使用特定的Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions
    of the four phases ‣ 2 A four-phase workflow framework can summarize the existing
    works in a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.")方法。例如，如果安全问题的输出被归入一个类别（例如，正常或异常），则神经网络的输出也应被归入分类。'
- en: 'From Figure  LABEL:fig:data1-5, we observe that embedding is commonly used
    to support a security problem for classification (100%). Parsing combined with
    embedding is used to support a security problem for object detection (41.7%) and
    classification (58.3%). One-hot encoding is used only for classification (100%).
    These observations indicate that classification of a given input data is the most
    common output which is obtained using Deep Learning under various Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") methods.'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
  zh: '从图 LABEL:fig:data1-5中，我们观察到嵌入通常用于支持分类任务的安全问题（100%）。解析结合嵌入用于支持目标检测（41.7%）和分类（58.3%）的安全问题。独热编码仅用于分类任务（100%）。这些观察结果表明，在各种Phase [1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.")方法下，给定输入数据的分类是最常见的输出。'
- en: 'From Figure LABEL:fig:data1-6, we observe that security problems, whose outputs
    are classification, commonly use embedding (43.8%) and parsing combined with embedding
    (21.9%) as the Phase [1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases
    ‣ 2 A four-phase workflow framework can summarize the existing works in a unified
    manner ‣ Using Deep Learning to Solve Computer Security Challenges: A Survey1footnote
    11footnote 1The authors of this paper are listed in alphabetic order.") method.
    We also observe that security problems, whose outputs are object detection, commonly
    use parsing combined with embedding (71.5%). However, security problems, whose
    outputs are data generation, commonly do not use the Phase[1](#S2.F1 "Figure 1
    ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework can summarize
    the existing works in a unified manner ‣ Using Deep Learning to Solve Computer
    Security Challenges: A Survey1footnote 11footnote 1The authors of this paper are
    listed in alphabetic order.") methods. These observations indicate that a specific
    Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") method has been used
    according to the relationship between output of security problem and use of NN
    models.'
  id: totrans-510
  prefs: []
  type: TYPE_NORMAL
  zh: '从图 LABEL:fig:data1-6 中我们观察到，输出为分类的安全问题通常使用嵌入（43.8%）和与嵌入结合的解析（21.9%）作为 Phase[1](#S2.F1
    "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase workflow framework
    can summarize the existing works in a unified manner ‣ Using Deep Learning to
    Solve Computer Security Challenges: A Survey1footnote 11footnote 1The authors
    of this paper are listed in alphabetic order.") 方法。我们还观察到，输出为对象检测的安全问题通常使用与嵌入结合的解析（71.5%）。然而，输出为数据生成的安全问题通常不使用
    Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four phases ‣ 2 A four-phase
    workflow framework can summarize the existing works in a unified manner ‣ Using
    Deep Learning to Solve Computer Security Challenges: A Survey1footnote 11footnote
    1The authors of this paper are listed in alphabetic order.") 方法。这些观察表明，根据安全问题的输出与
    NN 模型的使用之间的关系，已使用了特定的 Phase[1](#S2.F1 "Figure 1 ‣ 2.1 Definitions of the four
    phases ‣ 2 A four-phase workflow framework can summarize the existing works in
    a unified manner ‣ Using Deep Learning to Solve Computer Security Challenges:
    A Survey1footnote 11footnote 1The authors of this paper are listed in alphabetic
    order.") 方法。'
- en: 12 Further areas of investigation
  id: totrans-511
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 12 进一步的研究领域
- en: Since any Deep Learning models are stochastic, each time the same Deep Learning
    model is fit even on the same data, it might give different outcomes. This is
    because deep neural networks use random values such as random initial weights.
    However, if we have all possible data for every security problem, we may not make
    random predictions. Since we have the limited sample data in practice, we need
    to get the best-effort prediction results using the given Deep Learning model,
    which fits to the given security problem.
  id: totrans-512
  prefs: []
  type: TYPE_NORMAL
  zh: 由于任何深度学习模型都是随机的，即使在相同的数据上拟合相同的深度学习模型，也可能会得到不同的结果。这是因为深度神经网络使用了随机值，例如随机的初始权重。然而，如果我们拥有每个安全问题的所有可能数据，我们可能不会做出随机预测。由于实际中样本数据有限，我们需要使用给定的深度学习模型来获得最佳的预测结果，以适应给定的安全问题。
- en: How can we get the best-effort prediction results of Deep Learning models for
    different security problems? Let us begin to discuss about the stability of evaluation
    results for our selected papers for review. Next, we will show the influence of
    security domain knowledge on prediction results of Deep Learning models. Finally,
    we will discuss some common issues in those fields.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
  zh: 我们如何获得不同安全问题的深度学习模型的最佳预测结果？让我们首先讨论我们选择的论文的评估结果的稳定性。接下来，我们将展示安全领域知识对深度学习模型预测结果的影响。最后，我们将讨论这些领域的一些常见问题。
- en: 12.1 How stable are evaluation results?
  id: totrans-514
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.1 评估结果的稳定性如何？
- en: 'When evaluating neural network models, Deep Learning models commonly use three
    methods: train-test split; train-validation-test split; and $k$-fold cross validation.
    A train-test split method splits the data into two parts, i.e., training and test
    data. Even though a train-test split method makes the stable prediction with a
    large amount of data, predictions vary with a small amount of data. A train-validation-test
    split method splits the data into three parts, i.e., training, validation and
    test data. Validation data are used to estimate predictions over the unknown data.
    $k$-fold cross validation has $k$ different set of predictions from $k$ different
    evaluation data. Since $k$-fold cross validation takes the average expected performance
    of the NN model over $k$-fold validation data, the evaluation result is closer
    to the actual performance of the NN model.'
  id: totrans-515
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估神经网络模型时，深度学习模型通常使用三种方法：训练-测试拆分；训练-验证-测试拆分；和 $k$-折交叉验证。训练-测试拆分方法将数据分为两部分，即训练数据和测试数据。尽管训练-测试拆分方法在大量数据上可以提供稳定的预测，但在少量数据上，预测结果会有所不同。训练-验证-测试拆分方法将数据分为三部分，即训练数据、验证数据和测试数据。验证数据用于估计未知数据的预测。$k$-折交叉验证有
    $k$ 个不同的预测集，来自 $k$ 个不同的评估数据。由于 $k$-折交叉验证对神经网络模型在 $k$ 折验证数据上的期望性能进行平均，因此评估结果更接近神经网络模型的实际性能。
- en: From the analysis results of our selected papers for review, we observe that
    40.0% and 32.5% of the selected papers are measured using a train-test split method
    and a train-validation-test split method, respectively. Only 17.5% of the selected
    papers are measured using $k$-fold cross validation. This observation implies
    that even though the selected papers show almost more than 99% of accuracy or
    0.99 of F1 score, most solutions using Deep Learning might not show the same performance
    for the noisy data with randomness.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
  zh: 从我们选择的论文的分析结果来看，我们观察到 40.0% 和 32.5% 的选定论文分别使用训练-测试拆分方法和训练-验证-测试拆分方法。仅有 17.5%
    的选定论文使用 $k$-折交叉验证。这一观察结果表明，即使选定论文显示了超过 99% 的准确率或 0.99 的 F1 分数，大多数使用深度学习的解决方案可能在随机噪声数据上无法展示相同的性能。
- en: 'To get stable prediction results of Deep Learning models for different security
    problems, we might reduce the influence of the randomness of data on Deep Learning
    models. At least, it is recommended to consider the following methods:'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
  zh: 为了获得不同安全问题的深度学习模型的稳定预测结果，我们可能需要减少数据随机性对深度学习模型的影响。至少，建议考虑以下方法：
- en: •
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Do experiments using the same data many time: To get a stable prediction with
    a small amount of sample data, we might control the randomness of data using the
    same data many times.'
  id: totrans-519
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用相同的数据进行多次实验：为了从少量样本数据中获得稳定的预测，我们可能需要多次使用相同的数据以控制数据的随机性。
- en: •
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Use cross validation methods, e.g. $k$-fold cross validation: The expected
    average and variance from $k$-fold cross validation estimates how stable the proposed
    model is.'
  id: totrans-521
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用交叉验证方法，例如 $k$-折交叉验证：$k$-折交叉验证的期望平均值和方差可以估计所提出模型的稳定性。
- en: 12.2 How does security domain knowledge influence the performance of security
    solutions using Deep Learning?
  id: totrans-522
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.2 安全领域知识如何影响使用深度学习的安全解决方案的性能？
- en: When selecting a NN model that analyzes an application dataset, e.g., MNIST
    dataset [[71](#bib.bib71)], we should understand that the problem is to classify
    a handwritten digit using a $28\times 28$ black. Also, to solve the problem with
    the high classification accuracy, it is important to know which part of each handwritten
    digit mainly influences the outcome of the problem, i.e., a domain knowledge.
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
  zh: 在选择分析应用数据集的神经网络模型时，例如 MNIST 数据集 [[71](#bib.bib71)]，我们应该了解问题是对 $28\times 28$
    黑白图像中的手写数字进行分类。此外，为了以高分类准确率解决问题，了解每个手写数字的哪一部分主要影响问题的结果，即领域知识，也很重要。
- en: 'While solving a security problem, knowing and using security domain knowledge
    for each security problem is also important due to the following reasons (we label
    the observations and indications that realted to domain knowledge with ‘$*$’):
    Firstly, the dataset generation, preprocess and feature selection highly depend
    on domain knowledge. Different from the image classification and natural language
    processing, raw data in the security domain cannot be sent into the NN model directly.
    Researchers need to adopt strong domain knowledge to generate, extract, or clean
    the training set. Also, in some works, domain knowledge is adopted in data labeling
    because labels for data samples are not straightforward.'
  id: totrans-524
  prefs: []
  type: TYPE_NORMAL
  zh: 在解决安全问题时，了解和使用每个安全问题的安全领域知识也很重要，原因如下（我们用‘$*$’标记与领域知识相关的观察和指示）：首先，数据集生成、预处理和特征选择高度依赖领域知识。与图像分类和自然语言处理不同，安全领域中的原始数据不能直接输入到神经网络模型中。研究人员需要采用强大的领域知识来生成、提取或清理训练集。此外，在一些工作中，领域知识也被用于数据标注，因为数据样本的标签并不直观。
- en: Secondly, domain knowledge helps with the selection of DL models and its hierarchical
    structure. For example, the neural network architecture (hierarchical and bi-directional
    LSTM) designed in DEEPVSA[[22](#bib.bib22)] is based on the domain knowledge in
    the instruction analysis.
  id: totrans-525
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，领域知识有助于选择深度学习模型及其层次结构。例如，DEEPVSA[[22](#bib.bib22)]中设计的神经网络架构（层次结构和双向LSTM）是基于指令分析中的领域知识。
- en: Thirdly, domain knowledge helps to speed up the training process. For instance,
    by adopting strong domain knowledge to clean the training set, domain knowledge
    helps to spend up the training process while keeping the same performance. However,
    due to the influence of the randomness of data on Deep Learning models, domain
    knowledge should be carefully adopted to avoid potential decreased accuracy.
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，领域知识有助于加速训练过程。例如，通过采用强大的领域知识来清理训练集，领域知识有助于在保持相同性能的同时加快训练过程。然而，由于数据的随机性对深度学习模型的影响，领域知识应谨慎使用，以避免潜在的准确性下降。
- en: Finally, domain knowledge helps with the interpretability of models’ prediction.
    Recently, researchers try to explore the interpretability of the deep learning
    model in security areas, For instance, LEMNA[[72](#bib.bib72)] and EKLAVYA[[10](#bib.bib10)]
    explain how the prediction was made by models from different perspectives. By
    enhancing the trained models‘ interpretability, they can improve their approaches’
    accuracy and security. The explanation for the relation between input, hidden
    state, and the final output is based on domain knowledge.
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: 最终，领域知识有助于模型预测的可解释性。最近，研究人员尝试探讨深度学习模型在安全领域的可解释性。例如，LEMNA[[72](#bib.bib72)] 和
    EKLAVYA[[10](#bib.bib10)] 从不同的角度解释了模型如何进行预测。通过提升训练模型的可解释性，它们可以提高方法的准确性和安全性。输入、隐藏状态和最终输出之间关系的解释基于领域知识。
- en: 12.3 Common challenges
  id: totrans-528
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.3 常见挑战
- en: 'In this section, we will discuss the common challenges when applying DL to
    solving security problems. These challenges as least shared by the majority of
    works, if not by all the works. Generally, we observe 7 common challenges in our
    survey:'
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将讨论在解决安全问题时应用深度学习的常见挑战。这些挑战至少被大多数工作所共享，如果不是所有工作的话。一般而言，我们在调查中观察到7个常见挑战：
- en: '1.'
  id: totrans-530
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The raw data collected from the software or system usually contains lots of
    noise.
  id: totrans-531
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从软件或系统收集的原始数据通常包含大量噪声。
- en: '2.'
  id: totrans-532
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'The collected raw is untidy. For instance, the instruction trace, the Untidy
    data: variable length sequences,'
  id: totrans-533
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 收集的原始数据是不整洁的。例如，指令跟踪，数据不整洁：变量长度的序列，
- en: '3.'
  id: totrans-534
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Hierarchical data syntactic/structure. As discussed in Section LABEL:sec:pa:dis,
    the information may not simply be encoded in a single layer, rather, it is encoded
    hierarchically, and the syntactic is complex.
  id: totrans-535
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 层次数据的语法/结构。如在第LABEL:sec:pa:dis节中讨论的，信息可能不是简单地编码在单层中，而是以层次方式编码，并且语法复杂。
- en: '4.'
  id: totrans-536
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Dataset generation is challenging in some scenarios. Therefore, the generated
    training data might be less representative or unbalanced.
  id: totrans-537
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在某些场景下，数据集生成具有挑战性。因此，生成的训练数据可能不具代表性或不平衡。
- en: '5.'
  id: totrans-538
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Different for the application of DL in image classification, and natural language
    process, which is visible or understandable, the relation between data sample
    and its label is not intuitive, and hard to explain.
  id: totrans-539
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 与图像分类和自然语言处理中的深度学习应用不同，数据样本与其标签之间的关系不是直观的，且难以解释。
- en: 12.4 Availability of trained model and quality of dataset.
  id: totrans-540
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 12.4 训练模型的可用性和数据集的质量。
- en: 'Finally, we investigate the availability of the trained model and the quality
    of the dataset. Generally, the availability of the trained models affects its
    adoption in practice, and the quality of the training set and the testing set
    will affect the credibility of testing results and comparison between different
    works. Therefore, we collect relevant information to answer the following four
    questions and shows the statistic in Table LABEL:tab:dataset:'
  id: totrans-541
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们调查了训练模型的可用性和数据集的质量。通常，训练模型的可用性会影响其在实际中的应用，而训练集和测试集的质量会影响测试结果的可信度以及不同工作之间的比较。因此，我们收集了相关信息以回答以下四个问题，并在表 LABEL:tab:dataset 中展示了统计数据：
- en: '1.'
  id: totrans-542
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Whether a paper’s source code is publicly available?
  id: totrans-543
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 论文的源代码是否公开？
- en: '2.'
  id: totrans-544
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Whether raw data, which is used to generate the dataset, is publicly available?
  id: totrans-545
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成数据集的原始数据是否公开？
- en: '3.'
  id: totrans-546
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Whether its dataset is publicly available?
  id: totrans-547
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其数据集是否公开可用？
- en: '4.'
  id: totrans-548
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: How are the quality of the dataset?
  id: totrans-549
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数据集的质量如何？
- en: '| Topic | Paper | Source Available | Raw Data Available¹ | Dataset Available²
    | Quality of Dataset |'
  id: totrans-550
  prefs: []
  type: TYPE_TB
  zh: '| 主题 | 论文 | 源代码可用 | 原始数据可用¹ | 数据集可用² | 数据集质量 |'
- en: '|  |  |  |  |  | Sample Num | Balance |'
  id: totrans-551
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  |  | 样本数量 | 平衡性 |'
- en: '| PA | RFBNN [[9](#bib.bib9)] | ✗ | ✓ | ✗ | N/A | N/A |'
  id: totrans-552
  prefs: []
  type: TYPE_TB
  zh: '| PA | RFBNN [[9](#bib.bib9)] | ✗ | ✓ | ✗ | N/A | N/A |'
- en: '| EKLAVYA [[10](#bib.bib10)] | ✗ | ✓ | ✗ | N/A | N/A |'
  id: totrans-553
  prefs: []
  type: TYPE_TB
  zh: '| EKLAVYA [[10](#bib.bib10)] | ✗ | ✓ | ✗ | N/A | N/A |'
- en: '| ROP | ROPNN [[11](#bib.bib11)] | ✗ | ✗ | ✗ | N/A | N/A |'
  id: totrans-554
  prefs: []
  type: TYPE_TB
  zh: '| ROP | ROPNN [[11](#bib.bib11)] | ✗ | ✗ | ✗ | N/A | N/A |'
- en: '| HeNet [[12](#bib.bib12)] | ✗ | ✗ | ✗ | N/A | N/A |'
  id: totrans-555
  prefs: []
  type: TYPE_TB
  zh: '| HeNet [[12](#bib.bib12)] | ✗ | ✗ | ✗ | N/A | N/A |'
- en: '| CFI | Barnum [[13](#bib.bib13)] | ✓ | ✗ | ✗ | N/A | N/A |'
  id: totrans-556
  prefs: []
  type: TYPE_TB
  zh: '| CFI | Barnum [[13](#bib.bib13)] | ✓ | ✗ | ✗ | N/A | N/A |'
- en: '| CFG-CNN [[14](#bib.bib14)] | ✓ | ✓ | ✗ | N/A | N/A |'
  id: totrans-557
  prefs: []
  type: TYPE_TB
  zh: '| CFG-CNN [[14](#bib.bib14)] | ✓ | ✓ | ✗ | N/A | N/A |'
- en: '| Network | 50b(yte)-CNN[[15](#bib.bib15)] | ✗ | ✓ | ✗ | 115835 | ✗ |'
  id: totrans-558
  prefs: []
  type: TYPE_TB
  zh: '| Network | 50b(yte)-CNN[[15](#bib.bib15)] | ✗ | ✓ | ✗ | 115835 | ✗ |'
- en: '| PCCN [[16](#bib.bib16)] | ✓ | ✓ | ✓ | 1168671 | ✗ |'
  id: totrans-559
  prefs: []
  type: TYPE_TB
  zh: '| PCCN [[16](#bib.bib16)] | ✓ | ✓ | ✓ | 1168671 | ✗ |'
- en: '| Malware | Rosenber [[17](#bib.bib17)] | ✗ | ✗ | ✗ | 500000 | ✓ |'
  id: totrans-560
  prefs: []
  type: TYPE_TB
  zh: '| Malware | Rosenber [[17](#bib.bib17)] | ✗ | ✗ | ✗ | 500000 | ✓ |'
- en: '| DeLaRosa [[18](#bib.bib18)] | ✗ | ✗ | ✗ | 100000 | ✗ |'
  id: totrans-561
  prefs: []
  type: TYPE_TB
  zh: '| DeLaRosa [[18](#bib.bib18)] | ✗ | ✗ | ✗ | 100000 | ✗ |'
- en: '| LogEvent | DeepLog [[8](#bib.bib8)] | P³ | ✓ | P | N/A | ✗ |'
  id: totrans-562
  prefs: []
  type: TYPE_TB
  zh: '| LogEvent | DeepLog [[8](#bib.bib8)] | P³ | ✓ | P | N/A | ✗ |'
- en: '| LogAnom [[41](#bib.bib41)] | ✗ | ✓ | P | N/A | ✗ |'
  id: totrans-563
  prefs: []
  type: TYPE_TB
  zh: '| LogAnom [[41](#bib.bib41)] | ✗ | ✓ | P | N/A | ✗ |'
- en: '| MemoryFoensic | DeepMem [[19](#bib.bib19)] | ✓ | ✓ | ✓ | N/A | ✗ |'
  id: totrans-564
  prefs: []
  type: TYPE_TB
  zh: '| MemoryFoensic | DeepMem [[19](#bib.bib19)] | ✓ | ✓ | ✓ | N/A | ✗ |'
- en: '| MDMF[[48](#bib.bib48)] | ✗ | ✗ | ✗ | N/A | ✗ |'
  id: totrans-565
  prefs: []
  type: TYPE_TB
  zh: '| MDMF[[48](#bib.bib48)] | ✗ | ✗ | ✗ | N/A | ✗ |'
- en: '| FUZZING | NeuZZ [[20](#bib.bib20)] | ✓ | ✗ | ✗ | N/A | N/A |'
  id: totrans-566
  prefs: []
  type: TYPE_TB
  zh: '| FUZZING | NeuZZ [[20](#bib.bib20)] | ✓ | ✗ | ✗ | N/A | N/A |'
- en: '| Learn & Fuzz [[21](#bib.bib21)] | ✗ | ✗ | ✗ | N/A | N/A |'
  id: totrans-567
  prefs: []
  type: TYPE_TB
  zh: '| Learn & Fuzz [[21](#bib.bib21)] | ✗ | ✗ | ✗ | N/A | N/A |'
- en: '1'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '1'
- en: “Raw data” refers to the data that used to generate training set but cannot
    be feed into the model directly. For instance, a collection of binary files is
    raw file.
  id: totrans-569
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “原始数据”指的是用于生成训练集的数据，但不能直接输入到模型中。例如，一组二进制文件就是原始文件。
- en: '2'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '2'
- en: “Dataset” is the collection of data sample that can be feed in to the DL model
    directly. For instance, a collection of image, sequence.
  id: totrans-571
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “数据集”是可以直接输入到深度学习模型中的数据样本集合。例如，一组图像或序列。
- en: '3'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '3'
- en: “P” denotes that its source code or dataset is partially available to public.
  id: totrans-573
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: “P”表示其源代码或数据集部分公开。
- en: We observe that both the percentage of open source of code and dataset in our
    surveyed fields is low, which makes it a challenge to reproduce proposed schemes,
    make comparisons between different works, and adopt them in practice. Specifically,
    the statistic shows that 1) the percentage of open source of code in our surveyed
    fields is low, only 6 out of 16 paper published their model’s source code. 2)
    the percentage of public data sets is low. Even though, the raw data in half of
    the works are publicly available, only 4 out of 16 fully or partially published
    their dataset. 3) the quality of datasets is not guaranteed, for instance, most
    of the dataset is unbalanced.
  id: totrans-574
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到，在我们调查的领域中，开源代码和数据集的比例都很低，这使得重复提出的方案、对不同工作的比较以及在实践中的应用都面临挑战。具体来说，统计数据显示：1）我们调查的领域中，开源代码的比例很低，仅有16篇论文中有6篇公开了其模型的源代码。2）公开数据集的比例也很低。尽管一半的工作中的原始数据是公开的，但仅有16篇论文中有4篇完全或部分公开了数据集。3）数据集的质量无法保证，例如，大多数数据集是不平衡的。
- en: 'The performance of security solutions even using Deep Learning might vary according
    to datasets. Traditionally, when evaluating different NN models in image classification,
    standard datasets such as MNIST for recognizing handwritten 10 digits and CIFAR10 [[73](#bib.bib73)]
    for recognizing 10 object classes are used for performance comparison of different
    NN models. However, there are no known standard datasets for evaluating NN models
    on different security problems. Due to such a limitation, we observe that most
    security papers using Deep Learning do not compare the performance of different
    security solutions even when they consider the same security problem. Thus, it
    is recommended to generate and use a standard dataset for a specific security
    problem for comparison. In conclusion, we think that there are three aspects that
    need to be improved in future research:'
  id: totrans-575
  prefs: []
  type: TYPE_NORMAL
  zh: 即使使用深度学习，安全解决方案的性能也可能因数据集而异。传统上，在评估图像分类中的不同神经网络模型时，通常使用标准数据集，例如 MNIST 用于识别手写数字
    10 和 CIFAR10 [[73](#bib.bib73)] 用于识别 10 种物体类别，以比较不同神经网络模型的性能。然而，目前尚无标准数据集用于评估神经网络模型在不同安全问题上的表现。由于这一限制，我们观察到大多数使用深度学习的安全论文，即使在考虑相同的安全问题时，也没有比较不同安全解决方案的性能。因此，建议为特定安全问题生成并使用标准数据集以进行比较。总之，我们认为未来的研究中有三个方面需要改进：
- en: '1.'
  id: totrans-576
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Developing standard dataset.
  id: totrans-577
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开发标准数据集。
- en: '2.'
  id: totrans-578
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Publishing their source code and dataset.
  id: totrans-579
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发布他们的源代码和数据集。
- en: '3.'
  id: totrans-580
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Improving the interpretability of their model.
  id: totrans-581
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 提高模型的可解释性。
- en: 13 Conclusion
  id: totrans-582
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 13 结论
- en: 'This paper seeks to provide a dedicated review of the very recent research
    works on using Deep Learning techniques to solve computer security challenges.
    In particular, the review covers eight computer security problems being solved
    by applications of Deep Learning: security-oriented program analysis, defending
    ROP attacks, achieving CFI, defending network attacks, malware classification,
    system-event-based anomaly detection, memory forensics, and fuzzing for software
    security. Our observations of the reviewed works indicate that the literature
    of using Deep Learning techniques to solve computer security challenges is still
    at an earlier stage of development.'
  id: totrans-583
  prefs: []
  type: TYPE_NORMAL
  zh: 本文旨在提供关于使用深度学习技术解决计算机安全挑战的最新研究工作的专门综述。特别是，该综述涵盖了通过深度学习应用解决的八个计算机安全问题：安全导向的程序分析、防御
    ROP 攻击、实现 CFI、防御网络攻击、恶意软件分类、基于系统事件的异常检测、内存取证和软件安全模糊测试。我们对所评审工作的观察表明，使用深度学习技术解决计算机安全挑战的文献仍处于较早的开发阶段。
- en: 14 Availability of data and materials
  id: totrans-584
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 14 数据和材料的可用性
- en: Not applicable.
  id: totrans-585
  prefs: []
  type: TYPE_NORMAL
  zh: 不适用。
- en: 15 Funding
  id: totrans-586
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 15 资助
- en: This work was supported by ARO W911NF-13-1-0421 (MURI), NSF CNS-1814679, and
    ARO W911NF-15-1-0576.
  id: totrans-587
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到了 ARO W911NF-13-1-0421 (MURI)、NSF CNS-1814679 和 ARO W911NF-15-1-0576 的资助。
- en: 16 Acknowledgements
  id: totrans-588
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 16 致谢
- en: We are grateful to the anonymous reviewers for their useful comments and suggestions.
  id: totrans-589
  prefs: []
  type: TYPE_NORMAL
  zh: 我们感谢匿名审稿人提供的有益评论和建议。
- en: References
  id: totrans-590
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] A. K. Ghosh, J. Wanken, and F. Charron. Detecting Anomalous and Unknown
    Intrusions against Programs. In Proceeding of Annual Computer Security Applications
    Conference (ACSAC), 1998.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] A. K. Ghosh, J. Wanken 和 F. Charron. 《检测程序中的异常和未知入侵》。发表于年会计算机安全应用会议（ACSAC），1998年。'
- en: '[2] W. Hu, Y. Liao, and V. R. Vemuri. Robust Anomaly Detection using Support
    Vector Machines. In International Conference on Machine Learning (ICML), 2003.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] W. Hu, Y. Liao 和 V. R. Vemuri. 《使用支持向量机进行鲁棒异常检测》。发表于国际机器学习会议（ICML），2003年。'
- en: '[3] K. A. Heller, K. M. Svore, A. D. Keromytis, and S. J. Stolfo. One Class
    Support Vector Machines for Detecting Anomalous Windows Registry Accesses. In
    Proceedings of the Workshop on Data Mining for Computer Security, 2003.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] K. A. Heller, K. M. Svore, A. D. Keromytis 和 S. J. Stolfo. 《用于检测异常 Windows
    注册表访问的单类支持向量机》。发表于计算机安全数据挖掘研讨会论文集，2003年。'
- en: '[4] R. Sommer and V. Paxson. Outside the Closed World: On Using Machine Learning
    For Network Intrusion Detection. In 2010 IEEE Symposium on Security and Privacy
    (S&P), 2010.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] R. Sommer 和 V. Paxson. 《超越封闭世界：使用机器学习进行网络入侵检测》。发表于2010 IEEE 安全与隐私研讨会（S&P），2010年。'
- en: '[5] NSCAI Intern Report for Congress. Technical report, 2019. [https://drive.google.com/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view](https://drive.google.com/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view).'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] NSCAI 实习报告，供国会参考。技术报告，2019年。 [https://drive.google.com/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view](https://drive.google.com/file/d/153OrxnuGEjsUvlxWsFYauslwNeCEkvUb/view)。'
- en: '[6] Wei Xu, Ling Huang, Armando Fox, David Patterson, and Michael I. Jordan.
    Detecting Large-Scale System Problems by Mining Console Logs. In Proceedings of
    the ACM SIGOPS 22Nd Symposium on Operating Systems Principles, SOSP ’09, pages
    117–132, New York, NY, USA, 2009\. ACM.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] Wei Xu, Ling Huang, Armando Fox, David Patterson, 和 Michael I. Jordan.
    通过挖掘控制台日志检测大规模系统问题. 见《ACM SIGOPS第22届操作系统原则研讨会论文集》，SOSP ’09, 第117–132页, 纽约, NY,
    USA, 2009年. ACM.'
- en: '[7] Y. Bengio, A. Courville, and P. Vincent. Representation Learning: A Review
    and New Perspectives. IEEE Transactions on Pattern Analysis and Machine Intelligence,
    35(8):1798–1828, Aug 2013.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Y. Bengio, A. Courville, 和 P. Vincent. 表示学习: 综述与新视角. IEEE模式分析与机器智能学报, 35(8):1798–1828,
    2013年8月.'
- en: '[8] Min Du, Feifei Li, Guineng Zheng, and Vivek Srikumar. DeepLog: Anomaly
    Detection and Diagnosis from System Logs Through Deep Learning. In Proceedings
    of the 2017 ACM SIGSAC Conference on Computer and Communications Security, CCS
    ’17, pages 1285–1298, New York, NY, USA, 2017. ACM.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] Min Du, Feifei Li, Guineng Zheng, 和 Vivek Srikumar. DeepLog: 通过深度学习从系统日志中进行异常检测与诊断.
    见《2017年ACM SIGSAC计算机与通信安全会议论文集》，CCS ’17, 第1285–1298页, 纽约, NY, USA, 2017年. ACM.'
- en: '[9] Eui Chul Richard Shin, Dawn Song, and Reza Moazzezi. Recognizing Functions
    in Binaries with Neural Networks. In 24th USENIX Security Symposium (USENIX Security
    15), pages 611–626, 2015.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Eui Chul Richard Shin, Dawn Song, 和 Reza Moazzezi. 使用神经网络识别二进制中的函数. 见《第24届USENIX安全研讨会（USENIX
    Security 15）》，第611–626页, 2015年.'
- en: '[10] Zheng Leong Chua, Shiqi Shen, Prateek Saxena, and Zhenkai Liang. Neural
    Nets Can Learn Function Type Signatures from Binaries. In 26th USENIX Security
    Symposium (USENIX Security 17), pages 99–116, 2017.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] Zheng Leong Chua, Shiqi Shen, Prateek Saxena, 和 Zhenkai Liang. 神经网络可以从二进制文件中学习函数类型特征.
    见《第26届USENIX安全研讨会（USENIX Security 17）》，第99–116页, 2017年.'
- en: '[11] Xusheng Li, Zhisheng Hu, Yiwei Fu, Ping Chen, Minghui Zhu, and Peng Liu.
    ROPNN: Detection of ROP Payloads Using Deep Neural Networks. arXiv preprint arXiv:1807.11110,
    2018.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Xusheng Li, Zhisheng Hu, Yiwei Fu, Ping Chen, Minghui Zhu, 和 Peng Liu.
    ROPNN: 使用深度神经网络检测ROP载荷. arXiv 预印本 arXiv:1807.11110, 2018.'
- en: '[12] Li Chen, Salmin Sultana, and Ravi Sahita. Henet: A Deep Learning Approach
    on Intel® Processor Trace for Effective Exploit Detection. In 2018 IEEE Security
    and Privacy Workshops (SPW), pages 109–115\. IEEE, 2018.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Li Chen, Salmin Sultana, 和 Ravi Sahita. Henet: 基于Intel®处理器追踪的深度学习方法用于有效的漏洞检测.
    见《2018年IEEE安全与隐私研讨会论文集（SPW）》，第109–115页. IEEE, 2018年.'
- en: '[13] Carter Yagemann, Salmin Sultana, Li Chen, and Wenke Lee. Barnum: Detecting
    Document Malware via Control Flow Anomalies in Hardware Traces. In International
    Conference on Information Security, pages 341–359\. Springer, 2019.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Carter Yagemann, Salmin Sultana, Li Chen, 和 Wenke Lee. Barnum: 通过硬件追踪中的控制流异常检测文档恶意软件.
    见《国际信息安全会议论文集》，第341–359页. Springer, 2019年.'
- en: '[14] Anh Viet Phan, Minh Le Nguyen, and Lam Thu Bui. Convolutional Neural Networks
    over Control Flow Graphs for Software defect prediction. In 2017 IEEE 29th International
    Conference on Tools with Artificial Intelligence (ICTAI), pages 45–52\. IEEE,
    2017.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Anh Viet Phan, Minh Le Nguyen, 和 Lam Thu Bui. 基于控制流图的卷积神经网络用于软件缺陷预测. 见《2017年IEEE第29届人工智能工具国际会议（ICTAI）》，第45–52页.
    IEEE, 2017年.'
- en: '[15] K Millar, A Cheng, HG Chew, and C-C Lim. Deep Learning for Classifying
    Malicious Network Traffic. In Pacific-Asia Conference on Knowledge Discovery and
    Data Mining, pages 156–161\. Springer, 2018.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] K Millar, A Cheng, HG Chew, 和 C-C Lim. 深度学习用于分类恶意网络流量. 见《亚太知识发现与数据挖掘会议》，第156–161页.
    Springer, 2018年.'
- en: '[16] Yong Zhang, Xu Chen, Da Guo, Mei Song, Yinglei Teng, and Xiaojuan Wang.
    PCCN: Parallel Cross Convolutional Neural Network for Abnormal Network Traffic
    Flows Detection in Multi-Class Imbalanced Network Traffic Flows. IEEE Access,
    7:119904–119916, 2019.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Yong Zhang, Xu Chen, Da Guo, Mei Song, Yinglei Teng, 和 Xiaojuan Wang.
    PCCN: 并行交叉卷积神经网络用于多类别不平衡网络流量的异常检测. IEEE Access, 7:119904–119916, 2019年.'
- en: '[17] Ishai Rosenberg, Asaf Shabtai, Lior Rokach, and Yuval Elovici. Generic
    Black-box End-to-End Attack against State of the Art API Call based Malware Classifiers.
    In International Symposium on Research in Attacks, Intrusions, and Defenses, 2018.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] Ishai Rosenberg, Asaf Shabtai, Lior Rokach, 和 Yuval Elovici. 针对最新API调用基恶意软件分类器的通用黑箱端到端攻击.
    见《攻击、入侵与防御研究国际研讨会》，2018年.'
- en: '[18] Leonardo De La Rosa, Sean Kilgallon, Tristan Vanderbruggen, and John Cavazos.
    Efficient Characterization and Classification of Malware Using Deep Learning.
    In Proceedings - Resilience Week 2018, RWS 2018, pages 77–83, 2018.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] Leonardo De La Rosa, Sean Kilgallon, Tristan Vanderbruggen, 和 John Cavazos.
    使用深度学习对恶意软件进行高效的特征化和分类. 见《2018年复原力周会议论文集》，RWS 2018, 第77–83页, 2018年.'
- en: '[19] Wei Song, Heng Yin, Chang Liu, and Dawn Song. DeepMem: Learning Graph
    Neural Network Models for Fast and Robust Memory Forensic Analysis. In Proceedings
    of the 2018 ACM SIGSAC Conference on Computer and Communications Security, CCS
    ’18, pages 606–618, New York, NY, USA, 2018. ACM.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] 宋伟、尹恒、刘畅和宋晨。DeepMem: 学习图神经网络模型以进行快速且稳健的内存取证分析。发表于2018年ACM SIGSAC计算机与通信安全会议，CCS
    ’18，第606–618页，美国纽约，2018年。ACM。'
- en: '[20] Dongdong Shi and Kexin Pei. NEUZZ: Efficient Fuzzing with Neural Program
    Smoothing. IEEE security & privacy, 2019.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] 石东东和裴克欣。NEUZZ: 通过神经程序平滑进行高效模糊测试。IEEE安全与隐私，2019年。'
- en: '[21] Patrice Godefroid, Hila Peleg, and Rishabh Singh. Learn&Fuzz: Machine
    Learning for Input Fuzzing. In Proceedings of the 32nd IEEE/ACM International
    Conference on Automated Software Engineering, pages 50–59\. IEEE Press, 2017.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] 帕特里斯·戈德弗鲁瓦、希拉·佩雷格和瑞沙布·辛格。Learn&Fuzz: 用于输入模糊测试的机器学习。发表于第32届IEEE/ACM自动化软件工程国际会议，第50–59页。IEEE出版社，2017年。'
- en: '[22] Wenbo Guo, Dongliang Mu, Xinyu Xing, Min Du, and Dawn Song. $\{$DEEPVSA$\}$:
    Facilitating Value-set Analysis with Deep Learning for Postmortem Program Analysis.
    In 28th USENIX Security Symposium (USENIX Security 19), pages 1787–1804, 2019.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] 郭文博、穆东良、邢心瑜、杜敏和宋晨。$\{$DEEPVSA$\}$: 使用深度学习促进价值集分析用于程序分析。发表于第28届USENIX安全研讨会（USENIX
    Security 19），第1787–1804页，2019年。'
- en: '[23] Xiaojun Xu, Chang Liu, Qian Feng, Heng Yin, Le Song, and Dawn Song. Neural
    Network-Based Graph Embedding for Cross-Platform Binary Code Similarity Detection.
    In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
    Security, pages 363–376\. ACM, 2017.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] 许晓军、刘畅、冯前、尹恒、宋乐和宋晨。基于神经网络的图嵌入用于跨平台二进制代码相似性检测。发表于2017年ACM SIGSAC计算机与通信安全会议，第363–376页。ACM，2017年。'
- en: '[24] Tiffany Bao, Jonathan Burket, Maverick Woo, Rafael Turner, and David Brumley.
    BYTEWEIGHT: Learning to Recognize Functions in Binary Code. In 23rd USENIX Security
    Symposium (USENIX Security 14), pages 845–860, San Diego, CA, August 2014\. USENIX
    Association.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] 蒂凡尼·鲍、乔纳森·伯克特、马弗里克·伍、拉斐尔·特纳和大卫·布拉姆利。BYTEWEIGHT: 学习识别二进制代码中的函数。发表于第23届USENIX安全研讨会（USENIX
    Security 14），第845–860页，美国加州圣地亚哥，2014年8月。USENIX协会。'
- en: '[25] Jiliang Zhang, Wuqiao Chen, and Yuqi Niu. DeepCheck: A Non-intrusive Control-flow
    Integrity Checking based on Deep Learning. arXiv preprint arXiv:1905.01858, 2019.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] 张季良、陈武乔和牛瑜琪。DeepCheck: 基于深度学习的非侵入式控制流完整性检查。arXiv预印本arXiv:1905.01858，2019年。'
- en: '[26] Xiaoyong Yuan, Chuanhuang Li, and Xiaolin Li. DeepDefense: Identifying
    DDoS Attack via Deep Learning. In 2017 IEEE International Conference on Smart
    Computing (SMARTCOMP), pages 1–8\. IEEE, 2017.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] 袁晓勇、李川煌和李晓林。DeepDefense: 通过深度学习识别DDoS攻击。发表于2017年IEEE智能计算国际会议（SMARTCOMP），第1–8页。IEEE，2017年。'
- en: '[27] Remi Varenne, Jean Michel Delorme, Emanuele Plebani, Danilo Pau, and Valeria
    Tomaselli. Intelligent Recognition of TCP Intrusions for Embedded Micro-controllers.
    In International Conference on Image Analysis and Processing, pages 361–373\.
    Springer, 2019.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] 雷米·瓦伦、让·米歇尔·德洛尔梅、埃马努埃尔·普莱巴尼、达尼洛·保和瓦莱里亚·托马塞利。嵌入式微控制器的TCP入侵智能识别。发表于国际图像分析与处理会议，第361–373页。Springer，2019年。'
- en: '[28] Chuanlong Yin, Yuefei Zhu, Jinlong Fei, and Xinzheng He. A Deep Learning
    Approach for Intrusion Detection using Recurrent Neural Networks. IEEE Access,
    5:21954–21961, 2017.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] 尹传龙、朱岳飞、费金龙和贺新政。基于递归神经网络的入侵检测深度学习方法。IEEE Access，第5卷，21954–21961页，2017年。'
- en: '[29] Serpil Ustebay, Zeynep Turgut, and M Ali Aydin. Cyber Attack Detection
    by Using Neural Network Approaches: Shallow Neural Network, Deep Neural Network
    and AutoEncoder. In International Conference on Computer Networks, pages 144–155\.
    Springer, 2019.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] 塞尔比尔·乌斯特贝、泽伊内普·图尔古特和马利·艾丁。通过神经网络方法检测网络攻击：浅层神经网络、深层神经网络和自编码器。发表于国际计算机网络会议，第144–155页。Springer，2019年。'
- en: '[30] Osama Faker and Erdogan Dogdu. Intrusion Detection Using Big Data and
    Deep Learning Techniques. In Proceedings of the 2019 ACM Southeast Conference,
    pages 86–93\. ACM, 2019.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] 奥萨马·法克尔和厄尔多安·多杜。利用大数据和深度学习技术进行入侵检测。发表于2019年ACM东南会议，第86–93页。ACM，2019年。'
- en: '[31] Joshua Saxe and Konstantin Berlin. Deep Neural Network based Malware Detection
    using Two Dimensional Binary Program Features. In 2015 10th International Conference
    on Malicious and Unwanted Software (MALWARE), pages 11–20\. IEEE, 2015.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] 约书亚·萨克斯和康斯坦丁·柏林。基于二维二进制程序特征的深度神经网络恶意软件检测。发表于2015年第10届恶意软件国际会议（MALWARE），第11–20页。IEEE，2015年。'
- en: '[32] Bojan Kolosnjaji, Ghadir Eraisha, George Webster, Apostolis Zarras, and
    Claudia Eckert. Empowering Convolutional Networks for Malware Classification and
    Analysis. Proceedings of the International Joint Conference on Neural Networks,
    2017-May:3838–3845, 2017.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Bojan Kolosnjaji、Ghadir Eraisha、George Webster、Apostolis Zarras和Claudia
    Eckert。增强卷积网络以进行恶意软件分类和分析。国际神经网络联合会议论文集，2017年5月：第3838–3845页，2017年。'
- en: '[33] Niall McLaughlin, Jesus Martinez Del Rincon, Boo Joong Kang, Suleiman
    Yerima, Paul Miller, Sakir Sezer, Yeganeh Safaei, Erik Trickel, Ziming Zhao, Adam
    Doupe, and Gail Joon Ahn. Deep Android Malware Detection. Proceedings of the 7th
    ACM Conference on Data and Application Security and Privacy, pages 301–308, 2017.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] 尼尔·麦克劳克林、耶稣·马丁内斯·德尔·林孔、姜博中、苏莱曼·耶里马、保罗·米勒、萨基尔·赛泽、耶戈内赫·萨法伊、埃里克·特里克、赵子明、亚当·杜普和盖尔·军·安。深度安卓恶意软件检测。第7届ACM数据与应用安全与隐私会议论文集，第301–308页，2017年。'
- en: '[34] Shun Tobiyama, Yukiko Yamaguchi, Hajime Shimada, Tomonori Ikuse, and Takeshi
    Yagi. Malware Detection with Deep Neural Network Using Process Behavior. In Proceedings
    - International Computer Software and Applications Conference, 2:577–582, 2016.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] 户部俊、山口由纪子、岛田初、育成友纪和八木健。基于进程行为的深度神经网络恶意软件检测。收录于国际计算机软件与应用会议论文集，第2卷：577–582，2016年。'
- en: '[35] George E. Dahl, Jack W. Stokes, Li Deng, and Dong Yu. Large-scale Malware
    Classification using Random Projections and Neural Networks. IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), pages 3422–3426,
    2013.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] George E. Dahl、Jack W. Stokes、Li Deng和Dong Yu。使用随机投影和神经网络的大规模恶意软件分类。IEEE国际声学、语音与信号处理会议（ICASSP），第3422–3426页，2013年。'
- en: '[36] Robin Nix and Jian Zhang. Classification of Android Apps and Malware using
    Deep Neural Networks. Proceedings of the International Joint Conference on Neural
    Networks, 2017-May:1871–1878, 2017.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Robin Nix和Jian Zhang。使用深度神经网络对安卓应用程序和恶意软件进行分类。国际神经网络联合会议论文集，2017年5月：第1871–1878页，2017年。'
- en: '[37] Mahmoud Kalash, Mrigank Rochan, Noman Mohammed, Neil D.B. Bruce, Yang
    Wang, and Farkhund Iqbal. Malware Classification with Deep Convolutional Neural
    Networks. 9th IFIP International Conference on New Technologies, Mobility and
    Security, NTMS 2018 - Proceedings, 2018-Janua:1–5, 2018.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Mahmoud Kalash、Mrigank Rochan、Noman Mohammed、Neil D.B. Bruce、杨旺和Farkhund
    Iqbal。基于深度卷积神经网络的恶意软件分类。第9届IFIP国际新技术、移动性与安全会议，NTMS 2018 - 论文集，2018年1月：第1–5页，2018年。'
- en: '[38] Zhihua Cui, Fei Xue, Xingjuan Cai, Yang Cao, Gai Ge Wang, and Jinjun Chen.
    Detection of Malicious Code Variants Based on Deep Learning. IEEE Transactions
    on Industrial Informatics, 14(7):3187–3196, 2018.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] 崔志华、薛飞、蔡兴娟、曹阳、王盖戈和陈金俊。基于深度学习的恶意代码变种检测。IEEE工业信息学汇刊，14(7)：3187–3196，2018年。'
- en: '[39] Omid E. David and Nathan S. Netanyahu. DeepSign: Deep Learning for Automatic
    Malware Signature Generation and Classification. Proceedings of the International
    Joint Conference on Neural Networks, 2015-Septe, 2015.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Omid E. David和Nathan S. Netanyahu。DeepSign：用于自动恶意软件签名生成和分类的深度学习。国际神经网络联合会议论文集，2015年9月，2015年。'
- en: '[40] Lifan Xu, Dongping Zhang, Nuwan Jayasena, and John Cavazos. HADM: Hybrid
    Analysis for Detection of Malware. 16:702–724, 2018.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] 徐立凡、张东平、努万·贾亚森和约翰·卡瓦索斯。HADM：用于恶意软件检测的混合分析。第16卷：702–724，2018年。'
- en: '[41] Weibin Meng, Ying Liu, Yichen Zhu, Shenglin Zhang, Dan Pei, Yuqing Liu,
    Yihao Chen, Ruizhi Zhang, Shimin Tao, Pei Sun, and Rong Zhou. Loganomaly: Unsupervised
    Detection of Sequential and Quantitative Anomalies in Unstructured Logs. In Proceedings
    of the 28th International Joint Conference on Artificial Intelligence, IJCAI’19,
    pages 4739–4745\. AAAI Press, 2019.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] 孟伟彬、刘颖、朱毅晨、张胜林、裴丹、刘宇清、陈义浩、张瑞之、陶士敏、孙培和周蓉。Loganomaly：在非结构化日志中无监督检测序列和定量异常。收录于第28届国际人工智能联合会议论文集，IJCAI’19，第4739–4745页。AAAI出版社，2019年。'
- en: '[42] Anwesha Das, Frank Mueller, Charles Siegel, and Abhinav Vishnu. Desh:
    Deep Learning for System Health Prediction of Lead Times to Failure in HPC. In
    Proceedings of the 27th International Symposium on High-Performance Parallel and
    Distributed Computing, HPDC ’18, pages 40–51, New York, NY, USA, 2018\. ACM.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Anwesha Das、Frank Mueller、Charles Siegel和Abhinav Vishnu。Desh：用于高性能计算系统健康预测的深度学习。收录于第27届高性能并行和分布式计算国际研讨会论文集，HPDC
    ’18，第40–51页，纽约，NY，美国，2018年。ACM。'
- en: '[43] Andy Brown, Aaron Tuor, Brian Hutchinson, and Nicole Nichols. Recurrent
    Neural Network Attention Mechanisms for Interpretable System Log Anomaly Detection.
    In Proceedings of the First Workshop on Machine Learning for Computing Systems,
    MLCS’18, pages 1:1–1:8, New York, NY, USA, 2018\. ACM.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Andy Brown、Aaron Tuor、Brian Hutchinson 和 Nicole Nichols。用于可解释系统日志异常检测的递归神经网络注意力机制。发表于第一次机器学习计算系统研讨会（MLCS’18），第1:1–1:8页，纽约，NY，美国，2018年。ACM。'
- en: '[44] Xu Zhang, Yong Xu, Qingwei Lin, Bo Qiao, Hongyu Zhang, Yingnong Dang,
    Chunyu Xie, Xinsheng Yang, Qian Cheng, Ze Li, Junjie Chen, Xiaoting He, Randolph
    Yao, Jian-Guang Lou, Murali Chintalapati, Furao Shen, and Dongmei Zhang. Robust
    Log-based Anomaly Detection on Unstable Log Data. In Proceedings of the 27th ACM
    Joint Meeting on European Software Engineering Conference and Symposium on the
    Foundations of Software Engineering, ESEC/FSE 2019, pages 807–817, New York, NY,
    USA, 2019\. ACM.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Xu Zhang、Yong Xu、Qingwei Lin、Bo Qiao、Hongyu Zhang、Yingnong Dang、Chunyu
    Xie、Xinsheng Yang、Qian Cheng、Ze Li、Junjie Chen、Xiaoting He、Randolph Yao、Jian-Guang
    Lou、Murali Chintalapati、Furao Shen 和 Dongmei Zhang。基于日志的鲁棒异常检测在不稳定日志数据上的应用。发表于第27届ACM联合欧洲软件工程会议及软件工程基础研讨会，ESEC/FSE
    2019，第807–817页，纽约，NY，美国，2019年。ACM。'
- en: '[45] C. Bertero, M. Roy, C. Sauvanaud, and G. Tredan. Experience Report: Log
    Mining Using Natural Language Processing and Application to Anomaly Detection.
    In 2017 IEEE 28th International Symposium on Software Reliability Engineering
    (ISSRE), pages 351–360, Oct 2017.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] C. Bertero、M. Roy、C. Sauvanaud 和 G. Tredan。经验报告：使用自然语言处理的日志挖掘及其在异常检测中的应用。发表于
    2017 IEEE 第28届国际软件可靠性工程研讨会（ISSRE），第351–360页，2017年10月。'
- en: '[46] M. Du and F. Li. Spell: Streaming Parsing of System Event Logs. In 2016
    IEEE 16th International Conference on Data Mining (ICDM), pages 859–864, Dec 2016.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] M. Du 和 F. Li。Spell：系统事件日志的流式解析。发表于 2016 IEEE 第16届国际数据挖掘会议（ICDM），第859–864页，2016年12月。'
- en: '[47] Shenglin Zhang, Weibin Meng, Jiahao Bu, Sen Yang, Ying Liu, D. Pei, J. Xu,
    Yu Chen, Hui Dong, Xianping Qu, and Lei Song. Syslog Processing for Switch Failure
    Diagnosis and Prediction in Datacenter Networks. In 2017 IEEE/ACM 25th International
    Symposium on Quality of Service (IWQoS), pages 1–10, June 2017.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] Shenglin Zhang、Weibin Meng、Jiahao Bu、Sen Yang、Ying Liu、D. Pei、J. Xu、Yu
    Chen、Hui Dong、Xianping Qu 和 Lei Song。数据中心网络中用于交换机故障诊断和预测的系统日志处理。发表于 2017 IEEE/ACM
    第25届国际服务质量研讨会（IWQoS），第1–10页，2017年6月。'
- en: '[48] Rachel Petrik, Berat Arik, and Jared M. Smith. Towards Architecture and
    OS-Independent Malware Detection via Memory Forensics. In Proceedings of the 2018
    ACM SIGSAC Conference on Computer and Communications Security, CCS ’18, pages
    2267–2269, New York, NY, USA, 2018. ACM.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] Rachel Petrik、Berat Arik 和 Jared M. Smith。通过内存取证实现架构和操作系统无关的恶意软件检测。发表于
    2018 ACM SIGSAC 计算机与通信安全会议，CCS ’18，第2267–2269页，纽约，NY，美国，2018年。ACM。'
- en: '[49] Antonis Michalas and Rohan Murray. MemTri: A Memory Forensics Triage Tool
    Using Bayesian Network and Volatility. In Proceedings of the 2017 International
    Workshop on Managing Insider Security Threats, MIST ’17, pages 57–66, New York,
    NY, USA, 2017. ACM.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] Antonis Michalas 和 Rohan Murray。MemTri：使用贝叶斯网络和波动性的内存取证分类工具。发表于 2017 年国际内部安全威胁管理研讨会（MIST
    ’17），第57–66页，纽约，NY，美国，2017年。ACM。'
- en: '[50] Yusheng Dai, Hui Li, Yekui Qian, and Xidong Lu. A Malware Classification
    Method Based on Memory Dump Grayscale Image. Digital Investigation, 27:30 – 37,
    2018.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] Yusheng Dai、Hui Li、Yekui Qian 和 Xidong Lu。基于内存转储灰度图像的恶意软件分类方法。数字调查，27:30–37，2018年。'
- en: '[51] Yunchao Wang, Zehui Wu, Qiang Wei, and Qingxian Wang. NeuFuzz: Efficient
    Fuzzing with Deep Neural Network. IEEE Access, 7:36340–36352, 2019.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Yunchao Wang、Zehui Wu、Qiang Wei 和 Qingxian Wang。NeuFuzz：基于深度神经网络的高效模糊测试。IEEE
    Access，7:36340–36352，2019年。'
- en: '[52] Konstantin Böttinger, Patrice Godefroid, and Rishabh Singh. Deep Reinforcement
    Fuzzing. In 2018 IEEE Security and Privacy Workshops (SPW), pages 116–122\. IEEE,
    2018.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] Konstantin Böttinger、Patrice Godefroid 和 Rishabh Singh。深度强化模糊测试。发表于 2018
    IEEE 安全与隐私研讨会（SPW），第116–122页。IEEE，2018年。'
- en: '[53] Mohit Rajpal, William Blum, and Rishabh Singh. Not All Bytes are Equal:
    Neural Byte Sieve for Fuzzing. arXiv preprint arXiv:1711.04596, 2017.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] Mohit Rajpal、William Blum 和 Rishabh Singh。并非所有字节都相同：用于模糊测试的神经字节筛选器。arXiv
    预印本 arXiv:1711.04596，2017年。'
- en: '[54] Hovav Shacham et al. The Geometry of Innocent Flesh on the Bone: Return-into-libc
    without Function Calls (on the x86). In ACM conference on Computer and communications
    security, pages 552–561\. New York,, 2007.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Hovav Shacham 等。骨头上的无辜肉体的几何学：无函数调用的返回至 libc（x86）。发表于 ACM 计算机与通信安全会议，第552–561页。纽约，2007年。'
- en: '[55] Martín Abadi, Mihai Budiu, Úlfar Erlingsson, and Jay Ligatti. Control-Flow
    Integrity Principles, Implementations, and Applications. ACM Transactions on Information
    and System Security (TISSEC), 13(1):4, 2009.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Martín Abadi, Mihai Budiu, Úlfar Erlingsson 和 Jay Ligatti. 控制流完整性原则、实现与应用。ACM
    信息与系统安全事务 (TISSEC)，第 13 卷第 1 期：4，2009 年。'
- en: '[56] Jonathan Salwant. ROPGadget. [https://github.com/JonathanSalwan/ROPgadget](https://github.com/JonathanSalwan/ROPgadget).'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Jonathan Salwant. ROPGadget。 [https://github.com/JonathanSalwan/ROPgadget](https://github.com/JonathanSalwan/ROPgadget)。'
- en: '[57] Unicorn-The ultimate CPU emulator. [https://www.unicorn-engine.org/](https://www.unicorn-engine.org/).'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Unicorn - 终极 CPU 模拟器。 [https://www.unicorn-engine.org/](https://www.unicorn-engine.org/)。'
- en: '[58] Vladimir Kiriansky, Derek Bruening, Saman P Amarasinghe, et al. Secure
    Execution via Program Shepherding. In USENIX Security Symposium, volume 92, page 84,
    2002.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Vladimir Kiriansky, Derek Bruening, Saman P Amarasinghe 等. 通过程序牧羊实现安全执行。发表于
    USENIX 安全研讨会，卷 92，第 84 页，2002 年。'
- en: '[59] Xiaoyang Xu, Masoud Ghaffarinia, Wenhao Wang, Kevin W. Hamlen, and Zhiqiang
    Lin. CONFIRM: Evaluating Compatibility and Relevance of Control-flow Integrity
    Protections for Modern Software. In 28th USENIX Security Symposium (USENIX Security
    19), pages 1805–1821, Santa Clara, CA, August 2019\. USENIX Association.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Xiaoyang Xu, Masoud Ghaffarinia, Wenhao Wang, Kevin W. Hamlen 和 Zhiqiang
    Lin. CONFIRM：评估现代软件控制流完整性保护的兼容性和相关性。发表于第 28 届 USENIX 安全研讨会 (USENIX Security 19)，第
    1805–1821 页，加利福尼亚州圣克拉拉，2019 年 8 月。USENIX 协会。'
- en: '[60] Susan Horwitz. Precise Flow-insensitive May-alias Analysis is NP-hard.
    ACM Trans. Program. Lang. Syst., 19(1):1–6, January 1997.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Susan Horwitz. 精确的流不敏感 May-alias 分析是 NP-困难的。ACM 转换程序语言系统，第 19 卷第 1 期：1–6，1997
    年 1 月。'
- en: '[61] Gang Tan and Trent Jaeger. CFG Construction Soundness in Control-Flow
    Integrity. In Proceedings of the 2017 Workshop on Programming Languages and Analysis
    for Security, pages 3–13\. ACM, 2017.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Gang Tan 和 Trent Jaeger. 控制流完整性中的 CFG 构建健全性。发表于 2017 年编程语言与安全分析研讨会论文集，第
    3–13 页。ACM，2017 年。'
- en: '[62] Zhilong Wang and Peng Liu. GPT Conjecture: Understanding the Trade-offs
    between Granularity, Performance and Timeliness in Control-Flow Integrity, 2019.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Zhilong Wang 和 Peng Liu. GPT 猜想：理解控制流完整性中的粒度、性能和时效性的权衡，2019 年。'
- en: '[63] Minh Hai Nguyen, Dung Le Nguyen, Xuan Mao Nguyen, and Tho Thanh Quan.
    Auto-Detection of Sophisticated Malware using Lazy-Binding Control Flow Graph
    and Deep Learning. Computers & Security, 76:128–155, 2018.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Minh Hai Nguyen, Dung Le Nguyen, Xuan Mao Nguyen 和 Tho Thanh Quan. 使用惰性绑定控制流图和深度学习自动检测复杂恶意软件。计算机与安全，76：128–155，2018
    年。'
- en: '[64] Nour Moustafa and Jill Slay. UNSW-NB15: A Comprehensive Data Set for Network
    Intrusion Detection Systems (UNSW-NB15 Network Data Set). In 2015 military communications
    and information systems conference (MilCIS), pages 1–6\. IEEE, 2015.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Nour Moustafa 和 Jill Slay. UNSW-NB15：一个用于网络入侵检测系统的全面数据集（UNSW-NB15 网络数据集）。发表于
    2015 年军事通信与信息系统会议 (MilCIS)，第 1–6 页。IEEE，2015 年。'
- en: '[65] IDS 2017 Datasets, 2019. [https://www.unb.ca/cic/datasets/ids-2017.html](https://www.unb.ca/cic/datasets/ids-2017.html).'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] IDS 2017 数据集，2019 年。 [https://www.unb.ca/cic/datasets/ids-2017.html](https://www.unb.ca/cic/datasets/ids-2017.html)。'
- en: '[66] Jun Li, Bodong Zhao, and Chao Zhang. Fuzzing: A Survey. Cybersecurity,
    1(1):6, 2018.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Jun Li, Bodong Zhao 和 Chao Zhang. 模糊测试：综述。网络安全，1(1)：6，2018 年。'
- en: '[67] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
    Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel, and Giovanni Vigna.
    Driller: Augmenting Fuzzing Through Selective Symbolic Execution. In In the Network
    and Distributed System Security Symposium (NDSS), volume 16, pages 1–16, 2016.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Nick Stephens, John Grosen, Christopher Salls, Andrew Dutcher, Ruoyu Wang,
    Jacopo Corbetta, Yan Shoshitaishvili, Christopher Kruegel 和 Giovanni Vigna. Driller：通过选择性符号执行增强模糊测试。在网络与分布式系统安全研讨会
    (NDSS) 中，第 16 卷，第 1–16 页，2016 年。'
- en: '[68] S. Bekrar, C. Bekrar, R. Groz, and L. Mounier. A Taint Based Approach
    for Smart Fuzzing. In 2012 IEEE Fifth International Conference on Software Testing,
    Verification and Validation, pages 818–825, April 2012.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] S. Bekrar, C. Bekrar, R. Groz 和 L. Mounier. 一种基于污点的智能模糊测试方法。发表于 2012 年
    IEEE 第五届国际软件测试、验证与验证会议，第 818–825 页，2012 年 4 月。'
- en: '[69] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang, and Taesoo Kim. QSYM : A
    Practical Concolic Execution Engine Tailored for Hybrid Fuzzing. In 27th USENIX
    Security Symposium (USENIX Security 18), pages 745–761, Baltimore, MD, August
    2018\. USENIX Association.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Insu Yun, Sangho Lee, Meng Xu, Yeongjin Jang 和 Taesoo Kim. QSYM：一个针对混合模糊测试的实用符号执行引擎。发表于第
    27 届 USENIX 安全研讨会 (USENIX Security 18)，第 745–761 页，马里兰州巴尔的摩，2018 年 8 月。USENIX
    协会。'
- en: '[70] Google Developers. Embeddings, 2016. [https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture).'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] 谷歌开发者. 嵌入表示，2016年。 [https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture](https://developers.google.com/machine-learning/crash-course/embeddings/video-lecture)。'
- en: '[71] Yann LeCun and Corinna Cortes. MNIST Handwritten Digit Database. 2010.
    [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/).'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Yann LeCun 和 Corinna Cortes. MNIST 手写数字数据库。2010年。 [http://yann.lecun.com/exdb/mnist/](http://yann.lecun.com/exdb/mnist/)。'
- en: '[72] Wenbo Guo, Dongliang Mu, Jun Xu, Purui Su, Gang Wang, and Xinyu Xing.
    Lemna: Explaining deep learning based security applications. In Proceedings of
    the 2018 ACM SIGSAC Conference on Computer and Communications Security, pages
    364–379, 2018.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Wenbo Guo、Dongliang Mu、Jun Xu、Purui Su、Gang Wang 和 Xinyu Xing. Lemna：解释基于深度学习的安全应用。发表于2018年ACM
    SIGSAC计算机与通信安全会议论文集，页码 364–379。'
- en: '[73] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. CIFAR-10 (Canadian Institute
    for Advanced Research). 2010. [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html).'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Alex Krizhevsky、Vinod Nair 和 Geoffrey Hinton. CIFAR-10（加拿大高级研究所）。2010年。
    [https://www.cs.toronto.edu/~kriz/cifar.html](https://www.cs.toronto.edu/~kriz/cifar.html)。'
