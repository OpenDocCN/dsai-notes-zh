- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:30:21'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2408.16202] Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive
    Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2408.16202](https://ar5iv.labs.arxiv.org/html/2408.16202)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Qi Dong [0009-0008-1737-9324](https://orcid.org/0009-0008-1737-9324 "ORCID identifier")
    [3230006098@student.must.edu.mo](mailto:3230006098@student.must.edu.mo) School
    of Computer Science and Engineering, Macau University of Science and TechnologyTaipaMacauChina999078
    ,  Rubing Huang [rbhuang@must.edu.mo](mailto:rbhuang@must.edu.mo) [0000-0002-1769-6126](https://orcid.org/0000-0002-1769-6126
    "ORCID identifier") School of Computer Science and Engineering, Macau University
    of Science and TechnologyTaipaMacauChina999078 ,  Chenhui Cui [3230002105@student.must.edu.mo](mailto:3230002105@student.must.edu.mo)
    [0009-0004-8746-316X](https://orcid.org/0009-0004-8746-316X "ORCID identifier")
    School of Computer Science and Engineering, Macau University of Science and TechnologyTaipaMacauChina999078
    ,  Dave Towey [dave.towey@nottingham.edu.cn](mailto:dave.towey@nottingham.edu.cn)
    [0000-0003-0877-4353](https://orcid.org/0000-0003-0877-4353 "ORCID identifier")
    School of Computer Science, University of Nottingham Ningbo ChinaNingboZhejiangChina315100
    ,  Ling Zhou [lzhou@must.edu.mo](mailto:lzhou@must.edu.mo) [0000-0002-8313-5749](https://orcid.org/0000-0002-8313-5749
    "ORCID identifier") School of Computer Science and Engineering, Macau University
    of Science and TechnologyTaipaMacauChina999078 ,  Jinyu Tian [jytian@must.edu.mo](mailto:jytian@must.edu.mo)
    [0000-0002-2449-5277](https://orcid.org/0000-0002-2449-5277 "ORCID identifier")
    School of Computer Science and Engineering, Macau University of Science and TechnologyTaipaMacauChina999078
     and  Jianzhou Wang [jzwang@must.edu.mo](mailto:jzwang@must.edu.mo) [0000-0001-9078-7617](https://orcid.org/0000-0001-9078-7617
    "ORCID identifier") Department of Engineering Science, Macau University of Science
    and TechnologyTaipaMacauChina999078(2018; )
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Short-Term Electricity-Load Forecasting (STELF) refers to the prediction of
    the immediate demand (in the next few hours to several days) for the power system.
    Various external factors, such as weather changes and the emergence of new electricity
    consumption scenarios, can impact electricity demand, causing load data to fluctuate
    and become non-linear, which increases the complexity and difficulty of STELF.
    In the past decade, deep learning has been applied to STELF, modeling and predicting
    electricity demand with high accuracy, and contributing significantly to the development
    of STELF. This paper provides a comprehensive survey on deep-learning-based STELF
    over the past ten years. It examines the entire forecasting process, including
    data pre-processing, feature extraction, deep-learning modeling and optimization,
    and results evaluation. This paper also identifies some research challenges and
    potential research directions to be further investigated in future work.
  prefs: []
  type: TYPE_NORMAL
- en: 'electricity, load, deep learning, short term^†^†copyright: acmcopyright^†^†journalyear:
    2018^†^†doi: XXXXXXX.XXXXXXX^†^†journal: JACM^†^†journalvolume: 37^†^†journalnumber:
    4^†^†article: 111^†^†publicationmonth: 8^†^†ccs: Computing methodologies Machine
    learning algorithms^†^†ccs: Mathematics of computing Probability and statistics^†^†ccs:
    Applied computing Forecasting'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Electricity-Load Forecasting (ELF) aims to meet power systems’ daily operational,
    management, and planning needs. This can provide essential guidance and reference
    points for system operators and planners. The absence of large-scale energy storage
    technologies means that power systems must ensure a constant power supply to meet
    current demands (Pełka and Dudek, [2020](#bib.bib135)). This means that ELF has
    become an essential component in the planning, scheduling, and operational management
    of power systems. Short-Term Electricity-Load Forecasting (STELF) uses historical
    load data to predict future loads, over a period ranging from several hours to
    a few days. STELF is a time-series forecasting task primarily used for the short-term
    scheduling of smart grids (including equipment maintenance, load distribution,
    and unit startup and shutdown), and for determining electricity prices (Wu et al.,
    [2021](#bib.bib177)). Data from a British electricity company in 1984 showed that
    a 1% reduction in forecasting error could save £10 million annually (Bunn and
    Farmer, [1985](#bib.bib19)). Increasing the STELF accuracy could improve planning
    and scheduling, and reduce operational costs for power systems (Kouhi et al.,
    [2014](#bib.bib103)). This practical impact of STELF has led to an increasing
    amount of attention from researchers. Our review of the literature from the past
    decade highlights that most load forecasting articles have focused on STELF (Ghofrani
    et al., [2015](#bib.bib58); Hu et al., [2017](#bib.bib84); Raza et al., [2017](#bib.bib139);
    Hoori et al., [2019](#bib.bib77); Choi et al., [2018](#bib.bib31); Guo et al.,
    [2020](#bib.bib62)).
  prefs: []
  type: TYPE_NORMAL
- en: Many factors can impact the electricity load, including climate, weather, economic
    conditions, seasonality, and electricity prices. Furthermore, advances in smart-grid
    technologies, and the widespread adoption of smart meters and other sensors have
    significantly increased both the complexity and the volume of electricity-load
    data. The data exhibits strong non-linearity, randomness, volatility, and complexity.
    This is a challenge for STELF. An accurate, robust, and fast STELF model is essential
    for the reliable daily operations of power systems (Wang et al., [2019c](#bib.bib171)),
    and the development of efficient forecasting models has become an important STELF
    research goal (Dou et al., [2018](#bib.bib42)).
  prefs: []
  type: TYPE_NORMAL
- en: 'ELF has been extensively studied since the 1970s, with various methods having
    been proposed (Fahiman et al., [2019](#bib.bib46)). STELF methods can be broadly
    categorized into three types: statistical methods, machine learning methods, and
    deep learning methods (Dudek, [2016](#bib.bib43)). Statistical methods perform
    well when dealing with linear relationships, but are often inadequate for handling
    the nonlinear patterns commonly found in electricity-load data. Machine learning
    methods, such as support vector machines and decision trees, typically perform
    well with simple or moderately complex data patterns. Deep learning methods can
    capture and model complex nonlinear relationships through their multi-layered
    structures, which is particularly important for predicting dynamic changes in
    electricity loads. In summary, while traditional statistical and machine learning
    methods have their strengths, deep learning techniques are more suited to the
    dynamic and nonlinear characteristics of electricity-load data.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning approaches are among the most revolutionary breakthroughs in the
    fields of computer science and artificial intelligence in recent years (LeCun
    et al., [2015](#bib.bib106)). The concept of deep learning builds on earlier work
    on Artificial Neural Networks (ANNs) (Hinton et al., [2006](#bib.bib72)), which
    were a type of shallow learning model  (Schmidhuber, [2015](#bib.bib144)), consisting
    of an input layer, a hidden layer, and an output layer (Almalaq and Edwards, [2017](#bib.bib7)).
    ANNs were used in early STELF studies (Hayati and Shirvany, [2007](#bib.bib68);
    Park et al., [1991](#bib.bib134)). Deep Neural Networks (DNNs), a type of ANN
    with multiple hidden layers, can also be used for STELF (Hosein and Hosein, [2017](#bib.bib78);
    Lai et al., [2020](#bib.bib104); Alipour et al., [2020](#bib.bib6)). The multiple
    hidden layers in DNNs enable a complex computational framework that uses features
    as inputs to represent different levels of data abstraction. Through a cascading
    network structure, each layer in the DNN is capable of extracting and recognizing
    different features of the data, forming a hierarchy from basic to advanced features,
    thereby significantly enhancing both the model’s flexibility and its ability to
    handle complex issues. Recurrent Neural Networks (RNNs) (Rumelhart et al., [1986](#bib.bib140))
    are DNNs that were designed specifically to process sequential data, making them
    highly suitable for time-series prediction tasks. Although RNNs are theoretically
    ideal for time-series data, they may face challenges, like vanishing or exploding
    gradients in practical applications (Tang et al., [2019b](#bib.bib155)). Long
    Short-Term Memory (LSTM) (Hochreiter and Schmidhuber, [1997](#bib.bib73)) and
    Gated Recurrent Units (GRUs) (Wang et al., [2021](#bib.bib170)) have addressed
    gradient vanishing, making them more effective for practical applications. These
    advanced technologies, capable of handling large-scale, high-dimensional, and
    nonlinear data, provide more accurate and flexible solutions for STELF, making
    deep learning the preferred technique for STELF (Ahajjam et al., [2022](#bib.bib3);
    Das et al., [2020](#bib.bib33); Li et al., [2023](#bib.bib107)).
  prefs: []
  type: TYPE_NORMAL
- en: Previous STELF reviews have compiled and examined the research achievements
    from various perspectives, examining all types of models, or concentrating on
    certain steps of the forecasting process (Akhtar et al., [2023](#bib.bib4); Hou
    et al., [2022](#bib.bib82); Al Mamun et al., [2020](#bib.bib5)). Akhtar et al. (Akhtar
    et al., [2023](#bib.bib4)), for example, reviewed various STELF models (including
    time series and regression models), rather than focusing only on Artificial Intelligence
    (AI) models. Although Hou et al. (Hou et al., [2022](#bib.bib82)) reviewed load
    forecasting based on AI models, focusing on data processing and prediction models.
    Al Mamun et al. (Al Mamun et al., [2020](#bib.bib5)) reviewed load forecasting,
    but only focused on hybrid models based on machine learning algorithms. To date,
    there has been no comprehensive and exhaustive review based on deep learning for
    STELF that covers the entire forecasting process. This paper aims to fill this
    gap in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: 'This article explores the application of deep learning in STELF, providing
    a comprehensive review of current relevant research. The entire STELF process
    is examined through a comprehensive review of the literature from 2014 to 2023.
    The paper is guided by eight research questions (RQs), each of which addresses
    a key aspect of the STELF process. This survey paper addresses the following key
    points: (1) a summary and analysis of the literature search results; (2) a classification
    and description of electricity load datasets; (3) an introduction to STELF data
    preprocessing methods; (4) an analysis of feature extraction; (5) a description,
    classification, and summary of STELF models based on deep learning; (6) a review
    of the optimization process; (7) a summary of evaluation metrics; and (8) a discussion
    of the challenges and trends for the future of STELF.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of this paper is organized as follows: Section [2](#S2 "2\. Background
    ‣ Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey")
    introduces some background information about the formal description of STELF and
    the basic deep learning models. Section [3](#S3 "3\. Methodology ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey") explains
    the methodology of this review, including the eight RQs related to STELF, the
    literature retrieval methods, and the statistical results of the retrieval. Sections [4](#S4
    "4\. Answer to RQ1: The Distribution and Analysis of the Search Results ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey") to [11](#S11
    "11\. Answer to RQ8: Challenges and Future Development Trends of STELF ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey") answer
    the eight RQs from Section [3](#S3 "3\. Methodology ‣ Short-Term Electricity-Load
    Forecasting by Deep Learning: A Comprehensive Survey"), respectively. Finally,
    Section [12](#S12 "12\. Conclusion ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey") concludes the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we introduce the task definition of STELF and the basic deep
    learning methods. The primary objective is to quickly familiarize readers with
    STELF and provide them with an initial understanding of deep learning methods.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. STELF Task Definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'STELF aims to predict the electricity load over a future period ranging from
    a few hours to several days. The model’s input consists of historical load data
    and some influencing factors, with the task being to learn a set of mapping functions
    from input to output. If $y_{t}$ represents the load demand at time $t$, the STELF
    goal is to predict the load demand within the next $h$ hours, denoted as $\hat{y}_{t+h}$.
    The prediction model can generally be expressed as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\hat{y}_{t+h}=f(y_{t},y_{t-1},\ldots,y_{t-n+1},X_{t}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\hat{y}_{t+h}$ is the predicted load at time $t+h$; $f$ is the prediction
    model (which can be statistical, a machine learning model, or a deep learning
    model); $y_{t},y_{t-1},\ldots,y_{t-n+1}$ are the historical load data for the
    previous $n$ time periods; and $X_{t}$ are the external variables at time $t$
    (such as weather data, calendar information, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Basic Deep-Learning Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we introduce traditional deep learning models and explore their
    innovations and variations. We also provide an introduction to the basic definitions
    and structures of these models, establishing a basis for a more detailed exploration
    of the application of deep learning methods in STELF.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.1\. Deep Neural Networks (DNNs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: DNNs are a complex and highly non-linear method for representation learning,
    typically consisting of an input layer, multiple hidden layers, and an output
    layer (Din and Marnerides, [2017](#bib.bib36)). Each neuron in the hidden layers
    functions as a unit that performs mapping within a multi-dimensional data space.
    Together, these neurons extract complex abstract features and patterns from the
    input data. Both the width and the depth of DNN networks can be modified (Hossen
    et al., [2017](#bib.bib81)). Shallow neural networks, which have only a single
    hidden layer, offer only the number of neurons as an adjustable parameter. The
    strength of DNNs lies not only in their deep structure but also in their non-linear
    activation functions. Non-linear activation functions, such as ReLU, Sigmoid,
    or Tanh, enable the network to capture non-linear relationships and complex patterns
    in the input data. Considering the non-linear nature of ELF load curves (which
    are influenced by various external factors), the use of DNN as a predictive model
    is well justified (Hossen et al., [2018](#bib.bib80)).
  prefs: []
  type: TYPE_NORMAL
- en: The Deep Belief Network (DBN) is a DNN variant that uses a layered unsupervised
    learning method for initial weight pre-training (Hinton et al., [2006](#bib.bib72)).
    This layer-by-layer unsupervised training process ensures that each layer effectively
    captures the features of the preceding layer, allowing the most fundamental features
    to be extracted from the training set. Typically, a DBN is composed of multiple
    stacked Restricted Boltzmann Machines (RBMs). An RBM is a type of ANN consisting
    of a visible layer and a hidden layer, where there are no connections between
    nodes within the same layer, but nodes between layers are fully connected (Hafeez
    et al., [2020](#bib.bib64)). Stacked RBMs are used for model pre-training and
    unsupervised learning, with the top layer fine-tuned using a backpropagation neural
    network. Fundamentally, an RBM learns a feature representation of a probability
    distribution over the original input data while also extracting feature information (Kong
    et al., [2019](#bib.bib102)).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.2\. Recurrent Neural Networks (RNNs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: RNNs are particularly effective at processing sequential data, such as time-series
    data (Gürses-Tran et al., [2022](#bib.bib63)). The RNN internal loops allow for
    the continuous transmission of information, which is the use of previous information
    to influence the current output, a capability also known as the memory function (Kong
    et al., [2017](#bib.bib101)).However, RNNs often encounter vanishing or exploding
    gradient issues when processing long sequences, which hinders their ability to
    learn long-term dependencies (Bashir et al., [2022](#bib.bib13)). LSTM and GRU
    were designed to overcome the RNN gradient issues when handling long sequences.
    They use different memory mechanisms to retain input information over extended
    periods (Tayab et al., [2020](#bib.bib158); Li et al., [2022a](#bib.bib109)).
    Faced with the distinct temporal sequences and cyclic patterns in ELF, LSTM, and
    GRU can utilize historical information for load forecasting and avoid gradient-related
    issues.
  prefs: []
  type: TYPE_NORMAL
- en: 'LSTM is a special kind of RNN capable of learning long-term dependencies, specifically
    designed to address the issue of vanishing gradients. The key to LSTM is its internal
    structure, the memory cell, which includes four main components: an input gate,
    a forget gate, an output gate, and a cell state that can maintain information
    over time (Haque and Rahman, [2022](#bib.bib67)).'
  prefs: []
  type: TYPE_NORMAL
- en: GRU is an improved model based on LSTM, but with a simpler structure and shorter
    training times, which helps it to better capture long-term dependencies within
    sequential data. GRU integrates the forget and input gates of LSTM into a single
    update gate, combining the cell state and hidden state. Compared to LSTM, GRU
    has fewer parameters, due to having one less gating unit. This significantly improves
    the computational efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: Both LSTM and GRU improve the information flow control through their gating
    mechanisms. While LSTM provides precise control mechanisms, GRU improves the computational
    efficiency of these controls by simplifying them. A choice between these two models
    typically depends on the specific demands of the task, the nature of the data,
    and the computational resources available.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2.3\. Convolutional Neural Networks (CNNs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In recent years, CNNs have become one of the most popular and widely utilized
    deep-learning models (Lu et al., [2019](#bib.bib120)). Although initially designed
    for processing image data, CNNs are also very effective at handling time-series
    data. For such data, One-Dimensional (1-D) convolutional layers can capture local
    patterns and features through a sliding window mechanism. Additionally, CNNs can
    handle data with grid-like topologies, allowing sequence data to be converted
    into graph-structured data for processing. A CNN model consists of four main parts (Li
    et al., [2020a](#bib.bib113); Kim et al., [2019](#bib.bib99)): (i) convolutional
    layers (which create feature maps from the input data); (ii) pooling layers (which
    reduce the dimensionality of the convolutional features); (iii) flattening layers
    (which reshape the data into a column vector); and (iv) fully connected layers
    (which link the features extracted by the convolutional and pooling layers to
    other layers).'
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we present the eight RQs related to STELF that guided our study.
    This section also provides a detailed introduction to the literature retrieval
    methods, and the filtering methods used to screen search results. The research
    methodology of this paper was guided by previous work (Huang et al., [21](#bib.bib91);
    Zhang et al., [2021](#bib.bib201)), and represents a systematic, comprehensive,
    and rationality approach. For ease of description, we use the term “STELF” to
    represent the term “deep-learning-based STELF” in this paper, unless explicitly
    stated.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Research Questions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This paper provides a comprehensive review of the application of deep learning
    in STELF. It examines the entire STELF process, structured around the following
    RQs:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ1: What is the distribution and analysis of the literature search results?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ2: What are the electricity load datasets?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ3: How can a dataset be preprocessed for STELF?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ4: What are the methods for feature extraction?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ5: What are the deep-learning-based modeling methods for STELF?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ6: How can the training processes be optimized?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ7: How have the STELF research results been evaluated?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RQ8: What are the challenges and the future development trends of STELF?'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'RQ1 explores the distribution of literature related to the use of deep learning
    for STELF over the past decade, leading to a detailed analysis of this data. RQ2
    leads to an overview of electricity load datasets. An answer to RQ3 includes the
    steps and methods used in data preprocessing. RQ4 leads to a discussion of the
    deep-learning feature-extraction techniques employed in the prediction process.
    Answering RQ5 classifies, describes, and analyzes the current state of deep-learning
    models in STELF. RQ6 explores the methods for optimizing the model-training process.
    The answer to RQ7 is an organized summary of the evaluation methods used for the
    forecasting results. Finally, the answer to RQ8 lists the challenges and future
    development trends of STELF. In the following sections, we provide detailed responses
    to each RQ, as illustrated in Fig. [1](#S3.F1 "Figure 1 ‣ 3.1\. Research Questions
    ‣ 3\. Methodology ‣ Short-Term Electricity-Load Forecasting by Deep Learning:
    A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d7333ca22b618adde0ad09231ea7542e.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1. The structure of this survey paper.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: This figure provides an overview of the survey structure.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Literature Search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The literature search method employed in this paper follows the approach used
    by Huang et al. (Huang et al., [21](#bib.bib91)), involving the following mainstream
    databases to ensure a comprehensive data collection:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ACM Digital Library;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Elsevier Science Direct;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IEEE Xplore Digital Library;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Springer Online Library;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wiley Online Library;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: MDPI.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The search time range was set to the period 2014 to 2023. An initial attempt
    using certain keywords for the search (Zhang et al., [2021](#bib.bib201)) in each
    database revealed that the ELF titles were not uniformly represented. Some papers,
    for example, did not include words such as “electricity” or “power” in their titles,
    even though their actual contents were related to ELF. Furthermore, not all STELF
    papers had the phrase “short-term” in their titles or keywords list. In addition,
    because of the diverse terminology used in deep-learning methods, the inclusion
    of such terminology in the keyword search could result in the omission of relevant
    papers. To broaden the scope, and avoid missing publications from a particular
    category, “electricity”, “power”, “short-term”, and “deep learning” were not included
    in the keywords. As a result, the final set of keywords used in the search was
    limited to four phrases: “load forecasting”, “load forecast”, “load prediction”,
    and “load predicting”.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3\. Literature Selection and Statistics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A total of 2,823 papers were retrieved from the six databases, according to
    the search parameters. These papers were further filtered according to the following
    selection criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not written in English.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not discussing ELF.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not using deep-learning methods.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Not focused on “short-term” forecasting research.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The paper was a review article.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Based on these criteria, 628 papers were selected from the initial 2,823. Additionally,
    the references of these papers were examined according to the snowballing approach (Huang
    et al., [21](#bib.bib91)), yielding an additional 22 papers. In total, 650 papers
    were included in the preliminary review and statistical analysis. The details
    of this search and filtering are shown in Table [1](#S3.T1 "Table 1 ‣ 3.3\. Literature
    Selection and Statistics ‣ 3\. Methodology ‣ Short-Term Electricity-Load Forecasting
    by Deep Learning: A Comprehensive Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1. Literature search and selection results
  prefs: []
  type: TYPE_NORMAL
- en: '| Digital library | No. of studies from the search results | No. of studies
    after filtering | No. of studies by snowballing | Total of filtering and snowballing
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ACM Digital Library | 80 | 14 | 0 | 14 |'
  prefs: []
  type: TYPE_TB
- en: '| Elsevier Science Direct | 889 | 126 | 0 | 126 |'
  prefs: []
  type: TYPE_TB
- en: '| IEEE Xplore Digital Library | 846 | 332 | 22 | 354 |'
  prefs: []
  type: TYPE_TB
- en: '| Springer Online Library | 440 | 20 | 0 | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| Wiley Online Library | 112 | 25 | 0 | 25 |'
  prefs: []
  type: TYPE_TB
- en: '| MDPI | 456 | 111 | 0 | 111 |'
  prefs: []
  type: TYPE_TB
- en: '| Total | 2823 | 628 | 22 | 650 |'
  prefs: []
  type: TYPE_TB
- en: 'We manually processed each of the 650 papers. This process involved an initial
    checking of all papers, followed by the extraction and recording of key information
    (including the deep-learning models, datasets, data-preprocessing methods, prediction
    intervals, model block diagrams, and evaluation metrics). Finally, the content
    was structured according to Fig. [1](#S3.F1 "Figure 1 ‣ 3.1\. Research Questions
    ‣ 3\. Methodology ‣ Short-Term Electricity-Load Forecasting by Deep Learning:
    A Comprehensive Survey"). Although the statistics and analysis results are based
    on all 650 publications, not all 650 are cited in this paper. Instead, we selectively
    cited papers with similar content based on the extracted information. Ultimately,
    this paper thoroughly reviews and cites approximately 200 articles.'
  prefs: []
  type: TYPE_NORMAL
- en: '4\. Answer to RQ1: The Distribution and Analysis of the Search Results'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ1. Our approach involved an analysis
    of the publication year trends and their distribution across various literature
    sources, providing a framework for understanding the evolution and scope of the
    field.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Publication Trends
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We gathered the publication year data of the 650 papers (shown in Fig. [2(b)](#S4.F2.sf2
    "Figure 2(b) ‣ Figure 2 ‣ 4.1\. Publication Trends ‣ 4\. Answer to RQ1: The Distribution
    and Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey")) to show the trends of STELF papers between
    2014 and 2023. Fig. [2(a)](#S4.F2.sf1 "Figure 2(a) ‣ Figure 2 ‣ 4.1\. Publication
    Trends ‣ 4\. Answer to RQ1: The Distribution and Analysis of the Search Results
    ‣ Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey")
    shows the number of publications per year, and Fig. [2(b)](#S4.F2.sf2 "Figure
    2(b) ‣ Figure 2 ‣ 4.1\. Publication Trends ‣ 4\. Answer to RQ1: The Distribution
    and Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey") shows the cumulative number of publications.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Fig. [2(a)](#S4.F2.sf1 "Figure 2(a) ‣ Figure 2 ‣ 4.1\. Publication Trends ‣
    4\. Answer to RQ1: The Distribution and Analysis of the Search Results ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey") shows
    that there were fewer than 10 publications per year during the first three years
    (2014 to 2016). There has been a rapid growth since 2017, with the number of publications
    exceeding 100 per year by 2021. Furthermore, an examination of the cumulative
    numbers of publications (Fig. [2(b)](#S4.F2.sf2 "Figure 2(b) ‣ Figure 2 ‣ 4.1\.
    Publication Trends ‣ 4\. Answer to RQ1: The Distribution and Analysis of the Search
    Results ‣ Short-Term Electricity-Load Forecasting by Deep Learning: A Comprehensive
    Survey")) reveals an exponential growth in the research output for STELF. Fig. [2(b)](#S4.F2.sf2
    "Figure 2(b) ‣ Figure 2 ‣ 4.1\. Publication Trends ‣ 4\. Answer to RQ1: The Distribution
    and Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey") also shows a linear function with an exceptionally
    high coefficient of determination ($R^{2}=0.9996$). The trend shown in Fig. [2(a)](#S4.F2.sf1
    "Figure 2(a) ‣ Figure 2 ‣ 4.1\. Publication Trends ‣ 4\. Answer to RQ1: The Distribution
    and Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey") is directly related to the rapid development
    of deep-learning technologies in recent years. It also highlights the significance
    of research in this field.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/76982f9eb86ec91d405ca9bd27e41a92.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Number of publications per year.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4fdb0f926f78a13cb8a05717282de6a3.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Cumulative number of publications per year.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 2. STELF papers published between January 1, 2014, and December 31, 2023.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: This figure depicts the distribution of publication years and the cumulative
    distribution over the years.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Types of Publication Venues
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The papers were sourced from multiple journals and conferences, with their
    proportion and distribution plotted in Fig. [3(b)](#S4.F3.sf2 "Figure 3(b) ‣ Figure
    3 ‣ 4.2\. Types of Publication Venues ‣ 4\. Answer to RQ1: The Distribution and
    Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by Deep
    Learning: A Comprehensive Survey"). Fig. [3(a)](#S4.F3.sf1 "Figure 3(a) ‣ Figure
    3 ‣ 4.2\. Types of Publication Venues ‣ 4\. Answer to RQ1: The Distribution and
    Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by Deep
    Learning: A Comprehensive Survey") shows that the number of publications published
    in journals (55%) exceeds those in conferences (45%). Fig. [3(b)](#S4.F3.sf2 "Figure
    3(b) ‣ Figure 3 ‣ 4.2\. Types of Publication Venues ‣ 4\. Answer to RQ1: The Distribution
    and Analysis of the Search Results ‣ Short-Term Electricity-Load Forecasting by
    Deep Learning: A Comprehensive Survey") shows that, apart from 2017, the number
    of journal publications consistently outpaces the number of conference publications.
    Fig. [3(b)](#S4.F3.sf2 "Figure 3(b) ‣ Figure 3 ‣ 4.2\. Types of Publication Venues
    ‣ 4\. Answer to RQ1: The Distribution and Analysis of the Search Results ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey") also shows
    a trend, for both journals and conferences, of increasing publication volume.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ea664fb34e5acecb63608ffcb5c72cb6.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Proportion of journals and conferences.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9f7a7ca021d04e737d2050a9cb67a50d.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Venue distribution per year.
  prefs: []
  type: TYPE_NORMAL
- en: Figure 3. Venue distribution of surveyed papers.
  prefs: []
  type: TYPE_NORMAL
- en: \Description
  prefs: []
  type: TYPE_NORMAL
- en: This figure provides a description of the classification and distribution for
    publication.
  prefs: []
  type: TYPE_NORMAL
- en: '5\. Answer to RQ2: The Electricity Load Datasets'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ2, which discusses the classification
    of datasets and examines some common public datasets. When selecting electricity
    load datasets, researchers need to choose the appropriate type of dataset based
    on the specific requirements of the forecasting scenario, which may include loads
    for residential households, commercial buildings, industry, and entire cities’
    system-level load.
  prefs: []
  type: TYPE_NORMAL
- en: Electricity load datasets play a crucial role in STELF. ELF typically relies
    on historical data to predict future electricity demand over specific periods.
    With the advancement of deep learning methods, these models require substantial
    amounts of data to train for accurate predictions. Electricity load datasets provide
    comprehensive historical electricity usage information, including load changes
    during different periods, consumer usage patterns, and the impact of seasonal
    and weather factors on electricity demand (Zhang et al., [2022c](#bib.bib203)).
    This information is vital for a deep understanding and accurate prediction of
    electricity demand patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Classification of Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Electricity load datasets can be broadly categorized based on their accessibility
    as either public or not. Public datasets are typically available online, and are
    usually provided by government agencies, power market operators, or research institutions (Giacomazzi
    et al., [2023](#bib.bib59); Li et al., [2020b](#bib.bib111); Xia et al., [2023](#bib.bib179);
    Khan et al., [2022](#bib.bib98); Atef and Eltawil, [2020](#bib.bib11)). Non-public
    datasets, in contrast, are usually not available due to considerations such as
    protecting competitive advantage, ensuring national security, complying with legal
    regulations, or protecting personal privacy.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Common Public Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The review of the 650 papers revealed a wide variety of datasets. Some papers
    (such as (Deepanraj et al., [2022](#bib.bib35); Sun et al., [2018](#bib.bib153);
    Chen et al., [2021](#bib.bib27))) did not mention the name or source of the dataset,
    while others (such as (Wang et al., [2020a](#bib.bib172); Arastehfar et al., [2022](#bib.bib9);
    Zhang et al., [2023c](#bib.bib207))) used multiple datasets, making it difficult
    to compile statistics. Table [2](#S5.T2 "Table 2 ‣ 5.2\. Common Public Datasets
    ‣ 5\. Answer to RQ2: The Electricity Load Datasets ‣ Short-Term Electricity-Load
    Forecasting by Deep Learning: A Comprehensive Survey") lists some of the most
    frequently used public datasets, which are:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Independent System Operator of New England (ISO-NE)¹¹1[https://www.iso-ne.com/](https://www.iso-ne.com/).:
    The dataset includes hourly electrical load, temperature, day type, and other
    information for the New England area of North America, from March 2003 to December
    2014.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Australian Energy Market Operator (AEMO)²²2[https://www.aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data](https://www.aemo.com.au/energy-systems/electricity/national-electricity-market-nem/data-nem/aggregated-data).:
    The dataset contains 30-minute time-series data on electrical loads for five regions
    in Australia (South Australia, Queensland, New South Wales, Western Australia,
    and Victoria).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Global Energy Forecasting Competition (GEFCom)³³3[https://www.kaggle.com/c/global-energy-forecasting-competition-2012-load-forecasting/data](https://www.kaggle.com/c/global-energy-forecasting-competition-2012-load-forecasting/data).:
    Each competition provides different datasets that cover historical data and related
    influencing factors for various regions and periods. The design of the datasets
    reflects the real-world conditions of energy markets and system operations.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'University of California, Irvine (UCI) Machine Learning Repository (MLR)⁴⁴4[https://archive.ics.uci.edu/ml/datasets](https://archive.ics.uci.edu/ml/datasets).:
    This dataset is a widely used public database covering simple datasets to complex
    multivariate time-series datasets. The household load data uses a sampling frequency
    of one minute.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'European Network of Transmission System Operators for Electricity (ENTSO-E)⁵⁵5[https://open-power-system-data.org/data-sources##1_European_load_data](https://open-power-system-data.org/data-sources##1_European_load_data).:
    This dataset is from an organization of electricity transmission system operators
    covering 35 European countries. The dataset includes real-world hourly electricity
    load time series from across Europe.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'PJM Interconnection (PJM)⁶⁶6[https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption](https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption).:
    This dataset is from a regional transmission organization in the United States
    responsible for operating the Eastern Interconnection grid. PJM transmits electricity
    to 14 regions in the United States, with data recorded at hourly MW intervals.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Commission for Energy Regulation (CER)⁷⁷7[https://www.cru.ie/](https://www.cru.ie/).:
    This dataset records the half-hourly load data of residential households and small
    to medium-sized enterprises in Ireland.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '2016 China Electrical Mathematical Modeling Competition⁸⁸8[https://github.com/huberyCC/Load-datasets](https://github.com/huberyCC/Load-datasets).:
    This dataset originates from the China Electrical Engineering Mathematical Modeling
    Competition and includes electrical load data and weather data from 2009 to 2015.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'All the datasets listed in Table [2](#S5.T2 "Table 2 ‣ 5.2\. Common Public
    Datasets ‣ 5\. Answer to RQ2: The Electricity Load Datasets ‣ Short-Term Electricity-Load
    Forecasting by Deep Learning: A Comprehensive Survey") have been used at least
    10 times. The frequent use of ISO-NE and AEMO especially, both of which exceed
    30 times, highlights their significant role and the high level of activity these
    datasets sustain in ELF research. The sampling frequency of the datasets varies
    from every minute to every hour, highlighting the diversity of real-time granularity,
    which supports a wide range of research and practical applications. Many important
    power datasets are covered, and distributed across multiple regions (including
    North America, Australia, Europe, and China).'
  prefs: []
  type: TYPE_NORMAL
- en: The majority of the public datasets can be accessed online through platforms
    such as Kaggle, official websites, and specialized data repositories. This facilitates
    their access and use by researchers worldwide. Open access and faster updates
    are two major trends in the development of power datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2. Commonly Used Electricity Datasets
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Usage Frequency | Sampling Frequency |'
  prefs: []
  type: TYPE_TB
- en: '| Independent System Operator of New England (ISO-NE) | 47 | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: '| Australian Energy Market Operator (AEMO) | 35 | 30 minutes |'
  prefs: []
  type: TYPE_TB
- en: '| Global Energy Forecasting Competition (GEFCom) | 23 | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: '| UCI Machine Learning Repository (UCI) | 23 | 1 minute |'
  prefs: []
  type: TYPE_TB
- en: '| European Network of Transmission System Operators for Electricity (ENTSO-E)
    | 15 | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: '| PJM Interconnection (PJM) | 11 | 1 hour |'
  prefs: []
  type: TYPE_TB
- en: '| Commission for Energy Regulation (CER) | 10 | 30 minutes |'
  prefs: []
  type: TYPE_TB
- en: '| 2016 China Electrical Mathematical Modeling Competition | 10 | 15 minutes
    |'
  prefs: []
  type: TYPE_TB
- en: '6\. Answer to RQ3: STELF Dataset Preprocessing'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we address RQ3, introducing the main data-preprocessing methods
    (including data cleaning, selection of external variables, and data reconstruction).
  prefs: []
  type: TYPE_NORMAL
- en: Data preprocessing is a crucial step that directly impacts the accuracy and
    reliability of the prediction models. Raw electricity-load data frequently contains
    noise, anomalies, and inconsistent records. There are also often missing values.
    Unaddressed, these issues can significantly disrupt the learning process of models,
    leading to inaccurate or ineffective predictions (Meng et al., [2022](#bib.bib125)).
    Data preprocessing uses a series of methods (such as filling in missing values,
    and anomaly detection, correction, and normalization) to enhance the data quality (Subbiah
    and Chinnappan, [2022](#bib.bib151)). The data also often exhibits strong temporal
    characteristics and seasonal variability. Appropriate preprocessing can help models
    capture these complex patterns, enhancing their understanding and responsiveness
    to temporal dynamics (Lv et al., [2021](#bib.bib123)). This section examines the
    various data-preprocessing steps and methods. It should be noted that published
    papers generally only mention one or several data preprocessing steps, not all.
    For example, Dong et al. (Dong et al., [2021a](#bib.bib40)) only discussed data
    normalization; Gao et al. (Gao et al., [2023a](#bib.bib56)) focused only on handling
    missing data; and Huang et al. (Dogra et al., [2023](#bib.bib37)) introduced data
    standardization and data reconstruction. Specific preprocessing measures are usually
    applied based on the design requirements of the model.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Data Cleaning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The data-cleaning process involves handling missing values, outliers, erroneous
    records, duplicate data, and performing standardization.
  prefs: []
  type: TYPE_NORMAL
- en: Various data-imputation techniques can be used to fill in the gaps of missing
    data (Rafati et al., [2020](#bib.bib137); Gan et al., [2017](#bib.bib54)). Some
    simple approaches include using the value from a previous time point or calculating
    the average of data from before and after the missing value (Li et al., [2019](#bib.bib108);
    Chen et al., [2023](#bib.bib25); Hua et al., [2023](#bib.bib87)). Other methods
    include data clustering (Li et al., [2022b](#bib.bib112)), and using values from
    the same time on adjacent dates (Zhang et al., [2022a](#bib.bib199)).
  prefs: []
  type: TYPE_NORMAL
- en: Outlier detection is often addressed using the three-sigma method (Khan et al.,
    [2022](#bib.bib98); Chandola et al., [2009](#bib.bib21)). Sharma et al. (Sharma
    and Jain, [2022](#bib.bib147)) also used the interquartile range for this purpose,
    while Qin et al. (Qin et al., [2022](#bib.bib136)) used box plots. Typically,
    when encountering outliers, erroneous records, or duplicated data, the main remedial
    strategies involve deletion or replacement (using established methods for handling
    missing values).
  prefs: []
  type: TYPE_NORMAL
- en: Data standardization relates to eliminating scale differences in the original
    data, allowing for comparison and calculation on the same scale. The use of raw
    data for analysis may lead to biases towards features with larger numerical ranges (Tan
    et al., [2022](#bib.bib154)). Two methods for data standardization are Min-Max
    Scaling and Z-Score Normalization (Wang et al., [2023b](#bib.bib174); Huang et al.,
    [2021](#bib.bib88)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Min-Max Scaling adjusts the data to fit within a specified range, commonly
    between 0 and 1. The formula for Min-Max Scaling is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $x_{\text{norm}}=\frac{x-\min(x)}{\max(x)-\min(x)},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $x$ is the original data value; $\min(x)$ and $\max(x)$ are the minimum
    and maximum values of the original data, respectively; and $x_{\text{norm}}$ is
    the scaled data.
  prefs: []
  type: TYPE_NORMAL
- en: 'Z-Score Normalization shifts the data’s mean to 0 and standard deviation to
    1, making it suitable for data that requires outlier mitigation and handling of
    skewed distributions. The formula for Z-Score Standardization is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $z=\frac{(x-\mu)}{\sigma},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $x$ is the original data value; $\mu$ is the mean of the data; and $\sigma$
    is the standard deviation.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. External Variable Selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The accuracy of STELF is determined not only by the operational conditions within
    the power system, but also by carefully considering a series of important external
    variables (Wang et al., [2023d](#bib.bib169)). The next task after completing
    the data cleaning is to identify the external variables that significantly impact
    the forecasting results (Cai et al., [2020](#bib.bib20)), such as the variability
    of climatic conditions, periodic fluctuations in temperature, holiday status,
    and dynamic changes in industrial activities. Appropriate consideration of these
    external factors can lead to a more comprehensive load forecasting model. This
    usually involves correlation analysis and variable-importance evaluation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [3](#S6.T3 "Table 3 ‣ 6.2\. External Variable Selection ‣ 6\. Answer
    to RQ3: STELF Dataset Preprocessing ‣ Short-Term Electricity-Load Forecasting
    by Deep Learning: A Comprehensive Survey") lists six commonly used methods for
    external variable selection, and some of the papers that use them. The Pearson
    Correlation Coefficient, for example, calculates the Pearson correlation between
    two continuous variables, with values ranging from -1 to 1. By determining a threshold
    for the correlation coefficient, only variables whose correlation with the target
    variable exceeds this threshold are considered to be correlated.'
  prefs: []
  type: TYPE_NORMAL
- en: Zheng et al. (Zheng et al., [2018](#bib.bib208)) used the Least Absolute Shrinkage
    and Selection Operator (LASSO) method to perform variable selection. Subbiah et
    al. (Subbiah and Chinnappan, [2022](#bib.bib151)) introduced the Robust ReliefF
    Mutual Information Recursive Feature Elimination Hybrid Feature Selection (RMR-HFS),
    which uses a combination of filter and wrapper methods for variable selection.
    These selection methods cover a wide range of data analysis needs, from linear
    to nonlinear correlations, from time series analysis to dimensionality-reduction
    techniques. Each method has its unique advantages, helping to better understand
    and uncover correlations within the data, and enabling the construction of more
    accurate and efficient predictive models.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3. Common Methods for Selecting External Variables
  prefs: []
  type: TYPE_NORMAL
- en: '| Selection Methods | Example reference |'
  prefs: []
  type: TYPE_TB
- en: '| Pearson Correlation Coefficient | (Wang et al., [2020a](#bib.bib172); Tang
    et al., [2019a](#bib.bib157); Shaqour et al., [2022](#bib.bib146); Bian et al.,
    [2022a](#bib.bib16); Hossain and Mahmood, [2020](#bib.bib79); Dong et al., [2017](#bib.bib39);
    Xie et al., [2022](#bib.bib181)) |'
  prefs: []
  type: TYPE_TB
- en: '| Copula Function Theory | (Wang et al., [2023d](#bib.bib169); He et al., [2017](#bib.bib71))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Maximum Information Coefficient | (Tang et al., [2022](#bib.bib156); Xiang
    et al., [2023](#bib.bib180); Jiao et al., [2021](#bib.bib96); Lu et al., [2022](#bib.bib121);
    Huang et al., [2023](#bib.bib89)) |'
  prefs: []
  type: TYPE_TB
- en: '| Autocorrelation Function | (Li et al., [2021](#bib.bib110); Javed et al.,
    [2022](#bib.bib94); Farid et al., [2023](#bib.bib49)) |'
  prefs: []
  type: TYPE_TB
- en: '| Spearman’s Rank Correlation Analysis | (Hong and Chan, [2023](#bib.bib75);
    Liu et al., [2022c](#bib.bib117); Hu et al., [2022c](#bib.bib85); Zamee et al.,
    [2021](#bib.bib195)) |'
  prefs: []
  type: TYPE_TB
- en: '| Principal Component Analysis | (Veeramsetty et al., [2022](#bib.bib162);
    Han et al., [2023](#bib.bib66)) |'
  prefs: []
  type: TYPE_TB
- en: 6.3\. Data Reconstruction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Data reconstruction plays a key role in dealing with the randomness, volatility,
    periodicity, and diversity (Kim et al., [2022](#bib.bib100)) of raw load data,
    and has become one of the key focus points in many STELF studies. A deep exploration
    of historical load data combined with advanced analytical methods (such as decomposition
    and clustering techniques) can reveal the key recurring patterns and trends in
    the data. These things are crucial for predictive models, as they help the models
    better understand and capture the dependencies within time-series data.
  prefs: []
  type: TYPE_NORMAL
- en: Several common methods are used for data reconstruction. The Variational Mode
    Decomposition (VMD) technique decomposes load data into a series of Intrinsic
    Mode Functions (IMFs), which are then used to reconstruct the data for training (Ahajjam
    et al., [2022](#bib.bib3)). Zang et al. (Zang et al., [2021](#bib.bib196)) also
    used VMD technology to decompose the load data into modalities of different frequencies,
    employing LSTM with self-attention mechanism for forecasting. This multi-frequency
    analysis method allows for a more nuanced handling of the complexity within load
    data. Similarly, Mathew et al. (Mathew et al., [2021](#bib.bib124)) used Empirical
    Mode Decomposition (EMD) to decompose the raw data into a series of IMFs, and
    then used the same model to train each mode. Based on EMD, Ensemble Empirical
    Mode Decomposition (EEMD) (Yue et al., [2022](#bib.bib194)) and Improved Complete
    Ensemble Empirical Mode Decomposition with Adaptive Noise (ICEEMDAN) (Zhang et al.,
    [2023f](#bib.bib206)) are also used for data reconstruction.
  prefs: []
  type: TYPE_NORMAL
- en: Advanced clustering methods have also been used for data reconstruction (Wu
    et al., [2022](#bib.bib178); Yang et al., [2019](#bib.bib186); Wang et al., [2020b](#bib.bib168)).
    Wu et al. (Wu et al., [2022](#bib.bib178)) applied K-shape time-series clustering
    to categorize users with similar electricity usage habits and characteristics
    into multiple types. Yang et al. (Yang et al., [2019](#bib.bib186)) used the K-means
    clustering algorithm to identify customer groups with similar electricity usage
    behaviors. Wang et al. (Wang et al., [2020b](#bib.bib168)) employed the Density-Based
    Spatial Clustering of Applications with Noise (DBSCAN) algorithm to deal with
    datasets that contained noise. Chaturvedi et al. (Chaturvedi et al., [2015](#bib.bib23))
    used wavelet transform technology to decompose load data into four wavelet components
    and then trained a neural network for each component, achieving precise predictions
    of different frequency characteristics.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [4](#S6.T4 "Table 4 ‣ 6.3\. Data Reconstruction ‣ 6\. Answer to RQ3:
    STELF Dataset Preprocessing ‣ Short-Term Electricity-Load Forecasting by Deep
    Learning: A Comprehensive Survey") summarizes some common data-reconstruction
    methods. Whether using decomposition or clustering techniques, the goal is to
    reconstruct the overall data to capture the distribution characteristics and underlying
    patterns of the data. Due to the complexity of load data, adopting a divide-and-conquer
    approach (where each part is trained using the same or different models) can enhance
    the efficiency and accuracy of the model. Reconstruction techniques not only provide
    a solid data foundation for the models but also directly influence the model’s
    design, the algorithm selection, and the precision of the forecasting outcomes.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4. Summary of Common Data Reconstruction Methods
  prefs: []
  type: TYPE_NORMAL
- en: '| Reconstruction method | Abbreviation | Example reference | Description |'
  prefs: []
  type: TYPE_TB
- en: '| Variational Mode Decomposition | VMD | (Wu et al., [2023b](#bib.bib176);
    Zang et al., [2021](#bib.bib196); Zhuang et al., [2022](#bib.bib210)) | A decomposition
    method based on the variational principle, solving intrinsic mode functions through
    optimization problems. |'
  prefs: []
  type: TYPE_TB
- en: '| Empirical Mode Decomposition | EMD | (Fan et al., [2020](#bib.bib48); Mounir
    et al., [2023](#bib.bib127); Ran et al., [2023](#bib.bib138)) | An empirical decomposition
    method that extracts intrinsic mode functions through an iterative process. |'
  prefs: []
  type: TYPE_TB
- en: '| Wavelet Transform | WT | (Chaturvedi et al., [2015](#bib.bib23); Zhang et al.,
    [2022c](#bib.bib203)) | A method that uses a set of wavelet functions to analyze
    signals, providing both time (or spatial) and frequency information about the
    signals. |'
  prefs: []
  type: TYPE_TB
- en: '| Density-Based Spatial Clustering of Applications with Noise | DBSCAN | (Yang
    et al., [2022](#bib.bib185); Wang et al., [2020b](#bib.bib168); Kong et al., [2017](#bib.bib101))
    | A density-based clustering algorithm that classifies points as cluster members,
    noise, or border points based on their density. |'
  prefs: []
  type: TYPE_TB
- en: '| K-means Clustering Algorithm | K-means | (Hu et al., [2022a](#bib.bib86);
    Yang et al., [2019](#bib.bib186)) | A clustering algorithm that partitions a dataset
    into K distinct, non-overlapping groups based on the similarity of data points.
    |'
  prefs: []
  type: TYPE_TB
- en: '| K-shape Clustering Algorithm | K-shape | (Wu et al., [2022](#bib.bib178);
    Fahiman et al., [2017](#bib.bib47)) | A clustering algorithm for time-series data
    that partitions the data into different groups based on shape similarity. |'
  prefs: []
  type: TYPE_TB
- en: '| Singular Spectrum Analysis | SSA | (Niu et al., [2016](#bib.bib132); Nie
    et al., [2020](#bib.bib131)) | A method for decomposing time-series data by extracting
    trend, periodic, and noise components to analyze the time series. |'
  prefs: []
  type: TYPE_TB
- en: '7\. Answer to RQ4: Methods for Feature Extraction'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ4, examining how deep learning can effectively
    extract deep non-linear features from the data, enhancing the model’s predictive
    capabilities. The purpose of feature extraction is to mine complex relationships
    from the raw load data that aid the model in understanding load changes. In STELF,
    feature extraction is a critical step, as it directly impacts the performance
    of the predictive model.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning can extract features in an unsupervised learning manner, automatically
    learning useful feature representations from the data (Wang et al., [2019b](#bib.bib165)).
    At different levels of the ANN, features at various levels of abstraction can
    be learned, providing the model with rich information. In STELF, in addition to
    considering the feature relationships within the time series itself, spatial feature
    relationships must also be considered (Cheung et al., [2021](#bib.bib29)), such
    as for large-scale ELF involving regional or urban power grids with distinct spatial
    relationships. The spatial characteristics are also crucial for fully understanding
    load change patterns and enhancing the accuracy of forecasts.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Temporal Feature Relationship Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Because electricity-load data are time-series data, RNNs can be used to capture
    the temporal dependencies. LSTMs and GRUs are often used in temporal feature relationship
    extraction. Xu et al. (Xu et al., [2018](#bib.bib183)) used an LSTM to extract
    deep features of electricity loads and employed an Extreme Learning Machine (ELM)
    to model shallow patterns. Abdel et al. (Abdel-Basset et al., [2022](#bib.bib2))
    proposed STLF-Net, using a GRU to get the long-term temporal representations of
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The success of feature extraction models based on the Multi-Channel One-Dimensional
    Convolutional Neural Network (MCNN) (Dong et al., [2023](#bib.bib38)) suggests
    that convolution operations can also be used to extract feature relationships
    in time-series data. This allows for the direct capture of inter-feature relationships
    on sequence data through One-Dimensional Convolution (Conv1D) operations. Although
    One-Dimensional CNNs (1-D CNNs) are functionally similar to RNNs (such as LSTM
    and GRU), they also have unique network structural designs to accommodate the
    varying characteristics and requirements of time-series data. These structural
    designs make it possible for 1-D CNNs to be optimized for specific types of sequence
    data, making them better at extracting useful feature relationships. Dai et al. (Dai
    et al., [2023](#bib.bib32)) used CNNs with Conv1D and pooling layers, where the
    Conv1D layer extracts pivotal features from the input data, and a pooling layer
    reduces the dimensionality and spatial complexity of the features.
  prefs: []
  type: TYPE_NORMAL
- en: Temporal Convolutional Networks (TCNs) are another type of ANN designed for
    sequence modeling tasks, especially those involving time-series data. Because
    the TCN is based on CNN (Bai et al., [2018](#bib.bib12)), it has also been widely
    used to extract feature vectors and long-term temporal dependencies (Bian et al.,
    [2022a](#bib.bib16); Wang et al., [2020a](#bib.bib172); Zhang et al., [2023c](#bib.bib207)).
    Zhang et al. (Zhang et al., [2023c](#bib.bib207)) proposed a hybrid network architecture
    combining TCN and LSTM to address the issue of model complexity. Their model leveraged
    the TCN’s ability to capture the receptive field in time series and effectively
    model temporal dependencies, while also incorporating the LSTM’s ability to handle
    long-term dependency problems.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2\. Spatial Feature Relationship Extraction
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Extraction of spatial feature relationships involves the construction of an
    adjacency matrix to represent the connections between nodes in the power network.
    Multi-dimensional convolution is used to obtain the spatial features. Hua et al. (Hua
    et al., [2023](#bib.bib87)) proposed a predictive model that combines CNN and
    GRU, extracting spatial features through the CNN and temporal features through
    the GRU. Wan et al. (Wan et al., [2023](#bib.bib164)) used CNNs to extract spatial
    information from the load data, with the resulting features then input into the
    RNN for training.
  prefs: []
  type: TYPE_NORMAL
- en: Another approach involves the construction of a spatio-temporal graph model
    that can simultaneously capture the spatial and temporal dependencies of electricity-load
    data. Yu et al. (Yu and Li, [2021](#bib.bib192)) fed graph-structured data into
    a Spatio-Temporal Synchronous Graph Convolutional Network (STSGCN) model to perform
    load forecasting by extracting the inherent spatio-temporal features from historical
    load data. The spatio-temporal graph model constructs a similarity-weighted spatio-temporal
    graph by combining the feature sets of multiple nodes (Huang et al., [2023](#bib.bib89)).
    The Spatial Convolutional Layer (SCL) extracts the features of neighboring nodes
    for each node in the graph, thereby enhancing the full-domain node features.
  prefs: []
  type: TYPE_NORMAL
- en: Features extracted using deep learning cannot be directly applied to STELF.
    A supervised learning-regression process is required to transform these nonlinear
    features into prediction results. A variety of methods (such as linear/nonlinear
    regression, or neural networks) can be used to perform this mapping (Wang et al.,
    [2019b](#bib.bib165)).
  prefs: []
  type: TYPE_NORMAL
- en: '8\. Answer to RQ5: Deep-Learning-Based Modeling Methods for STELF'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ5, offering an extensive review of the
    literature on deep-learning-based predictive models. From the perspective of forecasting
    outcomes, predictive models can be categorized as either deterministic or probabilistic
    (Benidis et al., [2022](#bib.bib15)).
  prefs: []
  type: TYPE_NORMAL
- en: 8.1\. Deterministic Forecasting Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In STELF, deterministic forecasting provides an exact numerical prediction,
    offering precise predictions of the load level at a specific point in time or
    over a certain period in the future. This type of forecasting focuses on delivering
    a concrete value rather than a range or distribution. Due to the extensive literature
    and methods involved, we examine this type of forecasting from the perspectives
    of single and hybrid models.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.1\. Single Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Simplicity is the main advantage of the single model, which is easy to understand
    and construct. Deep learning algorithms make use of deep networks, consisting
    of a series of complex hidden layers (Eren and Küçükdemiral, [2024](#bib.bib44)).
    Early STELF achieved predictive results by stacking ANNs (Singh and Dwivedi, [2018](#bib.bib149);
    Din and Marnerides, [2017](#bib.bib36)). Chen et al. (Chen et al., [2019](#bib.bib24))
    and Hossen et al. (Hossen et al., [2017](#bib.bib81)) explored ELF using DNNs.
    Chen et al. proposed a method based on two-terminal sparse coding and deep neural
    network fusion, while Hossen et al. examined the impact of single-layer versus
    double-layer DNN architectures. A DBN, similar in structure to DNN, combines multiple
    RBMs for ELF and uses a layer-by-layer unsupervised learning method to pre-train
    the initial weights (Dedinec et al., [2016](#bib.bib34)).
  prefs: []
  type: TYPE_NORMAL
- en: 'DNNs or DBNs formed by stacking multiple layers typically lack memory capability,
    which means that they may not be able to use previous information effectively
    when processing time-series data. RNNs use recurrent connections, allowing the
    network to retain previous information while processing sequence data, potentially
    adjusting the output based on earlier elements in the sequence. This makes RNNs
    (including LSTM and GRU, as introduced in Section [2](#S2 "2\. Background ‣ Short-Term
    Electricity-Load Forecasting by Deep Learning: A Comprehensive Survey")) very
    popular for time-series forecasting. LSTMs and GRUs are advanced RNNs that have
    been used in STELF (Kong et al., [2017](#bib.bib101); Morais et al., [2023](#bib.bib126)).
    Zhu et al. (Zhu et al., [2022](#bib.bib209)) proposed a dual-attention encoder-decoder
    structure using attention mechanisms, using an LSTM as a specific encoder and
    decoder for nonlinear dynamic time modeling. This attention mechanism dynamically
    focused on the importance of different parts of the input sequence, significantly
    enhancing the performance of RNNs used in conjunction. Aseeri et al. (Aseeri,
    [2023](#bib.bib10)) also used a GRU structure to focus on key variables, improving
    performance, particularly with longer sequences.'
  prefs: []
  type: TYPE_NORMAL
- en: A bidirectional RNN is an innovative ANN architecture that integrates two recurrent
    layers, each with a distinct role. One layer captures the forward flow of the
    sequence, while the other focuses on the backward flow. This bidirectional processing
    mechanism makes it possible to comprehensively understand the sequence data, enabling
    feature and information extraction from both temporal directions simultaneously
    (Mughees et al., [2021](#bib.bib128)). This bidirectional structure, such as in
    the Bidirectional Long Short-Term Memory (BiLSTM) (Wang et al., [2019c](#bib.bib171))
    and Bidirectional Gated Recurrent Unit (BiGRU) (Shaqour et al., [2022](#bib.bib146)),
    has a strong predictive capability, and is popular in STELF research.
  prefs: []
  type: TYPE_NORMAL
- en: Using a CNN as a standalone STELF model involves treating time-series data directly
    as one-dimensional images or creating images from the sequence values of multivariate
    time series (Sadaei et al., [2019](#bib.bib141)). The convolutional layers in
    CNNs are used to extract local features; while pooling layers reduce the dimensionality
    of time-series data — this helps with both extracting more abstract features and
    reducing computational complexity (Jalali et al., [2021](#bib.bib92)). Finally,
    one or more fully connected layers are used to generate the output sequence. As
    a variant of CNNs, TCNs extend the receptive field and capture long-range sequence
    dependencies by increasing the spacing of convolutional kernels (Bai et al., [2018](#bib.bib12)).
    TCNs extract the complex interactions between time-series and non-time-series
    data, resulting in precise feature quantities (Bian et al., [2022b](#bib.bib17)).
    Yin et al. (Yin and Xie, [2021](#bib.bib190)) used TCNs to extract key features
    from multiple spatial scale samples, yielding initial predictive outcomes. A similar
    model based on CNN, WaveNet, is a generative model developed by DeepMind, primarily
    used for generating audio waveforms (Van Den Oord et al., [2016](#bib.bib159)).
    WaveNet has also been used for STELF (Voß et al., [2018](#bib.bib163); Lin et al.,
    [2021](#bib.bib115)).
  prefs: []
  type: TYPE_NORMAL
- en: The Transformer model, proposed by Vaswani et al. (Vaswani et al., [2017](#bib.bib161))
    in 2017, has seen great success in various natural language processing tasks,
    and has also been extended to other fields such as image processing and time-series
    forecasting. The Transformer’s powerful feature-extraction and sequence-modeling
    capabilities also make it a good choice for STELF (Zhang et al., [2023b](#bib.bib202),
    [2022b](#bib.bib198); Nawar et al., [2023](#bib.bib129)).
  prefs: []
  type: TYPE_NORMAL
- en: Two models based on the Transformer are the Informer and the Temporal Fusion
    Transformer (TFT) (Gao et al., [2023b](#bib.bib57); Santos et al., [2023](#bib.bib143)).
    The Informer model focuses on the most critical time steps, using a probabilistic
    sparsity approach, ignoring less important information. Gao et al. (Gao et al.,
    [2023b](#bib.bib57)), for example, established a hybrid ELF model based on the
    Informer. Yu et al. (Yu et al., [2022](#bib.bib191)) proposed a self-attention-based
    STELF method considering demand-side management, using an informer to independently
    predict and reconstruct the decomposed intrinsic mode function components. The
    TFT model focuses on how to integrate different types of time-series data to improve
    prediction accuracy. Giacomazzi et al. (Giacomazzi et al., [2023](#bib.bib59))
    explored the potential of TFT for hourly STELF across different time ranges (such
    as the previous day and the previous week).
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.2\. Hybrid Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In STELF, hybrid deep-learning models are becoming a key technology for solving
    complex forecasting problems. Hybrid models integrate a variety of deep-learning
    models, with advantages including their diversity and flexibility. Complementing
    each other’s strengths, they enhance the accuracy and robustness of predictions (Lin
    et al., [2022b](#bib.bib116)). The hybrid model primarily employs two strategies
    for combination: stage-wise training and joint training. Stage-wise training involves
    focusing on specific learning tasks at each stage, while joint training involves
    training all components of the hybrid model simultaneously.'
  prefs: []
  type: TYPE_NORMAL
- en: '(1) Stage-wise Training: Stage-wise training strategy addresses some challenges
    for training complex models by breaking down the training process into a series
    of orderly stages. In each stage, a part of the model is independently trained
    and optimized to learn specific patterns.'
  prefs: []
  type: TYPE_NORMAL
- en: A hybrid model integrating CNN with RNN has become a widely adopted solution,
    due to its exceptional performance (Feng et al., [2024](#bib.bib53); Shi et al.,
    [2023](#bib.bib148); Yi et al., [2023](#bib.bib189); Sekhar and Dahiya, [2023](#bib.bib145);
    Aouad et al., [2022](#bib.bib8); Guo et al., [2021](#bib.bib61)). Zhang et al. (Zhang
    et al., [2023a](#bib.bib205)) proposed a hybrid model based on CNN and LSTM, using
    CNN layers for feature extraction from the input dataset and an LSTM model for
    sequence prediction, supporting multi-step forecasting of time-series data. Their
    approach leverages the efficient CNN capability to extract local features, using
    their output feature vectors as inputs for the RNN, which allows the RNN to further
    capture the dynamic changes and long-term dependencies in the time series. Jin
    et al. (Jin et al., [2022](#bib.bib97)) used a CNN-GRU hybrid model based on parameter-transfer
    learning. By transferring the parameters of a trained model from one with a large
    dataset to another trained with a smaller dataset, the model’s performance and
    predictive accuracy were enhanced. Here, transfer learning was used to address
    the issue of insufficient training data (Ozer et al., [2021](#bib.bib133)).
  prefs: []
  type: TYPE_NORMAL
- en: There are also some novel hybrid models based on the stage-wise structure. The
    combination of Graph Neural Network (GNN) and TCN passes the features extracted
    by the GNN to the TCN for further training (Lin et al., [2021](#bib.bib115)).
    The combination of LSTM and TFT uses the LSTM as an encoder-decoder to preprocess
    the data, which is then fed as training data into the TFT (Santos et al., [2023](#bib.bib143)).
    A more complex fusion proposed by Bu et al. (Bu et al., [2023](#bib.bib18)) involves
    a hybrid model combining Conditional Generative Adversarial Networks (CGAN) with
    CNN. The CGAN uses the CNN’s ability to accurately capture internal features to
    generate realistic fake samples, while the semi-supervised regression layer optimizes
    the discriminator to enhance sample authenticity recognition.
  prefs: []
  type: TYPE_NORMAL
- en: '(2) Joint Training: Joint training integrates various components of a model
    into a unified training framework, enabling synchronous training of each component.
    Data reconstruction techniques can result in different modalities, requiring models
    to be trained for each modality (Wang et al., [2023d](#bib.bib169); Zhang et al.,
    [2023d](#bib.bib200); Luo et al., [2022](#bib.bib122)). This approach leverages
    the characteristics of the different modalities, training concurrently, enhancing
    the overall performance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Data can be divided into multiple components, with different models being used
    to train separately and simultaneously on their respective data. He et al. (He
    et al., [2021](#bib.bib69)) used Per-unit Curve Rotation Decoupling (PCRD) to
    decompose the load into three parts: the rotating unit-load curve; the zero AM
    load; and the daily average load. A CNN extracted the shape features of the rotating
    unit-load curve, while a TCN simultaneously extracted the temporal features of
    the zero AM load and daily average load. This divide-and-conquer mechanism generates
    multiple preliminary prediction results, which ultimately need to be synthesized
    into a final prediction using weighted averaging, voting mechanisms, or attention
    mechanisms. Hua et al. (Hua et al., [2023](#bib.bib87)) used an attention mechanism
    to dynamically connect the preliminary results, with a CNN capturing spatial features
    and a GRU capturing temporal features.'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike existing ELF methods that place separate convolutional layers on top
    of the entire RNN, Liu et al. (Liu et al., [2022b](#bib.bib119)) embedded a 3-D
    convolutional filter within the LSTM unit, enabling the capture of translation-invariant
    local patterns both within and across spatial neighborhoods in the channels. This
    strategy of embedding one deep-learning model into another, through hierarchical
    model integration, enabled deep abstraction and effective utilization of data
    features. Eskandari et al. (Eskandari et al., [2021](#bib.bib45)) also used this
    strategy, combining a GRU and an LSTM to form a bidirectionally-propagating neural
    network. This used multidimensional features extracted by a 2-D CNN as input and
    provided these features to the bidirectional units for hourly ELF.
  prefs: []
  type: TYPE_NORMAL
- en: 8.2\. Probabilistic Forecasting Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Probabilistic ELF predicts future demand using the uncertainty and randomness
    of the load. Unlike traditional deterministic methods, probabilistic models provide
    a quantified expression of predictive uncertainty, which has significant advantages
    for power grid planning and operation (Yang et al., [2018](#bib.bib187)). Probabilistic
    models express the uncertainty of prediction results by generating a distribution
    of outcomes, rather than a single value (Jalali et al., [2022](#bib.bib93)).
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main approaches for probabilistic ELF: parametric and non-parametric
    methods(Hou et al., [2022](#bib.bib82)). Parametric methods are based on assumptions
    about the distribution of the load data, typically assuming that the data follows
    a known probability distribution (such as the normal distribution or the Poisson
    distribution). Due to their use of fewer assumptions, non-parametric methods have
    much broader applicability (Van der Meer et al., [2018](#bib.bib160)). Non-parametric
    methods do not require that the data follow a specific distribution form, starting
    instead directly from the actual data, uncovering the probabilistic distribution
    characteristics through the data itself (Huang et al., [2020](#bib.bib90)). To
    the best of our knowledge, the application of deep learning in probabilistic ELF
    extends from deterministic point predictions to probabilistic distribution forecasting (Feng
    et al., [2019](#bib.bib52); Cheng et al., [2021](#bib.bib28); Chen et al., [2018](#bib.bib26)).
    This process requires the generation of point predictions, and then uses non-parametric
    techniques (such as quantile regression, bootstrapping, confidence interval estimation,
    gradient boosting, and kernel density estimation (Wang et al., [2019b](#bib.bib165)))
    to construct a probabilistic ELF model.'
  prefs: []
  type: TYPE_NORMAL
- en: Lin et al. (Lin et al., [2022a](#bib.bib114)) introduced an LSTM with a two-stage
    attention mechanism for probabilistic short-term regional load forecasting, enhancing
    uncertainty estimation and accuracy when trained with quantile loss. The combination
    of deep learning and non-parametric methods is an innovative solution to probabilistic
    ELF. This harnesses the deep-learning ability to capture data complexity and generate
    accurate point predictions, and enables forecasts with probability distributions
    through non-parametric techniques. Wang et al. (Wang et al., [2019a](#bib.bib173))
    extended the traditional LSTM-based point prediction to a quantile-based probabilistic
    forecast. Liu et al. (Liu et al., [2022a](#bib.bib118)) integrated the GRU deep-feature-extraction
    capability with the CNN’s efficient parallel processing, while also employing
    kernel density estimation to accurately fit the probability density. Zhang et
    al. (Zhang et al., [2023e](#bib.bib197)) proposed the Quantile Regression Convolutional
    Bidirectional Long Short-Term Memory (QRCNNBiLSTM), which integrates quantile
    regression with feature extraction and bidirectional data processing. Through
    this integration, QRCNNBiLSTM can make precise joint predictions for the upper
    and lower bounds of the forecast interval.
  prefs: []
  type: TYPE_NORMAL
- en: The integration of deep learning and non-parametric methods in probabilistic
    ELF can more accurately capture the uncertainty in load variations, providing
    more comprehensive and reliable decision support for power systems.
  prefs: []
  type: TYPE_NORMAL
- en: '9\. Answer to RQ6: Optimizing the Training Process'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ6, examining ways to optimize deep-learning
    training processes (Zhang et al., [2021](#bib.bib201)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Optimization mainly involves two aspects: network-structure optimization and
    error optimization. Optimization of the network structure relates to the architectural
    design of the model, and involves adjusting the number of layers, configuring
    the neurons, and modifying the connection methods. This all aims at constructing
    a robust model capable of capturing the complex features of the data. Error optimization
    involves thorough analysis and fine-tuning of the prediction errors, aiming to
    minimize the discrepancy between the model’s predictions and the actual observed
    values, thereby enhancing the accuracy and reliability.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.1\. Network-Structure Optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Network architecture design is a very important task, requiring careful selection
    of the number of neurons in each layer and the number of hidden layers in the
    network, etc (Jiang and Zheng, [2022](#bib.bib95)). The selection is not completed
    in a single step, but rather needs to be determined based on the nature of the
    problem, the characteristics of the data, and the expected performance of the
    model. Selecting the optimal network structure and model parameters is a complex
    process, with a number of trial-and-error methods and heuristic optimization algorithms
    having been proposed (Wang et al., [2019b](#bib.bib165)).
  prefs: []
  type: TYPE_NORMAL
- en: As a fundamental problem-solving method, the trial-and-error approach involves
    gradually approaching a solution through continuous attempts and adjustments.
    This is not limited to only simple experiments and adjustments, but has been combined
    with heuristic optimization techniques to form efficient and systematic optimization
    strategies. The heuristic algorithms draw inspiration from optimization mechanisms
    found in nature and social phenomena, including Particle Swarm Optimization (PSO) (Hong
    and Chan, [2023](#bib.bib75)), Genetic Algorithms (GAs) (Dong et al., [2021b](#bib.bib41)),
    the Whale Optimization Algorithm (WOA) (Haiyan et al., [2020](#bib.bib65)), Grey
    Wolf Optimizer (GWO) (Sekhar and Dahiya, [2023](#bib.bib145)), and the Grasshopper
    Optimization Algorithm (GOA) (Hu et al., [2022b](#bib.bib83)).
  prefs: []
  type: TYPE_NORMAL
- en: Methods based on Bayesian optimization (Bayram et al., [2023](#bib.bib14); Xu
    et al., [2022](#bib.bib182)) predict parameter performance using probabilistic
    models, guiding the search process to more intelligently select the next set of
    candidate parameters. This is particularly well-suited for high-dimensional parameter
    spaces, significantly reducing the number of evaluations required. In summary,
    more accurate optimization algorithms can help to more effectively explore the
    potentially vast parameter space and identify parameter combinations that significantly
    enhance performance.
  prefs: []
  type: TYPE_NORMAL
- en: 9.2\. Error Optimization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Once the loss function is defined, the network weights need to be updated by
    calculating the loss-function gradient using optimization algorithms, such as
    gradient descent and its variants (Adam, RMSprop, etc. (Wu et al., [2023a](#bib.bib175);
    Ganjouri et al., [2023](#bib.bib55))) (Hong and Fan, [2016](#bib.bib74)). These
    algorithms adjust the model’s parameters to gradually reduce the loss-function
    value, improving the model’s accuracy. The following is a list of some commonly-used
    optimizers:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SGD (Sakib et al., [2021](#bib.bib142)): This uses only one sample to compute
    the gradient and update the parameters in each iteration. This allows for quick
    updates, but can result in high variance, due to only using a single sample.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RMSprop (Langevin et al., [2023](#bib.bib105); Yazici et al., [2022](#bib.bib188);
    He, [2017](#bib.bib70)): This adjusts the learning rate by maintaining a decaying
    average of the squared gradients for each parameter, achieving adaptive learning
    rates. This is particularly effective for handling different learning rates for
    different parameters, accelerating convergence, and avoiding local minima or saddle
    points.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AdaBelief (Yu et al., [2022](#bib.bib191)): This employs a concept of belief,
    which depends on the ratio of the squared gradient to its historical mean. When
    this ratio is greater than 1, AdaBelief is more inclined to trust the current
    gradient information; otherwise, it relies more on previous information.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Adam (Wang et al., [2023a](#bib.bib166); Su et al., [2023](#bib.bib150); Sun
    et al., [2020](#bib.bib152)): This is an adaptive gradient descent method that
    independently adjusts the learning rate for each parameter by combining the exponentially
    weighted averages of the first and second moments. This approach achieves a fast
    and robust optimization process.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '10\. Answer to RQ7: Evaluation of Forecast Results'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ7, examining ways to evaluate the accuracy
    of the prediction results. This not only involves verifying the accuracy of the
    model outputs (to ensure that the predicted results are close to the actual load
    values), but also relates to the model’s reliability and effectiveness.
  prefs: []
  type: TYPE_NORMAL
- en: 'A comprehensive evaluation of the prediction model performance requires a set
    of evaluation metrics. These metrics should be able to quantify the size and distribution
    of prediction errors from different perspectives. They should enable a fair and
    objective comparison of the prediction performance of different models, under
    a unified standard. Metrics for the evaluation of deterministic load forecasting
    include: Mean Squared Error (MSE); Root Mean Squared Error (RMSE); Mean Absolute
    Error (MAE); Mean Absolute Percentage Error (MAPE); and $R^{2}$. Similarly, metrics
    for the evaluation of probabilistic load forecasting include: Continuous Ranked
    Probability Score (CRPS); Prediction Interval Coverage Probability (PICP); and
    Pinball Loss (PL). Typically, multiple evaluation metrics are used together to
    enable a multi-faceted assessment. Table [5](#S10.T5 "Table 5 ‣ 10\. Answer to
    RQ7: Evaluation of Forecast Results ‣ Short-Term Electricity-Load Forecasting
    by Deep Learning: A Comprehensive Survey") lists the formulas and descriptions
    for some commonly-used evaluation metrics.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 5. Common Evaluation Metrics
  prefs: []
  type: TYPE_NORMAL
- en: Evaluation Metrics Formula Description Purpose MSE $\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}$
    Measures the difference between predicted values and actual values, focusing on
    large errors Deterministic Forecasting RMSE $\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}}$
    The square root of the MSE, preserving its properties while also keeping consistent
    with the original data, making interpretation easier MAE $\frac{1}{n}\sum_{i=1}^{n}|y_{i}-\hat{y}_{i}|$
    Measures the average absolute difference between predicted and actual values,
    focusing on small errors MAPE $\frac{1}{n}\sum_{i=1}^{n}\left|\frac{y_{i}-\hat{y}_{i}}{y_{i}}\right|\times
    100\%$ Measures the error as a percentage relative to the actual values, suitable
    for proportional data R² $1-\frac{\sum_{i=1}^{n}(y_{i}-\hat{y}_{i})^{2}}{\sum_{i=1}^{n}(y_{i}-\overline{y})^{2}}$
    Assesses the model’s explanatory power, with values closer to 1 indicating a superior
    fit to the data CRPS $\int_{-\infty}^{\infty}\left(F(x)-\mathbf{1}_{\{x\geq y\}}\right)^{2}dx$
    Measures the difference between the probabilistic forecast distribution and the
    actual observations Probabilistic Forecasting PICP $\frac{1}{N}\sum_{i=1}^{N}\mathbf{1}_{\{a_{i}\leq
    y_{i}\leq b_{i}\}}$ Assesses how often the prediction intervals contain the actual
    observations PL $\frac{1}{n}\sum_{i=1}^{n}\left(\tau(y_{i}-\hat{y}_{i})\mathbf{1}_{\{y_{i}\geq\hat{y}_{i}\}}+(1-\tau)(\hat{y}_{i}-y_{i})\mathbf{1}_{\{y_{i}<\hat{y}_{i}\}}\right)$
    Assesses the effectiveness of quantile predictions
  prefs: []
  type: TYPE_NORMAL
- en: Recently, some novel and improved evaluation metrics have also been introduced.
    Faustine et al. (Faustine and Pereira, [2022](#bib.bib50)) and Ganjouri et al. (Ganjouri
    et al., [2023](#bib.bib55)), for example, used a Normalized Root Mean Square Error
    (NRMSE) as evaluation metrics; Wang et al. (Wang et al., [2023c](#bib.bib167))
    used an Average Interval Score (AIS), Coverage Probability (CP), and Specificity
    Probability (SP) to evaluate the performance of interval probabilistic forecasting;
    and Zhang et al. (Zhang et al., [2023g](#bib.bib204)) introduced the Coverage
    Rate (CR) to evaluate the predictive coverage of the model (which represents the
    proportion of times the confidence intervals generated by the model cover the
    true values out of the total number of instances) and the Interval Average Convergence
    (IAC) to assess the model’s convergence.
  prefs: []
  type: TYPE_NORMAL
- en: '11\. Answer to RQ8: Challenges and Future Development Trends of STELF'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section provides the answers to RQ8, examining the challenges and potential
    future opportunities for the application of deep learning in STELF.
  prefs: []
  type: TYPE_NORMAL
- en: 11.1\. Challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Although there has been significant effort dedicated to exploring the application
    of deep learning in STELF, especially in recent years, some challenges remain.
    Some of these challenges include: the need for standardized datasets; the generalizability
    of models; insufficient research in probabilistic load forecasting; the interpretability
    of deep learning results; and real-time prediction capabilities. Addressing and
    overcoming these challenges will be critical for the widespread application of
    deep learning in the field of STELF. In particular:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: STELF researchers use a variety of datasets, including both private and public
    data. This can present a challenge for verifying model performance. The lack of
    standardized benchmark datasets makes it complex and difficult to compare performances.
    Developing some widely recognized standardized datasets is thus of urgent importance
    for advancing STELF research.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although many studies have addressed the common goal of ELF, they often focus
    on different application scenarios and loads, such as building loads (Chiu et al.,
    [2023](#bib.bib30)), household loads (Fekri et al., [2021](#bib.bib51)), and city-level
    loads (Yang et al., [2023](#bib.bib184)). The specificity of these scenarios may
    lead to models being overly optimized for a particular environment, raising challenges
    for the model’s generalizability. Therefore, It is necessary to study models with
    strong generalization ability for use in different scenarios.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Although the academic community has extensively studied deterministic STELF,
    there remains a lack of research into probabilistic load forecasting. Compared
    with deterministic forecasting, there is significantly less focus on deep-learning-based
    probabilistic ELF models. Therefore, more research needs to be applied to probabilistic
    forecasting models, which will enhance their ability to cope with uncertainties.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The interpretability of deep-learning-based forecasting models is an unresolved
    challenge. The complex mechanisms and decision pathways used by these models are
    often unknown, and lack intuitive transparency. This can impact the acceptance
    and effectiveness of the models in practical applications. Therefore, improving
    the interpretability of deep learning is crucial for its widespread adoption,
    long-term operation, and decision support in power systems.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The demand for STELF is increasing, especially for real-time capabilities. However,
    most previous research is based on offline learning modes, which rely on large
    amounts of historical data for training, and may not easily incorporate the latest
    data for real-time learning (Eren and Küçükdemiral, [2024](#bib.bib44)). To address
    this challenge, online learning mechanisms will be essential.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 11.2\. Research Trends
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recent STELF research trends include moving towards better integration, precision,
    and intelligence. Ongoing work to develop more sophisticated and enhanced forecasting
    models aims at improving prediction accuracy and reliability. This section examines
    the future STELF research directions of image-processing techniques, Large Language
    Models (LLMs), and optimization.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As power networks evolve, dynamic graph models can adapt to changes in nodes
    and edges, maintaining the flexibility of the forecasting model. Graph techniques
    can integrate multiple data sources (such as geographical locations, historical
    loads, and weather conditions). Our review found that most STELF graph techniques
    use convolution operations to extract temporal or spatial feature relationships.
    However, Liu et al. (Liu et al., [2022b](#bib.bib119)) converted the data into
    an image, and part of the future values to be predicted was transformed into blank
    patches. Thus, estimating future values became a similar problem to generating
    pixels for the missing regions of an image. Similar to image inpainting techniques,
    image generation and segmentation technologies have not yet been widely applied
    in STELF. Although these techniques may seem unrelated to STELF, their core ideas
    and methodologies can provide new perspectives and possibilities for STELF research.
    By applying these key image-processing concepts and algorithms to STELF, new research
    directions can be created, and models’ ability to identify and predict complex
    load patterns can be enhanced.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The recent rapid development of LLM technology has led to the exploration of
    its application to time-series forecasting tasks, opening up new areas in time-series
    prediction (Yu et al., [2023](#bib.bib193); Chang et al., [2023](#bib.bib22)).
    However, the use of LLMs for STELF has not yet been developed. Nevertheless, it
    is anticipated that application of LLMs to STELF shall become an important research
    direction. This may provide us with new ways to address the challenge of insufficient
    generalizability of forecasting models, while also opening up the possibility
    to achieve zero-shot learning in ELF (Gruver et al., [2024](#bib.bib60)). This
    type of model may not only demonstrate stronger adaptability and predictive power
    on diverse datasets, but also make reasonable predictions on unseen data.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Optimization is a critical stage in the development of deep-learning models,
    and has been receiving attention in STELF  (Zhang et al., [2021](#bib.bib201)).
    Future research will continue to explore more efficient optimization algorithms,
    such as improved SSA (Neeraj et al., [2021](#bib.bib130)), Adam (Hong et al.,
    [2022](#bib.bib76)), and other optimization methods tailored to specific problems.
    Network architecture optimization is evolving towards more lightweight networks,
    with the relevant error-optimization process becoming more refined (including
    in-depth research and customization of loss functions). Model compression techniques
    and acceleration algorithms will continue to evolve, leading the optimization
    process to place greater emphasis on computational efficiency.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 12\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This review paper has examined advances in the application of deep learning
    in STELF over the past decade. Over this period, the application of deep learning
    to STELF has grown in popularity, and will continue to do so. We employed a comprehensive
    review-research methodology to identify the relevant literature, ensuring the
    breadth and depth of the research findings. We used specific keywords to search
    six major databases and conducted manual screening to ensure the completeness
    of the data. During the literature review process, we specifically extracted and
    recorded key information from each paper based on the designed eight RQs. We carefully
    organized the extracted information and created specific charts and tables to
    help readers understand.
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we have analyzed and summarized the search results, and provided
    a detailed analysis of publication trends. We organized the structure of the paper
    according to the practical workflow of STELF, (including the introduction of the
    dataset, data preprocessing methods, feature extraction methods, the introduction
    of deep learning models, optimization methods, and evaluation metrics) and conducted
    an in-depth analysis of each stage. The content of each prediction step is categorized
    according to a specific method to ensure it is presented in an organized manner.
    We have provided concise explanations of commonly-used techniques in conjunction
    with cited literature. This structured presentation makes the content clear and
    logical, while also helping researchers quickly understand the research trends
    and core issues in this domain. We have also summarized the challenges and future
    research trends in the STELF field. Overall, this review paper, with its comprehensive,
    systematic approach, and guidance, provides significant academic value and practical
    relevance.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abdel-Basset et al. (2022) Mohamed Abdel-Basset, Hossam Hawash, Karam Sallam,
    Sameh S Askar, and Mohamed Abouhawwash. 2022. STLF-Net: Two-stream deep network
    for short-term load forecasting in residential buildings. *Journal of King Saud
    University-Computer and Information Sciences* 34, 7 (2022), 4296–4311.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ahajjam et al. (2022) Mohamed Aymane Ahajjam, Daniel Bonilla Licea, Mounir Ghogho,
    and Abdellatif Kobbane. 2022. Experimental investigation of variational mode decomposition
    and deep learning for short-term multi-horizon residential electric load forecasting.
    *Applied Energy* 326 (2022), 119963.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akhtar et al. (2023) Saima Akhtar, Sulman Shahzad, Asad Zaheer, Hafiz Sami
    Ullah, Heybet Kilic, Radomir Gono, Michał Jasiński, and Zbigniew Leonowicz. 2023.
    Short-term load forecasting models: A review of challenges, progress, and the
    road ahead. *Energies* 16, 10 (2023), 4060.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Al Mamun et al. (2020) Abdullah Al Mamun, Md Sohel, Naeem Mohammad, Md Samiul Haque
    Sunny, Debopriya Roy Dipta, and Eklas Hossain. 2020. A comprehensive review of
    the load forecasting techniques using single and hybrid predictive models. *IEEE
    Access* 8 (2020), 134911–134939.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alipour et al. (2020) Mohammadali Alipour, Jamshid Aghaei, Mohammadali Norouzi,
    Taher Niknam, Sattar Hashemi, and Matti Lehtonen. 2020. A novel electrical net-load
    forecasting model based on deep neural networks and wavelet transform integration.
    *Energy* 205 (2020), 118106.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Almalaq and Edwards (2017) Abdulaziz Almalaq and George Edwards. 2017. A review
    of deep learning methods applied on load forecasting. In *Proceedings of the 16th
    IEEE International Conference on Machine Learning and Applications (ICMLA’17)*.
    511–516.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Aouad et al. (2022) Mosbah Aouad, Hazem Hajj, Khaled Shaban, Rabih A Jabr, and
    Wassim El-Hajj. 2022. A CNN-Sequence-to-Sequence network with attention for residential
    short-term load forecasting. *Electric Power Systems Research* 211 (2022), 108152.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arastehfar et al. (2022) Sana Arastehfar, Mohammadjavad Matinkia, and Mohammad Reza
    Jabbarpour. 2022. Short-term residential load forecasting using graph convolutional
    recurrent neural networks. *Engineering Applications of Artificial Intelligence*
    116 (2022), 105358.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aseeri (2023) Ahmad O Aseeri. 2023. Effective RNN-based forecasting methodology
    design for improving short-term power load forecasts: Application to large-scale
    power-grid time series. *Journal of Computational Science* 68 (2023), 101984.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Atef and Eltawil (2020) Sara Atef and Amr B Eltawil. 2020. Assessment of stacked
    unidirectional and bidirectional long short-term memory networks for electricity
    load forecasting. *Electric Power Systems Research* 187 (2020), 106489.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bai et al. (2018) Shaojie Bai, J Zico Kolter, and Vladlen Koltun. 2018. An empirical
    evaluation of generic convolutional and recurrent networks for sequence modeling.
    *arXiv preprint arXiv:1803.01271* (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bashir et al. (2022) Tasarruf Bashir, Chen Haoyong, Muhammad Faizan Tahir, and
    Zhu Liqiang. 2022. Short term electricity load forecasting using hybrid prophet-LSTM
    model optimized by BPNN. *Energy reports* 8 (2022), 1678–1686.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bayram et al. (2023) Firas Bayram, Phil Aupke, Bestoun S Ahmed, Andreas Kassler,
    Andreas Theocharis, and Jonas Forsman. 2023. DA-LSTM: A dynamic drift-adaptive
    learning framework for interval load forecasting with LSTM networks. *Engineering
    Applications of Artificial Intelligence* 123 (2023), 106480.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Benidis et al. (2022) Konstantinos Benidis, Syama Sundar Rangapuram, Valentin
    Flunkert, Yuyang Wang, Danielle Maddix, Caner Turkmen, Jan Gasthaus, Michael Bohlke-Schneider,
    David Salinas, Lorenzo Stella, et al. 2022. Deep learning for time series forecasting:
    Tutorial and literature survey. *Comput. Surveys* 55, 6 (2022), 1–36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bian et al. (2022a) Haihong Bian, Qian Wang, Guozheng Xu, and Xiu Zhao. 2022a.
    Load forecasting of hybrid deep learning model considering accumulated temperature
    effect. *Energy Reports* 8 (2022), 205–215.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bian et al. (2022b) Haihong Bian, Qian Wang, Guozheng Xu, and Xiu Zhao. 2022b.
    Research on short-term load forecasting based on accumulated temperature effect
    and improved temporal convolutional network. *Energy Reports* 8 (2022), 1482–1491.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bu et al. (2023) Xiangya Bu, Qiuwei Wu, Bin Zhou, and Canbing Li. 2023. Hybrid
    short-term load forecasting using CGAN with CNN and semi-supervised regression.
    *Applied Energy* 338 (2023), 120920.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bunn and Farmer (1985) D Bunn and E Dillon Farmer. 1985. Comparative models
    for electrical load forecasting. (1985).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cai et al. (2020) Qiuna Cai, Binjie Yan, Binghong Su, Sijie Liu, Mingxu Xiang,
    Yakun Wen, Yanyu Cheng, and Nan Feng. 2020. Short-term load forecasting method
    based on deep neural network with sample weights. *International Transactions
    on Electrical Energy Systems* 30, 5 (2020), e12340.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chandola et al. (2009) Varun Chandola, Arindam Banerjee, and Vipin Kumar. 2009.
    Anomaly detection: A survey. *ACM computing surveys (CSUR)* 41, 3 (2009), 1–58.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang et al. (2023) Ching Chang, Wen-Chih Peng, and Tien-Fu Chen. 2023. Llm4ts:
    Two-stage fine-tuning for time-series forecasting with pre-trained LLMs. *arXiv
    preprint arXiv:2308.08469* (2023).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaturvedi et al. (2015) DK Chaturvedi, AP Sinha, and OP Malik. 2015. Short
    term load forecast using fuzzy logic and wavelet transform integrated generalized
    neural network. *International Journal of Electrical Power & Energy Systems* 67
    (2015), 230–237.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019) Haiwen Chen, Shouxiang Wang, Shaomin Wang, and Ye Li. 2019.
    Day-ahead aggregated load forecasting based on two-terminal sparse coding and
    deep neural network fusion. *Electric Power Systems Research* 177 (2019), 105987.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2023) Houhe Chen, Mingyang Zhu, Xiao Hu, Jiarui Wang, Yong Sun,
    and Jinduo Yang. 2023. Research on short-term load forecasting of new-type power
    system based on GCN-LSTM considering multiple influencing factors. *Energy Reports*
    9 (2023), 1022–1031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2018) Kunjin Chen, Kunlong Chen, Qin Wang, Ziyu He, Jun Hu, and
    Jinliang He. 2018. Short-term load forecasting with deep residual networks. *IEEE
    Transactions on Smart Grid* 10, 4 (2018), 3943–3952.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2021) Zexi Chen, Delong Zhang, Haoran Jiang, Longze Wang, Yongcong
    Chen, Yang Xiao, Jinxin Liu, Yan Zhang, and Meicheng Li. 2021. Load forecasting
    based on LSTM neural network and applicable to loads of “replacement of coal with
    electricity”. *Journal of Electrical Engineering & Technology* 16, 5 (2021), 2333–2342.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2021) Lilin Cheng, Haixiang Zang, Yan Xu, Zhinong Wei, and Guoqiang
    Sun. 2021. Probabilistic residential load forecasting based on micrometeorological
    data and customer consumption pattern. *IEEE Transactions on Power systems* 36,
    4 (2021), 3762–3775.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheung et al. (2021) Chung Ming Cheung, Sanmukh Kuppannagari, Rajgopal Kannan,
    and Viktor K Prasanna. 2021. Leveraging spatial information in smart grids using
    STGCN for short-term load forecasting. In *Proceedings of the 13th International
    Conference on Contemporary Computing (IC3’21)*. 159–167.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chiu et al. (2023) Ming-Chuan Chiu, Hsin-Wei Hsu, Ke-Sin Chen, and Chih-Yuan
    Wen. 2023. A hybrid CNN-GRU based probabilistic model for load forecasting from
    individual household to commercial building. *Energy Reports* 9 (2023), 94–105.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Choi et al. (2018) Hyungeun Choi, Seunghyoung Ryu, and Hongseok Kim. 2018. Short-term
    load forecasting based on ResNet and LSTM. In *Proceedings of the 2018 IEEE International
    Conference on Communications, Control, and Computing Technologies for Smart Grids
    (SmartGridComm’18)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dai et al. (2023) Yeming Dai, Xinyu Yang, and Mingming Leng. 2023. Optimized
    Seq2Seq model based on multiple methods for short-term power load forecasting.
    *Applied Soft Computing* 142 (2023), 110335.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Das et al. (2020) Anooshmita Das, Masab Khalid Annaqeeb, Elie Azar, Vojislav
    Novakovic, and Mikkel Baun Kjærgaard. 2020. Occupant-centric miscellaneous electric
    loads prediction in buildings using state-of-the-art deep learning methods. *Applied
    Energy* 269 (2020), 115135.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dedinec et al. (2016) Aleksandra Dedinec, Sonja Filiposka, Aleksandar Dedinec,
    and Ljupco Kocarev. 2016. Deep belief network based electricity load forecasting:
    An analysis of Macedonian case. *Energy* 115 (2016), 1688–1700.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deepanraj et al. (2022) B Deepanraj, N Senthilkumar, T Jarin, Ali Etem Gurel,
    L Syam Sundar, and A Vivek Anand. 2022. Intelligent wild geese algorithm with
    deep learning driven short term load forecasting for sustainable energy management
    in microgrids. *Sustainable Computing: Informatics and Systems* 36 (2022), 100813.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Din and Marnerides (2017) Ghulam Mohi Ud Din and Angelos K Marnerides. 2017.
    Short term power load forecasting using deep neural networks. In *Proceedings
    of the 2017 International Conference on Computing, Networking and Communications
    (ICNC’17)*. 594–598.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dogra et al. (2023) Atharvan Dogra, Ashima Anand, and Jatin Bedi. 2023. Consumers
    profiling based federated learning approach for energy load forecasting. *Sustainable
    Cities and Society* 98 (2023), 104815.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2023) Jizhe Dong, Long Luo, Yu Lu, and Qi Zhang. 2023. A parallel
    short-term power load forecasting method considering high-level elastic loads.
    *IEEE Transactions on Instrumentation and Measurement* 72 (2023), 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. (2017) Xishuang Dong, Lijun Qian, and Lei Huang. 2017. Short-term
    load forecasting in smart grid: A combined CNN and K-means clustering approach.
    In *Proceedings of the 2017 IEEE International Conference on Big Data and Smart
    Computing (BigComp’17)*. 119–125.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dong et al. (2021a) Yi Dong, Zhen Dong, Tianqiao Zhao, Zhongguo Li, and Zhengtao
    Ding. 2021a. Short term load forecasting with markovian switching distributed
    deep belief networks. *International Journal of Electrical Power & Energy Systems*
    130 (2021), 106942.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. (2021b) Yunxuan Dong, Xuejiao Ma, and Tonglin Fu. 2021b. Electrical
    load forecasting: A deep learning approach based on K-nearest neighbors. *Applied
    Soft Computing* 99 (2021), 106900.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dou et al. (2018) Yuchen Dou, Xinman Zhang, Zhihui Wu, and Hang Zhang. 2018.
    Application of deep learning method in short-term load forecasting of characteristic
    enterprises. In *Proceedings of the 2018 Artificial Intelligence and Cloud Computing
    Conference (AICCC’18)*. 35–40.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dudek (2016) Grzegorz Dudek. 2016. Neural networks for pattern-based short-term
    load forecasting: A comparative study. *Neurocomputing* 205 (2016), 64–74.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eren and Küçükdemiral (2024) Yavuz Eren and İbrahim Küçükdemiral. 2024. A comprehensive
    review on deep learning approaches for short-term load forecasting. *Renewable
    and Sustainable Energy Reviews* 189 (2024), 114031.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eskandari et al. (2021) Hosein Eskandari, Maryam Imani, and Mohsen Parsa Moghaddam.
    2021. Convolutional and recurrent neural network based model for short-term load
    forecasting. *Electric Power Systems Research* 195 (2021), 107173.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fahiman et al. (2019) Fateme Fahiman, Sarah M Erfani, and Christopher Leckie.
    2019. Robust and accurate short-term load forecasting: A cluster oriented ensemble
    learning approach. In *Proceedings of the 2019 International Joint Conference
    on Neural Networks (IJCNN’19)*. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fahiman et al. (2017) Fateme Fahiman, Sarah M Erfani, Sutharshan Rajasegarar,
    Marimuthu Palaniswami, and Christopher Leckie. 2017. Improving load forecasting
    based on deep learning and K-shape clustering. In *Proceedings of the 2017 International
    Joint Conference on Neural Networks (IJCNN’17)*. 4134–4141.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2020) Chaodong Fan, Changkun Ding, Jinhua Zheng, Leyi Xiao, and
    Zhaoyang Ai. 2020. Empirical mode decomposition based multi-objective deep belief
    network for short-term power load forecasting. *Neurocomputing* 388 (2020), 110–123.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Farid et al. (2023) Karim S Farid, AA Ali, Sameh A Salem, and Amr E Mohamed.
    2023. CONV1D-GRU: A hybrid model for short-term electrical load forecasting. In
    *Proceedings of the 2023 International Telecommunications Conference (ITC-Egypt’23)*.
    281–286.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Faustine and Pereira (2022) Anthony Faustine and Lucas Pereira. 2022. FPSeq2Q:
    Fully parameterized sequence to quantile regression for net-load forecasting with
    uncertainty estimates. *IEEE Transactions on Smart Grid* 13, 3 (2022), 2440–2451.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fekri et al. (2021) Mohammad Navid Fekri, Harsh Patel, Katarina Grolinger,
    and Vinay Sharma. 2021. Deep learning for load forecasting with smart meter data:
    Online adaptive recurrent neural network. *Applied Energy* 282 (2021), 116177.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. (2019) Cong Feng, Mucun Sun, and Jie Zhang. 2019. Reinforced deterministic
    and probabilistic load forecasting via Q-learning dynamic model selection. *IEEE
    Transactions on Smart Grid* 11, 2 (2019), 1377–1386.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Feng et al. (2024) Ding Feng, Dengao Li, Yu Zhou, Jumin Zhao, and Kenan Zhang.
    2024. STGNet: Short-term residential load forecasting with spatial–temporal gated
    fusion network. *Energy Science & Engineering* 12, 3 (2024), 541–560.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gan et al. (2017) Dahua Gan, Yi Wang, Ning Zhang, and Wenjun Zhu. 2017. Enhancing
    short-term probabilistic residential load forecasting with quantile long–short-term
    memory. *The Journal of Engineering* 2017, 14 (2017), 2622–2627.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ganjouri et al. (2023) Mahtab Ganjouri, Mazda Moattari, Ahmad Forouzantabar,
    and Mohammad Azadi. 2023. Spatial-temporal learning structure for short-term load
    forecasting. *IET Generation, Transmission & Distribution* 17, 2 (2023), 427–437.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2023a) Jiaxin Gao, Yuntian Chen, Wenbo Hu, and Dongxiao Zhang. 2023a.
    An adaptive deep-learning load forecasting framework by integrating transformer
    and domain knowledge. *Advances in Applied Energy* 10 (2023), 100142.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. (2023b) Qiang Gao, Kaiyi Liu, Kaibin Wu, Menghan You, and Hang Liu.
    2023b. Short-term load forecasting for typical buildings based on VMD-Informer-DMD
    model. In *Proceedings of the IEEE 2nd Industrial Electronics Society Annual On-Line
    Conference (ONCON’23)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ghofrani et al. (2015) Mahmoud Ghofrani, M Ghayekhloo, A Arabali, and A Ghayekhloo.
    2015. A hybrid short-term load forecasting with a new input selection framework.
    *Energy* 81 (2015), 777–786.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Giacomazzi et al. (2023) Elena Giacomazzi, Felix Haag, and Konstantin Hopf.
    2023. Short-term electricity load forecasting using the temporal fusion transformer:
    Effect of grid hierarchies and data sources. In *Proceedings of the 14th ACM International
    Conference on Future Energy Systems (e-Energy’23)*. 353–360.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gruver et al. (2024) Nate Gruver, Marc Finzi, Shikai Qiu, and Andrew G Wilson.
    2024. Large language models are zero-shot time series forecasters. *Advances in
    Neural Information Processing Systems* 36 (2024).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2021) Xifeng Guo, Ye Gao, Yupeng Li, Di Zheng, and Dan Shan. 2021.
    Short-term household load forecasting based on long-and short-term time-series
    network. *Energy Reports* 7 (2021), 58–64.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guo et al. (2020) Xifeng Guo, Qiannan Zhao, Di Zheng, Yi Ning, and Ye Gao. 2020.
    A short-term load forecasting model of multi-scale CNN-LSTM hybrid neural network
    considering the real-time electricity price. *Energy Reports* 6 (2020), 1046–1053.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gürses-Tran et al. (2022) Gonca Gürses-Tran, Tobias Alexander Körner, and Antonello
    Monti. 2022. Introducing explainability in sequence-to-sequence learning for short-term
    load forecasting. *Electric Power Systems Research* 212 (2022), 108366.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hafeez et al. (2020) Ghulam Hafeez, Khurram Saleem Alimgeer, and Imran Khan.
    2020. Electric load forecasting based on deep learning and optimized by heuristic
    algorithm in smart grid. *Applied Energy* 269 (2020), 114915.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haiyan et al. (2020) Wang Haiyan, Lv Xinhang, and Luo Xiaonan. 2020. Short-term
    load forecasting of power grid based on improved WOA optimized LSTM. In *Proceedings
    of the 5th International Conference on Power and Renewable Energy (ICPRE’20)*.
    54–60.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. (2023) Shuwei Han, Huitong Ru, Guangling Wang, Xuezhi Fu, Guoxu Zhou,
    and Chengqiao Yang. 2023. Research on power load forecasting of PCA-CNN-LSTM based
    on sliding window. In *Proceedings of the 3rd International Conference on New
    Energy and Power Engineering (ICNEPE’23)*. 466–471.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haque and Rahman (2022) Ashraful Haque and Saifur Rahman. 2022. Short-term electrical
    load forecasting through heuristic configuration of regularized deep neural network.
    *Applied Soft Computing* 122 (2022), 108877.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hayati and Shirvany (2007) Mohsen Hayati and Yazdan Shirvany. 2007. Artificial
    neural network approach for short term load forecasting for Illam region. *World
    Academy of Science, Engineering and Technology* 28 (2007), 280–284.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2021) Shengtao He, Canbing Li, Xubin Liu, Xinyu Chen, Mohammad Shahidehpour,
    Tao Chen, Bin Zhou, and Qiuwei Wu. 2021. A per-unit curve rotated decoupling method
    for CNN-TCN based day-ahead load forecasting. *IET Generation, Transmission &
    Distribution* 15, 19 (2021), 2773–2786.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He (2017) Wan He. 2017. Load forecasting via deep neural networks. *Procedia
    Computer Science* 122 (2017), 308–314.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2017) Yusen He, Jiahao Deng, and Huajin Li. 2017. Short-term power
    load forecasting with deep belief network and copula models. In *Proceedings of
    the 9th International Conference on Intelligent Human-Machine Systems and Cybernetics
    (IHMSC’17)*. 191–194.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hinton et al. (2006) Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. 2006.
    A fast learning algorithm for deep belief nets. *Neural computation* 18, 7 (2006),
    1527–1554.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hochreiter and Schmidhuber (1997) Sepp Hochreiter and Jürgen Schmidhuber. 1997.
    Long short-term memory. *Neural computation* 9, 8 (1997), 1735–1780.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hong and Fan (2016) Tao Hong and Shu Fan. 2016. Probabilistic electric load
    forecasting: A tutorial review. *International Journal of Forecasting* 32, 3 (2016),
    914–938.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hong and Chan (2023) Ying-Yi Hong and Yu-Hsuan Chan. 2023. Short-term electric
    load forecasting using particle swarm optimization-based convolutional neural
    network. *Engineering Applications of Artificial Intelligence* 126 (2023), 106773.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hong et al. (2022) Ying-Yi Hong, Yu-Hsuan Chan, Yung-Han Cheng, Yih-Der Lee,
    Jheng-Lun Jiang, and Shen-Szu Wang. 2022. Week-ahead daily peak load forecasting
    using genetic algorithm-based hybrid convolutional neural network. *IET Generation,
    Transmission & Distribution* 16, 12 (2022), 2416–2424.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoori et al. (2019) Ammar O Hoori, Ahmad Al Kazzaz, Rameez Khimani, Yuichi Motai,
    and Alex J Aved. 2019. Electric load forecasting model using a multicolumn deep
    neural networks. *IEEE Transactions on Industrial Electronics* 67, 8 (2019), 6473–6482.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hosein and Hosein (2017) Stefan Hosein and Patrick Hosein. 2017. Load forecasting
    using deep neural networks. In *Proceedings of the 2017 IEEE Power & Energy Society
    Innovative Smart Grid Technologies Conference (ISGT’17)*. 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hossain and Mahmood (2020) Mohammad Safayet Hossain and Hisham Mahmood. 2020.
    Short-term load forecasting using an LSTM neural network. In *Proceedings of the
    2020 IEEE Power and Energy Conference at Illinois (PECI’20)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hossen et al. (2018) Tareq Hossen, Arun Sukumaran Nair, Radhakrishnan Angamuthu
    Chinnathambi, and Prakash Ranganathan. 2018. Residential load forecasting using
    deep neural networks (DNN). In *Proceedings of the 2018 North American Power Symposium
    (NAPS’18)*. 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hossen et al. (2017) Tareq Hossen, Siby Jose Plathottam, Radha Krishnan Angamuthu,
    Prakash Ranganathan, and Hossein Salehfar. 2017. Short-term load forecasting using
    deep neural networks (DNN). In *Proceedings of the 2017 North American Power Symposium
    (NAPS’17)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hou et al. (2022) Hui Hou, Chao Liu, Qing Wang, Xixiu Wu, Jinrui Tang, Ying
    Shi, and Changjun Xie. 2022. Review of load forecasting based on artificial intelligence
    methodologies, models, and challenges. *Electric Power Systems Research* 210 (2022),
    108067.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2022b) Haowen Hu, Xin Xia, Yuanlin Luo, Chu Zhang, Muhammad Shahzad
    Nazir, and Tian Peng. 2022b. Development and application of an evolutionary deep
    learning framework of LSTM based on improved grasshopper optimization algorithm
    for short-term load forecasting. *Journal of Building Engineering* 57 (2022),
    104975.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2017) Rui Hu, Shiping Wen, Zhigang Zeng, and Tingwen Huang. 2017.
    A short-term power load forecasting model based on the generalized regression
    neural network with decreasing step fruit fly optimization algorithm. *Neurocomputing*
    221 (2017), 24–31.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2022c) Weimin Hu, Chao Yan, Liping Fan, Jie Yu, Mei Yu, Sheng Hua,
    and Chonghao Yue. 2022c. Short-term power load forecasting based on VMD-SSA-LSTM.
    In *Proceedings of the 2022 International Conference on High Performance Big Data
    and Intelligent Systems (HDIS’22)*. 287–293.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2022a) Xin Hu, Keyi Li, Jingfu Li, Taotao Zhong, Weinong Wu, Xia
    Zhang, and Wenjiang Feng. 2022a. Load forecasting model consisting of data mining
    based orthogonal greedy algorithm and long short-term memory network. *Energy
    Reports* 8 (2022), 235–242.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hua et al. (2023) Heng Hua, Mingping Liu, Yuqin Li, Suhui Deng, and Qingnian
    Wang. 2023. An ensemble framework for short-term load forecasting based on parallel
    CNN and GRU with improved ResNet. *Electric Power Systems Research* 216 (2023),
    109057.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2021) Jiehui Huang, Zhiwang Zhou, Chunquan Li, Zhiyuan Liao, and
    Peter X Liu. 2021. A decomposition-based multi-time dimension long short-term
    memory model for short-term electric load forecasting. *IET Generation, Transmission
    & Distribution* 15, 24 (2021), 3459–3473.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2023) Nantian Huang, Shengyuan Wang, Rijun Wang, Guowei Cai, Yang
    Liu, and Qianbin Dai. 2023. Gated spatial-temporal graph neural network based
    short-term load forecasting for wide-area multiple buses. *International Journal
    of Electrical Power & Energy Systems* 145 (2023), 108651.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2020) Qian Huang, Jinghua Li, and Mengshu Zhu. 2020. An improved
    convolutional neural network with load range discretization for probabilistic
    load forecasting. *Energy* 203 (2020), 117902.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (21) Rubing Huang, Weifeng Sun, Yinyin Xu, Haibo Chen, Dave Towey,
    and Xin Xia. 21. A survey on adaptive random testing. *IEEE Transactions on Software
    Engineering* 47, 10 (21), 2052–2083.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jalali et al. (2021) Seyed Mohammad Jafar Jalali, Sajad Ahmadian, Abbas Khosravi,
    Miadreza Shafie-khah, Saeid Nahavandi, and João PS Catalão. 2021. A novel evolutionary-based
    deep convolutional neural network model for intelligent load forecasting. *IEEE
    Transactions on Industrial Informatics* 17, 12 (2021), 8243–8253.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jalali et al. (2022) Seyed Mohammad Jafar Jalali, Parul Arora, BK Panigrahi,
    Abbas Khosravi, Saeid Nahavandi, Gerardo J Osório, and João PS Catalão. 2022.
    An advanced deep neuroevolution model for probabilistic load forecasting. *Electric
    Power Systems Research* 211 (2022), 108351.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Javed et al. (2022) Umar Javed, Khalid Ijaz, Muhammad Jawad, Ikramullah Khosa,
    Ejaz Ahmad Ansari, Khurram Shabih Zaidi, Muhammad Nadeem Rafiq, and Noman Shabbir.
    2022. A novel short receptive field based dilated causal convolutional network
    integrated with Bidirectional LSTM for short-term load forecasting. *Expert Systems
    with Applications* 205 (2022), 117689.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang and Zheng (2022) He Jiang and Weihua Zheng. 2022. Deep learning with regularized
    robust long-and short-term memory network for probabilistic short-term load forecasting.
    *Journal of Forecasting* 41, 6 (2022), 1201–1216.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiao et al. (2021) Runhai Jiao, Shuangkun Wang, Tianle Zhang, Hui Lu, Hui He,
    and Brij B Gupta. 2021. Adaptive feature selection and construction for day-ahead
    load forecasting use deep learning method. *IEEE Transactions on Network and Service
    Management* 18, 4 (2021), 4019–4029.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jin et al. (2022) Yuwei Jin, Moses Amoasi Acquah, Mingyu Seo, and Sekyung Han.
    2022. Short-term electric load prediction using transfer learning with interval
    estimate adjustment. *Energy and Buildings* 258 (2022), 111846.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2022) Zulfiqar Ahmad Khan, Amin Ullah, Ijaz Ul Haq, Mohamed Hamdy,
    Gerardo Maria Mauro, Khan Muhammad, Mohammad Hijji, and Sung Wook Baik. 2022.
    Efficient short-term electricity load forecasting for effective energy management.
    *Sustainable Energy Technologies and Assessments* 53 (2022), 102337.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2019) Junhong Kim, Jihoon Moon, Eenjun Hwang, and Pilsung Kang.
    2019. Recurrent inception convolution neural network for multi short-term load
    forecasting. *Energy and buildings* 194 (2019), 328–341.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2022) Nakyoung Kim, Hyunseo Park, Joohyung Lee, and Jun Kyun Choi.
    2022. Short-term electrical load forecasting with multidimensional feature extraction.
    *IEEE Transactions on Smart Grid* 13, 4 (2022), 2999–3013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kong et al. (2017) Weicong Kong, Zhao Yang Dong, Youwei Jia, David J Hill, Yan
    Xu, and Yuan Zhang. 2017. Short-term residential load forecasting based on LSTM
    recurrent neural network. *IEEE Transactions on Smart Grid* 10, 1 (2017), 841–851.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kong et al. (2019) Xiangyu Kong, Chuang Li, Feng Zheng, and Chengshan Wang.
    2019. Improved deep belief network for short-term load forecasting considering
    demand-side management. *IEEE Transactions on Power Systems* 35, 2 (2019), 1531–1538.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kouhi et al. (2014) Sajjad Kouhi, Farshid Keynia, and Sajad Najafi Ravadanegh.
    2014. A new short-term load forecast method based on neuro-evolutionary algorithm
    and chaotic feature selection. *International Journal of Electrical Power & Energy
    Systems* 62 (2014), 862–867.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lai et al. (2020) Chun Sing Lai, Zhenyao Mo, Ting Wang, Haoliang Yuan, Wing WY
    Ng, and Loi Lei Lai. 2020. Load forecasting based on deep neural network and historical
    data augmentation. *IET Generation, Transmission & Distribution* 14, 24 (2020),
    5927–5934.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Langevin et al. (2023) Antoine Langevin, Mohamed Cheriet, and Ghyslain Gagnon.
    2023. Efficient deep generative model for short-term household load forecasting
    using non-intrusive load monitoring. *Sustainable Energy, Grids and Networks*
    34 (2023), 101006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2015) Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep
    learning. *Nature* 521, 7553 (2015), 436–444.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2023) Bin Li, Yulu Mo, Feng Gao, and Xiaoqing Bai. 2023. Short-term
    probabilistic load forecasting method based on uncertainty estimation and deep
    learning model considering meteorological factors. *Electric Power Systems Research*
    225 (2023), 109804.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019) Chen Li, Zhenyu Chen, Jinbo Liu, Dapeng Li, Xingyu Gao, Fangchun
    Di, Lixin Li, and Xiaohui Ji. 2019. Power load forecasting based on the combined
    model of LSTM and XGBoost. In *Proceedings of the 2019 International Conference
    on Pattern Recognition and Artificial Intelligence (PRAI’19)*. 46–51.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022a) Dan Li, Guangfan Sun, Shuwei Miao, Yingzhong Gu, Yuanhang
    Zhang, and Shuai He. 2022a. A short-term electric load forecast method based on
    improved sequence-to-sequence GRU with adaptive temporal dependence. *International
    Journal of Electrical Power & Energy Systems* 137 (2022), 107627.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2021) Lechen Li, Christoph J Meinrenken, Vijay Modi, and Patricia J
    Culligan. 2021. Short-term apartment-level load forecasting using a modified neural
    network with selected auto-regressive features. *Applied Energy* 287 (2021), 116509.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2020b) Ning Li, Lu Wang, Xinquan Li, and Qing Zhu. 2020b. An effective
    deep learning neural network model for short-term load forecasting. *Concurrency
    and Computation: Practice and Experience* 32, 7 (2020), e5595.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022b) Xiaole Li, Yiqin Wang, Guibo Ma, Xin Chen, Qianxiang Shen,
    and Bo Yang. 2022b. Electric load forecasting based on Long-Short-Term-Memory
    network via simplex optimizer during COVID-19. *Energy Reports* 8 (2022), 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2020a) Zhuoling Li, Yuanzheng Li, Yun Liu, Ping Wang, Renzhi Lu,
    and Hoay Beng Gooi. 2020a. Deep learning based densely connected network for load
    forecasting. *IEEE Transactions on Power Systems* 36, 4 (2020), 2829–2840.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2022a) Jun Lin, Jin Ma, Jianguo Zhu, and Yu Cui. 2022a. Short-term
    load forecasting based on LSTM networks considering attention mechanism. *International
    Journal of Electrical Power & Energy Systems* 137 (2022), 107818.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2021) Weixuan Lin, Di Wu, and Benoit Boulet. 2021. Spatial-temporal
    residential short-term load forecasting via graph neural networks. *IEEE Transactions
    on Smart Grid* 12, 6 (2021), 5373–5384.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2022b) Xin Lin, Ramon Zamora, Craig A Baguley, and Anurag K Srivastava.
    2022b. A hybrid short-term load forecasting approach for individual residential
    customer. *IEEE Transactions on Power Delivery* 38, 1 (2022), 26–37.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022c) Jiefeng Liu, Zhenhao Zhang, Xianhao Fan, Yiyi Zhang, Jiaqi
    Wang, Ke Zhou, Shuo Liang, Xiaoyong Yu, and Wei Zhang. 2022c. Power system load
    forecasting using mobility optimization and multi-task learning in COVID-19. *Applied
    Energy* 310 (2022), 118303.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022a) Ronghui Liu, Teng Chen, Gaiping Sun, SM Muyeen, Shunfu Lin,
    and Yang Mi. 2022a. Short-term probabilistic building load forecasting based on
    feature integrated artificial intelligent approach. *Electric Power Systems Research*
    206 (2022), 107802.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2022b) Yanzhu Liu, Shreya Dutta, Adams Wai Kin Kong, and Chai Kiat
    Yeo. 2022b. An image inpainting approach to short-term load forecasting. *IEEE
    Transactions on Power Systems* 38, 1 (2022), 177–187.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2019) Jixiang Lu, Qipei Zhang, Zhihong Yang, and Mengfu Tu. 2019.
    A hybrid model based on convolutional neural network and long short-term memory
    for short-term load forecasting. In *Proceedings of the 2019 IEEE Power & Energy
    Society General Meeting (PESGM’19)*. 1–5.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2022) Yuting Lu, Gaocai Wang, and Shuqiang Huang. 2022. A short-term
    load forecasting model based on mixup and transfer learning. *Electric Power Systems
    Research* 207 (2022), 107837.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo et al. (2022) Hua Luo, Haipeng Zhang, and Jianzhou Wang. 2022. Ensemble
    power load forecasting based on competitive-inhibition selection strategy and
    deep learning. *Sustainable Energy Technologies and Assessments* 51 (2022), 101940.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lv et al. (2021) Lingling Lv, Zongyu Wu, Jinhua Zhang, Lei Zhang, Zhiyuan Tan,
    and Zhihong Tian. 2021. A VMD and LSTM based hybrid model of load forecasting
    for power grid security. *IEEE Transactions on Industrial Informatics* 18, 9 (2021),
    6474–6482.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathew et al. (2021) Jimson Mathew, Ranjan Kumar Behera, et al. 2021. EMD-Att-LSTM:
    A data-driven strategy combined with deep learning for short-term load forecasting.
    *Journal of Modern Power Systems and Clean Energy* 10, 5 (2021), 1229–1240.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Meng et al. (2022) Zhaorui Meng, Yanqi Xie, and Jinhua Sun. 2022. Short-term
    load forecasting using neural attention model based on EMD. *Electrical Engineering*
    (2022), 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Morais et al. (2023) Lucas Barros Scianni Morais, Giancarlo Aquila, Victor
    Augusto Durães de Faria, Luana Medeiros Marangon Lima, José Wanderley Marangon
    Lima, and Anderson Rodrigo de Queiroz. 2023. Short-term load forecasting using
    neural networks and global climate models: An application to a large-scale electrical
    power system. *Applied Energy* 348 (2023), 121439.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mounir et al. (2023) Nada Mounir, Hamid Ouadi, and Ismael Jrhilifa. 2023. Short-term
    electric load forecasting using an EMD-BI-LSTM approach for smart grid energy
    management system. *Energy and Buildings* 288 (2023), 113022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mughees et al. (2021) Neelam Mughees, Syed Ali Mohsin, Abdullah Mughees, and
    Anam Mughees. 2021. Deep sequence to sequence Bi-LSTM neural networks for day-ahead
    peak load forecasting. *Expert Systems with Applications* 175 (2021), 114844.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nawar et al. (2023) Menna Nawar, Moustafa Shomer, Samy Faddel, and Huangjie
    Gong. 2023. Transfer learning in deep learning models for building load forecasting:
    Case of limited data. In *Proceedings of the IEEE SoutheastCon 2023*. 532–538.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neeraj et al. (2021) Neeraj Neeraj, Jimson Mathew, Mayank Agarwal, and Ranjan Kumar
    Behera. 2021. Long short-term memory-singular spectrum analysis-based model for
    electric load forecasting. *Electrical Engineering* 103, 2 (2021), 1067–1082.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nie et al. (2020) Ying Nie, Ping Jiang, and Haipeng Zhang. 2020. A novel hybrid
    model based on combined preprocessing method and advanced optimization algorithm
    for power load forecasting. *Applied Soft Computing* 97 (2020), 106809.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Niu et al. (2016) Mingfei Niu, Shaolong Sun, Jing Wu, Lean Yu, and Jianzhou
    Wang. 2016. An innovative integrated model using the singular spectrum analysis
    and nonlinear multi-layer perceptron network optimized by hybrid intelligent algorithm
    for short-term load forecasting. *Applied Mathematical Modelling* 40, 5-6 (2016),
    4079–4093.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ozer et al. (2021) Ilyas Ozer, Serhat Berat Efe, and Harun Ozbay. 2021. A combined
    deep learning application for short term load forecasting. *Alexandria Engineering
    Journal* 60, 4 (2021), 3807–3818.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Park et al. (1991) Dong C Park, MA El-Sharkawi, RJ Marks, LE Atlas, and MJ Damborg.
    1991. Electric load forecasting using an artificial neural network. *IEEE Transactions
    on Power Systems* 6, 2 (1991), 442–449.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pełka and Dudek (2020) Paweł Pełka and Grzegorz Dudek. 2020. Pattern-based long
    short-term memory for mid-term electrical load forecasting. In *Proceedings of
    the 2020 International Joint Conference on Neural Networks (IJCNN’20)*. 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. (2022) Jiaqi Qin, Yi Zhang, Shixiong Fan, Xiaonan Hu, Yongqiang Huang,
    Zexin Lu, and Yan Liu. 2022. Multi-task short-term reactive and active load forecasting
    method based on attention-LSTM model. *International Journal of Electrical Power
    & Energy Systems* 135 (2022), 107517.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rafati et al. (2020) Amir Rafati, Mahmood Joorabian, and Elaheh Mashhour. 2020.
    An efficient hour-ahead electrical load forecasting method based on innovative
    features. *Energy* 201 (2020), 117511.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ran et al. (2023) Peng Ran, Kun Dong, Xu Liu, and Jing Wang. 2023. Short-term
    load forecasting based on CEEMDAN and Transformer. *Electric Power Systems Research*
    214 (2023), 108885.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raza et al. (2017) Muhammad Qamar Raza, Mithulananthan Nadarajah, Duong Quoc
    Hung, and Zuhairi Baharudin. 2017. An intelligent hybrid short-term load forecasting
    model for smart power grids. *Sustainable Cities and Society* 31 (2017), 264–275.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rumelhart et al. (1986) David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams.
    1986. Learning representations by back-propagating errors. *Nature* 323, 6088
    (1986), 533–536.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sadaei et al. (2019) Hossein Javedani Sadaei, Petrônio Cândido de Lima e Silva,
    Frederico Gadelha Guimaraes, and Muhammad Hisyam Lee. 2019. Short-term load forecasting
    by using a combined method of convolutional neural networks and fuzzy time series.
    *Energy* 175 (2019), 365–377.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sakib et al. (2021) Shadman Sakib, Khan Md Hasib, Ihtyaz Kader Tasawar, Abyaz Kader
    Tanzeem, Md Fahim Arefin, Saharul Islam, and Mohammad Shafiul Alam. 2021. A data-driven
    hybrid optimization based deep network model for short-term residential load forecasting.
    In *Proceedings of the IEEE 12th Annual Information Technology, Electronics and
    Mobile Communication Conference (IEMCON’21)*. 0187–0193.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Santos et al. (2023) Miguel López Santos, Saúl Díaz García, Xela García-Santiago,
    Ana Ogando-Martínez, Fernando Echevarría Camarero, Gonzalo Blázquez Gil, and Pablo Carrasco
    Ortega. 2023. Deep learning and transfer learning techniques applied to short-term
    load forecasting of data-poor buildings in local energy communities. *Energy and
    Buildings* 292 (2023), 113164.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schmidhuber (2015) Jürgen Schmidhuber. 2015. Deep learning in neural networks:
    An overview. *Neural networks* 61 (2015), 85–117.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sekhar and Dahiya (2023) Charan Sekhar and Ratna Dahiya. 2023. Robust framework
    based on hybrid deep learning approach for short term load forecasting of building
    electricity demand. *Energy* 268 (2023), 126660.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shaqour et al. (2022) Ayas Shaqour, Tetsushi Ono, Aya Hagishima, and Hooman
    Farzaneh. 2022. Electrical demand aggregation effects on the performance of deep
    learning-based short-term load forecasting of a residential building. *Energy
    and AI* 8 (2022), 100141.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sharma and Jain (2022) Abhishek Sharma and Sachin Kumar Jain. 2022. A novel
    seasonal segmentation approach for day-ahead load forecasting. *Energy* 257 (2022),
    124752.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2023) Huifeng Shi, Kai Miao, and Xiaochen Ren. 2023. Short-term
    load forecasting based on CNN-BiLSTM with Bayesian optimization and attention
    mechanism. *Concurrency and Computation: Practice and Experience* 35, 17 (2023),
    e6676.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh and Dwivedi (2018) Priyanka Singh and Pragya Dwivedi. 2018. Integration
    of new evolutionary approach with artificial neural network for solving short
    term load forecast problem. *Applied energy* 217 (2018), 537–549.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2023) Yongxin Su, Qiyao He, Jie Chen, and Mao Tan. 2023. A residential
    load forecasting method for multi-attribute adversarial learning considering multi-source
    uncertainties. *International Journal of Electrical Power & Energy Systems* 154
    (2023), 109421.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subbiah and Chinnappan (2022) Siva Sankari Subbiah and Jayakumar Chinnappan.
    2022. Deep learning based short term load forecasting with hybrid feature selection.
    *Electric Power Systems Research* 210 (2022), 108065.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2020) Gaiping Sun, Chuanwen Jiang, Xu Wang, and Xiu Yang. 2020.
    Short-term building load forecast based on a data-mining feature selection and
    LSTM-RNN method. *IEEJ Transactions on Electrical and Electronic Engineering*
    15, 7 (2020), 1002–1010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2018) Hongbin Sun, Xin Pan, and Changxin Meng. 2018. A short-term
    power load prediction algorithm of based on power load factor deep cluster neural
    network. *Wireless Personal Communications* 102 (2018), 1073–1084.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan et al. (2022) Mao Tan, Chenglin Hu, Jie Chen, Ling Wang, and Zhengmao Li.
    2022. Multi-node load forecasting based on multi-task learning with modal feature
    extraction. *Engineering Applications of Artificial Intelligence* 112 (2022),
    104856.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2019b) Lingling Tang, Yulin Yi, and Yuexing Peng. 2019b. An ensemble
    deep learning model for short-term load forecasting based on ARIMA and LSTM. In
    *Proceedings of the 2019 IEEE International Conference on Communications, Control,
    and Computing Technologies for Smart Grids (SmartGridComm’19)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2022) Xianlun Tang, Hongxu Chen, Wenhao Xiang, Jingming Yang, and
    Mi Zou. 2022. Short-term load forecasting using channel and temporal attention
    based temporal convolutional network. *Electric Power Systems Research* 205 (2022),
    107761.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tang et al. (2019a) Xianlun Tang, Yuyan Dai, Ting Wang, and Yingjie Chen. 2019a.
    Short-term power load forecasting based on multi-layer bidirectional recurrent
    neural network. *IET Generation, Transmission & Distribution* 13, 17 (2019), 3847–3854.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tayab et al. (2020) Usman Bashir Tayab, Ali Zia, Fuwen Yang, Junwei Lu, and
    Muhammad Kashif. 2020. Short-term load forecasting for microgrid energy management
    system using hybrid HHO-FNN model with best-basis stationary wavelet packet transform.
    *Energy* 203 (2020), 117857.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Van Den Oord et al. (2016) Aaron Van Den Oord, Sander Dieleman, Heiga Zen,
    Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, Koray
    Kavukcuoglu, et al. 2016. Wavenet: A generative model for raw audio. *arXiv preprint
    arXiv:1609.03499* 12 (2016).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Van der Meer et al. (2018) Dennis W Van der Meer, Joakim Widén, and Joakim Munkhammar.
    2018. Review on probabilistic forecasting of photovoltaic power production and
    electricity consumption. *Renewable and Sustainable Energy Reviews* 81 (2018),
    1484–1512.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is all you need. *Advances in Neural Information Processing Systems* 30 (2017).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Veeramsetty et al. (2022) Venkataramana Veeramsetty, Dongari Rakesh Chandra,
    Francesco Grimaccia, and Marco Mussetta. 2022. Short term electric power load
    forecasting using principal component analysis and recurrent neural networks.
    *Forecasting* 4, 1 (2022), 149–164.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Voß et al. (2018) Marcus Voß, Christian Bender-Saebelkampf, and Sahin Albayrak.
    2018. Residential short-term load forecasting using convolutional neural networks.
    In *Proceedings of the 2018 IEEE International Conference on Communications, Control,
    and Computing Technologies for Smart Grids (SmartGridComm’18)*. 1–6.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wan et al. (2023) Anping Wan, Qing Chang, AL-Bukhaiti Khalil, and Jiabo He.
    2023. Short-term power load forecasting for combined heat and power using CNN-LSTM
    enhanced by attention mechanism. *Energy* 282 (2023), 128274.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019b) Huaizhi Wang, Zhenxing Lei, Xian Zhang, Bin Zhou, and Jianchun
    Peng. 2019b. A review of deep learning for renewable energy forecasting. *Energy
    Conversion and Management* 198 (2019), 111799.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023a) Jianguo Wang, Lincheng Han, Xiuyu Zhang, Yingzhou Wang,
    and Shude Zhang. 2023a. Electrical load forecasting based on variable T-distribution
    and dual attention mechanism. *Energy* 283 (2023), 128569.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023c) Jianzhou Wang, Kang Wang, Zhiwu Li, Haiyan Lu, and He Jiang.
    2023c. Short-term power load forecasting system based on rough set, information
    granule and multi-objective optimization. *Applied Soft Computing* 146 (2023),
    110692.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020b) Lingxiao Wang, Shiwen Mao, Bogdan M Wilamowski, and RM Nelms.
    2020b. Ensemble learning for load forecasting. *IEEE Transactions on Green Communications
    and Networking* 4, 2 (2020), 616–628.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023d) Lingyun Wang, Xiang Zhou, Honglei Xu, Tian Tian, and Huamin
    Tong. 2023d. Short-term electrical load forecasting model based on multi-dimensional
    meteorological information spatio-temporal fusion and optimized variational mode
    decomposition. *IET Generation, Transmission & Distribution* 17, 20 (2023), 4647–4663.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2021) Shouxiang Wang, Xinyu Deng, Haiwen Chen, Qingyuan Shi, and
    Di Xu. 2021. A bottom-up short-term residential load forecasting approach based
    on appliance characteristic analysis and multi-task learning. *Electric Power
    Systems Research* 196 (2021), 107233.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019c) Shouxiang Wang, Xuan Wang, Shaomin Wang, and Dan Wang. 2019c.
    Bi-directional long short-term memory method based on attention mechanism and
    rolling update for short-term load forecasting. *International Journal of Electrical
    Power & Energy Systems* 109 (2019), 470–479.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2020a) Yuanyuan Wang, Jun Chen, Xiaoqiao Chen, Xiangjun Zeng, Yang
    Kong, Shanfeng Sun, Yongsheng Guo, and Ying Liu. 2020a. Short-term load forecasting
    for industrial customers based on TCN-LightGBM. *IEEE Transactions on Power Systems*
    36, 3 (2020), 1984–1997.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019a) Yi Wang, Dahua Gan, Mingyang Sun, Ning Zhang, Zongxiang
    Lu, and Chongqing Kang. 2019a. Probabilistic individual load forecasting using
    pinball loss guided LSTM. *Applied Energy* 235 (2019), 10–20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023b) Yufeng Wang, Lingxiao Rui, Jianhua Ma, et al. 2023b. A short-term
    residential load forecasting scheme based on the multiple correlation-temporal
    graph neural networks. *Applied Soft Computing* 146 (2023), 110629.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2023a) Han Wu, Yan Liang, and Jiani Heng. 2023a. Pulse-diagnosis-inspired
    multi-feature extraction deep network for short-term electricity load forecasting.
    *Applied Energy* 339 (2023), 120995.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2023b) Kaitong Wu, Xiangang Peng, Zhiwen Chen, Haokun Su, Huan Quan,
    and Hanyu Liu. 2023b. A novel short-term household load forecasting method combined
    BiLSTM with trend feature extraction. *Energy Reports* 9 (2023), 1013–1022.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2021) Xuedong Wu, Yaonan Wang, Yingjie Bai, Zhiyu Zhu, and Aiming
    Xia. 2021. Online short-term load forecasting methods using hybrids of single
    multiplicative neuron model, particle swarm optimization variants and nonlinear
    filters. *Energy Reports* 7 (2021), 683–692.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2022) Zeqing Wu, Yunfei Mu, Shuai Deng, and Yang Li. 2022. Spatial–temporal
    short-term load forecasting framework via K-shape time series clustering method
    and graph convolutional networks. *Energy Reports* 8 (2022), 8752–8766.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xia et al. (2023) Yurui Xia, Jianzhou Wang, Danxiang Wei, and Ziyuan Zhang.
    2023. Combined framework based on data preprocessing and multi-objective optimizer
    for electricity load forecasting. *Engineering Applications of Artificial Intelligence*
    119 (2023), 105776.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiang et al. (2023) Siyu Xiang, Cao Zhen, Jian Peng, Linghao Zhang, and Zhengguo
    Pu. 2023. Power load prediction of smart grid based on deep learning. *Procedia
    Computer Science* 228 (2023), 762–773.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie et al. (2022) Jiangjian Xie, Yujie Zhong, Tong Xiao, Zheng Wang, Junguo
    Zhang, Tuowai Wang, and Björn W Schuller. 2022. A multi-information fusion model
    for short term load forecasting of an architectural complex considering spatio-temporal
    characteristics. *Energy and Buildings* 277 (2022), 112566.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2022) Lei Xu, Maomao Hu, and Cheng Fan. 2022. Probabilistic electrical
    load forecasting for buildings using Bayesian deep neural networks. *Journal of
    Building Engineering* 46 (2022), 103853.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2018) Liwen Xu, Chengdong Li, Xiuying Xie, and Guiqing Zhang. 2018.
    Long-short-term memory network based hybrid model for short-term electrical load
    forecasting. *Information* 9, 7 (2018), 165.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2023) Bo Yang, Xiaohui Yuan, and Fei Tang. 2023. Iterative memory-driven
    load forecast network model for accuracy improvement. *Energy Reports* 9 (2023),
    388–395.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2022) Wangwang Yang, Jing Shi, Shujian Li, Zhaofang Song, Zitong
    Zhang, and Zexu Chen. 2022. A combined deep learning load forecasting model of
    single household resident user considering multi-time scale electricity consumption
    behavior. *Applied Energy* 307 (2022), 118197.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2019) Yandong Yang, Weijun Hong, and Shufang Li. 2019. Deep ensemble
    learning based probabilistic load forecasting in smart grids. *Energy* 189 (2019),
    116324.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2018) Yandong Yang, Shufang Li, Wenqi Li, and Meijun Qu. 2018.
    Power load probability density forecasting using gaussian process quantile regression.
    *Applied Energy* 213 (2018), 499–509.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yazici et al. (2022) Ibrahim Yazici, Omer Faruk Beyca, and Dursun Delen. 2022.
    Deep-learning-based short-term electricity load forecasting: A real case application.
    *Engineering Applications of Artificial Intelligence* 109 (2022), 104645.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yi et al. (2023) Shiyan Yi, Haichun Liu, Tao Chen, Jianwen Zhang, and Yibo Fan.
    2023. A deep LSTM-CNN based on self-attention mechanism with input data reduction
    for short-term load forecasting. *IET Generation, Transmission & Distribution*
    17, 7 (2023), 1538–1552.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yin and Xie (2021) Linfei Yin and Jiaxing Xie. 2021. Multi-temporal-spatial-scale
    temporal convolution network for short-term load forecasting of power systems.
    *Applied Energy* 283 (2021), 116328.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2022) Fan Yu, Lei Wang, Qiaoyong Jiang, Qunmin Yan, and Shi Qiao.
    2022. Self-attention-based short-term load forecasting considering demand-side
    management. *Energies* 15, 12 (2022), 4198.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu and Li (2021) Qun Yu and Zhiyi Li. 2021. Correlated load forecasting in active
    distribution networks using spatial-temporal synchronous graph convolutional networks.
    *IET Energy Systems Integration* 3, 3 (2021), 355–366.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2023) Xinli Yu, Zheng Chen, Yuan Ling, Shujing Dong, Zongyi Liu,
    and Yanbin Lu. 2023. Temporal data meets LLM–explainable financial time series
    forecasting. *arXiv preprint arXiv:2306.11025* (2023).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yue et al. (2022) Weimin Yue, Qingrong Liu, Yingjun Ruan, Fanyue Qian, and Hua
    Meng. 2022. A prediction approach with mode decomposition-recombination technique
    for short-term load forecasting. *Sustainable Cities and Society* 85 (2022), 104034.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zamee et al. (2021) Muhammad Ahsan Zamee, Dongjun Han, and Dongjun Won. 2021.
    Online hour-ahead load forecasting using appropriate time-delay neural network
    based on multiple correlation–multicollinearity analysis in IoT energy network.
    *IEEE Internet of Things Journal* 9, 14 (2021), 12041–12055.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zang et al. (2021) Haixiang Zang, Ruiqi Xu, Lilin Cheng, Tao Ding, Ling Liu,
    Zhinong Wei, and Guoqiang Sun. 2021. Residential load forecasting based on LSTM
    fusing self-attention mechanism with pooling. *Energy* 229 (2021), 120682.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023e) Dongxue Zhang, Shuai Wang, Yuqiu Liang, and Zhiyuan Du.
    2023e. A novel combined model for probabilistic load forecasting based on deep
    learning and improved optimizer. *Energy* 264 (2023), 126172.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022b) Guangqi Zhang, Chuyuan Wei, Changfeng Jing, and Yanxue
    Wang. 2022b. Short-term electrical load forecasting based on time augmented transformer.
    *International Journal of Computational Intelligence Systems* 15, 1 (2022), 67:1–67:11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022a) Han Zhang, Chen Peng, Jun Li, Yajie Niu, and Longxiang
    Li. 2022a. Electricity load forecasting based on an interpretable probsparse attention
    mechanism. In *Proceedings of the 3rd International Conference on Artificial Intelligence,
    Information Processing and Cloud Computing (AIIPCC’22)*. 1–7.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023d) Jinliang Zhang, Wang Siya, Tan Zhongfu, and Sun Anli. 2023d.
    An improved hybrid model for short term power load prediction. *Energy* 268 (2023),
    126561.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2021) Liang Zhang, Jin Wen, Yanfei Li, Jianli Chen, Yunyang Ye,
    Yangyang Fu, and William Livingood. 2021. A review of machine learning in building
    load prediction. *Applied Energy* 285 (2021), 116452.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2023b) Qingyong Zhang, Jiahua Chen, Gang Xiao, Shangyang He,
    and Kunxiang Deng. 2023b. TransformGraph: A novel short-term electricity net load
    forecasting model. *Energy Reports* 9 (2023), 2705–2717.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2022c) Ruixuan Zhang, Chuyan Zhang, and Miao Yu. 2022c. A similar
    day based short term load forecasting method using wavelet transform and LSTM.
    *IEEJ Transactions on Electrical and Electronic Engineering* 17, 4 (2022), 506–513.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023g) Ruixiang Zhang, Ziyu Zhu, Meng Yuan, Yihan Guo, Jie Song,
    Xuanxuan Shi, Yu Wang, and Yaojie Sun. 2023g. Regional residential short-term
    load-interval forecasting based on SSA-LSTM and load consumption consistency analysis.
    *Energies* 16, 24 (2023), 8062.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023a) Shiyun Zhang, Runhuan Chen, Jiacheng Cao, and Jian Tan.
    2023a. A CNN and LSTM-based multi-task learning architecture for short and medium-term
    electricity load forecasting. *Electric power systems research* 222 (2023), 109507.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023f) Tingze Zhang, Xinan Zhang, Tat Kei Chau, Yau Chow, Tyrone
    Fernando, Herbert Ho-Ching Iu, et al. 2023f. Highly accurate peak and valley prediction
    short-term net load forecasting approach based on decomposition for power systems
    with high PV penetration. *Applied Energy* 333 (2023), 120641.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023c) Zhenhao Zhang, Jiefeng Liu, Senshen Pang, Mingchen Shi,
    Hui Hwang Goh, Yiyi Zhang, and Dongdong Zhang. 2023c. General short-term load
    forecasting based on multi-task temporal convolutional network in COVID-19. *International
    Journal of Electrical Power & Energy Systems* 147 (2023), 108811.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2018) Jiaxiang Zheng, Xingying Chen, Kun Yu, Lei Gan, Yifan Wang,
    and Ke Wang. 2018. Short-term power load forecasting of residential community
    based on GRU neural network. In *Proceedings of the 2018 International Conference
    on Power System Technology (POWERCON’18)*. 4862–4868.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2022) Kedong Zhu, Yaping Li, Wenbo Mao, Feng Li, and Jiahao Yan.
    2022. LSTM enhanced by dual-attention-based encoder-decoder for daily peak load
    forecasting. *Electric Power Systems Research* 208 (2022), 107860.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhuang et al. (2022) Zhiyuan Zhuang, Xidong Zheng, Zixing Chen, and Tao Jin.
    2022. A reliable short-term power load forecasting method based on VMD-IWOA-LSTM
    algorithm. *IEEJ Transactions on Electrical and Electronic Engineering* 17, 8
    (2022), 1121–1132.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
