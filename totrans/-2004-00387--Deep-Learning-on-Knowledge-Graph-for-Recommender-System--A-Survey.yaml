- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:01:52'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2004.00387] Deep Learning on Knowledge Graph for Recommender System: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2004.00387](https://ar5iv.labs.arxiv.org/html/2004.00387)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning on Knowledge Graph for Recommender System: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Yang Gao [yxg122530@utdallas.edu](mailto:yxg122530@utdallas.edu) ,  Yi-Fan Li
    [yli@utdallas.edu](mailto:yli@utdallas.edu) University of Texas at Dallas ,  Yu
    Lin University of Texas at Dallas [yxl163430@utdallas.edu](mailto:yxl163430@utdallas.edu)
    ,  Hang Gao University of Maryland Baltimore County [hanggao1@umbc.edu](mailto:hanggao1@umbc.edu)
     and  Latifur Khan University of Texas at Dallas [lkhan@utdallas.edu](mailto:lkhan@utdallas.edu)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Recent advances in research have demonstrated the effectiveness of knowledge
    graphs (KG) in providing valuable external knowledge to improve recommendation
    systems (RS). A knowledge graph is capable of encoding high-order relations which
    connect two objects with one or multiple related attributes. With the help of
    the emerging Graph Neural Networks (GNN), it is possible to extract both object
    characteristics and relations from KG, which is an essential factor for successful
    recommendations. In this paper, we provide a comprehensive survey of the GNN-based
    knowledge-aware deep recommender systems. Specifically, we discuss the state-of-the-art
    frameworks with a focus on their core component, i.e., the graph embedding module,
    and how they address practical recommendation issues such as scalability, cold-start
    and so on. We further summarize the commonly-used benchmark datasets, evaluation
    metrics as well as the open-source codes. Finally, we conclude the survey and
    propose potential research directions in this rapidly growing field.
  prefs: []
  type: TYPE_NORMAL
- en: Knowledge Graph, Graph Neural Network (GNN), Recommender System
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In modern life, recommender systems (RS) are critical for users to make proper
    choices from the huge amount of products or services. For example, people are
    lured in AI-driven recommendation service for more than $75\%$ of the time they
    spent on watching YouTube videos (Solsman, [2018](#bib.bib23)). These systems
    attempt to learn the users’ interests and keep them away from over-choice, which
    significantly boosts their decision making process (Jannach et al., [2010](#bib.bib12)).
    They also help to promote services and sales for business such as e-commerce.
  prefs: []
  type: TYPE_NORMAL
- en: 'There are two main architectures for traditional recommender systems: content-based
    system and collaborative-filtering based system. Content-based systems accept
    data that can be represented as vectors in an euclidean space (Wu et al., [2019a](#bib.bib39))
    and measure their similarities based on these vectors. Collaborative-filtering
    based systems usually assume that each user-item interaction is an independent
    instance with side information encoded (Wang et al., [2019a](#bib.bib33)). However,
    in modern society, there is an increasing number of applications where data are
    generated from non-Euclidean domains and are represented in the form of Knowledge
    Graphs (KG). This data structure breaks the independent interaction assumption
    by linking items with their attributes. For example, in YouTube RS (show in Fig. [1](#S1.F1
    "Figure 1 ‣ 1\. Introduction ‣ Deep Learning on Knowledge Graph for Recommender
    System: A Survey")), the connections between users and movies might be actions
    such as views, likes and comments. On the other hand, movies may share the same
    genre, director, and etc. With these information, a knowledge-aware RS is hence
    able to capture not only the user-item interactions but also the rich item-item/user-user
    relations to make more accurate recommendations. It is worth noticing that nodes
    in the KG (e.g., person or movies) may have distinct neighborhood size (i.e.,
    number of neighboring nodes), and the relationships between them could vary as
    well, which makes recommendation with KG even more challenging.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a9540929dd600213ae956a872b095aea.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 1\. Illustration of user-item interactions and knowledge graph on YouTube,
    which contains users, movies, directors and genres as objects; liking, categorizing,
    directing and writing as object relations
  prefs: []
  type: TYPE_NORMAL
- en: Recently, there is an increasing interest in extending deep learning approaches
    for graph data. Motivated by CNNs, RNNs, and autoencoders from deep learning,
    new neural network architectures have been rapidly developed over the past few
    years to handle the complexity of graph data. These types of networks are referred
    as Graph Neural Networks (GNNs) (Wu et al., [2019a](#bib.bib39)) and are critical
    for recent success of knowledge-aware deep recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: There are a number of existing reviews on the topic of graph neural networks
    and knowledge graph analysis. Wu et al. (Wu et al., [2019a](#bib.bib39)) give
    an overview of graph neural networks in data mining and machine learning fields.
    Although it is the first comprehensive review of GNNs, this survey mainly focuses
    on the network architectures and only briefly mentions the possibility of applying
    GNNs for recommendation. On the other hand, Shi et al. (Shi et al., [2017](#bib.bib21))
    summarize the recommender systems utilizing the traditional knowledge graph analysis
    methods. But it misses the most recent development of GNN-based algorithms. To
    our best knowledge, our survey is the first review of state-of-the-art deep recommender
    systems that utilize GNNs to extract information from knowledge graphs for improving
    recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our Contributions: Our paper makes notable contributions summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'New Taxonomy: The core component of knowledge-aware deep recommender systems
    is the graph embedding module, which is usually a GNN in the state-of-the-art
    frameworks. Each layer of a GNN consists of two basic components: Aggregator and
    Updater. We categorize the aggregators into three groups: relation-unaware aggregator,
    relation-aware subgraph aggregator, and relation-aware attentive aggregator. We
    also divide the updaters into three categories, i.e., context-only updater, single-interaction
    updater and multi-interaction updater.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Comprehensive Overview: We provide the most comprehensive overview of state-of-the-art
    GNN-based Knowledge Aware Deep Recommender (GNN-KADR) systems. We provide detailed
    descriptions on representative models, make the necessary comparison, and discuss
    their solution to practical recommendation issues such as cold start, scalability
    and so on.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Resource Collection: We summarize resources regarding GNN-KADR systems, including
    benchmark datasets, evaluation metrics and open-source codes.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Future Directions: We analyze the limitations of existing works and suggest
    a few future research directions such as dynamicity, interpretability, fairness
    and so on.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Organization of Our Survey: The rest of the survey is organized as follows.
    Section [1](#S2.T1 "Table 1 ‣ 2\. Preliminary and Notation ‣ Deep Learning on
    Knowledge Graph for Recommender System: A Survey") defines the concepts related
    to GNN-based knowledge aware recommendations and lists the notations used in this
    paper. Section [3](#S3 "3\. Categorization and Frameworks ‣ Deep Learning on Knowledge
    Graph for Recommender System: A Survey") provides an overview of state-of-the-art
    GNN-KADR systems. Section [4](#S4 "4\. Solution to Practical Recommendation Issues
    ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey") discusses
    their solutions to practical recommendation issues. Section [5](#S5.T5 "Table
    5 ‣ 5.1\. Datasets ‣ 5\. Datasets, Codes and Evaluations ‣ Deep Learning on Knowledge
    Graph for Recommender System: A Survey") outlines the widely used benchmark datasets,
    evaluation metrics, and open-source codes. Section [6](#S6 "6\. Future Directions
    ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey") discusses
    the current challenges and suggests future research directions. Section [7](#S7
    "7\. Conclusion ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey")
    summarizes the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Preliminary and Notation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/36d9cdd6045d08375ce3e2d86bf1f1fc.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2\. Example of a knowledge graph on e-commerce websites.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let us consider a typical scenario on a e-commerce website: Jack is
    a customer who prefers to wear blue jeans and has queried about “jeans” one day.
    From the list of returned items, Jack clicked some attractive items for detailed
    information. During this week, he also visited some online shops for checking
    out T-shirts. Finally, on Sunday, Jack purchased a blue jean from his favorite
    brand as a birthday gift and added another T-shirt in the same shop to his shopping
    cart. Based on Jack’s behavior, the platform has collected rich information (submitted
    query words, clicked items, visited shops, preferred properties and brands) for
    recommending potential interesting items to him in the future. This kind of recommendation
    scenarios could also be observed on other websites. In general, multiple kinds
    of objects and historical user behaviors form a knowledge graph. Figure [2](#S2.F2
    "Figure 2 ‣ 2\. Preliminary and Notation ‣ Deep Learning on Knowledge Graph for
    Recommender System: A Survey") shows a toy example on e-commerce websites.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition 2.1.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Knowledge Graph (KG) (Sun et al., [2018a](#bib.bib25)) is defined as a directed
    graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$, where $\mathcal{V}$ is the set
    of nodes and $\mathcal{E}\subseteq\mathcal{V}\times\mathcal{V}$ is the set of
    edges between nodes in $\mathcal{V}$. $\mathcal{G}$ is associated with a node
    type mapping function $\phi$: $\mathcal{V}\rightarrow\mathcal{A}$ and an edge
    type mapping function $\psi$: $\mathcal{E}\rightarrow\mathcal{R}$, where $|\mathcal{A}|>1$
    and/or $|\mathcal{R}|>1$. Each node $v\in\mathcal{V}$ belongs to one particular
    node type in the node type set $\mathcal{A}$: $\phi(v)\in\mathcal{A}$, and each
    edge $e\in\mathcal{E}$ belongs to a particular relation type in relation type
    set $\mathcal{R}$: $\psi(e)\in\mathcal{R}$. Mining knowledge graphs is usually
    based on a basic entity-relation-entity triplet $(u,\mathpzc{e},v)$, where $u\in\mathcal{V}$,
    $\mathpzc{e}\in\mathcal{E}$, $v\in\mathcal{V}$ denote the head, relation and tail
    of this triplet. In this paper, we refer these entity-relation-entity triplets
    as knowledge triplets for simplicity. Here the types of nodes $u$ and $v$ could
    be either same or different depending on the context.'
  prefs: []
  type: TYPE_NORMAL
- en: Definition 2.2.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Neighborhood $N(v)$. Given a knowledge graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$,
    for a node $v$, its neighborhood $N(v)$ is defined as the set of nodes that directly
    connect to $v$, i.e., $\{w|(w,\mathpzc{e},u)\textit{ or }(u,\mathpzc{e},w),\mathpzc{e}\in\mathcal{E}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 2.3.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: $r$-Neighborhood $N_{r}(v)$. Given a knowledge graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$,
    for a node $v$, its $r$-neighborhood $N_{r}(v)$ is defined as the set of nodes
    that connect to $v$ with edges of type $r$, i.e., $\{w|(w,\mathpzc{e},u)\textit{
    or }(u,\mathpzc{e},w),\textit{ where }\mathpzc{e}\in\mathcal{E}\textit{ and }\psi(\mathpzc{e})=r\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'User-Item Recommendation In general, $\mathcal{V}$ can be further written as
    $\mathcal{V}=\mathcal{V}_{1}\cup\mathcal{V}_{2}\cup\cdots\cup\mathcal{V}_{i}\cup\cdots\cup\mathcal{V}_{n}$,
    where $\mathcal{V}_{i}$ denotes the set of nodes with type $i$ and $n=|\mathcal{A}|$.
    In recommendation we denote $\mathcal{V}_{1}$ as the set of user nodes and $\mathcal{V}_{2}$
    as the set of item nodes, with $\mathcal{V}_{3},\ldots,\mathcal{V}_{n}$ representing
    the other objects’ nodes (brand, properties, etc). We also denote $\mathcal{E}=\mathcal{E}_{label}\cup\mathcal{E}_{unlabel}$,
    where $\mathcal{E}_{label}\subseteq\mathcal{V}_{1}\times\mathcal{V}_{2}$ represents
    the set of edges between user and item nodes, and $\mathcal{E}_{unlabel}=\mathcal{E}\setminus\mathcal{E}_{label}$
    represents other edges. Since a typical recommendation setting in real world is
    to predict a user’s preferred items based on his historical behaviors, we use
    $\mathcal{G}=(\mathcal{V},\mathcal{E})$ to denote the graph constructed from historical
    data, and $\mathcal{G}^{P}=(\mathcal{V}^{P},\mathcal{E}^{P})$ to denote the graph
    of real future. The user-item recommendation problem can hence be formulated as
    a link prediction problem on graph:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Input: A KG $\mathcal{G}=(\mathcal{V},\mathcal{E})$ constructed based on historical
    data.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Output: A predicted edge set $\widehat{\mathcal{E}}^{p}_{label}$, which is
    the prediction of the real edge set $\mathcal{E}^{P}_{label}$ on $\mathcal{G}^{P}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout this paper, the bold uppercase characters are used to denote matrices
    and bold lowercase characters are used to denote vectors. Unless particularly
    specified, the notations used in this paper are illustrated in Table [1](#S2.T1
    "Table 1 ‣ 2\. Preliminary and Notation ‣ Deep Learning on Knowledge Graph for
    Recommender System: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Table 1\. Commonly used notations.
  prefs: []
  type: TYPE_NORMAL
- en: '| Notations | Descriptions |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $&#124;\cdot&#124;$ | The size of a set. |'
  prefs: []
  type: TYPE_TB
- en: '| $\odot$ | Element-wise product. |'
  prefs: []
  type: TYPE_TB
- en: '| $&#124;&#124;$ | Concatenation |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{G}$ | A knowledge graph. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{V}$ | The set of nodes in a knowledge graph. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{E}$ | The set of edges between nodes in $\mathcal{V}$. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{A}$ | The node type set. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathcal{R}$ | The edge relation type set. |'
  prefs: []
  type: TYPE_TB
- en: '| $v$ | A node $v\in\mathcal{V}$. |'
  prefs: []
  type: TYPE_TB
- en: '| $e_{i,j}$ | An edge $e_{i,j}\in\mathcal{E}$. |'
  prefs: []
  type: TYPE_TB
- en: '| $(u,\mathpzc{e},v)$ | A knowledge triplet where $u\in\mathcal{V}$, $\mathpzc{e}=e_{u,v}\in\mathcal{E}$,
    $v\in\mathcal{V}$ denote the head, relation and tail of this triplet. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{z}_{v}\in\mathbf{R}^{d}$ | The feature vector of node $v$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{z}_{\mathpzc{e}}\in\mathbf{R}^{c}$ | The feature vector of edge
    $\mathpzc{e}=e_{u,v}$ or $e_{v,u}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{z}_{\mathpzc{e}_{i,j}}\in\mathbf{R}^{c}$ | The feature vector of
    edge $e_{i,j}$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}\in\mathbf{R}^{k}$ | The context representation of node $u$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}^{r}\in\mathbf{R}^{k}$ | Type-$r$ context representation of
    node $u$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{X}\in\mathbf{R}^{N\times d}$ | The feature matrix of nodes in a
    knowledge graph. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{A}\in\mathbf{R}^{N\times N}$ | The adjacency matrix of a knowledge
    graph |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{N}\in\mathbf{R}^{N\times k}$ | The context representations of all
    nodes in a knowledge graph |'
  prefs: []
  type: TYPE_TB
- en: '| $N(v)$ | The neighborhood of a node $v$ |'
  prefs: []
  type: TYPE_TB
- en: '| $N_{r}(v)$ | $r$-Neighborhood of a node $v$. |'
  prefs: []
  type: TYPE_TB
- en: '| $n$ | The number of nodes, $n=&#124;\mathcal{V}&#124;$. |'
  prefs: []
  type: TYPE_TB
- en: '| $m$ | The number of edges, $m=&#124;\mathcal{E}&#124;$. |'
  prefs: []
  type: TYPE_TB
- en: '| $d$ | The dimension of a node feature vector. |'
  prefs: []
  type: TYPE_TB
- en: '| $c$ | The dimension of an edge feature vector |'
  prefs: []
  type: TYPE_TB
- en: '| $k$ | The dimension of $v$’s context representation. |'
  prefs: []
  type: TYPE_TB
- en: '| $\sigma(\cdot)$ | The sigmoid activation function |'
  prefs: []
  type: TYPE_TB
- en: '| $\beta(\cdot)$ | The LeakyReLU activation function |'
  prefs: []
  type: TYPE_TB
- en: '| $\gamma(\cdot)$ | An activation function, e.g., sigmoid, ReLU, etc. |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{W}$, $\mathbf{\Theta}$, $\mathbf{b}$ | Learnable model parameters.
    |'
  prefs: []
  type: TYPE_TB
- en: 3\. Categorization and Frameworks
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0370f2a218c777a738c9977539a3d760.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. The general workflow of a GNN-based Knowledge Aware Deep Recommender
    (GNN-KADR) system.
  prefs: []
  type: TYPE_NORMAL
- en: 'The general workflow of a GNN-based Knowledge Aware Deep Recommender (GNN-KADR)
    system is shown in Figure [3](#S3.F3 "Figure 3 ‣ 3\. Categorization and Frameworks
    ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey"). The graph
    embedding module of GNN-KADR first learns to produce an embedding for every graph
    node (including the user and item nodes), which encodes the information distilled
    from the input knowledge graph. Next, for a given user, the ranking module computes
    a match score between this user and each of the candidate items according to their
    corresponding embeddings. Those items with top-N match scores (or match scores
    above a user-specified threshold) are linked (recommended) to this user.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this process, the core component of the system is the graph embedding module,
    which is usually a Graph Neural Network (GNN) in the state-of-the-art frameworks.
    Each layer of a GNN consists of two basic components: Aggregator and Updater.
    For a node $v$, the Aggregator aggregates the feature information from the neighbors
    of $v$ to produce a context representation. The Updater then utilizes this context
    representation as well as other input information to obtain a new embedding for
    node $v$. Stacking $K$ different GNN layers or reusing the same GNN layer $K$
    times expands GNN’s receptive field to $K$-hop graph neighborhoods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We categorize the aggregators of GNNs into relation-unaware aggregator, relation-aware
    subgraph aggregator and relation-aware attentive aggregator. On the other hand,
    we divide the updaters into three categories, i.e., context-only updater, single-interaction
    updater and multi-interaction updater. Various categories of aggregators and updaters
    are described in Figure [4](#S3.F4 "Figure 4 ‣ 3\. Categorization and Frameworks
    ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey") and Figure [5](#S3.F5
    "Figure 5 ‣ 3\. Categorization and Frameworks ‣ Deep Learning on Knowledge Graph
    for Recommender System: A Survey") respectively. In the following, we discuss
    them in details.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 2\. Taxonomy and representative publications of GNN-based Knowledge Aware
    Deep Recommender (GNN-KADR) systems.
  prefs: []
  type: TYPE_NORMAL
- en: '| GNN | Category |  | Publications |'
  prefs: []
  type: TYPE_TB
- en: '| Aggregator | Relation-unaware Aggregator |  | (Fan et al., [2019b](#bib.bib5)), (Ying
    et al., [2018](#bib.bib43)) |'
  prefs: []
  type: TYPE_TB
- en: '| Relation-aware Aggregator | Subgraph Aggregator | (Xu et al., [2019](#bib.bib42)), (Zhang
    et al., [2019](#bib.bib46)),  (Zhao et al., [2019](#bib.bib47)) |'
  prefs: []
  type: TYPE_TB
- en: '| Attentive Aggregator | (Fan et al., [2019a](#bib.bib7)), (Li et al., [2019](#bib.bib16)), (Song
    et al., [2019](#bib.bib24)), (Wang et al., [2019d](#bib.bib31)), (Wang et al.,
    [2019e](#bib.bib32)), (Wang et al., [2019b](#bib.bib34)), (Wu et al., [2019c](#bib.bib37))
    |'
  prefs: []
  type: TYPE_TB
- en: '| Updater | Context-only Updater |  | (Fan et al., [2019b](#bib.bib5)), (Fan
    et al., [2019a](#bib.bib7)), (Li et al., [2019](#bib.bib16)), (Song et al., [2019](#bib.bib24)), (Wang
    et al., [2019e](#bib.bib32)), (Wu et al., [2019c](#bib.bib37)), (Zhang et al.,
    [2019](#bib.bib46)) |'
  prefs: []
  type: TYPE_TB
- en: '| Single-interaction Updater |  | (Wang et al., [2019d](#bib.bib31)), (Wang
    et al., [2019e](#bib.bib32)), (Xu et al., [2019](#bib.bib42)), (Ying et al., [2018](#bib.bib43)), (Zhao
    et al., [2019](#bib.bib47)) |'
  prefs: []
  type: TYPE_TB
- en: '| Multi-interaction Updater |  | (Wang et al., [2019b](#bib.bib34)) | ![Refer
    to caption](img/7915e1467c67d5ec85aea38d91fd27b7.png)'
  prefs: []
  type: TYPE_NORMAL
- en: Figure 4\. Description of relation-unaware aggregator, relation-aware subgraph
    aggregator, and relation-aware attentive aggregator.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bad61ad2072f20995d95c9738263beab.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. Description of context-only updater, single-interaction updater,
    and multi-interaction updater.
  prefs: []
  type: TYPE_NORMAL
- en: Table 3\. Summary of studied GNN-KADR systems.
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | Aggregator | Updater | Issues Solved |'
  prefs: []
  type: TYPE_TB
- en: '| MEIRec (Fan et al., [2019b](#bib.bib5)) | $\mathbf{n}_{u}=Avg/LSTM/CNN(\{\mathbf{z}_{v}&#124;v\in
    N(u)\})$ | $\mathbf{z}_{u}^{new}=\mathbf{n}_{u}$ | Scalability; Cold-Start |'
  prefs: []
  type: TYPE_TB
- en: '| GraphRec (Fan et al., [2019a](#bib.bib7)) | $\mathbf{x}_{u,v}=MLP(\mathbf{z}_{v}&#124;&#124;\mathbf{z}_{\mathpzc{e}})$
    | $\mathbf{z}_{u}^{new}=\gamma(\mathbf{W}\cdot\mathbf{n}_{u}+\mathbf{b})$ | —
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\alpha_{u,v}^{*}=\mathbf{W}_{2}^{T}\cdot\gamma(\mathbf{W}_{1}\cdot(\mathbf{x}_{u,v}&#124;&#124;\mathbf{z}_{u})+\mathbf{b}_{1})+\mathbf{b}_{2}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in N(u)}\exp(\alpha_{u,v^{\prime}}^{*})}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{x}_{u,v}$ |'
  prefs: []
  type: TYPE_TB
- en: '| V2HT (Li et al., [2019](#bib.bib16)) | $\mathbf{A}_{i,j}=f_{weight}(\mathbf{X}[i,:],\mathbf{X}[j,:],\mathpzc{e}_{i,j})$
    | $\mathbf{X}^{new}=\gamma(\mathbf{N}\mathbf{W})$ | Data Sparsity, Multimodality
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{A}^{\prime}_{i,j}=\alpha\cdot\frac{\mathbf{A}_{i,j}}{\sum_{j^{\prime}}\mathbf{A}_{i,j^{\prime}}}$
    if $i\neq j$ else $1-\alpha$ |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{N}=\tilde{\mathbf{D}}^{\prime-\frac{1}{2}}\mathbf{A}^{\prime}\tilde{\mathbf{D}}^{\prime-\frac{1}{2}}\mathbf{X}$,
    where $\tilde{\mathbf{D}}^{\prime}_{i,i}=\sum_{j}\mathbf{A}^{\prime}_{i,j}$ |'
  prefs: []
  type: TYPE_TB
- en: '| DGRec (Song et al., [2019](#bib.bib24)) | $\alpha_{u,v}=\frac{\mathrm{exp}(\mathbf{z}_{u}\cdot\mathbf{z}_{v})}{\sum_{v\in
    N(v)}\mathrm{exp}(\mathbf{z}_{u}\cdot\mathbf{z}_{v})}$ | $\mathbf{z}_{u}^{new}=ReLU(\mathbf{W}\cdot\mathbf{n}_{u})$
    | Dynamicity |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |'
  prefs: []
  type: TYPE_TB
- en: '| KGNN-LS (Wang et al., [2019d](#bib.bib31)) | $\mathbf{A}^{\prime}=\mathbf{A}+\mathbf{I}$
    | $\mathbf{X}^{new}=\gamma\big{(}(\mathbf{N}+\mathbf{D}^{-\frac{1}{2}}\cdot\mathbf{I}\cdot\mathbf{D}^{-\frac{1}{2}}\mathbf{X})\cdot\mathbf{W}\big{)}$
    | Personalization |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{N}=\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}\mathbf{X}$
    where $\mathbf{D}_{i,i}=\sum_{j}\mathbf{A}^{\prime}_{i,j}$ |'
  prefs: []
  type: TYPE_TB
- en: '| KGCN  (Wang et al., [2019e](#bib.bib32)) | $\alpha_{u,v}^{*}=g(\mathbf{z}_{v},\mathbf{z}_{\mathpzc{e}})$
    | $\mathbf{z}_{u,sum}^{new}=\gamma\big{(}\mathbf{W}\cdot(\mathbf{z}_{u}+\mathbf{n}_{u})+\mathbf{b}\big{)}$
    | — |'
  prefs: []
  type: TYPE_TB
- en: '| $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in N(u)}\exp(\alpha_{u,v^{\prime}}^{*})}$
    | $\mathbf{z}_{u,concat}^{new}=\gamma\big{(}\mathbf{W}\cdot(\mathbf{z}_{u}&#124;&#124;\mathbf{n}_{u})+\mathbf{b}\big{)}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ | $\mathbf{z}_{u,context}^{new}=\gamma\big{(}\mathbf{W}\cdot\mathbf{n}_{u}+\mathbf{b}\big{)}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| KGAT (Wang et al., [2019b](#bib.bib34)) | $\alpha_{u,v}^{*}=(\mathbf{W}_{\mathpzc{e}}\mathbf{z}_{v})^{T}tanh(\mathbf{W}_{\mathpzc{e}}\mathbf{z}_{u}+\mathbf{z}_{\mathpzc{e}})$
    | $\mathbf{z}_{u}^{new}=\beta\big{(}\mathbf{W}_{1}\cdot(\mathbf{z}_{u}+\mathbf{n}_{u})\big{)}+\beta\big{(}\mathbf{W}_{2}\cdot(\mathbf{z}_{u}\odot\mathbf{n}_{u})\big{)}$
    | — |'
  prefs: []
  type: TYPE_TB
- en: '| $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in N(u)}\exp(\alpha_{u,v^{\prime}}^{*})}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |'
  prefs: []
  type: TYPE_TB
- en: '| DANSER (Wu et al., [2019c](#bib.bib37)) | $\alpha_{u,v}=\frac{LeakyReLU(\mathbf{w}_{u}(\mathbf{W}_{e}\mathbf{z}_{\mathpzc{e}}\odot(\mathbf{W}_{p}\mathbf{z_{u}}&#124;&#124;\mathbf{W}_{p}\mathbf{z_{v}})))}{\sum_{v\in
    N(u)}LeakyReLU(\mathbf{w}_{u}(\mathbf{W}_{e}\mathbf{z}_{\mathpzc{e}}\odot(\mathbf{W}_{p}\mathbf{z_{u}}&#124;&#124;\mathbf{W}_{p}\mathbf{z_{v}})))}$
    | $\mathbf{z}_{u}^{new}=\gamma(\mathbf{W}\cdot\mathbf{n}_{u}+\mathbf{b})$ | Dynamicity
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |'
  prefs: []
  type: TYPE_TB
- en: '| RecoGCN (Xu et al., [2019](#bib.bib42)) | $\alpha_{v,u}^{r}=\text{softmax}_{v}\big{(}\{\mathbf{W}_{1}^{r}\mathbf{z}_{v}\cdot\mathbf{W}_{2}^{r}\mathbf{z}_{u}&#124;v\in
    N_{r}(u)\}\big{)}$ | $\mathbf{z}_{u}^{new}=ReLU\big{(}\mathbf{W}\cdot(\mathbf{z}_{u}&#124;&#124;\mathbf{n}_{u})+\mathbf{b}\big{)}$
    | Scalability |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}^{r}=\sum_{\forall v\in N_{r}(u)}\alpha_{v,u}^{r}\mathbf{z}_{v}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{r}\mathbf{n}_{u}^{r}$ |'
  prefs: []
  type: TYPE_TB
- en: '| PinSage (Ying et al., [2018](#bib.bib43)) | $\mathbf{n}_{u}=Avg/Pool\big{(}\{ReLU(\mathbf{W}_{1}\mathbf{z}_{v}+\mathbf{b})&#124;v\in
    N(u)\},\{\alpha_{v}\}\big{)}$ | $\mathbf{z}_{u}^{new}=ReLU\big{(}\mathbf{W}_{2}\cdot(\mathbf{z}_{u}&#124;&#124;\mathbf{n}_{u})+\mathbf{b}\big{)}$
    | Scalability |'
  prefs: []
  type: TYPE_TB
- en: '| STAR-GCN (Zhang et al., [2019](#bib.bib46)) | $\mathbf{n}_{u}^{r}=\sum\limits_{v\in
    N_{r}(u)}\frac{1}{\sqrt{&#124;N_{r}(u)&#124;\cdot&#124;N_{r}(v)&#124;}}\mathbf{W}^{r}\mathbf{z}_{v}$
    | $\mathbf{z}_{u}^{new}=\gamma\big{(}\mathbf{W}\cdot\gamma(\mathbf{n}_{u})\big{)}$
    | Cold-Start |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{r}\mathbf{n}_{u}^{r}$ |'
  prefs: []
  type: TYPE_TB
- en: '| IntentGC (Zhao et al., [2019](#bib.bib47)) | $\mathbf{n}_{u}^{r}=Avg\big{(}\{\mathbf{z}_{v}&#124;v\in
    N_{r}(u)\}\big{)}$ | $\mathbf{z}_{u}^{new}=\gamma(\mathbf{W}\cdot\mathbf{z}_{u}+\mathbf{n}_{u})$
    | Scalability |'
  prefs: []
  type: TYPE_TB
- en: '| $\mathbf{n}_{u}=\sum_{r=1}^{&#124;\mathcal{R}&#124;-2}\mathbf{W}^{r}\mathbf{n}_{u}^{r}$
    |'
  prefs: []
  type: TYPE_TB
- en: 3.1\. Aggregator
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 3.1.1\. Relation-unaware Aggregator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For a target node $u$, a relation-unaware aggregator aims to aggregate information
    from parts or all of $u$’s neighboring nodes to produce a context representation.
    However, in this process, the relation $r=\psi(\mathpzc{e})$ ($\mathpzc{e}=e_{u,v}\text{
    or }e_{v,u}$) between the target node $u$ and any neighboring node $v$ is ignored,
    and its information is hence not encoded in the context representation $\mathbf{n}_{u}$.
  prefs: []
  type: TYPE_NORMAL
- en: Fan et al. (Fan et al., [2019b](#bib.bib5)) points out that existing methods
    used in industry for intent recommendation rely on extensive laboring feature
    engineering and fail to utilize the rich interaction between users and items,
    which limits the model performance. To solve these issues, they model the complex
    objects (i.e., users and items with their attributes) as well as their interactions
    as a knowledge graph, and present a framework called MEIRec to learn the object
    embeddings for recommendation. The GNN in MEIRec generates a context representation
    for a target node $u$ by
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\mathbf{n}_{u}=g(\{\mathbf{z}_{v}&#124;v\in N(u)\})$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{z}_{v}$ is the embedding of node $v$ and $g$ is a aggregate function
    that can be either average, LSTM or CNN depending on the context. For example,
    they choose $g$ to be average function if $u$ is an item node, since there is
    usually no priority among users that have clicked/purchased an item. On the other
    hand, they choose LSTM as $g$ if $u$ represents a user node, because a user usually
    clicks items with timestamp and its neighbors can be viewed as a sequence data.
  prefs: []
  type: TYPE_NORMAL
- en: Ying et.al. (Ying et al., [2018](#bib.bib43)) introduce a data-efficient large-scale
    deep recommendation engine PinSage that is developed and deployed at Pinterest.
    PinSage combines efficient random walks and GNN to generate embeddings of nodes
    that incorporate both graph structure as well as node feature information. For
    each target node $u$, PinSage first measures the importance of $u$’s neighboring
    nodes by simulating random walks starting from $u$ and computes the $L_{1}$-normalized
    visit count of nodes. Then the context representation $\mathbf{n}_{u}$ is computed
    by
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $\mathbf{n}_{u}=Avg/Pool(\{ReLU(\mathbf{W}_{1}\mathbf{z}_{v}+\mathbf{b})&#124;v\in
    N(u)\},\{\alpha_{v}\})$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{W}_{1}$, $\mathbf{b}$ are parameters to learn, and $\{\alpha_{v}\}$
    are $L_{1}$-normalized visit counts of $u$’s corresponding neighboring nodes.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2\. Relation-aware Subgraph Aggregator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To handle different relations in the knowledge graph, the relation-aware subgraph
    aggregators split the neighborhood graph into multiple subgraphs such that all
    edges of a subgraph belong to only one of the relation types in $\mathcal{R}$.
    Each subgraph is assigned with an aggregator characterized by a unique set of
    parameters, and its information is extracted by this aggregator to produce a relation-sensitive
    context representation. We use $\mathbf{n}_{u}^{r}$ to denote the representation
    generated from a subgraph with type $r$ edges. Finally, $\{\mathbf{n}_{u}^{r_{1}},\mathbf{n}_{u}^{r_{2}},\ldots\}$
    are further fused together to produce the overall context representation for target
    node $u$. A typical example is shown in Figure [4](#S3.F4 "Figure 4 ‣ 3\. Categorization
    and Frameworks ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey")b.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The complex interactions in agent-initialized social e-commerce can be formulated
    as a knowledge graph with numerous types of relations between three types of nodes,
    i.e., users, selling agents and items. Xu et al. (Xu et al., [2019](#bib.bib42))
    propose a novel framework RecoGCN to effectively aggregate the heterogeneous features
    in this knowledge graph. The “relation-aware aggregator” used in RecoGCN is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $\alpha_{v,u}^{r}=\text{softmax}_{v}\big{(}\{\mathbf{W}_{1}^{r}\mathbf{z}_{v}\cdot\mathbf{W}_{2}^{r}\mathbf{z}_{u}&#124;v\in
    N_{r}(u)\}\big{)}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (4) |  | $\mathbf{n}_{u}^{r}=\sum_{\forall v\in N_{r}(u)}\alpha_{v,u}^{r}\mathbf{z}_{v}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (5) |  | $\mathbf{n}_{u}=\sum_{r}\mathbf{n}_{u}^{r}$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{W}_{1}^{r}$ and $\mathbf{W}_{2}^{r}$ are two learnable transformations
    assigned to the relation type $r\in\mathcal{R}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'To boost the performance in recommender systems, The STAR-GCN architecture
    introduced by Zhang et al. (Zhang et al., [2019](#bib.bib46)) employs a multi-link
    graph convolutional encoder to learn the node representations. Each representation
    type $r\in\mathcal{R}$ is assigned with a specific transformation. Its aggregator
    is hence formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $\mathbf{n}_{u}^{r}=\sum_{v\in N_{r}(u)}\frac{1}{\sqrt{&#124;N_{r}(u)&#124;\cdot&#124;N_{r}(v)&#124;}}\mathbf{W}^{r}\mathbf{z}_{v}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (7) |  | $\mathbf{n}_{u}=\sum_{r}\mathbf{n}_{u}^{r}$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\{\mathbf{W}^{r}|r\in\mathcal{R}\}$ are the parameters to learn.
  prefs: []
  type: TYPE_NORMAL
- en: 'IntentGC proposed by Zhao et al. (Zhao et al., [2019](#bib.bib47)) is a recommendation
    framework that captures both the explicit user preference and heterogeneous relationships
    of auxiliary information. To perform large-scale recommendation, IntentGC introduces
    a vector-wise aggregator:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (8) |  | $\mathbf{n}_{u}^{r}=Avg\big{(}\{\mathbf{z}_{v}&#124;v\in N_{r}(u)\}\big{)}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (9) |  | $\mathbf{n}_{u}=\sum_{r=1}^{&#124;\mathcal{R}&#124;-2}\mathbf{W}^{r}\mathbf{n}_{u}^{r}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: This aggregator is computationally efficient since it avoids unnecessary computations
    by replacing the expensive operation $\mathbf{W}\cdot(\mathbf{n}_{u}^{r_{1}}||\mathbf{n}_{u}^{r_{2}}||\ldots)$
    with the summation of multiple small matrix products.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3\. Relation-aware Attentive Aggregator
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In contrast to the other two types of aggregators, relation-aware attentive
    aggregators convert the neighborhood graph into a weighted graph, where the weight
    of each edge is a function of corresponding knowledge triplet, e.g., $w=\frac{f(\mathbf{z}_{u},\mathbf{z}_{\mathpzc{e}},\mathbf{z}_{v})}{\sum_{v^{\prime}\in
    N(u)}f(\mathbf{z}_{u},\mathbf{z}_{\mathpzc{e}^{\prime}},\mathbf{z}_{v^{\prime}})}$,
    $w=f(\mathbf{z}_{u},\mathbf{z}_{\mathpzc{e}},\mathbf{z}_{v})$, etc. These weights
    capture the rich semantic information encoded in the edges of a knowledge graph,
    and measure the relatedness of different knowledge triplets to the target node
    $u$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Wang et al. (Wang et al., [2019d](#bib.bib31)) propose an end-to-end framework
    KGNN-LS that utilizes a knowledge graph as an addition information source to improve
    recommendation. For a given user, KGNN-LS applies a trainable function to identify
    important knowledge graph relationships and converts the knowledge graph into
    a user-specific weighted graph. The aggregator in KGNN-LS is hence formulated
    as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (10) |  | $\mathbf{A}^{\prime}=\mathbf{A}+\mathbf{I}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (11) |  | $\mathbf{N}=\mathbf{D}^{-\frac{1}{2}}\mathbf{A}\mathbf{D}^{-\frac{1}{2}}\mathbf{X}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{A}_{i,j}=f(\mathbf{z}_{\mathpzc{e}_{i,j}})$ and $\mathbf{D}$
    is a diagonal matrix with $\mathbf{D}_{i,i}=\sum_{j}\mathbf{A}^{\prime}_{i,j}$.
    $f$ is a user-specific scoring function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Li et al. (Li et al., [2019](#bib.bib16)) introduce a novel framework named
    V2HT, which is capable of boosting the performance of micro-video hashtag recommendation
    by jointly considering the sequential feature learning, the video-user-hashtag
    interaction, and the hashtag correlations. Similar to KGNN-LS, they assign different
    weights on different types of edges to transform the knowledge graph into a weighted
    graph. Specifically, the aggregator used in V2HT is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (12) |  | $\mathbf{A}_{i,j}=f_{weight}(\mathbf{X}[i,:],\mathbf{X}[j,:],\mathpzc{e}_{i,j})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (13) |  | $\mathbf{A}^{\prime}_{i,j}=\begin{cases}\alpha\cdot\frac{\mathbf{A}_{i,j}}{\sum_{j^{\prime}}\mathbf{A}_{i,j^{\prime}}}&amp;\text{if
    $i\neq j$}\\ 1-\alpha&amp;\text{otherwise}\end{cases}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (14) |  | $\mathbf{N}=\tilde{\mathbf{D}}^{\prime-\frac{1}{2}}\mathbf{A}^{\prime}\tilde{\mathbf{D}}^{\prime-\frac{1}{2}}\mathbf{X}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the subscripts $i$ and $j$ denote the $i_{th}$ and $j_{th}$ node in the
    graph, and $\tilde{\mathbf{D}}$ is a diagonal matrix with $\tilde{\mathbf{D}}_{i,i}=\sum_{j}\mathbf{A}^{\prime}_{i,j}$.
    Here $\alpha$ determines the weights assigned to a node itself and other correlated
    nodes. When $\alpha\rightarrow 1$, the feature of a node itself will be ignored;
    when $\alpha\rightarrow 0$, neighboring information will be ignored.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fan et al. (Fan et al., [2019a](#bib.bib7)) propose a novel graph neural network
    framework GraphRec for social recommendation. The knowledge graph in social recommendation
    usually consists of two graphs: a social graph denoting the relationship between
    users and a user-item graph denoting interactions between users and items. GraphRec
    introduces three aggregators to process these two different graphs, i.e., user
    aggregator, item aggregator and social aggregator. The user and item aggregators
    extract information from the user-item graph while the social aggregator distills
    information from the social graph. These aggregators work in a similar way. Thus
    we only explain the item aggregator here for simplicity. Mathematically, the item
    aggregator is formulated as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (15) |  | $\mathbf{x}_{u,v}=MLP(\mathbf{z}_{v}&#124;&#124;\mathbf{z}_{\mathpzc{e}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (16) |  | $\alpha_{u,v}^{*}=\mathbf{W}_{2}^{T}\cdot\gamma(\mathbf{W}_{1}\cdot(\mathbf{x}_{u,v}&#124;&#124;\mathbf{z}_{u})+\mathbf{b}_{1})+\mathbf{b}_{2}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (17) |  | $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in
    N(u)}\exp(\alpha_{u,v}^{*})}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (18) |  | $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{x}_{u,v}$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\alpha_{u,v}$ represents the attention weight of the interaction with
    $v$ in contributing $u$’s context representation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Recommendation in online communities faces two challenges: 1) users’ interest
    are dynamic, and 2) users are influenced by their friends. To address these challenges,
    Song et al. (Song et al., [2019](#bib.bib24)) introduce a novel framework DGRec
    based on a dynamic graph attention neural network. Specifically, They first model
    dynamic user behaviors with a recurrent neural network, and its outputs are used
    as initial graph node embeddings. Then, a graph attention neural network is adopted
    to model context dependent social influence, which dynamically infers the influencers
    based on user’s current interest. The aggregator in this graph attention neural
    network is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (19) |  | $\alpha_{u,v}=\frac{\mathrm{exp}(\mathbf{z}_{u}\cdot\mathbf{z}_{v})}{\sum_{v\in
    N(v)}\mathrm{exp}(\mathbf{z}_{u}\cdot\mathbf{z}_{v})}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (20) |  | $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'The KGCN framework proposed by Wang et al. (Wang et al., [2019e](#bib.bib32))
    is an end-to-end recommender system that automatically discovers the high-order
    structure information and semantic information of Knowledge Graph (KG). The key
    idea of KGCN is to aggregate and incorporate neighborhood information with bias
    when calculating the representation for a given node in the knowledge graph. It
    is implemented by weighting neighbors with scores dependent on the connecting
    relations and nodes, which characterizes both the semantic information of KG and
    user’s personalized interests in relations. Specifically, the aggregator in KGCN
    is:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (21) |  | $\alpha_{u,v}^{*}=g(\mathbf{z}_{v},\mathbf{z}_{e})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (22) |  | $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in
    N(u)}\exp(\alpha_{u,v^{\prime}}^{*})}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (23) |  | $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Wang et al. (Wang et al., [2019b](#bib.bib34)) propose a method named KGAT
    to explicitly model the high-order connectivities in KG in an end-to-end fashion.
    The aggregator in KGAT works in a similar way as that of KGCN. The only difference
    is that it takes all the three embeddings $\mathbf{z}_{u}$, $\mathbf{z}_{e}$,
    and $\mathbf{z}_{v}$ of a knowledge triplet as input to compute the attention
    score:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (24) |  | $\alpha_{u,v}^{*}=(\mathbf{W}_{e}\mathbf{z}_{v})^{T}tanh(\mathbf{W}_{e}\mathbf{z}_{u}+\mathbf{z}_{e})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (25) |  | $\alpha_{u,v}=\frac{\exp(\alpha_{u,v}^{*})}{\sum_{v^{\prime}\in
    N(u)}\exp(\alpha_{u,v^{\prime}}^{*})}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (26) |  | $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |  |'
  prefs: []
  type: TYPE_TB
- en: Here $\mathbf{W}_{e}$ is a projection matrix to learn, which transforms inputs
    from the node embedding space to the edge embedding space.
  prefs: []
  type: TYPE_NORMAL
- en: 'In social recommendation, there are four different social effects in recommender
    systems, including two-fold effects in user domain, i.e., a static effect from
    social homophily and a dynamic effect from social influence, and the other symmetric
    two-fold ones in item domain. To capture these four effects, Wu et al. (Wu et al.,
    [2019c](#bib.bib37)) propose a framework named DANSER, which is composed of two
    dual Graph ATtention networks (GAT) (Velickovic et al., [2018](#bib.bib28)): one
    dual GAT for users-including a GAT to capture social homophily and a GAT to capture
    social influence—and the other dual GAT for items. The aggregators in DENSER work
    in a similar way. We show one of them as an example:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (27) |  | $\alpha_{u,v}=\frac{LeakyReLU(\mathbf{w}_{u}(\mathbf{W}_{e}\mathbf{z}_{\mathpzc{e}}\odot(\mathbf{W}_{p}\mathbf{z_{u}}&#124;&#124;\mathbf{W}_{p}\mathbf{z_{v}})))}{\sum_{v\in
    N(u)}LeakyReLU(\mathbf{w}_{u}(\mathbf{W}_{e}\mathbf{z}_{\mathpzc{e}}\odot(\mathbf{W}_{p}\mathbf{z_{u}}&#124;&#124;\mathbf{W}_{p}\mathbf{z_{v}})))}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (28) |  | $\mathbf{n}_{u}=\sum_{v\in N(u)}\alpha_{u,v}\mathbf{z}_{v}$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{W}_{p}$, $\mathbf{W}_{e}$, and $\mathbf{w}_{u}$ are two weight
    matrices and one weight vector to learn.
  prefs: []
  type: TYPE_NORMAL
- en: '3.1.4\. Discussion:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Compared to the other two types of aggregators, the relation-unaware aggregator
    loses the rich semantic information encoded in the edges of a Knowledge Graph
    (KG), which limits the model performance. On the other hand, although the relation-aware
    subgraph aggregator is able to model various semantic relations in KG, it has
    several limitations. First, as each relation type $r\in\mathcal{R}$ is assigned
    with a unique set of parameters, the number of training parameters in this type
    of aggregators significantly increases when the relation type set $\mathcal{R}$
    becomes larger. Those methods utilizing relation-aware subgraph aggregators are
    hence not suitable for processing knowledge graphs with numerous types of relations.
    Second, these aggregators process the subgraphs of different relation types independently.
    The correlation between different relation types are hence not encoded in the
    learned context representation $\mathbf{n}_{u}$, which limits the recommendation
    performance. The relation-aware attentive aggregator utilizes a single function
    to compute attention scores for different relation types in KG, and hence can
    be applied for large-scale knowledge graphs. Meanwhile, it also improves the explainability
    of deep recommender systems by weighting the contributions of different nodes
    neighboring to the target node $u$.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Updater
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 3.2.1\. Context-only Updater
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For any node $u$ in the knowledge graph, the context-only updater only receives
    $u$’s context representation $\mathbf{n}_{u}$ as input, and produces a new representation
    $\mathbf{z}_{u}^{new}=f(\mathbf{n}_{u})$ for this node. Here $f$ is the updater
    function.
  prefs: []
  type: TYPE_NORMAL
- en: 'MEIRec (Fan et al., [2019b](#bib.bib5)) simply takes $\mathbf{n}_{u}$ as the
    new embedding for node $u$, i.e., $\mathbf{z}_{u}^{new}=\mathbf{n}_{u}$, which
    is computational efficient but may not be optimal. To overcome this issue, GraphRec (Fan
    et al., [2019a](#bib.bib7)), V2HT (Li et al., [2019](#bib.bib16)), DGRec (Song
    et al., [2019](#bib.bib24)), KGCN  (Wang et al., [2019e](#bib.bib32)), and DANSER (Wu
    et al., [2019c](#bib.bib37)) propose to approximate $f$ via a MLP:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (29) |  | $\mathbf{z}_{u}^{new}=\gamma(\mathbf{W}\cdot\mathbf{n}_{u}+\mathbf{b})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\gamma$ is a non-linear activation function such as ReLU, and the bias
    $\mathbf{b}$ could be set to $\mathbf{0}$. STAR-GCN (Zhang et al., [2019](#bib.bib46))
    improves the non-linearity of $f$ by applying another activation function on $\mathbf{n}_{u}$
    before sending it to the MLP layer:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (30) |  | $\mathbf{z}_{u}^{new}=\gamma(\mathbf{W}\cdot\gamma(\mathbf{n}_{u})+\mathbf{b})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 3.2.2\. Single-interaction Updater
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For any node $u$ in the knowledge graph, the single-interaction updater takes
    both $u$’s context representation $\mathbf{n}_{u}$ and $u$’s current embedding
    $\mathbf{z}_{u}$ as input to compute a new representation $\mathbf{z}_{u}^{new}=f(\mathbf{n}_{u},\mathbf{z}_{u})$.
    $f$ is a function that involves a binary operator such as sum, concatenation,
    etc, which is applied to both $\mathbf{n}_{u}$ and $\mathbf{z}_{u}$. This operator
    builds an interaction between the node $u$ and its context, and could potentially
    improve the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: KGNN-LS (Wang et al., [2019d](#bib.bib31)) and KGCN  (Wang et al., [2019e](#bib.bib32))
    both utilize summation as the interaction operator. The only difference is that
    KGNN-LS applies a scaling operation on the input node embeddings before feeding
    them to the operator. Their updaters can be written as
  prefs: []
  type: TYPE_NORMAL
- en: '| (31) |  | $\mathbf{z}_{u}^{new}=\gamma\big{(}\mathbf{W}\cdot(\lambda\mathbf{z}_{u}+\mathbf{n}_{u})+\mathbf{b})\big{)}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\lambda$ is the scaling factor and $\mathbf{b}$ is a bias that could
    be set to $\mathbf{0}$.
  prefs: []
  type: TYPE_NORMAL
- en: RecoGCN (Xu et al., [2019](#bib.bib42)) and PinSage (Ying et al., [2018](#bib.bib43))
    replace the summation operator in the above updaters with the concatenation operation.
    It improves the expressiveness of the updater by doubling the learnable parameters,
    but also increases the computation cost.
  prefs: []
  type: TYPE_NORMAL
- en: '| (32) |  | $\mathbf{z}_{u}^{new}=ReLU\big{(}\mathbf{W}\cdot(\mathbf{z}_{u}&#124;&#124;\mathbf{n}_{u})+\mathbf{b})\big{)}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 3.2.3\. Multi-interaction Updater
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The multi-interaction updater is a combination of multiple single-interaction
    updaters with different binary operators, i.e., $\mathbf{z}_{u}^{new}=g\big{(}f_{1}(\mathbf{n}_{u},\mathbf{z}_{u}),f_{2}(\mathbf{n}_{u},\mathbf{z}_{u}),\ldots\big{)}$.
    Here $g$ is a function to fuse the representations obtained from different single-interaction
    updaters. This type of updaters improves feature interactions and may lead to
    better performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'The only method in current literature that utilizes multi-interaction updaters
    is KGAT (Wang et al., [2019b](#bib.bib34)). It considers two different operators:
    summation and element-wise product. The mathematical formulation of this updater
    is'
  prefs: []
  type: TYPE_NORMAL
- en: '| (33) |  | $\mathbf{z}_{u}^{new}=LeakyReLU\big{(}\mathbf{W}_{1}(\mathbf{z}_{u}+\mathbf{n}_{u})\big{)}+LeakyReLU\big{(}\mathbf{W}_{2}(\mathbf{z}_{u}\odot\mathbf{n}_{u})\big{)}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: The authors choose element-wise product because it makes the information being
    propagated in the graph sensitive to the affinity between $\mathbf{z}_{u}$ and
    $\mathbf{n}_{u}$, e.g., passing more information from similar nodes.
  prefs: []
  type: TYPE_NORMAL
- en: '3.2.4\. Discussion:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since the information of the target node $u$ is missing in the inputs of context-only
    updaters, they may not be sufficient to model the interaction between $u$ and
    its context, which limits the quality of learned representations. Single-interaction
    updaters address this issue by manually encoding the feature interactions between
    $\mathbf{z}_{u}$ and $\mathbf{n}_{u}$. Multi-interaction updaters further improve
    it by considering different binary operators at a time. In general, more attention
    is needed on the multi-interaction updaters, especially for the fusion function
    $g$. For example, instead of using a simple operation like summation, is it possible
    to learn a fusion function $g$?
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Solution to Practical Recommendation Issues
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss the solution proposed by the state-of-the-art frameworks
    to practical recommendation issues such as scalability, data sparsity, and so
    on.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Cold Start
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The cold-start problem (Acilar and Arslan, [2009](#bib.bib2)), i.e., how to
    make proper recommendations for new users or new items, is a daunting dilemma
    in practical recommender systems. On one hand, new users and new items occupy
    a large portion in many real-world applications such as YouTube (Covington et al.,
    [2016](#bib.bib4)). On the other hand, the performance of recommendation largely
    depends on sufficient amount of historical user-item interaction data, and degrades
    significantly on new users/items.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1\. Uniform Term Embedding
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: MEIRec (Fan et al., [2019b](#bib.bib5)) proposed by Fan et al. is an intent
    recommendation framework that recommends the most relevant intent (i.e., query)
    to a user based on his/her click history. The authors find that queries and titles
    of items are constituted by terms, and the number of terms are not many. So they
    propose to represent the queries/titles with a small number of term embeddings.
    It significantly reduces the number of training parameters in the model. The new
    queries/items that have never been searched/added before can also be represented
    by these terms.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2\. Masked Embedding Training with Encoder-Decoder Architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'STAR-GCN (Zhang et al., [2019](#bib.bib46)) adopts a multi-block graph encoder-decoder
    architecture. Each block contains two components: a graph encoder and a graph
    decoder. The graph encoder generates node representations by encoding semantic
    graph structure and input content features, and the decoder aims to recover the
    input node embeddings. To train STAR-GCN, the authors mask some percentage of
    the input nodes at random and then reconstruct the clean node embeddings utilizing
    their context information. This is referred as masked embedding training mechanism.
    By using this mechanism, STAR-GCN can learn embeddings for nodes that are not
    observed in the training phase. In a cold start scenario, STAR-GCN initializes
    the embeddings of new nodes to be zero and gradually refines the estimated embeddings
    by multiple blocks of GNN encoder-decoders.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. Scalability
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In most existing graph neural networks, their aggregators have to visit the
    full neighborhood of a node to produce its node embedding, which is computationally
    intractable for large-scale knowledge graphs. In the following, we show some solutions
    proposed by the studied methods to this scalability issue.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1\. Important Node Sampling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Instead of examining k-hop graph neighborhood to compute node embeddings, PinSage (Ying
    et al., [2018](#bib.bib43)) defines importance-based neighborhoods, where the
    neighborhood of a node $u$ is defined as the $T$ nodes that exert the most influence
    on node $u$. Specifically, it simulates random walks starting from $u$ and computes
    the $L_{1}$-normalized visit count for nodes visited by random walks. The neighborhood
    of $u$ is hence the top $T$ nodes with the highest normalized visit counts.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2\. Meta-path Defined Receptive Field
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: MEIRec (Fan et al., [2019b](#bib.bib5)) and RecoGCN (Xu et al., [2019](#bib.bib42))
    propose to leverage the semantic-aware meta paths to carve out concise and relevant
    receptive fields for each node, which is referred as meta-path defined receptive
    field.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 4.1.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Meta-path (Xu et al., [2019](#bib.bib42)). A meta-path $\rho$ is defined as
    a path in a knowledge graph in the form of $t_{1}\xrightarrow{r_{1}}t_{2}\xrightarrow{r_{2}}\cdots\xrightarrow{r_{l}}t_{l+1}$,
    where there is a composite relation $R=r_{1}\circ r_{2}\circ\cdots\circ r_{l}$
    between node type $t_{1}$ and $t_{l+1}$.
  prefs: []
  type: TYPE_NORMAL
- en: Definition 4.2.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Meta-path defined Receptive Field (MRF) (Xu et al., [2019](#bib.bib42)). Given
    a knowledge graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$, for a node $v$ and
    a meta-path $\rho$ of length $l$, a meta-path defined receptive field $F_{v}^{\rho}=\big{(}f_{v}^{\rho}(0),f_{v}^{\rho}(1),\cdots,f_{v}^{\rho}(l)\big{)}$
    is defined as the set of nodes that can be travelled to or passed by from node
    $v$ via the meta-path $\rho$, where $f_{v}^{\rho}(k)$ denotes the set of nodes
    reached by $k$ jumps on $\rho$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [6](#S4.F6 "Figure 6 ‣ 4.2.2\. Meta-path Defined Receptive Field ‣ 4.2\.
    Scalability ‣ 4\. Solution to Practical Recommendation Issues ‣ Deep Learning
    on Knowledge Graph for Recommender System: A Survey") shows an example of MRF.
    Compared to $k$-hop graph neighborhood, MRF focuses only on the relations selected
    based on prior knowledge, and accelerates the training by greatly reducing the
    number of nodes in the computation graph. Moreover, it is possible to enlarge
    the receptive field of a node $u$ by computing multiple embeddings along different
    meta-paths and fusing them together to obtain a final representation:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (34) |  | $\mathbf{z}_{u}^{new}=g(\mathbf{z}_{u,\rho_{1}}^{new},\mathbf{z}_{u,\rho_{2}}^{new},\ldots,\mathbf{z}_{u,\rho_{K}}^{new})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $g$ is a fusion function. Note that the computation of these embeddings
    are independent from each other, and hence can be done in parallel.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/765d8e5e9cc69850570aaf7f770bc318.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6\. An example of meta-path defined receptive field.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3\. Vector-wise Aggregator and Updater
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To remove the limitation of training on clustered mini-graphs for large-scale
    graphs, IntentGC (Zhao et al., [2019](#bib.bib47)) introduces a special graph
    neural network, which replaces the normal aggregator and updater in GNNs with
    a vector-wise aggregator and a vector-wise updater. The key idea is to avoid unnecessary
    feature interactions by replacing the expensive matrix multiplication between
    a huge weight matrix and a giant feature vector (formed by concatenation of many
    vectors) with a summation of multiple small matrix products. The detailed formulation
    is shown in Table [3](#S3.T3 "Table 3 ‣ 3\. Categorization and Frameworks ‣ Deep
    Learning on Knowledge Graph for Recommender System: A Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Personalization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.3.1\. Graph Translation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: KGNN-LS (Wang et al., [2019d](#bib.bib31)) performs personalized recommendation
    by converting the knowledge graph into a user-specific weighted graph, on which
    a graph neural network is applied to compute personalized item embeddings. The
    weights of edges on this new graph are computed by a trainable function $f(\mathbf{z}_{e})$
    that identifies important knowledge graph relationships for a given user. We refer
    this technique as graph translation.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Dynamicity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Knowledge graph could evolve over time dynamically, i.e, its nodes/edges may
    appear or disappear. For example, in the scenario of social recommendation, a
    user’s friend list may change from time to time. When a user adds a number of
    new friends with similar interests, the recommender system should update its recommendation
    strategy accordingly and reflect this change in its results.
  prefs: []
  type: TYPE_NORMAL
- en: To address this issue, Wu et al. (Song et al., [2019](#bib.bib24)) consider
    a dynamic feature graph setting. Specifically, for each user, they construct a
    graph where each node represents either this user or one of his/her friends. If
    user $u$ has $|N(u)|$ friends, then the total number of nodes in this graph is
    $|N(u)+1|$. The node feature of friends in this graph is kept unchanged but that
    of user $u$ is updated whenever $u$ consumes a new item. Moreover, to capture
    the context-dependent social influence, the authors propose a graph attention
    neural network, which utilizes an attention mechanism to guide the influence propogation
    in its aggregator. Each friend of user $u$ is assigned with an attention weight
    which measures its level of influence.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Datasets, Codes and Evaluations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1\. Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We summarize the state-of-the-art papers and list their publicly available
    datasets in Table [4](#S5.T4 "Table 4 ‣ 5.1\. Datasets ‣ 5\. Datasets, Codes and
    Evaluations ‣ Deep Learning on Knowledge Graph for Recommender System: A Survey")
    alphabetically. Generally speaking, we fit those datasets into 6 major scenarios:
    book, citation, movie, music, point of interest (POI) and social network. Here
    the general goal in each dataset is to let the recommender system infer users’
    preferred items based on users’ past history, for example, watched movies or read
    books. The size and complexity of the datasets are upon the problem settings in
    different papers.'
  prefs: []
  type: TYPE_NORMAL
- en: Table 4\. Summary of datasets under different scenarios
  prefs: []
  type: TYPE_NORMAL
- en: '| Scenario | Dataset | # Entities | # Connections |'
  prefs: []
  type: TYPE_TB
- en: '&#124; # Relation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Types &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Citation |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Book | [Amazon-books](http://jmcauley.ucsd.edu/data/amazon/) | 95,594 | 847,733
    | 39 | (Wang et al., [2019f](#bib.bib29)), (Zhao et al., [2019](#bib.bib47)) |'
  prefs: []
  type: TYPE_TB
- en: '| Book-crossing | 25,787 | 60,787 | 18 | (Wang et al., [2019d](#bib.bib31)),
     (Wang et al., [2019e](#bib.bib32)) |'
  prefs: []
  type: TYPE_TB
- en: '| Citation | S2 | - | - | - | (Xiong et al., [2017](#bib.bib41)) |'
  prefs: []
  type: TYPE_TB
- en: '| Movie | Douban | 46,423 | 331,315 | 5 | (Song et al., [2019](#bib.bib24)),
     (Zhang et al., [2019](#bib.bib46)) |'
  prefs: []
  type: TYPE_TB
- en: '| Flixter | 1,049,000 | 26,700,000 | - | (Zhang et al., [2019](#bib.bib46))
    |'
  prefs: []
  type: TYPE_TB
- en: '| MovieLens | 102,569 | 499,474 | 32 | (Palumbo et al., [2017](#bib.bib18)),
     (Sun et al., [2018b](#bib.bib26)),  (Wang et al., [2019d](#bib.bib31)),  (Zhang
    et al., [2019](#bib.bib46)) |'
  prefs: []
  type: TYPE_TB
- en: '| Music | Last-FM | 9,336 | 15,518 | 60 | (Wang et al., [2019d](#bib.bib31)),
     (Wang et al., [2019b](#bib.bib34)) |'
  prefs: []
  type: TYPE_TB
- en: '| POI | Delicious | 5,932 | 15,328 | - | (Wu et al., [2019b](#bib.bib38)) |'
  prefs: []
  type: TYPE_TB
- en: '| Yelp | 159,426 | 6,818,026 | 6 | (Song et al., [2019](#bib.bib24)),  (Sun
    et al., [2018b](#bib.bib26)) |'
  prefs: []
  type: TYPE_TB
- en: '| Dianping | 28,115 | 160,519 | 7 | (Wang et al., [2019d](#bib.bib31)) |'
  prefs: []
  type: TYPE_TB
- en: '| Social Network | Epinions | 175,000 | 508,000 | - | (Fan et al., [2019a](#bib.bib7)),
     (Wu et al., [2019c](#bib.bib37)) |'
  prefs: []
  type: TYPE_TB
- en: Table 5\. Summary of different evaluation metrics
  prefs: []
  type: TYPE_NORMAL
- en: '| Evaluation Metrics | Formula | Papers |'
  prefs: []
  type: TYPE_TB
- en: '| Metrics (@K) |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Precision | $\frac{TP}{TP+FP}$ | (Palumbo et al., [2017](#bib.bib18)),  (Sun
    et al., [2018b](#bib.bib26)),  (Wu et al., [2019c](#bib.bib37)),  (Xiong et al.,
    [2017](#bib.bib41)) |'
  prefs: []
  type: TYPE_TB
- en: '| Recall | $\frac{TP}{TP+FN}$ | (Li et al., [2019](#bib.bib16)),  (Song et al.,
    [2019](#bib.bib24)),  (Wang et al., [2019d](#bib.bib31)),  (Wang et al., [2019e](#bib.bib32)),
     (Wang et al., [2019b](#bib.bib34)),  (Xiong et al., [2017](#bib.bib41)) |'
  prefs: []
  type: TYPE_TB
- en: '| F1 Score | $2\cdot\frac{\textit{Precision}\cdot\textit{Recall}}{\textit{Precision}+\textit{Recall}}$
    | (Wang et al., [2018](#bib.bib30)),  (Wang et al., [2019e](#bib.bib32)) |'
  prefs: []
  type: TYPE_TB
- en: '| MRR | $\frac{1}{&#124;Q&#124;}\sum_{i=1}^{&#124;Q&#124;}\frac{1}{rank_{i}}$
    | (Sun et al., [2018b](#bib.bib26)),  (Xu et al., [2019](#bib.bib42)),  (Ying
    et al., [2018](#bib.bib43)),  (Zhao et al., [2019](#bib.bib47)) |'
  prefs: []
  type: TYPE_TB
- en: '| NDCG | $\textit{NDCG}=\frac{\textit{DCG}}{\textit{iDCG}}$ | (Li et al., [2019](#bib.bib16)),
     (Song et al., [2019](#bib.bib24)),  (Wang et al., [2019b](#bib.bib34)),  (Xiong
    et al., [2017](#bib.bib41)),  (Xu et al., [2019](#bib.bib42)) |'
  prefs: []
  type: TYPE_TB
- en: '| $\textit{DCG}=\sum_{i=1}^{n}\frac{2^{\textit{rel}_{i}}-1}{\log_{2}(i+1)}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| $\textit{iDCG}=\sum_{i=1}^{&#124;\textit{REL}_{p}&#124;}\frac{2^{\textit{rel}_{i}}-1}{\log_{2}(i+1)}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| RMSE | $\sqrt{\frac{1}{n}\sum_{i=1}^{n}(\hat{y}_{i}-y_{i})^{2}}$ | (Fan et al.,
    [2019a](#bib.bib7)),  (Wu et al., [2019c](#bib.bib37)),  (Zhang et al., [2019](#bib.bib46)),
    |'
  prefs: []
  type: TYPE_TB
- en: '| HR | $\sum_{i=1}^{&#124;U&#124;}I()$ | (Xu et al., [2019](#bib.bib42)),  (Ying
    et al., [2018](#bib.bib43)) |'
  prefs: []
  type: TYPE_TB
- en: '| MAE | $\frac{1}{n}\sum_{i=1}^{n}&#124;\hat{y}_{i}-y_{i}&#124;^{2}$ | (Fan
    et al., [2019a](#bib.bib7)),  (Wu et al., [2019c](#bib.bib37)) |'
  prefs: []
  type: TYPE_TB
- en: '| mAP | $\textit{AP}=\frac{1}{m}\sum_{k=1}^{K}\textit{Precision}@k\cdot rel(k)$
    | (Palumbo et al., [2017](#bib.bib18)) |'
  prefs: []
  type: TYPE_TB
- en: '| $MAP=\frac{1}{&#124;U&#124;}\sum_{i=1}^{&#124;U&#124;}AP$ |'
  prefs: []
  type: TYPE_TB
- en: '| AUC |  | (Fan et al., [2019c](#bib.bib6)),  (Wang et al., [2018](#bib.bib30)),
     (Wang et al., [2019d](#bib.bib31)),  (Wang et al., [2019e](#bib.bib32)),  (Wu
    et al., [2019c](#bib.bib37)),  (Zhao et al., [2019](#bib.bib47)) |'
  prefs: []
  type: TYPE_TB
- en: 6\. Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Although existing works have established a solid foundation for GNN-based Knowledge-Aware
    Deep Recommender (GNN-KADR) systems, it is still a young and promising research
    field. In this section, we suggest several prospective future research directions.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Scalability Trade-Off
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The scalability of existing GNN-KADR systems is gained at the price of sacrificing
    knowledge graph completeness. By sampling a fixed number of neighboring nodes,
    a node may lose its influential neighbors. By defining receptive field with meta-paths,
    the knowledge graph perceived by the model may be deprived of some important semantic
    information. Moreover, selecting and weighting meta-paths requires extensive prior
    knowledge and may be hard for some real-world applications. How to trade-off the
    scalability and the knowledge graph completeness is an interesting research direction.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. Dynamicity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Knowledge graphs are in nature dynamic in a way that nodes and edges may appear
    or disappear, and that node/edge inputs may change time by time (Wu et al., [2019a](#bib.bib39)).
    Moreover, the types of relations between nodes in a KG may also change along time
    in real-world scenarios. For example, in agent-initialized social e-commerce,
    a user may become a selling agent to his friends someday in the future. Although
    DGRec proposed by Wu et al. (Song et al., [2019](#bib.bib24)) has partially addressed
    the dynamicity of graph, few of the GNN-KADR systems consider accommodating their
    frameworks to cases where the knowledge graph contains dynamic spatial and semantic
    relations. New aggregators and updaters are needed to adapt to the dynamicity
    of knowledge graphs. According to our literature survey, we argue that this is
    still an open area for future research.
  prefs: []
  type: TYPE_NORMAL
- en: 6.3\. Explainability of Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared to traditional content or collaborate-filtering based recommender systems,
    explainability is particular important for GNN-KADR systems, because non-expert
    humans cannot intuitively determine the relevant context within a knowledge graph,
    for example, when identifying influential users in social network that are good
    candidates for selling agents in social e-commerce. In addition, Making explainable
    predictions to users allow them to understand the factors behind the network’s
    recommendations (i.e., why was this item/services recommended? (Seo et al., [2017](#bib.bib20);
    Xiao et al., [2017](#bib.bib40))), and is helpful to earn user’s trust on the
    system. It also helps the practitioner prob weights and activations to understand
    more about the model (Tay et al., [2018](#bib.bib27)).
  prefs: []
  type: TYPE_NORMAL
- en: There are several existing works focusing on the explainability of GNNs. GNNEXPLAINER (Ying
    et al., [2019](#bib.bib44)) proposed by Ying et al. is a model agnostic approach
    that provides interpretable explanations for predictions of any GNN-based model.
    Given an instance, it identifies a compact subgraph structure and a small subset
    of node features that have a crucial role in GNN’s prediction. Pope et al. (Pope
    et al., [2019](#bib.bib19)) extend three common explainability methods, i.e.,
    gradient-based saliency maps (Simonyan et al., [2014](#bib.bib22)), Class Activation
    Mapping (CAM) (Zhang et al., [2016](#bib.bib45)), and Excitation Backpropagation
    (EB) (Zhang et al., [2016](#bib.bib45)), from CNNs to GNNs to identify important
    aspects of the computation. However, these methods are designed for homogeneous
    graphs and do not take the heterogeneity of knowledge graph into account.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, some other methods, e.g., KPRN (Wang et al., [2019c](#bib.bib36)),
    EIUM (Huang et al., [2019](#bib.bib11)), RuleRec (Ma et al., [2019](#bib.bib17)),
    attempt to utilize the knowledge graph as an information source to make explainable
    recommendations. However, these methods usually sample paths from the knowledge
    graph and extract information from them via non-GNN algorithms such as RNN. Thus,
    compared to GNNs, the topological and semantic structure of knowledge graphs is
    corrupted in these cases, leading to unsatisfied performance.
  prefs: []
  type: TYPE_NORMAL
- en: To our best knowledge, how to build an explainable GNN-based knowledge-aware
    deep recommender system is still an open problem and is unexplored in current
    literature. We believe this is the next frontier.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4\. Fairness of Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Nowadays, recommender systems are used in a variety of domains affecting people’s
    lives. This has raised concerns about possible biases and discriminations that
    such systems might exacerbate. A typical example is news recommendation, where
    articles with biased stand may affect people’s vote decisions. There are two kinds
    of biases inherent in recommender systems (Farnadi et al., [2018](#bib.bib8)):
    observation bias and bias stemming from imbalanced data. Observation bias exists
    due to a feedback loop which causes the model only learn to predict recommendations
    similar to previous ones. In contrast, imbalance in data is caused when a systematic
    bias is present due to society, historical or other ambient biases. This bias
    is implicit in data so that recommender systems are usually unaware of them.'
  prefs: []
  type: TYPE_NORMAL
- en: Various methods have been proposed to build fair recommender systems. Alex et
    al. (Beutel et al., [2019](#bib.bib3)) introduce a pairwise recommendation fairness
    metric to evaluate algorithmic fairness concern in recommender systems, and offer
    a novel regularizer to encourage improve this metric during model training. Sahin
    et al. (Geyik et al., [2019](#bib.bib10)) propose complementary measures to quantify
    bias with respect to protected attributes and present an algorithm for computing
    fairness-aware re-ranking of results. Specifically, their algorithm seek to achieve
    a desired distribution of top ranked results with respect to one or more protected
    attributes. Jurek et al. (Leonhardt et al., [2018](#bib.bib15)) propose to quantify
    the user unfairness or discrimination caused by the post-processing module of
    recommender systems, which have the original goal of improving diversity in recommendation.
  prefs: []
  type: TYPE_NORMAL
- en: However, these algorithms are mainly designed for traditional recommender systems
    and cannot be used for GNN-KADR systems directly, since they do not consider any
    information or bias introduced by the knowledge graph. Therefore, building a fair
    GNN-KADR system is a promising but largely-unexplored area where more studies
    are expected.
  prefs: []
  type: TYPE_NORMAL
- en: 6.5\. Cross-Domain Recommendation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Besides mining a single knowledge graph, there is an increasing need of computing
    recommendations using data from multiple sources. For instance, a customer may
    be users of more than one social networks at the same time, e.g., Facebook and
    LinkedIn. Each of these social networks collect data regarding this customer and
    embed them into their own knowledge graphs. Thus, it is reasonable to leverage
    information from all these knowledge graphs to boost the recommendation performance.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are two significant gaps in the current research. The first gap
    is that existing research lacks exploration on effectively integrating information
    from multiple knowledge graph sources (Jiang et al., [2018](#bib.bib13)). Most
    of them attempt to build associations between two different knowledge graphs by
    connecting related entities (i.e., nodes), as in Wang et al. (Wang et al., [2017](#bib.bib35)).
    The group knowledge represented by a collection of nodes or edges of the same
    types, which may be critical to align multiple knowledge graphs, is ignored in
    these methods.
  prefs: []
  type: TYPE_NORMAL
- en: Secondly, most existing work provide cross-domain recommendations based on traditional
    techniques such as collaborative filtering (CF). Some other researches use spectral
    clustering algorithms to aggregate knowledge from graphs of different domains,
    but make strong assumptions that all graphs should be available simultaneously (Farseev
    et al., [2017](#bib.bib9)). Limited effort have been made to utilize GNNs for
    cross-domain recommendations. We believe this is a promising research field, since
    GNNs perform better than spectral clustering algorithms (Kipf and Welling, [2016](#bib.bib14)).
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this survey, we conduct a comprehensive overview of GNN-based Knowledge
    Aware Deep Recommender (GNN-KADR) systems. We provide a taxonomy for their core
    component, i.e., the graph embedding module, which is usually a GNN in the state-of-the-art
    frameworks. According to the taxonomy, we categorize the aggregators of these
    GNNs into three groups: relation-unaware aggregator, relation-aware subgraph aggregator
    and relation-aware attentive aggregator. We also divide their updaters into three
    categories: context-only updater, single-interaction updater, and multi-interaction
    updater. We provide a thorough review, comparisons and summarizations of these
    systems within or between categories. Then, we discuss the solution proposed by
    these frameworks to the common practical recommendation issues such as cold-start,
    scalability and so on. Datasets, open-source codes and benchmarks for GNN-KADR
    systems are also summarized. Finally, we suggest future research directions in
    this rapidly growing field.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Acilar and Arslan (2009) Ayse Merve Acilar and Ahmet Arslan. 2009. A collaborative
    filtering method based on artificial immune network. *Expert Syst. Appl.* 36,
    4 (2009), 8324–8332. [https://doi.org/10.1016/j.eswa.2008.10.029](https://doi.org/10.1016/j.eswa.2008.10.029)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beutel et al. (2019) Alex Beutel, Jilin Chen, Tulsee Doshi, Hai Qian, Li Wei,
    Yi Wu, Lukasz Heldt, Zhe Zhao, Lichan Hong, Ed H. Chi, and Cristos Goodrow. 2019.
    Fairness in Recommendation Ranking through Pairwise Comparisons. In *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining, KDD 2019, Anchorage, AK, USA, August 4-8, 2019*. 2212–2220. [https://doi.org/10.1145/3292500.3330745](https://doi.org/10.1145/3292500.3330745)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Covington et al. (2016) Paul Covington, Jay Adams, and Emre Sargin. 2016. Deep
    Neural Networks for YouTube Recommendations. In *Proceedings of the 10th ACM Conference
    on Recommender Systems, Boston, MA, USA, September 15-19, 2016*. 191–198. [https://doi.org/10.1145/2959100.2959190](https://doi.org/10.1145/2959100.2959190)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2019b) Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei
    Hu, Biyu Ma, and Yongliang Li. 2019b. Metapath-guided Heterogeneous Graph Neural
    Network for Intent Recommendation. In *Proceedings of the 25th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining*. 2478–2486.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2019c) Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi, Linmei
    Hu, Biyu Ma, and Yongliang Li. 2019c. Metapath-guided Heterogeneous Graph Neural
    Network for Intent Recommendation. In *Proceedings of the 25th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining, KDD 2019, Anchorage, AK, USA,
    August 4-8, 2019*. 2478–2486. [https://doi.org/10.1145/3292500.3330673](https://doi.org/10.1145/3292500.3330673)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2019a) Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang,
    and Dawei Yin. 2019a. Graph neural networks for social recommendation. In *The
    World Wide Web Conference*. 417–426.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Farnadi et al. (2018) Golnoosh Farnadi, Pigi Kouki, Spencer K. Thompson, Sriram
    Srinivasan, and Lise Getoor. 2018. A Fairness-aware Hybrid Recommender System.
    *CoRR* abs/1809.09030 (2018). arXiv:1809.09030 [http://arxiv.org/abs/1809.09030](http://arxiv.org/abs/1809.09030)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Farseev et al. (2017) Aleksandr Farseev, Ivan Samborskii, Andrey Filchenkov,
    and Tat-Seng Chua. 2017. Cross-domain recommendation via clustering on multi-layer
    graphs. In *Proceedings of the 40th International ACM SIGIR Conference on Research
    and Development in Information Retrieval*. 195–204.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Geyik et al. (2019) Sahin Cem Geyik, Stuart Ambler, and Krishnaram Kenthapadi.
    2019. Fairness-Aware Ranking in Search & Recommendation Systems with Application
    to LinkedIn Talent Search. In *Proceedings of the 25th ACM SIGKDD International
    Conference on Knowledge Discovery & Data Mining, KDD 2019, Anchorage, AK, USA,
    August 4-8, 2019*. 2221–2231. [https://doi.org/10.1145/3292500.3330691](https://doi.org/10.1145/3292500.3330691)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. (2019) Xiaowen Huang, Quan Fang, Shengsheng Qian, Jitao Sang, Yan
    Li, and Changsheng Xu. 2019. Explainable Interaction-driven User Modeling over
    Knowledge Graph for Sequential Recommendation. In *Proceedings of the 27th ACM
    International Conference on Multimedia, MM 2019, Nice, France, October 21-25,
    2019*. 548–556. [https://doi.org/10.1145/3343031.3350893](https://doi.org/10.1145/3343031.3350893)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jannach et al. (2010) Dietmar Jannach, Markus Zanker, Alexander Felfernig,
    and Gerhard Friedrich. 2010. *Recommender systems: an introduction*. Cambridge
    University Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang et al. (2018) Zhuoren Jiang, Yue Yin, Liangcai Gao, Yao Lu, and Xiaozhong
    Liu. 2018. Cross-language citation recommendation via hierarchical representation
    learning on heterogeneous graph. In *The 41st International ACM SIGIR Conference
    on Research & Development in Information Retrieval*. 635–644.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kipf and Welling (2016) Thomas N Kipf and Max Welling. 2016. Semi-supervised
    classification with graph convolutional networks. *arXiv preprint arXiv:1609.02907*
    (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leonhardt et al. (2018) Jurek Leonhardt, Avishek Anand, and Megha Khosla. 2018.
    User Fairness in Recommender Systems. In *Companion of the The Web Conference
    2018 on The Web Conference 2018, WWW 2018, Lyon , France, April 23-27, 2018*.
    101–102. [https://doi.org/10.1145/3184558.3186949](https://doi.org/10.1145/3184558.3186949)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2019) Mengmeng Li, Tian Gan, Meng Liu, Zhiyong Cheng, Jianhua Yin,
    and Liqiang Nie. 2019. Long-tail Hashtag Recommendation for Micro-videos with
    Graph Convolutional Network. In *Proceedings of the 28th ACM International Conference
    on Information and Knowledge Management*. 509–518.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2019) Weizhi Ma, Min Zhang, Yue Cao, Woojeong Jin, Chenyang Wang,
    Yiqun Liu, Shaoping Ma, and Xiang Ren. 2019. Jointly Learning Explainable Rules
    for Recommendation with Knowledge Graph. In *The World Wide Web Conference, WWW
    2019, San Francisco, CA, USA, May 13-17, 2019*. 1210–1221. [https://doi.org/10.1145/3308558.3313607](https://doi.org/10.1145/3308558.3313607)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Palumbo et al. (2017) Enrico Palumbo, Giuseppe Rizzo, and Raphaël Troncy. 2017.
    Entity2rec: Learning user-item relatedness from knowledge graphs for top-n item
    recommendation. In *Proceedings of the eleventh ACM conference on recommender
    systems*. 32–36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pope et al. (2019) Phillip E. Pope, Soheil Kolouri, Mohammad Rostami, Charles E.
    Martin, and Heiko Hoffmann. 2019. Explainability Methods for Graph Convolutional
    Neural Networks. In *IEEE Conference on Computer Vision and Pattern Recognition,
    CVPR 2019, Long Beach, CA, USA, June 16-20, 2019*. 10772–10781. [https://doi.org/10.1109/CVPR.2019.01103](https://doi.org/10.1109/CVPR.2019.01103)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seo et al. (2017) Sungyong Seo, Jing Huang, Hao Yang, and Yan Liu. 2017. Interpretable
    Convolutional Neural Networks with Dual Local and Global Attention for Review
    Rating Prediction. In *Proceedings of the Eleventh ACM Conference on Recommender
    Systems, RecSys 2017, Como, Italy, August 27-31, 2017*. 297–305. [https://doi.org/10.1145/3109859.3109890](https://doi.org/10.1145/3109859.3109890)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2017) Chuan Shi, Yitong Li, Jiawei Zhang, Yizhou Sun, and Philip S.
    Yu. 2017. A Survey of Heterogeneous Information Network Analysis. *IEEE Trans.
    Knowl. Data Eng.* 29, 1 (2017), 17–37. [https://doi.org/10.1109/TKDE.2016.2598561](https://doi.org/10.1109/TKDE.2016.2598561)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simonyan et al. (2014) Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman.
    2014. Deep Inside Convolutional Networks: Visualising Image Classification Models
    and Saliency Maps. In *2nd International Conference on Learning Representations,
    ICLR 2014, Banff, AB, Canada, April 14-16, 2014, Workshop Track Proceedings*.
    [http://arxiv.org/abs/1312.6034](http://arxiv.org/abs/1312.6034)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solsman (2018) Joan E. Solsman. 2018. Ever get caught in an unexpected hourlong
    YouTube binge? Thank YouTube AI for that. [https://www.cnet.com/news/youtube-ces-2018-neal-mohan/](https://www.cnet.com/news/youtube-ces-2018-neal-mohan/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2019) Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin,
    Ming Zhang, and Jian Tang. 2019. Session-Based Social Recommendation via Dynamic
    Graph Attention Networks. In *Proceedings of the Twelfth ACM International Conference
    on Web Search and Data Mining, WSDM 2019, Melbourne, VIC, Australia, February
    11-15, 2019*. 555–563. [https://doi.org/10.1145/3289600.3290989](https://doi.org/10.1145/3289600.3290989)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2018a) Zhu Sun, Jie Yang, Jie Zhang, Alessandro Bozzon, Long-Kai
    Huang, and Chi Xu. 2018a. Recurrent knowledge graph embedding for effective recommendation.
    In *Proceedings of the 12th ACM Conference on Recommender Systems, RecSys 2018,
    Vancouver, BC, Canada, October 2-7, 2018*. 297–305. [https://doi.org/10.1145/3240323.3240361](https://doi.org/10.1145/3240323.3240361)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2018b) Zhu Sun, Jie Yang, Jie Zhang, Alessandro Bozzon, Long-Kai
    Huang, and Chi Xu. 2018b. Recurrent knowledge graph embedding for effective recommendation.
    In *Proceedings of the 12th ACM Conference on Recommender Systems*. 297–305.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tay et al. (2018) Yi Tay, Luu Anh Tuan, and Siu Cheung Hui. 2018. Latent Relational
    Metric Learning via Memory-based Attention for Collaborative Ranking. In *Proceedings
    of the 2018 World Wide Web Conference on World Wide Web, WWW 2018, Lyon, France,
    April 23-27, 2018*. 729–739. [https://doi.org/10.1145/3178876.3186154](https://doi.org/10.1145/3178876.3186154)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Velickovic et al. (2018) Petar Velickovic, Guillem Cucurull, Arantxa Casanova,
    Adriana Romero, Pietro Liò, and Yoshua Bengio. 2018. Graph Attention Networks.
    In *6th International Conference on Learning Representations, ICLR 2018, Vancouver,
    BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings*. [https://openreview.net/forum?id=rJXMpikCZ](https://openreview.net/forum?id=rJXMpikCZ)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019f) Chengwei Wang, Tengfei Zhou, Chen Chen, Tianlei Hu, and
    Gang Chen. 2019f. CAMO: A Collaborative Ranking Method for Content Based Recommendation.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, Vol. 33. 5224–5231.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2018) Hongwei Wang, Fuzheng Zhang, Xing Xie, and Minyi Guo. 2018.
    DKN: Deep knowledge-aware network for news recommendation. In *Proceedings of
    the 2018 world wide web conference*. 1835–1844.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019d) Hongwei Wang, Fuzheng Zhang, Mengdi Zhang, Jure Leskovec,
    Miao Zhao, Wenjie Li, and Zhongyuan Wang. 2019d. Knowledge-aware graph neural
    networks with label smoothness regularization for recommender systems. In *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining*. 968–977.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019e) Hongwei Wang, Miao Zhao, Xing Xie, Wenjie Li, and Minyi
    Guo. 2019e. Knowledge Graph Convolutional Networks for Recommender Systems. In
    *The World Wide Web Conference, WWW 2019, San Francisco, CA, USA, May 13-17, 2019*.
    3307–3313. [https://doi.org/10.1145/3308558.3313417](https://doi.org/10.1145/3308558.3313417)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019a) Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng
    Chua. 2019a. KGAT: Knowledge Graph Attention Network for Recommendation. In *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining, KDD 2019, Anchorage, AK, USA, August 4-8, 2019*. 950–958. [https://doi.org/10.1145/3292500.3330989](https://doi.org/10.1145/3292500.3330989)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019b) Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng
    Chua. 2019b. Kgat: Knowledge graph attention network for recommendation. In *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining*. 950–958.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2017) Xiang Wang, Xiangnan He, Liqiang Nie, and Tat-Seng Chua.
    2017. Item silk road: Recommending items from information domains to social users.
    In *Proceedings of the 40th International ACM SIGIR conference on Research and
    Development in Information Retrieval*. 185–194.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019c) Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin
    Cao, and Tat-Seng Chua. 2019c. Explainable Reasoning over Knowledge Graphs for
    Recommendation. In *The Thirty-Third AAAI Conference on Artificial Intelligence,
    AAAI 2019, The Thirty-First Innovative Applications of Artificial Intelligence
    Conference, IAAI 2019, The Ninth AAAI Symposium on Educational Advances in Artificial
    Intelligence, EAAI 2019, Honolulu, Hawaii, USA, January 27 - February 1, 2019*.
    5329–5336. [https://doi.org/10.1609/aaai.v33i01.33015329](https://doi.org/10.1609/aaai.v33i01.33015329)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019c) Qitian Wu, Hengrui Zhang, Xiaofeng Gao, Peng He, Paul Weng,
    Han Gao, and Guihai Chen. 2019c. Dual graph attention networks for deep latent
    representation of multifaceted social effects in recommender systems. In *The
    World Wide Web Conference*. 2091–2102.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019b) Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and
    Tieniu Tan. 2019b. Session-based recommendation with graph neural networks. In
    *Proceedings of the AAAI Conference on Artificial Intelligence*, Vol. 33. 346–353.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2019a) Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi
    Zhang, and Philip S. Yu. 2019a. A Comprehensive Survey on Graph Neural Networks.
    *CoRR* abs/1901.00596 (2019). arXiv:1901.00596 [http://arxiv.org/abs/1901.00596](http://arxiv.org/abs/1901.00596)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xiao et al. (2017) Jun Xiao, Hao Ye, Xiangnan He, Hanwang Zhang, Fei Wu, and
    Tat-Seng Chua. 2017. Attentional Factorization Machines: Learning the Weight of
    Feature Interactions via Attention Networks. In *Proceedings of the Twenty-Sixth
    International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne,
    Australia, August 19-25, 2017*. 3119–3125. [https://doi.org/10.24963/ijcai.2017/435](https://doi.org/10.24963/ijcai.2017/435)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xiong et al. (2017) Chenyan Xiong, Russell Power, and Jamie Callan. 2017. Explicit
    semantic ranking for academic search via knowledge graph embedding. In *Proceedings
    of the 26th international conference on world wide web*. 1271–1279.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2019) Fengli Xu, Jianxun Lian, Zhenyu Han, Yong Li, Yujian Xu, and
    Xing Xie. 2019. Relation-Aware Graph Convolutional Networks for Agent-Initiated
    Social E-Commerce Recommendation. In *Proceedings of the 28th ACM International
    Conference on Information and Knowledge Management*. 529–538.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ying et al. (2018) Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L
    Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale
    recommender systems. In *Proceedings of the 24th ACM SIGKDD International Conference
    on Knowledge Discovery & Data Mining*. 974–983.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ying et al. (2019) Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik,
    and Jure Leskovec. 2019. GNNExplainer: Generating Explanations for Graph Neural
    Networks. In *Advances in Neural Information Processing Systems 32: Annual Conference
    on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14 December 2019,
    Vancouver, BC, Canada*. 9240–9251. [http://papers.nips.cc/paper/9123-gnnexplainer-generating-explanations-for-graph-neural-networks](http://papers.nips.cc/paper/9123-gnnexplainer-generating-explanations-for-graph-neural-networks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2016) Jianming Zhang, Zhe L. Lin, Jonathan Brandt, Xiaohui Shen,
    and Stan Sclaroff. 2016. Top-Down Neural Attention by Excitation Backprop. In
    *Computer Vision - ECCV 2016 - 14th European Conference, Amsterdam, The Netherlands,
    October 11-14, 2016, Proceedings, Part IV*. 543–559. [https://doi.org/10.1007/978-3-319-46493-0_33](https://doi.org/10.1007/978-3-319-46493-0_33)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2019) Jiani Zhang, Xingjian Shi, Shenglin Zhao, and Irwin King.
    2019. STAR-GCN: Stacked and Reconstructed Graph Convolutional Networks for Recommender
    Systems. In *Proceedings of the Twenty-Eighth International Joint Conference on
    Artificial Intelligence, IJCAI 2019, Macao, China, August 10-16, 2019*. 4264–4270.
    [https://doi.org/10.24963/ijcai.2019/592](https://doi.org/10.24963/ijcai.2019/592)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2019) Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang
    Qiu, and Xiaofei He. 2019. IntentGC: a Scalable Graph Convolution Framework Fusing
    Heterogeneous Information for Recommendation. In *Proceedings of the 25th ACM
    SIGKDD International Conference on Knowledge Discovery & Data Mining*. 2347–2357.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
