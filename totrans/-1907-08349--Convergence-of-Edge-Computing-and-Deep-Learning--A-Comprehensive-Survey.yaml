- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 20:05:54'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:05:54
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1907.08349] Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1907.08349] 边缘计算与深度学习的融合：全面调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1907.08349](https://ar5iv.labs.arxiv.org/html/1907.08349)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1907.08349](https://ar5iv.labs.arxiv.org/html/1907.08349)
- en: 'Convergence of Edge Computing and Deep Learning: A Comprehensive Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 边缘计算与深度学习的融合：全面调查
- en: 'Xiaofei Wang,  Yiwen Han,  Victor C.M. Leung,  Dusit Niyato,  Xueqiang Yan,
    Xu Chen Xiaofei Wang and Yiwen Han are with the College of Intelligence and Computing,
    Tianjin University, Tianjin, China. E-mails: xiaofeiwang@tju.edu.cn, hanyiwen@tju.edu.cn.V.
    C. M. Leung is with the College of Computer Science and Software Engineering,
    Shenzhen University, Shenzhen, China, and also with the Department of Electrical
    and Computer Engineering, the University of British Columbia, Vancouver, Canada.
    E-mail: vleung@ieee.org.Dusit Niyato is with School of Computer Science and Engineering,
    Nanyang Technological University, Singapore. E-mail: dniyato@ntu.edu.sg.Xueqiang
    Yan is with 2012 Lab of Huawei Technologies, Shenzhen, China. Email: yanxueqiang1@huawei.com.Xu
    Chen is with the School of Data and Computer Science, Sun Yat-sen University,
    Guangzhou, China. E-mail: chenxu35@mail.sysu.edu.cn.Corresponding author: Yiwen
    Han (hanyiwen@tju.edu.cn)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**Xiaofei Wang**、**Yiwen Han**、**Victor C.M. Leung**、**Dusit Niyato**、**Xueqiang
    Yan** 和 **Xu Chen** 均来自中国天津大学智能与计算学院。电子邮件：xiaofeiwang@tju.edu.cn、hanyiwen@tju.edu.cn。**V.
    C. M. Leung** 来自中国深圳大学计算机科学与软件工程学院，同时也在加拿大英属哥伦比亚大学电气与计算机工程系。电子邮件：vleung@ieee.org。**Dusit
    Niyato** 来自新加坡南洋理工大学计算机科学与工程学院。电子邮件：dniyato@ntu.edu.sg。**Xueqiang Yan** 在中国深圳华为技术有限公司2012实验室工作。电子邮件：yanxueqiang1@huawei.com。**Xu
    Chen** 来自中国中山大学数据与计算机学院。电子邮件：chenxu35@mail.sysu.edu.cn。通讯作者：**Yiwen Han** (hanyiwen@tju.edu.cn)'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Ubiquitous sensors and smart devices from factories and communities are generating
    massive amounts of data, and ever-increasing computing power is driving the core
    of computation and services from the cloud to the edge of the network. As an important
    enabler broadly changing people’s lives, from face recognition to ambitious smart
    factories and cities, developments of artificial intelligence (especially deep
    learning, DL) based applications and services are thriving. However, due to efficiency
    and latency issues, the current cloud computing service architecture hinders the
    vision of “providing artificial intelligence for every person and every organization
    at everywhere”. Thus, unleashing DL services using resources at the network edge
    near the data sources has emerged as a desirable solution. Therefore, edge intelligence,
    aiming to facilitate the deployment of DL services by edge computing, has received
    significant attention. In addition, DL, as the representative technique of artificial
    intelligence, can be integrated into edge computing frameworks to build intelligent
    edge for dynamic, adaptive edge maintenance and management. With regard to mutually
    beneficial edge intelligence and intelligent edge, this paper introduces and discusses:
    1) the application scenarios of both; 2) the practical implementation methods
    and enabling technologies, namely DL training and inference in the customized
    edge computing framework; 3) challenges and future trends of more pervasive and
    fine-grained intelligence. We believe that by consolidating information scattered
    across the communication, networking, and DL areas, this survey can help readers
    to understand the connections between enabling technologies while promoting further
    discussions on the fusion of edge intelligence and intelligent edge, i.e., Edge
    DL.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 工厂和社区中普遍存在的传感器和智能设备正在生成大量数据，而不断增长的计算能力将计算和服务的核心从云端推向网络边缘。作为一种重要的推动力，广泛地改变了人们的生活，从面部识别到雄心勃勃的智能工厂和城市，基于人工智能（尤其是深度学习DL）的应用和服务正在蓬勃发展。然而，由于效率和延迟问题，目前的云计算服务架构阻碍了“为每个人和每个组织在任何地方提供人工智能”的愿景。因此，利用网络边缘靠近数据源的资源来释放深度学习服务已成为一种理想的解决方案。因此，边缘智能旨在通过边缘计算促进深度学习服务的部署，受到了广泛关注。此外，作为人工智能的代表技术，深度学习可以集成到边缘计算框架中，以构建智能边缘，实现动态、适应性的边缘维护和管理。关于相互促进的边缘智能和智能边缘，本文介绍并讨论了：1）两者的应用场景；2）实际实施方法和使能技术，即在定制的边缘计算框架中的深度学习训练和推理；3）更普遍和更精细智能的挑战与未来趋势。我们相信，通过整合散布在通信、网络和深度学习领域的信息，本调查可以帮助读者理解使能技术之间的联系，同时促进对边缘智能和智能边缘融合的进一步讨论，即边缘深度学习（Edge
    DL）。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Edge computing, deep learning, wireless communication, computation offloading,
    artificial intelligence
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算，深度学习，无线通信，计算卸载，人工智能
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: 'With the proliferation of computing and storage devices, from server clusters
    in cloud data centers (the cloud) to personal computers and smartphones, further,
    to wearable and other Internet of Things (IoT) devices, we are now in an information-centric
    era in which computing is ubiquitous and computation services are overflowing
    from the cloud to the edge. According to a Cisco white paper [[1](#bib.bib1)],
    $50$ billion IoT devices will be connected to the Internet by 2020\. On the other
    hand, Cisco estimates that nearly $850$ Zettabytes (ZB) of data will be generated
    each year outside the cloud by 2021, while global data center traffic is only
    $20.6$ ZB [[2](#bib.bib2)]. This indicates that data sources for big data are
    also undergoing a transformation: from large-scale cloud data centers to an increasingly
    wide range of edge devices. However, existing cloud computing is gradually unable
    to manage these massively distributed computing power and analyze their data:
    1) a large number of computation tasks need to be delivered to the cloud for processing
    [[3](#bib.bib3)], which undoubtedly poses serious challenges on network capacity
    and the computing power of cloud computing infrastructures; 2) many new types
    of applications, e.g., cooperative autonomous driving, have strict or tight delay
    requirements that the cloud would have difficulty meeting since it may be far
    away from the users [[4](#bib.bib4)].'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着计算和存储设备的普及，从云数据中心的服务器集群（云端）到个人计算机和智能手机，再到可穿戴设备和其他物联网（IoT）设备，我们现在处于一个信息为中心的时代，其中计算无处不在，计算服务从云端溢出到边缘。根据思科的白皮书[[1](#bib.bib1)]，到2020年，将有$50$亿个IoT设备连接到互联网。另一方面，思科预计到2021年，每年在云端之外将产生近$850$泽字节（ZB）的数据，而全球数据中心流量仅为$20.6$
    ZB[[2](#bib.bib2)]。这表明大数据的数据来源也正在经历转型：从大规模的云数据中心到范围越来越广泛的边缘设备。然而，现有的云计算逐渐无法管理这些大规模分布的计算能力并分析其数据：1）大量计算任务需要传送到云端处理[[3](#bib.bib3)]，这无疑对网络容量和云计算基础设施的计算能力提出了严峻挑战；2）许多新类型的应用，例如协作自动驾驶，有严格或紧迫的延迟要求，云端可能因距离用户较远而难以满足这些要求[[4](#bib.bib4)]。
- en: 'Therefore, edge computing [[5](#bib.bib5), [6](#bib.bib6)] emerges as an attractive
    alternative, especially to host computation tasks as close as possible to the
    data sources and end users. Certainly, edge computing and cloud computing are
    not mutually exclusive [[7](#bib.bib7), [8](#bib.bib8)]. Instead, the edge complements
    and extends the cloud. Compared with cloud computing only, the main advantages
    of edge computing combined with cloud computing are three folds: 1) backbone network
    alleviation, distributed edge computing nodes can handle a large number of computation
    tasks without exchanging the corresponding data with the cloud, thus alleviating
    the traffic load of the network; 2) agile service response, services hosted at
    the edge can significantly reduce the delay of data transmissions and improve
    the response speed; 3) powerful cloud backup, the cloud can provide powerful processing
    capabilities and massive storage when the edge cannot afford.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，边缘计算[[5](#bib.bib5), [6](#bib.bib6)]作为一种有吸引力的替代方案出现，特别是为了将计算任务尽可能靠近数据源和最终用户。当然，边缘计算和云计算并不是相互排斥的[[7](#bib.bib7),
    [8](#bib.bib8)]。相反，边缘计算补充和扩展了云计算。与单独的云计算相比，边缘计算结合云计算的主要优势有三点：1）骨干网络缓解，分布式边缘计算节点可以处理大量计算任务而无需与云端交换相应的数据，从而缓解网络流量负载；2）灵活的服务响应，托管在边缘的服务可以显著减少数据传输延迟，提高响应速度；3）强大的云端备份，当边缘无法承担时，云端可以提供强大的处理能力和海量存储。
- en: As a typical and more widely used new form of applications [[9](#bib.bib9)],
    various deep learning-based intelligent services and applications have changed
    many aspects of people’s lives due to the great advantages of Deep Learning (DL)
    in the fields of Computer Vision (CV) and Natural Language Processing (NLP) [[10](#bib.bib10)].
    These achievements are not only derived from the evolution of DL but also inextricably
    linked to increasing data and computing power. Nevertheless, for a wider range
    of application scenarios, such as smart cities, Internet of Vehicles (IoVs), etc.,
    there are only a limited number of intelligent services offered due to the following
    factors.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 作为一种典型且更广泛使用的新型应用 [[9](#bib.bib9)]，各种基于深度学习的智能服务和应用由于深度学习（DL）在计算机视觉（CV）和自然语言处理（NLP）领域的巨大优势，已经改变了人们生活的许多方面
    [[10](#bib.bib10)]。这些成就不仅源于DL的演进，还与数据和计算能力的增加密不可分。然而，对于更广泛的应用场景，如智能城市、车联网（IoVs）等，由于以下因素，提供的智能服务数量仍然有限。
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Cost: training and inference of DL models in the cloud requires devices or
    users to transmit massive amounts of data to the cloud, thus consuming a large
    amount of network bandwidth;'
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 成本：在云中训练和推理深度学习（DL）模型需要设备或用户将大量数据传输到云端，从而消耗大量网络带宽；
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Latency: the delay to access cloud services is generally not guaranteed and
    might not be short enough to satisfy the requirements of many time-critical applications
    such as cooperative autonomous driving [[11](#bib.bib11)];'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 延迟：访问云服务的延迟通常无法保证，可能不足以满足许多时间关键型应用的要求，例如协同自动驾驶 [[11](#bib.bib11)];
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reliability: most cloud computing applications relies on wireless communications
    and backbone networks for connecting users to services, but for many industrial
    scenarios, intelligent services must be highly reliable, even when network connections
    are lost;'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可靠性：大多数云计算应用依赖于无线通信和骨干网络将用户与服务连接起来，但对于许多工业场景，智能服务必须具有很高的可靠性，即使在网络连接丢失的情况下也是如此；
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Privacy: the data required for DL might carry a lot of private information,
    and privacy issues are critical to areas such as smart home and cities.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 隐私：深度学习所需的数据可能包含大量私人信息，隐私问题在智能家居和智能城市等领域至关重要。
- en: 'TABLE I: List of Important Abbreviations in Alphabetical Order'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：按字母顺序列出的重要缩写列表
- en: '| Abbr. | Definition | Abbr. | Definition | Abbr. | Definition |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 缩写 | 定义 | 缩写 | 定义 | 缩写 | 定义 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| A-LSH | Adaptive Locality Sensitive Hashing | DVFS | Dynamic Voltage and
    Frequency Scaling | NLP | Natural Language Processing |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| A-LSH | 自适应局部敏感哈希 | DVFS | 动态电压和频率缩放 | NLP | 自然语言处理 |'
- en: '| AC | Actor-Critic | ECSP | Edge Computing Service Provider | NN | Neural
    Network |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| AC | Actor-Critic | ECSP | 边缘计算服务提供商 | NN | 神经网络 |'
- en: '| A3C | Asynchronous Advantage Actor-Critic | EEoI | Early Exit of Inference
    | NPU | Neural Processing Unit |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| A3C | 异步优势演员-评论员 | EEoI | 推理早期退出 | NPU | 神经处理单元 |'
- en: '| AE | Auto-Encoder | EH | Energy Harvesting | PPO | Proximate Policy Optimization
    |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| AE | 自编码器 | EH | 能量采集 | PPO | 近端策略优化 |'
- en: '| AI | Artificial Intelligence | FAP | Fog radio Access Point | QoE | Quality
    of Experience |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| AI | 人工智能 | FAP | 雾计算无线接入点 | QoE | 体验质量 |'
- en: '| APU | AI Processing Unit | FCNN | Fully Connected Neural Network | QoS |
    Quality of Service |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| APU | AI处理单元 | FCNN | 全连接神经网络 | QoS | 服务质量 |'
- en: '| AR | Augmented Reality | FL | Federated Learning | RAM | Random Access Memory
    |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| AR | 增强现实 | FL | 联邦学习 | RAM | 随机存取存储器 |'
- en: '| ASIC | Application-Specific Integrated Circuit | FPGA | Field Programmable
    Gate Array | RNN | Recurrent Neural Network |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| ASIC | 应用特定集成电路 | FPGA | 现场可编程门阵列 | RNN | 循环神经网络 |'
- en: '| BS | Base Station | FTP | Fused Tile Partitioning | RoI | Region-of-Interest
    |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| BS | 基站 | FTP | 融合瓷砖分区 | RoI | 关注区域 |'
- en: '| C-RAN | Cloud-Radio Access Networks | GAN | Generative Adversarial Network
    | RRH | Remote Radio Head |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| C-RAN | 云无线接入网络 | GAN | 生成对抗网络 | RRH | 遥控无线电头 |'
- en: '| CDN | Content Delivery Network | GNN | Graph Neural Network | RSU | Road-Side
    Unit |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| CDN | 内容分发网络 | GNN | 图神经网络 | RSU | 道路边单元 |'
- en: '| CNN | Convolutional Neural Network | IID | Independent and Identically Distributed
    | SDN | Software-Defined Network |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| CNN | 卷积神经网络 | IID | 独立同分布 | SDN | 软件定义网络 |'
- en: '| CV | Computer Vision | IoT | Internet of Things | SGD | Stochastic Gradient
    Descent |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| CV | 计算机视觉 | IoT | 物联网 | SGD | 随机梯度下降 |'
- en: '| DAG | Directed Acyclic Graph | IoV | Internet of Vehicles | SINR | Signal-to-Interference-plus-Noise
    Ratio |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| DAG | 有向无环图 | IoV | 车联网 | SINR | 信号干扰加噪声比 |'
- en: '| D2D | Device-to-Device | KD | Knowledge Distillation | SNPE | Snapdragon
    Neural Processing Engine |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| D2D | 设备到设备 | KD | 知识蒸馏 | SNPE | 骁龙神经处理引擎 |'
- en: '| DDoS | Distributed Denial of Service | $k$NN | $k$-Nearest Neighbor | TL
    | Transfer Learning |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| DDoS | 分布式拒绝服务 | $k$NN | $k$-最近邻 | TL | 迁移学习 |'
- en: '| DDPG | Deep Deterministic Policy Gradient | MAB | Multi-Armed Bandit | UE
    | User Equipment |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| DDPG | 深度确定性策略梯度 | MAB | 多臂赌博机 | UE | 用户设备 |'
- en: '| DL | Deep Learning | MEC | Mobile (Multi-access) Edge Computing | VM | Virtual
    Machine |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| DL | 深度学习 | MEC | 移动（多接入）边缘计算 | VM | 虚拟机 |'
- en: '| DNN | Deep Neural Networks | MDC | Micro Data Center | VNF | Virtual Network
    Function |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| DNN | 深度神经网络 | MDC | 微型数据中心 | VNF | 虚拟网络功能 |'
- en: '| DQL | Deep Q-Learning | MDP | Markov Decision Process | V2V | Vehicle-to-Vehicle
    |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| DQL | 深度Q学习 | MDP | 马尔可夫决策过程 | V2V | 车对车 |'
- en: '| DRL | Deep Reinforcement Learning | MLP | Multi-Layer Perceptron | WLAN |
    Wireless Local Area Network |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| DRL | 深度强化学习 | MLP | 多层感知器 | WLAN | 无线局域网 |'
- en: '| DSL | Domain-specific Language | NFV | Network Functions Virtualizatio |
    ZB | Zettabytes |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| DSL | 特定领域语言 | NFV | 网络功能虚拟化 | ZB | 硬盘字节 |'
- en: '![Refer to caption](img/b7244ece9821d1edd97eed575f5d6fb2.png)'
  id: totrans-49
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/b7244ece9821d1edd97eed575f5d6fb2.png)'
- en: 'Figure 1: Edge intelligence and intelligent edge.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：边缘智能与智能边缘。
- en: 'Since the edge is closer to users than the cloud, edge computing is expected
    to solve many of these issues. In fact, edge computing is gradually being combined
    with Artificial Intelligence (AI), benefiting each other in terms of the realization
    of edge intelligence and intelligent edge as depicted in Fig. [1](#S1.F1 "Figure
    1 ‣ I Introduction ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"). Edge intelligence and intelligent edge are not independent of each other.
    Edge intelligence is the goal, and the DL services in intelligent edge are also
    a part of edge intelligence. In turn, intelligent edge can provide higher service
    throughput and resource utilization for edge intelligence.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 由于边缘离用户比云更近，边缘计算有望解决这些问题。实际上，边缘计算正逐渐与人工智能（AI）结合，相互促进，如图[1](#S1.F1 "图1 ‣ I 介绍
    ‣ 边缘计算与深度学习的融合：综合调查")所示。边缘智能与智能边缘并不是彼此独立的。边缘智能是目标，而智能边缘中的深度学习服务也是边缘智能的一部分。反过来，智能边缘可以为边缘智能提供更高的服务吞吐量和资源利用率。
- en: 'To be specific, on one hand, edge intelligence is expected to push DL computations
    from the cloud to the edge as much as possible, thus enabling various distributed,
    low-latency and reliable intelligent services. As shown in Fig. [2](#S1.F2 "Figure
    2 ‣ I Introduction ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"), the advantages include: 1) DL services are deployed close to the requesting
    users, and the cloud only participates when additional processing is required
    [[12](#bib.bib12)], hence significantly reducing the latency and cost of sending
    data to the cloud for processing; 2) since the raw data required for DL services
    is stored locally on the edge or user devices themselves instead of the cloud,
    protection of user privacy is enhanced; 3) the hierarchical computing architecture
    provides more reliable DL computation; 4) with richer data and application scenarios,
    edge computing can promote the pervasive application of DL and realize the prospect
    of “providing AI for every person and every organization at everywhere” [[13](#bib.bib13)];
    5) diversified and valuable DL services can broaden the commercial value of edge
    computing and accelerate its deployment and growth.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 具体而言，一方面，边缘智能有望将深度学习计算从云端尽可能推向边缘，从而实现各种分布式、低延迟和可靠的智能服务。如图[2](#S1.F2 "图2 ‣ I
    介绍 ‣ 边缘计算与深度学习的融合：综合调查")所示，优势包括：1）深度学习服务部署在靠近请求用户的地方，云端仅在需要额外处理时参与[[12](#bib.bib12)]，从而显著减少将数据发送到云端进行处理的延迟和成本；2）由于深度学习服务所需的原始数据存储在边缘或用户设备上而不是云端，用户隐私保护得到增强；3）分层计算架构提供了更可靠的深度学习计算；4）凭借更丰富的数据和应用场景，边缘计算可以促进深度学习的广泛应用，实现“为每个人和每个组织在任何地方提供AI”的前景[[13](#bib.bib13)]；5）多样化和有价值的深度学习服务可以拓宽边缘计算的商业价值，加速其部署和增长。
- en: '![Refer to caption](img/ee121dd0618fa521bce6c6e722ec7817.png)'
  id: totrans-53
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ee121dd0618fa521bce6c6e722ec7817.png)'
- en: 'Figure 2: Capabilities comparison of cloud, on-device and edge intelligence.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：云、设备端和边缘智能的能力对比。
- en: 'On the other hand, intelligent edge aims to incorporate DL into the edge for
    dynamic, adaptive edge maintenance and management. With the development of communication
    technology, network access methods are becoming more diverse. At the same time,
    the edge computing infrastructure acts as an intermediate medium, making the connection
    between ubiquitous end devices and the cloud more reliable and persistent [[14](#bib.bib14)].
    Thus the end devices, edge, and cloud are gradually merging into a community of
    shared resources. However, the maintenance and management of such a large and
    complex overall architecture (community) involving wireless communication, networking,
    computing, storage, etc., is a major challenge [[15](#bib.bib15)]. Typical network
    optimization methodologies rely on fixed mathematical models; however, it is difficult
    to accurately model rapidly changing edge network environments and systems. DL
    is expected to deal with this problem: when faced with complex and cumbersome
    network information, DL can rely on its powerful learning and reasoning ability
    to extract valuable information from data and make adaptive decisions, achieving
    intelligent maintenance and management accordingly.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，智能边缘旨在将深度学习融入边缘，实现动态、自适应的边缘维护和管理。随着通信技术的发展，网络接入方式变得更加多样。同时，边缘计算基础设施充当了中介，使得无处不在的终端设备与云之间的连接更加可靠和持久[[14](#bib.bib14)]。因此，终端设备、边缘和云逐渐融合成一个共享资源的社区。然而，涉及无线通信、网络、计算、存储等的大规模复杂整体架构（社区）的维护和管理是一个重大挑战[[15](#bib.bib15)]。典型的网络优化方法依赖于固定的数学模型，但准确建模快速变化的边缘网络环境和系统是困难的。深度学习被期望解决这个问题：面对复杂繁琐的网络信息时，深度学习可以依靠其强大的学习和推理能力，从数据中提取有价值的信息，并做出自适应决策，从而实现智能维护和管理。
- en: 'Therefore, considering that edge intelligence and intelligent edge, i.e., Edge
    DL, together face some of the same challenges and practical issues in multiple
    aspects, we identify the following five technologies that are essential for Edge
    DL:'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，考虑到边缘智能和智能边缘，即边缘深度学习，共同面临多个方面的一些相同挑战和实际问题，我们确定了以下五项对边缘深度学习至关重要的技术：
- en: 1)
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 1)
- en: DL applications on Edge, technical frameworks for systematically organizing
    edge computing and DL to provide intelligent services;
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 边缘上的深度学习应用，系统化组织边缘计算和深度学习以提供智能服务的技术框架；
- en: 2)
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 2)
- en: DL inference in Edge, focusing on the practical deployment and inference of
    DL in the edge computing architecture to fulfill different requirements, such
    as accuracy and latency;
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 边缘深度学习推理，专注于边缘计算架构中深度学习的实际部署和推理，以满足不同的需求，如准确性和延迟；
- en: 3)
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 3)
- en: Edge computing for DL, which adapts the edge computing platform in terms of
    network architecture, hardware and software to support DL computation;
  id: totrans-62
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度学习的边缘计算，指的是在网络架构、硬件和软件方面调整边缘计算平台以支持深度学习计算；
- en: 4)
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 4)
- en: DL training at Edge, training DL models for edge intelligence at distributed
    edge devices under resource and privacy constraints;
  id: totrans-64
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 边缘深度学习训练，在资源和隐私约束下，在分布式边缘设备上训练边缘智能的深度学习模型；
- en: 5)
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 5)
- en: DL for optimizing Edge, application of DL for maintaining and managing different
    functions of edge computing networks (systems), e.g., edge caching [[16](#bib.bib16)],
    computation offloading[[17](#bib.bib17)].
  id: totrans-66
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用于优化边缘的深度学习（DL），即应用深度学习来维护和管理边缘计算网络（系统）的不同功能，例如边缘缓存[[16](#bib.bib16)]、计算卸载[[17](#bib.bib17)]。
- en: 'As illustrated in Fig. [3](#S1.F3 "Figure 3 ‣ I Introduction ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey"), “DL applications
    on Edge” and “DL for optimizing edge” correspond to the theoretical goals of edge
    intelligence and intelligent edge, respectively. To support them, various DL models
    should be trained by intensive computation at first. In this case, for the related
    works leveraging edge computing resources to train various DL models, we classify
    them as “DL training at Edge”. Second, to enable and speed up Edge DL services,
    we focus on a variety of techniques supporting the efficient inference of DL models
    in edge computing frameworks and networks, called “DL inference in Edge”. At last,
    we classify all techniques, which adapts edge computing frameworks and networks
    to better serve Edge DL, as “Edge computing for DL”.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [3](#S1.F3 "Figure 3 ‣ I Introduction ‣ Convergence of Edge Computing and
    Deep Learning: A Comprehensive Survey") 所示，“边缘上的 DL 应用”和“用于优化边缘的 DL”分别对应边缘智能和智能边缘的理论目标。为了支持这些目标，首先需要通过密集的计算训练各种
    DL 模型。在这种情况下，对于利用边缘计算资源训练各种 DL 模型的相关工作，我们将其归类为“边缘上的 DL 训练”。其次，为了实现并加速边缘 DL 服务，我们关注支持
    DL 模型在边缘计算框架和网络中高效推理的各种技术，称为“边缘中的 DL 推理”。最后，我们将所有调整边缘计算框架和网络以更好地服务于边缘 DL 的技术归类为“用于
    DL 的边缘计算”。'
- en: '![Refer to caption](img/94240842679c6f9cb97a4d8b299a33c5.png)'
  id: totrans-68
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/94240842679c6f9cb97a4d8b299a33c5.png)'
- en: 'Figure 3: Landscape of Edge DL according to the proposed taxonomy.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 根据提出的分类法，边缘 DL 的全景。'
- en: 'To the best of our knowledge, existing articles that are most related to our
    work include [[18](#bib.bib18), [19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)].
    Different from our more extensive coverage of Edge DL, [[18](#bib.bib18)] is focussed
    on the use of machine learning (rather than DL) in edge intelligence for wireless
    communication perspective, i.e., training machine learning at the network edge
    to improve wireless communication. Besides, discussions about DL inference and
    training are the main contribution of [[19](#bib.bib19), [20](#bib.bib20), [21](#bib.bib21)].
    Different from these works, this survey focuses on these respects: 1) comprehensively
    consider deployment issues of DL by edge computing, spanning networking, communication,
    and computation; 2) investigate the holistic technical spectrum about the convergence
    of DL and edge computing in terms of the five enablers; 3) point out that DL and
    edge computing are beneficial to each other and considering only deploying DL
    on the edge is incomplete.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 据我们所知，现有与我们工作最相关的文章包括 [[18](#bib.bib18)、[19](#bib.bib19)、[20](#bib.bib20)、[21](#bib.bib21)]。不同于我们对边缘
    DL 更广泛的覆盖，[[18](#bib.bib18)] 专注于机器学习（而非 DL）在无线通信视角下的边缘智能应用，即在网络边缘训练机器学习以提高无线通信。此外，关于
    DL 推理和训练的讨论是 [[19](#bib.bib19)、[20](#bib.bib20)、[21](#bib.bib21)] 的主要贡献。不同于这些工作，本综述关注以下方面：1)
    全面考虑边缘计算下 DL 的部署问题，涵盖网络、通信和计算；2) 研究 DL 与边缘计算的融合在五个促进因素方面的整体技术谱；3) 指出 DL 和边缘计算相互促进，仅在边缘上部署
    DL 是不完整的。
- en: 'This paper is organized as follows (as abstracted in Fig. [4](#S1.F4 "Figure
    4 ‣ I Introduction ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")). We have given the background and motivations of this survey in the
    current section. Next, we provide some fundamentals related to edge computing
    and DL in Section [II](#S2 "II Fundamentals of Edge Computing ‣ Convergence of
    Edge Computing and Deep Learning: A Comprehensive Survey") and Section [III](#S3
    "III Fundamentals of Deep Learning ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"), respectively. The following sections introduce the five
    enabling technologies, i.e., DL applications on edge (Section [IV](#S4 "IV Deep
    Learning Applications on Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")), DL inference in edge (Section [V](#S5 "V Deep Learning
    Inference in Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")), edge computing for DL services (Section [VI](#S6 "VI Edge Computing
    for Deep Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")), DL training at edge (Section [VII](#S7 "VII Deep Learning Training
    at Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")),
    and DL for optimizing edge (Section [VIII](#S8 "VIII Deep Learning for Optimizing
    Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")).
    Finally, we present lessons learned and discuss open challenges in Section [IX](#S9
    "IX Lessons Learned and Open Challenges ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey") and conclude this paper in Section [X](#S10
    "X Conclusions ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"). All related acronyms are listed in Table [I](#S1.T1 "TABLE I ‣ I Introduction
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey").'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '本文的组织结构如下（如图 [4](#S1.F4 "Figure 4 ‣ I Introduction ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey") 所示）。我们在当前章节中介绍了本次调查的背景和动机。接下来，我们在第
    [II](#S2 "II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and
    Deep Learning: A Comprehensive Survey") 节和第 [III](#S3 "III Fundamentals of Deep
    Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")
    节中分别提供了与边缘计算和深度学习相关的一些基础知识。接下来的章节介绍了五项关键技术，即边缘上的深度学习应用（第 [IV](#S4 "IV Deep Learning
    Applications on Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey") 节）、边缘中的深度学习推理（第 [V](#S5 "V Deep Learning Inference in Edge ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey") 节）、用于深度学习服务的边缘计算（第
    [VI](#S6 "VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey") 节）、边缘上的深度学习训练（第 [VII](#S7 "VII Deep
    Learning Training at Edge ‣ Convergence of Edge Computing and Deep Learning: A
    Comprehensive Survey") 节）以及用于优化边缘的深度学习（第 [VIII](#S8 "VIII Deep Learning for Optimizing
    Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")
    节）。最后，我们在第 [IX](#S9 "IX Lessons Learned and Open Challenges ‣ Convergence of Edge
    Computing and Deep Learning: A Comprehensive Survey") 节总结了所学到的经验和讨论了开放挑战，并在第 [X](#S10
    "X Conclusions ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey") 节中结束本文。所有相关的缩略词列在表 [I](#S1.T1 "TABLE I ‣ I Introduction ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey") 中。'
- en: '![Refer to caption](img/e5f9dbf7935687dc7c4d4e95bba49483.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/e5f9dbf7935687dc7c4d4e95bba49483.png)'
- en: 'Figure 4: Conceptual relationships of edge intelligence and intelligent edge.'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：边缘智能与智能边缘的概念关系。
- en: II Fundamentals of Edge Computing
  id: totrans-74
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 边缘计算基础知识
- en: Edge computing has become an important solution to break the bottleneck of emerging
    technologies by virtue of its advantages of reducing data transmission, improving
    service latency and easing cloud computing pressure. The edge computing architecture
    will become an important complement to the cloud, even replacing the role of the
    cloud in some scenarios. More detailed information can be found in [[22](#bib.bib22),
    [8](#bib.bib8), [23](#bib.bib23)].
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算凭借其减少数据传输、提高服务延迟和减轻云计算压力的优势，已成为突破新兴技术瓶颈的重要解决方案。边缘计算架构将成为云计算的重要补充，甚至在某些场景中取代云计算的角色。更多详细信息请参见
    [[22](#bib.bib22), [8](#bib.bib8), [23](#bib.bib23)]。
- en: II-A Paradigms of Edge Computing
  id: totrans-76
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 边缘计算的范式
- en: In the development of edge computing, there have been various new technologies
    aimed at working at the edge of the network, with the same principles but different
    focuses, such as Cloudlet [[24](#bib.bib24)], Micro Data Centers (MDCs) [[25](#bib.bib25)],
    Fog Computing [[26](#bib.bib26)][[27](#bib.bib27)] and Mobile Edge Computing [[5](#bib.bib5)]
    (viz., Multi-access Edge Computing [[28](#bib.bib28)] now). However, the edge
    computing community has not yet reached a consensus on the standardized definitions,
    architectures and protocols of edge computing [[23](#bib.bib23)]. We use a common
    term “edge computing” for this set of emerging technologies. In this section,
    different edge computing concepts are introduced and differentiated.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 在边缘计算的发展中，出现了各种新技术，旨在在网络边缘工作，虽然原则相同但重点不同，如云集群 [[24](#bib.bib24)]、微数据中心（MDCs）
    [[25](#bib.bib25)]、雾计算 [[26](#bib.bib26)][[27](#bib.bib27)] 和移动边缘计算 [[5](#bib.bib5)]（即现在的多接入边缘计算
    [[28](#bib.bib28)]）。然而，边缘计算社区尚未就边缘计算的标准定义、架构和协议达成共识 [[23](#bib.bib23)]。我们使用“边缘计算”这一通用术语来指代这一系列新兴技术。在本节中，将介绍并区分不同的边缘计算概念。
- en: II-A1 Cloudlet and Micro Data Centers
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A1 云集群和微数据中心
- en: Cloudlet is a network architecture element that combines mobile computing and
    cloud computing. It represents the middle layer of the three-tier architecture,
    i.e., mobile devices, the micro cloud, and the cloud. Its highlights are efforts
    to 1) define the system and create algorithms that support low-latency edge cloud
    computing, and 2) implement related functionality in open source code as an extension
    of Open Stack cloud management software [[24](#bib.bib24)]. Similar to Cloudlets,
    MDCs [[25](#bib.bib25)] are also designed to complement the cloud. The idea is
    to package all the computing, storage, and networking equipment needed to run
    customer applications in one enclosure, as a stand-alone secure computing environment,
    for applications that require lower latency or end devices with limited battery
    life or computing abilities.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 云集群是一个结合移动计算和云计算的网络架构元素。它代表三层架构的中间层，即移动设备、微云和云。它的亮点在于 1) 定义系统并创建支持低延迟边缘云计算的算法，以及
    2) 将相关功能实现为开源代码，作为 Open Stack 云管理软件的扩展 [[24](#bib.bib24)]。类似于云集群，MDCs [[25](#bib.bib25)]
    也旨在补充云计算。其理念是将所有运行客户应用所需的计算、存储和网络设备打包在一个封装中，作为一个独立的安全计算环境，用于需要较低延迟或具有有限电池寿命或计算能力的终端设备的应用。
- en: II-A2 Fog Computing
  id: totrans-80
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A2 雾计算
- en: One of the highlights of fog computing is that it assumes a fully distributed
    multi-tier cloud computing architecture with billions of devices and large-scale
    cloud data centers [[26](#bib.bib26)][[27](#bib.bib27)]. While cloud and fog paradigms
    share a similar set of services, such as computing, storage, and networking, the
    deployment of fog is targeted to specific geographic areas. In addition, fog is
    designed for applications that require real-time responding with less latency,
    such as interactive and IoT applications. Unlike Cloudlet, MDCs and MEC, fog computing
    is more focused on IoTs.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 雾计算的一个亮点是它假设一个完全分布式的多层云计算架构，包含数十亿个设备和大规模的云数据中心 [[26](#bib.bib26)][[27](#bib.bib27)]。尽管云计算和雾计算范式共享类似的服务，如计算、存储和网络，雾计算的部署则针对特定的地理区域。此外，雾计算设计用于需要实时响应且延迟较低的应用程序，如交互式和物联网应用。与云集群、MDCs
    和 MEC 不同，雾计算更加关注物联网。
- en: II-A3 Mobile (Multi-access) Edge Computing (MEC)
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A3 移动（多接入）边缘计算（MEC）
- en: Mobile Edge Computing places computing capabilities and service environments
    at the edge of cellular networks [[5](#bib.bib5)]. It is designed to provide lower
    latency, context and location awareness, and higher bandwidth. Deploying edge
    servers on cellular Base Stations (BSs) allows users to deploy new applications
    and services flexibly and quickly. The European Telecommunications Standards Institute
    (ETSI) further extends the terminology of MEC from Mobile Edge Computing to Multi-access
    Edge Computing by accommodating more wireless communication technologies, such
    as Wi-Fi [[28](#bib.bib28)].
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 移动边缘计算将计算能力和服务环境置于蜂窝网络的边缘 [[5](#bib.bib5)]。它旨在提供较低的延迟、上下文和位置感知，以及更高的带宽。在蜂窝基站（BSs）上部署边缘服务器允许用户灵活、快速地部署新的应用程序和服务。欧洲电信标准协会（ETSI）进一步将
    MEC 的术语从移动边缘计算扩展到多接入边缘计算，以适应更多的无线通信技术，如 Wi-Fi [[28](#bib.bib28)]。
- en: II-A4 Definition of Edge Computing Terminologies
  id: totrans-84
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A4 边缘计算术语定义
- en: 'The definition and division of edge devices are ambiguous in most literature
    (the boundary between edge nodes and end devices is not clear). For this reason,
    as depicted in Fig. [1](#S1.F1 "Figure 1 ‣ I Introduction ‣ Convergence of Edge
    Computing and Deep Learning: A Comprehensive Survey"), we further divide common
    edge devices into end devices and edge nodes: the “end devices” (end level) is
    used to refer to mobile edge devices (including smartphones, smart vehicles, etc.)
    and various IoT devices, and the “edge nodes” (edge level) include Cloudlets,
    Road-Side Units (RSUs), Fog nodes, edge servers, MEC servers and so on, namely
    servers deployed at the edge of the network.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '边缘设备的定义和划分在大多数文献中模糊（边缘节点和终端设备之间的界限不清）。因此，如图 [1](#S1.F1 "Figure 1 ‣ I Introduction
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey") 所示，我们进一步将常见的边缘设备划分为终端设备和边缘节点：“终端设备”（终端层）指移动边缘设备（包括智能手机、智能车辆等）和各种IoT设备，“边缘节点”（边缘层）包括Cloudlets、路边单元（RSUs）、雾节点、边缘服务器、MEC服务器等，即部署在网络边缘的服务器。'
- en: '![Refer to caption](img/7efad9cd67c75ec67150e8045d3ccfae.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/7efad9cd67c75ec67150e8045d3ccfae.png)'
- en: 'Figure 5: A sketch of collaborative end-edge-cloud DL computing.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：协作的端-边缘-云深度学习计算的示意图。
- en: '![Refer to caption](img/386b118464424e2d426e4d46c6aaf389.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/386b118464424e2d426e4d46c6aaf389.png)'
- en: 'Figure 6: Computation collaboration is becoming more important for DL with
    respect to both training and inference.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：在训练和推理方面，计算协作对深度学习变得越来越重要。
- en: 'TABLE II: Summary of Edge Computing AI Hardwares and Systems'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 表II：边缘计算AI硬件和系统汇总
- en: '|  | Owner | Production | Feature |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|  | 供应商 | 产品 | 特性 |'
- en: '| Integrated Commodities | Microsoft | Data Box Edge [[29](#bib.bib29)] | Competitive
    in data preprocessing and data transmission |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 集成商品 | 微软 | Data Box Edge [[29](#bib.bib29)] | 在数据预处理和数据传输方面具有竞争力 |'
- en: '| Intel |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 英特尔 |'
- en: '&#124; Movidius Neural &#124;'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Movidius神经网络 &#124;'
- en: '&#124; Compute Stick [[30](#bib.bib30)] &#124;'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Compute Stick [[30](#bib.bib30)] &#124;'
- en: '| Prototype on any platform with plug-and-play simplicity |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 在任何平台上进行原型设计，具有即插即用的简便性 |'
- en: '| NVIDIA | Jetson [[31](#bib.bib31)] | Easy-to-use platforms that runs in as
    little as 5 Watts |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | Jetson [[31](#bib.bib31)] | 易于使用的平台，运行功耗低至5瓦 |'
- en: '|  | Huawei | Atlas Series [[32](#bib.bib32)] | An all-scenario AI infrastructure
    solution that bridges “device, edge, and cloud” |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|  | 华为 | Atlas系列 [[32](#bib.bib32)] | 一种全场景的AI基础设施解决方案，连接“设备、边缘和云” |'
- en: '| AI Hardware for Edge Computing | Qualcomm | Snapdragon 8 Series [[33](#bib.bib33)]
    | Powerful adaptability to major DL frameworks |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 边缘计算AI硬件 | 高通 | Snapdragon 8系列 [[33](#bib.bib33)] | 对主要深度学习框架具有强大的适应性 |'
- en: '| HiSilicon | Kirin 600/900 Series [[34](#bib.bib34)] | Independent NPU for
    DL computation |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| HiSilicon | Kirin 600/900系列 [[34](#bib.bib34)] | 独立的NPU用于深度学习计算 |'
- en: '| HiSilicon | Ascend Series [[35](#bib.bib35)] |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| HiSilicon | Ascend系列 [[35](#bib.bib35)] |'
- en: '&#124; Full coverage – from the ultimate low energy consumption scenario &#124;'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 全面覆盖 – 从极低能耗场景 &#124;'
- en: '&#124; to high computing power scenario &#124;'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 高计算能力场景 &#124;'
- en: '|'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| MediaTek | Helio P60 [[36](#bib.bib36)] | Simultaneous use of GPU and NPU
    to accelerate neural network computing |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 联发科 | Helio P60 [[36](#bib.bib36)] | GPU和NPU的同时使用以加速神经网络计算 |'
- en: '| NVIDIA | Turing GPUs [[37](#bib.bib37)] | Powerful capabilities and compatibility
    but with high energy consumption |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | Turing GPUs [[37](#bib.bib37)] | 强大的能力和兼容性但能耗较高 |'
- en: '| Google | TPU [[38](#bib.bib38)] | Stable in terms of performance and power
    consumption |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 谷歌 | TPU [[38](#bib.bib38)] | 性能和功耗方面稳定 |'
- en: '| Intel | Xeon D-2100 [[39](#bib.bib39)] | Optimized for power- and space-constrained
    cloud-edge solutions |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 英特尔 | Xeon D-2100 [[39](#bib.bib39)] | 针对电源和空间受限的云边解决方案进行了优化 |'
- en: '|  | Samsung | Exynos 9820 [[40](#bib.bib40)] | Mobile NPU for accelerating
    AI tasks |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|  | 三星 | Exynos 9820 [[40](#bib.bib40)] | 用于加速AI任务的移动NPU |'
- en: '| Edge Computing Frameworks | Huawei | KubeEdge [[41](#bib.bib41)] | Native
    support for edge-cloud collaboration |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 边缘计算框架 | 华为 | KubeEdge [[41](#bib.bib41)] | 原生支持边缘-云协作 |'
- en: '| Baidu | OpenEdge [[42](#bib.bib42)] | Computing framework shielding and application
    production simplification |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 百度 | OpenEdge [[42](#bib.bib42)] | 计算框架屏蔽和应用程序生产简化 |'
- en: '| Microsoft | Azure IoT Edge [[43](#bib.bib43)] | Remotely edge management
    with zero-touch device provisioning |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 微软 | Azure IoT Edge [[43](#bib.bib43)] | 通过零触摸设备配置进行远程边缘管理 |'
- en: '| Linux Foundation | EdgeX [[44](#bib.bib44)] | IoT edge across the industrial
    and enterprise use cases |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Linux Foundation | EdgeX [[44](#bib.bib44)] | 适用于工业和企业用例的IoT边缘计算 |'
- en: '| Linux Foundation | Akraino Edge Stack [[45](#bib.bib45)] | Integrated distributed
    cloud edge platform |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Linux Foundation | Akraino Edge Stack [[45](#bib.bib45)] | 集成分布式云边缘平台 |'
- en: '| NVIDIA | NVIDIA EGX [[46](#bib.bib46)] | Real-time perception, understanding,
    and processing at the edge |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| NVIDIA | NVIDIA EGX [[46](#bib.bib46)] | 实时感知、理解和处理边缘数据 |'
- en: '|  | Amazon | AWS IoT Greengrass [[47](#bib.bib47)] | Tolerance to edge devices
    even with intermittent connectivity |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | Amazon | AWS IoT Greengrass [[47](#bib.bib47)] | 即使在间歇性连接的边缘设备上也具有容错性
    |'
- en: '|  | Google | Google Cloud IoT [[48](#bib.bib48)] | Compatible with Google
    AI products, such as TensorFlow Lite and Edge TPU |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | Google | Google Cloud IoT [[48](#bib.bib48)] | 兼容 Google AI 产品，如 TensorFlow
    Lite 和 Edge TPU |'
- en: II-A5 Collaborative End-Edge-Cloud Computing
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A5 协作的端-边缘-云计算
- en: 'While cloud computing is created for processing computation-intensive tasks,
    such as DL, it cannot guarantee the delay requirements throughout the whole process
    from data generation to transmission to execution. Moreover, independent processing
    on the end or edge devices is limited by their computing capability, power consumption,
    and cost bottleneck. Therefore, collaborative end-edge-cloud computing for DL
    [[12](#bib.bib12)], abstracted in Fig. [5](#S2.F5 "Figure 5 ‣ II-A4 Definition
    of Edge Computing Terminologies ‣ II-A Paradigms of Edge Computing ‣ II Fundamentals
    of Edge Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"), is emerging as an important trend as depicted in Fig. [6](#S2.F6 "Figure
    6 ‣ II-A4 Definition of Edge Computing Terminologies ‣ II-A Paradigms of Edge
    Computing ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey"). In this novel computing paradigm,
    computation tasks with lower computational intensities, generated by end devices,
    can be executed directly at the end devices or offloaded to the edge, thus avoiding
    the delay caused by sending data to the cloud. For a computation-intensive task,
    it will be reasonably segmented and dispatched separately to the end, edge and
    cloud for execution, reducing the execution delay of the task while ensuring the
    accuracy of the results [[12](#bib.bib12), [49](#bib.bib49), [50](#bib.bib50)].
    The focus of this collaborative paradigm is not only the successful completion
    of tasks but also achieving the optimal balance of equipment energy consumption,
    server loads, transmission and execution delays.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然云计算是为了处理计算密集型任务而创建的，例如深度学习，但它不能保证从数据生成到传输再到执行的整个过程中都满足延迟要求。此外，终端或边缘设备上的独立处理受到其计算能力、功耗和成本瓶颈的限制。因此，协作的端-边缘-云计算用于深度学习
    [[12](#bib.bib12)]，如图 [5](#S2.F5 "Figure 5 ‣ II-A4 Definition of Edge Computing
    Terminologies ‣ II-A Paradigms of Edge Computing ‣ II Fundamentals of Edge Computing
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey") 所示，正在成为一个重要趋势，如图
    [6](#S2.F6 "Figure 6 ‣ II-A4 Definition of Edge Computing Terminologies ‣ II-A
    Paradigms of Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey") 所示。在这一新的计算范式中，由终端设备生成的计算任务强度较低，可以直接在终端设备上执行或卸载到边缘，从而避免因将数据发送到云而导致的延迟。对于计算密集型任务，它将被合理分段并分别调度到终端、边缘和云进行执行，以减少任务的执行延迟，同时确保结果的准确性
    [[12](#bib.bib12), [49](#bib.bib49), [50](#bib.bib50)]。这一协作范式的重点不仅是任务的成功完成，还在于实现设备能耗、服务器负载、传输和执行延迟的最佳平衡。'
- en: II-B Hardware for Edge Computing
  id: totrans-120
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 边缘计算的硬件
- en: 'In this section, we discuss potential enabling hardware of edge intelligence,
    i.e., customized AI chips and commodities for both end devices and edge nodes.
    Besides, edge-cloud systems for DL are introduced as well (listed in Table [II](#S2.T2
    "TABLE II ‣ II-A4 Definition of Edge Computing Terminologies ‣ II-A Paradigms
    of Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")).'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们讨论了边缘智能的潜在使能硬件，即定制的 AI 芯片以及面向终端设备和边缘节点的商品。此外，还介绍了用于深度学习的边缘云系统（见表格 [II](#S2.T2
    "TABLE II ‣ II-A4 Definition of Edge Computing Terminologies ‣ II-A Paradigms
    of Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")）。'
- en: II-B1 AI Hardware for Edge Computing
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 边缘计算的 AI 硬件
- en: 'Emerged edge AI hardware can be classified into three categories according
    to their technical architecture: 1) Graphics Processing Unit (GPU)-based hardware,
    which tend to have good compatibility and performance, but generally consume more
    energy, e.g., NVIDIA’ GPUs based on Turing architecture [[37](#bib.bib37)]; 2)
    Field Programmable Gate Array (FPGA)-based hardware [[51](#bib.bib51), [52](#bib.bib52)],
    which are energy-saving and require less computation resources, but with worse
    compatibility and limited programming capability compared to GPUs; 3) Application
    Specific Integrated Circuit (ASIC)-based hardware, such as Google’s TPU [[38](#bib.bib38)]
    and HiSilicon’s Ascend series [[35](#bib.bib35)], usually with a custom design
    that is more stable in terms of performance and power consumption.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 新兴的边缘 AI 硬件可以根据其技术架构分为三类：1）基于图形处理单元（GPU）的硬件，通常具有良好的兼容性和性能，但一般消耗更多的能量，例如基于图灵架构的
    NVIDIA GPU [[37](#bib.bib37)]；2）基于现场可编程门阵列（FPGA）的硬件 [[51](#bib.bib51), [52](#bib.bib52)]，这些硬件节能且计算资源需求较少，但与
    GPU 相比，兼容性较差且编程能力有限；3）基于应用特定集成电路（ASIC）的硬件，如 Google 的 TPU [[38](#bib.bib38)] 和海思的
    Ascend 系列 [[35](#bib.bib35)]，通常具有定制设计，在性能和功耗方面更为稳定。
- en: As smartphones represent the most widely-deployed edge devices, chips for smartphones
    have undergone rapid developments, and their capabilities have been extended to
    the acceleration of AI computing. To name a few, Qualcomm first applies AI hardware
    acceleration [[33](#bib.bib33)] in Snapdragon and releases Snapdragon Neural Processing
    Engine (SNPE) SDK [[53](#bib.bib53)], which supports almost all major DL frameworks.
    Compared to Qualcomm, HiSilicon’s 600 series and 900 series chips [[34](#bib.bib34)]
    do not depend on GPUs. Instead, they incorporate an additional Neural Processing
    Unit (NPU) to achieve fast calculation of vectors and matrices, which greatly
    improves the efficiency of DL. Compared to HiSilicon and Qualcomm, MediaTek’s
    Helio P60 not only uses GPUs but also introduces an AI Processing Unit (APU) to
    further accelerate neural network computing [[36](#bib.bib36)]. Performance comparison
    of most commodity chips with respect to DL can be found in [[54](#bib.bib54)],
    and more customized chips of edge devices will be discussed in detail later.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 由于智能手机是最广泛部署的边缘设备，智能手机芯片经历了快速的发展，其能力也扩展到了 AI 计算加速。例如，高通首次在 Snapdragon 中应用 AI
    硬件加速 [[33](#bib.bib33)]，并发布了支持几乎所有主要深度学习框架的 Snapdragon Neural Processing Engine
    (SNPE) SDK [[53](#bib.bib53)]。相比之下，海思的 600 系列和 900 系列芯片 [[34](#bib.bib34)] 不依赖
    GPU，而是集成了额外的神经处理单元（NPU），以实现快速的向量和矩阵计算，从而大大提高了深度学习的效率。与海思和高通相比，联发科的 Helio P60 不仅使用
    GPU，还引入了 AI 处理单元（APU）以进一步加速神经网络计算 [[36](#bib.bib36)]。有关大多数商品芯片在深度学习方面的性能比较可以参见
    [[54](#bib.bib54)]，更多关于边缘设备的定制芯片将在后续详细讨论。
- en: '![Refer to caption](img/cbb2e2a3365b76a6a308b9babf99a5a8.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/cbb2e2a3365b76a6a308b9babf99a5a8.png)'
- en: 'Figure 7: Basic structures and functions of typical DNNs and DL.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：典型 DNN 和深度学习的基本结构与功能。
- en: II-B2 Integrated Commodities Potentially for Edge Nodes
  id: totrans-127
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 可能用于边缘节点的集成商品
- en: Edge nodes are expected to have computing and caching capabilities and to provide
    high-quality network connection and computing services near end devices. Compared
    to most end devices, edge nodes have more powerful computing capability to process
    tasks. On the other side, edge nodes can respond to end devices more quickly than
    the cloud. Therefore, by deploying edge nodes to perform the computation task,
    the task processing can be accelerated while ensuring accuracy. In addition, edge
    nodes also have the ability to cache, which can improve the response time by caching
    popular contents. For example, practical solutions including Huawei’ Atlas modules
    [[32](#bib.bib32)] and Microsoft’s Data Box Edge [[29](#bib.bib29)] can carry
    out preliminary DL inference and then transfer to the cloud for further improvement.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘节点预计具备计算和缓存能力，并提供高质量的网络连接和接近终端设备的计算服务。与大多数终端设备相比，边缘节点具有更强的计算能力来处理任务。另一方面，边缘节点能够比云计算更快地响应终端设备。因此，通过部署边缘节点来执行计算任务，可以加速任务处理，同时确保准确性。此外，边缘节点还具备缓存能力，可以通过缓存热门内容来改善响应时间。例如，实际解决方案包括华为的
    Atlas 模块 [[32](#bib.bib32)] 和微软的数据盒边缘 [[29](#bib.bib29)]，可以进行初步的深度学习推理，然后转移到云端进行进一步优化。
- en: II-B3 Edge Computing Frameworks
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B3 边缘计算框架
- en: Solutions for edge computing systems are blooming. For DL services with complex
    configuration and intensive resource requirements, edge computing systems with
    advanced and excellent microservice architecture are the future development direction.
    Currently, Kubernetes is as a mainstream container-centric system for the deployment,
    maintenance, and scaling of applications in cloud computing [[55](#bib.bib55)].
    Based on Kubernetes, Huawei develops its edge computing solution “KubeEdge” [[41](#bib.bib41)]
    for networking, application deployment and metadata synchronization between the
    cloud and the edge (also supported in Akraino Edge Stack [[45](#bib.bib45)]).
    “OpenEdge” [[42](#bib.bib42)] focus on shielding computing framework and simplifying
    application production. For IoT, Azure IoT Edge [[43](#bib.bib43)] and EdgeX [[44](#bib.bib44)]
    are devised for delivering cloud intelligence to the edge by deploying and running
    AI on cross-platform IoT devices.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算系统的解决方案正在蓬勃发展。对于具有复杂配置和大量资源需求的 DL 服务，具有先进和优秀的微服务架构的边缘计算系统是未来的发展方向。目前，Kubernetes
    是用于在云计算中部署、维护和扩展应用程序的主流容器中心系统 [[55](#bib.bib55)]. 华为基于 Kubernetes 开发了其边缘计算解决方案
    "KubeEdge" [[41](#bib.bib41)]，用于云和边缘之间的网络、应用部署和元数据同步（也支持于 Akraino Edge Stack [[45](#bib.bib45)]
    中）。"OpenEdge" [[42](#bib.bib42)] 专注于屏蔽计算框架和简化应用程序生产。对于物联网，Azure IoT Edge [[43](#bib.bib43)]
    和 EdgeX [[44](#bib.bib44)] 是用于通过部署和运行 AI 在跨平台物联网设备上向边缘提供云智能的解决方案。
- en: 'TABLE III: Potential DL libraries for edge computing'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 III：边缘计算的潜在 DL 库
- en: '| Library |  CNTK [[56](#bib.bib56)]  |  Chainer [[57](#bib.bib57)]  |  TensorFlow
    [[58](#bib.bib58)]  |  DL4J [[59](#bib.bib59)]  |  TensorFlow Lite [[60](#bib.bib60)]  |  MXNet
    [[61](#bib.bib61)]  |  (Py)Torch [[62](#bib.bib62)]  |  CoreML [[63](#bib.bib63)]  |  SNPE
    [[53](#bib.bib53)]  |  NCNN [[64](#bib.bib64)]  |  MNN [[65](#bib.bib65)]  |  Paddle-Mobile
    [[66](#bib.bib66)]  |  MACE [[67](#bib.bib67)]  |  FANN [[68](#bib.bib68)]  |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 库 |  CNTK [[56](#bib.bib56)]  |  Chainer [[57](#bib.bib57)]  |  TensorFlow
    [[58](#bib.bib58)]  |  DL4J [[59](#bib.bib59)]  |  TensorFlow Lite [[60](#bib.bib60)]  |  MXNet
    [[61](#bib.bib61)]  |  (Py)Torch [[62](#bib.bib62)]  |  CoreML [[63](#bib.bib63)]  |  SNPE
    [[53](#bib.bib53)]  |  NCNN [[64](#bib.bib64)]  |  MNN [[65](#bib.bib65)]  |  Paddle-Mobile
    [[66](#bib.bib66)]  |  MACE [[67](#bib.bib67)]  |  FANN [[68](#bib.bib68)]  |'
- en: '| Owner |  Microsoft  |  Preferred Networks  |  Google  |  Skymind  |  Google  |  Apache
    Incubator  |  Facebook  |  Apple  |  Qualcomm  |  Tencent  |  Alibaba  |  Baidu  |  XiaoMi  |  ETH
    Zürich  |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 负责人 |  微软公司  |  Preferred Networks  |  谷歌  |  Skymind  |  谷歌  |  Apache 孵化器
    |  Facebook  |  苹果  |  Qualcomm  |  腾讯  |  阿里巴巴  |  百度  |  小米  |  ETH Zurich  |'
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Edge &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 边缘 &#124;'
- en: '&#124; Support &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 支持 &#124;'
- en: '| $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ |'
- en: '| Android | $\times$ | $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ |
    ✓ | ✓ | ✓ | ✓ | $\times$ |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| Android | $\times$ | $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ |
    ✓ | ✓ | ✓ | ✓ | $\times$ |'
- en: '| iOS | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | ✓ | ✓ | ✓ |
    $\times$ | ✓ | ✓ | ✓ | ✓ | $\times$ |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| iOS | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | ✓ | ✓ | ✓ |
    $\times$ | ✓ | ✓ | ✓ | ✓ | $\times$ |'
- en: '| Arm | $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ | ✓ | ✓ | ✓
    | ✓ | ✓ |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| Arm | $\times$ | $\times$ | ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ | ✓ | ✓ | ✓
    | ✓ | ✓ |'
- en: '| FPGA | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ |
    ✓ | $\times$ | $\times$ | $\times$ | $\times$ | ✓ | $\times$ | $\times$ |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ |
    ✓ | $\times$ | $\times$ | $\times$ | $\times$ | ✓ | $\times$ | $\times$ |'
- en: '| DSP | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | ✓ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| DSP | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | ✓ | $\times$ | $\times$ | $\times$ | $\times$ | $\times$ |'
- en: '| GPU | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | $\times$ | $\times$ |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| GPU | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | $\times$ | $\times$ |'
- en: '|'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Mobile &#124;'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 移动 &#124;'
- en: '&#124; GPU &#124;'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPU &#124;'
- en: '| $\times$ | $\times$ | $\times$ | $\times$ | ✓ | $\times$ | $\times$ | ✓ |
    ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| $\times$ | $\times$ | $\times$ | $\times$ | ✓ | $\times$ | $\times$ | ✓ |
    ✓ | ✓ | ✓ | ✓ | ✓ | $\times$ |'
- en: '|'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Training &#124;'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练 &#124;'
- en: '&#124; Support &#124;'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 支持 &#124;'
- en: '| ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ | ✓ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | $\times$ | ✓ |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| ✓ | ✓ | ✓ | ✓ | $\times$ | ✓ | ✓ | $\times$ | $\times$ | $\times$ | $\times$
    | $\times$ | $\times$ | ✓ |'
- en: II-C Virtualizing the Edge
  id: totrans-152
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 虚拟化边缘
- en: 'The requirements of virtualization technology for integrating edge computing
    and DL reflect in the following aspects: 1) The resource of edge computing is
    limited. Edge computing cannot provide that resources for DL services as the cloud
    does. Virtualization technologies should maximize resource utilization under the
    constraints of limited resources; 2) DL services rely heavily on complex software
    libraries. The versions and dependencies of these software libraries should be
    taken into account carefully. Therefore, virtualization catering to Edge DL services
    should be able to isolate different services. Specifically, the upgrade, shutdown,
    crash, and high resource consumption of a single service should not affect other
    services; 3) The service response speed is critical for Edge DL. Edge DL requires
    not only the computing power of edge devices but also the agile service response
    that the edge computing architecture can provide.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟化技术在集成边缘计算和深度学习（DL）方面的要求体现在以下几个方面：1）边缘计算的资源有限。边缘计算无法像云计算那样提供资源给DL服务。虚拟化技术应在资源有限的约束下最大化资源利用；2）DL服务严重依赖复杂的软件库。这些软件库的版本和依赖关系需要仔细考虑。因此，针对边缘DL服务的虚拟化应能够隔离不同的服务。具体来说，单个服务的升级、关闭、崩溃和高资源消耗不应影响其他服务；3）服务响应速度对边缘DL至关重要。边缘DL不仅需要边缘设备的计算能力，还需要边缘计算架构能够提供的敏捷服务响应。
- en: '![Refer to caption](img/58adcebbbb3d87a29f6c4d572fca047d.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/58adcebbbb3d87a29f6c4d572fca047d.png)'
- en: 'Figure 8: Virtualizing edge computing infrastructure and networks.'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：虚拟化边缘计算基础设施和网络。
- en: 'The combination of edge computing and DL to form high-performance Edge DL services
    requires the coordinated integration of computing, networking and communication
    resources, as depicted in Fig. [8](#S2.F8 "Figure 8 ‣ II-C Virtualizing the Edge
    ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"). Specifically, both the computation virtualization and
    the integration of network virtualization, and management technologies are necessary.
    In this section, we discuss potential virtualization technologies for the edge.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘计算和DL的结合形成高性能的边缘DL服务，需要计算、网络和通信资源的协调整合，如图[8](#S2.F8 "图 8 ‣ II-C 虚拟化边缘 ‣ II
    边缘计算基础 ‣ 边缘计算与深度学习的融合：全面调查")所示。具体来说，计算虚拟化以及网络虚拟化和管理技术的整合都是必要的。在这一部分，我们讨论了边缘的潜在虚拟化技术。
- en: II-C1 Virtualization Techniques
  id: totrans-157
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C1 虚拟化技术
- en: 'Currently, there are two main virtualization strategies: Virtual Machine (VM)
    and container. In general, VM is better at isolating while container provides
    easier deployment of repetitive tasks [[69](#bib.bib69)]. With VM virtualization
    at operating system level, a VM hypervisor splits a physical server into one or
    multiple VMs, and can easily manage each VM to execute tasks in isolation. Besides,
    the VM hypervisor can allocate and use idle computing resources more efficiently
    by creating a scalable system that includes multiple independent virtual computing
    devices.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，主要有两种虚拟化策略：虚拟机（VM）和容器。一般来说，VM在隔离方面更为出色，而容器则提供了更便捷的重复任务部署[[69](#bib.bib69)]。通过操作系统级别的VM虚拟化，VM虚拟机监控程序将物理服务器拆分成一个或多个VM，并能够轻松管理每个VM以在隔离的环境中执行任务。此外，VM虚拟机监控程序可以通过创建一个包含多个独立虚拟计算设备的可扩展系统，更高效地分配和利用闲置的计算资源。
- en: In contrast to VM, container virtualization is a more flexible tool for packaging,
    delivering, and orchestrating software infrastructure services and applications.
    Container virtualization for edge computing can effectively reduce the workload
    execution time with high performance and storage requirements, and can also deploy
    a large number of services in a scalable and straightforward fashion [[70](#bib.bib70)].
    A container consists of a single file that includes an application and execution
    environment with all dependencies, which makes it enable efficient service handoff
    to cope with user mobility [[71](#bib.bib71)]. Owning to that the execution of
    applications in the container does not depend on additional virtualization layers
    as in VM virtualization, the processor consumption and the amount of memory required
    to execute the application are significantly reduced.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 与虚拟机（VM）相比，容器虚拟化是打包、交付和编排软件基础设施服务和应用程序的更灵活工具。边缘计算的容器虚拟化可以有效地减少工作负载执行时间，满足高性能和存储要求，并且可以以可扩展和直接的方式部署大量服务[[70](#bib.bib70)]。容器由一个包含应用程序及其所有依赖项的执行环境的单一文件组成，这使得它能够有效地进行服务切换以应对用户的移动性[[71](#bib.bib71)]。由于容器中的应用程序执行不依赖于如虚拟机虚拟化中的额外虚拟化层，因此处理器消耗和执行应用程序所需的内存显著减少。
- en: II-C2 Network Virtualization
  id: totrans-160
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C2 网络虚拟化
- en: 'Traditional networking functions, combined with specific hardware, is not flexible
    enough to manage edge computing networks in an on-demand fashion. In order to
    consolidate network device functions into industry-standard servers, switches
    and storage, Network Functions Virtualization (NFV) enables Virtual Network Functions
    (VNFs) to run in software, by separating network functions and services from dedicated
    network hardware. Further, Edge DL services typically require high bandwidth,
    low latency, and dynamic network configuration, while Software-defined Networking
    (SDN) allows rapid deployment of services, network programmability and multi-tenancy
    support, through three key innovations [[72](#bib.bib72)]: 1) Decoupling of control
    planes and data planes; 2) Centralized and programmable control planes; 3) Standardized
    application programming interface. With these advantages, it supports a highly
    customized network strategy that is well suited for the high bandwidth, dynamic
    nature of Edge DL services.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的网络功能结合特定硬件，无法以按需方式灵活管理边缘计算网络。为了将网络设备功能整合到行业标准的服务器、交换机和存储中，网络功能虚拟化（NFV）通过将网络功能和服务从专用网络硬件中分离，使虚拟网络功能（VNF）能够在软件中运行。此外，边缘深度学习服务通常需要高带宽、低延迟和动态网络配置，而软件定义网络（SDN）通过三个关键创新[[72](#bib.bib72)]：1)
    控制平面和数据平面的解耦；2) 集中和可编程的控制平面；3) 标准化的应用编程接口，允许快速部署服务、网络编程和多租户支持。凭借这些优势，它支持一种高度定制的网络策略，非常适合边缘深度学习服务的高带宽和动态特性。
- en: Network virtualization and edge computing benefit each other. On the one hand,
    NFV/SDN can enhance the interoperability of edge computing infrastructure. For
    example, with the support of NFV/SDN, edge nodes can be efficiently orchestrated
    and integrated with cloud data centers [[73](#bib.bib73)]. On the other hand,
    both VNFs and Edge DL services can be hosted on a lightweight NFV framework (deployed
    on the edge) [[74](#bib.bib74)], thus reusing the infrastructure and infrastructure
    management of NFV to the largest extent possible [[75](#bib.bib75)].
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 网络虚拟化和边缘计算相互受益。一方面，NFV/SDN可以增强边缘计算基础设施的互操作性。例如，借助NFV/SDN的支持，边缘节点可以高效地编排并与云数据中心集成[[73](#bib.bib73)]。另一方面，VNF和边缘深度学习服务都可以托管在轻量级NFV框架（部署在边缘）[[74](#bib.bib74)]上，从而在最大程度上重用NFV的基础设施和基础设施管理[[75](#bib.bib75)]。
- en: II-C3 Network Slicing
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-C3 网络切片
- en: 'Network slicing is a form of agile and virtual network architecture, a high-level
    abstraction of the network that allows multiple network instances to be created
    on top of a common shared physical infrastructure, each of which optimized for
    specific services. With increasingly diverse service and QoS requirements, network
    slicing, implemented by NFV/SDN, is naturally compatible with distributed paradigms
    of edge computing. To meet these, network slicing can be coordinated with joint
    optimization of computing and communication resources in edge computing networks
    [[76](#bib.bib76)]. Fig. [8](#S2.F8 "Figure 8 ‣ II-C Virtualizing the Edge ‣ II
    Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey") depicts an example of network slicing based on edge virtualization.
    In order to implement service customization in network slicing, virtualization
    technologies and SDN must be together to support tight coordination of resource
    allocation and service provision on edge nodes while allowing flexible service
    control. With network slicing, customized and optimized resources can be provided
    for Edge DL services, which can help reduce latency caused by access networks
    and support dense access to these services [[77](#bib.bib77)].'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '网络切片是一种敏捷和虚拟的网络架构，是网络的高级抽象，允许在共享的物理基础设施上创建多个网络实例，每个实例针对特定服务进行优化。随着服务和 QoS 要求的日益多样化，通过
    NFV/SDN 实现的网络切片自然与边缘计算的分布式范式兼容。为满足这些要求，网络切片可以与边缘计算网络中计算和通信资源的联合优化进行协调[[76](#bib.bib76)]。图[8](#S2.F8
    "Figure 8 ‣ II-C Virtualizing the Edge ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")展示了基于边缘虚拟化的网络切片示例。为了在网络切片中实现服务定制，虚拟化技术和
    SDN 必须共同支持边缘节点上资源分配和服务提供的紧密协调，同时允许灵活的服务控制。通过网络切片，可以为边缘 DL 服务提供定制和优化的资源，这有助于减少由接入网络引起的延迟，并支持对这些服务的密集访问[[77](#bib.bib77)]。'
- en: III Fundamentals of Deep Learning
  id: totrans-165
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 深度学习基础
- en: With respect to CV, NLP, and AI, DL is adopted in a myriad of applications and
    corroborates its superior performance [[78](#bib.bib78)]. Currently, a large number
    of GPUs, TPUs, or FPGAs are required to be deployed in the cloud to process DL
    service requests. Nonetheless, the edge computing architecture, on account of
    it covers a large number of distributed edge devices, can be utilized to better
    serve DL. Certainly, edge devices typically have limited computing power or power
    consumption compared to the cloud. Therefore, the combination of DL and edge computing
    is not straightforward and requires a comprehensive understanding of DL models
    and edge computing features for design and deployment. In this section, we compendiously
    introduce DL and related technical terms, paving the way for discussing the integration
    of DL and edge computing (more details can be found in [[79](#bib.bib79)]).
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 关于 CV、NLP 和 AI，DL 被广泛应用，并证实了其卓越的性能[[78](#bib.bib78)]。目前，需要大量的 GPUs、TPUs 或 FPGAs
    部署在云端以处理 DL 服务请求。然而，由于边缘计算架构覆盖了大量分布式边缘设备，它可以更好地服务于 DL。确实，边缘设备通常相比云端具有有限的计算能力或功耗。因此，DL
    与边缘计算的结合并非简单，需要全面理解 DL 模型和边缘计算特性的设计和部署。在本节中，我们简要介绍了 DL 及相关技术术语，为讨论 DL 与边缘计算的整合铺平了道路（更多细节见[[79](#bib.bib79)]）。
- en: III-A Neural Networks in Deep Learning
  id: totrans-167
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 深度学习中的神经网络
- en: DL models consist of various types of Deep Neural Networks (DNNs) [[79](#bib.bib79)].
    Fundamentals of DNNs in terms of basic structures and functions are introduced
    as follows.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: DL 模型由各种类型的深度神经网络（DNNs）组成[[79](#bib.bib79)]。DNN 的基本结构和功能如下所示。
- en: III-A1 Fully Connected Neural Network (FCNN)
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 全连接神经网络（FCNN）
- en: 'The output of each layer of FCNN, i.e., Multi-Layer Perceptron (MLP), is fed
    forward to the next layer, as in Fig. [7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware
    for Edge Computing ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge
    Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")(a).
    Between contiguous FCNN layers, the output of a neuron (cell), either the input
    or hidden cell, is directly passed to and activated by neurons belong to the next
    layer [[80](#bib.bib80)]. FCNN can be used for feature extraction and function
    approximation, however with high complexity, modest performance, and slow convergence.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 'FCNN 的每一层的输出，即多层感知器 (MLP)，被前馈到下一层，如图 [7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware
    for Edge Computing ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge
    Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")(a)
    所示。在连续的 FCNN 层之间，神经元（单元）的输出，无论是输入单元还是隐藏单元，都被直接传递到下一层的神经元并被激活 [[80](#bib.bib80)]。FCNN
    可以用于特征提取和函数逼近，但具有高复杂性、适中性能和缓慢收敛。'
- en: III-A2 Auto-Encoder (AE)
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 自编码器 (AE)
- en: 'AE, as in Fig. [7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware for Edge Computing
    ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")(b), is actually
    a stack of two NNs that replicate input to its output in an unsupervised learning
    style. The first NN learns the representative characteristics of the input (encoding).
    The second NN takes these features as input and restores the approximation of
    the original input at the match input output cell, used to converge on the identity
    function from input to output, as the final output (decoding). Since AEs are able
    to learn the low-dimensional useful features of input data to recover input data,
    it is often used to classify and store high-dimensional data [[81](#bib.bib81)].'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware
    for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")(b) 所示，AE 实际上是两个神经网络的堆叠，它们以无监督学习的方式将输入复制到输出。第一个神经网络学习输入的代表性特征（编码）。第二个神经网络以这些特征作为输入，并在匹配输入输出单元中恢复原始输入的近似值，用于从输入到输出的身份函数的收敛，作为最终输出（解码）。由于
    AE 能够学习输入数据的低维有用特征以恢复输入数据，因此它通常用于分类和存储高维数据 [[81](#bib.bib81)]。'
- en: III-A3 Convolutional Neural Network (CNN)
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A3 卷积神经网络 (CNN)
- en: 'By employing pooling operations and a set of distinct moving filters, CNNs
    seize correlations between adjacent data pieces, and then generate a successively
    higher level abstraction of the input data, as in Fig. [7](#S2.F7 "Figure 7 ‣
    II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣ II Fundamentals
    of Edge Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")(c). Compared to FCNNs, CNNs can extract features while reducing the model
    complexity, which mitigates the risk of overfitting [[82](#bib.bib82)]. These
    characteristics make CNNs achieve remarkable performance in image processing and
    also useful in processing structural data similar to images.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '通过使用池化操作和一组不同的移动滤波器，CNN 捕捉到相邻数据片段之间的关联，然后生成输入数据的逐层高层抽象，如图 [7](#S2.F7 "Figure
    7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣
    II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(c) 所示。与 FCNNs 相比，CNNs 能够在减少模型复杂性的同时提取特征，这降低了过拟合的风险 [[82](#bib.bib82)]。这些特性使
    CNNs 在图像处理方面表现出色，也适用于处理类似图像的结构化数据。'
- en: III-A4 Generative Adversarial Network (GAN)
  id: totrans-175
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A4 生成对抗网络 (GAN)
- en: 'GAN originates from game theory. As illustrated in Fig. [7](#S2.F7 "Figure
    7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣
    II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(d), GAN is composed of generator and discriminator. The
    goal of the generator is to learn about the true data distribution as much as
    possible by deliberately introducing feedback at the back-fed input cell, while
    the discriminator is to correctly determine whether the input data is coming from
    the true data or the generator. These two participants need to constantly optimize
    their ability to generate and distinguish in the adversarial process until finding
    a Nash equilibrium [[83](#bib.bib83)]. According to the features learned from
    the real information, a well-trained generator can thus fabricate indistinguishable
    information.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 'GAN（生成对抗网络）起源于博弈论。如图[7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware for Edge Computing
    ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")(d)所示，GAN由生成器和判别器组成。生成器的目标是通过故意在反向输入单元中引入反馈，尽可能多地了解真实数据分布，而判别器的目标是正确判断输入数据是否来自真实数据或生成器。这两个参与者需要在对抗过程中不断优化它们的生成和区分能力，直到找到纳什均衡[[83](#bib.bib83)]。根据从真实信息中学习到的特征，经过良好训练的生成器可以制造出无法区分的信息。'
- en: III-A5 Recurrent Neural Network (RNN)
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A5 递归神经网络（RNN）
- en: 'RNNs are designed for handling sequential data. As depicted in Fig. [7](#S2.F7
    "Figure 7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing
    ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(e), each neuron in RNNs not only receives information
    from the upper layer but also receives information from the previous channel of
    its own [[10](#bib.bib10)]. In general, RNNs are natural choices for predicting
    future information or restoring missing parts of sequential data. However, a serious
    problem with RNNs is the gradient explosion. LSTM, as in Fig. [7](#S2.F7 "Figure
    7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣
    II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(f), improving RNN with adding a gate structure and a
    well-defined memory cell, can overcome this issue by controlling (prohibiting
    or allowing) the flow of information [[84](#bib.bib84)].'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 'RNNs（递归神经网络）旨在处理序列数据。如图[7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware for Edge Computing
    ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")(e)所示，RNNs中的每个神经元不仅接收来自上层的信息，还接收来自自身前一通道的信息[[10](#bib.bib10)]。一般来说，RNNs是预测未来信息或恢复序列数据丢失部分的自然选择。然而，RNNs的一个严重问题是梯度爆炸。LSTM，如图[7](#S2.F7
    "Figure 7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing
    ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(f)所示，通过增加一个门控结构和一个明确定义的记忆单元来改进RNN，可以通过控制（禁止或允许）信息流来克服这一问题[[84](#bib.bib84)]。'
- en: III-A6 Transfer Learning (TL)
  id: totrans-179
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A6 转移学习（TL）
- en: 'TL can transfer knowledge, as shown in Fig. [7](#S2.F7 "Figure 7 ‣ II-B1 AI
    Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣ II Fundamentals
    of Edge Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")(g), from the source domain to the target domain so as to achieve better
    learning performance in the target domain [[85](#bib.bib85)]. By using TL, existing
    knowledge learned by a large number of computation resources can be transferred
    to a new scenario, and thus accelerating the training process and reducing model
    development costs. Recently, a novel form of TL emerges, viz., Knowledge Distillation
    (KD) [[86](#bib.bib86)] emerges. As indicated in Fig. [7](#S2.F7 "Figure 7 ‣ II-B1
    AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing ‣ II Fundamentals
    of Edge Computing ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")(h), KD can extract implicit knowledge from a well-trained model (teacher),
    inference of which possess excellent performance but requires high overhead. Then,
    by designing the structure and objective function of the target DL model, the
    knowledge is “transferred” to a smaller DL model (student), so that the significantly
    reduced (pruned or quantized) target DL model achieves high performance as possible.'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 'TL可以将知识从源领域转移到目标领域，如图[7](#S2.F7 "Figure 7 ‣ II-B1 AI Hardware for Edge Computing
    ‣ II-B Hardware for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")(g)所示，从而在目标领域实现更好的学习表现[[85](#bib.bib85)]。通过使用TL，已有的知识可以由大量计算资源转移到新场景，从而加速训练过程并降低模型开发成本。最近，出现了一种新型的TL形式，即知识蒸馏（KD）[[86](#bib.bib86)]。如图[7](#S2.F7
    "Figure 7 ‣ II-B1 AI Hardware for Edge Computing ‣ II-B Hardware for Edge Computing
    ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")(h)所示，KD可以从经过良好训练的模型（教师）中提取隐含知识，该模型的推理表现出色，但需要较高的开销。然后，通过设计目标DL模型的结构和目标函数，这些知识被“转移”到一个较小的DL模型（学生）中，以便显著减少（剪枝或量化）的目标DL模型能够实现尽可能高的性能。'
- en: III-B Deep Reinforcement Learning (DRL)
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 深度强化学习（DRL）
- en: 'As depicted in Fig. [9](#S3.F9 "Figure 9 ‣ III-B Deep Reinforcement Learning
    (DRL) ‣ III Fundamentals of Deep Learning ‣ Convergence of Edge Computing and
    Deep Learning: A Comprehensive Survey"), the goal of RL is to enable an agent
    in the environment to take the best action in the current state to maximize long-term
    gains, where the interaction between the agent’s action and state through the
    environment is modeled as a Markov Decision Process (MDP). DRL is the combination
    of DL and RL, but it focuses more on RL and aims to solve decision-making problems.
    The role of DL is to use the powerful representation ability of DNNs to fit the
    value function or the direct strategy to solve the explosion of state-action space
    or continuous state-action space problem. By virtue of these characteristics,
    DRL becomes a powerful solution in robotics, finance, recommendation system, wireless
    communication, etc [[87](#bib.bib87), [18](#bib.bib18)].'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[9](#S3.F9 "Figure 9 ‣ III-B Deep Reinforcement Learning (DRL) ‣ III Fundamentals
    of Deep Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")所示，RL的目标是使环境中的智能体在当前状态下采取最佳行动，以最大化长期收益，其中智能体通过环境与状态之间的交互被建模为马尔可夫决策过程（MDP）。DRL是DL和RL的结合，但它更侧重于RL，旨在解决决策问题。DL的作用是利用DNNs的强大表示能力来拟合价值函数或直接策略，以解决状态-动作空间爆炸或连续状态-动作空间问题。凭借这些特性，DRL在机器人技术、金融、推荐系统、无线通信等领域成为一种强大的解决方案[[87](#bib.bib87),
    [18](#bib.bib18)]。'
- en: '![Refer to caption](img/02ffdacc393245036c1c4929faa8690b.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/02ffdacc393245036c1c4929faa8690b.png)'
- en: 'Figure 9: Value-based and policy-gradient-based DRL approaches.'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：基于价值和基于策略梯度的DRL方法。
- en: III-B1 Value-based DRL
  id: totrans-185
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 基于价值的DRL
- en: As a representative of value-based DRL, Deep $Q$-Learning (DQL) uses DNNs to
    fit action values, successfully mapping high-dimensional input data to actions
    [[88](#bib.bib88)]. In order to ensure stable convergence of training, experience
    replay method is adopted to break the correlation between transition information
    and a separate target network is set up to suppress instability. Besides, Double
    Deep $Q$-Learning (Double-DQL) can deal with that DQL generally overestimating
    action values [[89](#bib.bib89)], and Dueling Deep $Q$-Learning (Dueling-DQL)
    [[90](#bib.bib90)] can learn which states are (or are not) valuable without having
    to learn the effect of each action at each state.
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: 作为基于价值的深度强化学习（DRL）的代表，Deep $Q$-Learning（DQL）使用深度神经网络（DNNs）来拟合动作值，成功地将高维输入数据映射到动作[[88](#bib.bib88)]。为了确保训练的稳定收敛，采用了经验回放方法来打破过渡信息之间的关联，并设置了一个独立的目标网络来抑制不稳定性。此外，Double
    Deep $Q$-Learning（Double-DQL）可以解决DQL通常会高估动作值的问题[[89](#bib.bib89)]，而Dueling Deep
    $Q$-Learning（Dueling-DQL）[[90](#bib.bib90)]可以学习哪些状态是（或不是）有价值的，而无需学习每个状态下每个动作的效果。
- en: III-B2 Policy-gradient-based DRL
  id: totrans-187
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 基于策略梯度的DRL
- en: Policy gradient is another common strategy optimization method, such as Deep
    Deterministic Policy Gradient (DDPG) [[91](#bib.bib91)], Asynchronous Advantage
    Actor-Critic (A3C) [[92](#bib.bib92)], Proximate Policy Optimization (PPO) [[93](#bib.bib93)],
    etc. It updates the policy parameters by continuously calculating the gradient
    of the policy expectation reward with respect to them, and finally converges to
    the optimal strategy [[94](#bib.bib94)]. Therefore, when solving the DRL problem,
    DNNs can be used to parameterize the policy, and then be optimized by the policy
    gradient method. Further, Actor-Critic (AC) framework is widely adopted in policy-gradient-based
    DRL, in which the policy DNN is used to update the policy, corresponding to the
    Actor; the value DNN is used to approximate the value function of the state action
    pair, and provides gradient information, corresponding to the Critic.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 策略梯度是另一种常见的策略优化方法，例如深度确定性策略梯度（DDPG）[[91](#bib.bib91)]、异步优势演员-评论家（A3C）[[92](#bib.bib92)]、近端策略优化（PPO）[[93](#bib.bib93)]等。它通过不断计算策略期望奖励的梯度来更新策略参数，最终收敛到最优策略[[94](#bib.bib94)]。因此，在解决DRL问题时，可以使用DNNs来参数化策略，然后通过策略梯度方法进行优化。此外，Actor-Critic（AC）框架在基于策略梯度的DRL中被广泛采用，其中策略DNN用于更新策略，对应于Actor；价值DNN用于近似状态动作对的价值函数，并提供梯度信息，对应于Critic。
- en: III-C Distributed DL Training
  id: totrans-189
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 分布式深度学习训练
- en: 'At present, training DL models in a centralized manner consumes a lot of time
    and computation resources, hindering further improving the algorithm performance.
    Nonetheless, distributed training can facilitate the training process by taking
    full advantage of parallel servers. There are two common ways to perform distributed
    training, i.e., data parallelism and model parallelism [[95](#bib.bib95), [96](#bib.bib96),
    [97](#bib.bib97), [98](#bib.bib98)] as illustrated in Fig. [10](#S3.F10 "Figure
    10 ‣ III-C Distributed DL Training ‣ III Fundamentals of Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey").'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '目前，集中式训练深度学习模型消耗大量时间和计算资源，阻碍了算法性能的进一步提升。然而，分布式训练可以通过充分利用并行服务器来促进训练过程。分布式训练有两种常见的方法，即数据并行性和模型并行性[[95](#bib.bib95),
    [96](#bib.bib96), [97](#bib.bib97), [98](#bib.bib98)]，如图[10](#S3.F10 "Figure 10
    ‣ III-C Distributed DL Training ‣ III Fundamentals of Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")所示。'
- en: '![Refer to caption](img/d4f4c6a1e1d0b333f37b60fc21ebfd42.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d4f4c6a1e1d0b333f37b60fc21ebfd42.png)'
- en: 'Figure 10: Distributed training in terms of data and model parallelism.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：数据和模型并行方面的分布式训练。
- en: Model parallelism first splits a large DL model into multiple parts and then
    feeds data samples for training these segmented models in parallel. This not only
    can improve the training speed but also deal with the circumstance that the model
    is larger than the device memory. Training a large DL model generally requires
    a lot of computation resources, even thousands of CPUs are required to train a
    large-scale DL model. In order to solve this problem, distributed GPUs can be
    utilized for model parallel training [[99](#bib.bib99)]. Data parallelism means
    dividing data into multiple partitions, and then respectively training copies
    of the model in parallel with their own allocated data samples. By this means,
    the training efficiency of model training can be improved [[100](#bib.bib100)].
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 模型并行性首先将一个大型深度学习模型分割成多个部分，然后并行训练这些分割后的模型。这样不仅可以提高训练速度，还能处理模型超出设备内存的情况。训练大型深度学习模型通常需要大量的计算资源，甚至需要数千个CPU来训练大规模的深度学习模型。为了解决这个问题，可以利用分布式GPU进行模型并行训练[[99](#bib.bib99)]。数据并行性指的是将数据划分为多个部分，然后分别在并行的模型副本中用各自分配的数据样本进行训练。通过这种方式，可以提高模型训练的效率[[100](#bib.bib100)]。
- en: Coincidentally, a large number of end devices, edge nodes, and cloud data centers,
    are scattered and envisioned to be connected by virtue of edge computing networks.
    These distributed devices can potentially be powerful contributors once the DL
    training jumps out of the cloud.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 恰巧的是，大量的终端设备、边缘节点和云数据中心被分散，并预计通过边缘计算网络连接起来。这些分布式设备一旦深度学习训练从云端转移，可能会成为强大的贡献者。
- en: III-D Potential DL Libraries for Edge
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 边缘计算的潜在深度学习库
- en: 'Development and deployment of DL models rely on the support of various DL libraries.
    However, different DL libraries have their own application scenarios. For deploying
    DL on and for the edge, efficient lightweight DL libraries are required. Features
    of DL frameworks potentially supporting future edge intelligence are listed in
    Table [III](#S2.T3 "TABLE III ‣ II-B3 Edge Computing Frameworks ‣ II-B Hardware
    for Edge Computing ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey") (excluding libraries unavailable for
    edge devices, such as Theano [[101](#bib.bib101)]).'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习模型的开发和部署依赖于各种深度学习库的支持。然而，不同的深度学习库有各自的应用场景。对于边缘计算及其应用，需要高效的轻量级深度学习库。未来支持边缘智能的深度学习框架的特点列在表[III](#S2.T3
    "TABLE III ‣ II-B3 Edge Computing Frameworks ‣ II-B Hardware for Edge Computing
    ‣ II Fundamentals of Edge Computing ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")中（不包括不可用于边缘设备的库，例如Theano [[101](#bib.bib101)]）。'
- en: IV Deep Learning Applications on Edge
  id: totrans-197
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 边缘上的深度学习应用
- en: In general, DL services are currently deployed in cloud data centers (the cloud)
    for handling requests, due to the fact that most DL models are complex and hard
    to compute their inference results on the side of resource-limited devices. However,
    such kind of “end-cloud” architecture cannot meet the needs of real-time DL services
    such as real-time analytics, smart manufacturing and etc. Thus, deploying DL applications
    on the edge can broaden the application scenarios of DL especially with respect
    to the low latency characteristic. In the following, we present edge DL applications
    and highlight their advantages over the comparing architectures without edge computing.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，由于大多数深度学习模型复杂且难以在资源有限的设备上计算其推断结果，深度学习服务当前主要部署在云数据中心（云端）以处理请求。然而，这种“端-云”架构无法满足实时深度学习服务的需求，如实时分析、智能制造等。因此，将深度学习应用部署在边缘上可以拓宽深度学习的应用场景，特别是对于低延迟特性。接下来，我们将介绍边缘深度学习应用，并强调它们相对于没有边缘计算的比较架构的优势。
- en: IV-A Real-time Video Analytic
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实时视频分析
- en: 'Real-time video analytic is important in various fields, such as automatic
    pilot, VR and Augmented Reality (AR), smart surveillance, etc. In general, applying
    DL for it requires high computation and storage resources. Unfortunately, executing
    these tasks in the cloud often incurs high bandwidth consumption, unexpected latency,
    and reliability issues. With the development of edge computing, those problems
    tend to be addressed by moving video analysis near to the data source, viz., end
    devices or edge nodes, as the complementary of the cloud. In this section, as
    depicted in Fig. [11](#S4.F11 "Figure 11 ‣ IV-A Real-time Video Analytic ‣ IV
    Deep Learning Applications on Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"), we summarize related works as a hybrid hierarchical
    architecture, which is divided into three levels: end, edge, and cloud.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '实时视频分析在各种领域中都很重要，如自动驾驶、虚拟现实（VR）和增强现实（AR）、智能监控等。一般来说，应用深度学习（DL）需要高计算和存储资源。不幸的是，在云端执行这些任务通常会带来高带宽消耗、意外延迟和可靠性问题。随着边缘计算的发展，这些问题往往通过将视频分析移至数据源附近，即终端设备或边缘节点，作为云的补充来解决。在这一部分，如图[11](#S4.F11
    "Figure 11 ‣ IV-A Real-time Video Analytic ‣ IV Deep Learning Applications on
    Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")所示，我们总结了作为混合层次结构的相关工作，分为三个层次：终端、边缘和云。'
- en: '![Refer to caption](img/5bfb2ad0bb45386ec698ffa2fef91232.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/5bfb2ad0bb45386ec698ffa2fef91232.png)'
- en: 'Figure 11: The collaboration of the end, edge and cloud layer for performing
    real-time video analytic by deep learning.'
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：终端、边缘和云层协作进行深度学习实时视频分析。
- en: IV-A1 End Level
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 终端层
- en: At the end level, video capture devices, such as smartphones and surveillance
    cameras are responsible for video capture, media data compression [[102](#bib.bib102)],
    image pre-processing, and image segmentation [[103](#bib.bib103)]. By coordinating
    with these participated devices, collaboratively training a domain-aware adaptation
    model can lead to better object recognition accuracy when used together with a
    domain-constrained deep model [[104](#bib.bib104)]. Besides, in order to appropriately
    offload the DL computation to the end devices, the edge nodes or the cloud, end
    devices should comprehensively consider tradeoffs between video compression and
    key metrics, e.g., network condition, data usage, battery consumption, processing
    delay, frame rate and accuracy of analytics, and thus determine the optimal offloading
    strategy [[102](#bib.bib102)].
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 在终端层，视频捕捉设备，如智能手机和监控摄像头，负责视频捕捉、媒体数据压缩 [[102](#bib.bib102)]、图像预处理和图像分割 [[103](#bib.bib103)]。通过与这些参与设备协调，协同训练领域感知适应模型可以在与领域约束深度模型
    [[104](#bib.bib104)] 一起使用时，提高物体识别的准确性。此外，为了适当地将深度学习计算卸载到终端设备、边缘节点或云端，终端设备应全面考虑视频压缩和关键指标之间的权衡，例如网络状况、数据使用、耗电量、处理延迟、帧率和分析准确性，从而确定最佳的卸载策略
    [[102](#bib.bib102)]。
- en: If various DL tasks are executed at the end level independently, enabling parallel
    analytics requires a solution that supports efficient multi-tenant DL. With the
    model pruning and recovery scheme, NestDNN [[105](#bib.bib105)] transforms the
    DL model into a set of descendant models, in which the descendant model with fewer
    resource requirements shares its model parameters with the descendant model requiring
    more resources, making itself nested inside the descendent model requiring more
    resources without taking extra memory space. In this way, the multi-capacity model
    provides variable resource-accuracy trade-offs with a compact memory footprint,
    hence ensuring efficient multi-tenant DL at the end level.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 如果各种深度学习任务在终端层独立执行，实现并行分析需要一个支持高效多租户深度学习的解决方案。通过模型修剪和恢复方案，NestDNN [[105](#bib.bib105)]
    将深度学习模型转化为一组后代模型，其中资源需求较少的后代模型与资源需求更多的后代模型共享其模型参数，使得自身嵌套在需要更多资源的后代模型内部，而不占用额外的内存空间。通过这种方式，多容量模型提供了具有紧凑内存占用的可变资源-准确度权衡，从而确保了终端层高效的多租户深度学习。
- en: IV-A2 Edge Level
  id: totrans-206
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 边缘层
- en: Numerous distributed edge nodes at the edge level generally cooperate with each
    other to provide better services. For example, LAVEA [[106](#bib.bib106)] attaches
    edge nodes to the same access point or BS as well as the end devices, which ensure
    that services can be as ubiquitous as Internet access. In addition, compressing
    the DL model on the edge can improve holistic performance. The resource consumption
    of the edge layer can be greatly reduced while ensuring the analysis performance,
    by reducing the unnecessary filters in CNN layers [[107](#bib.bib107)]. Besides,
    in order to optimize performance and efficiency, [[108](#bib.bib108)] presents
    an edge service framework, i.e., EdgeEye, which realizes a high-level abstraction
    of real-time video analytic functions based on DL. To fully exploit the bond function
    of the edge, VideoEdge [[109](#bib.bib109)] implements an end-edge-cloud hierarchical
    architecture to help achieve load balancing concerning analytical tasks while
    maintaining high analysis accuracy.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘级的众多分布式边缘节点通常相互合作以提供更好的服务。例如，LAVEA [[106](#bib.bib106)] 将边缘节点连接到相同的接入点或基站以及终端设备，从而确保服务能够像互联网访问一样无处不在。此外，通过在边缘压缩
    DL 模型可以提高整体性能。通过减少 CNN 层中的不必要滤波器 [[107](#bib.bib107)]，可以在确保分析性能的同时大幅减少边缘层的资源消耗。此外，为了优化性能和效率，[[108](#bib.bib108)]
    提出了一个边缘服务框架，即 EdgeEye，基于 DL 实现实时视频分析功能的高层抽象。为了充分发挥边缘的功能，VideoEdge [[109](#bib.bib109)]
    实现了一个端-边缘-云分层架构，以帮助实现分析任务的负载均衡，同时保持高分析准确性。
- en: IV-A3 Cloud Level
  id: totrans-208
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A3 云级
- en: At the cloud level, the cloud is responsible for the integration of DL models
    among the edge layer and updating parameters of distributed DL models on edge
    nodes [[102](#bib.bib102)]. Since the distributed model training performance on
    an edge node may be significantly impaired due to its local knowledge, the cloud
    needs to integrate different well-trained DL models to achieve global knowledge.
    When the edge is unable to provide the service confidently (e.g., detecting objects
    with low confidence), the cloud can use its powerful computing power and global
    knowledge for further processing and assist the edge nodes to update DL models.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在云级，云负责整合边缘层之间的 DL 模型，并更新边缘节点上分布式 DL 模型的参数 [[102](#bib.bib102)]。由于边缘节点上的分布式模型训练性能可能因为本地知识的局限而显著下降，云需要整合不同的训练良好的
    DL 模型以实现全局知识。当边缘无法自信地提供服务（例如，以低置信度检测物体）时，云可以利用其强大的计算能力和全局知识进行进一步处理，并协助边缘节点更新 DL
    模型。
- en: IV-B Autonomous Internet of Vehicles (IoVs)
  id: totrans-210
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 自主互联网汽车（IoVs）
- en: It is envisioned that vehicles can be connected to improve safety, enhance efficiency,
    reduce accidents, and decrease traffic congestion in transportation systems [[110](#bib.bib110)].
    There are many information and communication technologies such as networking,
    caching, edge computing which can be used for facilitating the IoVs, though usually
    studied respectively. On one hand, edge computing provides low-latency, high-speed
    communication and fast-response services for vehicles, making automatic driving
    possible. On the other hand, DL techniques are important in various smart vehicle
    applications. Further, they are expected to optimize complex IoVs systems.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 设想中，车辆可以通过连接来提高安全性、增强效率、减少事故，并降低交通拥堵 [[110](#bib.bib110)]。有许多信息和通信技术，如网络、缓存、边缘计算，可以用于促进
    IoVs，尽管这些技术通常是分别研究的。一方面，边缘计算为车辆提供低延迟、高速通信和快速响应服务，使自动驾驶成为可能。另一方面，深度学习（DL）技术在各种智能车辆应用中非常重要。此外，预计它们将优化复杂的
    IoVs 系统。
- en: In [[110](#bib.bib110)], a framework which integrates these technologies is
    proposed. This integrated framework enables dynamic orchestration of networking,
    caching and computation resources to meet requirements of different vehicular
    applications [[110](#bib.bib110)]. Since this system involves multi-dimensional
    control, a DRL-based approach is first utilized to solve the optimization problem
    for enhancing the holistic system performance. Similarly, DRL is also used in
    [[111](#bib.bib111)] to obtain the optimal task offloading policy in vehicular
    edge computing. Besides, Vehicle-to-Vehicle (V2V) communication technology can
    be taken advantaged to further connect vehicles, either as an edge node or an
    end device managed by DRL-based control policies [[112](#bib.bib112)].
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[110](#bib.bib110)]中，提出了一种集成这些技术的框架。该集成框架使得网络、缓存和计算资源的动态调度成为可能，以满足不同车辆应用的需求[[110](#bib.bib110)]。由于该系统涉及多维控制，因此首先利用基于深度强化学习（DRL）的方法来解决优化问题，以提升整体系统性能。类似地，[[111](#bib.bib111)]中也使用DRL来获取车辆边缘计算中的最优任务卸载策略。此外，可以利用车与车（V2V）通信技术进一步连接车辆，无论是作为边缘节点还是由DRL控制策略管理的终端设备[[112](#bib.bib112)]。
- en: IV-C Intelligent Manufacturing
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 智能制造
- en: Two most important principles in the intelligent manufacturing era are automation
    and data analysis, the former one of which is the main target and the latter one
    is one of the most useful tools [[113](#bib.bib113)]. In order to follow these
    principles, intelligent manufacturing should first address response latency, risk
    control, and privacy protection, and hence requires DL and edge computing. In
    intelligent factories, edge computing is conducive to expand the computation resources,
    the network bandwidth, and the storage capacity of the cloud to the IoT edge,
    as well as realizing the resource scheduling and data processing during manufacturing
    and production [[114](#bib.bib114)]. For autonomous manufacturing inspection,
    DeepIns [[113](#bib.bib113)] uses DL and edge computing to guarantee performance
    and process delay respectively. The main idea of this system is partitioning the
    DL model, used for inspection, and deploying them on the end, edge and cloud layer
    separately for improving the inspection efficiency.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 在智能制造时代，两个最重要的原则是自动化和数据分析，其中前者是主要目标，后者是最有用的工具之一[[113](#bib.bib113)]。为了遵循这些原则，智能制造首先需要解决响应延迟、风险控制和隐私保护，因此需要深度学习和边缘计算。在智能工厂中，边缘计算有助于将计算资源、网络带宽和云存储容量扩展到物联网边缘，并实现制造和生产过程中的资源调度和数据处理[[114](#bib.bib114)]。对于自主制造检查，DeepIns[[113](#bib.bib113)]利用深度学习和边缘计算分别保证性能和处理延迟。该系统的主要思想是将用于检查的深度学习模型进行分区，并将其分别部署在端、边缘和云层，以提高检查效率。
- en: Nonetheless, with the exponential growth of IoT edge devices, 1) how to remotely
    manage evolving DL models and 2) how to continuously evaluate these models for
    them are necessary. In [[115](#bib.bib115)], a framework, dealing with these challenges,
    is developed to support complex-event learning during intelligent manufacturing,
    thus facilitating the development of real-time application on IoT edge devices.
    Besides, the power, energy efficiency, memory footprint limitation of IoT edge
    devices [[116](#bib.bib116)] should also be considered. Therefore, caching, communication
    with heterogeneous IoT devices, and computation offloading can be integrated [[117](#bib.bib117)]
    to break the resource bottleneck.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，随着物联网边缘设备的指数级增长，1）如何远程管理不断发展的深度学习模型，以及2）如何持续评估这些模型是必需的。在[[115](#bib.bib115)]中，开发了一种框架来应对这些挑战，以支持智能制造过程中的复杂事件学习，从而促进实时应用在物联网边缘设备上的发展。此外，还应考虑物联网边缘设备的功率、能源效率和内存占用限制[[116](#bib.bib116)]。因此，可以整合缓存、与异构物联网设备的通信以及计算卸载[[117](#bib.bib117)]，以突破资源瓶颈。
- en: IV-D Smart Home and City
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 智能家居与城市
- en: The popularity of IoTs will bring more and more intelligent applications to
    home life, such as intelligent lighting control systems, smart televisions, and
    smart air conditioners. But at the same time, smart homes need to deploy numerous
    wireless IoT sensors and controllers in corners, floors, and walls. For the protection
    of sensitive home data, the data processing of smart home systems must rely on
    edge computing. Like use cases in [[118](#bib.bib118), [119](#bib.bib119)], edge
    computing is deployed to optimize indoor positioning systems and home intrusion
    monitoring so that they can get lower latency than using cloud computing as well
    as the better accuracy. Further, the combination of DL and edge computing can
    make these intelligent services become more various and powerful. For instance,
    it endows robots the ability of dynamic visual servicing [[120](#bib.bib120)]
    and enables efficient music cognition system [[121](#bib.bib121)].
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 物联网的普及将带来越来越多的智能应用到家庭生活中，如智能照明控制系统、智能电视和智能空调。但同时，智能家居需要在角落、地板和墙壁上部署大量无线物联网传感器和控制器。为了保护敏感的家庭数据，智能家居系统的数据处理必须依赖边缘计算。如在[[118](#bib.bib118),
    [119](#bib.bib119)]中的使用案例所示，边缘计算被部署以优化室内定位系统和家庭入侵监控，从而比使用云计算获得更低的延迟和更好的准确性。此外，深度学习与边缘计算的结合可以使这些智能服务变得更加多样和强大。例如，它赋予机器人动态视觉服务能力[[120](#bib.bib120)]，并使高效的音乐认知系统得以实现[[121](#bib.bib121)]。
- en: If the smart home is enlarged to a community or city, public safety, health
    data, public facilities, transportation, and other fields can benefit. The original
    intention of applying edge computing in smart cities is more due to cost and efficiency
    considerations. The natural characteristic of geographically distributed data
    sources in cities requires an edge computing-based paradigm to offer location-awareness
    and latency-sensitive monitoring and intelligent control. For instance, the hierarchical
    distributed edge computing architecture in [[122](#bib.bib122)] can support the
    integration of massive infrastructure components and services in future smart
    cities. This architecture can not only support latency-sensitive applications
    on end devices but also perform slightly latency-tolerant tasks efficiently on
    edge nodes, while large-scale DL models responsible for deep analysis are hosted
    on the cloud. Besides, DL can be utilized to orchestrate and schedule infrastructures
    to achieve the holistic load balancing and optimal resource utilization among
    a region of a city (e.g., within a campus [[123](#bib.bib123)]) or the whole city.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 如果智能家居扩大到一个社区或城市，公共安全、健康数据、公共设施、交通等领域都能从中受益。将边缘计算应用于智能城市的初衷更多是出于成本和效率的考虑。城市中地理分布的数据源的自然特性要求基于边缘计算的模式提供位置感知和延迟敏感的监控与智能控制。例如，[[122](#bib.bib122)]中的分层分布式边缘计算架构可以支持未来智能城市中大量基础设施组件和服务的集成。这种架构不仅可以支持终端设备上的延迟敏感应用，还可以在边缘节点上高效执行稍微能容忍延迟的任务，而负责深度分析的大规模深度学习模型则托管在云端。此外，深度学习可以用来编排和调度基础设施，实现区域内（如校园内[[123](#bib.bib123)]）或整个城市的全面负载均衡和资源优化利用。
- en: V Deep Learning Inference in Edge
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 深度学习推断在边缘
- en: In order to further improve the accuracy, DNNs become deeper and require larger-scale
    dataset. By this means, dramatic computation costs are introduced. Certainly,
    the outstanding performance of DL models is inseparable from the support of high-level
    hardware, and it is difficult to deploy them in the edge with limited resources.
    Therefore, large-scale DL models are generally deployed in the cloud while end
    devices just send input data to the cloud and then wait for the DL inference results.
    However, the cloud-only inference limits the ubiquitous deployment of DL services.
    Specifically, it can not guarantee the delay requirement of real-time services,
    e.g., real-time detection with strict latency demands. Moreover, for important
    data sources, data safety and privacy protection should be addressed. To deal
    with these issues, DL services tend to resort to edge computing. Therefore, DL
    models should be further customized to fit in the resource-constrained edge, while
    carefully treating the trade-off between the inference accuracy and the execution
    latency of them.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高准确性，深度神经网络（DNN）变得更深，并需要更大规模的数据集。这会引入剧烈的计算成本。当然，深度学习（DL）模型的卓越性能离不开高端硬件的支持，但在资源有限的边缘环境中部署它们较为困难。因此，大规模的DL模型通常在云端部署，而终端设备只需将输入数据发送到云端，然后等待DL推断结果。然而，仅依赖云端推断限制了DL服务的普遍部署。具体来说，这不能保证实时服务的延迟要求，例如具有严格延迟要求的实时检测。此外，对于重要的数据源，数据安全和隐私保护也应得到解决。为了解决这些问题，DL服务往往依赖边缘计算。因此，DL模型应进一步定制以适应资源受限的边缘，同时仔细权衡推断准确性和执行延迟之间的权衡。
- en: V-A Optimization of DL Models in Edge
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 边缘计算中的深度学习模型优化
- en: 'DL tasks are usually computationally intensive and requires large memory footprints.
    But in the edge, there are not enough resources to support raw large-scale DL
    models. Optimizing DL models and quantize their weights can reduce resource costs.
    In fact, model redundancies are common in DNNs [[124](#bib.bib124), [125](#bib.bib125)]
    and can be utilized to make model optimization possible. The most important challenge
    is how to ensure that there is no significant loss in model accuracy after being
    optimized. In other words, the optimization approach should transform or re-design
    DL models and make them fit in edge devices, with as little loss of model performance
    as possible. In this section, optimization methods for different scenarios are
    discussed: 1) general optimization methods for edge nodes with relatively sufficient
    resources; 2) fine-grained optimization methods for end devices with tight resource
    budgets.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: DL任务通常计算密集并且需要大内存。但在边缘环境中，没有足够的资源来支持原始的大规模DL模型。优化DL模型和量化其权重可以减少资源成本。实际上，DNN中模型冗余是常见的[[124](#bib.bib124)，[125](#bib.bib125)]，这些冗余可以用来实现模型优化。最重要的挑战是如何确保在优化后模型准确性没有显著下降。换句话说，优化方法应该转化或重新设计DL模型，使其适应边缘设备，并尽可能少地损失模型性能。本节讨论了不同场景下的优化方法：1）针对相对资源充足的边缘节点的一般优化方法；2）针对资源预算紧张的终端设备的精细化优化方法。
- en: V-A1 General Methods for Model Optimization
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A1 模型优化的一般方法
- en: 'On one hand, increasing the depth and width of DL models with nearly constant
    computation overhead is one direction of optimization, such as inception [[126](#bib.bib126)]
    and deep residual networks [[127](#bib.bib127)] for CNNs. On the other hand, for
    more general neural network structures, existing optimization methods can be divided
    into four categories [[128](#bib.bib128)]: 1) parameter pruning and sharing [[129](#bib.bib129),
    [130](#bib.bib130)], including also weights quantization [[131](#bib.bib131),
    [132](#bib.bib132), [133](#bib.bib133)]; 2) low-rank factorization [[124](#bib.bib124)];
    3) transferred/compact convolution filters [[134](#bib.bib134), [135](#bib.bib135),
    [107](#bib.bib107)]; 4) knowledge distillation [[136](#bib.bib136)]. These approaches
    can be applied to different kinds of DNNs or be composed to optimize a complex
    DL model for the edge.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 一方面，增加DL模型的深度和宽度，同时计算开销几乎保持不变，是一种优化方向，如用于CNN的inception[[126](#bib.bib126)]和深度残差网络[[127](#bib.bib127)]。另一方面，对于更一般的神经网络结构，现有的优化方法可以分为四类[[128](#bib.bib128)]：1）参数剪枝和共享[[129](#bib.bib129)，[130](#bib.bib130)]，还包括权重量化[[131](#bib.bib131)，[132](#bib.bib132)，[133](#bib.bib133)];
    2）低秩分解[[124](#bib.bib124)]; 3）转移/紧凑卷积滤波器[[134](#bib.bib134)，[135](#bib.bib135)，[107](#bib.bib107)];
    4）知识蒸馏[[136](#bib.bib136)]。这些方法可以应用于不同类型的DNN或组合应用以优化边缘计算中的复杂DL模型。
- en: V-A2 Model Optimization for Edge Devices
  id: totrans-225
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A2 边缘设备的模型优化
- en: In addition to limited computing and memory footprint, other factors such as
    network bandwidth and power consumption also need to be considered. In this section,
    efforts for running DL on edge devices are differentiated and discussed.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 除了有限的计算和内存占用外，还需要考虑其他因素，如网络带宽和功耗。在本节中，对在边缘设备上运行DL的努力进行了区分和讨论。
- en: •
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Input: Each application scenario has specific optimization spaces. Concerning
    object detection, FFS-VA uses two prepositive stream-specialized filters and a
    small full-function tiny-YOLO model to filter out vast but non-target-object frames
    [[137](#bib.bib137)]. In order to adjust the configuration of the input video
    stream (such as frame resolution and sampling rate) online with low cost, Chameleon
    [[138](#bib.bib138)] greatly saves the cost of searching the best model configuration
    by leveraging temporal and spatial correlations of the video inputs, and allows
    the cost to be amortized over time and across multiple video feeds. Besides, as
    depicted in Fig. [12](#S5.F12 "Figure 12 ‣ 1st item ‣ V-A2 Model Optimization
    for Edge Devices ‣ V-A Optimization of DL Models in Edge ‣ V Deep Learning Inference
    in Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey"),
    narrowing down the classifier’s searching space [[139](#bib.bib139)] and dynamic
    Region-of-Interest (RoI) encoding [[140](#bib.bib140)] to focus on target objects
    in video frames can further reduce the bandwidth consumption and data transmission
    delay. Though this kind of methods can significantly compress the size of model
    inputs and hence reduce the computation overhead without altering the structure
    of DL models, it requires a deep understanding of the related application scenario
    to dig out the potential optimization space.'
  id: totrans-228
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型输入：每个应用场景都有特定的优化空间。针对目标检测，FFS-VA使用两个前置流专用过滤器和一个小型全功能小型YOLO模型来筛选出大量但非目标物体帧[[137](#bib.bib137)]。为了以低成本在线调整输入视频流的配置（如帧分辨率和采样率），Chameleon
    [[138](#bib.bib138)]通过利用视频输入的时间和空间相关性大大节省了搜索最佳模型配置的成本，并允许成本随时间和跨多个视频源进行摊销。此外，如图[12](#S5.F12
    "图12 ‣ 1st item ‣ V-A2模型优化用于边缘设备 ‣ V-A边缘DL模型的优化 ‣ V边缘深度学习推断 ‣ 边缘计算和深度学习的融合：一项全面调查")所示，缩小分类器的搜索空间[[139](#bib.bib139)]和动态感兴趣区域（RoI）编码[[140](#bib.bib140)]以聚焦视频帧中的目标对象可以进一步减少带宽消耗和数据传输延迟。尽管这种方法可以显著压缩模型输入的大小，从而减少DL模型的计算开销，而不改变其结构，但这需要对相关应用场景有深刻的理解，以挖掘潜在的优化空间。
- en: '![Refer to caption](img/0a29b1689d2994bf1db8a7e54c60345e.png)'
  id: totrans-229
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![参考标题](img/0a29b1689d2994bf1db8a7e54c60345e.png)'
- en: 'Figure 12: Optimization for model inputs, e.g., narrowing down the searching
    space of DL models (pictures are with permission from [[141](#bib.bib141)]).'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图12：模型输入的优化，例如缩小DL模型的搜索空间（图片取自[[141](#bib.bib141)]，经允许使用）。
- en: •
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Structure: Not paying attention to specific applications, but focusing
    on the widely used DNNs’ structures is also feasible. For instance, point-wise
    group convolution and channel shuffle [[142](#bib.bib142)], paralleled convolution
    and pooling computation [[143](#bib.bib143)], depth-wise separable convolution
    [[107](#bib.bib107)] can greatly reduce computation cost while maintaining accuracy.
    NoScope [[144](#bib.bib144)] leverages two types of models rather than the standard
    model (such as YOLO [[9](#bib.bib9)]): specialized models that waive the generality
    of standard models in exchange for faster inference, and difference detectors
    that identify temporal differences across input data. After performing efficient
    cost-based optimization of the model architecture and thresholds for each model,
    NoScope can maximize the throughput of DL services and by cascading these models.
    Besides, as depicted in Fig. [13](#S5.F13 "Figure 13 ‣ 2nd item ‣ V-A2 Model Optimization
    for Edge Devices ‣ V-A Optimization of DL Models in Edge ‣ V Deep Learning Inference
    in Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey"),
    parameters pruning can be applied adaptively in model structure optimization as
    well [[145](#bib.bib145), [146](#bib.bib146), [147](#bib.bib147)]. Furthermore,
    the optimization can be more efficient if across the boundary between algorithm,
    software and hardware. Specifically, general hardware is not ready for the irregular
    computation pattern introduced by model optimization. Therefore, hardware architectures
    should be designed to work directly for optimized models [[145](#bib.bib145)].'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型结构：不关注具体应用，而是专注于广泛使用的 DNN 结构也是可行的。例如，点对点组卷积和通道重排 [[142](#bib.bib142)]，并行卷积和池化计算
    [[143](#bib.bib143)]，深度可分离卷积 [[107](#bib.bib107)] 可以在保持准确性的同时大大降低计算成本。NoScope
    [[144](#bib.bib144)] 利用两种模型类型而不是标准模型（如 YOLO [[9](#bib.bib9)]）：专门模型通过放弃标准模型的通用性来换取更快的推理速度，以及识别输入数据中时间差异的差异检测器。经过对模型架构和每个模型的阈值进行高效的基于成本的优化后，NoScope
    可以最大化 DL 服务的吞吐量，并通过级联这些模型。此外，如图 [13](#S5.F13 "图 13 ‣ 第二项 ‣ V-A2 边缘设备模型优化 ‣ V-A
    DL 模型优化 ‣ V 边缘深度学习推理 ‣ 边缘计算与深度学习的融合：全面调查") 所示，参数剪枝也可以在模型结构优化中自适应地应用 [[145](#bib.bib145)，[146](#bib.bib146)，[147](#bib.bib147)]。此外，如果跨越算法、软件和硬件的边界进行优化，效率会更高。具体而言，一般硬件尚未准备好处理模型优化引入的不规则计算模式。因此，硬件架构应设计为直接支持优化后的模型
    [[145](#bib.bib145)]。
- en: '![Refer to caption](img/a2eee14f20f1368c6b59ffe904719ad2.png)'
  id: totrans-233
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![参考说明](img/a2eee14f20f1368c6b59ffe904719ad2.png)'
- en: 'Figure 13: Adaptive parameters pruning in model structure optimization.'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 13：模型结构优化中的自适应参数剪枝。
- en: •
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Selection: With various DL models, choosing the best one from available
    DL models in the edge requires weighing both precision and inference time. In
    [[148](#bib.bib148)], the authors use $k$NN to automatically construct a predictor,
    composed of DL models arranged in sequence. Then, the model selection can be determined
    by that predictor along with a set of automatically tuned features of the model
    input. Besides, combining different compression techniques (such as model pruning),
    multiple compressed DL models with different tradeoffs between the performance
    and the resource requirement can be derived. AdaDeep [[149](#bib.bib149)] explores
    the desirable balance between performance and resource constraints, and based
    on DRL, automatically selects various compression techniques (such as model pruning)
    to form a compressed model according to current available resources, thus fully
    utilizing the advantages of them.'
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型选择：在各种 DL 模型中，从可用的 DL 模型中选择最佳模型需要权衡精度和推理时间。在 [[148](#bib.bib148)] 中，作者使用 $k$NN
    自动构建一个预测器，由按序排列的 DL 模型组成。然后，可以通过该预测器以及一组自动调节的模型输入特征来确定模型选择。此外，通过结合不同的压缩技术（如模型剪枝），可以得到多个压缩的
    DL 模型，这些模型在性能和资源需求之间具有不同的权衡。AdaDeep [[149](#bib.bib149)] 探索了性能和资源约束之间的理想平衡，并基于
    DRL 自动选择各种压缩技术（如模型剪枝），以根据当前可用资源形成压缩模型，从而充分利用这些优势。
- en: •
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model Framework: Given the high memory footprint and computational demands
    of DL, running them on edge devices requires expert-tailored software and hardware
    frameworks. A software framework is valuable if it 1) provides a library of optimized
    software kernels to enable deployment of DL [[150](#bib.bib150)]; 2) automatically
    compresses DL models into smaller dense matrices by finding the minimum number
    of non-redundant hidden elements [[151](#bib.bib151)]; 3) performs quantization
    and coding on all commonly used DL structures [[146](#bib.bib146), [152](#bib.bib152),
    [151](#bib.bib151)]; 4) specializes DL models to contexts and shares resources
    across multiple simultaneously executing DL models [[152](#bib.bib152)]. With
    respect to the hardware, running DL models on Static Random Access Memory (SRAM)
    achieves better energy savings compared to Dynamic RAM (DRAM) [[146](#bib.bib146)].
    Hence, DL performance can be benefited if underlying hardware directly supports
    running optimized DL models [[153](#bib.bib153)] on the on-chip SRAM.'
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模型框架：鉴于深度学习的高内存占用和计算需求，在边缘设备上运行它们需要专家量身定制的软件和硬件框架。如果一个软件框架具有以下特点，则其价值更高：1) 提供优化的软件内核库以支持深度学习部署[[150](#bib.bib150)]；2)
    通过找到最少的非冗余隐藏元素，将深度学习模型自动压缩成更小的稠密矩阵[[151](#bib.bib151)]；3) 对所有常用的深度学习结构进行量化和编码[[146](#bib.bib146)、[152](#bib.bib152)、[151](#bib.bib151)]；4)
    专门为上下文定制深度学习模型，并在多个同时执行的深度学习模型之间共享资源[[152](#bib.bib152)]。在硬件方面，与动态随机存取内存（DRAM）相比，运行在静态随机存取内存（SRAM）上的深度学习模型可以实现更好的能量节省[[146](#bib.bib146)]。因此，如果底层硬件直接支持在片上SRAM上运行优化的深度学习模型[[153](#bib.bib153)]，则可以提高深度学习性能。
- en: V-B Segmentation of DL Models
  id: totrans-239
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 深度学习模型的分段
- en: In [[12](#bib.bib12)], the delay and power consumption of the most advanced
    DL models are evaluated on the cloud and edge devices, finding that uploading
    data to the cloud is the bottleneck of current DL servicing methods (leading to
    a large overhead of transmitting). Dividing the DL model and performing distributed
    computation can achieve better end-to-end delay performance and energy efficiency.
    In addition, by pushing part of DL tasks from the cloud to the edge, the throughput
    of the cloud can be improved. Therefore, the DL model can be segmented into multiple
    partitions and then allocated to 1) heterogeneous local processors (e.g., GPUs,
    CPUs) on the end device [[154](#bib.bib154)], 2) distributed edge nodes [[155](#bib.bib155),
    [156](#bib.bib156)], or 3) collaborative “end-edge-cloud” architecture [[157](#bib.bib157),
    [158](#bib.bib158), [12](#bib.bib12), [49](#bib.bib49)].
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[12](#bib.bib12)]中，评估了最先进的深度学习模型在云端和边缘设备上的延迟和功耗，发现将数据上传到云端是当前深度学习服务方法的瓶颈（导致了大量的传输开销）。将深度学习模型划分并进行分布式计算可以实现更好的端到端延迟性能和能效。此外，通过将部分深度学习任务从云端推送到边缘，可以提高云端的吞吐量。因此，可以将深度学习模型分割成多个部分，然后分配到1)
    异构本地处理器（例如，GPU、CPU）[[154](#bib.bib154)]，2) 分布式边缘节点[[155](#bib.bib155)、[156](#bib.bib156)]，或3)
    协作的“端-边缘-云”架构[[157](#bib.bib157)、[158](#bib.bib158)、[12](#bib.bib12)、[49](#bib.bib49)]。
- en: 'Partitioning the DL model horizontally, i.e., along the end, edge and cloud,
    is the most common segmentation method. The challenge lies in how to intelligently
    select the partition points. As illustrated in Fig. [14](#S5.F14 "Figure 14 ‣
    V-B Segmentation of DL Models ‣ V Deep Learning Inference in Edge ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey"), a general process
    for determining the partition point can be divided into three steps [[157](#bib.bib157),
    [12](#bib.bib12)]: 1) measuring and modeling the resource cost of different DNN
    layers and the size of intermediate data between layers; 2) predicting the total
    cost by specific layer configurations and network bandwidth; 3) choosing the best
    one from candidate partition points according to delay, energy requirements, etc.
    Another kind of model segmentation is vertically partitioning particularly for
    CNNs [[156](#bib.bib156)]. In contrast to horizontal partition, vertical partition
    fuses layers and partitions them vertically in a grid fashion, and thus divides
    CNN layers into independently distributable computation tasks.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '对深度学习模型进行水平划分，即沿着端、边缘和云，是最常见的分割方法。挑战在于如何智能地选择划分点。如图[14](#S5.F14 "Figure 14
    ‣ V-B Segmentation of DL Models ‣ V Deep Learning Inference in Edge ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")所示，确定划分点的一般过程可以分为三个步骤[[157](#bib.bib157),
    [12](#bib.bib12)]：1) 测量和建模不同DNN层的资源成本以及层间中间数据的大小；2) 根据特定的层配置和网络带宽预测总成本；3) 根据延迟、能量需求等从候选划分点中选择最佳点。另一种模型分割方法是垂直划分，特别是对于卷积神经网络（CNN）[[156](#bib.bib156)]。与水平划分相比，垂直划分将层融合并以网格方式垂直划分，从而将CNN层分成可以独立分配的计算任务。'
- en: '![Refer to caption](img/77a69832a770696b509418feb23ad22a.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/77a69832a770696b509418feb23ad22a.png)'
- en: 'Figure 14: Segmentation of DL models in the edge.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：边缘中的深度学习模型分割。
- en: V-C Early Exit of Inference (EEoI)
  id: totrans-244
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 推理的早期退出（EEoI）
- en: To reach the best trade-off between model accuracy and processing delay, multiple
    DL models with different model performance and resource cost can be maintained
    for each DL service. Then, by intelligently selecting the best model, the desired
    adaptive inference is achieved [[159](#bib.bib159)]. Nonetheless, this idea can
    be further improved by the emerged EEoI [[160](#bib.bib160)].
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在模型准确性和处理延迟之间达到最佳权衡，可以为每个深度学习服务维护多个具有不同模型性能和资源成本的深度学习模型。然后，通过智能选择最佳模型，实现所需的自适应推理[[159](#bib.bib159)]。然而，这一思路可以通过新出现的EEoI[[160](#bib.bib160)]进一步改进。
- en: The performance improvement of additional layers in DNNs is at the expense of
    increased latency and energy consumption in feedforward inference. As DNNs grow
    larger and deeper, these costs become more prohibitive for edge devices to run
    real-time and energy-sensitive DL applications. By additional side branch classifiers,
    for partial samples, EEoI allows inference to exit early via these branches if
    with high confidence. For more difficult samples, EEoI will use more or all DNN
    layers to provide the best predictions.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度神经网络（DNN）中，增加额外层数的性能提升是以增加前向推理的延迟和能耗为代价的。随着DNN规模的扩大和加深，这些成本变得更加难以承受，使得边缘设备运行实时和能量敏感的深度学习应用变得困难。通过额外的分支分类器，对于部分样本，EEoI允许通过这些分支在高信心的情况下提前退出推理。对于更困难的样本，EEoI将使用更多或所有DNN层来提供最佳预测。
- en: 'As depicted in Fig. [15](#S5.F15 "Figure 15 ‣ V-C Early Exit of Inference (EEoI)
    ‣ V Deep Learning Inference in Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"), by taking advantage of EEoI, fast and localized inference
    using shallow portions of DL models at edge devices can be enabled. By this means,
    the shallow model on the edge device can quickly perform initial feature extraction
    and, if confident, can directly give inference results. Otherwise, the additional
    large DL model deployed in the cloud performs further processing and final inference.
    Compared to directly offloading DL computation to the cloud, this approach has
    lower communication costs and can achieve higher inference accuracy than those
    of the pruned or quantized DL models on edge devices [[113](#bib.bib113), [161](#bib.bib161)].
    In addition, since only immediate features rather than the original data are sent
    to the cloud, it provides better privacy protection. Nevertheless, EEoI shall
    not be deemed independent to model optimization (Section [V-A2](#S5.SS1.SSS2 "V-A2
    Model Optimization for Edge Devices ‣ V-A Optimization of DL Models in Edge ‣
    V Deep Learning Inference in Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")) and segmentation (Section [V-B](#S5.SS2 "V-B Segmentation
    of DL Models ‣ V Deep Learning Inference in Edge ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")). The envision of distributed DL over
    the end, edge and cloud should take their collaboration into consideration, e.g.,
    developing a collaborative and on-demand co-inference framework [[162](#bib.bib162)]
    for adaptive DNN partitioning and EEoI.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[15](#S5.F15 "Figure 15 ‣ V-C Early Exit of Inference (EEoI) ‣ V Deep Learning
    Inference in Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")所示，通过利用EEoI，可以在边缘设备上实现快速和本地化的推理，使用DL模型的浅层部分。通过这种方式，边缘设备上的浅层模型可以快速执行初步特征提取，如果有信心，可以直接给出推理结果。否则，部署在云端的大型DL模型将进行进一步处理和最终推理。与直接将DL计算卸载到云端相比，这种方法具有更低的通信成本，并且可以实现比边缘设备上修剪或量化DL模型更高的推理准确度[[113](#bib.bib113),
    [161](#bib.bib161)]。此外，由于仅将即时特征而非原始数据发送到云端，这提供了更好的隐私保护。然而，EEoI不能被视为与模型优化（第[V-A2](#S5.SS1.SSS2
    "V-A2 Model Optimization for Edge Devices ‣ V-A Optimization of DL Models in Edge
    ‣ V Deep Learning Inference in Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")节）和分段（第[V-B](#S5.SS2 "V-B Segmentation of DL Models ‣
    V Deep Learning Inference in Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey")节）的模型优化独立。对端、边缘和云的分布式DL的设想应考虑它们的协作，例如，开发一个协作和按需的共同推理框架[[162](#bib.bib162)]，用于自适应DNN分区和EEoI。'
- en: '![Refer to caption](img/08bb6475b1066b0005d0c50a76f41009.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08bb6475b1066b0005d0c50a76f41009.png)'
- en: 'Figure 15: Early exit of inference for DL inference in the edge.'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图15：边缘DL推理的早期退出。
- en: V-D Sharing of DL Computation
  id: totrans-250
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D DL计算共享
- en: The requests from nearby users within the coverage of an edge node may exhibit
    spatiotemporal locality [[163](#bib.bib163)]. For instance, users within the same
    area might request recognition tasks for the same object of interest, and it may
    introduce redundant computation of DL inference. In this case, based on offline
    analysis of applications and online estimates of network conditions, Cachier [[163](#bib.bib163)]
    proposes to cache related DL models for recognition applications in the edge node
    and to minimize expected end-to-end latency by dynamically adjusting its cache
    size. Based on the similarity between consecutive frames in first-person-view
    videos, DeepMon [[164](#bib.bib164)] and DeepCache [[165](#bib.bib165)] utilize
    the internal processing structure of CNN layers to reuse the intermediate results
    of the previous frame to calculate the current frame, i.e., caching internally
    processed data within CNN layers, to reduce the processing latency of continuous
    vision applications.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘节点覆盖范围内附近用户的请求可能表现出时空局部性[[163](#bib.bib163)]。例如，同一地区的用户可能会请求相同对象的识别任务，这可能会引入冗余的DL推理计算。在这种情况下，根据对应用程序的离线分析和对网络条件的在线估计，Cachier
    [[163](#bib.bib163)]建议在边缘节点缓存与识别应用程序相关的DL模型，并通过动态调整缓存大小来最小化期望的端到端延迟。基于第一人称视角视频中连续帧之间的相似性，DeepMon
    [[164](#bib.bib164)]和DeepCache [[165](#bib.bib165)]利用CNN层的内部处理结构重用前一帧的中间结果来计算当前帧，即在CNN层内部缓存处理过的数据，以减少连续视觉应用的处理延迟。
- en: Nevertheless, to proceed with effective caching and results reusing, accurate
    lookup for reusable results shall be addressed, i.e., the cache framework must
    systematically tolerate the variations and evaluate key similarities. DeepCache
    [[165](#bib.bib165)] performs cache key lookup to solve this. Specifically, it
    divides each video frame into fine-grained regions and searches for similar regions
    from cached frames in a specific pattern of video motion heuristics. For the same
    challenge, FoggyCache [[166](#bib.bib166)] first embeds heterogeneous raw input
    data into feature vectors with generic representation. Then, Adaptive Locality
    Sensitive Hashing (A-LSH), a variant of LSH commonly used for indexing high-dimensional
    data, is proposed to index these vectors for fast and accurate lookup. At last,
    Homogenized $k$NN, which utilizes the cached values to remove outliers and ensure
    a dominant cluster among the $k$ records initially chosen, is implemented based
    on $k$NN to determine the reuse output from records looked up by A-LSH.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，为了有效进行缓存和结果重用，必须解决准确查找可重用结果的问题，即缓存框架必须系统地容忍变化并评估关键相似性。DeepCache [[165](#bib.bib165)]
    通过执行缓存键查找来解决这个问题。具体而言，它将每个视频帧划分为细粒度区域，并以特定的视频运动启发式模式从缓存帧中搜索相似区域。对于相同的挑战，FoggyCache
    [[166](#bib.bib166)] 首先将异构原始输入数据嵌入为具有通用表示的特征向量。然后，提出了自适应局部敏感哈希（A-LSH），这是LSH的一个变体，常用于高维数据的索引，以便快速准确地查找这些向量。最后，基于
    $k$NN 实现的同质化 $k$NN 利用缓存值来去除异常值并确保在初步选择的 $k$ 条记录中主导的集群，从而确定从A-LSH查找的记录中的重用输出。
- en: Differ from sharing inference results, Mainstream [[167](#bib.bib167)] proposes
    to adaptively orchestrate DNN stem-sharing (the common part of several specialized
    DL models) among concurrent video processing applications. By exploiting computation
    sharing of specialized models among applications trained through TL from a common
    DNN stem, aggregate per-frame compute time can be significantly decreased. Though
    more specialized DL models mean both higher model accuracy and less shared DNN
    stems, the model accuracy decreases slowly as less-specialized DL models are employed
    (unless the fraction of the model specialized is very small). This characteristic
    hence enables that large portions of the DL model can be shared with low accuracy
    loss in Mainstream.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 与共享推理结果不同，Mainstream [[167](#bib.bib167)] 提议自适应地协调DNN stem-sharing（几个专用深度学习模型的共同部分）在并发的视频处理应用程序之间。通过利用应用程序之间通过TL从通用DNN
    stem训练的专用模型的计算共享，可以显著减少每帧的计算时间。尽管更多的专用深度学习模型意味着更高的模型准确性和更少的共享DNN stem，但模型准确性随着不那么专用的深度学习模型的使用而缓慢下降（除非模型的专用部分非常小）。因此，这一特性使得Mainstream能够在较低的准确性损失情况下共享大部分深度学习模型。
- en: VI Edge Computing for Deep Learning
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 边缘计算与深度学习
- en: Extensive deployment of DL services, especially mobile DL, requires the support
    of edge computing. This support is not just at the network architecture level,
    the design, adaptation, and optimization of edge hardware and software are equally
    important. Specifically, 1) customized edge hardware and corresponding optimized
    software frameworks and libraries can help DL execution more efficiently; 2) the
    edge computing architecture can enable the offloading of DL computation; 3) well-designed
    edge computing frameworks can better maintain DL services running on the edge;
    4) fair platforms for evaluating Edge DL performance help further evolve the above
    implementations.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习服务的大规模部署，特别是移动深度学习，需要边缘计算的支持。这种支持不仅仅是网络架构层面的，边缘硬件和软件的设计、适配和优化同样重要。具体来说，1)
    定制的边缘硬件和相应优化的软件框架和库可以提高深度学习的执行效率；2) 边缘计算架构可以实现深度学习计算的卸载；3) 设计良好的边缘计算框架可以更好地维持在边缘运行的深度学习服务；4)
    公平的边缘深度学习性能评估平台有助于进一步发展上述实现。
- en: VI-A Edge Hardware for DL
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 深度学习的边缘硬件
- en: VI-A1 Mobile CPUs and GPUs
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A1 移动CPU和GPU
- en: DL applications are more valuable if directly enabled on lightweight edge devices,
    such as mobile phones, wearable devices, and surveillance cameras, near to the
    location of events. Low-power IoT edge devices can be used to undertake lightweight
    DL computation, and hence avoiding communication with the cloud, but it still
    needs to face limited computation resources, memory footprint, and energy consumption.
    To break through these bottlenecks, in [[143](#bib.bib143)], the authors focus
    on ARM Cortex-M micro-controllers and develop CMSIS-NN, a collection of efficient
    NN kernels. By CMSIS-NN, the memory footprint of NNs on ARM Cortex-M processor
    cores can be minimized, and then the DL model can be fitted into IoT devices,
    meantime achieving normal performance and energy efficiency.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 如果直接在轻量级边缘设备上启用 DL 应用程序，如手机、可穿戴设备和监控摄像头，这些应用程序将更有价值，因为它们更接近事件发生的位置。低功耗 IoT 边缘设备可以用于承担轻量级的
    DL 计算，从而避免与云端的通信，但仍需面对计算资源、内存占用和能源消耗的限制。为突破这些瓶颈，在 [[143](#bib.bib143)] 中，作者关注
    ARM Cortex-M 微控制器，并开发了 CMSIS-NN，这是一个高效 NN 内核的集合。通过 CMSIS-NN，可以最小化 ARM Cortex-M
    处理器核心上 NNs 的内存占用，从而将 DL 模型适配到 IoT 设备中，同时实现正常的性能和能源效率。
- en: With regard to the bottleneck when running CNN layers on mobile GPUs, DeepMon
    [[164](#bib.bib164)] decomposes the matrices used in the CNN layers to accelerate
    the multiplications between high-dimensional matrices. By this means, high-dimensional
    matrix operations (particularly multiplications) in CNN layers are available in
    mobile GPUs and can be accelerated. In view of this work, various mobile GPUs,
    already deployed in edge devices, can be potentially explored with specific DL
    models and play a more important role in enabling edge DL.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 关于在移动 GPU 上运行 CNN 层时的瓶颈，DeepMon [[164](#bib.bib164)] 分解了 CNN 层中使用的矩阵，以加速高维矩阵之间的乘法。通过这种方式，CNN
    层中的高维矩阵操作（特别是乘法）可以在移动 GPU 上进行并加速。鉴于这项工作，已经在边缘设备中部署的各种移动 GPU 可以与特定的 DL 模型进行潜在探索，并在实现边缘
    DL 中发挥更重要的作用。
- en: Other than DL inference [[143](#bib.bib143), [164](#bib.bib164)], important
    factors that affect the performance of DL training on mobile CPUs and GPUs are
    discussed in [[168](#bib.bib168)]. Since commonly used DL models, such as VGG
    [[169](#bib.bib169)], are too large for the memory size of mainstream edge devices,
    a relatively small Mentee network [[170](#bib.bib170)] is adopted to evaluate
    DL training. Evaluation results point out that the size of DL models is crucial
    for training performance and the efficient fusion of mobile CPUs and GPUs is important
    for accelerating the training process.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 除了 DL 推断 [[143](#bib.bib143), [164](#bib.bib164)]，影响移动 CPU 和 GPU 上 DL 训练性能的重要因素在
    [[168](#bib.bib168)] 中进行了讨论。由于常用的 DL 模型，如 VGG [[169](#bib.bib169)]，对于主流边缘设备的内存大小来说过于庞大，因此采用了相对较小的
    Mentee 网络 [[170](#bib.bib170)] 来评估 DL 训练。评估结果指出，DL 模型的大小对训练性能至关重要，并且移动 CPU 和 GPU
    的高效融合对加速训练过程非常重要。
- en: VI-A2 FPGA-based Solutions
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A2 基于 FPGA 的解决方案
- en: Though GPU solutions are widely adopted in the cloud for DL training and inference,
    however, restricted by the tough power and cost budget in the edge, these solutions
    may not be available. Besides, edge nodes should be able to serve multiple DL
    computation requests at a time, and it makes simply using lightweight CPUs and
    GPUs impractical. Therefore, edge hardware based on Field Programmable Gate Array
    (FPGA) is explored to study their feasibility for edge DL.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 GPU 解决方案在云端广泛用于 DL 训练和推断，但由于边缘设备在功耗和成本预算上的限制，这些解决方案可能无法使用。此外，边缘节点应能够同时处理多个
    DL 计算请求，因此仅使用轻量级的 CPU 和 GPU 是不切实际的。因此，探索基于现场可编程门阵列（FPGA）的边缘硬件，以研究其在边缘 DL 中的可行性。
- en: FPGA-based edge devices can achieve CNN acceleration with arbitrarily sized
    convolution and reconfigurable pooling [[143](#bib.bib143)], and they perform
    faster than the state-of-the-art CPU and GPU implementations [[145](#bib.bib145)]
    with respect to RNN-based speech recognition applications while achieving higher
    energy efficiency. In [[52](#bib.bib52)], the design and setup of an FPGA-based
    edge platform are developed to admit DL computation offloading from mobile devices.
    On implementing the FPGA-based edge platform, a wireless router and an FPGA board
    are combined together. Testing this preliminary system with typical vision applications,
    the FPGA-based edge platform shows its advantages, in terms of both energy consumption
    and hardware cost, over the GPU (or CPU)-based one.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 基于 FPGA 的边缘设备可以通过任意尺寸的卷积和可重构的池化实现 CNN 加速 [[143](#bib.bib143)]，并且在 RNN 基于的语音识别应用中，相比最先进的
    CPU 和 GPU 实现，它们的性能更快，同时能效更高 [[145](#bib.bib145)]。在 [[52](#bib.bib52)] 中，开发了一种
    FPGA 基于的边缘平台，以允许将深度学习计算从移动设备卸载。在实现 FPGA 基于的边缘平台时，将无线路由器和 FPGA 板结合在一起。对这一初步系统进行典型视觉应用测试时，FPGA
    基于的边缘平台在能耗和硬件成本方面显示出相对于 GPU（或 CPU）基础平台的优势。
- en: 'Nevertheless, it is still pended to determine whether FPGAs or GPUs/CPUs are
    more suitable for edge computing, as shown in Table [IV](#S6.T4 "TABLE IV ‣ VI-A2
    FPGA-based Solutions ‣ VI-A Edge Hardware for DL ‣ VI Edge Computing for Deep
    Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey").
    Elaborated experiments are performed in [[171](#bib.bib171)] to investigate the
    advantages of FPGAs over GPUs: 1) capable of providing workload insensitive throughput;
    2) guaranteeing consistently high performance for high-concurrency DL computation;
    3) better energy efficiency. However, the disadvantage of FPGAs lies in that developing
    efficient DL algorithms on FPGA is unfamiliar to most programmers. Although tools
    such as Xilinx SDSoC can greatly reduce the difficulty [[52](#bib.bib52)], at
    least for now, additional works are still required to transplant the state-of-the-art
    DL models, programmed for GPUs, into the FPGA platform.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，尚未确定 FPGA 还是 GPU/CPU 更适合边缘计算，如表 [IV](#S6.T4 "表 IV ‣ VI-A2 基于 FPGA 的解决方案
    ‣ VI-A 边缘硬件用于深度学习 ‣ VI 边缘计算用于深度学习 ‣ 边缘计算与深度学习的融合：综合调查") 所示。在 [[171](#bib.bib171)]
    中进行了详细的实验，以研究 FPGA 相比于 GPU 的优势：1) 能提供与工作负载无关的吞吐量；2) 保证高并发深度学习计算的一致性高性能；3) 更好的能源效率。然而，FPGA
    的劣势在于开发高效的深度学习算法对于大多数程序员来说是不熟悉的。尽管像 Xilinx SDSoC 这样的工具可以大大降低难度 [[52](#bib.bib52)]，但至少目前，仍需额外的工作将针对
    GPU 编写的最先进的深度学习模型移植到 FPGA 平台上。
- en: 'TABLE IV: Comparison of Solutions for Edge nodes'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '表 IV: 边缘节点解决方案比较'
- en: '| Metrics |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 指标 |'
- en: '&#124; Preferred &#124;'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 优选 &#124;'
- en: '&#124; Hardware &#124;'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 硬件 &#124;'
- en: '| Analysis |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 分析 |'
- en: '| --- | --- | --- |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '|'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Resource &#124;'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 资源 &#124;'
- en: '&#124; overhead &#124;'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开销 &#124;'
- en: '| FPGA | FPGA can be optimized by customized designs. |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | FPGA 可以通过定制化设计进行优化。 |'
- en: '|'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DL &#124;'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深度学习 &#124;'
- en: '&#124; training &#124;'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 训练 &#124;'
- en: '| GPU | Floating point capabilities are better on GPU. |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| GPU | GPU 的浮点运算能力更强。 |'
- en: '|'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; DL &#124;'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深度学习 &#124;'
- en: '&#124; inference &#124;'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 推理 &#124;'
- en: '| FPGA | FPGA can be customized for specific DL models. |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | FPGA 可以针对特定的深度学习模型进行定制。 |'
- en: '|'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Interface &#124;'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 接口 &#124;'
- en: '&#124; scalability &#124;'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 可扩展性 &#124;'
- en: '| FPGA | It is more free to implement interfaces on FPGAs. |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | 在 FPGA 上实现接口更加自由。 |'
- en: '|'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Space &#124;'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 空间 &#124;'
- en: '&#124; occupation &#124;'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 占用 &#124;'
- en: '|'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CPU/ &#124;'
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CPU/ &#124;'
- en: '&#124; FPGA &#124;'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; FPGA &#124;'
- en: '| Lower power consumption of FPGA leads to smaller space occupation. |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| FPGA 的低功耗导致空间占用更小。 |'
- en: '| Compatibility |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| 兼容性 |'
- en: '&#124; CPU/ &#124;'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CPU/ &#124;'
- en: '&#124; GPU &#124;'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPU &#124;'
- en: '| CPUs and GPUs have more stable architecture. |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| CPU 和 GPU 具有更稳定的架构。 |'
- en: '|'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Development &#124;'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 开发 &#124;'
- en: '&#124; efforts &#124;'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 努力 &#124;'
- en: '|'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; CPU/ &#124;'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CPU/ &#124;'
- en: '&#124; GPU &#124;'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GPU &#124;'
- en: '| Toolchains and software libraries facilitate the practical development. |'
  id: totrans-304
  prefs: []
  type: TYPE_TB
  zh: '| 工具链和软件库有助于实际开发。 |'
- en: '|'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Energy &#124;'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 能耗 &#124;'
- en: '&#124; efficiency &#124;'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 效率 &#124;'
- en: '| FPGA | Customized designs can be optimized. |'
  id: totrans-308
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | 定制化设计可以进行优化。 |'
- en: '|'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Concurrency &#124;'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 并发性 &#124;'
- en: '&#124; support &#124;'
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 支持 &#124;'
- en: '| FPGA | FPGAs are suitable for stream process. |'
  id: totrans-312
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | FPGA 适合流处理。 |'
- en: '|'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Timing &#124;'
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时序 &#124;'
- en: '&#124; latency &#124;'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 延迟 &#124;'
- en: '| FPGA | Timing on FPGAs can be an order of magnitude faster than GPUs. |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| FPGA | FPGA上的时序可以比GPU快一个数量级。 |'
- en: VI-B Communication and Computation Modes for Edge DL
  id: totrans-317
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 边缘深度学习的通信和计算模式
- en: 'TABLE V: Details about Edge Communication and Computation Modes for DL'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 表 V：深度学习的边缘通信和计算模式详细信息
- en: '|  | Ref. | DL Model | End/Edge/Cloud | Network | Dependency | Objective |
    Performance |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '|  | 参考文献 | 深度学习模型 | 终端/边缘/云 | 网络 | 依赖 | 目标 | 性能 |'
- en: '| Integral Offloading |  &#124; DeepDecision &#124; &#124; [[172](#bib.bib172)]
    &#124;  | YOLO | Samsung Galaxy S7 / Server with a quad-core CPU at 2.7GHz, GTX970
    and 8GB RAM / N/A | Simulated WLAN & LAN | TensorFlow, Darknet | Consider the
    complex interaction between model accuracy, video quality, battery constraints,
    network data usage, and network conditions to determine an optimal offloading
    strategy | Achieve about 15 FPS video analytic while possessing higher accuracy
    than that of the baseline approaches |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 完全卸载 |  &#124; DeepDecision &#124; &#124; [[172](#bib.bib172)] &#124;  |
    YOLO | Samsung Galaxy S7 / 配备2.7GHz四核CPU、GTX970和8GB RAM的服务器 / 无 | 模拟的WLAN & LAN
    | TensorFlow, Darknet | 考虑模型准确性、视频质量、电池约束、网络数据使用和网络条件之间的复杂互动，以确定最佳的卸载策略 | 实现约15
    FPS的视频分析，同时具有比基线方法更高的准确性 |'
- en: '|  |  &#124; MASM &#124; &#124; [[173](#bib.bib173)] &#124;  | $\backslash$
    | Simulated devices / Cloudlet / N/A | $\backslash$ | $\backslash$ | Optimize
    workload assignment weights and the computation capacities of the VMs hosted on
    the Cloudlet | $\backslash$ |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '|  |  &#124; MASM &#124; &#124; [[173](#bib.bib173)] &#124;  | $\backslash$
    | 模拟设备 / 云小站 / 无 | $\backslash$ | $\backslash$ | 优化工作负载分配权重和Cloudlet上托管的VM的计算能力
    | $\backslash$ |'
- en: '|  |  &#124; EdgeEye &#124; &#124; [[108](#bib.bib108)] &#124;  | DetectNet,
    FaceNet | Cameras / Server with Intel i7-6700, GTX 1060 and 24GB RAM / N/A | Wi-Fi
    | TensorRT, ParaDrop, Kurento | Offload the live video analytics tasks to the
    edge using EdgeEye API, instead of using DL framework specific APIs, to provide
    higher inference performance | $\backslash$ |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '|  |  &#124; EdgeEye &#124; &#124; [[108](#bib.bib108)] &#124;  | DetectNet,
    FaceNet | 摄像头 / 配备Intel i7-6700、GTX 1060和24GB RAM的服务器 / 无 | Wi-Fi | TensorRT,
    ParaDrop, Kurento | 使用EdgeEye API将实时视频分析任务卸载到边缘，而不是使用特定于DL框架的API，以提供更高的推理性能 |
    $\backslash$ |'
- en: '| Partial Offloading |  &#124; DeepWear &#124; &#124; [[174](#bib.bib174)]
    &#124;  | MobileNet, GoogLeNet, DeepSense, etc. | Commodity smartwatches running
    Android Wear OS / Commodity smartphone running Android / N/A | Bluetooth | TensorFlow
    | Provide context-aware offloading, strategic model partition, and pipelining
    support to efficiently utilize the processing capacity of the edge | Bring up
    to 5.08$\times$ and 23.0$\times$ execution speedup, as well as 53.5% and 85.5%
    energy saving against wearable-only and handheld-only strategies, respectively
    |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 部分卸载 |  &#124; DeepWear &#124; &#124; [[174](#bib.bib174)] &#124;  | MobileNet,
    GoogLeNet, DeepSense等 | 运行Android Wear OS的普通智能手表 / 运行Android的普通智能手机 / 无 | 蓝牙 |
    TensorFlow | 提供上下文感知卸载、战略性模型分区和管道支持，以高效利用边缘的处理能力 | 提供高达5.08$\times$和23.0$\times$的执行加速，并相对于仅穿戴和仅手持策略节省53.5%和85.5%的能源
    |'
- en: '|  |  &#124; IONN &#124; &#124; [[175](#bib.bib175)] &#124;  | AlexNet | Embedded
    board Odroid XU4 / Server with an quad-core CPU at 3.6GHz, GTX 1080 Ti and 32GB
    RAM / Unspecified | WLAN | Caffe | Partitions the DNN layers and incrementally
    uploads the partitions to allow collaborative execution by the end and the edge
    (or cloud) to improves both the query performance and the energy consumption |
    Maintain almost the same uploading latency as integral uploading while largely
    improving query execution time |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '|  |  &#124; IONN &#124; &#124; [[175](#bib.bib175)] &#124;  | AlexNet | 嵌入式板Odroid
    XU4 / 配备3.6GHz四核CPU、GTX 1080 Ti和32GB RAM的服务器 / 未指定 | WLAN | Caffe | 对DNN层进行分区，并逐步上传这些分区，以允许终端和边缘（或云）进行协作执行，从而提高查询性能和能耗
    | 维持几乎相同的上传延迟，同时大幅提升查询执行时间 |'
- en: '| Vertical Collaboration |  [[176](#bib.bib176)]  | CNN, LSTM | Google Nexus
    9 / Server with an quad-core CPU and 16GB RAM / 3 desktops, each with i7-6850K
    and 2$\times$GTX 1080 Ti | WLAN & LAN | Apache Spark, TensorFlow | Perform data
    pre-processing and preliminary learning at the edge to reduce the network traffic,
    so as to speed up the computation in the cloud | Achieve 90% accuracy while reducing
    the execution time and the data transmission |'
  id: totrans-325
  prefs: []
  type: TYPE_TB
  zh: '| 垂直协作 |  [[176](#bib.bib176)]  | CNN, LSTM | Google Nexus 9 / 配备四核CPU和16GB
    RAM的服务器 / 3台桌面电脑，每台配有i7-6850K和2$\times$GTX 1080 Ti | WLAN & LAN | Apache Spark,
    TensorFlow | 在边缘进行数据预处理和初步学习，以减少网络流量，从而加快云端计算 | 实现90%的准确率，同时减少执行时间和数据传输 |'
- en: '|  |  &#124; Neurosurgeon &#124; &#124; [[12](#bib.bib12)] &#124;  | AlexNet,
    VGG, Deepface, MNIST, Kaldi, SENNA | Jetson TK1 mobile platform / Server with
    Intel Xeon E5$\times$2, NVIDIA Tesla K40 GPU and 256GB RAM / Unspecified | Wi-Fi,
    LTE & 3G | Caffe | Adapt to various DNN architectures, hardware platforms, wireless
    connections, and server load levels, and choose the partition point for best latency
    and best mobile energy consumption | Improve end-to-end latency by 3.1$\times$
    on average and up to 40.7$\times$, reduce mobile energy consumption by 59.5% on
    average and up to 94.7%, and improve data-center throughput by 1.5$\times$ on
    average and up to 6.7$\times$ |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '|  |  &#124; Neurosurgeon &#124; &#124; [[12](#bib.bib12)] &#124;  | AlexNet,
    VGG, Deepface, MNIST, Kaldi, SENNA | Jetson TK1移动平台 / 配备Intel Xeon E5$\times$2、NVIDIA
    Tesla K40 GPU和256GB RAM的服务器 / 未指明 | Wi-Fi, LTE & 3G | Caffe | 适应各种DNN架构、硬件平台、无线连接和服务器负载水平，并选择最佳分区点以实现最佳延迟和最佳移动能效
    | 平均提高端到端延迟3.1$\times$，最高可达40.7$\times$，平均减少移动能耗59.5%，最高可达94.7%，并且数据中心吞吐量平均提高1.5$\times$，最高可达6.7$\times$
    |'
- en: '|  |  [[161](#bib.bib161)]  | BranchyNet | $\backslash$ | $\backslash$ | $\backslash$
    | Minimize communication and resource usage for devices while allowing low-latency
    classification via EEoI | Reduce the communication cost by a factor of over 20$\times$
    while achieving 95% overall accuracy |'
  id: totrans-327
  prefs: []
  type: TYPE_TB
  zh: '|  |  [[161](#bib.bib161)]  | BranchyNet | $\backslash$ | $\backslash$ | $\backslash$
    | 最小化设备的通信和资源使用，同时通过EEoI实现低延迟分类 | 通信成本减少超过20$\times$，同时实现95%的总体准确率 |'
- en: '|  |  [[102](#bib.bib102)]  | Faster R-CNN | Xiaomi 6 / Server with i7 6700,
    GTX 980Ti and 32GB RAM / Work station with E5-2683 V3, GTX TitanXp$\times$4 and
    128GB RAM | WLAN & LAN | $\backslash$ | Achieve efficient object detection via
    wireless communications by interactions between the end, the edge and the cloud
    | Lose only 2.5% detection accuracy under the image compression ratio of 60% while
    significantly improving image transmission efficiency |'
  id: totrans-328
  prefs: []
  type: TYPE_TB
  zh: '|  |  [[102](#bib.bib102)]  | Faster R-CNN | 小米6 / 配备i7 6700、GTX 980Ti和32GB
    RAM的服务器 / 配备E5-2683 V3、GTX TitanXp$\times$4和128GB RAM的工作站 | WLAN & LAN | $\backslash$
    | 通过终端、边缘和云之间的交互实现高效的对象检测 | 在图像压缩比为60%的情况下，仅损失2.5%的检测准确率，同时显著提高图像传输效率 |'
- en: '|  |  &#124; VideoEdge &#124; &#124; [[109](#bib.bib109)] &#124;  | AlexNet,
    DeepFace, VGG16 | 10 Azure nodes emulating Cameras / 2 Azure nodes / 12 Azure
    nodes | Emulated hierarchical networks | $\backslash$ | Introduce dominant demand
    to identify the best tradeoff between multiple resources and accuracy | Improve
    accuracy by 5.4$\times$ compared to VideoStorm and only lose 6% accuracy of the
    optimum |'
  id: totrans-329
  prefs: []
  type: TYPE_TB
  zh: '|  |  &#124; VideoEdge &#124; &#124; [[109](#bib.bib109)] &#124;  | AlexNet,
    DeepFace, VGG16 | 10台Azure节点模拟摄像头 / 2台Azure节点 / 12台Azure节点 | 模拟的层次网络 | $\backslash$
    | 引入主导需求以识别多个资源与准确性之间的最佳权衡 | 与VideoStorm相比，准确性提高了5.4$\times$，且仅损失了6%的最佳准确性 |'
- en: '| Horizontal Collaboration |  &#124; MoDNN &#124; &#124; [[177](#bib.bib177)]
    &#124;  | VGG-16 | Multiple LG Nexus 5 / N/A / N/A | WLAN | MXNet | Partition
    already trained DNN models onto several mobile devices to accelerate DNN computations
    by alleviating device-level computing cost and memory usage | When the number
    of worker nodes increases from 2 to 4, MoDNN can speedup the DNN computation by
    2.17-4.28$\times$ |'
  id: totrans-330
  prefs: []
  type: TYPE_TB
  zh: '| Horizontal Collaboration |  &#124; MoDNN &#124; &#124; [[177](#bib.bib177)]
    &#124;  | VGG-16 | 多台LG Nexus 5 / 不适用 / 不适用 | WLAN | MXNet | 将已训练的DNN模型分配到多个移动设备上，以通过减轻设备级计算成本和内存使用来加速DNN计算
    | 当工作节点数量从2增加到4时，MoDNN可以使DNN计算速度提高2.17-4.28$\times$ |'
- en: '|  |  [[130](#bib.bib130)]  | VGGNet-E, AlexNet | Xilinx Virtex-7 FPGA simulating
    multiple end devices / N/A / N/A | On-chip simulation | Torch, Vivado HLS | Fuse
    the processing of multiple CNN layers and enable caching of intermediate data
    to save data transfer (bandwidth) | Reduce the total data transfer by 95%, from
    77MB down to 3.6MB per image |'
  id: totrans-331
  prefs: []
  type: TYPE_TB
  zh: '|  |  [[130](#bib.bib130)]  | VGGNet-E, AlexNet | Xilinx Virtex-7 FPGA模拟多个终端设备
    / 不适用 / 不适用 | 片上模拟 | Torch, Vivado HLS | 融合多个CNN层的处理并启用中间数据缓存以节省数据传输（带宽） | 将总数据传输量减少95%，从每张图像77MB降至3.6MB
    |'
- en: '|  |  &#124; DeepThings &#124; &#124; [[156](#bib.bib156)] &#124;  | YOLOv2
    | Perfromance-limited Raspberry Pi 3 Model B / Raspberry Pi 3 Model B as gateway
    / N/A | WLAN | Darknet | Employ a scalable Fused Tile Partitioning of CNN layers
    to minimize memory footprint while exposing parallelism and a novel work scheduling
    process to reduce overall execution latency | Reduce memory footprint by more
    than 68% without sacrificing accuracy, improve throughput by 1.7$\times$-2.2$\times$
    and speedup CNN inference by 1.7$\times$-3.5$\times$ |'
  id: totrans-332
  prefs: []
  type: TYPE_TB
- en: '|  |  &#124; DeepCham &#124; &#124; [[104](#bib.bib104)] &#124;  | AlexNet
    | Multiple LG G2 / Wi-Fi router connected with a Linux server / N/A | WLAN & LAN
    | Android Caffe, OpenCV, EdgeBoxes | Coordinate participating mobile users for
    collaboratively training a domain-aware adaptation model to improve object recognition
    accuracy | Improve the object recognition accuracy by 150% when compared to that
    achieved merely using a generic DL model |'
  id: totrans-333
  prefs: []
  type: TYPE_TB
- en: '|  |  &#124; LAVEA &#124; &#124; [[106](#bib.bib106)] &#124;  | OpenALPR |
    Raspberry PI 2 & Raspberry PI 3 / Servers with quad-core CPU and 4GB RAM / N/A
    | WLAN & LAN | Docker, Redis | Design various task placement schemes that are
    tailed for inter-edge collaboration to minimize the service response time | Have
    a speedup ranging from 1.3$\times$ to 4$\times$ (1.2$\times$ to 1.7$\times$) against
    running in local (client-cloud confguration) |'
  id: totrans-334
  prefs: []
  type: TYPE_TB
- en: 'Though on-device DL computation, illustrated in Sec. [V](#S5 "V Deep Learning
    Inference in Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"), can cater for lightweight DL services. Nevertheless, an independent
    end device still cannot afford intensive DL computation tasks. The concept of
    edge computing can potentially cope with this dilemma by offloading DL computation
    from end devices to edge or (and) the cloud. Accompanied by the edge architectures,
    DL-centric edge nodes can become the significant extension of cloud computing
    infrastructure to deal with massive DL tasks. In this section, we classify four
    modes for Edge DL computation, as exhibited in Fig. [16](#S6.F16 "Figure 16 ‣
    VI-B Communication and Computation Modes for Edge DL ‣ VI Edge Computing for Deep
    Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey").'
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f71bd06635fe73731402fa36b95abf79.png)'
  id: totrans-336
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Communication and computation modes for Edge DL.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
- en: VI-B1 Integral Offloading
  id: totrans-338
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The most natural mode of DL computation offloading is similar to the existed
    “end-cloud” computing, i.e., the end device sends its computation requests to
    the cloud for DL inference results (as depicted in Fig. [16](#S6.F16 "Figure 16
    ‣ VI-B Communication and Computation Modes for Edge DL ‣ VI Edge Computing for
    Deep Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")(a)). This kind of offloading is straightforward by extricating itself
    from DL task decomposition and combinatorial problems of resource optimization,
    which may bring about additional computation cost and scheduling delay, and thus
    simple to implement. In [[172](#bib.bib172)], the proposed distributed infrastructure
    DeepDecision ties together powerful edge nodes with less powerful end devices.
    In DeepDecision, DL inference can be performed on the end or the edge, depending
    on the tradeoffs between the inference accuracy, the inference latency, the DL
    model size, the battery level, and network conditions. With regard to each DL
    task, the end device decides whether locally processing or offloading it to an
    edge node.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 'DL计算卸载的最自然模式类似于现有的“端-云”计算，即终端设备将计算请求发送到云端以获得DL推断结果（如图[16](#S6.F16 "Figure 16
    ‣ VI-B Communication and Computation Modes for Edge DL ‣ VI Edge Computing for
    Deep Learning ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey")(a)所示）。这种卸载方式通过摆脱DL任务分解和资源优化组合问题的额外计算成本和调度延迟，显得直截了当，且易于实现。在[[172](#bib.bib172)]中，提出的分布式基础设施DeepDecision将强大的边缘节点与较弱的终端设备结合起来。在DeepDecision中，DL推断可以在终端或边缘上进行，具体取决于推断准确性、推断延迟、DL模型大小、电池电量和网络条件之间的权衡。对于每个DL任务，终端设备决定是本地处理还是卸载到边缘节点。'
- en: Further, the workload optimization among edge nodes should not be ignored in
    the offloading problem, since edge nodes are commonly resource-restrained compared
    to the cloud. In order to satisfy the delay and energy requirements of accomplishing
    a DL task with limited edge resources, providing DL models with different model
    sizes and performance in the edge can be adopted to fulfill one kind of task.
    Hence, multiple VMs or containers, undertaking different DL models separately,
    can be deployed on the edge node to process DL requests. Specifically, when a
    DL model with lower complexity can meet the requirements, it is selected as the
    serving model. For instance, by optimizing the workload assignment weights and
    computing capacities of VMs, MASM [[173](#bib.bib173)] can reduce the energy cost
    and delay while guaranteeing the DL inference accuracy.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，在卸载问题中，不应忽视边缘节点之间的工作负载优化，因为边缘节点通常相对于云资源有限。为了满足完成DL任务所需的延迟和能量要求，可以在边缘提供不同模型大小和性能的DL模型，以完成某种任务。因此，可以在边缘节点上部署多个虚拟机或容器，分别承担不同的DL模型来处理DL请求。具体来说，当较低复杂度的DL模型能够满足要求时，它将被选为服务模型。例如，通过优化虚拟机的工作负载分配权重和计算能力，MASM[[173](#bib.bib173)]可以在保证DL推断准确性的同时，减少能量消耗和延迟。
- en: VI-B2 Partial Offloading
  id: totrans-341
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B2 部分卸载
- en: 'Partially offloading the DL task to the edge is also feasible (as depicted
    in Fig. [16](#S6.F16 "Figure 16 ‣ VI-B Communication and Computation Modes for
    Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")(b)). An offloading system can be developed
    to enable online fine-grained partition of a DL task, and determine how to allocate
    these divided tasks to the end device and the edge node. As exemplified in [[178](#bib.bib178)],
    MAUI, capable of adaptively partitioning general computer programs, can conserve
    an order of magnitude energy by optimizing the task allocation strategies, under
    the network constraints. More importantly, this solution can decompose the whole
    program at runtime instead of manually partitioning of programmers before program
    deploying.'
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: '部分将深度学习（DL）任务卸载到边缘也是可行的（如图[16](#S6.F16 "Figure 16 ‣ VI-B Communication and
    Computation Modes for Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey")(b)所示）。可以开发一个卸载系统，以实现在线精细划分DL任务，并确定如何将这些划分后的任务分配给终端设备和边缘节点。如[[178](#bib.bib178)]中的例子，MAUI能够自适应地划分通用计算程序，通过优化任务分配策略，在网络约束下节省了一个数量级的能量。更重要的是，这种解决方案可以在运行时对整个程序进行分解，而不是在程序部署前由程序员手动划分。'
- en: Further, particularly for DL computation, DeepWear [[174](#bib.bib174)] abstracts
    a DL model as a Directed Acyclic Graph (DAG), where each node represents a layer
    and each edge represents the data flow among those layers. To efficiently determine
    partial offloading decisions, DeepWear first prunes the DAG by keeping only the
    computation-intensive nodes, and then grouping the repeated sub-DAGs. In this
    manner, the complex DAG can be transformed into a linear and much simpler one,
    thus enabling a linear complexity solution for selecting the optimal partition
    to offload.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，特别针对DL计算，DeepWear [[174](#bib.bib174)] 将DL模型抽象为有向无环图（DAG），其中每个节点代表一个层，每个边代表这些层之间的数据流。为了高效确定部分卸载决策，DeepWear首先通过保留仅计算密集的节点来修剪DAG，然后对重复的子DAG进行分组。通过这种方式，复杂的DAG可以转化为线性且简单的DAG，从而实现选择最佳卸载分区的线性复杂度解决方案。
- en: Nevertheless, uploading a part of the DL model to the edge nodes may still seriously
    delay the whole process of offloading DL computation. To deal with this challenge,
    an incremental offloading system IONN is proposed in [[175](#bib.bib175)]. Differ
    from packing up the whole DL model for uploading, IONN divides a DL model, prepared
    for uploading, into multiple partitions, and uploads them to the edge node in
    sequential. The edge node, receiving the partitioned models, incrementally builds
    the DL model as each partitioned model arrives, while being able to execute the
    offloaded partial DL computation even before the entire DL model is uploaded.
    Therefore, the key lies in the determination concerning the best partitions of
    the DL model and the uploading order. Specifically, on the one hand, DNN layers,
    performance benefit and uploading overhead of which are high and low, respectively,
    are preferred to be uploaded first, and thus making the edge node quickly build
    a partial DNN to achieve the best-expected query performance. On the other hand,
    unnecessary DNN layers, which cannot bring in any performance increase, are not
    uploaded and hence avoiding the offloading.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管如此，将DL模型的一部分上传到边缘节点仍可能严重延迟整个DL计算的卸载过程。为应对这一挑战，提出了一种增量卸载系统IONN，如[[175](#bib.bib175)]所示。与打包整个DL模型进行上传不同，IONN将准备上传的DL模型分割成多个分区，并依次上传到边缘节点。接收分割模型的边缘节点会随着每个分割模型的到达逐步构建DL模型，同时能够在整个DL模型上传之前执行已卸载的部分DL计算。因此，关键在于确定DL模型的最佳分区及上传顺序。具体来说，一方面，优先上传DNN层，因为这些层的性能收益高而上传开销低，从而使边缘节点能够快速构建部分DNN以实现最佳期望查询性能。另一方面，不上传那些无法带来性能提升的DNN层，从而避免卸载。
- en: VI-B3 Vertical Collaboration
  id: totrans-345
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B3 垂直协作
- en: 'Expected offloading strategies among “End-Edge” architecture, as discussed
    in Section [VI-B1](#S6.SS2.SSS1 "VI-B1 Integral Offloading ‣ VI-B Communication
    and Computation Modes for Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey") and [VI-B2](#S6.SS2.SSS2
    "VI-B2 Partial Offloading ‣ VI-B Communication and Computation Modes for Edge
    DL ‣ VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey"), are feasible for supporting less computation-intensive
    DL services and small-scale concurrent DL queries. However, when a large number
    of DL queries need to be processed at one time, a single edge node is certainly
    insufficient.'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: '在“端-边缘”架构中的预期卸载策略，如第[VI-B1](#S6.SS2.SSS1 "VI-B1 Integral Offloading ‣ VI-B
    Communication and Computation Modes for Edge DL ‣ VI Edge Computing for Deep Learning
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")节和[VI-B2](#S6.SS2.SSS2
    "VI-B2 Partial Offloading ‣ VI-B Communication and Computation Modes for Edge
    DL ‣ VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey")节所讨论的，适用于支持计算不那么密集的DL服务和小规模并发DL查询。然而，当需要同时处理大量DL查询时，单个边缘节点显然不够用。'
- en: A natural choice of collaboration is the edge performs data pre-processing and
    preliminary learning, when the DL tasks are offloaded. Then, the intermediate
    data, viz., the output of edge architectures, are transmitted to the cloud for
    further DL computation [[176](#bib.bib176)]. Nevertheless, the hierarchical structure
    of DNNs can be further excavated for fitting the vertical collaboration. In [[12](#bib.bib12)],
    all layers of a DNN are profiled on the end device and the edge node in terms
    of the data and computation characteristics, in order to generate performance
    prediction models. Based on these prediction models, wireless conditions and server
    load levels, the proposed Neurosurgeon evaluates each candidate point in terms
    of end-to-end latency or mobile energy consumption and partition the DNN at the
    best one. Then, it decides the allocation of DNN partitions, i.e., which part
    should be deployed on the end, the edge or the cloud, while achieving best latency
    and energy consumption of end devices.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
- en: 'By taking advantages of EEoI (Section [V-C](#S5.SS3 "V-C Early Exit of Inference
    (EEoI) ‣ V Deep Learning Inference in Edge ‣ Convergence of Edge Computing and
    Deep Learning: A Comprehensive Survey")), vertical collaboration can be more adapted.
    Partitions of a DNN can be mapped onto a distributed computing hierarchy (i.e.,
    the end, the edge and the cloud) and can be trained with multiple early exit points
    [[161](#bib.bib161)]. Therefore, the end and the edge can perform a portion of
    DL inference on themselves rather than directly requesting the cloud. Using an
    exit point after inference, results of DL tasks, the local device is confident
    about, can be given without sending any information to the cloud. For providing
    more accurate DL inference, the intermediate DNN output will be sent to the cloud
    for further inference by using additional DNN layers. Nevertheless, the intermediate
    output, e.g., high-resolution surveillance video streams, should be carefully
    designed much smaller than the raw input, therefore drastically reducing the network
    traffic required between the end and the edge (or the edge and the cloud).'
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
- en: Though vertical collaboration can be considered as an evolution of cloud computing,
    i.e., “end-cloud” strategy. Compared to the pure “end-edge” strategy, the process
    of vertical collaboration may possibly be delayed, due to it requires additional
    communication with the cloud. However, vertical collaboration has its own advantages.
    One side, when edge architectures cannot afford the flood of DL queries by themselves,
    the cloud architectures can share partial computation tasks and hence ensure servicing
    these queries. On the other hand, the raw data must be preprocessed at the edge
    before they are transmitted to the cloud. If these operations can largely reduce
    the size of intermediate data and hence reduce the network traffic, the pressure
    of backbone networks can be alleviated.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
- en: VI-B4 Horizontal Collaboration
  id: totrans-350
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In Section [VI-B3](#S6.SS2.SSS3 "VI-B3 Vertical Collaboration ‣ VI-B Communication
    and Computation Modes for Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey"), vertical collaboration
    is discussed. However, devices among the edge or the end can also be united without
    the cloud to process resource-hungry DL applications, i.e., horizontal collaboration.
    By this means, the trained DNN models or the whole DL task can be partitioned
    and allocated to multiple end devices or edge nodes to accelerate DL computation
    by alleviating the resource cost of each of them. MoDNN, proposed in [[177](#bib.bib177)],
    executes DL in a local distributed mobile computing system over a Wireless Local
    Area Network (WLAN). Each layer of DNNs is partitioned into slices to increase
    parallelism and to reduce memory footprint, and these slices are executed layer-by-layer.
    By the execution parallelism among multiple end devices, the DL computation can
    be significantly accelerated.'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
- en: With regard to specific DNN structures, e.g., CNN, a finer grid partitioning
    can be applied to minimize communication, synchronization, and memory overhead
    [[130](#bib.bib130)]. In [[156](#bib.bib156)], a Fused Tile Partitioning (FTP)
    method, able to divide each CNN layer into independently distributable tasks,
    is proposed. In contrast to only partitioning the DNN by layers as in [[12](#bib.bib12)],
    FTP can fuse layers and partitions them vertically in a grid fashion, hence minimizing
    the required memory footprint of participated edge devices regardless of the number
    of partitions and devices, while reducing communication and task migration cost
    as well. Besides, to support FTP, a distributed work-stealing runtime system,
    viz., idle edge devices stealing tasks from other devices with active work items
    [[156](#bib.bib156)], can adaptively distribute FTP partitions for balancing the
    workload of collaborated edge devices.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
- en: VI-C Tailoring Edge Frameworks for DL
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Though there are gaps between the computational complexity and energy efficiency
    required by DL and the capacity of edge hardware [[179](#bib.bib179)], customized
    edge DL frameworks can help efficiently 1) match edge platform and DL models;
    2) exploit underlying hardware in terms of performance and power; 3) orchestrate
    and maintain DL services automatically.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
- en: First, where to deploy DL services in edge computing (cellular) networks should
    be determined. The RAN controllers deployed at edge nodes are introduced in [[180](#bib.bib180)]
    to collect the data and run DL services, while the network controller, placed
    in the cloud, orchestrates the operations of the RAN controllers. In this manner,
    after running and feeding analytics and extract relevant metrics to DL models,
    these controllers can provide DL services to the users at the network edge.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
- en: 'Second, as the deployment environment and requirements of DL models can be
    substantially different from those during model development, customized operators,
    adopted in developing DL models with (Py)Torch, TensorFlow, etc., may not be directly
    executed with the DL framework at the edge. To bridge the gap between deployment
    and development, the authors of [[181](#bib.bib181)] propose to specify DL models
    in development using the deployment tool with an operator library from the DL
    framework deployed at the edge. Furthermore, to automate the selection and optimization
    of DL models, ALOHA [[182](#bib.bib182)] formulates a toolflow: 1) Automate the
    model design. It generates the optimal model configuration by taking into account
    the target task, the set of constraints and the target architecture; 2) Optimize
    the model configuration. It partitions the DL model and accordingly generates
    architecture-aware mapping information between different inference tasks and the
    available resources. 3) Automate the model porting. It translates the mapping
    information into adequate calls to computing and communication primitives exposed
    by the target architecture.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
- en: Third, the orchestration of DL models deployed at the edge should be addressed.
    OpenEI [[183](#bib.bib183)] defines each DL algorithm as a four-element tuple
    ¡Accuracy, Latency, Energy, Memory Footprint¿ to evaluate the Edge DL capability
    of the target hardware platform. Based on such tuple, OpenEI can select a matched
    model for a specific edge platform based on different Edge DL capabilities in
    an online manner. Zoo [[184](#bib.bib184)] provides a concise Domain-specific
    Language (DSL) to enable easy and type-safe composition of DL services. Besides,
    to enable a wide range of geographically distributed topologies, analytic engines,
    and DL services, ECO [[185](#bib.bib185)] uses a graph-based overlay network approach
    to 1) model and track pipelines and dependencies and then 2) map them to geographically
    distributed analytic engines ranging from small edge-based engines to powerful
    multi-node cloud-based engines. By this means, DL computation can be distributed
    as needed to manage cost and performance, while also supporting other practical
    situations, such as engine heterogeneity and discontinuous operations.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
- en: 'Nevertheless, these pioneer works are not ready to natively support valuable
    and also challenging features discussed in Section [VI-B](#S6.SS2 "VI-B Communication
    and Computation Modes for Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence
    of Edge Computing and Deep Learning: A Comprehensive Survey"), such as computation
    offloading and collaboration, which still calls for further development.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
- en: VI-D Performance Evaluation for Edge DL
  id: totrans-359
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Throughout the process of selecting appropriate edge hardware and associated
    software stacks for deploying different kinds of Edge DL services, it is necessary
    to evaluate their performance. Impartial evaluation methodologies can point out
    possible directions to optimize software stacks for specific edge hardware. In
    [[186](#bib.bib186)], for the first time, the performance of DL libraries is evaluated
    by executing DL inference on resource-constrained edge devices, pertaining to
    metrics like latency, memory footprint, and energy. In addition, particularly
    for Android smartphones, as one kind of edge devices with mobile CPUs or GPUs,
    AI Benchmark [[54](#bib.bib54)] extensively evaluates DL computation capabilities
    over various device configurations. Experimental results show that no single DL
    library or hardware platform can entirely outperform others, and loading the DL
    model may take more time than that of executing it. These discoveries imply that
    there are still opportunities to further optimize the fusion of edge hardware,
    edge software stacks, and DL libraries.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, a standard testbed for Edge DL is missing, which hinders the study
    of edge architectures for DL. To evaluate the end-to-end performance of Edge DL
    services, not only the edge computing architecture but also its combination with
    end devices and the cloud shall be established, such as openLEON [[187](#bib.bib187)]
    and CAVBench [[188](#bib.bib188)] particularly for vehicular scenarios. Furthermore,
    simulations of the control panel of managing DL services are still not dabbled.
    An integrated testbed, consisting of wireless links and networking models, service
    requesting simulation, edge computing platforms, cloud architectures, etc., is
    ponderable in facilitating the evolution of “Edge Computing for DL”.
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
- en: VII Deep Learning Training at Edge
  id: totrans-362
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Present DL training (distributed or not) in the cloud data center, namely cloud
    training, or cloud-edge training [[50](#bib.bib50)], viz., training data are preprocessed
    at the edge and then transmitted to cloud, are not appropriate for all kind of
    DL services, especially for DL models requiring locality and persistent training.
    Besides, a significant amount of communication resources will be consumed, and
    hence aggravating wireless and backbone networks if massive data are required
    to be continually transmitted from distributed end devices or edge nodes to the
    cloud. For example, with respect to surveillance applications integrated with
    object detection and target tracking, if end devices directly send a huge amount
    of real-time monitoring data to the cloud for persistent training, it will bring
    about high networking costs. In addition, merging all data into the cloud might
    violate privacy issues. All these challenges put forward the need for a novel
    training scheme against existing cloud training.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
- en: 'Naturally, the edge architecture, which consists of a large number of edge
    nodes with modest computing resources, can cater for alleviating the pressure
    of networks by processing the data or training at themselves. Training at the
    edge or potentially among “end-edge-cloud”, treating the edge as the core architecture
    of training, is called “DL Training at Edge”. Such kind of DL training may require
    significant resources to digest distributed data and exchange updates. Nonetheless,
    FL is emerging and is promised to address these issues. We summarize select works
    on FL in Table [VI](#S7.T6 "TABLE VI ‣ VII-C Communication-efficient FL ‣ VII
    Deep Learning Training at Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey").'
  id: totrans-364
  prefs: []
  type: TYPE_NORMAL
  zh: '自然地，由大量边缘节点组成的边缘架构，其计算资源适中，可以通过在自身处理数据或训练来缓解网络压力。边缘训练或潜在的“终端-边缘-云”训练，将边缘视为训练的核心架构，称为“边缘的深度学习训练”。这种深度学习训练可能需要大量资源来消化分布式数据并交换更新。然而，联邦学习（FL）正在兴起，并有望解决这些问题。我们在表格[VI](#S7.T6
    "TABLE VI ‣ VII-C Communication-efficient FL ‣ VII Deep Learning Training at Edge
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")中总结了关于FL的相关研究。'
- en: VII-A Distributed Training at Edge
  id: totrans-365
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-A 边缘的分布式训练
- en: 'Distributed training at the edge can be traced back to the work of [[189](#bib.bib189)],
    where a decentralized Stochastic Gradient Descent (SGD) method is proposed for
    the edge computing network to solve a large linear regression problem. However,
    this proposed method is designed for seismic imaging application and can not be
    generalized for future DL training, since the communication cost for training
    large scale DL models is extremely high. In [[190](#bib.bib190)], two different
    distributed learning solutions for edge computing environments are proposed. As
    depicted in Fig. [17](#S7.F17 "Figure 17 ‣ VII-A Distributed Training at Edge
    ‣ VII Deep Learning Training at Edge ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey"), one solution is that each end device trains
    a model based on local data, and then these model updates are aggregated at edge
    nodes. Another one is edge nodes train their own local models, and their model
    updates are exchanged and refined for constructing a global model. Though large-scale
    distributed training at edge evades transmitting bulky raw dataset to the cloud,
    the communication cost for gradients exchanging between edge devices is inevitably
    introduced. Besides, in practical, edge devices may suffer from higher latency,
    lower transmission rate and intermittent connections, and therefore further hindering
    the gradients exchanging between DL models belong to different edge devices.'
  id: totrans-366
  prefs: []
  type: TYPE_NORMAL
  zh: '边缘的分布式训练可以追溯到[[189](#bib.bib189)]的工作，其中提出了一种用于边缘计算网络的去中心化随机梯度下降（SGD）方法，以解决大规模线性回归问题。然而，这种方法是为地震成像应用设计的，不能推广到未来的深度学习训练，因为大规模深度学习模型的训练通信成本极高。在[[190](#bib.bib190)]中，提出了两种不同的边缘计算环境分布式学习解决方案。如图[17](#S7.F17
    "Figure 17 ‣ VII-A Distributed Training at Edge ‣ VII Deep Learning Training at
    Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")所示，一种解决方案是每个终端设备基于本地数据训练模型，然后将这些模型更新聚合在边缘节点。另一种方案是边缘节点训练各自的本地模型，然后交换和精炼这些模型更新，以构建一个全球模型。尽管大规模分布式边缘训练可以避免将大数据集传输到云端，但边缘设备之间梯度交换的通信成本不可避免地引入。此外，在实际应用中，边缘设备可能会遭遇更高的延迟、更低的传输速率和间歇性的连接，从而进一步阻碍不同边缘设备间的梯度交换。'
- en: '![Refer to caption](img/d408fa2fdadb8ed26b70427e1a0b3893.png)'
  id: totrans-367
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/d408fa2fdadb8ed26b70427e1a0b3893.png)'
- en: 'Figure 17: Distributed DL training at edge environments.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：边缘环境中的分布式深度学习训练。
- en: Most of the gradient exchanges are redundant, and hence updated gradients can
    be compressed to cut down the communication cost while preserving the training
    accuracy (such as DGC in [[191](#bib.bib191)]). First, DGC stipulates that only
    important gradients are exchanged, i.e., only gradients larger than a heuristically
    given threshold are transmitted. In order to avoid the information losing, the
    rest of the gradients are accumulated locally until they exceed the threshold.
    To be noted, gradients whether being immediately transmitted or accumulated for
    later exchanging will be coded and compressed, and hence saving the communication
    cost. Second, considering the sparse update of gradients might harm the convergence
    of DL training, momentum correction and local gradient clipping are adopted to
    mitigate the potential risk. By momentum correction, the sparse updates can be
    approximately equivalent to the dense updates. Before adding the current gradient
    to previous accumulation on each edge device locally, gradient clipping is performed
    to avoid the exploding gradient problem possibly introduced by gradient accumulation.
    Certainly, since partial gradients are delayed for updating, it might slow down
    the convergence. Hence, finally, for preventing the stale momentum from jeopardizing
    the performance of training, the momentum for delayed gradients is stopped, and
    less aggressive learning rate and gradient sparsity are adopted at the start of
    training to reduce the number of extreme gradients being delayed.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数梯度交换是冗余的，因此更新的梯度可以被压缩，以降低通信成本，同时保持训练精度（例如[[191](#bib.bib191)]中的DGC）。首先，DGC规定仅交换重要的梯度，即仅传输大于启发式给定阈值的梯度。为了避免信息丢失，其余梯度会在本地累积，直到超过阈值。需要注意的是，无论是立即传输还是累积以便后续交换的梯度都将被编码和压缩，从而节省通信成本。其次，考虑到稀疏梯度更新可能会影响深度学习训练的收敛性，采用动量修正和本地梯度裁剪来减轻潜在风险。通过动量修正，稀疏更新可以近似等同于密集更新。在每个边缘设备本地将当前梯度添加到之前的累积之前，会进行梯度裁剪，以避免因梯度累积可能引发的梯度爆炸问题。当然，由于部分梯度的更新被延迟，这可能会减缓收敛速度。因此，最终，为了防止过时的动量损害训练性能，对于延迟的梯度会停止动量，并在训练开始时采用较不激进的学习率和梯度稀疏性，以减少被延迟的极端梯度数量。
- en: With the same purpose of reducing the communication cost of synchronizing gradients
    and parameters during distributed training, two mechanisms can be combined together
    [[192](#bib.bib192)]. The first is transmitting only important gradients by taking
    advantage of sparse training gradients [[193](#bib.bib193)]. Hidden weights are
    maintained to record times of a gradient coordinate participating in gradient
    synchronization, and gradient coordinates with large hidden weight value are deemed
    as important gradients and will be more likely be selected in the next round training.
    On the other hand, the training convergence will be greatly harmed if residual
    gradient coordinates (i.e., less important gradients) are directly ignored, hence,
    in each training round, small gradient values are accumulated. Then, in order
    to avoid that these outdated gradients only contribute little influence on the
    training, momentum correction, viz., setting a discount factor to correct residual
    gradient accumulation, is applied.
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少分布式训练中同步梯度和参数的通信成本，可以将两种机制结合在一起[[192](#bib.bib192)]。第一种机制是通过利用稀疏训练梯度来仅传输重要的梯度[[193](#bib.bib193)]。隐藏权重用于记录梯度坐标参与梯度同步的次数，具有较大隐藏权重值的梯度坐标被认为是重要梯度，并且在下一轮训练中更有可能被选择。另一方面，如果直接忽略残余梯度坐标（即较不重要的梯度），训练收敛性会受到很大影响，因此在每轮训练中，较小的梯度值会被累积。然后，为了避免这些过时的梯度对训练的影响微乎其微，会应用动量修正，即设置折扣因子来修正残余梯度累积。
- en: Particularly, when training a large DL model, exchanging corresponded model
    updates may consume more resources. Using an online version of KD can reduce such
    kind of communication cost [[194](#bib.bib194)]. In other words, the model outputs
    rather the updated model parameters on each device are exchanged, making the training
    of large-sized local models possible. Besides communication cost, privacy issues
    should be concerned as well. For example, in [[195](#bib.bib195)], personal information
    can be purposely obtained from training data by making use of the privacy leaking
    of a trained classifier. The privacy protection of training dataset at the edge
    is investigated in [[196](#bib.bib196)]. Different from [[190](#bib.bib190), [191](#bib.bib191),
    [192](#bib.bib192)], in the scenario of [[196](#bib.bib196)], training data are
    trained at edge nodes as well as be uploaded to the cloud for further data analysis.
    Hence, Laplace noises [[197](#bib.bib197)] are added to these possibly exposed
    training data for enhancing the training data privacy assurance.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
- en: VII-B Vanilla Federated Learning at Edge
  id: totrans-372
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In Section [VII-A](#S7.SS1 "VII-A Distributed Training at Edge ‣ VII Deep Learning
    Training at Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"), the holistic network architecture is explicitly separated, specifically,
    training is limited at the end devices or the edge nodes independently instead
    of among both of them. Certainly, by this means, it is simple to orchestrate the
    training process since there is no need to deal with heterogeneous computing capabilities
    and networking environments between the end and the edge. Nonetheless, DL training
    should be ubiquitous as well as DL inference. Federated Learning (FL) [[198](#bib.bib198),
    [199](#bib.bib199)] is emerged as a practical DL training mechanism among the
    end, the edge and the cloud. Though in the framework of native FL, modern mobile
    devices are taken as the clients performing local training. Naturally, these devices
    can be extended more widely in edge computing [[200](#bib.bib200), [201](#bib.bib201)].
    End devices, edge nodes and servers in the cloud can be equivalently deemed as
    clients in FL. These clients are assumed capable of handling different levels
    of DL training tasks, and hence contribute their updates to the global DL model.
    In this section, fundamentals of FL are discussed.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
- en: 'Without requiring uploading data for central cloud training, FL [[198](#bib.bib198),
    [199](#bib.bib199)] can allow edge devices to train their local DL models with
    their own collected data and upload only the updated model instead. As depicted
    in Fig. [18](#S7.F18 "Figure 18 ‣ VII-B Vanilla Federated Learning at Edge ‣ VII
    Deep Learning Training at Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"), FL iteratively solicits a random set of edge devices
    to 1) download the global DL model from an aggregation server (use “server” in
    following), 2) train their local models on the downloaded global model with their
    own data, and 3) upload only the updated model to the server for model averaging.
    Privacy and security risks can be significantly reduced by restricting the training
    data to only the device side, and thus avoiding the privacy issues as in [[195](#bib.bib195)],
    incurred by uploading training data to the cloud. Besides, FL introduces FederatedAveraging
    to combine local SGD on each device with a server performing model averaging.
    Experimental results corroborate FederatedAveraging is robust to unbalanced and
    non-IID data and can facilitate the training process, viz., reducing the rounds
    of communication needed to train a DL model.'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/52278b866b963331598f4bccf7eda2fa.png)'
  id: totrans-375
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: Federated learning among hierarchical network architectures.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
- en: 'To summarize, FL can deal with several key challenges in edge computing networks:
    1) Non-IID training data. Training data on each device is sensed and collected
    by itself. Hence, any individual training data of a device will not be able to
    represent the global one. In FL, this can be met by FederatedAveraging; 2) Limited
    communication. Devices might potentially off-line or located in a poor communication
    environment. Nevertheless, performing more training computation on resource-sufficient
    devices can cut down communication rounds needed for global model training. In
    addition, FL only selects a part of devices to upload their updates in one round,
    therefore successfully handling the circumstance where devices are unpredictably
    off-line; 3) Unbalanced contribution. It can be tackled by FederatedAveraging,
    specifically, some devices may have less free resources for FL, resulting in varying
    amounts of training data and training capability among devices; 4) Privacy and
    security. The data need to be uploaded in FL is only the updated DL model. Further,
    secure aggregation and differential privacy [[197](#bib.bib197)], which are useful
    in avoiding the disclosure of privacy-sensitive data contained in local updates,
    can be applied naturally.'
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
- en: VII-C Communication-efficient FL
  id: totrans-378
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In FL, raw training data are not required to be uploaded, thus largely reducing
    the communication cost. However, FL still needs to transmit locally updated models
    to the central server. Supposing the DL model size is large enough, uploading
    updates, such as model weights, from edge devices to the central server may also
    consume nonnegligible communication resources. To meet this, we can let FL clients
    communicate with the central server periodically (rather continually) to seek
    consensus on the shared DL model [[202](#bib.bib202)]. In addition, structured
    update, sketched update can help enhance the communication efficiency when clients
    uploading updates to the server as well. Structured update means restricting the
    model updates to have a pre-specified structure, specifically, 1) low-rank matrix;
    or 2) sparse matrix [[203](#bib.bib203), [202](#bib.bib202)]. On the other hand,
    for sketched update, full model updates are maintained. But before uploading them
    for model aggregation, combined operations of subsampling, probabilistic quantization,
    and structured random rotations are performed to compress the full updates [[203](#bib.bib203)].
    FedPAQ [[204](#bib.bib204)] simultaneously incorporates these features and provides
    near-optimal theoretical guarantees for both strongly convex and non-convex loss
    functions, while empirically demonstrating the communication-computation tradeoff.
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
- en: Different from only investigating on reducing communication cost on the uplink,
    [[205](#bib.bib205)] takes both server-to-device (downlink) and device-to-server
    (uplink) communication into consideration. For the downlink, the weights of the
    global DL model are reshaped into a vector, and then subsampling and quantization
    are applied [[203](#bib.bib203)]. Naturally, such kind of model compression is
    lossy, and unlike on the uplink (multiple edge devices are uploading their models
    for averaging), the loss cannot be mitigated by averaging on the downlink. Kashin’s
    representation [[206](#bib.bib206)] can be utilized before subsampling as a basis
    transform to mitigate the error incurred by subsequent compression operations.
    Furthermore, for the uplink, each edge device is not required to train a model
    based on the whole global model locally, but only to train a smaller sub-model
    or pruned model [[207](#bib.bib207)] instead. Since sub-models and pruned models
    are more lightweight than the global model, the amount of data in updates uploading
    is reduced.
  id: totrans-380
  prefs: []
  type: TYPE_NORMAL
- en: 'Computation resources of edge devices are scarce compared to the cloud. Additional
    challenges should be considered to improve communication efficiencies: 1) Computation
    resources are heterogeneous and limited at edge devices; 2) Training data at edge
    devices may be distributed non-uniformly [[208](#bib.bib208), [209](#bib.bib209),
    [210](#bib.bib210)]. For more powerful edge devices, ADSP [[211](#bib.bib211)]
    lets them continue training while committing model aggregation at strategically
    decided intervals. For general cases, based on the deduced convergence bound for
    distributed learning with non-IID data distributions, the aggregation frequency
    under given resource budgets among all participating devices can be optimized
    with theoretical guarantees [[208](#bib.bib208)]. Astraea [[212](#bib.bib212)]
    reduces $92\%$ communication traffic by designing a mediator-based multi-client
    rescheduling strategy. On the one hand, Astraea leverages data augmentation [5]
    to alleviate the defect of non-uniformly distributed training data. On the other
    hand, Astraea designs a greedy strategy for mediator-based rescheduling, in order
    to assign clients to the mediators. Each mediator traverses the data distribution
    of all unassigned clients to select the appropriate participating clients, aiming
    to make the mediator’s data distribution closest to the uniform distribution,
    i.e., minimizing the KullbackLeibler divergence [[213](#bib.bib213)] between mediator’s
    data distribution and uniform distribution. When a mediator reaches the max assigned
    clients limitation, the central server will create a new mediator and repeat the
    process until all clients have been assigned with training tasks.'
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
- en: Aiming to accelerate the global aggregation in FL, [[214](#bib.bib214)] takes
    advantage of over-the-air computation [[215](#bib.bib215), [216](#bib.bib216),
    [217](#bib.bib217)], of which the principle is to explore the superposition property
    of a wireless multiple-access channel to compute the desired function by the concurrent
    transmission of multiple edge devices. The interferences of wireless channels
    can be harnessed instead of merely overcoming them. During the transmission, concurrent
    analog signals from edge devices can be naturally weighed by channel coefficients.
    Then the server only needs to superpose these reshaped weights as the aggregation
    results, nonetheless, without other aggregation operations.
  id: totrans-382
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VI: Summary of the Selected Works on FL'
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Ref. | DL Model | Scale | Dependency | Main Idea | Key Metrics or Performance
    |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-385
  prefs: []
  type: TYPE_TB
- en: '| Vanilla FL | [[198](#bib.bib198)] | FCNN, CNN, LSTM | Up to $5\mathrm{e}{5}$
    clients | TensorFlow | Leave the training data distributed on the mobile devices,
    and learns a shared model by aggregating locally-training updates | Communication
    rounds reduction: 10-100$\times$ |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
- en: '| [[199](#bib.bib199)] | RNN | Up to $1.5\mathrm{e}{6}$ clients | TensorFlow
    | Pace steering for scalable FL | Scalability improvement: up to 1.5e6 clients
    |'
  id: totrans-387
  prefs: []
  type: TYPE_TB
- en: '| Communication-efficient FL | [[202](#bib.bib202)] | ResNet18 | 4 clients
    per cluster / 7 clusters | $\backslash$ | Gradient sparsification; Periodic averaging
    | Top 1 accuracy; Communication latency reduction |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
- en: '| [[203](#bib.bib203)] | CNN, LSTM | Up to $1\mathrm{e}{3}$ clients | $\backslash$
    | Sketched updates | Communication cost reduction: by two orders of magnitude
    |'
  id: totrans-389
  prefs: []
  type: TYPE_TB
- en: '| [[205](#bib.bib205)] | CNN | Up to 500 clients | TensorFlow | Lossy compression
    on the global model; Federated Dropout | Downlink reduction: 14$\times$; Uplink
    reduction: 28$\times$; Local computation reduction: 1.7$\times$ |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
- en: '| [[211](#bib.bib211)] | CNN, RNN | Up to 37 clients | TensorFlow | Let faster
    clients continue with their mini-batch training to keep overall synchronization
    | Convergence acceleration: 62.4% |'
  id: totrans-391
  prefs: []
  type: TYPE_TB
- en: '| [[208](#bib.bib208)] | CNN | 5-500 clients (simulation); 3 Raspberry Pi and
    2 laptops (testbed) | $\backslash$ | Design a control algorithm that determines
    the best trade-off between local update and global aggregation | Training accuracy
    under resource budget |'
  id: totrans-392
  prefs: []
  type: TYPE_TB
- en: '| [[204](#bib.bib204)] | FCNN | 50 clients | $\backslash$ | Periodic averaging;
    Partial device participation; Quantized message-passing | Total training loss
    and time |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
- en: '| [[212](#bib.bib212)] | CNN | 500 clients | $\backslash$ | Global data distribution
    based data augmentation; Mediator based multi-client rescheduling | Top 1 accuracy
    imrpovement: 5.59%-5.89%; Communication traffic reduction: 92% |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
- en: '| [[207](#bib.bib207)] | LeNet, CNN, VGG11 | 10 Raspberry Pi | Py(Torch) |
    Jointly trains and prunes the model in a federated manner | Communication and
    computation load reduction |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
- en: '| Resource -optimized FL | [[218](#bib.bib218)] | AlexNet, LeNet | Multiple
    Nvidia Jetson Nano | $\backslash$ | Partially train the model by masking a particular
    number of resource-intensive neurons | Training acceleration: 2$\times$; Model
    accuracy improvement: 4% |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
- en: '| [[219](#bib.bib219)] | $\backslash$ | Up to 50 clients | TensorFlow | Jointly
    optimize FL parameters and resources of user equipments | Convergence rate; Test
    accuracy |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
- en: '| [[220](#bib.bib220)] | $\backslash$ | 20 clients / 1 BS | $\backslash$ |
    Jointly optimize wireless resource allocation and client selection | Reduction
    of the FL loss function value: up to 16% |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
- en: '| [[221](#bib.bib221)] | LSTM | 23-1,101 clients | TensorFlow | Modify FL training
    objectives with $\alpha$-fairness | Fairness; Training accuracy |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
- en: '| Security -enhanced FL | [[201](#bib.bib201)] | CNN | 100 clients | MXNET
    | Use the trimmed mean as a robust aggregation | Top 1 accuracy against data poisoning
    |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
- en: '| [[222](#bib.bib222)] | $\backslash$ | $2\mathrm{e}{10}$-$2\mathrm{e}{14}$
    clients | $\backslash$ | Use Secure Aggregation to protect the privacy of each
    client’s model gradient | Communication expansion: 1.73$\times$-1.98$\times$ |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
- en: '| [[223](#bib.bib223)] | $\backslash$ | 10 clients | $\backslash$ | Leverage
    blockchain to exchange and verify model updates of local training | Learning completion
    latency |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
- en: VII-D Resource-optimized FL
  id: totrans-403
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When FL deploys the same neural network model to heterogeneous edge devices,
    devices with weak computing power (stragglers) may greatly delay the global model
    aggregation. Although the training model can be optimized to accelerate the stragglers,
    due to the limited resources of heterogeneous equipment, the optimized model usually
    leads to diverged structures and severely defect the collaborative convergence.
    ELFISH [[218](#bib.bib218)] first analyzes the computation consumption of the
    model training in terms of the time cost, memory usage, and computation workload.
    Under the guidance of the model analysis, which neurons need to be masked in each
    layer to ensure that the computation consumption of model training meets specific
    resource constraints can be determined. Second, unlike generating a deterministically
    optimized model with diverged structures, different sets of neurons will be dynamically
    masked in each training period and recovered and updated during the subsequent
    aggregation period, thereby ensuring comprehensive model updates overtime. It
    is worth noting that although ELFISH improves the training speed by 2$\times$
    through resource optimization, the idea of ELFISH is to make all stragglers work
    synchronously, the synchronous aggregation of which may not able to handle extreme
    situations.
  id: totrans-404
  prefs: []
  type: TYPE_NORMAL
- en: When FL is deployed in a mobile edge computing scenario, the wall-clock time
    of FL will mainly depend on the number of clients and their computing capabilities.
    Specifically, the total wall-clock time of FL includes not only the computation
    time but also the communication time of all clients. On the one hand, the computation
    time of a client depends on the computing capability of the clients and local
    data sizes. On the other hand, the communication time correlates to clients’ channel
    gains, transmission power, and local data sizes. Therefore, to minimize the wall-clock
    training time of the FL, appropriate resource allocation for the FL needs to consider
    not only FL parameters, such as accuracy level for computation-communication trade-off,
    but also the resources allocation on the client side, such as power and CPU cycles.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: However, minimizing the energy consumption of the client and the FL wall-clock
    time are conflicting. For example, the client can save energy by always maintain
    its CPU at low frequency, but this will definitely increase training time. Therefore,
    in order to strike a balance between energy cost and training time, the authors
    of [[219](#bib.bib219)] first design a new FL algorithm FEDL for each client to
    solve its local problem approximately till a local accuracy level achieved. Then,
    by using Pareto efficiency model [[224](#bib.bib224)], they formulate a non-convex
    resource allocation problem for FEDL over wireless networks to capture the trade-off
    between the clients’ energy cost and the FL wall-clock time). Finally, by exploiting
    the special structure of that problem, they decompose it into three sub-problems,
    and accordingly derive closed-form solutions and characterize the impact of the
    Pareto-efficient controlling knob to the optimal.
  id: totrans-406
  prefs: []
  type: TYPE_NORMAL
- en: 'Since the uplink bandwidth for transmitting model updates is limited, the BS
    must optimize its resource allocation while the user must optimize its transmit
    power allocation to reduce the packet error rates of each user, thereby improving
    FL performance. To this end, the authors of [[220](#bib.bib220)] formulate resource
    allocation and user selection of FL into a joint optimization problem, the goal
    of which is to minimize the value of the FL loss function while meeting the delay
    and energy consumption requirements. To solve this problem, they first derive
    a closed-form expression for the expected convergence rate of the FL in order
    to establish an explicit relationship between the packet error rates and the FL
    performance. Based on this relationship, the optimization problem can be reduced
    to a mixed-integer nonlinear programming problem, and then solved as follows:
    First, find the optimal transmit power under a given user selection and resource
    block allocation; Then, transform the original optimization problem into a binary
    matching problem; Finally, using Hungarian algorithm [[225](#bib.bib225)] to find
    the best user selection and resource block allocation strategy.'
  id: totrans-407
  prefs: []
  type: TYPE_NORMAL
- en: The number of devices involved in FL is usually large, ranging from hundreds
    to millions. Simply minimizing the average loss in such a large network may be
    not suited for the required model performance on some devices. In fact, although
    the average accuracy under vanilla FL is high, the model accuracy required for
    individual devices may not be guaranteed. To this end, based on the utility function
    $\alpha$-fairness [[226](#bib.bib226)] used in fair resource allocation in wireless
    networks, the authors of [[221](#bib.bib221)] define a fair-oriented goal $q$-FFL
    for joint resource optimization. $q$-FFL minimizes an aggregate re-weighted loss
    parameterized by $q$, so that devices with higher loss are given higher relative
    weight, thus encouraging less variance (i.e., more fairness) in the accuracy distribution.
    Adaptively minimizing $q$-FFL avoids the burden of hand-crafting fairness constraints,
    and can adjust the goal according to the required fairness dynamically, achieving
    the effect of reducing the variance of accuracy distribution among participated
    devices.
  id: totrans-408
  prefs: []
  type: TYPE_NORMAL
- en: VII-E Security-enhanced FL
  id: totrans-409
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In vanilla FL, local data samples are processed on each edge device. Such a
    manner can prevent the devices from revealing private data to the server. However,
    the server also should not trust edge devices completely, since devices with abnormal
    behavior can forge or poison their training data, which results in worthless model
    updates, and hence harming the global model. To make FL capable of tolerating
    a small number of devices training on the poisoned dataset, robust federated optimization
    [[201](#bib.bib201)] defines a trimmed mean operation. By filtering out not only
    the the values produced by poisoned devices but also the natural outliers in the
    normal devices, robust aggregation protecting the global model from data poisoning
    is achieved.
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
- en: Other than intentional attacks, passive adverse effects on the security, brought
    by unpredictable network conditions and computation capabilities, should be concerned
    as well. FL must be robust to the unexpectedly drop out of edge devices, or else
    once a device loses its connection, the synchronization of FL in one round will
    be failed. To solve this issue, Secure Aggregation protocol is proposed in [[222](#bib.bib222)]
    to achieve the robustness of tolerating up to one-third devices failing to timely
    process the local training or upload the updates.
  id: totrans-411
  prefs: []
  type: TYPE_NORMAL
- en: In turn, malfunctions of the aggregation server in FL may result in inaccurate
    global model updates and thereby distorting all local model updates. Besides,
    edge devices (with a larger number of data samples) may be less willing to participate
    FL with others (with less contribution). Therefore, in [[223](#bib.bib223)], combining
    Blockchain and FL as BlockFL is proposed to realize 1) locally global model updating
    at each edge device rather a specific server, ensuring device malfunction cannot
    affect other local updates when updating the global model; 2) appropriate reward
    mechanism for stimulating edge devices to participate in FL.
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
- en: VIII Deep Learning for Optimizing Edge
  id: totrans-413
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'DNNs (general DL models) can extract latent data features, while DRL can learn
    to deal with decision-making problems by interacting with the environment. Computation
    and storage capabilities of edge nodes, along with the collaboration of the cloud,
    make it possible to use DL to optimize edge computing networks and systems. With
    regard to various edge management issues such as edge caching, offloading, communication,
    security protection, etc., 1) DNNs can process user information and data metrics
    in the network, as well as perceiving the wireless environment and the status
    of edge nodes, and based on these information 2) DRL can be applied to learn the
    long-term optimal resource management and task scheduling strategies, so as to
    achieve the intelligent management of the edge, viz., intelligent edge as shown
    in Table [VII](#S8.T7 "TABLE VII ‣ VIII-B DL for Optimizing Edge Task Offloading
    ‣ VIII Deep Learning for Optimizing Edge ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey").'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
- en: VIII-A DL for Adaptive Edge Caching
  id: totrans-415
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: From Content Delivery Network (CDN) [[227](#bib.bib227)] to caching contents
    in cellular networks, caching in the network have been investigated over the years
    to deal with soaring demand for multimedia services [[228](#bib.bib228)]. Aligned
    with the concept of pushing contents near to users, edge caching [[229](#bib.bib229)],
    is deemed as a promising solution for further reducing the redundant data transmission,
    easing the pressure of cloud data centers and improving the QoE.
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
- en: 'Edge caching meets two challenges: 1) the content popularity distribution among
    the coverage of edge nodes is hard to estimate, since it may be different and
    change with spatio-temporal variation [[230](#bib.bib230)]; 2) in view of massive
    heterogeneous devices in edge computing environments, the hierarchical caching
    architecture and complex network characteristics further perplex the design of
    content caching strategy [[231](#bib.bib231)]. Specifically, the optimal edge
    caching strategy can only be deduced when the content popularity distribution
    is known. However, users’ predilection for contents is actually unknown since
    the mobility, personal preference and connectivity of them may vary all the time.
    In this section, DL for determining edge caching policies, as illustrated in Fig.
    [19](#S8.F19 "Figure 19 ‣ VIII-A DL for Adaptive Edge Caching ‣ VIII Deep Learning
    for Optimizing Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"), are discussed.'
  id: totrans-417
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/aa0f251ebd7cd7aa7715b610a00e9ff6.png)'
  id: totrans-418
  prefs: []
  type: TYPE_IMG
- en: 'Figure 19: DL and DRL for optimizing the edge caching policy.'
  id: totrans-419
  prefs: []
  type: TYPE_NORMAL
- en: VIII-A1 Use Cases of DNNs
  id: totrans-420
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Traditional caching methods are generally with high computational complexity
    since they require a large number of online optimization iterations to determine
    1) the features of users and contents and 2) the strategy of content placement
    and delivery.
  id: totrans-421
  prefs: []
  type: TYPE_NORMAL
- en: For the first purpose, DL can be used to process raw data collected from the
    mobile devices of users and hence extract the features of the users and content
    as a feature-based content popularity matrix. By this means, the popular content
    at the core network is estimated by applying feature-based collaborative filtering
    to the popularity matrix [[232](#bib.bib232)].
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
- en: For the second purpose, when using DNNs to optimize the strategy of edge caching,
    online heavy computation iterations can be avoided by offline training. A DNN,
    which consists of an encoder for data regularization and a followed hidden layer,
    can be trained with solutions generated by optimal or heuristic algorithms and
    be deployed to determine the cache policy [[233](#bib.bib233)], hence avoiding
    online optimization iterations. Similarly, in [[234](#bib.bib234)], inspired by
    the fact that the output of optimization problem about partial cache refreshing
    has some patterns, an MLP is trained for accepting the current content popularity
    and the last content placement probability as input to generate the cache refresh
    policy.
  id: totrans-423
  prefs: []
  type: TYPE_NORMAL
- en: As illustrated in [[233](#bib.bib233)][[234](#bib.bib234)], the complexity of
    optimization algorithms can be transferred to the training of DNNs, and thus breaking
    the practical limitation of employing them. In this case, DL is used to learn
    input-solution relations, and DNN-based methods are only available when optimization
    algorithms for the original caching problem exist. Therefore, the performance
    of DNN-based methods bounds by fixed optimization algorithms and is not self-adapted.
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
- en: In addition, DL can be utilized for customized edge caching. For example, to
    minimize content-downloading delay in the self-driving car, an MLP is deployed
    in the cloud to predict the popularity of contents to be requested, and then the
    outputs of MLP are delivered to the edge nodes (namely MEC servers at RSUs in
    [[235](#bib.bib235)]). According to these outputs, each edge node caches contents
    that are most likely to be requested. On self-driving cars, CNN is chosen to predict
    the age and gender of the owner. Once these features of owners are identified,
    $k$-means clustering [[236](#bib.bib236)] and binary classification algorithms
    are used to determine which contents, already cached in edge nodes, should be
    further downloaded and cached from edge nodes to the car. Moreover, concerning
    taking full advantage of users’ features, [[237](#bib.bib237)] points out that
    the user’s willing to access the content in different environments is varying.
    Inspired by this, RNN is used to predict the trajectories of users. And based
    on these predictions, all contents of users’ interests are then prefetched and
    cached in advance at the edge node of each predicted location.
  id: totrans-425
  prefs: []
  type: TYPE_NORMAL
- en: VIII-A2 Use Cases of DRL
  id: totrans-426
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The function of DNNs described in Section [VIII-A1](#S8.SS1.SSS1 "VIII-A1 Use
    Cases of DNNs ‣ VIII-A DL for Adaptive Edge Caching ‣ VIII Deep Learning for Optimizing
    Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")
    can be deemed as a part of the whole edge caching solution, i.e., the DNN itself
    does not deal with the whole optimization problem. Different from these DNNs-based
    edge caching, DRL can exploit the context of users and networks and take adaptive
    strategies for maximizing the long-term caching performance [[238](#bib.bib238)]
    as the main body of the optimization method. Traditional RL algorithms are limited
    by the requirement for handcrafting features and the flaw that hardly handling
    high-dimensional observation data and actions [[239](#bib.bib239)]. Compared to
    traditional RL irrelevant to DL, such as $Q$-learning [[240](#bib.bib240)] and
    Multi-Armed Bandit (MAB) learning [[230](#bib.bib230)], the advantage of DRL lies
    in that DNNs can learn key features from the raw observation data. The integrated
    DRL agent combining RL and DL can optimize its strategies with respect to cache
    management in edge computing networks directly from high-dimensional observation
    data.'
  id: totrans-427
  prefs: []
  type: TYPE_NORMAL
- en: In [[241](#bib.bib241)], DDPG is used to train a DRL agent, in order to maximize
    the long-term cache hit rate, to make proper cache replacement decisions. This
    work considers a scenario with a single BS, in which the DRL agent decides whether
    to cache the requested contents or replace the cached contents. While training
    the DRL agent, the reward is devised as the cache hit rate. In addition, Wolpertinger
    architecture [[242](#bib.bib242)] is utilized to cope with the challenge of large
    action space. In detail, a primary action set is first set for the DRL agent and
    then using $k$NN to map the practical action inputs to one out of this set. In
    this manner, the action space is narrowed deliberately without missing the optimal
    caching policy. Compared DQL-based algorithms searching the whole action space,
    the trained DRL agent with DDPG and Wolpertinger architecture is able to achieve
    competitive cache hit rates while reducing the runtime.
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
- en: VIII-B DL for Optimizing Edge Task Offloading
  id: totrans-429
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Edge computing allows edge devices offload part of their computing tasks to
    the edge node [[243](#bib.bib243)], under constraints of energy, delay, computing
    capability, etc. As shown in Fig. [20](#S8.F20 "Figure 20 ‣ VIII-B DL for Optimizing
    Edge Task Offloading ‣ VIII Deep Learning for Optimizing Edge ‣ Convergence of
    Edge Computing and Deep Learning: A Comprehensive Survey"), these constraints
    put forward challenges of identifying 1) which edge nodes should receive tasks,
    2) what ratio of tasks edge devices should offload and 3) how many resources should
    be allocated to these tasks. To solve this kind of task offloading problem is
    NP-hard [[244](#bib.bib244)], since at least combination optimization of communication
    and computing resources along with the contention of edge devices is required.
    Particularly, the optimization should concern both the time-varying wireless environments
    (such as the varying channel quality) and requests of task offloading, hence drawing
    the attention of using learning methods [[245](#bib.bib245), [246](#bib.bib246),
    [247](#bib.bib247), [248](#bib.bib248), [249](#bib.bib249), [250](#bib.bib250),
    [251](#bib.bib251), [252](#bib.bib252), [253](#bib.bib253), [254](#bib.bib254),
    [255](#bib.bib255)]. Among all these works related to learning-based optimization
    methods, DL-based approaches have advantages over others when multiple edge nodes
    and radio channels are available for computation offloading. At this background,
    large state and action spaces in the whole offloading problem make the conventional
    learning algorithms [[245](#bib.bib245)][[256](#bib.bib256)][[247](#bib.bib247)]
    infeasible actually.'
  id: totrans-430
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/340d8baa2df2d85e79f511239d0ef07f.png)'
  id: totrans-431
  prefs: []
  type: TYPE_IMG
- en: 'Figure 20: Computation offloading problem in edge computing.'
  id: totrans-432
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE VII: DL for Optimizing Edge Application Scenarios'
  id: totrans-433
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Ref. | DL | Comm. Scale | Inputs - DNN (States - DRL) | Outputs - DNN
    (Action - DRL) | Loss func. - DL (Reward - DRL) | Performance |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
- en: '| DL for Adaptive Edge Caching |  [[232](#bib.bib232)]  |  SDAE  | 60 users
    / 6 SBSs | User features, content features | Feature-based content popularity
    matrix | Normalized differences between input features and the consequent reconstruction
    | QoE improvement: up to 30%; Backhaul offloading: 6.2% |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
- en: '|  [[233](#bib.bib233)]  |  FCNN  | 100-200 UEs per cell / 7 BSs | Channel
    conditions, file requests | Caching decisions | Normalized differences between
    prediction decisions and the optimum | Prediction accuracy: up to 92%; Energy
    saving: 8% gaps to the optimum |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
- en: '|  [[234](#bib.bib234)]  |  FCNN  | UEs with density 25-30 / Multi-tier BSs
    | Current content popularity, last content placement probability | Content placement
    probability | Statistical average of the error between the model outputs and the
    optimal CVX solution | Prediction accuracy: slight degeneration to the optimum
    |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
- en: '|  [[235](#bib.bib235)]  |  &#124; FCNN &#124; &#124; CNN &#124;  | Cars /
    6 RSUs with MEC servers | Facial images - CNN; Content features - FCNN | Gender
    and age prediction - CNN; Content request probability - FCNN | N/A - CNN; Cross
    entropy error - FCNN | Caching accuracy: up to 98.04% |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
- en: '|  [[237](#bib.bib237)]  |  RNN  | 20 UEs / 10 servers | User historical traces
    | User location prediction | Cross entropy error | Caching accuracy: up to 75%
    |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
- en: '|  [[241](#bib.bib241)]  |  DDPG  | Multiple UEs / Single BS | Features of
    cached contents, current requests | Content replacement | Cache hit rate | Cache
    hit rate: about 50% |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
- en: '| DL for Optimizing Edge Task Offloading |  [[252](#bib.bib252)]  |  FCNN  |
    20 miners / Single edge node | Bidder valuation profiles of miners | Assignment
    probabilities, conditional payments | Expected, negated revenue of the service
    provider | Revenue increment |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
- en: '|  [[257](#bib.bib257)]  |  &#124; Double- &#124; &#124; DQL &#124;  | Single
    UE | System utilization states, dynamic slack states | DVFS algorithm selection
    | Average energy consumption | Energy saving: 2%-4% |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
- en: '|  [[253](#bib.bib253)]  |  DQL  | Multiple UEs / Single eNodeB | Sum cost
    of the entire system, available capacity of the MEC server | Offloading decision,
    resource allocation | Negatively correlated to the sum cost | System cost reduction
    |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
- en: '|  [[255](#bib.bib255)]  |  DDPG  | Multiple UEs / Single BS with an MEC server
    | Channel vectors, task queue length | Offloading decision, power allocation |
    Negative wighted sum of the power consumption and task queue length | Computation
    cost reduction |'
  id: totrans-444
  prefs: []
  type: TYPE_TB
- en: '|  [[254](#bib.bib254)]  |  DQL  | Single UE / Multiple MEC servers | Previous
    radio bandwidth, predicted harvested energy, current battery level | MEC server
    selection, offloading rate | Composition of overall data sharing gains, task drop
    loss, energy consumption and delay | Energy saving; Delay improvement |'
  id: totrans-445
  prefs: []
  type: TYPE_TB
- en: '|  [[251](#bib.bib251)]  |  &#124; Double- &#124; &#124; DQL &#124;  | Single
    UE / 6 BSs with MEC servers | Channel gain states, UE-BS association state, energy
    queue length, task queue length | Offloading decision, energy units allocation
    | Composition of task execution delay, task drop times, task queuing delay, task
    failing penalty and service payment | Offloading performance improvement |'
  id: totrans-446
  prefs: []
  type: TYPE_TB
- en: '|  [[258](#bib.bib258)]  |  DROO  | Multiple UEs / Single MEC server | Channel
    gain states | Offloading action | Computation rate | Algorithn execution time:
    less than 0.1s in 30-UE network |'
  id: totrans-447
  prefs: []
  type: TYPE_TB
- en: '| DL for Edge Management and Maintenance | Communication |  [[259](#bib.bib259)]  |  &#124;
    RNN & &#124; &#124; LSTM &#124;  | 53 vehicles / 20 fog servers | Coordinates
    of vehicles and interacting fog nodes, time, service cost | Cost prediction |
    Mean absolute error | Prediction accuracy: 99.2% |'
  id: totrans-448
  prefs: []
  type: TYPE_TB
- en: '|  [[260](#bib.bib260)]  |  DQL  | 4 UEs / Multiple RRHs | Current on-off states
    of processors, current communication modes of UEs, cache states | Processor state
    control, communication mode selection | Negative of system energy consumption
    | System power consumption |'
  id: totrans-449
  prefs: []
  type: TYPE_TB
- en: '| Security |  [[261](#bib.bib261)]  |  DQL  | Multiple UEs / Multiple edge
    nodes | Jamming power, channel bandwidth, battery levels, user density | Edge
    node and channel selection, offloading rate, transmit power | Composition of defense
    costs and secrecy capacity | Signal SINR increasement |'
  id: totrans-450
  prefs: []
  type: TYPE_TB
- en: '| Joint Optimization |  &#124; [[110](#bib.bib110)] &#124;  |  &#124; Double-
    &#124; &#124; Dueling &#124;'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; DQL &#124;  | Multiple UEs / 5 BSs and 5 MEC servers | Status from each
    BS, MEC server and content cache | BS allocation, caching decision, offloading
    decision | Composition of received SNRs, computation capabilities and cache states
    | System utility increasement |'
  id: totrans-452
  prefs: []
  type: TYPE_NORMAL
- en: '|  [[262](#bib.bib262)]  |  &#124; AC &#124; &#124; DRL &#124;  | 20 UEs per
    router / 3 fog nodes | States of requests, fog nodes, tasks, contents and SINR
    | Decisions about fog node, channel, resource allocation, offloading and caching
    | Composition of computation offloading delay and content delivery delay | Average
    service latency: 1.5-4.0s |'
  id: totrans-453
  prefs: []
  type: TYPE_TB
- en: '|  [[112](#bib.bib112)]  |  DQL  | 50 vehicles / 10 RSUs | States of RSUs,
    vehicles and caches, contact rate, contact times | RSU assignment, caching control
    and control | Composition of communication, storage and computation cost | Backhaul
    capacity mitigation; Resource saving |'
  id: totrans-454
  prefs: []
  type: TYPE_TB
- en: VIII-B1 Use Cases of DNNs
  id: totrans-455
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In [[249](#bib.bib249)], the computation offloading problem is formulated as
    a multi-label classification problem. By exhaustively searching the solution in
    an offline way, the obtained optimal solution can be used to train a DNN with
    the composite state of the edge computing network as the input, and the offloading
    decision as the output. By this means, optimal solutions may not require to be
    solved online avoiding belated offloading decision making, and the computation
    complexity can be transferred to DL training.
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
- en: Further, a particular offloading scenario with respect to Blockchain is investigated
    in [[252](#bib.bib252)]. The computing and energy resources consumption of mining
    tasks on edge devices may limit the practical application of Blockchain in the
    edge computing network. Naturally, these mining tasks can be offloaded from edge
    devices to edge nodes, but it may cause unfair edge resource allocation. Thus,
    all available resources are allocated in the form of auctions to maximize the
    revenue of the Edge Computing Service Provider (ECSP). Based on an analytical
    solution of the optimal auction, an MLP can be constructed [[252](#bib.bib252)]
    and trained with valuations of the miners (i.e., edge devices) for maximizing
    the expected revenue of ECSP.
  id: totrans-457
  prefs: []
  type: TYPE_NORMAL
- en: VIII-B2 Use Cases of DRL
  id: totrans-458
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Though offloading computation tasks to edge nodes can enhance the processing
    efficiency of the computation tasks, the reliability of offloading suffers from
    the potentially low quality of wireless environments. In [[248](#bib.bib248)],
    to maximize offloading utilities, the authors first quantify the influence of
    various communication modes on the task offloading performance and accordingly
    propose applying DQL to online select the optimal target edge node and transmission
    mode. For optimizing the total offloading cost, a DRL agent that modifies Dueling-
    and Double-DQL [[263](#bib.bib263)] can allocate edge computation and bandwidth
    resources for end devices.
  id: totrans-459
  prefs: []
  type: TYPE_NORMAL
- en: Besides, offloading reliability should also be concerned. The coding rate, by
    which transmitting the data, is crucial to make the offloading meet the required
    reliability level. Hence, in [[250](#bib.bib250)], effects of the coding block-length
    are investigated and an MDP concerning resource allocation is formulated and then
    solved by DQL, in order to improve the average offloading reliability. Exploring
    further on scheduling fine-grained computing resources of the edge device, in
    [[257](#bib.bib257)], Double-DQL [[89](#bib.bib89)] is used to determine the best
    Dynamic Voltage and Frequency Scaling (DVFS) algorithm. Compared to DQL, the experiment
    results indicate that Double-DQL can save more energy and achieve higher training
    efficiency. Nonetheless, the action space of DQL-based approaches may increase
    rapidly with increasing edge devices. Under the circumstances, a pre-classification
    step can be performed before learning [[253](#bib.bib253)] to narrow the action
    space.
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
- en: IoT edge environments powered by Energy Harvesting (EH) is investigated in [[254](#bib.bib254),
    [251](#bib.bib251)]. In EH environments, the energy harvesting makes the offloading
    problem more complicated, since IoT edge devices can harvest energy from ambient
    radio-frequency signals. Hence, CNN is used to compress the state space in the
    learning process [[254](#bib.bib254)]. Further, in [[251](#bib.bib251)], inspired
    by the additive structure of the reward function, $Q$-function decomposition is
    applied in Double-DQL, and it improves the vanilla Double-DQL. However, value-based
    DRL can only deal with discrete action space. To perform more fine-grained power
    control for local execution and task offloading, policy-gradient-based DRL should
    be considered. For example, compared tot he discrete power control strategy based
    on DQL, DDPG can adaptively allocate the power of edge devices with finer granularity
    [[255](#bib.bib255)].
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
- en: Freely letting DRL agents take over the whole process of computation offloading
    may lead to huge computational complexity. Therefore, only employing DNN to make
    partial decisions can largely reduce the complexity. For instance, in [[258](#bib.bib258)],
    the problem of maximizing the weighted sum computation rate is decomposed into
    two sub-problems, viz., offloading decision and resource allocation. By only using
    DRL to deal with the NP-hard offloading decision problem rather than both, the
    action space of the DRL agent is narrowed, and the offloading performance is not
    impaired as well since the resource allocation problem is solved optimally.
  id: totrans-462
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C DL for Edge Management and Maintenance
  id: totrans-463
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Edge DL services are envisioned to be deployed on BSs in cellular networks,
    as implemented in [[264](#bib.bib264)]. Therefore, edge management and maintenance
    require optimizations from multiple perspectives (including communication perspective).
    Many works focus on applying DL in wireless communication [[265](#bib.bib265),
    [266](#bib.bib266), [267](#bib.bib267)]. Nevertheless, management and maintenance
    at the edge should consider more aspects.
  id: totrans-464
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C1 Edge Communication
  id: totrans-465
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: When edge nodes are serving mobile devices (users), mobility issues in edge
    computing networks should be addressed. DL-based methods can be used to assist
    the smooth transition of connections between devices and edge nodes. To minimize
    energy consumption per bit, in [[268](#bib.bib268)], the optimal device association
    strategy is approximated by a DNN. Meanwhile, a digital twin of network environments
    is established at the central server for training this DNN off-line. To minimize
    the interruptions of a mobile device moving from an edge node to the next one
    throughout its moving trajectory, the MLP can be used to predict available edge
    nodes at a given location and time [[259](#bib.bib259)]. Moreover, determining
    the best edge node, with which the mobile device should associate, still needs
    to evaluate the cost (the latency of servicing a request) for the interaction
    between the mobile device and each edge node. Nonetheless, modeling the cost of
    these interactions requires a more capable learning model. Therefore, a two-layer
    stacked RNN with LSTM cells is implemented for modeling the cost of interaction.
    At last, based on the capability of predicting available edge nodes along with
    corresponding potential cost, the mobile device can associate with the best edge
    node, and hence the possibility of disruption is minimized.
  id: totrans-466
  prefs: []
  type: TYPE_NORMAL
- en: Aiming at minimizing long-term system power consumption in the communication
    scenario with multiple modes (to serve various IoT services), i.e., Cloud-Radio
    Access Networks (C-RAN) mode, Device-to-Device (D2D) mode, and Fog radio Access
    Point (FAP) mode, DQL can be used to control communication modes of edge devices
    and on-off states of processors throughout the communicating process [[260](#bib.bib260)].
    After determining the communication mode and the processors’ on-off states of
    a given edge device, the whole problem can be degraded into an Remote Radio Head
    (RRH) transmission power minimization problem and solved. Further, TL is integrated
    with DQL to reduce the required interactions with the environment in the DQL training
    process while maintaining a similar performance without TL.
  id: totrans-467
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C2 Edge Security
  id: totrans-468
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since edge devices generally equipped with limited computation, energy and radio
    resources, the transmission between them and the edge node is more vulnerable
    to various attacks, such as jamming attacks and Distributed Denial of Service
    (DDoS) attacks, compared to cloud computing. Therefore, the security of the edge
    computing system should be enhanced. First, the system should be able to actively
    detect unknown attacks, for instance, using DL techniques to extract features
    of eavesdropping and jamming attacks [[269](#bib.bib269)]. According to the attack
    mode detected, the system determines the strategy of security protection. Certainly,
    security protection generally requires additional energy consumption and the overhead
    of both computation and communication. Consequently, each edge device shall optimize
    its defense strategies, viz., choosing the transmit power, channel and time, without
    violating its resource limitation. The optimization is challenging since it is
    hard to estimate the attack model and the dynamic model of edge computing networks.
  id: totrans-469
  prefs: []
  type: TYPE_NORMAL
- en: DRL-based security solutions can provide secure offloading (from the edge device
    to the edge node) to against jamming attacks [[261](#bib.bib261)] or protect user
    location privacy and the usage pattern privacy [[270](#bib.bib270)]. The edge
    device observes the status of edge nodes and the attack characteristics and then
    determines the defense level and key parameters in security protocols. By setting
    the reward as the anti-jamming communication efficiency, such as the signal-to-interference-plus-noise
    ratio of the signals, the bit error rate of the received messages, and the protection
    overhead, the DQL-based security agent can be trained to cope with various types
    of attacks.
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
- en: VIII-C3 Joint Edge Optimization
  id: totrans-471
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Edge computing can cater for the rapid growth of smart devices and the advent
    of massive computation-intensive and data-consuming applications. Nonetheless,
    it also makes the operation of future networks even more complex [[271](#bib.bib271)].
    To manage the complex networks with respect to comprehensive resource optimization
    [[16](#bib.bib16)] is challenging, particularly under the premise of considering
    key enablers of the future network, including Software-Defined Network (SDN) [[272](#bib.bib272)],
    IoTs, Internet of Vehicles (IoVs).
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
- en: In general, SDN is designed for separating the control plane from the data plane,
    and thus allowing the operation over the whole network with a global view. Compared
    to the distributed nature of edge computing networks, SDN is a centralized approach,
    and it is challenging to apply SDN to edge computing networks directly. In [[273](#bib.bib273)],
    an SDN-enabled edge computing network catering for smart cities is investigated.
    To improve the servicing performance of this prototype network, DQL is deployed
    in its control plane to orchestrate networking, caching, and computing resources.
  id: totrans-473
  prefs: []
  type: TYPE_NORMAL
- en: Edge computing can empower IoT systems with more computation-intensive and delay-sensitive
    services but also raises challenges for efficient management and synergy of storage,
    computation, and communication resources. For minimizing the average end-to-end
    servicing delay, policy-gradient-based DRL combined with AC architecture can deal
    with the assignment of edge nodes, the decision about whether to store the requesting
    content or not, the choice of the edge node performing the computation tasks and
    the allocation of computation resources [[262](#bib.bib262)].
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
- en: IoVs is a special case of IoTs and focuses on connected vehicles. Similar to
    the consideration of integrating networking, caching and computing as in [[262](#bib.bib262)],
    Double-Dueling DQL (i.e., combining Double DQL and Dueling DQL) with more robust
    performance, can be used to orchestrate available resources to improve the performance
    of future IoVs [[110](#bib.bib110)]. In addition, considering the mobility of
    vehicles in the IoVs, the hard service deadline constraint might be easily broken,
    and this challenge is often either neglected or tackled inadequately because of
    high complexities. To deal with the mobility challenge, in [[112](#bib.bib112)],
    the mobility of vehicles is first modeled as discrete random jumping, and the
    time dimension is split into epochs, each of which comprises several time slots.
    Then, a small timescale DQL model, regarding the granularity of time slot, is
    devised for incorporating the impact of vehicles’ mobility in terms of the carefully
    designed immediate reward function. At last, a large timescale DQL model is proposed
    for every time epoch. By using such multi-timescale DRL, issues about both immediate
    impacts of the mobility and the unbearable large action space in the resource
    allocation optimization are solved.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
- en: IX Lessons Learned and Open Challenges
  id: totrans-476
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To identify existing challenges and circumvent potential misleading directions,
    we briefly introduce the potential scenario of “DL application on Edge”, and separately
    discuss open issues related to four enabling technologies that we focus on, i.e.,
    “DL inference in Edge”, “Edge Computing for DL”, “DL training at Edge” and “DL
    for optimizing Edge”.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
- en: IX-A More Promising Applications
  id: totrans-478
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: if DL and edge are well-integrated, they can offer great potential for the development
    of innovative applications. There are still many areas to be explored to provide
    operators, suppliers and third parties with new business opportunities and revenue
    streams.
  id: totrans-479
  prefs: []
  type: TYPE_NORMAL
- en: For example, with more DL techniques are universally embedded in these emerged
    applications, the introduced processing delay and additional computation cost
    make the cloud gaming architecture struggle to meet the latency requirements.
    Edge computing architectures, near to users, can be leveraged with the cloud to
    form a hybrid gaming architecture. Besides, intelligent driving involves speech
    recognition, image recognition, intelligent decision making, etc. Various DL applications
    in intelligent driving, such as collision warning, require edge computing platforms
    to ensure millisecond-level interaction delay. In addition, edge perception is
    more conducive to analyze the traffic environment around the vehicle, thus enhancing
    driving safety.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
- en: IX-B General DL Model for Inference
  id: totrans-481
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When deploying DL in edge devices, it is necessary to accelerate DL inference
    by model optimization. In this section, lessons learned and future directions
    for “DL inference in Edge”, with respect to model compression, model segmentation,
    and EEoI, used to optimize DL models, is discussed.
  id: totrans-482
  prefs: []
  type: TYPE_NORMAL
- en: IX-B1 Ambiguous Performance Metrics
  id: totrans-483
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For an Edge DL service for a specific task, there are usually a series of DL
    model candidates that can accomplish the task. However, it is difficult for service
    providers to choose the right DL model for each service. Due to the uncertain
    characteristics of edge computing networks (varying wireless channel qualities,
    unpredictable concurrent service requests, etc.), commonly used standard performance
    indicators (such as top-$k$ accuracy [[138](#bib.bib138)] or mean average accuracy
    [[164](#bib.bib164)]) cannot reflect the runtime performance of DL model inference
    in the edge. For Edge DL services, besides model accuracy, inference delay, resource
    consumption, and service revenue are also key indicators. Therefore, we need to
    identify the key performance indicators of Edge DL, quantitatively analyze the
    factors affecting them, and explore the trade-offs between these indicators to
    help improve the efficiency of Edge DL deployment.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
- en: IX-B2 Generalization of EEoI
  id: totrans-485
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Currently, EEoI can be applied to classification problems in DL [[160](#bib.bib160)],
    but there is no generalized solution for a wider range of DL applications. Furthermore,
    in order to build an intelligent edge and support edge intelligence, not only
    DL but also the possibility of applying EEoI to DRL should be explored, since
    applying DRL to real-time resource management for the edge, as discussed in Section
    [VIII](#S8 "VIII Deep Learning for Optimizing Edge ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey"), requires stringent response speed.'
  id: totrans-486
  prefs: []
  type: TYPE_NORMAL
- en: IX-B3 Hybrid model modification
  id: totrans-487
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Coordination issues with respect to model optimization, model segmentation,
    and EEoI should be thought over. These customized DL models are often used independently
    to enable “end-edge-cloud” collaboration. Model optimizations, such as model quantification
    and pruning, may be required on the end and edge sides, but because of the sufficient
    computation resources, the cloud does not need to take the risk of model accuracy
    to use these optimizations. Therefore, how to design a hybrid precision scheme,
    that is, to effectively combine the simplified DL models in the edge with the
    raw DL model in the cloud is important.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
- en: IX-B4 Coordination between training and inference
  id: totrans-489
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Pruning, quantizing and introducing EEoI into trained raw DL models require
    retraining to give them the desired inference performance. In general, customized
    models can be trained offline in the cloud. However, the advantage of edge computing
    lies in its response speed and might be neutralized because of belated DL training.
    Moreover, due to a large number of heterogeneous devices in the edge and the dynamic
    network environment, the customization requirements of DL models are not monotonous.
    Then, is this continuous model training requirement reasonable, and will it affect
    the timeliness of model inference? How to design a mechanism to avoid these side-effects?
  id: totrans-490
  prefs: []
  type: TYPE_NORMAL
- en: IX-C Complete Edge Architecture for DL
  id: totrans-491
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Edge intelligence and intelligent edge require a complete system framework,
    covering data acquisition, service deployment and task processing. In this section,
    we discuss challenges for “Edge Computing for DL” to build a complete edge computing
    framework for DL.
  id: totrans-492
  prefs: []
  type: TYPE_NORMAL
- en: IX-C1 Edge for Data Processing
  id: totrans-493
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Both pervasively deployed DL services on the edge and DL algorithms for optimizing
    edge cannot be realized without data acquiring. Edge architecture should be able
    to efficiently acquire and process the original data, sensed or collected by edge
    devices, and then feed them to DL models.
  id: totrans-494
  prefs: []
  type: TYPE_NORMAL
- en: Adaptively acquiring data at the edge and then transmitting them to cloud (as
    done in [[7](#bib.bib7)]) is a natural way to alleviate the workload of edge devices
    and to reduce the potential resource overhead. In addition, it is better to further
    compress the data, which can alleviate the bandwidth pressure of the network,
    while the transmission delay can be reduced to provide better QoS. Most existed
    works focus only on vision applications [[102](#bib.bib102)]. However, the heterogeneous
    data structures and characteristics of a wide variety of DL-based services are
    not addressed well yet. Therefore, developing a heterogeneous, parallel and collaborative
    architecture for edge data processing for various DL services will be helpful.
  id: totrans-495
  prefs: []
  type: TYPE_NORMAL
- en: IX-C2 Microservice for Edge DL Services
  id: totrans-496
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Edge and cloud services have recently started undergoing a major shift from
    monolithic entities to graphs of hundreds of loosely-coupled microservices [[274](#bib.bib274)].
    Executing DL computations may need a series of software dependencies, and it calls
    for a solution for isolating different DL services on the shared resources. At
    present, the microservice framework, deployed on the edge for hosting DL services,
    is in its infant [[275](#bib.bib275)], due to several critical challenges: 1)
    Handling DL deployment and management flexibly; 2) Achieving live migration of
    microservices to reduce migration times and unavailability of DL services due
    to user mobilities; 3) Orchestrating resources among the cloud and distributed
    edge infrastructures to achieve better performance, as illustrated in Section
    [VI-B3](#S6.SS2.SSS3 "VI-B3 Vertical Collaboration ‣ VI-B Communication and Computation
    Modes for Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence of Edge
    Computing and Deep Learning: A Comprehensive Survey").'
  id: totrans-497
  prefs: []
  type: TYPE_NORMAL
- en: IX-C3 Incentive and trusty offloading mechanism for DL
  id: totrans-498
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Heavy DL computations on resource-limited end devices can be offloaded to nearby
    edge nodes (Section [VI-B](#S6.SS2 "VI-B Communication and Computation Modes for
    Edge DL ‣ VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing
    and Deep Learning: A Comprehensive Survey")). However, there are still several
    issues, 1) an incentive mechanism should be established for stimulating edge nodes
    to take over DL computations; 2) the security should be guaranteed to avoid the
    risks from anonymous edge nodes [[276](#bib.bib276)].'
  id: totrans-499
  prefs: []
  type: TYPE_NORMAL
- en: Blockchain, as a decentralized public database storing transaction records across
    participated devices, can avoid the risk of tampering the records [[277](#bib.bib277)].
    By taking advantage of these characteristics, incentive and trust problems with
    respect to computation offloading can potentially be tackled. To be specific,
    all end devices and edge nodes have to first put down deposits to the blockchain
    to participate. The end device request the help of edge nodes for DL computation,
    and meantime send a “require” transaction to the blockchain with a bounty. Once
    an edge nodes complete the computation, it returns results to the end device with
    sending a “complete” transaction to the blockchain. After a while, other participated
    edge nodes also execute the offloaded task and validate the former recorded result.
    At last, for incentives, firstly recorded edge nodes win the game and be awarded
    [[278](#bib.bib278)]. However, this idea about blockchained edge is still in its
    infancy. Existing blockchains such as Ethereum [[279](#bib.bib279)] do not support
    the execution of complex DL computations, which raises the challenge of adjusting
    blockchain structure and protocol in order to break this limitation.
  id: totrans-500
  prefs: []
  type: TYPE_NORMAL
- en: IX-C4 Integration with “DL for optimizing Edge”
  id: totrans-501
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'End devices, edge nodes, and base stations in edge computing networks are expected
    to run various DL models and deploy corresponding services in the future. In order
    to make full use of decentralized resources of edge computing, and to establish
    connections with existing cloud computing infrastructure, dividing the computation-intensive
    DL model into sub-tasks and effectively offloading these tasks between edge devices
    for collaboration are essential. Owing to deployment environments of Edge DL are
    usually highly dynamic, edge computing frameworks need excellent online resource
    orchestration and parameter configuration to support a large number of DL services.
    Heterogeneous computation resources, real-time joint optimization of communication
    and cache resources, and high-dimensional system parameter configuration are critical.
    We have introduced various theoretical methods to optimize edge computing frameworks
    (networks) with DL technologies in Section [VIII](#S8 "VIII Deep Learning for
    Optimizing Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey"). Nonetheless, there is currently no relevant work to deeply study the
    performance analysis of deploying and using these DL technologies for long-term
    online resource orchestration in practical edge computing networks or testbeds.
    We believe that “Edge Computing for DL” should continue to focus on how to integrate
    “DL for optimizing Edge” into the edge computing framework to realize the above
    vision.'
  id: totrans-502
  prefs: []
  type: TYPE_NORMAL
- en: IX-D Practical Training Principles at Edge
  id: totrans-503
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared with DL inference in the edge, DL training at the edge is currently
    mainly limited by the weak performance of edge devices and the fact that most
    Edge DL frameworks or libraries still do not support training. At present, most
    studies are at the theoretical level, i.e., simulating the process of DL training
    at the edge. In this section, we point out the lessons learned and challenges
    in “DL Training at Edge”.
  id: totrans-504
  prefs: []
  type: TYPE_NORMAL
- en: IX-D1 Data Parallelism versus Model Parallelism
  id: totrans-505
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'DL models are both computation and memory intensive. When they become deeper
    and larger, it is not feasible to acquire their inference results or train them
    well by a single device. Therefore, large DL models are trained in distributed
    manners over thousands of CPU or GPU cores, in terms of data parallelism, model
    parallelism or their combination (Section [III-C](#S3.SS3 "III-C Distributed DL
    Training ‣ III Fundamentals of Deep Learning ‣ Convergence of Edge Computing and
    Deep Learning: A Comprehensive Survey")). However, differing from parallel training
    over bus-or switch-connected CPUs or GPUs in the cloud, perform model training
    at distributed edge devices should further consider wireless environments, device
    configurations, privacies, etc.'
  id: totrans-506
  prefs: []
  type: TYPE_NORMAL
- en: 'At present, FL only copies the whole DL model to every participated edge devices,
    namely in the manner of data parallelism. Hence, taking the limited computing
    capabilities of edge devices (at least for now) into consideration, partitioning
    a large-scale DL model and allocating these segments to different edge devices
    for training may be a more feasible and practical solution. Certainly, this does
    not mean abandoning the native data parallelism of FL, instead, posing the challenge
    of blending data parallelism and model parallelism particularly for training DL
    models at the edge, as illustrated in Fig. [21](#S9.F21 "Figure 21 ‣ IX-D1 Data
    Parallelism versus Model Parallelism ‣ IX-D Practical Training Principles at Edge
    ‣ IX Lessons Learned and Open Challenges ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey").'
  id: totrans-507
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/262182344eacc927c835ae5908eb8f54.png)'
  id: totrans-508
  prefs: []
  type: TYPE_IMG
- en: 'Figure 21: DL training at the edge by both data and model parallelism.'
  id: totrans-509
  prefs: []
  type: TYPE_NORMAL
- en: IX-D2 Where is training data from?
  id: totrans-510
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Currently, most of the DL training frameworks at the edge are aimed at supervised
    learning tasks, and test their performance with complete data sets. However, in
    practical scenarios, we cannot assume that all data in the edge computing network
    are labeled and with a correctness guarantee. For unsupervised learning tasks
    such as DRL, we certainly do not need to pay too much attention to the production
    of training data. For example, the training data required for DRL compose of the
    observed state vectors and rewards obtained by interacting with the environment.
    These training data can generate automatically when the system is running. But
    for a wider range of supervised learning tasks, how edge nodes and devices find
    the exact training data for model training? The application of vanilla FL is using
    RNN for next-word-prediction [[199](#bib.bib199)], in which the training data
    can be obtained along with users’ daily inputs. Nonetheless, for extensive Edge
    DL services concerning video analysis, where are their training data from. If
    all training data is manually labeled and uploaded to the cloud data center, and
    then distributed to edge devices by the cloud, the original intention of FL is
    obviously violated. One possible solution is to enable edge devices to construct
    their labeled data by learning “labeled data” from each other. We believe that
    the production of training data and the application scenarios of DL models training
    at the edge should first be clarified in the future, and the necessity and feasibility
    of DL model training at the edge should be discussed as well.
  id: totrans-511
  prefs: []
  type: TYPE_NORMAL
- en: IX-D3 Asynchronous FL at Edge
  id: totrans-512
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Existing FL methods [[199](#bib.bib199), [198](#bib.bib198)] focus on synchronous
    training, and can only process hundreds of devices in parallel. However, this
    synchronous updating mode potentially cannot scale well, and is inefficient and
    inflexible in view of two key properties of FL, specifically, 1) infrequent training
    tasks, since edge devices typically have weaker computing power and limited battery
    endurance and thus cannot afford intensive training tasks; 2) limited and uncertain
    communication between edge devices, compared to typical distributed training in
    the cloud.
  id: totrans-513
  prefs: []
  type: TYPE_NORMAL
- en: Thus, whenever the global model is updating, the server is limited to selecting
    from a subset of available edge devices to trigger a training task. In addition,
    due to limited computing power and battery endurance, task scheduling varies from
    device to device, making it difficult to synchronize selected devices at the end
    of each epoch. Some devices may no longer be available when they should be synchronized,
    and hence the server must determine the timeout threshold to discard the laggard.
    If the number of surviving devices is too small, the server has to discard the
    entire epoch including all received updates. These bottlenecks in FL can potentially
    be addressed by asynchronous training mechanisms [[280](#bib.bib280), [281](#bib.bib281),
    [282](#bib.bib282)]. Adequately selecting clients in each training period with
    resource constraints may also help. By setting a certain deadline for clients
    to download, update, and upload DL models, the central server can determine which
    clients to perform local training such that it can aggregate as many client updates
    as possible in each period, thus allowing the server to accelerate performance
    improvement in DL models [[283](#bib.bib283)].
  id: totrans-514
  prefs: []
  type: TYPE_NORMAL
- en: IX-D4 Transfer Learning-based Training
  id: totrans-515
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Due to resource constraints, training and deploying computation-intensive DL
    models on edge devices such as mobile phones is challenging. In order to facilitate
    learning on such resource-constrained edge devices, TL can be utilized. For instance,
    in order to reduce the amount of training data and speeding up the training process,
    using unlabeled data to transfer knowledge between edge devices can be adopted
    [[284](#bib.bib284)]. By using the cross-modal transfer in the learning of edge
    devices across different sensing modalities, required labeled data and the training
    process can be largely reduced and accelerated, respectively.
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: 'Besides, KD, as a method of TL, can also be exploited thanks to several advantages
    [[136](#bib.bib136)]: 1) using information from well-trained large DL models (teachers)
    to help lightweight DL models (students), expected to be deployed on edge devices,
    converge faster; 2) improving the accuracy of students; 3) helping students become
    more general instead of being overfitted by a certain set of data. Although results
    of [[136](#bib.bib136), [284](#bib.bib284)] show some prospects, further research
    is needed to extend the TL-based training method to DL applications with different
    types of perceptual data.'
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: IX-E Deployment and Improvement of Intelligent Edge
  id: totrans-518
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There have been many attempts to use DL to optimize and schedule resources in
    edge computing networks. In this regard, there are many potential areas where
    DL can be applied, including online content streaming [[285](#bib.bib285)], routing
    and traffic control [[286](#bib.bib286)][[287](#bib.bib287)], etc. However, since
    DL solutions do not rely entirely on accurate modeling of networks and devices,
    finding a scenario where DL can be applied is not the most important concern.
    Besides, if applying DL to optimize real-time edge computing networks, the training
    and inference of DL models or DRL algorithms may bring certain side effects, such
    as the additional bandwidth consumed by training data transmission and the latency
    of DL inference.
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: 'Existing works mainly concern about solutions of “DL for optimizing Edge” at
    the high level, but overlook the practical feasibility at the low level. Though
    DL exhibits its theoretical performance, the deployment issues of DNNs/DRL should
    be carefully considered (as illustrated in Fig. [22](#S9.F22 "Figure 22 ‣ IX-E
    Deployment and Improvement of Intelligent Edge ‣ IX Lessons Learned and Open Challenges
    ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive Survey")):'
  id: totrans-520
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Where DL and DRL should be deployed, in view of the resource overhead of them
    and the requirement of managing edge computing networks in real time?
  id: totrans-522
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: When using DL to determine caching policies or optimize task offloading, will
    the benefits of DL be neutralized by the bandwidth consumption and the processing
    delay brought by DL itself?
  id: totrans-524
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How to explore and improve edge computing architectures in Section [VI](#S6
    "VI Edge Computing for Deep Learning ‣ Convergence of Edge Computing and Deep
    Learning: A Comprehensive Survey") to support “DL for optimizing Edge”?'
  id: totrans-526
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Are the ideas of customized DL models, introduced in Section [V](#S5 "V Deep
    Learning Inference in Edge ‣ Convergence of Edge Computing and Deep Learning:
    A Comprehensive Survey"), can help to facilitate the practical deployment?'
  id: totrans-528
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How to modify the training principles in Section [VII](#S7 "VII Deep Learning
    Training at Edge ‣ Convergence of Edge Computing and Deep Learning: A Comprehensive
    Survey") to enhance the performance of DL training, in order to meet the timeliness
    of edge management?'
  id: totrans-530
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9fc4ee62d08250b7a9235dae753432b2.png)'
  id: totrans-531
  prefs: []
  type: TYPE_IMG
- en: 'Figure 22: Deployment issues of intelligent edge, i.e., how and where to deploy
    DL models for optimizing edge computing networks (systems).'
  id: totrans-532
  prefs: []
  type: TYPE_NORMAL
- en: Besides, the abilities of the state-of-the-art DL or DRL, such as Multi-Agent
    Deep Reinforcement Learning [[288](#bib.bib288), [289](#bib.bib289), [290](#bib.bib290)],
    Graph Neural Networks (GNNs) [[291](#bib.bib291), [292](#bib.bib292)], can also
    be exploited to facilitate this process. For example, end devices, edge nodes,
    and the cloud can be deemed as individual agents. By this means, each agent trains
    its own strategy according to its local imperfect observations, and all participated
    agents work together for optimizing edge computing networks. In addition, the
    structure of edge computing networks across the end, the edge, and the cloud is
    actually an immense graph, which comprises massive latent structure information,
    e.g., the connection and bandwidth between devices. For better understanding edge
    computing networks, GNNs, which focuses on extracting features from graph structures
    instead of two-dimensional meshes and one-dimensional sequences, might be a promising
    method.
  id: totrans-533
  prefs: []
  type: TYPE_NORMAL
- en: X Conclusions
  id: totrans-534
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'DL, as a key technique of artificial intelligence, and edge computing are expected
    to benefit each other. This survey has comprehensively introduced and discussed
    various applicable scenarios and fundamental enabling techniques for edge intelligence
    and intelligent edge. In summary, the key issue of extending DL from the cloud
    to the edge of the network is: under the multiple constraints of networking, communication,
    computing power, and energy consumption, how to devise and develop edge computing
    architecture to achieve the best performance of DL training and inference. As
    the computing power of the edge increases, edge intelligence will become common,
    and intelligent edge will play an important supporting role to improve the performance
    of edge intelligence. We hope that this survey will increase discussions and research
    efforts on DL/Edge integration that will advance future communication applications
    and services.'
  id: totrans-535
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgement
  id: totrans-536
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported by the National Key R&D Program of China (No.2019YFB2101901
    and No.2018YFC0809803), National Science Foundation of China (No.61702364, No.61972432
    and No.U1711265), the Program for Guangdong Introducing Innovative and Enterpreneurial
    Teams (No.2017ZT07X355), Chinese National Engineering Laboratory for Big Data
    System Computing Technology and Canadian Natural Sciences and Engineering Research
    Council. It was also supported in part by Singapore NRF National Satellite of
    Excellence, Design Science and Technology for Secure Critical Infrastructure NSoE
    DeST-SCI2019-0007, A*STAR-NTU-SUTD Joint Research Grant Call on Artificial Intelligence
    for the Future of Manufacturing RGANS1906, WASP/NTU M4082187 (4080), Singapore
    MOE Tier 1 2017-T1-002-007 RG122/17, MOE Tier 2 MOE2014-T2-2-015 ARC4/15, Singapore
    NRF2015-NRF-ISF001-2277, and Singapore EMA Energy Resilience NRF2017EWT-EP003-041.
    Especially, we would like to thank the editors of IEEE COMST and the reviewers
    for their help and support in making this work possible.
  id: totrans-537
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-538
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] “Fog Computing and the Internet of Things: Extend the Cloud to Where the
    Things Are.” [Online]. Available: [https://www.cisco.com/c/dam/en_us/solutions/trends/iot/docs/computing-overview.pdf](https://www.cisco.com/c/dam/en_us/solutions/trends/iot/docs/computing-overview.pdf)'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] “Cisco Global Cloud Index: Forecast and Methodology.” [Online]. Available:
    [https://www.cisco.com/c/en/us/solutions/collateral/service-provider/global-cloud-index-gci/white-paper-c11-738085.html](https://www.cisco.com/c/en/us/solutions/collateral/service-provider/global-cloud-index-gci/white-paper-c11-738085.html)'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] M. V. Barbera, S. Kosta, A. Mei *et al.*, “To offload or not to offload?
    The bandwidth and energy costs of mobile cloud computing,” in *2013 IEEE Conference
    on Computer Communications (INFOCOM 2013)*, 2013, pp. 1285–1293.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] W. Hu, Y. Gao, K. Ha *et al.*, “Quantifying the Impact of Edge Computing
    on Mobile Applications,” in *Proc. 7th ACM SIGOPS Asia-Pacific Workshop Syst.
    (APSys 2016)*, 2016, pp. 1–8.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] “Mobile-Edge Computing–Introductory Technical White Paper,” ETSI. [Online].
    Available: [https://portal.etsi.org/Portals/0/TBpages/MEC/Docs/Mobile-edge_Computing_-_Introductory_Technical_White_Paper_V1%2018-09-14.pdf](https://portal.etsi.org/Portals/0/TBpages/MEC/Docs/Mobile-edge_Computing_-_Introductory_Technical_White_Paper_V1%2018-09-14.pdf)'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] W. Shi, J. Cao *et al.*, “Edge Computing: Vision and Challenges,” *IEEE
    Internet Things J.*, vol. 3, no. 5, pp. 637–646, Oct. 2016.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] B. A. Mudassar, J. H. Ko, and S. Mukhopadhyay, “Edge-cloud collaborative
    processing for intelligent internet of things,” in *Proc. the 55th Annual Design
    Automation Conference (DAC 2018)*, 2018, pp. 1–6.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] A. Yousefpour, C. Fung, T. Nguyen *et al.*, “All one needs to know about
    fog computing and related edge computing paradigms: A complete survey,” *J SYST
    ARCHITECT.*, 2019.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] J. Redmon, S. Divvala *et al.*, “You Only Look Once: Unified, Real-Time
    Object Detection,” in *Proc. 2016 IEEE Conference on Computer Vision and Pattern
    Recognition (CVPR 2016)*, 2016, pp. 779–788.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] J. Schmidhuber, “Deep learning in neural networks: An overview,” *Neural
    Networks*, vol. 61, pp. 85–117, Jan. 2015.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] H. Khelifi, S. Luo, B. Nour *et al.*, “Bringing deep learning at the edge
    of information-centric internet of things,” *IEEE Commun. Lett.*, vol. 23, no. 1,
    pp. 52–55, Jan. 2019.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Y. Kang, J. Hauswald, C. Gao *et al.*, “Neurosurgeon: Collaborative Intelligence
    Between the Cloud and Mobile Edge,” in *Proc. 22nd Int. Conf. Archit. Support
    Program. Lang. Oper. Syst. (ASPLOS 2017)*, 2017, pp. 615–629.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] “Democratizing AI.” [Online]. Available: [https://news.microsoft.com/features/democratizing-ai/](https://news.microsoft.com/features/democratizing-ai/)'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Y. Yang, “Multi-tier computing networks for intelligent IoT,” *Nature
    Electronics*, vol. 2, no. 1, pp. 4–5, Jan. 2019.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] C. Li, Y. Xue, J. Wang *et al.*, “Edge-Oriented Computing Paradigms: A
    Survey on Architecture Design and System Management,” *ACM Comput. Surv.*, vol. 51,
    no. 2, pp. 1–34, Apr. 2018.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] S. Wang, X. Zhang, Y. Zhang *et al.*, “A Survey on Mobile Edge Networks:
    Convergence of Computing, Caching and Communications,” *IEEE Access*, vol. 5,
    pp. 6757–6779, 2017.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] T. X. Tran, A. Hajisami *et al.*, “Collaborative Mobile Edge Computing
    in 5G Networks: New Paradigms, Scenarios, and Challenges,” *IEEE Commun. Mag.*,
    vol. 55, no. 4, pp. 54–61, Apr. 2017.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] J. Park, S. Samarakoon, M. Bennis, and M. Debbah, “Wireless Network Intelligence
    at the Edge,” *Proc. IEEE*, vol. 107, no. 11, pp. 2204–2239, Nov. 2019.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Z. Zhou, X. Chen, E. Li, L. Zeng, K. Luo, and J. Zhang, “Edge Intelligence:
    Paving the Last Mile of Artificial Intelligence With Edge Computing,” *Proc. IEEE*,
    vol. 107, no. 8, pp. 1738–1762, Aug. 2019.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] J. Chen and X. Ran, “Deep Learning With Edge Computing: A Review,” *Proc.
    IEEE*, vol. 107, no. 8, pp. 1655–1674, Aug. 2019.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
    D. Niyato *et al.*, “Federated Learning in Mobile Edge Networks: A Comprehensive
    Survey,” *arXiv preprint arXiv:1909.11875*, 2019.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] C. Mouradian, D. Naboulsi, S. Yangui *et al.*, “A Comprehensive Survey
    on Fog Computing: State-of-the-Art and Research Challenges,” *IEEE Commun. Surveys
    Tuts.*, vol. 20, no. 1, pp. 416–464, 2018.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] K. Bilal, O. Khalid, A. Erbad, and S. U. Khan, “Potentials, trends, and
    prospects in edge technologies: Fog, cloudlet, mobile edge, and micro data centers,”
    *Comput. Networks*, vol. 130, no. 2018, pp. 94–120, 2018.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] M. Satyanarayanan, P. Bahl, R. Cáceres, and N. Davies, “The case for vm-based
    cloudlets in mobile computing,” *IEEE Pervasive Comput.*, vol. 8, no. 4, pp. 14–23,
    2009.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] M. Aazam and E. Huh, “Fog computing micro datacenter based dynamic resource
    estimation and pricing model for iot,” in *Proc. IEEE 29th International Conference
    on Advanced Information Networking and Applications (AINA 2019)*, Mar. 2015, pp.
    687–694.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] F. Bonomi, R. Milito, J. Zhu, and S. Addepalli, “Fog computing and its
    role in the internet of things,” in *Proc. the first edition of the MCC workshop
    on Mobile cloud computing*, 2012, pp. 13–16.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] F. Bonomi, R. Milito, P. Natarajan, and J. Zhu, *Fog Computing: A Platform
    for Internet of Things and Analytics*.   Cham: Springer International Publishing,
    2014, pp. 169–186.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] “Multi-access Edge Computing.” [Online]. Available: [http://www.etsi.org/technologies-clusters/technologies/multi-access-edge-computing](http://www.etsi.org/technologies-clusters/technologies/multi-access-edge-computing)'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] “What is Azure Data Box Edge?” [Online]. Available: [https://docs.microsoft.com/zh-cn/azure/databox-online/data-box-edge-overview](https://docs.microsoft.com/zh-cn/azure/databox-online/data-box-edge-overview)'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] “Intel Movidius Neural Compute Stick.” [Online]. Available: [https://software.intel.com/en-us/movidius-ncs](https://software.intel.com/en-us/movidius-ncs)'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] “Latest Jetson Products.” [Online]. Available: [https://developer.nvidia.com/buy-jetson](https://developer.nvidia.com/buy-jetson)'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] “An all-scenario AI infrastructure solution that bridges ’device, edge,
    and cloud’ and delivers unrivaled compute power to lead you towards an AI-fueled
    future.” [Online]. Available: [https://e.huawei.com/en/solutions/business-needs/data-center/atlas](https://e.huawei.com/en/solutions/business-needs/data-center/atlas)'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] “Snapdragon 8 Series Mobile Platforms.” [Online]. Available: [https://www.qualcomm.com/products/snapdragon-8-series-mobile-platforms](https://www.qualcomm.com/products/snapdragon-8-series-mobile-platforms)'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] “Kirin.” [Online]. Available: [http://www.hisilicon.com/en/Products/ProductList/Kirin](http://www.hisilicon.com/en/Products/ProductList/Kirin)'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] “The World’s First Full-Stack All-Scenario AI Chip.” [Online]. Available:
    [http://www.hisilicon.com/en/Products/ProductList/Ascend](http://www.hisilicon.com/en/Products/ProductList/Ascend)'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] “MediaTek Helio P60.” [Online]. Available: [https://www.mediatek.com/products/smartphones/mediatek-helio-p60](https://www.mediatek.com/products/smartphones/mediatek-helio-p60)'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] “NVIDIA Turing GPU Architecture.” [Online]. Available: [https://www.nvidia.com/en-us/geforce/turing/](https://www.nvidia.com/en-us/geforce/turing/)'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] N. P. Jouppi, A. Borchers, R. Boyle, P. L. Cantin, and B. Nan, “In-Datacenter
    Performance Analysis of a Tensor Processing Unit,” in *Proc. 44th Int. Symp. Comput.
    Archit. (ISCA 2017)*, 2017, pp. 1–12.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] “Intel Xeon Processor D-2100 Product Brief: Advanced Intelligence for
    High-Density Edge Solutions.” [Online]. Available: [https://www.intel.cn/content/www/cn/zh/products/docs/processors/xeon/d-2100-brief.html](https://www.intel.cn/content/www/cn/zh/products/docs/processors/xeon/d-2100-brief.html)'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] “Mobile Processor: Exynos 9820.” [Online]. Available: [https://www.samsung.com/semiconductor/minisite/exynos/products/mobileprocessor/exynos-9-series-9820/](https://www.samsung.com/semiconductor/minisite/exynos/products/mobileprocessor/exynos-9-series-9820/)'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] Y. Xiong, Y. Sun, L. Xing, and Y. Huang, “Extend Cloud to Edge with KubeEdge,”
    in *Proc. 2018 IEEE/ACM Symposium on Edge Computing (SEC 2018)*, 2018, pp. 373–377.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] “OpenEdge, extend cloud computing, data and service seamlessly to edge
    devices.” [Online]. Available: [https://github.com/baidu/openedge](https://github.com/baidu/openedge)'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] “Azure IoT Edge, extend cloud intelligence and analytics to edge devices.”
    [Online]. Available: [https://github.com/Azure/iotedge](https://github.com/Azure/iotedge)'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] “EdgeX, the Open Platform for the IoT Edge.” [Online]. Available: [https://www.edgexfoundry.org/](https://www.edgexfoundry.org/)'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] “Akraino Edge Stack.” [Online]. Available: [https://www.lfedge.org/projects/akraino/](https://www.lfedge.org/projects/akraino/)'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] “NVIDIA EGX Edge Computing Platform: Real-Time AI at the Edge.” [Online].
    Available: [https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/](https://www.nvidia.com/en-us/data-center/products/egx-edge-computing/)'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] “AWS IoT Greengrass: Bring local compute, messaging, data caching, sync,
    and ML inference capabilities to edge devices.” [Online]. Available: [https://aws.amazon.com/greengrass/](https://aws.amazon.com/greengrass/)'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] “Google Cloud IoT: Unlock business insights from your global device network
    with an intelligent IoT platform.” [Online]. Available: [https://cloud.google.com/solutions/iot/](https://cloud.google.com/solutions/iot/)'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] G. Li, L. Liu, X. Wang *et al.*, “Auto-tuning Neural Network Quantization
    Framework for Collaborative Inference Between the Cloud and Edge,” in *Proc. International
    Conference on Artificial Neural Networks (ICANN 2018)*, 2018, pp. 402–411.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Y. Huang, Y. Zhu, X. Fan *et al.*, “Task Scheduling with Optimized Transmission
    Time in Collaborative Cloud-Edge Learning,” in *Proc. 27th International Conference
    on Computer Communication and Networks (ICCCN 2018)*, 2018, pp. 1–9.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] E. Nurvitadhi, G. Venkatesh, J. Sim *et al.*, “Can fpgas beat gpus in
    accelerating next-generation deep neural networks?” in *Proc. ACM/SIGDA International
    Symposium on Field-Programmable Gate Arrays (FPGA 2017)*, 2017, pp. 5–14.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] S. Jiang, D. He, C. Yang *et al.*, “Accelerating Mobile Applications at
    the Network Edge with Software-Programmable FPGAs,” in *2018 IEEE Conference on
    Computer Communications (INFOCOM 2018)*, 2018, pp. 55–62.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] “Qualcomm Neural Processing SDK for AI.” [Online]. Available: [https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk](https://developer.qualcomm.com/software/qualcomm-neural-processing-sdk)'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] A. Ignatov, R. Timofte, W. Chou *et al.*, “AI Benchmark: Running Deep
    Neural Networks on Android Smartphones,” *arXiv preprint arXiv:1810.01109*.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] D. Bernstein, “Containers and cloud: From lxc to docker to kubernetes,”
    *IEEE Cloud Comput.*, vol. 1, no. 3, pp. 81–84, Sep. 2014.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] “Microsoft Cognitive Toolkit (CNTK), an open source deep-learning toolkit.”
    [Online]. Available: [https://github.com/microsoft/CNTK](https://github.com/microsoft/CNTK)'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] S. Tokui, K. Oono *et al.*, “Chainer: a next-generation open source framework
    for deep learning,” in *Proc. workshop on machine learning systems (LearningSys)
    in the twenty-ninth annual conference on neural information processing systems
    (NeurIPS 2015)*, 2015, pp. 1–6.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M. Abadi, P. Barham *et al.*, “TensorFlow: A System for Large-Scale Machine
    Learning,” in *Proc. the 12th USENIX conference on Operating Systems Design and
    Implementation (OSDI 2016)*, 2016, pp. 265–283.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] “Deeplearning4j: Open-source distributed deep learning for the JVM, Apache
    Software Foundation License 2.0.” [Online]. Available: [https://deeplearning4j.org](https://deeplearning4j.org)'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] “Deploy machine learning models on mobile and IoT devices.” [Online].
    Available: [https://www.tensorflow.org/lite](https://www.tensorflow.org/lite)'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] T. Chen, M. Li, Y. Li *et al.*, “MXNet: A Flexible and Efficient Machine
    Learning Library for Heterogeneous Distributed Systems,” *arXiv preprint arXiv:1512.01274*,
    2015.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] “PyTorch: tensors and dynamic neural networks in Python with strong GPU
    acceleration.” [Online]. Available: [https://github.com/pytorch/](https://github.com/pytorch/)'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] “Core ML: Integrate machine learning models into your app.” [Online].
    Available: [https://developer.apple.com/documentation/coreml?language=objc](https://developer.apple.com/documentation/coreml?language=objc)'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] “NCNN is a high-performance neural network inference framework optimized
    for the mobile platform.” [Online]. Available: [https://github.com/Tencent/ncnn](https://github.com/Tencent/ncnn)'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] “MNN is a lightweight deep neural network inference engine.” [Online].
    Available: [https://github.com/alibaba/MNN](https://github.com/alibaba/MNN)'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] “Multi-platform embedded deep learning framework.” [Online]. Available:
    [https://github.com/PaddlePaddle/paddle-mobile](https://github.com/PaddlePaddle/paddle-mobile)'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] “MACE is a deep learning inference framework optimized for mobile heterogeneous
    computing platforms.” [Online]. Available: [https://github.com/XiaoMi/mace](https://github.com/XiaoMi/mace)'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] X. Wang, M. Magno, L. Cavigelli, and L. Benini, “FANN-on-MCU: An Open-Source
    Toolkit for Energy-Efficient Neural Network Inference at the Edge of the Internet
    of Things,” *arXiv preprint arXiv:1911.03314*, 2019.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] Z. Tao, Q. Xia, Z. Hao, C. Li, L. Ma, S. Yi, and Q. Li, “A Survey of Virtual
    Machine Management in Edge Computing,” *Proc. IEEE*, vol. 107, no. 8, pp. 1482–1499,
    2019.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] R. Morabito, “Virtualization on internet of things edge devices with container
    technologies: A performance evaluation,” *IEEE Access*, vol. 5, pp. 8835–8850,
    2017.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] L. Ma, S. Yi, N. Carter, and Q. Li, “Efficient Live Migration of Edge
    Services Leveraging Container Layered Storage,” *IEEE Trans. Mob. Comput.*, vol. 18,
    no. 9, pp. 2020–2033, Sep. 2019.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] A. Wang, Z. Zha, Y. Guo, and S. Chen, “Software-Defined Networking Enhanced
    Edge Computing: A Network-Centric Survey,” *Proc. IEEE*, vol. 107, no. 8, pp.
    1500–1519, Aug. 2019.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] Y. D. Lin, C. C. Wang, C. Y. Huang, and Y. C. Lai, “Hierarchical CORD
    for NFV Datacenters: Resource Allocation with Cost-Latency Tradeoff,” *IEEE Netw.*,
    vol. 32, no. 5, pp. 124–130, 2018.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] L. Li, K. Ota, and M. Dong, “DeepNFV: A Lightweight Framework for Intelligent
    Edge Network Functions Virtualization,” *IEEE Netw.*, vol. 33, no. 1, pp. 136–141,
    Jan. 2019.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] “Mobile Edge Computing A key technology towards 5G,” ETSI. [Online]. Available:
    [https://www.etsi.org/images/files/ETSIWhitePapers/etsi_wp11_mec_a_key_technology_towards_5g.pdf](https://www.etsi.org/images/files/ETSIWhitePapers/etsi_wp11_mec_a_key_technology_towards_5g.pdf)'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] H.-T. Chien, Y.-D. Lin, C.-L. Lai, and C.-T. Wang, “End-to-End Slicing
    as a Service with Computing and Communication Resource Allocation for Multi-Tenant
    5G Systems,” *IEEE Wirel. Commun.*, vol. 26, no. 5, pp. 104–112, Oct. 2019.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] T. Taleb, K. Samdanis, B. Mada, H. Flinck, S. Dutta, and D. Sabella, “On
    Multi-Access Edge Computing: A Survey of the Emerging 5G Network Edge Cloud Architecture
    and Orchestration,” *IEEE Commun. Surv. Tutor.*, vol. 19, no. 3, pp. 1657–1681,
    2017.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] Y. LeCun, Y. Bengio, and G. Hinton, “Deep learning,” *Nature*, vol. 521,
    no. 7553, pp. 436–444, May 2015.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] S. S. Haykin and K. Elektroingenieur, *Neural networks and learning machines*.   Pearson
    Prentice Hall, 2009.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] R. Collobert and S. Bengio, “Links between perceptrons, MLPs and SVMs,”
    in *Proc. the Twenty-first international conference on Machine learning (ICML
    2004)*, 2004, p. 23.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] C. D. Manning, C. D. Manning, and H. Schütze, *Foundations of statistical
    natural language processing*.   MIT press, 1999.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] M. D. Zeiler and R. Fergus, “Visualizing and Understanding Convolutional
    Networks,” in *2014 European Conference on Computer Vision (ECCV 2014)*, 2014,
    pp. 818–833.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] I. Goodfellow, J. Pouget-Abadie, M. Mirza *et al.*, “Generative adversarial
    nets,” in *Advances in Neural Information Processing Systems 27 (NeurIPS 2014)*,
    2014, pp. 2672–2680.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” *Neural Computation*,
    vol. 9, no. 8, pp. 1735–1780, Nov. 1997.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] S. J. Pan and Q. Yang, “A survey on transfer learning,” *IEEE Trans. Knowl.
    Data Eng.*, vol. 22, no. 10, pp. 1345–1359, Oct. 2010.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] G. Hinton, O. Vinyals, and J. Dean, “Distilling the knowledge in a neural
    network,” *arXiv preprint arXiv:1503.02531*, 2015.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] S. S. Mousavi, M. Schukat, and E. Howley, “Deep Reinforcement Learning:
    An Overview,” in *Proc. the 2016 SAI Intelligent Systems Conference (IntelliSys
    2016)*, 2016, pp. 426–440.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] V. Mnih, K. Kavukcuoglu, D. Silver *et al.*, “Human-level control through
    deep reinforcement learning,” *Nature*, vol. 518, no. 7540, pp. 529–533, Feb.
    2015.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] H. Van Hasselt, A. Guez, and D. Silver, “Deep Reinforcement Learning with
    Double Q-Learning,” in *Proc. the Thirtieth AAAI Conference on Artificial Intelligence
    (AAAI 2016)*, 2016, pp. 2094–2100.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] Z. Wang, T. Schaul, M. Hessel *et al.*, “Dueling network architectures
    for deep reinforcement learning,” in *Proc. the 33rd International Conference
    on Machine Learning (ICML 2016)*, 2016, pp. 1995–2003.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] T. P. Lillicrap, J. J. Hunt, A. Pritzel *et al.*, “Continuous control
    with deep reinforcement learning,” in *Proc. the 6th International Conference
    on Learning Representations (ICLR 2016)*, 2016.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] V. Mnih, A. P. Badia, M. Mirza *et al.*, “Asynchronous Methods for Deep
    Reinforcement Learning,” in *Proc. the 33rd International Conference on Machine
    Learning (ICML 2016)*, 2016, pp. 1928–1937.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] J. Schulman, F. Wolski, P. Dhariwal *et al.*, “Proximal policy optimization
    algorithms,” *arXiv preprint arXiv:1707.06347*, 2017.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] R. S. Sutton, D. McAllester, S. Singh, and Y. Mansour, “Policy gradient
    methods for reinforcement learning with function approximation,” in *Proc. the
    12th International Conference on Neural Information Processing Systems (NeurIPS
    1999)*, 1999, pp. 1057–1063.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] Monin and Yaglom, “Large Scale Distributed Deep Networks,” in *Proc. Advances
    in Neural Information Processing Systems 25 (NeurIPS 2012)*, 2012, pp. 1223–1231.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] Y. Zou, X. Jin, Y. Li *et al.*, “Mariana: Tencent deep learning platform
    and its applications,” in *Proc. VLDB Endow.*, vol. 7, no. 13, 2014, pp. 1772–1777.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] X. Chen, A. Eversole, G. Li *et al.*, “Pipelined Back-Propagation for
    Context-Dependent Deep Neural Networks,” in *13th Annual Conference of the International
    Speech Communication Association (INTERSPEECH 2012)*, 2012, pp. 26–29.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] M. Stevenson, R. Winter *et al.*, “1-Bit Stochastic Gradient Descent and
    its Application to Data-Parallel Distributed Training of Speech DNNs,” in *15th
    Annual Conference of the International Speech Communication Association (INTERSPEECH
    2014)*, 2014, pp. 1058–1062.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] A. Coates, B. Huval, T. Wang *et al.*, “Deep learning with cots hpc systems,”
    in *Proc. the 30th International Conference on Machine Learning (PMLR 2013)*,
    2013, pp. 1337–1345.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] P. Moritz, R. Nishihara, I. Stoica, and M. I. Jordan, “SparkNet: Training
    Deep Networks in Spark,” *arXiv preprint arXiv:1511.06051*, 2015.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] “Theano is a Python library that allows you to define, optimize, and
    evaluate mathematical expressions involving multi-dimensional arrays efficiently.”
    [Online]. Available: [https://github.com/Theano/Theano](https://github.com/Theano/Theano)'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] J. Ren, Y. Guo, D. Zhang *et al.*, “Distributed and Efficient Object
    Detection in Edge Computing: Challenges and Solutions,” *IEEE Netw.*, vol. 32,
    no. 6, pp. 137–143, Nov. 2018.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] C. Liu, Y. Cao, Y. Luo *et al.*, “A New Deep Learning-Based Food Recognition
    System for Dietary Assessment on An Edge Computing Service Infrastructure,” *IEEE
    Trans. Serv. Comput.*, vol. 11, no. 2, pp. 249–261, Mar. 2018.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] D. Li, T. Salonidis, N. V. Desai, and M. C. Chuah, “DeepCham: Collaborative
    Edge-Mediated Adaptive Deep Learning for Mobile Object Recognition,” in *Proc.
    the First ACM/IEEE Symposium on Edge Computing (SEC 2016)*, 2016, pp. 64–76.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] B. Fang, X. Zeng, and M. Zhang, “NestDNN: Resource-Aware Multi-Tenant
    On-Device Deep Learning for Continuous Mobile Vision,” in *Proc. the 24th Annual
    International Conference on Mobile Computing and Networking (MobiCom 2018)*, 2018,
    pp. 115–127.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] S. Yi, Z. Hao, Q. Zhang *et al.*, “LAVEA: Latency-aware Video Analytics
    on Edge Computing Platform,” in *Proc. the Second ACM/IEEE Symposium on Edge Computing
    (SEC 2017)*, 2017, pp. 1–13.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] S. Y. Nikouei, Y. Chen, S. Song *et al.*, “Smart surveillance as an edge
    network service: From harr-cascade, svm to a lightweight cnn,” in *IEEE 4th International
    Conference on Collaboration and Internet Computing (CIC 2018)*, 2018, pp. 256–265.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] P. Liu, B. Qi, and S. Banerjee, “EdgeEye - An Edge Service Framework
    for Real-time Intelligent Video Analytics,” in *Proc. the 1st International Workshop
    on Edge Systems, Analytics and Networking (EdgeSys 2018)*, 2018, pp. 1–6.'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] C.-C. Hung, G. Ananthanarayanan, P. Bodik, L. Golubchik, M. Yu, P. Bahl,
    and M. Philipose, “VideoEdge: Processing Camera Streams using Hierarchical Clusters,”
    in *Proc. 2018 IEEE/ACM Symposium on Edge Computing (SEC 2018)*, 2018, pp. 115–131.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] Y. He, N. Zhao *et al.*, “Integrated Networking, Caching, and Computing
    for Connected Vehicles: A Deep Reinforcement Learning Approach,” *IEEE Trans.
    Veh. Technol.*, vol. 67, no. 1, pp. 44–55, Jan. 2018.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] Q. Qi and Z. Ma, “Vehicular Edge Computing via Deep Reinforcement Learning,”
    *arXiv preprint arXiv:1901.04290*, 2018.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] L. T. Tan and R. Q. Hu, “Mobility-Aware Edge Caching and Computing in
    Vehicle Networks: A Deep Reinforcement Learning,” *IEEE Trans. Veh. Technol.*,
    vol. 67, no. 11, pp. 10 190–10 203, Nov. 2018.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] L. Li, K. Ota, and M. Dong, “Deep Learning for Smart Industry: Efficient
    Manufacture Inspection System with Fog Computing,” *IEEE Trans. Ind. Inf.*, vol. 14,
    no. 10, pp. 4665–4673, 2018.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] L. Hu, Y. Miao, G. Wu *et al.*, “iRobot-Factory: An intelligent robot
    factory based on cognitive manufacturing and edge computing,” *Future Gener. Comput.
    Syst.*, vol. 90, pp. 569–577, Jan. 2019.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] J. A. C. Soto, M. Jentsch *et al.*, “CEML: Mixing and moving complex
    event processing and machine learning to the edge of the network for IoT applications,”
    in *Proc. the 6th International Conference on the Internet of Things (IoT 2016)*,
    2016, pp. 103–110.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] G. Plastiras, M. Terzi, C. Kyrkou, and T. Theocharidcs, “Edge Intelligence:
    Challenges and Opportunities of Near-Sensor Machine Learning Applications,” in
    *Proc. IEEE 29th International Conference on Application-specific Systems, Architectures
    and Processors (ASAP 2018)*, 2018, pp. 1–7.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] Y. Hao, Y. Miao, Y. Tian *et al.*, “Smart-Edge-CoCaCo: AI-Enabled Smart
    Edge with Joint Computation, Caching, and Communication in Heterogeneous IoT,”
    *arXiv preprint arXiv:1901.02126*, 2019.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] S. Liu, P. Si, M. Xu *et al.*, “Edge Big Data-Enabled Low-Cost Indoor
    Localization Based on Bayesian Analysis of RSS,” in *Proc. 2017 IEEE Wireless
    Communications and Networking Conference (WCNC 2017)*, 2017, pp. 1–6.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] A. Dhakal *et al.*, “Machine learning at the network edge for automated
    home intrusion monitoring,” in *Proc. IEEE 25th International Conference on Network
    Protocols (ICNP 2017)*, 2017, pp. 1–6.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] N. Tian, J. Chen, M. Ma *et al.*, “A Fog Robotic System for Dynamic Visual
    Servoing,” *arXiv preprint arXiv:1809.06716*, 2018.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] L. Lu, L. Xu, B. Xu *et al.*, “Fog Computing Approach for Music Cognition
    System Based on Machine Learning Algorithm,” *IEEE Trans. Comput. Social Syst.*,
    vol. 5, no. 4, pp. 1142–1151, Dec. 2018.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] B. Tang, Z. Chen, G. Hefferman *et al.*, “Incorporating Intelligence
    in Fog Computing for Big Data Analysis in Smart Cities,” *IEEE Trans. Ind. Inf.*,
    vol. 13, no. 5, pp. 2140–2150, Oct. 2017.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] Y.-C. Chang and Y.-H. Lai, “Campus Edge Computing Network Based on IoT
    Street Lighting Nodes,” *IEEE Syst. J. (Early Access)*, 2018.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] E. Denton *et al.*, “Exploiting Linear Structure Within Convolutional
    Networks for Efficient Evaluation,” in *Advances in Neural Information Processing
    Systems 27 (NeurIPS 2014)*, 2014, pp. 1269–1277.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] W. Chen, J. Wilson, S. Tyree *et al.*, “Compressing Neural Networks with
    the Hashing Trick,” in *Proc. the 32nd International Conference on International
    Conference on Machine Learning (ICML 2015)*, 2015, pp. 2285–2294.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] C. Szegedy, Wei Liu, Yangqing Jia *et al.*, “Going deeper with convolutions,”
    in *2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2015)*,
    2015, pp. 1–9.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] K. He, X. Zhang, S. Ren, and J. Sun, “Deep Residual Learning for Image
    Recognition,” in *2016 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR 2016)*, 2016, pp. 770–778.'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] Y. Cheng, D. Wang, P. Zhou, and T. Zhang, “A Survey of Model Compression
    and Acceleration for Deep Neural Networks,” *arXiv preprint arXiv:1710.09282*,
    2017.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] S. Han, J. Pool, J. Tran *et al.*, “Learning both Weights and Connections
    for Efficient Neural Networks,” in *Advances in Neural Information Processing
    Systems 28 (NeurIPS 2015)*, 2015, pp. 1135–1143.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] M. Alwani, H. Chen, M. Ferdman, and P. Milder, “Fused-layer CNN accelerators,”
    in *49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2016)*,
    2016, pp. 1–12.'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] M. Courbariaux, Y. Bengio, and J.-P. David, “BinaryConnect: Training
    Deep Neural Networks with binary weights during propagations,” in *Advances in
    Neural Information Processing Systems 28 (NeurIPS 2015)*, 2015, pp. 3123–3131.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] M. Rastegari, V. Ordonez *et al.*, “XNOR-Net: ImageNet Classification
    Using Binary Convolutional Neural Networks,” in *2018 European Conference on Computer
    Vision (ECCV 2016)*, 2016, pp. 525–542.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] B. Mcdanel, “Embedded Binarized Neural Networks,” in *Proc. the 2017
    International Conference on Embedded Wireless Systems and Networks (EWSN 2017)*,
    2017, pp. 168–173.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] F. N. Iandola, S. Han, M. W. Moskewicz *et al.*, “Squeezenet: Alexnet-level
    Accuracy with 50x Fewer Parameters and < 0.5 MB Model Size,” *arXiv preprint arXiv:1602.07360*,
    2016.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] A. G. Howard, M. Zhu, B. Chen *et al.*, “MobileNets: Efficient Convolutional
    Neural Networks for Mobile Vision Applications,” *arXiv preprint arXiv:1704.04861*,
    2017.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] R. Sharma, S. Biookaghazadeh *et al.*, “Are Existing Knowledge Transfer
    Techniques Effective For Deep Learning on Edge Devices?” in *Proc. the 27th International
    Symposium on High-Performance Parallel and Distributed Computing (HPDC 2018)*,
    2018, pp. 15–16.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] C. Zhang, Q. Cao, H. Jiang *et al.*, “FFS-VA: A Fast Filtering System
    for Large-scale Video Analytics,” in *Proc. the 47th International Conference
    on Parallel Processing (ICPP 2018)*, 2018, pp. 1–10.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] J. Jiang, G. Ananthanarayanan, P. Bodik, S. Sen, and I. Stoica, “Chameleon:
    Scalable adaptation of video analytics,” in *Proc. the 2018 Conference of the
    ACM Special Interest Group on Data Communication (SIGCOMM 2018)*, 2018, pp. 253–266.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] S. Y. Nikouei *et al.*, “Real-time human detection as an edge service
    enabled by a lightweight cnn,” in *2018 IEEE International Conference on Edge
    Computing (IEEE EDGE 2018)*, 2018, pp. 125–129.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] L. Liu, H. Li, and M. Gruteser, “Edge Assisted Real-time Object Detection
    for Mobile Augmented Reality,” in *Proc. the 25th Annual International Conference
    on Mobile Computing and Networking (MobiCom 2019)*, 2019, pp. 1–16.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] Fox, “Homer simpson.” [Online]. Available: [https://simpsons.fandom.com/wiki/File:Homer_Simpson.svg](https://simpsons.fandom.com/wiki/File:Homer_Simpson.svg)'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] X. Zhang, X. Zhou, M. Lin, and J. Sun, “Shufflenet: An extremely efficient
    convolutional neural network for mobile devices,” in *2018 IEEE/CVF Conference
    on Computer Vision and Pattern Recognition (CVPR 2018)*, 2018, pp. 6848–6856.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] L. Du *et al.*, “A Reconfigurable Streaming Deep Convolutional Neural
    Network Accelerator for Internet of Things,” *IEEE Trans. Circuits Syst. I Regul.
    Pap.*, vol. 65, no. 1, pp. 198–208, Jan. 2018.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] D. Kang, J. Emmons, F. Abuzaid, P. Bailis, and M. Zaharia, “NoScope:
    Optimizing Neural Network Queries over Video at Scale,” *Proceedings of the VLDB
    Endowment*, vol. 10, no. 11, pp. 1586–1597, Aug. 2017.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] S. Han, Y. Wang, H. Yang *et al.*, “ESE: Efficient Speech Recognition
    Engine with Sparse LSTM on FPGA,” in *Proc. the 2017 ACM/SIGDA International Symposium
    on Field-Programmable Gate Arrays (FPGA 2017)*, 2017, pp. 75–84.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] S. Han, H. Mao, and W. J. Dally, “Deep Compression: Compressing Deep
    Neural Networks with Pruning, Trained Quantization and Huffman Coding,” in *Proc.
    the 6th International Conference on Learning Representations (ICLR 2016)*, 2016.'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] S. Bhattacharya and N. D. Lane, “Sparsification and separation of deep
    learning layers for constrained resource inference on wearables,” in *Proc. the
    14th ACM Conference on Embedded Network Sensor Systems CD-ROM (SenSys 2016)*,
    2016, pp. 176–189.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] B. Taylor, V. S. Marco, W. Wolff *et al.*, “Adaptive deep learning model
    selection on embedded systems,” in *Proc. the 19th ACM SIGPLAN/SIGBED International
    Conference on Languages, Compilers, and Tools for Embedded Systems (LCTES 2018)*,
    2018, pp. 31–43.'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] S. Liu, Y. Lin, Z. Zhou *et al.*, “On-Demand Deep Model Compression for
    Mobile Devices,” in *Proc. the 16th Annual International Conference on Mobile
    Systems, Applications, and Services (MobiSys 2018)*, 2018, pp. 389–400.'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] L. Lai and N. Suda, “Enabling deep learning at the IoT edge,” in *Proc.
    the International Conference on Computer-Aided Design (ICCAD 2018)*, 2018, pp.
    1–6.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] S. Yao, Y. Zhao, A. Zhang *et al.*, “DeepIoT: Compressing Deep Neural
    Network Structures for Sensing Systems with a Compressor-Critic Framework,” in
    *Proc. the 15th ACM Conference on Embedded Network Sensor Systems (SenSys 2017)*,
    2017, pp. 1–14.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] S. Han, H. Shen, M. Philipose *et al.*, “MCDNN: An Execution Framework
    for Deep Neural Networks on Resource-Constrained Devices,” in *Proc. the 14th
    Annual International Conference on Mobile Systems, Applications, and Services
    (MobiSys 2016)*, 2016, pp. 123–136.'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] S. Han *et al.*, “EIE: Efficient Inference Engine on Compressed Deep
    Neural Network,” in *ACM/IEEE 43rd Annual International Symposium on Computer
    Architecture (ISCA 2016)*, 2016, pp. 243–254.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] N. D. Lane, S. Bhattacharya, P. Georgiev *et al.*, “DeepX: A Software
    Accelerator for Low-Power Deep Learning Inference on Mobile Devices,” in *15th
    ACM/IEEE International Conference on Information Processing in Sensor Networks
    (IPSN 2016)*, 2016, pp. 1–12.'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] J. Zhang *et al.*, “A Locally Distributed Mobile Computing Framework
    for DNN based Android Applications,” in *Proc. the Tenth Asia-Pacific Symposium
    on Internetware (Internetware 2018)*, 2018, pp. 1–6.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] Z. Zhao, K. M. Barijough, and A. Gerstlauer, “DeepThings: Distributed
    Adaptive Deep Learning Inference on Resource-Constrained IoT Edge Clusters,” *IEEE
    Trans. Comput. Aided Des. Integr. Circuits Syst.*, vol. 37, no. 11, pp. 2348–2359,
    Nov. 2018.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] Z. Zhao, Z. Jiang, N. Ling *et al.*, “ECRT: An Edge Computing System
    for Real-Time Image-based Object Tracking,” in *Proc. the 16th ACM Conference
    on Embedded Networked Sensor Systems (SenSys 2018)*, 2018, pp. 394–395.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] H. Li, K. Ota, and M. Dong, “Learning IoT in Edge: Deep Learning for
    the Internet of Things with Edge Computing,” *IEEE Netw.*, vol. 32, no. 1, pp.
    96–101, Jan. 2018.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] S. S. Ogden and T. Guo, “MODI: Mobile Deep Inference Made Efficient by
    Edge Computing,” in *{USENIX} Workshop on Hot Topics in Edge Computing (HotEdge
    2018)*, 2018.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] S. Teerapittayanon *et al.*, “BranchyNet: Fast inference via early exiting
    from deep neural networks,” in *Proc. the 23rd International Conference on Pattern
    Recognition (ICPR 2016)*, 2016, pp. 2464–2469.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] S. Teerapittayanon, B. McDanel, and H. T. Kung, “Distributed Deep Neural
    Networks over the Cloud, the Edge and End Devices,” in *IEEE 37th International
    Conference on Distributed Computing Systems (ICDCS 2017)*, 2017, pp. 328–339.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] E. Li, Z. Zhou, and X. Chen, “Edge Intelligence: On-Demand Deep Learning
    Model Co-Inference with Device-Edge Synergy,” in *Proc. the 2018 Workshop on Mobile
    Edge Communications (MECOMM 2018)*, 2018, pp. 31–36.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] U. Drolia, K. Guo, J. Tan *et al.*, “Cachier: Edge-Caching for Recognition
    Applications,” in *IEEE 37th International Conference on Distributed Computing
    Systems (ICDCS 2017)*, 2017, pp. 276–286.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] L. N. Huynh, Y. Lee, and R. K. Balan, “DeepMon: Mobile GPU-based Deep
    Learning Framework for Continuous Vision Applications,” in *Proc. the 15th Annual
    International Conference on Mobile Systems, Applications, and Services (MobiSys
    2017)*, 2017, pp. 82–95.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] M. Xu, M. Zhu *et al.*, “DeepCache: Principled Cache for Mobile Deep
    Vision,” in *Proc. the 24th Annual International Conference on Mobile Computing
    and Networking (MobiCom 2018)*, 2018, pp. 129–144.'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] P. Guo, B. Hu *et al.*, “FoggyCache: Cross-Device Approximate Computation
    Reuse,” in *Proc. the 24th Annual International Conference on Mobile Computing
    and Networking (MobiCom 2018)*, 2018, pp. 19–34.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] A. H. Jiang, D. L.-K. Wong, C. Canel, L. Tang, I. Misra, M. Kaminsky,
    M. A. Kozuch, P. Pillai, D. G. Andersen, and G. R. Ganger, “Mainstream: Dynamic
    Stem-sharing for Multi-tenant Video Processing,” in *Proc. the 2018 USENIX Conference
    on Usenix Annual Technical Conference (USENIX ATC 2018)*, 2018, pp. 29–41.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] Y. Chen, S. Biookaghazadeh, and M. Zhao, “Exploring the Capabilities
    of Mobile Devices Supporting Deep Learning,” in *Proc. the 27th International
    Symposium on High-Performance Parallel and Distributed Computing (HPDC 2018)*,
    2018, pp. 17–18.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] K. Simonyan and A. Zisserman, “Very deep convolutional networks for large-scale
    image recognition,” *arXiv preprint arXiv:1409.1556*, 2014.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] R. Venkatesan and B. Li, “Diving deeper into mentee networks,” *arXiv
    preprint arXiv:1604.08220*, 2016.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] S. Biookaghazadeh, F. Ren, and M. Zhao, “Are FPGAs Suitable for Edge
    Computing?” *arXiv preprint arXiv:1804.06404*, 2018.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] X. Ran, H. Chen, X. Zhu, Z. Liu, and J. Chen, “DeepDecision: A Mobile
    Deep Learning Framework for Edge Video Analytics,” in *2018 IEEE Conference on
    Computer Communications (INFOCOM 2018)*, 2018, pp. 1421–1429.'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] W. Zhang, Z. Zhang, S. Zeadally *et al.*, “MASM: A Multiple-algorithm
    Service Model for Energy-delay Optimization in Edge Artificial Intelligence,”
    *IEEE Trans. Ind. Inf. (Early Access)*, 2019.'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] M. Xu, F. Qian, M. Zhu, F. Huang, S. Pushp, and X. Liu, “DeepWear: Adaptive
    Local Offloading for On-Wearable Deep Learning,” *IEEE Trans. Mob. Comput. (Early
    Access)*, 2019.'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] H.-j. Jeong, H.-j. Lee, C. H. Shin, and S.-M. Moon, “IONN: Incremental
    Offloading of Neural Network Computations from Mobile Devices to Edge Servers,”
    in *Proc. the ACM Symposium on Cloud Computing (SoCC 2018)*, 2018, pp. 401–411.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] Y. Huang, X. Ma, X. Fan *et al.*, “When deep learning meets edge computing,”
    in *IEEE 25th International Conference on Network Protocols (ICNP 2017)*, 2017,
    pp. 1–2.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] J. Mao, X. Chen, K. W. Nixon *et al.*, “MoDNN: Local distributed mobile
    computing system for Deep Neural Network,” in *Design, Automation & Test in Europe
    Conference & Exhibition (DATE 2017)*, 2017, pp. 1396–1401.'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] E. Cuervo, A. Balasubramanian, D.-k. Cho *et al.*, “MAUI: Making Smartphones
    Last Longer with Code Offload,” in *Proc. the 8th international conference on
    Mobile systems, applications, and services (MobiSys 2010)*, 2010, pp. 49–62.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] X. Xu, Y. Ding, S. X. Hu, M. Niemier, J. Cong, Y. Hu, and Y. Shi, “Scaling
    for edge inference of deep neural networks,” *Nature Electronics*, vol. 1, no. 4,
    pp. 216–222, Apr. 2018.'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] M. Polese, R. Jana, V. Kounev *et al.*, “Machine Learning at the Edge:
    A Data-Driven Architecture with Applications to 5G Cellular Networks,” *arXiv
    preprint arXiv:1808.07647*, 2018.'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] L. Lai *et al.*, “Rethinking Machine Learning Development and Deployment
    for Edge Devices,” *arXiv preprint arXiv:1806.07846*, 2018.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] P. Meloni, O. Ripolles, D. Solans *et al.*, “ALOHA: an architectural-aware
    framework for deep learning at the edge,” in *Proc. the Workshop on INTelligent
    Embedded Systems Architectures and Applications (INTESA 2018)*, 2018, pp. 19–26.'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] X. Zhang, Y. Wang, S. Lu, L. Liu, L. Xu, and W. Shi, “OpenEI: An Open
    Framework for Edge Intelligence,” *arXiv preprint arXiv:1906.01864*, 2019.'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] J. Zhao, T. Tiplea, R. Mortier, J. Crowcroft, and L. Wang, “Data Analytics
    Service Composition and Deployment on IoT Devices,” in *Proc. the 16th Annual
    International Conference on Mobile Systems, Applications, and Services (MobiSys
    2018)*, 2018, pp. 502–504.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] N. Talagala, S. Sundararaman, V. Sridhar, D. Arteaga, Q. Luo, S. Subramanian,
    S. Ghanta, L. Khermosh, and D. Roselli, “ECO: Harmonizing edge and cloud with
    ml/dl orchestration,” in *USENIX Workshop on Hot Topics in Edge Computing (HotEdge
    2018)*.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] X. Zhang, Y. Wang, and W. Shi, “pCAMP: Performance Comparison of Machine
    Learning Packages on the Edges,” in *{USENIX} Workshop on Hot Topics in Edge Computing
    (HotEdge 2018)*, 2018.'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] C. Andrés Ramiro, C. Fiandrino, A. Blanco Pizarro *et al.*, “openLEON:
    An End-to-End Emulator from the Edge Data Center to the Mobile Users Carlos,”
    in *Proc. the 12th International Workshop on Wireless Network Testbeds, Experimental
    Evaluation & Characterization (WiNTECH 2018)*, 2018, pp. 19–27.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] Y. Wang, S. Liu, X. Wu, and W. Shi, “CAVBench: A Benchmark Suite for
    Connected and Autonomous Vehicles,” in *2018 IEEE/ACM Symposium on Edge Computing
    (SEC 2018)*, 2018, pp. 30–42.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] G. Kamath, P. Agnihotri, M. Valero *et al.*, “Pushing Analytics to the
    Edge,” in *2016 IEEE Global Communications Conference (GLOBECOM 2016)*, 2016,
    pp. 1–6.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] L. Valerio, A. Passarella, and M. Conti, “A communication efficient distributed
    learning framework for smart environments,” *Pervasive Mob. Comput.*, vol. 41,
    pp. 46–68, Oct. 2017.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] Y. Lin, S. Han, H. Mao *et al.*, “Deep Gradient Compression: Reducing
    the Communication Bandwidth for Distributed Training,” *eprint arXiv:1712.01887*,
    2017.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] Z. Tao and C. William, “eSGD : Communication Efficient Distributed Deep
    Learning on the Edge,” in *{USENIX} Workshop on Hot Topics in Edge Computing (HotEdge
    2018)*, 2018, pp. 1–6.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] N. Strom, “Scalable distributed DNN training using commodity GPU cloud
    computing,” in *16th Annual Conference of the International Speech Communication
    Association (INTERSPEECH 2015)*, 2015, pp. 1488–1492.'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] E. Jeong, S. Oh, H. Kim *et al.*, “Communication-Efficient On-Device
    Machine Learning: Federated Distillation and Augmentation under Non-IID Private
    Data,” *arXiv preprint arXiv:1811.11479*, 2018.'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] M. Fredrikson, S. Jha, and T. Ristenpart, “Model Inversion Attacks That
    Exploit Confidence Information and Basic Countermeasures,” in *Proc. the 22nd
    ACM SIGSAC Conference on Computer and Communications Security (CCS 2015)*, 2015,
    pp. 1322–1333.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] M. Du, K. Wang, Z. Xia, and Y. Zhang, “Differential Privacy Preserving
    of Training Model in Wireless Big Data with Edge Computing,” *IEEE Trans. Big
    Data (Early Access)*, 2018.'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to
    sensitivity in private data analysis,” in *Theory of Cryptography*.   Springer
    Berlin Heidelberg, 2006, pp. 265–284.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] H. B. McMahan, E. Moore, D. Ramage *et al.*, “Communication-efficient
    learning of deep networks from decentralized data,” in *Proc. the 20th International
    Conference on Artificial Intelligence and Statistics (AISTATS 2017)*, 2017, pp.
    1273–1282.'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] K. Bonawitz, H. Eichner *et al.*, “Towards Federated Learning at Scale:
    System Design,” *arXiv preprint arXiv:1902.01046*, 2019.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] S. Samarakoon, M. Bennis, W. Saad, and M. Debbah, “Distributed federated
    learning for ultra-reliable low-latency vehicular communications,” *IEEE Trans.
    Commun. (Early Access)*, 2019.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] C. Xie, S. Koyejo, and I. Gupta, “Practical Distributed Learning: Secure
    Machine Learning with Communication-Efficient Local Updates,” *arXiv preprint
    arXiv:1903.06996*, 2019.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] M. S. H. Abad, E. Ozfatura, D. Gunduz, and O. Ercetin, “Hierarchical
    Federated Learning Across Heterogeneous Cellular Networks,” *arXiv preprint arXiv:
    1909.02362*, 2019.'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] J. Konečný, H. B. McMahan, F. X. Yu *et al.*, “Federated Learning: Strategies
    for Improving Communication Efficiency,” *arXiv preprint arXiv:1610.05492*, 2016.'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani,
    “FedPAQ: A Communication-Efficient Federated Learning Method with Periodic Averaging
    and Quantization,” *arXiv preprint arXiv:1909.13014*, 2019.'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] S. Caldas, J. Konečny, H. B. McMahan, and A. Talwalkar, “Expanding the
    Reach of Federated Learning by Reducing Client Resource Requirements,” *arXiv
    preprint arXiv:1812.07210*, 2018.'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] B. S. Kashin, “Diameters of some finite-dimensional sets and classes
    of smooth functions,” *Izv. Akad. Nauk SSSR Ser. Mat.*, vol. 41, pp. 334–351,
    1977.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] Y. Jiang, S. Wang, B. J. Ko, W.-H. Lee, and L. Tassiulas, “Model Pruning
    Enables Efficient Federated Learning on Edge Devices,” *arXiv preprint arXiv:1909.12326*,
    2019.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] S. Wang, T. Tuor, T. Salonidis *et al.*, “When Edge Meets Learning: Adaptive
    Control for Resource-Constrained Distributed Machine Learning,” in *IEEE Conference
    on Computer Communications (INFOCOM 2018)*, Apr. 2018, pp. 63–71.'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] S. Wang, T. Tuor, T. Salonidis *et al.*, “Adaptive federated learning
    in resource constrained edge computing systems,” *IEEE J. Sel. Areas Commun.*,
    vol. 37, no. 6, pp. 1205–1221, Jun. 2019.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] T. Tuor, S. Wang, T. Salonidis *et al.*, “Demo abstract: Distributed
    machine learning at resource-limited edge nodes,” in *2018 IEEE Conference on
    Computer Communications Workshops (INFOCOM WKSHPS 2018)*, 2018, pp. 1–2.'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] H. Hu, D. Wang, and C. Wu, “Distributed Machine Learning through Heterogeneous
    Edge Systems,” *arXiv preprint arXiv:1911.06949*, 2019.'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] M. Duan, “Astraea: Self-balancing Federated Learning for Improving Classification
    Accuracy of Mobile Deep Learning Applications,” *arXiv preprint arXiv:1907.01132*,
    2019.'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] S. Kullback and R. A. Leibler, “On information and sufficiency,” *The
    Annals of Mathematical Statistics*, vol. 22, no. 1, pp. 79–86, 1951.'
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] K. Yang, T. Jiang, Y. Shi, and Z. Ding, “Federated Learning via Over-the-Air
    Computation,” *arXiv preprint arXiv:1812.11750*, 2018.'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] B. Nazer *et al.*, “Computation over multiple-access channels,” *IEEE
    Trans. Inf. Theory*, vol. 53, no. 10, pp. 3498–3516, Oct. 2007.'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] L. Chen, N. Zhao, Y. Chen *et al.*, “Over-the-Air Computation for IoT
    Networks: Computing Multiple Functions With Antenna Arrays,” *IEEE Internet Things
    J.*, vol. 5, no. 6, pp. 5296–5306, Dec. 2018.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] G. Zhu, Y. Wang, and K. Huang, “Broadband Analog Aggregation for Low-Latency
    Federated Edge Learning (Extended Version),” *arXiv preprint arXiv:1812.11494*,
    2018.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] Z. Xu, Z. Yang, J. Xiong, J. Yang, and X. Chen, “ELFISH: Resource-Aware
    Federated Learning on Heterogeneous Edge Devices,” *arXiv preprint arXiv:1912.01684*,
    2019.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] C. Dinh, N. H. Tran, M. N. H. Nguyen, C. S. Hong, W. Bao, A. Y. Zomaya,
    and V. Gramoli, “Federated Learning over Wireless Networks: Convergence Analysis
    and Resource Allocation,” *arXiv preprint arXiv:1910.13067*, 2019.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] M. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, “A Joint Learning
    and Communications Framework for Federated Learning over Wireless Networks,” *arXiv
    preprint arXiv:1909.07972*, 2019.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] T. Li, M. Sanjabi, and V. Smith, “Fair Resource Allocation in Federated
    Learning,” *arXiv preprint arXiv:1905.10497*, 2019.'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] K. Bonawitz, V. Ivanov, B. Kreuter *et al.*, “Practical Secure Aggregation
    for Privacy-Preserving Machine Learning,” in *Proc. the 2017 ACM SIGSAC Conference
    on Computer and Communications Security (CCS 2017)*, 2017, pp. 1175–1191.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] H. Kim, J. Park, M. Bennis, and S.-L. Kim, “On-Device Federated Learning
    via Blockchain and its Latency Analysis,” *arXiv preprint arXiv:1808.03949*, 2018.'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] J. E. Stiglitz, “Self-selection and pareto efficient taxation,” *Journal
    of Public Economics*, vol. 17, no. 2, pp. 213 – 240, 1982.'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] H. W. Kuhn, “The hungarian method for the assignment problem,” *Naval
    Research Logistics Quarterly*, vol. 2, no. 1‐2, pp. 83–97, 1955.'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] H. SHI, R. V. Prasad, E. Onur, and I. G. M. M. Niemegeers, “Fairness
    in wireless networks:issues, measures and challenges,” *IEEE Commun. Surv. Tutor.*,
    vol. 16, no. 1, pp. 5–24, First 2014.'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] M. Hofmann and L. Beaumont, “Chapter 3 - caching techniques for web content,”
    in *Content Networking*, 2005, pp. 53–79.'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] X. Wang, M. Chen, T. Taleb *et al.*, “Cache in the air: Exploiting content
    caching and delivery techniques for 5G systems,” *IEEE Commun. Mag.*, vol. 52,
    no. 2, pp. 131–139, Feb. 2014.'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] E. Zeydan, E. Bastug, M. Bennis *et al.*, “Big data caching for networking:
    moving from cloud to edge,” *IEEE Commun. Mag.*, vol. 54, no. 9, pp. 36–42, Sep.
    2016.'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] J. Song, M. Sheng, T. Q. S. Quek *et al.*, “Learning-based content caching
    and sharing for wireless networks,” *IEEE Trans. Commun.*, vol. 65, no. 10, pp.
    4309–4324, Oct. 2017.'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] X. Li, X. Wang, P.-J. Wan *et al.*, “Hierarchical Edge Caching in Device-to-Device
    Aided Mobile Networks: Modeling, Optimization, and Design,” *IEEE J. Sel. Areas
    Commun.*, vol. 36, no. 8, pp. 1768–1785, Aug. 2018.'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] S. Rathore, J. H. Ryu, P. K. Sharma, and J. H. Park, “DeepCachNet: A
    Proactive Caching Framework Based on Deep Learning in Cellular Networks,” *IEEE
    Netw.*, vol. 33, no. 3, pp. 130–138, May 2019.'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] Z. Chang, L. Lei, Z. Zhou *et al.*, “Learn to Cache: Machine Learning
    for Network Edge Caching in the Big Data Era,” *IEEE Wireless Commun.*, vol. 25,
    no. 3, pp. 28–35, Jun. 2018.'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] J. Yang, J. Zhang, C. Ma *et al.*, “Deep learning-based edge caching
    for multi-cluster heterogeneous networks,” *Neural Computing and Applications*,
    Feb. 2019.'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] A. Ndikumana, N. H. Tran, and C. S. Hong, “Deep Learning Based Caching
    for Self-Driving Car in Multi-access Edge Computing,” *arXiv preprint arXiv:1810.01548*,
    2018.'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] T. Kanungo, D. M. Mount *et al.*, “An Efficient k-Means Clustering Algorithm:
    Analysis and Implementation,” *IEEE Trans. Pattern Anal. Mach. Intell.*, vol. 24,
    no. 7, pp. 881–892, Jul. 2002.'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] Y. Tang, K. Guo *et al.*, “A smart caching mechanism for mobile multimedia
    in information centric networking with edge computing,” *Future Gener. Comput.
    Syst.*, vol. 91, pp. 590–600, Feb. 2019.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] D. Adelman and A. J. Mersereau, “Relaxations of weakly coupled stochastic
    dynamic programs,” *Operations Research*, vol. 56, no. 3, pp. 712–727, 2008.'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] H. Zhu, Y. Cao, W. Wang *et al.*, “Deep Reinforcement Learning for Mobile
    Edge Caching: Review, New Features, and Open Issues,” *IEEE Netw.*, vol. 32, no. 6,
    pp. 50–57, Nov. 2018.'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] K. Guo, C. Yang, and T. Liu, “Caching in Base Station with Recommendation
    via Q-Learning,” in *2017 IEEE Wireless Communications and Networking Conference
    (WCNC 2017)*, 2017, pp. 1–6.'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] C. Zhong, M. C. Gursoy *et al.*, “A deep reinforcement learning-based
    framework for content caching,” in *52nd Annual Conference on Information Sciences
    and Systems (CISS 2018)*, 2018, pp. 1–6.'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] G. Dulac-Arnold, R. Evans, H. van Hasselt *et al.*, “Deep Reinforcement
    Learning in Large Discrete Action Spaces,” *arXiv preprint arXiv:1512.07679*,
    2015.'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] P. Mach and Z. Becvar, “Mobile edge computing: A survey on architecture
    and computation offloading,” *IEEE Commun. Surveys Tuts.*, vol. 19, no. 3, pp.
    1628–1656, Thirdquarter 2017.'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] X. Chen, L. Jiao, W. Li, and X. Fu, “Efficient multi-user computation
    offloading for mobile-edge cloud computing,” *IEEE/ACM Trans. Netw.*, vol. 24,
    no. 5, pp. 2795–2808, Oct. 2016.'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] J. Xu, L. Chen *et al.*, “Online Learning for Offloading and Autoscaling
    in Energy Harvesting Mobile Edge Computing,” *IEEE Trans. on Cogn. Commun. Netw.*,
    vol. 3, no. 3, pp. 361–373, Sep. 2017.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] T. Q. Dinh, Q. D. La, T. Q. S. Quek, and H. Shin, “Distributed Learning
    for Computation Offloading in Mobile Edge Computing,” *IEEE Trans. Commun.*, vol. 66,
    no. 12, pp. 6353–6367, Dec. 2018.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] T. Chen and G. B. Giannakis, “Bandit convex optimization for scalable
    and dynamic iot management,” *IEEE Internet Things J.*, vol. 6, no. 1, pp. 1276–1286,
    Feb. 2019.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] K. Zhang, Y. Zhu, S. Leng, Y. He, S. Maharjan, and Y. Zhang, “Deep Learning
    Empowered Task Offloading for Mobile Edge Computing in Urban Informatics,” *IEEE
    Internet Things J.*, vol. 6, no. 5, pp. 7635–7647, Oct. 2019.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] S. Yu, X. Wang, and R. Langar, “Computation offloading for mobile edge
    computing: A deep learning approach,” in *IEEE 28th Annual International Symposium
    on Personal, Indoor, and Mobile Radio Communications (PIMRC 2017)*, 2017, pp.
    1–6.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] T. Yang, Y. Hu, M. C. Gursoy *et al.*, “Deep Reinforcement Learning based
    Resource Allocation in Low Latency Edge Computing Networks,” in *15th International
    Symposium on Wireless Communication Systems (ISWCS 2018)*, 2018, pp. 1–5.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] X. Chen, H. Zhang, C. Wu, S. Mao, Y. Ji, and M. Bennis, “Optimized computation
    offloading performance in virtual edge computing systems via deep reinforcement
    learning,” *IEEE Internet Things J.*, vol. 6, no. 3, pp. 4005–4018, Jun. 2019.'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] N. C. Luong, Z. Xiong, P. Wang, and D. Niyato, “Optimal Auction for Edge
    Computing Resource Management in Mobile Blockchain Networks: A Deep Learning Approach,”
    in *2018 IEEE International Conference on Communications (ICC 2018)*, 2018, pp.
    1–6.'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] J. Li, H. Gao, T. Lv, and Y. Lu, “Deep reinforcement learning based computation
    offloading and resource allocation for MEC,” in *2018 IEEE Wireless Communications
    and Networking Conference (WCNC 2018)*, 2018, pp. 1–6.'
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] M. Min, L. Xiao, Y. Chen *et al.*, “Learning-based computation offloading
    for iot devices with energy harvesting,” *IEEE Trans. Veh. Technol.*, vol. 68,
    no. 2, pp. 1930–1941, Feb. 2019.'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] Z. Chen and X. Wang, “Decentralized Computation Offloading for Multi-User
    Mobile Edge Computing: A Deep Reinforcement Learning Approach,” *arXiv preprint
    arXiv:1812.07394*, 2018.'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] T. Chen *et al.*, “Harnessing Bandit Online Learning to Low-Latency Fog
    Computing,” in *2018 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP 2018)*, 2018, pp. 6418–6422.'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] Q. Zhang, M. Lin, L. T. Yang, Z. Chen, S. U. Khan, and P. Li, “A double
    deep q-learning model for energy-efficient edge scheduling,” *IEEE Trans. Serv.
    Comput.*, vol. 12, no. 05, pp. 739–749, Jan. 2019.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] L. Huang, S. Bi, and Y.-j. A. Zhang, “Deep Reinforcement Learning for
    Online Offloading in Wireless Powered Mobile-Edge Computing Networks,” *arXiv
    preprint arXiv:1808.01977*, 2018.'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] S. Memon *et al.*, “Using machine learning for handover optimization
    in vehicular fog computing,” in *Proc. the 34th ACM/SIGAPP Symposium on Applied
    Computing (SAC 2019)*, 2019, pp. 182–190.'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Y. Sun, M. Peng, and S. Mao, “Deep reinforcement learning-based mode
    selection and resource management for green fog radio access networks,” *IEEE
    Internet Things J.*, vol. 6, no. 2, pp. 1960–1971, 2019.'
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] L. Xiao, X. Wan, C. Dai *et al.*, “Security in mobile edge caching with
    reinforcement learning,” *IEEE Wireless Commun.*, vol. 25, no. 3, pp. 116–122,
    Jun. 2018.'
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Y. Wei, F. R. Yu, M. Song, and Z. Han, “Joint optimization of caching,
    computing, and radio resources for fog-enabled iot using natural actor–critic
    deep reinforcement learning,” *IEEE Internet Things J.*, vol. 6, no. 2, pp. 2061–2073,
    Apr. 2019.'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] D. C. Nguyen, P. N. Pathirana, M. Ding, and A. Seneviratne, “Secure Computation
    Offloading in Blockchain based IoT Networks with Deep Reinforcement Learning,”
    *arXiv preprint arXiv:1908.07466*, 2018.'
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] C.-Y. Li, H.-Y. Liu *et al.*, “Mobile Edge Computing Platform Deployment
    in 4G LTE Networks : A Middlebox Approach,” in *{USENIX} Workshop on Hot Topics
    in Edge Computing (HotEdge 2018)*, 2018.'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] Q. Mao, F. Hu, and Q. Hao, “Deep learning for intelligent wireless networks:
    A comprehensive survey,” *IEEE Commun. Surveys Tuts.*, vol. 20, no. 4, pp. 2595–2621,
    Fourthquarter 2018.'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] R. Li, Z. Zhao, X. Zhou *et al.*, “Intelligent 5g: When cellular networks
    meet artificial intelligence,” *IEEE Wireless Commun.*, vol. 24, no. 5, pp. 175–183,
    Oct. 2017.'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] X. Chen, J. Wu, Y. Cai *et al.*, “Energy-efficiency oriented traffic
    offloading in wireless networks: A brief survey and a learning approach for heterogeneous
    cellular networks,” *IEEE J. Sel. Areas Commun.*, vol. 33, no. 4, pp. 627–640,
    Apr. 2015.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] R. Dong, C. She, W. Hardjawana, Y. Li, and B. Vucetic, “Deep Learning
    for Hybrid 5G Services in Mobile Edge Computing Systems: Learn From a Digital
    Twin,” *IEEE Trans. Wirel. Commun.*, vol. 18, no. 10, pp. 4692–4707, Oct. 2019.'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Y. Chen, Y. Zhang, S. Maharjan, M. Alam, and T. Wu, “Deep Learning for
    Secure Mobile Edge Computing in Cyber-Physical Transportation Systems,” *IEEE
    Netw.*, vol. 33, no. 4, pp. 36–41, 2019.'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] M. Min, X. Wan, L. Xiao *et al.*, “Learning-Based Privacy-Aware Offloading
    for Healthcare IoT with Energy Harvesting,” *IEEE Internet Things J. (Early Access)*,
    2018.'
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] T. E. Bogale, X. Wang, and L. B. Le, “Machine Intelligence Techniques
    for Next-Generation Context-Aware Wireless Networks,” *arXiv preprint arXiv:1801.04223*,
    2018.'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] D. Kreutz *et al.*, “Software-defined networking: A comprehensive survey,”
    *Proc. IEEE*, vol. 103, no. 1, pp. 14–76, Jan. 2015.'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] Y. He, F. R. Yu, N. Zhao *et al.*, “Software-defined networks with mobile
    edge computing and caching for smart cities: A big data deep reinforcement learning
    approach,” *IEEE Commun. Mag.*, vol. 55, no. 12, pp. 31–37, Dec. 2017.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] Y. Gan, Y. Zhang, D. Cheng *et al.*, “An Open-Source Benchmark Suite
    for Microservices and Their Hardware-Software Implications for Cloud and Edge
    Systems,” in *Proc. the Twenty Fourth International Conference on Architectural
    Support for Programming Languages and Operating Systems (ASPLOS 2019)*, 2019.'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] M. Alam, J. Rufino, J. Ferreira, S. H. Ahmed, N. Shah, and Y. Chen, “Orchestration
    of Microservices for IoT Using Docker and Edge Computing,” *IEEE Commun. Mag.*,
    vol. 56, no. 9, pp. 118–123, 2018.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] J. Xu, S. Wang, B. Bhargava, and F. Yang, “A Blockchain-enabled Trustless
    Crowd-Intelligence Ecosystem on Mobile Edge Computing,” *IEEE Trans. Ind. Inf.
    (Early Access)*, 2019.'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] Z. Zheng, S. Xie, H. Dai *et al.*, “An overview of blockchain technology:
    Architecture, consensus, and future trends,” in *2017 IEEE International Congress
    on Big Data (BigData Congress 2017)*, 2017, pp. 557–564.'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] J.-y. Kim and S.-M. Moon, “Blockchain-based edge computing for deep neural
    network applications,” in *Proc. the Workshop on INTelligent Embedded Systems
    Architectures and Applications (INTESA 2018)*, 2018, pp. 53–55.'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] G. Wood, “Ethereum: A secure decentralised generalised transaction ledger,”
    2014\. [Online]. Available: [http://gavwood.com/Paper.pdf](http://gavwood.com/Paper.pdf)'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] S. Zheng, Q. Meng, T. Wang *et al.*, “Asynchronous stochastic gradient
    descent with delay compensation,” in *Proc. the 34th International Conference
    on Machine Learning (ICML 2017)*, 2017, pp. 4120–4129.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] C. Xie, S. Koyejo, and I. Gupta, “Asynchronous Federated Optimization,”
    *arXiv preprint arXiv:1903.03934*, 2019.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] W. Wu, L. He, W. Lin, RuiMao, and S. Jarvis, “SAFA: a Semi-Asynchronous
    Protocol for Fast Federated Learning with Low Overhead,” *arXiv preprint arXiv:1910.01355*,
    2019.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] T. Nishio and R. Yonetani, “Client Selection for Federated Learning with
    Heterogeneous Resources in Mobile Edge,” *arXiv preprint arXiv:1804.08333*, 2018.'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] T. Xing, S. S. Sandha, B. Balaji *et al.*, “Enabling Edge Devices that
    Learn from Each Other: Cross Modal Training for Activity Recognition,” in *Proc.
    the 1st International Workshop on Edge Systems, Analytics and Networking (EdgeSys
    2018)*, 2018, pp. 37–42.'
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] J. Yoon, P. Liu, and S. Banerjee, “Low-Cost Video Transcoding at the
    Wireless Edge,” in *2016 IEEE/ACM Symposium on Edge Computing (SEC 2016)*, 2016,
    pp. 129–141.'
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] N. Kato *et al.*, “The deep learning vision for heterogeneous network
    traffic control: Proposal, challenges, and future perspective,” *IEEE Wireless
    Commun.*, vol. 24, no. 3, pp. 146–153, Jun. 2017.'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] Z. M. Fadlullah, F. Tang, B. Mao *et al.*, “State-of-the-art deep learning:
    Evolving machine intelligence toward tomorrow’s intelligent network traffic control
    systems,” *IEEE Commun. Surveys Tuts.*, vol. 19, no. 4, pp. 2432–2455, Fourthquarter
    2017.'
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] J. Foerster, I. A. Assael *et al.*, “Learning to communicate with deep
    multi-agent reinforcement learning,” in *Advances in Neural Information Processing
    Systems 29 (NeurIPS 2016)*, 2016, pp. 2137–2145.'
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] S. Omidshafiei, J. Pazis, C. Amato *et al.*, “Deep decentralized multi-task
    multi-agent reinforcement learning under partial observability,” in *Proc. the
    34th International Conference on Machine Learning (ICML 2017)*, 2017, pp. 2681–2690.'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] R. Lowe, Y. WU *et al.*, “Multi-agent actor-critic for mixed cooperative-competitive
    environments,” in *Advances in Neural Information Processing Systems 30 (NeurIPS
    2017)*, 2017, pp. 6379–6390.'
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] J. Zhou, G. Cui *et al.*, “Graph neural networks: A review of methods
    and applications,” *arXiv preprint arXiv:1812.08434*, 2018.'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] Z. Zhang, P. Cui, and W. Zhu, “Deep learning on graphs: A survey,” *arXiv
    preprint arXiv:1812.04202*, 2018.'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '| ![[Uncaptioned image]](img/1bee7c3d772bdebc312641af9ff7741e.png) | Xiaofei
    Wang [S’06, M’13, SM’18] is currently a Professor with the Tianjin Key Laboratory
    of Advanced Networking, School of Computer Science and Technology, Tianjin University,
    China. He got master and doctor degrees in Seoul National University from 2006
    to 2013, and was a Post-Doctoral Fellow with The University of British Columbia
    from 2014 to 2016\. Focusing on the research of social-aware cloud computing,
    cooperative cell caching, and mobile traffic offloading, he has authored over
    100 technical papers in the IEEE JSAC, the IEEE TWC, the IEEE WIRELESS COMMUNICATIONS,
    the IEEE COMMUNICATIONS, the IEEE TMM, the IEEE INFOCOM, and the IEEE SECON. He
    was a recipient of the National Thousand Talents Plan (Youth) of China. He received
    the “Scholarship for Excellent Foreign Students in IT Field” by NIPA of South
    Korea from 2008 to 2011, the “Global Outstanding Chinese Ph.D. Student Award”
    by the Ministry of Education of China in 2012, and the Peiyang Scholar from Tianjin
    University. In 2017, he received the “Fred W. Ellersick Prize” from the IEEE Communication
    Society. |'
  id: totrans-831
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/7131c7d234e7cc824c4ce4c8da1eb6a8.png) | Yiwen
    Han [S’18] received his B.S. degree from Nanchang University, China, and M.S.
    degree from Tianjin University, China, in 2015 and 2018, respectively, both in
    communication engineering. He received the Outstanding B.S. Graduates in 2015
    and M.S. National Scholarship of China in 2016. He is currently pursuing the Ph.D.
    degree in computer science at Tianjin University. His current research interests
    include edge computing, reinforcement learning, and deep learning. |'
  id: totrans-832
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/ff420f55034a176c3920bf5c571248e0.png) | Victor
    C. M. Leung [S’75, M’89, SM’97, F’03] is a Distinguished Professor of Computer
    Science and Software Engineering at Shenzhen University. He was a Professor of
    Electrical and Computer Engineering and holder of the TELUS Mobility Research
    Chair at the University of British Columbia (UBC) when he retired from UBC in
    2018 and became a Professor Emeritus. His research is in the broad areas of wireless
    networks and mobile systems. He has co-authored more than 1300 journal/conference
    papers and book chapters. Dr. Leung is serving on the editorial boards of the
    IEEE Transactions on Green Communications and Networking, IEEE Transactions on
    Cloud Computing, IEEE Access, IEEE Network, and several other journals. He received
    the IEEE Vancouver Section Centennial Award, 2011 UBC Killam Research Prize, 2017
    Canadian Award for Telecommunications Research, and 2018 IEEE TCGCC Distinguished
    Technical Achievement Recognition Award. He co-authored papers that won the 2017
    IEEE ComSoc Fred W. Ellersick Prize, 2017 IEEE Systems Journal Best Paper Award,
    2018 IEEE CSIM Best Journal Paper Award, and 2019 IEEE TCGCC Best Journal Paper
    Award. He is a Fellow of IEEE, the Royal Society of Canada, Canadian Academy of
    Engineering, and Engineering Institute of Canada. He is named in the current Clarivate
    Analytics list of “Highly Cited Researchers”. |'
  id: totrans-833
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/cd8cfc58098d295fe91f0fe7c1275d4b.png) | Dusit
    Niyato [M’09, SM’15, F’17] is currently a Professor in the School of Computer
    Science and Engineering, at Nanyang Technological University,Singapore. He received
    B.Eng. from King Mongkuts Institute of Technology Ladkrabang (KMITL), Thailand
    in 1999 and Ph.D. in Electrical and Computer Engineering from the University of
    Manitoba, Canada in 2008\. His research interests are in the area of Internet
    of Things (IoT) and network resource pricing. |'
  id: totrans-834
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/a9a240598a23d31519dd946122a5a772.png) | Xueqiang
    Yan is currently a technology expert with Wireless Technology Lab at Huawei Technologies.
    He was a member of technical staff of Bell Labs from 2000 to 2004\. From 2004
    to 2016 he was a director of Strategy Department of Alcatel-Lucent Shanghai Bell.
    His current research interests include wireless networking, Internet of Things,
    edge AI, future mobile network architecture, network convergence and evolution.
    |'
  id: totrans-835
  prefs: []
  type: TYPE_TB
- en: '| ![[Uncaptioned image]](img/0a383f3bc8fa2ca6e13bc394af7319f1.png) | Xu Chen
    [M’12] is a Full Professor with Sun Yat-sen University, Guangzhou, China, and
    the vice director of National and Local Joint Engineering Laboratory of Digital
    Home Interactive Applications. He received the Ph.D. degree in information engineering
    from the Chinese University of Hong Kong in 2012, and worked as a Postdoctoral
    Research Associate at Arizona State University, Tempe, USA from 2012 to 2014,
    and a Humboldt Scholar Fellow at Institute of Computer Science of University of
    Goettingen, Germany from 2014 to 2016\. He received the prestigious Humboldt research
    fellowship awarded by Alexander von Humboldt Foundation of Germany, 2014 Hong
    Kong Young Scientist Runner-up Award, 2016 Thousand Talents Plan Award for Young
    Professionals of China, 2017 IEEE Communication Society Asia-Pacific Outstanding
    Young Researcher Award, 2017 IEEE ComSoc Young Professional Best Paper Award,
    Honorable Mention Award of 2010 IEEE international conference on Intelligence
    and Security Informatics (ISI), Best Paper Runner-up Award of 2014 IEEE International
    Conference on Computer Communications (INFOCOM), and Best Paper Award of 2017
    IEEE Intranational Conference on Communications (ICC). He is currently an Associate
    Editor of IEEE Internet of Things Journal and IEEE Transactions on Wireless Communications,
    and Area Editor of IEEE Open Journal of the Communications Society. |'
  id: totrans-836
  prefs: []
  type: TYPE_TB
