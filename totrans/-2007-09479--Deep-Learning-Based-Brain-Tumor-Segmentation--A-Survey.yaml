- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:00:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 20:00:17'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2007.09479] Deep Learning Based Brain Tumor Segmentation: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2007.09479] 基于深度学习的脑肿瘤分割：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2007.09479](https://ar5iv.labs.arxiv.org/html/2007.09479)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2007.09479](https://ar5iv.labs.arxiv.org/html/2007.09479)
- en: 'Deep Learning Based Brain Tumor Segmentation: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于深度学习的脑肿瘤分割：综述
- en: Zhihua Liu Lei Tong Zheheng Jiang Long Chen Feixiang Zhou Qianni Zhang Xiangrong
    Zhang Yaochu Jin Huiyu Zhou [hz143@leicester.ac.uk](mailto:hz143@leicester.ac.uk)
    School of Computing and Mathematical Sciences, University of Leicester, United
    Kingdom School of Computing and Communications, University of Lancaster, United
    Kingdom School of Electronic Engineering and Computer Science, Queen Mary, University
    of London, United Kingdom School of Artificial Intelligence, Xidian University,
    China Faculty of Technology, Bielefeld University, Germany
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Zhihua Liu Lei Tong Zheheng Jiang Long Chen Feixiang Zhou Qianni Zhang Xiangrong
    Zhang Yaochu Jin Huiyu Zhou [hz143@leicester.ac.uk](mailto:hz143@leicester.ac.uk)
    莱斯特大学计算与数学科学学院，英国 兰卡斯特大学计算与通信学院，英国 伦敦大学玛丽女王学院电子工程与计算机科学学院，英国 西安电子科技大学人工智能学院，中国
    比勒费尔德大学技术学院，德国
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Brain tumor segmentation is one of the most challenging problems in medical
    image analysis. The goal of brain tumor segmentation is to generate accurate delineation
    of brain tumor regions. In recent years, deep learning methods have shown promising
    performance in solving various computer vision problems, such as image classification,
    object detection and semantic segmentation. A number of deep learning based methods
    have been applied to brain tumor segmentation and achieved promising results.
    Considering the remarkable breakthroughs made by state-of-the-art technologies,
    we use this survey to provide a comprehensive study of recently developed deep
    learning based brain tumor segmentation techniques. More than 100 scientific papers
    are selected and discussed in this survey, extensively covering technical aspects
    such as network architecture design, segmentation under imbalanced conditions,
    and multi-modality processes. We also provide insightful discussions for future
    development directions.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 脑肿瘤分割是医学图像分析中最具挑战性的问题之一。脑肿瘤分割的目标是生成准确的脑肿瘤区域轮廓。近年来，深度学习方法在解决各种计算机视觉问题上表现出色，如图像分类、物体检测和语义分割。许多基于深度学习的方法已应用于脑肿瘤分割，并取得了令人满意的结果。考虑到最先进技术取得的显著突破，我们使用这份综述对最近开发的基于深度学习的脑肿瘤分割技术进行全面研究。我们选择并讨论了100多篇科学论文，广泛涵盖了网络架构设计、在不平衡条件下的分割和多模态处理等技术方面。我们还对未来发展方向提供了有益的讨论。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 'keywords:'
- en: 'Brain tumor segmentation, deep learning, network design, data imbalance, multi modalities^†^†journal:
    Journal of LaTeX Templates![Refer to caption](img/1178c1e6c849df8e16da6d27b3fe6670.png)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '脑肿瘤分割，深度学习，网络设计，数据不平衡，多模态^†^†journal: LaTeX模板期刊![Refer to caption](img/1178c1e6c849df8e16da6d27b3fe6670.png)'
- en: 'Figure 1: Growth of scientific attention on deep learning based brain tumor
    segmentation. (a) Keyword frequency map in MICCAI from 2018 to 2020\. The size
    of the keyword is proportional to the frequency of the word. We observe that ’brain’,
    ’tumor’, ’segmentation’, and ’deep learning’ have drawn large research interests
    in the community. (b) Blue line represents the number of deep learning based solutions
    in The Multimodal Brain Tumor Segmentation Challenge (BraTS) in each year. Red
    line represents the Top-1 whole tumor dice score of the test set in each year.
    Researchers shift their interests to deep learning based segmentation methods
    due to the powerful feature learning ability and systematic performance due to
    deep learning techniques since 2012 (green dashed line). Best viewed in colors.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：基于深度学习的脑肿瘤分割的科学关注度增长。 (a) 2018年至2020年MICCAI中的关键词频率图。关键词的大小与词频成正比。我们观察到“脑”，“肿瘤”，“分割”和“深度学习”在研究社区中引起了广泛关注。
    (b) 蓝线代表每年在多模态脑肿瘤分割挑战赛（BraTS）中基于深度学习的解决方案数量。红线代表每年测试集的Top-1整个肿瘤Dice得分。自2012年起（绿色虚线），研究人员由于深度学习技术的强大特征学习能力和系统性能，将兴趣转向了基于深度学习的分割方法。最好在彩色模式下查看。
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Medical imaging analysis has been commonly involved in basic medical research
    and clinical treatment, e.g. computer-aided diagnosis [[1](#bib.bib1)], medical
    record data management [[2](#bib.bib2)], medical robots [[3](#bib.bib3)] and image-based
    applications [[4](#bib.bib4)]. Medical image analysis provides useful guidance
    for medical professionals to understand diseases and investigate clinical challenges
    in order to improve health-care quality. Among various tasks in medical image
    analysis, brain tumor segmentation has attracted much attention in the research
    community, which has been continuously studied (illustrated in Fig. [1](#S0.F1
    "Figure 1 ‣ Deep Learning Based Brain Tumor Segmentation: A Survey") (a)). In
    spite of tireless efforts of researchers, as a key challenge, accurate brain tumor
    segmentation still remains to be solved, due to various challenges such as location
    uncertainty, morphological uncertainty, low contrast imaging, annotation bias
    and data imbalance. With the promising performance made by powerful deep learning
    methods, a number of deep learning based methods have been applied upon brain
    tumor segmentation to extract feature representations automatically and achieve
    accurate and stable performance as illustrated in Fig. [1](#S0.F1 "Figure 1 ‣
    Deep Learning Based Brain Tumor Segmentation: A Survey") (b).'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 医学影像分析已经广泛应用于基础医学研究和临床治疗中，例如计算机辅助诊断[[1](#bib.bib1)]、医疗记录数据管理[[2](#bib.bib2)]、医疗机器人[[3](#bib.bib3)]和基于图像的应用[[4](#bib.bib4)]。医学影像分析为医疗专业人员提供了有用的指导，以理解疾病和研究临床挑战，从而提高医疗质量。在医学影像分析的各种任务中，脑肿瘤分割在研究界引起了广泛关注，这一领域也在不断研究（见图
    [1](#S0.F1 "图 1 ‣ 基于深度学习的脑肿瘤分割：综述") (a)）。尽管研究人员做出了不懈的努力，准确的脑肿瘤分割仍然是一个关键挑战，因其面临位置不确定性、形态学不确定性、低对比度成像、注释偏差和数据不平衡等各种挑战。凭借强大的深度学习方法所取得的良好性能，许多基于深度学习的方法已经应用于脑肿瘤分割，以自动提取特征表示，并实现准确且稳定的性能，如图
    [1](#S0.F1 "图 1 ‣ 基于深度学习的脑肿瘤分割：综述") (b) 所示。
- en: Glioma is one of the most primary brain tumors that stems from glial cells.
    World Health Organization (WHO) reports that glioma can be graded into four different
    levels based on microscopic images and tumor behaviors [[5](#bib.bib5)]. Grade
    I and II are Low-Grade-Gliomas (LGGs) which are close to benign with slow-growing
    pace. Grade III and IV are High-Grade-Gliomas (HGGs) which are cancerous and aggressive.
    Magnetic Resonance Imaging (MRI) is one of the most common imaging methods used
    before and after surgery, aiming at providing fundamental information for the
    treatment plan.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 胶质瘤是起源于神经胶质细胞的最常见原发性脑肿瘤之一。世界卫生组织（WHO）报告指出，胶质瘤可以根据显微镜图像和肿瘤行为分为四个不同等级[[5](#bib.bib5)]。I级和II级是低级胶质瘤（LGGs），接近良性且生长缓慢。III级和IV级是高级胶质瘤（HGGs），具有癌性和侵袭性。磁共振成像（MRI）是手术前后最常用的成像方法之一，旨在为治疗计划提供基础信息。
- en: '![Refer to caption](img/08e059fd2f1188539b7fd36376de9037.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08e059fd2f1188539b7fd36376de9037.png)'
- en: 'Figure 2: Exemplar input dataset with different MRI modalities and corresponding
    ground truth segmentation map. Each frame represents a unique MRI modality. The
    last frame on the right is the ground truth with corresponding manual segmentation
    annotation. Different colors represent different tumor sub-regions, i.e., gadolinium
    (GD) enhancing tumor (green), pertumoral edema (yellow) and necrotic and non-enhancing
    tumor core (NCR/ECT) (red). Best viewed in colors.'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：具有不同 MRI 模态和相应地面真值分割图的示例输入数据集。每一帧代表一种独特的 MRI 模态。右侧的最后一帧是带有相应手动分割注释的地面真值。不同的颜色代表不同的肿瘤子区域，即钆增强肿瘤（绿色）、肿瘤周围水肿（黄色）和坏死及非增强肿瘤核心（NCR/ECT）（红色）。建议以彩色查看。
- en: 'Image segmentation plays an active role in gliomas diagnosis and treatment.
    For example, an accurate glioma segmentation mask may help surgery planning, postoperative
    observations and improve the survival rate [[6](#bib.bib6)], [[7](#bib.bib7)],
    [[8](#bib.bib8)]. To quantify the outcome of image segmentation, we define the
    task of brain tumor segmentation as follows: Given an image from one or multiple
    image modality (e.g. multiple MRI sequences), the system aims to automatically
    segment the tumor area from the normal tissues and to classify each voxel or pixel
    of the input data into a pre-set sub-region category. Finally, the system returns
    the segmentation map of the corresponding input. Fig. [2](#S1.F2 "Figure 2 ‣ 1
    Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey") shows
    one exemplar HGG case with different MRI sequences as input and corresponding
    ground truth segmentation map.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: '图像分割在胶质瘤的诊断和治疗中发挥着积极作用。例如，准确的胶质瘤分割掩模可能有助于手术规划、术后观察并提高生存率[[6](#bib.bib6)], [[7](#bib.bib7)],
    [[8](#bib.bib8)]。为了量化图像分割的结果，我们定义脑肿瘤分割任务如下：给定一个来自一个或多个图像模态（例如多个MRI序列）的图像，系统旨在自动分割肿瘤区域与正常组织，并将输入数据的每个体素或像素分类到预设的子区域类别中。最后，系统返回相应输入的分割图。图[2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")显示了一个示例HGG病例，输入为不同的MRI序列以及相应的真实分割图。'
- en: 1.1 Difference from Previous Surveys
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1 与以往综述的区别
- en: 'A number of notable brain tumor segmentation surveys have been published in
    the last few years. We present recent relevant surveys with details and highlights
    in Table [1](#S1.T1 "Table 1 ‣ 1.1 Difference from Previous Surveys ‣ 1 Introduction
    ‣ Deep Learning Based Brain Tumor Segmentation: A Survey"). Among them, the closest
    survey paper to ours is presented by Ghaffari et al.[[9](#bib.bib9)]. The authors
    in [[9](#bib.bib9)] covered a majority of submissions from BraTS2012 to BraTS2018
    challenges, lacking, however, an analyses based on methodology category and highlights.
    Two recent surveys by Kapoor et al. [[10](#bib.bib10)] and Hameurlaine et al.
    [[11](#bib.bib11)] also focused on the summarisation of classic brain tumor segmentation
    methods. However, both of them lacked the technical analysis and discussion of
    deep learning based segmentation methods. A survey of early state-of-the-art brain
    tumor segmentation methods before 2013 was presented in [[12](#bib.bib12)], where
    most of the proposals before 2013 combined conventional machine learning models
    with hand-crafted features. Liu et al. [[13](#bib.bib13)] reported a survey on
    MRI based brain tumor segmentation in 2014\. This survey does not include deep
    learning based methods as well. Nalepa et al. [[14](#bib.bib14)] analysed the
    technical details and impacts of different kinds of data augmentation methods
    with the application to brain tumor segmentation, while ours focuses on the technical
    analysis of deep learning based brain tumor segmentation methods.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '近年来，已经发表了许多显著的脑肿瘤分割综述。我们在表[1](#S1.T1 "Table 1 ‣ 1.1 Difference from Previous
    Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")中展示了最近相关的综述及其细节和亮点。与我们的研究最接近的综述文章由Ghaffari等人提供[[9](#bib.bib9)]。在[[9](#bib.bib9)]中，作者涵盖了BraTS2012至BraTS2018挑战的大部分提交内容，但缺乏基于方法类别和亮点的分析。Kapoor等人[[10](#bib.bib10)]和Hameurlaine等人[[11](#bib.bib11)]的两篇近期综述也集中于经典脑肿瘤分割方法的总结。然而，它们都缺乏对基于深度学习的分割方法的技术分析和讨论。[[12](#bib.bib12)]中介绍了一篇2013年前早期前沿脑肿瘤分割方法的综述，其中大多数2013年前的提案将传统机器学习模型与手工特征结合。Liu等人[[13](#bib.bib13)]报告了一项关于2014年MRI基础的脑肿瘤分割的综述。这篇综述也没有包括基于深度学习的方法。Nalepa等人[[14](#bib.bib14)]分析了不同类型的数据增强方法的技术细节和影响，并应用于脑肿瘤分割，而我们的综述则集中于基于深度学习的脑肿瘤分割方法的技术分析。'
- en: 'Table 1: A summary of the existing surveys relates to the topic ’brain tumor
    segmentation’.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：与“脑肿瘤分割”主题相关的现有综述总结。
- en: '| Survey Title | Venue | Year | Remarks |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 综述标题 | 发表场所 | 年份 | 备注 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Automated brain tumor segmentation using multimodal brain scans: a survey
    based on models submitted to the BraTS 2012–2018 challenges [[9](#bib.bib9)] |
    IEEE Reviews in Biomedical Engineering | 2019 | A review of challenge submissions
    of BraTS during 2012-2018. |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 基于提交至BraTS 2012-2018挑战模型的多模态脑扫描自动脑肿瘤分割综述[[9](#bib.bib9)] | IEEE生物医学工程评论 |
    2019 | 对BraTS 2012-2018年挑战提交内容的综述。 |'
- en: '| A survey on brain tumor detection using image processing techniques [[10](#bib.bib10)]
    | 2017 7th International Conference on Cloud computing, Data science & Engineering-confluence
    | 2017 | A review of general brain tumor segmentation methods. |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 基于图像处理技术的大脑肿瘤检测综述 [[10](#bib.bib10)] | 2017年第七届云计算、大数据与工程国际会议 | 2017 | 大脑肿瘤分割方法的一般综述。
    |'
- en: '| Survey of brain tumor segmentation techniques on magnetic resonance imaging
    [[11](#bib.bib11)] | Nano Biomedicine and Engineering | 2019 | A general summary
    of classic brain tumor segmentation methods. |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 磁共振成像中大脑肿瘤分割技术的综述 [[11](#bib.bib11)] | 纳米生物医学与工程 | 2019 | 关于经典大脑肿瘤分割方法的一般总结。
    |'
- en: '| State of the art survey on MRI brain tumor segmentation [[12](#bib.bib12)]
    | Magnetic Resonance Imaging | 2013 | Review on convolutional neural networks
    used for brain MRI image analysis. |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| MRI大脑肿瘤分割的最新进展综述 [[12](#bib.bib12)] | 磁共振成像 | 2013 | 关于用于大脑MRI图像分析的卷积神经网络的综述。
    |'
- en: '| A survey of MRI-based brain tumor segmentation methods [[13](#bib.bib13)]
    | Tsinghua Science and Technology | 2014 | Review on MRI based brain tumor segmentation
    methods. |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 基于MRI的大脑肿瘤分割方法综述 [[13](#bib.bib13)] | 清华科技 | 2014 | 关于基于MRI的大脑肿瘤分割方法的综述。
    |'
- en: '| Data augmentation for brain-tumor segmentation: a review [[14](#bib.bib14)]
    | Frontiers in Computational Neuroscience | 2019 | Analysed the technical details
    and impacts of different kinds of data augmentation methods with the application
    to brain tumor segmentation. |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 大脑肿瘤分割的数据增强：综述 [[14](#bib.bib14)] | 计算神经科学前沿 | 2019 | 分析了不同数据增强方法的技术细节及其对大脑肿瘤分割的影响。
    |'
- en: '| A survey on deep learning in medical image analysis [[4](#bib.bib4)] | Medical
    Image Analysis | 2017 | A comprehensive review on deep learning based medical
    image analysis. |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 医学图像分析中的深度学习综述 [[4](#bib.bib4)] | 医学图像分析 | 2017 | 关于基于深度学习的医学图像分析的全面综述。 |'
- en: '| Deep convolutional neural networks for brain image analysis on magnetic resonance
    imaging: a review [[15](#bib.bib15)] | Artificial Intelligence in Medicine | 2018
    | A review on use of deep convolutional neural networks for brain image analysis.
    |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 磁共振成像中用于大脑图像分析的深度卷积神经网络：综述 [[15](#bib.bib15)] | 医学中的人工智能 | 2018 | 关于深度卷积神经网络用于大脑图像分析的综述。
    |'
- en: '| Deep learning for brain MRI segmentation: state of the art and future directions
    [[16](#bib.bib16)] | Journal of Digital Imaging | 2017 | A survey on deep learning
    for brain MRI segmentation. |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 大脑MRI分割的深度学习：现状与未来方向 [[16](#bib.bib16)] | 数字成像杂志 | 2017 | 关于大脑MRI分割的深度学习综述。
    |'
- en: '| A guide to deep learning in healthcare [[17](#bib.bib17)] | Nature Medicine
    | 2019 | A survey on deep learning for health-care. |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 医疗保健中的深度学习指南 [[17](#bib.bib17)] | 自然医学 | 2019 | 关于健康护理领域深度学习的综述。 |'
- en: '| Deep learning for generic object detection: A survey [[18](#bib.bib18)] |
    International Journal of Computer Vision | 2020 | A comprehensive review on deep
    learning based object detection. |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 通用目标检测的深度学习：综述 [[18](#bib.bib18)] | 国际计算机视觉杂志 | 2020 | 关于基于深度学习的目标检测的全面综述。
    |'
- en: '| Deep learning [[19](#bib.bib19)] | Nature | 2015 | An introduction review
    on deep learning and its application. |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习 [[19](#bib.bib19)] | 自然 | 2015 | 对深度学习及其应用的介绍性综述。 |'
- en: '| Recent advances in convolutional neural networks [[20](#bib.bib20)] | Pattern
    Recognition | 2018 | A survey on convolutional neural networksand its application
    on computer vision, language processing and speech. |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 卷积神经网络的最新进展 [[20](#bib.bib20)] | 模式识别 | 2018 | 关于卷积神经网络及其在计算机视觉、语言处理和语音中的应用的综述。
    |'
- en: '| Deep Learning Based Brain Tumor Segmentation: A Survey | Ours | - | A comprehensive
    survey of deep learning based brain tumor segmentation. |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 基于深度学习的大脑肿瘤分割：综述 | 我们的研究 | - | 对基于深度学习的大脑肿瘤分割的全面综述。 |'
- en: There is a number of representative survey papers published with similar topics
    in recent years. Litjens et al. [[4](#bib.bib4)] summarised recent medical image
    analysis applications with deep learning techniques. This survey gives an over
    of broad studies on medical image analysis including several state-of-the-art
    deep learning based brain tumor segmentation methods before 2017\. Bernal et al.
    [[21](#bib.bib21)] reported a review focusing on the use of deep convolutional
    neural networks for brain image analysis. This review only highlights the application
    of deep convolutional neural networks. Other important learning strategies such
    as segmentation under imbalance condition and learning from multi-modality were
    not mentioned. Akkus et al. [[16](#bib.bib16)] presented a survey on deep learning
    for brain MRI segmentation. Recently, Esteva et al. [[22](#bib.bib22)] presented
    a survey on deep learning for health-care applications. This survey summarized
    how deep learning in computer vision, natural language processing, reinforcement
    learning and generalized methods promote health-care applications. For a broader
    view of object detection and semantic segmentation, a survey was recently published
    in [[18](#bib.bib18)], providing the implications on object detection and semantic
    segmentation.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，已出版了一些具有相似主题的代表性调查论文。Litjens 等人[[4](#bib.bib4)]总结了近期基于深度学习技术的医学图像分析应用。这项调查概述了包括几种2017年前最新深度学习脑肿瘤分割方法在内的医学图像分析的广泛研究。Bernal
    等人[[21](#bib.bib21)]报道了一项重点关注深度卷积神经网络在脑部图像分析中的应用的综述。这项综述仅强调了深度卷积神经网络的应用。其他重要的学习策略，如不平衡条件下的分割和多模态学习，并未提及。Akkus
    等人[[16](#bib.bib16)]提出了一项关于脑MRI分割的深度学习调查。最近，Esteva 等人[[22](#bib.bib22)]提出了一项关于深度学习在医疗保健应用中的调查。这项调查总结了深度学习在计算机视觉、自然语言处理、强化学习和广义方法中的应用如何推动医疗保健应用。为了更广泛地了解目标检测和语义分割，最近在[[18](#bib.bib18)]中发布了一项调查，提供了关于目标检测和语义分割的启示。
- en: '![Refer to caption](img/56a9f87fb6f6519dced77ee1107a6e78.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/56a9f87fb6f6519dced77ee1107a6e78.png)'
- en: 'Figure 3: Challenges in segmentation of brain glioma tumors. (a) shows glioma
    tumor exemplars with various sizes and locations inside the brain. (b) and (c)
    show the statistical information of the training set in the multimodal brain tumor
    segmentation challenge 2017 (BraTS2017). The left hand side of (b) shows the FLAIR
    and T2 intensity projection, and the right hand side shows the T1ce and T1 intensity
    projection. (c) is the pie chart of the training data with labels, where the top
    figure shows the HGG labels while the bottom figure shows the LGG labels. We here
    experience region and label imbalance problems. Best viewed in colors.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：脑胶质瘤肿瘤分割中的挑战。(a) 显示了脑内不同大小和位置的胶质瘤肿瘤样本。(b) 和 (c) 显示了2017年多模态脑肿瘤分割挑战赛 (BraTS2017)
    中训练集的统计信息。(b) 的左侧显示了FLAIR和T2强度投影，右侧显示了T1ce和T1强度投影。(c) 是带有标签的训练数据的饼图，其中上半部分显示了HGG标签，而下半部分显示了LGG标签。这里我们经历了区域和标签不平衡的问题。最佳效果请在彩色显示下查看。
- en: Narrowly speaking, the word ”deep learning” means using neural network models
    with stacked functional layers (usually the layer number $>$ 5) [[23](#bib.bib23)].
    Neural networks are able to learn high dimensional hierarchical features and approximate
    any continuous functions [[24](#bib.bib24)], [[25](#bib.bib25)]. Considering the
    achievements and recent advances of deep neural networks, several surveys have
    reported the developed deep learning techniques, such as [[20](#bib.bib20)] and
    [[19](#bib.bib19)].
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 狭义上，“深度学习”一词意味着使用具有堆叠功能层（通常层数$>$ 5）的神经网络模型[[23](#bib.bib23)]。神经网络能够学习高维层次特征并近似任何连续函数[[24](#bib.bib24)],
    [[25](#bib.bib25)]。考虑到深度神经网络的成就和近期进展，已有几项调查报告了已开发的深度学习技术，例如[[20](#bib.bib20)]和[[19](#bib.bib19)]。
- en: 1.2 Scope of This Survey
  id: totrans-42
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2 本次调查的范围
- en: In this survey, we have collected and summarized the research studies reported
    on over one hundred scientific papers. We have examined major journals in the
    scientific community such as Medical Image Analysis and IEEE Transactions on Medical
    Imaging. We also evaluated proceedings of major conferences, such as ISBI, MICCAI,
    IPMI, MIDL, CVPR, ECCV and ICCV, to retain frontier medical imaging research outcomes.
    We reviewed annual challenges and their related competition entries such as The
    Multimodal Brain Tumor Segmentation Challenge (BraTS). In addition, the pre-printed
    versions of the established methods on arXiv are also included as a source of
    information.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项调查中，我们收集并总结了在一百多篇科学论文中报告的研究成果。我们检查了科学界的主要期刊，如《医学图像分析》和《IEEE医学成像汇刊》。我们还评估了主要会议的会议录，如ISBI、MICCAI、IPMI、MIDL、CVPR、ECCV和ICCV，以保留前沿医学成像研究成果。我们回顾了年度挑战及其相关竞赛条目，如多模态脑肿瘤分割挑战赛（BraTS）。此外，还包括了arXiv上的已建立方法的预印本版本作为信息来源。
- en: 'The goal of this survey is to present a comprehensive technical review of deep
    learning based brain tumor segmentation methods, according to architectural categories
    and strategy comparisons. We wish to explore how different architectures affect
    the segmentation performance of deep neural networks and how different learning
    strategies can be further improved for various challenges in brain tumor segmentation.
    We cover diverse high level perspectives, including effective architecture design,
    imbalance segmentation and multi-modality process. The taxonomy of this survey
    is made (Fig. [5](#S2.F5 "Figure 5 ‣ 2.2 Progress in the Past Decades ‣ 2 Background
    ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")) such that our categorization
    can help the reader to understand the technical similarities and differences between
    segmentation methods. The proposed taxonomy may also enable the reader to identify
    open challenges and future research directions.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本次调查的目标是根据架构类别和策略比较，呈现基于深度学习的脑肿瘤分割方法的全面技术综述。我们希望探讨不同的架构如何影响深度神经网络的分割性能，以及不同的学习策略如何进一步改进以应对脑肿瘤分割中的各种挑战。我们涵盖了多种高级视角，包括有效的架构设计、不平衡分割和多模态处理。本调查的分类（见图
    [5](#S2.F5 "图 5 ‣ 2.2 过去几十年的进展 ‣ 2 背景 ‣ 基于深度学习的脑肿瘤分割：综述")）使我们的分类有助于读者理解分割方法之间的技术相似性和差异。提出的分类法还可能帮助读者识别开放性挑战和未来的研究方向。
- en: 'We first present the background information of deep learning based brain tumor
    segmentation methods in Section [2](#S2 "2 Background ‣ Deep Learning Based Brain
    Tumor Segmentation: A Survey") and the rest of this survey is organised as follows:
    In Section [3](#S3 "3 Designing Effective Segmentation Networks ‣ Deep Learning
    Based Brain Tumor Segmentation: A Survey"), we review the design paradigm of effective
    segmentation modules and network architectures. In Section [4](#S4 "4 Segmentation
    under Imbalanced Condition ‣ Deep Learning Based Brain Tumor Segmentation: A Survey"),
    we categorise, explore and compare the solutions for tackling the data imbalance
    issue, which is a long-standing problem in brain tumor segmentation. As multi-modality
    provides promising solutions towards accurate brain tumor segmentation, we finally
    review the methods of utilising multi-modality information in Section [5](#S5
    "5 Utilising Multi Modality Information ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey"). We conclude this paper in Section [6](#S6 "6 Conclusion ‣ Deep Learning
    Based Brain Tumor Segmentation: A Survey"). We also build up a regularly maintained
    project page to accommodate the updates related to this survey.¹¹1http://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首先在第 [2](#S2 "2 背景 ‣ 基于深度学习的脑肿瘤分割：综述") 节介绍基于深度学习的脑肿瘤分割方法的背景信息，余下的调查内容组织如下：在第
    [3](#S3 "3 设计有效的分割网络 ‣ 基于深度学习的脑肿瘤分割：综述") 节，我们回顾了有效分割模块和网络架构的设计范式。在第 [4](#S4 "4
    在不平衡条件下的分割 ‣ 基于深度学习的脑肿瘤分割：综述") 节，我们对解决数据不平衡问题的方案进行分类、探索和比较，这在脑肿瘤分割中是一个长期存在的问题。由于多模态提供了准确脑肿瘤分割的有前景的解决方案，我们最后在第
    [5](#S5 "5 利用多模态信息 ‣ 基于深度学习的脑肿瘤分割：综述") 节回顾了利用多模态信息的方法。我们在第 [6](#S6 "6 结论 ‣ 基于深度学习的脑肿瘤分割：综述")
    节总结了本文。我们还建立了一个定期维护的项目页面，以容纳与本调查相关的更新。¹¹1http://github.com/ZhihuaLiuEd/SoTA-Brain-Tumor-Segmentation
- en: '![Refer to caption](img/92a357b167bdc4316fc144204b436fb9.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/92a357b167bdc4316fc144204b436fb9.png)'
- en: 'Figure 4: The evolution of brain tumor segmentation with selective milestones
    over the past decade. Best viewed in colors.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：过去十年中脑肿瘤分割的发展及关键里程碑。最佳彩色显示。
- en: 2 Background
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: 2.1 Research Challenges
  id: totrans-49
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 研究挑战
- en: 'Despite significant progress that has been made in brain tumor segmentation,
    state-of-the-art deep learning methods still experience difficulties with several
    challenges to be solved. The challenges associated with brain tumor segmentation
    can be categorised as follows:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管脑肿瘤分割取得了显著进展，最先进的深度学习方法仍然面临一些待解决的挑战。脑肿瘤分割相关的挑战可以归纳如下：
- en: '1.'
  id: totrans-51
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Location Uncertainty Glioma is mutated from gluey cells which surround nerve
    cells. Due to the wide spatial distribution of gluey cells, either High-Grade
    Glioma (HGG) or Low-Grade Glioma (LGG) may appear at any location inside the brain.
  id: totrans-52
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 位置不确定性 胶质瘤是由包围神经细胞的胶质细胞突变形成的。由于胶质细胞的空间分布广泛，高级胶质瘤 (HGG) 或低级胶质瘤 (LGG) 可能出现在脑部的任何位置。
- en: '2.'
  id: totrans-53
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Morphological Uncertainty Different from a rigid object, the morphology, e.g.
    shape and size, of different brain tumors varies with large uncertainty. As the
    external layer of a brain tumor, edema tissues show different fluid structures,
    which barely provide any prior information for describing the tumor’s shapes.
    The sub-regions of a tumor may also vary in shape and size.
  id: totrans-54
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 形态不确定性 与刚性物体不同，不同脑肿瘤的形态，例如形状和大小，具有较大的不确定性。作为脑肿瘤的外层，浮肿组织显示出不同的液体结构，这几乎无法提供描述肿瘤形状的先验信息。肿瘤的子区域可能在形状和大小上也有所变化。
- en: '3.'
  id: totrans-55
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Low Contrast High resolution and high contrast images are expected to contain
    diverse image information [[26](#bib.bib26)]. Due to the image projection and
    tomography process, MRI images may be of low quality and low contrast. The boundary
    between biological tissues tends to be blurred and hard to detect. Cells near
    the boundary are hard to be classified, which makes precise segmentation more
    difficult and harder to achieve.
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 低对比度 高分辨率和高对比度图像预计包含多样的图像信息 [[26](#bib.bib26)]。由于图像投影和断层扫描过程，MRI 图像可能质量较低且对比度不足。生物组织之间的边界趋向模糊，难以检测。靠近边界的细胞很难分类，这使得精确分割变得更加困难且难以实现。
- en: '4.'
  id: totrans-57
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: 'Annotation Bias Manual annotation highly depends on individual experience,
    which can introduce an annotation bias during data labeling. As shown in Fig.
    [3](#S1.F3 "Figure 3 ‣ 1.1 Difference from Previous Surveys ‣ 1 Introduction ‣
    Deep Learning Based Brain Tumor Segmentation: A Survey") (a), it seems that some
    annotations tend to connect all the small regions together while the other annotations
    can label individual voxels precisely. The annotation biases have a huge impact
    on the segmentation algorithm during the learning process [[27](#bib.bib27)].'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '注释偏差 手动注释高度依赖个人经验，这可能会在数据标记过程中引入注释偏差。如图 [3](#S1.F3 "Figure 3 ‣ 1.1 Difference
    from Previous Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey") (a) 所示，一些注释似乎倾向于将所有小区域连接在一起，而其他注释则可以精确地标记单个体素。注释偏差在学习过程中对分割算法有很大的影响
    [[27](#bib.bib27)]。'
- en: '5.'
  id: totrans-59
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: 'Imbalanced Issue As shown in Fig. [3](#S1.F3 "Figure 3 ‣ 1.1 Difference from
    Previous Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey") (b) and (c), there exists an imbalanced number of voxels in different
    tumor regions. For example, the necrotic/non-enhancing tumor core (NCR/ECT) region
    is much smaller than the other two regions. The imbalanced issue affects the data-driven
    learning algorithm as the extracted features may be highly influenced by large
    tumor regions [[28](#bib.bib28)].'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '不平衡问题 如图 [3](#S1.F3 "Figure 3 ‣ 1.1 Difference from Previous Surveys ‣ 1 Introduction
    ‣ Deep Learning Based Brain Tumor Segmentation: A Survey") (b) 和 (c) 所示，不同肿瘤区域中体素的数量存在不平衡。例如，坏死/非增强肿瘤核心
    (NCR/ECT) 区域远小于其他两个区域。不平衡问题影响数据驱动的学习算法，因为提取的特征可能受到大肿瘤区域的高度影响 [[28](#bib.bib28)]。'
- en: 2.2 Progress in the Past Decades
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 过去几十年的进展
- en: 'Representative research milestones of brain tumor segmentation are shown in
    Fig. [4](#S1.F4 "Figure 4 ‣ 1.2 Scope of This Survey ‣ 1 Introduction ‣ Deep Learning
    Based Brain Tumor Segmentation: A Survey"). In the late 90s’, researchers Zhu
    et al. [[29](#bib.bib29)] started to use a Hopfield Neural Network with active
    contours to extract the tumor boundary and dilate the tumor region. However, training
    a neural network was highly constrained due to the computational resource limitation
    and technical supporting. From late 90s’ to early 20s’, most of the brain tumor
    segmentation methods focused on traditional machine learning algorithms with hand-crafted
    features, such as expert systems with multi-spectral histogram [[30](#bib.bib30)],
    segmentation with templates [[31](#bib.bib31)], [[32](#bib.bib32)], graphical
    models with intensity histograms [[33](#bib.bib33)], [[34](#bib.bib34)], tumor
    boundary detection from latent atlas [[35](#bib.bib35)]. These early works pioneered
    the use of machine learning in solving brain tumor segmentation problems. However,
    early research works have significant shortcomings. First, most of the early works
    only focused on the segmentation of the whole tumor region, that is, the segmentation
    result has only one category. Compared with recent brain tumor segmentation algorithms,
    early works are formulated with strong conditions, relying on unrealistic assumptions.
    Second, manually designed feature engineering is constrained by prior knowledge,
    which cannot be fully generalised. Last but not least, early research works fail
    to address some challenges such as appearance uncertainty and data imbalance.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 脑肿瘤分割的代表性研究里程碑如图[4](#S1.F4 "图 4 ‣ 1.2 本调查的范围 ‣ 1 介绍 ‣ 基于深度学习的脑肿瘤分割：调查")所示。在90年代末，研究人员Zhu等人[[29](#bib.bib29)]开始使用具有活动轮廓的Hopfield神经网络来提取肿瘤边界并扩张肿瘤区域。然而，由于计算资源限制和技术支持问题，训练神经网络受到很大限制。从90年代末到20年代初，大多数脑肿瘤分割方法集中在具有手工特征的传统机器学习算法上，如具有多光谱直方图的专家系统[[30](#bib.bib30)]、使用模板的分割[[31](#bib.bib31)],
    [[32](#bib.bib32)]、具有强度直方图的图形模型[[33](#bib.bib33)], [[34](#bib.bib34)]、从潜在图谱中检测肿瘤边界[[35](#bib.bib35)]。这些早期工作开创了在解决脑肿瘤分割问题中使用机器学习的先河。然而，早期研究工作存在显著缺陷。首先，大多数早期工作仅关注于整个肿瘤区域的分割，即分割结果只有一个类别。与最近的脑肿瘤分割算法相比，早期工作在强条件下进行，依赖于不切实际的假设。其次，手工设计的特征工程受到先验知识的限制，无法完全推广。最后但同样重要的是，早期研究未能解决一些挑战，例如外观不确定性和数据不平衡。
- en: '![Refer to caption](img/b41d36397d83fa963ac3278904954c36.png)'
  id: totrans-63
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/b41d36397d83fa963ac3278904954c36.png)'
- en: 'Figure 5: Our proposed taxonomy of deep learning based brain tumor segmentation
    methods. Best viewed in colors.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：我们提出的基于深度学习的脑肿瘤分割方法的分类法。最佳查看效果为彩色显示。
- en: With the revolutionary breakthrough by deep learning technology [[36](#bib.bib36)],
    researchers began to focus on using deep neural networks to solve various practical
    problems. Pioneering works from Zikic et al.[[37](#bib.bib37)], Havaei et al.[[38](#bib.bib38)],
    Pereira et al.[[39](#bib.bib39)] intend to design customized deep convolutional
    neural networks to achieve accurate brain tumor segmentation. With breakthrough
    brought by Fully Convolutional Network (FCN) [[40](#bib.bib40)] and U-Net [[41](#bib.bib41)],
    recent innovations [[42](#bib.bib42)], [[43](#bib.bib43)] on brain tumor segmentation
    focus on building encoder-decoder networks without fully connected layers to achieve
    end-to-end tumor segmentation.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习技术的革命性突破[[36](#bib.bib36)]，研究人员开始集中精力使用深度神经网络解决各种实际问题。Zikic等人的开创性工作[[37](#bib.bib37)]、Havaei等人的研究[[38](#bib.bib38)]、Pereira等人的研究[[39](#bib.bib39)]旨在设计定制的深度卷积神经网络，以实现准确的脑肿瘤分割。通过全卷积网络（FCN）[[40](#bib.bib40)]和U-Net[[41](#bib.bib41)]的突破，最近的创新[[42](#bib.bib42)],
    [[43](#bib.bib43)]在脑肿瘤分割中集中于构建编码器-解码器网络，而无需全连接层，以实现端到端的肿瘤分割。
- en: A long-standing challenge in brain tumor segmentation is data imbalance. To
    effectively deal with the imbalance problem, researchers try different solutions,
    such as network cascade and ensemble [[44](#bib.bib44)], [[45](#bib.bib45)], [[46](#bib.bib46)],
    multi-task learning [[47](#bib.bib47)], [[48](#bib.bib48)], and customized loss
    functions [[49](#bib.bib49)]. Another solution is to fully utilise information
    from multi-modality. Recent research focused on modality fusion [[50](#bib.bib50)]
    and dealing with modality missing [[51](#bib.bib51)].
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑肿瘤分割中的一个长期挑战是数据不平衡。为有效解决不平衡问题，研究人员尝试了不同的解决方案，如网络级联和集成[[44](#bib.bib44)], [[45](#bib.bib45)],
    [[46](#bib.bib46)]，多任务学习[[47](#bib.bib47)], [[48](#bib.bib48)]，以及定制的损失函数[[49](#bib.bib49)]。另一种解决方案是充分利用多模态信息。最近的研究集中在模态融合[[50](#bib.bib50)]和处理模态缺失[[51](#bib.bib51)]。
- en: 'Based on the evolution, we generally categorise the existing deep learning
    based brain tumor segmentation methods into three categories, i.e., methods with
    effective architectures, methods for dealing with imbalanced condition and methods
    of utilising multi-modality information. Fig. [5](#S2.F5 "Figure 5 ‣ 2.2 Progress
    in the Past Decades ‣ 2 Background ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey") shows a taxonomy of the research work in deep learning based brain
    tumor segmentation.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '基于演变，我们通常将现有的深度学习基础的大脑肿瘤分割方法分为三类，即具有有效架构的方法、处理不平衡条件的方法和利用多模态信息的方法。图[5](#S2.F5
    "Figure 5 ‣ 2.2 Progress in the Past Decades ‣ 2 Background ‣ Deep Learning Based
    Brain Tumor Segmentation: A Survey")展示了深度学习基础的大脑肿瘤分割研究工作的分类。'
- en: 2.3 Related Problems
  id: totrans-68
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 相关问题
- en: There are a number of unsolved problems that relates to brain tumor segmentation.
    Brain tissue segmentation or anatomical brain segmentation aims to label each
    unit with a unique brain tissue class. Their task assumes that the brain image
    does not contain any tumor tissue or other anomalies [[52](#bib.bib52)], [[53](#bib.bib53)].
    The goal of white matter lesion segmentation is to segment the white matter lesion
    from the normal tissue. In their task, the white matter lesion does not contain
    sub-regions such as tumor cores, where segmentation may be achieved through binary
    classification methods. Tumor detection aims to detect abnormal tumors or lesion
    and reports the predicted class of each tissue. Generally, this task has the bounding
    box as the detection result and the label as the classification result [[54](#bib.bib54)],
    [[55](#bib.bib55)],[[56](#bib.bib56)]. It is worth mentioning that some research
    methods in brain tumor segmentation only return the single label segmentation
    mask or the center point of the tumor core without sub-region segmentation. In
    our paper, we focus on tumor segmentation with sub-region level semantic segmentation
    as the main topic. Disorder classification is to extract pre-defined features
    from brain scan images and then classify feature representations into graded disorders
    such as High-Grade-Gliomas (HGGs) vs Low-Grade-Gliomas (LGGs), Mild Cognitive
    Impairment (MCI) [[57](#bib.bib57)], Alzheimer’s Disease (AD) [[58](#bib.bib58)]
    and Schizophrenia [[59](#bib.bib59)]. Survival Prediction identifies tumors’ patterns
    and activities [[60](#bib.bib60)] in order to predict the survival rate as a supplementary
    to clinical diagnosis [[61](#bib.bib61)]. Both disorder classification and survival
    prediction can be regarded as down-stream tasks, based on the tumor segmentation
    outcomes.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 大脑肿瘤分割存在许多未解决的问题。大脑组织分割或解剖学大脑分割旨在为每个单位标记一个唯一的大脑组织类别。它们的任务假设大脑图像不包含任何肿瘤组织或其他异常[[52](#bib.bib52)],
    [[53](#bib.bib53)]。白质病变分割的目标是将白质病变从正常组织中分割出来。在它们的任务中，白质病变不包含如肿瘤核心等子区域，其中分割可以通过二分类方法实现。肿瘤检测旨在检测异常的肿瘤或病变，并报告每个组织的预测类别。通常，这个任务的检测结果是边界框，分类结果是标签[[54](#bib.bib54)],
    [[55](#bib.bib55)], [[56](#bib.bib56)]。值得一提的是，一些大脑肿瘤分割的研究方法仅返回单一标签分割掩膜或肿瘤核心的中心点，而不进行子区域分割。在我们的论文中，我们的重点是以子区域级别的语义分割作为肿瘤分割的主要主题。疾病分类是从脑扫描图像中提取预定义特征，然后将特征表示分类为不同等级的疾病，如高等级胶质瘤（HGGs）与低等级胶质瘤（LGGs），轻度认知障碍（MCI）[[57](#bib.bib57)]，阿尔茨海默病（AD）[[58](#bib.bib58)]和精神分裂症[[59](#bib.bib59)]。生存预测识别肿瘤的模式和活动[[60](#bib.bib60)]，以预测生存率作为临床诊断的补充[[61](#bib.bib61)]。疾病分类和生存预测都可以被视为下游任务，基于肿瘤分割结果。
- en: 2.4 Contributions of this survey
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 本调查的贡献
- en: 'A large number of deep learning based brain tumor segmentation methods have
    been published with promising results. Our paper, as a platform, provides a comprehensive
    and critical survey of state-of-the-art brain tumor segmentation methods. We anticipate
    that this survey supplies useful guidelines and coherent technical insights to
    academia and industry. The major contributions of this survey can be summarised
    as follows:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 大量基于深度学习的脑肿瘤分割方法已发表并取得了令人鼓舞的结果。我们的论文作为一个平台，提供了对最先进的脑肿瘤分割方法的全面和批判性调查。我们预期这项调查能为学术界和工业界提供有用的指南和一致的技术见解。此项调查的主要贡献可以总结如下：
- en: '1.'
  id: totrans-72
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: To our best knowledge, this is the first survey to catergorise and outline deep
    learning based brain tumor segmentation methods with a structured taxonomy of
    various important technical perspectives.
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 据我们所知，这是首次以结构化的分类法概述和分类基于深度学习的脑肿瘤分割方法，涵盖了各种重要的技术视角。
- en: '2.'
  id: totrans-74
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: 'We present the reader with a summarisation of technological progress of deep
    learning base brain tumor segmentation with detailed background information and
    system comparisons (e.g. Tables [1](#S1.T1 "Table 1 ‣ 1.1 Difference from Previous
    Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey"),
    [5](#S5.T5 "Table 5 ‣ 5.1 Learning with multiple modalities ‣ 5 Utilising Multi
    Modality Information ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")).'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们向读者提供了基于深度学习的脑肿瘤分割技术进展的总结，包括详细的背景信息和系统比较（例如，表格[1](#S1.T1 "表格 1 ‣ 1.1 与以往调查的区别
    ‣ 1 引言 ‣ 基于深度学习的脑肿瘤分割：一项调查"), [5](#S5.T5 "表格 5 ‣ 5.1 多模态学习 ‣ 5 利用多模态信息 ‣ 基于深度学习的脑肿瘤分割：一项调查")）。
- en: '3.'
  id: totrans-76
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'We carefully and extensively compares existing methods based on results from
    public accessible challenges and datasets (e.g. Tables [2](#S3.T2 "Table 2 ‣ 3.2.2
    Encoder-Decoder Architecture ‣ 3.2 Designing Effective Architectures ‣ 3 Designing
    Effective Segmentation Networks ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey"), [3](#S4.T3 "Table 3 ‣ 4.3 Customised Loss Function Driven Approaches
    ‣ 4 Segmentation under Imbalanced Condition ‣ Deep Learning Based Brain Tumor
    Segmentation: A Survey"), [4](#S5.T4 "Table 4 ‣ 5.1 Learning with multiple modalities
    ‣ 5 Utilising Multi Modality Information ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey").), with critical summaries and insightful discussions.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们基于公共访问的挑战和数据集（例如，表格[2](#S3.T2 "表格 2 ‣ 3.2.2 编码器-解码器架构 ‣ 3.2 设计有效的架构 ‣ 3 设计有效的分割网络
    ‣ 基于深度学习的脑肿瘤分割：一项调查"), [3](#S4.T3 "表格 3 ‣ 4.3 定制损失函数驱动的方法 ‣ 4 不平衡条件下的分割 ‣ 基于深度学习的脑肿瘤分割：一项调查"),
    [4](#S5.T4 "表格 4 ‣ 5.1 多模态学习 ‣ 5 利用多模态信息 ‣ 基于深度学习的脑肿瘤分割：一项调查")），对现有方法进行了详细且广泛的比较，附有关键总结和深刻讨论。
- en: 3 Designing Effective Segmentation Networks
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 设计有效的分割网络
- en: 'Compared with complex feature engineering pipelines to extract useful features,
    recent deep learning mainly relies on designing effective deep neural networks
    to automatically extract high-dimensional discriminative features. Designing effective
    modules and network architectures has become one of the important factors for
    achieving accurate segmentation performance. In this section, we reviewed two
    important design guidelines for deep learning based brain tumor segmentation:
    to design effective modules and network architecture.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 与复杂的特征工程管道相比，近期的深度学习主要依赖于设计有效的深度神经网络来自动提取高维判别特征。设计有效的模块和网络架构已成为实现准确分割性能的重要因素之一。在本节中，我们回顾了基于深度学习的脑肿瘤分割的两个重要设计指南：设计有效的模块和网络架构。
- en: There are mainly two principles to follow when designing effective components.
    One is to learn high level semantics and localise precious targets, through the
    enlargement of the receptive field [[62](#bib.bib62)], [[63](#bib.bib63)], [[64](#bib.bib64)],
    attention mechanism [[65](#bib.bib65)], [[66](#bib.bib66)], [[48](#bib.bib48)]
    feature fusion update [[67](#bib.bib67)], [[68](#bib.bib68)] and other forms.
    The other way is to reduce the amount of the network parameters and speed up during
    training and inference, thereby saving computational time and resources[[69](#bib.bib69)],
    [[70](#bib.bib70)], [[71](#bib.bib71)], [[72](#bib.bib72)], [[73](#bib.bib73)],
    [[74](#bib.bib74)], [[75](#bib.bib75)].
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 设计有效组件时主要遵循两个原则。其一是学习高级语义并定位珍贵目标，通过扩大感受野[[62](#bib.bib62)], [[63](#bib.bib63)],
    [[64](#bib.bib64)], 注意力机制[[65](#bib.bib65)], [[66](#bib.bib66)], [[48](#bib.bib48)]，特征融合更新[[67](#bib.bib67)],
    [[68](#bib.bib68)]等形式。另一种方法是减少网络参数量，加快训练和推理过程，从而节省计算时间和资源[[69](#bib.bib69)], [[70](#bib.bib70)],
    [[71](#bib.bib71)], [[72](#bib.bib72)], [[73](#bib.bib73)], [[74](#bib.bib74)],
    [[75](#bib.bib75)]。
- en: 'The design of the network architecture is mainly reflected in the transition
    from a single-channel network to a multi-channel network, from a network with
    fully connected layers to a fully convolutional network, from a simple network
    to a deep cascaded network. The purpose is to deepen the network, enhance the
    feature learning ability of the network and completes more precise segmentation.
    In the following, we divide theses methods and review them comprehensively. A
    systematical comparison between various network architectures and modules is shown
    in Fig. [6](#S3.F6 "Figure 6 ‣ 3 Designing Effective Segmentation Networks ‣ Deep
    Learning Based Brain Tumor Segmentation: A Survey").'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '网络架构的设计主要体现在从单通道网络过渡到多通道网络，从具有全连接层的网络过渡到完全卷积网络，从简单网络到深度级联网络。其目的是深化网络，增强网络的特征学习能力，并完成更精确的分割。接下来，我们将这些方法进行分类并全面回顾。不同网络架构和模块的系统比较见图。[6](#S3.F6
    "Figure 6 ‣ 3 Designing Effective Segmentation Networks ‣ Deep Learning Based
    Brain Tumor Segmentation: A Survey")'
- en: '![Refer to caption](img/4cc04c04a17410f4a50766cb281cac67.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4cc04c04a17410f4a50766cb281cac67.png)'
- en: 'Figure 6: Structural comparison between representative methods based on designing
    effective network modules and architectures. From top-left to bottom-right: (a1)
    CNN in [[37](#bib.bib37)], (b1) CNN with (b2) residual convolution module [[76](#bib.bib76)],
    (c1) CNN with (c2) full resolution residual unit [[77](#bib.bib77)], (d1) CNN
    with (d2) dense connection module [[78](#bib.bib78)], (e1) CNN with (e2) residual
    dilation block [[63](#bib.bib63)], (f1) CNN with (f2) atrous convolution feature
    pyramid module [[79](#bib.bib79)], (g1) FCN with (g2) multi-fiber unit [[71](#bib.bib71)],
    (h1) FCN with (h2) reversible block [[70](#bib.bib70)] and (i1) FCN with (i2)
    modality fusion module [[80](#bib.bib80)]. Best viewed in colors.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：基于有效网络模块和架构设计的代表性方法结构比较。从左上到右下：(a1) [[37](#bib.bib37)]中的CNN，(b1) 带有 (b2)
    残差卷积模块[[76](#bib.bib76)]的CNN，(c1) 带有 (c2) 全分辨率残差单元[[77](#bib.bib77)]的CNN，(d1)
    带有 (d2) 密集连接模块[[78](#bib.bib78)]的CNN，(e1) 带有 (e2) 残差膨胀块[[63](#bib.bib63)]的CNN，(f1)
    带有 (f2) 空洞卷积特征金字塔模块[[79](#bib.bib79)]的CNN，(g1) 带有 (g2) 多纤维单元[[71](#bib.bib71)]的FCN，(h1)
    带有 (h2) 可逆块[[70](#bib.bib70)]的FCN，以及 (i1) 带有 (i2) 模态融合模块[[80](#bib.bib80)]的FCN。最佳效果为彩色显示。
- en: 3.1 Designing Specialised Modules
  id: totrans-84
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 设计专业化模块
- en: 3.1.1 Modules for Higher Accuracy
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 提高准确性的模块
- en: Numerous methods for brain tumor segmentation focuses on designing effective
    modules inside neural networks, aiming to stabilise training, learning informative,
    discriminative, and conducive features for accurate segmentation. Early design
    work followed the pattern of well-known networks such as AlexNet [[36](#bib.bib36)]
    and gradually deepened the network depth by stacking convolutional blocks. Early
    research works such as [[81](#bib.bib81)], [[82](#bib.bib82)] and [[43](#bib.bib43)]
    stacked several blocks with convolutional layers composed of a large kernel size
    (typically greater than 5), pooling layers and activation layers together. Blocks
    with a large size convolution kernel enable us to capture useful details with
    a large number of parameters to be trained. Other research works such as [[37](#bib.bib37)]
    and [[39](#bib.bib39)] followed the pattern of VGG [[83](#bib.bib83)] to build
    convolutional layers with a small sized kernel (typically 3) as basic blocks.
    Further research works such as [[38](#bib.bib38)] stacked hybrid blocks with a
    combination of different kernel sizes, where large sized kernels tend to find
    global features (such as tumor location and size) with a large receptive field
    and small kernels tend to contain local features (such as boundary and texture)
    with a small receptive field. As stacking two $3\times 3$ convolutional layers
    leads to equal sized reception fields while maintaining less parameters, compared
    with a single $5\times 5$ layer, most recent tumor segmentation works constructed
    basic network blocks, based on stacking $3\times 3$ layers, and started to extend
    to volumetric reconstruction in MRI with $3\times 3\times 3$ kernels [[84](#bib.bib84)],
    [[85](#bib.bib85)].
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 许多脑肿瘤分割方法集中于设计神经网络内部的有效模块，旨在稳定训练，学习信息丰富、具区分性且有助于准确分割的特征。早期设计工作遵循了像AlexNet[[36](#bib.bib36)]这样的知名网络模式，并通过堆叠卷积块逐步加深网络深度。早期研究工作如[[81](#bib.bib81)]、[[82](#bib.bib82)]和[[43](#bib.bib43)]堆叠了多个由大卷积核（通常大于5）、池化层和激活层组成的卷积层块。大尺寸卷积核的块使我们能够捕捉到有用的细节，并拥有大量需要训练的参数。其他研究工作如[[37](#bib.bib37)]和[[39](#bib.bib39)]遵循了VGG[[83](#bib.bib83)]的模式，以小尺寸卷积核（通常为3）构建基础卷积层块。进一步的研究工作如[[38](#bib.bib38)]堆叠了不同卷积核尺寸的混合块，其中大尺寸卷积核倾向于找到全局特征（如肿瘤的位置和大小）具有大的感受野，而小卷积核则倾向于包含局部特征（如边界和纹理）具有小的感受野。由于堆叠两个$3\times
    3$卷积层可以保持相同大小的感受野，同时参数较少，相比于单个$5\times 5$层，大多数最近的肿瘤分割工作构建了基于堆叠$3\times 3$层的基本网络块，并开始扩展到MRI的体积重建中，使用$3\times
    3\times 3$卷积核[[84](#bib.bib84)]、[[85](#bib.bib85)]。
- en: As the number of stacked layers increases, the network is getting deeper, causing
    the issue of gradient explosion and vanishing during the training process. In
    order to stabilise system training and reach higher segmentation accuracy, early
    brain tumor segmentation methods such as [[86](#bib.bib86)] and [[76](#bib.bib76)]
    followed ResNet[[87](#bib.bib87)] and introduced residual connection into module
    design. Residual connection helps solving the problem of gradient vanishing and
    explosion, by adding the input of a convolution module to its output, which avoids
    degradation and converges faster with better accuracy. Now, residual connection
    has become one of the standard operations for designing modules and complex network
    architectures. In the following works [[88](#bib.bib88)], [[78](#bib.bib78)],
    [[89](#bib.bib89)] and [[90](#bib.bib90)], the authors followed Densenet [[91](#bib.bib91)]
    and expanded residual connection to dense connection. Although dense connection
    design looks more conducive to gradient back-propagation, the complex close connection
    structure can cause multiple usage of the computing memory during the network
    training.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 随着堆叠层数的增加，网络变得越来越深，导致训练过程中出现梯度爆炸和消失的问题。为了稳定系统训练并达到更高的分割精度，早期脑肿瘤分割方法如[[86](#bib.bib86)]和[[76](#bib.bib76)]跟随了ResNet[[87](#bib.bib87)]并在模块设计中引入了残差连接。残差连接通过将卷积模块的输入添加到其输出中，帮助解决梯度消失和爆炸的问题，这样可以避免退化，并更快地收敛且准确性更高。现在，残差连接已成为设计模块和复杂网络架构的标准操作之一。在以下工作[[88](#bib.bib88)]、[[78](#bib.bib78)]、[[89](#bib.bib89)]和[[90](#bib.bib90)]中，作者跟随Densenet[[91](#bib.bib91)]将残差连接扩展到密集连接。尽管密集连接设计看起来更有利于梯度反向传播，但复杂的紧密连接结构在网络训练期间可能会导致计算内存的多次使用。
- en: By stacking convolution modules and using residual connections inside and outside
    modules, neural networks can be deeper and features can be learnt with higher
    dimensions and uncertainty. However, this process may lead to the sacrifice of
    spatial resolution, whereas the resolution of high dimensional feature maps is
    much smaller than that of the original data. In order to preserve the spatial
    resolution of data whilst still expanding the receptive field, [[62](#bib.bib62)],
    [[63](#bib.bib63)], [[64](#bib.bib64)] replaced the standard convolution layer
    with a dilated convolution layer [[92](#bib.bib92)]. The dilated convolution comes
    up with several benefits. First, dilation convolution enlarges the receptive field
    without introducing additional parameters. Larger receptive fields are helpful
    for segmenting large-area targets, such as edema. Second, dilated convolution
    avoids the loss of spatial resolution. Thus, the position of the object to be
    segmented can be accurately localised in the original input space. However, the
    problem of incorrect localisation and segmentation of small structures remains
    to be solved. In response to this problem, [[93](#bib.bib93)] proposed to design
    a multi-scale dilation convolution or atrous spatial pyramid pooling module, capturing
    the semantic context that describes subtle details of the object.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 通过堆叠卷积模块并使用模块内外的残差连接，神经网络可以变得更深，特征可以以更高的维度和不确定性进行学习。然而，这一过程可能会牺牲空间分辨率，而高维特征图的分辨率远低于原始数据的分辨率。为了在扩展感受野的同时保持数据的空间分辨率，[[62](#bib.bib62)]、[[63](#bib.bib63)]、[[64](#bib.bib64)]
    用扩张卷积层[[92](#bib.bib92)]替换了标准卷积层。扩张卷积带来了几个好处。首先，扩张卷积在不引入额外参数的情况下扩大了感受野。较大的感受野有助于分割大面积的目标，如水肿。其次，扩张卷积避免了空间分辨率的损失。因此，待分割物体的位置可以在原始输入空间中准确定位。然而，小结构的不正确定位和分割问题仍需解决。针对这一问题，[[93](#bib.bib93)]提出设计多尺度扩张卷积或空洞空间金字塔池化模块，以捕捉描述物体微妙细节的语义上下文。
- en: 3.1.2 Modules for Efficient Computation
  id: totrans-89
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 高效计算的模块
- en: Designing and stacking complex modules may help effectively learn high-dimensional
    discriminative features and achieve precise segmentation, but it requires high
    computational resources and long training and inference time. In response to this
    request, many works have adopted lightweight ideas in module design. With similar
    accuracy, fewer computing resources are required by lightweight architectures,
    training and reasoning time is shorter, and the speed is faster. [[94](#bib.bib94)]
    is one of the earliest research works aiming at speeding up brain tumor segmentation.
    The authors of [[94](#bib.bib94)] reordered the input data (a data sample rotated
    by 6-degrees) so that the samples with high visual similarity are placed closer
    in the memory, in an attempt to speed up I/O communication. Instead of managing
    the input data, [[72](#bib.bib72)] chose to build a U-Net variant with decreased
    down-sampling channels to reduce the computational cost.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 设计和堆叠复杂的模块可以有效地学习高维度的判别特征并实现精确的分割，但这需要高计算资源以及长时间的训练和推理时间。对此，许多研究在模块设计中采用了轻量级的思路。轻量级架构在相似的准确率下所需的计算资源更少，训练和推理时间更短，速度更快。[[94](#bib.bib94)]是旨在加速脑肿瘤分割的最早研究之一。[[94](#bib.bib94)]的作者重新排序了输入数据（旋转6度的数据样本），使具有高视觉相似性的样本在内存中更接近，从而尝试加速I/O通信。与管理输入数据不同，[[72](#bib.bib72)]选择构建一个减少下采样通道的U-Net变体以降低计算成本。
- en: The above-mentioned works used less computational resources, but lose learning
    information and decreased segmentation accuracy. Inspired by reversible residual
    network [[95](#bib.bib95)], [[70](#bib.bib70)] introduced reversible blocks into
    U-Net where each layer’s activation can be collected from the previous layer’s
    output during the backward pass process. Thus, no additional memory is used to
    store intermediate activation and hence reduce memory cost. [[73](#bib.bib73)]
    further extend reversible blocks by introducing Mobile Reversible Convolution
    Blocks (MBConvBlock) used in MobileNetV2 [[96](#bib.bib96)] and EfficientNet [[97](#bib.bib97)].
    In addition to the reversible computation design, MBConvBlock replaced standard
    convolutions with depthwise separable convolutions. Depthwise separable convolutions
    first split the computation of feature maps accordingly using depthwise convolution
    and merge the feature maps together using $1\times 1\times 1$ pointwise convolutions,
    which further reduced parameters compared with the standard convolution. Later
    research works, including 3DESPNet[[98](#bib.bib98)] and DMFNet [[71](#bib.bib71)],
    further extend this idea with dilated convolutions, requiring less computational
    resources while preserving most spatial resolutions.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 上述工作使用了较少的计算资源，但丢失了学习信息并降低了分割精度。受可逆残差网络[[95](#bib.bib95)]的启发，[[70](#bib.bib70)]将可逆块引入了U-Net，其中每层的激活可以在反向传播过程中从前一层的输出中收集。因此，无需额外的内存来存储中间激活，从而减少了内存成本。[[73](#bib.bib73)]进一步扩展了可逆块，通过引入在MobileNetV2
    [[96](#bib.bib96)]和EfficientNet [[97](#bib.bib97)]中使用的Mobile Reversible Convolution
    Blocks (MBConvBlock)。除了可逆计算设计，MBConvBlock将标准卷积替换为深度可分卷积。深度可分卷积首先使用深度卷积按特征图进行计算分离，然后使用$1\times
    1\times 1$点卷积将特征图合并，这比标准卷积进一步减少了参数。后续研究工作，包括3DESPNet[[98](#bib.bib98)]和DMFNet
    [[71](#bib.bib71)]，进一步扩展了这一理念，引入了膨胀卷积，在保持大部分空间分辨率的同时，减少了计算资源的需求。
- en: 3.2 Designing Effective Architectures
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 设计有效的架构
- en: A major factor that promotes prosperity and development of deep neural networks
    in various fields is to invest efforts in designing intelligent and effective
    network architectures. We divide most deep learning based brain tumor segmentation
    networks into single/multiple path networks and encoder-decoder networks according
    to the characteristics of network structures. Single and multiple path networks
    are used to extract features and classify the center pixels of the input patch.
    Encoder-Decoder networks are designed in an end-to-end fashion, that is, the encoder
    enables deep feature to be extracted from part of or the entire image, and then
    the decoder conducts feature-to-segmentation mapping. In the following subsections,
    we conduct a systematic analysis and comparison of variant architecture designs.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 促进深度神经网络在各个领域繁荣和发展的主要因素之一是投入精力设计智能且有效的网络架构。我们根据网络结构的特征，将大多数基于深度学习的脑肿瘤分割网络分为单路径/多路径网络和编码器-解码器网络。单路径和多路径网络用于提取特征和分类输入补丁的中心像素。编码器-解码器网络以端到端的方式设计，即编码器使得能够从部分或整个图像中提取深层特征，然后解码器进行特征到分割的映射。在以下小节中，我们对各种架构设计进行系统分析和比较。
- en: 3.2.1 Multi-Path Architecture
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 多路径架构
- en: '![Refer to caption](img/0be01986ac915c016866713ae51ad087.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0be01986ac915c016866713ae51ad087.png)'
- en: 'Figure 7: A high level comparison between single-path and two-path CNN. Best
    viewed in colors.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：单路径和双路径CNN的高级比较。最佳效果为彩色显示。
- en: 'Here we refer network path as the flow of data processing (Fig. [7](#S3.F7
    "Figure 7 ‣ 3.2.1 Multi-Path Architecture ‣ 3.2 Designing Effective Architectures
    ‣ 3 Designing Effective Segmentation Networks ‣ Deep Learning Based Brain Tumor
    Segmentation: A Survey")). Many research works e.g. [[39](#bib.bib39)], [[99](#bib.bib99)],
    [[37](#bib.bib37)] use single path networks due to their computational efficiency.
    Compared with single path networks, multi-path networks can extract different
    features from different pathways of different scales. The extracted features are
    combined (added or concatenated) together for further processing. A common interpretation
    is that a large scale path (path with a large size’s kernel or input etc.) allows
    us to learn global features. Small scale’s paths (paths with a small size’s kernel
    or input etc.) allows us to learn features known as local features. Similar to
    the functionality mentioned in the previous section, global features tend to provide
    global information such as tumor location, size and shape while local features
    provide descriptive details such as tumor texture and boundary.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '在这里，我们将网络路径称为数据处理的流（见图 [7](#S3.F7 "Figure 7 ‣ 3.2.1 Multi-Path Architecture
    ‣ 3.2 Designing Effective Architectures ‣ 3 Designing Effective Segmentation Networks
    ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")）。许多研究工作，例如 [[39](#bib.bib39)]、[[99](#bib.bib99)]、[[37](#bib.bib37)]，由于其计算效率，使用了单路径网络。与单路径网络相比，多路径网络可以从不同尺度的不同路径中提取不同特征。提取的特征被组合（加或串联）在一起进行进一步处理。一种常见的解释是，大尺度路径（路径具有较大尺寸的卷积核或输入等）允许我们学习全局特征。小尺度路径（路径具有较小尺寸的卷积核或输入等）则允许我们学习被称为局部特征的特征。类似于前一节提到的功能，全局特征倾向于提供如肿瘤位置、大小和形状等全局信息，而局部特征则提供如肿瘤纹理和边界等描述性细节。'
- en: The work of Havaei et al. [[38](#bib.bib38)] is one of the early multi-path
    network based solutions. The author reported a novel two pathway structure that
    learns local tumor information as well as global contexts. The local pathway uses
    a $7\times 7$ convolution kernel and the global pathway uses a $13\times 13$ convolution
    kernel. In order to utilise CNN architectures, the authors designed several variant
    architectures that concatenate CNN outputs. Castillo et al. [[76](#bib.bib76)]
    used a 3 pathway CNN to segment brain tumors. Different from [[38](#bib.bib38)]
    that used kernels in different scales, [[76](#bib.bib76)] inputs each path with
    different sizes’ patches e.g. patches with low ($15\times 15$), medium($17\times
    17$) and normal ($27\times 27$) resolutions. Thus, each path can learn specific
    features under the condition of different spatial resolutions. Inspired by [[38](#bib.bib38)],
    Akil et al. [[100](#bib.bib100)] extended the network structure with overlapping
    patch prediction methods, where the center of the target patch is associated with
    the neighbouring overlapping patches.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Havaei 等人的研究 [[38](#bib.bib38)] 是早期基于多路径网络的解决方案之一。作者报告了一种新颖的两路径结构，该结构既能学习局部肿瘤信息，也能学习全局背景。局部路径使用
    $7\times 7$ 卷积核，而全局路径使用 $13\times 13$ 卷积核。为了利用 CNN 架构，作者设计了几种变体架构，将 CNN 输出进行串联。Castillo
    等人 [[76](#bib.bib76)] 使用了一个三路径 CNN 来分割脑肿瘤。与 [[38](#bib.bib38)] 使用不同尺度的卷积核不同，[[76](#bib.bib76)]
    对每条路径输入不同尺寸的补丁，例如低分辨率 ($15\times 15$)、中等分辨率 ($17\times 17$) 和正常分辨率 ($27\times
    27$) 的补丁。因此，每条路径可以在不同空间分辨率的条件下学习特定特征。受 [[38](#bib.bib38)] 的启发，Akil 等人 [[100](#bib.bib100)]
    扩展了网络结构，引入了重叠补丁预测方法，其中目标补丁的中心与邻近的重叠补丁相关联。
- en: Instead of building multi-path networks with different sizes’ kernels, other
    research works attempt to learn local-to-global information from the input directly.
    For example, Kamnitsas et al. [[101](#bib.bib101)] presented a dual pathway network
    which considers the input with different sizes’ patches, known as the normal resolution
    input of size $25\times 25\times 25$ and the low resolution input of size $19\times
    19\times 19$. Different from [[76](#bib.bib76)], the authors in [[101](#bib.bib101)]
    applied small convolution kernels with a size of $3\times 3\times 3$ on both pathways.
    Later research works by Zhao et al. [[74](#bib.bib74)] also designed a multi-scale
    CNN with a large scale path with the input size of $48\times 48$, a middle scale
    path with the input size of $18\times 18$ and a small scale path with the input
    size of $12\times 12$.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 其他研究工作尝试直接从输入中学习局部到全局的信息，而不是构建具有不同尺寸核的多路径网络。例如，Kamnitsas等人[[101](#bib.bib101)]提出了一种双路径网络，该网络考虑了不同尺寸补丁的输入，即尺寸为$25\times
    25\times 25$的正常分辨率输入和尺寸为$19\times 19\times 19$的低分辨率输入。与[[76](#bib.bib76)]不同，[[101](#bib.bib101)]中的作者在两个路径上应用了尺寸为$3\times
    3\times 3$的小卷积核。随后，赵等人[[74](#bib.bib74)]的研究工作也设计了一种多尺度CNN，其中包括一个输入尺寸为$48\times
    48$的大尺度路径，一个输入尺寸为$18\times 18$的中尺度路径，以及一个输入尺寸为$12\times 12$的小尺度路径。
- en: 3.2.2 Encoder-Decoder Architecture
  id: totrans-100
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 编码器-解码器架构
- en: '![Refer to caption](img/ea8666f14d5c31f9b392ad7785042044.png)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/ea8666f14d5c31f9b392ad7785042044.png)'
- en: 'Figure 8: A high level comparison between different fully convolutional networks
    (FCNs). Best viewed in colors.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：不同全卷积网络（FCNs）之间的高级比较。最佳查看效果为彩色。
- en: The input of the single and multiple path network for brain tumor segmentation
    is a patch or a certain area of the image, and the output is the classification
    outcome of the patch or the classification outcome of the central pixel of the
    input. It is very challenging to promote an accurate mapping from the patch level
    to the category label. First of all, the segmentation performance of single and
    multiple path network is easily affected by the size and quality of the input
    patch. A small sized input patch holds incomplete spatial information, while a
    large sized patch requires more computational resources. Secondly, the feature-to-label
    mapping is mostly conducted by the last fully connected layer. A simple fully
    connected layer cannot fully represent the feature space where complicated fully
    connected layers may overload the computer’s memory. Last but not least, this
    feature-to-label mapping is not of an end-to-end mode, which significantly increases
    the optimisation cost. To tackle these problems, recent research works start to
    use fully convolutional network (FCN) [[40](#bib.bib40)] and U-Net [[41](#bib.bib41)]
    based encoder-decoder networks, establish an end-to-end fashion from the input
    image to the output segmentation map, and further improve the segmentation performance
    of networks.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 单路径和多路径网络在脑肿瘤分割中的输入是图像的一个补丁或某个区域，输出是该补丁的分类结果或输入中心像素的分类结果。从补丁级别到类别标签的准确映射非常具有挑战性。首先，单路径和多路径网络的分割性能容易受到输入补丁的大小和质量的影响。小尺寸的输入补丁包含不完整的空间信息，而大尺寸的补丁则需要更多的计算资源。其次，特征到标签的映射通常由最后一个全连接层完成。一个简单的全连接层无法完全表示特征空间，而复杂的全连接层可能会超载计算机内存。最后但同样重要的是，这种特征到标签的映射不是端到端模式，这显著增加了优化成本。为了应对这些问题，最近的研究开始使用基于全卷积网络（FCN）[[40](#bib.bib40)]和U-Net
    [[41](#bib.bib41)]的编码器-解码器网络，建立从输入图像到输出分割图的端到端模式，并进一步提高网络的分割性能。
- en: Jesson et al. [[85](#bib.bib85)] extended standard FCN by using a multi-scale
    loss function. One limitation of FCN is that FCN does not explicitly model the
    contexts in the label domain. In [[85](#bib.bib85)], the FCN variant minimised
    the multi-scale loss by combining higher and lower resolution feature maps to
    model the contexts in both image and label domains. In [[102](#bib.bib102)], researchers
    proposed a boundary aware fully convolutional neural network, including two branches
    for up-sampling. The boundary detection branch aims to learn and model boundary
    information of the whole tumor as a binary classification problem. The region
    detection branch learns to detect and classify sub-region classes of the tumor.
    The outputs from the two branches are concatenated and fed to a block of two convolutional
    layers with a softmax classification layer.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Jesson 等人 [[85](#bib.bib85)] 通过使用多尺度损失函数扩展了标准 FCN。FCN 的一个限制是它没有明确建模标签域中的上下文。在
    [[85](#bib.bib85)] 中，FCN 变体通过结合高分辨率和低分辨率特征图来建模图像和标签域中的上下文，从而最小化多尺度损失。在 [[102](#bib.bib102)]
    中，研究人员提出了一种边界感知全卷积神经网络，包括两个用于上采样的分支。边界检测分支旨在将整个肿瘤的边界信息作为二分类问题进行学习和建模。区域检测分支学习检测和分类肿瘤的子区域类别。两个分支的输出被连接并送入一个由两个卷积层和一个
    softmax 分类层组成的块。
- en: One important mutant of FCN is U-Net [[41](#bib.bib41)]. U-Net consists of a
    contracting path to capture features and a symmetric expanding path that enables
    precise localisation. One advantage of using U-Net, compared against traditional
    FCN, is the skip connections between the contracting and the expanding paths.
    The skip connections pass feature maps from the contracting path to the expanding
    path and concatenate the feature maps from the two paths directly. The original
    image data through skip connections can help the layers in the contracting path
    recover details. Several research works have been proposed for brain tumor segmentation
    based on U-Net. For example, Brosch et al. [[103](#bib.bib103)] used a fully convolutional
    network with skip connections to segment multiple sclerosis lesions. Isensee et
    al. [[104](#bib.bib104)] reported a modified U-Net for brain tumor segmentation,
    where the authors used a dice loss function and extensive data augmentation to
    successfully avoid over-fitting. In [[105](#bib.bib105)], the authors used zero
    padding to keep the identical output dimension for all the convolutional layers
    in both down-sampling and up-sampling paths. Chang et al. [[86](#bib.bib86)] reported
    a fully convolutional neural network with residual connections. Similar to skip
    connection, the residual connection allows both low- and high-level feature maps
    to contribute towards the final segmentation.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: FCN 的一个重要变种是 U-Net [[41](#bib.bib41)]。U-Net 由一个收缩路径和一个对称的扩展路径组成，前者用于捕捉特征，后者实现精确的定位。与传统
    FCN 相比，使用 U-Net 的一个优势是收缩路径和扩展路径之间的跳跃连接。跳跃连接将特征图从收缩路径传递到扩展路径，并直接连接来自两个路径的特征图。通过跳跃连接的原始图像数据可以帮助收缩路径中的层恢复细节。基于
    U-Net 的脑肿瘤分割已经有多个研究成果。例如，Brosch 等人 [[103](#bib.bib103)] 使用具有跳跃连接的全卷积网络来分割多发性硬化病变。Isensee
    等人 [[104](#bib.bib104)] 报告了一种改进的 U-Net 用于脑肿瘤分割，作者使用了 dice 损失函数和广泛的数据增强来成功避免过拟合。在
    [[105](#bib.bib105)] 中，作者使用零填充保持所有卷积层在下采样和上采样路径中的相同输出维度。Chang 等人 [[86](#bib.bib86)]
    报告了一种具有残差连接的全卷积神经网络。类似于跳跃连接，残差连接允许低级和高级特征图都对最终分割结果做出贡献。
- en: 'In order to extract information from the original volumetric data, Milletari
    et al. [[106](#bib.bib106)] introduced a modified 3D version of U-Net, called
    V-Net, with a customized dice coefficient loss function. Beers et al. [[107](#bib.bib107)]
    introduced 3D U-Nets based on sequential tasks, which uses the entire tumor ground
    truth as an auxiliary channel to detect enhancing tumors and tumor cores. In the
    post-processing stage, the authors employed two additional U-Nets that serve to
    enhance prediction for better classification outcomes. The input patches consist
    of seven channels: four anatomical MR and three label maps corresponding to the
    entire tumor, enhancing tumor, and tumor core.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了从原始体积数据中提取信息，Milletari 等人 [[106](#bib.bib106)] 引入了一种修改版的 3D U-Net，称为 V-Net，具有自定义的
    dice 系数损失函数。Beers 等人 [[107](#bib.bib107)] 引入了基于序列任务的 3D U-Nets，它使用整个肿瘤的真实标签作为辅助通道来检测增强的肿瘤和肿瘤核心。在后处理阶段，作者使用了两个额外的
    U-Net 以增强预测，从而获得更好的分类结果。输入的补丁由七个通道组成：四个解剖 MR 图像和三个标签图，分别对应于整个肿瘤、增强的肿瘤和肿瘤核心。
- en: 'Table 2: Comparison between novel methods focuses on effective network design.
    We categorise the methods based on their main contributions. In column Input,
    ’P’ means patch and ’I’ means image. ’Dim’ means the dimension of the network.
    In column Loss, ’CE’ means cross-entropy loss, ’mIoU’ means the mean Intersection
    of Union and ’KL’ means KL-divergence. In column Dice and Hausdorff, ’WT’ means
    whole tumor, ’TC’ means tumor core and ’ET’ means enhancing tumor. Column Dataset
    indicates the associated dataset with the segmentation performance. In column
    Type, ’CV’ means cross-validation on the BraTS training set, ’V’ means BraTS validation
    set and ’T’ means BraTS test set. ’-’ means the entry has not been reported in
    the original paper.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 比较新方法，侧重于有效网络设计。我们根据主要贡献对方法进行分类。在“输入”栏中，‘P’表示补丁，‘I’表示图像。‘Dim’表示网络的维度。在“损失”栏中，‘CE’表示交叉熵损失，‘mIoU’表示均值交并比，‘KL’表示KL散度。在“Dice”和“Hausdorff”栏中，‘WT’表示整体肿瘤，‘TC’表示肿瘤核心，‘ET’表示增强肿瘤。“数据集”栏指示与分割性能相关的数据集。在“类型”栏中，‘CV’表示在BraTS训练集上的交叉验证，‘V’表示BraTS验证集，‘T’表示BraTS测试集。‘-’表示原始论文中未报告该条目。'
- en: '| Methods | Input | Dim | Loss | Dice | Hausdorff | Dataset |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 输入 | 维度 | 损失 | Dice | Hausdorff | 数据集 |'
- en: '| WT | TC | ET | WT | TC | ET | Year | Type |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| WT | TC | ET | WT | TC | ET | 年份 | 类型 |'
- en: '| Designing Effective Modules | [[81](#bib.bib81)] | P | 2D | - | 0.81 | 0.79
    | - | - | - | - | 2014 | V |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 设计有效模块 | [[81](#bib.bib81)] | P | 2D | - | 0.81 | 0.79 | - | - | - | - |
    2014 | V |'
- en: '|  | [[43](#bib.bib43)] | I | 2D | Softmax | 0.84 | 0.73 | 0.62 | - | - | -
    | 2015 | T |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | [[43](#bib.bib43)] | I | 2D | Softmax | 0.84 | 0.73 | 0.62 | - | - | -
    | 2015 | T |'
- en: '|  | [[82](#bib.bib82)] | P | 2D | - | - | - | - | - | - | - | - | - |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | [[82](#bib.bib82)] | P | 2D | - | - | - | - | - | - | - | - | - |'
- en: '|  | [[84](#bib.bib84)] | I | 3D | CE | 0.91 | 0.83 | - | - | - | - | 2015
    | CV |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | [[84](#bib.bib84)] | I | 3D | CE | 0.91 | 0.83 | - | - | - | - | 2015
    | CV |'
- en: '|  | [[78](#bib.bib78)] | I | 2D | CE+Soft Dice | 0.87 | 0.68 | - | - | - |
    - | 2017 | V |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|  | [[78](#bib.bib78)] | I | 2D | CE+软 Dice | 0.87 | 0.68 | - | - | - | -
    | 2017 | V |'
- en: '|  | [[88](#bib.bib88)] | I | 3D | Dice | 0.9 | 0.82 | 0.78 | 5.14 | 6.64 |
    7.71 | 2020 | V |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | [[88](#bib.bib88)] | I | 3D | Dice | 0.9 | 0.82 | 0.78 | 5.14 | 6.64 |
    7.71 | 2020 | V |'
- en: '|  | [[79](#bib.bib79)] | I | 2D | - | 0.86 | 0.77 | 0.74 | - | - | - | 2018
    | V |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | [[79](#bib.bib79)] | I | 2D | - | 0.86 | 0.77 | 0.74 | - | - | - | 2018
    | V |'
- en: '|  | [[89](#bib.bib89)] | I | 2D | CE+Dice+MP | 0.91 | 0.85 | 0.79 | 4.71 |
    5.7 | 35.01 | 2020 | V |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | [[89](#bib.bib89)] | I | 2D | CE+Dice+MP | 0.91 | 0.85 | 0.79 | 4.71 |
    5.7 | 35.01 | 2020 | V |'
- en: '|  | [[94](#bib.bib94)] | P | 3D | Multinomial Logistic | - | - | - | - | -
    | - | - | - |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | [[94](#bib.bib94)] | P | 3D | 多项式逻辑回归 | - | - | - | - | - | - | - | -
    |'
- en: '|  | [[72](#bib.bib72)] | I | 2D | Dice+Edge+Mask | 0.9 | 0.82 | 0.78 | 5.41
    | 7.26 | 5.282 | 2019 | V |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | [[72](#bib.bib72)] | I | 2D | Dice+Edge+Mask | 0.9 | 0.82 | 0.78 | 5.41
    | 7.26 | 5.282 | 2019 | V |'
- en: '|  | [[70](#bib.bib70)] | I | 3D | Dice | 0.91 | 0.86 | 0.81 | 5.61 | 7.83
    | 3.35 | 2018 | V |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|  | [[70](#bib.bib70)] | I | 3D | Dice | 0.91 | 0.86 | 0.81 | 5.61 | 7.83
    | 3.35 | 2018 | V |'
- en: '|  | [[73](#bib.bib73)] | I | 3D | - | - | - | - | - | - | - | - | - |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|  | [[73](#bib.bib73)] | I | 3D | - | - | - | - | - | - | - | - | - |'
- en: '|  | [[98](#bib.bib98)] | I | 2D | mIoU | 0.85 | 0.78 | 0.67 | 9.6 | 8.67 |
    5.5 | 2018 | T |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | [[98](#bib.bib98)] | I | 2D | mIoU | 0.85 | 0.78 | 0.67 | 9.6 | 8.67 |
    5.5 | 2018 | T |'
- en: '|  | [[71](#bib.bib71)] | I | 3D | Generalized Dice | 0.91 | 0.85 | 0.8 | 4.66
    | 6.44 | 3.06 | 2018 | V |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | [[71](#bib.bib71)] | I | 3D | 一般化 Dice | 0.91 | 0.85 | 0.8 | 4.66 | 6.44
    | 3.06 | 2018 | V |'
- en: '| Designing Effective Architectures | [[37](#bib.bib37)] | P | 2D | Log Loss
    | 0.84 | 0.73 | 0.69 | - | - | - | 2013 | V |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 设计有效架构 | [[37](#bib.bib37)] | P | 2D | 对数损失 | 0.84 | 0.73 | 0.69 | - | -
    | - | 2013 | V |'
- en: '|  | [[39](#bib.bib39)] | P | 2D | Categorical CE | 0.78 | 0.65 | 0.75 | 15.83
    | 26.54 | 6.99 | 2015 | T |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | [[39](#bib.bib39)] | P | 2D | 分类 CE | 0.78 | 0.65 | 0.75 | 15.83 | 26.54
    | 6.99 | 2015 | T |'
- en: '|  | [[38](#bib.bib38)] | P | 2D | Surrogate Loss | 0.84 | 0.71 | 0.57 | -
    | - | - | 2013 | T |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  | [[38](#bib.bib38)] | P | 2D | 替代损失 | 0.84 | 0.71 | 0.57 | - | - | - |
    2013 | T |'
- en: '|  | [[76](#bib.bib76)] | P | 3D | - | - | - | - | - | - | - | 2015 | CV |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|  | [[76](#bib.bib76)] | P | 3D | - | - | - | - | - | - | - | 2015 | CV |'
- en: '|  | [[45](#bib.bib45)] | P | 3D | CE/IoU | 0.9 | 0.8 | 0.74 | 4.23 | 6.56
    | 4.5 | 2017 | V |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | [[45](#bib.bib45)] | P | 3D | CE/IoU | 0.9 | 0.8 | 0.74 | 4.23 | 6.56
    | 4.5 | 2017 | V |'
- en: '|  | [[74](#bib.bib74)] | P | 2D | - | - | - | - | - | - | - | - | - |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|  | [[74](#bib.bib74)] | P | 2D | - | - | - | - | - | - | - | - | - |'
- en: '|  | [[85](#bib.bib85)] | I | 3D | Categorical CE | 0.9 | 0.75 | 0.71 | 4.16
    | 8.65 | 6.98 | 2017 | V |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|  | [[85](#bib.bib85)] | I | 3D | 分类 CE | 0.9 | 0.75 | 0.71 | 4.16 | 8.65
    | 6.98 | 2017 | V |'
- en: '|  | [[104](#bib.bib104)] | I | 3D | Dice | 0.9 | 0.8 | 0.73 | 7 | 9.48 | 4.55
    | 2017 | V |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|  | [[104](#bib.bib104)] | I | 3D | Dice | 0.9 | 0.8 | 0.73 | 7 | 9.48 | 4.55
    | 2017 | V |'
- en: '|  | [[105](#bib.bib105)] | I | 2D | Soft Dice | 0.86 | 0.86 | 0.65 | - | -
    | - | 2015 | CV |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|  | [[105](#bib.bib105)] | I | 2D | 软 Dice | 0.86 | 0.86 | 0.65 | - | - |
    - | 2015 | CV |'
- en: '|  | [[86](#bib.bib86)] | I | 2D | - | 0.89 | 0.83 | 0.78 | 8 | 10 | 5.9 |
    2016 | T |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|  | [[86](#bib.bib86)] | I | 2D | - | 0.89 | 0.83 | 0.78 | 8 | 10 | 5.9 |
    2016 | T |'
- en: '|  | [[108](#bib.bib108)] | P | 2D | KL | 0.87 | 0.74 | 0.65 | - | - | - |
    2017 | V |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|  | [[108](#bib.bib108)] | P | 2D | KL | 0.87 | 0.74 | 0.65 | - | - | - |
    2017 | V |'
- en: '|  | [[109](#bib.bib109)] | P | 3D | KL | 0.89 | 0.74 | 0.73 | - | - | - |
    2017 | V |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | [[109](#bib.bib109)] | P | 3D | KL | 0.89 | 0.74 | 0.73 | - | - | - |
    2017 | V |'
- en: '|  | [[110](#bib.bib110)] | I | 2D | Softmax | 0.82 | 0.63 | 0.57 | - | - |
    - | 2017 | V |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | [[110](#bib.bib110)] | I | 2D | Softmax | 0.82 | 0.63 | 0.57 | - | - |
    - | 2017 | V |'
- en: '|  | [[111](#bib.bib111)] | I | 3D | Dice | 0.84 | 0.78 | 0.68 | 9.2 | 7.71
    | 4.52 | 2018 | T |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  | [[111](#bib.bib111)] | I | 3D | Dice | 0.84 | 0.78 | 0.68 | 9.2 | 7.71
    | 4.52 | 2018 | T |'
- en: '|  | [[112](#bib.bib112)] | I | 2D | - | 0.86 | 0.73 | 0.72 | 7.5 | 9.5 | 5.7
    | 2018 | V |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|  | [[112](#bib.bib112)] | I | 2D | - | 0.86 | 0.73 | 0.72 | 7.5 | 9.5 | 5.7
    | 2018 | V |'
- en: '|  | [[113](#bib.bib113)] | I | 3D | Focal | 0.9 | 0.84 | 0.77 | 5.18 | 6.28
    | 3.51 | 2018 | V |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | [[113](#bib.bib113)] | I | 3D | Focal | 0.9 | 0.84 | 0.77 | 5.18 | 6.28
    | 3.51 | 2018 | V |'
- en: '|  | [[42](#bib.bib42)] | P | 3D | Dice | 0.91 | 0.86 | 0.81 | 4.27 | 6.52
    | 2.41 | 2018 | V |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|  | [[42](#bib.bib42)] | P | 3D | Dice | 0.91 | 0.86 | 0.81 | 4.27 | 6.52
    | 2.41 | 2018 | V |'
- en: '|  | [[114](#bib.bib114)] | I | 3D | Dice | 0.88 | 0.79 | 0.72 | 29.21 | 11.06
    | 7.93 | 2018 | V |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|  | [[114](#bib.bib114)] | I | 3D | Dice | 0.88 | 0.79 | 0.72 | 29.21 | 11.06
    | 7.93 | 2018 | V |'
- en: '|  | [[47](#bib.bib47)] | I | 3D | Dice+L2+KL | 0.91 | 0.87 | 0.82 | 4.52 |
    6.85 | 3.92 | 2018 | V |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | [[47](#bib.bib47)] | I | 3D | Dice+L2+KL | 0.91 | 0.87 | 0.82 | 4.52 |
    6.85 | 3.92 | 2018 | V |'
- en: '|  | [[115](#bib.bib115)] | P | 3D | CE+Dice | 0.91 | 0.84 | 0.75 | 4.57 |
    5.58 | 3.84 | 2019 | V |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  | [[115](#bib.bib115)] | P | 3D | CE+Dice | 0.91 | 0.84 | 0.75 | 4.57 |
    5.58 | 3.84 | 2019 | V |'
- en: '|  | [[116](#bib.bib116)] | I | 3D | Jaccard+Focal | 0.91 | 0.85 | 0.79 | 4.09
    | 5.88 | 18.19 | 2020 | V |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  | [[116](#bib.bib116)] | I | 3D | Jaccard+Focal | 0.91 | 0.85 | 0.79 | 4.09
    | 5.88 | 18.19 | 2020 | V |'
- en: '|  | [[117](#bib.bib117)] | I | 2D | Dice | 0.91 | 0.85 | 0.8 | 4.3 | 5.69
    | 20.56 | 2020 | V |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '|  | [[117](#bib.bib117)] | I | 2D | Dice | 0.91 | 0.85 | 0.8 | 4.3 | 5.69
    | 20.56 | 2020 | V |'
- en: 3.3 Summary
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 总结
- en: 'In this section, we review and compare the work focused on module and network
    architecture design in brain tumor segmentation. Table [2](#S3.T2 "Table 2 ‣ 3.2.2
    Encoder-Decoder Architecture ‣ 3.2 Designing Effective Architectures ‣ 3 Designing
    Effective Segmentation Networks ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey") shows the results generated by methods focused on module and network
    architecture design in brain tumor segmentation. We drawn key information of these
    research works and list it below.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '在这一部分，我们回顾并比较了集中于脑肿瘤分割中的模块和网络架构设计的研究工作。表格 [2](#S3.T2 "Table 2 ‣ 3.2.2 Encoder-Decoder
    Architecture ‣ 3.2 Designing Effective Architectures ‣ 3 Designing Effective Segmentation
    Networks ‣ Deep Learning Based Brain Tumor Segmentation: A Survey") 展示了集中于脑肿瘤分割中的模块和网络架构设计方法生成的结果。我们提取了这些研究工作的关键信息，并列在下面。'
- en: '1.'
  id: totrans-148
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: By designing custom modules, the accuracy and speed of the network can be improved.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过设计定制模块，可以提高网络的准确性和速度。
- en: '2.'
  id: totrans-150
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: By designing a customised architecture, it can help the network learn features
    at different scales, which is one of the most important steps to achieve accurate
    brain tumor segmentation.
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过设计定制化架构，可以帮助网络学习不同尺度的特征，这是一项实现准确脑肿瘤分割的重要步骤。
- en: '3.'
  id: totrans-152
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: The design of modules and networks heavily relies on human experience. In the
    future, we anticipate the application of network architecture search for searching
    effective brain tumor segmentation architectures [[118](#bib.bib118)], [[119](#bib.bib119)],
    [[120](#bib.bib120)], [[121](#bib.bib121)].
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 模块和网络的设计在很大程度上依赖于人类经验。未来，我们预期会应用网络架构搜索来寻找有效的脑肿瘤分割架构 [[118](#bib.bib118)], [[119](#bib.bib119)],
    [[120](#bib.bib120)], [[121](#bib.bib121)]。
- en: '4.'
  id: totrans-154
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Most of the existing network architecture designs do not combine domain knowledge
    about brain tumor, such as modelling degree information and physically inspired
    morphological information within tumor segmentation network.
  id: totrans-155
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现有的大多数网络架构设计没有结合关于脑肿瘤的领域知识，例如在肿瘤分割网络中建模度信息和受物理启发的形态学信息。
- en: 4 Segmentation under Imbalanced Condition
  id: totrans-156
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 不平衡条件下的分割
- en: 'One of the long standing challenges for brain tumor segmentation is the data
    imbalance issue. As shown in Fig [3](#S1.F3 "Figure 3 ‣ 1.1 Difference from Previous
    Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")
    (c), imbalance is mainly reflected in the number of pixels in the sub-regions
    of the brain tumor. In addition, there is also an imbalance issue in patient samples,
    that is, the number of the HGG cases is much more than that of the LGG cases.
    At the same time, labeling biases introduced by manual experts can also be treated
    as a special form of data imbalance (different experts have different standards,
    resulting in imbalanced labeling results). Data imbalance plays a significant
    effect on learning algorithms especially deep networks. The main manifestation
    is that learning models trained with imbalanced data tend to learn more about
    the dominant groups, e.g. to learn the morphology of the edema area, and to learn
    HGG instead of LGG patients) [[122](#bib.bib122)], [[123](#bib.bib123)], [[49](#bib.bib49)].'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: '脑肿瘤分割的一个长期挑战是数据不平衡问题。如图 [3](#S1.F3 "Figure 3 ‣ 1.1 Difference from Previous
    Surveys ‣ 1 Introduction ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")
    (c) 所示，不平衡主要体现在脑肿瘤子区域的像素数量上。此外，患者样本中也存在不平衡问题，即HGG病例的数量远多于LGG病例。同时，由人工专家引入的标注偏差也可以视为一种特殊的数据不平衡形式（不同专家有不同的标准，导致标注结果不平衡）。数据不平衡对学习算法特别是深度网络有显著影响。主要表现为，用不平衡数据训练的学习模型往往更倾向于学习占主导的组，例如学习水肿区域的形态，学习HGG而非LGG患者）[[122](#bib.bib122)],
    [[123](#bib.bib123)], [[49](#bib.bib49)]。'
- en: 'It is less likely to deal with the data imbalance issue by designing a specific
    module or architecture. Numerous works have presented many improvement strategies
    to address data imbalance. According to core components of these strategies, we
    divide the existing methods into three categories: multi-network driven, multi-task
    driven and custom loss function driven approaches.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 通过设计特定模块或架构来处理数据不平衡问题的可能性较小。大量工作提出了许多改进策略来解决数据不平衡问题。根据这些策略的核心组成部分，我们将现有方法分为三类：多网络驱动、多任务驱动和定制损失函数驱动的方法。
- en: 4.1 Multi-Network Driven Approaches
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 多网络驱动方法
- en: Even if complex modules and architectures have been designed to ensure the learning
    of high-dimensional discriminative features, a single network often suffers from
    the problem of data imbalance. Inspired by the methods such as multi-expert systems,
    people have started to construct complex network systems to effectively deal with
    data imbalance and achieved promising segmentation performance. Common multi-network
    systems can be divided into network cascade and network ensemble, according to
    data flows shared between multiple networks.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 即使设计了复杂的模块和架构以确保高维区分特征的学习，单一网络仍常常面临数据不平衡的问题。受多专家系统等方法的启发，人们开始构建复杂的网络系统，以有效处理数据不平衡并取得了有希望的分割性能。根据多个网络之间共享的数据流，常见的多网络系统可以分为网络级联和网络集成。
- en: '![Refer to caption](img/3fb42601890add9a39fff05d9b6904ce.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/3fb42601890add9a39fff05d9b6904ce.png)'
- en: 'Figure 9: The structure of cascaded convolutional networks for brain tumor
    segmentation, modified from the original structure reported in [[46](#bib.bib46)].
    WNet, TNet and ENet are used for segmenting the whole tumor, tumor core and enhancing
    tumor core, respectively.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：用于脑肿瘤分割的级联卷积网络结构，已根据[[46](#bib.bib46)]中的原始结构进行修改。WNet、TNet和ENet分别用于分割整个肿瘤、肿瘤核心和增强肿瘤核心。
- en: 4.1.1 Network Cascade
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 网络级联
- en: The definition of network cascade is that, in a serially connected network,
    the output of an upstream network is passed to the downstream network as input.
    This topology simulates the coarse-to-fine strategy, that is, the upstream network
    extracts rough information or features, and the downstream network subdivides
    the input and achieves a fine-grained segmentation.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 网络级联的定义是，在串联连接的网络中，上游网络的输出被传递到下游网络作为输入。这种拓扑结构模拟了从粗到细的策略，即上游网络提取粗略的信息或特征，下游网络细分输入，实现细粒度的分割。
- en: 'The earliest work of adopting the cascade strategy was undertaken by Wang et
    al [[46](#bib.bib46)] (Fig. [9](#S4.F9 "Figure 9 ‣ 4.1 Multi-Network Driven Approaches
    ‣ 4 Segmentation under Imbalanced Condition ‣ Deep Learning Based Brain Tumor
    Segmentation: A Survey")). In their work, the author proposed to connect three
    networks in series. First, WNet segmented Whole Tumor, and output the segmentation
    result of Whole Tumor to TNet, and TNet traces Tumor Core. Finally, the segmentation
    result of TNet is handed over to ENet for the segmentation of Enhancing Tumor.
    This design logic is inspired by the attributes of the tumor sub-region, where
    it is assumed that Whole Tumor, Tumor Core, and Enhancing Tumor are included one
    by one. Therefore, the segmentation output of the upstream network is the Region-of-Interest
    (RoI) of the downstream network. The advantage of this practice is to avoid the
    interference caused by the unbalanced data. The introduction of astropic convolution
    and the manually cropped input effectively reduces the amount of network parameters.
    But there are two disadvantages: First of all, the segmentation effect of the
    downstream network is heavily dependent on the performance of the upstream network.
    Second, only the upstream segmentation result is considered as the input so that
    the downstream network cannot use other image areas as auxiliary information,
    which is not conducive to other tasks such as tumor location detection. Similarly,
    Hua et al. [[113](#bib.bib113)] also proposed a network cascade based on the physical
    inclusion characteristics of tumor. Unlike Wang et al. [[46](#bib.bib46)], [[113](#bib.bib113)]
    replaced the cascade unit with a V-Net, which is suitable for 3D segmentation
    to improve performance. Fang et al. [[112](#bib.bib112)] trained two networks
    to act as upstream networks at the same time according to different organisational
    characteristics highlighted by different modalities, respectively training for
    Flair and T1ce, and then the results of the two upstream networks can be passed
    to the downstream network for final fine segmentation. Jia et al. [[124](#bib.bib124)]
    replaced upstream and downstream networks with HRNet [[125](#bib.bib125)] to preserve
    maximum spatial resolutions.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 采用级联策略的最早工作由王等人进行 [[46](#bib.bib46)]（见图 [9](#S4.F9 "图 9 ‣ 4.1 多网络驱动方法 ‣ 4 不平衡条件下的分割
    ‣ 基于深度学习的脑肿瘤分割：综述")）。在他们的工作中，作者提出将三个网络串联起来。首先，WNet 对整个肿瘤进行分割，并将整个肿瘤的分割结果输出给 TNet，TNet
    则跟踪肿瘤核心。最后，TNet 的分割结果交给 ENet 进行增强肿瘤的分割。这种设计逻辑受到肿瘤子区域属性的启发，假设整个肿瘤、肿瘤核心和增强肿瘤是逐个包含的。因此，上游网络的分割输出是下游网络的感兴趣区域（RoI）。这种做法的优点在于避免了数据不平衡带来的干扰。引入自适应卷积和手动裁剪输入有效减少了网络参数的数量。但也有两个缺点：首先，下游网络的分割效果严重依赖于上游网络的性能。其次，仅将上游分割结果作为输入，使得下游网络无法利用其他图像区域作为辅助信息，这不利于肿瘤位置检测等其他任务。同样，华等人
    [[113](#bib.bib113)] 也提出了一种基于肿瘤物理包含特征的网络级联。与王等人 [[46](#bib.bib46)] 不同的是，[[113](#bib.bib113)]
    将级联单元替换为适用于 3D 分割的 V-Net，以提高性能。方等人 [[112](#bib.bib112)] 训练了两个网络同时作为上游网络，根据不同的模态突出不同的组织特征，分别对
    Flair 和 T1ce 进行训练，然后将两个上游网络的结果传递给下游网络进行最终的细化分割。贾等人 [[124](#bib.bib124)] 用 HRNet
    [[125](#bib.bib125)] 替换了上游和下游网络，以保持最大的空间分辨率。
- en: Combining 3D networks for cascading can bring better segmentation performance,
    but the combination of multiple 3D networks requires a large amount of parameters
    and high computational resources. In response to this, Li [[114](#bib.bib114)]
    proposed a cascading model that mixes 2D and 3D networks. 2D networks learn from
    multi views of a volume to obtain the segmentation mask of the whole tumor. Then,
    the whole tumor mask and the original 3D volume are fed to the downstream 3D U-Net.
    The downstream network pairs tumor core and enhancing tumor for fine segmentation.
    Li et al. [[126](#bib.bib126)] also adopted a similar method by connecting multiple
    U-Nets in series for coarse-to-fine segmentation. The segmentation results at
    each stage is associated with different loss functions. Vu et al. [[127](#bib.bib127)]
    further introduced dense connection between the upstream and downstream networks
    to enhance feature expression. The two-stage cascaded U-Net designed by Jiang
    et al. [[44](#bib.bib44)] has been further enhanced at the output end. In addition
    to the single network architecture, they also tried two different segmentation
    modules (interpolation and deconvolution) at the output end.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 将3D网络进行级联可以带来更好的分割性能，但多个3D网络的组合需要大量的参数和高计算资源。为此，Li [[114](#bib.bib114)] 提出了一个将2D和3D网络混合的级联模型。2D网络从体积的多个视角学习，以获取整个肿瘤的分割掩模。然后，将整个肿瘤掩模和原始3D体积输入下游的3D
    U-Net。下游网络将肿瘤核心和增强型肿瘤配对进行精细分割。Li 等人 [[126](#bib.bib126)] 也采用了类似的方法，通过串联多个U-Net进行粗到精的分割。每个阶段的分割结果与不同的损失函数相关联。Vu
    等人 [[127](#bib.bib127)] 进一步引入了上游和下游网络之间的密集连接，以增强特征表达。Jiang 等人 [[44](#bib.bib44)]
    设计的两阶段级联U-Net 在输出端得到了进一步的增强。除了单一网络架构，他们还在输出端尝试了两种不同的分割模块（插值和反卷积）。
- en: In addition to coarse-to-fine segmentation, there are other attempts to introduce
    other auxiliary functions. Liu designed a novel strategy in [[128](#bib.bib128)]
    to pass the segmentation result of the upstream network to the downstream network.
    The downstream network reconstructs the original input image according to the
    segmentation result of the upstream network. The loss of the recovery network
    is also back-propagated to the upstream segmentation network, in order to help
    the upstream network to outline the tumor area. Cirillo et al. [[129](#bib.bib129)]
    introduced adversarial training to tumor segmentation. The generator network constitutes
    the upstream network, and the discriminator network is used as the downstream
    network to determine whether a segmentation map is from ground truth or not. Chen
    et al. [[130](#bib.bib130)] introduced left and right symmetry characteristics
    of the brain to the system. The added left and right similarity masks at the connection
    of the upstream and downstream networks can improve the robustness of network
    segmentation.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 除了粗到精的分割，还有其他尝试引入其他辅助功能。Liu 在 [[128](#bib.bib128)] 中设计了一种新策略，将上游网络的分割结果传递给下游网络。下游网络根据上游网络的分割结果重建原始输入图像。恢复网络的损失也被反向传播到上游分割网络，以帮助上游网络描绘肿瘤区域。Cirillo
    等人 [[129](#bib.bib129)] 将对抗训练引入肿瘤分割中。生成网络构成上游网络，判别网络作为下游网络，用于判断分割图是否来自真实数据。Chen
    等人 [[130](#bib.bib130)] 将大脑的左右对称特性引入系统。在上游和下游网络连接处添加的左右相似掩模可以提高网络分割的鲁棒性。
- en: 4.1.2 Network Ensemble
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 网络集成
- en: One main drawback of using a single deep neural network is that its performance
    is heavily influenced by the hyper-parameter choices. This refers to a limited
    generalisation capability of the deep neural network. Cascaded network intends
    to aggregate multiple networks’ output in a coarse-to-fine strategy, however downstream
    networks’ performance relies on the upstream network, which still limits the capability
    of a cascaded system. In order to achieve a more robust and more generalised tumor
    segmentation, the segmentation output from multiple networks can be aggregated
    together with a high variance, known as network ensemble. Network ensemble enlarges
    the hypothesis space of the parameters to be trained by aggregating multiple networks
    and avoids falling into local optimum caused by data imbalance.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 使用单一深度神经网络的一个主要缺点是其性能受超参数选择的影响较大。这指的是深度神经网络的有限泛化能力。级联网络旨在以粗到细的策略聚合多个网络的输出，但下游网络的性能依赖于上游网络，这仍然限制了级联系统的能力。为了实现更强大且更具泛化性的肿瘤分割，可以通过高方差将多个网络的分割输出聚合在一起，这被称为网络集成。网络集成通过聚合多个网络扩大了待训练参数的假设空间，避免了由于数据不平衡而导致的局部最优。
- en: 'Early research works presented in multi-path network (Sec. [3.2.1](#S3.SS2.SSS1
    "3.2.1 Multi-Path Architecture ‣ 3.2 Designing Effective Architectures ‣ 3 Designing
    Effective Segmentation Networks ‣ Deep Learning Based Brain Tumor Segmentation:
    A Survey")) such as Castillo et al. [[76](#bib.bib76)], Kamnitsas et al. [[131](#bib.bib131)],
    [[101](#bib.bib101)] can be regarded as a special form of network ensemble, where
    each path can be treated as a sub-network. The features extracted by the sub-network
    are then ensembled and processed for the final segmentation. In this section,
    we pay more attention to explicit ensemble of segmentation results from multiple
    sub-networks, rather than implicit ensemble of the features extracted by sub-paths.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '早期在多路径网络（第[3.2.1节](#S3.SS2.SSS1 "3.2.1 Multi-Path Architecture ‣ 3.2 Designing
    Effective Architectures ‣ 3 Designing Effective Segmentation Networks ‣ Deep Learning
    Based Brain Tumor Segmentation: A Survey")）中提出的研究工作，如Castillo等人[[76](#bib.bib76)]、Kamnitsas等人[[131](#bib.bib131)]和[[101](#bib.bib101)]，可以视为一种特殊形式的网络集成，其中每个路径都可以视为一个子网络。子网络提取的特征随后被集成并处理以获得最终分割。在本节中，我们更关注从多个子网络中明确地集成分割结果，而不是隐式地集成由子路径提取的特征。'
- en: Ensembles of multiple models and architectures (EMMA) [[45](#bib.bib45)] is
    one of the early well-structured works using ensemble deep neural networks for
    brain tumor segmentation. EMMA ensembles segmentation results from DeepMedic [[131](#bib.bib131)],
    FCN [[40](#bib.bib40)] and U-Net [[41](#bib.bib41)] and associated the final segmentation
    with the highest confidence score. Kao et al. [[132](#bib.bib132)] ensembles 26
    neural networks for tumor segmentation and survival prediction. [[132](#bib.bib132)]
    introduced brain parcellation atlas to produce a location prior information for
    tumor segmentation. Lachinov et al. [[133](#bib.bib133)] ensembles two variant
    U-Net [[42](#bib.bib42)], [[47](#bib.bib47)] and a cascaded U-Net [[134](#bib.bib134)].
    The final ensemble result out-performs each single network $1-2\%$.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 多模型和架构集成（EMMA）[[45](#bib.bib45)]是早期使用集成深度神经网络进行脑肿瘤分割的结构良好的工作之一。EMMA集成了DeepMedic
    [[131](#bib.bib131)]、FCN [[40](#bib.bib40)] 和U-Net [[41](#bib.bib41)]的分割结果，并将最终分割与最高置信度分数相关联。Kao等人[[132](#bib.bib132)]集成了26个神经网络用于肿瘤分割和生存预测。[[132](#bib.bib132)]
    引入了脑分区图谱，以为肿瘤分割提供位置先验信息。Lachinov等人[[133](#bib.bib133)]集成了两个变种U-Net [[42](#bib.bib42)]、[[47](#bib.bib47)]和一个级联U-Net
    [[134](#bib.bib134)]。最终的集成结果比每个单一网络的表现提高了$1-2\%$。
- en: '![Refer to caption](img/f7c4313cadcd4742a7674a97f9fa2d9e.png)'
  id: totrans-172
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f7c4313cadcd4742a7674a97f9fa2d9e.png)'
- en: 'Figure 10: The structure of multi-task networks for brain tumor segmentation.
    Image courtesy of [[47](#bib.bib47)]. The shared encoder learns generalised feature
    representation and the reconstruction decoder performs multi-task as regularisation.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：用于脑肿瘤分割的多任务网络结构。图片由[[47](#bib.bib47)]提供。共享编码器学习通用特征表示，重建解码器执行作为正则化的多任务。
- en: Instead of feeding sub-networks with the same input, Zhao et al. [[135](#bib.bib135)]
    averaged ensembles 3 2D-FCNs where each FCN takes different view slices as input.
    Similarly, Sundaresan et al. [[136](#bib.bib136)] averaged ensembles 4 2D-FCNs,
    where each FCN is designed for segmenting a specific tumor region. Chen et al.
    [[137](#bib.bib137)] used a DeconvNet [[138](#bib.bib138)] to generate a primary
    segmentation probability map and another multi-scale Convolutional Label Evaluation
    Net is used to evaluate previously generated segmentation maps. False positives
    can be reduced using both the probability map and the original input image. Hu
    et al. [[139](#bib.bib139)] ensembles a 3D cascaded U-Net with a multi-modality
    fusion structure. The proposed two-level U-Net in [[139](#bib.bib139)] aims to
    outline the boundary of tumors and the patch-based deep network associates tumor
    voxels with predicted labels.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 赵等人[[135](#bib.bib135)] 并没有给子网络提供相同的输入，而是平均了3个2D-FCN的集合，其中每个FCN接收不同的视图切片作为输入。类似地，Sundaresan等人[[136](#bib.bib136)]
    平均了4个2D-FCN的集合，其中每个FCN设计用于分割特定的肿瘤区域。陈等人[[137](#bib.bib137)] 使用了一个DeconvNet[[138](#bib.bib138)]来生成初步的分割概率图，而另一个多尺度卷积标签评估网络用于评估先前生成的分割图。通过使用概率图和原始输入图像，可以减少假阳性。胡等人[[139](#bib.bib139)]
    集成了一个3D级联U-Net与多模态融合结构。[[139](#bib.bib139)]中提出的两级U-Net旨在描绘肿瘤的边界，并且基于补丁的深度网络将肿瘤体素与预测标签相关联。
- en: Ensemble can be regarded as a boosting strategy for improving final segmentation
    results by aggregating results from multiple homogeneous networks. The winner
    of the BraTS2018 [[47](#bib.bib47)] ensembles 10 models, which further boosted
    the performance with $1\%$ on dice score compared with the best single network
    segmentation. Similar benefits brought by ensembling can be observed from Silva
    et al. [[140](#bib.bib140)] as well. BraTS2019 winner [[44](#bib.bib44)] also
    adopted an ensemble strategy where the final result is generated by ensembling
    12 models, which slightly improves the result (around $0.6-1\%$) compared with
    the best single model’s performance.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 集成可以被视为一种提升策略，通过汇总多个同质网络的结果来改进最终的分割结果。BraTS2018的获胜者[[47](#bib.bib47)] 集成了10个模型，相比于最佳单一网络分割，进一步提升了$1\%$的dice得分。类似的集成带来的好处也可以从Silva等人[[140](#bib.bib140)]的工作中观察到。BraTS2019的获胜者[[44](#bib.bib44)]也采用了集成策略，其中最终结果由12个模型的集成生成，相比于最佳单一模型的性能，略微提高了结果（大约$0.6-1\%$）。
- en: 4.2 Multi-Task Driven Approaches
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 多任务驱动的方法
- en: Most of the work described above only perform single-task learning, that is,
    only design and optimise a network for precise segmentation of brain tumors only.
    The disadvantage of single-task learning is that the training target of a single-task
    may ignore the potential information in some tasks. Information from related tasks
    may improve the performance of tumor segmentation. Therefore, in recent years,
    many research works have started from the perspective of multi-task learning,
    introducing auxiliary tasks on the basis of precise segmentation of brain tumors.
    The main setting of multi-task learning is a low-level feature representation
    that can be shared among multiple tasks. There are two advantages from the shared
    representation. One is to share the learnt domain-related information with each
    other through shallow shared representations so as to promote learning and to
    enhance the ability to obtain updated information. The second is mutual restraint.
    When multi-task learning performs gradient back-propagation, it will take into
    account the feedback of multiple tasks. Since different tasks may have different
    noise patterns, the model that learns multiple tasks at the same time will learn
    a more general representation, which reduces the risk of overfitting and increases
    the generalisation ability of the system.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '上述大部分工作仅执行单任务学习，即仅为精确分割脑肿瘤设计和优化网络。单任务学习的缺点在于单一任务的训练目标可能忽略了某些任务中的潜在信息。相关任务的信息可能会提高肿瘤分割的性能。因此，近年来，许多研究工作从多任务学习的角度出发，在精确分割脑肿瘤的基础上引入辅助任务。多任务学习的主要设置是可以在多个任务之间共享的低级特征表示。共享表示有两个优势。其一是通过浅层共享表示相互分享学习到的领域相关信息，从而促进学习，增强获取更新信息的能力。其二是相互约束。当多任务学习执行梯度反向传播时，会考虑多个任务的反馈。由于不同任务可能具有不同的噪声模式，同时学习多个任务的模型将学习到更通用的表示，从而减少过拟合的风险，增加系统的泛化能力。 '
- en: Early attempts such as [[141](#bib.bib141)] and [[142](#bib.bib142)] adapt the
    idea of multi-task learning and split the brain tumor segmentation task into three
    different sub-region segmentation tasks, i.e. segmenting whole tumor, tumor core
    and enhancing tumor individually. In [[141](#bib.bib141)], the author incorporated
    three sub-region segmentation tasks into an end-to-end holistic network, and exploited
    the underlying relevance among the three sub-region segmentation tasks. In [[142](#bib.bib142)],
    the author designed three different loss functions, corresponding to the segmentation
    loss of whole tumor, tumor core and enhancing tumor. In addition, more recent
    works introduce auxiliary tasks different from image segmentation. The learnt
    features from other tasks will support accurate segmentation. In [[102](#bib.bib102)],
    the author additionally introduces a boundary localisation task. The features
    extracted by the shared encoder are not only suitable for tumor segmentation,
    but also for tumor boundary localisation. Precise boundary localisation can assist
    in minimising the searching space and defining precise boundaries during tumor
    segmentation. [[143](#bib.bib143)] introduced the idea of first detecting and
    then segmenting, that is, detecting the location of tumors, and then performing
    precise tumor segmentation.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 早期尝试如[[141](#bib.bib141)]和[[142](#bib.bib142)]适应了多任务学习的理念，将脑肿瘤分割任务拆分为三个不同的子区域分割任务，即分别分割整个肿瘤、肿瘤核心和增强肿瘤。在[[141](#bib.bib141)]中，作者将三个子区域分割任务纳入了一个端到端的整体网络，并利用了这三个子区域分割任务之间的内在相关性。在[[142](#bib.bib142)]中，作者设计了三种不同的损失函数，对应于整个肿瘤、肿瘤核心和增强肿瘤的分割损失。此外，最近的工作引入了与图像分割不同的辅助任务。其他任务中学习到的特征将支持准确的分割。在[[102](#bib.bib102)]中，作者额外引入了边界定位任务。共享编码器提取的特征不仅适用于肿瘤分割，还适用于肿瘤边界定位。精确的边界定位可以帮助减少搜索空间，并在肿瘤分割过程中定义精确的边界。[[143](#bib.bib143)]
    引入了先检测再分割的思想，即检测肿瘤的位置，然后进行精确的肿瘤分割。
- en: Another commonly used auxiliary task is to reconstruct the input data, that
    is, the learnt feature representation can be restored to the original input by
    an auxiliary decoder. [[47](#bib.bib47)] is the first method to introduce reconstruction
    as an auxiliary task to brain tumor segmentation. [[144](#bib.bib144)] introduced
    two auxiliary tasks, reconstruction and enhancement, to further enhance the ability
    of feature representation. [[145](#bib.bib145)] introduced three auxiliary tasks,
    including reconstruction, edge segmentation and patch comparison. These works
    regard the auxiliary task as a regularization to the main brain tumor segmentation
    task. Most multi-task designs use shared encoder to extract features and independent
    decoders to process different tasks. From the perspective of parameter update,
    the role of auxiliary task is to further regularize shared encoder’s parameter.
    Different from L1 or L2 that explicitly regularize parameter numbers and values,
    the auxiliary task shared low-level sub-space with main task. During training,
    auxiliary task is helpful for the network to train in the direction that simultaneously
    optimize the auxiliary task and the main segmentation task, which reduces the
    search space of the parameters, makes the extracted features more generalized
    for accurate segmentation [[146](#bib.bib146)], [[147](#bib.bib147)], [[148](#bib.bib148)],
    [[149](#bib.bib149)].
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种常用的辅助任务是重建输入数据，即通过辅助解码器可以将学习到的特征表示恢复到原始输入。[[47](#bib.bib47)] 是第一个将重建引入脑肿瘤分割的辅助任务的方法。[[144](#bib.bib144)]
    引入了重建和增强两个辅助任务，以进一步提升特征表示的能力。[[145](#bib.bib145)] 引入了三个辅助任务，包括重建、边缘分割和补丁比较。这些工作将辅助任务视为对主要脑肿瘤分割任务的正则化。大多数多任务设计使用共享编码器来提取特征，并使用独立解码器处理不同的任务。从参数更新的角度来看，辅助任务的作用是进一步正则化共享编码器的参数。与显式正则化参数数量和数值的L1或L2不同，辅助任务与主要任务共享低层次子空间。在训练过程中，辅助任务有助于网络在优化辅助任务和主要分割任务的方向上进行训练，这减少了参数的搜索空间，使提取的特征更加通用，从而实现更精确的分割[[146](#bib.bib146)],
    [[147](#bib.bib147)], [[148](#bib.bib148)], [[149](#bib.bib149)]。
- en: 4.3 Customised Loss Function Driven Approaches
  id: totrans-180
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 定制损失函数驱动的方法
- en: During network training, the gradient is likely dominated by the excessively
    large sample if we use an imbalanced dataset. Therefore, a number of works propose
    a custom loss function to regulate gradients during the training of a brain tumor
    segmentation model. Designing a custom loss function aims to reduce the weights
    of the easy-to-classify samples in the loss function, whilst increasing the weights
    of the hard samples, so that the model is more focused on the samples of a small
    proportion, reducing the impact of imbalanced datasets.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在网络训练过程中，如果使用了不平衡的数据集，梯度可能会被过大的样本主导。因此，许多研究提出了自定义损失函数，以在脑肿瘤分割模型训练期间调节梯度。设计自定义损失函数的目的是减少损失函数中易分类样本的权重，同时增加困难样本的权重，使模型更关注少数样本，从而减少不平衡数据集的影响。
- en: 'Table 3: Comparisons between the methods with the novelty of dealing with the
    imbalance issue. We categorise each method based on its main novel contribution.
    In column Input, ’P’ means the patch and ’I’ means the image. ’Dim’ means the
    dimension of the network. #Nets means the number of the network candidates. In
    column Connection, ’C’ means the cascade connection and ’E’ means the network
    ensemble. In column Task, ’S’ means the segmentation task, ’G’ means the modality
    generation task, ’C’ means the classification task, ’B’ means the boundary segmentation
    task, ’R’ means the input reconstruction task. In column Loss, ’CE’ means the
    cross-entropy loss, ’TV’ means the total variation loss and ’KL’ means the KL-divergence,
    ’CPC’ means the contrastive predictive coding loss. In column Dice and Hausdorff,
    ’WT’ means whole tumor, ’TC’ means tumor core and ’ET’ means enhancing tumor.
    Column Dataset indicates the associated dataset with the reported segmentation
    performance. In column Type, ’CV’ means the cross-validation on BraTS training
    set, ’V’ means the BraTS validation set and ’T’ means the BraTS test set. ’-’
    means the entry was not reported in the original paper.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：处理不平衡问题的方法比较。我们根据每种方法的主要创新贡献对其进行分类。在“输入”列中，“P”表示补丁，“I”表示图像。“维度”表示网络的维度。“网络数量”表示网络候选数量。在“连接方式”列中，“C”表示级联连接，“E”表示网络集成。在“任务”列中，“S”表示分割任务，“G”表示模态生成任务，“C”表示分类任务，“B”表示边界分割任务，“R”表示输入重建任务。在“损失函数”列中，“CE”表示交叉熵损失，“TV”表示总变差损失，“KL”表示KL散度，“CPC”表示对比预测编码损失。在“Dice”和“Hausdorff”列中，“WT”表示整个肿瘤，“TC”表示肿瘤核心，“ET”表示增强肿瘤。“数据集”列指示报告的分割性能相关数据集。在“类型”列中，“CV”表示在BraTS训练集上的交叉验证，“V”表示BraTS验证集，“T”表示BraTS测试集。“-”表示原文中未报告的条目。
- en: '| Methods | Input | Dim | #Nets | Connection | Task | Loss | Dice | Hausdorff
    | Dataset |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 输入 | 维度 | 网络数量 | 连接方式 | 任务 | 损失函数 | Dice | Hausdorff | 数据集 |'
- en: '| WT | TC | ET | WT | TC | ET | Year | Type |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| WT | TC | ET | WT | TC | ET | Year | Type |'
- en: '| Multi Networks Driven Approaches | [[46](#bib.bib46)] | P | 3D | 3 | C |
    S | Dice | 0.9 | 0.84 | 0.78 | 3.89 | 6.48 | 3.28 | 2017 | V |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 多网络驱动的方法 | [[46](#bib.bib46)] | P | 3D | 3 | C | S | Dice | 0.9 | 0.84 |
    0.78 | 3.89 | 6.48 | 3.28 | 2017 | V |'
- en: '|  | [[113](#bib.bib113)] | P | 3D | 5 | C+E | S | Focal | 0.9 | 0.84 | 0.77
    | 5.18 | 6.28 | 3.51 | 2018 | V |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | [[113](#bib.bib113)] | P | 3D | 5 | C+E | S | Focal | 0.9 | 0.84 | 0.77
    | 5.18 | 6.28 | 3.51 | 2018 | V |'
- en: '|  | [[112](#bib.bib112)] | I | 2D | 2 | E | S | - | 0.86 | 0.73 | 0.72 | 7.5
    | 9.5 | 5.7 | 2018 | V |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '|  | [[112](#bib.bib112)] | I | 2D | 2 | E | S | - | 0.86 | 0.73 | 0.72 | 7.5
    | 9.5 | 5.7 | 2018 | V |'
- en: '|  | [[124](#bib.bib124)] | I | 3D | 2 | C | S | Dice + CE | 0.91 | 0.85 |
    0.79 | 4.18 | 4.97 | 26.57 | 2020 | V |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '|  | [[124](#bib.bib124)] | I | 3D | 2 | C | S | Dice + CE | 0.91 | 0.85 |
    0.79 | 4.18 | 4.97 | 26.57 | 2020 | V |'
- en: '|  | [[114](#bib.bib114)] | I | 3D | 5 | C+E | S | Dice | 0.88 | 0.79 | 0.72
    | 29.21 | 11.06 | 7.93 | 2018 | V |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '|  | [[114](#bib.bib114)] | I | 3D | 5 | C+E | S | Dice | 0.88 | 0.79 | 0.72
    | 29.21 | 11.06 | 7.93 | 2018 | V |'
- en: '|  | [[127](#bib.bib127)] | I | 3D | 3 | C | S | Dice | 0.9 | 0.81 | 0.78 |
    4.32 | 6.28 | 3.7 | 2019 | V |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | [[127](#bib.bib127)] | I | 3D | 3 | C | S | Dice | 0.9 | 0.81 | 0.78 |
    4.32 | 6.28 | 3.7 | 2019 | V |'
- en: '|  | [[44](#bib.bib44)] | I | 3D | 2 | C | S | Dice | 0.91 | 0.86 | 0.8 | 4.26
    | 5.43 | 3.14 | 2019 | V |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '|  | [[44](#bib.bib44)] | I | 3D | 2 | C | S | Dice | 0.91 | 0.86 | 0.8 | 4.26
    | 5.43 | 3.14 | 2019 | V |'
- en: '|  | [[128](#bib.bib128)] | I | 2D | 2 | C | G+S | L1+TV | - | - | - | - |
    - | - | - | - |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | [[128](#bib.bib128)] | I | 2D | 2 | C | G+S | L1+TV | - | - | - | - |
    - | - | - | - |'
- en: '|  | [[129](#bib.bib129)] | I | 3D | 2 | C | G+S | L2+Dice | 0.89 | 0.79 |
    0.75 | 6.39 | 14.07 | 36 | 2020 | V |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '|  | [[129](#bib.bib129)] | I | 3D | 2 | C | G+S | L2+Dice | 0.89 | 0.79 |
    0.75 | 6.39 | 14.07 | 36 | 2020 | V |'
- en: '|  | [[45](#bib.bib45)] | I | 3D | 3 | E | S | CE+IoU | 0.9 | 0.8 | 0.74 |
    4.23 | 6.56 | 4.5 | 2017 | V |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | [[45](#bib.bib45)] | I | 3D | 3 | E | S | CE+IoU | 0.9 | 0.8 | 0.74 |
    4.23 | 6.56 | 4.5 | 2017 | V |'
- en: '|  | [[133](#bib.bib133)] | I | 3D | 3 | E | S | Dice+CE | 0.9 | 0.84 | 0.76
    | - | - | - | 2019 | V |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '|  | [[133](#bib.bib133)] | I | 3D | 3 | E | S | Dice+CE | 0.9 | 0.84 | 0.76
    | - | - | - | 2019 | V |'
- en: '|  | [[135](#bib.bib135)] | P | 2D | 3 | E | S | - | 0.89 | 0.79 | 0.75 | -
    | - | - | 2017 | V |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | [[135](#bib.bib135)] | P | 2D | 3 | E | S | - | 0.89 | 0.79 | 0.75 | -
    | - | - | 2017 | V |'
- en: '|  | [[136](#bib.bib136)] | P | 2D | 4 | E | S | Dice+CE | 0.89 | 0.77 | 0.77
    | 4.4 | 15.3 | 29.4 | 2020 | V |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | [[136](#bib.bib136)] | P | 2D | 4 | E | S | Dice+CE | 0.89 | 0.77 | 0.77
    | 4.4 | 15.3 | 29.4 | 2020 | V |'
- en: '|  | [[139](#bib.bib139)] | I | 2D | 3 | C | S+C | Dice | 0.85 | 0.7 | 0.65
    | 25.24 | 21.45 | 17.98 | 2017 | V |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  | [[139](#bib.bib139)] | I | 2D | 3 | C | S+C | Dice | 0.85 | 0.7 | 0.65
    | 25.24 | 21.45 | 17.98 | 2017 | V |'
- en: '|  | [[140](#bib.bib140)] | P | 2D | 3 | C | S | CE | 0.91 | 0.81 | 0.76 |
    4.34 | 9.39 | 27.16 | 2020 | V |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  | [[140](#bib.bib140)] | P | 2D | 3 | C | S | CE | 0.91 | 0.81 | 0.76 |
    4.34 | 9.39 | 27.16 | 2020 | V |'
- en: '| Multi Tasks Driven Approaches | [[141](#bib.bib141)] | P | 3D | 2 | C+E |
    S+C | - | 0.91 | 0.86 | 0.81 | 4.17 | 6.54 | 2.71 | 2018 | V |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 多任务驱动的方法 | [[141](#bib.bib141)] | P | 3D | 2 | C+E | S+C | - | 0.91 | 0.86
    | 0.81 | 4.17 | 6.54 | 2.71 | 2018 | V |'
- en: '|  | [[130](#bib.bib130)] | - | - | 1 | - | S+Sim | CE+Focal | 0.85 | 0.68
    | 0.58 | - | - | - | 2015 | V |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '|  | [[130](#bib.bib130)] | - | - | 1 | - | S+Sim | CE+Focal | 0.85 | 0.68
    | 0.58 | - | - | - | 2015 | V |'
- en: '|  | [[142](#bib.bib142)] | I | 2D | 1 | - | S | CE | 0.88 | 0.71 | 0.73 |
    - | - | - | 2015 | T |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | [[142](#bib.bib142)] | I | 2D | 1 | - | S | CE | 0.88 | 0.71 | 0.73 |
    - | - | - | 2015 | T |'
- en: '|  | [[102](#bib.bib102)] | I | 2D | 1 | - | S+B | CE | 0.89 | 0.72 | 0.73
    | - | - | - | 2015 | T |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | [[102](#bib.bib102)] | I | 2D | 1 | - | S+B | CE | 0.89 | 0.72 | 0.73
    | - | - | - | 2015 | T |'
- en: '|  | [[47](#bib.bib47)] | I | 3D | 10 | E | S+R | Dice+L2+KL | 0.91 | 0.87
    | 0.82 | 4.52 | 6.85 | 3.92 | 2018 | V |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  | [[47](#bib.bib47)] | I | 3D | 10 | E | S+R | Dice+L2+KL | 0.91 | 0.87
    | 0.82 | 4.52 | 6.85 | 3.92 | 2018 | V |'
- en: '|  | [[144](#bib.bib144)] | P | 3D | 1 | - | S+R+C | Dice+L2+KL | 0.85 | 0.78
    | 0.75 | 7.98 | 8.25 | 5.76 | 2019 | V |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '|  | [[144](#bib.bib144)] | P | 3D | 1 | - | S+R+C | Dice+L2+KL | 0.85 | 0.78
    | 0.75 | 7.98 | 8.25 | 5.76 | 2019 | V |'
- en: '|  | [[145](#bib.bib145)] | I | 3D | 1 | - | S+R+B | L2+KL+Dice+CE+CPC | 0.92
    | 0.88 | 0.88 | 12.4 | 16.09 | 8.71 | 2017 | Sub |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | [[145](#bib.bib145)] | I | 3D | 1 | - | S+R+B | L2+KL+Dice+CE+CPC | 0.92
    | 0.88 | 0.88 | 12.4 | 16.09 | 8.71 | 2017 | Sub |'
- en: '| Customized Loss Function Driven Approaches | [[150](#bib.bib150)] | P | 2D
    | 1 | - | S | L1+L2+CE | 0.87 | 0.75 | 0.71 | - | - | - | 2016 | T |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 定制损失函数驱动的方法 | [[150](#bib.bib150)] | P | 2D | 1 | - | S | L1+L2+CE | 0.87
    | 0.75 | 0.71 | - | - | - | 2016 | T |'
- en: '|  | [[67](#bib.bib67)] | I | 2D | 1 | - | S | Dice | 0.88 | 0.8 | 0.76 | 6.49
    | 6.68 | 21.39 | 2020 | V |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | [[67](#bib.bib67)] | I | 2D | 1 | - | S | Dice | 0.88 | 0.8 | 0.76 | 6.49
    | 6.68 | 21.39 | 2020 | V |'
- en: '|  | [[143](#bib.bib143)] | I | 3D | 10 | E | S | Dice+Focal+CE | 0.9 | 0.84
    | 0.78 | 5.68 | 9.57 | 24.02 | 2020 | V |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | [[143](#bib.bib143)] | I | 3D | 10 | E | S | Dice+Focal+CE | 0.9 | 0.84
    | 0.78 | 5.68 | 9.57 | 24.02 | 2020 | V |'
- en: '|  | [[104](#bib.bib104)] | I | 3D | 1 | - | S | Dice | 0.9 | 0.8 | 0.73 |
    7 | 9.48 | 4.55 | 2017 | V |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | [[104](#bib.bib104)] | I | 3D | 1 | - | S | Dice | 0.9 | 0.8 | 0.73 |
    7 | 9.48 | 4.55 | 2017 | V |'
- en: '|  | [[85](#bib.bib85)] | I | 3D | 1 | - | S | CE | 0.9 | 0.75 | 0.71 | 4.16
    | 8.65 | 6.98 | 2017 | V |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | [[85](#bib.bib85)] | I | 3D | 1 | - | S | CE | 0.9 | 0.75 | 0.71 | 4.16
    | 8.65 | 6.98 | 2017 | V |'
- en: '|  | [[72](#bib.bib72)] | I | 3D | 1 | - | S | Dice+Edge+Mask | 0.9 | 0.82
    | 0.78 | 5.41 | 7.26 | 5.282 | 2019 | V |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '|  | [[72](#bib.bib72)] | I | 3D | 1 | - | S | Dice+Edge+Mask | 0.9 | 0.82
    | 0.78 | 5.41 | 7.26 | 5.282 | 2019 | V |'
- en: '|  | [[151](#bib.bib151)] | I | 2D | 5 | E | S | Dice | 0.92 | 0.88 | 0.87
    | 4.23 | 5.77 | 8.18 | 2019 | V |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | [[151](#bib.bib151)] | I | 2D | 5 | E | S | Dice | 0.92 | 0.88 | 0.87
    | 4.23 | 5.77 | 8.18 | 2019 | V |'
- en: Early research works tend to uses the standard loss functions, e.g. categorical
    cross-entropy [[39](#bib.bib39)], cross-entropy [[152](#bib.bib152)], and dice
    loss [[153](#bib.bib153)]. [[150](#bib.bib150)] is the first attempt to customise
    the loss function. In [[150](#bib.bib150)], the authors enhance the loss function
    to give more weights to the edge pixels, which significantly improve segmentation
    accuracy at classifying tumor boundaries. Experimental results show that the weighted
    loss function for edge pixels helps to improve the performance of segmentation
    dice by $2-4\%$. Later on, [[102](#bib.bib102)] proposed a customised cross-entropy
    loss for boundary pixels while using an auxiliary task that includes boundary
    localisation. In [[128](#bib.bib128)], the reconstruction task is adopted as regularisation,
    so the loss function aims at improving pixel-wise reconstruction accuracy. In
    [[67](#bib.bib67)], the space loss function was designed to ensure that the learnt
    features can keep spatial information as much as possible. [[143](#bib.bib143)]
    further used a focal loss to deal with imbalanced issues. [[104](#bib.bib104)]
    used a multi-class dice loss, that is, the smaller the proportion of the category,
    the higher the error weight during back-propagation. In [[85](#bib.bib85)], a
    multi-scale loss function was added to perform in-depth supervision on the features
    of different scales at each stage of the encoder, helping the network to learn
    the features in multi-scale resolutions that are more conducive to object segmentation.
    In [[112](#bib.bib112)], from the perspective of a modal, two types of losses
    were designed for T1ce and Flair respectively. [[72](#bib.bib72)] proposed a weighted
    combination of the dice loss, the edge loss and the mask loss. The result shows
    that the combined losses can improve dice performance by about $2\%$. [[151](#bib.bib151)]
    also proposed a combination loss set, which includes the categotical cross-entropy
    and the soft dice loss.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 早期研究工作倾向于使用标准损失函数，例如分类交叉熵[[39](#bib.bib39)]、交叉熵[[152](#bib.bib152)]和骰子损失[[153](#bib.bib153)]。[[150](#bib.bib150)]是首次尝试定制损失函数。在[[150](#bib.bib150)]中，作者增强了损失函数，为边缘像素赋予更多权重，这显著提高了肿瘤边界分类的分割精度。实验结果表明，边缘像素的加权损失函数有助于提高分割骰子系数约$2-4\%$。随后，[[102](#bib.bib102)]提出了一种针对边界像素的定制交叉熵损失，同时使用了包括边界定位的辅助任务。在[[128](#bib.bib128)]中，重建任务被作为正则化方法，以提高像素级重建精度。在[[67](#bib.bib67)]中，空间损失函数被设计用于确保学习到的特征尽可能保留空间信息。[[143](#bib.bib143)]进一步使用了焦点损失来处理不平衡问题。[[104](#bib.bib104)]使用了多类别骰子损失，即类别比例越小，反向传播时的错误权重越高。在[[85](#bib.bib85)]中，添加了一种多尺度损失函数，对编码器每个阶段不同尺度的特征进行深入监督，帮助网络学习更有利于物体分割的多尺度分辨率特征。在[[112](#bib.bib112)]中，从模态的角度来看，为T1ce和Flair分别设计了两种损失类型。[[72](#bib.bib72)]提出了一种加权组合骰子损失、边缘损失和掩码损失的方案。结果表明，组合损失可以将骰子系数提升约$2\%$。[[151](#bib.bib151)]还提出了一组组合损失，包括分类交叉熵和软骰子损失。
- en: '![Refer to caption](img/0d11892e9d118d12f0fe01688e4b8e62.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0d11892e9d118d12f0fe01688e4b8e62.png)'
- en: 'Figure 11: The illustration of cross-modality feature learning framework. Image
    courtesy from [[154](#bib.bib154)].'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '图 11: 跨模态特征学习框架的插图。图片来自[[154](#bib.bib154)]。'
- en: 4.3.1 Summary
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1 摘要
- en: 'Table [3](#S4.T3 "Table 3 ‣ 4.3 Customised Loss Function Driven Approaches
    ‣ 4 Segmentation under Imbalanced Condition ‣ Deep Learning Based Brain Tumor
    Segmentation: A Survey") shows the results generated by methods focused on dealing
    with data imbalance in brain tumor segmentation. From the above comparison, we
    can find several interesting observations.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 表[3](#S4.T3 "表 3 ‣ 4.3 定制损失函数驱动的方法 ‣ 4 在不平衡条件下的分割 ‣ 基于深度学习的脑肿瘤分割：综述")展示了专注于处理脑肿瘤分割中数据不平衡的方法生成的结果。从上述比较中，我们可以发现几个有趣的观察。
- en: '1.'
  id: totrans-219
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: From the perspective of the network, the strategy to solve the imbalance problem
    is mainly to combine the output of multiple networks. Commonly used combination
    methods include network cascade and network ensemble. But these strategies all
    depend on the performance of each network. The consumption of the computing resources
    is also increased proportionally to the number of the network candidates.
  id: totrans-220
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从网络的角度来看，解决不平衡问题的策略主要是结合多个网络的输出。常用的组合方法包括网络级联和网络集成。但这些策略都依赖于每个网络的性能。计算资源的消耗也会随着网络候选数量的增加而成比例增加。
- en: '2.'
  id: totrans-221
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: From the perspective of a task, the strategy to solve the imbalance problem
    is to set up auxiliary tasks for the regulating networks so that the networks
    can make full use of the existing data and learn more generalised features that
    are beneficial to the auxiliary tasks as well as the segmentation task.
  id: totrans-222
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从任务的角度来看，解决不平衡问题的策略是为调节网络设置辅助任务，以便网络可以充分利用现有数据，并学习对辅助任务以及分割任务有益的更一般化特征。
- en: '3.'
  id: totrans-223
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: From the perspective of the loss function, the strategy to solve the imbalance
    problem is to use a custom loss function or an auxiliary loss function. By weighting
    the hard samples, the networks are regulated to pay more attention to the small
    data.
  id: totrans-224
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从损失函数的角度来看，解决不平衡问题的策略是使用自定义损失函数或辅助损失函数。通过对困难样本加权，网络被调节以更多关注小数据。
- en: 5 Utilising Multi Modality Information
  id: totrans-225
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 利用多模态信息
- en: 'Multi-modality imaging has played a key role in medical image analysis and
    applications. Different modalities of MRI emphasise on different tissues. Effective
    use of multi-modality information is one of the key factors in MRI-based brain
    tumor segmentation. According to the number of the available modalities, we divide
    the multi-modality brain tumor segmentation into two scenes: leveraging information
    based on multiple modalities and limited information processing with missing modality.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 多模态成像在医学图像分析和应用中发挥了关键作用。不同模态的MRI强调不同的组织。有效利用多模态信息是基于MRI的脑肿瘤分割的关键因素之一。根据可用模态的数量，我们将多模态脑肿瘤分割分为两种场景：利用多模态信息和处理缺失模态的有限信息。
- en: '![Refer to caption](img/7280dde4d22c9093d30974a7458c26a1.png)'
  id: totrans-227
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7280dde4d22c9093d30974a7458c26a1.png)'
- en: 'Figure 12: The structure of the modality-aware feature embedding module. Image
    courtesy of [[50](#bib.bib50)].'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：模态感知特征嵌入模块的结构。图片来自[[50](#bib.bib50)]。
- en: 5.1 Learning with multiple modalities
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 多模态学习
- en: 'In this paper, we follow the BraTS competition standard, that is, multi-modality
    refers the input data modalities include but not limit to T1, T1ce, T2, and Flair.
    In order to effectively use multi-modality information, existing works focus on
    effectively learning multi-modality information. The designed learning methods
    can be classified into three categories based on their purposes: Learning to Rank,
    Learning to Pair and Learning to Fuse.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们遵循BraTS竞赛标准，即多模态指输入数据模态包括但不限于T1、T1ce、T2和Flair。为了有效利用多模态信息，现有工作集中于有效学习多模态信息。根据其目的，设计的学习方法可以分为三类：学习排序、学习配对和学习融合。
- en: 'Learning to Rank Modalities In multi-modality processing, the existing data
    modality is sorted by relevance based on the learning task, so that the network
    can focus on learning the modality with high relevance. This definition can be
    re-named as modality-task modeling. Early work from [[82](#bib.bib82)] can be
    treated as basic learning to rank formation. In [[82](#bib.bib82)], the author
    transformed each modality to a single CNN. In [[82](#bib.bib82)], each CNN corresponds
    to a different modality and the features extracted by CNN are independent of each
    other. The loss returned by the final classifier is similar to the scoring of
    the input data and the segmentation is undertaken according to the score. A similar
    processing method was used in [[50](#bib.bib50)]. For each of the two modalities,
    two independent networks were used for modeling relationship matching, and the
    parameters of each network are affected by the influence of different supervision
    losses. [[154](#bib.bib154)] extracted features of different embedding modalities
    (as shown in Fig. [11](#S4.F11 "Figure 11 ‣ 4.3 Customised Loss Function Driven
    Approaches ‣ 4 Segmentation under Imbalanced Condition ‣ Deep Learning Based Brain
    Tumor Segmentation: A Survey")), modeled the relationship between the modalities
    and the segmentation of different tumor sub-regions, so that the data of different
    modalities were weighted and sorted corresponding to individual tasks.'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 学习排序模态 在多模态处理过程中，现有的数据模态根据学习任务的相关性进行排序，以便网络能够集中学习高相关性的模态。这个定义可以重新命名为模态-任务建模。早期的工作来自于[[82](#bib.bib82)]，可以视为基本的学习排序形成。在[[82](#bib.bib82)]中，作者将每个模态转换为一个单独的CNN。在[[82](#bib.bib82)]中，每个CNN对应一个不同的模态，并且CNN提取的特征彼此独立。最终分类器返回的损失类似于输入数据的评分，分割则根据评分进行。[[50](#bib.bib50)]中使用了类似的处理方法。对于两个模态，使用了两个独立的网络进行关系匹配建模，每个网络的参数受到不同监督损失的影响。[[154](#bib.bib154)]提取了不同嵌入模态的特征（如图
    [11](#S4.F11 "图 11 ‣ 4.3 定制损失函数驱动方法 ‣ 4 不平衡条件下的分割 ‣ 基于深度学习的脑肿瘤分割：综述")所示），建模了模态之间的关系和不同肿瘤子区域的分割，使得不同模态的数据按照单独任务加权和排序。
- en: '![Refer to caption](img/c5b23622459730840bab85ecf48c8a34.png)'
  id: totrans-232
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c5b23622459730840bab85ecf48c8a34.png)'
- en: 'Figure 13: The structure of the modality correlation module. Image courtesy
    of [[80](#bib.bib80)].'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：模态相关模块的结构。图片来源于[[80](#bib.bib80)]。
- en: Learning to Pair Modalities Learning to rank modalities refers to the sorting
    of the modality-task relation for a certain segmentation task. Another commonly
    used modeling is the modality-modality pairing, which selects the best combination
    from multi-modality data to achieve precise segmentation. [[155](#bib.bib155)]
    is one of the early works to model the modality-modality relationship. The authors
    paired every two modalities and sent all the pairing combinations to the downstream
    network. [[154](#bib.bib154)] further strengthens the modality-modality pairing
    relationship through the cross-modal feature transition module and the modal pairing
    module. In the cross-modality feature transition module, the authors converted
    the input and output from one modality’s data to the concatenation of a modality
    pair. In the cross-modality feature fusion module, the authors converted the single-modality
    feature learning to the single-modality-pair feature learning, which predicts
    the segmentation masks of each single-modality-pair.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 学习配对模态 学习排序模态指的是针对某个分割任务对模态-任务关系进行排序。另一种常用的建模方法是模态-模态配对，它从多模态数据中选择最佳组合以实现精确分割。[[155](#bib.bib155)]是早期建模模态-模态关系的工作之一。作者对每两个模态进行了配对，并将所有配对组合发送到下游网络。[[154](#bib.bib154)]通过跨模态特征转换模块和模态配对模块进一步加强了模态-模态配对关系。在跨模态特征转换模块中，作者将输入和输出从一个模态的数据转换为模态对的拼接。在跨模态特征融合模块中，作者将单模态特征学习转换为单模态对特征学习，以预测每个单模态对的分割掩码。
- en: Learning to Fuse Modalities More recent works focus on learning to fuse multi-modality.
    Different from the modality ranking and pairing, modality fusion is to fuse features
    from each modality for accurate segmentation. The early fusion method is relatively
    simple, usually concatenates or adds features learned from different modalities.
    In [[82](#bib.bib82)], the authors used 4 networks to extract features from each
    modality and concatenates the extracted modality aware features. The features
    after concatenation are sent to Random Forest to classify the central pixel of
    the input patch. In [[112](#bib.bib112)], features from T1ce and Flair were added
    and sent to the downstream network for entire tumor segmentation. Similarly, in
    [[154](#bib.bib154)], modality aware feature extraction is performed and sent
    to the downstream network for further learning. These two fusion methods do not
    introduce additional parameters and are very simple and efficient. In [[154](#bib.bib154)],
    even though the authors fused the features from more complex cross-modal feature
    pairing and single-modal feature pairing modules. In addition, there are other
    works such as [[152](#bib.bib152)] and [[155](#bib.bib155)] that used additional
    convolutional modules to combine and learn features from different modalities
    so as to accomplish modality fusion.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 学习融合模态 更近期的研究工作集中于学习融合多模态。与模态排序和配对不同，模态融合是将来自每个模态的特征融合以实现准确的分割。早期的融合方法相对简单，通常是连接或加法处理来自不同模态的特征。在
    [[82](#bib.bib82)] 中，作者使用了 4 个网络来提取每个模态的特征，并连接提取到的模态感知特征。连接后的特征被送入随机森林以对输入补丁的中心像素进行分类。在
    [[112](#bib.bib112)] 中，将 T1ce 和 Flair 的特征进行了加法处理，并将结果发送到下游网络进行整个肿瘤的分割。同样，在 [[154](#bib.bib154)]
    中，进行了模态感知特征提取并将其送到下游网络进行进一步学习。这两种融合方法没有引入额外的参数，非常简单高效。在 [[154](#bib.bib154)] 中，尽管作者融合了来自更复杂的跨模态特征配对和单模态特征配对模块的特征。此外，还有其他工作如
    [[152](#bib.bib152)] 和 [[155](#bib.bib155)] 使用了额外的卷积模块来结合和学习来自不同模态的特征，以实现模态融合。
- en: Although concatenation and addition are used, these two fusion methods do not
    change the semantics of learned features and cannot highlight or suppress features.
    To tackling this problem, many research works in recent years have adopted attention
    mechanisms to strengthen the learnt features. [[65](#bib.bib65)], [[67](#bib.bib67)],
    [[66](#bib.bib66)] and [[68](#bib.bib68)] used a spatial and channel attention
    based fusion module. The proposed attention mechanism highlights useful features
    and suppresses redundant features, resulting in accurate segmentation.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管连接和加法被使用，这两种融合方法并不会改变学习到的特征的语义，也不能突出或抑制特征。为了解决这个问题，近年来许多研究工作采用了注意力机制来增强学习到的特征。[[65](#bib.bib65)]、[[67](#bib.bib67)]、[[66](#bib.bib66)]
    和 [[68](#bib.bib68)] 使用了基于空间和通道的注意力融合模块。所提出的注意力机制能够突出有用的特征并抑制冗余特征，从而实现准确的分割。
- en: 'Table 4: Comparison between the methods with the novelty of learning with multi-modality.
    We categorise each method based on its main novel contribution. In column Input,
    ’P’ means the patch and ’I’ means the image. ’Dim’ means the dimension of the
    network. Column ’Learning To’ means the learning task of multi-modality, where
    ’R’ means learning to rank, ’P’ means learning to pair, ’F’ means learning to
    fuse, ’G’ means learning to generate missing modality, ’Fw/M’ means fuse with
    missing modalities. In column Fusion, ’Concate’ means concatenation, ’Conv’ means
    the convolution module, ’Add’ mean addition, ’S Att’ means spatial attention,
    ’C Att’ means channel attention. In column Task, ’S’ means segmentation task,
    ’G’ means modality generation task. In column Loss, ’CE’ means cross-entropy loss,
    ’Adv’ means adversarial loss, ’CC’ means cycle consistency loss and ’MAE’ means
    mean absolute square loss. In column Dice and Hausdorff, ’WT’ means whole tumor,
    ’TC’ means tumor core and ’ET’ means enhancing tumor. Column Dataset indicates
    the associated dataset with the reported segmentation performance. In column Type,
    ’CV’ means cross-validation on the BraTS training set, ’V’ means the BraTS validation
    set and ’Sub’ means the manually divided subset from training set. ’-’ means the
    entry was not reported in the original paper.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 表4：多模态学习方法的比较。我们根据每种方法的主要新颖贡献进行分类。在输入列中，'P' 表示补丁，'I' 表示图像。'Dim' 表示网络的维度。列 'Learning
    To' 表示多模态的学习任务，其中 'R' 表示学习排序，'P' 表示学习配对，'F' 表示学习融合，'G' 表示学习生成缺失模态，'Fw/M' 表示与缺失模态融合。在融合列中，'Concate'
    表示拼接，'Conv' 表示卷积模块，'Add' 表示加法，'S Att' 表示空间注意力，'C Att' 表示通道注意力。在任务列中，'S' 表示分割任务，'G'
    表示模态生成任务。在损失列中，'CE' 表示交叉熵损失，'Adv' 表示对抗损失，'CC' 表示循环一致性损失，'MAE' 表示平均绝对误差损失。在 Dice
    和 Hausdorff 列中，'WT' 表示整个肿瘤，'TC' 表示肿瘤核心，'ET' 表示增强肿瘤。数据集列表示与报告的分割性能相关的数据集。在类型列中，'CV'
    表示在 BraTS 训练集上的交叉验证，'V' 表示 BraTS 验证集，'Sub' 表示从训练集中手动划分的子集。'-' 表示原始论文中未报告的条目。
- en: '| Methods | Input | Dim | Learning To | Fusion | Task | Loss | Dice | Hausdorff
    | Dataset |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 输入 | 维度 | 学习目标 | 融合 | 任务 | 损失 | Dice | Hausdorff | 数据集 |'
- en: '| WT | TC | ET | WT | TC | ET | Year | Type |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| WT | TC | ET | WT | TC | ET | 年份 | 类型 |'
- en: '| Learning with Complete Modalities | [[82](#bib.bib82)] | P | 2D | R+F | Concate
    | S | - | - | - | - | - | - | - | - | - |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 使用完整模态学习 | [[82](#bib.bib82)] | P | 2D | R+F | Concate | S | - | - | - |
    - | - | - | - | - |'
- en: '|  | [[152](#bib.bib152)] | I | 2D | F | Conv | S | CE | 0.85 | 0.68 | 0.69
    | - | - | - | 2015 | V |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  | [[152](#bib.bib152)] | I | 2D | F | Conv | S | CE | 0.85 | 0.68 | 0.69
    | - | - | - | 2015 | V |'
- en: '|  | [[155](#bib.bib155)] | I | 2D | P+F | Conv | S | Focal | 0.88 | 0.71 |
    0.75 |  |  |  | 2017 | V |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  | [[155](#bib.bib155)] | I | 2D | P+F | Conv | S | Focal | 0.88 | 0.71 |
    0.75 |  |  |  | 2017 | V |'
- en: '|  | [[112](#bib.bib112)] | I | 2D | F | Add | S | - | 0.86 | 0.73 | 0.72 |
    7.5 | 9.5 | 5.7 | 2018 | V |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | [[112](#bib.bib112)] | I | 2D | F | Add | S | - | 0.86 | 0.73 | 0.72 |
    7.5 | 9.5 | 5.7 | 2018 | V |'
- en: '|  | [[66](#bib.bib66)] | I | 2D | F | S Att + C Att | S | Dice | - | - | -
    | - | - | - | - | - |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  | [[66](#bib.bib66)] | I | 2D | F | S Att + C Att | S | Dice | - | - | -
    | - | - | - | - | - |'
- en: '|  | [[65](#bib.bib65)] | P | 3D | F | S Att + C Att | S | - | 0.9 | 0.79 |
    0.7 | 6.29 | 8.76 | 7.05 | 2019 | V |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  | [[65](#bib.bib65)] | P | 3D | F | S Att + C Att | S | - | 0.9 | 0.79 |
    0.7 | 6.29 | 8.76 | 7.05 | 2019 | V |'
- en: '|  | [[67](#bib.bib67)] | I | 2D | F | S Att + C Att | S | Dice | 0.88 | 0.8
    | 0.76 | 6.49 | 6.68 | 21.39 | 2020 | V |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  | [[67](#bib.bib67)] | I | 2D | F | S Att + C Att | S | Dice | 0.88 | 0.8
    | 0.76 | 6.49 | 6.68 | 21.39 | 2020 | V |'
- en: '|  | [[50](#bib.bib50)] | P | 3D | R+P+F | Concate + Add | S | Adv+CC | 0.9
    | 0.84 | 0.79 | 5 | 6.37 | 3.99 | 2018 | V |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | [[50](#bib.bib50)] | P | 3D | R+P+F | Concate + Add | S | Adv+CC | 0.9
    | 0.84 | 0.79 | 5 | 6.37 | 3.99 | 2018 | V |'
- en: '|  | [[154](#bib.bib154)] | P | 3D | R+F | Concate | G+S | Dice+T-Test | 0.9
    | 0.82 | 0.78 | 5.73 | 9.27 | 3.57 | 2020 | V |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | [[154](#bib.bib154)] | P | 3D | R+F | Concate | G+S | Dice+T-Test | 0.9
    | 0.82 | 0.78 | 5.73 | 9.27 | 3.57 | 2020 | V |'
- en: '|  | [[68](#bib.bib68)] | I | 3D | F | S Att + C Att | S | Dice | 0.87 | 0.79
    | 0.74 | 7.54 | 7.68 | 6.1 | 2017 | CV |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '|  | [[68](#bib.bib68)] | I | 3D | F | S Att + C Att | S | Dice | 0.87 | 0.79
    | 0.74 | 7.54 | 7.68 | 6.1 | 2017 | CV |'
- en: '| Dealing with Missing Modalities | [[156](#bib.bib156)] | I | 3D | G | - |
    G+S | L1 | 0.68 | 0.72 | - | - | - | - | 2015 | Sub |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 处理缺失模态 | [[156](#bib.bib156)] | I | 3D | G | - | G+S | L1 | 0.68 | 0.72 |
    - | - | - | - | 2015 | Sub |'
- en: '|  | [[80](#bib.bib80)] | I | 3D | Fw/M | S Att + C Att | S | Dice+MAE | 0.87
    | 0.72 | 0.73 | 6.7 | 9.3 | 6.3 | 2019 | V |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '|  | [[80](#bib.bib80)] | I | 3D | Fw/M | S Att + C Att | S | Dice+MAE | 0.87
    | 0.72 | 0.73 | 6.7 | 9.3 | 6.3 | 2019 | V |'
- en: '|  | [[157](#bib.bib157)] | I | 3D | Fw/M | S Att + C Att | S | Dice+MAE |
    0.88 | 0.79 | 0.69 | - | - | - | 2018 | CV |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  | [[157](#bib.bib157)] | I | 3D | Fw/M | S Att + C Att | S | Dice+MAE |
    0.88 | 0.79 | 0.69 | - | - | - | 2018 | CV |'
- en: '|  | [[158](#bib.bib158)] | I | 3D | Fw/M | - | S | - | 0.91 | 0.85 | 0.78
    | 4.46 | 5.26 | 3.69 | 2019 | V |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  | [[158](#bib.bib158)] | I | 3D | Fw/M | - | S | - | 0.91 | 0.85 | 0.78
    | 4.46 | 5.26 | 3.69 | 2019 | V |'
- en: 'Table 5: Opensourced projects from deep learning based brain tumor segmentation.
    where ’3rd Party’ means the code is re-implemented by a third party based on the
    associated paper.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：基于深度学习的脑肿瘤分割开源项目。这里的“第三方”指的是代码由第三方基于相关论文重新实现。
- en: '| Paper Title | Code Link |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 论文标题 | 代码链接 |'
- en: '| --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Brain tumor segmentation with Deep Neural Networks | (3rd Party) https://github.com/naldeborgh7575/
    brain_segmentation |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度神经网络的脑肿瘤分割 | (第三方) https://github.com/naldeborgh7575/brain_segmentation
    |'
- en: '| DeepMedic on Brain Tumor Segmentation | https://github.com/deepmedic/deepmedic
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| DeepMedic 在脑肿瘤分割中的应用 | https://github.com/deepmedic/deepmedic |'
- en: '| Multi-dimensional Gated Recurrent Units for Brain Tumor Segmentation | https://github.com/zubata88/mdgru
    |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 用于脑肿瘤分割的多维门控递归单元 | https://github.com/zubata88/mdgru |'
- en: '| Volumetric Multimodality Neural Network For Brain Tumor Segmentation | https://github.com/BCV-Uniandes/BCVbrats
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 用于脑肿瘤分割的体积多模态神经网络 | https://github.com/BCV-Uniandes/BCVbrats |'
- en: '| Brain Tumor Segmentation and Radiomics Survival Prediction: Contribution
    to the BRATS 2017 Challenge | (3rd Party) https://github.com/pykao/Modified-3D-UNet-Pytorch
    |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 脑肿瘤分割与放射组学生存预测：对 BRATS 2017 挑战的贡献 | (第三方) https://github.com/pykao/Modified-3D-UNet-Pytorch
    |'
- en: '| Residual Encoder and Convolutional Decoder Neural Network for Glioma Segmentation
    | https://github.com/kamleshpawar17/BratsNet-2017 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 用于神经胶质瘤分割的残差编码器和卷积解码器神经网络 | https://github.com/kamleshpawar17/BratsNet-2017
    |'
- en: '| Automatic Brain Tumor Segmentation Using Cascaded Anisotropic Convolutional
    Neural Networks | https://github.com/taigw/brats18_docker |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 使用级联各向异性卷积神经网络的自动脑肿瘤分割 | https://github.com/taigw/brats18_docker |'
- en: '| No New-Net | https://github.com/MIC-DKFZ/nnUNet |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| No New-Net | https://github.com/MIC-DKFZ/nnUNet |'
- en: '| 3D MRI Brain Tumor Segmentation Using Autoencoder Regularization | (3rd Party)
    https://github.com/IAmSuyogJadhav/3d-mri-brain-tumor-segmentation-using-autoencoder-regularization
    |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 使用自编码器正则化的 3D MRI 脑肿瘤分割 | (第三方) https://github.com/IAmSuyogJadhav/3d-mri-brain-tumor-segmentation-using-autoencoder-regularization
    |'
- en: '| 3D-ESPNet with Pyramidal Refinement for Volumetric Brain Tumor Image Segmentation
    | https://github.com/sacmehta/3D-ESPNet |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 带有金字塔细化的 3D-ESPNet 用于体积脑肿瘤图像分割 | https://github.com/sacmehta/3D-ESPNet |'
- en: '| One-pass Multi-task Networks with Cross-task Guided Attention for Brain Tumor
    Segmentation | https://github.com/chenhong-zhou/OM-Net |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 一次性多任务网络与跨任务引导注意力用于脑肿瘤分割 | https://github.com/chenhong-zhou/OM-Net |'
- en: '| Multi-step Cascaded Networks for Brain Tumor Segmentation | https://github.com/JohnleeHIT/Brats2019
    |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 用于脑肿瘤分割的多步级联网络 | https://github.com/JohnleeHIT/Brats2019 |'
- en: '| An Ensemble of 2D Convolutional Neural Network for 3D Brain Tumor Segmentation
    | https://github.com/kamleshpawar17/Brats19 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| 用于 3D 脑肿瘤分割的 2D 卷积神经网络集成 | https://github.com/kamleshpawar17/Brats19 |'
- en: '| Knowledge Distillation for Brain Tumor Segmentation | https://github.com/lachinov/brats2019
    |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 脑肿瘤分割的知识蒸馏 | https://github.com/lachinov/brats2019 |'
- en: '| Label-Efficient Multi-Task Segmentation using Contrastive Learning | https://github.com/pfnet-research/label-efficient-brain-tumor-segmentation
    |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 使用对比学习的标签高效多任务分割 | https://github.com/pfnet-research/label-efficient-brain-tumor-segmentation
    |'
- en: '| Vox2Vox: 3D-GAN for Brain Tumour Segmentation | https://github.com/mdciri/Vox2Vox
    |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| Vox2Vox: 用于脑肿瘤分割的 3D-GAN | https://github.com/mdciri/Vox2Vox |'
- en: '| Brain tumor segmentation with self-ensembled, deeply-supervised 3D U-net
    neural networks: a BraTS 2020 challenge solution. | https://github.com/lescientifik/open_brats2020
    |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| 自我集成、深度监督 3D U-net 神经网络的脑肿瘤分割：BraTS 2020 挑战解决方案。 | https://github.com/lescientifik/open_brats2020
    |'
- en: '| Brain tumour segmentation using a triplanar ensemble of U-Nets on MR images
    | https://git.fmrib.ox.ac.uk/vaanathi/truenet_tumseg |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '| 使用三平面 U-Nets 集成的脑肿瘤分割 | https://git.fmrib.ox.ac.uk/vaanathi/truenet_tumseg
    |'
- en: '| A Two-Stage Cascade Model with Variational Autoencoders and Attention Gates
    for MRI Brain Tumor Segmentation | https://github.com/shu-hai/two-stage-VAE-Attention-gate-BraTS2020
    |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| 带有变分自编码器和注意力门的两阶段级联模型用于 MRI 脑肿瘤分割 | https://github.com/shu-hai/two-stage-VAE-Attention-gate-BraTS2020
    |'
- en: '| HDC-Net: Hierarchical Decoupled Convolution Network for Brain Tumor Segmentation
    | https://github.com/luozhengrong/HDC-Net |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| HDC-Net: 层次化解耦卷积网络用于脑肿瘤分割 | https://github.com/luozhengrong/HDC-Net |'
- en: 5.2 Dealing with Missing Modalities
  id: totrans-277
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 处理缺失模态
- en: 'The modality learning methods mentioned above work in the multi-modality scene.
    For example, in BraTS, we obtain the data of four modalities: T1, T1ce, T2, and
    FLAIR. However, in actual application scenarios, it is very difficult to obtain
    complete and high-quality multi-modality datasets, refers to as missing modality
    scenarios. [[156](#bib.bib156)] is one of the earliest works targeting learning
    under missing modality. The authors in [[156](#bib.bib156)] constructed the only
    available modal T1 and used generative adversarial networks to generate the missed
    modalities. In [[156](#bib.bib156)], the authors used the existing T1 modality
    as input to generate Flair modality. The generated Flair data is sent as a supplement
    with the original T1 data to the downstream segmentation network. [[157](#bib.bib157)],
    [[80](#bib.bib80)] learnt the implicit relationship between modalities and examined
    all possible missing scenarios. The results show that multi-modality have an important
    influence on accurate segmentation. In [[158](#bib.bib158)], the intensity correction
    algorithm was proposed for different scenarios of the single modality input. In
    this framework, the intensity query and correction of the data of multiple modalities
    makes it easier to distinguish the tumor and non-tumor regions in the synthetic
    data.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 上述模态学习方法适用于多模态场景。例如，在BraTS中，我们获取了四种模态的数据：T1、T1ce、T2和FLAIR。然而，在实际应用场景中，获取完整且高质量的多模态数据集非常困难，这被称为缺失模态场景。[[156](#bib.bib156)]
    是最早针对缺失模态学习的研究之一。在 [[156](#bib.bib156)] 中，作者构建了唯一可用的模态 T1，并使用生成对抗网络生成缺失的模态。在 [[156](#bib.bib156)]
    中，作者使用现有的 T1 模态作为输入来生成 Flair 模态。生成的 Flair 数据作为补充，与原始 T1 数据一起送入下游分割网络。[[157](#bib.bib157)]、[[80](#bib.bib80)]
    研究了模态之间的隐含关系，并检查了所有可能的缺失场景。结果表明，多模态对准确分割具有重要影响。在 [[158](#bib.bib158)] 中，提出了针对单一模态输入不同场景的强度校正算法。在该框架中，多模态数据的强度查询和校正使得在合成数据中更容易区分肿瘤和非肿瘤区域。
- en: 5.2.1 Summary
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 总结
- en: 'Table [4](#S5.T4 "Table 4 ‣ 5.1 Learning with multiple modalities ‣ 5 Utilising
    Multi Modality Information ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")
    shows the results generated by methods focused learning with multi-modality in
    deep learning based brain tumor segmentation. We can collect several common observations
    in utilising the information from multi modalities.'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [4](#S5.T4 "Table 4 ‣ 5.1 Learning with multiple modalities ‣ 5 Utilising
    Multi Modality Information ‣ Deep Learning Based Brain Tumor Segmentation: A Survey")
    显示了基于多模态学习的深度学习脑肿瘤分割方法生成的结果。我们可以从利用多模态信息中收集到几个常见的观察结果。'
- en: '1.'
  id: totrans-281
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: For task-modality modeling, learning to rank modalities can help the network
    choose the most relative and conducive modality for accurate segmentation. Most
    of the research works model the implicit ranking while learning the modality aware
    features.
  id: totrans-282
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于任务-模态建模，学习排序模态可以帮助网络选择最相关和有利的模态以进行准确分割。大多数研究工作在学习模态感知特征的过程中对隐含排序进行了建模。
- en: '2.'
  id: totrans-283
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: For modality-modality modeling, learning to pair modalities can help the network
    find the most suitable modality combination for segmentation. However, existing
    pairing works show modality pairs through exhaustive combination with large computing
    resources.
  id: totrans-284
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对于模态-模态建模，学习配对模态可以帮助网络找到最适合分割的模态组合。然而，现有的配对工作通过穷举组合显示模态对，这需要大量计算资源。
- en: '3.'
  id: totrans-285
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: The fusion of multi-modality information can improve the expressive ability
    and generalisation of features. Existing fusion methods have their own advantages
    and disadvantages. Addition or concatenation does not introduce additional parameters,
    but lacks the physical expression of features. Using a small network, an attention
    module can optimise feature expression, but introduce additional parameters and
    computational cost.
  id: totrans-286
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多模态信息的融合可以提高特征的表达能力和泛化能力。现有的融合方法各有优缺点。加法或连接不会引入额外的参数，但缺乏特征的物理表达。使用小型网络，注意力模块可以优化特征表达，但会引入额外的参数和计算成本。
- en: '4.'
  id: totrans-287
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Missing modalities are one of the common scenes in clinical imaging. Existing
    works focus on the perspective of generation, using existing modality data to
    generate missing modalities. However, the performance and quality of the generator
    modal heavily relies on the quality of the existing modality data.
  id: totrans-288
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 缺失模态是临床影像中常见的场景之一。现有的研究主要集中在生成的角度，利用现有模态数据生成缺失的模态。然而，生成器模态的性能和质量在很大程度上依赖于现有模态数据的质量。
- en: 6 Conclusion
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: Applying various deep learning methods to brain tumor segmentation is an invaluable
    and challenging task. Automated image segmentation benefits several aspects due
    to the powerful feature learning ability of deep learning techniques. In this
    paper, we have investigated relevant deep learning based brain tumor segmentation
    methods and presented a comprehensive survey. We structurally categorised and
    summarised the deep learning based brain tumor segmentation methods. We have widely
    investigated this task and discussed several key aspects such as methods’ pros
    and cons, designing motivation and performance evaluation.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 应用各种深度学习方法进行脑肿瘤分割是一项宝贵而具有挑战性的任务。由于深度学习技术强大的特征学习能力，自动图像分割在多个方面受益。本文探讨了相关的深度学习基础脑肿瘤分割方法，并进行了全面的调查。我们系统地分类和总结了深度学习基础脑肿瘤分割方法，广泛研究了这一任务，并讨论了方法的优缺点、设计动机和性能评估等关键方面。
- en: Acknowledgement
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was funded by the Chine Scholarship Council and Graduate Teaching
    Assistantship of University of Leicester. Yaochu Jin is supported by an Alexander
    von Humboldt Professorship endowed by the German Federal Ministry for Education
    and Research. The authors thank Prof. Guotai Wang, Prof. Dingwen Zhang and Dr.
    Tongxue Zhou for their detailed suggestions and discussions.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究由中国奖学金委员会和莱斯特大学研究生教学助理资助。Yaochu Jin 由德国联邦教育和研究部资助的亚历山大·冯·洪堡教授职位支持。作者感谢郭泰王教授、张定文教授和周同学博士的详细建议和讨论。
- en: References
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] K. Doi, Computer-aided diagnosis in medical imaging: historical review,
    current status and future potential, Computerized medical imaging and graphics
    31 (4-5) (2007) 198–211.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] K. Doi，《医学影像中的计算机辅助诊断：历史回顾、现状和未来潜力》，《计算机化医学影像与图形》31 (4-5) (2007) 198–211。'
- en: '[2] M. Lavin, M. Nathan, System and method for managing patient medical records,
    uS Patent 5,772,585 (Jun. 30 1998).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] M. Lavin, M. Nathan，《管理病人医疗记录的系统和方法》，美国专利 5,772,585（1998年6月30日）。'
- en: '[3] R. H. Taylor, A. Menciassi, G. Fichtinger, P. Fiorini, P. Dario, Medical
    robotics and computer-integrated surgery, in: Springer handbook of robotics, Springer,
    2016, pp. 1657–1684.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] R. H. Taylor, A. Menciassi, G. Fichtinger, P. Fiorini, P. Dario，《医学机器人和计算机集成手术》，见：《施普林格机器人手册》，施普林格，2016年，第1657–1684页。'
- en: '[4] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. van der Laak, B. Van Ginneken, C. I. Sánchez, A survey on deep learning
    in medical image analysis, Medical image analysis 42 (2017) 60–88.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. van der Laak, B. Van Ginneken, C. I. Sánchez，《医学图像分析中的深度学习调查》，《医学图像分析》42
    (2017) 60–88。'
- en: '[5] D. N. Louis, A. Perry, G. Reifenberger, A. Von Deimling, D. Figarella-Branger,
    W. K. Cavenee, H. Ohgaki, O. D. Wiestler, P. Kleihues, D. W. Ellison, The 2016
    world health organization classification of tumors of the central nervous system:
    a summary, Acta neuropathologica 131 (6) (2016) 803–820.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] D. N. Louis, A. Perry, G. Reifenberger, A. Von Deimling, D. Figarella-Branger,
    W. K. Cavenee, H. Ohgaki, O. D. Wiestler, P. Kleihues, D. W. Ellison，《2016年世界卫生组织中枢神经系统肿瘤分类：总结》，《神经病理学报》
    131 (6) (2016) 803–820。'
- en: '[6] U. Baid, S. Ghodasara, S. Mohan, M. Bilello, E. Calabrese, E. Colak, K. Farahani,
    J. Kalpathy-Cramer, F. C. Kitamura, S. Pati, et al., The rsna-asnr-miccai brats
    2021 benchmark on brain tumor segmentation and radiogenomic classification, arXiv
    preprint arXiv:2107.02314.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] U. Baid, S. Ghodasara, S. Mohan, M. Bilello, E. Calabrese, E. Colak, K.
    Farahani, J. Kalpathy-Cramer, F. C. Kitamura, S. Pati 等，《rsna-asnr-miccai brats
    2021 关于脑肿瘤分割和放射基因组分类的基准》，arXiv 预印本 arXiv:2107.02314。'
- en: '[7] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. S. Kirby, J. B.
    Freymann, K. Farahani, C. Davatzikos, Advancing the cancer genome atlas glioma
    mri collections with expert segmentation labels and radiomic features, Scientific
    data 4 (1) (2017) 1–13.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. S. Kirby, J.
    B. Freymann, K. Farahani, C. Davatzikos，《通过专家分割标签和放射组学特征推进癌症基因组图谱胶质瘤 MRI 数据集》，《科学数据》4
    (1) (2017) 1–13。'
- en: '[8] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby,
    Y. Burren, N. Porz, J. Slotboom, R. Wiest, et al., The multimodal brain tumor
    image segmentation benchmark (brats), IEEE transactions on medical imaging 34 (10)
    (2014) 1993–2024.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby,
    Y. Burren, N. Porz, J. Slotboom, R. Wiest 等，《多模态脑肿瘤图像分割基准（brats）》，《IEEE医学影像学汇刊》34
    (10) (2014) 1993–2024。'
- en: '[9] M. Ghaffari, A. Sowmya, R. Oliver, Automated brain tumor segmentation using
    multimodal brain scans: a survey based on models submitted to the brats 2012–2018
    challenges, IEEE reviews in biomedical engineering 13 (2019) 156–168.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] M. Ghaffari, A. Sowmya, R. Oliver, 使用多模态脑扫描的自动化脑肿瘤分割：基于提交到 BRATS 2012–2018
    挑战的模型综述，《IEEE 生物医学工程评论》13 (2019) 156–168。'
- en: '[10] L. Kapoor, S. Thakur, A survey on brain tumor detection using image processing
    techniques, in: 2017 7th international conference on cloud computing, data science
    & engineering-confluence, IEEE, 2017, pp. 582–585.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] L. Kapoor, S. Thakur, 基于图像处理技术的脑肿瘤检测调查，见：2017 第七届国际云计算、数据科学与工程大会—汇流，IEEE，2017，第
    582–585 页。'
- en: '[11] M. Hameurlaine, A. Moussaoui, Survey of brain tumor segmentation techniques
    on magnetic resonance imaging, Nano Biomedicine and Engineering 11 (2) (2019)
    178–191.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] M. Hameurlaine, A. Moussaoui, 基于磁共振成像的脑肿瘤分割技术调查，《纳米生物医学与工程》11 (2) (2019)
    178–191。'
- en: '[12] N. Gordillo, E. Montseny, P. Sobrevilla, State of the art survey on mri
    brain tumor segmentation, Magnetic resonance imaging 31 (8) (2013) 1426–1438.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] N. Gordillo, E. Montseny, P. Sobrevilla, MRI 脑肿瘤分割的现状调查，《磁共振成像》31 (8)
    (2013) 1426–1438。'
- en: '[13] J. Liu, M. Li, J. Wang, F. Wu, T. Liu, Y. Pan, A survey of mri-based brain
    tumor segmentation methods, Tsinghua Science and Technology 19 (6) (2014) 578–595.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] J. Liu, M. Li, J. Wang, F. Wu, T. Liu, Y. Pan, 基于 MRI 的脑肿瘤分割方法调查，《清华科技》19
    (6) (2014) 578–595。'
- en: '[14] J. Nalepa, M. Marcinkiewicz, M. Kawulok, Data augmentation for brain-tumor
    segmentation: a review, Frontiers in computational neuroscience 13 (2019) 83.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. Nalepa, M. Marcinkiewicz, M. Kawulok, 脑肿瘤分割的数据增强：综述，《计算神经科学前沿》13 (2019)
    83。'
- en: '[15] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver, R. Martí,
    X. Lladó, Deep convolutional neural networks for brain image analysis on magnetic
    resonance imaging: a review, Artificial intelligence in medicine 95 (2019) 64–81.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver, R. Martí,
    X. Lladó, 深度卷积神经网络在磁共振成像脑部图像分析中的应用综述，《医学中的人工智能》95 (2019) 64–81。'
- en: '[16] Z. Akkus, A. Galimzianova, A. Hoogi, D. L. Rubin, B. J. Erickson, Deep
    learning for brain mri segmentation: state of the art and future directions, Journal
    of digital imaging 30 (4) (2017) 449–459.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] Z. Akkus, A. Galimzianova, A. Hoogi, D. L. Rubin, B. J. Erickson, 深度学习在脑
    MRI 分割中的应用：现状与未来方向，《数字成像杂志》30 (4) (2017) 449–459。'
- en: '[17] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun, J. Dean, A guide to deep learning in healthcare,
    Nature medicine 25 (1) (2019) 24–29.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun, J. Dean, 医疗保健中深度学习指南，《自然医学》25 (1) (2019) 24–29。'
- en: '[18] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, M. Pietikäinen,
    Deep learning for generic object detection: A survey, International journal of
    computer vision 128 (2) (2020) 261–318.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] L. Liu, W. Ouyang, X. Wang, P. Fieguth, J. Chen, X. Liu, M. Pietikäinen,
    通用目标检测的深度学习：一项综述，《国际计算机视觉杂志》128 (2) (2020) 261–318。'
- en: '[19] Y. LeCun, Y. Bengio, G. Hinton, Deep learning, nature 521 (7553) (2015)
    436.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Y. LeCun, Y. Bengio, G. Hinton, 《深度学习》，《自然》521 (7553) (2015) 436。'
- en: '[20] J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai, T. Liu, X. Wang,
    G. Wang, J. Cai, et al., Recent advances in convolutional neural networks, Pattern
    Recognition 77 (2018) 354–377.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. Gu, Z. Wang, J. Kuen, L. Ma, A. Shahroudy, B. Shuai, T. Liu, X. Wang,
    G. Wang, J. Cai, 等，卷积神经网络的最新进展，《模式识别》77 (2018) 354–377。'
- en: '[21] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver, R. Martí,
    X. Lladó, Deep convolutional neural networks for brain image analysis on magnetic
    resonance imaging: a review, Artificial intelligence in medicine.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] J. Bernal, K. Kushibar, D. S. Asfaw, S. Valverde, A. Oliver, R. Martí,
    X. Lladó, 深度卷积神经网络在磁共振成像脑部图像分析中的应用综述，《医学中的人工智能》。'
- en: '[22] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun, J. Dean, A guide to deep learning in healthcare,
    Nature Medicine 25 (1) (2019) 24–29.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] A. Esteva, A. Robicquet, B. Ramsundar, V. Kuleshov, M. DePristo, K. Chou,
    C. Cui, G. Corrado, S. Thrun, J. Dean, 医疗保健中深度学习指南，《自然医学》25 (1) (2019) 24–29。'
- en: '[23] I. Goodfellow, Y. Bengio, A. Courville, Deep learning, 2016.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] I. Goodfellow, Y. Bengio, A. Courville, 《深度学习》，2016。'
- en: '[24] H. Lin, S. Jegelka, Resnet with one-neuron hidden layers is a universal
    approximator, Advances in Neural Information Processing Systems 31 (2018) 6169–6178.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] H. Lin, S. Jegelka, 具有单神经元隐藏层的 ResNet 是一种通用近似器，《神经信息处理系统进展》31 (2018) 6169–6178。'
- en: '[25] D. Yarotsky, Error bounds for approximations with deep relu networks,
    Neural Networks 94 (2017) 103–114.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] D. Yarotsky, 深度 ReLU 网络近似的误差界限，《神经网络》94 (2017) 103–114。'
- en: '[26] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, A. C. Berg,
    Ssd: Single shot multibox detector, in: European conference on computer vision,
    Springer, 2016, pp. 21–37.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y. Fu, A. C. Berg,
    SSD: 单次多框检测器，欧洲计算机视觉会议，Springer，2016，pp. 21–37。'
- en: '[27] Y. Chen, J. Joo, Understanding and mitigating annotation bias in facial
    expression recognition, in: Proceedings of the IEEE/CVF International Conference
    on Computer Vision, 2021, pp. 14980–14991.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Y. Chen, J. Joo, 理解和减轻面部表情识别中的注释偏差，IEEE/CVF国际计算机视觉会议，2021，pp. 14980–14991。'
- en: '[28] S. R. Bulo, G. Neuhold, P. Kontschieder, Loss max-pooling for semantic
    image segmentation, in: 2017 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR), IEEE, 2017, pp. 7082–7091.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. R. Bulo, G. Neuhold, P. Kontschieder, 语义图像分割的损失最大池化，2017 IEEE计算机视觉与模式识别会议（CVPR），IEEE，2017，pp.
    7082–7091。'
- en: '[29] Y. Zhu, Z. Yan, Computerized tumor boundary detection using a hopfield
    neural network, IEEE transactions on medical imaging 16 (1) (1997) 55–67.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Y. Zhu, Z. Yan, 使用Hopfield神经网络的计算机化肿瘤边界检测，《IEEE医学影像学报》16 (1) (1997) 55–67。'
- en: '[30] M. C. Clark, L. O. Hall, D. B. Goldgof, R. Velthuizen, F. R. Murtagh,
    M. S. Silbiger, Automatic tumor segmentation using knowledge-based techniques,
    IEEE transactions on medical imaging 17 (2) (1998) 187–201.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. C. Clark, L. O. Hall, D. B. Goldgof, R. Velthuizen, F. R. Murtagh,
    M. S. Silbiger, 使用基于知识的技术的自动肿瘤分割，《IEEE医学影像学报》17 (2) (1998) 187–201。'
- en: '[31] M. Kaus, S. K. Warfield, A. Nabavi, E. Chatzidakis, P. M. Black, F. A.
    Jolesz, R. Kikinis, Segmentation of meningiomas and low grade gliomas in mri,
    in: International conference on medical image computing and computer-assisted
    intervention, Springer, 1999, pp. 1–10.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] M. Kaus, S. K. Warfield, A. Nabavi, E. Chatzidakis, P. M. Black, F. A.
    Jolesz, R. Kikinis, 磁共振成像中脑膜瘤和低级别胶质瘤的分割，国际医学图像计算与计算机辅助干预会议，Springer，1999，pp. 1–10。'
- en: '[32] M. Prastawa, E. Bullitt, S. Ho, G. Gerig, A brain tumor segmentation framework
    based on outlier detection, Medical image analysis 8 (3) (2004) 275–283.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] M. Prastawa, E. Bullitt, S. Ho, G. Gerig, 基于离群点检测的脑肿瘤分割框架，《医学图像分析》8 (3)
    (2004) 275–283。'
- en: '[33] J. J. Corso, E. Sharon, S. Dube, S. El-Saden, U. Sinha, A. Yuille, Efficient
    multilevel brain tumor segmentation with integrated bayesian model classification,
    IEEE transactions on medical imaging 27 (5) (2008) 629–640.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] J. J. Corso, E. Sharon, S. Dube, S. El-Saden, U. Sinha, A. Yuille, 使用集成贝叶斯模型分类的高效多级脑肿瘤分割，《IEEE医学影像学报》27
    (5) (2008) 629–640。'
- en: '[34] M. Wels, G. Carneiro, A. Aplas, M. Huber, J. Hornegger, D. Comaniciu,
    A discriminative model-constrained graph cuts approach to fully automated pediatric
    brain tumor segmentation in 3-d mri, in: International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer, 2008, pp. 67–75.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] M. Wels, G. Carneiro, A. Aplas, M. Huber, J. Hornegger, D. Comaniciu,
    一种针对3D MRI的完全自动化小儿脑肿瘤分割的判别模型约束图割方法，国际医学图像计算与计算机辅助干预会议，Springer，2008，pp. 67–75。'
- en: '[35] B. H. Menze, K. Van Leemput, D. Lashkari, M.-A. Weber, N. Ayache, P. Golland,
    A generative model for brain tumor segmentation in multi-modal images, in: International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    2010, pp. 151–159.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] B. H. Menze, K. Van Leemput, D. Lashkari, M.-A. Weber, N. Ayache, P. Golland,
    用于多模态图像脑肿瘤分割的生成模型，国际医学图像计算与计算机辅助干预会议，Springer，2010，pp. 151–159。'
- en: '[36] A. Krizhevsky, I. Sutskever, G. E. Hinton, Imagenet classification with
    deep convolutional neural networks, Advances in neural information processing
    systems 25 (2012) 1097–1105.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] A. Krizhevsky, I. Sutskever, G. E. Hinton, 使用深度卷积神经网络进行ImageNet分类，《神经信息处理系统进展》25
    (2012) 1097–1105。'
- en: '[37] D. Zikic, Y. Ioannou, M. Brown, A. Criminisi, Segmentation of brain tumor
    tissues with convolutional neural networks, Proceedings MICCAI-BRATS 36 (2014)
    36–39.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] D. Zikic, Y. Ioannou, M. Brown, A. Criminisi, 使用卷积神经网络的脑肿瘤组织分割，MICCAI-BRATS
    36 (2014) 36–39 会议录。'
- en: '[38] M. Havaei, A. Davy, D. Warde-Farley, A. Biard, A. Courville, Y. Bengio,
    C. Pal, P.-M. Jodoin, H. Larochelle, Brain tumor segmentation with deep neural
    networks, Medical image analysis 35 (2017) 18–31.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] M. Havaei, A. Davy, D. Warde-Farley, A. Biard, A. Courville, Y. Bengio,
    C. Pal, P.-M. Jodoin, H. Larochelle, 使用深度神经网络的脑肿瘤分割，《医学图像分析》35 (2017) 18–31。'
- en: '[39] S. Pereira, A. Pinto, V. Alves, C. A. Silva, Brain tumor segmentation
    using convolutional neural networks in mri images, IEEE transactions on medical
    imaging 35 (5) (2016) 1240–1251.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] S. Pereira, A. Pinto, V. Alves, C. A. Silva, 使用卷积神经网络进行脑肿瘤分割的磁共振成像，《IEEE医学影像学报》35
    (5) (2016) 1240–1251。'
- en: '[40] J. Long, E. Shelhamer, T. Darrell, Fully convolutional networks for semantic
    segmentation, in: Proceedings of the IEEE conference on computer vision and pattern
    recognition, 2015, pp. 3431–3440.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] J. Long, E. Shelhamer, T. Darrell, 用于语义分割的全卷积网络，载于：IEEE计算机视觉与模式识别会议论文集，2015，第3431–3440页。'
- en: '[41] O. Ronneberger, P. Fischer, T. Brox, U-net: Convolutional networks for
    biomedical image segmentation, in: International Conference on Medical image computing
    and computer-assisted intervention, Springer, 2015, pp. 234–241.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] O. Ronneberger, P. Fischer, T. Brox, U-Net：用于生物医学图像分割的卷积网络，载于：国际医学图像计算与计算机辅助手术会议，Springer，2015，第234–241页。'
- en: '[42] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein,
    No new-net, in: International MICCAI Brainlesion Workshop, Springer, 2018, pp.
    234–244.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein,
    无新网络，载于：国际MICCAI脑损伤研讨会，Springer，2018，第234–244页。'
- en: '[43] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, A deep learning model
    integrating fcnns and crfs for brain tumor segmentation, Medical image analysis
    43 (2018) 98–111.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, 一个集成FCNNs和CRFs的深度学习模型用于脑肿瘤分割，医学图像分析
    43 (2018) 98–111。'
- en: '[44] Z. Jiang, C. Ding, M. Liu, D. Tao, Two-stage cascaded u-net: 1st place
    solution to brats challenge 2019 segmentation task, in: International MICCAI Brainlesion
    Workshop, Springer, 2019, pp. 231–241.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Z. Jiang, C. Ding, M. Liu, D. Tao, 两阶段级联U-Net：BRATS挑战赛2019分割任务的第一名解决方案，载于：国际MICCAI脑损伤研讨会，Springer，2019，第231–241页。'
- en: '[45] K. Kamnitsas, W. Bai, E. Ferrante, S. McDonagh, M. Sinclair, N. Pawlowski,
    M. Rajchl, M. Lee, B. Kainz, D. Rueckert, et al., Ensembles of multiple models
    and architectures for robust brain tumour segmentation, in: International MICCAI
    brainlesion workshop, Springer, 2017, pp. 450–462.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] K. Kamnitsas, W. Bai, E. Ferrante, S. McDonagh, M. Sinclair, N. Pawlowski,
    M. Rajchl, M. Lee, B. Kainz, D. Rueckert, 等，多个模型和架构的集成用于稳健的脑肿瘤分割，载于：国际MICCAI脑损伤研讨会，Springer，2017，第450–462页。'
- en: '[46] G. Wang, W. Li, S. Ourselin, T. Vercauteren, Automatic brain tumor segmentation
    using cascaded anisotropic convolutional neural networks, in: International MICCAI
    brainlesion workshop, Springer, 2017, pp. 178–190.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] G. Wang, W. Li, S. Ourselin, T. Vercauteren, 使用级联各向异性卷积神经网络的自动脑肿瘤分割，载于：国际MICCAI脑损伤研讨会，Springer，2017，第178–190页。'
- en: '[47] A. Myronenko, 3d mri brain tumor segmentation using autoencoder regularization,
    in: International MICCAI Brainlesion Workshop, Springer, 2018, pp. 311–320.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] A. Myronenko, 使用自编码器正则化的3D MRI脑肿瘤分割，载于：国际MICCAI脑损伤研讨会，Springer，2018，第311–320页。'
- en: '[48] C. Zhou, C. Ding, X. Wang, Z. Lu, D. Tao, One-pass multi-task networks
    with cross-task guided attention for brain tumor segmentation, IEEE Transactions
    on Image Processing 29 (2020) 4516–4529.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] C. Zhou, C. Ding, X. Wang, Z. Lu, D. Tao, 用于脑肿瘤分割的跨任务引导注意力的单次多任务网络，IEEE图像处理汇刊
    29 (2020) 4516–4529。'
- en: '[49] C. H. Sudre, W. Li, T. Vercauteren, S. Ourselin, M. J. Cardoso, Generalised
    dice overlap as a deep learning loss function for highly unbalanced segmentations,
    in: Deep learning in medical image analysis and multimodal learning for clinical
    decision support, Springer, 2017, pp. 240–248.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] C. H. Sudre, W. Li, T. Vercauteren, S. Ourselin, M. J. Cardoso, 作为深度学习损失函数的广义骰子重叠用于高度不平衡的分割，载于：医学图像分析中的深度学习与临床决策支持的多模态学习，Springer，2017，第240–248页。'
- en: '[50] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Yu, Cross-modality deep
    feature learning for brain tumor segmentation, Pattern Recognition 110 (2021)
    107562.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Yu, 跨模态深度特征学习用于脑肿瘤分割，模式识别
    110 (2021) 107562。'
- en: '[51] T. Zhou, S. Canu, P. Vera, S. Ruan, Latent correlation representation
    learning for brain tumor segmentation with missing mri modalities, IEEE Transactions
    on Image Processing 30 (2021) 4263–4274. [doi:10.1109/TIP.2021.3070752](http://dx.doi.org/10.1109/TIP.2021.3070752).'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] T. Zhou, S. Canu, P. Vera, S. Ruan, 用于缺失MRI模态的脑肿瘤分割的潜在相关表示学习，IEEE图像处理汇刊
    30 (2021) 4263–4274. [doi:10.1109/TIP.2021.3070752](http://dx.doi.org/10.1109/TIP.2021.3070752)。'
- en: '[52] A. de Brebisson, G. Montana, Deep neural networks for anatomical brain
    segmentation, in: Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition Workshops, 2015, pp. 20–28.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] A. de Brebisson, G. Montana, 用于解剖脑分割的深度神经网络，载于：IEEE计算机视觉与模式识别研讨会论文集，2015，第20–28页。'
- en: '[53] B. Patenaude, S. M. Smith, D. N. Kennedy, M. Jenkinson, A bayesian model
    of shape and appearance for subcortical brain segmentation, Neuroimage 56 (3)
    (2011) 907–922.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] B. Patenaude, S. M. Smith, D. N. Kennedy, M. Jenkinson, 用于皮层下脑分割的形状和外观贝叶斯模型，Neuroimage
    56 (3) (2011) 907–922。'
- en: '[54] Q. Dou, H. Chen, L. Yu, L. Shi, D. Wang, V. C. Mok, P. A. Heng, Automatic
    cerebral microbleeds detection from mr images via independent subspace analysis
    based hierarchical features, in: Engineering in Medicine and Biology Society (EMBC),
    2015 37th Annual International Conference of the IEEE, IEEE, 2015, pp. 7933–7936.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] Q. Dou, H. Chen, L. Yu, L. Shi, D. Wang, V. C. Mok, P. A. Heng, 基于独立子空间分析的分层特征从MRI图像自动检测脑微出血，载于：2015年第37届IEEE医学工程与生物学学会年会（EMBC），IEEE，2015年，页码：7933–7936。'
- en: '[55] Q. Dou, H. Chen, L. Yu, L. Zhao, J. Qin, D. Wang, V. C. Mok, L. Shi, P.-A.
    Heng, Automatic detection of cerebral microbleeds from mr images via 3d convolutional
    neural networks, IEEE transactions on medical imaging 35 (5) (2016) 1182–1195.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Q. Dou, H. Chen, L. Yu, L. Zhao, J. Qin, D. Wang, V. C. Mok, L. Shi, P.-A.
    Heng, 基于3D卷积神经网络的MRI图像自动检测脑微出血，IEEE医学影像学报 35 (5) (2016) 1182–1195。'
- en: '[56] M. Ghafoorian, N. Karssemeijer, T. Heskes, M. Bergkamp, J. Wissink, J. Obels,
    K. Keizer, F.-E. de Leeuw, B. van Ginneken, E. Marchiori, et al., Deep multi-scale
    location-aware 3d convolutional neural networks for automated detection of lacunes
    of presumed vascular origin, NeuroImage: Clinical 14 (2017) 391–399.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] M. Ghafoorian, N. Karssemeijer, T. Heskes, M. Bergkamp, J. Wissink, J.
    Obels, K. Keizer, F.-E. de Leeuw, B. van Ginneken, E. Marchiori 等，深度多尺度位置感知3D卷积神经网络用于自动检测推测为血管源的腔隙，NeuroImage:
    Clinical 14 (2017) 391–399。'
- en: '[57] H.-I. Suk, C.-Y. Wee, S.-W. Lee, D. Shen, State-space model with deep
    learning for functional dynamics estimation in resting-state fmri, NeuroImage
    129 (2016) 292–307.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] H.-I. Suk, C.-Y. Wee, S.-W. Lee, D. Shen，基于深度学习的状态空间模型用于静息态fMRI中的功能动态估计，NeuroImage
    129 (2016) 292–307。'
- en: '[58] H.-I. Suk, D. Shen, Deep ensemble sparse regression network for alzheimer’s
    disease diagnosis, in: International Workshop on Machine Learning in Medical Imaging,
    Springer, 2016, pp. 113–121.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] H.-I. Suk, D. Shen，针对阿尔茨海默病诊断的深度集成稀疏回归网络，载于：医学影像机器学习国际研讨会，Springer，2016年，页码：113–121。'
- en: '[59] W. H. Pinaya, A. Gadelha, O. M. Doyle, C. Noto, A. Zugman, Q. Cordeiro,
    A. P. Jackowski, R. A. Bressan, J. R. Sato, Using deep belief network modelling
    to characterize differences in brain morphometry in schizophrenia, Scientific
    reports 6 (2016) 38897.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] W. H. Pinaya, A. Gadelha, O. M. Doyle, C. Noto, A. Zugman, Q. Cordeiro,
    A. P. Jackowski, R. A. Bressan, J. R. Sato，使用深度置信网络建模来表征精神分裂症脑形态学的差异，Scientific
    reports 6 (2016) 38897。'
- en: '[60] Y. Yoo, L. W. Tang, T. Brosch, D. K. Li, L. Metz, A. Traboulsee, R. Tam,
    Deep learning of brain lesion patterns for predicting future disease activity
    in patients with early symptoms of multiple sclerosis, in: Deep Learning and Data
    Labeling for Medical Applications, Springer, 2016, pp. 86–94.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Y. Yoo, L. W. Tang, T. Brosch, D. K. Li, L. Metz, A. Traboulsee, R. Tam，深度学习脑损伤模式用于预测早期多发性硬化症患者的未来疾病活动，载于：医学应用中的深度学习与数据标注，Springer，2016年，页码：86–94。'
- en: '[61] H. K. van der Burgh, R. Schmidt, H.-J. Westeneng, M. A. de Reus, L. H.
    van den Berg, M. P. van den Heuvel, Deep learning predictions of survival based
    on mri in amyotrophic lateral sclerosis, NeuroImage: Clinical 13 (2017) 361–369.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] H. K. van der Burgh, R. Schmidt, H.-J. Westeneng, M. A. de Reus, L. H.
    van den Berg, M. P. van den Heuvel，基于MRI的深度学习生存预测在肌萎缩侧索硬化症中的应用，NeuroImage: Clinical
    13 (2017) 361–369。'
- en: '[62] X. Li, X. Zhang, Z. Luo, Brain tumor segmentation via 3d fully dilated
    convolutional networks, in: Multimodal Brain Tumor Segmentation Benchmark, Brain-lesion
    Workshop, MICCAI, Vol. 9, 2017, p. 2017.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] X. Li, X. Zhang, Z. Luo，通过3D全扩张卷积网络进行脑肿瘤分割，载于：多模态脑肿瘤分割基准，脑损伤研讨会，MICCAI，第9卷，2017年，页码：2017。'
- en: '[63] M. M. Lopez, J. Ventura, Dilated convolutions for brain tumor segmentation
    in mri scans, in: International MICCAI Brainlesion Workshop, Springer, 2017, pp.
    253–262.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] M. M. Lopez, J. Ventura，针对MRI扫描中脑肿瘤分割的扩张卷积，载于：国际MICCAI脑损伤研讨会，Springer，2017年，页码：253–262。'
- en: '[64] L. Zhao, Automatic brain tumor segmentation with 3d deconvolution network
    with dilated inception block, MICCAI BraTS (2017) 316–320.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] L. Zhao，使用3D去卷积网络与扩张起始块的自动脑肿瘤分割，MICCAI BraTS (2017) 316–320。'
- en: '[65] M. Islam, V. Vibashan, V. J. M. Jose, N. Wijethilake, U. Utkarsh, H. Ren,
    Brain tumor segmentation and survival prediction using 3d attention unet, in:
    International MICCAI Brainlesion Workshop, Springer, 2019, pp. 262–272.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] M. Islam, V. Vibashan, V. J. M. Jose, N. Wijethilake, U. Utkarsh, H. Ren，使用3D注意力UNet进行脑肿瘤分割和生存预测，载于：国际MICCAI脑损伤研讨会，Springer，2019年，页码：262–272。'
- en: '[66] H. Wang, G. Wang, Z. Liu, S. Zhang, Global and local multi-scale feature
    fusion enhancement for brain tumor segmentation and pancreas segmentation, in:
    International MICCAI Brainlesion Workshop, Springer, 2019, pp. 80–88.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] H. Wang, G. Wang, Z. Liu, S. Zhang, 全球和局部多尺度特征融合增强用于脑肿瘤分割和胰腺分割，见：国际MICCAI脑病变研讨会，Springer，2019年，第80–88页。'
- en: '[67] C. Liu, W. Ding, L. Li, Z. Zhang, C. Pei, L. Huang, X. Zhuang, Brain tumor
    segmentation network using attention-based fusion and spatial relationship constraint,
    arXiv preprint arXiv:2010.15647.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] C. Liu, W. Ding, L. Li, Z. Zhang, C. Pei, L. Huang, X. Zhuang, 使用基于注意力的融合和空间关系约束的脑肿瘤分割网络，arXiv预印本
    arXiv:2010.15647。'
- en: '[68] T. Zhou, S. Ruan, Y. Guo, S. Canu, A multi-modality fusion network based
    on attention mechanism for brain tumor segmentation, in: 2020 IEEE 17th international
    symposium on biomedical imaging (ISBI), IEEE, 2020, pp. 377–380.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] T. Zhou, S. Ruan, Y. Guo, S. Canu, 基于注意力机制的多模态融合网络用于脑肿瘤分割，见：2020 IEEE第17届生物医学成像国际研讨会（ISBI），IEEE，2020年，第377–380页。'
- en: '[69] S. Andermatt, S. Pezold, P. Cattin, Multi-dimensional gated recurrent
    units for brain tumor segmentation, in: International MICCAI BraTS Challenge.
    Pre-Conference Proceedings, 2017, pp. 15–19.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] S. Andermatt, S. Pezold, P. Cattin, 多维门控递归单元用于脑肿瘤分割，见：国际MICCAI BraTS挑战赛，会议前期论文集，2017年，第15–19页。'
- en: '[70] R. Brügger, C. F. Baumgartner, E. Konukoglu, A partially reversible u-net
    for memory-efficient volumetric image segmentation, in: International conference
    on medical image computing and computer-assisted intervention, Springer, 2019,
    pp. 429–437.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] R. Brügger, C. F. Baumgartner, E. Konukoglu, 一种部分可逆的u-net用于内存高效的体积图像分割，见：医学图像计算与计算机辅助手术国际会议，Springer，2019年，第429–437页。'
- en: '[71] C. Chen, X. Liu, M. Ding, J. Zheng, J. Li, 3d dilated multi-fiber network
    for real-time brain tumor segmentation in mri, in: International Conference on
    Medical Image Computing and Computer-Assisted Intervention, Springer, 2019, pp.
    184–192.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] C. Chen, X. Liu, M. Ding, J. Zheng, J. Li, 基于3d扩张多纤维网络的实时脑肿瘤分割，见：医学图像计算与计算机辅助手术国际会议，Springer，2019年，第184–192页。'
- en: '[72] X. Cheng, Z. Jiang, Q. Sun, J. Zhang, Memory-efficient cascade 3d u-net
    for brain tumor segmentation, in: International MICCAI Brainlesion Workshop, Springer,
    2019, pp. 242–253.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] X. Cheng, Z. Jiang, Q. Sun, J. Zhang, 内存高效的级联3d u-net用于脑肿瘤分割，见：国际MICCAI脑病变研讨会，Springer，2019年，第242–253页。'
- en: '[73] M. Pendse, V. Thangarasa, V. Chiley, R. Holmdahl, J. Hestness, D. DeCoste,
    Memory efficient 3d u-net with reversible mobile inverted bottlenecks for brain
    tumor segmentation, in: International MICCAI Brainlesion Workshop, Springer, 2020,
    pp. 388–397.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] M. Pendse, V. Thangarasa, V. Chiley, R. Holmdahl, J. Hestness, D. DeCoste,
    内存高效的3d u-net与可逆的移动倒瓶颈用于脑肿瘤分割，见：国际MICCAI脑病变研讨会，Springer，2020年，第388–397页。'
- en: '[74] L. Zhao, K. Jia, Multiscale cnns for brain tumor segmentation and diagnosis,
    Computational and mathematical methods in medicine 2016.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] L. Zhao, K. Jia, 多尺度卷积神经网络用于脑肿瘤分割和诊断，计算与数学方法医学 2016年。'
- en: '[75] H. Shen, J. Zhang, W. Zheng, Efficient symmetry-driven fully convolutional
    network for multimodal brain tumor segmentation, in: 2017 IEEE International Conference
    on Image Processing (ICIP), IEEE, 2017, pp. 3864–3868.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] H. Shen, J. Zhang, W. Zheng, 高效的对称驱动全卷积网络用于多模态脑肿瘤分割，见：2017 IEEE国际图像处理会议（ICIP），IEEE，2017年，第3864–3868页。'
- en: '[76] L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbeláez, Volumetric multimodality
    neural network for brain tumor segmentation, in: 13th international conference
    on medical information processing and analysis, Vol. 10572, International Society
    for Optics and Photonics, 2017, p. 105720E.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] L. S. Castillo, L. A. Daza, L. C. Rivera, P. Arbeláez, 体积多模态神经网络用于脑肿瘤分割，见：第13届国际医学信息处理与分析会议，第10572卷，国际光学和光子学学会，2017年，第105720E页。'
- en: '[77] A. Jungo, R. McKinley, R. Meier, U. Knecht, L. Vera, J. Pérez-Beteta,
    D. Molina-García, V. M. Pérez-García, R. Wiest, M. Reyes, Towards uncertainty-assisted
    brain tumor segmentation and survival prediction, in: International MICCAI Brainlesion
    Workshop, Springer, 2017, pp. 474–485.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] A. Jungo, R. McKinley, R. Meier, U. Knecht, L. Vera, J. Pérez-Beteta,
    D. Molina-García, V. M. Pérez-García, R. Wiest, M. Reyes, 面向不确定性辅助的脑肿瘤分割和生存预测，见：国际MICCAI脑病变研讨会，Springer，2017年，第474–485页。'
- en: '[78] M. Shaikh, G. Anand, G. Acharya, A. Amrutkar, V. Alex, G. Krishnamurthi,
    Brain tumor segmentation using dense fully convolutional neural network, in: International
    MICCAI brainlesion workshop, Springer, 2017, pp. 309–319.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] M. Shaikh, G. Anand, G. Acharya, A. Amrutkar, V. Alex, G. Krishnamurthi,
    使用密集全卷积神经网络进行脑肿瘤分割，见：国际MICCAI脑病变研讨会，Springer，2017年，第309–319页。'
- en: '[79] Z. Zhou, Z. He, Y. Jia, Afpnet: A 3d fully convolutional neural network
    with atrous-convolution feature pyramid for brain tumor segmentation via mri images,
    Neurocomputing 402 (2020) 235–244.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Z. Zhou, Z. He, Y. Jia, Afpnet：一种3D全卷积神经网络，结合膨胀卷积特征金字塔用于通过MRI图像进行脑肿瘤分割，Neurocomputing
    402（2020年）第235–244页。'
- en: '[80] T. Zhou, S. Canu, P. Vera, S. Ruan, Latent correlation representation
    learning for brain tumor segmentation with missing mri modalities, IEEE Transactions
    on Image Processing 30 (2021) 4263–4274.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] T. Zhou, S. Canu, P. Vera, S. Ruan, 具有缺失MRI模态的脑肿瘤分割的潜在相关性表示学习，IEEE图像处理学报
    30（2021年）第4263–4274页。'
- en: '[81] P. Dvořák, B. Menze, Local structure prediction with convolutional neural
    networks for multimodal brain tumor segmentation, in: International MICCAI workshop
    on medical computer vision, Springer, 2015, pp. 59–71.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] P. Dvořák, B. Menze, 使用卷积神经网络进行局部结构预测以进行多模态脑肿瘤分割，载于：国际MICCAI医学计算机视觉研讨会，Springer，2015年，第59–71页。'
- en: '[82] V. Rao, M. S. Sarabi, A. Jaiswal, Brain tumor segmentation with deep learning,
    MICCAI Multimodal Brain Tumor Segmentation Challenge (BraTS) 59.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] V. Rao, M. S. Sarabi, A. Jaiswal, 基于深度学习的脑肿瘤分割，MICCAI多模态脑肿瘤分割挑战赛（BraTS）第59页。'
- en: '[83] K. Simonyan, A. Zisserman, Very deep convolutional networks for large-scale
    image recognition, arXiv preprint arXiv:1409.1556.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] K. Simonyan, A. Zisserman, 用于大规模图像识别的非常深卷积网络，arXiv预印本 arXiv:1409.1556。'
- en: '[84] A. Casamitjana, S. Puch, A. Aduriz, E. Sayrol, V. Vilaplana, 3d convolutional
    networks for brain tumor segmentation, Proceedings of the MICCAI Challenge on
    Multimodal Brain Tumor Image Segmentation (BRATS) (2016) 65–68.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] A. Casamitjana, S. Puch, A. Aduriz, E. Sayrol, V. Vilaplana, 用于脑肿瘤分割的3D卷积网络，MICCAI多模态脑肿瘤图像分割挑战赛（BRATS）论文集（2016年）第65–68页。'
- en: '[85] A. Jesson, T. Arbel, Brain tumor segmentation using a 3d fcn with multi-scale
    loss, in: International MICCAI Brainlesion Workshop, Springer, 2017, pp. 392–402.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] A. Jesson, T. Arbel, 使用具有多尺度损失的3D FCN进行脑肿瘤分割，载于：国际MICCAI脑病变研讨会，Springer，2017年，第392–402页。'
- en: '[86] P. D. Chang, Fully convolutional deep residual neural networks for brain
    tumor segmentation, in: International workshop on Brainlesion: Glioma, multiple
    sclerosis, stroke and traumatic brain injuries, Springer, 2016, pp. 108–118.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] P. D. Chang, 用于脑肿瘤分割的全卷积深度残差神经网络，载于：Brainlesion国际研讨会：胶质瘤、多发性硬化症、中风和创伤性脑损伤，Springer，2016年，第108–118页。'
- en: '[87] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recognition,
    in: Proceedings of the IEEE conference on computer vision and pattern recognition,
    2016, pp. 770–778.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] K. He, X. Zhang, S. Ren, J. Sun, 用于图像识别的深度残差学习，载于：IEEE计算机视觉与模式识别会议论文集，2016年，第770–778页。'
- en: '[88] M. Ghaffari, A. Sowmya, R. Oliver, Brain tumour segmentation using cascaded
    3d densely-connected u-net (2020). [arXiv:2009.07563](http://arxiv.org/abs/2009.07563).'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] M. Ghaffari, A. Sowmya, R. Oliver, 使用级联3D密集连接U-Net的脑肿瘤分割（2020年）。 [arXiv:2009.07563](http://arxiv.org/abs/2009.07563)。'
- en: '[89] Y. Wang, Y. Zhang, F. Hou, Y. Liu, J. Tian, C. Zhong, Y. Zhang, Z. He,
    Modality-pairing learning for brain tumor segmentation, arXiv preprint arXiv:2010.09277.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Y. Wang, Y. Zhang, F. Hou, Y. Liu, J. Tian, C. Zhong, Y. Zhang, Z. He,
    基于模态配对学习的脑肿瘤分割，arXiv预印本 arXiv:2010.09277。'
- en: '[90] Z. Zhou, Z. He, M. Shi, J. Du, D. Chen, [3d dense connectivity network
    with atrous convolutional feature pyramid for brain tumor segmentation in magnetic
    resonance imaging of human heads](https://doi.org/10.1016/j.compbiomed.2020.103766),
    Comput. Biol. Medicine 121 (2020) 103766. [doi:10.1016/j.compbiomed.2020.103766](http://dx.doi.org/10.1016/j.compbiomed.2020.103766).'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Z. Zhou, Z. He, M. Shi, J. Du, D. Chen, [用于磁共振成像脑肿瘤分割的3D密集连接网络，结合膨胀卷积特征金字塔](https://doi.org/10.1016/j.compbiomed.2020.103766)，Comput.
    Biol. Medicine 121（2020年）103766。 [doi:10.1016/j.compbiomed.2020.103766](http://dx.doi.org/10.1016/j.compbiomed.2020.103766)。'
- en: URL [https://doi.org/10.1016/j.compbiomed.2020.103766](https://doi.org/10.1016/j.compbiomed.2020.103766)
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: URL [https://doi.org/10.1016/j.compbiomed.2020.103766](https://doi.org/10.1016/j.compbiomed.2020.103766)
- en: '[91] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger, Densely connected
    convolutional networks, in: Proceedings of the IEEE conference on computer vision
    and pattern recognition, 2017, pp. 4700–4708.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] G. Huang, Z. Liu, L. Van Der Maaten, K. Q. Weinberger, 密集连接卷积网络，载于：IEEE计算机视觉与模式识别会议论文集，2017年，第4700–4708页。'
- en: '[92] F. Yu, V. Koltun, T. Funkhouser, Dilated residual networks, in: Proceedings
    of the IEEE conference on computer vision and pattern recognition, 2017, pp. 472–480.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] F. Yu, V. Koltun, T. Funkhouser, 膨胀残差网络，载于：IEEE计算机视觉与模式识别会议论文集，2017年，第472–480页。'
- en: '[93] A. R. Choudhury, R. Vanguri, S. R. Jambawalikar, P. Kumar, Segmentation
    of brain tumors using deeplabv3+, in: International MICCAI Brainlesion Workshop,
    Springer, 2018, pp. 154–167.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] A. R. Choudhury, R. Vanguri, S. R. Jambawalikar, P. Kumar, 使用deeplabv3+进行脑肿瘤分割，见：国际MICCAI脑病变研讨会，Springer，2018，第154–167页。'
- en: '[94] S. Andermatt, S. Pezold, P. Cattin, Multi-dimensional gated recurrent
    units for the segmentation of biomedical 3d-data, in: Deep learning and data labeling
    for medical applications, Springer, 2016, pp. 142–151.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] S. Andermatt, S. Pezold, P. Cattin, 用于生物医学3d数据分割的多维门控递归单元，见：医学应用中的深度学习与数据标注，Springer，2016，第142–151页。'
- en: '[95] A. N. Gomez, M. Ren, R. Urtasun, R. B. Grosse, The reversible residual
    network: Backpropagation without storing activations, in: Proceedings of the 31st
    International Conference on Neural Information Processing Systems, 2017, pp. 2211–2221.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] A. N. Gomez, M. Ren, R. Urtasun, R. B. Grosse, 可逆残差网络：无需存储激活的反向传播，见：第31届国际神经信息处理系统会议论文集，2017，第2211–2221页。'
- en: '[96] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L.-C. Chen, Mobilenetv2:
    Inverted residuals and linear bottlenecks, in: Proceedings of the IEEE conference
    on computer vision and pattern recognition, 2018, pp. 4510–4520.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] M. Sandler, A. Howard, M. Zhu, A. Zhmoginov, L.-C. Chen, Mobilenetv2：反转残差和线性瓶颈，见：IEEE计算机视觉与模式识别会议论文集，2018，第4510–4520页。'
- en: '[97] M. Tan, Q. Le, Efficientnet: Rethinking model scaling for convolutional
    neural networks, in: International Conference on Machine Learning, PMLR, 2019,
    pp. 6105–6114.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] M. Tan, Q. Le, Efficientnet：重新思考卷积神经网络的模型缩放，见：国际机器学习会议，PMLR，2019，第6105–6114页。'
- en: '[98] N. Nuechterlein, S. Mehta, 3d-espnet with pyramidal refinement for volumetric
    brain tumor image segmentation, in: International MICCAI Brainlesion Workshop,
    Springer, 2018, pp. 245–253.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] N. Nuechterlein, S. Mehta, 使用金字塔细化的3d-espnet进行体积脑肿瘤图像分割，见：国际MICCAI脑病变研讨会，Springer，2018，第245–253页。'
- en: '[99] G. Urban, M. Bendszus, F. Hamprecht, J. Kleesiek, Multi-modal brain tumor
    segmentation using deep convolutional neural networks, MICCAI BraTS (brain tumor
    segmentation) challenge. Proceedings, winning contribution (2014) 31–35.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] G. Urban, M. Bendszus, F. Hamprecht, J. Kleesiek, 使用深度卷积神经网络的多模态脑肿瘤分割，MICCAI
    BraTS（脑肿瘤分割）挑战。论文集，获胜贡献（2014）31–35。'
- en: '[100] M. Akil, R. Saouli, R. Kachouri, et al., Fully automatic brain tumor
    segmentation with deep learning-based selective attention using overlapping patches
    and multi-class weighted cross-entropy, Medical image analysis 63 (2020) 101692.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] M. Akil, R. Saouli, R. Kachouri, 等，基于深度学习的选择性注意与重叠补丁和多类加权交叉熵的完全自动脑肿瘤分割，《医学图像分析》63（2020）101692。'
- en: '[101] K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simpson, A. D. Kane, D. K.
    Menon, D. Rueckert, B. Glocker, Efficient multi-scale 3d cnn with fully connected
    crf for accurate brain lesion segmentation, Medical image analysis 36 (2017) 61–78.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] K. Kamnitsas, C. Ledig, V. F. Newcombe, J. P. Simpson, A. D. Kane, D.
    K. Menon, D. Rueckert, B. Glocker, 高效的多尺度3d cnn与完全连接的crf用于准确的脑病变分割，《医学图像分析》36（2017）61–78。'
- en: '[102] H. Shen, R. Wang, J. Zhang, S. J. McKenna, Boundary-aware fully convolutional
    network for brain tumor segmentation, in: International Conference on Medical
    Image Computing and Computer-Assisted Intervention, Springer, 2017, pp. 433–441.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] H. Shen, R. Wang, J. Zhang, S. J. McKenna, 边界感知全卷积网络用于脑肿瘤分割，见：国际医学图像计算与计算机辅助干预会议，Springer，2017，第433–441页。'
- en: '[103] T. Brosch, L. Y. Tang, Y. Yoo, D. K. Li, A. Traboulsee, R. Tam, Deep
    3d convolutional encoder networks with shortcuts for multiscale feature integration
    applied to multiple sclerosis lesion segmentation, IEEE transactions on medical
    imaging 35 (5) (2016) 1229–1239.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] T. Brosch, L. Y. Tang, Y. Yoo, D. K. Li, A. Traboulsee, R. Tam, 带有捷径的深度3d卷积编码器网络用于多尺度特征融合应用于多发性硬化病变分割，《IEEE医学影像学汇刊》35（5）（2016）1229–1239。'
- en: '[104] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein,
    Brain tumor segmentation and radiomics survival prediction: Contribution to the
    brats 2017 challenge, in: International MICCAI Brainlesion Workshop, Springer,
    2017, pp. 287–297.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] F. Isensee, P. Kickingereder, W. Wick, M. Bendszus, K. H. Maier-Hein,
    脑肿瘤分割和放射组学生存预测：对brats 2017挑战的贡献，见：国际MICCAI脑病变研讨会，Springer，2017，第287–297页。'
- en: '[105] H. Dong, G. Yang, F. Liu, Y. Mo, Y. Guo, Automatic brain tumor detection
    and segmentation using u-net based fully convolutional networks, in: annual conference
    on medical image understanding and analysis, Springer, 2017, pp. 506–517.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] H. Dong, G. Yang, F. Liu, Y. Mo, Y. Guo, 使用基于u-net的全卷积网络进行脑肿瘤自动检测和分割，见：医学图像理解与分析年会，Springer，2017，第506–517页。'
- en: '[106] F. Milletari, N. Navab, S.-A. Ahmadi, V-net: Fully convolutional neural
    networks for volumetric medical image segmentation, in: 3D Vision (3DV), 2016
    Fourth International Conference on, IEEE, 2016, pp. 565–571.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] F. Milletari, N. Navab, S.-A. Ahmadi, V-net：用于体积医学图像分割的全卷积神经网络，见：2016年第四届国际3D视觉会议（3DV），IEEE，2016年，页码
    565–571。'
- en: '[107] A. Beers, K. Chang, J. Brown, E. Sartor, C. Mammen, E. Gerstner, B. Rosen,
    J. Kalpathy-Cramer, Sequential 3d u-nets for biologically-informed brain tumor
    segmentation, arXiv preprint arXiv:1709.02967.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] A. Beers, K. Chang, J. Brown, E. Sartor, C. Mammen, E. Gerstner, B. Rosen,
    J. Kalpathy-Cramer, 顺序3D u-nets用于生物学信息的脑肿瘤分割，arXiv预印本 arXiv:1709.02967。'
- en: '[108] S. Chen, C. Ding, C. Zhou, Brain tumor segmentation with label distribution
    learning and multi-level feature representation, 2017 International MICCAI BraTS
    Challenge.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] S. Chen, C. Ding, C. Zhou, 使用标签分布学习和多级特征表示的脑肿瘤分割，2017国际MICCAI BraTS挑战赛。'
- en: '[109] S. Chen, C. Ding, M. Liu, Dual-force convolutional neural networks for
    accurate brain tumor segmentation, Pattern Recognition 88 (2019) 90–100.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] S. Chen, C. Ding, M. Liu, 双重力卷积神经网络用于精确的脑肿瘤分割，模式识别 88 (2019) 90–100。'
- en: '[110] K. Pawar, Z. Chen, N. J. Shah, G. Egan, Residual encoder and convolutional
    decoder neural network for glioma segmentation, in: International MICCAI Brainlesion
    Workshop, Springer, 2017, pp. 263–273.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] K. Pawar, Z. Chen, N. J. Shah, G. Egan, 用于胶质瘤分割的残差编码器和卷积解码器神经网络，见：国际MICCAI脑病变研讨会，Springer，2017年，页码
    263–273。'
- en: '[111] W. Chen, B. Liu, S. Peng, J. Sun, X. Qiao, S3d-unet: separable 3d u-net
    for brain tumor segmentation, in: International MICCAI Brainlesion Workshop, Springer,
    2018, pp. 358–368.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] W. Chen, B. Liu, S. Peng, J. Sun, X. Qiao, S3d-unet：用于脑肿瘤分割的可分离3D u-net，见：国际MICCAI脑病变研讨会，Springer，2018年，页码
    358–368。'
- en: '[112] L. Fang, H. He, Three pathways u-net for brain tumor segmentation, in:
    Pre-conference proceedings of the 7th medical image computing and computer-assisted
    interventions (MICCAI) BraTS Challenge, Vol. 2018, 2018, pp. 119–126.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] L. Fang, H. He, 三路径u-net用于脑肿瘤分割，见：第7届医学图像计算与计算机辅助干预（MICCAI）BraTS挑战赛预会议论文集，第2018卷，2018年，页码
    119–126。'
- en: '[113] R. Hua, Q. Huo, Y. Gao, Y. Sun, F. Shi, Multimodal brain tumor segmentation
    using cascaded v-nets, in: International MICCAI Brainlesion Workshop, Springer,
    2018, pp. 49–60.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] R. Hua, Q. Huo, Y. Gao, Y. Sun, F. Shi, 使用级联v-net的多模态脑肿瘤分割，见：国际MICCAI脑病变研讨会，Springer，2018年，页码
    49–60。'
- en: '[114] X. Li, Fused u-net for brain tumor segmentation based on multimodal mr
    images, International MICCAI Brain Tumor Segmentation (BraTS) challenge (2018)
    290–297.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] X. Li, 基于多模态MR图像的融合u-net用于脑肿瘤分割，国际MICCAI脑肿瘤分割（BraTS）挑战赛（2018年）290–297。'
- en: '[115] Y.-X. Zhao, Y.-M. Zhang, C.-L. Liu, Bag of tricks for 3d mri brain tumor
    segmentation, in: International MICCAI Brainlesion Workshop, Springer, 2019, pp.
    210–220.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Y.-X. Zhao, Y.-M. Zhang, C.-L. Liu, 用于3D MRI脑肿瘤分割的技巧包，见：国际MICCAI脑病变研讨会，Springer，2019年，页码
    210–220。'
- en: '[116] Y. Yuan, Automatic brain tumor segmentation with scale attention network,
    in: BrainLes@MICCAI, 2020.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Y. Yuan, 使用尺度注意力网络的自动脑肿瘤分割，见：BrainLes@MICCAI，2020年。'
- en: '[117] T. Henry, A. Carre, M. Lerousseau, T. Estienne, C. Robert, N. Paragios,
    E. Deutsch, Brain tumor segmentation with self-ensembled, deeply-supervised 3d
    u-net neural networks: a brats 2020 challenge solution, arXiv preprint arXiv:2011.01045.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] T. Henry, A. Carre, M. Lerousseau, T. Estienne, C. Robert, N. Paragios,
    E. Deutsch, 使用自集成、深度监督的3D u-net神经网络进行脑肿瘤分割：一个BraTS 2020挑战赛解决方案，arXiv预印本 arXiv:2011.01045。'
- en: '[118] W. Bae, S. Lee, Y. Lee, B. Park, M. Chung, K.-H. Jung, Resource optimized
    neural architecture search for 3d medical image segmentation, in: International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    2019, pp. 228–236.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] W. Bae, S. Lee, Y. Lee, B. Park, M. Chung, K.-H. Jung, 针对3D医学图像分割的资源优化神经架构搜索，见：国际医学图像计算与计算机辅助干预会议，Springer，2019年，页码
    228–236。'
- en: '[119] S. Kim, I. Kim, S. Lim, W. Baek, C. Kim, H. Cho, B. Yoon, T. Kim, Scalable
    neural architecture search for 3d medical image segmentation, in: International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    2019, pp. 220–228.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] S. Kim, I. Kim, S. Lim, W. Baek, C. Kim, H. Cho, B. Yoon, T. Kim, 用于3D医学图像分割的可扩展神经架构搜索，见：国际医学图像计算与计算机辅助干预会议，Springer，2019年，页码
    220–228。'
- en: '[120] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++: Redesigning
    skip connections to exploit multiscale features in image segmentation, IEEE transactions
    on medical imaging 39 (6) (2019) 1856–1867.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, J. Liang, Unet++: 重新设计跳跃连接以利用图像分割中的多尺度特征，IEEE医学成像学报
    39 (6) (2019) 1856–1867。'
- en: '[121] Z. Zhu, C. Liu, D. Yang, A. Yuille, D. Xu, V-nas: Neural architecture
    search for volumetric medical image segmentation, in: 2019 International Conference
    on 3D Vision (3DV), IEEE, 2019, pp. 240–248.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] Z. 朱, C. 刘, D. 杨, A. 尤, D. 徐，V-nas：用于体积医学影像分割的神经架构搜索，见：2019 国际 3D 视觉会议（3DV），IEEE，2019，第240–248页。'
- en: '[122] Q. Dong, S. Gong, X. Zhu, Imbalanced deep learning by minority class
    incremental rectification, IEEE transactions on pattern analysis and machine intelligence
    41 (6) (2018) 1367–1381.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] Q. 董, S. 龚, X. 朱，不平衡深度学习通过少数类增量修正，《IEEE 模式分析与机器智能》41（6）（2018）1367–1381。'
- en: '[123] J. M. Johnson, T. M. Khoshgoftaar, Survey on deep learning with class
    imbalance, Journal of Big Data 6 (1) (2019) 1–54.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] J. M. 约翰逊, T. M. 科什戈夫塔尔，关于深度学习与类别不平衡的综述，《大数据杂志》6（1）（2019）1–54。'
- en: '[124] H. Jia, W. Cai, H. Huang, Y. Xia, H2nf-net for brain tumor segmentation
    using multimodal mr imaging: 2nd place solution to brats challenge 2020 segmentation
    task, in: BrainLes@ MICCAI (2), 2020.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] H. 贾, W. 蔡, H. 黄, Y. 夏，H2NF-Net 用于脑肿瘤分割使用多模态 MR 成像：BRATS 挑战 2020 分割任务第二名解决方案，见：BrainLes@
    MICCAI（2），2020。'
- en: '[125] K. Sun, B. Xiao, D. Liu, J. Wang, Deep high-resolution representation
    learning for human pose estimation, in: CVPR, 2019.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] K. 孙, B. 萧, D. 刘, J. 王，深度高分辨率表示学习用于人体姿态估计，见：CVPR，2019。'
- en: '[126] X. Li, G. Luo, K. Wang, Multi-step cascaded networks for brain tumor
    segmentation, in: International MICCAI Brainlesion Workshop, Springer, 2019, pp.
    163–173.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] X. 李, G. 罗, K. 王，多步骤级联网络用于脑肿瘤分割，见：国际 MICCAI 脑病损研讨会，Springer，2019，第163–173页。'
- en: '[127] M. H. Vu, T. Nyholm, T. Löfstedt, Tunet: End-to-end hierarchical brain
    tumor segmentation using cascaded networks, in: International MICCAI Brainlesion
    Workshop, Springer, 2019, pp. 174–186.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] M. H. 武, T. 奈霍尔姆, T. 洛夫斯特，Tunet：使用级联网络的端到端层级脑肿瘤分割，见：国际 MICCAI 脑病损研讨会，Springer，2019，第174–186页。'
- en: '[128] Z. Liu, D. Gu, Y. Zhang, X. Cao, Z. Xue, Automatic segmentation of non-tumor
    tissues in glioma mr brain images using deformable registration with partial convolutional
    networks, in: International MICCAI Brainlesion Workshop, Springer, 2020, pp. 41–50.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] Z. 刘, D. 顾, Y. 张, X. 曹, Z. 薛, 使用部分卷积网络的可变形配准对胶质瘤 MR 脑影像中非肿瘤组织进行自动分割，见：国际
    MICCAI 脑病损研讨会，Springer，2020，第41–50页。'
- en: '[129] M. D. Cirillo, D. Abramian, A. Eklund, Vox2vox: 3d-gan for brain tumour
    segmentation, arXiv preprint arXiv:2003.13653.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] M. D. 西里洛, D. 阿布拉米安, A. 埃克伦，Vox2vox：用于脑肿瘤分割的 3D-GAN，arXiv 预印本 arXiv:2003.13653。'
- en: '[130] H. Chen, Z. Qin, Y. Ding, L. Tian, Z. Qin, Brain tumor segmentation with
    deep convolutional symmetric neural network, Neurocomputing 392 (2020) 305–313.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] H. 陈, Z. 秦, Y. 丁, L. 田, Z. 秦，使用深度卷积对称神经网络进行脑肿瘤分割，《神经计算》392（2020）305–313。'
- en: '[131] K. Kamnitsas, E. Ferrante, S. Parisot, C. Ledig, A. V. Nori, A. Criminisi,
    D. Rueckert, B. Glocker, Deepmedic for brain tumor segmentation, in: International
    workshop on Brainlesion: Glioma, multiple sclerosis, stroke and traumatic brain
    injuries, Springer, 2016, pp. 138–149.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] K. 卡姆尼察斯, E. 费兰特, S. 帕里索特, C. 莱迪格, A. V. 诺里, A. 克里米尼西, D. 鲁克特, B. 格洛克，Deepmedic
    用于脑肿瘤分割，见：国际脑病损研讨会：胶质瘤、多发性硬化、脑卒中和创伤性脑损伤，Springer，2016，第138–149页。'
- en: '[132] P.-Y. Kao, T. Ngo, A. Zhang, J. W. Chen, B. Manjunath, Brain tumor segmentation
    and tractographic feature extraction from structural mr images for overall survival
    prediction, in: International MICCAI Brainlesion Workshop, Springer, 2018, pp.
    128–141.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] P.-Y. 高, T. 伍, A. 张, J. W. 陈, B. 曼朱纳特，基于结构 MR 影像进行脑肿瘤分割和束图特征提取以预测整体生存，见：国际
    MICCAI 脑病损研讨会，Springer，2018，第128–141页。'
- en: '[133] D. Lachinov, E. Shipunova, V. Turlapov, Knowledge distillation for brain
    tumor segmentation, in: International MICCAI Brainlesion Workshop, Springer, 2019,
    pp. 324–332.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] D. 拉钦诺夫, E. 希普诺娃, V. 图尔拉波夫，知识蒸馏用于脑肿瘤分割，见：国际 MICCAI 脑病损研讨会，Springer，2019，第324–332页。'
- en: '[134] D. Lachinov, E. Vasiliev, V. Turlapov, Glioma segmentation with cascaded
    unet, in: International MICCAI Brainlesion Workshop, Springer, 2018, pp. 189–198.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] D. 拉钦诺夫, E. 瓦西里耶夫, V. 图尔拉波夫，使用级联 Unet 的胶质瘤分割，见：国际 MICCAI 脑病损研讨会，Springer，2018，第189–198页。'
- en: '[135] X. Zhao, Y. Wu, G. Song, Z. Li, Y. Zhang, Y. Fan, 3d brain tumor segmentation
    through integrating multiple 2d fcnns, in: International MICCAI Brainlesion Workshop,
    Springer, 2017, pp. 191–203.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] X. 赵, Y. 吴, G. 宋, Z. 李, Y. 张, Y. 范，通过集成多个 2D FCNNs 进行 3D 脑肿瘤分割，见：国际 MICCAI
    脑病损研讨会，Springer，2017，第191–203页。'
- en: '[136] V. Sundaresan, L. Griffanti, M. Jenkinson, Brain tumour segmentation
    using a triplanar ensemble of u-nets on mr images, in: International MICCAI Brainlesion
    Workshop, Springer, 2020, pp. 340–353.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] V. Sundaresan, L. Griffanti, M. Jenkinson, 使用三平面 U-Net 集成进行脑肿瘤分割，见：国际
    MICCAI 脑病变研讨会，Springer，2020年，第340–353页。'
- en: '[137] L. Chen, P. Bentley, D. Rueckert, Fully automatic acute ischemic lesion
    segmentation in dwi using convolutional neural networks, NeuroImage: Clinical
    15 (2017) 633–643.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] L. Chen, P. Bentley, D. Rueckert, 使用卷积神经网络在 DWI 中完全自动化急性缺血性病灶分割，NeuroImage:
    Clinical 15 (2017) 633–643。'
- en: '[138] H. Noh, S. Hong, B. Han, Learning deconvolution network for semantic
    segmentation, in: Proceedings of the IEEE international conference on computer
    vision, 2015, pp. 1520–1528.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] H. Noh, S. Hong, B. Han, 学习反卷积网络进行语义分割，见：IEEE 国际计算机视觉会议论文集，2015年，第1520–1528页。'
- en: '[139] Y. Hu, Y. Xia, 3d deep neural network-based brain tumor segmentation
    using multimodality magnetic resonance sequences, in: International MICCAI Brainlesion
    Workshop, Springer, 2017, pp. 423–434.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] Y. Hu, Y. Xia, 基于 3D 深度神经网络的脑肿瘤分割使用多模态磁共振序列，见：国际 MICCAI 脑病变研讨会，Springer，2017年，第423–434页。'
- en: '[140] C. A. Silva, A. Pinto, S. Pereira, A. Lopes, Multi-stage deep layer aggregation
    for brain tumor segmentation, in: International MICCAI Brainlesion Workshop, Springer,
    2020, pp. 179–188.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] C. A. Silva, A. Pinto, S. Pereira, A. Lopes, 脑肿瘤分割的多阶段深层聚合，见：国际 MICCAI
    脑病变研讨会，Springer，2020年，第179–188页。'
- en: '[141] C. Zhou, S. Chen, C. Ding, D. Tao, Learning contextual and attentive
    information for brain tumor segmentation, in: International MICCAI brainlesion
    workshop, Springer, 2018, pp. 497–507.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] C. Zhou, S. Chen, C. Ding, D. Tao, 学习脑肿瘤分割的上下文和注意力信息，见：国际 MICCAI 脑病变研讨会，Springer，2018年，第497–507页。'
- en: '[142] H. Shen, R. Wang, J. Zhang, S. McKenna, Multi-task fully convolutional
    network for brain tumour segmentation, in: Annual Conference on Medical Image
    Understanding and Analysis, Springer, 2017, pp. 239–248.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] H. Shen, R. Wang, J. Zhang, S. McKenna, 用于脑肿瘤分割的多任务全卷积网络，见：年度医学图像理解与分析会议，Springer，2017年，第239–248页。'
- en: '[143] H. T. Nguyen, T. T. Le, T. V. Nguyen, N. T. Nguyen, Enhancing mri brain
    tumor segmentation with an additional classification network, arXiv preprint arXiv:2009.12111.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] H. T. Nguyen, T. T. Le, T. V. Nguyen, N. T. Nguyen, 通过额外的分类网络增强 MRI 脑肿瘤分割，arXiv
    预印本 arXiv:2009.12111。'
- en: '[144] L. Weninger, Q. Liu, D. Merhof, Multi-task learning for brain tumor segmentation,
    in: International MICCAI brainlesion workshop, Springer, 2019, pp. 327–337.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] L. Weninger, Q. Liu, D. Merhof, 脑肿瘤分割的多任务学习，见：国际 MICCAI 脑病变研讨会，Springer，2019年，第327–337页。'
- en: '[145] J. Iwasawa, Y. Hirano, Y. Sugawara, Label-efficient multi-task segmentation
    using contrastive learning, arXiv preprint arXiv:2009.11160.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] J. Iwasawa, Y. Hirano, Y. Sugawara, 使用对比学习的标签高效多任务分割，arXiv 预印本 arXiv:2009.11160。'
- en: '[146] R. Caruana, Multitask learning, Machine learning 28 (1) (1997) 41–75.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] R. Caruana, 多任务学习，机器学习 28 (1) (1997) 41–75。'
- en: '[147] T. Evgeniou, M. Pontil, Regularized multi–task learning, in: Proceedings
    of the tenth ACM SIGKDD international conference on Knowledge discovery and data
    mining, 2004, pp. 109–117.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] T. Evgeniou, M. Pontil, 正则化的多任务学习，见：第十届 ACM SIGKDD 国际知识发现与数据挖掘会议论文集，2004年，第109–117页。'
- en: '[148] O. Sener, V. Koltun, Multi-task learning as multi-objective optimization,
    in: Proceedings of the 32nd International Conference on Neural Information Processing
    Systems, 2018, pp. 525–536.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] O. Sener, V. Koltun, 多任务学习作为多目标优化，见：第32届国际神经信息处理系统会议论文集，2018年，第525–536页。'
- en: '[149] Y. Zhang, Q. Yang, A survey on multi-task learning, IEEE Transactions
    on Knowledge and Data Engineering.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Y. Zhang, Q. Yang, 关于多任务学习的综述，IEEE 知识与数据工程学报。'
- en: '[150] R. S. Randhawa, A. Modi, P. Jain, P. Warier, Improving boundary classification
    for brain tumor segmentation and longitudinal disease progression, in: International
    Workshop on Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain
    Injuries, Springer, 2016, pp. 65–74.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] R. S. Randhawa, A. Modi, P. Jain, P. Warier, 改进脑肿瘤分割和纵向疾病进展的边界分类，见：脑病变国际研讨会：神经胶质瘤、多发性硬化、脑卒中和创伤性脑损伤，Springer，2016年，第65–74页。'
- en: '[151] K. Pawar, Z. Chen, N. J. Shah, G. F. Egan, An ensemble of 2d convolutional
    neural network for 3d brain tumor segmentation, in: International MICCAI Brainlesion
    Workshop, Springer, 2019, pp. 359–367.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] K. Pawar, Z. Chen, N. J. Shah, G. F. Egan, 一种用于三维脑肿瘤分割的二维卷积神经网络集成，见：国际
    MICCAI 脑病变研讨会，Springer，2019年，第359–367页。'
- en: '[152] K.-L. Tseng, Y.-L. Lin, W. Hsu, C.-Y. Huang, Joint sequence learning
    and cross-modality convolution for 3d biomedical segmentation, in: Proceedings
    of the IEEE conference on Computer Vision and Pattern Recognition, 2017, pp. 6393–6400.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] K.-L. Tseng, Y.-L. Lin, W. Hsu, C.-Y. Huang，《3d 生物医学分割的联合序列学习和跨模态卷积》，发表于：2017
    年 IEEE 计算机视觉与模式识别会议论文集，第 6393–6400 页。'
- en: '[153] M. Catà, A. Casamitjana Díaz, I. Sanchez Muriana, M. Combalia, V. Vilaplana Besler,
    Masked v-net: an approach to brain tumor segmentation, in: 2017 International
    MICCAI BraTS Challenge. Pre-conference proceedings, 2017, pp. 42–49.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] M. Catà, A. Casamitjana Díaz, I. Sanchez Muriana, M. Combalia, V. Vilaplana
    Besler，《Masked v-net：一种脑肿瘤分割方法》，发表于：2017 年国际 MICCAI BraTS 挑战。会议前期论文集，第 42–49 页。'
- en: '[154] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Wang, Y. Yu, Exploring
    task structure for brain tumor segmentation from multi-modality mr images, IEEE
    Transactions on Image Processing 29 (2020) 9032–9043.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] D. Zhang, G. Huang, Q. Zhang, J. Han, J. Han, Y. Wang, Y. Yu，《从多模态 MR
    图像中探索任务结构以进行脑肿瘤分割》，IEEE 图像处理学报 29 (2020) 9032–9043。'
- en: '[155] Y. Li, L. Shen, Deep learning based multimodal brain tumor diagnosis,
    in: International MICCAI Brainlesion Workshop, Springer, 2017, pp. 149–158.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] Y. Li, L. Shen，《基于深度学习的多模态脑肿瘤诊断》，发表于：国际 MICCAI Brainlesion 研讨会，Springer，2017，第
    149–158 页。'
- en: '[156] B. Yu, L. Zhou, L. Wang, J. Fripp, P. Bourgeat, 3d cgan based cross-modality
    mr image synthesis for brain tumor segmentation, in: 2018 IEEE 15th International
    Symposium on Biomedical Imaging (ISBI 2018), IEEE, 2018, pp. 626–630.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] B. Yu, L. Zhou, L. Wang, J. Fripp, P. Bourgeat，《基于 3d cgan 的跨模态 MR 图像合成用于脑肿瘤分割》，发表于：2018
    IEEE 第 15 届国际生物医学成像研讨会（ISBI 2018），IEEE，2018，第 626–630 页。'
- en: '[157] T. Zhou, S. Canu, P. Vera, S. Ruan, Brain tumor segmentation with missing
    modalities via latent multi-source correlation representation, in: International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    2020, pp. 533–541.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] T. Zhou, S. Canu, P. Vera, S. Ruan，《通过潜在多源相关表示进行缺失模态脑肿瘤分割》，发表于：医学图像计算与计算机辅助干预国际会议，Springer，2020，第
    533–541 页。'
- en: '[158] B. Yu, L. Zhou, L. Wang, W. Yang, M. Yang, P. Bourgeat, J. Fripp, Sa-lut-nets:
    Learning sample-adaptive intensity lookup tables for brain tumor segmentation,
    IEEE Transactions on Medical Imaging 40 (5) (2021) 1417–1427.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] B. Yu, L. Zhou, L. Wang, W. Yang, M. Yang, P. Bourgeat, J. Fripp，《Sa-lut-nets：学习样本自适应强度查找表用于脑肿瘤分割》，IEEE
    医学影像学报 40 (5) (2021) 1417–1427。'
