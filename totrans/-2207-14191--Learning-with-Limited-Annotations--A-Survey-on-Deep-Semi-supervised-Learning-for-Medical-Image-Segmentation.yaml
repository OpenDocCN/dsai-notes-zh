- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:45:08'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:45:08
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2207.14191] Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2207.14191] 使用有限注释进行学习：深度半监督学习在医学图像分割中的综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2207.14191](https://ar5iv.labs.arxiv.org/html/2207.14191)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2207.14191](https://ar5iv.labs.arxiv.org/html/2207.14191)
- en: \cormark
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[1]'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: \cormark
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[1]'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]'
- en: \cormark
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[2]'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: \cormark
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: \cormark
- en: '[2]'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[2]'
- en: \cortext
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: \cortext
- en: '[1]Contribute equally to this work. \cortext[2]Corresponding author'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]对本工作做出同等贡献。 \cortext[2]通讯作者'
- en: 'Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation'
  id: totrans-16
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用有限注释进行学习：深度半监督学习在医学图像分割中的综述
- en: Rushi Jiao    Yichi Zhang    Le Ding    Bingsen Xue    Jicong Zhang    Rong
    Cai    Cheng Jin School of Biomedical Engineering, Shanghai Jiao Tong University,
    Shanghai, 200240, China School of Data Science, Fudan University, Shanghai, 200433,
    China School of Engineering Medicine, Beihang University, Beijing, 100191, China
    Artificial Intelligence Innovation and Incubation Institute, Fudan University,
    Shanghai, 200433, China School of Biological Science and Medical Engineering,
    Beihang University, Beijing, 100191, China Shanghai Artificial Intelligence Laboratory,
    Shanghai, 200232, China Beijing Anding Hospital, Capital Medical University, Beijing,
    100088, China Key Laboratory for Biomechanics and Mechanobiology of Ministry of
    Education, Beihang University, Beijing, 100191, China Hefei Innovation Research
    Institute, Beihang University, Hefei, 230012, China
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: Rushi Jiao    Yichi Zhang    Le Ding    Bingsen Xue    Jicong Zhang    Rong
    Cai    Cheng Jin 上海交通大学生物医学工程学院，上海，200240，中国 复旦大学数据科学学院，上海，200433，中国 北京航空航天大学工程医学学院，北京，100191，中国
    复旦大学人工智能创新与孵化研究所，上海，200433，中国 北京航空航天大学生物科学与医学工程学院，北京，100191，中国 上海人工智能实验室，上海，200232，中国
    首都医科大学北京安定医院，北京，100088，中国 北京航空航天大学教育部生物力学与生物力学重点实验室，北京，100191，中国 北京航空航天大学合肥创新研究院，合肥，230012，中国
- en: Abstract
  id: totrans-18
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Medical image segmentation is a fundamental and critical step in many image-guided
    clinical approaches. Recent success of deep learning-based segmentation methods
    usually relies on a large amount of labeled data, which is particularly difficult
    and costly to obtain, especially in the medical imaging domain where only experts
    can provide reliable and accurate annotations. Semi-supervised learning has emerged
    as an appealing strategy and been widely applied to medical image segmentation
    tasks to train deep models with limited annotations. In this paper, we present
    a comprehensive review of recently proposed semi-supervised learning methods for
    medical image segmentation and summarize both the technical novelties and empirical
    results. Furthermore, we analyze and discuss the limitations and several unsolved
    problems of existing approaches. We hope this review can inspire the research
    community to explore solutions to this challenge and further advance the field
    of medical image segmentation.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像分割是许多图像引导临床方法中的基础和关键步骤。近期基于深度学习的分割方法通常依赖于大量标注数据，这在医学影像领域尤其困难且成本高昂，因为只有专家才能提供可靠且准确的注释。半监督学习作为一种有吸引力的策略应运而生，并被广泛应用于医学图像分割任务，以利用有限的注释训练深度模型。本文提供了对近期提出的医学图像分割半监督学习方法的全面综述，总结了技术创新和实证结果。此外，我们还分析和讨论了现有方法的局限性和若干未解决的问题。我们希望这篇综述能激发研究界探索解决这一挑战的方案，并进一步推动医学图像分割领域的发展。
- en: 'keywords:'
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: \sepMedical Image Segmentation, \sepSemi-Supervised Learning,\sepConvolutional
    Neural Network, \sepSurvey.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: \sep医学图像分割，\sep半监督学习，\sep卷积神经网络，\sep综述。
- en: 1 Introduction
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Medical image segmentation aims to delineate the interested anatomical structures
    like organs and tumors from the original images by labeling each pixel into a
    certain class, which is a basic and important step for many clinical approaches
    like computer-aided diagnosis, treatment planning and radiation therapy [[1](#bib.bib1),
    [4](#bib.bib4)]. Accurate segmentation can provide reliable volumetric and shape
    information so as to assist in further clinical applications like disease diagnosis
    and quantitative analysis [[23](#bib.bib23), [24](#bib.bib24), [6](#bib.bib6)].
    According to the word cloud of paper titles in the 25rd International Conference
    and Medical Image Computing and Computer Assisted Intervention ¹¹1http://miccai2022.org
    (MICCAI 2022) in Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation"), we can observe that "segmentation" is one of the most active research
    topics and has the highest frequency in medical image analysis community.'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 医学图像分割的目标是通过将每个像素标记为某一类别，从原始图像中描绘出感兴趣的解剖结构，如器官和肿瘤，这是许多临床方法如计算机辅助诊断、治疗规划和放射治疗的基本且重要的一步[[1](#bib.bib1),
    [4](#bib.bib4)]。准确的分割可以提供可靠的体积和形状信息，以便辅助进一步的临床应用，如疾病诊断和定量分析[[23](#bib.bib23),
    [24](#bib.bib24), [6](#bib.bib6)]。根据图[1](#S1.F1 "图 1 ‣ 1 引言 ‣ 具有有限标注的学习：医学图像分割深度半监督学习的综述")中第25届国际医学图像计算与计算机辅助干预会议（MICCAI
    2022）的论文标题词云图，我们可以观察到“分割”是医学图像分析社区中最活跃的研究主题之一，并且频率最高。
- en: '![Refer to caption](img/5f72365c5983cb0e57e5e0af715d91c3.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/5f72365c5983cb0e57e5e0af715d91c3.png)'
- en: 'Figure 1: Word cloud of paper titles in MICCAI 2022.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：MICCAI 2022会议论文标题的词云图。
- en: Since the introduction of U-Net [[38](#bib.bib38), [39](#bib.bib39)] for medical
    image segmentation in 2015, many variants of encoder-decoder architecture have
    been proposed to improve it by re-designing skip connections [[42](#bib.bib42)],
    incorporating residual/dense convolution blocks [[8](#bib.bib8), [41](#bib.bib41)],
    attention mechanisms [[52](#bib.bib52), [211](#bib.bib211), [43](#bib.bib43)],
    etc. Moreover, nnU-Net (no-new-U-Net) [[49](#bib.bib49)] can automatically configure
    the strategies of pre-processing, the network architecture, the training, the
    inference, and the post-processing to a given dataset for medical image segmentation
    based on the encoder-decoder structure of U-Net. Without manual intervention,
    nnU-Net surpasses most existing approaches and achieves the state-of-the-art performance
    in several fully supervised medical image segmentation tasks. Inspired by recent
    success of transformer architectures in the field of natural language processing,
    many transformer-based methods have been proposed and applied for medical image
    segmentation [[11](#bib.bib11), [13](#bib.bib13)]. Although these architectural
    advancements have shown encouraging results and achieved state-of-the-art performances
    in many medical image segmentation tasks [[10](#bib.bib10)], these methods still
    require relatively large amount of high-quality annotated data for training, more
    than ever. However, it is impractical to obtain large-scale carefully-labeled
    datasets to train segmentation models, particularly for medical imaging where
    it is hard and expensive to obtain well-annotated data where only experts can
    provide reliable and accurate annotations [[25](#bib.bib25)]. Besides, many commonly
    used medical images like computed tomography (CT) and magnetic resonance imaging
    (MRI) scans are 3D volumetric data, which further increase the burden of manual
    annotation compared with 2D images where experts need to delineate the object
    from the volume slice by slice [[64](#bib.bib64)].
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自2015年引入U-Net [[38](#bib.bib38), [39](#bib.bib39)] 用于医学图像分割以来，已经提出了许多变体的编码器-解码器架构，通过重新设计跳跃连接
    [[42](#bib.bib42)]、结合残差/密集卷积块 [[8](#bib.bib8), [41](#bib.bib41)]、注意力机制 [[52](#bib.bib52),
    [211](#bib.bib211), [43](#bib.bib43)] 等来改进它。此外，nnU-Net (no-new-U-Net) [[49](#bib.bib49)]
    可以自动配置医学图像分割的预处理、网络架构、训练、推断和后处理策略，基于U-Net的编码器-解码器结构。无需人工干预，nnU-Net 超越了大多数现有方法，在多个全监督医学图像分割任务中达到了*最先进的*性能。受到最近在自然语言处理领域中变压器架构成功的启发，许多基于变压器的方法已经被提出并应用于医学图像分割
    [[11](#bib.bib11), [13](#bib.bib13)]。尽管这些架构的进展在许多医学图像分割任务中取得了令人鼓舞的结果并达到了*最先进的*性能
    [[10](#bib.bib10)]，但这些方法仍然需要比以往更多的高质量标注数据用于训练。然而，获取大规模精心标注的数据集以训练分割模型是不切实际的，尤其是在医学成像领域，因为获取高质量标注数据既困难又昂贵，只有专家才能提供可靠和准确的标注
    [[25](#bib.bib25)]。此外，许多常用的医学图像如计算机断层扫描（CT）和磁共振成像（MRI）扫描是3D体积数据，这进一步增加了相对于2D图像的人工标注负担，因为专家需要逐层划定体积中的对象
    [[64](#bib.bib64)]。
- en: 'To ease the manual labeling burden in response to these challenges, significant
    efforts have been devoted to annotation-efficient deep learning methods for medical
    image segmentation tasks by enlarging the training data through label generation[[12](#bib.bib12)],
    data augmentation [[7](#bib.bib7)], leveraging external related labeled datasets
    [[26](#bib.bib26)], and leveraging unlabeled data with semi-supervised learning.
    Among these approaches, semi-supervised segmentation is a more practical method
    by encouraging segmentation models to utilize unlabeled data which is much easier
    to acquire in conjunction with limited amount of labeled data for training, which
    has a high impact on real-world clinical applications. According to the statistics
    in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation"), semi-supervised
    medical image segmentation has obtained increasing attention from the medical
    imaging and computer vision community in recent years. However, without expert-examined
    annotations, it is still an open and challenging question on how to efficiently
    exploit useful information from these unlabeled data.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对这些挑战并减轻人工标注的负担，已投入大量努力于通过标签生成[[12](#bib.bib12)]、数据增强[[7](#bib.bib7)]、利用外部相关标注数据集[[26](#bib.bib26)]和利用半监督学习的无标注数据，来提高医学图像分割任务的注释效率。在这些方法中，半监督分割是一种更实际的方法，通过鼓励分割模型利用无标注数据，这些数据比有限的标注数据更容易获取，对实际临床应用有很大影响。根据图[2](#S1.F2
    "图2 ‣ 1 引言 ‣ 使用有限注释进行学习：深度半监督医学图像分割的综述")中的统计数据，近年来半监督医学图像分割获得了医学成像和计算机视觉领域的越来越多关注。然而，在没有专家审核的注释的情况下，如何有效地从这些无标注数据中挖掘有用信息仍然是一个开放而具有挑战性的问题。
- en: '![Refer to caption](img/a3816d79d0722460cd2c29b1bf2c75db.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a3816d79d0722460cd2c29b1bf2c75db.png)'
- en: 'Figure 2: Statistics of papers retrieved from Web of Science on semi-supervised
    medical image segmentation.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：从Web of Science中检索到的关于半监督医学图像分割的论文统计数据。
- en: Main contributions. Compared with related surveys[[27](#bib.bib27), [25](#bib.bib25)],
    we mainly focus on deep semi-supervised medical image segmentation. And we provide
    a comprehensive review of recent solutions, summarizing both the technical novelties
    and empirical results. Furthermore, we analyze and discussed the limitations and
    several unsolved problems of existing approaches. We hope this review could inspire
    the research community to explore solutions for this challenge and further promote
    the developments in medical image segmentation field.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 主要贡献。与相关综述[[27](#bib.bib27), [25](#bib.bib25)]相比，我们主要关注深度半监督医学图像分割。我们提供了对近期解决方案的全面回顾，总结了技术创新和实证结果。此外，我们分析和讨论了现有方法的局限性以及若干未解决的问题。我们希望这篇综述能激发研究界探索该挑战的解决方案，并进一步推动医学图像分割领域的发展。
- en: '![Refer to caption](img/fb925a00af8748e311d06377245e09db.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fb925a00af8748e311d06377245e09db.png)'
- en: 'Figure 3: Example comparison of supervised learning and semi-supervised learning.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：监督学习与半监督学习的示例对比。
- en: '![Refer to caption](img/2effc8ed17f1cd224a91281afbf96b38.png)'
  id: totrans-33
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2effc8ed17f1cd224a91281afbf96b38.png)'
- en: 'Figure 4: The overview of existing deep semi-supervised learning methods for
    medical image segmentation.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：现有深度半监督学习方法在医学图像分割中的概述。
- en: 2 Preliminaries
  id: totrans-35
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 前言
- en: 2.1 Basic Formulation of Semi-Supervised Learning
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 半监督学习的基本公式
- en: Semi-supervised learning aims to utilize large amount of unlabeled data in conjunction
    with labeled data to train higher-performing segmentation models. To ease the
    description in the following sections, we formulate the semi-supervised learning
    task as follows.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习旨在利用大量无标注数据与标注数据相结合，训练性能更高的分割模型。为了简化接下来的描述，我们将半监督学习任务公式化如下。
- en: Given a dataset $\mathcal{D}$ for training, we denote the labeled set with $M$
    labeled cases as $\mathcal{D}_{L}=\{x_{i}^{l},y_{i}\}_{i=1}^{M}$, and the unlabeled
    set with $N$ unlabeled cases as $\mathcal{D}_{U}=\{x_{i}^{u}\}_{i=1}^{N}$, where
    $x_{i}^{l}$ and $x_{i}^{u}$ denote the input images and $y_{i}$ denotes the corresponding
    ground truth of labeled data. Generally, $\mathcal{D}_{L}$ is a relative small
    subset of the entire dataset $\mathcal{D}$, which means $M\ll N$. For semi-supervised
    segmentation settings, we aim at building a data-efficient deep learning model
    with the combination of $\mathcal{D}_{L}$ and $\mathcal{D}_{U}$ and making the
    performance to be comparable to an optimal model trained over fully labeled dataset.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个用于训练的数据集 $\mathcal{D}$，我们用 $M$ 个标记样本表示标记集为 $\mathcal{D}_{L}=\{x_{i}^{l},y_{i}\}_{i=1}^{M}$，用
    $N$ 个未标记样本表示未标记集为 $\mathcal{D}_{U}=\{x_{i}^{u}\}_{i=1}^{N}$，其中 $x_{i}^{l}$ 和 $x_{i}^{u}$
    表示输入图像，$y_{i}$ 表示标记数据的对应真实值。通常，$\mathcal{D}_{L}$ 是整个数据集 $\mathcal{D}$ 的一个相对较小的子集，即
    $M\ll N$。对于半监督分割设置，我们的目标是利用 $\mathcal{D}_{L}$ 和 $\mathcal{D}_{U}$ 的结合建立一个数据高效的深度学习模型，并使其性能可与在完全标记数据集上训练的最优模型相媲美。
- en: 'Based on whether test data are wholly available in the training process, semi-supervised
    learning can be classified into two settings: the transductive learning and the
    inductive learning. For transductive learning, it is assumed that the unlabeled
    samples in the training process are exactly the data to be predicted (i.e. the
    test set), and the purpose of the transductive learning is to generalize the model
    over these unlabeled samples. While for inductive learning, the semi-supervised
    model will be applied to new unseen data.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 根据测试数据在训练过程中是否完全可用，半监督学习可以分为两种设置：传导学习和归纳学习。对于传导学习，假设训练过程中的未标记样本正是要预测的数据（即测试集），传导学习的目的是对这些未标记样本进行模型推广。而对于归纳学习，半监督模型将应用于新的未见数据。
- en: 2.2 Assumptions for Semi-Supervised Learning
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 半监督学习的假设
- en: 'For semi-supervised learning, an essential prerequisite is that the data distribution
    should be under some assumptions. Otherwise, it is impossible to generalize from
    a finite training set to an infinite invisible set. The three basic assumptions
    for semi-supervised learning include [[204](#bib.bib204), [205](#bib.bib205)]:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 对于半监督学习，一个重要的前提是数据分布应满足某些假设。否则，从有限的训练集推广到无限的不可见集将是不可能的。半监督学习的三个基本假设包括[[204](#bib.bib204),
    [205](#bib.bib205)]：
- en: The Cluster Assumption. When two samples $x_{1}$ and $x_{2}$ are similar or
    belong to the same cluster, their corresponding outputs $y_{1}$ and $y_{2}$ should
    also be similar or belong to the same category, and vice versa. This assumption
    implies that the samples in a single class tend to form a cluster.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 聚类假设。当两个样本 $x_{1}$ 和 $x_{2}$ 相似或属于同一簇时，它们对应的输出 $y_{1}$ 和 $y_{2}$ 也应相似或属于同一类别，反之亦然。这个假设暗示了单一类别中的样本倾向于形成一个簇。
- en: Low-density Separation. The decision boundary should be positioned in low-density
    regions of the feature space rather than high-density regions. This assumption
    is closely tied to the cluster assumption as it implies that samples belonging
    to the same class tend to be concentrated in the same cluster. Therefore, a large
    amount of unlabeled data can be used to adjust the decision boundary.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 低密度分离。决策边界应位于特征空间的低密度区域，而非高密度区域。这个假设与聚类假设紧密相关，因为它暗示属于同一类别的样本倾向于集中在同一簇中。因此，可以利用大量的未标记数据来调整决策边界。
- en: The Manifold Assumption. If two samples $x_{1}$ and $x_{2}$ reside in a local
    neighborhood within a low-dimensional manifold, they are likely to possess similar
    class labels. This assumption reflects the local smoothness of the decision boundary
    and encourages nearby samples in the feature space to have the same predictions.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 多样本假设。如果两个样本 $x_{1}$ 和 $x_{2}$ 位于低维流形中的局部邻域内，它们可能具有相似的类别标签。这个假设反映了决策边界的局部平滑性，并鼓励特征空间中的相邻样本具有相同的预测。
- en: 3 Related Work on Semi-Supervised Medical Image Segmentation
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 半监督医学图像分割的相关工作
- en: 'In this section, we mainly divide these semi-supervised medical image segmentation
    methods into three strategies as follows:'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们主要将这些半监督医学图像分割方法分为以下三种策略：
- en: 1) semi-supervised learning with pseudo labels, where unlabeled images are firstly
    predicted and pseudo labeled by a segmentation model and then used as new examples
    for further training.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 1) 带伪标签的半监督学习，其中未标记的图像首先由分割模型进行预测和伪标记，然后作为新示例用于进一步训练。
- en: 2) semi-supervised learning with unsupervised regularization, where unlabeled
    images are used jointly with labeled data to train a segmentation model with unsupervised
    regularization. This section mainly contains consistency learning, co-training,
    adversarial learning, entropy minimization.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 带无监督正则化的半监督学习，其中未标记的图像与标记数据共同用于训练带有无监督正则化的分割模型。本节主要包含一致性学习、共同训练、对抗学习、熵最小化。
- en: 3) semi-supervised learning with knowledge priors, where unlabeled images is
    utilized to enable the model with knowledge priors like the shape and position
    of the targets to improve the representation ability for medical image segmentation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 3) 带有知识先验的半监督学习，其中未标记的图像被用于赋予模型如目标的形状和位置等知识先验，以提高医疗图像分割的表征能力。
- en: 'Table 1: The summarized review of semi-supervised medical image segmentation
    methods with pseudo labels.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 带伪标签的半监督医学图像分割方法的总结评论'
- en: '| Reference | 2D/3D | Modality | Dataset | Label generation methods |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 2D/3D | 模态 | 数据集 | 标签生成方法 |'
- en: '| PLRS, Thompson et al. [[82](#bib.bib82)] | 3D | MRI | BraTS 2020 [[128](#bib.bib128)]
    | Superpixel maps calculated by simple linear iterative clustering (SLIC) algorithm
    [[83](#bib.bib83)] to refine pseudo labels [online]. |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| PLRS, Thompson et al. [[82](#bib.bib82)] | 3D | MRI | BraTS 2020 [[128](#bib.bib128)]
    | 通过简单线性迭代聚类 (SLIC) 算法 [[83](#bib.bib83)] 计算超像素图以精炼伪标签 [在线] |'
- en: '| SSA-Net, Wang et al. [[109](#bib.bib109)] | 2D | CT | COVID-19-CT-Seg dataset
    [[16](#bib.bib16)], COVID-19 CT Segmentation dataset ¹¹10 | Add a trust module
    to re-evaluate the pseudo labels from the model outputs [online]. |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| SSA-Net, Wang et al. [[109](#bib.bib109)] | 2D | CT | COVID-19-CT-Seg 数据集
    [[16](#bib.bib16)], COVID-19 CT Segmentation 数据集 ¹¹10 | 添加信任模块以重新评估模型输出中的伪标签 [在线]
    |'
- en: '| CoraNet, Shi et al. [[87](#bib.bib87)] | 2D/3D | CT, MRI | Pancreas CT [[130](#bib.bib130)],
    MR Endocardium [[167](#bib.bib167)], ACDC [[22](#bib.bib22)] | Conservative-radical
    network to generate more reliable results [online]. |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| CoraNet, Shi et al. [[87](#bib.bib87)] | 2D/3D | CT, MRI | 胰腺 CT [[130](#bib.bib130)],
    MR 内膜 [[167](#bib.bib167)], ACDC [[22](#bib.bib22)] | 保守-激进网络以生成更可靠的结果 [在线] |'
- en: '| ECLR, Zhang et al. [[72](#bib.bib72)] | 2D | Microscope | Gland Segmentation
    Challenge dataset [[189](#bib.bib189)], ColoRectal Adenocarcinoma Gland (CRAG)[[168](#bib.bib168)]
    | Add an error prediction network to divide segmentation errors into intra-class
    inconsistency or inter-class similarity problems [online]. |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| ECLR, Zhang et al. [[72](#bib.bib72)] | 2D | 显微镜 | 腺体分割挑战数据集 [[189](#bib.bib189)],
    结直肠腺癌腺体 (CRAG) [[168](#bib.bib168)] | 添加错误预测网络以将分割错误划分为类内不一致或类间相似性问题 [在线] |'
- en: '| SECT, Li et al. [[136](#bib.bib136)] | 2D | CT | UESTC-COVID-19 Dataset[[169](#bib.bib169)],
    COVID-19-CT-Seg dataset [[16](#bib.bib16)] | Self-ensembling strategy to build
    the up-to-date predictions via exponential moving average [online]. |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| SECT, Li et al. [[136](#bib.bib136)] | 2D | CT | UESTC-COVID-19 数据集[[169](#bib.bib169)],
    COVID-19-CT-Seg 数据集 [[16](#bib.bib16)] | 通过指数移动平均[在线]构建最新的预测 |'
- en: '| LoL-SSL, Han et al.[[69](#bib.bib69)] | 2D | CT | part of LiTS dataset[[17](#bib.bib17)]
    | Generate class representations from labeled data based on prototype learning
    [label propagation]. |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| LoL-SSL, Han et al. [[69](#bib.bib69)] | 2D | CT | 部分 LiTS 数据集[[17](#bib.bib17)]
    | 基于原型学习 [标签传播] 从标记数据中生成类别表示 |'
- en: '| NM-SSL, Wang et al. [[92](#bib.bib92)] | 2D | X-Ray, Dermoscopic | ISIC Skin
    [[19](#bib.bib19)], Chexpert [[20](#bib.bib20)] | Neighbor matching to generate
    pseudo-labels on a weight basis according to the embedding similarity with neighboring
    labeled data [label propagation]. |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| NM-SSL, Wang et al. [[92](#bib.bib92)] | 2D | X-Ray, 皮肤镜 | ISIC 皮肤 [[19](#bib.bib19)],
    Chexpert [[20](#bib.bib20)] | 邻域匹配根据与邻近标记数据的嵌入相似性生成伪标签 [标签传播] |'
- en: '| RPG, Seibold et al. [[86](#bib.bib86)] | 2D | X-Ray | JSRT dataset[[15](#bib.bib15)]
    | Generate pseudo labels through transferring semantics [label propagation]. |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| RPG, Seibold et al. [[86](#bib.bib86)] | 2D | X-Ray | JSRT 数据集[[15](#bib.bib15)]
    | 通过转移语义 [标签传播] 生成伪标签 |'
- en: 1\. https://medicalsegmentation.com/covid19/
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. https://medicalsegmentation.com/covid19/
- en: 3.1 Semi-Supervised Medical Image Segmentation with Pseudo Labels
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 带伪标签的半监督医学图像分割
- en: 'To utilize unlabeled data, a direct and intuitive method is assigning pseudo
    annotations for unlabeled images, and then using the pseudo labeled images in
    conjunction with labeled images to update the segmentation model. Pseudo labeling
    is commonly implemented in an iterative manner therefore the model can improve
    the quality of pseudo annotations iteratively. Algorithm [1](#alg1 "Algorithm
    1 ‣ 3.1 Semi-Supervised Medical Image Segmentation with Pseudo Labels ‣ 3 Related
    Work on Semi-Supervised Medical Image Segmentation ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation") presents
    the overall workflow of this strategy.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '为了利用未标记的数据，一个直接且直观的方法是为未标记的图像分配伪注释，然后将伪标记的图像与标记的图像一起使用，以更新分割模型。伪标记通常以迭代的方式实现，因此模型可以逐步提高伪注释的质量。算法
    [1](#alg1 "Algorithm 1 ‣ 3.1 Semi-Supervised Medical Image Segmentation with Pseudo
    Labels ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning
    with Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical
    Image Segmentation") 展示了这一策略的整体工作流程。'
- en: Firstly, an initial segmentation model is trained using limited labeled data.
    The initial segmentation model is then applied to unlabeled data to generate pseudo
    segmentation masks. After that, pseudo-labeled dataset is then merged with labeled
    dataset to update the initial model. The training procedure alternates between
    the two steps introduced above, until a predefined iteration number.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用有限的标记数据训练初始分割模型。然后，将初始分割模型应用于未标记数据，以生成伪分割掩码。之后，将伪标记的数据集与标记的数据集合并，以更新初始模型。训练过程在上述两个步骤之间交替进行，直到达到预定义的迭代次数。
- en: Algorithm 1 Training procedure of semi-supervised learning with pseudo labels.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 半监督学习中伪标签的训练过程。
- en: 0:   $\{x^{l},y^{l}\}$ from labeled dataset $D_{L}$, $\{x^{u}\}$ from unlabeled
    dataset $D_{U}$, initial segmentation model $\mathcal{M}_{0}$, iteration times
    $\mathcal{T}$0:  Trained segmentation model $\mathcal{M}_{\mathcal{T}}$1:  Training
    initial segmentation model $\mathcal{M}_{0}$ with $D_{L}$2:  for $i\leftarrow
    1$ to $\mathcal{T}$ do3:     Generate pseudo labels $\{\hat{y}^{u}\}$ of unlabeled
    cases $\{x^{u}\}$ with model $\mathcal{M}_{i-1}$4:     Generate new training dataset
    $D_{PLi}$ with the combination of labeled dataset $\{x^{l},y^{l}\}$ and pseudo
    labeled dataset with $\{x^{u},\hat{y}^{u}\}$5:     $\mathcal{M}_{i}$ $\leftarrow$
    Fine-tuning model $\mathcal{M}_{i-1}$ using $D_{PLi}$6:  end for7:  return  Updated
    model $\mathcal{M}_{\mathcal{T}}$
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '0:   $\{x^{l},y^{l}\}$ 来自标记数据集 $D_{L}$，$\{x^{u}\}$ 来自未标记数据集 $D_{U}$，初始分割模型
    $\mathcal{M}_{0}$，迭代次数 $\mathcal{T}$0:  训练的分割模型 $\mathcal{M}_{\mathcal{T}}$1:  使用
    $D_{L}$ 训练初始分割模型 $\mathcal{M}_{0}$2:  对于 $i\leftarrow 1$ 到 $\mathcal{T}$  做3:     使用模型
    $\mathcal{M}_{i-1}$ 生成未标记样本 $\{x^{u}\}$ 的伪标签 $\{\hat{y}^{u}\}$4:     通过将标记数据集
    $\{x^{l},y^{l}\}$ 和伪标记数据集 $\{x^{u},\hat{y}^{u}\}$ 组合生成新的训练数据集 $D_{PLi}$5:     $\mathcal{M}_{i}$
    $\leftarrow$ 使用 $D_{PLi}$ 微调模型 $\mathcal{M}_{i-1}$6:  结束 7:  返回 更新后的模型 $\mathcal{M}_{\mathcal{T}}$'
- en: 'Within this strategy for semi-supervised learning, these methods mainly differ
    in the model initialization, generation of pseudo labels, and how the noise in
    pseudo labels is handled. The outputs of an under-trained segmentation model with
    limited labeled data are noisy. If these noisy outputs are used as pseudo labels
    directly, it may make the subsequent training process unstable and hurt the performance
    [[145](#bib.bib145)]. For better leverage of the pseudo labels with potential
    noise, lots of methods have been proposed. In this section, we will explain the
    generation of pseudo-labels from two aspects: online generation followed by removing
    noisy predictions and label propagation.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在半监督学习的这一策略中，这些方法主要在模型初始化、伪标签生成以及如何处理伪标签中的噪声上有所不同。使用有限标记数据的欠训练分割模型的输出是噪声较大的。如果直接将这些噪声输出用作伪标签，可能会使后续训练过程不稳定并影响性能
    [[145](#bib.bib145)]。为了更好地利用具有潜在噪声的伪标签，已经提出了许多方法。在这一部分，我们将从两个方面解释伪标签的生成：在线生成后去除噪声预测和标签传播。
- en: 'Online generation Pseudo labels are mostly generated through the predictions
    of a trained model in an online manner followed by some post-processing algorithms
    for refinement. A common method is to choose unlabeled pixels with maximum predicted
    probability greater than the setting threshold. However, the predictions can be
    noisy and unreliable, and may provide incorrect guidance. It is unreasonable to
    set the same threshold fit for all the samples. In [[213](#bib.bib213)], double-threshold
    pseudo labeling is introduced, in which predictions from the classification branch
    and the segmentation branch jointly determine the reliable pseudo labels. Based
    on the work in [[109](#bib.bib109), [145](#bib.bib145)], the pseudo labels with
    higher confidence are usually more effective. Therefore, many confidence- or uncertainty-aware
    methods are proposed to generate more stable and reliable pseudo labels. For example,
    Yao et al. [[68](#bib.bib68)] propose a confidence-aware cross pseudo supervision
    network to improve the pseudo label quality of unlabeled images from unknown distributions.
    Specifically, the input image from source domain is perturbed with the amplitude
    of the target domain through the Fourier transformation to generate the transformed
    image. The pixel-wise KL-divergence of the predictions of the original and transformed
    images is calculated as the variance $V$, which is then used to calculate the
    pixel-wise confidence. Pseudo labels with high confidence are selected for loss
    calculation. This process is shown as follows:'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 在线生成伪标签通常通过经过训练的模型在线预测生成，然后经过一些后处理算法进行精炼。一种常见的方法是选择预测概率大于设定阈值的未标记像素。然而，预测可能会有噪声且不可靠，可能提供错误的指导。为所有样本设置相同的阈值是不合理的。在
    [[213](#bib.bib213)] 中，引入了双阈值伪标签，其中分类分支和分割分支的预测共同决定可靠的伪标签。基于 [[109](#bib.bib109),
    [145](#bib.bib145)] 的工作，通常情况下，置信度更高的伪标签更有效。因此，许多基于置信度或不确定性的方法被提出以生成更稳定和可靠的伪标签。例如，Yao
    等人 [[68](#bib.bib68)] 提出了一个基于置信度的交叉伪监督网络，以改善来自未知分布的未标记图像的伪标签质量。具体来说，通过傅里叶变换将源域的输入图像与目标域的幅度扰动生成变换图像。计算原始图像和变换图像预测的像素级
    KL 散度作为方差 $V$，然后用来计算像素级置信度。高置信度的伪标签被选择用于损失计算。此过程如下所示：
- en: '|  | $\begin{split}V=E[P_{F}\log(\frac{P_{F}}{P_{O}})]\end{split}$ |  | (1)
    |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}V=E[P_{F}\log(\frac{P_{F}}{P_{O}})]\end{split}$ |  | (1)
    |'
- en: '|  | $\begin{split}confidence=e^{-V}\end{split}$ |  | (2) |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}confidence=e^{-V}\end{split}$ |  | (2) |'
- en: where, $P_{F}$ and $P_{O}$ represent the predictions of the transformed images
    and original images. Wang et al. [[109](#bib.bib109)] add a trust module to re-evaluate
    the pseudo labels from the model outputs and set a threshold to choose high confidence
    values. Except adding confidence-aware modules, Li et al. [[136](#bib.bib136)]
    propose a self-ensembling strategy to build the up-to-date predictions via exponential
    moving average to avoid noisy and unstable pseudo labels. For post-processing
    algorithms, morphological methods, machine learning methods [[83](#bib.bib83)]
    and additional networks [[87](#bib.bib87), [72](#bib.bib72)] are usually used
    to further refine pseudo labels. For example, superpixel maps calculated by simple
    linear iterative clustering (SLIC) algorithm [[83](#bib.bib83)] are introduced
    to refine pseudo labels in [[82](#bib.bib82)]. This algorithm is suitable for
    segmentation of targets with irregular shapes. Shi et al. [[87](#bib.bib87)] propose
    a conservative-radical network. The object conservative setting tends to predict
    pixels into background while the object radical setting tends to predict pixels
    into foreground. The certain region in predictions of unlabeled data is the overlap
    between conservative and radical settings and employed as pseudo labels. Zhang
    et al. [[72](#bib.bib72)] rectify the segmentation results of unlabeled data through
    another error segmentation network followed by the main segmentation network.
    The segmentation errors are divided into intra-class inconsistency or inter-class
    similarity problems. This method is applicable for different segmentation models
    and tasks. Recently, vision foundation models such as Segment Anything Model (SAM)
    [[202](#bib.bib202)], have shown their amazing capabilities and generalization
    abilities. [[209](#bib.bib209)] hypothesized that reliable pseudo-labels usually
    make SAM [[202](#bib.bib202)] conduct predictions consistent with the SSL models.
    So predictions of the SSL models are used as prompts to the SAM [[202](#bib.bib202)]
    to select reliable pseudo-labels. Then the SSL models are retrained with the reliable
    sets. This method shows a superior performance compared with existing SSL algorithms.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$P_{F}$ 和 $P_{O}$ 代表了变换图像和原始图像的预测。Wang 等人[[109](#bib.bib109)] 添加了一个信任模块，以重新评估模型输出的伪标签，并设置了一个阈值以选择高置信度的值。除了添加关注置信度的模块外，Li
    等人[[136](#bib.bib136)] 提出了自我集成策略，通过指数移动平均建立最新的预测，以避免嘈杂和不稳定的伪标签。对于后处理算法，通常使用形态学方法、机器学习方法[[83](#bib.bib83)]和额外的网络[[87](#bib.bib87),
    [72](#bib.bib72)]进一步细化伪标签。例如，使用简单线性迭代聚类（SLIC）算法[[83](#bib.bib83)]计算的超像素图被引入[[82](#bib.bib82)]以细化伪标签。该算法适用于不规则形状目标的分割。Shi
    等人[[87](#bib.bib87)] 提出了保守-激进网络。对象保守设置倾向于将像素预测为背景，而对象激进设置倾向于将像素预测为前景。在未标记数据的预测中，保守与激进设置之间的某些区域作为伪标签。Zhang
    等人[[72](#bib.bib72)] 通过另一个错误分割网络对未标记数据的分割结果进行修正，然后进行主分割网络。分割错误被划分为类内不一致或类间相似性问题。这种方法适用于不同的分割模型和任务。最近，视觉基础模型如Segment
    Anything Model (SAM) [[202](#bib.bib202)] 展现了其惊人的能力和泛化能力。[[209](#bib.bib209)]
    假设可靠的伪标签通常使SAM [[202](#bib.bib202)] 的预测与SSL模型一致。因此，SSL模型的预测被用作SAM [[202](#bib.bib202)]
    选择可靠伪标签的提示。然后，使用可靠的数据集对SSL模型进行重新训练。这种方法相比于现有的SSL算法表现出优越的性能。
- en: 'Label propagation Pseudo labels can be generated indirectly through label propagation
    e.g. prototype learning[[69](#bib.bib69)] and nearest-neighbor matching[[92](#bib.bib92),
    [86](#bib.bib86)]. However, these indirect generation ways are time-consuming
    and demand higher memory consumption, mostly in an offline manner. For example,
    Han et al. [[69](#bib.bib69)] generate class representations from labeled data
    based on prototype learning. Through calculating the distances between feature
    vectors of unlabeled images and each class representation followed by a series
    morphological operations, high-quality pseudo labels are then generated. However,
    this prototype learning-based label propagation strategy requests high quality
    and representative feature extraction. For neighbor matching methods, Wang et
    al. [[92](#bib.bib92)] generate pseudo-labels on a weight basis according to the
    embedding similarity with neighboring labeled data. [[86](#bib.bib86)] generate
    pseudo labels through transferring semantics that have a best fit with the unlabeled
    data in feature space among a pool of labeled reference images, as shown in Figure
    [5](#S3.F5 "Figure 5 ‣ 3.1 Semi-Supervised Medical Image Segmentation with Pseudo
    Labels ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning
    with Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical
    Image Segmentation"). Compared with network prediction-based pseudo label generation
    methods, label propagation-based pseudo label generation can avoid confirmation
    bias. Confirmation bias, which refers to the tendency a model to favor information
    that confirms its existing assumptions, while disregarding information that contradicts
    them, can be caused by the unbalanced training data and usually exists in network
    prediction-based pseudo label generation methods. In conclusion, these label propagation
    methods can premeditate the relations among data points with labeled dataset.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '标签传播 伪标签可以通过标签传播间接生成，例如原型学习[[69](#bib.bib69)]和最近邻匹配[[92](#bib.bib92), [86](#bib.bib86)]。然而，这些间接生成的方法是时间消耗大的，并且需要更高的内存消耗，大多数情况下是在离线模式下进行的。例如，Han等人[[69](#bib.bib69)]基于原型学习从标注数据中生成类表示。通过计算未标注图像的特征向量与每个类表示之间的距离，并经过一系列形态学操作，生成高质量的伪标签。然而，这种基于原型学习的标签传播策略要求高质量和具有代表性的特征提取。对于邻域匹配方法，Wang等人[[92](#bib.bib92)]根据与邻近标注数据的嵌入相似度生成基于权重的伪标签。[[86](#bib.bib86)]
    通过在特征空间中从标注参考图像池中转移最符合未标注数据的语义生成伪标签，如图 [5](#S3.F5 "Figure 5 ‣ 3.1 Semi-Supervised
    Medical Image Segmentation with Pseudo Labels ‣ 3 Related Work on Semi-Supervised
    Medical Image Segmentation ‣ Learning with Limited Annotations: A Survey on Deep
    Semi-supervised Learning for Medical Image Segmentation") 所示。与基于网络预测的伪标签生成方法相比，基于标签传播的伪标签生成方法可以避免确认偏差。确认偏差指的是模型倾向于偏向那些确认其现有假设的信息，同时忽视那些与之矛盾的信息，这种偏差可能由不平衡的训练数据引起，通常存在于基于网络预测的伪标签生成方法中。总之，这些标签传播方法可以预先考虑标注数据集中数据点之间的关系。'
- en: Along with adding more high-confidence pseudo labels, pseudo labeling encourages
    low-density separation between classes. The quality of pseudo labels is the main
    constraint for pseudo labeling strategy. A model is unable to correct its mistakes
    when it overfits to a small labeled data and has confirmation bias. Then wrong
    predictions can be quickly amplified resulting in confident but erroneous pseudo
    labels during the training process [[163](#bib.bib163)]. Thus, how to choose pseudo
    labels that will be added in the next training process and how many iterations
    to repeat need to be further considered.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 随着更多高置信度伪标签的增加，伪标注方法鼓励类之间的低密度分离。伪标签的质量是伪标注策略的主要制约因素。当模型在小规模标注数据上过拟合并存在确认偏差时，它无法纠正自身的错误。这样，错误的预测会在训练过程中迅速放大，导致产生自信但错误的伪标签[[163](#bib.bib163)]。因此，如何选择将在下一个训练过程中添加的伪标签以及需要重复多少次迭代仍需进一步考虑。
- en: '![Refer to caption](img/b0da8a9e130c75d2ef884917d25c1e36.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b0da8a9e130c75d2ef884917d25c1e36.png)'
- en: 'Figure 5: Reference-guided pseudo-label generation [[86](#bib.bib86)]. The
    framework extract features of each unlabeled data and a pool of sampled annotated
    images are employed to generate pseudo-labels. The pseudo-label generation process
    is illustrated on the right, which choose the top-k closest distances in feature
    space among a pool of labeled reference images and transfer their semantics.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：参考引导的伪标签生成 [[86](#bib.bib86)]。该框架提取每个未标记数据的特征，并使用一个样本标注图像的池来生成伪标签。伪标签生成过程在右侧示例中，选择特征空间中与标记参考图像池中距离最近的
    top-k 图像，并转移其语义。
- en: 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
  id: totrans-75
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 半监督医学图像分割与无监督正则化
- en: 'Different from generating pseudo labels and updating the segmentation model
    in an iterative manner, some recent progress in semi-supervised medical image
    segmentation has been focused on incorporating unlabeled data into the training
    procedure with unsupervised regularization like unsupervised loss functions. Algorithm
    [2](#alg2 "Algorithm 2 ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised
    Regularization ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation") presents the overall workflow of this strategy.
    Different choices of the unsupervised loss functions and regularization terms
    lead to different semi-supervised models. Generally, unsupervised regularization
    can be formulated into three sub-categories: consistency learning, co-training
    and entropy minimization.'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '不同于生成伪标签并以迭代方式更新分割模型，最近在半监督医学图像分割方面的一些进展侧重于将未标记数据融入训练过程中，并应用无监督正则化，如无监督损失函数。算法
    [2](#alg2 "Algorithm 2 ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised
    Regularization ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation") 展示了这一策略的整体工作流程。无监督损失函数和正则化项的不同选择会导致不同的半监督模型。一般来说，无监督正则化可以分为三个子类别：一致性学习、协同训练和熵最小化。'
- en: Algorithm 2 Training procedure of semi-supervised learning with unsupervised
    regularization.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 算法2 无监督正则化的半监督学习训练过程。
- en: 0:   $\{x^{l},y^{l}\}$ from labeled dataset $D_{L}$, $\{x^{u}\}$ from unlabeled
    dataset $D_{U}$, segmentation model $\mathcal{M}$0:  Trained segmentation model
    $\mathcal{M}$1:  while not converge do2:     Calculate supervised segmentation
    loss $\mathcal{L}_{sup}(\theta;\mathcal{D}_{L})$3:     Calculate unsupervised
    loss $\mathcal{L}_{unsup}(\theta;\mathcal{D})$4:     Update the segmentation model
    $\mathcal{M}$ with the combination of supervised loss $\mathcal{L}_{sup}$ and
    unsupervised loss $\mathcal{L}_{unsup}$5:  end while6:  return  Trained segmentation
    model $\mathcal{M}$
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: '0:   $\{x^{l},y^{l}\}$ 来自标记数据集 $D_{L}$，$\{x^{u}\}$ 来自未标记数据集 $D_{U}$，分割模型 $\mathcal{M}$0:  训练好的分割模型
    $\mathcal{M}$1:  当未收敛时2:     计算监督分割损失 $\mathcal{L}_{sup}(\theta;\mathcal{D}_{L})$3:     计算无监督损失
    $\mathcal{L}_{unsup}(\theta;\mathcal{D})$4:     通过结合监督损失 $\mathcal{L}_{sup}$ 和无监督损失
    $\mathcal{L}_{unsup}$ 更新分割模型 $\mathcal{M}$5:  结束 当6:  返回 训练好的分割模型 $\mathcal{M}$'
- en: 3.2.1 Unsupervised Regularization with Consistency Learning
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 一致性学习的无监督正则化
- en: 'For unsupervised regularization, consistency learning is widely applied by
    enforcing an invariance of predictions of input images under different perturbations
    and pushing the decision boundary to low-density regions, based on the assumptions
    that the perturbations should not change the output of the model. The consistency
    between two objects can be calculated as follow:'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 对于无监督正则化，广泛应用一致性学习，通过在不同扰动下强制输入图像预测的一致性，并将决策边界推向低密度区域，基于扰动不应改变模型输出的假设。两个对象之间的一致性可以通过以下方式计算：
- en: '|  | $Loss=D[p(x),p^{{}^{\prime}}(T(x)]$ |  | (3) |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '|  | $Loss=D[p(x),p^{{}^{\prime}}(T(x)]$ |  | (3) |'
- en: '$D$ is the similarity measure function, typically using Kullback-Leibler (KL)
    divergence, mean squared error(MSE), Jensen-Shannon divergence(JS) and so on.
    $T(\cdot)$ is augmentation that adds random perturbations on data. $p$ and $p^{{}^{\prime}}$
    represent segmentation models, and their parameters can either be shared or establish
    a connection through certain transformations, such as exponential moving average
    (EMA), or they can be independent of each other. While consistency learning methods
    have shown promising results in semi-supervised medical image segmentation tasks
    due to their simplicity, it has some limitations that need to be considered:'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: $D$是相似度测量函数，通常使用Kullback-Leibler（KL）散度，均方误差（MSE），Jensen-Shannon散度（JS）等。$T(\cdot)$是对数据加入随机扰动的增强。$p$和$p^{{}^{\prime}}$代表分割模型，它们的参数可以共享，也可以通过某些转换建立联系，例如指数移动平均（EMA），或它们可以彼此独立。虽然一致性学习方法在半监督医学图像分割任务中显示出了有希望的结果，但它有一些需要考虑的限制：
- en: '1\. Sensitivity to noise: Consistency learning assumes that small perturbations
    in the input images should not affect the model’s output. However, in practice,
    this assumption may not always hold true as the input data can contain noise or
    outliers. This can lead to the model focusing on these noisy regions during training,
    which may reduce its generalization capability.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 对噪声的敏感性：一致性学习假设输入图像中的小扰动不应影响模型的输出。然而，在实践中，这一假设可能并不总是成立，因为输入数据可能包含噪声或异常值。这可能导致模型在训练过程中关注这些嘈杂的区域，从而降低其泛化能力。
- en: '2\. Hyperparameter tuning: The performance of consistency learning methods
    depends on the choice of hyperparameters. Selecting appropriate hyperparameters
    can be challenging and may require extensive experiments, making it difficult
    to apply these methods in practice.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 超参数调整：一致性学习方法的性能取决于超参数的选择。选择合适的超参数可能具有挑战性，可能需要进行大量实验，这使得难以将这些方法应用到实践中。
- en: '3\. Appropriate perturbations: If the perturbations are too weak, consistency-based
    learning may not work, but strong perturbations may confuse the model, and lead
    to low performance.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 适当的扰动：如果扰动过弱，基于一致性的学习可能不起作用，但强烈的扰动可能使模型混淆，导致性能低下。
- en: 'Common architectures The common architectures used in consistency learning
    in Figure [6](#S3.F6 "Figure 6 ‣ 3.2.1 Unsupervised Regularization with Consistency
    Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation") are illustrated as follows. Sajjadi et al. [[115](#bib.bib115)]
    propose $\Pi$ Model to create two random augmentations of a sample for both labeled
    and unlabeled data. In the training process, the model expects the output of same
    unlabeled sample propagates forward twice under different random perturbations
    to be consistent. Samuli et al. [[30](#bib.bib30)] propose temporal ensembling
    strategy to use EMA predictions for unlabeled data as the consistency targets.
    The basic idea behind temporal ensembling is to train multiple models at different
    time points, and then combine their predictions to make a final prediction. However,
    maintaining the EMA predictions during the training process is a heavy burden.
    To issue the problem, Tarvainen et al. [[29](#bib.bib29)] propose to use a teacher
    model with the EMA weights of the student model for training and enforce the consistency
    of predictions from perturbed inputs between student and teacher models. Thus,
    this mean-teacher architecture is widely employed due to its simplicity. Zeng
    et al. [[95](#bib.bib95)] improve the EMA weighted way in teacher models. They
    add a feedback signal from the performance of the student on the labeled set,
    through which the teacher model can be updated by gradient descent algorithm autonomously
    and purposefully.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 常见架构 图 [6](#S3.F6 "图 6 ‣ 3.2.1 使用一致性学习的无监督正则化 ‣ 3.2 无监督正则化的半监督医学图像分割 ‣ 3 关于半监督医学图像分割的相关工作
    ‣ 有限标注学习：深度半监督学习在医学图像分割中的调查") 中所示的常见架构如下。Sajjadi 等人 [[115](#bib.bib115)] 提出了$\Pi$模型，以创建标记和未标记数据的样本的两个随机增强。在训练过程中，该模型期望相同的未标记样本在不同的随机扰动下向前传播两次保持一致。Samuli
    等人 [[30](#bib.bib30)] 提出了时间集成策略，使用EMA预测作为未标记数据的一致性目标。时间集成的基本思想是训练多个模型在不同的时间点，然后结合它们的预测以做出最终预测。然而，在训练过程中维护EMA预测是一项沉重的负担。为了解决这个问题，Tarvainen
    等人 [[29](#bib.bib29)] 提出了使用带有学生模型EMA权重的教师模型进行训练，并强制学生模型和教师模型之间扰动输入的预测一致。因此，这种mean-teacher架构由于其简单性被广泛采用。Zeng
    等人 [[95](#bib.bib95)] 改进了教师模型中的EMA加权方式。他们通过反馈信号来自标记集上学生的表现，从而使教师模型可以通过梯度下降算法自主和有目的地更新。
- en: '![Refer to caption](img/5c2989eafc5a3fd7760d7821b78e8763.png)![Refer to caption](img/7993645b293816ba95594a824fa54685.png)![Refer
    to caption](img/5c6cfbd47ff6454710c1804e6dbb4841.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5c2989eafc5a3fd7760d7821b78e8763.png)![参见说明](img/7993645b293816ba95594a824fa54685.png)![参见说明](img/5c6cfbd47ff6454710c1804e6dbb4841.png)'
- en: 'Figure 6: The classic architectures used in consistency learning. (a): $\Pi$
    Model [[115](#bib.bib115)] which creates two random augmentations of a sample
    and encourages consistent predictions. (b):Temporal ensembling strategy [[30](#bib.bib30)]
    to use EMA predictions for unlabeled data as the consistency targets. (c):The
    mean-teacher architecture [[29](#bib.bib29)], in which the teacher model is with
    the EMA weights of the student model.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：一致性学习中使用的经典架构。 (a)：$\Pi$模型 [[115](#bib.bib115)]，它创建样本的两个随机增强并鼓励一致的预测。 (b)：时间集成策略
    [[30](#bib.bib30)]，使用EMA预测作为未标记数据的一致性目标。 (c)：mean-teacher架构 [[29](#bib.bib29)]，其中教师模型带有学生模型的EMA权重。
- en: Perturbations utilized for consistency learning can be divided into input perturbations
    and feature map perturbations, which should be meaningful for corresponding task.
    The effect of perturbations on segmentation performance has an upper bound, when
    adding more perturbations, the segmentation performance won’t be further improved
    [[99](#bib.bib99)].
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 用于一致性学习的扰动可以分为输入扰动和特征图扰动，这些扰动应对相应任务有意义。扰动对分割性能的影响有一个上限，当添加更多扰动时，分割性能不会进一步提升
    [[99](#bib.bib99)]。
- en: Input perturbations There are some commonly used input perturbations, such as
    Gaussian noise, Gaussian blurring, randomly rotation, scaling and contrast variations,
    and the segmentation network is encouraged to be transformation-consistent for
    unlabeled data [[61](#bib.bib61)]. Bortsova et al. [[118](#bib.bib118)] explore
    the equivariance to elastic deformations and encourage the segmentation consistency
    between the predictions of the two identical branches which receive differently
    transformed images. Huang et al. [[99](#bib.bib99)] add cutout and slice misalignment
    as input perturbations. Another common perturbation is mix-up augmentation [[146](#bib.bib146),
    [112](#bib.bib112), [76](#bib.bib76)], which encourages the segmentation of interpolation
    of two data to be consistent with the interpolation of segmentation results of
    those data.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 输入扰动常见的有高斯噪声、高斯模糊、随机旋转、缩放和对比度变化，鼓励分割网络对于未标记数据保持变换一致性[[61](#bib.bib61)]。Bortsova
    等人[[118](#bib.bib118)] 探讨了对弹性形变的等变性，并鼓励对接收不同变换图像的两个相同分支之间的预测进行分割一致性检查。Huang 等人[[99](#bib.bib99)]
    在输入扰动中加入了剪切和切片对齐问题。另一个常见的扰动是混合增强[[146](#bib.bib146), [112](#bib.bib112), [76](#bib.bib76)]，它鼓励对两个数据的插值分割结果保持一致。
- en: 'Feature map perturbations Apart from disturbances on input images, there are
    also many studies focusing on disturbances at feature map level. Zheng et al.
    [[89](#bib.bib89)] propose to add random noise to the parameter calculations of
    the teacher model. Xu et al. [[91](#bib.bib91)] propose morphological feature
    perturbations through designing different network architectures, as shown in Figure
    [7](#S3.F7 "Figure 7 ‣ 3.2.1 Unsupervised Regularization with Consistency Learning
    ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation"). Atrous convolutions can enlarge foreground features while skip-connections
    will shrink foreground features [[164](#bib.bib164), [165](#bib.bib165)]. Li et
    al. [[96](#bib.bib96)] add seven types of feature perturbations to seven extra
    decoders and require this seven predictions to be consistent with the main decoder.
    These feature level perturbations are feature noise, feature dropout, object masking,
    context masking, guided cutout, intermediate VAT, and random dropout, based on
    the work in [[156](#bib.bib156)]. Among them, object masking, context masking
    and guided cutout utilize the predictions of the decoder to mask objects or contexts
    in feature maps; intermediate VAT refers to using virtual adversarial training
    as a perturbation function for feature maps. Some studies apply perturbations
    both at the input and feature map levels. For example, Xu et al. [[77](#bib.bib77)]
    propose a novel shadow perturbation which contains shadow augmentation [8(a)](#S3.F8.sf1
    "In Figure 8 ‣ 3.2.1 Unsupervised Regularization with Consistency Learning ‣ 3.2
    Semi-Supervised Medical Image Segmentation with Unsupervised Regularization ‣
    3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with Limited
    Annotations: A Survey on Deep Semi-supervised Learning for Medical Image Segmentation")
    and shadow dropout [8(b)](#S3.F8.sf2 "In Figure 8 ‣ 3.2.1 Unsupervised Regularization
    with Consistency Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation with
    Unsupervised Regularization ‣ 3 Related Work on Semi-Supervised Medical Image
    Segmentation ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation") to simulate the low image quality and
    shadow artifacts in medical images. Specifically, shadow augmentation is a perturbation
    through adding simulated shadow artifacts to the input images while shadow dropout
    will drop neural nodes according to the prior knowledge of the shadow artifacts,
    which is a disturbance acting directly on feature maps. However, if the perturbations
    are too weak, it may cause the student model to memorize these easy variations
    and fit the training data quickly. Finally, the student model fails to discover
    effective features, which is the Lazy Student Phenomenon. But strong perturbations
    may confuse the teacher and student, and lead to low performance. To avoid the
    large gap between the student model and teacher model, Shu et al. [[112](#bib.bib112)]
    add a transductive monitor for further knowledge distillation to narrow the semantic
    gap between the student model and teacher model. Some works [[207](#bib.bib207),
    [208](#bib.bib208), [206](#bib.bib206)] explicitly divide perturbations into strong
    and weak perturbations, and use the prediction from a weakly perturbed input to
    supervise the prediction from its strong perturbed version. These works hold the
    assumption that weakly perturbed inputs can provide reliable predictions whereas
    strongly perturbed ones can improve the learning process and model robustness.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '特征图扰动 除了输入图像上的干扰，还有许多研究集中于特征图级别的干扰。郑等人 [[89](#bib.bib89)] 提出向教师模型的参数计算中添加随机噪声。许等人
    [[91](#bib.bib91)] 通过设计不同的网络架构提出形态特征扰动，如图 [7](#S3.F7 "Figure 7 ‣ 3.2.1 Unsupervised
    Regularization with Consistency Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation
    with Unsupervised Regularization ‣ 3 Related Work on Semi-Supervised Medical Image
    Segmentation ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation") 所示。Atrous 卷积可以放大前景特征，而跳跃连接则会缩小前景特征 [[164](#bib.bib164),
    [165](#bib.bib165)]。李等人 [[96](#bib.bib96)] 向七个额外的解码器中添加了七种特征扰动，并要求这七个预测与主解码器一致。这些特征级别的扰动包括特征噪声、特征丢弃、目标遮罩、上下文遮罩、引导切割、中间
    VAT 和随机丢弃，基于 [[156](#bib.bib156)] 的工作。其中，目标遮罩、上下文遮罩和引导切割利用解码器的预测来遮罩特征图中的目标或上下文；中间
    VAT 指使用虚拟对抗训练作为特征图的扰动函数。一些研究同时在输入和特征图级别应用扰动。例如，许等人 [[77](#bib.bib77)] 提出了一种新颖的阴影扰动，包括阴影增强
    [8(a)](#S3.F8.sf1 "In Figure 8 ‣ 3.2.1 Unsupervised Regularization with Consistency
    Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation") 和阴影丢弃 [8(b)](#S3.F8.sf2 "In Figure 8 ‣ 3.2.1 Unsupervised Regularization
    with Consistency Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation with
    Unsupervised Regularization ‣ 3 Related Work on Semi-Supervised Medical Image
    Segmentation ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation")，以模拟医学图像中的低图像质量和阴影伪影。具体来说，阴影增强是一种通过向输入图像中添加模拟阴影伪影的扰动，而阴影丢弃则根据阴影伪影的先验知识丢弃神经节点，这是一种直接作用于特征图的干扰。然而，如果扰动过于微弱，可能会导致学生模型记住这些简单的变化，并快速拟合训练数据。最终，学生模型未能发现有效特征，这就是懒惰学生现象。但强扰动可能会混淆教师和学生，从而导致性能下降。为了避免学生模型和教师模型之间的差距，舒等人
    [[112](#bib.bib112)] 添加了一个转导监控器以进一步进行知识蒸馏，从而缩小学生模型和教师模型之间的语义差距。一些工作 [[207](#bib.bib207),
    [208](#bib.bib208), [206](#bib.bib206)] 明确将扰动分为强扰动和弱扰动，并利用来自弱扰动输入的预测来监督其强扰动版本的预测。这些工作假设弱扰动输入可以提供可靠的预测，而强扰动输入可以改善学习过程和模型鲁棒性。'
- en: '![Refer to caption](img/a0811ee5e3e95c76395aea7a72904ba5.png)'
  id: totrans-92
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/a0811ee5e3e95c76395aea7a72904ba5.png)'
- en: (a) Atrous convolution [[164](#bib.bib164)] to enlarge foreground features
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 膨胀卷积 [[164](#bib.bib164)] 扩大前景特征
- en: '![Refer to caption](img/d406be621482698e293cd2cf0ddf659d.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/d406be621482698e293cd2cf0ddf659d.png)'
- en: (b) Skip-connections [[166](#bib.bib166)] to shrink foreground features
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 跳跃连接 [[166](#bib.bib166)] 以缩小前景特征
- en: 'Figure 7: Morphological feature perturbations through designing different network
    architectures [[91](#bib.bib91)].'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：通过设计不同的网络架构来进行形态特征扰动 [[91](#bib.bib91)]。
- en: '![Refer to caption](img/a98416aaae88d2843849048fbee90987.png)'
  id: totrans-97
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/a98416aaae88d2843849048fbee90987.png)'
- en: (a) Shadow augmentation which imposes the shadow artifacts extracted from shadow
    source images on the original input images with different values of shadow threshold
    $\tau_{s}$.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 阴影增强，将从阴影源图像中提取的阴影伪影以不同的阴影阈值 $\tau_{s}$ 施加到原始输入图像上。
- en: '![Refer to caption](img/45fa5e794d5b5aada72951f421a64b93.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/45fa5e794d5b5aada72951f421a64b93.png)'
- en: (b) Shadow dropout which filters the features extracted from the shadow regions
    in feature maps.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 阴影丢弃，这种方法在特征图中的阴影区域提取特征。
- en: 'Figure 8: Shadow augmentation and dropout [[77](#bib.bib77)]'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：阴影增强和丢弃 [[77](#bib.bib77)]
- en: 'Task-level regularization Other than utilizing data-level perturbations for
    consistency learning, some methods focus on building task-level regularization
    by adding auxiliary task to leverage geometric information. Li et al. [[34](#bib.bib34)]
    develop a multi-task network to build shape-aware constraints with adversarial
    regularization. Liu et al. [[143](#bib.bib143)] propose a shape-aware multi-task
    framework which contained segmentation, signed distance map prediction and organ
    contour prediction. Luo et al. [[35](#bib.bib35)] combine the level set function
    regression task with the segmentation task to form a dual-task consistency for
    semi-supervised learning. Zhang et al. [[36](#bib.bib36)] propose dual-task mutual
    learning framework by encouraging dual-task networks to explore useful knowledge
    from each other. Based on dual-task framework, Zhang et al. [[9](#bib.bib9)] utilize
    both segmentation task and regression task for self-ensembling and utilize estimated
    uncertainty to guide the mutual consistency learning and obtain further performance
    improvement, Shi et al. [[218](#bib.bib218)] propose to utilize segmentation task
    and regression task as student networks for competitive ensembling to the teacher
    network. Chen et al. [[113](#bib.bib113)] propose a dual-task consistency joint
    learning framework that encouraged the segmentation results to be consistent with
    the transformation of the signed distance map predictions. Wang et al. [[97](#bib.bib97)]
    inject multi-task learning into mean teacher architecture which contain the segmentation
    task, the reconstruction task, and the signed distance field prediction task so
    that the model can take account of the data-, model- and task-level consistency,
    as shown in Figure [9](#S3.F9 "Figure 9 ‣ 3.2.1 Unsupervised Regularization with
    Consistency Learning ‣ 3.2 Semi-Supervised Medical Image Segmentation with Unsupervised
    Regularization ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation"). In signed distance field prediction, a neural
    network is trained to predict the signed distance value of each pixel from the
    nearest foreground points. The sign of the distance indicates whether the point
    is inside or outside the region of interest, while the magnitude of the distance
    gives an estimate of the distance from the foreground. Besides, they propose an
    uncertainty weighted integration (UWI) strategy to estimate the uncertainty on
    all tasks and develop a triple-uncertainty based on these tasks to guide the student
    model to learn reliable information from teacher.'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '任务级正则化 除了利用数据级扰动进行一致性学习，一些方法专注于通过添加辅助任务来构建任务级正则化，从而利用几何信息。Li等人[[34](#bib.bib34)]开发了一个多任务网络，通过对抗性正则化建立形状感知约束。Liu等人[[143](#bib.bib143)]提出了一个包含分割、符号距离图预测和器官轮廓预测的形状感知多任务框架。Luo等人[[35](#bib.bib35)]将水平集函数回归任务与分割任务结合起来，形成一个用于半监督学习的双任务一致性。Zhang等人[[36](#bib.bib36)]提出了双任务互学习框架，鼓励双任务网络相互探索有用的知识。基于双任务框架，Zhang等人[[9](#bib.bib9)]利用分割任务和回归任务进行自我集成，并利用估计的不确定性来指导互一致性学习，从而获得进一步的性能提升。Shi等人[[218](#bib.bib218)]提出利用分割任务和回归任务作为学生网络进行竞争性集成，以增强对教师网络的效果。Chen等人[[113](#bib.bib113)]提出了一种双任务一致性联合学习框架，鼓励分割结果与符号距离图预测的变换保持一致。Wang等人[[97](#bib.bib97)]将多任务学习注入到包含分割任务、重建任务和符号距离场预测任务的均值教师架构中，使得模型能够考虑数据级、模型级和任务级的一致性，如图[9](#S3.F9
    "Figure 9 ‣ 3.2.1 Unsupervised Regularization with Consistency Learning ‣ 3.2
    Semi-Supervised Medical Image Segmentation with Unsupervised Regularization ‣
    3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with Limited
    Annotations: A Survey on Deep Semi-supervised Learning for Medical Image Segmentation")所示。在符号距离场预测中，训练一个神经网络来预测每个像素到最近前景点的符号距离值。距离的符号表示该点是否在感兴趣区域内外，而距离的大小则估计了前景的距离。此外，他们提出了一种不确定性加权集成（UWI）策略，用于估计所有任务的不确定性，并基于这些任务开发了三重不确定性，以指导学生模型从教师那里学习可靠的信息。'
- en: Variants of consistency calculation methods There are multiple consistency calculation
    methods to avoid noisy pixel predictions, such as uncertainty-based consistency
    learning [[31](#bib.bib31), [141](#bib.bib141), [106](#bib.bib106), [50](#bib.bib50),
    [106](#bib.bib106), [50](#bib.bib50), [110](#bib.bib110)], multi-level consistency
    learning [[124](#bib.bib124)], attention-guided consistency learning [[81](#bib.bib81)]
    and so on. The predictions of the teacher model can be wrong at some locations
    and might confuse the student model in the mean-teacher architecture. So uncertainty
    or confidence estimation are utilized to learn from more meaningful and reliable
    targets during training. Yu et al. [[31](#bib.bib31)] extend the mean teacher
    paradigm with an uncertainty estimation strategy through Monte Carlo dropout [[90](#bib.bib90)].
    To use Monte Carlo dropout in semi-supervised learning, the labeled data is used
    to train the model with dropout turned on. Then, the model is used to make predictions
    on the unlabeled data, with dropout turned on. The multiple predictions of the
    same unlabeled sample are then used to compute an uncertainty. This uncertainty
    can be used to guide the pseudo-labeling process, by identifying pixels that are
    likely to be mislabeled or ambiguous. Xie et al. [[141](#bib.bib141)] add a confidence-aware
    module to learn the model confidence under the guidance of labeled data. Luo et
    al. [[106](#bib.bib106), [50](#bib.bib50)] calculate uncertainty using pyramid
    predictions in one forward pass and proposed an multi-level uncertainty rectified
    pyramid consistency regularization. Fang et al. [[110](#bib.bib110)] attach an
    error estimation network to predict the loss map of the teacher’s prediction.
    Then the consistency loss will be calculated on low loss pixels. Chen et al. [[124](#bib.bib124)]
    propose multi-level consistency loss which computes the similarities between multi-scale
    features in an additional discriminator, where the inputs are the segmentation
    regions by multiplying the unlabeled input image with predicted segmentation probability
    maps instead of segmentation probability maps. Hu et al. [[81](#bib.bib81)] propose
    attention guided consistency which encourages the attention maps from the student
    model and the teacher model to be consistent. Zhao et al. [[75](#bib.bib75)] introduce
    cross-level consistency constraint which is calculated between patches and the
    full image.Except encouraging consistency on network segmentation results directly,
    generative consistency [[101](#bib.bib101)] is proposed through a generation network
    that reconstructs medical images from its predictions of the segmentation network.
    Xu et al. [[84](#bib.bib84)] propose contour consistency and utilize Fourier series
    which contained a series of harmonics as an elliptical descriptor. Through minimizing
    the L2 distance of the parameters between the student and the teacher branch,
    the model is equipped with shape awareness. However, this method needs to choose
    different maximum harmonic numbers for the segmentation of targets with different
    irregularity. Each image contains the same class object, so different images share
    similar semantics in the feature space. Xie et al. [[135](#bib.bib135)] introduce
    intra- and inter-pair consistency to augment feature maps. The pixel-level relation
    between a pair of images in the feature space is first calculated to obtain the
    attention maps that highlight the regions with the same semantics but on different
    images. Then multiple attention maps are taken into account to filter the low-confidence
    regions and then merged with the original feature map to improve its representation
    ability. Liu et al. [[102](#bib.bib102)] propose contrastive consistency which
    encourages segmentation outputs to be consistent in class-level through foreground
    and background class-vectors generated from a classification network. Xu et al.
    [[70](#bib.bib70)] propose the cyclic prototype consistency learning (CPCL) framework
    which contains a labeled-to-unlabeled (L2U) prototypical forward process and an
    unlabeled-to-labeled (U2L) backward process. The L2U forward consistency can transfer
    the real label supervision signals to unlabeled data using labeled prototypes
    while the U2L backward consistency can directly using unlabeled prototypes to
    segment labeled data.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性计算方法的变体 有多种一致性计算方法可用于避免嘈杂的像素预测，例如基于不确定性的学习[[31](#bib.bib31)、[141](#bib.bib141)、[106](#bib.bib106)、[50](#bib.bib50)、[106](#bib.bib106)、[50](#bib.bib50)、[110](#bib.bib110)]，多层次一致性学习[[124](#bib.bib124)]，以及注意力引导的一致性学习[[81](#bib.bib81)]等。在均值教师架构中，教师模型的预测在某些位置可能是错误的，这可能会使学生模型感到困惑。因此，在训练过程中，利用不确定性或置信度估计来学习更有意义和可靠的目标。Yu
    等人[[31](#bib.bib31)]通过蒙特卡罗 dropout[[90](#bib.bib90)]扩展了均值教师范式。在半监督学习中使用蒙特卡罗 dropout时，使用标记数据训练模型，同时启用
    dropout。然后，使用模型对未标记数据进行预测，依然启用 dropout。随后，通过计算同一未标记样本的多个预测结果来计算不确定性。这种不确定性可以用于指导伪标签化过程，识别可能被错误标记或模糊的像素。Xie
    等人[[141](#bib.bib141)]添加了一个置信度感知模块，以在标记数据的指导下学习模型置信度。Luo 等人[[106](#bib.bib106)、[50](#bib.bib50)]通过在一次前向传播中计算金字塔预测的不确定性，并提出了多层次不确定性修正的金字塔一致性正则化。Fang
    等人[[110](#bib.bib110)]附加了一个误差估计网络，以预测教师预测的损失图。然后将在低损失像素上计算一致性损失。Chen 等人[[124](#bib.bib124)]提出了多层次一致性损失，该方法计算额外判别器中多尺度特征之间的相似性，其中输入是通过将未标记输入图像与预测的分割概率图相乘得到的分割区域，而不是分割概率图。Hu
    等人[[81](#bib.bib81)]提出了注意力引导一致性，鼓励学生模型和教师模型的注意力图保持一致。Zhao 等人[[75](#bib.bib75)]引入了跨层一致性约束，该约束在补丁和整个图像之间计算。除了直接鼓励网络分割结果的一致性外，还提出了生成一致性[[101](#bib.bib101)]，通过一个生成网络从分割网络的预测中重建医学图像。Xu
    等人[[84](#bib.bib84)]提出了轮廓一致性，利用傅里叶级数（包含一系列谐波）作为椭圆描述符。通过最小化学生和教师分支之间参数的L2距离，模型获得了形状感知能力。然而，这种方法需要为不同不规则性的目标选择不同的最大谐波数。每张图像包含相同类别的对象，因此不同的图像在特征空间中共享相似的语义。Xie
    等人[[135](#bib.bib135)]引入了内对和外对一致性来增强特征图。首先计算特征空间中一对图像之间的像素级关系，以获得突出显示具有相同语义但在不同图像上的区域的注意力图。然后考虑多个注意力图以过滤低置信度区域，并将其与原始特征图合并，以提高其表示能力。Liu
    等人[[102](#bib.bib102)]提出了对比一致性，通过分类网络生成的前景和背景类别向量，鼓励分割输出在类别级别上保持一致。Xu 等人[[70](#bib.bib70)]提出了循环原型一致性学习（CPCL）框架，该框架包含标记到未标记（L2U）的原型前向过程和未标记到标记（U2L）的反向过程。L2U前向一致性可以使用标记原型将真实标签监督信号转移到未标记数据，而U2L反向一致性可以直接使用未标记原型对标记数据进行分割。
- en: '![Refer to caption](img/c2ce1e2535d2e3045a53f64f9b52fa16.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c2ce1e2535d2e3045a53f64f9b52fa16.png)'
- en: 'Figure 9: Multi-task learning in mean teacher architecture which contains the
    segmentation task, the reconstruction task, and the signed distance field prediction
    task[[97](#bib.bib97)]. The inter-task consistency encourages consistent predictions
    between the three tasks and the inter-model consistency encourages consistent
    predictions between the teacher model and the student model.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：均值教师架构中的多任务学习，包括分割任务、重建任务和签名距离场预测任务[[97](#bib.bib97)]。任务间一致性鼓励三个任务之间的预测一致性，模型间一致性鼓励教师模型与学生模型之间的预测一致性。
- en: 'Table 2: The summarized review of semi-supervised medical image segmentation
    methods with consistency learning.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：带有一致性学习的半监督医学图像分割方法的总结评审。
- en: '| Reference | 2D/3D | Modality | Dataset | Perturbations |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 2D/3D | 模态 | 数据集 | 扰动 |'
- en: '| SSN-RCL, Huang et al. [[99](#bib.bib99)] | 3D | Microscopy | Kasthuri15 [[171](#bib.bib171)],
    CREMI ¹¹10 | Gaussian blurring, Gaussian noise, slice misalignment, contrast variations
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| SSN-RCL, Huang et al. [[99](#bib.bib99)] | 3D | 显微镜 | Kasthuri15 [[171](#bib.bib171)]，CREMI
    ¹¹10 | 高斯模糊，高斯噪声，切片错位，对比度变化 |'
- en: '| SCO-SSL, Xu et al.[[77](#bib.bib77)] | 3D | US | UCLA [[172](#bib.bib172)]
    | Shadow augmentation, shadow dropout |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| SCO-SSL, Xu et al.[[77](#bib.bib77)] | 3D | US | UCLA [[172](#bib.bib172)]
    | 阴影增强，阴影丢弃 |'
- en: '| SemiTC, Bortsova et al. [[118](#bib.bib118)] | 2D | X-Ray | JSRT dataset
    [[15](#bib.bib15)] | Elastic deformations |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| SemiTC, Bortsova et al. [[118](#bib.bib118)] | 2D | X-Ray | JSRT 数据集 [[15](#bib.bib15)]
    | 弹性变形 |'
- en: '| GCS, Chen et al.[[101](#bib.bib101)] | 3D | TOF-MRA | MIDAS dataset [[18](#bib.bib18)]
    | Random perturbations |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| GCS, Chen et al.[[101](#bib.bib101)] | 3D | TOF-MRA | MIDAS 数据集 [[18](#bib.bib18)]
    | 随机扰动 |'
- en: '| DUW-SSL, Wang et al. [[32](#bib.bib32)] | 3D | CT, MRI | LA dataset [[66](#bib.bib66)],
    KiTS dataset [[175](#bib.bib175)] | Random noise, dropout |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| DUW-SSL, Wang et al. [[32](#bib.bib32)] | 3D | CT, MRI | LA 数据集 [[66](#bib.bib66)]，KiTS
    数据集 [[175](#bib.bib175)] | 随机噪声，丢弃 |'
- en: '| URPC, Luo et al.[[50](#bib.bib50)] | 3D | CT | BraTS 2019[[128](#bib.bib128)],
    Pancreas CT[[130](#bib.bib130)] | Randomly cropped patches, multi-level pyramid
    predictions |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| URPC, Luo et al.[[50](#bib.bib50)] | 3D | CT | BraTS 2019[[128](#bib.bib128)]，胰腺
    CT[[130](#bib.bib130)] | 随机裁剪的补丁，多级金字塔预测 |'
- en: '| Mtans, Chen et al.[[124](#bib.bib124)] | 3D | MRI | Longitudinal Multiple
    Sclerosis Lesion Segmentation [[173](#bib.bib173)], ISLES 2015[[174](#bib.bib174)],
    BraTS 2018[[128](#bib.bib128)] | Multi-scale features |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Mtans, Chen et al.[[124](#bib.bib124)] | 3D | MRI | 经年的多发性硬化病变分割 [[173](#bib.bib173)]，ISLES
    2015[[174](#bib.bib174)]，BraTS 2018[[128](#bib.bib128)] | 多尺度特征 |'
- en: '| CPCL, Xu et al.[[70](#bib.bib70)] | 3D | CT, MRI | BraTS 2019 [[128](#bib.bib128)],
    KiTS dataset [[175](#bib.bib175)] | Different input images |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| CPCL, Xu et al.[[70](#bib.bib70)] | 3D | CT, MRI | BraTS 2019 [[128](#bib.bib128)]，KiTS
    数据集 [[175](#bib.bib175)] | 不同输入图像 |'
- en: '| AHDC, Chen et al.[[88](#bib.bib88)] | 3D | CT, MRI | LGE-CMR datasets from
    [[176](#bib.bib176), [177](#bib.bib177)], MM-WHS dataset [[178](#bib.bib178),
    [179](#bib.bib179)] | Different domain inputs |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| AHDC, Chen et al.[[88](#bib.bib88)] | 3D | CT, MRI | LGE-CMR 数据集来自 [[176](#bib.bib176),
    [177](#bib.bib177)]，MM-WHS 数据集 [[178](#bib.bib178), [179](#bib.bib179)] | 不同领域输入
    |'
- en: '| UA-MT, Yu et al.[[31](#bib.bib31)] | 3D | MRI | LA dataset [[66](#bib.bib66)]
    | Random flipping, random rotating |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| UA-MT, Yu et al.[[31](#bib.bib31)] | 3D | MRI | LA 数据集 [[66](#bib.bib66)]
    | 随机翻转，随机旋转 |'
- en: '| SASSNet, Zhang et al.[[34](#bib.bib34)] | 3D | MRI | LA dataset [[66](#bib.bib66)]
    | Task-level consistency |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| SASSNet, Zhang et al.[[34](#bib.bib34)] | 3D | MRI | LA 数据集 [[66](#bib.bib66)]
    | 任务级一致性 |'
- en: '| DTC, Luo et al.[[35](#bib.bib35)] | 3D | CT, MRI | LA dataset [[66](#bib.bib66)],
    Pancreas CT [[130](#bib.bib130)] | Task-level consistency |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| DTC, Luo et al.[[35](#bib.bib35)] | 3D | CT, MRI | LA 数据集 [[66](#bib.bib66)]，胰腺
    CT [[130](#bib.bib130)] | 任务级一致性 |'
- en: '| T-UncA, Wang et al.[[67](#bib.bib67)] | 2D | MRI | ACDC dataset [[22](#bib.bib22)],
    PROMISE [[182](#bib.bib182)] | Task-level consistency |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| T-UncA, Wang et al.[[67](#bib.bib67)] | 2D | MRI | ACDC 数据集 [[22](#bib.bib22)]，PROMISE
    [[182](#bib.bib182)] | 任务级一致性 |'
- en: 1\. https://cremi.org/
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. https://cremi.org/
- en: 3.2.2 Unsupervised Regularization with Co-Training
  id: totrans-122
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 无监督正则化与协同训练
- en: 'Co-training framework assumes that each data has two or more different views
    and each view has sufficient information to give predictions independently [[147](#bib.bib147)].
    It first learns a separate segmentation model for each view on labeled data, and
    then the predictions of the models on unlabeled data are gradually added to training
    set to continue the training. In co-training, one view is redundant to other views
    and the models are encouraged to have consistent predictions on all the views.
    Note that different from self-training methods, co-training methods add pseudo
    labels from one view to the training set and act as supervision signals to train
    models of other views. And the difference between co-training and consistency
    learning is that all the models in co-training will be updated through gradient
    descent algorithm whereas the consistency learning encourages the outputs for
    different perturbations to be consistent and only one main model is updated by
    gradient descent algorithm, such as the mean-teacher architecture [[29](#bib.bib29)].
    There are also some limitations that need to be considered:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 共训练框架假设每个数据有两个或更多不同的视角，每个视角都有足够的信息进行独立预测[[147](#bib.bib147)]。它首先在标记数据上为每个视角学习一个独立的分割模型，然后逐渐将模型在未标记数据上的预测添加到训练集中以继续训练。在共训练中，一个视角对其他视角是冗余的，模型被鼓励在所有视角上具有一致的预测。与自训练方法不同的是，共训练方法将一个视角的伪标签添加到训练集中，并作为监督信号来训练其他视角的模型。而共训练与一致性学习的区别在于，共训练中的所有模型都会通过梯度下降算法进行更新，而一致性学习则鼓励不同扰动的输出保持一致，并且只有一个主要模型通过梯度下降算法进行更新，例如均值教师架构[[29](#bib.bib29)]。还需要考虑一些限制：
- en: '1\. Sufficient independence between views: Co-training assumes that each view
    is sufficient and independent enough to make predictions on its own. However,
    in real-world scenarios, this assumption may not always hold true, leading to
    poor performance when the views are correlated or redundant.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 视角之间的充分独立性：共训练假设每个视角足够独立，能够单独做出预测。然而，在实际情况中，这一假设可能不总是成立，当视角之间相关或冗余时，性能可能会下降。
- en: '2\. Risk of model conflict: Co-training encourages consistency between the
    models’ predictions across different views. However, if the models are too similar,
    they may become overly specialized and fail to capture the underlying patterns
    in the data.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 模型冲突的风险：共训练方法鼓励模型在不同视角下的预测一致性。然而，如果模型过于相似，它们可能会过度专注于特定领域，无法捕捉数据中的潜在模式。
- en: '3\. Sensitivity to noisy pseudo labels: Co-training adds pseudo labels from
    one view to the training set as supervision signals for other views. If these
    pseudo labels from one view are noisy or incorrect, it can negatively impact the
    performance of other views.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 3\. 对噪声伪标签的敏感性：共训练将一个视角的伪标签添加到训练集中作为其他视角的监督信号。如果这些伪标签有噪声或不正确，会对其他视角的性能产生负面影响。
- en: 'Construction of different views The core of co-training is how to construct
    two (or more) deep models of approximately represent sufficiently independent
    views. The methods mainly contain using different sources of data, employing different
    network architectures and using special training methods to obtain diverse deep
    models. First, different sources of data includes data from different modalities
    [[94](#bib.bib94), [103](#bib.bib103)], medical centers [[60](#bib.bib60)] or
    anatomical planes [[148](#bib.bib148), [133](#bib.bib133)], which lead to different
    distributions. For example, Zhu et al. [[94](#bib.bib94)] propose a co-training
    framework for unpaired multi-modal learning. This framework contains two segmentation
    networks and two image translation networks across two modalities. They utilize
    the pseudo-labels (from unlabeled data) or labels (from labeled data) from one
    modality to train the segmentation network in the other modality after image translation.
    For one thing, it increases supervision signals. For another, it adds modality-level
    consistency. Chen et al. [[103](#bib.bib103)] leveraged unpaired multi-modality
    images to be cross-modal consistent in anatomy and semantic information. The multi
    modalities which are collaborative and complementary could encourage better modality-independent
    representation learning. Liu et al. [[60](#bib.bib60)] present a co-training framework
    for domain-adaptive medical image segmentation. This framework contains two segmentors
    used for semi-supervised segmentation task (labeled and unlabeled target domain
    data as inputs) and unsupervised domain adaptation task (labeled source domain
    data and unlabeled target domain data as inputs), respectively. [[148](#bib.bib148),
    [133](#bib.bib133)] use coronal, sagittal and axial views of 3D medical images
    as view difference at input level and [[148](#bib.bib148)] also use asymmetric
    3D kernels with 2D initialization as view difference at feature level. However,
    when there are only one source of data available, training two (or more) identical
    networks may lead to collapsed neural networks as the predictions from these models
    are encouraged to be similar. [[149](#bib.bib149), [151](#bib.bib151)] generate
    adversarial examples as another view. Second, as different models usually extract
    different representations, different models in co-training framework can focus
    on different views. Except using CNN as the backbones, there are also some transformer-based
    backbones [[114](#bib.bib114), [119](#bib.bib119)]. As shown in Figure [10](#S3.F10
    "Figure 10 ‣ 3.2.2 Unsupervised Regularization with Co-Training ‣ 3.2 Semi-Supervised
    Medical Image Segmentation with Unsupervised Regularization ‣ 3 Related Work on
    Semi-Supervised Medical Image Segmentation ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation"), Luo
    et al. [[132](#bib.bib132)] introduce the cross teaching between CNN- and transformer-based
    backbones which implicitly encourages the consistency and complementary between
    different networks. Liu et al. [[114](#bib.bib114)] combine CNN blocks and Swin
    Transformer blocks as the backbone. Xiao et al. [[119](#bib.bib119)] add another
    teacher model with the transformer-based architecture. The teacher models communicate
    with each other with consistency regularization and guide the student learning
    process. Third, diverse deep models can also be trained using special training
    methods. For instance, Chen et al. [[150](#bib.bib150)] use output smearing to
    generate different labeled data sets to initialize diverse models. To maintain
    the diversity in the subsequent training process, the modules are fine-tuned using
    the generated sets in specific rounds.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '不同视图的构建 Co-training 的核心在于如何构建两个（或更多）深度模型来代表足够独立的视图。这些方法主要包括使用不同来源的数据、采用不同的网络架构和使用特殊的训练方法来获得多样化的深度模型。首先，不同来源的数据包括来自不同模态的数据
    [[94](#bib.bib94), [103](#bib.bib103)]、医疗中心 [[60](#bib.bib60)] 或解剖平面 [[148](#bib.bib148),
    [133](#bib.bib133)]，这些会导致不同的分布。例如，Zhu 等人 [[94](#bib.bib94)] 提出了一个用于无配对多模态学习的 co-training
    框架。该框架包含两个分割网络和两个跨模态的图像翻译网络。他们利用来自一种模态的伪标签（来自未标记数据）或标签（来自已标记数据），在图像翻译后训练另一模态的分割网络。一方面，这增加了监督信号。另一方面，它增加了模态级别的一致性。Chen
    等人 [[103](#bib.bib103)] 利用未配对的多模态图像在解剖和语义信息上保持跨模态一致性。协作和互补的多模态可以促进更好的模态独立表示学习。Liu
    等人 [[60](#bib.bib60)] 提出了一个用于领域适应的医学图像分割的 co-training 框架。该框架包含两个分割器，分别用于半监督分割任务（标记和未标记目标领域数据作为输入）和无监督领域适应任务（标记源领域数据和未标记目标领域数据作为输入）。[[148](#bib.bib148),
    [133](#bib.bib133)] 使用 3D 医学图像的冠状面、矢状面和横断面作为输入级别的视图差异，[[148](#bib.bib148)] 还使用具有
    2D 初始化的非对称 3D 核心作为特征级别的视图差异。然而，当只有一个数据源可用时，训练两个（或更多）相同的网络可能导致神经网络崩溃，因为这些模型的预测被鼓励变得相似。[[149](#bib.bib149),
    [151](#bib.bib151)] 生成对抗样本作为另一种视图。其次，由于不同的模型通常提取不同的表示，co-training 框架中的不同模型可以关注不同的视图。除了使用
    CNN 作为骨干网络外，还有一些基于 transformer 的骨干网络 [[114](#bib.bib114), [119](#bib.bib119)]。如图
    [10](#S3.F10 "Figure 10 ‣ 3.2.2 Unsupervised Regularization with Co-Training ‣
    3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation") 所示，Luo 等人 [[132](#bib.bib132)] 介绍了 CNN 和 transformer 基于骨干网络之间的交叉教学，这隐式地鼓励不同网络之间的一致性和互补性。Liu
    等人 [[114](#bib.bib114)] 将 CNN 模块和 Swin Transformer 模块结合在一起作为骨干网络。Xiao 等人 [[119](#bib.bib119)]
    增加了另一个具有 transformer 架构的教师模型。教师模型通过一致性正则化进行相互沟通，并指导学生的学习过程。第三，使用特殊的训练方法也可以训练出多样化的深度模型。例如，Chen
    等人 [[150](#bib.bib150)] 使用输出模糊来生成不同的标记数据集，以初始化多样化的模型。为了保持后续训练过程中的多样性，这些模块在特定轮次中使用生成的数据集进行微调。'
- en: '![Refer to caption](img/ca193da4f61d34b00e0c555887e6f8e1.png)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/ca193da4f61d34b00e0c555887e6f8e1.png)'
- en: 'Figure 10: A co-training framework which uses CNN- and transformer-based backbones
    and encourages the consistency and complementary between different networks [[132](#bib.bib132)].'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：一种使用CNN和Transformer基础架构的协同训练框架，鼓励不同网络之间的一致性和互补性[[132](#bib.bib132)]。
- en: 'Avoiding noisy pseudo labels in co-training is also important. Although consistent
    predictions are encouraged across the networks, they may contain noise leading
    to unstable training process. To overcome the third limitation mentioned in the
    Sec.[3.2.2](#S3.SS2.SSS2 "3.2.2 Unsupervised Regularization with Co-Training ‣
    3.2 Semi-Supervised Medical Image Segmentation with Unsupervised Regularization
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation"), an uncertainty-aware co-training framework [[148](#bib.bib148)]
    is proposed through estimating the confidence of each view and fusing the predictions
    from the other views to generate the pseudo labels for one view. Wang et al. [[100](#bib.bib100)]
    develop a self-paced and self-consistent co-training framework. The self-paced
    strategy can encourage the network to transfer the knowledge of easier-to-segment
    regions to the harder ones gradually through minimizing a generalized Jensen-Shannon
    divergence. Another way to alleviate the influence from noisy pseudo labels is
    through exponential mix-up decay to adjust the contribution of the supervision
    signals from both labels and pseudo labels across the training process [[60](#bib.bib60)].
    Except the methods mentioned above, adversarial learning in [3.2.3](#S3.SS2.SSS3
    "3.2.3 Unsupervised Regularization with Adversarial Learning ‣ 3.2 Semi-Supervised
    Medical Image Segmentation with Unsupervised Regularization ‣ 3 Related Work on
    Semi-Supervised Medical Image Segmentation ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation") is
    always conducted to generate pixel-wise confidence maps or uncertainty. The semi-supervised
    models will learn from high-confidence predictions [[210](#bib.bib210)], thus
    avoiding noisy pseudo labels.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '避免在协同训练中出现嘈杂的伪标签也很重要。尽管鼓励网络之间的一致预测，但它们可能包含噪声，导致训练过程不稳定。为了解决第[3.2.2](#S3.SS2.SSS2
    "3.2.2 Unsupervised Regularization with Co-Training ‣ 3.2 Semi-Supervised Medical
    Image Segmentation with Unsupervised Regularization ‣ 3 Related Work on Semi-Supervised
    Medical Image Segmentation ‣ Learning with Limited Annotations: A Survey on Deep
    Semi-supervised Learning for Medical Image Segmentation")节中提到的第三个限制，提出了一种基于不确定性的协同训练框架[[148](#bib.bib148)]，通过估计每个视图的置信度并融合其他视图的预测来生成一个视图的伪标签。王等人[[100](#bib.bib100)]开发了一种自适应和自一致的协同训练框架。自适应策略可以通过最小化广义的Jensen-Shannon散度，鼓励网络将易于分割的区域的知识逐渐转移到难度更大的区域。另一种减轻嘈杂伪标签影响的方法是通过指数混合衰减来调整标签和伪标签在训练过程中的监督信号的贡献[[60](#bib.bib60)]。除了上述方法外，[3.2.3](#S3.SS2.SSS3
    "3.2.3 Unsupervised Regularization with Adversarial Learning ‣ 3.2 Semi-Supervised
    Medical Image Segmentation with Unsupervised Regularization ‣ 3 Related Work on
    Semi-Supervised Medical Image Segmentation ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation")节中的对抗学习也总是进行的，以生成逐像素的置信度图或不确定性。半监督模型将从高置信度的预测[[210](#bib.bib210)]中学习，从而避免嘈杂的伪标签。'
- en: 'Table 3: The summarized review of semi-supervised medical image segmentation
    methods with co-training.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：带有协同训练的半监督医学图像分割方法的总结回顾。
- en: '| Reference | 2D/3D | Modality | Dataset | Diverse views from |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 2D/3D | 模态 | 数据集 | 来自多样视角的 |'
- en: '| Spsco-Cot, Wang et al.[[100](#bib.bib100)] | 2D | CT, MRI | ACDC dataset
    [[22](#bib.bib22)], Spleen sub-task of Medical Segmentation Decathlon [[185](#bib.bib185)],
    PROMISE [[182](#bib.bib182)] | Perturbations |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| Spsco-Cot, 王等人[[100](#bib.bib100)] | 2D | CT, MRI | ACDC 数据集 [[22](#bib.bib22)],
    医学分割十项挑战的脾脏子任务 [[185](#bib.bib185)], PROMISE [[182](#bib.bib182)] | 扰动 |'
- en: '| DCT-Seg, Peng et al.[[151](#bib.bib151)] | 2D | CT, MRI | ACDC dataset[[22](#bib.bib22)],
    SCGM [[184](#bib.bib184)], Spleen dataset [[185](#bib.bib185)] | Perturbations
    |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| DCT-Seg, 彭等人[[151](#bib.bib151)] | 2D | CT, MRI | ACDC 数据集[[22](#bib.bib22)],
    SCGM [[184](#bib.bib184)], 脾脏数据集 [[185](#bib.bib185)] | 扰动 |'
- en: '| MASS, Chen et al.[[103](#bib.bib103)] | 3D | CT, MRI | BTCV[[187](#bib.bib187)],
    CHAOS[[183](#bib.bib183)] | Different modalities |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| MASS, 陈等人[[103](#bib.bib103)] | 3D | CT, MRI | BTCV[[187](#bib.bib187)],
    CHAOS[[183](#bib.bib183)] | 不同模态 |'
- en: '| SSUML, Zhu et al.[[94](#bib.bib94)] | 2D | CT, MRI | Cardiac substructure
    segmentation [[178](#bib.bib178)], Abdominal multi-organ segmentation [[186](#bib.bib186),
    [183](#bib.bib183)] | Different modalities |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| SSUML, Zhu et al.[[94](#bib.bib94)] | 2D | CT, MRI | 心脏亚结构分割 [[178](#bib.bib178)],
    腹部多脏器分割 [[186](#bib.bib186), [183](#bib.bib183)] | 不同的模态 |'
- en: '| CT_CNN&Trans, Luo et al.[[132](#bib.bib132)] | 2D | MRI | ACDC dataset [[22](#bib.bib22)]
    | Different segmentation networks |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| CT_CNN&Trans, Luo et al.[[132](#bib.bib132)] | 2D | MRI | ACDC 数据集 [[22](#bib.bib22)]
    | 不同的分割网络 |'
- en: '| Mmgl, Zhao et al.[[133](#bib.bib133)] | 3D | CT | MM-WHS dataset [[178](#bib.bib178),
    [179](#bib.bib179)] | Different transformations |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| Mmgl, Zhao et al.[[133](#bib.bib133)] | 3D | CT | MM-WHS 数据集 [[178](#bib.bib178),
    [179](#bib.bib179)] | 不同的变换 |'
- en: '| UMCT, Xia et al.[[148](#bib.bib148)] | 3D | CT | NIH Pancreas [[130](#bib.bib130)],
    LiTS dataset [[17](#bib.bib17)] | Different transformations |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| UMCT, Xia et al.[[148](#bib.bib148)] | 3D | CT | NIH 胰腺 [[130](#bib.bib130)],
    LiTS 数据集 [[17](#bib.bib17)] | 不同的变换 |'
- en: 3.2.3 Unsupervised Regularization with Adversarial Learning
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 基于对抗学习的无监督正则化
- en: Adversarial methods is used to encourage the distribution of predictions from
    unlabeled images to be closer to that of labeled images in semi-supervised learning.
    These methods always contain a discriminator to distinguish the inputs from labeled
    annotations or unlabeled predictions [[45](#bib.bib45), [137](#bib.bib137), [124](#bib.bib124),
    [93](#bib.bib93)]. However, adversarial training may be challenging in terms of
    convergence.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗方法用于鼓励来自未标记图像的预测分布更接近标记图像的分布，应用于半监督学习。这些方法通常包含一个判别器，用于区分来自标记注释或未标记预测的输入 [[45](#bib.bib45),
    [137](#bib.bib137), [124](#bib.bib124), [93](#bib.bib93)]。然而，对抗训练可能在收敛方面具有挑战性。
- en: Zhang et al. [[45](#bib.bib45)] introduce adversarial learning to encourage
    the segmentations of unlabeled data to be similar with the annotations of labeled
    data. Chen et al. [[124](#bib.bib124)] add a discriminator following the segmentation
    network which is used to distinguish between the input signed distance maps from
    labeled images or unlabeled images. Peiris et al. [[93](#bib.bib93), [210](#bib.bib210)]
    add a critic network into the segmentation architecture which can perform the
    min-max game through discriminating between prediction masks and the ground truth
    masks. The experiments show that it could sharpen boundaries in prediction masks.
    The discriminator can also be used to generate pixel-wise confidence maps and
    select the trustworthy pixel predictions used for co-training. Wu et al. [[134](#bib.bib134)]
    add two discriminators for predicting confidence maps and distinguishing the segmentation
    results from labeled or unlabeled data. Through adding another auxiliary discriminator,
    the under trained primary discriminator due to limited labeled images can be alleviated.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang et al. [[45](#bib.bib45)] 引入对抗学习以鼓励未标记数据的分割结果与标记数据的注释相似。Chen et al. [[124](#bib.bib124)]
    在分割网络后添加了一个判别器，用于区分来自标记图像或未标记图像的输入签名距离图。Peiris et al. [[93](#bib.bib93), [210](#bib.bib210)]
    在分割架构中添加了一个批评网络，该网络可以通过区分预测掩码和真实掩码进行最小-最大博弈。实验表明，这可以锐化预测掩码中的边界。判别器还可以用于生成逐像素置信度图，并选择用于协同训练的可信像素预测。Wu
    et al. [[134](#bib.bib134)] 为预测置信度图和区分标记或未标记数据的分割结果添加了两个判别器。通过添加另一个辅助判别器，可以缓解由于标记图像有限导致的主判别器训练不足的问题。
- en: 3.2.4 Unsupervised Regularization with Entropy Minimization
  id: totrans-143
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 基于熵最小化的无监督正则化
- en: 'Entropy minimization encourages the model to output low-entropy predictions
    on unlabeled data and avoids the class overlap. Semi-supervised learning algorithms
    [[105](#bib.bib105), [154](#bib.bib154), [155](#bib.bib155)] are usually combined
    with entropy minimization based on the assumption that the decision boundary should
    lie in low-density regions. For instance, in [[154](#bib.bib154)], a loss term
    is added to minimize the entropy of the predictions of the model on unlabeled
    data and the objective function turns to be as follow:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 熵最小化鼓励模型对未标记数据输出低熵预测，避免类别重叠。半监督学习算法 [[105](#bib.bib105), [154](#bib.bib154),
    [155](#bib.bib155)] 通常结合熵最小化，基于决策边界应位于低密度区域的假设。例如，在 [[154](#bib.bib154)] 中，添加了一个损失项来最小化模型在未标记数据上的预测熵，目标函数变为：
- en: '|  | <math   alttext="\begin{split}C(\theta,\lambda;\mathcal{L}_{n})&amp;=L(\theta;\mathcal{L}_{n})-\lambda
    H_{emp}(Y&#124;X,Z;\mathcal{L}_{n})\\ &amp;=\sum_{i=1}^{n}\log(\sum_{k=1}^{K}z_{ik}f_{k}(x_{i}))\\'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math alttext="\begin{split}C(\theta,\lambda;\mathcal{L}_{n})&amp;=L(\theta;\mathcal{L}_{n})-\lambda
    H_{emp}(Y&#124;X,Z;\mathcal{L}_{n})\\ &amp;=\sum_{i=1}^{n}\log(\sum_{k=1}^{K}z_{ik}f_{k}(x_{i}))\\'
- en: '&amp;+\lambda\sum_{i=1}^{n}\sum_{k=1}^{K}g_{k}(x_{i},z_{i})\log g_{k}(x_{i},z_{i})\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd  columnalign="right" ><mrow ><mi  >C</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><mi >θ</mi><mo  >,</mo><mi >λ</mi><mo >;</mo><msub
    ><mi >ℒ</mi><mi  >n</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mo >=</mo><mrow ><mrow  ><mi >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mi >θ</mi><mo  >;</mo><msub
    ><mi >ℒ</mi><mi >n</mi></msub><mo stretchy="false" >)</mo></mrow></mrow><mo >−</mo><mrow
    ><mi  >λ</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi >H</mi><mrow ><mi
    >e</mi><mo lspace="0em" rspace="0em" >​</mo><mi >m</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    >p</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mrow ><mi  >Y</mi><mo fence="false"  >&#124;</mo><mrow ><mi >X</mi><mo
    >,</mo><mi >Z</mi><mo >;</mo><msub ><mi >ℒ</mi><mi >n</mi></msub></mrow></mrow><mo
    stretchy="false" >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mo rspace="0.111em" >=</mo><mrow ><munderover ><mo movablelimits="false" >∑</mo><mrow
    ><mi  >i</mi><mo >=</mo><mn >1</mn></mrow><mi >n</mi></munderover><mrow ><mi >log</mi><mo
    >⁡</mo><mrow ><mo stretchy="false" >(</mo><mrow ><munderover ><mo lspace="0em"
    movablelimits="false" >∑</mo><mrow ><mi  >k</mi><mo >=</mo><mn >1</mn></mrow><mi
    >K</mi></munderover><mrow ><msub ><mi >z</mi><mrow ><mi >i</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi >k</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >f</mi><mi >k</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    stretchy="false"  >(</mo><msub ><mi >x</mi><mi >i</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mo >+</mo><mrow  ><mi >λ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><munderover
    ><mo movablelimits="false" rspace="0em"  >∑</mo><mrow ><mi >i</mi><mo >=</mo><mn
    >1</mn></mrow><mi >n</mi></munderover><mrow ><munderover ><mo movablelimits="false"
    >∑</mo><mrow ><mi  >k</mi><mo >=</mo><mn >1</mn></mrow><mi >K</mi></munderover><mrow
    ><msub ><mi  >g</mi><mi >k</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msub ><mi >x</mi><mi >i</mi></msub><mo >,</mo><msub
    ><mi  >z</mi><mi >i</mi></msub><mo stretchy="false"  >)</mo></mrow><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi >log</mi><mo lspace="0.167em" >⁡</mo><msub ><mi  >g</mi><mi
    >k</mi></msub></mrow><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><msub
    ><mi >x</mi><mi >i</mi></msub><mo >,</mo><msub ><mi  >z</mi><mi >i</mi></msub><mo
    stretchy="false"  >)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >𝐶</ci><vector  ><ci >𝜃</ci><ci
    >𝜆</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >ℒ</ci><ci >𝑛</ci></apply></vector></apply><apply
    ><apply  ><ci >𝐿</ci><list ><ci >𝜃</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ℒ</ci><ci >𝑛</ci></apply></list></apply><apply ><ci  >𝜆</ci><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐻</ci><apply ><ci >𝑒</ci><ci >𝑚</ci><ci
    >𝑝</ci></apply></apply><apply ><csymbol cd="latexml" >conditional</csymbol><ci
    >𝑌</ci><list ><ci >𝑋</ci><ci >𝑍</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ℒ</ci><ci >𝑛</ci></apply></list></apply></apply></apply></apply><apply ><apply
    ><apply  ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑛</ci></apply><apply ><apply  ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><ci >𝑘</ci><cn type="integer"
    >1</cn></apply></apply><ci >𝐾</ci></apply><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑧</ci><apply ><ci >𝑖</ci><ci >𝑘</ci></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑓</ci><ci >𝑘</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑥</ci><ci >𝑖</ci></apply></apply></apply></apply></apply><apply ><ci >𝜆</ci><apply  ><apply
    ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑛</ci></apply><apply ><apply  ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><ci >𝑘</ci><cn type="integer"
    >1</cn></apply></apply><ci >𝐾</ci></apply><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑔</ci><ci >𝑘</ci></apply><interval closure="open" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑥</ci><ci >𝑖</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑧</ci><ci >𝑖</ci></apply></interval><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑔</ci><ci >𝑘</ci></apply></apply><interval closure="open" ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑥</ci><ci >𝑖</ci></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑧</ci><ci >𝑖</ci></apply></interval></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}C(\theta,\lambda;\mathcal{L}_{n})&=L(\theta;\mathcal{L}_{n})-\lambda
    H_{emp}(Y&#124;X,Z;\mathcal{L}_{n})\\ &=\sum_{i=1}^{n}\log(\sum_{k=1}^{K}z_{ik}f_{k}(x_{i}))\\
    &+\lambda\sum_{i=1}^{n}\sum_{k=1}^{K}g_{k}(x_{i},z_{i})\log g_{k}(x_{i},z_{i})\end{split}</annotation></semantics></math>
    |  | (4) |'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '&amp;+\lambda\sum_{i=1}^{n}\sum_{k=1}^{K}g_{k}(x_{i},z_{i})\log g_{k}(x_{i},z_{i})\end{split}"
    display="block"><semantics ><mtable columnspacing="0pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd  columnalign="right" ><mrow ><mi  >C</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false" >(</mo><mi >θ</mi><mo  >,</mo><mi >λ</mi><mo >;</mo><msub
    ><mi >ℒ</mi><mi  >n</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow></mtd><mtd
    columnalign="left"  ><mrow ><mo >=</mo><mrow ><mrow  ><mi >L</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><mi >θ</mi><mo  >;</mo><msub
    ><mi >ℒ</mi><mi >n</mi></msub><mo stretchy="false" >)</mo></mrow></mrow><mo >−</mo><mrow
    ><mi  >λ</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi >H</mi><mrow ><mi
    >e</mi><mo lspace="0em" rspace="0em" >​</mo><mi >m</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    >p</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"
    >(</mo><mrow ><mi  >Y</mi><mo fence="false"  >&#124;</mo><mrow ><mi >X</mi><mo
    >,</mo><mi >Z</mi><mo >;</mo><msub ><mi >ℒ</mi><mi >n</mi></msub></mrow></mrow><mo
    stretchy="false" >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mo rspace="0.111em" >=</mo><mrow ><munderover ><mo movablelimits="false" >∑</mo><mrow
    ><mi  >i</mi><mo >=</mo><mn >1</mn></mrow><mi >n</mi></munderover><mrow ><mi >log</mi><mo
    >⁡</mo><mrow ><mo stretchy="false" >(</mo><mrow ><munderover ><mo lspace="0em"
    movablelimits="false" >∑</mo><mrow ><mi  >k</mi><mo >=</mo><mn >1</mn></mrow><mi
    >K</mi></munderover><mrow ><msub ><mi >z</mi><mrow ><mi >i</mi><mo lspace="0em"
    rspace="0em"  >​</mo><mi >k</mi></mrow></msub><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >f</mi><mi >k</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo
    stretchy="false"  >(</mo><msub ><mi >x</mi><mi >i</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow></mrow><mo
    stretchy="false"  >)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr ><mtd columnalign="left"  ><mrow
    ><mo >+</mo><mrow  ><mi >λ</mi><mo lspace="0em" rspace="0em"  >​</mo><mrow ><munderover
    ><mo movablelimits="false" rspace="0em"  >∑</mo><mrow ><mi >i</mi><mo >=</mo><mn
    >1</mn></mrow><mi >n</mi></munderover><mrow ><munderover ><mo movablelimits="false"
    >∑</mo><mrow ><mi  >k</mi><mo >=</mo><mn >1</mn></mrow><mi >K</mi></munderover><mrow
    ><msub ><mi  >g</mi><mi >k</mi></msub><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mo stretchy="false"  >(</mo><msub ><mi >x</mi><mi >i</mi></msub><mo >,</mo><msub
    ><mi  >z</mi><mi >i</mi></msub><mo stretchy="false"  >)</mo></mrow><mo lspace="0.167em"
    rspace="0em"  >​</mo><mrow ><mi >log</mi><mo lspace="0.167em" >⁡</mo><msub ><mi  >g</mi><mi
    >k</mi></msub></mrow><mo lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false"  >(</mo><msub
    ><mi >x</mi><mi >i</mi></msub><mo >,</mo><msub ><mi  >z</mi><mi >i</mi></msub><mo
    stretchy="false"  >)</mo></mrow></mrow></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml
    encoding="MathML-Content" ><apply ><apply  ><apply ><ci >𝐶</ci><vector  ><ci >𝜃</ci><ci
    >𝜆</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >ℒ</ci><ci >𝑛</ci></apply></vector></apply><apply
    ><apply  ><ci >𝐿</ci><list ><ci >𝜃</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ℒ</ci><ci >𝑛</ci></apply></list></apply><apply ><ci  >𝜆</ci><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝐻</ci><apply ><ci >𝑒</ci><ci >𝑚</ci><ci
    >𝑝</ci></apply></apply><apply ><csymbol cd="latexml" >conditional</csymbol><ci
    >𝑌</ci><list ><ci >𝑋</ci><ci >𝑍</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >ℒ</ci><ci >𝑛</ci></apply></list></apply></apply></apply></apply><apply ><apply
    ><apply  ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑛</ci></apply><apply ><apply  ><apply ><csymbol cd="ambiguous" >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><apply ><ci >𝑘</ci><cn type="integer"
    >1</cn></apply></apply><ci >𝐾</ci></apply><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑧</ci><apply ><ci >𝑖</ci><ci >𝑘</ci></apply></csymbol></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}C(\theta,\lambda;\mathcal{L}_{n})&=L(\theta;\mathcal{L}_{n})-\lambda
    H_{emp}(Y&#124;X,Z;\mathcal{L}_{n})\\ &=\sum_{i=1}^{n}\log(\sum_{k=1}^{K}z_{ik}f_{k}(x_{i}))\\
    &+\lambda\sum_{i=1}^{n}\sum_{k=1}^{K}g_{k}(x_{i},z_{i})\log g_{k}(x_{i},z_{i})\end{split}</annotation></semantics></math>
    |  | (4) |'
- en: 'where $L(\theta;\mathcal{L}_{n})$ is the conditional log-likelihood and sensitive
    to the labeled data and $H_{emp}(Y|X,Z;\mathcal{L}_{n})$ is conditional entropy
    and only affected by the unlabeled data which works to minimize the class overlap.
    $x_{i}$ and $z_{i}$ represent inputs and corresponding labels. If $x_{i}$ is labeled
    $\omega_{k}$, then $z_{ik}=1$ and $z_{il}=0$ for $l\neq k$ ; if $X_{i}$ is unlabeled,
    then $z_{il}=1$ for $l=1...k$. $f_{k}(x_{i})$ and $g_{k}(x_{i},z_{i})$ denote
    the model of $P(\omega_{k}|x_{i})$ and the model of $P(\omega_{k}|x_{i},z_{i})$.
    Wu et al. [[105](#bib.bib105)] add entropy minimization technique in the student
    branch. Berthelot et al. [[146](#bib.bib146)] propose MixMatch to use a sharpening
    function on the target distribution of unlabeled data to minimize the entropy.
    The sharpening through adjusting the “temperature” of this categorical distribution
    is as follow:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $L(\theta;\mathcal{L}_{n})$ 是条件对数似然，受标记数据影响，$H_{emp}(Y|X,Z;\mathcal{L}_{n})$
    是条件熵，仅受未标记数据影响，旨在最小化类别重叠。$x_{i}$ 和 $z_{i}$ 代表输入和对应的标签。如果 $x_{i}$ 被标记为 $\omega_{k}$，则
    $z_{ik}=1$ 且 $z_{il}=0$ 对于 $l\neq k$；如果 $X_{i}$ 是未标记的，则 $z_{il}=1$ 对于 $l=1...k$。$f_{k}(x_{i})$
    和 $g_{k}(x_{i},z_{i})$ 分别表示 $P(\omega_{k}|x_{i})$ 的模型和 $P(\omega_{k}|x_{i},z_{i})$
    的模型。Wu 等人 [[105](#bib.bib105)] 在学生分支中添加了熵最小化技术。Berthelot 等人 [[146](#bib.bib146)]
    提出了 MixMatch，使用锐化函数对未标记数据的目标分布进行熵最小化。通过调整该分类分布的“温度”来进行锐化如下：
- en: '|  | $\begin{split}Sharpen(p,T)_{i}=p_{i}^{\frac{1}{T}}/\sum_{j=1}^{L}p_{j}^{\frac{1}{T}}\end{split}$
    |  | (5) |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}Sharpen(p,T)_{i}=p_{i}^{\frac{1}{T}}/\sum_{j=1}^{L}p_{j}^{\frac{1}{T}}\end{split}$
    |  | (5) |'
- en: where $p$ is input categorical distribution and $T$ is a hyperparameter. As
    $T\rightarrow{}$ 0 , the output of $Sharpen(p,T)$ will approach a Dirac (“one-hot”)
    distribution. Lowering temperature encourages model to produce lower-entropy predictions.
    However, the hyperparameter needs to be set carefully and different samples may
    have different $T$, so [[2](#bib.bib2)] propose an adaptive sharpening which can
    adjust T adaptively for each sample according to its uncertainty predicted by
    the model. [[159](#bib.bib159)] introduce a mutual exclusivity loss for multi-class
    problems that explicitly forces the predictions to be mutually exclusive and encourages
    the decision boundary to lie on the low density space between the manifolds corresponding
    to different classes of data, which has a better performance in object detection
    task compared with entropy minimization in [[154](#bib.bib154)].
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $p$ 是输入的分类分布，$T$ 是一个超参数。随着 $T\rightarrow{}$ 0，$Sharpen(p,T)$ 的输出将接近于 Dirac（“one-hot”）分布。降低温度鼓励模型生成低熵的预测。然而，超参数需要仔细设置，不同样本可能有不同的
    $T$，因此 [[2](#bib.bib2)] 提出了自适应锐化方法，该方法可以根据模型预测的不确定性为每个样本自适应调整 $T$。[[159](#bib.bib159)]
    引入了一个互斥损失，用于多类别问题，强制预测结果相互排斥，并鼓励决策边界位于不同类别数据流形之间的低密度空间，这在目标检测任务中相比于 [[154](#bib.bib154)]
    的熵最小化表现更好。
- en: Another application of entropy minimization is the use of hard label in the
    pseudo labeling. As argmax operation applied to a probability distribution can
    produce a valid “one-hot” low-entropy (i.e., high-confidence) distribution, both
    the entropy minimization and pseudo labeling encourages the decision boundary
    passing low-density regions. Therefore, the strategy of using hard label in the
    pseudo labeling is closely related with entropy minimization [[160](#bib.bib160)].
    However, a high capacity model that tends to overfit quickly can give high-confidence
    predictions which also have low entropy [[161](#bib.bib161)]. Therefore, entropy
    minimization doesn’t work in some cases [[154](#bib.bib154)].
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 熵最小化的另一个应用是在伪标签中的硬标签使用。由于对概率分布应用 argmax 操作可以产生有效的“one-hot”低熵（即高置信度）分布，因此熵最小化和伪标签都鼓励决策边界穿越低密度区域。因此，在伪标签中使用硬标签的策略与熵最小化密切相关
    [[160](#bib.bib160)]。然而，一个容易过拟合的高容量模型可能会给出高置信度的预测，这也有低熵 [[161](#bib.bib161)]。因此，熵最小化在某些情况下不起作用
    [[154](#bib.bib154)]。
- en: 'Table 4: The summarized review of semi-supervised medical image segmentation
    methods with adversarial learning and entropy minimization.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：带有对抗学习和熵最小化的半监督医学图像分割方法的总结回顾。
- en: '| Reference | 2D/3D | Modality | Dataset | Highlights | Class |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 2D/3D | 模态 | 数据集 | 亮点 | 类别 |'
- en: '| CAFD, Wu et al.[[134](#bib.bib134)] | 2D | Colonoscope | Kvasir-SEG [[196](#bib.bib196)],
    CVC-Clinic DB [[188](#bib.bib188)] | Introduce collaborative and adversarial learning
    of focused and dispersive representations | Adversarial learning |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| CAFD, 吴等[[134](#bib.bib134)] | 2D | 胶囊内镜 | Kvasir-SEG [[196](#bib.bib196)],
    CVC-Clinic DB [[188](#bib.bib188)] | 引入专注与分散表征的协作与对抗学习 | 对抗学习 |'
- en: '| SSTD-Aug, Chaitanya et al. [[117](#bib.bib117)] | 2D | MRI | ACDC dataset
    [[22](#bib.bib22)] | Task-driven data augmentation method to synthesize new training
    examples | Adversarial learning |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| SSTD-Aug, Chaitanya 等 [[117](#bib.bib117)] | 2D | MRI | ACDC 数据集 [[22](#bib.bib22)]
    | 任务驱动的数据增强方法以合成新的训练示例 | 对抗学习 |'
- en: '| DAN, Zhang et al.[[45](#bib.bib45)] | 3D | Microscopy | Gland Segmentation
    Challenge dataset [[189](#bib.bib189)] | Introduce adversarial learning to encourage
    the segmentation output of unlabeled data to be similar with the annotations of
    labeled data. | Adversarial learning |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| DAN, 张等[[45](#bib.bib45)] | 3D | 显微镜 | 腺体分割挑战数据集 [[189](#bib.bib189)] | 引入对抗学习，鼓励未标记数据的分割结果与标记数据的注释相似。
    | 对抗学习 |'
- en: '| GAVA, Li et al.[[125](#bib.bib125)] | 2D | MRI | M&Ms dataset [[123](#bib.bib123)]
    | Employ U-net as encoder and conditional GAN as decoder | Adversarial learning
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| GAVA, 李等[[125](#bib.bib125)] | 2D | MRI | M&Ms 数据集 [[123](#bib.bib123)] |
    使用 U-net 作为编码器，条件 GAN 作为解码器 | 对抗学习 |'
- en: '| LeakGAN_ssl, Hou et al.[[144](#bib.bib144)] | 2D | Fundus | DRIVE[[190](#bib.bib190)],
    STARE[[191](#bib.bib191)], CHASE_DB1[[192](#bib.bib192)] | Add a leaking GAN to
    pollute the discriminator by leaking information from the generator for more moderate
    generations | Adversarial learning |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| LeakGAN_ssl, 侯等[[144](#bib.bib144)] | 2D | 眼底 | DRIVE[[190](#bib.bib190)],
    STARE[[191](#bib.bib191)], CHASE_DB1[[192](#bib.bib192)] | 添加泄漏 GAN，通过从生成器泄漏信息来污染判别器，以实现更温和的生成
    | 对抗学习 |'
- en: '| LG-ER-MT, Hang et al.[[33](#bib.bib33)] | 3D | MRI | LA dataset [[66](#bib.bib66)]
    | Introduce the entropy minimization principle to the student network | Entropy
    minimization |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| LG-ER-MT, Hang 等[[33](#bib.bib33)] | 3D | MRI | LA 数据集 [[66](#bib.bib66)]
    | 将熵最小化原则引入学生网络 | 熵最小化 |'
- en: '| MC-Net, Wu et al.[[2](#bib.bib2)] | 3D | MRI | LA dataset [[66](#bib.bib66)]
    | Adjust sharpening temperature adaptively according to the uncertainty predicted
    by the model | Entropy minimization |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| MC-Net, 吴等[[2](#bib.bib2)] | 3D | MRI | LA 数据集 [[66](#bib.bib66)] | 根据模型预测的不确定性自适应调整锐化温度
    | 熵最小化 |'
- en: 3.3 Semi-Supervised Medical Image Segmentation with Knowledge Priors
  id: totrans-160
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 带有知识先验的半监督医学图像分割
- en: 'Knowledge priors are the information that a learner already has before it learns
    new information, and sometimes are helpful for dealing with new tasks. Compared
    with non-medical images, medical images have many anatomical priors such as the
    shape and position of organs and incorporating the anatomical prior knowledge
    in deep learning can improve the performance for medical image segmentation [[153](#bib.bib153)].
    Some semi-supervised algorithms utilize knowledge priors to improve the representation
    ability for new tasks. While knowledge priors can be helpful in semi-supervised
    medical image segmentation, there are also several limitations to consider:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 知识先验是学习者在学习新信息之前已经掌握的信息，有时对处理新任务有帮助。与非医学图像相比，医学图像具有许多解剖学先验，如器官的形状和位置，将解剖学先验知识纳入深度学习可以提高医学图像分割的性能
    [[153](#bib.bib153)]。一些半监督算法利用知识先验来提高对新任务的表征能力。虽然知识先验在半监督医学图像分割中可能有帮助，但也有几个需要考虑的限制：
- en: '1\. Overfitting: If the prior knowledge is too specific to the training data,
    it may lead to overfitting, where the model performs well on the training data
    but poorly on new, unseen data.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 1\. 过拟合：如果先验知识过于特定于训练数据，可能会导致过拟合，使得模型在训练数据上表现良好，但在新数据上表现不佳。
- en: '2\. Non-differentiable: Some complex priors, such as region connectivity, convexity
    and symmetry are usually non-differentiable and complex losses need to be designed.
    In this part, we categorize the knowledge priors as self-supervised tasks and
    anatomical priors.'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 2\. 非可微分：一些复杂的先验，如区域连通性、凸性和对称性，通常是非可微分的，需要设计复杂的损失函数。在这一部分，我们将知识先验分为自监督任务和解剖学先验。
- en: '![Refer to caption](img/31f7f9d158186cd48db3544ea363c547.png)'
  id: totrans-164
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/31f7f9d158186cd48db3544ea363c547.png)'
- en: 'Figure 11: DPA-DenseBiasNet [[152](#bib.bib152)] for fine renal artery segmentation.
    An auto-encoder of a reconstruction task is trained in stage 1 process. The deep
    prior anatomy (DPA) features extracted from the encoder, which contain representations
    of anatomy priors, are then embedded for the downstream segmentation task in stage
    2 process.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：DPA-DenseBiasNet [[152](#bib.bib152)] 用于细化肾动脉分割。重建任务的自编码器在阶段 1 过程中进行训练。从编码器提取的深度先验解剖（DPA）特征包含解剖先验的表示，然后在阶段
    2 过程中嵌入以用于下游分割任务。
- en: 'Self-supervised tasks which employs large unlabeled data to train networks
    can provide useful representations and visual priors. An important role is to
    pretrain networks and provide better starting points for target tasks. For example,
    huang et al. [[99](#bib.bib99)] add a reconstruction pre-training from the counterparts
    to avoid networks being randomly initialized in a cold start stage. Wang et al.
    [[131](#bib.bib131)] use superpixels to separate an image into regions and learned
    intra- and inter-organ representation based on contrastive learning, then the
    model is used to initialize the semi-supervised framework, which boost the performance
    significantly. Self-supervised tasks can also be trained jointly with target semi-supervised
    tasks as regularization. Contrastive learning are the most popular methods to
    integrate with semi-supervised framework. For example, hu et al. [[98](#bib.bib98)]
    introduce the self-supervised image-level and pixel-level contrastive learning
    into the semi-supervised framework. [[80](#bib.bib80)] integrate self-paced contrastive
    learning. Wu et al. [[105](#bib.bib105)] add patch- and pixel-level dense contrastive
    loss to align the features from the teacher and student models. Zhao et al. [[133](#bib.bib133)]
    introduce the multi-scale multi-view global-local contrastive learning into co-training
    framework. However, in contrastive learning, negative samples may come from the
    similar features from anchors, which may confuse models during training. You et
    al. [[199](#bib.bib199)] integrate contrastive learning from a variance-reduction
    perspective, which uses stratified group sampling theory and generalize well in
    long-tail distribution. Except contrastive learning, jigsaw puzzle tasks [[120](#bib.bib120)],
    lesion region inpainting [[3](#bib.bib3)] and reconstruction tasks [[152](#bib.bib152)]
    can also be utilized easily into semi-supervised framework. [[3](#bib.bib3)] propose
    a dual-task network with a shared encoder and two independent decoders for lesion
    region inpainting and segmentation. They also add entropy minimization technique
    in the student branch. He et al. [[152](#bib.bib152)] train an auto-encoder through
    a reconstruction task and the deep prior anatomy (DPA) features extracted from
    it are then embedded for segmenting, as shown in Figure [11](#S3.F11 "Figure 11
    ‣ 3.3 Semi-Supervised Medical Image Segmentation with Knowledge Priors ‣ 3 Related
    Work on Semi-Supervised Medical Image Segmentation ‣ Learning with Limited Annotations:
    A Survey on Deep Semi-supervised Learning for Medical Image Segmentation").'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: '自监督任务利用大量未标记的数据来训练网络，可以提供有用的表示和视觉先验。一个重要作用是预训练网络，为目标任务提供更好的起点。例如，huang 等人 [[99](#bib.bib99)]
    添加了一个来自对等体的重建预训练，以避免网络在冷启动阶段随机初始化。Wang 等人 [[131](#bib.bib131)] 使用超像素将图像分割成区域，并基于对比学习学习了内部和外部的表示，然后将模型用于初始化半监督框架，这显著提升了性能。自监督任务还可以与目标半监督任务共同训练作为正则化。对比学习是与半监督框架集成的最流行方法。例如，hu
    等人 [[98](#bib.bib98)] 将自监督图像级和像素级对比学习引入半监督框架。[[80](#bib.bib80)] 集成了自适应对比学习。Wu
    等人 [[105](#bib.bib105)] 添加了补丁级和像素级的密集对比损失，以对齐教师和学生模型的特征。Zhao 等人 [[133](#bib.bib133)]
    将多尺度多视角的全局-局部对比学习引入共训练框架。然而，在对比学习中，负样本可能来自于锚点的相似特征，这可能在训练过程中使模型混淆。You 等人 [[199](#bib.bib199)]
    从方差减少的角度整合了对比学习，使用了分层组抽样理论，并在长尾分布中表现良好。除了对比学习，拼图任务 [[120](#bib.bib120)]、病灶区域修复
    [[3](#bib.bib3)] 和重建任务 [[152](#bib.bib152)] 也可以轻松地融入半监督框架。[[3](#bib.bib3)] 提出了一个具有共享编码器和两个独立解码器的双任务网络，用于病灶区域修复和分割。他们还在学生分支中添加了熵最小化技术。He
    等人 [[152](#bib.bib152)] 通过重建任务训练了一个自编码器，然后提取的深度先验解剖（DPA）特征被嵌入用于分割，如图 [11](#S3.F11
    "Figure 11 ‣ 3.3 Semi-Supervised Medical Image Segmentation with Knowledge Priors
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation") 所示。'
- en: '![Refer to caption](img/2d48bbbeeafff6af33b40139c9ae5d1d.png)'
  id: totrans-167
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2d48bbbeeafff6af33b40139c9ae5d1d.png)'
- en: 'Figure 12: Illustration of the framework of $ABS^{3}Net$ [[79](#bib.bib79)]
    with the confidence map. The left is the $ABS^{3}Net$, in which atlas-based pixel
    selection module is introduced to select reliable pixel results based on pixel-wise
    confidence. The right shows the atlas-based confidence map. The high confidence
    (shown in red) represents both probability atlas map (PA) and the segmentation
    probability map $s_{output}$ are close to the prediction mask $s_{mask}$. The
    confidence decreases from red to blue.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：$ABS^{3}Net$的框架示意图[[79](#bib.bib79)]，包括置信度图。左侧是$ABS^{3}Net$，其中引入了基于图谱的像素选择模块，以基于像素级置信度选择可靠的像素结果。右侧显示了基于图谱的置信度图。高置信度（以红色显示）表示概率图谱（PA）和分割概率图$s_{output}$接近于预测掩膜$s_{mask}$。置信度从红色逐渐减少到蓝色。
- en: 'Anatomical priors include fixed locations, shapes, region sizes and anatomical
    relations and so on. Objects, such as organs, in medical segmentation usually
    have fixed locations and shapes. To take position information and shape prior
    into account, atlas maps are widely applied in medical image segmentation[[157](#bib.bib157),
    [158](#bib.bib158), [153](#bib.bib153), [79](#bib.bib79), [111](#bib.bib111)].
    As shown in Figure [13](#S3.F13 "Figure 13 ‣ 3.3 Semi-Supervised Medical Image
    Segmentation with Knowledge Priors ‣ 3 Related Work on Semi-Supervised Medical
    Image Segmentation ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation"), an atlas map, which indicates the probability
    of objects appearing at some location, can be generated as follows. First, annotated
    volumes need to be registered to a referenced volume. Then the probabilistic atlas
    (PA) can be generated through averaging manually masks after deformable of all
    annotated volumes. For example, Zheng et al. [[153](#bib.bib153)] calculate the
    liver PA and predefined the hard pixel samples with the atlas values close to
    0.5\. Huang et al. [[79](#bib.bib79)] utilize PA to give the unlabeled data segmentation
    pixel-wise confidence to select reliable pixel results, as shown in Figure [12](#S3.F12
    "Figure 12 ‣ 3.3 Semi-Supervised Medical Image Segmentation with Knowledge Priors
    ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation ‣ Learning with
    Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical Image
    Segmentation"). The pixel-wise confidence is calculated as follows:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 解剖学先验包括固定的位置、形状、区域大小和解剖关系等。医学分割中的物体（如器官）通常具有固定的位置和形状。为了考虑位置信息和形状先验，图谱图在医学图像分割中被广泛应用[[157](#bib.bib157),
    [158](#bib.bib158), [153](#bib.bib153), [79](#bib.bib79), [111](#bib.bib111)]。如图[13](#S3.F13
    "图 13 ‣ 3.3 基于知识先验的半监督医学图像分割 ‣ 3 半监督医学图像分割的相关工作 ‣ 有限标注学习：医学图像分割的深度半监督学习调查")所示，图谱图可以生成如下。首先，需将注释的体积注册到参考体积。然后，通过对所有注释体积进行形变后平均手动掩膜，可以生成概率图谱（PA）。例如，郑等人[[153](#bib.bib153)]计算了肝脏PA并将图谱值接近0.5的硬像素样本进行预定义。黄等人[[79](#bib.bib79)]利用PA为未标记数据提供像素级置信度，以选择可靠的像素结果，如图[12](#S3.F12
    "图 12 ‣ 3.3 基于知识先验的半监督医学图像分割 ‣ 3 半监督医学图像分割的相关工作 ‣ 有限标注学习：医学图像分割的深度半监督学习调查")所示。像素级置信度计算如下：
- en: '|  | $\begin{split}Confidence=\exp(-\frac{(PA-s_{mask})^{2}+(s_{output}-s_{mask})^{2}}{2\sigma^{2}})\end{split}$
    |  | (6) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}Confidence=\exp(-\frac{(PA-s_{mask})^{2}+(s_{output}-s_{mask})^{2}}{2\sigma^{2}})\end{split}$
    |  | (6) |'
- en: '|  | $\begin{split}s_{mask}=[s_{output}+0.5]\end{split}$ |  | (7) |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}s_{mask}=[s_{output}+0.5]\end{split}$ |  | (7) |'
- en: 'where $s_{output}$ and $s_{mask}$ refer to the segmentation probability map
    for the organ to be segmented and the prediction mask of unlabeled data, whose
    value is only 0 or 1\. $[\cdot]$ denotes the integer-valued function. As can be
    seen in Figure [12](#S3.F12 "Figure 12 ‣ 3.3 Semi-Supervised Medical Image Segmentation
    with Knowledge Priors ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation"), the confidence decreases from red to blue and
    the confidence is higher, when both PA and $s_{output}$ are close to $s_{mask}$,
    that is 0 or 1\. However, segmentation algorithms utilizing atlas maps may be
    unsuitable for targets that have large positional variance. Furthermore, the segmentation
    performance highly relies on accurate registration. Fixed locations and shapes
    are always utilized in organ segmentation whereas anatomical relations can be
    utilized in multi-type pathology segmentation. Anatomical relations represent
    relative locations of different objects. For example, MyoPS-Net [[200](#bib.bib200)]
    uses inclusiveness loss to represent relations between different types of pathologies,
    which constrains the pixels of scars to be included in the pixels of edema. [[217](#bib.bib217)]
    propose magic-cube partition and recovery, encouraging unlabeled images to learn
    organ semantics in relative locations from labeled images. The limitation of this
    magic-cube partition and recovery augmentation is that it may not work well on
    unaligned images. Another assumption is that objects from the same class across
    all the samples share the same anatomical adjacencies, despite their varying region
    geometries, thus an adjacency-graph based auxiliary training loss that penalizes
    outputs with anatomically incorrect region relationships is introduced in [[220](#bib.bib220)].
    For size priors, PaNN[[198](#bib.bib198)] constrains the predicted average distribution
    of organ sizes to be similar with the prior statistics from the labeled dataset.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $s_{output}$ 和 $s_{mask}$ 指的是待分割器官的分割概率图和未标记数据的预测掩膜，其值仅为 0 或 1。 $[\cdot]$
    表示整数值函数。如图 [12](#S3.F12 "Figure 12 ‣ 3.3 Semi-Supervised Medical Image Segmentation
    with Knowledge Priors ‣ 3 Related Work on Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation") 所示，信心度从红色到蓝色逐渐降低，当 PA 和 $s_{output}$ 接近 $s_{mask}$
    时，即 0 或 1，信心度较高。然而，利用图谱图的分割算法可能不适用于具有大位置变化的目标。此外，分割性能高度依赖于准确的配准。器官分割通常利用固定位置和形状，而多类型病理分割可以利用解剖关系。解剖关系表示不同物体的相对位置。例如，MyoPS-Net
    [[200](#bib.bib200)] 使用包容性损失来表示不同类型病理之间的关系，这约束了伤疤的像素包含在水肿的像素中。 [[217](#bib.bib217)]
    提出了魔方分割和恢复，鼓励未标记图像从标记图像中学习器官语义的相对位置。这种魔方分割和恢复增强的局限性在于它可能不适用于未对齐的图像。另一个假设是尽管样本的区域几何形状不同，但同一类别的对象在所有样本中共享相同的解剖邻接关系，因此在
    [[220](#bib.bib220)] 中引入了一种基于邻接图的辅助训练损失，惩罚解剖上不正确的区域关系的输出。对于尺寸先验，PaNN[[198](#bib.bib198)]
    约束预测的器官大小的平均分布与标记数据集中的先验统计数据相似。'
- en: The algorithms mentioned above are typically simple whereas some complex priors,
    such as region connectivity, convexity, symmetry are usually non-differentiable.
    Therefore, specific losses need to be designed for these complex constraints.
    In [[215](#bib.bib215)], an out-of-box and differentiable way to consider complex
    anatomical priors is developed based on reinforce algorithm and adversarial samples.
    Experiments show that clinical-plausible segmentations are obtained. Another work
    in [[219](#bib.bib219)] introduces persistent homology, a concept from topological
    data analysis, to specify the desired topology of segmented objects in terms of
    their Betti numbers and then drive the predictions of unlabeled data to contain
    the specified topological features. The Betti numbers count the number of features
    of some dimension, such as the number of connected components, the number of loops
    or holes, the number of hollow voids and so on. This process does not require
    any ground-truth labels, just prior knowledge of the topology of the structure
    being segmented. The idea of persistent homology can be applicable for segmentation
    of objects with a fixed and regular shape, such as cardiac chambers and myocardium.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 上述提到的算法通常很简单，而一些复杂的先验知识，例如区域连通性、凸性、对称性，通常是不可微分的。因此，需要为这些复杂的约束设计特定的损失函数。在 [[215](#bib.bib215)]
    中，开发了一种基于强化算法和对抗样本的、可以处理复杂解剖学先验的现成可微分方法。实验结果显示，得到了临床上合理的分割结果。另一项工作在 [[219](#bib.bib219)]
    中引入了持久同源性，这是一种来自拓扑数据分析的概念，用于指定分割对象的期望拓扑结构，即其 Betti 数，然后驱动未标记数据的预测以包含指定的拓扑特征。Betti
    数计算某些维度的特征数量，例如连通组件的数量、环或孔的数量、空洞的数量等。此过程不需要任何真实标签，只需对被分割结构的拓扑有先验知识。持久同源性的方法适用于分割具有固定且规则形状的对象，例如心脏腔室和心肌。
- en: Rich knowledge priors make medical image segmentation different from natural
    image segmentation. In semi-supervised medical image segmentation with limited
    labeled data, more accurate and plausible results can be obtained by incorporating
    medical knowledge priors.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 丰富的知识先验使医学图像分割不同于自然图像分割。在标记数据有限的半监督医学图像分割中，通过结合医学知识先验，可以获得更准确且合理的结果。
- en: '![Refer to caption](img/636bf48ac389f166ef9a112c41f1c743.png)![Refer to caption](img/5238d36313f4dc1d3438604f077e582a.png)![Refer
    to caption](img/02b2c17fa6c6dd84fe50b87e4cb9e5be.png)'
  id: totrans-175
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/636bf48ac389f166ef9a112c41f1c743.png)![参见说明](img/5238d36313f4dc1d3438604f077e582a.png)![参见说明](img/02b2c17fa6c6dd84fe50b87e4cb9e5be.png)'
- en: 'Figure 13: The 3D probabilistic atlas of liver organ [[79](#bib.bib79)], which
    indicates the probability of liver pixels appearing at some location. (a)-(c)
    are superior–inferior, left–right direction and anterior–posterior direction correspondingly.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：肝脏器官的 3D 概率图谱 [[79](#bib.bib79)]，显示了肝脏像素在某些位置出现的概率。(a)-(c) 分别对应优–劣、左右方向和前–后方向。
- en: 'Table 5: The summarized review of semi-supervised medical image segmentation
    methods with knowledge priors.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：带有知识先验的半监督医学图像分割方法的总结综述。
- en: '| Reference | 2D/3D | Modality | Dataset | Highlights | Class |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 2D/3D | 模态 | 数据集 | 亮点 | 类别 |'
- en: '| SepaReg, Wang et al.[[131](#bib.bib131)] | 3D | CT | PDDCA[[193](#bib.bib193)]
    | Initialization with pre-trained model based on intra- and inter-organ contrastive
    learning | Contrastive learning |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| SepaReg, Wang 等 [[131](#bib.bib131)] | 3D | CT | PDDCA[[193](#bib.bib193)]
    | 基于内外器官对比学习的预训练模型初始化 | 对比学习 |'
- en: '| S4 ML, Kiyasseh et al.[[122](#bib.bib122)] | 2D | MRI | LA dataset [[66](#bib.bib66)]
    | Using dataform multi centers through meta-learning and contrastive learning
    task performed with unlabelled data | Contrastive learning |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| S4 ML, Kiyasseh 等 [[122](#bib.bib122)] | 2D | MRI | LA 数据集 [[66](#bib.bib66)]
    | 使用数据形式的多个中心通过元学习和对比学习任务处理未标记数据 | 对比学习 |'
- en: '| Le-SSCL, Hu et al.[[98](#bib.bib98)] | 3D | CT, MRI | Hippocampus subset
    of Medical Segmentation Decathlon [[185](#bib.bib185)], MM-WHS dataset [[178](#bib.bib178),
    [179](#bib.bib179)] | Self-supervised image-level and supervised pixel-level contrastive
    pre-training | Contrastive learning |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Le-SSCL, Hu 等 [[98](#bib.bib98)] | 3D | CT, MRI | Medical Segmentation Decathlon
    的海马体子集 [[185](#bib.bib185)]，MM-WHS 数据集 [[178](#bib.bib178), [179](#bib.bib179)]
    | 自监督图像级和监督像素级对比预训练 | 对比学习 |'
- en: '| SimCVD, You et al. [[47](#bib.bib47)] | 3D | CT, MRI | LA dataset [[66](#bib.bib66)],
    Pancreas CT [[130](#bib.bib130)] | Contrastive distillation of voxel-wise representation
    with signed distance maps | Contrastive learning |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| SimCVD, You et al. [[47](#bib.bib47)] | 3D | CT, MRI | LA 数据集 [[66](#bib.bib66)],
    胰腺 CT [[130](#bib.bib130)] | 基于带符号距离图的体素级对比蒸馏 | 对比学习 |'
- en: '| CPDC, Wu et al.[[105](#bib.bib105)] | 2D | Microscope | DSB[[194](#bib.bib194)]
    , MoNuSeg[[195](#bib.bib195)] | Cross-patch dense contrastive learning framework
    | Contrastive learning |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| CPDC, Wu et al.[[105](#bib.bib105)] | 2D | 显微镜 | DSB[[194](#bib.bib194)]
    , MoNuSeg[[195](#bib.bib195)] | 跨补丁密集对比学习框架 | 对比学习 |'
- en: '| Dt-DDCL, Zhang et al.[[3](#bib.bib3)] | 2D | Colonoscope | kvasir-SEG dataset[[196](#bib.bib196)],
    Skin lesion dataset [[197](#bib.bib197)] | Dual-task network for segmentation
    and lesion region inpainting. | Inpainting task |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Dt-DDCL, Zhang et al.[[3](#bib.bib3)] | 2D | 内窥镜 | kvasir-SEG 数据集[[196](#bib.bib196)],
    皮肤病变数据集 [[197](#bib.bib197)] | 用于分割和病变区域修复的双任务网络 | 修复任务 |'
- en: '| RLS_SSL, Yang et al. [[120](#bib.bib120)] | 3D | OCT | Private | Add self-supervised
    jigsaw puzzle task into training | Jigsaw puzzle task |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| RLS_SSL, Yang et al. [[120](#bib.bib120)] | 3D | OCT | 私有数据 | 将自监督拼图任务添加到训练中
    | 拼图任务 |'
- en: '| MTL-ABS3Net, Huang et al. [[79](#bib.bib79)] | 3D | CT | LiTS dataset [[17](#bib.bib17)]
    | Utilize prior anatomy to give the unlabeled data segmentation pixel-wise confidence
    | Atlas priors |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| MTL-ABS3Net, Huang et al. [[79](#bib.bib79)] | 3D | CT | LiTS 数据集 [[17](#bib.bib17)]
    | 利用解剖先验为未标记数据提供分割像素级置信度 | 图谱先验 |'
- en: '| DAP, Zheng et al. [[153](#bib.bib153)] | 3D | CT | LiTS dataset [[17](#bib.bib17)]
    | Semi-supervised adversarial learning with deep atlas prior | Atlas priors |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| DAP, Zheng et al. [[153](#bib.bib153)] | 3D | CT | LiTS 数据集 [[17](#bib.bib17)]
    | 基于深度图谱先验的半监督对抗学习 | 图谱先验 |'
- en: 3.4 Other Semi-Supervised Medical Image Segmentation Methods
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 其他半监督医学图像分割方法
- en: A frequently encountered obstacle in medical imaging is that, in real-world
    applications, the acquired data and annotations may be difficult to meet the assumptions,
    thus affecting the performance of semi-supervised learning. Other than these methodological
    developments for semi-supervised segmentation methods mentioned above, We have
    also compiled some different concerns in real-world applications.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在医学影像领域，一个常见的障碍是，在实际应用中，获取的数据和注释可能难以满足假设，从而影响半监督学习的性能。除了上述提到的半监督分割方法的方法论发展外，我们还汇总了一些在实际应用中的不同关注点。
- en: As there is usually a large amount of unlabeled data in semi-supervised learning,
    the distribution of labeled and unlabeled data may be misaligned. For better leverage
    of large scale data from different distributions or medical centers, some methods
    are proposed to deal with distribution misalignment[[78](#bib.bib78), [88](#bib.bib88),
    [122](#bib.bib122)]. Zhang et al. [[78](#bib.bib78)] try to align labeled data
    distribution and unlabeled data distribution through minimising the L2 distance
    between the feature maps of them. Meanwhile, to remain discriminative for the
    segmentation of labeled and unlabeled data, further segmentation supervision is
    obtained through comparing the non-local semantic relation matrix in feature maps
    from the ground truth label mask and the student inputs. Another work in [[88](#bib.bib88)]
    propose adaptive hierarchical dual consistency to use the dataset from different
    centers, which learns mapping networks adversarially to align the distributions
    and extend consistency learning into intra- and inter-consistency in cross-domain
    segmentation. Another idea for using data from multi centers is through meta-learning.
    In [[122](#bib.bib122)], one distinct task is formulated for each medical centre
    such that a segmentation task is performed for a centre with labelled data while
    the contrastive learning task is performed with unlabelled data.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 由于半监督学习中通常存在大量未标记的数据，标记数据和未标记数据的分布可能会不一致。为更好地利用来自不同分布或医疗中心的大规模数据，一些方法被提出以处理分布不一致问题[[78](#bib.bib78),
    [88](#bib.bib88), [122](#bib.bib122)]。Zhang 等人[[78](#bib.bib78)]尝试通过最小化它们的特征图之间的L2距离来对齐标记数据分布和未标记数据分布。同时，为了保持对标记和未标记数据分割的区分能力，通过比较来自地面真实标签掩模和学生输入的特征图中的非局部语义关系矩阵，获得了进一步的分割监督。另一个工作[[88](#bib.bib88)]提出了自适应分层双一致性方法，以利用来自不同中心的数据，这些方法通过对抗性地学习映射网络来对齐分布，并将一致性学习扩展到跨域分割中的内在和外在一致性。使用来自多个中心的数据的另一种思路是通过元学习。在[[122](#bib.bib122)]中，为每个医疗中心制定了一个独特的任务，使得在有标记数据的中心进行分割任务，而在无标记数据上进行对比学习任务。
- en: Another concern in semi-supervised learning is how to fuse different supervision
    signals for label-efficient semi-supervised learning. As existing public imaging
    datasets usually have different annotations for different tasks, like CT images
    singly labelled tumors or partially labelled organs. Zhang et al. [[126](#bib.bib126)]
    propose a dual-path semi-supervised conditional nnU-Net that can be trained on
    a union of partially labelled datasets, segmentation of organs at risk or tumors.
    Another situation is the integration of different levels of supervision signals.
    [[138](#bib.bib138)] propose multi-label deep supervision in semi-supervised framework,
    which leveraged image-level, box-level and pixel-level annotations. If only image-level
    or box-level labels exist, the pseudo labels would be constrained to the classes
    contained in that or to lie within coarse regions. Except that, the noisy pseudo
    labels generated from the teacher model is smoothed using max-pooling to match
    different level predictions from the decoder for multi-level consistency.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习中的另一个关注点是如何融合不同的监督信号，以实现标签高效的半监督学习。由于现有的公共成像数据集通常对不同任务有不同的标注，例如CT图像中单独标记的肿瘤或部分标记的器官。张等人[[126](#bib.bib126)]提出了一种双路径半监督条件nnU-Net，它可以在部分标记数据集的联合上进行训练，以进行器官风险或肿瘤的分割。另一种情况是整合不同级别的监督信号。[[138](#bib.bib138)]提出了半监督框架中的多标签深度监督，利用了图像级、框级和像素级的标注。如果只有图像级或框级标签存在，伪标签将被限制在这些标签包含的类别内或粗略区域内。除此之外，由教师模型生成的噪声伪标签通过最大池化进行平滑，以匹配解码器的不同级别预测，实现多级一致性。
- en: Class imbalance is a common problem in segmentation. In semi-supervised learning,
    class imbalance and limited labeled data may further bring the confirmation bias
    and uncertainty imbalance problem. Recently, some researchers propose class-imbalanced
    methods in semi-supervised learning[[212](#bib.bib212), [109](#bib.bib109), [216](#bib.bib216)].
    Lin et al. [[212](#bib.bib212)] propose a dual uncertainty-aware sampling strategy
    to sample low-confident categories of pixels for unsupervised consistency learning.
    Another direction focuses on utilizing re-weighting strategies calculated by the
    pixel proportion of categories[[109](#bib.bib109), [216](#bib.bib216)].
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 类别不平衡是分割中的一个常见问题。在半监督学习中，类别不平衡和有限的标记数据可能进一步引发确认偏差和不确定性不平衡问题。最近，一些研究者在半监督学习中提出了类别不平衡方法[[212](#bib.bib212),
    [109](#bib.bib109), [216](#bib.bib216)]。林等人[[212](#bib.bib212)]提出了一种双重不确定性感知采样策略，以对低置信度的像素类别进行采样，用于无监督一致性学习。另一种方向集中在利用按类别像素比例计算的重新加权策略[[109](#bib.bib109),
    [216](#bib.bib216)]。
- en: Besides, most of previous semi-supervised frameworks are discriminative models,
    where labeled data is only used in the early training stage and the model may
    tend to overfit to the labeled data [[104](#bib.bib104)]. Wang et al. [[104](#bib.bib104)]
    proposed a Bayesian deep learning framework for semi-supervised segmentation.
    In that way, both labeled and unlabeled data are utilized to estimate the joint
    distribution, which alleviates potential overfitting problem caused by using labeled
    data for early training only.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，大多数之前的半监督框架是判别模型，其中标记数据仅在早期训练阶段使用，并且模型可能会倾向于过拟合标记数据[[104](#bib.bib104)]。王等人[[104](#bib.bib104)]提出了一种用于半监督分割的贝叶斯深度学习框架。通过这种方式，既使用标记数据又使用未标记数据来估计联合分布，从而缓解了仅使用标记数据进行早期训练可能导致的过拟合问题。
- en: 4 Analysis of Empirical Results for Semi-Supervised Medical Image Segmentation
  id: totrans-194
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 半监督医学图像分割的实证结果分析
- en: 4.1 Common Evaluation Metrics for Medical Image Segmentation
  id: totrans-195
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 医学图像分割的常见评估指标
- en: 'For medical image segmentation tasks, Dice Similarity Coefficient (DSC) is
    a widely used metric to measure the region overlap ratio of the ground truth $G$
    and segmentation result $S$. Another similar metric IoU (or Jaccard) is used as
    an alternative for the evaluation. These two metrics are defined as follows:'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 对于医学图像分割任务，Dice相似系数（DSC）是衡量真实值$G$和分割结果$S$区域重叠比例的广泛使用的指标。另一个类似的指标IoU（或Jaccard）可作为评估的替代。这两个指标定义如下：
- en: '|  | $DSC=\frac{2&#124;G\cap S&#124;}{&#124;G&#124;+&#124;S&#124;},\quad IoU=\frac{&#124;G\cap
    S&#124;}{&#124;G\cup S&#124;}.$ |  | (8) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | $DSC=\frac{2\vert G\cap S\vert}{\vert G\vert+\vert S\vert},\quad IoU=\frac{\vert
    G\cap S\vert}{\vert G\cup S\vert}.$ |  | (8) |'
- en: 'However, region-based metrics like DSC cannot well reflect the boundary error
    or small region of mis-segmentation. To issue this limitation, boundary-based
    evaluation metrics like Hausdorff Distance (HD) are applied to focus on the boundary
    distance error defined as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，基于区域的度量如 DSC 不能很好地反映边界误差或小区域的误分割。为了应对这一限制，应用了基于边界的评估度量，如 Hausdorff 距离（HD），以关注如下定义的边界距离误差：
- en: '|  | $HD(\partial G,\partial S)=\max(\max\limits_{x\in\partial G}\min\limits_{y\in\partial
    S}&#124;&#124;x-y&#124;&#124;_{2},\max\limits_{x\in\partial S}\min\limits_{y\in\partial
    G}&#124;&#124;x-y&#124;&#124;_{2}),$ |  | (9) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '|  | $HD(\partial G,\partial S)=\max(\max\limits_{x\in\partial G}\min\limits_{y\in\partial
    S}&#124;&#124;x-y&#124;&#124;_{2},\max\limits_{x\in\partial S}\min\limits_{y\in\partial
    G}&#124;&#124;x-y&#124;&#124;_{2}),$ |  | (9) |'
- en: where $\partial G$ and $\partial S$ represent the boundary of the ground truth
    and the segmentation result, respectively. To eliminate the influence caused by
    small subsets of outliers, 95% Hausdorff Distance (95HD) is also widely used,
    which is based on the calculation of the 95th percentile of the distances between
    boundary points.
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\partial G$ 和 $\partial S$ 分别表示真实值和分割结果的边界。为了消除由小型离群点子集引起的影响，95% Hausdorff
    距离（95HD）也被广泛使用，这基于边界点之间距离的第95百分位数计算。
- en: 'Table 6: Representative works and empirical results on semi-supervised LA MRI
    segmentation benchmark.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：半监督 LA MRI 分割基准的代表性工作和实证结果。
- en: '| Method | Highlights | $\mathcal{D}_{L}/\mathcal{D}_{U}$ | Dice | Publication&Year
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 亮点 | $\mathcal{D}_{L}/\mathcal{D}_{U}$ | Dice | 发表&年份 |'
- en: '| Baseline V-Net [[40](#bib.bib40)] | Fully supervised baseline with only labeled
    data | 8/0 | 79.99 |  |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Baseline V-Net [[40](#bib.bib40)] | 仅使用标记数据的全监督基线 | 8/0 | 79.99 |  |'
- en: '|  | 16/0 | 86.03 |  |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/0 | 86.03 |  |'
- en: '| Upper-bound V-Net [[40](#bib.bib40)] | Fully supervised upper bound with
    all annotations | 80/0 | 91.14 |  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| Upper-bound V-Net [[40](#bib.bib40)] | 具有所有标注的全监督上界 | 80/0 | 91.14 |  |'
- en: '| UA-MT, Yu et al. [[31](#bib.bib31)] | Teacher-student framework with the
    guidance of uncertainty | 8/72 | 84.25 | MICCAI 2019 |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| UA-MT, Yu et al. [[31](#bib.bib31)] | 具有不确定性指导的教师-学生框架 | 8/72 | 84.25 | MICCAI
    2019 |'
- en: '|  | 16/64 | 88.88 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 88.88 |'
- en: '| SASS, Li et al. [[34](#bib.bib34)] | Incorporating signed distance maps for
    shape regularization | 8/72 | 87.32 | MICCAI 2020 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| SASS, Li et al. [[34](#bib.bib34)] | 结合签名距离图进行形状正则化 | 8/72 | 87.32 | MICCAI
    2020 |'
- en: '|  | 16/64 | 89.54 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 89.54 |'
- en: '| DUWM, Wang et al. [[32](#bib.bib32)] | Utilizing both segmentation and feature
    uncertainty | 8/72 | 85.91 | MICCAI 2020 |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| DUWM, Wang et al. [[32](#bib.bib32)] | 利用分割和特征不确定性 | 8/72 | 85.91 | MICCAI
    2020 |'
- en: '|  | 16/64 | 89.65 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 89.65 |'
- en: '| LG-ER-MT, Hang et al. [[33](#bib.bib33)] | Entropy minimization to produce
    high-confident predictions and local structural consistency to encourage inter-voxel
    similarities | 8/72 | 85.54 | MICCAI 2020 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| LG-ER-MT, Hang et al. [[33](#bib.bib33)] | 熵最小化以生成高置信度预测，并通过局部结构一致性鼓励体素间相似性
    | 8/72 | 85.54 | MICCAI 2020 |'
- en: '|  | 16/64 | 89.62 |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 89.62 |'
- en: '| DTC, Luo et al. [[35](#bib.bib35)] | Encourage the consistency between output
    segmentation maps and signed distance map | 16/64 | 89.42 | AAAI 2021 |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| DTC, Luo et al. [[35](#bib.bib35)] | 鼓励输出分割图与签名距离图之间的一致性 | 16/64 | 89.42
    | AAAI 2021 |'
- en: '| PDC-Net, Hao et al. [[46](#bib.bib46)] | Parameter decoupling to encourage
    consistent predictions from two branch network | 8/72 | 86.55 | ICMV 2021 |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| PDC-Net, Hao et al. [[46](#bib.bib46)] | 参数解耦以鼓励两个分支网络的一致预测 | 8/72 | 86.55
    | ICMV 2021 |'
- en: '|  | 16/64 | 89.76 |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 89.76 |'
- en: '| HCR-MT, Li et al. [[85](#bib.bib85)] | Teacher-student framework with multi-scale
    deep supervision and hierarchical consistency regularization | 16/64 | 90.04 |
    EMBC 2021 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| HCR-MT, Li et al. [[85](#bib.bib85)] | 具有多尺度深度监督和层次一致性正则化的教师-学生框架 | 16/64
    | 90.04 | EMBC 2021 |'
- en: '| DTML, Zhang et al. [[36](#bib.bib36)] | Mutual learning of dual-task networks
    for generating segmentation and signed distance maps | 16/64 | 90.12 | PRCV 2021
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| DTML, Zhang et al. [[36](#bib.bib36)] | 双任务网络的互学习，用于生成分割图和签名距离图 | 16/64 |
    90.12 | PRCV 2021 |'
- en: '| MC-Net, Wu et al. [[2](#bib.bib2)] | Consistency learning between outputs
    from two different decoders | 8/72 | 87.71 | MICCAI 2021 |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| MC-Net, Wu et al. [[2](#bib.bib2)] | 来自两个不同解码器的输出之间的一致性学习 | 8/72 | 87.71
    | MICCAI 2021 |'
- en: '|  | 16/64 | 90.34 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 90.34 |'
- en: '| CASS, Liu et al. [[102](#bib.bib102)] | Contrastive consistency on class-level
    | 8/72 | 86.51 | CMIG 2022 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| CASS, Liu et al. [[102](#bib.bib102)] | 类别级对比一致性 | 8/72 | 86.51 | CMIG 2022
    |'
- en: '|  | 16/64 | 89.81 |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 89.81 |'
- en: '| SimCVD, You et al. [[47](#bib.bib47)] | Contrastive distillation of voxel-wise
    representation with signed distance maps | 8/72 | 89.03 | TMI 2022 |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| SimCVD, 游等人 [[47](#bib.bib47)] | 具有符号距离图的体素级表示的对比蒸馏 | 8/72 | 89.03 | TMI
    2022 |'
- en: '|  | 16/64 | 90.85 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 90.85 |'
- en: '| CMM, Shu et al. [[112](#bib.bib112)] | Asynchronously perform Cross-Mix Teaching
    and transductive monitor for active knowledge distillation | 8/72 | 85.92 | TMM
    2022 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| CMM, 舒等人 [[112](#bib.bib112)] | 异步执行 Cross-Mix Teaching 和传导监视以进行主动知识蒸馏 |
    8/72 | 85.92 | TMM 2022 |'
- en: '|  | 16/64 | 90.03 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '|  | 16/64 | 90.03 |'
- en: '| DTCJL, Chen et al. [[113](#bib.bib113)] | Semi-supervised dual-task consistent
    joint learning framework with task-level regularization | 16/64 | 90.32 | TCBB
    2022 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| DTCJL, 陈等人 [[113](#bib.bib113)] | 带有任务级正则化的半监督双任务一致性联合学习框架 | 16/64 | 90.32
    | TCBB 2022 |'
- en: 4.2 Benchmark Datasets for Semi-Supervised Medical Image Segmentation
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 半监督医学图像分割的基准数据集
- en: In addition to the promising progress in semi-supervised medical image segmentation
    methods, several segmentation benchmarks are also evolved to ensure a fair comparison
    of these methods with the same task setting on same public dataset.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 除了半监督医学图像分割方法的有希望的进展外，还发展了几个分割基准，以确保这些方法在相同任务设置和相同公共数据集上的公平比较。
- en: 'LA dataset. The LA benchmark dataset [[66](#bib.bib66)] from the Left Atrium
    Segmentation Challenge ²²2http://atriaseg2018.cardiacatlas.org/data/ contains
    100 3D gadolinium-enhanced MR imaging scans (GE-MRIs) for training, with an isotropic
    resolution of $0.625\times 0.625\times 0.625mm^{3}$ . Since the testing set of
    LA does not include public annotations, for the settings in [[31](#bib.bib31)],
    the 100 training scans are splitted into 80 scans for training and 20 scans for
    testing. Out of the 80 training scans, 20% (i.e. 16 scans) are used as labeled
    data and the remaining as unlabeled data. V-Net [[40](#bib.bib40)] is used as
    the network backbone for all experiments with a joint cross-entropy loss and dice
    loss for training. For supervised comparisons, V-Net trained with only labeled
    data (i.e. 16 scans) and trained with all labeled data (i.e. 80 scans) is performed
    as lower bound and upper bound for semi-supervised learning. As shown in Table.
    [6](#S4.T6 "Table 6 ‣ 4.1 Common Evaluation Metrics for Medical Image Segmentation
    ‣ 4 Analysis of Empirical Results for Semi-Supervised Medical Image Segmentation
    ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised Learning
    for Medical Image Segmentation"), as one of the most popular benchmark dataset
    for semi-supervised medical image segmentation, many methods are further proposed
    and evaluated on the same dataset under the same task settings following the task
    design of [[31](#bib.bib31)]. Specifically, several researches further promote
    the benchmark with 10% (i.e. 8 scans) labeled scans to further evaluate the performance
    under the circumstance with fewer labeled data.'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 'LA 数据集。LA 基准数据集 [[66](#bib.bib66)] 来自左心房分割挑战 ²²2http://atriaseg2018.cardiacatlas.org/data/
    包含 100 个用于训练的 3D 钆增强 MR 成像扫描 (GE-MRIs)，其各向同性分辨率为 $0.625\times 0.625\times 0.625mm^{3}$。由于
    LA 的测试集不包括公共注释，因此在 [[31](#bib.bib31)] 的设置中，100 个训练扫描被拆分为 80 个用于训练和 20 个用于测试。在
    80 个训练扫描中，20%（即 16 个扫描）被用作标注数据，其余为未标注数据。V-Net [[40](#bib.bib40)] 被用作所有实验的网络骨干，采用联合交叉熵损失和骰子损失进行训练。对于监督比较，V-Net
    仅用标注数据（即 16 个扫描）和用所有标注数据（即 80 个扫描）进行训练，作为半监督学习的下界和上界。正如表 [6](#S4.T6 "Table 6 ‣
    4.1 Common Evaluation Metrics for Medical Image Segmentation ‣ 4 Analysis of Empirical
    Results for Semi-Supervised Medical Image Segmentation ‣ Learning with Limited
    Annotations: A Survey on Deep Semi-supervised Learning for Medical Image Segmentation")
    中所示，作为最流行的半监督医学图像分割基准数据集之一，许多方法在相同数据集下、相同任务设置中进一步提出和评估，遵循 [[31](#bib.bib31)] 的任务设计。具体而言，几个研究进一步推广了带有
    10%（即 8 个扫描）标注扫描的基准，以进一步评估在标注数据较少的情况下的性能。'
- en: Pancreas CT dataset. The NIH Pancreas CT segmentation dataset [[130](#bib.bib130)]
    contains 82 3D abdominal contrast-enhanced CT volumes, which are collected from
    53 male and 27 female subjects at the National Institutes of Health Clinical Center
    ³³3https://wiki.cancerimagingarchive.net/display/Public/Pancreas-CT. The dataset
    are collected on Philips and Siemens MDCT scanners and have a fixed resolution
    of $512\times 512$ with varying thicknesses from 1.5 to 2.5 mm, while the axial
    view slice number can vary from 181 to 466\. In [[148](#bib.bib148)], the dataset
    is randomly split into 20 testing cases and 62 training cases. Experimental results
    with 10% labeled training cases (6 labeled and 56 unlabeled) and 20% labeled training
    cases (12 labeled and 50 unlabeled) is reported. Following the pre-processing
    in [[198](#bib.bib198)], the voxel values are clipped to the range of [-125,275]
    Hounsfield Units (HU) and further re-sampled to an isotropic resolution of $1\times
    1\times 1mm^{3}$. several researches further promote the benchmark with 10% (i.e.
    8 scans) labeled scans to further evaluate the performance under the circumstance
    with fewer labeled data. Several semi-supervised approaches [[106](#bib.bib106),
    [127](#bib.bib127), [47](#bib.bib47)] are evaluated on Pancreas CT dataset.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 胰腺CT数据集。NIH胰腺CT分割数据集[[130](#bib.bib130)]包含82个3D腹部对比增强CT体积，这些体积采集自53名男性和27名女性受试者，来自美国国立卫生研究院临床中心³³3https://wiki.cancerimagingarchive.net/display/Public/Pancreas-CT。数据集采集于Philips和Siemens
    MDCT扫描仪上，分辨率固定为$512\times 512$，厚度从1.5到2.5毫米不等，而轴向视图切片数可从181到466\. 在[[148](#bib.bib148)]中，数据集被随机拆分为20个测试案例和62个训练案例。报告了使用10%标注训练案例（6个标注和56个未标注）和20%标注训练案例（12个标注和50个未标注）的实验结果。按照[[198](#bib.bib198)]中的预处理，体素值被裁剪到[-125,275]
    Hounsfield单位（HU）范围内，并进一步重新采样到$1\times 1\times 1mm^{3}$的各向同性分辨率。若干研究进一步推动了基准测试，使用10%（即8个扫描）标注扫描来进一步评估在标注数据较少的情况下的性能。几个半监督方法[[106](#bib.bib106),
    [127](#bib.bib127), [47](#bib.bib47)]在胰腺CT数据集上进行了评估。
- en: BraTS dataset. The Brain Tumor Segmentation (BraTS) 2019 dataset [[128](#bib.bib128)]
    contains multi-institutional preoperative MRI of 335 glioma patients, where each
    patient has four modalities of MRI scans including T1, T1Gd, T2 and T2-FLAIR with
    neuroradiologist-examined labels. For several existing approaches [[70](#bib.bib70),
    [9](#bib.bib9), [106](#bib.bib106)], T2-FLAIR for whole tumor segmentation is
    used since such modality can better manifest the malignant tumors [[129](#bib.bib129)].
    All the scans are re-sampled to the same resolution of $1\times 1\times 1mm^{3}$
    with intensity normalized to zero mean and unit variance. For semi-supervised
    settings, the dataset is splitted into 250 scans for training, 25 scans for validation
    and the remaining 60 scans for testing. Among the 250 training scans, two different
    settings are performed with 10%/25 and 20%/50 scans as labeled data and the remaining
    scans as unlabeled data.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: BraTS数据集。脑肿瘤分割（BraTS）2019数据集[[128](#bib.bib128)]包含335名胶质瘤患者的多机构术前MRI，每位患者具有包括T1、T1Gd、T2和T2-FLAIR在内的四种MRI扫描模式，并附有神经放射科医师检查的标签。对于几种现有的方法[[70](#bib.bib70),
    [9](#bib.bib9), [106](#bib.bib106)]，由于T2-FLAIR模式能够更好地表现恶性肿瘤[[129](#bib.bib129)]，因此用于整个肿瘤分割。所有扫描均被重新采样到$1\times
    1\times 1mm^{3}$的相同分辨率，强度归一化为零均值和单位方差。在半监督设置下，数据集被拆分为250个扫描用于训练，25个扫描用于验证，其余60个扫描用于测试。在250个训练扫描中，执行了两种不同的设置，分别为10%/25和20%/50扫描作为标注数据，其余扫描作为未标注数据。
- en: ACDC dataset. The ACDC (Automated Cardiac Diagnosis Challenge) dataset [[22](#bib.bib22)]
    was collected from real clinical exams acquired at the University Hospital of
    Dijon ⁴⁴4https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html. The dataset
    contains multi-slice 2D cine cardiac MR imaging samples from 100 patients for
    training. For semi-supervised settings, the dataset is splitted into 70 scans
    for training, 10 scans for validation and 20 scans for testing. Unlike previous
    3D binary segmentation benchmark datasets, ACDC is a 2D multi-class segmentation
    task including RV cavity, myocardium and the LV cavity.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: ACDC数据集。ACDC（自动心脏诊断挑战）数据集[[22](#bib.bib22)]来自于在第戎大学医院进行的真实临床检查⁴⁴4https://www.creatis.insa-lyon.fr/Challenge/acdc/databases.html。数据集包含来自100名患者的多层2D动态心脏MR成像样本，用于训练。在半监督设置下，数据集被拆分为70个扫描用于训练，10个扫描用于验证，20个扫描用于测试。与之前的3D二值分割基准数据集不同，ACDC是一个2D多类分割任务，包括右心室腔、心肌和左心室腔。
- en: 5 Existing Challenges and Future Directions
  id: totrans-234
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5个现有挑战和未来方向
- en: Although considerable performance has been achieved for semi-supervised medical
    image segmentation tasks, there are still several open questions for future work.
    In this section, we outline some of these challenges and potential future directions
    as follows.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管半监督医学图像分割任务已经取得了相当的性能，但仍有若干未解的问题需要在未来研究中解决。在本节中，我们概述了一些这些挑战和未来的潜在方向。
- en: 'Misaligned distribution and class imbalance. As described in Section [4.2](#S4.SS2
    "4.2 Benchmark Datasets for Semi-Supervised Medical Image Segmentation ‣ 4 Analysis
    of Empirical Results for Semi-Supervised Medical Image Segmentation ‣ Learning
    with Limited Annotations: A Survey on Deep Semi-supervised Learning for Medical
    Image Segmentation"), existing semi-supervised medical image segmentation approaches
    have achieved comparable results with upper-bound fully supervised results in
    some benchmark datasets like LA segmentation [[66](#bib.bib66)]. However, these
    benchmarks are relatively "simple" tasks, with small amount of experimental data
    where the training and test set are from the same domain/medical center. However,
    a clinical applicable deep learning model should be generalized suitably across
    multiple centres and scanner vendors from different domains [[123](#bib.bib123)].
    As there is usually a large amount of unlabeled data in semi-supervised learning,
    the distribution of labeled and unlabeled data may be misaligned. This limitation
    is also highlighted by recent semi-supervised medical segmentation benchmarks
    like [[5](#bib.bib5)] and FLARE 22 challenge ⁵⁵5https://flare22.grand-challenge.org.
    Based on the work in [[161](#bib.bib161)], adding unlabeled data from a mismatched
    distribution from labeled data can lower the performance compared to not using
    any unlabeled data. Therefore, it is of great importance to issue the challenge
    of misaligned distribution for semi-supervised learning. As for class imbalance,
    when the training data is highly imbalanced, the trained model will show bias
    towards the majority classes, and may completely ignore the minority classes in
    some extreme cases [[142](#bib.bib142)]. Besides, for semi-supervised multi-class
    segmentation, there usually exists the uncertainty imbalance problem brought by
    class imbalance and limited labeled data. Recent studies [[74](#bib.bib74)] found
    that aleatoric uncertainty derived from the entropy of the predictions may lead
    to sub-optimal results in a multi-class context.'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '错位分布和类别不平衡。如第[4.2节](#S4.SS2 "4.2 Benchmark Datasets for Semi-Supervised Medical
    Image Segmentation ‣ 4 Analysis of Empirical Results for Semi-Supervised Medical
    Image Segmentation ‣ Learning with Limited Annotations: A Survey on Deep Semi-supervised
    Learning for Medical Image Segmentation")所述，现有的半监督医学图像分割方法在一些基准数据集如LA分割中，已取得与上限完全监督结果相当的结果[[66](#bib.bib66)]。然而，这些基准测试相对“简单”，实验数据量小，训练集和测试集来自同一领域/医疗中心。一个临床适用的深度学习模型应该能够在来自不同领域的多个中心和扫描仪供应商之间适当地推广[[123](#bib.bib123)]。由于半监督学习中通常存在大量未标记数据，标记数据和未标记数据的分布可能会错位。这一限制也在最近的半监督医学分割基准测试中得到了突出，例如[[5](#bib.bib5)]和FLARE
    22挑战赛 ⁵⁵5https://flare22.grand-challenge.org。基于[[161](#bib.bib161)]的工作，将来自与标记数据分布不匹配的未标记数据添加进去，可能会比不使用任何未标记数据导致性能下降。因此，解决半监督学习中的错位分布问题至关重要。至于类别不平衡，当训练数据高度不平衡时，训练出的模型会对多数类别表现出偏见，在某些极端情况下可能完全忽略少数类别[[142](#bib.bib142)]。此外，对于半监督多类分割，通常存在由类别不平衡和有限标记数据带来的不确定性不平衡问题。最近的研究[[74](#bib.bib74)]发现，源自预测熵的随机不确定性可能在多类环境中导致次优结果。'
- en: Methodological analysis. Existing semi-supervised medical image segmentation
    approaches predominantly use unlabeled data to generate constraints, then the
    models are updated with supervised loss for labeled data and unsupervised loss/constraints
    for unlabeled data (or both labeled and unlabeled data). Generally, there is only
    a single weight to balance between supervised and unsupervised loss as described
    in many approaches [[31](#bib.bib31), [35](#bib.bib35), [36](#bib.bib36)]. In
    other words, all the unlabeled data are treated equally for semi-supervised learning.
    However, not all unlabeled data is equally appropriate for the learning procedure
    of the model. For example, when the estimation of an unlabeled case is incorrect,
    training on that particular label-estimate may hurt the overall performance. To
    issue this problem, it is important to encourage the model focusing on more challenging
    areas/cases and therefore exploit more useful information from unlabeled data
    like assigning different weights for each unlabeled example [[71](#bib.bib71)].
    Recent studies [[73](#bib.bib73)] also found that the quality of the perturbations
    is key to obtaining reasonable performances for semi-supervised learning, especially
    in the case of efficient data augmentations or perturbations schemes when the
    data lies in the neighborhood of low-dimensional manifolds.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 方法学分析。现有的半监督医学图像分割方法主要使用未标注数据生成约束，然后用标注数据的监督损失和未标注数据的无监督损失/约束（或两者）来更新模型。通常，许多方法
    [[31](#bib.bib31), [35](#bib.bib35), [36](#bib.bib36)] 中只有一个权重来平衡监督和无监督损失。换句话说，所有未标注数据在半监督学习中都被同等对待。然而，并非所有未标注数据对于模型的学习过程都是同样合适的。例如，当对未标注数据的估计不准确时，训练这些特定标签估计可能会损害整体性能。为了解决这个问题，重要的是鼓励模型关注更具挑战性的区域/案例，从而从未标注数据中挖掘更多有用的信息，例如为每个未标注样本分配不同的权重
    [[71](#bib.bib71)]。最近的研究 [[73](#bib.bib73)] 还发现，扰动的质量对于获得合理的半监督学习性能是关键，特别是在数据处于低维流形邻域中的高效数据增强或扰动方案的情况下。
- en: Integration with other annotation-efficient approaches. For existing semi-supervised
    learning approaches, we still need a small amount of well-annotated labeled data
    to guide the learning of unlabeled data. However, acquiring such fully annotated
    training data can still be costly, especially for the tasks of medical image segmentation.
    To further alleviate the annotation cost, some researches integrate semi-supervised
    learning with other annotation-efficient approaches like utilizing partially labelled
    datasets [[126](#bib.bib126)], leveraging image-level, box-level and pixel-level
    annotations [[138](#bib.bib138)] or scribble supervisions [[139](#bib.bib139)],
    or exploiting noisy labeled data [[140](#bib.bib140)]. Semi-supervised medical
    image segmentation could also be integrated with few-shot segmentation to improve
    the generalization ability with combination strategies to segment similar objects
    in unseen images. Both methods aim to improve the performance of a model when
    there is limited labeled data available. In semi-supervised learning, the model
    learns from both the labeled and unlabeled data by making assumptions about the
    distribution of the data, which is different from few-shot learning. Besides,
    with the recent introduction of SAM [[202](#bib.bib202)], which can serve as pseudo-label
    generator for image segmentation [[203](#bib.bib203), [209](#bib.bib209)], may
    provide some insights into the future development of semi-supervised learning
    for medical image segmentation [[201](#bib.bib201)].
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他高效标注方法的集成。对于现有的半监督学习方法，我们仍然需要少量标注良好的数据来指导未标注数据的学习。然而，获取这些完全标注的训练数据仍然可能很昂贵，尤其是对于医学图像分割任务。为了进一步减少标注成本，一些研究将半监督学习与其他高效标注方法结合起来，例如利用部分标注数据集
    [[126](#bib.bib126)]，利用图像级、框级和像素级标注 [[138](#bib.bib138)] 或者草图监督 [[139](#bib.bib139)]，或利用有噪声的标注数据
    [[140](#bib.bib140)]。半监督医学图像分割也可以与少样本分割集成，通过组合策略提高模型的泛化能力，从而分割未见过的图像中的类似物体。这两种方法都旨在在标注数据有限的情况下提高模型性能。在半监督学习中，模型通过对数据分布的假设从标注和未标注数据中学习，这与少样本学习不同。此外，最近引入的SAM
    [[202](#bib.bib202)]，可以作为图像分割的伪标签生成器 [[203](#bib.bib203), [209](#bib.bib209)]，可能为未来医学图像分割的半监督学习发展提供一些启示
    [[201](#bib.bib201)]。
- en: 6 Conclusion
  id: totrans-239
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: Semi-supervised learning has been widely applied to medical image segmentation
    tasks since it alleviates the heavy burden of acquiring expert-examined annotations
    and takes the advantage of unlabeled data which is much easier to acquire. In
    this survey, we provide a taxonomy of existing deep semi-supervised learning methods
    for medical image segmentation tasks and group these methods into three main categories,
    namely, pseudo labels, unsupervised regularization, and knowledge priors. Other
    than summarizing technical novelties of these approaches, we also analyse and
    discuss the empirical results of these methods on several public benchmark datasets.
    Furthermore, we analysed and discussed the limitations and several unsolved problems
    of existing approaches. We hope this review could inspire the research community
    to explore solutions for this challenge and further promote the developments in
    this impactful area of research.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习已广泛应用于医学图像分割任务，因为它减轻了获取专家审查注释的沉重负担，并利用了更容易获得的未标记数据。在本调查中，我们提供了现有深度半监督学习方法在医学图像分割任务中的分类，并将这些方法分为三类，即伪标签、无监督正则化和知识先验。除了总结这些方法的技术创新外，我们还分析和讨论了这些方法在若干公共基准数据集上的经验结果。此外，我们分析并讨论了现有方法的局限性和若干未解决的问题。我们希望这篇综述能激励研究界探索解决这一挑战的方案，进一步推动这一重要研究领域的发展。
- en: Acknowledgment
  id: totrans-241
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This paper was supported in part by the National Science Foundation under Grant
    32000687, and in part by the University Synergy Innovation Program of Anhui Province
    under Grant GXXT-2019-044 and Beijing Natural Science Foundation under Grant Z200024\.
    We also appreciate the efforts of literature collection and code implementations
    of SSL4MIS ⁶⁶6https://github.com/HiLab-git/SSL4MIS and several public benchmarks.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 本论文部分由国家科学基金会资助（资助号32000687），部分由安徽省大学协同创新计划资助（资助号GXXT-2019-044）和北京市自然科学基金资助（资助号Z200024）。我们还感谢SSL4MIS
    ⁶⁶6https://github.com/HiLab-git/SSL4MIS以及若干公共基准测试的文献收集和代码实施工作的努力。
- en: References
  id: totrans-243
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] B. Van Ginneken, C. M. Schaefer-Prokop, and M. Prokop, “Computer-aided
    diagnosis: how to move from the laboratory to the clinic,” *Radiology*, vol. 261,
    no. 3, pp. 719–732, 2011.'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] B. Van Ginneken, C. M. Schaefer-Prokop, 和 M. Prokop, “计算机辅助诊断：如何从实验室转向临床，”
    *放射学*，第261卷，第3期，页719–732，2011年。'
- en: '[2] Y. Wu, M. Xu, Z. Ge, J. Cai, and L. Zhang, “Semi-supervised left atrium
    segmentation with mutual consistency training,” in *International Conference on
    Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2021,
    pp. 297–306.'
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Y. Wu, M. Xu, Z. Ge, J. Cai, 和 L. Zhang, “具有互一致性训练的半监督左心房分割，” 在 *国际医学图像计算与计算机辅助手术会议*。
     Springer，2021年，页297–306。'
- en: '[3] R. Zhang, S. Liu, Y. Yu, and G. Li, “Self-supervised correction learning
    for semi-supervised biomedical image segmentation,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2021,
    pp. 134–144.'
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] R. Zhang, S. Liu, Y. Yu, 和 G. Li, “用于半监督生物医学图像分割的自监督校正学习，” 在 *国际医学图像计算与计算机辅助手术会议*。
     Springer，2021年，页134–144。'
- en: '[4] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, and C. I. Sánchez, “A survey on deep learning
    in medical image analysis,” *Medical image analysis*, vol. 42, pp. 60–88, 2017.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, 和 C. I. Sánchez, “关于医学图像分析中深度学习的调查，” *医学图像分析*，第42卷，页60–88，2017年。'
- en: '[5] J. Ma, Y. Zhang, S. Gu, C. Zhu, C. Ge, Y. Zhang, X. An, C. Wang, Q. Wang,
    X. Liu, S. Cao, Q. Zhang, S. Liu, Y. Wang, Y. Li, J. He, and X. Yang, “Abdomenct-1k:
    Is abdominal organ segmentation a solved problem,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, pp. 1–1, 2021.'
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] J. Ma, Y. Zhang, S. Gu, C. Zhu, C. Ge, Y. Zhang, X. An, C. Wang, Q. Wang,
    X. Liu, S. Cao, Q. Zhang, S. Liu, Y. Wang, Y. Li, J. He, 和 X. Yang, “Abdomenct-1k：腹部器官分割是否已解决问题，”
    *IEEE模式分析与机器智能汇刊*，页1–1，2021年。'
- en: '[6] A. Lalande, Z. Chen, T. Pommier, T. Decourselle, A. Qayyum, M. Salomon,
    D. Ginhac, Y. Skandarani, A. Boucher, K. Brahim *et al.*, “Deep learning methods
    for automatic evaluation of delayed enhancement-mri. the results of the emidec
    challenge,” *Medical Image Analysis*, vol. 79, p. 102428, 2022.'
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] A. Lalande, Z. Chen, T. Pommier, T. Decourselle, A. Qayyum, M. Salomon,
    D. Ginhac, Y. Skandarani, A. Boucher, K. Brahim *等*，“用于自动评估延迟增强MRI的深度学习方法。EMIDEC挑战赛结果，”
    *医学图像分析*，第79卷，页102428，2022年。'
- en: '[7] L. Zhang, X. Wang, D. Yang, T. Sanford, S. Harmon, B. Turkbey, B. J. Wood,
    H. Roth, A. Myronenko, D. Xu *et al.*, “Generalizing deep learning for medical
    image segmentation to unseen domains via deep stacked transformation,” *IEEE transactions
    on medical imaging*, vol. 39, no. 7, pp. 2531–2540, 2020.'
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] L. Zhang, X. Wang, D. Yang, T. Sanford, S. Harmon, B. Turkbey, B. J. Wood,
    H. Roth, A. Myronenko, D. Xu *等人*，“通过深度堆叠变换将深度学习推广到未见领域的医学图像分割，”*IEEE医学成像学报*，第39卷，第7期，页2531–2540，2020年。'
- en: '[8] M. Z. Alom, C. Yakopcic, M. Hasan, T. M. Taha, and V. K. Asari, “Recurrent
    residual u-net for medical image segmentation,” *Journal of Medical Imaging*,
    vol. 6, no. 1, p. 014006, 2019.'
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] M. Z. Alom, C. Yakopcic, M. Hasan, T. M. Taha, 和 V. K. Asari，“用于医学图像分割的递归残差U-Net，”*医学成像期刊*，第6卷，第1期，页014006，2019年。'
- en: '[9] Y. Zhang, R. Jiao, Q. Liao, D. Li, and J. Zhang, “Uncertainty-guided mutual
    consistency learning for semi-supervised medical image segmentation,” *Artificial
    Intelligence in Medicine*, vol. 138, p. 102476, 2023.'
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] Y. Zhang, R. Jiao, Q. Liao, D. Li, 和 J. Zhang，“用于半监督医学图像分割的不确定性引导互一致学习，”*医学中的人工智能*，第138卷，页102476，2023年。'
- en: '[10] J. Ma, “Cutting-edge 3d medical image segmentation methods in 2020: Are
    happy families all alike?” *arXiv preprint arXiv:2101.00232*, 2021.'
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. Ma，“2020年前沿3D医学图像分割方法：幸福的家庭都是相似的吗？”*arXiv预印本 arXiv:2101.00232*，2021年。'
- en: '[11] J. Chen, Y. Lu, Q. Yu, X. Luo, E. Adeli, Y. Wang, L. Lu, A. L. Yuille,
    and Y. Zhou, “Transunet: Transformers make strong encoders for medical image segmentation,”
    *arXiv preprint arXiv:2102.04306*, 2021.'
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] J. Chen, Y. Lu, Q. Yu, X. Luo, E. Adeli, Y. Wang, L. Lu, A. L. Yuille,
    和 Y. Zhou，“Transunet：变压器使医学图像分割变得强大，”*arXiv预印本 arXiv:2102.04306*，2021年。'
- en: '[12] Q. Yao, L. Xiao, P. Liu, and S. K. Zhou, “Label-free segmentation of covid-19
    lesions in lung ct,” *IEEE transactions on medical imaging*, vol. 40, no. 10,
    pp. 2808–2819, 2021.'
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Q. Yao, L. Xiao, P. Liu, 和 S. K. Zhou，“无标签的COVID-19肺部CT病变分割，”*IEEE医学成像学报*，第40卷，第10期，页2808–2819，2021年。'
- en: '[13] Y. Xie, J. Zhang, C. Shen, and Y. Xia, “Cotr: Efficiently bridging cnn
    and transformer for 3d medical image segmentation,” in *International conference
    on medical image computing and computer-assisted intervention*.   Springer, 2021,
    pp. 171–180.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Xie, J. Zhang, C. Shen, 和 Y. Xia，“Cotr：高效地连接CNN和变压器以进行3D医学图像分割，”在*国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页171–180。'
- en: '[14] M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider, B. A.
    Landman, G. Litjens, B. Menze, O. Ronneberger, R. M. Summers *et al.*, “The medical
    segmentation decathlon,” *Nature Communications*, vol. 13, no. 1, pp. 1–13, 2022.'
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] M. Antonelli, A. Reinke, S. Bakas, K. Farahani, A. Kopp-Schneider, B.
    A. Landman, G. Litjens, B. Menze, O. Ronneberger, R. M. Summers *等人*，“医学分割十项全能，”*自然通讯*，第13卷，第1期，页1–13，2022年。'
- en: '[15] J. Shiraishi, S. Katsuragawa, J. Ikezoe, T. Matsumoto, T. Kobayashi, K.-i.
    Komatsu, M. Matsui, H. Fujita, Y. Kodera, and K. Doi, “Development of a digital
    image database for chest radiographs with and without a lung nodule: receiver
    operating characteristic analysis of radiologists’ detection of pulmonary nodules,”
    *American Journal of Roentgenology*, vol. 174, no. 1, pp. 71–74, 2000.'
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] J. Shiraishi, S. Katsuragawa, J. Ikezoe, T. Matsumoto, T. Kobayashi, K.-i.
    Komatsu, M. Matsui, H. Fujita, Y. Kodera, 和 K. Doi，“开发包含有无肺结节的胸部X光图像的数字图像数据库：放射科医生对肺结节的检测特征分析，”*美国放射学杂志*，第174卷，第1期，页71–74，2000年。'
- en: '[16] J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, Q. Zhu, G. Dong, J. He,
    Z. He *et al.*, “Toward data-efficient learning: A benchmark for covid-19 ct lung
    and infection segmentation,” *Medical physics*, vol. 48, no. 3, pp. 1197–1210,
    2021.'
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, Q. Zhu, G. Dong, J. He,
    Z. He *等人*，“迈向数据高效学习：COVID-19 CT肺部及感染分割基准，”*医学物理*，第48卷，第3期，页1197–1210，2021年。'
- en: '[17] P. Bilic, P. Christ, H. B. Li, E. Vorontsov, A. Ben-Cohen, G. Kaissis,
    A. Szeskin, C. Jacobs, G. E. H. Mamani, G. Chartrand *et al.*, “The liver tumor
    segmentation benchmark (lits),” *Medical Image Analysis*, vol. 84, p. 102680,
    2023.'
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] P. Bilic, P. Christ, H. B. Li, E. Vorontsov, A. Ben-Cohen, G. Kaissis,
    A. Szeskin, C. Jacobs, G. E. H. Mamani, G. Chartrand *等人*，“肝肿瘤分割基准（LITS），”*医学图像分析*，第84卷，页102680，2023年。'
- en: '[18] E. Bullitt, D. Zeng, G. Gerig, S. Aylward, S. Joshi, J. K. Smith, W. Lin,
    and M. G. Ewend, “Vessel tortuosity and brain tumor malignancy: a blinded study1,”
    *Academic radiology*, vol. 12, no. 10, pp. 1232–1240, 2005.'
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] E. Bullitt, D. Zeng, G. Gerig, S. Aylward, S. Joshi, J. K. Smith, W. Lin,
    和 M. G. Ewend，“血管曲折度与脑肿瘤恶性度：盲研究1，”*学术放射学*，第12卷，第10期，页1232–1240，2005年。'
- en: '[19] N. Codella, V. Rotemberg, P. Tschandl, M. E. Celebi, S. Dusza, D. Gutman,
    B. Helba, A. Kalloo, K. Liopyris, M. Marchetti *et al.*, “Skin lesion analysis
    toward melanoma detection 2018: A challenge hosted by the international skin imaging
    collaboration (isic),” *arXiv preprint arXiv:1902.03368*, 2019.'
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] N. Codella, V. Rotemberg, P. Tschandl, M. E. Celebi, S. Dusza, D. Gutman,
    B. Helba, A. Kalloo, K. Liopyris, M. Marchetti *等*，“皮肤病变分析与黑色素瘤检测2018：由国际皮肤影像合作组织（ISIC）主办的挑战赛，”
    *arXiv预印本 arXiv:1902.03368*，2019年。'
- en: '[20] J. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciurea-Ilcus, C. Chute, H. Marklund,
    B. Haghgoo, R. Ball, K. Shpanskaya *et al.*, “Chexpert: A large chest radiograph
    dataset with uncertainty labels and expert comparison,” in *Proceedings of the
    AAAI conference on artificial intelligence*, vol. 33, no. 01, 2019, pp. 590–597.'
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] J. Irvin, P. Rajpurkar, M. Ko, Y. Yu, S. Ciurea-Ilcus, C. Chute, H. Marklund,
    B. Haghgoo, R. Ball, K. Shpanskaya *等*，“Chexpert：一个大型胸部X光影像数据集，包含不确定性标签和专家比较，”发表在*AAAI人工智能会议论文集*，第33卷，第01期，2019年，页码590–597。'
- en: '[21] G. Wang, S. Zhai, G. Lasio, B. Zhang, B. Yi, S. Chen, T. J. Macvittie,
    D. Metaxas, J. Zhou, and S. Zhang, “Semi-supervised segmentation of radiation-induced
    pulmonary fibrosis from lung ct scans with multi-scale guided dense attention,”
    *IEEE transactions on medical imaging*, vol. 41, no. 3, pp. 531–542, 2021.'
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] G. Wang, S. Zhai, G. Lasio, B. Zhang, B. Yi, S. Chen, T. J. Macvittie,
    D. Metaxas, J. Zhou, 和 S. Zhang, “采用多尺度引导密集注意力的放射线诱导肺纤维化的半监督分割，” *IEEE医学成像交易*，第41卷，第3期，页码531–542，2021年。'
- en: '[22] O. Bernard, A. Lalande, C. Zotti, F. Cervenansky, X. Yang, P.-A. Heng,
    I. Cetin, K. Lekadir, O. Camara, M. A. G. Ballester *et al.*, “Deep learning techniques
    for automatic mri cardiac multi-structures segmentation and diagnosis: is the
    problem solved?” *IEEE transactions on medical imaging*, vol. 37, no. 11, pp.
    2514–2525, 2018.'
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] O. Bernard, A. Lalande, C. Zotti, F. Cervenansky, X. Yang, P.-A. Heng,
    I. Cetin, K. Lekadir, O. Camara, M. A. G. Ballester *等*，“用于自动MRI心脏多结构分割和诊断的深度学习技术：问题是否得到解决？”
    *IEEE医学成像交易*，第37卷，第11期，页码2514–2525，2018年。'
- en: '[23] N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, Y. Nan,
    G. Mu, Z. Lin, M. Han *et al.*, “The state of the art in kidney and kidney tumor
    segmentation in contrast-enhanced ct imaging: Results of the kits19 challenge,”
    *Medical image analysis*, vol. 67, p. 101821, 2021.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] N. Heller, F. Isensee, K. H. Maier-Hein, X. Hou, C. Xie, F. Li, Y. Nan,
    G. Mu, Z. Lin, M. Han *等*，“对比增强CT成像中肾脏及肾脏肿瘤分割的最新进展：KITS19挑战赛结果，” *医学图像分析*，第67卷，文章编号101821，2021年。'
- en: '[24] V. Oreiller, V. Andrearczyk, M. Jreige, S. Boughdad, H. Elhalawani, J. Castelli,
    M. Vallières, S. Zhu, J. Xie, Y. Peng *et al.*, “Head and neck tumor segmentation
    in pet/ct: the hecktor challenge,” *Medical image analysis*, vol. 77, p. 102336,
    2022.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] V. Oreiller, V. Andrearczyk, M. Jreige, S. Boughdad, H. Elhalawani, J.
    Castelli, M. Vallières, S. Zhu, J. Xie, Y. Peng *等*，“PET/CT中的头颈部肿瘤分割：HECKTOR挑战，”
    *医学图像分析*，第77卷，文章编号102336，2022年。'
- en: '[25] N. Tajbakhsh, L. Jeyaseelan, Q. Li, J. N. Chiang, Z. Wu, and X. Ding,
    “Embracing imperfect datasets: A review of deep learning solutions for medical
    image segmentation,” *Medical Image Analysis*, vol. 63, p. 101693, 2020.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] N. Tajbakhsh, L. Jeyaseelan, Q. Li, J. N. Chiang, Z. Wu, 和 X. Ding, “拥抱不完美的数据集：医学图像分割的深度学习解决方案综述，”
    *医学图像分析*，第63卷，文章编号101693，2020年。'
- en: '[26] Y. Zhang, Q. Liao, L. Yuan, H. Zhu, J. Xing, and J. Zhang, “Exploiting
    shared knowledge from non-covid lesions for annotation-efficient covid-19 ct lung
    infection segmentation,” *IEEE journal of biomedical and health informatics*,
    vol. 25, no. 11, pp. 4152–4162, 2021.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Y. Zhang, Q. Liao, L. Yuan, H. Zhu, J. Xing, 和 J. Zhang, “利用非COVID病变的共享知识进行注释高效的COVID-19
    CT肺感染分割，” *IEEE生物医学与健康信息学期刊*，第25卷，第11期，页码4152–4162，2021年。'
- en: '[27] V. Cheplygina, M. de Bruijne, and J. P. Pluim, “Not-so-supervised: a survey
    of semi-supervised, multi-instance, and transfer learning in medical image analysis,”
    *Medical image analysis*, vol. 54, pp. 280–296, 2019.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] V. Cheplygina, M. de Bruijne, 和 J. P. Pluim, “不那么监督：医学图像分析中的半监督、多实例和迁移学习综述，”*医学图像分析*，第54卷，页码280–296，2019年。'
- en: '[28] S. Min, X. Chen, Z.-J. Zha, F. Wu, and Y. Zhang, “A two-stream mutual
    attention network for semi-supervised biomedical segmentation with noisy labels,”
    in *Proceedings of the AAAI Conference on Artificial Intelligence*, vol. 33, no. 01,
    2019, pp. 4578–4585.'
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] S. Min, X. Chen, Z.-J. Zha, F. Wu, 和 Y. Zhang, “一种用于带噪标签的半监督生物医学分割的双流互注意力网络，”发表在*AAAI人工智能会议论文集*，第33卷，第01期，2019年，页码4578–4585。'
- en: '[29] A. Tarvainen and H. Valpola, “Mean teachers are better role models: Weight-averaged
    consistency targets improve semi-supervised deep learning results,” *Advances
    in neural information processing systems*, vol. 30, 2017.'
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] A. Tarvainen 和 H. Valpola，“平均教师更是好的榜样：权重平均一致性目标改善半监督深度学习结果”，*神经信息处理系统进展*，第
    30 卷，2017 年。'
- en: '[30] S. Laine and T. Aila, “Temporal ensembling for semi-supervised learning,”
    *arXiv preprint arXiv:1610.02242*, 2016.'
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] S. Laine 和 T. Aila，“用于半监督学习的时间集成”，*arXiv 预印本 arXiv:1610.02242*，2016 年。'
- en: '[31] L. Yu, S. Wang, X. Li, C.-W. Fu, and P.-A. Heng, “Uncertainty-aware self-ensembling
    model for semi-supervised 3d left atrium segmentation,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2019,
    pp. 605–613.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] L. Yu, S. Wang, X. Li, C.-W. Fu 和 P.-A. Heng，“面向半监督 3D 左心房分割的自不确定性自集成模型”，发表于
    *国际医学图像计算与计算机辅助手术会议*。  Springer, 2019, 第 605–613 页。'
- en: '[32] Y. Wang, Y. Zhang, J. Tian, C. Zhong, Z. Shi, Y. Zhang, and Z. He, “Double-uncertainty
    weighted method for semi-supervised learning,” in *International Conference on
    Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2020,
    pp. 542–551.'
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Y. Wang, Y. Zhang, J. Tian, C. Zhong, Z. Shi, Y. Zhang 和 Z. He，“用于半监督学习的双不确定性加权方法”，发表于
    *国际医学图像计算与计算机辅助手术会议*。  Springer, 2020, 第 542–551 页。'
- en: '[33] W. Hang, W. Feng, S. Liang, L. Yu, Q. Wang, K.-S. Choi, and J. Qin, “Local
    and global structure-aware entropy regularized mean teacher model for 3d left
    atrium segmentation,” in *International Conference on Medical Image Computing
    and Computer-Assisted Intervention*.   Springer, 2020, pp. 562–571.'
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] W. Hang, W. Feng, S. Liang, L. Yu, Q. Wang, K.-S. Choi 和 J. Qin，“用于 3D
    左心房分割的局部和全局结构感知熵正则化平均教师模型”，发表于 *国际医学图像计算与计算机辅助手术会议*。  Springer, 2020, 第 562–571
    页。'
- en: '[34] S. Li, C. Zhang, and X. He, “Shape-aware semi-supervised 3d semantic segmentation
    for medical images,” in *International Conference on Medical Image Computing and
    Computer-Assisted Intervention*.   Springer, 2020, pp. 552–561.'
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] S. Li, C. Zhang 和 X. He，“面向医学图像的形状感知半监督 3D 语义分割”，发表于 *国际医学图像计算与计算机辅助手术会议*。
     Springer, 2020, 第 552–561 页。'
- en: '[35] X. Luo, J. Chen, T. Song, and G. Wang, “Semi-supervised medical image
    segmentation through dual-task consistency,” in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 35, no. 10, 2021, pp. 8801–8809.'
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] X. Luo, J. Chen, T. Song 和 G. Wang，“通过双任务一致性进行半监督医学图像分割”，发表于 *AAAI 人工智能会议论文集*，第
    35 卷，第 10 期，2021 年，第 8801–8809 页。'
- en: '[36] Y. Zhang and J. Zhang, “Dual-task mutual learning for semi-supervised
    medical image segmentation,” in *Chinese Conference on Pattern Recognition and
    Computer Vision (PRCV)*.   Springer, 2021, pp. 548–559.'
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Y. Zhang 和 J. Zhang，“用于半监督医学图像分割的双任务互学习”，发表于 *中国模式识别与计算机视觉大会 (PRCV)*。
     Springer, 2021, 第 548–559 页。'
- en: '[37] J. Long, E. Shelhamer, and T. Darrell, “Fully convolutional networks for
    semantic segmentation,” in *Proceedings of the IEEE conference on computer vision
    and pattern recognition*, 2015, pp. 3431–3440.'
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] J. Long, E. Shelhamer 和 T. Darrell，“用于语义分割的全卷积网络”，发表于 *IEEE 计算机视觉与模式识别会议论文集*，2015
    年，第 3431–3440 页。'
- en: '[38] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
    for biomedical image segmentation,” in *International Conference on Medical image
    computing and computer-assisted intervention*.   Springer, 2015, pp. 234–241.'
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] O. Ronneberger, P. Fischer 和 T. Brox，“U-net: 生物医学图像分割的卷积网络”，发表于 *国际医学图像计算与计算机辅助手术会议*。
     Springer, 2015, 第 234–241 页。'
- en: '[39] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox, and O. Ronneberger,
    “3d u-net: learning dense volumetric segmentation from sparse annotation,” in
    *International conference on medical image computing and computer-assisted intervention*.   Springer,
    2016, pp. 424–432.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Ö. Çiçek, A. Abdulkadir, S. S. Lienkamp, T. Brox 和 O. Ronneberger，“3D
    U-net: 从稀疏注释中学习密集体积分割”，发表于 *国际医学图像计算与计算机辅助手术会议*。  Springer, 2016, 第 424–432 页。'
- en: '[40] F. Milletari, N. Navab, and S.-A. Ahmadi, “V-net: Fully convolutional
    neural networks for volumetric medical image segmentation,” in *2016 fourth international
    conference on 3D vision (3DV)*.   IEEE, 2016, pp. 565–571.'
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] F. Milletari, N. Navab 和 S.-A. Ahmadi，“V-net: 用于体积医学图像分割的全卷积神经网络”，发表于
    *2016 年第四届国际 3D 视觉会议 (3DV)*。  IEEE, 2016, 第 565–571 页。'
- en: '[41] X. Li, H. Chen, X. Qi, Q. Dou, C.-W. Fu, and P.-A. Heng, “H-denseunet:
    hybrid densely connected unet for liver and tumor segmentation from ct volumes,”
    *IEEE transactions on medical imaging*, vol. 37, no. 12, pp. 2663–2674, 2018.'
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] X. Li, H. Chen, X. Qi, Q. Dou, C.-W. Fu, 和 P.-A. Heng，“H-denseunet: 混合密集连接的unet用于从ct体积中分割肝脏和肿瘤”，*IEEE
    医学影像学报*，第37卷，第12期，第2663–2674页，2018年。'
- en: '[42] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, and J. Liang, “Unet++: Redesigning
    skip connections to exploit multiscale features in image segmentation,” *IEEE
    transactions on medical imaging*, vol. 39, no. 6, pp. 1856–1867, 2019.'
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Z. Zhou, M. M. R. Siddiquee, N. Tajbakhsh, 和 J. Liang，“Unet++: 重新设计跳跃连接以利用图像分割中的多尺度特征”，*IEEE
    医学影像学报*，第39卷，第6期，第1856–1867页，2019年。'
- en: '[43] Y. Zhang, L. Yuan, Y. Wang, and J. Zhang, “Sau-net: efficient 3d spine
    mri segmentation using inter-slice attention,” in *Medical Imaging With Deep Learning*.   PMLR,
    2020, pp. 903–913.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Y. Zhang, L. Yuan, Y. Wang, 和 J. Zhang，“Sau-net: 使用切片间注意力的高效3d脊柱MRI分割”，在*深度学习医学影像学*中。
    PMLR, 2020年，第903–913页。'
- en: '[44] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker,
    A. King, P. M. Matthews, and D. Rueckert, “Semi-supervised learning for network-based
    cardiac mr image segmentation,” in *International Conference on Medical Image
    Computing and Computer-Assisted Intervention*.   Springer, 2017, pp. 253–260.'
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] W. Bai, O. Oktay, M. Sinclair, H. Suzuki, M. Rajchl, G. Tarroni, B. Glocker,
    A. King, P. M. Matthews, 和 D. Rueckert，“基于网络的心脏mr图像分割的半监督学习”，在*国际医学图像计算与计算机辅助手术会议*中。
    Springer, 2017年，第253–260页。'
- en: '[45] Y. Zhang, L. Yang, J. Chen, M. Fredericksen, D. P. Hughes, and D. Z. Chen,
    “Deep adversarial networks for biomedical image segmentation utilizing unannotated
    images,” in *International conference on medical image computing and computer-assisted
    intervention*.   Springer, 2017, pp. 408–416.'
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] Y. Zhang, L. Yang, J. Chen, M. Fredericksen, D. P. Hughes, 和 D. Z. Chen，“利用未标注图像的深度对抗网络用于生物医学图像分割”，在*国际医学图像计算与计算机辅助手术会议*中。
    Springer, 2017年，第408–416页。'
- en: '[46] X. Hao, S. Gao, L. Sheng, and J. Zhang, “Parameter decoupling strategy
    for semi-supervised 3d left atrium segmentation,” in *Fourteenth International
    Conference on Machine Vision (ICMV 2021)*, vol. 12084.   SPIE, 2022, pp. 118–124.'
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] X. Hao, S. Gao, L. Sheng, 和 J. Zhang，“半监督3d左心房分割的参数解耦策略”，在*第十四届国际机器视觉会议
    (ICMV 2021)*中，第12084卷。 SPIE, 2022年，第118–124页。'
- en: '[47] C. You, Y. Zhou, R. Zhao, L. Staib, and J. S. Duncan, “Simcvd: Simple
    contrastive voxel-wise representation distillation for semi-supervised medical
    image segmentation,” *IEEE Transactions on Medical Imaging*, pp. 1–1, 2022.'
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] C. You, Y. Zhou, R. Zhao, L. Staib, 和 J. S. Duncan，“Simcvd: 用于半监督医学图像分割的简单对比体素级表示蒸馏”，*IEEE
    医学影像学报*，第1页，2022年。'
- en: '[48] J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, Q. Zhu, G. Dong, J. He,
    Z. He *et al.*, “Toward data-efficient learning: A benchmark for covid-19 ct lung
    and infection segmentation,” *Medical physics*, vol. 48, no. 3, pp. 1197–1210,
    2021.'
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] J. Ma, Y. Wang, X. An, C. Ge, Z. Yu, J. Chen, Q. Zhu, G. Dong, J. He,
    Z. He *等*，“迈向数据高效学习：COVID-19 CT肺部和感染分割基准”，*医学物理*，第48卷，第3期，第1197–1210页，2021年。'
- en: '[49] F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, and K. H. Maier-Hein,
    “nnu-net: a self-configuring method for deep learning-based biomedical image segmentation,”
    *Nature methods*, vol. 18, no. 2, pp. 203–211, 2021.'
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] F. Isensee, P. F. Jaeger, S. A. Kohl, J. Petersen, 和 K. H. Maier-Hein，“nnu-net:
    一种自配置的深度学习生物医学图像分割方法”，*自然方法*，第18卷，第2期，第203–211页，2021年。'
- en: '[50] X. Luo, W. Liao, J. Chen, T. Song, Y. Chen, S. Zhang, N. Chen, G. Wang,
    and S. Zhang, “Efficient semi-supervised gross target volume of nasopharyngeal
    carcinoma segmentation via uncertainty rectified pyramid consistency,” in *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2021, pp. 318–329.'
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] X. Luo, W. Liao, J. Chen, T. Song, Y. Chen, S. Zhang, N. Chen, G. Wang,
    和 S. Zhang，“通过不确定性校正的金字塔一致性进行有效的半监督鼻咽癌肿瘤体积分割”，在*国际医学图像计算与计算机辅助手术会议*中。 Springer,
    2021年，第318–329页。'
- en: '[51] Q. Jin, Z. Meng, C. Sun, H. Cui, and R. Su, “Ra-unet: A hybrid deep attention-aware
    network to extract liver and tumor in ct scans,” *Frontiers in Bioengineering
    and Biotechnology*, p. 1471, 2020.'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Q. Jin, Z. Meng, C. Sun, H. Cui, 和 R. Su，“Ra-unet: 一种混合深度注意力网络用于提取CT扫描中的肝脏和肿瘤”，*生物工程与生物技术前沿*，第1471页，2020年。'
- en: '[52] O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Misawa,
    K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz *et al.*, “Attention u-net: Learning
    where to look for the pancreas,” *arXiv preprint arXiv:1804.03999*, 2018.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] O. Oktay, J. Schlemper, L. L. Folgoc, M. Lee, M. Heinrich, K. Misawa,
    K. Mori, S. McDonagh, N. Y. Hammerla, B. Kainz *等*，“Attention u-net: 学习如何查看胰腺”，*arXiv
    预印本 arXiv:1804.03999*，2018年。'
- en: '[53] X. Luo, W. Liao, J. Xiao, J. Chen, T. Song, X. Zhang, K. Li, D. N. Metaxas,
    G. Wang, and S. Zhang, “Word: A large scale dataset, benchmark and clinical applicable
    study for abdominal organ segmentation from ct image,” *Medical Image Analysis*,
    vol. 82, p. 102642, 2022.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] X. Luo, W. Liao, J. Xiao, J. Chen, T. Song, X. Zhang, K. Li, D. N. Metaxas,
    G. Wang, 和 S. Zhang，“Word: 一种用于腹部器官CT图像分割的大规模数据集、基准和临床应用研究，”*医学图像分析*，第82卷，第102642页，2022年。'
- en: '[54] B. Lakshminarayanan, A. Pritzel, and C. Blundell, “Simple and scalable
    predictive uncertainty estimation using deep ensembles,” *Advances in neural information
    processing systems*, vol. 30, 2017.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] B. Lakshminarayanan, A. Pritzel, 和 C. Blundell，“使用深度集成进行简单且可扩展的预测不确定性估计，”*神经信息处理系统进展*，第30卷，2017年。'
- en: '[55] Y. Gal and Z. Ghahramani, “Dropout as a bayesian approximation: Representing
    model uncertainty in deep learning,” in *international conference on machine learning*.   PMLR,
    2016, pp. 1050–1059.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] Y. Gal 和 Z. Ghahramani，“Dropout作为贝叶斯近似：在深度学习中表示模型不确定性，”在*国际机器学习会议*中。PMLR，2016年，第1050–1059页。'
- en: '[56] Y. Wang, X. Wei, F. Liu, J. Chen, Y. Zhou, W. Shen, E. K. Fishman, and
    A. L. Yuille, “Deep distance transform for tubular structure segmentation in ct
    scans,” pp. 3833–3842, 2020.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Y. Wang, X. Wei, F. Liu, J. Chen, Y. Zhou, W. Shen, E. K. Fishman, 和 A.
    L. Yuille，“深度距离变换用于CT扫描中的管状结构分割，”第3833–3842页，2020年。'
- en: '[57] S. Dangi, C. A. Linte, and Z. Yaniv, “A distance map regularized cnn for
    cardiac cine mr image segmentation,” *Medical physics*, vol. 46, no. 12, pp. 5637–5651,
    2019.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] S. Dangi, C. A. Linte, 和 Z. Yaniv，“一种距离图正则化的CNN用于心脏电影MR图像分割，”*医学物理*，第46卷，第12期，第5637–5651页，2019年。'
- en: '[58] J. Ma, Z. Wei, Y. Zhang, Y. Wang, R. Lv, C. Zhu, C. Gaoxiang, J. Liu,
    C. Peng, L. Wang *et al.*, “How distance transform maps boost segmentation cnns:
    an empirical study,” in *Medical Imaging with Deep Learning*.   PMLR, 2020, pp.
    479–492.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] J. Ma, Z. Wei, Y. Zhang, Y. Wang, R. Lv, C. Zhu, C. Gaoxiang, J. Liu,
    C. Peng, L. Wang *等*，“距离变换图如何提升分割CNN：一项实证研究，”在*医学成像与深度学习*中。PMLR，2020年，第479–492页。'
- en: '[59] F. Navarro, S. Shit, I. Ezhov, J. Paetzold, A. Gafita, J. C. Peeken, S. E.
    Combs, and B. H. Menze, “Shape-aware complementary-task learning for multi-organ
    segmentation,” in *International Workshop on Machine Learning in Medical Imaging*.   Springer,
    2019, pp. 620–627.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] F. Navarro, S. Shit, I. Ezhov, J. Paetzold, A. Gafita, J. C. Peeken, S.
    E. Combs, 和 B. H. Menze，“形状感知的互补任务学习用于多器官分割，”在*国际医学成像中的机器学习研讨会*中。Springer，2019年，第620–627页。'
- en: '[60] X. Liu, F. Xing, N. Shusharina, R. Lim, C.-C. Jay Kuo, G. El Fakhri, and
    J. Woo, “Act: Semi-supervised domain-adaptive medical image segmentation with
    asymmetric co-training,” in *International Conference on Medical Image Computing
    and Computer-Assisted Intervention*.   Springer, 2022, pp. 66–76.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] X. Liu, F. Xing, N. Shusharina, R. Lim, C.-C. Jay Kuo, G. El Fakhri, 和
    J. Woo，“ACT: 半监督领域自适应医学图像分割与非对称共同训练，”在*国际医学图像计算与计算机辅助干预会议*中。Springer，2022年，第66–76页。'
- en: '[61] X. Li, L. Yu, H. Chen, C.-W. Fu, L. Xing, and P.-A. Heng, “Transformation-consistent
    self-ensembling model for semisupervised medical image segmentation,” *IEEE Transactions
    on Neural Networks and Learning Systems*, vol. 32, no. 2, pp. 523–534, 2020.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] X. Li, L. Yu, H. Chen, C.-W. Fu, L. Xing, 和 P.-A. Heng，“用于半监督医学图像分割的变换一致自集成模型，”*IEEE神经网络与学习系统汇刊*，第32卷，第2期，第523–534页，2020年。'
- en: '[62] Y. Zhang, T. Xiang, T. M. Hospedales, and H. Lu, “Deep mutual learning,”
    in *Proceedings of the IEEE conference on computer vision and pattern recognition*,
    2018, pp. 4320–4328.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Y. Zhang, T. Xiang, T. M. Hospedales, 和 H. Lu，“深度互学习，”在*IEEE计算机视觉与模式识别会议论文集*中，2018年，第4320–4328页。'
- en: '[63] L. Yu, J.-Z. Cheng, Q. Dou, X. Yang, H. Chen, J. Qin, and P.-A. Heng,
    “Automatic 3d cardiovascular mr segmentation with densely-connected volumetric
    convnets,” in *International conference on medical image computing and computer-assisted
    intervention*.   Springer, 2017, pp. 287–295.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] L. Yu, J.-Z. Cheng, Q. Dou, X. Yang, H. Chen, J. Qin, 和 P.-A. Heng，“使用密集连接的体积卷积网络进行自动3D心血管MR分割，”在*国际医学图像计算与计算机辅助干预会议*中。Springer，2017年，第287–295页。'
- en: '[64] Y. Zhang, Q. Liao, L. Ding, and J. Zhang, “Bridging 2d and 3d segmentation
    networks for computation-efficient volumetric medical image segmentation: An empirical
    study of 2.5 d solutions,” *Computerized Medical Imaging and Graphics*, p. 102088,
    2022.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Y. Zhang, Q. Liao, L. Ding, 和 J. Zhang，“桥接2D和3D分割网络以实现计算高效的体积医学图像分割：2.5D解决方案的实证研究，”*计算机化医学成像与图形*，第102088页，2022年。'
- en: '[65] T.-H. Vu, H. Jain, M. Bucher, M. Cord, and P. Pérez, “Advent: Adversarial
    entropy minimization for domain adaptation in semantic segmentation,” in *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2019,
    pp. 2517–2526.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] T.-H. Vu, H. Jain, M. Bucher, M. Cord, 和 P. Pérez，“Advent: 对语义分割中的领域适应进行对抗性熵最小化，”发表于
    *IEEE/CVF计算机视觉与模式识别会议论文集*，2019年，第2517–2526页。'
- en: '[66] Z. Xiong, Q. Xia, Z. Hu, N. Huang, C. Bian, Y. Zheng, S. Vesal, N. Ravikumar,
    A. Maier, X. Yang *et al.*, “A global benchmark of algorithms for segmenting the
    left atrium from late gadolinium-enhanced cardiac magnetic resonance imaging,”
    *Medical Image Analysis*, vol. 67, p. 101832, 2021.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Z. Xiong, Q. Xia, Z. Hu, N. Huang, C. Bian, Y. Zheng, S. Vesal, N. Ravikumar,
    A. Maier, X. Yang *等*，“从晚期钆增强心脏磁共振成像中分割左心房的算法全球基准，” *医学图像分析*，第67卷，第101832页，2021年。'
- en: '[67] K. Wang, B. Zhan, C. Zu, X. Wu, J. Zhou, L. Zhou, and Y. Wang, “Semi-supervised
    medical image segmentation via a tripled-uncertainty guided mean teacher model
    with contrastive learning,” *Medical Image Analysis*, vol. 79, p. 102447, 2022.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] K. Wang, B. Zhan, C. Zu, X. Wu, J. Zhou, L. Zhou, 和 Y. Wang，“通过对比学习的三重不确定性指导均值教师模型进行半监督医学图像分割，”
    *医学图像分析*，第79卷，第102447页，2022年。'
- en: '[68] H. Yao, X. Hu, and X. Li, “Enhancing pseudo label quality for semi-supervised
    domain-generalized medical image segmentation,” in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 36, no. 3, 2022, pp. 3099–3107.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] H. Yao, X. Hu, 和 X. Li，“提升伪标签质量以实现半监督领域泛化医学图像分割，”发表于 *AAAI人工智能会议论文集*，第36卷，第3期，2022年，第3099–3107页。'
- en: '[69] K. Han, L. Liu, Y. Song, Y. Liu, C. Qiu, Y. Tang, Q. Teng, and Z. Liu,
    “An effective semi-supervised approach for liver ct image segmentation,” *IEEE
    Journal of Biomedical and Health Informatics*, vol. 26, no. 8, pp. 3999–4007,
    2022.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] K. Han, L. Liu, Y. Song, Y. Liu, C. Qiu, Y. Tang, Q. Teng, 和 Z. Liu，“一种有效的半监督肝脏CT图像分割方法，”
    *IEEE生物医学与健康信息学杂志*，第26卷，第8期，第3999–4007页，2022年。'
- en: '[70] Z. Xu, Y. Wang, D. Lu, L. Yu, J. Yan, J. Luo, K. Ma, Y. Zheng, and R. K.-y.
    Tong, “All-around real label supervision: Cyclic prototype consistency learning
    for semi-supervised medical image segmentation,” *IEEE Journal of Biomedical and
    Health Informatics*, vol. 26, no. 7, pp. 3174–3184, 2022.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Z. Xu, Y. Wang, D. Lu, L. Yu, J. Yan, J. Luo, K. Ma, Y. Zheng, 和 R. K.-y.
    Tong，“全面真实标签监督：循环原型一致性学习用于半监督医学图像分割，” *IEEE生物医学与健康信息学杂志*，第26卷，第7期，第3174–3184页，2022年。'
- en: '[71] Z. Ren, R. Yeh, and A. Schwing, “Not all unlabeled data are equal: Learning
    to weight data in semi-supervised learning,” *Advances in Neural Information Processing
    Systems*, vol. 33, pp. 21 786–21 797, 2020.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Z. Ren, R. Yeh, 和 A. Schwing，“并非所有未标记的数据都是相同的：学习在半监督学习中加权数据，” *神经信息处理系统进展*，第33卷，第21 786–21 797页，2020年。'
- en: '[72] Z. Zhang, C. Tian, H. X. Bai, Z. Jiao, and X. Tian, “Discriminative error
    prediction network for semi-supervised colon gland segmentation,” *Medical Image
    Analysis*, vol. 79, p. 102458, 2022.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Z. Zhang, C. Tian, H. X. Bai, Z. Jiao, 和 X. Tian，“用于半监督结肠腺体分割的辨别性误差预测网络，”
    *医学图像分析*，第79卷，第102458页，2022年。'
- en: '[73] A. Ghosh and A. H. Thiery, “On data-augmentation and consistency-based
    semi-supervised learning,” in *International Conference on Learning Representations*,
    2020.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] A. Ghosh 和 A. H. Thiery，“关于数据增强和基于一致性的半监督学习，”发表于 *国际学习表征会议*，2020年。'
- en: '[74] M. Van Waerebeke, G. Lodygensky, and J. Dolz, “On the pitfalls of entropy-based
    uncertainty for multi-class semi-supervised segmentation,” in *International Workshop
    on Uncertainty for Safe Utilization of Machine Learning in Medical Imaging*.   Springer,
    2022, pp. 36–46.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] M. Van Waerebeke, G. Lodygensky, 和 J. Dolz，“关于基于熵的不确定性在多类半监督分割中的陷阱，”发表于
    *医学成像中机器学习安全利用的国际研讨会*。Springer，2022年，第36–46页。'
- en: '[75] X. Zhao, C. Fang, D.-J. Fan, X. Lin, F. Gao, and G. Li, “Cross-level contrastive
    learning and consistency constraint for semi-supervised medical image segmentation,”
    in *2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)*.   IEEE,
    2022, pp. 1–5.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] X. Zhao, C. Fang, D.-J. Fan, X. Lin, F. Gao, 和 G. Li，“跨级对比学习和一致性约束用于半监督医学图像分割，”发表于
    *2022 IEEE 第19届国际生物医学成像研讨会（ISBI）*。IEEE，2022年，第1–5页。'
- en: '[76] H. Basak, R. Bhattacharya, R. Hussain, and A. Chatterjee, “An embarrassingly
    simple consistency regularization method for semi-supervised medical image segmentation,”
    *arXiv preprint arXiv:2202.00677*, 2022.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] H. Basak, R. Bhattacharya, R. Hussain, 和 A. Chatterjee，“一种令人尴尬的简单一致性正则化方法用于半监督医学图像分割，”
    *arXiv预印本 arXiv:2202.00677*，2022年。'
- en: '[77] X. Xu, T. Sanford, B. Turkbey, S. Xu, B. J. Wood, and P. Yan, “Shadow-consistent
    semi-supervised learning for prostate ultrasound segmentation,” *IEEE Transactions
    on Medical Imaging*, vol. 41, no. 6, pp. 1331–1345, 2021.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] X. Xu, T. Sanford, B. Turkbey, S. Xu, B. J. Wood, 和 P. Yan，“用于前列腺超声分割的阴影一致半监督学习，”
    *IEEE 医学影像学报*，第 41 卷，第 6 期，页码 1331–1345，2021年。'
- en: '[78] N. Zhang, J. Hou, R.-W. Zhao, R. Feng, and Y. Zhang, “Semi-supervised
    medical image segmentation with distribution calibration and non-local semantic
    constraint,” in *2021 IEEE International Conference on Bioinformatics and Biomedicine
    (BIBM)*.   IEEE, 2021, pp. 1171–1178.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] N. Zhang, J. Hou, R.-W. Zhao, R. Feng, 和 Y. Zhang，“带有分布校准和非局部语义约束的半监督医学图像分割，”
    载于 *2021 IEEE 国际生物信息学与生物医学大会（BIBM）*。 IEEE，2021年，页码 1171–1178。'
- en: '[79] H. Huang, Q. Chen, L. Lin, M. Cai, Q. Zhang, Y. Iwamoto, X. Han, A. Furukawa,
    S. Kanasaki, Y.-W. Chen, R. Tong, and H. Hu, “Mtl-abs3net: Atlas-based semi-supervised
    organ segmentation network with multi-task learning for medical images,” *IEEE
    Journal of Biomedical and Health Informatics*, vol. 26, no. 8, pp. 3988–3998,
    2022.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] H. Huang, Q. Chen, L. Lin, M. Cai, Q. Zhang, Y. Iwamoto, X. Han, A. Furukawa,
    S. Kanasaki, Y.-W. Chen, R. Tong, 和 H. Hu，“MTL-ABS3NET: 基于图谱的半监督器官分割网络，结合多任务学习用于医学图像，”
    *IEEE 生物医学与健康信息学报*，第 26 卷，第 8 期，页码 3988–3998，2022年。'
- en: '[80] J. Peng, P. Wang, C. Desrosiers, and M. Pedersoli, “Self-paced contrastive
    learning for semi-supervised medical image segmentation with meta-labels,” *Advances
    in Neural Information Processing Systems*, vol. 34, pp. 16 686–16 699, 2021.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] J. Peng, P. Wang, C. Desrosiers, 和 M. Pedersoli，“用于半监督医学图像分割的自适应对比学习与元标签，”
    *神经信息处理系统进展*，第 34 卷，页码 16 686–16 699，2021年。'
- en: '[81] L. Hu, J. Li, X. Peng, J. Xiao, B. Zhan, C. Zu, X. Wu, J. Zhou, and Y. Wang,
    “Semi-supervised npc segmentation with uncertainty and attention guided consistency,”
    *Knowledge-Based Systems*, vol. 239, p. 108021, 2022.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] L. Hu, J. Li, X. Peng, J. Xiao, B. Zhan, C. Zu, X. Wu, J. Zhou, 和 Y. Wang，“具有不确定性和注意力引导一致性的半监督
    NPC 分割，” *知识基系统*，第 239 卷，页码 108021，2022年。'
- en: '[82] B. H. Thompson, G. Di Caterina, and J. P. Voisey, “Pseudo-label refinement
    using superpixels for semi-supervised brain tumour segmentation,” in *2022 IEEE
    19th International Symposium on Biomedical Imaging (ISBI)*.   IEEE, 2022, pp.
    1–5.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] B. H. Thompson, G. Di Caterina, 和 J. P. Voisey，“使用超像素进行伪标签细化的半监督脑肿瘤分割，”
    载于 *2022 IEEE 第19届国际生物医学成像研讨会（ISBI）*。 IEEE，2022年，页码 1–5。'
- en: '[83] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Süsstrunk, “Slic
    superpixels compared to state-of-the-art superpixel methods,” *IEEE transactions
    on pattern analysis and machine intelligence*, vol. 34, no. 11, pp. 2274–2282,
    2012.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, 和 S. Süsstrunk，“与最先进的超像素方法相比的
    Slic 超像素，” *IEEE 模式分析与机器智能学报*，第 34 卷，第 11 期，页码 2274–2282，2012年。'
- en: '[84] A. Xu, S. Wang, S. Ye, J. Fan, X. Shi, and X. Xia, “Ca-mt: A self-ensembling
    model for semi-supervised cardiac segmentation with elliptical descriptor based
    contour-aware,” in *2022 IEEE 19th International Symposium on Biomedical Imaging
    (ISBI)*.   IEEE, 2022, pp. 1–5.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] A. Xu, S. Wang, S. Ye, J. Fan, X. Shi, 和 X. Xia，“Ca-mt: 一种基于椭圆描述符的轮廓感知半监督心脏分割自集成模型，”
    载于 *2022 IEEE 第19届国际生物医学成像研讨会（ISBI）*。 IEEE，2022年，页码 1–5。'
- en: '[85] S. Li, Z. Zhao, K. Xu, Z. Zeng, and C. Guan, “Hierarchical consistency
    regularized mean teacher for semi-supervised 3d left atrium segmentation,” in
    *2021 43rd Annual International Conference of the IEEE Engineering in Medicine
    & Biology Society (EMBC)*.   IEEE, 2021, pp. 3395–3398.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] S. Li, Z. Zhao, K. Xu, Z. Zeng, 和 C. Guan，“用于半监督三维左心房分割的分层一致性正则化均值教师，”
    载于 *2021 第43届IEEE医学与生物工程年会（EMBC）*。 IEEE，2021年，页码 3395–3398。'
- en: '[86] C. M. Seibold, S. Reiß, J. Kleesiek, and R. Stiefelhagen, “Reference-guided
    pseudo-label generation for medical semantic segmentation,” in *Proceedings of
    the AAAI Conference on Artificial Intelligence*, vol. 36, no. 2, 2022, pp. 2171–2179.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] C. M. Seibold, S. Reiß, J. Kleesiek, 和 R. Stiefelhagen，“用于医学语义分割的参考引导伪标签生成，”
    载于 *AAAI 人工智能会议论文集*，第 36 卷，第 2 期，2022年，页码 2171–2179。'
- en: '[87] Y. Shi, J. Zhang, T. Ling, J. Lu, Y. Zheng, Q. Yu, L. Qi, and Y. Gao,
    “Inconsistency-aware uncertainty estimation for semi-supervised medical image
    segmentation,” *IEEE Transactions on Medical Imaging*, vol. 41, no. 3, pp. 608–620,
    2021.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Y. Shi, J. Zhang, T. Ling, J. Lu, Y. Zheng, Q. Yu, L. Qi, 和 Y. Gao，“用于半监督医学图像分割的一致性感知不确定性估计，”
    *IEEE 医学影像学报*，第 41 卷，第 3 期，页码 608–620，2021年。'
- en: '[88] J. Chen, H. Zhang, R. Mohiaddin, T. Wong, D. Firmin, J. Keegan, and G. Yang,
    “Adaptive hierarchical dual consistency for semi-supervised left atrium segmentation
    on cross-domain data,” *IEEE Transactions on Medical Imaging*, vol. 41, no. 2,
    pp. 420–433, 2021.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] J. Chen, H. Zhang, R. Mohiaddin, T. Wong, D. Firmin, J. Keegan, 和 G. Yang,
    “自适应层次双一致性用于跨领域数据上的半监督左心房分割，” *IEEE 医学影像学汇刊*，第41卷，第2期，页码420–433，2021年。'
- en: '[89] K. Zheng, J. Xu, and J. Wei, “Double noise mean teacher self-ensembling
    model for semi-supervised tumor segmentation,” in *ICASSP 2022-2022 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*.   IEEE, 2022,
    pp. 1446–1450.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] K. Zheng, J. Xu, 和 J. Wei, “双噪声均值教师自我集成模型用于半监督肿瘤分割，”发表于 *ICASSP 2022-2022
    IEEE 国际声学、语音和信号处理会议（ICASSP）*。IEEE，2022年，页码1446–1450。'
- en: '[90] A. Kendall and Y. Gal, “What uncertainties do we need in bayesian deep
    learning for computer vision?” *Advances in neural information processing systems*,
    vol. 30, 2017.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] A. Kendall 和 Y. Gal, “我们需要在计算机视觉的贝叶斯深度学习中处理哪些不确定性？” *神经信息处理系统进展*，第30卷，2017年。'
- en: '[91] M.-C. Xu, Y.-K. Zhou, C. Jin, S. B. Blumberg, F. J. Wilson, M. deGroot,
    D. C. Alexander, N. P. Oxtoby, and J. Jacob, “Learning morphological feature perturbations
    for calibrated semi-supervised segmentation,” in *International Conference on
    Medical Imaging with Deep Learning*.   PMLR, 2022, pp. 1413–1429.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] M.-C. Xu, Y.-K. Zhou, C. Jin, S. B. Blumberg, F. J. Wilson, M. deGroot,
    D. C. Alexander, N. P. Oxtoby, 和 J. Jacob, “学习形态特征扰动以进行校准的半监督分割，”发表于 *国际医学影像深度学习会议*。PMLR，2022年，页码1413–1429。'
- en: '[92] R. Wang, Y. Wu, H. Chen, L. Wang, and D. Meng, “Neighbor matching for
    semi-supervised learning,” in *International Conference on Medical Image Computing
    and Computer-Assisted Intervention*.   Springer, 2021, pp. 439–449.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] R. Wang, Y. Wu, H. Chen, L. Wang, 和 D. Meng, “邻域匹配用于半监督学习，”发表于 *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码439–449。'
- en: '[93] H. Peiris, Z. Chen, G. Egan, and M. Harandi, “Duo-segnet: adversarial
    dual-views for semi-supervised medical image segmentation,” in *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2021, pp. 428–438.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] H. Peiris, Z. Chen, G. Egan, 和 M. Harandi, “Duo-segnet：用于半监督医学图像分割的对抗性双视图，”发表于
    *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码428–438。'
- en: '[94] L. Zhu, K. Yang, M. Zhang, L. L. Chan, T. K. Ng, and B. C. Ooi, “Semi-supervised
    unpaired multi-modal learning for label-efficient medical image segmentation,”
    in *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*.   Springer, 2021, pp. 394–404.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] L. Zhu, K. Yang, M. Zhang, L. L. Chan, T. K. Ng, 和 B. C. Ooi, “半监督无配对多模态学习用于标签高效的医学图像分割，”发表于
    *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码394–404。'
- en: '[95] X. Zeng, R. Huang, Y. Zhong, D. Sun, C. Han, D. Lin, D. Ni, and Y. Wang,
    “Reciprocal learning for semi-supervised segmentation,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2021,
    pp. 352–361.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] X. Zeng, R. Huang, Y. Zhong, D. Sun, C. Han, D. Lin, D. Ni, 和 Y. Wang,
    “互惠学习用于半监督分割，”发表于 *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码352–361。'
- en: '[96] Y. Li, L. Luo, H. Lin, H. Chen, and P.-A. Heng, “Dual-consistency semi-supervised
    learning with uncertainty quantification for covid-19 lesion segmentation from
    ct images,” in *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*.   Springer, 2021, pp. 199–209.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] Y. Li, L. Luo, H. Lin, H. Chen, 和 P.-A. Heng, “基于不确定性量化的双一致性半监督学习用于从CT图像中分割COVID-19病变，”发表于
    *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码199–209。'
- en: '[97] K. Wang, B. Zhan, C. Zu, X. Wu, J. Zhou, L. Zhou, and Y. Wang, “Tripled-uncertainty
    guided mean teacher model for semi-supervised medical image segmentation,” in
    *International Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2021, pp. 450–460.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] K. Wang, B. Zhan, C. Zu, X. Wu, J. Zhou, L. Zhou, 和 Y. Wang, “三重不确定性引导的均值教师模型用于半监督医学图像分割，”发表于
    *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码450–460。'
- en: '[98] X. Hu, D. Zeng, X. Xu, and Y. Shi, “Semi-supervised contrastive learning
    for label-efficient medical image segmentation,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2021,
    pp. 481–490.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] X. Hu, D. Zeng, X. Xu, 和 Y. Shi, “半监督对比学习用于标签高效的医学图像分割，”发表于 *国际医学图像计算与计算机辅助干预会议*。Springer，2021年，页码481–490。'
- en: '[99] W. Huang, C. Chen, Z. Xiong, Y. Zhang, X. Chen, X. Sun, and F. Wu, “Semi-supervised
    neuron segmentation via reinforced consistency learning,” *IEEE Transactions on
    Medical Imaging*, pp. 1–1, 2022.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] W. Huang, C. Chen, Z. Xiong, Y. Zhang, X. Chen, X. Sun, 和 F. Wu，“通过强化一致性学习进行半监督神经元分割，”*IEEE
    医学成像汇刊*，页码1–1，2022年。'
- en: '[100] P. Wang, J. Peng, M. Pedersoli, Y. Zhou, C. Zhang, and C. Desrosiers,
    “Self-paced and self-consistent co-training for semi-supervised image segmentation,”
    *Medical Image Analysis*, vol. 73, p. 102146, 2021.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] P. Wang, J. Peng, M. Pedersoli, Y. Zhou, C. Zhang, 和 C. Desrosiers，“自适应和自一致的共同训练用于半监督图像分割，”*医学图像分析*，第73卷，页码102146，2021年。'
- en: '[101] C. Chen, K. Zhou, Z. Wang, and R. Xiao, “Generative consistency for semi-supervised
    cerebrovascular segmentation from tof-mra,” *IEEE Transactions on Medical Imaging*,
    pp. 1–1, 2022.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] C. Chen, K. Zhou, Z. Wang, 和 R. Xiao，“基于生成一致性的半监督脑血管分割，”*IEEE 医学成像汇刊*，页码1–1，2022年。'
- en: '[102] Y. Liu, W. Wang, G. Luo, K. Wang, and S. Li, “A contrastive consistency
    semi-supervised left atrium segmentation model,” *Computerized Medical Imaging
    and Graphics*, p. 102092, 2022.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] Y. Liu, W. Wang, G. Luo, K. Wang, 和 S. Li，“对比一致性半监督左心房分割模型，”*计算医学成像与图形*，页码102092，2022年。'
- en: '[103] X. Chen, H.-Y. Zhou, F. Liu, J. Guo, L. Wang, and Y. Yu, “Mass: Modality-collaborative
    semi-supervised segmentation by exploiting cross-modal consistency from unpaired
    ct and mri images,” *Medical Image Analysis*, p. 102506, 2022.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] X. Chen, H.-Y. Zhou, F. Liu, J. Guo, L. Wang, 和 Y. Yu，“MASS：通过利用未配对CT和MRI图像的跨模态一致性进行模态协作半监督分割，”*医学图像分析*，页码102506，2022年。'
- en: '[104] J. Wang and T. Lukasiewicz, “Rethinking bayesian deep learning methods
    for semi-supervised volumetric medical image segmentation,” in *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2022, pp.
    182–190.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] J. Wang 和 T. Lukasiewicz，“重新思考用于半监督体积医学图像分割的贝叶斯深度学习方法，”载于*IEEE/CVF 计算机视觉与模式识别大会论文集*，2022年，页码182–190。'
- en: '[105] H. Wu, Z. Wang, Y. Song, L. Yang, and J. Qin, “Cross-patch dense contrastive
    learning for semi-supervised segmentation of cellular nuclei in histopathologic
    images,” in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition*, 2022, pp. 11 666–11 675.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] H. Wu, Z. Wang, Y. Song, L. Yang, 和 J. Qin，“用于半监督细胞核分割的跨补丁密集对比学习，”载于*IEEE/CVF
    计算机视觉与模式识别大会论文集*，2022年，页码11 666–11 675。'
- en: '[106] X. Luo, G. Wang, W. Liao, J. Chen, T. Song, Y. Chen, S. Zhang, D. N.
    Metaxas, and S. Zhang, “Semi-supervised medical image segmentation via uncertainty
    rectified pyramid consistency,” *Medical Image Analysis*, p. 102517, 2022.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] X. Luo, G. Wang, W. Liao, J. Chen, T. Song, Y. Chen, S. Zhang, D. N.
    Metaxas, 和 S. Zhang，“通过不确定性校正金字塔一致性进行半监督医学图像分割，”*医学图像分析*，页码102517，2022年。'
- en: '[107] Y. Lin, H. Yao, Z. Li, G. Zheng, and X. Li, “Calibrating label distribution
    for class-imbalanced barely-supervised knee segmentation,” in *International Conference
    on Medical Image Computing and Computer-Assisted Intervention*.   Springer, 2022,
    pp. 109–118.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Y. Lin, H. Yao, Z. Li, G. Zheng, 和 X. Li，“为类别不平衡的几乎监督膝关节分割校准标签分布，”载于*国际医学图像计算与计算机辅助干预会议*，Springer，2022年，页码109–118。'
- en: '[108] H. Wu, J. Liu, F. Xiao, Z. Wen, L. Cheng, and J. Qin, “Semi-supervised
    segmentation of echocardiography videos via noise-resilient spatiotemporal semantic
    calibration and fusion,” *Medical Image Analysis*, vol. 78, p. 102397, 2022.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] H. Wu, J. Liu, F. Xiao, Z. Wen, L. Cheng, 和 J. Qin，“通过噪声抗性时空语义校准和融合进行半监督超声心动图视频分割，”*医学图像分析*，第78卷，页码102397，2022年。'
- en: '[109] X. Wang, Y. Yuan, D. Guo, X. Huang, Y. Cui, M. Xia, Z. Wang, C. Bai,
    and S. Chen, “Ssa-net: Spatial self-attention network for covid-19 pneumonia infection
    segmentation with semi-supervised few-shot learning,” *Medical Image Analysis*,
    vol. 79, p. 102459, 2022.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] X. Wang, Y. Yuan, D. Guo, X. Huang, Y. Cui, M. Xia, Z. Wang, C. Bai,
    和 S. Chen，“SSA-Net：用于新冠肺炎感染分割的空间自注意力网络，结合半监督少样本学习，”*医学图像分析*，第79卷，页码102459，2022年。'
- en: '[110] Z. Fang, J. Bai, X. Guo, X. Wang, F. Gao, H.-Y. Yang, B. Kong, Y. Hou,
    K. Cao, Q. Song *et al.*, “Annotation-efficient covid-19 pneumonia lesion segmentation
    using error-aware unified semi-supervised and active learning,” *IEEE Transactions
    on Artificial Intelligence*, 2022.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Z. Fang, J. Bai, X. Guo, X. Wang, F. Gao, H.-Y. Yang, B. Kong, Y. Hou,
    K. Cao, Q. Song *等*，“基于错误感知统一半监督和主动学习的高效标注新冠肺炎病灶分割，”*IEEE 人工智能汇刊*，2022年。'
- en: '[111] Z. Li, Z. Li, R. Liu, Z. Luo, and X. Fan, “Coupling deep deformable registration
    with contextual refinement for semi-supervised medical image segmentation,” in
    *2022 IEEE 19th International Symposium on Biomedical Imaging (ISBI)*.   IEEE,
    2022, pp. 1–5.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Z. Li, Z. Li, R. Liu, Z. Luo, 和 X. Fan, “将深度可变形配准与上下文细化相结合用于半监督医学图像分割,”
    发表在 *2022 IEEE 第十九届国际生物医学成像研讨会 (ISBI)*。IEEE, 2022, 第 1–5 页。'
- en: '[112] Y. Shu, H. Li, B. Xiao, X. Bi, and W. Li, “Cross-mix monitoring for medical
    image segmentation with limited supervision,” *IEEE Transactions on Multimedia*,
    pp. 1–1, 2022.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] Y. Shu, H. Li, B. Xiao, X. Bi, 和 W. Li, “针对有限监督的医学图像分割的 Cross-mix 监控,”
    *IEEE 多媒体学报*, 第 1–1 页, 2022。'
- en: '[113] Q.-Q. Chen, Z.-H. Sun, C.-F. Wei, E. Q. Wu, and D. Ming, “Semi-supervised
    3d medical image segmentation based on dual-task consistent joint learning and
    task-level regularization,” *IEEE/ACM Transactions on Computational Biology and
    Bioinformatics*, pp. 1–1, 2022.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] Q.-Q. Chen, Z.-H. Sun, C.-F. Wei, E. Q. Wu, 和 D. Ming, “基于双任务一致性联合学习和任务级正则化的半监督
    3D 医学图像分割,” *IEEE/ACM 计算生物学与生物信息学期刊*, 第 1–1 页, 2022。'
- en: '[114] M. Liu, L. Xiao, H. Jiang, and Q. He, “Ccat-net: A novel transformer
    based semi-supervised framework for covid-19 lung lesion segmentation,” in *2022
    IEEE 19th International Symposium on Biomedical Imaging (ISBI)*.   IEEE, 2022,
    pp. 1–5.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] M. Liu, L. Xiao, H. Jiang, 和 Q. He, “Ccat-net: 一种基于 transformer 的新型半监督框架用于
    COVID-19 肺部病变分割,” 发表在 *2022 IEEE 第十九届国际生物医学成像研讨会 (ISBI)*。IEEE, 2022, 第 1–5 页。'
- en: '[115] M. Sajjadi, M. Javanmardi, and T. Tasdizen, “Regularization with stochastic
    transformations and perturbations for deep semi-supervised learning,” *Advances
    in neural information processing systems*, vol. 29, 2016.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] M. Sajjadi, M. Javanmardi, 和 T. Tasdizen, “带有随机变换和扰动的正则化用于深度半监督学习,” *神经信息处理系统进展*,
    第 29 卷, 2016。'
- en: '[116] D. Nie, Y. Gao, L. Wang, and D. Shen, “Asdnet: attention based semi-supervised
    deep networks for medical image segmentation,” in *International conference on
    medical image computing and computer-assisted intervention*.   Springer, 2018,
    pp. 370–378.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] D. Nie, Y. Gao, L. Wang, 和 D. Shen, “Asdnet: 基于注意力的半监督深度网络用于医学图像分割,”
    发表在 *医学图像计算与计算机辅助干预国际会议*。Springer, 2018, 第 370–378 页。'
- en: '[117] K. Chaitanya, N. Karani, C. F. Baumgartner, A. Becker, O. Donati, and
    E. Konukoglu, “Semi-supervised and task-driven data augmentation,” in *International
    conference on information processing in medical imaging*.   Springer, 2019, pp.
    29–41.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] K. Chaitanya, N. Karani, C. F. Baumgartner, A. Becker, O. Donati, 和 E.
    Konukoglu, “半监督和任务驱动的数据增强,” 发表在 *医学图像信息处理国际会议*。Springer, 2019, 第 29–41 页。'
- en: '[118] G. Bortsova, F. Dubost, L. Hogeweg, I. Katramados, and M. d. Bruijne,
    “Semi-supervised medical image segmentation via learning consistency under transformations,”
    in *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*.   Springer, 2019, pp. 810–818.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] G. Bortsova, F. Dubost, L. Hogeweg, I. Katramados, 和 M. d. Bruijne, “通过在变换下学习一致性进行半监督医学图像分割,”
    发表在 *医学图像计算与计算机辅助干预国际会议*。Springer, 2019, 第 810–818 页。'
- en: '[119] Z. Xiao, Y. Su, Z. Deng, and W. Zhang, “Efficient combination of cnn
    and transformer for dual-teacher uncertainty-aware guided semi-supervised medical
    image segmentation,” *Available at SSRN 4081789*.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] Z. Xiao, Y. Su, Z. Deng, 和 W. Zhang, “高效结合 CNN 和 transformer 进行双教师不确定性感知的半监督医学图像分割,”
    *可在 SSRN 4081789 查阅*。'
- en: '[120] J. Yang, Y. Tao, Q. Xu, Y. Zhang, X. Ma, S. Yuan, and Q. Chen, “Self-supervised
    sequence recovery for semi-supervised retinal layer segmentation,” *IEEE Journal
    of Biomedical and Health Informatics*, vol. 26, no. 8, pp. 3872–3883, 2022.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] J. Yang, Y. Tao, Q. Xu, Y. Zhang, X. Ma, S. Yuan, 和 Q. Chen, “自监督序列恢复用于半监督视网膜层分割,”
    *IEEE 生物医学与健康信息学期刊*, 第 26 卷，第 8 期，第 3872–3883 页, 2022。'
- en: '[121] H. He, A. Banerjee, M. Beetz, R. P. Choudhury, and V. Grau, “Semi-supervised
    coronary vessels segmentation from invasive coronary angiography with connectivity-preserving
    loss function,” in *2022 IEEE 19th International Symposium on Biomedical Imaging
    (ISBI)*, 2022, pp. 1–5.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] H. He, A. Banerjee, M. Beetz, R. P. Choudhury, 和 V. Grau, “用于半监督冠状动脉血管分割的连接性保留损失函数,”
    发表在 *2022 IEEE 第十九届国际生物医学成像研讨会 (ISBI)*, 2022, 第 1–5 页。'
- en: '[122] D. Kiyasseh, A. Swiston, R. Chen, and A. Chen, “Segmentation of left
    atrial mr images via self-supervised semi-supervised meta-learning,” in *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2021, pp. 13–24.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] D. Kiyasseh, A. Swiston, R. Chen, 和 A. Chen, “通过自监督半监督元学习进行左心房 MR 图像分割,”
    发表在 *医学图像计算与计算机辅助干预国际会议*。Springer, 2021, 第 13–24 页。'
- en: '[123] V. M. Campello, P. Gkontra, C. Izquierdo, C. Martin-Isla, A. Sojoudi,
    P. M. Full, K. Maier-Hein, Y. Zhang, Z. He, J. Ma *et al.*, “Multi-centre, multi-vendor
    and multi-disease cardiac segmentation: the m&ms challenge,” *IEEE Transactions
    on Medical Imaging*, vol. 40, no. 12, pp. 3543–3554, 2021.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] V. M. Campello, P. Gkontra, C. Izquierdo, C. Martin-Isla, A. Sojoudi,
    P. M. Full, K. Maier-Hein, Y. Zhang, Z. He, J. Ma *等*，“多中心、多供应商和多疾病的心脏分割：M&MS
    挑战，” *IEEE 医学影像学汇刊*，第40卷，第12期，页码3543–3554，2021年。'
- en: '[124] G. Chen, J. Ru, Y. Zhou, I. Rekik, Z. Pan, X. Liu, Y. Lin, B. Lu, and
    J. Shi, “Mtans: Multi-scale mean teacher combined adversarial network with shape-aware
    embedding for semi-supervised brain lesion segmentation,” *NeuroImage*, vol. 244,
    p. 118568, 2021.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] G. Chen, J. Ru, Y. Zhou, I. Rekik, Z. Pan, X. Liu, Y. Lin, B. Lu, 和 J.
    Shi, “MTANS：多尺度均值教师结合对抗网络和形状感知嵌入用于半监督脑病灶分割，” *神经影像*，第244卷，文章编号118568，2021年。'
- en: '[125] S. Li, Y. Zhang, and X. Yang, “Semi-supervised cardiac mri segmentation
    based on generative adversarial network and variational auto-encoder,” in *2021
    IEEE International Conference on Bioinformatics and Biomedicine (BIBM)*.   IEEE,
    2021, pp. 1402–1405.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] S. Li, Y. Zhang, 和 X. Yang, “基于生成对抗网络和变分自编码器的半监督心脏 MRI 分割，”发表在 *2021
    IEEE 生物信息学与生物医学国际会议（BIBM）*。 IEEE，2021年，页码1402–1405。'
- en: '[126] G. Zhang, Z. Yang, B. Huo, S. Chai, and S. Jiang, “Automatic segmentation
    of organs at risk and tumors in ct images of lung cancer from partially labelled
    datasets with a semi-supervised conditional nnu-net,” *Computer methods and programs
    in biomedicine*, vol. 211, p. 106419, 2021.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] G. Zhang, Z. Yang, B. Huo, S. Chai, 和 S. Jiang, “使用半监督条件 NNU-Net 从部分标注数据集中自动分割肺癌
    CT 图像中的器官和肿瘤，” *生物医学中的计算方法与程序*，第211卷，文章编号106419，2021年。'
- en: '[127] Y. Wu, Z. Ge, D. Zhang, M. Xu, L. Zhang, Y. Xia, and J. Cai, “Mutual
    consistency learning for semi-supervised medical image segmentation,” *Medical
    Image Analysis*, p. 102530, 2022.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] Y. Wu, Z. Ge, D. Zhang, M. Xu, L. Zhang, Y. Xia, 和 J. Cai, “用于半监督医学图像分割的互一致性学习，”
    *医学图像分析*，文章编号102530，2022年。'
- en: '[128] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby,
    Y. Burren, N. Porz, J. Slotboom, R. Wiest *et al.*, “The multimodal brain tumor
    image segmentation benchmark (brats),” *IEEE transactions on medical imaging*,
    vol. 34, no. 10, pp. 1993–2024, 2014.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J.
    Kirby, Y. Burren, N. Porz, J. Slotboom, R. Wiest *等*，“多模态脑肿瘤图像分割基准（BRATS），” *IEEE
    医学影像学汇刊*，第34卷，第10期，页码1993–2024，2014年。'
- en: '[129] R. A. Zeineldin, M. E. Karar, J. Coburger, C. R. Wirtz, and O. Burgert,
    “Deepseg: deep neural network framework for automatic brain tumor segmentation
    using magnetic resonance flair images,” *International journal of computer assisted
    radiology and surgery*, vol. 15, no. 6, pp. 909–920, 2020.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] R. A. Zeineldin, M. E. Karar, J. Coburger, C. R. Wirtz, 和 O. Burgert,
    “Deepseg：一种用于自动脑肿瘤分割的深度神经网络框架，使用磁共振 FLAIR 图像，” *计算机辅助放射学与外科国际期刊*，第15卷，第6期，页码909–920，2020年。'
- en: '[130] K. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore,
    S. Phillips, D. Maffitt, M. Pringle *et al.*, “The cancer imaging archive (tcia):
    maintaining and operating a public information repository,” *Journal of digital
    imaging*, vol. 26, no. 6, pp. 1045–1057, 2013.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] K. Clark, B. Vendt, K. Smith, J. Freymann, J. Kirby, P. Koppel, S. Moore,
    S. Phillips, D. Maffitt, M. Pringle *等*，“癌症影像档案（TCIA）：维护和操作公共信息存储库，” *数字影像学杂志*，第26卷，第6期，页码1045–1057，2013年。'
- en: '[131] J. Wang, X. Li, Y. Han, J. Qin, L. Wang, and Z. Qichao, “Separated contrastive
    learning for organ-at-risk and gross-tumor-volume segmentation with limited annotation,”
    in *Proceedings of the AAAI Conference on Artificial Intelligence*, vol. 36, no. 3,
    2022, pp. 2459–2467.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] J. Wang, X. Li, Y. Han, J. Qin, L. Wang, 和 Z. Qichao, “用于器官风险和总肿瘤体积分割的分离对比学习，注释有限，”发表在
    *AAAI 人工智能会议论文集*，第36卷，第3期，2022年，页码2459–2467。'
- en: '[132] X. Luo, M. Hu, T. Song, G. Wang, and S. Zhang, “Semi-supervised medical
    image segmentation via cross teaching between cnn and transformer,” in *Medical
    Imaging With Deep Learning*.   PMLR, 2022, pp. 1–14.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] X. Luo, M. Hu, T. Song, G. Wang, 和 S. Zhang, “通过 CNN 和 Transformer 之间的交叉教学进行半监督医学图像分割，”发表在
    *深度学习医学影像*。 PMLR，2022年，页码1–14。'
- en: '[133] Z. Zhao, J. Hu, Z. Zeng, X. Yang, P. Qian, B. Veeravalli, and C. Guan,
    “Mmgl: Multi-scale multi-view global-local contrastive learning for semi-supervised
    cardiac image segmentation,” in *2022 IEEE international conference on image processing
    (ICIP)*.   IEEE, 2022, pp. 401–405.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Z. Zhao, J. Hu, Z. Zeng, X. Yang, P. Qian, B. Veeravalli, 和 C. Guan,
    “MMGL：用于半监督心脏图像分割的多尺度多视图全局-局部对比学习，”发表在 *2022 IEEE 图像处理国际会议（ICIP）*。 IEEE，2022年，页码401–405。'
- en: '[134] H. Wu, G. Chen, Z. Wen, and J. Qin, “Collaborative and adversarial learning
    of focused and dispersive representations for semi-supervised polyp segmentation,”
    in *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    2021, pp. 3489–3498.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] H. Wu, G. Chen, Z. Wen, 和 J. Qin, “面向半监督息肉分割的聚焦和分散表示的协作与对抗学习”，发表于*IEEE/CVF
    国际计算机视觉会议*，2021年，第3489–3498页。'
- en: '[135] Y. Xie, J. Zhang, Z. Liao, J. Verjans, C. Shen, and Y. Xia, “Intra-and
    inter-pair consistency for semi-supervised gland segmentation,” *IEEE Transactions
    on Image Processing*, vol. 31, pp. 894–905, 2021.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Y. Xie, J. Zhang, Z. Liao, J. Verjans, C. Shen, 和 Y. Xia, “用于半监督腺体分割的内外配对一致性”，*IEEE
    图像处理汇刊*，第31卷，第894–905页，2021年。'
- en: '[136] C. Li, L. Dong, Q. Dou, F. Lin, K. Zhang, Z. Feng, W. Si, X. Deng, Z. Deng,
    and P.-A. Heng, “Self-ensembling co-training framework for semi-supervised covid-19
    ct segmentation,” *IEEE Journal of Biomedical and Health Informatics*, vol. 25,
    no. 11, pp. 4140–4151, 2021.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] C. Li, L. Dong, Q. Dou, F. Lin, K. Zhang, Z. Feng, W. Si, X. Deng, Z.
    Deng, 和 P.-A. Heng, “用于半监督COVID-19 CT分割的自我集成协同训练框架”，*IEEE 生物医学与健康信息学期刊*，第25卷，第11期，第4140–4151页，2021年。'
- en: '[137] H. Yang, C. Shan, A. Bouwman, L. R. Dekker, A. F. Kolen, and P. H. de With,
    “Medical instrument segmentation in 3d us by hybrid constrained semi-supervised
    learning,” *IEEE Journal of Biomedical and Health Informatics*, vol. 26, no. 2,
    pp. 762–773, 2021.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] H. Yang, C. Shan, A. Bouwman, L. R. Dekker, A. F. Kolen, 和 P. H. de With,
    “通过混合约束的半监督学习进行3D超声医学仪器分割”，*IEEE 生物医学与健康信息学期刊*，第26卷，第2期，第762–773页，2021年。'
- en: '[138] S. Reiß, C. Seibold, A. Freytag, E. Rodner, and R. Stiefelhagen, “Every
    annotation counts: Multi-label deep supervision for medical image segmentation,”
    in *Proceedings of the IEEE/CVF conference on computer vision and pattern recognition*,
    2021, pp. 9532–9542.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] S. Reiß, C. Seibold, A. Freytag, E. Rodner, 和 R. Stiefelhagen, “每一个注释都重要：医学图像分割的多标签深度监督”，发表于*IEEE/CVF
    计算机视觉与模式识别会议*，2021年，第9532–9542页。'
- en: '[139] K. Zhang and X. Zhuang, “Cyclemix: A holistic strategy for medical image
    segmentation from scribble supervision,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, 2022, pp. 11 656–11 665.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] K. Zhang 和 X. Zhuang, “Cyclemix: 一种全方位的医学图像分割策略，基于涂鸦监督”，发表于*IEEE/CVF
    计算机视觉与模式识别会议*，2022年，第11 656–11 665页。'
- en: '[140] Z. Xu, D. Lu, Y. Wang, J. Luo, J. Jayender, K. Ma, Y. Zheng, and X. Li,
    “Noisy labels are treasure: mean-teacher-assisted confident learning for hepatic
    vessel segmentation,” in *International Conference on Medical Image Computing
    and Computer-Assisted Intervention*.   Springer, 2021, pp. 3–13.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] Z. Xu, D. Lu, Y. Wang, J. Luo, J. Jayender, K. Ma, Y. Zheng, 和 X. Li,
    “噪声标签是宝贵的：利用均值教师辅助的自信学习进行肝血管分割”，发表于*医学图像计算与计算机辅助干预国际会议*。 Springer，2021年，第3–13页。'
- en: '[141] Z. Xie, E. Tu, H. Zheng, Y. Gu, and J. Yang, “Semi-supervised skin lesion
    segmentation with learning model confidence,” in *ICASSP 2021-2021 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*.   IEEE, 2021,
    pp. 1135–1139.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Z. Xie, E. Tu, H. Zheng, Y. Gu, 和 J. Yang, “基于学习模型信心的半监督皮肤病变分割”，发表于*ICASSP
    2021-2021 IEEE 国际声学、语音和信号处理会议（ICASSP）*。 IEEE，2021年，第1135–1139页。'
- en: '[142] J. M. Johnson and T. M. Khoshgoftaar, “Survey on deep learning with class
    imbalance,” *Journal of Big Data*, vol. 6, no. 1, pp. 1–54, 2019.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] J. M. Johnson 和 T. M. Khoshgoftaar, “关于类不平衡的深度学习调查”，*大数据期刊*，第6卷，第1期，第1–54页，2019年。'
- en: '[143] S. Liu, Y. Li, X. Li, and G. Cao, “Shape-aware multi-task learning for
    semi-supervised 3d medical image segmentation,” in *2021 IEEE International Conference
    on Bioinformatics and Biomedicine (BIBM)*.   IEEE, 2021, pp. 1418–1423.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] S. Liu, Y. Li, X. Li, 和 G. Cao, “面向半监督3D医学图像分割的形状感知多任务学习”，发表于*2021 IEEE
    国际生物信息学与生物医学会议（BIBM）*。 IEEE，2021年，第1418–1423页。'
- en: '[144] J. Hou, X. Ding, and J. D. Deng, “Semi-supervised semantic segmentation
    of vessel images using leaking perturbations,” in *Proceedings of the IEEE/CVF
    Winter Conference on Applications of Computer Vision*, 2022, pp. 2625–2634.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] J. Hou, X. Ding, 和 J. D. Deng, “利用泄漏扰动进行半监督语义分割的血管图像”，发表于*IEEE/CVF 冬季计算机视觉应用会议*，2022年，第2625–2634页。'
- en: '[145] D.-H. Lee *et al.*, “Pseudo-label: The simple and efficient semi-supervised
    learning method for deep neural networks,” in *Workshop on challenges in representation
    learning, ICML*, vol. 3, no. 2, 2013, p. 896.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] D.-H. Lee *等*，“伪标签：深度神经网络的简单而高效的半监督学习方法”，发表于*ICML 表示学习挑战研讨会*，第3卷，第2期，2013年，第896页。'
- en: '[146] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, and
    C. A. Raffel, “Mixmatch: A holistic approach to semi-supervised learning,” *Advances
    in neural information processing systems*, vol. 32, 2019.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] D. Berthelot, N. Carlini, I. Goodfellow, N. Papernot, A. Oliver, 和 C.
    A. Raffel，“Mixmatch：一种整体的半监督学习方法”，*神经信息处理系统进展*，第32卷，2019年。'
- en: '[147] A. Blum and T. Mitchell, “Combining labeled and unlabeled data with co-training,”
    in *Proceedings of the eleventh annual conference on Computational learning theory*,
    1998, pp. 92–100.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] A. Blum 和 T. Mitchell，“结合标记和未标记数据的协同训练”，在*第十一届计算学习理论年会论文集*中，1998年，第92–100页。'
- en: '[148] Y. Xia, F. Liu, D. Yang, J. Cai, L. Yu, Z. Zhu, D. Xu, A. Yuille, and
    H. Roth, “3d semi-supervised learning with uncertainty-aware multi-view co-training,”
    in *Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
    Vision*, 2020, pp. 3646–3655.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Y. Xia, F. Liu, D. Yang, J. Cai, L. Yu, Z. Zhu, D. Xu, A. Yuille, 和 H.
    Roth，“具有不确定性感知多视角协同训练的3D半监督学习”，在*IEEE/CVF冬季计算机视觉应用会议论文集*中，2020年，第3646–3655页。'
- en: '[149] S. Qiao, W. Shen, Z. Zhang, B. Wang, and A. Yuille, “Deep co-training
    for semi-supervised image recognition,” in *Proceedings of the european conference
    on computer vision (eccv)*, 2018, pp. 135–152.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] S. Qiao, W. Shen, Z. Zhang, B. Wang, 和 A. Yuille，“用于半监督图像识别的深度协同训练”，在*欧洲计算机视觉会议（ECCV）论文集*中，2018年，第135–152页。'
- en: '[150] W. Dong-DongChen and Z.-H. WeiGao, “Tri-net for semi-supervised deep
    learning,” in *Proceedings of twenty-seventh international joint conference on
    artificial intelligence*, 2018, pp. 2014–2020.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] W. Dong-DongChen 和 Z.-H. WeiGao，“用于半监督深度学习的Tri-net”，在*第二十七届国际人工智能联合会议论文集*中，2018年，第2014–2020页。'
- en: '[151] J. Peng, G. Estrada, M. Pedersoli, and C. Desrosiers, “Deep co-training
    for semi-supervised image segmentation,” *Pattern Recognition*, vol. 107, p. 107269,
    2020.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] J. Peng, G. Estrada, M. Pedersoli, 和 C. Desrosiers，“用于半监督图像分割的深度协同训练”，*模式识别*，第107卷，第107269页，2020年。'
- en: '[152] Y. He, G. Yang, J. Yang, Y. Chen, Y. Kong, J. Wu, L. Tang, X. Zhu, J.-L.
    Dillenseger, P. Shao *et al.*, “Dense biased networks with deep priori anatomy
    and hard region adaptation: Semi-supervised learning for fine renal artery segmentation,”
    *Medical image analysis*, vol. 63, p. 101722, 2020.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] Y. He, G. Yang, J. Yang, Y. Chen, Y. Kong, J. Wu, L. Tang, X. Zhu, J.-L.
    Dillenseger, P. Shao *等*，“具有深层先验解剖和硬区域适应的稠密偏置网络：用于精细肾动脉分割的半监督学习”，*医学图像分析*，第63卷，第101722页，2020年。'
- en: '[153] H. Zheng, L. Lin, H. Hu, Q. Zhang, Q. Chen, Y. Iwamoto, X. Han, Y.-W.
    Chen, R. Tong, and J. Wu, “Semi-supervised segmentation of liver using adversarial
    learning with deep atlas prior,” in *International Conference on Medical Image
    Computing and Computer-Assisted Intervention*.   Springer, 2019, pp. 148–156.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] H. Zheng, L. Lin, H. Hu, Q. Zhang, Q. Chen, Y. Iwamoto, X. Han, Y.-W.
    Chen, R. Tong, 和 J. Wu，“使用对抗学习和深度图谱先验的肝脏半监督分割”，在*医学图像计算与计算机辅助干预国际会议*中。Springer，2019年，第148–156页。'
- en: '[154] Y. Grandvalet and Y. Bengio, “Semi-supervised learning by entropy minimization,”
    *Advances in neural information processing systems*, vol. 17, 2004.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] Y. Grandvalet 和 Y. Bengio，“通过熵最小化进行半监督学习”，*神经信息处理系统进展*，第17卷，2004年。'
- en: '[155] J. Wu, H. Fan, X. Zhang, S. Lin, and Z. Li, “Semi-supervised semantic
    segmentation via entropy minimization,” in *2021 IEEE International Conference
    on Multimedia and Expo (ICME)*.   IEEE, 2021, pp. 1–6.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] J. Wu, H. Fan, X. Zhang, S. Lin, 和 Z. Li，“通过熵最小化进行半监督语义分割”，在*2021 IEEE国际多媒体与博览会（ICME）*中。IEEE，2021年，第1–6页。'
- en: '[156] Y. Ouali, C. Hudelot, and M. Tami, “Semi-supervised semantic segmentation
    with cross-consistency training,” in *Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition*, 2020, pp. 12 674–12 684.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] Y. Ouali, C. Hudelot, 和 M. Tami，“通过交叉一致性训练进行半监督语义分割”，在*IEEE/CVF计算机视觉与模式识别会议论文集*中，2020年，第12,674–12,684页。'
- en: '[157] C. Dong, Y.-w. Chen, A. H. Foruzan, L. Lin, X.-h. Han, T. Tateyama, X. Wu,
    G. Xu, and H. Jiang, “Segmentation of liver and spleen based on computational
    anatomy models,” *Computers in biology and medicine*, vol. 67, pp. 146–160, 2015.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] C. Dong, Y.-w. Chen, A. H. Foruzan, L. Lin, X.-h. Han, T. Tateyama, X.
    Wu, G. Xu, 和 H. Jiang，“基于计算解剖模型的肝脏和脾脏分割”，*计算机生物学与医学*，第67卷，第146–160页，2015年。'
- en: '[158] H. Park, P. H. Bland, and C. R. Meyer, “Construction of an abdominal
    probabilistic atlas and its application in segmentation,” *IEEE Transactions on
    medical imaging*, vol. 22, no. 4, pp. 483–492, 2003.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] H. Park, P. H. Bland, 和 C. R. Meyer，“腹部概率图谱的构建及其在分割中的应用”，*IEEE医学成像交易*，第22卷，第4期，第483–492页，2003年。'
- en: '[159] M. Sajjadi, M. Javanmardi, and T. Tasdizen, “Mutual exclusivity loss
    for semi-supervised deep learning,” in *2016 IEEE International Conference on
    Image Processing (ICIP)*.   IEEE, 2016, pp. 1908–1912.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] M. Sajjadi, M. Javanmardi, 和 T. Tasdizen, “用于半监督深度学习的互斥损失，” 在 *2016 IEEE
    国际图像处理会议 (ICIP)*。IEEE, 2016, 页 1908–1912。'
- en: '[160] K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. A. Raffel,
    E. D. Cubuk, A. Kurakin, and C.-L. Li, “Fixmatch: Simplifying semi-supervised
    learning with consistency and confidence,” *Advances in neural information processing
    systems*, vol. 33, pp. 596–608, 2020.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. A. Raffel,
    E. D. Cubuk, A. Kurakin, 和 C.-L. Li, “Fixmatch：通过一致性和信心简化半监督学习，” *神经信息处理系统进展*,
    卷 33, 页 596–608, 2020。'
- en: '[161] A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, and I. Goodfellow, “Realistic
    evaluation of deep semi-supervised learning algorithms,” *Advances in neural information
    processing systems*, vol. 31, 2018.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] A. Oliver, A. Odena, C. A. Raffel, E. D. Cubuk, 和 I. Goodfellow, “深度半监督学习算法的现实评估，”
    *神经信息处理系统进展*, 卷 31, 2018。'
- en: '[162] T. Miyato, S.-i. Maeda, M. Koyama, and S. Ishii, “Virtual adversarial
    training: a regularization method for supervised and semi-supervised learning,”
    *IEEE transactions on pattern analysis and machine intelligence*, vol. 41, no. 8,
    pp. 1979–1993, 2018.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] T. Miyato, S.-i. Maeda, M. Koyama, 和 S. Ishii, “虚拟对抗训练：一种用于监督和半监督学习的正则化方法，”
    *IEEE 模式分析与机器智能汇刊*, 卷 41, 期 8, 页 1979–1993, 2018。'
- en: '[163] Y. Ouali, C. Hudelot, and M. Tami, “An overview of deep semi-supervised
    learning,” *ArXiv*, vol. abs/2006.05278, 2020.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] Y. Ouali, C. Hudelot, 和 M. Tami, “深度半监督学习概述，” *ArXiv*, 卷 abs/2006.05278,
    2020。'
- en: '[164] W. Luo, Y. Li, R. Urtasun, and R. S. Zemel, “Understanding the effective
    receptive field in deep convolutional neural networks,” in *NIPS*, 2016, p. 4905–4913.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] W. Luo, Y. Li, R. Urtasun, 和 R. S. Zemel, “理解深度卷积神经网络中的有效感受野，” 在 *NIPS*，2016,
    页 4905–4913。'
- en: '[165] M. Xu, N. P. Oxtoby, D. C. Alexander, and J. Jacob, “Learning to pay
    attention to mistakes,” *ArXiv*, vol. abs/2007.15131, 2020.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] M. Xu, N. P. Oxtoby, D. C. Alexander, 和 J. Jacob, “学会关注错误，” *ArXiv*,
    卷 abs/2007.15131, 2020。'
- en: '[166] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *Proceedings of the IEEE conference on computer vision and pattern
    recognition*, 2016, pp. 770–778.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] K. He, X. Zhang, S. Ren, 和 J. Sun, “用于图像识别的深度残差学习，” 在 *IEEE 计算机视觉与模式识别会议论文集*，2016,
    页 770–778。'
- en: '[167] A. Andreopoulos and J. K. Tsotsos, “Efficient and generalizable statistical
    models of shape and appearance for analysis of cardiac mri,” *Medical image analysis*,
    vol. 12, no. 3, pp. 335–357, 2008.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] A. Andreopoulos 和 J. K. Tsotsos, “用于心脏 MRI 分析的高效且可推广的形状和外观统计模型，” *医学图像分析*,
    卷 12, 期 3, 页 335–357, 2008。'
- en: '[168] R. Awan, K. Sirinukunwattana, D. Epstein, S. Jefferyes, U. Qidwai, Z. Aftab,
    I. Mujeeb, D. Snead, and N. Rajpoot, “Glandular morphometrics for objective grading
    of colorectal adenocarcinoma histology images,” *Scientific reports*, vol. 7,
    no. 1, pp. 1–12, 2017.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] R. Awan, K. Sirinukunwattana, D. Epstein, S. Jefferyes, U. Qidwai, Z.
    Aftab, I. Mujeeb, D. Snead, 和 N. Rajpoot, “用于客观评估结直肠腺癌组织图像的腺体形态测量学，” *Scientific
    reports*, 卷 7, 期 1, 页 1–12, 2017。'
- en: '[169] G. Wang, X. Liu, C. Li, Z. Xu, J. Ruan, H. Zhu, T. Meng, K. Li, N. Huang,
    and S. Zhang, “A noise-robust framework for automatic segmentation of covid-19
    pneumonia lesions from ct images,” *IEEE Transactions on Medical Imaging*, vol. 39,
    no. 8, pp. 2653–2663, 2020.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] G. Wang, X. Liu, C. Li, Z. Xu, J. Ruan, H. Zhu, T. Meng, K. Li, N. Huang,
    和 S. Zhang, “一个噪声鲁棒框架用于自动分割 COVID-19 肺炎病灶从 CT 图像，” *IEEE 医学影像学汇刊*, 卷 39, 期 8,
    页 2653–2663, 2020。'
- en: '[170] M. Jun, G. Cheng, W. Yixin, A. Xingle, G. Jiantao, Y. Ziqi, and H. Jian,
    “Covid-19 ct lung and infection segmentation dataset (version verson 1.0)[data
    set]. zenodo,” 2020.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] M. Jun, G. Cheng, W. Yixin, A. Xingle, G. Jiantao, Y. Ziqi, 和 H. Jian,
    “Covid-19 CT 肺部和感染分割数据集（版本 verson 1.0）[数据集]。zenodo，” 2020。'
- en: '[171] N. Kasthuri, K. J. Hayworth, D. R. Berger, R. L. Schalek, J. A. Conchello,
    S. Knowles-Barley, D. Lee, A. Vázquez-Reina, V. Kaynig, T. R. Jones *et al.*,
    “Saturated reconstruction of a volume of neocortex,” *Cell*, vol. 162, no. 3,
    pp. 648–661, 2015.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] N. Kasthuri, K. J. Hayworth, D. R. Berger, R. L. Schalek, J. A. Conchello,
    S. Knowles-Barley, D. Lee, A. Vázquez-Reina, V. Kaynig, T. R. Jones *等*，“新皮层体积的饱和重建，”
    *Cell*, 卷 162, 期 3, 页 648–661, 2015。'
- en: '[172] G. A. Sonn, S. Natarajan, D. J. Margolis, M. MacAiran, P. Lieu, J. Huang,
    F. J. Dorey, and L. S. Marks, “Targeted biopsy in the detection of prostate cancer
    using an office based magnetic resonance ultrasound fusion device,” *The Journal
    of urology*, vol. 189, no. 1, pp. 86–92, 2013.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] G. A. Sonn, S. Natarajan, D. J. Margolis, M. MacAiran, P. Lieu, J. Huang,
    F. J. Dorey, 和 L. S. Marks, “使用基于办公室的磁共振超声融合设备在前列腺癌检测中的靶向活检，” *泌尿学杂志*，第 189 卷，第
    1 期，页码 86–92，2013 年。'
- en: '[173] A. Carass, S. Roy, A. Jog, J. L. Cuzzocreo, E. Magrath, A. Gherman, J. Button,
    J. Nguyen, F. Prados, C. H. Sudre *et al.*, “Longitudinal multiple sclerosis lesion
    segmentation: resource and challenge,” *NeuroImage*, vol. 148, pp. 77–102, 2017.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] A. Carass, S. Roy, A. Jog, J. L. Cuzzocreo, E. Magrath, A. Gherman, J.
    Button, J. Nguyen, F. Prados, C. H. Sudre *等*，“纵向多发性硬化病灶分割：资源与挑战，” *神经影像*，第 148
    卷，页码 77–102，2017 年。'
- en: '[174] O. Maier, B. H. Menze, J. von der Gablentz, L. Häni, M. P. Heinrich,
    M. Liebrand, S. Winzeck, A. Basit, P. Bentley, L. Chen *et al.*, “Isles 2015-a
    public evaluation benchmark for ischemic stroke lesion segmentation from multispectral
    mri,” *Medical image analysis*, vol. 35, pp. 250–269, 2017.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] O. Maier, B. H. Menze, J. von der Gablentz, L. Häni, M. P. Heinrich,
    M. Liebrand, S. Winzeck, A. Basit, P. Bentley, L. Chen *等*，“ISLES 2015：一个用于从多光谱
    MRI 中分割缺血性中风病灶的公共评估基准，” *医学图像分析*，第 35 卷，页码 250–269，2017 年。'
- en: '[175] N. Heller, N. Sathianathen, A. Kalapara, E. Walczak, K. Moore, H. Kaluzniak,
    J. Rosenberg, P. Blake, Z. Rengel, M. Oestreich *et al.*, “The kits19 challenge
    data: 300 kidney tumor cases with clinical context, ct semantic segmentations,
    and surgical outcomes,” *arXiv preprint arXiv:1904.00445*, 2019.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] N. Heller, N. Sathianathen, A. Kalapara, E. Walczak, K. Moore, H. Kaluzniak,
    J. Rosenberg, P. Blake, Z. Rengel, M. Oestreich *等*，“KITS19 挑战数据：300 例肾脏肿瘤病例，包括临床背景、CT
    语义分割和手术结果，” *arXiv 预印本 arXiv:1904.00445*，2019 年。'
- en: '[176] R. Karim, R. J. Housden, M. Balasubramaniam, Z. Chen, D. Perry, A. Uddin,
    Y. Al-Beyatti, E. Palkhi, P. Acheampong, S. Obom *et al.*, “Evaluation of current
    algorithms for segmentation of scar tissue from late gadolinium enhancement cardiovascular
    magnetic resonance of the left atrium: an open-access grand challenge,” *Journal
    of Cardiovascular Magnetic Resonance*, vol. 15, no. 1, pp. 1–17, 2013.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] R. Karim, R. J. Housden, M. Balasubramaniam, Z. Chen, D. Perry, A. Uddin,
    Y. Al-Beyatti, E. Palkhi, P. Acheampong, S. Obom *等*，“评估当前算法在晚期钆增强心血管磁共振成像中左心房瘢痕组织分割的表现：一个开放获取的大挑战，”
    *心血管磁共振杂志*，第 15 卷，第 1 期，页码 1–17，2013 年。'
- en: '[177] L. Li, V. A. Zimmer, J. A. Schnabel, and X. Zhuang, “Atrialgeneral: Domain
    generalization for left atrial segmentation of multi-center lge mris,” in *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2021, pp. 557–566.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] L. Li, V. A. Zimmer, J. A. Schnabel, 和 X. Zhuang, “Atrialgeneral: 用于多中心
    LGE MRI 左心房分割的领域泛化，” 在 *国际医学图像计算与计算机辅助干预会议*。Springer, 2021, 页码 557–566。'
- en: '[178] X. Zhuang and J. Shen, “Multi-scale patch and multi-modality atlases
    for whole heart segmentation of mri,” *Medical image analysis*, vol. 31, pp. 77–87,
    2016.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] X. Zhuang 和 J. Shen, “用于 MRI 的多尺度补丁和多模态图谱的全心脏分割，” *医学图像分析*，第 31 卷，页码
    77–87，2016 年。'
- en: '[179] X. Zhuang, “Challenges and methodologies of fully automatic whole heart
    segmentation: a review,” *Journal of healthcare engineering*, vol. 4, no. 3, pp.
    371–407, 2013.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] X. Zhuang, “完全自动化全心脏分割的挑战与方法论：综述，” *医疗工程杂志*，第 4 卷，第 3 期，页码 371–407，2013
    年。'
- en: '[180] X. Zhuang, W. Bai, J. Song, S. Zhan, X. Qian, W. Shi, Y. Lian, and D. Rueckert,
    “Multiatlas whole heart segmentation of ct data using conditional entropy for
    atlas ranking and selection,” *Medical physics*, vol. 42, no. 7, pp. 3822–3833,
    2015.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] X. Zhuang, W. Bai, J. Song, S. Zhan, X. Qian, W. Shi, Y. Lian, 和 D. Rueckert,
    “使用条件熵进行图谱排名和选择的多图谱全心脏分割，” *医学物理学*，第 42 卷，第 7 期，页码 3822–3833，2015 年。'
- en: '[181] X. Zhuang, K. S. Rhode, R. S. Razavi, D. J. Hawkes, and S. Ourselin,
    “A registration-based propagation framework for automatic whole heart segmentation
    of cardiac mri,” *IEEE transactions on medical imaging*, vol. 29, no. 9, pp. 1612–1625,
    2010.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] X. Zhuang, K. S. Rhode, R. S. Razavi, D. J. Hawkes, 和 S. Ourselin, “基于配准的自动全心脏分割框架，”
    *IEEE 医学影像学汇刊*，第 29 卷，第 9 期，页码 1612–1625，2010 年。'
- en: '[182] G. Litjens, R. Toth, W. van de Ven, C. Hoeks, S. Kerkstra, B. van Ginneken,
    G. Vincent, G. Guillard, N. Birbeck, J. Zhang *et al.*, “Evaluation of prostate
    segmentation algorithms for mri: the promise12 challenge,” *Medical image analysis*,
    vol. 18, no. 2, pp. 359–373, 2014.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] G. Litjens, R. Toth, W. van de Ven, C. Hoeks, S. Kerkstra, B. van Ginneken,
    G. Vincent, G. Guillard, N. Birbeck, J. Zhang *等*，“MRI 前列腺分割算法评估：PROMISE12 挑战，”
    *医学图像分析*，第 18 卷，第 2 期，页码 359–373，2014 年。'
- en: '[183] A. E. Kavur, N. S. Gezer, M. Barış, S. Aslan, P.-H. Conze, V. Groza,
    D. D. Pham, S. Chatterjee, P. Ernst, S. Özkan *et al.*, “Chaos challenge-combined
    (ct-mr) healthy abdominal organ segmentation,” *Medical Image Analysis*, vol. 69,
    p. 101950, 2021.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] A. E. Kavur, N. S. Gezer, M. Barış, S. Aslan, P.-H. Conze, V. Groza,
    D. D. Pham, S. Chatterjee, P. Ernst, S. Özkan *等*，“混合（CT-MR）健康腹部器官分割挑战，” *医学图像分析*，第
    69 卷，页码 101950，2021 年。'
- en: '[184] F. Prados, J. Ashburner, C. Blaiotta, T. Brosch, J. Carballido-Gamio,
    M. J. Cardoso, B. N. Conrad, E. Datta, G. Dávid, B. De Leener *et al.*, “Spinal
    cord grey matter segmentation challenge,” *Neuroimage*, vol. 152, pp. 312–329,
    2017.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] F. Prados, J. Ashburner, C. Blaiotta, T. Brosch, J. Carballido-Gamio,
    M. J. Cardoso, B. N. Conrad, E. Datta, G. Dávid, B. De Leener *等*，“脊髓灰质分割挑战，”
    *神经影像*，第 152 卷，页码 312–329，2017 年。'
- en: '[185] A. L. Simpson, M. Antonelli, S. Bakas, M. Bilello, K. Farahani, B. Van Ginneken,
    A. Kopp-Schneider, B. A. Landman, G. Litjens, B. Menze *et al.*, “A large annotated
    medical image dataset for the development and evaluation of segmentation algorithms,”
    *arXiv preprint arXiv:1902.09063*, 2019.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] A. L. Simpson, M. Antonelli, S. Bakas, M. Bilello, K. Farahani, B. Van
    Ginneken, A. Kopp-Schneider, B. A. Landman, G. Litjens, B. Menze *等*，“一个大型标注医学图像数据集，用于分割算法的开发和评估，”
    *arXiv 预印本 arXiv:1902.09063*，2019 年。'
- en: '[186] B. Landman, Z. Xu, J. Igelsias, M. Styner, T. Langerak, and A. Klein,
    “Multi-atlas labeling beyond the cranial vault,” *URL: https://www. synapse. org*,
    2015.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] B. Landman, Z. Xu, J. Igelsias, M. Styner, T. Langerak, 和 A. Klein，“超出颅骨的多
    atlas 标注，” *网址: https://www.synapse.org*，2015 年。'
- en: '[187] ——, “Miccai multi-atlas labeling beyond the cranial vault–workshop and
    challenge,” in *Proc. MICCAI Multi-Atlas Labeling Beyond Cranial Vault—Workshop
    Challenge*, vol. 5, 2015, p. 12.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] ——，“Miccai 多 atlas 标注超出颅骨–研讨会和挑战，” 在 *Proc. MICCAI 多 Atlas 标注超出颅骨—研讨会挑战*，第
    5 卷，2015 年，第 12 页。'
- en: '[188] J. Bernal, F. J. Sánchez, G. Fernández-Esparrach, D. Gil, C. Rodríguez,
    and F. Vilariño, “Wm-dova maps for accurate polyp highlighting in colonoscopy:
    Validation vs. saliency maps from physicians,” *Computerized medical imaging and
    graphics*, vol. 43, pp. 99–111, 2015.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] J. Bernal, F. J. Sánchez, G. Fernández-Esparrach, D. Gil, C. Rodríguez,
    和 F. Vilariño，“用于准确突出结肠镜中息肉的 wm-dova 地图：与医生的显著性地图的验证，” *计算机医学影像与图形*，第 43 卷，页码
    99–111，2015 年。'
- en: '[189] K. Sirinukunwattana, J. P. Pluim, H. Chen, X. Qi, P.-A. Heng, Y. B. Guo,
    L. Y. Wang, B. J. Matuszewski, E. Bruni, U. Sanchez *et al.*, “Gland segmentation
    in colon histology images: The glas challenge contest,” *Medical image analysis*,
    vol. 35, pp. 489–502, 2017.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] K. Sirinukunwattana, J. P. Pluim, H. Chen, X. Qi, P.-A. Heng, Y. B. Guo,
    L. Y. Wang, B. J. Matuszewski, E. Bruni, U. Sanchez *等*，“结肠组织学图像中的腺体分割：GLAS 挑战比赛，”
    *医学图像分析*，第 35 卷，页码 489–502，2017 年。'
- en: '[190] J. Staal, M. D. Abràmoff, M. Niemeijer, M. A. Viergever, and B. Van Ginneken,
    “Ridge-based vessel segmentation in color images of the retina,” *IEEE transactions
    on medical imaging*, vol. 23, no. 4, pp. 501–509, 2004.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] J. Staal, M. D. Abràmoff, M. Niemeijer, M. A. Viergever, 和 B. Van Ginneken，“基于脊的血管分割在视网膜彩色图像中，”
    *IEEE 医学影像交易*，第 23 卷，第 4 期，页码 501–509，2004 年。'
- en: '[191] A. Hoover, V. Kouznetsova, and M. Goldbaum, “Locating blood vessels in
    retinal images by piecewise threshold probing of a matched filter response,” *IEEE
    Transactions on Medical imaging*, vol. 19, no. 3, pp. 203–210, 2000.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] A. Hoover, V. Kouznetsova, 和 M. Goldbaum，“通过逐段阈值探测匹配滤波响应定位视网膜图像中的血管，”
    *IEEE 医学影像交易*，第 19 卷，第 3 期，页码 203–210，2000 年。'
- en: '[192] M. M. Fraz, P. Remagnino, A. Hoppe, B. Uyyanonvara, A. R. Rudnicka, C. G.
    Owen, and S. A. Barman, “An ensemble classification-based approach applied to
    retinal blood vessel segmentation,” *IEEE Transactions on Biomedical Engineering*,
    vol. 59, no. 9, pp. 2538–2548, 2012.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] M. M. Fraz, P. Remagnino, A. Hoppe, B. Uyyanonvara, A. R. Rudnicka, C.
    G. Owen, 和 S. A. Barman，“应用于视网膜血管分割的集合分类方法，” *IEEE 生物医学工程交易*，第 59 卷，第 9 期，页码 2538–2548，2012
    年。'
- en: '[193] P. F. Raudaschl, P. Zaffino, G. C. Sharp, M. F. Spadea, A. Chen, B. M.
    Dawant, T. Albrecht, T. Gass, C. Langguth, M. Lüthi *et al.*, “Evaluation of segmentation
    methods on head and neck ct: auto-segmentation challenge 2015,” *Medical physics*,
    vol. 44, no. 5, pp. 2020–2036, 2017.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[193] P. F. Raudaschl, P. Zaffino, G. C. Sharp, M. F. Spadea, A. Chen, B. M.
    Dawant, T. Albrecht, T. Gass, C. Langguth, M. Lüthi *等*，“头部和颈部 CT 切割方法的评估：自动分割挑战
    2015，” *医学物理*，第 44 卷，第 5 期，页码 2020–2036，2017 年。'
- en: '[194] J. C. Caicedo, A. Goodman, K. W. Karhohs, B. A. Cimini, J. Ackerman,
    M. Haghighi, C. Heng, T. Becker, M. Doan, C. McQuin *et al.*, “Nucleus segmentation
    across imaging experiments: the 2018 data science bowl,” *Nature methods*, vol. 16,
    no. 12, pp. 1247–1253, 2019.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[194] J. C. Caicedo, A. Goodman, K. W. Karhohs, B. A. Cimini, J. Ackerman,
    M. Haghighi, C. Heng, T. Becker, M. Doan, C. McQuin *等*，“跨成像实验的细胞核分割：2018 数据科学杯，”
    *自然方法*，第 16 卷，第 12 期，页码 1247–1253，2019 年。'
- en: '[195] N. Kumar, R. Verma, D. Anand, Y. Zhou, O. F. Onder, E. Tsougenis, H. Chen,
    P.-A. Heng, J. Li, Z. Hu *et al.*, “A multi-organ nucleus segmentation challenge,”
    *IEEE transactions on medical imaging*, vol. 39, no. 5, pp. 1380–1391, 2019.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[195] N. Kumar, R. Verma, D. Anand, Y. Zhou, O. F. Onder, E. Tsougenis, H.
    Chen, P.-A. Heng, J. Li, Z. Hu *等*，“一个多脏器细胞核分割挑战，” *IEEE 医学成像学报*，第39卷，第5期，第1380–1391页，2019年。'
- en: '[196] D. Jha, P. H. Smedsrud, M. A. Riegler, P. Halvorsen, T. d. Lange, D. Johansen,
    and H. D. Johansen, “Kvasir-seg: A segmented polyp dataset,” in *International
    Conference on Multimedia Modeling*.   Springer, 2020, pp. 451–462.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[196] D. Jha, P. H. Smedsrud, M. A. Riegler, P. Halvorsen, T. d. Lange, D.
    Johansen, 和 H. D. Johansen, “Kvasir-seg: 一个分割的息肉数据集，” 见于 *国际多媒体建模会议*，Springer，2020年，第451–462页。'
- en: '[197] D. Gutman, N. C. Codella, E. Celebi, B. Helba, M. Marchetti, N. Mishra,
    and A. Halpern, “Skin lesion analysis toward melanoma detection: A challenge at
    the international symposium on biomedical imaging (isbi) 2016, hosted by the international
    skin imaging collaboration (isic),” *arXiv preprint arXiv:1605.01397*, 2016.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[197] D. Gutman, N. C. Codella, E. Celebi, B. Helba, M. Marchetti, N. Mishra,
    和 A. Halpern, “皮肤病变分析以检测黑色素瘤：国际生物医学成像研讨会 (ISBI) 2016 挑战，由国际皮肤成像协作组织 (ISIC) 主办，”
    *arXiv 预印本 arXiv:1605.01397*，2016年。'
- en: '[198] Y. Zhou, Z. Li, S. Bai, C. Wang, X. Chen, M. Han, E. Fishman, and A. L.
    Yuille, “Prior-aware neural network for partially-supervised multi-organ segmentation,”
    in *Proceedings of the IEEE/CVF international conference on computer vision*,
    2019, pp. 10 672–10 681.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[198] Y. Zhou, Z. Li, S. Bai, C. Wang, X. Chen, M. Han, E. Fishman, 和 A. L.
    Yuille, “用于部分监督多脏器分割的先验感知神经网络，” 见于 *IEEE/CVF 国际计算机视觉会议论文集*，2019年，第10,672–10,681页。'
- en: '[199] C. You, W. Dai, Y. Min, F. Liu, X. Zhang, C. Feng, D. A. Clifton, S. K.
    Zhou, L. H. Staib, and J. S. Duncan, “Rethinking semi-supervised medical image
    segmentation: A variance-reduction perspective,” *arXiv preprint arXiv:2302.01735*,
    2023.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[199] C. You, W. Dai, Y. Min, F. Liu, X. Zhang, C. Feng, D. A. Clifton, S.
    K. Zhou, L. H. Staib, 和 J. S. Duncan, “重新思考半监督医学图像分割：一种方差减少的视角，” *arXiv 预印本 arXiv:2302.01735*，2023年。'
- en: '[200] J. Qiu, L. Li, S. Wang, K. Zhang, Y. Chen, S. Yang, and X. Zhuang, “Myops-net:
    Myocardial pathology segmentation with flexible combination of multi-sequence
    cmr images,” *Medical Image Analysis*, vol. 84, p. 102694, 2023.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[200] J. Qiu, L. Li, S. Wang, K. Zhang, Y. Chen, S. Yang, 和 X. Zhuang, “Myops-net:
    使用多序列 CMR 图像的灵活组合进行心肌病理分割，” *医学图像分析*，第84卷，第102694页，2023年。'
- en: '[201] Y. Zhang and R. Jiao, “How segment anything model (sam) boost medical
    image segmentation?” *arXiv preprint arXiv:2305.03678*, 2023.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[201] Y. Zhang 和 R. Jiao, “如何利用 segment anything model (sam) 提升医学图像分割？” *arXiv
    预印本 arXiv:2305.03678*，2023年。'
- en: '[202] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T. Xiao,
    S. Whitehead, A. C. Berg, W.-Y. Lo *et al.*, “Segment anything,” *arXiv preprint
    arXiv:2304.02643*, 2023.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[202] A. Kirillov, E. Mintun, N. Ravi, H. Mao, C. Rolland, L. Gustafson, T.
    Xiao, S. Whitehead, A. C. Berg, W.-Y. Lo *等*，“Segment anything，” *arXiv 预印本 arXiv:2304.02643*，2023年。'
- en: '[203] P.-T. Jiang and Y. Yang, “Segment anything is a good pseudo-label generator
    for weakly supervised semantic segmentation,” *arXiv preprint arXiv:2305.01275*,
    2023.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[203] P.-T. Jiang 和 Y. Yang, “Segment anything 是一种良好的伪标签生成器，用于弱监督语义分割，” *arXiv
    预印本 arXiv:2305.01275*，2023年。'
- en: '[204] O. Chapelle, B. Schölkopf, and A. Zien, *Introduction to Semi-Supervised
    Learning*, 2006, pp. 1–12.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[204] O. Chapelle, B. Schölkopf, 和 A. Zien, *半监督学习导论*，2006年，第1–12页。'
- en: '[205] X. Yang, Z. Song, I. King, and Z. Xu, “A survey on deep semi-supervised
    learning,” *IEEE Transactions on Knowledge and Data Engineering*, 2022.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[205] X. Yang, Z. Song, I. King, 和 Z. Xu, “深度半监督学习综述，” *IEEE 知识与数据工程学报*，2022年。'
- en: '[206] L. Yang, L. Qi, L. Feng, W. Zhang, and Y. Shi, “Revisiting weak-to-strong
    consistency in semi-supervised semantic segmentation,” in *Proceedings of the
    IEEE/CVF Conference on Computer Vision and Pattern Recognition*, 2023, pp. 7236–7246.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[206] L. Yang, L. Qi, L. Feng, W. Zhang, 和 Y. Shi, “重新审视半监督语义分割中的弱到强一致性，” 见于
    *IEEE/CVF 计算机视觉与模式识别会议论文集*，2023年，第7236–7246页。'
- en: '[207] K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. A. Raffel,
    E. D. Cubuk, A. Kurakin, and C.-L. Li, “Fixmatch: Simplifying semi-supervised
    learning with consistency and confidence,” in *Advances in Neural Information
    Processing Systems*, H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, and H. Lin,
    Eds., vol. 33.   Curran Associates, Inc., 2020, pp. 596–608\. [Online]. Available:
    [https://proceedings.neurips.cc/paper_files/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf)'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[207] K. Sohn, D. Berthelot, N. Carlini, Z. Zhang, H. Zhang, C. A. Raffel,
    E. D. Cubuk, A. Kurakin, 和 C.-L. Li，“Fixmatch：通过一致性和信心简化半监督学习，” 见 *Advances in
    Neural Information Processing Systems*，H. Larochelle, M. Ranzato, R. Hadsell,
    M. Balcan, 和 H. Lin 编，第33卷。Curran Associates, Inc., 2020，第596–608页。[在线]。可用：[https://proceedings.neurips.cc/paper_files/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2020/file/06964dce9addb1c5cb5d6e3d9838f733-Paper.pdf)'
- en: '[208] J. Kim, Y. Min, D. Kim, G. Lee, J. Seo, K. Ryoo, and S. Kim, “Conmatch:
    Semi-supervised learning with confidence-guided consistency regularization,” in
    *Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October
    23–27, 2022, Proceedings, Part XXX*.   Springer, 2022, pp. 674–690.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[208] J. Kim, Y. Min, D. Kim, G. Lee, J. Seo, K. Ryoo, 和 S. Kim，“Conmatch：带有信心引导一致性正则化的半监督学习，”
    见 *Computer Vision–ECCV 2022: 17th European Conference, Tel Aviv, Israel, October
    23–27, 2022, Proceedings, Part XXX*。Springer, 2022，第674–690页。'
- en: '[209] N. Li, L. Xiong, W. Qiu, Y. Pan, Y. Luo, and Y. Zhang, “Segment anything
    model for semi-supervised medical image segmentation via selecting reliable pseudo-labels,”
    *Available at SSRN 4477443*, 2023.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[209] N. Li, L. Xiong, W. Qiu, Y. Pan, Y. Luo, 和 Y. Zhang，“通过选择可靠伪标签进行半监督医学图像分割的分割任何模型，”
    *Available at SSRN 4477443*，2023年。'
- en: '[210] H. Peiris, M. Hayat, Z. Chen, G. Egan, and M. Harandi, “Uncertainty-guided
    dual-views for semi-supervised volumetric medical image segmentation,” *Nature
    Machine Intelligence*, Jul 2023.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[210] H. Peiris, M. Hayat, Z. Chen, G. Egan, 和 M. Harandi，“不确定性引导的双视图用于半监督体积医学图像分割，”
    *Nature Machine Intelligence*，2023年7月。'
- en: '[211] J. Schlemper, O. Oktay, M. Schaap, M. Heinrich, B. Kainz, B. Glocker,
    and D. Rueckert, “Attention gated networks: Learning to leverage salient regions
    in medical images,” *Medical image analysis*, vol. 53, pp. 197–207, 2019.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[211] J. Schlemper, O. Oktay, M. Schaap, M. Heinrich, B. Kainz, B. Glocker,
    和 D. Rueckert，“注意力门控网络：学习利用医学图像中的显著区域，” *Medical image analysis*，第53卷，第197–207页，2019年。'
- en: '[212] Y. Lin, H. Yao, Z. Li, G. Zheng, and X. Li, “Calibrating label distribution
    for class-imbalanced barely-supervised knee segmentation,” in *Medical Image Computing
    and Computer Assisted Intervention – MICCAI 2022*, L. Wang, Q. Dou, P. T. Fletcher,
    S. Speidel, and S. Li, Eds.   Cham: Springer Nature Switzerland, 2022, pp. 109–118.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[212] Y. Lin, H. Yao, Z. Li, G. Zheng, 和 X. Li，“为类别不平衡的几乎监督膝关节分割校准标签分布，” 见
    *Medical Image Computing and Computer Assisted Intervention – MICCAI 2022*，L.
    Wang, Q. Dou, P. T. Fletcher, S. Speidel, 和 S. Li 编，Cham: Springer Nature Switzerland,
    2022，第109–118页。'
- en: '[213] L.-L. Zeng, K. Gao, D. Hu, Z. Feng, C. Hou, P. Rong, and W. Wang, “Ss-tbn:
    A semi-supervised tri-branch network for covid-19 screening and lesion segmentation,”
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*, 2023.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[213] L.-L. Zeng, K. Gao, D. Hu, Z. Feng, C. Hou, P. Rong, 和 W. Wang，“Ss-tbn：一种用于COVID-19筛查和病灶分割的半监督三分支网络，”
    *IEEE Transactions on Pattern Analysis and Machine Intelligence*，2023年。'
- en: '[214] A. Lou, K. Tawfik, X. Yao, Z. Liu, and J. Noble, “Min-max similarity:
    A contrastive semi-supervised deep learning network for surgical tools segmentation,”
    *IEEE Transactions on Medical Imaging*, 2023.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[214] A. Lou, K. Tawfik, X. Yao, Z. Liu, 和 J. Noble，“最小-最大相似度：一种用于手术工具分割的对比半监督深度学习网络，”
    *IEEE Transactions on Medical Imaging*，2023年。'
- en: '[215] P. Wang, J. Peng, M. Pedersoli, Y. Zhou, C. Zhang, and C. Desrosiers,
    “Cat: Constrained adversarial training for anatomically-plausible semi-supervised
    segmentation,” *IEEE Transactions on Medical Imaging*, 2023.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[215] P. Wang, J. Peng, M. Pedersoli, Y. Zhou, C. Zhang, 和 C. Desrosiers，“Cat：用于解剖学上合理的半监督分割的约束对抗训练，”
    *IEEE Transactions on Medical Imaging*，2023年。'
- en: '[216] H. Wang and X. Li, “Dhc: Dual-debiased heterogeneous co-training framework
    for class-imbalanced semi-supervised medical image segmentation,” in *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*.   Springer,
    2023, pp. 582–591.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[216] H. Wang 和 X. Li，“Dhc：用于类别不平衡的半监督医学图像分割的双重去偏异质共同训练框架，” 见 *International
    Conference on Medical Image Computing and Computer-Assisted Intervention*。Springer,
    2023，第582–591页。'
- en: '[217] D. Chen, Y. Bai, W. Shen, Q. Li, L. Yu, and Y. Wang, “Magicnet: Semi-supervised
    multi-organ segmentation via magic-cube partition and recovery,” in *2023 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition (CVPR)*, 2023, pp. 23 869–23 878.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[217] D. 陈, Y. 白, W. 沈, Q. 李, L. 余, 和 Y. 王, “Magicnet: 通过 magic-cube 分割和恢复的半监督多脏器分割,”
    发表在*2023 IEEE/CVF 计算机视觉与模式识别会议 (CVPR)*, 2023, 页码 23 869–23 878。'
- en: '[218] Y. Shi, Y. Zhang, and S. Wang, “Competitive ensembling teacher-student
    framework for semi-supervised left atrium mri segmentation,” *arXiv preprint arXiv:2310.13955*,
    2023.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[218] Y. Shi, Y. Zhang, 和 S. Wang, “竞争性集成教师-学生框架用于半监督左心房 MRI 分割,” *arXiv 预印本
    arXiv:2310.13955*, 2023。'
- en: '[219] J. R. Clough, N. Byrne, I. Oksuz, V. A. Zimmer, J. A. Schnabel, and A. P.
    King, “A topological loss function for deep-learning based image segmentation
    using persistent homology,” *IEEE transactions on pattern analysis and machine
    intelligence*, vol. 44, no. 12, pp. 8766–8778, 2020.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[219] J. R. Clough, N. Byrne, I. Oksuz, V. A. Zimmer, J. A. Schnabel, 和 A.
    P. King, “一种用于深度学习图像分割的拓扑损失函数，利用持久同源性,” *IEEE 模式分析与机器智能学报*, 卷 44, 第 12 期, 页码 8766–8778,
    2020。'
- en: '[220] P.-A. Ganaye, M. Sdika, B. Triggs, and H. Benoit-Cattin, “Removing segmentation
    inconsistencies with semi-supervised non-adjacency constraint,” *Medical image
    analysis*, vol. 58, p. 101551, 2019.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[220] P.-A. Ganaye, M. Sdika, B. Triggs, 和 H. Benoit-Cattin, “通过半监督非邻接约束去除分割不一致性,”
    *医学图像分析*, 卷 58, 页码 101551, 2019。'
