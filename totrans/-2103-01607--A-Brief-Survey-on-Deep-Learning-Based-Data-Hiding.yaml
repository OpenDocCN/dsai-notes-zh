- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:56:36'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2103.01607] A Brief Survey on Deep Learning Based Data Hiding'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2103.01607](https://ar5iv.labs.arxiv.org/html/2103.01607)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Brief Survey on Deep Learning Based Data Hiding
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Chaoning Zhang^(1∗)    Chenguo Lin²¹¹1Equal Contribution    Philipp Benz¹   
    Kejiang Chen³    Weiming Zhang³&In So Kweon¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹KAIST    ²Sichuan University    ³University of Science and Technology of China
  prefs: []
  type: TYPE_NORMAL
- en: chaoningzhang1990@gmail.com, linchenguo@stu.scu.edu.cn, pbenz@kaist.ac.kr, chenkj@mail.ustc.edu.cn,
    zhangwm@ustc.edu.cn, iskweon77@kaist.ac.kr
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Data hiding is the art of concealing messages with limited perceptual changes.
    Recently, deep learning has enriched it from various perspectives with significant
    progress. In this work, we conduct a brief yet comprehensive review of existing
    literature for deep learning based data hiding (deep hiding) by first classifying
    it according to three essential properties (i.e., capacity, security and robustness),
    and outline three commonly used architectures. Based on this, we summarize specific
    strategies for different applications of data hiding, including basic hiding,
    steganography, watermarking and light field messaging. Finally, further insight
    into deep hiding is provided by incorporating the perspective of adversarial attack.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Seeing is *not* always believing, i.e., a natural-looking image can contain
    secret information that is invisible to the general public. Data hiding enables
    concealing a secret message within a transport medium, such as a digital image,
    and its essential property lies in *imperceptibility* for achieving the fundamental
    goal of being hidden. With easy access to the Internet and gaining popularity
    of the social media platform, digital media, such as image or video, has become
    the most commonly used host for secure data transfer in applications ranging from
    secret communication to copy-right protection. Data hiding schemes can be characterized
    by three requirements: i) *capacity*, regarding the embedded payload; ii) *security*,
    in terms of being undetectable by steganalysis; iii) *robustness*, against distortions
    in the transmission channel. There is a trade-off among the above three requirements Kadhim
    et al. ([2019](#bib.bib18)); Zhang et al. ([2020a](#bib.bib52)), as depicted in
    Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ A Brief Survey on Deep Learning
    Based Data Hiding"). For example, a large-capacity hiding algorithm is often subject
    to low security and weak robustness. We term the capacity-oriented task as “basic
    data hiding”, which aims to hide more information given no extra constraint (except
    imperceptibility) is applied. Secure data hiding and robust data hiding, as the
    term suggests, prioritize security and robustness, respectively. However, their
    shared constraint still lies in being imperceptible for the human eyes.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/41ee2001eb459f4fa4b839d87a0967fb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Trade-off among capacity, security and robustness for information
    hiding techniques.'
  prefs: []
  type: TYPE_NORMAL
- en: Most traditional data hiding methods are carried out under a distortion-coding
    framework, which aims to minimize a particular distortion metric and allocate
    different distortions to different elements in the information carrier to embed
    hidden messages Pevnỳ et al. ([2010](#bib.bib27)); Holub and Fridrich ([2012](#bib.bib11));
    Holub et al. ([2014](#bib.bib12)). With the increasing popularity of deep learning
    in recent years, numerous works apply deep neural networks (DNNs) to the task
    of data hiding. Early researches of applying deep learning into data hiding often
    adopt DNNs to substitute only a *partial* stage in the hiding-and-extraction pipeline Husien
    and Badi ([2015](#bib.bib15)); Kandi et al. ([2017](#bib.bib19)); Mun et al. ([2017](#bib.bib26)).
    The trend is to train networks end-to-end for embedding as well as revealing information Baluja
    ([2017](#bib.bib3)); Zhu et al. ([2018](#bib.bib56)); Weng et al. ([2019](#bib.bib37));
    Zhang et al. ([2020a](#bib.bib52)); Lu et al. ([2021](#bib.bib23)); Guan et al.
    ([2022](#bib.bib9)), as most of them are less cumbersome and outperform former
    methods in capacity, security and/or robustness by a large margin. In this work,
    we term deep learning based data hiding methods as *deep hiding*. It is an emerging
    and vibrant research area and has achieved significant progress, but there are
    relatively few systematic introductions on this field. We believe that it is necessary
    and valuable to conduct a brief yet comprehensive literature review about deep
    hiding.
  prefs: []
  type: TYPE_NORMAL
- en: In the remainder of this survey, we first present the formulation of deep hiding,
    followed by introducing the three basic architectures for the hiding-and-extraction
    pipeline. With the focus of adopting images as the carrier for information transfer,
    we conduct a complete survey on its applications, including i) large-capacity
    basic hiding, ii) secure steganography, iii) robust watermarking and iv) light
    field messaging, which place emphasis on different properties of data hiding.
    We further present a brief review on hiding a secret message within other multimedia
    beyond images. Finally, we discuss the link between deep hiding and another parallel
    line of research in the adversarial attack.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0852521d3dbb6c198c4077443f40326f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Schematic diagram for three basic architectures in the form of hiding
    images within images, where P, H and R represent preparation, hiding and reveal
    network respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Problem Formulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The *basic data hiding* considers a scenario of communication between two agents:
    Alice and Bob, where Alice is the sender and Bob is the recipient. Alice is responsible
    for concealing secret information (*secret*, $S$) within transport carrier (*cover*,
    $C$) and the result is a *container* ($C^{\prime}$) which is encoded to contain
    secret. Bob receives $C^{\prime}$ after a communication with Alice, and then the
    *revealed secret* ($S^{\prime}$) can be retrieved. These operations are described
    in Equation [1](#S2.E1 "In 2 Problem Formulation ‣ A Brief Survey on Deep Learning
    Based Data Hiding"), where $\mathcal{H}$ and $\mathcal{R}$ are the hiding and
    reveal neural network in deep hiding, with $\theta_{\mathcal{H}}$ and $\theta_{\mathcal{R}}$
    as their respective parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $C^{\prime}=\mathcal{H}(S,C;\theta_{\mathcal{H}});\quad S^{\prime}=\mathcal{R}(C^{\prime};\theta_{\mathcal{R}})$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: 'A key requirement of successful data hiding is *imperceptibility* for hiding
    and *precision* for revealing, i.e., simultaneously minimizing the differences
    between $C$ and $C^{\prime}$ and that between $S$ and $S^{\prime}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\theta_{\mathcal{H}}^{*}$ | $\displaystyle=\mathop{\arg\min_{\theta_{\mathcal{H}}}}\
    dist_{c}(C,C^{\prime})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\mathop{\arg\min_{\theta_{\mathcal{H}}}}\ dist_{c}(C,\mathcal{H}(S,C;\theta_{\mathcal{H}})),$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\theta_{\mathcal{R}}^{*}$ | $\displaystyle=\mathop{\arg\min_{\theta_{\mathcal{R}}}}\
    dist_{s}(S,S^{\prime})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\mathop{\arg\min_{\theta_{\mathcal{R}}}}\ dist_{s}(S,\mathcal{R}(C^{\prime};\theta_{\mathcal{R}})),$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $dist_{c}(\cdot)$ and $dist_{s}(\cdot)$ are the metrics of distances between
    two distributions. L2 distance is the most widely used one and cross-entropy loss
    is widely used as $dist_{s}(\cdot)$ when $S$ is in the form of binary bits. One
    commonly used loss for optimization is defined as $\mathcal{L}=\|C^{\prime}-C\|+\beta\|S^{\prime}-S\|$ Baluja
    ([2017](#bib.bib3)), where $\beta$ is a weight factor for balancing imperceptibility
    and precision. A higher $\beta$ often results in a higher quality of the retrieved
    secret at the cost of lower quality for the container. Alternatively, L1 distance,
    PSNR (Peak Signal-to-Noise Ratio), SSIM (Structural Similarity Index Measure) Hore
    and Ziou ([2010](#bib.bib13)) and LPIPS (Learned Perceptual Image Patch Similarity) Zhang
    et al. ([2018](#bib.bib47)) are also adopted commonly associated with L2 distance
    to evaluate perceptual quality Zhang et al. ([2020a](#bib.bib52)).
  prefs: []
  type: TYPE_NORMAL
- en: 'In *secure data hiding*, there is a new participant who plays as an adversary
    of Alice and Bob by distinguishing containers from covers by a steganalyzer $\mathcal{A}$.
    An effective algorithm with high security is expected to confuse $\mathcal{A}$
    such that it cannot perform better than a random guess, i.e., the confidence score
    of an image being $C$ or $C^{\prime}$ is approximately equal to each other:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $&#124;\mathcal{A}(\mathcal{H}(S,C;\theta_{\mathcal{H}}))-\mathcal{A}(C)&#124;<\epsilon,$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $\epsilon$ is a sufficiently small positive number.
  prefs: []
  type: TYPE_NORMAL
- en: 'In *robust data hiding*, the adversary perturbs containers with distortions
    to destroy secret information within them. A robust scheme should maintain secret
    information even after container $C^{\prime}$ is attacked by a noise attacker
    (denoted as $\mathcal{N}$):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\min_{\theta_{\mathcal{H}},\theta_{\mathcal{R}}}dist_{s}(S,\mathcal{R}(\mathcal{N}(C^{\prime});\theta_{\mathcal{R}})).$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: 3 Deep Hiding Architectures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep steganography Baluja ([2017](#bib.bib3), [2019](#bib.bib4)) defines a new
    task of hiding a full image in another. This task is different from traditional
    steganography that requires perfect decoding of secret messages. Instead, the
    goal is to improve the image quality for the retrieved secret image by minimizing
    $dist_{s}(S,S^{\prime})$. Moreover, the hiding capacity of traditional steganography
    is often very low, e.g., HUGO Pevnỳ et al. ([2010](#bib.bib27)) hides $<0.5$ bpp
    (bits per pixel), while that for deep steganography Baluja ([2017](#bib.bib3))
    is 24bpp. Due to the trade-off between capacity and secrecy, most deep steganography
    can be relatively easily detected by some steganalysis algorithms. Thus, to make
    a distinction, this kind of capacity-oriented task is termed “basic data hiding”
    in this survey, instead of “steganography”.
  prefs: []
  type: TYPE_NORMAL
- en: In terms of how $C$ and $S$ are processed as the input of hiding network $\mathcal{H}$,
    we summarize three basic architectures which can be directly applied for the task
    of *basic* data hiding. Meanwhile, these architectures can be extended to other
    applications including steganography, watermarking and light field messaging by
    adding some targeted strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 'Cover-Dependent Deep Hiding with Preparation. The first deep learning based
    framework for hiding data in large capacity is proposed by Baluja Baluja ([2017](#bib.bib3),
    [2019](#bib.bib4)), which places a full-size color image within another image
    of the same size. Specifically, it has three networks: preparation, hiding and
    reveal network in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ A Brief Survey
    on Deep Learning Based Data Hiding")(a). The preparation network ($\mathcal{P}$)
    is adopted to transform secret images $S$ into features that are commonly useful
    for compressing images, such as edges and orthogonal components. The hiding network
    takes the concatenated cover image $C$ and *prepared* secret image $\mathcal{P}(S)$
    as the input. With the reveal network, recipients can retrieve the secret image
    $S^{\prime}$ from the container image $C^{\prime}$. In Figure [2](#S1.F2 "Figure
    2 ‣ 1 Introduction ‣ A Brief Survey on Deep Learning Based Data Hiding")(a), how
    a secret image is encoded is dependent on the cover image. Thus, following the
    terminology in Zhang et al. ([2020a](#bib.bib52)), we call it cover-dependent
    deep hiding, or DDH in short, architecture. Specifically, it also has an additional
    network $\mathcal{P}$, thus this kind of architecture is termed DDH with P in
    this survey.'
  prefs: []
  type: TYPE_NORMAL
- en: Cover-Dependent Deep Hiding without Preparation. Despite being conducive to
    embedding analysis, preparation network $\mathcal{P}$ complicates the entire pipeline
    and requires much more GPU memory Wu et al. ([2018](#bib.bib39)). Later works Weng
    et al. ([2019](#bib.bib37)); Mishra et al. ([2019](#bib.bib25)); Zhang et al.
    ([2020a](#bib.bib52)) show that $\mathcal{P}$ is not necessary and can be combined
    with hiding network into a single network Baluja ([2019](#bib.bib4)). Excluding
    $\mathcal{P}$ network results in a simpler DDH, i.e., DDH without P, in Figure [2](#S1.F2
    "Figure 2 ‣ 1 Introduction ‣ A Brief Survey on Deep Learning Based Data Hiding")(b).
    As it is the most commonly adopted architecture for deep hiding, the methods mentioned
    later belong to DDH without P without special explanation.
  prefs: []
  type: TYPE_NORMAL
- en: Universal Deep Hiding. Further, Zhang et al. ([2020a](#bib.bib52)) proposes
    a new architecture termed Universal Deep Hiding (UDH). The key difference between
    UDH and DDH is that UDH disentangles the encoding of secret from cover, i.e.,
    how the secret image is encoded is independent of the cover image. This disentangling
    facilitates the visualization of the encoding operation of secret images and their
    results show that secret images are encoded into repetitive high-frequency components.
    The encoded secret image in UDH can be directly added to any random cover image
    to form a container, which enhances the flexibility of information hiding. Based
    on this UDH architecture, Zhang et al. ([2020a](#bib.bib52)) shows the success
    of hiding M (6 for instance) image in N (3 for instance) images. The universal
    property of UDH also makes it efficient for watermarking, because it only requires
    a single summation, which is a noticeable advantage when a large number of images
    need to be watermarked.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Applications of Deep Hiding
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 Large-Capacity Basic Hiding
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Increasing the capacity of data hiding easily leads to contour artifacts and
    color distortion Guan et al. ([2022](#bib.bib9)), which makes the goal of remaining
    imperceptible a non-trivial challenge. The high payload of a certain method is
    often demonstrated by simultaneously hiding multiple images into one image of
    the same size. Alternatively, independent pixel-wise sources for supplementary
    information, such as depth and motion, are also proper choices to take full advantage
    of extra capacity Baluja ([2019](#bib.bib4)). A simple and widely used implementation
    to hide multiple images is to concatenate them along the RGB channel, and treat
    the concatenated tensor as an integrated secret $S$ for the network input Baluja
    ([2019](#bib.bib4)); Zhang et al. ([2020a](#bib.bib52)); Lu et al. ([2021](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: The primal motivation to hide multiple images in Baluja ([2019](#bib.bib4))
    is to obfuscate the remnants of the hidden image in the container. However, significant
    color distortion occurs when hiding 2 images. Thanks to the cover-independent
    property for secret embedding, UDH in Zhang et al. ([2020a](#bib.bib52)) can hide
    M secret images into N cover images, where embedding space is not limited to the
    RGB channels in one image. By training multiple pairs of $\mathcal{H}$ and $\mathcal{R}$,
    UDH can also hide multiple secret images within one image, but the specific secret
    can only be revealed by the corresponding $\mathcal{R}$, i.e., different recipients
    get different secret messages from the same cover. Lu et al. ([2021](#bib.bib23))
    and Jing et al. ([2021](#bib.bib17)) adopt invertible neural network to archive
    high capacity, where $\mathcal{H}$ and $\mathcal{R}$ share the same parameters.
    However, considering the simple concatenation neglects the correlation between
    secret images, follow-up DeepMIH Guan et al. ([2022](#bib.bib9)) hides multiple
    secret images in series, i.e., the concealing result of the previous image can
    assist the current concealing to improve the overall hiding performance for hiding
    multiple images.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Secure Steganography
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Steganography deals with hiding information imperceptibly and *undetectably*,
    while steganalysis plays as its adversary by detecting the potentially hidden
    information from observed data with little or no knowledge about the hiding algorithm.
    Steganography and steganalysis defeat but also enhance each other.
  prefs: []
  type: TYPE_NORMAL
- en: Generally speaking, to archive being undetectable for steganalysis, targeted
    designs are required. Some methods that are not specifically designed for steganography
    also conduct steganalysis evaluation in their works. Most of them can not be detected
    by classic steganalysis tools (e.g., StegExpose Boehm ([2014](#bib.bib5)), which
    combines several traditional steganalysis techniques), but fail when facing deep
    learning based steganalyzer. To be specific, when facing one of the state-of-the-art
    steganalyzer SRNet Boroumand et al. ([2018](#bib.bib6)), the detection accuracy
    for Baluja ([2017](#bib.bib3)), Weng et al. ([2019](#bib.bib37)), Lu et al. ([2021](#bib.bib23))
    and Guan et al. ([2022](#bib.bib9)) is 99.58%, 77.43%, 75.69% and 75.54%, respectively Guan
    et al. ([2022](#bib.bib9)). The accuracy closer to 50% (random guess) indicates
    a higher security level. It is worth noting that the SRNet steganalysis accuracy
    for HiNet Jing et al. ([2021](#bib.bib17)) is reported as 55.86%, which indicates
    that $C^{\prime}$ of HiNet is nearly indistinguishable from nature cover images.
    This is mainly attributed to their proposed low-frequency wavelet loss which makes
    the low-frequency sub-bands of $C^{\prime}$ and $C$ similar to each other.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Adversarial Architecture
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: On account of the undetectability of secure steganography, the above three architectures
    cannot be directly applied. Hence, *adversarial architecture* is widely adopted
    to enhance security and visual quality Hayes and Danezis ([2017](#bib.bib10)).
    The core of an adversarial architecture lies in an adversarial model where containers
    and covers are fed in, and form a 3-player game. The adversarial model can be
    either fine-tuned from an off-the-shelf steganalysis network Xu et al. ([2016](#bib.bib40));
    Ye et al. ([2017](#bib.bib44)), or assumed to be a regular convolutional neural
    network (CNN) Zhang et al. ([2019a](#bib.bib48)); Weng et al. ([2019](#bib.bib37))
    or similar structure to reveal network Zhu et al. ([2018](#bib.bib56)); Hayes
    and Danezis ([2017](#bib.bib10)). The work of Hayes and Danezis Hayes and Danezis
    ([2017](#bib.bib10)) has shown that supervised training of the adversarial model
    can produce a robust steganalyzer.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned above, an adversarial architecture can be obtained simply by incorporating
    an additional steganalysis classifier in the basic architecture, e.g., Weng et
    al. ([2019](#bib.bib37)); Zhang et al. ([2019c](#bib.bib50)); Yedroudj et al.
    ([2020](#bib.bib45)), which increases the resistance to steganalysis by adding
    an adversarial discriminator. However, this does not indicate that these methods
    can counter independently trained steganalyzers because the adversarial training
    strategy limits the effectiveness of the discriminator Shang et al. ([2020](#bib.bib33)).
  prefs: []
  type: TYPE_NORMAL
- en: Note that the adversarial network is *not* exclusively applied for security.
    It also helps improve the container image visual quality as well as robustness
    for watermarking or light field messaging Zhu et al. ([2018](#bib.bib56)); Liu
    et al. ([2019](#bib.bib22)); Tancik et al. ([2020](#bib.bib34)); Jia et al. ([2020](#bib.bib16));
    Plata and Syga ([2020](#bib.bib28)). Based on the adversarial architecture, the
    attention idea has been investigated in Zhang et al. ([2019b](#bib.bib49)); Yu
    ([2020](#bib.bib46)) for biasing the mode towards hiding secrets in textures and
    objects that are less affected by transformations or areas that are inconspicuous
    to the human observer, resulting in higher robustness as well imperceptibility.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Synthesis Technology
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Another interesting research direction of deep hiding for secure steganography
    is *synthesis technology*. Different from the embedding-based schemes mentioned
    above, there is no modification operated in synthesis technology, because containers
    are generated directly based on secret messages Hu et al. ([2018](#bib.bib14)).
    First, it derives a generator in deep convolutional generative adversarial nets
    (GANs) to synthesize images with random noise vectors. Second, an extractor network
    learns to reveal the corresponding vector fed into the generator. Finally, with
    the fixed generator and extractor from previous steps, Alice and Bob can have
    an undetectable secret communication by mapping secret messages into vectors prior
    to synthesis. The steganographic embedding operation becomes an image sampling
    problem in Zhang et al. ([2019d](#bib.bib51)) and containers are sampled by a
    well-trained generator. While Zhang et al. Zhang et al. ([2020b](#bib.bib53))
    establish a mapping relationship between secret message and semantic category
    for a generation. In contrast to Hu et al. ([2018](#bib.bib14)); Zhang et al.
    ([2019d](#bib.bib51)) that divide the training process into several steps and
    the extractor is trained outside the adversarial training, Wang et al. ([2018](#bib.bib35));
    Li et al. ([2020](#bib.bib21)) synchronize the training of extractor and generator,
    leading to superior performance and training efficiency. SSteGAN proposed in Wang
    et al. ([2018](#bib.bib35)) can also be defined as adversarial architecture since
    there is a steganalyzer in its system.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Robust Watermarking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Compared with capacity and security, digital watermarking prioritizes robustness.
    Thus, it often contains a well-designed module or adopts special techniques to
    enhance robustness.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1 Data Augmentation Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is widely known that a well trained deep classifier can have a non-trivial
    performance drop under the perturbation of noise. One straightforward approach
    to improve robustness against a specific type of noise is to perform data augmentation
    with such noise during the training. Inspired by this, one intuitive and commonly
    used strategy to resist noise attack for robust watermarking is to simulate such
    distortions in the training process, i.e., distorting containers with the respective
    attacks before feeding them to the reveal network Zhu et al. ([2018](#bib.bib56)).
    In practice, the attack might occur in different forms, thus it is of high practical
    relevance to make the hiding pipeline robust against various types of image distortions.
    To this end, HiDDeN Zhu et al. ([2018](#bib.bib56)) applies a single type of noise
    in a mini-batch and swaps it in each iteration. ReDMark Ahmadi et al. ([2020](#bib.bib2))
    adopts a similar approach by choosing one type of attack with a given probability
    in every iteration. This simple approach has been shown effective to achieve a
    reasonable robustness performance. Zhang et al.Zhang et al. ([2020a](#bib.bib52))
    introduces one simple change to this approach by dividing the mini-batch equally
    into multiple groups, each group applying one type of image distortion. This dividing
    strategy facilitates simultaneously applying all the investigated image distortions
    in every iteration, resulting in faster convergence as well as a significant performance
    boost. Compared with the swapping strategy adopted in Zhu et al. ([2018](#bib.bib56));
    Ahmadi et al. ([2020](#bib.bib2)), the dividing strategy does not cause any additional
    computation overhead and thus can be seen as a “free” technique to improve the
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.2 Advances on Handling Non-Differentiable Compression
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'For reducing the bandwidth or traffic to facilitate the storage and transmission,
    most images/videos are often pre-processed with lossy compressions, such as JPEG
    or MPEG. Especially, JPEG, the most popular lossy compression for images, is often
    considered the most common attack against watermarking. However, it is a non-trivial
    task to improve the robustness against JPEG compression, because it is a non-differentiable
    operation, which hinders training $\mathcal{H}$ and $\mathcal{R}$ jointly. HiDDeN Zhu
    et al. ([2018](#bib.bib56)) has attempted to simulate the JPEG compression with
    JPEG-Mast and JPEG-Drop. Inspired by the fact that JPEG mainly discards the high-frequency
    component, JPEG-Mask keeps only low-frequency DCT coefficients with fixed masking
    and JPEG-Drop adopts a progressive dropout on the coefficients, i.e., having a
    higher probability to drop high-frequency coefficients. Due to the mismatch between
    the simulated JPEG and real JPEG, there is a significant performance drop under
    real JPEG. ReDMark Ahmadi et al. ([2020](#bib.bib2)) attempts to address this
    challenge by carefully designing a series of differentiable functions for mimicking
    every step of real JPEG compression. Similar approach has been adopted in Luo
    et al. ([2020](#bib.bib24)). Such an approach has two limitations: i) it requires
    full knowledge of the attack, which is the case for JPEG attack but might not
    be true for other types of attacks; ii) it requires a careful engineering design
    of various differentiable functions to mimic the real attack, which might still
    fail for a real attack.'
  prefs: []
  type: TYPE_NORMAL
- en: To address this challenge, Liu et al. ([2019](#bib.bib22)) proposes a two-stage
    separable deep learning framework. In the first stage, the encoder $\mathcal{H}$
    and decoder $\mathcal{R}$ are trained simultaneously without noise, resulting
    in a powerful redundant-coding encoder. In the second stage, the pre-trained encoder
    obtained from the first stage is fixed and the loss back-propagates only through
    the decoder. This alleviates the non-differentiability concern because the loss
    does not need to back-propagate through the encoder. A limitation of this two-stage
    approach is that the encoder is trained without JPEG compression, thus it is a
    sub-optimal solution compared with jointly training the $\mathcal{H}$ and $\mathcal{R}$
    with JPEG compression.
  prefs: []
  type: TYPE_NORMAL
- en: Due to the non-differentiability of JPEG compression, jointly training the encoder
    and decoder seems to be a non-trivial task. A recent work Zhang et al. ([2021b](#bib.bib55))
    proposes one elegant pseudo-differentiable approach that treats the JPEG compression
    as a special noise. A unique property of their approach is that the forward path
    and backward path are not the same. Specifically, the backward propagation does
    not go through the JPEG compression part. In essence, this approach is similar
    to the above noise augmentation approach but mitigates the non-differentiability
    issue by a plus and minus operation. This approach achieves the SOTA performance
    for robustness against JPEG attack and has also been shown to provide satisfactory
    performance for video compression.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.3 Adversarial Training Inspired Approaches
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To improve the robustness against unknown distortions, Luo et al. ([2020](#bib.bib24))
    proposes to combine the known distortions with adversarial perturbation which
    constitutes the worst perturbation. Such a min-max approach is inspired by another
    line of research on adversarial training for improving the deep classifier robustness
    against adversarial attack. The effect of adversarial training on the robustness
    against common corruptions has been investigated in Luo et al. ([2020](#bib.bib24)),
    which shows that it improves the robustness against noise-type perturbation at
    the cost of performance drop for some known distortions. For example, the known
    Crop and Gaussian Blur distortion have a non-trivial performance drop Luo et al.
    ([2020](#bib.bib24)). A similar approach has also been explored in Wen and Aydore
    ([2019](#bib.bib36)), which selects the predefined distortion type and strength
    adaptively through maximizing the loss for the decoder. Both Luo et al. ([2020](#bib.bib24))
    and Wen and Aydore ([2019](#bib.bib36)) formulate the watermarking robustness
    as a min-max optimization problem and their key difference is that Luo et al.
    ([2020](#bib.bib24)) generates an adversarial perturbation through a DNN, while
    Wen and Aydore ([2019](#bib.bib36)) selects it from a fixed pool of common distortions.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Light Field Messaging
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As a practical application for data hiding, light field messaging (LFM) Wengrowski
    and Dana ([2019](#bib.bib38)) describes the process of embedding, transmitting
    and receiving hidden information in an image displayed on a display *screen* and
    captured by a *camera*. The LFM process is also often termed screen-camera communication Cui
    et al. ([2019](#bib.bib7)) or photographic steganography but has no concern of
    being detected by steganalysis. Instead, the challenge of this task lies in the
    robustness against image transformations induced by the light effect which can
    be seen as a mixed influence of electronic display characteristics, camera exposure
    and camera-display angle. In essence, it is very similar to robust watermarking,
    but the goal is to transmit useful information instead of proving the ownership.
    Wengrowski and Dana ([2019](#bib.bib38)) found that directly applying the DDH
    architecture without taking the light effect leads to total failure of extracting
    the hidden barcode information. To this end, they collect a huge (1.9TB) dataset
    of camera-captured images from 25 camera-display pairs and then trains a camera-display
    transfer function (CDTF) to mimic the distortion caused by light field transfer.
    However, it requires lots of resources for training on such a huge dataset, and
    its performance is not satisfactory, especially for the unknown camera-display
    pairs.
  prefs: []
  type: TYPE_NORMAL
- en: To address the above disadvantages, StegaStamp Tancik et al. ([2020](#bib.bib34)),
    extending the application also to printed images, proposes to augment the container
    images with a mixture of image transformations, such as perspective warp, motion/defocus
    blur, color manipulation, noise as well as JPEG compression. Moreover, their approach
    requires a relatively complex weighted loss that has L2 residual regularization,
    perceptual loss, critic loss and cross-entropy loss for the message. Such a complex
    loss requires a careful choice of the hyper-parameters. Zhang et al. Zhang et
    al. ([2020a](#bib.bib52)) provides a much simpler solution based on the proposed
    UDH. Specifically, they adopt only the perspective warp as the image transformation
    and the same simple loss for basic data hiding in Baluja ([2017](#bib.bib3)) can
    be directly used. This simple approach yields competitive performance and the
    reason has been attributed to the fact that UDH is more robust against perturbation
    on the container images, especially for the constant pixel value shift, like color
    change. Moreover, UDH is more versatile in the sense that it can also hide a secret
    image, while  Wengrowski and Dana ([2019](#bib.bib38)) and  Tancik et al. ([2020](#bib.bib34))
    can only hide limited binary information. Concealing information in vector drawings
    such as SVG files has also been explored in DeepMorph Rasmussen et al. ([2020](#bib.bib31))
    with the artistic freedom to convey information via their own designed drawings,
    but it’s not as versatile as UDH that can hide all kinds of images, including
    natural images. RIHOOP Jia et al. ([2020](#bib.bib16)) incorporates a distortion
    network based on differentiable 3D rendering to better simulate realistic distortions
    introduced by camera imaging. It would be an interesting direction to combine
    the techniques in RIHOOP Jia et al. ([2020](#bib.bib16)) and UDH Zhang et al.
    ([2020a](#bib.bib52)) for future research to achieve the purpose of being both
    robust and versatile.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Hiding Data within Other Multimedia
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The master branch of research on data hiding adopts images as information carrier
    to hide either binary messages  Hayes and Danezis ([2017](#bib.bib10)); Zhu et
    al. ([2018](#bib.bib56)); Liu et al. ([2019](#bib.bib22)); Tancik et al. ([2020](#bib.bib34))
    or natural images Baluja ([2017](#bib.bib3)); Wengrowski and Dana ([2019](#bib.bib38));
    Zhang et al. ([2020a](#bib.bib52)); Yu ([2020](#bib.bib46)). Nonetheless, there
    are also a variety of other multimedia that can be adopted, such as video, audio
    and text. The basic architectures and strategies for improving security and robustness
    mentioned before are suitable for other forms of carriers. However, some adaptive
    approaches might be necessary according to the characteristics of these multimedia.
  prefs: []
  type: TYPE_NORMAL
- en: 'In essence, video can be seen as a sequence of images, thus the framework of
    hiding an image in another can be easily extended to the new task of hiding videos
    in videos by encoding each frame of the secret video within that of the cover
    video in a sequential manner. However, this naive approach does not exploit the
    temporal redundancy within the consecutive frames, since the residual between
    two consecutive frames is highly-sparse. To this end, Weng et al. Weng et al.
    ([2019](#bib.bib37)) propose a straightforward solution that contains two branches:
    one for the benchmark secret frame reference and the other for the frame residuals.
    By dividing the video into frame groups each containing 8 frames, Mishra et al.
    ([2019](#bib.bib25)) exploits 3D-CNN to hide 8 frames within 8 frames via exploiting
    the motion relationship between consecutive frames.'
  prefs: []
  type: TYPE_NORMAL
- en: Hiding audio in audio has been demonstrated in Kreuk et al. ([2019](#bib.bib20)).
    It has been found that the framework for hiding images in images is suitable for
    the audio domain but requires including a short-time Fourier transform and inverse-time
    transform as differentiable layers during the training. Deep learning has also
    been applied in cross-modal hiding applications, such as hiding images or video
    in audio, with favourable performance. Taking advantage of the serialization feature
    of audio, Cui et al. Cui et al. ([2020](#bib.bib8)) present a method for hiding
    image content within audio carriers by multi-stage hiding and reveal networks.
    They progressively embed multilevel residual errors of the secret image into cover
    audio in a multi-stage hiding network. Subsequently, the decreasing residual errors
    from the modified carrier are decoded with corresponding stage sub-networks and
    added together to produce the final revealed result. Yang et al. Yang et al. ([2019a](#bib.bib42))
    provide a different approach for this cross-modal task of hiding video in audio,
    which is practically challenging because of the high bitrate of video files. One
    of its potential drawbacks is that the reveal stage also needs access to the original
    clean audio.
  prefs: []
  type: TYPE_NORMAL
- en: Data hiding in text is also a broad research direction. Different from those
    generative methods Yang et al. ([2018](#bib.bib41), [2019b](#bib.bib43)), Abdelnabi
    et al. Abdelnabi and Fritz ([2020](#bib.bib1)) introduce the Adversarial Watermarking
    Transformer (AWT) with a jointly trained encoder-decoder and adversarial training.
    With an input text and a binary message, the watermarking system can generate
    an output text that is unobtrusively modified with the given message. It is worth
    mentioning that text data hiding is highly related to the field of natural language
    processing.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Link with Adversarial Attack
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A Small Change Makes a Big Difference. In essence, the container image is just
    a cover image with an imperceptible change. The reveal network is very sensitive
    to such small invisible changes. In other words, there is a misalignment between
    human vision and DNNs. Such misalignment has also been observed in another line
    of research on the adversarial attack, where an imperceptible perturbation can
    fool the deep classifier with high confidence.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, Zhang et al. Zhang et al. ([2021a](#bib.bib54)) has performed a joint
    investigation of such misalignment phenomenon in both tasks, providing a unified
    Fourier perspective on why such small perturbation can dominate the images in
    the context of universal attack and hiding. The reason for the misalignment has
    been attributed to the fact that DNNs are sensitive to high-frequency content
    Zhang et al. ([2021a](#bib.bib54)) with the observation that frequency is a key
    factor that influences the performance for both tasks. The joint investigation
    of deep learning based watermarking and adversarial attack has also been previously
    explored in Quiring et al. ([2018](#bib.bib30)), with a unified notion of black-box
    attacks against both tasks, the efficacy of which is demonstrated by applying
    the concepts from adversarial attack to watermarking and vice versa. For example,
    counter-measures in watermarking can be utilized to defend against some model-extraction
    adversarial attacks and the techniques for improving the model adversarial robustness
    can also help mitigate the attacks against the watermarking Quiring et al. ([2018](#bib.bib30)).
    Moreover, the lesson in multimedia forensics has also been found useful for facilitating
    the detection of adversarial examples Schöttle et al. ([2018](#bib.bib32)). On
    the other hand, adversarial machine learning against watermarking has also been
    explored in Quiring and Rieck ([2018](#bib.bib29)), adopting a neural network
    to detect and remove the watermark. It is worth mentioning that adversarial training
    techniques for improving adversarial robustness have also been investigated in
    Luo et al. ([2020](#bib.bib24)) for improving the deep learning based watermarking
    robustness against unknown distortion, as discussed in Sec. [4.3.3](#S4.SS3.SSS3
    "4.3.3 Adversarial Training Inspired Approaches ‣ 4.3 Robust Watermarking ‣ 4
    Applications of Deep Hiding ‣ A Brief Survey on Deep Learning Based Data Hiding").
  prefs: []
  type: TYPE_NORMAL
- en: Overall, there exists a unified Fourier perspective Zhang et al. ([2021a](#bib.bib54))
    on the success of deep hiding and attack. Meanwhile, techniques from watermarking
    are often found effective in adversarial attack, vice versa Quiring et al. ([2018](#bib.bib30)).
    A single universal secret adversarial perturbation has also been demonstrated
    in Zhang et al. ([2021a](#bib.bib54)) to perform an attack while containing a
    secret message simultaneously. However, the joint investigation of them is still
    in its infancy and we believe it is an interesting direction to perform deep analysis
    of them together for both theoretical and practical relevance.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep hiding has become an emerging field to attract significant attention. Our
    work conducts a brief yet comprehensive survey on this topic by first classifying
    data hiding by its essential properties and outlining three basic architectures.
    Moreover, we discuss the challenges of deep hiding in various applications, including
    large-capacity basic hiding, secure steganography, robust watermarking and light
    field messaging. For completeness, we also summarize hiding data within other
    multimedia content. Finally, we discuss its impact on the field of adversarial
    attack and vice versa. A joint investigation of data hiding and adversarial attack
    will be an interesting direction with potential new insights.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Abdelnabi and Fritz [2020] Sahar Abdelnabi and Mario Fritz. Adversarial watermarking
    transformer: Towards tracing text provenance with data hiding. arXiv preprint
    arXiv:2009.03015, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ahmadi et al. [2020] Mahdi Ahmadi, Alireza Norouzi, Nader Karimi, Shadrokh
    Samavi, and Ali Emami. Redmark: Framework for residual diffusion watermarking
    based on deep networks. Expert Systems with Applications, 146:113157, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baluja [2017] Shumeet Baluja. Hiding images in plain sight: Deep steganography.
    In NeurIPS, pages 2066–2076, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baluja [2019] Shumeet Baluja. Hiding images within images. TPAMI, 42(7):1685–1697,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boehm [2014] Benedikt Boehm. Stegexpose-a tool for detecting lsb steganography.
    arXiv preprint arXiv:1410.6656, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boroumand et al. [2018] Mehdi Boroumand, Mo Chen, and Jessica Fridrich. Deep
    residual network for steganalysis of digital images. TIFS, 14(5):1181–1193, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cui et al. [2019] Hao Cui, Huanyu Bian, Weiming Zhang, and Nenghai Yu. Unseencode:
    Invisible on-screen barcode with image-based extraction. In INFOCOM, pages 1315–1323\.
    IEEE, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cui et al. [2020] Wenxue Cui, Shaohui Liu, Feng Jiang, Yongliang Liu, and Debin
    Zhao. Multi-stage residual hiding for image-into-audio steganography. In ICASSP,
    pages 2832–2836\. IEEE, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Guan et al. [2022] Zhenyu Guan, Junpeng Jing, Xin Deng, Mai Xu, Lai Jiang,
    Zhou Zhang, and Yipeng Li. Deepmih: Deep invertible network for multiple image
    hiding. TPAMI, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hayes and Danezis [2017] Jamie Hayes and George Danezis. Generating steganographic
    images via adversarial training. In NeurIPS, pages 1951–1960, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holub and Fridrich [2012] Vojtěch Holub and Jessica Fridrich. Designing steganographic
    distortion using directional filters. In WIFS, pages 234–239\. IEEE, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holub et al. [2014] Vojtěch Holub, Jessica Fridrich, and Tomáš Denemark. Universal
    distortion function for steganography in an arbitrary domain. EURASIP Journal
    on Information Security, 2014(1):1–13, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hore and Ziou [2010] Alain Hore and Djemel Ziou. Image quality metrics: Psnr
    vs. ssim. In ICPR, pages 2366–2369\. IEEE, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. [2018] Donghui Hu, Liang Wang, Wenjie Jiang, Shuli Zheng, and Bin
    Li. A novel image steganography method via deep convolutional generative adversarial
    networks. IEEE Access, 6:38303–38314, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Husien and Badi [2015] Sabah Husien and Haitham Badi. Artificial neural network
    for steganography. Neural Computing and Applications, 26(1):111–116, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jia et al. [2020] Jun Jia, Zhongpai Gao, Kang Chen, Menghan Hu, Xiongkuo Min,
    Guangtao Zhai, and Xiaokang Yang. Rihoop: Robust invisible hyperlinks in offline
    and online photographs. Transactions on Cybernetics, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jing et al. [2021] Junpeng Jing, Xin Deng, Mai Xu, Jianyi Wang, and Zhenyu
    Guan. Hinet: Deep image hiding by invertible network. In ICCV, pages 4733–4742,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kadhim et al. [2019] Inas Jawad Kadhim, Prashan Premaratne, Peter James Vial,
    and Brendan Halloran. Comprehensive survey of image steganography: Techniques,
    evaluations, and trends in future research. Neurocomputing, 335:299–326, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kandi et al. [2017] Haribabu Kandi, Deepak Mishra, and Subrahmanyam RK Sai Gorthi.
    Exploring the learning capabilities of convolutional neural networks for robust
    image watermarking. Computers & Security, 65:247–268, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kreuk et al. [2019] Felix Kreuk, Yossi Adi, Bhiksha Raj, Rita Singh, and Joseph
    Keshet. Hide and speak: Towards deep neural networks for speech steganography.
    arXiv preprint arXiv:1902.03083, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. [2020] Jun Li, Ke Niu, Liwei Liao, Lijie Wang, Jia Liu, Yu Lei, and
    Minqing Zhang. A generative steganography method based on wgan-gp. In International
    Conference on Artificial Intelligence and Security, pages 386–397\. Springer,
    2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2019] Yang Liu, Mengxi Guo, Jian Zhang, Yuesheng Zhu, and Xiaodong
    Xie. A novel two-stage separable deep learning framework for practical blind watermarking.
    In ACM Multimedia, pages 1509–1517, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. [2021] Shao-Ping Lu, Rong Wang, Tao Zhong, and Paul L Rosin. Large-capacity
    image steganography based on invertible neural networks. In CVPR, pages 10816–10825,
    2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo et al. [2020] Xiyang Luo, Ruohan Zhan, Huiwen Chang, Feng Yang, and Peyman
    Milanfar. Distortion agnostic deep watermarking. In CVPR, pages 13548–13557, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mishra et al. [2019] Aayush Mishra, Suraj Kumar, Aditya Nigam, and Saiful Islam.
    Vstegnet: Video steganography network using spatio-temporal features and micro-bottleneck.
    In BMVC, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mun et al. [2017] Seung-Min Mun, Seung-Hun Nam, Han-Ul Jang, Dongkyu Kim, and
    Heung-Kyu Lee. A robust blind watermarking using convolutional neural network.
    arXiv preprint arXiv:1704.03248, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pevnỳ et al. [2010] Tomáš Pevnỳ, Tomáš Filler, and Patrick Bas. Using high-dimensional
    image models to perform highly undetectable steganography. In International Workshop
    on Information Hiding, pages 161–177\. Springer, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Plata and Syga [2020] Marcin Plata and Piotr Syga. Robust spatial-spread deep
    neural image watermarking. arXiv preprint arXiv:2005.11735, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quiring and Rieck [2018] Erwin Quiring and Konrad Rieck. Adversarial machine
    learning against digital watermarking. In EUSIPCO, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quiring et al. [2018] Erwin Quiring, Daniel Arp, and Konrad Rieck. Forgotten
    siblings: Unifying attacks on machine learning and digital watermarking. In EuroS&P,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rasmussen et al. [2020] Søren Rasmussen, Karsten Østergaard Noe, Oliver Gyldenberg
    Hjermitslev, and Henrik Pedersen. Deepmorph: A system for hiding bitstrings in
    morphable vector drawings. arXiv preprint arXiv:2011.09783, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schöttle et al. [2018] Pascal Schöttle, Alexander Schlögl, Cecilia Pasquini,
    and Rainer Böhme. Detecting adversarial examples-a lesson from multimedia forensics.
    arXiv preprint arXiv:1803.03613, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shang et al. [2020] Yueyun Shang, Shunzhi Jiang, Dengpan Ye, and Jiaqing Huang.
    Enhancing the security of deep learning steganography via adversarial examples.
    Mathematics, 8(9):1446, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tancik et al. [2020] Matthew Tancik, Ben Mildenhall, and Ren Ng. Stegastamp:
    Invisible hyperlinks in physical photographs. In CVPR, pages 2117–2126, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2018] Zihan Wang, Neng Gao, Xin Wang, Xuexin Qu, and Linghui Li.
    Sstegan: self-learning steganography based on generative adversarial networks.
    In ICONIP, pages 253–264\. Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wen and Aydore [2019] Bingyang Wen and Sergul Aydore. Romark: A robust watermarking
    system using adversarial training. arXiv preprint arXiv:1910.01221, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weng et al. [2019] Xinyu Weng, Yongzhi Li, Lu Chi, and Yadong Mu. High-capacity
    convolutional video steganography with temporal residual modeling. In ICMR, pages
    87–95, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wengrowski and Dana [2019] Eric Wengrowski and Kristin Dana. Light field messaging
    with deep photographic steganography. In CVPR, pages 1515–1524, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. [2018] Pin Wu, Yang Yang, and Xiaoqiang Li. Stegnet: Mega image steganography
    capacity with deep convolutional network. Future Internet, 10(6):54, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. [2016] Guanshuo Xu, Han-Zhou Wu, and Yun-Qing Shi. Structural design
    of convolutional neural networks for steganalysis. IEEE Signal Processing Letters,
    23(5):708–712, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2018] Zhong-Liang Yang, Xiao-Qing Guo, Zi-Ming Chen, Yong-Feng
    Huang, and Yu-Jin Zhang. Rnn-stega: Linguistic steganography based on recurrent
    neural networks. TIFS, 14(5):1280–1295, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2019a] Hyukryul Yang, Hao Ouyang, Vladlen Koltun, and Qifeng Chen.
    Hiding video in audio via reversible generative models. In ICCV, pages 1100–1109,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2019b] Zhongliang Yang, Nan Wei, Qinghe Liu, Yongfeng Huang, and
    Yujin Zhang. Gan-tstega: Text steganography based on generative adversarial networks.
    In International Workshop on Digital Watermarking, pages 18–31\. Springer, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ye et al. [2017] Jian Ye, Jiangqun Ni, and Yang Yi. Deep learning hierarchical
    representations for image steganalysis. TIFS, 12(11):2545–2557, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yedroudj et al. [2020] Mehdi Yedroudj, Frédéric Comby, and Marc Chaumont. Steganography
    using a 3-player game. Journal of Visual Communication and Image Representation,
    72:102910, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu [2020] Chong Yu. Attention based data hiding with generative adversarial
    networks. In AAAI, pages 1120–1128, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2018] Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman,
    and Oliver Wang. The unreasonable effectiveness of deep features as a perceptual
    metric. In Proceedings of the IEEE conference on computer vision and pattern recognition,
    pages 586–595, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2019a] Kevin Alex Zhang, Alfredo Cuesta-Infante, Lei Xu, and
    Kalyan Veeramachaneni. Steganogan: High capacity image steganography with gans.
    arXiv preprint arXiv:1901.03892, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2019b] Kevin Alex Zhang, Lei Xu, Alfredo Cuesta-Infante, and Kalyan
    Veeramachaneni. Robust invisible video watermarking with attention. arXiv preprint
    arXiv:1909.01285, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2019c] Ru Zhang, Shiqi Dong, and Jianyi Liu. Invisible steganography
    via generative adversarial networks. Multimedia tools and applications, 78(7):8559–8575,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2019d] Zhuo Zhang, Jia Liu, Yan Ke, Yu Lei, Jun Li, Minqing Zhang,
    and Xiaoyuan Yang. Generative steganography by sampling. IEEE Access, 7:118586–118597,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2020a] Chaoning Zhang, Philipp Benz, Adil Karjauv, Geng Sun,
    and In-So Kweon. Udh: Universal deep hiding for steganography, watermarking, and
    light field messaging. In NeurIPS, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2020b] Zhuo Zhang, Guangyuan Fu, Rongrong Ni, Jia Liu, and Xiaoyuan
    Yang. A generative method for steganography by cover synthesis with auxiliary
    semantics. Tsinghua Science and Technology, 25(4):516–527, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2021a] Chaoning Zhang, Philipp Benz, Adil Karjauv, and In So
    Kweon. Universal adversarial perturbations through the lens of deep steganography:
    Towards a fourier perspective. AAAI, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2021b] Chaoning Zhang, Adil Karjauv, Philipp Benz, and In So Kweon.
    Towards robust deep hiding under non-differentiable distortions for practical
    blind watermarking. In ACM Multimedia, pages 5158–5166, 2021.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. [2018] Jiren Zhu, Russell Kaplan, Justin Johnson, and Li Fei-Fei.
    Hidden: Hiding data with deep networks. In ECCV, pages 657–672, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
