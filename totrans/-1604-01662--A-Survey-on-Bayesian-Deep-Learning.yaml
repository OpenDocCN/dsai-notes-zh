- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:09:18'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[1604.01662] A Survey on Bayesian Deep Learning'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1604.01662](https://ar5iv.labs.arxiv.org/html/1604.01662)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Survey on Bayesian Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hao Wang [hoguewang@gmail.com](mailto:hoguewang@gmail.com) Massachusetts Institute
    of TechnologyUSA  and  Dit-Yan Yeung [dyyeung}@cse.ust.hk](mailto:dyyeung%7D@cse.ust.hk)
    Hong Kong University of Science and TechnologyP.O. Box 1212Hong Kong
  prefs: []
  type: TYPE_NORMAL
- en: Abstract.
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: A comprehensive artificial intelligence system needs to not only perceive the
    environment with different ‘senses’ (e.g., seeing and hearing) but also infer
    the world’s conditional (or even causal) relations and corresponding uncertainty.
    The past decade has seen major advances in many perception tasks such as visual
    object recognition and speech recognition using deep learning models. For higher-level
    inference, however, probabilistic graphical models with their Bayesian nature
    are still more powerful and flexible. In recent years, *Bayesian deep learning*
    has emerged as a unified probabilistic framework to tightly integrate deep learning
    and Bayesian models¹¹1See a curated and updating list of papers related to Bayesian
    deep learning at [https://github.com/js05212/BayesianDeepLearning-Survey](https://github.com/js05212/BayesianDeepLearning-Survey)..
    In this general framework, the perception of text or images using deep learning
    can boost the performance of higher-level inference and in turn, the feedback
    from the inference process is able to enhance the perception of text or images.
    This survey provides a comprehensive introduction to *Bayesian deep learning*
    and reviews its recent applications on recommender systems, topic models, control,
    etc. Besides, we also discuss the relationship and differences between Bayesian
    deep learning and other related topics such as Bayesian treatment of neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Learning, Bayesian Networks, Probabilistic Graphical Models, Generative
    Models^†^†copyright: acmlicensed^†^†journal: CSUR^†^†journalyear: 2020^†^†journalvolume:
    1^†^†journalnumber: 1^†^†article: 1^†^†publicationmonth: 1^†^†price: 15.00^†^†doi:
    10.1145/3409383^†^†conference: ACM Computing Surveys; March, 2020; New York, NY^†^†booktitle:
    ACM Computing Surveys^†^†price: 15.00^†^†isbn: xxx-x-xxxx-xxxx-x/xx/xx^†^†ccs:
    Mathematics of computing Probabilistic representations^†^†ccs: Information systems Data
    mining^†^†ccs: Computing methodologies Neural networks'
  prefs: []
  type: TYPE_NORMAL
- en: 1\. Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the past decade, deep learning has achieved significant success in many
    popular perception tasks including visual object recognition, text understanding,
    and speech recognition. These tasks correspond to artificial intelligence (AI)
    systems’ ability to *see*, *read*, and *hear*, respectively, and they are undoubtedly
    indispensable for AI to effectively perceive the environment. However, in order
    to build a practical and comprehensive AI system, simply being able to perceive
    is far from sufficient. It should, above all, possess the ability of *thinking*.
  prefs: []
  type: TYPE_NORMAL
- en: 'A typical example is medical diagnosis, which goes far beyond simple perception:
    besides *seeing* visible symptoms (or medical images from CT) and *hearing* descriptions
    from patients, a doctor also has to look for relations among all the symptoms
    and preferably infer their corresponding etiology. Only after that can the doctor
    provide medical advice for the patients. In this example, although the abilities
    of *seeing* and *hearing* allow the doctor to acquire information from the patients,
    it is the *thinking* part that defines a doctor. Specifically, the ability of
    *thinking* here could involve identifying conditional dependencies, causal inference,
    logic deduction, and dealing with uncertainty, which are apparently beyond the
    capability of conventional deep learning methods. Fortunately, another machine
    learning paradigm, probabilistic graphical models (PGM), excels at probabilistic
    or causal inference and at dealing with uncertainty. The problem is that PGM is
    not as good as deep learning models at perception tasks, which usually involve
    large-scale and high-dimensional signals (e.g., images and videos). To address
    this problem, it is therefore a natural choice to unify deep learning and PGM
    within a principled probabilistic framework, which we call *Bayesian deep learning*
    (BDL) in this paper.'
  prefs: []
  type: TYPE_NORMAL
- en: In the example above, the *perception task* involves perceiving the patient’s
    symptoms (e.g., by *seeing* medical images), while the *inference task* involves
    handling conditional dependencies, causal inference, logic deduction, and uncertainty.
    With the principled integration in Bayesian deep learning, the perception task
    and inference task are regarded as a whole and can benefit from each other. Concretely,
    being able to see the medical image could help with the doctor’s diagnosis and
    inference. On the other hand, diagnosis and inference can, in turn, help understand
    the medical image. Suppose the doctor may not be sure about what a dark spot in
    a medical image is, but if she is able to *infer* the etiology of the symptoms
    and disease, it can help her better decide whether the dark spot is a tumor or
    not.
  prefs: []
  type: TYPE_NORMAL
- en: Take recommender systems ([CDL,](#bib.bib121) ; [DBLP:conf/aaai/LuDLX015,](#bib.bib71)
    ; [DBLP:journals/tkde/AdomaviciusK12,](#bib.bib1) ; [ricci2011introduction,](#bib.bib92)
    ; [DBLP:conf/recsys/LiuMLY11,](#bib.bib70) ) as another example. A highly accurate
    recommender system requires (1) thorough understanding of item content (e.g.,
    content in documents and movies) ([DBLP:journals/tkde/Park13,](#bib.bib85) ),
    (2) careful analysis of users’ profiles/preferences ([DBLP:journals/tkde/WeiMJ05,](#bib.bib126)
    ; [DBLP:journals/tkde/YapTP07,](#bib.bib130) ; [DBLP:conf/aaai/ZhengCZXY10,](#bib.bib134)
    ), and (3) proper evaluation of similarity among users ([DBLP:journals/tkde/CaiLLMTL14,](#bib.bib12)
    ; [DBLP:journals/tkde/TangQZX13,](#bib.bib109) ; [DBLP:journals/tkde/HornickT12,](#bib.bib46)
    ; [DBLP:journals/tkde/BartoliniZP11,](#bib.bib3) ). Deep learning with its ability
    to efficiently process dense high-dimensional data such as movie content is good
    at the first subtask, while PGM specializing in modeling conditional dependencies
    among users, items, and ratings (see Figure [7](#S5.F7 "Figure 7 ‣ 5.1.1\. Collaborative
    Deep Learning ‣ 5.1\. Supervised Bayesian Deep Learning for Recommender Systems
    ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning")
    as an example, where ${\bf u}$, ${\bf v}$, and ${\bf R}$ are user latent vectors,
    item latent vectors, and ratings, respectively) excels at the other two. Hence
    unifying them two in a single principled probabilistic framework gets us the best
    of both worlds. Such integration also comes with additional benefit that uncertainty
    in the recommendation process is handled elegantly. What’s more, one can also
    derive Bayesian treatments for concrete models, leading to more robust predictions ([CDL,](#bib.bib121)
    ; [ColVAE,](#bib.bib68) ).
  prefs: []
  type: TYPE_NORMAL
- en: As a third example, consider controlling a complex dynamical system according
    to the live video stream received from a camera. This problem can be transformed
    into iteratively performing two tasks, perception from raw images and control
    based on dynamic models. The perception task of processing raw images can be handled
    by deep learning while the control task usually needs more sophisticated models
    such as hidden Markov models and Kalman filters ([harrison1999bayesian,](#bib.bib35)
    ; [DBLP:conf/uai/MatsubaraGK14,](#bib.bib74) ). The feedback loop is then completed
    by the fact that actions chosen by the control model can affect the received video
    stream in turn. To enable an effective iterative process between the perception
    task and the control task, we need information to flow back and forth between
    them. The perception component would be the basis on which the control component
    estimates its states and the control component with a dynamic model built in would
    be able to predict the future trajectory (images). Therefore Bayesian deep learning
    is a suitable choice ([watter2015embed,](#bib.bib125) ) for this problem. Note
    that similar to the recommender system example, both noise from raw images and
    uncertainty in the control process can be naturally dealt with under such a probabilistic
    framework.
  prefs: []
  type: TYPE_NORMAL
- en: 'The above examples demonstrate BDL’s major advantages as a principled way of
    unifying deep learning and PGM: information exchange between the *perception task*
    and the *inference task*, conditional dependencies on high-dimensional data, and
    effective modeling of uncertainty. In terms of uncertainty, it is worth noting
    that when BDL is applied to complex tasks, there are *three kinds of parameter
    uncertainty* that need to be taken into account:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uncertainty on the neural network parameters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uncertainty on the task-specific parameters.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Uncertainty of exchanging information between the perception component and the
    task-specific component.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: By representing the unknown parameters using distributions instead of point
    estimates, BDL offers a promising framework to handle these three kinds of uncertainty
    in a unified way. It is worth noting that the third uncertainty could only be
    handled under a unified framework like BDL; training the perception component
    and the task-specific component separately is equivalent to assuming no uncertainty
    when *exchanging information* between them two. Note that neural networks are
    usually over-parameterized and therefore pose additional challenges in efficiently
    handling the uncertainty in such a large parameter space. On the other hand, graphical
    models are often more concise and have smaller parameter space, providing better
    interpretability.
  prefs: []
  type: TYPE_NORMAL
- en: Besides the advantages above, another benefit comes from the implicit regularization
    built in BDL. By imposing a prior on hidden units, parameters defining a neural
    network, or the model parameters specifying the conditional dependencies, BDL
    can to some degree avoid overfitting, especially when we have insufficient data.
    Usually, a BDL model consists of two components, a *perception component* that
    is a Bayesian formulation of a certain type of neural networks and a *task-specific
    component* that describes the relationship among different hidden or observed
    variables using PGM. Regularization is crucial for them both. Neural networks
    are usually heavily over-parameterized and therefore needs to be regularized properly.
    Regularization techniques such as weight decay and dropout ([srivastava2014dropout,](#bib.bib103)
    ) are shown to be effective in improving performance of neural networks and they
    both have Bayesian interpretations ([gal2015dropout,](#bib.bib22) ). In terms
    of the task-specific component, expert knowledge or prior information, as a kind
    of regularization, can be incorporated into the model through the prior we imposed
    to guide the model when data are scarce.
  prefs: []
  type: TYPE_NORMAL
- en: There are also challenges when applying BDL to real-world tasks. (1) First,
    it is nontrivial to design an efficient Bayesian formulation of neural networks
    with reasonable time complexity. This line of work is pioneered by ([mackay1992practical,](#bib.bib72)
    ; [hinton1993keeping,](#bib.bib42) ; [neal1995bayesian,](#bib.bib80) ), but it
    has not been widely adopted due to its lack of scalability. Fortunately, some
    recent advances in this direction ([DBLP:conf/nips/Graves11,](#bib.bib31) ; [kingma2013auto,](#bib.bib58)
    ; [DBLP:conf/icml/Hernandez-Lobato15b,](#bib.bib39) ; [DBLP:conf/icml/BlundellCKW15,](#bib.bib9)
    ; [balan2015bayesian,](#bib.bib2) ; [CDL,](#bib.bib121) ; [NPN,](#bib.bib119)
    ) seem to shed light²²2In summary, reduction in time complexity can be achieved
    via expectation propagation ([DBLP:conf/icml/Hernandez-Lobato15b,](#bib.bib39)
    ), the reparameterization trick ([kingma2013auto,](#bib.bib58) ; [DBLP:conf/icml/BlundellCKW15,](#bib.bib9)
    ), probabilistic formulation of neural networks with maximum a posteriori estimates ([CDL,](#bib.bib121)
    ), approximate variational inference with natural-parameter networks ([NPN,](#bib.bib119)
    ), knowledge distillation ([balan2015bayesian,](#bib.bib2) ), etc. We refer readers
    to ([NPN,](#bib.bib119) ) for a detailed overview. on the practical adoption of
    Bayesian neural network³³3Here we refer to the Bayesian treatment of neural networks
    as Bayesian neural networks. The other term, Bayesian deep learning, is retained
    to refer to complex Bayesian models with both a perception component and a task-specific
    component. See Section [4.1](#S4.SS1 "4.1\. A Brief History of Bayesian Neural
    Networks and Bayesian Deep Learning ‣ 4\. Bayesian Deep Learning ‣ A Survey on
    Bayesian Deep Learning") for a detailed discussion.. (2) The second challenge
    is to ensure efficient and effective information exchange between the perception
    component and the task-specific component. Ideally both the first-order and second-order
    information (e.g., the mean and the variance) should be able to flow back and
    forth between the two components. A natural way is to represent the perception
    component as a PGM and seamlessly connect it to the task-specific PGM, as done
    in ([RSDAE,](#bib.bib118) ; [CDL,](#bib.bib121) ; [DPFA,](#bib.bib24) ).
  prefs: []
  type: TYPE_NORMAL
- en: 'This survey provides a comprehensive overview of BDL with concrete models for
    various applications. The rest of the survey is organized as follows: In Section
    [2](#S2 "2\. Deep Learning ‣ A Survey on Bayesian Deep Learning"), we provide
    a review of some basic deep learning models. Section [3](#S3 "3\. Probabilistic
    Graphical Models ‣ A Survey on Bayesian Deep Learning") covers the main concepts
    and techniques for PGM. These two sections serve as the preliminaries for BDL,
    and the next section, Section [4](#S4 "4\. Bayesian Deep Learning ‣ A Survey on
    Bayesian Deep Learning"), demonstrates the rationale for the unified BDL framework
    and details various choices for implementing its *perception component* and *task-specific
    component*. Section [5](#S5 "5\. Concrete BDL Models and Applications ‣ A Survey
    on Bayesian Deep Learning") reviews the BDL models applied to various areas such
    as recommender systems, topic models, and control, showcasing how BDL works in
    supervised learning, unsupervised learning, and general representation learning,
    respectively. Section [6](#S6 "6\. Conclusions and Future Research ‣ A Survey
    on Bayesian Deep Learning") discusses some future research issues and concludes
    the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning normally refers to neural networks with more than two layers.
    To better understand deep learning, here we start with the simplest type of neural
    networks, multilayer perceptrons (MLP), as an example to show how conventional
    deep learning works. After that, we will review several other types of deep learning
    models based on MLP.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Multilayer Perceptrons
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Essentially a multilayer perceptron is a sequence of parametric nonlinear transformations.
    Suppose we want to train a multilayer perceptron to perform a regression task
    which maps a vector of $M$ dimensions to a vector of $D$ dimensions. We denote
    the input as a matrix ${\bf X}_{0}$ ($0$ means it is the $0$-th layer of the perceptron).
    The $j$-th row of ${\bf X}_{0}$, denoted as ${\bf X}_{0,j*}$, is an $M$-dimensional
    vector representing one data point. The target (the output we want to fit) is
    denoted as ${\bf Y}$. Similarly ${\bf Y}_{j*}$ denotes a $D$-dimensional row vector.
    The problem of learning an $L$-layer multilayer perceptron can be formulated as
    the following optimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min\limits_{\{{\bf W}_{l}\},\{{\bf b}_{l}\}}~{}$ | $\displaystyle\&#124;{\bf
    X}_{L}-{\bf Y}\&#124;_{F}+\lambda\sum\limits_{l}\&#124;{\bf W}_{l}\&#124;_{F}^{2}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | subject to | $\displaystyle{\bf X}_{l}=\sigma({\bf X}_{l-1}{\bf W}_{l}+{\bf
    b}_{l}),l=1,\dots,L-1$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle{\bf X}_{L}={\bf X}_{L-1}{\bf W}_{L}+{\bf b}_{L},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\sigma(\cdot)$ is an element-wise sigmoid function for a matrix and $\sigma(x)=\frac{1}{1+\exp(-x)}$.
    $\|\cdot\|_{F}$ denotes the Frobenius norm. The purpose of imposing $\sigma(\cdot)$
    is to allow nonlinear transformation. Normally other transformations like $\tanh(x)$
    and $\max(0,x)$ can be used as alternatives of the sigmoid function.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here ${\bf X}_{l}$ ($l=1,2,\dots,L-1$) is the hidden units. As we can see,
    ${\bf X}_{L}$ can be easily computed once ${\bf X}_{0}$, ${\bf W}_{l}$, and ${\bf
    b}_{l}$ are given. Since ${\bf X}_{0}$ is given as input, one only needs to learn
    ${\bf W}_{l}$ and ${\bf b}_{l}$ here. Usually this is done using backpropagation
    and stochastic gradient descent (SGD). The key is to compute the gradients of
    the objective function with respect to ${\bf W}_{l}$ and ${\bf b}_{l}$. Denoting
    the value of the objective function as $E$, one can compute the gradients using
    the chain rule as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\frac{\partial E}{\partial{\bf X}_{L}}$ | $\displaystyle=2({\bf
    X}_{L}-{\bf Y}),\;\;\;\;\frac{\partial E}{\partial{\bf X}_{l}}=(\frac{\partial
    E}{\partial{\bf X}_{l+1}}\circ{\bf X}_{l+1}\circ(1-{\bf X}_{l+1})){\bf W}_{l+1},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\frac{\partial E}{\partial{\bf W}_{l}}$ | $\displaystyle={\bf
    X}_{l-1}^{T}(\frac{\partial E}{\partial{\bf X}_{l}}\circ{\bf X}_{l}\circ(1-{\bf
    X}_{l})),\;\;\;\;\frac{\partial E}{\partial{\bf b}_{l}}=mean(\frac{\partial E}{\partial{\bf
    X}_{l}}\circ{\bf X}_{l}\circ(1-{\bf X}_{l}),1),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $l=1,\dots,L$ and the regularization terms are omitted. $\circ$ denotes
    the element-wise product and $mean(\cdot,1)$ is the matlab operation on matrices.
    In practice, we only use a small part of the data (e.g., $128$ data points) to
    compute the gradients for each update. This is called stochastic gradient descent.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, in conventional deep learning models, only ${\bf W}_{l}$ and
    ${\bf b}_{l}$ are free parameters, which we will update in each iteration of the
    optimization. ${\bf X}_{l}$ is not a free parameter since it can be computed exactly
    if ${\bf W}_{l}$ and ${\bf b}_{l}$ are given.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/27df31e056f4222846c15db24ab5bd4a.png)![Refer to caption](img/841c5520d5a4d2f25c8dd3c39dae3dbf.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1\. Left: A 2-layer SDAE with $L=4$. Right: A convolutional layer with
    $4$ input feature maps and $2$ output feature maps.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Autoencoders
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: An autoencoder (AE) is a feedforward neural network to encode the input into
    a more compact representation and reconstruct the input with the learned representation.
    In its simplest form, an autoencoder is no more than a multilayer perceptron with
    a bottleneck layer (a layer with a small number of hidden units) in the middle.
    The idea of autoencoders has been around for decades ([lecun-87,](#bib.bib63)
    ; [bourlard1988auto,](#bib.bib10) ; [hinton1994autoencoders,](#bib.bib43) ; [dlbook,](#bib.bib29)
    ) and abundant variants of autoencoders have been proposed to enhance representation
    learning including sparse AE ([poultney2006efficient,](#bib.bib88) ), contrastive
    AE ([rifai2011contractive,](#bib.bib93) ), and denoising AE ([DBLP:journals/jmlr/VincentLLBM10,](#bib.bib111)
    ). For more details, please refer to a nice recent book on deep learning ([dlbook,](#bib.bib29)
    ). Here we introduce a kind of multilayer denoising AE, known as stacked denoising
    autoencoders (SDAE), both as an example of AE variants and as background for its
    applications on BDL-based recommender systems in Section [4](#S4 "4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: 'SDAE ([DBLP:journals/jmlr/VincentLLBM10,](#bib.bib111) ) is a feedforward neural
    network for learning representations (encoding) of the input data by learning
    to predict the clean input itself in the output, as shown in Figure [1](#S2.F1
    "Figure 1 ‣ 2.1\. Multilayer Perceptrons ‣ 2\. Deep Learning ‣ A Survey on Bayesian
    Deep Learning")(left). The hidden layer in the middle, i.e., ${\bf X}_{2}$ in
    the figure, can be constrained to be a bottleneck to learn compact representations.
    The difference between traditional AE and SDAE is that the input layer ${\bf X}_{0}$
    is a *corrupted* version of the *clean* input data ${\bf X}_{c}$. Essentially
    an SDAE solves the following optimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\min\limits_{\{{\bf W}_{l}\},\{{\bf b}_{l}\}}$ | $\displaystyle\&#124;{\bf
    X}_{c}-{\bf X}_{L}\&#124;_{F}^{2}+\lambda\sum\limits_{l}\&#124;{\bf W}_{l}\&#124;_{F}^{2}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | subject to | $\displaystyle{\bf X}_{l}=\sigma({\bf X}_{l-1}{\bf W}_{l}+{\bf
    b}_{l}),l=1,\dots,L-1$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle{\bf X}_{L}={\bf X}_{L-1}{\bf W}_{L}+{\bf b}_{L},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\lambda$ is a regularization parameter. Here SDAE can be regarded as
    a multilayer perceptron for regression tasks described in the previous section.
    The input ${\bf X}_{0}$ of the MLP is the corrupted version of the data and the
    target ${\bf Y}$ is the clean version of the data ${\bf X}_{c}$. For example,
    ${\bf X}_{c}$ can be the raw data matrix, and we can randomly set $30\%$ of the
    entries in ${\bf X}_{c}$ to $0$ and get ${\bf X}_{0}$. In a nutshell, SDAE learns
    a neural network that takes the noisy data as input and recovers the clean data
    in the last layer. This is what ‘denoising’ in the name means. Normally, the output
    of the middle layer, i.e., ${\bf X}_{2}$ in Figure [1](#S2.F1 "Figure 1 ‣ 2.1\.
    Multilayer Perceptrons ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning")(left),
    would be used to compactly represent the data.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3\. Convolutional Neural Networks
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Convolutional neural networks (CNN) can be viewed as another variant of MLP.
    Different from AE, which is initially designed to perform dimensionality reduction,
    CNN is biologically inspired. According to ([hubel1968receptive,](#bib.bib53)
    ), two types of cells have been identified in the cat’s visual cortex. One is
    simple cells that respond maximally to specific patterns within their receptive
    field, and the other is complex cells with larger receptive field that are considered
    locally invariant to positions of patterns. Inspired by these findings, the two
    key concepts in CNN are then developed: convolution and max-pooling.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Convolution: In CNN, a feature map is the result of the convolution of the
    input and a linear filter, followed by some element-wise nonlinear transformation.
    The *input* here can be the raw image or the feature map from the previous layer.
    Specifically, with input ${\bf X}$, weights ${\bf W}^{k}$, bias $b^{k}$, the $k$-th
    feature map ${\bf H}^{k}$ can be obtained as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf H}_{ij}^{k}=\tanh(({\bf W}^{k}*{\bf X})_{ij}+b^{k}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Note that in the equation above we assume one single input feature map and multiple
    output feature maps. In practice, CNN often has multiple input feature maps as
    well due to its deep structure. A convolutional layer with $4$ input feature maps
    and $2$ output feature maps is shown in Figure [1](#S2.F1 "Figure 1 ‣ 2.1\. Multilayer
    Perceptrons ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning")(right).
  prefs: []
  type: TYPE_NORMAL
- en: 'Max-Pooling: Traditionally, a convolutional layer in CNN is followed by a max-pooling
    layer, which can be seen as a type of nonlinear downsampling. The operation of
    max-pooling is simple. For example, if we have a feature map of size $6\times
    9$, the result of max-pooling with a $3\times 3$ region would be a downsampled
    feature map of size $2\times 3$. Each entry of the downsampled feature map is
    the maximum value of the corresponding $3\times 3$ region in the $6\times 9$ feature
    map. Max-pooling layers can not only reduce computational cost by ignoring the
    non-maximal entries but also provide local translation invariance.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Putting it all together: Usually to form a complete and working CNN, the input
    would alternate between convolutional layers and max-pooling layers before going
    into an MLP for tasks such as classification or regression. One classic example
    is the LeNet-5 ([lecun1998gradient,](#bib.bib64) ), which alternates between $2$
    convolutional layers and $2$ max-pooling layers before going into a fully connected
    MLP for target tasks.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bef2440df62ad04fce7fdf009b014f32.png)![Refer to caption](img/a769afe3160383435d126879a8dd09a2.png)![Refer
    to caption](img/7c95e4383a5caf46919576108bc4a487.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2\. Left: A conventional feedforward neural network with one hidden
    layer, where ${\bf x}$ is the input, ${\bf z}$ is the hidden layer, and ${\bf
    o}$ is the output, ${\bf W}$ and ${\bf V}$ are the corresponding weights (biases
    are omitted here). Middle: A recurrent neural network with input $\{{\bf x}_{t}\}_{t=1}^{T}$,
    hidden states $\{{\bf h}_{t}\}_{t=1}^{T}$, and output $\{{\bf o}_{t}\}_{t=1}^{T}$.
    Right: An unrolled RNN which is equivalent to the one in Figure [2](#S2.F2 "Figure
    2 ‣ 2.3\. Convolutional Neural Networks ‣ 2\. Deep Learning ‣ A Survey on Bayesian
    Deep Learning")(middle). Here each node (e.g., ${\bf x}_{1}$, ${\bf h}_{1}$, or
    ${\bf o}_{1}$) is associated with one particular time step.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.4\. Recurrent Neural Network
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: When reading an article, one normally takes in one word at a time and try to
    understand the current word based on previous words. This is a recurrent process
    that needs short-term memory. Unfortunately conventional feedforward neural networks
    like the one shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.3\. Convolutional Neural
    Networks ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning")(left) fail
    to do so. For example, imagine we want to constantly predict the next word as
    we read an article. Since the feedforward network only computes the output ${\bf
    o}$ as ${\bf V}q({\bf W}{\bf x})$, where the function $q(\cdot)$ denotes element-wise
    nonlinear transformation, it is unclear how the network could naturally model
    the sequence of words to predict the next word.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.1\. Vanilla Recurrent Neural Network
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To solve the problem, we need a recurrent neural network ([dlbook,](#bib.bib29)
    ) instead of a feedforward one. As shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.3\.
    Convolutional Neural Networks ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep
    Learning")(middle), the computation of the current hidden states ${\bf h}_{t}$
    depends on the current input ${\bf x}_{t}$ (e.g., the $t$-th word) and the previous
    hidden states ${\bf h}_{t-1}$. This is why there is a loop in the RNN. It is this
    loop that enables short-term memory in RNNs. The ${\bf h}_{t}$ in the RNN represents
    what the network knows so far at the $t$-th time step. To see the computation
    more clearly, we can unroll the loop and represent the RNN as in Figure [2](#S2.F2
    "Figure 2 ‣ 2.3\. Convolutional Neural Networks ‣ 2\. Deep Learning ‣ A Survey
    on Bayesian Deep Learning")(right). If we use hyperbolic tangent nonlinearity
    ($\tanh$), the computation of output ${\bf o}_{t}$ will be as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf a}_{t}={\bf W}{\bf h}_{t-1}+{\bf Y}{\bf x}_{t}+{\bf
    b},\;\;\;\;\;{\bf h}_{t}=\tanh({\bf a}_{t}),\;\;\;\;\;{\bf o}_{t}={\bf V}{\bf
    h}_{t}+{\bf c},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\bf Y}$, ${\bf W}$, and ${\bf V}$ denote the weight matrices for input-to-hidden,
    hidden-to-hidden, and hidden-to-output connections, respectively, and ${\bf b}$
    and ${\bf c}$ are the corresponding biases. If the task is to classify the input
    data at each time step, we can compute the classification probability as ${\bf
    p}_{t}=\mbox{softmax}({\bf o}_{t})$ where
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mbox{softmax}({\bf q})=\frac{\exp({\bf q})}{\sum\limits_{i}\exp({\bf
    q}_{i})}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: '![Refer to caption](img/526e3c6bc7f93bf0fc019df5beb2b997.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 3\. The encoder-decoder architecture involving two LSTMs. The encoder
    LSTM (in the left rectangle) encodes the sequence ‘ABC’ into a representation
    and the decoder LSTM (in the right rectangle) recovers the sequence from the representation.
    ‘$’ marks the end of a sentence.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to feedforward networks, an RNN is trained with a generalized back-propagation
    algorithm called *back-propagation through time* (BPTT) ([dlbook,](#bib.bib29)
    ). Essentially the gradients are computed through the unrolled network as shown
    in Figure [2](#S2.F2 "Figure 2 ‣ 2.3\. Convolutional Neural Networks ‣ 2\. Deep
    Learning ‣ A Survey on Bayesian Deep Learning")(right) with shared weights and
    biases for all time steps.
  prefs: []
  type: TYPE_NORMAL
- en: 2.4.2\. Gated Recurrent Neural Network
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The problem with the vanilla RNN above is that the gradients propagated over
    many time steps are prone to vanish or explode, making the optimization notoriously
    difficult. In addition, the signal passing through the RNN decays exponentially,
    making it impossible to model long-term dependencies in long sequences. Imagine
    we want to predict the last word in the paragraph ‘I have many books … I like
    *reading*’. In order to get the answer, we need ‘long-term memory’ to retrieve
    information (the word ‘books’) at the start of the text. To address this problem,
    the long short-term memory model (LSTM) is designed as a type of gated RNN to
    model and accumulate information over a relatively long duration. The intuition
    behind LSTM is that when processing a sequence consisting of several subsequences,
    it is sometimes useful for the neural network to summarize or forget the old states
    before moving on to process the next subsequence ([dlbook,](#bib.bib29) ). Using
    $t=1\dots T_{j}$ to index the words in the sequence, the formulation of LSTM is
    as follows (we drop the item index $j$ for notational simplicity):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\displaystyle{\bf x}_{t}={\bf W}_{w}{\bf e}_{t},\;\;\;\;\;{\bf
    s}_{t}={\bf h}_{t-1}^{f}\odot{\bf s}_{t-1}+{\bf h}_{t-1}^{i}\odot\sigma({\bf Y}{\bf
    x}_{t-1}+{\bf W}{\bf h}_{t-1}+{\bf b}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where ${\bf x}_{t}$ is the word embedding of the $t$-th word, ${\bf W}_{w}$
    is a $K_{W}$-by-$S$ word embedding matrix, and ${\bf e}_{t}$ is the $1$-of-$S$
    representation, $\odot$ stands for the element-wise product operation between
    two vectors, $\sigma(\cdot)$ denotes the sigmoid function, ${\bf s}_{t}$ is the
    cell state of the $t$-th word, and ${\bf b}$, ${\bf Y}$, and ${\bf W}$ denote
    the biases, input weights, and recurrent weights respectively. The forget gate
    units ${\bf h}_{t}^{f}$ and the input gate units ${\bf h}_{t}^{i}$ in Equation
    ([1](#S2.E1 "In 2.4.2\. Gated Recurrent Neural Network ‣ 2.4\. Recurrent Neural
    Network ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning")) can be computed
    using their corresponding weights and biases ${\bf Y}^{f}$, ${\bf W}^{f}$, ${\bf
    Y}^{i}$, ${\bf W}^{i}$, ${\bf b}^{f}$, and ${\bf b}^{i}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf h}_{t}^{f}=\sigma({\bf Y}^{f}{\bf x}_{t}+{\bf W}^{f}{\bf
    h}_{t}+{\bf b}^{f}),\;\;\;\;\;{\bf h}_{t}^{i}=\sigma({\bf Y}^{i}{\bf x}_{t}+{\bf
    W}^{i}{\bf h}_{t}+{\bf b}^{i}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'The output depends on the output gate ${\bf h}_{t}^{o}$ which has its own weights
    and biases ${\bf Y}^{o}$, ${\bf W}^{o}$, and ${\bf b}^{o}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf h}_{t}=\tanh({\bf s}_{t})\odot{\bf h}_{t-1}^{o},\;\;\;\;\;{\bf
    h}_{t}^{o}=\sigma({\bf Y}^{o}{\bf x}_{t}+{\bf W}^{o}{\bf h}_{t}+{\bf b}^{o}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Note that in the LSTM, information of the processed sequence is contained in
    the cell states ${\bf s}_{t}$ and the output states ${\bf h}_{t}$, both of which
    are column vectors of length $K_{W}$.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to ([sutskever2014sequence,](#bib.bib108) ; [DBLP:conf/emnlp/ChoMGBBSB14,](#bib.bib16)
    ), we can use the output state and cell state at the last time step (${\bf h}_{T_{j}}$
    and ${\bf s}_{T_{j}}$) of the first LSTM as the initial output state and cell
    state of the second LSTM. This way the two LSTMs can be concatenated to form an
    encoder-decoder architecture, as shown in Figure [3](#S2.F3 "Figure 3 ‣ 2.4.1\.
    Vanilla Recurrent Neural Network ‣ 2.4\. Recurrent Neural Network ‣ 2\. Deep Learning
    ‣ A Survey on Bayesian Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: Note that there is a vast literature on deep learning and neural networks. The
    introduction in this section intends to serve only as the background of Bayesian
    deep learning. Readers are referred to ([dlbook,](#bib.bib29) ) for a comprehensive
    survey and more details.
  prefs: []
  type: TYPE_NORMAL
- en: 3\. Probabilistic Graphical Models
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Probabilistic Graphical Models (PGM) use diagrammatic representations to describe
    random variables and relationships among them. Similar to a graph that contains
    nodes (vertices) and links (edges), PGM has nodes to represent random variables
    and links to indicate probabilistic relationships among them.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are essentially two types of PGM, directed PGM (also known as Bayesian
    networks) and undirected PGM (also known as Markov random fields) ([PRML,](#bib.bib5)
    ). In this survey we mainly focus on directed PGM⁴⁴4For convenience, PGM stands
    for directed PGM in this survey unless specified otherwise.. For details on undirected
    PGM, readers are referred to ([PRML,](#bib.bib5) ).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ba60f9489eed5b62b8c54638158c12fb.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 4\. The probabilistic graphical model for LDA, $J$ is the number of documents,
    $D$ is the number of words in a document, and $K$ is the number of topics.
  prefs: []
  type: TYPE_NORMAL
- en: 'A classic example of PGM would be latent Dirichlet allocation (LDA), which
    is used as a topic model to analyze the generation of words and topics in documents ([LDA,](#bib.bib8)
    ). Usually PGM comes with a graphical representation of the model and a generative
    process to depict the story of how the random variables are generated step by
    step. Figure [4](#S3.F4 "Figure 4 ‣ 3.1\. Models ‣ 3\. Probabilistic Graphical
    Models ‣ A Survey on Bayesian Deep Learning") shows the graphical model for LDA
    and the corresponding generative process is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each document $j$ ($j=1,2,\dots,J$),
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw topic proportions $\theta_{j}\sim\mbox{Dirichlet}(\alpha)$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each word $w_{jn}$ of item (document) ${\bf w}_{j}$,
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw topic assignment $z_{jn}\sim\mbox{Mult}(\theta_{j})$.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw word $w_{jn}\sim\mbox{Mult}(\beta_{z_{jn}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: The generative process above provides the story of how the random variables
    are generated. In the graphical model in Figure [4](#S3.F4 "Figure 4 ‣ 3.1\. Models
    ‣ 3\. Probabilistic Graphical Models ‣ A Survey on Bayesian Deep Learning"), the
    shaded node denotes observed variables while the others are latent variables ($\theta$
    and ${\bf z}$) or parameters ($\alpha$ and $\beta$). Once the model is defined,
    learning algorithms can be applied to automatically learn the latent variables
    and parameters.
  prefs: []
  type: TYPE_NORMAL
- en: Due to its Bayesian nature, PGM such as LDA is easy to extend to incorporate
    other information or to perform other tasks. For example, following LDA, different
    variants of topic models have been proposed. ([DTM,](#bib.bib7) ; [cDTM,](#bib.bib113)
    ) are proposed to incorporate temporal information, and ([CTM,](#bib.bib6) ) extends
    LDA by assuming correlations among topics. ([onlineLDA,](#bib.bib44) ) extends
    LDA from the batch mode to the online setting, making it possible to process large
    datasets. On recommender systems, collaborative topic regression (CTR) ([CTR,](#bib.bib112)
    ) extends LDA to incorporate rating information and make recommendations. This
    model is then further extended to incorporate social information ([CTR-SMF,](#bib.bib89)
    ; [CTRSR,](#bib.bib115) ; [RCTR,](#bib.bib116) ).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1\. Summary of BDL Models with Different Learning Algorithms (MAP: Maximum
    a Posteriori, VI: Variational Inference, Hybrid MC: Hybrid Monte Carlo) and Different
    Variance Types (ZV: Zero-Variance, HV: Hyper-Variance, LV: Learnable-Variance).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Applications | Models | Variance of $\mbox{\boldmath$\Omega$\unboldmath}_{h}$
    | MAP | VI | Gibbs Sampling | Hybrid MC |'
  prefs: []
  type: TYPE_TB
- en: '| Recommender Systems | Collaborative Deep Learning (CDL) ([CDL,](#bib.bib121)
    ) | HV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bayesian CDL ([CDL,](#bib.bib121) ) | HV |  |  | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Marginalized CDL ([li2015deep,](#bib.bib66) ) | LV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Symmetric CDL ([li2015deep,](#bib.bib66) ) | LV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Collaborative Deep Ranking ([yingcollaborative,](#bib.bib131) ) | HV | ✓
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Collaborative Knowledge Base Embedding ([CKE,](#bib.bib132) ) | HV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Collaborative Recurrent AE ([CRAE,](#bib.bib122) ) | HV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Collaborative Variational Autoencoders ([ColVAE,](#bib.bib68) ) | HV |  |
    ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Topic Models | Relational SDAE | HV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Poisson Factor Analysis with Sigmoid Belief Networks ([DPFA,](#bib.bib24)
    ) | ZV |  |  | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Poisson Factor Analysis with Restricted Boltzmann Machine ([DPFA,](#bib.bib24)
    ) | ZV |  |  | ✓ | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Latent Dirichlet Allocation ([DLDA,](#bib.bib18) ) | LV |  |  |  | ✓
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | Dirichlet Belief Networks ([DirBN,](#bib.bib133) ) | LV |  |  | ✓ |  |'
  prefs: []
  type: TYPE_TB
- en: '| Control | Embed to Control ([watter2015embed,](#bib.bib125) ) | LV |  | ✓
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Variational Bayes Filters ([DVBF,](#bib.bib57) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Probabilistic Recurrent State-Space Models ([PR-SSM,](#bib.bib19) ) | LV
    |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Planning Networks ([PlaNet,](#bib.bib34) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Link Prediction | Relational Deep Learning ([RDL,](#bib.bib120) ) | LV |
    ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Graphite ([Graphite,](#bib.bib32) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Generative Latent Feature Relational Model ([SBGNN,](#bib.bib75) ) |
    LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| NLP | Sequence to Better Sequence ([S2BS,](#bib.bib77) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Quantifiable Sequence Editing ([QuaSE,](#bib.bib69) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Computer Vision | Asynchronous Temporal Fields ([ATF,](#bib.bib102) ) | LV
    |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Attend, Infer, Repeat (AIR) ([AIR,](#bib.bib20) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Fast AIR ([FastAIR,](#bib.bib105) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Sequential AIR ([SQAIR,](#bib.bib60) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Speech | Factorized Hierarchical VAE ([FHVAE,](#bib.bib48) ) | LV |  | ✓
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Scalable Factorized Hierarchical VAE ([SFHVAE,](#bib.bib47) ) | LV |  | ✓
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Gaussian Mixture Variational Autoencoders ([GMVAE,](#bib.bib49) ) | LV |  |
    ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Recurrent Poisson Process Units ([RPPU,](#bib.bib51) ) | LV | ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Graph Random Process ([DGP,](#bib.bib52) ) | LV | ✓ | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Time Series Forecasting | DeepAR ([DeepAR,](#bib.bib21) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DeepState ([DeepState,](#bib.bib90) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Spline Quantile Function RNN ([SQF-RNN,](#bib.bib27) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DeepFactor ([DeepFactor,](#bib.bib124) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Health Care | Deep Poisson Factor Models ([DPFM,](#bib.bib38) ) | LV |  |  |  |
    ✓ |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Markov Models ([DeepMarkov,](#bib.bib61) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Black-Box False Discovery Rate ([BBFDR,](#bib.bib110) ) | LV |  | ✓ |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Bidirectional Inference Networks ([BIN,](#bib.bib117) ) | LV | ✓ |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 3.2\. Inference and Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Strictly speaking, the process of finding the parameters (e.g., $\alpha$ and
    $\beta$ in Figure [4](#S3.F4 "Figure 4 ‣ 3.1\. Models ‣ 3\. Probabilistic Graphical
    Models ‣ A Survey on Bayesian Deep Learning")) is called learning and the process
    of finding the latent variables (e.g., $\theta$ and ${\bf z}$ in Figure [4](#S3.F4
    "Figure 4 ‣ 3.1\. Models ‣ 3\. Probabilistic Graphical Models ‣ A Survey on Bayesian
    Deep Learning")) given the parameters is called inference. However, given only
    the observed variables (e.g. ${\bf w}$ in Figure [4](#S3.F4 "Figure 4 ‣ 3.1\.
    Models ‣ 3\. Probabilistic Graphical Models ‣ A Survey on Bayesian Deep Learning")),
    learning and inference are often intertwined. Usually the learning and inference
    of LDA would alternate between the updates of latent variables (which correspond
    to inference) and the updates of the parameters (which correspond to learning).
    Once the learning and inference of LDA is completed, one could obtain the learned
    parameters $\alpha$ and $\beta$. If a new document comes, one can now fix the
    learned $\alpha$ and $\beta$ and then perform inference alone to find the topic
    proportions $\theta_{j}$ of the new document.⁵⁵5For convenience, we use ‘learning’
    to represent both ‘learning and inference’ in the following text.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to LDA, various learning and inference algorithms are available for
    each PGM. Among them, the most cost-effective one is probably maximum a posteriori
    (MAP), which amounts to maximizing the posterior probability of the latent variable.
    Using MAP, the learning process is equivalent to minimizing (or maximizing) an
    objective function with regularization. One famous example is the probabilistic
    matrix factorization (PMF) ([PMF,](#bib.bib96) ), where the learning of the graphical
    model is equivalent to factorizing a large matrix into two low-rank matrices with
    L2 regularization.
  prefs: []
  type: TYPE_NORMAL
- en: MAP, as efficient as it is, gives us only *point estimates* of latent variables
    (and parameters). In order to take the uncertainty into account and harness the
    full power of Bayesian models, one would have to resort to Bayesian treatments
    such as variational inference and Markov chain Monte Carlo (MCMC). For example,
    the original LDA uses variational inference to approximate the true posterior
    with factorized variational distributions ([LDA,](#bib.bib8) ). Learning of the
    latent variables and parameters then boils down to minimizing the KL-divergence
    between the variational distributions and the true posterior distributions. Besides
    variational inference, another choice for a Bayesian treatment is MCMC. For example,
    MCMC algorithms such as ([porteous2008fast,](#bib.bib86) ) have been proposed
    to learn the posterior distributions of LDA.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Bayesian Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: With the preliminaries on deep learning and PGM, we are now ready to introduce
    the general framework and some concrete examples of BDL. Specifically, in this
    section we will list some recent BDL models with applications on recommender systems,
    topic models, control, etc. A summary of these models is shown in Table [1](#S3.T1
    "Table 1 ‣ 3.1\. Models ‣ 3\. Probabilistic Graphical Models ‣ A Survey on Bayesian
    Deep Learning").
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. A Brief History of Bayesian Neural Networks and Bayesian Deep Learning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One topic highly related to BDL is Bayesian neural networks (BNN) or Bayesian
    treatments of neural networks. Similar to any Bayesian treatment, BNN imposes
    a prior on the neural network’s parameters and aims to learn a posterior distribution
    of these parameters. During the inference phrase, such a distribution is then
    marginalized out to produce final predictions. In general such a process is called
    Bayesian model averaging ([PRML,](#bib.bib5) ) and can be seen as learning an
    infinite number of (or a distribution over) neural networks and then aggregating
    the results through ensembling.
  prefs: []
  type: TYPE_NORMAL
- en: The study of BNN dates back to 1990s with notable works from ([mackay1992practical,](#bib.bib72)
    ; [hinton1993keeping,](#bib.bib42) ; [neal1995bayesian,](#bib.bib80) ). Over the
    years, a large body of works ([DBLP:conf/nips/Graves11,](#bib.bib31) ; [kingma2013auto,](#bib.bib58)
    ; [DBLP:conf/icml/Hernandez-Lobato15b,](#bib.bib39) ; [DBLP:conf/icml/BlundellCKW15,](#bib.bib9)
    ; [balan2015bayesian,](#bib.bib2) ; [MaxNPN,](#bib.bib100) ) have emerged to enable
    substantially better scalability and incorporate recent advancements of deep neural
    networks. Due to BNN’s long history, the term ‘Bayesian deep learning’ sometimes
    specifically refers to ‘Bayesian neural networks’ ([maddox2019simple,](#bib.bib73)
    ; [BDL-report,](#bib.bib128) ). In this survey, we instead use ‘Bayesian deep
    learning’ in a broader sense to refer to the probabilistic framework subsuming
    Bayesian neural networks. To see this, note that a BDL model with a *perception
    component* and an empty *task-specific component* is equivalent to a Bayesian
    neural network (details on these two components are discussed in Section [4.2](#S4.SS2
    "4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep
    Learning")).
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, though BNN started in 1990s, the study of BDL in a broader sense
    started roughly in 2014 ([RSDAE,](#bib.bib118) ; [CDL,](#bib.bib121) ; [DPFM,](#bib.bib38)
    ; [BDL-thesis,](#bib.bib114) ), slightly after the deep learning breakthrough
    in the ImageNet LSVRC contest in 2012 ([krizhevsky2012imagenet,](#bib.bib62) ).
    As we will see in later sections, BNN is usually used as a perception component
    in BDL models.
  prefs: []
  type: TYPE_NORMAL
- en: Today BDL is gaining more and more popularity, has found successful applications
    in areas such as recommender systems and computer vision, and appears as the theme
    of various conference workshops (e.g., the NeurIPS BDL workshop⁶⁶6[http://bayesiandeeplearning.org/](http://bayesiandeeplearning.org/)).
  prefs: []
  type: TYPE_NORMAL
- en: 4.2\. General Framework
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As mentioned in Section [1](#S1 "1\. Introduction ‣ A Survey on Bayesian Deep
    Learning"), BDL is a principled probabilistic framework with two seamlessly integrated
    components: a *perception component* and a *task-specific component*.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Two Components: Figure [5](#S4.F5 "Figure 5 ‣ 4.2\. General Framework ‣ 4\.
    Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning") shows the PGM of
    a simple BDL model as an example. The part inside the red rectangle on the left
    represents the perception component and the part inside the blue rectangle on
    the right is the task-specific component. Typically, the perception component
    would be a probabilistic formulation of a deep learning model with multiple nonlinear
    processing layers represented as a chain structure in the PGM. While the nodes
    and edges in the perception component are relatively simple, those in the task-specific
    component often describe more complex distributions and relationships among variables.
    Concretely, a task-specific component can take various forms. For example, it
    can be a typical Bayesian network (directed PGM) such as LDA, a deep Bayesian
    network ([BIN,](#bib.bib117) ), or a stochastic process ([ross1996stochastic,](#bib.bib94)
    ; [RPPU,](#bib.bib51) ), all of which can be represented in the form of PGM.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2cfab2827eb19b48e5b4aa756b994559.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 5\. The PGM for an example BDL. The red rectangle on the left indicates
    the perception component, and the blue rectangle on the right indicates the task-specific
    component. The hinge variable $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    H}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Three Variable Sets: There are three sets of variables in a BDL model: perception
    variables, hinge variables, and task variables. In this paper, we use $\mbox{\boldmath$\Omega$\unboldmath}_{p}$
    to denote the set of perception variables (e.g., ${\bf X}_{0}$, ${\bf X}_{1}$,
    and ${\bf W}_{1}$ in Figure [5](#S4.F5 "Figure 5 ‣ 4.2\. General Framework ‣ 4\.
    Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning")), which are the
    variables in the perception component. Usually $\mbox{\boldmath$\Omega$\unboldmath}_{p}$
    would include the weights and neurons in the probabilistic formulation of a deep
    learning model. $\mbox{\boldmath$\Omega$\unboldmath}_{h}$ is used to denote the
    set of hinge variables (e.g. ${\bf H}$ in Figure [5](#S4.F5 "Figure 5 ‣ 4.2\.
    General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning")).
    These variables directly interact with the perception component from the task-specific
    component. The set of task variables (e.g. ${\bf A}$, ${\bf B}$, and ${\bf C}$
    in Figure [5](#S4.F5 "Figure 5 ‣ 4.2\. General Framework ‣ 4\. Bayesian Deep Learning
    ‣ A Survey on Bayesian Deep Learning")), i.e., variables in the task-specific
    component without direct relation to the perception component, is denoted as $\mbox{\boldmath$\Omega$\unboldmath}_{t}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Generative Processes for Supervised and Unsupervised Learning: If the edges
    between the two components *point towards* $\mbox{\boldmath$\Omega$\unboldmath}_{h}$,
    the joint distribution of all variables can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $\displaystyle p(\mbox{\boldmath$\Omega$\unboldmath}_{p},\mbox{\boldmath$\Omega$\unboldmath}_{h},\mbox{\boldmath$\Omega$\unboldmath}_{t})=p(\mbox{\boldmath$\Omega$\unboldmath}_{p})p(\mbox{\boldmath$\Omega$\unboldmath}_{h}&#124;\mbox{\boldmath$\Omega$\unboldmath}_{p})p(\mbox{\boldmath$\Omega$\unboldmath}_{t}&#124;\mbox{\boldmath$\Omega$\unboldmath}_{h}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'If the edges between the two components *originate from* $\mbox{\boldmath$\Omega$\unboldmath}_{h}$,
    the joint distribution of all variables can be written as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $\displaystyle p(\mbox{\boldmath$\Omega$\unboldmath}_{p},\mbox{\boldmath$\Omega$\unboldmath}_{h},\mbox{\boldmath$\Omega$\unboldmath}_{t})=p(\mbox{\boldmath$\Omega$\unboldmath}_{t})p(\mbox{\boldmath$\Omega$\unboldmath}_{h}&#124;\mbox{\boldmath$\Omega$\unboldmath}_{t})p(\mbox{\boldmath$\Omega$\unboldmath}_{p}&#124;\mbox{\boldmath$\Omega$\unboldmath}_{h}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Equation ([2](#S4.E2 "In 4.2\. General Framework ‣ 4\. Bayesian Deep Learning
    ‣ A Survey on Bayesian Deep Learning")) and ([3](#S4.E3 "In 4.2\. General Framework
    ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning")) assume different
    generative processes for the data and correspond to different learning tasks.
    The former is usually used for supervised learning, where the perception component
    serves as a probabilistic (or Bayesian) representation learner to facilitate any
    downstream tasks (see Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian Deep Learning
    for Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey
    on Bayesian Deep Learning") for some examples). The latter is usually used for
    unsupervised learning, where the task-specific component provides structured constraints
    and domain knowledge to help the perception component learn stronger representations
    (see Section [5.2](#S5.SS2 "5.2\. Unsupervised Bayesian Deep Learning for Topic
    Models ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep
    Learning") for some examples).
  prefs: []
  type: TYPE_NORMAL
- en: Note that besides these two vanilla cases, it is possible for BDL to simultaneously
    have some edges between the two components pointing towards $\mbox{\boldmath$\Omega$\unboldmath}_{h}$
    and some originating from $\mbox{\boldmath$\Omega$\unboldmath}_{h}$, in which
    case the decomposition of the joint distribution would be more complex.
  prefs: []
  type: TYPE_NORMAL
- en: 'Independence Requirement: The introduction of hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}$
    and related conditional distributions simplifies the model (especially when $\mbox{\boldmath$\Omega$\unboldmath}_{h}$’s
    in-degree or out-degree is $1$), facilitate learning, and provides inductive bias
    to concentrate information inside $\mbox{\boldmath$\Omega$\unboldmath}_{h}$. Note
    that hinge variables are always in the task-specific component; the connections
    between hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}$ and the perception
    component (e.g., ${\bf X}_{4}\rightarrow{\bf H}$ in Figure [5](#S4.F5 "Figure
    5 ‣ 4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian
    Deep Learning")) should normally be independent for convenience of parallel computation
    in the perception component. For example, each row in ${\bf H}$ is related to
    only one corresponding row in ${\bf X}_{4}$. Although it is not mandatory in BDL
    models, meeting this requirement would significantly increase the efficiency of
    parallel computation in model training.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Flexibility of Variance for $\mbox{\boldmath$\Omega$\unboldmath}_{h}$: As mentioned
    in Section [1](#S1 "1\. Introduction ‣ A Survey on Bayesian Deep Learning"), one
    of BDL’s motivations is to model the *uncertainty of exchanging information* between
    the perception component and the task-specific component, which boils down to
    modeling the uncertainty related to $\mbox{\boldmath$\Omega$\unboldmath}_{h}$.
    For example, such uncertainty is reflected in the variance of the conditional
    density $p(\mbox{\boldmath$\Omega$\unboldmath}_{h}|\mbox{\boldmath$\Omega$\unboldmath}_{p})$
    in Equation ([2](#S4.E2 "In 4.2\. General Framework ‣ 4\. Bayesian Deep Learning
    ‣ A Survey on Bayesian Deep Learning"))⁷⁷7For models with the joint likelihood
    decomposed as in Equation ([3](#S4.E3 "In 4.2\. General Framework ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")), the uncertainty is reflected
    in the variance of $p(\mbox{\boldmath$\Omega$\unboldmath}_{p}|\mbox{\boldmath$\Omega$\unboldmath}_{h})$..
    According to the degree of flexibility, there are three types of variance for
    $\mbox{\boldmath$\Omega$\unboldmath}_{h}$ (for simplicity we assume the joint
    likelihood of BDL is Equation ([2](#S4.E2 "In 4.2\. General Framework ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")), $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{p\}$,
    $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{h\}$, and $p(\mbox{\boldmath$\Omega$\unboldmath}_{h}|\mbox{\boldmath$\Omega$\unboldmath}_{p})={\mathcal{N}}(h|\mu_{p},\sigma_{p}^{2})$
    in our example):'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zero-Variance: Zero-Variance (ZV) assumes no uncertainty during the information
    exchange between the two components. In the example, zero-variance means directly
    setting $\sigma_{p}^{2}$ to $0$.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hyper-Variance: Hyper-Variance (HV) assumes that uncertainty during the information
    exchange is defined through hyperparameters. In the example, HV means that $\sigma_{p}^{2}$
    is a manually tuned hyperparameter.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Learnable Variance: Learnable Variance (LV) uses learnable parameters to represent
    uncertainty during the information exchange. In the example, $\sigma_{p}^{2}$
    is the learnable parameter.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: As shown above, we can see that in terms of model flexibility, $\text{LV}>\text{HV}>\text{ZV}$.
    Normally, if properly regularized, an LV model outperforms an HV model, which
    is superior to a ZV model. In Table [1](#S3.T1 "Table 1 ‣ 3.1\. Models ‣ 3\. Probabilistic
    Graphical Models ‣ A Survey on Bayesian Deep Learning"), we show the types of
    variance for $\mbox{\boldmath$\Omega$\unboldmath}_{h}$ in different BDL models.
    Note that although each model in the table has a specific type, one can always
    adjust the models to devise their counterparts of other types. For example, while
    CDL in the table is an HV model, we can easily adjust $p(\mbox{\boldmath$\Omega$\unboldmath}_{h}|\mbox{\boldmath$\Omega$\unboldmath}_{p})$
    in CDL to devise its ZV and LV counterparts. In ([CDL,](#bib.bib121) ), the authors
    compare the performance of an HV CDL and a ZV CDL and find that the former performs
    significantly better, meaning that sophisticatedly modeling uncertainty between
    two components is essential for performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning Algorithms: Due to the nature of BDL, practical learning algorithms
    need to meet the following criteria:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They should be online algorithms in order to scale well for large datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: They should be efficient enough to scale linearly with the number of free parameters
    in the perception component.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Criterion (1) implies that conventional variational inference or MCMC methods
    are not applicable. Usually an online version of them is needed ([onlineVB,](#bib.bib45)
    ). Most SGD-based methods do not work either unless only MAP inference (as opposed
    to Bayesian treatments) is performed. Criterion (2) is needed because there are
    typically a large number of free parameters in the perception component. This
    means methods based on Laplace approximation ([mackay1992practical,](#bib.bib72)
    ) are not realistic since they involve the computation of a Hessian matrix that
    scales quadratically with the number of free parameters.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3\. Perception Component
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Ideally, the perception component should be a probabilistic or Bayesian neural
    network, in order to be compatible with the task-specific component, which is
    probabilistic in nature. This is to ensure the perception component’s built-in
    capability to handle uncertainty of parameters and its output.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in Section [4.1](#S4.SS1 "4.1\. A Brief History of Bayesian Neural
    Networks and Bayesian Deep Learning ‣ 4\. Bayesian Deep Learning ‣ A Survey on
    Bayesian Deep Learning"), the study of Bayesian neural networks dates back to
    1990s ([mackay1992practical,](#bib.bib72) ; [hinton1993keeping,](#bib.bib42) ;
    [neal1995bayesian,](#bib.bib80) ; [DBLP:conf/nips/Graves11,](#bib.bib31) ). However,
    pioneering work at that time was not widely adopted due to its lack of scalability.
    To address the this issue, there has been recent development such as restricted
    Boltzmann machine (RBM) ([DBN-fast,](#bib.bib41) ; [RBM,](#bib.bib40) ), probabilistic
    generalized stacked denoising autoencoders (pSDAE) ([RSDAE,](#bib.bib118) ; [CDL,](#bib.bib121)
    ), variational autoencoders (VAE) ([kingma2013auto,](#bib.bib58) ), probabilistic
    back-propagation (PBP) ([DBLP:conf/icml/Hernandez-Lobato15b,](#bib.bib39) ), Bayes
    by Backprop (BBB) ([DBLP:conf/icml/BlundellCKW15,](#bib.bib9) ), Bayesian dark
    knowledge (BDK) ([balan2015bayesian,](#bib.bib2) ), and natural-parameter networks
    (NPN) ([NPN,](#bib.bib119) ).
  prefs: []
  type: TYPE_NORMAL
- en: More recently, generative adversarial networks (GAN) ([GAN,](#bib.bib30) ) prevail
    as a new training scheme for training neural networks and have shown promise in
    generating photo-realistic images. Later on, Bayesian formulations (as well as
    related theoretical results) for GAN have also been proposed ([GAN,](#bib.bib30)
    ; [ProbGAN,](#bib.bib37) ). These models are also potential building blocks as
    the BDL framework’s perception component.
  prefs: []
  type: TYPE_NORMAL
- en: In this subsection, we mainly focus on the introduction of recent Baysian neural
    networks such as RBM, pSDAE, VAE, and NPN. We refer the readers to ([dlbook,](#bib.bib29)
    ) for earlier work in this direction.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.1\. Restricted Boltzmann Machine
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Restricted Boltzmann Machine (RBM) is a special kind of BNN in that (1) it
    is not trained with back-propagation (BP) and that (2) its hidden neurons are
    binary. Specifically, RBM defines the following energy:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle E({\bf v},{\bf h})=-{\bf v}^{T}{\bf W}{\bf h}-{\bf v}^{T}{\bf
    b}-{\bf h}^{T}{\bf a},$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where ${\bf v}$ denotes visible (observed) neurons, and ${\bf h}$ denotes binary
    hidden neurons. ${\bf W}$, ${\bf a}$, and ${\bf b}$ are learnable weights. The
    energy function leads to the following conditional distributions:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (4) |  | $\displaystyle p({\bf v}&#124;{\bf h})=\frac{\exp(-E({\bf v},{\bf
    h}))}{\sum\limits_{{\bf v}}\exp(-E({\bf v},{\bf h}))},\;\;\;\;\;\;\;\;p({\bf h}&#124;{\bf
    v})=\frac{\exp(-E({\bf v},{\bf h}))}{\sum\limits_{{\bf h}}\exp(-E({\bf v},{\bf
    h}))}$ |  |'
  prefs: []
  type: TYPE_TB
- en: RBM is trained using ‘Contrastive Divergence’ ([DBN-fast,](#bib.bib41) ) rather
    than BP. Once trained, RBM can infer ${\bf v}$ or ${\bf h}$ by marginalizing out
    other neurons. One can also stack layers of RBM to form a deep belief network
    (DBN) ([DBN-speech,](#bib.bib76) ), use multiple branches of deep RBN for multimodal
    learning ([MultRBM,](#bib.bib104) ), or combine DBN with convolutional layers
    to form a convolutional DBN ([ConvDBN,](#bib.bib65) ).
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.2\. Probabilistic Generalized SDAE
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Following the introduction of SDAE in Section [2.2](#S2.SS2 "2.2\. Autoencoders
    ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning"), if we assume that
    both the clean input ${\bf X}_{c}$ and the corrupted input ${\bf X}_{0}$ are observed,
    similar to ([PRML,](#bib.bib5) ; [mackay1992practical,](#bib.bib72) ; [DBLP:conf/nips/BengioYAV13,](#bib.bib4)
    ; [nmSDAE,](#bib.bib13) ), we can define the following generative process of the
    probabilistic SDAE:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each layer $l$ of the SDAE network,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each column $n$ of the weight matrix ${\bf W}_{l}$, draw ${\bf W}_{l,*n}\sim{\mathcal{N}}({\bf
    0},\lambda_{w}^{-1}{\bf I}_{K_{l}}).$
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the bias vector ${\bf b}_{l}\sim{\mathcal{N}}({\bf 0},\lambda_{w}^{-1}{\bf
    I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each row $j$ of ${\bf X}_{l}$, draw
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (5) |  | $\displaystyle{\bf X}_{l,j*}\sim{\mathcal{N}}(\sigma({\bf X}_{l-1,j*}{\bf
    W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K_{l}}).$ |  |'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_TB
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item $j$, draw a clean input⁸⁸8Note that while generation of the *clean*
    input ${\bf X}_{c}$ from ${\bf X}_{L}$ is part of the generative process of the
    Bayesian SDAE, generation of the *noise-corrupted* input ${\bf X}_{0}$ from ${\bf
    X}_{c}$ is an artificial noise injection process to help the SDAE learn a more
    robust feature representation. ${\bf X}_{c,j*}\sim{\mathcal{N}}({\bf X}_{L,j*},\lambda_{n}^{-1}{\bf
    I}_{B}).$
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Note that if $\lambda_{s}$ goes to infinity, the Gaussian distribution in Equation
    ([5](#S4.E5 "In item 1c ‣ item 1 ‣ 4.3.2\. Probabilistic Generalized SDAE ‣ 4.3\.
    Perception Component ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep
    Learning")) will become a Dirac delta distribution ([strichartz2003guide,](#bib.bib106)
    ) centered at $\sigma({\bf X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l})$, where $\sigma(\cdot)$
    is the sigmoid function, and the model will degenerate into a Bayesian formulation
    of vanilla SDAE. This is why we call it ‘generalized’ SDAE.
  prefs: []
  type: TYPE_NORMAL
- en: The first $L/2$ layers of the network act as an encoder and the last $L/2$ layers
    act as a decoder. Maximization of the posterior probability is equivalent to minimization
    of the reconstruction error with weight decay taken into consideration.
  prefs: []
  type: TYPE_NORMAL
- en: Following pSDAE, both its convolutional version ([CKE,](#bib.bib132) ) and its
    recurrent version ([CRAE,](#bib.bib122) ) have been proposed with applications
    in knowledge base embedding and recommender systems.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.3\. Variational Autoencoders
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Variational Autoencoders (VAE) ([kingma2013auto,](#bib.bib58) ) essentially
    tries to learn parameters $\phi$ and $\theta$ that maximize the evidence lower
    bound (ELBO):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $\displaystyle\mathcal{L}_{vae}=E_{q_{\phi}({\bf z}&#124;{\bf x})}[\log
    p_{\theta}({\bf x}&#124;{\bf z})]-KL(q_{\phi}({\bf z}&#124;{\bf x})\&#124;p({\bf
    z})),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $q_{\phi}({\bf z}|{\bf x})$ is the encoder parameterized by $\phi$ and
    $p_{\theta}({\bf x}|{\bf z})$ is the decoder parameterized by $\theta$. The negation
    of the first term is similar to the reconstrunction error in vanilla AE, while
    the KL divergence works as a regularization term for the encoder. During training
    $q_{\phi}({\bf z}|{\bf x})$ will output the mean and variance of a Gaussian distribution,
    from which ${\bf z}$ is sampled via the reparameterization trick. Usually $q_{\phi}({\bf
    z}|{\bf x})$ is parameterized by an MLP with two branches, one producing the mean
    and the other producing the variance.
  prefs: []
  type: TYPE_NORMAL
- en: Similar to the case of pSDAE, various VAE variants have been proposed. For example,
    Importance weighted Autoencoders (IWAE) ([IWAE,](#bib.bib11) ) derived a tighter
    lower bound via importance weighting, ([LSTM-VAE-CNN,](#bib.bib129) ) combined
    LSTM, VAE, and dilated CNN for text modeling, ([VRNN,](#bib.bib17) ) proposed
    a recurrent version of VAE dubbed variational RNN (VRNN).
  prefs: []
  type: TYPE_NORMAL
- en: 4.3.4\. Natural-Parameter Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Different from vanilla NN which usually takes deterministic input, NPN ([NPN,](#bib.bib119)
    ) is a probabilistic NN taking distributions as input. The input distributions
    go through layers of linear and nonlinear transformation to produce output distributions.
    In NPN, all hidden neurons and weights are also distributions expressed in closed
    form. Note that this is in contrast to VAE where only the middle layer output
    ${\bf z}$ is a distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a simple example, in a vanilla linear NN $f_{w}(x)=wx$ takes a scalar $x$
    as input and computes the output based on a scalar parameter $w$; a corresponding
    Gaussian NPN would assume $w$ is drawn from a Gaussian distribution $\mathcal{N}(w_{m},w_{s})$
    and that $x$ is drawn from $\mathcal{N}(x_{m},x_{s})$ ($x_{s}$ is set to $0$ when
    the input is deterministic). With $\theta=(w_{m},w_{s})$ as a learnable parameter
    pair, NPN will then compute the mean and variance of the output Gaussian distribution
    $\mu_{\theta}(x_{m},x_{s})$ and $s_{\theta}(x_{m},x_{s})$ in closed form (bias
    terms are ignored for clarity) as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (7) |  | $\displaystyle\mu_{\theta}(x_{m},x_{s})$ | $\displaystyle=E[wx]=x_{m}w_{m},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (8) |  | $\displaystyle s_{\theta}(x_{m},x_{s})$ | $\displaystyle=D[wx]=x_{s}w_{s}+x_{s}w_{m}^{2}+x_{m}^{2}w_{s},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Hence the output of this Gaussian NPN is a tuple $(\mu_{\theta}(x_{m},x_{s}),s_{\theta}(x_{m},x_{s}))$
    representing a Gaussian distribution instead of a single value. Input variance
    $x_{s}$ to NPN can be set to $0$ if not available. Note that since $s_{\theta}(x_{m},0)=x_{m}^{2}w_{s}$,
    $w_{m}$ and $w_{s}$ can still be learned even if $x_{s}=0$ for all data points.
    The derivation above is generalized to handle vectors and matrices in practice ([NPN,](#bib.bib119)
    ). Besides Gaussian distributions, NPN also support other exponential-family distributions
    such as Poisson distributions and gamma distributions ([NPN,](#bib.bib119) ).
  prefs: []
  type: TYPE_NORMAL
- en: Following NPN, a light-weight version ([LightNPN,](#bib.bib26) ) was proposed
    to speed up the training and inference process. Another variant, MaxNPN ([MaxNPN,](#bib.bib100)
    ), extended NPN to handle max-pooling and categorical layers. ConvNPN ([ConvNPN,](#bib.bib87)
    ) enables convolutional layers in NPN. In terms of model quantization and compression,
    BinaryNPN ([BinaryNPN,](#bib.bib107) ) was also proposed as NPN’s binary version
    to achieve better efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Task-Specific Component
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this subsection, we introduce different forms of task-specific components.
    The purpose of a task-specific component is to incorporate probabilistic prior
    knowledge into the BDL model. Such knowledge can be naturally represented using
    PGM. Concretely, it can be a typical (or shallow) Bayesian network ([BayesNetBook,](#bib.bib54)
    ; [PRML,](#bib.bib5) ), a bidirectional inference network ([BIN,](#bib.bib117)
    ), or a stochastic process ([ross1996stochastic,](#bib.bib94) ).
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.1\. Bayesian Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Bayesian networks are the most common choice for a task-specific component.
    As mentioned in Section [3](#S3 "3\. Probabilistic Graphical Models ‣ A Survey
    on Bayesian Deep Learning"), Bayesian networks can naturally represent conditional
    dependencies and handle uncertainty. Besides LDA introduced above, a more straightforward
    example is probabilistic matrix factorization (PMF) ([PMF,](#bib.bib96) ), where
    one uses a Bayesian network to describe the conditional dependencies among users,
    items, and ratings. Specifically, PMF assumes the following generative process:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each item $j$, draw a latent item vector: ${\bf v}_{i}\sim{\mathcal{N}}({\bf
    0},\lambda_{v}^{-1}{\bf I}_{K}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each user $i$, draw a latent user vector: ${\bf u}_{i}\sim{\mathcal{N}}({\bf
    0},\lambda_{u}^{-1}{\bf I}_{K}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each user-item pair $(i,j)$, draw a rating: ${\bf R}_{ij}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j},{\bf C}_{ij}^{-1}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'In the generative process above, ${\bf C}_{ij}^{-1}$ is the corresponding variance
    for the rating ${\bf R}_{ij}$. Using MAP estimates, learning PMF amounts to maximize
    the following log-likelihood of $p(\{{\bf u}_{i}\},\{{\bf v}_{j}\}|\{{\bf R}_{ij}\},\{{\bf
    C}_{ij}\},\lambda_{u},\lambda_{v})$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=-\frac{\lambda_{u}}{2}\sum\limits_{i}\&#124;{\bf
    u}_{i}\&#124;_{2}^{2}-\frac{\lambda_{v}}{2}\sum\limits_{j}\&#124;{\bf v}_{j}\&#124;_{2}^{2}-\sum\limits_{i,j}\frac{{\bf
    C}_{ij}}{2}({\bf R}_{ij}-{\bf u}_{i}^{T}{\bf v}_{j})^{2},$ |  |'
  prefs: []
  type: TYPE_TB
- en: Note that one can also impose another layer of priors on the hyperparameters
    with a fully Bayesian treatment. For example, ([BPMF,](#bib.bib97) ) imposes priors
    on the precision matrix of latent factors and learn the Bayesian PMF with Gibbs
    sampling.
  prefs: []
  type: TYPE_NORMAL
- en: In Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian Deep Learning for Recommender
    Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep
    Learning"), we will show how PMF can be used as a task-specific component along
    with a perception component defined to significantly improve recommender systems’
    performance.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.2\. Bidirectional Inference Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Typical Bayesian networks assume ‘shallow’ conditional dependencies among random
    variables. In the generative process, one random variable (which can be either
    latent or observed) is usually drawn from a conditional distribution parameterized
    by the linear combination of its parent variables. For example, in PMF the rating
    ${\bf R}_{ij}$ is drawn from a Gaussian distribution mainly parameterized by the
    linear combination of ${\bf u}_{i}$ and ${\bf v}_{j}$, i.e., ${\bf R}_{ij}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j},{\bf C}_{ij}^{-1})$.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bceb1d41d2e5f6b07d3bb320a80b0414.png)![Refer to caption](img/66fcc7c07ec74be81f42e6a410b8e137.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6\. Left: A simple example of BIN with each conditional distribution
    parameterized by a Bayesian neural networks (BNN) or simply a probabilistic neural
    network. Right: Another example BIN. Shaded and transparent nodes indicate observed
    and unobserved variables, respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: Such ‘shallow’ and linear structures can be replaced with nonlinear or even
    deep nonlinear structures to form a *deep Bayesian network*. As an example, bidirectional
    inference network (BIN) ([BIN,](#bib.bib117) ) is a class of deep Bayesian networks
    that enable deep nonlinear structures in each conditional distribution, while
    retaining the ability to incorporate prior knowledge as Bayesian networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, Figure [6](#S4.F6 "Figure 6 ‣ 4.4.2\. Bidirectional Inference
    Networks ‣ 4.4\. Task-Specific Component ‣ 4\. Bayesian Deep Learning ‣ A Survey
    on Bayesian Deep Learning")(left) shows a BIN, where each conditional distribution
    is parameterized by a Bayesian neural network. Specifically, this example assumes
    the following factorization:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p(v_{1},v_{2},v_{3}&#124;X)=p(v_{1}&#124;X)p(v_{2}&#124;X,v_{1})p(v_{3}&#124;X,v_{1},v_{2}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: A vanilla Bayesian network parameterizes each distribution with simple linear
    operations. For example, $p(v_{2}|X,v_{1})={\mathcal{N}}(v_{2}|Xw_{0}+v_{1}w_{1}+b,\sigma^{2})$).
    In contrast, BIN (as a deep Bayesian network) uses a BNN. For example, BIN has
    $p(v_{2}|X,v_{1})={\mathcal{N}}(v_{2}|\mu_{\theta}(X,v_{1}),s_{\theta}(X,v_{1}))$,
    where $\mu_{\theta}(X,v_{1})$ and $s_{\theta}(X,v_{1})$ are the output mean and
    variance of the BNN. The inference and learning of such a deep Bayesian network
    is done by performing BP across all BNNs (e.g., BNN 1, 2, and 3 in Figure [6](#S4.F6
    "Figure 6 ‣ 4.4.2\. Bidirectional Inference Networks ‣ 4.4\. Task-Specific Component
    ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning")(left)) ([BIN,](#bib.bib117)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: Compared to vanilla (shallow) Bayesian networks, deep Bayesian networks such
    as BIN make it possible to handle deep and nonlinear conditional dependencies
    effectively and efficiently. Besides, with BNN as building blocks, task-specific
    components based on deep Bayesian networks can better work with the perception
    component which is usually a BNN as well. Figure [6](#S4.F6 "Figure 6 ‣ 4.4.2\.
    Bidirectional Inference Networks ‣ 4.4\. Task-Specific Component ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")(right) shows a more complicated
    case with both observed (shaded nodes) and unobserved (transparent nodes) variables.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4.3\. Stochastic Processes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Besides vanilla Bayesian networks and deep Bayesian networks, a task-specific
    component can also take the form of a stochastic process ([ross1996stochastic,](#bib.bib94)
    ). For example, a Wiener process can naturally describe a continuous-time Brownian
    motion model ${\bf x}_{t+u}|{\bf x}_{t}\sim{\mathcal{N}}({\bf x}_{t},\lambda u{\bf
    I}$), where ${\bf x}_{t+u}$ and ${\bf x}_{t}$ are the states at time $t$ and $t+u$,
    respectively. In the graphical model literature, such a process has been used
    to model the continuous-time topic evolution of articles over time ([cDTM,](#bib.bib113)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: Another example is to model phonemes’ boundary positions using a Poisson process
    in automatic speech recognition (ASR) ([RPPU,](#bib.bib51) ). Note that this is
    a fundamental problem in ASR since speech is no more than a sequence of phonemes.
    Specifically, a Poisson process defines the generative process $\Delta t_{i}=t_{i}-t_{i-1}\sim
    g(\lambda(t))$, with $\mathcal{T}=\{t_{1},t_{2},\dots,t_{N}\}$ as the set of boundary
    positions, and $g(\lambda(t))$ is a exponential distribution with the parameter
    $\lambda(t)$ (also known as the intensity). Such a stochastic process naturally
    models the occurrence of phoneme boundaries in continuous time. The parameter
    $\lambda(t)$ can be the output of a neural network taking raw speech signals as
    input ([RPPU,](#bib.bib51) ; [IFL,](#bib.bib99) ; [NN-SP,](#bib.bib83) ).
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, stochastic processes can be seen as a type of dynamic Bayesian
    networks. To see this, we can rewrite the Poisson process above in an equivalent
    form, where given $t_{i-1}$, the probability that $t_{i}$ has not occurred at
    time $t$, $P(t_{i}>t)=\exp(\int_{t_{i-1}}^{t}-\lambda(t)dt)$. Obviously both the
    Wiener process and the Poisson process are Markovian and can be represented with
    a dynamic Bayesian network ([murphybook,](#bib.bib78) ).
  prefs: []
  type: TYPE_NORMAL
- en: For clarity, we focus on using vanilla Bayesian networks as task-specific components
    in Section [5](#S5 "5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian
    Deep Learning"); they can be naturally replaced with other types of task-specific
    components to represent different prior knowledge if necessary.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Concrete BDL Models and Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss how the BDL framework can facilitate supervised
    learning, unsupervised learning, and representation learning in general. Concretely
    we use examples in domains such as recommender systems, topic models, control,
    etc.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Supervised Bayesian Deep Learning for Recommender Systems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Despite the successful applications of deep learning on natural language processing
    and computer vision, very few attempts have been made to develop deep learning
    models for collaborative filtering (CF) before the emergence of BDL. ([DBLP:conf/icml/SalakhutdinovMH07,](#bib.bib98)
    ) uses restricted Boltzmann machines instead of the conventional matrix factorization
    formulation to perform CF and ([DBLP:conf/icml/GeorgievN13,](#bib.bib28) ) extends
    this work by incorporating user-user and item-item correlations. Although these
    methods involve both deep learning and CF, they actually belong to CF-based methods
    because they ignore users’ or items’ content information, which is crucial for
    accurate recommendation. ([DBLP:conf/icassp/SainathKSAR13,](#bib.bib95) ) uses
    low-rank matrix factorization in the last weight layer of a deep network to significantly
    reduce the number of model parameters and speed up training, but it is for classification
    instead of recommendation tasks. On music recommendation, ([DBLP:conf/nips/OordDS13,](#bib.bib84)
    ; [DBLP:conf/mm/WangW14,](#bib.bib123) ) directly use conventional CNN or deep
    belief networks (DBN) to assist representation learning for content information,
    but the deep learning components of their models are deterministic without modeling
    the noise and hence they are less robust. The models achieve performance boost
    mainly by loosely coupled methods without exploiting the interaction between content
    information and ratings. Besides, the CNN is linked directly to the rating matrix,
    which means the models will perform poorly due to serious overfitting when the
    ratings are sparse.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.1\. Collaborative Deep Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To address the challenges above, a hierarchical Bayesian model called collaborative
    deep learning (CDL) as a novel tightly coupled method for recommender systems
    is introduced in ([CDL,](#bib.bib121) ). Based on a Bayesian formulation of SDAE,
    CDL tightly couples deep representation learning for the content information and
    collaborative filtering for the rating (feedback) matrix, allowing two-way interaction
    between the two. From BDL’s perspective, a probabilistic SDAE as the perception
    component is tightly coupled with a probabilistic graphical model as the task-specific
    component. Experiments show that CDL significantly improves upon the state of
    the art.
  prefs: []
  type: TYPE_NORMAL
- en: In the following text, we will start with the introduction of the notation used
    during our presentation of CDL. After that we will review the design and learning
    of CDL.
  prefs: []
  type: TYPE_NORMAL
- en: 'Notation and Problem Formulation: Similar to the work in ([CTR,](#bib.bib112)
    ), the recommendation task considered in CDL takes implicit feedback ([DBLP:conf/icdm/HuKV08,](#bib.bib50)
    ) as the training and test data. The entire collection of $J$ items (articles
    or movies) is represented by a $J$-by-$B$ matrix ${\bf X}_{c}$, where row $j$
    is the bag-of-words vector ${\bf X}_{c,j*}$ for item $j$ based on a vocabulary
    of size $B$. With $I$ users, we define an $I$-by-$J$ binary rating matrix ${\bf
    R}=[{\bf R}_{ij}]_{I\times J}$. For example, in the dataset *citeulike-a* ([CTR,](#bib.bib112)
    ; [CTRSR,](#bib.bib115) ; [CDL,](#bib.bib121) ) ${\bf R}_{ij}=1$ if user $i$ has
    article $j$ in his or her personal library and ${\bf R}_{ij}=0$ otherwise. Given
    part of the ratings in ${\bf R}$ and the content information ${\bf X}_{c}$, the
    problem is to predict the other ratings in ${\bf R}$. Note that although CDL in
    its current from focuses on movie recommendation (where plots of movies are considered
    as content information) and article recommendation like ([CTR,](#bib.bib112) )
    in this section, it is general enough to handle other recommendation tasks (e.g.,
    tag recommendation).'
  prefs: []
  type: TYPE_NORMAL
- en: The matrix ${\bf X}_{c}$ plays the role of clean input to the SDAE while the
    noise-corrupted matrix, also a $J$-by-$B$ matrix, is denoted by ${\bf X}_{0}$.
    The output of layer $l$ of the SDAE is denoted by ${\bf X}_{l}$ which is a $J$-by-$K_{l}$
    matrix. Similar to ${\bf X}_{c}$, row $j$ of ${\bf X}_{l}$ is denoted by ${\bf
    X}_{l,j*}$. ${\bf W}_{l}$ and ${\bf b}_{l}$ are the weight matrix and bias vector,
    respectively, of layer $l$, ${\bf W}_{l,*n}$ denotes column $n$ of ${\bf W}_{l}$,
    and $L$ is the number of layers. For convenience, we use ${\bf W}^{+}$ to denote
    the collection of all layers of weight matrices and biases. Note that an $L/2$-layer
    SDAE corresponds to an $L$-layer network.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4827b82264d29eb9c941f21c9081035d.png)![Refer to caption](img/aae5d09904a009fc726ad18ed40e3f3e.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7\. On the left is the graphical model of CDL. The part inside the dashed
    rectangle represents an SDAE. An example SDAE with $L=2$ is shown. On the right
    is the graphical model of the degenerated CDL. The part inside the dashed rectangle
    represents the encoder of an SDAE. An example SDAE with $L=2$ is shown on its
    right. Note that although $L$ is still $2$, the decoder of the SDAE vanishes.
    To prevent clutter, we omit all variables ${\bf x}_{l}$ except ${\bf x}_{0}$ and
    ${\bf x}_{L/2}$ in the graphical models.
  prefs: []
  type: TYPE_NORMAL
- en: 'Collaborative Deep Learning: Using the probabilistic SDAE in Section [4.3.2](#S4.SS3.SSS2
    "4.3.2\. Probabilistic Generalized SDAE ‣ 4.3\. Perception Component ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning") as a component, the generative
    process of CDL is defined as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each layer $l$ of the SDAE network,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each column $n$ of the weight matrix ${\bf W}_{l}$, draw ${\bf W}_{l,*n}\sim{\mathcal{N}}({\bf
    0},\lambda_{w}^{-1}{\bf I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the bias vector ${\bf b}_{l}\sim{\mathcal{N}}({\bf 0},\lambda_{w}^{-1}{\bf
    I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each row $j$ of ${\bf X}_{l}$, draw ${\bf X}_{l,j*}\sim{\mathcal{N}}(\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K_{l}}).$
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item $j$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a clean input ${\bf X}_{c,j*}\sim{\mathcal{N}}({\bf X}_{L,j*},\lambda_{n}^{-1}{\bf
    I}_{J}$).
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw the latent item offset vector $\mbox{\boldmath$\epsilon$\unboldmath}_{j}\sim{\mathcal{N}}({\bf
    0},\lambda_{v}^{-1}{\bf I}_{K})$ and then set the latent item vector: ${\bf v}_{j}=\mbox{\boldmath$\epsilon$\unboldmath}_{j}+{\bf
    X}_{\frac{L}{2},j*}^{T}.$'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a latent user vector for each user $i$: ${\bf u}_{i}\sim{\mathcal{N}}({\bf
    0},\lambda_{u}^{-1}{\bf I}_{K}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a rating ${\bf R}_{ij}$ for each user-item pair $(i,j)$: <math id="S5.I1.i4.p1.3.m3.1"
    class="ltx_Math" alttext="{\bf R}_{ij}\sim{\mathcal{N}}({\bf u}_{i}^{T}{\bf v}_{j},{\bf
    C}_{ij}^{-1}).\\'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '" display="inline"><semantics id="S5.I1.i4.p1.3.m3.1a"><mrow id="S5.I1.i4.p1.3.m3.1.1.1"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.cmml"><mrow id="S5.I1.i4.p1.3.m3.1.1.1.1" xref="S5.I1.i4.p1.3.m3.1.1.1.1.cmml"><msub
    id="S5.I1.i4.p1.3.m3.1.1.1.1.4" xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.cmml"><mi id="S5.I1.i4.p1.3.m3.1.1.1.1.4.2"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.2.cmml">𝐑</mi><mrow id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.cmml"><mi id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.2"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em"
    id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.1" xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.1.cmml">​</mo><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.3.cmml">j</mi></mrow></msub><mo
    id="S5.I1.i4.p1.3.m3.1.1.1.1.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.3.cmml">∼</mo><mrow
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic"
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.4" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.4.cmml">𝒩</mi><mo
    lspace="0em" rspace="0em" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.3.cmml">​</mo><mrow
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.3.cmml"><mo
    stretchy="false" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.3.cmml">(</mo><mrow
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.cmml"><msubsup
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.cmml"><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.2.cmml">𝐮</mi><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.3.cmml">i</mi><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.3.cmml">T</mi></msubsup><mo
    lspace="0em" rspace="0em" id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.1" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.1.cmml">​</mo><msub
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.cmml"><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.2.cmml">𝐯</mi><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.3.cmml">j</mi></msub></mrow><mo
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.4" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.3.cmml">,</mo><msubsup
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.cmml"><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.2.cmml">𝐂</mi><mrow
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.cmml"><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.2.cmml">i</mi><mo
    lspace="0em" rspace="0em" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.1" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.1.cmml">​</mo><mi
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.3.cmml">j</mi></mrow><mrow
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.cmml"><mo
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3a" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.cmml">−</mo><mn
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.2.cmml">1</mn></mrow></msubsup><mo
    stretchy="false" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.5" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo
    lspace="0em" id="S5.I1.i4.p1.3.m3.1.1.1.2" xref="S5.I1.i4.p1.3.m3.1.1.1.1.cmml">.</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S5.I1.i4.p1.3.m3.1b"><apply id="S5.I1.i4.p1.3.m3.1.1.1.1.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1"><csymbol cd="latexml" id="S5.I1.i4.p1.3.m3.1.1.1.1.3.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.3">similar-to</csymbol><apply id="S5.I1.i4.p1.3.m3.1.1.1.1.4.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4"><csymbol cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.4.1.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4">subscript</csymbol><ci id="S5.I1.i4.p1.3.m3.1.1.1.1.4.2.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.2">𝐑</ci><apply id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3"><ci id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.2.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.2">𝑖</ci><ci id="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.3.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.4.3.3">𝑗</ci></apply></apply><apply id="S5.I1.i4.p1.3.m3.1.1.1.1.2.cmml"
    xref="S5.I1.i4.p1.3.m3.1.1.1.1.2"><ci id="S5.I1.i4.p1.3.m3.1.1.1.1.2.4.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.4">𝒩</ci><interval
    closure="open" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2"><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1"><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2"><csymbol
    cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2">superscript</csymbol><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2"><csymbol
    cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.2">𝐮</ci><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.2.3">𝑖</ci></apply><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.2.3">𝑇</ci></apply><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3"><csymbol
    cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.2">𝐯</ci><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.1.1.1.1.3.3">𝑗</ci></apply></apply><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2"><csymbol
    cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2">superscript</csymbol><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2"><csymbol
    cd="ambiguous" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.1.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2">subscript</csymbol><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.2">𝐂</ci><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3"><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.2">𝑖</ci><ci
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.2.3.3">𝑗</ci></apply></apply><apply
    id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3"><cn
    type="integer" id="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.2.cmml" xref="S5.I1.i4.p1.3.m3.1.1.1.1.2.2.2.2.3.2">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S5.I1.i4.p1.3.m3.1c">{\bf R}_{ij}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j},{\bf C}_{ij}^{-1}).\\</annotation></semantics></math>'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Here $\lambda_{w}$, $\lambda_{n}$, $\lambda_{u}$, $\lambda_{s}$, and $\lambda_{v}$
    are hyperparameters and ${\bf C}_{ij}$ is a confidence parameter similar to that
    for CTR ([CTR,](#bib.bib112) ) (${\bf C}_{ij}=a$ if ${\bf R}_{ij}=1$ and ${\bf
    C}_{ij}=b$ otherwise). Note that the middle layer ${\bf X}_{L/2}$ serves as a
    bridge between the ratings and content information. This middle layer, along with
    the latent offset $\mbox{\boldmath$\epsilon$\unboldmath}_{j}$, is the key that
    enables CDL to simultaneously learn an effective feature representation and capture
    the similarity and (implicit) relationship among items (and users). Similar to
    the generalized SDAE, we can also take $\lambda_{s}$ to infinity for computational
    efficiency.
  prefs: []
  type: TYPE_NORMAL
- en: The graphical model of CDL when $\lambda_{s}$ approaches positive infinity is
    shown in Figure [7](#S5.F7 "Figure 7 ‣ 5.1.1\. Collaborative Deep Learning ‣ 5.1\.
    Supervised Bayesian Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models
    and Applications ‣ A Survey on Bayesian Deep Learning"), where, for notational
    simplicity, we use ${\bf x}_{0}$, ${\bf x}_{L/2}$, and ${\bf x}_{L}$ in place
    of ${\bf X}_{0,j*}^{T}$, ${\bf X}_{\frac{L}{2},j*}^{T}$, and ${\bf X}_{L,j*}^{T}$,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Note that according the definition in Section [4.2](#S4.SS2 "4.2\. General Framework
    ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning"), here the
    perception variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{\{{\bf W}_{l}\},\{{\bf
    b}_{l}\},\{{\bf X}_{l}\},{\bf X}_{c}\}$, the hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    V}\}$, and the task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{{\bf
    U},{\bf R}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning: Based on the CDL model above, all parameters could be treated as
    random variables so that fully Bayesian methods such as Markov chain Monte Carlo
    (MCMC) or variational inference ([DBLP:journals/ml/JordanGJS99,](#bib.bib55) )
    may be applied. However, such treatment typically incurs high computational cost.
    Therefore CDL uses an EM-style algorithm to obtain the MAP estimates, as in ([CTR,](#bib.bib112)
    ).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Concretely, note that maximizing the posterior probability is equivalent to
    maximizing the joint log-likelihood of ${\bf U}$, ${\bf V}$, $\{{\bf X}_{l}\}$,
    ${\bf X}_{c}$, $\{{\bf W}_{l}\}$, $\{{\bf b}_{l}\}$, and ${\bf R}$ given $\lambda_{u}$,
    $\lambda_{v}$, $\lambda_{w}$, $\lambda_{s}$, and $\lambda_{n}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=$ | $\displaystyle-\frac{\lambda_{u}}{2}\sum\limits_{i}\&#124;{\bf
    u}_{i}\&#124;_{2}^{2}-\frac{\lambda_{w}}{2}\sum\limits_{l}(\&#124;{\bf W}_{l}\&#124;_{F}^{2}+\&#124;{\bf
    b}_{l}\&#124;_{2}^{2})-\frac{\lambda_{v}}{2}\sum\limits_{j}\&#124;{\bf v}_{j}-{\bf
    X}_{\frac{L}{2},j*}^{T}\&#124;_{2}^{2}-\frac{\lambda_{n}}{2}\sum\limits_{j}\&#124;{\bf
    X}_{L,j*}-{\bf X}_{c,j*}\&#124;_{2}^{2}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle-\frac{\lambda_{s}}{2}\sum\limits_{l}\sum\limits_{j}\&#124;\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l})-{\bf X}_{l,j*}\&#124;_{2}^{2}-\sum\limits_{i,j}\frac{{\bf
    C}_{ij}}{2}({\bf R}_{ij}-{\bf u}_{i}^{T}{\bf v}_{j})^{2}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'If $\lambda_{s}$ goes to infinity, the likelihood becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=$ | $\displaystyle-\frac{\lambda_{u}}{2}\sum\limits_{i}\&#124;{\bf
    u}_{i}\&#124;_{2}^{2}-\frac{\lambda_{w}}{2}\sum\limits_{l}(\&#124;{\bf W}_{l}\&#124;_{F}^{2}+\&#124;{\bf
    b}_{l}\&#124;_{2}^{2})-\frac{\lambda_{v}}{2}\sum\limits_{j}\&#124;{\bf v}_{j}-f_{e}({\bf
    X}_{0,j*},{\bf W}^{+})^{T}\&#124;_{2}^{2}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '| (9) |  |  | $\displaystyle-\frac{\lambda_{n}}{2}\sum\limits_{j}\&#124;f_{r}({\bf
    X}_{0,j*},{\bf W}^{+})-{\bf X}_{c,j*}\&#124;_{2}^{2}-\sum\limits_{i,j}\frac{{\bf
    C}_{ij}}{2}({\bf R}_{ij}-{\bf u}_{i}^{T}{\bf v}_{j})^{2},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where the encoder function $f_{e}(\cdot,{\bf W}^{+})$ takes the corrupted content
    vector ${\bf X}_{0,j*}$ of item $j$ as input and computes its encoding, and the
    function $f_{r}(\cdot,{\bf W}^{+})$ also takes ${\bf X}_{0,j*}$ as input, computes
    the encoding and then reconstructs item $j$’s content vector. For example, if
    the number of layers $L=6$, $f_{e}({\bf X}_{0,j*},{\bf W}^{+})$ is the output
    of the third layer while $f_{r}({\bf X}_{0,j*},{\bf W}^{+})$ is the output of
    the sixth layer.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/290a1884753821341acd8afeaea26d4d.png)![Refer to caption](img/2be2047032aae63cc3ed089eb8640a3f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8\. Left: NN representation for degenerated CDL. Right: Sampling as
    generalized BP in Bayesian CDL.'
  prefs: []
  type: TYPE_NORMAL
- en: From the perspective of optimization, the third term in the objective function,
    i.e., Equation ([5.1.1](#S5.Ex20 "5.1.1\. Collaborative Deep Learning ‣ 5.1\.
    Supervised Bayesian Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models
    and Applications ‣ A Survey on Bayesian Deep Learning")), above is equivalent
    to a multi-layer perceptron using the latent item vectors ${\bf v}_{j}$ as the
    target while the fourth term is equivalent to an SDAE minimizing the reconstruction
    error. Seeing from the view of neural networks (NN), when $\lambda_{s}$ approaches
    positive infinity, training of the probabilistic graphical model of CDL in Figure
    [7](#S5.F7 "Figure 7 ‣ 5.1.1\. Collaborative Deep Learning ‣ 5.1\. Supervised
    Bayesian Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning")(left) would degenerate to simultaneously
    training two neural networks overlaid together with a common input layer (the
    corrupted input) but different output layers, as shown in Figure [8](#S5.F8 "Figure
    8 ‣ 5.1.1\. Collaborative Deep Learning ‣ 5.1\. Supervised Bayesian Deep Learning
    for Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey
    on Bayesian Deep Learning")(left). Note that the second network is much more complex
    than typical neural networks due to the involvement of the rating matrix.
  prefs: []
  type: TYPE_NORMAL
- en: When the ratio $\lambda_{n}/\lambda_{v}$ approaches positive infinity, it will
    degenerate to a two-step model in which the latent representation learned using
    SDAE is put directly into the CTR. Another extreme happens when $\lambda_{n}/\lambda_{v}$
    goes to zero where the decoder of the SDAE essentially vanishes. Figure [7](#S5.F7
    "Figure 7 ‣ 5.1.1\. Collaborative Deep Learning ‣ 5.1\. Supervised Bayesian Deep
    Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣
    A Survey on Bayesian Deep Learning")(right) shows the graphical model of the degenerated
    CDL when $\lambda_{n}/\lambda_{v}$ goes to zero. As demonstrated in experiments,
    the predictive performance will suffer greatly for both extreme cases ([CDL,](#bib.bib121)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: 'For ${\bf u}_{i}$ and ${\bf v}_{j}$, block coordinate descent similar to ([CTR,](#bib.bib112)
    ; [DBLP:conf/icdm/HuKV08,](#bib.bib50) ) is used. Given the current ${\bf W}^{+}$,
    we compute the gradients of $\mathscr{L}$ with respect to ${\bf u}_{i}$ and ${\bf
    v}_{j}$ and then set them to zero, leading to the following update rules:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf u}_{i}$ | $\displaystyle\leftarrow({\bf V}{\bf C}_{i}{\bf
    V}^{T}+\lambda_{u}{\bf I}_{K})^{-1}{\bf V}{\bf C}_{i}{\bf R}_{i},\;\;\;\;{\bf
    v}_{j}\leftarrow({\bf U}{\bf C}_{i}{\bf U}^{T}+\lambda_{v}{\bf I}_{K})^{-1}({\bf
    U}{\bf C}_{j}{\bf R}_{j}+\lambda_{v}f_{e}({\bf X}_{0,j*},{\bf W}^{+})^{T}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\bf U}=({\bf u}_{i})^{I}_{i=1}$, ${\bf V}=({\bf v}_{j})^{J}_{j=1}$,
    ${\bf C}_{i}=\mbox{diag}({\bf C}_{i1},\ldots,{\bf C}_{iJ})$ is a diagonal matrix,
    ${\bf R}_{i}=({\bf R}_{i1},\ldots,{\bf R}_{iJ})^{T}$ is a column vector containing
    all the ratings of user $i$, and ${\bf C}_{ij}$ reflects the confidence controlled
    by $a$ and $b$ as discussed in ([DBLP:conf/icdm/HuKV08,](#bib.bib50) ). ${\bf
    C}_{j}$ and ${\bf R}_{j}$ are defined similarly for item $j$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given ${\bf U}$ and ${\bf V}$, we can learn the weights ${\bf W}_{l}$ and biases
    ${\bf b}_{l}$ for each layer using the back-propagation learning algorithm. The
    gradients of the likelihood with respect to ${\bf W}_{l}$ and ${\bf b}_{l}$ are
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\nabla_{{\bf W}_{l}}\mathscr{L}=$ | $\displaystyle-\lambda_{w}{\bf
    W}_{l}-\lambda_{v}\sum\limits_{j}\nabla_{{\bf W}_{l}}f_{e}({\bf X}_{0,j*},{\bf
    W}^{+})^{T}(f_{e}({\bf X}_{0,j*},{\bf W}^{+})^{T}-{\bf v}_{j})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle-\lambda_{n}\sum\limits_{j}\nabla_{{\bf W}_{l}}f_{r}({\bf
    X}_{0,j*},{\bf W}^{+})(f_{r}({\bf X}_{0,j*},{\bf W}^{+})-{\bf X}_{c,j*})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\nabla_{{\bf b}_{l}}\mathscr{L}=$ | $\displaystyle-\lambda_{w}{\bf
    b}_{l}-\lambda_{v}\sum\limits_{j}\nabla_{{\bf b}_{l}}f_{e}({\bf X}_{0,j*},{\bf
    W}^{+})^{T}(f_{e}({\bf X}_{0,j*},{\bf W}^{+})^{T}-{\bf v}_{j})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle-\lambda_{n}\sum\limits_{j}\nabla_{{\bf b}_{l}}f_{r}({\bf
    X}_{0,j*},{\bf W}^{+})(f_{r}({\bf X}_{0,j*},{\bf W}^{+})-{\bf X}_{c,j*}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: By alternating the update of ${\bf U}$, ${\bf V}$, ${\bf W}_{l}$, and ${\bf
    b}_{l}$, we can find a local optimum for $\mathscr{L}$. Several commonly used
    techniques such as using a momentum term may be applied to alleviate the local
    optimum problem.
  prefs: []
  type: TYPE_NORMAL
- en: 'Prediction: Let $D$ be the observed test data. Similar to ([CTR,](#bib.bib112)
    ), CDL uses the point estimates of ${\bf u}_{i}$, ${\bf W}^{+}$ and $\mbox{\boldmath$\epsilon$\unboldmath}_{j}$
    to calculate the predicted rating:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle E[{\bf R}_{ij}&#124;D]\approx E[{\bf u}_{i}&#124;D]^{T}(E[f_{e}({\bf
    X}_{0,j*},{\bf W}^{+})^{T}&#124;D]+E[\mbox{\boldmath$\epsilon$\unboldmath}_{j}&#124;D]),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $E[\cdot]$ denotes the expectation operation. In other words, we approximate
    the predicted rating as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf R}^{*}_{ij}\approx({\bf u}^{*}_{j})^{T}(f_{e}({\bf
    X}_{0,j*},{{\bf W}^{+}}^{*})^{T}+\mbox{\boldmath$\epsilon$\unboldmath}^{*}_{j})=({\bf
    u}^{*}_{i})^{T}{\bf v}^{*}_{j}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: Note that for any new item $j$ with no rating in the training data, its offset
    $\mbox{\boldmath$\epsilon$\unboldmath}^{*}_{j}$ will be ${\bf 0}$.
  prefs: []
  type: TYPE_NORMAL
- en: Recall that in CDL, the probabilistic SDAE and PMF work as the perception and
    task-specific components. As mentioned in Section [4](#S4 "4\. Bayesian Deep Learning
    ‣ A Survey on Bayesian Deep Learning"), both components can take various forms,
    leading to different concrete models. For example, one can replace the probabilistic
    SDAE with a VAE or an NPN as the perception component ([ColVAE,](#bib.bib68) ).
    It is also possible to use Bayesian PMF ([BPMF,](#bib.bib97) ) rather than PMF ([PMF,](#bib.bib96)
    ) as the task-specific component and thereby produce more robust predictions.
  prefs: []
  type: TYPE_NORMAL
- en: In the following subsections, we provide several extensions of CDL from different
    perspectives.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.2\. Bayesian Collaborative Deep Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Besides the MAP estimates, a sampling-based algorithm for the Bayesian treatment
    of CDL is also proposed in ([CDL,](#bib.bib121) ). This algorithm turns out to
    be a Bayesian and generalized version of BP. We list the key conditional densities
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'For ${\bf W}^{+}$: We denote the concatenation of ${\bf W}_{l,*n}$ and ${\bf
    b}_{l}^{(n)}$ as ${\bf W}_{l,*n}^{+}$. Similarly, the concatenation of ${\bf X}_{l,j*}$
    and $1$ is denoted as ${\bf X}_{l,j*}^{+}$. The subscripts of ${\bf I}$ are ignored.
    Then'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p({\bf W}_{l,*n}^{+}&#124;{\bf X}_{l-1,j*},{\bf X}_{l,j*},\lambda_{s})\propto\
    {\mathcal{N}}({\bf W}_{l,*n}^{+}&#124;0,\lambda_{w}^{-1}{\bf I})\cdot{\mathcal{N}}({\bf
    X}_{l,*n}&#124;\sigma({\bf X}_{l-1}^{+}{\bf W}_{l,*n}^{+}),\lambda_{s}^{-1}{\bf
    I}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'For ${\bf X}_{l,j*}$ ($l\neq L/2$): Similarly, we denote the concatenation
    of ${\bf W}_{l}$ and ${\bf b}_{l}$ as ${\bf W}_{l}^{+}$ and have'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | $\displaystyle p({\bf X}_{l,j*}&#124;{\bf W}_{l}^{+},{\bf W}_{l+1}^{+},{\bf
    X}_{l-1,j*},{\bf X}_{l+1,j*}\lambda_{s})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\propto\ $ | $\displaystyle{\mathcal{N}}({\bf X}_{l,j*}&#124;\sigma({\bf
    X}_{l-1,j*}^{+}{\bf W}_{l}^{+}),\lambda_{s}^{-1}{\bf I})\cdot{\mathcal{N}}({\bf
    X}_{l+1,j*}&#124;\sigma({\bf X}_{l,j*}^{+}{\bf W}_{l+1}^{+}),\lambda_{s}^{-1}{\bf
    I}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where for the last layer ($l=L$) the second Gaussian would be ${\mathcal{N}}({\bf
    X}_{c,j*}|{\bf X}_{l,j*},\lambda_{s}^{-1}{\bf I})$ instead.
  prefs: []
  type: TYPE_NORMAL
- en: 'For ${\bf X}_{l,j*}$ ($l=L/2$): Similarly, we have'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  | $\displaystyle p({\bf X}_{l,j*}&#124;{\bf W}_{l}^{+},{\bf W}_{l+1}^{+},{\bf
    X}_{l-1,j*},{\bf X}_{l+1,j*},\lambda_{s},\lambda_{v},{\bf v}_{j})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\propto\ $ | $\displaystyle{\mathcal{N}}({\bf X}_{l,j*}&#124;\sigma({\bf
    X}_{l-1,j*}^{+}{\bf W}_{l}^{+}),\lambda_{s}^{-1}{\bf I})\cdot{\mathcal{N}}({\bf
    X}_{l+1,j*}&#124;\sigma({\bf X}_{l,j*}^{+}{\bf W}_{l+1}^{+}),\lambda_{s}^{-1}{\bf
    I})\cdot{\mathcal{N}}({\bf v}_{j}&#124;{\bf X}_{l,j*},\lambda_{v}^{-1}{\bf I}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'For ${\bf v}_{j}$: The posterior $p({\bf v}_{j}|{\bf X}_{L/2,j*},{\bf R}_{*j},{\bf
    C}_{*j},\lambda_{v},{\bf U})\propto{\mathcal{N}}({\bf v}_{j}|{\bf X}_{L/2,j*}^{T},\lambda_{v}^{-1}{\bf
    I})\prod\limits_{i}{\mathcal{N}}({\bf R}_{ij}|{\bf u}_{i}^{T}{\bf v}_{j},{\bf
    C}_{ij}^{-1}).$'
  prefs: []
  type: TYPE_NORMAL
- en: 'For ${\bf u}_{i}$: The posterior $p({\bf u}_{i}|{\bf R}_{i*},{\bf V},\lambda_{u},{\bf
    C}_{i*})\propto{\mathcal{N}}({\bf u}_{i}|0,\lambda_{u}^{-1}{\bf I})\prod\limits_{j}{\mathcal{N}}({\bf
    R}_{ij}|{\bf u}_{i}^{T}{\bf v}_{j},{\bf C}_{ij}^{-1}).$'
  prefs: []
  type: TYPE_NORMAL
- en: Interestingly, if $\lambda_{s}$ goes to infinity and adaptive rejection Metropolis
    sampling (which involves using the gradients of the objective function to approximate
    the proposal distribution) is used, the sampling for ${\bf W}^{+}$ turns out to
    be a *Bayesian generalized* version of BP. Specifically, as Figure [8](#S5.F8
    "Figure 8 ‣ 5.1.1\. Collaborative Deep Learning ‣ 5.1\. Supervised Bayesian Deep
    Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣
    A Survey on Bayesian Deep Learning")(right) shows, after getting the gradient
    of the loss function at one point (the red dashed line on the left), the next
    sample would be drawn in the region under that line, which is equivalent to a
    probabilistic version of BP. If a sample is above the curve of the loss function,
    a new tangent line (the black dashed line on the right) would be added to better
    approximate the distribution corresponding to the loss function. After that, samples
    would be drawn from the region under both lines. During the sampling, besides
    searching for local optima using the gradients (MAP), the algorithm also takes
    the variance into consideration. That is why it is called *Bayesian generalized
    back-propagation* in ([CDL,](#bib.bib121) ).
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.3\. Marginalized Collaborative Deep Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In SDAE, corrupted input goes through the encoder and decoder to recover the
    clean input. Usually, different epochs of training use different corrupted versions
    as input. Hence generally, SDAE needs to go through enough epochs of training
    to see sufficient corrupted versions of the input. Marginalized SDAE (mSDAE) ([mSDAE,](#bib.bib14)
    ) seeks to avoid this by marginalizing out the corrupted input and obtaining closed-form
    solutions directly. In this sense, mSDAE is more computationally efficient than
    SDAE.
  prefs: []
  type: TYPE_NORMAL
- en: 'As mentioned in ([li2015deep,](#bib.bib66) ), using mSDAE instead of the Bayesian
    SDAE could lead to more efficient learning algorithms. For example, in ([li2015deep,](#bib.bib66)
    ), the objective when using a one-layer mSDAE can be written as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=-\sum\limits_{j}\&#124;\widetilde{{\bf X}}_{0,j*}{\bf
    W}_{1}-\overline{{\bf X}}_{c,j*}\&#124;_{2}^{2}-\sum\limits_{i,j}\frac{{\bf C}_{ij}}{2}({\bf
    R}_{ij}-{\bf u}_{i}^{T}{\bf v}_{j})^{2}-\frac{\lambda_{u}}{2}\sum\limits_{i}\&#124;{\bf
    u}_{i}\&#124;_{2}^{2}-\frac{\lambda_{v}}{2}\sum\limits_{j}\&#124;{\bf v}_{j}^{T}{\bf
    P}_{1}-{\bf X}_{0,j*}{\bf W}_{1}\&#124;_{2}^{2},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\widetilde{{\bf X}}_{0,j*}$ is the collection of $k$ different corrupted
    versions of ${{\bf X}}_{0,j*}$ (a $k$-by-$B$ matrix) and $\overline{{\bf X}}_{c,j*}$
    is the $k$-time repeated version of ${{\bf X}}_{c,j*}$ (also a $k$-by-$B$ matrix).
    ${\bf P}_{1}$ is the transformation matrix for item latent factors.
  prefs: []
  type: TYPE_NORMAL
- en: The solution for ${\bf W}_{1}$ would be ${\bf W}_{1}=E({\bf S}_{1})E({\bf Q}_{1})^{-1}$,
    where ${\bf S}_{1}=\overline{{\bf X}}_{c,j*}^{T}\widetilde{{\bf X}}_{0,j*}+\frac{\lambda_{v}}{2}{\bf
    P}_{1}^{T}{\bf V}{\bf X}_{c}$ and ${\bf Q}_{1}=\overline{{\bf X}}_{c,j*}^{T}\widetilde{{\bf
    X}}_{0,j*}+\frac{\lambda_{v}}{2}{\bf X}_{c}^{T}{\bf X}_{c}$. A solver for the
    expectation in the equation above is provided in ([mSDAE,](#bib.bib14) ). Note
    that this is a linear and one-layer case which can be generalized to the nonlinear
    and multi-layer case using the same techniques as in ([mSDAE,](#bib.bib14) ; [nmSDAE,](#bib.bib13)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: Marginalized CDL’s perception variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{{\bf
    X}_{0},{\bf X}_{c},{\bf W}_{1}\}$, its hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    V}\}$, and its task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{{\bf
    P}_{1},{\bf R},{\bf U}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.4\. Collaborative Deep Ranking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'CDL assumes a collaborative filtering setting to model the ratings directly.
    Naturally, one can design a similar model to focus more on the ranking among items
    rather than exact ratings ([yingcollaborative,](#bib.bib131) ). The corresponding
    generative process is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each layer $l$ of the SDAE network,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each column $n$ of the weight matrix ${\bf W}_{l}$, draw ${\bf W}_{l,*n}\sim{\mathcal{N}}({\bf
    0},\lambda_{w}^{-1}{\bf I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the bias vector ${\bf b}_{l}\sim{\mathcal{N}}({\bf 0},\lambda_{w}^{-1}{\bf
    I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each row $j$ of ${\bf X}_{l}$, draw ${\bf X}_{l,j*}\sim{\mathcal{N}}(\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K_{l}}).$
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item $j$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw a clean input ${\bf X}_{c,j*}\sim{\mathcal{N}}({\bf X}_{L,j*},\lambda_{n}^{-1}{\bf
    I}_{J}$).
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a latent item offset vector $\mbox{\boldmath$\epsilon$\unboldmath}_{j}\sim{\mathcal{N}}({\bf
    0},\lambda_{v}^{-1}{\bf I}_{K})$ and then set the latent item vector to be: ${\bf
    v}_{j}=\mbox{\boldmath$\epsilon$\unboldmath}_{j}+{\bf X}_{\frac{L}{2},j*}^{T}.$'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each user $i$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a latent user vector for each user $i$: ${\bf u}_{i}\sim{\mathcal{N}}({\bf
    0},\lambda_{u}^{-1}{\bf I}_{K}).$'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For each pair-wise preference $(j,k)\in\mathcal{P}_{i}$, where $\mathcal{P}_{i}=\{(j,k):{\bf
    R}_{ij}-{\bf R}_{ik}>0\}$, draw the preference: <math id="S5.I2.i3.I1.i2.p1.3.m3.2"
    class="ltx_Math" alttext="\mbox{\boldmath$\Delta$\unboldmath}_{ijk}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j}-{\bf u}_{i}^{T}{\bf v}_{k},{\bf C}_{ijk}^{-1}).\\'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: '" display="inline"><semantics id="S5.I2.i3.I1.i2.p1.3.m3.2a"><mrow id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.cmml"><mrow id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.cmml"><msub id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.cmml"><mi id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.2"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.2.cmml">𝚫</mi><mrow id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.cmml"><mi id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.2"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.2.cmml">i</mi><mo lspace="0em" rspace="0em"
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.1.cmml">​</mo><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.3.cmml">j</mi><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.1a" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.1.cmml">​</mo><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.4" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.4.cmml">k</mi></mrow></msub><mo
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.3.cmml">∼</mo><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.cmml"><mi
    class="ltx_font_mathcaligraphic" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.4" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.4.cmml">𝒩</mi><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.3.cmml">​</mo><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.3.cmml"><mo
    stretchy="false" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.3.cmml">(</mo><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.cmml"><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.cmml"><msubsup
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.2.cmml">𝐮</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.3.cmml">i</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.3.cmml">T</mi></msubsup><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.1.cmml">​</mo><msub
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.2.cmml">𝐯</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.3.cmml">j</mi></msub></mrow><mo
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.1.cmml">−</mo><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.cmml"><msubsup
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.2.cmml">𝐮</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.3.cmml">i</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.3.cmml">T</mi></msubsup><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.1.cmml">​</mo><msub
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.2.cmml">𝐯</mi><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.3.cmml">k</mi></msub></mrow></mrow><mo
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.4" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.3.cmml">,</mo><msubsup
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.2.cmml">𝐂</mi><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.cmml"><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.2.cmml">i</mi><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.1" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.1.cmml">​</mo><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.3.cmml">j</mi><mo
    lspace="0em" rspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.1a" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.1.cmml">​</mo><mi
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.4" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.4.cmml">k</mi></mrow><mrow
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.cmml"><mo
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3a" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.cmml">−</mo><mn
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.2.cmml">1</mn></mrow></msubsup><mo
    stretchy="false" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.5" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.3.cmml">)</mo></mrow></mrow></mrow><mo
    lspace="0em" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.2" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.cmml">.</mo></mrow><annotation-xml
    encoding="MathML-Content" id="S5.I2.i3.I1.i2.p1.3.m3.2b"><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1"><csymbol cd="latexml" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.3.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.3">similar-to</csymbol><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4"><csymbol cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.1.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4">subscript</csymbol><ci id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.2.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.2">𝚫</ci><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3"><ci id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.2.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.2">𝑖</ci><ci id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.3.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.3">𝑗</ci><ci id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.4.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.4.3.4">𝑘</ci></apply></apply><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2"><ci id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.4.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.4">𝒩</ci><interval closure="open" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.3.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2"><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1"><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2"><apply id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.1.cmml"
    xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2">superscript</csymbol><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2">subscript</csymbol><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.2">𝐮</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.2.3">𝑇</ci></apply><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3">subscript</csymbol><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.2">𝐯</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.2.3.3">𝑗</ci></apply></apply><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3"><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2">superscript</csymbol><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2">subscript</csymbol><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.2">𝐮</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.2.3">𝑖</ci></apply><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.2.3">𝑇</ci></apply><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3">subscript</csymbol><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.2">𝐯</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.1.1.1.1.3.3.3">𝑘</ci></apply></apply></apply><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2">superscript</csymbol><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2"><csymbol
    cd="ambiguous" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.1.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2">subscript</csymbol><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.2">𝐂</ci><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3"><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.2">𝑖</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.3">𝑗</ci><ci
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.4.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.2.3.4">𝑘</ci></apply></apply><apply
    id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3"><cn
    type="integer" id="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.2.cmml" xref="S5.I2.i3.I1.i2.p1.3.m3.2.2.1.1.2.2.2.2.3.2">1</cn></apply></apply></interval></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" id="S5.I2.i3.I1.i2.p1.3.m3.2c">\mbox{\boldmath$\Delta$\unboldmath}_{ijk}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j}-{\bf u}_{i}^{T}{\bf v}_{k},{\bf C}_{ijk}^{-1}).\\</annotation></semantics></math>'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Following the generative process above, the log-likelihood in Equation ([5.1.1](#S5.Ex20
    "5.1.1\. Collaborative Deep Learning ‣ 5.1\. Supervised Bayesian Deep Learning
    for Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey
    on Bayesian Deep Learning")) becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=$ | $\displaystyle-\frac{\lambda_{u}}{2}\sum\limits_{i}\&#124;{\bf
    u}_{i}\&#124;_{2}^{2}-\frac{\lambda_{w}}{2}\sum\limits_{l}(\&#124;{\bf W}_{l}\&#124;_{F}^{2}+\&#124;{\bf
    b}_{l}\&#124;_{2}^{2})-\frac{\lambda_{v}}{2}\sum\limits_{j}\&#124;{\bf v}_{j}-f_{e}({\bf
    X}_{0,j*},{\bf W}^{+})^{T}\&#124;_{2}^{2}$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle-\frac{\lambda_{n}}{2}\sum\limits_{j}\&#124;f_{r}({\bf
    X}_{0,j*},{\bf W}^{+})-{\bf X}_{c,j*}\&#124;_{2}^{2}-\sum\limits_{i,j,k}\frac{{\bf
    C}_{ijk}}{2}(\mbox{\boldmath$\Delta$\unboldmath}_{ijk}-({\bf u}_{i}^{T}{\bf v}_{j}-{\bf
    u}_{i}^{T}{\bf v}_{k}))^{2}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: Similar algorithms can be used to learn the parameters in CDR. As reported in
    ([yingcollaborative,](#bib.bib131) ), using the ranking objective leads to significant
    improvement in the recommendation performance. Following the definition in Section
    [4.2](#S4.SS2 "4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey
    on Bayesian Deep Learning"), CDR’s perception variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{\{{\bf
    W}_{l}\},\{{\bf b}_{l}\},\{{\bf X}_{l}\},{\bf X}_{c}\}$, the hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    V}\}$, and the task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{{\bf
    U},\mbox{\boldmath$\Delta$\unboldmath}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.5\. Collaborative Variational Autoencoders
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In CDL, the perception component takes the form of a probabilistic SDAE. Naturally,
    one can also replace the probabilistic SDAE in CDL with a VAE (introduced in Section [4.3.3](#S4.SS3.SSS3
    "4.3.3\. Variational Autoencoders ‣ 4.3\. Perception Component ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")), as is done in collaborative
    variational autoencoders (CVAE) ([ColVAE,](#bib.bib68) ). Specifically, CVAE with
    a inference network (encoder) denoted as $(f_{\mu}(\cdot),f_{s}(\cdot))$ and a
    generation network (decoder) denoted as $g(\cdot)$ assumes the following generative
    process:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item $j$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw the latent item vector from the VAE inference network: ${\bf z}_{j}\sim{\mathcal{N}}(f_{\mu}({\bf
    X}_{0,j*}),f_{s}({\bf X}_{0,j*}))$'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw the latent item offset vector $\mbox{\boldmath$\epsilon$\unboldmath}_{j}\sim{\mathcal{N}}({\bf
    0},\lambda_{v}^{-1}{\bf I}_{K})$ and then set the latent item vector: ${\bf v}_{j}=\mbox{\boldmath$\epsilon$\unboldmath}_{j}+{\bf
    z}_{j}.$'
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the orignial input from the VAE generation network ${\bf X}_{0,j*}\sim{\mathcal{N}}(g({\bf
    z}_{j}),\lambda_{n}^{-1}{\bf I}_{B}$).
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a latent user vector for each user $i$: ${\bf u}_{i}\sim{\mathcal{N}}({\bf
    0},\lambda_{u}^{-1}{\bf I}_{K}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw a rating ${\bf R}_{ij}$ for each user-item pair $(i,j)$: ${\bf R}_{ij}\sim{\mathcal{N}}({\bf
    u}_{i}^{T}{\bf v}_{j},{\bf C}_{ij}^{-1}).$'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Similar to CDL, $\lambda_{n}$, $\lambda_{u}$, $\lambda_{s}$, and $\lambda_{v}$
    are hyperparameters and ${\bf C}_{ij}$ is a confidence parameter (${\bf C}_{ij}=a$
    if ${\bf R}_{ij}=1$ and ${\bf C}_{ij}=b$ otherwise). Following ([ColVAE,](#bib.bib68)
    ), the ELBO similar to Equation ([6](#S4.E6 "In 4.3.3\. Variational Autoencoders
    ‣ 4.3\. Perception Component ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian
    Deep Learning")) can be derived, using which one can train the model’s parameters
    using BP and the reparameterization trick.
  prefs: []
  type: TYPE_NORMAL
- en: The evolution from CDL to CVAE demonstrates the BDL framework’s flexibility
    in terms of its components’ specific forms. It is also worth noting that the perception
    component can be a recurrent version of probabilistic SDAE ([CRAE,](#bib.bib122)
    ) or VAE ([VRNN,](#bib.bib17) ; [ColVAE,](#bib.bib68) ) to handle raw sequential
    data, while the task-specific component can take more sophisticated forms to accommodate
    more complex recommendation scenarios (e.g., cross-domain recommendation).
  prefs: []
  type: TYPE_NORMAL
- en: 5.1.6\. Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recommender systems are a typical use case for BDL in that they often require
    both thorough understanding of high-dimensional signals (e.g., text and images)
    and principled reasoning on the conditional dependencies among users/items/ratings.
  prefs: []
  type: TYPE_NORMAL
- en: In this regard, CDL, as an instantiation of BDL, is the first hierarchical Bayesian
    model to bridge the gap between state-of-the-art deep learning models and recommender
    systems. By performing deep learning collaboratively, CDL and its variants can
    simultaneously extract an effective deep feature representation from high-dimensional
    content and capture the similarity and implicit relationship between items (and
    users). The learned representation may also be used for tasks other than recommendation.
    Unlike previous deep learning models which use a simple target like classification
    ([DBLP:journals/acl/KalchbrennerGB14,](#bib.bib56) ) and reconstruction ([DBLP:journals/jmlr/VincentLLBM10,](#bib.bib111)
    ), CDL-based models use CF as a more complex target in a probabilistic framework.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in Section [1](#S1 "1\. Introduction ‣ A Survey on Bayesian Deep
    Learning"), *information exchange* between two components is crucial for the performance
    of BDL. In the CDL-based models above, the exchange is achieved by assuming Gaussian
    distributions that connect the hinge variables and the variables in the perception
    component (drawing the hinge variable ${\bf v}_{j}\sim{\mathcal{N}}({\bf X}_{\frac{L}{2},j*}^{T},\lambda_{v}^{-1}{\bf
    I}_{K})$ in the generative process of CDL, where ${\bf X}_{\frac{L}{2}}$ is a
    perception variable), which is simple but effective and efficient in computation.
    Among the eight CDL-based models in Table [1](#S3.T1 "Table 1 ‣ 3.1\. Models ‣
    3\. Probabilistic Graphical Models ‣ A Survey on Bayesian Deep Learning"), six
    of them are HV models and the others are LV models, according to the definition
    of Section [4.2](#S4.SS2 "4.2\. General Framework ‣ 4\. Bayesian Deep Learning
    ‣ A Survey on Bayesian Deep Learning"). Since it has been verified that the HV
    CDL significantly outperforms its ZV counterpart ([CDL,](#bib.bib121) ), we can
    expect additional performance boost from the LV counterparts of the six HV models.
  prefs: []
  type: TYPE_NORMAL
- en: Besides efficient *information exchange*, the model designs also meet the independence
    requirement on the distribution concerning hinge variables discussed in Section
    [4.2](#S4.SS2 "4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey
    on Bayesian Deep Learning") and are hence easily parallelizable. In some models
    to be introduced later, we will see alternative designs to enable efficient and
    independent information exchange between the two components of BDL.
  prefs: []
  type: TYPE_NORMAL
- en: Note that BDL-based models above use typical static Bayesian networks as their
    task-specific components. Although these are often sufficient for most use cases,
    it is possible for the task-specific components to take the form of deep Bayesian
    networks such as BIN ([BIN,](#bib.bib117) ). This allows the models to handle
    highly nonlinear interactions between users and items if necessary. One can also
    use stochastic processes (or dynamic Bayesian networks in general) to explicitly
    model users purchase or clicking behaviors. For example, it is natural to model
    a user’s purchase of groceries as a Poisson process. In terms of perception components,
    one can also replace the pSDAE, mSDAE, or VAE above with their convolutional or
    recurrent counterparts (see Section [2.3](#S2.SS3 "2.3\. Convolutional Neural
    Networks ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep Learning") and Section [2.4](#S2.SS4
    "2.4\. Recurrent Neural Network ‣ 2\. Deep Learning ‣ A Survey on Bayesian Deep
    Learning")), as is done in Collaborative Knowledge Base Embedding (CKE) ([CKE,](#bib.bib132)
    ) or Collaborative Recurrent Autoencoders (CRAE) ([CRAE,](#bib.bib122) ), respectively.
    Note that for the convolutional or recurrent perception components to be compatible
    with the task-specific component (which is inherently probabilistic), ideally
    one would need to formulate probabilistic versions of CNN or RNN as well. Readers
    are referred to ([CKE,](#bib.bib132) ) and ([CRAE,](#bib.bib122) ) for more details.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, this subsection discusses BDL’s applications on supervised leraning,
    using recommender systems as an example. Section [5.2](#S5.SS2 "5.2\. Unsupervised
    Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning") below will cover BDL’s applications on
    unsupervised learning.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2\. Unsupervised Bayesian Deep Learning for Topic Models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: To demonstrate how BDL can also be applied to unsupervised learning, we review
    some examples of BDL-based topic models in this section. These models combine
    the merits of PGM (which naturally incorporates the probabilistic relations among
    variables) and NN (which learns deep representations efficiently), leading to
    significant performance boost. In the case of unsupervised learning, the ‘task’
    for a task-specific component is to describe/characterize the conditional dependencies
    in the BDL model, thereby improving its interpretability and genearalizability.
    This is different from the supervised learning setting where the ‘task’ is simply
    to ‘match the target’.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.1\. Relational Stacked Denoising Autoencoders as Topic Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As a BDL-based topic model, relational stacked denoising autoencoders (RSDAE)
    essentially tries to learn a hierarchy of topics (or latent factors) while enforcing
    relational (graph) constraints under an unsupervised learning setting.
  prefs: []
  type: TYPE_NORMAL
- en: 'Problem Statement and Notation: Assume we have a set of items (articles or
    movies) ${\bf X}_{c}$, with ${\bf X}_{c,j*}^{T}\in{\mathbb{R}}^{B}$ denoting the
    content (attributes) of item $j$. Besides, we use ${\bf I}_{K}$ to denote a $K$-dimensional
    identity matrix and ${\bf S}=[{\bf s}_{1},{\bf s}_{2},\cdots,{\bf s}_{J}]$ to
    denote the *relational latent matrix* with ${\bf s}_{j}$ representing the relational
    properties of item $j$.'
  prefs: []
  type: TYPE_NORMAL
- en: From the perspective of SDAE, the $J$-by-$B$ matrix ${\bf X}_{c}$ represents
    the clean input to the SDAE and the noise-corrupted matrix of the same size is
    denoted by ${\bf X}_{0}$. Besides, we denote the output of layer $l$ of the SDAE,
    a $J$-by-$K_{l}$ matrix, by ${\bf X}_{l}$. Row $j$ of ${\bf X}_{l}$ is denoted
    by ${\bf X}_{l,j*}$, ${\bf W}_{l}$ and ${\bf b}_{l}$ are the weight matrix and
    bias vector of layer $l$, ${\bf W}_{l,*n}$ denotes column $n$ of ${\bf W}_{l}$,
    and $L$ is the number of layers. As a shorthand, we refer to the collection of
    weight matrices and biases in all layers as ${\bf W}^{+}$. Note that an $L/2$-layer
    SDAE corresponds to an $L$-layer network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Model Formulation: In RSDAE, the perception component takes the form of a probabilistic
    SDAE (introduced in Section [4.3.2](#S4.SS3.SSS2 "4.3.2\. Probabilistic Generalized
    SDAE ‣ 4.3\. Perception Component ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian
    Deep Learning")) as a building block. At a higher level, RSDAE is formulated as
    a novel probabilistic model which seamlessly integrates a hierarchy of latent
    factors and the relational information available. This way, the model can simultaneously
    learn the feature representation from the content information and the relation
    among items ([RSDAE,](#bib.bib118) ). The graphical model for RSDAE is shown in
    Figure [9](#S5.F9 "Figure 9 ‣ 5.2.1\. Relational Stacked Denoising Autoencoders
    as Topic Models ‣ 5.2\. Unsupervised Bayesian Deep Learning for Topic Models ‣
    5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning"),
    and the generative process is listed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Refer to caption](img/260ed05cf98cb20010f5e327706987d7.png) |'
  prefs: []
  type: TYPE_TB
- en: Figure 9\. Graphical model of RSDAE for $L=4$. $\lambda_{s}$ is omitted here
    to prevent clutter.
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Draw the relational latent matrix ${\bf S}$ from a *matrix-variate normal distribution* ([gupta2000matrix,](#bib.bib33)
    ):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (10) |  | $\displaystyle{\bf S}\sim{\mathcal{N}}_{K,J}(0,{\bf I}_{K}\otimes(\lambda_{l}\mathscr{L}_{a})^{-1}).$
    |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For layer $l$ of the SDAE where $l=1,2,\dots,\frac{L}{2}-1$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each column $n$ of the weight matrix ${\bf W}_{l}$, draw ${\bf W}_{l,*n}\sim{\mathcal{N}}(0,\lambda_{w}^{-1}{\bf
    I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the bias vector ${\bf b}_{l}\sim{\mathcal{N}}(0,\lambda_{w}^{-1}{\bf I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each row $j$ of ${\bf X}_{l}$, draw ${\bf X}_{l,j*}\sim{\mathcal{N}}(\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K_{l}}).$
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'For layer $\frac{L}{2}$ of the SDAE, draw the representation vector for item
    $j$ from the product of two Gaussians (PoG) ([DBLP:journals/csl/GalesA06,](#bib.bib23)
    ):'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (11) |  | $\displaystyle{\bf X}_{\frac{L}{2},j*}\sim\mbox{PoG}(\sigma({\bf
    X}_{\frac{L}{2}-1,j*}{\bf W}_{l}+{\bf b}_{l}),{\bf s}_{j}^{T},\lambda_{s}^{-1}{\bf
    I}_{K},\lambda_{r}^{-1}{\bf I}_{K}).$ |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For layer $l$ of the SDAE where $l=\frac{L}{2}+1,\frac{L}{2}+2,\dots,L$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (a)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each column $n$ of the weight matrix ${\bf W}_{l}$, draw ${\bf W}_{l,*n}\sim{\mathcal{N}}(0,\lambda_{w}^{-1}{\bf
    I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (b)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Draw the bias vector ${\bf b}_{l}\sim{\mathcal{N}}(0,\lambda_{w}^{-1}{\bf I}_{K_{l}})$.
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (c)
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: For each row $j$ of ${\bf X}_{l}$, draw ${\bf X}_{l,j*}\sim{\mathcal{N}}(\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K_{l}}).$
  prefs:
  - PREF_IND
  - PREF_IND
  type: TYPE_NORMAL
- en: (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: For each item $j$, draw a clean input ${\bf X}_{c,j*}\sim{\mathcal{N}}({\bf
    X}_{L,j*},\lambda_{n}^{-1}{\bf I}_{B}).$
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Here $K=K_{\frac{L}{2}}$ is the dimensionality of the learned representation
    vector for each item, ${\bf S}$ denotes the $K\times J$ relational latent matrix
    in which column $j$ is the *relational latent vector* ${\bf s}_{j}$ for item $j$.
    Note that ${\mathcal{N}}_{K,J}(0,{\bf I}_{K}\otimes(\lambda_{l}\mathscr{L}_{a})^{-1})$
    in Equation ([10](#S5.E10 "In item 1 ‣ 5.2.1\. Relational Stacked Denoising Autoencoders
    as Topic Models ‣ 5.2\. Unsupervised Bayesian Deep Learning for Topic Models ‣
    5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning"))
    is a matrix-variate normal distribution defined as in ([gupta2000matrix,](#bib.bib33)
    ):'
  prefs: []
  type: TYPE_NORMAL
- en: '| (12) |  | $\displaystyle p({\bf S})={\mathcal{N}}_{K,J}(0,{\bf I}_{K}\otimes(\lambda_{l}\mathscr{L}_{a})^{-1})=\frac{\exp\{\mathrm{tr}[-\frac{\lambda_{l}}{2}{\bf
    S}\mathscr{L}_{a}{\bf S}^{T}]\}}{(2\pi)^{JK/2}&#124;{\bf I}_{K}&#124;^{J/2}&#124;\lambda_{l}\mathscr{L}_{a}&#124;^{-K/2}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the operator $\otimes$ denotes the Kronecker product of two matrices ([gupta2000matrix,](#bib.bib33)
    ), $\mathrm{tr}(\cdot)$ denotes the trace of a matrix, and $\mathscr{L}_{a}$ is
    the Laplacian matrix incorporating the relational information. $\mathscr{L}_{a}={\bf
    D}-{\bf A}$, where ${\bf D}$ is a diagonal matrix whose diagonal elements ${\bf
    D}_{ii}=\sum_{j}{\bf A}_{ij}$ and ${\bf A}$ is the adjacency matrix representing
    the relational information with binary entries indicating the links (or relations)
    between items. ${\bf A}_{jj^{\prime}}=1$ indicates that there is a link between
    item $j$ and item $j^{\prime}$ and ${\bf A}_{jj^{\prime}}=0$ otherwise. $\mbox{PoG}(\sigma({\bf
    X}_{\frac{L}{2}-1,j*}{\bf W}_{l}+{\bf b}_{l}),{\bf s}_{j}^{T},\lambda_{s}^{-1}{\bf
    I}_{K},\lambda_{r}^{-1}{\bf I}_{K})$ denotes the product of the Gaussian ${\mathcal{N}}(\sigma({\bf
    X}_{\frac{L}{2}-1,j*}{\bf W}_{l}+{\bf b}_{l}),\lambda_{s}^{-1}{\bf I}_{K})$ and
    the Gaussian ${\mathcal{N}}({\bf s}_{j}^{T},\lambda_{r}^{-1}{\bf I}_{K})$, which
    is also a Gaussian ([DBLP:journals/csl/GalesA06,](#bib.bib23) ).
  prefs: []
  type: TYPE_NORMAL
- en: 'According to the generative process above, maximizing the posterior probability
    is equivalent to maximizing the joint log-likelihood of $\{{\bf X}_{l}\}$, ${\bf
    X}_{c}$, ${\bf S}$, $\{{\bf W}_{l}\}$, and $\{{\bf b}_{l}\}$ given $\lambda_{s}$,
    $\lambda_{w}$, $\lambda_{l}$, $\lambda_{r}$, and $\lambda_{n}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathscr{L}=$ | $\displaystyle-\frac{\lambda_{l}}{2}\mathrm{tr}({\bf
    S}\mathscr{L}_{a}{\bf S}^{T})-\frac{\lambda_{r}}{2}\sum\limits_{j}\&#124;({\bf
    s}_{j}^{T}-{\bf X}_{\frac{L}{2},j*})\&#124;_{2}^{2}-\frac{\lambda_{w}}{2}\sum\limits_{l}(\&#124;{\bf
    W}_{l}\&#124;_{F}^{2}+\&#124;{\bf b}_{l}\&#124;_{2}^{2})$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle-\frac{\lambda_{n}}{2}\sum\limits_{j}\&#124;{\bf X}_{L,j*}-{\bf
    X}_{c,j*}\&#124;_{2}^{2}-\frac{\lambda_{s}}{2}\sum\limits_{l}\sum\limits_{j}\&#124;\sigma({\bf
    X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l})-{\bf X}_{l,j*}\&#124;_{2}^{2}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'Similar to the pSDAE, taking $\lambda_{s}$ to infinity, the joint log-likelihood
    becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (13) |  | $\displaystyle\mathscr{L}=-\frac{\lambda_{l}}{2}\mathrm{tr}({\bf
    S}\mathscr{L}_{a}{\bf S}^{T})-\frac{\lambda_{r}}{2}\sum\limits_{j}\&#124;({\bf
    s}_{j}^{T}-{\bf X}_{\frac{L}{2},j*})\&#124;_{2}^{2}-\frac{\lambda_{w}}{2}\sum\limits_{l}(\&#124;{\bf
    W}_{l}\&#124;_{F}^{2}+\&#124;{\bf b}_{l}\&#124;_{2}^{2})-\frac{\lambda_{n}}{2}\sum\limits_{j}\&#124;{\bf
    X}_{L,j*}-{\bf X}_{c,j*}\&#124;_{2}^{2},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\bf X}_{l,j*}=\sigma({\bf X}_{l-1,j*}{\bf W}_{l}+{\bf b}_{l})$. Note
    that the first term $-\frac{\lambda_{l}}{2}\mathrm{tr}({\bf S}\mathscr{L}_{a}{\bf
    S}^{T})$ corresponds to $\log p({\bf S})$ in the matrix-variate distribution in
    Equation ([12](#S5.E12 "In 5.2.1\. Relational Stacked Denoising Autoencoders as
    Topic Models ‣ 5.2\. Unsupervised Bayesian Deep Learning for Topic Models ‣ 5\.
    Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning")).
    Besides, by simple manipulation, we have $\mathrm{tr}({\bf S}\mathscr{L}_{a}{\bf
    S}^{T})=\sum\limits_{k=1}^{K}{\bf S}_{k*}^{T}\mathscr{L}_{a}{\bf S}_{k*}$, where
    ${\bf S}_{k*}$ denotes the $k$-th row of ${\bf S}$. As we can see, maximizing
    $-\frac{\lambda_{l}}{2}\mathrm{tr}({\bf S}^{T}\mathscr{L}_{a}{\bf S})$ is equivalent
    to making ${\bf s}_{j}$ closer to ${\bf s}_{j^{\prime}}$ if item $j$ and item
    $j^{\prime}$ are linked (namely ${\bf A}_{jj^{\prime}}=1$) ([CTRSR,](#bib.bib115)
    ).
  prefs: []
  type: TYPE_NORMAL
- en: In RSDAE, the perception variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{\{{\bf
    X}_{l}\},{\bf X}_{c},\{{\bf W}_{l}\},\{{\bf b}_{l}\}\}$, the hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    S}\}$, and the task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{{\bf
    A}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning and Inference: ([RSDAE,](#bib.bib118) ) provides an EM-style algorithm
    for MAP estimation. Below we review some of the key steps.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the E step, the challenge lies in the inference of the relational latent
    matrix ${\bf S}$. We first fix all rows of ${\bf S}$ except the $k$-th one ${\bf
    S}_{k*}$ and then update ${\bf S}_{k*}$. Specifically, we take the gradient of
    $\mathscr{L}$ with respect to ${\bf S}_{k*}$, set it to 0, and get the following
    linear system:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (14) |  | $\displaystyle(\lambda_{l}\mathscr{L}_{a}+\lambda_{r}{\bf I}_{J}){\bf
    S}_{k*}=\lambda_{r}{\bf X}_{\frac{L}{2},*k}^{T}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'A naive approach is to solve the linear system by setting ${\bf S}_{k*}=\lambda_{r}(\lambda_{l}\mathscr{L}_{a}+\lambda_{r}{\bf
    I}_{J})^{-1}{\bf X}_{\frac{L}{2},*k}^{T}$. Unfortunately, the complexity is $O(J^{3})$
    for one single update. Similar to ([DBLP:conf/ijcai/LiY09,](#bib.bib67) ), the
    steepest descent method ([techreport/Shewchuk94,](#bib.bib101) ) is used to iteratively
    update ${\bf S}_{k*}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf S}_{k*}(t+1)\leftarrow{\bf S}_{k*}(t)+\delta(t)r(t),\;\;\;r(t)\leftarrow\lambda_{r}{\bf
    X}_{\frac{L}{2},*k}^{T}-(\lambda_{l}\mathscr{L}_{a}+\lambda_{r}{\bf I}_{J}){\bf
    S}_{k*}(t),\;\;\;\delta(t)\leftarrow\frac{r(t)^{T}r(t)}{r(t)^{T}(\lambda_{l}\mathscr{L}_{a}+\lambda_{r}{\bf
    I}_{J})r(t)}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: As discussed in ([DBLP:conf/ijcai/LiY09,](#bib.bib67) ), the steepest descent
    method dramatically reduces the computation cost in each iteration from $O(J^{3})$
    to $O(J)$.
  prefs: []
  type: TYPE_NORMAL
- en: The M step involves learning ${\bf W}_{l}$ and ${\bf b}_{l}$ for each layer
    using the back-propagation algorithm given ${\bf S}$. By alternating the update
    of ${\bf S}$, ${\bf W}_{l}$, and ${\bf b}_{l}$, a local optimum for $\mathscr{L}$
    can be found. Also, techniques such as including a momentum term may help to avoid
    being trapped in a local optimum.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.2\. Deep Poisson Factor Analysis with Sigmoid Belief Networks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The Poisson distribution with support over nonnegative integers is known as
    a natural choice to model counts. It is, therefore, desirable to use it as a building
    block for topic models, which are generally interested in word counts ([LDA,](#bib.bib8)
    ). With this motivation, ([PFA,](#bib.bib136) ) proposed a model, dubbed Poisson
    factor analysis (PFA), for latent nonnegative matrix factorization via Poisson
    distributions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Poisson Factor Analysis: PFA assumes a discrete $P$-by-$N$ matrix ${\bf X}$
    containing word counts of $N$ documents with a vocabulary size of $P$ ([PFA,](#bib.bib136)
    ; [DPFA,](#bib.bib24) ). In a nutshell, PFA can be described using the equation
    ${\bf X}\sim\mbox{Pois}(\mbox{\boldmath$\Phi$\unboldmath}(\mbox{\boldmath$\Theta$\unboldmath}\circ{\bf
    H}))$, where $\Phi$ (of size $P$-by-$K$ where $K$ is the number of topics) denotes
    the factor loading matrix in factor analysis with the $k$-th column $\mbox{\boldmath$\phi$\unboldmath}_{k}$
    encoding the importance of each word in topic $k$. The $K$-by-$N$ matrix $\Theta$
    is the factor score matrix with the $n$-th column $\mbox{\boldmath$\theta$\unboldmath}_{n}$
    containing topic proportions for document $n$. The $K$-by-$N$ matrix ${\bf H}$
    is a latent binary matrix with the $n$-th column ${\bf h}_{n}$ defining a set
    of topics associated with document $n$.'
  prefs: []
  type: TYPE_NORMAL
- en: Different priors correspond to different models. For example, Dirichlet priors
    on $\mbox{\boldmath$\phi$\unboldmath}_{k}$ and $\mbox{\boldmath$\theta$\unboldmath}_{n}$
    with an all-one matrix ${\bf H}$ would recover LDA ([LDA,](#bib.bib8) ) while
    a beta-Bernoulli prior on ${\bf h}_{n}$ leads to the NB-FTM model in ([DBLP:journals/pami/ZhouC15,](#bib.bib135)
    ). In ([DPFA,](#bib.bib24) ), a deep-structured prior based on sigmoid belief
    networks (SBN) ([neal1992,](#bib.bib79) ) (an MLP variant with binary hidden units)
    is imposed on ${\bf h}_{n}$ to form a deep PFA model for topic modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Poisson Factor Analysis: In the deep PFA model ([DPFA,](#bib.bib24) ),
    the generative process can be summarized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mbox{\boldmath$\phi$\unboldmath}_{k}$ | $\displaystyle\sim\mbox{Dir}(a_{\phi},\dots,a_{\phi}),\;\;\;\;\theta_{kn}\sim\mbox{Gamma}(r_{k},\frac{p_{n}}{1-p_{n}}),\;\;\;\;r_{k}\sim\mbox{Gamma}(\gamma_{0},\frac{1}{c_{0}}),\;\;\;\;\gamma_{0}\sim\mbox{Gamma}(e_{0},\frac{1}{f_{0}}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (15) |  | $\displaystyle h_{k_{L}n}^{(L)}$ | $\displaystyle\sim\mbox{Ber}(\sigma(b_{k_{L}}^{(L)})),\;\;\;\;h_{k_{l}n}^{(l)}\sim\mbox{Ber}(\sigma({{\bf
    w}_{k_{l}}^{(l)}}^{T}{\bf h}_{n}^{(l+1)}+b_{k_{l}}^{(l)})),\;\;\;\;x_{pnk}\sim\mbox{Pois}(\phi_{pk}\theta_{kn}h_{kn}^{(1)}),\;\;\;\;x_{pn}=\sum\limits_{k=1}^{K}x_{pnk},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $L$ is the number of layers in SBN, which corresponds to Equation ([15](#S5.E15
    "In 5.2.2\. Deep Poisson Factor Analysis with Sigmoid Belief Networks ‣ 5.2\.
    Unsupervised Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models
    and Applications ‣ A Survey on Bayesian Deep Learning")). $x_{pnk}$ is the count
    of word $p$ that comes from topic $k$ in document $n$.
  prefs: []
  type: TYPE_NORMAL
- en: In this model, the perception variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{\{{\bf
    H}^{(l)}\},\{{\bf W}_{l}\},\{{\bf b}_{l}\}\}$, the hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    X}\}$, and the task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{\{\mbox{\boldmath$\phi$\unboldmath}_{k}\},\{r_{k}\},\mbox{\boldmath$\Theta$\unboldmath},\gamma_{0}\}$.
    ${\bf W}_{l}$ is the weight matrix containing columns of ${\bf w}_{k_{l}}^{(l)}$
    and ${\bf b}_{l}$ is the bias vector containing entries of $b_{k_{l}}^{(l)}$ in
    Equation ([15](#S5.E15 "In 5.2.2\. Deep Poisson Factor Analysis with Sigmoid Belief
    Networks ‣ 5.2\. Unsupervised Bayesian Deep Learning for Topic Models ‣ 5\. Concrete
    BDL Models and Applications ‣ A Survey on Bayesian Deep Learning")).
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning Using Bayesian Conditional Density Filtering: Efficient learning algorithms
    are needed for Bayesian treatments of deep PFA. ([DPFA,](#bib.bib24) ) proposed
    to use an online version of MCMC called Bayesian conditional density filtering
    (BCDF) to learn both the global parameters $\mbox{\boldmath$\Psi$\unboldmath}_{g}=(\{\mbox{\boldmath$\phi$\unboldmath}_{k}\},\{r_{k}\},\gamma_{0},\{{\bf
    W}_{l}\},\{{\bf b}_{l}\})$ and the local variables $\mbox{\boldmath$\Psi$\unboldmath}_{l}=(\mbox{\boldmath$\Theta$\unboldmath},\{{\bf
    H}^{(l)}\})$. The key conditional densities used for the Gibbs updates are as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle x_{pnk}&#124;-$ | $\displaystyle\sim\mbox{Multi}(x_{pn};\zeta_{pn1},\dots,\zeta_{pnK}),\;\;\;\;\mbox{\boldmath$\phi$\unboldmath}_{k}&#124;-\sim\mbox{Dir}(a_{\phi}+x_{1\cdot
    k},\dots,a_{\phi}+x_{P\cdot k}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle\theta_{kn}&#124;-$ | $\displaystyle\sim\mbox{Gamma}(r_{k}h_{kn}^{(1)}+x_{\cdot
    nk},p_{n}),\;\;\;\;h_{kn}^{(1)}&#124;-\sim\delta(x_{\cdot nk}=0)\mbox{Ber}(\frac{\widetilde{\pi}_{kn}}{\widetilde{\pi}_{kn}+(1-\pi_{kn})})+\delta(x_{\cdot
    nk}>0),$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\widetilde{\pi}_{kn}=\pi_{kn}(1-p_{n})^{r_{k}}$, $\pi_{kn}=\sigma(({\bf
    w}_{k}^{(1)})^{T}{\bf h}_{n}^{(2)}+c_{k}^{(1)})$, $x_{\cdot nk}=\sum\limits_{p=1}^{P}x_{pnk}$,
    $x_{p\cdot k}=\sum\limits_{n=1}^{N}x_{pnk}$, and $\zeta_{pnk}\propto\phi_{pk}\theta_{kn}$.
    For the learning of $h_{kn}^{(l)}$ where $l>1$, the same techniques as in ([DBLP:conf/aistats/GanHCC15,](#bib.bib25)
    ) can be used.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning Using Stochastic Gradient Thermostats: An alternative way of learning
    deep PFA is through *stochastic gradient Nóse-Hoover thermostats* (SGNHT), which
    is more accurate and scalable. SGNHT is a generalization of the *stochastic gradient
    Langevin dynamics* (SGLD) ([SGLD,](#bib.bib127) ) and the *stochastic gradient
    Hamiltonian Monte Carlo* (SGHMC) ([SGHMC,](#bib.bib15) ). Compared with the previous
    two, SGNHT introduces momentum variables into the system, helping the system to
    jump out of local optima. Specifically, the following stochastic differential
    equations (SDE) can be used:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle d\mbox{\boldmath$\Psi$\unboldmath}_{g}={\bf v}dt,\;\;\;\;d{\bf
    v}=\widetilde{f}(\mbox{\boldmath$\Psi$\unboldmath}_{g})dt-\xi{\bf v}dt+\sqrt{D}d\mathcal{W},\;\;\;\;d\xi=(\frac{1}{M}{\bf
    v}^{T}{\bf v}-1)dt,$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\widetilde{f}(\mbox{\boldmath$\Psi$\unboldmath}_{g})=-\nabla_{\mbox{\boldmath$\Psi$\unboldmath}_{g}}\widetilde{U}(\mbox{\boldmath$\Psi$\unboldmath}_{g})$
    and $\widetilde{U}(\mbox{\boldmath$\Psi$\unboldmath}_{g})$ is the negative log-posterior
    of the model. $t$ indexes time and $\mathcal{W}$ denotes the standard Wiener process.
    $\xi$ is the thermostats variable to make sure the system has a constant temperature.
    $D$ is the injected variance which is a constant. To speed up convergence, the
    SDE is generalized to:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle d\mbox{\boldmath$\Psi$\unboldmath}_{g}={\bf v}dt,\;\;\;\;d{\bf
    v}=\widetilde{f}(\mbox{\boldmath$\Psi$\unboldmath}_{g})dt-\mbox{\boldmath$\Xi$\unboldmath}{\bf
    v}dt+\sqrt{D}d\mathcal{W},\;\;\;\;d\mbox{\boldmath$\Xi$\unboldmath}=({\bf q}-{\bf
    I})dt,$ |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\bf I}$ is the identity matrix, $\mbox{\boldmath$\Xi$\unboldmath}=\mbox{diag}(\xi_{1},\dots,\xi_{M})$,
    ${\bf q}=\mbox{diag}(v_{1}^{2},\dots,v_{M}^{2})$, and $M$ is the dimensionality
    of the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: SGNHT, SGLD, and SGHMC all belong to a larger class of sampling algorithms called
    hybrid Monte Carlo (HMC) ([PRML,](#bib.bib5) ). The idea is to leverage an analogy
    with physical systems to guide transitions of system states. Compared to the Metropolis
    algorithm, HMC can make much larger changes to system states while keeping a small
    rejection probability. For more details, we refer readers to ([PRML,](#bib.bib5)
    ; [neal2011mcmc,](#bib.bib81) ).
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.3\. Deep Poisson Factor Analysis with Restricted Boltzmann Machine
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The deep PFA model above uses SBN as a perception component. Similarly, one
    can replace SBN with RBM ([RBM,](#bib.bib40) ) (discussed in Section [4.3.1](#S4.SS3.SSS1
    "4.3.1\. Restricted Boltzmann Machine ‣ 4.3\. Perception Component ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")) to achieve comparable performance.
    With RBM as the perception component, Equation ([15](#S5.E15 "In 5.2.2\. Deep
    Poisson Factor Analysis with Sigmoid Belief Networks ‣ 5.2\. Unsupervised Bayesian
    Deep Learning for Topic Models ‣ 5\. Concrete BDL Models and Applications ‣ A
    Survey on Bayesian Deep Learning")) becomes conditional distributions similar
    to Equation ([4](#S4.E4 "In 4.3.1\. Restricted Boltzmann Machine ‣ 4.3\. Perception
    Component ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning"))
    with the following energy ([RBM,](#bib.bib40) ):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle E({\bf h}_{n}^{(l)},{\bf h}_{n}^{(l+1)})=-({\bf h}_{n}^{(l)})^{T}{\bf
    c}^{(l)}-({\bf h}_{n}^{(l)})^{T}{\bf W}^{(l)}{\bf h}_{n}^{(l+1)}-({\bf h}_{n}^{(l+1)})^{T}{\bf
    c}^{(l+1)}.$ |  |'
  prefs: []
  type: TYPE_TB
- en: Similar learning algorithms as the deep PFA with SBN can be used. Specifically,
    the sampling process would alternate between $\{\{\mbox{\boldmath$\phi$\unboldmath}_{k}\},\{\gamma_{k}\},\gamma_{0}\}$
    and $\{\{{\bf W}^{(l)}\},\{{\bf c}^{(l)}\}\}$. The former involves similar conditional
    density as the SBN-based DPFA. The latter is RBM’s parameters and can be updated
    using the *contrastive divergence* algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2.4\. Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Here we choose topic models as an example application to demonstrate how BDL
    can be applied in the unsupervised learning setting. In BDL-based topic models,
    the perception component is responsible for inferring the topic hierarchy from
    documents, while the task-specific component is in charge of modeling the word
    generation, topic generation, word-topic relation, or inter-document relation.
    The synergy between these two components comes from the bidirectional interaction
    between them. On one hand, knowledge on the topic hierarchy facilitates accurate
    modeling of words and topics, providing valuable information for learning inter-document
    relation. On the other hand, accurately modeling the words, topics, and inter-document
    relation can help discover the topic hierarchy and learn compact latent factors
    for documents.
  prefs: []
  type: TYPE_NORMAL
- en: It is worth noting that the *information exchange* mechanism in some BDL-based
    topic models is different from that in Section [5.1](#S5.SS1 "5.1\. Supervised
    Bayesian Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning"). For example, in the SBN-based DPFA model,
    the exchange is natural since the bottom layer of SBN, ${\bf H}^{(1)}$, and the
    relationship between ${\bf H}^{(1)}$ and $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    X}\}$ are both inherently probabilistic, as shown in Equation ([15](#S5.E15 "In
    5.2.2\. Deep Poisson Factor Analysis with Sigmoid Belief Networks ‣ 5.2\. Unsupervised
    Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning")), which means additional assumptions on
    the distribution are not necessary. The SBN-based DPFA model is equivalent to
    assuming that ${\bf H}$ in PFA is generated from a Dirac delta distribution (a
    Gaussian distribution with zero variance) centered at the bottom layer of the
    SBN, ${\bf H}^{(1)}$. Hence both DPFA models in Table [1](#S3.T1 "Table 1 ‣ 3.1\.
    Models ‣ 3\. Probabilistic Graphical Models ‣ A Survey on Bayesian Deep Learning")
    are ZV models, according to the definition in Section [4.2](#S4.SS2 "4.2\. General
    Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning").
    It is worth noting that RSDAE is an HV model (see Equation ([11](#S5.E11 "In item
    3 ‣ 5.2.1\. Relational Stacked Denoising Autoencoders as Topic Models ‣ 5.2\.
    Unsupervised Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models
    and Applications ‣ A Survey on Bayesian Deep Learning")), where ${\bf S}$ is the
    hinge variable and the others are perception variables), and naively modifying
    this model to be its ZV counterpart would violate the i.i.d. requirement in Section [4.2](#S4.SS2
    "4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep
    Learning").
  prefs: []
  type: TYPE_NORMAL
- en: Similar to Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian Deep Learning for
    Recommender Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian
    Deep Learning"), BDL-based topic models above use typical static Bayesian networks
    as task-specific components. Naturally, one can choose to use other forms of task-specific
    components. For example, it is straightforward to replace the relational prior
    of RSDAE in Section [5.2.1](#S5.SS2.SSS1 "5.2.1\. Relational Stacked Denoising
    Autoencoders as Topic Models ‣ 5.2\. Unsupervised Bayesian Deep Learning for Topic
    Models ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep
    Learning") with a stochastic process (e.g., a Wiener process as in ([cDTM,](#bib.bib113)
    )) to model the evolution of the topic hierarchy over time.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3\. Bayesian Deep Representation Learning for Control
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian Deep Learning for Recommender
    Systems ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep
    Learning") and Section [5.2](#S5.SS2 "5.2\. Unsupervised Bayesian Deep Learning
    for Topic Models ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian
    Deep Learning"), we covered how BDL can be applied in the supervised and unsupervised
    learning settings, respectively. In this section, we will discuss how BDL can
    help representation learning in general, using *control* as an example application.
  prefs: []
  type: TYPE_NORMAL
- en: As mentioned in Section [1](#S1 "1\. Introduction ‣ A Survey on Bayesian Deep
    Learning"), Bayesian deep learning can also be applied to the control of nonlinear
    dynamical systems from raw images. Consider controlling a complex dynamical system
    according to the live video stream received from a camera. One way of solving
    this control problem is by iteration between two tasks, perception from raw images
    and control based on dynamic models. The perception task can be taken care of
    using multiple layers of simple nonlinear transformation (deep learning) while
    the control task usually needs more sophisticated models like hidden Markov models
    and Kalman filters ([harrison1999bayesian,](#bib.bib35) ; [DBLP:conf/uai/MatsubaraGK14,](#bib.bib74)
    ). To enable an effective iterative process between the perception task and the
    control task, we need two-way information exchange between them. The perception
    component would be the basis on which the control component estimates its states
    and on the other hand, the control component with a dynamic model built in would
    be able to predict the future trajectory (images) by reversing the perception
    process ([watter2015embed,](#bib.bib125) ).
  prefs: []
  type: TYPE_NORMAL
- en: As one of the pioneering works in this direction, ([watter2015embed,](#bib.bib125)
    ) posed this task as a representation learning problem and proposed a model called
    *Embed to Control* to take into account the feedback loop mentioned above during
    representation learning. Essentially, the goal is to learn representations that
    (1) capture semantic information from raw images/videos and (2) preserve local
    linearity in the state space for convenient control. This is not possible without
    the BDL framework since the perception component guarantees the first sub-goal
    while the task-specific component guarantees the second. Below we start with some
    preliminaries on stochastic optimal control and then introduce the BDL-based model
    for representation learning.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1\. Stochastic Optimal Control
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Following ([watter2015embed,](#bib.bib125) ), we consider the stochastic optimal
    control of an unknown dynamical system as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (16) |  | $\displaystyle{\bf z}_{t+1}=f({\bf z}_{t},{\bf u}_{t})+\mbox{\boldmath$\xi$\unboldmath},\
    \mbox{\boldmath$\xi$\unboldmath}\sim{\mathcal{N}}(0,\mbox{\boldmath$\Sigma$\unboldmath}_{\xi}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $t$ indexes the time steps and ${\bf z}_{t}\in\mathbb{R}^{n_{z}}$ is
    the latent states. ${\bf u}_{t}\in\mathbb{R}^{n_{u}}$ is the applied control at
    time $t$ and $\xi$ denotes the system noise. Equivalently, the equation above
    can be written as $P({\bf z}_{t+1}|{\bf z}_{t},{\bf u}_{t})={\mathcal{N}}({\bf
    z}_{t+1}|f({\bf z}_{t},{\bf u}_{t}),\mbox{\boldmath$\Sigma$\unboldmath}_{\xi})$.
    Hence we need a mapping function to map the corresponding raw image ${\bf x}_{t}$
    (observed input) into the latent space:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\bf z}_{t}=m({\bf x}_{t})+\mbox{\boldmath$\omega$\unboldmath},\
    \mbox{\boldmath$\omega$\unboldmath}\sim{\mathcal{N}}(0,\mbox{\boldmath$\Sigma$\unboldmath}_{\omega}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\omega$ is the corresponding system noise. Similarly the equation above
    can be rewritten as ${\bf z}_{t}\sim{\mathcal{N}}(m({\bf x}_{t}),\mbox{\boldmath$\Sigma$\unboldmath}_{\omega})$.
    If the function $f$ is given, finding optimal control for a trajectory of length
    $T$ in a dynamical system amounts to minimizing the following cost:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (17) |  | $\displaystyle J({\bf z}_{1:T},{\bf u}_{1:T})=\mathbb{E}_{{\bf
    z}}(c_{T}({\bf z}_{T},{\bf u}_{T})+\sum\limits_{t_{0}}^{T-1}c({\bf z}_{t},{\bf
    u}_{t})),$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $c_{T}({\bf z}_{T},{\bf u}_{T})$ is the terminal cost and $c({\bf z}_{t},{\bf
    u}_{t})$ is the instantaneous cost. ${\bf z}_{1:T}=\{{\bf z}_{1},\dots,{\bf z}_{T}\}$
    and ${\bf u}_{1:T}=\{{\bf u}_{1},\dots,{\bf u}_{T}\}$ are the state and action
    sequences, respectively. For simplicity we can let $c_{T}({\bf z}_{T},{\bf u}_{T})=c({\bf
    z}_{T},{\bf u}_{T})$ and use the following quadratic cost $c({\bf z}_{t},{\bf
    u}_{t})=({\bf z}_{t}-{\bf z}_{goal})^{T}{\bf R}_{z}({\bf z}_{t}-{\bf z}_{goal})+{\bf
    u}_{t}^{T}{\bf R}_{u}{\bf u}_{t},$ where ${\bf R}_{z}\in\mathbb{R}^{n_{z}\times
    n_{z}}$ and ${\bf R}_{u}\in\mathbb{R}^{n_{u}\times n_{u}}$ are the weighting matrices.
    ${\bf z}_{goal}$ is the target latent state that should be inferred from the raw
    images (observed input). Given the function $f$, $\overline{{\bf z}}_{1:T}$ (current
    estimates of the optimal trajectory), and $\overline{{\bf u}}_{1:T}$ (the corresponding
    controls), the dynamical system can be linearized as:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (18) |  | $\displaystyle{\bf z}_{t+1}={\bf A}(\overline{{\bf z}}_{t}){\bf
    z}_{t}+{\bf B}(\overline{{\bf z}}_{t}){\bf u}_{t}+{\bf o}(\overline{{\bf z}}_{t})+\mbox{\boldmath$\omega$\unboldmath},\
    \mbox{\boldmath$\omega$\unboldmath}\sim{\mathcal{N}}(0,\mbox{\boldmath$\Sigma$\unboldmath}_{\omega}),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\bf A}(\overline{{\bf z}}_{t})=\frac{\partial f(\overline{{\bf z}}_{t},\overline{{\bf
    u}}_{t})}{\partial\overline{{\bf z}}_{t}}$ and ${\bf B}(\overline{{\bf z}}_{t})=\frac{\partial
    f(\overline{{\bf z}}_{t},\overline{{\bf u}}_{t})}{\partial\overline{{\bf u}}_{t}}$
    are local Jacobians. ${\bf o}(\overline{{\bf z}}_{t})$ is the offset.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.2\. BDL-Based Representation Learning for Control
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'To minimize the function in Equation ([17](#S5.E17 "In 5.3.1\. Stochastic Optimal
    Control ‣ 5.3\. Bayesian Deep Representation Learning for Control ‣ 5\. Concrete
    BDL Models and Applications ‣ A Survey on Bayesian Deep Learning")), we need three
    key components: an encoding model to encode ${\bf x}_{t}$ into ${\bf z}_{t}$,
    a transition model to infer ${\bf z}_{t+1}$ given $({\bf z}_{t},{\bf u}_{t})$,
    and a reconstruction model to reconstruct ${\bf x}_{t+1}$ from the inferred ${\bf
    z}_{t+1}$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Encoding Model: An encoding model $Q_{\phi}(Z|X)={\mathcal{N}}(\mbox{\boldmath$\mu$\unboldmath}_{t},\mbox{diag}(\mbox{\boldmath$\sigma$\unboldmath}_{t}^{2}))$,
    where the mean $\mbox{\boldmath$\mu$\unboldmath}_{t}\in\mathbb{R}^{n_{z}}$ and
    the diagonal covariance $\mbox{\boldmath$\Sigma$\unboldmath}_{t}=\mbox{diag}(\mbox{\boldmath$\sigma$\unboldmath}_{t}^{2})\in\mathbb{R}^{n_{z}\times
    n_{z}}$, encodes the raw images ${\bf x}_{t}$ into latent states ${\bf z}_{t}$.
    Here,'
  prefs: []
  type: TYPE_NORMAL
- en: '| (19) |  | $\displaystyle\mbox{\boldmath$\mu$\unboldmath}_{t}$ | $\displaystyle={\bf
    W}_{\mu}h_{\phi}^{\text{enc}}({\bf x}_{t})+{\bf b}_{\mu},\;\;\;\;\log\mbox{\boldmath$\sigma$\unboldmath}_{t}={\bf
    W}_{\sigma}h_{\phi}^{\text{enc}}({\bf x}_{t})+{\bf b}_{\sigma},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $h_{\phi}({\bf x}_{t})^{\text{enc}}$ is the output of the encoding network
    with ${\bf x}_{t}$ as its input.
  prefs: []
  type: TYPE_NORMAL
- en: 'Transition Model: A transition model like Equation ([18](#S5.E18 "In 5.3.1\.
    Stochastic Optimal Control ‣ 5.3\. Bayesian Deep Representation Learning for Control
    ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning"))
    infers ${\bf z}_{t+1}$ from $({\bf z}_{t},{\bf u}_{t})$. If we use $\widetilde{Q}_{\psi}(\widetilde{Z}|Z,{\bf
    u})$ to denote the approximate posterior distribution to generate ${\bf z}_{t+1}$,
    the generative process of the full model would be:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (20) |  | $\displaystyle{\bf z}_{t}$ | $\displaystyle\sim Q_{\phi}(Z&#124;X)={\mathcal{N}}(\mbox{\boldmath$\mu$\unboldmath}_{t},\mbox{\boldmath$\Sigma$\unboldmath}_{t}),\;\;\widetilde{{\bf
    z}}_{t+1}\sim\widetilde{Q}_{\psi}(\widetilde{Z}&#124;Z,{\bf u})={\mathcal{N}}({\bf
    A}_{t}\mbox{\boldmath$\mu$\unboldmath}_{t}+{\bf B}_{t}{\bf u}_{t}+{\bf o}_{t},{\bf
    C}_{t}),\;\;\widetilde{{\bf x}}_{t},\widetilde{{\bf x}}_{t+1}\sim P_{\theta}(X&#124;Z)=Bern({\bf
    p}_{t}),$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where the last equation is the reconstruction model to be discussed later,
    ${\bf C}_{t}={\bf A}_{t}\mbox{\boldmath$\Sigma$\unboldmath}_{t}{\bf A}_{t}^{T}+{\bf
    H}_{t}$, and ${\bf H}_{t}$ is the covariance matrix of the estimated system noise
    ($\mbox{\boldmath$\omega$\unboldmath}_{t}\sim{\mathcal{N}}({\bf 0},{\bf H}_{t})$).
    The key here is to learn ${\bf A}_{t}$, ${\bf B}_{t}$ and ${\bf o}_{t}$, which
    are parameterized as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\text{vec}({\bf A}_{t})={\bf W}_{A}h_{\psi}^{\text{trans}}({\bf
    z}_{t})+{\bf b}_{A},\;\;\;\;\text{vec}({\bf B}_{t})={\bf W}_{B}h_{\psi}^{\text{trans}}({\bf
    z}_{t})+{\bf b}_{B},\;\;\;\;{\bf o}_{t}={\bf W}_{o}h_{\psi}^{\text{trans}}({\bf
    z}_{t})+{\bf b}_{o},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $h_{\psi}^{\text{trans}}({\bf z}_{t})$ is the output of the transition
    network.
  prefs: []
  type: TYPE_NORMAL
- en: 'Reconstruction Model: As mentioned in the last part of Equation ([20](#S5.E20
    "In 5.3.2\. BDL-Based Representation Learning for Control ‣ 5.3\. Bayesian Deep
    Representation Learning for Control ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning")), the posterior distribution $P_{\theta}(X|Z)$
    reconstructs the raw images ${\bf x}_{t}$ from the latent states ${\bf z}_{t}$.
    The parameters for the Bernoulli distribution ${\bf p}_{t}={\bf W}_{p}h_{\theta}^{\text{dec}}({\bf
    z}_{t})+{\bf b}_{p}$ where $h_{\theta}^{\text{dec}}({\bf z}_{t})$ is the output
    of a third network, called the decoding network or the reconstruction network.
    Putting it all together, Equation ([20](#S5.E20 "In 5.3.2\. BDL-Based Representation
    Learning for Control ‣ 5.3\. Bayesian Deep Representation Learning for Control
    ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian Deep Learning"))
    shows the generative process of the full model.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.3\. Learning Using Stochastic Gradient Variational Bayes
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'With $\mathcal{D}=\{({\bf x}_{1},{\bf u}_{1},{\bf x}_{2}),\dots,({\bf x}_{T-1},{\bf
    u}_{T-1},{\bf x}_{T})\}$ as the training set, the loss function is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathcal{L}=\sum\limits_{({\bf x}_{t},{\bf u}_{t},{\bf x}_{t+1})\in\mathcal{D}}\mathcal{L}^{\text{bound}}({\bf
    x}_{t},{\bf u}_{t},{\bf x}_{t+1})+\lambda~{}\mbox{KL}(\widetilde{Q}_{\psi}(\widetilde{Z}&#124;\mbox{\boldmath$\mu$\unboldmath}_{t},{\bf
    u}_{t})\&#124;Q_{\phi}(Z&#124;{\bf x}_{t+1})),$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where the first term is the variational bound on the marginalized log-likelihood
    for each data point:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathcal{L}^{\text{bound}}({\bf x}_{t},{\bf u}_{t},{\bf
    x}_{t+1})=\mathbb{E}_{\begin{subarray}{c}{\bf z}_{t}\sim Q_{\phi}\\ \widetilde{{\bf
    z}}_{t+1}\sim\widetilde{Q}_{\psi}\end{subarray}}(-\log P_{\theta}({\bf x}_{t}&#124;{\bf
    z}_{t})-\log P_{\theta}({\bf x}_{t+1}&#124;\widetilde{{\bf z}}_{t+1}))+\mbox{KL}(Q_{\phi}\&#124;P(Z)),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $P(Z)$ is the prior distribution for $Z$. With the equations above, stochastic
    gradient variational Bayes can be used to learn the parameters.
  prefs: []
  type: TYPE_NORMAL
- en: According to the generative process in Equation ([20](#S5.E20 "In 5.3.2\. BDL-Based
    Representation Learning for Control ‣ 5.3\. Bayesian Deep Representation Learning
    for Control ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on Bayesian
    Deep Learning")) and the definition in Section [4.2](#S4.SS2 "4.2\. General Framework
    ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep Learning"), the perception
    variables $\mbox{\boldmath$\Omega$\unboldmath}_{p}=\{h_{\phi}^{\text{enc}}(\cdot),{\bf
    W}_{p}^{+},{\bf x}_{t},\mbox{\boldmath$\mu$\unboldmath}_{t},\mbox{\boldmath$\sigma$\unboldmath}_{t},{\bf
    p}_{t},h_{\theta}^{\text{dec}}(\cdot)\}$, where ${\bf W}_{p}^{+}$ is shorthand
    for $\{{\bf W}_{\mu},{\bf b}_{\mu},{\bf W}_{\sigma},{\bf b}_{\sigma},{\bf W}_{p},{\bf
    b}_{p}\}$. The hinge variables $\mbox{\boldmath$\Omega$\unboldmath}_{h}=\{{\bf
    z}_{t},{\bf z}_{t+1}\}$ and the task variables $\mbox{\boldmath$\Omega$\unboldmath}_{t}=\{{\bf
    A}_{t},{\bf B}_{t},{\bf o}_{t},{\bf u}_{t},{\bf C}_{t},\mbox{\boldmath$\omega$\unboldmath}_{t},{\bf
    W}_{t}^{+},h_{\psi}^{\text{trans}}(\cdot)\}$, where ${\bf W}_{t}^{+}$ is shorthand
    for $\{{\bf W}_{A},{\bf b}_{A},{\bf W}_{B},{\bf b}_{B},{\bf W}_{o},{\bf b}_{o}\}$.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.4\. Discussion
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The example model above demonstrates BDL’s capability of learning representations
    that satisfy domain-specific requirements. In the case of *control*, we are interested
    in learning representations that can capture semantic information from raw input
    and preserve local linearity in the space of system states.
  prefs: []
  type: TYPE_NORMAL
- en: To achieve this goal, the BDL-based model consists of two components, a perception
    component to *see* the live video and a control (task-specific) component to *infer*
    the states of the dynamical system. Inference of the system is based on the mapped
    states and the confidence of mapping from the perception component, and in turn,
    the control signals sent by the control component would affect the live video
    received by the perception component. Only when the two components work interactively
    within a unified probabilistic framework can the model reach its full potential
    and achieve the best control performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the BDL-based control model discussed above uses a different *information
    exchange* mechanism from that in Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian
    Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning") and Section [5.2](#S5.SS2 "5.2\. Unsupervised
    Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning"): it follows the VAE mechanism and uses
    neural networks to *separately* parameterize the mean and covariance of hinge
    variables (e.g., in the encoding model, the hinge variable ${\bf z}_{t}\sim{\mathcal{N}}(\mbox{\boldmath$\mu$\unboldmath}_{t},\mbox{diag}(\mbox{\boldmath$\sigma$\unboldmath}_{t}^{2}))$,
    where $\mbox{\boldmath$\mu$\unboldmath}_{t}$ and $\mbox{\boldmath$\sigma$\unboldmath}_{t}$
    are perception variables parameterized as in Equation ([19](#S5.E19 "In 5.3.2\.
    BDL-Based Representation Learning for Control ‣ 5.3\. Bayesian Deep Representation
    Learning for Control ‣ 5\. Concrete BDL Models and Applications ‣ A Survey on
    Bayesian Deep Learning"))), which is more flexible (with more free parameters)
    than models like CDL and CDR in Section [5.1](#S5.SS1 "5.1\. Supervised Bayesian
    Deep Learning for Recommender Systems ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning"), where Gaussian distributions with fixed
    variance are also used. Note that this BDL-based control model is an LV model
    as shown in Table [1](#S3.T1 "Table 1 ‣ 3.1\. Models ‣ 3\. Probabilistic Graphical
    Models ‣ A Survey on Bayesian Deep Learning"), and since the covariance is assumed
    to be diagonal, the model still meets the independence requirement in Section
    [4.2](#S4.SS2 "4.2\. General Framework ‣ 4\. Bayesian Deep Learning ‣ A Survey
    on Bayesian Deep Learning").'
  prefs: []
  type: TYPE_NORMAL
- en: 5.4\. Bayesian Deep Learning for Other Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: BDL has found wide applications such as recommender systems, topic models, and
    control in supervised learning, unsupervised learning, and representation learning
    in general. In this section, we briefly discuss a few more applications that could
    benefit from BDL.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.1\. Link Prediction
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Link prediction has long been a core problem in network analysis and is recently
    attracting more interest with the new advancements brought by BDL and deep neural
    networks in general. ([RDL,](#bib.bib120) ) proposed the first BDL-based model,
    dubbed relational deep learning (RDL), for link prediction. Graphite ([Graphite,](#bib.bib32)
    ) extends RDL using a perception component based on graph convolutional networks
    (GCN) ([GCN,](#bib.bib59) ). ([SBGNN,](#bib.bib75) ) combines the classic stochastic
    blockmodel ([SBM,](#bib.bib82) ) (as a task-specific component) and GCN-based
    perception component to jointly model latent community structures and link generation
    in a graph with reported state-of-the-art performance in link prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.2\. Natural Language Processing
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Besides topic modeling as discussed in Section [5.2](#S5.SS2 "5.2\. Unsupervised
    Bayesian Deep Learning for Topic Models ‣ 5\. Concrete BDL Models and Applications
    ‣ A Survey on Bayesian Deep Learning"), BDL is also useful for natural language
    processing in general. For example, ([S2BS,](#bib.bib77) ) and ([QuaSE,](#bib.bib69)
    ) build on top of the BDL principles to define a language revision process. These
    models typically involve RNN-based perception components and relatively simple
    task-specific components linking the input and output sequences.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.3\. Computer Vision
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: BDL is particularly powerful for computer vision in the unsupervised learning
    setting. This is because in the BDL framework, one can clearly define a generative
    process of how objects in a scene are generated from various factors such as counts,
    positions, and the content ([AIR,](#bib.bib20) ). The perception component, usually
    taking the form of a probabilistic neural network, can focus on modeling the raw
    images’ visual features, while the task-specific component handles the conditional
    dependencies among objects’ various attributes in the images. One notable work
    in this direction is *Attend, Infer, Repeat* (AIR) ([AIR,](#bib.bib20) ), where
    the task-specific component involves latent variables on each object’ position,
    scale, appearance, and presence (which is related to counting of objects). Following
    AIR, variants such as Fast AIR ([FastAIR,](#bib.bib105) ) and Sequential AIR ([SQAIR,](#bib.bib60)
    ) are proposed to improve its computational efficiency and performance. Besides
    unsupervised learning, BDL can also be useful for supervised learning tasks such
    as action recognition in videos ([ATF,](#bib.bib102) ), where conditional dependencies
    among different actions are modeled using a task-specific component.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.4\. Speech
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the field of speech recognition and synthesis, researchers have also been
    adopting the BDL framework to improve both accuracy and interpretability. For
    example, factorized hierarchical VAE ([FHVAE,](#bib.bib48) ; [SFHVAE,](#bib.bib47)
    ) composes VAE with a factorized latent variable model (represented as a PGM)
    to learn different latent factors in speech data following an unsupervised setting.
    Similarly, Gaussian mixture VAE ([GMVAE,](#bib.bib49) ) uses a Gaussian mixture
    model as the task-specific component to achieve controllable speech synthesis
    from text. In terms of speech recognition, recurrent Poisson process units (RPPU) ([RPPU,](#bib.bib51)
    ) instead adopt a different form of task-specific component; they use a stochastic
    process (i.e., a Poisson process) as the task-specific component to model boundaries
    between phonemes and successfully achieve a significantly lower word error rate
    (WER) for speech recognition. Similarly, deep graph random process (DGP) ([DGP,](#bib.bib52)
    ) as another stochastic process operates on graphs to model the relational structure
    among utterances, further improving performance in speech recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.5\. Time Series Forecasting
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Time series forecasting is a long-standing core problem in economics, statistics,
    and machine learning ([harvey1990forecasting,](#bib.bib36) ). It has wide applications
    across multiple areas. For example, accurate forecasts of regional energy consumption
    can provide valuable guidance to optimize energy generation and allocation. In
    e-commerce, retails rely on demand forecasts to decide when and where to replenish
    their supplies, thereby avoiding items going out of stock and guaranteeing fastest
    deliveries for customers. During a pandemic such as COVID-19, it is crucial to
    obtain reasonable forecasts on hospital workload and medical supply demand in
    order to best allocate resources across the country. Needless to say, an ideal
    forecasting model requires both efficient processing of high-dimensional data
    and sophisticated modeling of different random variables, either observed or latent.
    BDL-based forecasting models ([DeepAR,](#bib.bib21) ; [SQF-RNN,](#bib.bib27) ;
    [DeepState,](#bib.bib90) ; [DeepFactor,](#bib.bib124) ) achieve these with an
    RNN-based perception component and a task-specific component handling the conditional
    dependencies among different variables, showing substantial improvement over previous
    non-BDL forecasting models.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4.6\. Health Care
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In health-care-related applications ([ravi2016deep,](#bib.bib91) ), it is often
    desirable to incorporate human knowledge into models, either to boost performance
    or more importantly to improve interpretability. It is also crutial to ensure
    models’ robustness when they are used on under-represented data. BDL therefore
    provides a unified framework to meet all these requirements: (1) with its Bayesian
    nature, it can impose proper priors and perform Bayesian model averaging to improve
    robustness; (2) its task-specific component can naturally represents and incorporate
    human knowledge if necessary; (3) the model’s joint training provides interpretability
    for its both components. For example, ([DPFM,](#bib.bib38) ) proposed a deep Poisson
    factor model, which essentially stacks layers of Poisson factor models, to analyze
    electronic health records. ([BBFDR,](#bib.bib110) ) built a BDL model with experiment-specific
    priors (knowledge) to control the false discovery rate during study analysis with
    applications to cancer drug screening. ([DeepMarkov,](#bib.bib61) ) developed
    deep nonlinear state space models and demonstrated their effectiveness in processing
    electronic health records and performing counterfactual reasoning. Task-specific
    components in the BDL models above all take the form of a typical Bayesian network
    (as mentioned in Section [4.4.1](#S4.SS4.SSS1 "4.4.1\. Bayesian Networks ‣ 4.4\.
    Task-Specific Component ‣ 4\. Bayesian Deep Learning ‣ A Survey on Bayesian Deep
    Learning")). In contrast, ([BIN,](#bib.bib117) ) proposed to use bidirectional
    inference networks, which are essentially a class of deep Bayesian network, as
    the task-specific component (as mentioned in Section [4.4.2](#S4.SS4.SSS2 "4.4.2\.
    Bidirectional Inference Networks ‣ 4.4\. Task-Specific Component ‣ 4\. Bayesian
    Deep Learning ‣ A Survey on Bayesian Deep Learning")). This enables deep nonlinear
    structures in each conditional distribution of the Bayesian network and improves
    performance for applications such as health profiling.'
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Conclusions and Future Research
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: BDL strives to combine the merits of PGM and NN by organically integrating them
    in a single principled probabilistic framework. In this survey, we identified
    such a current trend and reviewed recent work. A BDL model consists of a perception
    component and a task-specific component; we therefore surveyed different instantiations
    of both components developed over the past few years respectively and discussed
    different variants in detail. To learn parameters in BDL, several types of algorithms
    have been proposed, ranging from block coordinate descent, Bayesian conditional
    density filtering, and stochastic gradient thermostats to stochastic gradient
    variational Bayes.
  prefs: []
  type: TYPE_NORMAL
- en: BDL draws inspiration and gain popularity both from the success of PGM and from
    recent promising advances on deep learning. Since many real-world tasks involve
    both efficient perception from high-dimensional signals (e.g., images and videos)
    and probabilistic inference on random variables, BDL emerges as a natural choice
    to harness the perception ability from NN and the (conditional and causal) inference
    ability from PGM. Over the past few years, BDL has found successful applications
    in various areas such as recommender systems, topic models, stochastic optimal
    control, computer vision, natural language processing, health care, etc. In the
    future, we can expect both more in-depth studies on existing applications and
    exploration on even more complex tasks. Besides, recent progress on efficient
    BNN (as the perception component of BDL) also lays down the foundation for further
    improving BDL’s scalability.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1) Gediminas Adomavicius and YoungOk Kwon. Improving aggregate recommendation
    diversity using ranking-based techniques. TKDE, 24(5):896–911, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (2) Anoop Korattikara Balan, Vivek Rathod, Kevin P Murphy, and Max Welling.
    Bayesian dark knowledge. In NIPS, pages 3420–3428, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (3) Ilaria Bartolini, Zhenjie Zhang, and Dimitris Papadias. Collaborative filtering
    with personalized skylines. TKDE, 23(2):190–203, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (4) Yoshua Bengio, Li Yao, Guillaume Alain, and Pascal Vincent. Generalized
    denoising auto-encoders as generative models. In NIPS, pages 899–907, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (5) Christopher M. Bishop. Pattern Recognition and Machine Learning. Springer-Verlag
    New York, Inc., Secaucus, NJ, USA, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (6) David Blei and John Lafferty. Correlated topic models. NIPS, 18:147, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (7) David M Blei and John D Lafferty. Dynamic topic models. In ICML, pages 113–120\.
    ACM, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (8) David M Blei, Andrew Y Ng, and Michael I Jordan. Latent Dirichlet allocation.
    JMLR, 3:993–1022, 2003.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (9) Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra.
    Weight uncertainty in neural network. In ICML, pages 1613–1622, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (10) Hervé Bourlard and Yves Kamp. Auto-association by multilayer perceptrons
    and singular value decomposition. Biological cybernetics, 59(4-5):291–294, 1988.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (11) Yuri Burda, Roger B. Grosse, and Ruslan Salakhutdinov. Importance weighted
    autoencoders. In ICLR, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (12) Yi Cai, Ho-fung Leung, Qing Li, Huaqing Min, Jie Tang, and Juanzi Li. Typicality-based
    collaborative filtering recommendation. TKDE, 26(3):766–779, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (13) Minmin Chen, Kilian Q Weinberger, Fei Sha, and Yoshua Bengio. Marginalized
    denoising auto-encoders for nonlinear representations. In ICML, pages 1476–1484,
    2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (14) Minmin Chen, Zhixiang Eddie Xu, Kilian Q. Weinberger, and Fei Sha. Marginalized
    denoising autoencoders for domain adaptation. In ICML, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (15) Tianqi Chen, Emily B. Fox, and Carlos Guestrin. Stochastic gradient Hamiltonian
    Monte Carlo. In ICML, pages 1683–1691, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (16) Kyunghyun Cho, Bart van Merrienboer, cCaglar Gülccehre, Dzmitry Bahdanau,
    Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning phrase representations
    using RNN encoder-decoder for statistical machine translation. In EMNLP, pages
    1724–1734, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (17) Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C. Courville,
    and Yoshua Bengio. A recurrent latent variable model for sequential data. In NIPS,
    pages 2980–2988, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (18) Yulai Cong, Bo Chen, Hongwei Liu, and Mingyuan Zhou. Deep latent dirichlet
    allocation with topic-layer-adaptive stochastic gradient riemannian MCMC. In ICML,
    pages 864–873, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (19) Andreas Doerr, Christian Daniel, Martin Schiegg, Duy Nguyen-Tuong, Stefan
    Schaal, Marc Toussaint, and Sebastian Trimpe. Probabilistic recurrent state-space
    models. In ICML, pages 1279–1288, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(20) S. M. Ali Eslami, Nicolas Heess, Theophane Weber, Yuval Tassa, David Szepesvari,
    Koray Kavukcuoglu, and Geoffrey E. Hinton. Attend, infer, repeat: Fast scene understanding
    with generative models. In NIPS, pages 3225–3233, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(21) Valentin Flunkert, David Salinas, and Jan Gasthaus. Deepar: Probabilistic
    forecasting with autoregressive recurrent networks. CoRR, abs/1704.04110, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(22) Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation:
    Insights and applications. In Deep Learning Workshop, ICML, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (23) M. J. F. Gales and S. S. Airey. Product of Gaussians for speech recognition.
    CSL, 20(1):22–40, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (24) Zhe Gan, Changyou Chen, Ricardo Henao, David E. Carlson, and Lawrence Carin.
    Scalable deep Poisson factor analysis for topic modeling. In ICML, pages 1823–1832,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (25) Zhe Gan, Ricardo Henao, David E. Carlson, and Lawrence Carin. Learning
    deep sigmoid belief networks with data augmentation. In AISTATS, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (26) Jochen Gast and Stefan Roth. Lightweight probabilistic deep networks. In
    CVPR, pages 3369–3378, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (27) Jan Gasthaus, Konstantinos Benidis, Yuyang Wang, Syama Sundar Rangapuram,
    David Salinas, Valentin Flunkert, and Tim Januschowski. Probabilistic forecasting
    with spline quantile function rnns. In AISTATS, pages 1901–1910, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (28) Kostadin Georgiev and Preslav Nakov. A non-iid framework for collaborative
    filtering with restricted Boltzmann machines. In ICML, pages 1148–1156, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (29) Ian Goodfellow, Yoshua Bengio, and Aaron Courville. Deep Learning. Book
    in preparation for MIT Press, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (30) Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets.
    In NIPS, pages 2672–2680, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (31) Alex Graves. Practical variational inference for neural networks. In NIPS,
    pages 2348–2356, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(32) Aditya Grover, Aaron Zweig, and Stefano Ermon. Graphite: Iterative generative
    modeling of graphs. In ICML, pages 2434–2444, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (33) A.K. Gupta and D.K. Nagar. Matrix Variate Distributions. Chapman & Hall/CRC
    Monographs and Surveys in Pure and Applied Mathematics. Chapman & Hall, 2000.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (34) Danijar Hafner, Timothy P. Lillicrap, Ian Fischer, Ruben Villegas, David
    Ha, Honglak Lee, and James Davidson. Learning latent dynamics for planning from
    pixels. In ICML, pages 2555–2565, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (35) Jeff Harrison and Mike West. Bayesian Forecasting & Dynamic Models. Springer,
    1999.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (36) Andrew C Harvey. Forecasting, structural time series models and the Kalman
    filter. Cambridge university press, 1990.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(37) Hao He, Hao Wang, Guang-He Lee, and Yonglong Tian. Probgan: Towards probabilistic
    GAN with theoretical guarantees. In ICLR, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (38) Ricardo Henao, James Lu, Joseph E. Lucas, Jeffrey M. Ferranti, and Lawrence
    Carin. Electronic health record analysis via deep poisson factor models. JMLR,
    17:186:1–186:32, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (39) José Miguel Hernández-Lobato and Ryan Adams. Probabilistic backpropagation
    for scalable learning of bayesian neural networks. In ICML, pages 1861–1869, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (40) Geoffrey E. Hinton. Training products of experts by minimizing contrastive
    divergence. Neural Computation, 14(8):1771–1800, 2002.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (41) Geoffrey E Hinton, Simon Osindero, and Yee-Whye Teh. A fast learning algorithm
    for deep belief nets. Neural computation, 18(7):1527–1554, 2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (42) Geoffrey E Hinton and Drew Van Camp. Keeping the neural networks simple
    by minimizing the description length of the weights. In COLT, pages 5–13, 1993.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (43) Geoffrey E Hinton and Richard S Zemel. Autoencoders, minimum description
    length, and Helmholtz free energy. NIPS, pages 3–3, 1994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (44) Matthew Hoffman, Francis R Bach, and David M Blei. Online learning for
    latent Dirichlet allocation. In NIPS, pages 856–864, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (45) Matthew D. Hoffman, David M. Blei, Chong Wang, and John William Paisley.
    Stochastic variational inference. JMLR, 14(1):1303–1347, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(46) Mark F. Hornick and Pablo Tamayo. Extending recommender systems for disjoint
    user/item sets: The conference recommendation problem. TKDE, 24(8):1478–1490,
    2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (47) Wei-Ning Hsu and James R. Glass. Scalable factorized hierarchical variational
    autoencoder training. In INTERSPEECH, pages 1462–1466, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (48) Wei-Ning Hsu, Yu Zhang, and James R. Glass. Unsupervised learning of disentangled
    and interpretable representations from sequential data. In NIPS, pages 1878–1889,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (49) Wei-Ning Hsu, Yu Zhang, Ron J. Weiss, Heiga Zen, Yonghui Wu, Yuxuan Wang,
    Yuan Cao, Ye Jia, Zhifeng Chen, Jonathan Shen, Patrick Nguyen, and Ruoming Pang.
    Hierarchical generative modeling for controllable speech synthesis. In ICLR, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (50) Yifan Hu, Yehuda Koren, and Chris Volinsky. Collaborative filtering for
    implicit feedback datasets. In ICDM, pages 263–272, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (51) Hengguan Huang, Hao Wang, and Brian Mak. Recurrent poisson process unit
    for speech recognition. In AAAI, pages 6538–6545, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (52) Hengguan Huang, Fuzhao Xue, Hao Wang, and Ye Wang. Deep graph random process
    for relational-thinking-based speech recognition. In ICML, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (53) David H Hubel and Torsten N Wiesel. Receptive fields and functional architecture
    of monkey striate cortex. The Journal of physiology, 195(1):215–243, 1968.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (54) Finn V Jensen et al. An introduction to Bayesian networks, volume 210.
    UCL press London, 1996.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (55) Michael I. Jordan, Zoubin Ghahramani, Tommi Jaakkola, and Lawrence K. Saul.
    An introduction to variational methods for graphical models. Machine Learning,
    37(2):183–233, 1999.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (56) Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. A convolutional
    neural network for modelling sentences. ACL, pages 655–665, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(57) Maximilian Karl, Maximilian Sölch, Justin Bayer, and Patrick van der Smagt.
    Deep variational bayes filters: Unsupervised learning of state space models from
    raw data. In ICLR, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (58) Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv
    preprint arXiv:1312.6114, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (59) Thomas N Kipf and Max Welling. Semi-supervised classification with graph
    convolutional networks. arXiv preprint arXiv:1609.02907, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(60) Adam R. Kosiorek, Hyunjik Kim, Yee Whye Teh, and Ingmar Posner. Sequential
    attend, infer, repeat: Generative modelling of moving objects. In NIPS, pages
    8615–8625, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (61) Rahul G. Krishnan, Uri Shalit, and David A. Sontag. Structured inference
    networks for nonlinear state space models. In AAAI, pages 2101–2109, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (62) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification
    with deep convolutional neural networks. In NIPS, pages 1097–1105, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (63) Y. LeCun. Modeles connexionnistes de l’apprentissage (connectionist learning
    models). PhD thesis, Université P. et M. Curie (Paris 6), June 1987.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (64) Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based
    learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324,
    1998.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (65) Honglak Lee, Roger Grosse, Rajesh Ranganath, and Andrew Y Ng. Convolutional
    deep belief networks for scalable unsupervised learning of hierarchical representations.
    In ICML, pages 609–616, 2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (66) Sheng Li, Jaya Kawale, and Yun Fu. Deep collaborative filtering via marginalized
    denoising auto-encoder. In CIKM, pages 811–820, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (67) Wu-Jun Li and Dit-Yan Yeung. Relation regularized matrix factorization.
    In IJCAI, 2009.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (68) Xiaopeng Li and James She. Collaborative variational autoencoder for recommender
    systems. In KDD, pages 305–314, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(69) Yi Liao, Lidong Bing, Piji Li, Shuming Shi, Wai Lam, and Tong Zhang. Quase:
    Sequence editing under quantifiable guidance. In EMNLP, pages 3855–3864, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(70) Nathan Nan Liu, Xiangrui Meng, Chao Liu, and Qiang Yang. Wisdom of the
    better few: cold start recommendation via representative based rating elicitation.
    In RecSys, pages 37–44, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (71) Zhongqi Lu, Zhicheng Dou, Jianxun Lian, Xing Xie, and Qiang Yang. Content-based
    collaborative filtering for news topic recommendation. In AAAI, pages 217–223,
    2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (72) JC MacKay David. A practical Bayesian framework for backprop networks.
    Neural computation, 1992.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (73) Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon
    Wilson. A simple baseline for bayesian uncertainty in deep learning. In NIPS,
    pages 13132–13143, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (74) Takamitsu Matsubara, Vicencc Gómez, and Hilbert J. Kappen. Latent Kullback
    Leibler control for continuous-state systems using probabilistic graphical models.
    In UAI, pages 583–592, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (75) Nikhil Mehta, Lawrence Carin, and Piyush Rai. Stochastic blockmodels meet
    graph neural networks. In ICML, pages 4466–4474, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (76) Abdel-rahman Mohamed, Tara N. Sainath, George E. Dahl, Bhuvana Ramabhadran,
    Geoffrey E. Hinton, and Michael A. Picheny. Deep belief networks using discriminative
    features for phone recognition. In ICASSP, pages 5060–5063, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(77) Jonas Mueller, David K. Gifford, and Tommi S. Jaakkola. Sequence to better
    sequence: Continuous revision of combinatorial structures. In ICML, pages 2536–2544,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(78) Kevin P Murphy. Machine learning: a probabilistic perspective. MIT press,
    2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (79) Radford M. Neal. Connectionist learning of belief networks. Artif. Intell.,
    56(1):71–113, 1992.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (80) Radford M Neal. Bayesian learning for neural networks. PhD thesis, University
    of Toronto, 1995.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (81) Radford M Neal et al. Mcmc using hamiltonian dynamics. Handbook of markov
    chain monte carlo, 2(11):2, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (82) Krzysztof Nowicki and Tom A B Snijders. Estimation and prediction for stochastic
    blockstructures. JASA, 96(455):1077–1087, 2001.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (83) Takahiro Omi, Naonori Ueda, and Kazuyuki Aihara. Fully neural network based
    model for general temporal point processes. In NIPS, pages 2120–2129, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (84) Aäron Van Den Oord, Sander Dieleman, and Benjamin Schrauwen. Deep content-based
    music recommendation. In NIPS, pages 2643–2651, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (85) Yoon-Joo Park. The adaptive clustering method for the long tail problem
    of recommender systems. TKDE, 25(8):1904–1915, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (86) Ian Porteous, David Newman, Alexander Ihler, Arthur Asuncion, Padhraic
    Smyth, and Max Welling. Fast collapsed gibbs sampling for latent Dirichlet allocation.
    In KDD, pages 569–577, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (87) Janis Postels, Francesco Ferroni, Huseyin Coskun, Nassir Navab, and Federico
    Tombari. Sampling-free epistemic uncertainty estimation using approximated variance
    propagation. In ICCV, pages 2931–2940, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (88) Christopher Poultney, Sumit Chopra, Yann L Cun, et al. Efficient learning
    of sparse representations with an energy-based model. In NIPS, pages 1137–1144,
    2006.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (89) Sanjay Purushotham, Yan Liu, and C.-C. Jay Kuo. Collaborative topic regression
    with social matrix factorization for recommendation systems. In ICML, pages 759–766,
    2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (90) Syama Sundar Rangapuram, Matthias W. Seeger, Jan Gasthaus, Lorenzo Stella,
    Yuyang Wang, and Tim Januschowski. Deep state space models for time series forecasting.
    In NIPS, pages 7796–7805, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (91) Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier
    Andreu-Perez, Benny Lo, and Guang-Zhong Yang. Deep learning for health informatics.
    IEEE journal of biomedical and health informatics, 21(1):4–21, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (92) Francesco Ricci, Lior Rokach, and Bracha Shapira. Introduction to Recommender
    Systems Handbook. Springer, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(93) Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, and Yoshua
    Bengio. Contractive auto-encoders: Explicit invariance during feature extraction.
    In ICML, pages 833–840, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (94) Sheldon M Ross, John J Kelly, Roger J Sullivan, William James Perry, Donald
    Mercer, Ruth M Davis, Thomas Dell Washburn, Earl V Sager, Joseph B Boyce, and
    Vincent L Bristow. Stochastic processes, volume 2. Wiley New York, 1996.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (95) Tara N. Sainath, Brian Kingsbury, Vikas Sindhwani, Ebru Arisoy, and Bhuvana
    Ramabhadran. Low-rank matrix factorization for deep neural network training with
    high-dimensional output targets. In ICASSP, pages 6655–6659, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (96) Ruslan Salakhutdinov and Andriy Mnih. Probabilistic matrix factorization.
    In NIPS, pages 1257–1264, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (97) Ruslan Salakhutdinov and Andriy Mnih. Bayesian probabilistic matrix factorization
    using markov chain monte carlo. In ICML, pages 880–887, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (98) Ruslan Salakhutdinov, Andriy Mnih, and Geoffrey E. Hinton. Restricted Boltzmann
    machines for collaborative filtering. In ICML, pages 791–798, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (99) Oleksandr Shchur, Marin Bilos, and Stephan Günnemann. Intensity-free learning
    of temporal point processes. 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (100) Alexander Shekhovtsov and Boris Flach. Feed-forward propagation in probabilistic
    neural networks with categorical and max layers. In ICLR, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (101) Jonathan R Shewchuk. An introduction to the conjugate gradient method
    without the agonizing pain. Technical report, Carnegie Mellon University, Pittsburgh,
    PA, USA, 1994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (102) Gunnar A. Sigurdsson, Santosh Kumar Divvala, Ali Farhadi, and Abhinav
    Gupta. Asynchronous temporal fields for action recognition. In CVPR, pages 5650–5659,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(103) Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever,
    and Ruslan Salakhutdinov. Dropout: A simple way to prevent neural networks from
    overfitting. JMLR, 15(1):1929–1958, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (104) Nitish Srivastava and Russ R Salakhutdinov. Multimodal learning with deep
    boltzmann machines. In NIPS, pages 2222–2230, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (105) Karl Stelzner, Robert Peharz, and Kristian Kersting. Faster attend-infer-repeat
    with tractable probabilistic models. In ICML, pages 5966–5975, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (106) Robert S Strichartz. A Guide to Distribution Theory and Fourier Transforms.
    World Scientific, 2003.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (107) Jiahao Su, Milan Cvitkovic, and Furong Huang. Sampling-free learning of
    bayesian quantized neural networks. 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (108) Ilya Sutskever, Oriol Vinyals, and Quoc VV Le. Sequence to sequence learning
    with neural networks. In NIPS, pages 3104–3112, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (109) Jinhui Tang, Guo-Jun Qi, Liyan Zhang, and Changsheng Xu. Cross-space affinity
    learning with its application to movie recommendation. IEEE Transactions on Knowledge
    and Data Engineering, 25(7):1510–1519, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (110) Wesley Tansey, Yixin Wang, David M. Blei, and Raul Rabadan. Black box
    FDR. In ICML, pages 4874–4883, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(111) Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, and
    Pierre-Antoine Manzagol. Stacked denoising autoencoders: Learning useful representations
    in a deep network with a local denoising criterion. JMLR, 11:3371–3408, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (112) Chong Wang and David M. Blei. Collaborative topic modeling for recommending
    scientific articles. In KDD, pages 448–456, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (113) Chong Wang, David M. Blei, and David Heckerman. Continuous time dynamic
    topic models. In UAI, pages 579–586, 2008.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(114) Hao Wang. Bayesian Deep Learning for Integrated Intelligence: Bridging
    the Gap between Perception and Inference. PhD thesis, Hong Kong University of
    Science and Technology, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (115) Hao Wang, Binyi Chen, and Wu-Jun Li. Collaborative topic regression with
    social regularization for tag recommendation. In IJCAI, pages 2719–2725, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (116) Hao Wang and Wu-Jun Li. Relational collaborative topic regression for
    recommender systems. TKDE, 27(5):1343–1355, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(117) Hao Wang, Chengzhi Mao, Hao He, Mingmin Zhao, Tommi S. Jaakkola, and
    Dina Katabi. Bidirectional inference networks: A class of deep bayesian networks
    for health profiling. In AAAI, pages 766–773, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (118) Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Relational stacked denoising
    autoencoder for tag recommendation. In AAAI, pages 3052–3058, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(119) Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Natural-parameter networks:
    A class of probabilistic neural networks. In NIPS, pages 118–126, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(120) Hao Wang, Xingjian Shi, and Dit-Yan Yeung. Relational deep learning:
    A deep latent variable model for link prediction. In AAAI, pages 2688–2694, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (121) Hao Wang, Naiyan Wang, and Dit-Yan Yeung. Collaborative deep learning
    for recommender systems. In KDD, pages 1235–1244, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(122) Hao Wang, SHI Xingjian, and Dit-Yan Yeung. Collaborative recurrent autoencoder:
    Recommend while learning to fill in the blanks. In NIPS, pages 415–423, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (123) Xinxi Wang and Ye Wang. Improving content-based and hybrid music recommendation
    using deep learning. In ACM MM, pages 627–636, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (124) Yuyang Wang, Alex Smola, Danielle C. Maddix, Jan Gasthaus, Dean Foster,
    and Tim Januschowski. Deep factors for forecasting. In ICML, pages 6607–6617,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(125) Manuel Watter, Jost Springenberg, Joschka Boedecker, and Martin Riedmiller.
    Embed to control: A locally linear latent dynamics model for control from raw
    images. In NIPS, pages 2728–2736, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (126) Yan Zheng Wei, Luc Moreau, and Nicholas R. Jennings. Learning users’ interests
    by quality classification in market-based recommender systems. TKDE, 17(12):1678–1688,
    2005.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (127) Max Welling and Yee Whye Teh. Bayesian learning via stochastic gradient
    langevin dynamics. In ICML, pages 681–688, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (128) Andrew Gordon Wilson. The case for bayesian deep learning. arXiv preprint
    arXiv:2001.10995, 2020.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (129) Zichao Yang, Zhiting Hu, Ruslan Salakhutdinov, and Taylor Berg-Kirkpatrick.
    Improved variational autoencoders for text modeling using dilated convolutions.
    In ICML, pages 3881–3890, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (130) Ghim-Eng Yap, Ah-Hwee Tan, and HweeHwa Pang. Discovering and exploiting
    causal dependencies for robust mobile context-aware recommenders. TKDE, 19(7):977–992,
    2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(131) Haochao Ying, Liang Chen, Yuwen Xiong, and Jian Wu. Collaborative deep
    ranking: a hybrid pair-wise recommendation algorithm with implicit feedback. In
    PAKDD, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (132) Fuzheng Zhang, Nicholas Jing Yuan, Defu Lian, Xing Xie, and Wei-Ying Ma.
    Collaborative knowledge base embedding for recommender systems. In Proceedings
    of the 22nd ACM SIGKDD international conference on knowledge discovery and data
    mining, pages 353–362\. ACM, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (133) He Zhao, Lan Du, Wray L. Buntine, and Mingyuan Zhou. Dirichlet belief
    networks for topic structure learning. In NIPS, pages 7966–7977, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '(134) Vincent Wenchen Zheng, Bin Cao, Yu Zheng, Xing Xie, and Qiang Yang. Collaborative
    filtering meets mobile recommendation: A user-centered approach. In AAAI, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (135) Mingyuan Zhou and Lawrence Carin. Negative binomial process count and
    mixture modeling. IEEE Trans. Pattern Anal. Mach. Intell., 37(2):307–320, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (136) Mingyuan Zhou, Lauren Hannah, David B. Dunson, and Lawrence Carin. Beta-negative
    binomial process and Poisson factor analysis. In AISTATS, pages 1462–1471, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
