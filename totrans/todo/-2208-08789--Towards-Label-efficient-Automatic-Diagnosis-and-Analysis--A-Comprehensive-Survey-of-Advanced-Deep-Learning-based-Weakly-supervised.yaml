- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:44:52'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2208.08789] Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2208.08789](https://ar5iv.labs.arxiv.org/html/2208.08789)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Linhao Qu, Siyu Liu, Xiaoyu Liu, Manning Wang¹¹1Corresponding Author., Zhijian
    Song²²footnotemark: 2 Digital Medical Research Center, School of Basic Medical
    Science, Fudan University, Shanghai Key Lab of Medical Image Computing and Computer
    Assisted Intervention, Shanghai 200032, China [{lhqu20, mnwang, zjsong}@fudan.edu.cn.](mailto:%7Blhqu20,%20mnwang,%20zjsong%7D@fudan.edu.cn.)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Histopathological images contain abundant phenotypic information and pathological
    patterns, which are the gold standards for disease diagnosis and essential for
    the prediction of patient prognosis and treatment outcome. In recent years, computer-automated
    analysis techniques for histopathological images have been urgently required in
    clinical practice, and deep learning methods represented by convolutional neural
    networks have gradually become the mainstream in the field of digital pathology.
    However, obtaining large numbers of fine-grained annotated data in this field
    is a very expensive and difficult task, which hinders the further development
    of traditional supervised algorithms based on large numbers of annotated data.
    More recent studies have started to liberate from the traditional supervised paradigm,
    and the most representative ones are the studies on weakly supervised learning
    paradigm based on weak annotation, semi-supervised learning paradigm based on
    limited annotation, and self-supervised learning paradigm based on pathological
    image representation learning. These new methods have led a new wave of automatic
    pathological image diagnosis and analysis targeted at annotation efficiency. With
    a survey of over 130 papers, we present a comprehensive and systematic review
    of the latest studies on weakly supervised learning, semi-supervised learning,
    and self-supervised learning in the field of computational pathology from both
    technical and methodological perspectives. Finally, we present the key challenges
    and future trends for these techniques.
  prefs: []
  type: TYPE_NORMAL
- en: \useunder
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords: histopathological images, automatic analysis, deep learning'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Histopathological images contain abundant phenotypic information and pathological
    patterns, which are the gold standards for disease diagnosis and essential for
    the prediction of patient prognosis and treatment outcome (Myronenko *et al.* [2021](#bib.bib116),
    Wang *et al.* [2019](#bib.bib181), Srinidhi *et al.* [2021](#bib.bib159)). For
    clinical diagnosis, experienced pathologists usually require exhaustive examination
    and interpretation of hematoxylin-eosin-stained (H&E) tissue slides under a high
    magnification microscope, including differentiation of tumor areas from large
    areas of normal tissues, elaborate grading of tumors, and detailed assessment
    of tumor progression and invasion (e.g., presence of invasive carcinoma or proliferative
    changes, etc.). This is a highly time-consuming and labor-intensive task, and
    for example, it usually takes an experienced histopathologist 15 to 30 minutes
    to examine a complete slide (Wang *et al.* [2019](#bib.bib181)). Moreover, even
    an experienced pathologist may not be able to accurately determine the deep features
    hidden in the pathological images, such as predicting lymph node metastasis and
    prognosis from the primary lesion. Therefore, computer-assisted automatic analysis
    techniques for histopathological images are in urgent need in clinical practice.
  prefs: []
  type: TYPE_NORMAL
- en: With the advent and development of digital slide scanners in the past two decades,
    tissues on biopsies can be converted into digital whole slide images (WSIs) that
    fully preserve the original tissue structure, laying the foundation for automatic
    pathological image analysis. Early studies in the field of digital pathology diagnosis
    primarily focused on extracting hand-crafted features from manually selected regions
    of interest (ROI) by pathologists (Jafari *et al.* [2003](#bib.bib78), Basavanhally
    *et al.* [2013](#bib.bib7), Mercan *et al.* [2017](#bib.bib113), Yu *et al.* [2016](#bib.bib203),
    Luo *et al.* [2017](#bib.bib106), Qaiser *et al.* [2016](#bib.bib127)) and using
    machine learning methods (Doyle *et al.* [2007](#bib.bib52), Rajpoot *et al.* [2004](#bib.bib134),
    Qureshi *et al.* [2008](#bib.bib132), Doyle *et al.* [2006](#bib.bib53)) for automatic
    analysis and diagnosis. In this regard, Gurcan *et al.* [2009](#bib.bib69) and
    Madabhushi *et al.* [2016](#bib.bib107) have presented an elaborate review.
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, thanks to the powerful and automatic feature extraction capability,
    deep learning methods represented by Convolutional Neural Network (CNN) have gradually
    become the mainstream in the field of digital pathology. However, a major challenge
    is the huge size of WSIs, typically reaching 100000$\times" display="inline"><semantics ><mo 
    xref=$100000
    pixels at the highest resolution, which prevents the direct use of the entire
    WSIs as the input to deep learning models. Therefore, when using CNNs to process
    pathological images, WSIs are usually tiled into many small patches to reduce
    the computational burden. Earlier studies usually adopted a strongly supervised
    approach based on these patches to train the network and perform the corresponding
    classification (Cruz-Roa *et al.* [2014](#bib.bib40), Cruz-Roa *et al.* [2017](#bib.bib41),
    Wei *et al.* [2019](#bib.bib185), Ehteshami *et al.* [2018](#bib.bib54), Nagpal
    *et al.* [2019](#bib.bib117), Shaban *et al.* [2019](#bib.bib145), Halicek *et
    al.* [2019](#bib.bib71)) and segmentation tasks (Chen *et al.* [2017](#bib.bib22),
    Gu *et al.* [2018](#bib.bib67), Swiderska *et al.* [2019](#bib.bib165)). In these
    works, detailed patch-level annotation is essential, e.g., supervised classification
    problems require pathologists to give detailed class labels for each patch, and
    segmentation problems require pathologists to give more detailed pixel-level annotation
    for each patch.
  prefs: []
  type: TYPE_NORMAL
- en: 'Although supervised deep learning methods have achieved unprecedented success
    in digital pathology, they share a common drawback: they all require large amounts
    of high-quality fine-grained labeled data (patch-level labeled data for classification
    problems or pixel-level labeled data for segmentation problems) for training.
    Unfortunately, in the field of digital pathology, obtaining a large amount of
    data with fine-grained annotation is a very expensive and challenging task, mainly
    because 1) only experienced pathologists can perform the annotation, and these
    pathologists are scarce; 2) histopathological images often contain complex and
    diverse instances of objects, resulting in a large amount of time-consuming and
    laborious manual annotation effort (Tajbakhsh *et al.* [2020](#bib.bib166), Yang
    *et al.* [2017](#bib.bib199), Srinidhi *et al.* [2021](#bib.bib159)). Arguably,
    the lack of a large amount of annotated data limits the application of deep learning
    techniques in computational pathology. For this reason, some new studies have
    recently attempted to liberate from the traditional strongly supervised paradigms,
    the most representative of which are the weakly supervised learning paradigm based
    on weak annotations, the semi-supervised learning paradigm based on limited annotations,
    and the self-supervised paradigm based on the representation learning of pathological
    images.'
  prefs: []
  type: TYPE_NORMAL
- en: The weakly supervised learning paradigm no longer requires pathologists to give
    annotations of all pixels or regions on the entire WSI, but only class labels
    or sparse region annotations on the entire WSI; the semi-supervised learning paradigm
    no longer requires pathologists to give fine-grained annotations of a large amount
    of data, but only a small fraction of fine-grained labeled data and a large amount
    of unlabeled data; while the self-supervised learning paradigm can create supervised
    information through a large amount of unlabeled data for self-supervised training
    to learn an accurate feature representation of the data. In the process of training
    with limited labeled data, using the features trained by self-supervised learning
    to determine the initial model weights can significantly improve the performance
    of the model. Therefore, weakly supervised learning, semi-supervised learning
    and self-supervised learning are leading a new study direction of the automatic
    diagnosis and analysis for pathological images.
  prefs: []
  type: TYPE_NORMAL
- en: However, there are very few related reviews. Srinidhi *et al.* [2021](#bib.bib159)
    reviewed representative supervised learning, weakly supervised learning, unsupervised
    learning, and transfer learning studies in the field of computational pathology
    until December 2019\. Rony *et al.* [2019](#bib.bib139) reviewed representative
    weakly supervised learning studies until 2020\. Nevertheless, in recent years,
    deep learning techniques have been developing rapidly and the new techniques continue
    to emerge. Therefore, a review regarding the applications of these techniques
    in the automatic diagnosis of pathological images has important theoretical value
    and clinical significance.
  prefs: []
  type: TYPE_NORMAL
- en: In this review, we summarize more than 130 recent technical studies systematically
    on weakly supervised learning, semi-supervised learning, and self-supervised learning
    in the field of computational pathology. We performed this extensive review by
    searching Google Scholar, PubMed, and arXiv for papers including keywords such
    as (”deep learning” or ”weakly supervised learning” or ”semi-supervised learning”
    or ”self-supervised learning ”) and (”digital pathology” or ”histopathology” or
    ”computational pathology”). Notably, on the one hand, we focus on papers presenting
    novel techniques and theories with high impact (h-index, citations and impact
    factors of journals), thus we concentrate more on studies published in top conferences
    (including CVPR, NeurIPS, MICCAI, ISBI, MIDL, IPMI, AAAI, ICCV, ECCV, etc.) and
    top journals (including TPAMI, TMI, MIA, etc.) on weakly supervised, semi-supervised,
    and self-supervised learning in the field of computational pathology. On the other
    hand, since technical research in this area is growing rapidly and more new techniques
    have been proposed, we mainly cover papers published in 2019-2021\. On the other
    hand, we also present a meticulous summary of the disease types, tasks, datasets,
    and performance covered by these papers. In total, this review contains more than
    200 relevant references.
  prefs: []
  type: TYPE_NORMAL
- en: 'The rest of the paper is organized as follows: Section [2](#S2 "2 Overview
    of Learning Paradigms and Problem Formulation ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") expounds a general overview of the weakly supervised, semi-supervised,
    and self-supervised learning paradigms in the context of computational pathology;
    Section [3](#S3 "3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and
    Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")
    includes a detailed review of the weakly supervised (Section [3.1](#S3.SS1 "3.1
    Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), semi-supervised (Section [3.2](#S3.SS2 "3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")),
    and self-supervised (Section [3.3](#S3.SS3 "3.3 Self-Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis")) learning paradigms;
    We discuss the three learning paradigms and their future trends in Section [4](#S4
    "4 Discussion and Future Trends ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis"),
    and conclude the whole paper in Section [5](#S5 "5 Conclusion ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"). The list of all the acronyms used in this review is shown in
    Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: List of all the acronyms in this review.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Full Name | Acronyms | Full Name | Acronyms |'
  prefs: []
  type: TYPE_TB
- en: '| Area Under ROC Curve | AUC | Graph Neural Network | GNN |'
  prefs: []
  type: TYPE_TB
- en: '| Auxiliary Classier Generative Adversarial Networks | AC-GAN | Hematoxylin-Eosin-Stained
    | H&E |'
  prefs: []
  type: TYPE_TB
- en: '| Average Hausdorff Distance | AHD | Magnication Prior Contrastive Similarity
    | MPCS |'
  prefs: []
  type: TYPE_TB
- en: '| Average Jaccard Index | AJI | Mean Average Precision | MAP |'
  prefs: []
  type: TYPE_TB
- en: '| Calinski-Harabaz Index | CHI | Mean Teachers | MT |'
  prefs: []
  type: TYPE_TB
- en: '| Contrastive Predictive Coding | CPC | Microsatellite Instability | MSI |'
  prefs: []
  type: TYPE_TB
- en: '| Convolutional Autoencoder | CAE | Multiple Instance Fully Convolutional Network
    | MI-FCN |'
  prefs: []
  type: TYPE_TB
- en: '| Convolutional Neural Network | CNN | Multiple Instance Learning | MIL |'
  prefs: []
  type: TYPE_TB
- en: '| Deep Learning Hashing | DLH | Noise Contrastive Estimation | NCE |'
  prefs: []
  type: TYPE_TB
- en: '| Deformation Representation Learning | DRL | Percentage Of Tumor Cellularity
    | TC |'
  prefs: []
  type: TYPE_TB
- en: '| Diffusion-Convolutional Neural Networks | DCNNs | Recurrent Neural Network
    | RNN |'
  prefs: []
  type: TYPE_TB
- en: '| Dual-Stream Multiple Instance Learning | DSMIL | Regions Of Interest | ROI
    |'
  prefs: []
  type: TYPE_TB
- en: '| Expectation-Maximization | EM | Resolution Sequence Prediction | RSP |'
  prefs: []
  type: TYPE_TB
- en: '| Exponential Moving Average | EMA | Silhouette Index | SI |'
  prefs: []
  type: TYPE_TB
- en: '| Focal-Aware Module | FAM | Support Vector Machines | SVM |'
  prefs: []
  type: TYPE_TB
- en: '| Frechet Inception Distance | FID | Temporal Ensembling | TE |'
  prefs: []
  type: TYPE_TB
- en: '| Generative Adversarial Networks | GAN | The Cancer Genome Atlas Program |
    TCGA |'
  prefs: []
  type: TYPE_TB
- en: '| Graph Convolutional Neural Network | GCN | Whole Slide Images | WSI |'
  prefs: []
  type: TYPE_TB
- en: 2 Overview of Learning Paradigms and Problem Formulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we provide a general overview and problem formulation of the
    three learning paradigms reviewed in this paper, and compare them with the traditional
    strongly supervised paradigm. To make the description more specific and vivid,
    we present an example of accurately classifying normal and cancerous tissues in
    a WSI, as shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis"). The raw
    data for this example WSI comes from a study on predicting lymph node metastasis
    in breast cancer using deep learning (Bejnordi *et al.* [2017a](#bib.bib9)). We
    also intuitively compare and summarize these paradigms in Table [2](#S2.T2 "Table
    2 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis").'
  prefs: []
  type: TYPE_NORMAL
- en: 'For the dataset <math  class="ltx_Math" alttext="W={\{W_{i}\}}_{i=1}^{N}"
    display="inline"><semantics ><mrow  ><mi
     >W</mi><mo 
    >=</mo><msubsup  ><mrow
     ><mo stretchy="false"
     >{</mo><msub 
    ><mi  >W</mi><mi
     >i</mi></msub><mo
    stretchy="false"  >}</mo></mrow><mrow
     ><mi 
    >i</mi><mo  >=</mo><mn
     >1</mn></mrow><mi
     >N</mi></msubsup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci
     >𝑊</ci><apply 
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><set 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci
     >𝑖</ci></apply></set><apply
     ><ci 
    >𝑖</ci><cn type="integer" 
    >1</cn></apply></apply><ci 
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math> consisting
    of <math  class="ltx_Math" alttext="N" display="inline"><semantics
    ><mi  >N</mi><annotation-xml
    encoding="MathML-Content" ><ci  >𝑁</ci></annotation-xml><annotation
    encoding="application/x-tex" >N</annotation></semantics></math>
    WSIs, each WSI <math  class="ltx_Math" alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> is now cut into patches
    <math  class="ltx_Math" alttext="\{p_{i,j},j=1,2,\ldots n_{i}\}"
    display="inline"><semantics ><mrow  ><mo
    stretchy="false"  >{</mo><mrow
     ><mrow 
    ><mrow  ><msub
     ><mi
     >p</mi><mrow
     ><mi 
    >i</mi><mo  >,</mo><mi
     >j</mi></mrow></msub><mo
     >,</mo><mi
     >j</mi></mrow><mo 
    >=</mo><mn  >1</mn></mrow><mo
     >,</mo><mrow 
    ><mn  >2</mn><mo
     >,</mo><mrow
     ><mi mathvariant="normal"
     >…</mi><mo
    lspace="0em" rspace="0em"  >​</mo><msub
     ><mi
     >n</mi><mi
     >i</mi></msub></mrow></mrow></mrow><mo
    stretchy="false"  >}</mo></mrow><annotation-xml
    encoding="MathML-Content" ><set  ><apply
     ><csymbol cd="ambiguous"
     >formulae-sequence</csymbol><apply
     ><list 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑝</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply><ci
     >𝑗</ci></list><cn type="integer"
     >1</cn></apply><list
     ><cn type="integer"
     >2</cn><apply 
    ><ci  >…</ci><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑛</ci><ci
     >𝑖</ci></apply></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots n_{i}\}</annotation></semantics></math>,
    and <math  class="ltx_Math" alttext="n_{i}" display="inline"><semantics
    ><msub  ><mi 
    >n</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑛</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >n_{i}</annotation></semantics></math> is the number of patches
    cut out of <math  class="ltx_Math" alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math>. In the supervised learning
    paradigm, a large number of patches with fine-grained labels are available for
    training, so each patch is given a label <math  class="ltx_Math"
    alttext="y_{i,j}\in\mathbb{R}^{C}" display="inline"><semantics ><mrow
     ><msub  ><mi
     >y</mi><mrow 
    ><mi  >i</mi><mo
     >,</mo><mi 
    >j</mi></mrow></msub><mo  >∈</mo><msup
     ><mi 
    >ℝ</mi><mi  >C</mi></msup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci  >𝑦</ci><list
     ><ci 
    >𝑖</ci><ci  >𝑗</ci></list></apply><apply
     ><csymbol cd="ambiguous" 
    >superscript</csymbol><ci 
    >ℝ</ci><ci  >𝐶</ci></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}\in\mathbb{R}^{C}</annotation></semantics></math>,
    and <math  class="ltx_Math" alttext="C" display="inline"><semantics
    ><mi  >C</mi><annotation-xml
    encoding="MathML-Content" ><ci  >𝐶</ci></annotation-xml><annotation
    encoding="application/x-tex" >C</annotation></semantics></math>
    denotes the possible class. For example, in the binary classification task, <math
     class="ltx_Math" alttext="C=2" display="inline"><semantics ><mrow
     ><mi  >C</mi><mo
     >=</mo><mn 
    >2</mn></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><ci 
    >𝐶</ci><cn type="integer"  >2</cn></apply></annotation-xml><annotation
    encoding="application/x-tex" >C=2</annotation></semantics></math>
    and the label takes the scalar form {0, 1} while in the regression task, <math
     class="ltx_Math" alttext="C" display="inline"><semantics ><mi
     >C</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝐶</ci></annotation-xml><annotation
    encoding="application/x-tex" >C</annotation></semantics></math>
    takes the form of a continuous set of real numbers $\mathbb{R}" display="inline"><semantics ><mi 
    >ℝ</mi><annotation-xml encoding="MathML-Content" ><ci
     >ℝ</ci></annotation-xml><annotation
    encoding=$.
    The goal of the supervised learning paradigm is to train a model <math 
    class="ltx_Math" alttext="f_{\theta}:x\rightarrow y" display="inline"><semantics
    ><mrow  ><msub
     ><mi 
    >f</mi><mi  >θ</mi></msub><mo
    lspace="0.278em" rspace="0.278em"  >:</mo><mrow
     ><mi 
    >x</mi><mo stretchy="false" 
    >→</mo><mi  >y</mi></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply 
    ><ci  >:</ci><apply
     ><csymbol cd="ambiguous"
     >subscript</csymbol><ci
     >𝑓</ci><ci 
    >𝜃</ci></apply><apply 
    ><ci  >→</ci><ci
     >𝑥</ci><ci 
    >𝑦</ci></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >f_{\theta}:x\rightarrow y</annotation></semantics></math>
    to optimally predict the labels <math  class="ltx_Math" alttext="y_{i,j}"
    display="inline"><semantics ><msub  ><mi
     >y</mi><mrow 
    ><mi  >i</mi><mo
     >,</mo><mi 
    >j</mi></mrow></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math>
    of the unknown patches <math  class="ltx_Math" alttext="p_{i,j}"
    display="inline"><semantics ><msub  ><mi
     >p</mi><mrow 
    ><mi  >i</mi><mo
     >,</mo><mi 
    >j</mi></mrow></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑝</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >p_{i,j}</annotation></semantics></math>
    in the test WSI based on the loss function $\mathcal{L}" display="inline"><semantics ><mi class="ltx_font_mathcaligraphic"
     >ℒ</mi><annotation-xml encoding="MathML-Content"
    ><ci  >ℒ</ci></annotation-xml><annotation
    encoding=$.
    Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms and Problem Formulation
    ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis") (a) illustrates the main process
    of this paradigm. During training, the model is trained in a supervised manner
    using patches cut out of the training WSIs and their labels (green for negative
    and red for positive) by pathologists; during testing, the trained model is used
    to predict the labels of the patches cut out of the unseen test WSIs.'
  prefs: []
  type: TYPE_NORMAL
- en: In the weakly supervised learning paradigm, the label <math 
    class="ltx_Math" alttext="y_{i,j}" display="inline"><semantics ><msub
     ><mi  >y</mi><mrow
     ><mi 
    >i</mi><mo  >,</mo><mi
     >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math>
    of each patch is typically unknown, while only the label of each WSI is available,
    and thus the traditional strongly supervised learning paradigm cannot work. In
    this review, we focus on the most dominant weakly supervised paradigm currently
    used in computational pathology, the deep multiple instance learning (MIL) approach.
    In MIL, each WSI is considered as a bag containing many patches (also called instances).
    if a WSI (bag) is labeled as disease-positive, then at least one patch (instance)
    in that WSI is disease-positive; if a WSI is disease-negative, then all patches
    in that WSI are negative. The relationship between a WSI (bag) and its patches
    (instances) can be expressed mathematically as follows.
  prefs: []
  type: TYPE_NORMAL
- en: 'Given a dataset <math  class="ltx_Math" alttext="W={\{W_{i}\}}_{i=1}^{N}"
    display="inline"><semantics ><mrow  ><mi
     >W</mi><mo 
    >=</mo><msubsup  ><mrow
     ><mo stretchy="false"
     >{</mo><msub 
    ><mi  >W</mi><mi
     >i</mi></msub><mo
    stretchy="false"  >}</mo></mrow><mrow
     ><mi 
    >i</mi><mo  >=</mo><mn
     >1</mn></mrow><mi
     >N</mi></msubsup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci
     >𝑊</ci><apply 
    ><csymbol cd="ambiguous"  >superscript</csymbol><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><set 
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci
     >𝑖</ci></apply></set><apply
     ><ci 
    >𝑖</ci><cn type="integer" 
    >1</cn></apply></apply><ci 
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math> consisting
    of <math  class="ltx_Math" alttext="N" display="inline"><semantics
    ><mi  >N</mi><annotation-xml
    encoding="MathML-Content" ><ci  >𝑁</ci></annotation-xml><annotation
    encoding="application/x-tex" >N</annotation></semantics></math>
    WSIs, each image <math  class="ltx_Math" alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> has a corresponding label
    <math  class="ltx_Math" alttext="Y_{i}\in\left\{0,1\right\},\
    i=\{1,2,...N\}" display="inline"><semantics ><mrow 
    ><mrow  ><msub
     ><mi 
    >Y</mi><mi  >i</mi></msub><mo
     >∈</mo><mrow 
    ><mo  >{</mo><mn
     >0</mn><mo 
    >,</mo><mn  >1</mn><mo
     >}</mo></mrow></mrow><mo
    rspace="0.667em"  >,</mo><mrow
     ><mi 
    >i</mi><mo  >=</mo><mrow
     ><mo stretchy="false"
     >{</mo><mn 
    >1</mn><mo  >,</mo><mn
     >2</mn><mo 
    >,</mo><mrow  ><mi
    mathvariant="normal"  >…</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi
     >N</mi></mrow><mo
    stretchy="false"  >}</mo></mrow></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply 
    ><csymbol cd="ambiguous"  >formulae-sequence</csymbol><apply
     ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑌</ci><ci  >𝑖</ci></apply><set
     ><cn type="integer"
     >0</cn><cn type="integer" 
    >1</cn></set></apply><apply 
    ><ci  >𝑖</ci><set
     ><cn type="integer"
     >1</cn><cn type="integer" 
    >2</cn><apply  ><ci
     >…</ci><ci
     >𝑁</ci></apply></set></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}\in\left\{0,1\right\},\ i=\{1,2,...N\}</annotation></semantics></math>.
    Now each WSI <math  class="ltx_Math" alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> is cut into small patches
    <math  class="ltx_Math" alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}"
    display="inline"><semantics ><mrow  ><mo
    stretchy="false"  >{</mo><mrow
     ><mrow 
    ><mrow  ><msub
     ><mi
     >p</mi><mrow
     ><mi 
    >i</mi><mo  >,</mo><mi
     >j</mi></mrow></msub><mo
     >,</mo><mi
     >j</mi></mrow><mo 
    >=</mo><mn  >1</mn></mrow><mo
     >,</mo><mrow 
    ><mn  >2</mn><mo
     >,</mo><mi
    mathvariant="normal"  >…</mi><mo
     >,</mo><msub
     ><mi 
    >n</mi><mi 
    >i</mi></msub></mrow></mrow><mo stretchy="false"
     >}</mo></mrow><annotation-xml
    encoding="MathML-Content" ><set  ><apply
     ><csymbol cd="ambiguous"
     >formulae-sequence</csymbol><apply
     ><list 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑝</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply><ci
     >𝑗</ci></list><cn type="integer"
     >1</cn></apply><list
     ><cn type="integer"
     >2</cn><ci 
    >…</ci><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑛</ci><ci
     >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>
    without overlapping each other, and <math  class="ltx_Math" alttext="n_{i}"
    display="inline"><semantics ><msub  ><mi
     >n</mi><mi 
    >i</mi></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑛</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >n_{i}</annotation></semantics></math> is the number of patches.
    All patches <math  class="ltx_Math" alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}"
    display="inline"><semantics ><mrow  ><mo
    stretchy="false"  >{</mo><mrow
     ><mrow 
    ><mrow  ><msub
     ><mi
     >p</mi><mrow
     ><mi 
    >i</mi><mo  >,</mo><mi
     >j</mi></mrow></msub><mo
     >,</mo><mi
     >j</mi></mrow><mo 
    >=</mo><mn  >1</mn></mrow><mo
     >,</mo><mrow 
    ><mn  >2</mn><mo
     >,</mo><mi
    mathvariant="normal"  >…</mi><mo
     >,</mo><msub
     ><mi 
    >n</mi><mi 
    >i</mi></msub></mrow></mrow><mo stretchy="false"
     >}</mo></mrow><annotation-xml
    encoding="MathML-Content" ><set  ><apply
     ><csymbol cd="ambiguous"
     >formulae-sequence</csymbol><apply
     ><list 
    ><apply 
    ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci 
    >𝑝</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply><ci
     >𝑗</ci></list><cn type="integer"
     >1</cn></apply><list
     ><cn type="integer"
     >2</cn><ci 
    >…</ci><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑛</ci><ci
     >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>
    in <math  class="ltx_Math" alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> form a bag, the bag-level
    label is the label <math  class="ltx_Math" alttext="Y_{i}"
    display="inline"><semantics ><msub  ><mi
     >Y</mi><mi 
    >i</mi></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑌</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >Y_{i}</annotation></semantics></math> of <math 
    class="ltx_Math" alttext="W_{i}" display="inline"><semantics ><msub
     ><mi 
    >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply 
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci
     >𝑊</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math>, and each small patch
    is called an instance of this bag, while the instance-level label <math 
    class="ltx_Math" alttext="y_{i,j}" display="inline"><semantics ><msub
     ><mi 
    >y</mi><mrow  ><mi
     >i</mi><mo 
    >,</mo><mi  >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply 
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math>
    and its corresponding bag-level label <math  class="ltx_Math"
    alttext="Y_{i}" display="inline"><semantics ><msub 
    ><mi  >Y</mi><mi
     >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply 
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci
     >𝑌</ci><ci 
    >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >Y_{i}</annotation></semantics></math> have the following
    relationship:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | <math  class="ltx_Math" alttext="Y_{i}=\left\{\begin{array}[]{cc}&amp;0,\text{
    if }\sum_{j}y_{i,j}=0\\ &amp;1,\text{ else }\end{array}\right." display="block"><semantics
    ><mrow  ><msub 
    ><mi  >Y</mi><mi
     >i</mi></msub><mo 
    >=</mo><mrow  ><mo
     >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr
     ><mtd  ><mrow
     ><mrow 
    ><mn  >0</mn><mo
     >,</mo><mrow 
    ><mtext  > if </mtext><mo
    lspace="0em" rspace="0em"  >​</mo><mrow
     ><mstyle
    displaystyle="false"  ><msub
     ><mo
     >∑</mo><mi
     >j</mi></msub></mstyle><msub
     ><mi
     >y</mi><mrow
     ><mi 
    >i</mi><mo 
    >,</mo><mi  >j</mi></mrow></msub></mrow></mrow></mrow><mo
     >=</mo><mn 
    >0</mn></mrow></mtd></mtr><mtr 
    ><mtd  ><mrow
     ><mn 
    >1</mn><mo  >,</mo><mtext
     > else </mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply
     ><csymbol cd="ambiguous" 
    >subscript</csymbol><ci  >𝑌</ci><ci
     >𝑖</ci></apply><apply 
    ><csymbol cd="latexml"  >cases</csymbol><matrix
     ><matrixrow 
    ><cerror  ><csymbol
    cd="ambiguous"  >missing-subexpression</csymbol></cerror><apply
     ><list 
    ><cn type="integer" 
    >0</cn><apply  ><ci
     ><mtext
     > if </mtext></ci><apply
     ><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑗</ci></apply><apply
     ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><list
     ><ci 
    >𝑖</ci><ci  >𝑗</ci></list></apply></apply></apply></list><cn
    type="integer"  >0</cn></apply></matrixrow><matrixrow
     ><cerror  ><csymbol
    cd="ambiguous"  >missing-subexpression</csymbol></cerror><list
     ><cn type="integer"
     >1</cn><ci 
    ><mtext  > else </mtext></ci></list></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}=\left\{\begin{array}[]{cc}&0,\text{
    if }\sum_{j}y_{i,j}=0\\ &1,\text{ else }\end{array}\right.</annotation></semantics></math>
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: It means that the labels of all instances in the negative bag are negative,
    while at least one positive instance exists in the positive bag and the labels
    of instances <math  class="ltx_Math" alttext="y_{i,j}" display="inline"><semantics
    ><msub  ><mi 
    >y</mi><mrow  ><mi
     >i</mi><mo 
    >,</mo><mi  >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci
     >𝑦</ci><list 
    ><ci  >𝑖</ci><ci
     >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math>
    are unknown.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7568353672e6498d941fd536fe5ff599.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: General overview of the learning paradigms reviewed in this paper,
    depicted as an example of classifying normal tissue (green) and cancerous tissue
    (red) in a WSI. Note that the training data and testing data in this figure are
    used for description only and are not necessarily the real case. (a) Supervised
    learning paradigm. (b) Weakly Supervised learning paradigm. (c) Semi-supervised
    learning paradigm. (d) Self-supervised learning paradigm.'
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis") (b), generally,
    there are two main goals of deep learning-based WSI analysis, one is global slide
    classification, i.e., to accurately classify each WSI, and the other is positive
    patch localization, i.e., to accurately classify each instance in positive bags.
    A review of the current state-of-the-art weakly supervised learning methods is
    presented in Section [3.1](#S3.SS1 "3.1 Weakly Supervised Learning Paradigm ‣
    3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis").'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the semi-supervised learning paradigm, we only have a very small number
    of patches with labels, in addition to a large number of unlabeled patches that
    can also be used for training. Therefore, the main goal of the semi-supervised
    learning paradigm is how to use the unlabeled data to improve the performance
    of the models trained with limited labeled data. As shown in Figure [1](#S2.F1
    "Figure 1 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards
    Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced
    Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised Techniques
    in Histopathological Image Analysis") (c), in contrast to the supervised learning
    paradigm, the semi-supervised learning paradigm makes use of a large amount of
    unlabeled data while training with the labeled data. During testing, the trained
    model is used to predict the labels of the patches in test WSIs. See Section [3.2](#S3.SS2
    "3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") for a detailed review of the semi-supervised learning methods.'
  prefs: []
  type: TYPE_NORMAL
- en: Self-supervised learning is a hybrid learning approach, which combines unsupervised
    and supervised learning paradigms in a pre-training and fine-tuning manner. The
    aim is to get better results of supervised training though generating supervised
    information from a large amount of unlabeled data, which can learn better feature
    representations, and can reduce manual annotation in the subsequent tasks. Due
    to the small amount of annotated data, it is not sufficient to use these data
    directly to train the model. Therefore, the self-supervised learning paradigm
    first learns a primary feature representation from a large amount of unlabeled
    data, which is called the pre-training process. The feature representations learned
    in the self-supervised auxiliary tasks are then transferred for further training
    in downstream tasks using limited labeled data, which is called the fine-tuning
    process. In this way, the primary feature representations can effectively help
    the network to achieve an effective training result with less labeled data.
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis") (d), the
    pre-training process of the self-supervised learning paradigm is typically performed
    through self-supervised auxiliary tasks. In the self-supervised auxiliary tasks,
    certain inherent properties of the unlabeled data are first utilized to generate
    supervised information, and then the network is trained by the self-supervised
    information, such as self-reconstruction, random rotation followed by angle prediction,
    color information discarding followed by colorization, and patch position disruption
    followed by restoration. Once accomplishing these self-supervised auxiliary tasks,
    the effective feature representations can be extracted. The fine-tuning process
    of self-supervised learning is done in the downstream tasks. During the fine-tuning
    process, a small amount of labeled data is used to perform the supervised training,
    and the model is not trained from scratch, but is further trained using the feature
    representations learned in the auxiliary tasks as the initial weights of the network.
    Finally, the trained network is used for testing. A review of the state-of-the-art
    self-supervised learning methods is presented in Section [3.3](#S3.SS3 "3.3 Self-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 2: Intuitive summary and comparison of the four paradigms.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Methods | Input | Suitable tasks | Technical paradigms | Strengths | Weaknesses
    |'
  prefs: []
  type: TYPE_TB
- en: '| Supervised learning paradigm | A large number of small patches (tiled from
    WSIs) with fine-grained labels | WSI-level and patch-level classification/segmentation/regression
    | - | Broad application, effective and simple training | Require large amount
    of fine-grained labeled data |'
  prefs: []
  type: TYPE_TB
- en: '| Weakly Supervised learning paradigm | Entire WSIs with overall labels or
    sparse labels | WSI-level classification/segmentation/regression, Patch-level
    coarse-grained localization | Instance-based approach, Bag-based approach, Hybrid
    approach | No need for fine-grained annotation, effectively reduce the burden
    of data annotation | Achieve limited performance for fine-grained tasks |'
  prefs: []
  type: TYPE_TB
- en: '| Semi-supervised learning paradigm | A limited number of small patches (tiled
    from WSIs) with fine-grained labels | WSI-level and patch-level classification/segmentation/regression
    | Pseudo-labelling-based approach, Consistency-based approach, Graph-based approach,
    Unsupervised-preprocessing-based approach, GAN-based approach and others | Require
    only a small amount of fine-grained annotation, effectively reduce the burden
    of data annotation | Need to satisfy various semi-supervised assumptions |'
  prefs: []
  type: TYPE_TB
- en: '| Self-supervised learning paradigm | A large number of small patches (tiled
    from WSIs) without labels | Patch-level feature representations, Multiple related
    down-stream tasks | Predictive approach, Generative approach, Contrastive approach,
    Hybrid approach | Efficiently extract image features from a large amount of unsupervised
    data, effectively reduce the data annotation burden | May result in information
    loss when the extracted features are not applicable to downstream tasks |'
  prefs: []
  type: TYPE_TB
- en: 3 Paradigms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 3.1 Weakly Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this section, we provide a comprehensive review of the primary deep multiple
    instance learning (MIL) methods currently used in the weakly supervised learning
    paradigm for computational pathology. In MIL, each WSI is considered as a bag
    containing many patches (also called instances). If a WSI (bag) is labeled disease-positive,
    then at least one patch (instance) in that WSI is disease-positive; if a WSI is
    disease-negative, then all patches in that WSI are negative.
  prefs: []
  type: TYPE_NORMAL
- en: 'We categorize the current deep MIL methods for WSI analysis into instance-based
    methods, bag-based methods, and hybrid methods. Our categorization is mainly based
    on whether the methods contain an instance classifier or a bag classifier, i.e.,
    instance-based methods contain only an instance classifier; bag-based methods
    contain only a bag classifier; while hybrid methods contain both an instance classifier
    and a bag classifier. In this way, the categories clearly cover almost current
    deep MIL methods for WSI analysis. A diagram of the three methods above is shown
    in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis").
    The detailed literatures in this section are summarized in Table [3](#S3.T3 "Table
    3 ‣ 3.1.4 Representative Clinical Studies ‣ 3.1 Weakly Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis").'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 Instance-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The main idea of the instance-based approach is to train a good instance classifier
    to accurately predict the potential labels of instances in each bag, and then
    use MIL-pooling to aggregate the predictions of all instances in each bag to obtain
    the prediction of the bag. The details are shown in Figure [2](#S3.F2 "Figure
    2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣
    3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis") (a). Since the
    true labels of each instance are unknown, these approaches usually first assign
    the labels of each instance with their corresponding bags as the pseudo labels
    (i.e., all instances in a positive bag are given positive labels, and all instances
    in a negative bag are given negative labels), and then train the instance classifier
    using a supervised way until it converges. The loss function is usually the cross-entropy
    function defined between the predictions of the instance classifier and the pseudo
    labels. After training, the instance classifier is used to make predictions for
    all instances in the test bag, and then the predictions of each instance are aggregated
    to obtain the prediction of the bag, and this aggregation process is called MIL-pooling.
    Commonly used MIL pooling methods include Mean-pooling (Wang *et al.* [2018](#bib.bib182)),
    Max-pooling (Feng *et al.* [2017](#bib.bib56), Wang *et al.* [2018](#bib.bib182),
    Wu *et al.* [2015](#bib.bib189)), Voting (Cruz-Roa *et al.* [2014](#bib.bib40)),
    log-sum-exp-pooling (Ramon *et al.* [2000](#bib.bib135)), Noisy-or-pooling (Maron
    *et al.* [1997](#bib.bib110)), Noisy-and-pooling (Kraus *et al.* [2016](#bib.bib90)),
    and Dynamic pooling (Yan *et al.* [2018](#bib.bib197)) among others.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b98364eaa5ad47a7afa0b4eecc6a86ba.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Overview of multiple instance learning methods. (a) Instance-based
    Approach. (b) Bag-based Approach. (c) Two-stage Hybrid Approach. (c) End-to-End
    Hybrid Approach.'
  prefs: []
  type: TYPE_NORMAL
- en: Instance-based approach is more common in early studies, and its main advantage
    lies in the direct prediction of each instance so that the localization task can
    be performed conveniently. However, it has two major drawbacks. First, since the
    true labels of each instance in the positive bags are not necessarily all positive,
    the pseudo labels assigned to the instances in the positive bags are noisy, which
    will lead to inaccurate training of the instance classifier; Second, the MIL-pooling
    method, which aggregates the predictions of instances in each bag, is manually
    designed and non-trainable, making it less flexible and robust. Therefore, the
    performance of these methods is usually limited.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 Bag-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The main idea of the bag-based approaches is to first extract the features
    of each instance in a bag using shared instance-level feature extractors, then
    use MIL-pooling to aggregate the instance-level features to obtain the bag-level
    features, and then train the bag classifier in a supervised manner until it converges.
    The specific diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based
    Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (b). The loss function is usually defined as the cross-entropy
    loss between the predictions of the bag classifier and the true bag labels.'
  prefs: []
  type: TYPE_NORMAL
- en: MIL-pooling also exists in bag-based methods, but unlike instance-based methods,
    MIL-pooling here aggregates not the predictions of instances, but the features
    of instances. Mean-pooling, Max-pooling and other aggregation methods can also
    be used as aggregation methods for instance features, but their drawbacks remain,
    i.e., they cannot be trained and adjusted adaptively, so they are often not flexible
    enough.
  prefs: []
  type: TYPE_NORMAL
- en: The key of the bag-based methods is the training of the bag classifier. Since
    the true labels of the bags are available, there is no noise in their training
    process, so these methods tend to be more accurate than instance-based methods
    in bag classification. However, a serious problem of the bag-based approaches
    is that they cannot perform the localization task easily. Furthermore, the aggregation
    functions for instance features are not flexible enough to show the contribution
    of different instances to bag classification.
  prefs: []
  type: TYPE_NORMAL
- en: Attention-based Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Ilse *et al.* [2018](#bib.bib77) have alleviated these dilemmas. They first
    proposed to use the trainable attention mechanism to aggregate instance features,
    and started a wave of study on attention-based aggregation methods by subsequent
    bag-based methods. They trained both the instance-level feature extractor and
    a bag-level classifier using an end-to-end manner, and used the attention mechanism
    to aggregate the features and measure the significance of each instance. Tu *et
    al.* [2019](#bib.bib173) proposed a new end-to-end graph neural network (GNN)
    for instance aggregation. This work is the first GNN-based MIL work. Hashimoto
    *et al.* [2020](#bib.bib72) proposed a novel end-to-end method for cancer subtype
    classification by combining MIL, domain adversarial and multiscale learning frameworks.
    Yao, Zhu *et al.* [2017](#bib.bib212), [2020](#bib.bib202) proposed a deep attention
    guided MIL framework for cancer survival analysis. They first used a pre-trained
    model from ImageNet (Deng *et al.* [2009](#bib.bib47)) to extract the features
    of instances in each bag, and then used K-means algorithm to cluster the instances
    in each bag to obtain the phenotypic patterns, and finally applied attention mechanism
    to aggregate the features of these patterns and performed prediction.
  prefs: []
  type: TYPE_NORMAL
- en: Self-supervised Pre-training-based Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Due to the extremely large size of WSIs and the large number of instances cut
    out, direct end-to-end training of all instances is easily limited by computational
    resources. Therefore, some studies first use advanced self-supervised pre-training
    methods to characterize each instance and then perform subsequent training. Lu
    *et al.* [2019](#bib.bib104) first proposed to obtain instance-level feature representations
    by self-supervised contrastive predictive coding (CPC), and then used the attention-based
    MIL method for instance aggregation to perform bag-level classification. This
    is the first MIL study using self-supervised contrastive learning. Zhao *et al.* [2020](#bib.bib206)
    used a pre-trained VAE-GAN (Larsen *et al.* [2016](#bib.bib93)) to extract instance-level
    features, and then used GNN to aggregate instance features and perform bag-level
    classification. Li *et al.* [2021](#bib.bib97) proposed DSMIL, where they used
    contrastive pre-training (Chen *et al.* [2020](#bib.bib26)) to obtain the instance
    features, and then proposed the masked non-local operation-based dual-stream aggregator
    to perform both instance-level classification and bag-level classification.
  prefs: []
  type: TYPE_NORMAL
- en: Transformer Based Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In MIL-based WSI analysis, not only the contribution of different instances
    to bag classification should be considered, the relationships among different
    instances should also be fully explored, because different instances in a WSI
    are not isolated from each other, but have strong correlation. To address this
    issue, Shao *et al.* [2021](#bib.bib146) and Li *et al.* [2021](#bib.bib99) et
    al. used Transformer-based architectures to aggregate instances and both achieved
    promising results. The former designed a Transformer-based correlated MIL framework
    to explore the morphological and spatial information among different instances
    and provided related proofs. The latter presented a MIL framework based on the
    deformable transformer and convolutional layers.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.3 Hybrid Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The hybrid approach combines the advantages of the above two approaches. It
    trains both the instance-level classifier and the bag-level classifier, and uses
    the former to predict the instance-level results while the latter for bag-level
    results. Overall, there are two types of the hybrid approaches. One is the two-stage
    approach and the other is the end-to-end approach.
  prefs: []
  type: TYPE_NORMAL
- en: Two-stage Hybrid Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The two-stage hybrid approach generally trains the instance classifier by assigning
    each instance in each bag with their corresponding bag labels as pseudo labels,
    and then trains the bag classifier to complete the bag classification based on
    the predictions of the instance classifier. Some studies have also attempted to
    select the key instances in each bag based on the predictions of the instance
    classifier, and then train the bag classifier based on these key instances. The
    specific diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based
    Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (c). Hou *et al.* [2016](#bib.bib76) proposed a new Expectation-Maximization
    (EM) based model. They selected discriminative instances based on spatial relationship
    to train the instance classifier and fed the histogram of instance predictions
    into the multiclass logistic regression model and the SVM model (Chang *et al.* [2011](#bib.bib20))
    for bag prediction. Campanella *et al.* [2019](#bib.bib17) first selected key
    instances with the maximum prediction probability of the instance classifier in
    the current iteration and assigned pseudo labels of the corresponding bag labels
    to them. Then they fed the features of these key instances into the recurrent
    neural network (RNN) to perform the aggregation and prediction of the bags. Wang
    *et al.* [2019](#bib.bib181) selected key instances based on the predictions of
    positive instance probability and fed their features into the global feature descriptor
    and used the random forest algorithm to classify the bags. Chen *et al.* [2021](#bib.bib30)
    proposed a focal-aware module (FAM) and used thumbnails of WSI to automatically
    estimate the key regions associated with the diagnosis. Then, the instance features
    at different scales were extracted based on these key regions and aggregated using
    GNN to perform the bag classification.'
  prefs: []
  type: TYPE_NORMAL
- en: End-to-end Hybrid Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The end-to-end hybrid approach generally trains the instance-level classifier
    and the bag-level classifier at the same time. A common approach is to train the
    two classifiers simultaneously by assigning each instance the corresponding bag
    labels as pseudo labels on top of the bag classifier. Some studies also train
    the instance classifier to select the key instances in an epoch first, and then
    train the bag classifier after aggregating the instance features. The specific
    diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based Approach
    ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (d). Shi *et al.* [2020](#bib.bib151) proposed loss-based attention
    MIL. They added an instance-level loss function weighted by the instance attention
    scores based on AB-MIL (Ilse *et al.* [2018](#bib.bib77)) as a regularization
    term to improve the recall of instances and used consistency constraints to smooth
    the training process to improve the generalization ability. Chikontwe *et al.* [2020](#bib.bib33)
    combined top-k instance selection, instance-level representation learning, and
    bag-level representation in an end-to-end framework. Sharma *et al.* [2021](#bib.bib147)
    also combined instance selection, instance-level representation learning and bag-level
    representation in an end-to-end framework. Unlike (Chikontwe *et al.* [2020](#bib.bib33)),
    they proposed to use a clustering-based sampling method to select key instances.
    Lu *et al.* [2021](#bib.bib105) also proposed a MIL framework based on clustering
    and attention mechanisms. They selected the instances with the largest and smallest
    attention scores in the current bag for clustering to enhance the learning of
    feature space. Myronenko *et al.* [2021](#bib.bib116) proposed a MIL framework
    combining the Transformer and CNN architectures to compute the interrelationships
    between instances and aggregate the instances features to accomplish the bag classification.
    They added the instance loss to assist the optimization process.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.4 Representative Clinical Studies
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A large number of outstanding studies have been dedicated to address significant
    clinical problems using weakly supervised methods. For example, Coudray *et al.* [2018](#bib.bib39)
    et al. developed deep learning models for accurate prediction of cancer subtypes
    and genetic mutations and sparked the whole field of weakly supervised computational
    pathology. Naik *et al.* [2020](#bib.bib118) et al. presented an attention-based
    deep MIL framework to predict directly estrogen receptor status from H&E slices.
    Another typical clinical work comes from Tomita *et al.* [2019](#bib.bib172),
    who proposed a grid-based attention network to perform 4-class classification
    of high-resolution endoscopic esophagus and gastroesophageal junction mucosal
    biopsy images from 379 patients. Skrede *et al.* [2020](#bib.bib156) developed
    a multi-scale deep MIL-based model to analyze conventional HE-stained slides and
    developed a model that can effectively predict the prognosis of patients after
    colorectal cancer surgery. Another gastrointestinal tract oncology study (Kather
    *et al.* [2019](#bib.bib85)) predicted microsatellite instability (MSI) based
    on a deep MIL model directly on HE-stained slides. Currently, weakly supervised
    deep-learning models for digital pathological analysis has been applied in a wide
    range of cancer types including breast, colorectal, lung, liver, cervical, thyroid,
    and bladder cancers (Coudray *et al.* [2018](#bib.bib39), Chaudhary *et al.* [2018](#bib.bib21),
    Wessels *et al.* [2021](#bib.bib186), Campanella *et al.* [2019](#bib.bib17),
    Anand *et al.* [2021](#bib.bib3), Yang *et al.* [2022](#bib.bib198), Li *et al.* [2021](#bib.bib98),
    Saillard *et al.* [2020](#bib.bib143), Velmahos *et al.* [2021](#bib.bib177),
    Woerl *et al.* [2020](#bib.bib188)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: List of literatures in the weakly supervised learning section.'
  prefs: []
  type: TYPE_NORMAL
- en: '|      Reference |      Approach |      Disease Type |      Staining |      Task
    |      Dataset |      Dataset Scale |      Dataset Link |      Performance |'
  prefs: []
  type: TYPE_TB
- en: '|      Yan et al. ([2018](#bib.bib197)) |      Instance-based |      Breast
    Cancer |      H&E |       Benign and      malignant classification |      UCSB
    breast dataset |      58 cases |      Kandemir et al. ([2014](#bib.bib80)) |      Accuracy:
    0.927 |'
  prefs: []
  type: TYPE_TB
- en: '|       Diabetes (from eye      fundus images) |      Messidor dataset |      1200
    cases |      Decencière et al. ([2014](#bib.bib44)) |      Accuracy: 0.740 |'
  prefs: []
  type: TYPE_TB
- en: '|      Kraus et al. ([2016](#bib.bib90)) |      Instance-based |      Breast
    Cancer |       Three channels with      fluorescent markers for      DNA, actin
    filaments,      and b-tubulin |       Classification of 12      distinct categories
    |       Broad Bioimage Benchmark      Collection (BBBC021v1) Dataset |      340
    cases |      Ljosa et al. ([2012](#bib.bib103)) |       Accuracy: 0.958 for full
         image, 0.971 for treatment |'
  prefs: []
  type: TYPE_TB
- en: '|      Cruz-Roa et al. ([2014](#bib.bib40)) |      Instance-based |      Breast
    Cancer |      H&E |       Automatic detection of      invasive ductal carcinoma
         tissue regions |       Clinical histopathology dataset      collected from
    multiple hospitals |      162 cases |      inhouse |      Accuracy: 0.842 |'
  prefs: []
  type: TYPE_TB
- en: '|      Ilse et al. ([2018](#bib.bib77)) |      Bag-based |      Breast Cancer
    |      H&E |       Automatic detection      of cancerous regions |      Breast
    cancer dataset |      58 cases |      Gelasca et al. ([2008](#bib.bib59)) |      Accuracy:
    0.755 |'
  prefs: []
  type: TYPE_TB
- en: '|      Colon Cancer |      Colon cancer dataset |      100 cases |      Sirinukunwattana
    et al. ([2016](#bib.bib155)) |      Accuracy: 0.904 |'
  prefs: []
  type: TYPE_TB
- en: '|      Tu et al. ([2019](#bib.bib173)) |      Bag-based |       Diabetes (from
    eye      fundus images) |      H&E |       Diagnosing diabetes from      weakly
    labeled retinal images |      Messidor dataset |      1200 cases |      Decencière
    et al. ([2014](#bib.bib44)) |      Accuracy: 0.742 |'
  prefs: []
  type: TYPE_TB
- en: '|      Hashimoto et al. ([2020](#bib.bib72)) |      Bag-based |      Malignant
    Lymphoma |      H&E |       Classification of malignant      lymphoma sub-types
    |       Clinical histopathology dataset      collected from multiple hospitals
    |      196 cases |      inhouse |      Accuracy: 0.871 |'
  prefs: []
  type: TYPE_TB
- en: '|      Yao et al. ([2020](#bib.bib202)) |      Bag-based |      Lung Cancer
    |      H&E |      Cancer survival prediction |       National Lung Screening      Trial
    (NLST) dataset |      387 cases |      Team et al. ([2011](#bib.bib169)) |      AUC:
    0.652 |'
  prefs: []
  type: TYPE_TB
- en: '|      Colorectal Cancer |       Molecular and Cellular      Oncology (MCO)
    dataset |      1146 cases |      Ward and Hawkins ([2015](#bib.bib184)) |      AUC:
    0.7143 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lu et al. ([2019](#bib.bib104)) |      Bag-based |      Breast Cancer
    |      H&E |      Classification of normal or benign |      BACH dataset |      400
    cases |      Aresta et al. ([2019](#bib.bib5)) |      Accuracy: 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '|      Zhao et al. ([2020](#bib.bib206)) |      Bag-based |      Colon Adenocarcinoma
    |      H&E |      Prediction of lymph node metastasis |       The Cancer Genome
         Atlas (TCGA) dataset |      425 cases |      Kandoth et al. ([2013](#bib.bib81))
    |      Accuracy: 0.6761 |'
  prefs: []
  type: TYPE_TB
- en: '|      Li, Li and Eliceiri ([2021](#bib.bib97)) |      Bag-based |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      Camelyon16
    dataset |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      Accuracy:
    0.8992 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lung Cancer |       Diagnosis of lung      cancer subtypes |       The
    Cancer Genome Atlas      (TCGA) lung cancer dataset |      1054 cases |      https://portal.gdc.cancer.gov/
    |      Accuracy: 0.9571 |'
  prefs: []
  type: TYPE_TB
- en: '|      Shao et al. ([2021](#bib.bib146)) |      Bag-based |      Breast Cancer
    |      H&E |      Detection of lymph node metastases |      Camelyon16 dataset
    |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      Accuracy:
    0.8837 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lung Cancer |      Diagnosis of cancer subtypes |      TCGA-NSCLC dataset
    |      993 cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.8835
    |'
  prefs: []
  type: TYPE_TB
- en: '|      Kidney Cancer |      Diagnosis of cancer subtypes |      TCGA-RCC dataset
    |      884 cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.9466
    |'
  prefs: []
  type: TYPE_TB
- en: '|      Li, Yang, Zhao and Yao ([2021](#bib.bib99)) |      Bag-based |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      BREAST-LNM
    dataset |      3957 cases |      inhouse |      AUC: 0.7288 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lung Cancer |      Diagnosis of lung cancer subtypes |      CPTAC-LUAD
    dataset |      1065 cases |      Clark et al. ([2013](#bib.bib37)) |      AUC:
    0.9906 |'
  prefs: []
  type: TYPE_TB
- en: '|      Hou et al. ([2016](#bib.bib76)) |      Hybrid |      Glioma |      H&E
    |      Classification of glioma |       The Cancer Genome Atlas (TCGA) dataset
    |      209cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.771 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lung Cancer |       Diagnosis of non-small-cell      lung carcinoma
    subtypes |      316cases |      Accuracy: 0.798 |'
  prefs: []
  type: TYPE_TB
- en: '|      Campanella et al. ([2019](#bib.bib17)) |      Hybrid |      Prostate
    Cancer |      H&E |      Benign and malignant classification |      Prostate core
    biopsy dataset |      24859 cases |      in house |      AUC: 0.986 |'
  prefs: []
  type: TYPE_TB
- en: '|      Skin Cancer |      Benign and malignant classification |      Skin dataset
    |      9,962 cases |      in house |      AUC: 0.986 |'
  prefs: []
  type: TYPE_TB
- en: '|      Breast Cancer |      Detection of lymph node metastases |      Breast
    dataset |      9894 cases |       MSK breast cancer:      http://thomasfuchslab.org/data/.
    |      AUC: 0.965 |'
  prefs: []
  type: TYPE_TB
- en: '|      Wang et al. ([2019](#bib.bib181)) |      Hybrid |      Lung Cancer |
         H&E |      Diagnosis of lung cancer subtypes |      Lung cancer dataset |
         939 cases |      inhouse |      Accuracy: 0.973 |'
  prefs: []
  type: TYPE_TB
- en: '|      Chen et al. ([2021](#bib.bib30)) |      Hybrid |      Breast Cancer
    |      IHC |       HER2 scoring (negative (0/1+),      equivocal (2+) and positive
    (3+)) |      HER2 scoring dataset |      1105 cases |      inhouse |      Accuracy:
    0.8970 |'
  prefs: []
  type: TYPE_TB
- en: '|      Chikontwe et al. ([2020](#bib.bib33)) |      Hybrid |      Colectoral
    Cancer |      H&E |       Prediction of normal      and malignant tissues |      CRC
    WSI Dataset I |      173 cases |      inhouse |      Accuracy: 0.9231 |'
  prefs: []
  type: TYPE_TB
- en: '|      CRC WSI Dataset II |      193 cases |      Accuracy: 0.9872 |'
  prefs: []
  type: TYPE_TB
- en: '|      Sharma et al. ([2021](#bib.bib147)) |      Hybrid |       Gastrointestinal
         Celiac Disease |      H&E |       Prediction of patients with      celiac
    disease or being healthy |      Gastrointestinal dataset |      413 cases |      inhouse
    |      Accuracy: 0.862 |'
  prefs: []
  type: TYPE_TB
- en: '|      Breast Cancer |      Detection of lymph node metastases |      Camelyon16
    dataset |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      AUC:
    0.9112 |'
  prefs: []
  type: TYPE_TB
- en: '|      Lu et al. ([2021](#bib.bib105)) |      Hybrid |      Renal Cell Carcinoma
    |      H&E |       subtyping and the detection      of lymph node metastasis |
         RCC dataset |      884 cases |      https://portal.gdc.cancer.gov |      AUC:
    0.991 |'
  prefs: []
  type: TYPE_TB
- en: '|      Non-small-cell Lung Cancer |      NSCLC dataset |      993 cases |      https://cancerimagingarchive.net/datascope/cptac
    |      AUC: 0.956 |'
  prefs: []
  type: TYPE_TB
- en: '|      Breast Cancer |      CAMELYON16 and CAMELYON17 dataset |      899 cases
    |      https://camelyon17.grand-challenge.org/Data |      AUC: 0.936 |'
  prefs: []
  type: TYPE_TB
- en: '|      Myronenko et al. ([2021](#bib.bib116)) |      Hybrid |      Prostate
    Cancer |      H&E |       Classifying cancer tissue      into Gleason patterns
    |       Prostate cANcer graDe Assessment      (PANDA) challenge dataset |      11,000
    cases |      https://panda.grandchallenge.org/home/ |      Accuracy: 0.805 |'
  prefs: []
  type: TYPE_TB
- en: '|      Naik et al. ([2020](#bib.bib118)) |      Clinical Studies |      Breast
    Cancer |      H&E |       Determination of      hormonal receptor status |      
    Australian Breast Cancer      Tissue Bank (ABCTB) dataset |      2535 cases |
         https://abctb.org.au/abctbNew2/ACCESSPOLICY.pdf |      AUC: 0.92 |'
  prefs: []
  type: TYPE_TB
- en: '|       The Cancer Genome Atlas (TCGA) dataset |      1014 cases |      https://portal.gdc.cancer.gov
    |      AUC: 0.861 |'
  prefs: []
  type: TYPE_TB
- en: '|      Tomita et al. ([2019](#bib.bib172)) |      Clinical Studies |      Esophagus
    Cancer |      H&E |       Detection of cancerous and      precancerous esophagus
    tissue |      Esophagus cancer dataset |      180 cases |      inhouse |      Accuracy:
    0.83 |'
  prefs: []
  type: TYPE_TB
- en: '|      Skrede et al. ([2020](#bib.bib156)) |      Clinical Studies |      Colorectal
    Cancer |      H&E |      Prediction of colorectal cancer outcome |      Colorectal
    cancer dataset |      2473 cases |      inhouse |       Ratio for poor versus
         good prognosis: 3.84 |'
  prefs: []
  type: TYPE_TB
- en: '|      Kather *et al.* ([2019](#bib.bib85)) |      Clinical Studies |      Gastrointestinal
    Cancer |      H&E |      Prediction of microsatellite instability |      TCGA-STAD
    dataset |      315 cases |      https://portal.gdc.cancer.gov/. |      AUC: 0.81
    |'
  prefs: []
  type: TYPE_TB
- en: '|      TCGA-CRC-DX dataset |      360 cases |      AUC: 0.84 |'
  prefs: []
  type: TYPE_TB
- en: '|      TCGA-CRC-KR dataset |      378 cases |      AUC: 0.77 |'
  prefs: []
  type: TYPE_TB
- en: '|      Coudray et al. ([2018](#bib.bib39)) |      Clinical Studies |      Lung
    Cancer |      H&E |      Classification of subtypes |       The Cancer Genome
    Atlas (TCGA) dataset |      1634 cases |      https://portal.gdc.cancer.gov/ |
         AUC: 0.97 |'
  prefs: []
  type: TYPE_TB
- en: '|       Prediction of mutation from      non-small cell lung cancer |      
    AUC of six of commonly mutated      genes from 0.733 to 0.856 |'
  prefs: []
  type: TYPE_TB
- en: '|      Bejnordi et al. ([2017a](#bib.bib9)) |      Clinical Studies |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      CAMELYON16
    dataset |      400 cases |      https://camelyon16.grand-challenge.org/ |      AUC:
    0.994 |'
  prefs: []
  type: TYPE_TB
- en: '|      Wessels et al. ([2021](#bib.bib186)) |      Clinical Studies |      Prostate
    Cancer |      H&E |      Prediction lymph node metastasis |      Prostate cancer
    dataset |      218 cases |      inhouse |      AUC: 0.68 |'
  prefs: []
  type: TYPE_TB
- en: '|      Anand et al. ([2021](#bib.bib3)) |      Clinical Studies |      Thyroid
    Cancer |      H&E |      Prediction of BRAF mutation |       ISBI 2017 Thyroid
    Tissue      Microarray (TH-TMA17) dataset |      85 cases | Wang *et al.* ([2018](#bib.bib180))
    |      AUC: 0.96 |'
  prefs: []
  type: TYPE_TB
- en: '|      TCGA-THCA dataset |      444 cases |      https://portal.gdc.cancer.gov/
    |      AUC: 0.98 |'
  prefs: []
  type: TYPE_TB
- en: '|      Yang et al. ([2022](#bib.bib198)) |      Clinical Studies |      Breast
    Cancer |      H&E |       Prediction of HER2-positive breast      cancer recurrence
    and metastasis risk |      HER2-positive breast cancer dataset |      127 cases
    |      https://github.com/bensteven2/HE_breast_recurrence |      AUC: 0.76 |'
  prefs: []
  type: TYPE_TB
- en: '|      The Cancer Genome Atlas (TCGA) dataset |      123 cases |      AUC:
    0.72 |'
  prefs: []
  type: TYPE_TB
- en: '| Li *et al.* ([2021](#bib.bib98)) |      Clinical Studies |      Breast Cancer
    |      H&E |       Predicting biomarker of      pathological complete response
         to neoadjuvant chemotherapy |      Breast cancer dataset |      540 cases
    |      inhouse |      AUC: 0.847 |'
  prefs: []
  type: TYPE_TB
- en: '|      Saillard et al. ([2020](#bib.bib143)) |      Clinical Studies |      Hepatocellular
    Carcinoma |      H&E |       Predicting survival after      hepatocellular carcinoma
    resection |      Discovery set |      194 cases |      inhouse |      C-Indices:
    0.78 |'
  prefs: []
  type: TYPE_TB
- en: '|      The Cancer Genome Atlas (TCGA) dataset |      328 cases |      https://portal.gdc.cancer.gov/
    |      C-Indices: 0.70 |'
  prefs: []
  type: TYPE_TB
- en: '|      Velmahos et al. ([2021](#bib.bib177)) |      Clinical Studies |      Bladder
    Cancer |      H&E |      Identifying FGFR-activating mutations |       The Cancer
    Genome      Atlas (TCGA) dataset |      418 cases |      https://portal.gdc.cancer.gov/
    |      AUC = 0.76 |'
  prefs: []
  type: TYPE_TB
- en: '|      Woerl et al. ([2020](#bib.bib188)) |      Clinical Studies |      Bladder
    Cancer |      H&E |      Prediction of molecular subtypes |       The Cancer Genome
    Atlas (TCGA)      Urothelial Bladder Carcinoma Dataset |      407 cases |      https://portal.gdc.cancer.gov/
    |      AUC = 0.89 |'
  prefs: []
  type: TYPE_TB
- en: '|      CCC-EMN cohort |      16 cases |      inhouse |      AUC = 0.85 |'
  prefs: []
  type: TYPE_TB
- en: 3.2 Semi-Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Semi-supervised learning is a branch of machine learning that combines both
    supervised and unsupervised learning tasks and improves model performance by exploiting
    the information associated between tasks (Zhu *et al.* [2005](#bib.bib211), Van
    *et al.* [2020](#bib.bib175)). In semi-supervised learning, only a small amount
    of labeled data is generally available, and besides that, a large amount of unlabeled
    data can be utilized for network training. Consequently, the main goal of semi-supervised
    learning is how to use these unlabeled data to improve the performance of the
    model trained with limited labeled data. Scenarios of the semi-supervised learning
    paradigm are very common in the field of pathological image analysis, both in
    diagnostic tasks and in segmentation tasks. Due to the expensive and time-consuming
    fine-grained annotation, pathologists often can only provide a small number of
    precise annotations for supervised training of the models, while a large amount
    of unannotated data cannot be used. Training deep models with only these limited
    labeled data can easily lead to over-fitting, thus significantly harming the performance
    and generalization of the models. In the semi-supervised learning paradigm, a
    large number of unlabeled images can be used to assist in training and thus further
    improve the performance, generalization, and robustness of the models.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the past two decades, numerous semi-supervised learning algorithms have
    been proposed and widely used in the fields of natural image processing and pathological
    image analysis. The representative approaches in the field of semi-supervised
    learning are divided into five categories, namely pseudo-labelling-based approach
    (Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Pseudo-labelling-based Approach ‣ 3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")),
    consistency-based approach (Section [3.2.2](#S3.SS2.SSS2 "3.2.2 Consistency-based
    Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), graph-based approach (Section [3.2.3](#S3.SS2.SSS3 "3.2.3 Graph-based
    Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), unsupervised-preprocessing approach (Section [3.2.4](#S3.SS2.SSS4
    "3.2.4 Unsupervised-preprocessing-based Approach ‣ 3.2 Semi-Supervised Learning
    Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis")), and other
    approaches (Section [3.2.5](#S3.SS2.SSS5 "3.2.5 Other Approaches ‣ 3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")).
    We introduce these methods below, respectively. For each category, we first describe
    their fundamental principles and then elaborate on their representative studies
    in the field of pathological image analysis. For a systematic review of the assumptions,
    concepts and representative methods of semi-supervised learning in the field of
    natural images, we recommend the review by Van *et al.* [2020](#bib.bib175). Table
    [4](#S3.T4 "Table 4 ‣ 3.2.5 Other Approaches ‣ 3.2 Semi-Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis") summarizes the
    detailed list of literatures in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Pseudo-labelling-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The pseudo-labeling-based approach is a classical and well-known semi-supervised
    method (Zhu *et al.* [2005](#bib.bib211)), which mainly consists of two alternating
    processes, training and pseudo-labeling. Taking the classification problem as
    an example, in the training process, one or more classifiers are first trained
    in a supervised manner on the labeled data. The labeled data may be derived from
    the initial accurately labeled data or from the pseudo-labeled data from the previous
    iterations. In the pseudo-labeling process, all the unlabeled data are first predicted
    using the classifier trained in the previous process, and then the most confidently
    predicted portion of the data are selected for pseudo-labeling. Finally, these
    pseudo-labeled data are added to the labeled data for the next iteration. This
    process is repeated until no data with high confidence are found or all data are
    labeled.
  prefs: []
  type: TYPE_NORMAL
- en: The pseudo-labeling-based methods are firstly applied to the field of natural
    image processing and typically contain self-training methods (Lee *et al.* [2013](#bib.bib94))
    and co-training methods (Blum *et al.* [1998](#bib.bib14), Zhou *et al.* [2005](#bib.bib209)).
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In pathological image analysis, Singh *et al.* [2011](#bib.bib153) proposed
    a semi-supervised method of learning distance metrics from labeled data and performing
    label propagation for identifying the subtypes of nuclei, which was locally adaptive
    and could fully consider the heterogeneity of the data. Bulten *et al.* [2020](#bib.bib16)
    developed a deep learning system for Gleason scoring of prostate biopsies based
    on semi-supervised learning. They first trained the network on a small training
    dataset with pure Gleason scores, and then applied the trained network to other
    internal training datasets to set reference standards. Then, the labels were corrected
    and relabeled using reports from pathologists. Tolkach *et al.* [2020](#bib.bib171)
    used a pseudo-labeling-based semi-supervised strategy to train the CNN network
    to accomplish Gleason pattern classification. Jasiwal *et al.* [2019](#bib.bib79)
    proposed a semi-supervised method based on pseudo-labeling and entropy regularization
    for breast cancer pathological image classification. Shaw *et al.* [2020](#bib.bib148)
    extended the study of Yalniz *et al.* [2019](#bib.bib196) by proposing a semi-supervised
    teacher-student distillation method for the classification of colorectal cancer
    pathological images. Marini *et al.* [2021](#bib.bib109) proposed a deep pseudo-labeling-based
    semi-supervised learning method for strongly heterogeneous pathology data containing
    only a small number of local annotations. Their method consists of a high-volume
    teacher model and a small-volume student model, where the teacher model is automatically
    labeled with pseudo labels for the training of the student model. Cheng *et al.* [2020](#bib.bib31)
    proposed a semi-supervised learning framework based on a teacher-student model
    with similarity learning for the segmentation of breast cancer lesions containing
    a small number of annotations and noisy annotations.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Consistency-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: The consistency-based semi-supervised learning approach is mainly based on the
    smoothing assumption. In the smoothing assumption, the prediction model should
    be robust to local perturbations within its input. This means that when we perturb
    the data points with a small amount of noise, the network’s predictions for the
    perturbed data points and the clean original data points should be similar. In
    the implementation of deep neural networks, the consistency-based approach can
    be easily extended to a semi-supervised learning setup by directly adding unsupervised
    consistency loss functions to the original supervised loss functions. In the field
    of natural image processing, typical methods include <math 
    class="ltx_Math" alttext="\pi" display="inline"><semantics ><mi
     >π</mi><annotation-xml
    encoding="MathML-Content" ><ci 
    >𝜋</ci></annotation-xml><annotation encoding="application/x-tex"
    >\pi</annotation></semantics></math>-model (Laine
    *et al.* [2016](#bib.bib92)), Temporal Ensembling model (Laine *et al.* [2016](#bib.bib92)),
    Mean Teachers (Tarvainen *et al.* [2017](#bib.bib167)) and UDA (Xie *et al.* [2020](#bib.bib190)).
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In pathological image analysis, Zhou *et al.* [2020](#bib.bib208) proposed a
    new Mean-teacher (MT) framework based on template-guided perturbation-sensitive
    sample mining. This framework consists of a teacher network and a student network.
    The teacher network is an integrated prediction network from K-times randomly
    augmented data, which is used to guide the student network to remain invariant
    to small perturbations at both feature and semantic levels. Su *et al.* [2019](#bib.bib162)
    proposed a novel global and local consistency loss and performed the nuclei classification
    task based on the Mean-Teacher framework.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3 Graph-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Methods of graph-based semi-supervised learning typically construct graphs to
    preserve the relationships of neighboring nodes, and use the graph transformations
    to simultaneously exploit information from labeled data and explore the underlying
    structure of unlabeled data. The key step of the graph-based semi-supervised learning
    methods is to construct a better graph to represent the original data structure.
    They usually define a graph on all data points (both labeled and unlabeled data
    points) and use weights to encode the similarity between pairs of the data points.
    In this way, the labeled information can be propagated through the graph to the
    unlabeled data points. For labeled data points, the predicted labels should match
    the true labels; similar data points defined by a similarity graph should have
    the same predictions. Graph-based semi-supervised methods are a relatively complex
    and long-developed field, and we recommend (Van *et al.* [2020](#bib.bib175),
    Chong *et al.* [2020](#bib.bib34)) for a more thorough understanding.
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In pathological image analysis, Xu *et al.* [2016](#bib.bib194) proposed a new
    framework that combines a CNN with a semi-supervised regularization term. They
    first generated a hypothetical label for each unlabeled sample, then proposed
    a graph-based smoothing term for regularization. Su *et al.* [2015](#bib.bib163)
    proposed an active learning and graph-based semi-supervised learning method for
    interactive cell segmentation. Inspired by the Temporal Ensembling model (Laine
    *et al.* [2016](#bib.bib92)), Shi *et al.* [2020](#bib.bib150) proposed a graph-based
    temporal ensembling model GTE. This method creates ensemble targets for both features
    and label predictions for each training sample, and encourages the model to form
    consistent predictions under different perturbations to exploit the semantic information
    of unlabeled data and improve the robustness of the model to noisy labels.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.4 Unsupervised-preprocessing-based Approach
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Unlike the previous approaches, unsupervised preprocessing-based approaches
    are typically dedicated to the unsupervised feature extraction, clustering (cluster-then-label),
    or initialization of the parameters of the subsequent supervised learning process
    (pre-training) from a large amount of unlabeled data. The most popular methods
    include autoencoders and their variants (Vincent *et al.* [2008](#bib.bib179),
    [2011](#bib.bib138)). Clustering is another method that enables adequate learning
    of the overall data distribution, thus many semi-supervised learning algorithms
    (Goldberg *et al.* [2009](#bib.bib62), Demiriz *et al.* [1999](#bib.bib46), Dara
    *et al.* [2002](#bib.bib43)) guide the subsequent classification process through
    clustering. The idea of the pre-training is to first pre-train a model using unsupervised
    methods with unlabeled data, and then use the parameters of this model as the
    initial parameters of the subsequent supervised training model, i.e., the subsequent
    supervised training is fine-tuned on the basis of these initial parameters. On
    this basis, the large number of unlabeled data can fully guide the subsequent
    classification models with limited labeled data thus improving the performance
    of semi-supervised learning (Erhan *et al.* [2010](#bib.bib55)).
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In pathological image analysis, Peikari *et al.* [2018](#bib.bib125) proposed
    a cluster-then-label semi-supervised learning method for identifying high-density
    regions in the data space and then utilized these regions to help support vector
    machines find decision boundaries. Lu *et al.* [2019](#bib.bib104) proposed a
    semi-supervised method based on feature extraction and pre-training for the WSI-level
    breast cancer classification task, which is the first work that relies on self-supervised
    feature learning using contrastive predictive coding for weakly supervised histopathological
    image classification. Koohbanani *et al.* [2021](#bib.bib89) proposed a joint
    framework of self-supervised learning and semi-supervised learning for pathological
    images. They proposed three pathology-specific self-supervised tasks, magnification
    prediction, magnification jigsaw prediction and hematoxylin channel prediction,
    to learn high-level semantic information and domain invariant information in pathological
    images. Srinidhi *et al.* [2022](#bib.bib160) also proposed a framework that combines
    self-supervised learning with semi-supervised learning. They first proposed the
    resolution sequence prediction (RSP) self-supervised auxiliary task to pre-train
    the model through unlabeled data, and then they performed fine-tuning of the model
    on the labeled data. After that they used the trained model from the above two
    steps as the initial weights of the model for further semi-supervised training
    based on the teacher-student consistency framework.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.5 Other Approaches
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Among semi-supervised learning, there are many other approaches, such as the
    methods based on generative adversarial networks (GAN) (Goodfellow *et al.* [2014](#bib.bib65),
    [2016](#bib.bib63), Salimans *et al.* [2016](#bib.bib144), Odena *et al.* [2016](#bib.bib121),
    Dai *et al.* [2017](#bib.bib42)), Manifold-based methods (Belkin *et al.* [2005](#bib.bib12),
    [2006](#bib.bib13), Weston *et al.* [2012](#bib.bib187), Rifai *et al.* [2011](#bib.bib137),
    [2011](#bib.bib138)) and Association learning based methods (Haeusser *et al.* [2017](#bib.bib70)).
  prefs: []
  type: TYPE_NORMAL
- en: In pathological image analysis, Kapil *et al.* [2018](#bib.bib82) first used
    auxiliary classifier generative adversarial networks (AC-GAN) for the pathological
    image semi-supervised classification task and achieved favorable results. Cong
    *et al.* [2021](#bib.bib38) proposed to use a GAN-based semi-supervised learning
    method to accomplish the stain normalization problem for pathological images.
    Sparks *et al.* [2016](#bib.bib158) proposed a semi-supervised method based on
    epidemic learning to accomplish a content-based histopathological image retrieval
    task. Li *et al.* [2018](#bib.bib100) developed an Expectation-Maximization (EM)-based
    semi-supervised method for the semantic segmentation task of radical prostatectomy
    histopathological images. Su *et al.* [2021](#bib.bib164) proposed a new semi-supervised
    method based on association learning for pathological image classification task
    inspired by Haeusser *et al.* [2017](#bib.bib70). Some studies (Foucart *et al.* [2019](#bib.bib57))
    have also attempted to analyze the weaknesses and effectiveness of semi-supervised,
    noisy learning and weak label learning based on deep learning for pathological
    image analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: List of literatures in the semi-supervised learning section.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Approach | Disease Type | Staining | Task | Dataset | Dataset
    Scale | Dataset Link | Performance |'
  prefs: []
  type: TYPE_TB
- en: '| Singh et al. ([2011](#bib.bib153)) | Pseudo- labelling-based | Breast Cancer
    | 3D fluorescence microscopy | Identifying nuclear phenotypes | Nuclei image dataset
    | 984 images | Inhouse | Mean Accuracy: 0.8 |'
  prefs: []
  type: TYPE_TB
- en: '| Bulten et al. ([2020](#bib.bib16)) | Pseudo- labelling-based | Prostate Cancer
    | H&E | Gleason grading | Inhouse dataset | 5759 biopsies from 1243 patients |
    Inhouse | AUC = 0.99 |'
  prefs: []
  type: TYPE_TB
- en: '| Tolkach et al. ([2020](#bib.bib171)) | Pseudo- labelling-based | Prostate
    Cancer | H&E | Detection of prostate cancer tissue | The Cancer Genome Atlas Program
    (TCGA) dataset | 1.67 million patches | http://portal.gdc.cancer.gov | Accuracy
    = 0.967 |'
  prefs: []
  type: TYPE_TB
- en: '| Gleason grading of prostatic adenocarcinomas | https://zenodo.org/deposit/3825933
    | Accuracy = 0.98 |'
  prefs: []
  type: TYPE_TB
- en: '| Jaiswal et al. ([2019](#bib.bib79)) | Pseudo- labelling-based | Breast Cancer
    | H&E | Detection of lymph node metastases | PatchCamelyon dataset | 327680 patches
    | https://camelyon16.grand-challenge.org/Data/ | AUC = 0.9816 |'
  prefs: []
  type: TYPE_TB
- en: '| Shaw et al. ([2020](#bib.bib148)) | Pseudo- labelling-based | Colorectal
    Cancer | H&E | Classification of 9 categories of pathology patterns | Public dataset
    | 100000 patches | https://zenodo.org/record/1214456#.YvyiX3ZByw4 | Mean Accuracy
    = 0.943 |'
  prefs: []
  type: TYPE_TB
- en: '| Marini et al. ([2021](#bib.bib109)) | Pseudo- labelling-based | Prostate
    Cancer | H&E | Gleason grading | Tissue MicroArray dataset Zurich dataset | 886
    cases | Inhouse | <math  class="ltx_Math" alttext="\kappa"
    display="inline"><semantics ><mi mathsize="80%" 
    >κ</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝜅</ci></annotation-xml><annotation
    encoding="application/x-tex" >\kappa</annotation></semantics></math>-score:
    0.7645 |'
  prefs: []
  type: TYPE_TB
- en: '| TCGA-PRAD dataset | 449 cases | http://portal.gdc.cancer.gov | <math 
    class="ltx_Math" alttext="\kappa" display="inline"><semantics ><mi
    mathsize="80%"  >κ</mi><annotation-xml
    encoding="MathML-Content" ><ci 
    >𝜅</ci></annotation-xml><annotation encoding="application/x-tex"
    >\kappa</annotation></semantics></math>-score: 0.4529
    |'
  prefs: []
  type: TYPE_TB
- en: '| Cheng et al. ([2020](#bib.bib31)) | Pseudo- labelling-based | Breast Cancer
    | H&E | Automated segmentation of cancerous regions | CAMELYON16 dataset | 400
    cases | https://camelyon16.grand-challenge.org/Data/ | Dice: 93.76 |'
  prefs: []
  type: TYPE_TB
- en: '| Prostate Cancer | TVGH TURP dataset | 71 cases | Inhouse | Dice: 77.24 |'
  prefs: []
  type: TYPE_TB
- en: '| Zhou et al. ([2020](#bib.bib208)) | Consistency-based | - | Liquid-based
    pap test specimen | Cervical cell instance segmentation | liquid-based Pap test
    specimen dataset | 4439 cytoplasm | Inhouse | AJI: 73.45, MAP: 46.01 |'
  prefs: []
  type: TYPE_TB
- en: '| Su et al. ([2019](#bib.bib162)) | Consistency-based | - | H&E | Nuclei classification
    | MoNuseg dataset | 22462 nuclei | Sirinukunwattana et al. ([2016](#bib.bib155))
    | F1 score: 75.02 (5% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Ki-67 nucleus dataset | 17516 nuclei | Inhouse | F1 score: 79.32 (5% labels)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Consistency-based | Breast Cancer,
    Colorectal Cancer | H&E | Detection of tumor metastasis | BreastPathQ dataset
    | 2579 patches | Martel et al. ([2019](#bib.bib111)) | TC: 0.876 (10% labels)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Classification of tissue types | Camelyon16 dataset | 399 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC: 0.855 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Quantification of tumor cellularity | Kather multiclass dataset | 100K patches
    | Kather *et al.* ([2019](#bib.bib84)) | Accuracy: 0.982 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Xu et al. ([2016](#bib.bib194)) | Graph-based | - | Microscopy images | Neuron
    segmentation | Neural morphology image dataset | 2000 neuron regions with with
    annotations | Inhouse | F1 score: 0.96 (40% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Su et al. ([2015](#bib.bib163)) | Graph-based | - | Microscopy images | Cell
    segmentation | Phase contrast microscopy image dataset | Multiple sequences of
    total 1404 frames | http://www.celltracking.ri.cmu.edu/downloads.html. | TC: 0.9813
    |'
  prefs: []
  type: TYPE_TB
- en: '| Shi, Su, Xing and Yang ([2020](#bib.bib150)) | Graph-based | Lung Cancer
    | H&E | Predictions of subtypes | The Cancer Genome Altas (TCGA) | 2904 patches
    | http://portal.gdc.cancer.gov | Accuracy: 0.905 (20% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Breast Cancer | 1763 patches | Accuracy: 0.895 (20% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Peikari et al. ([2018](#bib.bib125)) | Unsupervised- preprocessing-based
    | Breast Cancer | H&E | Identifying different breast tissue regions | Pathology
    triaging image dataset | 4402 patches | Inhouse | AUC: 0.86 |'
  prefs: []
  type: TYPE_TB
- en: '| Nuclei figure classification dataset | 30,000 figures | AUC: 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| Lu et al. ([2019](#bib.bib104)) | Unsupervised- preprocessing-based | Breast
    Cancer | H&E | Benign and malignant classification | BACH dataset | 400 cases
    | BACH: Grand challenge on Breast Cancer histology images | Accuracy: 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Unsupervised- preprocessing-based
    | Breast Cancer | H&E | Detection of tumor regions | Camelyon16 dataset | 399
    slides | https://camelyon16.grand-challenge.org/Data/ | AUC: 0.817 (1% labeled)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Oral Squamous Cell Carcinoma | Prediction of metastases in the cervical lymph
    nodes | LNM-OSCC dataset | 217 slides | Inhouse | AUC: 0.806 (1% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '| Colorectal Cancer | Classification of tissue types | Kather multiclass dataset
    | 100K patches | Kather *et al.* ([2019](#bib.bib84)) | AUC: 0.903 (1%labeled)
    |'
  prefs: []
  type: TYPE_TB
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Unsupervised- preprocessing-based
    | Breast Cancer, Colorectal Cancer | H&E | Detection of tumor metastasis | BreastPathQ
    dataset | 2579 patches | Martel et al. ([2019](#bib.bib111)) | TC: 0.876 (10%
    labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Classification of tissue type | Camelyon16 dataset | 399 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC: 0.855 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Quantification of tumor cellularity | Kather multiclass dataset | 100K patches
    | Kather *et al.* ([2019](#bib.bib84)) | ACC: 0.982 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Kapil et al. ([2018](#bib.bib82)) | GAN-based | Lung Cancer | Ventana PD-L1
    (SP263) assay | Automated tumor proportion scoring | NSCLC needle biopsy dataset
    | 270 slides | Inhouse | Ratio of the number of tumor positive cell pixels to
    the total number of tumor cell pixels: 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '| Cong et al. ([2021](#bib.bib38)) | GAN-based | Brain Cancer | H&E | Stain
    normalisation | TCGA1 glioma cohort | 22,229 images | Liu et al. ([2020](#bib.bib101))
    | F1 score: 0.937 |'
  prefs: []
  type: TYPE_TB
- en: '| Breast Cancer | BreakHis database | 7,909 images | Spanhol et al. ([2015](#bib.bib157))
    | F1 score: 0.980 |'
  prefs: []
  type: TYPE_TB
- en: '| Sparks and Madabhushi ([2016](#bib.bib158)) | Manifold- learning-based |
    Prostate Cancer | H&E | Image retrieval | Prostate histpathology dataset | 58
    patients | Inhouse | SI: 0.14 |'
  prefs: []
  type: TYPE_TB
- en: '| Li et al. ([2018](#bib.bib100)) | Expectation- Maximization-based | Prostate
    Cancer | H&E | Semantic segmentation | Prostate dataset | 135 fully annotated
    and 1800 weakly annotated tiles | Gertych et al. ([2015](#bib.bib60)) | AJI: 0.495
    |'
  prefs: []
  type: TYPE_TB
- en: '| Su et al. ([2021](#bib.bib164)) | Association- learning-based | Breast Cancer
    | H&E | Classification of cancerous and non-cancerous slides | Bioimaging 2015
    challenge dataset | 285 images | Araújo et al. ([2017](#bib.bib4)) | F1 score:
    0.75 |'
  prefs: []
  type: TYPE_TB
- en: '| BACH dataset | 400 images | Aresta et al. ([2019](#bib.bib5)) | F1 score:
    0.77 |'
  prefs: []
  type: TYPE_TB
- en: 3.3 Self-Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Unlike the former two paradigms, the self-supervised learning paradigm does
    not perform the classification or segmentation of pathological images directly,
    but in a two-stage ’pre-training and fine-tuning’ approach. Due to the small number
    of annotated pathological images, it is not enough to use these data to directly
    train the model. Therefore, the self-supervised learning paradigm aims to first
    learn effective feature representations from a large amount of unlabeled data,
    which is called the pre-training process. Afterwards, the feature representations
    learned in the self-supervised auxiliary tasks are used to be transferred to train
    the downstream tasks using limited labeled data, which is called the fine-tuning
    process. In this way, good feature representations can effectively help the model
    to achieve good results even if it is trained with only a small amount of labeled
    data.
  prefs: []
  type: TYPE_NORMAL
- en: The process of pre-training, i.e., the learning process of good feature representations,
    is the key to self-supervised learning. Typically, self-supervised learning learns
    good feature representations by performing self-supervised auxiliary tasks. In
    a self-supervised auxiliary task, certain inherent properties of the unlabeled
    data are first used to generate supervised signals, and then the network is trained
    by these self-supervised signals. Different studies usually focus on designing
    different self-supervised auxiliary tasks to perform feature representation learning
    efficiently. According to the properties of the auxiliary tasks, existing self-supervised
    learning paradigms can be mainly classified into predictive self-supervised learning,
    generative self-supervised learning, and contrastive self-supervised learning.
    Predictive self-supervised learning learns good feature representations by constructing
    the auxiliary tasks as classification problems with unlabeled data; generative
    self-supervised learning learns good feature representations by reconstructing
    the input images; and contrastive self-supervised learning learns good feature
    representations by learning to distinguish between similar samples (positive samples)
    and dissimilar samples (negative samples). For a systematic review of self-supervised
    methods in the natural image domain and medical image domain, we recommend the
    reviews by Liu *et al.* [2021](#bib.bib102) and Shurrab *et al.* [2021](#bib.bib152).
  prefs: []
  type: TYPE_NORMAL
- en: 'In this section, we provide a detailed review of the studies on self-supervised
    learning for pathological image analysis. Currently, some studies focus on proposing
    innovative self-supervised frameworks for pathological images (we call them study
    on novel self-supervised frameworks), while others attempt to apply existing self-supervised
    learning methods to pathological image analysis (we call them study on application
    of self-supervised frameworks). We introduce studies on novel self-supervised
    frameworks in Section [3.3.1](#S3.SS3.SSS1 "3.3.1 Study on Novel Self-supervised
    Frameworks ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"), where we focus on predictive self-supervised learning, generative
    self-supervised learning, contrastive self-supervised learning, and hybrid self-supervised
    learning and their state-of-the-art approaches in pathological image analysis.
    We introduce the study on application of self-supervised frameworks in Section
    [3.3.2](#S3.SS3.SSS2 "3.3.2 Study on Applications of Self-supervised Frameworks
    ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"). Table [5](#S3.T5 "Table 5 ‣ 3.3.2 Study on Applications of Self-supervised
    Frameworks ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") summarizes a detailed list of literatures in this section.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.1 Study on Novel Self-supervised Frameworks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Predictive Self-supervised Learning Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Predictive self-supervised learning learns good feature representations by constructing
    the auxiliary tasks as classification problems with unlabeled data, and the class
    labels for classification are constructed from the unlabeled data itself. Currently,
    predictive self-supervised auxiliary tasks widely applied in natural image processing
    are relative position prediction (Doersch *et al.* [2015](#bib.bib49)), solving
    Jigsaw puzzles (Noroozi *et al.* [2016](#bib.bib120)), and rotation angle prediction
    (Gidaris *et al.* [2018](#bib.bib61)), etc.
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In the field of pathological image processing, Sahasrabudhe *et al.* [2020](#bib.bib141)
    proposed the auxiliary task of predicting patch magnification for cell nuclei
    segmentation. Their main idea is that given WSIs of different magnification classes
    (e.g., 5$\times"
    display="inline"><semantics ><mo 
    >×</mo><annotation encoding="application/x-tex"
    id=$, 10$\times" display="inline"><semantics
    ><mo 
    >×</mo><annotation encoding="application/x-tex"
    id=$, 20$\times" display="inline"><semantics
    ><mo 
    >×</mo><annotation encoding="application/x-tex"
    id=$),
    they first obtained patches of different magnifications from them and then predicted
    the magnification class of those patches by examining the size and texture of
    the cell nuclei in the patches. Srinidhi *et al.* [2022](#bib.bib160) proposed
    the resolution sequence prediction (RSP) auxiliary task. First they used patches
    with different magnifications to construct different combinations of resolution
    sequences, and then trained the network to predict the order of the resolution
    sequences. Koohbanani *et al.* [2021](#bib.bib89) proposed magnification prediction
    and solving magnification puzzles auxiliary tasks for pathological images. They
    first trained the network to accurately predict the magnification category, and
    then trained the network to predict the order of the patches with different magnifications.
  prefs: []
  type: TYPE_NORMAL
- en: Generative Self-supervised Learning Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Generative self-supervised learning learns good feature representations by reconstructing
    the input images. They argue that the image itself is a useful self-supervised
    information and that the network can learn the potential feature representations
    of the generated image during the image reconstruction process. In natural image
    processing, autoencoders (Goodfellow *et al.* [2016](#bib.bib64)) are representative
    of early work on generative self-supervised feature representation learning. Later,
    denoising autoencoders (Vincent *et al.* [2008](#bib.bib179)) enhanced the feature
    representation capability of the model by introducing noise. Subsequently, researchers
    proposed a series of reconstructive self-supervised auxiliary tasks, including
    inpainting (Pathak *et al.* [2016](#bib.bib124)), colorization (Zhang *et al.* [2016](#bib.bib204)),
    patch shuffling and restoration (Chen *et al.* [2019](#bib.bib23), Zhou *et al.* [2021](#bib.bib210))
    to further enhance the feature representation capability of the network and achieved
    promising results. On the other hand, a series of GAN-based models (e.g., DCGAN
    [2015](#bib.bib133), BiGAN [2016](#bib.bib50)) have also been used to perform
    self-supervised representation learning. In the latest self-supervised studies
    on natural images, a series (e.g., BEiT [2021](#bib.bib6), MAE [2021](#bib.bib73),
    PeCo [2021](#bib.bib51), etc.) of self-supervised studies based on masked image
    blocks and reconstruction using Transformer achieved the highest performance,
    which is expected to start a new wave of research on reconstruction-based self-supervised
    representation learning.
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In pathological image analysis, Muhammad *et al.* [2019](#bib.bib114) proposed
    a new deep convolutional autoencoder-based clustering model to learn the feature
    representations of pathological images. Mahapatra *et al.* [2020](#bib.bib108)
    incorporated semantic information into a GAN-based generative model for self-supervised
    feature representation learning and used it for the stain normalization task of
    pathological images. Quiros *et al.* [2019](#bib.bib131), [2021](#bib.bib130)
    designed GANs for pathological images to extract key feature representations of
    tissues. Boyd et al *et al.* [2021](#bib.bib15) proposed a new generative auxiliary
    task which performs representation learning by extending the view of image patches.
    Hou et al *et al.* [2019](#bib.bib75) proposed a sparse convolutional autoencoder
    (CAE) for simultaneous nuclei detection and feature extraction in histopathological
    images. Koohbanani *et al.* [2021](#bib.bib89) proposed the hematoxylin channel
    prediction auxiliary task, where they used hematoxylin and eosin (H&E) stained
    images to predict the hematoxylin channel pixel by pixel.
  prefs: []
  type: TYPE_NORMAL
- en: Contrastive Self-supervised Learning Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Fundamental Principles
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The contrastive self-supervised approach is one of the most popular self-supervised
    paradigms, which focuses on learning good feature representations by encouraging
    the model to learn to distinguish between similar samples (positive samples) and
    dissimilar samples (negative samples).
  prefs: []
  type: TYPE_NORMAL
- en: Contrast predictive coding (CPC) (Van *et al.* [2018](#bib.bib174)) is an early
    contrastive self-supervised method applied to natural image processing whose goal
    is to maximize the mutual information between patches (positive samples) from
    the same image and minimize the mutual information between patches (negative samples)
    from different images within a mini-batch. Typical subsequent studies have been
    devoted to constructing negative samples. MoCo (He *et al.* [2020](#bib.bib74))
    is a momentum-based contrastive self-supervised framework, which is mainly based
    on the ideas of dynamic dictionary-lookup and queues. SimCLR (Chen *et al.* [2020](#bib.bib26))
    is a simple contrastive learning framework that aims to maximize the cosine similarity
    between two augmented views of the same image (positive samples) and minimize
    the similarity between different images in a minibatch (negative samples).
  prefs: []
  type: TYPE_NORMAL
- en: These methods rely heavily on a large number of negative samples since only
    positive samples will easily lead to model degeneration, i.e., mapping the features
    of all samples to an identical vector. However, recent studies have shown that
    negative samples are not necessary. Caron *et al.* [2020](#bib.bib18) introduced
    clustering into contrastive learning, thus eliminating the need for negative samples.
    Chen *et al.* [2021](#bib.bib28) explored stop-gradient operation applied to siamese
    networks without the need for a large number of negative samples. Grill *et al.* [2020](#bib.bib66),
    Caron *et al.* [2021](#bib.bib19) proposed a self-supervised learning model based
    on a teacher-student knowledge distillation framework that achieves state-of-the-art
    performance without any negative samples.
  prefs: []
  type: TYPE_NORMAL
- en: Study in Pathological Image Analysis
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In pathological image analysis, Xie *et al.* [2020](#bib.bib191) employed patches
    from different magnifications as positive samples and patches from different magnifications
    as negative samples and constructed scale-wise triplet loss to perform contrastive
    learning for the nuclei segmentation. Chhipa *et al.* [2022](#bib.bib32) proposed
    Magnification Prior Contrastive Similarity (MPCS) to construct contrastive loss.
    Xu *et al.* [2020](#bib.bib193) proposed a self-supervised Deformation Representation
    Learning (DRL) framework to learn semantic features from unlabeled pathological
    images. They used mutual information to train the network to distinguish original
    histopathological images from those deformed in local structure, while consistent
    global contextual information was maintained using noise contrastive estimation
    (NCE). Wang *et al.* [2021](#bib.bib183) proposed Transpath based on the BYOL
    framework [2020](#bib.bib66). They first collected the current largest histopathological
    image dataset for self-supervised pre-training, which includes about 2.7 million
    images from 32529 WSIs. Then they proposed a hybrid framework combining CNN and
    Transformer to extract both local structural features and global contextual features,
    and proposed a TAE module to further enhance the feature extraction capability.
  prefs: []
  type: TYPE_NORMAL
- en: Hybrid Self-supervised Learning Approach
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Many studies have also presented hybrid self-supervised methods for pathological
    images. Abbet *et al.* [2020](#bib.bib2) proposed a combination of generative
    and contrastive self-supervised representation learning method for pathological
    images. They first applied colorization as a generative auxiliary task. Then,
    they constructed the contrastive loss using spatially neighboring patches as positive
    samples and distant patches as negative samples. Yang *et al.* [2021](#bib.bib200)
    also proposed a self-supervised representation method combining generative and
    contrastive approaches for pathological images. They first proposed a generative-based
    self-supervised task called cross-stain prediction, in which they defined two
    encoders and decoders to predict the E-channel and H-channel, respectively, and
    then they used the encoders trained in the previous task to perform further contrastive
    training.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3.2 Study on Applications of Self-supervised Frameworks
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In addition to studies that aim to propose innovative self-supervised frameworks
    for pathological images, more studies have attempted to apply existing self-supervised
    learning methods to various pathological image analysis tasks. Chen *et al.* [2020](#bib.bib25)
    proposed an end-to-end multimodal fusion framework for histopathological images
    and genomic data for survival prognosis prediction, in which they used contrastive
    predictive coding (CPC) pre-trained self-supervised features for initialization
    of the network model. Ciga *et al.* [2022](#bib.bib36) showed through extensive
    experiments that using self-supervised pre-training methods can yield better features
    to improve performance on several downstream tasks. They found that the success
    of contrastive self-supervised pre-training methods depended heavily on the diversity
    of the unlabeled training set rather than the number of images. On the other hand,
    positive and negative samples that are visually significantly different facilitate
    contrastive self-supervised learning, while positive and negative sample that
    contain only minor differences but are generally similar (e.g., normal patches
    versus patches containing only a small percentage of tumor regions) are not conducive
    to contrastive learning. However, this is uncommon in natural images, so it is
    particularly important to design targeted self-supervised tasks for the characteristics
    of pathological images. Tellez *et al.* [2019](#bib.bib170) used the variational
    autoencoder [2013](#bib.bib87), contrastive learning [2016](#bib.bib112) and BiGAN
    [2016](#bib.bib50) for the compression of gigapixel pathological images and evaluated
    the performance on a synthetic dataset and two public histopathology datasets,
    respectively, achieving promising results. Stacke *et al.* [2021](#bib.bib161)
    investigated how SimCLR [2020](#bib.bib26) could be extended for pathological
    images to learn useful feature representations. They systematically compared the
    differences between ImageNet data and histopathology data and how this affected
    the goals of self-supervised learning, and pointed out the impact that designing
    for different self-supervised goals would have on the results. Chen *et al.* [2022](#bib.bib24)
    comprehensively compared the performance of ImageNet pre-trained features, SimCLR
    pre-trained features, and DINO [2021](#bib.bib19) pre-trained features in weakly
    supervised classification and fully supervised classification tasks for histopathological
    images. They found that the DINO-based knowledge distillation framework could
    better learn effective and interpretable features in pathological images.
  prefs: []
  type: TYPE_NORMAL
- en: Saillard *et al.* [2021](#bib.bib142) and Dehaene *et al.* [2020](#bib.bib45)
    used the MoCo V2 [2020](#bib.bib27) self-supervised learning method to train pathological
    images and the experimental results showed that the results using the self-supervised
    pre-trained features were consistently better than those using features pre-trained
    on ImageNet under the same conditions. Lu *et al.* [2019](#bib.bib104), Zhao *et
    al.* [2020](#bib.bib206), and Li *et al.* [2021](#bib.bib97) used contrastive
    predictive coding (CPC) [2018](#bib.bib174), VAE-GAN [2016](#bib.bib93), and SimCLR
    [2020](#bib.bib26) self-supervised pre-trained features for weakly supervised
    WSI classification, respectively, and achieved the current state-of-the-art performance.
    Koohbanani *et al.* [2021](#bib.bib89) developed a semi-supervised learning framework
    facilitated by self-supervised learning with a multi-task learning approach for
    training, i.e., training with a small amount of labeled data as the main task
    and self-supervised tasks as auxiliary tasks. In their study, they also compared
    the effectiveness of various commonly used pathology-agnostic self-supervised
    auxiliary tasks (including rotation, flipping, auto-encoder, real/fake prediction,
    domain prediction, etc.) to facilitate semi-supervised learning. Srinidhi *et
    al.* [2022](#bib.bib160) also attempted to use self-supervised pre-trained features
    to enhance semi-supervised learning. They first proposed the resolution sequence
    prediction (RSP) self-supervised auxiliary task to pre-train the model through
    unlabeled data, and then they fine-tuned the model on the labeled data. After
    that, they used the trained model from the above two steps as the initial weights
    of the model for further semi-supervised training based on the teacher-student
    consistency framework.
  prefs: []
  type: TYPE_NORMAL
- en: In addition, self-supervised learning has been used for a variety of other pathological
    tasks, such as pathological image retrieval (Shi *et al.* [2018](#bib.bib149),
    Yang *et al.* [2020](#bib.bib201)), active learning (Zheng *et al.* [2019](#bib.bib207)),
    and molecular signature prediction (Ding *et al.* [2020](#bib.bib48), Fu *et al.* [2020](#bib.bib58),
    Kather *et al.* [2020](#bib.bib83)), etc.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 5: List of literatures in the self-supervised learning section.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Approach | Disease Type | Staining | Dataset | Dataset Scale
    | Dataset Link | Self-supervised Method | Downstream Task | Downstream Performance
    |'
  prefs: []
  type: TYPE_TB
- en: '| Sahasrabudhe et al. ([2020](#bib.bib141)) | Predictive | - | H&E | MoNuSeg
    database | 1,125,737 tiles | Kumar et al. ([2017](#bib.bib91)) | Identification
    of the magnification levels for tiles | Nuclei segmentation | AJI: 0.5354, AHD:
    7.7502, Dice: 0.7477 |'
  prefs: []
  type: TYPE_TB
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Predictive | Breast Cancer, Colorectal
    Cancer | H&E | BreastPathQ dataset | 2579 patches | Martel et al. ([2019](#bib.bib111))
    | Predicting the resolution sequences | Detection of tumor metastasis | TC: 0.876
    (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Camelyon16 dataset | 399 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | Classification of tissue types | AUC: 0.855 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Kather multiclass dataset | 100K patches | Kather *et al.* ([2019](#bib.bib84))
    |  | Quantification of tumor cellularity | Accuracy: 0.982 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Predictive | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Magnification prediction and solving magnification puzzles | Detection of tumor
    regions | AUC: 0.817 (1% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  prefs: []
  type: TYPE_TB
- en: '| Muhammad et al. ([2019](#bib.bib114)) | Generative | Cholangi-ocarcinoma
    | H&E | Intrahepatic cholangiocarcinoma (ICC) dataset | 246 patients | Inhouse
    | Deep clustering convolutional autoencoder | Subtyping of cholangiocarcinoma
    | CHI: 3863(5 clusters) and 4314 (clutsering weight = 0.2) |'
  prefs: []
  type: TYPE_TB
- en: '| Mahapatra et al. ([2020](#bib.bib108)) | Generative | Breast Cancer | H&E
    | CAMELYON16 dataset | 100, 000 patches | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Using pre-trained networks for semantic guidance | Stain normalization | Average
    AUC: 0.9320 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Breast Cancer |  | CAMELYON17 dataset | 100, 000 patches | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/),
    inhouse |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Quiros et al. ([2019](#bib.bib131)) | Generative | Colorectal Cancer | H&E
    | National Center for Tumor diseases (NCT) dataset | 86 slides | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | Using Generative Adversarial Networks (GANs) to capture key tissue features
    and structure information | Count of cancer, lymphocytes, or stromal cells | FID:
    16.65 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Breast Cancer |  | Netherlands Cancer Institute (NKI) dataset and Vancouver
    General Hospital (VGH) dataset | 576 tissue micro-arrays (TMAs) | Beck et al.
    ([2011](#bib.bib8)) |  |  | FID: 32.05 |'
  prefs: []
  type: TYPE_TB
- en: '| Quiros et al. ([2021](#bib.bib130)) | Generative | Breast Cancer | H&E |
    Netherlands Cancer Institute (NKI, Netherlands) and Vancouver General Hospital
    (VGH, Canada) cohorts | Total of 576 patients | Beck et al. ([2011](#bib.bib8))
    | Presenting an adversarial learning model to extract feature representations
    of cancer tissue | Classifying tissue types and predicting the presence of tumor
    in Whole Slide Images (WSIs) using multiple instance learning (MIL) | AUC: 0.97
    and Accuracy: 0.85; AUC: 0.98 and Accuracy: 0.94 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colon cancer |  | National Center for Tumor diseases (NCT, Germany)
    dataset | 100K tissue tiles | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Lung Cancer |  | TCGA LUAD, LUSC dataset | 1184 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Boyd et al. ([2021](#bib.bib15)) | Generative | Breast Cancer | H&E | CAMELYON17
    dataset | 500 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Visual field expansion | Binary classification of tiles into metastatic and
    non-metastatic classes | Accuracy: 0.8569 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colorectal Cancer |  | CRC benchmark dataset | 100K image tiles | [https://doi.org/10.5281/zenodo.1214456](https://doi.org/10.5281/zenodo.1214456)
    |  | Classification of tiles into the 9 tissue types | Accuracy: 0.8511 |'
  prefs: []
  type: TYPE_TB
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Generative | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Hematoxylin channel prediction auxiliary task | Detection of tumor regions |
    AUC: 0.817 (1% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  prefs: []
  type: TYPE_TB
- en: '| Hou et al. ([2019](#bib.bib75)) | Generative | - | H&E | Self-collected lymphocyte
    classification dataset | 1785 images | Inhouse | Sparse Convolutional Autoencoder
    (CAE) | Nucleus detection | Nucleus Classification: Lymphocyte Classification
    AUC 0.7856 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Nuclear shape and attribute classification dataset | 2000 images
    | Murthy et al. ([2017](#bib.bib115)) |  |  | Nuclear Attribute &Shape AUC 0.8788
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | CRCHistoPhenotypes nucleus detection dataset | 100 images | Sirinukunwattana
    et al. ([2016](#bib.bib155)) |  |  | Nucleus detection: F-measure: 0.8345 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | MICCAI 2015 nucleus segmentation challenge dataset | 763 images
    | https://wiki.cancerimagingarchive.net/ pages/viewpage.action?pageId=20644646
    |  |  | Lymphocyte classification: AUC 0.7856 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | TCGA lung cancer dataset | 0.5 million images | [https://cancergenome.nih.gov/](https://cancergenome.nih.gov/)
    |  |  | Nucleus segmentation: DICE: 0.8362 |'
  prefs: []
  type: TYPE_TB
- en: '| Xie, Chen, Li and Zheng ([2020](#bib.bib191)) | Contrastive | - | H&E | MoNuSeg
    dataset | 44 images | Naylor et al. ([2018](#bib.bib119)) | Scale-wise triplet
    learning and count ranking | Nuclei segmentation | AJI: 0.7063 |'
  prefs: []
  type: TYPE_TB
- en: '| Chhipa et al. ([2022](#bib.bib32)) | Contrastive | Breast Cancer | H&E |
    BreakHis dataset | 7909 images | Spanhol et al. ([2015](#bib.bib157)) | Magnification
    prior contrastive similarity | Classifying histopathological images | Mean Accuracy:
    0.9233 |'
  prefs: []
  type: TYPE_TB
- en: '| Xu et al. ([2020](#bib.bib193)) | Contrastive | Breast Cancer | H&E | MICCAI
    2015 Gland Segmentation Challenge (GLaS) dataset | 165 images | Sirinukunwattana
    et al. ([2017](#bib.bib154)) | Deformation representation learning | Gland segmentation
    | F1-score 0.900, Accuracy 0.8548 (10% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colon Cancer |  | Patch Camelyon (PCam) image classification dataset
    | 327,680 patches | Veeling et al. ([2018](#bib.bib176)) |  | Semi-supervised
    classification |  |'
  prefs: []
  type: TYPE_TB
- en: '| Wang et al. ([2021](#bib.bib183)) | Contrastive | Liver, Renal, Colorectal,
    Prostatic, Pancreatic, and Cholangio Breast Cancers | H&E | Multiple histopathological
    image datasets including MHIST, NCT-CRC-HE, PatchCamelyon dataset | 2.7 million
    images | [https://github.com/Xiyue-Wang/TransPath](https://github.com/Xiyue-Wang/TransPath)
    | Contrastive learning like BYOL (Bootstrap your own latent: a new approach to
    self-supervised learning) | Histopathological image classification tasks | F1-score:
    0.8993, 0.9582, 0.8983 on MHIST, NCT-CRC-HE, PatchCamelyon dataset |'
  prefs: []
  type: TYPE_TB
- en: '| Abbet et al. ([2020](#bib.bib2)) | Generative + Contrastive | Colorectal
    Cancer | H&E | Clinicopathological dataset | 660 WSIs | Inhouse | Colorization,
    Image reconstrucation and Contrastive learning | Survival analysis | C-Index:
    0.6943 |'
  prefs: []
  type: TYPE_TB
- en: '| Yang et al. ([2021](#bib.bib200)) | Generative + Contrastive | Colorectal
    Cancer | H&E | NCTCRC-HE-100K dataset | 100K images | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | Cross-stain prediction, Contrastive training | Nine-class classification of
    histopathological images | Accuracy of eight-class classification with only 1,000
    labeled data: 0.915 |'
  prefs: []
  type: TYPE_TB
- en: '| Chen, Lu and Mahmood ([2020](#bib.bib25)) | Application | Glioma and Cell
    Carcinoma | H&E | The Cancer Genome Atlas (TCGA) dataset | 1505 images | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Contrastive predictive coding (CPC) | Survival prognosis prediction | C-Index:
    0.826 |'
  prefs: []
  type: TYPE_TB
- en: '| Ciga et al. ([2022](#bib.bib36)) | Application | Multiple Types | H&E | Out
    of the total 57 datasets from various institutions | A large number of images
    | [https://github.com/ozanciga/self-supervised-histopathology](https://github.com/ozanciga/self-supervised-histopathology)
    | Contrastive learning | Classification, Regression, and Segmentation | Multiple
    results |'
  prefs: []
  type: TYPE_TB
- en: '| Tellez et al. ([2019](#bib.bib170)) | Application | Breast Cancer | H&E |
    Camelyon16 dataset | 400 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Variational autoencoder, Contrastive learning and BiGAN | Predicting the presence
    of metastasis | AUC: 0.725 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | TUPAC16 dataset | 492 WSIs | Veta et al. ([2019](#bib.bib178))
    |  | Predicting tumor proliferation speed | Spearman correlation: 0.522 |'
  prefs: []
  type: TYPE_TB
- en: '| Stacke et al. ([2021](#bib.bib161)) | Application | Multiple Types | H&E
    | Camelyon16 dataset | 400 slides | [https://github.com/k-stacke/ssl-pathology](https://github.com/k-stacke/ssl-pathology)
    | Contrastive learning | Binary tumor classification | Multiple results |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | AIDA-LNSK dataset | 96 slides |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Multidata (samples from 60 publicly available datasets) | A large
    number of images |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Chen and Krishnan ([2022](#bib.bib24)) | Application | Colorectal Cancer
    | H&E | CRC-100K dataset | 100K images | Kather et al. ([2016](#bib.bib86)) |
    Contrastive learning | Weakly-supervised cancer subtyping | AUC: 0.886 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Breast Cancer |  | BreastPathQ dataset | 2766 patches | Petrick et al.
    ([2021](#bib.bib126)) |  | Patch-level tissue phenotyping | AUC: 0.987 |'
  prefs: []
  type: TYPE_TB
- en: '| Saillard et al. ([2021](#bib.bib142)) | Application | Colorectal Cancer |
    H&E | TCGA-CRC dataset | 555 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Contrastive learning | Microsatellite instability | AUC: 0.92 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Gastric Cancer |  | TCGA-Gastric dataset | 375 patients |  |  |  |
    AUC: 0.83 |'
  prefs: []
  type: TYPE_TB
- en: '| Dehaene et al. ([2020](#bib.bib45)) | Application | Colorectal Cancer | H&E
    | Camelyon16 dataset | 400 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Contrastive learning | Predicting lymph node metastasis in Breast Cancer | AUC:
    0.987 |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Breast Cancer |  | TCGA-COAD dataset | 461 slides | Guinney et al.
    ([2015](#bib.bib68)) |  | Colorectal Cancer subtyping | AUC: 0.882 (CMS1) and
    AUC: 0.829 (CMS3) |'
  prefs: []
  type: TYPE_TB
- en: '| Lu et al. ([2019](#bib.bib104)) | Application | Breast Cancer | H&E | BACH
    dataset | 400 cases | Aresta et al. ([2019](#bib.bib5)) | Contrastive predictive
    coding (CPC) | classification and localization of clinically relevant histopathological
    classes | Accuracy: 0.95 |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao et al. ([2020](#bib.bib206)) | Application | Colon Adenocarcinoma |
    H&E | The Cancer Genome Atlas (TCGA) dataset | 425 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Variational Auto Encoder and Generative Adversial Network (VAE-GAN) | Predicting
    lymph node metastasis | Accuracy: 0.6761 |'
  prefs: []
  type: TYPE_TB
- en: '| Li, Li and Eliceiri ([2021](#bib.bib97)) | Application | Breast Cancer |
    H&E | Camelyon16 dataset | 400 cases | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Contrastive learning | Detection of lymph node metastases | Accuracy: 0.8992
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Lung Cancer |  | TCGA lung cancer dataset | 1054 cases | [https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga)
    |  | Diagnosis of lung cancer subtypes | Accuracy: 0.9571 |'
  prefs: []
  type: TYPE_TB
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Application | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Magnification prediction, JigMag prediction and Hematoxylin channel prediction
    | Detection of tumor regions | AUC: 0.817 (1% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  prefs: []
  type: TYPE_TB
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Application | Breast Cancer, Colorectal
    Cancer | H&E | BreastPathQ dataset | 2579 patches | Martel et al. ([2019](#bib.bib111))
    | Resolution sequence prediction | Detection of tumor metastasis | TC: 0.876 (10%
    labels) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Camelyon16 dataset | 399 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | Classification of tissue types | AUC: 0.855 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Kather multiclass dataset | 100K patches | Kather *et al.* ([2019](#bib.bib84))
    |  | Quantification of tumor cellularity | ACC: 0.982 (10% labels) |'
  prefs: []
  type: TYPE_TB
- en: '| Zheng et al. ([2019](#bib.bib207)) | Application | Colon Cancer | H&E | MICCAI
    2015 Gland Segmentation Challenge (GlaS) dataset | 165 images | Sirinukunwattana
    et al. ([2017](#bib.bib154)) | Variational Auto Encoder (VAE) | Active learning
    in biomedical image segmentation | F1 score: 0.909, 0.9252 (30% labeled) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | Fungus dataset | 84 images | Zhang et al. ([2017](#bib.bib205))
    |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 4 Discussion and Future Trends
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 4.1 For Weakly Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The two main goals of WSI analysis using the weakly supervised learning paradigm
    are global slide classification, which aims to accurately predict the labels of
    each WSI, and positive patch localization, which aims to accurately predict the
    labels of each positive patch in the positive bags. Among above two tasks, the
    former can be used for rapid automatic diagnosis of clinical pathology slides,
    such as early clinical screening, and the latter can be used for precise localization
    of tumor cells, as well as interpretable analysis of clinical diagnosis by deep
    learning networks. Based on the diagnostic results obtained from the whole slides,
    pathologists are often more interested in the precise location of tumor cells,
    the cell morphology and other microstructures for further analysis and corroboration.
    On the other hand, pathologists also expect new knowledge from the diagnosis of
    the deep neural networks, such as discovering new pathological patterns and structures,
    etc. A few current algorithms can perform the task of global slide classification
    well, but the task of positive patch localization is another challenge for most
    algorithms. A primary reason is that the loss functions of most bag-based deep
    MIL algorithms are defined only at the bag-level, and although mechanisms such
    as attention (Ilse *et al.* [2018](#bib.bib77)) can be used to measure the contribution
    of each instance to the bag-level classification, the network does not have enough
    motivation to classify all instances accurately (Shi *et al.* [2020](#bib.bib151),
    Qu *et al.* [2022](#bib.bib129)). On the other hand, instance-based methods and
    hybrid methods, although defining instance-level classifiers, usually face a high
    risk of errors in pseudo-labeling or key instance selection. Therefore, it is
    a new challenge for the weakly supervised learning paradigm to further improve
    the ability to classify instances while obtaining a better slide-level diagnosis.
  prefs: []
  type: TYPE_NORMAL
- en: Further, with the emergence of the methods of the weakly supervised segmentation
    in the natural image processing field (Ru *et al.* [2022](#bib.bib140), Xu *et
    al.* [2022](#bib.bib195), Pan *et al.* [2022](#bib.bib122), Lee *et al.* [2021](#bib.bib95),
    Chen *et al.* [2022](#bib.bib29)), a new challenging direction for WSI analysis
    is to perform pixel-level semantic segmentation of the entire WSI based on weak
    or sparse labels. The task of the positive patch localization, which described
    in the previous section is still based on the classification of patches, and it
    is a more challenging task to further obtain pixel-level segmentation results
    based on the weak labels. A few current studies (Xu *et al.* [2019](#bib.bib192),
    Qu *et al.* [2020](#bib.bib128), Belharbi *et al.* [2021](#bib.bib11), Lerousseau
    *et al.* [2020](#bib.bib96)) have made attempts in this new direction, but they
    still face many problems such as lack of details and precision on the segmentation
    results. Overall, for the weakly supervised learning paradigm, how to obtain the
    most detailed segmentation results as possible with weak labels is another promising
    study direction.
  prefs: []
  type: TYPE_NORMAL
- en: Another urgent need is the publicly available WSI datasets with fine-grained
    annotations at the patch level. As we all know, the scarcity of the publicly available
    pathological image datasets is an important factor hindering the development of
    the field. In recent years, we are grateful for the support of large public pathology
    datasets such as TCGA ([2019](#bib.bib168)), but public pathology datasets with
    fine-grained annotations are still in short supply for deeper research. To our
    knowledge, the large public WSI dataset with detailed annotation at the patch
    level is merely CAMELYON (Bejnordi *et al.* [2017a](#bib.bib9)). We should encourage
    an individual or organization to provide more public WSI datasets with detailed
    patch-level annotations to promote the development of this study field.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 For Semi-Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For semi-supervised learning paradigm, a new study direction is the combination
    with active learning, the purpose of which is to use the most effective labeled
    data to obtain the highest performance. Active learning aims to find the most
    valuable samples in the unlabeled dataset to be annotated through iterative interactions
    with experts, which allows to further exploit the effects of semi-supervised learning.
    There are already a lot of studies on pathological image analysis with the help
    of active learning (Zheng *et al.* [2019](#bib.bib207), Yang *et al.* [2017](#bib.bib199))
    or combination with semi-supervised learning and active learning (Su *et al.* [2015](#bib.bib163),
    Parag *et al.* [2014](#bib.bib123)).
  prefs: []
  type: TYPE_NORMAL
- en: Another challenge is the effect that noisy data and domain variation have on
    the performance of semi-supervised learning algorithms. In the field of computational
    pathology, noisy annotations are very common, because the instance features of
    pathological images are very complex and variable, and their sizes are so huge
    that doctors are likely to suffer from missing and mislabeling during annotation.
    When performing multicenter validation, significant staining variation between
    the slides from different centers is also very common as there is no uniform standard
    for staining pathological images among different centers. Both the noisy labels
    and the domain variation are powerful factors that affect the performance of semi-supervised
    learning in real-world scenarios. Recent studies (Koohbanani *et al.* [2021](#bib.bib89),
    Cheng *et al.* [2020](#bib.bib31), Shi *et al.* [2020](#bib.bib150), Foucart *et
    al.* [2019](#bib.bib57), Marini *et al.* [2021](#bib.bib109)) have made efforts
    on these two problems, and more studies in this field are expected.
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 For Self-Supervised Learning Paradigm
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: For self-supervised learning paradigm, although current relevant studies in
    the field of natural images are developing rapidly, the direct applications of
    these methods to pathological images will be hindered by the strong domain discrepancy
    (Ciga *et al.* [2022](#bib.bib36), Koohbanani *et al.* [2021](#bib.bib89)). Therefore,
    how to design more effective self-supervised auxiliary tasks for pathological
    images is a promising direction.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, self-supervised learning has been promoting the development
    of weakly supervised learning and semi-supervised learning in pathological image
    analysis. As we all know, it is difficult for a network to learn effective feature
    representations with very limited annotations. In contrast, self-supervised learning
    is very suitable for learning effective feature representations from a lot of
    unlabeled data. Therefore, it will be a popular way to combine the features extracted
    by self-supervised pre-training with the weakly supervised or semi-supervised
    downstream tasks in the future. On the one hand, the efficient feature representations
    obtained from self-supervised pre-training will greatly improve the efficiency
    of weakly supervised learning and semi-supervised learning, and on the other hand,
    weakly supervised learning or semi-supervised learning will fully release the
    new potential of self-supervised learning in the field of computational pathology.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Limitations
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This review also has several limitations. First, due to space limitations, this
    review does not include more clinical studies. We focus more on top technical
    conferences and journals and do not include more excellent papers published in
    clinical journals. For more systematic reviews of clinical studies, see (Cifci
    *et al.* [2022](#bib.bib35)) and (Kleppe *et al.* [2021](#bib.bib88)) for details.
    In addition, since there are so many technical studies on artificial intelligence
    applied to computational pathology, it is difficult to summarize them all, and
    due to space limitations, we have tried to include as many recent articles as
    possible, while some of them have not been included.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this review, we provide a systematic summary of recent studies on weakly
    supervised learning, semi-supervised learning, and self-supervised learning in
    the field of computational pathology from the theoretical and methodological perspectives.
    On this basis, we also present targeted solutions to some current difficulties
    and shortcomings in this field, and illustrate its future trends. Through a survey
    of over 130 papers, we find that the field of computational pathology is marching
    at high speed into a new era, which is automatic diagnosis and analysis with fewer
    annotation needs, wider application scope, and higher prediction accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was supported by National Natural Science Foundation of China under
    Grant 82072021.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abbet et al. (2020) Abbet, C., Zlobec, I., Bozorgtabar, B. and Thiran, J.-P.
    (2020). Divide-and-rule: self-supervised learning for survival analysis in colorectal
    cancer, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 480–489.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Anand et al. (2021) Anand, D., Yashashwi, K., Kumar, N., Rane, S., Gann, P. H.
    and Sethi, A. (2021). Weakly supervised learning on unannotated h&e-stained slides
    predicts braf mutation in thyroid cancer with high accuracy, The Journal of Pathology  255(3): 232–242.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Araújo et al. (2017) Araújo, T., Aresta, G., Castro, E., Rouco, J., Aguiar,
    P., Eloy, C., Polónia, A. and Campilho, A. (2017). Classification of breast cancer
    histology images using convolutional neural networks, PloS One  12(6): e0177544.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aresta et al. (2019) Aresta, G., Araújo, T., Kwok, S., Chennamsetty, S. S.,
    Safwan, M., Alex, V., Marami, B., Prastawa, M., Chan, M., Donovan, M. et al. (2019).
    Bach: Grand challenge on breast cancer histology images, Medical Image Analysis  56: 122–139.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bao et al. (2021) Bao, H., Dong, L. and Wei, F. (2021). Beit: Bert pre-training
    of image transformers, arXiv preprint arXiv:2106.08254 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Basavanhally et al. (2013) Basavanhally, A., Ganesan, S., Feldman, M., Shih,
    N., Mies, C., Tomaszewski, J. and Madabhushi, A. (2013). Multi-field-of-view framework
    for distinguishing tumor grade in er+ breast cancer from entire histopathology
    slides, IEEE Transactions on Biomedical Engineering  60(8): 2089–2099.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Beck et al. (2011) Beck, A. H., Sangoi, A. R., Leung, S., Marinelli, R. J.,
    Nielsen, T. O., Van De Vijver, M. J., West, R. B., Van De Rijn, M. and Koller,
    D. (2011). Systematic analysis of breast cancer morphology uncovers stromal features
    associated with survival, Science Translational Medicine  3(108): 108ra113–108ra113.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bejnordi et al. (2017a) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q. F.,
    Balkenhol, M. et al. (2017a). Diagnostic assessment of deep learning algorithms
    for detection of lymph node metastases in women with breast cancer, Jama  318(22): 2199–2210.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bejnordi et al. (2017b) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q. F.,
    Balkenhol, M. et al. (2017b). Diagnostic assessment of deep learning algorithms
    for detection of lymph node metastases in women with breast cancer, JAMA  318(22): 2199–2210.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belharbi et al. (2021) Belharbi, S., Rony, J., Dolz, J., Ayed, I. B., McCaffrey,
    L. and Granger, E. (2021). Deep interpretable classification and weakly-supervised
    segmentation of histology images via max-min uncertainty, IEEE Transactions on
    Medical Imaging .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Belkin et al. (2005) Belkin, M., Niyogi, P. and Sindhwani, V. (2005). On manifold
    regularization, International Workshop on Artificial Intelligence and Statistics,
    PMLR, pp. 17–24.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Belkin et al. (2006) Belkin, M., Niyogi, P. and Sindhwani, V. (2006). Manifold
    regularization: A geometric framework for learning from labeled and unlabeled
    examples., Journal of Machine Learning Research  7(11).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blum and Mitchell (1998) Blum, A. and Mitchell, T. (1998). Combining labeled
    and unlabeled data with co-training, Proceedings of the Eleventh Annual Conference
    on Computational Learning Theory, pp. 92–100.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boyd et al. (2021) Boyd, J., Liashuha, M., Deutsch, E., Paragios, N., Christodoulidis,
    S. and Vakalopoulou, M. (2021). Self-supervised representation learning using
    visual field expansion on digital pathology, Proceedings of the IEEE/CVF International
    Conference on Computer Vision, pp. 639–647.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bulten et al. (2020) Bulten, W., Pinckaers, H., van Boven, H., Vink, R., de Bel,
    T., van Ginneken, B., van der Laak, J., Hulsbergen-van de Kaa, C. and Litjens,
    G. (2020). Automated deep-learning system for gleason grading of prostate cancer
    using biopsies: a diagnostic study, The Lancet Oncology  21(2): 233–241.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Campanella et al. (2019) Campanella, G., Hanna, M. G., Geneslaw, L., Miraflor,
    A., Werneck Krauss Silva, V., Busam, K. J., Brogi, E., Reuter, V. E., Klimstra,
    D. S. and Fuchs, T. J. (2019). Clinical-grade computational pathology using weakly
    supervised deep learning on whole slide images, Nature Medicine  25(8): 1301–1309.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caron et al. (2020) Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski,
    P. and Joulin, A. (2020). Unsupervised learning of visual features by contrasting
    cluster assignments, Advances in Neural Information Processing Systems  33: 9912–9924.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caron et al. (2021) Caron, M., Touvron, H., Misra, I., Jégou, H., Mairal, J.,
    Bojanowski, P. and Joulin, A. (2021). Emerging properties in self-supervised vision
    transformers, Proceedings of the IEEE/CVF International Conference on Computer
    Vision, pp. 9650–9660.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chang and Lin (2011) Chang, C.-C. and Lin, C.-J. (2011). Libsvm: a library
    for support vector machines, ACM Transactions on Intelligent Systems and Technology
    (TIST)  2(3): 1–27.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chaudhary et al. (2018) Chaudhary, K., Poirion, O. B., Lu, L. and Garmire, L. X.
    (2018). Deep learning–based multi-omics integration robustly predicts survival
    in liver cancer, Clinical Cancer Research  24(6): 1248–1259.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2017) Chen, H., Qi, X., Yu, L., Dou, Q., Qin, J. and Heng, P.-A.
    (2017). Dcan: Deep contour-aware networks for object instance segmentation from
    histology images, Medical Image Analysis  36: 135–146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019) Chen, L., Bentley, P., Mori, K., Misawa, K., Fujiwara, M.
    and Rueckert, D. (2019). Self-supervised learning for medical image analysis using
    image context restoration, Medical Image Analysis  58: 101539.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and Krishnan (2022) Chen, R. J. and Krishnan, R. G. (2022). Self-supervised
    vision transformers learn visual concepts in histopathology, arXiv preprint arXiv:2203.00585
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen, Lu and Mahmood (2020) Chen, R. J., Lu, N. I. and Mahmood, F. (2020).
    Pathomic fusion: an integrated framework for fusing histopathology and genomic
    features for cancer diagnosis and prognosis, IEEE Transactions on Medical Imaging
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen, Kornblith, Norouzi and Hinton (2020) Chen, T., Kornblith, S., Norouzi,
    M. and Hinton, G. (2020). A simple framework for contrastive learning of visual
    representations, International Conference on Machine Learning, PMLR, pp. 1597–1607.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen, Fan, Girshick and He (2020) Chen, X., Fan, H., Girshick, R. and He, K.
    (2020). Improved baselines with momentum contrastive learning, arXiv preprint
    arXiv:2003.04297 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen and He (2021) Chen, X. and He, K. (2021). Exploring simple siamese representation
    learning, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 15750–15758.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2022) Chen, Z., Wang, T., Wu, X., Hua, X.-S., Zhang, H. and Sun,
    Q. (2022). Class re-activation maps for weakly-supervised semantic segmentation,
    arXiv preprint arXiv:2203.00962 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2021) Chen, Z., Zhang, J., Che, S., Huang, J., Han, X. and Yuan,
    Y. (2021). Diagnose like a pathologist: Weakly-supervised pathologist-tree network
    for slide-level immunohistochemical scoring, 35th AAAI Conference on Artificial
    Intelligence (AAAI-21), AAAI Press, pp. 47–54.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2020) Cheng, H.-T., Yeh, C.-F., Kuo, P.-C., Wei, A., Liu, K.-C.,
    Ko, M.-C., Chao, K.-H., Peng, Y.-C. and Liu, T.-L. (2020). Self-similarity student
    for partial label histopathology image segmentation, European Conference on Computer
    Vision, Springer, pp. 117–132.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chhipa et al. (2022) Chhipa, P. C., Upadhyay, R., Pihlgren, G. G., Saini, R.,
    Uchida, S. and Liwicki, M. (2022). Magnification prior: A self-supervised method
    for learning representations on breast cancer histopathological images, arXiv
    preprint arXiv:2203.07707 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chikontwe et al. (2020) Chikontwe, P., Kim, M., Nam, S. J., Go, H. and Park,
    S. H. (2020). Multiple instance learning with center embeddings for histopathology
    classification, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 519–528.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chong et al. (2020) Chong, Y., Ding, Y., Yan, Q. and Pan, S. (2020). Graph-based
    semi-supervised learning: A review, Neurocomputing  408: 216–230.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cifci et al. (2022) Cifci, D., Foersch, S. and Kather, J. N. (2022). Artificial
    intelligence to identify genetic alterations in conventional histopathology, The
    Journal of Pathology .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ciga et al. (2022) Ciga, O., Xu, T. and Martel, A. L. (2022). Self supervised
    contrastive learning for digital histopathology, Machine Learning with Applications  7: 100198.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark et al. (2013) Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J.,
    Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M. et al. (2013). The
    cancer imaging archive (tcia): maintaining and operating a public information
    repository, Journal of Digital Imaging  26(6): 1045–1057.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cong et al. (2021) Cong, C., Liu, S., Ieva, A. D., Pagnucco, M., Berkovsky,
    S. and Song, Y. (2021). Semi-supervised adversarial learning for stain normalisation
    in histopathology images, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 581–591.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coudray et al. (2018) Coudray, N., Ocampo, P. S., Sakellaropoulos, T., Narula,
    N., Snuderl, M., Fenyö, D., Moreira, A. L., Razavian, N. and Tsirigos, A. (2018).
    Classification and mutation prediction from non–small cell lung cancer histopathology
    images using deep learning, Nature Medicine  24(10): 1559–1567.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cruz-Roa et al. (2014) Cruz-Roa, A., Basavanhally, A., González, F., Gilmore,
    H., Feldman, M., Ganesan, S., Shih, N., Tomaszewski, J. and Madabhushi, A. (2014).
    Automatic detection of invasive ductal carcinoma in whole slide images with convolutional
    neural networks, Medical Imaging 2014: Digital Pathology, Vol. 9041, SPIE, p. 904103.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cruz-Roa et al. (2017) Cruz-Roa, A., Gilmore, H., Basavanhally, A., Feldman,
    M., Ganesan, S., Shih, N. N., Tomaszewski, J., González, F. A. and Madabhushi,
    A. (2017). Accurate and reproducible invasive breast cancer detection in whole-slide
    images: a deep learning approach for quantifying tumor extent, Scientific Reports  7(1): 1–14.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dai et al. (2017) Dai, Z., Yang, Z., Yang, F., Cohen, W. W. and Salakhutdinov,
    R. R. (2017). Good semi-supervised learning that requires a bad gan, Advances
    in Neural Information Processing Systems  30.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dara et al. (2002) Dara, R., Kremer, S. C. and Stacey, D. A. (2002). Clustering
    unlabeled data with soms improves classification of labeled real-world data, Proceedings
    of the 2002 International Joint Conference on Neural Networks. IJCNN’02 (Cat.
    No. 02CH37290), Vol. 3, IEEE, pp. 2237–2242.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Decencière et al. (2014) Decencière, E., Zhang, X., Cazuguel, G., Lay, B.,
    Cochener, B., Trone, C., Gain, P., Ordonez, R., Massin, P., Erginay, A. et al.
    (2014). Feedback on a publicly distributed image database: the messidor database,
    Image Analysis & Stereology  33(3): 231–234.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dehaene et al. (2020) Dehaene, O., Camara, A., Moindrot, O., de Lavergne, A.
    and Courtiol, P. (2020). Self-supervision closes the gap between weak and strong
    supervision in histology, arXiv preprint arXiv:2012.03583 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Demiriz et al. (1999) Demiriz, A., Bennett, K. P. and Embrechts, M. J. (1999).
    Semi-supervised clustering using genetic algorithms, Artificial Neural Networks
    in Engineering (ANNIE-99) pp. 809–814.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Deng et al. (2009) Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K. and Fei-Fei,
    L. (2009). Imagenet: A large-scale hierarchical image database, 2009 IEEE Conference
    on Computer Vision and Pattern Recognition, Ieee, pp. 248–255.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ding et al. (2020) Ding, K., Liu, Q., Lee, E., Zhou, M., Lu, A. and Zhang, S.
    (2020). Feature-enhanced graph networks for genetic mutational prediction using
    histopathological images in colon cancer, International Conference on Medical
    Image Computing and Computer-Assisted Intervention, Springer, pp. 294–304.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doersch et al. (2015) Doersch, C., Gupta, A. and Efros, A. A. (2015). Unsupervised
    visual representation learning by context prediction, Proceedings of the IEEE
    International Conference on Computer Vision, pp. 1422–1430.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Donahue et al. (2016) Donahue, J., Krähenbühl, P. and Darrell, T. (2016). Adversarial
    feature learning, arXiv preprint arXiv:1605.09782 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong et al. (2021) Dong, X., Bao, J., Zhang, T., Chen, D., Zhang, W., Yuan,
    L., Chen, D., Wen, F. and Yu, N. (2021). Peco: Perceptual codebook for bert pre-training
    of vision transformers, arXiv preprint arXiv:2111.12710 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Doyle et al. (2007) Doyle, S., Hwang, M., Shah, K., Madabhushi, A., Feldman,
    M. and Tomaszeweski, J. (2007). Automated grading of prostate cancer using architectural
    and textural image features, 2007 4th IEEE International Symposium on Biomedical
    Imaging: From Nano to Macro, IEEE, pp. 1284–1287.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doyle et al. (2006) Doyle, S., Rodriguez, C., Madabhushi, A., Tomaszeweski,
    J. and Feldman, M. (2006). Detecting prostatic adenocarcinoma from digitized histology
    using a multi-scale hierarchical classification approach, 2006 International Conference
    of the IEEE Engineering in Medicine and Biology Society, IEEE, pp. 4759–4762.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ehteshami Bejnordi et al. (2018) Ehteshami Bejnordi, B., Mullooly, M., Pfeiffer,
    R. M., Fan, S., Vacek, P. M., Weaver, D. L., Herschorn, S., Brinton, L. A., van
    Ginneken, B., Karssemeijer, N. et al. (2018). Using deep convolutional neural
    networks to identify and classify tumor-associated stroma in diagnostic breast
    biopsies, Modern Pathology  31(10): 1502–1512.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Erhan et al. (2010) Erhan, D., Courville, A., Bengio, Y. and Vincent, P. (2010).
    Why does unsupervised pre-training help deep learning?, Proceedings of the Thirteenth
    International Conference on Artificial Intelligence and Statistics, JMLR Workshop
    and Conference Proceedings, pp. 201–208.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng and Zhou (2017) Feng, J. and Zhou, Z.-H. (2017). Deep miml network, Proceedings
    of the AAAI Conference on Artificial Intelligence, Vol. 31.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Foucart et al. (2019) Foucart, A., Debeir, O. and Decaestecker, C. (2019).
    Snow: Semi-supervised, noisy and/or weak data for deep learning in digital pathology,
    2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE,
    pp. 1869–1872.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fu et al. (2020) Fu, Y., Jung, A. W., Torne, R. V., Gonzalez, S., Vöhringer,
    H., Shmatko, A., Yates, L. R., Jimenez-Linan, M., Moore, L. and Gerstung, M. (2020).
    Pan-cancer computational histopathology reveals mutations, tumor composition and
    prognosis, Nature Cancer  1(8): 800–810.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gelasca et al. (2008) Gelasca, E. D., Byun, J., Obara, B. and Manjunath, B.
    (2008). Evaluation and benchmark for biological image segmentation, 2008 15th
    IEEE International Conference on Image Processing, IEEE, pp. 1816–1819.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gertych et al. (2015) Gertych, A., Ing, N., Ma, Z., Fuchs, T. J., Salman, S.,
    Mohanty, S., Bhele, S., Velásquez-Vacca, A., Amin, M. B. and Knudsen, B. S. (2015).
    Machine learning approaches to analyze histological images of tissues from radical
    prostatectomies, Computerized Medical Imaging and Graphics  46: 197–208.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gidaris et al. (2018) Gidaris, S., Singh, P. and Komodakis, N. (2018). Unsupervised
    representation learning by predicting image rotations, arXiv preprint arXiv:1803.07728
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goldberg et al. (2009) Goldberg, A., Zhu, X., Singh, A., Xu, Z. and Nowak, R.
    (2009). Multi-manifold semi-supervised learning, Artificial Intelligence and Statistics,
    PMLR, pp. 169–176.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Goodfellow (2016) Goodfellow, I. (2016). Nips 2016 tutorial: Generative adversarial
    networks, arXiv preprint arXiv:1701.00160 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2016) Goodfellow, I., Bengio, Y., Courville, A. and Bengio,
    Y. (2016). Deep learning, volume 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. (2014). Generative adversarial
    nets, Advances in Neural Information Processing Systems  27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grill et al. (2020) Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond,
    P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M.
    et al. (2020). Bootstrap your own latent-a new approach to self-supervised learning,
    Advances in Neural Information Processing Systems  33: 21271–21284.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gu et al. (2018) Gu, F., Burlutskiy, N., Andersson, M. and Wilén, L. K. (2018).
    Multi-resolution networks for semantic segmentation in whole slide images, Computational
    Pathology and Ophthalmic Medical Image Analysis, Springer, pp. 11–18.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Guinney et al. (2015) Guinney, J., Dienstmann, R., Wang, X., De Reynies, A.,
    Schlicker, A., Soneson, C., Marisa, L., Roepman, P., Nyamundanda, G., Angelino,
    P. et al. (2015). The consensus molecular subtypes of colorectal cancer, Nature
    Medicine  21(11): 1350–1356.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gurcan et al. (2009) Gurcan, M. N., Boucheron, L. E., Can, A., Madabhushi,
    A., Rajpoot, N. M. and Yener, B. (2009). Histopathological image analysis: A review,
    IEEE Reviews in Biomedical Engineering  2: 147–171.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haeusser et al. (2017) Haeusser, P., Mordvintsev, A. and Cremers, D. (2017).
    Learning by association–a versatile semi-supervised training method for neural
    networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pp. 89–98.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Halicek et al. (2019) Halicek, M., Shahedi, M., Little, J. V., Chen, A. Y.,
    Myers, L. L., Sumer, B. D. and Fei, B. (2019). Head and neck cancer detection
    in digitized whole-slide histology using convolutional neural networks, Scientific
    Reports  9(1): 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hashimoto et al. (2020) Hashimoto, N., Fukushima, D., Koga, R., Takagi, Y.,
    Ko, K., Kohno, K., Nakaguro, M., Nakamura, S., Hontani, H. and Takeuchi, I. (2020).
    Multi-scale domain-adversarial multiple-instance cnn for cancer subtype classification
    with unannotated histopathological images, Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 3852–3861.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2021) He, K., Chen, X., Xie, S., Li, Y., Dollár, P. and Girshick,
    R. (2021). Masked autoencoders are scalable vision learners, arXiv preprint arXiv:2111.06377
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2020) He, K., Fan, H., Wu, Y., Xie, S. and Girshick, R. (2020). Momentum
    contrast for unsupervised visual representation learning, Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 9729–9738.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hou et al. (2019) Hou, L., Nguyen, V., Kanevsky, A. B., Samaras, D., Kurc, T. M.,
    Zhao, T., Gupta, R. R., Gao, Y., Chen, W., Foran, D. et al. (2019). Sparse autoencoder
    for unsupervised nucleus detection and representation in histopathology images,
    Pattern Recognition  86: 188–200.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hou et al. (2016) Hou, L., Samaras, D., Kurc, T. M., Gao, Y., Davis, J. E. and Saltz,
    J. H. (2016). Patch-based convolutional neural network for whole slide tissue
    image classification, Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pp. 2424–2433.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ilse et al. (2018) Ilse, M., Tomczak, J. and Welling, M. (2018). Attention-based
    deep multiple instance learning, International Conference on Machine Learning,
    PMLR, pp. 2127–2136.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jafari-Khouzani and Soltanian-Zadeh (2003) Jafari-Khouzani, K. and Soltanian-Zadeh,
    H. (2003). Multiwavelet grading of pathological images of prostate, IEEE Transactions
    on Biomedical Engineering  50(6): 697–704.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaiswal et al. (2019) Jaiswal, A. K., Panshin, I., Shulkin, D., Aneja, N. and Abramov,
    S. (2019). Semi-supervised learning for cancer detection of lymph node metastases,
    arXiv preprint arXiv:1906.09587 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kandemir et al. (2014) Kandemir, M., Zhang, C. and Hamprecht, F. A. (2014).
    Empowering multiple instance histopathology cancer diagnosis by cell graphs, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 228–235.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kandoth et al. (2013) Kandoth, C., McLellan, M. D., Vandin, F., Ye, K., Niu,
    B., Lu, C., Xie, M., Zhang, Q., McMichael, J. F., Wyczalkowski, M. A. et al. (2013).
    Mutational landscape and significance across 12 major cancer types, Nature  502(7471): 333–339.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kapil et al. (2018) Kapil, A., Meier, A., Zuraw, A., Steele, K. E., Rebelatto,
    M. C., Schmidt, G. and Brieu, N. (2018). Deep semi supervised generative learning
    for automated tumor proportion scoring on nsclc tissue needle biopsies, Scientific
    Reports  8(1): 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kather et al. (2020) Kather, J. N., Heij, L. R., Grabsch, H. I., Loeffler, C.,
    Echle, A., Muti, H. S., Krause, J., Niehues, J. M., Sommer, K. A., Bankhead, P.
    et al. (2020). Pan-cancer image-based detection of clinically actionable genetic
    alterations, Nature Cancer  1(8): 789–799.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kather, Krisam, Charoentong, Luedde, Herpel, Weis, Gaiser, Marx, Valous, Ferber
    et al. (2019) Kather, J. N., Krisam, J., Charoentong, P., Luedde, T., Herpel,
    E., Weis, C.-A., Gaiser, T., Marx, A., Valous, N. A., Ferber, D. et al. (2019).
    Predicting survival from colorectal cancer histology slides using deep learning:
    A retrospective multicenter study, PLoS Medicine  16(1): e1002730.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kather, Pearson, Halama, Jäger, Krause, Loosen, Marx, Boor, Tacke, Neumann et al.
    (2019) Kather, J. N., Pearson, A. T., Halama, N., Jäger, D., Krause, J., Loosen,
    S. H., Marx, A., Boor, P., Tacke, F., Neumann, U. P. et al. (2019). Deep learning
    can predict microsatellite instability directly from histology in gastrointestinal
    cancer, Nature Medicine  25(7): 1054–1056.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kather et al. (2016) Kather, J. N., Weis, C.-A., Bianconi, F., Melchers, S. M.,
    Schad, L. R., Gaiser, T., Marx, A. and Zöllner, F. G. (2016). Multi-class texture
    analysis in colorectal cancer histology, Scientific Reports  6(1): 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma and Welling (2013) Kingma, D. P. and Welling, M. (2013). Auto-encoding
    variational bayes, arXiv preprint arXiv:1312.6114 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kleppe et al. (2021) Kleppe, A., Skrede, O.-J., De Raedt, S., Liestøl, K., Kerr,
    D. J. and Danielsen, H. E. (2021). Designing deep learning studies in cancer diagnostics,
    Nature Reviews Cancer  21(3): 199–211.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Koohbanani et al. (2021) Koohbanani, N. A., Unnikrishnan, B., Khurram, S. A.,
    Krishnaswamy, P. and Rajpoot, N. (2021). Self-path: Self-supervision for classification
    of pathology images with limited annotations, IEEE Transactions on Medical Imaging  40(10): 2845–2856.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kraus et al. (2016) Kraus, O. Z., Ba, J. L. and Frey, B. J. (2016). Classifying
    and segmenting microscopy images with deep multiple instance learning, Bioinformatics  32(12): i52–i59.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumar et al. (2017) Kumar, N., Verma, R., Sharma, S., Bhargava, S., Vahadane,
    A. and Sethi, A. (2017). A dataset and a technique for generalized nuclear segmentation
    for computational pathology, IEEE Transactions on Medical Imaging  36(7): 1550–1560.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Laine and Aila (2016) Laine, S. and Aila, T. (2016). Temporal ensembling for
    semi-supervised learning, arXiv preprint arXiv:1610.02242 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Larsen et al. (2016) Larsen, A. B. L., Sønderby, S. K., Larochelle, H. and Winther,
    O. (2016). Autoencoding beyond pixels using a learned similarity metric, International
    Conference on Machine Learning, PMLR, pp. 1558–1566.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2013) Lee, D.-H. et al. (2013). Pseudo-label: The simple and efficient
    semi-supervised learning method for deep neural networks, Workshop on Challenges
    in Representation Learning, ICML, Vol. 3, p. 896.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2021) Lee, J., Kim, E. and Yoon, S. (2021). Anti-adversarially manipulated
    attributions for weakly and semi-supervised semantic segmentation, Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4071–4080.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lerousseau et al. (2020) Lerousseau, M., Vakalopoulou, M., Classe, M., Adam,
    J., Battistella, E., Carré, A., Estienne, T., Henry, T., Deutsch, E. and Paragios,
    N. (2020). Weakly supervised multiple instance learning histopathological tumor
    segmentation, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 470–479.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li, Li and Eliceiri (2021) Li, B., Li, Y. and Eliceiri, K. W. (2021). Dual-stream
    multiple instance learning network for whole slide image classification with self-supervised
    contrastive learning, Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, pp. 14318–14328.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li, Yang, Wei, He, Chen, Zheng and Bu (2021) Li, F., Yang, Y., Wei, Y., He,
    P., Chen, J., Zheng, Z. and Bu, H. (2021). Deep learning-based predictive biomarker
    of pathological complete response to neoadjuvant chemotherapy from histological
    images in breast cancer, Journal of Translational Medicine  19(1): 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li, Yang, Zhao and Yao (2021) Li, H., Yang, F., Zhao and Yao, J. (2021). Dt-mil:
    Deformable transformer for multi-instance learning on histopathological image,
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer, pp. 206–216.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2018) Li, J., Speier, W., Ho, K. C., Sarma, K. V., Gertych, A., Knudsen,
    B. S. and Arnold, C. W. (2018). An em-based semi-supervised deep learning approach
    for semantic segmentation of histopathological images from radical prostatectomies,
    Computerized Medical Imaging and Graphics  69: 125–133.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020) Liu, S., Shah, Z., Sav, A., Russo, C., Berkovsky, S., Qian,
    Y., Coiera, E. and Di Ieva, A. (2020). Isocitrate dehydrogenase (idh) status prediction
    in histopathology images of gliomas using deep learning, Scientific Reports  10(1): 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2021) Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang, J.
    and Tang, J. (2021). Self-supervised learning: Generative or contrastive, IEEE
    Transactions on Knowledge and Data Engineering .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ljosa et al. (2012) Ljosa, V., Sokolnicki, K. L. and Carpenter, A. E. (2012).
    Annotated high-throughput microscopy image sets for validation, Nature methods  9(7): 637–637.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2019) Lu, M. Y., Chen, R. J., Wang, J., Dillon, D. and Mahmood, F.
    (2019). Semi-supervised histology classification using deep multiple instance
    learning and contrastive predictive coding, arXiv preprint arXiv:1910.10825 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu et al. (2021) Lu, M. Y., Williamson, D. F., Chen, T. Y., Chen, R. J., Barbieri,
    M. and Mahmood, F. (2021). Data-efficient and weakly supervised computational
    pathology on whole-slide images, Nature Biomedical Engineering  5(6): 555–570.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luo et al. (2017) Luo, X., Zang, X., Yang, L., Huang, J., Liang, F., Rodriguez-Canales,
    J., Wistuba, I. I., Gazdar, A., Xie, Y. and Xiao, G. (2017). Comprehensive computational
    pathological image analysis predicts lung cancer prognosis, Journal of Thoracic
    Oncology  12(3): 501–509.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Madabhushi and Lee (2016) Madabhushi, A. and Lee, G. (2016). Image analysis
    and machine learning in digital pathology: Challenges and opportunities, Medical
    Image Analysis  33: 170–175.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahapatra et al. (2020) Mahapatra, D., Bozorgtabar, B., Thiran, J.-P. and Shao,
    L. (2020). Structure preserving stain normalization of histopathology images using
    self supervised semantic guidance, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 309–319.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Marini et al. (2021) Marini, N., Otálora, S., Müller, H. and Atzori, M. (2021).
    Semi-supervised training of deep convolutional neural networks with heterogeneous
    data and few local annotations: An experiment on prostate histopathology image
    classification, Medical Image Analysis  73: 102165.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maron and Lozano-Pérez (1997) Maron, O. and Lozano-Pérez, T. (1997). A framework
    for multiple-instance learning, Advances in Neural Information Processing Systems  10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Martel et al. (2019) Martel, A., Nofech-Mozes, S., Salama, S., Akbar, S. and Peikari,
    M. (2019). Assessment of residual breast cancer cellularity after neoadjuvant
    chemotherapy using digital pathology [data set], The Cancer Imaging Archive .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Melekhov et al. (2016) Melekhov, I., Kannala, J. and Rahtu, E. (2016). Siamese
    network features for image matching, 2016 23rd International Conference on Pattern
    Recognition (ICPR), IEEE, pp. 378–383.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mercan et al. (2017) Mercan, C., Aksoy, S., Mercan, E., Shapiro, L. G., Weaver,
    D. L. and Elmore, J. G. (2017). Multi-instance multi-label learning for multi-class
    classification of whole slide breast histopathology images, IEEE Transactions
    on Medical Imaging  37(1): 316–325.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Muhammad et al. (2019) Muhammad, H., Sigel, C. S., Campanella, G., Boerner,
    T., Pak, L. M., Büttner, S., IJzermans, J. N., Koerkamp, B. G., Doukas, M., Jarnagin,
    W. R. et al. (2019). Unsupervised subtyping of cholangiocarcinoma using a deep
    clustering convolutional autoencoder, International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer, pp. 604–612.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Murthy et al. (2017) Murthy, V., Hou, L., Samaras, D., Kurc, T. M. and Saltz,
    J. H. (2017). Center-focusing multi-task cnn with injected features for classification
    of glioma nuclear images, 2017 IEEE Winter Conference on Applications of Computer
    Vision (WACV), IEEE, pp. 834–841.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Myronenko et al. (2021) Myronenko, A., Xu, Z., Yang, D., Roth, H. R. and Xu,
    D. (2021). Accounting for dependencies in deep learning based multiple instance
    learning for whole slide imaging, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 329–338.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nagpal et al. (2019) Nagpal, K., Foote, D., Liu, Y., Chen, P.-H. C., Wulczyn,
    E., Tan, F., Olson, N., Smith, J. L., Mohtashamian, A., Wren, J. H. et al. (2019).
    Development and validation of a deep learning algorithm for improving gleason
    scoring of prostate cancer, NPJ Digital Medicine  2(1): 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naik et al. (2020) Naik, N., Madani, A., Esteva, A., Keskar, N. S., Press, M. F.,
    Ruderman, D., Agus, D. B. and Socher, R. (2020). Deep learning-enabled breast
    cancer hormonal receptor status determination from base-level h&e stains, Nature
    Communications  11(1): 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Naylor et al. (2018) Naylor, P., Laé, M., Reyal, F. and Walter, T. (2018). Segmentation
    of nuclei in histopathology images by deep regression of the distance map, IEEE
    Transactions on Medical Imaging  38(2): 448–459.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Noroozi and Favaro (2016) Noroozi, M. and Favaro, P. (2016). Unsupervised learning
    of visual representations by solving jigsaw puzzles, European Conference on Computer
    Vision, Springer, pp. 69–84.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Odena (2016) Odena, A. (2016). Semi-supervised learning with generative adversarial
    networks, arXiv preprint arXiv:1606.01583 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pan et al. (2022) Pan, J., Bi, Q., Yang, Y., Zhu, P. and Bian, C. (2022). Label-efficient
    hybrid-supervised learning for medical image segmentation, arXiv preprint arXiv:2203.05956
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Parag et al. (2014) Parag, T., Plaza, S. and Scheffer, L. (2014). Small sample
    learning of superpixel classifiers for em segmentation, International Conference
    on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 389–397.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pathak et al. (2016) Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T. and Efros,
    A. A. (2016). Context encoders: Feature learning by inpainting, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2536–2544.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peikari et al. (2018) Peikari, M., Salama, S., Nofech-Mozes, S. and Martel,
    A. L. (2018). A cluster-then-label semi-supervised learning approach for pathology
    image classification, Scientific Reports  8(1): 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Petrick et al. (2021) Petrick, N. A., Akbar, S., Cha, K. H., Nofech-Mozes,
    S., Sahiner, B., Gavrielides, M. A., Kalpathy-Cramer, J., Drukker, K., Martel,
    A. L. et al. (2021). Spie-aapm-nci breastpathq challenge: an image analysis challenge
    for quantitative tumor cellularity assessment in breast cancer histology images
    following neoadjuvant treatment, Journal of Medical Imaging  8(3): 034501.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qaiser et al. (2016) Qaiser, T., Sirinukunwattana, K., Nakane, K., Tsang, Y.-W.,
    Epstein, D. and Rajpoot, N. (2016). Persistent homology for fast tumor segmentation
    in whole slide histology images, Procedia Computer Science  90: 119–124.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qu et al. (2020) Qu, H., Wu, P., Huang, Q., Yi, J., Yan, Z., Li, K., Riedlinger,
    G. M., De, S., Zhang, S. and Metaxas, D. N. (2020). Weakly supervised deep nuclei
    segmentation using partial points annotation in histopathology images, IEEE Transactions
    on Medical Imaging  39(11): 3655–3666.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Qu et al. (2022) Qu, L., Luo, X., Liu, S., Wang, M. and Song, Z. (2022). Dgmil:
    Distribution guided multiple instance learning for whole slide image classification,
    arXiv preprint arXiv:2206.08861 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Quiros et al. (2021) Quiros, A. C., Coudray, N., Yeaton, A., Sunhem, W., Murray-Smith,
    R., Tsirigos, A. and Yuan, K. (2021). Adversarial learning of cancer tissue representations,
    arXiv preprint arXiv:2108.02223 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Quiros et al. (2019) Quiros, A. C., Murray-Smith, R. and Yuan, K. (2019). Pathologygan:
    Learning deep representations of cancer tissue, arXiv preprint arXiv:1907.02644
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qureshi et al. (2008) Qureshi, H., Sertel, O., Rajpoot, N., Wilson, R. and Gurcan,
    M. (2008). Adaptive discriminant wavelet packet transform and local binary patterns
    for meningioma subtype classification, International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer, pp. 196–204.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Radford et al. (2015) Radford, A., Metz, L. and Chintala, S. (2015). Unsupervised
    representation learning with deep convolutional generative adversarial networks,
    arXiv preprint arXiv:1511.06434 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rajpoot and Rajpoot (2004) Rajpoot, K. and Rajpoot, N. (2004). Svm optimization
    for hyperspectral colon tissue cell classification, International Conference on
    Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 829–837.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ramon and De Raedt (2000) Ramon, J. and De Raedt, L. (2000). Multi instance
    neural networks, Proceedings of the ICML-2000 Workshop on Attribute-value and
    Relational Learning, pp. 53–60.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rethlefsen et al. (2021) Rethlefsen, M. L., Kirtley, S., Waffenschmidt, S.,
    Ayala, A. P., Moher, D., Page, M. J. and Koffel, J. B. (2021). Prisma-s: an extension
    to the prisma statement for reporting literature searches in systematic reviews,
    Systematic Reviews  10(1): 1–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rifai, Dauphin, Vincent, Bengio and Muller (2011) Rifai, S., Dauphin, Y. N.,
    Vincent, P., Bengio, Y. and Muller, X. (2011). The manifold tangent classifier,
    Advances in Neural Information Processing Systems  24.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rifai, Vincent, Muller, Glorot and Bengio (2011) Rifai, S., Vincent, P., Muller,
    X., Glorot, X. and Bengio, Y. (2011). Contractive auto-encoders: Explicit invariance
    during feature extraction, International Conference on Machine Learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rony et al. (2019) Rony, J., Belharbi, S., Dolz, J., Ayed, I. B., McCaffrey,
    L. and Granger, E. (2019). Deep weakly-supervised learning methods for classification
    and localization in histology images: a survey, arXiv preprint arXiv:1909.03354
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ru et al. (2022) Ru, L., Zhan, Y., Yu, B. and Du, B. (2022). Learning affinity
    from attention: End-to-end weakly-supervised semantic segmentation with transformers,
    arXiv preprint arXiv:2203.02664 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sahasrabudhe et al. (2020) Sahasrabudhe, M., Christodoulidis, S., Salgado, R.,
    Michiels, S., Loi, S., André, F., Paragios, N. and Vakalopoulou, M. (2020). Self-supervised
    nuclei segmentation in histopathological images using attention, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 393–402.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saillard et al. (2021) Saillard, C., Dehaene, O., Marchand, T., Moindrot, O.,
    Kamoun, A., Schmauch, B. and Jegou, S. (2021). Self supervised learning improves
    dmmr/msi detection from histology slides across multiple cancers, arXiv preprint
    arXiv:2109.05819 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saillard et al. (2020) Saillard, C., Schmauch, B., Laifa, O., Moarii, M., Toldo,
    S., Zaslavskiy, M., Pronier, E., Laurent, A., Amaddeo, G., Regnault, H. et al.
    (2020). Predicting survival after hepatocellular carcinoma resection using deep
    learning on histological slides, Hepatology  72(6): 2000–2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salimans et al. (2016) Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V.,
    Radford, A. and Chen, X. (2016). Improved techniques for training gans, Advances
    in Neural Information Processing Systems  29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shaban et al. (2019) Shaban, M., Khurram, S. A., Fraz, M. M., Alsubaie, N.,
    Masood, I., Mushtaq, S., Hassan, M., Loya, A. and Rajpoot, N. M. (2019). A novel
    digital score for abundance of tumour infiltrating lymphocytes predicts disease
    free survival in oral squamous cell carcinoma, Scientific Reports  9(1): 1–13.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shao et al. (2021) Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X.
    et al. (2021). Transmil: Transformer based correlated multiple instance learning
    for whole slide image classification, Advances in Neural Information Processing
    Systems  34.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sharma et al. (2021) Sharma, Y., Shrivastava, A., Ehsan, L., Moskaluk, C. A.,
    Syed, S. and Brown, D. (2021). Cluster-to-conquer: A framework for end-to-end
    multi-instance learning for whole slide image classification, Medical Imaging
    with Deep Learning, PMLR, pp. 682–698.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shaw et al. (2020) Shaw, S., Pajak, M., Lisowska, A., Tsaftaris, S. A. and O’Neil,
    A. Q. (2020). Teacher-student chain for efficient semi-supervised histology image
    classification, arXiv preprint arXiv:2003.08797 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. (2018) Shi, X., Sapkota, M., Xing, F., Liu, F., Cui, L. and Yang,
    L. (2018). Pairwise based deep ranking hashing for histopathology image classification
    and retrieval, Pattern Recognition  81: 14–22.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi, Su, Xing and Yang (2020) Shi, X., Su, H., Xing, G. and Yang, L. (2020).
    Graph temporal ensembling based semi-supervised convolutional neural network with
    noisy labels for histopathology image analysis, Medical Image Analysis  60: 101624.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi, Xing, Xie, Zhang, Cui and Yang (2020) Shi, X., Xing, F., Xie, Y., Zhang,
    Z., Cui, L. and Yang, L. (2020). Loss-based attention for deep multiple instance
    learning, Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34,
    pp. 5742–5749.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shurrab and Duwairi (2021) Shurrab, S. and Duwairi, R. (2021). Self-supervised
    learning methods and applications in medical imaging analysis: A survey, arXiv
    preprint arXiv:2109.08685 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh et al. (2011) Singh, S., Janoos, F., Pécot, T., Caserta, E., Leone, G.,
    Rittscher, J. and Machiraju, R. (2011). Identifying nuclear phenotypes using semi-supervised
    metric learning, Biennial International Conference on Information Processing in
    Medical Imaging, Springer, pp. 398–410.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sirinukunwattana et al. (2017) Sirinukunwattana, K., Pluim, J. P., Chen, H.,
    Qi, X., Heng, P.-A., Guo, Y. B., Wang, L. Y., Matuszewski, B. J., Bruni, E., Sanchez,
    U. et al. (2017). Gland segmentation in colon histology images: The glas challenge
    contest, Medical Image Analysis  35: 489–502.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sirinukunwattana et al. (2016) Sirinukunwattana, K., Raza, S. E. A., Tsang,
    Y.-W., Snead, D. R., Cree, I. A. and Rajpoot, N. M. (2016). Locality sensitive
    deep learning for detection and classification of nuclei in routine colon cancer
    histology images, IEEE transactions on medical imaging  35(5): 1196–1206.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Skrede et al. (2020) Skrede, O.-J., De Raedt, S., Kleppe, A., Hveem, T. S.,
    Liestøl, K., Maddison, J., Askautrud, H. A., Pradhan, M., Nesheim, J. A., Albregtsen,
    F. et al. (2020). Deep learning for prediction of colorectal cancer outcome: a
    discovery and validation study, The Lancet  395(10221): 350–360.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Spanhol et al. (2015) Spanhol, F. A., Oliveira, L. S., Petitjean, C. and Heutte,
    L. (2015). A dataset for breast cancer histopathological image classification,
    IEEE Transactions on Biomedical Engineering  63(7): 1455–1462.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sparks and Madabhushi (2016) Sparks, R. and Madabhushi, A. (2016). Out-of-sample
    extrapolation utilizing semi-supervised manifold learning (ose-ssl): content based
    image retrieval for histopathology images, Scientific Reports  6(1): 1–15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srinidhi et al. (2021) Srinidhi, C. L., Ciga, O. and Martel, A. L. (2021).
    Deep neural network models for computational histopathology: A survey, Medical
    Image Analysis  67: 101813.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Srinidhi et al. (2022) Srinidhi, C. L., Kim, S. W., Chen, F.-D. and Martel,
    A. L. (2022). Self-supervised driven consistency training for annotation efficient
    histopathology image analysis, Medical Image Analysis  75: 102256.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stacke et al. (2021) Stacke, K., Unger, J., Lundström, C. and Eilertsen, G.
    (2021). Learning representations with contrastive self-supervised learning for
    histopathology applications, arXiv preprint arXiv:2112.05760 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2019) Su, H., Shi, X., Cai, J. and Yang, L. (2019). Local and global
    consistency regularized mean teacher for semi-supervised nuclei classification,
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer, pp. 559–567.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Su et al. (2015) Su, H., Yin, Z., Huh, S., Kanade, T. and Zhu, J. (2015). Interactive
    cell segmentation based on active and semi-supervised learning, IEEE Transactions
    on Medical Imaging  35(3): 762–777.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Su et al. (2021) Su, L., Liu, Y., Wang, M. and Li, A. (2021). Semi-hic: A novel
    semi-supervised deep learning method for histopathological image classification,
    Computers in Biology and Medicine  137: 104788.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Swiderska-Chadaj et al. (2019) Swiderska-Chadaj, Z., Pinckaers, H., van Rijthoven,
    M., Balkenhol, M., Melnikova, M., Geessink, O., Manson, Q., Sherman, M., Polonia,
    A., Parry, J. et al. (2019). Learning to detect lymphocytes in immunohistochemistry
    with deep learning, Medical Image Analysis  58: 101547.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tajbakhsh et al. (2020) Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J. N.,
    Wu, Z. and Ding, X. (2020). Embracing imperfect datasets: A review of deep learning
    solutions for medical image segmentation, Medical Image Analysis  63: 101693.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tarvainen and Valpola (2017) Tarvainen, A. and Valpola, H. (2017). Mean teachers
    are better role models: Weight-averaged consistency targets improve semi-supervised
    deep learning results, Advances in Neural Information Processing Systems  30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: TCGA (2019) TCGA (2019). The cancer genome atlas, [https://www.cancer.gov/tcga](https://www.cancer.gov/tcga).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Team et al. (2011) Team, N. L. S. T. R. et al. (2011). The national lung screening
    trial: overview and study design, Radiology  258(1): 243.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tellez et al. (2019) Tellez, D., Litjens, G., van der Laak, J. and Ciompi, F.
    (2019). Neural image compression for gigapixel histopathology image analysis,
    IEEE Transactions on Pattern Analysis and Machine Intelligence  43(2): 567–578.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tolkach et al. (2020) Tolkach, Y., Dohmgörgen, T., Toma, M. and Kristiansen,
    G. (2020). High-accuracy prostate cancer pathology using deep learning, Nature
    Machine Intelligence  2(7): 411–418.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tomita et al. (2019) Tomita, N., Abdollahi, B., Wei, J., Ren, B., Suriawinata,
    A. and Hassanpour, S. (2019). Attention-based deep neural networks for detection
    of cancerous and precancerous esophagus tissue on histopathological slides, JAMA
    Network Open  2(11): e1914645–e1914645.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tu et al. (2019) Tu, M., Huang, J., He, X. and Zhou, B. (2019). Multiple instance
    learning with graph neural networks, arXiv preprint arXiv:1906.04881 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Van den Oord et al. (2018) Van den Oord, A., Li, Y. and Vinyals, O. (2018).
    Representation learning with contrastive predictive coding, arXiv e-prints pp. arXiv–1807.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Van Engelen and Hoos (2020) Van Engelen, J. E. and Hoos, H. H. (2020). A survey
    on semi-supervised learning, Machine Learning  109(2): 373–440.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Veeling et al. (2018) Veeling, B. S., Linmans, J., Winkens, J., Cohen, T. and Welling,
    M. (2018). Rotation equivariant cnns for digital pathology, International Conference
    on Medical Image Computing and Computer-assisted Intervention, Springer, pp. 210–218.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Velmahos et al. (2021) Velmahos, C. S., Badgeley, M. and Lo, Y.-C. (2021). Using
    deep learning to identify bladder cancers with fgfr-activating mutations from
    histology images, Cancer Medicine  10(14): 4805–4813.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Veta et al. (2019) Veta, M., Heng, Y. J., Stathonikos, N., Bejnordi, B. E.,
    Beca, F., Wollmann, T., Rohr, K., Shah, M. A., Wang, D., Rousson, M. et al. (2019).
    Predicting breast tumor proliferation from whole-slide images: the tupac16 challenge,
    Medical Image Analysis  54: 111–121.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vincent et al. (2008) Vincent, P., Larochelle, H., Bengio, Y. and Manzagol,
    P.-A. (2008). Extracting and composing robust features with denoising autoencoders,
    Proceedings of the 25th International Conference on Machine Learning, pp. 1096–1103.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang, Lee, Calista, Zhou, Zhu, Suzuki, Komura, Ishikawa and Cheng (2018) Wang,
    C.-W., Lee, Y.-C., Calista, E., Zhou, F., Zhu, H., Suzuki, R., Komura, D., Ishikawa,
    S. and Cheng, S.-P. (2018). A benchmark for comparing precision medicine methods
    in thyroid cancer diagnosis using tissue microarrays, Bioinformatics  34(10): 1767–1773.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2019) Wang, X., Chen, H., Gan, C., Lin, H., Dou, Q., Tsougenis,
    E., Huang, Q., Cai, M. and Heng, P.-A. (2019). Weakly supervised deep learning
    for whole slide lung cancer image analysis, IEEE Transactions on Cybernetics  50(9): 3950–3962.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang, Yan, Tang, Bai and Liu (2018) Wang, X., Yan, Y., Tang, P., Bai, X. and Liu,
    W. (2018). Revisiting multiple instance neural networks, Pattern Recognition  74: 15–24.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2021) Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Huang,
    J., Yang, W. and Han, X. (2021). Transpath: Transformer-based self-supervised
    learning for histopathological image classification, International Conference
    on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 186–195.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ward and Hawkins (2015) Ward, R. L. and Hawkins, N. J. (2015). Molecular and
    cellular oncology (mco) study tumour collection, UNSW Australia .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wei et al. (2019) Wei, J. W., Tafe, L. J., Linnik, Y. A., Vaickus, L. J., Tomita,
    N. and Hassanpour, S. (2019). Pathologist-level classification of histologic patterns
    on resected lung adenocarcinoma slides with deep neural networks, Scientific Reports  9(1): 1–8.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wessels et al. (2021) Wessels, F., Schmitt, M., Krieghoff-Henning, E., Jutzi,
    T., Worst, T. S., Waldbillig, F., Neuberger, M., Maron, R. C., Steeg, M., Gaiser,
    T. et al. (2021). Deep learning approach to predict lymph node metastasis directly
    from primary tumour histology in prostate cancer, BJU International  128(3): 352–360.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weston et al. (2012) Weston, J., Ratle, F., Mobahi, H. and Collobert, R. (2012).
    Deep learning via semi-supervised embedding, Neural Networks: Tricks of the Trade,
    Springer, pp. 639–655.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Woerl et al. (2020) Woerl, A.-C., Eckstein, M., Geiger, J., Wagner, D. C., Daher,
    T., Stenzel, P., Fernandez, A., Hartmann, A., Wand, M., Roth, W. et al. (2020).
    Deep learning predicts molecular subtype of muscle-invasive bladder cancer from
    conventional histopathological slides, European Urology  78(2): 256–264.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2015) Wu, J., Yu, Y., Huang, C. and Yu, K. (2015). Deep multiple
    instance learning for image classification and auto-annotation, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3460–3469.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie, Dai, Hovy, Luong and Le (2020) Xie, Q., Dai, Z., Hovy, E., Luong, T. and Le,
    Q. (2020). Unsupervised data augmentation for consistency training, Advances in
    Neural Information Processing Systems  33: 6256–6268.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xie, Chen, Li and Zheng (2020) Xie, X., Chen, J., Li, K. and Zheng, Y. (2020).
    Instance-aware self-supervised learning for nuclei segmentation, International
    Conference on Medical Image Computing and Computer-assisted Intervention, Springer,
    pp. 341–350.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2019) Xu, G., Song, Z., Sun, Z., Ku, C., Yang, Z., Liu, C., Wang,
    S., Ma, J. and Xu, W. (2019). Camel: A weakly supervised learning framework for
    histopathology image segmentation, Proceedings of the IEEE/CVF International Conference
    on Computer Vision, pp. 10682–10691.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2020) Xu, J., Hou, J., Zhang, Y., Feng, R., Ruan, C., Zhang, T. and Fan,
    W. (2020). Data-efficient histopathology image analysis with deformation representation
    learning, 2020 IEEE International Conference on Bioinformatics and Biomedicine
    (BIBM), IEEE, pp. 857–864.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2016) Xu, K., Su, H., Zhu, J., Guan, J.-S. and Zhang, B. (2016).
    Neuron segmentation based on cnn with semi-supervised regularization, Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 20–28.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. (2022) Xu, L., Ouyang, W., Bennamoun, M., Boussaid, F. and Xu, D.
    (2022). Multi-class token transformer for weakly supervised semantic segmentation,
    arXiv preprint arXiv:2203.02891 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yalniz et al. (2019) Yalniz, I. Z., Jégou, H., Chen, K., Paluri, M. and Mahajan,
    D. (2019). Billion-scale semi-supervised learning for image classification, arXiv
    preprint arXiv:1905.00546 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yan et al. (2018) Yan, Y., Wang, X., Guo, X., Fang, J., Liu, W. and Huang, J.
    (2018). Deep multi-instance learning with dynamic pooling, Asian Conference on
    Machine Learning, PMLR, pp. 662–677.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2022) Yang, J., Ju, J., Guo, L., Ji, B., Shi, S., Yang, Z., Gao,
    S., Yuan, X., Tian, G., Liang, Y. et al. (2022). Prediction of her2-positive breast
    cancer recurrence and metastasis risk from histopathological images and clinical
    information via multimodal deep learning, Computational and Structural Biotechnology
    Journal  20: 333–342.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2017) Yang, L., Zhang, Y., Chen, J., Zhang, S. and Chen, D. Z.
    (2017). Suggestive annotation: A deep active learning framework for biomedical
    image segmentation, International Conference on Medical Image Computing and Computer-assisted
    Intervention, Springer, pp. 399–407.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2021) Yang, P., Hong, Z., Yin, X., Zhu, C. and Jiang, R. (2021).
    Self-supervised visual representation learning for histopathological images, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 47–57.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2020) Yang, P., Zhai, Y., Li, L., Lv, H., Wang, J., Zhu, C. and Jiang,
    R. (2020). A deep metric learning approach for histopathological image retrieval,
    Methods  179: 14–25.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2020) Yao, J., Zhu, X., Jonnagaddala, J., Hawkins, N. and Huang,
    J. (2020). Whole slide images based cancer survival prediction using attention
    guided deep multiple instance learning networks, Medical Image Analysis  65: 101789.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2016) Yu, K.-H., Zhang, C., Berry, G. J., Altman, R. B., Ré, C.,
    Rubin, D. L. and Snyder, M. (2016). Predicting non-small cell lung cancer prognosis
    by fully automated microscopic pathology image features, Nature Communications  7(1): 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2016) Zhang, R., Isola, P. and Efros, A. A. (2016). Colorful image
    colorization, European Conference on Computer Vision, Springer, pp. 649–666.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2017) Zhang, Y., Yang, L., Chen, J., Fredericksen, M., Hughes,
    D. P. and Chen, D. Z. (2017). Deep adversarial networks for biomedical image segmentation
    utilizing unannotated images, International Conference on Medical Image Computing
    and Computer-assisted Intervention, Springer, pp. 408–416.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2020) Zhao, Y., Yang, F., Fang, Y., Liu, H., Zhou, N., Zhang, J.,
    Sun, J., Yang, S., Menze, B., Fan, X. et al. (2020). Predicting lymph node metastasis
    using histopathological images based on multiple instance learning with deep graph
    convolution, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 4837–4846.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2019) Zheng, H., Yang, L., Chen, J., Han, J., Zhang, Y., Liang,
    P., Zhao, Z., Wang, C. and Chen, D. Z. (2019). Biomedical image segmentation via
    representative annotation, Proceedings of the AAAI Conference on Artificial Intelligence,
    Vol. 33, pp. 5901–5908.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2020) Zhou, Y., Chen, H., Lin, H. and Heng, P.-A. (2020). Deep
    semi-supervised knowledge distillation for overlapping cervical cell instance
    segmentation, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 521–531.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou and Li (2005) Zhou, Z.-H. and Li, M. (2005). Tri-training: Exploiting
    unlabeled data using three classifiers, IEEE Transactions on Knowledge and Data
    Engineering  17(11): 1529–1541.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou et al. (2021) Zhou, Z., Sodha, V., Pang, J., Gotway, M. B. and Liang, J.
    (2021). Models genesis, Medical Image Analysis  67: 101840.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu (2005) Zhu, X. J. (2005). Semi-supervised learning literature survey, CS
    Technical Reports .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. (2017) Zhu, X., Yao, J., Zhu, F. and Huang, J. (2017). Wsisa: Making
    survival prediction from whole slide histopathological images, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7234–7242.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[◄](/html/2208.08786) [![ar5iv homepage](img/ed0f3cf5a019c4f8e48e41de62929bb0.png)](/)
    [Feeling'
  prefs: []
  type: TYPE_NORMAL
- en: lucky?](/feeling_lucky) [Conversion
  prefs: []
  type: TYPE_NORMAL
- en: report](/log/2208.08789) [Report
  prefs: []
  type: TYPE_NORMAL
- en: an issue](https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.08789)
    [View original
  prefs: []
  type: TYPE_NORMAL
- en: on arXiv](https://arxiv.org/abs/2208.08789)[►](/html/2208.08791)[](javascript:toggleColorScheme()
    "Toggle ar5iv color scheme")[Copyright](https://arxiv.org/help/license) [Privacy
    Policy](https://arxiv.org/help/policies/privacy_policy)Generated on Wed Mar 13
    16:26:27 2024 by [LaTeXML![Mascot Sammy](img/70e087b9e50c3aa663763c3075b0d6c5.png)](http://dlmf.nist.gov/LaTeXML/)
  prefs: []
  type: TYPE_NORMAL
