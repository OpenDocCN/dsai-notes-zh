- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:45:18'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:45:18
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2207.11719] Gradient-based Bi-level Optimization for Deep Learning: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2207.11719] 基于梯度的双层优化在深度学习中的应用：一项调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2207.11719](https://ar5iv.labs.arxiv.org/html/2207.11719)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2207.11719](https://ar5iv.labs.arxiv.org/html/2207.11719)
- en: 'Gradient-based Bi-level Optimization for Deep Learning: A Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 基于梯度的双层优化在深度学习中的应用：一项调查
- en: Can (Sam) Chen can.chen@mila.quebec
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Can (Sam) Chen can.chen@mila.quebec
- en: Mila - Quebec AI Institute
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Mila - Quebec AI Institute
- en: McGill University Xi Chen McGill University Chen Ma City University of Hong
    Kong Zixuan Liu University of Washington Xue Liu McGill University
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 麦吉尔大学的Xi Chen，麦吉尔大学的Chen Ma，香港城市大学的Zixuan Liu，华盛顿大学的Xue Liu，麦吉尔大学
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'Bi-level optimization, especially the gradient-based category, has been widely
    used in the deep learning community including hyperparameter optimization and
    meta-knowledge extraction. Bi-level optimization embeds one problem within another
    and the gradient-based category solves the outer-level task by computing the hypergradient,
    which is much more efficient than classical methods such as the evolutionary algorithm.
    In this survey, we first give a formal definition of the gradient-based bi-level
    optimization. Next, we delineate criteria to determine if a research problem is
    apt for bi-level optimization and provide a practical guide on structuring such
    problems into a bi-level optimization framework, a feature particularly beneficial
    for those new to this domain. More specifically, there are two formulations: the
    single-task formulation to optimize hyperparameters such as regularization parameters
    and the distilled data, and the multi-task formulation to extract meta-knowledge
    such as the model initialization. With a bi-level formulation, we then discuss
    four bi-level optimization solvers to update the outer variable including explicit
    gradient update, proxy update, implicit function update, and closed-form update.
    Finally, we wrap up the survey by highlighting two prospective future directions:
    (1) Effecctive Data Optimization for Science examined through the lens of task
    formulation. (2) Accurate Explicit Proxy Update analyzed from an optimization
    standpoint.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 双层优化，特别是基于梯度的类别，已经在深度学习社区中得到了广泛应用，包括超参数优化和元知识提取。双层优化将一个问题嵌套在另一个问题中，而基于梯度的类别通过计算超梯度来解决外层任务，这比经典方法如进化算法更加高效。在本调查中，我们首先给出基于梯度的双层优化的正式定义。接下来，我们描述了判断研究问题是否适合双层优化的标准，并提供了将这些问题结构化为双层优化框架的实用指南，这对新手尤其有益。更具体地说，有两种公式：单任务公式用于优化超参数如正则化参数和提取数据，以及多任务公式用于提取元知识如模型初始化。通过双层公式，我们讨论了四种双层优化求解器来更新外部变量，包括显式梯度更新、代理更新、隐式函数更新和闭式形式更新。最后，我们通过强调两个前景广阔的未来方向来总结这项调查：（1）通过任务公式视角考察的有效数据优化；（2）从优化角度分析的准确显式代理更新。
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'With the fast development of deep learning, bi-level optimization is drawing
    lots of research attention due to the nested problem structure in many deep learning
    problems, including hyperparameter optimization (Rendle, [2012](#bib.bib65); Chen
    et al., [2019](#bib.bib18); Liu et al., [2019](#bib.bib47)) and meta-knowledge
    extraction (Finn et al., [2017](#bib.bib25)). The bi-level optimization problem
    is a special kind of optimization problem where one problem is embedded within
    another and can be traced to two domains: one is from game theory where the leader
    and the follower compete on quantity in the Stackelberg game (Von Stackelberg,
    [2010](#bib.bib74)); another one is from mathematical programming where the inner
    level problem serves as a constraint on the outer level problem (Bracken & McGill,
    [1973](#bib.bib9)). Especially, compared with classical methods (Sinha et al.,
    [2017](#bib.bib71)) which require strict mathematical properties or can not scale
    to large datasets, the efficient gradient descent methods provide a promising
    solution to the complicated bi-level optimization problem and thus are widely
    adopted in much deep learning research work to optimize hyperparameters in the
    single-task formulation (Bertinetto et al., [2019](#bib.bib6); Hu et al., [2019](#bib.bib37);
    Liu et al., [2019](#bib.bib47); Rendle, [2012](#bib.bib65); Chen et al., [2019](#bib.bib18);
    Ma et al., [2020](#bib.bib53); Zhang et al., [2023](#bib.bib89); Li et al., [2022](#bib.bib45))
    or extract meta-knowledge in the multi-task formulation (Finn et al., [2017](#bib.bib25);
    Andrychowicz et al., [2016](#bib.bib2); Chen et al., [2023b](#bib.bib17); Zhong
    et al., [2022](#bib.bib90); Chi et al., [2021](#bib.bib19); [2022](#bib.bib20);
    Wu et al., [2022](#bib.bib81); Chen et al., [2022c](#bib.bib15)).'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的快速发展，双层优化因其在许多深度学习问题中的嵌套问题结构而受到大量研究关注，包括超参数优化（Rendle, [2012](#bib.bib65);
    Chen et al., [2019](#bib.bib18); Liu et al., [2019](#bib.bib47)）和元知识提取（Finn et
    al., [2017](#bib.bib25)）。双层优化问题是一种特殊的优化问题，其中一个问题嵌套在另一个问题中，可以追溯到两个领域：一个是来自博弈论的Stackelberg博弈（Von
    Stackelberg, [2010](#bib.bib74)），其中领导者和跟随者在数量上竞争；另一个是来自数学规划的，其中内层问题作为外层问题的约束（Bracken
    & McGill, [1973](#bib.bib9)）。尤其是，与要求严格数学属性或无法扩展到大数据集的经典方法（Sinha et al., [2017](#bib.bib71)）相比，高效的梯度下降方法为复杂的双层优化问题提供了有前景的解决方案，因此在许多深度学习研究工作中被广泛采用，以优化单任务形式化中的超参数（Bertinetto
    et al., [2019](#bib.bib6); Hu et al., [2019](#bib.bib37); Liu et al., [2019](#bib.bib47);
    Rendle, [2012](#bib.bib65); Chen et al., [2019](#bib.bib18); Ma et al., [2020](#bib.bib53);
    Zhang et al., [2023](#bib.bib89); Li et al., [2022](#bib.bib45)）或在多任务形式化中提取元知识（Finn
    et al., [2017](#bib.bib25); Andrychowicz et al., [2016](#bib.bib2); Chen et al.,
    [2023b](#bib.bib17); Zhong et al., [2022](#bib.bib90); Chi et al., [2021](#bib.bib19);
    [2022](#bib.bib20); Wu et al., [2022](#bib.bib81); Chen et al., [2022c](#bib.bib15)）。
- en: 'In this survey, we mainly focus on gradient-based bi-level optimization regarding
    deep neural networks with an explicitly defined objective function. This survey
    aims to guide researchers on their research problems involving bi-level optimization.
    We first define notations and give a formal definition of gradient-based bi-level
    optimization in Section [2](#S2 "2 Definition ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"). We then propose a new taxonomy in terms of task
    formulation in Section [3](#S3 "3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey") and methods to compute the hypergradient of the
    outer variable in Section [4](#S4 "4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"). This taxonomy provides guidance to researchers
    on the criteria and procedures to formulate a task as a bi-level optimization
    problem and how to solve this problem. Last, we conclude the survey with two promising
    future directions in Section [5](#S5 "5 Conclusion and Future Directions ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey").'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: '在本次调查中，我们主要关注具有明确定义的目标函数的深度神经网络的基于梯度的双层优化。该调查旨在指导研究人员处理涉及双层优化的研究问题。我们首先在第[2](#S2
    "2 Definition ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")节中定义了符号并给出了基于梯度的双层优化的正式定义。接着，我们在第[3](#S3
    "3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")节中提出了一种新的任务形式化分类法，并在第[4](#S4 "4 Optimization ‣ Gradient-based Bi-level
    Optimization for Deep Learning: A Survey")节中提出了计算外部变量超梯度的方法。这种分类法为研究人员提供了如何将任务形式化为双层优化问题以及如何解决这一问题的指导。最后，我们在第[5](#S5
    "5 Conclusion and Future Directions ‣ Gradient-based Bi-level Optimization for
    Deep Learning: A Survey")节中总结了调查并提出了两个有前景的未来方向。'
- en: 2 Definition
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 定义
- en: 'Table 1: Key notations used in this paper.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：本文中使用的关键符号。
- en: '| Notations | Descriptions |'
  id: totrans-17
  prefs: []
  type: TYPE_TB
  zh: '| Notations | Descriptions |'
- en: '| --- | --- |'
  id: totrans-18
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| $\boldsymbol{x}_{i}$ | Input of data point indexed by i |'
  id: totrans-19
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{x}_{i}$ | 由i索引的数据点的输入 |'
- en: '| $\boldsymbol{y}_{i}$ | Label of data point indexed by i |'
  id: totrans-20
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{y}_{i}$ | 由i索引的数据点的标签 |'
- en: '| $\mathcal{D}$/$\mathcal{D}_{train}$/$\mathcal{D}_{val}$ | Supervised/Training/Validation
    dataset |'
  id: totrans-21
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{D}$/$\mathcal{D}_{train}$/$\mathcal{D}_{val}$ | 监督/训练/验证数据集 |'
- en: '| $&#124;\mathcal{D}&#124;$ | Number of samples in the dataset $\mathcal{D}$
    |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| $&#124;\mathcal{D}&#124;$ | 数据集$\mathcal{D}$中的样本数量 |'
- en: '| $\boldsymbol{\theta}$/$\boldsymbol{\Theta}$ | Inner learnable variable |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\theta}$/$\boldsymbol{\Theta}$ | 内部可学习变量 |'
- en: '| $\boldsymbol{\phi}$/ $\boldsymbol{\Phi}$ | Outer learnable variable |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\phi}$/ $\boldsymbol{\Phi}$ | 外部可学习变量 |'
- en: '| $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$ | Best response of $\boldsymbol{\theta}$
    given $\boldsymbol{\phi}$ |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$ | 给定$\boldsymbol{\phi}$的$\boldsymbol{\theta}$的最佳响应
    |'
- en: '| $l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},y_{i})$ | Loss
    on the $i_{th}$ data point $\boldsymbol{x}_{i},\boldsymbol{y}_{i}$ |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| $l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},y_{i})$ | 第$i_{th}$个数据点$\boldsymbol{x}_{i},\boldsymbol{y}_{i}$上的损失
    |'
- en: '| $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$ | Loss on data $\boldsymbol{x}_{i},\boldsymbol{y}_{i}$
    without $\boldsymbol{\phi}$ |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$ | 没有$\boldsymbol{\phi}$的情况下，数据$\boldsymbol{x}_{i},\boldsymbol{y}_{i}$上的损失
    |'
- en: '| $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ | Loss on
    the whole dataset $\mathcal{D}$ |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ | 整个数据集$\mathcal{D}$上的损失
    |'
- en: '| $\mathcal{L}(\boldsymbol{\theta},\mathcal{D})$ | Loss on dataset $\mathcal{D}$
    without $\boldsymbol{\phi}$ |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}(\boldsymbol{\theta},\mathcal{D})$ | 没有$\boldsymbol{\phi}$的情况下，数据集$\mathcal{D}$上的损失
    |'
- en: '| $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ | Inner
    level loss on dataset $\mathcal{D}$ |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ | 数据集$\mathcal{D}$上的内部层损失
    |'
- en: '| $\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ |
    Outer level loss on dataset $\mathcal{D}$ |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ |
    数据集$\mathcal{D}$上的外部层损失 |'
- en: '| $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$ | Hypergradient regarding
    $\boldsymbol{\phi}$ |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$ | 关于$\boldsymbol{\phi}$的超梯度
    |'
- en: '| $\eta$ | Inner level learning rate |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| $\eta$ | 内部层学习率 |'
- en: '| $\rm{M}$ | Number of inner level tasks |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| $\rm{M}$ | 内部层任务的数量 |'
- en: '| $\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$ | Regularization parameterized
    by $\boldsymbol{\phi}$ |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| $\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$ | 由$\boldsymbol{\phi}$参数化的正则化参数
    |'
- en: '| $\rm{OPT}$ | Some optimizer like Adam |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| $\rm{OPT}$ | 一些如Adam的优化器 |'
- en: '| $\mathcal{D}_{real}$/$\mathcal{D}_{syn}$ | Real/Synthetic dataset |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{D}_{real}$/$\mathcal{D}_{syn}$ | 真实/合成数据集 |'
- en: '| $p(\cdot)$ | Product price in the market |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| $p(\cdot)$ | 市场中的产品价格 |'
- en: '| $C_{l}(\phi)/C_{f}(\theta)$ | Cost of leader and follower |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| $C_{l}(\phi)/C_{f}(\theta)$ | 领导者和跟随者的成本 |'
- en: '| $D$ | Predicted atom-atom distances |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| $D$ | 预测的原子间距离 |'
- en: '| $\mathcal{D}^{prf}$/$\mathcal{D}^{ft}$ | Pretraining/finetuning data |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| $\mathcal{D}^{prf}$/$\mathcal{D}^{ft}$ | 预训练/微调数据 |'
- en: '| $E$ | Some equation constraint |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| $E$ | 一些方程约束 |'
- en: '| $\lambda$/$\gamma$ | Regularization strength parameter |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '| $\lambda$/$\gamma$ | 正则化强度参数 |'
- en: '| $\epsilon$/$\tau$ | Some small positive constant |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| $\epsilon$/$\tau$ | 一些小的正数 |'
- en: '| $P_{\boldsymbol{\alpha}}$ | Proxy network parameterized by $\boldsymbol{\alpha}$
    |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| $P_{\boldsymbol{\alpha}}$ | 由$\boldsymbol{\alpha}$参数化的代理网络 |'
- en: '| $T$ | Number of iterations in optimization |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| $T$ | 优化中的迭代次数 |'
- en: 'In this section, we define the gradient-based bi-level optimization, which
    focuses on neural networks with an explicit objective function. For convenience,
    we list notations and their descriptions in Table [1](#S2.T1 "Table 1 ‣ 2 Definition
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey").'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们定义了基于梯度的双层优化，重点关注具有显式目标函数的神经网络。为方便起见，我们在表[1](#S2.T1 "Table 1 ‣ 2 Definition
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")中列出了符号及其描述。'
- en: 'Assume there is a dataset $\mathcal{D}$ = {($\boldsymbol{x}_{i}$, $y_{i}$)}
    under the supervised learning setting where $\boldsymbol{x}_{i}$ and $y_{i}$ represent
    the $i^{th}$ input and corresponding label, respectively. Besides, $\mathcal{D}_{train}$
    and $\mathcal{D}_{val}$ represent the training set and the validation set, respectively.
    We use $\boldsymbol{\theta}\in\mathbb{R}^{d}$ ($\boldsymbol{\Theta}$ for matrix
    form) to parameterize the inner learnable variable which often refers to the model
    parameters and use $\boldsymbol{\phi}\in\mathbb{R}^{m}$ ($\boldsymbol{\Phi}$ for
    matrix form) to parameterize the outer learnable variable including the hyperparameters
    and the meta knowledge. In this paper, the hyperparameters are not limited to
    the regularization and the learning rate but refer to any knowledge in a single
    task formulation, as we will illustrate more detailedly in Section [3](#S3 "3
    Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey").
    Denote the loss function on $(\boldsymbol{x}_{i},y_{i})$ as $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$,
    which refers to a certain format of objectives depending on the tasks such as
    Cross-Entropy loss or Mean Square Error (MSE) loss. Note that in some cases we
    use $l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},y_{i})$, which
    is an equivalent variant of $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$
    under this setting. This is because the outer learnable parameters $\boldsymbol{\phi}$
    can be hyperparameters like the learning rate when calculating $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$
    and is thus not explicitly represented. We then use $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$
    or $\mathcal{L}(\boldsymbol{\theta},\mathcal{D})$ to denote the loss over the
    dataset $\mathcal{D}$, and represent the inner level loss and the outer level
    loss as $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$
    and $\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$, respectively.
    Generally, the inner level loss is computed on the training dataset $\mathcal{D}^{train}$,
    and the outer level loss is assessed on the validation dataset $\mathcal{D}^{val}$.
    We use $\eta$ to represent the learning rate adopted by the inner-level optimization.
    Employing these notations, we present the mathematical expression for the bi-level
    optimization problem as follows:'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '假设有一个数据集 $\mathcal{D}$ = {($\boldsymbol{x}_{i}$, $y_{i}$)}，在监督学习设置下，其中 $\boldsymbol{x}_{i}$
    和 $y_{i}$ 分别表示第 $i^{th}$ 个输入及其对应的标签。此外，$\mathcal{D}_{train}$ 和 $\mathcal{D}_{val}$
    分别表示训练集和验证集。我们使用 $\boldsymbol{\theta}\in\mathbb{R}^{d}$ （矩阵形式为 $\boldsymbol{\Theta}$）来参数化内部可学习变量，这通常指的是模型参数，并使用
    $\boldsymbol{\phi}\in\mathbb{R}^{m}$ （矩阵形式为 $\boldsymbol{\Phi}$）来参数化外部可学习变量，包括超参数和元知识。本文中，超参数不仅限于正则化和学习率，而是指任何单任务公式中的知识，具体会在第[3](#S3
    "3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")节中详细说明。设在 $(\boldsymbol{x}_{i},y_{i})$ 上的损失函数为 $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$，它指的是根据任务不同的目标格式，如交叉熵损失或均方误差（MSE）损失。注意，在某些情况下我们使用
    $l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},y_{i})$，这是 $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$
    在此设置下的一个等效变体。这是因为外部可学习参数 $\boldsymbol{\phi}$ 在计算 $l(\boldsymbol{\theta},\boldsymbol{x}_{i},y_{i})$
    时可能是诸如学习率等超参数，因此没有被显式表示。我们使用 $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$
    或 $\mathcal{L}(\boldsymbol{\theta},\mathcal{D})$ 来表示数据集 $\mathcal{D}$ 上的损失，并将内部层损失和外部层损失表示为
    $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$ 和 $\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D})$，分别。通常，内部层损失在训练数据集
    $\mathcal{D}^{train}$ 上计算，而外部层损失在验证数据集 $\mathcal{D}^{val}$ 上评估。我们用 $\eta$ 表示内层优化所采用的学习率。采用这些符号表示法，我们将双层优化问题的数学表达式如下所示：'
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi}).$
    |  | (1) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi}).$
    |  | (1) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi}).$
    |  | (2) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi}).$
    |  | (2) |'
- en: 'The inner level problem in Eq. ([2](#S2.E2 "In 2 Definition ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey")) serves as a constraint and
    builds the relation between the $\boldsymbol{\phi}$ and $\boldsymbol{\theta}$.
    Here we use the $\arg\min$ form in Eq. ([2](#S2.E2 "In 2 Definition ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey")) but note that the inner level
    task can be extended to some equation constraints as we will further illustrate
    in Section [3](#S3 "3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"). In the nature of neural networks, one can use gradient
    descent to estimate $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$. The outer level
    problem acts as the main optimization problem and computes the hypergradient $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$
    to update the outer variable $\boldsymbol{\phi}$ by leveraging the relation built
    in Eq. ([2](#S2.E2 "In 2 Definition ‣ Gradient-based Bi-level Optimization for
    Deep Learning: A Survey")),'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '方程中内层问题（[2](#S2.E2 "In 2 Definition ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")）充当约束，并建立了$\boldsymbol{\phi}$和$\boldsymbol{\theta}$之间的关系。这里我们使用方程中的$\arg\min$形式（[2](#S2.E2
    "In 2 Definition ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")），但请注意，内层任务可以扩展到一些方程约束，我们将在第[3](#S3
    "3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")节进一步说明。在神经网络的本质中，可以使用梯度下降来估计$\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$。外层问题作为主要优化问题，通过利用方程中建立的关系（[2](#S2.E2
    "In 2 Definition ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")）来计算超梯度$\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$，以更新外层变量$\boldsymbol{\phi}$。'
- en: '|  | $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\phi}}.$
    |  | (3) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\phi}}.$
    |  | (3) |'
- en: 'This is called gradient-based bi-level optimization. When extended to the multi-task
    scenario to extract meta-knowledge on ${M}$ different tasks, the above formulation
    can be rewritten as:'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 这称为基于梯度的双层优化。当扩展到多任务场景中以提取${M}$个不同任务的元知识时，上述形式可以重写为：
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}_{i}(\boldsymbol{\phi}),\boldsymbol{\phi}).$
    |  | (4) |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}_{i}(\boldsymbol{\phi}),\boldsymbol{\phi}).$
    |  | (4) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\boldsymbol{\phi}).$
    |  | (5) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\boldsymbol{\phi}).$
    |  | (5) |'
- en: Here $\boldsymbol{\phi}$ symbolizes the meta-knowledge, denoting the knowledge
    that spans across multiple tasks, exemplified by aspects such as the model initialization.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这里$\boldsymbol{\phi}$象征着元知识，表示跨多个任务的知识，例如模型初始化等方面。
- en: 3 Task Formulation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 任务形式化
- en: 'The classification of bi-level optimization task formulation into single-task
    and multi-task types, as portrayed in Figure [1](#S3.F1 "Figure 1 ‣ 3 Task Formulation
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"), hinges on
    the kind of knowledge we are aiming to learn (Franceschi et al., [2018](#bib.bib27)).
    The single-task formulation focuses on the learning of hyperparameters within
    a single task, while the multi-task formulation is oriented towards the acquisition
    of meta-knowledge. These two formulations are expounded upon in Sections [3.1](#S3.SS1
    "3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey") and[3.2](#S3.SS2 "3.2 Multi-task formulation ‣ 3
    Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"),
    respectively.'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[1](#S3.F1 "Figure 1 ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")所示，将双层优化任务划分为单任务和多任务类型，取决于我们要学习的知识类型（Franceschi et
    al., [2018](#bib.bib27)）。单任务形式关注于单个任务中的超参数学习，而多任务形式则致力于元知识的获取。这两种形式在第[3.1](#S3.SS1
    "3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")节和第[3.2](#S3.SS2 "3.2 Multi-task formulation ‣ 3
    Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")节中分别阐述。'
- en: '![Refer to caption](img/c16cbcc93a763f709b8a74e5d416b607.png)'
  id: totrans-59
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c16cbcc93a763f709b8a74e5d416b607.png)'
- en: 'Figure 1: Summary of gradient-based bi-level optimization.'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：基于梯度的双层优化总结。
- en: 3.1 Single-task formulation
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 单任务表述
- en: The single-task formulation applies bi-level optimization on a single task and
    aims to learn hyperparameters for the task. Note that in this paper, the meaning
    of hyperparameter is not limited to its traditional meaning like regularization
    but has a broader meaning, referring to all single-task knowledge.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 单任务表述将双层优化应用于单一任务，旨在为该任务学习超参数。请注意，在本文中，超参数的意义不仅限于传统的意义，如正则化，而具有更广泛的意义，指所有单任务知识。
- en: A particular single-task problem can be deemed suitable for bi-level optimization
    if it meets two criteria. Firstly, it has a main optimization problem guiding
    the optimization of the outer variable. Secondly, a constraint exists between
    the inner and outer variables such that a differentiable relationship between
    these variables can be established. To elaborate, our first step is to identify
    the inner variable, denoted as $\boldsymbol{\theta}$, and the outer variable,
    $\boldsymbol{\phi}$. Next, we identify the main optimization component which optimizes
    the hyperparameters, which acts as the outer level problem. Finally, the inner
    level problem is framed by recognizing the constraint between these two variables,
    which further enables us to establish a differentiable relationship between them.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 特定的单任务问题如果满足两个标准，可以被认为适合双层优化。首先，它有一个主要的优化问题，指导外部变量的优化。其次，内外部变量之间存在约束，从而可以建立这些变量之间的可微关系。具体来说，我们的第一步是识别内变量，记作$\boldsymbol{\theta}$，和外变量$\boldsymbol{\phi}$。接下来，我们识别主要的优化组件，该组件优化超参数，作为外层问题。最后，通过识别这两个变量之间的约束来构建内层问题，这进一步使我们能够建立它们之间的可微关系。
- en: (1) A notable situation is when the constraint and the main optimization problem
    use different mathematical formulas, implying that they optimize entirely different
    problems. In these scenarios, the constraint typically arises organically, and
    its identification becomes straightforward. Examples include the energy constraint
    present in topology design (Christiansen et al., [2001](#bib.bib21)) or the bio-chemical
    constraint in protein representation learning(Chen et al., [2022b](#bib.bib13)).
    Conversely, when the main optimization problem and the constraint share the same
    mathematical formula, the formula needs to be broken down into two levels. This
    breakdown is usually accomplished by considering data variations between training
    and validation sets. The inner level, typically represented by the training loss,
    functions as the constraint in this setting (Franceschi et al., [2018](#bib.bib27)).
    This comprises the first criterion for our evaluation. (2) In some cases, the
    main optimization problem might not directly contain the outer variable. In such
    cases, the connection built at the inner level is utilized. This situation poses
    a challenge in formulating the outer level task, thereby leading us to introduce
    a second criterion. This second criterion classifies works based on whether the
    calculation of the hypergradient relies exclusively on the established inner level
    connection, $\frac{d\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))}{d\boldsymbol{\phi}}$,
    or not $\frac{d\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi})}{d\boldsymbol{\phi}}$.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: (1) 一种显著的情况是，当约束和主要优化问题使用不同的数学公式时，这意味着它们优化的是完全不同的问题。在这些情况下，约束通常会自然产生，其识别变得直接。例如，拓扑设计中的能量约束(Christiansen
    et al., [2001](#bib.bib21))或蛋白质表示学习中的生物化学约束(Chen et al., [2022b](#bib.bib13))。相反，当主要优化问题和约束共享相同的数学公式时，该公式需要被分解为两个层次。这种分解通常通过考虑训练集和验证集之间的数据变异来完成。内层，通常由训练损失表示，在这种设置下作为约束(Franceschi
    et al., [2018](#bib.bib27))。这构成了我们评估的第一个标准。 (2) 在某些情况下，主要优化问题可能不会直接包含外部变量。在这种情况下，利用在内层建立的连接。这种情况在制定外层任务时带来了挑战，从而引入了第二个标准。第二个标准根据超梯度的计算是否完全依赖于已建立的内层连接，$\frac{d\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))}{d\boldsymbol{\phi}}$，还是不依赖于$\frac{d\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi})}{d\boldsymbol{\phi}}$来对工作进行分类。
- en: 'To sum up, we consider the following four cases and discuss the corresponding
    examples for better illustration:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，我们考虑以下四种情况，并讨论相应的示例以便更好地说明：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 1). $\mathcal{L}^{in}$ and $\mathcal{L}^{out}$ share the same mathematical formula
    and the hypergradient only comes from the inner level connection $\boldsymbol{\theta}(\boldsymbol{\phi})$;
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 1). $\mathcal{L}^{in}$ 和 $\mathcal{L}^{out}$ 具有相同的数学公式，超梯度仅来自内层连接 $\boldsymbol{\theta}(\boldsymbol{\phi})$；
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 2). $\mathcal{L}^{in}$ and $\mathcal{L}^{out}$ share the same mathematical formula
    and the hypergradient comes from both the inner level connection $\boldsymbol{\theta}(\boldsymbol{\phi})$
    and the outer level objective explicitly;
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 2). $\mathcal{L}^{in}$ 和 $\mathcal{L}^{out}$ 具有相同的数学公式，超梯度来自内层连接 $\boldsymbol{\theta}(\boldsymbol{\phi})$
    和外层目标的显式组合；
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 3). $\mathcal{L}^{in}$ and $\mathcal{L}^{out}$ have different mathematical formulas
    and the hypergradient only comes from the inner level connection $\boldsymbol{\theta}(\boldsymbol{\phi})$;
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 3). $\mathcal{L}^{in}$ 和 $\mathcal{L}^{out}$ 具有不同的数学公式，超梯度仅来自内层连接 $\boldsymbol{\theta}(\boldsymbol{\phi})$；
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 4). $\mathcal{L}^{in}$ and $\mathcal{L}^{out}$ have different mathematical formulas
    and the hypergradient comes from both the inner level connection $\boldsymbol{\theta}(\boldsymbol{\phi})$
    and the outer level objective explicitly;
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 4). $\mathcal{L}^{in}$ 和 $\mathcal{L}^{out}$ 具有不同的数学公式，超梯度来自内层连接 $\boldsymbol{\theta}(\boldsymbol{\phi})$
    和外层目标的显式组合；
- en: 3.1.1 Same formula without explicit outer level hypergradient
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 没有显式外层超梯度的相同公式
- en: 'Table 2: Same formula without explicit outer level hypergradient.'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：没有显式外层超梯度的相同公式。
- en: '| Work | Inner Var $\boldsymbol{\theta}$ | Outer Var $\boldsymbol{\phi}$ |
    Inner Level Problem as Constraint | Outer Level Problem as Main Opt |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 内层变量 $\boldsymbol{\theta}$ | 外层变量 $\boldsymbol{\phi}$ | 内层问题作为约束 | 外层问题作为主要优化
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (a) | Model params | Regularization | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i},\boldsymbol{y}_{i})+\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| (a) | 模型参数 | 正则化 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i},\boldsymbol{y}_{i})+\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
- en: '| (b) | Model params | Learning rate | $\boldsymbol{\theta}^{*}({\boldsymbol{\phi}})=\rm{OPT}(\boldsymbol{\theta},\boldsymbol{\phi},\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| (b) | 模型参数 | 学习率 | $\boldsymbol{\theta}^{*}({\boldsymbol{\phi}})=\rm{OPT}(\boldsymbol{\theta},\boldsymbol{\phi},\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
- en: '| (c) | Model params | Perturbation | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i}+\boldsymbol{\phi}_{i},\boldsymbol{y}_{i}).$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}-l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| (c) | 模型参数 | 扰动 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},y_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i}+\boldsymbol{\phi}_{i},\boldsymbol{y}_{i}).$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}-l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
- en: '| (d) | Model params | Distilled data | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{\phi}_{i},\boldsymbol{y_{i}})\in\mathcal{D}_{syn}}l(\boldsymbol{\theta},\boldsymbol{\phi}_{i},\boldsymbol{y_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x_{j}},\boldsymbol{y_{j}})\in\mathcal{D}_{real}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x_{j}},\boldsymbol{y_{j}})$
    |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| (d) | 模型参数 | 蒸馏数据 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{\phi}_{i},\boldsymbol{y_{i}})\in\mathcal{D}_{syn}}l(\boldsymbol{\theta},\boldsymbol{\phi}_{i},\boldsymbol{y_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x_{j}},\boldsymbol{y_{j}})\in\mathcal{D}_{real}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x_{j}},\boldsymbol{y_{j}})$
    |'
- en: '| (e) | Model params | Data label | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},{\boldsymbol{\phi}_{i}})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i},{\boldsymbol{\phi}_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| (e) | 模型参数 | 数据标签 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},{\boldsymbol{\phi}_{i}})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{x}_{i},{\boldsymbol{\phi}_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
- en: '| (f) | Model params | Sample weight | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x_{i}},\boldsymbol{y_{i}})\in\mathcal{D}_{train}}\phi_{i}l(\boldsymbol{\theta},\boldsymbol{x_{i}},\boldsymbol{y_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},\boldsymbol{y}_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| (f) | 模型参数 | 样本权重 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x_{i}},\boldsymbol{y_{i}})\in\mathcal{D}_{train}}\phi_{i}l(\boldsymbol{\theta},\boldsymbol{x_{i}},\boldsymbol{y_{i}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{i},\boldsymbol{y}_{i})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    |'
- en: 'In instances where the inner and outer levels utilize the same mathematical
    formula, the objective of the task is the optimization of a single goal, viewed
    from two distinct perspectives. The outer variable often describes some aspects
    of the training process besides model parameters. The outer variable does not
    manifest explicitly in the main optimization problem, leading to a lack of explicit
    hypergradient at the outer level. In this case, the hypergradient of $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$
    is computed through the inner level connection as $\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})^{\top}}{\partial\boldsymbol{\phi}}$.
    Depending on the specific implications of $\phi$, outer variables can be divided
    into two categories: model-related outer variables and data-related outer variables.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 当内层和外层使用相同的数学公式时，任务的目标是从两个不同的视角优化一个单一目标。外部变量通常描述除了模型参数之外的训练过程的一些方面。外部变量在主要优化问题中不会显式体现，从而导致在外部层面缺乏明确的超梯度。在这种情况下，$\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$的超梯度通过内层连接计算为$\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})^{\top}}{\partial\boldsymbol{\phi}}$。根据$\phi$的具体含义，外部变量可以分为两类：与模型相关的外部变量和与数据相关的外部变量。
- en: Model-related. Model-related outer variables often describe the model optimization
    process, including (a) regularization parameters(Franceschi et al., [2018](#bib.bib27)),
    (b) learning rate (Franceschi et al., [2017](#bib.bib26)), etc, which are more
    common compared with data-related ones.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 与模型相关的。与模型相关的外部变量通常描述模型优化过程，包括（a）正则化参数（Franceschi et al., [2018](#bib.bib27)），（b）学习率（Franceschi
    et al., [2017](#bib.bib26)）等，这些比与数据相关的外部变量更为常见。
- en: '(a) Regularization is an essential component to avoid overfitting in machine
    learning models. However, identifying an effective regularization term is a challenging
    task, primarily because each evaluation of a single regularization term necessitates
    training the entire model. A model trained with a suitable regularization term
    is expected to produce a low error rate on the validation set. This observation
    leads Franceschi et al. ([2018](#bib.bib27)) to approach the selection of regularization
    as a bi-level optimization problem to enable direct and efficient optimization.
    As illustrated in Table[2](#S3.T2 "Table 2 ‣ 3.1.1 Same formula without explicit
    outer level hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣
    Gradient-based Bi-level Optimization for Deep Learning: A Survey")(a), the inner
    level loss on the training set acts as a constraint, establishing a differentiable
    connection between the model parameters $\theta$ and the regularization term.
    The outer level loss on the validation set forms the main optimization problem,
    aimed at optimizing the regularization through the inner level connection. In
    this context, $\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$ denotes the regularization
    term parameterized by $\boldsymbol{\phi}$ on $\boldsymbol{\theta}$. An example
    of a simple case is the L2 regularization, where $\Omega(\boldsymbol{\theta},{\phi})=\phi|\boldsymbol{\theta}|^{2}$.
    In the outer level loss, the regularization term is considered as zero, making
    it the same as the inner level loss in mathematical form. When dealing with high
    dimensionalities, traditional methods such as random search and bayesian optimization
    can prove inadequate. In contrast, the bi-level optimization framework offers
    an efficient approach to directly update high-dimensional hyperparameters, such
    as regularization, as demonstrated by Rendle ([2012](#bib.bib65)), Chen et al.
    ([2019](#bib.bib18)), and Lorraine et al. ([2020](#bib.bib50)).'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 正则化是避免机器学习模型过拟合的一个重要组成部分。然而，识别有效的正则化项是一个具有挑战性的任务，主要因为每次评估一个正则化项都需要训练整个模型。使用合适的正则化项训练的模型预期在验证集上产生低错误率。这一观察促使Franceschi等人（[2018](#bib.bib27)）将正则化选择视为一个双层优化问题，以实现直接和高效的优化。如表[2](#S3.T2
    "表 2 ‣ 3.1.1 没有明确外层超梯度的相同公式 ‣ 3.1 单任务公式 ‣ 3 任务公式 ‣ 基于梯度的双层优化在深度学习中的应用：综述")(a)所示，训练集上的内层损失作为约束，建立了模型参数$\theta$与正则化项之间的可微连接。验证集上的外层损失构成了主要的优化问题，旨在通过内层连接优化正则化。在这种情况下，$\Omega(\boldsymbol{\theta},\boldsymbol{\phi})$表示由$\boldsymbol{\phi}$在$\boldsymbol{\theta}$上参数化的正则化项。一个简单的例子是L2正则化，其中$\Omega(\boldsymbol{\theta},{\phi})=\phi|\boldsymbol{\theta}|^{2}$。在外层损失中，正则化项被视为零，使其在数学形式上与内层损失相同。处理高维度时，传统方法如随机搜索和贝叶斯优化可能显得不够充分。相比之下，双层优化框架提供了一种高效的方法来直接更新高维超参数，如正则化，正如Rendle（[2012](#bib.bib65)）、Chen等人（[2019](#bib.bib18)）和Lorraine等人（[2020](#bib.bib50)）所展示的那样。
- en: '![Refer to caption](img/4dcb712133b0e17eeb91c142e1569a52.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/4dcb712133b0e17eeb91c142e1569a52.png)'
- en: 'Figure 2: Model-related outer variables.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：模型相关的外部变量。
- en: '(b) Contrary to regularization parameters, which are explicitly present in
    the loss objective, some model-related outer variables exist only within the optimization
    process. The distinction between these two categories of variables is listed in
    Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Same formula without explicit outer level
    hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey"). One example of such a variable
    is the learning rate, as discussed by Franceschi et al. ([2017](#bib.bib26)).
    The approach to optimize the learning rate, as demonstrated in Table [2](#S3.T2
    "Table 2 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(b), resembles the regularization optimization process
    in the bi-level optimization context. The key difference lies in the way the differentiable
    connection is constructed. This connection is established by $\boldsymbol{\theta}^{*}({\boldsymbol{\phi}})=\rm{OPT}(\boldsymbol{\theta},\boldsymbol{\phi},\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}})$.
    Here, $\rm{OPT}$ represents an optimization process aimed at minimizing the training
    loss, which acts as the constraint. A simple case can be represented by a one-step
    Stochastic Gradient Descent (SGD), written as $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\boldsymbol{\theta}-\phi\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}^{\top}}$.
    In this equation, the outer variable ${\phi}$ represents the learning rate $\eta$.
    Though the inner level problem is represented through the perspective of an optimizer,
    fundamentally it is still the same math objective being optimized as in the outer
    level loss. This learning rate-learning procedure exhibits some similarities to
    meta-learned optimization, which we will discuss further in Section [3.2.2](#S3.SS2.SSS2
    "3.2.2 Optimizer ‣ 3.2 Multi-task formulation ‣ 3 Task Formulation ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey").'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 与明确存在于损失目标中的正则化参数相反，一些与模型相关的外部变量仅存在于优化过程中。这两类变量的区别见于图[2](#S3.F2 "图 2 ‣ 3.1.1
    无显式外层超梯度的相同公式 ‣ 3.1 单任务表述 ‣ 3 任务表述 ‣ 基于梯度的双层优化在深度学习中的调查")。其中一个例子是学习率，如Franceschi等人所讨论的([2017](#bib.bib26))。优化学习率的方法，如表[2](#S3.T2
    "表 2 ‣ 3.1.1 无显式外层超梯度的相同公式 ‣ 3.1 单任务表述 ‣ 3 任务表述 ‣ 基于梯度的双层优化在深度学习中的调查")(b)所示，类似于双层优化背景下的正则化优化过程。关键区别在于可微连接的构建方式。这个连接由$\boldsymbol{\theta}^{*}({\boldsymbol{\phi}})=\rm{OPT}(\boldsymbol{\theta},\boldsymbol{\phi},\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}})$建立。这里，$\rm{OPT}$表示一个旨在最小化训练损失的优化过程，作为约束。一个简单的例子可以用一步随机梯度下降（SGD）表示，写作$\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\boldsymbol{\theta}-\phi\frac{\partial\mathcal{L}(\boldsymbol{\theta},\mathcal{D}_{train})}{\partial\boldsymbol{\theta}^{\top}}$。在这个方程中，外部变量${\phi}$表示学习率$\eta$。尽管内部层问题是通过优化器的视角表示的，但从根本上讲，它仍然是优化外层损失的相同数学目标。这种学习率-学习过程与元学习优化有一些相似之处，我们将在第[3.2.2节](#S3.SS2.SSS2
    "3.2.2 优化器 ‣ 3.2 多任务表述 ‣ 3 任务表述 ‣ 基于梯度的双层优化在深度学习中的调查")中进一步讨论。
- en: 'Data-related. Transitioning from the discussion on model-related outer variables,
    we now turn our attention to data-related variables. As illustrated in Figure[3](#S3.F3
    "Figure 3 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"), either the data point $(\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    itself or its associated weights can be treated as the outer variable. These can
    be updated via bi-level optimization across a spectrum of research areas. This
    includes (c) adversarial attack, (d) data distillation, (e) label learning, and
    (f) sample reweighting, among others.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 数据相关。从模型相关的外部变量讨论过渡到数据相关的变量，我们现在将注意力转向数据相关的变量。如图[3](#S3.F3 "图 3 ‣ 3.1.1 无显式外层超梯度的相同公式
    ‣ 3.1 单任务表述 ‣ 3 任务表述 ‣ 基于梯度的双层优化在深度学习中的调查")所示，数据点$(\boldsymbol{x}_{i},\boldsymbol{y}_{i})$本身或其相关权重可以被视为外部变量。这些可以通过跨多个研究领域的双层优化进行更新。这包括（c）对抗攻击，（d）数据蒸馏，（e）标签学习，以及（f）样本重新加权等。
- en: '(c) Adversarial attacks represent an effort to identify data perturbations,
    denoted as $\boldsymbol{\phi}$, that lead the model to perform poorly on the validation
    set. This concept is further elucidated in Table [2](#S3.T2 "Table 2 ‣ 3.1.1 Same
    formula without explicit outer level hypergradient ‣ 3.1 Single-task formulation
    ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")(c), showcasing how it forms a bi-level optimization problem (Biggio
    et al., [2012](#bib.bib7); Yuan & Wu, [2021](#bib.bib87)). In this context, $\boldsymbol{\phi}_{i}$
    signifies the perturbation added to the sample $\boldsymbol{x}_{i}$. The inner
    level acts as a constraint, creating a differentiable connection between these
    perturbations $\boldsymbol{\phi}_{i}$ and the model parameters $\boldsymbol{\theta}$.
    This connection is achieved by minimizing the training loss. Concurrently, the
    outer level updates the perturbation $\boldsymbol{\phi}$ by maximizing the validation
    loss. Through this, we can effectively pinpoint adversarial attacks, represented
    by $\boldsymbol{\phi}_{i}$. The outer level loss, with zero perturbation, can
    be viewed as being the same mathmatical form as the inner level loss.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '(c) 对抗性攻击是识别数据扰动的努力，记作 $\boldsymbol{\phi}$，这些扰动会导致模型在验证集上的表现不佳。这个概念在表 [2](#S3.T2
    "Table 2 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(c) 中进一步阐明，展示了它如何形成一个双层优化问题（Biggio 等人，[2012](#bib.bib7);
    Yuan & Wu，[2021](#bib.bib87)）。在这个背景下，$\boldsymbol{\phi}_{i}$ 表示添加到样本 $\boldsymbol{x}_{i}$
    上的扰动。内部层作为约束，创建这些扰动 $\boldsymbol{\phi}_{i}$ 和模型参数 $\boldsymbol{\theta}$ 之间的可微连接。通过最小化训练损失来实现这个连接。同时，外部层通过最大化验证损失来更新扰动
    $\boldsymbol{\phi}$。通过这种方式，我们可以有效地定位对抗性攻击，这些攻击由 $\boldsymbol{\phi}_{i}$ 表示。外部层损失在零扰动情况下，可以视为与内部层损失具有相同的数学形式。'
- en: '(d) Data distillation techniques  (Wang et al., [2018](#bib.bib77); Lei & Tao,
    [2023](#bib.bib44)) aim to encapsulate the knowledge from a large training dataset
    into a significantly smaller one for the purpose of compression. This objective
    is accomplished by training a model on the smaller dataset and expecting it to
    deliver strong performance on the larger one, an approach that aligns with the
    framework of a bi-level optimization problem as demonstrated in Table[2](#S3.T2
    "Table 2 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(d). Within this context, $\mathcal{D}_{real}$ is
    the dataset consisting of real data, whereas $\mathcal{D}_{syn}$ is the dataset
    made up of synthesized data. The inner level establishes the connection between
    the $i^{th}$ data point $\boldsymbol{\phi}_{i}$ and the model parameters $\boldsymbol{\theta}$
    by minimizing the training loss. Simultaneously, the outer optimization level
    updates the synthesized $\boldsymbol{\phi}$ to ensure effective performance on
    the real data, serving as the main optimization component. Intriguingly, Nguyen
    et al. ([2020](#bib.bib57)) leverage the correspondence between infinitely-wide
    neural networks and kernels to achieve remarkable results in data distillation.
    Furthermore, the concept of data distillation has been effectively applied to
    black-box optimization, as demonstrated by Chen et al. ([2022a](#bib.bib12)) and
    Chen et al. ([2023a](#bib.bib14)), yielding impressive outcomes.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '(d) 数据蒸馏技术（Wang 等，[2018](#bib.bib77); Lei & Tao，[2023](#bib.bib44)）旨在将来自大规模训练数据集的知识浓缩到一个显著较小的数据集中，以实现压缩目的。这个目标通过在较小的数据集上训练模型并期望其在较大数据集上表现良好来实现，这种方法符合表[2](#S3.T2
    "Table 2 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(d)所示的双层优化问题框架。在这种背景下，$\mathcal{D}_{real}$ 是包含真实数据的数据集，而
    $\mathcal{D}_{syn}$ 是由合成数据构成的数据集。内部层通过最小化训练损失来建立 $i^{th}$ 数据点 $\boldsymbol{\phi}_{i}$
    和模型参数 $\boldsymbol{\theta}$ 之间的联系。同时，外部优化层更新合成的 $\boldsymbol{\phi}$ 以确保在真实数据上的有效性能，作为主要的优化组件。有趣的是，Nguyen
    等人（[2020](#bib.bib57)）利用无限宽神经网络与核之间的对应关系在数据蒸馏中取得了显著成果。此外，数据蒸馏的概念已被有效应用于黑箱优化，如
    Chen 等人（[2022a](#bib.bib12)）和 Chen 等人（[2023a](#bib.bib14)）所展示，取得了令人印象深刻的成果。'
- en: '(e) Label learning strategies, such as those proposed by Algan & Ulusoy ([2021](#bib.bib1))
    and Wu et al. ([2021](#bib.bib80)), consider the label $\boldsymbol{y_{i}}$ as
    an outer variable that is parameterized by $\boldsymbol{\phi}$. Distinct from
    data distillation methods, label learning strategies do not endeavor to reduce
    the size of the dataset. The principal aim of this learning approach is to learn
    cleaner labels that can enhance model performance under label noise, with the
    guidance of a clean dataset. This process can be conceptualized as a bi-level
    optimization problem as laid out in Table [2](#S3.T2 "Table 2 ‣ 3.1.1 Same formula
    without explicit outer level hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task
    Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")
    (e), where the main optimization task is to optimize the label against the validation
    loss.'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: (e) 标签学习策略，例如 Algan & Ulusoy（[2021](#bib.bib1)）和 Wu 等（[2021](#bib.bib80)）提出的策略，将标签
    $\boldsymbol{y_{i}}$ 视为由 $\boldsymbol{\phi}$ 参数化的外部变量。与数据蒸馏方法不同，标签学习策略不旨在减少数据集的大小。这种学习方法的主要目标是学习更干净的标签，从而在标签噪声下提升模型性能，并借助干净的数据集进行指导。这一过程可以被概念化为一个双层优化问题，如表[2](#S3.T2
    "表 2 ‣ 3.1.1 带有显式外部层超梯度的相同公式 ‣ 3.1 单任务公式 ‣ 3 任务公式 ‣ 基于梯度的双层优化在深度学习中的应用综述")（e）所述，其中主要优化任务是优化标签以对抗验证损失。
- en: '![Refer to caption](img/bab535c51cb541fb1e895cc30c5f1d01.png)'
  id: totrans-94
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/bab535c51cb541fb1e895cc30c5f1d01.png)'
- en: 'Figure 3: Data-related outer variables.'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：与数据相关的外部变量。
- en: '(f) Several studies (Ren et al., [2018](#bib.bib64); Hu et al., [2019](#bib.bib37))
    have put forth the idea of assigning an instance weight $\phi_{i}$ to each data
    point $(\boldsymbol{x_{i}},\boldsymbol{y_{i}})$ to enhance the model’s training
    process. These instance weights can be considered as outer variables and learned
    under the guidance of an unbiased validation set. As depicted in Table[2](#S3.T2
    "Table 2 ‣ 3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1
    Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"), the methodology of instance reweighting shares
    similarities with label learning methods and can be encapsulated within a bi-level
    optimization framework. The initial work by Hu et al. ([2019](#bib.bib37)) considers
    each instance weight as a learnable parameter, which however posed scalability
    challenges for large datasets. To circumvent this issue, subsequent works(Shu
    et al., [2019](#bib.bib69)) devise an alternative solution - a weighting network.
    This network is designed to parameterize instance weights, wherein the input is
    the instance loss, and the output becomes the instance weight, enhancing scalability
    for large datasets. This innovative approach has been further employed by Xu et al.
    ([2021](#bib.bib82)), who parameterize the atom distance in a molecular structure
    using a message passing neural network, a mechanism designed to encapsulate graph
    information effectively. It is crucial to note that efficient optimization is
    closely tied to the effective parameterization of high-dimensional hyperparameters.
    Achieving this involves the use of a meticulously designed neural network/input
    that caters to the demands of the specific problem at hand, ensuring both efficiency
    and accuracy in the optimization process.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: (f) 一些研究（Ren 等，[2018](#bib.bib64)；Hu 等，[2019](#bib.bib37)）提出了为每个数据点 $(\boldsymbol{x_{i}},\boldsymbol{y_{i}})$
    分配一个实例权重 $\phi_{i}$ 的想法，以增强模型的训练过程。这些实例权重可以视为外部变量，并在无偏验证集的指导下进行学习。如表[2](#S3.T2
    "表 2 ‣ 3.1.1 带有显式外部层超梯度的相同公式 ‣ 3.1 单任务公式 ‣ 3 任务公式 ‣ 基于梯度的双层优化在深度学习中的应用综述")所示，实例重加权的方法与标签学习方法有相似之处，并可以纳入双层优化框架中。Hu
    等的初步工作（[2019](#bib.bib37)）将每个实例权重视为可学习的参数，但这对大数据集带来了可扩展性挑战。为解决这一问题，后续工作（Shu 等，[2019](#bib.bib69)）提出了一种替代方案——加权网络。该网络旨在对实例权重进行参数化，其中输入为实例损失，输出为实例权重，从而提高大数据集的可扩展性。这一创新方法已被
    Xu 等（[2021](#bib.bib82)）进一步采用，他们使用消息传递神经网络对分子结构中的原子距离进行参数化，该机制旨在有效地封装图信息。需要特别注意的是，高维超参数的有效优化与高效的参数化密切相关。实现这一点需要使用精心设计的神经网络/输入，以满足特定问题的要求，从而确保优化过程中的效率和准确性。
- en: 3.1.2 Same formula with explicit outer level hypergradient
  id: totrans-97
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 带有显式外部层超梯度的相同公式
- en: 'Table 3: Same formula with explicit outer level hypergradient.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：带有显式外部层超梯度的相同公式。
- en: '| Work | Inner Var $\boldsymbol{\theta}$ | Outer Var $\boldsymbol{\phi}$ |
    Inner Level Problem as Constraint | Outer Level Problem as Main Opt |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 内部变量 $\boldsymbol{\theta}$ | 外部变量 $\boldsymbol{\phi}$ | 作为约束的内部级别问题
    | 作为主要优化目标的外部级别问题 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (g) | Follower unit | Leader unit | ${\theta}^{*}({\phi})=\mathop{\arg\min}_{{\phi}}p(\phi+\theta)\theta-C_{f}(\theta)$
    | $\mathop{\arg\min}_{{\phi}}p(\phi+{\theta}^{*}({\phi}))\phi-C_{l}(\phi)$ |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| (g) | 追随者单位 | 领导者单位 | ${\theta}^{*}({\phi})=\mathop{\arg\min}_{{\phi}}p(\phi+\theta)\theta-C_{f}(\theta)$
    | $\mathop{\arg\min}_{{\phi}}p(\phi+{\theta}^{*}({\phi}))\phi-C_{l}(\phi)$ |'
- en: '| (h) | Model params | Network arch | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},\boldsymbol{y}_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| (h) | 模型参数 | 网络结构 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{(\boldsymbol{x}_{i},\boldsymbol{y}_{i})\in\mathcal{D}_{train}}l(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x}_{i},\boldsymbol{y}_{i})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{(\boldsymbol{x}_{j},\boldsymbol{y}_{j})\in\mathcal{D}_{val}}l(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\boldsymbol{x}_{j},\boldsymbol{y}_{j})$
    |'
- en: '| (i) | Model params | Perturbation | $\boldsymbol{\Theta}^{*}(\boldsymbol{\Phi})=\mathop{\arg\min}_{\boldsymbol{\Theta}}\mathcal{L}(\boldsymbol{\Theta},\boldsymbol{\Phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\Phi}}\mathcal{L}(\boldsymbol{\Theta}(\boldsymbol{\Phi}),\boldsymbol{\Phi})$
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| (i) | 模型参数 | 扰动 | $\boldsymbol{\Theta}^{*}(\boldsymbol{\Phi})=\mathop{\arg\min}_{\boldsymbol{\Theta}}\mathcal{L}(\boldsymbol{\Theta},\boldsymbol{\Phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\Phi}}\mathcal{L}(\boldsymbol{\Theta}(\boldsymbol{\Phi}),\boldsymbol{\Phi})$
    |'
- en: In instances where the inner and outer levels of the optimization share the
    same mathematical objective, it is possible for the hypergradient to be derived
    directly from the outer level. However, such instances are relatively infrequent
    compared to the previously discussed scenarios. We surmise that this is likely
    because, in most cases, the outer variable can be directly updated along with
    the inner variable, either through alternate or joint optimization, without resorting
    to the more complex approach of bi-level optimization.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 在内外优化级别具有相同数学目标的情况下，超梯度可能直接从外部级别中推导出来。然而，这种情况相比之前讨论的场景相对较少。我们推测这可能是因为在大多数情况下，外部变量可以直接与内部变量一起通过交替或联合优化进行更新，而不需要采用更复杂的双层优化方法。
- en: '![Refer to caption](img/886615350bc9ff9cf0232bfc8a58f67e.png)'
  id: totrans-105
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/886615350bc9ff9cf0232bfc8a58f67e.png)'
- en: 'Figure 4: Stackelberg game as bi-level optimization.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：Stackelberg 博弈作为双层优化。
- en: '(g) In the context of a Stackelberg game (Von Stackelberg, [2010](#bib.bib74)),
    there are two competing entities - a leading company and a following company,
    as depicted in Figure [4](#S3.F4 "Figure 4 ‣ 3.1.2 Same formula with explicit
    outer level hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣
    Gradient-based Bi-level Optimization for Deep Learning: A Survey"). These companies
    compute with each other over the production quantities, where the leader produces
    $\phi$ units and the follower produces $\theta$ units. The combined price of their
    output can be expressed as $p(\phi+\theta)$. The cost functions for the leader
    and the follower are denoted as $C_{l}(\phi)$ and $C_{f}(\theta)$ respectively.
    The resulting profits for the leader and follower can then be calculated as $p(\phi+\theta)\phi-C_{l}(\phi)$
    and $p(\phi+\theta)\theta-C_{f}(\theta)$. In the Stackelberg game scenario, it
    is assumed that the leader is aware of the follower’s best response. This situation
    can be aptly framed as a bi-level optimization problem, as detailed in Table [3](#S3.T3
    "Table 3 ‣ 3.1.2 Same formula with explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")(g). Importantly, the leader cannot directly optimize $\phi$
    at the outer level without taking into account the differentiable constraint imposed
    at the inner level. This interdependence validates the necessity for the bi-level
    optimization framework.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '在 Stackelberg 博弈（Von Stackelberg, [2010](#bib.bib74)）的背景下，有两个竞争实体——一个领导公司和一个跟随公司，如图
    [4](#S3.F4 "Figure 4 ‣ 3.1.2 Same formula with explicit outer level hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey") 所示。这些公司在生产数量上进行计算，其中领导者生产 $\phi$ 单位，跟随者生产 $\theta$
    单位。它们输出的总价格可以表示为 $p(\phi+\theta)$。领导者和跟随者的成本函数分别表示为 $C_{l}(\phi)$ 和 $C_{f}(\theta)$。然后可以计算出领导者和跟随者的利润，分别为
    $p(\phi+\theta)\phi-C_{l}(\phi)$ 和 $p(\phi+\theta)\theta-C_{f}(\theta)$。在 Stackelberg
    博弈场景中，假设领导者了解跟随者的最佳响应。这种情况可以恰当地框架为一个双层优化问题，如表 [3](#S3.T3 "Table 3 ‣ 3.1.2 Same
    formula with explicit outer level hypergradient ‣ 3.1 Single-task formulation
    ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")(g) 所详细描述。重要的是，领导者不能直接在外层优化 $\phi$，而不考虑内层施加的可微约束。这种相互依赖验证了双层优化框架的必要性。'
- en: '![Refer to caption](img/67079bb35fb233c111793c00f2e4f5ac.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/67079bb35fb233c111793c00f2e4f5ac.png)'
- en: 'Figure 5: Continuous relaxation of the neural architecture in DARTS.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: DARTS 中神经架构的连续松弛。'
- en: '(h) The task of searching for an optimal neural network architecture within
    a defined search space is a critical determinant of the performance of that task.
    As a neural network architecture can be considered a type of hyperparameter, it
    appears logical to model the search process as a bi-level optimization problem
    to enable effective updates, as discussed in Section [3.1.1](#S3.SS1.SSS1 "3.1.1
    Same formula without explicit outer level hypergradient ‣ 3.1 Single-task formulation
    ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey"). However, this task is not straightforward as the network architecture
    is non-differentiable and cannot be directly optimized using gradient methods.
    To address this, Liu et al. ([2019](#bib.bib47)) suggest a continuous relaxation
    of the architecture representation, parameterized by $\boldsymbol{\phi}$ as depicted
    in Figure[5](#S3.F5 "Figure 5 ‣ 3.1.2 Same formula with explicit outer level hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"), and update $\boldsymbol{\phi}$ to pinpoint superior
    neural network architectures. This scenario can be framed as a bi-level optimization
    problem as elaborated in Table[3](#S3.T3 "Table 3 ‣ 3.1.2 Same formula with explicit
    outer level hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣
    Gradient-based Bi-level Optimization for Deep Learning: A Survey")(h). Here, the
    inner level loss on the training set serves as a constraint and builds a differentiable
    relationship between the model parameters $\theta$ and the network architectures.
    At the same time, the outer level loss on the validation set constitutes the main
    optimization problem, aiming to optimize the network architectures. As there is
    no ground truth for neural architectures, the outer variable $\boldsymbol{\phi}$
    cannot be viewed as a constant as in instance weighting cases(Shu et al., [2019](#bib.bib69);
    Chen et al., [2021](#bib.bib11)). Therefore, it is necessary to explicitly update
    the neural architectures within the context of the outer level loss. It’s worth
    noting that the first-order DARTS method treats $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    as $\boldsymbol{\theta}^{*}$, independent of $\boldsymbol{\phi}$. In this scenario,
    bi-level optimization simplifies to alternate optimization. As a result, the performance
    of the first-order DARTS is typically inferior compared to the original second-order
    DARTS. It’s notable that the conversion of discrete variables to continuous ones
    holds significant importance in gradient-based bi-level optimization as it offers
    an efficient method to adjust discrete parameters. This technique finds its application
    in earlier label learning methodologies, as demonstrated in the works by (Algan
    & Ulusoy, [2021](#bib.bib1); Wu et al., [2021](#bib.bib80)). In these cases, discrete
    one-hot labels are morphed into soft labels for optimization. However, in such
    instances, the conversion to continuous forms isn’t as crucial as in our present
    context, owing to the existence of alternate methods like instance reweighting
    for managing label noise.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '在定义的搜索空间内寻找最佳神经网络架构的任务是决定该任务性能的关键因素。由于神经网络架构可以被视为一种超参数，因此将搜索过程建模为一个双层优化问题，以实现有效更新，似乎是合乎逻辑的，正如第[3.1.1](#S3.SS1.SSS1
    "3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")节中讨论的。然而，这个任务并不简单，因为网络架构是不可微分的，不能直接使用梯度方法进行优化。为了解决这个问题，Liu
    等人（[2019](#bib.bib47)）建议对架构表示进行连续松弛，使用$\boldsymbol{\phi}$参数化，如图[5](#S3.F5 "Figure
    5 ‣ 3.1.2 Same formula with explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")所示，并更新$\boldsymbol{\phi}$以确定优越的神经网络架构。这个场景可以被构建为一个双层优化问题，如表[3](#S3.T3
    "Table 3 ‣ 3.1.2 Same formula with explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")所述。在这里，训练集上的内层损失作为约束，建立了模型参数$\theta$与网络架构之间的可微关系。同时，验证集上的外层损失构成了主要的优化问题，旨在优化网络架构。由于神经架构没有真实值，外层变量$\boldsymbol{\phi}$不能像实例加权情况下那样被视为常数（Shu
    等人，[2019](#bib.bib69)；Chen 等人，[2021](#bib.bib11)）。因此，在外层损失的背景下，必须显式更新神经架构。值得注意的是，一阶DARTS方法将$\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$视为$\boldsymbol{\theta}^{*}$，与$\boldsymbol{\phi}$无关。在这种情况下，双层优化简化为交替优化。因此，一阶DARTS的性能通常低于原始的二阶DARTS。值得注意的是，将离散变量转换为连续变量在基于梯度的双层优化中具有重要意义，因为它提供了一种有效调整离散参数的方法。这项技术在早期标签学习方法中得到了应用，如（Algan
    & Ulusoy，[2021](#bib.bib1)；Wu 等人，[2021](#bib.bib80)）的研究所示。在这些情况下，离散的one-hot标签被转化为软标签以进行优化。然而，在这种情况下，与我们目前的背景相比，将其转换为连续形式并不是那么关键，因为存在像实例重加权这样的替代方法来处理标签噪声。'
- en: '(i) Dictionary learning methods (Mairal et al., [2010](#bib.bib55)) also belong
    to this category. These methods aim to find the sparse code $\boldsymbol{\Theta}\in\mathbb{R}^{d\times
    p}$ and the dictionary $\boldsymbol{\Phi}\in\mathbb{R}^{m\times d}$ to reconstruct
    the noise measurements $\boldsymbol{Y}\in\mathbb{R}^{m\times p}$. Note that $p$
    represents the dataset size, $d$ represents the dictionary size and $m$ represents
    the feature size of the dictionary feature. The loss function can be written as:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (i) 字典学习方法（Mairal 等，[2010](#bib.bib55)）也属于这一类别。这些方法旨在找到稀疏编码 $\boldsymbol{\Theta}\in\mathbb{R}^{d\times
    p}$ 和字典 $\boldsymbol{\Phi}\in\mathbb{R}^{m\times d}$ 以重建噪声测量 $\boldsymbol{Y}\in\mathbb{R}^{m\times
    p}$。请注意，$p$ 代表数据集大小，$d$ 代表字典大小，$m$ 代表字典特征的特征大小。损失函数可以写作：
- en: '|  | $\arg\min_{\boldsymbol{\Theta},\boldsymbol{\Phi}}\mathcal{L}(\boldsymbol{\Theta},\boldsymbol{\Phi})=\frac{1}{2}\&#124;\boldsymbol{\Phi}\boldsymbol{\Theta}-\boldsymbol{Y}\&#124;^{2}+\gamma\&#124;\boldsymbol{\Theta}\&#124;_{1}.$
    |  | (6) |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|  | $\arg\min_{\boldsymbol{\Theta},\boldsymbol{\Phi}}\mathcal{L}(\boldsymbol{\Theta},\boldsymbol{\Phi})=\frac{1}{2}\&#124;\boldsymbol{\Phi}\boldsymbol{\Theta}-\boldsymbol{Y}\&#124;^{2}+\gamma\&#124;\boldsymbol{\Theta}\&#124;_{1}.$
    |  | (6) |'
- en: 'In this context, $\gamma$ is a regularization parameter. Rather than employing
    a slow alternate optimization over $\boldsymbol{\Theta}$ and $\boldsymbol{\Phi}$,
    which ignores their explicit relationship (that a given dictionary $\boldsymbol{\Phi}$
    should determine the sparse code $\boldsymbol{\Theta}$), this can be effectively
    formulated as a bi-level problem, as detailed in Table [3](#S3.T3 "Table 3 ‣ 3.1.2
    Same formula with explicit outer level hypergradient ‣ 3.1 Single-task formulation
    ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey") (i). This approach significantly enhances the rate of convergence.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '在这种情况下，$\gamma$ 是一个正则化参数。与其采用对 $\boldsymbol{\Theta}$ 和 $\boldsymbol{\Phi}$
    进行缓慢的交替优化（这种方法忽视了它们的明确关系，即给定的字典 $\boldsymbol{\Phi}$ 应该决定稀疏编码 $\boldsymbol{\Theta}$），不如将其有效地表述为一个双层问题，如表[3](#S3.T3
    "Table 3 ‣ 3.1.2 Same formula with explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey") (i) 所详细说明的那样。这种方法显著提高了收敛速度。'
- en: 3.1.3 Different formulas without explicit hypergradient
  id: totrans-114
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 没有显式超梯度的不同公式
- en: 'Table 4: Different formulas without explicit hypergradient.'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：没有显式超梯度的不同公式。
- en: '| Work | Inner Var $\boldsymbol{\theta}$ | Outer Var $\boldsymbol{\phi}$ |
    Inner Level Problem as Constraint | Outer Level Problem as Main Opt |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 内层变量 $\boldsymbol{\theta}$ | 外层变量 $\boldsymbol{\phi}$ | 内层问题作为约束 | 外层问题作为主要优化
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (j) | Conformation | Atom distance | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{D}_{\boldsymbol{\phi}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(\boldsymbol{\phi}))$
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| (j) | 形状 | 原子距离 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{D}_{\boldsymbol{\phi}})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(\boldsymbol{\phi}))$
    |'
- en: '| (k) | Model params | Pretrain hyperparams | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}_{prt})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}_{ft})$
    |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| (k) | 模型参数 | 预训练超参数 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}_{prt})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}_{ft})$
    |'
- en: '| (l) | System state | Topology design | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))$
    |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| (l) | 系统状态 | 拓扑设计 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))$
    |'
- en: '| (m) | Layer output | Model params | $\boldsymbol{\theta}=E(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{x},\boldsymbol{y})$
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| (m) | 层输出 | 模型参数 | $\boldsymbol{\theta}=E(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{x},\boldsymbol{y})$
    |'
- en: '| (n) | Layer output | Model params | $\dot{\boldsymbol{\theta}(t)}=E(\boldsymbol{\theta}(t),\boldsymbol{\phi},t),\quad\boldsymbol{\theta}(0)=\boldsymbol{\theta}_{0}$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(t,\boldsymbol{\phi}),\boldsymbol{x},\boldsymbol{y})$
    |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| (n) | 层输出 | 模型参数 | $\dot{\boldsymbol{\theta}(t)}=E(\boldsymbol{\theta}(t),\boldsymbol{\phi},t),\quad\boldsymbol{\theta}(0)=\boldsymbol{\theta}_{0}$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}(t,\boldsymbol{\phi}),\boldsymbol{x},\boldsymbol{y})$
    |'
- en: Generally, the inner and outer level objectives share a similar mathematical
    structure, with the validation set used to gauge the performance of the model
    parameters. However, there are instances where the inner and outer level objectives
    differ substantially due to their respective optimization of entirely distinct
    problems.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，内层和外层目标具有类似的数学结构，验证集用于衡量模型参数的性能。然而，在某些情况下，由于内层和外层目标分别优化完全不同的问题，它们之间可能存在显著差异。
- en: '(j) The study by Xu et al. ([2021](#bib.bib82)) exemplifies such a case. In
    this research, the prediction of molecular conformation is divided into two levels,
    each addressing a distinct problem. The inner level problem aims to construct
    the molecular conformation with the predicted atom distances by leveraging the
    physical constraint and the outer level problem aims to align the molecular conformation
    with the ground truth conformations, functioning as the main optimization component.
    As explicated in Table[4](#S3.T4 "Table 4 ‣ 3.1.3 Different formulas without explicit
    hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey")(j), this setup forms a bi-level
    optimization problem where $\mathcal{L}^{in}$ and $\mathcal{L}^{out}$ denote the
    reconstruction and alignment losses, respectively. Here, $\boldsymbol{D}_{\boldsymbol{\phi}}$
    signifies the predicted atom distances, parameterized by $\boldsymbol{\phi}$,
    while the inner variable, $\boldsymbol{\theta}$, represents the predicted molecular
    conformation. The culmination of this process is a finely-tuned neural network
    capable of accurately predicting atoms’ distances.'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '(j) Xu 等人 ([2021](#bib.bib82)) 的研究就是一个例子。在这项研究中，分子构象的预测被分为两个层次，每个层次解决一个不同的问题。内层问题旨在利用物理约束构建具有预测原子距离的分子构象，而外层问题则旨在将分子构象与实际构象对齐，作为主要优化组件。如表[4](#S3.T4
    "Table 4 ‣ 3.1.3 不同公式没有显式超梯度 ‣ 3.1 单任务公式 ‣ 3 任务公式 ‣ 基于梯度的双层优化深度学习: 综述")(j)所述，这种设置形成了一个双层优化问题，其中
    $\mathcal{L}^{in}$ 和 $\mathcal{L}^{out}$ 分别表示重建损失和对齐损失。这里，$\boldsymbol{D}_{\boldsymbol{\phi}}$
    表示由 $\boldsymbol{\phi}$ 参数化的预测原子距离，而内层变量 $\boldsymbol{\theta}$ 表示预测的分子构象。这个过程的最终结果是一个精细调整的神经网络，能够准确预测原子的距离。'
- en: '![Refer to caption](img/10d765487ab353c9f2a22adb17cf3da8.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/10d765487ab353c9f2a22adb17cf3da8.png)'
- en: 'Figure 6: Pretraining and finetuning as bi-level optimization.'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '图 6: 预训练和微调作为双层优化。'
- en: (k) Pretraining is a crucial strategy in fields such as computer vision and
    natural language processing, where identifying the right pretraining hyperparameters
    can significantly improve the performance on downstream tasks. Raghu et al. ([2021](#bib.bib61))
    propose an approach to optimize pretraining hyperparameters based on downstream
    task performance.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: (k) 预训练是在计算机视觉和自然语言处理等领域中的关键策略，其中正确的预训练超参数选择可以显著提高下游任务的性能。Raghu 等人 ([2021](#bib.bib61))
    提出了基于下游任务性能优化预训练超参数的方法。
- en: 'This process of pretraining and fine-tuning can be effectively represented
    as a bi-level optimization problem, as illustrated in Table [4](#S3.T4 "Table
    4 ‣ 3.1.3 Different formulas without explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")(k). In this context, $\mathcal{D}_{prt}$ and $\mathcal{D}_{ft}$
    denote the pretraining and fine-tuning datasets, respectively. At the inner level,
    the loss on the pretraining set serves as a constraint and establishes a differentiable
    connection between the model parameters and the pretraining hyperparameters. The
    aim at this level is to minimize the pretraining loss. At the outer level, the
    focus is on optimizing the pretraining hyperparameters by minimizing the loss
    on the fine-tuning set. This is the main optimization task, and it leverages the
    differentiable connection established at the inner level. In this way, the pretraining
    hyperparameters can be effectively tuned to enhance downstream task performances.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '预训练和微调的过程可以有效地表示为一个双层优化问题，如表[4](#S3.T4 "Table 4 ‣ 3.1.3 Different formulas
    without explicit hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task Formulation
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")(k)所示。在这个背景下，$\mathcal{D}_{prt}$
    和 $\mathcal{D}_{ft}$ 分别表示预训练和微调数据集。在内层，预训练集上的损失作为约束，并建立了模型参数与预训练超参数之间的可微连接。这个层级的目标是最小化预训练损失。在外层，重点是通过最小化微调集上的损失来优化预训练超参数。这是主要的优化任务，并利用了在内层建立的可微连接。通过这种方式，可以有效地调整预训练超参数，以提高下游任务的表现。'
- en: '(l) The design of a topology that minimizes system cost is an important problem
    in science (Christiansen et al., [2001](#bib.bib21); Zehnder et al., [2021](#bib.bib88)).
    In the context of topology design, the system reaches an equilibrium state, denoted
    by $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$, once a topology $\boldsymbol{\phi}$
    is provided. This equilibrium state is achieved by minimizing the energy function
    $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$. Following this, the
    system cost can be calculated as $\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))$.
    This process can be articulated as a bi-level optimization problem, as detailed
    in Table [4](#S3.T4 "Table 4 ‣ 3.1.3 Different formulas without explicit hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey") (l). The incorporation of an energy constraint also
    proves valuable in better simulating soft-body physics(Rojas et al., [2021](#bib.bib66)).'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '设计一个能够最小化系统成本的拓扑结构是科学中的一个重要问题（Christiansen 等，[2001](#bib.bib21)；Zehnder 等，[2021](#bib.bib88)）。在拓扑设计的背景下，一旦提供了拓扑
    $\boldsymbol{\phi}$，系统就会达到一个平衡状态，用 $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    表示。这个平衡状态通过最小化能量函数 $\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$ 来实现。随后，系统成本可以计算为
    $\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}))$。这个过程可以表述为一个双层优化问题，如表[4](#S3.T4
    "Table 4 ‣ 3.1.3 Different formulas without explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey") (l) 中详细说明。引入能量约束在更好地模拟软体物理方面也被证明是有价值的（Rojas 等，[2021](#bib.bib66)）。'
- en: 'This concept extends to implicit layers, which encompass (m) Deep Equilibrium
    Models (DEQ) (Bai et al., [2019](#bib.bib5)) and (n) Neural Ordinary Differential
    Equations (NeuralODE)(Chen et al., [2018](#bib.bib16)). Both models entail an
    equation constraint. DEQ enhances the effectiveness of neural network (NN) representation
    $\boldsymbol{\theta}$ with input $\boldsymbol{x}$ by employing an infinite-depth
    layer $E$. This is expressed as $\boldsymbol{\theta}=E(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x})$,
    which establishes a relationship between the equilibrium point $\boldsymbol{\theta}$
    and the model parameters $\boldsymbol{\phi}$. Subsequently, the supervised loss
    is utilized to update the model parameters $\phi$ via this relationship, thus
    forming a bi-level optimization problem, as described in Table[4](#S3.T4 "Table
    4 ‣ 3.1.3 Different formulas without explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey") (m). NeuralODE follows a similar structure as displayed in
    Table[4](#S3.T4 "Table 4 ‣ 3.1.3 Different formulas without explicit hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey") (n). The sole difference resides in the equation
    constraint applied in this context, which is an Ordinary Differential Equation:
    $\dot{\boldsymbol{\theta}(t)}=E(\boldsymbol{\theta}(t),\boldsymbol{\phi},t)$.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '这个概念扩展到隐式层，其中包括 (m) 深度平衡模型（DEQ）（Bai 等，[2019](#bib.bib5)）和 (n) 神经常微分方程（NeuralODE）（Chen
    等，[2018](#bib.bib16)）。这两种模型都包含一个方程约束。DEQ 通过使用一个无限深度的层 $E$，提升了神经网络（NN）表示 $\boldsymbol{\theta}$
    在输入 $\boldsymbol{x}$ 下的效果。这可以表示为 $\boldsymbol{\theta}=E(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{x})$，建立了平衡点
    $\boldsymbol{\theta}$ 与模型参数 $\boldsymbol{\phi}$ 之间的关系。随后，监督损失用于通过这种关系更新模型参数 $\phi$，从而形成一个双层优化问题，如表[4](#S3.T4
    "Table 4 ‣ 3.1.3 Different formulas without explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")（m）中所述。NeuralODE 遵循与表[4](#S3.T4 "Table 4 ‣ 3.1.3 Different
    formulas without explicit hypergradient ‣ 3.1 Single-task formulation ‣ 3 Task
    Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")（n）中显示的类似结构。唯一的不同在于应用于此上下文的方程约束是常微分方程：$\dot{\boldsymbol{\theta}(t)}=E(\boldsymbol{\theta}(t),\boldsymbol{\phi},t)$。'
- en: 3.1.4 Different formulas with explicit hypergradient
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.4 具有明确超梯度的不同公式
- en: 'Table 5: Different formulas without explicit hypergradient.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：不同的公式在没有明确超梯度的情况下。
- en: '| Work | Inner Var $\boldsymbol{\theta}$ | Outer Var $\boldsymbol{\phi}$ |
    Inner Level Problem as Constraint | Outer Level Problem as Main Opt |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 内层变量 $\boldsymbol{\theta}$ | 外层变量 $\boldsymbol{\phi}$ | 内层问题作为约束 | 外层问题作为主要优化
    |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| (o) | Model params | Surrogate loss params | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}{\mathcal{L}^{in}}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\mathcal{L}(\boldsymbol{\theta},\mathcal{D}^{val})),{\mathcal{L}^{in}}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{val}))$
    |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| (o) | 模型参数 | 替代损失参数 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}{\mathcal{L}^{in}}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\mathcal{L}(\boldsymbol{\theta},\mathcal{D}^{val})),{\mathcal{L}^{in}}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{val}))$
    |'
- en: '| (p) | Seq params | Struc params | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi})$
    |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| (p) | 序列参数 | 结构参数 | $\boldsymbol{\theta}^{*}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi})$
    | $\mathop{\arg\min}_{\boldsymbol{\phi}}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\boldsymbol{\phi})$
    |'
- en: In situations where the inner and outer level objectives are distinct from each
    other, some scenarios feature a tangible hypergradient. Such cases include (o)
    learning the surrogate loss function (Grabocka et al., [2019](#bib.bib30)) and
    (p) protein representation learning(Chen et al., [2022b](#bib.bib13)), among others.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在内层和外层目标彼此不同的情况下，一些场景会出现具体的超梯度。这些情况包括 (o) 学习替代损失函数（Grabocka 等，[2019](#bib.bib30)）和
    (p) 蛋白质表示学习（Chen 等，[2022b](#bib.bib13)），以及其他情况。
- en: '(o) In machine learning, proxies of misclassification rate such as cross-entropy
    are often used to approximate actual losses, primarily due to their non-differentiable
    and discontinuous nature. To bridge this gap, a study by Grabocka et al. ([2019](#bib.bib30))
    introduces a surrogate neural network for accurate approximation of these true
    losses. This process involves a bi-level optimization formulation, as outlined
    in Table[5](#S3.T5 "Table 5 ‣ 3.1.4 Different formulas with explicit hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(o). The inner level focuses on minimizing the surrogate
    loss ${\mathcal{L}_{in}}$ by optimizing model parameters $\boldsymbol{\theta}$,
    while the outer level refines the surrogate loss $\boldsymbol{\phi}$ to resemble
    the true loss ${\mathcal{L}}$. The main objective here is to minimize the distance
    between the true loss $\mathcal{L}$ and the surrogate loss $\mathcal{L}^{in}$
    through the outer level optimization process. This method facilitates the effective
    and virtual minimization of any non-differentiable and non-decomposable loss function,
    such as the misclassification rate.'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '在机器学习中，像交叉熵这样的误分类率代理常用于近似实际损失，主要是由于它们的不连续性和不可微性。为了解决这一问题，Grabocka 等人（[2019](#bib.bib30)）提出了一种替代神经网络，用于准确近似这些真实损失。这个过程涉及一个双层优化公式，如表[5](#S3.T5
    "Table 5 ‣ 3.1.4 Different formulas with explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")(o)所述。内部层专注于通过优化模型参数$\boldsymbol{\theta}$来最小化替代损失${\mathcal{L}_{in}}$，而外部层则将替代损失$\boldsymbol{\phi}$调整为接近真实损失${\mathcal{L}}$。这里的主要目标是通过外部层优化过程最小化真实损失$\mathcal{L}$与替代损失$\mathcal{L}^{in}$之间的距离。这种方法有助于有效地和虚拟地最小化任何不可微和不可分解的损失函数，如误分类率。'
- en: '(p) Protein pretraining plays a pivotal role in facilitating downstream tasks,
    and incorporating bio-chemical constraints into the learning process can enhance
    its performance. In this context, the protein modeling neural network deals with
    two types of information: sequential representation parameterized by $\boldsymbol{\theta}$
    and structural representation parameterized by $\boldsymbol{\phi}$. The study
    by Chen et al. ([2022b](#bib.bib13)) utilizes the bio-chemical constraint that
    every protein sequence is associated with a particular protein structure, and
    formulates protein pretraining as a bi-level optimization problem, as detailed
    in Table[5](#S3.T5 "Table 5 ‣ 3.1.4 Different formulas with explicit hypergradient
    ‣ 3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")(p). As seen, the inner level establishes the connection
    between the sequential and structural information by minimizing the negative mutual
    information loss, $\mathcal{L}^{in}$, acting as the biochemical constraint. Simultaneously,
    the outer level refines the structural parameters by minimizing the pretraining
    loss, $\mathcal{L}^{out}$, serving as the main optimization component. Overall,
    this pretraining scheme bolsters the performance of protein representation learning.'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '蛋白质预训练在促进下游任务中扮演了关键角色，将生物化学约束纳入学习过程可以提升其性能。在这种背景下，蛋白质建模神经网络处理两种信息：由$\boldsymbol{\theta}$参数化的序列表示和由$\boldsymbol{\phi}$参数化的结构表示。Chen
    等人（[2022b](#bib.bib13)）利用每个蛋白质序列与特定蛋白质结构相关联的生物化学约束，并将蛋白质预训练公式化为一个双层优化问题，如表[5](#S3.T5
    "Table 5 ‣ 3.1.4 Different formulas with explicit hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")(p)所述。可以看到，内部层通过最小化负的互信息损失$\mathcal{L}^{in}$，作为生物化学约束，来建立序列信息和结构信息之间的联系。同时，外部层通过最小化预训练损失$\mathcal{L}^{out}$，作为主要优化组件，来优化结构参数。总体而言，这种预训练方案提升了蛋白质表示学习的性能。'
- en: 3.2 Multi-task formulation
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 多任务公式
- en: 'Multi-task formulation, in contrast to single-task formulation, seeks to extract
    meta-knowledge spanning across various tasks. While the choice of hyperparameters
    in a single-task formulation is broad and diverse as we illustrate in Section [3.1](#S3.SS1
    "3.1 Single-task formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"), in the context of multi-task formulation, the choice
    of meta-knowledge tends to be more constrained, making its formulation relatively
    straightforward. Primarily, two types of meta-knowledge are embodied by the outer
    variable in multi-task formulation: model initialization and optimizer, which
    we will elaborate upon in the following subsections.'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 与单任务方法相比，多任务方法旨在提取跨任务的元知识。虽然单任务方法中的超参数选择广泛且多样，如我们在第[3.1](#S3.SS1 "3.1 单任务方法
    ‣ 3 任务方法 ‣ 基于梯度的双层优化在深度学习中的应用：综述")节中所述，但在多任务方法的背景下，元知识的选择趋于更为受限，使得其公式化相对简单。主要有两种类型的元知识在多任务方法中体现：模型初始化和优化器，我们将在以下小节中详细阐述。
- en: 3.2.1 Model initialization
  id: totrans-142
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 模型初始化
- en: 'The first kind of meta-knowledge is model initialization, which is useful in
    the data-scarce scenario (Hiller et al., [2022](#bib.bib36); Liu et al., [2020](#bib.bib48);
    Li et al., [2017](#bib.bib46)). The work (Finn et al., [2017](#bib.bib25)) proposes
    Model-Agnostic Meta-Learning (MAML) to train the parameters of the model across
    a family of tasks to generate a good model initialization. A good model initialization
    means a few steps on this initialization reach a good solution. Given a model
    initialization $\boldsymbol{\phi}$, the model parameters fine-tuned on the task
    $i$ after a gradient descent step can be written as:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 第一种元知识是模型初始化，这在数据稀缺的场景中非常有用（Hiller 等，[2022](#bib.bib36)；Liu 等，[2020](#bib.bib48)；Li
    等，[2017](#bib.bib46)）。工作（Finn 等，[2017](#bib.bib25)）提出了模型无关元学习（MAML），用于训练跨任务系列的模型参数，以生成良好的模型初始化。良好的模型初始化意味着在该初始化上进行几步就能达到较好的解决方案。给定模型初始化
    $\boldsymbol{\phi}$，经过一次梯度下降步骤后，任务 $i$ 上微调的模型参数可以表示为：
- en: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\boldsymbol{\phi}-\eta\frac{\partial\mathcal{L}_{i}^{in}(\boldsymbol{\phi},\mathcal{D}^{train}_{i})}{\partial\boldsymbol{\phi}^{\top}}.$
    |  | (7) |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\boldsymbol{\phi}-\eta\frac{\partial\mathcal{L}_{i}^{in}(\boldsymbol{\phi},\mathcal{D}^{train}_{i})}{\partial\boldsymbol{\phi}^{\top}}.$
    |  | (7) |'
- en: 'The updated model parameters are expected to perform well on the validation
    set:'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的模型参数预计在验证集上表现良好。
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (8) |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (8) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\phi},\mathcal{D}^{train}_{i}).$
    |  | (9) |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\phi},\mathcal{D}^{train}_{i}).$
    |  | (9) |'
- en: 'This forms a bi-level optimization problem as shown in Figure [7](#S3.F7 "Figure
    7 ‣ 3.2.1 Model initialization ‣ 3.2 Multi-task formulation ‣ 3 Task Formulation
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"). MAML is
    applicable to a wide range of learning tasks including classification, regression,
    etc.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 这形成了一个如图[7](#S3.F7 "图7 ‣ 3.2.1 模型初始化 ‣ 3.2 多任务方法 ‣ 3 任务方法 ‣ 基于梯度的双层优化在深度学习中的应用：综述")所示的双层优化问题。MAML适用于包括分类、回归等在内的各种学习任务。
- en: A single initialization may not be able to generalize to all tasks and thus
    some research work propose to learn different initialization for different tasks.
    The method (Vuorio et al., [2019](#bib.bib75)) modulates the initialization according
    to the task mode and adapts quickly by gradient updates. The approach(Yao et al.,
    [2019](#bib.bib84)) clusters tasks hierarchically and adapts the initialization
    according to the cluster. According to the task formulation, maybe only part of
    the model parameters need to be updated, which can save much memory considering
    millions of parameters for the model. The work(Lee et al., [2019](#bib.bib42))
    fixes the user embedding and item embedding and only updates the interaction parameters
    in the meta-learned phase. The method(Rusu et al., [2018](#bib.bib67)) proposes
    to map the high dimensional parameter space to a low-dimensional latent where
    they can perform MAML.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 单一初始化可能无法推广到所有任务，因此一些研究工作提出为不同任务学习不同的初始化。方法(Vuorio et al., [2019](#bib.bib75))根据任务模式调节初始化，并通过梯度更新快速适应。方法(Yao
    et al., [2019](#bib.bib84))按层次聚类任务，并根据集群调整初始化。根据任务的表述，可能只需要更新部分模型参数，这可以节省大量内存，因为模型的参数可能高达数百万。工作(Lee
    et al., [2019](#bib.bib42))固定用户嵌入和项目嵌入，仅在元学习阶段更新交互参数。方法(Rusu et al., [2018](#bib.bib67))提出将高维参数空间映射到低维潜在空间，在其中执行MAML。
- en: '![Refer to caption](img/b5140381c5161bcd152299bca14f98d6.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b5140381c5161bcd152299bca14f98d6.png)'
- en: 'Figure 7: Illustration of MAML.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：MAML的示意图。
- en: Besides, some analyses (Zou et al., [2021](#bib.bib91)) are also proposed for
    choosing the inner loop learning rate. Last but not least, domain knowledge such
    as biological prior(Yao et al., [2021](#bib.bib85)) can also be incorporated into
    the MAML modeling where they propose a region localization network to customize
    the initialization to each assay. Tack et al. ([2022](#bib.bib72)) adapt the temporal
    ensemble of the meta-learner to generate the target model. Hiller et al. ([2022](#bib.bib36))
    develop a novel method to increase adaptation speed inspired by preconditioning.
    Guan et al. ([2022](#bib.bib34)) analyze modern meta-learning algorithms and give
    a detailed analysis of stability.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，某些分析(Zou et al., [2021](#bib.bib91))也提出了选择内循环学习率的方法。最后但同样重要的是，领域知识如生物先验(Yao
    et al., [2021](#bib.bib85))也可以融入到MAML建模中，他们提出了一个区域定位网络，以为每个测定定制初始化。Tack et al.
    ([2022](#bib.bib72))适配了元学习者的时间集成以生成目标模型。Hiller et al. ([2022](#bib.bib36))开发了一种受预处理启发的增加适应速度的新方法。Guan
    et al. ([2022](#bib.bib34))分析了现代元学习算法，并对稳定性进行了详细分析。
- en: 3.2.2 Optimizer
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 优化器
- en: 'Another kind of meta-knowledge across tasks is an optimizer. Previous optimizers
    such as Adam are designed by hand and may be sub-optimal. The work (Andrychowicz
    et al., [2016](#bib.bib2)) proposes to learn an optimizer for a family of tasks.
    As shown in Figure[8](#S3.F8 "Figure 8 ‣ 3.2.2 Optimizer ‣ 3.2 Multi-task formulation
    ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey"), the learned optimizer is parameterized by $\boldsymbol{\phi}$ where
    an LSTM takes the state as input and outputs the update. In this way, for the
    $i_{th}$ task, the model parameters $\boldsymbol{\theta}$ are connected with the
    optimizer parameters via:'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '另一种跨任务的元知识是优化器。以前的优化器如Adam是手动设计的，可能效果次优。工作(Andrychowicz et al., [2016](#bib.bib2))提出为一组任务学习优化器。如图[8](#S3.F8
    "Figure 8 ‣ 3.2.2 Optimizer ‣ 3.2 Multi-task formulation ‣ 3 Task Formulation
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")所示，学习的优化器由$\boldsymbol{\phi}$参数化，其中LSTM将状态作为输入并输出更新。这样，对于第$i$个任务，模型参数$\boldsymbol{\theta}$通过以下方式与优化器参数连接：'
- en: '|  | $\boldsymbol{\theta}_{t+1}^{i}(\boldsymbol{\phi})=\boldsymbol{\theta}_{t}^{i}+g_{t}^{i}(\boldsymbol{\phi}).$
    |  | (10) |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}_{t+1}^{i}(\boldsymbol{\phi})=\boldsymbol{\theta}_{t}^{i}+g_{t}^{i}(\boldsymbol{\phi}).$
    |  | (10) |'
- en: '|  | $[g_{t}^{i}(\boldsymbol{\phi}),h_{t+1}^{i}]=\rm{OPT}(\bigtriangledown_{\boldsymbol{\theta}_{t}^{i}}l_{t},h_{t}^{i},\boldsymbol{\phi}).$
    |  | (11) |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  | $[g_{t}^{i}(\boldsymbol{\phi}),h_{t+1}^{i}]=\rm{OPT}(\bigtriangledown_{\boldsymbol{\theta}_{t}^{i}}l_{t},h_{t}^{i},\boldsymbol{\phi}).$
    |  | (11) |'
- en: 'Here $\rm{OPT}$ denotes the learned LSTM optimizer and $h$ represents the hidden
    state. The optimizer is updated to improve the validation performance over a horizon
    $\rm{T}$, and this can be written as:'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 这里$\rm{OPT}$表示学习到的LSTM优化器，$h$表示隐藏状态。优化器会被更新以改善在$\rm{T}$范围内的验证性能，这可以写成：
- en: '|  | $\boldsymbol{\phi}^{*}=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{t=1}^{T}\mathcal{L}_{out}(\boldsymbol{\theta}_{t}^{i}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (12) |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\phi}^{*}=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{t=1}^{T}\mathcal{L}_{out}(\boldsymbol{\theta}_{t}^{i}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (12) |'
- en: 'Overall, this can be formulated as a bi-level optimization problem where the
    inner level builds the connection between the model parameters $\boldsymbol{\theta}$
    and the optimizer parameters $\boldsymbol{\phi}$ by minimizing the training loss,
    and the outer level updates the optimizer by minimizing the validation loss. Formally,
    the formulation of bi-level optimization across a family of $\rm{M}$ tasks can
    be written as:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这可以被表述为一个双层优化问题，其中内层通过最小化训练损失来建立模型参数$\boldsymbol{\theta}$与优化器参数$\boldsymbol{\phi}$之间的联系，而外层通过最小化验证损失来更新优化器。正式地，跨越一系列$\rm{M}$任务的双层优化的表述可以写为：
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\sum_{t=1}^{\top}\mathcal{L}_{out}(\boldsymbol{\theta}_{t}^{i}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (13) |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\sum_{t=1}^{\top}\mathcal{L}_{out}(\boldsymbol{\theta}_{t}^{i}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (13) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{t+1}^{i}(\boldsymbol{\phi})$
    | $\displaystyle=\boldsymbol{\theta}_{t}^{i}+g_{t}^{i}(\boldsymbol{\phi});[g_{t}^{i}(\boldsymbol{\phi}),h_{t+1}^{i}]=\rm{OPT}(\bigtriangledown_{\boldsymbol{\theta}_{t}^{i}}l_{t},h_{t}^{i},\boldsymbol{\phi}).$
    |  | (14) |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{t+1}^{i}(\boldsymbol{\phi})$
    | $\displaystyle=\boldsymbol{\theta}_{t}^{i}+g_{t}^{i}(\boldsymbol{\phi});[g_{t}^{i}(\boldsymbol{\phi}),h_{t+1}^{i}]=\rm{OPT}(\bigtriangledown_{\boldsymbol{\theta}_{t}^{i}}l_{t},h_{t}^{i},\boldsymbol{\phi}).$
    |  | (14) |'
- en: To optimize millions of parameters, the LSTM is designed to be coordinatewise,
    which means every parameter shares the same LSTM. This greatly alleviates the
    computational burden.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 为了优化数百万个参数，LSTM被设计为逐坐标优化，这意味着每个参数共享相同的LSTM。这大大减轻了计算负担。
- en: '![Refer to caption](img/57c5499ab334cdca0a7bf4e5b374b67c.png)'
  id: totrans-163
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/57c5499ab334cdca0a7bf4e5b374b67c.png)'
- en: 'Figure 8: LSTM optimizer.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：LSTM优化器。
- en: Besides, some preprocessing and postprocessing techniques are proposed to rescale
    the inputs and the outputs of LSTM into a normal range. One key challenge of learning
    to optimize is the generalization to longer horizons or unseen optimizees and
    many research works try to mitigate this challenge. The work (Metz et al., [2019](#bib.bib56))
    proposes to use an MLP layer instead of an LSTM to parameterize the optimizer
    and smooth the loss scope by dynamic gradient reweighting.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，提出了一些预处理和后处理技术，将LSTM的输入和输出重新缩放到正常范围内。学习优化的一个关键挑战是对更长时间范围或未见优化对象的泛化，许多研究工作尝试缓解这一挑战。工作(Metz
    et al., [2019](#bib.bib56))建议使用MLP层代替LSTM来参数化优化器，并通过动态梯度重加权平滑损失范围。
- en: The approach (Wichrowska et al., [2017](#bib.bib79)) proposes a hierarchical
    RNN formed by three RNN layers that could communicate from bottom to up and this
    hierarchical design achieves better generalization. The work(Lv et al., [2017](#bib.bib52))
    proposes training tricks such as random scaling to improve the generalization.
    Besides the above, some work(Knyazev et al., [2021](#bib.bib40))(Kang et al.,
    [2021](#bib.bib39)) proposes to directly predict parameters, which can be seen
    as a specially learned optimizer without any gradient update.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 方法(Wichrowska et al., [2017](#bib.bib79))提出了一种由三个RNN层组成的层次化RNN，这些层次可以自下而上进行通信，这种层次化设计实现了更好的泛化。工作(Lv
    et al., [2017](#bib.bib52))提出了诸如随机缩放等训练技巧，以提高泛化能力。除此之外，一些工作(Knyazev et al., [2021](#bib.bib40))(Kang
    et al., [2021](#bib.bib39))建议直接预测参数，这可以视为一种特殊学习的优化器，无需任何梯度更新。
- en: Recent works also try to incorporate the existing optimizer into the optimizer
    learning, which can leverage both the existing prior and the learning capacity.
    The key is to replace the constant (i.e. scalar/vector/matrix) in the existing
    optimizer with learnable parameters. HyperAdam (Wang et al., [2019](#bib.bib76))
    learns the combination weights and decay rates according to the task. The method(Gregor
    & LeCun, [2010](#bib.bib33)) first writes the ISTA as a recurrent formula and
    then parameterizes the coefficients as the outer variable. The approach(Shu et al.,
    [2020](#bib.bib70)) designs a Meta-LR-Schedule-Net which takes the loss value
    and the state as input and outputs the learning rate for the current iteration.
    The work(Ravi & Larochelle, [2016](#bib.bib63)) proposes to parameterize the weight
    coefficient and the learning rate.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究还尝试将现有优化器融入优化器学习中，这可以利用现有的先验知识和学习能力。关键在于用可学习的参数替换现有优化器中的常量（即标量/向量/矩阵）。HyperAdam（Wang
    et al., [2019](#bib.bib76)）根据任务学习组合权重和衰减率。该方法（Gregor & LeCun, [2010](#bib.bib33)）首先将ISTA写成递归公式，然后将系数参数化为外部变量。该方法（Shu
    et al., [2020](#bib.bib70)）设计了一个Meta-LR-Schedule-Net，它将损失值和状态作为输入，输出当前迭代的学习率。该工作（Ravi
    & Larochelle, [2016](#bib.bib63)）提出将权重系数和学习率进行参数化。
- en: Besides the model initialization and the parameterized optimizer, there is some
    other meta-knowledge like the loss function learning (Gao et al., [2022](#bib.bib28)).
    They propose to learn a generic loss function to train a robust DNN model that
    can perform well on out-of-distribution tasks. Given a parametric loss function
    as the outer variable $\boldsymbol{\phi}$, the inner level yields the optimized
    model parameters $\boldsymbol{\theta}(\boldsymbol{\phi})$ by minimizing the training
    loss on the source domain. Then a good parametric loss can be identified by minimizing
    the validation loss on the target domain. The above process formulates a bi-level
    optimization problem, which is given by
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 除了模型初始化和参数化优化器，还有一些其他的元知识，比如损失函数学习（Gao et al., [2022](#bib.bib28)）。他们提出学习一个通用的损失函数，以训练一个在分布外任务中表现良好的稳健DNN模型。给定一个作为外部变量的参数化损失函数$\boldsymbol{\phi}$，内层通过最小化源领域上的训练损失来获得优化的模型参数$\boldsymbol{\theta}(\boldsymbol{\phi})$。然后，通过最小化目标领域上的验证损失来识别一个好的参数化损失。上述过程构造了一个双层优化问题，其形式为：
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{N}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (15) |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{N}\mathcal{L}^{out}(\boldsymbol{\theta}^{*}(\boldsymbol{\phi}),\mathcal{D}_{val}^{i}).$
    |  | (15) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{i=1}^{M}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}_{train}^{i}).$
    |  | (16) |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}^{*}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\sum_{i=1}^{M}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}_{train}^{i}).$
    |  | (16) |'
- en: Here $\mathcal{L}^{out}$ is a loss function to measure the performance on target
    domains and $N$, and $M$ represent the number of target domain and source domain
    tasks, respectively. They further propose to compute the hyper-gradient by leveraging
    the implicit function theorem.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 这里$\mathcal{L}^{out}$是一个用于衡量目标领域性能的损失函数，$N$和$M$分别代表目标领域任务和源领域任务的数量。他们进一步提出通过利用隐函数定理来计算超梯度。
- en: 4 Optimization
  id: totrans-172
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 优化
- en: 'Gradient-based bi-level optimization requires the hypergradient computation
    of $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$ in the outer level. The hypergradient
    $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$ can be unrolled via the chain
    rule as:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 基于梯度的双层优化需要在外层计算超梯度$\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$。超梯度$\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$可以通过链式法则展开为：
- en: '|  | $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\phi}}.$
    |  | (17) |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\phi}}.$
    |  | (17) |'
- en: 'Here $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}$
    often involves second-order gradient computation and thus are resource demanding.
    There are generally four types of methods to calculate $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}$:
    explicit gradient update in Section [4.1](#S4.SS1 "4.1 Explicit gradient update
    ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"),
    explicit proxy update in Section [4.2](#S4.SS2 "4.2 Explicit proxy update ‣ 4
    Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"),
    implicit function update in Section [4.3](#S4.SS3 "4.3 Implicit function update
    ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"),
    and closed-form method in Section [4.4](#S4.SS4 "4.4 Closed-form update ‣ 4 Optimization
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"), where the
    previous three are approximation methods for general functions with the difference
    in how to build the connection between $\boldsymbol{\theta}$ and $\boldsymbol{\phi}$
    and the last one is an accurate method for certain functions. Subsequent to these
    detailed descriptions, a comprehensive analysis comparing their time and space
    complexities will be carried out in Section[4.5](#S4.SS5 "4.5 Comparative Analysis.
    ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey").'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '这里 $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}$
    通常涉及二阶梯度计算，因此资源需求较高。一般有四种方法来计算 $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}$：在第[4.1节](#S4.SS1
    "4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")中的显式梯度更新，第[4.2节](#S4.SS2 "4.2 Explicit proxy update
    ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")中的显式代理更新，第[4.3节](#S4.SS3
    "4.3 Implicit function update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")中的隐式函数更新，以及第[4.4节](#S4.SS4 "4.4 Closed-form update
    ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")中的封闭形式方法，其中前三种是对一般函数的近似方法，区别在于如何建立
    $\boldsymbol{\theta}$ 和 $\boldsymbol{\phi}$ 之间的联系，最后一种则是对某些函数的准确方法。随后在第[4.5节](#S4.SS5
    "4.5 Comparative Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")将对它们的时间和空间复杂度进行全面分析。'
- en: 4.1 Explicit gradient update
  id: totrans-176
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 显式梯度更新
- en: 'The explicit gradient update is the most straight-forward one which approximates
    $\boldsymbol{\theta}$ via some optimizer directly:'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 显式梯度更新是最直接的方法，它通过某种优化器直接逼近 $\boldsymbol{\theta}$：
- en: '|  | $\boldsymbol{\theta}_{t}=\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi}),\quad
    t=1,\cdots,T.$ |  | (18) |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}_{t}=\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi}),\quad
    t=1,\cdots,T.$ |  | (18) |'
- en: 'Here $T$ denotes the number of iterations, $\boldsymbol{\theta}$ represents
    the model parameters and other optimization variables like momentum, $\rm{OPT}$
    represents the optimization algorithm like SGD, and $\phi$ denotes the outer variable
    in the training process. Note that when $\rm{OPT}$ is the SGD optimizer and only
    one gradient descent step is considered, Eq. ([18](#S4.E18 "In 4.1 Explicit gradient
    update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")) becomes'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '这里 $T$ 表示迭代次数，$\boldsymbol{\theta}$ 代表模型参数和其他优化变量，如动量，$\rm{OPT}$ 代表优化算法，如 SGD，$\phi$
    表示训练过程中的外部变量。注意，当 $\rm{OPT}$ 是 SGD 优化器且仅考虑一次梯度下降步骤时，公式 ([18](#S4.E18 "In 4.1 Explicit
    gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")) 变为'
- en: '|  | $\boldsymbol{\theta}(\boldsymbol{\phi})=\boldsymbol{\theta}-\eta\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (19) |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}(\boldsymbol{\phi})=\boldsymbol{\theta}-\eta\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (19) |'
- en: 'In this case, we can compute the hypergradient as:'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我们可以计算超梯度如下：
- en: '|  | $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}=-\eta\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}.$
    |  | (20) |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}=-\eta\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}.$
    |  | (20) |'
- en: This process often requires the second-order gradient computation. In some cases,
    the first-order approximation can be adopted to replace the second-order gradient
    in (Liu et al., [2019](#bib.bib47); Finn et al., [2017](#bib.bib25); Nichol et al.,
    [2018](#bib.bib58)). Besides, Liu et al. ([2019](#bib.bib47)) uses the finite
    difference approximation technique to compute the second-order gradient efficiently.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 这个过程通常需要二阶梯度计算。在某些情况下，可以采用一阶近似来代替 (Liu et al., [2019](#bib.bib47); Finn et al.,
    [2017](#bib.bib25); Nichol et al., [2018](#bib.bib58)) 中的二阶梯度。此外，Liu et al. ([2019](#bib.bib47))
    使用有限差分近似技术来高效计算二阶梯度。
- en: '|  | $\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\approx\frac{\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta}^{+},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\phi}-\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta}^{-},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\phi}}}{2\epsilon},$
    |  | (21) |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}\approx\frac{\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta}^{+},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\phi}-\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta}^{-},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\phi}}}{2\epsilon},$
    |  | (21) |'
- en: 'where $\boldsymbol{\theta}^{\pm}=\boldsymbol{\theta}\pm\epsilon\frac{\partial\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}}$.
    This avoids the expensive computational cost of the Hessian matrix. Furthermore,
    the work (Deleu et al., [2022](#bib.bib22)) proposes to adopt infinitely small
    gradient steps to solve the inner level task, which leads to a continuous-time
    bi-level optimization solver:'
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\boldsymbol{\theta}^{\pm}=\boldsymbol{\theta}\pm\epsilon\frac{\partial\mathcal{L}^{out}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}}$。这避免了计算
    Hessian 矩阵的高昂成本。此外，工作（Deleu et al., [2022](#bib.bib22)）建议采用无穷小的梯度步长来解决内层任务，从而导致一个连续时间双层优化求解器：
- en: '|  | $\frac{d\boldsymbol{\theta}(t)}{dt}=\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (22) |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\boldsymbol{\theta}(t)}{dt}=\frac{\partial\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (22) |'
- en: In this way, the final output is the solution of an ODE. One great advantage
    of this formulation is making the fixed and discrete number of gradient steps
    the length of the trajectory, which serves as a continuous variable and is also
    learnable. This work also proposes to use forward mode differentiation to compute
    the hypergradient where the memory does not scale with the length of the trajectory.
    A similar continuous bi-level solver is used in Yuan & Wu ([2021](#bib.bib87)).
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 通过这种方式，最终输出是一个常微分方程的解。这种表述的一个重大优点是将固定和离散的梯度步数作为轨迹的长度，这既充当了一个连续变量，也可以学习。该工作还提出使用前向模式微分来计算超梯度，其中内存不会随着轨迹长度的增加而扩展。类似的连续双层求解器在
    Yuan & Wu ([2021](#bib.bib87)) 中使用。
- en: 'Generally speaking, the update is not limited to one step nor SGD optimizer,
    which makes the hypergradient computation process complicated. There are generally
    two modes (Franceschi et al., [2017](#bib.bib26)) to compute the hypergradient:
    forward mode and reverse mode.'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，更新不仅限于一步或 SGD 优化器，这使得超梯度计算过程变得复杂。计算超梯度通常有两种模式（Franceschi et al., [2017](#bib.bib26)）：前向模式和反向模式。
- en: 'Forward mode. Forward mode methods apply the chain rule to the composite functions:'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 前向模式。前向模式方法应用链式法则于复合函数：
- en: '|  | $\frac{d\boldsymbol{\theta}_{t}}{d\boldsymbol{\phi}}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}_{t-1}}\frac{d\boldsymbol{\theta}_{t-1}}{d\boldsymbol{\phi}}+\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}.$
    |  | (23) |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\boldsymbol{\theta}_{t}}{d\boldsymbol{\phi}}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}_{t-1}}\frac{d\boldsymbol{\theta}_{t-1}}{d\boldsymbol{\phi}}+\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}.$
    |  | (23) |'
- en: 'Then the matrics are defined as:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 然后矩阵被定义为：
- en: '|  | $\boldsymbol{Z}_{t}=\frac{d\boldsymbol{\theta}_{t}}{d\boldsymbol{\phi}},\quad\boldsymbol{A}_{t}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}_{t}},\quad\boldsymbol{B}_{t}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t},\boldsymbol{\phi})}{\partial\boldsymbol{\phi}_{t}}.\quad$
    |  | (24) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{Z}_{t}=\frac{d\boldsymbol{\theta}_{t}}{d\boldsymbol{\phi}},\quad\boldsymbol{A}_{t}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}_{t}},\quad\boldsymbol{B}_{t}=\frac{\partial\rm{OPT}(\boldsymbol{\theta}_{t},\boldsymbol{\phi})}{\partial\boldsymbol{\phi}_{t}}.\quad$
    |  | (24) |'
- en: 'Thus the Eq.([23](#S4.E23 "In 4.1 Explicit gradient update ‣ 4 Optimization
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")) can be written
    as:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，方程([23](#S4.E23 "In 4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey"))可以写成：'
- en: '|  | $\boldsymbol{Z}_{t}=\boldsymbol{A}_{t}\boldsymbol{Z}_{t-1}+\boldsymbol{B}_{t-1}.$
    |  | (25) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{Z}_{t}=\boldsymbol{A}_{t}\boldsymbol{Z}_{t-1}+\boldsymbol{B}_{t-1}.$
    |  | (25) |'
- en: 'In this way, $\boldsymbol{Z}_{T}$ can be written as:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 这样，$\boldsymbol{Z}_{T}$ 可以写成：
- en: '|  | $\displaystyle\boldsymbol{Z}_{T}$ | $\displaystyle=\boldsymbol{A}_{T}\boldsymbol{Z}_{T-1}+\boldsymbol{B}_{T-1}$
    |  | (26) |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{Z}_{T}$ | $\displaystyle=\boldsymbol{A}_{T}\boldsymbol{Z}_{T-1}+\boldsymbol{B}_{T-1}$
    |  | (26) |'
- en: '|  |  | $\displaystyle=\sum_{t=1}^{T}(\prod_{s=t+1}^{T}\boldsymbol{A}_{s})\boldsymbol{B}_{t}.$
    |  | (27) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=\sum_{t=1}^{T}(\prod_{s=t+1}^{T}\boldsymbol{A}_{s})\boldsymbol{B}_{t}.$
    |  | (27) |'
- en: which yields the final hypergradient.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 这将得出最终的超梯度。
- en: 'Reverse mode. The reverse mode approach originates from Lagrangian optimization.
    The Lagrangian of bi-level problems can be formulated as:'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 反向模式。反向模式方法源自拉格朗日优化。二层问题的拉格朗日可以被表述为：
- en: '|  | $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})=\mathcal{L}^{out}(\boldsymbol{\theta}_{T})+\sum_{t=1}^{T}\boldsymbol{\gamma}_{t}(\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})-\boldsymbol{\theta}_{t}).$
    |  | (28) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '|  | $\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})=\mathcal{L}^{out}(\boldsymbol{\theta}_{T})+\sum_{t=1}^{T}\boldsymbol{\gamma}_{t}(\rm{OPT}(\boldsymbol{\theta}_{t-1},\boldsymbol{\phi})-\boldsymbol{\theta}_{t}).$
    |  | (28) |'
- en: 'The main calculation of partial derivatives can be presented as follows:'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 偏导数的主要计算可以表示如下：
- en: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\theta}_{t}}=\boldsymbol{\gamma}_{t+1}\boldsymbol{A}_{t+1}-\boldsymbol{\gamma}_{t},\quad
    t\in\{1,\cdots,T-1\}.$ |  | (29) |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\theta}_{t}}=\boldsymbol{\gamma}_{t+1}\boldsymbol{A}_{t+1}-\boldsymbol{\gamma}_{t},\quad
    t\in\{1,\cdots,T-1\}.$ |  | (29) |'
- en: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\theta}_{T}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}_{T}}-\boldsymbol{\gamma}_{T}.$
    |  | (30) |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\theta}_{T}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}_{T}}-\boldsymbol{\gamma}_{T}.$
    |  | (30) |'
- en: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\phi}}=\sum_{t=1}^{T}\boldsymbol{\gamma}_{t}\boldsymbol{B}_{t}.$
    |  | (31) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\phi}}=\sum_{t=1}^{T}\boldsymbol{\gamma}_{t}\boldsymbol{B}_{t}.$
    |  | (31) |'
- en: 'Upon setting the partial derivatives in Eq.([29](#S4.E29 "In 4.1 Explicit gradient
    update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey")) and Eq.([30](#S4.E30 "In 4.1 Explicit gradient update ‣ 4 Optimization
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")) to zero,
    we can deduce the values of $\boldsymbol{\gamma}_{t}$. Incorporating this solution
    with Eq. ([31](#S4.E31 "In 4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey")), we find:'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '在将方程([29](#S4.E29 "In 4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based
    Bi-level Optimization for Deep Learning: A Survey"))和方程([30](#S4.E30 "In 4.1 Explicit
    gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey"))中的偏导数设置为零后，我们可以推导出$\boldsymbol{\gamma}_{t}$的值。将此解代入方程([31](#S4.E31
    "In 4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"))，我们得到：'
- en: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}_{T}}\sum_{t=1}^{T}(\prod_{s=t+1}^{T}\boldsymbol{A}_{s})\boldsymbol{B}_{t}.$
    |  | (32) |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi},\boldsymbol{\gamma})}{\partial\boldsymbol{\phi}}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}_{T}}\sum_{t=1}^{T}(\prod_{s=t+1}^{T}\boldsymbol{A}_{s})\boldsymbol{B}_{t}.$
    |  | (32) |'
- en: It can be seen that the reverse mode produces the same solution as the forward
    mode. Works by Shaban et al. ([2019](#bib.bib68)); Luketina et al. ([2016](#bib.bib51))
    suggest disregarding long-term dependencies to increase efficiency.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 可以看出，反向模式产生与正向模式相同的解。Shaban等人的作品（[2019](#bib.bib68)）; Luketina等人的作品（[2016](#bib.bib51)）建议忽略长期依赖以提高效率。
- en: 4.2 Explicit proxy update
  id: totrans-208
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 显式代理更新
- en: Besides using explicit gradient update to solve the inner level task, a more
    direct way (MacKay et al., [2019](#bib.bib54); Bae & Grosse, [2020](#bib.bib4);
    Lorraine & Duvenaud, [2018](#bib.bib49)) is to fit a proxy network $P_{\alpha}(\cdot)$
    which takes the outer variable as input and outputs the inner variable,
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 除了使用显式梯度更新来解决内部层任务外，一种更直接的方法（MacKay等人，[2019](#bib.bib54); Bae＆Grosse，[2020](#bib.bib4);
    Lorraine＆Duvenaud，[2018](#bib.bib49)）是拟合一个代理网络$P_{\alpha}(\cdot)$，该网络以外部变量作为输入并输出内部变量，
- en: '|  | $\boldsymbol{\theta}^{*}=P_{\alpha}(\boldsymbol{\phi}).$ |  | (33) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}^{*}=P_{\alpha}(\boldsymbol{\phi}).$ |  | (33) |'
- en: 'There are two ways to train the proxy: global and local. The global way aims
    to learn a proxy for all $\boldsymbol{\phi}$ by minimizing $\mathcal{L}^{in}(P_{\alpha}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{train})$
    for all $\boldsymbol{\phi}$ against $\boldsymbol{\alpha}$ while the local way
    minimizes $\mathcal{L}^{in}(P_{\alpha}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{train})$
    against $\boldsymbol{\alpha}$ for a neighborhood of $\boldsymbol{\phi}$.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 训练代理有两种方式：全局和局部。全局方式旨在通过最小化$\mathcal{L}^{in}(P_{\alpha}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{train})$对所有$\boldsymbol{\phi}$针对$\boldsymbol{\alpha}$进行学习代理，而局部方式则针对$\boldsymbol{\phi}$的邻域对$\boldsymbol{\alpha}$最小化$\mathcal{L}^{in}(P_{\alpha}(\boldsymbol{\phi}),\boldsymbol{\phi},\mathcal{D}^{train})$。
- en: A special case (Bohdal et al., [2021](#bib.bib8)) is to design the proxy as
    a weighted average of the perturbed inner variable. This work adopts an evolutionary
    algorithm to obtain an approximate solution for $\boldsymbol{\theta}$. By perturbing
    $\boldsymbol{\theta}$ to $\boldsymbol{\theta}_{k}$ for $K$ times, they compute
    the training losses as $\{l_{k}(\boldsymbol{\phi})\}_{k=1}^{K}$ where $l_{k}(\boldsymbol{\phi})=\mathcal{L}^{in}(\boldsymbol{\theta}_{k},\boldsymbol{\phi},\mathcal{D}^{train})$.
    Then the weights for each perturbed loss are,
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 一种特殊情况（Bohdal等人，[2021](#bib.bib8)）是将代理设计为扰动内部变量的加权平均值。该研究采用进化算法来获取$\boldsymbol{\theta}$的近似解。通过将$\boldsymbol{\theta}$扰动为$\boldsymbol{\theta}_{k}$共$K$次，计算训练损失为$\{l_{k}(\boldsymbol{\phi})\}_{k=1}^{K}$，其中$l_{k}(\boldsymbol{\phi})=\mathcal{L}^{in}(\boldsymbol{\theta}_{k},\boldsymbol{\phi},\mathcal{D}^{train})$。然后每个扰动损失的权重为，
- en: '|  | $\omega_{1},\omega_{2},\cdots,\omega_{K}=\rm{softmax}([-l_{1}(\boldsymbol{\phi}),-l_{2}(\boldsymbol{\phi}),\cdots,-l_{K}(\boldsymbol{\phi})]/\tau),$
    |  | (34) |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '|  | $\omega_{1},\omega_{2},\cdots,\omega_{K}=\rm{softmax}([-l_{1}(\boldsymbol{\phi}),-l_{2}(\boldsymbol{\phi}),\cdots,-l_{K}(\boldsymbol{\phi})]/\tau),$
    |  | (34) |'
- en: where $\tau>0$ is a hyperparameter. Last, the proxy is obtained as
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\tau>0$为超参数。最后，代理网络的计算结果为
- en: '|  | $\boldsymbol{\theta}^{*}=\omega_{1}\boldsymbol{\theta}_{1}+\omega_{2}\boldsymbol{\theta}_{1}+\cdots+\omega_{K}\boldsymbol{\theta}_{K}.$
    |  | (35) |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}^{*}=\omega_{1}\boldsymbol{\theta}_{1}+\omega_{2}\boldsymbol{\theta}_{1}+\cdots+\omega_{K}\boldsymbol{\theta}_{K}.$
    |  | (35) |'
- en: Compared with explicit gradient update methods, these proxy methods can adopt
    deep learning modules to directly build the relationship between the inner variable
    and the outer variable. Thus these methods generally require less memory while
    are less accurate due to the rough approximation brought by the deep learning
    module.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 与显式梯度更新方法相比，这些代理方法可以采用深度学习模块直接建立内部变量与外部变量之间的关系。因此，这些方法通常需要更少的内存，但由于深度学习模块带来的粗略逼近，精度较低。
- en: 4.3 Implicit function update
  id: totrans-217
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 隐式函数更新
- en: 'The hypergradient computation of the explicit gradient update methods relies
    on the path taken at the inner level, while the implicit function update makes
    use of the implicit function theorem to derive a more accurate hypergradient without
    vanishing gradients or memory constraints issues. First, the derivate of the inner
    level is set as zero:'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 显式梯度更新方法的超梯度计算依赖于内部层的路径，而隐式函数更新则利用隐式函数定理得到更精确的超梯度，避免了梯度消失或内存限制的问题。首先，内部层的导数设为零：
- en: '|  | $\displaystyle\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}}=\boldsymbol{0}.$
    |  | (36) |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\frac{\partial\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}}=\boldsymbol{0}.$
    |  | (36) |'
- en: 'Then according to the implicit function theorem, we have:'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然后根据隐式函数定理，我们有：
- en: '|  | $\displaystyle\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{2}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}=\boldsymbol{0}.$
    |  | (37) |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}+\frac{\partial\mathcal{L}^{2}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}=\boldsymbol{0}.$
    |  | (37) |'
- en: 'At last, we can compute the hypergradient as:'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，我们可以计算超梯度为：
- en: '|  | $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}=-(\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{-1}\frac{\partial\mathcal{L}^{2}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}.$
    |  | (38) |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{\partial\boldsymbol{\theta}(\boldsymbol{\phi})}{\partial\boldsymbol{\phi}}=-(\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{-1}\frac{\partial\mathcal{L}^{2}(\boldsymbol{\theta},\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\phi}}.$
    |  | (38) |'
- en: 'Take iMAML (Rajeswaran et al., [2019](#bib.bib62)) as an example. To keep the
    dependency between the model parameters $\boldsymbol{\theta}$ and the meta parameters
    $\boldsymbol{\phi}$, iMAML proposes a constraint on the inner level task:'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: 以iMAML（Rajeswaran et al., [2019](#bib.bib62)）为例。为了保持模型参数$\boldsymbol{\theta}$和元参数$\boldsymbol{\phi}$之间的依赖关系，iMAML在内层任务上提出了一个约束：
- en: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\mathcal{D}^{train}_{i})+\frac{\lambda}{2}\&#124;\boldsymbol{\phi}-\boldsymbol{\theta}\&#124;^{2}.$
    |  | (39) |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\mathcal{D}^{train}_{i})+\frac{\lambda}{2}\&#124;\boldsymbol{\phi}-\boldsymbol{\theta}\&#124;^{2}.$
    |  | (39) |'
- en: 'The regularization strength $\lambda$ controls the strength of the prior $\boldsymbol{\phi}$
    relative to the dataset. The iMAML bi-level optimization task can be formulated
    as:'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化强度$\lambda$控制相对于数据集的先验$\boldsymbol{\phi}$的强度。iMAML的双层优化任务可以表述为：
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (40) |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (40) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\mathcal{D}^{train}_{i})+\frac{\lambda}{2}\&#124;\boldsymbol{\phi}-\boldsymbol{\theta}\&#124;^{2},i=1,\cdots,M.$
    |  | (41) |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}_{i}(\boldsymbol{\theta},\mathcal{D}^{train}_{i})+\frac{\lambda}{2}\&#124;\boldsymbol{\phi}-\boldsymbol{\theta}\&#124;^{2},i=1,\cdots,M.$
    |  | (41) |'
- en: 'The hyper-gradient can be computed as:'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 超梯度可以计算为：
- en: '|  | $\frac{d\boldsymbol{\theta}_{i}{(\boldsymbol{\phi})}}{d\boldsymbol{\phi}}=(\mathbf{I}+\frac{1}{\lambda}\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta}_{i},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}_{i}^{\top}\partial\boldsymbol{\theta}_{i}})^{-1},$
    |  | (42) |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '|  | $\frac{d\boldsymbol{\theta}_{i}{(\boldsymbol{\phi})}}{d\boldsymbol{\phi}}=(\mathbf{I}+\frac{1}{\lambda}\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta}_{i},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}_{i}^{\top}\partial\boldsymbol{\theta}_{i}})^{-1},$
    |  | (42) |'
- en: 'which is independent of the inner level optimization path. In this case, the
    hypergradient can be computed as the solution $\boldsymbol{g}$ to a linear system
    $\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}\boldsymbol{g}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}$.
    More specifically, $\boldsymbol{g}$ can be seen as the approximate solution to
    the following optimization problem:'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 这与内层优化路径无关。在这种情况下，超梯度可以计算为线性系统$\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta},\mathcal{D}^{train})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}\boldsymbol{g}=\frac{\partial\mathcal{L}^{out}}{\partial\boldsymbol{\theta}}$的解$\boldsymbol{g}$。更具体地说，$\boldsymbol{g}$可以被视为以下优化问题的近似解：
- en: '|  | $\arg\min_{\boldsymbol{\omega}}\boldsymbol{\omega}^{\top}(\boldsymbol{I}+\frac{1}{\lambda}\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})\boldsymbol{\omega}-\boldsymbol{\omega}^{\top}\frac{\partial\mathcal{L}^{out}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (43) |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '|  | $\arg\min_{\boldsymbol{\omega}}\boldsymbol{\omega}^{\top}(\boldsymbol{I}+\frac{1}{\lambda}\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})\boldsymbol{\omega}-\boldsymbol{\omega}^{\top}\frac{\partial\mathcal{L}^{out}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}}.$
    |  | (43) |'
- en: 'Conjugate gradient methods can be applied to solve this problem where only
    Hessian-vector products are computed and the hessian matrix is not explicitly
    formed. This efficient algorithm is also used in HOAG (Pedregosa, [2016](#bib.bib60))
    to compute the hypergradient. Besides the linear system way to compute hypergradient,
    the work inLorraine et al. ([2020](#bib.bib50)) proposes to unroll the above term
    into the Neumann Series:'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 共轭梯度方法可以应用于解决这个问题，其中仅计算Hessian-向量乘积，而不显式地形成Hessian矩阵。这个高效的算法也在HOAG (Pedregosa,
    [2016](#bib.bib60))中用于计算超梯度。除了计算超梯度的线性系统方法，Lorraine等人 ([2020](#bib.bib50)) 提出了将上述项展开为Neumann级数：
- en: '|  | $(\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{-1}=\sum_{i=0}^{\inf}(\boldsymbol{I}-\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{i}.$
    |  | (44) |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  | $(\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{-1}=\sum_{i=0}^{\inf}(\boldsymbol{I}-\frac{\partial^{2}\mathcal{L}^{in}(\boldsymbol{\theta})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}})^{i}.$
    |  | (44) |'
- en: The first $i_{th}$ steps’ result are used to approximate the computation if
    $\boldsymbol{I}-\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}$
    is contractive. This can avoid the expensive computation of the inverse Hessian.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 如果 $\boldsymbol{I}-\frac{\partial^{2}\mathcal{L}(\boldsymbol{\theta}(\boldsymbol{\phi}),\boldsymbol{\phi})}{\partial\boldsymbol{\theta}^{\top}\partial\boldsymbol{\theta}}$
    是收缩的，那么第一个 $i_{th}$ 步骤的结果可以用来近似计算。这可以避免昂贵的Hessian逆计算。
- en: 4.4 Closed-form update
  id: totrans-236
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 闭式更新
- en: While the above three methods provide an approximate solution for general loss
    functions, we here consider deriving a closed-form connection between $\boldsymbol{\theta}$
    and $\boldsymbol{\phi}$ from
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然上述三种方法为一般损失函数提供了近似解，但我们这里考虑从中推导 $\boldsymbol{\theta}$ 和 $\boldsymbol{\phi}$
    之间的闭式连接。
- en: '|  | $\boldsymbol{\theta}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train}),$
    |  | (45) |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\mathcal{L}^{in}(\boldsymbol{\theta},\boldsymbol{\phi},\mathcal{D}^{train}),$
    |  | (45) |'
- en: 'which is only applicable for some special cases. Bertinetto et al. ([2019](#bib.bib6))
    propose ridge regression as part of its internal model for closed-form solutions.
    Assume a linear predictor $f$ parameterized by $\boldsymbol{\theta}$ is considered
    as the final layer of a CNN parameterized by $\boldsymbol{\phi}$. Asume the input
    $\boldsymbol{X}\in\mathbb{R}^{n\times p}$ and the output $\boldsymbol{Y}\in\mathbb{R}^{n\times
    o}$ where $n$ represents the number of data points and $d,o$ represents the input
    dimension and the output dimension, respectively. Denote the CNN as $\boldsymbol{\phi}(\boldsymbol{X})$:
    $\mathbb{R}^{p}\rightarrow\mathbb{R}^{e}$ and then the predictor’s output is $\boldsymbol{\phi}(\boldsymbol{X})\boldsymbol{\theta}$
    where $\boldsymbol{\phi}(\boldsymbol{X})\in\mathbb{R}^{n\times e}$ and $\boldsymbol{\theta}\in\mathbb{R}^{e\times
    o}$. The $i_{th}$ inner level optimization task can be written as:'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '这仅适用于一些特殊情况。Bertinetto等人 ([2019](#bib.bib6)) 提出了岭回归作为其内部模型的一部分，以便得到闭式解。假设一个线性预测器
    $f$ 由 $\boldsymbol{\theta}$ 参数化，并被视为由 $\boldsymbol{\phi}$ 参数化的CNN的最终层。假设输入为 $\boldsymbol{X}\in\mathbb{R}^{n\times
    p}$ 和输出为 $\boldsymbol{Y}\in\mathbb{R}^{n\times o}$，其中 $n$ 代表数据点的数量，$d,o$ 分别代表输入维度和输出维度。记CNN为
    $\boldsymbol{\phi}(\boldsymbol{X})$: $\mathbb{R}^{p}\rightarrow\mathbb{R}^{e}$，则预测器的输出为
    $\boldsymbol{\phi}(\boldsymbol{X})\boldsymbol{\theta}$，其中 $\boldsymbol{\phi}(\boldsymbol{X})\in\mathbb{R}^{n\times
    e}$ 和 $\boldsymbol{\theta}\in\mathbb{R}^{e\times o}$。第 $i_{th}$ 层次优化任务可以写作：'
- en: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\&#124;\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\theta}-\boldsymbol{Y}_{i}\&#124;^{2}+\lambda\&#124;\boldsymbol{\theta}\&#124;^{2}.$
    |  | (46) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '|  | $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\mathop{\arg\min}_{\boldsymbol{\theta}}\&#124;\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\theta}-\boldsymbol{Y}_{i}\&#124;^{2}+\lambda\&#124;\boldsymbol{\theta}\&#124;^{2}.$
    |  | (46) |'
- en: 'where $\lambda$ controls the strength of $L^{2}$ regularization. The closed
    form solution is $\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}(\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}+\lambda\mathbf{I})^{-1}\boldsymbol{Y}_{i}.$
    To sum up, to extract meta-knowledge $\boldsymbol{\phi}$ in the feature extractor,
    we have the bi-level optimization formulation as:'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$\lambda$控制$L^{2}$正则化的强度。封闭形式的解是$\boldsymbol{\theta}_{i}(\boldsymbol{\phi})=\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}(\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}+\lambda\mathbf{I})^{-1}\boldsymbol{Y}_{i}$。总之，为了在特征提取器中提取元知识$\boldsymbol{\phi}$，我们有如下的双层优化公式：
- en: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (47) |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\boldsymbol{\phi}^{*}$ | $\displaystyle=\mathop{\arg\min}_{\boldsymbol{\phi}}\sum_{i=1}^{M}\mathcal{L}^{out}(\boldsymbol{\theta}_{i}(\boldsymbol{\phi}),\mathcal{D}^{val}_{i}).$
    |  | (47) |'
- en: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}(\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}+\lambda\mathbf{I})^{-1}\boldsymbol{Y}_{i},i=1,\cdots,M.$
    |  | (48) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mbox{s.t.}\quad\boldsymbol{\theta}_{i}(\boldsymbol{\phi})$
    | $\displaystyle=\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}(\boldsymbol{\phi}(\boldsymbol{X}_{i})\boldsymbol{\phi}(\boldsymbol{X}_{i})^{\top}+\lambda\mathbf{I})^{-1}\boldsymbol{Y}_{i},i=1,\cdots,M.$
    |  | (48) |'
- en: Applying Newton’s method to logistic regression, yields a series of weighted
    least squares (or ridge regression) problems. This is also a closed-form solution
    but requires a few steps.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 将牛顿法应用于逻辑回归，得到一系列加权最小二乘（或岭回归）问题。这也是一个封闭形式的解，但需要几个步骤。
- en: Another special case is to assume the model to be wide enough. Recent work (Jacot
    et al., [2018](#bib.bib38); Lee et al., [2017](#bib.bib43)) build the correspondence
    between the NNGP kernel and the Bayesian Neural Network and the correspondence
    between the NTK kernel and the gradient trained Neural Network with MSE loss.
    In this case, the inner level can have a closed-form solution. The works(Nguyen
    et al., [2020](#bib.bib57); Yuan & Wu, [2021](#bib.bib87)) treat the data as the
    outer variable for data distillation and adversarial attack tasks respectively,
    which yield better-distilled samples and adversarial attacks. These algorithms
    can be achieved by NTK tool(Novak et al., [2019](#bib.bib59)) easily. The approach(Dukler
    et al., [2021](#bib.bib23)) treats the instance weights as the outer variable
    and assumes the pretrained model with linear representation to yield a closed-form
    solution for the inner level task. Besides assuming the inner level as ridge regression
    and least squares, some works(Ghadimi & Wang, [2018](#bib.bib29); Yang et al.,
    [2021](#bib.bib83)) also assume the inner level loss function is strongly convex
    and propose effective algorithms to better solve the bi-level optimization problem.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个特殊情况是假设模型足够宽。近期的工作（Jacot et al., [2018](#bib.bib38); Lee et al., [2017](#bib.bib43)）建立了NNGP核与贝叶斯神经网络之间的对应关系，以及NTK核与通过均方误差损失训练的神经网络之间的对应关系。在这种情况下，内层可以有一个封闭形式的解。这些工作（Nguyen
    et al., [2020](#bib.bib57); Yuan & Wu, [2021](#bib.bib87)）分别将数据视为数据蒸馏和对抗攻击任务的外部变量，从而产生了更好的蒸馏样本和对抗攻击。这些算法可以通过NTK工具（Novak
    et al., [2019](#bib.bib59)）轻松实现。方法（Dukler et al., [2021](#bib.bib23)）将实例权重视为外部变量，并假设预训练模型具有线性表示，以为内层任务提供封闭形式的解。除了假设内层为岭回归和最小二乘回归外，一些工作（Ghadimi
    & Wang, [2018](#bib.bib29); Yang et al., [2021](#bib.bib83)）还假设内层损失函数是强凸的，并提出了有效的算法来更好地解决双层优化问题。
- en: 4.5 Comparative Analysis.
  id: totrans-246
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 比较分析。
- en: 'This subsection delves into a comparative analysis of the time and space complexity
    involved in computing the hypergradient $\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$
    in Eq.([3](#S2.E3 "In 2 Definition ‣ Gradient-based Bi-level Optimization for
    Deep Learning: A Survey")). We will evaluate the following four methods for this
    purpose, with a summary provided in Table [6](#S4.T6 "Table 6 ‣ 4.5 Comparative
    Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey") for reference.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: '本小节深入探讨了计算超梯度$\frac{d\mathcal{L}^{out}}{d\boldsymbol{\phi}}$的时间和空间复杂性的比较分析（见Eq.([3](#S2.E3
    "In 2 Definition ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey")）。我们将评估以下四种方法，并在表[6](#S4.T6
    "Table 6 ‣ 4.5 Comparative Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level
    Optimization for Deep Learning: A Survey")中提供总结以供参考。'
- en: 'Explicit gradient update. Denote the time of computing Eq.([18](#S4.E18 "In
    4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")) as $c(d,m)$. Following the approach (Franceschi
    et al., [2017](#bib.bib26)), the product between the Jacobian matrix in Eq.([18](#S4.E18
    "In 4.1 Explicit gradient update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey")) and any vector can be computed within a time complexity
    of $\mathcal{O}(c(d,m))$. In the context of the forward mode for explicit gradient
    update (termed explicit gradient forward), the time complexity becomes $\mathcal{O}(Tmc(d,m))$.
    This is because it requires $T$ iterations, and each iteration involves $m$ Jacobian-vector
    products. The space complexity for the forward mode is $\mathcal{O}(d+m)$, as
    the inner variable $\boldsymbol{\theta}$ can be overwritten in each iteration.
    Contrastingly, for the reverse mode (termed explicit gradient reverse), the time
    complexity is $\mathcal{O}(Tc(d,m))$ since it involves only one Jacobian-vector
    product per iteration. However, the space complexity increases to $\mathcal{O}(Td+m)$,
    as the inner variable cannot be overwritten. In summary, the explicit gradient
    forward and explicit gradient reverse methods offer a trade-off between time and
    space complexities: the former minimizes memory usage at the cost of increased
    computation time, whereas the latter accelerates computation at the expense of
    memory.'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '显式梯度更新。将计算公式([18](#S4.E18 "In 4.1 Explicit gradient update ‣ 4 Optimization
    ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"))的时间表示为$c(d,m)$。按照方法
    (Franceschi et al., [2017](#bib.bib26))，公式([18](#S4.E18 "In 4.1 Explicit gradient
    update ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning:
    A Survey"))中的雅可比矩阵与任意向量的乘积可以在时间复杂度为$\mathcal{O}(c(d,m))$内计算。在显式梯度更新的前向模式下（称为显式梯度前向），时间复杂度变为$\mathcal{O}(Tmc(d,m))$。这是因为需要$T$次迭代，每次迭代涉及$m$个雅可比-向量乘积。前向模式的空间复杂度为$\mathcal{O}(d+m)$，因为每次迭代中内部变量$\boldsymbol{\theta}$可以被覆盖。相对而言，反向模式（称为显式梯度反向）的时间复杂度为$\mathcal{O}(Tc(d,m))$，因为每次迭代只涉及一个雅可比-向量乘积。然而，空间复杂度增加到$\mathcal{O}(Td+m)$，因为内部变量不能被覆盖。总之，显式梯度前向和显式梯度反向方法在时间和空间复杂度之间提供了权衡：前者通过增加计算时间来最小化内存使用，而后者则通过增加内存来加速计算。'
- en: Explicit proxy update. The implementation of this method necessitates the training
    and utilization of a proxy network. The space complexity is $\mathcal{O}(d+m)$
    as it maintains both the inner variable and the outer variable. Let $t(d,m)$ represent
    the time required to train the proxy network, and $i(d,m)$ denote the inference
    time. The time complexity is $\mathcal{O}(t(d,m)+i(d,m))$. While it’s challenging
    to draw direct comparisons with other methods due to the potential variations
    in proxy network designs, this method is generally considered to be both time-
    and space-efficient. However, this comes at the expense of solution accuracy.
    Often, the explicit proxy update method may not perform as well as other methods
    because the proxy network $\boldsymbol{\theta}^{*}=P_{\alpha}(\boldsymbol{\phi})$
    may not accurately approximate the relation between the inner variable and the
    outer variable.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 显式代理更新。实施这种方法需要训练和使用代理网络。空间复杂度为$\mathcal{O}(d+m)$，因为它同时保持内部变量和外部变量。设$t(d,m)$表示训练代理网络所需的时间，$i(d,m)$表示推断时间。时间复杂度为$\mathcal{O}(t(d,m)+i(d,m))$。虽然由于代理网络设计的潜在变异，难以与其他方法进行直接比较，但这种方法通常被认为在时间和空间上都具有高效性。然而，这种方法的解决方案精度可能会有所牺牲。通常，显式代理更新方法可能表现不如其他方法，因为代理网络$\boldsymbol{\theta}^{*}=P_{\alpha}(\boldsymbol{\phi})$可能无法准确地近似内部变量和外部变量之间的关系。
- en: Implicit function update. The implicit function update method capitalizes on
    the implicit function theorem to calculate the hypergradient. Solutions are often
    approximated through conjugate gradient or Neumann series methods. Given a $K$-step
    approximation, the time complexity is $\mathcal{O}((Km+T)c(d,m))$, as each step
    involves $m$ matrix-vector products and the whole process is followed by a $T$-step
    gradient descent The space complexity is $\mathcal{O}(d+m)$.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 隐式函数更新。隐式函数更新方法利用隐式函数定理来计算超梯度。解决方案通常通过共轭梯度或诺伊曼级数方法进行近似。给定一个$K$步的近似，时间复杂度为$\mathcal{O}((Km+T)c(d,m))$，因为每一步涉及$m$个矩阵-向量乘积，整个过程之后进行$T$步梯度下降。空间复杂度为$\mathcal{O}(d+m)$。
- en: 'In practical scenarios, the implicit function update and explicit gradient
    update methods often yield more precise solutions compared to the explicit proxy
    update. The latter, while less accurate, is often utilized for its efficiency
    advantage. As established by Lorraine et al. ([2020](#bib.bib50)), the solutions
    obtained by the implicit function update can be viewed as the limit of the explicit
    gradient update as the number of iterations $T$ approaches infinity. This insight
    bridges these two methods. Moreover, Grazzi et al. ([2020](#bib.bib31)) demonstrated
    that both the implicit function update and explicit gradient update methods converge
    linearly under certain conditions, with the former typically converging at a faster
    rate. As detailed in Table[6](#S4.T6 "Table 6 ‣ 4.5 Comparative Analysis. ‣ 4
    Optimization ‣ Gradient-based Bi-level Optimization for Deep Learning: A Survey"),
    the time complexity of the implicit function update is $\mathcal{O}((Km+T)c(d,m))$.
    Compared to the explicit gradient forward’s time complexity of $\mathcal{O}(Tmc(d,m))$,
    the implicit function update method can be more time-efficient when the approximation
    step $K$ is smaller than $T$ and the hyperparameter dimension $m$ is large. It’s
    worth noting that Lorraine et al. ([2020](#bib.bib50)) demonstrate the application
    of the implicit function update method for optimizing millions of hyperparameters,
    proving the efficiency of implicit function update. When considering the trade-off
    between time and memory efficiency, as illustrated in Table[6](#S4.T6 "Table 6
    ‣ 4.5 Comparative Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level Optimization
    for Deep Learning: A Survey"), the implicit function update is generally more
    memory-efficient than the reverse mode of the explicit gradient update but somewhat
    less time-efficient. This analysis serves to guide the choice of method by considering
    specific requirements of the task at hand, balancing both time and space efficiencies.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: '在实际场景中，相比于显式代理更新，隐式函数更新和显式梯度更新方法通常能获得更精确的解决方案。后者虽然精度较低，但由于其效率优势而被广泛使用。正如Lorraine等人（[2020](#bib.bib50)）所确定的那样，隐式函数更新获得的解可以被视为显式梯度更新在迭代次数$T$趋于无限时的极限。这一见解桥接了这两种方法。此外，Grazzi等人（[2020](#bib.bib31)）证明，在某些条件下，隐式函数更新和显式梯度更新方法都具有线性收敛性，其中隐式函数更新通常收敛速度更快。正如表[6](#S4.T6
    "Table 6 ‣ 4.5 Comparative Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level
    Optimization for Deep Learning: A Survey")中详细说明的那样，隐式函数更新的时间复杂度为$\mathcal{O}((Km+T)c(d,m))$。相比之下，显式梯度前向的时间复杂度为$\mathcal{O}(Tmc(d,m))$，当近似步数$K$小于$T$且超参数维度$m$较大时，隐式函数更新方法可以更具时间效率。值得注意的是，Lorraine等人（[2020](#bib.bib50)）展示了隐式函数更新方法在优化数百万个超参数中的应用，证明了隐式函数更新的效率。在考虑时间和内存效率的权衡时，如表[6](#S4.T6
    "Table 6 ‣ 4.5 Comparative Analysis. ‣ 4 Optimization ‣ Gradient-based Bi-level
    Optimization for Deep Learning: A Survey")所示，隐式函数更新通常比显式梯度更新的反向模式更具内存效率，但在时间效率上略逊一筹。这一分析旨在通过考虑具体任务的需求，平衡时间和空间效率，以指导方法的选择。'
- en: 'Compared to the implicit function update method, the explicit gradient update
    method is more prevalently employed within the research community, particularly
    for optimizing hyperparameters such as learning sample weights (Ren et al., [2018](#bib.bib64);
    Hu et al., [2019](#bib.bib37); Wang et al., [2020](#bib.bib78); Shu et al., [2019](#bib.bib69)).
    This preference is especially pronounced within the deep learning community, which
    often leans towards the explicit gradient update method. Several reasons can explain
    this inclination: (1). The popularity of the explicit gradient update method was
    propelled by seminal works that used influence functions to study the impact of
    a training point on prediction outcomes (Koh & Liang, [2017](#bib.bib41)). This
    method was then widely adopted in subsequent research, particularly in works focusing
    on learning sample weights (Ren et al., [2018](#bib.bib64); Hu et al., [2019](#bib.bib37);
    Wang et al., [2020](#bib.bib78); Shu et al., [2019](#bib.bib69)). (2). The explicit
    gradient update method’s appeal lies in its intuitiveness and straightforwardness
    within the context of deep learning. It can also offer interpretability in certain
    scenarios. For instance, during sample reweighting, samples with gradients similar
    to the gradient on the validation set are reweighted to be high (Shu et al., [2019](#bib.bib69)).
    In contrast, the implicit function update method, while potent, is more complex,
    relying on optimization techniques such as the conjugate gradient method and Neumann
    series for approximation. (3). Lastly, the explicit gradient update method benefits
    from advanced deep learning libraries like higher (Grefenstette et al., [2019](#bib.bib32)),
    designed explicitly for calculating the explicit gradient update. This tool offers
    substantial support, making the explicit gradient update method more accessible
    and efficient to implement, contributing to its prevalence.'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 相较于隐式函数更新方法，显式梯度更新方法在研究社区中使用更为广泛，特别是在优化超参数如学习样本权重方面（Ren等，[2018](#bib.bib64)；Hu等，[2019](#bib.bib37)；Wang等，[2020](#bib.bib78)；Shu等，[2019](#bib.bib69)）。这种偏好在深度学习社区尤为明显，他们通常倾向于使用显式梯度更新方法。这种倾向有几个原因：（1）显式梯度更新方法的流行是由使用影响函数研究训练点对预测结果影响的开创性工作推动的（Koh
    & Liang，[2017](#bib.bib41)）。该方法随后在后续研究中被广泛采用，特别是在关注学习样本权重的工作中（Ren等，[2018](#bib.bib64)；Hu等，[2019](#bib.bib37)；Wang等，[2020](#bib.bib78)；Shu等，[2019](#bib.bib69)）。
    （2）显式梯度更新方法在深度学习环境中的直观性和简单性使其颇具吸引力。在某些场景下，它也可以提供可解释性。例如，在样本重加权过程中，具有与验证集上的梯度相似的梯度的样本会被重新加权为高（Shu等，[2019](#bib.bib69)）。相比之下，隐式函数更新方法虽然强大，但更为复杂，依赖于共轭梯度方法和Neumann级数等优化技术进行近似。（3）最后，显式梯度更新方法受益于像higher（Grefenstette等，[2019](#bib.bib32)）这样的先进深度学习库，这些库专门设计用于计算显式梯度更新。这个工具提供了大量支持，使得显式梯度更新方法更易于实现和高效，从而促进了它的普及。
- en: Closed-form update. The closed-form update method is specifically designed for
    certain problems where a closed-form solution for the inner level problem can
    be obtained. Contrary to the other methods, this one yields an exact hypergradient.
    The most time-consuming aspect of this method is the inverse matrix computation,
    which results in a time complexity of $\mathcal{O}(n^{3})$, where $n$ denotes
    the dataset size. The space complexity stands at $\mathcal{O}(n^{2})$.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 闭式更新。闭式更新方法专门针对那些可以获得内层问题闭式解的特定问题。与其他方法不同，这种方法产生精确的超梯度。该方法最耗时的方面是逆矩阵计算，时间复杂度为$\mathcal{O}(n^{3})$，其中$n$表示数据集大小。空间复杂度为$\mathcal{O}(n^{2})$。
- en: 'Table 6: Comparison on time and space complexity.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 表6：时间和空间复杂度比较。
- en: '| Method | Time | Space |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 时间 | 空间 |'
- en: '| --- | --- | --- |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Explicit gradient forward | $\mathcal{O}(Tmc(d,m))$ | $\mathcal{O}(d+m)$
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '| 显式梯度前向 | $\mathcal{O}(Tmc(d,m))$ | $\mathcal{O}(d+m)$ |'
- en: '| Explicit gradient reverse | $\mathcal{O}(Tc(d,m))$ | $\mathcal{O}(Td+m)$
    |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| 显式梯度反向 | $\mathcal{O}(Tc(d,m))$ | $\mathcal{O}(Td+m)$ |'
- en: '| Explicit proxy update | $t(d,m)+i(d,m)$ | $\mathcal{O}(d+m)$ |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 显式代理更新 | $t(d,m)+i(d,m)$ | $\mathcal{O}(d+m)$ |'
- en: '| Implicit function update | $\mathcal{O}((Km+T)c(d,m))$ | $\mathcal{O}(d+m)$
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '| 隐式函数更新 | $\mathcal{O}((Km+T)c(d,m))$ | $\mathcal{O}(d+m)$ |'
- en: '| Closed-form update | $\mathcal{O}(N^{3})$ | $\mathcal{O}(N^{2})$ |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 闭式更新 | $\mathcal{O}(N^{3})$ | $\mathcal{O}(N^{2})$ |'
- en: Distinguishing between optimizing data and other hyperparameters, we observe
    divergent preferences in the community regarding the suitable method for each
    task. For hyperparameters like regularization (Franceschi et al., [2018](#bib.bib27)),
    the explicit gradient update method is the common choice. This method provides
    an optimal balance between computational efficiency and solution precision, a
    crucial consideration for online model training where real-time updates are essential.
    Its strength lies in its ability to iteratively and efficiently fine-tune hyperparameters,
    thereby significantly enhancing the model’s performance during the training phase.
    Conversely, the optimization of data, such as data distillation (Nguyen et al.,
    [2020](#bib.bib57)), generally employs the closed-form kernel method. This method
    may be computationally intensive, leading to perceived inefficiencies, but it
    delivers highly precise solutions, a quality that is integral in the context of
    data optimization. In scenarios like data distillation, the output is often used
    for offline tasks such as continual learning. The computation burden of the closed-form
    method, therefore, becomes less of a concern because the optimization is carried
    out once and the solution can be reused indefinitely. This singular computation
    for lasting usage offsets the computational inefficiency, making it a viable choice
    for data optimization tasks.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 区分数据优化和其他超参数优化时，我们观察到社区对每个任务适用方法的偏好存在差异。对于像正则化这样的超参数（Franceschi et al., [2018](#bib.bib27)），显式梯度更新方法是常见选择。该方法在计算效率和解的精确度之间提供了最佳平衡，这在需要实时更新的在线模型训练中尤为重要。它的优点在于能够迭代且高效地微调超参数，从而显著提升模型在训练阶段的性能。相反，数据优化，如数据蒸馏（Nguyen
    et al., [2020](#bib.bib57)），通常采用闭式形式的核方法。该方法可能计算上较为密集，导致效率低下，但它提供了高度精确的解决方案，这在数据优化中是至关重要的。在数据蒸馏等场景中，输出通常用于离线任务，如持续学习。因此，闭式形式方法的计算负担减少，因为优化只进行一次，解决方案可以无限次重用。这种为长久使用而进行的单次计算抵消了计算上的低效，使其成为数据优化任务的可行选择。
- en: 5 Conclusion and Future Directions
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论与未来方向
- en: 'Bi-level optimization embeds one problem within another and the gradient-based
    category solves the outer level task via gradient descent methods. We first discuss
    how to formulate a research problem from a bi-level optimization perspective.
    There are two formulations: the single-task formulation to optimize hyperparameters
    and the multi-task formulation to extract meta-knowledge. Further, we discuss
    four possible ways to compute the hypergradient in the outer level, including
    explicit gradient update, proxy update, implicit function update, and closed-form
    update. This could serve as a good guide for researchers on applying gradient-based
    bi-level optimization.'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 双层优化将一个问题嵌入到另一个问题中，基于梯度的方法通过梯度下降法来解决外层任务。我们首先讨论如何从双层优化的角度来表述研究问题。主要有两种表述方式：单任务表述以优化超参数和多任务表述以提取元知识。接下来，我们讨论四种可能的计算超梯度的方法，包括显式梯度更新、代理更新、隐式函数更新和闭式形式更新。这可以作为研究人员应用基于梯度的双层优化的良好指南。
- en: 'As we conclude our survey, we spotlight two promising future directions: (1)
    Effecctive Data Optimization for Science from a task formulation perspective corresponding
    to Section[3](#S3 "3 Task Formulation ‣ Gradient-based Bi-level Optimization for
    Deep Learning: A Survey"). (2) Accurate Explicit Proxy Update from an optimization
    perspective corresponding to Section[4](#S4 "4 Optimization ‣ Gradient-based Bi-level
    Optimization for Deep Learning: A Survey").'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 在总结我们的调查时，我们重点关注两个有前景的未来方向：（1）从任务表述的角度看，**有效的数据优化**，对应于第[3](#S3 "3 任务表述 ‣ 基于梯度的双层优化在深度学习中的应用：综述")节。（2）从优化角度看，**准确的显式代理更新**，对应于第[4](#S4
    "4 优化 ‣ 基于梯度的双层优化在深度学习中的应用：综述")节。
- en: '5.1 Future Direction 1: Effecctive Data Optimization for Science'
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 未来方向 1：**有效的数据优化**
- en: 'Depending on the nature of the data, this domain can be primarily divided into
    three areas: tuning parameter optimization, design optimization, and feature optimization.
    Here, we elaborate on how bi-level optimization acts as a potent tool to optimize
    these categories of data, aiding in solving scientific problems.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 根据数据的性质，这个领域可以主要分为三个方面：参数优化、设计优化和特征优化。在这里，我们深入探讨双层优化如何作为一种有效工具来优化这些类别的数据，帮助解决科学问题。
- en: 'Tuning parameter optimization. In the scientific domain, a common problem is
    to find a design - be it a protein, a material, a robot, or a DNA sequence - that
    optimizes a specific black-box objective function such as a protein property score(Trabucco
    et al., [2022](#bib.bib73)). This process often trains a proxy model using collected
    pairs of designs and scores along with certain tuning parameters, and the trained
    proxy guides the design search in evolutionary algorithms (Hansen, [2006](#bib.bib35))
    or reinforcement learning(Angermueller et al., [2019](#bib.bib3)). Parameter tuning
    via bi-level optimization has emerged as a promising approach to achieve data-specific
    optimization and can enhance the local accuracy of the proxy model around the
    current point in the search space. This could potentially revolutionize the design
    search process, making it more effective and targeted. Such optimization can be
    achieved by locally sampling data points from the collected design-score pairs
    or by using pseudo-labelers to label neighboring samples. As mentioned in Section [3.1.1](#S3.SS1.SSS1
    "3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey"), we envision utilizing a clean validation set to fine-tune
    these data-specific parameters via bi-level optimization. This approach offers
    promising prospects in identifying reliable portions of locally sampled data,
    thereby improving the local accuracy of the proxy model, and providing a more
    effective direction to the search process. As we move forward, the nuances of
    these techniques will be refined and expanded, offering greater possibilities
    in design optimization tasks.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '调参优化。在科学领域中，一个常见的问题是寻找一个设计——无论是蛋白质、材料、机器人还是DNA序列——以优化一个特定的黑箱目标函数，例如蛋白质属性评分（Trabucco
    等，[2022](#bib.bib73)）。这个过程通常会使用收集到的设计和评分对以及某些调节参数来训练一个代理模型，然后经过训练的代理模型在进化算法（Hansen，[2006](#bib.bib35)）或强化学习（Angermueller
    等，[2019](#bib.bib3)）中指导设计搜索。通过双层优化进行的参数调节已经成为一种有前景的方法，用于实现数据特定的优化，并可以提高代理模型在当前搜索空间点附近的局部准确性。这有可能彻底改变设计搜索过程，使其更加高效和有针对性。这种优化可以通过从收集的设计-评分对中局部采样数据点或使用伪标签器对邻近样本进行标注来实现。如在第[3.1.1节](#S3.SS1.SSS1
    "3.1.1 Same formula without explicit outer level hypergradient ‣ 3.1 Single-task
    formulation ‣ 3 Task Formulation ‣ Gradient-based Bi-level Optimization for Deep
    Learning: A Survey")所述，我们设想通过双层优化利用干净的验证集来微调这些数据特定的参数。这种方法在识别可靠的局部采样数据部分方面提供了有希望的前景，从而提高了代理模型的局部准确性，并为搜索过程提供了更有效的方向。随着我们不断前进，这些技术的细微之处将得到完善和扩展，提供更多设计优化任务的可能性。'
- en: Design optimization. A paradigm shift in approaching scientific problems could
    be to focus on directly optimizing the design, instead of tuning parameters to
    enhance proxy model performance. Data distillation through bi-level optimization,
    could serve as a pivotal strategy in this context. This technique extracts extensive
    knowledge from large datasets into distilled samples, a process which has been
    found to retain features corresponding to the labels associated with the distilled
    samples(Wang et al., [2018](#bib.bib77); Lei & Tao, [2023](#bib.bib44)). Taking
    inspiration from these findings, certain studies assign a predefined high score
    to an initial design and distill knowledge from the training set into the design (Chen
    et al., [2022a](#bib.bib12); [2023a](#bib.bib14)). This procedure results in a
    design with high-scoring features, essentially creating a desirable final candidate.
    As we look towards the future of gradient-based bi-level optimization, two intriguing
    directions arise from this research line. Firstly, employing foundational models
    specific to fields such as materials science, alongside advanced data distillation
    techniques (Lei & Tao, [2023](#bib.bib44)), could substantially improve distillation
    performance. This would enable more accurate high-scoring features to be incorporated
    into the design. Secondly, analyzing the distilled high-scoring sample to extract
    patterns and potential rules presents another exciting prospect. Armed with this
    derived knowledge, it may be possible to create high-scoring designs or to integrate
    this understanding into our modelling process, paving the way for more insightful
    and accurate predictions.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 设计优化。科学问题处理的一个范式转变可能是直接优化设计，而不是调整参数以提高代理模型的性能。在这种情况下，通过双层优化进行的数据提炼可能是一种关键策略。这种技术将从大型数据集中提取广泛的知识到提炼样本中，这一过程被发现能够保留与提炼样本相关的标签特征（Wang
    et al., [2018](#bib.bib77); Lei & Tao, [2023](#bib.bib44)）。从这些发现中汲取灵感，某些研究为初始设计分配了预定义的高分，并从训练集中提炼知识到设计中（Chen
    et al., [2022a](#bib.bib12); [2023a](#bib.bib14)）。这一过程产生了具有高得分特征的设计，基本上创造了一个理想的最终候选设计。展望基于梯度的双层优化的未来，这一研究方向提出了两个有趣的方向。首先，采用特定领域如材料科学的基础模型，以及先进的数据提炼技术（Lei
    & Tao, [2023](#bib.bib44)），可能会显著提高提炼性能。这将使更准确的高得分特征能够被纳入设计中。其次，分析提炼出的高得分样本以提取模式和潜在规则是另一个令人兴奋的前景。凭借这些衍生的知识，可能能够创建高得分的设计，或将这种理解融入我们的建模过程中，为更具洞察力和准确性的预测铺平道路。
- en: Feature optimization. Another pivotal area in science is feature optimization,
    which aims to improve the learning of data features. This optimization process
    is intertwined with scientific constraints, which can be effectively incorporated
    as the inner level task in bi-level optimization. These constraints generally
    include geometric and biochemical constraints. Geometric constraints stem from
    the physical or spatial characteristics of a system. An example of leveraging
    these constraints can be seen in the work(Xu et al., [2021](#bib.bib82)). Here,
    the process of molecular conformation prediction is decomposed into two levels,
    with the geometric constraint between molecular conformation and predicted atom
    distances being the inner level task. By utilizing this constraint, the trained
    neural network can produce atom distance features that are more compatible with
    the actual molecular structure. Biochemical constraints are rooted in the chemical
    and biological principles that govern a system. These constraints have been utilized
    by Chen et al. ([2022b](#bib.bib13)), where the inherent correspondence between
    the sequential and structural representations of a protein is used as the biochemical
    constraint. The task of maximizing mutual information is formulated as the inner
    level task, which allows the Graph Neural Network (GNN) to output protein structural
    features with higher accuracy. Moving forward, feature optimization is set to
    play an increasingly important role in enhancing the learning of data features
    by leveraging inherent scientific constraints within a bi-level optimization framework.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '5.2 Future Direction 2: Accurate Explicit Proxy Update'
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Beyond the potential identified in the first future direction, another significant
    area of exploration centers around constructing a more accurate proxy in explicit
    proxy update. This promises to yield a more accurate computation of hypergradients
    efficiently. One viable strategy is to employ a more interpretable construction
    of the proxy network, $\boldsymbol{\theta}^{*}=P_{\alpha}(\boldsymbol{\phi})$.
    For example, Bohdal et al. ([2021](#bib.bib8)) design a proxy by utilizing a weighted
    average of the perturbed inner variable, a process that offers interpretability
    and improved accuracy.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'Moreover, we underline the connection between model-based optimization (Trabucco
    et al., [2022](#bib.bib73)) and explicit proxy update, in the context of computing
    the inner variable from the outer variable using gradient methods. Specifically,
    the explicit proxy update aims to discover a proxy network that maps the outer
    variable to the inner variable. This mapping bears a resemblance to the trained
    model in model-based optimization, which maps the input design (e.g., a robot)
    to its property (e.g., robot speed). Consequently, recent advancements in model-based
    optimization can potentially enhance the performance of explicit proxy update.
    Here, we discuss some directions that are not exhaustive:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: Modeling Priors. In model-based optimization, integrating various modeling priors,
    such as smoothness(Yu et al., [2021](#bib.bib86)), is critical for model performance.
    Analogously, these priors could be integrated into the training of the proxy network,
    leading to more precise prediction from the outer to the inner variable.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 建模先验。在基于模型的优化中，整合各种建模先验，如平滑性（Yu 等人，[2021](#bib.bib86)），对模型性能至关重要。类似地，这些先验可以整合到代理网络的训练中，从而提高从外部变量到内部变量的预测精度。
- en: Importance Sampling. Model-based optimization utilizes data gathered during
    the optimization process, and the model might not be accurate for the neighborhood
    of the current optimization point. A technique used in model-based optimization(Fannjiang
    & Listgarten, [2020](#bib.bib24)) involves employing importance sampling to retrain
    the model, based on input distribution. This approach could be adapted to the
    training of proxy neural network on the already gathered outer-inner variable
    pairs.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 重要性采样。基于模型的优化利用在优化过程中收集的数据，模型可能在当前优化点的邻域内不准确。在模型优化中使用的一种技术（Fannjiang & Listgarten，[2020](#bib.bib24)）涉及使用重要性采样来重新训练模型，基于输入分布。这种方法可以适应于在已收集的外部-内部变量对上训练代理神经网络。
- en: Reverse Mapping. Some works in model-based optimization(Fannjiang & Listgarten,
    [2020](#bib.bib24); Chan et al., [2021](#bib.bib10)) suggest using a reverse mapping
    for predicting the input design from the property score using generative modeling
    techniques. By maintaining consistency between the forward mapping (i.e., the
    model prediction process) and the reverse mapping, the model’s accuracy is significantly
    enhanced. A parallel strategy can be applied in explicit proxy updates where the
    introduction of a reverse mapping to predict the outer variable from the inner
    variable could improve the accuracy of the proxy by ensuring consistency.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 反向映射。在基于模型的优化中，一些研究（Fannjiang & Listgarten，[2020](#bib.bib24)；Chan 等人，[2021](#bib.bib10)）建议使用反向映射，通过生成建模技术从属性评分预测输入设计。通过保持前向映射（即模型预测过程）和反向映射之间的一致性，模型的准确性得到了显著提升。在显式代理更新中，可以采用类似的策略，通过引入反向映射从内部变量预测外部变量，以确保一致性，从而提高代理的准确性。
- en: Efficient Sampling. Training the proxy neural network involves sampling the
    outer variable and computing the corresponding inner variable, which can be computationally
    expensive. Utilizing the acquisition function, as seen in model-based optimization
    (Trabucco et al., [2022](#bib.bib73)), to decide the next batch for sampling may
    prove to be an efficient solution to this challenge.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 高效采样。训练代理神经网络涉及采样外部变量并计算相应的内部变量，这可能计算开销较大。利用如模型优化中所见的获取函数（Trabucco 等人，[2022](#bib.bib73)）来决定下一个批次的采样可能是解决这一挑战的有效方案。
- en: References
  id: totrans-278
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Algan & Ulusoy (2021) Görkem Algan and Ilkay Ulusoy. Meta soft label generation
    for noisy labels. In *International Conference on Pattern Recognition*, 2021.
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Algan & Ulusoy (2021) Görkem Algan 和 Ilkay Ulusoy。噪声标签的元软标签生成。发表于 *国际模式识别大会*，2021年。
- en: Andrychowicz et al. (2016) Marcin Andrychowicz, Misha Denil, Sergio Gomez, Matthew W
    Hoffman, David Pfau, Tom Schaul, Brendan Shillingford, and Nando De Freitas. Learning
    to learn by gradient descent by gradient descent. In *Advances in neural information
    processing systems*, 2016.
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrychowicz 等人 (2016) Marcin Andrychowicz、Misha Denil、Sergio Gomez、Matthew
    W Hoffman、David Pfau、Tom Schaul、Brendan Shillingford 和 Nando De Freitas。通过梯度下降学习梯度下降。发表于
    *神经信息处理系统进展*，2016年。
- en: Angermueller et al. (2019) Christof Angermueller, David Dohan, David Belanger,
    Ramya Deshpande, Kevin Murphy, and Lucy Colwell. Model-based reinforcement learning
    for biological sequence design. In *Proc. Int. Conf. Learning Rep. (ICLR)*, 2019.
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Angermueller 等人 (2019) Christof Angermueller、David Dohan、David Belanger、Ramya
    Deshpande、Kevin Murphy 和 Lucy Colwell。基于模型的强化学习用于生物序列设计。发表于 *国际学习报告会议 (ICLR)*，2019年。
- en: 'Bae & Grosse (2020) Juhan Bae and Roger B Grosse. Delta-stn: Efficient bilevel
    optimization for neural networks using structured response jacobians. *Advances
    in Neural Information Processing Systems*, 2020.'
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bae & Grosse (2020) Juhan Bae 和 Roger B Grosse。Delta-stn：使用结构化响应雅可比矩阵的高效双层优化。*神经信息处理系统进展*，2020年。
- en: Bai et al. (2019) Shaojie Bai, J Zico Kolter, and Vladlen Koltun. Deep equilibrium
    models. *Advances in Neural Information Processing Systems*, 2019.
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bai 等人 (2019) Shaojie Bai、J Zico Kolter 和 Vladlen Koltun。深度平衡模型。*神经信息处理系统进展*，2019年。
- en: Bertinetto et al. (2019) Luca Bertinetto, Joao F. Henriques, Philip Torr, and
    Andrea Vedaldi. Meta-learning with differentiable closed-form solvers. In *International
    Conference on Learning Representations*, 2019.
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bertinetto 等（2019）卢卡·贝尔蒂内托，若昂·F·亨里克斯，菲利普·托尔，和安德烈亚·维达尔迪。使用可微分的封闭形式求解器进行元学习。发表于
    *国际学习表征会议*，2019年。
- en: Biggio et al. (2012) Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning
    attacks against support vector machines. *arXiv preprint arXiv:1206.6389*, 2012.
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Biggio 等（2012）巴蒂斯塔·比吉奥，布莱恩·纳尔逊，和帕维尔·拉斯科夫。针对支持向量机的毒化攻击。*arXiv 预印本 arXiv:1206.6389*，2012年。
- en: 'Bohdal et al. (2021) Ondrej Bohdal, Yongxin Yang, and Timothy Hospedales. Evograd:
    Efficient gradient-based meta-learning and hyperparameter optimization. *Advances
    in Neural Information Processing Systems*, 2021.'
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bohdal 等（2021）翁德雷·博达尔，杨永欣，和蒂莫西·霍斯佩代尔斯。Evograd：高效的基于梯度的元学习和超参数优化。*神经信息处理系统进展*，2021年。
- en: Bracken & McGill (1973) Jerome Bracken and James T McGill. Mathematical programs
    with optimization problems in the constraints. *Operations Research*, 1973.
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bracken & McGill（1973）杰罗姆·布拉肯和詹姆斯·T·麦吉尔。约束中的优化问题的数学程序。*运筹学*，1973年。
- en: Chan et al. (2021) Alvin Chan, Ali Madani, Ben Krause, and Nikhil Naik. Deep
    extrapolation for attribute-enhanced generation. *Advances in Neural Information
    Processing Systems*, 2021.
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan 等（2021）艾尔文·陈，阿里·马达尼，本·考斯，和尼基尔·奈克。用于属性增强生成的深度外推。*神经信息处理系统进展*，2021年。
- en: Chen et al. (2021) Can Chen, Shuhao Zheng, Xi Chen, Erqun Dong, Xue Steve Liu,
    Hao Liu, and Dejing Dou. Generalized dataweighting via class-level gradient manipulation.
    *Advances in Neural Information Processing Systems*, 2021.
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2021）陈，郑书豪，陈曦，董二群，刘雪，刘浩，和窦德敬。通过类别级梯度操控的广义数据加权。*神经信息处理系统进展*，2021年。
- en: Chen et al. (2022a) Can Chen, Yingxue Zhang, Jie Fu, Xue Liu, and Mark Coates.
    Bidirectional learning for offline infinite-width model-based optimization. In
    *Advances in Neural Information Processing Systems*, 2022a.
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2022a）陈灿，张盈雪，傅杰，刘雪，和马克·科茨。用于离线无限宽模型基础优化的双向学习。发表于 *神经信息处理系统进展*，2022a年。
- en: Chen et al. (2022b) Can Chen, Jingbo Zhou, Fan Wang, Xue Liu, and Dejing Dou.
    Structure-aware protein self-supervised learning. *Bioinformatics*, 2022b.
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2022b）陈灿，周静波，王凡，刘雪，和窦德敬。结构感知的蛋白质自监督学习。*生物信息学*，2022b年。
- en: Chen et al. (2023a) Can Chen, Yingxue Zhang, Xue Liu, and Mark Coates. Bidirectional
    learning for offline model-based biological sequence design. In *International
    Conference on Machine Learning*, 2023a.
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2023a）陈灿，张盈雪，刘雪，和马克·科茨。用于离线模型基础生物序列设计的双向学习。发表于 *国际机器学习会议*，2023a年。
- en: Chen et al. (2022c) Lisha Chen, Songtao Lu, and Tianyi Chen. Understanding benign
    overfitting in gradient-based meta learning. In Alice H. Oh, Alekh Agarwal, Danielle
    Belgrave, and Kyunghyun Cho (eds.), *Advances in Neural Information Processing
    Systems*, 2022c.
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2022c）陈丽莎，卢松涛，和陈天逸。理解基于梯度的元学习中的良性过拟合。在 Alice H. Oh，阿勒赫·阿加瓦尔，丹妮尔·贝尔格雷夫，和崔京贤（编辑），*神经信息处理系统进展*，2022c年。
- en: Chen et al. (2018) Ricky TQ Chen, Yulia Rubanova, Jesse Bettencourt, and David K
    Duvenaud. Neural ordinary differential equations. *Advances in neural information
    processing systems*, 2018.
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2018）陈瑞奇，尤利亚·鲁巴诺娃，杰西·贝滕科特，和大卫·K·杜维诺。神经常微分方程。*神经信息处理系统进展*，2018年。
- en: Chen et al. (2023b) Wenlin Chen, Austin Tripp, and José Miguel Hernández-Lobato.
    Meta-learning adaptive deep kernel gaussian processes for molecular property prediction.
    In *ICLR*, 2023b.
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2023b）陈文林，奥斯汀·特里普，和何塞·米格尔·埃尔南德斯-洛巴托。用于分子属性预测的元学习自适应深度核高斯过程。发表于 *国际学习表征会议*，2023b年。
- en: 'Chen et al. (2019) Yihong Chen, Bei Chen, Xiangnan He, Chen Gao, Yong Li, Jian-Guang
    Lou, and Yue Wang. $\lambda$opt: Learn to regularize recommender models in finer
    levels. In *Special Interest Group on Knowledge Discovery and Data Mining*, 2019.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等（2019）陈一鸿，陈贝，何向南，高晨，李勇，娄建光，和王跃。$\lambda$opt：在更细的层次上学习正则化推荐模型。发表于 *知识发现与数据挖掘特别兴趣组*，2019年。
- en: Chi et al. (2021) Zhixiang Chi, Yang Wang, Yuanhao Yu, and Jin Tang. Test-time
    fast adaptation for dynamic scene deblurring via meta-auxiliary learning. In *CVPR*,
    2021.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等（2021）池志翔，王洋，余元浩，和唐进。通过元辅助学习实现动态场景去模糊的测试时快速适应。发表于 *计算机视觉与模式识别会议*，2021年。
- en: 'Chi et al. (2022) Zhixiang Chi, Li Gu, Huan Liu, Yang Wang, Yuanhao Yu, and
    Jin Tang. Metafscil: A meta-learning approach for few-shot class incremental learning.
    In *CVPR*, 2022.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chi 等（2022）池志翔，顾力，刘欢，王洋，余元浩，和唐进。Metafscil：一种用于少量样本类别增量学习的元学习方法。发表于 *计算机视觉与模式识别会议*，2022年。
- en: Christiansen et al. (2001) Snorre Christiansen, Michael Patriksson, and Laura
    Wynter. Stochastic bilevel programming in structural optimization. *Structural
    and multidisciplinary optimization*, 2001.
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Christiansen 等 (2001) Snorre Christiansen, Michael Patriksson 和 Laura Wynter.
    结构优化中的随机双层规划. *结构与多学科优化*, 2001.
- en: Deleu et al. (2022) Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua
    Bengio, Guillaume Lajoie, and Pierre-Luc Bacon. Continuous-time meta-learning
    with forward mode differentiation. In *International Conference on Learning Representations*,
    2022. URL [https://openreview.net/forum?id=57PipS27Km](https://openreview.net/forum?id=57PipS27Km).
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deleu 等 (2022) Tristan Deleu, David Kanaa, Leo Feng, Giancarlo Kerg, Yoshua
    Bengio, Guillaume Lajoie 和 Pierre-Luc Bacon. 具有正向模式微分的连续时间元学习. 在 *国际学习表征会议*, 2022.
    URL [https://openreview.net/forum?id=57PipS27Km](https://openreview.net/forum?id=57PipS27Km).
- en: 'Dukler et al. (2021) Yonatan Dukler, Alessandro Achille, Giovanni Paolini,
    Avinash Ravichandran, Marzia Polito, and Stefano Soatto. Diva: Dataset derivative
    of a learning task. *arXiv preprint arXiv:2111.09785*, 2021.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dukler 等 (2021) Yonatan Dukler, Alessandro Achille, Giovanni Paolini, Avinash
    Ravichandran, Marzia Polito 和 Stefano Soatto. Diva: 学习任务的数据集导数. *arXiv 预印本 arXiv:2111.09785*,
    2021.'
- en: Fannjiang & Listgarten (2020) Clara Fannjiang and Jennifer Listgarten. Autofocused
    oracles for model-based design. *Advances in Neural Information Processing Systems*,
    2020.
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fannjiang & Listgarten (2020) Clara Fannjiang 和 Jennifer Listgarten. 面向模型的设计的自动聚焦预言机.
    *神经信息处理系统进展*, 2020.
- en: Finn et al. (2017) Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic
    meta-learning for fast adaptation of deep networks. In *International conference
    on machine learning*, 2017.
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Finn 等 (2017) Chelsea Finn, Pieter Abbeel 和 Sergey Levine. 面向模型的元学习以快速适应深度网络.
    在 *国际机器学习会议*, 2017.
- en: Franceschi et al. (2017) Luca Franceschi, Michele Donini, Paolo Frasconi, and
    Massimiliano Pontil. Forward and reverse gradient-based hyperparameter optimization.
    In *International Conference on Machine Learning*, 2017.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franceschi 等 (2017) Luca Franceschi, Michele Donini, Paolo Frasconi 和 Massimiliano
    Pontil. 正向和反向梯度基础的超参数优化. 在 *国际机器学习会议*, 2017.
- en: Franceschi et al. (2018) Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo
    Grazzi, and Massimiliano Pontil. Bilevel programming for hyperparameter optimization
    and meta-learning. In *International Conference on Machine Learning*, 2018.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Franceschi 等 (2018) Luca Franceschi, Paolo Frasconi, Saverio Salzo, Riccardo
    Grazzi 和 Massimiliano Pontil. 用于超参数优化和元学习的双层规划. 在 *国际机器学习会议*, 2018.
- en: Gao et al. (2022) Boyan Gao, Henry Gouk, Yongxin Yang, and Timothy Hospedales.
    Loss function learning for domain generalization by implicit gradient. In *International
    Conference on Machine Learning*, 2022.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao 等 (2022) Boyan Gao, Henry Gouk, Yongxin Yang 和 Timothy Hospedales. 通过隐式梯度的领域泛化损失函数学习.
    在 *国际机器学习会议*, 2022.
- en: Ghadimi & Wang (2018) Saeed Ghadimi and Mengdi Wang. Approximation methods for
    bilevel programming. *arXiv preprint arXiv:1802.02246*, 2018.
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghadimi & Wang (2018) Saeed Ghadimi 和 Mengdi Wang. 双层规划的近似方法. *arXiv 预印本 arXiv:1802.02246*,
    2018.
- en: Grabocka et al. (2019) Josif Grabocka, Randolf Scholz, and Lars Schmidt-Thieme.
    Learning surrogate losses. *arXiv preprint arXiv:1905.10108*, 2019.
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grabocka 等 (2019) Josif Grabocka, Randolf Scholz 和 Lars Schmidt-Thieme. 学习代理损失.
    *arXiv 预印本 arXiv:1905.10108*, 2019.
- en: Grazzi et al. (2020) Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil,
    and Saverio Salzo. On the iteration complexity of hypergradient computation. In
    *International Conference on Machine Learning*. PMLR, 2020.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grazzi 等 (2020) Riccardo Grazzi, Luca Franceschi, Massimiliano Pontil 和 Saverio
    Salzo. 超梯度计算的迭代复杂度. 在 *国际机器学习会议*. PMLR, 2020.
- en: Grefenstette et al. (2019) Edward Grefenstette, Brandon Amos, Denis Yarats,
    Phu Mon Htut, Artem Molchanov, Franziska Meier, Douwe Kiela, Kyunghyun Cho, and
    Soumith Chintala. Generalized inner loop meta-learning. *arXiv preprint arXiv:1910.01727*,
    2019.
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grefenstette 等 (2019) Edward Grefenstette, Brandon Amos, Denis Yarats, Phu Mon
    Htut, Artem Molchanov, Franziska Meier, Douwe Kiela, Kyunghyun Cho 和 Soumith Chintala.
    广义内循环元学习. *arXiv 预印本 arXiv:1910.01727*, 2019.
- en: Gregor & LeCun (2010) Karol Gregor and Yann LeCun. Learning fast approximations
    of sparse coding. In *Proceedings of the 27th international conference on international
    conference on machine learning*, 2010.
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gregor & LeCun (2010) Karol Gregor 和 Yann LeCun. 学习稀疏编码的快速近似. 在 *第27届国际机器学习会议论文集*,
    2010.
- en: Guan et al. (2022) Jiechao Guan, Yong Liu, and Zhiwu Lu. Fine-grained analysis
    of stability and generalization for modern meta learning algorithms. In Alice H.
    Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), *Advances in Neural
    Information Processing Systems*, 2022.
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guan 等人（2022）解超关、永刘 和 志武陆。现代元学习算法的稳定性和泛化的细粒度分析。在 Alice H. Oh、Alekh Agarwal、Danielle
    Belgrave 和 Kyunghyun Cho（编），*神经信息处理系统进展*，2022年。
- en: 'Hansen (2006) Nikolaus Hansen. The CMA evolution strategy: A comparing review.
    In Jose A. Lozano, Pedro Larrañaga, Iñaki Inza, and Endika Bengoetxea (eds.),
    *Towards a New Evolutionary Computation: Advances in the Estimation of Distribution
    Algorithms*. 2006.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hansen（2006）尼古劳斯·汉森。CMA进化策略：比较评述。在 Jose A. Lozano、Pedro Larrañaga、Iñaki Inza
    和 Endika Bengoetxea（编），*迈向新的进化计算：分布估计算法的进展*，2006年。
- en: Hiller et al. (2022) Markus Hiller, Mehrtash Harandi, and Tom Drummond. On enforcing
    better conditioned meta-learning for rapid few-shot adaptation. In Alice H. Oh,
    Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho (eds.), *Advances in Neural
    Information Processing Systems*, 2022.
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hiller 等人（2022）马库斯·希勒、Mehrtash Harandi 和 汤姆·德拉蒙德。在 Alice H. Oh、Alekh Agarwal、Danielle
    Belgrave 和 Kyunghyun Cho（编），*神经信息处理系统进展*，2022年中，关于强制改进条件较好的元学习以实现快速少样本适应。
- en: Hu et al. (2019) Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M Mitchell,
    and Eric P Xing. Learning data manipulation for augmentation and weighting. In
    *Advances in Neural Information Processing Systems*, 2019.
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 等人（2019）志婷胡、博文谭、Russ R Salakhutdinov、Tom M Mitchell 和 Eric P Xing。学习数据操作以进行增强和加权。在
    *神经信息处理系统进展*，2019年。
- en: 'Jacot et al. (2018) Arthur Jacot, Franck Gabriel, and Clément Hongler. Neural
    tangent kernel: Convergence and generalization in neural networks. *Advances in
    neural information processing systems*, 2018.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacot 等人（2018）亚瑟·雅科、弗朗克·加布里埃尔 和 克莱门特·洪勒。神经切线核：神经网络中的收敛性和泛化。在 *神经信息处理系统进展*，2018年。
- en: Kang et al. (2021) Jikun Kang, Miao Liu, Abhinav Gupta, Chris Pal, Xue Liu,
    and Jie Fu. Learning multi-objective curricula for deep reinforcement learning.
    *arXiv preprint arXiv:2110.03032*, 2021.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等人（2021）纪坤·康、苗刘、Abhinav Gupta、Chris Pal、薛刘 和 杰·傅。学习多目标课程以进行深度强化学习。在 *arXiv
    预印本 arXiv:2110.03032*，2021年。
- en: Knyazev et al. (2021) Boris Knyazev, Michal Drozdzal, Graham W Taylor, and Adriana
    Romero Soriano. Parameter prediction for unseen deep architectures. *Advances
    in Neural Information Processing Systems*, 2021.
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Knyazev 等人（2021）鲍里斯·克尼亚泽夫、米哈尔·德罗兹达尔、格雷厄姆·W·泰勒 和 阿德里安娜·罗梅罗·索里亚诺。未见深度架构的参数预测。在
    *神经信息处理系统进展*，2021年。
- en: Koh & Liang (2017) Pang Wei Koh and Percy Liang. Understanding black-box predictions
    via influence functions. In *International Conference on Machine Learning*, 2017.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koh & Liang（2017）庞伟 Koh 和 Percy Liang。通过影响函数理解黑箱预测。在 *国际机器学习会议*，2017年。
- en: 'Lee et al. (2019) Hoyeop Lee, Jinbae Im, Seongwon Jang, Hyunsouk Cho, and Sehee
    Chung. Melu: Meta-learned user preference estimator for cold-start recommendation.
    In *Special Interest Group on Knowledge Discovery and Data Mining*, 2019.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等人（2019）慧叶李、晋培·林、成元·张、贤烁·曹 和 世熙·郑。Melu：用于冷启动推荐的元学习用户偏好估计器。在 *知识发现与数据挖掘特别兴趣小组*，2019年。
- en: Lee et al. (2017) Jaehoon Lee, Yasaman Bahri, Roman Novak, Samuel S Schoenholz,
    Jeffrey Pennington, and Jascha Sohl-Dickstein. Deep neural networks as gaussian
    processes. *arXiv preprint arXiv:1711.00165*, 2017.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等人（2017）在浩李、雅萨曼·巴赫里、罗曼·诺瓦克、Samuel S Schoenholz、杰弗里·佩宁顿 和 贾斯查·索尔-迪克斯坦。深度神经网络作为高斯过程。在
    *arXiv 预印本 arXiv:1711.00165*，2017年。
- en: Lei & Tao (2023) Shiye Lei and Dacheng Tao. A comprehensive survey to dataset
    distillation. *arXiv preprint arXiv:2301.05603*, 2023.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lei & Tao（2023）施业·雷 和 大成·陶。数据集蒸馏的综合调查。在 *arXiv 预印本 arXiv:2301.05603*，2023年。
- en: 'Li et al. (2022) Jiangmeng Li, Wenwen Qiang, Yanan Zhang, Wenyi Mo, Changwen
    Zheng, Bing Su, and Hui Xiong. Metamask: Revisiting dimensional confounder for
    self-supervised learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and
    Kyunghyun Cho (eds.), *Advances in Neural Information Processing Systems*, 2022.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人（2022）姜梦李、温文强、燕南张、文艺莫、常文郑、冰苏、和辉雄。Metamask: 重新审视自监督学习中的维度混杂因素。在 Alice H.
    Oh、Alekh Agarwal、Danielle Belgrave 和 Kyunghyun Cho（编），*神经信息处理系统进展*，2022年。'
- en: 'Li et al. (2017) Zhenguo Li, Fengwei Zhou, Fei Chen, and Hang Li. Meta-sgd:
    Learning to learn quickly for few-shot learning. *arXiv preprint arXiv:1707.09835*,
    2017.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等人（2017）郑国李、冯伟周、费陈 和 行李。Meta-sgd: 学习快速适应少样本学习。在 *arXiv 预印本 arXiv:1707.09835*，2017年。'
- en: 'Liu et al. (2019) Hanxiao Liu, Karen Simonyan, and Yiming Yang. DARTS: Differentiable
    architecture search. In *International Conference on Learning Representations*,
    2019.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2020) Lin Liu, Shanxin Yuan, Jianzhuang Liu, Liping Bao, Gregory
    Slabaugh, and Qi Tian. Self-adaptively learning to demoiré from focused and defocused
    image pairs. *Advances in Neural Information Processing Systems*, 2020.
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lorraine & Duvenaud (2018) Jonathan Lorraine and David Duvenaud. Stochastic
    hyperparameter optimization through hypernetworks. *arXiv preprint arXiv:1802.09419*,
    2018.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lorraine et al. (2020) Jonathan Lorraine, Paul Vicol, and David Duvenaud. Optimizing
    millions of hyperparameters by implicit differentiation. In *International Conference
    on Artificial Intelligence and Statistics*, 2020.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Luketina et al. (2016) Jelena Luketina, Mathias Berglund, Klaus Greff, and Tapani
    Raiko. Scalable gradient-based tuning of continuous regularization hyperparameters.
    In *International conference on machine learning*, 2016.
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lv et al. (2017) Kaifeng Lv, Shunhua Jiang, and Jian Li. Learning gradient
    descent: Better generalization and longer horizons. In *International Conference
    on Machine Learning*, 2017.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2020) Chen Ma, Liheng Ma, Yingxue Zhang, Ruiming Tang, Xue Liu, and
    Mark Coates. Probabilistic metric learning with adaptive margin for top-k recommendation.
    In *Special Interest Group on Knowledge Discovery and Data Mining*, 2020.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MacKay et al. (2019) Matthew MacKay, Paul Vicol, Jon Lorraine, David Duvenaud,
    and Roger Grosse. Self-tuning networks: Bilevel optimization of hyperparameters
    using structured best-response functions. *arXiv preprint arXiv:1903.03088*, 2019.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mairal et al. (2010) Julien Mairal, Francis Bach, Jean Ponce, and Guillermo
    Sapiro. Online learning for matrix factorization and sparse coding. *Journal of
    Machine Learning Research*, 2010.
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Metz et al. (2019) Luke Metz, Niru Maheswaranathan, Jeremy Nixon, Daniel Freeman,
    and Jascha Sohl-Dickstein. Understanding and correcting pathologies in the training
    of learned optimizers. In *International Conference on Machine Learning*, 2019.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nguyen et al. (2020) Timothy Nguyen, Zhourong Chen, and Jaehoon Lee. Dataset
    meta-learning from kernel ridge-regression. *arXiv preprint arXiv:2011.00050*,
    2020.
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nichol et al. (2018) Alex Nichol, Joshua Achiam, and John Schulman. On first-order
    meta-learning algorithms. *arXiv preprint arXiv:1803.02999*, 2018.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Novak et al. (2019) Roman Novak, Lechao Xiao, Jiri Hron, Jaehoon Lee, Alexander A
    Alemi, Jascha Sohl-Dickstein, and Samuel S Schoenholz. Neural tangents: Fast and
    easy infinite neural networks in python. *arXiv preprint arXiv:1912.02803*, 2019.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pedregosa (2016) Fabian Pedregosa. Hyperparameter optimization with approximate
    gradient. In *International conference on machine learning*, 2016.
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Raghu et al. (2021) Aniruddh Raghu, Jonathan Lorraine, Simon Kornblith, Matthew
    McDermott, and David K Duvenaud. Meta-learning to improve pre-training. *Advances
    in Neural Information Processing Systems*, 2021.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rajeswaran et al. (2019) Aravind Rajeswaran, Chelsea Finn, Sham Kakade, and
    Sergey Levine. Meta-learning with implicit gradients. *Advances in Neural Information
    Processing Systems*, 2019.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravi & Larochelle (2016) Sachin Ravi and Hugo Larochelle. Optimization as a
    model for few-shot learning. 2016.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ren et al. (2018) Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urtasun. Learning
    to Reweight Examples for Robust Deep Learning. In *International Conference on
    Machine Learning*, 2018.
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rendle (2012) Steffen Rendle. Learning recommender systems with adaptive regularization.
    In *Web Search and Data Mining*, 2012.
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rojas et al. (2021) Junior Rojas, Eftychios Sifakis, and Ladislav Kavan. Differentiable
    implicit soft-body physics. *arXiv preprint arXiv:2102.05791*, 2021.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rusu et al. (2018) Andrei A Rusu, Dushyant Rao, Jakub Sygnowski, Oriol Vinyals,
    Razvan Pascanu, Simon Osindero, and Raia Hadsell. Meta-learning with latent embedding
    optimization. *arXiv preprint arXiv:1807.05960*, 2018.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shaban et al. (2019) Amirreza Shaban, Ching-An Cheng, Nathan Hatch, and Byron
    Boots. Truncated back-propagation for bilevel optimization. In *International
    Conference on Artificial Intelligence and Statistics*, 2019.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shu et al. (2019) Jun Shu, Qi Xie, Lixuan Yi, Qian Zhao, Sanping Zhou, Zongben
    Xu, and Deyu Meng. Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting.
    In *Advances in Neural Information Processing Systems*, 2019.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shu et al. (2020) Jun Shu, Yanwen Zhu, Qian Zhao, Deyu Meng, and Zongben Xu.
    Meta-lr-schedule-net: learned lr schedules that scale and generalize. 2020.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sinha et al. (2017) Ankur Sinha, Pekka Malo, and Kalyanmoy Deb. A review on
    bilevel optimization: from classical to evolutionary approaches and applications.
    *IEEE Transactions on Evolutionary Computation*, 2017.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tack et al. (2022) Jihoon Tack, Jongjin Park, Hankook Lee, Jaeho Lee, and Jinwoo
    Shin. Meta-learning with self-improving momentum target. In *Advances in Neural
    Information Processing Systems*, 2022.
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trabucco et al. (2022) Brandon Trabucco, Xinyang Geng, Aviral Kumar, and Sergey
    Levine. Design-bench: Benchmarks for data-driven offline model-based optimization.
    *arXiv preprint arXiv:2202.08450*, 2022.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Von Stackelberg (2010) Heinrich Von Stackelberg. *Market structure and equilibrium*.
    Springer Science & Business Media, 2010.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vuorio et al. (2019) Risto Vuorio, Shao-Hua Sun, Hexiang Hu, and Joseph J Lim.
    Multimodal model-agnostic meta-learning via task-aware modulation. *Advances in
    Neural Information Processing Systems*, 2019.
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019) Shipeng Wang, Jian Sun, and Zongben Xu. Hyperadam: A learnable
    task-adaptive adam for network training. In *Proceedings of the AAAI Conference
    on Artificial Intelligence*, 2019.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2018) Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, and Alexei A
    Efros. Dataset distillation. *arXiv preprint arXiv:1811.10959*, 2018.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2018) Tongzhou Wang, Jun-Yan Zhu, Antonio Torralba, 和 Alexei A
    Efros. 数据集蒸馏。*arXiv 预印本 arXiv:1811.10959*，2018年。
- en: Wang et al. (2020) Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos,
    Jaime Carbonell, and Graham Neubig. Optimizing data usage via differentiable rewards.
    In *International Conference on Machine Learning*, 2020.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2020) Xinyi Wang, Hieu Pham, Paul Michel, Antonios Anastasopoulos,
    Jaime Carbonell, 和 Graham Neubig. 通过可微奖励优化数据使用。在 *国际机器学习会议*，2020年。
- en: Wichrowska et al. (2017) Olga Wichrowska, Niru Maheswaranathan, Matthew W Hoffman,
    Sergio Gomez Colmenarejo, Misha Denil, Nando Freitas, and Jascha Sohl-Dickstein.
    Learned optimizers that scale and generalize. In *International Conference on
    Machine Learning*, 2017.
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wichrowska et al. (2017) Olga Wichrowska, Niru Maheswaranathan, Matthew W Hoffman,
    Sergio Gomez Colmenarejo, Misha Denil, Nando Freitas, 和 Jascha Sohl-Dickstein.
    学习的优化器具有规模化和泛化能力。在 *国际机器学习会议*，2017年。
- en: Wu et al. (2021) Yichen Wu, Jun Shu, Qi Xie, Qian Zhao, and Deyu Meng. Learning
    to purify noisy labels via meta soft label corrector. In *AAAI*, 2021.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2021) Yichen Wu, Jun Shu, Qi Xie, Qian Zhao, 和 Deyu Meng. 通过元软标签修正器学习净化噪声标签。在
    *AAAI*，2021年。
- en: Wu et al. (2022) Yichen Wu, Long-Kai Huang, and Ying Wei. Adversarial task up-sampling
    for meta-learning. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun
    Cho (eds.), *Advances in Neural Information Processing Systems*, 2022.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2022) Yichen Wu, Long-Kai Huang, 和 Ying Wei. 对抗任务上采样用于元学习。在 Alice
    H. Oh, Alekh Agarwal, Danielle Belgrave, 和 Kyunghyun Cho (编)，*神经信息处理系统进展*，2022年。
- en: Xu et al. (2021) Minkai Xu, Wujie Wang, Shitong Luo, Chence Shi, Yoshua Bengio,
    Rafael Gomez-Bombarelli, and Jian Tang. An end-to-end framework for molecular
    conformation generation via bilevel programming. In *International Conference
    on Machine Learning*, 2021.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu et al. (2021) Minkai Xu, Wujie Wang, Shitong Luo, Chence Shi, Yoshua Bengio,
    Rafael Gomez-Bombarelli, 和 Jian Tang. 通过双层编程生成分子构象的端到端框架。在 *国际机器学习会议*，2021年。
- en: Yang et al. (2021) Junjie Yang, Kaiyi Ji, and Yingbin Liang. Provably faster
    algorithms for bilevel optimization. *Advances in Neural Information Processing
    Systems*, 2021.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2021) Junjie Yang, Kaiyi Ji, 和 Yingbin Liang. 可证明的双层优化算法加速。*神经信息处理系统进展*，2021年。
- en: Yao et al. (2019) Huaxiu Yao, Ying Wei, Junzhou Huang, and Zhenhui Li. Hierarchically
    structured meta-learning. In *International Conference on Machine Learning*, 2019.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2019) Huaxiu Yao, Ying Wei, Junzhou Huang, 和 Zhenhui Li. 分层结构的元学习。在
    *国际机器学习会议*，2019年。
- en: Yao et al. (2021) Huaxiu Yao, Ying Wei, Long-Kai Huang, Ding Xue, Junzhou Huang,
    and Zhenhui Jessie Li. Functionally regionalized knowledge transfer for low-resource
    drug discovery. *Advances in Neural Information Processing Systems*, 2021.
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2021) Huaxiu Yao, Ying Wei, Long-Kai Huang, Ding Xue, Junzhou Huang,
    和 Zhenhui Jessie Li. 面向低资源药物发现的功能区域化知识迁移。*神经信息处理系统进展*，2021年。
- en: 'Yu et al. (2021) Sihyun Yu, Sungsoo Ahn, Le Song, and Jinwoo Shin. Roma: Robust
    model adaptation for offline model-based optimization. *Advances in Neural Information
    Processing Systems*, 2021.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2021) Sihyun Yu, Sungsoo Ahn, Le Song, 和 Jinwoo Shin. Roma：用于离线模型优化的鲁棒模型适应。*神经信息处理系统进展*，2021年。
- en: Yuan & Wu (2021) Chia-Hung Yuan and Shan-Hung Wu. Neural tangent generalization
    attacks. In *International Conference on Machine Learning*, 2021.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuan & Wu (2021) Chia-Hung Yuan 和 Shan-Hung Wu. 神经切线泛化攻击。在 *国际机器学习会议*，2021年。
- en: 'Zehnder et al. (2021) Jonas Zehnder, Yue Li, Stelian Coros, and Bernhard Thomaszewski.
    Ntopo: Mesh-free topology optimization using implicit neural representations.
    *Advances in Neural Information Processing Systems*, 2021.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zehnder et al. (2021) Jonas Zehnder, Yue Li, Stelian Coros, 和 Bernhard Thomaszewski.
    Ntopo：使用隐式神经表示的无网格拓扑优化。*神经信息处理系统进展*，2021年。
- en: Zhang et al. (2023) An Zhang, Fangfu Liu, Wenchang Ma, Zhibo Cai, Xiang Wang,
    and Tat-Seng Chua. Boosting causal discovery via adaptive sample reweighting.
    In *ICLR*, 2023.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang et al. (2023) An Zhang, Fangfu Liu, Wenchang Ma, Zhibo Cai, Xiang Wang,
    和 Tat-Seng Chua. 通过自适应样本重标定促进因果发现。在 *ICLR*，2023年。
- en: 'Zhong et al. (2022) Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu,
    and Jin Tang. Meta-dmoe: Adapting to domain shift by meta-distillation from mixture-of-experts.
    *arXiv preprint arXiv:2210.03885*, 2022.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhong et al. (2022) Tao Zhong, Zhixiang Chi, Li Gu, Yang Wang, Yuanhao Yu, 和
    Jin Tang. Meta-dmoe：通过专家混合的元蒸馏适应领域变化。*arXiv 预印本 arXiv:2210.03885*，2022年。
- en: Zou et al. (2021) Yingtian Zou, Fusheng Liu, and Qianxiao Li. Unraveling model-agnostic
    meta-learning via the adaptation learning rate. In *International Conference on
    Learning Representations*, 2021.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zou 等人（2021），Yingtian Zou、Fusheng Liu 和 Qianxiao Li。通过适应学习率揭示模型无关的元学习。在 *国际学习表征会议*，2021。
