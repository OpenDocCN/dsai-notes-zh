["```py\n**from** **fastai.text** **import** *\n```", "```py\nPATH = Path('data/translate')\nTMP_PATH = PATH/'tmp'\nTMP_PATH.mkdir(exist_ok=**True**)\nfname='giga-fren.release2.fixed'\nen_fname = PATH/f'**{fname}**.en'\nfr_fname = PATH/f'**{fname}**.fr'\n```", "```py\nre_eq = re.compile('^(Wh[^?.!]+\\?)')\nre_fq = re.compile('^([^?.!]+\\?)')lines = ((re_eq.search(eq), re_fq.search(fq)) \n         **for** eq, fq **in** zip(open(en_fname, encoding='utf-8'), \n                           open(fr_fname, encoding='utf-8')))qs = [(e.group(), f.group()) **for** e,f **in** lines **if** e **and** f]\n```", "```py\npickle.dump(qs, (PATH/'fr-en-qs.pkl').open('wb'))\nqs = pickle.load((PATH/'fr-en-qs.pkl').open('rb'))\n```", "```py\nqs[:5], len(qs)*([('What is light ?', 'Qu\u2019est-ce que la lumi\u00e8re?'),\n  ('Who are we?', 'O\u00f9 sommes-nous?'),\n  ('Where did we come from?', \"D'o\u00f9 venons-nous?\"),\n  ('What would we do without it?', 'Que ferions-nous sans elle ?'),\n  ('What is the absolute location (latitude and longitude) of Badger, Newfoundland and Labrador?',\n   'Quelle sont les coordonn\u00e9es (latitude et longitude) de Badger, \u00e0 Terre-Neuve-etLabrador?')],\n 52331)*\n```", "```py\nen_qs,fr_qs = zip(*qs)\n```", "```py\nen_tok = Tokenizer.proc_all_mp(partition_by_cores(en_qs))fr_tok = Tokenizer.proc_all_mp(partition_by_cores(fr_qs), 'fr')\n```", "```py\nen_tok[0], fr_tok[0](['what', 'is', 'light', '?'],\n ['qu\u2019', 'est', '-ce', 'que', 'la', 'lumi\u00e8re', '?'])\n```", "```py\nnp.percentile([len(o) **for** o **in** en_tok], 90), \n    np.percentile([len(o) **for** o **in** fr_tok], 90)*(23.0, 28.0)*keep = np.array([len(o)<30 **for** o **in** en_tok])en_tok = np.array(en_tok)[keep]\nfr_tok = np.array(fr_tok)[keep]pickle.dump(en_tok, (PATH/'en_tok.pkl').open('wb'))\npickle.dump(fr_tok, (PATH/'fr_tok.pkl').open('wb'))en_tok = pickle.load((PATH/'en_tok.pkl').open('rb'))\nfr_tok = pickle.load((PATH/'fr_tok.pkl').open('rb'))\n```", "```py\n**def** toks2ids(tok,pre):\n    freq = Counter(p **for** o **in** tok **for** p **in** o)\n    itos = [o **for** o,c **in** freq.most_common(40000)]\n    itos.insert(0, '_bos_')\n    itos.insert(1, '_pad_')\n    itos.insert(2, '_eos_')\n    itos.insert(3, '_unk')\n    stoi = collections.defaultdict(**lambda**: 3, \n                                   {v:k **for** k,v **in** enumerate(itos)})\n    ids = np.array([([stoi[o] **for** o **in** p] + [2]) **for** p **in** tok])\n    np.save(TMP_PATH/f'**{pre}**_ids.npy', ids)\n    pickle.dump(itos, open(TMP_PATH/f'**{pre}**_itos.pkl', 'wb'))\n    **return** ids,itos,stoi\n```", "```py\nen_ids,en_itos,en_stoi = toks2ids(en_tok,'en')\nfr_ids,fr_itos,fr_stoi = toks2ids(fr_tok,'fr')\n```", "```py\n**def** load_ids(pre):\n    ids = np.load(TMP_PATH/f'**{pre}**_ids.npy')\n    itos = pickle.load(open(TMP_PATH/f'**{pre}**_itos.pkl', 'rb'))\n    stoi = collections.defaultdict(**lambda**: 3, \n                                   {v:k **for** k,v **in** enumerate(itos)})\n    **return** ids,itos,stoien_ids,en_itos,en_stoi = load_ids('en')\nfr_ids,fr_itos,fr_stoi = load_ids('fr')[fr_itos[o] **for** o **in** fr_ids[0]], len(en_itos), len(fr_itos)*(['qu\u2019', 'est', '-ce', 'que', 'la', 'lumi\u00e8re', '?', '_eos_'], 17573, 24793)*\n```", "```py\n*# ! pip install git+https://github.com/facebookresearch/fastText.git***import** **fastText** **as** **ft**\n```", "```py\nen_vecs = ft.load_model(str((PATH/'wiki.en.bin')))fr_vecs = ft.load_model(str((PATH/'wiki.fr.bin')))\n```", "```py\n**def** get_vecs(lang, ft_vecs):\n    vecd = {w:ft_vecs.get_word_vector(w) \n                **for** w **in** ft_vecs.get_words()}\n    pickle.dump(vecd, open(PATH/f'wiki.**{lang}**.pkl','wb'))\n    **return** vecden_vecd = get_vecs('en', en_vecs)\nfr_vecd = get_vecs('fr', fr_vecs)en_vecd = pickle.load(open(PATH/'wiki.en.pkl','rb'))\nfr_vecd = pickle.load(open(PATH/'wiki.fr.pkl','rb'))ft_words = ft_vecs.get_words(include_freq=**True**)\nft_word_dict = {k:v **for** k,v **in** zip(*ft_words)}\nft_words = sorted(ft_word_dict.keys(), \n                     key=**lambda** x: ft_word_dict[x])\n```", "```py\ndim_en_vec = len(en_vecd[','])\ndim_fr_vec = len(fr_vecd[','])\ndim_en_vec,dim_fr_vec*(300, 300)*\n```", "```py\nen_vecs = np.stack(list(en_vecd.values()))\nen_vecs.mean(),en_vecs.std()*(0.0075652334, 0.29283327)*\n```", "```py\nenlen_90 = int(np.percentile([len(o) **for** o **in** en_ids], 99))\nfrlen_90 = int(np.percentile([len(o) **for** o **in** fr_ids], 97))\nenlen_90,frlen_90*(29, 33)*\n```", "```py\nen_ids_tr = np.array([o[:enlen_90] **for** o **in** en_ids])\nfr_ids_tr = np.array([o[:frlen_90] **for** o **in** fr_ids])**class** **Seq2SeqDataset**(Dataset):\n    **def** __init__(self, x, y): self.x,self.y = x,y\n    **def** __getitem__(self, idx): **return** A(self.x[idx], self.y[idx])\n    **def** __len__(self): **return** len(self.x)\n```", "```py\nnp.random.seed(42)\ntrn_keep = np.random.rand(len(en_ids_tr))>0.1\nen_trn,fr_trn = en_ids_tr[trn_keep],fr_ids_tr[trn_keep]\nen_val,fr_val = en_ids_tr[~trn_keep],fr_ids_tr[~trn_keep]\nlen(en_trn),len(en_val)*(45219, 5041)*\n```", "```py\ntrn_ds = Seq2SeqDataset(fr_trn,en_trn)\nval_ds = Seq2SeqDataset(fr_val,en_val)\n```", "```py\nbs=125trn_samp = SortishSampler(en_trn, key=**lambda** x: len(en_trn[x]), \n                          bs=bs)\nval_samp = SortSampler(en_val, key=**lambda** x: len(en_val[x]))trn_dl = DataLoader(trn_ds, bs, transpose=**True**, transpose_y=**True**, \n                    num_workers=1, pad_idx=1, pre_pad=**False**, \n                    sampler=trn_samp)\nval_dl = DataLoader(val_ds, int(bs*1.6), transpose=**True**, \n                    transpose_y=**True**, num_workers=1, pad_idx=1,\n                    pre_pad=**False**, sampler=val_samp)\nmd = ModelData(PATH, trn_dl, val_dl)\n```", "```py\n**def** create_emb(vecs, itos, em_sz):\n    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n    wgts = emb.weight.data\n    miss = []\n    **for** i,w **in** enumerate(itos):\n        **try**: wgts[i] = torch.from_numpy(vecs[w]*3)\n        **except**: miss.append(w)\n    print(len(miss),miss[5:10])\n    **return** embnh,nl = 256,2\n```", "```py\n*3097 ['l\u2019', \"d'\", 't_up', 'd\u2019', \"qu'\"]\n1285 [\"'s\", '\u2019s', \"n't\", 'n\u2019t', ':']*\n```", "```py\n**class** **Seq2SeqRNN**(nn.Module):\n    **def** __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, \n                 itos_dec, em_sz_dec, nh, out_sl, nl=2):\n        super().__init__()\n        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n        self.emb_enc_drop = nn.Dropout(0.15)\n        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, \n                              dropout=0.25)\n        self.out_enc = nn.Linear(nh, em_sz_dec, bias=**False**)\n\n        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, \n                              dropout=0.1)\n        self.out_drop = nn.Dropout(0.35)\n        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n        self.out.weight.data = self.emb_dec.weight.data\n\n    **def** forward(self, inp):\n        sl,bs = inp.size()\n        h = self.initHidden(bs)\n        emb = self.emb_enc_drop(self.emb_enc(inp))\n        enc_out, h = self.gru_enc(emb, h)\n        h = self.out_enc(h)\n\n        dec_inp = V(torch.zeros(bs).long())\n        res = []\n        **for** i **in** range(self.out_sl):\n            emb = self.emb_dec(dec_inp).unsqueeze(0)\n            outp, h = self.gru_dec(emb, h)\n            outp = self.out(self.out_drop(outp[0]))\n            res.append(outp)\n            dec_inp = V(outp.data.max(1)[1])\n            **if** (dec_inp==1).all(): **break**\n        **return** torch.stack(res)\n\n    **def** initHidden(self, bs): \n        **return** V(torch.zeros(self.nl, bs, self.nh))\n```", "```py\n**def** seq2seq_loss(input, target):\n    sl,bs = target.size()\n    sl_in,bs_in,nc = input.size()\n    **if** sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n    input = input[:sl]\n    **return** F.cross_entropy(input.view(-1,nc), target.view(-1))\n```", "```py\nopt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n```", "```py\nrnn = Seq2SeqRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, \n                 dim_en_vec, nh, enlen_90)\nlearn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\nlearn.crit = seq2seq_loss*3097 ['l\u2019', \"d'\", 't_up', 'd\u2019', \"qu'\"]\n1285 [\"'s\", '\u2019s', \"n't\", 'n\u2019t', ':']*\n```", "```py\nlearn.lr_find()\nlearn.sched.plot()\n```", "```py\nlr=3e-3\nlearn.fit(lr, 1, cycle_len=12, use_clr=(20,10))*epoch      trn_loss   val_loss                              \n    0      5.48978    5.462648  \n    1      4.616437   4.770539                              \n    2      4.345884   4.37726                               \n    3      3.857125   4.136014                              \n    4      3.612306   3.941867                              \n    5      3.375064   3.839872                              \n    6      3.383987   3.708972                              \n    7      3.224772   3.664173                              \n    8      3.238523   3.604765                              \n    9      2.962041   3.587814                              \n    10     2.96163    3.574888                              \n    11     2.866477   3.581224**[3.5812237]* learn.save('initial')\nlearn.load('initial')\n```", "```py\nx,y = next(iter(val_dl))\nprobs = learn.model(V(x))\npreds = to_np(probs.max(2)[1])\n\n**for** i **in** range(180,190):\n    print(' '.join([fr_itos[o] **for** o **in** x[:,i] **if** o != 1]))\n    print(' '.join([en_itos[o] **for** o **in** y[:,i] **if** o != 1]))\n    print(' '.join([en_itos[o] **for** o **in** preds[:,i] **if** o!=1]))\n    print()*quels facteurs pourraient influer sur le choix de leur emplacement ? _eos_\nwhat factors influencetheir location ? _eos_\nwhat factors might might influence on the their ? ? _eos_\n\nqu\u2019 est -ce qui ne peut pas changer ? _eos_\nwhat can not change ? _eos_\nwhat not change change ? _eos_\n\nque faites - vous ? _eos_\nwhat do you do ? _eos_\nwhat do you do ? _eos_\n\nqui r\u00e9glemente les pyl\u00f4nes d' antennes ? _eos_\nwho regulates antenna towers ? _eos_\nwho regulates the doors doors ? _eos_\n\no\u00f9 sont - ils situ\u00e9s ? _eos_\nwhere are they located ? _eos_\nwhere are the located ? _eos_\n\nquelles sont leurs comp\u00e9tences ? _eos_\nwhat are their qualifications ? _eos_\nwhat are their skills ? _eos_\n\nqui est victime de harc\u00e8lement sexuel ? _eos_\nwho experiences sexual harassment ? _eos_\nwho is victim sexual sexual ? ? _eos_\n\nquelles sont les personnes qui visitent les communaut\u00e9s autochtones ? _eos_\nwho visits indigenous communities ? _eos_\nwho are people people aboriginal aboriginal ? _eos_\n\npourquoi ces trois points en particulier ? _eos_\nwhy these specific three ? _eos_\nwhy are these two different ? ? _eos_\n\npourquoi ou pourquoi pas ? _eos_\nwhy or why not ? _eos_\nwhy or why not _eos_*\n```", "```py\n**class** **Seq2SeqRNN_Bidir**(nn.Module):\n    **def** __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, \n                 itos_dec, em_sz_dec, nh, out_sl, nl=2):\n        super().__init__()\n        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl,\n                              dropout=0.25, bidirectional=**True**)\n        self.out_enc = nn.Linear(nh***2**, em_sz_dec, bias=**False**)\n        self.drop_enc = nn.Dropout(0.05)\n        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl,\n                              dropout=0.1)\n        self.emb_enc_drop = nn.Dropout(0.15)\n        self.out_drop = nn.Dropout(0.35)\n        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n        self.out.weight.data = self.emb_dec.weight.data\n\n    **def** forward(self, inp):\n        sl,bs = inp.size()\n        h = self.initHidden(bs)\n        emb = self.emb_enc_drop(self.emb_enc(inp))\n        enc_out, h = self.gru_enc(emb, h)\n        h = h.view(2,2,bs,-1).permute(0,2,1,3)\n                .contiguous().view(2,bs,-1)\n        h = self.out_enc(self.drop_enc(h)) dec_inp = V(torch.zeros(bs).long())\n        res = []\n        **for** i **in** range(self.out_sl):\n            emb = self.emb_dec(dec_inp).unsqueeze(0)\n            outp, h = self.gru_dec(emb, h)\n            outp = self.out(self.out_drop(outp[0]))\n            res.append(outp)\n            dec_inp = V(outp.data.max(1)[1])\n            **if** (dec_inp==1).all(): **break**\n        **return** torch.stack(res)\n\n    **def** initHidden(self, bs): \n        **return** V(torch.zeros(self.nl***2**, bs, self.nh))\n```", "```py\nrnn = Seq2SeqRNN_Bidir(fr_vecd, fr_itos, dim_fr_vec, en_vecd,\n                       en_itos, dim_en_vec, nh, enlen_90)\nlearn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\nlearn.crit = seq2seq_losslearn.fit(lr, 1, cycle_len=12, use_clr=(20,10))*epoch      trn_loss   val_loss                              \n    0      4.896942   4.761351  \n    1      4.323335   4.260878                              \n    2      3.962747   4.06161                               \n    3      3.596254   3.940087                              \n    4      3.432788   3.944787                              \n    5      3.310895   3.686629                              \n    6      3.454976   3.638168                              \n    7      3.093827   3.588456                              \n    8      3.257495   3.610536                              \n    9      3.033345   3.540344                              \n    10     2.967694   3.516766                              \n    11     2.718945   3.513977**[3.5139771]*\n```", "```py\n**class** **Seq2SeqStepper**(Stepper):\n    **def** step(self, xs, y, epoch):\n        self.m.pr_force = (10-epoch)*0.1 **if** epoch<10 **else** 0\n        xtra = []\n        output = self.m(*xs, y)\n        **if** isinstance(output,tuple): output,*xtra = output\n        self.opt.zero_grad()\n        loss = raw_loss = self.crit(output, y)\n        **if** self.reg_fn: loss = self.reg_fn(output, xtra, raw_loss)\n        loss.backward()\n        **if** self.clip:   *# Gradient clipping*\n            nn.utils.clip_grad_norm(trainable_params_(self.m), \n                                    self.clip)\n        self.opt.step()\n        **return** raw_loss.data[0]\n```", "```py\n**class** **Seq2SeqRNN_TeacherForcing**(nn.Module):\n    **def** __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec,\n                 itos_dec, em_sz_dec, nh, out_sl, nl=2):\n        super().__init__()\n        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, \n                              dropout=0.25)\n        self.out_enc = nn.Linear(nh, em_sz_dec, bias=**False**)\n        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, \n                              dropout=0.1)\n        self.emb_enc_drop = nn.Dropout(0.15)\n        self.out_drop = nn.Dropout(0.35)\n        self.out = nn.Linear(em_sz_dec, len(itos_dec))\n        self.out.weight.data = self.emb_dec.weight.data\n        self.pr_force = 1.\n\n    **def** forward(self, inp, y=**None**):\n        sl,bs = inp.size()\n        h = self.initHidden(bs)\n        emb = self.emb_enc_drop(self.emb_enc(inp))\n        enc_out, h = self.gru_enc(emb, h)\n        h = self.out_enc(h) dec_inp = V(torch.zeros(bs).long())\n        res = []\n        **for** i **in** range(self.out_sl):\n            emb = self.emb_dec(dec_inp).unsqueeze(0)\n            outp, h = self.gru_dec(emb, h)\n            outp = self.out(self.out_drop(outp[0]))\n            res.append(outp)\n            dec_inp = V(outp.data.max(1)[1])\n            **if** (dec_inp==1).all(): **break**\n            **if** (y **is** **not** **None**) **and** (random.random()<self.pr_force):\n                **if** i>=len(y): **break**\n                dec_inp = y[i]\n        **return** torch.stack(res)\n\n    **def** initHidden(self, bs): \n        **return** V(torch.zeros(self.nl, bs, self.nh))\n```", "```py\n**class** **Seq2SeqStepper**(Stepper):\n    **def** step(self, xs, y, epoch):\n        self.m.pr_force = (10-epoch)*0.1 **if** epoch<10 **else** 0\n        **return** super.step(xs, y, epoch)\n```", "```py\n **if** (y **is** **not** **None**) **and** (random.random()<self.pr_force):\n                **if** i>=len(y): **break**\n                dec_inp = y[i]\n```", "```py\nrnn = Seq2SeqRNN_TeacherForcing(fr_vecd, fr_itos, dim_fr_vec, \n                         en_vecd, en_itos, dim_en_vec, nh, enlen_90)\nlearn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\nlearn.crit = seq2seq_losslearn.fit(lr, 1, cycle_len=12, use_clr=(20,10), \n          stepper=Seq2SeqStepper)*epoch      trn_loss   val_loss                              \n    0      4.460622   12.661013 \n    1      3.468132   7.138729                              \n    2      3.235244   6.202878                              \n    3      3.101616   5.454283                              \n    4      3.135989   4.823736                              \n    5      2.980696   4.933402                              \n    6      2.91562    4.287475                              \n    7      3.032661   3.975346                              \n    8      3.103834   3.790773                              \n    9      3.121457   3.578682                              \n    10     2.917534   3.532427                              \n    11     3.326946   3.490643**[3.490643]*\n```", "```py\n**def** rand_t(*sz): **return** torch.randn(sz)/math.sqrt(sz[0])\n**def** rand_p(*sz): **return** nn.Parameter(rand_t(*sz))**class** **Seq2SeqAttnRNN**(nn.Module):\n    **def** __init__(self, vecs_enc, itos_enc, em_sz_enc, vecs_dec, \n                 itos_dec, em_sz_dec, nh, out_sl, nl=2):\n        super().__init__()\n        self.emb_enc = create_emb(vecs_enc, itos_enc, em_sz_enc)\n        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n        self.gru_enc = nn.GRU(em_sz_enc, nh, num_layers=nl, \n                              dropout=0.25)\n        self.out_enc = nn.Linear(nh, em_sz_dec, bias=**False**)\n        self.emb_dec = create_emb(vecs_dec, itos_dec, em_sz_dec)\n        self.gru_dec = nn.GRU(em_sz_dec, em_sz_dec, num_layers=nl, \n                              dropout=0.1)\n        self.emb_enc_drop = nn.Dropout(0.15)\n        self.out_drop = nn.Dropout(0.35)\n        self.out = nn.Linear(em_sz_dec*2, len(itos_dec))\n        self.out.weight.data = self.emb_dec.weight.data self.W1 = rand_p(nh, em_sz_dec)\n        self.l2 = nn.Linear(em_sz_dec, em_sz_dec)\n        self.l3 = nn.Linear(em_sz_dec+nh, em_sz_dec)\n        self.V = rand_p(em_sz_dec) **def** forward(self, inp, y=**None**, ret_attn=**False**):\n        sl,bs = inp.size()\n        h = self.initHidden(bs)\n        emb = self.emb_enc_drop(self.emb_enc(inp))\n        enc_out, h = self.gru_enc(emb, h)\n        h = self.out_enc(h) dec_inp = V(torch.zeros(bs).long())\n        res,attns = [],[]\n        w1e = enc_out @ self.W1\n        **for** i **in** range(self.out_sl):\n            w2h = self.l2(h[-1])\n            u = F.tanh(w1e + w2h)\n            a = F.softmax(u @ self.V, 0)\n            attns.append(a)\n            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n            emb = self.emb_dec(dec_inp)\n            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n\n            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n            outp = self.out(self.out_drop(outp[0]))\n            res.append(outp)\n            dec_inp = V(outp.data.max(1)[1])\n            **if** (dec_inp==1).all(): **break**\n            **if** (y **is** **not** **None**) **and** (random.random()<self.pr_force):\n                **if** i>=len(y): **break**\n                dec_inp = y[i] res = torch.stack(res)\n        **if** ret_attn: res = res,torch.stack(attns)\n        **return** res **def** initHidden(self, bs): \n        **return** V(torch.zeros(self.nl, bs, self.nh))\n```", "```py\nw2h = self.l2(h[-1])\nu = F.tanh(w1e + w2h)\na = F.softmax(u @ self.V, 0)\n```", "```py\nrnn = Seq2SeqAttnRNN(fr_vecd, fr_itos, dim_fr_vec, en_vecd, en_itos, dim_en_vec, nh, enlen_90)\nlearn = RNN_Learner(md, SingleModel(to_gpu(rnn)), opt_fn=opt_fn)\nlearn.crit = seq2seq_loss\nlr=2e-3learn.fit(lr, 1, cycle_len=15, use_clr=(20,10), \n          stepper=Seq2SeqStepper)*epoch      trn_loss   val_loss                              \n    0      3.882168   11.125291 \n    1      3.599992   6.667136                              \n    2      3.236066   5.552943                              \n    3      3.050283   4.919096                              \n    4      2.99024    4.500383                              \n    5      3.07999    4.000295                              \n    6      2.891087   4.024115                              \n    7      2.854725   3.673913                              \n    8      2.979285   3.590668                              \n    9      3.109851   3.459867                              \n    10     2.92878    3.517598                              \n    11     2.778292   3.390253                              \n    12     2.795427   3.388423                              \n    13     2.809757   3.353334                              \n    14     2.6723     3.368584*[3.3685837]\n```", "```py\nlearn.save('attn')\n```", "```py\nx,y = next(iter(val_dl))\nprobs,attns = learn.model(V(x),ret_attn=**True**)\npreds = to_np(probs.max(2)[1])**for** i **in** range(180,190):\n    print(' '.join([fr_itos[o] **for** o **in** x[:,i] **if** o != 1]))\n    print(' '.join([en_itos[o] **for** o **in** y[:,i] **if** o != 1]))\n    print(' '.join([en_itos[o] **for** o **in** preds[:,i] **if** o!=1]))\n    print()*quels facteurs pourraient influer sur le choix de leur emplacement ? _eos_\nwhat factors influencetheir location ? _eos_\nwhat factors might influence the their their their ? _eos_**qu\u2019 est -ce qui ne peut pas changer ? _eos_\nwhat can not change ? _eos_\nwhat can not change change ? _eos_**que faites - vous ? _eos_\nwhat do you do ? _eos_\nwhat do you do ? _eos_**qui r\u00e9glemente les pyl\u00f4nes d' antennes ? _eos_\nwho regulates antenna towers ? _eos_\nwho regulates the lights ? ? _eos_**o\u00f9 sont - ils situ\u00e9s ? _eos_\nwhere are they located ? _eos_\nwhere are they located ? _eos_**quelles sont leurs comp\u00e9tences ? _eos_\nwhat are their qualifications ? _eos_\nwhat are their skills ? _eos_**qui est victime de harc\u00e8lement sexuel ? _eos_\nwho experiences sexual harassment ? _eos_\nwho is victim sexual sexual ? _eos_**quelles sont les personnes qui visitent les communaut\u00e9s autochtones ? _eos_\nwho visits indigenous communities ? _eos_\nwho is people people aboriginal people ? _eos_**pourquoi ces trois points en particulier ? _eos_\nwhy these specific three ? _eos_\nwhy are these three three ? ? _eos_**pourquoi ou pourquoi pas ? _eos_\nwhy or why not ? _eos_\nwhy or why not ? _eos_*\n```", "```py\nprobs,attns = learn.model(V(x),ret_attn=**True**)\n```", "```py\nattn = to_np(attns[...,180])fig, axes = plt.subplots(3, 3, figsize=(15, 10))\n**for** i,ax **in** enumerate(axes.flat):\n    ax.plot(attn[i])\n```", "```py\n**from** **fastai.conv_learner** **import** *\ntorch.backends.cudnn.benchmark=**True**\n\n**import** **fastText** **as** **ft**PATH = Path('data/imagenet/')\nTMP_PATH = PATH/'tmp'\nTRANS_PATH = Path('data/translate/')\nPATH_TRN = PATH/'train'\n```", "```py\nft_vecs = ft.load_model(str((TRANS_PATH/'wiki.en.bin')))np.corrcoef(ft_vecs.get_word_vector('jeremy'), \n            ft_vecs.get_word_vector('Jeremy'))*array([[1\\.     , 0.60866],\n       [0.60866, 1\\.     ]])*\n```", "```py\nnp.corrcoef(ft_vecs.get_word_vector('banana'), \n            ft_vecs.get_word_vector('Jeremy'))*array([[1\\.     , 0.14482],\n       [0.14482, 1\\.     ]])*\n```", "```py\nft_words = ft_vecs.get_words(include_freq=**True**)\nft_word_dict = {k:v **for** k,v **in** zip(*ft_words)}\nft_words = sorted(ft_word_dict.keys(), key=**lambda** x: ft_word_dict[x])len(ft_words)*2519370***from** **fastai.io** **import** get_data\n```", "```py\nCLASSES_FN = 'imagenet_class_index.json'\nget_data(f'http://files.fast.ai/models/{CLASSES_FN}', \n         TMP_PATH/CLASSES_FN)\n```", "```py\nWORDS_FN = 'classids.txt'\nget_data(f'http://files.fast.ai/data/{WORDS_FN}', PATH/WORDS_FN)\n```", "```py\nclass_dict = json.load((TMP_PATH/CLASSES_FN).open())\nclassids_1k = dict(class_dict.values())\nnclass = len(class_dict); nclass*1000*\n```", "```py\nclass_dict['0']*['n01440764', 'tench']*\n```", "```py\nclassid_lines = (PATH/WORDS_FN).open().readlines()\nclassid_lines[:5]*['n00001740 entity\\n',\n 'n00001930 physical_entity\\n',\n 'n00002137 abstraction\\n',\n 'n00002452 thing\\n',\n 'n00002684 object\\n']*classids = dict(l.strip().split() **for** l **in** classid_lines)\nlen(classids),len(classids_1k)*(82115, 1000)*\n```", "```py\nlc_vec_d = {w.lower(): ft_vecs.get_word_vector(w) **for** w \n                           **in** ft_words[-1000000:]}\n```", "```py\nsyn_wv = [(k, lc_vec_d[v.lower()]) **for** k,v **in** classids.items()\n          **if** v.lower() **in** lc_vec_d]\nsyn_wv_1k = [(k, lc_vec_d[v.lower()]) **for** k,v **in** classids_1k.items()\n          **if** v.lower() **in** lc_vec_d]\nsyn2wv = dict(syn_wv)\nlen(syn2wv)*49469*\n```", "```py\npickle.dump(syn2wv, (TMP_PATH/'syn2wv.pkl').open('wb'))\npickle.dump(syn_wv_1k, (TMP_PATH/'syn_wv_1k.pkl').open('wb'))syn2wv = pickle.load((TMP_PATH/'syn2wv.pkl').open('rb'))\nsyn_wv_1k = pickle.load((TMP_PATH/'syn_wv_1k.pkl').open('rb'))\n```", "```py\nimages = []\nimg_vecs = []**for** d **in** (PATH/'train').iterdir():\n    **if** d.name **not** **in** syn2wv: **continue**\n    vec = syn2wv[d.name]\n    **for** f **in** d.iterdir():\n        images.append(str(f.relative_to(PATH)))\n        img_vecs.append(vec)n_val=0\n**for** d **in** (PATH/'valid').iterdir():\n    **if** d.name **not** **in** syn2wv: **continue**\n    vec = syn2wv[d.name]\n    **for** f **in** d.iterdir():\n        images.append(str(f.relative_to(PATH)))\n        img_vecs.append(vec)\n        n_val += 1n_val*28650*\n```", "```py\nimg_vecs = np.stack(img_vecs)\nimg_vecs.shape\n```", "```py\npickle.dump(images, (TMP_PATH/'images.pkl').open('wb'))\npickle.dump(img_vecs, (TMP_PATH/'img_vecs.pkl').open('wb'))images = pickle.load((TMP_PATH/'images.pkl').open('rb'))\nimg_vecs = pickle.load((TMP_PATH/'img_vecs.pkl').open('rb'))arch = resnet50n = len(images); n*766876*val_idxs = list(range(n-28650, n))\n```", "```py\ntfms = tfms_from_model(arch, 224, transforms_side_on, max_zoom=1.1)\nmd = ImageClassifierData.**from_names_and_array**(PATH, images,  \n        img_vecs, val_idxs=val_idxs, classes=**None**, tfms=tfms,\n        continuous=**True**, bs=256)x,y = next(iter(md.val_dl))\n```", "```py\nmodels = ConvnetBuilder(arch, md.c, is_multi=**False**, is_reg=**True**, \n             xtra_fc=[1024], ps=[0.2,0.2])learn = ConvLearner(md, models, precompute=**True**)\nlearn.opt_fn = partial(optim.Adam, betas=(0.9,0.99))\n```", "```py\n**def** cos_loss(inp,targ):\n    **return** 1 - F.cosine_similarity(inp,targ).mean()\nlearn.crit = cos_losslearn.lr_find(start_lr=1e-4, end_lr=1e15)learn.sched.plot()lr = 1e-2\nwd = 1e-7\n```", "```py\nlearn.precompute=**True**learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))*epoch      trn_loss   val_loss                                  \n    0      0.104692   0.125685  \n    1      0.112455   0.129307                                 \n    2      0.110631   0.126568                                 \n    3      0.108629   0.127338                                 \n    4      0.110791   0.125033                                 \n    5      0.108859   0.125186                                 \n    6      0.106582   0.123875                                 \n    7      0.103227   0.123945                                 \n    8      0.10396    0.12304                                  \n    9      0.105898   0.124894                                 \n    10     0.10498    0.122582                                 \n    11     0.104983   0.122906                                 \n    12     0.102317   0.121171                                  \n    13     0.10017    0.121816                                  \n    14     0.099454   0.119647                                  \n    15     0.100425   0.120914                                  \n    16     0.097226   0.119724                                  \n    17     0.094666   0.118746                                  \n    18     0.094137   0.118744                                  \n    19     0.090076   0.117908**[0.11790786389489033]*learn.bn_freeze(**True**)learn.fit(lr, 1, cycle_len=20, wds=wd, use_clr=(20,10))*epoch      trn_loss   val_loss                                  \n    0      0.104692   0.125685  \n    1      0.112455   0.129307                                 \n    2      0.110631   0.126568                                 \n    3      0.108629   0.127338                                 \n    4      0.110791   0.125033                                 \n    5      0.108859   0.125186                                 \n    6      0.106582   0.123875                                 \n    7      0.103227   0.123945                                 \n    8      0.10396    0.12304                                  \n    9      0.105898   0.124894                                 \n    10     0.10498    0.122582                                 \n    11     0.104983   0.122906                                 \n    12     0.102317   0.121171                                  \n    13     0.10017    0.121816                                  \n    14     0.099454   0.119647                                  \n    15     0.100425   0.120914                                  \n    16     0.097226   0.119724                                  \n    17     0.094666   0.118746                                  \n    18     0.094137   0.118744                                  \n    19     0.090076   0.117908**[0.11790786389489033]*lrs = np.array([lr/1000,lr/100,lr])learn.precompute=**False**\nlearn.freeze_to(1)learn.save('pre0')learn.load('pre0')\n```", "```py\nsyns, wvs = list(zip(*syn_wv_1k))\nwvs = np.array(wvs)%time pred_wv = learn.predict()*CPU times: user 18.4 s, sys: 7.91 s, total: 26.3 s\nWall time: 7.17 s*start=300denorm = md.val_ds.denorm**def** show_img(im, figsize=**None**, ax=**None**):\n    **if** **not** ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.axis('off')\n    **return** ax**def** show_imgs(ims, cols, figsize=**None**):\n    fig,axes = plt.subplots(len(ims)//cols, cols, figsize=figsize)\n    **for** i,ax **in** enumerate(axes.flat): show_img(ims[i], ax=ax)\n    plt.tight_layout()\n```", "```py\nshow_imgs(denorm(md.val_ds[start:start+25][0]), 5, (10,10))\n```", "```py\n**import** **nmslib****def** create_index(a):\n    index = nmslib.init(space='angulardist')\n    index.addDataPointBatch(a)\n    index.createIndex()\n    **return** index**def** get_knns(index, vecs):\n     **return** zip(*index.knnQueryBatch(vecs, k=10, num_threads=4))**def** get_knn(index, vec): **return** index.knnQuery(vec, k=10)nn_wvs = create_index(wvs)\n```", "```py\nidxs,dists = get_knns(nn_wvs, pred_wv)\n```", "```py\n[[classids[syns[id]] **for** id **in** ids[:3]] \n                         **for** ids **in** idxs[start:start+10]]*[['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['spoonbill', 'bustard', 'oystercatcher'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill']]*\n```", "```py\nall_syns, all_wvs = list(zip(*syn2wv.items()))\nall_wvs = np.array(all_wvs)nn_allwvs = create_index(all_wvs)idxs,dists = get_knns(nn_allwvs, pred_wv)[[classids[all_syns[id]] **for** id **in** ids[:3]] \n                             **for** ids **in** idxs[start:start+10]]*[['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['spoonbill', 'bustard', 'oystercatcher'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill'],\n ['limpkin', 'oystercatcher', 'spoonbill']]*\n```", "```py\nnn_predwv = create_index(pred_wv)\nen_vecd = pickle.load(open(TRANS_PATH/'wiki.en.pkl','rb'))\nvec = en_vecd['boat']idxs,dists = get_knn(nn_predwv, vec)\nshow_imgs([open_image(PATH/md.val_ds.fnames[i]) **for** i **in** idxs[:3]],\n                      3, figsize=(9,3));\n```", "```py\nvec = (en_vecd['engine'] + en_vecd['boat'])/2 idxs,dists = get_knn(nn_predwv, vec)\nshow_imgs([open_image(PATH/md.val_ds.fnames[i]) **for** i **in** idxs[:3]],\n                      3, figsize=(9,3));\n```", "```py\nvec = (en_vecd['sail'] + en_vecd['boat'])/2idxs,dists = get_knn(nn_predwv, vec)\nshow_imgs([open_image(PATH/md.val_ds.fnames[i]) **for** i **in** idxs[:3]],\n                      3, figsize=(9,3));\n```", "```py\nfname = 'valid/n01440764/ILSVRC2012_val_00007197.JPEG'\nimg = open_image(PATH/fname)\nshow_img(img);\n```", "```py\nt_img = md.val_ds.transform(img)\npred = learn.predict_array(t_img[**None**])idxs,dists = get_knn(nn_predwv, pred)\nshow_imgs([open_image(PATH/md.val_ds.fnames[i]) **for** i **in** idxs[1:4]],\n                      3, figsize=(9,3));\n```"]