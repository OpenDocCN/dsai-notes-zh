- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 20:05:25'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:05:25'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1908.03610] Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1908.03610] 使用暗能量巡天成像优化自动形态分类银河的机器学习和深度学习'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1908.03610](https://ar5iv.labs.arxiv.org/html/1908.03610)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1908.03610](https://ar5iv.labs.arxiv.org/html/1908.03610)
- en: Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 使用暗能量巡天成像优化自动形态分类银河的机器学习和深度学习
- en: Ting-Yun Cheng,¹ Christopher J. Conselice,¹ Alfonso Aragón-Salamanca,¹ Nan Li,¹
    Asa F. L. Bluck,² Will G. Hartley,^(3,4) James Annis,⁵ David Brooks,³ Peter Doel,³
    Juan García-Bellido,⁶ David J. James,⁷ Kyler Kuehn,⁸ Nikolay Kuropatkin,⁵ Mathew
    Smith,⁹ Flavia Sobreira,^(10,11) and Gregory Tarle^(12)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Ting-Yun Cheng,¹ Christopher J. Conselice,¹ Alfonso Aragón-Salamanca,¹ Nan Li,¹
    Asa F. L. Bluck,² Will G. Hartley,^(3,4) James Annis,⁵ David Brooks,³ Peter Doel,³
    Juan García-Bellido,⁶ David J. James,⁷ Kyler Kuehn,⁸ Nikolay Kuropatkin,⁵ Mathew
    Smith,⁹ Flavia Sobreira,^(10,11) 和 Gregory Tarle^(12)
- en: ¹School of Physics and Astronomy, The University of Nottingham, University Park,
    Nottingham, NG7 2RD, UK
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹诺丁汉大学物理与天文学系，大学公园，诺丁汉，NG7 2RD，英国
- en: ²Kavli Institute for Cosmology, The University of Cambridge, Madingley Road,
    Cambridge, CB3 0HA, UK
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ²卡夫利宇宙学研究所，剑桥大学，Madingley Road，剑桥，CB3 0HA，英国
- en: ³Department of Physics & Astronomy, University College London, Gower Street,
    London, WC1E 6BT, UK
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³伦敦大学学院物理与天文学系，戈尔街，伦敦，WC1E 6BT，英国
- en: ⁴Department of Physics, ETH Zurich, Wolfgang-Pauli-Strasse 16, CH-8093 Zurich,
    Switzerland
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴物理系，苏黎世联邦理工大学，Wolfgang-Pauli-Strasse 16，CH-8093 苏黎世，瑞士
- en: ⁵Fermi National Accelerator Laboratory, P. O. Box 500, Batavia, IL 60510, USA
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: ⁵费米国家加速器实验室，P. O. Box 500，伊利诺伊州巴塔维亚60510，美国
- en: ⁶Instituto de Fisica Teorica UAM/CSIC, Universidad Autonoma de Madrid, 28049
    Madrid, Spain
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: ⁶西班牙马德里自治大学/CSIC理论物理研究所，28049 马德里，西班牙
- en: ⁷Harvard-Smithsonian Center for Astrophysics, Cambridge, MA 02138, USA
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: ⁷哈佛-史密森天体物理中心，美国马萨诸塞州剑桥市02138
- en: ⁸Australian Astronomical Optics, Macquarie University, North Ryde, NSW 2113,
    Australia
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: ⁸澳大利亚天文学光学，麦考瑞大学，北赖德，NSW 2113，澳大利亚
- en: ⁹School of Physics and Astronomy, University of Southampton, Southampton, SO17
    1BJ, UK
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: ⁹南安普顿大学物理与天文学系，南安普顿，SO17 1BJ，英国
- en: ^(10)Instituto de Física Gleb Wataghin, Universidade Estadual de Campinas, 13083-859,
    Campinas, SP, Brazil
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: ^(10)格列布·瓦塔金物理研究所，坎皮纳斯州立大学，13083-859，巴西坎皮纳斯
- en: ^(11)Laboratório Interinstitucional de e-Astronomia - LIneA, Rua Gal. José Cristino
    77, Rio de Janeiro, RJ - 20921-400, Brazil
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: ^(11)跨机构电子天文学实验室 - LIneA，Rua Gal. José Cristino 77，里约热内卢，RJ - 20921-400，巴西
- en: '^(12)Department of Physics, University of Michigan, Ann Arbor, MI 48109, USA
    E-mail: ting-yun.cheng@nottingham.ac.uk(Accepted 2020 February 13\. Received 2020
    January 15; in original form 2019 March 02)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '^(12)物理系，密歇根大学，安娜堡，MI 48109，美国 电子邮件: ting-yun.cheng@nottingham.ac.uk（接受日期：2020年2月13日。收到日期：2020年1月15日；原稿日期：2019年3月2日）'
- en: Abstract
  id: totrans-20
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: There are several supervised machine learning methods used for the application
    of automated morphological classification of galaxies; however, there has not
    yet been a clear comparison of these different methods using imaging data, or
    a investigation for maximising their effectiveness. We carry out a comparison
    between several common machine learning methods for galaxy classification (Convolutional
    Neural Network (CNN), K-nearest neighbour, Logistic Regression, Support Vector
    Machine, Random Forest, and Neural Networks) by using Dark Energy Survey (DES)
    data combined with visual classifications from the Galaxy Zoo 1 project (GZ1).
    Our goal is to determine the optimal machine learning methods when using imaging
    data for galaxy classification. We show that CNN is the most successful method
    of these ten methods in our study. Using a sample of $\sim$2,800 galaxies with
    visual classification from GZ1, we reach an accuracy of $\sim$0.99 for the morphological
    classification of Ellipticals and Spirals. The further investigation of the galaxies
    that have a different ML and visual classification but with high predicted probabilities
    in our CNN usually reveals an the incorrect classification provided by GZ1\. We
    further find the galaxies having a low probability of being either spirals or
    ellipticals are visually Lenticulars (S0), demonstrating that supervised learning
    is able to rediscover that this class of galaxy is distinct from both Es and Spirals.
    We confirm that $\sim$2.5% galaxies are misclassified by GZ1 in our study. After
    correcting these galaxies’ labels, we improve our CNN performance to an average
    accuracy of over 0.99 (accuracy of 0.994 is our best result).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 有几种监督学习方法用于自动化银河形态分类的应用；然而，尚未对这些不同方法使用成像数据进行明确比较，或对其有效性进行深入研究。我们对多种常见的银河分类机器学习方法（卷积神经网络（CNN）、K-最近邻、逻辑回归、支持向量机、随机森林和神经网络）进行比较，使用暗能量巡天（DES）数据结合银河动物园
    1 项目（GZ1）的视觉分类。我们的目标是确定使用成像数据进行银河分类的最佳机器学习方法。我们显示 CNN 是我们研究中的十种方法中最成功的一种。使用来自
    GZ1 的$\sim$2,800个银河的视觉分类样本，我们达到了$\sim$0.99的椭圆星系和螺旋星系形态分类准确率。进一步调查那些在我们的 CNN 中具有高预测概率但
    ML 和视觉分类不同的银河通常会揭示 GZ1 提供的不正确分类。我们进一步发现，具有低概率为螺旋星系或椭圆星系的银河在视觉上是透镜状星系（S0），这表明监督学习能够重新发现这一类银河与椭圆星系和螺旋星系不同。我们确认在我们的研究中$\sim$2.5%
    的银河被 GZ1 误分类。纠正这些银河的标签后，我们将 CNN 的性能提高到超过 0.99 的平均准确率（准确率为 0.994 是我们的最佳结果）。
- en: 'keywords:'
  id: totrans-22
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: 'galaxies: structure – methods: data analysis – methods: statistical^†^†pubyear:
    2020^†^†pagerange: Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging–[A](#A1
    "Appendix A Support Vector Machine ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 银河：结构 – 方法：数据分析 – 方法：统计^†^†出版年份：2020^†^†页码范围：使用暗能量巡天成像的机器学习和深度学习优化自动形态分类银河 –
    [A](#A1 "附录 A 支持向量机 ‣ 使用暗能量巡天成像的机器学习和深度学习优化自动形态分类银河")
- en: 1 Introduction
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'The morphological classification of galaxies is a very important tool for understanding
    the history of galaxy assembly. It not only tells us about the evolution of galaxies,
    but it can also reveal the stellar properties of galaxies, and thus their histories.
    Since the pioneering work by Hubble ([1926](#bib.bib35)), nearby galaxies can
    be easily and clearly classified into two main types: early-type galaxies (ETGs),
    which include elliptical galaxies and lenticular galaxies, which are mostly massive,
    with older stellar populations, and no spiral structure; and late-type galaxies,
    which include spiral galaxies and irregular galaxies, often with spiral arms,
    and which consist of a younger population. These two types are the basic classifications
    of galaxies in local universe and have remained so for nearly a century.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 银河的形态分类是理解银河形成历史的重要工具。它不仅告诉我们银河的演化，还能揭示银河的恒星性质，从而了解它们的历史。自哈勃（[1926](#bib.bib35)）开创性工作以来，邻近银河可以轻松而清楚地分为两种主要类型：早期型银河（ETGs），包括椭圆星系和透镜状星系，这些星系大多是大型的，具有较老的恒星群体，没有螺旋结构；以及晚期型银河，包括螺旋星系和不规则星系，通常具有螺旋臂，包含较年轻的群体。这两种类型是局部宇宙中银河的基本分类，几乎一个世纪以来一直如此。
- en: Along with the data explosion by more and more survey projects in astronomy,
    e.g. The Sloan Digital Sky Survey (SDSS)¹¹1https://www.sdss.org, the Large Synoptic
    Survey Telescope (LSST)²²2https://www.lsst.org, the Dark Energy Survey (DES)³³3https://www.darkenergysurvey.org/
    (Abbott et al., [2018](#bib.bib1)), etc, which will image more than hundreds of
    millions of galaxies, the traditional manual classification analysis by experts
    is obviously impossible to deal with this enormous amount of data.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 随着天文学中越来越多调查项目的数据爆炸，例如 Sloan Digital Sky Survey (SDSS)¹¹1https://www.sdss.org、Large
    Synoptic Survey Telescope (LSST)²²2https://www.lsst.org、Dark Energy Survey (DES)³³3https://www.darkenergysurvey.org/（Abbott
    等，[2018](#bib.bib1)）等，这些项目将成像数亿个星系，传统的专家手动分类分析显然无法处理如此巨大的数据量。
- en: The series of the Galaxy Zoo projects (Lintott et al., [2008](#bib.bib47), [2011](#bib.bib48);
    Willett et al., [2013](#bib.bib72)) are one of the most successful tool to solve
    the problem of large scale morphological analysis. It allows amateurs to do the
    classification by answering a series of questions based on galaxy images. However,
    classification analysis is complex and difficult such that background knowledge
    and experience are essential when doing it. In addition, while visual morphological
    classification with Galaxy Zoo is faster than for single individuals, it is also
    time-consuming. For example, the Galaxy Zoo Project spent around 3 years on obtaining
    the classifications of $\sim$300,000 galaxies, due to the need for so many individual
    classifications per object. DES and LSST, for instance, would take on the order
    of $>100$ years to classify with the Galaxy Zoo project. Therefore, an efficient
    automated classification method by computational science is essential for the
    future of this field. The way forward is clearly through machine learning, although
    we are still learning the best ways to apply this to galaxy morphology and other
    areas of astronomy, e.g. star-galaxy separation (Odewahn et al., [1992](#bib.bib53);
    Weir et al., [1995](#bib.bib70); Ball et al., [2006](#bib.bib5), etc), the Galaxy
    Zoo challenge (Chou, [2014](#bib.bib13)), the Strong Gravitational Lens Finding
    Challenge (Metcalf et al., [2019](#bib.bib51)), etc.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 银河动物园项目系列（Lintott 等，[2008](#bib.bib47)，[2011](#bib.bib48)；Willett 等，[2013](#bib.bib72)）是解决大规模形态学分析问题最成功的工具之一。它允许业余爱好者通过回答基于银河图像的一系列问题来进行分类。然而，分类分析复杂且困难，因此在进行分类时背景知识和经验至关重要。此外，虽然使用银河动物园进行的视觉形态分类比单个个体更快，但它仍然非常耗时。例如，银河动物园项目花费了大约
    3 年的时间来获得 $\sim$300,000 个星系的分类，因为每个对象需要如此多的单独分类。例如，DES 和 LSST 等项目如果使用银河动物园项目进行分类，则需要超过
    $>100$ 年的时间。因此，未来这一领域的研究中，计算科学的高效自动分类方法至关重要。前进的方向显然是通过机器学习，尽管我们仍在学习如何将其最佳应用于银河形态学和天文学的其他领域，例如星系-恒星分离（Odewahn
    等，[1992](#bib.bib53)；Weir 等，[1995](#bib.bib70)；Ball 等，[2006](#bib.bib5) 等）、银河动物园挑战（Chou，[2014](#bib.bib13)）、强引力透镜发现挑战（Metcalf
    等，[2019](#bib.bib51)）等。
- en: The concept and application of machine learning in computational science have
    been around for some time (Fukushima, [1980](#bib.bib28)), and the application
    in astronomy started in the 1990s. However, it has not been widely used in astronomy
    until the last few years due to the big improvement of the computation ability
    of computers and the development of this technology. The first application of
    machine learning on morphological classification can be traced to Storrie-Lombardi
    et al. ([1992](#bib.bib67)). They applied a neural network with an input layer
    of 13 parameters, e.g. stellar properties, brightness profile, etc., which gave
    an output of five different types of galaxies. Since then, a slew of studies in
    astronomy have appeared utilising the technology of machine learning (e.g. Huertas-Company
    et al., [2008](#bib.bib36); Huertas-Company et al., [2009](#bib.bib37), [2011](#bib.bib38);
    Shamir, [2009](#bib.bib62); Polsterer et al., [2012](#bib.bib56); Sreejith et al.,
    [2018](#bib.bib66); Hocking et al., [2018](#bib.bib33)), neural networks (e.g.
    Maehoenen & Hakala, [1995](#bib.bib49); Naim et al., [1995](#bib.bib52); Lahav
    et al., [1996](#bib.bib45); Goderya & Lolling, [2002](#bib.bib31); Ball et al.,
    [2004](#bib.bib4); de la Calleja & Fuentes, [2004](#bib.bib75); Banerji et al.,
    [2010](#bib.bib7)), and Convolutional Neural Networks (CNN) (e.g. Dieleman et al.,
    [2015](#bib.bib19); Huertas-Company et al., [2015](#bib.bib39), [2018](#bib.bib40);
    Domínguez Sánchez et al., [2018](#bib.bib20)) for the morphological classification
    of galaxies.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习在计算科学中的概念和应用已经存在一段时间（Fukushima, [1980](#bib.bib28)），而在天文学中的应用始于1990年代。然而，直到最近几年，由于计算机计算能力的显著提升和技术的发展，这项技术在天文学中的应用才逐渐广泛。第一次将机器学习应用于形态分类可以追溯到Storrie-Lombardi等人（[1992](#bib.bib67)）。他们应用了一个具有13个参数的输入层的神经网络，例如星体属性、亮度曲线等，输出五种不同类型的星系。从那时起，大量研究开始利用机器学习技术（例如
    Huertas-Company 等人，[2008](#bib.bib36)；Huertas-Company 等人，[2009](#bib.bib37)、[2011](#bib.bib38)；Shamir，[2009](#bib.bib62)；Polsterer
    等人，[2012](#bib.bib56)；Sreejith 等人，[2018](#bib.bib66)；Hocking 等人，[2018](#bib.bib33)），神经网络（例如
    Maehoenen & Hakala，[1995](#bib.bib49)；Naim 等人，[1995](#bib.bib52)；Lahav 等人，[1996](#bib.bib45)；Goderya
    & Lolling，[2002](#bib.bib31)；Ball 等人，[2004](#bib.bib4)；de la Calleja & Fuentes，[2004](#bib.bib75)；Banerji
    等人，[2010](#bib.bib7)），以及卷积神经网络（CNN）（例如 Dieleman 等人，[2015](#bib.bib19)；Huertas-Company
    等人，[2015](#bib.bib39)、[2018](#bib.bib40)；Domínguez Sánchez 等人，[2018](#bib.bib20)）来进行星系的形态分类。
- en: There are now several different methods in machine learning used to carry out
    morphological classifications. However, although machine learning have been highly
    developed for decades there is not a clear quantitative comparison between these
    different methods yet especially concerning imaging data. In our study, we carry
    out a comparison of the simplest classification – binary morphological classification
    of ‘Ellipticals’ and ‘Spirals’ (follows the classification of the Galaxy Zoo 1
    project) – between several common methods in machine learning (listed in Table [1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"))
    using imaging data.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，在机器学习中有几种不同的方法用于进行形态分类。然而，尽管机器学习在过去几十年中得到了高度发展，但针对这些不同方法的明确定量比较仍然缺乏，特别是在成像数据方面。在我们的研究中，我们对几种常见的机器学习方法（见表 [1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")）进行了比较，这些方法用于对‘椭圆星系’和‘螺旋星系’（遵循银河动物园
    1 项目的分类）进行最简单的分类——二分类形态分类——使用成像数据。
- en: In previous studies, except for the application of CNN, there were very few
    studies which directly exploited imaging data when using other machine learning
    algorithms, such as neural networks or support vector machine. Therefore, we imitate
    the application of face and hand-writing recognition in computational science
    (Bishop, [2006](#bib.bib9)) that directly input image pixels as features to all
    the methods we compared for a fair comparison of different methods.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 在以往的研究中，除了CNN的应用外，很少有研究直接利用成像数据来使用其他机器学习算法，如神经网络或支持向量机。因此，我们模仿计算科学中人脸和手写识别的应用（Bishop,
    [2006](#bib.bib9)），将图像像素直接作为特征输入到我们比较的所有方法中，以公平比较不同的方法。
- en: In this study we use DES imaging data which has better resolution and deeper
    depth than SDSS images (see Section [2](#S2 "2 Data Sets ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")). With our machine learning algorithm, these
    properties of DES data help us to build a larger, deeper, and better catalogue
    of galaxy morphology containing the largest sample to date. We therefore also
    discuss galaxies which ’fail’ in our training algorithms, and discuss how these
    systems are often misclassified in Galaxy Zoo. We also discuss systems that have
    a low probability of being either an elliptical or a spiral and how these systems
    are visually classifiable on the DES imaging as lenticulars.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们使用DES成像数据，其分辨率更高，深度更大，优于SDSS图像（见第[2节](#S2 "2 数据集 ‣ 使用暗能量 survey 成像优化自动形态分类的银河系")）。通过我们的机器学习算法，这些DES数据的特性帮助我们构建了一个更大、更深、质量更高的银河系形态目录，包含迄今为止最大的样本。因此，我们还讨论了在训练算法中“失败”的银河系，并讨论这些系统在Galaxy
    Zoo中常被错误分类的原因。我们还讨论了那些被认为是椭圆或螺旋星系概率较低的系统，并探讨了这些系统在DES成像中如何被视觉上分类为透镜状星系。
- en: The arrangement for this paper is as follows. Section [2](#S2 "2 Data Sets ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging") describes the data resources,
    the procedure of pre-processing, and the datasets we use in this paper. The descriptions
    of each method are discussed in Section [3](#S3 "3 Models of Machine Learning
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging"). We present the main results
    in Section [4](#S4 "4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    and include a further discussion in Section [5](#S5 "5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging"). The conclusion is shown in Section [6](#S6
    "6 Conclusions ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging").
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的安排如下。第[2节](#S2 "2 数据集 ‣ 使用暗能量 survey 成像优化自动形态分类的银河系")描述了数据资源、预处理过程以及我们在本文中使用的数据集。每种方法的描述在第[3节](#S3
    "3 机器学习模型 ‣ 使用暗能量 survey 成像优化自动形态分类的银河系")中讨论。我们在第[4节](#S4 "4 结果 ‣ 使用暗能量 survey
    成像优化自动形态分类的银河系")中展示了主要结果，并在第[5节](#S5 "5 进一步讨论 ‣ 使用暗能量 survey 成像优化自动形态分类的银河系")中进行了进一步讨论。结论在第[6节](#S6
    "6 结论 ‣ 使用暗能量 survey 成像优化自动形态分类的银河系")中展示。
- en: '| Labels | Machine Learning Algorithms |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 机器学习算法 |'
- en: '| --- | --- |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| 1 | K-Nearest Neighbour (KNN) |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 1 | K-近邻 (KNN) |'
- en: '| 2 | KNN + Restricted Boltzmann Machine |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 2 | KNN + 受限玻尔兹曼机 |'
- en: '|  | (KNN+RBM) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | (KNN+RBM) |'
- en: '| 3 | Support Vector Machine (SVM) |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 支持向量机 (SVM) |'
- en: '| 4 | SVM + Restricted Boltzmann Machine |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 4 | SVM + 受限玻尔兹曼机 |'
- en: '|  | (SVM+RBM) |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|  | (SVM+RBM) |'
- en: '| 5 | Logistic Regression (LR) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 逻辑回归 (LR) |'
- en: '| 6 | LR + Restricted Boltzmann Machine |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '| 6 | LR + 受限玻尔兹曼机 |'
- en: '|  | (LR+RBM) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | (LR+RBM) |'
- en: '| 7 | Random Forest (RF) |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 随机森林 (RF) |'
- en: '| 8 | RF + Restricted Boltzmann Machine |'
  id: totrans-45
  prefs: []
  type: TYPE_TB
  zh: '| 8 | RF + 受限玻尔兹曼机 |'
- en: '|  | (RF+RBM) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | (RF+RBM) |'
- en: '| 9 | Multi-Layer Perceptron Classifier |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| 9 | 多层感知机分类器 |'
- en: '|  | (MLPC) |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '|  | (MLPC) |'
- en: '| 10 | Convolutional Neural Network (CNN) |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 10 | 卷积神经网络 (CNN) |'
- en: 'Table 1: The list of machine learning methods tested in this study.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：本研究中测试的机器学习方法列表。
- en: 2 Data Sets
  id: totrans-51
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 数据集
- en: For the images in this analysis we use the subset of Dark Energy Survey (DES)
    Year 1 (Y1) GOLD data - DES observation of SDSS stripe 82, selected at magnitude
    i $<$22.5 and redshift z $<$0.7 (Drlica-Wagner et al., [2018](#bib.bib21)). DES
    data covers 5000 square degrees ($\sim 1/8$ sky) and partially overlaps with the
    survey area of the Sloan Digital Sky Surveys (SDSS), but has a better seeing than
    the SDSS images from Galaxy Zoo. Dark Energy Camera (DECam) (Flaugher et al.,
    [2015](#bib.bib26)), the new installed camera used in DES, which is mounted on
    the Victor M. Blanco 4-meter Telescope at the Cerro Tololo Inter-American Observatory
    (CTIO) in the Chilean Andes, improved the quantum efficiency in the infrared wavebands
    ($>$90% from $\sim$650 nm to $\sim$900 nm), and gives a better quality images
    for the observation of very distant objects than previous surveys with the spatial
    resolution of ${0.}^{\prime\prime}263$ per pixel and the depth of $i=22.51$ (Abbott
    et al., [2018](#bib.bib1)).
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 在本分析中，我们使用了暗能量survey（DES）第一年（Y1）黄金数据子集——DES对SDSS条纹82的观测，选择了亮度i $<$22.5和红移z $<$0.7（Drlica-Wagner等，[2018](#bib.bib21)）。DES数据覆盖了5000平方度（$\sim
    1/8$天空），与斯隆数字天空调查（SDSS）的调查区域部分重叠，但比Galaxy Zoo的SDSS图像具有更好的视场。暗能量相机（DECam）（Flaugher等，[2015](#bib.bib26)），这是在DES中使用的新安装相机，安装在智利安第斯山脉的塞罗·托洛洛洲际天文台（CTIO）的Victor
    M. Blanco 4米望远镜上，改进了红外波段的量子效率（$\sim$650 nm到$\sim$900 nm的效率>$90%），并且提供了比之前的调查更高质量的图像，用于观测非常遥远的天体，具有每像素${0.}^{\prime\prime}263$的空间分辨率和深度为$i=22.51$（Abbott等，[2018](#bib.bib1)）。
- en: A DES survey image has more than 500M pixels. Each tile is 1/2 sq.-deg. The
    coadd (tile) images are 10000 by 10000 pixels in size with a pixel scale ${0.}^{\prime\prime}263$.
    The total number of the data in this subset is around 1.87 million galaxy stamps
    with photometric redshift, and photometry information in 308 i-band coadd images.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一个DES调查图像拥有超过5亿像素。每个图块为1/2平方度。合成（图块）图像的大小为10000乘10000像素，像素尺度为${0.}^{\prime\prime}263$。这个子集中的数据总数约为187万个具有光度红移的星系印记，以及308个i带合成图像中的光度信息。
- en: In order to train our machine learning algorithm, we match the DES data with
    the visual morphological classifications from the Galaxy Zoo 1 project (GZ1, hereafter)⁴⁴4https://data.galaxyzoo.org/
    (Lintott et al., [2008](#bib.bib47), [2011](#bib.bib48)). we only exploit the
    visual classifications which have agreements (votes rates) over 80 percent and
    have been bias corrected by Bamford et al. ([2009](#bib.bib6)) for both Ellipticals
    and Spirals in GZ1\. However, the matching of DES data with visual classifications
    from GZ1 only gives 2,862 objects in total, with the number ratio between Ellipticals
    and Spirals being 1 to 3\. Their magnitude ranges from $\sim$12.5 to 18 in $i$-band,
    and the redshift z$\leq$0.25 (peak at z$\sim$0.1). To avoid overfitting while
    carrying out the ML training, we apply data augmentation in the pre-processing
    procedure in our study (Section [2.1.1](#S2.SS1.SSS1 "2.1.1 Data augmentation
    ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    To improve the performance of our machine learning methods, we apply other techniques
    including feature extraction, i.e. Histogram of Oriented Gradient (HOG) (Dalal
    & Triggs, [2005](#bib.bib18)) to extract other informative features from galaxy
    stamps (Section [2.1.3](#S2.SS1.SSS3 "2.1.3 Feature Extraction ‣ 2.1 Pre-Processing
    ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 为了训练我们的机器学习算法，我们将DES数据与Galaxy Zoo 1项目（GZ1，以下简称）⁴⁴4https://data.galaxyzoo.org/（Lintott等，[2008](#bib.bib47)，[2011](#bib.bib48)）中的视觉形态分类进行匹配。我们仅利用那些在视觉分类中具有超过80%一致性（投票率）的数据，这些数据经过Bamford等人（[2009](#bib.bib6)）的偏差校正，涵盖GZ1中的椭圆星系和螺旋星系。然而，与GZ1中的视觉分类匹配的DES数据仅提供了2862个对象，其中椭圆星系与螺旋星系的比例为1比3。它们的亮度范围从$i$-带的$\sim$12.5到18，红移z$\leq$0.25（峰值在z$\sim$0.1）。为了避免在进行机器学习训练时过拟合，我们在研究的预处理过程中应用了数据增强（第[2.1.1](#S2.SS1.SSS1
    "2.1.1 Data augmentation ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")节）。为了提高我们的机器学习方法的性能，我们还应用了其他技术，包括特征提取，即方向梯度直方图（HOG）（Dalal
    & Triggs，[2005](#bib.bib18)），以从星系印记中提取其他有用的特征（第[2.1.3](#S2.SS1.SSS3 "2.1.3 Feature
    Extraction ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")节）。
- en: 2.1 Pre-Processing
  id: totrans-55
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 预处理
- en: 'Before data pre-processing, we separate our 2,862 galaxies with DES data and
    the GZ1 classification randomly into training sets, and testing set, to prevent
    repeated galaxies in both sets. Our data pre-processing has four main steps: (1)
    Data Augmentation; (2) Stamps creation; (3) Feature Extraction; (4) Rescaling.
    The details are shown below.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在数据预处理之前，我们将 2,862 个带有 DES 数据和 GZ1 分类的星系随机分为训练集和测试集，以防止两个数据集中重复的星系。我们的数据预处理包括四个主要步骤：（1）数据增强；（2）印章创建；（3）特征提取；（4）重新缩放。详细信息如下所示。
- en: '![Refer to caption](img/fb93d30ec181e3fe8d0b07ca63cbc5d7.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fb93d30ec181e3fe8d0b07ca63cbc5d7.png)'
- en: 'Figure 1: Pre-processing procedure pipeline. The pipeline starts from the initial
    coadd images, then we chop the coadd images into different sizes according to
    the size of galaxies. After rotation, we chop and downsize the images to the required
    sizes: 50 by 50 pixels. The details of the procedure is in Section [2.1](#S2.SS1
    "2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：预处理过程流程图。流程图从初始的叠加图像开始，然后根据星系的大小将叠加图像切割成不同的尺寸。经过旋转后，我们将图像切割并缩小到所需的尺寸：50
    x 50 像素。该过程的详细信息见第[2.1节](#S2.SS1 "2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")。
- en: 2.1.1 Data augmentation
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 数据增强
- en: Data augmentation is of great importance while using pixel inputs in machine
    learning. Since Dieleman et al. ([2015](#bib.bib19)), data augmentation by rotating
    images has been widely used within CNN for the morphological classification of
    galaxies. In this paper, we have 2,862 galaxies with visual classifications from
    GZ1, 759 Ellipticals and 2,103 Spirals, respectively, to train and test our methods.
    In order to prevent over-fitting during training, we rotate each galaxy image
    by 10 degrees differences from 0 to 350 degrees to increase the number of training
    samples. Hence, the available number of training samples increase to $\sim$100,000\.
    After rotation, we add Gaussian noise to the rotated images (Huertas-Company et al.,
    [2015](#bib.bib39)). This noise is small enough to not to influence the visual
    appearance and structures of the galaxies (namely, remain the same visual classification),
    but it is big enough to make a detectable but change of pixel values.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强在使用像素输入的机器学习中非常重要。自 Dieleman 等人（[2015](#bib.bib19)）以来，通过旋转图像进行的数据增强已在 CNN
    中广泛应用于星系的形态分类。在本文中，我们有 2,862 个具有 GZ1 视觉分类的星系，其中 759 个为椭圆星系，2,103 个为螺旋星系，用于训练和测试我们的方法。为了防止训练中的过拟合，我们将每个星系图像旋转
    10 度，范围从 0 到 350 度，以增加训练样本的数量。因此，可用的训练样本数量增加到约 100,000。旋转后，我们向旋转图像中添加高斯噪声（Huertas-Company
    等，[2015](#bib.bib39)）。这种噪声足够小，不会影响星系的视觉外观和结构（即保持相同的视觉分类），但足够大以使像素值发生可检测的变化。
- en: Although data augmentation through rotating images is a well known method used
    in machine learning application (e.g. Dieleman et al., [2015](#bib.bib19); Huertas-Company
    et al., [2015](#bib.bib39)), the effect of these rotated images is unexplored.
    Therefore, we investigate the difference of performance between partially and
    fully using rotated images in the datasets in Section [4.2](#S4.SS2 "4.2 The impact
    of rotated images ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging").
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管通过旋转图像进行数据增强是一种在机器学习应用中广泛使用的方法（例如 Dieleman 等，[2015](#bib.bib19)；Huertas-Company
    等，[2015](#bib.bib39)），但这些旋转图像的效果尚未被探索。因此，我们在第[4.2节](#S4.SS2 "4.2 The impact of
    rotated images ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中研究了部分使用和完全使用旋转图像在数据集中的性能差异。
- en: 2.1.2 Creation of the galaxy stamps
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 星系印章的创建
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") shows the pre-processing procedure used in
    our study. Using the galaxy catalogue from DES, we cut the coadd images with units
    of size 10000 by 10000 pixels into millions of galaxy stamps with sizes of 50
    by 50 pixels. The size of galaxy stamp is based on the size distribution of galaxies
    in the DES Y1 GOLD data (stripe 82), where over 99% of galaxies are smaller than
    a threshold of 25 by 25 pixels. Therefore, the size of our stamp is 50 by 50 pixels,
    which is twice as large as the threshold in the size distribution of galaxies.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S2.F1 "图 1 ‣ 2.1 预处理 ‣ 2 数据集 ‣ 使用暗能量探测器成像优化自动形态分类") 显示了我们研究中使用的预处理过程。利用
    DES 的星系目录，我们将大小为 10000 像素乘 10000 像素的合成图像裁剪成数百万个大小为 50 像素乘 50 像素的星系图章。星系图章的大小基于
    DES Y1 GOLD 数据（条纹 82）中星系的大小分布，其中超过 99% 的星系小于 25 像素乘 25 像素的阈值。因此，我们的图章大小为 50 像素乘
    50 像素，比星系大小分布中的阈值大两倍。
- en: Fig. [1](#S2.F1 "Figure 1 ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") shows that before chopping the stamp to the
    size of 50 by 50 pixels, we create the galaxy stamps with an initial size of 200
    by 200 pixels when the galaxy size is smaller than 30 by 30 pixels, and 400 by
    400 pixels when the galaxy size is larger than 30 by 30 pixels. For smaller galaxies,
    we rotate the 200 by 200 pixels stamps first, then reduce them in size to 50 by
    50 pixels; for larger galaxies, we rotate 400 by 400 pixel stamps, reduce them
    in size to 200 by 200 pixels, then downsize them to 50 by 50 pixels by calculating
    the mean value of pixels in a size of 4 by 4 pixel cell. This procedure is designed
    to prevent empty pixel values showing up at the corner of stamps when we rotate
    images with non-90 degrees rotations.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [1](#S2.F1 "图 1 ‣ 2.1 预处理 ‣ 2 数据集 ‣ 使用暗能量探测器成像优化自动形态分类") 显示，在将图章裁剪到 50 像素乘
    50 像素的大小之前，我们创建了初始大小为 200 像素乘 200 像素的星系图章，当星系大小小于 30 像素乘 30 像素时，使用 400 像素乘 400
    像素的图章，当星系大小大于 30 像素乘 30 像素时。对于较小的星系，我们首先旋转 200 像素乘 200 像素的图章，然后将其大小缩小到 50 像素乘
    50 像素；对于较大的星系，我们旋转 400 像素乘 400 像素的图章，将其缩小到 200 像素乘 200 像素，然后通过计算 4 像素乘 4 像素单元格中的像素均值将其缩小到
    50 像素乘 50 像素。此过程旨在防止在我们旋转图像时角落出现空白像素值，特别是当旋转角度不是 90 度时。
- en: 2.1.3 Feature Extraction
  id: totrans-65
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.3 特征提取
- en: In our study, we apply the Histogram of Oriented Gradients (HOG) on both our
    original and rotated stamps to investigate the impact of this feature extractor
    on supervised machine learning. HOG is a feature extractor which is able to extract
    the distribution of gradients with their direction from each pixel value. It is
    useful for characterising the appearance and the shape of objects (Dalal & Triggs,
    [2005](#bib.bib18)). It calculates the gradients of the horizontal (x) and vertical
    (y) direction of stamps. The magnitude and orientation of the gradient are calculated
    as below,
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的研究中，我们对原始和旋转的图章应用了方向梯度直方图（HOG），以调查该特征提取器对监督机器学习的影响。HOG 是一种特征提取器，能够从每个像素值中提取梯度及其方向的分布。它对于表征物体的外观和形状非常有用（Dalal
    & Triggs，[2005](#bib.bib18)）。它计算图章中水平（x）和垂直（y）方向的梯度。梯度的幅度和方向计算如下：
- en: '|  | $\left&#124;G\right&#124;=\sqrt{{G}_{x}^{2}+{G}_{y}^{2}},\\ \theta=\arctan{\left(\frac{{G}_{y}}{{G}_{x}}\right)}$
    |  | (1) |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '|  | $\left\|G\right\|=\sqrt{{G}_{x}^{2}+{G}_{y}^{2}},\\ \theta=\arctan{\left(\frac{{G}_{y}}{{G}_{x}}\right)}$
    |  | (1) |'
- en: where $\left|G\right|$ is the gradient magnitude of each pixel, ${G}_{x}$ is
    the gradient magnitude measured in x-direction, ${G}_{y}$ is the gradient magnitude
    measured in y-direction, and $\theta$ is the orientation of the gradient for each
    pixel in the images. It then measures the contribution of gradients from each
    pixel in the cell with the size of 2 by 2 pixels, and uses a histogram to describe
    the contribution of gradient magnitude to each orientation of gradient. The input
    of HOG image is the direct output of this feature extraction process, and we rescale
    the pixel value to the range between 0 and 1 (Section [2.1.4](#S2.SS1.SSS4 "2.1.4
    Rescaling ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")). Examples of HOG images are shown in Fig. [2](#S2.F2
    "Figure 2 ‣ 2.1.3 Feature Extraction ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging").
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\left|G\right|$ 是每个像素的梯度幅值，${G}_{x}$ 是在 x 方向测量的梯度幅值，${G}_{y}$ 是在 y 方向测量的梯度幅值，$\theta$
    是图像中每个像素的梯度方向。接着，它测量每个 2 x 2 像素单元格中梯度的贡献，并使用直方图描述梯度幅值对每个梯度方向的贡献。HOG 图像的输入是此特征提取过程的直接输出，我们将像素值重新缩放到
    0 和 1 之间（第 [2.1.4](#S2.SS1.SSS4 "2.1.4 重新缩放 ‣ 2.1 预处理 ‣ 2 数据集 ‣ 使用暗能量探测器成像优化星系的自动形态分类")
    节）。HOG 图像的示例见图 [2](#S2.F2 "图 2 ‣ 2.1.3 特征提取 ‣ 2.1 预处理 ‣ 2 数据集 ‣ 使用暗能量探测器成像优化星系的自动形态分类")。
- en: HOG is very popular within pattern recognition studies, e.g. human detection,
    face recognition, and handwriting recognition (e.g. Dalal & Triggs, [2005](#bib.bib18);
    Shu et al., [2011](#bib.bib64); Kamble & Hegadi, [2015](#bib.bib42), etc); however,
    it is not popular yet in astronomy studies for the usage of machine learning algorithms.
    One of the applications is the detection of gravitational lensing images (Avestruz
    et al., [2019](#bib.bib3)), and a few previous works on the galaxy morphology
    (e.g. The Galaxy Zoo challenge Chou, [2014](#bib.bib13)). However, none of these
    studies have examined the influence of HOG on the performance of machine learning
    algorithms. In this study, we apply HOG on our images to investigate not only
    the effect of it on automated morphological classification of galaxies, but also
    the impact of it on the performance of different machine learning algorithms (Section [4.4](#S4.SS4
    "4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")).
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: HOG 在模式识别研究中非常流行，例如人类检测、面部识别和手写识别（例如 Dalal & Triggs，[2005](#bib.bib18)；Shu 等，[2011](#bib.bib64)；Kamble
    & Hegadi，[2015](#bib.bib42) 等）；然而，它在天文学研究中尚未广泛应用于机器学习算法。一个应用实例是引力透镜图像的检测（Avestruz
    等，[2019](#bib.bib3)），以及一些关于星系形态的前期研究（例如 Galaxy Zoo 挑战 Chou，[2014](#bib.bib13)）。然而，这些研究中没有任何一项探讨
    HOG 对机器学习算法性能的影响。在本研究中，我们应用 HOG 于我们的图像，以探讨其对星系自动形态分类的影响，以及对不同机器学习算法性能的影响（第 [4.4](#S4.SS4
    "4.4 不同类型输入数据的影响 ‣ 4 结果 ‣ 使用暗能量探测器成像优化星系的自动形态分类") 节）。
- en: '![Refer to caption](img/5d18fe738fcb24d223f64f8c8d37f677.png)'
  id: totrans-70
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5d18fe738fcb24d223f64f8c8d37f677.png)'
- en: 'Figure 2: Examples of images from Histogram Oriented Gradient (HOG) with the
    cell size of 2 by 2 pixels. Left: HOG images. Right: original images in linear
    scale. Top: Spirals. Bottom: Ellipticals.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：直方图梯度（HOG）示例图像，单元格大小为 2 x 2 像素。左侧：HOG 图像。右侧：线性尺度的原始图像。顶部：螺旋星系。底部：椭圆星系。
- en: 2.1.4 Rescaling
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.4 重新缩放
- en: Rescaling is a very important process in the application of machine learning.
    Different galaxies have different brightness due to their different properties
    and their distances, so the pixel values of each image have significant variation
    between galaxies. This would cause difficulties for machine learning algorithms
    when defining the boundaries between different classes. Therefore, we rescale
    the pixel values of each image (raw and HOG images) to the range between 0 and
    1 through normalising by the maximum and minimum pixel value of each image. We
    are aware that intrinsic brightness can be a classification criteria, including
    surface brightness. However, in this study we are interested in the structure
    only and not on other properties that might correlate with a class of galaxy such
    as surface brightness.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 重新缩放是机器学习应用中一个非常重要的过程。由于不同星系具有不同的亮度，原因在于它们的性质和距离，因此每张图像的像素值在星系之间有显著的变化。这会导致机器学习算法在定义不同类别之间的边界时出现困难。因此，我们通过对每张图像（原始图像和HOG图像）的像素值进行归一化，将其缩放到0和1之间的范围。我们知道固有亮度可以作为分类标准，包括表面亮度。然而，在这项研究中，我们只关注结构，而不是可能与星系类别相关的其他属性，例如表面亮度。
- en: 2.2 The datasets
  id: totrans-74
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 数据集
- en: In this study, we create 4 different datasets (see Table [2](#S2.T2 "Table 2
    ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    The first two datasets (1 $\&amp;$ 2) contain both the original images and the
    rotated images, and the last two (3 $\&amp;$ 4) contain only the rotated images.
    This setting is used for investigating the influence of rotated images on the
    performance (Section [4.2](#S4.SS2 "4.2 The impact of rotated images ‣ 4 Results
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")).
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们创建了4个不同的数据集（见表[2](#S2.T2 "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")）。前两个数据集（1 $\&$ 2）包含原始图像和旋转图像，而最后两个数据集（3
    $\&$ 4）仅包含旋转图像。这个设置用于研究旋转图像对性能的影响（第[4.2](#S4.SS2 "4.2 The impact of rotated images
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")节）。
- en: On the other hand, the datasets 1 $\&amp;$ 3 are unbalanced which contain more
    spiral galaxies than elliptical galaxies in the datasets while the datasets 2
    $\&amp;$ 4 have an equal number of spiral galaxies and elliptical galaxies in
    each dataset. We balance the number of each type by adding different numbers of
    rotated images to each type. For example, we rotate images of the Ellipticals
    7 times, but only 2 times for the images of Spirals in dataset 2, and 3 times
    for both types in dataset 1\. We use this setting to investigate the effect of
    the balance between the number of each type in training samples (Section [4.3](#S4.SS3
    "4.3 Balance or Unbalance? ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    In addition, we also reduce the differences in the number of total training samples
    between each dataset to reduce the probable bias from this.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，数据集1 $\&$ 3是不平衡的，其中包含的螺旋星系数量多于椭圆星系，而数据集2 $\&$ 4在每个数据集中包含的螺旋星系和椭圆星系数量相等。我们通过向每种类型添加不同数量的旋转图像来平衡每种类型的数量。例如，我们将椭圆星系图像旋转7次，而数据集2中的螺旋星系图像仅旋转2次，数据集1中的两种类型均旋转3次。我们使用这个设置来研究训练样本中每种类型数量平衡的影响（第[4.3](#S4.SS3
    "4.3 Balance or Unbalance? ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")节）。此外，我们还减少了每个数据集中训练样本总数的差异，以减少可能的偏差。
- en: On the other hand, we have 2 (or 3 in CNN) different types of input data (i,
    ii, iii). The first type (i) is the raw image with linear scale, and the second
    type (ii) is the HOG image from feature extraction. The third type, ‘combination
    input (iii)’, is special for CNN due to the characteristic structure of CNN that
    we can combine both the raw images (i) and HOG images (ii) as input without increasing
    the number of features. This is an new way to combine data using CNN whereas people
    used to restore the images with different colours in the third dimension of CNN
    in previous studies. We then also investigate the effect of this combination input
    (iii) and compare it with the other two types (i $\&amp;$ ii) (Section [4.4](#S4.SS4
    "4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")).
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们有2（或CNN中的3）种不同类型的输入数据（i，ii，iii）。第一种类型（i）是线性尺度的原始图像，第二种类型（ii）是从特征提取中获得的HOG图像。第三种类型，“组合输入（iii）”，由于CNN的特殊结构，我们可以将原始图像（i）和HOG图像（ii）作为输入，而无需增加特征的数量。这是一种使用CNN结合数据的新方式，而以前的研究中，人们通常在CNN的第三维中恢复不同颜色的图像。然后我们还研究了这种组合输入（iii）的效果，并将其与其他两种类型（i
    $\&$ ii）进行比较（见[4.4](#S4.SS4 "4.4 不同类型输入数据的效果 ‣ 4 结果 ‣ 使用暗能量调查成像优化自动形态分类的机器学习和深度学习")）。
- en: For the testing set, we randomly pick 500 galaxies from 2,862 galaxies for each
    type (Ellipticals and Spirals). The rest of unselected galaxies are training set.
    Therefore, we have 1,000 galaxies in total for testing and the ratio between Ellipticals
    and Spiral is 1:1.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试集，我们从2,862个星系中随机挑选每种类型（椭圆星系和螺旋星系）各500个。未被选择的星系则作为训练集。因此，我们总共有1,000个星系用于测试，椭圆星系与螺旋星系的比例为1:1。
- en: '| labels | i (raw), | ii (HOG), | iii (combination, for CNN) |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | i（原始）， | ii（HOG）， | iii（组合，用于CNN） |'
- en: '| --- | --- | --- | --- |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 1 | original images+rotated images | E:S$\sim$1:3, Training$=$10,448 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 原始图像+旋转图像 | E:S$\sim$1:3，训练数据$=$10,448 |'
- en: '| 2 | original images+rotated images | E:S$\sim$1:1, Training$=$11,381 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 原始图像+旋转图像 | E:S$\sim$1:1，训练数据$=$11,381 |'
- en: '| 3 | only rotated images | E:S$\sim$1:3, Training$=$11,448 |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 仅旋转图像 | E:S$\sim$1:3，训练数据$=$11,448 |'
- en: '| 4 | only rotated images | E:S$\sim$1:1, Training$=$12,381 |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 仅旋转图像 | E:S$\sim$1:1，训练数据$=$12,381 |'
- en: 'Table 2: The arrangement of training datasets in this paper. The content included
    in the datasets are shown in the second column, and the third column shows that
    the ratio between Ellipticals and Spirals and the total number of training data
    in each dataset.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：本文中训练数据集的排列。数据集中包含的内容显示在第二列，第三列显示了椭圆星系和螺旋星系之间的比例以及每个数据集中的总训练数据量。
- en: 3 Models of Machine Learning
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 机器学习模型
- en: The concept of machine learning can connect with the invention of calculators
    (TURING, [1950](#bib.bib68)) that we program machine to obtain the information
    we want through the input numbers or characters (features). The breakthrough of
    visual pattern recognition in machine learning started from Fukushima ([1980](#bib.bib28))
    which proposed a hierarchical and multilayered neural network - Neocognitron.
    Machine learning stood on the stage of astronomical applications since the 1990s
    (e.g. Odewahn et al., [1992](#bib.bib53); Storrie-Lombardi et al., [1992](#bib.bib67);
    Weir et al., [1995](#bib.bib70), etc).
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习的概念可以与计算器的发明（TURING，[1950](#bib.bib68)）联系起来，我们通过输入数字或字符（特征）来编程机器以获取所需的信息。机器学习中的视觉模式识别突破始于Fukushima（[1980](#bib.bib28)），他提出了一个分层和多层次的神经网络——Neocognitron。自1990年代以来，机器学习站上了天文应用的舞台（例如，Odewahn等，[1992](#bib.bib53)；Storrie-Lombardi等，[1992](#bib.bib67)；Weir等，[1995](#bib.bib70)等）。
- en: There are two main types of features, ‘parameter input’ and ‘pixel input’, that
    can be fed into machine. In the studies of galaxy morphological classification,
    the ‘parameter input’ is where we use parameters, which have clear correlations
    with galaxy types (e.g. Storrie-Lombardi et al., [1992](#bib.bib67); Naim et al.,
    [1995](#bib.bib52); Lahav et al., [1996](#bib.bib45); Ball et al., [2004](#bib.bib4);
    Huertas-Company et al., [2008](#bib.bib36); Huertas-Company et al., [2009](#bib.bib37);
    Banerji et al., [2010](#bib.bib7); Huertas-Company et al., [2011](#bib.bib38);
    Sreejith et al., [2018](#bib.bib66)). For example, the ‘parameter’ input can be
    surface brightness profile, colour, C-A-S system (Conselice, [2003](#bib.bib14)),
    Gini Coefficient (Abraham et al., [2003](#bib.bib2)), etc.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 可以输入机器学习的特征主要有两种类型，‘参数输入’和‘像素输入’。在星系形态分类研究中，‘参数输入’是我们使用与星系类型有明显相关性的参数（例如，Storrie-Lombardi
    et al., [1992](#bib.bib67)；Naim et al., [1995](#bib.bib52)；Lahav et al., [1996](#bib.bib45)；Ball
    et al., [2004](#bib.bib4)；Huertas-Company et al., [2008](#bib.bib36)；Huertas-Company
    et al., [2009](#bib.bib37)；Banerji et al., [2010](#bib.bib7)；Huertas-Company et
    al., [2011](#bib.bib38)；Sreejith et al., [2018](#bib.bib66)）。例如，‘参数’输入可以是表面亮度剖面、颜色、C-A-S系统（Conselice,
    [2003](#bib.bib14)）、Gini系数（Abraham et al., [2003](#bib.bib2)）等。
- en: On the other hand, the ‘pixel input’ means that we treat each pixel of an image
    as a feature to feed machine learning algorithms. The ‘pixel input’ is the most
    straightforward feature used in two for machine to learn although it significantly
    increases the number of features for computation. However, it is uncommon in previous
    studies of automated classification of galaxy morphology to use ‘pixel input’
    (e.g. Maehoenen & Hakala, [1995](#bib.bib49); Goderya & Lolling, [2002](#bib.bib31);
    de la Calleja & Fuentes, [2004](#bib.bib75); Polsterer et al., [2012](#bib.bib56))
    until the application of CNN become popular in recent years (Dieleman et al.,
    [2015](#bib.bib19); Huertas-Company et al., [2015](#bib.bib39); Domínguez Sánchez
    et al., [2018](#bib.bib20)).
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，‘像素输入’意味着我们将图像的每个像素视为一个特征来输入机器学习算法。虽然‘像素输入’显著增加了计算所需的特征数量，但它是机器学习中最直接的特征。然而，在以往的星系形态自动分类研究中，‘像素输入’的使用并不常见（例如，Maehoenen
    & Hakala, [1995](#bib.bib49)；Goderya & Lolling, [2002](#bib.bib31)；de la Calleja
    & Fuentes, [2004](#bib.bib75)；Polsterer et al., [2012](#bib.bib56)），直到近年来CNN应用变得流行（Dieleman
    et al., [2015](#bib.bib19)；Huertas-Company et al., [2015](#bib.bib39)；Domínguez
    Sánchez et al., [2018](#bib.bib20)）。
- en: We use ‘pixel input’ for each method in this study to investigate the effect
    of ‘pixel input’ on different machine learning algorithms (Table [1](#S1.T1 "Table
    1 ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")). Restricted
    Boltzmann Machine (RBM) (Smolensky, [1986](#bib.bib65); Hinton, [2002](#bib.bib32);
    Salakhutdinov et al., [2007](#bib.bib60)), shown in Table [1](#S1.T1 "Table 1
    ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging"), is
    the simplest neural network with one hidden layer, which we treat as a feature
    extractor for in this study (Section [3.1](#S3.SS1 "3.1 Restricted Boltzmann Machine
    (RBM) ‣ 3 Models of Machine Learning ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在本研究的每种方法中使用‘像素输入’，以研究‘像素输入’对不同机器学习算法的影响（表[1](#S1.T1 "Table 1 ‣ 1 Introduction
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")）。限制玻尔兹曼机（RBM）（Smolensky,
    [1986](#bib.bib65)；Hinton, [2002](#bib.bib32)；Salakhutdinov et al., [2007](#bib.bib60)），如表[1](#S1.T1
    "Table 1 ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")所示，是最简单的具有一个隐藏层的神经网络，我们在本研究中将其视为特征提取器（第[3.1节](#S3.SS1
    "3.1 Restricted Boltzmann Machine (RBM) ‣ 3 Models of Machine Learning ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")）。
- en: All of the codes in this study are built on Python. The main packages we use
    in this paper are scikit-learn⁵⁵5http://scikit-learn.org/stable/ (Pedregosa et al.,
    [2012](#bib.bib55)) for most of methods; Theano⁶⁶6http://deeplearning.net/software/theano/,
    Lasagne⁷⁷7http://lasagne.readthedocs.io/en/latest/, and nolearn⁸⁸8https://pythonhosted.org/nolearn/
    for CNN.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究中的所有代码都基于Python。我们在本文中使用的主要软件包是用于大多数方法的scikit-learn⁵⁵5http://scikit-learn.org/stable/（Pedregosa
    et al., [2012](#bib.bib55)）；以及用于CNN的Theano⁶⁶6http://deeplearning.net/software/theano/，Lasagne⁷⁷7http://lasagne.readthedocs.io/en/latest/和nolearn⁸⁸8https://pythonhosted.org/nolearn/。
- en: 3.1 Restricted Boltzmann Machine (RBM)
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 限制玻尔兹曼机（RBM）
- en: Restricted Boltzmann Machine (RBM) (Smolensky, [1986](#bib.bib65); Hinton, [2002](#bib.bib32);
    Salakhutdinov et al., [2007](#bib.bib60)) contains one hidden layer which is the
    simplest neural network architecture (more explanation for the architecutre of
    neural network in section [3.6](#S3.SS6 "3.6 Multi-Layer Perceptron Classifier
    (MLPC) ‣ 3 Models of Machine Learning ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    This is a useful algorithm for dimensionality reduction and feature learning;
    therefore, in this paper, the RBM is used as a feature extractor to connect each
    feature. It extracts the features which are more interlinked with each other before
    we feed them to other machine learning algorithms. The combination of machine
    learning algorithms such as logistic regression (Chopra & Yadav, [2017](#bib.bib12))
    and RBM is actually widely used in face and handwriting recognition.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 限制玻尔兹曼机（RBM）（Smolensky，[1986](#bib.bib65)；Hinton，[2002](#bib.bib32)；Salakhutdinov
    等，[2007](#bib.bib60)）包含一个隐藏层，这是最简单的神经网络架构（更多关于神经网络架构的解释见第[3.6](#S3.SS6 "3.6 Multi-Layer
    Perceptron Classifier (MLPC) ‣ 3 Models of Machine Learning ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")节）。这是一个有用的降维和特征学习算法；因此，在本文中，RBM 被用作特征提取器，以连接每个特征。它提取出那些在输入其他机器学习算法之前彼此更紧密关联的特征。像逻辑回归（Chopra
    & Yadav，[2017](#bib.bib12)）和 RBM 这样的机器学习算法组合实际上广泛应用于面部和手写识别。
- en: In this study, the setting of RBM is identical amongst all methods that we apply
    a fixed learning rate ($=$0.001), 1,024 numbers of hidden units, and 500 iterations
    for RBM in training, where the learning rate determines how far to move the weights
    each time towards the local minimum of loss function. The number of iteration
    is approximately determined by where the maximum of log-likelihood is shown.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，RBM 的设置在所有方法中都是相同的，我们使用固定的学习率（`=$0.001`）、1,024 个隐藏单元和 500 次 RBM 训练迭代，其中学习率决定了每次向损失函数局部最小值移动的权重幅度。迭代次数大致由对数似然的最大值来确定。
- en: 3.2 k-Nearest Neighbours (KNN)
  id: totrans-95
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 k-近邻（KNN）
- en: K-Nearest Neighbours (KNN) is the simplest non-parametric machine learning algorithm
    (Fix & Hodges, [1989](#bib.bib25); Cover & Hart, [1967](#bib.bib16); Short & Fukunaga,
    [1981](#bib.bib63); Cunningham & Delany, [2007](#bib.bib17)). This is one of the
    most common methods in pattern recognition and has several applications in clustering
    and classification problems (in astronomy e.g. Kügler et al., [2015](#bib.bib44)).
    The concept of KNN is to find highly similar data, where similarity is defined
    by the ‘distance’ in the feature space between data. Parameter k is the number
    of nearest neighbours counted in the same group. This factor controls the shape
    of the decision boundary for the distribution of data.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: K-近邻（KNN）是最简单的非参数机器学习算法（Fix & Hodges，[1989](#bib.bib25)；Cover & Hart，[1967](#bib.bib16)；Short
    & Fukunaga，[1981](#bib.bib63)；Cunningham & Delany，[2007](#bib.bib17)）。这是模式识别中最常见的方法之一，并且在聚类和分类问题中有多个应用（如天文学中的
    Kügler 等，[2015](#bib.bib44)）。KNN 的概念是找到高度相似的数据，其中相似性由数据在特征空间中的“距离”定义。参数 k 是在同一组中计数的最近邻居的数量。这个因素控制数据分布的决策边界的形状。
- en: Increasing the value of k decreases the variance in the classification but also
    increases the bias of the classification. We chose the value of k by plotting
    the accuracy (Equation [5](#S4.E5 "In 4.5 Comparison between methods ‣ 4 Results
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")) versus different values
    of k, and the value we ultimately use is k=5\. The distance metric for calculating
    the distance between each data is defined by the Euclidean metric.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 增加 k 的值会减少分类的方差，但也会增加分类的偏差。我们通过绘制准确率（方程[5](#S4.E5 "In 4.5 Comparison between
    methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")）与不同
    k 值的关系来选择 k 的值，最终使用的值是 k=5。计算每个数据之间距离的距离度量由欧几里得度量定义。
- en: 3.3 Logistic Regression (LR)
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 逻辑回归（LR）
- en: Logistic Regression (LR) is a generalised linear model (McCullagh & Nelder,
    [1989](#bib.bib50)) which uses the sigmoid function $\frac{1}{1+{e}^{-x}}$ (or
    logistic function) to output the probability of classification. The application
    in astronomy such as Huppenkothen et al. ([2017](#bib.bib41)) studies the variability
    of galactic black hole binary.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 逻辑回归（LR）是一种广义线性模型（McCullagh & Nelder, [1989](#bib.bib50)），它使用 sigmoid 函数 $\frac{1}{1+{e}^{-x}}$（或逻辑函数）来输出分类的概率。在天文学中的应用，例如
    Huppenkothen 等人（[2017](#bib.bib41)）研究了银河系黑洞双星的变异性。
- en: The combination of LR and RBM is commonly used in face and handwriting recognition
    (Chopra & Yadav, [2017](#bib.bib12)). The improvement of this combination is rather
    significant in LR while using ‘pixel input’ because of the characteristics of
    neural networks (See section [4](#S4 "4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: LR 和 RBM 的结合通常用于人脸和手写识别（Chopra & Yadav, [2017](#bib.bib12)）。由于神经网络的特性，这种结合在使用“像素输入”时在
    LR 中的改进是相当显著的（参见第 [4](#S4 "4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging)
    节）。
- en: 3.4 Support Vector Machine (SVM)
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 支持向量机（SVM）
- en: 'The concept of Support Vector Machine (SVM) algorithm is to find a hyperplane
    with the maximal distance to the nearest data for each type (support vector) (Vapnik,
    [1995](#bib.bib69); Cortes & Vapnik, [1995](#bib.bib15)). In this study, we use
    a non-linear SVM, in particular, the Radial Basis Function (RBF) kernel function
    (Orr & Science, [1996](#bib.bib54)): $\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)\rightarrow
    K\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)=exp\left(-\gamma{\left\|{\vec{x}}-{\vec{x}}^{{}^{\prime}}\right\|}^{2}\right)$.
    The detailed introduction of the SVM algorithm is given in Appendix [A](#A1 "Appendix
    A Support Vector Machine ‣ Optimising Automatic Morphological Classification of
    Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging").'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）算法的概念是找到一个与每种类型的最近数据的距离最大的超平面（支持向量）（Vapnik, [1995](#bib.bib69); Cortes
    & Vapnik, [1995](#bib.bib15)）。在这项研究中，我们使用非线性 SVM，特别是径向基函数（RBF）核函数（Orr & Science,
    [1996](#bib.bib54)）：$\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)\rightarrow
    K\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)=exp\left(-\gamma{\left\|{\vec{x}}-{\vec{x}}^{{}^{\prime}}\right\|}^{2}\right)$。SVM
    算法的详细介绍见附录 [A](#A1 "Appendix A Support Vector Machine ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")。
- en: SVM was expecting to be an alternative option for the neural network due to
    the capability of dealing with high-dimensional data (Zanaty, [2012](#bib.bib74)).
    The application of this in astronomy is very popular, e.g. Gao et al. ([2008](#bib.bib30));
    Huertas-Company et al. ([2008](#bib.bib36)); Huertas-Company et al. ([2009](#bib.bib37));
    Kovács & Szapudi ([2015](#bib.bib43)). In this study, we use Nu-SVM which was
    first introduced by Scholkopf & Smola ([2001](#bib.bib61)), and apply the Python
    package NuSVC. The value of nu is determined by the Python package GridSearchCV
    (Hsu et al., [2003](#bib.bib34)).
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 由于处理高维数据的能力，SVM 被期望成为神经网络的替代选项（Zanaty，[2012](#bib.bib74)）。在天文学中的应用非常普遍，例如 Gao
    等人（[2008](#bib.bib30)）；Huertas-Company 等人（[2008](#bib.bib36)）；Huertas-Company
    等人（[2009](#bib.bib37)）；Kovács & Szapudi（[2015](#bib.bib43)）。在这项研究中，我们使用了 Nu-SVM，首先由
    Scholkopf & Smola（[2001](#bib.bib61)）引入，并应用了 Python 包 NuSVC。nu 的值由 Python 包 GridSearchCV
    确定（Hsu 等人，[2003](#bib.bib34)）。
- en: 3.5 Random Forest (RF)
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 随机森林（RF）
- en: Random Forest (RF) is an ensemble learning method developed by Breiman ([2001](#bib.bib11))
    which aggregates the results from a number of individual decision trees to decide
    the final classification (Fawagreh et al., [2014](#bib.bib23)). Each tree is trained
    by a randomly picked subset from the training set. The RF is a well known machine
    learning technique applied in Astronomy using ‘parameter input’ (e.g. Dubath et al.,
    [2011](#bib.bib22); Beck et al., [2018](#bib.bib8)) but the application that directly
    using pixel such as our study is untested.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林（RF）是一种由 Breiman（[2001](#bib.bib11)）开发的集成学习方法，它将多个单独决策树的结果汇总以决定最终分类（Fawagreh
    等人，[2014](#bib.bib23)）。每棵树都是通过从训练集中随机选取的子集进行训练的。RF 是一种在天文学中应用的著名机器学习技术，使用“参数输入”（例如
    Dubath 等人，[2011](#bib.bib22)；Beck 等人，[2018](#bib.bib8)），但直接使用像素的应用，如我们的研究，尚未经过测试。
- en: We use RandomForestClassifier from the scikit-learn module (Pedregosa et al.,
    [2012](#bib.bib55)). The number of trees (n_estimators) used in this study is
    determined by plotting the accuracy (Equation [5](#S4.E5 "In 4.5 Comparison between
    methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")) versus
    different values of n_estimators, and we ultimately use 200 trees. The maximal
    number of features to consider for each split (max_features) is equal to $\sqrt{{N}_{f}}$,
    where ${{N}_{f}}$ is the total number of features. Each tree grows until all leaves
    are pure or all leaves contain the number of leaves less than 2.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用 scikit-learn 模块中的 RandomForestClassifier (Pedregosa et al., [2012](#bib.bib55))。本研究中使用的树的数量
    (n_estimators) 是通过绘制准确度 (方程 [5](#S4.E5 "在 4.5 方法比较 ‣ 4 结果 ‣ 利用机器学习和深度学习优化暗能量探测器成像的自动形态分类"))
    对不同 n_estimators 值的图来确定的，最终我们使用了 200 棵树。每次分裂考虑的最大特征数量 (max_features) 等于 $\sqrt{{N}_{f}}$，其中
    ${{N}_{f}}$ 是特征的总数。每棵树生长直到所有叶子都是纯净的或所有叶子包含的叶子数量少于 2。
- en: 3.6 Multi-Layer Perceptron Classifier (MLPC)
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 多层感知机分类器 (MLPC)
- en: Multi-Layer Perceptron Classifier (MLPC) is a supervised artificial neural network
    with multiple hidden layers (Rosenblatt, [1958](#bib.bib58); Fukushima, [1975](#bib.bib27);
    Fukushima et al., [1983](#bib.bib29)). Hidden layers which have several hidden
    units are invisible layers between input and output layer in neural networks,
    and are used to connect input features with each other. Each hidden unit is an
    activation function calculated by the product of weights and input. Using a neural
    network with one hidden layer as an example (Fig. [3](#S3.F3 "Figure 3 ‣ 3.6 Multi-Layer
    Perceptron Classifier (MLPC) ‣ 3 Models of Machine Learning ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")), $X1$ and $X2$ are input features, $f1$ and
    $f2$ are the activation functions of hidden units calculated by (using $f1$ as
    an example) $f1=f\left(w0\cdot 1+w1X1+w2X2\right)$, where $w$ are weights and
    $f$ represents an activation function as well. Through the calculation, it connects
    each input feature with hidden units by weights. Therefore, more hidden layers
    and more hidden units in each hidden layer can form more complicated connections
    of input features; however, the architecture with more hidden layers and hidden
    units is more time-consuming and can lead to overfitting problems. Similarly,
    the output layer also can be calculated from this concept.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 多层感知机分类器 (MLPC) 是一种具有多个隐藏层的监督式人工神经网络 (Rosenblatt, [1958](#bib.bib58); Fukushima,
    [1975](#bib.bib27); Fukushima et al., [1983](#bib.bib29))。隐藏层是输入层和输出层之间不可见的层，用于将输入特征彼此连接。每个隐藏单元是通过权重和输入的乘积计算得到的激活函数。以一个隐藏层的神经网络为例
    (图 [3](#S3.F3 "图 3 ‣ 3.6 多层感知机分类器 (MLPC) ‣ 3 机器学习模型 ‣ 利用暗能量探测器成像优化自动形态分类"))，$X1$
    和 $X2$ 是输入特征，$f1$ 和 $f2$ 是通过 (以 $f1$ 为例) $f1=f\left(w0\cdot 1+w1X1+w2X2\right)$
    计算得到的隐藏单元的激活函数，其中 $w$ 是权重，$f$ 也是激活函数。通过计算，它通过权重将每个输入特征与隐藏单元连接。因此，更多的隐藏层和每层更多的隐藏单元可以形成更复杂的输入特征连接；然而，更多的隐藏层和隐藏单元架构更耗时，并且可能导致过拟合问题。类似地，输出层也可以从这个概念中计算得出。
- en: MLPC uses a back-propagation algorithm (Werbos & John, [1974](#bib.bib71); Rumelhart
    et al., [1986](#bib.bib59)), which returns the error of predicted classification
    compared with the true label to the algorithm when the neural network is activated
    and the preliminary output is obtained. Algorithm adjusts the weights through
    the error until the error is lower than the tolerance which we set ${10}^{-5}$.
    There are two hidden layers and 1,024 hidden units for each hidden layer in MLPC
    method we used. The learning rate is fixed to 0.001.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: MLPC 使用反向传播算法 (Werbos & John, [1974](#bib.bib71); Rumelhart et al., [1986](#bib.bib59))，当神经网络被激活并得到初步输出时，将预测分类的误差与真实标签进行比较，然后返回给算法。算法通过误差调整权重，直到误差低于我们设置的容忍度${10}^{-5}$。我们使用的
    MLPC 方法有两个隐藏层，每个隐藏层有 1,024 个隐藏单元。学习率固定为 0.001。
- en: '![Refer to caption](img/e18ce1383990493ee359676d76cce784.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e18ce1383990493ee359676d76cce784.png)'
- en: 'Figure 3: Illustration of a neural networks. This structure is for illustration
    only and this includes one hidden layer, and two hidden units. Two input features,
    $X1$ and $X2$, work with the activation functions, $f1$ and $f2$, then obtain
    the outputs, $Y1$ and $Y2$.'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：神经网络的示意图。此结构仅用于说明，包括一个隐藏层和两个隐藏单元。两个输入特征，$X1$ 和 $X2$，与激活函数 $f1$ 和 $f2$ 一起工作，然后获得输出
    $Y1$ 和 $Y2$。
- en: '![Refer to caption](img/f94a469ed80aaa734fa38de7ad139884.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f94a469ed80aaa734fa38de7ad139884.png)'
- en: 'Figure 4: The schematic overview of the architecture of CNN. The architecture
    starts from an input image with size 50 by 50 pixels, then three convolutional
    layers (filter: 32, 64, and 128). Each convolutional layer is followed a pooling
    layer. Two hidden layers with 1,024 hidden units for each are following the third
    convolutional layer. One dropout (p=0.5) follows after the third convolutional
    layer and the other follows after the second hidden layer. At last, there are
    two outputs in our CNN, ‘Ellipticals’ and ‘Spirals’.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：CNN 架构的示意图。架构从尺寸为50x50像素的输入图像开始，然后经过三层卷积层（滤波器：32、64和128）。每个卷积层后面跟着一个池化层。第三层卷积层后面跟着两个具有1,024个隐藏单元的隐藏层。一个丢弃层（p=0.5）在第三层卷积层后面跟着，另一个在第二个隐藏层后面跟着。最后，我们的
    CNN 有两个输出，“椭圆形”和“螺旋形”。
- en: 3.7 Convolutional Neural Networks (CNN)
  id: totrans-114
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 卷积神经网络（CNN）
- en: Convolutional Neural Networks (CNN) started from the design of LeNet-5 (Lecun
    et al., [1998](#bib.bib46)). However, CNN were not applied to the morphological
    classification of galaxies utill Dieleman et al. ([2015](#bib.bib19)) in the Galaxy
    Zoo Challenge⁹⁹9https://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge. There
    are two main differences between artificial neural networks (e.g. MLPC) and CNN.
    One is that CNN has convolutional layers which are able to extract notable features
    from the input images by applying several filter matrices, and the other difference
    is the dimension of the input.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 卷积神经网络（CNN）始于 LeNet-5 的设计（Lecun 等人，[1998](#bib.bib46)）。然而，CNN 直到 Dieleman 等人（[2015](#bib.bib19)）在银河挑战赛中才被应用于星系的形态分类。人工神经网络（例如
    MLPC）和 CNN 之间有两个主要区别。一是 CNN 具有卷积层，能够通过应用多个滤波器矩阵从输入图像中提取显著特征，另一个区别是输入的维度。
- en: Most machine learning algorithms are designed for dealing with 1D array input
    (e.g. parameter input), but some of them (e.g. SVM and neural networks) are able
    to deal with higher dimension data. However, the input still needs to be reshaped
    to 1D arrays for SVM and MLPC. On the contrast, CNN is designed for image input
    with three dimension arrays which means that in addition to the image itself,
    CNN has an extra dimension to store more information of image such as colours
    (RGB).
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数机器学习算法设计用于处理1D数组输入（例如参数输入），但其中一些（例如SVM和神经网络）能够处理更高维度的数据。然而，输入仍然需要被重塑为1D数组以便于SVM和MLPC。相比之下，CNN设计用于处理三维数组的图像输入，这意味着除了图像本身，CNN还有一个额外的维度来存储图像的更多信息，例如颜色（RGB）。
- en: Fig. [4](#S3.F4 "Figure 4 ‣ 3.6 Multi-Layer Perceptron Classifier (MLPC) ‣ 3
    Models of Machine Learning ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    shows the architecture of CNN that we use in this study. The input size of image
    is 50 by 50 pixels (Section [2.1.2](#S2.SS1.SSS2 "2.1.2 Creation of the galaxy
    stamps ‣ 2.1 Pre-Processing ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")). We have 3 convolutional layers with filter sizes of
    3, 3, 2, respectively, and each of them is followed with a pooling layer with
    size 2\. These are then connected with two hidden layers with 1,024 hidden units
    for each layer. Additionally, two dropout layers are used to prevent overfitting,
    one follows the third convolutional layer (pooling layer), and the other comes
    after two hidden layers. The rectification of non-linearity is applied for each
    convolutional layer and hidden layer, and the softmax function is applied to the
    output layer to get the probability distribution of each type (all from the Python
    package lasagne.nonlinearities). We use Adam Optimiser, Nesterov momentum, and
    set momentum=0.9 according to Dieleman et al. ([2015](#bib.bib19)), and the learning
    rate 0.001 and maximum 500 iterations for the CNN training.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [4](#S3.F4 "图 4 ‣ 3.6 多层感知机分类器 (MLPC) ‣ 3 机器学习模型 ‣ 使用暗能量调查成像优化星系的自动形态分类")
    显示了我们在本研究中使用的 CNN 架构。图像的输入大小为 50 x 50 像素（第 [2.1.2](#S2.SS1.SSS2 "2.1.2 星系邮票的创建
    ‣ 2.1 预处理 ‣ 2 数据集 ‣ 使用暗能量调查成像优化星系的自动形态分类") 节）。我们有 3 个卷积层，滤波器大小分别为 3、3、2，每个卷积层后面跟一个大小为
    2 的池化层。然后，这些层与两个隐藏层连接，每个层有 1,024 个隐藏单元。此外，使用两个 dropout 层来防止过拟合，一个跟在第三个卷积层（池化层）后面，另一个跟在两个隐藏层之后。每个卷积层和隐藏层应用了非线性修正，输出层应用
    softmax 函数以获得每种类型的概率分布（均来自 Python 包 lasagne.nonlinearities）。我们使用 Adam 优化器、Nesterov
    动量，并根据 Dieleman 等人 ([2015](#bib.bib19)) 设置动量=0.9，学习率 0.001 和最多 500 次迭代进行 CNN 训练。
- en: 4 Results
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 结果
- en: '![Refer to caption](img/5f455365119420a2ef7e68be6f4d75a3.png)'
  id: totrans-119
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5f455365119420a2ef7e68be6f4d75a3.png)'
- en: 'Figure 5: The confusion matrix. The x-axis label is the predicted label and
    the y-axis label is the true label. The ‘0’ means negative as well as Ellipticals
    type while ‘1’ represents positive signal and Spirals type in this study.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：混淆矩阵。x 轴标签是预测标签，y 轴标签是真实标签。‘0’表示负类以及椭圆星系类型，而‘1’代表正类信号和螺旋星系类型。
- en: 4.1 The evaluation factors for models
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 模型的评估因素
- en: We use the Receiver Operating Characteristic curve (ROC curve) (Fawcett, [2006](#bib.bib24);
    Powers, [2011](#bib.bib57)) to examine the performance of each method and dataset.
    On a ROC curve the y-axis is the true positive rate and the x-axis is the false
    positive rate; therefore, the closer the ROC curve gets to the corner (0,1), the
    better the performance is. The definition of true positive and the false positive
    are shown in Fig. [5](#S4.F5 "Figure 5 ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") in terms of the confusion matrix. Therefore, the true
    positive rate ($TPR$) and false positive rate ($FPR$) are defined as below,
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用接收者操作特性曲线（ROC 曲线）（Fawcett，[2006](#bib.bib24)；Powers，[2011](#bib.bib57)）来检验每种方法和数据集的性能。在
    ROC 曲线中，y 轴是真阳性率，x 轴是假阳性率；因此，ROC 曲线越接近角落（0,1），性能越好。真实阳性和假阳性的定义如图 [5](#S4.F5 "图
    5 ‣ 4 结果 ‣ 使用暗能量调查成像优化星系的自动形态分类") 所示。 因此，真实阳性率 ($TPR$) 和假阳性率 ($FPR$) 定义如下，
- en: '|  | $TPR=\frac{TP}{TP+FN};\quad FPR=\frac{FP}{FP+TN}.$ |  | (2) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | $TPR=\frac{TP}{TP+FN};\quad FPR=\frac{FP}{FP+TN}.$ |  | (2) |'
- en: 'The definition of $TPR$ is identical to ‘recall ($R$)’ in statistics which
    represents the completeness that shows how many true types have been picked, while
    ‘precision ($Prec$)’ indicates the contamination which means how many picked types
    (predicted types) are true types. We are doing binary classification - positive:
    Spirals and negative: Ellipticals. Therefore, the recalls for Spirals and Ellipticals
    are shown below,'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: $TPR$ 的定义与统计学中的“召回率 ($R$)”相同，表示显示被挑选的真实类型的完整性，而“精准率 ($Prec$)”表示污染，意味着被挑选的类型（预测类型）中有多少是实际类型。我们进行的是二分类
    - 正类：螺旋星系，负类：椭圆星系。因此，螺旋星系和椭圆星系的召回率如下所示，
- en: '|  | $Prec=\frac{TP}{TP+FP};$ |  | (3) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | $Prec=\frac{TP}{TP+FP};$ |  | (3) |'
- en: '|  | $R\left(1\right)=\frac{TP}{TP+FN};\quad R\left(0\right)=\frac{TN}{TN+FP}.$
    |  | (4) |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|  | $R\left(1\right)=\frac{TP}{TP+FN};\quad R\left(0\right)=\frac{TN}{TN+FP}.$
    |  | (4) |'
- en: Additionally, we also use the factor - the area under the ROC curve (AUC) as
    a performance evaluation for machine learning (Bradley, [1997](#bib.bib10); Fawcett,
    [2006](#bib.bib24)). The meaning of AUC is the probability that a classifier ranks
    a randomly chosen positive example greater than a randomly chosen negative example.
    This factor also indicates the separability - how well the classifications can
    be correctly separated from each other.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们还使用了一个因子——ROC曲线下面积（AUC）作为机器学习的性能评估标准（Bradley，[1997](#bib.bib10)；Fawcett，[2006](#bib.bib24)）。AUC的意义是分类器将一个随机选择的正例排在一个随机选择的负例之上的概率。这个因子也表明了可分离性——分类能否被正确分开。
- en: 4.2 The impact of rotated images
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 旋转图像的影响
- en: '![Refer to caption](img/617a9a662310d4511b73a3d78fa51e26.png)'
  id: totrans-129
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/617a9a662310d4511b73a3d78fa51e26.png)'
- en: 'Figure 6: The ROC curve of each method and each dataset using the raw images
    input (i). The abbreviation of the methods are the same as Table [1](#S1.T1 "Table
    1 ‣ 1 Introduction ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging"). Different
    colours are for the different datasets (Table [2](#S2.T2 "Table 2 ‣ 2.2 The datasets
    ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")). Yellow,
    orange, cyan, blue are for dataset 1, 2, 3, 4, respectively. The lighter colour
    shading shows the scatters defined by the minimum and maximum of three reruns,
    and the lines inside are the averages of the three reruns. The black diagonal
    dashed line represents a random classification.'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：使用原始图像输入（i）的各方法和各数据集的ROC曲线。方法的缩写与表[1](#S1.T1 "Table 1 ‣ 1 Introduction ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")相同。不同的颜色用于不同的数据集（表[2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。黄色、橙色、青色、蓝色分别代表数据集1、2、3、4。较浅的颜色阴影表示由三次重复运行的最小值和最大值定义的散点，内部线条为三次重复运行的平均值。黑色对角虚线表示随机分类。
- en: The ROC curves of each method and datasets are shown in Fig. [6](#S4.F6 "Figure
    6 ‣ 4.2 The impact of rotated images ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging"). We show the results of raw images input (i) in this figure.
    Different colours represent different datasets such that the yellow, orange, cyan,
    blue lines represents datasets 1, 2, 3, 4, respectively (Table [2](#S2.T2 "Table
    2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    The datasets 1 and 2 contain both the original images and the rotated images,
    and the datasets 3 and 4 only contain the rotated images. Meanwhile, the datasets
    1 and 3 have an unbalance number of each type, conversely, the datasets 2 and
    4 have an identical number for each classification. The lighter colour shadings
    are the scatters defined by the minimum and maximum over three reruns. The black
    diagonal dashed line indicates a random classification.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 各方法和数据集的ROC曲线如图[6](#S4.F6 "Figure 6 ‣ 4.2 The impact of rotated images ‣ 4 Results
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")所示。我们在此图中展示了原始图像输入（i）的结果。不同的颜色表示不同的数据集，黄色、橙色、青色、蓝色线条分别表示数据集1、2、3、4（表[2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。数据集1和2包含原始图像和旋转图像，而数据集3和4仅包含旋转图像。同时，数据集1和3的每种类型的数量不平衡，相反，数据集2和4的每种分类的数量相同。较浅的颜色阴影是由三次重复运行的最小值和最大值定义的散点。黑色对角虚线表示随机分类。
- en: First, the results of the LR and SVM methods, with and without combining with
    neural network, RBM show an improvement for LR and SVM when combining with RBM
    in Fig. [6](#S4.F6 "Figure 6 ‣ 4.2 The impact of rotated images ‣ 4 Results ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging"). On the contrary, the performance
    of RF+RBM method shows slightly worse performance than the one of the RF method.
    Secondly, the scatters of the three reruns show small variance for each dataset,
    confirming the consistency of the reruns with each other. Additionally, as can
    be seen there are not large differences in the results between the different datasets.
    However, the slight shifts of the ROC curve occur within a few methods between
    the different datasets (e.g. MLPC). These are due to the slight differences in
    the total number of training samples for different datasets (Table [2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")). For example in MLPC, the dataset 4 has the maximum number
    of training data within the 4 datasets used ($\sim$12400 galaxies), so the performance
    of this dataset is the best in MLPC; the datasets 2 and 3 have very similar number
    of training data (the differences in number is only 67), thus they have a similar
    performance to each other. The dataset 1 has the least number of training data
    ($\sim$10400 galaxies), therefore, the performance is relatively worse. The shifts
    seen are also influenced by the condition of the balance between the ratio of
    each type (e.g. SVM and RF), for example, the datasets 1 and 3 are the unbalanced
    training data, so the shape of their ROC curve are similar to each other. This
    is also the case for the datasets 2 and 4\. To summarise, from Fig. [6](#S4.F6
    "Figure 6 ‣ 4.2 The impact of rotated images ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"), data augmentation through rotated images works
    fair to improve the performance of classification with machine learning.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，图[6](#S4.F6 "图 6 ‣ 4.2 旋转图像的影响 ‣ 4 结果 ‣ 使用暗能量调查图像优化银河自动形态分类的机器学习与深度学习")中展示了LR和SVM方法的结果，无论是否与神经网络、RBM结合，当与RBM结合时，LR和SVM都有所改善。相反，RF+RBM方法的表现略逊于RF方法。其次，三次重复实验的散点图显示每个数据集的方差很小，确认了重复实验之间的一致性。此外，如所见，不同数据集之间的结果差异不大。然而，不同数据集之间（例如MLPC）的ROC曲线的轻微偏移发生在几个方法中。这些偏移是由于不同数据集的训练样本总数的轻微差异（表[2](#S2.T2
    "表 2 ‣ 2.2 数据集 ‣ 2 数据集 ‣ 使用暗能量调查图像优化银河自动形态分类的机器学习与深度学习")）。例如，在MLPC中，数据集4在4个使用的数据集中拥有最多的训练数据（$\sim$12400个银河），因此在MLPC中的表现最好；数据集2和3的训练数据数量非常相似（数量差异仅为67），因此它们的表现也相似。数据集1的训练数据最少（$\sim$10400个银河），因此其表现相对较差。看到的偏移也受每种类型比例的平衡条件的影响（例如SVM和RF），例如，数据集1和3是训练数据不平衡的，因此它们的ROC曲线形状彼此相似。数据集2和4也存在这种情况。总之，从图[6](#S4.F6
    "图 6 ‣ 4.2 旋转图像的影响 ‣ 4 结果 ‣ 使用暗能量调查图像优化银河自动形态分类的机器学习与深度学习")中总结，旋转图像的数据增强对机器学习分类性能的提升效果一般。
- en: 4.3 Balance or Unbalance?
  id: totrans-133
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 平衡还是不平衡？
- en: '![Refer to caption](img/0a8cc2a4b8e775e4ad6849511d9331d9.png)'
  id: totrans-134
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0a8cc2a4b8e775e4ad6849511d9331d9.png)'
- en: 'Figure 7: The recalls of the Ellipticals and Spirals for all methods and the
    different types of the input data used. The colours represent the different datasets,
    while the different shape markers are the different methods. The different types
    of filled-points represent the different types of input. The fully-colour-filled
    markers are the raw images only (i), the diagonal-line-filled markers are the
    HOG images (ii), and those with dots are the combination input of the raw and
    HOG images (iii) which is only for CNN. The black dashed line represents the condition
    that $R(0)=R(1)$ (Equation [4](#S4.E4 "In 4.1 The evaluation factors for models
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")). The black
    dotted lines indicate that the differences in the recalls between these two types
    are within $\pm$0.1\. The error bars are from the standard deviation of the three
    reruns.'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：所有方法和不同类型输入数据的椭圆星系和螺旋星系的召回率。颜色表示不同的数据集，而不同的形状标记表示不同的方法。不同类型的填充点表示不同的输入类型。完全填充颜色的标记仅为原始图像
    (i)，对角线填充的标记为 HOG 图像 (ii)，而带有点的标记是原始图像和 HOG 图像的组合输入 (iii)，仅适用于 CNN。黑色虚线表示 $R(0)=R(1)$
    的条件（方程 [4](#S4.E4 "In 4.1 The evaluation factors for models ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")）。黑色虚点线表示这两种类型的召回率差异在 $\pm$0.1 以内。误差条来源于三次重跑的标准偏差。
- en: Here we investigate the influence of the balance between the number of each
    type in training data. Fig. [7](#S4.F7 "Figure 7 ‣ 4.3 Balance or Unbalance? ‣
    4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") shows the
    recalls of Ellipticals and Spirals for the different datasets using the different
    methods. The colour representation is the same as the ROC curve of Fig. [6](#S4.F6
    "Figure 6 ‣ 4.2 The impact of rotated images ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"), and the different methods are marked by the
    different shape markers. We obtain the value of the recall from equation [4](#S4.E4
    "In 4.1 The evaluation factors for models ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") for Fig. [7](#S4.F7 "Figure 7 ‣ 4.3 Balance or Unbalance?
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") by averaging
    the values from the three reruns. Different pattern types represent different
    types of input. The colour-filled points are the raw images input (i) while the
    points with diagonal-filled marker are the HOG images (ii), and with dotted-filled
    marker are the combination input (iii). The black diagonal dashed line shows the
    condition that $R(0)=R(1)$ (Equation [4](#S4.E4 "In 4.1 The evaluation factors
    for models ‣ 4 Results ‣ Optimising Automatic Morphological Classification of
    Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")),
    and the black dotted lines show that the recall differences between these two
    types are within $\pm$0.1.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们调查了训练数据中每种类型数量平衡的影响。图 [7](#S4.F7 "Figure 7 ‣ 4.3 Balance or Unbalance?
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") 显示了不同数据集使用不同方法得到的椭圆星系和螺旋星系的召回率。颜色表示与图
    [6](#S4.F6 "Figure 6 ‣ 4.2 The impact of rotated images ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging") 的 ROC 曲线相同，不同的方法用不同形状的标记表示。我们通过对三次重跑的值取平均来获得图
    [7](#S4.F7 "Figure 7 ‣ 4.3 Balance or Unbalance? ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") 中召回率的值。不同的模式类型表示不同的输入类型。颜色填充的点是原始图像输入 (i)，而带有对角线填充标记的点是
    HOG 图像 (ii)，带有点状填充标记的是组合输入 (iii)。黑色对角虚线表示 $R(0)=R(1)$ 的条件（方程 [4](#S4.E4 "In 4.1
    The evaluation factors for models ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")），黑色虚线表示这两种类型之间的召回率差异在 $\pm$0.1 以内。
- en: We observe that the unbalance training dataset 1 (yellow) and dataset 3 (cyan)
    are all above the upper dotted line which means that these two datasets generally
    have relatively higher recalls for Spirals compared to Ellipticals, and the differences
    of the recalls between Spirals and Ellipticals are larger than 0.1\. For example,
    the result of the LR with the raw images input (i) (using the dataset 3 as an
    example shown as the leftmost cyan square in Fig. [7](#S4.F7 "Figure 7 ‣ 4.3 Balance
    or Unbalance? ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"))
    has the recall of (0.34, 0.81) for Ellipticals and Spirals, respectively. We also
    observe that the LR, LR+RBM, SVM, and SVM+RBM methods have more seriously unbalanced
    results than other methods when using the unbalanced datasets (close to top-left
    in Fig. [7](#S4.F7 "Figure 7 ‣ 4.3 Balance or Unbalance? ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")). This situation is due to the characteristics
    of these methods. For example, LR simply uses logistic functions to determine
    the decision boundary which can be easily shifted by unbalanced number of each
    type. On the other hand, Wu & Chang ([2003](#bib.bib73)) discusses the skewed
    decision boundary of SVM caused by an unbalanced data such that the decision boundary
    is likely to be dominated by the support vector for the majority class.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 我们观察到，不平衡的训练数据集1（黄色）和数据集3（青色）都位于上方虚线之上，这意味着这两个数据集对于螺旋星系的召回率通常相对较高，而与椭圆星系相比，螺旋星系的召回率差异大于0.1。例如，使用原始图像输入（i）的LR结果（以数据集3为例，如图[7](#S4.F7
    "图7 ‣ 4.3 平衡还是不平衡？ ‣ 4 结果 ‣ 使用暗能量探测器成像优化自动形态分类")中最左边的青色方块所示）对椭圆星系和螺旋星系的召回率分别为（0.34,
    0.81）。我们还观察到，当使用不平衡数据集时，LR、LR+RBM、SVM和SVM+RBM方法的结果比其他方法更为严重不平衡（如图[7](#S4.F7 "图7
    ‣ 4.3 平衡还是不平衡？ ‣ 4 结果 ‣ 使用暗能量探测器成像优化自动形态分类")中的左上方接近）。这种情况是由于这些方法的特性。例如，LR简单地使用逻辑函数来确定决策边界，这很容易被每种类型的不平衡数量所影响。另一方面，Wu
    & Chang（[2003](#bib.bib73)）讨论了SVM由于不平衡数据而导致的偏斜决策边界，使得决策边界可能被多数类的支持向量所主导。
- en: On the other hand, most of the balanced dataset 2 (orange) and dataset 4 (blue)
    are located within two dotted lines which implies that these two datasets have
    similar recalls between Ellipticals and Spirals (the differences are smaller than
    0.1). However, a few results of the balanced datasets in KNN have a higher recall
    of Ellipticals, but a relatively lower recall of Spirals (the orange and blue
    stars which are below the lower dotted line). KNN algorithm obtains the similarity
    between two images by calculating the ‘distance’ between each pixel of two images
    (Section [3.2](#S3.SS2 "3.2 k-Nearest Neighbours (KNN) ‣ 3 Models of Machine Learning
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")). Spirals have various shapes
    (e.g. different numbers of the spiral arms) while Ellipticals have a relatively
    simple appearance similar to one another. Therefore, it is easier for KNN to recognise
    Ellipticals than Spirals when we have the same numbers of both types within the
    training data.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，大多数平衡的数据集2（橙色）和数据集4（蓝色）位于两条虚线之间，这意味着这两个数据集在椭圆星系和螺旋星系之间的召回率相似（差异小于0.1）。然而，在KNN中，一些平衡数据集的结果显示椭圆星系的召回率较高，但螺旋星系的召回率相对较低（橙色和蓝色星星位于下方虚线之下）。KNN算法通过计算两幅图像之间每个像素的“距离”来获取两幅图像之间的相似性（见第[3.2节](#S3.SS2
    "3.2 k-最近邻（KNN） ‣ 3 机器学习模型 ‣ 使用暗能量探测器成像优化自动形态分类")）。螺旋星系具有多种形状（例如，螺旋臂的数量不同），而椭圆星系的外观相对简单且相似。因此，当训练数据中有相同数量的两种类型时，KNN更容易识别椭圆星系。
- en: We apply ten different common machine learning algorithms in this study and
    they show the consistent result in their balance except for KNN which we have
    discussed above; therefore, according to this discussion, the balance between
    the number of each type in training process is of great importance while using
    pixel input in most machine learning algorithms. In this figure, we also observe
    that the CNN method with a balanced datasets obtains the best recalls of both
    Ellipticals and Spirals.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 在这项研究中，我们应用了十种不同的常见机器学习算法，它们在平衡方面显示出一致的结果，除了上述讨论的KNN；因此，根据这一讨论，在使用大多数机器学习算法的像素输入时，各类型在训练过程中的数量平衡非常重要。在此图中，我们还观察到，使用平衡数据集的CNN方法获得了最佳的椭圆星系和螺旋星系的召回率。
- en: 4.4 The effect of different types of input data
  id: totrans-140
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 不同类型输入数据的影响
- en: '![Refer to caption](img/2bb0ddc01d846e9fd641aba4c14ef731.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2bb0ddc01d846e9fd641aba4c14ef731.png)'
- en: 'Figure 8: The ROC curve for different types of input within each method. Different
    colours are for different input types of data. Cyan, orange, and blue are for
    raw images (i), HOG images (ii), and combination input (iii), respectively. The
    lighter colour shadings show the scatters defined by the standard deviation calculated
    through three runs of the balanced datasets 2 and 4\. The lines inside the shading
    are the averages of the three reruns of the datasets 2 and 4\. The black diagonal
    dashed line represents a random classification. The subplot in the CNN method
    is the zoom-in area from 0.75 to 1.0 in y-axis and from 0.0 to 0.25 in x-axis.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：每种方法中不同类型输入的ROC曲线。不同的颜色代表不同类型的数据输入。青色、橙色和蓝色分别代表原始图像（i）、HOG图像（ii）和组合输入（iii）。较浅的颜色阴影显示由平衡数据集2和4的三次重跑计算得到的标准偏差定义的散布。阴影中的线条是数据集2和4的三次重跑的平均值。黑色对角虚线表示随机分类。CNN方法中的子图是y轴从0.75到1.0以及x轴从0.0到0.25的放大区域。
- en: '![Refer to caption](img/20a8729e9096b38609dc7182b3d8f693.png)'
  id: totrans-143
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/20a8729e9096b38609dc7182b3d8f693.png)'
- en: 'Figure 9: The average accuracy (Equation [5](#S4.E5 "In 4.5 Comparison between
    methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")) of
    the three reruns versus each method with the different datasets and the different
    types of input shown. The y-axis is from 0.5 to 1.0\. Colours represent different
    datasets such that yellow, orange, cyan, blue represents dataset 1, 2, 3, 4 (Table [2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")), respectively. The different styles of shading are the
    different types of input data such that the fully-filled, the diagonal-line-filled,
    the dotted-filled represents the raw images (i), the HOG images (ii), and the
    combination input (iii), respectively. The labels above bars are the highest value
    of the accuracy for each method.'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：三个重跑的平均准确度（公式 [5](#S4.E5 "在4.5方法之间的比较 ‣ 4 结果 ‣ 使用深空探测成像优化自动形态分类的银河系的机器学习和深度学习")）与不同数据集和不同类型输入的方法的对比。y轴范围从0.5到1.0。颜色代表不同的数据集，其中黄色、橙色、青色和蓝色分别代表数据集1、2、3、4（表 [2](#S2.T2
    "表2 ‣ 2.2 数据集 ‣ 2 数据集 ‣ 使用深空探测成像优化自动形态分类的银河系的机器学习和深度学习")）。不同的阴影样式表示不同类型的输入数据，其中完全填充、对角线填充、虚线填充分别代表原始图像（i）、HOG图像（ii）和组合输入（iii）。条形图上方的标签是每种方法的准确度最高值。
- en: Here we show the comparison results between the different types of input for
    each method (Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of
    input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification of
    Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    We have 2 (3 for CNN) different types of input - the raw images (i) , the HOG
    images (ii), and the combinations input (iii) (for CNN only). Different colours
    in Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input data
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") indicate
    different types of input such that cyan, orange, and blue are for the raw images
    (i), the HOG images (ii), and the combination input (iii), respectively. According
    to the discussions in section [4.2](#S4.SS2 "4.2 The impact of rotated images
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") and section [4.3](#S4.SS3
    "4.3 Balance or Unbalance? ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"),
    the results of the balanced datasets 2 and 4 are basically equivalent, and are
    better representations in our four datasets (Table [2](#S2.T2 "Table 2 ‣ 2.2 The
    datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification of
    Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    Therefore, we show the averages of the balanced datasets 2 and 4 after three reruns
    in Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input data
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging"), and the
    lighter colour shadings show the scatters defined by the standard deviation of
    the three reruns.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 这里展示了每种方法不同输入类型之间的比较结果（见图[8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different
    types of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")）。我们有2种（CNN为3种）不同类型的输入
    - 原始图像 (i)、HOG图像 (ii) 和组合输入 (iii)（仅对CNN适用）。图[8](#S4.F8 "Figure 8 ‣ 4.4 The effect
    of different types of input data ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")中的不同颜色表示不同的输入类型，其中青色、橙色和蓝色分别表示原始图像 (i)、HOG图像 (ii) 和组合输入
    (iii)。根据第[4.2](#S4.SS2 "4.2 The impact of rotated images ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")节和第[4.3](#S4.SS3 "4.3 Balance or Unbalance?
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")节的讨论，平衡数据集2和4的结果基本相当，并且在我们的四个数据集中表现更佳（见表[2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。因此，我们在图[8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different
    types of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中展示了平衡数据集2和4的平均值，较浅的颜色阴影显示了三次重复实验的标准偏差定义的散布。
- en: Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input data
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging") shows that
    the HOG images input successfully improves the performance in most of methods,
    except for KNN. Although the HOG image is able to extract the characteristics
    of the morphologies according to the value of the gradients, it also loses some
    of the detailed information (i.e. the smaller fluctuations or gradients) and the
    smooth structure as well. Therefore, for KNN, the loss of the smooth structure
    in HOG images causes difficulties in determining the correct decision boundary.
    This result can be significantly improved by combining KNN with RBM when using
    the HOG images.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: 图[8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input data ‣ 4
    Results ‣ Optimising Automatic Morphological Classification of Galaxies with Machine
    Learning and Deep Learning using Dark Energy Survey Imaging")显示，HOG图像输入在大多数方法中成功提高了性能，除了KNN。尽管HOG图像能够根据梯度值提取形态特征，但它也丧失了一些详细信息（即较小的波动或梯度）以及光滑的结构。因此，对于KNN，HOG图像中光滑结构的丧失导致确定正确决策边界的困难。当使用HOG图像时，将KNN与RBM结合可以显著改善这一结果。
- en: On the other hand, we observe that the application of HOG images shows an unapparent
    effect when combining RBM in LR+RBM, SVM+RBM and RF+RBM. We infer that this phenomenon
    is caused because that the RBM interlinks with the HOG features which have less
    information in the images than the raw images input. Therefore, it ‘annihilate’
    the effect of RBM and HOG which leave an unapparent change in these three methods.
    This effect is shown in both MLPC and CNN as well such that the HOG images input
    shows only a slight improvement in these two methods as well. However, increasing
    the number of hidden layers or more neurons in the neural networks helps to connect
    the HOG features with each other. Therefore, the improvements with HOG images
    in MLPC and CNN are qualitatively better than LR+RBM, SVM+RBM, and RF+RBM. A more
    qualitatively significant improvement is shown in CNN when we combine both the
    raw images input and the HOG images input (blue colour in CNN plot of Fig. [8](#S4.F8
    "Figure 8 ‣ 4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")).
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们观察到，当在LR+RBM、SVM+RBM和RF+RBM中结合使用HOG图像时，效果并不明显。我们推测这一现象是由于RBM与HOG特征的结合，而HOG特征在图像中的信息量少于原始图像输入。因此，它“消除了”RBM和HOG的效果，这导致这三种方法中几乎没有变化。这一效果在MLPC和CNN中也有所体现，使得HOG图像输入在这两种方法中的改进也只是微乎其微。然而，增加神经网络中的隐藏层数或更多神经元有助于将HOG特征彼此连接。因此，HOG图像在MLPC和CNN中的改进质量优于LR+RBM、SVM+RBM和RF+RBM。当我们将原始图像输入和HOG图像输入结合使用时（在图[8](#S4.F8
    "Figure 8 ‣ 4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")的CNN图中显示为蓝色），CNN表现出更显著的质量提升。
- en: 4.5 Comparison between methods
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.5 方法比较
- en: The definition of the accuracy used in Fig. [9](#S4.F9 "Figure 9 ‣ 4.4 The effect
    of different types of input data ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") is shown below,
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 图[9](#S4.F9 "Figure 9 ‣ 4.4 The effect of different types of input data ‣ 4
    Results ‣ Optimising Automatic Morphological Classification of Galaxies with Machine
    Learning and Deep Learning using Dark Energy Survey Imaging")中使用的准确率定义如下，
- en: '|  | $Accuracy=\frac{TP+TN}{TP+FP+TN+FN},$ |  | (5) |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  | $Accuracy=\frac{TP+TN}{TP+FP+TN+FN},$ |  | (5) |'
- en: such the meaning of this is defined as how many successfully classified samples
    there are out of all the samples tested. The comparison of the accuracy for the
    different datasets and the different methods is shown in Fig. [9](#S4.F9 "Figure
    9 ‣ 4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"). Through this figure we can observe the same
    situations as we have discussed in section [4.4](#S4.SS4 "4.4 The effect of different
    types of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    such that most methods have a better performance when using the HOG images as
    input, except for the KNN where the HOG image input slightly reduces the performance,
    and the LR+RBM, SVM+RBM, and RF+RBM methods which the HOG images input gives no
    apparent improvement in performance. We also make another comparison of efficiency
    between all methods (Table [3](#S4.T3 "Table 3 ‣ 4.5 Comparison between methods
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")). Most methods
    were run on the 2.3GHz Intel Core i5 Processor with 16GB 2133 MHz LPDDR3 memory
    except for the ‘CNN (GPU)’ which was run on the NVIDIA GeForce GTX 1080 Ti GPU.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着定义为在所有测试样本中成功分类的样本数量。不同数据集和不同方法的准确率比较如图[9](#S4.F9 "Figure 9 ‣ 4.4 The effect
    of different types of input data ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")所示。通过此图，我们可以观察到与我们在章节[4.4](#S4.SS4 "4.4 The effect of different
    types of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")讨论的相同情况，大多数方法在使用HOG图像作为输入时表现更好，除了KNN，其中HOG图像输入略微降低了性能，以及LR+RBM、SVM+RBM和RF+RBM方法，HOG图像输入对性能没有明显提升。我们还对所有方法的效率进行了另一项比较（表[3](#S4.T3
    "Table 3 ‣ 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。大多数方法在2.3GHz Intel Core i5处理器和16GB 2133 MHz LPDDR3内存上运行，除非是‘CNN
    (GPU)’，它在NVIDIA GeForce GTX 1080 Ti GPU上运行。
- en: Interestingly, the performance of RF wins the performance of MLPC with a faster
    computation time (Table [3](#S4.T3 "Table 3 ‣ 4.5 Comparison between methods ‣
    4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")) using raw
    images which was totally unexpected. The further investigation for the capability
    of the RF on imaging data will be very helpful considering both the computing
    speed and a high accuracy the RF can reach. On the other hand, we can see that
    KNN and MLPC need less computation time but can reach a relatively good accuracy
    compared to other methods. Therefore, KNN and MLPC can be a good option when using
    pixel input. Additionally, although the KNN method has lower accuracy than MLPC,
    it applies raw images input which saves the preprocessing time that generates
    the HOG images (or other types of scaling).
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 有趣的是，RF的性能在计算时间更快的情况下超越了MLPC（表[3](#S4.T3 "Table 3 ‣ 4.5 Comparison between methods
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")），使用原始图像的表现完全出乎意料。进一步研究RF在图像数据上的能力将对RF的计算速度和高精度非常有帮助。另一方面，我们可以看到KNN和MLPC需要较少的计算时间，但相对于其他方法可以达到相对较好的准确性。因此，KNN和MLPC在使用像素输入时是一个不错的选择。此外，尽管KNN方法的准确性低于MLPC，但它应用了原始图像输入，从而节省了生成HOG图像（或其他类型缩放）的预处理时间。
- en: The most successful methods when using pixel input in our study according to
    both the ROC curve (Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types
    of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"))
    and the comparison of accuracy (Fig. [9](#S4.F9 "Figure 9 ‣ 4.4 The effect of
    different types of input data ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")) between each method is certainly CNN. Both of these two
    figures indicate that the HOG image input helps the performance of CNN (Table [4](#S4.T4
    "Table 4 ‣ 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")).
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 根据ROC曲线（图 [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input
    data ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")）和每种方法的准确性比较（图 [9](#S4.F9
    "Figure 9 ‣ 4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")），我们研究中使用像素输入时最成功的方法无疑是CNN。这两个图都表明，HOG图像输入有助于CNN的表现（表 [4](#S4.T4
    "Table 4 ‣ 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。
- en: Additionally, we create a new way to utilise the third dimension in CNN when
    we combine the raw image (i) with the HOG images (ii) which together we call a
    ‘combination input (iii)’. This shows a slight but qualitatively great improvement
    when using the combination input (iii) to do training in CNN (see CNN plot in
    Fig. [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different types of input data ‣
    4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")). With the
    combination input (iii) and the balanced datasets, we can reach $\sim$0.95 accuracy
    with CNN using pixel input in this study (Table [4](#S4.T4 "Table 4 ‣ 4.5 Comparison
    between methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们创建了一种新方法来利用CNN中的第三维度，当我们将原始图像 (i) 与HOG图像 (ii) 结合时，我们称之为“组合输入 (iii)”。使用组合输入
    (iii) 进行CNN训练时显示出轻微但在定性上显著的改进（见图 [8](#S4.F8 "Figure 8 ‣ 4.4 The effect of different
    types of input data ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    中CNN图）。使用组合输入 (iii) 和均衡的数据集，我们可以在本研究中使用像素输入的CNN中达到 $\sim$0.95 的准确性（表 [4](#S4.T4
    "Table 4 ‣ 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）。
- en: On the other hand, Sreejith et al. ([2018](#bib.bib66)) proposes an ‘unanimous
    disagreement’ indicating an object that all the classifiers agree with each other
    but disagree with the visual classification. In our study, we found only 3 galaxies
    out of 1,000 galaxies show an unanimous disagreement when considering all classifiers.
    These galaxies are all labelled as Spirals by the Galaxy Zoo 1 classification
    (GZ1) but classified as Ellipticals by our classifiers. We also visually confirmed
    that these galaxies are indeed Ellipticals. This unanimous disagreement is more
    likely caused by the debias process applied in GZ1 to statistically adjust the
    population of galaxies at a higher redshift rather than a simple visual misclassification.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，Sreejith 等人 ([2018](#bib.bib66)) 提出了“普遍异议”的概念，指的是所有分类器一致同意某个对象，但与视觉分类结果不一致。在我们的研究中，我们发现从1,000个星系中仅有3个星系在考虑所有分类器时显示出普遍异议。这些星系在银河系动物园1（GZ1）分类中都被标记为螺旋星系，但在我们的分类器中被分类为椭圆星系。我们还通过视觉确认这些星系确实是椭圆星系。这种普遍异议更可能是由于GZ1中应用的去偏过程，以统计调整高红移星系的数量，而不是简单的视觉误分类。
- en: '| Methods | Training time | Testing time | accuracy |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 训练时间 | 测试时间 | 准确性 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| KNN | $\sim$ 0.2 sec | $\sim$45 sec | 0.782$\pm$0.027 (raw) |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| KNN | $\sim$ 0.2秒 | $\sim$45秒 | 0.782$\pm$0.027 (原始) |'
- en: '| KNN+RBM | $\sim$3000 sec | $\sim$45 sec | 0.830$\pm$0.007 (HOG) |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| KNN+RBM | $\sim$3000秒 | $\sim$45秒 | 0.830$\pm$0.007 (HOG) |'
- en: '| LR | $\sim$7-8 sec | $\leq$ 1 sec | 0.682$\pm$0.040 (HOG) |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| LR | $\sim$7-8秒 | $\leq$ 1秒 | 0.682$\pm$0.040 (HOG) |'
- en: '| LR+RBM | $\sim$3000 sec | $\leq$ 1 sec | 0.810$\pm$0.012 (HOG) |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| LR+RBM | $\sim$3000秒 | $\leq$ 1秒 | 0.810$\pm$0.012 (HOG) |'
- en: '| SVM | $\sim$800 sec | $\leq$ 8 sec | 0.764$\pm$0.029 (HOG) |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| SVM | $\sim$800秒 | $\leq$ 8秒 | 0.764$\pm$0.029 (HOG) |'
- en: '| SVM+RBM | $\sim$3000 sec | $\leq$ 8 sec | 0.762$\pm$0.001 (HOG) |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| SVM+RBM | $\sim$3000 秒 | $\leq$ 8 秒 | 0.762$\pm$0.001 (HOG) |'
- en: '| RF | $\leq$1 sec | $\leq$ 5 sec | 0.913$\pm$0.009 (raw) |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| RF | $\leq$1 秒 | $\leq$ 5 秒 | 0.913$\pm$0.009 (原始) |'
- en: '| RF+RBM | $\sim$3000 sec | $\leq$ 5 sec | 0.870$\pm$0.031 (raw) |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| RF+RBM | $\sim$3000 秒 | $\leq$ 5 秒 | 0.870$\pm$0.031 (原始) |'
- en: '| MLPC | $\sim$18 sec | $\leq$ 3 sec | 0.857$\pm$0.010 (HOG) |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| MLPC | $\sim$18 秒 | $\leq$ 3 秒 | 0.857$\pm$0.010 (HOG) |'
- en: '| CNN | $\sim$3000 sec | $\leq$ 5 sec | 0.951$\pm$0.005 (comb) |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| CNN | $\sim$3000 秒 | $\leq$ 5 秒 | 0.951$\pm$0.005 (组合) |'
- en: '| CNN (GPU) | $\sim$360 sec | $\leq$ 5 sec | 0.951$\pm$0.005 (comb) |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| CNN (GPU) | $\sim$360 秒 | $\leq$ 5 秒 | 0.951$\pm$0.005 (组合) |'
- en: 'Table 3: The comparison of the computing time (per $\sim$1000 galaxies) for
    each method. The ‘accuracy’ is the best accuracy shown in Fig. [9](#S4.F9 "Figure
    9 ‣ 4.4 The effect of different types of input data ‣ 4 Results ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"). The first ten methods were run on the 2.3GHz
    Intel Core i5 Processor with 16GB 2133 MHz LPDDR3 memory, while the sixth method
    ‘CNN (GPU) was run on the NVIDIA GeForce GTX 1080 Ti GPU.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '表 3: 各方法计算时间的比较（每 $\sim$1000 张银河系）。‘准确率’为图 [9](#S4.F9 "图 9 ‣ 4.4 不同输入数据类型的影响
    ‣ 4 结果 ‣ 使用暗能量巡天成像优化自动形态分类") 中显示的最佳准确率。前十种方法运行在 2.3GHz Intel Core i5 处理器和 16GB
    2133 MHz LPDDR3 内存上，而第六种方法 ‘CNN (GPU)’ 运行在 NVIDIA GeForce GTX 1080 Ti GPU 上。'
- en: '| Input Types | accuracy | $R_{01}$ |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| 输入类型 | 准确率 | $R_{01}$ |'
- en: '| --- | --- | --- |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| raw (i) | dataset 2: 0.924$\pm$0.013 | 0.933 |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 原始 (i) | 数据集 2: 0.924$\pm$0.013 | 0.933 |'
- en: '| dataset 4: 0.906$\pm$0.018 | 0.907 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 4: 0.906$\pm$0.018 | 0.907 |'
- en: '| HOG (ii) | dataset 2: 0.943$\pm$0.016 | 0.940 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| HOG (ii) | 数据集 2: 0.943$\pm$0.016 | 0.940 |'
- en: '| dataset 4: 0.940$\pm$0.003 | 0.940 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 4: 0.940$\pm$0.003 | 0.940 |'
- en: '| comb (iii) | dataset 2: 0.945$\pm$0.004 | 0.947 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 组合 (iii) | 数据集 2: 0.945$\pm$0.004 | 0.947 |'
- en: '| dataset 4: 0.951$\pm$0.005 | 0.953 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 4: 0.951$\pm$0.005 | 0.953 |'
- en: 'Table 4: The comparison between the different types of input in CNN when using
    the datasets 2 and 4 (Table [2](#S2.T2 "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")). The total number of testing
    images is 1,000 galaxies. The definition of the accuracy is according to Equation [5](#S4.E5
    "In 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging"). The value of $R_{01}$ is the recall value of Ellipticals
    and Spiral (Eqaution [4](#S4.E4 "In 4.1 The evaluation factors for models ‣ 4
    Results ‣ Optimising Automatic Morphological Classification of Galaxies with Machine
    Learning and Deep Learning using Dark Energy Survey Imaging")) after taking a
    weighted average, and the value of this is shown in the table as the three reruns
    average of $R_{01}$.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: CNN 在使用数据集 2 和 4 时不同输入类型的比较 (表 [2](#S2.T2 "表 2 ‣ 2.2 数据集 ‣ 2 数据集 ‣ 使用暗能量巡天成像优化自动形态分类"))。测试图像总数为
    1,000 张银河系。准确性的定义参见公式 [5](#S4.E5 "在 4.5 方法比较 ‣ 4 结果 ‣ 使用暗能量巡天成像优化自动形态分类")。$R_{01}$
    的值是对椭圆星系和螺旋星系的召回值 (公式 [4](#S4.E4 "在 4.1 模型评估因素 ‣ 4 结果 ‣ 使用暗能量巡天成像优化自动形态分类")) 经过加权平均后的结果，该值在表中显示为
    $R_{01}$ 的三次重复平均值。'
- en: 5 Further Discussion
  id: totrans-179
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 进一步讨论
- en: We have already discussed some of our results in Section [4](#S4 "4 Results
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging") while presenting the results.
    In the last section we concluded that the best method of these ten supervised
    machine learning methods is Convolutional Neural Networks (CNN), the further analysis
    and the discussion of CNN is essential for all future usage (Section [5.1](#S5.SS1
    "5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")), as well as the investigation of
    misclassification and galaxies with low predicted probabilities (Section [5.2](#S5.SS2
    "5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第[4](#S4 "4 结果 ‣ 使用暗能量调查成像的机器学习和深度学习优化星系的自动形态分类")节中已经讨论了部分结果。在最后一节中，我们得出结论认为这十种监督机器学习方法中最佳的是卷积神经网络（CNN），对CNN的进一步分析和讨论对未来的所有使用都至关重要（第[5.1](#S5.SS1
    "5.1 卷积神经网络（CNN）的分析 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像的机器学习和深度学习优化星系的自动形态分类")节），同时还需要调查误分类和预测概率较低的星系（第[5.2](#S5.SS2
    "5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像的机器学习和深度学习优化星系的自动形态分类")节）。
- en: 5.1 Analysis of Convolutional Neural Network (CNN)
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 卷积神经网络（CNN）的分析
- en: 'Here we discuss in more detail the results of our CNN machine learning classification.
    We use a default criterion for the classification in CNN such that the probability
    $(p)>0.5$ is the criterion for classification; namely, Ellipticals or Spirals
    with $p>0.5$ will be classified as that type. When we change the criterion to
    $p\geq 0.8$, namely, any types with $p\geq 0.8$ are classified as the predicted
    type, and if both types have $p<0.8$ then that galaxy will be classified as ‘Uncertain
    type’. With this criterion, we separate our testing data into three different
    classes: Ellipticals, Spirals, and Uncertain. Using the combination input (iii),
    the accuracy of classification increases to $\sim$0.97 (Table [5](#S5.T5 "Table
    5 ‣ 5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")).'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，我们更详细地讨论了CNN机器学习分类的结果。我们在CNN中的分类使用默认标准，即概率$(p)>0.5$作为分类标准；即，Ellipticals或Spirals的$p>0.5$将被分类为该类型。当我们将标准更改为$p\geq
    0.8$时，即任何类型的$p\geq 0.8$都会被分类为预测类型，如果两种类型的$p<0.8$，那么该星系将被分类为“类型不确定”。使用这一标准，我们将测试数据分为三种不同的类别：Ellipticals、Spirals和不确定。使用组合输入（iii），分类的准确率提高到$\sim$0.97（表[5](#S5.T5
    "表 5 ‣ 5.1 卷积神经网络（CNN）的分析 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像的机器学习和深度学习优化星系的自动形态分类")）。
- en: '|  | accuracy | $R_{01}$ | ${N}_{\text{classifiable}}$ | ${N}_{\text{uncetain}}$
    |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确率 | $R_{01}$ | ${N}_{\text{可分类}}$ | ${N}_{\text{不确定}}$ |'
- en: '| dataset 2 | 0.974$\pm$0.004 | 0.973 | 912 | 88 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 2 | 0.974$\pm$0.004 | 0.973 | 912 | 88 |'
- en: '| dataset 4 | 0.974$\pm$0.003 | 0.973 | 927 | 73 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 4 | 0.974$\pm$0.003 | 0.973 | 927 | 73 |'
- en: '| Maximum | 0.987$\pm$0.001 | 0.99 | 958 | 42 |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 0.987$\pm$0.001 | 0.99 | 958 | 42 |'
- en: 'Table 5: The average result of the classification success with the classification
    criterion $p>0.8$ through using CNN for dataset 2, dataset 4 (Table [2](#S2.T2
    "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")), and the result of the maximum available number of training
    data in our study with the combination input (iii) which includes both raw and
    HOG images. The total number of testing galaxies is 1,000\. The definition of
    accuracy (Equation [5](#S4.E5 "In 4.5 Comparison between methods ‣ 4 Results ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")) and the meaning of $R_{01}$
    are same as in Table [4](#S4.T4 "Table 4 ‣ 4.5 Comparison between methods ‣ 4
    Results ‣ Optimising Automatic Morphological Classification of Galaxies with Machine
    Learning and Deep Learning using Dark Energy Survey Imaging"). ${N}_{\text{classifiable}}$
    and ${N}_{\text{uncertain}}$ are the number of testing data which are classifiable
    (namely $p\geq 0.8$) and uncertain (probabilities of both types $(p)<0.8$), respectively.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 5：使用CNN对数据集2、数据集4（表格[2](#S2.T2 "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")）进行分类成功的平均结果，以及我们研究中使用组合输入（iii）的最大可用训练数据数量的结果，该输入包括原始图像和HOG图像。测试银河系的总数量为1,000。准确率的定义（方程[5](#S4.E5
    "In 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）和$R_{01}$的意义与表格[4](#S4.T4 "Table 4 ‣ 4.5 Comparison between
    methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中的相同。${N}_{\text{classifiable}}$和${N}_{\text{uncertain}}$分别是可以分类（即$p\geq
    0.8$）和不确定（两种类型的概率$(p)<0.8$）的测试数据的数量。
- en: 'Secondly, increasing the number of training samples should intuitively improve
    the performance; however, we investigate whether this assumption is correct. We
    increase the number of our training samples by the rotated images, and keep the
    balance between the number of both types of galaxies. The maximum balanced number
    of the training data in our study is 53,663 (S: 26,839; E: 26,824).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '其次，增加训练样本的数量应该直观地提高性能；然而，我们调查了这一假设是否正确。我们通过旋转图像来增加训练样本的数量，并保持两种类型的银河系数量之间的平衡。在我们的研究中，最大平衡的训练数据数量为53,663（S:
    26,839；E: 26,824）。'
- en: In Fig. [10](#S5.F10 "Figure 10 ‣ 5.1 Analysis of Convolutional Neural Network
    (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"),
    we observe that the increased rate of accuracy remains basically positive, but
    this decreases as the number of training data increases. This shows that there
    is likely a maximum accuracy limitation within the CNN method for galaxy classification.
    This indicates that our combination input (iii) has a better performance than
    the other two types of input data as we increase the number of training data,
    and the combination input (iii) is the only one which is able to reach over the
    accuracy of $\sim$0.97 without any condition.
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: 在图[10](#S5.F10 "Figure 10 ‣ 5.1 Analysis of Convolutional Neural Network (CNN)
    ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification of
    Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中，我们观察到准确率的增加率基本保持为正，但随着训练数据数量的增加而减少。这表明，CNN方法在银河系分类中的准确率可能存在一个最大限制。这表明，我们的组合输入（iii）在增加训练数据数量时表现优于其他两种输入数据类型，并且组合输入（iii）是唯一能够在没有任何条件下达到约0.97准确率的输入方式。
- en: Therefore, we apply our maximum number of training data (53,663) with the combination
    input (iii) to do the training, and combine it with the classification criterion
    $p=0.8$. We then obtain a high accuracy of $\sim$0.987 in the morphological classification
    of galaxies. The result is shown in the third row of Table [5](#S5.T5 "Table 5
    ‣ 5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging").
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们使用最大训练数据数量（53,663）和组合输入（iii）进行训练，并结合分类标准$p=0.8$。我们随后在银河系的形态分类中获得了约0.987的高准确率。结果显示在表格[5](#S5.T5
    "Table 5 ‣ 5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")的第三行。
- en: '![Refer to caption](img/ac20d3571925855fca82e881720b43b9.png)'
  id: totrans-191
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ac20d3571925855fca82e881720b43b9.png)'
- en: 'Figure 10: The accuracy versus the number of training data with different types
    of input. Different colours show different types of input such that cyan, orange,
    blue are for the raw images (i), the HOG images (ii), and the combination input
    (iii), respectively. The lighter colour areas show the scatters of the standard
    deviation calculated by the five reruns, and the lines inside shadings show the
    average of the five reruns. The two dotted horizontal lines indicate the accuracy
    of 0.95 and 0.97.'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：不同类型输入的训练数据量与准确率的关系。不同颜色表示不同类型的输入，其中青色、橙色、蓝色分别代表原始图像（i）、HOG图像（ii）和组合输入（iii）。较浅的颜色区域显示了通过五次重跑计算的标准偏差的散布，阴影中的线条表示五次重跑的平均值。两条虚线表示准确率为0.95和0.97。
- en: 5.2 Origin of Classification Failures
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 分类失败的来源
- en: As shown in the above section, we are able to reach a high classification accuracy
    of $\sim$0.987 by using CNN with the maximum number of the training data with
    a combination of input (iii), and the criterion of the probability $p\geq 0.8$.
    However, the $<100$ percent accuracy indicates that there are a few galaxies misclassified
    but with high predicted probabilities ($p\geq 0.8$). On the other hand, there
    are also a few galaxies ($\sim$42 out of 1,000 testing galaxies) which are non-classifiable
    (lower predicted probability $p<0.8$ in both Ellipticals and Spirals). Table [6](#S5.T6
    "Table 6 ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging") shows the fraction of the samples
    within a range of probability (out of 1,000 testing galaxies), and the number
    of misclassification out of the galaxies within a probability range. It indicates
    that the classifications with higher probabilities ($p\geq 0.8$) are much less
    often misclassified. However, it also shows that galaxies with the predicted probabilities
    between 0.7-0.8 have a higher misclassified rate than the predicted probabilities
    between 0.6-0.7\. This means that there are some galaxies with relatively higher
    predicted probabilities but which are misclassified by our CNN.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 如上节所示，通过使用CNN和最大数量的训练数据与组合输入（iii），以及概率标准为$p\geq 0.8$，我们能够达到约0.987的高分类准确率。然而，低于100%的准确率表明存在一些星系被错误分类，但具有较高的预测概率（$p\geq
    0.8$）。另一方面，也有一些星系（约1000个测试星系中的42个）是无法分类的（在椭圆星系和螺旋星系中，预测概率较低$p<0.8$）。表 [6](#S5.T6
    "表 6 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像的机器学习和深度学习优化自动形态分类")显示了在一定概率范围内的样本比例（从1000个测试星系中），以及在该概率范围内的错误分类数量。它表明，高概率（$p\geq
    0.8$）的分类错误发生得更少。然而，它也显示，预测概率在0.7-0.8之间的星系比预测概率在0.6-0.7之间的星系有更高的错误分类率。这意味着一些相对较高预测概率的星系被我们的CNN错误分类了。
- en: '| probability | sample fraction | misclassification |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| 概率 | 样本比例 | 错误分类 |'
- en: '| --- | --- | --- |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $p\geq 0.8$ | 0.958 | 0.0142 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| $p\geq 0.8$ | 0.958 | 0.0142 |'
- en: '| $0.7\leq p<0.8$ | 0.0184 | 0.239 |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| $0.7\leq p<0.8$ | 0.0184 | 0.239 |'
- en: '| $0.6\leq p<0.7$ | 0.0302 | 0.132 |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| $0.6\leq p<0.7$ | 0.0302 | 0.132 |'
- en: '| $0.5\leq p<0.6$ | 0.0114 | 0.368 |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| $0.5\leq p<0.6$ | 0.0114 | 0.368 |'
- en: 'Table 6: The fraction of the samples out of 1000 testing galaxies, and the
    fraction of misclassification within a certain probability range calculated by
    being divided by the sample number. The results are the average of five reruns.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 表 6：在1000个测试星系中样本的比例，以及在某一概率范围内的错误分类比例，这些比例是通过样本数量进行计算的。结果是五次重跑的平均值。
- en: In this section, we define two types of failures by our CNN. One is the misclassification
    with the comparison to the Galaxy Zoo 1 classification with high predicted probabilities
    ($p\geq 0.8$), that are galaxies which were classified with high probabilities
    with CNN but which later turned out to have a different classification in Galaxy
    Zoo. The other type of ‘failed’ classification are those galaxies with low predicted
    probabilities ($p<0.8$ in both types) of being either elliptical or spiral. We
    investigate the origin of these ‘failures’ in this section.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们通过我们的CNN定义了两种类型的失败。一种是与Galaxy Zoo 1分类相比的误分类，即那些被CNN高概率（$p\geq 0.8$）分类为银河的，但在Galaxy
    Zoo中实际分类不同的银河。另一种‘失败’分类是那些被预测概率较低（$p<0.8$）的椭圆星系或螺旋星系。我们在本节中探讨这些‘失败’的起源。
- en: '5.2.1 The failure with high probability: The misclassification of the classifiable
    galaxies'
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 高概率的失败：可分类银河的误分类
- en: 'We rerun five times the best combination of our method (i.e. the CNN trained
    by the maximum balanced number of training data and the combination input (iii),
    and classified by the criterion $p=0.8$), and we then collect all the misclassification
    of the classifiable galaxies from these five reruns together, obtaining 22 galaxies
    in total (Fig. [11](#S5.F11 "Figure 11 ‣ 5.2.1 The failure with high probability:
    The misclassification of the classifiable galaxies ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    Misclassification in this sense is that what we get from our CNN analysis differs
    from the Galaxy Zoo classification. Most of these 22 galaxies are repeatedly misclassified
    between these five reruns, in Fig. [11](#S5.F11 "Figure 11 ‣ 5.2.1 The failure
    with high probability: The misclassification of the classifiable galaxies ‣ 5.2
    Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"), objects 1-7 only show up once, objects 8-17
    are repeated more than twice, and objects 18-22 are repeatedly showing up in five
    reruns. There are two main probable reasons for these misclassifications with
    a high probability through our CNN method. One is that we use the galaxy images
    with linear scale (including HOG images) on our CNN training, so in some cases,
    even if it shows the feature of Spirals in logarithmic scale, it is just a point
    source, a round object, or a large bright area in linear scale. Therefore, they
    prefer to be classified as Ellipticals rather than Spirals in our CNN. This will
    be further discussed in the section [5.2.3](#S5.SS2.SSS3 "5.2.3 Combined with
    logarithmic scale images ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging").'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将我们方法的最佳组合（即由最大平衡训练数据数量和组合输入（iii）训练的CNN，并按标准$p=0.8$进行分类）运行五次，然后将这五次运行中的所有可分类银河的误分类结果汇总，总共获得22个银河（见图 [11](#S5.F11
    "图 11 ‣ 5.2.1 高概率的失败：可分类银河的误分类 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像优化自动形态分类的机器学习和深度学习")）。这里的误分类是指我们从CNN分析中得到的结果与Galaxy
    Zoo分类不同。这22个银河中，大多数在这五次运行中反复被误分类，在图 [11](#S5.F11 "图 11 ‣ 5.2.1 高概率的失败：可分类银河的误分类
    ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像优化自动形态分类的机器学习和深度学习")中，对象1-7仅出现一次，对象8-17出现超过两次，而对象18-22在五次运行中反复出现。这些高概率误分类有两个主要可能原因。其一是我们在CNN训练中使用了线性尺度的银河图像（包括HOG图像），因此在一些情况下，即使它在对数尺度上显示螺旋特征，在线性尺度上它只是一个点源、一个圆形物体或一个大亮区。因此，它们更倾向于被CNN分类为椭圆星系而不是螺旋星系。有关这一点的进一步讨论将在[5.2.3](#S5.SS2.SSS3
    "5.2.3 结合对数尺度图像 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像优化自动形态分类的机器学习和深度学习")节中进行。
- en: 'The other reason for the differences is due to misclassifications by the Galaxy
    Zoo 1 (GZ1). We apply visual classifications which have over 80$\%$ agreement
    between volunteer classifiers in the GZ1 catalogue in which we use to label our
    DES data. When we compare the SDSS imaging to the DES imaging, we can see some
    GZ1 classifications based on the SDSS data were simply wrong. Some examples are
    shown in Fig. [12](#S5.F12 "Figure 12 ‣ 5.2.1 The failure with high probability:
    The misclassification of the classifiable galaxies ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging").
    Most of them are revealed to be misclassifications due to the better resolution
    and deeper depth of the DES data than the SDSS data. With higher resolution of
    the DES data, we reveal more detailed structure than the SDSS data (e.g the number
    4 and 8 in Fig. [12](#S5.F12 "Figure 12 ‣ 5.2.1 The failure with high probability:
    The misclassification of the classifiable galaxies ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    which show clear spiral structures in the DES data but nothing in the SDSS data).
    We will further discuss this in Section [5.2.4](#S5.SS2.SSS4 "5.2.4 The advantage
    of Dark Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging").'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 差异的另一个原因是由于Galaxy Zoo 1 (GZ1)的误分类。我们应用了视觉分类，这些分类在GZ1目录中的志愿者分类者之间有超过80$\%$的一致性，我们用来标记我们的DES数据。当我们将SDSS成像与DES成像进行比较时，可以看到一些基于SDSS数据的GZ1分类明显是错误的。图[12](#S5.F12
    "图12 ‣ 5.2.1 高概率下的失败：可分类星系的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 通过机器学习和深度学习优化星系的自动形态分类")中展示了一些例子。大多数误分类是由于DES数据比SDSS数据具有更高的分辨率和更深的深度。通过DES数据的更高分辨率，我们揭示了比SDSS数据更多的详细结构（例如图[12](#S5.F12
    "图12 ‣ 5.2.1 高概率下的失败：可分类星系的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 通过机器学习和深度学习优化星系的自动形态分类")中显示的编号4和8在DES数据中显示了清晰的螺旋结构，而在SDSS数据中什么也没有）。我们将在第[5.2.4](#S5.SS2.SSS4
    "5.2.4 暗能量图像的优势和Galaxy Zoo项目的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 通过机器学习和深度学习优化星系的自动形态分类")节进一步讨论这一点。
- en: 'On the other hand, we also discover that some galaxies with large, bright,
    and oval structure are easy to misclassify using our method. These galaxies are
    lenticular galaxies when examined on the DES imaging. The main reason for their
    misclassifications is because there is not a class for lenticular galaxies in
    the Galaxy Zoo project. Lenticular galaxy is difficult to see by visual classification
    and typically requires high resolution and deep imaging, even for nearby galaxies.
    Some of them are therefore classified as Spirals, and some of them are recognised
    as Ellipticals in the GZ1 catalogue. The details will be discussed in the next
    section (Section [5.2.2](#S5.SS2.SSS2 "5.2.2 The failures at low probability:
    Uncertain type ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")) as most of these galaxies
    generally have lower predicted probabilities of being either elliptical or spiral.'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，我们还发现一些结构庞大、明亮且呈椭圆形的星系在使用我们的方法时容易被误分类。这些星系在DES成像中被认为是透镜状星系。其误分类的主要原因是Galaxy
    Zoo项目中没有透镜状星系的类别。透镜状星系通过视觉分类很难观察，通常需要高分辨率和深度成像，即使是对附近的星系也是如此。因此，一些星系被归类为螺旋星系，一些则在GZ1目录中被识别为椭圆星系。具体细节将在下一节（第[5.2.2](#S5.SS2.SSS2
    "5.2.2 低概率下的失败：不确定类型 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 通过机器学习和深度学习优化星系的自动形态分类")节）中讨论，因为这些星系通常被预测为椭圆星系或螺旋星系的概率较低。
- en: '![Refer to caption](img/1b9be621a3b1ec288de9c231eda9d33c.png)'
  id: totrans-207
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1b9be621a3b1ec288de9c231eda9d33c.png)'
- en: 'Figure 11: The misclassified galaxies with high probabilities ($p\geq 0.8$)
    comparing the classification of Galaxy Zoo 1 and our CNN. On the top of the images
    shows the probabilities of being Ellipticals, E(0) and Spirals, S(1) by our CNN.
    The line below the image shows the ID number of the galaxies in Dark Energy Survey
    (DES), and the second row shows the classifications by Galaxy Zoo and our CNN.'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：与Galaxy Zoo 1和我们的CNN分类比较的高概率误分类星系（$p\geq 0.8$）。图像上方显示了我们的CNN对椭圆星系E(0)和螺旋星系S(1)的概率。图像下方的线显示了Dark
    Energy Survey (DES)中的星系ID号码，第二行显示了Galaxy Zoo和我们CNN的分类。
- en: '![Refer to caption](img/7f758ccc9ad5417d670ca5afed24ba9a.png)'
  id: totrans-209
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7f758ccc9ad5417d670ca5afed24ba9a.png)'
- en: 'Figure 12: Examples of the incorrect label from GZ1 with SDSS imaging. The
    figures under each number show the galaxy images of DES and SDSS, and their ID
    numbers. The label of ‘CNN’ shows the predicted label from our method, and which
    of ’GZ’ shows the label from the Galaxy Zoo 1 catalogue.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：GZ1中标记错误的例子，使用了SDSS成像。每个数字下的图示展示了DES和SDSS的星系图像及其ID号码。‘CNN’的标签显示了我们方法的预测标签，而‘GZ’则显示了Galaxy
    Zoo 1目录中的标签。
- en: '5.2.2 The failures at low probability: Uncertain type'
  id: totrans-211
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.2 低概率的失败：不确定类型
- en: 'In this section, we investigate the galaxies with lower predicted probabilities
    ($p<0.8$) for classification as either elliptical or spiral in the five reruns
    of our best method. The majority of the samples with lower probabilities are repeated
    between five reruns, and some of them also show up in the previous section (Section [5.2.1](#S5.SS2.SSS1
    "5.2.1 The failure with high probability: The misclassification of the classifiable
    galaxies ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")) which are misclassified but with
    high probabilities. The probabilities of these galaxies vary significantly between
    each rerun.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们研究了在我们最佳方法的五次重跑中被预测为椭圆形或螺旋形的星系的低概率（$p<0.8$）。大多数低概率样本在五次重跑中被重复，一些样本也出现在上一节（第[5.2.1](#S5.SS2.SSS1
    "5.2.1 The failure with high probability: The misclassification of the classifiable
    galaxies ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")节），这些星系被误分类但具有高概率。这些星系的概率在每次重跑中变化显著。'
- en: 'The appearance of these galaxies can be separated into two types. One type
    are the galaxies which look large, oval, and bright (Top 1-12 in Fig. [13](#S5.F13
    "Figure 13 ‣ 5.2.2 The failures at low probability: Uncertain type ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")), and the other type are those which do not appear this
    way, e.g. galaxies which are relatively fainter or with large bulge and spiral
    structure at the same time, or the target galaxy is shifted significantly away
    from the centre of the image (Bottom 1-12 in Fig. [13](#S5.F13 "Figure 13 ‣ 5.2.2
    The failures at low probability: Uncertain type ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '这些星系的外观可以分为两种类型。一种是看起来大、椭圆且明亮的星系（图[13](#S5.F13 "Figure 13 ‣ 5.2.2 The failures
    at low probability: Uncertain type ‣ 5.2 Origin of Classification Failures ‣ 5
    Further Discussion ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中的Top
    1-12），另一种则不是这种外观，例如相对较暗的星系或同时具有大凸起和螺旋结构的星系，或者目标星系显著偏离图像中心（图[13](#S5.F13 "Figure
    13 ‣ 5.2.2 The failures at low probability: Uncertain type ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")中的Bottom
    1-12）。'
- en: 'The galaxies with large and oval structure are lenticular galaxies which we
    discussed in the previous section (Section [5.2.1](#S5.SS2.SSS1 "5.2.1 The failure
    with high probability: The misclassification of the classifiable galaxies ‣ 5.2
    Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging")). As discussed there is not a lenticular galaxy
    class in the GZ project, nor can these types be easily seen in SDSS data, therefore,
    the classification of these galaxies in the GZ1 catalogue are such that half of
    them are classified as Spirals, and half of them are classified as Ellipticals.
    Because lentinculars are neither spirals or ellipticals, their structure confuses
    our CNN such that it gives lower probabilities for these galaxies to be of either
    type. This is a ’rediscovery’ of lenticulars, and shows the power of machine learning
    for discovering new types of galaxies, as we did not expect this to occur.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 大而椭圆形结构的星系是我们在前一节（[5.2.1节](#S5.SS2.SSS1 "5.2.1 高概率失败：可分类星系的误分类 ‣ 5.2 分类失败的来源
    ‣ 5 进一步讨论 ‣ 利用暗能量测量影像优化自动形态分类的星系")）中讨论过的透镜状星系。正如讨论中所述，GZ项目中没有透镜状星系分类，也不容易在SDSS数据中看到这些类型，因此，GZ1目录中的这些星系被分类为螺旋星系和椭圆星系各一半。由于透镜状星系既不是螺旋星系也不是椭圆星系，它们的结构使我们的CNN混淆，从而使这些星系被归为任何类型的概率降低。这是对透镜状星系的‘重新发现’，展示了机器学习在发现新类型星系方面的强大能力，我们没有预料到这一点。
- en: '![Refer to caption](img/406a073b1e38563c82715c325e4b8664.png)'
  id: totrans-215
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/406a073b1e38563c82715c325e4b8664.png)'
- en: 'Figure 13: Examples of the galaxies with low probabilities of classification
    as either spiral or elliptical. Top 1-12: these objects are turned out to be lenticular
    galaxies (S0) in cluster inspection. Bottom 1-12: the other types of galaxies.'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 图13：低概率被分类为螺旋星系或椭圆星系的星系示例。上方1-12：这些对象在集群检查中被发现是透镜状星系（S0）。下方1-12：其他类型的星系。
- en: 5.2.3 Combined with logarithmic scale images
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.3 结合对数尺度图像
- en: 'According to the discussion in the section [5.2.1](#S5.SS2.SSS1 "5.2.1 The
    failure with high probability: The misclassification of the classifiable galaxies
    ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"), we investigate the impact on our classification
    with CNN when using images with logarithmic scale (hereafter, log images) to train
    our CNN algorithm by using the datasets 2 and 4 (Table [2](#S2.T2 "Table 2 ‣ 2.2
    The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")).
    In addition to the log images, we also combine the log images with our combination
    input (iii) as the input to train our CNN. The comparison of the results are shown
    in Table [7](#S5.T7 "Table 7 ‣ 5.2.3 Combined with logarithmic scale images ‣
    5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging").'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[5.2.1节](#S5.SS2.SSS1 "5.2.1 高概率失败：可分类星系的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 利用暗能量测量影像优化自动形态分类的星系")的讨论，我们调查了在使用对数尺度图像（以下简称，log图像）训练CNN算法时对分类的影响，使用的数据集是2和4（表[2](#S2.T2
    "表2 ‣ 2.2 数据集 ‣ 2 数据集 ‣ 利用暗能量测量影像优化自动形态分类的星系")）。除了log图像，我们还将log图像与我们的组合输入(iii)结合作为训练CNN的输入。结果的比较见于表[7](#S5.T7
    "表7 ‣ 5.2.3 结合对数尺度图像 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 利用暗能量测量影像优化自动形态分类的星系")。
- en: Comparing Table [7](#S5.T7 "Table 7 ‣ 5.2.3 Combined with logarithmic scale
    images ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging") with Table [4](#S4.T4 "Table 4 ‣ 4.5
    Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    shows a significant improvement when using the log images, and the combination
    of the log images and our combination input (iii) shows a better accuracy than
    just using the log images as input.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 比较表格 [7](#S5.T7 "Table 7 ‣ 5.2.3 Combined with logarithmic scale images ‣ 5.2
    Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") 和表格 [4](#S4.T4 "Table 4 ‣ 4.5 Comparison between
    methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging") 显示使用对数图像时有显著的改进，而对数图像与我们的组合输入
    (iii) 的结合显示比仅使用对数图像作为输入具有更好的准确性。
- en: However, comparing Table [7](#S5.T7 "Table 7 ‣ 5.2.3 Combined with logarithmic
    scale images ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging") with Table [5](#S5.T5 "Table
    5 ‣ 5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging") shows that there are not
    significant differences in the performance from log images input to the other
    three types of input, (i), (ii), (iii), when we train our CNN through the maximum
    available number of the training data. This means that there is an intrinsic limitation
    of our method. This limitation can also be seen in Fig. [10](#S5.F10 "Figure 10
    ‣ 5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion ‣
    Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging") in Section [5.1](#S5.SS1
    "5.1 Analysis of Convolutional Neural Network (CNN) ‣ 5 Further Discussion ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging").
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，比较表格 [7](#S5.T7 "Table 7 ‣ 5.2.3 Combined with logarithmic scale images ‣
    5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") 和表格 [5](#S5.T5 "Table 5 ‣ 5.1 Analysis of Convolutional
    Neural Network (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") 显示，从对数图像输入到其他三种输入 (i)、(ii)、(iii) 的性能差异不显著，当我们通过最大可用的训练数据来训练我们的
    CNN 时。这意味着我们的方法存在固有的限制。这种限制在图 [10](#S5.F10 "Figure 10 ‣ 5.1 Analysis of Convolutional
    Neural Network (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") 和第 [5.1](#S5.SS1 "5.1 Analysis of Convolutional Neural
    Network (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    节中也可以看到。
- en: Therefore, we conclude that although adding the log images as input helps the
    performance, it still has no apparent difference from our result when we apply
    the maximum number of training data to our CNN.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，我们得出结论，尽管将对数图像作为输入有助于性能，但当我们将最大数量的训练数据应用于我们的 CNN 时，它与我们的结果没有明显的差异。
- en: '|  |  |  | comb. input(iii) |  |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 组合输入 (iii) |  |'
- en: '|  | log image |  | +log image |  |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '|  | 对数图像 |  | +对数图像 |  |'
- en: '|  | accuracy | $R_{01}$ | accuracy | $R_{01}$ |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确性 | $R_{01}$ | 准确性 | $R_{01}$ |'
- en: '| dataset 2 | 0.950$\pm$0.006 | 0.947 | 0.952$\pm$0.006 | 0.950 |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 2 | 0.950$\pm$0.006 | 0.947 | 0.952$\pm$0.006 | 0.950 |'
- en: '| dataset 4 | 0.954$\pm$0.004 | 0.953 | 0.964$\pm$0.007 | 0.967 |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 4 | 0.954$\pm$0.004 | 0.953 | 0.964$\pm$0.007 | 0.967 |'
- en: '| Maximum | 0.973$\pm$0.002 | 0.970 | 0.971$\pm$0.005 | 0.973 |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 | 0.973$\pm$0.002 | 0.970 | 0.971$\pm$0.005 | 0.973 |'
- en: '| Max ($p=0.8$) | 0.987$\pm$0.004 | 0.987 | 0.987$\pm$0.003 | 0.987 |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| 最大值 ($p=0.8$) | 0.987$\pm$0.004 | 0.987 | 0.987$\pm$0.003 | 0.987 |'
- en: 'Table 7: The comparison of the accuracy (Equation [5](#S4.E5 "In 4.5 Comparison
    between methods ‣ 4 Results ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"))
    and the recalls (Same as Table [4](#S4.T4 "Table 4 ‣ 4.5 Comparison between methods
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")) between
    the inputs of the log images and the combination of log images and combination
    input (iii) by using the dataset 2, dataset 4 (Table [2](#S2.T2 "Table 2 ‣ 2.2
    The datasets ‣ 2 Data Sets ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")),
    and the maximum number of training data.'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 表7：使用数据集2、数据集4（表[2](#S2.T2 "Table 2 ‣ 2.2 The datasets ‣ 2 Data Sets ‣ Optimising
    Automatic Morphological Classification of Galaxies with Machine Learning and Deep
    Learning using Dark Energy Survey Imaging")）和最大训练数据量对log图像输入与log图像和组合输入（iii）的准确率（方程[5](#S4.E5
    "In 4.5 Comparison between methods ‣ 4 Results ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")）和召回率（同表[4](#S4.T4 "Table 4 ‣ 4.5 Comparison between methods
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")）的比较。
- en: 5.2.4 The advantage of Dark Energy images and the misclassifications by Galaxy
    Zoo project
  id: totrans-230
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.4 黑暗能量图像的优势与Galaxy Zoo项目的误分类
- en: We have discussed the incorrect labels by Galaxy Zoo in previous sections. As
    discussed, the main reason to reveal the misclassification by SDSS imaging Galaxy
    Zoo is because of the better resolution (${0.}^{\prime\prime}263$ per pixel) and
    deeper depth of DES data ($i=22.51$) (Abbott et al., [2018](#bib.bib1)).
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在前面的部分讨论了Galaxy Zoo的错误标签。如讨论所示，揭示SDSS成像Galaxy Zoo误分类的主要原因是因为DES数据具有更好的分辨率（${0.}^{\prime\prime}263$每像素）和更深的深度（$i=22.51$）（Abbott等，[2018](#bib.bib1)）。
- en: 'These wrong labels not only influence the results of our CNN, but also contaminate
    the training set. Therefore, we remove the potential misclassified galaxies from
    the training set. We purify our training set by excluding the suspected misclassified
    galaxies then use the criteria shown in Table [8](#S5.T8 "Table 8 ‣ 5.2.4 The
    advantage of Dark Energy images and the misclassifications by Galaxy Zoo project
    ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") to confirm or dismiss our suspected misclassifications.
    We then rerun our CNN classification five times on each new training set and obtain
    five new CNN models on the new classifications. After carrying out this purification
    twice, and then retraining and updating our list of suspects, we obtain two lists
    of these galaxies: one is the confirmed misclassified galaxies by the Galaxy Zoo,
    and the other are the suspected misclassified galaxies.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 这些错误标签不仅影响我们CNN的结果，还污染了训练集。因此，我们从训练集中移除潜在的误分类星系。我们通过排除可疑的误分类星系来净化训练集，然后使用表[8](#S5.T8
    "Table 8 ‣ 5.2.4 The advantage of Dark Energy images and the misclassifications
    by Galaxy Zoo project ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")中所示的标准来确认或排除我们的可疑误分类。然后我们在每个新的训练集上重新运行CNN分类五次，并获得五个新的CNN模型。经过两次这种净化过程，然后重新训练并更新我们的可疑名单，我们得到两个星系列表：一个是Galaxy
    Zoo确认的误分类星系，另一个是可疑的误分类星系。
- en: 'The images of these systems are shown in Fig. [14](#S5.F14 "Figure 14 ‣ 5.2.4
    The advantage of Dark Energy images and the misclassifications by Galaxy Zoo project
    ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") and Fig. [15](#S5.F15 "Figure 15 ‣ 5.2.4 The
    advantage of Dark Energy images and the misclassifications by Galaxy Zoo project
    ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging"). There are $\sim 2.5\%$ misclassified galaxies
    in the Galaxy Zoo 1 catalogue out of  2,800 in our study as revealed by using
    DES images and our CNN, and $\sim 0.56\%$ are suspected candidates in our study.
    We then correct our training set according to these two lists. We change the label
    of the confirmed misclassified galaxies, and exclude the suspected misclassified
    galaxies from the training set, then do the training with the maximum available
    number which is 53,141 galaxies in total (E: 26,344; S: 26,797). We then change
    the label of the confirmed misclassified galaxies in the testing set as well.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '这些系统的图像见图 [14](#S5.F14 "图 14 ‣ 5.2.4 黑暗能量图像的优势和 Galaxy Zoo 项目的误分类 ‣ 5.2 分类失败的起源
    ‣ 5 进一步讨论 ‣ 使用黑暗能量调查成像优化星系的自动形态分类") 和图 [15](#S5.F15 "图 15 ‣ 5.2.4 黑暗能量图像的优势和 Galaxy
    Zoo 项目的误分类 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用黑暗能量调查成像优化星系的自动形态分类")。通过使用 DES 图像和我们的 CNN，我们发现
    Galaxy Zoo 1 目录中有$\sim 2.5\%$的星系被误分类，在我们的研究中$\sim 0.56\%$是疑似候选星系。然后我们根据这两个列表修正我们的训练集。我们更改确认误分类星系的标签，并将疑似误分类的星系从训练集中排除，然后使用最大可用数量（总共
    53,141 个星系（E: 26,344；S: 26,797））进行训练。然后我们也更改了测试集中确认误分类星系的标签。'
- en: '|  | Criteria: |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '|  | 标准： |'
- en: '| --- | --- |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Confirmed | (1) Appearing $\geq 4$ times in total failures. |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| 确认 | (1) 总失败次数中出现次数$\geq 4$。 |'
- en: '|  | (2) Appearing at least once in the high-p failures. |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '|  | (2) 在高失败率中至少出现一次。 |'
- en: '| Suspected | (1) Appearing $\geq 2$ but $\leq 4$ times in total failures.
    |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 疑似 | (1) 总失败次数中出现次数$\geq 2$且$\leq 4$。 |'
- en: '|  | (2) Does not satisfy the criteria for ‘confirmed’. |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '|  | (2) 不满足“确认”的标准。 |'
- en: '| Not misclassified | (1) Appearing $\leq$ 1 time in the test of new models
    |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| 未误分类 | (1) 在新模型测试中出现次数$\leq$ 1次 |'
- en: 'Table 8: The criteria for selecting the suspected misclassified galaxies by
    the Galaxy Zoo project and purifying the training set.'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 表 8：Galaxy Zoo 项目选择疑似误分类星系的标准及净化训练集的方法。
- en: 'Figure 14: The confirmed list of the misclassified galaxies in the Galaxy Zoo
    1 catalogue. The first row underneath the images is the ID numbers of galaxies,
    and the second row shows the classification by Galaxy Zoo (GZ) and our CNN (CNN).'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：Galaxy Zoo 1 目录中确认的误分类星系列表。图像下方的第一行是星系的 ID 号码，第二行显示了 Galaxy Zoo (GZ) 和我们的
    CNN (CNN) 的分类结果。
- en: '![Refer to caption](img/46d92faf3b21315b39e54f9c02c8de3c.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/46d92faf3b21315b39e54f9c02c8de3c.png)'
- en: 'Figure 15: The suspected list of the misclassified galaxies in the Galaxy Zoo
    1 catalogue. The first row underneath the images is the ID numbers of galaxies,
    and the second row shows the classification by Galaxy Zoo (GZ) and our CNN (CNN).'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15：Galaxy Zoo 1 目录中被误分类的星系的疑似列表。图像下方的第一行是星系的 ID 号码，第二行显示了 Galaxy Zoo (GZ)
    和我们的 CNN (CNN) 的分类结果。
- en: The results are shown in Table [9](#S5.T9 "Table 9 ‣ 5.2.4 The advantage of
    Dark Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging"). The first row of Table [9](#S5.T9 "Table 9 ‣ 5.2.4 The
    advantage of Dark Energy images and the misclassifications by Galaxy Zoo project
    ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic
    Morphological Classification of Galaxies with Machine Learning and Deep Learning
    using Dark Energy Survey Imaging") is the testing result excluding 8 suspected
    misclassified galaxies out of 1,000 testing galaxies. Compared this result with
    the results in Table [5](#S5.T5 "Table 5 ‣ 5.1 Analysis of Convolutional Neural
    Network (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging"),
    our new models predict the highest accuracy, and end up having a resulting fewer
    number of uncertain type (about half the original number) than the previous results.
    Therefore, Fig. [16](#S5.F16 "Figure 16 ‣ 5.2.4 The advantage of Dark Energy images
    and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin of Classification
    Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")
    shows the best testing result in our study. In this result, we change the label
    of the confirmed misclassified galaxies and exclude the suspected misclassified
    galaxies in testing set. We obtain the accuracy of 0.994 for the best model within
    five reruns, and the average accuracy of five reruns is 0.991.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 结果显示在表[9](#S5.T9 "表 9 ‣ 5.2.4 暗能量图像的优势及银河动物园项目的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣
    使用暗能量测量成像的机器学习和深度学习优化星系的自动形态分类")中。表[9](#S5.T9 "表 9 ‣ 5.2.4 暗能量图像的优势及银河动物园项目的误分类
    ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 使用暗能量测量成像的机器学习和深度学习优化星系的自动形态分类")的第一行是排除1000个测试星系中8个疑似误分类星系后的测试结果。将此结果与表[5](#S5.T5
    "表 5 ‣ 5.1 卷积神经网络 (CNN) 的分析 ‣ 5 进一步讨论 ‣ 使用暗能量测量成像的机器学习和深度学习优化星系的自动形态分类")中的结果进行比较，我们的新模型预测了最高的准确性，并且结果中不确定类型的数量比之前的结果少（大约是原来数量的一半）。因此，图[16](#S5.F16
    "图 16 ‣ 5.2.4 暗能量图像的优势及银河动物园项目的误分类 ‣ 5.2 分类失败的来源 ‣ 5 进一步讨论 ‣ 使用暗能量测量成像的机器学习和深度学习优化星系的自动形态分类")展示了我们研究中的最佳测试结果。在此结果中，我们更改了确认的误分类星系的标签，并在测试集中排除了疑似误分类星系。我们获得了最佳模型在五次重复运行中的准确率为0.994，五次重复运行的平均准确率为0.991。
- en: The second and third rows of Table [9](#S5.T9 "Table 9 ‣ 5.2.4 The advantage
    of Dark Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") show the results including suspected galaxies which retain
    the initial label from the Galaxy Zoo in test and change the label of them to
    the opposite label, respectively. We have lower accuracy in these two conditions
    than the result of the first row. This indicates that part of our suspected galaxies
    have incorrect labels in Galaxy Zoo catalogue, and part of them are not, based
    on our CNN. Some examples of the successful classifications by the purified CNN
    training are shown in Fig. [17](#S5.F17 "Figure 17 ‣ 5.2.4 The advantage of Dark
    Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin of
    Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging") and Fig. [18](#S5.F18 "Figure 18 ‣ 5.2.4 The advantage
    of Dark Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging").
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [9](#S5.T9 "表 9 ‣ 5.2.4 暗能量图像的优势及Galaxy Zoo项目的分类错误 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论
    ‣ 使用暗能量调查成像优化自动形态分类") 的第二行和第三行分别显示了包括怀疑星系的测试结果，其中怀疑星系保留了Galaxy Zoo的初始标签，以及将这些星系标签更改为对立标签的结果。在这两种情况下的准确度低于第一行的结果。这表明我们怀疑的部分星系在Galaxy
    Zoo目录中有错误标签，而另一部分则没有，根据我们的CNN。净化CNN训练成功分类的一些示例显示在图 [17](#S5.F17 "图 17 ‣ 5.2.4
    暗能量图像的优势及Galaxy Zoo项目的分类错误 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像优化自动形态分类") 和图 [18](#S5.F18
    "图 18 ‣ 5.2.4 暗能量图像的优势及Galaxy Zoo项目的分类错误 ‣ 5.2 分类失败的起源 ‣ 5 进一步讨论 ‣ 使用暗能量调查成像优化自动形态分类")
    中。
- en: '|  | accuracy | $R_{01}$ | ${N}_{\text{classifiable}}$ | ${N}_{\text{uncetain}}$
    |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '|  | 准确度 | $R_{01}$ | ${N}_{\text{classifiable}}$ | ${N}_{\text{uncertain}}$
    |'
- en: '| No suspects | 0.991$\pm$0.003 | 0.990 | 976 | 16 |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '| 无嫌疑的 | 0.991$\pm$0.003 | 0.990 | 976 | 16 |'
- en: '| with suspects | 0.989$\pm$0.001 | 0.990 | 981 | 19 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| 有嫌疑的 | 0.989$\pm$0.001 | 0.990 | 981 | 19 |'
- en: '| label changed | 0.987$\pm$0.003 | 0.986 | 981 | 19 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '| 标签更改 | 0.987$\pm$0.003 | 0.986 | 981 | 19 |'
- en: 'Table 9: The testing result after using the purified training set. The meaning
    of each column are same as Table [5](#S5.T5 "Table 5 ‣ 5.1 Analysis of Convolutional
    Neural Network (CNN) ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging"). There are 8 suspected misclassified galaxies out of 1,000
    testing galaxies. The first row is the testing result excluding suspected galaxies.
    The second row shows the result with the suspected galaxies which retain their
    initial labels from the Galaxy Zoo catalogue. The third row is the result with
    the suspected galaxies but their initial labels changed – for instance, the label
    changes to Elliptical if the initial label was Spiral.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 表 9：使用净化训练集后的测试结果。每列的意义与表 [5](#S5.T5 "表 5 ‣ 5.1 卷积神经网络 (CNN) 分析 ‣ 5 进一步讨论 ‣
    使用暗能量调查成像优化自动形态分类") 相同。在1,000个测试星系中，有8个被怀疑分类错误。第一行是排除怀疑星系的测试结果。第二行显示了包括怀疑星系的结果，这些星系保留了来自Galaxy
    Zoo目录的初始标签。第三行是包括怀疑星系的结果，但它们的初始标签发生了变化——例如，如果初始标签是螺旋星系，则标签更改为椭圆星系。
- en: '![Refer to caption](img/f6b5cbee193be4b558f02978f2d1ba5d.png)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f6b5cbee193be4b558f02978f2d1ba5d.png)'
- en: 'Figure 16: The best testing result which we changed the label of the confirmed
    misclassified galaxies and excluded the suspected misclassified galaxies in both
    training and testing set. Top: Confusion matrix. The ‘0’ means Ellipticals and
    ‘1’ represents Spirals. The colour bar shows the fraction of each true label (Galaxy
    Zoo), and the number shows the corresponding number of the fraction. Bottom: The
    ROC curve of this testing result.'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 图 16：我们更改了确认的误分类星系的标签，并排除了训练和测试集中的疑似误分类星系，从而获得的最佳测试结果。顶部：混淆矩阵。“0”表示椭圆星系，“1”表示螺旋星系。颜色条显示每个真实标签（Galaxy
    Zoo）的比例，数字显示对应的比例数量。底部：该测试结果的ROC曲线。
- en: '![Refer to caption](img/863bdf6df770a55fc203143a3c931594.png)'
  id: totrans-254
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/863bdf6df770a55fc203143a3c931594.png)'
- en: 'Figure 17: Successful examples of classified Ellipticals. The ‘prob’ on the
    top of the images show the predicted probability of being Ellipticals.'
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：分类椭圆星系的成功示例。图像顶部的“prob”显示了被分类为椭圆星系的预测概率。
- en: '![Refer to caption](img/f4bff6af943db2ae4f133886fb69f878.png)'
  id: totrans-256
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/f4bff6af943db2ae4f133886fb69f878.png)'
- en: 'Figure 18: Successful examples of the classified Spirals. The ‘prob’ on the
    top of the images show the predicted probability of being Spirals.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18：分类螺旋星系的成功示例。图像顶部的“prob”显示了被分类为螺旋星系的预测概率。
- en: 6 Conclusions
  id: totrans-258
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this study, we have examined ten supervised machine learning methods to determine
    the most successful method for classifying galaxies into ellipticals and spirals
    using only pixel input on a single band ($i$-band). As part of the investigation,
    we have also tested how using rotated images with various angles of rotation with
    10 degrees increments to augment our data influences on our classification. In
    addition, we also confirmed that the balance between the number ratio of each
    type is rather important when using pixel input in machine learning.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 在本研究中，我们考察了十种监督学习方法，以确定最成功的将星系分类为椭圆星系和螺旋星系的方法，仅使用单一波段（$i$-波段）的像素输入。作为调查的一部分，我们还测试了如何使用旋转角度为10度增量的旋转图像来扩充数据对分类的影响。此外，我们还确认，当使用像素输入进行机器学习时，各类型之间的数量比例平衡相当重要。
- en: We show that the machine learning algorithms, Logistic Regression (LR) and Support
    Vector Machine (SVM) improve the performance of machine learning when combining
    with neural networks features, such as Restricted Boltzmann Machine (RBM). However,
    we find that using the image input along with the the Histogram of Oriented Gradient
    (HOG image) helps the performance in most methods, except for k-Nearest Neighbour
    (KNN). We also observe that the application of HOG images gives less help when
    combining with a neural network (e.g. LR+RBM, SVM+RBM, RF+RBM) because the RBM
    interlinks the HOG image features which have less information than the raw images.
    However, increasing the number of hidden layers and neurons qualitatively helps
    the connection between the HOG image features according to the performance of
    Multi-Layer Perceptron Classifier (MLPC) and Convolutional Neural Networks (CNN).
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了机器学习算法逻辑回归（LR）和支持向量机（SVM）在结合神经网络特征（如限制玻尔兹曼机（RBM））时能提高机器学习性能。然而，我们发现使用图像输入和方向梯度直方图（HOG
    图像）可以在大多数方法中提高性能，但k-最近邻（KNN）除外。我们还观察到，当与神经网络结合（如LR+RBM、SVM+RBM、RF+RBM）时，HOG 图像的应用帮助较少，因为RBM链接了HOG图像特征，这些特征的信息少于原始图像。然而，增加隐藏层和神经元的数量在定性上有助于HOG图像特征之间的连接，这一点从多层感知机分类器（MLPC）和卷积神经网络（CNN）的性能中可以看出。
- en: According to the Receiver Operating Characteristic (ROC) curve, the computing
    accuracy and the efficiency of each method, the performance of RF is comparable
    with a neural network (i.e. MLPC) with a faster computation time. In addition
    to RF, both the KNN and MLPC are alternative options can be considered when using
    pixel input because both of them have a relatively good accuracy with much less
    computing time than other conventional machine learning algorithms (e.g. LR, SVM)
    shown in this study (Table [3](#S4.T3 "Table 3 ‣ 4.5 Comparison between methods
    ‣ 4 Results ‣ Optimising Automatic Morphological Classification of Galaxies with
    Machine Learning and Deep Learning using Dark Energy Survey Imaging")). The most
    successful method within the ten methods we test is the Convolutional Neural Networks
    (CNN) with the combination input of raw images and HOG images and when using a
    balanced training data. Through this we are able to reach an accuracy of $\sim$0.95
    using $\sim$12,000 galaxies (including rotated images) as the initial training
    set. When using a classification criterion for the probability of the predicted
    type, $p>0.8$, we increase the accuracy to $\sim$0.97 and we are able to separate
    the classification into three types - Ellipticals, Spirals, and Uncertain. In
    the final test, when we apply the available maximum number of training data to
    train our CNN, and classified our testing galaxies by the criterion $p>0.8$, we
    reach a very high accuracy of $\sim$0.987 in the automated morphological classification
    of Ellipticals and Spirals.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 根据接收者操作特征（ROC）曲线、计算准确性和每种方法的效率，RF 的性能与神经网络（即 MLPC）相当，但计算时间更快。除了 RF，KNN 和 MLPC
    也是可以考虑的替代选项，因为它们在使用像素输入时具有相对较好的准确性，并且计算时间比本研究中展示的其他传统机器学习算法（例如 LR、SVM）要少得多（见表 [3](#S4.T3
    "表 3 ‣ 4.5 方法比较 ‣ 4 结果 ‣ 使用深空探测成像的机器学习和深度学习优化自动形态分类的银河系")）。在我们测试的十种方法中，最成功的方法是卷积神经网络（CNN），结合了原始图像和
    HOG 图像，并使用了平衡的训练数据。通过这种方法，我们能够使用约 12,000 个银河系（包括旋转图像）作为初始训练集，达到约 0.95 的准确率。当使用预测类型的概率分类标准
    $p>0.8$ 时，我们将准确率提高到约 0.97，并能够将分类分为三种类型——椭圆、螺旋和不确定。在最终测试中，当我们应用可用的最大训练数据数量来训练我们的
    CNN，并根据标准 $p>0.8$ 对测试银河系进行分类时，我们在椭圆和螺旋的自动形态分类中达到了约 0.987 的非常高的准确率。
- en: In the discussion, we investigate the probable reasons for the failures in a
    small number of our classifications. We separate the failure into two situations
    - galaxies with high probabilities but still misclassified according to Galaxy
    Zoo, and galaxies with lower probabilities of being either elliptical or spiral.
    Most of galaxies in these two situations are repeated between the five reruns
    we do; therefore, these galaxies have some features in common which cause the
    difficulties within our CNN algorithm.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 在讨论中，我们调查了分类中少数失败的可能原因。我们将失败情况分为两种情况——一是银河系的概率很高，但根据 Galaxy Zoo 仍被误分类；二是银河系被分类为椭圆或螺旋的概率较低。在这两种情况中的大多数银河系在我们进行的五次重跑中都重复出现；因此，这些银河系具有一些共同特征，导致了我们的
    CNN 算法中的困难。
- en: We conclude that these ‘failures’ are not true failures of the CNN. First of
    all, there is not a class for lenticular galaxy classification in the Galaxy Zoo
    catalogue, therefore, the confusion of lenticular galaxies with various labels
    cause difficulties to our CNN, resulting in low probability classifications for
    both ellipticals and spirals. Secondly, the better resolution (${0.}^{\prime\prime}263$
    per pixel) and deeper depth ($i=$22.51) of DES data compared to the SDSS data
    reveals a more detailed structure of our sample of galaxies. Ultimately, this
    reveals incorrect labels from the Galaxy Zoo catalogue, due to the lower resolution
    and shallower depth of that data. As a result we find a few misclassifications
    by the Galaxy Zoo project, identified through our machine learning. We find that
    about $2.5\%$ of the Ellipticals and Spirals are mislabelled out of $\sim 2,800$
    galaxies from Galaxy Zoo. After correcting the labels of these confirmed misclassified
    galaxies by Galaxy Zoo, we reach an average accuracy of over 0.99 (0.994 in the
    best result within five reruns, Fig. [16](#S5.F16 "Figure 16 ‣ 5.2.4 The advantage
    of Dark Energy images and the misclassifications by Galaxy Zoo project ‣ 5.2 Origin
    of Classification Failures ‣ 5 Further Discussion ‣ Optimising Automatic Morphological
    Classification of Galaxies with Machine Learning and Deep Learning using Dark
    Energy Survey Imaging")) on the classification of Ellipticals and Spirals by our
    CNN.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 我们得出结论，这些“失败”并不是 CNN 的真正失败。首先，Galaxy Zoo 目录中没有透镜星系分类类别，因此透镜星系与各种标签的混淆使我们的 CNN
    遇到困难，导致对椭圆星系和螺旋星系的分类概率较低。其次，与 SDSS 数据相比，DES 数据的更高分辨率（每像素 ${0.}^{\prime\prime}263$）和更深的深度（$i=$22.51）揭示了我们样本星系的更详细结构。最终，这揭示了
    Galaxy Zoo 目录中的错误标签，因为该数据的分辨率较低且深度较浅。因此，我们通过机器学习发现了 Galaxy Zoo 项目的几个误分类。我们发现，约
    $2.5\%$ 的椭圆星系和螺旋星系在 Galaxy Zoo 的 $\sim 2,800$ 个星系中被标记错误。在纠正了这些被确认误分类的 Galaxy Zoo
    星系的标签后，我们在 CNN 对椭圆星系和螺旋星系的分类中达到了超过 0.99 的平均准确率（在五次重跑中的最佳结果为 0.994，见图 [16](#S5.F16
    "Figure 16 ‣ 5.2.4 The advantage of Dark Energy images and the misclassifications
    by Galaxy Zoo project ‣ 5.2 Origin of Classification Failures ‣ 5 Further Discussion
    ‣ Optimising Automatic Morphological Classification of Galaxies with Machine Learning
    and Deep Learning using Dark Energy Survey Imaging")）。
- en: In summary, the purpose of this paper is to pick the most successful machine
    learning method through pixel input for future usage in DES. With this method,
    we can quickly classify over millions of galaxies in DES data using a pre-trained
    model. Meanwhile, with current classification catalogues from other surveys and
    our own visual classification for galaxies in fainter bands, we can cross-validate
    and statistically analyse our classification by this optimal method on DES data.
    The most optimal method found amongst the 10 methods used in this paper is CNN.
    Ultimately, we will apply our CNN models trained by corrected labels of galaxies
    on DES data to build the largest morphological catalog ever with machine learning
    classifications. There is not a catalogue of morphological classification of galaxies
    for DES yet. Therefore, this catalogue as a reference will be useful for a comparison
    or further investigation with other studies. The binary classification in our
    paper has an advantage for direct blind tests of machine learning comparisons
    but otherwise has very limited application, therefore, we will also extend our
    algorithm to do more complicated morphological classifications of galaxies afterwards.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，本论文的目的是通过像素输入选择最成功的机器学习方法，以便将来在 DES 中使用。使用此方法，我们可以通过预训练模型快速分类 DES 数据中的数百万个星系。同时，结合其他调查的当前分类目录和我们自己对更暗带星系的视觉分类，我们可以通过这种最优方法对
    DES 数据进行交叉验证和统计分析。本文使用的10种方法中发现的最优方法是 CNN。最终，我们将应用由星系的正确标签训练的 CNN 模型于 DES 数据，构建有史以来最大的机器学习分类形态目录。目前，DES
    尚未有星系形态分类目录。因此，这一目录作为参考将对与其他研究的比较或进一步调查有所帮助。我们论文中的二元分类对机器学习比较的直接盲测具有优势，但其他方面应用非常有限，因此，我们还将扩展我们的算法以进行更复杂的星系形态分类。
- en: In the longer term, we are developing the usage of Unsupervised Machine Learning
    (UML) for galaxy classification using pixel input. UML has no need for (much)
    pre-labelled data, so it can reduce the bias from human influences and interference
    as much as possible. At the same time it saves time which would otherwise be used
    to labelling data. With the development of UML and the Big Data from DES data,
    it will be very interesting to investigate the scenario of the evolution of galaxies
    and different possible classifications through machine learning.
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 从长远来看，我们正在开发使用无监督机器学习（UML）进行银河系分类的方法，该方法使用像素输入。UML不需要（大量）预先标记的数据，因此可以尽可能减少人为影响和干扰的偏差。同时，它节省了本来用于标记数据的时间。随着UML的发展和DES数据的大数据出现，通过机器学习研究银河系的演化场景及不同的可能分类将非常有趣。
- en: Acknowledgements
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: Funding for the DES Projects has been provided by the U.S. Department of Energy,
    the U.S. National Science Foundation, the Ministry of Science and Education of
    Spain, the Science and Technology Facilities Council of the United Kingdom, the
    Higher Education Funding Council for England, the National Center for Supercomputing
    Applications at the University of Illinois at Urbana-Champaign, the Kavli Institute
    of Cosmological Physics at the University of Chicago, the Center for Cosmology
    and Astro-Particle Physics at the Ohio State University, the Mitchell Institute
    for Fundamental Physics and Astronomy at Texas A$\&amp;$M University, Financiadora
    de Estudos e Projetos, Fundação Carlos Chagas Filho de Amparo à Pesquisa do Estado
    do Rio de Janeiro, Conselho Nacional de Desenvolvimento Científico e Tecnológico
    and the Ministério da Ciência, Tecnologia e Inovação, the Deutsche Forschungsgemeinschaft,
    and the Collaborating Institutions in the Dark Energy Survey.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: DES项目的资助来自于美国能源部、美国国家科学基金会、西班牙科学与教育部、英国科学与技术设施委员会、英格兰高等教育资助委员会、伊利诺伊大学厄尔巴纳-香槟分校国家超级计算应用中心、芝加哥大学卡夫里宇宙物理研究所、俄亥俄州立大学宇宙学与天体粒子物理中心、德州A$\&amp;$M大学基础物理与天文学米切尔研究所、研究与项目资助资助机构、里约热内卢州卡洛斯·查加斯·费略研究基金会、国家科学与技术发展委员会和科学、技术与创新部、德国研究基金会，以及参与暗能量调查的合作机构。
- en: The Collaborating Institutions are Argonne National Laboratory, the University
    of California at Santa Cruz, the University of Cambridge, Centro de Investigaciones
    Energéticas, Medioambientales y Tecnológicas-Madrid, the University of Chicago,
    University College London, the DES-Brazil Consortium, the University of Edinburgh,
    the Eidgenössische Technische Hochschule (ETH) Zürich, Fermi National Accelerator
    Laboratory, the University of Illinois at Urbana-Champaign, the Institut de Ciències
    de l’Espai (IEEC/CSIC), the Institut de Física d’Altes Energies, Lawrence Berkeley
    National Laboratory, the Ludwig-Maximilians Universität München and the associated
    Excellence Cluster Universe, the University of Michigan, the National Optical
    Astronomy Observatory, the University of Nottingham, The Ohio State University,
    the University of Pennsylvania, the University of Portsmouth, SLAC National Accelerator
    Laboratory, Stanford University, the University of Sussex, Texas A$\&amp;$M University,
    and the OzDES Membership Consortium.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 合作机构包括：阿贡国家实验室，加州大学圣克鲁斯分校，剑桥大学，马德里能源、环境与技术研究中心，芝加哥大学，伦敦大学学院，DES-巴西联盟，爱丁堡大学，瑞士联邦理工学院（ETH），费米国家加速器实验室，伊利诺伊大学厄尔巴纳-香槟分校，空间科学研究所（IEEC/CSIC），高能物理研究所，劳伦斯伯克利国家实验室，路德维希-马克西米利安大学及其附属的宇宙卓越集群，密歇根大学，国家光学天文台，诺丁汉大学，俄亥俄州立大学，宾夕法尼亚大学，朴茨茅斯大学，SLAC国家加速器实验室，斯坦福大学，苏塞克斯大学，德州A$\&amp;$M大学，以及OzDES会员联盟。
- en: Based in part on observations at Cerro Tololo Inter-American Observatory, National
    Optical Astronomy Observatory, which is operated by the Association of Universities
    for Research in Astronomy (AURA) under a cooperative agreement with the National
    Science Foundation.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 部分基于在塞罗托洛洛洲际天文台的观测，国家光学天文台由美国天文学研究大学协会（AURA）根据与国家科学基金会的合作协议运营。
- en: The DES data management system is supported by the National Science Foundation
    under grant numbers AST-1138766 and AST-1536171\. The DES participants from Spanish
    institutions are partially supported by MINECO under grants AYA2015-71825, ESP2015-66861,
    FPA2015-68048, SEV-2016-0588, SEV-2016-0597, and MDM-2015-0509, some of which
    include ERDF funds from the European Union. IFAE is partially funded by the CERCA
    programme of the Generalitat de Catalunya. Research leading to these results has
    received funding from the European Research Council under the European Union’s
    Seventh Framework Program (FP7/2007-2013) including ERC grant agreements 240672,
    291329, and 306478\. We acknowledge support from the Australian Research Council
    Centre of Excellence for All-sky Astrophysics (CAASTRO), through project number
    CE110001020, and the Brazilian Instituto Nacional de Ciencia e Tecnologia (INCT)
    e-Universe (CNPq grant 465376/2014-2).
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: DES 数据管理系统由国家科学基金会资助，资助号为 AST-1138766 和 AST-1536171。来自西班牙机构的 DES 参与者部分由 MINECO
    资助，资助号包括 AYA2015-71825、ESP2015-66861、FPA2015-68048、SEV-2016-0588、SEV-2016-0597
    和 MDM-2015-0509，其中部分包括欧盟的 ERDF 资金。IFAE 部分由加泰罗尼亚政府的 CERCA 计划资助。导致这些结果的研究得到了欧洲研究委员会的资助，资助来自欧盟第七框架计划（FP7/2007-2013），包括
    ERC 资助协议 240672、291329 和 306478。我们还感谢澳大利亚研究委员会全视天文中心（CAASTRO）的支持，项目号为 CE110001020，以及巴西国家科学与技术研究所（INCT）e-Universe（CNPq
    资助号 465376/2014-2）。
- en: References
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Abbott et al. (2018) Abbott T. M. C., et al., 2018, [ApJS](http://dx.doi.org/10.3847/1538-4365/aae9f0),
    [239, 18](https://ui.adsabs.harvard.edu/abs/2018ApJS..239...18A)
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abbott 等 (2018) Abbott T. M. C., 等，2018, [ApJS](http://dx.doi.org/10.3847/1538-4365/aae9f0),
    [239, 18](https://ui.adsabs.harvard.edu/abs/2018ApJS..239...18A)
- en: Abraham et al. (2003) Abraham R. G., van den Bergh S., Nair P., 2003, [ApJ](http://dx.doi.org/10.1086/373919),
    [588, 218](https://ui.adsabs.harvard.edu/abs/2003ApJ...588..218A)
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abraham 等 (2003) Abraham R. G., van den Bergh S., Nair P., 2003, [ApJ](http://dx.doi.org/10.1086/373919),
    [588, 218](https://ui.adsabs.harvard.edu/abs/2003ApJ...588..218A)
- en: Avestruz et al. (2019) Avestruz C., Li N., Zhu H., Lightman M., Collett T. E.,
    Luo W., 2019, [ApJ](http://dx.doi.org/10.3847/1538-4357/ab16d9), [877, 58](https://ui.adsabs.harvard.edu/abs/2019ApJ...877...58A)
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avestruz 等 (2019) Avestruz C., Li N., Zhu H., Lightman M., Collett T. E., Luo
    W., 2019, [ApJ](http://dx.doi.org/10.3847/1538-4357/ab16d9), [877, 58](https://ui.adsabs.harvard.edu/abs/2019ApJ...877...58A)
- en: Ball et al. (2004) Ball N. M., Loveday J., Fukugita M., Nakamura O., Okamura
    S., Brinkmann J., Brunner R. J., 2004, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2004.07429.x),
    [348, 1038](https://ui.adsabs.harvard.edu/abs/2004MNRAS.348.1038B)
  id: totrans-275
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ball 等 (2004) Ball N. M., Loveday J., Fukugita M., Nakamura O., Okamura S.,
    Brinkmann J., Brunner R. J., 2004, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2004.07429.x),
    [348, 1038](https://ui.adsabs.harvard.edu/abs/2004MNRAS.348.1038B)
- en: Ball et al. (2006) Ball N. M., Brunner R. J., Myers A. D., Tcheng D., 2006,
    [ApJ](http://dx.doi.org/10.1086/507440), [650, 497](https://ui.adsabs.harvard.edu/abs/2006ApJ...650..497B)
  id: totrans-276
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ball 等 (2006) Ball N. M., Brunner R. J., Myers A. D., Tcheng D., 2006, [ApJ](http://dx.doi.org/10.1086/507440),
    [650, 497](https://ui.adsabs.harvard.edu/abs/2006ApJ...650..497B)
- en: Bamford et al. (2009) Bamford S. P., et al., 2009, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.14252.x),
    [393, 1324](https://ui.adsabs.harvard.edu/abs/2009MNRAS.393.1324B)
  id: totrans-277
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bamford 等 (2009) Bamford S. P., 等，2009, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.14252.x),
    [393, 1324](https://ui.adsabs.harvard.edu/abs/2009MNRAS.393.1324B)
- en: Banerji et al. (2010) Banerji M., et al., 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x),
    [406, 342](https://ui.adsabs.harvard.edu/abs/2010MNRAS.406..342B)
  id: totrans-278
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerji 等 (2010) Banerji M., 等，2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x),
    [406, 342](https://ui.adsabs.harvard.edu/abs/2010MNRAS.406..342B)
- en: Beck et al. (2018) Beck M. R., et al., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty503),
    [476, 5516](https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.5516B)
  id: totrans-279
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Beck 等 (2018) Beck M. R., 等，2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty503),
    [476, 5516](https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.5516B)
- en: Bishop (2006) Bishop C. M., 2006, Pattern Recognition and Machine Learning (Information
    Science and Statistics). Springer-Verlag, Berlin, Heidelberg
  id: totrans-280
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bishop (2006) Bishop C. M., 2006, 《模式识别与机器学习》（信息科学与统计）。施普林格出版社，柏林，海德堡
- en: Bradley (1997) Bradley A. P., 1997, [Pattern Recognition](http://dx.doi.org/https://doi.org/10.1016/S0031-3203(96)00142-2),
    30, 1145
  id: totrans-281
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bradley (1997) Bradley A. P., 1997, [模式识别](http://dx.doi.org/https://doi.org/10.1016/S0031-3203(96)00142-2),
    30, 1145
- en: Breiman (2001) Breiman L., 2001, [Mach. Learn.](http://dx.doi.org/10.1023/A:1010933404324),
    45, 5–32
  id: totrans-282
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Breiman (2001) Breiman L., 2001, [机器学习](http://dx.doi.org/10.1023/A:1010933404324),
    45, 5–32
- en: Chopra & Yadav (2017) Chopra P., Yadav S., 2017, [Complex & Intelligent Systems](http://dx.doi.org/10.1007/s40747-017-0054-8),
    pp 1–11
  id: totrans-283
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chopra & Yadav (2017) Chopra P., Yadav S., 2017, [复杂与智能系统](http://dx.doi.org/10.1007/s40747-017-0054-8),
    第 1–11 页
- en: Chou (2014) Chou F.-C., 2014
  id: totrans-284
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chou (2014) Chou F.-C., 2014
- en: Conselice (2003) Conselice C. J., 2003, [ApJS](http://dx.doi.org/10.1086/375001),
    [147, 1](https://ui.adsabs.harvard.edu/abs/2003ApJS..147....1C)
  id: totrans-285
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conselice (2003) Conselice C. J., 2003, [ApJS](http://dx.doi.org/10.1086/375001),
    [147, 1](https://ui.adsabs.harvard.edu/abs/2003ApJS..147....1C)
- en: Cortes & Vapnik (1995) Cortes C., Vapnik V., 1995, in Machine Learning. pp 273–297
  id: totrans-286
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cortes & Vapnik (1995) Cortes C., Vapnik V., 1995, in Machine Learning. pp 273–297
- en: Cover & Hart (1967) Cover T., Hart P., 1967, [IEEE Transactions on Information
    Theory](http://dx.doi.org/10.1109/TIT.1967.1053964), 13, 21
  id: totrans-287
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cover & Hart (1967) Cover T., Hart P., 1967, [IEEE Transactions on Information
    Theory](http://dx.doi.org/10.1109/TIT.1967.1053964), 13, 21
- en: Cunningham & Delany (2007) Cunningham P., Delany S. J., 2007, k-Nearest Neighbour
    Classifiers
  id: totrans-288
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cunningham & Delany (2007) Cunningham P., Delany S. J., 2007, k-Nearest Neighbour
    Classifiers
- en: Dalal & Triggs (2005) Dalal N., Triggs B., 2005, in 2005 IEEE Computer Society
    Conference on Computer Vision and Pattern Recognition (CVPR’05). pp 886–893 vol.
    1, [doi:10.1109/CVPR.2005.177](http://dx.doi.org/10.1109/CVPR.2005.177)
  id: totrans-289
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalal & Triggs (2005) Dalal N., Triggs B., 2005, in 2005 IEEE Computer Society
    Conference on Computer Vision and Pattern Recognition (CVPR’05). pp 886–893 vol.
    1, [doi:10.1109/CVPR.2005.177](http://dx.doi.org/10.1109/CVPR.2005.177)
- en: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
  id: totrans-290
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
- en: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company M., Bernardi
    M., Tuccillo D., Fischer J. L., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty338),
    [476, 3661](https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.3661D)
  id: totrans-291
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company M., Bernardi
    M., Tuccillo D., Fischer J. L., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty338),
    [476, 3661](https://ui.adsabs.harvard.edu/abs/2018MNRAS.476.3661D)
- en: Drlica-Wagner et al. (2018) Drlica-Wagner A., et al., 2018, [ApJS](http://dx.doi.org/10.3847/1538-4365/aab4f5),
    [235, 33](https://ui.adsabs.harvard.edu/abs/2018ApJS..235...33D)
  id: totrans-292
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Drlica-Wagner et al. (2018) Drlica-Wagner A., et al., 2018, [ApJS](http://dx.doi.org/10.3847/1538-4365/aab4f5),
    [235, 33](https://ui.adsabs.harvard.edu/abs/2018ApJS..235...33D)
- en: Dubath et al. (2011) Dubath P., et al., 2011, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2011.18575.x),
    [414, 2602](https://ui.adsabs.harvard.edu/abs/2011MNRAS.414.2602D)
  id: totrans-293
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dubath et al. (2011) Dubath P., et al., 2011, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2011.18575.x),
    [414, 2602](https://ui.adsabs.harvard.edu/abs/2011MNRAS.414.2602D)
- en: Fawagreh et al. (2014) Fawagreh K., Gaber M. M., Elyan E., 2014, [Systems Science
    & Control Engineering](http://dx.doi.org/10.1080/21642583.2014.956265), 2, 602
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawagreh et al. (2014) Fawagreh K., Gaber M. M., Elyan E., 2014, [Systems Science
    & Control Engineering](http://dx.doi.org/10.1080/21642583.2014.956265), 2, 602
- en: Fawcett (2006) Fawcett T., 2006, [Pattern Recognition Letters](http://dx.doi.org/https://doi.org/10.1016/j.patrec.2005.10.010),
    27, 861
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fawcett (2006) Fawcett T., 2006, [Pattern Recognition Letters](http://dx.doi.org/https://doi.org/10.1016/j.patrec.2005.10.010),
    27, 861
- en: Fix & Hodges (1989) Fix E., Hodges J. L., 1989, International Statistical Review
    / Revue Internationale de Statistique, 57, 238
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fix & Hodges (1989) Fix E., Hodges J. L., 1989, International Statistical Review
    / Revue Internationale de Statistique, 57, 238
- en: Flaugher et al. (2015) Flaugher B., et al., 2015, [AJ](http://dx.doi.org/10.1088/0004-6256/150/5/150),
    [150, 150](https://ui.adsabs.harvard.edu/abs/2015AJ....150..150F)
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Flaugher et al. (2015) Flaugher B., et al., 2015, [AJ](http://dx.doi.org/10.1088/0004-6256/150/5/150),
    [150, 150](https://ui.adsabs.harvard.edu/abs/2015AJ....150..150F)
- en: Fukushima (1975) Fukushima K., 1975, Biological Cybernetics, 20, 121
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fukushima (1975) Fukushima K., 1975, Biological Cybernetics, 20, 121
- en: Fukushima (1980) Fukushima K., 1980, [Biological Cybernetics](http://dx.doi.org/10.1007/bf00344251),
    36, 193
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fukushima (1980) Fukushima K., 1980, [Biological Cybernetics](http://dx.doi.org/10.1007/bf00344251),
    36, 193
- en: Fukushima et al. (1983) Fukushima K., Miyake S., Ito T., 1983, [IEEE Transactions
    on Systems, Man, and Cybernetics](http://dx.doi.org/10.1109/TSMC.1983.6313076),
    SMC-13, 826
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fukushima et al. (1983) Fukushima K., Miyake S., Ito T., 1983, [IEEE Transactions
    on Systems, Man, and Cybernetics](http://dx.doi.org/10.1109/TSMC.1983.6313076),
    SMC-13, 826
- en: Gao et al. (2008) Gao D., Zhang Y.-X., Zhao Y.-H., 2008, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13070.x),
    [386, 1417](https://ui.adsabs.harvard.edu/abs/2008MNRAS.386.1417G)
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gao et al. (2008) Gao D., Zhang Y.-X., Zhao Y.-H., 2008, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13070.x),
    [386, 1417](https://ui.adsabs.harvard.edu/abs/2008MNRAS.386.1417G)
- en: Goderya & Lolling (2002) Goderya S. N., Lolling S. M., 2002, [Ap&SS](http://dx.doi.org/10.1023/A:1015193432240),
    [279, 377](https://ui.adsabs.harvard.edu/abs/2002Ap&SS.279..377G)
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goderya & Lolling (2002) Goderya S. N., Lolling S. M., 2002, [Ap&SS](http://dx.doi.org/10.1023/A:1015193432240),
    [279, 377](https://ui.adsabs.harvard.edu/abs/2002Ap&SS.279..377G)
- en: Hinton (2002) Hinton G. E., 2002, [Neural Comput.](http://dx.doi.org/10.1162/089976602760128018),
    14, 1771–1800
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton (2002) Hinton G. E., 2002, [Neural Comput.](http://dx.doi.org/10.1162/089976602760128018),
    14, 1771–1800
- en: Hocking et al. (2018) Hocking A., Geach J. E., Sun Y., Davey N., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2351),
    [473, 1108](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473.1108H)
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hocking 等（2018）Hocking A.，Geach J. E.，Sun Y.，Davey N.，2018，[MNRAS](http://dx.doi.org/10.1093/mnras/stx2351)，[473,
    1108](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473.1108H)
- en: Hsu et al. (2003) Hsu C.-W., Chang C.-C., Lin C.-J., 2003, Technical report,
    A Practical Guide to Support Vector Classification, [http://www.csie.ntu.edu.tw/~cjlin/papers.html](http://www.csie.ntu.edu.tw/~cjlin/papers.html).
    Department of Computer Science, National Taiwan University, [http://www.csie.ntu.edu.tw/~cjlin/papers.html](http://www.csie.ntu.edu.tw/~cjlin/papers.html)
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hsu 等（2003）Hsu C.-W.，Chang C.-C.，Lin C.-J.，2003，技术报告，《支持向量分类实用指南》，[http://www.csie.ntu.edu.tw/~cjlin/papers.html](http://www.csie.ntu.edu.tw/~cjlin/papers.html)。国立台湾大学计算机科学系，[http://www.csie.ntu.edu.tw/~cjlin/papers.html](http://www.csie.ntu.edu.tw/~cjlin/papers.html)
- en: Hubble (1926) Hubble E. P., 1926, [ApJ](http://dx.doi.org/10.1086/143018), [64,
    321](https://ui.adsabs.harvard.edu/abs/1926ApJ....64..321H)
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hubble（1926）Hubble E. P.，1926，[ApJ](http://dx.doi.org/10.1086/143018)，[64, 321](https://ui.adsabs.harvard.edu/abs/1926ApJ....64..321H)
- en: Huertas-Company et al. (2008) Huertas-Company M., Rouan D., Tasca L., Soucail
    G., Le Fèvre O., 2008, [A&A](http://dx.doi.org/10.1051/0004-6361:20078625), [478,
    971](https://ui.adsabs.harvard.edu/abs/2008A&A...478..971H)
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等（2008）Huertas-Company M.，Rouan D.，Tasca L.，Soucail G.，Le Fèvre
    O.，2008，[A&A](http://dx.doi.org/10.1051/0004-6361:20078625)，[478, 971](https://ui.adsabs.harvard.edu/abs/2008A&A...478..971H)
- en: Huertas-Company et al. (2009) Huertas-Company M., et al., 2009, [A&A](http://dx.doi.org/10.1051/0004-6361/200811255),
    [497, 743](https://ui.adsabs.harvard.edu/abs/2009A&A...497..743H)
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等（2009）Huertas-Company M. 等，2009，[A&A](http://dx.doi.org/10.1051/0004-6361/200811255)，[497,
    743](https://ui.adsabs.harvard.edu/abs/2009A&A...497..743H)
- en: Huertas-Company et al. (2011) Huertas-Company M., Aguerri J. A. L., Bernardi
    M., Mei S., Sánchez Almeida J., 2011, [A&A](http://dx.doi.org/10.1051/0004-6361/201015735),
    [525, A157](https://ui.adsabs.harvard.edu/abs/2011A&A...525A.157H)
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等（2011）Huertas-Company M.，Aguerri J. A. L.，Bernardi M.，Mei S.，Sánchez
    Almeida J.，2011，[A&A](http://dx.doi.org/10.1051/0004-6361/201015735)，[525, A157](https://ui.adsabs.harvard.edu/abs/2011A&A...525A.157H)
- en: Huertas-Company et al. (2015) Huertas-Company M., et al., 2015, [ApJS](http://dx.doi.org/10.1088/0067-0049/221/1/8),
    [221, 8](https://ui.adsabs.harvard.edu/abs/2015ApJS..221....8H)
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等（2015）Huertas-Company M. 等，2015，[ApJS](http://dx.doi.org/10.1088/0067-0049/221/1/8)，[221,
    8](https://ui.adsabs.harvard.edu/abs/2015ApJS..221....8H)
- en: Huertas-Company et al. (2018) Huertas-Company M., et al., 2018, [ApJ](http://dx.doi.org/10.3847/1538-4357/aabfed),
    [858, 114](https://ui.adsabs.harvard.edu/abs/2018ApJ...858..114H)
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huertas-Company 等（2018）Huertas-Company M. 等，2018，[ApJ](http://dx.doi.org/10.3847/1538-4357/aabfed)，[858,
    114](https://ui.adsabs.harvard.edu/abs/2018ApJ...858..114H)
- en: Huppenkothen et al. (2017) Huppenkothen D., Heil L. M., Hogg D. W., Mueller
    A., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stw3190), [466, 2364](https://ui.adsabs.harvard.edu/abs/2017MNRAS.466.2364H)
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huppenkothen 等（2017）Huppenkothen D.，Heil L. M.，Hogg D. W.，Mueller A.，2017，[MNRAS](http://dx.doi.org/10.1093/mnras/stw3190)，[466,
    2364](https://ui.adsabs.harvard.edu/abs/2017MNRAS.466.2364H)
- en: Kamble & Hegadi (2015) Kamble P. M., Hegadi R. S., 2015, [Procedia Computer
    Science](http://dx.doi.org/https://doi.org/10.1016/j.procs.2015.03.137), 45, 266
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kamble & Hegadi（2015）Kamble P. M.，Hegadi R. S.，2015，[Procedia Computer Science](http://dx.doi.org/https://doi.org/10.1016/j.procs.2015.03.137)，45，266
- en: Kovács & Szapudi (2015) Kovács A., Szapudi I., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv063),
    [448, 1305](https://ui.adsabs.harvard.edu/abs/2015MNRAS.448.1305K)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kovács & Szapudi（2015）Kovács A.，Szapudi I.，2015，[MNRAS](http://dx.doi.org/10.1093/mnras/stv063)，[448,
    1305](https://ui.adsabs.harvard.edu/abs/2015MNRAS.448.1305K)
- en: Kügler et al. (2015) Kügler S. D., Polsterer K., Hoecker M., 2015, [A&A](http://dx.doi.org/10.1051/0004-6361/201424801),
    [576, A132](https://ui.adsabs.harvard.edu/abs/2015A&A...576A.132K)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kügler 等（2015）Kügler S. D.，Polsterer K.，Hoecker M.，2015，[A&A](http://dx.doi.org/10.1051/0004-6361/201424801)，[576,
    A132](https://ui.adsabs.harvard.edu/abs/2015A&A...576A.132K)
- en: Lahav et al. (1996) Lahav O., Naim A., Sodré L. J., Storrie-Lombardi M. C.,
    1996, [MNRAS](http://dx.doi.org/10.1093/mnras/283.1.207), [283, 207](https://ui.adsabs.harvard.edu/abs/1996MNRAS.283..207L)
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lahav 等（1996）Lahav O.，Naim A.，Sodré L. J.，Storrie-Lombardi M. C.，1996，[MNRAS](http://dx.doi.org/10.1093/mnras/283.1.207)，[283,
    207](https://ui.adsabs.harvard.edu/abs/1996MNRAS.283..207L)
- en: Lecun et al. (1998) Lecun Y., Bottou L., Bengio Y., Haffner P., 1998, [Proceedings
    of the IEEE](http://dx.doi.org/10.1109/5.726791), 86, 2278
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lecun 等（1998）Lecun Y.，Bottou L.，Bengio Y.，Haffner P.，1998，[IEEE 会议论文集](http://dx.doi.org/10.1109/5.726791)，86，2278
- en: Lintott et al. (2008) Lintott C. J., et al., 2008, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13689.x),
    [389, 1179](https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L)
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lintott 等（2008）Lintott C. J. 等，2008，[MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2008.13689.x)，[389,
    1179](https://ui.adsabs.harvard.edu/abs/2008MNRAS.389.1179L)
- en: Lintott et al. (2011) Lintott C., et al., 2011, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x),
    [410, 166](https://ui.adsabs.harvard.edu/abs/2011MNRAS.410..166L)
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lintott et al. (2011) Lintott C., 等，2011, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x),
    [410, 166](https://ui.adsabs.harvard.edu/abs/2011MNRAS.410..166L)
- en: Maehoenen & Hakala (1995) Maehoenen P. H., Hakala P. J., 1995, [ApJ](http://dx.doi.org/10.1086/309697),
    [452, L77](https://ui.adsabs.harvard.edu/abs/1995ApJ...452L..77M)
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Maehoenen & Hakala (1995) Maehoenen P. H., Hakala P. J., 1995, [ApJ](http://dx.doi.org/10.1086/309697),
    [452, L77](https://ui.adsabs.harvard.edu/abs/1995ApJ...452L..77M)
- en: McCullagh & Nelder (1989) McCullagh P., Nelder J., 1989, Generalized Linear
    Models, Second Edition. Chapman and Hall/CRC Monographs on Statistics and Applied
    Probability Series, Chapman & Hall, [http://books.google.com/books?id=h9kFH2_FfBkC](http://books.google.com/books?id=h9kFH2_FfBkC)
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCullagh & Nelder (1989) McCullagh P., Nelder J., 1989, 《广义线性模型》（第二版）。查普曼与霍尔/CRC
    统计与应用概率丛书，查普曼与霍尔, [http://books.google.com/books?id=h9kFH2_FfBkC](http://books.google.com/books?id=h9kFH2_FfBkC)
- en: Metcalf et al. (2019) Metcalf R. B., et al., 2019, [A&A](http://dx.doi.org/10.1051/0004-6361/201832797),
    [625, A119](https://ui.adsabs.harvard.edu/abs/2019A&A...625A.119M)
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Metcalf et al. (2019) Metcalf R. B., 等，2019, [A&A](http://dx.doi.org/10.1051/0004-6361/201832797),
    [625, A119](https://ui.adsabs.harvard.edu/abs/2019A&A...625A.119M)
- en: Naim et al. (1995) Naim A., Lahav O., Sodre L. J., Storrie-Lombardi M. C., 1995,
    [MNRAS](http://dx.doi.org/10.1093/mnras/275.3.567), [275, 567](https://ui.adsabs.harvard.edu/abs/1995MNRAS.275..567N)
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naim et al. (1995) Naim A., Lahav O., Sodre L. J., Storrie-Lombardi M. C., 1995,
    [MNRAS](http://dx.doi.org/10.1093/mnras/275.3.567), [275, 567](https://ui.adsabs.harvard.edu/abs/1995MNRAS.275..567N)
- en: Odewahn et al. (1992) Odewahn S. C., Stockwell E. B., Pennington R. L., Humphreys
    R. M., Zumach W. A., 1992, [AJ](http://dx.doi.org/10.1086/116063), [103, 318](https://ui.adsabs.harvard.edu/abs/1992AJ....103..318O)
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Odewahn et al. (1992) Odewahn S. C., Stockwell E. B., Pennington R. L., Humphreys
    R. M., Zumach W. A., 1992, [AJ](http://dx.doi.org/10.1086/116063), [103, 318](https://ui.adsabs.harvard.edu/abs/1992AJ....103..318O)
- en: Orr & Science (1996) Orr M. J. L., Science C. F. C., 1996, Technical report,
    Introduction to radial basis function networks
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Orr & Science (1996) Orr M. J. L., Science C. F. C., 1996, 技术报告，《径向基函数网络导论》
- en: Pedregosa et al. (2012) Pedregosa F., et al., 2012, arXiv e-prints, [p. arXiv:1201.0490](https://ui.adsabs.harvard.edu/abs/2012arXiv1201.0490P)
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pedregosa et al. (2012) Pedregosa F., 等，2012, arXiv 电子预印本, [p. arXiv:1201.0490](https://ui.adsabs.harvard.edu/abs/2012arXiv1201.0490P)
- en: Polsterer et al. (2012) Polsterer K. L., Gieseke F., Kramer O., 2012, Galaxy
    Classification without Feature Extraction. p. 561
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Polsterer et al. (2012) Polsterer K. L., Gieseke F., Kramer O., 2012, 《没有特征提取的星系分类》。第561页
- en: Powers (2011) Powers D. M. W., 2011, Journal of Machine Learning Technologies,
    2, 37
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Powers (2011) Powers D. M. W., 2011, 机器学习技术杂志, 2, 37
- en: Rosenblatt (1958) Rosenblatt F., 1958, Psychological Review, pp 65–386
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rosenblatt (1958) Rosenblatt F., 1958, 心理学评论, 第65–386页
- en: Rumelhart et al. (1986) Rumelhart D. E., Hinton G. E., Williams R. J., 1986,
    [Nature](http://dx.doi.org/10.1038/323533a0), [323, 533](https://ui.adsabs.harvard.edu/abs/1986Natur.323..533R)
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rumelhart et al. (1986) Rumelhart D. E., Hinton G. E., Williams R. J., 1986,
    [Nature](http://dx.doi.org/10.1038/323533a0), [323, 533](https://ui.adsabs.harvard.edu/abs/1986Natur.323..533R)
- en: Salakhutdinov et al. (2007) Salakhutdinov R., Mnih A., Hinton G., 2007, in Proceedings
    of the 24th International Conference on Machine Learning. ICML ’07. Association
    for Computing Machinery, New York, NY, USA, p. 791–798, [doi:10.1145/1273496.1273596](http://dx.doi.org/10.1145/1273496.1273596),
    [https://doi.org/10.1145/1273496.1273596](https://doi.org/10.1145/1273496.1273596)
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salakhutdinov et al. (2007) Salakhutdinov R., Mnih A., Hinton G., 2007, 发表在第24届国际机器学习会议论文集。ICML
    ’07。计算机协会，纽约，NY，美国，第791–798页, [doi:10.1145/1273496.1273596](http://dx.doi.org/10.1145/1273496.1273596),
    [https://doi.org/10.1145/1273496.1273596](https://doi.org/10.1145/1273496.1273596)
- en: 'Scholkopf & Smola (2001) Scholkopf B., Smola A. J., 2001, Learning with Kernels:
    Support Vector Machines, Regularization, Optimization, and Beyond. MIT Press,
    Cambridge, MA, USA'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Scholkopf & Smola (2001) Scholkopf B., Smola A. J., 2001, 《使用核函数学习：支持向量机、正则化、优化及更多》。MIT出版社，剑桥，MA，美国
- en: Shamir (2009) Shamir L., 2009, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2009.15366.x),
    [399, 1367](https://ui.adsabs.harvard.edu/abs/2009MNRAS.399.1367S)
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shamir (2009) Shamir L., 2009, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2009.15366.x),
    [399, 1367](https://ui.adsabs.harvard.edu/abs/2009MNRAS.399.1367S)
- en: Short & Fukunaga (1981) Short R. D., Fukunaga K., 1981, IEEE Trans. Information
    Theory, 27, 622
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Short & Fukunaga (1981) Short R. D., Fukunaga K., 1981, IEEE信息理论汇刊, 27, 622
- en: Shu et al. (2011) Shu C., Ding X., Fang C., 2011, [Tsinghua Science and Technology](http://dx.doi.org/10.1016/S1007-0214(11)70032-3),
    16, 216
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shu et al. (2011) Shu C., Ding X., Fang C., 2011, [清华科学技术](http://dx.doi.org/10.1016/S1007-0214(11)70032-3),
    16, 216
- en: 'Smolensky (1986) Smolensky P., 1986, Information Processing in Dynamical Systems:
    Foundations of Harmony Theory. MIT Press, Cambridge, MA, USA, p. 194–281'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smolensky（1986）Smolensky P.，1986，动态系统中的信息处理：和谐理论基础。麻省理工学院出版社，剑桥，MA，美国，第194–281页
- en: Sreejith et al. (2018) Sreejith S., et al., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2976),
    [474, 5232](https://ui.adsabs.harvard.edu/abs/2018MNRAS.474.5232S)
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sreejith等（2018）Sreejith S.等，2018，[MNRAS](http://dx.doi.org/10.1093/mnras/stx2976)，[474,
    5232](https://ui.adsabs.harvard.edu/abs/2018MNRAS.474.5232S)
- en: Storrie-Lombardi et al. (1992) Storrie-Lombardi M. C., Lahav O., Sodre L. J.,
    Storrie-Lombardi L. J., 1992, [MNRAS](http://dx.doi.org/10.1093/mnras/259.1.8P),
    [259, 8P](https://ui.adsabs.harvard.edu/abs/1992MNRAS.259P...8S)
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Storrie-Lombardi等（1992）Storrie-Lombardi M. C.，Lahav O.，Sodre L. J.，Storrie-Lombardi
    L. J.，1992，[MNRAS](http://dx.doi.org/10.1093/mnras/259.1.8P)，[259, 8P](https://ui.adsabs.harvard.edu/abs/1992MNRAS.259P...8S)
- en: TURING (1950) TURING A. M., 1950, [Mind](http://dx.doi.org/10.1093/mind/LIX.236.433),
    LIX, 433
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TURING（1950）TURING A. M.，1950，[Mind](http://dx.doi.org/10.1093/mind/LIX.236.433)，LIX，433
- en: Vapnik (1995) Vapnik V. N., 1995, The Nature of Statistical Learning Theory.
    Springer-Verlag, Berlin, Heidelberg
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vapnik（1995）Vapnik V. N.，1995，统计学习理论的本质。施普林格出版社，柏林，海德堡
- en: Weir et al. (1995) Weir N., Fayyad U. M., Djorgovski S., 1995, [AJ](http://dx.doi.org/10.1086/117459),
    [109, 2401](https://ui.adsabs.harvard.edu/abs/1995AJ....109.2401W)
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Weir等（1995）Weir N.，Fayyad U. M.，Djorgovski S.，1995，[AJ](http://dx.doi.org/10.1086/117459)，[109,
    2401](https://ui.adsabs.harvard.edu/abs/1995AJ....109.2401W)
- en: Werbos & John (1974) Werbos P., John P., 1974
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Werbos & John（1974）Werbos P.，John P.，1974
- en: Willett et al. (2013) Willett K. W., et al., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt1458),
    [435, 2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Willett等（2013）Willett K. W.等，2013，[MNRAS](http://dx.doi.org/10.1093/mnras/stt1458)，[435,
    2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
- en: Wu & Chang (2003) Wu G., Chang E. Y., 2003, in In ICML 2003 Workshop on Learning
    from Imbalanced Data Sets. pp 49–56
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu & Chang（2003）Wu G.，Chang E. Y.，2003，在ICML 2003学习不平衡数据集研讨会上，第49–56页
- en: Zanaty (2012) Zanaty E., 2012, [Egyptian Informatics Journal](http://dx.doi.org/https://doi.org/10.1016/j.eij.2012.08.002),
    13, 177
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zanaty（2012）Zanaty E.，2012，[埃及信息学期刊](http://dx.doi.org/https://doi.org/10.1016/j.eij.2012.08.002)，13，177
- en: de la Calleja & Fuentes (2004) de la Calleja J., Fuentes O., 2004, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2004.07442.x),
    [349, 87](https://ui.adsabs.harvard.edu/abs/2004MNRAS.349...87D)
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de la Calleja & Fuentes（2004）de la Calleja J.，Fuentes O.，2004，[MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2004.07442.x)，[349,
    87](https://ui.adsabs.harvard.edu/abs/2004MNRAS.349...87D)
- en: Appendix A Support Vector Machine
  id: totrans-347
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 支持向量机
- en: Support Vector Machine (SVM) algorithm is to find a hyperplane defined as below,
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 支持向量机（SVM）算法的目标是找到下述定义的超平面，
- en: '|  | $\vec{w}\cdot\vec{x}-b=0,$ |  | (6) |'
  id: totrans-349
  prefs: []
  type: TYPE_TB
  zh: '|  | $\vec{w}\cdot\vec{x}-b=0,$ |  | (6) |'
- en: 'where $\vec{w}$ is a weighted vector, $\vec{x}$ is the input data, and $b$
    is the bias, with the maximum distance to the nearest data for each type (support
    vector): $\left|\vec{w}\cdot\vec{x}-b\right|=1$ (Vapnik, [1995](#bib.bib69); Cortes
    & Vapnik, [1995](#bib.bib15)). For example (See the top of Fig. [19](#A1.F19 "Figure
    19 ‣ Appendix A Support Vector Machine ‣ Optimising Automatic Morphological Classification
    of Galaxies with Machine Learning and Deep Learning using Dark Energy Survey Imaging")),
    in 2-class classification, $\left\{{\vec{{x}_{j}}},{y}_{j}\right\}$, ${\vec{{x}_{j}}}$
    is a vector which represents input data, and ${y}_{j}$ represents the classification.
    The $j$ means the $j$-th data. ${y}_{j}\in\left\{1(\text{circle}),-1(\text{square})\right\}$.
    While the parameter $\frac{b}{\left\|\vec{w}\right\|}$ determines the distance
    between the hyperplane to the support vectors, finding the maximum of this parameter
    is finding the minimum $\left\|\vec{w}\right\|$. After determining the decision
    boundary, data above the boundary: $\vec{w}\cdot\vec{x}-b\geq 1$ is classified
    as a circle, the below one: $\vec{w}\cdot\vec{x}-b\leq-1$ is classified as a square.'
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\vec{w}$ 是加权向量，$\vec{x}$ 是输入数据，$b$ 是偏置，每种类型的最近数据的最大距离（支持向量）为：$\left|\vec{w}\cdot\vec{x}-b\right|=1$（Vapnik，[1995](#bib.bib69)；Cortes
    & Vapnik，[1995](#bib.bib15)）。例如（见图 [19](#A1.F19 "Figure 19 ‣ Appendix A Support
    Vector Machine ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging)"), 在二分类问题中，$\left\{{\vec{{x}_{j}}},{y}_{j}\right\}$，${\vec{{x}_{j}}}$
    是表示输入数据的向量，${y}_{j}$ 代表分类。$j$ 表示第 $j$ 个数据。${y}_{j}\in\left\{1(\text{circle}),-1(\text{square})\right\}$。参数
    $\frac{b}{\left\|\vec{w}\right\|}$ 决定了超平面到支持向量的距离，最大化该参数即是最小化 $\left\|\vec{w}\right\|$。确定决策边界后，边界上的数据：$\vec{w}\cdot\vec{x}-b\geq
    1$ 被分类为圆形，边界下的数据：$\vec{w}\cdot\vec{x}-b\leq-1$ 被分类为方形。
- en: 'When using a non-linear SVM, the algorithm uses a kernel function $K$ to the
    data: $\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)\rightarrow K\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)$
    to map the data. The bottom of Fig. [19](#A1.F19 "Figure 19 ‣ Appendix A Support
    Vector Machine ‣ Optimising Automatic Morphological Classification of Galaxies
    with Machine Learning and Deep Learning using Dark Energy Survey Imaging") shows
    a 2D illustration of an example of non-linear SVM with a circular transformation.
    In this example, we assume each point is $\left({a}_{k},{b}_{k}\right)$, and we
    transform the data into a new feature space which is defined as $c=\sqrt{{a}_{k}^{2}+{b}_{k}^{2}}$
    (circular transformation); therefore, the decision boundary is shown as the circular
    shape in the input space (i.e. $a-b$ space), but shown lines in feature space
    ($c$ space).'
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 使用非线性SVM时，算法将核函数 $K$ 应用于数据：$\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)\rightarrow
    K\left({\vec{x}},\vec{{x}}^{{}^{\prime}}\right)$ 以映射数据。图[19](#A1.F19 "图 19 ‣ 附录
    A 支持向量机 ‣ 使用深空探测图像的机器学习和深度学习优化自动形态分类")底部展示了一个圆形变换的非线性SVM示例的二维示意图。在这个示例中，我们假设每个点为
    $\left({a}_{k},{b}_{k}\right)$，并将数据转换到一个新的特征空间，定义为 $c=\sqrt{{a}_{k}^{2}+{b}_{k}^{2}}$（圆形变换）；因此，决策边界在输入空间（即
    $a-b$ 空间）中呈圆形，但在特征空间（$c$ 空间）中呈线形。
- en: 'There are two standard regularisation parameters for SVM: C-SVM and Nu-SVM
    (Scholkopf & Smola, [2001](#bib.bib61)) methods. Both C and Nu are the parameter
    of regularisation which are related to the number of support vectors and the number
    of misclassification. The range of C can be any positive value, but the range
    of Nu is limited to 0 and 1 which is easier to control.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 对于SVM，有两个标准的正则化参数：C-SVM和Nu-SVM（Scholkopf & Smola，[2001](#bib.bib61)）方法。C和Nu都是正则化参数，与支持向量的数量和分类错误的数量相关。C的范围可以是任何正值，但Nu的范围限制在0到1之间，较易控制。
- en: '![Refer to caption](img/4d1e91fb892fad0889988c503b1b50c1.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4d1e91fb892fad0889988c503b1b50c1.png)'
- en: 'Figure 19: Illustration of the linear and non-linear SVM method. Different
    markers represent two different classifications. Top: linear SVM. Bottom Left:
    non-linear SVM in input space. Bottom Right: non-linear SVM in feature space (kernel
    space).'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：线性和非线性支持向量机（SVM）方法的示意图。不同的标记表示两种不同的分类。顶部：线性SVM。左下：输入空间中的非线性SVM。右下：特征空间（核空间）中的非线性SVM。
