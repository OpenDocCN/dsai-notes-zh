- en: 'Machine Learning 1: Lesson 5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 机器学习1：第5课
- en: 原文：[https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-5-df45f0c99618](https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-5-df45f0c99618)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: '[原文](https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-5-df45f0c99618)'
- en: '*My personal notes from* [*machine learning class*](http://forums.fast.ai/t/another-treat-early-access-to-intro-to-machine-learning-videos/6826/1)*.
    These notes will continue to be updated and improved as I continue to review the
    course to “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '*我从*[*机器学习课程*](http://forums.fast.ai/t/another-treat-early-access-to-intro-to-machine-learning-videos/6826/1)*中得到的个人笔记。随着我继续复习课程以“真正”理解它，这些笔记将继续更新和改进。非常感谢*[*Jeremy*](https://twitter.com/jeremyphoward)
    *和*[*Rachel*](https://twitter.com/math_rachel) *给了我这个学习的机会。*'
- en: '[Video](https://youtu.be/3jl2h9hSRvc)'
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: '[视频](https://youtu.be/3jl2h9hSRvc)'
- en: Review
  id: totrans-4
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 复习
- en: Test sets , training sets, validation sets and OOB
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 测试集，训练集，验证集和OOB
- en: We have a dataset with bunch of rows in it and we’ve got some dependent variable.
    What is the difference between machine learning and any other kind of work? The
    difference is that in machine learning, the thing we care about is the generalization
    accuracy or the generalization error where else, in pretty much in everything
    else, all we care about is how well we could map to the observations. So this
    thing about generalization is the key unique piece of machine learning. And if
    we want to know whether we are doing a good job of machine learning, we need to
    know whether we are doing a good job of generalizing. If we don’t know that, we
    know nothing.
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: 我们有一个数据集，其中有很多行，我们有一些因变量。机器学习和其他任何工作之间的区别是什么？区别在于，在机器学习中，我们关心的是泛化准确性或泛化错误，而在其他几乎所有情况下，我们只关心我们能够如何将观察结果映射到。所以，泛化是机器学习的关键独特部分。如果我们想知道我们是否做得好，我们需要知道我们是否做得好泛化。如果我们不知道这一点，我们什么也不知道。
- en: '**Question**: By generalizing, do you mean scaling? Being able to scale larger?
    [[1:26](https://youtu.be/3jl2h9hSRvc?t=1m26s)] No, I don’t mean scaling at all.
    Scaling is an important thing in many areas. It’s like okay we’ve got something
    that works on my computer with 10,000 items, I now need to make it work on 10,000
    items per second. So scaling is important but not just for machine learning but
    for just about everything we put in production. Generalization is where I say
    okay, here is a model that can predict cats from dogs. I’ve looked at five pictures
    of cats and five pictures of dogs, and I’ve built a model that is perfect. Then
    I look at a different set of five cats and dogs, and it gets them all wrong. So
    in that case, what it learned was not the difference between a cat and a dog,
    but it learnt what those five exact cats looked like and what those five exact
    dogs looked like. Or I built a model of predicting grocery sales for a particular
    product, so for toilet rolls in New Jersey last month, and then I go and put it
    into production and it scales great (in other words, a great latency, no high
    CPU load) but it fails to predicting anything other than toilet rolls in New Jersey.
    It also turns out it only did it well for last month, not the next month. So these
    are all generalization failures.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：泛化，你是指缩放吗？能够扩展吗？[[1:26](https://youtu.be/3jl2h9hSRvc?t=1m26s)] 不，我一点也不是指缩放。缩放在许多领域中是重要的。就像好吧，我们有一个在我的电脑上使用1万个项目的东西，现在我需要让它每秒处理1万个项目。所以缩放很重要，但不仅仅是对于机器学习，而是对于我们投入生产的几乎所有东西都很重要。泛化是我说的，好吧，这是一个可以预测猫和狗的模型。我看了五张猫的图片和五张狗的图片，我建立了一个完美的模型。然后我看了另一组五只猫和狗，结果全都错了。所以在这种情况下，它学到的不是猫和狗之间的区别，而是学到了那五只具体的猫长什么样，那五只具体的狗长什么样。或者我建立了一个预测特定产品的杂货销售模型，比如上个月新泽西的卫生纸销售，然后我把它投入生产，它扩展得很好（换句话说，延迟很低，没有高CPU负载），但它无法预测除了新泽西的卫生纸之外的任何东西。事实证明，它只在上个月做得好，而不是下个月。这些都是泛化失败。'
- en: The most common way that people check for the ability to generalize is to create
    a random sample. So they will grab a few rows at random and pull it out into a
    test set. Then they will build all of their models on the rest of the rows and
    then when they are finished, they will check that the accuracy they got on the
    test set (the rest of the rows are called the training set). So at the end of
    their modeling process, on the training set, they got an accuracy of 99% of predicting
    cats from dogs, at the very end, they check it against a test set to make sure
    that the model really does generalize.
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 人们检查泛化能力最常见的方法是创建一个随机样本。他们会随机选择几行数据并将其提取到一个测试集中。然后他们会在其余的行上构建所有模型，当他们完成时，他们会检查在测试集上获得的准确性（其余的行被称为训练集）。所以在建模过程结束时，在训练集上，他们得到了99%的准确性，预测猫和狗，最后，他们会将其与测试集进行比较，以确保模型真正泛化。
- en: Now the problem is, what if it doesn’t? Well, I could go back and change some
    hyper parameters, do some data augmentation, whatever else trying to create a
    more generalizable model. And then I’ll go back again after doing all that, and
    check and it’s still no good. I’ll keep doing this again and again until eventually,
    after fifty attempts, it does generalize. But does it really generalize? Because
    maybe all I’ve done is accidentally found this one which happens to work just
    for that test set because I’ve tried fifty different things. So if I’ve got something
    which is right coincidentally 5% of the time, they are not very likely to accidentally
    get a good result. So what we generally do is we put aside a second dataset (validation
    set). Then everything that’s not in the validation or test is now training. What
    we do is we train a model, check it against the validation to see if it generalizes,
    do that a few times. Then when we finally got something we think will generalize
    successfully based on the validation set (at the end of the project), we check
    it against the test set.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 现在的问题是，如果不行怎么办？嗯，我可以回去改变一些超参数，做一些数据增强，或者尝试创建一个更具泛化性的模型。然后我再次回去，做了所有这些之后，检查结果仍然不好。我会一遍又一遍地这样做，直到最终，在尝试了五十次之后，它泛化了。但它真的泛化了吗？因为也许我所做的一切只是偶然找到了这个恰好适用于那个测试集的模型，因为我尝试了五十种不同的方法。所以如果我有一个东西，巧合地5%的时间是正确的，那么很可能不会偶然得到一个好的结果。所以我们通常会将第二个数据集（验证集）放在一边。然后，不在验证集或测试集中的所有内容现在都是训练集。我们训练一个模型，对其进行验证以查看其是否泛化，重复几次。然后当我们最终得到了我们认为会根据验证集成功泛化的东西（在项目结束时），我们会对其进行测试。
- en: '**Question**: So basically by making this two layer test set validation set,
    if it gets one right the other wrong, you are kind of double checking your errors?
    [[5:19](https://youtu.be/3jl2h9hSRvc?t=5m19s)] It’s checking that we haven’t overfit
    to the validation set. So if we are using the validation set again and again,
    then we could end up not coming up with a generalizable sort of hyper parameters
    but a set of hyper parameters that just so happened to work on the training set
    and the validation set. So if we try 50 different models against the validation
    set and then at the end of all that, we then check that against the test set and
    it’s still generalized as well, then we are going to say okay that’s good we’ve
    actually come up with generalizable model. If it doesn’t, then that’s going to
    say we’ve actually now overfit to the validation set. At that point, you are kind
    of in trouble. Because you don’t have anything left behind. So the idea is to
    use effective techniques during the modeling so that doesn’t happen. But if it’s
    going to happen, you want to find out about it — you need that test set to be
    there because otherwise when you put it in production and then it turns out that
    it doesn’t generalize, that would be a really bad outcome. You’ll end up with
    less people clicking on your ads or selling less of your products, or providing
    car insurance to very risky vehicles.'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：所以基本上通过制作这两层测试集和验证集，如果一个对了另一个错了，你就是在双重检查你的错误？它检查我们是否过度拟合验证集。所以如果我们一遍又一遍地使用验证集，那么我们最终可能得不到一组适用于训练集和验证集的可泛化的超参数，而只是一组恰好适用于训练集和验证集的超参数。所以如果我们对验证集尝试了50种不同的模型，然后在所有这些之后，我们再对测试集进行检查，结果仍然是泛化的，那么我们会说好的，我们实际上已经得到了一个可泛化的模型。如果不是，那么就会说我们实际上现在过度拟合了验证集。在那一点上，你会陷入麻烦。因为你没有留下任何东西。所以想法是在建模过程中使用有效的技术，以防止这种情况发生。但如果它确实发生了，你希望找出原因——你需要那个测试集，否则当你投入生产时，结果却不能泛化，那将是一个非常糟糕的结果。你最终会发现点击你的广告的人会减少，或者销售你的产品会减少，或者为高风险车辆提供汽车保险的人会减少。
- en: '**Question**: So just to make sure, do we need to ever check if the validation
    set and the test set are coherent or you just keep test set?[[6:43](https://youtu.be/3jl2h9hSRvc?t=6m43s)]
    So if you’ve done what I’ve just done here which is to randomly sample, there
    is no particular reason to check as long as they are big enough. But we will come
    back to your question in a different context in just moment.'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 问题：所以只是为了确保，我们需要检查验证集和测试集是否一致，还是只保留测试集？如果你像我刚刚做的那样随机抽样，没有特定的原因需要检查，只要它们足够大。但我们将在稍后的不同情境中回答你的问题。
- en: Another trick we’ve learnt for random forest is a way of not needing a validation
    set [[7:10](https://youtu.be/3jl2h9hSRvc?t=7m10s)]. And the way we learnt was
    to use, instead, the OOB score. This idea was to say every time we train a tree
    in a random forest, there is a bunch of observations that are held out anyway
    because that’s how we get some of the randomness. So let’s calculate our score
    for each tree based on those held out samples and therefore the forest by averaging
    the trees that each row was not part of training. So the OOB score gives us something
    which is pretty similar to the validation score, but on average it’s a little
    less good. Why? Because every row is going to be using a subset of the trees to
    make its prediction, and with less trees, we know we get a less accurate prediction.
    So that’s a subtle one and if you didn’t get it, have a think during the week
    until you understand why this is because it’s a really interesting test of your
    understanding of random forests. Why is OOB score on average less good than your
    validation score? They are both using random held-out subsets.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 我们学到的另一个随机森林的技巧是一种不需要验证集的方法。我们学到的方法是使用OOB分数。这个想法是，每次我们在随机森林中训练一棵树时，都会有一些观察结果被保留，因为这就是我们获得一些随机性的方式。因此，让我们基于这些保留样本计算每棵树的分数，然后通过对每行不参与训练的树进行平均，得到整个森林的分数。因此，OOB分数给我们提供了与验证分数非常相似的东西，但平均来看，它稍微差一些。为什么？因为每一行都将使用一部分树来进行预测，而树越少，我们知道预测就越不准确。这是一个微妙的问题，如果你没有理解，那就在这一周内考虑一下，直到你明白为什么，因为这是对你对随机森林理解的一个非常有趣的测试。为什么OOB分数平均来看比你的验证分数差一些？它们都使用随机保留的子集。
- en: Anyway, it’s generally close enough [[11:06](https://youtu.be/3jl2h9hSRvc?t=11m6s)].
    So why have a validation set at all when you are using random forests? If it’s
    a randomly chosen validation set, it’s not strictly speaking necessary but you’ve
    got like four levels of things to test — so you could test on the OOB, when that’s
    working well, you can test on the validation set, and hopefully by the time you
    check against the test set, there’s going to be no surprises so that’ll be one
    good reason.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 总的来说，这通常足够了。那么在使用随机森林时为什么还要有一个验证集呢？如果是一个随机选择的验证集，严格来说并不是必需的，但你有四个层次的测试——所以你可以在OOB上测试，当那个工作良好时，你可以在验证集上测试，希望到检查测试集时不会有什么意外，这将是一个很好的理由。
- en: 'What Kaggle do, the way they do this, is kind of clever. What Kaggle do is
    they split the test set into two pieces: a public and a private. And they don’t
    tell you which is which. So you submit your predictions to Kaggle and then a random
    30% of those are used to tell you the leaderboard score. But then at the end of
    the competition, that gets thrown away and they use the other 70% to calculate
    your real score. So what that’s doing is that you are making sure that you are
    not continuously using that feedback from the leaderboard to figure out some set
    of hyper parameters that happens to do well on the public that actually doesn’t
    generalize. So it’s a great test. This is one of the reasons why it’s good practice
    to use Kaggle because at the end of a competition, at some point this will happen
    to you, and you’ll drop a hundred places on the leaderboard the last day of the
    competition when they use the private test set and say oh okay, that’s what it
    feels like to overfit and it’s much better to practice and get that sense there
    than it is to do it in a company where there’s hundreds of millions of dollars
    on the line.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: Kaggle的做法是相当聪明的。Kaggle的做法是将测试集分成两部分：一个公共部分和一个私有部分。他们不告诉你哪个是哪个。所以你将你的预测提交给Kaggle，然后随机选择其中30%用来告诉你排行榜分数。但是在比赛结束时，这部分将被丢弃，他们将使用另外70%来计算你的真实分数。这样做的目的是确保你不会持续使用来自排行榜的反馈来找出一组在公共部分表现良好但实际上不具有泛化性的超参数。这是一个很好的测试。这也是为什么在比赛结束时使用Kaggle是一个很好的做法的原因之一，因为在比赛的最后一天，当他们使用私有测试集时，你的排名会下降一百名，然后你会明白，这就是过拟合的感觉，练习和获得这种感觉要比在公司中有数亿美元的风险要好得多。
- en: This is like the easiest possible situation where you are able to use a random
    sample for your validation set [[12:55](https://youtu.be/3jl2h9hSRvc?t=12m55s)].
    Why might I not be able to use a random sample from my validation or possibly
    fail? My claim is that by using a random validation set, we could get totally
    the wrong idea about our model. important thing to remember is when you build
    a model, you always have a systematic error which is that you’re going to use
    the model at a later time than the time you built it. You’re going to put it into
    production by which time the world is different to the world that you are in now
    and even when you’re building the model, you’re using data which is older than
    today anyway. So there’s some lag between the data that you are building it on
    and the data that it’s going to actually be used on in real life. And a lot of
    the time, if not most of the time, that matters.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 这就像是可能的最简单情况，你可以使用一个随机样本作为你的验证集。为什么我可能无法使用一个随机样本作为我的验证集，或者可能失败呢？我的观点是，通过使用一个随机验证集，我们可能会对我们的模型完全产生错误的看法。要记住的重要事情是，当你构建一个模型时，你总是会有一个系统误差，即你将在比构建模型时晚的时间使用该模型。你将在生产中使用它，到那时，世界已经不同于你现在所处的世界，即使在构建模型时，你使用的数据也比今天的数据旧。因此，在你构建模型的数据和实际使用的数据之间存在一些滞后。大部分时间，如果不是大部分时间，这是很重要的。
- en: 'So if we are predicting who is going to buy toilet paper in New Jersey and
    it takes us two weeks to put it in production and we did it using data from the
    last couple of years and by that time, things may look very different. And particularly
    our validation set, if we randomly sampled it, and it was from a four year period,
    then the vast majority of the data is going to be over a year old. And it may
    be that the toilet paper buying habits of folks in New Jersey may have dramatically
    shifted. Maybe they’ve got a terrible recession there now and they can’t afford
    a high-quality toilet paper anymore. Or maybe they know their paper making industry
    has gone through the roof and suddenly they are buying a lot more toilet paper
    because it’s so cheap. So the world changes and therefore if you use a random
    sample for your validation set, then you are actually checking how good are you
    at predicting things that are totally obsolete now? How good are you at predicting
    things that happened four years ago? That’s not interesting. So what we want to
    do in practice, anytime there is some temporal piece is to instead say assuming
    that we’ve ordered it by time, we’ll use the latest portion as our validation
    set. I suppose, actually do it properly:'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我们正在预测谁会在新泽西购买卫生纸，而我们需要两周时间将其投入生产，并且我们使用了过去几年的数据进行预测，那时情况可能会大不相同。特别是我们的验证集，如果我们随机抽样，而且是从四年的时间段中抽取的，那么绝大多数数据将是一年多以前的。也许新泽西人的购买习惯可能已经发生了巨大变化。也许他们现在正经历着严重的经济衰退，无法再购买高质量的卫生纸。或者也许他们的造纸工业飞速发展，突然间他们购买更多卫生纸，因为价格便宜。世界在变化，因此如果你为验证集使用随机样本，那么实际上你正在检查你在预测完全过时的事物方面有多好？你有多擅长预测四年前发生的事情？这并不有趣。因此，在实践中，每当有一些时间因素时，我们要做的是假设我们已经按时间排序，我们将使用最新的部分作为我们的验证集。我想，实际上应该正确地执行：
- en: '![](../Images/c4f153983c2108eddb42bd5a032ebdf6.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/c4f153983c2108eddb42bd5a032ebdf6.png)'
- en: That’s our validation set, and that’s our test set. So the rest is our training
    set and we use that and we try and be able to model that still works on stuff
    that’s later in time than anything the model was built on. So we are not just
    testing generalization in some kind of abstract sense but in a very specific time
    sense which is it generalizes to the future.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我们的验证集，这是我们的测试集。所以剩下的就是我们的训练集，我们使用它并尝试能够建立一个模型，使其仍然适用于比模型建立时更晚的时间。因此，我们不仅仅是在某种抽象意义上测试泛化性能，而是在一个非常具体的时间意义上，即它是否能泛化到未来。
- en: '**Question**: As you said, there is some temporal ordering in the data, so
    in that case, is it wise to take the entire data for training or only a few recent
    dataset for training [[19:07](https://youtu.be/3jl2h9hSRvc?t=19m7s)]? Yeah, that
    is a whole other question. So how do you get the validation set to be good? So
    I build a random forest on all the training data. It looks good on the training
    data, it looks good on OOB. And this is actually a really good reason to have
    OOB. If it looks good on the OOB then it means you are not overfitting in a statistical
    sense. It’s working well on a random sample. But then it looks bad on the validation
    set. So what happened? Well, what happened was that you somehow failed to predict
    the future. You only predicted the past so Suraj had an idea about how we could
    fix that. Okay, well, maybe we should just train so maybe we shouldn’t use the
    whole training set. We should try a recent period only. Now on the downside, we
    are now using less data so we can create less rich models, on the upside, it’s
    more up-to-date data. And this is something you have to play around with. Most
    machine learning functions have the ability to provide a weight that is given
    to each row. So for example, with a random forest, rather than bootstrapping at
    random, you could have a weight on every row and randomly pick that row with some
    probability. So we could put probability such that the most recent rows have a
    higher probability of being selected. That can work really well. It’s something
    that you have to try and if you don’t have a validation set that represents the
    future compared to what you are training on, you have no way to know which of
    your techniques are working.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：正如您所说，数据中存在一些时间顺序，那么在这种情况下，是明智地使用整个数据进行训练，还是只使用最近的一些数据集进行训练？是的，这是一个完全不同的问题。那么如何确保验证集的质量良好呢？我在所有训练数据上构建了一个随机森林。它在训练数据上看起来不错，在OOB上也看起来不错。这实际上是有OOB的一个很好的原因。如果在OOB上看起来不错，那么这意味着你在统计意义上没有过拟合。它在一个随机样本上表现良好。但是然后在验证集上看起来不好。那么发生了什么？嗯，发生的是你在某种程度上未能预测未来。你只是预测了过去，所以Suraj有一个关于如何解决这个问题的想法。好吧，也许我们应该只训练，也许我们不应该使用整个训练集。我们应该只尝试最近的一段时间。现在缺点是，我们现在使用的数据更少，因此我们可以创建更少的丰富模型，但好处是，这是更为最新的数据。这是你必须尝试的事情。大多数机器学习函数都有能力为每一行提供一个权重。例如，对于随机森林，你可以在每一行上设置一个权重，并以某种概率随机选择该行。因此，我们可以设置概率，使得最近的行有更高的被选中的概率。这可能非常有效。这是你必须尝试的事情，如果你没有一个代表未来的验证集，与你正在训练的数据相比，你就无法知道哪些技术是有效的。'
- en: How do you make the compromise between amount of data vs. recency of data? What
    I tend to do is when I have this kind of temporal issue, which is probably most
    of the time, once I have something that’s working well on the validation set,
    I wouldn’t then go and just use that model on the test set because the test set
    is much farther in the future compared to the training set. So I would then replicate
    building that model again but this time I would combine the training and validation
    sets together and retrain the model. At that point, you’ve got no way to test
    against a validation set, so you have to make sure you have a reproducible script
    or notebook that does exactly the same steps in exactly the same ways because
    if you get something wrong then you’re going to find on the test set that you’ve
    got a problem. So what I do in practice is I need to know if my validation set
    is a truly representative of the test set. So what I do is I build five models
    on the training set, and I try to have them vary in how good I think they are.
    Then I score my five models on the validation set and then I also score them on
    the test set. So I’m not cheating since I’m not using any feedback from the test
    set to change my hyper parameters — I’m only using it for this one thing which
    is to check my validation set. So I get my five scores from the validation set
    and test set and then I check that they fall in a line. If they don’t, then you’re
    not going to get good enough feedback from the validation set. So keep doing that
    process until you’re getting a line and that can be quite tricky . Trying to create
    something that’s as similar to the real-world outcome as possible is difficult.
    And in the real world, the same is true of creating the test set — the test set
    has to be as close to production as possible. So what’s the actual mix of customers
    that are going to be using this, how much time is there actually going to be between
    when you build the model and when you put it in production? How often you are
    going to be able to refresh the model? These are all the things to think about
    when you build that test set.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 你如何在数据量和数据新旧之间做出妥协？我倾向于这样做，当我遇到这种时间问题时，也许大部分时间都是这样，一旦我在验证集上找到了一个表现良好的模型，我就不会直接在测试集上使用那个模型，因为测试集比训练集要远得多。所以我会重新构建那个模型，但这次我会将训练和验证集合并起来重新训练模型。在那一点上，你没有办法对验证集进行测试，所以你必须确保你有一个可重现的脚本或笔记本，以确保完全相同的步骤，因为如果你出错了，你会发现在测试集上出现了问题。所以我在实践中所做的是，我需要知道我的验证集是否真正代表了测试集。所以我在训练集上建立了五个模型，并尝试让它们在我认为它们有多好的方面有所不同。然后我在验证集上对我的五个模型进行评分，然后我也在测试集上对它们进行评分。所以我没有作弊，因为我没有使用来自测试集的任何反馈来改变我的超参数——我只是用它来检查我的验证集。所以我从验证集和测试集中得到了五个分数，然后我检查它们是否在一条线上。如果不是，那么你将无法从验证集中获得足够好的反馈。所以继续这个过程，直到你得到一条线，这可能会很棘手。试图创建尽可能接近真实结果的东西是困难的。在现实世界中，创建测试集也是如此——测试集必须尽可能接近生产。那么实际使用这个产品的客户组合是什么样的，你构建模型和投入生产之间实际会有多少时间？你能够多频繁地更新模型？这些都是在构建测试集时需要考虑的事情。
- en: '**Question**: So first you build five models on the training data and if you
    didn’t get a straight-line relationship, change your validation and test set [[24:01](https://youtu.be/3jl2h9hSRvc?t=24m1s)]?
    You can’t really change the test set generally, so this is assuming that the test
    set is given and you change the validation set. So if you start with a random
    sample validation set and then it’s all over the place and you realize oh I should
    have picked the last two months. Then you pick the last two months and it’s still
    going all over the place and you realize oh I should have picked it so that it’s
    also from the first of the month to the fifteenth of the month, and keep changing
    the validation set until you found a set which is indicative of your test set
    results.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：所以首先你在训练数据上建立了五个模型，如果没有得到直线关系，就改变你的验证和测试集？通常你不能真正改变测试集，所以这是假设测试集已经给定，你改变验证集。所以如果你开始用一个随机样本验证集，然后结果千奇百怪，你意识到哦，我应该选择最近的两个月。然后你选择了最近的两个月，结果还是千奇百怪，你意识到哦，我应该选择从每个月的第一天到第十五天，然后不断改变验证集，直到找到一个能够反映你的测试集结果的集合。'
- en: '**Question**: For five models, you start with maybe just random data, average,
    etc [[24:45](https://youtu.be/3jl2h9hSRvc?t=24m45s)]? Maybe five not terrible
    ones but you want some variety and you also particularly want some variety in
    how well they might generalize through time. So one that was trained on the whole
    training set, one was trained on the last two weeks, one that was trained on the
    last six week, one which used lots and lots of columns and might over fit a bit
    more. So you want to get a sense of if my validation set fails to generalize temporarily,
    I’d want to see that, if it fails to generalize statistically, I’d want to see
    that.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：对于五个模型，你可能从随机数据、平均值等开始？也许不是五个糟糕的模型，但你想要一些变化，尤其是你想要一些在时间上可能泛化得更好的模型。一个是在整个训练集上训练的，一个是在最后两周训练的，一个是在最后六周训练的，一个使用了很多列可能会过拟合一些。所以你想要知道如果我的验证集在时间上无法泛化，我想看到这一点，如果在统计上无法泛化，我也想看到这一点。'
- en: '**Question**: Can you explain a bit more in detail what you mean by change
    your validation set so it indicates the test set? What does that look like [[25:28](https://youtu.be/3jl2h9hSRvc?t=25m28s)]?
    Let’s take the groceries competitions where we are trying to predict the next
    two weeks of grocery sales. The possible validation set that Terrance and I played
    with was:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：你能详细解释一下你所说的改变验证集以使其表示测试集是什么意思吗？看起来是什么样子？让我们以杂货竞赛为例，我们试图预测接下来两周的杂货销售额。Terrance和我尝试过的可能的验证集是：'
- en: Random sample (4 years)
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 随机样本（4年）
- en: Last month of data (July 15–August 15)
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 最近一个月的数据（7月15日至8月15日）
- en: Last 2 weeks (August 1–15)
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 过去的两周（8月1日至15日）
- en: Same day range one month earlier (July 15–30)
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 一个月前的同一天范围（7月15日至30日）
- en: The test set in this competition was the 15th to the 30th of the August. So
    above were four different validation sets we tried. With random, our results were
    all over the place. With last month, they were not bad but not great. The last
    two weeks, there was a couple that didn’t look good but on the whole they were
    good. The same day range a month earlier, they’ve got a basically perfect line.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 这个比赛中的测试集是8月15日至30日。所以上面是我们尝试的四个不同的验证集。随机的结果是完全不稳定的。上个月的结果不错但也不是很好。过去的两周，有一些看起来不好，但总体上还不错。一个月前的同一天范围内，他们有一个基本完美的线。
- en: '**Question**: What exactly are we comparing it to from the test set [[26:58](https://youtu.be/3jl2h9hSRvc?t=26m58s)]?
    I build 5 models, so there might be 1\. just predict the average, 2\. do some
    kind of simple group mean of the whole data set, 3\. do some group mean over the
    last month of the data, 4\. build a random forests of the whole thing, 5, build
    random forest from the last three weeks. On each of those, I calculate the validation
    score. Then I retrain the model on the whole training set and calculate the same
    thing on the test set. So each of these points now tells me how well did it go
    on the validation set and how well did it go in the test set. If the validation
    set is useful, we would say every time the validation score set improves, the
    test set score should also improve.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：我们到底是在与测试集中的什么进行比较？我建立了5个模型，可能是1.只是预测平均值，2.对整个数据集进行某种简单的组平均，3.对过去一个月的数据进行某种组平均，4.构建整个数据集的随机森林，5.从过去三周构建随机森林。在每一个上，我计算验证分数。然后我在整个训练集上重新训练模型，并在测试集上进行相同的计算。所以现在每个点告诉我它在验证集上表现如何，它在测试集上表现如何。如果验证集有用，我们会说每次验证分数提高，测试集分数也应该提高。'
- en: '**Question** : When you say “re-train” do you mean re-train the model on training
    and validation set [[27:50](https://youtu.be/3jl2h9hSRvc?t=27m50s)]? Yes, so once
    I’ve got the validation score based on just the training set, then retrain it
    on the train and validation and check against the test set.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：当你说“重新训练”时，你是指在训练和验证集上重新训练模型吗？是的，所以一旦我得到了基于训练集的验证分数，然后在训练和验证集上重新训练，并与测试集进行对比。'
- en: '**Question**: By test set, do you mean submitting it to Kaggle and check the
    score? If it’s Kaggle, then your test set is Kaggle’s leader board. In the real
    world, the test set is this third data set you put aside. It’s that third dataset
    that having it reflect real world production differences is the most important
    step in a machine learning project. Why is it the most important step? Because
    if you screw up everything else but you don’t screw up that, you’ll know you screwed
    up. If you’ve got a good test set, then you’ll know you screwed up because you
    screwed up something else and you tested it and it didn’t work out, it’s okay.
    You’re not going to destroy the company. If you screwed up creating the test set,
    that would be awful. Because then you don’t know if you’ve made a mistake. You
    try to build a model, you test it on the test set and it looks good. But the test
    set was not indicative of real-world environment. So you don’t actually know if
    you are going to destroy the company. Hopefully you’ve got ways to put things
    into production gradually so you won’t actually destroy the company but you’ll
    at least destroy your reputation at work. Oh, Jeremy tried to put this thing into
    production and in the first week the cohort we tried it on, their sales halved
    and we’re never gonna give Jeremy a machine learning job again. But if Jeremy
    had used a proper test set then he would have known, uh-oh this is half as good
    as my validation set said it would be, I’ll keep trying. Now I’m not going to
    get in any trouble. I was actually like oh, Jeremy is awesome — he identifies
    ahead of time when there’s going to be a generalization problem.'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：通过测试集，你是指将其提交到Kaggle并检查分数吗？如果是Kaggle，那么你的测试集就是Kaggle的排行榜。在现实世界中，测试集是你放在一边的第三个数据集。这第三个数据集反映真实世界生产差异是机器学习项目中最重要的一步。为什么这是最重要的一步？因为如果你搞砸了其他一切但没有搞砸这个，你会知道你搞砸了。如果你有一个好的测试集，那么你会知道你搞砸了，因为你搞砸了其他东西并测试了它，结果不尽人意，没关系。你不会毁掉公司。如果你搞砸了创建测试集，那将是可怕的。因为那样你就不知道自己是否犯了错误。你尝试构建一个模型，你在测试集上测试它，看起来不错。但测试集并不代表真实世界环境。所以你实际上不知道你是否会毁掉公司。希望你有逐渐将事物投入生产的方式，这样你就不会真的毁掉公司，但至少会毁掉你在工作中的声誉。哦，Jeremy试图将这个东西投入生产，在第一周我们尝试的队伍中，他们的销售额减半了，我们再也不会让Jeremy做机器学习工作了。但如果Jeremy使用了适当的测试集，那么他会知道，哦，这只有我的验证集说的一半好，我会继续尝试。现在我不会惹麻烦了。我实际上很喜欢Jeremy
    - 他能提前识别出将会出现泛化问题的情况。'
- en: This is something everybody talks about a little bit in machine learning classes
    but often it stops at the point where you learned that there is a thing in sklearn
    called make `train_test_split` and it returns these things and off you go, or
    here is the cross-validation function [[30:10](https://youtu.be/3jl2h9hSRvc?t=30m10s)].
    The fact that these things always give you random samples tells you that much
    if not most of the time, you shouldn’t be using them. The fact that random forest
    gives you an OOB for free, it’s useful but only tells you that this generalizes
    in a statistical sense, not in a practical sense.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 这是每个人在机器学习课程中都会谈论一点的事情，但通常停在你学到了sklearn中有一个叫做make `train_test_split`的东西，它返回这些东西，然后你就可以继续了，或者这里是交叉验证函数。这些东西总是给你随机样本的事实告诉你，如果不是大部分时间，你不应该使用它们。随机森林免费提供OOB，这很有用，但只告诉你这在统计意义上是泛化的，而不是在实际意义上。
- en: Cross validation [[30:54](https://youtu.be/3jl2h9hSRvc?t=30m54s)]
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 交叉验证
- en: Outside of class, you guys have been talking about a lot which makes me feel
    somebody’s been over emphasizing the value of this technique. So I’ll explain
    what cross-validation is and then I explain why you probably shouldn’t be using
    it most of the time.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在课外，你们一直在讨论很多，这让我觉得有人一直在过分强调这种技术的价值。所以我会解释什么是交叉验证，然后解释为什么你大部分时间可能不应该使用它。
- en: Cross validation says let’s not just pull out one validation set, but let’s
    pull out five, for example. So let’s assume that we’re going to randomly shuffle
    the data first of all. This is critical.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 交叉验证意味着我们不只是拿出一个验证集，而是拿出五个，例如。所以让我们首先假设我们要随机洗牌数据。这是至关重要的。
- en: Randomly shuffle the data.
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 随机洗牌数据。
- en: Split it into five groups
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 将其分成五组
- en: For model №1, we will call the first one the validation set, and the bottom
    four the training set.
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 对于模型 №1，我们将第一个称为验证集，底部四个称为训练集。
- en: We will train and we will check against the validation and we get some RMSE,
    R², etc.
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将训练并检查验证，得到一些RMSE、R²等。
- en: We will repeat that five times, and we will take the average of RMSE, R², etc,
    and that is a cross-validation average accuracy.
  id: totrans-40
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 我们将重复这个过程五次，然后取RMSE、R²等的平均值，这是交叉验证的平均准确度。
- en: What is the benefit of using cross-validation over a standard validation set
    I talked about before? You can use all of the data. You don’t have to put anything
    aside. And you get a little benefit as well in that you’ve now got five models
    that you could ensemble together, each one used 80% of the data. So sometimes
    that ensemble can be helpful.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 使用交叉验证相比标准验证集的好处是什么？你可以使用所有的数据。你不必留下任何东西。而且你还有一个小小的好处，你现在有了五个模型，可以将它们组合在一起，每个模型使用了80%的数据。有时这种集成可以很有帮助。
- en: What could be some reasons that you wouldn’t use cross-validation? For large
    dataset, it will take a long time. We have to fit five models rather than one,
    so time is a key downside. If we are doing deep learning and it takes a day to
    run, suddenly it takes five days or we need 5 GPUs. What about my earlier issues
    about validation sets? Our earlier concerns about why random validation sets are
    a problem are entirely relevant here. These validation sets are random, so if
    a random validation set is not appropriate for your problem, most likely because,
    for example, of temporal issues then none of these five validation sets are any
    good. They are all random. So if you have temporal data like we did before, there’s
    no way to do cross validation or no good way to do cross validation. You want
    to have your validation set to be as close to the test set as possible, and you
    can’t do that by randomly sampling different things. You may well not need to
    do cross validation because most of the time in the real world, we don’t really
    have that little data — unless your data is based on some very very expensive
    labeling process or some experiments that cost a lot to run, etc. But nowadays,
    data scientists are not very often doing that kind of work. Some are, in which
    case this is an issue, but most of us aren’t. So we probably don’t need to. If
    we do do it, it’s going to take a whole a lot of time, then even if we did do
    it and we took up all that time, it might give us totally the wrong answer because
    random validation sets are inappropriate for our probblem.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 有哪些原因你不会使用交叉验证呢？对于大型数据集，它会花费很长时间。我们必须拟合五个模型而不是一个，所以时间是一个关键的缺点。如果我们在进行深度学习，需要一天的时间来运行，突然之间需要五天，或者我们需要5个GPU。那么关于我之前关于验证集的问题呢？我们之前对为什么随机验证集是一个问题的担忧在这里完全相关。这些验证集是随机的，所以如果一个随机验证集对你的问题不合适，很可能是因为，例如，时间问题，那么这五个验证集都不好。它们都是随机的。所以如果你有像之前一样的时间数据，就没有办法进行交叉验证，或者没有好的方法进行交叉验证。你希望你的验证集尽可能接近测试集，而你不能通过随机抽样不同的东西来做到这一点。你可能不需要进行交叉验证，因为在现实世界中，我们通常并没有那么少的数据
    —— 除非你的数据是基于一些非常昂贵的标记过程或一些昂贵的实验。但如今，数据科学家并不经常做这种工作。有些人在做，如果是这样，那么这是一个问题，但我们大多数人不是。所以我们可能不需要。即使我们这样做了，它会花费很多时间，即使我们这样做了并花费了所有的时间，它可能会给我们完全错误的答案，因为随机验证集对我们的问题是不合适的。
- en: I’m not going to be spending much time on cross validation because I think it’s
    an interesting tool to have, it’s easy to use (sklearn has a cross validation
    thing you can use), but it’s not that often that it’s going to be an important
    part of your toolbox in my opinion. It’ll come up sometimes. So that is validation
    sets.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 我不会花太多时间在交叉验证上，因为我认为它是一个有趣的工具，易于使用（sklearn有一个可以使用的交叉验证工具），但在我看来，它并不经常是你工具箱中的重要部分。有时会用到。所以这就是验证集。
- en: Tree interpretation [[38:02](https://youtu.be/3jl2h9hSRvc?t=38m2s)]
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 树解释[[38:02](https://youtu.be/3jl2h9hSRvc?t=38m2s)]
- en: 'What does tree interpreter do and how does it do it? Let’s start with the output
    of tree interpreter [[38:51](https://youtu.be/3jl2h9hSRvc?t=38m51s)]. Here is
    a single tree:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 树解释器是做什么的，它是如何做到的呢？让我们从树解释器的输出开始[[38:51](https://youtu.be/3jl2h9hSRvc?t=38m51s)]。这里是一棵树：
- en: '![](../Images/765db675f664a2bce60cbc7fe6307f92.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/765db675f664a2bce60cbc7fe6307f92.png)'
- en: The root of the tree is before there’s been any split at all. So 10.189 is the
    average log price of all of the options in our training set. Then if I go `Coupler_System
    ≤ 0.5`, then we get an average of 10.345 (the subset of 16815). Off the people
    with `Coupler_System ≤0.5`, we then take the subset where `Enclosure ≤ 2.0` and
    average log price there is 9.955\. Then the final step is `ModelID ≤ 4573.0` and
    that gives us 10.226.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 树的根在任何分割之前。因此，10.189是我们训练集中所有选项的平均对数价格。然后，如果我选择 `Coupler_System ≤ 0.5`，那么我们得到一个平均值为10.345（共16815个子集）。在
    `Coupler_System ≤0.5` 的人中，我们然后取 `Enclosure ≤ 2.0` 的子集，那里的平均对数价格为9.955。然后最后一步是
    `ModelID ≤ 4573.0`，这给我们10.226。
- en: '![](../Images/f6cadf323e5c2862cd75b5bdc4b03bc0.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/f6cadf323e5c2862cd75b5bdc4b03bc0.png)'
- en: We can then calculate the change in average log price by each additional criteria.
    We can draw that as what’s called a waterfall plot. Waterfall plots are one of
    the most useful plots I know about and weirdly enough, there’s nothing in Python
    to do them. This is one of these things where there’s this disconnect between
    the world of management consulting and business where everybody uses waterfall
    plots all the time and academia who have no idea what these things are. Every
    time you have a starting point and a number of changes and a finishing point,
    waterfall charts are pretty much always the best way to show it.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 然后我们可以计算每个额外标准对平均对数价格的变化。我们可以将其绘制为所谓的瀑布图。瀑布图是我知道的最有用的图之一，奇怪的是，Python 中没有任何工具可以绘制它们。这是其中一种情况，管理咨询和商业领域中每个人都经常使用瀑布图，而学术界却不知道这些是什么。每当你有一个起点、一些变化和一个终点时，瀑布图几乎总是展示它们的最佳方式。
- en: '![](../Images/4ba7c2df232997d01f2f2f798998bbc7.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/4ba7c2df232997d01f2f2f798998bbc7.png)'
- en: With Excel 2016, it’s build-in. You just click insert waterfall chart and there
    it is. If you want to be a hero, create a waterfall chart package for matplotlib,
    put it on pip, and everybody will love you for it. These are actually super easy
    to build. You basically do a stacked column plot where the bottom of this is all
    white. You can kind of do it but if you can wrap that up, put the points in the
    right spots and color them nicely, that would be totally awesome. I think you’ve
    all got the skills to do it, and would be a terrific thing for your portfolio.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Excel 2016 中，它是内置的。你只需点击插入瀑布图，它就在那里。如果你想成为一个英雄，为 matplotlib 创建一个瀑布图包，将其放在
    pip 上，每个人都会喜欢你的。实际上，这些非常容易构建。你基本上做一个堆叠柱状图，底部全是白色。你可以做到这一点，但如果你能整理好它，把点放在正确的位置并精心着色，那将是非常棒的。我认为你们都有能力做到，这对你的作品集来说将是一件了不起的事情。
- en: In general, they are going from all, then going through each change, then the
    sum of all of those is going to be equal to the final prediction [[43:38](https://youtu.be/3jl2h9hSRvc?t=43m38s)].
    So if we were just doing a decision tree and someone asks “how come this particular
    auction’s prediction was this particular price?”, this is how you can answer “because
    these three things had these three impacts”.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，它们从所有开始，然后逐个变化，然后所有这些的总和将等于最终预测[[43:38](https://youtu.be/3jl2h9hSRvc?t=43m38s)]。所以如果我们只是做一个决策树，有人问“为什么这个特定拍卖的预测是这个特定价格？”，这就是你可以回答“因为这三个事物产生了这三个影响”的方式。
- en: For a random forest, we could do that across all of the trees. So every time
    we see coupler, we add up that change. Every time we see enclosure, we add up
    that change, and so on. Then we combine them all together, we get what tree interpreter
    does. So you could go into the source code for tree interpreter and it’s not at
    all complex logic. Or you could build it yourself and you can see how it does
    exactly this.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对于随机森林，我们可以在所有树中执行相同的操作。所以每次我们看到联接器时，我们累加那个变化。每次我们看到围栏时，我们累加那个变化，依此类推。然后将它们全部组合在一起，我们就得到了树解释器的功能。所以你可以查看树解释器的源代码，它并不是非常复杂的逻辑。或者你可以自己构建它，看看它是如何做到这一点的。
- en: '[PRE0]'
  id: totrans-54
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'So when you go `treeinterpreter.predict` with a random forest model for some
    specific auction (in this case it’s zero index row), it tells you:'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 所以当你使用随机森林模型对某个特定拍卖进行 `treeinterpreter.predict` 时（在这种情况下是零索引行），它告诉你：
- en: '`prediction`: the same as the random forest prediction'
  id: totrans-56
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`prediction`: 与随机森林预测相同'
- en: '`bias`: this is going to be always the same — it’s the average sale price for
    everybody for each of the random samples in the tree'
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`偏差`: 这将始终是相同的 - 这是树中每个随机样本的每个人的平均销售价格'
- en: '`contributions`: the total of all the contributions for each time we see that
    specific column appear in a tree.'
  id: totrans-58
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`contributions`: 每次我们在树中看到特定列出现时所有贡献的总和。'
- en: '[PRE1]'
  id: totrans-59
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: The last time I made a mistake of not sorting this correctly. so this time `np.argsort`
    is a super handy function. It doesn’t actually sort `contributions[0]`, it just
    tells you where each item would move to if it were sorted. So now by passing `idxs`
    to each one of the column, the level, and contribution , I can then print out
    all those in the right order.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 上次我犯了一个错误，没有正确排序这个。所以这次 `np.argsort` 是一个非常方便的函数。它实际上并不对 `contributions[0]` 进行排序，它只是告诉你如果对其进行排序，每个项目将移动到哪里。所以现在通过将
    `idxs` 传递给每个列、级别和贡献，我可以按正确的顺序打印出所有这些。
- en: '[PRE2]'
  id: totrans-61
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: So small piece of industrial equipment meant that it was less expensive. If
    it was made pretty recently meant that was more expensive, etc. So this is not
    going to really help you much at all with Kaggle where you just need predictions.
    But it’s going to help you a lot in a production environment or even pre production.
    So something which any good manager should do if you say here is a machine learning
    model I think we should use is they should go away and grab a few example of actual
    customers or actual auctions and check whether your model looks intuitive. If
    it says my prediction is that lots of people are going to really enjoy this crappy
    movie, and it is like “wow, that was a really crappy movie” then they’re going
    to come back to you and say “explain why your model is telling me that I’m going
    to like this movie because I hate that movie”. Then you can go back and say well,
    it’s because you like this movie and because you’re this age range and you’re
    this gender, and on average actually people like you did like that movie.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 所以小型工业设备意味着它更便宜。如果它是最近制造的，那就意味着更昂贵，等等。所以这实际上对 Kaggle 不会有太大帮助，因为你只需要预测。但在生产环境甚至是预生产阶段，这将对你有很大帮助。所以任何一个好的经理应该做的事情是，如果你说这里有一个机器学习模型，我认为我们应该使用它，他们应该离开并抓取一些实际客户或实际拍卖的例子，检查你的模型是否看起来直观。如果它说我的预测是很多人会真的喜欢这部糟糕的电影，而实际上是“哇，那是一部真的糟糕的电影”，那么他们会回来问你“解释一下为什么你的模型告诉我我会喜欢这部电影，因为我讨厌那部电影”。然后你可以回答说，这是因为你喜欢这部电影，因为你是这个年龄段，你是这个性别，平均而言，实际上像你这样的人确实喜欢那部电影。
- en: '**Question**: What’s the second element of each tuple [[47:25](https://youtu.be/3jl2h9hSRvc?t=47m25s)]?
    This is saying for this particular row, ‘ProductSize’ was ‘Mini’, and it was 11
    years old, etc. So it’s just feeding back and telling you. Because this is actually
    what it was:'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：每个元组的第二个元素是什么[[47:25](https://youtu.be/3jl2h9hSRvc?t=47m25s)]？这是说对于这一行，''ProductSize''是''Mini''，它已经11岁了，等等。所以它只是反馈并告诉你。因为这实际上就是它的样子：'
- en: '[PRE3]'
  id: totrans-64
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: It was these numbers. So I just went back to the original data to actually pull
    out the descriptive versions of each one.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 就是这些数字。所以我只是回到原始数据中实际提取出每个描述性版本。
- en: So if we sum up all the contributions together, and then add them to the bias,
    then that would give us the final prediction.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 所以如果我们把所有的贡献加在一起，然后加到偏差中，那将给我们最终的预测。
- en: '[PRE4]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: This is an almost totally unknown technique and this particular library is almost
    totally unknown as well. So it’s a great opportunity to show something that a
    lot of people don’t know. It’s totally critical in my opinion but rarely done.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个几乎完全未知的技术，这个特定的库也几乎完全未知。所以这是一个展示很多人不知道的东西的绝佳机会。在我看来，这是非常关键的，但很少有人这样做。
- en: So this is kind of the end of the random forest interpretation piece and hopefully
    you’ve now seen enough that when somebody says we can’t use modern machine learning
    techniques because they are black boxes that aren’t interpretable, you have enough
    information to say you are full of crap. They are extremely interpretable and
    the stuff that we’ve just done — trying to do that with a linear model, good luck
    to you. Even where you can do something similar with a linear model, trying to
    do it so that is not giving you totally the wrong answer and you had no idea it’s
    a wrong answer is going to be a real challenge.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 所以这基本上是随机森林解释部分的结束，希望你现在已经看到足够多，当有人说我们不能使用现代机器学习技术，因为它们是不可解释的黑匣子时，你有足够的信息来说你是在胡说。它们是非常可解释的，我们刚刚做的事情——试图用线性模型做到这一点，祝你好运。即使你可以用线性模型做类似的事情，试图做到不给你完全错误答案并且你不知道它是错误答案将是一个真正的挑战。
- en: Extrapolation [[49:23](https://youtu.be/3jl2h9hSRvc?t=49m23s)]
  id: totrans-70
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 外推[[49:23](https://youtu.be/3jl2h9hSRvc?t=49m23s)]
- en: The last step we are going to do before we try and build our own random forest
    is to deal with this tricky issue of extrapolation. So in this case, if we look
    at the accuracy of our recent trees, we still have a big difference between our
    validation score and our training score.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们尝试构建自己的随机森林之前，我们要做的最后一步是处理这个棘手的外推问题。所以在这种情况下，如果我们看一下我们最近树的准确性，我们仍然在我们的验证分数和训练分数之间有很大的差异。
- en: '![](../Images/bb86638bde04fb34da0a4ac67e16e973.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb86638bde04fb34da0a4ac67e16e973.png)'
- en: 'Actually, in this case, the difference between the OOB (0.89420) and the validation
    (0.89319) is actually pretty close. So if there was a big difference, I’d be very
    worried about whether we’ve dealt with the temporal side of things correctly.
    Here is the most recent model:'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，在这种情况下，OOB（0.89420）和验证（0.89319）之间的差异实际上非常接近。所以如果有很大的差异，我会非常担心我们是否正确处理了时间方面的问题。这是最近的模型：
- en: '![](../Images/9a0ab597e234a6d7f66adce0d8ca03e3.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9a0ab597e234a6d7f66adce0d8ca03e3.png)'
- en: On Kaggle, you need that last decimal place. In real world, I probably stopped
    here. But quite often you’ll see there’s a big difference between your validation
    score and your OOB score, and I want to show you how you would deal with that
    particularly because we know that the OOB score should be a little worse because
    it’s using less trees so it gives me a sense that we should get to do a little
    bit better. The way we should be able to do a little bit better is by handling
    the time component a little bit better.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在Kaggle上，你需要那个最后的小数点。在现实世界中，我可能会停在这里。但很多时候你会看到你的验证分数和OOB分数之间有很大的差异，我想向你展示如何处理这个问题，特别是因为我们知道OOB分数应该稍微差一点，因为它使用的树较少，所以这让我感觉我们应该做得更好一点。我们应该能够做得更好一点的方法是更好地处理时间组件。
- en: Here is the problem with random forests when it comes to extrapolation. When
    you’ve got a dataset that got four years of sales data in it, and you create your
    tree and it says if it’s in some particular store and some particular item and
    it is on special, here is the average price. And it actually tells us the average
    price over the whole training set which could be pretty old. So when you then
    want to step forward to what is going to be the price next month, it’s never seen
    next month. Where else with a linear model, it can find a relationship between
    time and price where even though we only had this much data, when you then go
    and predict something in the future, it can extrapolate that. But a random forest
    can’t do that. If you think about it, there is no way for a tree to be able to
    say well next month, it would be higher still. So there is a few ways to deal
    with this and we’ll talk about it over the next couple of lessons, but one simple
    way is just to try to avoid using time variables as predictors if there’s something
    else we could use that’s going to give us a better or stronger relationship that’s
    actually going to work in the future [[52:19](https://youtu.be/3jl2h9hSRvc?t=52m19s)].
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 当涉及外推时，随机森林存在问题。当你有一个包含四年销售数据的数据集时，你创建了你的树，它说如果它在某个特定的商店和某个特定的物品上特价，这里是平均价格。它实际上告诉我们整个训练集上的平均价格，这可能相当古老。所以当你想要向前迈进到下个月的价格时，它从未见过下个月。而线性模型可以找到时间和价格之间的关系，即使我们只有这么多数据，当你预测未来的某事时，它可以外推。但是随机森林做不到这一点。如果你考虑一下，树无法说下个月价格会更高。所以有几种处理这个问题的方法，我们将在接下来的几堂课中讨论，但一个简单的方法就是尽量避免使用时间变量作为预测因子，如果有其他东西可以使用，可以给我们更好或更强的关系，那实际上会在未来起作用[[52:19](https://youtu.be/3jl2h9hSRvc?t=52m19s)]。
- en: So in this case, what I wanted to do was to first of all figure out what’s the
    difference between our validation set and our training set. If I understand the
    difference between our validation set and our training set, then that tells me
    what are the predictors which have a strong temporal component and therefore they
    may be irrelevant by the time I get to the future time period. So I do something
    really interesting which is I create a random forest where my dependent variable
    is “is it in the validation set” (`is_valid`). I’ve gone back and I’ve got my
    whole data frame with the training and validation all together and I’ve created
    a new column called `is_valid` which I’ve set to one and then for all of the stuff
    in the training set, I set it to zero. So I’ve got a new column which is just
    is this in the validation set or not and then I’m going to use that as my dependent
    variable and build a random forest. This is a random forest not to predict price
    but predict is this in the validation set or not. So if your variable were not
    time dependent, then it shouldn’t be possible to figure out if something is in
    the validation set or not.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，在这种情况下，我想要做的第一件事是弄清楚我们的验证集和训练集之间的差异。如果我了解我们的验证集和训练集之间的差异，那么这告诉我哪些预测变量具有强烈的时间成分，因此到了未来时间段可能是无关紧要的。因此，我做了一些非常有趣的事情，我创建了一个随机森林，其中我的因变量是“是否在验证集中”（`is_valid`）。我回去拿到了整个数据框，包括训练和验证全部在一起，然后我创建了一个新列叫做`is_valid`，我将其设置为1，然后对于所有在训练集中的东西，我将其设置为0。因此，我有了一个新列，只是这个是否在验证集中，然后我将其用作我的因变量并构建一个随机森林。这是一个随机森林，不是为了预测价格，而是为了预测这是否在验证集中。因此，如果您的变量不是时间相关的，那么应该不可能弄清楚某样东西是否在验证集中。
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: This is a great trick in Kaggle because they often won’t tell you whether the
    test set is a random sample or not. So you could put the test set and training
    set together, create a new column called `is_test` and see if you can predict
    it. If you can, you don’t have a random sample which means you have to figure
    out how to create a validation set from it.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 这是Kaggle中的一个很棒的技巧，因为他们通常不会告诉您测试集是否是随机样本。因此，您可以将测试集和训练集放在一起，创建一个新列叫做`is_test`，看看您是否可以预测它。如果可以，那么您就没有一个随机样本，这意味着您必须弄清楚如何从中创建一个验证集。
- en: '[PRE6]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: In this case, I can see I don’t have a random sample because my validation set
    can be predicted with a .9999 R².
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，我可以看到我没有一个随机样本，因为我的验证集可以用0.9999的R²来预测。
- en: So then if I look at feature importance, the top thing is `SalesID` [[54:36](https://youtu.be/3jl2h9hSRvc?t=54m36s)].
    So this is really interesting. It tells us very clearly `SalesID` is not a random
    identifier but probably it’s something that’s just set consecutively as time goes
    on — we just increase the `SalesID`. `saleElapsed` was the number of days since
    the first date in our dataset so not surprisingly that also is a good predictor.
    Interestingly `MachineID` — clearly each machine is being labeled with some consecutive
    identifier as well and then there’s a big drop in importance, so we’ll stop here.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，如果我查看特征重要性，最重要的是`SalesID`[[54:36](https://youtu.be/3jl2h9hSRvc?t=54m36s)]。这非常有趣。它清楚地告诉我们`SalesID`不是一个随机标识符，而可能是随着时间的推移而连续设置的某些东西——我们只是增加`SalesID`。`saleElapsed`是自我们数据集中第一个日期以来的天数，因此不足为奇，它也是一个很好的预测变量。有趣的是`MachineID`——显然每台机器也被标记为一些连续的标识符，然后重要性大幅下降，所以我们就到此为止。
- en: '[PRE7]'
  id: totrans-83
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '![](../Images/a692ee826e44d034c4c389ddb819a6f7.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/a692ee826e44d034c4c389ddb819a6f7.png)'
- en: Let’s next grab those top three and we can then have a look at their values
    both from the training set and in the validation set. [[55:22](https://youtu.be/3jl2h9hSRvc?t=55m22s)]
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来让我们获取前三个，然后我们可以查看它们在训练集和验证集中的值。[[55:22](https://youtu.be/3jl2h9hSRvc?t=55m22s)]
- en: '[PRE8]'
  id: totrans-86
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '![](../Images/927ade0892b7e4ac5ed43e9df0334faf.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/927ade0892b7e4ac5ed43e9df0334faf.png)'
- en: '[PRE9]'
  id: totrans-88
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '![](../Images/5550478d44046e76f333581c005dbce5.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/5550478d44046e76f333581c005dbce5.png)'
- en: We can see for example, SalesID on average is 1.8 million in the training set
    and 5.8 million in the validation set (notice that the value is divided by 1000).
    So you can confirm they are very different.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我们可以看到，销售ID在训练集中平均为180万，在验证集中为580万（请注意该值已除以1000）。因此，您可以确认它们是非常不同的。
- en: So let’s drop them.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 所以让我们把它们删除。
- en: '[PRE10]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: So after I drop them, let’s now see if I can predict whether something is in
    the validation set. I still can with 0.98 R².
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在我删除它们之后，现在让我们看看我是否可以预测某样东西是否在验证集中。我仍然可以用0.98的R²来预测。
- en: '[PRE11]'
  id: totrans-94
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '![](../Images/9836d21c99139fb67f800888ef76da83.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/9836d21c99139fb67f800888ef76da83.png)'
- en: Once you remove some things, then other things can come to the front, and it
    now turns out that not surprisingly age — things that are old are more likely
    to be in the validation set because earlier on in the training set, they can’t
    be that old yet. YearMade for the same reason. So then we can try removing those
    as well — `SalesID`, `saleElapsed`, `MachineID` from the first one, `age`, `YearMade`,
    and `saleDayofyear` from the second one. They are all time dependent features.
    I still want them in my random forest if they are important. But if they are not
    important, then taking them out if there are some other none-time dependent variables
    that work just as well — that would be better. Because now I am going to have
    a model that generalizes over time better.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦您删除了一些东西，其他东西就会浮现出来，现在显然老年——年龄较大的东西更有可能在验证集中，因为在训练集中的早期阶段，它们还不可能那么老。YearMade也是同样的原因。因此，我们也可以尝试删除这些——从第一个中删除`SalesID`、`saleElapsed`、`MachineID`，从第二个中删除`age`、`YearMade`和`saleDayofyear`。它们都是与时间有关的特征。如果它们很重要，我仍然希望它们出现在我的随机森林中。但如果它们不重要，那么如果有其他一些非时间相关的变量效果一样好——那将更好。因为现在我将拥有一个更好地泛化时间的模型。
- en: '[PRE12]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: So here, I’m just going to go through each one of those features and drop each
    one, one at a time, retrain a new random forest, and print out the score [[57:19](https://youtu.be/3jl2h9hSRvc?t=57m19s)].
    Before we do any of that, our score was 0.88 for validation, 0.89 for OOB. And
    you can see below, when I remove SalesID, my score goes up. This is what we were
    hoping for. We’ve removed a time dependent variable, there were other variables
    that could find similar relationships without the time dependency. So removing
    it caused our validation to go up. Now OOB didn’t go up, because this is genuinely
    statistically a useful predictor, but it’s a time dependent one and we have a
    time dependent validation set. So this is really subtle but it can be really important.
    It’s trying to find the things that gives you a generalizable-across-time prediction
    and here is how you can see it.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 所以在这里，我将逐个查看这些特征并逐个删除，重新训练一个新的随机森林，并打印出分数。在我们做任何这些之前，我们的验证分数是0.88，OOB是0.89。你可以看到，当我删除SalesID时，我的分数上升了。这正是我们所希望的。我们删除了一个时间相关的变量，还有其他变量可以找到类似的关系而不依赖于时间。因此，删除它导致我们的验证分数上升。现在OOB没有上升，因为这实际上在统计上是一个有用的预测变量，但它是一个时间相关的变量，我们有一个时间相关的验证集。这是非常微妙的，但它可能非常重要。它试图找到能够提供跨时间泛化预测的因素，这里是你可以看到的方式。
- en: '[PRE13]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: We should remove `SalesID` for sure, but `saleElapsed` didn’t get better, so
    we don’t want. `MachineID` did get better — 0.888 to 0.893 so it’s actually quite
    a bit better. `age` got a bit better. `YearMade` got worse, `saleDayofyear` got
    a bit better.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 我们肯定应该删除`SalesID`，但`saleElapsed`没有变得更好，所以我们不想要。`MachineID`变得更好了-从0.888到0.893，所以实际上好了很多。`age`有点变好了。`YearMade`变得更糟了，`saleDayofyear`有点变好了。
- en: '[PRE14]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE14]'
- en: So now we can say, let’s get rid of the three where we know that getting rid
    of it actually made it better. And as a result, we are now up to .915! So we got
    rid of three time dependent things and now as expected our validation is better
    than our OOB.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们可以说，让我们摆脱那三个我们知道摆脱它实际上使它变得更好的东西。因此，我们现在达到了0.915！所以我们摆脱了三个时间相关的因素，现在如我们所料，我们的验证比OOB更好。
- en: '[PRE15]'
  id: totrans-103
  prefs: []
  type: TYPE_PRE
  zh: '[PRE15]'
- en: So that was a super successful approach there, and now we can check the feature
    importance.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 所以那是一个非常成功的方法，现在我们可以检查特征的重要性。
- en: '[PRE16]'
  id: totrans-105
  prefs: []
  type: TYPE_PRE
  zh: '[PRE16]'
- en: '![](../Images/474f880db65e91ac289aa57aab5deebb.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/474f880db65e91ac289aa57aab5deebb.png)'
- en: '[PRE17]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE17]'
- en: Let’s go ahead and say alright, that was pretty darn good. Let’s now leave it
    for a while so give it 160 trees, let it chew on it, and see how that goes.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们继续说好吧，那真是相当不错。现在让它静置一段时间，给它160棵树，让它消化一下，看看效果如何。
- en: Our final model!
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 我们的最终模型！
- en: '[PRE18]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE18]'
- en: As you can see, we did all of our interpretation, all of our fine-tuning basically
    with smaller models/subsets and at the end, we run the whole thing. And it actually
    still only took 16 seconds and so we’ve now got an RMSE of 0.21\. Now we can check
    that against Kaggle. Unfortunately, this is an older competition and we are not
    allowed to enter anymore to see how we would have gone. So the best we can do
    is check whether it looks like we could have done well based on their validation
    set so it should be in the right area. Based on that, we would have come first.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，我们进行了所有的解释，所有的微调基本上都是用较小的模型/子集进行的，最后，我们运行了整个过程。实际上，这只花了16秒，所以我们现在的RMSE是0.21。现在我们可以将其与Kaggle进行比较。不幸的是，这是一个较旧的比赛，我们不允许再参加，看看我们会取得怎样的成绩。所以我们能做的最好的就是检查它是否看起来我们可能会根据他们的验证集做得很好，所以应该在正确的范围内。根据这一点，我们本来会得第一名。
- en: I think this is an interesting series of steps. So you can go through the same
    series of steps in your Kaggle projects and more importantly, your real-world
    projects. One of the challenges is once you leave this learning environment, suddenly
    you are surrounded by people who never have enough time, they always want you
    to be in a hurry, they’re always telling you do this and then do that. You need
    to find the time to step away and go back because this is a genuine real-world
    modeling process you can use. And it gives, when I said gives world-class results,
    I mean it. The guy who won this, Leustagos, sadly he passed away but he is the
    top Kaggle competitor of all time. He won I believe dozens of competitions so
    if we can get a score even within cooee of him, then we are doing really well.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 我认为这是一系列有趣的步骤。所以你可以在你的Kaggle项目和更重要的是你的现实世界项目中按照相同的步骤进行。其中一个挑战是一旦你离开这个学习环境，突然间你周围都是从来没有足够时间的人，他们总是希望你赶快，他们总是告诉你这样做然后那样做。你需要找到时间远离一下然后回来，因为这是一个你可以使用的真正的现实世界建模过程。当我说它提供了世界级的结果时，我的意思是真的。赢得这个比赛的人，Leustagos，不幸地去世了，但他是有史以来最顶尖的Kaggle竞争者。我相信他赢得了数十个比赛，所以如果我们能够得到一个甚至接近他的分数，那么我们做得真的很好。
- en: '**Clarification** [[1:01:31](https://youtu.be/3jl2h9hSRvc?t=1h1m31s)]: The
    change in R² between these two is not just due to the fact that we removed these
    three predictors. We also went `reset_rf_samples()` . So to actually see the impact
    of just removing, we need to compare it to the final step earlier.'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: '**澄清**：这两者之间R²的变化不仅仅是因为我们删除了这三个预测因子。我们还进行了`reset_rf_samples()`。因此，要真正看到仅仅删除的影响，我们需要将其与之前的最终步骤进行比较。'
- en: '![](../Images/bb918a228059a483c993a32b6f8c7b3e.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/bb918a228059a483c993a32b6f8c7b3e.png)'
- en: So it’s actually compared to 0.907 validation. So removing those three things
    took us from 0.907 to 0.915\. In the end, of course, what matters is our final
    model but just to clarify.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上与0.907的验证相比。因此，删除这三个因素使我们的分数从0.907提高到0.915。最终，当然最重要的是我们的最终模型，但只是澄清一下。
- en: Writing Random Forest from scratch! [[1:02:31](https://youtu.be/3jl2h9hSRvc?t=1h2m31s)]
  id: totrans-116
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从头开始编写随机森林！
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson3-rf_foundations.ipynb)'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '[笔记本](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson3-rf_foundations.ipynb)'
- en: My original plan here was to do it in real time and then as I started to do
    it, I realized that would have been boring, so instead, we might do more of a
    walk through the code together.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 我的原始计划是实时进行，但当我开始做的时候，我意识到那样会很无聊，所以，我们可能会一起更多地走一遍代码。
- en: Implementing random forest algorithm is actually quite tricky not because the
    code is tricky [[1:05:03](https://youtu.be/3jl2h9hSRvc?t=1h5m3s)]. Generally speaking,
    most random forest algorithms are pretty conceptually easy. Generally speaking,
    academic papers and books have a knack of making them look difficult, but they
    are not difficult conceptually. What’s difficult is getting all the details right
    and knowing when you’re right. In other words, we need a good way of doing testing.
    So if we are going to reimplement something that already exists, like say we want
    to create a random forest in some different framework, different language, different
    operating system, I would always start with something that does exist. So in this
    case, we’re just going to do it as learning exercise, writing a random forest
    in Python, so for testing, I’m going to compare it to an existing random forest
    implementation.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 实现随机森林算法实际上是相当棘手的，不是因为代码很棘手。一般来说，大多数随机森林算法在概念上都很容易。一般来说，学术论文和书籍往往让它们看起来很困难，但从概念上讲并不困难。困难的是把所有细节搞对，知道什么时候是对的。换句话说，我们需要一种好的测试方法。因此，如果我们要重新实现已经存在的东西，比如说我们想在一些不同的框架、不同的语言、不同的操作系统中创建一个随机森林，我总是从已经存在的东西开始。因此，在这种情况下，我们只是把它作为学习练习，用Python编写一个随机森林，因此为了测试，我将把它与现有的随机森林实现进行比较。
- en: That’s critical. Anytime you are doing anything involving non-trivial amounts
    of code in machine learning, knowing whether you’ve got it right or wrong is the
    hardest bit. I always assume that I’ve screwed everything up at every step, and
    so I’m thinking okay assuming that I screwed it up, how do I figure out that I
    screwed it up. Then much to my surprise from time to time, I actually get something
    right and then I can move on. But most of the time, I get it wrong, so unfortunately
    with machine learning, there’s a lot of ways you can get things wrong that don’t
    give you an error. They just make your result slightly less good and so that’s
    what you you want to pick up.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 这是至关重要的。每当你在涉及机器学习中的非平凡量的代码时，知道你是对还是错是最困难的部分。我总是假设在每一步都搞砸了一切，所以我在想，好吧，假设我搞砸了，我怎么知道我搞砸了。然后令我惊讶的是，有时候我实际上做对了，然后我可以继续。但大多数时候，我做错了，所以不幸的是，对于机器学习来说，有很多方法可以让你出错，而不会给你错误。它们只会让你的结果稍微不那么好，这就是你想要发现的。
- en: '[PRE19]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE19]'
- en: So given that I want to compare it to an existing implementation, I’m going
    to use our existing dataset, our existing validation set, and then to simplify
    things, I’m just going to use two columns to start with [[1:06:44](https://youtu.be/3jl2h9hSRvc?t=1h6m44s)].
    So let’s go ahead and start writing a random forest.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，考虑到我想要将其与现有实现进行比较，我将使用我们现有的数据集，我们现有的验证集，然后为了简化事情，我只会从两列开始。因此，让我们继续开始编写一个随机森林。
- en: '[PRE20]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE20]'
- en: 'My way of writing nearly all code is top-down just like my teaching. So by
    top-down, I start by assuming that everything I want already exists. In other
    words, the first thing I want to do, I’m going to call this a tree ensemble. To
    create a random forest, the first question I have is what do I need to pass in.
    What do I need to initialize my random forest. I’m going to need:'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 我写代码的方式几乎都是自顶向下的，就像我的教学一样。因此，从顶部开始，我假设我想要的一切都已经存在。换句话说，我想要做的第一件事是，我将称之为树集合。要创建一个随机森林，我首先要问的问题是我需要传入什么。我需要初始化我的随机森林。我将需要：
- en: '`x`: some independent variables'
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`x`：一些自变量'
- en: '`y`: some dependent variable'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`y`：一些因变量'
- en: '`n_trees`: pick how many trees I want'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_trees`：选择我想要的树的数量'
- en: '`sample_sz`: I’m going to use the sample size parameter from the start here,
    so how big you want each sample to be'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`sample_sz`：我将从一开始使用样本大小参数，因此您希望每个样本有多大'
- en: '`min_leaf`: then maybe some optional parameter of what’s the smallest leaf
    size.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`min_leaf`：然后可能是一些可选参数，表示最小叶子大小。'
- en: '[PRE21]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE21]'
- en: 'For testing, it’s nice to use a constant random seed, so we’ll get the same
    result each time. So `np.random.seed(42)` is how you set a random seed. Maybe
    it’s worth mentioning for those of you who aren’t familiar with it, random number
    generators on computers aren’t random at all. They are actually called pseudo
    random number generators and what they do is given some initial starting point
    (in this case 42), a pseudo random number generator is a mathematical function
    that generates a deterministic (always the same) sequence of numbers such that
    those numbers are designed to be:'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 对于测试，最好使用一个固定的随机种子，这样每次都会得到相同的结果。`np.random.seed(42)`是设置随机种子的方法。也许值得一提的是，对于那些不熟悉的人来说，计算机上的随机数生成器根本不是随机的。它们实际上被称为伪随机数生成器，它们的作用是在给定一些初始起点（在这种情况下是42）的情况下，生成一系列确定性（始终相同）的数字，这些数字被设计为：
- en: as uncorrelated with the pervious number as possible
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能与前一个数字不相关
- en: as unpredictable as possible
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能不可预测
- en: as uncorrelated as possible with something with a different random seed (so
    the second number in the sequence starting with 42 should be very different to
    the second number starting with 41)
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 尽可能与具有不同随机种子的东西不相关（因此以42开头的序列中的第二个数字应该与以41开头的序列中的第二个数字非常不同）
- en: And generally, they involve using big prime numbers, taking mods, and stuff
    like that. It’s an interesting area of math. If you want real random numbers,
    the only way to do that is you can actually buy hardware called a hardware random
    number generator that’ll have inside them like a little bit of some radioactive
    substance and something that detects how many things it’s spitting out or there’ll
    be some hardware thing.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，它们涉及使用大素数，取模等等。这是一个有趣的数学领域。如果你想要真正的随机数，唯一的方法就是你可以购买一种叫做硬件随机数生成器的硬件，里面会有一点放射性物质，以及一些检测它输出了多少东西的东西，或者会有一些硬件设备。
- en: '**Question**: Is current system time a valid random number generation [[1:09:25](https://youtu.be/3jl2h9hSRvc?t=1h9m25s)]?
    So that would be maybe for a random seed (the thing we start the function with).
    One of the really interesting area is in your computer, if you don’t set the random
    seed, what is it set to. Quite often, people use the current time for security
    — obviously we use a lot of random number stuff for security, like if you are
    generating an SSH key, it needs to be random. It turns out people can figure out
    roughly when you created a key. They could look at oh, `id_rsa` has a timestamp
    and they could try all the different nanoseconds starting points for a random
    number generator around that timestamp and figure out your key. So in practice,
    a lot of high randomness requiring applications actually have a step that say
    “please move your mouse and type random stuff at the keyboard for a while” and
    so it gets you to be a source of “entropy”. Other approach is they’ll look at
    the hash of some of your log files or stuff like that. It’s a really really fun
    area.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：当前系统时间是否是有效的随机数生成器[[1:09:25](https://youtu.be/3jl2h9hSRvc?t=1h9m25s)]？这可能是一个随机种子（我们用来启动函数的东西）。一个非常有趣的领域是，在您的计算机中，如果您没有设置随机种子，它会被设置为什么。通常，人们会使用当前时间来确保安全性
    - 显然，我们在安全方面使用了很多随机数，比如如果您正在生成SSH密钥，它需要是随机的。事实证明，人们可以大致确定您创建密钥的时间。他们可以查看`id_rsa`的时间戳，然后尝试在该时间戳周围的所有不同纳秒起始点上尝试随机数生成器，并找出您的密钥。因此，在实践中，许多需要高度随机性的应用程序实际上都有一步说“请移动鼠标并在键盘上输入一段时间的随机内容”，这样就可以让您成为“熵”的来源。另一种方法是他们会查看一些日志文件的哈希值或类似的东西。这是一个非常有趣的领域。'
- en: In our case, our purpose actually is to remove randomness [[1:10:48](https://youtu.be/3jl2h9hSRvc?t=1h10m48s)].
    So we are saying okay, generate a series of pseudo random numbers starting with
    42, so it always should be the same.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的情况下，我们的目的实际上是消除随机性[[1:10:48](https://youtu.be/3jl2h9hSRvc?t=1h10m48s)]。所以我们说，好吧，生成一系列以42开始的伪随机数，所以它应该始终相同。
- en: If you haven’t done much stuff in Python OO, this is basically standard idiom
    at least I write it this way, most people don’t, but if you pass in five things
    that you are going to want to keep inside this object, then you basically have
    to say `self.x = x`, etc. We can assign to a tuple from a tuple.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 如果您在Python面向对象方面没有做过太多事情，这基本上是标准习语，至少我是这样写的，大多数人不这样写，但是如果您传入五个要保存在此对象内部的东西，那么您基本上必须说`self.x
    = x`，等等。我们可以从元组中赋值给元组。
- en: '![](../Images/b50c5cfec00ef768509952835719b1ac.png)'
  id: totrans-139
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/b50c5cfec00ef768509952835719b1ac.png)'
- en: This is my way of coding. Most people thing this is horrible, but I prefer to
    be able to see everything at once and so I know in my code anytime I see something
    that looks like this, it’s always all of the stuff in the method being set. If
    I did it a different way, then half of the code now come off the bottom of the
    page and you can’t see it.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我的编码方式。大多数人认为这很糟糕，但我更喜欢一次看到所有东西，这样我就知道在我的代码中，每当我看到类似这样的东西时，它总是在方法中设置的所有内容。如果我以不同的方式做，那么现在一半的代码会从页面底部消失，你就看不到了。
- en: So that was the first thing I thought about — to create a random forest what
    information do you need. Then I’m going to need to store that information inside
    my object, and then I need to create some trees. A random forest is something
    that has some trees. So I basically figured to use list comprehension to create
    a list of trees. How many trees do we have? We got `n_trees` trees. That’s what
    we asked for. `range(n_trees)` gives me the numbers from 0 up to `n_trees — 1`.
    So if I create a list comprehension that loops through that range calling `create_tree`
    each time, I now have `n_trees` trees.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 这是我考虑的第一件事 - 要创建一个随机森林，您需要哪些信息。然后我需要将该信息存储在我的对象内部，然后我需要创建一些树。随机森林是一些树的集合。因此，我基本上想到使用列表推导来创建一组树。我们有多少棵树？我们有`n_trees`棵树。这就是我们要求的。`range(n_trees)`给我从0到`n_trees-1`的数字。因此，如果我创建一个列表推导，循环遍历该范围，每次调用`create_tree`，我现在有了`n_trees`棵树。
- en: To write that, I didn’t have to think at all. That’s all obvious. So I’ve delayed
    the thinking to the point where it’s like well wait, we don’t have something to
    create a tree. Okay, no worries. But let’s pretend we did. If we did, we’ve now
    created a random forest. we’d still need to do a few things on top of that. For
    example, once we have it we need a predict function. Okay, let’s write a predict
    function. How do you predict in a random forest? For a particular row (or rows),
    go through each tree, calculate its prediction. So here is a list comprehension
    that is calculating the prediction for every tree for `x`. I don’t know if `x`
    is one row or multiple rows, it doesn’t matter as long as `tree.predict` works
    on it. And once you’ve got a list of things, a cool thing to know is you can pass
    `numpy.mean` a regular non numpy list and it will take the mean — you just need
    to tell it `axis=0` means average across the lists. So this is going to return
    the average of `.predict()` for each tree.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 为了写这个，我根本不用思考。这一切都是显而易见的。所以我把思考推迟到了这一点，就像好吧，我们没有东西来创建一棵树。好吧，没关系。但让我们假装我们有。如果我们有了，我们现在创建了一个随机森林。我们仍然需要在此基础上做一些事情。例如，一旦我们有了它，我们需要一个预测函数。好的，让我们写一个预测函数。在随机森林中如何进行预测？对于特定的行（或行），遍历每棵树，计算其预测。因此，这里是一个列表推导，它正在为`x`的每棵树计算预测。我不知道`x`是一行还是多行，这并不重要，只要`tree.predict`对其起作用。一旦你有了一系列东西，要知道的一个很酷的事情是你可以传递`numpy.mean`一个常规的非numpy列表，它将取平均值
    - 你只需要告诉它`axis=0`表示跨列表平均。因此，这将返回每棵树的`.predict()`的平均值。
- en: I find list comprehensions allow me to write the code in the way the brain works
    [[1:14:24](https://youtu.be/3jl2h9hSRvc?t=1h14m24s)]. You could take the words
    and translate them into this code, or you could take this code and translate them
    into words. So when I write code, I want it to be as much like that as possible.
    I want it to be readable and so hopefully you’ll find when you look at the fast.ai
    code trying to understand how Jeremy did x, I try to write things in a way that
    you can read it and turn it into English in your head.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: We’ve nearly finished writing our random forest, haven’t we [[1:15:29](https://youtu.be/3jl2h9hSRvc?t=1h15m29s)]?
    All we need to do now is write `create_tree`. We will construct a decision tree
    (i.e. non-random tree) from a random sample of the data. So again, we’ve delayed
    any actual thought process here. We’ve basically said ok, we could pick some random
    IDs. This is a good trick to know. If you call `np.random.permutation` passing
    in an `int`, it’ll give you back a randomly shuffled sequence from zero to that
    `int`. So if you grab the first `:n` items of that, that’s now a random subsample.
    So this is not doing bootstrapping (i.e. we are not doing sampling with replacement)
    here which I think is fine. For my random forest, I’m deciding that it’s going
    to be something where we do subsampling not bootstrapping.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/a14a2ce4e8535f02402de4c95e880637.png)'
  id: totrans-145
  prefs: []
  type: TYPE_IMG
- en: '`np.random.permutation(len(self.y))[:self.sample_sz]`'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: So here is a good line of code to know how to write because it comes up all
    the time. I find in machine learning, most algorithms I use are somewhat random
    and so often I need some kind of random sample.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: Personally I prefer this over bootstrapping because I feel like most of the
    time, we have more data than we want to put in a tree at once [[1:18:54](https://youtu.be/3jl2h9hSRvc?t=1h18m54s)].
    Back when Breiman created random forest, it was 1999 and was a very different
    world. We now have too much data. So what people tend to do is fire-up a spark
    cluster and they will run it on hundreds of machines when it makes no sense because
    if they had just used a subsample each time, they could have done it on one machine.
    The overhead of spark is a huge amount of I/O overhead. If you do something on
    a single machine, it can often be hundreds of times faster because you don’t have
    this I/O overhead and it also tends to be easier to write the algorithms, easier
    to visualize, cheaper and so forth. So I almost always avoid distributed computing
    and I have my whole life. Even 25 years ago when I was starting in machine learning,
    I still didn’t use clusters because I always feel like whatever I could do with
    a cluster now, I could do with a single machine in five years time. So why not
    focus on always being as good as possible with a single machine. That would be
    more interactive and iterative.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: So again, we delayed thinking to the point where we have to write decision tree
    [[1:20:26](https://youtu.be/3jl2h9hSRvc?t=1h20m26s)]. So hopefully you get an
    idea that this top-down approach, the goal is going to be that we’re going to
    keep delaying thinking so long that eventually we’ve somehow written the whole
    thing without actually having to think. Notice that you never have to design anything.
    You just say, what if somebody already gave me the exact API I needed, how would
    I use it? Then to implement the next stage, what would be the exact API I would
    need to implement that? You keep going down until eventually you notice oh, that
    already exists.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: This assumes we’ve got a class called `DecisionTree` , so we’re going to have
    to create that [[1:21:13](https://youtu.be/3jl2h9hSRvc?t=1h21m13s)]. We know what
    we’re going to have to pass it because we just passed it. So we are passing in
    random sample of `x`’s and `y`’s. We know that a decision tree is going to contain
    decision trees which themselves contain decision trees. So as we go down the decision
    tree, there’s going to be some subset of the original data that we’ve kind of
    got so I’m going to pass in the indexes of the data that we’re actually going
    to use here. So initially, it’s the entire random sample. And we also pass down
    the `min_leaf` size. So everything that we got for constructing the random forest,
    we’ll pass down to the decision tree except, of course, `num_tree` which is irrelevant
    for the decision tree.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 这假设我们有一个名为`DecisionTree`的类，所以我们将不得不创建它。我们知道我们将不得不传递什么，因为我们刚刚传递了它。所以我们传递了`x`和`y`的随机样本。我们知道决策树将包含决策树，这些决策树本身包含决策树。因此，当我们沿着决策树向下走时，原始数据的某个子集将被包含在内，因此我将传递我们实际上将在这里使用的数据的索引。所以最初，它是整个随机样本。我们还传递`min_leaf`的大小。因此，我们为构建随机森林所做的一切，我们将传递给决策树，除了当然不包括对于决策树无关的`num_tree`。
- en: '[PRE22]'
  id: totrans-151
  prefs: []
  type: TYPE_PRE
  zh: '[PRE22]'
- en: '`self.n`: how many rows we have in this tree (the number of indexes we’ve given)'
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self.n`: 这棵树中有多少行（我们给定的索引数量）'
- en: '`self.c`: how many columns we have (how ever many columns there are in the
    independent variables)'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self.c`: 我们有多少列（独立变量中有多少列）'
- en: '`self.val`: For this tree, what’s its prediction. Prediction of this tree is
    the mean of our dependent variable for those indexes. When we talk about indexes,
    we are not talking about the random sampling to create the tree. We’re assuming
    this tree now has some random sample. Inside decision tree, the whole random sampling
    thing is gone. That was done by the random forest. So at this point, we are building
    something that is just a plain old decision tree. It’s not in any way a random
    sampling anything. So indexes is literally which subset of the data have we got
    to so far in this tree.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`self.val`: 对于这棵树，它的预测是什么。这棵树的预测是我们依赖变量的均值。当我们谈论索引时，我们并不是在谈论用于创建树的随机抽样。我们假设这棵树现在有一些随机样本。在决策树内部，整个随机抽样的过程已经消失了。那是由随机森林完成的。所以在这一点上，我们正在构建的只是一棵普通的决策树。它不以任何方式是随机抽样的任何东西。所以索引实际上是我们到目前为止在这棵树中得到的数据的哪个子集。'
- en: A quick Object Oriented Programming primer[[1:24:50](https://youtu.be/3jl2h9hSRvc?t=1h24m50s)]
  id: totrans-155
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 一个快速的面向对象编程入门
- en: 'I’ll skip this but here is the funny bit about `self`:'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 我会跳过这部分，但这里有关于`self`的有趣内容：
- en: You can call it anything you like. If you call it anything other than “self”,
    everybody will hate you and you’re a bad person. [[1:29:24](https://youtu.be/3jl2h9hSRvc?t=1h29m24s)]
  id: totrans-157
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 你可以随意命名它。如果你把它命名为除了“self”之外的任何其他名称，每个人都会讨厌你，你是个坏人。
