- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 19:44:52'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 'date: 2024-09-06 19:44:52'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2208.08789] Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2208.08789] 面向标签高效的自动诊断和分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的综合调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2208.08789](https://ar5iv.labs.arxiv.org/html/2208.08789)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2208.08789](https://ar5iv.labs.arxiv.org/html/2208.08789)
- en: 'Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 面向标签高效的自动诊断和分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的综合调查
- en: 'Linhao Qu, Siyu Liu, Xiaoyu Liu, Manning Wang¹¹1Corresponding Author., Zhijian
    Song²²footnotemark: 2 Digital Medical Research Center, School of Basic Medical
    Science, Fudan University, Shanghai Key Lab of Medical Image Computing and Computer
    Assisted Intervention, Shanghai 200032, China [{lhqu20, mnwang, zjsong}@fudan.edu.cn.](mailto:%7Blhqu20,%20mnwang,%20zjsong%7D@fudan.edu.cn.)'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 'Linhao Qu, Siyu Liu, Xiaoyu Liu, Manning Wang¹¹1Corresponding Author., Zhijian
    Song²²footnotemark: 2 数字医学研究中心，基础医学学院，复旦大学，上海医学图像计算与计算机辅助干预重点实验室，上海 200032，中国
    [{lhqu20, mnwang, zjsong}@fudan.edu.cn.](mailto:%7Blhqu20,%20mnwang,%20zjsong%7D@fudan.edu.cn.)'
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: Abstract
- en: Histopathological images contain abundant phenotypic information and pathological
    patterns, which are the gold standards for disease diagnosis and essential for
    the prediction of patient prognosis and treatment outcome. In recent years, computer-automated
    analysis techniques for histopathological images have been urgently required in
    clinical practice, and deep learning methods represented by convolutional neural
    networks have gradually become the mainstream in the field of digital pathology.
    However, obtaining large numbers of fine-grained annotated data in this field
    is a very expensive and difficult task, which hinders the further development
    of traditional supervised algorithms based on large numbers of annotated data.
    More recent studies have started to liberate from the traditional supervised paradigm,
    and the most representative ones are the studies on weakly supervised learning
    paradigm based on weak annotation, semi-supervised learning paradigm based on
    limited annotation, and self-supervised learning paradigm based on pathological
    image representation learning. These new methods have led a new wave of automatic
    pathological image diagnosis and analysis targeted at annotation efficiency. With
    a survey of over 130 papers, we present a comprehensive and systematic review
    of the latest studies on weakly supervised learning, semi-supervised learning,
    and self-supervised learning in the field of computational pathology from both
    technical and methodological perspectives. Finally, we present the key challenges
    and future trends for these techniques.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 组织病理图像包含丰富的表型信息和病理模式，这些是疾病诊断的金标准，对于患者预后和治疗结果的预测至关重要。近年来，临床实践中急需组织病理图像的计算机自动分析技术，卷积神经网络代表的深度学习方法逐渐成为数字病理学领域的主流。然而，在该领域获取大量细粒度标注数据是一项非常昂贵和困难的任务，这阻碍了基于大量标注数据的传统监督算法的进一步发展。更近期的研究开始摆脱传统的监督范式，最具代表性的研究包括基于弱标注的弱监督学习范式、基于有限标注的半监督学习范式和基于病理图像表示学习的自监督学习范式。这些新方法引领了一波针对标注效率的自动病理图像诊断和分析的新潮流。通过对130多篇论文的调查，我们从技术和方法学的角度对计算病理学领域中的最新研究进行了全面和系统的回顾。最后，我们呈现了这些技术的关键挑战和未来趋势。
- en: \useunder
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: \useunder
- en: 'Keywords: histopathological images, automatic analysis, deep learning'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 'Keywords: 组织病理图像，自动分析，深度学习'
- en: 1 Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Histopathological images contain abundant phenotypic information and pathological
    patterns, which are the gold standards for disease diagnosis and essential for
    the prediction of patient prognosis and treatment outcome (Myronenko *et al.* [2021](#bib.bib116),
    Wang *et al.* [2019](#bib.bib181), Srinidhi *et al.* [2021](#bib.bib159)). For
    clinical diagnosis, experienced pathologists usually require exhaustive examination
    and interpretation of hematoxylin-eosin-stained (H&E) tissue slides under a high
    magnification microscope, including differentiation of tumor areas from large
    areas of normal tissues, elaborate grading of tumors, and detailed assessment
    of tumor progression and invasion (e.g., presence of invasive carcinoma or proliferative
    changes, etc.). This is a highly time-consuming and labor-intensive task, and
    for example, it usually takes an experienced histopathologist 15 to 30 minutes
    to examine a complete slide (Wang *et al.* [2019](#bib.bib181)). Moreover, even
    an experienced pathologist may not be able to accurately determine the deep features
    hidden in the pathological images, such as predicting lymph node metastasis and
    prognosis from the primary lesion. Therefore, computer-assisted automatic analysis
    techniques for histopathological images are in urgent need in clinical practice.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 组织病理图像包含丰富的表型信息和病理模式，这些是疾病诊断的金标准，并且对患者预后和治疗结果的预测至关重要（Myronenko *et al.* [2021](#bib.bib116),
    Wang *et al.* [2019](#bib.bib181), Srinidhi *et al.* [2021](#bib.bib159)）。对于临床诊断，经验丰富的病理学家通常需要在高倍显微镜下对苏木精-伊红染色（H&E）组织切片进行详尽的检查和解读，包括区分肿瘤区域与大面积正常组织、对肿瘤进行详细分级，以及评估肿瘤的进展和侵袭（例如，侵袭性癌症的存在或增生性变化等）。这是一个非常耗时和劳动密集的任务，例如，经验丰富的组织病理学家通常需要15到30分钟来检查一个完整的切片（Wang
    *et al.* [2019](#bib.bib181)）。此外，即使是经验丰富的病理学家也可能无法准确确定病理图像中隐藏的深层特征，例如预测淋巴结转移和原发病灶的预后。因此，临床实践中迫切需要计算机辅助的自动分析技术来处理组织病理图像。
- en: With the advent and development of digital slide scanners in the past two decades,
    tissues on biopsies can be converted into digital whole slide images (WSIs) that
    fully preserve the original tissue structure, laying the foundation for automatic
    pathological image analysis. Early studies in the field of digital pathology diagnosis
    primarily focused on extracting hand-crafted features from manually selected regions
    of interest (ROI) by pathologists (Jafari *et al.* [2003](#bib.bib78), Basavanhally
    *et al.* [2013](#bib.bib7), Mercan *et al.* [2017](#bib.bib113), Yu *et al.* [2016](#bib.bib203),
    Luo *et al.* [2017](#bib.bib106), Qaiser *et al.* [2016](#bib.bib127)) and using
    machine learning methods (Doyle *et al.* [2007](#bib.bib52), Rajpoot *et al.* [2004](#bib.bib134),
    Qureshi *et al.* [2008](#bib.bib132), Doyle *et al.* [2006](#bib.bib53)) for automatic
    analysis and diagnosis. In this regard, Gurcan *et al.* [2009](#bib.bib69) and
    Madabhushi *et al.* [2016](#bib.bib107) have presented an elaborate review.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着过去二十年数字切片扫描仪的出现和发展，活检组织可以转换为完全保留原始组织结构的数字全切片图像（WSIs），为自动病理图像分析奠定了基础。数字病理诊断领域的早期研究主要集中在从病理学家手动选择的感兴趣区域（ROI）中提取手工特征（Jafari
    *et al.* [2003](#bib.bib78), Basavanhally *et al.* [2013](#bib.bib7), Mercan *et
    al.* [2017](#bib.bib113), Yu *et al.* [2016](#bib.bib203), Luo *et al.* [2017](#bib.bib106),
    Qaiser *et al.* [2016](#bib.bib127)），并使用机器学习方法（Doyle *et al.* [2007](#bib.bib52),
    Rajpoot *et al.* [2004](#bib.bib134), Qureshi *et al.* [2008](#bib.bib132), Doyle
    *et al.* [2006](#bib.bib53)）进行自动分析和诊断。在这方面，Gurcan *et al.* [2009](#bib.bib69)
    和 Madabhushi *et al.* [2016](#bib.bib107) 提供了详尽的综述。
- en: In recent years, thanks to the powerful and automatic feature extraction capability,
    deep learning methods represented by Convolutional Neural Network (CNN) have gradually
    become the mainstream in the field of digital pathology. However, a major challenge
    is the huge size of WSIs, typically reaching 100000$\times" display="inline"><semantics
    ><mo xref=$100000 pixels at the highest resolution, which prevents the direct
    use of the entire WSIs as the input to deep learning models. Therefore, when using
    CNNs to process pathological images, WSIs are usually tiled into many small patches
    to reduce the computational burden. Earlier studies usually adopted a strongly
    supervised approach based on these patches to train the network and perform the
    corresponding classification (Cruz-Roa *et al.* [2014](#bib.bib40), Cruz-Roa *et
    al.* [2017](#bib.bib41), Wei *et al.* [2019](#bib.bib185), Ehteshami *et al.* [2018](#bib.bib54),
    Nagpal *et al.* [2019](#bib.bib117), Shaban *et al.* [2019](#bib.bib145), Halicek
    *et al.* [2019](#bib.bib71)) and segmentation tasks (Chen *et al.* [2017](#bib.bib22),
    Gu *et al.* [2018](#bib.bib67), Swiderska *et al.* [2019](#bib.bib165)). In these
    works, detailed patch-level annotation is essential, e.g., supervised classification
    problems require pathologists to give detailed class labels for each patch, and
    segmentation problems require pathologists to give more detailed pixel-level annotation
    for each patch.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近几年，由于强大的自动特征提取能力，以卷积神经网络（CNN）为代表的深度学习方法逐渐成为数字病理学领域的主流。然而，一个主要挑战是WSIs的巨大尺寸，通常在最高分辨率下达到`100000`像素，这阻碍了将整个WSIs直接作为深度学习模型输入。因此，在使用CNN处理病理图像时，WSIs通常会被切割成许多小块，以减少计算负担。早期的研究通常采用基于这些小块的强监督方法来训练网络并执行相应的分类（Cruz-Roa
    *et al.* [2014](#bib.bib40), Cruz-Roa *et al.* [2017](#bib.bib41), Wei *et al.*
    [2019](#bib.bib185), Ehteshami *et al.* [2018](#bib.bib54), Nagpal *et al.* [2019](#bib.bib117),
    Shaban *et al.* [2019](#bib.bib145), Halicek *et al.* [2019](#bib.bib71)）和分割任务（Chen
    *et al.* [2017](#bib.bib22), Gu *et al.* [2018](#bib.bib67), Swiderska *et al.*
    [2019](#bib.bib165)）。在这些工作中，详细的小块级注释是必不可少的，例如，监督分类问题需要病理学家为每个小块提供详细的类别标签，而分割问题需要病理学家为每个小块提供更详细的像素级注释。
- en: 'Although supervised deep learning methods have achieved unprecedented success
    in digital pathology, they share a common drawback: they all require large amounts
    of high-quality fine-grained labeled data (patch-level labeled data for classification
    problems or pixel-level labeled data for segmentation problems) for training.
    Unfortunately, in the field of digital pathology, obtaining a large amount of
    data with fine-grained annotation is a very expensive and challenging task, mainly
    because 1) only experienced pathologists can perform the annotation, and these
    pathologists are scarce; 2) histopathological images often contain complex and
    diverse instances of objects, resulting in a large amount of time-consuming and
    laborious manual annotation effort (Tajbakhsh *et al.* [2020](#bib.bib166), Yang
    *et al.* [2017](#bib.bib199), Srinidhi *et al.* [2021](#bib.bib159)). Arguably,
    the lack of a large amount of annotated data limits the application of deep learning
    techniques in computational pathology. For this reason, some new studies have
    recently attempted to liberate from the traditional strongly supervised paradigms,
    the most representative of which are the weakly supervised learning paradigm based
    on weak annotations, the semi-supervised learning paradigm based on limited annotations,
    and the self-supervised paradigm based on the representation learning of pathological
    images.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管监督深度学习方法在数字病理学中取得了前所未有的成功，但它们都有一个共同的缺点：都需要大量高质量的细粒度标注数据（分类问题的块级标注数据或分割问题的像素级标注数据）进行训练。不幸的是，在数字病理学领域，获取大量细粒度注释的数据是一项非常昂贵且具有挑战性的任务，主要因为1）只有经验丰富的病理学家才能进行注释，而这些病理学家稀缺；2）组织病理图像通常包含复杂多样的对象实例，导致耗时且劳动密集的手动注释工作（Tajbakhsh
    *et al.* [2020](#bib.bib166), Yang *et al.* [2017](#bib.bib199), Srinidhi *et
    al.* [2021](#bib.bib159)）。可以说，缺乏大量注释数据限制了深度学习技术在计算病理学中的应用。因此，一些新研究最近尝试摆脱传统的强监督范式，其中最具代表性的是基于弱注释的弱监督学习范式、基于有限注释的半监督学习范式和基于病理图像表示学习的自监督范式。
- en: The weakly supervised learning paradigm no longer requires pathologists to give
    annotations of all pixels or regions on the entire WSI, but only class labels
    or sparse region annotations on the entire WSI; the semi-supervised learning paradigm
    no longer requires pathologists to give fine-grained annotations of a large amount
    of data, but only a small fraction of fine-grained labeled data and a large amount
    of unlabeled data; while the self-supervised learning paradigm can create supervised
    information through a large amount of unlabeled data for self-supervised training
    to learn an accurate feature representation of the data. In the process of training
    with limited labeled data, using the features trained by self-supervised learning
    to determine the initial model weights can significantly improve the performance
    of the model. Therefore, weakly supervised learning, semi-supervised learning
    and self-supervised learning are leading a new study direction of the automatic
    diagnosis and analysis for pathological images.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督学习范式不再要求病理学家对整个WSI中的所有像素或区域进行标注，只需对整个WSI进行类别标签或稀疏区域标注；半监督学习范式不再要求病理学家对大量数据进行细粒度标注，只需少量细粒度标注数据和大量未标注数据；而自监督学习范式则可以通过大量未标注数据创建监督信息进行自监督训练，从而学习数据的准确特征表示。在有限标注数据的训练过程中，使用自监督学习训练的特征来确定初始模型权重，可以显著提高模型性能。因此，弱监督学习、半监督学习和自监督学习正在引领病理图像自动诊断与分析的新研究方向。
- en: However, there are very few related reviews. Srinidhi *et al.* [2021](#bib.bib159)
    reviewed representative supervised learning, weakly supervised learning, unsupervised
    learning, and transfer learning studies in the field of computational pathology
    until December 2019\. Rony *et al.* [2019](#bib.bib139) reviewed representative
    weakly supervised learning studies until 2020\. Nevertheless, in recent years,
    deep learning techniques have been developing rapidly and the new techniques continue
    to emerge. Therefore, a review regarding the applications of these techniques
    in the automatic diagnosis of pathological images has important theoretical value
    and clinical significance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，相关的综述非常少。Srinidhi *等人* [2021](#bib.bib159) 回顾了截至2019年12月在计算病理学领域的代表性监督学习、弱监督学习、无监督学习和迁移学习研究。Rony
    *等人* [2019](#bib.bib139) 回顾了截至2020年的代表性弱监督学习研究。尽管如此，近年来深度学习技术发展迅速，新技术不断涌现。因此，关于这些技术在病理图像自动诊断中的应用的综述具有重要的理论价值和临床意义。
- en: In this review, we summarize more than 130 recent technical studies systematically
    on weakly supervised learning, semi-supervised learning, and self-supervised learning
    in the field of computational pathology. We performed this extensive review by
    searching Google Scholar, PubMed, and arXiv for papers including keywords such
    as (”deep learning” or ”weakly supervised learning” or ”semi-supervised learning”
    or ”self-supervised learning ”) and (”digital pathology” or ”histopathology” or
    ”computational pathology”). Notably, on the one hand, we focus on papers presenting
    novel techniques and theories with high impact (h-index, citations and impact
    factors of journals), thus we concentrate more on studies published in top conferences
    (including CVPR, NeurIPS, MICCAI, ISBI, MIDL, IPMI, AAAI, ICCV, ECCV, etc.) and
    top journals (including TPAMI, TMI, MIA, etc.) on weakly supervised, semi-supervised,
    and self-supervised learning in the field of computational pathology. On the other
    hand, since technical research in this area is growing rapidly and more new techniques
    have been proposed, we mainly cover papers published in 2019-2021\. On the other
    hand, we also present a meticulous summary of the disease types, tasks, datasets,
    and performance covered by these papers. In total, this review contains more than
    200 relevant references.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇综述中，我们系统地总结了130多项近期在计算病理学领域的弱监督学习、半监督学习和自监督学习的技术研究。我们通过搜索Google Scholar、PubMed和arXiv，查找包含（“深度学习”或“弱监督学习”或“半监督学习”或“自监督学习”）以及（“数字病理学”或“组织病理学”或“计算病理学”）等关键词的论文来进行这项广泛的综述。值得注意的是，一方面，我们重点关注那些呈现出高影响力的新技术和理论的论文（如h指数、引用次数和期刊的影响因子），因此我们更加关注在顶级会议（包括CVPR、NeurIPS、MICCAI、ISBI、MIDL、IPMI、AAAI、ICCV、ECCV等）和顶级期刊（包括TPAMI、TMI、MIA等）上发表的关于计算病理学领域的弱监督学习、半监督学习和自监督学习的研究。另一方面，由于这一领域的技术研究发展迅速，提出了更多的新技术，我们主要涵盖了2019年至2021年间发表的论文。此外，我们还对这些论文涵盖的疾病类型、任务、数据集和性能进行了细致的总结。总的来说，这篇综述包含了200多篇相关参考文献。
- en: 'The rest of the paper is organized as follows: Section [2](#S2 "2 Overview
    of Learning Paradigms and Problem Formulation ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") expounds a general overview of the weakly supervised, semi-supervised,
    and self-supervised learning paradigms in the context of computational pathology;
    Section [3](#S3 "3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and
    Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")
    includes a detailed review of the weakly supervised (Section [3.1](#S3.SS1 "3.1
    Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), semi-supervised (Section [3.2](#S3.SS2 "3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")),
    and self-supervised (Section [3.3](#S3.SS3 "3.3 Self-Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis")) learning paradigms;
    We discuss the three learning paradigms and their future trends in Section [4](#S4
    "4 Discussion and Future Trends ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis"),
    and conclude the whole paper in Section [5](#S5 "5 Conclusion ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"). The list of all the acronyms used in this review is shown in
    Table [1](#S1.T1 "Table 1 ‣ 1 Introduction ‣ Towards Label-efficient Automatic
    Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis").'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 论文的其余部分组织如下：第[2](#S2 "2 监督学习和问题表述概述 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节阐述了计算病理学背景下的弱监督、半监督和自监督学习范式的一般概述；第[3](#S3
    "3 范式 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节包括对弱监督（第[3.1](#S3.SS1
    "3.1 弱监督学习范式 ‣ 3 范式 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节）、半监督（第[3.2](#S3.SS2
    "3.2 半监督学习范式 ‣ 3 范式 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节）和自监督（第[3.3](#S3.SS3
    "3.3 自监督学习范式 ‣ 3 范式 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节）学习范式的详细回顾；我们在第[4](#S4
    "4 讨论与未来趋势 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节讨论了这三种学习范式及其未来趋势，并在第[5](#S5
    "5 结论 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")节总结了整篇论文。本综述中使用的所有缩写的列表见表[1](#S1.T1
    "表 1 ‣ 1 引言 ‣ 面向标签效率的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面综述")。
- en: 'Table 1: List of all the acronyms in this review.'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 本综述中所有缩写的列表。'
- en: '| Full Name | Acronyms | Full Name | Acronyms |'
  id: totrans-22
  prefs: []
  type: TYPE_TB
  zh: '| 全称 | 缩写 | 全称 | 缩写 |'
- en: '| Area Under ROC Curve | AUC | Graph Neural Network | GNN |'
  id: totrans-23
  prefs: []
  type: TYPE_TB
  zh: '| ROC曲线下面积 | AUC | 图神经网络 | GNN |'
- en: '| Auxiliary Classier Generative Adversarial Networks | AC-GAN | Hematoxylin-Eosin-Stained
    | H&E |'
  id: totrans-24
  prefs: []
  type: TYPE_TB
  zh: '| 辅助分类生成对抗网络 | AC-GAN | 苏木精-伊红染色 | H&E |'
- en: '| Average Hausdorff Distance | AHD | Magnication Prior Contrastive Similarity
    | MPCS |'
  id: totrans-25
  prefs: []
  type: TYPE_TB
  zh: '| 平均Hausdorff距离 | AHD | 放大优先对比相似度 | MPCS |'
- en: '| Average Jaccard Index | AJI | Mean Average Precision | MAP |'
  id: totrans-26
  prefs: []
  type: TYPE_TB
  zh: '| 平均Jaccard指数 | AJI | 平均精度均值 | MAP |'
- en: '| Calinski-Harabaz Index | CHI | Mean Teachers | MT |'
  id: totrans-27
  prefs: []
  type: TYPE_TB
  zh: '| Calinski-Harabaz指数 | CHI | 平均教师 | MT |'
- en: '| Contrastive Predictive Coding | CPC | Microsatellite Instability | MSI |'
  id: totrans-28
  prefs: []
  type: TYPE_TB
  zh: '| 对比预测编码 | CPC | 微卫星不稳定性 | MSI |'
- en: '| Convolutional Autoencoder | CAE | Multiple Instance Fully Convolutional Network
    | MI-FCN |'
  id: totrans-29
  prefs: []
  type: TYPE_TB
  zh: '| 卷积自编码器 | CAE | 多实例全卷积网络 | MI-FCN |'
- en: '| Convolutional Neural Network | CNN | Multiple Instance Learning | MIL |'
  id: totrans-30
  prefs: []
  type: TYPE_TB
  zh: '| 卷积神经网络 | CNN | 多实例学习 | MIL |'
- en: '| Deep Learning Hashing | DLH | Noise Contrastive Estimation | NCE |'
  id: totrans-31
  prefs: []
  type: TYPE_TB
  zh: '| 深度学习哈希 | DLH | 噪声对比估计 | NCE |'
- en: '| Deformation Representation Learning | DRL | Percentage Of Tumor Cellularity
    | TC |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '| 变形表示学习 | DRL | 肿瘤细胞百分比 | TC |'
- en: '| Diffusion-Convolutional Neural Networks | DCNNs | Recurrent Neural Network
    | RNN |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| 扩散卷积神经网络 | DCNNs | 循环神经网络 | RNN |'
- en: '| Dual-Stream Multiple Instance Learning | DSMIL | Regions Of Interest | ROI
    |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '| 双流多实例学习 | DSMIL | 感兴趣区域 | ROI |'
- en: '| Expectation-Maximization | EM | Resolution Sequence Prediction | RSP |'
  id: totrans-35
  prefs: []
  type: TYPE_TB
  zh: '| 期望最大化 | EM | 分辨率序列预测 | RSP |'
- en: '| Exponential Moving Average | EMA | Silhouette Index | SI |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| 指数移动平均 | EMA | 轮廓指数 | SI |'
- en: '| Focal-Aware Module | FAM | Support Vector Machines | SVM |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '| 焦点感知模块 | FAM | 支持向量机 | SVM |'
- en: '| Frechet Inception Distance | FID | Temporal Ensembling | TE |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| Frechet感知距离 | FID | 时间集成 | TE |'
- en: '| Generative Adversarial Networks | GAN | The Cancer Genome Atlas Program |
    TCGA |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '| 生成对抗网络 | GAN | 癌症基因组图谱计划 | TCGA |'
- en: '| Graph Convolutional Neural Network | GCN | Whole Slide Images | WSI |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '| 图卷积神经网络 | GCN | 整张幻灯片图像 | WSI |'
- en: 2 Overview of Learning Paradigms and Problem Formulation
  id: totrans-41
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 学习范式和问题定义概述
- en: 'In this section, we provide a general overview and problem formulation of the
    three learning paradigms reviewed in this paper, and compare them with the traditional
    strongly supervised paradigm. To make the description more specific and vivid,
    we present an example of accurately classifying normal and cancerous tissues in
    a WSI, as shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis"). The raw
    data for this example WSI comes from a study on predicting lymph node metastasis
    in breast cancer using deep learning (Bejnordi *et al.* [2017a](#bib.bib9)). We
    also intuitively compare and summarize these paradigms in Table [2](#S2.T2 "Table
    2 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis").'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了本文回顾的三种学习范式的总体概述和问题定义，并将它们与传统的强监督范式进行比较。为了使描述更具体和生动，我们展示了一个在WSI中准确分类正常组织和癌组织的示例，如图[1](#S2.F1
    "图 1 ‣ 2 学习范式和问题定义概述 ‣ 面向标签效率自动诊断和分析：先进深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的综合调查")所示。该示例WSI的原始数据来自于一项使用深度学习预测乳腺癌淋巴结转移的研究（Bejnordi
    *et al.* [2017a](#bib.bib9)）。我们还在表[2](#S2.T2 "表 2 ‣ 2 学习范式和问题定义概述 ‣ 面向标签效率自动诊断和分析：先进深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的综合调查")中直观地比较和总结了这些范式。
- en: 'For the dataset <math   alttext="W={\{W_{i}\}}_{i=1}^{N}" display="inline"><semantics
    ><mrow  ><mi >W</mi><mo >=</mo><msubsup  ><mrow ><mo stretchy="false" >{</mo><msub
    ><mi  >W</mi><mi >i</mi></msub><mo stretchy="false"  >}</mo></mrow><mrow ><mi
    >i</mi><mo  >=</mo><mn >1</mn></mrow><mi >N</mi></msubsup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >𝑊</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></set><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math> consisting of <math   alttext="N"
    display="inline"><semantics ><mi  >N</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝑁</ci></annotation-xml><annotation encoding="application/x-tex" >N</annotation></semantics></math>
    WSIs, each WSI <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi
    >W</mi><mi  >i</mi></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >W_{i}</annotation></semantics></math> is now cut
    into patches <math   alttext="\{p_{i,j},j=1,2,\ldots n_{i}\}" display="inline"><semantics
    ><mrow  ><mo stretchy="false"  >{</mo><mrow ><mrow ><mrow  ><msub ><mi >p</mi><mrow
    ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo >,</mo><mi >j</mi></mrow><mo
    >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo >,</mo><mrow ><mi
    mathvariant="normal" >…</mi><mo lspace="0em" rspace="0em"  >​</mo><msub ><mi >n</mi><mi
    >i</mi></msub></mrow></mrow></mrow><mo stretchy="false"  >}</mo></mrow><annotation-xml
    encoding="MathML-Content" ><set  ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><list ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci
    >𝑗</ci></list></apply><ci >𝑗</ci></list><cn type="integer" >1</cn></apply><list
    ><cn type="integer" >2</cn><apply ><ci  >…</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑛</ci><ci >𝑖</ci></apply></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots n_{i}\}</annotation></semantics></math>,
    and <math   alttext="n_{i}" display="inline"><semantics ><msub  ><mi >n</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑛</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >n_{i}</annotation></semantics></math> is the number of patches cut out of <math   alttext="W_{i}"
    display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math>. In the supervised learning paradigm, a
    large number of patches with fine-grained labels are available for training, so
    each patch is given a label <math alttext="y_{i,j}\in\mathbb{R}^{C}" display="inline"><semantics
    ><mrow ><msub  ><mi >y</mi><mrow ><mi  >i</mi><mo >,</mo><mi >j</mi></mrow></msub><mo  >∈</mo><msup
    ><mi >ℝ</mi><mi  >C</mi></msup></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝑦</ci><list
    ><ci >𝑖</ci><ci  >𝑗</ci></list></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℝ</ci><ci  >𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >y_{i,j}\in\mathbb{R}^{C}</annotation></semantics></math>, and <math   alttext="C"
    display="inline"><semantics ><mi  >C</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝐶</ci></annotation-xml><annotation encoding="application/x-tex" >C</annotation></semantics></math>
    denotes the possible class. For example, in the binary classification task, <math
    alttext="C=2" display="inline"><semantics ><mrow ><mi  >C</mi><mo >=</mo><mn >2</mn></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >𝐶</ci><cn type="integer"  >2</cn></apply></annotation-xml><annotation
    encoding="application/x-tex" >C=2</annotation></semantics></math> and the label
    takes the scalar form {0, 1} while in the regression task, <math alttext="C" display="inline"><semantics
    ><mi >C</mi><annotation-xml encoding="MathML-Content" ><ci  >𝐶</ci></annotation-xml><annotation
    encoding="application/x-tex" >C</annotation></semantics></math> takes the form
    of a continuous set of real numbers $\mathbb{R}" display="inline"><semantics ><mi
    >ℝ</mi><annotation-xml encoding="MathML-Content" ><ci >ℝ</ci></annotation-xml><annotation
    encoding=$. The goal of the supervised learning paradigm is to train a model <math
    alttext="f_{\theta}:x\rightarrow y" display="inline"><semantics ><mrow  ><msub
    ><mi >f</mi><mi  >θ</mi></msub><mo lspace="0.278em" rspace="0.278em"  >:</mo><mrow
    ><mi >x</mi><mo stretchy="false" >→</mo><mi  >y</mi></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><ci  >:</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑓</ci><ci >𝜃</ci></apply><apply ><ci  >→</ci><ci >𝑥</ci><ci
    >𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >f_{\theta}:x\rightarrow y</annotation></semantics></math> to optimally predict
    the labels <math   alttext="y_{i,j}" display="inline"><semantics ><msub  ><mi
    >y</mi><mrow ><mi  >i</mi><mo >,</mo><mi >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑦</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math> of the unknown
    patches <math   alttext="p_{i,j}" display="inline"><semantics ><msub  ><mi >p</mi><mrow
    ><mi  >i</mi><mo >,</mo><mi >j</mi></mrow></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci
    >𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex"
    >p_{i,j}</annotation></semantics></math> in the test WSI based on the loss function
    $\mathcal{L}" display="inline"><semantics ><mi >ℒ</mi><annotation-xml encoding="MathML-Content"
    ><ci  >ℒ</ci></annotation-xml><annotation encoding=$. Figure [1](#S2.F1 "Figure
    1 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (a) illustrates the main process of this paradigm. During training,
    the model is trained in a supervised manner using patches cut out of the training
    WSIs and their labels (green for negative and red for positive) by pathologists;
    during testing, the trained model is used to predict the labels of the patches
    cut out of the unseen test WSIs.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 对于数据集<math   alttext="W={\{W_{i}\}}_{i=1}^{N}" display="inline"><semantics ><mrow  ><mi
    >W</mi><mo >=</mo><msubsup  ><mrow ><mo stretchy="false" >{</mo><msub ><mi  >W</mi><mi
    >i</mi></msub><mo stretchy="false"  >}</mo></mrow><mrow ><mi >i</mi><mo  >=</mo><mn
    >1</mn></mrow><mi >N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><ci >𝑊</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></set><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math>包含<math   alttext="N"
    display="inline"><semantics ><mi  >N</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝑁</ci></annotation-xml><annotation encoding="application/x-tex" >N</annotation></semantics></math>个WSI，每个WSI
    <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> 现在被切割成补丁<math   alttext="\{p_{i,j},j=1,2,\ldots
    n_{i}\}" display="inline"><semantics ><mrow  ><mo stretchy="false"  >{</mo><mrow
    ><mrow ><mrow  ><msub ><mi >p</mi><mrow ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo
    >,</mo><mi >j</mi></mrow><mo >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo
    >,</mo><mrow ><mi mathvariant="normal" >…</mi><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >n</mi><mi >i</mi></msub></mrow></mrow></mrow><mo stretchy="false"  >}</mo></mrow><annotation-xml
    encoding="MathML-Content" ><set  ><apply ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply
    ><list ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci
    >𝑗</ci></list></apply><ci >𝑗</ci></list><cn type="integer" >1</cn></apply><list
    ><cn type="integer" >2</cn><apply ><ci  >…</ci><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑛</ci><ci >𝑖</ci></apply></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots n_{i}\}</annotation></semantics></math>，其中<math   alttext="n_{i}"
    display="inline"><semantics ><msub  ><mi >n</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑛</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >n_{i}</annotation></semantics></math>是从<math   alttext="W_{i}" display="inline"><semantics
    ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >W_{i}</annotation></semantics></math>中切割出的补丁数量。在监督学习范式中，大量带有细粒度标签的补丁用于训练，因此每个补丁都被赋予一个标签<math
    alttext="y_{i,j}\in\mathbb{R}^{C}" display="inline"><semantics ><mrow ><msub  ><mi
    >y</mi><mrow ><mi  >i</mi><mo >,</mo><mi >j</mi></mrow></msub><mo  >∈</mo><msup
    ><mi >ℝ</mi><mi  >C</mi></msup></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝑦</ci><list
    ><ci >𝑖</ci><ci >𝑗</ci></list></apply><apply ><csymbol cd="ambiguous" >superscript</csymbol><ci
    >ℝ</ci><ci  >𝐶</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >y_{i,j}\in\mathbb{R}^{C}</annotation></semantics></math>，其中<math   alttext="C"
    display="inline"><semantics ><mi  >C</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝐶</ci></annotation-xml><annotation encoding="application/x-tex" >C</annotation></semantics></math>表示可能的类别。例如，在二分类任务中，<math
    alttext="C=2" display="inline"><semantics ><mrow ><mi  >C</mi><mo >=</mo><mn >2</mn></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >𝐶</ci><cn type="integer"  >2</cn></apply></annotation-xml><annotation
    encoding="application/x-tex" >C=2</annotation></semantics></math>，标签采用标量形式{0,
    1}；而在回归任务中，<math alttext="C" display="inline"><semantics ><mi >C</mi><annotation-xml
    encoding="MathML-Content" ><ci  >𝐶</ci></annotation-xml><annotation encoding="application/x-tex"
    >C</annotation></semantics></math>则采用实数的连续集合形式<math alttext="ℝ" display="inline"><semantics
    ><mi >ℝ</mi><annotation-xml encoding="MathML-Content" ><ci >ℝ</ci></annotation-xml><annotation
    encoding="application/x-tex" >ℝ</annotation></semantics></math>。监督学习范式的目标是训练一个模型<math
    alttext="f_{\theta}:x\rightarrow y" display="inline"><semantics ><mrow  ><msub
    ><mi >f</mi><mi  >θ</mi></msub><mo lspace="0.278em" rspace="0.278em"  >:</mo><mrow
    ><mi >x</mi><mo stretchy="false" >→</mo><mi  >y</mi></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><ci  >:</ci><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑓</ci><ci >𝜃</ci></apply><apply ><ci  >→</ci><ci >𝑥</ci><ci
    >𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >f_{\theta}:x\rightarrow y</annotation></semantics></math>，以**最佳**地预测未知补丁<math   alttext="y_{i,j}"
    display="inline"><semantics ><msub  ><mi >y</mi><mrow ><mi  >i</mi><mo >,</mo><mi
    >j</mi></mrow></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol
- en: In the weakly supervised learning paradigm, the label <math alttext="y_{i,j}"
    display="inline"><semantics ><msub ><mi  >y</mi><mrow ><mi >i</mi><mo  >,</mo><mi
    >j</mi></mrow></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝑦</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math> of each
    patch is typically unknown, while only the label of each WSI is available, and
    thus the traditional strongly supervised learning paradigm cannot work. In this
    review, we focus on the most dominant weakly supervised paradigm currently used
    in computational pathology, the deep multiple instance learning (MIL) approach.
    In MIL, each WSI is considered as a bag containing many patches (also called instances).
    if a WSI (bag) is labeled as disease-positive, then at least one patch (instance)
    in that WSI is disease-positive; if a WSI is disease-negative, then all patches
    in that WSI are negative. The relationship between a WSI (bag) and its patches
    (instances) can be expressed mathematically as follows.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 在弱监督学习范式中，每个补丁的标签<math alttext="y_{i,j}" display="inline"><semantics ><msub
    ><mi  >y</mi><mrow ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑦</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math> 通常是未知的，而只有每个
    WSI 的标签是已知的，因此传统的强监督学习范式无法使用。在这篇综述中，我们重点介绍了目前在计算病理学中使用的最主要的弱监督范式，即深度多实例学习（MIL）方法。在
    MIL 中，每个 WSI 被视为包含多个补丁（也称为实例）的包。如果一个 WSI（包）被标记为疾病阳性，则该 WSI 中至少有一个补丁（实例）是疾病阳性；如果一个
    WSI 是疾病阴性，则该 WSI 中的所有补丁都是阴性。WSI（包）与其补丁（实例）之间的关系可以用数学表达如下。
- en: 'Given a dataset <math   alttext="W={\{W_{i}\}}_{i=1}^{N}" display="inline"><semantics
    ><mrow  ><mi >W</mi><mo >=</mo><msubsup  ><mrow ><mo stretchy="false" >{</mo><msub
    ><mi  >W</mi><mi >i</mi></msub><mo stretchy="false"  >}</mo></mrow><mrow ><mi
    >i</mi><mo  >=</mo><mn >1</mn></mrow><mi >N</mi></msubsup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >𝑊</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></set><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math> consisting of <math   alttext="N"
    display="inline"><semantics ><mi  >N</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝑁</ci></annotation-xml><annotation encoding="application/x-tex" >N</annotation></semantics></math>
    WSIs, each image <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi
    >W</mi><mi  >i</mi></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >W_{i}</annotation></semantics></math> has a corresponding
    label <math   alttext="Y_{i}\in\left\{0,1\right\},\ i=\{1,2,...N\}" display="inline"><semantics
    ><mrow ><mrow  ><msub ><mi >Y</mi><mi  >i</mi></msub><mo >∈</mo><mrow ><mo  >{</mo><mn
    >0</mn><mo >,</mo><mn  >1</mn><mo >}</mo></mrow></mrow><mo rspace="0.667em"  >,</mo><mrow
    ><mi >i</mi><mo  >=</mo><mrow ><mo stretchy="false" >{</mo><mn >1</mn><mo  >,</mo><mn
    >2</mn><mo >,</mo><mrow  ><mi mathvariant="normal"  >…</mi><mo lspace="0em" rspace="0em"  >​</mo><mi
    >N</mi></mrow><mo stretchy="false"  >}</mo></mrow></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><csymbol cd="ambiguous"  >formulae-sequence</csymbol><apply
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑌</ci><ci  >𝑖</ci></apply><set
    ><cn type="integer" >0</cn><cn type="integer" >1</cn></set></apply><apply ><ci  >𝑖</ci><set
    ><cn type="integer" >1</cn><cn type="integer" >2</cn><apply  ><ci >…</ci><ci >𝑁</ci></apply></set></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}\in\left\{0,1\right\},\ i=\{1,2,...N\}</annotation></semantics></math>.
    Now each WSI <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi
    >W</mi><mi  >i</mi></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >W_{i}</annotation></semantics></math> is cut into
    small patches <math   alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}" display="inline"><semantics
    ><mrow  ><mo stretchy="false"  >{</mo><mrow ><mrow ><mrow  ><msub ><mi >p</mi><mrow
    ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo >,</mo><mi >j</mi></mrow><mo
    >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo >,</mo><mi mathvariant="normal"  >…</mi><mo
    >,</mo><msub ><mi >n</mi><mi >i</mi></msub></mrow></mrow><mo stretchy="false"
    >}</mo></mrow><annotation-xml encoding="MathML-Content" ><set  ><apply ><csymbol
    cd="ambiguous" >formulae-sequence</csymbol><apply ><list ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply><ci
    >𝑗</ci></list><cn type="integer" >1</cn></apply><list ><cn type="integer" >2</cn><ci
    >…</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑛</ci><ci >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>
    without overlapping each other, and <math   alttext="n_{i}" display="inline"><semantics
    ><msub  ><mi >n</mi><mi >i</mi></msub><annotation-xml encoding="MathML-Content"
    ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑛</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >n_{i}</annotation></semantics></math> is the number
    of patches. All patches <math   alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}" display="inline"><semantics
    ><mrow  ><mo stretchy="false"  >{</mo><mrow ><mrow ><mrow  ><msub ><mi >p</mi><mrow
    ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo >,</mo><mi >j</mi></mrow><mo
    >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo >,</mo><mi mathvariant="normal"  >…</mi><mo
    >,</mo><msub ><mi >n</mi><mi >i</mi></msub></mrow></mrow><mo stretchy="false"
    >}</mo></mrow><annotation-xml encoding="MathML-Content" ><set  ><apply ><csymbol
    cd="ambiguous" >formulae-sequence</csymbol><apply ><list ><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply><ci
    >𝑗</ci></list><cn type="integer" >1</cn></apply><list ><cn type="integer" >2</cn><ci
    >…</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑛</ci><ci >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>
    in <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> form a bag, the bag-level label is the
    label <math   alttext="Y_{i}" display="inline"><semantics ><msub  ><mi >Y</mi><mi
    >i</mi></msub><annotation-xml encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑌</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >Y_{i}</annotation></semantics></math> of <math alttext="W_{i}" display="inline"><semantics
    ><msub ><mi >W</mi><mi  >i</mi></msub><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation
    encoding="application/x-tex" >W_{i}</annotation></semantics></math>, and each
    small patch is called an instance of this bag, while the instance-level label
    <math alttext="y_{i,j}" display="inline"><semantics ><msub ><mi >y</mi><mrow  ><mi
    >i</mi><mo >,</mo><mi  >j</mi></mrow></msub><annotation-xml encoding="MathML-Content"
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑦</ci><list ><ci  >𝑖</ci><ci
    >𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex"
    >y_{i,j}</annotation></semantics></math> and its corresponding bag-level label
    <math alttext="Y_{i}" display="inline"><semantics ><msub ><mi  >Y</mi><mi >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑌</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >Y_{i}</annotation></semantics></math> have the following relationship:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个数据集 <math   alttext="W={\{W_{i}\}}_{i=1}^{N}" display="inline"><semantics
    ><mrow  ><mi >W</mi><mo >=</mo><msubsup  ><mrow ><mo stretchy="false" >{</mo><msub
    ><mi  >W</mi><mi >i</mi></msub><mo stretchy="false"  >}</mo></mrow><mrow ><mi
    >i</mi><mo  >=</mo><mn >1</mn></mrow><mi >N</mi></msubsup></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><ci >𝑊</ci><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><set ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></set><apply ><ci >𝑖</ci><cn type="integer" >1</cn></apply></apply><ci
    >𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex"
    >W={\{W_{i}\}}_{i=1}^{N}</annotation></semantics></math> 包含 <math   alttext="N"
    display="inline"><semantics ><mi  >N</mi><annotation-xml encoding="MathML-Content"
    ><ci  >𝑁</ci></annotation-xml><annotation encoding="application/x-tex" >N</annotation></semantics></math>
    个 WSIs，每个图像 <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> 都有一个对应的标签 <math   alttext="Y_{i}\in\left\{0,1\right\},\
    i=\{1,2,...N\}" display="inline"><semantics ><mrow ><mrow  ><msub ><mi >Y</mi><mi  >i</mi></msub><mo
    >∈</mo><mrow ><mo  >{</mo><mn >0</mn><mo >,</mo><mn  >1</mn><mo >}</mo></mrow></mrow><mo
    rspace="0.667em"  >,</mo><mrow ><mi >i</mi><mo  >=</mo><mrow ><mo stretchy="false"
    >{</mo><mn >1</mn><mo  >,</mo><mn >2</mn><mo >,</mo><mrow  ><mi mathvariant="normal"  >…</mi><mo
    lspace="0em" rspace="0em"  >​</mo><mi >N</mi></mrow><mo stretchy="false"  >}</mo></mrow></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply ><csymbol cd="ambiguous"  >formulae-sequence</csymbol><apply
    ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑌</ci><ci  >𝑖</ci></apply><set
    ><cn type="integer" >0</cn><cn type="integer" >1</cn></set></apply><apply ><ci  >𝑖</ci><set
    ><cn type="integer" >1</cn><cn type="integer" >2</cn><apply  ><ci >…</ci><ci >𝑁</ci></apply></set></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}\in\left\{0,1\right\},\ i=\{1,2,...N\}</annotation></semantics></math>。现在，每个
    WSI <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑊</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >W_{i}</annotation></semantics></math> 被切割成小块 <math   alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}"
    display="inline"><semantics ><mrow  ><mo stretchy="false"  >{</mo><mrow ><mrow
    ><mrow  ><msub ><mi >p</mi><mrow ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo
    >,</mo><mi >j</mi></mrow><mo >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo
    >,</mo><mi mathvariant="normal"  >…</mi><mo >,</mo><msub ><mi >n</mi><mi >i</mi></msub></mrow></mrow><mo
    stretchy="false" >}</mo></mrow><annotation-xml encoding="MathML-Content" ><set  ><apply
    ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><list ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply><ci
    >𝑗</ci></list><cn type="integer" >1</cn></apply><list ><cn type="integer" >2</cn><ci
    >…</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑛</ci><ci >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>，这些小块之间不重叠，其中
    <math   alttext="n_{i}" display="inline"><semantics ><msub  ><mi >n</mi><mi >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑛</ci><ci >𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex"
    >n_{i}</annotation></semantics></math> 是小块的数量。所有的小块 <math   alttext="\{p_{i,j},j=1,2,\ldots,n_{i}\}"
    display="inline"><semantics ><mrow  ><mo stretchy="false"  >{</mo><mrow ><mrow
    ><mrow  ><msub ><mi >p</mi><mrow ><mi >i</mi><mo  >,</mo><mi >j</mi></mrow></msub><mo
    >,</mo><mi >j</mi></mrow><mo >=</mo><mn  >1</mn></mrow><mo >,</mo><mrow ><mn  >2</mn><mo
    >,</mo><mi mathvariant="normal"  >…</mi><mo >,</mo><msub ><mi >n</mi><mi >i</mi></msub></mrow></mrow><mo
    stretchy="false" >}</mo></mrow><annotation-xml encoding="MathML-Content" ><set  ><apply
    ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><list ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑝</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply><ci
    >𝑗</ci></list><cn type="integer" >1</cn></apply><list ><cn type="integer" >2</cn><ci
    >…</ci><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑛</ci><ci >𝑖</ci></apply></list></apply></set></annotation-xml><annotation
    encoding="application/x-tex" >\{p_{i,j},j=1,2,\ldots,n_{i}\}</annotation></semantics></math>
    在 <math   alttext="W_{i}" display="inline"><semantics ><msub  ><mi >W</mi><mi  >i</mi></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="
- en: '|  | <math   alttext="Y_{i}=\left\{\begin{array}[]{cc}&amp;0,\text{ if }\sum_{j}y_{i,j}=0\\
    &amp;1,\text{ else }\end{array}\right." display="block"><semantics ><mrow  ><msub
    ><mi  >Y</mi><mi >i</mi></msub><mo >=</mo><mrow  ><mo >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr ><mtd  ><mrow ><mrow ><mn  >0</mn><mo
    >,</mo><mrow ><mtext  > if </mtext><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mstyle displaystyle="false"  ><msub ><mo >∑</mo><mi >j</mi></msub></mstyle><msub
    ><mi >y</mi><mrow ><mi >i</mi><mo >,</mo><mi  >j</mi></mrow></msub></mrow></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow></mtd></mtr><mtr ><mtd  ><mrow ><mn >1</mn><mo  >,</mo><mtext
    > else </mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝑌</ci><ci
    >𝑖</ci></apply><apply ><csymbol cd="latexml"  >cases</csymbol><matrix ><matrixrow
    ><cerror  ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><apply
    ><list ><cn type="integer" >0</cn><apply  ><ci ><mtext > if </mtext></ci><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑗</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑦</ci><list ><ci >𝑖</ci><ci  >𝑗</ci></list></apply></apply></apply></list><cn
    type="integer"  >0</cn></apply></matrixrow><matrixrow ><cerror  ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><list
    ><cn type="integer" >1</cn><ci ><mtext  > else </mtext></ci></list></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}=\left\{\begin{array}[]{cc}&0,\text{ if }\sum_{j}y_{i,j}=0\\
    &1,\text{ else }\end{array}\right.</annotation></semantics></math> |  | (1) |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '|  | <math   alttext="Y_{i}=\left\{\begin{array}[]{cc}&amp;0,\text{ if }\sum_{j}y_{i,j}=0\\
    &amp;1,\text{ else }\end{array}\right." display="block"><semantics ><mrow  ><msub
    ><mi  >Y</mi><mi >i</mi></msub><mo >=</mo><mrow  ><mo >{</mo><mtable columnspacing="5pt"
    displaystyle="true" rowspacing="0pt"  ><mtr ><mtd  ><mrow ><mrow ><mn  >0</mn><mo
    >,</mo><mrow ><mtext  > if </mtext><mo lspace="0em" rspace="0em"  >​</mo><mrow
    ><mstyle displaystyle="false"  ><msub ><mo >∑</mo><mi >j</mi></msub></mstyle><msub
    ><mi >y</mi><mrow ><mi >i</mi><mo >,</mo><mi  >j</mi></mrow></msub></mrow></mrow></mrow><mo
    >=</mo><mn >0</mn></mrow></mtd></mtr><mtr ><mtd  ><mrow ><mn >1</mn><mo  >,</mo><mtext
    > else </mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content"
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝑌</ci><ci
    >𝑖</ci></apply><apply ><csymbol cd="latexml"  >cases</csymbol><matrix ><matrixrow
    ><cerror  ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><apply
    ><list ><cn type="integer" >0</cn><apply  ><ci ><mtext > if </mtext></ci><apply
    ><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑗</ci></apply><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑦</ci><list ><ci >𝑖</ci><ci  >𝑗</ci></list></apply></apply></apply></list><cn
    type="integer"  >0</cn></apply></matrixrow><matrixrow ><cerror  ><csymbol cd="ambiguous"  >missing-subexpression</csymbol></cerror><list
    ><cn type="integer" >1</cn><ci ><mtext  > else </mtext></ci></list></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >Y_{i}=\left\{\begin{array}[]{cc}&0,\text{ if }\sum_{j}y_{i,j}=0\\
    &1,\text{ else }\end{array}\right.</annotation></semantics></math> |  | (1) |'
- en: It means that the labels of all instances in the negative bag are negative,
    while at least one positive instance exists in the positive bag and the labels
    of instances <math   alttext="y_{i,j}" display="inline"><semantics ><msub  ><mi
    >y</mi><mrow  ><mi >i</mi><mo >,</mo><mi  >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑦</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math> are unknown.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 这意味着负袋中的所有实例标签都是负的，而正袋中至少存在一个正实例，且实例的标签<math   alttext="y_{i,j}" display="inline"><semantics
    ><msub  ><mi >y</mi><mrow  ><mi >i</mi><mo >,</mo><mi  >j</mi></mrow></msub><annotation-xml
    encoding="MathML-Content" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝑦</ci><list ><ci  >𝑖</ci><ci >𝑗</ci></list></apply></annotation-xml><annotation
    encoding="application/x-tex" >y_{i,j}</annotation></semantics></math> 是未知的。
- en: '![Refer to caption](img/7568353672e6498d941fd536fe5ff599.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7568353672e6498d941fd536fe5ff599.png)'
- en: 'Figure 1: General overview of the learning paradigms reviewed in this paper,
    depicted as an example of classifying normal tissue (green) and cancerous tissue
    (red) in a WSI. Note that the training data and testing data in this figure are
    used for description only and are not necessarily the real case. (a) Supervised
    learning paradigm. (b) Weakly Supervised learning paradigm. (c) Semi-supervised
    learning paradigm. (d) Self-supervised learning paradigm.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：本文回顾的学习范式的一般概述，展示了在 WSI 中分类正常组织（绿色）和癌组织（红色）的示例。请注意，这图中的训练数据和测试数据仅用于描述，并不一定是真实情况。
    (a) 监督学习范式。 (b) 弱监督学习范式。 (c) 半监督学习范式。 (d) 自监督学习范式。
- en: 'As shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis") (b), generally,
    there are two main goals of deep learning-based WSI analysis, one is global slide
    classification, i.e., to accurately classify each WSI, and the other is positive
    patch localization, i.e., to accurately classify each instance in positive bags.
    A review of the current state-of-the-art weakly supervised learning methods is
    presented in Section [3.1](#S3.SS1 "3.1 Weakly Supervised Learning Paradigm ‣
    3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis").'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms and Problem Formulation
    ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis") (b)所示，深度学习基础的WSI分析通常有两个主要目标，一个是全局幻灯片分类，即准确分类每个WSI，另一个是正样本定位，即准确分类每个正样本包中的实例。有关当前最先进的弱监督学习方法的综述见[3.1](#S3.SS1
    "3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")节。'
- en: 'In the semi-supervised learning paradigm, we only have a very small number
    of patches with labels, in addition to a large number of unlabeled patches that
    can also be used for training. Therefore, the main goal of the semi-supervised
    learning paradigm is how to use the unlabeled data to improve the performance
    of the models trained with limited labeled data. As shown in Figure [1](#S2.F1
    "Figure 1 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards
    Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced
    Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised Techniques
    in Histopathological Image Analysis") (c), in contrast to the supervised learning
    paradigm, the semi-supervised learning paradigm makes use of a large amount of
    unlabeled data while training with the labeled data. During testing, the trained
    model is used to predict the labels of the patches in test WSIs. See Section [3.2](#S3.SS2
    "3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") for a detailed review of the semi-supervised learning methods.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: '在半监督学习范式中，我们仅有少量带标签的样本，以及大量未标记的样本也可以用于训练。因此，半监督学习范式的主要目标是如何利用未标记的数据来提高在有限带标签数据上训练的模型的性能。如图[1](#S2.F1
    "Figure 1 ‣ 2 Overview of Learning Paradigms and Problem Formulation ‣ Towards
    Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced
    Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised Techniques
    in Histopathological Image Analysis") (c)所示，与监督学习范式相比，半监督学习范式在使用带标签数据进行训练的同时，利用大量未标记的数据。在测试阶段，训练好的模型被用于预测测试WSI中样本的标签。有关半监督学习方法的详细综述见[3.2](#S3.SS2
    "3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")节。'
- en: Self-supervised learning is a hybrid learning approach, which combines unsupervised
    and supervised learning paradigms in a pre-training and fine-tuning manner. The
    aim is to get better results of supervised training though generating supervised
    information from a large amount of unlabeled data, which can learn better feature
    representations, and can reduce manual annotation in the subsequent tasks. Due
    to the small amount of annotated data, it is not sufficient to use these data
    directly to train the model. Therefore, the self-supervised learning paradigm
    first learns a primary feature representation from a large amount of unlabeled
    data, which is called the pre-training process. The feature representations learned
    in the self-supervised auxiliary tasks are then transferred for further training
    in downstream tasks using limited labeled data, which is called the fine-tuning
    process. In this way, the primary feature representations can effectively help
    the network to achieve an effective training result with less labeled data.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督学习是一种混合学习方法，结合了无监督学习和监督学习范式，通过预训练和微调的方式进行。其目的是通过从大量未标记数据中生成监督信息来获得更好的监督训练结果，这可以学到更好的特征表示，并减少后续任务中的人工标注。由于标注数据量少，直接使用这些数据训练模型是不够的。因此，自监督学习范式首先从大量未标记数据中学习主要的特征表示，这称为预训练过程。然后，将在自监督辅助任务中学到的特征表示转移到下游任务中，使用有限的标记数据进行进一步训练，这称为微调过程。通过这种方式，主要的特征表示可以有效地帮助网络在少量标记数据下实现有效的训练结果。
- en: 'As shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Overview of Learning Paradigms
    and Problem Formulation ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis") (d), the
    pre-training process of the self-supervised learning paradigm is typically performed
    through self-supervised auxiliary tasks. In the self-supervised auxiliary tasks,
    certain inherent properties of the unlabeled data are first utilized to generate
    supervised information, and then the network is trained by the self-supervised
    information, such as self-reconstruction, random rotation followed by angle prediction,
    color information discarding followed by colorization, and patch position disruption
    followed by restoration. Once accomplishing these self-supervised auxiliary tasks,
    the effective feature representations can be extracted. The fine-tuning process
    of self-supervised learning is done in the downstream tasks. During the fine-tuning
    process, a small amount of labeled data is used to perform the supervised training,
    and the model is not trained from scratch, but is further trained using the feature
    representations learned in the auxiliary tasks as the initial weights of the network.
    Finally, the trained network is used for testing. A review of the state-of-the-art
    self-supervised learning methods is presented in Section [3.3](#S3.SS3 "3.3 Self-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis").'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [1](#S2.F1 "图 1 ‣ 2 学习范式和问题表述概述 ‣ 面向标签高效的自动诊断和分析：基于深度学习的先进弱监督、半监督和自监督技术在组织病理图像分析中的全面调查")
    (d) 所示，自监督学习范式的预训练过程通常通过自监督辅助任务来完成。在自监督辅助任务中，首先利用未标记数据的某些固有特性生成监督信息，然后通过自监督信息（例如自我重建、随机旋转后角度预测、颜色信息丢弃后颜色化以及补丁位置破坏后恢复）来训练网络。一旦完成这些自监督辅助任务，就可以提取有效的特征表示。自监督学习的微调过程在下游任务中进行。在微调过程中，使用少量标记数据进行监督训练，模型不是从头开始训练，而是利用在辅助任务中学到的特征表示作为网络的初始权重进行进一步训练。最后，使用训练好的网络进行测试。最先进的自监督学习方法的综述见第
    [3.3](#S3.SS3 "3.3 自监督学习范式 ‣ 3 范式 ‣ 面向标签高效的自动诊断和分析：基于深度学习的先进弱监督、半监督和自监督技术在组织病理图像分析中的全面调查")
    节。
- en: 'Table 2: Intuitive summary and comparison of the four paradigms.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：四种范式的直观总结和比较。
- en: '| Methods | Input | Suitable tasks | Technical paradigms | Strengths | Weaknesses
    |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 输入 | 适用任务 | 技术范式 | 优势 | 劣势 |'
- en: '| Supervised learning paradigm | A large number of small patches (tiled from
    WSIs) with fine-grained labels | WSI-level and patch-level classification/segmentation/regression
    | - | Broad application, effective and simple training | Require large amount
    of fine-grained labeled data |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| 监督学习范式 | 大量的小块（从WSIs拼接而来）带有细粒度标签 | WSI级别和小块级别的分类/分割/回归 | - | 广泛应用，有效且简单的训练
    | 需要大量的细粒度标注数据 |'
- en: '| Weakly Supervised learning paradigm | Entire WSIs with overall labels or
    sparse labels | WSI-level classification/segmentation/regression, Patch-level
    coarse-grained localization | Instance-based approach, Bag-based approach, Hybrid
    approach | No need for fine-grained annotation, effectively reduce the burden
    of data annotation | Achieve limited performance for fine-grained tasks |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| 弱监督学习范式 | 整个WSI带有整体标签或稀疏标签 | WSI级别分类/分割/回归，小块级别粗粒度定位 | 基于实例的方法，基于包的方法，混合方法
    | 不需要细粒度标注，有效减少数据标注负担 | 对细粒度任务的表现有限 |'
- en: '| Semi-supervised learning paradigm | A limited number of small patches (tiled
    from WSIs) with fine-grained labels | WSI-level and patch-level classification/segmentation/regression
    | Pseudo-labelling-based approach, Consistency-based approach, Graph-based approach,
    Unsupervised-preprocessing-based approach, GAN-based approach and others | Require
    only a small amount of fine-grained annotation, effectively reduce the burden
    of data annotation | Need to satisfy various semi-supervised assumptions |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 半监督学习范式 | 有限数量的小块（从WSIs拼接而来）带有细粒度标签 | WSI级别和小块级别的分类/分割/回归 | 基于伪标注的方法，一致性方法，图形方法，无监督预处理方法，GAN方法等
    | 只需少量细粒度标注，有效减少数据标注负担 | 需要满足各种半监督假设 |'
- en: '| Self-supervised learning paradigm | A large number of small patches (tiled
    from WSIs) without labels | Patch-level feature representations, Multiple related
    down-stream tasks | Predictive approach, Generative approach, Contrastive approach,
    Hybrid approach | Efficiently extract image features from a large amount of unsupervised
    data, effectively reduce the data annotation burden | May result in information
    loss when the extracted features are not applicable to downstream tasks |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| 自监督学习范式 | 大量的小块（从WSIs拼接而来）没有标签 | 小块级别的特征表示，多个相关的下游任务 | 预测方法，生成方法，对比方法，混合方法
    | 从大量无监督数据中高效提取图像特征，有效减少数据标注负担 | 当提取的特征不适用于下游任务时，可能会导致信息丢失 |'
- en: 3 Paradigms
  id: totrans-60
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 个范式
- en: 3.1 Weakly Supervised Learning Paradigm
  id: totrans-61
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 弱监督学习范式
- en: In this section, we provide a comprehensive review of the primary deep multiple
    instance learning (MIL) methods currently used in the weakly supervised learning
    paradigm for computational pathology. In MIL, each WSI is considered as a bag
    containing many patches (also called instances). If a WSI (bag) is labeled disease-positive,
    then at least one patch (instance) in that WSI is disease-positive; if a WSI is
    disease-negative, then all patches in that WSI are negative.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们全面回顾了目前在计算病理学的弱监督学习范式中使用的主要深度多实例学习（MIL）方法。在MIL中，每个WSI被视为一个包含多个小块（也称为实例）的包。如果WSI（包）被标记为疾病阳性，那么该WSI中的至少一个小块（实例）也是疾病阳性；如果WSI是疾病阴性，则该WSI中的所有小块都是阴性。
- en: 'We categorize the current deep MIL methods for WSI analysis into instance-based
    methods, bag-based methods, and hybrid methods. Our categorization is mainly based
    on whether the methods contain an instance classifier or a bag classifier, i.e.,
    instance-based methods contain only an instance classifier; bag-based methods
    contain only a bag classifier; while hybrid methods contain both an instance classifier
    and a bag classifier. In this way, the categories clearly cover almost current
    deep MIL methods for WSI analysis. A diagram of the three methods above is shown
    in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis").
    The detailed literatures in this section are summarized in Table [3](#S3.T3 "Table
    3 ‣ 3.1.4 Representative Clinical Studies ‣ 3.1 Weakly Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis").'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将当前用于WSI分析的深度MIL方法分为基于实例的方法、基于包的方法和混合方法。我们的分类主要依据方法是否包含实例分类器或包分类器，即，基于实例的方法仅包含实例分类器；基于包的方法仅包含包分类器；而混合方法则同时包含实例分类器和包分类器。这样，类别就清晰地覆盖了几乎所有当前用于WSI分析的深度MIL方法。上述三种方法的图示见图[2](#S3.F2
    "图 2 ‣ 3.1.1 基于实例的方法 ‣ 3.1 弱监督学习范式 ‣ 3 种范式 ‣ 面向标签高效的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面调查")。本节的详细文献总结在表[3](#S3.T3
    "表 3 ‣ 3.1.4 代表性临床研究 ‣ 3.1 弱监督学习范式 ‣ 3 种范式 ‣ 面向标签高效的自动诊断与分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面调查")。
- en: 3.1.1 Instance-based Approach
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 基于实例的方法
- en: 'The main idea of the instance-based approach is to train a good instance classifier
    to accurately predict the potential labels of instances in each bag, and then
    use MIL-pooling to aggregate the predictions of all instances in each bag to obtain
    the prediction of the bag. The details are shown in Figure [2](#S3.F2 "Figure
    2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣
    3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis") (a). Since the
    true labels of each instance are unknown, these approaches usually first assign
    the labels of each instance with their corresponding bags as the pseudo labels
    (i.e., all instances in a positive bag are given positive labels, and all instances
    in a negative bag are given negative labels), and then train the instance classifier
    using a supervised way until it converges. The loss function is usually the cross-entropy
    function defined between the predictions of the instance classifier and the pseudo
    labels. After training, the instance classifier is used to make predictions for
    all instances in the test bag, and then the predictions of each instance are aggregated
    to obtain the prediction of the bag, and this aggregation process is called MIL-pooling.
    Commonly used MIL pooling methods include Mean-pooling (Wang *et al.* [2018](#bib.bib182)),
    Max-pooling (Feng *et al.* [2017](#bib.bib56), Wang *et al.* [2018](#bib.bib182),
    Wu *et al.* [2015](#bib.bib189)), Voting (Cruz-Roa *et al.* [2014](#bib.bib40)),
    log-sum-exp-pooling (Ramon *et al.* [2000](#bib.bib135)), Noisy-or-pooling (Maron
    *et al.* [1997](#bib.bib110)), Noisy-and-pooling (Kraus *et al.* [2016](#bib.bib90)),
    and Dynamic pooling (Yan *et al.* [2018](#bib.bib197)) among others.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '实例化方法的主要思想是训练一个优秀的实例分类器，以准确预测每个袋子中实例的潜在标签，然后使用MIL-pooling将每个袋子中所有实例的预测结果进行聚合，从而获得袋子的预测结果。详细信息见图[2](#S3.F2
    "Figure 2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis")（a）。由于每个实例的真实标签未知，这些方法通常首先将每个实例的标签与其对应的袋子作为伪标签（即，正袋中的所有实例被赋予正标签，负袋中的所有实例被赋予负标签），然后使用监督方式训练实例分类器，直到其收敛。损失函数通常是实例分类器预测结果与伪标签之间的交叉熵函数。训练后，实例分类器用于对测试袋中的所有实例进行预测，然后将每个实例的预测结果进行聚合以获得袋子的预测结果，这一聚合过程称为MIL-pooling。常用的MIL
    pooling方法包括均值池化（Wang *et al.* [2018](#bib.bib182)）、最大池化（Feng *et al.* [2017](#bib.bib56),
    Wang *et al.* [2018](#bib.bib182), Wu *et al.* [2015](#bib.bib189)）、投票（Cruz-Roa
    *et al.* [2014](#bib.bib40)）、对数和指数池化（Ramon *et al.* [2000](#bib.bib135)）、噪声或池化（Maron
    *et al.* [1997](#bib.bib110)）、噪声与池化（Kraus *et al.* [2016](#bib.bib90)）和动态池化（Yan
    *et al.* [2018](#bib.bib197)）等。'
- en: '![Refer to caption](img/b98364eaa5ad47a7afa0b4eecc6a86ba.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b98364eaa5ad47a7afa0b4eecc6a86ba.png)'
- en: 'Figure 2: Overview of multiple instance learning methods. (a) Instance-based
    Approach. (b) Bag-based Approach. (c) Two-stage Hybrid Approach. (c) End-to-End
    Hybrid Approach.'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：多实例学习方法概览。（a）实例化方法。（b）袋子方法。（c）两阶段混合方法。（d）端到端混合方法。
- en: Instance-based approach is more common in early studies, and its main advantage
    lies in the direct prediction of each instance so that the localization task can
    be performed conveniently. However, it has two major drawbacks. First, since the
    true labels of each instance in the positive bags are not necessarily all positive,
    the pseudo labels assigned to the instances in the positive bags are noisy, which
    will lead to inaccurate training of the instance classifier; Second, the MIL-pooling
    method, which aggregates the predictions of instances in each bag, is manually
    designed and non-trainable, making it less flexible and robust. Therefore, the
    performance of these methods is usually limited.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 实例化方法在早期研究中更为常见，其主要优点在于能够直接预测每个实例，从而方便进行定位任务。然而，它有两个主要缺点。首先，由于正袋中每个实例的真实标签不一定全部为正标签，因此赋予正袋中实例的伪标签是嘈杂的，这会导致实例分类器训练不准确；其次，MIL-pooling方法将每个袋子中实例的预测结果进行聚合，是手动设计且不可训练的，使其灵活性和鲁棒性较差。因此，这些方法的性能通常受限。
- en: 3.1.2 Bag-based Approach
  id: totrans-69
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 袋子方法
- en: 'The main idea of the bag-based approaches is to first extract the features
    of each instance in a bag using shared instance-level feature extractors, then
    use MIL-pooling to aggregate the instance-level features to obtain the bag-level
    features, and then train the bag classifier in a supervised manner until it converges.
    The specific diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based
    Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (b). The loss function is usually defined as the cross-entropy
    loss between the predictions of the bag classifier and the true bag labels.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 基于包的方法的主要思路是首先使用共享的实例级特征提取器提取包中每个实例的特征，然后使用 MIL-pooling 聚合实例级特征以获得包级特征，然后以监督方式训练包分类器直至收敛。具体示意图见图
    [2](#S3.F2 "图 2 ‣ 3.1.1 基于实例的方法 ‣ 3.1 弱监督学习范式 ‣ 3 范式 ‣ 面向标签效率自动诊断和分析：基于深度学习的弱监督、半监督和自监督技术在组织病理图像分析中的全面调查")
    (b)。损失函数通常定义为包分类器预测与真实包标签之间的交叉熵损失。
- en: MIL-pooling also exists in bag-based methods, but unlike instance-based methods,
    MIL-pooling here aggregates not the predictions of instances, but the features
    of instances. Mean-pooling, Max-pooling and other aggregation methods can also
    be used as aggregation methods for instance features, but their drawbacks remain,
    i.e., they cannot be trained and adjusted adaptively, so they are often not flexible
    enough.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: MIL-pooling 在基于包的方法中也存在，但不同于基于实例的方法，MIL-pooling 在这里聚合的不是实例的预测结果，而是实例的特征。均值池化、最大池化及其他聚合方法也可以用作实例特征的聚合方法，但它们的缺点仍然存在，即它们无法自适应地训练和调整，因此通常不够灵活。
- en: The key of the bag-based methods is the training of the bag classifier. Since
    the true labels of the bags are available, there is no noise in their training
    process, so these methods tend to be more accurate than instance-based methods
    in bag classification. However, a serious problem of the bag-based approaches
    is that they cannot perform the localization task easily. Furthermore, the aggregation
    functions for instance features are not flexible enough to show the contribution
    of different instances to bag classification.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 基于包的方法的关键在于包分类器的训练。由于包的真实标签是已知的，因此在训练过程中没有噪声，因此这些方法在包分类中往往比基于实例的方法更准确。然而，基于包的方法的一个严重问题是它们无法轻易地执行定位任务。此外，实例特征的聚合函数不够灵活，无法展示不同实例对包分类的贡献。
- en: Attention-based Approach
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于注意力的方法
- en: Ilse *et al.* [2018](#bib.bib77) have alleviated these dilemmas. They first
    proposed to use the trainable attention mechanism to aggregate instance features,
    and started a wave of study on attention-based aggregation methods by subsequent
    bag-based methods. They trained both the instance-level feature extractor and
    a bag-level classifier using an end-to-end manner, and used the attention mechanism
    to aggregate the features and measure the significance of each instance. Tu *et
    al.* [2019](#bib.bib173) proposed a new end-to-end graph neural network (GNN)
    for instance aggregation. This work is the first GNN-based MIL work. Hashimoto
    *et al.* [2020](#bib.bib72) proposed a novel end-to-end method for cancer subtype
    classification by combining MIL, domain adversarial and multiscale learning frameworks.
    Yao, Zhu *et al.* [2017](#bib.bib212), [2020](#bib.bib202) proposed a deep attention
    guided MIL framework for cancer survival analysis. They first used a pre-trained
    model from ImageNet (Deng *et al.* [2009](#bib.bib47)) to extract the features
    of instances in each bag, and then used K-means algorithm to cluster the instances
    in each bag to obtain the phenotypic patterns, and finally applied attention mechanism
    to aggregate the features of these patterns and performed prediction.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 伊尔斯*等人* [2018](#bib.bib77) 缓解了这些困境。他们首次提出使用可训练的注意力机制来聚合实例特征，并通过后续的包级方法开启了基于注意力的聚合方法的研究浪潮。他们采用端到端方式训练了实例级特征提取器和包级分类器，并使用注意力机制聚合特征并衡量每个实例的重要性。图*等人*
    [2019](#bib.bib173) 提出了用于实例聚合的新型端到端图神经网络（GNN）。这项工作是首个基于GNN的MIL工作。桥本*等人* [2020](#bib.bib72)
    提出了通过结合MIL、领域对抗和多尺度学习框架的癌症亚型分类的新型端到端方法。姚、朱*等人* [2017](#bib.bib212), [2020](#bib.bib202)
    提出了用于癌症生存分析的深度注意力引导MIL框架。他们首先使用来自ImageNet的预训练模型（邓*等人* [2009](#bib.bib47)）提取每个包中实例的特征，然后使用K-means算法对每个包中的实例进行聚类，以获得表型模式，最后应用注意力机制聚合这些模式的特征并进行预测。
- en: Self-supervised Pre-training-based Approach
  id: totrans-75
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于自监督预训练的方法
- en: Due to the extremely large size of WSIs and the large number of instances cut
    out, direct end-to-end training of all instances is easily limited by computational
    resources. Therefore, some studies first use advanced self-supervised pre-training
    methods to characterize each instance and then perform subsequent training. Lu
    *et al.* [2019](#bib.bib104) first proposed to obtain instance-level feature representations
    by self-supervised contrastive predictive coding (CPC), and then used the attention-based
    MIL method for instance aggregation to perform bag-level classification. This
    is the first MIL study using self-supervised contrastive learning. Zhao *et al.* [2020](#bib.bib206)
    used a pre-trained VAE-GAN (Larsen *et al.* [2016](#bib.bib93)) to extract instance-level
    features, and then used GNN to aggregate instance features and perform bag-level
    classification. Li *et al.* [2021](#bib.bib97) proposed DSMIL, where they used
    contrastive pre-training (Chen *et al.* [2020](#bib.bib26)) to obtain the instance
    features, and then proposed the masked non-local operation-based dual-stream aggregator
    to perform both instance-level classification and bag-level classification.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 由于WSIs的极大尺寸和大量切割出的实例，直接对所有实例进行端到端训练很容易受到计算资源的限制。因此，一些研究首先使用先进的自监督预训练方法来刻画每个实例，然后进行后续训练。卢*等人*
    [2019](#bib.bib104) 首次提出通过自监督对比预测编码（CPC）获得实例级特征表示，然后使用基于注意力的MIL方法进行实例聚合，以执行包级分类。这是首个使用自监督对比学习的MIL研究。赵*等人*
    [2020](#bib.bib206) 使用预训练的VAE-GAN（拉尔森*等人* [2016](#bib.bib93)）来提取实例级特征，然后使用GNN聚合实例特征并进行包级分类。李*等人*
    [2021](#bib.bib97) 提出了DSMIL，他们使用对比预训练（陈*等人* [2020](#bib.bib26)）来获取实例特征，然后提出了基于掩蔽非局部操作的双流聚合器，以进行实例级分类和包级分类。
- en: Transformer Based Approach
  id: totrans-77
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基于Transformer的方法
- en: In MIL-based WSI analysis, not only the contribution of different instances
    to bag classification should be considered, the relationships among different
    instances should also be fully explored, because different instances in a WSI
    are not isolated from each other, but have strong correlation. To address this
    issue, Shao *et al.* [2021](#bib.bib146) and Li *et al.* [2021](#bib.bib99) et
    al. used Transformer-based architectures to aggregate instances and both achieved
    promising results. The former designed a Transformer-based correlated MIL framework
    to explore the morphological and spatial information among different instances
    and provided related proofs. The latter presented a MIL framework based on the
    deformable transformer and convolutional layers.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在基于MIL的WSI分析中，除了考虑不同实例对包分类的贡献外，还应充分探索不同实例之间的关系，因为WSI中的不同实例并不是彼此孤立的，而是有强关联的。为了解决这个问题，Shao
    *et al.* [2021](#bib.bib146) 和 Li *et al.* [2021](#bib.bib99) 等使用了基于Transformer的架构来聚合实例，并取得了令人鼓舞的结果。前者设计了一种基于Transformer的相关MIL框架来探索不同实例之间的形态和空间信息，并提供了相关证明。后者提出了一种基于可变形变换器和卷积层的MIL框架。
- en: 3.1.3 Hybrid Approach
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.3 混合方法
- en: The hybrid approach combines the advantages of the above two approaches. It
    trains both the instance-level classifier and the bag-level classifier, and uses
    the former to predict the instance-level results while the latter for bag-level
    results. Overall, there are two types of the hybrid approaches. One is the two-stage
    approach and the other is the end-to-end approach.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 混合方法结合了上述两种方法的优点。它同时训练实例级分类器和包级分类器，使用前者预测实例级结果，而后者用于包级结果。总体而言，混合方法有两种类型，一种是两阶段方法，另一种是端到端方法。
- en: Two-stage Hybrid Approach
  id: totrans-81
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 两阶段混合方法
- en: 'The two-stage hybrid approach generally trains the instance classifier by assigning
    each instance in each bag with their corresponding bag labels as pseudo labels,
    and then trains the bag classifier to complete the bag classification based on
    the predictions of the instance classifier. Some studies have also attempted to
    select the key instances in each bag based on the predictions of the instance
    classifier, and then train the bag classifier based on these key instances. The
    specific diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based
    Approach ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (c). Hou *et al.* [2016](#bib.bib76) proposed a new Expectation-Maximization
    (EM) based model. They selected discriminative instances based on spatial relationship
    to train the instance classifier and fed the histogram of instance predictions
    into the multiclass logistic regression model and the SVM model (Chang *et al.* [2011](#bib.bib20))
    for bag prediction. Campanella *et al.* [2019](#bib.bib17) first selected key
    instances with the maximum prediction probability of the instance classifier in
    the current iteration and assigned pseudo labels of the corresponding bag labels
    to them. Then they fed the features of these key instances into the recurrent
    neural network (RNN) to perform the aggregation and prediction of the bags. Wang
    *et al.* [2019](#bib.bib181) selected key instances based on the predictions of
    positive instance probability and fed their features into the global feature descriptor
    and used the random forest algorithm to classify the bags. Chen *et al.* [2021](#bib.bib30)
    proposed a focal-aware module (FAM) and used thumbnails of WSI to automatically
    estimate the key regions associated with the diagnosis. Then, the instance features
    at different scales were extracted based on these key regions and aggregated using
    GNN to perform the bag classification.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 两阶段混合方法通常通过将每个袋中的每个实例分配其对应的袋标签作为伪标签来训练实例分类器，然后训练袋分类器，根据实例分类器的预测完成袋分类。一些研究也尝试基于实例分类器的预测选择每个袋中的关键实例，然后基于这些关键实例训练袋分类器。具体图示见图
    [2](#S3.F2 "图 2 ‣ 3.1.1 实例基础方法 ‣ 3.1 弱监督学习范式 ‣ 3 个范式 ‣ 迈向标签高效的自动诊断与分析：先进深度学习基础的弱监督、半监督和自监督技术在组织病理图像分析中的综合调查")
    (c)。Hou *等* [2016](#bib.bib76) 提出了一个新的基于期望最大化（EM）的模型。他们基于空间关系选择了具有区分性的实例来训练实例分类器，并将实例预测的直方图输入多类逻辑回归模型和SVM模型（Chang
    *等* [2011](#bib.bib20)）进行袋预测。Campanella *等* [2019](#bib.bib17) 首先在当前迭代中选择了实例分类器预测概率最大的关键实例，并将相应袋标签的伪标签分配给它们。然后，他们将这些关键实例的特征输入递归神经网络（RNN），以执行袋的聚合和预测。Wang
    *等* [2019](#bib.bib181) 基于正实例概率的预测选择了关键实例，并将其特征输入全局特征描述符，使用随机森林算法对袋进行分类。Chen *等*
    [2021](#bib.bib30) 提出了一个关注焦点模块（FAM），并使用WSI的缩略图自动估计与诊断相关的关键区域。然后，基于这些关键区域提取不同尺度的实例特征，并使用GNN进行聚合以执行袋分类。
- en: End-to-end Hybrid Approach
  id: totrans-83
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 端到端混合方法
- en: 'The end-to-end hybrid approach generally trains the instance-level classifier
    and the bag-level classifier at the same time. A common approach is to train the
    two classifiers simultaneously by assigning each instance the corresponding bag
    labels as pseudo labels on top of the bag classifier. Some studies also train
    the instance classifier to select the key instances in an epoch first, and then
    train the bag classifier after aggregating the instance features. The specific
    diagram is shown in Figure [2](#S3.F2 "Figure 2 ‣ 3.1.1 Instance-based Approach
    ‣ 3.1 Weakly Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") (d). Shi *et al.* [2020](#bib.bib151) proposed loss-based attention
    MIL. They added an instance-level loss function weighted by the instance attention
    scores based on AB-MIL (Ilse *et al.* [2018](#bib.bib77)) as a regularization
    term to improve the recall of instances and used consistency constraints to smooth
    the training process to improve the generalization ability. Chikontwe *et al.* [2020](#bib.bib33)
    combined top-k instance selection, instance-level representation learning, and
    bag-level representation in an end-to-end framework. Sharma *et al.* [2021](#bib.bib147)
    also combined instance selection, instance-level representation learning and bag-level
    representation in an end-to-end framework. Unlike (Chikontwe *et al.* [2020](#bib.bib33)),
    they proposed to use a clustering-based sampling method to select key instances.
    Lu *et al.* [2021](#bib.bib105) also proposed a MIL framework based on clustering
    and attention mechanisms. They selected the instances with the largest and smallest
    attention scores in the current bag for clustering to enhance the learning of
    feature space. Myronenko *et al.* [2021](#bib.bib116) proposed a MIL framework
    combining the Transformer and CNN architectures to compute the interrelationships
    between instances and aggregate the instances features to accomplish the bag classification.
    They added the instance loss to assist the optimization process.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '端到端混合方法通常同时训练实例级分类器和包级分类器。一个常见的方法是通过将每个实例分配到包分类器上作为伪标签来同时训练这两个分类器。一些研究还训练实例分类器首先在一个时期内选择关键实例，然后在汇总实例特征后训练包分类器。具体图示见图[2](#S3.F2
    "Figure 2 ‣ 3.1.1 Instance-based Approach ‣ 3.1 Weakly Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis") (d)。Shi *et al.*
    [2020](#bib.bib151) 提出了基于损失的注意力MIL。他们在AB-MIL (Ilse *et al.* [2018](#bib.bib77))
    的基础上增加了一个按实例注意力分数加权的实例级损失函数作为正则化项，以提高实例的召回率，并使用一致性约束来平滑训练过程，提高泛化能力。Chikontwe *et
    al.* [2020](#bib.bib33) 在端到端框架中结合了 top-k 实例选择、实例级表示学习和包级表示。Sharma *et al.* [2021](#bib.bib147)
    也在端到端框架中结合了实例选择、实例级表示学习和包级表示。与 (Chikontwe *et al.* [2020](#bib.bib33)) 不同，他们提出使用基于聚类的采样方法来选择关键实例。Lu
    *et al.* [2021](#bib.bib105) 还提出了一个基于聚类和注意力机制的MIL框架。他们在当前包中选择注意力分数最大和最小的实例进行聚类，以增强特征空间的学习。Myronenko
    *et al.* [2021](#bib.bib116) 提出了一个结合了 Transformer 和 CNN 架构的MIL框架，以计算实例之间的相互关系并汇总实例特征以完成包分类。他们增加了实例损失以辅助优化过程。'
- en: 3.1.4 Representative Clinical Studies
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.4 代表性临床研究
- en: A large number of outstanding studies have been dedicated to address significant
    clinical problems using weakly supervised methods. For example, Coudray *et al.* [2018](#bib.bib39)
    et al. developed deep learning models for accurate prediction of cancer subtypes
    and genetic mutations and sparked the whole field of weakly supervised computational
    pathology. Naik *et al.* [2020](#bib.bib118) et al. presented an attention-based
    deep MIL framework to predict directly estrogen receptor status from H&E slices.
    Another typical clinical work comes from Tomita *et al.* [2019](#bib.bib172),
    who proposed a grid-based attention network to perform 4-class classification
    of high-resolution endoscopic esophagus and gastroesophageal junction mucosal
    biopsy images from 379 patients. Skrede *et al.* [2020](#bib.bib156) developed
    a multi-scale deep MIL-based model to analyze conventional HE-stained slides and
    developed a model that can effectively predict the prognosis of patients after
    colorectal cancer surgery. Another gastrointestinal tract oncology study (Kather
    *et al.* [2019](#bib.bib85)) predicted microsatellite instability (MSI) based
    on a deep MIL model directly on HE-stained slides. Currently, weakly supervised
    deep-learning models for digital pathological analysis has been applied in a wide
    range of cancer types including breast, colorectal, lung, liver, cervical, thyroid,
    and bladder cancers (Coudray *et al.* [2018](#bib.bib39), Chaudhary *et al.* [2018](#bib.bib21),
    Wessels *et al.* [2021](#bib.bib186), Campanella *et al.* [2019](#bib.bib17),
    Anand *et al.* [2021](#bib.bib3), Yang *et al.* [2022](#bib.bib198), Li *et al.* [2021](#bib.bib98),
    Saillard *et al.* [2020](#bib.bib143), Velmahos *et al.* [2021](#bib.bib177),
    Woerl *et al.* [2020](#bib.bib188)).
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 大量杰出的研究致力于使用弱监督方法解决重大临床问题。例如，Coudray *et al.* [2018](#bib.bib39) 等人开发了用于精确预测癌症亚型和基因突变的深度学习模型，推动了整个弱监督计算病理学领域的发展。Naik
    *et al.* [2020](#bib.bib118) 等人提出了一种基于注意力的深度 MIL 框架，以从 H&E 切片中直接预测雌激素受体状态。另一个典型的临床工作来自
    Tomita *et al.* [2019](#bib.bib172)，他们提出了一种基于网格的注意力网络，以对来自 379 名患者的高分辨率内窥镜食管和胃食管交界处黏膜活检图像进行
    4 类分类。Skrede *et al.* [2020](#bib.bib156) 开发了一种多尺度深度 MIL 基模型来分析传统的 HE 染色切片，并开发了一种可以有效预测结直肠癌手术后患者预后的模型。另一个胃肠道肿瘤研究（Kather
    *et al.* [2019](#bib.bib85)）基于深度 MIL 模型直接在 HE 染色切片上预测微卫星不稳定性（MSI）。目前，弱监督深度学习模型已经广泛应用于包括乳腺癌、结直肠癌、肺癌、肝癌、宫颈癌、甲状腺癌和膀胱癌在内的多种癌症类型（Coudray
    *et al.* [2018](#bib.bib39), Chaudhary *et al.* [2018](#bib.bib21), Wessels *et
    al.* [2021](#bib.bib186), Campanella *et al.* [2019](#bib.bib17), Anand *et al.*
    [2021](#bib.bib3), Yang *et al.* [2022](#bib.bib198), Li *et al.* [2021](#bib.bib98),
    Saillard *et al.* [2020](#bib.bib143), Velmahos *et al.* [2021](#bib.bib177),
    Woerl *et al.* [2020](#bib.bib188))。
- en: 'Table 3: List of literatures in the weakly supervised learning section.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：弱监督学习部分文献列表。
- en: '|      Reference |      Approach |      Disease Type |      Staining |      Task
    |      Dataset |      Dataset Scale |      Dataset Link |      Performance |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '|      参考文献 |      方法 |      疾病类型 |      染色 |      任务 |      数据集 |      数据集规模
    |      数据集链接 |      性能 |'
- en: '|      Yan et al. ([2018](#bib.bib197)) |      Instance-based |      Breast
    Cancer |      H&E |       Benign and      malignant classification |      UCSB
    breast dataset |      58 cases |      Kandemir et al. ([2014](#bib.bib80)) |      Accuracy:
    0.927 |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '|      Yan 等人 ([2018](#bib.bib197)) |      基于实例 |      乳腺癌 |      H&E |      
    良性和恶性分类 |      UCSB 乳腺数据集 |      58 个病例 |      Kandemir 等人 ([2014](#bib.bib80))
    |      准确率：0.927 |'
- en: '|       Diabetes (from eye      fundus images) |      Messidor dataset |      1200
    cases |      Decencière et al. ([2014](#bib.bib44)) |      Accuracy: 0.740 |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '|       糖尿病（来自眼底图像） |      Messidor 数据集 |      1200 个病例 |      Decencière 等人
    ([2014](#bib.bib44)) |      准确率：0.740 |'
- en: '|      Kraus et al. ([2016](#bib.bib90)) |      Instance-based |      Breast
    Cancer |       Three channels with      fluorescent markers for      DNA, actin
    filaments,      and b-tubulin |       Classification of 12      distinct categories
    |       Broad Bioimage Benchmark      Collection (BBBC021v1) Dataset |      340
    cases |      Ljosa et al. ([2012](#bib.bib103)) |       Accuracy: 0.958 for full
         image, 0.971 for treatment |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '|      Kraus 等人 ([2016](#bib.bib90)) |      基于实例 |      乳腺癌 |       三通道荧光标记用于
    DNA、肌动蛋白纤维和 b-微管 |       12 个不同类别的分类 |       Broad Bioimage Benchmark Collection
    (BBBC021v1) 数据集 |      340 个病例 |      Ljosa 等人 ([2012](#bib.bib103)) |       准确率：完整图像
    0.958，处理图像 0.971 |'
- en: '|      Cruz-Roa et al. ([2014](#bib.bib40)) |      Instance-based |      Breast
    Cancer |      H&E |       Automatic detection of      invasive ductal carcinoma
         tissue regions |       Clinical histopathology dataset      collected from
    multiple hospitals |      162 cases |      inhouse |      Accuracy: 0.842 |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '|      Cruz-Roa 等人 ([2014](#bib.bib40)) |      基于实例的 |      乳腺癌 |      H&E
    |       侵袭性导管癌组织区域的自动检测 |       临床组织病理数据集 收集自多个医院 |      162 个案例 |      内部 |      准确率:
    0.842 |'
- en: '|      Ilse et al. ([2018](#bib.bib77)) |      Bag-based |      Breast Cancer
    |      H&E |       Automatic detection      of cancerous regions |      Breast
    cancer dataset |      58 cases |      Gelasca et al. ([2008](#bib.bib59)) |      Accuracy:
    0.755 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|      Ilse 等人 ([2018](#bib.bib77)) |      基于包的 |      乳腺癌 |      H&E |      
    癌变区域的自动检测 |      乳腺癌数据集 |      58 个案例 |      Gelasca 等人 ([2008](#bib.bib59)) |
         准确率: 0.755 |'
- en: '|      Colon Cancer |      Colon cancer dataset |      100 cases |      Sirinukunwattana
    et al. ([2016](#bib.bib155)) |      Accuracy: 0.904 |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '|      结肠癌 |      结肠癌数据集 |      100 个案例 |      Sirinukunwattana 等人 ([2016](#bib.bib155))
    |      准确率: 0.904 |'
- en: '|      Tu et al. ([2019](#bib.bib173)) |      Bag-based |       Diabetes (from
    eye      fundus images) |      H&E |       Diagnosing diabetes from      weakly
    labeled retinal images |      Messidor dataset |      1200 cases |      Decencière
    et al. ([2014](#bib.bib44)) |      Accuracy: 0.742 |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|      涂等人 ([2019](#bib.bib173)) |      基于包的 |       糖尿病（来自眼底图像） |      H&E
    |       从弱标记的视网膜图像中诊断糖尿病 |      Messidor 数据集 |      1200 个案例 |      Decencière
    等人 ([2014](#bib.bib44)) |      准确率: 0.742 |'
- en: '|      Hashimoto et al. ([2020](#bib.bib72)) |      Bag-based |      Malignant
    Lymphoma |      H&E |       Classification of malignant      lymphoma sub-types
    |       Clinical histopathology dataset      collected from multiple hospitals
    |      196 cases |      inhouse |      Accuracy: 0.871 |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|      Hashimoto 等人 ([2020](#bib.bib72)) |      基于包的 |      恶性淋巴瘤 |      H&E
    |       恶性淋巴瘤亚型分类 |       临床组织病理数据集 收集自多个医院 |      196 个案例 |      内部 |      准确率:
    0.871 |'
- en: '|      Yao et al. ([2020](#bib.bib202)) |      Bag-based |      Lung Cancer
    |      H&E |      Cancer survival prediction |       National Lung Screening      Trial
    (NLST) dataset |      387 cases |      Team et al. ([2011](#bib.bib169)) |      AUC:
    0.652 |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '|      姚等人 ([2020](#bib.bib202)) |      基于包的 |      肺癌 |      H&E |      癌症生存预测
    |       国家肺部筛查试验 (NLST) 数据集 |      387 个案例 |      团队等人 ([2011](#bib.bib169)) |
         AUC: 0.652 |'
- en: '|      Colorectal Cancer |       Molecular and Cellular      Oncology (MCO)
    dataset |      1146 cases |      Ward and Hawkins ([2015](#bib.bib184)) |      AUC:
    0.7143 |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '|      结直肠癌 |       分子和细胞肿瘤学 (MCO) 数据集 |      1146 个案例 |      Ward 和 Hawkins
    ([2015](#bib.bib184)) |      AUC: 0.7143 |'
- en: '|      Lu et al. ([2019](#bib.bib104)) |      Bag-based |      Breast Cancer
    |      H&E |      Classification of normal or benign |      BACH dataset |      400
    cases |      Aresta et al. ([2019](#bib.bib5)) |      Accuracy: 0.95 |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|      卢等人 ([2019](#bib.bib104)) |      基于包的 |      乳腺癌 |      H&E |      正常或良性分类
    |      BACH 数据集 |      400 个案例 |      Aresta 等人 ([2019](#bib.bib5)) |      准确率:
    0.95 |'
- en: '|      Zhao et al. ([2020](#bib.bib206)) |      Bag-based |      Colon Adenocarcinoma
    |      H&E |      Prediction of lymph node metastasis |       The Cancer Genome
         Atlas (TCGA) dataset |      425 cases |      Kandoth et al. ([2013](#bib.bib81))
    |      Accuracy: 0.6761 |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '|      赵等人 ([2020](#bib.bib206)) |      基于包的 |      结肠腺癌 |      H&E |      淋巴结转移预测
    |       癌症基因组图谱 (TCGA) 数据集 |      425 个案例 |      Kandoth 等人 ([2013](#bib.bib81))
    |      准确率: 0.6761 |'
- en: '|      Li, Li and Eliceiri ([2021](#bib.bib97)) |      Bag-based |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      Camelyon16
    dataset |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      Accuracy:
    0.8992 |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|      李、李和 Eliceiri ([2021](#bib.bib97)) |      基于包的 |      乳腺癌 |      H&E
    |      淋巴结转移检测 |      Camelyon16 数据集 |      400 个案例 |      Bejnordi 等人 ([2017b](#bib.bib10))
    |      准确率: 0.8992 |'
- en: '|      Lung Cancer |       Diagnosis of lung      cancer subtypes |       The
    Cancer Genome Atlas      (TCGA) lung cancer dataset |      1054 cases |      https://portal.gdc.cancer.gov/
    |      Accuracy: 0.9571 |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|      肺癌 |       肺癌亚型的诊断 |       癌症基因组图谱 (TCGA) 肺癌数据集 |      1054 个案例 |      https://portal.gdc.cancer.gov/
    |      准确率: 0.9571 |'
- en: '|      Shao et al. ([2021](#bib.bib146)) |      Bag-based |      Breast Cancer
    |      H&E |      Detection of lymph node metastases |      Camelyon16 dataset
    |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      Accuracy:
    0.8837 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '|      邵等人 ([2021](#bib.bib146)) |      基于包的 |      乳腺癌 |      H&E |      淋巴结转移检测
    |      Camelyon16 数据集 |      400 个案例 |      Bejnordi 等人 ([2017b](#bib.bib10))
    |      准确率: 0.8837 |'
- en: '|      Lung Cancer |      Diagnosis of cancer subtypes |      TCGA-NSCLC dataset
    |      993 cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.8835
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '|      肺癌 |      癌症亚型诊断 |      TCGA-NSCLC 数据集 |      993 例 |      https://portal.gdc.cancer.gov/
    |      准确率: 0.8835 |'
- en: '|      Kidney Cancer |      Diagnosis of cancer subtypes |      TCGA-RCC dataset
    |      884 cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.9466
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|      肾癌 |      癌症亚型诊断 |      TCGA-RCC 数据集 |      884 例 |      https://portal.gdc.cancer.gov/
    |      准确率: 0.9466 |'
- en: '|      Li, Yang, Zhao and Yao ([2021](#bib.bib99)) |      Bag-based |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      BREAST-LNM
    dataset |      3957 cases |      inhouse |      AUC: 0.7288 |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '|      Li, Yang, Zhao 和 Yao ([2021](#bib.bib99)) |      基于袋的 |      乳腺癌 |      H&E
    |      淋巴结转移检测 |      BREAST-LNM 数据集 |      3,957 例 |      内部 |      AUC: 0.7288
    |'
- en: '|      Lung Cancer |      Diagnosis of lung cancer subtypes |      CPTAC-LUAD
    dataset |      1065 cases |      Clark et al. ([2013](#bib.bib37)) |      AUC:
    0.9906 |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|      肺癌 |      肺癌亚型诊断 |      CPTAC-LUAD 数据集 |      1065 例 |      Clark 等人
    ([2013](#bib.bib37)) |      AUC: 0.9906 |'
- en: '|      Hou et al. ([2016](#bib.bib76)) |      Hybrid |      Glioma |      H&E
    |      Classification of glioma |       The Cancer Genome Atlas (TCGA) dataset
    |      209cases |      https://portal.gdc.cancer.gov/ |      Accuracy: 0.771 |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|      Hou 等人 ([2016](#bib.bib76)) |      混合 |      胶质瘤 |      H&E |      胶质瘤分类
    |       癌症基因组图谱 (TCGA) 数据集 |      209 例 |      https://portal.gdc.cancer.gov/
    |      准确率: 0.771 |'
- en: '|      Lung Cancer |       Diagnosis of non-small-cell      lung carcinoma
    subtypes |      316cases |      Accuracy: 0.798 |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '|      肺癌 |       非小细胞肺癌亚型诊断 |      316 例 |      准确率: 0.798 |'
- en: '|      Campanella et al. ([2019](#bib.bib17)) |      Hybrid |      Prostate
    Cancer |      H&E |      Benign and malignant classification |      Prostate core
    biopsy dataset |      24859 cases |      in house |      AUC: 0.986 |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '|      Campanella 等人 ([2019](#bib.bib17)) |      混合 |      前列腺癌 |      H&E
    |      良性与恶性分类 |      前列腺核心活检数据集 |      24,859 例 |      内部 |      AUC: 0.986 |'
- en: '|      Skin Cancer |      Benign and malignant classification |      Skin dataset
    |      9,962 cases |      in house |      AUC: 0.986 |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|      皮肤癌 |      良性与恶性分类 |      皮肤数据集 |      9,962 例 |      内部 |      AUC:
    0.986 |'
- en: '|      Breast Cancer |      Detection of lymph node metastases |      Breast
    dataset |      9894 cases |       MSK breast cancer:      http://thomasfuchslab.org/data/.
    |      AUC: 0.965 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '|      乳腺癌 |      淋巴结转移检测 |      乳腺数据集 |      9894 例 |       MSK 乳腺癌:      http://thomasfuchslab.org/data/.
    |      AUC: 0.965 |'
- en: '|      Wang et al. ([2019](#bib.bib181)) |      Hybrid |      Lung Cancer |
         H&E |      Diagnosis of lung cancer subtypes |      Lung cancer dataset |
         939 cases |      inhouse |      Accuracy: 0.973 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|      Wang 等人 ([2019](#bib.bib181)) |      混合 |      肺癌 |      H&E |      肺癌亚型诊断
    |      肺癌数据集 |      939 例 |      内部 |      准确率: 0.973 |'
- en: '|      Chen et al. ([2021](#bib.bib30)) |      Hybrid |      Breast Cancer
    |      IHC |       HER2 scoring (negative (0/1+),      equivocal (2+) and positive
    (3+)) |      HER2 scoring dataset |      1105 cases |      inhouse |      Accuracy:
    0.8970 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '|      Chen 等人 ([2021](#bib.bib30)) |      混合 |      乳腺癌 |      IHC |      
    HER2 评分 (阴性 (0/1+)，可疑 (2+) 和阳性 (3+)) |      HER2 评分数据集 |      1,105 例 |      内部
    |      准确率: 0.8970 |'
- en: '|      Chikontwe et al. ([2020](#bib.bib33)) |      Hybrid |      Colectoral
    Cancer |      H&E |       Prediction of normal      and malignant tissues |      CRC
    WSI Dataset I |      173 cases |      inhouse |      Accuracy: 0.9231 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|      Chikontwe 等人 ([2020](#bib.bib33)) |      混合 |      结肠癌 |      H&E |
          预测正常和恶性组织 |      CRC WSI 数据集 I |      173 例 |      内部 |      准确率: 0.9231
    |'
- en: '|      CRC WSI Dataset II |      193 cases |      Accuracy: 0.9872 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|      CRC WSI 数据集 II |      193 例 |      准确率: 0.9872 |'
- en: '|      Sharma et al. ([2021](#bib.bib147)) |      Hybrid |       Gastrointestinal
         Celiac Disease |      H&E |       Prediction of patients with      celiac
    disease or being healthy |      Gastrointestinal dataset |      413 cases |      inhouse
    |      Accuracy: 0.862 |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|      Sharma 等人 ([2021](#bib.bib147)) |      混合 |       胃肠道      乳糜泻 |      H&E
    |       预测乳糜泻患者或健康人 |      胃肠道数据集 |      413 例 |      内部 |      准确率: 0.862 |'
- en: '|      Breast Cancer |      Detection of lymph node metastases |      Camelyon16
    dataset |      400 cases |      Bejnordi et al. ([2017b](#bib.bib10)) |      AUC:
    0.9112 |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|      乳腺癌 |      淋巴结转移检测 |      Camelyon16 数据集 |      400 例 |      Bejnordi
    等人 ([2017b](#bib.bib10)) |      AUC: 0.9112 |'
- en: '|      Lu et al. ([2021](#bib.bib105)) |      Hybrid |      Renal Cell Carcinoma
    |      H&E |       subtyping and the detection      of lymph node metastasis |
         RCC dataset |      884 cases |      https://portal.gdc.cancer.gov |      AUC:
    0.991 |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|      Lu 等 ([2021](#bib.bib105)) |      混合 |      肾细胞癌 |      H&E |      
    亚型分类及淋巴结转移的检测 |      RCC 数据集 |      884 个病例 |      https://portal.gdc.cancer.gov
    |      AUC: 0.991 |'
- en: '|      Non-small-cell Lung Cancer |      NSCLC dataset |      993 cases |      https://cancerimagingarchive.net/datascope/cptac
    |      AUC: 0.956 |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '|      非小细胞肺癌 |      NSCLC 数据集 |      993 个病例 |      https://cancerimagingarchive.net/datascope/cptac
    |      AUC: 0.956 |'
- en: '|      Breast Cancer |      CAMELYON16 and CAMELYON17 dataset |      899 cases
    |      https://camelyon17.grand-challenge.org/Data |      AUC: 0.936 |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '|      乳腺癌 |      CAMELYON16 和 CAMELYON17 数据集 |      899 个病例 |      https://camelyon17.grand-challenge.org/Data
    |      AUC: 0.936 |'
- en: '|      Myronenko et al. ([2021](#bib.bib116)) |      Hybrid |      Prostate
    Cancer |      H&E |       Classifying cancer tissue      into Gleason patterns
    |       Prostate cANcer graDe Assessment      (PANDA) challenge dataset |      11,000
    cases |      https://panda.grandchallenge.org/home/ |      Accuracy: 0.805 |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|      Myronenko 等 ([2021](#bib.bib116)) |      混合 |      前列腺癌 |      H&E |
          癌组织分类      为 Gleason 模式 |       前列腺癌等级评估      (PANDA) 挑战数据集 |      11,000
    个病例 |      https://panda.grandchallenge.org/home/ |      准确度: 0.805 |'
- en: '|      Naik et al. ([2020](#bib.bib118)) |      Clinical Studies |      Breast
    Cancer |      H&E |       Determination of      hormonal receptor status |      
    Australian Breast Cancer      Tissue Bank (ABCTB) dataset |      2535 cases |
         https://abctb.org.au/abctbNew2/ACCESSPOLICY.pdf |      AUC: 0.92 |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|      Naik 等 ([2020](#bib.bib118)) |      临床研究 |      乳腺癌 |      H&E |      
    激素受体状态的确定 |       澳大利亚乳腺癌组织库      (ABCTB) 数据集 |      2535 个病例 |      https://abctb.org.au/abctbNew2/ACCESSPOLICY.pdf
    |      AUC: 0.92 |'
- en: '|       The Cancer Genome Atlas (TCGA) dataset |      1014 cases |      https://portal.gdc.cancer.gov
    |      AUC: 0.861 |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '|       癌症基因组图谱 (TCGA) 数据集 |      1014 个病例 |      https://portal.gdc.cancer.gov
    |      AUC: 0.861 |'
- en: '|      Tomita et al. ([2019](#bib.bib172)) |      Clinical Studies |      Esophagus
    Cancer |      H&E |       Detection of cancerous and      precancerous esophagus
    tissue |      Esophagus cancer dataset |      180 cases |      inhouse |      Accuracy:
    0.83 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|      Tomita 等 ([2019](#bib.bib172)) |      临床研究 |      食管癌 |      H&E |      
    癌性和癌前食管组织的检测 |      食管癌数据集 |      180 个病例 |      内部数据 |      准确度: 0.83 |'
- en: '|      Skrede et al. ([2020](#bib.bib156)) |      Clinical Studies |      Colorectal
    Cancer |      H&E |      Prediction of colorectal cancer outcome |      Colorectal
    cancer dataset |      2473 cases |      inhouse |       Ratio for poor versus
         good prognosis: 3.84 |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '|      Skrede 等 ([2020](#bib.bib156)) |      临床研究 |      结直肠癌 |      H&E |
         结直肠癌预后预测 |      结直肠癌数据集 |      2473 个病例 |      内部数据 |       不良预后与      良好预后的比例:
    3.84 |'
- en: '|      Kather *et al.* ([2019](#bib.bib85)) |      Clinical Studies |      Gastrointestinal
    Cancer |      H&E |      Prediction of microsatellite instability |      TCGA-STAD
    dataset |      315 cases |      https://portal.gdc.cancer.gov/. |      AUC: 0.81
    |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '|      Kather *et al.* ([2019](#bib.bib85)) |      临床研究 |      胃肠癌 |      H&E
    |      微卫星不稳定性的预测 |      TCGA-STAD 数据集 |      315 个病例 |      https://portal.gdc.cancer.gov/.
    |      AUC: 0.81 |'
- en: '|      TCGA-CRC-DX dataset |      360 cases |      AUC: 0.84 |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|      TCGA-CRC-DX 数据集 |      360 个病例 |      AUC: 0.84 |'
- en: '|      TCGA-CRC-KR dataset |      378 cases |      AUC: 0.77 |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '|      TCGA-CRC-KR 数据集 |      378 个病例 |      AUC: 0.77 |'
- en: '|      Coudray et al. ([2018](#bib.bib39)) |      Clinical Studies |      Lung
    Cancer |      H&E |      Classification of subtypes |       The Cancer Genome
    Atlas (TCGA) dataset |      1634 cases |      https://portal.gdc.cancer.gov/ |
         AUC: 0.97 |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|      Coudray 等 ([2018](#bib.bib39)) |      临床研究 |      肺癌 |      H&E |      亚型分类
    |       癌症基因组图谱 (TCGA) 数据集 |      1634 个病例 |      https://portal.gdc.cancer.gov/
    |      AUC: 0.97 |'
- en: '|       Prediction of mutation from      non-small cell lung cancer |      
    AUC of six of commonly mutated      genes from 0.733 to 0.856 |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '|       从非小细胞肺癌中预测突变 |       六种常见突变基因的 AUC 从 0.733 到 0.856 |'
- en: '|      Bejnordi et al. ([2017a](#bib.bib9)) |      Clinical Studies |      Breast
    Cancer |      H&E |      Detection of lymph node metastases |      CAMELYON16
    dataset |      400 cases |      https://camelyon16.grand-challenge.org/ |      AUC:
    0.994 |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|      Bejnordi 等 ([2017a](#bib.bib9)) |      临床研究 |      乳腺癌 |      H&E |
         淋巴结转移的检测 |      CAMELYON16 数据集 |      400 个病例 |      https://camelyon16.grand-challenge.org/
    |      AUC: 0.994 |'
- en: '|      Wessels et al. ([2021](#bib.bib186)) |      Clinical Studies |      Prostate
    Cancer |      H&E |      Prediction lymph node metastasis |      Prostate cancer
    dataset |      218 cases |      inhouse |      AUC: 0.68 |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '|      Wessels等人（[2021](#bib.bib186)） |      临床研究 |      前列腺癌 |      H&E |
         预测淋巴结转移 |      前列腺癌数据集 |      218例 |      内部数据 |      AUC: 0.68 |'
- en: '|      Anand et al. ([2021](#bib.bib3)) |      Clinical Studies |      Thyroid
    Cancer |      H&E |      Prediction of BRAF mutation |       ISBI 2017 Thyroid
    Tissue      Microarray (TH-TMA17) dataset |      85 cases | Wang *et al.* ([2018](#bib.bib180))
    |      AUC: 0.96 |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|      Anand等人（[2021](#bib.bib3)） |      临床研究 |      甲状腺癌 |      H&E |      预测BRAF突变
    |       ISBI 2017甲状腺组织微阵列（TH-TMA17）数据集 |      85例 | Wang *等人*（[2018](#bib.bib180)）
    |      AUC: 0.96 |'
- en: '|      TCGA-THCA dataset |      444 cases |      https://portal.gdc.cancer.gov/
    |      AUC: 0.98 |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|      TCGA-THCA数据集 |      444例 |      https://portal.gdc.cancer.gov/ |      AUC:
    0.98 |'
- en: '|      Yang et al. ([2022](#bib.bib198)) |      Clinical Studies |      Breast
    Cancer |      H&E |       Prediction of HER2-positive breast      cancer recurrence
    and metastasis risk |      HER2-positive breast cancer dataset |      127 cases
    |      https://github.com/bensteven2/HE_breast_recurrence |      AUC: 0.76 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|      杨等人（[2022](#bib.bib198)） |      临床研究 |      乳腺癌 |      H&E |       预测HER2阳性乳腺癌复发和转移风险
    |      HER2阳性乳腺癌数据集 |      127例 |      https://github.com/bensteven2/HE_breast_recurrence
    |      AUC: 0.76 |'
- en: '|      The Cancer Genome Atlas (TCGA) dataset |      123 cases |      AUC:
    0.72 |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|      癌症基因组图谱（TCGA）数据集 |      123例 |      AUC: 0.72 |'
- en: '| Li *et al.* ([2021](#bib.bib98)) |      Clinical Studies |      Breast Cancer
    |      H&E |       Predicting biomarker of      pathological complete response
         to neoadjuvant chemotherapy |      Breast cancer dataset |      540 cases
    |      inhouse |      AUC: 0.847 |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 李*等人*（[2021](#bib.bib98)） |      临床研究 |      乳腺癌 |      H&E |       预测新辅助化疗的病理完全反应生物标志物
    |      乳腺癌数据集 |      540例 |      内部数据 |      AUC: 0.847 |'
- en: '|      Saillard et al. ([2020](#bib.bib143)) |      Clinical Studies |      Hepatocellular
    Carcinoma |      H&E |       Predicting survival after      hepatocellular carcinoma
    resection |      Discovery set |      194 cases |      inhouse |      C-Indices:
    0.78 |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|      Saillard等人（[2020](#bib.bib143)） |      临床研究 |      肝细胞癌 |      H&E |
          预测肝细胞癌切除后的生存率 |      发现集 |      194例 |      内部数据 |      C-指数：0.78 |'
- en: '|      The Cancer Genome Atlas (TCGA) dataset |      328 cases |      https://portal.gdc.cancer.gov/
    |      C-Indices: 0.70 |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '|      癌症基因组图谱（TCGA）数据集 |      328例 |      https://portal.gdc.cancer.gov/ |
         C-指数：0.70 |'
- en: '|      Velmahos et al. ([2021](#bib.bib177)) |      Clinical Studies |      Bladder
    Cancer |      H&E |      Identifying FGFR-activating mutations |       The Cancer
    Genome      Atlas (TCGA) dataset |      418 cases |      https://portal.gdc.cancer.gov/
    |      AUC = 0.76 |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '|      Velmahos等人（[2021](#bib.bib177)） |      临床研究 |      膀胱癌 |      H&E |
         识别FGFR激活突变 |       癌症基因组图谱（TCGA）数据集 |      418例 |      https://portal.gdc.cancer.gov/
    |      AUC = 0.76 |'
- en: '|      Woerl et al. ([2020](#bib.bib188)) |      Clinical Studies |      Bladder
    Cancer |      H&E |      Prediction of molecular subtypes |       The Cancer Genome
    Atlas (TCGA)      Urothelial Bladder Carcinoma Dataset |      407 cases |      https://portal.gdc.cancer.gov/
    |      AUC = 0.89 |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|      Woerl等人（[2020](#bib.bib188)） |      临床研究 |      膀胱癌 |      H&E |      预测分子亚型
    |       癌症基因组图谱（TCGA）尿路上皮膀胱癌数据集 |      407例 |      https://portal.gdc.cancer.gov/
    |      AUC = 0.89 |'
- en: '|      CCC-EMN cohort |      16 cases |      inhouse |      AUC = 0.85 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|      CCC-EMN队列 |      16例 |      内部数据 |      AUC = 0.85 |'
- en: 3.2 Semi-Supervised Learning Paradigm
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 半监督学习范式
- en: Semi-supervised learning is a branch of machine learning that combines both
    supervised and unsupervised learning tasks and improves model performance by exploiting
    the information associated between tasks (Zhu *et al.* [2005](#bib.bib211), Van
    *et al.* [2020](#bib.bib175)). In semi-supervised learning, only a small amount
    of labeled data is generally available, and besides that, a large amount of unlabeled
    data can be utilized for network training. Consequently, the main goal of semi-supervised
    learning is how to use these unlabeled data to improve the performance of the
    model trained with limited labeled data. Scenarios of the semi-supervised learning
    paradigm are very common in the field of pathological image analysis, both in
    diagnostic tasks and in segmentation tasks. Due to the expensive and time-consuming
    fine-grained annotation, pathologists often can only provide a small number of
    precise annotations for supervised training of the models, while a large amount
    of unannotated data cannot be used. Training deep models with only these limited
    labeled data can easily lead to over-fitting, thus significantly harming the performance
    and generalization of the models. In the semi-supervised learning paradigm, a
    large number of unlabeled images can be used to assist in training and thus further
    improve the performance, generalization, and robustness of the models.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 半监督学习是机器学习的一个分支，它结合了监督学习和无监督学习任务，并通过利用任务间的信息来提高模型性能（Zhu *et al.* [2005](#bib.bib211),
    Van *et al.* [2020](#bib.bib175)）。在半监督学习中，通常只有少量标记数据可用，除此之外，还可以利用大量未标记的数据进行网络训练。因此，半监督学习的主要目标是如何利用这些未标记的数据来提高用有限标记数据训练的模型的性能。半监督学习范式的场景在病理图像分析领域非常普遍，无论是在诊断任务还是分割任务中。由于精细标注的成本高且耗时，病理学家通常只能提供少量精确的标注来进行模型的监督训练，而大量未标注的数据无法被利用。仅用这些有限的标记数据训练深度模型容易导致过拟合，从而显著损害模型的性能和泛化能力。在半监督学习范式中，大量未标记图像可以用于辅助训练，从而进一步提高模型的性能、泛化能力和鲁棒性。
- en: 'In the past two decades, numerous semi-supervised learning algorithms have
    been proposed and widely used in the fields of natural image processing and pathological
    image analysis. The representative approaches in the field of semi-supervised
    learning are divided into five categories, namely pseudo-labelling-based approach
    (Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Pseudo-labelling-based Approach ‣ 3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")),
    consistency-based approach (Section [3.2.2](#S3.SS2.SSS2 "3.2.2 Consistency-based
    Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), graph-based approach (Section [3.2.3](#S3.SS2.SSS3 "3.2.3 Graph-based
    Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")), unsupervised-preprocessing approach (Section [3.2.4](#S3.SS2.SSS4
    "3.2.4 Unsupervised-preprocessing-based Approach ‣ 3.2 Semi-Supervised Learning
    Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis")), and other
    approaches (Section [3.2.5](#S3.SS2.SSS5 "3.2.5 Other Approaches ‣ 3.2 Semi-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")).
    We introduce these methods below, respectively. For each category, we first describe
    their fundamental principles and then elaborate on their representative studies
    in the field of pathological image analysis. For a systematic review of the assumptions,
    concepts and representative methods of semi-supervised learning in the field of
    natural images, we recommend the review by Van *et al.* [2020](#bib.bib175). Table
    [4](#S3.T4 "Table 4 ‣ 3.2.5 Other Approaches ‣ 3.2 Semi-Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis") summarizes the
    detailed list of literatures in this section.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '在过去的二十年中，许多半监督学习算法被提出并广泛应用于自然图像处理和病理图像分析领域。半监督学习领域的代表性方法分为五类，即基于伪标记的方法（第[3.2.1](#S3.SS2.SSS1
    "3.2.1 Pseudo-labelling-based Approach ‣ 3.2 Semi-Supervised Learning Paradigm
    ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis")节），基于一致性的方法（第[3.2.2](#S3.SS2.SSS2
    "3.2.2 Consistency-based Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3
    Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive
    Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and
    Self-supervised Techniques in Histopathological Image Analysis")节），基于图的方法（第[3.2.3](#S3.SS2.SSS3
    "3.2.3 Graph-based Approach ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms
    ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis")节），无监督预处理方法（第[3.2.4](#S3.SS2.SSS4
    "3.2.4 Unsupervised-preprocessing-based Approach ‣ 3.2 Semi-Supervised Learning
    Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis")节），以及其他方法（第[3.2.5](#S3.SS2.SSS5
    "3.2.5 Other Approaches ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms
    ‣ Towards Label-efficient Automatic Diagnosis and Analysis: A Comprehensive Survey
    of Advanced Deep Learning-based Weakly-supervised, Semi-supervised and Self-supervised
    Techniques in Histopathological Image Analysis")节）。我们将分别介绍这些方法。对于每一类，我们首先描述其基本原理，然后详细阐述其在病理图像分析领域的代表性研究。有关自然图像领域半监督学习的假设、概念和代表性方法的系统综述，我们推荐Van
    *et al.* [2020](#bib.bib175)的综述。表[4](#S3.T4 "Table 4 ‣ 3.2.5 Other Approaches
    ‣ 3.2 Semi-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis")总结了本节文献的详细列表。'
- en: 3.2.1 Pseudo-labelling-based Approach
  id: totrans-147
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 基于伪标记的方法
- en: Fundamental Principles
  id: totrans-148
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基本原理
- en: The pseudo-labeling-based approach is a classical and well-known semi-supervised
    method (Zhu *et al.* [2005](#bib.bib211)), which mainly consists of two alternating
    processes, training and pseudo-labeling. Taking the classification problem as
    an example, in the training process, one or more classifiers are first trained
    in a supervised manner on the labeled data. The labeled data may be derived from
    the initial accurately labeled data or from the pseudo-labeled data from the previous
    iterations. In the pseudo-labeling process, all the unlabeled data are first predicted
    using the classifier trained in the previous process, and then the most confidently
    predicted portion of the data are selected for pseudo-labeling. Finally, these
    pseudo-labeled data are added to the labeled data for the next iteration. This
    process is repeated until no data with high confidence are found or all data are
    labeled.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 基于伪标签的方法是一种经典且知名的半监督方法（Zhu *等人* [2005](#bib.bib211)），主要包括两个交替的过程：训练和伪标签。以分类问题为例，在训练过程中，一个或多个分类器首先在标记数据上以监督方式进行训练。这些标记数据可能来源于初始准确标记的数据，或来自于之前迭代中产生的伪标签数据。在伪标签过程中，首先使用在前一过程训练的分类器对所有未标记的数据进行预测，然后选择预测最为自信的数据部分进行伪标签。最后，这些伪标签数据被添加到标记数据中进行下一轮迭代。这个过程会重复，直到没有高置信度的数据或所有数据都被标记。
- en: The pseudo-labeling-based methods are firstly applied to the field of natural
    image processing and typically contain self-training methods (Lee *et al.* [2013](#bib.bib94))
    and co-training methods (Blum *et al.* [1998](#bib.bib14), Zhou *et al.* [2005](#bib.bib209)).
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 基于伪标签的方法最初应用于自然图像处理领域，通常包括自训练方法（Lee *等人* [2013](#bib.bib94)）和协同训练方法（Blum *等人*
    [1998](#bib.bib14)，Zhou *等人* [2005](#bib.bib209)）。
- en: Study in Pathological Image Analysis
  id: totrans-151
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 病理图像分析研究
- en: In pathological image analysis, Singh *et al.* [2011](#bib.bib153) proposed
    a semi-supervised method of learning distance metrics from labeled data and performing
    label propagation for identifying the subtypes of nuclei, which was locally adaptive
    and could fully consider the heterogeneity of the data. Bulten *et al.* [2020](#bib.bib16)
    developed a deep learning system for Gleason scoring of prostate biopsies based
    on semi-supervised learning. They first trained the network on a small training
    dataset with pure Gleason scores, and then applied the trained network to other
    internal training datasets to set reference standards. Then, the labels were corrected
    and relabeled using reports from pathologists. Tolkach *et al.* [2020](#bib.bib171)
    used a pseudo-labeling-based semi-supervised strategy to train the CNN network
    to accomplish Gleason pattern classification. Jasiwal *et al.* [2019](#bib.bib79)
    proposed a semi-supervised method based on pseudo-labeling and entropy regularization
    for breast cancer pathological image classification. Shaw *et al.* [2020](#bib.bib148)
    extended the study of Yalniz *et al.* [2019](#bib.bib196) by proposing a semi-supervised
    teacher-student distillation method for the classification of colorectal cancer
    pathological images. Marini *et al.* [2021](#bib.bib109) proposed a deep pseudo-labeling-based
    semi-supervised learning method for strongly heterogeneous pathology data containing
    only a small number of local annotations. Their method consists of a high-volume
    teacher model and a small-volume student model, where the teacher model is automatically
    labeled with pseudo labels for the training of the student model. Cheng *et al.* [2020](#bib.bib31)
    proposed a semi-supervised learning framework based on a teacher-student model
    with similarity learning for the segmentation of breast cancer lesions containing
    a small number of annotations and noisy annotations.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，Singh *等人* [2011](#bib.bib153) 提出了一种半监督学习距离度量的方法，该方法从标记数据中学习，并执行标签传播以识别细胞核的亚型，该方法在本地自适应，并能够充分考虑数据的异质性。Bulten
    *等人* [2020](#bib.bib16) 开发了一种基于半监督学习的前列腺活检Gleason评分的深度学习系统。他们首先在一个包含纯Gleason评分的小训练数据集上训练网络，然后将训练好的网络应用于其他内部训练数据集以设定参考标准。之后，使用病理学家的报告来修正和重新标记标签。Tolkach
    *等人* [2020](#bib.bib171) 采用基于伪标签的半监督策略来训练CNN网络，以完成Gleason模式分类。Jasiwal *等人* [2019](#bib.bib79)
    提出了一种基于伪标签和熵正则化的半监督方法用于乳腺癌病理图像分类。Shaw *等人* [2020](#bib.bib148) 通过提出一种半监督教师-学生蒸馏方法来扩展Yalniz
    *等人* [2019](#bib.bib196) 的研究，用于结直肠癌病理图像的分类。Marini *等人* [2021](#bib.bib109) 提出了一种基于深度伪标签的半监督学习方法，用于包含仅少量本地注释的强异质性病理数据。他们的方法包括一个大容量教师模型和一个小容量学生模型，其中教师模型使用伪标签自动标记，以训练学生模型。Cheng
    *等人* [2020](#bib.bib31) 提出了一个基于教师-学生模型的半监督学习框架，结合相似性学习，用于分割包含少量注释和噪声注释的乳腺癌病变。
- en: 3.2.2 Consistency-based Approach
  id: totrans-153
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 基于一致性的方法
- en: Fundamental Principles
  id: totrans-154
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基本原理
- en: The consistency-based semi-supervised learning approach is mainly based on the
    smoothing assumption. In the smoothing assumption, the prediction model should
    be robust to local perturbations within its input. This means that when we perturb
    the data points with a small amount of noise, the network’s predictions for the
    perturbed data points and the clean original data points should be similar. In
    the implementation of deep neural networks, the consistency-based approach can
    be easily extended to a semi-supervised learning setup by directly adding unsupervised
    consistency loss functions to the original supervised loss functions. In the field
    of natural image processing, typical methods include <math alttext="\pi" display="inline"><semantics
    ><mi >π</mi><annotation-xml encoding="MathML-Content" ><ci >𝜋</ci></annotation-xml><annotation
    encoding="application/x-tex" >\pi</annotation></semantics></math>-model (Laine
    *et al.* [2016](#bib.bib92)), Temporal Ensembling model (Laine *et al.* [2016](#bib.bib92)),
    Mean Teachers (Tarvainen *et al.* [2017](#bib.bib167)) and UDA (Xie *et al.* [2020](#bib.bib190)).
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 一致性基半监督学习方法主要基于平滑假设。在平滑假设中，预测模型应该对输入的局部扰动具有鲁棒性。这意味着当我们对数据点施加少量噪声时，网络对扰动数据点和干净原始数据点的预测应该是相似的。在深度神经网络的实现中，一致性基方法可以通过直接将无监督一致性损失函数添加到原有的监督损失函数中，轻松扩展到半监督学习设置。在自然图像处理领域，典型的方法包括
    <math alttext="\pi" display="inline"><semantics ><mi >π</mi><annotation-xml encoding="MathML-Content"
    ><ci >𝜋</ci></annotation-xml><annotation encoding="application/x-tex" >\pi</annotation></semantics></math>-model
    (Laine *et al.* [2016](#bib.bib92))，Temporal Ensembling model (Laine *et al.*
    [2016](#bib.bib92))，Mean Teachers (Tarvainen *et al.* [2017](#bib.bib167)) 和 UDA
    (Xie *et al.* [2020](#bib.bib190))。
- en: Study in Pathological Image Analysis
  id: totrans-156
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 病理图像分析研究
- en: In pathological image analysis, Zhou *et al.* [2020](#bib.bib208) proposed a
    new Mean-teacher (MT) framework based on template-guided perturbation-sensitive
    sample mining. This framework consists of a teacher network and a student network.
    The teacher network is an integrated prediction network from K-times randomly
    augmented data, which is used to guide the student network to remain invariant
    to small perturbations at both feature and semantic levels. Su *et al.* [2019](#bib.bib162)
    proposed a novel global and local consistency loss and performed the nuclei classification
    task based on the Mean-Teacher framework.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，Zhou *et al.* [2020](#bib.bib208) 提出了一个基于模板引导的扰动敏感样本挖掘的新型 Mean-teacher
    (MT) 框架。该框架由一个教师网络和一个学生网络组成。教师网络是一个从K次随机增强数据中集成的预测网络，用于指导学生网络在特征和语义层面上对小扰动保持不变。Su
    *et al.* [2019](#bib.bib162) 提出了一个新颖的全局和局部一致性损失，并基于 Mean-Teacher 框架执行了核分类任务。
- en: 3.2.3 Graph-based Approach
  id: totrans-158
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3 基于图的方法
- en: Fundamental Principles
  id: totrans-159
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基本原理
- en: Methods of graph-based semi-supervised learning typically construct graphs to
    preserve the relationships of neighboring nodes, and use the graph transformations
    to simultaneously exploit information from labeled data and explore the underlying
    structure of unlabeled data. The key step of the graph-based semi-supervised learning
    methods is to construct a better graph to represent the original data structure.
    They usually define a graph on all data points (both labeled and unlabeled data
    points) and use weights to encode the similarity between pairs of the data points.
    In this way, the labeled information can be propagated through the graph to the
    unlabeled data points. For labeled data points, the predicted labels should match
    the true labels; similar data points defined by a similarity graph should have
    the same predictions. Graph-based semi-supervised methods are a relatively complex
    and long-developed field, and we recommend (Van *et al.* [2020](#bib.bib175),
    Chong *et al.* [2020](#bib.bib34)) for a more thorough understanding.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图基半监督学习方法通常构建图以保持邻近节点的关系，并利用图的变换同时利用标记数据的信息以及探索未标记数据的潜在结构。图基半监督学习方法的关键步骤是构建一个更好的图来表示原始数据结构。它们通常在所有数据点（包括标记和未标记的数据点）上定义图，并使用权重来编码数据点对之间的相似性。通过这种方式，标记的信息可以通过图传播到未标记的数据点。对于标记的数据点，预测的标签应该与真实标签匹配；由相似性图定义的相似数据点应该有相同的预测。图基半监督方法是一个相对复杂且发展较长的领域，我们推荐（Van
    *et al.* [2020](#bib.bib175)，Chong *et al.* [2020](#bib.bib34)）以获得更全面的理解。
- en: Study in Pathological Image Analysis
  id: totrans-161
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 病理图像分析研究
- en: In pathological image analysis, Xu *et al.* [2016](#bib.bib194) proposed a new
    framework that combines a CNN with a semi-supervised regularization term. They
    first generated a hypothetical label for each unlabeled sample, then proposed
    a graph-based smoothing term for regularization. Su *et al.* [2015](#bib.bib163)
    proposed an active learning and graph-based semi-supervised learning method for
    interactive cell segmentation. Inspired by the Temporal Ensembling model (Laine
    *et al.* [2016](#bib.bib92)), Shi *et al.* [2020](#bib.bib150) proposed a graph-based
    temporal ensembling model GTE. This method creates ensemble targets for both features
    and label predictions for each training sample, and encourages the model to form
    consistent predictions under different perturbations to exploit the semantic information
    of unlabeled data and improve the robustness of the model to noisy labels.
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，徐*等人* [2016](#bib.bib194) 提出了一个结合卷积神经网络（CNN）和半监督正则化项的新框架。他们首先为每个未标记样本生成了一个假设标签，然后提出了一种基于图的平滑项进行正则化。苏*等人*
    [2015](#bib.bib163) 提出了一种用于交互式细胞分割的主动学习和基于图的半监督学习方法。受到时间集成模型（Laine*等人* [2016](#bib.bib92)）的启发，石*等人*
    [2020](#bib.bib150) 提出了基于图的时间集成模型GTE。该方法为每个训练样本创建特征和标签预测的集成目标，并鼓励模型在不同扰动下形成一致的预测，从而利用未标记数据的语义信息，提高模型对噪声标签的鲁棒性。
- en: 3.2.4 Unsupervised-preprocessing-based Approach
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.4 无监督预处理方法
- en: Fundamental Principles
  id: totrans-164
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 基本原理
- en: Unlike the previous approaches, unsupervised preprocessing-based approaches
    are typically dedicated to the unsupervised feature extraction, clustering (cluster-then-label),
    or initialization of the parameters of the subsequent supervised learning process
    (pre-training) from a large amount of unlabeled data. The most popular methods
    include autoencoders and their variants (Vincent *et al.* [2008](#bib.bib179),
    [2011](#bib.bib138)). Clustering is another method that enables adequate learning
    of the overall data distribution, thus many semi-supervised learning algorithms
    (Goldberg *et al.* [2009](#bib.bib62), Demiriz *et al.* [1999](#bib.bib46), Dara
    *et al.* [2002](#bib.bib43)) guide the subsequent classification process through
    clustering. The idea of the pre-training is to first pre-train a model using unsupervised
    methods with unlabeled data, and then use the parameters of this model as the
    initial parameters of the subsequent supervised training model, i.e., the subsequent
    supervised training is fine-tuned on the basis of these initial parameters. On
    this basis, the large number of unlabeled data can fully guide the subsequent
    classification models with limited labeled data thus improving the performance
    of semi-supervised learning (Erhan *et al.* [2010](#bib.bib55)).
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前的方法不同，无监督预处理方法通常专注于从大量未标记数据中进行无监督特征提取、聚类（先聚类后标记）或后续监督学习过程的参数初始化（预训练）。最流行的方法包括自编码器及其变体（Vincent*等人*
    [2008](#bib.bib179), [2011](#bib.bib138)）。聚类是另一种方法，能够充分学习整体数据分布，因此许多半监督学习算法（Goldberg*等人*
    [2009](#bib.bib62), Demiriz*等人* [1999](#bib.bib46), Dara*等人* [2002](#bib.bib43)）通过聚类引导后续的分类过程。预训练的思想是首先使用未标记数据通过无监督方法预训练一个模型，然后将该模型的参数作为后续监督训练模型的初始参数，即后续的监督训练是在这些初始参数的基础上进行微调。在此基础上，大量未标记数据可以充分引导具有有限标记数据的后续分类模型，从而提高半监督学习的性能（Erhan*等人*
    [2010](#bib.bib55)）。
- en: Study in Pathological Image Analysis
  id: totrans-166
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 病理图像分析中的研究
- en: In pathological image analysis, Peikari *et al.* [2018](#bib.bib125) proposed
    a cluster-then-label semi-supervised learning method for identifying high-density
    regions in the data space and then utilized these regions to help support vector
    machines find decision boundaries. Lu *et al.* [2019](#bib.bib104) proposed a
    semi-supervised method based on feature extraction and pre-training for the WSI-level
    breast cancer classification task, which is the first work that relies on self-supervised
    feature learning using contrastive predictive coding for weakly supervised histopathological
    image classification. Koohbanani *et al.* [2021](#bib.bib89) proposed a joint
    framework of self-supervised learning and semi-supervised learning for pathological
    images. They proposed three pathology-specific self-supervised tasks, magnification
    prediction, magnification jigsaw prediction and hematoxylin channel prediction,
    to learn high-level semantic information and domain invariant information in pathological
    images. Srinidhi *et al.* [2022](#bib.bib160) also proposed a framework that combines
    self-supervised learning with semi-supervised learning. They first proposed the
    resolution sequence prediction (RSP) self-supervised auxiliary task to pre-train
    the model through unlabeled data, and then they performed fine-tuning of the model
    on the labeled data. After that they used the trained model from the above two
    steps as the initial weights of the model for further semi-supervised training
    based on the teacher-student consistency framework.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，Peikari *等人* [2018](#bib.bib125) 提出了一个先聚类后标记的半监督学习方法，用于识别数据空间中的高密度区域，并利用这些区域帮助支持向量机找到决策边界。Lu
    *等人* [2019](#bib.bib104) 提出了一个基于特征提取和预训练的半监督方法，用于WSI级别的乳腺癌分类任务，这是首个依赖对比预测编码进行自监督特征学习的弱监督病理图像分类工作。Koohbanani
    *等人* [2021](#bib.bib89) 提出了一个自监督学习与半监督学习相结合的病理图像联合框架。他们提出了三种特定于病理学的自监督任务：放大预测、放大拼图预测和苏木精通道预测，以学习病理图像中的高级语义信息和领域不变信息。Srinidhi
    *等人* [2022](#bib.bib160) 也提出了一个结合自监督学习与半监督学习的框架。他们首先提出了解析序列预测（RSP）自监督辅助任务，通过未标记数据预训练模型，然后在标记数据上对模型进行微调。之后，他们使用上述两步得到的训练模型作为模型的初始权重，进行基于师生一致性框架的进一步半监督训练。
- en: 3.2.5 Other Approaches
  id: totrans-168
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.5 其他方法
- en: Among semi-supervised learning, there are many other approaches, such as the
    methods based on generative adversarial networks (GAN) (Goodfellow *et al.* [2014](#bib.bib65),
    [2016](#bib.bib63), Salimans *et al.* [2016](#bib.bib144), Odena *et al.* [2016](#bib.bib121),
    Dai *et al.* [2017](#bib.bib42)), Manifold-based methods (Belkin *et al.* [2005](#bib.bib12),
    [2006](#bib.bib13), Weston *et al.* [2012](#bib.bib187), Rifai *et al.* [2011](#bib.bib137),
    [2011](#bib.bib138)) and Association learning based methods (Haeusser *et al.* [2017](#bib.bib70)).
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在半监督学习中，还有许多其他方法，如基于生成对抗网络（GAN）的方法（Goodfellow *等人* [2014](#bib.bib65), [2016](#bib.bib63),
    Salimans *等人* [2016](#bib.bib144), Odena *等人* [2016](#bib.bib121), Dai *等人* [2017](#bib.bib42)）、流形方法（Belkin
    *等人* [2005](#bib.bib12), [2006](#bib.bib13), Weston *等人* [2012](#bib.bib187),
    Rifai *等人* [2011](#bib.bib137), [2011](#bib.bib138)）和基于关联学习的方法（Haeusser *等人* [2017](#bib.bib70)）。
- en: In pathological image analysis, Kapil *et al.* [2018](#bib.bib82) first used
    auxiliary classifier generative adversarial networks (AC-GAN) for the pathological
    image semi-supervised classification task and achieved favorable results. Cong
    *et al.* [2021](#bib.bib38) proposed to use a GAN-based semi-supervised learning
    method to accomplish the stain normalization problem for pathological images.
    Sparks *et al.* [2016](#bib.bib158) proposed a semi-supervised method based on
    epidemic learning to accomplish a content-based histopathological image retrieval
    task. Li *et al.* [2018](#bib.bib100) developed an Expectation-Maximization (EM)-based
    semi-supervised method for the semantic segmentation task of radical prostatectomy
    histopathological images. Su *et al.* [2021](#bib.bib164) proposed a new semi-supervised
    method based on association learning for pathological image classification task
    inspired by Haeusser *et al.* [2017](#bib.bib70). Some studies (Foucart *et al.* [2019](#bib.bib57))
    have also attempted to analyze the weaknesses and effectiveness of semi-supervised,
    noisy learning and weak label learning based on deep learning for pathological
    image analysis.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，Kapil *等* [2018](#bib.bib82) 首次使用了辅助分类生成对抗网络 (AC-GAN) 来处理病理图像半监督分类任务，并取得了良好结果。Cong
    *等* [2021](#bib.bib38) 提出了使用基于 GAN 的半监督学习方法来解决病理图像的染色标准化问题。Sparks *等* [2016](#bib.bib158)
    提出了基于流行病学习的半监督方法来完成基于内容的组织病理图像检索任务。Li *等* [2018](#bib.bib100) 开发了一种基于期望最大化 (EM)
    的半监督方法，用于前列腺切除术病理图像的语义分割任务。Su *等* [2021](#bib.bib164) 提出了基于关联学习的新型半监督方法，用于病理图像分类任务，灵感来源于
    Haeusser *等* [2017](#bib.bib70)。一些研究 (Foucart *等* [2019](#bib.bib57)) 也尝试分析了基于深度学习的半监督、噪声学习和弱标签学习在病理图像分析中的弱点和有效性。
- en: 'Table 4: List of literatures in the semi-supervised learning section.'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '表 4: 半监督学习部分文献列表。'
- en: '| Reference | Approach | Disease Type | Staining | Task | Dataset | Dataset
    Scale | Dataset Link | Performance |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 方法 | 疾病类型 | 染色 | 任务 | 数据集 | 数据集规模 | 数据集链接 | 性能 |'
- en: '| Singh et al. ([2011](#bib.bib153)) | Pseudo- labelling-based | Breast Cancer
    | 3D fluorescence microscopy | Identifying nuclear phenotypes | Nuclei image dataset
    | 984 images | Inhouse | Mean Accuracy: 0.8 |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| Singh 等 ([2011](#bib.bib153)) | 基于伪标签 | 乳腺癌 | 3D 荧光显微镜 | 识别核表型 | 核图像数据集 |
    984 张图像 | 内部 | 平均准确率: 0.8 |'
- en: '| Bulten et al. ([2020](#bib.bib16)) | Pseudo- labelling-based | Prostate Cancer
    | H&E | Gleason grading | Inhouse dataset | 5759 biopsies from 1243 patients |
    Inhouse | AUC = 0.99 |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
  zh: '| Bulten 等 ([2020](#bib.bib16)) | 基于伪标签 | 前列腺癌 | H&E | 格里森评分 | 内部数据集 | 1243
    名患者的 5759 个活检样本 | 内部 | AUC = 0.99 |'
- en: '| Tolkach et al. ([2020](#bib.bib171)) | Pseudo- labelling-based | Prostate
    Cancer | H&E | Detection of prostate cancer tissue | The Cancer Genome Atlas Program
    (TCGA) dataset | 1.67 million patches | http://portal.gdc.cancer.gov | Accuracy
    = 0.967 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| Tolkach 等 ([2020](#bib.bib171)) | 基于伪标签 | 前列腺癌 | H&E | 前列腺癌组织的检测 | 癌症基因组图谱计划
    (TCGA) 数据集 | 167 万个补丁 | http://portal.gdc.cancer.gov | 准确率 = 0.967 |'
- en: '| Gleason grading of prostatic adenocarcinomas | https://zenodo.org/deposit/3825933
    | Accuracy = 0.98 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 前列腺腺癌的格里森评分 | https://zenodo.org/deposit/3825933 | 准确率 = 0.98 |'
- en: '| Jaiswal et al. ([2019](#bib.bib79)) | Pseudo- labelling-based | Breast Cancer
    | H&E | Detection of lymph node metastases | PatchCamelyon dataset | 327680 patches
    | https://camelyon16.grand-challenge.org/Data/ | AUC = 0.9816 |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| Jaiswal 等 ([2019](#bib.bib79)) | 基于伪标签 | 乳腺癌 | H&E | 淋巴结转移的检测 | PatchCamelyon
    数据集 | 327680 个补丁 | https://camelyon16.grand-challenge.org/Data/ | AUC = 0.9816
    |'
- en: '| Shaw et al. ([2020](#bib.bib148)) | Pseudo- labelling-based | Colorectal
    Cancer | H&E | Classification of 9 categories of pathology patterns | Public dataset
    | 100000 patches | https://zenodo.org/record/1214456#.YvyiX3ZByw4 | Mean Accuracy
    = 0.943 |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| Shaw 等 ([2020](#bib.bib148)) | 基于伪标签 | 结直肠癌 | H&E | 9 类病理模式的分类 | 公开数据集 |
    100000 个补丁 | https://zenodo.org/record/1214456#.YvyiX3ZByw4 | 平均准确率 = 0.943 |'
- en: '| Marini et al. ([2021](#bib.bib109)) | Pseudo- labelling-based | Prostate
    Cancer | H&E | Gleason grading | Tissue MicroArray dataset Zurich dataset | 886
    cases | Inhouse | <math   alttext="\kappa" display="inline"><semantics ><mi mathsize="80%"
    >κ</mi><annotation-xml encoding="MathML-Content" ><ci  >𝜅</ci></annotation-xml><annotation
    encoding="application/x-tex" >\kappa</annotation></semantics></math>-score: 0.7645
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| Marini et al. ([2021](#bib.bib109)) | 基于伪标签的方法 | 前列腺癌 | H&E | Gleason 分级
    | Tissue MicroArray 数据集 Zurich 数据集 | 886 个案例 | 内部 | <math alttext="\kappa" display="inline"><semantics
    ><mi mathsize="80%" >κ</mi><annotation-xml encoding="MathML-Content" ><ci  >𝜅</ci></annotation-xml><annotation
    encoding="application/x-tex" >\kappa</annotation></semantics></math>分数：0.7645
    |'
- en: '| TCGA-PRAD dataset | 449 cases | http://portal.gdc.cancer.gov | <math alttext="\kappa"
    display="inline"><semantics ><mi mathsize="80%"  >κ</mi><annotation-xml encoding="MathML-Content"
    ><ci >𝜅</ci></annotation-xml><annotation encoding="application/x-tex" >\kappa</annotation></semantics></math>-score:
    0.4529 |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| TCGA-PRAD 数据集 | 449 个案例 | http://portal.gdc.cancer.gov | <math alttext="\kappa"
    display="inline"><semantics ><mi mathsize="80%"  >κ</mi><annotation-xml encoding="MathML-Content"
    ><ci >𝜅</ci></annotation-xml><annotation encoding="application/x-tex" >\kappa</annotation></semantics></math>分数：0.4529
    |'
- en: '| Cheng et al. ([2020](#bib.bib31)) | Pseudo- labelling-based | Breast Cancer
    | H&E | Automated segmentation of cancerous regions | CAMELYON16 dataset | 400
    cases | https://camelyon16.grand-challenge.org/Data/ | Dice: 93.76 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Cheng et al. ([2020](#bib.bib31)) | 基于伪标签的方法 | 乳腺癌 | H&E | 自动化癌区分割 | CAMELYON16
    数据集 | 400 个案例 | https://camelyon16.grand-challenge.org/Data/ | Dice：93.76 |'
- en: '| Prostate Cancer | TVGH TURP dataset | 71 cases | Inhouse | Dice: 77.24 |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 前列腺癌 | TVGH TURP 数据集 | 71 个案例 | 内部 | Dice：77.24 |'
- en: '| Zhou et al. ([2020](#bib.bib208)) | Consistency-based | - | Liquid-based
    pap test specimen | Cervical cell instance segmentation | liquid-based Pap test
    specimen dataset | 4439 cytoplasm | Inhouse | AJI: 73.45, MAP: 46.01 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Zhou et al. ([2020](#bib.bib208)) | 基于一致性的方法 | - | 液体巴氏测试标本 | 宫颈细胞实例分割 |
    液体巴氏测试标本数据集 | 4439 个细胞质 | 内部 | AJI：73.45，MAP：46.01 |'
- en: '| Su et al. ([2019](#bib.bib162)) | Consistency-based | - | H&E | Nuclei classification
    | MoNuseg dataset | 22462 nuclei | Sirinukunwattana et al. ([2016](#bib.bib155))
    | F1 score: 75.02 (5% labels) |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Su et al. ([2019](#bib.bib162)) | 基于一致性的方法 | - | H&E | 细胞核分类 | MoNuseg 数据集
    | 22462 个细胞核 | Sirinukunwattana et al. ([2016](#bib.bib155)) | F1 分数：75.02（5%
    标签） |'
- en: '| Ki-67 nucleus dataset | 17516 nuclei | Inhouse | F1 score: 79.32 (5% labels)
    |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Ki-67 核数据集 | 17516 个核 | 内部 | F1 分数：79.32（5% 标签） |'
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Consistency-based | Breast Cancer,
    Colorectal Cancer | H&E | Detection of tumor metastasis | BreastPathQ dataset
    | 2579 patches | Martel et al. ([2019](#bib.bib111)) | TC: 0.876 (10% labels)
    |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Srinidhi et al. ([2022](#bib.bib160)) | 基于一致性的方法 | 乳腺癌、结直肠癌 | H&E | 肿瘤转移检测
    | BreastPathQ 数据集 | 2579 个补丁 | Martel et al. ([2019](#bib.bib111)) | TC：0.876（10%
    标签） |'
- en: '| Classification of tissue types | Camelyon16 dataset | 399 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC: 0.855 (10% labels) |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 组织类型分类 | Camelyon16 数据集 | 399 个 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC：0.855（10% 标签） |'
- en: '| Quantification of tumor cellularity | Kather multiclass dataset | 100K patches
    | Kather *et al.* ([2019](#bib.bib84)) | Accuracy: 0.982 (10% labels) |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| 肿瘤细胞性定量 | Kather 多类数据集 | 100K 个补丁 | Kather *et al.* ([2019](#bib.bib84))
    | 准确率：0.982（10% 标签） |'
- en: '| Xu et al. ([2016](#bib.bib194)) | Graph-based | - | Microscopy images | Neuron
    segmentation | Neural morphology image dataset | 2000 neuron regions with with
    annotations | Inhouse | F1 score: 0.96 (40% labels) |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Xu et al. ([2016](#bib.bib194)) | 基于图的方法 | - | 显微镜图像 | 神经元分割 | 神经形态图像数据集
    | 2000个神经元区域带注释 | 内部 | F1 分数：0.96（40% 标签） |'
- en: '| Su et al. ([2015](#bib.bib163)) | Graph-based | - | Microscopy images | Cell
    segmentation | Phase contrast microscopy image dataset | Multiple sequences of
    total 1404 frames | http://www.celltracking.ri.cmu.edu/downloads.html. | TC: 0.9813
    |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Su et al. ([2015](#bib.bib163)) | 基于图的方法 | - | 显微镜图像 | 细胞分割 | 相位对比显微镜图像数据集
    | 多个序列，总计 1404 帧 | http://www.celltracking.ri.cmu.edu/downloads.html | TC：0.9813
    |'
- en: '| Shi, Su, Xing and Yang ([2020](#bib.bib150)) | Graph-based | Lung Cancer
    | H&E | Predictions of subtypes | The Cancer Genome Altas (TCGA) | 2904 patches
    | http://portal.gdc.cancer.gov | Accuracy: 0.905 (20% labels) |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Shi, Su, Xing 和 Yang ([2020](#bib.bib150)) | 基于图的方法 | 肺癌 | H&E | 亚型预测 | 癌症基因组图谱（TCGA）
    | 2904 个补丁 | http://portal.gdc.cancer.gov | 准确率：0.905（20% 标签） |'
- en: '| Breast Cancer | 1763 patches | Accuracy: 0.895 (20% labels) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| 乳腺癌 | 1763 个补丁 | 准确率：0.895（20% 标签） |'
- en: '| Peikari et al. ([2018](#bib.bib125)) | Unsupervised- preprocessing-based
    | Breast Cancer | H&E | Identifying different breast tissue regions | Pathology
    triaging image dataset | 4402 patches | Inhouse | AUC: 0.86 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Peikari 等 ([2018](#bib.bib125)) | 无监督预处理基础的 | 乳腺癌 | H&E | 识别不同乳腺组织区域 | 病理筛查图像数据集
    | 4402 个补丁 | 内部数据 | AUC: 0.86 |'
- en: '| Nuclei figure classification dataset | 30,000 figures | AUC: 0.95 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 核图形分类数据集 | 30,000 个图形 | AUC: 0.95 |'
- en: '| Lu et al. ([2019](#bib.bib104)) | Unsupervised- preprocessing-based | Breast
    Cancer | H&E | Benign and malignant classification | BACH dataset | 400 cases
    | BACH: Grand challenge on Breast Cancer histology images | Accuracy: 0.95 |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Lu 等 ([2019](#bib.bib104)) | 无监督预处理基础的 | 乳腺癌 | H&E | 良性与恶性分类 | BACH 数据集 |
    400 个病例 | BACH: 乳腺癌组织图像大挑战 | 准确率: 0.95 |'
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Unsupervised- preprocessing-based
    | Breast Cancer | H&E | Detection of tumor regions | Camelyon16 dataset | 399
    slides | https://camelyon16.grand-challenge.org/Data/ | AUC: 0.817 (1% labeled)
    |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Koohbanani 等 ([2021](#bib.bib89)) | 无监督预处理基础的 | 乳腺癌 | H&E | 肿瘤区域检测 | Camelyon16
    数据集 | 399 张幻灯片 | https://camelyon16.grand-challenge.org/Data/ | AUC: 0.817 (1%
    标记)'
- en: '| Oral Squamous Cell Carcinoma | Prediction of metastases in the cervical lymph
    nodes | LNM-OSCC dataset | 217 slides | Inhouse | AUC: 0.806 (1% labeled) |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| 口腔鳞状细胞癌 | 颈部淋巴结转移预测 | LNM-OSCC 数据集 | 217 张幻灯片 | 内部数据 | AUC: 0.806 (1% 标记)
    |'
- en: '| Colorectal Cancer | Classification of tissue types | Kather multiclass dataset
    | 100K patches | Kather *et al.* ([2019](#bib.bib84)) | AUC: 0.903 (1%labeled)
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 结直肠癌 | 组织类型分类 | Kather 多类别数据集 | 100K 个补丁 | Kather *等* ([2019](#bib.bib84))
    | AUC: 0.903 (1% 标记) |'
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Unsupervised- preprocessing-based
    | Breast Cancer, Colorectal Cancer | H&E | Detection of tumor metastasis | BreastPathQ
    dataset | 2579 patches | Martel et al. ([2019](#bib.bib111)) | TC: 0.876 (10%
    labels) |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| Srinidhi 等 ([2022](#bib.bib160)) | 无监督预处理基础的 | 乳腺癌, 结直肠癌 | H&E | 肿瘤转移检测 |
    BreastPathQ 数据集 | 2579 个补丁 | Martel 等 ([2019](#bib.bib111)) | TC: 0.876 (10% 标签)
    |'
- en: '| Classification of tissue type | Camelyon16 dataset | 399 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC: 0.855 (10% labels) |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 组织类型分类 | Camelyon16 数据集 | 399 张 WSIs | https://camelyon16.grand-challenge.org/Data/
    | AUC: 0.855 (10% 标签) |'
- en: '| Quantification of tumor cellularity | Kather multiclass dataset | 100K patches
    | Kather *et al.* ([2019](#bib.bib84)) | ACC: 0.982 (10% labels) |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 肿瘤细胞性定量 | Kather 多类别数据集 | 100K 个补丁 | Kather *等* ([2019](#bib.bib84)) | ACC:
    0.982 (10% 标签) |'
- en: '| Kapil et al. ([2018](#bib.bib82)) | GAN-based | Lung Cancer | Ventana PD-L1
    (SP263) assay | Automated tumor proportion scoring | NSCLC needle biopsy dataset
    | 270 slides | Inhouse | Ratio of the number of tumor positive cell pixels to
    the total number of tumor cell pixels: 0.94 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| Kapil 等 ([2018](#bib.bib82)) | 基于 GAN 的 | 肺癌 | Ventana PD-L1 (SP263) 检测 |
    自动肿瘤比例评分 | NSCLC 针刺活检数据集 | 270 张幻灯片 | 内部数据 | 肿瘤阳性细胞像素与肿瘤细胞像素总数的比率: 0.94 |'
- en: '| Cong et al. ([2021](#bib.bib38)) | GAN-based | Brain Cancer | H&E | Stain
    normalisation | TCGA1 glioma cohort | 22,229 images | Liu et al. ([2020](#bib.bib101))
    | F1 score: 0.937 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Cong 等 ([2021](#bib.bib38)) | 基于 GAN 的 | 脑癌 | H&E | 染色标准化 | TCGA1 神经胶质瘤队列
    | 22,229 张图像 | Liu 等 ([2020](#bib.bib101)) | F1 分数: 0.937 |'
- en: '| Breast Cancer | BreakHis database | 7,909 images | Spanhol et al. ([2015](#bib.bib157))
    | F1 score: 0.980 |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 乳腺癌 | BreakHis 数据库 | 7,909 张图像 | Spanhol 等 ([2015](#bib.bib157)) | F1 分数:
    0.980 |'
- en: '| Sparks and Madabhushi ([2016](#bib.bib158)) | Manifold- learning-based |
    Prostate Cancer | H&E | Image retrieval | Prostate histpathology dataset | 58
    patients | Inhouse | SI: 0.14 |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| Sparks 和 Madabhushi ([2016](#bib.bib158)) | 流形学习基础的 | 前列腺癌 | H&E | 图像检索 |
    前列腺组织病理数据集 | 58 位患者 | 内部数据 | SI: 0.14 |'
- en: '| Li et al. ([2018](#bib.bib100)) | Expectation- Maximization-based | Prostate
    Cancer | H&E | Semantic segmentation | Prostate dataset | 135 fully annotated
    and 1800 weakly annotated tiles | Gertych et al. ([2015](#bib.bib60)) | AJI: 0.495
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| Li 等 ([2018](#bib.bib100)) | 基于期望最大化的 | 前列腺癌 | H&E | 语义分割 | 前列腺数据集 | 135
    个完全注释和 1800 个弱注释图块 | Gertych 等 ([2015](#bib.bib60)) | AJI: 0.495 |'
- en: '| Su et al. ([2021](#bib.bib164)) | Association- learning-based | Breast Cancer
    | H&E | Classification of cancerous and non-cancerous slides | Bioimaging 2015
    challenge dataset | 285 images | Araújo et al. ([2017](#bib.bib4)) | F1 score:
    0.75 |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| Su 等 ([2021](#bib.bib164)) | 关联学习基础的 | 乳腺癌 | H&E | 癌性和非癌性幻灯片分类 | Bioimaging
    2015 挑战数据集 | 285 张图像 | Araújo 等 ([2017](#bib.bib4)) | F1 分数: 0.75 |'
- en: '| BACH dataset | 400 images | Aresta et al. ([2019](#bib.bib5)) | F1 score:
    0.77 |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| BACH 数据集 | 400 张图像 | Aresta 等 ([2019](#bib.bib5)) | F1 分数: 0.77 |'
- en: 3.3 Self-Supervised Learning Paradigm
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 自监督学习范式
- en: Unlike the former two paradigms, the self-supervised learning paradigm does
    not perform the classification or segmentation of pathological images directly,
    but in a two-stage ’pre-training and fine-tuning’ approach. Due to the small number
    of annotated pathological images, it is not enough to use these data to directly
    train the model. Therefore, the self-supervised learning paradigm aims to first
    learn effective feature representations from a large amount of unlabeled data,
    which is called the pre-training process. Afterwards, the feature representations
    learned in the self-supervised auxiliary tasks are used to be transferred to train
    the downstream tasks using limited labeled data, which is called the fine-tuning
    process. In this way, good feature representations can effectively help the model
    to achieve good results even if it is trained with only a small amount of labeled
    data.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 与前两种范式不同，自监督学习范式并不直接对病理图像进行分类或分割，而是采用“两阶段‘预训练和微调’”的方法。由于标记的病理图像数量较少，无法仅用这些数据直接训练模型。因此，自监督学习范式旨在首先从大量未标记数据中学习有效的特征表示，这被称为预训练过程。之后，利用在自监督辅助任务中学习到的特征表示，将其迁移用于使用有限标记数据训练下游任务，这被称为微调过程。通过这种方式，即使仅用少量标记数据进行训练，良好的特征表示也能有效帮助模型获得良好的结果。
- en: The process of pre-training, i.e., the learning process of good feature representations,
    is the key to self-supervised learning. Typically, self-supervised learning learns
    good feature representations by performing self-supervised auxiliary tasks. In
    a self-supervised auxiliary task, certain inherent properties of the unlabeled
    data are first used to generate supervised signals, and then the network is trained
    by these self-supervised signals. Different studies usually focus on designing
    different self-supervised auxiliary tasks to perform feature representation learning
    efficiently. According to the properties of the auxiliary tasks, existing self-supervised
    learning paradigms can be mainly classified into predictive self-supervised learning,
    generative self-supervised learning, and contrastive self-supervised learning.
    Predictive self-supervised learning learns good feature representations by constructing
    the auxiliary tasks as classification problems with unlabeled data; generative
    self-supervised learning learns good feature representations by reconstructing
    the input images; and contrastive self-supervised learning learns good feature
    representations by learning to distinguish between similar samples (positive samples)
    and dissimilar samples (negative samples). For a systematic review of self-supervised
    methods in the natural image domain and medical image domain, we recommend the
    reviews by Liu *et al.* [2021](#bib.bib102) and Shurrab *et al.* [2021](#bib.bib152).
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 预训练过程，即良好特征表示的学习过程，是自监督学习的关键。通常，自监督学习通过执行自监督辅助任务来学习良好的特征表示。在自监督辅助任务中，首先利用未标记数据的某些固有属性生成监督信号，然后通过这些自监督信号来训练网络。不同的研究通常集中于设计不同的自监督辅助任务，以有效地进行特征表示学习。根据辅助任务的性质，现有的自监督学习范式主要可以分为预测性自监督学习、生成性自监督学习和对比性自监督学习。预测性自监督学习通过将辅助任务构建为带有未标记数据的分类问题来学习良好的特征表示；生成性自监督学习通过重建输入图像来学习良好的特征表示；对比性自监督学习通过学习区分相似样本（正样本）和不相似样本（负样本）来学习良好的特征表示。有关自然图像领域和医学图像领域自监督方法的系统性综述，我们推荐刘*等*
    [2021](#bib.bib102) 和 Shurrab*等* [2021](#bib.bib152)的综述。
- en: 'In this section, we provide a detailed review of the studies on self-supervised
    learning for pathological image analysis. Currently, some studies focus on proposing
    innovative self-supervised frameworks for pathological images (we call them study
    on novel self-supervised frameworks), while others attempt to apply existing self-supervised
    learning methods to pathological image analysis (we call them study on application
    of self-supervised frameworks). We introduce studies on novel self-supervised
    frameworks in Section [3.3.1](#S3.SS3.SSS1 "3.3.1 Study on Novel Self-supervised
    Frameworks ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"), where we focus on predictive self-supervised learning, generative
    self-supervised learning, contrastive self-supervised learning, and hybrid self-supervised
    learning and their state-of-the-art approaches in pathological image analysis.
    We introduce the study on application of self-supervised frameworks in Section
    [3.3.2](#S3.SS3.SSS2 "3.3.2 Study on Applications of Self-supervised Frameworks
    ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis"). Table [5](#S3.T5 "Table 5 ‣ 3.3.2 Study on Applications of Self-supervised
    Frameworks ‣ 3.3 Self-Supervised Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient
    Automatic Diagnosis and Analysis: A Comprehensive Survey of Advanced Deep Learning-based
    Weakly-supervised, Semi-supervised and Self-supervised Techniques in Histopathological
    Image Analysis") summarizes a detailed list of literatures in this section.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们详细回顾了用于病理图像分析的自监督学习研究。目前，一些研究专注于提出创新的自监督框架用于病理图像（我们称之为新颖自监督框架研究），而另一些则尝试将现有自监督学习方法应用于病理图像分析（我们称之为自监督框架应用研究）。我们在第[3.3.1](#S3.SS3.SSS1
    "3.3.1 Study on Novel Self-supervised Frameworks ‣ 3.3 Self-Supervised Learning
    Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis and Analysis:
    A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised, Semi-supervised
    and Self-supervised Techniques in Histopathological Image Analysis")节介绍了新颖自监督框架的研究，其中我们重点讨论了预测性自监督学习、生成性自监督学习、对比性自监督学习和混合自监督学习及其在病理图像分析中的最先进方法。我们在第[3.3.2](#S3.SS3.SSS2
    "3.3.2 Study on Applications of Self-supervised Frameworks ‣ 3.3 Self-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")节介绍了自监督框架应用研究。表[5](#S3.T5
    "Table 5 ‣ 3.3.2 Study on Applications of Self-supervised Frameworks ‣ 3.3 Self-Supervised
    Learning Paradigm ‣ 3 Paradigms ‣ Towards Label-efficient Automatic Diagnosis
    and Analysis: A Comprehensive Survey of Advanced Deep Learning-based Weakly-supervised,
    Semi-supervised and Self-supervised Techniques in Histopathological Image Analysis")总结了本节的详细文献列表。'
- en: 3.3.1 Study on Novel Self-supervised Frameworks
  id: totrans-213
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1 新颖自监督框架的研究
- en: Predictive Self-supervised Learning Approach
  id: totrans-214
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 预测性自监督学习方法
- en: Fundamental Principles
  id: totrans-215
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 基本原理
- en: Predictive self-supervised learning learns good feature representations by constructing
    the auxiliary tasks as classification problems with unlabeled data, and the class
    labels for classification are constructed from the unlabeled data itself. Currently,
    predictive self-supervised auxiliary tasks widely applied in natural image processing
    are relative position prediction (Doersch *et al.* [2015](#bib.bib49)), solving
    Jigsaw puzzles (Noroozi *et al.* [2016](#bib.bib120)), and rotation angle prediction
    (Gidaris *et al.* [2018](#bib.bib61)), etc.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 预测性自监督学习通过将辅助任务构建为无标签数据的分类问题来学习良好的特征表示，分类的类别标签是从无标签数据本身构建的。目前，广泛应用于自然图像处理的预测性自监督辅助任务包括相对位置预测（Doersch
    *et al.* [2015](#bib.bib49)）、拼图解决（Noroozi *et al.* [2016](#bib.bib120)）和旋转角度预测（Gidaris
    *et al.* [2018](#bib.bib61)）等。
- en: Study in Pathological Image Analysis
  id: totrans-217
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 病理图像分析研究
- en: In the field of pathological image processing, Sahasrabudhe *et al.* [2020](#bib.bib141)
    proposed the auxiliary task of predicting patch magnification for cell nuclei
    segmentation. Their main idea is that given WSIs of different magnification classes
    (e.g., 5$\times" display="inline"><semantics ><mo >×</mo><annotation encoding="application/x-tex"
    id=$, 10$\times" display="inline"><semantics ><mo >×</mo><annotation encoding="application/x-tex"
    id=$, 20$\times" display="inline"><semantics ><mo >×</mo><annotation encoding="application/x-tex"
    id=$), they first obtained patches of different magnifications from them and then
    predicted the magnification class of those patches by examining the size and texture
    of the cell nuclei in the patches. Srinidhi *et al.* [2022](#bib.bib160) proposed
    the resolution sequence prediction (RSP) auxiliary task. First they used patches
    with different magnifications to construct different combinations of resolution
    sequences, and then trained the network to predict the order of the resolution
    sequences. Koohbanani *et al.* [2021](#bib.bib89) proposed magnification prediction
    and solving magnification puzzles auxiliary tasks for pathological images. They
    first trained the network to accurately predict the magnification category, and
    then trained the network to predict the order of the patches with different magnifications.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像处理领域，Sahasrabudhe *等* [2020](#bib.bib141) 提出了预测细胞核分割的补充任务。他们的主要思路是，对于不同放大倍数的WSI（例如，5$\times$、10$\times$、20$\times$），他们首先从中获取不同放大倍数的图块，然后通过检查图块中细胞核的大小和纹理来预测这些图块的放大倍数类别。Srinidhi
    *等* [2022](#bib.bib160) 提出了分辨率序列预测（RSP）补充任务。他们首先使用不同放大倍数的图块构建不同的分辨率序列组合，然后训练网络预测分辨率序列的顺序。Koohbanani
    *等* [2021](#bib.bib89) 提出了放大倍数预测和解决放大倍数难题的补充任务。他们首先训练网络准确预测放大倍数类别，然后训练网络预测不同放大倍数图块的顺序。
- en: Generative Self-supervised Learning Approach
  id: totrans-219
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 生成自监督学习方法
- en: Fundamental Principles
  id: totrans-220
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 基本原理
- en: Generative self-supervised learning learns good feature representations by reconstructing
    the input images. They argue that the image itself is a useful self-supervised
    information and that the network can learn the potential feature representations
    of the generated image during the image reconstruction process. In natural image
    processing, autoencoders (Goodfellow *et al.* [2016](#bib.bib64)) are representative
    of early work on generative self-supervised feature representation learning. Later,
    denoising autoencoders (Vincent *et al.* [2008](#bib.bib179)) enhanced the feature
    representation capability of the model by introducing noise. Subsequently, researchers
    proposed a series of reconstructive self-supervised auxiliary tasks, including
    inpainting (Pathak *et al.* [2016](#bib.bib124)), colorization (Zhang *et al.* [2016](#bib.bib204)),
    patch shuffling and restoration (Chen *et al.* [2019](#bib.bib23), Zhou *et al.* [2021](#bib.bib210))
    to further enhance the feature representation capability of the network and achieved
    promising results. On the other hand, a series of GAN-based models (e.g., DCGAN
    [2015](#bib.bib133), BiGAN [2016](#bib.bib50)) have also been used to perform
    self-supervised representation learning. In the latest self-supervised studies
    on natural images, a series (e.g., BEiT [2021](#bib.bib6), MAE [2021](#bib.bib73),
    PeCo [2021](#bib.bib51), etc.) of self-supervised studies based on masked image
    blocks and reconstruction using Transformer achieved the highest performance,
    which is expected to start a new wave of research on reconstruction-based self-supervised
    representation learning.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 生成自监督学习通过重建输入图像来学习良好的特征表示。他们认为图像本身是一种有用的自监督信息，网络可以在图像重建过程中学习生成图像的潜在特征表示。在自然图像处理中，自编码器（Goodfellow
    *等* [2016](#bib.bib64)）是生成自监督特征表示学习的早期代表工作。随后，去噪自编码器（Vincent *等* [2008](#bib.bib179)）通过引入噪声增强了模型的特征表示能力。随后，研究人员提出了一系列重建自监督辅助任务，包括修补（Pathak
    *等* [2016](#bib.bib124)）、着色（Zhang *等* [2016](#bib.bib204)）、补丁打乱和恢复（Chen *等* [2019](#bib.bib23)，Zhou
    *等* [2021](#bib.bib210)），以进一步提升网络的特征表示能力，并取得了良好的结果。另一方面，一系列基于GAN的模型（如DCGAN [2015](#bib.bib133)，BiGAN
    [2016](#bib.bib50)）也被用于执行自监督表示学习。在最新的自然图像自监督研究中，一系列（如BEiT [2021](#bib.bib6)，MAE
    [2021](#bib.bib73)，PeCo [2021](#bib.bib51)等）基于遮罩图像块和使用Transformer进行重建的自监督研究达到了最高的性能，预计将引发新一波基于重建的自监督表示学习研究。
- en: Study in Pathological Image Analysis
  id: totrans-222
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 病理图像分析中的研究
- en: In pathological image analysis, Muhammad *et al.* [2019](#bib.bib114) proposed
    a new deep convolutional autoencoder-based clustering model to learn the feature
    representations of pathological images. Mahapatra *et al.* [2020](#bib.bib108)
    incorporated semantic information into a GAN-based generative model for self-supervised
    feature representation learning and used it for the stain normalization task of
    pathological images. Quiros *et al.* [2019](#bib.bib131), [2021](#bib.bib130)
    designed GANs for pathological images to extract key feature representations of
    tissues. Boyd et al *et al.* [2021](#bib.bib15) proposed a new generative auxiliary
    task which performs representation learning by extending the view of image patches.
    Hou et al *et al.* [2019](#bib.bib75) proposed a sparse convolutional autoencoder
    (CAE) for simultaneous nuclei detection and feature extraction in histopathological
    images. Koohbanani *et al.* [2021](#bib.bib89) proposed the hematoxylin channel
    prediction auxiliary task, where they used hematoxylin and eosin (H&E) stained
    images to predict the hematoxylin channel pixel by pixel.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，穆罕默德 *等* [2019](#bib.bib114) 提出了一个基于深度卷积自编码器的新型聚类模型，用于学习病理图像的特征表示。马哈帕特拉
    *等* [2020](#bib.bib108) 将语义信息融入到基于GAN的生成模型中，用于自监督特征表示学习，并将其应用于病理图像的染色体标准化任务。基罗斯
    *等* [2019](#bib.bib131)，[2021](#bib.bib130) 设计了用于病理图像的GAN，提取组织的关键特征表示。博伊德 *等*
    [2021](#bib.bib15) 提出了一个新的生成辅助任务，通过扩展图像补丁的视角来进行表示学习。侯 *等* [2019](#bib.bib75) 提出了一个稀疏卷积自编码器（CAE），用于在组织病理图像中同时进行核检测和特征提取。库班尼
    *等* [2021](#bib.bib89) 提出了血红素通道预测辅助任务，他们使用血红素和伊红（H&E）染色图像逐像素预测血红素通道。
- en: Contrastive Self-supervised Learning Approach
  id: totrans-224
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 对比自监督学习方法
- en: Fundamental Principles
  id: totrans-225
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 基本原理
- en: The contrastive self-supervised approach is one of the most popular self-supervised
    paradigms, which focuses on learning good feature representations by encouraging
    the model to learn to distinguish between similar samples (positive samples) and
    dissimilar samples (negative samples).
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 对比自监督方法是最受欢迎的自监督范式之一，它通过鼓励模型学习区分相似样本（正样本）和不相似样本（负样本）来学习良好的特征表示。
- en: Contrast predictive coding (CPC) (Van *et al.* [2018](#bib.bib174)) is an early
    contrastive self-supervised method applied to natural image processing whose goal
    is to maximize the mutual information between patches (positive samples) from
    the same image and minimize the mutual information between patches (negative samples)
    from different images within a mini-batch. Typical subsequent studies have been
    devoted to constructing negative samples. MoCo (He *et al.* [2020](#bib.bib74))
    is a momentum-based contrastive self-supervised framework, which is mainly based
    on the ideas of dynamic dictionary-lookup and queues. SimCLR (Chen *et al.* [2020](#bib.bib26))
    is a simple contrastive learning framework that aims to maximize the cosine similarity
    between two augmented views of the same image (positive samples) and minimize
    the similarity between different images in a minibatch (negative samples).
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 对比预测编码（CPC）（Van *et al.* [2018](#bib.bib174)）是一种早期应用于自然图像处理的对比自监督方法，其目标是最大化来自同一图像的补丁（正样本）之间的互信息，并最小化来自不同图像的补丁（负样本）之间的互信息。典型的后续研究致力于构造负样本。MoCo（He
    *et al.* [2020](#bib.bib74)）是基于动量的对比自监督框架，主要基于动态字典查找和队列的思想。SimCLR（Chen *et al.*
    [2020](#bib.bib26)）是一个简单的对比学习框架，旨在最大化同一图像的两个增强视图（正样本）之间的余弦相似度，并最小化小批量中不同图像之间的相似度（负样本）。
- en: These methods rely heavily on a large number of negative samples since only
    positive samples will easily lead to model degeneration, i.e., mapping the features
    of all samples to an identical vector. However, recent studies have shown that
    negative samples are not necessary. Caron *et al.* [2020](#bib.bib18) introduced
    clustering into contrastive learning, thus eliminating the need for negative samples.
    Chen *et al.* [2021](#bib.bib28) explored stop-gradient operation applied to siamese
    networks without the need for a large number of negative samples. Grill *et al.* [2020](#bib.bib66),
    Caron *et al.* [2021](#bib.bib19) proposed a self-supervised learning model based
    on a teacher-student knowledge distillation framework that achieves state-of-the-art
    performance without any negative samples.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法严重依赖大量负样本，因为仅有正样本容易导致模型退化，即将所有样本的特征映射到相同的向量。然而，最近的研究表明负样本并非必需。Caron *et
    al.* [2020](#bib.bib18) 将聚类引入对比学习，从而消除了对负样本的需求。Chen *et al.* [2021](#bib.bib28)
    探索了应用于孪生网络的停止梯度操作，无需大量负样本。Grill *et al.* [2020](#bib.bib66)，Caron *et al.* [2021](#bib.bib19)
    提出了基于教师-学生知识蒸馏框架的自监督学习模型，在没有任何负样本的情况下实现了最先进的性能。
- en: Study in Pathological Image Analysis
  id: totrans-229
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 病理图像分析研究
- en: In pathological image analysis, Xie *et al.* [2020](#bib.bib191) employed patches
    from different magnifications as positive samples and patches from different magnifications
    as negative samples and constructed scale-wise triplet loss to perform contrastive
    learning for the nuclei segmentation. Chhipa *et al.* [2022](#bib.bib32) proposed
    Magnification Prior Contrastive Similarity (MPCS) to construct contrastive loss.
    Xu *et al.* [2020](#bib.bib193) proposed a self-supervised Deformation Representation
    Learning (DRL) framework to learn semantic features from unlabeled pathological
    images. They used mutual information to train the network to distinguish original
    histopathological images from those deformed in local structure, while consistent
    global contextual information was maintained using noise contrastive estimation
    (NCE). Wang *et al.* [2021](#bib.bib183) proposed Transpath based on the BYOL
    framework [2020](#bib.bib66). They first collected the current largest histopathological
    image dataset for self-supervised pre-training, which includes about 2.7 million
    images from 32529 WSIs. Then they proposed a hybrid framework combining CNN and
    Transformer to extract both local structural features and global contextual features,
    and proposed a TAE module to further enhance the feature extraction capability.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 在病理图像分析中，Xie *等人* [2020](#bib.bib191) 使用不同放大倍数的图块作为正样本，而用不同放大倍数的图块作为负样本，并构建了尺度级三元组损失，以进行对比学习以进行核分割。Chhipa
    *等人* [2022](#bib.bib32) 提出了放大优先对比相似度（MPCS）来构建对比损失。Xu *等人* [2020](#bib.bib193)
    提出了一个自监督变形表示学习（DRL）框架，从未标记的病理图像中学习语义特征。他们使用互信息训练网络，以区分原始的组织病理图像和局部结构变形的图像，同时使用噪声对比估计（NCE）保持一致的全局上下文信息。Wang
    *等人* [2021](#bib.bib183) 提出了基于 BYOL 框架 [2020](#bib.bib66) 的 Transpath。他们首先收集了当前最大的病理图像数据集用于自监督预训练，其中包括约
    270 万张来自 32529 个 WSIs 的图像。然后他们提出了一个结合 CNN 和 Transformer 的混合框架，以提取局部结构特征和全局上下文特征，并提出了
    TAE 模块以进一步增强特征提取能力。
- en: Hybrid Self-supervised Learning Approach
  id: totrans-231
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 混合自监督学习方法
- en: Many studies have also presented hybrid self-supervised methods for pathological
    images. Abbet *et al.* [2020](#bib.bib2) proposed a combination of generative
    and contrastive self-supervised representation learning method for pathological
    images. They first applied colorization as a generative auxiliary task. Then,
    they constructed the contrastive loss using spatially neighboring patches as positive
    samples and distant patches as negative samples. Yang *et al.* [2021](#bib.bib200)
    also proposed a self-supervised representation method combining generative and
    contrastive approaches for pathological images. They first proposed a generative-based
    self-supervised task called cross-stain prediction, in which they defined two
    encoders and decoders to predict the E-channel and H-channel, respectively, and
    then they used the encoders trained in the previous task to perform further contrastive
    training.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 许多研究还提出了用于病理图像的混合自监督方法。Abbet *等人* [2020](#bib.bib2) 提出了用于病理图像的生成对比自监督表示学习方法的组合。他们首先将颜色化作为生成辅助任务。然后，他们使用空间上相邻的图块作为正样本，而远离的图块作为负样本，构建对比损失。Yang
    *等人* [2021](#bib.bib200) 还提出了一种结合生成和对比方法的自监督表示方法用于病理图像。他们首先提出了一种基于生成的自监督任务，称为交叉染色预测，其中定义了两个编码器和解码器分别预测
    E 通道和 H 通道，然后他们使用在前一个任务中训练的编码器进行进一步的对比训练。
- en: 3.3.2 Study on Applications of Self-supervised Frameworks
  id: totrans-233
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2 自监督框架的应用研究
- en: In addition to studies that aim to propose innovative self-supervised frameworks
    for pathological images, more studies have attempted to apply existing self-supervised
    learning methods to various pathological image analysis tasks. Chen *et al.* [2020](#bib.bib25)
    proposed an end-to-end multimodal fusion framework for histopathological images
    and genomic data for survival prognosis prediction, in which they used contrastive
    predictive coding (CPC) pre-trained self-supervised features for initialization
    of the network model. Ciga *et al.* [2022](#bib.bib36) showed through extensive
    experiments that using self-supervised pre-training methods can yield better features
    to improve performance on several downstream tasks. They found that the success
    of contrastive self-supervised pre-training methods depended heavily on the diversity
    of the unlabeled training set rather than the number of images. On the other hand,
    positive and negative samples that are visually significantly different facilitate
    contrastive self-supervised learning, while positive and negative sample that
    contain only minor differences but are generally similar (e.g., normal patches
    versus patches containing only a small percentage of tumor regions) are not conducive
    to contrastive learning. However, this is uncommon in natural images, so it is
    particularly important to design targeted self-supervised tasks for the characteristics
    of pathological images. Tellez *et al.* [2019](#bib.bib170) used the variational
    autoencoder [2013](#bib.bib87), contrastive learning [2016](#bib.bib112) and BiGAN
    [2016](#bib.bib50) for the compression of gigapixel pathological images and evaluated
    the performance on a synthetic dataset and two public histopathology datasets,
    respectively, achieving promising results. Stacke *et al.* [2021](#bib.bib161)
    investigated how SimCLR [2020](#bib.bib26) could be extended for pathological
    images to learn useful feature representations. They systematically compared the
    differences between ImageNet data and histopathology data and how this affected
    the goals of self-supervised learning, and pointed out the impact that designing
    for different self-supervised goals would have on the results. Chen *et al.* [2022](#bib.bib24)
    comprehensively compared the performance of ImageNet pre-trained features, SimCLR
    pre-trained features, and DINO [2021](#bib.bib19) pre-trained features in weakly
    supervised classification and fully supervised classification tasks for histopathological
    images. They found that the DINO-based knowledge distillation framework could
    better learn effective and interpretable features in pathological images.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 除了旨在提出创新的自监督框架以处理病理图像的研究，更多的研究尝试将现有的自监督学习方法应用于各种病理图像分析任务。Chen *等人* [2020](#bib.bib25)
    提出了一个用于生存预后预测的端到端多模态融合框架，该框架结合了组织病理图像和基因组数据，其中使用了对比预测编码（CPC）预训练的自监督特征来初始化网络模型。Ciga
    *等人* [2022](#bib.bib36) 通过大量实验表明，使用自监督预训练方法可以产生更好的特征，从而提升多个下游任务的性能。他们发现，对比自监督预训练方法的成功在很大程度上依赖于未标记训练集的多样性，而不是图像的数量。另一方面，视觉上显著不同的正样本和负样本有助于对比自监督学习，而只有微小差异但总体上相似的正负样本（例如正常的补丁与仅包含少量肿瘤区域的补丁）则不利于对比学习。然而，这在自然图像中并不常见，因此针对病理图像特征设计有针对性的自监督任务尤为重要。Tellez
    *等人* [2019](#bib.bib170) 使用变分自编码器 [2013](#bib.bib87)、对比学习 [2016](#bib.bib112)
    和 BiGAN [2016](#bib.bib50) 对 gigapixel 病理图像进行压缩，并分别在一个合成数据集和两个公共组织病理数据集上评估了性能，取得了令人满意的结果。Stacke
    *等人* [2021](#bib.bib161) 研究了如何将 SimCLR [2020](#bib.bib26) 扩展到病理图像上，以学习有用的特征表示。他们系统地比较了
    ImageNet 数据和组织病理数据之间的差异，以及这些差异如何影响自监督学习的目标，并指出了为不同自监督目标设计对结果的影响。Chen *等人* [2022](#bib.bib24)
    对 ImageNet 预训练特征、SimCLR 预训练特征和 DINO [2021](#bib.bib19) 预训练特征在病理图像的弱监督分类和完全监督分类任务中的表现进行了全面比较。他们发现基于
    DINO 的知识蒸馏框架能够更好地学习病理图像中的有效和可解释的特征。
- en: Saillard *et al.* [2021](#bib.bib142) and Dehaene *et al.* [2020](#bib.bib45)
    used the MoCo V2 [2020](#bib.bib27) self-supervised learning method to train pathological
    images and the experimental results showed that the results using the self-supervised
    pre-trained features were consistently better than those using features pre-trained
    on ImageNet under the same conditions. Lu *et al.* [2019](#bib.bib104), Zhao *et
    al.* [2020](#bib.bib206), and Li *et al.* [2021](#bib.bib97) used contrastive
    predictive coding (CPC) [2018](#bib.bib174), VAE-GAN [2016](#bib.bib93), and SimCLR
    [2020](#bib.bib26) self-supervised pre-trained features for weakly supervised
    WSI classification, respectively, and achieved the current state-of-the-art performance.
    Koohbanani *et al.* [2021](#bib.bib89) developed a semi-supervised learning framework
    facilitated by self-supervised learning with a multi-task learning approach for
    training, i.e., training with a small amount of labeled data as the main task
    and self-supervised tasks as auxiliary tasks. In their study, they also compared
    the effectiveness of various commonly used pathology-agnostic self-supervised
    auxiliary tasks (including rotation, flipping, auto-encoder, real/fake prediction,
    domain prediction, etc.) to facilitate semi-supervised learning. Srinidhi *et
    al.* [2022](#bib.bib160) also attempted to use self-supervised pre-trained features
    to enhance semi-supervised learning. They first proposed the resolution sequence
    prediction (RSP) self-supervised auxiliary task to pre-train the model through
    unlabeled data, and then they fine-tuned the model on the labeled data. After
    that, they used the trained model from the above two steps as the initial weights
    of the model for further semi-supervised training based on the teacher-student
    consistency framework.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: Saillard *et al.* [2021](#bib.bib142) 和 Dehaene *et al.* [2020](#bib.bib45)
    使用了 MoCo V2 [2020](#bib.bib27) 自监督学习方法来训练病理图像，实验结果显示，在相同条件下，使用自监督预训练特征的结果始终优于使用在
    ImageNet 上预训练的特征。Lu *et al.* [2019](#bib.bib104), Zhao *et al.* [2020](#bib.bib206),
    和 Li *et al.* [2021](#bib.bib97) 分别使用了对比预测编码（CPC） [2018](#bib.bib174), VAE-GAN
    [2016](#bib.bib93), 和 SimCLR [2020](#bib.bib26) 自监督预训练特征进行弱监督 WSI 分类，并取得了当前的最新性能。Koohbanani
    *et al.* [2021](#bib.bib89) 开发了一个通过自监督学习和多任务学习方法促进的半监督学习框架，即以少量标注数据作为主要任务，自监督任务作为辅助任务进行训练。在他们的研究中，他们还比较了各种常用的病理无关自监督辅助任务（包括旋转、翻转、自编码器、真/假预测、领域预测等）以促进半监督学习。Srinidhi
    *et al.* [2022](#bib.bib160) 也尝试使用自监督预训练特征来增强半监督学习。他们首先提出了分辨率序列预测（RSP）自监督辅助任务，通过未标记的数据预训练模型，然后在标记数据上对模型进行微调。之后，他们使用上述两个步骤得到的训练模型作为模型的初始权重，进行基于教师-学生一致性框架的进一步半监督训练。
- en: In addition, self-supervised learning has been used for a variety of other pathological
    tasks, such as pathological image retrieval (Shi *et al.* [2018](#bib.bib149),
    Yang *et al.* [2020](#bib.bib201)), active learning (Zheng *et al.* [2019](#bib.bib207)),
    and molecular signature prediction (Ding *et al.* [2020](#bib.bib48), Fu *et al.* [2020](#bib.bib58),
    Kather *et al.* [2020](#bib.bib83)), etc.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，自监督学习还被用于各种其他病理任务，如病理图像检索（Shi *et al.* [2018](#bib.bib149), Yang *et al.*
    [2020](#bib.bib201)），主动学习（Zheng *et al.* [2019](#bib.bib207)），以及分子特征预测（Ding *et
    al.* [2020](#bib.bib48), Fu *et al.* [2020](#bib.bib58), Kather *et al.* [2020](#bib.bib83)）等。
- en: 'Table 5: List of literatures in the self-supervised learning section.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：自监督学习部分文献列表。
- en: '| Reference | Approach | Disease Type | Staining | Dataset | Dataset Scale
    | Dataset Link | Self-supervised Method | Downstream Task | Downstream Performance
    |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| 参考文献 | 方法 | 疾病类型 | 染色 | 数据集 | 数据集规模 | 数据集链接 | 自监督方法 | 下游任务 | 下游性能 |'
- en: '| Sahasrabudhe et al. ([2020](#bib.bib141)) | Predictive | - | H&E | MoNuSeg
    database | 1,125,737 tiles | Kumar et al. ([2017](#bib.bib91)) | Identification
    of the magnification levels for tiles | Nuclei segmentation | AJI: 0.5354, AHD:
    7.7502, Dice: 0.7477 |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| Sahasrabudhe 等 ([2020](#bib.bib141)) | 预测 | - | H&E | MoNuSeg 数据库 | 1,125,737
    个图块 | Kumar 等 ([2017](#bib.bib91)) | 识别图块的放大级别 | 细胞核分割 | AJI: 0.5354, AHD: 7.7502,
    Dice: 0.7477 |'
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Predictive | Breast Cancer, Colorectal
    Cancer | H&E | BreastPathQ dataset | 2579 patches | Martel et al. ([2019](#bib.bib111))
    | Predicting the resolution sequences | Detection of tumor metastasis | TC: 0.876
    (10% labels) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| Srinidhi 等 ([2022](#bib.bib160)) | 预测 | 乳腺癌、结直肠癌 | H&E | BreastPathQ 数据集
    | 2579 个补丁 | Martel 等 ([2019](#bib.bib111)) | 预测分辨率序列 | 肿瘤转移检测 | TC: 0.876 (10%
    标签) |'
- en: '|  |  |  |  | Camelyon16 dataset | 399 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | Classification of tissue types | AUC: 0.855 (10% labels) |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | Camelyon16 数据集 | 399 张全切片图像 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | 组织类型分类 | AUC: 0.855 (10% 标签) |'
- en: '|  |  |  |  | Kather multiclass dataset | 100K patches | Kather *et al.* ([2019](#bib.bib84))
    |  | Quantification of tumor cellularity | Accuracy: 0.982 (10% labels) |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | Kather 多类别数据集 | 100K 贴片 | Kather *et al.* ([2019](#bib.bib84))
    |  | 肿瘤细胞量化 | 准确率: 0.982 (10% 标签) |'
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Predictive | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Magnification prediction and solving magnification puzzles | Detection of tumor
    regions | AUC: 0.817 (1% labeled) |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| Koohbanani et al. ([2021](#bib.bib89)) | 预测模型 | 乳腺癌 | H&E | Camelyon16 数据集
    | 399 张幻灯片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 放大预测和解决放大难题 | 肿瘤区域检测 | AUC: 0.817 (1% 标记) |'
- en: '|  |  | oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 口腔鳞状细胞癌 |  | LNM-OSCC 数据集 | 217 张幻灯片 | 内部数据 |  | 预测颈部淋巴结中的转移 | AUC:
    0.806 (1% 标记) |'
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结直肠癌 |  | Kather 多类别数据集 | 100K 贴片 | Kather *et al.* ([2019](#bib.bib84))
    |  | 组织类型分类 | AUC: 0.903 (1% 标记) |'
- en: '| Muhammad et al. ([2019](#bib.bib114)) | Generative | Cholangi-ocarcinoma
    | H&E | Intrahepatic cholangiocarcinoma (ICC) dataset | 246 patients | Inhouse
    | Deep clustering convolutional autoencoder | Subtyping of cholangiocarcinoma
    | CHI: 3863(5 clusters) and 4314 (clutsering weight = 0.2) |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '| Muhammad et al. ([2019](#bib.bib114)) | 生成模型 | 胆管癌 | H&E | 肝内胆管癌 (ICC) 数据集
    | 246 名患者 | 内部数据 | 深度聚类卷积自编码器 | 胆管癌的亚型划分 | CHI: 3863（5 个簇）和 4314（簇权重 = 0.2） |'
- en: '| Mahapatra et al. ([2020](#bib.bib108)) | Generative | Breast Cancer | H&E
    | CAMELYON16 dataset | 100, 000 patches | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Using pre-trained networks for semantic guidance | Stain normalization | Average
    AUC: 0.9320 |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| Mahapatra et al. ([2020](#bib.bib108)) | 生成模型 | 乳腺癌 | H&E | CAMELYON16 数据集
    | 100,000 贴片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 使用预训练网络进行语义引导 | 染色标准化 | 平均 AUC: 0.9320 |'
- en: '|  |  | Breast Cancer |  | CAMELYON17 dataset | 100, 000 patches | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/),
    inhouse |  |  |  |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 乳腺癌 |  | CAMELYON17 数据集 | 100,000 贴片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)，内部数据
    |  |  |  |'
- en: '| Quiros et al. ([2019](#bib.bib131)) | Generative | Colorectal Cancer | H&E
    | National Center for Tumor diseases (NCT) dataset | 86 slides | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | Using Generative Adversarial Networks (GANs) to capture key tissue features
    and structure information | Count of cancer, lymphocytes, or stromal cells | FID:
    16.65 |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| Quiros et al. ([2019](#bib.bib131)) | 生成模型 | 结直肠癌 | H&E | 国家肿瘤疾病中心 (NCT)
    数据集 | 86 张幻灯片 | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | 使用生成对抗网络 (GANs) 捕捉关键组织特征和结构信息 | 癌症、淋巴细胞或基质细胞的计数 | FID: 16.65 |'
- en: '|  |  | Breast Cancer |  | Netherlands Cancer Institute (NKI) dataset and Vancouver
    General Hospital (VGH) dataset | 576 tissue micro-arrays (TMAs) | Beck et al.
    ([2011](#bib.bib8)) |  |  | FID: 32.05 |'
  id: totrans-250
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 乳腺癌 |  | 荷兰癌症研究所 (NKI) 数据集 和 温哥华综合医院 (VGH) 数据集 | 576 个组织微阵列 (TMAs)
    | Beck et al. ([2011](#bib.bib8)) |  |  | FID: 32.05 |'
- en: '| Quiros et al. ([2021](#bib.bib130)) | Generative | Breast Cancer | H&E |
    Netherlands Cancer Institute (NKI, Netherlands) and Vancouver General Hospital
    (VGH, Canada) cohorts | Total of 576 patients | Beck et al. ([2011](#bib.bib8))
    | Presenting an adversarial learning model to extract feature representations
    of cancer tissue | Classifying tissue types and predicting the presence of tumor
    in Whole Slide Images (WSIs) using multiple instance learning (MIL) | AUC: 0.97
    and Accuracy: 0.85; AUC: 0.98 and Accuracy: 0.94 |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| Quiros et al. ([2021](#bib.bib130)) | 生成模型 | 乳腺癌 | H&E | 荷兰癌症研究所 (NKI, 荷兰)
    和 温哥华综合医院 (VGH, 加拿大) 队列 | 总计 576 名患者 | Beck et al. ([2011](#bib.bib8)) | 提出对抗学习模型以提取癌症组织的特征表示
    | 使用多实例学习 (MIL) 分类组织类型和预测全切片图像 (WSIs) 中的肿瘤存在 | AUC: 0.97 和 准确率: 0.85; AUC: 0.98
    和 准确率: 0.94 |'
- en: '|  |  | Colon cancer |  | National Center for Tumor diseases (NCT, Germany)
    dataset | 100K tissue tiles | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    |  |  |  |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结肠癌 |  | 国家肿瘤中心 (NCT, 德国) 数据集 | 100K 组织块 | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    |  |  |  |'
- en: '|  |  | Lung Cancer |  | TCGA LUAD, LUSC dataset | 1184 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    |  |  |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 肺癌 |  | TCGA LUAD, LUSC 数据集 | 1184 名患者 | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    |  |  |  |'
- en: '| Boyd et al. ([2021](#bib.bib15)) | Generative | Breast Cancer | H&E | CAMELYON17
    dataset | 500 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Visual field expansion | Binary classification of tiles into metastatic and
    non-metastatic classes | Accuracy: 0.8569 |'
  id: totrans-254
  prefs: []
  type: TYPE_TB
  zh: '| Boyd 等人 ([2021](#bib.bib15)) | 生成型 | 乳腺癌 | H&E | CAMELYON17 数据集 | 500 张切片
    | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 视场扩展 | 将切片二分类为转移性和非转移性类别 | 准确率: 0.8569 |'
- en: '|  |  | Colorectal Cancer |  | CRC benchmark dataset | 100K image tiles | [https://doi.org/10.5281/zenodo.1214456](https://doi.org/10.5281/zenodo.1214456)
    |  | Classification of tiles into the 9 tissue types | Accuracy: 0.8511 |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结直肠癌 |  | CRC 基准数据集 | 100K 图像块 | [https://doi.org/10.5281/zenodo.1214456](https://doi.org/10.5281/zenodo.1214456)
    |  | 切片分类为 9 种组织类型 | 准确率: 0.8511 |'
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Generative | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Hematoxylin channel prediction auxiliary task | Detection of tumor regions |
    AUC: 0.817 (1% labeled) |'
  id: totrans-256
  prefs: []
  type: TYPE_TB
  zh: '| Koohbanani 等人 ([2021](#bib.bib89)) | 生成型 | 乳腺癌 | H&E | Camelyon16 数据集 | 399
    张切片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 苏木精通道预测辅助任务 | 肿瘤区域检测 | AUC: 0.817 (1% 标记) |'
- en: '|  |  | Oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  id: totrans-257
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 口腔鳞状细胞癌 |  | LNM-OSCC 数据集 | 217 张切片 | 内部收集 |  | 颈部淋巴结转移预测 | AUC: 0.806
    (1% 标记) |'
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结直肠癌 |  | Kather 多类别数据集 | 100K 补丁 | Kather *等人* ([2019](#bib.bib84))
    |  | 组织类型分类 | AUC: 0.903 (1% 标记) |'
- en: '| Hou et al. ([2019](#bib.bib75)) | Generative | - | H&E | Self-collected lymphocyte
    classification dataset | 1785 images | Inhouse | Sparse Convolutional Autoencoder
    (CAE) | Nucleus detection | Nucleus Classification: Lymphocyte Classification
    AUC 0.7856 |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| Hou 等人 ([2019](#bib.bib75)) | 生成型 | - | H&E | 自收集淋巴细胞分类数据集 | 1785 张图像 | 内部收集
    | 稀疏卷积自编码器（CAE） | 核检测 | 核分类：淋巴细胞分类 AUC 0.7856 |'
- en: '|  |  |  |  | Nuclear shape and attribute classification dataset | 2000 images
    | Murthy et al. ([2017](#bib.bib115)) |  |  | Nuclear Attribute &Shape AUC 0.8788
    |'
  id: totrans-260
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 核形状和属性分类数据集 | 2000 张图像 | Murthy 等人 ([2017](#bib.bib115)) |  |  |
    核属性与形状 AUC 0.8788 |'
- en: '|  |  |  |  | CRCHistoPhenotypes nucleus detection dataset | 100 images | Sirinukunwattana
    et al. ([2016](#bib.bib155)) |  |  | Nucleus detection: F-measure: 0.8345 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | CRCHistoPhenotypes 核检测数据集 | 100 张图像 | Sirinukunwattana 等人 ([2016](#bib.bib155))
    |  |  | 核检测：F-measure: 0.8345 |'
- en: '|  |  |  |  | MICCAI 2015 nucleus segmentation challenge dataset | 763 images
    | https://wiki.cancerimagingarchive.net/ pages/viewpage.action?pageId=20644646
    |  |  | Lymphocyte classification: AUC 0.7856 |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | MICCAI 2015 核分割挑战数据集 | 763 张图像 | [https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=20644646](https://wiki.cancerimagingarchive.net/pages/viewpage.action?pageId=20644646)
    |  |  | 淋巴细胞分类：AUC 0.7856 |'
- en: '|  |  |  |  | TCGA lung cancer dataset | 0.5 million images | [https://cancergenome.nih.gov/](https://cancergenome.nih.gov/)
    |  |  | Nucleus segmentation: DICE: 0.8362 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | TCGA 肺癌数据集 | 50 万张图像 | [https://cancergenome.nih.gov/](https://cancergenome.nih.gov/)
    |  |  | 核分割：DICE: 0.8362 |'
- en: '| Xie, Chen, Li and Zheng ([2020](#bib.bib191)) | Contrastive | - | H&E | MoNuSeg
    dataset | 44 images | Naylor et al. ([2018](#bib.bib119)) | Scale-wise triplet
    learning and count ranking | Nuclei segmentation | AJI: 0.7063 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| Xie、Chen、Li 和 Zheng ([2020](#bib.bib191)) | 对比型 | - | H&E | MoNuSeg 数据集 |
    44 张图像 | Naylor 等人 ([2018](#bib.bib119)) | 尺度三重学习与计数排序 | 核分割 | AJI: 0.7063 |'
- en: '| Chhipa et al. ([2022](#bib.bib32)) | Contrastive | Breast Cancer | H&E |
    BreakHis dataset | 7909 images | Spanhol et al. ([2015](#bib.bib157)) | Magnification
    prior contrastive similarity | Classifying histopathological images | Mean Accuracy:
    0.9233 |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| Chhipa 等人 ([2022](#bib.bib32)) | 对比型 | 乳腺癌 | H&E | BreakHis 数据集 | 7909 张图像
    | Spanhol 等人 ([2015](#bib.bib157)) | 放大优先对比相似性 | 分类组织病理图像 | 平均准确率: 0.9233 |'
- en: '| Xu et al. ([2020](#bib.bib193)) | Contrastive | Breast Cancer | H&E | MICCAI
    2015 Gland Segmentation Challenge (GLaS) dataset | 165 images | Sirinukunwattana
    et al. ([2017](#bib.bib154)) | Deformation representation learning | Gland segmentation
    | F1-score 0.900, Accuracy 0.8548 (10% labeled) |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| Xu 等人 ([2020](#bib.bib193)) | 对比 | 乳腺癌 | H&E | MICCAI 2015 腺体分割挑战赛 (GLaS)
    数据集 | 165 张图像 | Sirinukunwattana 等人 ([2017](#bib.bib154)) | 变形表示学习 | 腺体分割 | F1-score
    0.900, 准确率 0.8548 (10% 标注) |'
- en: '|  |  | Colon Cancer |  | Patch Camelyon (PCam) image classification dataset
    | 327,680 patches | Veeling et al. ([2018](#bib.bib176)) |  | Semi-supervised
    classification |  |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结肠癌 |  | Patch Camelyon (PCam) 图像分类数据集 | 327,680 个补丁 | Veeling 等人 ([2018](#bib.bib176))
    |  | 半监督分类 |  |'
- en: '| Wang et al. ([2021](#bib.bib183)) | Contrastive | Liver, Renal, Colorectal,
    Prostatic, Pancreatic, and Cholangio Breast Cancers | H&E | Multiple histopathological
    image datasets including MHIST, NCT-CRC-HE, PatchCamelyon dataset | 2.7 million
    images | [https://github.com/Xiyue-Wang/TransPath](https://github.com/Xiyue-Wang/TransPath)
    | Contrastive learning like BYOL (Bootstrap your own latent: a new approach to
    self-supervised learning) | Histopathological image classification tasks | F1-score:
    0.8993, 0.9582, 0.8983 on MHIST, NCT-CRC-HE, PatchCamelyon dataset |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人 ([2021](#bib.bib183)) | 对比 | 肝癌、肾癌、结直肠癌、前列腺癌、胰腺癌和胆管癌 | H&E | 包括 MHIST、NCT-CRC-HE、PatchCamelyon
    数据集在内的多个组织病理图像数据集 | 270 万张图像 | [https://github.com/Xiyue-Wang/TransPath](https://github.com/Xiyue-Wang/TransPath)
    | 对比学习，如 BYOL（自监督学习的新方法） | 组织病理图像分类任务 | F1-score: 0.8993、0.9582、0.8983（在 MHIST、NCT-CRC-HE、PatchCamelyon
    数据集上） |'
- en: '| Abbet et al. ([2020](#bib.bib2)) | Generative + Contrastive | Colorectal
    Cancer | H&E | Clinicopathological dataset | 660 WSIs | Inhouse | Colorization,
    Image reconstrucation and Contrastive learning | Survival analysis | C-Index:
    0.6943 |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| Abbet 等人 ([2020](#bib.bib2)) | 生成 + 对比 | 结直肠癌 | H&E | 临床病理数据集 | 660 个WSI
    | 内部 | 着色、图像重建和对比学习 | 生存分析 | C-Index: 0.6943 |'
- en: '| Yang et al. ([2021](#bib.bib200)) | Generative + Contrastive | Colorectal
    Cancer | H&E | NCTCRC-HE-100K dataset | 100K images | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | Cross-stain prediction, Contrastive training | Nine-class classification of
    histopathological images | Accuracy of eight-class classification with only 1,000
    labeled data: 0.915 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| Yang 等人 ([2021](#bib.bib200)) | 生成 + 对比 | 结直肠癌 | H&E | NCTCRC-HE-100K 数据集
    | 100K 张图像 | [https://zenodo.org/record/1214456#.Yvzd-nZBxhE](https://zenodo.org/record/1214456#.Yvzd-nZBxhE)
    | 跨染色预测、对比训练 | 九类组织病理图像分类 | 仅用1,000个标注数据的八类分类准确率: 0.915 |'
- en: '| Chen, Lu and Mahmood ([2020](#bib.bib25)) | Application | Glioma and Cell
    Carcinoma | H&E | The Cancer Genome Atlas (TCGA) dataset | 1505 images | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Contrastive predictive coding (CPC) | Survival prognosis prediction | C-Index:
    0.826 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| Chen, Lu 和 Mahmood ([2020](#bib.bib25)) | 应用 | 神经胶质瘤和细胞癌 | H&E | 癌症基因组图谱
    (TCGA) 数据集 | 1505 张图像 | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | 对比预测编码 (CPC) | 生存预后预测 | C-Index: 0.826 |'
- en: '| Ciga et al. ([2022](#bib.bib36)) | Application | Multiple Types | H&E | Out
    of the total 57 datasets from various institutions | A large number of images
    | [https://github.com/ozanciga/self-supervised-histopathology](https://github.com/ozanciga/self-supervised-histopathology)
    | Contrastive learning | Classification, Regression, and Segmentation | Multiple
    results |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
  zh: '| Ciga 等人 ([2022](#bib.bib36)) | 应用 | 多种类型 | H&E | 来自不同机构的总共57个数据集 | 大量图像 |
    [https://github.com/ozanciga/self-supervised-histopathology](https://github.com/ozanciga/self-supervised-histopathology)
    | 对比学习 | 分类、回归和分割 | 多项结果 |'
- en: '| Tellez et al. ([2019](#bib.bib170)) | Application | Breast Cancer | H&E |
    Camelyon16 dataset | 400 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Variational autoencoder, Contrastive learning and BiGAN | Predicting the presence
    of metastasis | AUC: 0.725 |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
  zh: '| Tellez 等人 ([2019](#bib.bib170)) | 应用 | 乳腺癌 | H&E | Camelyon16 数据集 | 400 个WSI
    | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 变分自编码器、对比学习和 BiGAN | 预测转移的存在 | AUC: 0.725 |'
- en: '|  |  |  |  | TUPAC16 dataset | 492 WSIs | Veta et al. ([2019](#bib.bib178))
    |  | Predicting tumor proliferation speed | Spearman correlation: 0.522 |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | TUPAC16 数据集 | 492 个WSI | Veta 等人 ([2019](#bib.bib178)) |  | 预测肿瘤增殖速度
    | Spearman 相关系数: 0.522 |'
- en: '| Stacke et al. ([2021](#bib.bib161)) | Application | Multiple Types | H&E
    | Camelyon16 dataset | 400 slides | [https://github.com/k-stacke/ssl-pathology](https://github.com/k-stacke/ssl-pathology)
    | Contrastive learning | Binary tumor classification | Multiple results |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| Stacke 等人 ([2021](#bib.bib161)) | 应用 | 多种类型 | H&E | Camelyon16 数据集 | 400
    张幻灯片 | [https://github.com/k-stacke/ssl-pathology](https://github.com/k-stacke/ssl-pathology)
    | 对比学习 | 二元肿瘤分类 | 多重结果 |'
- en: '|  |  |  |  | AIDA-LNSK dataset | 96 slides |  |  |  |  |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | AIDA-LNSK 数据集 | 96 张幻灯片 |  |  |  |  |'
- en: '|  |  |  |  | Multidata (samples from 60 publicly available datasets) | A large
    number of images |  |  |  |  |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | Multidata（来自 60 个公开数据集的样本） | 大量图像 |  |  |  |  |'
- en: '| Chen and Krishnan ([2022](#bib.bib24)) | Application | Colorectal Cancer
    | H&E | CRC-100K dataset | 100K images | Kather et al. ([2016](#bib.bib86)) |
    Contrastive learning | Weakly-supervised cancer subtyping | AUC: 0.886 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| Chen 和 Krishnan ([2022](#bib.bib24)) | 应用 | 结直肠癌 | H&E | CRC-100K 数据集 | 10
    万张图像 | Kather 等人 ([2016](#bib.bib86)) | 对比学习 | 弱监督癌症亚型分类 | AUC: 0.886 |'
- en: '|  |  | Breast Cancer |  | BreastPathQ dataset | 2766 patches | Petrick et al.
    ([2021](#bib.bib126)) |  | Patch-level tissue phenotyping | AUC: 0.987 |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 乳腺癌 |  | BreastPathQ 数据集 | 2766 个补丁 | Petrick 等人 ([2021](#bib.bib126))
    |  | 补丁级组织表型分析 | AUC: 0.987 |'
- en: '| Saillard et al. ([2021](#bib.bib142)) | Application | Colorectal Cancer |
    H&E | TCGA-CRC dataset | 555 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Contrastive learning | Microsatellite instability | AUC: 0.92 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| Saillard 等人 ([2021](#bib.bib142)) | 应用 | 结直肠癌 | H&E | TCGA-CRC 数据集 | 555
    名患者 | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov) | 对比学习 | 微卫星不稳定性
    | AUC: 0.92 |'
- en: '|  |  | Gastric Cancer |  | TCGA-Gastric dataset | 375 patients |  |  |  |
    AUC: 0.83 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 胃癌 |  | TCGA-胃癌数据集 | 375 名患者 |  |  |  | AUC: 0.83 |'
- en: '| Dehaene et al. ([2020](#bib.bib45)) | Application | Colorectal Cancer | H&E
    | Camelyon16 dataset | 400 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Contrastive learning | Predicting lymph node metastasis in Breast Cancer | AUC:
    0.987 |'
  id: totrans-282
  prefs: []
  type: TYPE_TB
  zh: '| Dehaene 等人 ([2020](#bib.bib45)) | 应用 | 结直肠癌 | H&E | Camelyon16 数据集 | 400
    张幻灯片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 对比学习 | 预测乳腺癌淋巴结转移 | AUC: 0.987 |'
- en: '|  |  | Breast Cancer |  | TCGA-COAD dataset | 461 slides | Guinney et al.
    ([2015](#bib.bib68)) |  | Colorectal Cancer subtyping | AUC: 0.882 (CMS1) and
    AUC: 0.829 (CMS3) |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 乳腺癌 |  | TCGA-COAD 数据集 | 461 张幻灯片 | Guinney 等人 ([2015](#bib.bib68))
    |  | 结直肠癌亚型分类 | AUC: 0.882 (CMS1) 和 AUC: 0.829 (CMS3) |'
- en: '| Lu et al. ([2019](#bib.bib104)) | Application | Breast Cancer | H&E | BACH
    dataset | 400 cases | Aresta et al. ([2019](#bib.bib5)) | Contrastive predictive
    coding (CPC) | classification and localization of clinically relevant histopathological
    classes | Accuracy: 0.95 |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
  zh: '| Lu 等人 ([2019](#bib.bib104)) | 应用 | 乳腺癌 | H&E | BACH 数据集 | 400 例 | Aresta
    等人 ([2019](#bib.bib5)) | 对比预测编码 (CPC) | 临床相关组织病理学类别的分类和定位 | 准确率: 0.95 |'
- en: '| Zhao et al. ([2020](#bib.bib206)) | Application | Colon Adenocarcinoma |
    H&E | The Cancer Genome Atlas (TCGA) dataset | 425 patients | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov)
    | Variational Auto Encoder and Generative Adversial Network (VAE-GAN) | Predicting
    lymph node metastasis | Accuracy: 0.6761 |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
  zh: '| Zhao 等人 ([2020](#bib.bib206)) | 应用 | 结肠腺癌 | H&E | 癌症基因组图谱（TCGA）数据集 | 425
    名患者 | [http://portal.gdc.cancer.gov](http://portal.gdc.cancer.gov) | 变分自编码器和生成对抗网络
    (VAE-GAN) | 预测淋巴结转移 | 准确率: 0.6761 |'
- en: '| Li, Li and Eliceiri ([2021](#bib.bib97)) | Application | Breast Cancer |
    H&E | Camelyon16 dataset | 400 cases | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Contrastive learning | Detection of lymph node metastases | Accuracy: 0.8992
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| Li, Li 和 Eliceiri ([2021](#bib.bib97)) | 应用 | 乳腺癌 | H&E | Camelyon16 数据集
    | 400 例 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 对比学习 | 乳腺癌淋巴结转移检测 | 准确率: 0.8992 |'
- en: '|  |  | Lung Cancer |  | TCGA lung cancer dataset | 1054 cases | [https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga)
    |  | Diagnosis of lung cancer subtypes | Accuracy: 0.9571 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 肺癌 |  | TCGA 肺癌数据集 | 1054 例 | [https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga)
    |  | 肺癌亚型诊断 | 准确率: 0.9571 |'
- en: '| Koohbanani et al. ([2021](#bib.bib89)) | Application | Breast Cancer | H&E
    | Camelyon16 dataset | 399 slides | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | Magnification prediction, JigMag prediction and Hematoxylin channel prediction
    | Detection of tumor regions | AUC: 0.817 (1% labeled) |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| Koohbanani 等人 ([2021](#bib.bib89)) | 应用 | 乳腺癌 | H&E | Camelyon16 数据集 | 399
    玻片 | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    | 放大倍率预测, JigMag 预测和苏木精通道预测 | 肿瘤区域检测 | AUC: 0.817 (1% 标注) |'
- en: '|  |  | Oral Squamous Cell Carcinoma |  | LNM-OSCC dataset | 217 slides | Inhouse
    |  | Prediction of metastases in the cervical lymph nodes | AUC: 0.806 (1% labeled)
    |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 口腔鳞状细胞癌 |  | LNM-OSCC 数据集 | 217 玻片 | 内部数据 |  | 颈部淋巴结转移预测 | AUC: 0.806
    (1% 标注) |'
- en: '|  |  | Colorectal Cancer |  | Kather multiclass dataset | 100K patches | Kather
    *et al.* ([2019](#bib.bib84)) |  | Classification of tissue types | AUC: 0.903
    (1%labeled) |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '|  |  | 结直肠癌 |  | Kather 多类别数据集 | 100K 片段 | Kather *等人* ([2019](#bib.bib84))
    |  | 组织类型分类 | AUC: 0.903 (1% 标注) |'
- en: '| Srinidhi et al. ([2022](#bib.bib160)) | Application | Breast Cancer, Colorectal
    Cancer | H&E | BreastPathQ dataset | 2579 patches | Martel et al. ([2019](#bib.bib111))
    | Resolution sequence prediction | Detection of tumor metastasis | TC: 0.876 (10%
    labels) |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| Srinidhi 等人 ([2022](#bib.bib160)) | 应用 | 乳腺癌, 结直肠癌 | H&E | BreastPathQ 数据集
    | 2579 片段 | Martel 等人 ([2019](#bib.bib111)) | 分辨率序列预测 | 肿瘤转移检测 | TC: 0.876 (10%
    标注) |'
- en: '|  |  |  |  | Camelyon16 dataset | 399 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | Classification of tissue types | AUC: 0.855 (10% labels) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | Camelyon16 数据集 | 399 WSIs | [https://camelyon16.grand-challenge.org/Data/](https://camelyon16.grand-challenge.org/Data/)
    |  | 组织类型分类 | AUC: 0.855 (10% 标注) |'
- en: '|  |  |  |  | Kather multiclass dataset | 100K patches | Kather *et al.* ([2019](#bib.bib84))
    |  | Quantification of tumor cellularity | ACC: 0.982 (10% labels) |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | Kather 多类别数据集 | 100K 片段 | Kather *等人* ([2019](#bib.bib84)) |  |
    肿瘤细胞密度定量 | ACC: 0.982 (10% 标注) |'
- en: '| Zheng et al. ([2019](#bib.bib207)) | Application | Colon Cancer | H&E | MICCAI
    2015 Gland Segmentation Challenge (GlaS) dataset | 165 images | Sirinukunwattana
    et al. ([2017](#bib.bib154)) | Variational Auto Encoder (VAE) | Active learning
    in biomedical image segmentation | F1 score: 0.909, 0.9252 (30% labeled) |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| Zheng 等人 ([2019](#bib.bib207)) | 应用 | 结肠癌 | H&E | MICCAI 2015 腺体分割挑战（GlaS）数据集
    | 165 张图像 | Sirinukunwattana 等人 ([2017](#bib.bib154)) | 变分自编码器（VAE） | 生物医学图像分割中的主动学习
    | F1 分数: 0.909, 0.9252 (30% 标注) |'
- en: '|  |  |  |  | Fungus dataset | 84 images | Zhang et al. ([2017](#bib.bib205))
    |  |  |  |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  |  | 真菌数据集 | 84 张图像 | Zhang 等人 ([2017](#bib.bib205)) |  |  |  |'
- en: 4 Discussion and Future Trends
  id: totrans-296
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 讨论与未来趋势
- en: 4.1 For Weakly Supervised Learning Paradigm
  id: totrans-297
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 对于弱监督学习范式
- en: The two main goals of WSI analysis using the weakly supervised learning paradigm
    are global slide classification, which aims to accurately predict the labels of
    each WSI, and positive patch localization, which aims to accurately predict the
    labels of each positive patch in the positive bags. Among above two tasks, the
    former can be used for rapid automatic diagnosis of clinical pathology slides,
    such as early clinical screening, and the latter can be used for precise localization
    of tumor cells, as well as interpretable analysis of clinical diagnosis by deep
    learning networks. Based on the diagnostic results obtained from the whole slides,
    pathologists are often more interested in the precise location of tumor cells,
    the cell morphology and other microstructures for further analysis and corroboration.
    On the other hand, pathologists also expect new knowledge from the diagnosis of
    the deep neural networks, such as discovering new pathological patterns and structures,
    etc. A few current algorithms can perform the task of global slide classification
    well, but the task of positive patch localization is another challenge for most
    algorithms. A primary reason is that the loss functions of most bag-based deep
    MIL algorithms are defined only at the bag-level, and although mechanisms such
    as attention (Ilse *et al.* [2018](#bib.bib77)) can be used to measure the contribution
    of each instance to the bag-level classification, the network does not have enough
    motivation to classify all instances accurately (Shi *et al.* [2020](#bib.bib151),
    Qu *et al.* [2022](#bib.bib129)). On the other hand, instance-based methods and
    hybrid methods, although defining instance-level classifiers, usually face a high
    risk of errors in pseudo-labeling or key instance selection. Therefore, it is
    a new challenge for the weakly supervised learning paradigm to further improve
    the ability to classify instances while obtaining a better slide-level diagnosis.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 使用弱监督学习范式进行WSI分析的两个主要目标是全球幻灯片分类，其目的是准确预测每个WSI的标签，以及正样本补丁定位，其目的是准确预测正样本包中每个正样本补丁的标签。在这两个任务中，前者可以用于临床病理幻灯片的快速自动诊断，例如早期临床筛查，而后者可以用于精确定位肿瘤细胞，以及通过深度学习网络进行可解释的临床诊断分析。基于从整个幻灯片中获得的诊断结果，病理学家通常对肿瘤细胞的精确位置、细胞形态及其他微观结构进行进一步分析和确认更加感兴趣。另一方面，病理学家也期望从深度神经网络的诊断中获得新知识，例如发现新的病理模式和结构等。目前一些算法可以很好地执行全球幻灯片分类任务，但正样本补丁定位任务对于大多数算法来说仍然是另一个挑战。主要原因是大多数基于袋的深度MIL算法的损失函数仅在袋级别定义，尽管可以使用注意力等机制（Ilse
    *et al.* [2018](#bib.bib77)）来测量每个实例对袋级别分类的贡献，但网络没有足够的动力来准确分类所有实例（Shi *et al.*
    [2020](#bib.bib151)，Qu *et al.* [2022](#bib.bib129)）。另一方面，基于实例的方法和混合方法虽然定义了实例级分类器，但通常面临伪标签或关键实例选择的高错误风险。因此，在获得更好的幻灯片级诊断的同时，进一步提高分类实例的能力是弱监督学习范式面临的新挑战。
- en: Further, with the emergence of the methods of the weakly supervised segmentation
    in the natural image processing field (Ru *et al.* [2022](#bib.bib140), Xu *et
    al.* [2022](#bib.bib195), Pan *et al.* [2022](#bib.bib122), Lee *et al.* [2021](#bib.bib95),
    Chen *et al.* [2022](#bib.bib29)), a new challenging direction for WSI analysis
    is to perform pixel-level semantic segmentation of the entire WSI based on weak
    or sparse labels. The task of the positive patch localization, which described
    in the previous section is still based on the classification of patches, and it
    is a more challenging task to further obtain pixel-level segmentation results
    based on the weak labels. A few current studies (Xu *et al.* [2019](#bib.bib192),
    Qu *et al.* [2020](#bib.bib128), Belharbi *et al.* [2021](#bib.bib11), Lerousseau
    *et al.* [2020](#bib.bib96)) have made attempts in this new direction, but they
    still face many problems such as lack of details and precision on the segmentation
    results. Overall, for the weakly supervised learning paradigm, how to obtain the
    most detailed segmentation results as possible with weak labels is another promising
    study direction.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，随着自然图像处理领域中弱监督分割方法的出现（Ru *et al.* [2022](#bib.bib140)，Xu *et al.* [2022](#bib.bib195)，Pan
    *et al.* [2022](#bib.bib122)，Lee *et al.* [2021](#bib.bib95)，Chen *et al.* [2022](#bib.bib29)），WSI分析的新挑战方向是基于弱或稀疏标签对整个WSI进行像素级语义分割。上一节描述的正样本补丁定位仍然基于补丁分类，而基于弱标签进一步获得像素级分割结果是一个更具挑战性的任务。一些当前研究（Xu
    *et al.* [2019](#bib.bib192)，Qu *et al.* [2020](#bib.bib128)，Belharbi *et al.* [2021](#bib.bib11)，Lerousseau
    *et al.* [2020](#bib.bib96)）在这个新方向上做出了尝试，但仍面临诸如分割结果缺乏细节和精度等许多问题。总体而言，对于弱监督学习范式，如何利用弱标签获得尽可能详细的分割结果是另一个有前途的研究方向。
- en: Another urgent need is the publicly available WSI datasets with fine-grained
    annotations at the patch level. As we all know, the scarcity of the publicly available
    pathological image datasets is an important factor hindering the development of
    the field. In recent years, we are grateful for the support of large public pathology
    datasets such as TCGA ([2019](#bib.bib168)), but public pathology datasets with
    fine-grained annotations are still in short supply for deeper research. To our
    knowledge, the large public WSI dataset with detailed annotation at the patch
    level is merely CAMELYON (Bejnordi *et al.* [2017a](#bib.bib9)). We should encourage
    an individual or organization to provide more public WSI datasets with detailed
    patch-level annotations to promote the development of this study field.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个迫切需要的是公开的具有细粒度注释的WSI数据集。众所周知，公开的病理图像数据集稀缺是制约该领域发展的重要因素。近年来，我们感谢TCGA等大型公开病理数据集的支持（[2019](#bib.bib168)），但仍然缺乏具有细粒度注释的公开病理数据集以进行更深入的研究。据我们了解，具有详细注释的大型公开WSI数据集仅有CAMELYON（Bejnordi
    *et al.* [2017a](#bib.bib9)）。我们应鼓励个人或组织提供更多具有详细补丁级别注释的公开WSI数据集，以促进该研究领域的发展。
- en: 4.2 For Semi-Supervised Learning Paradigm
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 对于半监督学习范式
- en: For semi-supervised learning paradigm, a new study direction is the combination
    with active learning, the purpose of which is to use the most effective labeled
    data to obtain the highest performance. Active learning aims to find the most
    valuable samples in the unlabeled dataset to be annotated through iterative interactions
    with experts, which allows to further exploit the effects of semi-supervised learning.
    There are already a lot of studies on pathological image analysis with the help
    of active learning (Zheng *et al.* [2019](#bib.bib207), Yang *et al.* [2017](#bib.bib199))
    or combination with semi-supervised learning and active learning (Su *et al.* [2015](#bib.bib163),
    Parag *et al.* [2014](#bib.bib123)).
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 对于半监督学习范式，一个新的研究方向是与主动学习的结合，其目的是利用最有效的标记数据获得最高的性能。主动学习旨在通过与专家的迭代互动，找到未标记数据集中最有价值的样本进行标注，这进一步发挥了半监督学习的效果。已经有很多研究利用主动学习进行病理图像分析（Zheng
    *et al.* [2019](#bib.bib207)，Yang *et al.* [2017](#bib.bib199)）或将半监督学习与主动学习结合（Su
    *et al.* [2015](#bib.bib163)，Parag *et al.* [2014](#bib.bib123)）。
- en: Another challenge is the effect that noisy data and domain variation have on
    the performance of semi-supervised learning algorithms. In the field of computational
    pathology, noisy annotations are very common, because the instance features of
    pathological images are very complex and variable, and their sizes are so huge
    that doctors are likely to suffer from missing and mislabeling during annotation.
    When performing multicenter validation, significant staining variation between
    the slides from different centers is also very common as there is no uniform standard
    for staining pathological images among different centers. Both the noisy labels
    and the domain variation are powerful factors that affect the performance of semi-supervised
    learning in real-world scenarios. Recent studies (Koohbanani *et al.* [2021](#bib.bib89),
    Cheng *et al.* [2020](#bib.bib31), Shi *et al.* [2020](#bib.bib150), Foucart *et
    al.* [2019](#bib.bib57), Marini *et al.* [2021](#bib.bib109)) have made efforts
    on these two problems, and more studies in this field are expected.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个挑战是噪声数据和领域变化对半监督学习算法性能的影响。在计算病理领域，噪声标注非常普遍，因为病理图像的实例特征非常复杂且多变，其尺寸庞大，医生在标注过程中容易出现遗漏和错误标注。在进行多中心验证时，不同中心之间的切片染色变化也非常常见，因为不同中心没有统一的病理图像染色标准。噪声标签和领域变化都是影响现实世界场景中半监督学习性能的重要因素。近期的研究（Koohbanani
    *等* [2021](#bib.bib89)，Cheng *等* [2020](#bib.bib31)，Shi *等* [2020](#bib.bib150)，Foucart
    *等* [2019](#bib.bib57)，Marini *等* [2021](#bib.bib109)）已经对这两个问题进行了研究，未来对此领域的更多研究值得期待。
- en: 4.3 For Self-Supervised Learning Paradigm
  id: totrans-304
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 自监督学习范式
- en: For self-supervised learning paradigm, although current relevant studies in
    the field of natural images are developing rapidly, the direct applications of
    these methods to pathological images will be hindered by the strong domain discrepancy
    (Ciga *et al.* [2022](#bib.bib36), Koohbanani *et al.* [2021](#bib.bib89)). Therefore,
    how to design more effective self-supervised auxiliary tasks for pathological
    images is a promising direction.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 对于自监督学习范式，尽管当前在自然图像领域的相关研究发展迅速，但这些方法直接应用于病理图像将受到强烈领域差异的阻碍（Ciga *等* [2022](#bib.bib36)，Koohbanani
    *等* [2021](#bib.bib89)）。因此，如何为病理图像设计更有效的自监督辅助任务是一个有前景的方向。
- en: On the other hand, self-supervised learning has been promoting the development
    of weakly supervised learning and semi-supervised learning in pathological image
    analysis. As we all know, it is difficult for a network to learn effective feature
    representations with very limited annotations. In contrast, self-supervised learning
    is very suitable for learning effective feature representations from a lot of
    unlabeled data. Therefore, it will be a popular way to combine the features extracted
    by self-supervised pre-training with the weakly supervised or semi-supervised
    downstream tasks in the future. On the one hand, the efficient feature representations
    obtained from self-supervised pre-training will greatly improve the efficiency
    of weakly supervised learning and semi-supervised learning, and on the other hand,
    weakly supervised learning or semi-supervised learning will fully release the
    new potential of self-supervised learning in the field of computational pathology.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，自监督学习正在推动病理图像分析中弱监督学习和半监督学习的发展。众所周知，网络很难在非常有限的标注下学习有效的特征表示。相比之下，自监督学习非常适合从大量未标记的数据中学习有效的特征表示。因此，将自监督预训练提取的特征与弱监督或半监督下游任务结合起来，将是未来的一种热门方式。一方面，自监督预训练获得的高效特征表示将大大提高弱监督学习和半监督学习的效率，另一方面，弱监督学习或半监督学习将充分释放自监督学习在计算病理领域的新潜力。
- en: 4.4 Limitations
  id: totrans-307
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 限制
- en: This review also has several limitations. First, due to space limitations, this
    review does not include more clinical studies. We focus more on top technical
    conferences and journals and do not include more excellent papers published in
    clinical journals. For more systematic reviews of clinical studies, see (Cifci
    *et al.* [2022](#bib.bib35)) and (Kleppe *et al.* [2021](#bib.bib88)) for details.
    In addition, since there are so many technical studies on artificial intelligence
    applied to computational pathology, it is difficult to summarize them all, and
    due to space limitations, we have tried to include as many recent articles as
    possible, while some of them have not been included.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述也存在若干局限性。首先，由于篇幅限制，本综述未包括更多的临床研究。我们更多关注顶级技术会议和期刊，而未纳入更多在临床期刊上发表的优秀论文。有关临床研究的更系统综述，请参见(Cifci
    *et al.* [2022](#bib.bib35))和(Kleppe *et al.* [2021](#bib.bib88))。此外，由于人工智能应用于计算病理学的技术研究众多，难以一一总结，且由于篇幅限制，我们尽力包含了尽可能多的最新文章，部分文章未被纳入。
- en: 5 Conclusion
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 结论
- en: In this review, we provide a systematic summary of recent studies on weakly
    supervised learning, semi-supervised learning, and self-supervised learning in
    the field of computational pathology from the theoretical and methodological perspectives.
    On this basis, we also present targeted solutions to some current difficulties
    and shortcomings in this field, and illustrate its future trends. Through a survey
    of over 130 papers, we find that the field of computational pathology is marching
    at high speed into a new era, which is automatic diagnosis and analysis with fewer
    annotation needs, wider application scope, and higher prediction accuracy.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中，我们从理论和方法论的角度系统总结了最近在计算病理学领域的弱监督学习、半监督学习和自监督学习的研究。在此基础上，我们还提出了一些针对当前领域困难和不足的解决方案，并阐述了其未来趋势。通过对超过130篇论文的调查，我们发现计算病理学领域正以高速迈入一个新时代，即自动诊断和分析，需求的标注更少，应用范围更广，预测准确度更高。
- en: Acknowledgments
  id: totrans-311
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This work was supported by National Natural Science Foundation of China under
    Grant 82072021.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作得到了中国国家自然科学基金（资助编号82072021）的支持。
- en: References
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Abbet et al. (2020) Abbet, C., Zlobec, I., Bozorgtabar, B. and Thiran, J.-P.
    (2020). Divide-and-rule: self-supervised learning for survival analysis in colorectal
    cancer, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 480–489.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abbet等（2020）Abbet, C., Zlobec, I., Bozorgtabar, B. 和 Thiran, J.-P.（2020）。分而治之：用于结直肠癌生存分析的自监督学习，《国际医学图像计算与计算机辅助干预会议》，Springer，第480–489页。
- en: Anand et al. (2021) Anand, D., Yashashwi, K., Kumar, N., Rane, S., Gann, P. H.
    and Sethi, A. (2021). Weakly supervised learning on unannotated h&e-stained slides
    predicts braf mutation in thyroid cancer with high accuracy, The Journal of Pathology  255(3): 232–242.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Anand等（2021）Anand, D., Yashashwi, K., Kumar, N., Rane, S., Gann, P. H. 和 Sethi,
    A.（2021）。在未标注的H&E染色切片上进行弱监督学习，以高准确度预测甲状腺癌中的BRAF突变，《The Journal of Pathology》255(3):
    232–242。'
- en: Araújo et al. (2017) Araújo, T., Aresta, G., Castro, E., Rouco, J., Aguiar,
    P., Eloy, C., Polónia, A. and Campilho, A. (2017). Classification of breast cancer
    histology images using convolutional neural networks, PloS One  12(6): e0177544.
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Araújo等（2017）Araújo, T., Aresta, G., Castro, E., Rouco, J., Aguiar, P., Eloy,
    C., Polónia, A. 和 Campilho, A.（2017）。使用卷积神经网络对乳腺癌组织学图像进行分类，《PloS One》12(6): e0177544。'
- en: 'Aresta et al. (2019) Aresta, G., Araújo, T., Kwok, S., Chennamsetty, S. S.,
    Safwan, M., Alex, V., Marami, B., Prastawa, M., Chan, M., Donovan, M. et al. (2019).
    Bach: Grand challenge on breast cancer histology images, Medical Image Analysis  56: 122–139.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Aresta等（2019）Aresta, G., Araújo, T., Kwok, S., Chennamsetty, S. S., Safwan,
    M., Alex, V., Marami, B., Prastawa, M., Chan, M., Donovan, M. 等（2019）。Bach：乳腺癌组织学图像大挑战，《医学图像分析》56:
    122–139。'
- en: 'Bao et al. (2021) Bao, H., Dong, L. and Wei, F. (2021). Beit: Bert pre-training
    of image transformers, arXiv preprint arXiv:2106.08254 .'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bao等（2021）Bao, H., Dong, L. 和 Wei, F.（2021）。Beit：图像变换器的Bert预训练，arXiv预印本arXiv:2106.08254。
- en: Basavanhally et al. (2013) Basavanhally, A., Ganesan, S., Feldman, M., Shih,
    N., Mies, C., Tomaszewski, J. and Madabhushi, A. (2013). Multi-field-of-view framework
    for distinguishing tumor grade in er+ breast cancer from entire histopathology
    slides, IEEE Transactions on Biomedical Engineering  60(8): 2089–2099.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Basavanhally等（2013）Basavanhally, A., Ganesan, S., Feldman, M., Shih, N., Mies,
    C., Tomaszewski, J. 和 Madabhushi, A.（2013）。用于区分ER+乳腺癌肿瘤等级的多视角框架，从整个组织病理切片中区分肿瘤等级，《IEEE生物医学工程学报》60(8):
    2089–2099。'
- en: Beck et al. (2011) Beck, A. H., Sangoi, A. R., Leung, S., Marinelli, R. J.,
    Nielsen, T. O., Van De Vijver, M. J., West, R. B., Van De Rijn, M. and Koller,
    D. (2011). Systematic analysis of breast cancer morphology uncovers stromal features
    associated with survival, Science Translational Medicine  3(108): 108ra113–108ra113.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Beck et al. (2011) Beck, A. H., Sangoi, A. R., Leung, S., Marinelli, R. J.,
    Nielsen, T. O., Van De Vijver, M. J., West, R. B., Van De Rijn, M. 和 Koller, D.
    (2011). 乳腺癌形态的系统分析揭示与生存相关的基质特征，《科学转化医学》 3(108): 108ra113–108ra113。'
- en: Bejnordi et al. (2017a) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q. F.,
    Balkenhol, M. et al. (2017a). Diagnostic assessment of deep learning algorithms
    for detection of lymph node metastases in women with breast cancer, Jama  318(22): 2199–2210.
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bejnordi et al. (2017a) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q.
    F., Balkenhol, M. 等 (2017a). 对乳腺癌女性淋巴结转移检测的深度学习算法的诊断评估，《Jama》 318(22): 2199–2210。'
- en: Bejnordi et al. (2017b) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q. F.,
    Balkenhol, M. et al. (2017b). Diagnostic assessment of deep learning algorithms
    for detection of lymph node metastases in women with breast cancer, JAMA  318(22): 2199–2210.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bejnordi et al. (2017b) Bejnordi, B. E., Veta, M., Van Diest, P. J., Van Ginneken,
    B., Karssemeijer, N., Litjens, G., Van Der Laak, J. A., Hermsen, M., Manson, Q.
    F., Balkenhol, M. 等 (2017b). 对乳腺癌女性淋巴结转移检测的深度学习算法的诊断评估，《JAMA》 318(22): 2199–2210。'
- en: Belharbi et al. (2021) Belharbi, S., Rony, J., Dolz, J., Ayed, I. B., McCaffrey,
    L. and Granger, E. (2021). Deep interpretable classification and weakly-supervised
    segmentation of histology images via max-min uncertainty, IEEE Transactions on
    Medical Imaging .
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Belharbi et al. (2021) Belharbi, S., Rony, J., Dolz, J., Ayed, I. B., McCaffrey,
    L. 和 Granger, E. (2021). 通过最大-最小不确定性进行深度可解释分类和弱监督分割《医学影像IEEE交易》。
- en: Belkin et al. (2005) Belkin, M., Niyogi, P. and Sindhwani, V. (2005). On manifold
    regularization, International Workshop on Artificial Intelligence and Statistics,
    PMLR, pp. 17–24.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Belkin et al. (2005) Belkin, M., Niyogi, P. 和 Sindhwani, V. (2005). 关于流形正则化，《人工智能与统计国际研讨会》，PMLR，第17–24页。
- en: 'Belkin et al. (2006) Belkin, M., Niyogi, P. and Sindhwani, V. (2006). Manifold
    regularization: A geometric framework for learning from labeled and unlabeled
    examples., Journal of Machine Learning Research  7(11).'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Belkin et al. (2006) Belkin, M., Niyogi, P. 和 Sindhwani, V. (2006). 流形正则化：从标记和未标记样本中学习的几何框架，《机器学习研究杂志》
    7(11)。
- en: Blum and Mitchell (1998) Blum, A. and Mitchell, T. (1998). Combining labeled
    and unlabeled data with co-training, Proceedings of the Eleventh Annual Conference
    on Computational Learning Theory, pp. 92–100.
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blum 和 Mitchell (1998) Blum, A. 和 Mitchell, T. (1998). 结合标记和未标记数据的共同训练，《第十一届计算学习理论年会论文集》，第92–100页。
- en: Boyd et al. (2021) Boyd, J., Liashuha, M., Deutsch, E., Paragios, N., Christodoulidis,
    S. and Vakalopoulou, M. (2021). Self-supervised representation learning using
    visual field expansion on digital pathology, Proceedings of the IEEE/CVF International
    Conference on Computer Vision, pp. 639–647.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boyd et al. (2021) Boyd, J., Liashuha, M., Deutsch, E., Paragios, N., Christodoulidis,
    S. 和 Vakalopoulou, M. (2021). 使用视觉领域扩展的自监督表示学习在数字病理学中的应用，《IEEE/CVF国际计算机视觉会议论文集》，第639–647页。
- en: 'Bulten et al. (2020) Bulten, W., Pinckaers, H., van Boven, H., Vink, R., de Bel,
    T., van Ginneken, B., van der Laak, J., Hulsbergen-van de Kaa, C. and Litjens,
    G. (2020). Automated deep-learning system for gleason grading of prostate cancer
    using biopsies: a diagnostic study, The Lancet Oncology  21(2): 233–241.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Bulten et al. (2020) Bulten, W., Pinckaers, H., van Boven, H., Vink, R., de
    Bel, T., van Ginneken, B., van der Laak, J., Hulsbergen-van de Kaa, C. 和 Litjens,
    G. (2020). 用于前列腺癌Gleason评分的自动深度学习系统：一项诊断研究，《柳叶刀肿瘤学》 21(2): 233–241。'
- en: Campanella et al. (2019) Campanella, G., Hanna, M. G., Geneslaw, L., Miraflor,
    A., Werneck Krauss Silva, V., Busam, K. J., Brogi, E., Reuter, V. E., Klimstra,
    D. S. and Fuchs, T. J. (2019). Clinical-grade computational pathology using weakly
    supervised deep learning on whole slide images, Nature Medicine  25(8): 1301–1309.
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Campanella et al. (2019) Campanella, G., Hanna, M. G., Geneslaw, L., Miraflor,
    A., Werneck Krauss Silva, V., Busam, K. J., Brogi, E., Reuter, V. E., Klimstra,
    D. S. 和 Fuchs, T. J. (2019). 使用弱监督深度学习的临床级计算病理学，《自然医学》 25(8): 1301–1309。'
- en: Caron et al. (2020) Caron, M., Misra, I., Mairal, J., Goyal, P., Bojanowski,
    P. and Joulin, A. (2020). Unsupervised learning of visual features by contrasting
    cluster assignments, Advances in Neural Information Processing Systems  33: 9912–9924.
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡隆等（2020）卡隆，米斯拉，马伊拉尔，戈亚尔，博扬诺夫斯基和朱利安（2020）。通过对比集群分配进行的视觉特征无监督学习，神经信息处理系统进展33：9912–9924。
- en: Caron et al. (2021) Caron, M., Touvron, H., Misra, I., Jégou, H., Mairal, J.,
    Bojanowski, P. and Joulin, A. (2021). Emerging properties in self-supervised vision
    transformers, Proceedings of the IEEE/CVF International Conference on Computer
    Vision, pp. 9650–9660.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 卡隆等（2021）卡隆，图弗龙，米斯拉，杰古，马伊拉尔，博扬诺夫斯基和朱利安（2021）。自监督视觉变换器中的新兴特性，IEEE/CVF国际计算机视觉会议论文集，第9650–9660页。
- en: 'Chang and Lin (2011) Chang, C.-C. and Lin, C.-J. (2011). Libsvm: a library
    for support vector machines, ACM Transactions on Intelligent Systems and Technology
    (TIST)  2(3): 1–27.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 张和林（2011）张志成和林志坚（2011）。Libsvm：支持向量机库，ACM智能系统与技术交易（TIST）2（3）：1–27。
- en: Chaudhary et al. (2018) Chaudhary, K., Poirion, O. B., Lu, L. and Garmire, L. X.
    (2018). Deep learning–based multi-omics integration robustly predicts survival
    in liver cancer, Clinical Cancer Research  24(6): 1248–1259.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 查乌达里等（2018）查乌达里，普瓦里昂，卢丽和加尔米尔（2018）。基于深度学习的多组学整合稳健预测肝癌生存，临床癌症研究24（6）：1248–1259。
- en: 'Chen et al. (2017) Chen, H., Qi, X., Yu, L., Dou, Q., Qin, J. and Heng, P.-A.
    (2017). Dcan: Deep contour-aware networks for object instance segmentation from
    histology images, Medical Image Analysis  36: 135–146.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2017）陈浩，齐鑫，余亮，窦庆，秦健和横鹏安（2017）。Dcan：用于组织学图像对象实例分割的深度轮廓感知网络，医学图像分析36：135–146。
- en: Chen et al. (2019) Chen, L., Bentley, P., Mori, K., Misawa, K., Fujiwara, M.
    and Rueckert, D. (2019). Self-supervised learning for medical image analysis using
    image context restoration, Medical Image Analysis  58: 101539.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2019）陈立，彭利，森本，三泽佳和藤原美（2019）。用于医学图像分析的自监督学习，通过图像上下文恢复，医学图像分析58：101539。
- en: Chen and Krishnan (2022) Chen, R. J. and Krishnan, R. G. (2022). Self-supervised
    vision transformers learn visual concepts in histopathology, arXiv preprint arXiv:2203.00585
    .
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈和克里希南（2022）陈瑞杰和克里希南拉维（2022）。自监督视觉变换器在组织病理学中的视觉概念学习，arXiv预印本arXiv:2203.00585。
- en: 'Chen, Lu and Mahmood (2020) Chen, R. J., Lu, N. I. and Mahmood, F. (2020).
    Pathomic fusion: an integrated framework for fusing histopathology and genomic
    features for cancer diagnosis and prognosis, IEEE Transactions on Medical Imaging
    .'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈，卢和马哈茂德（2020）陈瑞杰，卢宁和马哈茂德（2020）。病理组学融合：用于癌症诊断和预后的组织病理学和基因组特征融合的集成框架，IEEE医学成像事务。
- en: Chen, Kornblith, Norouzi and Hinton (2020) Chen, T., Kornblith, S., Norouzi,
    M. and Hinton, G. (2020). A simple framework for contrastive learning of visual
    representations, International Conference on Machine Learning, PMLR, pp. 1597–1607.
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈，科恩布利斯，诺鲁兹和辛顿（2020）陈天，科恩布利斯，诺鲁兹和辛顿（2020）。视觉表征对比学习的简单框架，国际机器学习会议，PMLR，第1597–1607页。
- en: Chen, Fan, Girshick and He (2020) Chen, X., Fan, H., Girshick, R. and He, K.
    (2020). Improved baselines with momentum contrastive learning, arXiv preprint
    arXiv:2003.04297 .
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈，范，吉尔希克和何（2020）陈轩，范浩，吉尔希克瑞和何凯（2020）。基于动量对比学习的改进基线，arXiv预印本arXiv:2003.04297。
- en: Chen and He (2021) Chen, X. and He, K. (2021). Exploring simple siamese representation
    learning, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 15750–15758.
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈和何（2021）陈轩和何凯（2021）。探索简单的孪生表示学习，IEEE/CVF计算机视觉与模式识别会议论文集，第15750–15758页。
- en: Chen et al. (2022) Chen, Z., Wang, T., Wu, X., Hua, X.-S., Zhang, H. and Sun,
    Q. (2022). Class re-activation maps for weakly-supervised semantic segmentation,
    arXiv preprint arXiv:2203.00962 .
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2022）陈子，王腾，吴翔，华晓晟，张宏和孙强（2022）。用于弱监督语义分割的类别重激活图，arXiv预印本arXiv:2203.00962。
- en: 'Chen et al. (2021) Chen, Z., Zhang, J., Che, S., Huang, J., Han, X. and Yuan,
    Y. (2021). Diagnose like a pathologist: Weakly-supervised pathologist-tree network
    for slide-level immunohistochemical scoring, 35th AAAI Conference on Artificial
    Intelligence (AAAI-21), AAAI Press, pp. 47–54.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2021）陈子，张杰，车舒，黄俊，韩晓和袁阳（2021）。像病理学家一样诊断：用于滑片级免疫组织化学评分的弱监督病理学家树网络，第35届AAAI人工智能会议（AAAI-21），AAAI出版社，第47–54页。
- en: Cheng et al. (2020) Cheng, H.-T., Yeh, C.-F., Kuo, P.-C., Wei, A., Liu, K.-C.,
    Ko, M.-C., Chao, K.-H., Peng, Y.-C. and Liu, T.-L. (2020). Self-similarity student
    for partial label histopathology image segmentation, European Conference on Computer
    Vision, Springer, pp. 117–132.
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等人 (2020) Cheng, H.-T., Yeh, C.-F., Kuo, P.-C., Wei, A., Liu, K.-C., Ko,
    M.-C., Chao, K.-H., Peng, Y.-C. 和 Liu, T.-L. (2020)。用于部分标签组织病理图像分割的自相似学生，欧洲计算机视觉会议，Springer，第117–132页。
- en: 'Chhipa et al. (2022) Chhipa, P. C., Upadhyay, R., Pihlgren, G. G., Saini, R.,
    Uchida, S. and Liwicki, M. (2022). Magnification prior: A self-supervised method
    for learning representations on breast cancer histopathological images, arXiv
    preprint arXiv:2203.07707 .'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chhipa 等人 (2022) Chhipa, P. C., Upadhyay, R., Pihlgren, G. G., Saini, R., Uchida,
    S. 和 Liwicki, M. (2022)。放大先验：用于学习乳腺癌组织病理图像表示的自监督方法，arXiv 预印本 arXiv:2203.07707。
- en: Chikontwe et al. (2020) Chikontwe, P., Kim, M., Nam, S. J., Go, H. and Park,
    S. H. (2020). Multiple instance learning with center embeddings for histopathology
    classification, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 519–528.
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chikontwe 等人 (2020) Chikontwe, P., Kim, M., Nam, S. J., Go, H. 和 Park, S. H.
    (2020)。基于中心嵌入的多实例学习用于组织病理学分类，医学图像计算与计算机辅助手术国际会议，Springer，第519–528页。
- en: 'Chong et al. (2020) Chong, Y., Ding, Y., Yan, Q. and Pan, S. (2020). Graph-based
    semi-supervised learning: A review, Neurocomputing  408: 216–230.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chong 等人 (2020) Chong, Y., Ding, Y., Yan, Q. 和 Pan, S. (2020)。基于图的半监督学习：综述，神经计算
    408: 216–230。'
- en: Cifci et al. (2022) Cifci, D., Foersch, S. and Kather, J. N. (2022). Artificial
    intelligence to identify genetic alterations in conventional histopathology, The
    Journal of Pathology .
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cifci 等人 (2022) Cifci, D., Foersch, S. 和 Kather, J. N. (2022)。人工智能识别常规组织病理学中的遗传变异，《病理学杂志》。
- en: Ciga et al. (2022) Ciga, O., Xu, T. and Martel, A. L. (2022). Self supervised
    contrastive learning for digital histopathology, Machine Learning with Applications  7: 100198.
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ciga 等人 (2022) Ciga, O., Xu, T. 和 Martel, A. L. (2022)。用于数字组织病理学的自监督对比学习，机器学习应用
    7: 100198。'
- en: 'Clark et al. (2013) Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J.,
    Koppel, P., Moore, S., Phillips, S., Maffitt, D., Pringle, M. et al. (2013). The
    cancer imaging archive (tcia): maintaining and operating a public information
    repository, Journal of Digital Imaging  26(6): 1045–1057.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Clark 等人 (2013) Clark, K., Vendt, B., Smith, K., Freymann, J., Kirby, J., Koppel,
    P., Moore, S., Phillips, S., Maffitt, D., Pringle, M. 等 (2013)。癌症影像档案（tcia）：维护和运营公共信息库，数字成像杂志
    26(6): 1045–1057。'
- en: Cong et al. (2021) Cong, C., Liu, S., Ieva, A. D., Pagnucco, M., Berkovsky,
    S. and Song, Y. (2021). Semi-supervised adversarial learning for stain normalisation
    in histopathology images, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 581–591.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cong 等人 (2021) Cong, C., Liu, S., Ieva, A. D., Pagnucco, M., Berkovsky, S. 和
    Song, Y. (2021)。用于组织病理图像染色标准化的半监督对抗学习，医学图像计算与计算机辅助手术国际会议，Springer，第581–591页。
- en: Coudray et al. (2018) Coudray, N., Ocampo, P. S., Sakellaropoulos, T., Narula,
    N., Snuderl, M., Fenyö, D., Moreira, A. L., Razavian, N. and Tsirigos, A. (2018).
    Classification and mutation prediction from non–small cell lung cancer histopathology
    images using deep learning, Nature Medicine  24(10): 1559–1567.
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Coudray 等人 (2018) Coudray, N., Ocampo, P. S., Sakellaropoulos, T., Narula,
    N., Snuderl, M., Fenyö, D., Moreira, A. L., Razavian, N. 和 Tsirigos, A. (2018)。使用深度学习从非小细胞肺癌组织病理图像中进行分类和突变预测，Nature
    Medicine 24(10): 1559–1567。'
- en: 'Cruz-Roa et al. (2014) Cruz-Roa, A., Basavanhally, A., González, F., Gilmore,
    H., Feldman, M., Ganesan, S., Shih, N., Tomaszewski, J. and Madabhushi, A. (2014).
    Automatic detection of invasive ductal carcinoma in whole slide images with convolutional
    neural networks, Medical Imaging 2014: Digital Pathology, Vol. 9041, SPIE, p. 904103.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cruz-Roa 等人 (2014) Cruz-Roa, A., Basavanhally, A., González, F., Gilmore, H.,
    Feldman, M., Ganesan, S., Shih, N., Tomaszewski, J. 和 Madabhushi, A. (2014)。使用卷积神经网络自动检测全片图像中的侵袭性导管癌，医学成像2014：数字病理学，第9041卷，SPIE，第904103页。
- en: 'Cruz-Roa et al. (2017) Cruz-Roa, A., Gilmore, H., Basavanhally, A., Feldman,
    M., Ganesan, S., Shih, N. N., Tomaszewski, J., González, F. A. and Madabhushi,
    A. (2017). Accurate and reproducible invasive breast cancer detection in whole-slide
    images: a deep learning approach for quantifying tumor extent, Scientific Reports  7(1): 1–14.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Cruz-Roa 等人 (2017) Cruz-Roa, A., Gilmore, H., Basavanhally, A., Feldman, M.,
    Ganesan, S., Shih, N. N., Tomaszewski, J., González, F. A. 和 Madabhushi, A. (2017)。全片图像中侵袭性乳腺癌的准确和可重复检测：一种用于量化肿瘤范围的深度学习方法，Scientific
    Reports 7(1): 1–14。'
- en: Dai et al. (2017) Dai, Z., Yang, Z., Yang, F., Cohen, W. W. and Salakhutdinov,
    R. R. (2017). Good semi-supervised learning that requires a bad gan, Advances
    in Neural Information Processing Systems  30.
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dai等（2017）Dai, Z., Yang, Z., Yang, F., Cohen, W. W. 和Salakhutdinov, R. R.（2017）。需要一个糟糕的GAN的良好半监督学习，《神经信息处理系统进展》30。
- en: Dara et al. (2002) Dara, R., Kremer, S. C. and Stacey, D. A. (2002). Clustering
    unlabeled data with soms improves classification of labeled real-world data, Proceedings
    of the 2002 International Joint Conference on Neural Networks. IJCNN’02 (Cat.
    No. 02CH37290), Vol. 3, IEEE, pp. 2237–2242.
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dara等（2002）Dara, R., Kremer, S. C. 和Stacey, D. A.（2002）。使用SOMs对未标记数据进行聚类改善标记真实数据的分类，2002年国际神经网络联合会议论文集。IJCNN’02（Cat.
    No. 02CH37290），第3卷，IEEE，第2237–2242页。
- en: 'Decencière et al. (2014) Decencière, E., Zhang, X., Cazuguel, G., Lay, B.,
    Cochener, B., Trone, C., Gain, P., Ordonez, R., Massin, P., Erginay, A. et al.
    (2014). Feedback on a publicly distributed image database: the messidor database,
    Image Analysis & Stereology  33(3): 231–234.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Decencière等（2014）Decencière, E., Zhang, X., Cazuguel, G., Lay, B., Cochener,
    B., Trone, C., Gain, P., Ordonez, R., Massin, P., Erginay, A. 等（2014）。对公开分发的图像数据库的反馈：Messidor数据库，图像分析与立体视觉
    33(3)：231–234。
- en: Dehaene et al. (2020) Dehaene, O., Camara, A., Moindrot, O., de Lavergne, A.
    and Courtiol, P. (2020). Self-supervision closes the gap between weak and strong
    supervision in histology, arXiv preprint arXiv:2012.03583 .
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dehaene等（2020）Dehaene, O., Camara, A., Moindrot, O., de Lavergne, A. 和Courtiol,
    P.（2020）。自监督缩小了组织学中弱监督和强监督之间的差距，arXiv预印本arXiv:2012.03583。
- en: Demiriz et al. (1999) Demiriz, A., Bennett, K. P. and Embrechts, M. J. (1999).
    Semi-supervised clustering using genetic algorithms, Artificial Neural Networks
    in Engineering (ANNIE-99) pp. 809–814.
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Demiriz等（1999）Demiriz, A., Bennett, K. P. 和Embrechts, M. J.（1999）。使用遗传算法的半监督聚类，人工神经网络工程（ANNIE-99）第809–814页。
- en: 'Deng et al. (2009) Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K. and Fei-Fei,
    L. (2009). Imagenet: A large-scale hierarchical image database, 2009 IEEE Conference
    on Computer Vision and Pattern Recognition, Ieee, pp. 248–255.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng等（2009）Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K. 和Fei-Fei, L.（2009）。ImageNet：大规模层次化图像数据库，2009年IEEE计算机视觉与模式识别会议，IEEE，第248–255页。
- en: Ding et al. (2020) Ding, K., Liu, Q., Lee, E., Zhou, M., Lu, A. and Zhang, S.
    (2020). Feature-enhanced graph networks for genetic mutational prediction using
    histopathological images in colon cancer, International Conference on Medical
    Image Computing and Computer-Assisted Intervention, Springer, pp. 294–304.
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding等（2020）Ding, K., Liu, Q., Lee, E., Zhou, M., Lu, A. 和Zhang, S.（2020）。用于结肠癌组织病理图像的遗传突变预测的特征增强图网络，医学图像计算与计算机辅助干预国际会议，Springer，第294–304页。
- en: Doersch et al. (2015) Doersch, C., Gupta, A. and Efros, A. A. (2015). Unsupervised
    visual representation learning by context prediction, Proceedings of the IEEE
    International Conference on Computer Vision, pp. 1422–1430.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doersch等（2015）Doersch, C., Gupta, A. 和Efros, A. A.（2015）。通过上下文预测进行无监督视觉表示学习，IEEE国际计算机视觉会议论文集，第1422–1430页。
- en: Donahue et al. (2016) Donahue, J., Krähenbühl, P. and Darrell, T. (2016). Adversarial
    feature learning, arXiv preprint arXiv:1605.09782 .
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Donahue等（2016）Donahue, J., Krähenbühl, P. 和Darrell, T.（2016）。对抗性特征学习，arXiv预印本arXiv:1605.09782。
- en: 'Dong et al. (2021) Dong, X., Bao, J., Zhang, T., Chen, D., Zhang, W., Yuan,
    L., Chen, D., Wen, F. and Yu, N. (2021). Peco: Perceptual codebook for bert pre-training
    of vision transformers, arXiv preprint arXiv:2111.12710 .'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong等（2021）Dong, X., Bao, J., Zhang, T., Chen, D., Zhang, W., Yuan, L., Chen,
    D., Wen, F. 和Yu, N.（2021）。PECO：用于BERT预训练视觉变换器的感知编码本，arXiv预印本arXiv:2111.12710。
- en: 'Doyle et al. (2007) Doyle, S., Hwang, M., Shah, K., Madabhushi, A., Feldman,
    M. and Tomaszeweski, J. (2007). Automated grading of prostate cancer using architectural
    and textural image features, 2007 4th IEEE International Symposium on Biomedical
    Imaging: From Nano to Macro, IEEE, pp. 1284–1287.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doyle等（2007）Doyle, S., Hwang, M., Shah, K., Madabhushi, A., Feldman, M. 和Tomaszeweski,
    J.（2007）。利用建筑学和纹理图像特征对前列腺癌进行自动评分，2007年第4届IEEE国际生物医学成像研讨会：从纳米到宏观，IEEE，第1284–1287页。
- en: Doyle et al. (2006) Doyle, S., Rodriguez, C., Madabhushi, A., Tomaszeweski,
    J. and Feldman, M. (2006). Detecting prostatic adenocarcinoma from digitized histology
    using a multi-scale hierarchical classification approach, 2006 International Conference
    of the IEEE Engineering in Medicine and Biology Society, IEEE, pp. 4759–4762.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doyle等（2006）Doyle, S., Rodriguez, C., Madabhushi, A., Tomaszeweski, J. 和Feldman,
    M.（2006）。使用多尺度分层分类方法从数字化组织学中检测前列腺腺癌，2006年IEEE医学与生物工程学会国际会议，IEEE，第4759–4762页。
- en: Ehteshami Bejnordi et al. (2018) Ehteshami Bejnordi, B., Mullooly, M., Pfeiffer,
    R. M., Fan, S., Vacek, P. M., Weaver, D. L., Herschorn, S., Brinton, L. A., van
    Ginneken, B., Karssemeijer, N. et al. (2018). Using deep convolutional neural
    networks to identify and classify tumor-associated stroma in diagnostic breast
    biopsies, Modern Pathology  31(10): 1502–1512.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ehteshami Bejnordi 等 (2018) Ehteshami Bejnordi, B., Mullooly, M., Pfeiffer,
    R. M., Fan, S., Vacek, P. M., Weaver, D. L., Herschorn, S., Brinton, L. A., van
    Ginneken, B., Karssemeijer, N. 等 (2018). 使用深度卷积神经网络识别和分类诊断乳腺活检中的肿瘤相关基质，现代病理学 31(10):
    1502–1512。'
- en: Erhan et al. (2010) Erhan, D., Courville, A., Bengio, Y. and Vincent, P. (2010).
    Why does unsupervised pre-training help deep learning?, Proceedings of the Thirteenth
    International Conference on Artificial Intelligence and Statistics, JMLR Workshop
    and Conference Proceedings, pp. 201–208.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Erhan 等 (2010) Erhan, D., Courville, A., Bengio, Y. 和 Vincent, P. (2010). 为什么无监督预训练有助于深度学习？，第十三届国际人工智能与统计会议论文集，JMLR研讨会和会议论文集，第201–208页。
- en: Feng and Zhou (2017) Feng, J. and Zhou, Z.-H. (2017). Deep miml network, Proceedings
    of the AAAI Conference on Artificial Intelligence, Vol. 31.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Feng 和 Zhou (2017) Feng, J. 和 Zhou, Z.-H. (2017). 深度MIML网络，第31届AAAI人工智能会议论文集，第31卷。
- en: 'Foucart et al. (2019) Foucart, A., Debeir, O. and Decaestecker, C. (2019).
    Snow: Semi-supervised, noisy and/or weak data for deep learning in digital pathology,
    2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019), IEEE,
    pp. 1869–1872.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Foucart 等 (2019) Foucart, A., Debeir, O. 和 Decaestecker, C. (2019). Snow: 用于数字病理学的半监督、噪声和/或弱数据的深度学习，2019年第16届IEEE生物医学成像国际研讨会
    (ISBI 2019)，IEEE，第1869–1872页。'
- en: Fu et al. (2020) Fu, Y., Jung, A. W., Torne, R. V., Gonzalez, S., Vöhringer,
    H., Shmatko, A., Yates, L. R., Jimenez-Linan, M., Moore, L. and Gerstung, M. (2020).
    Pan-cancer computational histopathology reveals mutations, tumor composition and
    prognosis, Nature Cancer  1(8): 800–810.
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu 等 (2020) Fu, Y., Jung, A. W., Torne, R. V., Gonzalez, S., Vöhringer, H.,
    Shmatko, A., Yates, L. R., Jimenez-Linan, M., Moore, L. 和 Gerstung, M. (2020).
    泛癌计算组织病理学揭示了突变、肿瘤组成和预后，自然癌症 1(8): 800–810。'
- en: Gelasca et al. (2008) Gelasca, E. D., Byun, J., Obara, B. and Manjunath, B.
    (2008). Evaluation and benchmark for biological image segmentation, 2008 15th
    IEEE International Conference on Image Processing, IEEE, pp. 1816–1819.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gelasca 等 (2008) Gelasca, E. D., Byun, J., Obara, B. 和 Manjunath, B. (2008).
    生物图像分割的评估和基准，2008年第15届IEEE国际图像处理会议，IEEE，第1816–1819页。
- en: Gertych et al. (2015) Gertych, A., Ing, N., Ma, Z., Fuchs, T. J., Salman, S.,
    Mohanty, S., Bhele, S., Velásquez-Vacca, A., Amin, M. B. and Knudsen, B. S. (2015).
    Machine learning approaches to analyze histological images of tissues from radical
    prostatectomies, Computerized Medical Imaging and Graphics  46: 197–208.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gertych 等 (2015) Gertych, A., Ing, N., Ma, Z., Fuchs, T. J., Salman, S., Mohanty,
    S., Bhele, S., Velásquez-Vacca, A., Amin, M. B. 和 Knudsen, B. S. (2015). 分析根治性前列腺切除术组织的组织学图像的机器学习方法，计算机化医学成像与图形
    46: 197–208。'
- en: Gidaris et al. (2018) Gidaris, S., Singh, P. and Komodakis, N. (2018). Unsupervised
    representation learning by predicting image rotations, arXiv preprint arXiv:1803.07728
    .
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gidaris 等 (2018) Gidaris, S., Singh, P. 和 Komodakis, N. (2018). 通过预测图像旋转进行无监督表示学习，arXiv预印本
    arXiv:1803.07728。
- en: Goldberg et al. (2009) Goldberg, A., Zhu, X., Singh, A., Xu, Z. and Nowak, R.
    (2009). Multi-manifold semi-supervised learning, Artificial Intelligence and Statistics,
    PMLR, pp. 169–176.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goldberg 等 (2009) Goldberg, A., Zhu, X., Singh, A., Xu, Z. 和 Nowak, R. (2009).
    多流形半监督学习，人工智能与统计，PMLR，第169–176页。
- en: 'Goodfellow (2016) Goodfellow, I. (2016). Nips 2016 tutorial: Generative adversarial
    networks, arXiv preprint arXiv:1701.00160 .'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow (2016) Goodfellow, I. (2016). Nips 2016教程：生成对抗网络，arXiv预印本 arXiv:1701.00160。
- en: Goodfellow et al. (2016) Goodfellow, I., Bengio, Y., Courville, A. and Bengio,
    Y. (2016). Deep learning, volume 1.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 (2016) Goodfellow, I., Bengio, Y., Courville, A. 和 Bengio, Y. (2016).
    深度学习，第1卷。
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A. and Bengio, Y. (2014). Generative adversarial
    nets, Advances in Neural Information Processing Systems  27.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A. 和 Bengio, Y. (2014). 生成对抗网络，神经信息处理系统进展 27。
- en: Grill et al. (2020) Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond,
    P., Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M.
    et al. (2020). Bootstrap your own latent-a new approach to self-supervised learning,
    Advances in Neural Information Processing Systems  33: 21271–21284.
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Grill等人（2020）Grill, J.-B., Strub, F., Altché, F., Tallec, C., Richemond, P.,
    Buchatskaya, E., Doersch, C., Avila Pires, B., Guo, Z., Gheshlaghi Azar, M.等（2020）。自举自己的潜在空间——一种新的自监督学习方法，*神经信息处理系统进展*
    33: 21271–21284。'
- en: Gu et al. (2018) Gu, F., Burlutskiy, N., Andersson, M. and Wilén, L. K. (2018).
    Multi-resolution networks for semantic segmentation in whole slide images, Computational
    Pathology and Ophthalmic Medical Image Analysis, Springer, pp. 11–18.
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gu等人（2018）Gu, F., Burlutskiy, N., Andersson, M. 和 Wilén, L. K.（2018）。用于全幻灯片图像的多分辨率网络进行语义分割，*计算病理学与眼科医学图像分析*，Springer，第11–18页。
- en: Guinney et al. (2015) Guinney, J., Dienstmann, R., Wang, X., De Reynies, A.,
    Schlicker, A., Soneson, C., Marisa, L., Roepman, P., Nyamundanda, G., Angelino,
    P. et al. (2015). The consensus molecular subtypes of colorectal cancer, Nature
    Medicine  21(11): 1350–1356.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guinney等人（2015）Guinney, J., Dienstmann, R., Wang, X., De Reynies, A., Schlicker,
    A., Soneson, C., Marisa, L., Roepman, P., Nyamundanda, G., Angelino, P. 等（2015）。结直肠癌的共识分子亚型，*自然医学*
    21(11): 1350–1356。'
- en: 'Gurcan et al. (2009) Gurcan, M. N., Boucheron, L. E., Can, A., Madabhushi,
    A., Rajpoot, N. M. and Yener, B. (2009). Histopathological image analysis: A review,
    IEEE Reviews in Biomedical Engineering  2: 147–171.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gurcan等人（2009）Gurcan, M. N., Boucheron, L. E., Can, A., Madabhushi, A., Rajpoot,
    N. M. 和 Yener, B.（2009）。组织病理图像分析：综述，*IEEE生物医学工程评论* 2: 147–171。'
- en: Haeusser et al. (2017) Haeusser, P., Mordvintsev, A. and Cremers, D. (2017).
    Learning by association–a versatile semi-supervised training method for neural
    networks, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pp. 89–98.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haeusser等人（2017）Haeusser, P., Mordvintsev, A. 和 Cremers, D.（2017）。通过关联学习——一种通用的半监督神经网络训练方法，*IEEE计算机视觉与模式识别会议论文集*，第89–98页。
- en: Halicek et al. (2019) Halicek, M., Shahedi, M., Little, J. V., Chen, A. Y.,
    Myers, L. L., Sumer, B. D. and Fei, B. (2019). Head and neck cancer detection
    in digitized whole-slide histology using convolutional neural networks, Scientific
    Reports  9(1): 1–11.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Halicek等人（2019）Halicek, M., Shahedi, M., Little, J. V., Chen, A. Y., Myers,
    L. L., Sumer, B. D. 和 Fei, B.（2019）。使用卷积神经网络进行数字化全幻灯片组织学中的头颈癌检测，*科学报告* 9(1): 1–11。'
- en: Hashimoto et al. (2020) Hashimoto, N., Fukushima, D., Koga, R., Takagi, Y.,
    Ko, K., Kohno, K., Nakaguro, M., Nakamura, S., Hontani, H. and Takeuchi, I. (2020).
    Multi-scale domain-adversarial multiple-instance cnn for cancer subtype classification
    with unannotated histopathological images, Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 3852–3861.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hashimoto等人（2020）Hashimoto, N., Fukushima, D., Koga, R., Takagi, Y., Ko, K.,
    Kohno, K., Nakaguro, M., Nakamura, S., Hontani, H. 和 Takeuchi, I.（2020）。用于癌症亚型分类的多尺度领域对抗多实例CNN，*IEEE/CVF计算机视觉与模式识别会议论文集*，第3852–3861页。
- en: He et al. (2021) He, K., Chen, X., Xie, S., Li, Y., Dollár, P. and Girshick,
    R. (2021). Masked autoencoders are scalable vision learners, arXiv preprint arXiv:2111.06377
    .
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等人（2021）He, K., Chen, X., Xie, S., Li, Y., Dollár, P. 和 Girshick, R.（2021）。掩码自编码器是可扩展的视觉学习者，*arXiv预印本*
    arXiv:2111.06377。
- en: He et al. (2020) He, K., Fan, H., Wu, Y., Xie, S. and Girshick, R. (2020). Momentum
    contrast for unsupervised visual representation learning, Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, pp. 9729–9738.
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He等人（2020）He, K., Fan, H., Wu, Y., Xie, S. 和 Girshick, R.（2020）。动量对比用于无监督视觉表征学习，*IEEE/CVF计算机视觉与模式识别会议论文集*，第9729–9738页。
- en: Hou et al. (2019) Hou, L., Nguyen, V., Kanevsky, A. B., Samaras, D., Kurc, T. M.,
    Zhao, T., Gupta, R. R., Gao, Y., Chen, W., Foran, D. et al. (2019). Sparse autoencoder
    for unsupervised nucleus detection and representation in histopathology images,
    Pattern Recognition  86: 188–200.
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hou等人（2019）Hou, L., Nguyen, V., Kanevsky, A. B., Samaras, D., Kurc, T. M.,
    Zhao, T., Gupta, R. R., Gao, Y., Chen, W., Foran, D.等（2019）。用于无监督细胞核检测和表征的稀疏自编码器，*模式识别*
    86: 188–200。'
- en: Hou et al. (2016) Hou, L., Samaras, D., Kurc, T. M., Gao, Y., Davis, J. E. and Saltz,
    J. H. (2016). Patch-based convolutional neural network for whole slide tissue
    image classification, Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pp. 2424–2433.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hou等人（2016）Hou, L., Samaras, D., Kurc, T. M., Gao, Y., Davis, J. E. 和 Saltz,
    J. H.（2016）。基于块的卷积神经网络用于全幻灯片组织图像分类，*IEEE计算机视觉与模式识别会议论文集*，第2424–2433页。
- en: Ilse et al. (2018) Ilse, M., Tomczak, J. and Welling, M. (2018). Attention-based
    deep multiple instance learning, International Conference on Machine Learning,
    PMLR, pp. 2127–2136.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ilse 等（2018） Ilse, M., Tomczak, J. 和 Welling, M.（2018）。基于注意力的深度多实例学习，《机器学习国际会议》，PMLR，第
    2127–2136 页。
- en: Jafari-Khouzani and Soltanian-Zadeh (2003) Jafari-Khouzani, K. and Soltanian-Zadeh,
    H. (2003). Multiwavelet grading of pathological images of prostate, IEEE Transactions
    on Biomedical Engineering  50(6): 697–704.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jafari-Khouzani 和 Soltanian-Zadeh（2003） Jafari-Khouzani, K. 和 Soltanian-Zadeh,
    H.（2003）。前列腺病理图像的多小波分级，《IEEE 生物医学工程学报》 50(6): 697–704。'
- en: Jaiswal et al. (2019) Jaiswal, A. K., Panshin, I., Shulkin, D., Aneja, N. and Abramov,
    S. (2019). Semi-supervised learning for cancer detection of lymph node metastases,
    arXiv preprint arXiv:1906.09587 .
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaiswal 等（2019） Jaiswal, A. K., Panshin, I., Shulkin, D., Aneja, N. 和 Abramov,
    S.（2019）。用于癌症检测的半监督学习淋巴结转移，《arXiv 预印本 arXiv:1906.09587》。
- en: Kandemir et al. (2014) Kandemir, M., Zhang, C. and Hamprecht, F. A. (2014).
    Empowering multiple instance histopathology cancer diagnosis by cell graphs, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 228–235.
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kandemir 等（2014） Kandemir, M., Zhang, C. 和 Hamprecht, F. A.（2014）。通过细胞图提升多实例组织病理学癌症诊断，《医学图像计算与计算机辅助干预国际会议》，Springer，第
    228–235 页。
- en: Kandoth et al. (2013) Kandoth, C., McLellan, M. D., Vandin, F., Ye, K., Niu,
    B., Lu, C., Xie, M., Zhang, Q., McMichael, J. F., Wyczalkowski, M. A. et al. (2013).
    Mutational landscape and significance across 12 major cancer types, Nature  502(7471): 333–339.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kandoth 等（2013） Kandoth, C., McLellan, M. D., Vandin, F., Ye, K., Niu, B.,
    Lu, C., Xie, M., Zhang, Q., McMichael, J. F., Wyczalkowski, M. A. 等（2013）。12 种主要癌症类型的突变景观及其意义，《自然》
    502(7471): 333–339。'
- en: Kapil et al. (2018) Kapil, A., Meier, A., Zuraw, A., Steele, K. E., Rebelatto,
    M. C., Schmidt, G. and Brieu, N. (2018). Deep semi supervised generative learning
    for automated tumor proportion scoring on nsclc tissue needle biopsies, Scientific
    Reports  8(1): 1–10.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kapil 等（2018） Kapil, A., Meier, A., Zuraw, A., Steele, K. E., Rebelatto, M.
    C., Schmidt, G. 和 Brieu, N.（2018）。用于 nsclc 组织针刺活检的深度半监督生成学习自动肿瘤比例评分，《科学报告》 8(1):
    1–10。'
- en: Kather et al. (2020) Kather, J. N., Heij, L. R., Grabsch, H. I., Loeffler, C.,
    Echle, A., Muti, H. S., Krause, J., Niehues, J. M., Sommer, K. A., Bankhead, P.
    et al. (2020). Pan-cancer image-based detection of clinically actionable genetic
    alterations, Nature Cancer  1(8): 789–799.
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kather 等（2020） Kather, J. N., Heij, L. R., Grabsch, H. I., Loeffler, C., Echle,
    A., Muti, H. S., Krause, J., Niehues, J. M., Sommer, K. A., Bankhead, P. 等（2020）。基于图像的全癌种临床可操作基因变异检测，《自然癌症》
    1(8): 789–799。'
- en: 'Kather, Krisam, Charoentong, Luedde, Herpel, Weis, Gaiser, Marx, Valous, Ferber
    et al. (2019) Kather, J. N., Krisam, J., Charoentong, P., Luedde, T., Herpel,
    E., Weis, C.-A., Gaiser, T., Marx, A., Valous, N. A., Ferber, D. et al. (2019).
    Predicting survival from colorectal cancer histology slides using deep learning:
    A retrospective multicenter study, PLoS Medicine  16(1): e1002730.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kather, Krisam, Charoentong, Luedde, Herpel, Weis, Gaiser, Marx, Valous, Ferber
    等（2019） Kather, J. N., Krisam, J., Charoentong, P., Luedde, T., Herpel, E., Weis,
    C.-A., Gaiser, T., Marx, A., Valous, N. A., Ferber, D. 等（2019）。通过深度学习预测结直肠癌组织学切片的生存期：一项回顾性多中心研究，《PLoS
    医学》 16(1): e1002730。'
- en: Kather, Pearson, Halama, Jäger, Krause, Loosen, Marx, Boor, Tacke, Neumann et al.
    (2019) Kather, J. N., Pearson, A. T., Halama, N., Jäger, D., Krause, J., Loosen,
    S. H., Marx, A., Boor, P., Tacke, F., Neumann, U. P. et al. (2019). Deep learning
    can predict microsatellite instability directly from histology in gastrointestinal
    cancer, Nature Medicine  25(7): 1054–1056.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kather, Pearson, Halama, Jäger, Krause, Loosen, Marx, Boor, Tacke, Neumann
    等（2019） Kather, J. N., Pearson, A. T., Halama, N., Jäger, D., Krause, J., Loosen,
    S. H., Marx, A., Boor, P., Tacke, F., Neumann, U. P. 等（2019）。深度学习可以直接从胃肠癌的组织学中预测微卫星不稳定性，《自然医学》
    25(7): 1054–1056。'
- en: Kather et al. (2016) Kather, J. N., Weis, C.-A., Bianconi, F., Melchers, S. M.,
    Schad, L. R., Gaiser, T., Marx, A. and Zöllner, F. G. (2016). Multi-class texture
    analysis in colorectal cancer histology, Scientific Reports  6(1): 1–11.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kather 等（2016） Kather, J. N., Weis, C.-A., Bianconi, F., Melchers, S. M., Schad,
    L. R., Gaiser, T., Marx, A. 和 Zöllner, F. G.（2016）。结直肠癌组织学中的多类纹理分析，《科学报告》 6(1):
    1–11。'
- en: Kingma and Welling (2013) Kingma, D. P. and Welling, M. (2013). Auto-encoding
    variational bayes, arXiv preprint arXiv:1312.6114 .
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling（2013） Kingma, D. P. 和 Welling, M.（2013）。自编码变分贝叶斯，arXiv 预印本
    arXiv:1312.6114。
- en: Kleppe et al. (2021) Kleppe, A., Skrede, O.-J., De Raedt, S., Liestøl, K., Kerr,
    D. J. and Danielsen, H. E. (2021). Designing deep learning studies in cancer diagnostics,
    Nature Reviews Cancer  21(3): 199–211.
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kleppe 等（2021） Kleppe, A., Skrede, O.-J., De Raedt, S., Liestøl, K., Kerr,
    D. J. 和 Danielsen, H. E.（2021）。癌症诊断中的深度学习研究设计，《自然评论癌症》 21(3): 199–211。'
- en: 'Koohbanani et al. (2021) Koohbanani, N. A., Unnikrishnan, B., Khurram, S. A.,
    Krishnaswamy, P. and Rajpoot, N. (2021). Self-path: Self-supervision for classification
    of pathology images with limited annotations, IEEE Transactions on Medical Imaging  40(10): 2845–2856.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Koohbanani et al. (2021) Koohbanani, N. A., Unnikrishnan, B., Khurram, S. A.,
    Krishnaswamy, P. 和 Rajpoot, N. (2021). Self-path：有限注释的病理图像分类的自监督，《IEEE 医学成像汇刊》
    40(10): 2845–2856。'
- en: Kraus et al. (2016) Kraus, O. Z., Ba, J. L. and Frey, B. J. (2016). Classifying
    and segmenting microscopy images with deep multiple instance learning, Bioinformatics  32(12): i52–i59.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kraus et al. (2016) Kraus, O. Z., Ba, J. L. 和 Frey, B. J. (2016). 使用深度多实例学习进行显微镜图像的分类和分割，《生物信息学》
    32(12): i52–i59。'
- en: Kumar et al. (2017) Kumar, N., Verma, R., Sharma, S., Bhargava, S., Vahadane,
    A. and Sethi, A. (2017). A dataset and a technique for generalized nuclear segmentation
    for computational pathology, IEEE Transactions on Medical Imaging  36(7): 1550–1560.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kumar et al. (2017) Kumar, N., Verma, R., Sharma, S., Bhargava, S., Vahadane,
    A. 和 Sethi, A. (2017). 一种用于计算病理学的广义核分割的数据集和技术，《IEEE 医学成像汇刊》 36(7): 1550–1560。'
- en: Laine and Aila (2016) Laine, S. and Aila, T. (2016). Temporal ensembling for
    semi-supervised learning, arXiv preprint arXiv:1610.02242 .
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Laine 和 Aila (2016) Laine, S. 和 Aila, T. (2016). 半监督学习的时间集合，《arXiv 预印本 arXiv:1610.02242》。
- en: Larsen et al. (2016) Larsen, A. B. L., Sønderby, S. K., Larochelle, H. and Winther,
    O. (2016). Autoencoding beyond pixels using a learned similarity metric, International
    Conference on Machine Learning, PMLR, pp. 1558–1566.
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Larsen et al. (2016) Larsen, A. B. L., Sønderby, S. K., Larochelle, H. 和 Winther,
    O. (2016). 使用学习相似性度量的像素超编码，《机器学习国际会议》，PMLR，页码：1558–1566。
- en: 'Lee et al. (2013) Lee, D.-H. et al. (2013). Pseudo-label: The simple and efficient
    semi-supervised learning method for deep neural networks, Workshop on Challenges
    in Representation Learning, ICML, Vol. 3, p. 896.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2013) Lee, D.-H. et al. (2013). 伪标签：深度神经网络的简单高效半监督学习方法，《表示学习挑战研讨会》，ICML，卷
    3，页码：896。
- en: Lee et al. (2021) Lee, J., Kim, E. and Yoon, S. (2021). Anti-adversarially manipulated
    attributions for weakly and semi-supervised semantic segmentation, Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 4071–4080.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee et al. (2021) Lee, J., Kim, E. 和 Yoon, S. (2021). 针对弱监督和半监督语义分割的反对抗操控归因，《IEEE/CVF
    计算机视觉与模式识别会议论文集》，页码：4071–4080。
- en: Lerousseau et al. (2020) Lerousseau, M., Vakalopoulou, M., Classe, M., Adam,
    J., Battistella, E., Carré, A., Estienne, T., Henry, T., Deutsch, E. and Paragios,
    N. (2020). Weakly supervised multiple instance learning histopathological tumor
    segmentation, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 470–479.
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lerousseau et al. (2020) Lerousseau, M., Vakalopoulou, M., Classe, M., Adam,
    J., Battistella, E., Carré, A., Estienne, T., Henry, T., Deutsch, E. 和 Paragios,
    N. (2020). 弱监督多实例学习的组织病理学肿瘤分割，《医学图像计算与计算机辅助干预国际会议》，Springer，页码：470–479。
- en: Li, Li and Eliceiri (2021) Li, B., Li, Y. and Eliceiri, K. W. (2021). Dual-stream
    multiple instance learning network for whole slide image classification with self-supervised
    contrastive learning, Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, pp. 14318–14328.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li, Li 和 Eliceiri (2021) Li, B., Li, Y. 和 Eliceiri, K. W. (2021). 用于全幻灯片图像分类的双流多实例学习网络与自监督对比学习，《IEEE/CVF
    计算机视觉与模式识别会议论文集》，页码：14318–14328。
- en: Li, Yang, Wei, He, Chen, Zheng and Bu (2021) Li, F., Yang, Y., Wei, Y., He,
    P., Chen, J., Zheng, Z. and Bu, H. (2021). Deep learning-based predictive biomarker
    of pathological complete response to neoadjuvant chemotherapy from histological
    images in breast cancer, Journal of Translational Medicine  19(1): 1–13.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li, Yang, Wei, He, Chen, Zheng 和 Bu (2021) Li, F., Yang, Y., Wei, Y., He, P.,
    Chen, J., Zheng, Z. 和 Bu, H. (2021). 基于深度学习的乳腺癌新辅助化疗病理完全应答的预测生物标志物，《转化医学杂志》 19(1):
    1–13。'
- en: 'Li, Yang, Zhao and Yao (2021) Li, H., Yang, F., Zhao and Yao, J. (2021). Dt-mil:
    Deformable transformer for multi-instance learning on histopathological image,
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer, pp. 206–216.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li, Yang, Zhao 和 Yao (2021) Li, H., Yang, F., Zhao 和 Yao, J. (2021). Dt-mil：用于组织病理图像的可变形变换器多实例学习，《医学图像计算与计算机辅助干预国际会议》，Springer，页码：206–216。
- en: Li et al. (2018) Li, J., Speier, W., Ho, K. C., Sarma, K. V., Gertych, A., Knudsen,
    B. S. and Arnold, C. W. (2018). An em-based semi-supervised deep learning approach
    for semantic segmentation of histopathological images from radical prostatectomies,
    Computerized Medical Imaging and Graphics  69: 125–133.
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 李等（2018）李，J.，斯皮尔，W.，霍，K. C.，萨尔马，K. V.，格尔蒂奇，A.，克努森，B. S. 和 阿诺德，C. W.（2018）。一种基于EM的半监督深度学习方法用于从根治性前列腺切除术的组织病理图像中进行语义分割，计算机化医学成像与图形
    69：125–133。
- en: Liu et al. (2020) Liu, S., Shah, Z., Sav, A., Russo, C., Berkovsky, S., Qian,
    Y., Coiera, E. and Di Ieva, A. (2020). Isocitrate dehydrogenase (idh) status prediction
    in histopathology images of gliomas using deep learning, Scientific Reports  10(1): 1–11.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2020）刘，S.，沙，Z.，萨夫，A.，鲁索，C.，贝尔科夫斯基，S.，钱，Y.，科埃拉，E. 和 迪·耶瓦，A.（2020）。利用深度学习预测胶质瘤组织病理图像中的异柠檬酸脱氢酶（idh）状态，科学报告
    10(1)：1–11。
- en: 'Liu et al. (2021) Liu, X., Zhang, F., Hou, Z., Mian, L., Wang, Z., Zhang, J.
    and Tang, J. (2021). Self-supervised learning: Generative or contrastive, IEEE
    Transactions on Knowledge and Data Engineering .'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等（2021）刘，X.，张，F.，侯，Z.，缅，L.，王，Z.，张，J. 和 唐，J.（2021）。自监督学习：生成还是对比，IEEE知识与数据工程学报。
- en: Ljosa et al. (2012) Ljosa, V., Sokolnicki, K. L. and Carpenter, A. E. (2012).
    Annotated high-throughput microscopy image sets for validation, Nature methods  9(7): 637–637.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 利乔萨等（2012）利乔萨，V.，索科尔尼基，K. L. 和 卡彭特，A. E.（2012）。用于验证的标注高通量显微镜图像集，自然方法 9(7)：637–637。
- en: Lu et al. (2019) Lu, M. Y., Chen, R. J., Wang, J., Dillon, D. and Mahmood, F.
    (2019). Semi-supervised histology classification using deep multiple instance
    learning and contrastive predictive coding, arXiv preprint arXiv:1910.10825 .
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陆等（2019）陆，M. Y.，陈，R. J.，王，J.，迪龙，D. 和 马赫穆德，F.（2019）。使用深度多实例学习和对比预测编码的半监督组织学分类，arXiv预印本
    arXiv:1910.10825。
- en: Lu et al. (2021) Lu, M. Y., Williamson, D. F., Chen, T. Y., Chen, R. J., Barbieri,
    M. and Mahmood, F. (2021). Data-efficient and weakly supervised computational
    pathology on whole-slide images, Nature Biomedical Engineering  5(6): 555–570.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陆等（2021）陆，M. Y.，威廉姆森，D. F.，陈，T. Y.，陈，R. J.，巴比耶里，M. 和 马赫穆德，F.（2021）。基于全切片图像的数据高效和弱监督计算病理，自然生物医学工程
    5(6)：555–570。
- en: Luo et al. (2017) Luo, X., Zang, X., Yang, L., Huang, J., Liang, F., Rodriguez-Canales,
    J., Wistuba, I. I., Gazdar, A., Xie, Y. and Xiao, G. (2017). Comprehensive computational
    pathological image analysis predicts lung cancer prognosis, Journal of Thoracic
    Oncology  12(3): 501–509.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 罗等（2017）罗，X.，臧，X.，杨，L.，黄，J.，梁，F.，罗德里格斯-卡纳莱斯，J.，维斯图巴，I. I.，加兹达，A.，谢，Y. 和 肖，G.（2017）。综合计算病理图像分析预测肺癌预后，胸外科肿瘤学杂志
    12(3)：501–509。
- en: 'Madabhushi and Lee (2016) Madabhushi, A. and Lee, G. (2016). Image analysis
    and machine learning in digital pathology: Challenges and opportunities, Medical
    Image Analysis  33: 170–175.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马达布希和 李（2016）马达布希，A. 和 李，G.（2016）。数字病理学中的图像分析和机器学习：挑战与机遇，医学图像分析 33：170–175。
- en: Mahapatra et al. (2020) Mahapatra, D., Bozorgtabar, B., Thiran, J.-P. and Shao,
    L. (2020). Structure preserving stain normalization of histopathology images using
    self supervised semantic guidance, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 309–319.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马哈帕特拉等（2020）马哈帕特拉，D.，博佐格塔巴尔，B.，提兰，J.-P. 和 邵，L.（2020）。使用自监督语义指导的结构保持染色规范化组织病理图像，医学图像计算与计算机辅助干预国际会议，Springer，第309–319页。
- en: 'Marini et al. (2021) Marini, N., Otálora, S., Müller, H. and Atzori, M. (2021).
    Semi-supervised training of deep convolutional neural networks with heterogeneous
    data and few local annotations: An experiment on prostate histopathology image
    classification, Medical Image Analysis  73: 102165.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马里尼等（2021）马里尼，N.，奥塔洛拉，S.，穆勒，H. 和 阿佐里，M.（2021）。具有异质数据和少量局部注释的深度卷积神经网络的半监督训练：前列腺组织病理图像分类实验，医学图像分析
    73：102165。
- en: Maron and Lozano-Pérez (1997) Maron, O. and Lozano-Pérez, T. (1997). A framework
    for multiple-instance learning, Advances in Neural Information Processing Systems  10.
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马龙和 洛萨诺-佩雷斯（1997）马龙，O. 和 洛萨诺-佩雷斯，T.（1997）。多实例学习框架，神经信息处理系统进展 10。
- en: Martel et al. (2019) Martel, A., Nofech-Mozes, S., Salama, S., Akbar, S. and Peikari,
    M. (2019). Assessment of residual breast cancer cellularity after neoadjuvant
    chemotherapy using digital pathology [data set], The Cancer Imaging Archive .
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马特尔等（2019）马特尔，A.，诺费赫-莫泽斯，S.，萨拉马，S.，阿克巴尔，S. 和 佩卡里，M.（2019）。使用数字病理学[数据集]评估新辅助化疗后的残余乳腺癌细胞性，癌症影像档案馆。
- en: Melekhov et al. (2016) Melekhov, I., Kannala, J. and Rahtu, E. (2016). Siamese
    network features for image matching, 2016 23rd International Conference on Pattern
    Recognition (ICPR), IEEE, pp. 378–383.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Melekhov et al. (2016) Melekhov, I., Kannala, J. 和 Rahtu, E. (2016). 用于图像匹配的孪生网络特征，2016
    第 23 届国际模式识别大会 (ICPR)，IEEE，第 378–383 页。
- en: Mercan et al. (2017) Mercan, C., Aksoy, S., Mercan, E., Shapiro, L. G., Weaver,
    D. L. and Elmore, J. G. (2017). Multi-instance multi-label learning for multi-class
    classification of whole slide breast histopathology images, IEEE Transactions
    on Medical Imaging  37(1): 316–325.
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mercan et al. (2017) Mercan, C., Aksoy, S., Mercan, E., Shapiro, L. G., Weaver,
    D. L. 和 Elmore, J. G. (2017). 用于全切片乳腺组织病理图像的多实例多标签学习，《IEEE 医学成像交易》 37(1): 316–325。'
- en: Muhammad et al. (2019) Muhammad, H., Sigel, C. S., Campanella, G., Boerner,
    T., Pak, L. M., Büttner, S., IJzermans, J. N., Koerkamp, B. G., Doukas, M., Jarnagin,
    W. R. et al. (2019). Unsupervised subtyping of cholangiocarcinoma using a deep
    clustering convolutional autoencoder, International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer, pp. 604–612.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Muhammad et al. (2019) Muhammad, H., Sigel, C. S., Campanella, G., Boerner,
    T., Pak, L. M., Büttner, S., IJzermans, J. N., Koerkamp, B. G., Doukas, M., Jarnagin,
    W. R. 等 (2019). 使用深度聚类卷积自编码器对胆管癌进行无监督亚型分类，《医学图像计算与计算机辅助手术国际会议》，Springer，第 604–612
    页。
- en: Murthy et al. (2017) Murthy, V., Hou, L., Samaras, D., Kurc, T. M. and Saltz,
    J. H. (2017). Center-focusing multi-task cnn with injected features for classification
    of glioma nuclear images, 2017 IEEE Winter Conference on Applications of Computer
    Vision (WACV), IEEE, pp. 834–841.
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Murthy et al. (2017) Murthy, V., Hou, L., Samaras, D., Kurc, T. M. 和 Saltz,
    J. H. (2017). 通过注入特征的中心聚焦多任务 CNN 对胶质瘤核图像进行分类，2017 IEEE 冬季计算机视觉应用会议 (WACV)，IEEE，第
    834–841 页。
- en: Myronenko et al. (2021) Myronenko, A., Xu, Z., Yang, D., Roth, H. R. and Xu,
    D. (2021). Accounting for dependencies in deep learning based multiple instance
    learning for whole slide imaging, International Conference on Medical Image Computing
    and Computer-Assisted Intervention, Springer, pp. 329–338.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myronenko et al. (2021) Myronenko, A., Xu, Z., Yang, D., Roth, H. R. 和 Xu, D.
    (2021). 计算深度学习基础的多实例学习中对整体切片成像的依赖性，《医学图像计算与计算机辅助手术国际会议》，Springer，第 329–338 页。
- en: Nagpal et al. (2019) Nagpal, K., Foote, D., Liu, Y., Chen, P.-H. C., Wulczyn,
    E., Tan, F., Olson, N., Smith, J. L., Mohtashamian, A., Wren, J. H. et al. (2019).
    Development and validation of a deep learning algorithm for improving gleason
    scoring of prostate cancer, NPJ Digital Medicine  2(1): 1–10.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nagpal et al. (2019) Nagpal, K., Foote, D., Liu, Y., Chen, P.-H. C., Wulczyn,
    E., Tan, F., Olson, N., Smith, J. L., Mohtashamian, A., Wren, J. H. 等 (2019).
    提高前列腺癌 Gleason 评分的深度学习算法的开发与验证，《NPJ 数字医学》 2(1): 1–10。'
- en: Naik et al. (2020) Naik, N., Madani, A., Esteva, A., Keskar, N. S., Press, M. F.,
    Ruderman, D., Agus, D. B. and Socher, R. (2020). Deep learning-enabled breast
    cancer hormonal receptor status determination from base-level h&e stains, Nature
    Communications  11(1): 1–8.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Naik et al. (2020) Naik, N., Madani, A., Esteva, A., Keskar, N. S., Press,
    M. F., Ruderman, D., Agus, D. B. 和 Socher, R. (2020). 基于深度学习的乳腺癌激素受体状态确定，基于基础级别
    H&E 染色，《自然通讯》 11(1): 1–8。'
- en: Naylor et al. (2018) Naylor, P., Laé, M., Reyal, F. and Walter, T. (2018). Segmentation
    of nuclei in histopathology images by deep regression of the distance map, IEEE
    Transactions on Medical Imaging  38(2): 448–459.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Naylor et al. (2018) Naylor, P., Laé, M., Reyal, F. 和 Walter, T. (2018). 通过深度回归距离图对组织病理图像中的细胞核进行分割，《IEEE
    医学成像交易》 38(2): 448–459。'
- en: Noroozi and Favaro (2016) Noroozi, M. and Favaro, P. (2016). Unsupervised learning
    of visual representations by solving jigsaw puzzles, European Conference on Computer
    Vision, Springer, pp. 69–84.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Noroozi and Favaro (2016) Noroozi, M. 和 Favaro, P. (2016). 通过解决拼图来无监督学习视觉表示，《欧洲计算机视觉会议》，Springer，第
    69–84 页。
- en: Odena (2016) Odena, A. (2016). Semi-supervised learning with generative adversarial
    networks, arXiv preprint arXiv:1606.01583 .
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Odena (2016) Odena, A. (2016). 使用生成对抗网络的半监督学习，arXiv 预印本 arXiv:1606.01583。
- en: Pan et al. (2022) Pan, J., Bi, Q., Yang, Y., Zhu, P. and Bian, C. (2022). Label-efficient
    hybrid-supervised learning for medical image segmentation, arXiv preprint arXiv:2203.05956
    .
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pan et al. (2022) Pan, J., Bi, Q., Yang, Y., Zhu, P. 和 Bian, C. (2022). 用于医学图像分割的标签高效混合监督学习，arXiv
    预印本 arXiv:2203.05956。
- en: Parag et al. (2014) Parag, T., Plaza, S. and Scheffer, L. (2014). Small sample
    learning of superpixel classifiers for em segmentation, International Conference
    on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 389–397.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Parag et al. (2014) Parag, T., Plaza, S. 和 Scheffer, L. (2014). 用于 EM 分割的超像素分类器的小样本学习，《医学图像计算与计算机辅助手术国际会议》，Springer，第
    389–397 页。
- en: 'Pathak et al. (2016) Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T. and Efros,
    A. A. (2016). Context encoders: Feature learning by inpainting, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 2536–2544.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pathak等（2016）Pathak, D., Krahenbuhl, P., Donahue, J., Darrell, T. 和 Efros, A.
    A.（2016）。上下文编码器：通过修复进行特征学习，IEEE计算机视觉与模式识别会议论文集，第2536–2544页。
- en: Peikari et al. (2018) Peikari, M., Salama, S., Nofech-Mozes, S. and Martel,
    A. L. (2018). A cluster-then-label semi-supervised learning approach for pathology
    image classification, Scientific Reports  8(1): 1–13.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Peikari等（2018）Peikari, M., Salama, S., Nofech-Mozes, S. 和 Martel, A. L.（2018）。一种先聚类后标注的半监督学习方法用于病理图像分类，Scientific
    Reports 8(1): 1–13。'
- en: 'Petrick et al. (2021) Petrick, N. A., Akbar, S., Cha, K. H., Nofech-Mozes,
    S., Sahiner, B., Gavrielides, M. A., Kalpathy-Cramer, J., Drukker, K., Martel,
    A. L. et al. (2021). Spie-aapm-nci breastpathq challenge: an image analysis challenge
    for quantitative tumor cellularity assessment in breast cancer histology images
    following neoadjuvant treatment, Journal of Medical Imaging  8(3): 034501.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Petrick等（2021）Petrick, N. A., Akbar, S., Cha, K. H., Nofech-Mozes, S., Sahiner,
    B., Gavrielides, M. A., Kalpathy-Cramer, J., Drukker, K., Martel, A. L. 等（2021）。Spie-aapm-nci
    breastpathq挑战赛：用于定量评估乳腺癌组织学图像中肿瘤细胞性的一项图像分析挑战，Journal of Medical Imaging 8(3):
    034501。'
- en: Qaiser et al. (2016) Qaiser, T., Sirinukunwattana, K., Nakane, K., Tsang, Y.-W.,
    Epstein, D. and Rajpoot, N. (2016). Persistent homology for fast tumor segmentation
    in whole slide histology images, Procedia Computer Science  90: 119–124.
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qaiser等（2016）Qaiser, T., Sirinukunwattana, K., Nakane, K., Tsang, Y.-W., Epstein,
    D. 和 Rajpoot, N.（2016）。用于快速肿瘤分割的持久同调，Procedia Computer Science 90: 119–124。'
- en: Qu et al. (2020) Qu, H., Wu, P., Huang, Q., Yi, J., Yan, Z., Li, K., Riedlinger,
    G. M., De, S., Zhang, S. and Metaxas, D. N. (2020). Weakly supervised deep nuclei
    segmentation using partial points annotation in histopathology images, IEEE Transactions
    on Medical Imaging  39(11): 3655–3666.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qu等（2020）Qu, H., Wu, P., Huang, Q., Yi, J., Yan, Z., Li, K., Riedlinger, G.
    M., De, S., Zhang, S. 和 Metaxas, D. N.（2020）。使用部分点注释的弱监督深核分割，IEEE Transactions
    on Medical Imaging 39(11): 3655–3666。'
- en: 'Qu et al. (2022) Qu, L., Luo, X., Liu, S., Wang, M. and Song, Z. (2022). Dgmil:
    Distribution guided multiple instance learning for whole slide image classification,
    arXiv preprint arXiv:2206.08861 .'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Qu等（2022）Qu, L., Luo, X., Liu, S., Wang, M. 和 Song, Z.（2022）。Dgmil: 分布引导的多实例学习用于全幻灯片图像分类，arXiv预印本
    arXiv:2206.08861。'
- en: Quiros et al. (2021) Quiros, A. C., Coudray, N., Yeaton, A., Sunhem, W., Murray-Smith,
    R., Tsirigos, A. and Yuan, K. (2021). Adversarial learning of cancer tissue representations,
    arXiv preprint arXiv:2108.02223 .
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Quiros等（2021）Quiros, A. C., Coudray, N., Yeaton, A., Sunhem, W., Murray-Smith,
    R., Tsirigos, A. 和 Yuan, K.（2021）。癌症组织表示的对抗性学习，arXiv预印本 arXiv:2108.02223。
- en: 'Quiros et al. (2019) Quiros, A. C., Murray-Smith, R. and Yuan, K. (2019). Pathologygan:
    Learning deep representations of cancer tissue, arXiv preprint arXiv:1907.02644
    .'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Quiros等（2019）Quiros, A. C., Murray-Smith, R. 和 Yuan, K.（2019）。Pathologygan:
    学习癌症组织的深度表示，arXiv预印本 arXiv:1907.02644。'
- en: Qureshi et al. (2008) Qureshi, H., Sertel, O., Rajpoot, N., Wilson, R. and Gurcan,
    M. (2008). Adaptive discriminant wavelet packet transform and local binary patterns
    for meningioma subtype classification, International Conference on Medical Image
    Computing and Computer-Assisted Intervention, Springer, pp. 196–204.
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qureshi等（2008）Qureshi, H., Sertel, O., Rajpoot, N., Wilson, R. 和 Gurcan, M.（2008）。用于脑膜瘤亚型分类的自适应判别小波包变换和局部二值模式，国际医学图像计算与计算机辅助干预会议，Springer，第196–204页。
- en: Radford et al. (2015) Radford, A., Metz, L. and Chintala, S. (2015). Unsupervised
    representation learning with deep convolutional generative adversarial networks,
    arXiv preprint arXiv:1511.06434 .
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford等（2015）Radford, A., Metz, L. 和 Chintala, S.（2015）。使用深度卷积生成对抗网络的无监督表示学习，arXiv预印本
    arXiv:1511.06434。
- en: Rajpoot and Rajpoot (2004) Rajpoot, K. and Rajpoot, N. (2004). Svm optimization
    for hyperspectral colon tissue cell classification, International Conference on
    Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 829–837.
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajpoot和Rajpoot（2004）Rajpoot, K. 和 Rajpoot, N.（2004）。用于高光谱结肠组织细胞分类的支持向量机优化，国际医学图像计算与计算机辅助干预会议，Springer，第829–837页。
- en: Ramon and De Raedt (2000) Ramon, J. and De Raedt, L. (2000). Multi instance
    neural networks, Proceedings of the ICML-2000 Workshop on Attribute-value and
    Relational Learning, pp. 53–60.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramon和De Raedt（2000）Ramon, J. 和 De Raedt, L.（2000）。多实例神经网络，ICML-2000属性值与关系学习研讨会论文集，第53–60页。
- en: 'Rethlefsen et al. (2021) Rethlefsen, M. L., Kirtley, S., Waffenschmidt, S.,
    Ayala, A. P., Moher, D., Page, M. J. and Koffel, J. B. (2021). Prisma-s: an extension
    to the prisma statement for reporting literature searches in systematic reviews,
    Systematic Reviews  10(1): 1–19.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Rethlefsen等（2021）Rethlefsen, M. L., Kirtley, S., Waffenschmidt, S., Ayala,
    A. P., Moher, D., Page, M. J. 和 Koffel, J. B.（2021）。Prisma-s：对PRISMA声明的扩展，用于系统评价中的文献检索报告，《系统评价》10(1):
    1–19。'
- en: Rifai, Dauphin, Vincent, Bengio and Muller (2011) Rifai, S., Dauphin, Y. N.,
    Vincent, P., Bengio, Y. and Muller, X. (2011). The manifold tangent classifier,
    Advances in Neural Information Processing Systems  24.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rifai, Dauphin, Vincent, Bengio 和 Muller（2011）Rifai, S., Dauphin, Y. N., Vincent,
    P., Bengio, Y. 和 Muller, X.（2011）。流形切线分类器，《神经信息处理系统进展》24。
- en: 'Rifai, Vincent, Muller, Glorot and Bengio (2011) Rifai, S., Vincent, P., Muller,
    X., Glorot, X. and Bengio, Y. (2011). Contractive auto-encoders: Explicit invariance
    during feature extraction, International Conference on Machine Learning.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rifai, Vincent, Muller, Glorot 和 Bengio（2011）Rifai, S., Vincent, P., Muller,
    X., Glorot, X. 和 Bengio, Y.（2011）。压缩自编码器：特征提取中的显式不变性，《机器学习国际会议》。
- en: 'Rony et al. (2019) Rony, J., Belharbi, S., Dolz, J., Ayed, I. B., McCaffrey,
    L. and Granger, E. (2019). Deep weakly-supervised learning methods for classification
    and localization in histology images: a survey, arXiv preprint arXiv:1909.03354
    .'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rony等（2019）Rony, J., Belharbi, S., Dolz, J., Ayed, I. B., McCaffrey, L. 和 Granger,
    E.（2019）。用于组织学图像分类和定位的深度弱监督学习方法：综述，arXiv预印本 arXiv:1909.03354。
- en: 'Ru et al. (2022) Ru, L., Zhan, Y., Yu, B. and Du, B. (2022). Learning affinity
    from attention: End-to-end weakly-supervised semantic segmentation with transformers,
    arXiv preprint arXiv:2203.02664 .'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ru等（2022）Ru, L., Zhan, Y., Yu, B. 和 Du, B.（2022）。从注意力中学习亲和力：基于变换器的端到端弱监督语义分割，arXiv预印本
    arXiv:2203.02664。
- en: Sahasrabudhe et al. (2020) Sahasrabudhe, M., Christodoulidis, S., Salgado, R.,
    Michiels, S., Loi, S., André, F., Paragios, N. and Vakalopoulou, M. (2020). Self-supervised
    nuclei segmentation in histopathological images using attention, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 393–402.
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sahasrabudhe等（2020）Sahasrabudhe, M., Christodoulidis, S., Salgado, R., Michiels,
    S., Loi, S., André, F., Paragios, N. 和 Vakalopoulou, M.（2020）。使用注意力机制进行组织病理图像的自监督细胞核分割，《医学图像计算与计算机辅助干预国际会议》，Springer，第393–402页。
- en: Saillard et al. (2021) Saillard, C., Dehaene, O., Marchand, T., Moindrot, O.,
    Kamoun, A., Schmauch, B. and Jegou, S. (2021). Self supervised learning improves
    dmmr/msi detection from histology slides across multiple cancers, arXiv preprint
    arXiv:2109.05819 .
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saillard等（2021）Saillard, C., Dehaene, O., Marchand, T., Moindrot, O., Kamoun,
    A., Schmauch, B. 和 Jegou, S.（2021）。自监督学习提高了多癌症组织切片中的DMMR/MSI检测，arXiv预印本 arXiv:2109.05819。
- en: Saillard et al. (2020) Saillard, C., Schmauch, B., Laifa, O., Moarii, M., Toldo,
    S., Zaslavskiy, M., Pronier, E., Laurent, A., Amaddeo, G., Regnault, H. et al.
    (2020). Predicting survival after hepatocellular carcinoma resection using deep
    learning on histological slides, Hepatology  72(6): 2000–2013.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Saillard等（2020）Saillard, C., Schmauch, B., Laifa, O., Moarii, M., Toldo, S.,
    Zaslavskiy, M., Pronier, E., Laurent, A., Amaddeo, G., Regnault, H. 等（2020）。利用深度学习在组织学切片上预测肝细胞癌切除后的生存率，《肝病学》72(6):
    2000–2013。'
- en: Salimans et al. (2016) Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V.,
    Radford, A. and Chen, X. (2016). Improved techniques for training gans, Advances
    in Neural Information Processing Systems  29.
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salimans等（2016）Salimans, T., Goodfellow, I., Zaremba, W., Cheung, V., Radford,
    A. 和 Chen, X.（2016）。改进的GAN训练技术，《神经信息处理系统进展》29。
- en: Shaban et al. (2019) Shaban, M., Khurram, S. A., Fraz, M. M., Alsubaie, N.,
    Masood, I., Mushtaq, S., Hassan, M., Loya, A. and Rajpoot, N. M. (2019). A novel
    digital score for abundance of tumour infiltrating lymphocytes predicts disease
    free survival in oral squamous cell carcinoma, Scientific Reports  9(1): 1–13.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shaban等（2019）Shaban, M., Khurram, S. A., Fraz, M. M., Alsubaie, N., Masood,
    I., Mushtaq, S., Hassan, M., Loya, A. 和 Rajpoot, N. M.（2019）。一种新型数字评分用于预测口腔鳞状细胞癌中的肿瘤浸润淋巴细胞丰度，从而预测无病生存，《科学报告》9(1):
    1–13。'
- en: 'Shao et al. (2021) Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X.
    et al. (2021). Transmil: Transformer based correlated multiple instance learning
    for whole slide image classification, Advances in Neural Information Processing
    Systems  34.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shao等（2021）Shao, Z., Bian, H., Chen, Y., Wang, Y., Zhang, J., Ji, X. 等（2021）。Transmil：基于变换器的相关多实例学习用于全切片图像分类，《神经信息处理系统进展》34。
- en: 'Sharma et al. (2021) Sharma, Y., Shrivastava, A., Ehsan, L., Moskaluk, C. A.,
    Syed, S. and Brown, D. (2021). Cluster-to-conquer: A framework for end-to-end
    multi-instance learning for whole slide image classification, Medical Imaging
    with Deep Learning, PMLR, pp. 682–698.'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sharma 等（2021）Sharma, Y., Shrivastava, A., Ehsan, L., Moskaluk, C. A., Syed,
    S. 和 Brown, D.（2021）。Cluster-to-conquer：一种用于全幻灯片图像分类的端到端多实例学习框架，医学影像深度学习，PMLR，第682–698页。
- en: Shaw et al. (2020) Shaw, S., Pajak, M., Lisowska, A., Tsaftaris, S. A. and O’Neil,
    A. Q. (2020). Teacher-student chain for efficient semi-supervised histology image
    classification, arXiv preprint arXiv:2003.08797 .
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shaw 等（2020）Shaw, S., Pajak, M., Lisowska, A., Tsaftaris, S. A. 和 O’Neil, A.
    Q.（2020）。高效的半监督组织学图像分类的师生链，arXiv 预印本 arXiv:2003.08797。
- en: Shi et al. (2018) Shi, X., Sapkota, M., Xing, F., Liu, F., Cui, L. and Yang,
    L. (2018). Pairwise based deep ranking hashing for histopathology image classification
    and retrieval, Pattern Recognition  81: 14–22.
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi 等（2018）Shi, X., Sapkota, M., Xing, F., Liu, F., Cui, L. 和 Yang, L.（2018）。基于对的深度排序哈希用于组织病理图像分类和检索，模式识别
    81: 14–22。'
- en: Shi, Su, Xing and Yang (2020) Shi, X., Su, H., Xing, G. and Yang, L. (2020).
    Graph temporal ensembling based semi-supervised convolutional neural network with
    noisy labels for histopathology image analysis, Medical Image Analysis  60: 101624.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shi, Su, Xing 和 Yang（2020）Shi, X., Su, H., Xing, G. 和 Yang, L.（2020）。基于图的时间集成半监督卷积神经网络与噪声标签用于组织病理图像分析，医学图像分析
    60: 101624。'
- en: Shi, Xing, Xie, Zhang, Cui and Yang (2020) Shi, X., Xing, F., Xie, Y., Zhang,
    Z., Cui, L. and Yang, L. (2020). Loss-based attention for deep multiple instance
    learning, Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34,
    pp. 5742–5749.
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi, Xing, Xie, Zhang, Cui 和 Yang（2020）Shi, X., Xing, F., Xie, Y., Zhang, Z.,
    Cui, L. 和 Yang, L.（2020）。基于损失的注意力用于深度多实例学习，AAAI 人工智能会议论文集，卷34，第5742–5749页。
- en: 'Shurrab and Duwairi (2021) Shurrab, S. and Duwairi, R. (2021). Self-supervised
    learning methods and applications in medical imaging analysis: A survey, arXiv
    preprint arXiv:2109.08685 .'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shurrab 和 Duwairi（2021）Shurrab, S. 和 Duwairi, R.（2021）。自监督学习方法及其在医学影像分析中的应用：综述，arXiv
    预印本 arXiv:2109.08685。
- en: Singh et al. (2011) Singh, S., Janoos, F., Pécot, T., Caserta, E., Leone, G.,
    Rittscher, J. and Machiraju, R. (2011). Identifying nuclear phenotypes using semi-supervised
    metric learning, Biennial International Conference on Information Processing in
    Medical Imaging, Springer, pp. 398–410.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Singh 等（2011）Singh, S., Janoos, F., Pécot, T., Caserta, E., Leone, G., Rittscher,
    J. 和 Machiraju, R.（2011）。使用半监督度量学习识别核表型，医学影像信息处理国际会议（Biennial International Conference
    on Information Processing in Medical Imaging），Springer，第398–410页。
- en: 'Sirinukunwattana et al. (2017) Sirinukunwattana, K., Pluim, J. P., Chen, H.,
    Qi, X., Heng, P.-A., Guo, Y. B., Wang, L. Y., Matuszewski, B. J., Bruni, E., Sanchez,
    U. et al. (2017). Gland segmentation in colon histology images: The glas challenge
    contest, Medical Image Analysis  35: 489–502.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sirinukunwattana 等（2017）Sirinukunwattana, K., Pluim, J. P., Chen, H., Qi, X.,
    Heng, P.-A., Guo, Y. B., Wang, L. Y., Matuszewski, B. J., Bruni, E., Sanchez,
    U. 等（2017）。结肠组织学图像中的腺体分割：GLAS挑战赛，医学图像分析 35: 489–502。'
- en: Sirinukunwattana et al. (2016) Sirinukunwattana, K., Raza, S. E. A., Tsang,
    Y.-W., Snead, D. R., Cree, I. A. and Rajpoot, N. M. (2016). Locality sensitive
    deep learning for detection and classification of nuclei in routine colon cancer
    histology images, IEEE transactions on medical imaging  35(5): 1196–1206.
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sirinukunwattana 等（2016）Sirinukunwattana, K., Raza, S. E. A., Tsang, Y.-W.,
    Snead, D. R., Cree, I. A. 和 Rajpoot, N. M.（2016）。用于常规结肠癌组织学图像中细胞核检测和分类的局部敏感深度学习，IEEE医学影像学杂志
    35(5): 1196–1206。'
- en: 'Skrede et al. (2020) Skrede, O.-J., De Raedt, S., Kleppe, A., Hveem, T. S.,
    Liestøl, K., Maddison, J., Askautrud, H. A., Pradhan, M., Nesheim, J. A., Albregtsen,
    F. et al. (2020). Deep learning for prediction of colorectal cancer outcome: a
    discovery and validation study, The Lancet  395(10221): 350–360.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Skrede 等（2020）Skrede, O.-J., De Raedt, S., Kleppe, A., Hveem, T. S., Liestøl,
    K., Maddison, J., Askautrud, H. A., Pradhan, M., Nesheim, J. A., Albregtsen, F.
    等（2020）。用于预测结直肠癌结果的深度学习：发现和验证研究，《柳叶刀》 395(10221): 350–360。'
- en: Spanhol et al. (2015) Spanhol, F. A., Oliveira, L. S., Petitjean, C. and Heutte,
    L. (2015). A dataset for breast cancer histopathological image classification,
    IEEE Transactions on Biomedical Engineering  63(7): 1455–1462.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Spanhol 等（2015）Spanhol, F. A., Oliveira, L. S., Petitjean, C. 和 Heutte, L.（2015）。乳腺癌组织病理图像分类的数据集，IEEE生物医学工程学报
    63(7): 1455–1462。'
- en: 'Sparks and Madabhushi (2016) Sparks, R. and Madabhushi, A. (2016). Out-of-sample
    extrapolation utilizing semi-supervised manifold learning (ose-ssl): content based
    image retrieval for histopathology images, Scientific Reports  6(1): 1–15.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sparks 和 Madabhushi（2016）Sparks, R. 和 Madabhushi, A.（2016）。利用半监督流形学习（ose-ssl）的样本外外推：基于内容的组织病理图像检索，《科学报告》6(1):
    1–15。'
- en: 'Srinidhi et al. (2021) Srinidhi, C. L., Ciga, O. and Martel, A. L. (2021).
    Deep neural network models for computational histopathology: A survey, Medical
    Image Analysis  67: 101813.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Srinidhi 等人（2021）Srinidhi, C. L., Ciga, O. 和 Martel, A. L.（2021）。计算组织病理学的深度神经网络模型：综述，《医学图像分析》67:
    101813。'
- en: Srinidhi et al. (2022) Srinidhi, C. L., Kim, S. W., Chen, F.-D. and Martel,
    A. L. (2022). Self-supervised driven consistency training for annotation efficient
    histopathology image analysis, Medical Image Analysis  75: 102256.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Srinidhi 等人（2022）Srinidhi, C. L., Kim, S. W., Chen, F.-D. 和 Martel, A. L.（2022）。自监督驱动的一致性训练用于注释高效的组织病理图像分析，《医学图像分析》75:
    102256。'
- en: Stacke et al. (2021) Stacke, K., Unger, J., Lundström, C. and Eilertsen, G.
    (2021). Learning representations with contrastive self-supervised learning for
    histopathology applications, arXiv preprint arXiv:2112.05760 .
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stacke 等人（2021）Stacke, K., Unger, J., Lundström, C. 和 Eilertsen, G.（2021）。使用对比自监督学习进行组织病理应用的表示学习，arXiv
    预印本 arXiv:2112.05760。
- en: Su et al. (2019) Su, H., Shi, X., Cai, J. and Yang, L. (2019). Local and global
    consistency regularized mean teacher for semi-supervised nuclei classification,
    International Conference on Medical Image Computing and Computer-Assisted Intervention,
    Springer, pp. 559–567.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Su 等人（2019）Su, H., Shi, X., Cai, J. 和 Yang, L.（2019）。局部和全局一致性正则化的均值教师用于半监督核分类，国际医学图像计算与计算机辅助干预会议，Springer，第559–567页。
- en: Su et al. (2015) Su, H., Yin, Z., Huh, S., Kanade, T. and Zhu, J. (2015). Interactive
    cell segmentation based on active and semi-supervised learning, IEEE Transactions
    on Medical Imaging  35(3): 762–777.
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Su 等人（2015）Su, H., Yin, Z., Huh, S., Kanade, T. 和 Zhu, J.（2015）。基于主动和半监督学习的交互式细胞分割，《IEEE
    医学成像汇刊》35(3): 762–777。'
- en: 'Su et al. (2021) Su, L., Liu, Y., Wang, M. and Li, A. (2021). Semi-hic: A novel
    semi-supervised deep learning method for histopathological image classification,
    Computers in Biology and Medicine  137: 104788.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Su 等人（2021）Su, L., Liu, Y., Wang, M. 和 Li, A.（2021）。Semi-hic：一种新颖的半监督深度学习方法用于组织病理图像分类，《生物医学计算机》137:
    104788。'
- en: Swiderska-Chadaj et al. (2019) Swiderska-Chadaj, Z., Pinckaers, H., van Rijthoven,
    M., Balkenhol, M., Melnikova, M., Geessink, O., Manson, Q., Sherman, M., Polonia,
    A., Parry, J. et al. (2019). Learning to detect lymphocytes in immunohistochemistry
    with deep learning, Medical Image Analysis  58: 101547.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Swiderska-Chadaj 等人（2019）Swiderska-Chadaj, Z., Pinckaers, H., van Rijthoven,
    M., Balkenhol, M., Melnikova, M., Geessink, O., Manson, Q., Sherman, M., Polonia,
    A., Parry, J. 等人（2019）。在免疫组织化学中使用深度学习检测淋巴细胞，《医学图像分析》58: 101547。'
- en: 'Tajbakhsh et al. (2020) Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J. N.,
    Wu, Z. and Ding, X. (2020). Embracing imperfect datasets: A review of deep learning
    solutions for medical image segmentation, Medical Image Analysis  63: 101693.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tajbakhsh 等人（2020）Tajbakhsh, N., Jeyaseelan, L., Li, Q., Chiang, J. N., Wu,
    Z. 和 Ding, X.（2020）。拥抱不完美的数据集：深度学习解决方案在医学图像分割中的应用综述，《医学图像分析》63: 101693。'
- en: 'Tarvainen and Valpola (2017) Tarvainen, A. and Valpola, H. (2017). Mean teachers
    are better role models: Weight-averaged consistency targets improve semi-supervised
    deep learning results, Advances in Neural Information Processing Systems  30.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tarvainen 和 Valpola（2017）Tarvainen, A. 和 Valpola, H.（2017）。均值教师是更好的榜样：权重平均的一致性目标改善半监督深度学习结果，《神经信息处理系统进展》30。
- en: TCGA (2019) TCGA (2019). The cancer genome atlas, [https://www.cancer.gov/tcga](https://www.cancer.gov/tcga).
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: TCGA（2019）TCGA（2019）。癌症基因组图谱，[https://www.cancer.gov/tcga](https://www.cancer.gov/tcga)。
- en: 'Team et al. (2011) Team, N. L. S. T. R. et al. (2011). The national lung screening
    trial: overview and study design, Radiology  258(1): 243.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Team 等人（2011）Team, N. L. S. T. R. 等人（2011）。国家肺筛查试验：概述和研究设计，《放射学》258(1): 243。'
- en: Tellez et al. (2019) Tellez, D., Litjens, G., van der Laak, J. and Ciompi, F.
    (2019). Neural image compression for gigapixel histopathology image analysis,
    IEEE Transactions on Pattern Analysis and Machine Intelligence  43(2): 567–578.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tellez 等人（2019）Tellez, D., Litjens, G., van der Laak, J. 和 Ciompi, F.（2019）。用于千兆像素组织病理图像分析的神经图像压缩，《IEEE
    图案分析与机器智能汇刊》43(2): 567–578。'
- en: Tolkach et al. (2020) Tolkach, Y., Dohmgörgen, T., Toma, M. and Kristiansen,
    G. (2020). High-accuracy prostate cancer pathology using deep learning, Nature
    Machine Intelligence  2(7): 411–418.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tolkach 等人 (2020) Tolkach, Y., Dohmgörgen, T., Toma, M. 和 Kristiansen, G. (2020).
    使用深度学习进行高准确度前列腺癌病理分析，Nature Machine Intelligence 2(7): 411–418。'
- en: Tomita et al. (2019) Tomita, N., Abdollahi, B., Wei, J., Ren, B., Suriawinata,
    A. and Hassanpour, S. (2019). Attention-based deep neural networks for detection
    of cancerous and precancerous esophagus tissue on histopathological slides, JAMA
    Network Open  2(11): e1914645–e1914645.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tomita 等人 (2019) Tomita, N., Abdollahi, B., Wei, J., Ren, B., Suriawinata,
    A. 和 Hassanpour, S. (2019). 基于注意力的深度神经网络用于检测癌变和前癌变的食道组织在组织病理切片上的表现，JAMA Network
    Open 2(11): e1914645–e1914645。'
- en: Tu et al. (2019) Tu, M., Huang, J., He, X. and Zhou, B. (2019). Multiple instance
    learning with graph neural networks, arXiv preprint arXiv:1906.04881 .
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tu 等人 (2019) Tu, M., Huang, J., He, X. 和 Zhou, B. (2019). 基于图神经网络的多实例学习，arXiv
    预印本 arXiv:1906.04881。
- en: Van den Oord et al. (2018) Van den Oord, A., Li, Y. and Vinyals, O. (2018).
    Representation learning with contrastive predictive coding, arXiv e-prints pp. arXiv–1807.
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Van den Oord 等人 (2018) Van den Oord, A., Li, Y. 和 Vinyals, O. (2018). 使用对比预测编码进行表征学习，arXiv
    e-prints，第arXiv–1807页。
- en: Van Engelen and Hoos (2020) Van Engelen, J. E. and Hoos, H. H. (2020). A survey
    on semi-supervised learning, Machine Learning  109(2): 373–440.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Van Engelen 和 Hoos (2020) Van Engelen, J. E. 和 Hoos, H. H. (2020). 半监督学习的调查，Machine
    Learning 109(2): 373–440。'
- en: Veeling et al. (2018) Veeling, B. S., Linmans, J., Winkens, J., Cohen, T. and Welling,
    M. (2018). Rotation equivariant cnns for digital pathology, International Conference
    on Medical Image Computing and Computer-assisted Intervention, Springer, pp. 210–218.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Veeling 等人 (2018) Veeling, B. S., Linmans, J., Winkens, J., Cohen, T. 和 Welling,
    M. (2018). 针对数字病理的旋转等变卷积神经网络，国际医学图像计算与计算机辅助干预会议，Springer，第210–218页。
- en: Velmahos et al. (2021) Velmahos, C. S., Badgeley, M. and Lo, Y.-C. (2021). Using
    deep learning to identify bladder cancers with fgfr-activating mutations from
    histology images, Cancer Medicine  10(14): 4805–4813.
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Velmahos 等人 (2021) Velmahos, C. S., Badgeley, M. 和 Lo, Y.-C. (2021). 使用深度学习从组织学图像中识别具有
    fgfr 激活突变的膀胱癌，Cancer Medicine 10(14): 4805–4813。'
- en: 'Veta et al. (2019) Veta, M., Heng, Y. J., Stathonikos, N., Bejnordi, B. E.,
    Beca, F., Wollmann, T., Rohr, K., Shah, M. A., Wang, D., Rousson, M. et al. (2019).
    Predicting breast tumor proliferation from whole-slide images: the tupac16 challenge,
    Medical Image Analysis  54: 111–121.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Veta 等人 (2019) Veta, M., Heng, Y. J., Stathonikos, N., Bejnordi, B. E., Beca,
    F., Wollmann, T., Rohr, K., Shah, M. A., Wang, D., Rousson, M. 等 (2019). 从全切片图像预测乳腺肿瘤增殖：tupac16
    挑战，Medical Image Analysis 54: 111–121。'
- en: Vincent et al. (2008) Vincent, P., Larochelle, H., Bengio, Y. and Manzagol,
    P.-A. (2008). Extracting and composing robust features with denoising autoencoders,
    Proceedings of the 25th International Conference on Machine Learning, pp. 1096–1103.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vincent 等人 (2008) Vincent, P., Larochelle, H., Bengio, Y. 和 Manzagol, P.-A.
    (2008). 使用去噪自编码器提取和组合鲁棒特征，第25届国际机器学习会议论文集，第1096–1103页。
- en: Wang, Lee, Calista, Zhou, Zhu, Suzuki, Komura, Ishikawa and Cheng (2018) Wang,
    C.-W., Lee, Y.-C., Calista, E., Zhou, F., Zhu, H., Suzuki, R., Komura, D., Ishikawa,
    S. and Cheng, S.-P. (2018). A benchmark for comparing precision medicine methods
    in thyroid cancer diagnosis using tissue microarrays, Bioinformatics  34(10): 1767–1773.
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang, Lee, Calista, Zhou, Zhu, Suzuki, Komura, Ishikawa 和 Cheng (2018) Wang,
    C.-W., Lee, Y.-C., Calista, E., Zhou, F., Zhu, H., Suzuki, R., Komura, D., Ishikawa,
    S. 和 Cheng, S.-P. (2018). 使用组织微阵列比较甲状腺癌诊断中的精准医学方法的基准，Bioinformatics 34(10): 1767–1773。'
- en: Wang et al. (2019) Wang, X., Chen, H., Gan, C., Lin, H., Dou, Q., Tsougenis,
    E., Huang, Q., Cai, M. and Heng, P.-A. (2019). Weakly supervised deep learning
    for whole slide lung cancer image analysis, IEEE Transactions on Cybernetics  50(9): 3950–3962.
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang 等人 (2019) Wang, X., Chen, H., Gan, C., Lin, H., Dou, Q., Tsougenis, E.,
    Huang, Q., Cai, M. 和 Heng, P.-A. (2019). 弱监督深度学习用于全切片肺癌图像分析，IEEE Transactions
    on Cybernetics 50(9): 3950–3962。'
- en: Wang, Yan, Tang, Bai and Liu (2018) Wang, X., Yan, Y., Tang, P., Bai, X. and Liu,
    W. (2018). Revisiting multiple instance neural networks, Pattern Recognition  74: 15–24.
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang, Yan, Tang, Bai 和 Liu (2018) Wang, X., Yan, Y., Tang, P., Bai, X. 和 Liu,
    W. (2018). 重新审视多实例神经网络，Pattern Recognition 74: 15–24。'
- en: 'Wang et al. (2021) Wang, X., Yang, S., Zhang, J., Wang, M., Zhang, J., Huang,
    J., Yang, W. and Han, X. (2021). Transpath: Transformer-based self-supervised
    learning for histopathological image classification, International Conference
    on Medical Image Computing and Computer-Assisted Intervention, Springer, pp. 186–195.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 王等（2021）王旭、杨睿、张杰、王美、张捷、黄杰、杨威和韩旭（2021）。Transpath：基于变换器的自监督学习用于组织病理图像分类，《国际医学图像计算与计算机辅助手术会议》，Springer，第186–195页。
- en: Ward and Hawkins (2015) Ward, R. L. and Hawkins, N. J. (2015). Molecular and
    cellular oncology (mco) study tumour collection, UNSW Australia .
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 沃德和霍金斯（2015）沃德·R. L.和霍金斯·N. J.（2015）。分子和细胞肿瘤学（mco）研究肿瘤收集，澳大利亚新南威尔士大学。
- en: Wei et al. (2019) Wei, J. W., Tafe, L. J., Linnik, Y. A., Vaickus, L. J., Tomita,
    N. and Hassanpour, S. (2019). Pathologist-level classification of histologic patterns
    on resected lung adenocarcinoma slides with deep neural networks, Scientific Reports  9(1): 1–8.
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '魏等（2019）魏静文、塔夫·L. J.、林尼克·Y. A.、瓦伊克斯·L. J.、富田直和哈桑普尔（2019）。使用深度神经网络对切除的肺腺癌切片进行病理学模式的病理学家级分类，《科学报告》9(1):
    1–8。'
- en: Wessels et al. (2021) Wessels, F., Schmitt, M., Krieghoff-Henning, E., Jutzi,
    T., Worst, T. S., Waldbillig, F., Neuberger, M., Maron, R. C., Steeg, M., Gaiser,
    T. et al. (2021). Deep learning approach to predict lymph node metastasis directly
    from primary tumour histology in prostate cancer, BJU International  128(3): 352–360.
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '韦塞尔斯等（2021）韦塞尔斯、施密特、克雷霍夫-亨宁、朱茨、沃斯·T. S.、瓦尔比利希、纽伯格、马龙·R. C.、斯蒂格、盖瑟等（2021）。一种深度学习方法，用于直接从前列腺癌原发肿瘤组织学预测淋巴结转移，《BJU国际》128(3):
    352–360。'
- en: 'Weston et al. (2012) Weston, J., Ratle, F., Mobahi, H. and Collobert, R. (2012).
    Deep learning via semi-supervised embedding, Neural Networks: Tricks of the Trade,
    Springer, pp. 639–655.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 韦斯顿等（2012）韦斯顿、拉特尔、莫巴希和科洛贝尔（2012）。通过半监督嵌入进行深度学习，《神经网络：技术诀窍》，Springer，第639–655页。
- en: Woerl et al. (2020) Woerl, A.-C., Eckstein, M., Geiger, J., Wagner, D. C., Daher,
    T., Stenzel, P., Fernandez, A., Hartmann, A., Wand, M., Roth, W. et al. (2020).
    Deep learning predicts molecular subtype of muscle-invasive bladder cancer from
    conventional histopathological slides, European Urology  78(2): 256–264.
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '沃尔等（2020）沃尔·A.-C.、艾克斯坦、盖格尔、瓦格纳·D. C.、达赫、斯滕泽尔、费尔南德斯、哈特曼、万德、罗斯等（2020）。深度学习预测肌侵袭性膀胱癌的分子亚型，从传统组织病理切片中，《欧洲泌尿学》78(2):
    256–264。'
- en: Wu et al. (2015) Wu, J., Yu, Y., Huang, C. and Yu, K. (2015). Deep multiple
    instance learning for image classification and auto-annotation, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 3460–3469.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吴等（2015）吴峻、余阳、黄楚和余凯（2015）。用于图像分类和自动标注的深度多实例学习，《IEEE计算机视觉与模式识别会议论文集》，第3460–3469页。
- en: Xie, Dai, Hovy, Luong and Le (2020) Xie, Q., Dai, Z., Hovy, E., Luong, T. and Le,
    Q. (2020). Unsupervised data augmentation for consistency training, Advances in
    Neural Information Processing Systems  33: 6256–6268.
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '谢、戴、霍维、隆和乐（2020）谢强、戴志伟、霍维、隆涛和乐强（2020）。用于一致性训练的无监督数据增强，《神经信息处理系统进展》33: 6256–6268。'
- en: Xie, Chen, Li and Zheng (2020) Xie, X., Chen, J., Li, K. and Zheng, Y. (2020).
    Instance-aware self-supervised learning for nuclei segmentation, International
    Conference on Medical Image Computing and Computer-assisted Intervention, Springer,
    pp. 341–350.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 谢、陈、李和郑（2020）谢鑫、陈佳、李凯和郑颖（2020）。基于实例的自监督学习用于细胞核分割，《国际医学图像计算与计算机辅助手术会议》，Springer，第341–350页。
- en: 'Xu et al. (2019) Xu, G., Song, Z., Sun, Z., Ku, C., Yang, Z., Liu, C., Wang,
    S., Ma, J. and Xu, W. (2019). Camel: A weakly supervised learning framework for
    histopathology image segmentation, Proceedings of the IEEE/CVF International Conference
    on Computer Vision, pp. 10682–10691.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 徐等（2019）徐光、宋志、孙泽、库成、杨志、刘超、王晟、马杰和徐伟（2019）。Camel：用于组织病理图像分割的弱监督学习框架，《IEEE/CVF计算机视觉国际会议论文集》，第10682–10691页。
- en: Xu et al. (2020) Xu, J., Hou, J., Zhang, Y., Feng, R., Ruan, C., Zhang, T. and Fan,
    W. (2020). Data-efficient histopathology image analysis with deformation representation
    learning, 2020 IEEE International Conference on Bioinformatics and Biomedicine
    (BIBM), IEEE, pp. 857–864.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 徐等（2020）徐佳、侯俊、张艺、冯睿、阮晨、张婷和范伟（2020）。具有变形表示学习的数据高效组织病理图像分析，2020 IEEE国际生物信息学与生物医学会议（BIBM），IEEE，第857–864页。
- en: Xu et al. (2016) Xu, K., Su, H., Zhu, J., Guan, J.-S. and Zhang, B. (2016).
    Neuron segmentation based on cnn with semi-supervised regularization, Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 20–28.
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2016） Xu, K., Su, H., Zhu, J., Guan, J.-S. 和 Zhang, B.（2016）。基于CNN的神经元分割与半监督正则化，《IEEE计算机视觉与模式识别会议论文集》，第20–28页。
- en: Xu et al. (2022) Xu, L., Ouyang, W., Bennamoun, M., Boussaid, F. and Xu, D.
    (2022). Multi-class token transformer for weakly supervised semantic segmentation,
    arXiv preprint arXiv:2203.02891 .
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xu 等人（2022） Xu, L., Ouyang, W., Bennamoun, M., Boussaid, F. 和 Xu, D.（2022）。用于弱监督语义分割的多类标记转换器，arXiv
    预印本 arXiv:2203.02891。
- en: Yalniz et al. (2019) Yalniz, I. Z., Jégou, H., Chen, K., Paluri, M. and Mahajan,
    D. (2019). Billion-scale semi-supervised learning for image classification, arXiv
    preprint arXiv:1905.00546 .
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yalniz 等人（2019） Yalniz, I. Z., Jégou, H., Chen, K., Paluri, M. 和 Mahajan, D.（2019）。用于图像分类的十亿规模半监督学习，arXiv
    预印本 arXiv:1905.00546。
- en: Yan et al. (2018) Yan, Y., Wang, X., Guo, X., Fang, J., Liu, W. and Huang, J.
    (2018). Deep multi-instance learning with dynamic pooling, Asian Conference on
    Machine Learning, PMLR, pp. 662–677.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan 等人（2018） Yan, Y., Wang, X., Guo, X., Fang, J., Liu, W. 和 Huang, J.（2018）。具有动态池化的深度多实例学习，《亚洲机器学习会议》，PMLR，第662–677页。
- en: Yang et al. (2022) Yang, J., Ju, J., Guo, L., Ji, B., Shi, S., Yang, Z., Gao,
    S., Yuan, X., Tian, G., Liang, Y. et al. (2022). Prediction of her2-positive breast
    cancer recurrence and metastasis risk from histopathological images and clinical
    information via multimodal deep learning, Computational and Structural Biotechnology
    Journal  20: 333–342.
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人（2022） Yang, J., Ju, J., Guo, L., Ji, B., Shi, S., Yang, Z., Gao, S.,
    Yuan, X., Tian, G., Liang, Y. 等人（2022）。通过多模态深度学习从组织病理图像和临床信息中预测 HER2 阳性乳腺癌复发和转移风险，《计算与结构生物技术期刊》
    20: 333–342。'
- en: 'Yang et al. (2017) Yang, L., Zhang, Y., Chen, J., Zhang, S. and Chen, D. Z.
    (2017). Suggestive annotation: A deep active learning framework for biomedical
    image segmentation, International Conference on Medical Image Computing and Computer-assisted
    Intervention, Springer, pp. 399–407.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2017） Yang, L., Zhang, Y., Chen, J., Zhang, S. 和 Chen, D. Z.（2017）。建议性注释：一种用于生物医学图像分割的深度主动学习框架，《医学图像计算与计算机辅助干预国际会议》，Springer，第399–407页。
- en: Yang et al. (2021) Yang, P., Hong, Z., Yin, X., Zhu, C. and Jiang, R. (2021).
    Self-supervised visual representation learning for histopathological images, International
    Conference on Medical Image Computing and Computer-Assisted Intervention, Springer,
    pp. 47–57.
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等人（2021） Yang, P., Hong, Z., Yin, X., Zhu, C. 和 Jiang, R.（2021）。用于组织病理图像的自监督视觉表示学习，《医学图像计算与计算机辅助干预国际会议》，Springer，第47–57页。
- en: Yang et al. (2020) Yang, P., Zhai, Y., Li, L., Lv, H., Wang, J., Zhu, C. and Jiang,
    R. (2020). A deep metric learning approach for histopathological image retrieval,
    Methods  179: 14–25.
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang 等人（2020） Yang, P., Zhai, Y., Li, L., Lv, H., Wang, J., Zhu, C. 和 Jiang,
    R.（2020）。一种用于组织病理图像检索的深度度量学习方法，《方法》 179: 14–25。'
- en: Yao et al. (2020) Yao, J., Zhu, X., Jonnagaddala, J., Hawkins, N. and Huang,
    J. (2020). Whole slide images based cancer survival prediction using attention
    guided deep multiple instance learning networks, Medical Image Analysis  65: 101789.
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yao 等人（2020） Yao, J., Zhu, X., Jonnagaddala, J., Hawkins, N. 和 Huang, J.（2020）。基于全切片图像的癌症生存预测，使用注意力引导的深度多实例学习网络，《医学图像分析》
    65: 101789。'
- en: Yu et al. (2016) Yu, K.-H., Zhang, C., Berry, G. J., Altman, R. B., Ré, C.,
    Rubin, D. L. and Snyder, M. (2016). Predicting non-small cell lung cancer prognosis
    by fully automated microscopic pathology image features, Nature Communications  7(1): 1–10.
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yu 等人（2016） Yu, K.-H., Zhang, C., Berry, G. J., Altman, R. B., Ré, C., Rubin,
    D. L. 和 Snyder, M.（2016）。通过完全自动化的显微病理图像特征预测非小细胞肺癌预后，《自然通讯》 7(1): 1–10。'
- en: Zhang et al. (2016) Zhang, R., Isola, P. and Efros, A. A. (2016). Colorful image
    colorization, European Conference on Computer Vision, Springer, pp. 649–666.
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2016） Zhang, R., Isola, P. 和 Efros, A. A.（2016）。色彩丰富的图像上色，《欧洲计算机视觉会议》，Springer，第649–666页。
- en: Zhang et al. (2017) Zhang, Y., Yang, L., Chen, J., Fredericksen, M., Hughes,
    D. P. and Chen, D. Z. (2017). Deep adversarial networks for biomedical image segmentation
    utilizing unannotated images, International Conference on Medical Image Computing
    and Computer-assisted Intervention, Springer, pp. 408–416.
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等人（2017） Zhang, Y., Yang, L., Chen, J., Fredericksen, M., Hughes, D. P.
    和 Chen, D. Z.（2017）。利用未标注图像的深度对抗网络用于生物医学图像分割，《医学图像计算与计算机辅助干预国际会议》，Springer，第408–416页。
- en: Zhao et al. (2020) Zhao, Y., Yang, F., Fang, Y., Liu, H., Zhou, N., Zhang, J.,
    Sun, J., Yang, S., Menze, B., Fan, X. et al. (2020). Predicting lymph node metastasis
    using histopathological images based on multiple instance learning with deep graph
    convolution, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 4837–4846.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhao 等 (2020) Zhao, Y., Yang, F., Fang, Y., Liu, H., Zhou, N., Zhang, J., Sun,
    J., Yang, S., Menze, B., Fan, X. 等 (2020). 基于多实例学习与深度图卷积的组织病理图像预测淋巴结转移，IEEE/CVF计算机视觉与模式识别会议论文集，第4837–4846页。
- en: Zheng et al. (2019) Zheng, H., Yang, L., Chen, J., Han, J., Zhang, Y., Liang,
    P., Zhao, Z., Wang, C. and Chen, D. Z. (2019). Biomedical image segmentation via
    representative annotation, Proceedings of the AAAI Conference on Artificial Intelligence,
    Vol. 33, pp. 5901–5908.
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等 (2019) Zheng, H., Yang, L., Chen, J., Han, J., Zhang, Y., Liang, P.,
    Zhao, Z., Wang, C. 和 Chen, D. Z. (2019). 通过代表性注释进行生物医学图像分割，AAAI人工智能会议论文集，第33卷，第5901–5908页。
- en: Zhou et al. (2020) Zhou, Y., Chen, H., Lin, H. and Heng, P.-A. (2020). Deep
    semi-supervised knowledge distillation for overlapping cervical cell instance
    segmentation, International Conference on Medical Image Computing and Computer-Assisted
    Intervention, Springer, pp. 521–531.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等 (2020) Zhou, Y., Chen, H., Lin, H. 和 Heng, P.-A. (2020). 用于重叠宫颈细胞实例分割的深度半监督知识蒸馏，医学图像计算与计算机辅助干预国际会议，Springer，第521–531页。
- en: 'Zhou and Li (2005) Zhou, Z.-H. and Li, M. (2005). Tri-training: Exploiting
    unlabeled data using three classifiers, IEEE Transactions on Knowledge and Data
    Engineering  17(11): 1529–1541.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou 和 Li (2005) Zhou, Z.-H. 和 Li, M. (2005). 三重训练：利用三个分类器的无标签数据，IEEE知识与数据工程学报
    17(11): 1529–1541。'
- en: Zhou et al. (2021) Zhou, Z., Sodha, V., Pang, J., Gotway, M. B. and Liang, J.
    (2021). Models genesis, Medical Image Analysis  67: 101840.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Zhou 等 (2021) Zhou, Z., Sodha, V., Pang, J., Gotway, M. B. 和 Liang, J. (2021).
    模型起源，医学图像分析 67: 101840。'
- en: Zhu (2005) Zhu, X. J. (2005). Semi-supervised learning literature survey, CS
    Technical Reports .
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu (2005) Zhu, X. J. (2005). 半监督学习文献综述，计算机科学技术报告。
- en: 'Zhu et al. (2017) Zhu, X., Yao, J., Zhu, F. and Huang, J. (2017). Wsisa: Making
    survival prediction from whole slide histopathological images, Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition, pp. 7234–7242.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等 (2017) Zhu, X., Yao, J., Zhu, F. 和 Huang, J. (2017). Wsisa：从全切片组织病理图像中进行生存预测，IEEE计算机视觉与模式识别会议论文集，第7234–7242页。
- en: '[◄](/html/2208.08786) [![ar5iv homepage](img/ed0f3cf5a019c4f8e48e41de62929bb0.png)](/)
    [Feeling'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
  zh: '[◄](/html/2208.08786) [![ar5iv首页](img/ed0f3cf5a019c4f8e48e41de62929bb0.png)](/)
    [感觉]'
- en: lucky?](/feeling_lucky) [Conversion
  id: totrans-527
  prefs: []
  type: TYPE_NORMAL
  zh: '[幸运？](/feeling_lucky) [转换]'
- en: report](/log/2208.08789) [Report
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
  zh: '[报告](/log/2208.08789) [报告]'
- en: an issue](https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.08789)
    [View original
  id: totrans-529
  prefs: []
  type: TYPE_NORMAL
  zh: '[提出问题](https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.08789)
    [查看原文]'
- en: on arXiv](https://arxiv.org/abs/2208.08789)[►](/html/2208.08791)[](javascript:toggleColorScheme()
    "Toggle ar5iv color scheme")[Copyright](https://arxiv.org/help/license) [Privacy
    Policy](https://arxiv.org/help/policies/privacy_policy)Generated on Wed Mar 13
    16:26:27 2024 by [LaTeXML![Mascot Sammy](img/70e087b9e50c3aa663763c3075b0d6c5.png)](http://dlmf.nist.gov/LaTeXML/)
  id: totrans-530
  prefs: []
  type: TYPE_NORMAL
  zh: 在 arXiv 上](https://arxiv.org/abs/2208.08789)[►](/html/2208.08791)[](javascript:toggleColorScheme()
    "切换 ar5iv 颜色方案") [版权](https://arxiv.org/help/license) [隐私政策](https://arxiv.org/help/policies/privacy_policy)
    由 [LaTeXML ![吉祥物 Sammy](img/70e087b9e50c3aa663763c3075b0d6c5.png)](http://dlmf.nist.gov/LaTeXML/)
    生成于 2024年3月13日 星期三 16:26:27
