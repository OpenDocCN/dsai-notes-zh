- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:42:25'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2301.03362] Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2301.03362](https://ar5iv.labs.arxiv.org/html/2301.03362)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \headers
  prefs: []
  type: TYPE_NORMAL
- en: 'Image Denoising: The Deep Learning Revolution and Beyond M. Elad, B. Kawar
    and G. Vaksman'
  prefs: []
  type: TYPE_NORMAL
- en: 'Image Denoising: The Deep Learning Revolution and Beyond'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: – A Survey Paper –
  prefs: []
  type: TYPE_NORMAL
- en: Michael Elad    Bahjat Kawar and Gregory Vaksman
  prefs: []
  type: TYPE_NORMAL
- en: The Computer Science Department    Technion – Israel Institute of Technology
  prefs: []
  type: TYPE_NORMAL
- en: 'email: {elad    bahjat.kawar    grishavak}@cs.technion.ac.il'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Image denoising – removal of additive white Gaussian noise from an image – is
    one of the oldest and most studied problems in image processing. An extensive
    work over several decades has led to thousands of papers on this subject, and
    to many well-performing algorithms for this task. Indeed, ten years ago, these
    achievements have led some researchers to suspect that “Denoising is Dead”, in
    the sense that all that can be achieved in this domain has already been obtained.
    However, this turned out to be far from the truth, with the penetration of deep
    learning (DL) into the realm of image processing. The era of DL brought a revolution
    to image denoising, both by taking the lead in today’s ability for noise suppression
    in images, and by broadening the scope of denoising problems being treated. Our
    paper starts by describing this evolution, highlighting in particular the tension
    and synergy that exist between classical approaches and modern Artificial Intelligence
    (AI) alternatives in design of image denoisers.
  prefs: []
  type: TYPE_NORMAL
- en: The recent transitions in the field of image denoising go far beyond the ability
    to design better denoisers. In the second part of this paper we focus on recently
    discovered abilities and prospects of image denoisers. We expose the possibility
    of using image denoisers for service of other problems, such as regularizing general
    inverse problems and serving as the prime engine in diffusion-based image synthesis.
    We also unveil the (strange?) idea that denoising and other inverse problems might
    not have a unique solution, as common algorithms would have us believe. Instead,
    we describe constructive ways to produce randomized and diverse high perceptual
    quality results for inverse problems, all fueled by the progress that DL brought
    to image denoising.
  prefs: []
  type: TYPE_NORMAL
- en: This is a survey paper, and its prime goal is to provide a broad view of the
    history of the field of image denoising and closely related topics in image processing.
    Our aim is to give a better context to recent discoveries, and to the influence
    of the AI revolution in our domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Image denoising, Inverse problems, MMSE Estimation, Plug and Play Prior (PnP),
    Regularization by Denoising (RED), Langevin Dynamics, Diffusion Models, Image
    Synthesis, Perceptual Quality, Perception-Distortion Trade-off.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Within the wide fields of image processing and computational imaging, the task
    of image denoising has been given an exceptionally large attention over the past
    several decades. Indeed, noise suppression in images is one of the oldest and
    most studied problems in these fields, with numerous papers offering diverse algorithms,
    analysis of this task in various forms, or extensions of it.¹¹1See Figure [1](#S2.F1
    "Figure 1 ‣ 2.4 The Interest in Image Denoising ‣ 2 Image Denoising – Background
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    for the quantities of denoising related papers over the years. A substantial portion
    of the proposed denoising techniques has been dedicated to the removal of Additive
    White Gaussian Noise (AWGN) from images, while there are other contributions that
    target different noise distributions, e.g. Poisson, salt-and-pepper, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: Removal of noise from an image is an actual necessity that comes up with practically
    every imaging sensor [[191](#bib.bib191)]. However, the interest in this problem
    goes far beyond this practical need – image denoising is the simplest inverse
    problem, and as such, it has been recognized over the years as the perfect test-bed
    for assessing new ideas that are often brought to image processing. In recent
    years this appeal has further widened with the realization that denoisers can
    serve other imaging needs [[295](#bib.bib295), [231](#bib.bib231), [260](#bib.bib260)].
  prefs: []
  type: TYPE_NORMAL
- en: The years 1980 – 2010 have seen consistently improving denoising algorithms,
    many of which relying on the Bayesian point of view. This progress has been geared
    by an evolution of image priors that form the backbone of the overall progress
    in image processing. This path, which we will refer to as the *classical era*,
    started with the early $L_{2}$-based regularization, proceeding to robust statistics,
    moving to the introduction of wavelets, and the later deployment of partial differential
    equations to imaging tasks, and this continued all the way to sparse modeling,
    patch-based methods, and low-rank structure assumptions²²2As referencing this
    is too long, we provide specific citations to each of these in later sections..
    This extensive work over several decades has led to many well-performing denoising
    algorithms, and to a compelling and rich scientific field. In fact, ten years
    ago, these glorious achievements have led some researchers to consider the possibility
    that “Denoising is Dead”, believing that the existing solutions are already touching
    the achievable performance ceiling [[45](#bib.bib45), [162](#bib.bib162), [163](#bib.bib163)].
  prefs: []
  type: TYPE_NORMAL
- en: The past decade has brought a paradigm shift to the general topic of data processing
    due to the emergence of the Artificial Intelligence (AI) revolution. The great
    success of this deep learning (DL) trend has also introduced a reformation to
    the broad field of image processing, and to image denoising in particular. These
    new winds led to novel techniques for designing better performing denoisers [[50](#bib.bib50),
    [330](#bib.bib330), [167](#bib.bib167), [332](#bib.bib332), [270](#bib.bib270),
    [159](#bib.bib159), [8](#bib.bib8), [339](#bib.bib339), [165](#bib.bib165)], and
    discovering new and more daring ways for deploying them and broadening their scope [[1](#bib.bib1),
    [170](#bib.bib170), [323](#bib.bib323), [288](#bib.bib288), [102](#bib.bib102),
    [166](#bib.bib166), [146](#bib.bib146), [212](#bib.bib212), [113](#bib.bib113)].
    These days, deep-learning based denoisers are at the very top in their ability
    for noise suppression in images (see e.g. [[330](#bib.bib330), [165](#bib.bib165),
    [322](#bib.bib322)], leaving no competitive room for the classical alternatives).
  prefs: []
  type: TYPE_NORMAL
- en: 'In parallel to the above and seemingly detached from the deep learning activity,
    image denoising has been also a topic of investigation and discoveries of a different
    flavor: Harnessing denoiser engines for other imaging tasks. This started with
    the surprising idea that a good performing denoiser can serve as a prior, offering
    a highly effective regularization to inverse problems [[295](#bib.bib295), [231](#bib.bib231),
    [28](#bib.bib28), [139](#bib.bib139), [283](#bib.bib283), [268](#bib.bib268),
    [192](#bib.bib192), [280](#bib.bib280), [49](#bib.bib49), [55](#bib.bib55)]. This
    continued with the discovery that such denoisers can also be used for randomly
    synthesizing images by offering a practical sampling from the prior distribution
    of images, this way posing a potent competition to Generative Adversarial Networks
    (GANs) and other image generation methods [[260](#bib.bib260), [261](#bib.bib261),
    [262](#bib.bib262), [120](#bib.bib120), [287](#bib.bib287), [68](#bib.bib68),
    [122](#bib.bib122), [143](#bib.bib143), [121](#bib.bib121)].'
  prefs: []
  type: TYPE_NORMAL
- en: An intriguing sequel to the above synthesis revelation is the idea that solution
    of inverse problems could be revisited and posed as a sampling task from the posterior
    distribution of the image given the measurements, thus resorting again to image
    denoisers as the means for obtaining these solutions. This very recent line of
    work unveiled the daring idea that denoising and other inverse problems might
    not have a unique solution, as common algorithms would have us believe [[212](#bib.bib212),
    [146](#bib.bib146), [138](#bib.bib138), [145](#bib.bib145), [211](#bib.bib211)].
    Instead, this sampling approach has been shown to lead to constructive ways for
    producing randomized and diverse *high perceptual quality* results for inverse
    problems, exposing as a byproduct the inner uncertainty in such tasks.
  prefs: []
  type: TYPE_NORMAL
- en: All the above achievements have been strongly influenced and fueled by the progress
    that DL brought to image denoising. Adopting a wider perspective, image denoising
    these days has new horizons, and if any conclusion can be drawn from these recent
    accomplishments, it would be that this field is a very much alive playground with
    great challenges and prospects. This paper aims to disclose and detail the compelling
    story drawn above. Our prime goal is to provide a broad view of the history of
    the field of image denoising and closely related topics in image processing, give
    a better context to recent discoveries, and highlight the influence of the AI
    revolution in our domain.
  prefs: []
  type: TYPE_NORMAL
- en: 'We start our journey in Section [2](#S2 "2 Image Denoising – Background ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") by clearly
    defining the image denoising task, discussing its ill-posed nature, and demonstrating
    its appeal over the years. We proceed in Sections [3](#S3 "3 Image Denoising –
    The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –") and [4](#S4 "4 Image Denoising – The Deep Learning Revolution
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    by describing the evolution of image denoisers, from the classical era to the
    deep-learning-based alternatives. Section [5](#S5 "5 Synergy between Classics
    and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –") highlights the tension and the possible synergy that exists
    between classical approaches and modern Artificial Intelligence (AI) alternatives
    in design of image denoisers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In the second part of the paper we change gears and move to discuss three recent
    discoveries that consider image denoisers as building blocks for other needs.
    We start broadly in Section [6](#S6 "6 Image Denoising – Migration towards Recent
    Discoveries ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") by defining the denoiser engine and its properties, and set the stage
    for the presentation of these three discoveries. We proceed in Section [7](#S7
    "7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") by discussing the
    ability to deploy these engines for regularizing inverse problems. Section [8](#S8
    "8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") exposes the possibility of
    synthesizing images using such denoisers, and Section [9](#S9 "9 Discovery 3:
    High Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") presents the notion of targeting perfect perceptual
    quality outcomes in image denoising and inverse problems by sampling from the
    posterior distribution. We conclude this paper in Section [10](#S10 "10 Conclusion
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    with an attempt to point to open questions and potential research directions.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Disclaimer:* While this paper aims to present a survey on the various ups
    and downs that the field of image denoising has gone through over the years, it
    would be simply impossible to do justice to all the published literature in this
    domain. We apologize if some papers are omitted from our references, as we attempt
    to mark the critical milestones in the history of this field. The interested reader
    is referred to [[156](#bib.bib156), [197](#bib.bib197), [130](#bib.bib130), [18](#bib.bib18),
    [92](#bib.bib92), [281](#bib.bib281)] for other surveys with different orientations.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Image Denoising – Background
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 2.1 Problem Definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Our story must start with a proper definition of the denoising problem, and
    this will also serve the need for defining our notations hereafter. An ideal image³³3For
    simplicity of the discussion, assume that we refer to grayscale images. Addressing
    color is discussed shortly in Section [4](#S4 "4 Image Denoising – The Deep Learning
    Revolution ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –"). ${\mathbf{x}}\in\mathbb{R}^{N}$ is assumed to be drawn from the image
    manifold, represented by the probability density function $p({\mathbf{x}})$. Our
    measurement is the vector ${\mathbf{y}}\in\mathbb{R}^{N}$, given by'
  prefs: []
  type: TYPE_NORMAL
- en: '| (1) |  | $\displaystyle{\mathbf{y}}={\mathbf{x}}+{\mathbf{v}},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\mathbf{v}}\in\mathbb{R}^{N}$ is a zero-mean independent and identically
    distributed (i.i.d.) Gaussian noise, i.e. ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$.
    The denoising task is the recovery of ${\mathbf{x}}$ from ${\mathbf{y}}$ with
    the knowledge of $\sigma$, and a denoiser is thus a function of the form $\hat{{\mathbf{x}}}=D({\mathbf{y}},\sigma)$.
  prefs: []
  type: TYPE_NORMAL
- en: While there are many ways for assessing the performance of such denoisers, the
    most common one is the Mean-Squared-Error (MSE) measure,
  prefs: []
  type: TYPE_NORMAL
- en: '| (2) |  | $\displaystyle MSE=\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\mathbb{E}\left(\&#124;{\mathbf{x}}-D({\mathbf{y}},\sigma)\&#124;_{2}^{2}\right),$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where the expectation is taken over the image distribution. A well-known result
    in estimation theory states that the best denoising with respect to this measure
    (i.e., achieving the Minimum MSE, thus referred to as MMSE) is given by [[217](#bib.bib217)],
  prefs: []
  type: TYPE_NORMAL
- en: '| (3) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: This formula is misleadingly simple in its concise form, as designing a denoiser
    that achieves MMSE is quite challenging and oftentimes simply impossible. By the
    way, the curious reader may wonder why are we emphasizing the MSE measure and
    the MMSE denoiser. The answer will be carefully unfolded in the later parts of
    the paper, where these choices play a critical role. A brief note about this appears
    later in this section.
  prefs: []
  type: TYPE_NORMAL
- en: How hard is it to denoise an image? How complicated could it be? Again, the
    simplicity of the problem definition is illusive, as this task is highly tough
    and in fact ill-posed. One could easily design a filtering method for attenuating
    and suppressing the noise in ${\mathbf{y}}$, but such a process is very likely
    to ruin the image content as well, losing small details, sacrificing edges, damaging
    fine textures, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 The Gaussianity Assumption
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the problem definition above we focused on a very specific case of a zero-mean
    i.i.d. Gaussian noise contamination. The natural question arising is why are we
    restricting the discussion to this case? A brief inspection of the literature
    on image denoising reveals that this noise model is very popular, covered by most
    of the developed algorithms. Where this popularity comes from? Several answers
    come to mind:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Central Limit Theorem: Noise in imaging may arise due to many physical reasons,
    and their accumulation leads often to a Gaussian distribution of the form discussed
    above, as an empirical manifestation of the Central Limit Theorem [[277](#bib.bib277),
    [127](#bib.bib127)]. As such, rather than modelling the intricate noise origins,
    a Gaussian assumption offers a blessed simplification for the later analysis and
    algorithm development in this field.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Poisson Alternative: One might rightfully argue that the proper distribution
    to address for imaging noise would be the Poisson one, as imaging sensors essentially
    count photons, and their arrival is of Poissonian nature [[59](#bib.bib59)]. While
    this argument is indeed correct, when photon counts are high, the Poisson distribution
    becomes a Gaussian one [[26](#bib.bib26)]. If the counts are low, a variance stabilizing
    transform, such as *Anscombe* [[7](#bib.bib7)], can turn these measurements into
    additive Gaussian contaminated, again resorting to the Gaussianity regime [[81](#bib.bib81),
    [325](#bib.bib325), [233](#bib.bib233), [184](#bib.bib184), [12](#bib.bib12),
    [272](#bib.bib272), [334](#bib.bib334)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mathematical Elegance: The Gaussian case is easily modeled, and consequent
    formulations become simple and elegant. Such is the case with the log-likelihood
    function $p({\mathbf{y}}|{\mathbf{x}})$ and other related derivations that will
    be shown in subsequent sections.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MMSE Denoiser Engines: Our last argument for the Gaussianity assumption is
    quite surprising and unfamiliar to many in our field. As it turns out, an MMSE
    denoiser for the removal of zero-mean i.i.d. Gaussian noise is of great theoretical
    importance. Such an engine has critical properties that enable its deployment
    as a prior (see Section [7](#S7 "7 Discovery 1: Solving Inverse Problems via Image
    Denoisers ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –")) for inverse problems. In addition, and perhaps more importantly, such
    denoisers have strong theoretical ties to the *score function* [[260](#bib.bib260)],
    a fact that will be highlighted and exploited in Sections [8](#S8 "8 Discovery
    2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")-[9.2](#S9.SS2 "9.2 High Perceptual Quality Solution
    to Inverse Problems ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –").'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 2.3 Extensions of Image Denoising
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are many variations to the core image denoising task mentioned above.
    These can be roughly divided into four sub-categories: (i) Handling different
    noise statistics; (ii) Addressing structured noise removal; (iii) Considering
    different and various visual content; and (iv) Posing different problem assumptions
    and settings. Lets us briefly describe each of these.'
  prefs: []
  type: TYPE_NORMAL
- en: A natural extension of the original denoising problem posed above is to consider
    other noise statistics, such as Poisson (also referred to as shot-noise) denoising [[93](#bib.bib93),
    [248](#bib.bib248), [100](#bib.bib100), [65](#bib.bib65), [325](#bib.bib325),
    [291](#bib.bib291), [233](#bib.bib233), [184](#bib.bib184), [226](#bib.bib226),
    [12](#bib.bib12)], salt-and-pepper noise removal [[40](#bib.bib40), [264](#bib.bib264),
    [75](#bib.bib75), [300](#bib.bib300), [210](#bib.bib210)], treating mixtures of
    Poisson and Gaussian noise [[176](#bib.bib176), [326](#bib.bib326), [184](#bib.bib184)],
    and more. Other extensions consider structured noise, such as quantization noise
    in compression artifact removal [[206](#bib.bib206), [176](#bib.bib176), [297](#bib.bib297),
    [63](#bib.bib63), [106](#bib.bib106)], film-grain removal [[312](#bib.bib312),
    [311](#bib.bib311), [62](#bib.bib62)], and textured or otherwise colored noise [[108](#bib.bib108),
    [193](#bib.bib193), [3](#bib.bib3), [219](#bib.bib219)]. Another challenging task
    is noise removal in scenarios in which the noise is not spatially homogeneous,
    such as white noise with spatially varying $\sigma$ [[187](#bib.bib187), [332](#bib.bib332),
    [344](#bib.bib344), [148](#bib.bib148)]. The inpainting problem [[90](#bib.bib90),
    [182](#bib.bib182), [306](#bib.bib306), [134](#bib.bib134)] can be regarded as
    a special such case, where portions of the image are simply missing and need to
    be revived. These missing pixels can be regarded as contaminated by a very strong
    noise, while other regions of the image are reliably measured.
  prefs: []
  type: TYPE_NORMAL
- en: The denoising task may assume a different setting altogether if the visual content
    is of different form. Such an example is noise reduction in bursts of snapshots [[173](#bib.bib173),
    [102](#bib.bib102), [198](#bib.bib198), [189](#bib.bib189), [86](#bib.bib86),
    [166](#bib.bib166), [80](#bib.bib80)], where several images are treated jointly.
    Somewhat similar yet different is the task of video denoising [[179](#bib.bib179),
    [9](#bib.bib9), [10](#bib.bib10), [275](#bib.bib275), [276](#bib.bib276), [290](#bib.bib290),
    [259](#bib.bib259), [180](#bib.bib180), [322](#bib.bib322), [161](#bib.bib161)],
    in which we may seek online filtering of the incoming frames. When handling specific
    imaging types (e.g., microscopy [[223](#bib.bib223), [25](#bib.bib25), [13](#bib.bib13),
    [103](#bib.bib103), [340](#bib.bib340), [186](#bib.bib186), [158](#bib.bib158),
    [188](#bib.bib188)], CT [[164](#bib.bib164), [48](#bib.bib48), [318](#bib.bib318),
    [316](#bib.bib316), [70](#bib.bib70), [314](#bib.bib314)] and PET/SPECT imaging [[51](#bib.bib51),
    [82](#bib.bib82), [105](#bib.bib105), [227](#bib.bib227), [343](#bib.bib343),
    [266](#bib.bib266)], and more), the algorithm design may require adequate adaptations
    to the data format (e.g. treating 3D volumes [[294](#bib.bib294), [336](#bib.bib336),
    [324](#bib.bib324), [64](#bib.bib64), [178](#bib.bib178)]) or to the way it is
    captured.
  prefs: []
  type: TYPE_NORMAL
- en: The last category of extensions has to do with our prior knowledge when addressing
    denoising tasks. Blind denoising [[131](#bib.bib131), [169](#bib.bib169), [157](#bib.bib157),
    [47](#bib.bib47), [201](#bib.bib201), [256](#bib.bib256), [342](#bib.bib342),
    [321](#bib.bib321), [114](#bib.bib114)] refers to the case in which the noise
    is known to be i.i.d. Gaussian, but $\sigma$ is unknown, and may be even spatially
    changing. A more complex situation is when the noise statistics are totally unknown [[345](#bib.bib345),
    [8](#bib.bib8), [2](#bib.bib2), [307](#bib.bib307)]. In this context, a special
    case of great interest in recent years is removal of true noise from given images
    captured by digital cameras (e.g., cellphones) [[298](#bib.bib298), [149](#bib.bib149),
    [170](#bib.bib170), [285](#bib.bib285), [301](#bib.bib301), [128](#bib.bib128)].
  prefs: []
  type: TYPE_NORMAL
- en: 2.4 The Interest in Image Denoising
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2.4 The Interest in Image Denoising ‣ 2 Image
    Denoising – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") presents a graph showing the number of papers that have been
    published each year on the topic of image denoising. Overall, nearly $30,000$
    such papers are identified by Clarivate Web-Of-Science (WoS), published mostly
    in the past 25 years. As such, this is clearly one of the most heavily studied
    topics in image processing, and perhaps in exact sciences in general. Also evident
    from this graph is the consistent growth over the years in this topic. Where does
    this popularity come from?'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/041a2c93df50c403dc35a6de53d3da69.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: The number of papers on the image denoising topic over the years.
    This graph corresponds to the search topic=((image or video ) and (denoising or
    (noise and remov) or clean)) performed on December 1st 2022 in Clarivate Web-of-Science
    (WoS). Note that the lower count in 2022 does not stand for a new trend, but rather
    caused by a delayed reporting of new papers.'
  prefs: []
  type: TYPE_NORMAL
- en: A prime reason to study image denoising is its practical relevance to imaging
    systems. Removal of noise from acquired visual information is an actual necessity
    that comes up with practically every imaging sensor [[191](#bib.bib191)]. Thus,
    various algorithms have been developed for implementation in image processing
    software packages and within the ISP (Image Signal Processor) – the path that
    starts with the raw acquired data and ends with a high quality image – of every
    digital camera [[23](#bib.bib23), [30](#bib.bib30), [298](#bib.bib298), [338](#bib.bib338),
    [124](#bib.bib124)].
  prefs: []
  type: TYPE_NORMAL
- en: Beyond the obvious practical motivation described above, the interest in image
    denoising has other, more profound, roots. Image denoising is the simplest inverse
    problem, and as such, it has been recognized over the years as the perfect platform
    for assessing new ideas that are often brought to image processing. Indeed, all
    the major milestone advancements in image processing started with denoising experiments,
    so as to explore their validity to visual data. This was the case with Tikhonov-Arsenin’s
    regularization theory [[282](#bib.bib282), [104](#bib.bib104)], Wavelets [[185](#bib.bib185)],
    non–linear filtering based on partial differential equations [[302](#bib.bib302),
    [111](#bib.bib111)], sparse modeling of data [[31](#bib.bib31), [88](#bib.bib88)],
    and more. All these and many other sub-fields in imaging sciences saw image denoising
    as a critical first step in their diffusion into broad image processing tasks.
    We discuss these in greater details in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: The above two reasons for the popularity of image denoising may account for
    many of the published papers in this domain. However, the reason we have chosen
    to write this paper has to do with a third, and very different, origin of popularity.
    Image denoising has gained much interest and appeal in recent years due to the
    surprising realization that denoisers can serve other imaging needs, thus widening
    their scope and influence [[295](#bib.bib295), [231](#bib.bib231), [260](#bib.bib260),
    [120](#bib.bib120), [145](#bib.bib145)]. This discovery relies on a fundamental
    theoretical connection between denoisers and the prior distribution of images [[200](#bib.bib200),
    [265](#bib.bib265), [84](#bib.bib84)]. This bridge provides a solid and well-motivated
    approach to old and new tasks in image processing. In fact, this is the topic
    we shall be highlighting in the latter sections of our paper. We thus defer a
    more detailed explanation of these ideas.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Image Denoising – The Classic Era
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: So far we have discussed image denoisers without concretely diving into the
    actual quest of their construction. So, how can we design an image denoiser? Not
    so surprisingly, the answer to this question has evolved and changed over the
    years, with the accumulated knowledge and the progress in signal and image processing.
    And still, we may broadly separate this progress in design of image denoisers
    into two eras - the classical one that started in the 70’s and ended in the past
    decade, and the AI revolution era that started around 2012 and is very much vivid
    till this day. In this section we shall focus on the classical algorithms, and
    more specifically on the Bayesian point of view that played a key role in their
    creation.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 The Bayesian Point of View for Design of Denoisers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Starting with Equation ([1](#S2.E1 "Equation 1 ‣ 2.1 Problem Definition ‣ 2
    Image Denoising – Background ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –")), given the noisy image ${\mathbf{y}}$ and knowing
    that ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$, our goal
    is to estimate ${\mathbf{x}}$. A simple approach towards this task would be the
    Maximum-Likelihood Estimation (MLE) [[205](#bib.bib205), [235](#bib.bib235)],
    seeking $\hat{{\mathbf{x}}}$ that maximizes the conditional probability $p({\mathbf{y}}|{\mathbf{x}})$,
    essentially maximizing the likelihood of the given measurements ${\mathbf{y}}$.
    Due to the Gaussianity of the noise, this probability is given easily by'
  prefs: []
  type: TYPE_NORMAL
- en: '| (4) |  | $\displaystyle p({\mathbf{y}}&#124;{\mathbf{x}})=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'and maximizing it amounts to the trivial and fruitless solution: ${\hat{\mathbf{x}}}_{MLE}={\mathbf{y}}$.
    This outcome is a direct manifestation of the ill-posedness of the denoising problem,
    exposing the need for more information for its solution.'
  prefs: []
  type: TYPE_NORMAL
- en: '| (5) |  | $\displaystyle p({\mathbf{x}}&#124;{\mathbf{y}})=\frac{p({\mathbf{y}}&#124;{\mathbf{x}})\cdot
    p({\mathbf{x}})}{p({\mathbf{y}})}=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\}\cdot
    p({\mathbf{x}}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: In the last equality we have absorbed the denominator $p({\mathbf{y}})$ into
    the constant as it is independent of ${\mathbf{x}}$. While this expression is
    a simple modification to the MLE (multiplying the likelihood by the prior $p({\mathbf{x}})$),
    this is in fact a significant change, as it regularizes the inversion process
    from ${\mathbf{y}}$ to ${\mathbf{x}}$.
  prefs: []
  type: TYPE_NORMAL
- en: Two commonly used estimators that exploit $p({\mathbf{x}}|{\mathbf{y}})$ are
    the MAP and the MMSE. The first is obtained by maximizing this posterior, leading
    to the Maximum A’Posteriori Probability (MAP) estimation [[205](#bib.bib205),
    [235](#bib.bib235)], given by⁴⁴4This minimization is obtained by taking the $-\log$
    of the above expression.
  prefs: []
  type: TYPE_NORMAL
- en: '| (6) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: As opposed to the MLE, ${\hat{\mathbf{x}}}_{MAP}$ is dictated by two forces,
    the first pulling it towards ${\mathbf{y}}$, while the other seeks a “well-behaved”
    result that leads to a low value of $-\log\left(p({\mathbf{x}})\right)$ – this
    is exactly the regularization mentioned above.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similarly, the MMSE estimation [[132](#bib.bib132)] is also reliant on the
    posterior probability obtained, as shown in Equation ([3](#S2.E3 "Equation 3 ‣
    2.1 Problem Definition ‣ 2 Image Denoising – Background ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –")), via⁵⁵5See Appendix
    [A](#A1 "Appendix A Derivation of the MMSE Estimation ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") for a derivation of this statement.'
  prefs: []
  type: TYPE_NORMAL
- en: '| (7) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right)=\int_{\mathbf{x}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: While this expression is very concise and clear, operating with it has proven
    to be quite challenging due to the need for the partition function – the normalizing
    factor of this distribution. This explains the vast popularity of the MAP-based
    approach among the classical methods.
  prefs: []
  type: TYPE_NORMAL
- en: Be it the MAP or the MMSE, the Bayesian point of view requires access to $p({\mathbf{x}})$
    or proxies of it. This brings us to the next discussion on the evolution of priors
    in image processing and their impact on the design of denoisers.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Evolution of Priors
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A key player in image processing is the prior, $p({\mathbf{x}})$, the probability
    density function of the image distribution. Modeling $p({\mathbf{x}})$ and using
    it for problems in visual data processing have served as the skeleton of our field,
    and defined its trajectory over the years. Below we outline the central milestones
    in the evolution of modeling $p({\mathbf{x}})$.
  prefs: []
  type: TYPE_NORMAL
- en: 'One critical theme to remember is the fact that the expression $-\log(p({\mathbf{x}}))$,
    which appears in the popular MAP estimation (see equation ([6](#S3.E6 "Equation
    6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers ‣ 3 Image Denoising
    – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –"))), should assume a closed-form expression so as to lend itself
    to a manageable numerical optimization. For this reason, most attempts to characterize
    $p({\mathbf{x}})$ have chosen to use the Gibbs distribution form [[132](#bib.bib132)],
    $p({\mathbf{x}})=c\cdot\exp\{-\rho({\mathbf{x}})\}$, shifting our focus from $p({\mathbf{x}})$
    to the energy function $\rho({\mathbf{x}})$.'
  prefs: []
  type: TYPE_NORMAL
- en: 'So, what should $\rho({\mathbf{x}})$ be to properly describe the image distribution?
    In order to keep this discussion concise, we present in Table [1](#S3.T1 "Table
    1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") a brief list of possible
    analytical expressions for this function, without diving into their meaning, inter-relations,
    and effect. A more detailed explanation of these expressions is provided in Appendix
    [B](#A2 "Appendix B A Closer Look at the Evolution of Priors ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). Please bear in mind
    the fact that this naïve approach of choosing an expression for $\rho({\mathbf{x}})$
    is nothing short of a fantastic feat – can we really expect a simple formula to
    grasp the richness of the image content distribution?'
  prefs: []
  type: TYPE_NORMAL
- en: 'The evolution of the ideas in Table [1](#S3.T1 "Table 1 ‣ 3.2 Evolution of
    Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") is characterized by several major and
    interconnected trends – the migration from the familiar Gaussian distribution
    to the less intuitive heavy-tailed ones, the departure from $L_{2}$ to sparsity-promoting
    measures such as the $L_{1}$, the drift from linear approximation techniques (e.g.
    PCA) to non-linear ones (e.g. wavelets and sparse modeling), and above all, the
    replacement of axiomatic expressions with learned priors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Evolution of priors for images.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Years | Core concept | Formulae for $\rho(\cdot)$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| $\sim$ 1970 | Energy regularization | $\&#124;{\mathbf{x}}\&#124;_{2}^{2}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1975-1985 | Spatial smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{2}^{2}$
    or $\&#124;{\mathbf{D}}_{v}{\mathbf{x}}\&#124;_{2}^{2}+\&#124;{\mathbf{D}}_{h}{\mathbf{x}}\&#124;_{2}^{2}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1980-1985 | Optimally Learned Transform | $\&#124;{\mathbf{T}}{\mathbf{x}}\&#124;_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    (via PCA) |'
  prefs: []
  type: TYPE_TB
- en: '| 1980-1990 | Weighted smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{{\mathbf{W}}}^{2}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1990-2000 | Robust statistics | ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    e.g., Hubber-Markov |'
  prefs: []
  type: TYPE_TB
- en: '| 1992-2005 | Total-Variation | $\int_{v\in\Omega}&#124;\nabla{\mathbf{x}}(v)&#124;dv={\mathbf{1}}^{T}\sqrt{&#124;{\mathbf{D}}_{v}{\mathbf{x}}&#124;^{2}+&#124;{\mathbf{D}}_{h}{\mathbf{x}}&#124;^{2}}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1987-2005 | Other PDE-based options | $\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2005-2009 | Field-of-Experts | $\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 1993-2005 | Wavelet sparsity | $\&#124;{\mathbf{W}}{\mathbf{x}}\&#124;_{1}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2000-2010 | Self-similarity | $\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\}$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2002-2012 | Sparsity methods | $\&#124;\alpha\&#124;_{0}~{}s.t.~{}{\mathbf{x}}={\mathbf{D}}\alpha$
    |'
  prefs: []
  type: TYPE_TB
- en: '| 2010-2017 | Low-Rank assumption | $\sum_{k}\&#124;{\mathbf{X}}_{\Omega(k)}\&#124;_{*}$
    |'
  prefs: []
  type: TYPE_TB
- en: 3.3 Other Classical Denoisers
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: While the above-described Bayesian approach has proven to be quite productive,
    yielding a wide variety of denoising methods, alternative and more direct design
    techniques for such algorithms were also considered. Here we mention few such
    methods, some relying on the general notion of spatially adaptive smoothing of
    image content, while others leverage self-similarity that often-times exists in
    images.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider the following rough motivating idea: Recall that a denoiser should
    attenuate random i.i.d. Gaussian noise while preserving the image content. When
    operating on a noisy pixel $y[i,j]$, our intuitive strategy is to open a neighborhood
    around it, $\Omega[i,j]$, for averaging purposes. If it so happens that the local
    image content in $\Omega[i,j]$ behaves like a tilted plane, a simple averaging
    of these neighborhood pixels would provide a perfect local noise suppression.
    When the local behavior deviates from this simple structure, the averaging mask
    should take this into account and adapt accordingly.'
  prefs: []
  type: TYPE_NORMAL
- en: This is exactly the idea behind the Bilateral filter [[284](#bib.bib284), [87](#bib.bib87)]
    and the Beltrami-Flow [[255](#bib.bib255)], in which the averaging weight takes
    into account two forces – (i) the proximity of the weighted pixel to the center
    of the neighborhood; and (ii) the proximity of this pixel’s value to the center
    pixel’s value, indicating its relevance to the averaging. Computing these weights
    for each pixel $y[i,j]$ and normalizing them to sum to one creates the local averaging
    kernel to apply. This way, if $\Omega[i,j]$ covers an edge between two regions,
    averaging will be restricted to the “relevant” pixels while discarding others.
    Non-Local-Means [[32](#bib.bib32)] takes this approach one step further by widening
    $\Omega[i,j]$ to a semi-local region, and by assessing pixels’ relevance to the
    averaging by patch-matching instead of scalar value comparisons. This way we keep
    the spatially adaptive averaging concept, but robustify it and make it non-local.
    Kernel-regression [[271](#bib.bib271)] is also a spatially adaptive averaging
    technique, but one that relies on a local parametric estimation of the pixels’
    gray-values in $\Omega[i,j]$. A 2D Gaussian is fitted to the pixels in $\Omega[i,j]$,
    dictating its orientation and span, and this way offering a smoothing along edges
    instead of across ones.
  prefs: []
  type: TYPE_NORMAL
- en: Another direct image denoising method that deserves our specific attention,
    especially due to its superior performance, is the BM3D algorithm [[61](#bib.bib61)].
    This technique relies on the expectation that 2D-DCT transformed local patches
    in natural images are expected to be sparse. Furthermore, by gathering groups
    of similar patches from the overall image area, this transformed sparsity should
    align in support. Thus, BM3D builds a 3D cube of similar patches for each pixel
    $y[i,j]$, transforms this cube together and forces a joint sparsity outcome. Among
    the classical denoising algorithms, BM3D is considered among the very best approaches
    in terms of MSE results. In this context, we also mention the Weighted Nuclear
    Norm Minimization (WNNM) denoising method [[110](#bib.bib110)] and its followups
    (e.g. [[310](#bib.bib310)]). These rely on a similar rationale to the BM3D, but
    replace the joint sparsity by a low-rank assumption.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Is denoising dead?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The paper “Is Denoising Dead?”, published in 2009 by Chatterjee and Milanfar [[45](#bib.bib45)],
    exposed a disturbing feeling shared by many in our community at the time – a suspicion
    that we are touching the ceiling in terms of denoising ability. This impression
    relied on the considerable progress in design of denoising algorithms during the
    preceding years, and the fact that very different approaches towards this problem
    were found to lead to comparable denoising performance. A followup work [[162](#bib.bib162),
    [163](#bib.bib163)] by Levin and Nadler in 2011-2012 addressed the same question.
    Both lines of work suggested a derivation of an approximated lower-bound of the
    MSE for noise removal ability. Without diving into the specifics of their derivations,
    we should mention that both concluded that there is still room for some improvement,
    even though this claim was not made constructively, leaving the question of how
    to obtain better techniques vague at best.
  prefs: []
  type: TYPE_NORMAL
- en: 'From a practical point of view, and despite these optimistic conclusions, the
    progress in denoising performance after 2010-2011 was very slow and of diminishing
    returns. Indeed, the graph in Figure [1](#S2.F1 "Figure 1 ‣ 2.4 The Interest in
    Image Denoising ‣ 2 Image Denoising – Background ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") shows a decrease in the number of papers
    on image denoising around 2010\. However, this setback held true mostly for classically
    oriented methods of the kind discussed above. The emergence of deep neural networks
    brought a massive change to our domain, shattering the common belief about the
    end of this field, and the folklore around the attained performance limit.'
  prefs: []
  type: TYPE_NORMAL
- en: Indeed, deep learning brought new ways for the design of highly effective image
    denoisers, taking the lead in today’s ability for noise suppression in images.
    However, the AI revolution had a much wider impact on the image denoising task,
    opening new horizons to possibilities and abilities never dealt with before. Among
    many such directions, these include (i) image adaptation; (ii) true noise removal;
    and (iii) addressing new denoising objectives. In the following section we discuss
    all these with much greater details.
  prefs: []
  type: TYPE_NORMAL
- en: 'While the past decade can certainly be titled as the era of AI revolution,
    there has been another revolution, perhaps of a bigger scale, that took place
    in parallel in the field of image processing – one that refers to the discovery
    that an image denoiser can serve other tasks. From the seminal paper on the Plug-and-Play
    Priors [[295](#bib.bib295)], through Regularization by Denoising paper [[231](#bib.bib231)],
    and all the way to the recent and exciting diffusion-based image synthesis [[260](#bib.bib260),
    [120](#bib.bib120)], image denoisers are taking a new and much more exciting role
    in image processing. As this is the main theme of this paper, We shall expand
    on this line of work in Section [6](#S6 "6 Image Denoising – Migration towards
    Recent Discoveries ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") and after.'
  prefs: []
  type: TYPE_NORMAL
- en: So, to summarize, for the question ‘is denoising dead?’ our answer is ‘definitely
    not!’, and this is due to the vast influence of deep learning, and other new directions
    that brought new life to this domain. The rest of this paper is dedicated to the
    description of these developments and their impact and prospects.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Image Denoising – The Deep Learning Revolution
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The recently discovered ability to effectively train deep neural networks for
    classification, regression and other tasks should not be taken lightly. Nothing
    in this process is well-understood or well-justified. Indeed, the opposite is
    true – with overparametrized networks and a highly non-convex objective function,
    it is quite surprising that such networks are able to learn and generalize at
    all. And yet they do! This is the essence of the AI revolution that has found
    its way to so many fields, impacting each in a profound way.
  prefs: []
  type: TYPE_NORMAL
- en: Image processing and computational imaging is yet another playground that has
    been deeply influenced by this AI revolution. Today’s practice and theory in image
    processing is entirely different from the ones considered only 10 years ago. Indeed,
    image processing undergraduate and graduate courses had to change dramatically
    due to these new winds of change.
  prefs: []
  type: TYPE_NORMAL
- en: 'And all this brings us to the new era of image denoising. In Section [3](#S3
    "3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") we asked how should image denoisers be designed,
    and gave an answer that relies on the classical Bayesian approach. We now return
    to this question, and provide an entirely different answer – one that builds on
    supervised deep-learning. This approach takes the following steps:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Start by gathering a large⁶⁶6By ‘large’ we mean thousands and sometimes millions
    of images, and the more the better. Often-times, the training itself may rely
    on several hundreds of images, and these are augmented by randomized operations
    such as crop, scale-down, rotations, and more. dataset of clean images of diverse
    content - the kind of which we aim to denoise. We shall denote this set as ${\cal
    X}=\{{\mathbf{x}}_{k}\}_{k=1}^{M}$. For simplicity assume that all images are
    of the same size. If this is not the case, an easy process of random tile extraction
    may convert the given data to this desired structure.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Recall that our goal is a design of a denoiser that removes additive white Gaussian
    noise of a specific strength $\sigma$. Thus, the next step is to create noisy
    instances of ${\cal X}$, i.e. ${\cal Y}=\{{\mathbf{y}}_{k}\}_{k=1}^{M}$, where
    for $1\leq k\leq M,~{}{\mathbf{y}}_{k}={\mathbf{x}}_{k}+{\mathbf{v}}_{k}$ and
    ${\mathbf{v}}_{k}\sim{\cal N}(0,\sigma^{2}{\mathbf{I}})$. In fact, every example
    ${\mathbf{x}}_{k}$ could be contaminated by several noise realizations, this way
    enriching the training set.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define a parametric denoising architecture ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$
    that should be trained to perform the denoising task. This stage is necessarily
    vague as there are many options for constructing such an architecture, and there
    seems to be no clear guidelines for its structure. Indeed, the literature offers
    various such options conceived by trial-and-error, e.g.. More details and a discussion
    on this delicate stage is given below.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the training loss – a penalty function that exploits the availability
    of ${\cal X}$ and ${\cal Y}$ and the defined parametric denoiser $D_{\Theta}({\mathbf{y}},\sigma)$,
    posing a cost value to be minimized with respect to $\Theta$, encouraging the
    denoised images to be close to their corresponding ideal ones. Such a functional
    could be of the form
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (8) |  | $\displaystyle{\cal L}(\Theta)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},{\hat{\mathbf{x}}}_{k}\right)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k},\sigma)\right),$
    |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: where $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})$ is a distance
    function between the ideal and the denoised image, such as MSE – $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})=\|{\mathbf{x}}-{\hat{\mathbf{x}}}\|_{2}^{2}$.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '5.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Minimize ${\cal L}(\Theta)$ with respect to $\Theta$ via stochastic gradient
    descent [[24](#bib.bib24)] applied on small batches of training pairs $({\mathbf{x}}_{k},{\mathbf{y}}_{k})$,
    and exploiting back-propagation [[242](#bib.bib242)].
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Once all the above steps are completed, the denoiser ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$
    is ready to be deployed on newly incoming images, expected to perform better or
    worse in noise removal, depending on the size and quality of the training set,
    the similarity between the image to be denoised and the training set, the chosen
    architecture, and the quality and the hyperparameters of the optimization process.
  prefs: []
  type: TYPE_NORMAL
- en: A variant of the above is blind denoising, in which $\sigma$ is unknown. The
    straightforward approach towards this task is brute-force learning. This means
    that for every ideal image ${\mathbf{x}}$ we produce a sequence of noisy versions
    ${\mathbf{y}}_{k}^{\sigma}$ with varying values of $\sigma$ in the range we aim
    to cover. Then learning is done by minimizing a loss that integrates over all
    the noise levels,
  prefs: []
  type: TYPE_NORMAL
- en: '| (9) |  | $\displaystyle{\cal L}(\Theta)=\int_{\sigma}\sum_{k=1}^{M}dist\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k}^{\sigma})\right).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Observe that in this case the denoiser $D_{\Theta}$ gets only the noisy image
    without $\sigma$. An interesting alternative to the above was discovered in [[201](#bib.bib201)],
    showing that a bias-free architecture becomes robust to the noise power, and thus
    a simple training for a single value of $\sigma$ generalizes well to other levels
    of noise.
  prefs: []
  type: TYPE_NORMAL
- en: 'An amazing consequence of all the above description is this: All the glorious
    work on image priors that fueled the design of classical denoisers and other tools
    in image processing seem to have become totally obsolete. Observe that in this
    supervised deep learning approach we have no need nor room for all the knowledge
    and know-how that have been accumulated carefully over decades of extensive research
    and engineering work. Is this a fair description of the current state of things
    in our field? To a large extent, the sad answer is positive, while some reservations
    to this conclusive statement will be discussed in Section [5](#S5 "5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –").'
  prefs: []
  type: TYPE_NORMAL
- en: 'The emergence of deep learning techniques and their new abilities brought a
    new evolution of ideas on the design and span of image denoisers. While this literature
    is vast and rich, we describe below several key trends in this progress, in an
    attempt to expose both the new abilities obtained, and the new ideas accompanying
    them. These come in several fronts:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Better Denoisers: Improving image denoising capabilities via deep learning
    became a natural new front, where the aim is to perform better in terms of Peak-Signal-to-Noise-Ratio
    (PSNR) on an agreed-upon corpus of test images. This is manifested by an evolution
    of architectures that started with simple feed-forward Convolutional Neural Networks
    (CNN) [[330](#bib.bib330)], proceeded to more advanced structures, such as UNet [[234](#bib.bib234),
    [115](#bib.bib115)], and all the way to the recently introduced Transformers [[78](#bib.bib78),
    [165](#bib.bib165), [322](#bib.bib322)]. In Figure [2](#S4.F2 "Figure 2 ‣ 1st
    item ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –") we illustrate this trend
    by presenting a graph that shows the progress in denoising PSNR on the well-known
    BSD68 dataset [[190](#bib.bib190)]. More details on each of these algorithms is
    brought in Appendix [C](#A3 "Appendix C Landmark Denoisers over the Years ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –").'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/eb2047745559668001bb72ccfe6de17e.png)'
  prefs:
  - PREF_IND
  type: TYPE_IMG
- en: 'Figure 2: Denoising performance on the BSD68 dataset [[190](#bib.bib190)] with
    $\sigma=25$ (K-SVD [[89](#bib.bib89)], BM3D [[61](#bib.bib61)], FoE [[237](#bib.bib237)],
    LSSC [[181](#bib.bib181)], EPLL [[347](#bib.bib347)], MLP [[33](#bib.bib33)],
    CSF [[252](#bib.bib252)], WNNM [[110](#bib.bib110)], TNRD [[50](#bib.bib50)],
    DnCNN [[330](#bib.bib330)], IRCNN [[331](#bib.bib331)], NLRN [[167](#bib.bib167)],
    MVCNN [[168](#bib.bib168)], N3Net [[218](#bib.bib218)], FFDNet [[332](#bib.bib332)],
    FOCNet [[133](#bib.bib133)], RIDNet [[8](#bib.bib8)], GCDN [[292](#bib.bib292)],
    SwinIR [[165](#bib.bib165)], DRUNet [[329](#bib.bib329)]).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Different Training Schemes: We described above the most obvious, supervised,
    training strategy, where we gather pairs of ideal images and their noisy version.
    Various unsupervised alternatives have been also developed for this task, such
    as Noise2Noise [[160](#bib.bib160)], Noise2Void [[152](#bib.bib152)], Noise2Self [[16](#bib.bib16)],
    SURE-based denoising [[337](#bib.bib337), [175](#bib.bib175), [207](#bib.bib207)],
    and others, all aim to operate on noisy images directly without the need for an
    access to their clean versions. It should be clear, though, that these techniques
    become relevant only in cases where the noise does not follow a known analytic
    structure, as otherwise the supervised alternative would be preferred. Another
    appealing approach that adopts an unsupervised denoiser training is “Deep Image
    Prior” (DIP) [[286](#bib.bib286)], where a network is trained on a single image
    to best fit itself. An early stopping of this learning is shown to yield an effective
    denoising, revealing the regularization capabilities of the UNet architecture.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'True Noise Removal: We mentioned above the Noise2X line of work [[160](#bib.bib160),
    [152](#bib.bib152), [16](#bib.bib16)], which enables denoising of images without
    access to their clean versions. This ability becomes crucial when operating on
    images with un-modeled and unknown noise statistics. In such cases, learning should
    rely on more fundamental forces, such as self-similarity in images, the slow tendency
    of regressed neural networks to recreate noise from noise, the joint information
    that exists in burst of frames, and more. More broadly speaking, removal of true
    noise from images is a relatively new topic in image denoising, as it has hardly
    been addressed in the classical era due to its evident complexity. With advanced
    self-supervised and unsupervised learning techniques, new impressive abilities
    were created [[298](#bib.bib298), [149](#bib.bib149), [170](#bib.bib170), [285](#bib.bib285),
    [301](#bib.bib301), [128](#bib.bib128)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Image adaptation: This refers to the ability to take an already designed/trained
    denoiser and adapt it to perform better on unique images that deviate from the
    training set. This way, general purpose denoisers could be boosted when operating
    on scanned documents, astronomical images, cartoon images and more. The adaptation
    itself could be done in various ways, the most natural of these is the following [[289](#bib.bib289)]:
    Given a noisy yet unique image to be cleaned, apply first the available denoiser
    $D_{\Theta_{0}}$ and obtain ${\hat{\mathbf{x}}}_{0}=D_{\Theta_{0}}({\mathbf{y}},\sigma)$.
    Now retrain the denoiser (i.e. update the parameters $\Theta$) by minimizing $dist\left({\hat{\mathbf{x}}}_{0},D_{\Theta}({\mathbf{y}},\sigma)\right)$.
    Similar to the core idea behind Noise2Noise [[160](#bib.bib160)] and DIP [[286](#bib.bib286)],
    few gradient steps of this minimization are expected to go in the proper direction
    and yield a more informative and relevant denoiser, thus boosting the result for
    this specific image. The final outcome is obtained by ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$,
    using the slightly updated parameters $\Theta$.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Addressing Different Objectives: When describing the supervised learning strategy
    of denoisers, we offered the $L_{2}$ loss that considers PSNR performance. Over
    the years this quality measure took the lead in most papers, despite its known
    weaknesses. Indeed, our community has been constantly striving to get the MMSE
    denoiser, if not in body, then at least in spirit, and this is evident from the
    PSNR performance tables that appear in almost every paper on image denoising published
    over the years. As we argue later on in Section [9.1](#S9.SS1 "9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    while MMSE denoisers are of great value by themselves, their outcome is not necessarily
    visually appealing, being an average over many potential solutions.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Bearing this in mind, the learning paradigm creates a new opportunity for serving
    “new masters” – recall that the learning loss function is highly non-convex, and
    yet we have no fear of its complexity when training the neural networks. Thus,
    we can easily replace the pleasant $L_{2}$ by more sophisticated or adequate penalties.
    The immediate alternative that comes to mind is SSIM [[299](#bib.bib299)], which
    offers a more robust distance measure between images by considering structural
    similarity. We could go further and consider perceptual losses such as LPIPS [[335](#bib.bib335)],
    that is further robustified by a learned representation in order to fairly assess
    proximity between images. This trend can be characterized as an attempt to produce
    visually pleasing and crisp images from the denoisers, ones that will surpass
    the MMSE alternative. A step forward in this direction takes us to Generative
    Adversarial Networks (GANs) for denoising [[69](#bib.bib69), [67](#bib.bib67),
    [212](#bib.bib212)]. The idea is to challenge the output of the denoiser, by feeding
    it into a classifer that should tell apart true images versus denoised ones. By
    leveraging this classifier’s guidance, the denoiser can learn to produce better
    looking images. We will come back to this idea in Section [9.1](#S9.SS1 "9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    offering an improved approach that targets perfect perceptual quality results.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The description given above provides nothing but a glimpse into a very vibrant
    and rich body of literature that finds image denoising as an appealing playground
    for research. Still, we stop the survey of deep learning for denoising here, as
    our prime goal is the denoisers themselves and algorithms building on top of them.
  prefs: []
  type: TYPE_NORMAL
- en: As one final note, observe that all the preceding discussion on classical and
    modern denoisers’ design is given without referring to color images. Indeed, the
    formulation in this paper considers a grayscale image ${\mathbf{x}}$, yet most
    denoisers, old and new, are typically required to process color (Red-Green-Blue)
    images. Some of the existing methods discussed above are easily extended to color
    by operating on the three chroma channels jointly. For example, NLM [[32](#bib.bib32)]
    and K-SVD denoising [[89](#bib.bib89)] operate on RGB patches directly by flattening
    them to longer vectors. Another approach is to turn to the YUV or YCbCr color-space,
    and operate on the luma (Y) and the chroma (Cb/Cr or U/V) layers independently,
    as BM3D does [[61](#bib.bib61)]. Denoisers based on deep neural networks typically
    handle color directly by feeding the RGB image as a 3-dimensional tensor input
    to the network, processed by subsequent 3D convolutions. More intricate approaches
    do exist, in which the geometrical interplay between the color layers is taken
    into account more adequately [[255](#bib.bib255)].
  prefs: []
  type: TYPE_NORMAL
- en: 5 Synergy between Classics and Deep Learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'With the description given above, the reader may (rightfully!) get the impression
    that the vast knowledge regarding image denoising gathered during the classical
    era has become obsolete with the emergence of the deep learning alternatives.
    However, this claim is not entirely correct. In reality, the themes investigated
    and promoted by classical algorithms are serving as the foundations for building
    DL denoisers, even if practiced implicitly, and these are mostly manifested by
    the choice of architectures to be used. To illustrate this, we mention several
    well-known key concepts of classical image denoising algorithms, and show their
    impact on DL architectures:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Locality: Most information relevant to restoring a pixel’s value in denoising
    is contained in its local neighborhood. In classical algorithms, this concept
    is embodied using patch processing, local filtering, local image priors, and more.
    When it comes to DL schemes, many denoisers choose convolutional layers as their
    primary processing path, which leads to architectures with small to moderate receptive
    fields [[308](#bib.bib308), [330](#bib.bib330), [332](#bib.bib332)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sparsity under appropriate transforms: Local image patches are expected to
    be sparse when represented using certain 2D transforms. On the classical side,
    several of the priors listed in Table [1](#S3.T1 "Table 1 ‣ 3.2 Evolution of Priors
    ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") fall into the sparsity-promoting category. On
    the DL side, a similar treatment can be observed, where the commonly used ReLU
    activation promotes sparsity by nulling the negatively activated neurons [[101](#bib.bib101)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Self-similarity: Most image patches have similar twins at other locations in
    the same image. While classical algorithms usually harness this property by gathering
    similar patches and processing them jointly, some recent DL schemes leverage self-similarity
    using self-attention layers [[165](#bib.bib165), [317](#bib.bib317)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Unfortunately, these and other concepts inherited from the classical era do
    not provide a constructive answer to the main question DL faces: How should we
    choose the appropriate architecture for the denoising task? Researchers facing
    this question are usually taking one of the two following options: (i) Copy: adoption
    of an existing architecture that has been demonstrated to lead to good results
    in a similar task (e.g., DnCNN, UNet, ResNet, and more) [[330](#bib.bib330), [234](#bib.bib234),
    [117](#bib.bib117)]. Usually such an adoption is accompanied by some minor modifications
    such as changing the number of channels or layers, etc.; or (ii) Trial and error:
    gathering an architecture by piling a mix of known building blocks such as convolutions,
    strides, batch normalization steps, ReLU, fully-connected layers, down- and up-scaling,
    skip-connections, and more.'
  prefs: []
  type: TYPE_NORMAL
- en: Both these options seem to work rather well, leading to networks achieving very
    good practical results – see [[330](#bib.bib330), [332](#bib.bib332), [165](#bib.bib165)].
    However, this brute-force approach typically tends to end up with heavy and cumbersome
    architectures, relying on millions of trainable parameters, making the resulting
    networks expensive to use and hard to train. Another downside in such architectures
    is their lack of explainability. While this may seem unimportant, having a black-box
    denoiser with no explainability implies an inability to leverage it to other tasks
    (e.g., image separation [[199](#bib.bib199), [91](#bib.bib91), [153](#bib.bib153)]),
    or probe it for identifying origins of failures for ill-treated regions in the
    image. More broadly, the brute-force approach towards architecture design for
    denoisers may require a lengthy trial and error process and may end up hitting
    a performance barrier.
  prefs: []
  type: TYPE_NORMAL
- en: 'An alternative to copying or guessing architectures does appear in recent literature,
    known as *unfolding* [[109](#bib.bib109), [341](#bib.bib341), [250](#bib.bib250),
    [83](#bib.bib83), [204](#bib.bib204)]. This approach constructs the neural network
    so as to mimic the computational stages of a well motivated algorithm. The term
    unfolding has to do with the fact that many classical image denoising methods
    involve iterative algorithms, and thus networks mimicking these should unfold
    their iterations to a feed-forward computational path. This approach typically
    produces concise and perfectly explainable networks, both in terms of the learned
    parameters and the activations obtained, which are easier to train. In addition,
    such networks tend to be easily and effectively adapted to different data. There
    are various examples in the literature for the unfolding approach for various
    regression tasks, e.g. [[313](#bib.bib313), [58](#bib.bib58), [328](#bib.bib328),
    [125](#bib.bib125), [289](#bib.bib289), [250](#bib.bib250), [204](#bib.bib204)].
    Here we briefly describe two such methods for illustrative purpose: Deep K-SVD [[250](#bib.bib250)]
    and LIDIA [[289](#bib.bib289)]. Both propose a conversion of a classical denoising
    algorithm into a deep neural network architecture.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Deep K-SVD
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '![Refer to caption](img/861a7d254a2347a9180dba22693cc6ca.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: End-to-end architecture of the Deep K-SVD network [[250](#bib.bib250)].'
  prefs: []
  type: TYPE_NORMAL
- en: Deep K-SVD [[250](#bib.bib250)] is an unfolding version of the K-SVD image denoising
    algorithm [[89](#bib.bib89)]. We start with a brief explanation of the original
    K-SVD method, and then turn to describe its unfolding.
  prefs: []
  type: TYPE_NORMAL
- en: K-SVD denoising is based on sparse representation theory for constructing the
    image prior [[4](#bib.bib4)]. Consider a clean image $\mathbf{x}$ and patch extraction
    operators $\left\{\mathbf{R}_{k}\right\}_{k}$ such that $\mathbf{R}_{k}\mathbf{x}\in\mathbb{R}^{n}$
    are image patches of size $\sqrt{n}\times\sqrt{n}$ taken from location $k$ in
    the image. The sparsity-promoting prior assumes that any such patch, $\mathbf{R}_{k}\mathbf{x}$,
    can be represented as a linear combination of *f*ew columns (also referred to
    as atoms) from a redundant dictionary ${\mathbf{D}}\in\mathbb{R}^{n\times p}$
    (redundancy implied by $p>n$), i.e.,
  prefs: []
  type: TYPE_NORMAL
- en: '| (10) |  | $\mathbf{R}_{k}\mathbf{x}={\mathbf{D}}\alpha_{k}\;,$ |  |'
  prefs: []
  type: TYPE_TB
- en: 'where $\alpha_{k}\in\mathbb{R}^{p}$ is a sparse vector, $\left\|\alpha_{i}\right\|_{0}\ll
    n$. Armed with this assumption, K-SVD poses the following minimization problem:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (11) |  | $\min_{\left\{\alpha_{k}\right\}_{k},\mathbf{x}}\quad\frac{\mu}{2}\left\&#124;\mathbf{x}-\mathbf{y}\right\&#124;_{2}^{2}+\sum_{k}\left(\lambda_{k}\left\&#124;\alpha_{k}\right\&#124;_{0}+\frac{1}{2}\left\&#124;{\mathbf{D}}\alpha_{k}-\mathbf{R}_{k}\mathbf{x}\right\&#124;_{2}^{2}\right)\;,$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{y}$ is the given noisy image, and $\mu$ and $\lambda_{k}$ are
    hyper-parameters. In this expression, the first term is the Log-Likelihood that
    requires a proximity between the reconstructed image $\mathbf{x}$ and the noisy
    image $\mathbf{y}$. The second and third terms represent the sparse representation
    prior, demanding that every image patch $\mathbf{R}_{k}\mathbf{x}$ in every location
    $k$ has an approximate sparse representation $\alpha_{k}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The K-SVD algorithm solves this minimization problem by applying the following
    two steps iteratively: (i) Fix ${\mathbf{x}}$ (initialized by ${\mathbf{x}}={\mathbf{y}}$)
    and update the vectors $\left\{\alpha_{k}\right\}_{k}$; and (ii) Update ${\mathbf{x}}$
    while freezing the sparse representation vectors. The first is referred to as
    the sparse coding stage, where each patch in the contemporary solution obtains
    a sparse representation via the Orthogonal Matching Pursuit (OMP) greedy algorithm [[214](#bib.bib214)].
    The second step becomes a quadratic minimization task, its solution being a simple
    variation of patch-based averaging. A single round of the above two steps has
    been shown to suffice for getting very good results [[89](#bib.bib89)], and a
    repetition of this round several times could further boost the results [[347](#bib.bib347)].
    The dictionary ${\mathbf{D}}$ in the above process could be either universal –
    pretrained to best sparsify natural image content, or image adaptive – updated
    to the image ${\mathbf{y}}$ itself within the above optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We now turn to describe the Deep K-SVD algorithm, which adopts the universal
    dictionary approach. The end-to-end architecture referring to a single round is
    illustrated in Figure [3](#S5.F3 "Figure 3 ‣ 5.1 Deep K-SVD ‣ 5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –"). This neural network consists of three main blocks:
    Patch Decomposition, Patch Denoiser, and Patch Averaging, all following closely
    the very same steps described above, with appropriate adaptations. Patch Decomposition
    breaks the input image $\mathbf{y}$ into a set of fully overlapped patches $\left\{\mathbf{z}_{k}\right\}_{k}=\left\{\mathbf{R}_{k}\mathbf{y}\right\}_{k}$.
    The next block, Patch Denoiser, is applied patch-wise, but replaces the OMP by
    LISTA [[109](#bib.bib109)], in which $\mathbf{z}_{k}$ undergoes sparse coding
    via a differentiable shrinkage-based iterative algorithm [[109](#bib.bib109)].
    These inner iterations are unfolded as well to create a feed-forward computational
    path that starts with $\mathbf{z}_{k}$ and ends with $\mathbf{\hat{z}}_{k}={\mathbf{D}}\alpha_{k}$.
    Due to the gap between OMP and LISTA, a sub-network of fully-connected layers
    computes the value of $\lambda_{k}$ for the incoming patch ${\mathbf{z}}_{k}$.
    The last block, Patch Averaging, rebuilds the reconstructed image $\mathbf{\hat{x}}$
    by averaging the cleaned patches $\mathbf{\hat{z}}_{k}$ using learned weights.'
  prefs: []
  type: TYPE_NORMAL
- en: This Deep K-SVD network is trained end-to-end by minimizing the MSE distance
    between the ideal and denoised images for a set of $M$ training images,
  prefs: []
  type: TYPE_NORMAL
- en: '| (12) |  | $\mathcal{L}\left(\Theta\right)=\sum_{k=1}^{M}\left\&#124;\mathbf{x}_{k}-\mathbf{\hat{x}}_{k}\right\&#124;_{2}^{2}=\sum_{k=1}^{M}\left\&#124;\mathbf{x}_{k}-D_{\Theta}\left(\mathbf{y}_{k}\right)\right\&#124;_{2}^{2}\;,$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $\left\{{\mathbf{x}}_{k},y_{k}\right\}_{k}$ is a set of clean and noisy
    image pairs to train on. $D_{\Theta}$ is the denoising network, where $\Theta$
    stands for all trainable parameters, consisting of the dictionary ${\mathbf{D}}$,
    the parameters of the sub-network that evaluates $\lambda_{k}$ and the shrinkage
    thresholds.
  prefs: []
  type: TYPE_NORMAL
- en: Despite the close resemblance between the original algorithm and its unfolded
    version, the later performs much better [[250](#bib.bib250)], surpassing classical
    methods and aligning with deep-learning based techniques. This should not come
    as a surprise as the unfolded denoiser $D_{\Theta}$ is trained in a supervised
    manner, being fully aware of the task it serves, whereas the original algorithm
    relied on a “guessed” image prior. Interestingly, the universal dictionary obtained
    for $D_{\Theta}$ is markedly different from the one trained off-line for the original
    K-SVD denoising method, again a testimony to the major difference between the
    two design strategies.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 LIDIA - Lightweight Learned Image Denoising
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another example of unfolding-based denoising is LIDIA [[289](#bib.bib289)],
    which mimics the computational stages of the BM3D [[61](#bib.bib61)]. As already
    mentioned in Section [3.3](#S3.SS3 "3.3 Other Classical Denoisers ‣ 3 Image Denoising
    – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –"), BM3D harnesses two prime forces for its denoising goal – sparsity
    and self similarity. The first relies on the assumption that local image patches
    are sparse under the 2D-DCT spatial transform; the later is reflected by operating
    on groups of similar patches jointly, forcing sparsity again by transforming across
    these patches.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/46992dc7e7759e92673caf9fd59fbadb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The LIDIA denoising computational path.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fdf93b4fa79cffd4ea714881dd209408.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The Transform-ReLU-Transform block. Applying the matrices $\mathbf{T}_{1}$
    and $\mathbf{T}_{2}$ transforms the input, $\mathbf{Z}_{k}$, to a space in which
    patches are supposed to be sparse; the matrices $\mathbf{T}_{3}$ and $\mathbf{T}_{4}$
    transform the outcome to the pixel domain. Observe that the transform applied
    on $\mathbf{Z}_{k}$ is separable – $\mathbf{T}_{1}$ is applied within patches
    while $\mathbf{T}_{2}$ operates across. This enables a reduction of the size of
    the matrices $\mathbf{T}_{1},\dots,\mathbf{T}_{4}$ in order to enable their training.'
  prefs: []
  type: TYPE_NORMAL
- en: 'LIDIA’s core computational path is shown schematically in Figure [4](#S5.F4
    "Figure 4 ‣ 5.2 LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –"). This neural network starts by breaking the input
    image $\mathbf{y}$ into a set of fully overlapping patches $\left\{\mathbf{z}_{k}\right\}_{k}$
    of size $\sqrt{n}\times\sqrt{n}$. Then, each patch, $\mathbf{z}_{k}\in\mathbb{R}^{n}$,
    is augmented with a group of its $m-1$ nearest neighbors, forming a matrix $\mathbf{Z}_{k}$
    of size $n\times m$. The filtering is applied patch-wise – each matrix, $\mathbf{Z}_{k}$,
    undergoes a series of blocks composed of a separable transform, ReLU, and another
    separable transform, as shown schematically in Figure [5](#S5.F5 "Figure 5 ‣ 5.2
    LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between Classics and Deep
    Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –"). This mimics the BM3D operation by transforming the input matrix to
    a space in which local patches are believed to be sparse, forcing sparsity using
    the ReLU layer, and transforming back the outcome to the pixel domain. Unlike
    BM3D, the transforms are trainable and are not restricted to be the inverse of
    each other, nor forced to be square matrices. In addition, LIDIA includes a multi-scale
    treatment, simultaneously processing patches in several scales. During processing,
    the corresponding patches from different scales are fused using a learned joint
    transform. Finally, the reconstructed image is obtained by returning the denoised
    patches to their original places while averaging overlaps using learned weights.'
  prefs: []
  type: TYPE_NORMAL
- en: 'The LIDIA network is trained end-to-end (excluding the nearest-neighbor part)
    by minimizing the MSE loss, similar to the loss in Equation [12](#S5.E12 "Equation
    12 ‣ 5.1 Deep K-SVD ‣ 5 Synergy between Classics and Deep Learning ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"), applied on a set
    of $M$ training images. The network can be trained for a specific noise level
    $\sigma$ or blindly, aiming to serve a range of $\sigma$ values. LIDIA performs
    much better than the original BM3D algorithm since it uses learned rather than
    fixed transforms. Compared with other deep-learning techniques LIDIA achieves
    comparable results, while using a small fraction of the typical number of learned
    parameters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [4](#S4 "4 Image Denoising – The Deep Learning Revolution ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") we mentioned
    the ability to adapt a given denoiser to newly coming images that deviate from
    the training set. This adaptation starts by applying the trained denoiser, and
    then uses the output in order to fine-tune the denoiser parameters by applying
    few gradient steps. This rationale has been successfully demonstrated with LIDIA,
    and two such illustrative results are brought in Figure [6](#S5.F6 "Figure 6 ‣
    5.2 LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between Classics and
    Deep Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0d7ac1291c6fb0dcca45a6244d4254aa.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Clean
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a8db98410d2e082a2fc8d76f3dbfb3dc.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Noisy, ${\sigma=50}$
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/d09980bd0c439843978ba3f61063f407.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Denoised, $24.22$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/afc6ef07bc3aa36073ab6d8a89ddc431.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) Adapted, $26.34$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373)
    scale(1, -1)"><foreignobject width="598" height="373" overflow="visible">![Refer
    to caption](img/9ac2069983d8a4d91b096b4a535783bd.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (e) Clean
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373)
    scale(1, -1)"><foreignobject width="598" height="373" overflow="visible">![Refer
    to caption](img/f3178ea8f08af4c252dc51cceb88b7d4.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (f) Noisy, ${\sigma=50}$
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373)
    scale(1, -1)"><foreignobject width="598" height="373" overflow="visible">![Refer
    to caption](img/318a7d60b7a89e73b5d790cf30a6b94b.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (g) Denoised, $22.10$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373)
    scale(1, -1)"><foreignobject width="598" height="373" overflow="visible">![Refer
    to caption](img/842798629e878224506a8b512a23e991.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (h) Adapted, $25.82$dB
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Image adaptation via LIDIA: The original denoising network is trained
    for general content images, and performs reasonably well for astronomy and scanned
    document inputs. A substantial boost in denoising performance is obtained for
    these two examples, due to their deviation from the training set.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Summary - The classics is still here
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We described two unfolding instances in which classic denoising algorithms provide
    their architecture for the learned network. These and other such methods [[341](#bib.bib341),
    [250](#bib.bib250), [83](#bib.bib83), [204](#bib.bib204)], targeting various image
    recovery tasks, offer a constructive path towards well-motivated, low complexity
    and explainable neural architectures. In the quest for a synergy between classical
    denoising methods and novel deep-learning alternatives, this is probably the most
    natural manifestation of it.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Image Denoising – Migration towards Recent Discoveries
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The clear conclusions from the above discussion are these: Highly effective
    image denoisers for AWGN removal, $D({\mathbf{y}},\sigma)$, are definitely within
    reach, and the better ones are likely to be deep-learning based algorithms. In
    an attempt to illustrate these statements, Figures [7](#S6.F7 "Figure 7 ‣ 6 Image
    Denoising – Migration towards Recent Discoveries ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") and [8](#S6.F8 "Figure 8 ‣ 6 Image
    Denoising – Migration towards Recent Discoveries ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") present denoising results for two test
    images, two noise levels ($\sigma=15,50$) and by several denoisers – NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], and SwinIR (a transformer-based
    denoising network) [[165](#bib.bib165)]. As can be seen, the results are very
    impressive and more so by the later deep neural network solutions.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/5647162749e70a1c60c9489a5d29a2cd.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (a) Clean
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/37615ae04fbb3b0b526c9211319fd324.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Noisy, ${\sigma=50}$
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/db5f15ef94676f49f5b5d3e33f05ac41.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (c) NLM, $24.67$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/71a936452ee7bc41ccf45e0b3897ab28.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (d) BM3D, $26.31$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/42261bd39654c90164a7f3fde81739c2.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (e) DnCNN, $26.70$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/dc4f46cde577b45055480c6f9c37149b.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (f) SwinIR, $27.31$dB
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: Demonstration (1) of several denoising methods: (NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], SwinIR [[165](#bib.bib165)]).'
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/4569d9cdf37e55b6ff10a2e0a9b084a8.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (a) Clean
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/32111224538c27275bd8b9625f7c6753.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Noisy, ${\sigma=15}$
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/a2b4a7135bb660db1cb3bd29791baac3.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (c) NLM, $33.82$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/3422dcefec62c73a4950fa073654b895.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (d) BM3D, $36.23$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/48b7b61f5a1905a323c75aee036bb632.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (e) DnCNN, $36.33$dB
  prefs: []
  type: TYPE_NORMAL
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78)
    scale(1, -1)"><foreignobject width="664" height="78" overflow="visible">![Refer
    to caption](img/e5dc8f68cd58c563927e484431b483a3.png)</foreignobject></g></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (f) SwinIR, $37.17$dB
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: Demonstration (2) of several denoising methods: (NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], SwinIR [[165](#bib.bib165)]).'
  prefs: []
  type: TYPE_NORMAL
- en: 'We now turn to ask far more daring questions with regard to such denoisers,
    focusing this time on their deployment to other tasks. More specifically, we discuss
    three such questions, each corresponding to a recent discovery in the field of
    imaging sciences:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Discovery 1: Can we leverage a denoiser $D({\mathbf{y}},\sigma)$ for solving
    general linear inverse problems? As we shall shortly see, the answer to this question
    is positive and constructive, opening new horizons for design of recovery algorithms
    and their regularization.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Discovery 2: Can we leverage a denoiser $D({\mathbf{y}},\sigma)$ for synthesizing
    (hallucinating) high-quality images, fairly drawn from the prior probability density
    function $p({\mathbf{x}})$? Here again the answer is positive and constructive,
    offering a thrilling new line of activity in machine learning.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Discovery 3: If hallucination of perfect-looking images is achievable, can
    we revisit the topic of general linear inverse problems and leverage a denoiser
    $D({\mathbf{y}},\sigma)$ for their solution while targeting *perfect perceptual
    quality* results? Here again we give a positive answer, and lead to a new and
    inspiring branch of research in inverse problems, offering novel view of their
    treatment.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Below we discuss each of these discoveries in greater details. It is our sincere
    belief that these together form one of the most exciting eras for our field, marking
    a major transition in how image processing is perceived and practiced.
  prefs: []
  type: TYPE_NORMAL
- en: '7 Discovery 1: Solving Inverse Problems via Image Denoisers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Given a denoiser $D({\mathbf{y}},\sigma):\mathbb{R}^{N}\rightarrow\mathbb{R}^{N}$,
    our goal is to use it somehow for solving general linear inverse problems of the
    form
  prefs: []
  type: TYPE_NORMAL
- en: '| (13) |  | $\displaystyle{\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where ${\mathbf{H}}\in\mathbb{R}^{M\times N}$ is a known matrix, ${\mathbf{v}}\in\mathbb{R}^{M}$
    is AWGN, and ${\mathbf{y}}\in\mathbb{R}^{M}$ is the given measurement vector.
    Observe that ${\mathbf{H}}={\mathbf{I}}$ stands for the denoising problem. Therefore,
    the current discussion extends our view to a wider family of tasks in imaging
    sciences, covering applications such as deblurring, inpainting, demosaicing, super-resolution,
    tomographic reconstruction, compressed sensing, and more.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following the derivations in Section [3](#S3 "3 Image Denoising – The Classic
    Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper
    –") and specifically Equation ([6](#S3.E6 "Equation 6 ‣ 3.1 The Bayesian Point
    of View for Design of Denoisers ‣ 3 Image Denoising – The Classic Era ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), we can
    adopt the Bayesian point of view and obtain the MAP estimation for this family
    of problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (14) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Plugging in the Gibbs distribution form for the prior, $p({\mathbf{x}})\sim\exp\{-\rho({\mathbf{x}})\}$,
    this becomes
  prefs: []
  type: TYPE_NORMAL
- en: '| (15) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{x}})\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Clearly, the greatest riddle posed above has to do with the identity of the
    energy function $\rho({\mathbf{x}})$. Can a denoiser serve all linear inverse
    problems in a unified approach by providing a connection or an alternative to
    $\rho({\mathbf{x}})$? Surprisingly, the answer to this question is positive and
    constructive. The seminal Plug-and-Play Prior (PnP) work by Venkatakrishnan, Bouman
    and Wohlberg [[295](#bib.bib295)] was the first to provide such an answer⁷⁷7We
    should note that an alternative, yet closely related, derivation is offered in [[196](#bib.bib196)]
    from an approximate message passing point of view., followed and improved upon
    by RED (Regularization by Denoising) [[231](#bib.bib231)]. These and their various
    extensions and variations have created a vivid and stimulating sub-field of research
    in imaging sciences [[28](#bib.bib28), [139](#bib.bib139), [283](#bib.bib283),
    [34](#bib.bib34), [268](#bib.bib268), [41](#bib.bib41), [192](#bib.bib192), [280](#bib.bib280),
    [5](#bib.bib5), [49](#bib.bib49), [55](#bib.bib55)] in which denoisers play a
    central role. Below we describe PnP and RED in more detail, and then turn to describe
    another, perhaps better founded, bridge between denoisers and the energy function
    $\rho({\mathbf{x}})$ via the *score function*. This would serve our next step
    towards diffusion models, as they unravel in Section [8](#S8 "8 Discovery 2: Image
    Synthesis via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") and beyond.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Plug-and-Play Prior (PnP)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'PnP [[295](#bib.bib295)] suggests the following steps in handling the minimization
    of the problem posed in Equation ([15](#S7.E15 "Equation 15 ‣ 7 Discovery 1: Solving
    Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")): We start by splitting the variable ${\mathbf{x}}$
    by defining ${\mathbf{z}}={\mathbf{x}}$ and expressing each of the two penalties
    with a different variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (16) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}},{\mathbf{z}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})\right]~{}~{}\operatorname*{s.t.}~{}~{}{\mathbf{z}}={\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: The next step forms the Augmented Lagrangian of the above problem, converting
    the constraint into a penalty,
  prefs: []
  type: TYPE_NORMAL
- en: '| (17) |  | $\displaystyle L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})=\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}-\lambda\&#124;{\mathbf{u}}\&#124;_{2}^{2},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where ${\mathbf{u}}$ is the scaled dual variable and $\lambda$ is an (arbitrary)
    penalty weight (see more in [[295](#bib.bib295)]). The third and final step applies
    ADMM [[27](#bib.bib27)] for the minimization of $L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})$
    with respect to ${\mathbf{x}}$ and ${\mathbf{z}}$ while updating ${\mathbf{u}}$.
    These are obtained by alternating between the treatment of each variable while
    fixing the others:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (18) |  | $\displaystyle{\mathbf{x}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right]=\left[{\mathbf{H}}^{T}{\mathbf{H}}+\lambda{\mathbf{I}}\right]^{-1}\left[{\mathbf{H}}^{T}{\mathbf{y}}+{\mathbf{z}}-{\mathbf{u}}\right],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (19) |  | $\displaystyle{\mathbf{z}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{z}}}\left[c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| (20) |  | $\displaystyle{\mathbf{u}}$ | $\displaystyle\leftarrow$ | $\displaystyle{\mathbf{u}}+({\mathbf{x}}-{\mathbf{z}}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'In the above, the first update equation amounts to a simple Least-Squares,
    which does not involve $\rho({\mathbf{x}})$. The true drama takes place in the
    second update formula – observe its close resemblance to Equation ([6](#S3.E6
    "Equation 6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers ‣ 3 Image
    Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –")), which formulates an image denoising task. Indeed,
    instead of choosing/guessing/learning $\rho({\mathbf{x}})$, we can apply our favorite
    denoiser ${\hat{\mathbf{z}}}=D({\mathbf{x}}-{\mathbf{u}},\sigma_{0})$ where $\sigma_{0}$
    should be inversely proportional to $\lambda/c$. This way, PnP offers an appealing
    iterative algorithm that repeatedly applies a denoiser in order to handle any
    underlying inverse problem, just as promised.'
  prefs: []
  type: TYPE_NORMAL
- en: While the original PnP paper did not dive into the issue of convergence of the
    above ADMM algorithm, nor posed conditions on the denoiser to support such guarantees,
    later work offers such a theoretical discussion – we refer the interested readers
    to [[42](#bib.bib42), [309](#bib.bib309), [269](#bib.bib269), [155](#bib.bib155)].
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Regularization by Denoising (RED)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An alternative angle towards the relationship between $\rho({\mathbf{x}})$
    and image denoising is presented in [[231](#bib.bib231)]. The core idea is quite
    simple, using the following explicit formula for $\rho({\mathbf{x}})$ that relies
    on a denoiser:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (21) |  | $\displaystyle\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'The intuition behind this expression can be uncovered by considering a linearized
    form of the denoising process, $D({\mathbf{x}},\sigma_{0})=S({\mathbf{x}}){\mathbf{x}}$,
    where $S({\mathbf{x}})$ is an image-dependent matrix that represents the smoothing
    applied by the noise removal process. This way, the chosen energy function becomes
    $\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{I}}-S({\mathbf{x}})\right]{\mathbf{x}}$,
    which is a Laplacian smoothness prior of the kind described in Section [3](#S3
    "3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –"), although being image-adaptive (and thus far more
    effective).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The work in [[231](#bib.bib231)] shows that if the denoiser $D({\mathbf{x}},\sigma_{0})$
    is differentiable, passive and of symmetric Jacobian, the chosen energy function
    in Equation ([21](#S7.E21 "Equation 21 ‣ 7.2 Regularization by Denoising (RED)
    ‣ 7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")) is guaranteed to
    be convex. If, in addition, the denoiser satisfies a local homogeneity property⁸⁸8See
    [[231](#bib.bib231)] for the exact definitions of these ingredients and for the
    proof of their implications., then the following relationship holds:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (22) |  | $\displaystyle\nabla_{{\mathbf{x}}}\rho({\mathbf{x}})=2\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'This relationship is a centerpiece in the construction of several RED algorithms.
    Plugging the chosen $\rho({\mathbf{x}})$ from Equation ([21](#S7.E21 "Equation
    21 ‣ 7.2 Regularization by Denoising (RED) ‣ 7 Discovery 1: Solving Inverse Problems
    via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –")) into Equation ([15](#S7.E15 "Equation 15 ‣ 7 Discovery 1:
    Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")) implies that the gradient of this
    functional is easily accessible, requiring a single activation of the chosen denoiser.
    Critically, this gradient does not require the differentiation of $D({\mathbf{x}},\sigma_{0})$,
    which would have required far more computational power and memory consumption.
    As a consequence, various gradient-based optimization strategies can be applied
    for computing ${\hat{\mathbf{x}}}_{MAP}$, and all are guaranteed to converge to
    the global minimizer of the MAP penalty. Again, we arrive at iterative algorithms
    that apply simple linear operations and a denoiser in each step, aiming to solve
    general linear inverse problems.'
  prefs: []
  type: TYPE_NORMAL
- en: An intriguing question with respect to the above is the identity of the denoiser
    to use within RED. Should it be an MMSE denoiser? Should it be designed to remove
    AWGN? Would these choices lead to the required properties mentioned above (diffentiability,
    symmetry, passivity, homogeneity)? What should $\sigma_{0}$ be? Partial answers
    to these questions are given by the next discussion on the *score function*.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3 The Score Function and its Relevance to Inverse Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Embarking from Equations ([14](#S7.E14 "Equation 14 ‣ 7 Discovery 1: Solving
    Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")) and ([15](#S7.E15 "Equation 15 ‣ 7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")), we now present a very different approach
    towards getting to the same RED formulation, regularizing inverse problems via
    a denoiser. Assume that our goal is to find ${\hat{\mathbf{x}}}_{MAP}$ by Steepest
    Descent (SD), and thus our iterative formula should be'
  prefs: []
  type: TYPE_NORMAL
- en: '| (23) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})-c\cdot\nabla_{{\mathbf{x}}}\log
    p({\mathbf{x}})&#124;_{{\hat{\mathbf{x}}}_{k}}\right].$ |  |'
  prefs: []
  type: TYPE_TB
- en: The term $\nabla_{{\mathbf{x}}}\log p({\mathbf{x}})$ is known in the statistical
    literature as the *score function*, being a flow-field that describes the optimal
    ascent direction over the log of the prior. An old mathematical result, commonly
    attributed to Miyasawa [[200](#bib.bib200)], Stein [[265](#bib.bib265)], or Tweedie [[84](#bib.bib84)],
    and re-exposed in [[138](#bib.bib138)], proves that
  prefs: []
  type: TYPE_NORMAL
- en: '| (24) |  | $\nabla_{\mathbf{y}}\log p(\mathbf{y})=\frac{D(\mathbf{y},\sigma_{0})-\mathbf{y}}{\sigma_{0}^{2}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$ is a noisy version of ${\mathbf{x}}$
    with ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$, and
    $D(\mathbf{y},\sigma_{0})$ should be the optimal Minimum Mean Squared Error (MMSE)
    denoiser, $\mathbb{E}(\mathbf{x}|\mathbf{y})$. A proof of this result is brought
    in Appendix [D](#A4 "Appendix D Approximation of the Score Function by an MMSE
    Denoiser ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –").'
  prefs: []
  type: TYPE_NORMAL
- en: 'While it is impossible to obtain the MMSE denoiser (as $p(\mathbf{x})$ is unknown),
    modern deep learning-based denoisers perform very well (see Figure [2](#S4.F2
    "Figure 2 ‣ 1st item ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), and
    therefore constitute a good approximation for it. And so, while Equation ([23](#S7.E23
    "Equation 23 ‣ 7.3 The Score Function and its Relevance to Inverse Problems ‣
    7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")) expects to use the
    score function that refers to $p({\mathbf{x}})$, a denoiser can provide an approximation
    of it that considers a slightly blurry probability density function⁹⁹9See Appendix
    [D](#A4 "Appendix D Approximation of the Score Function by an MMSE Denoiser ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    for a justification of this claim. $p({\mathbf{y}})=p({\mathbf{x}})\otimes{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$. When $\sigma_{0}$ is small enough^(10)^(10)10RED [[231](#bib.bib231)]
    suggests to use $\sigma_{0}\approx 3-5$ for images with $256\times 256$ gray-values.,
    this approximation becomes very effective and the resulting algorithm admits the
    following update rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (25) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})+c\left({\mathbf{x}}_{k}-D({\hat{\mathbf{x}}}_{k},\sigma_{0})\right)\right],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: which is exactly the SD version of RED [[231](#bib.bib231)].
  prefs: []
  type: TYPE_NORMAL
- en: '7.4 Summary: Denoisers for Solving Inverse Problems'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Figures [9](#S7.F9 "Figure 9 ‣ 7.4 Summary: Denoisers for Solving Inverse Problems
    ‣ 7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") and [10](#S7.F10
    "Figure 10 ‣ 7.4 Summary: Denoisers for Solving Inverse Problems ‣ 7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") present illustrative results of PnP [[295](#bib.bib295)],
    RED [[231](#bib.bib231)], and NCSR [[74](#bib.bib74)] for deblurring and single-image
    super-resolution. Note that while NCSR is specifically tailored to handle these
    two applications, PnP and RED are unaware of the underlying task, and use a given
    denoiser. The tests presented employ both a simple median filter and the TNRD
    denoiser [[50](#bib.bib50)]. Surprisingly, even a plain denoiser as the median
    filter can provide some recovery effect. More details on these experiments and
    more results can be found in [[231](#bib.bib231)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/bcafc31d036ae115d2207ca12487a7eb.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Ground Truth
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fe47ec8bfec660f4d76babb681e4daaf.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Input $20.83$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/eaab41dcd08a47b5f58cf77534dc029a.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) RED (Median) $25.87$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/cc8b6785866f57f65c56919b29be3d7c.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) NCSR $28.39$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/caa8bb6565aa1b60037cbdd200b50fec.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) PnP (TNRD) $28.43$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2b3d18c8b7234310b33f003510475554.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) RED (TNRD) $28.82$dB
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 9: Visual comparison of deblurring results by PnP and RED. NCSR [[50](#bib.bib50)]
    is brought as a reference to compare with.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e471ba98805e8e7c2a567de189b67bc4.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Ground Truth
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fd6e092a9ff5fc110a967f8a10ed0f58.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Bicubic $20.68$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c970424e8dee5c2523614781aaddc73b.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) RED (Median) $24.44$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/66d598e3c0ca56f6063f5435a212e315.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) NCSR $26.79$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/61a03a8058b37dbd5b9eb723430615dc.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) PnP (TNRD) $26.61$dB
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7b76a86a2e0a3cc69df8fad8e5865153.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) RED (TNRD) $27.39$dB
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 10: Visual comparison of super-resolution (3:1) results by PnP and RED.
    NCSR [[50](#bib.bib50)] is brought as a reference to compare with.'
  prefs: []
  type: TYPE_NORMAL
- en: 'PnP and RED have drawn much interest in our community in the past several years.
    Followup work has been considering a theoretical analysis of the two methods [[42](#bib.bib42),
    [278](#bib.bib278), [225](#bib.bib225), [94](#bib.bib94), [309](#bib.bib309),
    [269](#bib.bib269)], deployment of the proposed algorithms in various applications [[263](#bib.bib263),
    [28](#bib.bib28), [139](#bib.bib139), [49](#bib.bib49)], creation of new variants
    of these two methods [[283](#bib.bib283), [279](#bib.bib279), [268](#bib.bib268),
    [280](#bib.bib280), [267](#bib.bib267), [123](#bib.bib123), [56](#bib.bib56)],
    and more. An appealing outlet of this work returns to the unfolding idea discussed
    in Section [5](#S5 "5 Synergy between Classics and Deep Learning ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"): PnP/RED can be used
    to define well-motivated architectures for solving general inverse problems, by
    unfolding the proposed algorithms, and then training the repeated denoiser to
    best serve a series of inverse problems jointly. This way, by plugging in the
    degradation operator ${\mathbf{H}}$, a single network can treat a variety of tasks
    in image processing, built around a core learned denoising engine [[194](#bib.bib194),
    [229](#bib.bib229), [73](#bib.bib73), [192](#bib.bib192), [333](#bib.bib333)].'
  prefs: []
  type: TYPE_NORMAL
- en: '8 Discovery 2: Image Synthesis via Image Denoisers'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The deep learning revolution has enabled several capabilities that were previously
    thought to be practically impossible. Among the most intriguing such capabilities
    is *image synthesis* – the ability to generate a variety of natural-looking images,
    without conditioning on any kind of input or initialization. More formally, the
    goal of image synthesis is to obtain a random generator whose outputs follow the
    prior distribution of images $\mathbf{x}\sim p(\mathbf{x})$. Succeeding in this
    task would testify that we have seized the true distribution of images, and this
    may aid in solving a variety of imaging tasks.
  prefs: []
  type: TYPE_NORMAL
- en: A common theme in the definition of such image generators is the need to design
    of a learned machine $G_{\Theta}({\mathbf{z}})$, which admits a simply distributed
    input vector ${\mathbf{z}}$ (e.g., ${\mathbf{z}}\sim{\cal N}(0,{\mathbf{I}})$)
    and converts it to a valid sample from $p({\mathbf{x}})$. $G_{\Theta}({\mathbf{z}})$
    is a neural network parameterized by $\Theta$, and various techniques were conceived
    in the past decade for learning $\Theta$ for best fitting the synthesized results
    with the destination PDF. In this context, the main tool of interest, which popularized
    image synthesis, is called GAN – Generative Adversarial Network [[107](#bib.bib107)].
    While alternatives to GANs do exist, such as Variational Auto-Encoders (VAE) [[151](#bib.bib151)],
    Normalizing Flow (NF) techniques [[228](#bib.bib228), [150](#bib.bib150)], Autoregressive
    models [[293](#bib.bib293)], and energy-based methods [[118](#bib.bib118), [79](#bib.bib79)],
    GANs were typically at the lead in image generation. Since their introduction
    and until recently, GANs have undergone various improvements [[222](#bib.bib222),
    [11](#bib.bib11), [112](#bib.bib112), [327](#bib.bib327)], and achieved stellar
    performance [[29](#bib.bib29), [141](#bib.bib141), [249](#bib.bib249)]. However,
    this changed dramatically with the arrival of *diffusion models* [[257](#bib.bib257),
    [260](#bib.bib260), [120](#bib.bib120)].
  prefs: []
  type: TYPE_NORMAL
- en: GANs, and the other generative models mentioned above, are detached from the
    topic of image denoising. In contrast, *diffusion models* heavily rely on the
    *score function* and thus on image denoisers for addressing the task of image
    synthesis. This recent line of work that started to gain traction, aptly named
    *score-based generative models* [[260](#bib.bib260), [261](#bib.bib261)] or *denoising
    diffusion probabilistic models* [[257](#bib.bib257), [120](#bib.bib120)], utilizes
    deep learning-based denoisers to approximate the score function, which is then
    used in an iterative algorithm to obtain images $\mathbf{x}$ that are fair samples
    from the PDF $p({\mathbf{x}})$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The iterative algorithms used for generation in this context are largely based
    on Langevin dynamics [[230](#bib.bib230), [19](#bib.bib19)], a Markov Chain Monte
    Carlo (MCMC) method with the following transition rule:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (26) |  | $\mathbf{x}_{t+1}=\mathbf{x}_{t}+\alpha\nabla_{\mathbf{x}_{t}}\log
    p(\mathbf{x}_{t})+\sqrt{2\alpha}\mathbf{z}_{t},$ |  |'
  prefs: []
  type: TYPE_TB
- en: where $\mathbf{z}_{t}\sim\mathcal{N}(0,\mathbf{I})$, and $\alpha$ is an appropriate
    small constant. Initialized randomly, after a sufficiently large number of iterations,
    and under some mild conditions on $p({\mathbf{x}})$, this process converges to
    a sampling from the distribution $p(\mathbf{x})$ whose score function is used [[230](#bib.bib230)].
    Intuitively, the algorithm follows the direction of the gradient of the log-probability,
    climbing from one image to a more probable one. This is a gradient ascent process,
    and the noise is added in each iteration to provide stochasticity, which effectively
    leads to sampling from $p(\mathbf{x})$ rather than converging to a local maximum.
  prefs: []
  type: TYPE_NORMAL
- en: While it is tempting to use the true data distribution’s score function in Langevin
    dynamics, a few problems prevent such a use [[260](#bib.bib260)]. One of the main
    issues lies with the well-known cardinal manifold assumption [[239](#bib.bib239)],
    which relies on the observation that natural images reside on a low-dimensional
    manifold in their embedding space. Therefore, for a random initialization of $\mathbf{x}_{0}$,
    it holds with probability $1$ that $p(\mathbf{x}_{0})=0$, rendering the score
    function undefined at best, and without an ability to drift towards the image
    manifold in subsequent iterations. A possible solution is to approximate $p(\mathbf{x})$
    by its slightly blurred counterpart $p(\mathbf{y})$, where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$,
    ${\mathbf{v}}\sim{\cal N}(0,\sigma^{2}{\mathbf{I}})$, with a very small $\sigma$ [[296](#bib.bib296)].
    This resolves the aforementioned problem, as the Gaussian noise distribution has
    infinite tails. However, in practice, such a Langevin sampling algorithm requires
    many thousands of iterations to converge [[155](#bib.bib155)], hindering its practical
    applicability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The authors of [[260](#bib.bib260)] suggest the *Annealed Langevin Dynamics*
    (ALD) algorithm^(11)^(11)11A very similar algorithm has been proposed in parallel
    by [[120](#bib.bib120)]. Preceding these two works is the one reported in [[257](#bib.bib257)]
    who proposed a similar process while relying on a different rationale borrowed
    from statistical physics., which considers a sequence of Gaussian noisy image
    distributions ${p_{0}(\mathbf{y}),p_{1}(\mathbf{y}),\dots,p_{L-1}(\mathbf{y}),p_{L}(\mathbf{y})}$
    with standard deviations ${\sigma_{0}>\sigma_{1}>\dots>\sigma_{L-1}>\sigma_{L}}$.
    Applying a few iterations of Langevin dynamics for each of the distributions,
    starting with a very large $\sigma_{0}$ and ending with a very small $\sigma_{L}$,
    enables a faster convergence. Each of these steps is applied using a denoiser
    that estimates the score function, and the output of each such process is used
    to initialize the next. This implies that the synthesis creates a chain of noisy
    images with diminishing levels of noise, starting with pure canonical Gaussian
    noise and gradually carving out an image content out of it. Intuitively, this
    translates to drawing from a wide distribution and then gradually narrowing it,
    leading to faster sampling and better performance in image generation. Algorithm
    [1](#alg1 "Algorithm 1 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    presents this image sampler: The outer loop sweeps through the $L+1$ values of
    $\sigma$, while the inner loop applies $T$ Langevin steps for each. The score
    function $\nabla_{{\mathbf{x}}}\log p_{i}({\mathbf{x}})$, which stands for the
    $\sigma_{i}$-blurred PDF of ${\mathbf{x}}$, is approximated by'
  prefs: []
  type: TYPE_NORMAL
- en: '| (27) |  | $\displaystyle\nabla_{{\mathbf{x}}}\log p_{i}({\mathbf{x}})=\frac{D({\mathbf{x}},\sigma_{i})-{\mathbf{x}}}{\sigma_{i}^{2}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Observe that the step size $\alpha$ is modified throughout this process, chosen
    to be proportional to $\sigma_{i}^{2}$. This aligns with the fact that larger
    $\sigma$ values imply a more regular and smooth PDF, which is easier to sample
    from.^(12)^(12)12A different explanation for this choice of the step size is given
    in [[260](#bib.bib260)], motivated by a desire to better balance the norms of
    the score versus the additive noise in the Langevin update formula. Figure [11](#S8.F11
    "Figure 11 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") presents several
    examples of temporal steps in the ALD process that starts with pure Gaussian noise
    and ends with a high-quality synthesized image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Input: $\left\{\sigma_{i}\right\}_{i=0}^{L}$, $\epsilon$, $T$Initialize $\mathbf{x}_{0}\sim{\cal
    N}(0,{\mathbf{I}})$for *$i$ $\leftarrow$ $0$ to $L$* do       $\alpha_{i}\leftarrow\epsilon\cdot\sigma_{i}^{2}/\sigma_{L}^{2}$      for *$t$
    $\leftarrow$ $1$ to $T$* do             Draw ${\mathbf{z}}_{t}\sim\mathcal{N}\left(0,\mathbf{I}\right)$            
    ${\mathbf{x}}_{t}$ $\leftarrow$ ${\mathbf{x}}_{t-1}+\alpha_{i}\left[D({\mathbf{x}}_{t-1},\sigma_{i})-{\mathbf{x}}_{t-1}\right]/\sigma_{i}^{2}+\sqrt{2\alpha_{i}}{\mathbf{z}}_{t}$      
    end for      $\mathbf{x}_{0}\leftarrow\mathbf{x}_{T}$end forOutput: $\mathbf{x}_{0}$'
  prefs: []
  type: TYPE_NORMAL
- en: Algorithm 1 the Annealed Langevin Dynamics (ALD) algorithm
  prefs: []
  type: TYPE_NORMAL
- en: 'The ALD algorithm sparked a wave of related works [[261](#bib.bib261), [120](#bib.bib120),
    [262](#bib.bib262), [208](#bib.bib208), [287](#bib.bib287), [68](#bib.bib68),
    [122](#bib.bib122), [143](#bib.bib143), [121](#bib.bib121)] that continually improved
    the performance of these generative *diffusion models*, eventually surpassing
    that of GANs [[68](#bib.bib68)]. We show some of their results in Figure [12](#S8.F12
    "Figure 12 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). Nevertheless, these
    iterative algorithms are still considerably slower than GANs, so substantial work
    has been invested in improving their speed without compromising significantly
    on generation quality [[258](#bib.bib258), [135](#bib.bib135), [247](#bib.bib247)],
    often achieving impressive speedup levels. Diffusion models have since become
    ubiquitous in many applications [[142](#bib.bib142), [209](#bib.bib209), [21](#bib.bib21),
    [116](#bib.bib116), [6](#bib.bib6), [253](#bib.bib253), [254](#bib.bib254), [144](#bib.bib144)],
    prompting researchers to prepare surveys of their impact on the image processing
    field and beyond [[315](#bib.bib315), [60](#bib.bib60), [36](#bib.bib36)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e4830e67ca96bac7e761f825e7d42c4e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Temporal steps along 3 independent synthesis paths of the Annealed
    Langevin Dynamics [[260](#bib.bib260)] algorithm, using a denoiser [[261](#bib.bib261)]
    trained on LSUN bedroom [[319](#bib.bib319)] images.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4b11019b00a968914d0e380ae37f458e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: Image generation results for CelebA-HQ [[172](#bib.bib172)] (left)
    and ImageNet [[66](#bib.bib66)] (right) using score-based denoising diffusion
    generative models [[262](#bib.bib262), [68](#bib.bib68)].'
  prefs: []
  type: TYPE_NORMAL
- en: '9 Discovery 3: High Perceptual Quality Image Recovery'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We are now stepping into the last and what we believe to be one of the most
    exciting topics in the story of image denoisers – solving general linear inverse
    problems while striving for perfect perceptual quality, and achieving this with
    the support of an MMSE denoiser. We start with the simplest inverse problem –
    image denoising itself – and grow from there to more general recovery tasks.
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Revisiting the Image Denoising Problem
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We return to the classic image denoising problem, where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$
    in a given noisy image, ${\mathbf{x}}\sim p({\mathbf{x}})$ is it’s ideal origin,
    and ${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2})$ is the AWGN. Our goal
    is to recover ${\mathbf{x}}$, but now we change the rules of the game by expecting
    high perceptual quality results. How could this be achieved?
  prefs: []
  type: TYPE_NORMAL
- en: 'Throughout the classical era of denoising, and well into the modern AI days,
    denoisers were mostly evaluated using the Mean Squared Error (MSE) measure shown
    in Equation ([2](#S2.E2 "Equation 2 ‣ 2.1 Problem Definition ‣ 2 Image Denoising
    – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –")) (or tightly related measures such as the Peak Signal-to-Noise Ratio
    – PSNR). As can be seen in Figure [2](#S4.F2 "Figure 2 ‣ 1st item ‣ 4 Image Denoising
    – The Deep Learning Revolution ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –"), MSE has been and still is a commonly used performance
    measure for denoisers. The MSE metric has several clear benefits: it is zero when
    the denoiser perfectly recovers the image, it is intuitive to understand, and
    it produces mathematically elegant results for theoretical analysis, as well as
    practical considerations such as ease of differentiation for optimization.'
  prefs: []
  type: TYPE_NORMAL
- en: 'However, the MSE distortion measure suffers from a critical shortcoming: As
    discussed in Section [2.1](#S2.SS1 "2.1 Problem Definition ‣ 2 Image Denoising
    – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") and in Appendix [A](#A1 "Appendix A Derivation of the MMSE Estimation
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    the best possible result in MSE (MMSE), regardless of the denoising method used
    to approximate it, would rely on a conditional expectation,'
  prefs: []
  type: TYPE_NORMAL
- en: '| (28) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\operatorname*{arg\,min}_{{\hat{\mathbf{x}}}}\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\int_{{\mathbf{x}}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'In other words, when optimizing for MSE, our main goal is to get as close as
    possible to the original image in expectation, and this implies an averaging over
    all possible solutions, weighted by their posterior probability. Thus, depending
    on the geometry of the image manifold and the severity of the noise, the MMSE
    solution may tend to be too blurry and of relatively low probability $p({\hat{\mathbf{x}}}_{MMSE})$,
    falling outside of the desired manifold. We illustrate this phenomenon in a 2-dimensional
    example in Figure [13](#S9.F13 "Figure 13 ‣ 9.1 Revisiting the Image Denoising
    Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f6d747e8bbb458a5c184dc5b7b866920.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: A $2$-dimensional qualitative demonstration of the disadvantages
    of MMSE denoising. Given a noisy image, the MMSE denoiser falls outside of the
    image manifold, whereas a posterior sampler would necessarily sample points that
    reside on it. This leads to better perceptual quality in the denoising results.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Indeed, the fact that MMSE denoising achieves optimal $L_{2}$ distortion necessarily
    implies that *perceptual* quality is compromised. The authors of [[22](#bib.bib22)]
    prove the existence of a “perception-distortion tradeoff”: distortion (of any
    kind!) and perceptual quality are at odds with each other, and optimizing one
    necessarily deteriorates the other. In this context, perceptual quality is defined
    as the proximity between the original image distribution $p(\mathbf{x})$, and
    the denoised image one $p(\hat{\mathbf{x}})$. Figure [14](#S9.F14 "Figure 14 ‣
    9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –") presents the essence of these findings in [[22](#bib.bib22)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/01323512d2f86da4e1ee3f4632e8a607.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 14: The perception-distortion trade-off [[22](#bib.bib22)]: Any recovery
    algorithm necessarily performs on the blue-curve or above it. On the perception-distortion
    bound curve, the top-left point refers to the MMSE estimation, while the right-bottom
    one (or right to it – see [[22](#bib.bib22)]) is obtained by a posterior sampler.
    A gap of $3$dB divides between the two when using the MSE distortion measure.'
  prefs: []
  type: TYPE_NORMAL
- en: 'With this tension between visual quality and distortion in mind, alternative
    approaches to MSE were developed over the years, aiming for high perceptual quality
    denoising [[69](#bib.bib69), [67](#bib.bib67), [212](#bib.bib212), [146](#bib.bib146)].
    One such technique is to sample from the posterior distribution: given a noisy
    image ${\mathbf{y}}$, we aim to develop a denoiser that outputs $\hat{\mathbf{x}}\sim
    p(\mathbf{x}|\mathbf{y})$, *i.e.*, samples from the posterior distribution of
    pristine images given the noisy measurement. A successful posterior sampler would
    achieve perfect perceptual quality, as when marginalizing over $\mathbf{y}$, we
    get $p(\hat{\mathbf{x}})=p(\mathbf{x})$. It is important to notice that this technique
    involves a subtle paradigm shift – the denoiser is no longer a deterministic function
    of the noisy input $\mathbf{y}$, but rather a stochastic one and this implies
    a multitude of possible solutions. In the following, we present two pragmatic
    approaches for approximating posterior sampling behavior.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To traverse the perception-distortion tradeoff, a Waserstein Generative Adversarial
    Network (WGAN) conditioned on noisy images can be used [[22](#bib.bib22), [69](#bib.bib69)].
    Such a network consists of two main elements: a *generator*, which takes a noisy
    image as well as a random vector as input, and outputs a denoised image, and a
    *discriminator*, whose job is to distinguish between denoised and original images.
    The discriminator is trained to discriminate between the generator’s outputs and
    original images, while the generator optimizes two loss functions: the MSE with
    respect to the original image, and the ability to “fool” the discriminator, thus
    encouraging its output to “look like a real image” in the eyes of the discriminator.
    These two losses, as proven in [[22](#bib.bib22)], are at odds with one another,
    and tuning their respective weights in the total loss function translates to the
    traversal of the perception-distortion tradeoff. This idea is further improved
    upon by [[212](#bib.bib212)]: instead of requiring low distortion on individual
    generator samples, the requirement is made on their mean. This results in a loss
    function that encourages the generator to act as a sampler from the posterior
    distribution, therefore attaining near-perfect perceptual quality while remaining
    faithful to the input image.'
  prefs: []
  type: TYPE_NORMAL
- en: An alternative posterior sampling approach, which reconnects with MMSE denoisers,
    is using the annealed Langevin dynamics algorithm [[260](#bib.bib260)] presented
    in the previous section. Recall that ALD uses the score function $\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})$ to sample from a prior distribution $p_{i}({\tilde{\mathbf{x}}})$^(13)^(13)13In
    these notations, $p_{i}$ stands for a $\sigma_{i}$-blurred PDF version of the
    original prior $p({\mathbf{x}})$, and ${\tilde{\mathbf{x}}}$ is a temporary synthesized
    image that contains annealing Gaussian noise with variance $\sigma_{i}^{2}$..
    In [[146](#bib.bib146)], the regular ALD algorithm is extended to treat image
    denoising by analytically conditioning the score function on a noisy input $\mathbf{y}$
    – effectively sampling from the posterior distribution $p_{i}({\tilde{\mathbf{x}}}|\mathbf{y})$.
    The algorithm is initialized with the noisy input $\mathbf{y}$, which is then
    gradually denoised using the conditional score function, obtained using the Bayes
    rule,
  prefs: []
  type: TYPE_NORMAL
- en: '| (29) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;{\mathbf{y}})=\nabla_{{\tilde{\mathbf{x}}}}\log\frac{p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})p_{i}({\tilde{\mathbf{x}}})}{p({\mathbf{y}})}=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\nabla_{{\tilde{\mathbf{x}}}}\log p(\mathbf{y}&#124;\mathbf{x}_{t}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'The term $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}})$ is
    the regular score function which can be approximated by an MSE-trained denoiser.
    As for the other term, $\nabla_{{\tilde{\mathbf{x}}}}\log p({\mathbf{y}}|{\tilde{\mathbf{x}}})$,
    observe that this likelihood can be rewritten by exploiting two facts: (i) ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$
    is the noisy image (${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}$),
    and (ii) ${\tilde{\mathbf{x}}}={\mathbf{x}}+{{\mathbf{z}}}$ is the annealed solution
    (${{\mathbf{z}}}\sim{\cal N}(0,\sigma_{i}^{2}{\mathbf{I}})$), and thus'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{x}}+{\mathbf{v}}-{\mathbf{x}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: If we assume statistical independence between the measurements’ noise and the
    annealing one, ${\mathbf{v}}-{\mathbf{z}}$ becomes a plain Gaussian vector. However,
    its conditioning on the knowledge of ${\tilde{\mathbf{x}}}$ leads to a dead-end,
    since this image contains ${\mathbf{z}}$ in it. The alternative, as developed
    in [[146](#bib.bib146)], is to construct the annealing noise such that ${\mathbf{v}}-{\mathbf{z}}$
    is statistically independent of both ${\mathbf{z}}$ and ${\tilde{\mathbf{x}}}$.
    This can be obtained by breaking the measurements’ noise ${\mathbf{v}}$ into small
    fragments, and assume that their partial accumulations constitute the annealing
    noise in each of the stages. Thus, ${\mathbf{v}}-{\mathbf{z}}$ is a white Gaussian
    noise that has no correlation with the noise ${\mathbf{z}}$, nor with the target
    image ${\mathbf{x}}$. Put in other words, this likelihood expression becomes simple
    when considering $\mathbf{y}$ to be an even more noisy version of ${\tilde{\mathbf{x}}}$.
    This in turn makes $p(\mathbf{y}|{\tilde{\mathbf{x}}})$ a simple white Gaussian
    distribution of the form ${\cal N}(0,(\sigma_{{\mathbf{y}}}^{2}-\sigma_{i}^{2}){\mathbf{I}})$.
    Therefore,
  prefs: []
  type: TYPE_NORMAL
- en: '| (31) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;\mathbf{y})=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\frac{\mathbf{y}-{\tilde{\mathbf{x}}}}{\sigma_{\mathbf{y}}^{2}-\sigma_{i}^{2}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Plugging this modification into ALD turns Algorithm [1](#alg1 "Algorithm 1
    ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") into an image denoiser. Beyond
    its ability to attain near-perfect perceptual quality, this approach has the advantage
    of not requiring any special model training. Crucially, this finding shows that
    simple MSE denoiser training is more powerful than originally thought – not only
    can it approximate MMSE denoiser behavior, but it can also perform denoising by
    posterior sampling under the Langevin dynamics scheme. Figure [15](#S9.F15 "Figure
    15 ‣ 9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual
    Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") presents a denoising result by the above-described method.
    Several observations are in order from this figure:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The generated results are indeed of very high perceptual quality;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Running ALD several times results with different solutions, all valid and yet
    diverse – see the STD image that exposes the uncertainty within the task being
    solved;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Denoising ${\mathbf{y}}$ directly by $D({\mathbf{y}},\sigma_{{\mathbf{y}}})$
    leads to better MMSE but poorer perceptual quality;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The figure also shows the evolving solution within the ALD steps, and as can
    be seen, the noise in ${\mathbf{y}}$ is effectively peeled layer by layer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6d58b9fef540972602700a6e5417cf40.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 15: Image denoising using the modified version of Annealed Langevin
    Dynamics [[146](#bib.bib146)]. Top row (left to right): An original image, its
    noisy version ($\sigma_{{\mathbf{y}}}=100$), the MMSE-optimized denoiser’s result,
    and the STD of the sampled solutions. Middle row: 6 sampled ALD denoising solutions.
    Bottom row: 6 intermediate steps within the ALD algorithm.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 High Perceptual Quality Solution to Inverse Problems
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We now expand our discussion by returning to general linear inverse problems
    of the form ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$, where ${\mathbf{H}}\in\mathbb{R}^{M\times
    N}$ is a known matrix, ${\mathbf{v}}\in\mathbb{R}^{M}$ is AWGN, and ${\mathbf{y}}\in\mathbb{R}^{M}$
    is the given measurement vector. Our goal is to propose novel solutions to these
    problems while striving for high perceptual quality.
  prefs: []
  type: TYPE_NORMAL
- en: The above discussion on the perception-distortion tradeoff is not limited to
    image denoising, but also applies to more general inverse problems [[22](#bib.bib22)].
    There too, potential solvers need to tradeoff distortion metrics (e.g. MSE) versus
    perception measures (e.g. the distribution shift between real images and the obtained
    solutions). Indeed, MSE in these cases may become far more challenging as an optimization
    goal due to the ill-posedness of the inverse problems. Consider, as an example,
    an inpainting problem in which the bottom half of the image is given and the goal
    is to recover the top part. The MMSE solution in this case necessarily averages
    all possible completions, resulting in a very blurry outcome. More broadly, optimizing
    for MSE in this context would result in a clear regression-to-the-mean, which
    is significantly more pronounced in under-determined inverse problems than in
    image denoising.
  prefs: []
  type: TYPE_NORMAL
- en: 'Successful inverse problem solvers, such as the Plug-and-Play Prior [[295](#bib.bib295)]
    and RED [[231](#bib.bib231)] algorithms mentioned in Section [7](#S7 "7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –"), aim for a Maximum-a-Posteriori (MAP)
    solution to the inverse problem at hand, rather than MMSE. While these methods
    achieve impressive results, the MAP solution can be improved upon in terms of
    perceptual quality without compromising on distortion performance [[22](#bib.bib22)].
    This is due to the deterministic nature of MAP solvers – a solver that aims for
    best perceptual quality should necessarily be stochastic in order to account for
    the multiple possible solutions to the given problem [[211](#bib.bib211)].'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/56e0f82d432ef6608aa992be117176ef.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 16: Comparison of an MMSE result with samples from the posterior distribution
    using SNIPS [[145](#bib.bib145)]. Note the subtle improvements in perceptual quality
    from MMSE to the posterior samples, especially in the finer details such as the
    hair. The comparison is conducted on $64\times 64$ pixel images from CelebA [[172](#bib.bib172)],
    on the problems of compressive sensing, inpainting, and $4\times$ super-resolution
    (top-to-bottom).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to the image denoising case, stochastically sampling from the posterior
    distribution achieves perfect perceptual quality in general inverse problems.
    Following the road paved in the previous section, an appealing way to approximate
    such sampling would be to follow Equation ([29](#S9.E29 "Equation 29 ‣ 9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")),
    using a generative diffusion model and augmenting the score by an analytical term
    that conditions on the observed measurement $\mathbf{y}$. This idea has been initially
    suggested by [[262](#bib.bib262), [138](#bib.bib138)] for handling noiseless linear
    inverse problems, and later extended to the more general case in [[145](#bib.bib145),
    [142](#bib.bib142), [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)]. Below
    we describe the essence of the proposed approach in SNIPS [[145](#bib.bib145)].
    Visual examples of this method in action are brought in Figure [16](#S9.F16 "Figure
    16 ‣ 9.2 High Perceptual Quality Solution to Inverse Problems ‣ 9 Discovery 3:
    High Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") for several inverse problems.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Our goal is to obtain a closed-form expression for the term $\nabla_{{\tilde{\mathbf{x}}}}\log
    p({\mathbf{y}}|{\tilde{\mathbf{x}}})$ in Equation ([29](#S9.E29 "Equation 29 ‣
    9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")). We use the following two relationships: (i) ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$
    is the noisy measurement (${\mathbf{v}}\sim{\cal N}\left(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}\right)$),
    and (ii) ${\tilde{\mathbf{x}}}={\mathbf{x}}+{\mathbf{z}}$ is the annealed solution
    (${\mathbf{z}}\sim{\cal N}(0,\sigma_{i}^{2}{\mathbf{I}})$). The likelihood function
    can be simplified to'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\mathbf{H}}{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}-{\mathbf{H}}{\mathbf{x}}-{\mathbf{H}}{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'As in the denoising case in Equation ([9.1](#S9.Ex2 "9.1 Revisiting the Image
    Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), statistical
    independence between ${\mathbf{v}}$ and ${\mathbf{z}}$ cannot be assumed due to
    the dependency on ${\tilde{\mathbf{x}}}$. The alternative, as shown by SNIPS [[145](#bib.bib145)]
    relies again on a delicate connection between these two random entities, obtained
    by a decoupling of the measurements’ equation via an Singular Value Decomposition
    (SVD) of the degradation matrix $\mathbf{H}={\mathbf{U}}\bm{\Sigma}{\mathbf{V}}^{T}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{U}}^{T}{\mathbf{v}}-\bm{\Sigma}{\mathbf{V}}^{T}{\mathbf{z}}&#124;{\mathbf{V}}^{T}{\mathbf{x}}+{\mathbf{V}}^{T}{\mathbf{z}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\hat{\mathbf{v}}}-\bm{\Sigma}{\hat{\mathbf{z}}}&#124;{\hat{\mathbf{x}}}+{\hat{\mathbf{z}}})$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\prod_{k}p({\hat{v}}_{k}-s_{k}{\hat{z}}_{k}&#124;{\hat{x}}_{k}+{\hat{z}}_{k}).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'The second row in the above equation is obtained by transforming the term ${\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}$
    by the matrix ${\mathbf{U}}^{T}$, and similarly transforming ${\mathbf{x}}+{\mathbf{z}}$
    via a multiplication with ${\mathbf{V}}^{T}$. As these are unitary matrices, the
    transformations applied do not change the statistics. Considering the transformed
    vectors ${\mathbf{U}}^{T}{\mathbf{y}}={\hat{\mathbf{y}}}$, ${\mathbf{V}}^{T}{\mathbf{x}}={\hat{\mathbf{x}}}$,
    ${\mathbf{V}}^{T}{\mathbf{z}}={\hat{\mathbf{z}}}$ and ${\mathbf{U}}^{T}{\mathbf{v}}={\hat{\mathbf{v}}}$
    leads to the third row in the above equation. This joint probability can be decoupled
    into a separable Gaussian distribution if we choose each entry ${\hat{v}}_{k}-s_{k}{\hat{z}}_{k}$
    to be independent of ${\hat{z}}_{k}$, just as practiced in the denoising case,
    and this time while taking into account the singular value $s_{k}$. This algorithm,
    fully described in [[145](#bib.bib145)], demonstrates considerable success in
    a number of inverse problems (see Figure [16](#S9.F16 "Figure 16 ‣ 9.2 High Perceptual
    Quality Solution to Inverse Problems ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")), and already has several followup works [[142](#bib.bib142),
    [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)].'
  prefs: []
  type: TYPE_NORMAL
- en: We should mention that an alternative to all the above exists, in which one
    simply adds the corrupted measurements $\mathbf{y}$ as an input to the denoising
    model itself, effectively conditioning the entire generative process on $\mathbf{y}$ [[245](#bib.bib245),
    [243](#bib.bib243), [303](#bib.bib303)]. This approach requires designing and
    training a separate denoiser for each inverse problem, as the denoiser would need
    to implicitly learn the connection between the images and their corresponding
    measurements for the specific problem at hand. Interestingly, this approach requires
    pairs of images, $\mathbf{x}$ and $\mathbf{y}$, in its training, but does not
    utilize knowledge of the degradation model itself (e.g., the matrix $\mathbf{H}$).
    This property allows this alternative approach to generalize beyond clearly formulated
    inverse problems, and handle tasks such as stylization, JPEG-deblocking, and more.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5287ce1d87ab1ae8ca56ef7937a0eb7c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 17: Examples of synthesized images using DALL-E 2 [[224](#bib.bib224)],
    a text-to-image generative denoising diffusion model. The input conditioning text
    is written below each image.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A particularly interesting case is when $\mathbf{y}$ is a textual description
    of the image contents. By conditioning the denoiser model on such text, the generative
    diffusion process allows users to perform *text-to-image generation* [[224](#bib.bib224),
    [244](#bib.bib244), [232](#bib.bib232), [14](#bib.bib14)]. This unprecedented
    capability became instantly popular, as users were able to synthesize high-quality
    images by simply describing the desired result in natural language, as we demonstrate
    in Figure [17](#S9.F17 "Figure 17 ‣ 9.2 High Perceptual Quality Solution to Inverse
    Problems ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). These models have
    become a centerpiece in an ongoing and quickly advancing research area, as they
    have been adapted for image editing [[147](#bib.bib147), [202](#bib.bib202)],
    object recontextualization [[241](#bib.bib241), [95](#bib.bib95)], 3D object generation [[220](#bib.bib220)],
    and more [[119](#bib.bib119), [129](#bib.bib129), [213](#bib.bib213), [346](#bib.bib346)].'
  prefs: []
  type: TYPE_NORMAL
- en: 10 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Removal of white additive Gaussian noise from an image is a fascinating topic,
    both because it poses a very interesting engineering challenge, and even more
    so, because it creates new opportunities in image processing and machine learning.
    In this paper we highlight these two branches of activities. The first half of
    the paper concentrates on the design of such denoisers, with a particular interest
    on the impact of the AI revolution on this field. The second half of the paper
    features the usefulness of such image denoisers for handling other tasks, such
    as image synthesis and solving inverse problems while targeting high-perceptual
    quality solutions. Figure [18](#S10.F18 "Figure 18 ‣ 10 Conclusion ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") encapsulates this
    part of the story in a block diagram.'
  prefs: []
  type: TYPE_NORMAL
- en: Much remains to be done in this domain, in better understanding how to design
    appropriate MMSE denoisers, and in harnessing them to other tasks beyond the ones
    described in this paper, such as compression, segmentation, and more. More broadly,
    there are so many opportunities and challenges in better understanding, designing,
    and proposing creative usage of image denoisers.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b42e0aa648a9841e72c910ba546970b0.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 18: A summary of the main message of this paper: an MMSE denoiser is
    key in synthesizing images and solving inverse problems. Interestingly, there
    is a great unexplored proximity between PnP and RED algorithms [[295](#bib.bib295),
    [231](#bib.bib231)] and the more recent, diffusion-based, techniques for getting
    high perceptual quality solutions for inverse problems [[145](#bib.bib145), [53](#bib.bib53),
    [195](#bib.bib195)].'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix A Derivation of the MMSE Estimation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Consider an ideal image ${\mathbf{x}}$ drawn from the probability density function
    $p({\mathbf{x}})$, and assume that we are given a measurement of it, ${\mathbf{y}}$,
    related to it via the conditional probability $p({\mathbf{y}}|{\mathbf{x}})$.
    Our goal is to find the estimator ${\hat{\mathbf{x}}}=f({\mathbf{y}})$ that minimizes
    the expected mean-squared-error,
  prefs: []
  type: TYPE_NORMAL
- en: '| (34) |  | $\displaystyle MSE=\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}~{}&#124;~{}{\mathbf{y}}\right)=\mathbb{E}\left(\&#124;{\mathbf{x}}-f({\mathbf{y}})\&#124;_{2}^{2}~{}&#124;~{}{\mathbf{y}}\right)=\int\&#124;{\mathbf{x}}-f({\mathbf{y}})\&#124;_{2}^{2}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Observe that this expectation is taken with respect to the unknown image ${\mathbf{x}}$,
    while considering ${\mathbf{y}}$ as known. In order to minimize the above measure,
    we take a derivative of this expression with respect to $f({\mathbf{y}})$ and
    null it,
  prefs: []
  type: TYPE_NORMAL
- en: '| (35) |  | $\displaystyle\frac{d}{df({\mathbf{y}})}\int\left\&#124;{\mathbf{x}}-f({\mathbf{y}})\right\&#124;_{2}^{2}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=-2\int\left({\mathbf{x}}-f({\mathbf{y}})\right)p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=0.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: This results in
  prefs: []
  type: TYPE_NORMAL
- en: '| (36) |  | $\displaystyle\int{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\int
    f({\mathbf{y}})p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=f({\mathbf{y}})\int
    p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=f({\mathbf{y}}).$ |  |'
  prefs: []
  type: TYPE_TB
- en: The last step on the right-hand-side relies on the fact that $\int p({\mathbf{x}}|{\mathbf{y}})d{\mathbf{x}}=1$.
    Thus, we get the familiar closed-form solution for the MMSE estimation [[217](#bib.bib217)],
  prefs: []
  type: TYPE_NORMAL
- en: '| (37) |  | $\displaystyle f_{MMSE}({\mathbf{y}})=\int_{\mathbf{x}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  prefs: []
  type: TYPE_TB
- en: As a final step, as the posterior is not directly accessible, we may use the
    Bayes rule [[137](#bib.bib137)] and write
  prefs: []
  type: TYPE_NORMAL
- en: '| (38) |  | $\displaystyle f_{MMSE}({\mathbf{y}})=\int_{\mathbf{x}}{\mathbf{x}}\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{p({\mathbf{y}})}d{\mathbf{x}}=\int_{\mathbf{x}}{\mathbf{x}}\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{\int_{\mathbf{x}}p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}}d{\mathbf{x}},$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where this formula uses the ingredients we started with – $p({\mathbf{y}}|{\mathbf{x}})$
    and $p({\mathbf{x}})$.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B A Closer Look at the Evolution of Priors
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the Gibbs distribution form, $p({\mathbf{x}})=c\cdot\exp\{-\rho({\mathbf{x}})\}$,
    we shift our focus from the probability density function $p({\mathbf{x}})$ to
    it’s corresponding energy function $\rho({\mathbf{x}})$. Table [1](#S3.T1 "Table
    1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") brings a list of
    possible analytical expressions for $\rho({\mathbf{x}})$ as evolved in the image
    processing literature. Below we describe each of these options briefly, adopting
    the context of solving a general linear inverse problem of the form ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$
    with the assumptions that ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$
    and ${\mathbf{H}}$ is a full-rank known matrix of size $m\times N$ ($m<N$). The
    MAP estimation in this case is given by'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}$ | $\displaystyle=$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right]$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{x}})\right].$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Notice that $2\sigma^{2}$ was absorbed into the constant: $c=2\sigma^{2}$.
    Armed with this expression, let’s consider each of the choices in Table [1](#S3.T1
    "Table 1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") and explore
    its implications. Before diving into these options, observe that without the regularization
    provided by $\rho({\mathbf{x}})$, the above optimization becomes an ill-posed
    Least-Squares problem with infinitely many possible solutions. Thus, the added
    prior serves as an important regularization, pushing towards a single (and hopefully,
    meaningful) solution.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Energy regularization: If ${\mathbf{H}}^{T}{\mathbf{H}}$ cannot be inverted,
    the most obvious algebraic remedy would be to add a constant to its diagonal,
    resulting with the regularized solution ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{I}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    This is exactly the solution offered by the choice $\rho({\mathbf{x}})=\|{\mathbf{x}}\|_{2}^{2}$,
    and when the constant $c$ is taken to $0$, this leads to the familiar pseudo-inverse
    solution ${\hat{\mathbf{x}}}_{MAP}={\mathbf{H}}^{\dagger}{\mathbf{y}}$. While
    mathematically appealing, this option does not yield satisfactory visual results [[251](#bib.bib251)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Spatial Smoothness: It is well-known that adjacent pixels in natural images
    are more likely to be of smoothly varying values. Thus, penalizing a deviation
    from such a smoothness property seems well-justified [[15](#bib.bib15), [154](#bib.bib154)].
    Plugging the option $\rho({\mathbf{x}})=\|{\mathbf{L}}{\mathbf{x}}\|_{2}^{2}$
    into the MAP expression leads to the closed-form solution ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{L}}^{T}{\mathbf{L}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$,
    which is very-closely related to the well-known Wiener filter [[304](#bib.bib304)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Optimally Learned Transform: Given a large enough dataset of images, we could
    fit a multivariate Gaussian ${\cal N}({\mathbf{0}},{\mathbf{R}})$ to them by adjusting
    the second moment. The assumed zero mean is easily obtained by subtracting the
    mean image from the given data. PCA [[215](#bib.bib215)] or Karhunen-Loéve Transform
    (KLT) [[174](#bib.bib174), [140](#bib.bib140), [37](#bib.bib37), [136](#bib.bib136)]
    offer a clear computational path towards this moment matrix ${\mathbf{R}}$ as
    the auto-correlation matrix of the available data. When the expression $\rho({\mathbf{x}})={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    is plugged into the MAP estimation, we come back to the Wiener filter, this time
    as ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{R}}^{-1})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    Note that the same treatment could emerge from this formulation – $\rho({\mathbf{x}})=\|{\mathbf{T}}{\mathbf{x}}\|_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$,
    where ${\mathbf{T}}$ is the corresponding transform that should be applied on
    ${\mathbf{x}}$, and clearly ${\mathbf{T}}^{T}{\mathbf{T}}={\mathbf{R}}^{-1}$.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weighted Smoothness: All the above options suffer from the same difficulty
    – they produce overly smoothed results. In retrospect, the reason is obvious:
    non-smooth behavior is heavily penalized and thus not encouraged, which results
    with smeared edges. A way to overcome this difficulty is to produce a weight map
    that describes the local smoothness tendency – regions in which smoothness is
    believed to be correct should be assigned with a high weight, while low weight
    should be given to regions suspected to be textured or edges [[246](#bib.bib246),
    [52](#bib.bib52)]. By constructing a diagonal matrix ${\mathbf{W}}$ that contains
    the above weights as the main diagonal, and using the choice & $\rho({\mathbf{x}})=\|{\mathbf{L}}{\mathbf{x}}\|_{{\mathbf{W}}}^{2}$,
    the MAP estimation becomes ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{L}}^{T}{\mathbf{W}}{\mathbf{L}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    This is a spatially adaptive solution, dependent on the local weights. One may
    consider an iterative approach where the temporary solution ${\hat{\mathbf{x}}}_{MAP}$
    is leveraged to update the weights and then ${\hat{\mathbf{x}}}_{MAP}$ is re-computed.
    This interesting option leads to the robust statistics alternative discussed next [[20](#bib.bib20)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Before proceeding with the other prior options, we would like to draw the readers’
    attention to the fact that all the above choices correspond to the core assumption
    that the probability density function $p({\mathbf{x}})$ is a multivariate Gaussian.
    The obtained visual results of these techniques expose the fact that this Gaussianity
    assumption is not adequate, and indeed, later research in image processing turned
    to non-Gaussian and heavy-tailed alternative distributions, which we discuss next.
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Robust statistics: Here is a simple experiment – take any natural image, apply
    a Laplacian on it, and gather a histogram of the resulting values. This histogram
    is likely to look as a heavy-tailed probability density function of a form similar
    to $c\cdot\exp(-|x|^{\alpha})$ with $\alpha\ll 2$. This is exactly the deviation
    from Gaussianity referred to above. Thus, the robust statistics alternative [[126](#bib.bib126),
    [97](#bib.bib97), [96](#bib.bib96), [44](#bib.bib44), [238](#bib.bib238)] suggests
    a replacement of the $L_{2}$-norm of ${\mathbf{L}}{\mathbf{x}}$ by $L_{1}$ or,
    more broadly, by functions of the form ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    (e.g. $\mu(x)=|x|^{\alpha}$). Notice that from here on, closed-form MAP solution
    cannot be obtained, and iterative minimization strategies are necessary.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Adopting a different point of view, robust statistics considers pixel on edges
    and textures regions as outliers to the Gaussian distribution, and thus use robust
    estimation techniques for their better handling.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Total-Variation (TV): The same motivation as described above led to this brilliant
    PDE formulation of spatial smoothness, $\rho({\mathbf{x}})=\int_{v\in\Omega}|\nabla{\mathbf{x}}(v)|dv$,
    which accumulates the length of the spatial gradients instead of their squares [[240](#bib.bib240)].
    In its discretized form, its treatment is very similar to the robust-statistics
    option. However, TV has very different roots, providing a geometrically oriented
    edge-preserving measure of smoothness – see various extensions of this line of
    work in [[17](#bib.bib17), [99](#bib.bib99), [39](#bib.bib39), [3](#bib.bib3)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Other PDE-based options: While TV applies an $L_{1}$-norm on the spatial gradients,
    more general options can be envisioned, in which the accumulation is spatially
    adaptive, orientation sensitive, geometrically faithful, and more [[216](#bib.bib216),
    [38](#bib.bib38), [255](#bib.bib255), [302](#bib.bib302), [111](#bib.bib111)].
    Starting with the seminal anisotropic diffusion method by Perona and Malik [[216](#bib.bib216)],
    various such methods of the form $\rho({\mathbf{x}})=\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    were proposed and perfected over the years, forming an exciting sub-field of mathematically
    oriented image processing that relies on the vast knowledge in partial differential
    equations.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Field-of-Experts (FoE): Let us return to the robust statistics option described
    above and enrich it by considering a mixture of such distributions, $\rho({\mathbf{x}})=\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$.
    This implies the need to define a series of functions $\mu_{k}$ and their corresponding
    weights $\lambda_{k}$. FoE suggests to learn these elements from an image dataset,
    thus better fitting the assumed prior to natural images. While earlier work on
    FoE [[236](#bib.bib236)] suggested a patch-based maximum-likelihood learning approach,
    later efforts [[50](#bib.bib50)] brought a deep-learning alternative tools to
    this fitting.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wavelet sparsity: The idea of relying on transform coefficients for constructing
    $\rho({\mathbf{x}})$ has already been explored in the context of the KLT. The
    emergence of the Wavelet transform in the late 80’s brought a new way of thinking
    about signals and images, offering an elegant and more effective multi-scale representation
    that relies on non-linear approximation [[77](#bib.bib77), [76](#bib.bib76), [57](#bib.bib57),
    [98](#bib.bib98), [185](#bib.bib185), [177](#bib.bib177), [43](#bib.bib43), [221](#bib.bib221),
    [175](#bib.bib175), [325](#bib.bib325), [108](#bib.bib108)]. Wavelets offer a
    concise description of the data with as few as possible coefficients, this way
    giving birth to the central notion of sparsity. This translates well to the proposed
    prior $\rho({\mathbf{x}})=\|{\mathbf{W}}{\mathbf{x}}\|_{1}$ that promotes fewer
    non-zero dominant Wavelet coefficients.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'As an interesting side note, if we are handling the image denoising problem
    – i.e. ${\mathbf{H}}={\mathbf{I}}$ in Equation ([B](#A2.Ex8 "Appendix B A Closer
    Look at the Evolution of Priors ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")) – and the Wavelet transform matrix ${\mathbf{W}}$
    is unitary, the solution ${\hat{\mathbf{x}}}_{MAP}$ has a closed-form solution,
    obtained via a soft-shrinkage [[77](#bib.bib77), [76](#bib.bib76)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Self-similarity: So far we described two primary forces that promote simplicity
    in image content – spatial smoothness and representation sparsity. Self-similarity
    is a third such force that has been recognized as central by series of contributions,
    starting with the seminal Non-Local-Means (NLM) algorithm [[32](#bib.bib32)],
    and heavily relied upon by the famous BM3D [[61](#bib.bib61)] and other algorithms [[181](#bib.bib181),
    [274](#bib.bib274), [187](#bib.bib187), [46](#bib.bib46), [297](#bib.bib297),
    [203](#bib.bib203), [273](#bib.bib273), [248](#bib.bib248), [167](#bib.bib167)].
    Self-similarity stands for the assumption that any given (small-enough) patch
    in an image is likely to find very similar ones in the image support, and thus
    treating these together somehow is likely to lead to better recovery. More specifically,
    the expression we bring here as an illustration,'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '| (40) |  | $\displaystyle\rho({\mathbf{x}})=\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\},$
    |  |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: sweeps through the image support, extract a patch in location $k$ by the operator
    ${\mathbf{R}}_{k}{\mathbf{x}}$, and finds all its corresponding matches $j\in\Omega(k)$.
    Forcing proximity between ${\mathbf{R}}_{k}{\mathbf{x}}$ and the patches ${\mathbf{R}}_{j}{\mathbf{x}}$
    induces a strong regularization over the unknown image ${\mathbf{x}}$.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sparsity methods: While the notion of sparsity has already been exploited by
    wavelets, later work took this idea and strengthened it by considering redundant
    and learned representations. Under the assumption that ideal images can be described
    as linear combinations of atoms from a pre-specified dictionary ${\mathbf{D}}$,
    i.e., ${\mathbf{x}}={\mathbf{D}}\alpha$, forcing sparsity on the representation
    via the term $\|\alpha\|_{0}$ provides an appealing and computationally feasible
    choice for $\rho({\mathbf{x}})$ [[31](#bib.bib31), [88](#bib.bib88)]. Vast work
    along these lines has been done, considering global dictionaries and later local
    (patch-based) ones, leading to various very successful recovery algorithms [[89](#bib.bib89),
    [90](#bib.bib90), [4](#bib.bib4), [183](#bib.bib183), [182](#bib.bib182), [181](#bib.bib181),
    [81](#bib.bib81), [320](#bib.bib320), [71](#bib.bib71), [74](#bib.bib74), [100](#bib.bib100),
    [72](#bib.bib72), [85](#bib.bib85)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Low-Rank assumption: The last member to enter the Pantheon of image priors
    for image processing relies on a low-rank assumption over groups of similar patches.
    This idea is closely related to the self-similarity force described above, and
    in fact builds on top of it. Given a set of closely related patches, instead of
    forcing proximity between them, one may gather these as columns in a matrix and
    force a low-rank structure, implying that all these patches are spanned by few
    main directions. Several very strong recovery algorithms leveraged this idea in
    various forms, while exploiting theoretical analysis that ties the low-rank requirement
    to the nuclear-norm [[305](#bib.bib305), [35](#bib.bib35)]. By summing these norms
    over such groups, $\rho({\mathbf{x}})=\sum_{k}\|{\mathbf{X}}_{\Omega(k)}\|_{*}$,
    a very potent regularization is obtained [[110](#bib.bib110), [310](#bib.bib310)].'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table 2: Evolution of priors for images.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Years | Core concept | Formulae for $\rho(\cdot)$ | Representative |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| $\sim$ 1970 | Energy regularization | $\&#124;{\mathbf{x}}\&#124;_{2}^{2}$
    | [[251](#bib.bib251)] |'
  prefs: []
  type: TYPE_TB
- en: '| 1975-1985 | Spatial smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{2}^{2}$
    or $\&#124;{\mathbf{D}}_{v}{\mathbf{x}}\&#124;_{2}^{2}+\&#124;{\mathbf{D}}_{h}{\mathbf{x}}\&#124;_{2}^{2}$
    | [[154](#bib.bib154)] |'
  prefs: []
  type: TYPE_TB
- en: '| 1980-1985 | Optimally Learned Transform | $\&#124;{\mathbf{T}}{\mathbf{x}}\&#124;_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    | [[37](#bib.bib37)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | where ${\mathbf{T}}/{\mathbf{R}}$ is learned via PCA |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1980-1990 | Weighted smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{{\mathbf{W}}}^{2}$
    | [[246](#bib.bib246)] |'
  prefs: []
  type: TYPE_TB
- en: '| 1990-2000 | Robust statistics | ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    | [[20](#bib.bib20)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | e.g., Hubber-Markov |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1992-2005 | Total-Variation | $\int_{v\in\Omega}&#124;\nabla{\mathbf{x}}(v)&#124;dv$
    | [[240](#bib.bib240)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | or ${\mathbf{1}}^{T}\sqrt{&#124;{\mathbf{D}}_{v}{\mathbf{x}}&#124;^{2}+&#124;{\mathbf{D}}_{h}{\mathbf{x}}&#124;^{2}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| 1987-2005 | Other PDE-based options | $\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    | [[302](#bib.bib302)] |'
  prefs: []
  type: TYPE_TB
- en: '| 2005-2009 | Field-of-Experts | $\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$
    | [[237](#bib.bib237)] |'
  prefs: []
  type: TYPE_TB
- en: '| 1993-2005 | Wavelet sparsity | $\&#124;{\mathbf{W}}{\mathbf{x}}\&#124;_{1}$
    | [[76](#bib.bib76)] |'
  prefs: []
  type: TYPE_TB
- en: '| 2000-2010 | Self-similarity | $\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\}$
    | [[32](#bib.bib32), [61](#bib.bib61)] |'
  prefs: []
  type: TYPE_TB
- en: '| 2002-2012 | Sparsity methods | $\&#124;\alpha\&#124;_{0}~{}s.t.~{}{\mathbf{x}}={\mathbf{D}}\alpha$
    | [[31](#bib.bib31)] |'
  prefs: []
  type: TYPE_TB
- en: '| 2010-2017 | Low-Rank assumption | $\sum_{k}\&#124;{\mathbf{X}}_{\Omega(k)}\&#124;_{*}$
    | [[110](#bib.bib110)] |'
  prefs: []
  type: TYPE_TB
- en: 'As a summary, the above-described evolution of the priors has served as the
    skeleton of image processing, forming the consistent progress of this field over
    the years. This evolution is characterized by four major and interconnected trends:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A migration from the familiar Gaussian distribution to the less intuitive heavy-tailed
    ones;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A departure from $L_{2}$ to sparsity-promoting norms, such as the $L_{1}$;
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A drift from linear approximation techniques (e.g. PCA) to non-linear ones (e.g.
    wavelets and sparse modeling); and above all,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A replacement of axiomatic expressions with learned ones.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix C Landmark Denoisers over the Years
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Figure [2](#S4.F2 "Figure 2 ‣ 1st item ‣ 4 Image Denoising – The Deep Learning
    Revolution ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") we brought a graph showing the PSNR performance of landmark denoising
    algorithms over the years. Below we provide more information on these techniques
    for completeness of this study. For each of these we bring the full reference,
    describe the core algorithmic idea, and provide the PSNR denoising performance
    on the BSD68 dataset ($\sigma=25$). We should note that in choosing the methods
    to include in this list we restricted the scope to ones that report of BSD68 results.'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'KSVD [[89](#bib.bib89)] [28.28dB]: Elad, M., & Aharon, M. (2006). Image denoising
    via sparse and redundant representations over learned dictionaries. IEEE Transactions
    on Image processing, 15(12), 3736-3745.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method decomposes the noisy image into fully overlapping patches, and denoises
    each by sparse approximation via OMP [[214](#bib.bib214)], while learning an over-complete
    dictionary. The denoised image is obtained by returning the cleaned patches to
    their original locations while averaging them over the overlaps and with a weighted
    version of the noisy image.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BM3D [[61](#bib.bib61)] [28.57dB]: Dabov, K., Foi, A., Katkovnik, V., & Egiazarian,
    K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering.
    IEEE Transactions on Image Processing, 16(8), 2080-2095.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm extracts all fully overlapping patches from the noisy image and
    gathers similar patches into 3D blocks. Denoising is performed by transforming
    these blocks, forcing sparsity, and then transforming the sparse outcome back
    to the image domain. The denoised image is obtained by returning the patches to
    their original locations while averaging over the overlaps. This process is ran
    twice, where the first round serves for an initial cleaning that improves the
    patch correspondences for the later round.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FoE [[237](#bib.bib237)] [27.77dB]: Roth, S., & Black, M. J. (2009). Fields
    of experts. International Journal of Computer Vision, 82(2), 205-229.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: FoE (appeared originally in 2005 [[236](#bib.bib236)]) builds a generic prior
    that mixes several regularizers (called ”experts”). The prior’s parameters are
    learned via a contrastive divergence penalty and MCMC sampling. The image denoising
    itself is obtained by an iterative algorithm that computes the MAP estimation.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LSSC [[181](#bib.bib181)] [28.70dB]: Mairal, J., Bach, F., Ponce, J., Sapiro,
    G., & Zisserman, A. (2009). Non-local sparse models for image restoration. CVPR
    (pp. 2272-2279).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm combines the sparse representations (as in KSVD) and non-local
    similarity (as in BM3D) concepts. It decomposes the noisy image into fully overlapping
    patches and groups similar patches together. These groups of patches are denoised
    by a joint sparse approximation that forces the same support over a learned dictionary.
    The denoised image is obtained by returning the patches to their original locations
    and averaging over the overlaps.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EPLL [[347](#bib.bib347)] [28.71]: Zoran, D., & Weiss, Y. (2011). From learning
    models of natural image patches to whole image restoration. ICCV (pp. 479-486).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: EPLL models the distribution of image patches as a Gaussian Mixture Model (GMM),
    and learns its parameters off-line with a dataset of clean images. Denoising with
    EPLL is a MAP estimation, posed as a minimization problem with a regularizer that
    consists of a sum of patch log-likelihoods. This task is solved by applying quadratic
    half-splitting and iterating over patch denoising and the whole image accumulation
    steps.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MPL [[33](#bib.bib33)] [28.96dB]: Burger, H. C., Schuler, C. J., & Harmeling,
    S. (2012, June). Image denoising: Can plain neural networks compete with BM3D?.
    CVPR (pp. 2392-2399).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the first effective deep-learning based method for image denoising.
    This method extracts all fully overlapped patches as in classical algorithms,
    and filters each patch by applying a multi-layer Perceptron (fully connected network).
    The reconstructed image is obtained by returning the patches to their locations
    and averaging over the overlapping regions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CSF [[252](#bib.bib252)] [28.74dB]: Schmidt, U., & Roth, S. (2014). Shrinkage
    fields for effective image restoration. CVPR (pp. 2774-2781).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm poses a MAP estimation problem using a product of cascaded shrinkage
    functions as a local prior. The parameters of these functions are learned from
    a dataset as in FoE. The algorithm solves the obtained optimization by half-quadratic
    splitting and iterating between local and global optimization steps.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'WNNM [[110](#bib.bib110)] [28.83dB]: Gu, S., Zhang, L., Zuo, W., & Feng, X.
    (2014). Weighted nuclear norm minimization with application to image denoising.
    CVPR (pp. 2862-2869).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method decomposes an incoming image into fully overlapping patches and
    groups similar patches arranging them as columns of a matrix. Denoising of the
    patches is performed by forcing the rank of the constructed matrices to be small
    by minimizing the matrix nuclear norm. The reconstructed image is obtained by
    returning the patches to their original locations while averaging the overlaps.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TNRD [[50](#bib.bib50)] [28.92dB]: Chen, Y., & Pock, T. (2016). Trainable nonlinear
    reaction diffusion: A flexible framework for fast and effective image restoration.
    IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6), 1256-1272.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method builds on the FoE method, by unfolding the minimization over its
    prior and this way defining a parametric trainable network. Once the architecture
    is defined, TNRD trains this neural network end-to-end in a supervised fashion
    using clean/noisy pairs of images. Denoising is a simple inference of the resulting
    machine.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DnCNN [[330](#bib.bib330)] [29.23dB]: Zhang, K., Zuo, W., Chen, Y., Meng, D.,
    & Zhang, L. (2017). Beyond a gaussian denoiser: Residual learning of deep cnn
    for image denoising. IEEE Transactions on Image Processing, 26(7), 3142-3155.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the first deep learning method that outperforms classical algorithms
    by a considerable gap. It filters images by applying a convolutional neural network.
    The network architecture is composed of convolutional layers followed by batch
    normalizations and ReLU. The network is trained end-to-end using a dataset consisting
    of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IRCNN [[331](#bib.bib331)] [29.15dB] Zhang, K., Zuo, W., Gu, S., & Zhang, L.
    (2017). Learning deep CNN denoiser prior for image restoration. CVPR (pp. 3929-3938).
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method is similar to DnCNN, but uses dilated convolutions within the architecture
    in order to enlarge the receptive field, thus creating an opportunity for a non-local
    processing. The network is trained end-to-end using a dataset consisting of noisy/clean
    image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NLRN [[167](#bib.bib167)] [29.41dB]: Liu, D., Wen, B., Fan, Y., Loy, C. C.,
    & Huang, T. S. (2018). Non-local recurrent network for image restoration. NeurIPS.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method incorporates the non-local similarity concept into a convolutional
    recurrent neural network in an explicit way. The denoising is done by recurrently
    applying convolutions and weighted averaging of similar regions (as in NLM [[32](#bib.bib32)])
    in the feature space. The network is trained end-to-end using a dataset consisting
    of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MVCNN [[168](#bib.bib168)] [29.41dB]: Liu, P., Zhang, H., Zhang, K., Lin, L.,
    & Zuo, W. (2018). Multi-level wavelet-CNN for image restoration. CVPR Workshop
    (pp. 773-782).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm incorporates the wavelet sparsity concept into the deep learning
    approach by combining the U-Net architecture with the multi-level wavelet transform.
    It replaces the downsampling and upsampling U-Net layers with the 2$D$ discrete
    wavelet transform and it’s inverse. The network is trained end-to-end using a
    dataset consisting of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'N3Net [[218](#bib.bib218)] [29.30dB]: Plötz, T., & Roth, S. (2018). Neural
    nearest neighbors networks. NeurIPS.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method combines the deep learning approach with the non-local self-similarity
    concept. This method introduces a differentiable continuous relaxation of the
    $k$-nearest neighbor (KNN) selection rule and uses it as a building block within
    the neural network. N3Net’s architecture interleaves convolutional blocks with
    KNN relaxation blocks. The convolutional blocks perform denoising, while the KNN
    parts augment the feature maps by breaking them into patches, applying patch matching,
    and finding $k$-nearest neighbors for each patch. The network is trained end-to-end
    using a dataset consisting of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FFDNet [[332](#bib.bib332)] [29.19dB]: Zhang, K., Zuo, W., & Zhang, L. (2018).
    FFDNet: Toward a fast and flexible solution for CNN-based image denoising. IEEE
    Transactions on Image Processing, 27(9), 4608-4622.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While the architecture of this deep learning method resembles DnCNN, it enlarges
    the receptive field by reshaping the incoming image into four downsampled sub-images
    that are simultaneously fed into the network. The network is trained end-to-end
    using a dataset consisting of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FOCNet [[133](#bib.bib133)] [29.38dB] Jia, X., Liu, S., Feng, X., & Zhang,
    L. (2019). Focnet: A fractional optimal control network for image denoising. CVPR
    (pp. 6054-6063).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm suggests a novel architecture to replace the one used by DnCNN,
    relying on an interpretation of residual neural networks as solvers of dynamical
    systems. While DnCNN refers to integer-order ordinary differential equation, FOCNet’s
    architecture poses a fractional optimal control (FOC) problem that translates
    into better connectivity. The algorithm for solving the equation is implemented
    using a feed-forward convolutional neural network whose parameters are learned
    using a dataset of images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RIDNet [[8](#bib.bib8)] [29.34dB]: Anwar, S., & Barnes, N. (2019). Real image
    denoising with feature attention. CVPR (pp. 3155-3164).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm introduces attention modules to a neural network whose architecture
    includes convolutional layers and skip connections. This attention is designed
    to capture feature dependencies and enhance the weight of important correspondences.
    The network is trained end-to-end using a dataset of clean/noisy image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GCDN [[292](#bib.bib292)] [29.35dB]: Valsesia, D., Fracastoro, G., & Magli,
    E. (2020). Deep graph-convolutional image denoising. IEEE Transactions on Image
    Processing, 29, 8226-8237.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method combines the deep-learning approach with graph modeling. The GCDN
    architecture includes convolutional and graph-convolutional layers. While regular
    convolutional layers catch local interrelations between pixels, the graph-convolution
    ones are designed to capture the non-local dependencies. Each graph-convolutional
    layer dynamically applies non-local aggregation (graph-convolution). The graph
    is constructed via a $k$-nearest neighbor whose vertices are feature vectors.
    Each vertex is connected to the $k$ most similar ones in terms of the $L_{2}$
    norm. The network is trained using a dataset of images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SwinIR [[165](#bib.bib165)] [29.50dB]: Liang, J., Cao, J., Sun, G., Zhang,
    K., Van Gool, L., & Timofte, R. (2021). Swinir: Image restoration using swin transformer.
    CVPR (pp. 1833-1844).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm incorporates non-locality into convolutional deep learning architecture
    using shifted window (Swin) transformer modules [[171](#bib.bib171)]. These modules
    are designed to compute local self-attention in shifted windows, this way exploitig
    non-local self-similarity. The SwinIR architecture is trained end-to-end using
    a dataset consisting of noisy/clean image pairs.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DRUNet [[329](#bib.bib329)] [29.48dB]: Zhang, K., Li, Y., Zuo, W., Zhang, L.,
    Van Gool, L., & Timofte, R. (2021). Plug-and-play image restoration with deep
    denoiser prior. IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This denoiser is a bias-free [[201](#bib.bib201)] neural network that combines
    ResNet [[117](#bib.bib117)] and U-Net [[234](#bib.bib234)]. Its architecture includes
    convolutions, downscaling and upscaling layers, and skip connections. The network
    is trained using a dataset of images.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix D Approximation of the *Score Function* by an MMSE Denoiser
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Section [7](#S7 "7 Discovery 1: Solving Inverse Problems via Image Denoisers
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    we brought the definition of the *score function*, $\nabla_{{\mathbf{x}}}\log
    p({\mathbf{x}})$, and its approximation via a denoiser. Here we bring the derivation
    of this result, following the work by Miyasawa [[200](#bib.bib200)], Stein [[265](#bib.bib265)],
    and Tweedie [[84](#bib.bib84)].'
  prefs: []
  type: TYPE_NORMAL
- en: Consider an ideal image ${\mathbf{x}}\in\mathbb{R}^{N}$ drawn from the Probability
    Density Function (PDF) $p({\mathbf{x}})$. Assume that ${\mathbf{y}}$ is a noisy
    version of it, ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$, where ${\mathbf{v}}\sim{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$. The PDF of ${\mathbf{y}}$ can be
    obtained by a marginalization,
  prefs: []
  type: TYPE_NORMAL
- en: '| (41) |  | $\displaystyle p({\mathbf{y}})=\int_{{\mathbf{x}}}p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}=\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'In the above we used the fact that $p({\mathbf{y}}|{\mathbf{x}})\sim{\cal N}({\mathbf{x}},\sigma_{0}^{2}{\mathbf{I}})$.
    The obtained relationship expresses $p({\mathbf{y}})$ as a convolution between
    the original prior $p({\mathbf{x}})$ and an isotropic zero-mean Gaussian of width
    $\sigma_{0}$. Taking a derivative of both sides with respect to ${\mathbf{y}}$
    results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\nabla_{{\mathbf{y}}}p({\mathbf{y}})$ | $\displaystyle=$
    | $\displaystyle\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}\nabla_{{\mathbf{y}}}\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\cdot\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}({\mathbf{y}}-{\mathbf{x}})\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{y}}-{\mathbf{x}})p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: Dividing both sides by $p({\mathbf{y}})$ leads to
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\frac{\nabla_{{\mathbf{y}}}p({\mathbf{y}})}{p({\mathbf{y}})}=\nabla_{{\mathbf{y}}}\log
    p({\mathbf{y}})$ | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{x}}-{\mathbf{y}})\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{p({\mathbf{y}})}d{\mathbf{x}}$
    |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{x}}-{\mathbf{y}})p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  prefs: []
  type: TYPE_TB
- en: 'Opening and rearranging the above expression leads to our final result:'
  prefs: []
  type: TYPE_NORMAL
- en: '| (44) |  | $\nabla_{{\mathbf{y}}}\log p({\mathbf{y}})=\frac{1}{\sigma_{0}^{2}}\left[\int_{{\mathbf{x}}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}-{\mathbf{y}}\int_{{\mathbf{x}}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}\right]=\frac{1}{\sigma_{0}^{2}}\left[D(\mathbf{y},\sigma_{0})-\mathbf{y}\right],$
    |  |'
  prefs: []
  type: TYPE_TB
- en: where $D(\mathbf{y},\sigma_{0})$ should be the optimal Minimum Mean Squared
    Error (MMSE) denoiser, $\mathbb{E}(\mathbf{x}|\mathbf{y})$. Thus, access to an
    approximation of the score function $\nabla_{{\mathbf{x}}}\log p({\mathbf{x}})$
    can be obtained by using a small value $\sigma_{0}$, and evaluating the above
    expression with a given denoiser.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] A. Abdelhamed, S. Lin, and M. S. Brown, A high-quality denoising dataset
    for smartphone cameras, in Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, 2018, pp. 1692–1700.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] A. Abdelhamed, R. Timofte, and M. S. Brown, Ntire 2019 challenge on real
    image denoising: Methods and results, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] H. K. Aggarwal and A. Majumdar, Hyperspectral image denoising using spatio-spectral
    total variation, IEEE Geoscience and Remote Sensing Letters, 13 (2016), pp. 442–446.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] M. Aharon, M. Elad, and A. Bruckstein, K-SVD: An algorithm for designing
    overcomplete dictionaries for sparse representation, IEEE Transactions on signal
    processing, 54 (2006), pp. 4311–4322.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] R. Ahmad, C. A. Bouman, G. T. Buzzard, S. Chan, S. Liu, E. T. Reehorst,
    and P. Schniter, Plug-and-play methods for magnetic resonance imaging: Using denoisers
    for image recovery, IEEE Signal Processing Magazine, 37 (2020), pp. 105–116.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] T. Amit, E. Nachmani, T. Shaharbany, and L. Wolf, Segdiff: Image segmentation
    with diffusion probabilistic models, arXiv preprint arXiv:2112.00390, (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] F. J. Anscombe, The transformation of poisson, binomial and negative-binomial
    data, Biometrika, 35 (1948), pp. 246–254.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] S. Anwar and N. Barnes, Real image denoising with feature attention, in
    Proceedings of the IEEE/CVF international conference on computer vision, 2019,
    pp. 3155–3164.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] P. Arias and J.-M. Morel, Video denoising via empirical bayesian estimation
    of space-time patches, Journal of Mathematical Imaging and Vision, 60 (2018),
    pp. 70–93.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] P. Arias and J.-M. Morel, Kalman filtering of patches for frame-recursive
    video denoising, in Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition Workshops, 2019, pp. 0–0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] M. Arjovsky, S. Chintala, and L. Bottou, Wasserstein generative adversarial
    networks, in Proceedings of the 34th International Conference on Machine Learning,
    vol. 70 of Proceedings of Machine Learning Research, PMLR, 06–11 Aug 2017, pp. 214–223.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] L. Azzari and A. Foi, Variance stabilization for noisy+ estimate combination
    in iterative poisson denoising, IEEE signal processing letters, 23 (2016), pp. 1086–1090.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] U. Bal, Dual tree complex wavelet transform based denoising of optical
    microscopy images, Biomedical optics express, 3 (2012), pp. 3231–3239.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Y. Balaji, S. Nah, X. Huang, A. Vahdat, J. Song, K. Kreis, M. Aittala,
    T. Aila, S. Laine, B. Catanzaro, et al., eDiff-I: Text-to-image diffusion models
    with an ensemble of expert denoisers, arXiv preprint arXiv:2211.01324, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] M. R. Banham and A. K. Katsaggelos, Digital image restoration, IEEE signal
    processing magazine, 14 (1997), pp. 24–41.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Batson and L. Royer, Noise2self: Blind denoising by self-supervision,
    in International Conference on Machine Learning, PMLR, 2019, pp. 524–533.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] A. Beck and M. Teboulle, Fast gradient-based algorithms for constrained
    total variation image denoising and deblurring problems, IEEE Transactions on
    image processing, 18 (2009), pp. 2419–2434.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M. Bertalmío, Denoising of photographic images and video: fundamentals,
    open challenges and new trends, Springer, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] J. Besag, Markov chain monte carlo for statistical inference, Center for
    Statistics and the Social Sciences, 9 (2001), pp. 24–25.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] M. J. Black, G. Sapiro, D. H. Marimont, and D. Heeger, Robust anisotropic
    diffusion, IEEE Transactions on image processing, 7 (1998), pp. 421–432.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] T. Blau, R. Ganz, B. Kawar, A. Bronstein, and M. Elad, Threat model-agnostic
    adversarial defense using diffusion models, arXiv preprint arXiv:2207.08089, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Y. Blau and T. Michaeli, The perception-distortion tradeoff, in Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 6228–6237.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] A. Bosco, R. Bruna, D. Giacalone, S. Battiato, and R. Rizzo, Signal-dependent
    raw image denoising using sensor noise characterization via multiple acquisitions,
    in Digital Photography VI, vol. 7537, SPIE, 2010, pp. 34–43.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] L. Bottou et al., Stochastic gradient learning in neural networks, Proceedings
    of Neuro-Nımes, 91 (1991), p. 12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J. Boulanger, C. Kervrann, P. Bouthemy, P. Elbau, J.-B. Sibarita, and
    J. Salamero, Patch-based nonlocal functional for denoising fluorescence microscopy
    image sequences, IEEE transactions on medical imaging, 29 (2009), pp. 442–454.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] C. Bouman and K. Sauer, A generalized gaussian image model for edge-preserving
    map estimation, IEEE Transactions on image processing, 2 (1993), pp. 296–310.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, et al., Distributed
    optimization and statistical learning via the alternating direction method of
    multipliers, Foundations and Trends® in Machine learning, 3 (2011), pp. 1–122.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] A. Brifman, Y. Romano, and M. Elad, Turning a denoiser into a super-resolver
    using plug and play priors, in 2016 IEEE International Conference on Image Processing
    (ICIP), IEEE, 2016, pp. 1404–1408.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] A. Brock, J. Donahue, and K. Simonyan, Large scale GAN training for high
    fidelity natural image synthesis, in International Conference on Learning Representations,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] T. Brooks, B. Mildenhall, T. Xue, J. Chen, D. Sharlet, and J. T. Barron,
    Unprocessing images for learned raw denoising, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2019, pp. 11036–11045.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] A. M. Bruckstein, D. L. Donoho, and M. Elad, From sparse solutions of
    systems of equations to sparse modeling of signals and images, SIAM review, 51
    (2009), pp. 34–81.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] A. Buades, B. Coll, and J.-M. Morel, A non-local algorithm for image denoising,
    in IEEE CVPR, vol. 2, 2005, pp. 60–65.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] H. C. Burger, C. J. Schuler, and S. Harmeling, Image denoising: Can plain
    neural networks compete with BM3D?, in IEEE CVPR, 2012, pp. 2392–2399.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] G. T. Buzzard, S. H. Chan, S. Sreehari, and C. A. Bouman, Plug-and-play
    unplugged: Optimization-free reconstruction using consensus equilibrium, SIAM
    Journal on Imaging Sciences, 11 (2018), pp. 2001–2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] E. J. Candès, X. Li, Y. Ma, and J. Wright, Robust principal component
    analysis?, Journal of the ACM (JACM), 58 (2011), pp. 1–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] H. Cao, C. Tan, Z. Gao, G. Chen, P.-A. Heng, and S. Z. Li, A survey on
    generative diffusion model, arXiv preprint arXiv:2209.02646, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] K. R. Castleman, Digital image processing, Prentice Hall Press, 1996.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] F. Catté, P.-L. Lions, J.-M. Morel, and T. Coll, Image selective smoothing
    and edge detection by nonlinear diffusion, SIAM Journal on Numerical analysis,
    29 (1992), pp. 182–193.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] A. Chambolle and T. Pock, A first-order primal-dual algorithm for convex
    problems with applications to imaging, Journal of mathematical imaging and vision,
    40 (2011), pp. 120–145.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] R. H. Chan, C.-W. Ho, and M. Nikolova, Salt-and-pepper noise removal by
    median-type noise detectors and detail-preserving regularization, IEEE Transactions
    on image processing, 14 (2005), pp. 1479–1485.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S. H. Chan, Performance analysis of plug-and-play admm: A graph signal
    processing perspective, IEEE Transactions on Computational Imaging, 5 (2019),
    pp. 274–286.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] S. H. Chan, X. Wang, and O. A. Elgendy, Plug-and-play ADMM for image restoration:
    Fixed-point convergence and applications, IEEE Transactions on Computational Imaging,
    3 (2016), pp. 84–98.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] S. G. Chang, B. Yu, and M. Vetterli, Adaptive wavelet thresholding for
    image denoising and compression, IEEE transactions on image processing, 9 (2000),
    pp. 1532–1546.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] P. Charbonnier, L. Blanc-Féraud, G. Aubert, and M. Barlaud, Deterministic
    edge-preserving regularization in computed imaging, IEEE Transactions on image
    processing, 6 (1997), pp. 298–311.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] P. Chatterjee and P. Milanfar, Is denoising dead?, IEEE Transactions on
    Image Processing, 19 (2009), pp. 895–911.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] P. Chatterjee and P. Milanfar, Patch-based near-optimal image denoising,
    IEEE Transactions on Image Processing, 21 (2011), pp. 1635–1649.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] C. Chen, Z. Xiong, X. Tian, and F. Wu, Deep boosting for image denoising,
    in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 3–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] H. Chen, Y. Zhang, W. Zhang, P. Liao, K. Li, J. Zhou, and G. Wang, Low-dose
    ct denoising with convolutional neural network, in 2017 IEEE 14th International
    Symposium on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 143–146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] W. Chen, D. Wipf, and M. Rodrigues, Deep learning for linear inverse problems
    using the plug-and-play priors framework, in ICASSP 2021-2021 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2021, pp. 8098–8102.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Y. Chen and T. Pock, Trainable nonlinear reaction diffusion: A flexible
    framework for fast and effective image restoration, IEEE transactions on pattern
    analysis and machine intelligence, 39 (2016), pp. 1256–1272.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] B. T. Christian, N. T. Vandehey, J. M. Floberg, and C. A. Mistretta, Dynamic
    pet denoising with hypr processing, Journal of Nuclear Medicine, 51 (2010), pp. 1147–1154.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] C. Chu, I. Glad, F. Godtliebsen, and J. Marron, Edge-preserving smoothers
    for image processing, Journal of the American Statistical Association, 93 (1998),
    pp. 526–541.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] H. Chung, J. Kim, M. T. Mccann, M. L. Klasky, and J. C. Ye, Diffusion
    posterior sampling for general noisy inverse problems, arXiv preprint arXiv:2209.14687,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] H. Chung, B. Sim, D. Ryu, and J. C. Ye, Improving diffusion models for
    inverse problems using manifold constraints, arXiv preprint arXiv:2206.00941,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] R. Cohen, Y. Blau, D. Freedman, and E. Rivlin, It has potential: Gradient-driven
    denoisers for convergent solutions to inverse problems, Advances in Neural Information
    Processing Systems, 34 (2021), pp. 18152–18164.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] R. Cohen, M. Elad, and P. Milanfar, Regularization by denoising via fixed-point
    projection (RED-PRO), SIAM Journal on Imaging Sciences, 14 (2021), pp. 1374–1406.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] R. R. Coifman and D. L. Donoho, Translation-invariant de-noising, in Wavelets
    and statistics, Springer, 1995, pp. 125–150.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M.-C. Corbineau, C. Bertocchi, E. Chouzenoux, M. Prato, and J.-C. Pesquet,
    Learned image deblurring by unfolding a proximal interior point algorithm, in
    2019 IEEE International Conference on Image Processing (ICIP), IEEE, 2019, pp. 4664–4668.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] R. Costantini and S. Susstrunk, Virtual sensor design, in Sensors and
    Camera Systems for Scientific, Industrial, and Digital Photography Applications
    V, vol. 5301, SPIE, 2004, pp. 408–419.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] F.-A. Croitoru, V. Hondru, R. T. Ionescu, and M. Shah, Diffusion models
    in vision: A survey, arXiv preprint arXiv:2209.04747, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, Image denoising by
    sparse 3-D transform-domain collaborative filtering, IEEE Transactions on image
    processing, 16 (2007), pp. 2080–2095.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Dai, O. C. Au, C. Pang, W. Yang, and F. Zou, Film grain noise removal
    and synthesis in video coding, in 2010 IEEE International Conference on Acoustics,
    Speech and Signal Processing, IEEE, 2010, pp. 890–893.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Y. Dar, A. M. Bruckstein, M. Elad, and R. Giryes, Postprocessing of compressed
    images via sequential denoising, IEEE Transactions on Image Processing, 25 (2016),
    pp. 3044–3058.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] P. Das, C. Pal, A. Chakrabarti, A. Acharyya, and S. Basu, Adaptive denoising
    of 3d volumetric mr images using local variance based estimator, Biomedical Signal
    Processing and Control, 59 (2020), p. 101901.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] C.-A. Deledalle, F. Tupin, and L. Denis, Poisson nl means: Unsupervised
    non local means for poisson noise, in 2010 IEEE international conference on image
    processing, IEEE, 2010, pp. 801–804.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ImageNet:
    A large-scale hierarchical image database, in 2009 IEEE Conference on Computer
    Vision and Pattern Recognition, 2009, pp. 248–255.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] R. Dey, D. Bhattacharjee, and M. Nasipuri, Image denoising using generative
    adversarial network, in Intelligent Computing: Image Processing Based Applications,
    Springer, 2020, pp. 73–90.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] P. Dhariwal and A. Q. Nichol, Diffusion models beat GANs on image synthesis,
    in Thirty-Fifth Conference on Neural Information Processing Systems, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] N. Divakar and R. Venkatesh Babu, Image denoising via CNNs: An adversarial
    approach, in Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition Workshops, 2017, pp. 80–87.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] M. Diwakar, P. Kumar, and A. K. Singh, Ct image denoising using nlm and
    its method noise thresholding, Multimedia Tools and Applications, 79 (2020), pp. 14449–14464.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] W. Dong, X. Li, L. Zhang, and G. Shi, Sparsity-based image denoising via
    dictionary learning and structural clustering, in CVPR 2011, 2011, pp. 457–464.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] W. Dong, G. Shi, Y. Ma, and X. Li, Image restoration via simultaneous
    sparse coding: Where structured sparsity meets Gaussian scale mixture, International
    Journal of Computer Vision, 114 (2015), pp. 217–232.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] W. Dong, P. Wang, W. Yin, G. Shi, F. Wu, and X. Lu, Denoising prior driven
    deep neural network for image restoration, IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 41 (2018), pp. 2305–2318.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] W. Dong, L. Zhang, G. Shi, and X. Li, Nonlocally centralized sparse representation
    for image restoration, IEEE Transactions on Image Processing, 22 (2012), pp. 1620–1630.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Y. Dong and S. Xu, A new directional weighted median filter for removal
    of random-valued impulse noise, IEEE Signal Processing Letters, 14 (2007), pp. 193–196.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] D. L. Donoho, De-noising by soft-thresholding, IEEE transactions on information
    theory, 41 (1995), pp. 613–627.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] D. L. Donoho and J. M. Johnstone, Ideal spatial adaptation by wavelet
    shrinkage, biometrika, 81 (1994), pp. 425–455.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner,
    M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al., An image is worth 16x16
    words: Transformers for image recognition at scale, in International Conference
    on Learning Representations, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Y. Du and I. Mordatch, Implicit generation and modeling with energy based
    models, in Advances in Neural Information Processing Systems, vol. 32, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] A. Dudhane, S. W. Zamir, S. Khan, F. S. Khan, and M.-H. Yang, Burst image
    restoration and enhancement, in Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, 2022, pp. 5759–5768.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] F.-X. Dupé, J. M. Fadili, and J.-L. Starck, A proximal iteration for deconvolving
    poisson noisy images using sparse representations, IEEE Transactions on Image
    Processing, 18 (2009), pp. 310–321.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] J. Dutta, R. M. Leahy, and Q. Li, Non-local means denoising of dynamic
    pet images, PloS one, 8 (2013), p. e81390.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] S. Dutta, A. Basarab, B. Georgeot, and D. Kouamé, Deep unfolding of image
    denoising by quantum interactive patches, in 2022 IEEE International Conference
    on Image Processing (ICIP), IEEE, 2022, pp. 491–495.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] B. Efron, Tweedie’s formula and selection bias, Journal of the American
    Statistical Association, 106 (2011), pp. 1602–1614.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] K. Egiazarian and V. Katkovnik, Single image super-resolution via BM3D
    sparse coding, in IEEE European Signal Processing Conference (EUSIPCO), 2015,
    pp. 2849–2853.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] T. Ehret, A. Davy, P. Arias, and G. Facciolo, Joint demosaicking and denoising
    by fine-tuning of bursts of raw images, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2019, pp. 8868–8877.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] M. Elad, On the origin of the bilateral filter and ways to improve it,
    IEEE Transactions on image processing, 11 (2002), pp. 1141–1151.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] M. Elad, Sparse and redundant representations: from theory to applications
    in signal and image processing, vol. 2, Springer, 2010.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] M. Elad and M. Aharon, Image denoising via sparse and redundant representations
    over learned dictionaries, IEEE Transactions on Image processing, 15 (2006), pp. 3736–3745.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] M. Elad, J.-L. Starck, P. Querre, and D. L. Donoho, Simultaneous cartoon
    and texture image inpainting using morphological component analysis (mca), Applied
    and Computational Harmonic Analysis, 19 (2005), pp. 340–358.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] M. J. Fadili, J.-L. Starck, J. Bobin, and Y. Moudden, Image decomposition
    and separation using sparse representations: an overview, Proceedings of the IEEE,
    98 (2009), pp. 983–994.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] L. Fan, F. Zhang, H. Fan, and C. Zhang, Brief review of image denoising
    techniques, Visual Computing for Industry, Biomedicine, and Art, 2 (2019), pp. 1–12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] M. A. Figueiredo and J. M. Bioucas-Dias, Restoration of poissonian images
    using alternating direction optimization, IEEE transactions on Image Processing,
    19 (2010), pp. 3133–3145.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] A. K. Fletcher, P. Pandit, S. Rangan, S. Sarkar, and P. Schniter, Plug-in
    estimation in high-dimensional linear inverse problems: A rigorous analysis, in
    Advances in Neural Information Processing Systems, 2018, pp. 7440–7449.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] R. Gal, Y. Alaluf, Y. Atzmon, O. Patashnik, A. H. Bermano, G. Chechik,
    and D. Cohen-Or, An image is worth one word: Personalizing text-to-image generation
    using textual inversion, arXiv preprint arXiv:2208.01618, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] D. Geman and G. Reynolds, Constrained restoration and the recovery of
    discontinuities, IEEE Transactions on pattern analysis and machine intelligence,
    14 (1992), pp. 367–383.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] S. Geman, Stochastic relaxation, gibbs distributions and bayesian restoration
    of images. ieee trans, Pattn. Anal. Mach. Intell., 6 (1984), pp. 721–741.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] S. Ghael, A. M. Sayeed, and R. G. Baraniuk, Improved wavelet denoising
    via empirical wiener filtering, in SPIE Technical Conference on Wavelet Applications
    in Signal Processing, 1997.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] G. Gilboa and S. Osher, Nonlocal operators with applications to image
    processing, Multiscale Modeling & Simulation, 7 (2009), pp. 1005–1028.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] R. Giryes and M. Elad, Sparsity-based poisson denoising with dictionary
    learning, IEEE Transactions on Image Processing, 23 (2014), pp. 5057–5069.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] X. Glorot, A. Bordes, and Y. Bengio, Deep sparse rectifier neural networks,
    in Proceedings of the fourteenth international conference on artificial intelligence
    and statistics, JMLR Workshop and Conference Proceedings, 2011, pp. 315–323.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] C. Godard, K. Matzen, and M. Uyttendaele, Deep burst denoising, in Proceedings
    of the European conference on computer vision (ECCV), 2018, pp. 538–554.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Y. E. Gökdağ, F. Şansal, and Y. D. Gökdel, Image denoising using 2-d
    wavelet algorithm for gaussian-corrupted confocal microscopy images, Biomedical
    Signal Processing and Control, 54 (2019), p. 101594.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] G. H. Golub, P. C. Hansen, and D. P. O’Leary, Tikhonov regularization
    and total least squares, SIAM Journal on Matrix Analysis and Applications, 21
    (1999), pp. 185–194.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] K. Gong, J. Guan, C.-C. Liu, and J. Qi, Pet image denoising using a deep
    neural network through fine tuning, IEEE Transactions on Radiation and Plasma
    Medical Sciences, 3 (2018), pp. 153–161.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] M. Gonzalez, J. Preciozzi, P. Musé, and A. Almansa, Joint denoising and
    decompression using cnn regularization, in Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition Workshops, 2018, pp. 2598–2601.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, Generative adversarial nets, Advances in Neural Information
    Processing Systems, 27 (2014).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] B. Goossens, A. Pizurica, and W. Philips, Removal of correlated noise
    by modeling the signal of interest in the wavelet domain, IEEE transactions on
    image processing, 18 (2009), pp. 1153–1165.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] K. Gregor and Y. LeCun, Learning fast approximations of sparse coding,
    in Proceedings of the 27th international conference on international conference
    on machine learning, 2010, pp. 399–406.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] S. Gu, L. Zhang, W. Zuo, and X. Feng, Weighted nuclear norm minimization
    with application to image denoising, in Proceedings of the IEEE conference on
    computer vision and pattern recognition, 2014, pp. 2862–2869.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] F. Guichard, L. Moisan, and J. M. Morel, A review of pde models in image
    processing and image analysis, In Journal de Physique IV, 12 (2002), pp. 137–154.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville,
    Improved training of Wasserstein GANs, Advances in neural information processing
    systems, 30 (2017).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] S. Guo, Z. Liang, and L. Zhang, Joint denoising and demosaicking with
    green channel prior for real-world burst images, IEEE Transactions on Image Processing,
    30 (2021), pp. 6930–6942.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] S. Guo, Z. Yan, K. Zhang, W. Zuo, and L. Zhang, Toward convolutional
    blind denoising of real photographs, in Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition, 2019, pp. 1712–1722.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] J. Gurrola-Ramos, O. Dalmau, and T. E. Alarcón, A residual dense u-net
    neural network for image denoising, IEEE Access, 9 (2021), pp. 31742–31754.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] X. Han, H. Zheng, and M. Zhou, CARD: Classification and regression diffusion
    models, arXiv preprint arXiv:2206.07275, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual learning for image
    recognition, in Proceedings of the IEEE conference on computer vision and pattern
    recognition, 2016, pp. 770–778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] G. E. Hinton, Training products of experts by minimizing contrastive
    divergence, Neural computation, 14 (2002), pp. 1771–1800.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko, D. P. Kingma,
    B. Poole, M. Norouzi, D. J. Fleet, et al., Imagen video: High definition video
    generation with diffusion models, arXiv preprint arXiv:2210.02303, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] J. Ho, A. Jain, and P. Abbeel, Denoising diffusion probabilistic models,
    in Advances in Neural Information Processing Systems, vol. 33, Curran Associates,
    Inc., 2020, pp. 6840–6851.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans,
    Cascaded diffusion models for high fidelity image generation, Journal of Machine
    Learning Research, 23 (2022), pp. 1–33.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] J. Ho and T. Salimans, Classifier-free diffusion guidance, in NeurIPS
    2021 Workshop on Deep Generative Models and Downstream Applications, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] T. Hong, Y. Romano, and M. Elad, Acceleration of RED via vector extrapolation,
    Journal of Visual Communication and Image Representation, 63 (2019), p. 102575.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] X. Hu, R. Ma, Z. Liu, Y. Cai, X. Zhao, Y. Zhang, and H. Wang, Pseudo
    3d auto-correlation network for real image denoising, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2021, pp. 16175–16184.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Y. Huang, S. Li, L. Wang, T. Tan, et al., Unfolding the alternating optimization
    for blind super resolution, Advances in Neural Information Processing Systems,
    33 (2020), pp. 5632–5643.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] P. Huber, Robust statistics. new-york: John wiley and sons, HuberRobust
    statistics1981, (1981).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] I. A. Ibragimov, I. V. Linnik, and J. F. C. Kingman, Independent and
    stationary sequences of random variables, Monographs and textbooks on pure and
    applied mathematics, Wolters-Noordhoff., 1971.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] A. Ignatov, K. Byeoung-Su, R. Timofte, and A. Pouget, Fast camera image
    denoising on mobile gpus with deep learning, mobile ai 2021 challenge: Report,
    in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2021, pp. 2515–2524.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] A. Jain, A. Xie, and P. Abbeel, Vectorfusion: Text-to-svg by abstracting
    pixel-based diffusion models, arXiv preprint arXiv:2211.11319, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] P. Jain and V. Tyagi, A survey of edge-preserving image denoising methods,
    Information Systems Frontiers, 18 (2016), pp. 159–170.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] V. Jain and S. Seung, Natural image denoising with convolutional networks,
    Advances in neural information processing systems, 21 (2008).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] E. T. Jaynes, Probability theory: The logic of science, Cambridge university
    press, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] X. Jia, S. Liu, X. Feng, and L. Zhang, Focnet: A fractional optimal control
    network for image denoising, 2019 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition (CVPR), (2019), pp. 6047–6056.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] K. H. Jin and J. C. Ye, Annihilating filter-based low-rank hankel matrix
    approach for image inpainting, IEEE Transactions on Image Processing, 24 (2015),
    pp. 3498–3511.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] A. Jolicoeur-Martineau, K. Li, R. Piché-Taillefer, T. Kachman, and I. Mitliagkas,
    Gotta go fast when generating data with score-based models, arXiv preprint arXiv:2105.14080,
    (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] I. T. Jolliffe and J. Cadima, Principal component analysis: a review
    and recent developments, Philosophical Transactions of the Royal Society A: Mathematical,
    Physical and Engineering Sciences, 374 (2016), p. 20150202.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] J. Joyce and E. N. Zalta, Bayes’ theorem, The Stanford Encyclopedia of
    Philosophy, 28 (2003).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] Z. Kadkhodaie and E. Simoncelli, Stochastic solutions for linear inverse
    problems using the prior implicit in a denoiser, Advances in Neural Information
    Processing Systems, 34 (2021), pp. 13242–13254.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] U. S. Kamilov, H. Mansour, and B. Wohlberg, A plug-and-play priors approach
    for solving nonlinear imaging inverse problems, IEEE Signal Processing Letters,
    24 (2017), pp. 1872–1876.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] K. Karhunen, Über lineare methoden in der wahrscheinlichkeitsrechnung,
    Ann. Acad. Sci. Fennicea, A137 (1947).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila,
    Analyzing and improving the image quality of stylegan, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2020, pp. 8110–8119.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] B. Kawar, M. Elad, S. Ermon, and J. Song, Denoising diffusion restoration
    models, in Advances in Neural Information Processing Systems, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] B. Kawar, R. Ganz, and M. Elad, Enhancing diffusion-based image synthesis
    with robust classifier guidance, arXiv preprint arXiv:2208.08664, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] B. Kawar, J. Song, S. Ermon, and M. Elad, JPEG artifact correction using
    denoising diffusion restoration models, in Neural Information Processing Systems
    (NeurIPS) Workshop on Score-Based Methods, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] B. Kawar, G. Vaksman, and M. Elad, SNIPS: solving noisy inverse problems
    stochastically, Advances in Neural Information Processing Systems, 34 (2021),
    pp. 21757–21769.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] B. Kawar, G. Vaksman, and M. Elad, Stochastic image denoising by sampling
    from the posterior distribution, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops, 2021, pp. 1866–1875.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] B. Kawar, S. Zada, O. Lang, O. Tov, H. Chang, T. Dekel, I. Mosseri, and
    M. Irani, Imagic: Text-based real image editing with diffusion models, arXiv preprint
    arXiv:2210.09276, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] S. A. Khowaja, B. N. Yahya, and S.-L. Lee, Cascaded and recursive convnets
    (crcnn): An effective and flexible approach for image denoising, Signal Processing:
    Image Communication, 99 (2021), p. 116420.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] S.-U. Kim, An image denoising algorithm for the mobile phone cameras,
    The Journal of the Korea institute of electronic communication sciences, 9 (2014),
    pp. 601–608.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] D. P. Kingma and P. Dhariwal, Glow: Generative flow with invertible 1x1
    convolutions, Advances in neural information processing systems, 31 (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] D. P. Kingma and M. Welling, Auto-encoding variational bayes, in International
    Conference on Learning Representations, 2014.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] A. Krull, T.-O. Buchholz, and F. Jug, Noise2void-learning denoising from
    single noisy images, in Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition, 2019, pp. 2129–2137.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] G. Kutyniok and W.-Q. Lim, Image separation using wavelets and shearlets,
    in International Conference on Curves and Surfaces, Springer, 2010, pp. 416–430.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] R. L. Lagendijk and J. Biemond, Basic methods for image restoration and
    identification, in The Essential Guide to Image Processing, Elsevier, 2009, pp. 323–348.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] R. Laumont, V. De Bortoli, A. Almansa, J. Delon, A. Durmus, and M. Pereyra,
    Bayesian imaging using plug & play priors: when Langevin meets Tweedie, arXiv
    preprint arXiv:2103.04715, (2021).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] M. Lebrun, M. Colom, A. Buades, and J.-M. Morel, Secrets of image denoising
    cuisine, Acta Numerica, 21 (2012), pp. 475–576.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] M. Lebrun, M. Colom, and J.-M. Morel, The noise clinic: A universal blind
    denoising algorithm, in 2014 IEEE International Conference on Image Processing
    (ICIP), IEEE, 2014, pp. 2674–2678.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] S. Lee, M. Negishi, H. Urakubo, H. Kasai, and S. Ishii, Mu-net: Multi-scale
    u-net for two-photon microscopy image denoising and restoration, Neural Networks,
    125 (2020), pp. 92–103.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] S. Lefkimmiatis, Universal denoising networks: a novel cnn architecture
    for image denoising, in Proceedings of the IEEE conference on computer vision
    and pattern recognition, 2018, pp. 3204–3213.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala,
    and T. Aila, Noise2noise: Learning image restoration without clean data, in International
    Conference on Machine Learning, PMLR, 2018, pp. 2965–2974.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] C. Lei, Y. Xing, and Q. Chen, Blind video temporal consistency via deep
    video prior, ArXiv, abs/2010.11838 (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] A. Levin and B. Nadler, Natural image denoising: Optimality and inherent
    bounds, in IEEE CVPR, 2011, pp. 2833–2840.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] A. Levin, B. Nadler, F. Durand, and W. T. Freeman, Patch complexity,
    finite pixel correlations and optimal denoising, in European Conference on Computer
    Vision, Springer, 2012, pp. 73–86.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] Z. Li, L. Yu, J. D. Trzasko, D. S. Lake, D. J. Blezek, J. G. Fletcher,
    C. H. McCollough, and A. Manduca, Adaptive nonlocal means filtering based on local
    noise level for ct denoising, Medical physics, 41 (2014), p. 011908.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] J. Liang, J. Cao, G. Sun, K. Zhang, L. Van Gool, and R. Timofte, SwinIR:
    Image restoration using swin transformer, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2021, pp. 1833–1844.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Z. Liang, S. Guo, H. Gu, H. Zhang, and L. Zhang, A decoupled learning
    scheme for real-world burst denoising from raw images, in European Conference
    on Computer Vision, Springer, 2020, pp. 150–166.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] D. Liu, B. Wen, Y. Fan, C. C. Loy, and T. S. Huang, Non-local recurrent
    network for image restoration, in Advances in Neural Information Processing Systems,
    2018, pp. 1673–1682.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] P. Liu, H. Zhang, K. Zhang, L. Lin, and W. Zuo, Multi-level wavelet-cnn
    for image restoration, 2018 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition Workshops (CVPRW), (2018), pp. 886–88609.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] X. Liu, M. Tanaka, and M. Okutomi, Single-image noise level estimation
    for blind denoising, IEEE transactions on image processing, 22 (2013), pp. 5226–5237.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] Y. Liu, Z. Qin, S. Anwar, P. Ji, D. Kim, S. Caldwell, and T. Gedeon,
    Invertible denoising network: A light solution for real noise removal, in Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 13365–13374.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo,
    Swin transformer: Hierarchical vision transformer using shifted windows, 2021
    IEEE/CVF International Conference on Computer Vision (ICCV), (2021), pp. 9992–10002.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] Z. Liu, P. Luo, X. Wang, and X. Tang, Deep learning face attributes in
    the wild, in Proceedings of the IEEE International Conference on Computer Vision,
    2015, pp. 3730–3738.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] Z. Liu, L. Yuan, X. Tang, M. Uyttendaele, and J. Sun, Fast burst images
    denoising, ACM Transactions on Graphics (TOG), 33 (2014), pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] M. Loéve, Fonctions aléatoires de second order, CR. Acad. Sci. Paris,
    220 (1945).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] F. Luisier, T. Blu, and M. Unser, A new sure approach to image denoising:
    Interscale orthonormal wavelet thresholding, IEEE Transactions on image processing,
    16 (2007), pp. 593–606.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] F. Luisier, T. Blu, and M. Unser, Image denoising in mixed poisson–gaussian
    noise, IEEE Transactions on image processing, 20 (2010), pp. 696–708.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] F. Luisier, C. Vonesch, T. Blu, and M. Unser, Fast interscale wavelet
    denoising of poisson-corrupted images, Signal processing, 90 (2010), pp. 415–427.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] S. Luo and W. Hu, Score-based point cloud denoising, in Proceedings of
    the IEEE/CVF International Conference on Computer Vision (ICCV), October 2021,
    pp. 4583–4592.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] M. Maggioni, G. Boracchi, A. Foi, and K. Egiazarian, Video denoising
    using separable 4d nonlocal spatiotemporal transforms, in Image Processing: Algorithms
    and Systems IX, vol. 7870, International Society for Optics and Photonics, 2011,
    p. 787003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] M. Maggioni, Y. Huang, C. Li, S. Xiao, Z. Fu, and F. Song, Efficient
    multi-stage video denoising with recurrent spatio-temporal fusion, 2021 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition (CVPR), (2021), pp. 3465–3474.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman, Non-local
    sparse models for image restoration, in IEEE 12th international conference on
    computer vision, 2009, pp. 2272–2279.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] J. Mairal, M. Elad, and G. Sapiro, Sparse representation for color image
    restoration, IEEE Transactions on Image Processing, 17 (2008), pp. 53–69.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] J. Mairal, G. Sapiro, and M. Elad, Multiscale sparse image representation
    with learned dictionaries, in 2007 IEEE International Conference on Image Processing,
    vol. 3, IEEE, 1997, pp. III–105.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] M. Makitalo and A. Foi, Optimal inversion of the anscombe transformation
    in low-count poisson image denoising, IEEE transactions on Image Processing, 20
    (2010), pp. 99–109.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] S. Mallat, A wavelet tour of signal processing, Elsevier, 1999.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] B. Manifold, E. Thomas, A. T. Francis, A. H. Hill, and D. Fu, Denoising
    of stimulated raman scattering microscopy images via deep learning, Biomedical
    optics express, 10 (2019), pp. 3860–3874.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] J. V. Manjón, P. Coupé, L. Martí-Bonmatí, D. L. Collins, and M. Robles,
    Adaptive non-local means denoising of mr images with spatially varying noise levels,
    Journal of Magnetic Resonance Imaging, 31 (2010), pp. 192–203.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] V. Mannam, Y. Zhang, Y. Zhu, E. Nichols, Q. Wang, V. Sundaresan, S. Zhang,
    C. Smith, P. W. Bohn, and S. S. Howard, Real-time image denoising of mixed poisson–gaussian
    noise in fluorescence microscopy images using imagej, Optica, 9 (2022), pp. 335–345.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] T. Marinč, V. Srinivasan, S. Gül, C. Hellge, and W. Samek, Multi-kernel
    prediction networks for denoising of burst images, in 2019 IEEE International
    Conference on Image Processing (ICIP), IEEE, 2019, pp. 2404–2408.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] D. R. Martin, C. C. Fowlkes, D. Tal, and J. Malik, A database of human
    segmented natural images and its application to evaluating segmentation algorithms
    and measuring ecological statistics, Proceedings Eighth IEEE International Conference
    on Computer Vision. ICCV 2001, 2 (2001), pp. 416–423 vol.2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] E. Martinec, Noise, dynamic range and bit depth in digital slrs, The
    University of Chicago, (2008).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] G. Mataev, P. Milanfar, and M. Elad, DeepRED: Deep image prior powered
    by RED, in Proceedings of the IEEE International Conference on Computer Vision
    Workshops, 2019, pp. 0–0.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] M. Matrecano, G. Poggi, and L. Verdoliva, Improved bm3d for correlated
    noise removal., in VISAPP (1), 2012, pp. 129–134.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] T. Meinhardt, M. Moller, C. Hazirbas, and D. Cremers, Learning proximal
    operators: Using denoising networks for regularizing inverse imaging problems,
    in Proceedings of the IEEE International Conference on Computer Vision, 2017,
    pp. 1781–1790.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] X. Meng and Y. Kabashima, Diffusion model based posterior sampling for
    noisy linear inverse problems, arXiv preprint arXiv:2211.12343, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] C. A. Metzler, A. Maleki, and R. G. Baraniuk, From denoising to compressed
    sensing, IEEE Transactions on Information Theory, 62 (2016), pp. 5117–5144.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] P. Milanfar, A tour of modern image filtering: New insights and methods,
    both practical and theoretical, IEEE signal processing magazine, 30 (2012), pp. 106–128.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] B. Mildenhall, J. T. Barron, J. Chen, D. Sharlet, R. Ng, and R. Carroll,
    Burst denoising with kernel prediction networks, in Proceedings of the IEEE conference
    on computer vision and pattern recognition, 2018, pp. 2502–2510.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] J. Miskin and D. J. MacKay, Ensemble learning for blind image separation
    and deconvolution, in Advances in independent component analysis, Springer, 2000,
    pp. 123–141.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] K. Miyasawa, An empirical Bayes estimator of the mean of a normal population,
    Bull. Inst. Internat. Statist., 38 (1961), pp. 181–188.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] S. Mohan, Z. Kadkhodaie, E. P. Simoncelli, and C. Fernandez-Granda, Robust
    and interpretable blind image denoising via bias-free convolutional neural networks,
    in International Conference on Learning Representations, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] R. Mokady, A. Hertz, K. Aberman, Y. Pritch, and D. Cohen-Or, Null-text
    inversion for editing real images using guided diffusion models, arXiv preprint
    arXiv:2211.09794, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] I. Mosseri, M. Zontak, and M. Irani, Combining the power of internal
    and external denoising, in IEEE international conference on computational photography
    (ICCP), IEEE, 2013, pp. 1–9.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] C. Mou, Q. Wang, and J. Zhang, Deep generalized unfolding networks for
    image restoration, in Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, 2022, pp. 17399–17410.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] K. P. Murphy, Machine learning: a probabilistic perspective, MIT press,
    2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] S. Neville and N. Dimopoulos, Wavelet denoising of coarsely quantized
    signals, IEEE Transactions on Instrumentation and Measurement, 55 (2006), pp. 892–901.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] H. V. Nguyen, M. O. Ulfarsson, and J. R. Sveinsson, Hyperspectral image
    denoising using sure-based unsupervised convolutional neural networks, IEEE Transactions
    on Geoscience and Remote Sensing, 59 (2020), pp. 3369–3382.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] A. Q. Nichol and P. Dhariwal, Improved denoising diffusion probabilistic
    models, in International Conference on Machine Learning, PMLR, 2021, pp. 8162–8171.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] W. Nie, B. Guo, Y. Huang, C. Xiao, A. Vahdat, and A. Anandkumar, Diffusion
    models for adversarial purification, in International Conference on Machine Learning
    (ICML), 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] M. Nikolova, A variational approach to remove outliers and impulse noise,
    Journal of Mathematical Imaging and Vision, 20 (2004), pp. 99–120.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] G. Ohayon, T. Adrai, M. Elad, and T. Michaeli, Reasons for the superiority
    of stochastic estimators over deterministic ones: Robustness, consistency and
    perceptual quality, arXiv preprint arXiv:2211.08944, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] G. Ohayon, T. Adrai, G. Vaksman, M. Elad, and P. Milanfar, High perceptual
    quality image denoising with a posterior sampling CGAN, in Proceedings of the
    IEEE/CVF International Conference on Computer Vision, 2021, pp. 1805–1813.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Z. Pan, X. Zhou, and H. Tian, Extreme generative image compression by
    learning text embedding from diffusion models, arXiv preprint arXiv:2211.07793,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad, Orthogonal matching
    pursuit: Recursive function approximation with applications to wavelet decomposition,
    in Proceedings of 27th Asilomar conference on signals, systems and computers,
    IEEE, 1993, pp. 40–44.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] K. Pearson, On lines and planes of closest fit to systems of points in
    space, The London, Edinburgh, and Dublin philosophical magazine and journal of
    science, 2 (1901), pp. 559–572.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] P. Perona and J. Malik, Scale-space and edge detection using anisotropic
    diffusion, IEEE Transactions on pattern analysis and machine intelligence, 12
    (1990), pp. 629–639.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] H. Pishro-Nik, Introduction to probability, statistics and random processes,
    (2014).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] T. Plötz and S. Roth, Neural nearest neighbors networks, in Neural Information
    Processing Systems, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] N. N. Ponomarenko, V. V. Lukin, A. A. Zelensky, J. T. Astola, and K. O.
    Egiazarian, Adaptive dct-based filtering of images corrupted by spatially correlated
    noise, in Image processing: algorithms and systems VI, vol. 6812, SPIE, 2008,
    pp. 285–295.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] B. Poole, A. Jain, J. T. Barron, and B. Mildenhall, Dreamfusion: Text-to-3d
    using 2d diffusion, arXiv preprint arXiv:2209.14988, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] J. Portilla, V. Strela, M. J. Wainwright, and E. P. Simoncelli, Image
    denoising using scale mixtures of gaussians in the wavelet domain, IEEE Transactions
    on Image processing, 12 (2003), pp. 1338–1351.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] A. Radford, L. Metz, and S. Chintala, Unsupervised representation learning
    with deep convolutional generative adversarial networks, in 4th International
    Conference on Learning Representations, ICLR, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] J. Rajan, K. Kannan, and M. Kaimal, An improved hybrid model for molecular
    image denoising, Journal of Mathematical Imaging and Vision, 31 (2008), pp. 73–79.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen, Hierarchical
    text-conditional image generation with clip latents, arXiv preprint arXiv:2204.06125,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] E. T. Reehorst and P. Schniter, Regularization by denoising: Clarifications
    and new interpretations, IEEE Transactions on computational imaging, 5 (2018),
    pp. 52–67.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] T. Remez, O. Litany, R. Giryes, and A. M. Bronstein, Class-aware fully
    convolutional gaussian and poisson denoising, IEEE Transactions on Image Processing,
    27 (2018), pp. 5707–5722.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] M. P. Reymann, T. Würfl, P. Ritt, B. Stimpel, M. Cachovan, A. H. Vija,
    and A. Maier, U-net for SPECT image denoising, in 2019 IEEE Nuclear Science Symposium
    and Medical Imaging Conference (NSS/MIC), IEEE, 2019, pp. 1–2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] D. Rezende and S. Mohamed, Variational inference with normalizing flows,
    in International Conference on Machine Learning, PMLR, 2015, pp. 1530–1538.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] J. Rick Chang, C.-L. Li, B. Poczos, B. Vijaya Kumar, and A. C. Sankaranarayanan,
    One network to solve them all: Solving linear inverse problems using deep projection
    models, in Proceedings of the IEEE International Conference on Computer Vision,
    2017, pp. 5888–5897.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] G. O. Roberts, R. L. Tweedie, et al., Exponential convergence of langevin
    distributions and their discrete approximations, Bernoulli, 2 (1996), pp. 341–363.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] Y. Romano, M. Elad, and P. Milanfar, The little engine that could: Regularization
    by denoising (RED), SIAM Journal on Imaging Sciences, 10 (2017), pp. 1804–1844.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, High-resolution
    image synthesis with latent diffusion models, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2022, pp. 10684–10695.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] A. Rond, R. Giryes, and M. Elad, Poisson inverse problems by the plug-and-play
    scheme, Journal of Visual Communication and Image Representation, 41 (2016), pp. 96–108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] O. Ronneberger, P. Fischer, and T. Brox, U-net: Convolutional networks
    for biomedical image segmentation, in International Conference on Medical image
    computing and computer-assisted intervention, Springer, 2015, pp. 234–241.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] R. J. Rossi, Mathematical statistics: an introduction to likelihood based
    inference, John Wiley & Sons, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] S. Roth and M. J. Black, Fields of experts: a framework for learning
    image priors, 2005 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition (CVPR’05), 2 (2005), pp. 860–867 vol. 2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] S. Roth and M. J. Black, Fields of experts, International Journal of
    Computer Vision, 82 (2009), pp. 205–229.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] P. J. Rousseeuw, F. R. Hampel, E. M. Ronchetti, and W. A. Stahel, Robust
    statistics: the approach based on influence functions, John Wiley & Sons, 2011.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] D. L. Ruderman, The statistics of natural images, Network: Computation
    in Neural Systems, 5 (1994), pp. 517–548.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] L. I. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based
    noise removal algorithms, Physica D: nonlinear phenomena, 60 (1992), pp. 259–268.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] N. Ruiz, Y. Li, V. Jampani, Y. Pritch, M. Rubinstein, and K. Aberman,
    Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation,
    arXiv preprint arXiv:2208.12242, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, Learning representations
    by back-propagating errors, nature, 323 (1986), pp. 533–536.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] C. Saharia, W. Chan, H. Chang, C. Lee, J. Ho, T. Salimans, D. Fleet,
    and M. Norouzi, Palette: Image-to-image diffusion models, in ACM SIGGRAPH 2022
    Conference Proceedings, 2022, pp. 1–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. Denton, S. K. S.
    Ghasemipour, B. K. Ayan, S. S. Mahdavi, R. G. Lopes, et al., Photorealistic text-to-image
    diffusion models with deep language understanding, arXiv preprint arXiv:2205.11487,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] C. Saharia, J. Ho, W. Chan, T. Salimans, D. J. Fleet, and M. Norouzi,
    Image super-resolution via iterative refinement, IEEE Transactions on Pattern
    Analysis and Machine Intelligence, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] P. Saint-Marc, J.-S. Chen, and G. Medioni, Adaptive smoothing: A general
    tool for early vision, IEEE Transactions on Pattern Analysis & Machine Intelligence,
    13 (1991), pp. 514–529.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] T. Salimans and J. Ho, Progressive distillation for fast sampling of
    diffusion models, arXiv preprint arXiv:2202.00512, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] J. Salmon, Z. Harmany, C.-A. Deledalle, and R. Willett, Poisson noise
    reduction with non-local pca, Journal of mathematical imaging and vision, 48 (2014),
    pp. 279–294.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] A. Sauer, K. Schwarz, and A. Geiger, StyleGAN-XL: Scaling StyleGAN to
    large diverse datasets, arXiv preprint arXiv:2202.00273, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] M. Scetbon, M. Elad, and P. Milanfar, Deep K-SVD denoising, IEEE Transactions
    on Image Processing, 30 (2021), pp. 5944–5955.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] R. W. Schafer, R. M. Mersereau, and M. A. Richards, Constrained iterative
    restoration algorithms, Proceedings of the IEEE, 69 (1981), pp. 432–450.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] U. Schmidt and S. Roth, Shrinkage fields for effective image restoration,
    2014 IEEE Conference on Computer Vision and Pattern Recognition, (2014), pp. 2774–2781.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Y. Shi, V. De Bortoli, G. Deligiannidis, and A. Doucet, Conditional simulation
    using diffusion Schrödinger bridges, arXiv preprint arXiv:2202.13460, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] A. Sinha, J. Song, C. Meng, and S. Ermon, D2c: Diffusion-decoding models
    for few-shot conditional generation, Advances in Neural Information Processing
    Systems, 34 (2021), pp. 12533–12548.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] N. Sochen, R. Kimmel, and R. Malladi, A general framework for low level
    vision, IEEE transactions on image processing, 7 (1998), pp. 310–318.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] J. W. Soh and N. I. Cho, Deep universal blind image denoising, in 2020
    25th International Conference on Pattern Recognition (ICPR), IEEE, 2021, pp. 747–754.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, Deep
    unsupervised learning using nonequilibrium thermodynamics, in International Conference
    on Machine Learning, PMLR, 2015, pp. 2256–2265.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] J. Song, C. Meng, and S. Ermon, Denoising diffusion implicit models,
    in International Conference on Learning Representations, April 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] M. Song, Y. Zhang, and T. O. Aydin, Tempformer: Temporally consistent
    transformer for video denoising, in European Conference on Computer Vision, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Y. Song and S. Ermon, Generative modeling by estimating gradients of
    the data distribution, in Advances in Neural Information Processing Systems, 2019,
    pp. 11918–11930.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] Y. Song and S. Ermon, Improved techniques for training score-based generative
    models, in Advances in Neural Information Processing Systems, 33, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole,
    Score-based generative modeling through stochastic differential equations, in
    International Conference on Learning Representations, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] S. Sreehari, S. V. Venkatakrishnan, B. Wohlberg, G. T. Buzzard, L. F.
    Drummy, J. P. Simmons, and C. A. Bouman, Plug-and-play priors for bright field
    electron tomography and sparse interpolation, IEEE Transactions on Computational
    Imaging, 2 (2016), pp. 408–423.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] K. Srinivasan and D. Ebenezer, A new fast and efficient decision-based
    algorithm for removal of high-density impulse noises, IEEE Signal Processing Letters,
    14 (2007), pp. 189–192.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] C. M. Stein, Estimation of the mean of a multivariate normal distribution,
    The annals of Statistics, (1981), pp. 1135–1151.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] J. Sun, Y. Du, C. Li, T.-H. Wu, B. Yang, and G. S. Mok, Pix2pix generative
    adversarial network for low dose myocardial perfusion SPECT denoising, Quantitative
    Imaging in Medicine and Surgery, 12 (2022), p. 3539.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] Y. Sun, J. Liu, and U. Kamilov, Block coordinate regularization by denoising,
    in Advances in Neural Information Processing Systems, 2019, pp. 380–390.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] Y. Sun, B. Wohlberg, and U. S. Kamilov, An online plug-and-play algorithm
    for regularized image reconstruction, IEEE Transactions on Computational Imaging,
    5 (2019), pp. 395–408.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Y. Sun, Z. Wu, X. Xu, B. Wohlberg, and U. S. Kamilov, Scalable plug-and-play
    admm with convergence guarantees, IEEE Transactions on Computational Imaging,
    7 (2021), pp. 849–863.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] Y. Tai, J. Yang, X. Liu, and C. Xu, Memnet: A persistent memory network
    for image restoration, in Proceedings of the IEEE international conference on
    computer vision, 2017, pp. 4539–4547.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] H. Takeda, S. Farsiu, and P. Milanfar, Kernel regression for image processing
    and reconstruction, IEEE Transactions on image processing, 16 (2007), pp. 349–366.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] H. Talbot, H. Phelippeau, M. Akil, and S. Bara, Efficient poisson denoising
    for photography, in 2009 16th IEEE International Conference on Image Processing
    (ICIP), IEEE, 2009, pp. 3881–3884.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] H. Talebi and P. Milanfar, Global image denoising, IEEE Transactions
    on Image Processing, 23 (2013), pp. 755–768.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] T. Tasdizen, Principal neighborhood dictionaries for nonlocal means image
    denoising, IEEE Transactions on Image Processing, 18 (2009), pp. 2649–2660.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] M. Tassano, J. Delon, and T. Veit, Dvdnet: A fast network for deep video
    denoising, in 2019 IEEE International Conference on Image Processing (ICIP), IEEE,
    2019, pp. 1805–1809.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] M. Tassano, J. Delon, and T. Veit, Fastdvdnet: Towards real-time deep
    video denoising without flow estimation, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2020, pp. 1354–1363.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] P. Tchebycheff, Sur deux théorèmes relatifs aux probabilités, Acta Mathematica,
    14 (1890), pp. 305 – 315.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, Scene-adapted
    plug-and-play algorithm with convergence guarantees, in IEEE 27th International
    Workshop on Machine Learning for Signal Processing (MLSP), 2017, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, A convergent
    image fusion algorithm using scene-adapted Gaussian-mixture-based denoising, IEEE
    Transactions on Image Processing, 28 (2018), pp. 451–463.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, Image restoration
    and reconstruction using targeted plug-and-play priors, IEEE Transactions on Computational
    Imaging, 5 (2019), pp. 675–686.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] C. Tian, L. Fei, W. Zheng, Y. Xu, W. Zuo, and C.-W. Lin, Deep learning
    on image denoising: An overview, Neural Networks, 131 (2020), pp. 251–275.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] A. Tikhonov and V. Arsenin, Solution of Ill-posed Problems, Washington:
    Winston & Sons, 1977.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] T. Tirer and R. Giryes, Image restoration by iterative denoising and
    backward projections, IEEE Transactions on Image Processing, 28 (2018), pp. 1220–1234.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] C. Tomasi and R. Manduchi, Bilateral filtering for gray and color images,
    in Sixth international conference on computer vision (IEEE Cat. No. 98CH36271),
    IEEE, 1998, pp. 839–846.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] L. D. Tran, S. M. Nguyen, and M. Arai, Gan-based noise model for denoising
    real images, in Proceedings of the Asian Conference on Computer Vision, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] D. Ulyanov, A. Vedaldi, and V. Lempitsky, Deep image prior, in Proceedings
    of the IEEE CVPR, 2018, pp. 9446–9454.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] A. Vahdat, K. Kreis, and J. Kautz, Score-based generative modeling in
    latent space, in Neural Information Processing Systems (NeurIPS), 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] G. Vaksman and M. Elad, Patch-craft self-supervised training for correlated
    image denoising, arXiv preprint arXiv:2211.09919, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] G. Vaksman, M. Elad, and P. Milanfar, LIDIA: Lightweight learned image
    denoising with instance adaptation, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops, 2020, pp. 524–525.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] G. Vaksman, M. Elad, and P. Milanfar, Patch craft: Video denoising by
    deep modeling and patch matching, 2021 IEEE/CVF International Conference on Computer
    Vision (ICCV), (2021), pp. 2137–2146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] G. Vaksman, M. Zibulevsky, and M. Elad, Patch ordering as a regularization
    for inverse problems in image processing, SIAM Journal on Imaging Sciences, 9
    (2016), pp. 287–319.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] D. Valsesia, G. Fracastoro, and E. Magli, Deep graph-convolutional image
    denoising, IEEE Transactions on Image Processing, 29 (2019), pp. 8226–8237.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[293] A. Van Den Oord, N. Kalchbrenner, and K. Kavukcuoglu, Pixel recurrent
    neural networks, in International Conference on Machine Learning, PMLR, 2016,
    pp. 1747–1756.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[294] M. Vatsa, R. Singh, and A. Noore, Denoising and segmentation of 3d brain
    images., IPCV, 9 (2009), pp. 561–567.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[295] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg, Plug-and-play priors
    for model based reconstruction, in 2013 IEEE Global Conference on Signal and Information
    Processing, IEEE, 2013, pp. 945–948.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[296] P. Vincent, A connection between score matching and denoising autoencoders,
    Neural computation, 23 (2011), pp. 1661–1674.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[297] C. Wang, J. Zhou, and S. Liu, Adaptive non-local means filter for image
    deblocking, Signal Processing: Image Communication, 28 (2013), pp. 522–530.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[298] Y. Wang, H. Huang, Q. Xu, J. Liu, Y. Liu, and J. Wang, Practical deep
    raw image denoising on mobile devices, in European Conference on Computer Vision,
    Springer, 2020, pp. 1–16.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[299] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, Image quality
    assessment: from error visibility to structural similarity, IEEE transactions
    on image processing, 13 (2004), pp. 600–612.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[300] Z. Wang and D. Zhang, Progressive switching median filter for the removal
    of impulse noise from highly corrupted images, IEEE Transactions on Circuits and
    Systems Ii: Analog and Digital Signal Processing, 46 (1999), pp. 78–80.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[301] K. Wei, Y. Fu, J. Yang, and H. Huang, A physics-based noise formation
    model for extreme low-light raw denoising, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2020, pp. 2758–2767.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[302] J. Weickert, Anisotropic diffusion in image processing, Stuttgart: Teubner,
    1998.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[303] J. Whang, M. Delbracio, H. Talebi, C. Saharia, A. G. Dimakis, and P. Milanfar,
    Deblurring via stochastic refinement, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2022, pp. 16293–16303.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[304] N. Wiener, Extrapolation, interpolation, and smoothing of stationary
    time series: with engineering applications, vol. 113, MIT press Cambridge, MA,
    1949.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[305] J. Wright, A. Ganesh, S. Rao, Y. Peng, and Y. Ma, Robust principal component
    analysis: Exact recovery of corrupted low-rank matrices via convex optimization,
    Advances in neural information processing systems, 22 (2009).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[306] J. Xie, L. Xu, and E. Chen, Image denoising and inpainting with deep
    neural networks, in NIPS, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[307] J. Xu, L. Zhang, and D. Zhang, A trilateral weighted sparse coding scheme
    for real-world image denoising, in Proceedings of the European conference on computer
    vision (ECCV), 2018, pp. 20–36.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[308] Q. Xu, C. Zhang, and L. Zhang, Denoising convolutional neural network,
    in 2015 IEEE International Conference on Information and Automation, IEEE, 2015,
    pp. 1184–1187.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[309] X. Xu, Y. Sun, J. Liu, B. Wohlberg, and U. S. Kamilov, Provable convergence
    of plug-and-play priors with MMSE denoisers, arXiv preprint arXiv:2005.07685,
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[310] N. Yair and T. Michaeli, Multi-scale weighted nuclear norm image restoration,
    in Proceedings of the IEEE conference on computer vision and pattern recognition,
    2018, pp. 3165–3174.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311] J. C. K. Yan, P. Campisi, and D. Hatzinakos, Film grain noise removal
    and generation for color images, in Proceedings of the 1998 IEEE International
    Conference on Acoustics, Speech and Signal Processing, ICASSP’98 (Cat. No. 98CH36181),
    vol. 5, IEEE, 1998, pp. 2957–2960.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[312] J. C. K. Yan and D. Hatzinakos, Signal-dependent film grain noise removal
    and generation based on higher-order statistics, Proceedings of the IEEE Signal
    Processing Workshop on Higher-Order Statistics, (1997), pp. 77–81.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[313] D. Yang and J. Sun, Proximal dehaze-net: A prior learning-based deep
    network for single image dehazing, in Proceedings of the european conference on
    computer vision (ECCV), 2018, pp. 702–717.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[314] L. Yang, Z. Li, R. Ge, J. Zhao, H. Si, and D. Zhang, Low-dose ct denoising
    via sinogram inner-structure transformer, IEEE Transactions on Medical Imaging,
    (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[315] L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao, Y. Shao, W. Zhang,
    B. Cui, and M.-H. Yang, Diffusion models: A comprehensive survey of methods and
    applications, arXiv preprint arXiv:2209.00796, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[316] Q. Yang, P. Yan, Y. Zhang, H. Yu, Y. Shi, X. Mou, M. K. Kalra, Y. Zhang,
    L. Sun, and G. Wang, Low-dose ct image denoising using a generative adversarial
    network with wasserstein distance and perceptual loss, IEEE transactions on medical
    imaging, 37 (2018), pp. 1348–1357.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[317] C. Yao, S. Jin, M. Liu, and X. Ban, Dense residual transformer for image
    denoising, Electronics, 11 (2022), p. 418.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[318] X. Yi and P. Babyn, Sharpness-aware low-dose ct denoising using conditional
    generative adversarial network, Journal of digital imaging, 31 (2018), pp. 655–669.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[319] F. Yu, Y. Zhang, S. Song, A. Seff, and J. Xiao, Lsun: Construction of
    a large-scale image dataset using deep learning with humans in the loop, arXiv
    preprint arXiv:1506.03365, (2015).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[320] G. Yu, G. Sapiro, and S. Mallat, Solving inverse problems with piecewise
    linear estimators: From Gaussian mixture models to structured sparsity, IEEE Transactions
    on Image Processing, 21 (2011), pp. 2481–2499.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[321] Z. Yue, H. Yong, Q. Zhao, D. Meng, and L. Zhang, Variational denoising
    network: Toward blind noise modeling and removal, Advances in neural information
    processing systems, 32 (2019).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[322] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, and M.-H. Yang,
    Restormer: Efficient transformer for high-resolution image restoration, in Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 5728–5739.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[323] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M.-H. Yang, and
    L. Shao, Multi-stage progressive image restoration, in Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition, 2021, pp. 14821–14831.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[324] J. Zeng, G. Cheung, M. Ng, J. Pang, and C. Yang, 3D point cloud denoising
    using graph laplacian regularization of a low dimensional manifold model, IEEE
    Transactions on Image Processing, PP (2018).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[325] B. Zhang, J. M. Fadili, and J.-L. Starck, Wavelets, ridgelets, and curvelets
    for poisson noise removal, IEEE Transactions on image processing, 17 (2008), pp. 1093–1108.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[326] B. Zhang, M. Fadili, J.-L. Starck, and J.-C. Olivo-Marin, Multiscale
    variance-stabilizing transform for mixed-poisson-gaussian processes and its applications
    in bioimaging, in 2007 IEEE International Conference on Image Processing, vol. 6,
    IEEE, 2007, pp. VI–233.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[327] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, Self-attention generative
    adversarial networks, in International Conference on Machine Learning, PMLR, 2019,
    pp. 7354–7363.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[328] K. Zhang, L. V. Gool, and R. Timofte, Deep unfolding network for image
    super-resolution, in Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition, 2020, pp. 3217–3226.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[329] K. Zhang, Y. Li, W. Zuo, L. Zhang, L. V. Gool, and R. Timofte, Plug-and-play
    image restoration with deep denoiser prior, IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 44 (2020), pp. 6360–6376.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[330] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, Beyond a Gaussian denoiser:
    Residual learning of deep CNN for image denoising, IEEE Transactions on Image
    Processing, 26 (2017), pp. 3142–3155.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[331] K. Zhang, W. Zuo, S. Gu, and L. Zhang, Learning deep CNN denoiser prior
    for image restoration, in Proceedings of the IEEE CVPR, 2017, pp. 3929–3938.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[332] K. Zhang, W. Zuo, and L. Zhang, FFDNet: Toward a fast and flexible solution
    for CNN-based image denoising, IEEE Transactions on Image Processing, 27 (2018),
    pp. 4608–4622.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[333] K. Zhang, W. Zuo, and L. Zhang, Deep plug-and-play super-resolution for
    arbitrary blur kernels, in Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, 2019, pp. 1671–1681.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[334] M. Zhang, F. Zhang, Q. Liu, and S. Wang, Vst-net: Variance-stabilizing
    transformation inspired network for poisson denoising, Journal of Visual Communication
    and Image Representation, 62 (2019), pp. 12–22.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[335] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang, The unreasonable
    effectiveness of deep features as a perceptual metric, in Proceedings of the IEEE
    conference on computer vision and pattern recognition, 2018, pp. 586–595.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[336] X. Zhang, Z. Xu, N. Jia, W. Yang, Q. Feng, W. Chen, and Y. Feng, Denoising
    of 3d magnetic resonance images by using higher-order singular value decomposition,
    Medical Image Analysis, In press (2014).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[337] X.-P. Zhang and M. D. Desai, Adaptive denoising based on sure risk, IEEE
    signal processing letters, 5 (1998), pp. 265–267.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[338] Y. Zhang, H. Qin, X. Wang, and H. Li, Rethinking noise synthesis and
    modeling in raw denoising, in Proceedings of the IEEE/CVF International Conference
    on Computer Vision, 2021, pp. 4593–4601.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[339] Y. Zhang, Y. Tian, Y. Kong, B. Zhong, and Y. Fu, Residual dense network
    for image restoration, IEEE Transactions on Pattern Analysis and Machine Intelligence,
    (2020).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[340] Y. Zhang, Y. Zhu, E. Nichols, Q. Wang, S. Zhang, C. Smith, and S. Howard,
    A poisson-gaussian denoising dataset with real fluorescence microscopy images,
    in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2019, pp. 11710–11718.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[341] Z. Zhang, Y. Liu, J. Liu, F. Wen, and C. Zhu, Amp-net: Denoising-based
    deep unfolding for compressive image sensing, IEEE Transactions on Image Processing,
    30 (2020), pp. 1487–1500.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[342] H. Zhao, W. Shao, B. Bao, and H. Li, A simple and robust deep convolutional
    approach to blind image denoising, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[343] L. Zhou, J. D. Schaefferkoetter, I. W. Tham, G. Huang, and J. Yan, Supervised
    learning with cyclegan for low-dose fdg pet image denoising, Medical image analysis,
    65 (2020), p. 101770.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[344] Y. Zhou, J. Jiao, H. Huang, Y. Wang, J. Wang, H. Shi, and T. Huang, When
    AWGN-based denoiser meets real noises, in Proceedings of the AAAI Conference on
    Artificial Intelligence, vol. 34, 2020, pp. 13074–13081.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[345] F. Zhu, G. Chen, and P.-A. Heng, From noise modeling to blind image denoising,
    in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    2016, pp. 420–429.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[346] Z. Zhu, Y. Wei, J. Wang, Z. Gan, Z. Zhang, L. Wang, G. Hua, L. Wang,
    Z. Liu, and H. Hu, Exploring discrete diffusion models for image captioning, arXiv
    preprint arXiv:2211.11694, (2022).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[347] D. Zoran and Y. Weiss, From learning models of natural image patches
    to whole image restoration, in IEEE International Conference on Computer Vision,
    2011, pp. 479–486.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
