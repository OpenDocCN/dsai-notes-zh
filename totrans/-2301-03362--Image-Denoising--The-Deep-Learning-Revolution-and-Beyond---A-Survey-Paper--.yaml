- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:42:25'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:42:25
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2301.03362] Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2301.03362] 图像去噪：深度学习革命及其超越 – 一篇综述论文 –'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2301.03362](https://ar5iv.labs.arxiv.org/html/2301.03362)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2301.03362](https://ar5iv.labs.arxiv.org/html/2301.03362)
- en: \headers
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \headers
- en: 'Image Denoising: The Deep Learning Revolution and Beyond M. Elad, B. Kawar
    and G. Vaksman'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 图像去噪：深度学习革命及其超越 M. Elad, B. Kawar 和 G. Vaksman
- en: 'Image Denoising: The Deep Learning Revolution and Beyond'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 图像去噪：深度学习革命及其超越
- en: – A Survey Paper –
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: – 一篇综述论文 –
- en: Michael Elad    Bahjat Kawar and Gregory Vaksman
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: Michael Elad    Bahjat Kawar 和 Gregory Vaksman
- en: The Computer Science Department    Technion – Israel Institute of Technology
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机科学系    以色列理工学院
- en: 'email: {elad    bahjat.kawar    grishavak}@cs.technion.ac.il'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 电子邮件：{elad    bahjat.kawar    grishavak}@cs.technion.ac.il
- en: Abstract
  id: totrans-13
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Image denoising – removal of additive white Gaussian noise from an image – is
    one of the oldest and most studied problems in image processing. An extensive
    work over several decades has led to thousands of papers on this subject, and
    to many well-performing algorithms for this task. Indeed, ten years ago, these
    achievements have led some researchers to suspect that “Denoising is Dead”, in
    the sense that all that can be achieved in this domain has already been obtained.
    However, this turned out to be far from the truth, with the penetration of deep
    learning (DL) into the realm of image processing. The era of DL brought a revolution
    to image denoising, both by taking the lead in today’s ability for noise suppression
    in images, and by broadening the scope of denoising problems being treated. Our
    paper starts by describing this evolution, highlighting in particular the tension
    and synergy that exist between classical approaches and modern Artificial Intelligence
    (AI) alternatives in design of image denoisers.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 图像去噪——从图像中去除加性白噪声——是图像处理领域最古老和研究最广泛的问题之一。经过数十年的广泛研究，产生了数千篇相关论文和许多高效的算法。确实，十年前，这些成就使一些研究人员怀疑“去噪已死”，即在这个领域能取得的所有成果已经得到。然而，随着深度学习（DL）渗透到图像处理领域，这一说法被证明是远非事实。DL时代给图像去噪带来了革命，不仅在噪声抑制能力方面领先于今天的技术，而且扩展了去噪问题的处理范围。我们的论文首先描述了这一演变，特别强调了经典方法与现代人工智能（AI）替代方法在图像去噪器设计中的张力和协同作用。
- en: The recent transitions in the field of image denoising go far beyond the ability
    to design better denoisers. In the second part of this paper we focus on recently
    discovered abilities and prospects of image denoisers. We expose the possibility
    of using image denoisers for service of other problems, such as regularizing general
    inverse problems and serving as the prime engine in diffusion-based image synthesis.
    We also unveil the (strange?) idea that denoising and other inverse problems might
    not have a unique solution, as common algorithms would have us believe. Instead,
    we describe constructive ways to produce randomized and diverse high perceptual
    quality results for inverse problems, all fueled by the progress that DL brought
    to image denoising.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图像去噪领域的近期变革远超出设计更好去噪器的能力。本文的第二部分重点关注近期发现的图像去噪器的能力和前景。我们揭示了将图像去噪器用于其他问题的可能性，例如正则化一般逆问题，以及在基于扩散的图像合成中作为主要引擎的可能性。我们还揭示了一个（奇怪的？）想法，即去噪和其他逆问题可能没有唯一解，这与常见算法的观点相矛盾。相反，我们描述了生成随机和多样化高感知质量结果的建设性方法，这些都得益于深度学习（DL）对图像去噪的进展。
- en: This is a survey paper, and its prime goal is to provide a broad view of the
    history of the field of image denoising and closely related topics in image processing.
    Our aim is to give a better context to recent discoveries, and to the influence
    of the AI revolution in our domain.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一篇综述论文，其主要目标是提供图像去噪领域及相关图像处理主题的广泛历史视角。我们的目的是为最近的发现和人工智能革命在我们领域中的影响提供更好的背景。
- en: 'keywords:'
  id: totrans-17
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Image denoising, Inverse problems, MMSE Estimation, Plug and Play Prior (PnP),
    Regularization by Denoising (RED), Langevin Dynamics, Diffusion Models, Image
    Synthesis, Perceptual Quality, Perception-Distortion Trade-off.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 图像去噪，逆问题，MMSE估计，插拔式先验（PnP），通过去噪正则化（RED），朗之万动力学，扩散模型，图像合成，感知质量，感知-失真权衡。
- en: 1 Introduction
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Within the wide fields of image processing and computational imaging, the task
    of image denoising has been given an exceptionally large attention over the past
    several decades. Indeed, noise suppression in images is one of the oldest and
    most studied problems in these fields, with numerous papers offering diverse algorithms,
    analysis of this task in various forms, or extensions of it.¹¹1See Figure [1](#S2.F1
    "Figure 1 ‣ 2.4 The Interest in Image Denoising ‣ 2 Image Denoising – Background
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    for the quantities of denoising related papers over the years. A substantial portion
    of the proposed denoising techniques has been dedicated to the removal of Additive
    White Gaussian Noise (AWGN) from images, while there are other contributions that
    target different noise distributions, e.g. Poisson, salt-and-pepper, and more.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像处理和计算成像的广泛领域中，图像去噪任务在过去几十年中得到了特别大的关注。事实上，图像中的噪声抑制是这些领域中最古老和最研究的问题之一，许多论文提供了各种算法，对这一任务的不同形式进行分析或扩展¹¹1见图
    [1](#S2.F1 "图 1 ‣ 2.4 图像去噪的兴趣 ‣ 2 图像去噪 – 背景 ‣ 图像去噪：深度学习革命及其后续 – 综述论文 –")，展示了多年间去噪相关论文的数量。提出的去噪技术中有相当一部分致力于从图像中去除加性白噪声（AWGN），而其他贡献则针对不同的噪声分布，如泊松噪声、盐和胡椒噪声等。
- en: Removal of noise from an image is an actual necessity that comes up with practically
    every imaging sensor [[191](#bib.bib191)]. However, the interest in this problem
    goes far beyond this practical need – image denoising is the simplest inverse
    problem, and as such, it has been recognized over the years as the perfect test-bed
    for assessing new ideas that are often brought to image processing. In recent
    years this appeal has further widened with the realization that denoisers can
    serve other imaging needs [[295](#bib.bib295), [231](#bib.bib231), [260](#bib.bib260)].
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 从图像中去除噪声是几乎每个成像传感器都会遇到的实际需求 [[191](#bib.bib191)]。然而，对这个问题的兴趣远超实际需求——图像去噪是最简单的逆问题，因此多年来被认为是评估新思路的理想测试平台，这些新思路通常会被引入图像处理领域。近年来，这种吸引力进一步扩大，因为认识到去噪器可以满足其他成像需求 [[295](#bib.bib295),
    [231](#bib.bib231), [260](#bib.bib260)]。
- en: The years 1980 – 2010 have seen consistently improving denoising algorithms,
    many of which relying on the Bayesian point of view. This progress has been geared
    by an evolution of image priors that form the backbone of the overall progress
    in image processing. This path, which we will refer to as the *classical era*,
    started with the early $L_{2}$-based regularization, proceeding to robust statistics,
    moving to the introduction of wavelets, and the later deployment of partial differential
    equations to imaging tasks, and this continued all the way to sparse modeling,
    patch-based methods, and low-rank structure assumptions²²2As referencing this
    is too long, we provide specific citations to each of these in later sections..
    This extensive work over several decades has led to many well-performing denoising
    algorithms, and to a compelling and rich scientific field. In fact, ten years
    ago, these glorious achievements have led some researchers to consider the possibility
    that “Denoising is Dead”, believing that the existing solutions are already touching
    the achievable performance ceiling [[45](#bib.bib45), [162](#bib.bib162), [163](#bib.bib163)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 1980年至2010年间，去噪算法持续改进，其中许多依赖于贝叶斯视角。这一进展得益于图像先验的演变，这些先验构成了图像处理整体进展的基础。这一过程，我们将其称为*经典时代*，从早期基于$L_{2}$的正则化开始，经过鲁棒统计，引入小波，到后来的偏微分方程在成像任务中的应用，最终发展到稀疏建模、基于块的方法和低秩结构假设²²2由于引用过长，我们在后续章节提供了这些的具体引用。多年来的大量工作导致了许多表现良好的去噪算法，并形成了一个引人注目且丰富的科学领域。实际上，十年前，这些辉煌的成就使得一些研究人员考虑到“去噪已死”的可能性，认为现有解决方案已经接近可实现的性能上限 [[45](#bib.bib45),
    [162](#bib.bib162), [163](#bib.bib163)]。
- en: The past decade has brought a paradigm shift to the general topic of data processing
    due to the emergence of the Artificial Intelligence (AI) revolution. The great
    success of this deep learning (DL) trend has also introduced a reformation to
    the broad field of image processing, and to image denoising in particular. These
    new winds led to novel techniques for designing better performing denoisers [[50](#bib.bib50),
    [330](#bib.bib330), [167](#bib.bib167), [332](#bib.bib332), [270](#bib.bib270),
    [159](#bib.bib159), [8](#bib.bib8), [339](#bib.bib339), [165](#bib.bib165)], and
    discovering new and more daring ways for deploying them and broadening their scope [[1](#bib.bib1),
    [170](#bib.bib170), [323](#bib.bib323), [288](#bib.bib288), [102](#bib.bib102),
    [166](#bib.bib166), [146](#bib.bib146), [212](#bib.bib212), [113](#bib.bib113)].
    These days, deep-learning based denoisers are at the very top in their ability
    for noise suppression in images (see e.g. [[330](#bib.bib330), [165](#bib.bib165),
    [322](#bib.bib322)], leaving no competitive room for the classical alternatives).
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 过去十年，由于人工智能（AI）革命的兴起，数据处理领域发生了范式转变。这一深度学习（DL）趋势的巨大成功也引入了对广泛的图像处理领域，尤其是图像去噪的改革。这些新风潮催生了设计更高性能去噪器的创新技术[[50](#bib.bib50),
    [330](#bib.bib330), [167](#bib.bib167), [332](#bib.bib332), [270](#bib.bib270),
    [159](#bib.bib159), [8](#bib.bib8), [339](#bib.bib339), [165](#bib.bib165)]，并发现了部署这些技术的新方法，扩展了它们的应用范围[[1](#bib.bib1),
    [170](#bib.bib170), [323](#bib.bib323), [288](#bib.bib288), [102](#bib.bib102),
    [166](#bib.bib166), [146](#bib.bib146), [212](#bib.bib212), [113](#bib.bib113)]。如今，基于深度学习的去噪器在图像噪声抑制能力方面处于领先地位（参见例如[[330](#bib.bib330),
    [165](#bib.bib165), [322](#bib.bib322)]，几乎没有竞争余地给经典的替代方法）。
- en: 'In parallel to the above and seemingly detached from the deep learning activity,
    image denoising has been also a topic of investigation and discoveries of a different
    flavor: Harnessing denoiser engines for other imaging tasks. This started with
    the surprising idea that a good performing denoiser can serve as a prior, offering
    a highly effective regularization to inverse problems [[295](#bib.bib295), [231](#bib.bib231),
    [28](#bib.bib28), [139](#bib.bib139), [283](#bib.bib283), [268](#bib.bib268),
    [192](#bib.bib192), [280](#bib.bib280), [49](#bib.bib49), [55](#bib.bib55)]. This
    continued with the discovery that such denoisers can also be used for randomly
    synthesizing images by offering a practical sampling from the prior distribution
    of images, this way posing a potent competition to Generative Adversarial Networks
    (GANs) and other image generation methods [[260](#bib.bib260), [261](#bib.bib261),
    [262](#bib.bib262), [120](#bib.bib120), [287](#bib.bib287), [68](#bib.bib68),
    [122](#bib.bib122), [143](#bib.bib143), [121](#bib.bib121)].'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述内容平行且看似与深度学习活动无关，图像去噪也成为了另一种风格的调查和发现的主题：将去噪器引擎用于其他成像任务。这一探索始于一个令人惊讶的想法，即一个表现良好的去噪器可以作为先验，提供对逆问题的高度有效正则化[[295](#bib.bib295),
    [231](#bib.bib231), [28](#bib.bib28), [139](#bib.bib139), [283](#bib.bib283),
    [268](#bib.bib268), [192](#bib.bib192), [280](#bib.bib280), [49](#bib.bib49),
    [55](#bib.bib55)]。这一研究继续发现，这些去噪器还可以用于通过提供实际的图像先验分布采样来随机合成图像，这为生成对抗网络（GANs）和其他图像生成方法提供了强有力的竞争[[260](#bib.bib260),
    [261](#bib.bib261), [262](#bib.bib262), [120](#bib.bib120), [287](#bib.bib287),
    [68](#bib.bib68), [122](#bib.bib122), [143](#bib.bib143), [121](#bib.bib121)]。
- en: An intriguing sequel to the above synthesis revelation is the idea that solution
    of inverse problems could be revisited and posed as a sampling task from the posterior
    distribution of the image given the measurements, thus resorting again to image
    denoisers as the means for obtaining these solutions. This very recent line of
    work unveiled the daring idea that denoising and other inverse problems might
    not have a unique solution, as common algorithms would have us believe [[212](#bib.bib212),
    [146](#bib.bib146), [138](#bib.bib138), [145](#bib.bib145), [211](#bib.bib211)].
    Instead, this sampling approach has been shown to lead to constructive ways for
    producing randomized and diverse *high perceptual quality* results for inverse
    problems, exposing as a byproduct the inner uncertainty in such tasks.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 对上述综合揭示的一个有趣的后续是，逆问题的解决方案可以被重新审视，并作为从图像后验分布中进行采样的任务，这样又将图像去噪器作为获取这些解决方案的手段。这一非常新的研究方向揭示了一个大胆的想法，即去噪和其他逆问题可能没有唯一解，如常见算法所相信的那样[[212](#bib.bib212),
    [146](#bib.bib146), [138](#bib.bib138), [145](#bib.bib145), [211](#bib.bib211)]。相反，这种采样方法已被证明能产生随机化和多样化的*高感知质量*结果，作为副产品暴露了此类任务中的内在不确定性。
- en: All the above achievements have been strongly influenced and fueled by the progress
    that DL brought to image denoising. Adopting a wider perspective, image denoising
    these days has new horizons, and if any conclusion can be drawn from these recent
    accomplishments, it would be that this field is a very much alive playground with
    great challenges and prospects. This paper aims to disclose and detail the compelling
    story drawn above. Our prime goal is to provide a broad view of the history of
    the field of image denoising and closely related topics in image processing, give
    a better context to recent discoveries, and highlight the influence of the AI
    revolution in our domain.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些成就都受到了深度学习（DL）对图像去噪带来的进展的强烈影响和推动。从更广阔的角度来看，如今的图像去噪有了新的视野，如果从这些近期的成就中得出任何结论，那就是这个领域是一个充满挑战和前景的充满活力的游乐场。本文旨在揭示和详细描述上述引人注目的故事。我们的主要目标是提供一个图像去噪领域及其相关图像处理主题的广泛历史视角，为近期发现提供更好的背景，并突出人工智能革命在我们领域的影响。
- en: 'We start our journey in Section [2](#S2 "2 Image Denoising – Background ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") by clearly
    defining the image denoising task, discussing its ill-posed nature, and demonstrating
    its appeal over the years. We proceed in Sections [3](#S3 "3 Image Denoising –
    The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –") and [4](#S4 "4 Image Denoising – The Deep Learning Revolution
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    by describing the evolution of image denoisers, from the classical era to the
    deep-learning-based alternatives. Section [5](#S5 "5 Synergy between Classics
    and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –") highlights the tension and the possible synergy that exists
    between classical approaches and modern Artificial Intelligence (AI) alternatives
    in design of image denoisers.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在第[2](#S2 "2 图像去噪 – 背景 ‣ 图像去噪：深度学习革命及其之后 – 调查论文 –")节开始我们的旅程，通过明确定义图像去噪任务、讨论其病态特性并展示其多年来的吸引力。我们在第[3](#S3
    "3 图像去噪 – 经典时代 ‣ 图像去噪：深度学习革命及其之后 – 调查论文 –")节和第[4](#S4 "4 图像去噪 – 深度学习革命 ‣ 图像去噪：深度学习革命及其之后
    – 调查论文 –")节中描述了图像去噪器的演变，从经典时代到基于深度学习的替代方案。第[5](#S5 "5 经典与深度学习的协同作用 ‣ 图像去噪：深度学习革命及其之后
    – 调查论文 –")节强调了经典方法和现代人工智能（AI）替代方案在图像去噪器设计中的紧张关系和可能的协同作用。
- en: 'In the second part of the paper we change gears and move to discuss three recent
    discoveries that consider image denoisers as building blocks for other needs.
    We start broadly in Section [6](#S6 "6 Image Denoising – Migration towards Recent
    Discoveries ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") by defining the denoiser engine and its properties, and set the stage
    for the presentation of these three discoveries. We proceed in Section [7](#S7
    "7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") by discussing the
    ability to deploy these engines for regularizing inverse problems. Section [8](#S8
    "8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") exposes the possibility of
    synthesizing images using such denoisers, and Section [9](#S9 "9 Discovery 3:
    High Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") presents the notion of targeting perfect perceptual
    quality outcomes in image denoising and inverse problems by sampling from the
    posterior distribution. We conclude this paper in Section [10](#S10 "10 Conclusion
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    with an attempt to point to open questions and potential research directions.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文的第二部分，我们切换主题，讨论三项将图像去噪器作为其他需求构建块的近期发现。我们在第[6节](#S6 "6 图像去噪 – 向近期发现的迁移 ‣ 图像去噪：深度学习革命及其超越
    – 综述论文 –")中广泛地定义了去噪器引擎及其属性，为这三项发现的展示奠定基础。接着在第[7节](#S7 "7 发现1：通过图像去噪器解决反问题 ‣ 图像去噪：深度学习革命及其超越
    – 综述论文 –")中讨论了将这些引擎用于规范化反问题的能力。第[8节](#S8 "8 发现2：通过图像去噪器进行图像合成 ‣ 图像去噪：深度学习革命及其超越
    – 综述论文 –")揭示了使用这些去噪器合成图像的可能性，第[9节](#S9 "9 发现3：高感知质量图像恢复 ‣ 图像去噪：深度学习革命及其超越 – 综述论文
    –")介绍了通过从后验分布中采样来实现图像去噪和反问题中的完美感知质量结果的概念。我们在第[10节](#S10 "10 结论 ‣ 图像去噪：深度学习革命及其超越
    – 综述论文 –")中总结了论文，尝试指出开放问题和潜在的研究方向。
- en: '*Disclaimer:* While this paper aims to present a survey on the various ups
    and downs that the field of image denoising has gone through over the years, it
    would be simply impossible to do justice to all the published literature in this
    domain. We apologize if some papers are omitted from our references, as we attempt
    to mark the critical milestones in the history of this field. The interested reader
    is referred to [[156](#bib.bib156), [197](#bib.bib197), [130](#bib.bib130), [18](#bib.bib18),
    [92](#bib.bib92), [281](#bib.bib281)] for other surveys with different orientations.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: '*免责声明：* 虽然本论文旨在综述图像去噪领域多年来经历的各种波折，但要全面覆盖这一领域的所有已发表文献几乎是不可能的。如果一些论文在我们的参考文献中被遗漏，我们表示歉意，因为我们尝试标记这一领域历史上的关键里程碑。感兴趣的读者可以参考[[156](#bib.bib156),
    [197](#bib.bib197), [130](#bib.bib130), [18](#bib.bib18), [92](#bib.bib92), [281](#bib.bib281)]了解不同方向的其他综述。'
- en: 2 Image Denoising – Background
  id: totrans-30
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 图像去噪 – 背景
- en: 2.1 Problem Definition
  id: totrans-31
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 问题定义
- en: 'Our story must start with a proper definition of the denoising problem, and
    this will also serve the need for defining our notations hereafter. An ideal image³³3For
    simplicity of the discussion, assume that we refer to grayscale images. Addressing
    color is discussed shortly in Section [4](#S4 "4 Image Denoising – The Deep Learning
    Revolution ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –"). ${\mathbf{x}}\in\mathbb{R}^{N}$ is assumed to be drawn from the image
    manifold, represented by the probability density function $p({\mathbf{x}})$. Our
    measurement is the vector ${\mathbf{y}}\in\mathbb{R}^{N}$, given by'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的故事必须从对去噪问题的适当定义开始，这也将为后续符号的定义提供依据。一个理想的图像³³为了简化讨论，假设我们指的是灰度图像。颜色问题在第[4节](#S4
    "4 图像去噪 – 深度学习革命 ‣ 图像去噪：深度学习革命及其超越 – 综述论文 –")中简要讨论。假设${\mathbf{x}}\in\mathbb{R}^{N}$来自于图像流形，由概率密度函数$p({\mathbf{x}})$表示。我们的测量是向量${\mathbf{y}}\in\mathbb{R}^{N}$，给出为
- en: '| (1) |  | $\displaystyle{\mathbf{y}}={\mathbf{x}}+{\mathbf{v}},$ |  |'
  id: totrans-33
  prefs: []
  type: TYPE_TB
  zh: '| (1) |  | $\displaystyle{\mathbf{y}}={\mathbf{x}}+{\mathbf{v}},$ |  |'
- en: where ${\mathbf{v}}\in\mathbb{R}^{N}$ is a zero-mean independent and identically
    distributed (i.i.d.) Gaussian noise, i.e. ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$.
    The denoising task is the recovery of ${\mathbf{x}}$ from ${\mathbf{y}}$ with
    the knowledge of $\sigma$, and a denoiser is thus a function of the form $\hat{{\mathbf{x}}}=D({\mathbf{y}},\sigma)$.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\mathbf{v}}\in\mathbb{R}^{N}$ 是零均值的独立同分布（i.i.d.）高斯噪声，即 ${\mathbf{v}}\sim{\cal
    N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$。去噪任务是从 ${\mathbf{y}}$ 中恢复 ${\mathbf{x}}$，并且去噪器因此是形式为
    $\hat{{\mathbf{x}}}=D({\mathbf{y}},\sigma)$ 的函数。
- en: While there are many ways for assessing the performance of such denoisers, the
    most common one is the Mean-Squared-Error (MSE) measure,
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有许多方法可以评估这种去噪器的性能，但最常见的方法是均方误差（MSE）度量，
- en: '| (2) |  | $\displaystyle MSE=\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\mathbb{E}\left(\&#124;{\mathbf{x}}-D({\mathbf{y}},\sigma)\&#124;_{2}^{2}\right),$
    |  |'
  id: totrans-36
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $\displaystyle MSE=\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\mathbb{E}\left(\&#124;{\mathbf{x}}-D({\mathbf{y}},\sigma)\&#124;_{2}^{2}\right),$
    |  |'
- en: where the expectation is taken over the image distribution. A well-known result
    in estimation theory states that the best denoising with respect to this measure
    (i.e., achieving the Minimum MSE, thus referred to as MMSE) is given by [[217](#bib.bib217)],
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，期望是对图像分布进行的。估计理论中的一个著名结果指出，相对于这一度量，最佳的去噪（即，达到最小均方误差，称为MMSE）由[[217](#bib.bib217)]给出，
- en: '| (3) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  id: totrans-38
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
- en: This formula is misleadingly simple in its concise form, as designing a denoiser
    that achieves MMSE is quite challenging and oftentimes simply impossible. By the
    way, the curious reader may wonder why are we emphasizing the MSE measure and
    the MMSE denoiser. The answer will be carefully unfolded in the later parts of
    the paper, where these choices play a critical role. A brief note about this appears
    later in this section.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 这个公式在其简洁形式中具有误导性，因为设计一个达到 MMSE 的去噪器是非常具有挑战性的，往往几乎是不可能的。顺便说一下，好奇的读者可能会想知道为什么我们强调
    MSE 度量和 MMSE 去噪器。答案将在论文的后续部分中详细展开，这些选择发挥了关键作用。关于此的简要说明将在本节后面出现。
- en: How hard is it to denoise an image? How complicated could it be? Again, the
    simplicity of the problem definition is illusive, as this task is highly tough
    and in fact ill-posed. One could easily design a filtering method for attenuating
    and suppressing the noise in ${\mathbf{y}}$, but such a process is very likely
    to ruin the image content as well, losing small details, sacrificing edges, damaging
    fine textures, and more.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪图像有多困难？这可能有多复杂？再说一次，问题定义的简单性是虚幻的，因为这个任务非常困难，实际上是病态的。一个人可以很容易地设计一种滤波方法来减轻和抑制
    ${\mathbf{y}}$ 中的噪声，但这种过程很可能也会破坏图像内容，丢失细节，牺牲边缘，损坏细腻纹理等等。
- en: 2.2 The Gaussianity Assumption
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 高斯性假设
- en: 'In the problem definition above we focused on a very specific case of a zero-mean
    i.i.d. Gaussian noise contamination. The natural question arising is why are we
    restricting the discussion to this case? A brief inspection of the literature
    on image denoising reveals that this noise model is very popular, covered by most
    of the developed algorithms. Where this popularity comes from? Several answers
    come to mind:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在上述问题定义中，我们专注于零均值 i.i.d. 高斯噪声污染的一个非常具体的情况。自然的问题是，为什么我们要将讨论限制在这种情况？对图像去噪文献的简要检查显示，这种噪声模型非常流行，被大多数开发的算法覆盖。这种流行性来源于哪里？有几个答案浮现在脑海中：
- en: •
  id: totrans-43
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Central Limit Theorem: Noise in imaging may arise due to many physical reasons,
    and their accumulation leads often to a Gaussian distribution of the form discussed
    above, as an empirical manifestation of the Central Limit Theorem [[277](#bib.bib277),
    [127](#bib.bib127)]. As such, rather than modelling the intricate noise origins,
    a Gaussian assumption offers a blessed simplification for the later analysis and
    algorithm development in this field.'
  id: totrans-44
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 中心极限定理：成像中的噪声可能由于许多物理原因而产生，它们的积累通常会导致上述形式的高斯分布，作为中心极限定理的经验表现[[277](#bib.bib277),
    [127](#bib.bib127)]。因此，与其建模复杂的噪声来源，不如使用高斯假设，这为后续分析和算法开发提供了一个有利的简化。
- en: •
  id: totrans-45
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The Poisson Alternative: One might rightfully argue that the proper distribution
    to address for imaging noise would be the Poisson one, as imaging sensors essentially
    count photons, and their arrival is of Poissonian nature [[59](#bib.bib59)]. While
    this argument is indeed correct, when photon counts are high, the Poisson distribution
    becomes a Gaussian one [[26](#bib.bib26)]. If the counts are low, a variance stabilizing
    transform, such as *Anscombe* [[7](#bib.bib7)], can turn these measurements into
    additive Gaussian contaminated, again resorting to the Gaussianity regime [[81](#bib.bib81),
    [325](#bib.bib325), [233](#bib.bib233), [184](#bib.bib184), [12](#bib.bib12),
    [272](#bib.bib272), [334](#bib.bib334)].'
  id: totrans-46
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 泊松替代：有人可能会正确地认为，处理成像噪声的适当分布是泊松分布，因为成像传感器本质上是计数光子，其到达具有泊松性质 [[59](#bib.bib59)]。虽然这个论点确实正确，但当光子计数较高时，泊松分布会变成高斯分布 [[26](#bib.bib26)]。如果计数较低，像*Anscombe* [[7](#bib.bib7)]这样的方差稳定变换可以将这些测量转变为加性高斯污染，再次回到高斯性范畴 [[81](#bib.bib81),
    [325](#bib.bib325), [233](#bib.bib233), [184](#bib.bib184), [12](#bib.bib12),
    [272](#bib.bib272), [334](#bib.bib334)]。
- en: •
  id: totrans-47
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Mathematical Elegance: The Gaussian case is easily modeled, and consequent
    formulations become simple and elegant. Such is the case with the log-likelihood
    function $p({\mathbf{y}}|{\mathbf{x}})$ and other related derivations that will
    be shown in subsequent sections.'
  id: totrans-48
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 数学优雅：高斯情况容易建模，相应的公式变得简单而优雅。这适用于对数似然函数 $p({\mathbf{y}}|{\mathbf{x}})$ 以及后续部分将展示的其他相关推导。
- en: •
  id: totrans-49
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'MMSE Denoiser Engines: Our last argument for the Gaussianity assumption is
    quite surprising and unfamiliar to many in our field. As it turns out, an MMSE
    denoiser for the removal of zero-mean i.i.d. Gaussian noise is of great theoretical
    importance. Such an engine has critical properties that enable its deployment
    as a prior (see Section [7](#S7 "7 Discovery 1: Solving Inverse Problems via Image
    Denoisers ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –")) for inverse problems. In addition, and perhaps more importantly, such
    denoisers have strong theoretical ties to the *score function* [[260](#bib.bib260)],
    a fact that will be highlighted and exploited in Sections [8](#S8 "8 Discovery
    2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")-[9.2](#S9.SS2 "9.2 High Perceptual Quality Solution
    to Inverse Problems ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –").'
  id: totrans-50
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'MMSE 去噪引擎：我们对高斯假设的最后一个论点对许多领域的人来说是相当惊讶且不熟悉的。事实证明，去除零均值独立同分布高斯噪声的 MMSE 去噪器具有极大的理论重要性。这种引擎具有关键属性，使其能够作为逆问题的先验（见第
    [7](#S7 "7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") 节）进行部署。此外，更重要的是，这些去噪器与*评分函数* [[260](#bib.bib260)]有着强烈的理论联系，这一点将在第
    [8](#S8 "8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")-[9.2](#S9.SS2 "9.2
    High Perceptual Quality Solution to Inverse Problems ‣ 9 Discovery 3: High Perceptual
    Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –")节中突出并利用。'
- en: 2.3 Extensions of Image Denoising
  id: totrans-51
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 图像去噪的扩展
- en: 'There are many variations to the core image denoising task mentioned above.
    These can be roughly divided into four sub-categories: (i) Handling different
    noise statistics; (ii) Addressing structured noise removal; (iii) Considering
    different and various visual content; and (iv) Posing different problem assumptions
    and settings. Lets us briefly describe each of these.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 上述核心图像去噪任务有许多变体。这些变体可以大致分为四个子类别：(i) 处理不同的噪声统计；(ii) 解决结构化噪声去除；(iii) 考虑不同和各种视觉内容；以及
    (iv) 提出不同的问题假设和设置。我们简要描述每一类。
- en: A natural extension of the original denoising problem posed above is to consider
    other noise statistics, such as Poisson (also referred to as shot-noise) denoising [[93](#bib.bib93),
    [248](#bib.bib248), [100](#bib.bib100), [65](#bib.bib65), [325](#bib.bib325),
    [291](#bib.bib291), [233](#bib.bib233), [184](#bib.bib184), [226](#bib.bib226),
    [12](#bib.bib12)], salt-and-pepper noise removal [[40](#bib.bib40), [264](#bib.bib264),
    [75](#bib.bib75), [300](#bib.bib300), [210](#bib.bib210)], treating mixtures of
    Poisson and Gaussian noise [[176](#bib.bib176), [326](#bib.bib326), [184](#bib.bib184)],
    and more. Other extensions consider structured noise, such as quantization noise
    in compression artifact removal [[206](#bib.bib206), [176](#bib.bib176), [297](#bib.bib297),
    [63](#bib.bib63), [106](#bib.bib106)], film-grain removal [[312](#bib.bib312),
    [311](#bib.bib311), [62](#bib.bib62)], and textured or otherwise colored noise [[108](#bib.bib108),
    [193](#bib.bib193), [3](#bib.bib3), [219](#bib.bib219)]. Another challenging task
    is noise removal in scenarios in which the noise is not spatially homogeneous,
    such as white noise with spatially varying $\sigma$ [[187](#bib.bib187), [332](#bib.bib332),
    [344](#bib.bib344), [148](#bib.bib148)]. The inpainting problem [[90](#bib.bib90),
    [182](#bib.bib182), [306](#bib.bib306), [134](#bib.bib134)] can be regarded as
    a special such case, where portions of the image are simply missing and need to
    be revived. These missing pixels can be regarded as contaminated by a very strong
    noise, while other regions of the image are reliably measured.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 对上述原始去噪问题的自然扩展是考虑其他噪声统计，如泊松噪声（也称为 shot-noise）去噪[[93](#bib.bib93), [248](#bib.bib248),
    [100](#bib.bib100), [65](#bib.bib65), [325](#bib.bib325), [291](#bib.bib291),
    [233](#bib.bib233), [184](#bib.bib184), [226](#bib.bib226), [12](#bib.bib12)]，盐和胡椒噪声去除[[40](#bib.bib40),
    [264](#bib.bib264), [75](#bib.bib75), [300](#bib.bib300), [210](#bib.bib210)]，处理泊松噪声和高斯噪声的混合[[176](#bib.bib176),
    [326](#bib.bib326), [184](#bib.bib184)]，以及其他。其他扩展考虑结构化噪声，例如压缩伪影去除中的量化噪声[[206](#bib.bib206),
    [176](#bib.bib176), [297](#bib.bib297), [63](#bib.bib63), [106](#bib.bib106)]，胶卷颗粒去除[[312](#bib.bib312),
    [311](#bib.bib311), [62](#bib.bib62)]，以及纹理或其他彩色噪声[[108](#bib.bib108), [193](#bib.bib193),
    [3](#bib.bib3), [219](#bib.bib219)]。另一个具有挑战性的任务是在噪声在空间上不均匀的情况下进行去噪，例如空间上变化的白噪声$\sigma$[[187](#bib.bib187),
    [332](#bib.bib332), [344](#bib.bib344), [148](#bib.bib148)]。修补问题[[90](#bib.bib90),
    [182](#bib.bib182), [306](#bib.bib306), [134](#bib.bib134)]可以看作是这样一种特殊情况，其中图像的部分区域缺失，需要恢复。这些缺失的像素可以视为受到非常强噪声的污染，而图像的其他区域则被可靠测量。
- en: The denoising task may assume a different setting altogether if the visual content
    is of different form. Such an example is noise reduction in bursts of snapshots [[173](#bib.bib173),
    [102](#bib.bib102), [198](#bib.bib198), [189](#bib.bib189), [86](#bib.bib86),
    [166](#bib.bib166), [80](#bib.bib80)], where several images are treated jointly.
    Somewhat similar yet different is the task of video denoising [[179](#bib.bib179),
    [9](#bib.bib9), [10](#bib.bib10), [275](#bib.bib275), [276](#bib.bib276), [290](#bib.bib290),
    [259](#bib.bib259), [180](#bib.bib180), [322](#bib.bib322), [161](#bib.bib161)],
    in which we may seek online filtering of the incoming frames. When handling specific
    imaging types (e.g., microscopy [[223](#bib.bib223), [25](#bib.bib25), [13](#bib.bib13),
    [103](#bib.bib103), [340](#bib.bib340), [186](#bib.bib186), [158](#bib.bib158),
    [188](#bib.bib188)], CT [[164](#bib.bib164), [48](#bib.bib48), [318](#bib.bib318),
    [316](#bib.bib316), [70](#bib.bib70), [314](#bib.bib314)] and PET/SPECT imaging [[51](#bib.bib51),
    [82](#bib.bib82), [105](#bib.bib105), [227](#bib.bib227), [343](#bib.bib343),
    [266](#bib.bib266)], and more), the algorithm design may require adequate adaptations
    to the data format (e.g. treating 3D volumes [[294](#bib.bib294), [336](#bib.bib336),
    [324](#bib.bib324), [64](#bib.bib64), [178](#bib.bib178)]) or to the way it is
    captured.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 去噪任务可能会在视觉内容形式不同的情况下假设完全不同的设置。例如，快照中的噪声减少[[173](#bib.bib173), [102](#bib.bib102),
    [198](#bib.bib198), [189](#bib.bib189), [86](#bib.bib86), [166](#bib.bib166),
    [80](#bib.bib80)]，其中多个图像一起处理。类似但又不同的是视频去噪任务[[179](#bib.bib179), [9](#bib.bib9),
    [10](#bib.bib10), [275](#bib.bib275), [276](#bib.bib276), [290](#bib.bib290),
    [259](#bib.bib259), [180](#bib.bib180), [322](#bib.bib322), [161](#bib.bib161)]，在这种任务中，我们可能需要对输入的帧进行在线滤波。处理特定成像类型（如显微镜成像[[223](#bib.bib223),
    [25](#bib.bib25), [13](#bib.bib13), [103](#bib.bib103), [340](#bib.bib340), [186](#bib.bib186),
    [158](#bib.bib158), [188](#bib.bib188)]，CT成像[[164](#bib.bib164), [48](#bib.bib48),
    [318](#bib.bib318), [316](#bib.bib316), [70](#bib.bib70), [314](#bib.bib314)]和PET/SPECT成像[[51](#bib.bib51),
    [82](#bib.bib82), [105](#bib.bib105), [227](#bib.bib227), [343](#bib.bib343),
    [266](#bib.bib266)]等），算法设计可能需要对数据格式（如处理3D体积[[294](#bib.bib294), [336](#bib.bib336),
    [324](#bib.bib324), [64](#bib.bib64), [178](#bib.bib178)]）或捕获方式进行适当调整。
- en: The last category of extensions has to do with our prior knowledge when addressing
    denoising tasks. Blind denoising [[131](#bib.bib131), [169](#bib.bib169), [157](#bib.bib157),
    [47](#bib.bib47), [201](#bib.bib201), [256](#bib.bib256), [342](#bib.bib342),
    [321](#bib.bib321), [114](#bib.bib114)] refers to the case in which the noise
    is known to be i.i.d. Gaussian, but $\sigma$ is unknown, and may be even spatially
    changing. A more complex situation is when the noise statistics are totally unknown [[345](#bib.bib345),
    [8](#bib.bib8), [2](#bib.bib2), [307](#bib.bib307)]. In this context, a special
    case of great interest in recent years is removal of true noise from given images
    captured by digital cameras (e.g., cellphones) [[298](#bib.bib298), [149](#bib.bib149),
    [170](#bib.bib170), [285](#bib.bib285), [301](#bib.bib301), [128](#bib.bib128)].
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一类扩展涉及在处理去噪任务时我们先前的知识。盲去噪[[131](#bib.bib131), [169](#bib.bib169), [157](#bib.bib157),
    [47](#bib.bib47), [201](#bib.bib201), [256](#bib.bib256), [342](#bib.bib342),
    [321](#bib.bib321), [114](#bib.bib114)] 指的是噪声已知为独立同分布的高斯噪声，但$\sigma$未知，甚至可能是空间变化的。更复杂的情况是噪声统计完全未知[[345](#bib.bib345),
    [8](#bib.bib8), [2](#bib.bib2), [307](#bib.bib307)]。在这种情况下，近年来一个特别引人关注的情况是从数字相机（例如手机）拍摄的图像中去除真实噪声[[298](#bib.bib298),
    [149](#bib.bib149), [170](#bib.bib170), [285](#bib.bib285), [301](#bib.bib301),
    [128](#bib.bib128)]。
- en: 2.4 The Interest in Image Denoising
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4 图像去噪的兴趣
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2.4 The Interest in Image Denoising ‣ 2 Image
    Denoising – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") presents a graph showing the number of papers that have been
    published each year on the topic of image denoising. Overall, nearly $30,000$
    such papers are identified by Clarivate Web-Of-Science (WoS), published mostly
    in the past 25 years. As such, this is clearly one of the most heavily studied
    topics in image processing, and perhaps in exact sciences in general. Also evident
    from this graph is the consistent growth over the years in this topic. Where does
    this popularity come from?'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图[1](#S2.F1 "图 1 ‣ 2.4 图像去噪的兴趣 ‣ 2 图像去噪 – 背景 ‣ 图像去噪：深度学习革命及其超越 – 一项调查论文 –")
    展示了一张图表，显示了每年在图像去噪主题上发表的论文数量。总体而言，Clarivate Web-Of-Science (WoS) 识别出近$30,000$篇此类论文，主要发表在过去的25年中。因此，这显然是图像处理领域中研究最为深入的主题之一，也可能是精确科学中的一个重要话题。从这张图表中还可以明显看出，这一主题的持续增长趋势。这种受欢迎程度来自哪里？
- en: '![Refer to caption](img/041a2c93df50c403dc35a6de53d3da69.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/041a2c93df50c403dc35a6de53d3da69.png)'
- en: 'Figure 1: The number of papers on the image denoising topic over the years.
    This graph corresponds to the search topic=((image or video ) and (denoising or
    (noise and remov) or clean)) performed on December 1st 2022 in Clarivate Web-of-Science
    (WoS). Note that the lower count in 2022 does not stand for a new trend, but rather
    caused by a delayed reporting of new papers.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：图像去噪主题上的论文数量随时间的变化。这张图表对应于2022年12月1日在Clarivate Web-of-Science (WoS)上执行的搜索主题=((image
    or video ) and (denoising or (noise and remov) or clean))。请注意，2022年较低的数量并不代表一种新趋势，而是由于新论文报告的延迟所致。
- en: A prime reason to study image denoising is its practical relevance to imaging
    systems. Removal of noise from acquired visual information is an actual necessity
    that comes up with practically every imaging sensor [[191](#bib.bib191)]. Thus,
    various algorithms have been developed for implementation in image processing
    software packages and within the ISP (Image Signal Processor) – the path that
    starts with the raw acquired data and ends with a high quality image – of every
    digital camera [[23](#bib.bib23), [30](#bib.bib30), [298](#bib.bib298), [338](#bib.bib338),
    [124](#bib.bib124)].
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 研究图像去噪的主要原因在于其对成像系统的实际相关性。从获取的视觉信息中去除噪声是几乎每个成像传感器都会面临的实际需求[[191](#bib.bib191)]。因此，已经开发了各种算法用于图像处理软件包和ISP（图像信号处理器）中的实现——从原始采集数据开始，最终生成高质量图像——每台数码相机[[23](#bib.bib23),
    [30](#bib.bib30), [298](#bib.bib298), [338](#bib.bib338), [124](#bib.bib124)]。
- en: Beyond the obvious practical motivation described above, the interest in image
    denoising has other, more profound, roots. Image denoising is the simplest inverse
    problem, and as such, it has been recognized over the years as the perfect platform
    for assessing new ideas that are often brought to image processing. Indeed, all
    the major milestone advancements in image processing started with denoising experiments,
    so as to explore their validity to visual data. This was the case with Tikhonov-Arsenin’s
    regularization theory [[282](#bib.bib282), [104](#bib.bib104)], Wavelets [[185](#bib.bib185)],
    non–linear filtering based on partial differential equations [[302](#bib.bib302),
    [111](#bib.bib111)], sparse modeling of data [[31](#bib.bib31), [88](#bib.bib88)],
    and more. All these and many other sub-fields in imaging sciences saw image denoising
    as a critical first step in their diffusion into broad image processing tasks.
    We discuss these in greater details in the next section.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上面明显的实际动机之外，对图像去噪的兴趣还有其他更深刻的根源。图像去噪是最简单的反问题，因此多年来被认为是评估常常被引入图像处理的新想法的理想平台。事实上，图像处理中的所有主要里程碑性进展都始于去噪实验，以探索它们对视觉数据的有效性。提赫诺夫-阿尔赛宁的正则化理论就是这种情况[[282](#bib.bib282),
    [104](#bib.bib104)]，小波[[185](#bib.bib185)]，基于偏微分方程的非线性滤波[[302](#bib.bib302), [111](#bib.bib111)]，数据的稀疏建模[[31](#bib.bib31),
    [88](#bib.bib88)]等等。所有这些以及图像科学中的许多其他子领域都将图像去噪视为它们进入广泛图像处理任务的关键第一步。我们将在下一节更详细地讨论这些问题。
- en: The above two reasons for the popularity of image denoising may account for
    many of the published papers in this domain. However, the reason we have chosen
    to write this paper has to do with a third, and very different, origin of popularity.
    Image denoising has gained much interest and appeal in recent years due to the
    surprising realization that denoisers can serve other imaging needs, thus widening
    their scope and influence [[295](#bib.bib295), [231](#bib.bib231), [260](#bib.bib260),
    [120](#bib.bib120), [145](#bib.bib145)]. This discovery relies on a fundamental
    theoretical connection between denoisers and the prior distribution of images [[200](#bib.bib200),
    [265](#bib.bib265), [84](#bib.bib84)]. This bridge provides a solid and well-motivated
    approach to old and new tasks in image processing. In fact, this is the topic
    we shall be highlighting in the latter sections of our paper. We thus defer a
    more detailed explanation of these ideas.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 上述两个图像去噪受欢迎的原因可能解释了这一领域中许多已发表的论文。然而，我们选择撰写本文的原因与第三个，非常不同的受欢迎原因有关。近年来，图像去噪因意识到去噪器可以满足其他图像需求这一令人惊讶的发现而引起了广泛的兴趣和吸引力，从而扩大了它们的范围和影响[[295](#bib.bib295),
    [231](#bib.bib231), [260](#bib.bib260), [120](#bib.bib120), [145](#bib.bib145)]。这一发现依赖于图像的先验分布与去噪器之间的基础理论联系[[200](#bib.bib200),
    [265](#bib.bib265), [84](#bib.bib84)]。这一联系为图像处理中新旧任务提供了扎实而有动机的方法。事实上，这正是我们将在本文的后面部分重点突出讨论的主题。因此，我们将把对这些想法的更详细解释推迟到后面。
- en: 3 Image Denoising – The Classic Era
  id: totrans-63
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 图像去噪 - 经典时代
- en: So far we have discussed image denoisers without concretely diving into the
    actual quest of their construction. So, how can we design an image denoiser? Not
    so surprisingly, the answer to this question has evolved and changed over the
    years, with the accumulated knowledge and the progress in signal and image processing.
    And still, we may broadly separate this progress in design of image denoisers
    into two eras - the classical one that started in the 70’s and ended in the past
    decade, and the AI revolution era that started around 2012 and is very much vivid
    till this day. In this section we shall focus on the classical algorithms, and
    more specifically on the Bayesian point of view that played a key role in their
    creation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经讨论了图像去噪器，但并没有具体深入探讨它们构造的实际问题。那么，我们如何设计一个图像去噪器呢？出人意料的是，这个问题的答案随着积累的知识和信号处理和图像处理的进展而不断演变和改变。而且，我们可以广义地将图像去噪器的设计进展分为两个时代
    - 从70年代开始的经典时代，到过去十年结束的时期，以及从2012年左右开始且至今非常活跃的人工智能革命时代。在本节中，我们将重点讨论经典算法，特别是在它们的创建中起关键作用的贝叶斯观点。
- en: 3.1 The Bayesian Point of View for Design of Denoisers
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 设计去噪器的贝叶斯观点
- en: 'Starting with Equation ([1](#S2.E1 "Equation 1 ‣ 2.1 Problem Definition ‣ 2
    Image Denoising – Background ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –")), given the noisy image ${\mathbf{y}}$ and knowing
    that ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$, our goal
    is to estimate ${\mathbf{x}}$. A simple approach towards this task would be the
    Maximum-Likelihood Estimation (MLE) [[205](#bib.bib205), [235](#bib.bib235)],
    seeking $\hat{{\mathbf{x}}}$ that maximizes the conditional probability $p({\mathbf{y}}|{\mathbf{x}})$,
    essentially maximizing the likelihood of the given measurements ${\mathbf{y}}$.
    Due to the Gaussianity of the noise, this probability is given easily by'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 从方程 ([1](#S2.E1 "方程 1 ‣ 2.1 问题定义 ‣ 2 图像去噪 – 背景 ‣ 图像去噪：深度学习的革命及其未来 – 调查论文 –"))
    开始，给定有噪声的图像 ${\mathbf{y}}$ 并知道 ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$，我们的目标是估计
    ${\mathbf{x}}$。一种简单的方法是最大似然估计 (MLE) [[205](#bib.bib205), [235](#bib.bib235)]，寻求使条件概率
    $p({\mathbf{y}}|{\mathbf{x}})$ 最大化的 $\hat{{\mathbf{x}}}$，本质上是最大化给定测量 ${\mathbf{y}}$
    的似然。由于噪声的高斯性，这个概率很容易得到
- en: '| (4) |  | $\displaystyle p({\mathbf{y}}&#124;{\mathbf{x}})=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\},$
    |  |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $\displaystyle p({\mathbf{y}}&#124;{\mathbf{x}})=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\},$
    |  |'
- en: 'and maximizing it amounts to the trivial and fruitless solution: ${\hat{\mathbf{x}}}_{MLE}={\mathbf{y}}$.
    This outcome is a direct manifestation of the ill-posedness of the denoising problem,
    exposing the need for more information for its solution.'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最大化它等同于平凡且徒劳的解：${\hat{\mathbf{x}}}_{MLE}={\mathbf{y}}$。这一结果直接反映了去噪问题的不适定性，暴露了其解需要更多信息的需求。
- en: '| (5) |  | $\displaystyle p({\mathbf{x}}&#124;{\mathbf{y}})=\frac{p({\mathbf{y}}&#124;{\mathbf{x}})\cdot
    p({\mathbf{x}})}{p({\mathbf{y}})}=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\}\cdot
    p({\mathbf{x}}).$ |  |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| (5) |  | $\displaystyle p({\mathbf{x}}&#124;{\mathbf{y}})=\frac{p({\mathbf{y}}&#124;{\mathbf{x}})\cdot
    p({\mathbf{x}})}{p({\mathbf{y}})}=\operatorname*{const}\cdot\exp\left\{\frac{-\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}\right\}\cdot
    p({\mathbf{x}}).$ |  |'
- en: In the last equality we have absorbed the denominator $p({\mathbf{y}})$ into
    the constant as it is independent of ${\mathbf{x}}$. While this expression is
    a simple modification to the MLE (multiplying the likelihood by the prior $p({\mathbf{x}})$),
    this is in fact a significant change, as it regularizes the inversion process
    from ${\mathbf{y}}$ to ${\mathbf{x}}$.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在最后的等式中，我们将分母 $p({\mathbf{y}})$ 吸收到常数中，因为它与 ${\mathbf{x}}$ 无关。虽然这个表达式是对 MLE
    的简单修改（将似然乘以先验 $p({\mathbf{x}})$），但实际上这是一个重要的变化，因为它对从 ${\mathbf{y}}$ 到 ${\mathbf{x}}$
    的反演过程进行了正则化。
- en: Two commonly used estimators that exploit $p({\mathbf{x}}|{\mathbf{y}})$ are
    the MAP and the MMSE. The first is obtained by maximizing this posterior, leading
    to the Maximum A’Posteriori Probability (MAP) estimation [[205](#bib.bib205),
    [235](#bib.bib235)], given by⁴⁴4This minimization is obtained by taking the $-\log$
    of the above expression.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 两个常用的估计量利用了 $p({\mathbf{x}}|{\mathbf{y}})$，分别是 MAP 和 MMSE。第一个通过最大化这一后验得到，即最大后验概率
    (MAP) 估计 [[205](#bib.bib205), [235](#bib.bib235)]，由⁴⁴4此最小化通过对上述表达式取 $-\log$ 得到。
- en: '| (6) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
- en: As opposed to the MLE, ${\hat{\mathbf{x}}}_{MAP}$ is dictated by two forces,
    the first pulling it towards ${\mathbf{y}}$, while the other seeks a “well-behaved”
    result that leads to a low value of $-\log\left(p({\mathbf{x}})\right)$ – this
    is exactly the regularization mentioned above.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 与 MLE 相对的是，${\hat{\mathbf{x}}}_{MAP}$ 受两个力量的支配，第一个将其拉向 ${\mathbf{y}}$，而另一个则寻求一个“表现良好”的结果，从而导致
    $-\log\left(p({\mathbf{x}})\right)$ 的低值——这正是上述的正则化。
- en: 'Similarly, the MMSE estimation [[132](#bib.bib132)] is also reliant on the
    posterior probability obtained, as shown in Equation ([3](#S2.E3 "Equation 3 ‣
    2.1 Problem Definition ‣ 2 Image Denoising – Background ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –")), via⁵⁵5See Appendix
    [A](#A1 "Appendix A Derivation of the MMSE Estimation ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") for a derivation of this statement.'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '类似地，MMSE 估计 [[132](#bib.bib132)] 也依赖于获得的后验概率，如方程 ([3](#S2.E3 "Equation 3 ‣
    2.1 Problem Definition ‣ 2 Image Denoising – Background ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –")) 所示，通过⁵⁵5 参见附录 [A](#A1
    "Appendix A Derivation of the MMSE Estimation ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") 以推导此声明。'
- en: '| (7) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right)=\int_{\mathbf{x}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right)=\int_{\mathbf{x}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
- en: While this expression is very concise and clear, operating with it has proven
    to be quite challenging due to the need for the partition function – the normalizing
    factor of this distribution. This explains the vast popularity of the MAP-based
    approach among the classical methods.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管这个表达式非常简洁明了，但由于需要分区函数——该分布的标准化因子——其操作被证明相当具有挑战性。这也解释了为什么在经典方法中基于 MAP 的方法非常流行。
- en: Be it the MAP or the MMSE, the Bayesian point of view requires access to $p({\mathbf{x}})$
    or proxies of it. This brings us to the next discussion on the evolution of priors
    in image processing and their impact on the design of denoisers.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 无论是 MAP 还是 MMSE，贝叶斯观点都需要访问 $p({\mathbf{x}})$ 或其代理。这将我们引向下一个讨论，即图像处理中的先验演变及其对去噪器设计的影响。
- en: 3.2 Evolution of Priors
  id: totrans-78
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 先验的演变
- en: A key player in image processing is the prior, $p({\mathbf{x}})$, the probability
    density function of the image distribution. Modeling $p({\mathbf{x}})$ and using
    it for problems in visual data processing have served as the skeleton of our field,
    and defined its trajectory over the years. Below we outline the central milestones
    in the evolution of modeling $p({\mathbf{x}})$.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理中的一个关键角色是先验 $p({\mathbf{x}})$，即图像分布的概率密度函数。对 $p({\mathbf{x}})$ 的建模及其在视觉数据处理问题中的应用构成了我们领域的骨架，并定义了其多年来的发展轨迹。下面我们概述了建模
    $p({\mathbf{x}})$ 演变的核心里程碑。
- en: 'One critical theme to remember is the fact that the expression $-\log(p({\mathbf{x}}))$,
    which appears in the popular MAP estimation (see equation ([6](#S3.E6 "Equation
    6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers ‣ 3 Image Denoising
    – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –"))), should assume a closed-form expression so as to lend itself
    to a manageable numerical optimization. For this reason, most attempts to characterize
    $p({\mathbf{x}})$ have chosen to use the Gibbs distribution form [[132](#bib.bib132)],
    $p({\mathbf{x}})=c\cdot\exp\{-\rho({\mathbf{x}})\}$, shifting our focus from $p({\mathbf{x}})$
    to the energy function $\rho({\mathbf{x}})$.'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '需要记住的一个关键主题是，出现在流行的 MAP 估计中的表达式 $-\log(p({\mathbf{x}}))$（参见方程 ([6](#S3.E6 "Equation
    6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers ‣ 3 Image Denoising
    – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –")）），应假设为封闭形式，以便进行可管理的数值优化。因此，大多数尝试表征 $p({\mathbf{x}})$ 的方法选择使用
    Gibbs 分布形式 [[132](#bib.bib132)]，即 $p({\mathbf{x}})=c\cdot\exp\{-\rho({\mathbf{x}})\}$，将我们的重点从
    $p({\mathbf{x}})$ 转移到能量函数 $\rho({\mathbf{x}})$。'
- en: 'So, what should $\rho({\mathbf{x}})$ be to properly describe the image distribution?
    In order to keep this discussion concise, we present in Table [1](#S3.T1 "Table
    1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") a brief list of possible
    analytical expressions for this function, without diving into their meaning, inter-relations,
    and effect. A more detailed explanation of these expressions is provided in Appendix
    [B](#A2 "Appendix B A Closer Look at the Evolution of Priors ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). Please bear in mind
    the fact that this naïve approach of choosing an expression for $\rho({\mathbf{x}})$
    is nothing short of a fantastic feat – can we really expect a simple formula to
    grasp the richness of the image content distribution?'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '那么，$\rho({\mathbf{x}})$ 应该是什么才能准确描述图像分布？为了简洁讨论，我们在表 [1](#S3.T1 "Table 1 ‣ 3.2
    Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –") 中展示了这个函数的可能分析表达式的简要列表，而不深入探讨它们的含义、相互关系和效果。这些表达式的详细解释见附录
    [B](#A2 "Appendix B A Closer Look at the Evolution of Priors ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")。请记住，选择 $\rho({\mathbf{x}})$
    的表达式这一幼稚的方法绝非一项简单的任务——我们真的可以期望一个简单的公式来把握图像内容分布的丰富性吗？'
- en: 'The evolution of the ideas in Table [1](#S3.T1 "Table 1 ‣ 3.2 Evolution of
    Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") is characterized by several major and
    interconnected trends – the migration from the familiar Gaussian distribution
    to the less intuitive heavy-tailed ones, the departure from $L_{2}$ to sparsity-promoting
    measures such as the $L_{1}$, the drift from linear approximation techniques (e.g.
    PCA) to non-linear ones (e.g. wavelets and sparse modeling), and above all, the
    replacement of axiomatic expressions with learned priors.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [1](#S3.T1 "Table 1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic
    Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper
    –") 中的思想演变特点是几个主要且相互关联的趋势——从熟悉的高斯分布迁移到不太直观的重尾分布，从 $L_{2}$ 离开到诸如 $L_{1}$ 的稀疏促进度量，从线性近似技术（例如
    PCA）漂移到非线性技术（例如小波和稀疏建模），最重要的是，用学习到的先验替代公理表达。'
- en: 'Table 1: Evolution of priors for images.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '表 1: 图像先验的演变。'
- en: '| Years | Core concept | Formulae for $\rho(\cdot)$ |'
  id: totrans-84
  prefs: []
  type: TYPE_TB
  zh: '| 年份 | 核心概念 | $\rho(\cdot)$ 的公式 |'
- en: '| --- | --- | --- |'
  id: totrans-85
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| $\sim$ 1970 | Energy regularization | $\&#124;{\mathbf{x}}\&#124;_{2}^{2}$
    |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| $\sim$ 1970 | 能量正则化 | $\&#124;{\mathbf{x}}\&#124;_{2}^{2}$ |'
- en: '| 1975-1985 | Spatial smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{2}^{2}$
    or $\&#124;{\mathbf{D}}_{v}{\mathbf{x}}\&#124;_{2}^{2}+\&#124;{\mathbf{D}}_{h}{\mathbf{x}}\&#124;_{2}^{2}$
    |'
  id: totrans-87
  prefs: []
  type: TYPE_TB
  zh: '| 1975-1985 | 空间平滑度 | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{2}^{2}$ 或 $\&#124;{\mathbf{D}}_{v}{\mathbf{x}}\&#124;_{2}^{2}+\&#124;{\mathbf{D}}_{h}{\mathbf{x}}\&#124;_{2}^{2}$
    |'
- en: '| 1980-1985 | Optimally Learned Transform | $\&#124;{\mathbf{T}}{\mathbf{x}}\&#124;_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    (via PCA) |'
  id: totrans-88
  prefs: []
  type: TYPE_TB
  zh: '| 1980-1985 | 最优学习变换 | $\&#124;{\mathbf{T}}{\mathbf{x}}\&#124;_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$（通过
    PCA） |'
- en: '| 1980-1990 | Weighted smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{{\mathbf{W}}}^{2}$
    |'
  id: totrans-89
  prefs: []
  type: TYPE_TB
  zh: '| 1980-1990 | 加权平滑度 | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{{\mathbf{W}}}^{2}$
    |'
- en: '| 1990-2000 | Robust statistics | ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    e.g., Hubber-Markov |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 1990-2000 | 鲁棒统计 | ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$ 例如，Hubber-Markov
    |'
- en: '| 1992-2005 | Total-Variation | $\int_{v\in\Omega}&#124;\nabla{\mathbf{x}}(v)&#124;dv={\mathbf{1}}^{T}\sqrt{&#124;{\mathbf{D}}_{v}{\mathbf{x}}&#124;^{2}+&#124;{\mathbf{D}}_{h}{\mathbf{x}}&#124;^{2}}$
    |'
  id: totrans-91
  prefs: []
  type: TYPE_TB
  zh: '| 1992-2005 | 总变差 | $\int_{v\in\Omega}&#124;\nabla{\mathbf{x}}(v)&#124;dv={\mathbf{1}}^{T}\sqrt{&#124;{\mathbf{D}}_{v}{\mathbf{x}}&#124;^{2}+&#124;{\mathbf{D}}_{h}{\mathbf{x}}&#124;^{2}}$
    |'
- en: '| 1987-2005 | Other PDE-based options | $\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    |'
  id: totrans-92
  prefs: []
  type: TYPE_TB
  zh: '| 1987-2005 | 其他基于PDE的选项 | $\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    |'
- en: '| 2005-2009 | Field-of-Experts | $\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$
    |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 2005-2009 | 专家领域 | $\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$
    |'
- en: '| 1993-2005 | Wavelet sparsity | $\&#124;{\mathbf{W}}{\mathbf{x}}\&#124;_{1}$
    |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 1993-2005 | 小波稀疏性 | $\&#124;{\mathbf{W}}{\mathbf{x}}\&#124;_{1}$ |'
- en: '| 2000-2010 | Self-similarity | $\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\}$
    |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 2000-2010 | 自相似性 | $\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\}$
    |'
- en: '| 2002-2012 | Sparsity methods | $\&#124;\alpha\&#124;_{0}~{}s.t.~{}{\mathbf{x}}={\mathbf{D}}\alpha$
    |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 2002-2012 | 稀疏性方法 | $\&#124;\alpha\&#124;_{0}~{}s.t.~{}{\mathbf{x}}={\mathbf{D}}\alpha$
    |'
- en: '| 2010-2017 | Low-Rank assumption | $\sum_{k}\&#124;{\mathbf{X}}_{\Omega(k)}\&#124;_{*}$
    |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 2010-2017 | 低秩假设 | $\sum_{k}\&#124;{\mathbf{X}}_{\Omega(k)}\&#124;_{*}$ |'
- en: 3.3 Other Classical Denoisers
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 其他经典去噪方法
- en: While the above-described Bayesian approach has proven to be quite productive,
    yielding a wide variety of denoising methods, alternative and more direct design
    techniques for such algorithms were also considered. Here we mention few such
    methods, some relying on the general notion of spatially adaptive smoothing of
    image content, while others leverage self-similarity that often-times exists in
    images.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述描述的贝叶斯方法已经证明相当有效，产生了多种去噪方法，但对于这类算法也考虑了替代性和更直接的设计技术。在这里，我们提到几种这样的方法，有些方法依赖于图像内容的空间自适应平滑的普遍概念，而其他方法则利用图像中常常存在的自相似性。
- en: 'Consider the following rough motivating idea: Recall that a denoiser should
    attenuate random i.i.d. Gaussian noise while preserving the image content. When
    operating on a noisy pixel $y[i,j]$, our intuitive strategy is to open a neighborhood
    around it, $\Omega[i,j]$, for averaging purposes. If it so happens that the local
    image content in $\Omega[i,j]$ behaves like a tilted plane, a simple averaging
    of these neighborhood pixels would provide a perfect local noise suppression.
    When the local behavior deviates from this simple structure, the averaging mask
    should take this into account and adapt accordingly.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑以下粗略的激励想法：回忆一下，去噪器应当在保持图像内容的同时减弱随机独立同分布的高斯噪声。当在一个嘈杂像素 $y[i,j]$ 上操作时，我们的直观策略是围绕它打开一个邻域
    $\Omega[i,j]$，以进行平均。如果 $\Omega[i,j]$ 中的局部图像内容像一个倾斜的平面，则简单地对这些邻域像素进行平均可以提供完美的局部噪声抑制。当局部行为偏离这种简单结构时，平均掩模应考虑这一点并做出相应的调整。
- en: This is exactly the idea behind the Bilateral filter [[284](#bib.bib284), [87](#bib.bib87)]
    and the Beltrami-Flow [[255](#bib.bib255)], in which the averaging weight takes
    into account two forces – (i) the proximity of the weighted pixel to the center
    of the neighborhood; and (ii) the proximity of this pixel’s value to the center
    pixel’s value, indicating its relevance to the averaging. Computing these weights
    for each pixel $y[i,j]$ and normalizing them to sum to one creates the local averaging
    kernel to apply. This way, if $\Omega[i,j]$ covers an edge between two regions,
    averaging will be restricted to the “relevant” pixels while discarding others.
    Non-Local-Means [[32](#bib.bib32)] takes this approach one step further by widening
    $\Omega[i,j]$ to a semi-local region, and by assessing pixels’ relevance to the
    averaging by patch-matching instead of scalar value comparisons. This way we keep
    the spatially adaptive averaging concept, but robustify it and make it non-local.
    Kernel-regression [[271](#bib.bib271)] is also a spatially adaptive averaging
    technique, but one that relies on a local parametric estimation of the pixels’
    gray-values in $\Omega[i,j]$. A 2D Gaussian is fitted to the pixels in $\Omega[i,j]$,
    dictating its orientation and span, and this way offering a smoothing along edges
    instead of across ones.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是双边滤波器[[284](#bib.bib284), [87](#bib.bib87)]和贝尔特拉米流[[255](#bib.bib255)]背后的思想，其中平均权重考虑了两个因素——（i）加权像素到邻域中心的距离；以及（ii）该像素的值与中心像素值的接近程度，表明它对平均的相关性。为每个像素
    $y[i,j]$ 计算这些权重，并将它们归一化使其总和为一，创建了用于应用的局部平均核。这样，如果 $\Omega[i,j]$ 涵盖了两个区域之间的边缘，则平均将限制在“相关”像素上，同时丢弃其他像素。非局部均值[[32](#bib.bib32)]将这种方法更进一步，通过将
    $\Omega[i,j]$ 扩展到半局部区域，并通过块匹配而非标量值比较来评估像素对平均的相关性。这样，我们保留了空间自适应平均的概念，但使其更具鲁棒性，并使其成为非局部的。核回归[[271](#bib.bib271)]也是一种空间自适应平均技术，但依赖于
    $\Omega[i,j]$ 中像素灰度值的局部参数估计。一个二维高斯分布被拟合到 $\Omega[i,j]$ 中的像素，决定了其方向和跨度，从而沿边缘而非跨边缘进行平滑。
- en: Another direct image denoising method that deserves our specific attention,
    especially due to its superior performance, is the BM3D algorithm [[61](#bib.bib61)].
    This technique relies on the expectation that 2D-DCT transformed local patches
    in natural images are expected to be sparse. Furthermore, by gathering groups
    of similar patches from the overall image area, this transformed sparsity should
    align in support. Thus, BM3D builds a 3D cube of similar patches for each pixel
    $y[i,j]$, transforms this cube together and forces a joint sparsity outcome. Among
    the classical denoising algorithms, BM3D is considered among the very best approaches
    in terms of MSE results. In this context, we also mention the Weighted Nuclear
    Norm Minimization (WNNM) denoising method [[110](#bib.bib110)] and its followups
    (e.g. [[310](#bib.bib310)]). These rely on a similar rationale to the BM3D, but
    replace the joint sparsity by a low-rank assumption.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个值得我们特别关注的直接图像去噪声方法，特别是由于其卓越的性能，是BM3D算法[[61](#bib.bib61)]。该技术依赖于对自然图像中2D-DCT变换后的局部块的稀疏性期望。此外，通过从整个图像区域收集类似的块，这种变换后的稀疏性应对齐于支持中。因此，BM3D为每个像素$y[i,j]$构建一个类似块的3D立方体，统一变换该立方体并强制产生联合稀疏结果。在经典的去噪声算法中，BM3D被认为是MSE结果方面最好的方法之一。在这种背景下，我们还提到加权核范数最小化（WNNM）去噪声方法[[110](#bib.bib110)]及其后续研究（例如[[310](#bib.bib310)]）。这些方法依赖于与BM3D类似的原理，但将联合稀疏性替换为低秩假设。
- en: 3.4 Is denoising dead?
  id: totrans-103
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 去噪声死了吗？
- en: The paper “Is Denoising Dead?”, published in 2009 by Chatterjee and Milanfar [[45](#bib.bib45)],
    exposed a disturbing feeling shared by many in our community at the time – a suspicion
    that we are touching the ceiling in terms of denoising ability. This impression
    relied on the considerable progress in design of denoising algorithms during the
    preceding years, and the fact that very different approaches towards this problem
    were found to lead to comparable denoising performance. A followup work [[162](#bib.bib162),
    [163](#bib.bib163)] by Levin and Nadler in 2011-2012 addressed the same question.
    Both lines of work suggested a derivation of an approximated lower-bound of the
    MSE for noise removal ability. Without diving into the specifics of their derivations,
    we should mention that both concluded that there is still room for some improvement,
    even though this claim was not made constructively, leaving the question of how
    to obtain better techniques vague at best.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 论文《去噪声死了吗？》，由Chatterjee和Milanfar于2009年发表[[45](#bib.bib45)]，揭示了当时我们社区中许多人共同的担忧——怀疑我们在去噪声能力方面已触及上限。这种印象依赖于前几年去噪声算法设计的显著进展，以及发现对这个问题的不同方法往往能达到相似的去噪声效果。Levin和Nadler于2011-2012年的后续研究[[162](#bib.bib162),
    [163](#bib.bib163)]也探讨了同样的问题。这两方面的研究均建议推导噪声去除能力的MSE近似下界。在不深入讨论其推导细节的情况下，我们应该提到两者都得出结论，尽管这一说法并未被建设性地提出，但仍有一些改进空间，使得如何获得更好技术的问题仍然模糊不清。
- en: 'From a practical point of view, and despite these optimistic conclusions, the
    progress in denoising performance after 2010-2011 was very slow and of diminishing
    returns. Indeed, the graph in Figure [1](#S2.F1 "Figure 1 ‣ 2.4 The Interest in
    Image Denoising ‣ 2 Image Denoising – Background ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") shows a decrease in the number of papers
    on image denoising around 2010\. However, this setback held true mostly for classically
    oriented methods of the kind discussed above. The emergence of deep neural networks
    brought a massive change to our domain, shattering the common belief about the
    end of this field, and the folklore around the attained performance limit.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: '从实际角度来看，尽管这些乐观结论，2010-2011年后的去噪声性能进展非常缓慢，且回报递减。实际上，图[1](#S2.F1 "Figure 1 ‣
    2.4 The Interest in Image Denoising ‣ 2 Image Denoising – Background ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")中的图表显示了2010年左右图像去噪声论文数量的减少。然而，这一挫折主要适用于上述讨论的经典方法。深度神经网络的出现给我们领域带来了巨大的变化，打破了关于这一领域结束的普遍信念，以及关于已达到性能极限的民间传说。'
- en: Indeed, deep learning brought new ways for the design of highly effective image
    denoisers, taking the lead in today’s ability for noise suppression in images.
    However, the AI revolution had a much wider impact on the image denoising task,
    opening new horizons to possibilities and abilities never dealt with before. Among
    many such directions, these include (i) image adaptation; (ii) true noise removal;
    and (iii) addressing new denoising objectives. In the following section we discuss
    all these with much greater details.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 确实，深度学习为设计高效的图像去噪器带来了新的方法，领先于今天图像噪声抑制的能力。然而，AI革命对图像去噪任务产生了更广泛的影响，开启了前所未有的可能性和能力的新视野。在众多方向中，这些包括（i）图像适应；（ii）真实噪声去除；以及（iii）应对新的去噪目标。在接下来的章节中，我们将更详细地讨论这些内容。
- en: 'While the past decade can certainly be titled as the era of AI revolution,
    there has been another revolution, perhaps of a bigger scale, that took place
    in parallel in the field of image processing – one that refers to the discovery
    that an image denoiser can serve other tasks. From the seminal paper on the Plug-and-Play
    Priors [[295](#bib.bib295)], through Regularization by Denoising paper [[231](#bib.bib231)],
    and all the way to the recent and exciting diffusion-based image synthesis [[260](#bib.bib260),
    [120](#bib.bib120)], image denoisers are taking a new and much more exciting role
    in image processing. As this is the main theme of this paper, We shall expand
    on this line of work in Section [6](#S6 "6 Image Denoising – Migration towards
    Recent Discoveries ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") and after.'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然过去十年无疑可以被称为AI革命的时代，但在图像处理领域还有另一场革命，也许规模更大，并且与之平行进行——即发现图像去噪器可以服务于其他任务。从开创性的《Plug-and-Play
    Priors》[[295](#bib.bib295)]论文，到《Regularization by Denoising》论文[[231](#bib.bib231)]，以及最近令人兴奋的基于扩散的图像合成[[260](#bib.bib260),
    [120](#bib.bib120)]，图像去噪器在图像处理中的角色变得更加新颖和激动人心。由于这是本文的主要主题，我们将在第[6](#S6 "6 Image
    Denoising – Migration towards Recent Discoveries ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")节及之后的部分详细展开这一工作方向。'
- en: So, to summarize, for the question ‘is denoising dead?’ our answer is ‘definitely
    not!’, and this is due to the vast influence of deep learning, and other new directions
    that brought new life to this domain. The rest of this paper is dedicated to the
    description of these developments and their impact and prospects.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，总结一下，对于“去噪是否已经过时？”这一问题，我们的回答是“绝对没有！”，这归功于深度学习的巨大影响以及其他新方向为这一领域带来的新生命。本文其余部分将专门描述这些发展及其影响和前景。
- en: 4 Image Denoising – The Deep Learning Revolution
  id: totrans-109
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 图像去噪——深度学习革命
- en: The recently discovered ability to effectively train deep neural networks for
    classification, regression and other tasks should not be taken lightly. Nothing
    in this process is well-understood or well-justified. Indeed, the opposite is
    true – with overparametrized networks and a highly non-convex objective function,
    it is quite surprising that such networks are able to learn and generalize at
    all. And yet they do! This is the essence of the AI revolution that has found
    its way to so many fields, impacting each in a profound way.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 最近发现的有效训练深度神经网络进行分类、回归和其他任务的能力不容小觑。这一过程中的任何环节都不够被理解或合理化。事实上，情况正好相反——由于网络的过度参数化和高度非凸的目标函数，这样的网络竟然能够学习和泛化，确实令人惊讶。然而，它们做到了！这正是AI革命的本质，它已经进入了许多领域，并以深远的方式影响着每个领域。
- en: Image processing and computational imaging is yet another playground that has
    been deeply influenced by this AI revolution. Today’s practice and theory in image
    processing is entirely different from the ones considered only 10 years ago. Indeed,
    image processing undergraduate and graduate courses had to change dramatically
    due to these new winds of change.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 图像处理和计算成像是另一个深受AI革命影响的领域。今天的图像处理实践和理论与仅仅10年前所考虑的完全不同。确实，由于这些新的变革，图像处理的本科生和研究生课程也不得不发生了剧变。
- en: 'And all this brings us to the new era of image denoising. In Section [3](#S3
    "3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") we asked how should image denoisers be designed,
    and gave an answer that relies on the classical Bayesian approach. We now return
    to this question, and provide an entirely different answer – one that builds on
    supervised deep-learning. This approach takes the following steps:'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '所有这些将我们带入了图像去噪的新纪元。在第 [3](#S3 "3 Image Denoising – The Classic Era ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") 节中，我们探讨了如何设计图像去噪器，并给出了依赖于经典贝叶斯方法的答案。现在我们回到这个问题，提供一个完全不同的答案——一个基于监督深度学习的方法。该方法包括以下步骤：'
- en: '1.'
  id: totrans-113
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: Start by gathering a large⁶⁶6By ‘large’ we mean thousands and sometimes millions
    of images, and the more the better. Often-times, the training itself may rely
    on several hundreds of images, and these are augmented by randomized operations
    such as crop, scale-down, rotations, and more. dataset of clean images of diverse
    content - the kind of which we aim to denoise. We shall denote this set as ${\cal
    X}=\{{\mathbf{x}}_{k}\}_{k=1}^{M}$. For simplicity assume that all images are
    of the same size. If this is not the case, an easy process of random tile extraction
    may convert the given data to this desired structure.
  id: totrans-114
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开始时，收集一个大规模的干净图像数据集——我们所期望去噪的图像种类。我们将这个集合表示为 ${\cal X}=\{{\mathbf{x}}_{k}\}_{k=1}^{M}$。为简单起见，假设所有图像的大小相同。如果不是这种情况，可以通过随机切片提取过程将给定数据转换为这种所需的结构。
- en: '2.'
  id: totrans-115
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Recall that our goal is a design of a denoiser that removes additive white Gaussian
    noise of a specific strength $\sigma$. Thus, the next step is to create noisy
    instances of ${\cal X}$, i.e. ${\cal Y}=\{{\mathbf{y}}_{k}\}_{k=1}^{M}$, where
    for $1\leq k\leq M,~{}{\mathbf{y}}_{k}={\mathbf{x}}_{k}+{\mathbf{v}}_{k}$ and
    ${\mathbf{v}}_{k}\sim{\cal N}(0,\sigma^{2}{\mathbf{I}})$. In fact, every example
    ${\mathbf{x}}_{k}$ could be contaminated by several noise realizations, this way
    enriching the training set.
  id: totrans-116
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 请记住，我们的目标是设计一个去噪器，以去除特定强度 $\sigma$ 的加性白噪声。因此，下一步是创建 ${\cal X}$ 的噪声实例，即 ${\cal
    Y}=\{{\mathbf{y}}_{k}\}_{k=1}^{M}$，其中对于 $1\leq k\leq M,~{}{\mathbf{y}}_{k}={\mathbf{x}}_{k}+{\mathbf{v}}_{k}$
    且 ${\mathbf{v}}_{k}\sim{\cal N}(0,\sigma^{2}{\mathbf{I}})$。实际上，每个示例 ${\mathbf{x}}_{k}$
    可能会被几个噪声实现污染，从而丰富训练集。
- en: '3.'
  id: totrans-117
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Define a parametric denoising architecture ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$
    that should be trained to perform the denoising task. This stage is necessarily
    vague as there are many options for constructing such an architecture, and there
    seems to be no clear guidelines for its structure. Indeed, the literature offers
    various such options conceived by trial-and-error, e.g.. More details and a discussion
    on this delicate stage is given below.
  id: totrans-118
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义一个参数化去噪架构 ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$，该架构应进行训练以执行去噪任务。这个阶段必然模糊，因为构建这样的架构有很多选择，并且似乎没有明确的结构指南。确实，文献提供了各种通过试错法构思的选项，例如。以下是关于这一微妙阶段的更多细节和讨论。
- en: '4.'
  id: totrans-119
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Define the training loss – a penalty function that exploits the availability
    of ${\cal X}$ and ${\cal Y}$ and the defined parametric denoiser $D_{\Theta}({\mathbf{y}},\sigma)$,
    posing a cost value to be minimized with respect to $\Theta$, encouraging the
    denoised images to be close to their corresponding ideal ones. Such a functional
    could be of the form
  id: totrans-120
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 定义训练损失——一个利用 ${\cal X}$ 和 ${\cal Y}$ 以及定义的参数化去噪器 $D_{\Theta}({\mathbf{y}},\sigma)$
    的惩罚函数，设定一个需要最小化的成本值，以鼓励去噪图像接近其对应的理想图像。这样的函数形式可以是
- en: '| (8) |  | $\displaystyle{\cal L}(\Theta)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},{\hat{\mathbf{x}}}_{k}\right)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k},\sigma)\right),$
    |  |'
  id: totrans-121
  prefs:
  - PREF_IND
  type: TYPE_TB
  zh: '| (8) |  | $\displaystyle{\cal L}(\Theta)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},{\hat{\mathbf{x}}}_{k}\right)=\sum_{k=1}^{M}\operatorname*{dist}\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k},\sigma)\right),$
    |  |'
- en: where $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})$ is a distance
    function between the ideal and the denoised image, such as MSE – $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})=\|{\mathbf{x}}-{\hat{\mathbf{x}}}\|_{2}^{2}$.
  id: totrans-122
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其中 $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})$ 是理想图像与去噪图像之间的距离函数，如
    MSE – $\operatorname*{dist}({\mathbf{x}},{\hat{\mathbf{x}}})=\|{\mathbf{x}}-{\hat{\mathbf{x}}}\|_{2}^{2}$。
- en: '5.'
  id: totrans-123
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Minimize ${\cal L}(\Theta)$ with respect to $\Theta$ via stochastic gradient
    descent [[24](#bib.bib24)] applied on small batches of training pairs $({\mathbf{x}}_{k},{\mathbf{y}}_{k})$,
    and exploiting back-propagation [[242](#bib.bib242)].
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过在小批量训练对$({\mathbf{x}}_{k},{\mathbf{y}}_{k})$上应用随机梯度下降法 [[24](#bib.bib24)]，并利用反向传播 [[242](#bib.bib242)]，来最小化${\cal
    L}(\Theta)$相对于$\Theta$的值。
- en: Once all the above steps are completed, the denoiser ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$
    is ready to be deployed on newly incoming images, expected to perform better or
    worse in noise removal, depending on the size and quality of the training set,
    the similarity between the image to be denoised and the training set, the chosen
    architecture, and the quality and the hyperparameters of the optimization process.
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦完成所有上述步骤，去噪器${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$就可以部署到新来的图像上，去噪效果可能会因训练集的大小和质量、待去噪图像与训练集之间的相似性、选择的架构以及优化过程的质量和超参数而有所不同。
- en: A variant of the above is blind denoising, in which $\sigma$ is unknown. The
    straightforward approach towards this task is brute-force learning. This means
    that for every ideal image ${\mathbf{x}}$ we produce a sequence of noisy versions
    ${\mathbf{y}}_{k}^{\sigma}$ with varying values of $\sigma$ in the range we aim
    to cover. Then learning is done by minimizing a loss that integrates over all
    the noise levels,
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 上述的一种变体是盲去噪，其中$\sigma$是未知的。处理这个任务的直接方法是暴力学习。这意味着对于每一个理想图像${\mathbf{x}}$，我们生成一系列噪声版本${\mathbf{y}}_{k}^{\sigma}$，其$\sigma$值在我们目标覆盖的范围内变化。然后，通过最小化一个对所有噪声水平进行积分的损失来完成学习。
- en: '| (9) |  | $\displaystyle{\cal L}(\Theta)=\int_{\sigma}\sum_{k=1}^{M}dist\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k}^{\sigma})\right).$
    |  |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| (9) |  | $\displaystyle{\cal L}(\Theta)=\int_{\sigma}\sum_{k=1}^{M}dist\left({\mathbf{x}}_{k},D_{\Theta}({\mathbf{y}}_{k}^{\sigma})\right).$
    |  |'
- en: Observe that in this case the denoiser $D_{\Theta}$ gets only the noisy image
    without $\sigma$. An interesting alternative to the above was discovered in [[201](#bib.bib201)],
    showing that a bias-free architecture becomes robust to the noise power, and thus
    a simple training for a single value of $\sigma$ generalizes well to other levels
    of noise.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这种情况下，去噪器$D_{\Theta}$仅接收带噪图像而没有$\sigma$。在[[201](#bib.bib201)]中发现了一个有趣的替代方案，表明无偏架构对噪声功率具有鲁棒性，因此仅针对单一值$\sigma$的简单训练能够很好地推广到其他噪声水平。
- en: 'An amazing consequence of all the above description is this: All the glorious
    work on image priors that fueled the design of classical denoisers and other tools
    in image processing seem to have become totally obsolete. Observe that in this
    supervised deep learning approach we have no need nor room for all the knowledge
    and know-how that have been accumulated carefully over decades of extensive research
    and engineering work. Is this a fair description of the current state of things
    in our field? To a large extent, the sad answer is positive, while some reservations
    to this conclusive statement will be discussed in Section [5](#S5 "5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –").'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: '上述描述的一个惊人后果是：所有对图像先验的辉煌研究，这些研究推动了经典去噪器和其他图像处理工具的设计，似乎已经变得完全过时。请注意，在这种监督式深度学习方法中，我们不需要也没有空间来容纳那些在几十年的广泛研究和工程工作中积累的所有知识和技术。这是否是我们领域当前状况的公正描述？在很大程度上，令人遗憾的答案是肯定的，而对这一结论的某些保留意见将在第[5](#S5
    "5 Synergy between Classics and Deep Learning ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")节中讨论。'
- en: 'The emergence of deep learning techniques and their new abilities brought a
    new evolution of ideas on the design and span of image denoisers. While this literature
    is vast and rich, we describe below several key trends in this progress, in an
    attempt to expose both the new abilities obtained, and the new ideas accompanying
    them. These come in several fronts:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术及其新能力的出现带来了图像去噪器设计和范围的新进展。虽然相关文献丰富而广泛，但我们在下文中描述了几个关键趋势，试图揭示获得的新能力以及伴随而来的新思想。这些新趋势体现在多个方面：
- en: •
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Better Denoisers: Improving image denoising capabilities via deep learning
    became a natural new front, where the aim is to perform better in terms of Peak-Signal-to-Noise-Ratio
    (PSNR) on an agreed-upon corpus of test images. This is manifested by an evolution
    of architectures that started with simple feed-forward Convolutional Neural Networks
    (CNN) [[330](#bib.bib330)], proceeded to more advanced structures, such as UNet [[234](#bib.bib234),
    [115](#bib.bib115)], and all the way to the recently introduced Transformers [[78](#bib.bib78),
    [165](#bib.bib165), [322](#bib.bib322)]. In Figure [2](#S4.F2 "Figure 2 ‣ 1st
    item ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –") we illustrate this trend
    by presenting a graph that shows the progress in denoising PSNR on the well-known
    BSD68 dataset [[190](#bib.bib190)]. More details on each of these algorithms is
    brought in Appendix [C](#A3 "Appendix C Landmark Denoisers over the Years ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –").'
  id: totrans-132
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '更好的去噪器：通过深度学习提高图像去噪能力已成为一个自然的新领域，其目标是在达成一致的测试图像语料库上取得更好的峰值信噪比（PSNR）。这体现在从简单的前馈卷积神经网络（CNN） [[330](#bib.bib330)]
    到更高级的结构，如 UNet [[234](#bib.bib234), [115](#bib.bib115)]，再到最近引入的 Transformers [[78](#bib.bib78),
    [165](#bib.bib165), [322](#bib.bib322)] 的架构演变中。在图 [2](#S4.F2 "Figure 2 ‣ 1st item
    ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") 中，我们通过呈现一张图表来展示这一趋势，显示了在著名的
    BSD68 数据集 [[190](#bib.bib190)] 上去噪 PSNR 的进展。有关这些算法的更多详细信息见附录 [C](#A3 "Appendix
    C Landmark Denoisers over the Years ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")。'
- en: '![Refer to caption](img/eb2047745559668001bb72ccfe6de17e.png)'
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_IMG
  zh: '![请参阅说明](img/eb2047745559668001bb72ccfe6de17e.png)'
- en: 'Figure 2: Denoising performance on the BSD68 dataset [[190](#bib.bib190)] with
    $\sigma=25$ (K-SVD [[89](#bib.bib89)], BM3D [[61](#bib.bib61)], FoE [[237](#bib.bib237)],
    LSSC [[181](#bib.bib181)], EPLL [[347](#bib.bib347)], MLP [[33](#bib.bib33)],
    CSF [[252](#bib.bib252)], WNNM [[110](#bib.bib110)], TNRD [[50](#bib.bib50)],
    DnCNN [[330](#bib.bib330)], IRCNN [[331](#bib.bib331)], NLRN [[167](#bib.bib167)],
    MVCNN [[168](#bib.bib168)], N3Net [[218](#bib.bib218)], FFDNet [[332](#bib.bib332)],
    FOCNet [[133](#bib.bib133)], RIDNet [[8](#bib.bib8)], GCDN [[292](#bib.bib292)],
    SwinIR [[165](#bib.bib165)], DRUNet [[329](#bib.bib329)]).'
  id: totrans-134
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图 2：在 BSD68 数据集 [[190](#bib.bib190)] 上的去噪性能，$\sigma=25$（K-SVD [[89](#bib.bib89)]、BM3D [[61](#bib.bib61)]、FoE [[237](#bib.bib237)]、LSSC [[181](#bib.bib181)]、EPLL [[347](#bib.bib347)]、MLP [[33](#bib.bib33)]、CSF [[252](#bib.bib252)]、WNNM [[110](#bib.bib110)]、TNRD [[50](#bib.bib50)]、DnCNN [[330](#bib.bib330)]、IRCNN [[331](#bib.bib331)]、NLRN [[167](#bib.bib167)]、MVCNN [[168](#bib.bib168)]、N3Net [[218](#bib.bib218)]、FFDNet [[332](#bib.bib332)]、FOCNet [[133](#bib.bib133)]、RIDNet [[8](#bib.bib8)]、GCDN [[292](#bib.bib292)]、SwinIR [[165](#bib.bib165)]、DRUNet [[329](#bib.bib329)])。
- en: •
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Different Training Schemes: We described above the most obvious, supervised,
    training strategy, where we gather pairs of ideal images and their noisy version.
    Various unsupervised alternatives have been also developed for this task, such
    as Noise2Noise [[160](#bib.bib160)], Noise2Void [[152](#bib.bib152)], Noise2Self [[16](#bib.bib16)],
    SURE-based denoising [[337](#bib.bib337), [175](#bib.bib175), [207](#bib.bib207)],
    and others, all aim to operate on noisy images directly without the need for an
    access to their clean versions. It should be clear, though, that these techniques
    become relevant only in cases where the noise does not follow a known analytic
    structure, as otherwise the supervised alternative would be preferred. Another
    appealing approach that adopts an unsupervised denoiser training is “Deep Image
    Prior” (DIP) [[286](#bib.bib286)], where a network is trained on a single image
    to best fit itself. An early stopping of this learning is shown to yield an effective
    denoising, revealing the regularization capabilities of the UNet architecture.'
  id: totrans-136
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 不同的训练方案：我们上述描述了最明显的监督训练策略，即收集理想图像及其噪声版本的配对。也有多种无监督替代方案被开发用于此任务，例如 Noise2Noise [[160](#bib.bib160)]、Noise2Void [[152](#bib.bib152)]、Noise2Self [[16](#bib.bib16)]、基于
    SURE 的去噪 [[337](#bib.bib337), [175](#bib.bib175), [207](#bib.bib207)] 等，它们的目标是直接处理噪声图像而无需访问其清晰版本。然而，应该明确的是，这些技术仅在噪声不遵循已知解析结构的情况下才变得相关，否则，监督替代方案将更受欢迎。另一种采用无监督去噪器训练的有吸引力的方法是“深度图像先验”（DIP） [[286](#bib.bib286)]，其中网络在单张图像上进行训练，以最佳拟合自身。研究表明，提前停止这种学习可以产生有效的去噪，揭示了
    UNet 架构的正则化能力。
- en: •
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'True Noise Removal: We mentioned above the Noise2X line of work [[160](#bib.bib160),
    [152](#bib.bib152), [16](#bib.bib16)], which enables denoising of images without
    access to their clean versions. This ability becomes crucial when operating on
    images with un-modeled and unknown noise statistics. In such cases, learning should
    rely on more fundamental forces, such as self-similarity in images, the slow tendency
    of regressed neural networks to recreate noise from noise, the joint information
    that exists in burst of frames, and more. More broadly speaking, removal of true
    noise from images is a relatively new topic in image denoising, as it has hardly
    been addressed in the classical era due to its evident complexity. With advanced
    self-supervised and unsupervised learning techniques, new impressive abilities
    were created [[298](#bib.bib298), [149](#bib.bib149), [170](#bib.bib170), [285](#bib.bib285),
    [301](#bib.bib301), [128](#bib.bib128)].'
  id: totrans-138
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 真正噪声去除：我们之前提到了 Noise2X 系列的工作 [[160](#bib.bib160), [152](#bib.bib152), [16](#bib.bib16)]，它使得在没有干净图像的情况下去噪成为可能。这种能力在处理具有未建模和未知噪声统计的图像时尤为重要。在这种情况下，学习应该依赖于更基本的力量，例如图像中的自相似性、回归神经网络从噪声中再现噪声的缓慢趋势、存在于图像帧突发中的联合信息等。更广泛地说，从图像中去除真正的噪声是图像去噪中的一个相对较新的主题，因为在经典时代由于其显而易见的复杂性，几乎没有被涉及。借助先进的自监督和无监督学习技术，创造了新的令人印象深刻的能力
    [[298](#bib.bib298), [149](#bib.bib149), [170](#bib.bib170), [285](#bib.bib285),
    [301](#bib.bib301), [128](#bib.bib128)]。
- en: •
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Image adaptation: This refers to the ability to take an already designed/trained
    denoiser and adapt it to perform better on unique images that deviate from the
    training set. This way, general purpose denoisers could be boosted when operating
    on scanned documents, astronomical images, cartoon images and more. The adaptation
    itself could be done in various ways, the most natural of these is the following [[289](#bib.bib289)]:
    Given a noisy yet unique image to be cleaned, apply first the available denoiser
    $D_{\Theta_{0}}$ and obtain ${\hat{\mathbf{x}}}_{0}=D_{\Theta_{0}}({\mathbf{y}},\sigma)$.
    Now retrain the denoiser (i.e. update the parameters $\Theta$) by minimizing $dist\left({\hat{\mathbf{x}}}_{0},D_{\Theta}({\mathbf{y}},\sigma)\right)$.
    Similar to the core idea behind Noise2Noise [[160](#bib.bib160)] and DIP [[286](#bib.bib286)],
    few gradient steps of this minimization are expected to go in the proper direction
    and yield a more informative and relevant denoiser, thus boosting the result for
    this specific image. The final outcome is obtained by ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$,
    using the slightly updated parameters $\Theta$.'
  id: totrans-140
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像适应：这指的是将已经设计/训练好的去噪器调整，使其在处理与训练集不同的独特图像时表现更好。这样，通用去噪器在处理扫描文档、天文图像、卡通图像等时可以得到提升。适应本身可以通过多种方式完成，其中最自然的一种是以下方法[[289](#bib.bib289)]：给定一张嘈杂而独特的图像进行清理，首先应用现有的去噪器
    $D_{\Theta_{0}}$ 并获得 ${\hat{\mathbf{x}}}_{0}=D_{\Theta_{0}}({\mathbf{y}},\sigma)$。然后，通过最小化
    $dist\left({\hat{\mathbf{x}}}_{0},D_{\Theta}({\mathbf{y}},\sigma)\right)$ 来重新训练去噪器（即更新参数
    $\Theta$）。类似于 Noise2Noise [[160](#bib.bib160)] 和 DIP [[286](#bib.bib286)] 的核心思想，这种最小化的几个梯度步骤预计会朝着正确的方向发展，从而生成更具信息性和相关性的去噪器，从而提高该特定图像的结果。最终结果是通过
    ${\hat{\mathbf{x}}}=D_{\Theta}({\mathbf{y}},\sigma)$ 获得，使用稍微更新的参数 $\Theta$。
- en: •
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Addressing Different Objectives: When describing the supervised learning strategy
    of denoisers, we offered the $L_{2}$ loss that considers PSNR performance. Over
    the years this quality measure took the lead in most papers, despite its known
    weaknesses. Indeed, our community has been constantly striving to get the MMSE
    denoiser, if not in body, then at least in spirit, and this is evident from the
    PSNR performance tables that appear in almost every paper on image denoising published
    over the years. As we argue later on in Section [9.1](#S9.SS1 "9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    while MMSE denoisers are of great value by themselves, their outcome is not necessarily
    visually appealing, being an average over many potential solutions.'
  id: totrans-142
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '解决不同目标：在描述去噪器的监督学习策略时，我们提供了考虑PSNR性能的$L_{2}$损失。多年来，这种质量度量在大多数论文中占据了主导地位，尽管它存在已知的缺陷。确实，我们的社区一直在不断努力追求MMSE去噪器，如果不能在实体上，至少在精神上，这从多年来几乎所有关于图像去噪的论文中出现的PSNR性能表中可以看出。正如我们在第[9.1节](#S9.SS1
    "9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")中稍后讨论的那样，尽管MMSE去噪器本身具有很大价值，但它们的结果并不一定具有视觉吸引力，因为它是对许多潜在解决方案的平均。'
- en: 'Bearing this in mind, the learning paradigm creates a new opportunity for serving
    “new masters” – recall that the learning loss function is highly non-convex, and
    yet we have no fear of its complexity when training the neural networks. Thus,
    we can easily replace the pleasant $L_{2}$ by more sophisticated or adequate penalties.
    The immediate alternative that comes to mind is SSIM [[299](#bib.bib299)], which
    offers a more robust distance measure between images by considering structural
    similarity. We could go further and consider perceptual losses such as LPIPS [[335](#bib.bib335)],
    that is further robustified by a learned representation in order to fairly assess
    proximity between images. This trend can be characterized as an attempt to produce
    visually pleasing and crisp images from the denoisers, ones that will surpass
    the MMSE alternative. A step forward in this direction takes us to Generative
    Adversarial Networks (GANs) for denoising [[69](#bib.bib69), [67](#bib.bib67),
    [212](#bib.bib212)]. The idea is to challenge the output of the denoiser, by feeding
    it into a classifer that should tell apart true images versus denoised ones. By
    leveraging this classifier’s guidance, the denoiser can learn to produce better
    looking images. We will come back to this idea in Section [9.1](#S9.SS1 "9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    offering an improved approach that targets perfect perceptual quality results.'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '考虑到这一点，学习范式为服务“新主宰”创造了新的机会——请记住，学习损失函数是高度非凸的，但我们在训练神经网络时对其复杂性并不感到害怕。因此，我们可以轻松地用更复杂或更合适的惩罚来替代令人愉悦的$L_{2}$。立刻想到的替代方案是SSIM [[299](#bib.bib299)]，它通过考虑结构相似性提供了图像之间更鲁棒的距离度量。我们还可以进一步考虑诸如LPIPS [[335](#bib.bib335)]这样的感知损失，这通过学习的表示进一步增强了鲁棒性，以公平地评估图像之间的接近度。这种趋势可以被描述为试图从去噪器中产生视觉上令人愉悦和清晰的图像，这些图像将超越MMSE替代方案。朝着这个方向迈出的第一步是将生成对抗网络（GANs）应用于去噪 [[69](#bib.bib69),
    [67](#bib.bib67), [212](#bib.bib212)]。这个想法是挑战去噪器的输出，通过将其输入到一个分类器中，该分类器应该区分真实图像和去噪图像。通过利用这个分类器的指导，去噪器可以学会产生更好看的图像。我们将在第[9.1节](#S9.SS1
    "9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")中回到这个想法，提供一种改进的方法，旨在获得完美的感知质量结果。'
- en: The description given above provides nothing but a glimpse into a very vibrant
    and rich body of literature that finds image denoising as an appealing playground
    for research. Still, we stop the survey of deep learning for denoising here, as
    our prime goal is the denoisers themselves and algorithms building on top of them.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 上述描述仅仅提供了一个对图像去噪领域非常活跃且丰富的文献的初步了解，该领域将图像去噪视为一个有吸引力的研究领域。尽管如此，我们在这里停止对深度学习在去噪中的调查，因为我们的主要目标是去噪器本身以及建立在其上的算法。
- en: As one final note, observe that all the preceding discussion on classical and
    modern denoisers’ design is given without referring to color images. Indeed, the
    formulation in this paper considers a grayscale image ${\mathbf{x}}$, yet most
    denoisers, old and new, are typically required to process color (Red-Green-Blue)
    images. Some of the existing methods discussed above are easily extended to color
    by operating on the three chroma channels jointly. For example, NLM [[32](#bib.bib32)]
    and K-SVD denoising [[89](#bib.bib89)] operate on RGB patches directly by flattening
    them to longer vectors. Another approach is to turn to the YUV or YCbCr color-space,
    and operate on the luma (Y) and the chroma (Cb/Cr or U/V) layers independently,
    as BM3D does [[61](#bib.bib61)]. Denoisers based on deep neural networks typically
    handle color directly by feeding the RGB image as a 3-dimensional tensor input
    to the network, processed by subsequent 3D convolutions. More intricate approaches
    do exist, in which the geometrical interplay between the color layers is taken
    into account more adequately [[255](#bib.bib255)].
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一点，请注意，所有关于经典和现代去噪器设计的讨论都是在没有提及彩色图像的情况下进行的。确实，本文中的公式考虑的是灰度图像${\mathbf{x}}$，然而大多数去噪器，无论新旧，通常需要处理彩色（红绿蓝）图像。上述一些现有方法可以通过对三个色度通道联合操作来轻松扩展到彩色图像。例如，NLM[[32](#bib.bib32)]和K-SVD去噪[[89](#bib.bib89)]通过将RGB图像块展平为更长的向量来直接操作。另一种方法是转向YUV或YCbCr色彩空间，独立操作亮度（Y）和色度（Cb/Cr或U/V）层，就像BM3D所做的那样[[61](#bib.bib61)]。基于深度神经网络的去噪器通常通过将RGB图像作为3维张量输入网络，并通过随后的3D卷积进行处理来直接处理彩色图像。确实存在更复杂的方法，这些方法对色彩层之间的几何相互作用进行了更充分的考虑[[255](#bib.bib255)]。
- en: 5 Synergy between Classics and Deep Learning
  id: totrans-146
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 经典与深度学习的协同作用
- en: 'With the description given above, the reader may (rightfully!) get the impression
    that the vast knowledge regarding image denoising gathered during the classical
    era has become obsolete with the emergence of the deep learning alternatives.
    However, this claim is not entirely correct. In reality, the themes investigated
    and promoted by classical algorithms are serving as the foundations for building
    DL denoisers, even if practiced implicitly, and these are mostly manifested by
    the choice of architectures to be used. To illustrate this, we mention several
    well-known key concepts of classical image denoising algorithms, and show their
    impact on DL architectures:'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 根据上述描述，读者可能会（有理由地！）产生这样的印象：在经典时代积累的大量关于图像去噪的知识在深度学习方法出现后已经变得过时。然而，这种说法并不完全正确。实际上，经典算法研究和推广的主题仍然是构建深度学习去噪器的基础，尽管这种应用可能是隐性的，这些基础主要体现在所使用的架构选择上。为说明这一点，我们提到了一些经典图像去噪算法的著名关键概念，并展示它们对深度学习架构的影响：
- en: •
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Locality: Most information relevant to restoring a pixel’s value in denoising
    is contained in its local neighborhood. In classical algorithms, this concept
    is embodied using patch processing, local filtering, local image priors, and more.
    When it comes to DL schemes, many denoisers choose convolutional layers as their
    primary processing path, which leads to architectures with small to moderate receptive
    fields [[308](#bib.bib308), [330](#bib.bib330), [332](#bib.bib332)].'
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 局部性：去噪中恢复像素值的大多数相关信息都包含在其局部邻域中。在经典算法中，这一概念通过块处理、本地滤波、本地图像先验等体现出来。而在深度学习方案中，许多去噪器选择卷积层作为主要处理路径，这导致了具有小到中等感受野的架构[[308](#bib.bib308),
    [330](#bib.bib330), [332](#bib.bib332)]。
- en: •
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Sparsity under appropriate transforms: Local image patches are expected to
    be sparse when represented using certain 2D transforms. On the classical side,
    several of the priors listed in Table [1](#S3.T1 "Table 1 ‣ 3.2 Evolution of Priors
    ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") fall into the sparsity-promoting category. On
    the DL side, a similar treatment can be observed, where the commonly used ReLU
    activation promotes sparsity by nulling the negatively activated neurons [[101](#bib.bib101)].'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 适当变换下的稀疏性：使用某些二维变换表示时，局部图像块被期望是稀疏的。在经典方法中，表格[1](#S3.T1 "表格 1 ‣ 3.2 先验的演变 ‣ 3
    图像去噪 – 经典时代 ‣ 图像去噪：深度学习革命及其未来 – 一项调查")列出的几个先验属于稀疏性促进类别。在深度学习方面，可以观察到类似的处理，其中常用的ReLU激活通过使负激活的神经元为零来促进稀疏性[[101](#bib.bib101)]。
- en: •
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Self-similarity: Most image patches have similar twins at other locations in
    the same image. While classical algorithms usually harness this property by gathering
    similar patches and processing them jointly, some recent DL schemes leverage self-similarity
    using self-attention layers [[165](#bib.bib165), [317](#bib.bib317)].'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自相似性：大多数图像补丁在同一图像的其他位置具有类似的双胞胎。尽管经典算法通常通过收集相似的补丁并将其联合处理来利用这一特性，但一些最近的深度学习方案利用自注意力层来发挥自相似性[[165](#bib.bib165)、[317](#bib.bib317)]。
- en: 'Unfortunately, these and other concepts inherited from the classical era do
    not provide a constructive answer to the main question DL faces: How should we
    choose the appropriate architecture for the denoising task? Researchers facing
    this question are usually taking one of the two following options: (i) Copy: adoption
    of an existing architecture that has been demonstrated to lead to good results
    in a similar task (e.g., DnCNN, UNet, ResNet, and more) [[330](#bib.bib330), [234](#bib.bib234),
    [117](#bib.bib117)]. Usually such an adoption is accompanied by some minor modifications
    such as changing the number of channels or layers, etc.; or (ii) Trial and error:
    gathering an architecture by piling a mix of known building blocks such as convolutions,
    strides, batch normalization steps, ReLU, fully-connected layers, down- and up-scaling,
    skip-connections, and more.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 不幸的是，这些以及其他从经典时代继承的概念并没有对深度学习面临的主要问题提供建设性的答案：我们应该如何选择适合去噪任务的架构？面对这个问题的研究人员通常会选择以下两种方案之一：（i）复制：采用已经在类似任务中被证明效果良好的现有架构（例如，DnCNN、UNet、ResNet等）[[330](#bib.bib330)、[234](#bib.bib234)、[117](#bib.bib117)]。通常，这种采用会伴随一些小的修改，比如更改通道数或层数等；或（ii）试错：通过将卷积、步幅、批归一化步骤、ReLU、全连接层、下采样和上采样、跳跃连接等已知构建块混合起来，逐步构建一个架构。
- en: Both these options seem to work rather well, leading to networks achieving very
    good practical results – see [[330](#bib.bib330), [332](#bib.bib332), [165](#bib.bib165)].
    However, this brute-force approach typically tends to end up with heavy and cumbersome
    architectures, relying on millions of trainable parameters, making the resulting
    networks expensive to use and hard to train. Another downside in such architectures
    is their lack of explainability. While this may seem unimportant, having a black-box
    denoiser with no explainability implies an inability to leverage it to other tasks
    (e.g., image separation [[199](#bib.bib199), [91](#bib.bib91), [153](#bib.bib153)]),
    or probe it for identifying origins of failures for ill-treated regions in the
    image. More broadly, the brute-force approach towards architecture design for
    denoisers may require a lengthy trial and error process and may end up hitting
    a performance barrier.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 这两种方案似乎效果都很好，导致网络获得了非常好的实际结果——见[[330](#bib.bib330)、[332](#bib.bib332)、[165](#bib.bib165)]。然而，这种蛮力方法通常会导致沉重而繁琐的架构，依赖于数百万个可训练参数，使得结果网络使用成本高且训练困难。这种架构的另一个缺点是缺乏可解释性。虽然这可能看起来不重要，但没有可解释性的黑箱去噪器意味着无法将其应用于其他任务（例如，图像分离[[199](#bib.bib199)、[91](#bib.bib91)、[153](#bib.bib153)]），或者无法用来识别图像中处理不当区域的故障来源。更广泛地说，对于去噪器的架构设计，蛮力方法可能需要漫长的试错过程，最终可能会遇到性能瓶颈。
- en: 'An alternative to copying or guessing architectures does appear in recent literature,
    known as *unfolding* [[109](#bib.bib109), [341](#bib.bib341), [250](#bib.bib250),
    [83](#bib.bib83), [204](#bib.bib204)]. This approach constructs the neural network
    so as to mimic the computational stages of a well motivated algorithm. The term
    unfolding has to do with the fact that many classical image denoising methods
    involve iterative algorithms, and thus networks mimicking these should unfold
    their iterations to a feed-forward computational path. This approach typically
    produces concise and perfectly explainable networks, both in terms of the learned
    parameters and the activations obtained, which are easier to train. In addition,
    such networks tend to be easily and effectively adapted to different data. There
    are various examples in the literature for the unfolding approach for various
    regression tasks, e.g. [[313](#bib.bib313), [58](#bib.bib58), [328](#bib.bib328),
    [125](#bib.bib125), [289](#bib.bib289), [250](#bib.bib250), [204](#bib.bib204)].
    Here we briefly describe two such methods for illustrative purpose: Deep K-SVD [[250](#bib.bib250)]
    and LIDIA [[289](#bib.bib289)]. Both propose a conversion of a classical denoising
    algorithm into a deep neural network architecture.'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 近期文献中出现了一种替代复制或猜测架构的方法，称为*展开* [[109](#bib.bib109), [341](#bib.bib341), [250](#bib.bib250),
    [83](#bib.bib83), [204](#bib.bib204)]。这种方法构建神经网络以模拟一个合理算法的计算阶段。展开一词与许多经典图像去噪方法涉及迭代算法有关，因此模仿这些方法的网络应将其迭代展开为前向计算路径。这种方法通常产生简洁且完全可解释的网络，无论是在学习参数还是获得的激活上，都更易于训练。此外，这样的网络往往很容易而且有效地适应不同的数据。文献中有各种展开方法的例子，例如用于各种回归任务的展开方法，如 [[313](#bib.bib313),
    [58](#bib.bib58), [328](#bib.bib328), [125](#bib.bib125), [289](#bib.bib289),
    [250](#bib.bib250), [204](#bib.bib204)]。在这里，我们简要描述两种用于举例的方法：深度K-SVD [[250](#bib.bib250)]和LIDIA [[289](#bib.bib289)]。它们都提出了将一个经典去噪算法转换为深度神经网络架构的方法。
- en: 5.1 Deep K-SVD
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 深度K-SVD
- en: '![Refer to caption](img/861a7d254a2347a9180dba22693cc6ca.png)'
  id: totrans-158
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/861a7d254a2347a9180dba22693cc6ca.png)'
- en: 'Figure 3: End-to-end architecture of the Deep K-SVD network [[250](#bib.bib250)].'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：深度K-SVD网络的端到端架构 [[250](#bib.bib250)]。
- en: Deep K-SVD [[250](#bib.bib250)] is an unfolding version of the K-SVD image denoising
    algorithm [[89](#bib.bib89)]. We start with a brief explanation of the original
    K-SVD method, and then turn to describe its unfolding.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 深度K-SVD [[250](#bib.bib250)]是K-SVD图像去噪算法的展开版本 [[89](#bib.bib89)]。我们先简要解释原始K-SVD方法，然后转而描述它的展开。
- en: K-SVD denoising is based on sparse representation theory for constructing the
    image prior [[4](#bib.bib4)]. Consider a clean image $\mathbf{x}$ and patch extraction
    operators $\left\{\mathbf{R}_{k}\right\}_{k}$ such that $\mathbf{R}_{k}\mathbf{x}\in\mathbb{R}^{n}$
    are image patches of size $\sqrt{n}\times\sqrt{n}$ taken from location $k$ in
    the image. The sparsity-promoting prior assumes that any such patch, $\mathbf{R}_{k}\mathbf{x}$,
    can be represented as a linear combination of *f*ew columns (also referred to
    as atoms) from a redundant dictionary ${\mathbf{D}}\in\mathbb{R}^{n\times p}$
    (redundancy implied by $p>n$), i.e.,
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: K-SVD去噪是基于稀疏表示理论构建图像先验 [[4](#bib.bib4)]。考虑一幅干净图像$\mathbf{x}$和提取操作符$\left\{\mathbf{R}_{k}\right\}_{k}$，使得$\mathbf{R}_{k}\mathbf{x}\in\mathbb{R}^{n}$是从图像位置$k$取得的大小为$\sqrt{n}\times\sqrt{n}$的图像块。稀疏先验假设任何这样的图像块，$\mathbf{R}_{k}\mathbf{x}$，可以表示为冗余字典${\mathbf{D}}\in\mathbb{R}^{n\times
    p}$中*少数*列（也称为原子）的线性组合（冗余性暗示$p>n$），即，
- en: '| (10) |  | $\mathbf{R}_{k}\mathbf{x}={\mathbf{D}}\alpha_{k}\;,$ |  |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| (10) |  | $\mathbf{R}_{k}\mathbf{x}={\mathbf{D}}\alpha_{k}\;,$ |  |'
- en: 'where $\alpha_{k}\in\mathbb{R}^{p}$ is a sparse vector, $\left\|\alpha_{i}\right\|_{0}\ll
    n$. Armed with this assumption, K-SVD poses the following minimization problem:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\alpha_{k}\in\mathbb{R}^{p}$是一个稀疏向量，$\left\|\alpha_{i}\right\|_{0}\ll n$。
    在这个假设的基础上，K-SVD提出了以下最小化问题：
- en: '| (11) |  | $\min_{\left\{\alpha_{k}\right\}_{k},\mathbf{x}}\quad\frac{\mu}{2}\left\&#124;\mathbf{x}-\mathbf{y}\right\&#124;_{2}^{2}+\sum_{k}\left(\lambda_{k}\left\&#124;\alpha_{k}\right\&#124;_{0}+\frac{1}{2}\left\&#124;{\mathbf{D}}\alpha_{k}-\mathbf{R}_{k}\mathbf{x}\right\&#124;_{2}^{2}\right)\;,$
    |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| (11) |  | $\min_{\left\{\alpha_{k}\right\}_{k},\mathbf{x}}\quad\frac{\mu}{2}\left\&#124;\mathbf{x}-\mathbf{y}\right\&#124;_{2}^{2}+\sum_{k}\left(\lambda_{k}\left\&#124;\alpha_{k}\right\&#124;_{0}+\frac{1}{2}\left\&#124;{\mathbf{D}}\alpha_{k}-\mathbf{R}_{k}\mathbf{x}\right\&#124;_{2}^{2}\right)\;,$
    |  |'
- en: where $\mathbf{y}$ is the given noisy image, and $\mu$ and $\lambda_{k}$ are
    hyper-parameters. In this expression, the first term is the Log-Likelihood that
    requires a proximity between the reconstructed image $\mathbf{x}$ and the noisy
    image $\mathbf{y}$. The second and third terms represent the sparse representation
    prior, demanding that every image patch $\mathbf{R}_{k}\mathbf{x}$ in every location
    $k$ has an approximate sparse representation $\alpha_{k}$.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{y}$是给定的带噪图像，$\mu$和$\lambda_{k}$是超参数。在这个表达式中，第一个项是对数似然度，要求重建图像$\mathbf{x}$与带噪图像$\mathbf{y}$之间的接近度。第二和第三项表示稀疏表示先验，要求每个位置$k$中的图像块$\mathbf{R}_{k}\mathbf{x}$有一个近似的稀疏表示$\alpha_{k}$。
- en: 'The K-SVD algorithm solves this minimization problem by applying the following
    two steps iteratively: (i) Fix ${\mathbf{x}}$ (initialized by ${\mathbf{x}}={\mathbf{y}}$)
    and update the vectors $\left\{\alpha_{k}\right\}_{k}$; and (ii) Update ${\mathbf{x}}$
    while freezing the sparse representation vectors. The first is referred to as
    the sparse coding stage, where each patch in the contemporary solution obtains
    a sparse representation via the Orthogonal Matching Pursuit (OMP) greedy algorithm [[214](#bib.bib214)].
    The second step becomes a quadratic minimization task, its solution being a simple
    variation of patch-based averaging. A single round of the above two steps has
    been shown to suffice for getting very good results [[89](#bib.bib89)], and a
    repetition of this round several times could further boost the results [[347](#bib.bib347)].
    The dictionary ${\mathbf{D}}$ in the above process could be either universal –
    pretrained to best sparsify natural image content, or image adaptive – updated
    to the image ${\mathbf{y}}$ itself within the above optimization.'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: K-SVD算法通过以下两步迭代地解决这个最小化问题：（i）固定${\mathbf{x}}$（初始化为${\mathbf{x}}={\mathbf{y}}$），并更新向量$\left\{\alpha_{k}\right\}_{k}$；（ii）更新${\mathbf{x}}$，同时冻结稀疏表示向量。第一步被称为稀疏编码阶段，在这一阶段，每个块通过正交匹配追踪（OMP）贪婪算法获得稀疏表示[[214](#bib.bib214)]。第二步变成一个二次最小化任务，其解是基于块的均值的简单变体。研究表明，以上两步的一次迭代足以获得非常好的结果[[89](#bib.bib89)]，多次重复这个过程可以进一步提高结果[[347](#bib.bib347)]。上述过程中的字典${\mathbf{D}}$可以是通用的——预训练以最有效地稀疏化自然图像内容，或者是图像自适应的——在上述优化过程中更新到图像${\mathbf{y}}$本身。
- en: 'We now turn to describe the Deep K-SVD algorithm, which adopts the universal
    dictionary approach. The end-to-end architecture referring to a single round is
    illustrated in Figure [3](#S5.F3 "Figure 3 ‣ 5.1 Deep K-SVD ‣ 5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –"). This neural network consists of three main blocks:
    Patch Decomposition, Patch Denoiser, and Patch Averaging, all following closely
    the very same steps described above, with appropriate adaptations. Patch Decomposition
    breaks the input image $\mathbf{y}$ into a set of fully overlapped patches $\left\{\mathbf{z}_{k}\right\}_{k}=\left\{\mathbf{R}_{k}\mathbf{y}\right\}_{k}$.
    The next block, Patch Denoiser, is applied patch-wise, but replaces the OMP by
    LISTA [[109](#bib.bib109)], in which $\mathbf{z}_{k}$ undergoes sparse coding
    via a differentiable shrinkage-based iterative algorithm [[109](#bib.bib109)].
    These inner iterations are unfolded as well to create a feed-forward computational
    path that starts with $\mathbf{z}_{k}$ and ends with $\mathbf{\hat{z}}_{k}={\mathbf{D}}\alpha_{k}$.
    Due to the gap between OMP and LISTA, a sub-network of fully-connected layers
    computes the value of $\lambda_{k}$ for the incoming patch ${\mathbf{z}}_{k}$.
    The last block, Patch Averaging, rebuilds the reconstructed image $\mathbf{\hat{x}}$
    by averaging the cleaned patches $\mathbf{\hat{z}}_{k}$ using learned weights.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们来描述Deep K-SVD算法，它采用了通用字典的方法。单轮的端到端架构如图[3](#S5.F3 "图 3 ‣ 5.1 Deep K-SVD ‣
    5 经典与深度学习的协同 ‣ 图像去噪：深度学习的革命及其未来 – 调查论文 –")所示。该神经网络由三个主要模块组成：块分解、块去噪和块平均，所有模块都紧密遵循上述相同的步骤，并进行了适当的调整。块分解将输入图像$\mathbf{y}$分解为一组完全重叠的块$\left\{\mathbf{z}_{k}\right\}_{k}=\left\{\mathbf{R}_{k}\mathbf{y}\right\}_{k}$。下一个模块，块去噪，是逐块应用的，但将OMP替换为LISTA[[109](#bib.bib109)]，其中$\mathbf{z}_{k}$通过可微分的收缩迭代算法进行稀疏编码[[109](#bib.bib109)]。这些内部迭代也被展开，创建了一个前向计算路径，从$\mathbf{z}_{k}$开始，到$\mathbf{\hat{z}}_{k}={\mathbf{D}}\alpha_{k}$结束。由于OMP和LISTA之间的差距，一个全连接层的子网络计算传入块${\mathbf{z}}_{k}$的$\lambda_{k}$值。最后一个模块，块平均，通过使用学习到的权重对清洁的块$\mathbf{\hat{z}}_{k}$进行平均，重建出重建图像$\mathbf{\hat{x}}$。
- en: This Deep K-SVD network is trained end-to-end by minimizing the MSE distance
    between the ideal and denoised images for a set of $M$ training images,
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这个深度 K-SVD 网络通过最小化一组 $M$ 训练图像的理想图像和去噪图像之间的 MSE 距离进行端到端的训练，
- en: '| (12) |  | $\mathcal{L}\left(\Theta\right)=\sum_{k=1}^{M}\left\&#124;\mathbf{x}_{k}-\mathbf{\hat{x}}_{k}\right\&#124;_{2}^{2}=\sum_{k=1}^{M}\left\&#124;\mathbf{x}_{k}-D_{\Theta}\left(\mathbf{y}_{k}\right)\right\&#124;_{2}^{2}\;,$
    |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| (12) |  | $\mathcal{L}\left(\Theta\right)=\sum_{k=1}^{M}\left\|\mathbf{x}_{k}-\mathbf{\hat{x}}_{k}\right\|_{2}^{2}=\sum_{k=1}^{M}\left\|\mathbf{x}_{k}-D_{\Theta}\left(\mathbf{y}_{k}\right)\right\|_{2}^{2}\;,$
    |  |'
- en: where $\left\{{\mathbf{x}}_{k},y_{k}\right\}_{k}$ is a set of clean and noisy
    image pairs to train on. $D_{\Theta}$ is the denoising network, where $\Theta$
    stands for all trainable parameters, consisting of the dictionary ${\mathbf{D}}$,
    the parameters of the sub-network that evaluates $\lambda_{k}$ and the shrinkage
    thresholds.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\left\{{\mathbf{x}}_{k},y_{k}\right\}_{k}$ 是用于训练的一组干净和噪声图像对。$D_{\Theta}$
    是去噪网络，其中 $\Theta$ 代表所有可训练的参数，包括字典 ${\mathbf{D}}$、评估 $\lambda_{k}$ 的子网络参数以及收缩阈值。
- en: Despite the close resemblance between the original algorithm and its unfolded
    version, the later performs much better [[250](#bib.bib250)], surpassing classical
    methods and aligning with deep-learning based techniques. This should not come
    as a surprise as the unfolded denoiser $D_{\Theta}$ is trained in a supervised
    manner, being fully aware of the task it serves, whereas the original algorithm
    relied on a “guessed” image prior. Interestingly, the universal dictionary obtained
    for $D_{\Theta}$ is markedly different from the one trained off-line for the original
    K-SVD denoising method, again a testimony to the major difference between the
    two design strategies.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始算法与其展开版本之间有很大的相似性，但后者表现更好 [[250](#bib.bib250)]，超越了经典方法，并与基于深度学习的技术对齐。这并不令人惊讶，因为展开的去噪器
    $D_{\Theta}$ 以监督的方式进行训练，充分了解其服务的任务，而原始算法依赖于“猜测”的图像先验。有趣的是，$D_{\Theta}$ 获得的通用字典与原始
    K-SVD 去噪方法离线训练的字典明显不同，这再次证明了这两种设计策略之间的重大差异。
- en: 5.2 LIDIA - Lightweight Learned Image Denoising
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 LIDIA - 轻量化学习图像去噪
- en: 'Another example of unfolding-based denoising is LIDIA [[289](#bib.bib289)],
    which mimics the computational stages of the BM3D [[61](#bib.bib61)]. As already
    mentioned in Section [3.3](#S3.SS3 "3.3 Other Classical Denoisers ‣ 3 Image Denoising
    – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and Beyond –
    A Survey Paper –"), BM3D harnesses two prime forces for its denoising goal – sparsity
    and self similarity. The first relies on the assumption that local image patches
    are sparse under the 2D-DCT spatial transform; the later is reflected by operating
    on groups of similar patches jointly, forcing sparsity again by transforming across
    these patches.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '另一个基于展开的去噪示例是 LIDIA [[289](#bib.bib289)]，它模拟了 BM3D [[61](#bib.bib61)] 的计算阶段。如第
    [3.3](#S3.SS3 "3.3 Other Classical Denoisers ‣ 3 Image Denoising – The Classic
    Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper
    –") 节所述，BM3D 利用稀疏性和自相似性这两种主要力量来实现去噪目标。首先，依赖于局部图像补丁在 2D-DCT 空间变换下的稀疏性；其次，通过对相似补丁组进行联合操作，强制稀疏性再次通过这些补丁之间的变换。'
- en: '![Refer to caption](img/46992dc7e7759e92673caf9fd59fbadb.png)'
  id: totrans-174
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/46992dc7e7759e92673caf9fd59fbadb.png)'
- en: 'Figure 4: The LIDIA denoising computational path.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: LIDIA 去噪计算路径。'
- en: '![Refer to caption](img/fdf93b4fa79cffd4ea714881dd209408.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fdf93b4fa79cffd4ea714881dd209408.png)'
- en: 'Figure 5: The Transform-ReLU-Transform block. Applying the matrices $\mathbf{T}_{1}$
    and $\mathbf{T}_{2}$ transforms the input, $\mathbf{Z}_{k}$, to a space in which
    patches are supposed to be sparse; the matrices $\mathbf{T}_{3}$ and $\mathbf{T}_{4}$
    transform the outcome to the pixel domain. Observe that the transform applied
    on $\mathbf{Z}_{k}$ is separable – $\mathbf{T}_{1}$ is applied within patches
    while $\mathbf{T}_{2}$ operates across. This enables a reduction of the size of
    the matrices $\mathbf{T}_{1},\dots,\mathbf{T}_{4}$ in order to enable their training.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: Transform-ReLU-Transform 块。应用矩阵 $\mathbf{T}_{1}$ 和 $\mathbf{T}_{2}$ 将输入
    $\mathbf{Z}_{k}$ 转换到一个补丁应该是稀疏的空间中；矩阵 $\mathbf{T}_{3}$ 和 $\mathbf{T}_{4}$ 将结果转换到像素域中。注意，应用于
    $\mathbf{Z}_{k}$ 的变换是可分离的 – $\mathbf{T}_{1}$ 在补丁内应用，而 $\mathbf{T}_{2}$ 在补丁间操作。这使得矩阵
    $\mathbf{T}_{1},\dots,\mathbf{T}_{4}$ 的大小得以缩小，从而使其可以进行训练。'
- en: 'LIDIA’s core computational path is shown schematically in Figure [4](#S5.F4
    "Figure 4 ‣ 5.2 LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between
    Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –"). This neural network starts by breaking the input
    image $\mathbf{y}$ into a set of fully overlapping patches $\left\{\mathbf{z}_{k}\right\}_{k}$
    of size $\sqrt{n}\times\sqrt{n}$. Then, each patch, $\mathbf{z}_{k}\in\mathbb{R}^{n}$,
    is augmented with a group of its $m-1$ nearest neighbors, forming a matrix $\mathbf{Z}_{k}$
    of size $n\times m$. The filtering is applied patch-wise – each matrix, $\mathbf{Z}_{k}$,
    undergoes a series of blocks composed of a separable transform, ReLU, and another
    separable transform, as shown schematically in Figure [5](#S5.F5 "Figure 5 ‣ 5.2
    LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between Classics and Deep
    Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –"). This mimics the BM3D operation by transforming the input matrix to
    a space in which local patches are believed to be sparse, forcing sparsity using
    the ReLU layer, and transforming back the outcome to the pixel domain. Unlike
    BM3D, the transforms are trainable and are not restricted to be the inverse of
    each other, nor forced to be square matrices. In addition, LIDIA includes a multi-scale
    treatment, simultaneously processing patches in several scales. During processing,
    the corresponding patches from different scales are fused using a learned joint
    transform. Finally, the reconstructed image is obtained by returning the denoised
    patches to their original places while averaging overlaps using learned weights.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 'LIDIA 的核心计算路径如图 [4](#S5.F4 "Figure 4 ‣ 5.2 LIDIA - Lightweight Learned Image
    Denoising ‣ 5 Synergy between Classics and Deep Learning ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –") 所示。这个神经网络首先将输入图像 $\mathbf{y}$
    切分成一组完全重叠的补丁 $\left\{\mathbf{z}_{k}\right\}_{k}$，每个补丁的大小为 $\sqrt{n}\times\sqrt{n}$。然后，每个补丁
    $\mathbf{z}_{k}\in\mathbb{R}^{n}$ 会被增强，加入其 $m-1$ 个最近邻的补丁，形成一个大小为 $n\times m$ 的矩阵
    $\mathbf{Z}_{k}$。滤波是逐补丁应用的 —— 每个矩阵 $\mathbf{Z}_{k}$ 会经过一系列的块，这些块由一个可分离变换、ReLU
    和另一个可分离变换组成，如图 [5](#S5.F5 "Figure 5 ‣ 5.2 LIDIA - Lightweight Learned Image Denoising
    ‣ 5 Synergy between Classics and Deep Learning ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") 所示。这一过程模拟了 BM3D 操作，通过将输入矩阵变换到一个局部补丁被认为是稀疏的空间，利用
    ReLU 层强制稀疏性，然后将结果变换回像素域。与 BM3D 不同的是，这些变换是可训练的，并且不必互为逆矩阵，也不强制要求是方阵。此外，LIDIA 还包括了多尺度处理，同时在多个尺度上处理补丁。在处理过程中，不同尺度的对应补丁通过一个学习的联合变换进行融合。最后，通过将去噪后的补丁还原到其原始位置并利用学习到的权重平均重叠部分，从而获得重建的图像。'
- en: 'The LIDIA network is trained end-to-end (excluding the nearest-neighbor part)
    by minimizing the MSE loss, similar to the loss in Equation [12](#S5.E12 "Equation
    12 ‣ 5.1 Deep K-SVD ‣ 5 Synergy between Classics and Deep Learning ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"), applied on a set
    of $M$ training images. The network can be trained for a specific noise level
    $\sigma$ or blindly, aiming to serve a range of $\sigma$ values. LIDIA performs
    much better than the original BM3D algorithm since it uses learned rather than
    fixed transforms. Compared with other deep-learning techniques LIDIA achieves
    comparable results, while using a small fraction of the typical number of learned
    parameters.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 'LIDIA 网络通过最小化 MSE 损失（与方程 [12](#S5.E12 "Equation 12 ‣ 5.1 Deep K-SVD ‣ 5 Synergy
    between Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") 中的损失类似），在一组 $M$ 个训练图像上进行端到端的训练（不包括最近邻部分）。该网络可以针对特定的噪声水平
    $\sigma$ 进行训练，也可以进行盲训练，旨在服务于一系列的 $\sigma$ 值。由于 LIDIA 使用的是学习得到的变换而非固定变换，因此它的表现比原始
    BM3D 算法要好。与其他深度学习技术相比，LIDIA 达到了可比的结果，同时使用了典型的少量学习参数。'
- en: 'In Section [4](#S4 "4 Image Denoising – The Deep Learning Revolution ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") we mentioned
    the ability to adapt a given denoiser to newly coming images that deviate from
    the training set. This adaptation starts by applying the trained denoiser, and
    then uses the output in order to fine-tune the denoiser parameters by applying
    few gradient steps. This rationale has been successfully demonstrated with LIDIA,
    and two such illustrative results are brought in Figure [6](#S5.F6 "Figure 6 ‣
    5.2 LIDIA - Lightweight Learned Image Denoising ‣ 5 Synergy between Classics and
    Deep Learning ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –").'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 在第[4](#S4 "4 图像去噪 – 深度学习革命 ‣ 图像去噪：深度学习革命及其未来 – 综述论文 –")节中，我们提到将给定的去噪器适应于新出现的偏离训练集的图像的能力。这种适应从应用训练好的去噪器开始，然后利用输出结果通过几个梯度步骤来微调去噪器参数。这一原理已经在LIDIA中成功演示，图[6](#S5.F6
    "图6 ‣ 5.2 LIDIA - 轻量级学习图像去噪 ‣ 经典方法与深度学习的协同作用 ‣ 图像去噪：深度学习革命及其未来 – 综述论文 –")中展示了两个这样的示例结果。
- en: '![Refer to caption](img/0d7ac1291c6fb0dcca45a6244d4254aa.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0d7ac1291c6fb0dcca45a6244d4254aa.png)'
- en: (a) Clean
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 清晰
- en: '![Refer to caption](img/a8db98410d2e082a2fc8d76f3dbfb3dc.png)'
  id: totrans-183
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a8db98410d2e082a2fc8d76f3dbfb3dc.png)'
- en: (b) Noisy, ${\sigma=50}$
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 噪声, ${\sigma=50}$
- en: '![Refer to caption](img/d09980bd0c439843978ba3f61063f407.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d09980bd0c439843978ba3f61063f407.png)'
- en: (c) Denoised, $24.22$dB
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 去噪, $24.22$dB
- en: '![Refer to caption](img/afc6ef07bc3aa36073ab6d8a89ddc431.png)'
  id: totrans-187
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/afc6ef07bc3aa36073ab6d8a89ddc431.png)'
- en: (d) Adapted, $26.34$dB
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 适应, $26.34$dB
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![Refer to caption](img/9ac2069983d8a4d91b096b4a535783bd.png)</foreignobject></g></g></g></svg>
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![参见说明](img/9ac2069983d8a4d91b096b4a535783bd.png)</foreignobject></g></g></g></svg>
- en: (e) Clean
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: (e) 清晰
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![Refer to caption](img/f3178ea8f08af4c252dc51cceb88b7d4.png)</foreignobject></g></g></g></svg>
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![参见说明](img/f3178ea8f08af4c252dc51cceb88b7d4.png)</foreignobject></g></g></g></svg>
- en: (f) Noisy, ${\sigma=50}$
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: (f) 噪声, ${\sigma=50}$
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![Refer to caption](img/318a7d60b7a89e73b5d790cf30a6b94b.png)</foreignobject></g></g></g></svg>
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![参见说明](img/318a7d60b7a89e73b5d790cf30a6b94b.png)</foreignobject></g></g></g></svg>
- en: (g) Denoised, $22.10$dB
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: (g) 去噪, $22.10$dB
- en: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![Refer to caption](img/842798629e878224506a8b512a23e991.png)</foreignobject></g></g></g></svg>
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="373" overflow="visible"><g transform="translate(0,373)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,373) scale(1,
    -1)"><foreignobject width="598" height="373" overflow="visible">![参见说明](img/842798629e878224506a8b512a23e991.png)</foreignobject></g></g></g></svg>
- en: (h) Adapted, $25.82$dB
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: (h) 适应, $25.82$dB
- en: 'Figure 6: Image adaptation via LIDIA: The original denoising network is trained
    for general content images, and performs reasonably well for astronomy and scanned
    document inputs. A substantial boost in denoising performance is obtained for
    these two examples, due to their deviation from the training set.'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '图6: 通过LIDIA进行图像适应：原始的去噪网络是针对通用内容图像进行训练的，对于天文学和扫描文档输入表现良好。由于这两个示例偏离了训练集，因此在去噪性能上获得了显著提升。'
- en: 5.3 Summary - The classics is still here
  id: totrans-198
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 总结 - 经典方法依然存在
- en: We described two unfolding instances in which classic denoising algorithms provide
    their architecture for the learned network. These and other such methods [[341](#bib.bib341),
    [250](#bib.bib250), [83](#bib.bib83), [204](#bib.bib204)], targeting various image
    recovery tasks, offer a constructive path towards well-motivated, low complexity
    and explainable neural architectures. In the quest for a synergy between classical
    denoising methods and novel deep-learning alternatives, this is probably the most
    natural manifestation of it.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 我们描述了两个展开实例，其中经典去噪算法提供了其架构以供学习网络使用。这些以及其他类似方法 [[341](#bib.bib341)、[250](#bib.bib250)、[83](#bib.bib83)、[204](#bib.bib204)]，针对各种图像恢复任务，提供了一条建设性路径，通向有充分动机的、低复杂度且可解释的神经架构。在经典去噪方法与新颖深度学习替代方案之间寻找协同效应时，这可能是最自然的体现。
- en: 6 Image Denoising – Migration towards Recent Discoveries
  id: totrans-200
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 图像去噪 – 向近期发现迁移
- en: 'The clear conclusions from the above discussion are these: Highly effective
    image denoisers for AWGN removal, $D({\mathbf{y}},\sigma)$, are definitely within
    reach, and the better ones are likely to be deep-learning based algorithms. In
    an attempt to illustrate these statements, Figures [7](#S6.F7 "Figure 7 ‣ 6 Image
    Denoising – Migration towards Recent Discoveries ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") and [8](#S6.F8 "Figure 8 ‣ 6 Image
    Denoising – Migration towards Recent Discoveries ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") present denoising results for two test
    images, two noise levels ($\sigma=15,50$) and by several denoisers – NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], and SwinIR (a transformer-based
    denoising network) [[165](#bib.bib165)]. As can be seen, the results are very
    impressive and more so by the later deep neural network solutions.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 从以上讨论中可以得出明确的结论：针对 AWGN 去噪的高效图像去噪算法 $D({\mathbf{y}},\sigma)$ 确实触手可及，而更好的算法很可能是基于深度学习的算法。为了说明这些观点，图
    [7](#S6.F7 "图 7 ‣ 6 图像去噪 – 向近期发现迁移 ‣ 图像去噪：深度学习革命及其超越 – 调研论文 –") 和 [8](#S6.F8 "图
    8 ‣ 6 图像去噪 – 向近期发现迁移 ‣ 图像去噪：深度学习革命及其超越 – 调研论文 –") 展示了两张测试图像的去噪结果，噪声水平为两个 ($\sigma=15,50$)
    和几种去噪算法 – NLM [[32](#bib.bib32)]、BM3D [[61](#bib.bib61)]、DnCNN [[330](#bib.bib330)]
    和 SwinIR（基于变换器的去噪网络） [[165](#bib.bib165)]。可以看出，结果非常令人印象深刻，尤其是后来的深度神经网络解决方案。
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/5647162749e70a1c60c9489a5d29a2cd.png)</foreignobject></g></g></g></svg>
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见标题](img/5647162749e70a1c60c9489a5d29a2cd.png)</foreignobject></g></g></g></svg>
- en: (a) Clean
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 清晰
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/37615ae04fbb3b0b526c9211319fd324.png)</foreignobject></g></g></g></svg>
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见标题](img/37615ae04fbb3b0b526c9211319fd324.png)</foreignobject></g></g></g></svg>
- en: (b) Noisy, ${\sigma=50}$
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 含噪，${\sigma=50}$
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/db5f15ef94676f49f5b5d3e33f05ac41.png)</foreignobject></g></g></g></svg>
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见标题](img/db5f15ef94676f49f5b5d3e33f05ac41.png)</foreignobject></g></g></g></svg>
- en: (c) NLM, $24.67$dB
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: (c) NLM，$24.67$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/71a936452ee7bc41ccf45e0b3897ab28.png)</foreignobject></g></g></g></svg>
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见标题](img/71a936452ee7bc41ccf45e0b3897ab28.png)</foreignobject></g></g></g></svg>
- en: (d) BM3D, $26.31$dB
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: (d) BM3D，$26.31$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/42261bd39654c90164a7f3fde81739c2.png)</foreignobject></g></g></g></svg>
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/42261bd39654c90164a7f3fde81739c2.png)</foreignobject></g></g></g></svg>
- en: (e) DnCNN, $26.70$dB
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: (e) DnCNN，$26.70$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/dc4f46cde577b45055480c6f9c37149b.png)</foreignobject></g></g></g></svg>
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/dc4f46cde577b45055480c6f9c37149b.png)</foreignobject></g></g></g></svg>
- en: (f) SwinIR, $27.31$dB
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: (f) SwinIR，$27.31$dB
- en: 'Figure 7: Demonstration (1) of several denoising methods: (NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], SwinIR [[165](#bib.bib165)]).'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：几种去噪方法的演示（1）：（NLM [[32](#bib.bib32)]，BM3D [[61](#bib.bib61)]，DnCNN [[330](#bib.bib330)]，SwinIR [[165](#bib.bib165)]）。
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/4569d9cdf37e55b6ff10a2e0a9b084a8.png)</foreignobject></g></g></g></svg>
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/4569d9cdf37e55b6ff10a2e0a9b084a8.png)</foreignobject></g></g></g></svg>
- en: (a) Clean
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 清晰
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/32111224538c27275bd8b9625f7c6753.png)</foreignobject></g></g></g></svg>
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/32111224538c27275bd8b9625f7c6753.png)</foreignobject></g></g></g></svg>
- en: (b) Noisy, ${\sigma=15}$
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 噪声，${\sigma=15}$
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/a2b4a7135bb660db1cb3bd29791baac3.png)</foreignobject></g></g></g></svg>
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/a2b4a7135bb660db1cb3bd29791baac3.png)</foreignobject></g></g></g></svg>
- en: (c) NLM, $33.82$dB
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: (c) NLM，$33.82$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/3422dcefec62c73a4950fa073654b895.png)</foreignobject></g></g></g></svg>
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/3422dcefec62c73a4950fa073654b895.png)</foreignobject></g></g></g></svg>
- en: (d) BM3D, $36.23$dB
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: (d) BM3D，$36.23$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/48b7b61f5a1905a323c75aee036bb632.png)</foreignobject></g></g></g></svg>
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/48b7b61f5a1905a323c75aee036bb632.png)</foreignobject></g></g></g></svg>
- en: (e) DnCNN, $36.33$dB
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: (e) DnCNN，$36.33$dB
- en: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![Refer to caption](img/e5dc8f68cd58c563927e484431b483a3.png)</foreignobject></g></g></g></svg>
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: <svg version="1.1" width="598" height="484" overflow="visible"><g transform="translate(0,484)
    scale(1,-1)"><g  transform="translate(0,0)"><g transform="translate(0,78) scale(1,
    -1)"><foreignobject width="664" height="78" overflow="visible">![参见说明](img/e5dc8f68cd58c563927e484431b483a3.png)</foreignobject></g></g></g></svg>
- en: (f) SwinIR, $37.17$dB
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: (f) SwinIR, $37.17$dB
- en: 'Figure 8: Demonstration (2) of several denoising methods: (NLM [[32](#bib.bib32)],
    BM3D [[61](#bib.bib61)], DnCNN [[330](#bib.bib330)], SwinIR [[165](#bib.bib165)]).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：几种去噪方法的演示（2）：（NLM [[32](#bib.bib32)]，BM3D [[61](#bib.bib61)]，DnCNN [[330](#bib.bib330)]，SwinIR
    [[165](#bib.bib165)]）。
- en: 'We now turn to ask far more daring questions with regard to such denoisers,
    focusing this time on their deployment to other tasks. More specifically, we discuss
    three such questions, each corresponding to a recent discovery in the field of
    imaging sciences:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在转向提出更为大胆的问题，关注这些去噪器的其他任务应用。更具体地说，我们讨论了三个这样的问提，每个问题都对应于成像科学领域的最新发现：
- en: •
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Discovery 1: Can we leverage a denoiser $D({\mathbf{y}},\sigma)$ for solving
    general linear inverse problems? As we shall shortly see, the answer to this question
    is positive and constructive, opening new horizons for design of recovery algorithms
    and their regularization.'
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发现 1：我们能否利用去噪器 $D({\mathbf{y}},\sigma)$ 来解决一般线性反问题？如我们将要看到的，答案是肯定且具有建设性的，为恢复算法的设计及其正则化开辟了新视野。
- en: •
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Discovery 2: Can we leverage a denoiser $D({\mathbf{y}},\sigma)$ for synthesizing
    (hallucinating) high-quality images, fairly drawn from the prior probability density
    function $p({\mathbf{x}})$? Here again the answer is positive and constructive,
    offering a thrilling new line of activity in machine learning.'
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发现 2：我们能否利用去噪器 $D({\mathbf{y}},\sigma)$ 合成（幻觉）高质量图像，这些图像来自先验概率密度函数 $p({\mathbf{x}})$？在这里，答案同样是肯定且具有建设性的，为机器学习领域提供了激动人心的新方向。
- en: •
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Discovery 3: If hallucination of perfect-looking images is achievable, can
    we revisit the topic of general linear inverse problems and leverage a denoiser
    $D({\mathbf{y}},\sigma)$ for their solution while targeting *perfect perceptual
    quality* results? Here again we give a positive answer, and lead to a new and
    inspiring branch of research in inverse problems, offering novel view of their
    treatment.'
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 发现 3：如果完美图像的幻觉是可以实现的，那么我们能否重新审视一般线性反问题的主题，并利用去噪器 $D({\mathbf{y}},\sigma)$ 解决这些问题，同时瞄准*完美的感知质量*结果？在这里，我们同样给出了肯定的答案，并引领了一个新的、激发人心的反问题研究分支，提供了对其处理的新视角。
- en: Below we discuss each of these discoveries in greater details. It is our sincere
    belief that these together form one of the most exciting eras for our field, marking
    a major transition in how image processing is perceived and practiced.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来我们将详细讨论这些发现。我们真诚地相信，这些发现共同构成了我们领域最激动人心的时代之一，标志着图像处理认知和实践的重大转变。
- en: '7 Discovery 1: Solving Inverse Problems via Image Denoisers'
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 发现 1：通过图像去噪器解决反问题
- en: Given a denoiser $D({\mathbf{y}},\sigma):\mathbb{R}^{N}\rightarrow\mathbb{R}^{N}$,
    our goal is to use it somehow for solving general linear inverse problems of the
    form
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个去噪器 $D({\mathbf{y}},\sigma):\mathbb{R}^{N}\rightarrow\mathbb{R}^{N}$，我们的目标是以某种方式利用它来解决形式为的线性反问题
- en: '| (13) |  | $\displaystyle{\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}},$
    |  |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| (13) |  | $\displaystyle{\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}},$
    |  |'
- en: where ${\mathbf{H}}\in\mathbb{R}^{M\times N}$ is a known matrix, ${\mathbf{v}}\in\mathbb{R}^{M}$
    is AWGN, and ${\mathbf{y}}\in\mathbb{R}^{M}$ is the given measurement vector.
    Observe that ${\mathbf{H}}={\mathbf{I}}$ stands for the denoising problem. Therefore,
    the current discussion extends our view to a wider family of tasks in imaging
    sciences, covering applications such as deblurring, inpainting, demosaicing, super-resolution,
    tomographic reconstruction, compressed sensing, and more.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\mathbf{H}}\in\mathbb{R}^{M\times N}$ 是已知矩阵，${\mathbf{v}}\in\mathbb{R}^{M}$
    是加性高斯白噪声，${\mathbf{y}}\in\mathbb{R}^{M}$ 是给定的测量向量。注意到 ${\mathbf{H}}={\mathbf{I}}$
    代表去噪问题。因此，当前讨论将我们的视野扩展到成像科学中更广泛的任务，涵盖去模糊、修补、去马赛克、超分辨率、断层重建、压缩感知等应用。
- en: 'Following the derivations in Section [3](#S3 "3 Image Denoising – The Classic
    Era ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper
    –") and specifically Equation ([6](#S3.E6 "Equation 6 ‣ 3.1 The Bayesian Point
    of View for Design of Denoisers ‣ 3 Image Denoising – The Classic Era ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), we can
    adopt the Bayesian point of view and obtain the MAP estimation for this family
    of problems:'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 根据第[3](#S3 "3 图像去噪 – 经典时代 ‣ 图像去噪：深度学习革命及其未来 – 综述论文 –")节的推导，特别是方程([6](#S3.E6
    "方程 6 ‣ 3.1 设计去噪器的贝叶斯观点 ‣ 3 图像去噪 – 经典时代 ‣ 图像去噪：深度学习革命及其未来 – 综述论文 –"))，我们可以采用贝叶斯观点并获得这个问题系列的最大后验估计：
- en: '| (14) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
  zh: '| (14) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right].$
    |  |'
- en: Plugging in the Gibbs distribution form for the prior, $p({\mathbf{x}})\sim\exp\{-\rho({\mathbf{x}})\}$,
    this becomes
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 将Gibbs分布形式的先验代入，$p({\mathbf{x}})\sim\exp\{-\rho({\mathbf{x}})\}$，这变成了
- en: '| (15) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{x}})\right].$
    |  |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| (15) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{x}})\right].$
    |  |'
- en: 'Clearly, the greatest riddle posed above has to do with the identity of the
    energy function $\rho({\mathbf{x}})$. Can a denoiser serve all linear inverse
    problems in a unified approach by providing a connection or an alternative to
    $\rho({\mathbf{x}})$? Surprisingly, the answer to this question is positive and
    constructive. The seminal Plug-and-Play Prior (PnP) work by Venkatakrishnan, Bouman
    and Wohlberg [[295](#bib.bib295)] was the first to provide such an answer⁷⁷7We
    should note that an alternative, yet closely related, derivation is offered in [[196](#bib.bib196)]
    from an approximate message passing point of view., followed and improved upon
    by RED (Regularization by Denoising) [[231](#bib.bib231)]. These and their various
    extensions and variations have created a vivid and stimulating sub-field of research
    in imaging sciences [[28](#bib.bib28), [139](#bib.bib139), [283](#bib.bib283),
    [34](#bib.bib34), [268](#bib.bib268), [41](#bib.bib41), [192](#bib.bib192), [280](#bib.bib280),
    [5](#bib.bib5), [49](#bib.bib49), [55](#bib.bib55)] in which denoisers play a
    central role. Below we describe PnP and RED in more detail, and then turn to describe
    another, perhaps better founded, bridge between denoisers and the energy function
    $\rho({\mathbf{x}})$ via the *score function*. This would serve our next step
    towards diffusion models, as they unravel in Section [8](#S8 "8 Discovery 2: Image
    Synthesis via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") and beyond.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 显然，上述最大谜团与能量函数$\rho({\mathbf{x}})$的身份有关。去噪器是否可以通过提供与$\rho({\mathbf{x}})$的连接或替代来统一处理所有线性反问题？令人惊讶的是，这个问题的答案是肯定的，并且具有建设性。Venkatakrishnan、Bouman和Wohlberg的开创性工作[[295](#bib.bib295)]首次提供了这样的答案⁷⁷7我们应该注意到，另一种紧密相关的推导是从近似消息传递的角度提供的，见[[196](#bib.bib196)]。其后由RED（通过去噪进行正则化）[[231](#bib.bib231)]进行跟进和改进。这些及其各种扩展和变体在成像科学领域创造了一个生动且激动人心的子领域[[28](#bib.bib28),
    [139](#bib.bib139), [283](#bib.bib283), [34](#bib.bib34), [268](#bib.bib268),
    [41](#bib.bib41), [192](#bib.bib192), [280](#bib.bib280), [5](#bib.bib5), [49](#bib.bib49),
    [55](#bib.bib55)]，在其中去噪器扮演了核心角色。下面我们将更详细地描述PnP和RED，然后转向描述另一种可能更有基础的去噪器与能量函数$\rho({\mathbf{x}})$之间的桥梁，通过*评分函数*。这将为我们迈向扩散模型的下一步提供基础，因为它们在第[8](#S8
    "8 发现 2：通过图像去噪器合成图像 ‣ 图像去噪：深度学习革命及其后续 – 调研论文 –")节及以后展现。
- en: 7.1 Plug-and-Play Prior (PnP)
  id: totrans-245
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 插拔式先验（PnP）
- en: 'PnP [[295](#bib.bib295)] suggests the following steps in handling the minimization
    of the problem posed in Equation ([15](#S7.E15 "Equation 15 ‣ 7 Discovery 1: Solving
    Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")): We start by splitting the variable ${\mathbf{x}}$
    by defining ${\mathbf{z}}={\mathbf{x}}$ and expressing each of the two penalties
    with a different variable:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: PnP [[295](#bib.bib295)]建议以下步骤来处理方程([15](#S7.E15 "方程 15 ‣ 7 发现 1：通过图像去噪器解决反问题
    ‣ 图像去噪：深度学习革命及其后续 – 调研论文 –"))中提出的最小化问题：我们首先通过定义${\mathbf{z}}={\mathbf{x}}$来拆分变量${\mathbf{x}}$，并用不同的变量表达两个惩罚项：
- en: '| (16) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}},{\mathbf{z}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})\right]~{}~{}\operatorname*{s.t.}~{}~{}{\mathbf{z}}={\mathbf{x}}.$
    |  |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| (16) |  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}=\operatorname*{arg\,min}_{{\mathbf{x}},{\mathbf{z}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})\right]~{}~{}\operatorname*{s.t.}~{}~{}{\mathbf{z}}={\mathbf{x}}.$
    |  |'
- en: The next step forms the Augmented Lagrangian of the above problem, converting
    the constraint into a penalty,
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 下一步是形成上述问题的增广拉格朗日形式，将约束转换为惩罚项，
- en: '| (17) |  | $\displaystyle L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})=\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}-\lambda\&#124;{\mathbf{u}}\&#124;_{2}^{2},$
    |  |'
  id: totrans-249
  prefs: []
  type: TYPE_TB
  zh: '| (17) |  | $\displaystyle L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})=\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}-\lambda\&#124;{\mathbf{u}}\&#124;_{2}^{2},$
    |  |'
- en: 'where ${\mathbf{u}}$ is the scaled dual variable and $\lambda$ is an (arbitrary)
    penalty weight (see more in [[295](#bib.bib295)]). The third and final step applies
    ADMM [[27](#bib.bib27)] for the minimization of $L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})$
    with respect to ${\mathbf{x}}$ and ${\mathbf{z}}$ while updating ${\mathbf{u}}$.
    These are obtained by alternating between the treatment of each variable while
    fixing the others:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\mathbf{u}}$ 是缩放的对偶变量，$\lambda$ 是一个（任意的）惩罚权重（见更多内容于 [[295](#bib.bib295)]）。第三步和最后一步应用
    ADMM [[27](#bib.bib27)] 来最小化 $L({\mathbf{x}},{\mathbf{z}},{\mathbf{u}})$，在更新 ${\mathbf{u}}$
    的同时相对于 ${\mathbf{x}}$ 和 ${\mathbf{z}}$ 进行优化。这些是通过在固定其他变量的同时交替处理每个变量来获得的：
- en: '| (18) |  | $\displaystyle{\mathbf{x}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right]=\left[{\mathbf{H}}^{T}{\mathbf{H}}+\lambda{\mathbf{I}}\right]^{-1}\left[{\mathbf{H}}^{T}{\mathbf{y}}+{\mathbf{z}}-{\mathbf{u}}\right],$
    |  |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| (18) |  | $\displaystyle{\mathbf{x}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right]=\left[{\mathbf{H}}^{T}{\mathbf{H}}+\lambda{\mathbf{I}}\right]^{-1}\left[{\mathbf{H}}^{T}{\mathbf{y}}+{\mathbf{z}}-{\mathbf{u}}\right],$
    |  |'
- en: '| (19) |  | $\displaystyle{\mathbf{z}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{z}}}\left[c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right],$
    |  |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
  zh: '| (19) |  | $\displaystyle{\mathbf{z}}$ | $\displaystyle\leftarrow$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{z}}}\left[c\cdot\rho({\mathbf{z}})+\lambda\&#124;{\mathbf{z}}-{\mathbf{x}}+{\mathbf{u}}\&#124;_{2}^{2}\right],$
    |  |'
- en: '| (20) |  | $\displaystyle{\mathbf{u}}$ | $\displaystyle\leftarrow$ | $\displaystyle{\mathbf{u}}+({\mathbf{x}}-{\mathbf{z}}).$
    |  |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
  zh: '| (20) |  | $\displaystyle{\mathbf{u}}$ | $\displaystyle\leftarrow$ | $\displaystyle{\mathbf{u}}+({\mathbf{x}}-{\mathbf{z}}).$
    |  |'
- en: 'In the above, the first update equation amounts to a simple Least-Squares,
    which does not involve $\rho({\mathbf{x}})$. The true drama takes place in the
    second update formula – observe its close resemblance to Equation ([6](#S3.E6
    "Equation 6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers ‣ 3 Image
    Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution and
    Beyond – A Survey Paper –")), which formulates an image denoising task. Indeed,
    instead of choosing/guessing/learning $\rho({\mathbf{x}})$, we can apply our favorite
    denoiser ${\hat{\mathbf{z}}}=D({\mathbf{x}}-{\mathbf{u}},\sigma_{0})$ where $\sigma_{0}$
    should be inversely proportional to $\lambda/c$. This way, PnP offers an appealing
    iterative algorithm that repeatedly applies a denoiser in order to handle any
    underlying inverse problem, just as promised.'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '在上述内容中，第一个更新方程相当于一个简单的最小二乘问题，不涉及 $\rho({\mathbf{x}})$。真正的难点在第二个更新公式中——观察它与公式
    ([6](#S3.E6 "Equation 6 ‣ 3.1 The Bayesian Point of View for Design of Denoisers
    ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")) 的相似之处，这个公式制定了一个图像去噪任务。确实，与其选择/猜测/学习 $\rho({\mathbf{x}})$，我们可以应用我们喜欢的去噪器
    ${\hat{\mathbf{z}}}=D({\mathbf{x}}-{\mathbf{u}},\sigma_{0})$，其中 $\sigma_{0}$ 应与
    $\lambda/c$ 成反比。这样，PnP 提供了一个有吸引力的迭代算法，重复应用去噪器来处理任何潜在的逆问题，正如承诺的那样。'
- en: While the original PnP paper did not dive into the issue of convergence of the
    above ADMM algorithm, nor posed conditions on the denoiser to support such guarantees,
    later work offers such a theoretical discussion – we refer the interested readers
    to [[42](#bib.bib42), [309](#bib.bib309), [269](#bib.bib269), [155](#bib.bib155)].
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管原始的 PnP 论文没有深入探讨上述 ADMM 算法的收敛问题，也没有对去噪器提出支持这种保证的条件，但后续的研究提供了这样的理论讨论——我们建议感兴趣的读者参见
    [[42](#bib.bib42), [309](#bib.bib309), [269](#bib.bib269), [155](#bib.bib155)]。
- en: 7.2 Regularization by Denoising (RED)
  id: totrans-256
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 通过去噪进行正则化 (RED)
- en: 'An alternative angle towards the relationship between $\rho({\mathbf{x}})$
    and image denoising is presented in [[231](#bib.bib231)]. The core idea is quite
    simple, using the following explicit formula for $\rho({\mathbf{x}})$ that relies
    on a denoiser:'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 $\rho({\mathbf{x}})$ 与图像去噪之间关系的另一种角度在 [[231](#bib.bib231)] 中提出。核心思想非常简单，使用以下依赖于去噪器的
    $\rho({\mathbf{x}})$ 明确公式：
- en: '| (21) |  | $\displaystyle\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
  id: totrans-258
  prefs: []
  type: TYPE_TB
  zh: '| (21) |  | $\displaystyle\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
- en: 'The intuition behind this expression can be uncovered by considering a linearized
    form of the denoising process, $D({\mathbf{x}},\sigma_{0})=S({\mathbf{x}}){\mathbf{x}}$,
    where $S({\mathbf{x}})$ is an image-dependent matrix that represents the smoothing
    applied by the noise removal process. This way, the chosen energy function becomes
    $\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{I}}-S({\mathbf{x}})\right]{\mathbf{x}}$,
    which is a Laplacian smoothness prior of the kind described in Section [3](#S3
    "3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –"), although being image-adaptive (and thus far more
    effective).'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '理解这个表达式的直观方法是考虑去噪过程的线性化形式，$D({\mathbf{x}},\sigma_{0})=S({\mathbf{x}}){\mathbf{x}}$，其中$S({\mathbf{x}})$是一个图像依赖的矩阵，表示去噪过程中应用的平滑。这样，选择的能量函数变为$\rho({\mathbf{x}})={\mathbf{x}}^{T}\left[{\mathbf{I}}-S({\mathbf{x}})\right]{\mathbf{x}}$，这是类似于第
    [3](#S3 "3 Image Denoising – The Classic Era ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")节中描述的拉普拉斯平滑先验，尽管它是自适应图像的（因此效果更佳）。'
- en: 'The work in [[231](#bib.bib231)] shows that if the denoiser $D({\mathbf{x}},\sigma_{0})$
    is differentiable, passive and of symmetric Jacobian, the chosen energy function
    in Equation ([21](#S7.E21 "Equation 21 ‣ 7.2 Regularization by Denoising (RED)
    ‣ 7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")) is guaranteed to
    be convex. If, in addition, the denoiser satisfies a local homogeneity property⁸⁸8See
    [[231](#bib.bib231)] for the exact definitions of these ingredients and for the
    proof of their implications., then the following relationship holds:'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '工作[[231](#bib.bib231)]表明，如果去噪器$D({\mathbf{x}},\sigma_{0})$是可微的、被动的且具有对称雅可比矩阵，则方程
    ([21](#S7.E21 "Equation 21 ‣ 7.2 Regularization by Denoising (RED) ‣ 7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –"))中选择的能量函数保证是凸的。如果此外去噪器满足局部同质性属性⁸⁸8参见[[231](#bib.bib231)]了解这些成分的确切定义及其含义的证明，则以下关系成立：'
- en: '| (22) |  | $\displaystyle\nabla_{{\mathbf{x}}}\rho({\mathbf{x}})=2\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| (22) |  | $\displaystyle\nabla_{{\mathbf{x}}}\rho({\mathbf{x}})=2\left[{\mathbf{x}}-D({\mathbf{x}},\sigma_{0})\right].$
    |  |'
- en: 'This relationship is a centerpiece in the construction of several RED algorithms.
    Plugging the chosen $\rho({\mathbf{x}})$ from Equation ([21](#S7.E21 "Equation
    21 ‣ 7.2 Regularization by Denoising (RED) ‣ 7 Discovery 1: Solving Inverse Problems
    via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –")) into Equation ([15](#S7.E15 "Equation 15 ‣ 7 Discovery 1:
    Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")) implies that the gradient of this
    functional is easily accessible, requiring a single activation of the chosen denoiser.
    Critically, this gradient does not require the differentiation of $D({\mathbf{x}},\sigma_{0})$,
    which would have required far more computational power and memory consumption.
    As a consequence, various gradient-based optimization strategies can be applied
    for computing ${\hat{\mathbf{x}}}_{MAP}$, and all are guaranteed to converge to
    the global minimizer of the MAP penalty. Again, we arrive at iterative algorithms
    that apply simple linear operations and a denoiser in each step, aiming to solve
    general linear inverse problems.'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '这种关系是构建多个RED算法的核心。在将方程 ([21](#S7.E21 "Equation 21 ‣ 7.2 Regularization by Denoising
    (RED) ‣ 7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")) 中选择的$\rho({\mathbf{x}})$代入方程
    ([15](#S7.E15 "Equation 15 ‣ 7 Discovery 1: Solving Inverse Problems via Image
    Denoisers ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –"))时，这个泛函的梯度容易获取，只需激活一次选择的去噪器。关键是，这个梯度不需要对$D({\mathbf{x}},\sigma_{0})$进行求导，这将需要更多的计算能力和内存消耗。因此，可以应用各种基于梯度的优化策略来计算${\hat{\mathbf{x}}}_{MAP}$，所有这些策略都保证收敛到MAP惩罚的全局最小值。我们再次得到迭代算法，在每一步中应用简单的线性操作和去噪器，旨在解决一般线性逆问题。'
- en: An intriguing question with respect to the above is the identity of the denoiser
    to use within RED. Should it be an MMSE denoiser? Should it be designed to remove
    AWGN? Would these choices lead to the required properties mentioned above (diffentiability,
    symmetry, passivity, homogeneity)? What should $\sigma_{0}$ be? Partial answers
    to these questions are given by the next discussion on the *score function*.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 关于上述内容，一个引人入胜的问题是，在 RED 中使用的去噪器的身份。它应该是一个 MMSE 去噪器吗？它应该设计为去除 AWGN 吗？这些选择会导致上述所提到的所需属性（可微性、对称性、无源性、齐次性）吗？$\sigma_{0}$
    应该是多少？这些问题的部分答案由下文对*得分函数*的讨论给出。
- en: 7.3 The Score Function and its Relevance to Inverse Problems
  id: totrans-264
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 得分函数及其对逆问题的相关性
- en: 'Embarking from Equations ([14](#S7.E14 "Equation 14 ‣ 7 Discovery 1: Solving
    Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")) and ([15](#S7.E15 "Equation 15 ‣ 7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")), we now present a very different approach
    towards getting to the same RED formulation, regularizing inverse problems via
    a denoiser. Assume that our goal is to find ${\hat{\mathbf{x}}}_{MAP}$ by Steepest
    Descent (SD), and thus our iterative formula should be'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 从方程 ([14](#S7.E14 "方程 14 ‣ 7 发现 1：通过图像去噪器解决逆问题 ‣ 图像去噪：深度学习革命及其超越 – 综述论文 –"))
    和 ([15](#S7.E15 "方程 15 ‣ 7 发现 1：通过图像去噪器解决逆问题 ‣ 图像去噪：深度学习革命及其超越 – 综述论文 –")) 出发，我们现在提出了一种非常不同的方法来获得相同的
    RED 公式，通过去噪器对逆问题进行正则化。假设我们的目标是通过最速下降（SD）找到 ${\hat{\mathbf{x}}}_{MAP}$，因此我们的迭代公式应为
- en: '| (23) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})-c\cdot\nabla_{{\mathbf{x}}}\log
    p({\mathbf{x}})&#124;_{{\hat{\mathbf{x}}}_{k}}\right].$ |  |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| (23) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})-c\cdot\nabla_{{\mathbf{x}}}\log
    p({\mathbf{x}})&#124;_{{\hat{\mathbf{x}}}_{k}}\right].$ |  |'
- en: The term $\nabla_{{\mathbf{x}}}\log p({\mathbf{x}})$ is known in the statistical
    literature as the *score function*, being a flow-field that describes the optimal
    ascent direction over the log of the prior. An old mathematical result, commonly
    attributed to Miyasawa [[200](#bib.bib200)], Stein [[265](#bib.bib265)], or Tweedie [[84](#bib.bib84)],
    and re-exposed in [[138](#bib.bib138)], proves that
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在统计文献中，术语 $\nabla_{{\mathbf{x}}}\log p({\mathbf{x}})$ 被称为*得分函数*，它是一个描述对先验对数的最优上升方向的流场。一个古老的数学结果，通常归因于
    Miyasawa [[200](#bib.bib200)]、Stein [[265](#bib.bib265)] 或 Tweedie [[84](#bib.bib84)]，并在
    [[138](#bib.bib138)] 中重新提出，证明了
- en: '| (24) |  | $\nabla_{\mathbf{y}}\log p(\mathbf{y})=\frac{D(\mathbf{y},\sigma_{0})-\mathbf{y}}{\sigma_{0}^{2}},$
    |  |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| (24) |  | $\nabla_{\mathbf{y}}\log p(\mathbf{y})=\frac{D(\mathbf{y},\sigma_{0})-\mathbf{y}}{\sigma_{0}^{2}},$
    |  |'
- en: 'where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$ is a noisy version of ${\mathbf{x}}$
    with ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$, and
    $D(\mathbf{y},\sigma_{0})$ should be the optimal Minimum Mean Squared Error (MMSE)
    denoiser, $\mathbb{E}(\mathbf{x}|\mathbf{y})$. A proof of this result is brought
    in Appendix [D](#A4 "Appendix D Approximation of the Score Function by an MMSE
    Denoiser ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –").'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$ 是 ${\mathbf{x}}$ 的带噪声版本，${\mathbf{v}}\sim{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$，$D(\mathbf{y},\sigma_{0})$ 应该是最优的最小均方误差（MMSE）去噪器，$\mathbb{E}(\mathbf{x}|\mathbf{y})$。这一结果的证明见附录
    [D](#A4 "附录 D 通过 MMSE 去噪器对得分函数的近似 ‣ 图像去噪：深度学习革命及其超越 – 综述论文 –")。
- en: 'While it is impossible to obtain the MMSE denoiser (as $p(\mathbf{x})$ is unknown),
    modern deep learning-based denoisers perform very well (see Figure [2](#S4.F2
    "Figure 2 ‣ 1st item ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), and
    therefore constitute a good approximation for it. And so, while Equation ([23](#S7.E23
    "Equation 23 ‣ 7.3 The Score Function and its Relevance to Inverse Problems ‣
    7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –")) expects to use the
    score function that refers to $p({\mathbf{x}})$, a denoiser can provide an approximation
    of it that considers a slightly blurry probability density function⁹⁹9See Appendix
    [D](#A4 "Appendix D Approximation of the Score Function by an MMSE Denoiser ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    for a justification of this claim. $p({\mathbf{y}})=p({\mathbf{x}})\otimes{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$. When $\sigma_{0}$ is small enough^(10)^(10)10RED [[231](#bib.bib231)]
    suggests to use $\sigma_{0}\approx 3-5$ for images with $256\times 256$ gray-values.,
    this approximation becomes very effective and the resulting algorithm admits the
    following update rule:'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然无法获得 MMSE 去噪器（因为 $p(\mathbf{x})$ 是未知的），但现代基于深度学习的去噪器表现非常出色（参见图 [2](#S4.F2
    "图 2 ‣ 第 1 项 ‣ 4 图像去噪 – 深度学习革命 ‣ 图像去噪：深度学习革命及其后续发展 – 综述论文 –")），因此可以很好地近似 MMSE
    去噪器。因此，尽管方程 ([23](#S7.E23 "方程 23 ‣ 7.3 分数函数及其与逆问题的相关性 ‣ 7 发现 1：通过图像去噪器解决逆问题 ‣
    图像去噪：深度学习革命及其后续发展 – 综述论文 –")) 期望使用指向 $p({\mathbf{x}})$ 的分数函数，去噪器可以提供其近似值，该近似值考虑了略微模糊的概率密度函数⁹⁹9参见附录
    [D](#A4 "附录 D 通过 MMSE 去噪器近似分数函数 ‣ 图像去噪：深度学习革命及其后续发展 – 综述论文 –") 以验证此声明。 $p({\mathbf{y}})=p({\mathbf{x}})\otimes{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$。当 $\sigma_{0}$ 足够小^(10)^(10)10RED
    [[231](#bib.bib231)] 建议对于 $256\times 256$ 灰度图像使用 $\sigma_{0}\approx 3-5$，这种近似变得非常有效，所得算法具有以下更新规则：
- en: '| (25) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})+c\left({\mathbf{x}}_{k}-D({\hat{\mathbf{x}}}_{k},\sigma_{0})\right)\right],$
    |  |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| (25) |  | $\displaystyle{\hat{\mathbf{x}}}_{k+1}={\hat{\mathbf{x}}}_{k}-\mu\left[{\mathbf{H}}^{T}({\mathbf{H}}{\hat{\mathbf{x}}}_{k}-{\mathbf{y}})+c\left({\mathbf{x}}_{k}-D({\hat{\mathbf{x}}}_{k},\sigma_{0})\right)\right],$
    |  |'
- en: which is exactly the SD version of RED [[231](#bib.bib231)].
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 这正是 RED [[231](#bib.bib231)] 的 SD 版本。
- en: '7.4 Summary: Denoisers for Solving Inverse Problems'
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 总结：用于解决逆问题的去噪器
- en: 'Figures [9](#S7.F9 "Figure 9 ‣ 7.4 Summary: Denoisers for Solving Inverse Problems
    ‣ 7 Discovery 1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") and [10](#S7.F10
    "Figure 10 ‣ 7.4 Summary: Denoisers for Solving Inverse Problems ‣ 7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –") present illustrative results of PnP [[295](#bib.bib295)],
    RED [[231](#bib.bib231)], and NCSR [[74](#bib.bib74)] for deblurring and single-image
    super-resolution. Note that while NCSR is specifically tailored to handle these
    two applications, PnP and RED are unaware of the underlying task, and use a given
    denoiser. The tests presented employ both a simple median filter and the TNRD
    denoiser [[50](#bib.bib50)]. Surprisingly, even a plain denoiser as the median
    filter can provide some recovery effect. More details on these experiments and
    more results can be found in [[231](#bib.bib231)].'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [9](#S7.F9 "图 9 ‣ 7.4 总结：用于解决逆问题的去噪器 ‣ 7 发现 1：通过图像去噪器解决逆问题 ‣ 图像去噪：深度学习革命及其后续发展
    – 综述论文 –") 和 [10](#S7.F10 "图 10 ‣ 7.4 总结：用于解决逆问题的去噪器 ‣ 7 发现 1：通过图像去噪器解决逆问题 ‣ 图像去噪：深度学习革命及其后续发展
    – 综述论文 –") 展示了 PnP [[295](#bib.bib295)]、RED [[231](#bib.bib231)] 和 NCSR [[74](#bib.bib74)]
    在去模糊和单图像超分辨率中的示例结果。请注意，尽管 NCSR 是专门设计来处理这两个应用的，PnP 和 RED 对底层任务并不知情，只是使用了给定的去噪器。所展示的测试使用了简单的中值滤波器和
    TNRD 去噪器 [[50](#bib.bib50)]。令人惊讶的是，即使是普通的去噪器如中值滤波器也能提供一定的恢复效果。有关这些实验的更多细节和结果，请参见
    [[231](#bib.bib231)]。
- en: '![Refer to caption](img/bcafc31d036ae115d2207ca12487a7eb.png)'
  id: totrans-275
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/bcafc31d036ae115d2207ca12487a7eb.png)'
- en: (a) Ground Truth
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 真实图像
- en: '![Refer to caption](img/fe47ec8bfec660f4d76babb681e4daaf.png)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fe47ec8bfec660f4d76babb681e4daaf.png)'
- en: (b) Input $20.83$dB
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 输入 $20.83$dB
- en: '![Refer to caption](img/eaab41dcd08a47b5f58cf77534dc029a.png)'
  id: totrans-279
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/eaab41dcd08a47b5f58cf77534dc029a.png)'
- en: (c) RED (Median) $25.87$dB
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: (c) RED (中值) $25.87$dB
- en: '![Refer to caption](img/cc8b6785866f57f65c56919b29be3d7c.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/cc8b6785866f57f65c56919b29be3d7c.png)'
- en: (d) NCSR $28.39$dB
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: (d) NCSR $28.39$dB
- en: '![Refer to caption](img/caa8bb6565aa1b60037cbdd200b50fec.png)'
  id: totrans-283
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/caa8bb6565aa1b60037cbdd200b50fec.png)'
- en: (e) PnP (TNRD) $28.43$dB
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: (e) PnP (TNRD) $28.43$dB
- en: '![Refer to caption](img/2b3d18c8b7234310b33f003510475554.png)'
  id: totrans-285
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2b3d18c8b7234310b33f003510475554.png)'
- en: (f) RED (TNRD) $28.82$dB
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: (f) RED (TNRD) $28.82$dB
- en: 'Figure 9: Visual comparison of deblurring results by PnP and RED. NCSR [[50](#bib.bib50)]
    is brought as a reference to compare with.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：PnP 和 RED 的去模糊结果的视觉比较。NCSR[[50](#bib.bib50)] 被用作对比参考。
- en: '![Refer to caption](img/e471ba98805e8e7c2a567de189b67bc4.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e471ba98805e8e7c2a567de189b67bc4.png)'
- en: (a) Ground Truth
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 真实情况
- en: '![Refer to caption](img/fd6e092a9ff5fc110a967f8a10ed0f58.png)'
  id: totrans-290
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fd6e092a9ff5fc110a967f8a10ed0f58.png)'
- en: (b) Bicubic $20.68$dB
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 双三次插值 $20.68$dB
- en: '![Refer to caption](img/c970424e8dee5c2523614781aaddc73b.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c970424e8dee5c2523614781aaddc73b.png)'
- en: (c) RED (Median) $24.44$dB
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: (c) RED (Median) $24.44$dB
- en: '![Refer to caption](img/66d598e3c0ca56f6063f5435a212e315.png)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/66d598e3c0ca56f6063f5435a212e315.png)'
- en: (d) NCSR $26.79$dB
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: (d) NCSR $26.79$dB
- en: '![Refer to caption](img/61a03a8058b37dbd5b9eb723430615dc.png)'
  id: totrans-296
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/61a03a8058b37dbd5b9eb723430615dc.png)'
- en: (e) PnP (TNRD) $26.61$dB
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: (e) PnP (TNRD) $26.61$dB
- en: '![Refer to caption](img/7b76a86a2e0a3cc69df8fad8e5865153.png)'
  id: totrans-298
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7b76a86a2e0a3cc69df8fad8e5865153.png)'
- en: (f) RED (TNRD) $27.39$dB
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: (f) RED (TNRD) $27.39$dB
- en: 'Figure 10: Visual comparison of super-resolution (3:1) results by PnP and RED.
    NCSR [[50](#bib.bib50)] is brought as a reference to compare with.'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：PnP 和 RED 的超分辨率 (3:1) 结果的视觉比较。NCSR[[50](#bib.bib50)] 被用作对比参考。
- en: 'PnP and RED have drawn much interest in our community in the past several years.
    Followup work has been considering a theoretical analysis of the two methods [[42](#bib.bib42),
    [278](#bib.bib278), [225](#bib.bib225), [94](#bib.bib94), [309](#bib.bib309),
    [269](#bib.bib269)], deployment of the proposed algorithms in various applications [[263](#bib.bib263),
    [28](#bib.bib28), [139](#bib.bib139), [49](#bib.bib49)], creation of new variants
    of these two methods [[283](#bib.bib283), [279](#bib.bib279), [268](#bib.bib268),
    [280](#bib.bib280), [267](#bib.bib267), [123](#bib.bib123), [56](#bib.bib56)],
    and more. An appealing outlet of this work returns to the unfolding idea discussed
    in Section [5](#S5 "5 Synergy between Classics and Deep Learning ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"): PnP/RED can be used
    to define well-motivated architectures for solving general inverse problems, by
    unfolding the proposed algorithms, and then training the repeated denoiser to
    best serve a series of inverse problems jointly. This way, by plugging in the
    degradation operator ${\mathbf{H}}$, a single network can treat a variety of tasks
    in image processing, built around a core learned denoising engine [[194](#bib.bib194),
    [229](#bib.bib229), [73](#bib.bib73), [192](#bib.bib192), [333](#bib.bib333)].'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 'PnP 和 RED 在我们社区中已经引起了很多关注。后续工作包括对这两种方法的理论分析[[42](#bib.bib42), [278](#bib.bib278),
    [225](#bib.bib225), [94](#bib.bib94), [309](#bib.bib309), [269](#bib.bib269)]，在各种应用中的算法部署[[263](#bib.bib263),
    [28](#bib.bib28), [139](#bib.bib139), [49](#bib.bib49)]，这两种方法的新变种的创建[[283](#bib.bib283),
    [279](#bib.bib279), [268](#bib.bib268), [280](#bib.bib280), [267](#bib.bib267),
    [123](#bib.bib123), [56](#bib.bib56)]，以及更多。这项工作的一个吸引人的方向回到第[5](#S5 "5 Synergy
    between Classics and Deep Learning ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")节中讨论的展开思路：PnP/RED 可以用来定义用于解决一般逆问题的良好动机架构，通过展开提出的算法，然后训练重复的去噪器以最佳方式共同解决一系列逆问题。这样，通过插入退化操作符${\mathbf{H}}$，一个单一的网络可以处理图像处理中的各种任务，围绕一个核心学习的去噪引擎构建[[194](#bib.bib194),
    [229](#bib.bib229), [73](#bib.bib73), [192](#bib.bib192), [333](#bib.bib333)]。'
- en: '8 Discovery 2: Image Synthesis via Image Denoisers'
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 发现 2：通过图像去噪器进行图像合成
- en: The deep learning revolution has enabled several capabilities that were previously
    thought to be practically impossible. Among the most intriguing such capabilities
    is *image synthesis* – the ability to generate a variety of natural-looking images,
    without conditioning on any kind of input or initialization. More formally, the
    goal of image synthesis is to obtain a random generator whose outputs follow the
    prior distribution of images $\mathbf{x}\sim p(\mathbf{x})$. Succeeding in this
    task would testify that we have seized the true distribution of images, and this
    may aid in solving a variety of imaging tasks.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习革命使得一些先前被认为在实践上不可能的能力成为现实。其中最引人注目的能力之一是*图像合成* - 在不依赖于任何输入或初始化的情况下生成各种自然的图像。更正式地说，图像合成的目标是获得一个随机生成器，其输出遵循图像的先验分布$\mathbf{x}\sim
    p(\mathbf{x})$。成功完成这项任务将证明我们已经掌握了图像的真实分布，这可能有助于解决各种成像任务。
- en: A common theme in the definition of such image generators is the need to design
    of a learned machine $G_{\Theta}({\mathbf{z}})$, which admits a simply distributed
    input vector ${\mathbf{z}}$ (e.g., ${\mathbf{z}}\sim{\cal N}(0,{\mathbf{I}})$)
    and converts it to a valid sample from $p({\mathbf{x}})$. $G_{\Theta}({\mathbf{z}})$
    is a neural network parameterized by $\Theta$, and various techniques were conceived
    in the past decade for learning $\Theta$ for best fitting the synthesized results
    with the destination PDF. In this context, the main tool of interest, which popularized
    image synthesis, is called GAN – Generative Adversarial Network [[107](#bib.bib107)].
    While alternatives to GANs do exist, such as Variational Auto-Encoders (VAE) [[151](#bib.bib151)],
    Normalizing Flow (NF) techniques [[228](#bib.bib228), [150](#bib.bib150)], Autoregressive
    models [[293](#bib.bib293)], and energy-based methods [[118](#bib.bib118), [79](#bib.bib79)],
    GANs were typically at the lead in image generation. Since their introduction
    and until recently, GANs have undergone various improvements [[222](#bib.bib222),
    [11](#bib.bib11), [112](#bib.bib112), [327](#bib.bib327)], and achieved stellar
    performance [[29](#bib.bib29), [141](#bib.bib141), [249](#bib.bib249)]. However,
    this changed dramatically with the arrival of *diffusion models* [[257](#bib.bib257),
    [260](#bib.bib260), [120](#bib.bib120)].
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 定义这种图像生成器的一个常见主题是需要设计一个学习的机器$G_{\Theta}({\mathbf{z}})$，它接受一个简单分布的输入向量${\mathbf{z}}$（例如，${\mathbf{z}}\sim{\cal
    N}(0,{\mathbf{I}})$），并将其转换为来自$p({\mathbf{x}})$的有效样本。$G_{\Theta}({\mathbf{z}})$是由$\Theta$参数化的神经网络，过去十年中构思出了各种学习$\Theta$以最佳拟合合成结果与目标PDF的技术。在这种情况下，引起图像合成热门的主要工具称为GAN
    - 生成对抗网络[[107](#bib.bib107)]。尽管GAN的替代方案存在，比如变分自动编码器（VAE）[[151](#bib.bib151)],
    正则流（NF）技术[[228](#bib.bib228), [150](#bib.bib150)], 自回归模型[[293](#bib.bib293)],
    以及基于能量的方法[[118](#bib.bib118), [79](#bib.bib79)], GAN通常处于图像生成的前列。自它们的引入直到最近,GAN已经经历了各种改进[[222](#bib.bib222),
    [11](#bib.bib11), [112](#bib.bib112), [327](#bib.bib327)], 并取得了出色的性能[[29](#bib.bib29),
    [141](#bib.bib141), [249](#bib.bib249)]。但是，随着*扩散模型*的到来，情况发生了戏剧性的变化[[257](#bib.bib257),
    [260](#bib.bib260), [120](#bib.bib120)].
- en: GANs, and the other generative models mentioned above, are detached from the
    topic of image denoising. In contrast, *diffusion models* heavily rely on the
    *score function* and thus on image denoisers for addressing the task of image
    synthesis. This recent line of work that started to gain traction, aptly named
    *score-based generative models* [[260](#bib.bib260), [261](#bib.bib261)] or *denoising
    diffusion probabilistic models* [[257](#bib.bib257), [120](#bib.bib120)], utilizes
    deep learning-based denoisers to approximate the score function, which is then
    used in an iterative algorithm to obtain images $\mathbf{x}$ that are fair samples
    from the PDF $p({\mathbf{x}})$.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: GANs和上述其他生成模型与图像去噪的话题无关。相比之下，*扩散模型*严重依赖于*得分函数*，因此依赖于图像去噪器来解决图像合成的任务。最近开始受到关注的这一系列工作，被恰当地命名为基于分数的生成模型[[260](#bib.bib260),
    [261](#bib.bib261)]或*去噪扩散概率模型*[[257](#bib.bib257), [120](#bib.bib120)]，利用基于深度学习的去噪器来逼近得分函数，然后在迭代算法中使用它们获得图像$\mathbf{x}$，这些图像是来自PDF
    $p({\mathbf{x}})$的公平样本。
- en: 'The iterative algorithms used for generation in this context are largely based
    on Langevin dynamics [[230](#bib.bib230), [19](#bib.bib19)], a Markov Chain Monte
    Carlo (MCMC) method with the following transition rule:'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下用于生成的迭代算法很大程度上基于Langevin动力学[[230](#bib.bib230), [19](#bib.bib19)], 这是一个具有以下转移规则的马尔可夫链蒙特卡洛方法：
- en: '| (26) |  | $\mathbf{x}_{t+1}=\mathbf{x}_{t}+\alpha\nabla_{\mathbf{x}_{t}}\log
    p(\mathbf{x}_{t})+\sqrt{2\alpha}\mathbf{z}_{t},$ |  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| (26) |  | $\mathbf{x}_{t+1}=\mathbf{x}_{t}+\alpha\nabla_{\mathbf{x}_{t}}\log
    p(\mathbf{x}_{t})+\sqrt{2\alpha}\mathbf{z}_{t},$ |  |'
- en: where $\mathbf{z}_{t}\sim\mathcal{N}(0,\mathbf{I})$, and $\alpha$ is an appropriate
    small constant. Initialized randomly, after a sufficiently large number of iterations,
    and under some mild conditions on $p({\mathbf{x}})$, this process converges to
    a sampling from the distribution $p(\mathbf{x})$ whose score function is used [[230](#bib.bib230)].
    Intuitively, the algorithm follows the direction of the gradient of the log-probability,
    climbing from one image to a more probable one. This is a gradient ascent process,
    and the noise is added in each iteration to provide stochasticity, which effectively
    leads to sampling from $p(\mathbf{x})$ rather than converging to a local maximum.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbf{z}_{t}\sim\mathcal{N}(0,\mathbf{I})$，$\alpha$是一个适当的小常数。随机初始化后，在足够多的迭代次数之后，并且在对$p({\mathbf{x}})$的某些温和条件下，该过程收敛到一个从分布$p(\mathbf{x})$中采样的过程，其评分函数被使用[[230](#bib.bib230)]。直观上，该算法遵循对数概率的梯度方向，从一个图像爬升到更可能的图像。这是一个梯度上升过程，每次迭代中添加噪声以提供随机性，这有效地导致从$p(\mathbf{x})$中采样，而不是收敛到局部最大值。
- en: While it is tempting to use the true data distribution’s score function in Langevin
    dynamics, a few problems prevent such a use [[260](#bib.bib260)]. One of the main
    issues lies with the well-known cardinal manifold assumption [[239](#bib.bib239)],
    which relies on the observation that natural images reside on a low-dimensional
    manifold in their embedding space. Therefore, for a random initialization of $\mathbf{x}_{0}$,
    it holds with probability $1$ that $p(\mathbf{x}_{0})=0$, rendering the score
    function undefined at best, and without an ability to drift towards the image
    manifold in subsequent iterations. A possible solution is to approximate $p(\mathbf{x})$
    by its slightly blurred counterpart $p(\mathbf{y})$, where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$,
    ${\mathbf{v}}\sim{\cal N}(0,\sigma^{2}{\mathbf{I}})$, with a very small $\sigma$ [[296](#bib.bib296)].
    This resolves the aforementioned problem, as the Gaussian noise distribution has
    infinite tails. However, in practice, such a Langevin sampling algorithm requires
    many thousands of iterations to converge [[155](#bib.bib155)], hindering its practical
    applicability.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然在Langevin动力学中使用真实数据分布的评分函数很有诱惑力，但一些问题阻止了这种使用[[260](#bib.bib260)]。主要问题之一在于著名的基数流形假设[[239](#bib.bib239)]，该假设依赖于自然图像在其嵌入空间中位于低维流形上的观察。因此，对于$\mathbf{x}_{0}$的随机初始化，$p(\mathbf{x}_{0})=0$的概率为$1$，这使得评分函数至多是未定义的，并且在后续迭代中没有向图像流形漂移的能力。一种可能的解决方案是通过其稍微模糊的对应物$p(\mathbf{y})$来近似$p(\mathbf{x})$，其中${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$，${\mathbf{v}}\sim{\cal
    N}(0,\sigma^{2}{\mathbf{I}})$，$\sigma$非常小[[296](#bib.bib296)]。这解决了上述问题，因为高斯噪声分布具有无限的尾部。然而，在实践中，这种Langevin采样算法需要数千次迭代才能收敛[[155](#bib.bib155)]，这限制了其实际应用性。
- en: 'The authors of [[260](#bib.bib260)] suggest the *Annealed Langevin Dynamics*
    (ALD) algorithm^(11)^(11)11A very similar algorithm has been proposed in parallel
    by [[120](#bib.bib120)]. Preceding these two works is the one reported in [[257](#bib.bib257)]
    who proposed a similar process while relying on a different rationale borrowed
    from statistical physics., which considers a sequence of Gaussian noisy image
    distributions ${p_{0}(\mathbf{y}),p_{1}(\mathbf{y}),\dots,p_{L-1}(\mathbf{y}),p_{L}(\mathbf{y})}$
    with standard deviations ${\sigma_{0}>\sigma_{1}>\dots>\sigma_{L-1}>\sigma_{L}}$.
    Applying a few iterations of Langevin dynamics for each of the distributions,
    starting with a very large $\sigma_{0}$ and ending with a very small $\sigma_{L}$,
    enables a faster convergence. Each of these steps is applied using a denoiser
    that estimates the score function, and the output of each such process is used
    to initialize the next. This implies that the synthesis creates a chain of noisy
    images with diminishing levels of noise, starting with pure canonical Gaussian
    noise and gradually carving out an image content out of it. Intuitively, this
    translates to drawing from a wide distribution and then gradually narrowing it,
    leading to faster sampling and better performance in image generation. Algorithm
    [1](#alg1 "Algorithm 1 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣
    Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    presents this image sampler: The outer loop sweeps through the $L+1$ values of
    $\sigma$, while the inner loop applies $T$ Langevin steps for each. The score
    function $\nabla_{{\mathbf{x}}}\log p_{i}({\mathbf{x}})$, which stands for the
    $\sigma_{i}$-blurred PDF of ${\mathbf{x}}$, is approximated by'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '[[260](#bib.bib260)] 的作者建议使用*退火Langevin动力学*（ALD）算法^(11)^(11)11一个非常相似的算法已经由
    [[120](#bib.bib120)] 平行提出。在这两个工作之前，有 [[257](#bib.bib257)] 报告的工作，提出了一个类似的过程，但依赖于来自统计物理学的不同原理，它考虑了一系列高斯噪声图像分布
    ${p_{0}(\mathbf{y}),p_{1}(\mathbf{y}),\dots,p_{L-1}(\mathbf{y}),p_{L}(\mathbf{y})}$，其中标准差为
    ${\sigma_{0}>\sigma_{1}>\dots>\sigma_{L-1}>\sigma_{L}}$。对每个分布应用几次Langevin动力学，从非常大的
    $\sigma_{0}$ 开始，到非常小的 $\sigma_{L}$ 结束，可以实现更快的收敛。每一步使用一个估计评分函数的去噪器，并且每个过程的输出用于初始化下一个过程。这意味着合成创建了一系列噪声逐渐减小的图像，从纯经典高斯噪声开始，逐渐雕刻出图像内容。直观地说，这相当于从宽分布中抽取样本，然后逐渐缩小它，从而实现更快的采样和更好的图像生成性能。算法
    [1](#alg1 "算法 1 ‣ 8 发现 2：通过图像去噪器的图像合成 ‣ 图像去噪：深度学习革命及其之后 – 一项调查论文 –") 展示了这种图像采样器：外部循环遍历
    $L+1$ 个 $\sigma$ 值，而内部循环对每个值应用 $T$ 次Langevin步骤。评分函数 $\nabla_{{\mathbf{x}}}\log
    p_{i}({\mathbf{x}})$，表示 $\sigma_{i}$ 模糊的 ${\mathbf{x}}$ 的PDF，通过以下公式近似：'
- en: '| (27) |  | $\displaystyle\nabla_{{\mathbf{x}}}\log p_{i}({\mathbf{x}})=\frac{D({\mathbf{x}},\sigma_{i})-{\mathbf{x}}}{\sigma_{i}^{2}}.$
    |  |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| (27) |  | $\displaystyle\nabla_{{\mathbf{x}}}\log p_{i}({\mathbf{x}})=\frac{D({\mathbf{x}},\sigma_{i})-{\mathbf{x}}}{\sigma_{i}^{2}}.$
    |  |'
- en: 'Observe that the step size $\alpha$ is modified throughout this process, chosen
    to be proportional to $\sigma_{i}^{2}$. This aligns with the fact that larger
    $\sigma$ values imply a more regular and smooth PDF, which is easier to sample
    from.^(12)^(12)12A different explanation for this choice of the step size is given
    in [[260](#bib.bib260)], motivated by a desire to better balance the norms of
    the score versus the additive noise in the Langevin update formula. Figure [11](#S8.F11
    "Figure 11 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") presents several
    examples of temporal steps in the ALD process that starts with pure Gaussian noise
    and ends with a high-quality synthesized image.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 请注意，在这个过程中，步长 $\alpha$ 被修改，并选择为与 $\sigma_{i}^{2}$ 成正比。这与较大的 $\sigma$ 值意味着更规则和平滑的概率密度函数（PDF）这一事实相一致，这样更容易进行采样。^(12)^(12)12
    对于选择步长的不同解释见于 [[260](#bib.bib260)]，其动机是希望更好地平衡Langevin更新公式中的评分与加性噪声的范数。图 [11](#S8.F11
    "图 11 ‣ 8 发现 2：通过图像去噪器的图像合成 ‣ 图像去噪：深度学习革命及其之后 – 一项调查论文 –") 展示了在ALD过程中从纯高斯噪声开始到结束时的高质量合成图像的若干时间步例子。
- en: 'Input: $\left\{\sigma_{i}\right\}_{i=0}^{L}$, $\epsilon$, $T$Initialize $\mathbf{x}_{0}\sim{\cal
    N}(0,{\mathbf{I}})$for *$i$ $\leftarrow$ $0$ to $L$* do       $\alpha_{i}\leftarrow\epsilon\cdot\sigma_{i}^{2}/\sigma_{L}^{2}$      for *$t$
    $\leftarrow$ $1$ to $T$* do             Draw ${\mathbf{z}}_{t}\sim\mathcal{N}\left(0,\mathbf{I}\right)$            
    ${\mathbf{x}}_{t}$ $\leftarrow$ ${\mathbf{x}}_{t-1}+\alpha_{i}\left[D({\mathbf{x}}_{t-1},\sigma_{i})-{\mathbf{x}}_{t-1}\right]/\sigma_{i}^{2}+\sqrt{2\alpha_{i}}{\mathbf{z}}_{t}$      
    end for      $\mathbf{x}_{0}\leftarrow\mathbf{x}_{T}$end forOutput: $\mathbf{x}_{0}$'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 输入：$\left\{\sigma_{i}\right\}_{i=0}^{L}$, $\epsilon$, $T$初始化 $\mathbf{x}_{0}\sim{\cal
    N}(0,{\mathbf{I}})$对 *$i$ $\leftarrow$ $0$ 到 $L$* 执行       $\alpha_{i}\leftarrow\epsilon\cdot\sigma_{i}^{2}/\sigma_{L}^{2}$      对 *$t$
    $\leftarrow$ $1$ 到 $T$* 执行             生成 ${\mathbf{z}}_{t}\sim\mathcal{N}\left(0,\mathbf{I}\right)$            
    ${\mathbf{x}}_{t}$ $\leftarrow$ ${\mathbf{x}}_{t-1}+\alpha_{i}\left[D({\mathbf{x}}_{t-1},\sigma_{i})-{\mathbf{x}}_{t-1}\right]/\sigma_{i}^{2}+\sqrt{2\alpha_{i}}{\mathbf{z}}_{t}$      
    结束执行      $\mathbf{x}_{0}\leftarrow\mathbf{x}_{T}$结束对 *$i$ $\leftarrow$ $0$ 到
    $L$* 执行输出：$\mathbf{x}_{0}$
- en: Algorithm 1 the Annealed Langevin Dynamics (ALD) algorithm
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: 算法 1 熔融朗之万动力学 (ALD) 算法
- en: 'The ALD algorithm sparked a wave of related works [[261](#bib.bib261), [120](#bib.bib120),
    [262](#bib.bib262), [208](#bib.bib208), [287](#bib.bib287), [68](#bib.bib68),
    [122](#bib.bib122), [143](#bib.bib143), [121](#bib.bib121)] that continually improved
    the performance of these generative *diffusion models*, eventually surpassing
    that of GANs [[68](#bib.bib68)]. We show some of their results in Figure [12](#S8.F12
    "Figure 12 ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). Nevertheless, these
    iterative algorithms are still considerably slower than GANs, so substantial work
    has been invested in improving their speed without compromising significantly
    on generation quality [[258](#bib.bib258), [135](#bib.bib135), [247](#bib.bib247)],
    often achieving impressive speedup levels. Diffusion models have since become
    ubiquitous in many applications [[142](#bib.bib142), [209](#bib.bib209), [21](#bib.bib21),
    [116](#bib.bib116), [6](#bib.bib6), [253](#bib.bib253), [254](#bib.bib254), [144](#bib.bib144)],
    prompting researchers to prepare surveys of their impact on the image processing
    field and beyond [[315](#bib.bib315), [60](#bib.bib60), [36](#bib.bib36)].'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 'ALD 算法引发了一波相关工作的浪潮[[261](#bib.bib261), [120](#bib.bib120), [262](#bib.bib262),
    [208](#bib.bib208), [287](#bib.bib287), [68](#bib.bib68), [122](#bib.bib122),
    [143](#bib.bib143), [121](#bib.bib121)]，这些工作不断提升了生成*扩散模型*的性能，最终超过了 GANs[[68](#bib.bib68)]。我们在图
    [12](#S8.F12 "图 12 ‣ 8 发现 2: 通过图像去噪器进行图像合成 ‣ 图像去噪：深度学习革命及其超越 – 一项调查论文 –") 中展示了它们的一些结果。尽管如此，这些迭代算法仍然比
    GANs 慢得多，因此投入了大量工作以提高其速度，而不显著影响生成质量[[258](#bib.bib258), [135](#bib.bib135), [247](#bib.bib247)]，通常实现了显著的加速水平。扩散模型此后在许多应用中变得普遍[[142](#bib.bib142),
    [209](#bib.bib209), [21](#bib.bib21), [116](#bib.bib116), [6](#bib.bib6), [253](#bib.bib253),
    [254](#bib.bib254), [144](#bib.bib144)]，促使研究人员准备了关于它们对图像处理领域及其他领域影响的调查[[315](#bib.bib315),
    [60](#bib.bib60), [36](#bib.bib36)]。'
- en: '![Refer to caption](img/e4830e67ca96bac7e761f825e7d42c4e.png)'
  id: totrans-316
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e4830e67ca96bac7e761f825e7d42c4e.png)'
- en: 'Figure 11: Temporal steps along 3 independent synthesis paths of the Annealed
    Langevin Dynamics [[260](#bib.bib260)] algorithm, using a denoiser [[261](#bib.bib261)]
    trained on LSUN bedroom [[319](#bib.bib319)] images.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：熔融朗之万动力学[[260](#bib.bib260)] 算法沿 3 条独立合成路径的时间步骤，使用在 LSUN 卧室[[319](#bib.bib319)]
    图像上训练的去噪器[[261](#bib.bib261)]。
- en: '![Refer to caption](img/4b11019b00a968914d0e380ae37f458e.png)'
  id: totrans-318
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4b11019b00a968914d0e380ae37f458e.png)'
- en: 'Figure 12: Image generation results for CelebA-HQ [[172](#bib.bib172)] (left)
    and ImageNet [[66](#bib.bib66)] (right) using score-based denoising diffusion
    generative models [[262](#bib.bib262), [68](#bib.bib68)].'
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：使用基于评分的去噪扩散生成模型[[262](#bib.bib262), [68](#bib.bib68)] 生成的 CelebA-HQ[[172](#bib.bib172)]
    (左) 和 ImageNet[[66](#bib.bib66)] (右) 的图像结果。
- en: '9 Discovery 3: High Perceptual Quality Image Recovery'
  id: totrans-320
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: '9 发现 3: 高感知质量图像恢复'
- en: We are now stepping into the last and what we believe to be one of the most
    exciting topics in the story of image denoisers – solving general linear inverse
    problems while striving for perfect perceptual quality, and achieving this with
    the support of an MMSE denoiser. We start with the simplest inverse problem –
    image denoising itself – and grow from there to more general recovery tasks.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在进入图像去噪故事中最后一个也是我们认为最令人兴奋的话题之一——解决一般的线性逆问题，同时追求完美的感知质量，并通过 MMSE 去噪器实现这一目标。我们从最简单的逆问题——图像去噪本身——开始，然后扩展到更一般的恢复任务。
- en: 9.1 Revisiting the Image Denoising Problem
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.1 重新审视图像去噪问题
- en: We return to the classic image denoising problem, where ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$
    in a given noisy image, ${\mathbf{x}}\sim p({\mathbf{x}})$ is it’s ideal origin,
    and ${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2})$ is the AWGN. Our goal
    is to recover ${\mathbf{x}}$, but now we change the rules of the game by expecting
    high perceptual quality results. How could this be achieved?
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回到经典的图像去噪问题，其中 ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$ 是给定的噪声图像，${\mathbf{x}}\sim
    p({\mathbf{x}})$ 是其理想来源，而 ${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2})$
    是加性高斯白噪声（AWGN）。我们的目标是恢复 ${\mathbf{x}}$，但现在我们改变了游戏规则，期望获得高感知质量的结果。这如何实现？
- en: 'Throughout the classical era of denoising, and well into the modern AI days,
    denoisers were mostly evaluated using the Mean Squared Error (MSE) measure shown
    in Equation ([2](#S2.E2 "Equation 2 ‣ 2.1 Problem Definition ‣ 2 Image Denoising
    – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –")) (or tightly related measures such as the Peak Signal-to-Noise Ratio
    – PSNR). As can be seen in Figure [2](#S4.F2 "Figure 2 ‣ 1st item ‣ 4 Image Denoising
    – The Deep Learning Revolution ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –"), MSE has been and still is a commonly used performance
    measure for denoisers. The MSE metric has several clear benefits: it is zero when
    the denoiser perfectly recovers the image, it is intuitive to understand, and
    it produces mathematically elegant results for theoretical analysis, as well as
    practical considerations such as ease of differentiation for optimization.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '在经典的去噪时代以及现代 AI 时代，去噪器大多使用均方误差（MSE）度量（见方程 [2](#S2.E2 "Equation 2 ‣ 2.1 Problem
    Definition ‣ 2 Image Denoising – Background ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")（或紧密相关的度量，如峰值信噪比 – PSNR）进行评估。正如图 [2](#S4.F2
    "Figure 2 ‣ 1st item ‣ 4 Image Denoising – The Deep Learning Revolution ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") 所示，MSE
    一直是并且仍然是去噪器的常用性能度量。MSE 具有几个明显的优点：当去噪器完美恢复图像时，它为零，易于理解，并且在理论分析以及实际应用中（例如优化时的易于微分）产生数学上优雅的结果。'
- en: 'However, the MSE distortion measure suffers from a critical shortcoming: As
    discussed in Section [2.1](#S2.SS1 "2.1 Problem Definition ‣ 2 Image Denoising
    – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") and in Appendix [A](#A1 "Appendix A Derivation of the MMSE Estimation
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –"),
    the best possible result in MSE (MMSE), regardless of the denoising method used
    to approximate it, would rely on a conditional expectation,'
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: '然而，MSE 失真度量存在一个关键缺陷：正如在第 [2.1](#S2.SS1 "2.1 Problem Definition ‣ 2 Image Denoising
    – Background ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") 节和附录 [A](#A1 "Appendix A Derivation of the MMSE Estimation ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") 中讨论的那样，无论使用何种去噪方法来近似
    MSE（MMSE），其最佳结果都依赖于条件期望，'
- en: '| (28) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\operatorname*{arg\,min}_{{\hat{\mathbf{x}}}}\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\int_{{\mathbf{x}}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  id: totrans-326
  prefs: []
  type: TYPE_TB
  zh: '| (28) |  | $\displaystyle{\hat{\mathbf{x}}}_{MMSE}=\operatorname*{arg\,min}_{{\hat{\mathbf{x}}}}\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}\right)=\int_{{\mathbf{x}}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
- en: 'In other words, when optimizing for MSE, our main goal is to get as close as
    possible to the original image in expectation, and this implies an averaging over
    all possible solutions, weighted by their posterior probability. Thus, depending
    on the geometry of the image manifold and the severity of the noise, the MMSE
    solution may tend to be too blurry and of relatively low probability $p({\hat{\mathbf{x}}}_{MMSE})$,
    falling outside of the desired manifold. We illustrate this phenomenon in a 2-dimensional
    example in Figure [13](#S9.F13 "Figure 13 ‣ 9.1 Revisiting the Image Denoising
    Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –").'
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: '换句话说，当优化均方误差（MSE）时，我们的主要目标是使期望值尽可能接近原始图像，这意味着需要对所有可能的解决方案进行加权平均，权重由其后验概率决定。因此，根据图像流形的几何结构和噪声的严重程度，MMSE
    解决方案可能会过于模糊，并且相对低概率 $p({\hat{\mathbf{x}}}_{MMSE})$，从而超出了所需的流形。我们在图 [13](#S9.F13
    "Figure 13 ‣ 9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High
    Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") 中展示了这一现象的二维示例。'
- en: '![Refer to caption](img/f6d747e8bbb458a5c184dc5b7b866920.png)'
  id: totrans-328
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/f6d747e8bbb458a5c184dc5b7b866920.png)'
- en: 'Figure 13: A $2$-dimensional qualitative demonstration of the disadvantages
    of MMSE denoising. Given a noisy image, the MMSE denoiser falls outside of the
    image manifold, whereas a posterior sampler would necessarily sample points that
    reside on it. This leads to better perceptual quality in the denoising results.'
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：一个二维定性演示 MMSE 去噪的缺点。给定一张噪声图像，MMSE 去噪器会落在图像流形之外，而后验采样器则会必然采样位于其上的点。这会导致去噪结果的感知质量更好。
- en: 'Indeed, the fact that MMSE denoising achieves optimal $L_{2}$ distortion necessarily
    implies that *perceptual* quality is compromised. The authors of [[22](#bib.bib22)]
    prove the existence of a “perception-distortion tradeoff”: distortion (of any
    kind!) and perceptual quality are at odds with each other, and optimizing one
    necessarily deteriorates the other. In this context, perceptual quality is defined
    as the proximity between the original image distribution $p(\mathbf{x})$, and
    the denoised image one $p(\hat{\mathbf{x}})$. Figure [14](#S9.F14 "Figure 14 ‣
    9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –") presents the essence of these findings in [[22](#bib.bib22)].'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，MMSE 去噪实现最佳 $L_{2}$ 失真必然意味着*感知*质量受到了妥协。[[22](#bib.bib22)] 的作者证明了“感知-失真权衡”的存在：失真（无论哪种形式！）与感知质量相互对立，优化其中一个必然会恶化另一个。在这种情况下，感知质量被定义为原始图像分布
    $p(\mathbf{x})$ 与去噪图像分布 $p(\hat{\mathbf{x}})$ 之间的接近程度。图 [14](#S9.F14 "图 14 ‣ 9.1
    重新审视图像去噪问题 ‣ 发现 3：高感知质量图像恢复 ‣ 图像去噪：深度学习革命及其超越 – 综述论文 –") 展示了 [[22](#bib.bib22)]
    中这些发现的精髓。
- en: '![Refer to caption](img/01323512d2f86da4e1ee3f4632e8a607.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/01323512d2f86da4e1ee3f4632e8a607.png)'
- en: 'Figure 14: The perception-distortion trade-off [[22](#bib.bib22)]: Any recovery
    algorithm necessarily performs on the blue-curve or above it. On the perception-distortion
    bound curve, the top-left point refers to the MMSE estimation, while the right-bottom
    one (or right to it – see [[22](#bib.bib22)]) is obtained by a posterior sampler.
    A gap of $3$dB divides between the two when using the MSE distortion measure.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14：感知-失真权衡 [[22](#bib.bib22)]：任何恢复算法必然在蓝色曲线或其上方运行。在感知-失真界限曲线上，左上角的点指代 MMSE
    估计，而右下角的点（或右侧点 – 参见 [[22](#bib.bib22)]）则由后验采样器获得。当使用 MSE 失真度量时，两者之间存在 $3$dB 的差距。
- en: 'With this tension between visual quality and distortion in mind, alternative
    approaches to MSE were developed over the years, aiming for high perceptual quality
    denoising [[69](#bib.bib69), [67](#bib.bib67), [212](#bib.bib212), [146](#bib.bib146)].
    One such technique is to sample from the posterior distribution: given a noisy
    image ${\mathbf{y}}$, we aim to develop a denoiser that outputs $\hat{\mathbf{x}}\sim
    p(\mathbf{x}|\mathbf{y})$, *i.e.*, samples from the posterior distribution of
    pristine images given the noisy measurement. A successful posterior sampler would
    achieve perfect perceptual quality, as when marginalizing over $\mathbf{y}$, we
    get $p(\hat{\mathbf{x}})=p(\mathbf{x})$. It is important to notice that this technique
    involves a subtle paradigm shift – the denoiser is no longer a deterministic function
    of the noisy input $\mathbf{y}$, but rather a stochastic one and this implies
    a multitude of possible solutions. In the following, we present two pragmatic
    approaches for approximating posterior sampling behavior.'
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到视觉质量和失真之间的这种紧张关系，近年来开发了针对 MSE 的替代方法，旨在实现高感知质量的去噪 [[69](#bib.bib69), [67](#bib.bib67),
    [212](#bib.bib212), [146](#bib.bib146)]。一种这样的技术是从后验分布中采样：给定一张噪声图像 ${\mathbf{y}}$，我们的目标是开发一个去噪器，该去噪器输出
    $\hat{\mathbf{x}}\sim p(\mathbf{x}|\mathbf{y})$，*即*，从给定噪声测量的原始图像的后验分布中采样。一个成功的后验采样器将实现完美的感知质量，因为在对
    $\mathbf{y}$ 进行边际化时，我们得到 $p(\hat{\mathbf{x}})=p(\mathbf{x})$。值得注意的是，这种技术涉及一个微妙的范式转变——去噪器不再是噪声输入
    $\mathbf{y}$ 的确定性函数，而是一个随机函数，这意味着存在大量可能的解决方案。在接下来的部分中，我们介绍两种实用的方法来逼近后验采样行为。
- en: 'To traverse the perception-distortion tradeoff, a Waserstein Generative Adversarial
    Network (WGAN) conditioned on noisy images can be used [[22](#bib.bib22), [69](#bib.bib69)].
    Such a network consists of two main elements: a *generator*, which takes a noisy
    image as well as a random vector as input, and outputs a denoised image, and a
    *discriminator*, whose job is to distinguish between denoised and original images.
    The discriminator is trained to discriminate between the generator’s outputs and
    original images, while the generator optimizes two loss functions: the MSE with
    respect to the original image, and the ability to “fool” the discriminator, thus
    encouraging its output to “look like a real image” in the eyes of the discriminator.
    These two losses, as proven in [[22](#bib.bib22)], are at odds with one another,
    and tuning their respective weights in the total loss function translates to the
    traversal of the perception-distortion tradeoff. This idea is further improved
    upon by [[212](#bib.bib212)]: instead of requiring low distortion on individual
    generator samples, the requirement is made on their mean. This results in a loss
    function that encourages the generator to act as a sampler from the posterior
    distribution, therefore attaining near-perfect perceptual quality while remaining
    faithful to the input image.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 为了遍历感知-失真权衡，可以使用基于噪声图像的 Waserstein 对抗网络（WGAN）[[22](#bib.bib22), [69](#bib.bib69)]。这样的网络由两个主要元素组成：一个
    *生成器*，它将噪声图像和随机向量作为输入，并输出去噪图像；以及一个 *鉴别器*，其任务是区分去噪图像和原始图像。鉴别器被训练以区分生成器的输出和原始图像，而生成器则优化两个损失函数：相对于原始图像的均方误差（MSE）和“欺骗”鉴别器的能力，从而鼓励其输出在鉴别器看来“像真实图像”。这两个损失，如
    [[22](#bib.bib22)] 中所证明，是相互矛盾的，调节它们在总损失函数中的权重可以实现感知-失真权衡。[[212](#bib.bib212)]
    进一步改进了这一思想：要求不再是单个生成器样本的低失真，而是它们的均值。这导致了一个鼓励生成器作为后验分布的采样器的损失函数，从而在保持对输入图像忠实的同时，实现接近完美的感知质量。
- en: An alternative posterior sampling approach, which reconnects with MMSE denoisers,
    is using the annealed Langevin dynamics algorithm [[260](#bib.bib260)] presented
    in the previous section. Recall that ALD uses the score function $\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})$ to sample from a prior distribution $p_{i}({\tilde{\mathbf{x}}})$^(13)^(13)13In
    these notations, $p_{i}$ stands for a $\sigma_{i}$-blurred PDF version of the
    original prior $p({\mathbf{x}})$, and ${\tilde{\mathbf{x}}}$ is a temporary synthesized
    image that contains annealing Gaussian noise with variance $\sigma_{i}^{2}$..
    In [[146](#bib.bib146)], the regular ALD algorithm is extended to treat image
    denoising by analytically conditioning the score function on a noisy input $\mathbf{y}$
    – effectively sampling from the posterior distribution $p_{i}({\tilde{\mathbf{x}}}|\mathbf{y})$.
    The algorithm is initialized with the noisy input $\mathbf{y}$, which is then
    gradually denoised using the conditional score function, obtained using the Bayes
    rule,
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 一种替代的后验采样方法是使用前一节中介绍的退火 Langevin 动力学算法[[260](#bib.bib260)]，它与 MMSE 去噪器重新连接。回顾一下，ALD
    使用评分函数 $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}})$ 从先验分布 $p_{i}({\tilde{\mathbf{x}}})$
    中进行采样。在这些符号中，$p_{i}$ 表示原始先验 $p({\mathbf{x}})$ 的 $\sigma_{i}$-模糊 PDF 版本，而 ${\tilde{\mathbf{x}}}$
    是一个包含方差为 $\sigma_{i}^{2}$ 的退火高斯噪声的临时合成图像。 在 [[146](#bib.bib146)] 中，常规 ALD 算法被扩展为通过对噪声输入
    $\mathbf{y}$ 进行解析性条件化来处理图像去噪——有效地从后验分布 $p_{i}({\tilde{\mathbf{x}}}|\mathbf{y})$
    中采样。该算法以噪声输入 $\mathbf{y}$ 初始化，然后利用条件评分函数逐步去噪，条件评分函数是通过贝叶斯规则获得的，
- en: '| (29) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;{\mathbf{y}})=\nabla_{{\tilde{\mathbf{x}}}}\log\frac{p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})p_{i}({\tilde{\mathbf{x}}})}{p({\mathbf{y}})}=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\nabla_{{\tilde{\mathbf{x}}}}\log p(\mathbf{y}&#124;\mathbf{x}_{t}).$
    |  |'
  id: totrans-336
  prefs: []
  type: TYPE_TB
  zh: '| (29) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;{\mathbf{y}})=\nabla_{{\tilde{\mathbf{x}}}}\log\frac{p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})p_{i}({\tilde{\mathbf{x}}})}{p({\mathbf{y}})}=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\nabla_{{\tilde{\mathbf{x}}}}\log p(\mathbf{y}&#124;\mathbf{x}_{t}).$
    |  |'
- en: 'The term $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}})$ is
    the regular score function which can be approximated by an MSE-trained denoiser.
    As for the other term, $\nabla_{{\tilde{\mathbf{x}}}}\log p({\mathbf{y}}|{\tilde{\mathbf{x}}})$,
    observe that this likelihood can be rewritten by exploiting two facts: (i) ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$
    is the noisy image (${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}$),
    and (ii) ${\tilde{\mathbf{x}}}={\mathbf{x}}+{{\mathbf{z}}}$ is the annealed solution
    (${{\mathbf{z}}}\sim{\cal N}(0,\sigma_{i}^{2}{\mathbf{I}})$), and thus'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 术语 $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}})$ 是常规评分函数，可以通过均方误差（MSE）训练的去噪器进行近似。至于另一个术语
    $\nabla_{{\tilde{\mathbf{x}}}}\log p({\mathbf{y}}|{\tilde{\mathbf{x}}})$，请注意，这个似然函数可以利用两个事实重新表达：（i）${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$
    是带噪图像（${\mathbf{v}}\sim{\cal N}(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}$），以及（ii）${\tilde{\mathbf{x}}}={\mathbf{x}}+{{\mathbf{z}}}$
    是退火解（${{\mathbf{z}}}\sim{\cal N}(0,\sigma_{i}^{2}{\mathbf{I}})$），因此
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  id: totrans-338
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{x}}+{\mathbf{v}}-{\mathbf{x}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  id: totrans-339
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{x}}+{\mathbf{v}}-{\mathbf{x}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}}).$
    |  |'
  id: totrans-340
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{z}}&#124;{\tilde{\mathbf{x}}}).$
    |  |'
- en: If we assume statistical independence between the measurements’ noise and the
    annealing one, ${\mathbf{v}}-{\mathbf{z}}$ becomes a plain Gaussian vector. However,
    its conditioning on the knowledge of ${\tilde{\mathbf{x}}}$ leads to a dead-end,
    since this image contains ${\mathbf{z}}$ in it. The alternative, as developed
    in [[146](#bib.bib146)], is to construct the annealing noise such that ${\mathbf{v}}-{\mathbf{z}}$
    is statistically independent of both ${\mathbf{z}}$ and ${\tilde{\mathbf{x}}}$.
    This can be obtained by breaking the measurements’ noise ${\mathbf{v}}$ into small
    fragments, and assume that their partial accumulations constitute the annealing
    noise in each of the stages. Thus, ${\mathbf{v}}-{\mathbf{z}}$ is a white Gaussian
    noise that has no correlation with the noise ${\mathbf{z}}$, nor with the target
    image ${\mathbf{x}}$. Put in other words, this likelihood expression becomes simple
    when considering $\mathbf{y}$ to be an even more noisy version of ${\tilde{\mathbf{x}}}$.
    This in turn makes $p(\mathbf{y}|{\tilde{\mathbf{x}}})$ a simple white Gaussian
    distribution of the form ${\cal N}(0,(\sigma_{{\mathbf{y}}}^{2}-\sigma_{i}^{2}){\mathbf{I}})$.
    Therefore,
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们假设测量噪声与退火噪声之间的统计独立性，那么 ${\mathbf{v}}-{\mathbf{z}}$ 就成为一个普通的高斯向量。然而，基于对 ${\tilde{\mathbf{x}}}$
    的知识进行条件化会导致困境，因为这个图像中包含了 ${\mathbf{z}}$。另一种方法，如在[[146](#bib.bib146)]中开发的，是构造退火噪声，使得
    ${\mathbf{v}}-{\mathbf{z}}$ 与 ${\mathbf{z}}$ 和 ${\tilde{\mathbf{x}}}$ 都是统计独立的。这可以通过将测量噪声
    ${\mathbf{v}}$ 分解为小的片段来实现，并假设它们的部分积累构成了每个阶段的退火噪声。因此，${\mathbf{v}}-{\mathbf{z}}$
    是一种白噪声，与噪声 ${\mathbf{z}}$ 以及目标图像 ${\mathbf{x}}$ 没有相关性。换句话说，当考虑 $\mathbf{y}$ 为
    ${\tilde{\mathbf{x}}}$ 的一个更嘈杂的版本时，这个似然表达变得简单。这反过来使得 $p(\mathbf{y}|{\tilde{\mathbf{x}}})$
    成为形式为 ${\cal N}(0,(\sigma_{{\mathbf{y}}}^{2}-\sigma_{i}^{2}){\mathbf{I}}$ 的简单白噪声分布。因此，
- en: '| (31) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;\mathbf{y})=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\frac{\mathbf{y}-{\tilde{\mathbf{x}}}}{\sigma_{\mathbf{y}}^{2}-\sigma_{i}^{2}}.$
    |  |'
  id: totrans-342
  prefs: []
  type: TYPE_TB
  zh: '| (31) |  | $\nabla_{{\tilde{\mathbf{x}}}}\log p_{i}({\tilde{\mathbf{x}}}&#124;\mathbf{y})=\nabla_{{\tilde{\mathbf{x}}}}\log
    p_{i}({\tilde{\mathbf{x}}})+\frac{\mathbf{y}-{\tilde{\mathbf{x}}}}{\sigma_{\mathbf{y}}^{2}-\sigma_{i}^{2}}.$
    |  |'
- en: 'Plugging this modification into ALD turns Algorithm [1](#alg1 "Algorithm 1
    ‣ 8 Discovery 2: Image Synthesis via Image Denoisers ‣ Image Denoising: The Deep
    Learning Revolution and Beyond – A Survey Paper –") into an image denoiser. Beyond
    its ability to attain near-perfect perceptual quality, this approach has the advantage
    of not requiring any special model training. Crucially, this finding shows that
    simple MSE denoiser training is more powerful than originally thought – not only
    can it approximate MMSE denoiser behavior, but it can also perform denoising by
    posterior sampling under the Langevin dynamics scheme. Figure [15](#S9.F15 "Figure
    15 ‣ 9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual
    Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond
    – A Survey Paper –") presents a denoising result by the above-described method.
    Several observations are in order from this figure:'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '将这种修改引入 ALD 会将算法 [1](#alg1 "算法 1 ‣ 8 发现 2: 通过图像去噪器进行图像合成 ‣ 图像去噪: 深度学习革命及其后续
    – 一项调查论文 –") 转变为图像去噪器。除了能够达到近乎完美的感知质量之外，这种方法还有一个优点，即不需要任何特殊的模型训练。关键是，这一发现表明简单的
    MSE 去噪器训练比最初认为的更强大——它不仅可以近似 MMSE 去噪器行为，还可以通过朗之万动力学方案进行后验采样去噪。图 [15](#S9.F15 "图
    15 ‣ 9.1 重新审视图像去噪问题 ‣ 9 发现 3: 高感知质量图像恢复 ‣ 图像去噪: 深度学习革命及其后续 – 一项调查论文 –") 展示了上述方法的去噪结果。从该图中可以得出以下几项观察：'
- en: •
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The generated results are indeed of very high perceptual quality;
  id: totrans-345
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 生成的结果确实具有非常高的感知质量；
- en: •
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Running ALD several times results with different solutions, all valid and yet
    diverse – see the STD image that exposes the uncertainty within the task being
    solved;
  id: totrans-347
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 多次运行 ALD 会得到不同的解决方案，所有方案都有效且各具多样性——请参阅 STD 图像，展示了解决任务中的不确定性；
- en: •
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Denoising ${\mathbf{y}}$ directly by $D({\mathbf{y}},\sigma_{{\mathbf{y}}})$
    leads to better MMSE but poorer perceptual quality;
  id: totrans-349
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过 $D({\mathbf{y}},\sigma_{{\mathbf{y}}})$ 直接去噪 ${\mathbf{y}}$ 可以获得更好的 MMSE，但感知质量较差；
- en: •
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The figure also shows the evolving solution within the ALD steps, and as can
    be seen, the noise in ${\mathbf{y}}$ is effectively peeled layer by layer.
  id: totrans-351
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 该图还显示了 ALD 步骤中的演变解决方案，可以看出，${\mathbf{y}}$ 中的噪声被有效地逐层去除。
- en: '![Refer to caption](img/6d58b9fef540972602700a6e5417cf40.png)'
  id: totrans-352
  prefs: []
  type: TYPE_IMG
  zh: '![请参阅说明](img/6d58b9fef540972602700a6e5417cf40.png)'
- en: 'Figure 15: Image denoising using the modified version of Annealed Langevin
    Dynamics [[146](#bib.bib146)]. Top row (left to right): An original image, its
    noisy version ($\sigma_{{\mathbf{y}}}=100$), the MMSE-optimized denoiser’s result,
    and the STD of the sampled solutions. Middle row: 6 sampled ALD denoising solutions.
    Bottom row: 6 intermediate steps within the ALD algorithm.'
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: '图 15: 使用改进版的退火朗之万动力学进行图像去噪 [[146](#bib.bib146)]。顶部行（从左到右）：原始图像、其噪声版本 ($\sigma_{{\mathbf{y}}}=100$)、MMSE
    优化去噪器的结果以及采样解决方案的 STD。中间行：6 个 ALD 去噪解决方案。底部行：ALD 算法中的 6 个中间步骤。'
- en: 9.2 High Perceptual Quality Solution to Inverse Problems
  id: totrans-354
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 9.2 高感知质量的逆问题解决方案
- en: We now expand our discussion by returning to general linear inverse problems
    of the form ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$, where ${\mathbf{H}}\in\mathbb{R}^{M\times
    N}$ is a known matrix, ${\mathbf{v}}\in\mathbb{R}^{M}$ is AWGN, and ${\mathbf{y}}\in\mathbb{R}^{M}$
    is the given measurement vector. Our goal is to propose novel solutions to these
    problems while striving for high perceptual quality.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在通过回到一般线性逆问题 ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$ 扩展我们的讨论，其中
    ${\mathbf{H}}\in\mathbb{R}^{M\times N}$ 是已知矩阵，${\mathbf{v}}\in\mathbb{R}^{M}$
    是 AWGN，${\mathbf{y}}\in\mathbb{R}^{M}$ 是给定的测量向量。我们的目标是提出这些问题的新颖解决方案，同时追求高感知质量。
- en: The above discussion on the perception-distortion tradeoff is not limited to
    image denoising, but also applies to more general inverse problems [[22](#bib.bib22)].
    There too, potential solvers need to tradeoff distortion metrics (e.g. MSE) versus
    perception measures (e.g. the distribution shift between real images and the obtained
    solutions). Indeed, MSE in these cases may become far more challenging as an optimization
    goal due to the ill-posedness of the inverse problems. Consider, as an example,
    an inpainting problem in which the bottom half of the image is given and the goal
    is to recover the top part. The MMSE solution in this case necessarily averages
    all possible completions, resulting in a very blurry outcome. More broadly, optimizing
    for MSE in this context would result in a clear regression-to-the-mean, which
    is significantly more pronounced in under-determined inverse problems than in
    image denoising.
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 上述关于感知-失真权衡的讨论不仅限于图像去噪，还适用于更一般的逆问题[[22](#bib.bib22)]。在这些问题中，潜在的求解器需要在失真度量（如
    MSE）和感知度量（如真实图像与获得解之间的分布差异）之间做权衡。实际上，由于逆问题的病态性，MSE 作为优化目标可能变得更加困难。例如，考虑一个修复问题，其中图像的下半部分已知，而目标是恢复上半部分。在这种情况下，MMSE
    解决方案必然会对所有可能的完成结果取平均，从而导致非常模糊的结果。更广泛地说，在这种背景下优化 MSE 会导致明显的均值回归，这在欠定的逆问题中比在图像去噪中更为显著。
- en: 'Successful inverse problem solvers, such as the Plug-and-Play Prior [[295](#bib.bib295)]
    and RED [[231](#bib.bib231)] algorithms mentioned in Section [7](#S7 "7 Discovery
    1: Solving Inverse Problems via Image Denoisers ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –"), aim for a Maximum-a-Posteriori (MAP)
    solution to the inverse problem at hand, rather than MMSE. While these methods
    achieve impressive results, the MAP solution can be improved upon in terms of
    perceptual quality without compromising on distortion performance [[22](#bib.bib22)].
    This is due to the deterministic nature of MAP solvers – a solver that aims for
    best perceptual quality should necessarily be stochastic in order to account for
    the multiple possible solutions to the given problem [[211](#bib.bib211)].'
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: '成功的逆问题求解器，例如第[7](#S7 "7 Discovery 1: Solving Inverse Problems via Image Denoisers
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")节提到的
    Plug-and-Play Prior [[295](#bib.bib295)] 和 RED [[231](#bib.bib231)] 算法，旨在对当前逆问题进行最大后验（MAP）求解，而不是
    MMSE。尽管这些方法取得了令人印象深刻的结果，但在不牺牲失真性能的情况下，MAP 解决方案的感知质量可以得到改善[[22](#bib.bib22)]。这是由于
    MAP 求解器的确定性特征——一个旨在最佳感知质量的求解器必须是随机的，以考虑到给定问题的多种可能解决方案[[211](#bib.bib211)]。'
- en: '![Refer to caption](img/56e0f82d432ef6608aa992be117176ef.png)'
  id: totrans-358
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/56e0f82d432ef6608aa992be117176ef.png)'
- en: 'Figure 16: Comparison of an MMSE result with samples from the posterior distribution
    using SNIPS [[145](#bib.bib145)]. Note the subtle improvements in perceptual quality
    from MMSE to the posterior samples, especially in the finer details such as the
    hair. The comparison is conducted on $64\times 64$ pixel images from CelebA [[172](#bib.bib172)],
    on the problems of compressive sensing, inpainting, and $4\times$ super-resolution
    (top-to-bottom).'
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：使用 SNIPS [[145](#bib.bib145)] 比较 MMSE 结果与后验分布样本。注意从 MMSE 到后验样本的感知质量的微妙改进，特别是在发丝等细节上。比较是在来自
    CelebA [[172](#bib.bib172)] 的 $64\times 64$ 像素图像上进行的，涉及压缩感知、修复和 $4\times$ 超分辨率（从上到下）。
- en: 'Similar to the image denoising case, stochastically sampling from the posterior
    distribution achieves perfect perceptual quality in general inverse problems.
    Following the road paved in the previous section, an appealing way to approximate
    such sampling would be to follow Equation ([29](#S9.E29 "Equation 29 ‣ 9.1 Revisiting
    the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")),
    using a generative diffusion model and augmenting the score by an analytical term
    that conditions on the observed measurement $\mathbf{y}$. This idea has been initially
    suggested by [[262](#bib.bib262), [138](#bib.bib138)] for handling noiseless linear
    inverse problems, and later extended to the more general case in [[145](#bib.bib145),
    [142](#bib.bib142), [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)]. Below
    we describe the essence of the proposed approach in SNIPS [[145](#bib.bib145)].
    Visual examples of this method in action are brought in Figure [16](#S9.F16 "Figure
    16 ‣ 9.2 High Perceptual Quality Solution to Inverse Problems ‣ 9 Discovery 3:
    High Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –") for several inverse problems.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 与图像去噪情况类似，从后验分布中进行随机采样在一般逆问题中通常能达到完美的感知质量。按照上一节铺垫的思路，一种近似此类采样的吸引方式是遵循方程 ([29](#S9.E29
    "方程 29 ‣ 9.1 重新审视图像去噪问题 ‣ 9 发现 3：高感知质量图像恢复 ‣ 图像去噪：深度学习的革命及其未来 – 一项调查论文"))，使用生成扩散模型，并通过一个条件于观察测量$\mathbf{y}$的解析项来增强分数。这个想法最初由[[262](#bib.bib262),
    [138](#bib.bib138)]提出用于处理无噪声线性逆问题，后来扩展到更一般的情况[[145](#bib.bib145), [142](#bib.bib142),
    [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)]。下面我们描述了SNIPS中提出方法的精髓[[145](#bib.bib145)]。此方法在多个逆问题中的视觉示例见于图[16](#S9.F16
    "图 16 ‣ 9.2 高感知质量逆问题解决方案 ‣ 9 发现 3：高感知质量图像恢复 ‣ 图像去噪：深度学习的革命及其未来 – 一项调查论文")。
- en: 'Our goal is to obtain a closed-form expression for the term $\nabla_{{\tilde{\mathbf{x}}}}\log
    p({\mathbf{y}}|{\tilde{\mathbf{x}}})$ in Equation ([29](#S9.E29 "Equation 29 ‣
    9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")). We use the following two relationships: (i) ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$
    is the noisy measurement (${\mathbf{v}}\sim{\cal N}\left(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}\right)$),
    and (ii) ${\tilde{\mathbf{x}}}={\mathbf{x}}+{\mathbf{z}}$ is the annealed solution
    (${\mathbf{z}}\sim{\cal N}(0,\sigma_{i}^{2}{\mathbf{I}})$). The likelihood function
    can be simplified to'
  id: totrans-361
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的目标是获得方程中的项$\nabla_{{\tilde{\mathbf{x}}}}\log p({\mathbf{y}}|{\tilde{\mathbf{x}}})$的闭式表达式
    ([29](#S9.E29 "方程 29 ‣ 9.1 重新审视图像去噪问题 ‣ 9 发现 3：高感知质量图像恢复 ‣ 图像去噪：深度学习的革命及其未来 –
    一项调查论文"))。我们使用以下两个关系：(i) ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$
    是带噪测量 (${\mathbf{v}}\sim{\cal N}\left(0,\sigma_{{\mathbf{y}}}^{2}{\mathbf{I}}\right)$)，以及
    (ii) ${\tilde{\mathbf{x}}}={\mathbf{x}}+{\mathbf{z}}$ 是退火解 (${\mathbf{z}}\sim{\cal
    N}(0,\sigma_{i}^{2}{\mathbf{I}})$)。似然函数可以简化为
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\mathbf{H}}{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  id: totrans-362
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{y}}-{\mathbf{H}}{\tilde{\mathbf{x}}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}-{\mathbf{H}}{\mathbf{x}}-{\mathbf{H}}{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
  id: totrans-363
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}-{\mathbf{H}}{\mathbf{x}}-{\mathbf{H}}{\mathbf{z}}&#124;{\tilde{\mathbf{x}}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}}).$
    |  |'
  id: totrans-364
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}}).$
    |  |'
- en: 'As in the denoising case in Equation ([9.1](#S9.Ex2 "9.1 Revisiting the Image
    Denoising Problem ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")), statistical
    independence between ${\mathbf{v}}$ and ${\mathbf{z}}$ cannot be assumed due to
    the dependency on ${\tilde{\mathbf{x}}}$. The alternative, as shown by SNIPS [[145](#bib.bib145)]
    relies again on a delicate connection between these two random entities, obtained
    by a decoupling of the measurements’ equation via an Singular Value Decomposition
    (SVD) of the degradation matrix $\mathbf{H}={\mathbf{U}}\bm{\Sigma}{\mathbf{V}}^{T}$:'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: '与方程 ([9.1](#S9.Ex2 "9.1 Revisiting the Image Denoising Problem ‣ 9 Discovery
    3: High Perceptual Quality Image Recovery ‣ Image Denoising: The Deep Learning
    Revolution and Beyond – A Survey Paper –")) 中的去噪情况类似，由于依赖于 ${\tilde{\mathbf{x}}}$，${\mathbf{v}}$
    和 ${\mathbf{z}}$ 之间不能假设统计独立。SNIPS [[145](#bib.bib145)] 提出的替代方法再次依赖于这两个随机实体之间的微妙联系，通过对退化矩阵
    $\mathbf{H}={\mathbf{U}}\bm{\Sigma}{\mathbf{V}}^{T}$ 进行奇异值分解 (SVD) 来实现测量方程的解耦：'
- en: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}})$
    |  |'
  id: totrans-366
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle p({\mathbf{y}}&#124;{\tilde{\mathbf{x}}})$ | $\displaystyle=$
    | $\displaystyle p({\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}&#124;{\mathbf{x}}+{\mathbf{z}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{U}}^{T}{\mathbf{v}}-\bm{\Sigma}{\mathbf{V}}^{T}{\mathbf{z}}&#124;{\mathbf{V}}^{T}{\mathbf{x}}+{\mathbf{V}}^{T}{\mathbf{z}})$
    |  |'
  id: totrans-367
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\mathbf{U}}^{T}{\mathbf{v}}-\bm{\Sigma}{\mathbf{V}}^{T}{\mathbf{z}}&#124;{\mathbf{V}}^{T}{\mathbf{x}}+{\mathbf{V}}^{T}{\mathbf{z}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle p({\hat{\mathbf{v}}}-\bm{\Sigma}{\hat{\mathbf{z}}}&#124;{\hat{\mathbf{x}}}+{\hat{\mathbf{z}}})$
    |  |'
  id: totrans-368
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle p({\hat{\mathbf{v}}}-\bm{\Sigma}{\hat{\mathbf{z}}}&#124;{\hat{\mathbf{x}}}+{\hat{\mathbf{z}}})$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle\prod_{k}p({\hat{v}}_{k}-s_{k}{\hat{z}}_{k}&#124;{\hat{x}}_{k}+{\hat{z}}_{k}).$
    |  |'
  id: totrans-369
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle\prod_{k}p({\hat{v}}_{k}-s_{k}{\hat{z}}_{k}&#124;{\hat{x}}_{k}+{\hat{z}}_{k}).$
    |  |'
- en: 'The second row in the above equation is obtained by transforming the term ${\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}$
    by the matrix ${\mathbf{U}}^{T}$, and similarly transforming ${\mathbf{x}}+{\mathbf{z}}$
    via a multiplication with ${\mathbf{V}}^{T}$. As these are unitary matrices, the
    transformations applied do not change the statistics. Considering the transformed
    vectors ${\mathbf{U}}^{T}{\mathbf{y}}={\hat{\mathbf{y}}}$, ${\mathbf{V}}^{T}{\mathbf{x}}={\hat{\mathbf{x}}}$,
    ${\mathbf{V}}^{T}{\mathbf{z}}={\hat{\mathbf{z}}}$ and ${\mathbf{U}}^{T}{\mathbf{v}}={\hat{\mathbf{v}}}$
    leads to the third row in the above equation. This joint probability can be decoupled
    into a separable Gaussian distribution if we choose each entry ${\hat{v}}_{k}-s_{k}{\hat{z}}_{k}$
    to be independent of ${\hat{z}}_{k}$, just as practiced in the denoising case,
    and this time while taking into account the singular value $s_{k}$. This algorithm,
    fully described in [[145](#bib.bib145)], demonstrates considerable success in
    a number of inverse problems (see Figure [16](#S9.F16 "Figure 16 ‣ 9.2 High Perceptual
    Quality Solution to Inverse Problems ‣ 9 Discovery 3: High Perceptual Quality
    Image Recovery ‣ Image Denoising: The Deep Learning Revolution and Beyond – A
    Survey Paper –")), and already has several followup works [[142](#bib.bib142),
    [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)].'
  id: totrans-370
  prefs: []
  type: TYPE_NORMAL
  zh: '上述方程的第二行是通过矩阵 ${\mathbf{U}}^{T}$ 对项 ${\mathbf{v}}-{\mathbf{H}}{\mathbf{z}}$
    进行变换得到的，并通过与 ${\mathbf{V}}^{T}$ 的乘法类似地对 ${\mathbf{x}}+{\mathbf{z}}$ 进行变换。由于这些是单位矩阵，所施加的变换不会改变统计量。考虑到变换后的向量
    ${\mathbf{U}}^{T}{\mathbf{y}}={\hat{\mathbf{y}}}$、${\mathbf{V}}^{T}{\mathbf{x}}={\hat{\mathbf{x}}}$、${\mathbf{V}}^{T}{\mathbf{z}}={\hat{\mathbf{z}}}$
    和 ${\mathbf{U}}^{T}{\mathbf{v}}={\hat{\mathbf{v}}}$ 得到上述方程中的第三行。如果我们选择每个条目 ${\hat{v}}_{k}-s_{k}{\hat{z}}_{k}$
    与 ${\hat{z}}_{k}$ 独立，就像在去噪案例中一样，并且这次考虑到奇异值 $s_{k}$，则这个联合概率可以被分解成一个可分离的高斯分布。这个算法在[[145](#bib.bib145)]中有详细描述，在多个逆问题中表现出显著的成功（参见图
    [16](#S9.F16 "Figure 16 ‣ 9.2 High Perceptual Quality Solution to Inverse Problems
    ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –")），并且已经有了几个后续工作 [[142](#bib.bib142),
    [54](#bib.bib54), [53](#bib.bib53), [195](#bib.bib195)]。'
- en: We should mention that an alternative to all the above exists, in which one
    simply adds the corrupted measurements $\mathbf{y}$ as an input to the denoising
    model itself, effectively conditioning the entire generative process on $\mathbf{y}$ [[245](#bib.bib245),
    [243](#bib.bib243), [303](#bib.bib303)]. This approach requires designing and
    training a separate denoiser for each inverse problem, as the denoiser would need
    to implicitly learn the connection between the images and their corresponding
    measurements for the specific problem at hand. Interestingly, this approach requires
    pairs of images, $\mathbf{x}$ and $\mathbf{y}$, in its training, but does not
    utilize knowledge of the degradation model itself (e.g., the matrix $\mathbf{H}$).
    This property allows this alternative approach to generalize beyond clearly formulated
    inverse problems, and handle tasks such as stylization, JPEG-deblocking, and more.
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 我们应该提到，所有上述方法中存在一种替代方案，其中将损坏的测量值$\mathbf{y}$作为输入直接添加到去噪模型中，从而有效地将整个生成过程条件化于$\mathbf{y}$[[245](#bib.bib245),
    [243](#bib.bib243), [303](#bib.bib303)]。这种方法需要为每个逆问题设计和训练一个单独的去噪器，因为去噪器需要隐式学习图像与其对应测量之间的连接。值得注意的是，这种方法在训练时需要图像对$\mathbf{x}$和$\mathbf{y}$，但不利用降解模型本身的知识（例如，矩阵$\mathbf{H}$）。这一特性使得这种替代方法能够超越明确制定的逆问题进行泛化，并处理诸如风格化、JPEG去块等任务。
- en: '![Refer to caption](img/5287ce1d87ab1ae8ca56ef7937a0eb7c.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5287ce1d87ab1ae8ca56ef7937a0eb7c.png)'
- en: 'Figure 17: Examples of synthesized images using DALL-E 2 [[224](#bib.bib224)],
    a text-to-image generative denoising diffusion model. The input conditioning text
    is written below each image.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图 17：使用 DALL-E 2[[224](#bib.bib224)]的合成图像示例，它是一个文本到图像生成去噪扩散模型。输入的条件文本写在每张图像下方。
- en: 'A particularly interesting case is when $\mathbf{y}$ is a textual description
    of the image contents. By conditioning the denoiser model on such text, the generative
    diffusion process allows users to perform *text-to-image generation* [[224](#bib.bib224),
    [244](#bib.bib244), [232](#bib.bib232), [14](#bib.bib14)]. This unprecedented
    capability became instantly popular, as users were able to synthesize high-quality
    images by simply describing the desired result in natural language, as we demonstrate
    in Figure [17](#S9.F17 "Figure 17 ‣ 9.2 High Perceptual Quality Solution to Inverse
    Problems ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –"). These models have
    become a centerpiece in an ongoing and quickly advancing research area, as they
    have been adapted for image editing [[147](#bib.bib147), [202](#bib.bib202)],
    object recontextualization [[241](#bib.bib241), [95](#bib.bib95)], 3D object generation [[220](#bib.bib220)],
    and more [[119](#bib.bib119), [129](#bib.bib129), [213](#bib.bib213), [346](#bib.bib346)].'
  id: totrans-374
  prefs: []
  type: TYPE_NORMAL
  zh: '一个特别有趣的情况是，当$\mathbf{y}$是图像内容的文本描述时。通过对这种文本进行去噪模型的条件设定，生成扩散过程允许用户执行*文本到图像生成*[[224](#bib.bib224),
    [244](#bib.bib244), [232](#bib.bib232), [14](#bib.bib14)]。这一前所未有的能力迅速流行开来，因为用户可以仅通过自然语言描述所需的结果来合成高质量图像，如我们在图
    [17](#S9.F17 "Figure 17 ‣ 9.2 High Perceptual Quality Solution to Inverse Problems
    ‣ 9 Discovery 3: High Perceptual Quality Image Recovery ‣ Image Denoising: The
    Deep Learning Revolution and Beyond – A Survey Paper –") 中所示。这些模型已成为一个持续快速发展的研究领域的核心，因为它们已被适用于图像编辑[[147](#bib.bib147),
    [202](#bib.bib202)]、对象重定位[[241](#bib.bib241), [95](#bib.bib95)]、3D 对象生成[[220](#bib.bib220)]等更多应用[[119](#bib.bib119),
    [129](#bib.bib129), [213](#bib.bib213), [346](#bib.bib346)]。'
- en: 10 Conclusion
  id: totrans-375
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 10 结论
- en: 'Removal of white additive Gaussian noise from an image is a fascinating topic,
    both because it poses a very interesting engineering challenge, and even more
    so, because it creates new opportunities in image processing and machine learning.
    In this paper we highlight these two branches of activities. The first half of
    the paper concentrates on the design of such denoisers, with a particular interest
    on the impact of the AI revolution on this field. The second half of the paper
    features the usefulness of such image denoisers for handling other tasks, such
    as image synthesis and solving inverse problems while targeting high-perceptual
    quality solutions. Figure [18](#S10.F18 "Figure 18 ‣ 10 Conclusion ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") encapsulates this
    part of the story in a block diagram.'
  id: totrans-376
  prefs: []
  type: TYPE_NORMAL
  zh: 从图像中去除白色加性高斯噪声是一个引人入胜的主题，既因为它提出了一个非常有趣的工程挑战，更因为它在图像处理和机器学习中创造了新的机会。在本文中，我们强调了这两个活动分支。论文的前半部分集中于这类去噪器的设计，特别关注人工智能革命对这一领域的影响。论文的后半部分展示了这些图像去噪器在处理其他任务时的有用性，如图像合成和解决逆问题，同时目标是高感知质量的解决方案。图
    [18](#S10.F18 "图 18 ‣ 10 结论 ‣ 图像去噪：深度学习革命及其未来 – 一项调查论文 –") 通过框图概括了这一部分内容。
- en: Much remains to be done in this domain, in better understanding how to design
    appropriate MMSE denoisers, and in harnessing them to other tasks beyond the ones
    described in this paper, such as compression, segmentation, and more. More broadly,
    there are so many opportunities and challenges in better understanding, designing,
    and proposing creative usage of image denoisers.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 在这个领域还有很多工作要做，以更好地理解如何设计合适的 MMSE 去噪器，并将其应用于本文所述之外的其他任务，如压缩、分割等。更广泛地说，了解、设计和提出图像去噪器的创新使用还有许多机会和挑战。
- en: '![Refer to caption](img/b42e0aa648a9841e72c910ba546970b0.png)'
  id: totrans-378
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/b42e0aa648a9841e72c910ba546970b0.png)'
- en: 'Figure 18: A summary of the main message of this paper: an MMSE denoiser is
    key in synthesizing images and solving inverse problems. Interestingly, there
    is a great unexplored proximity between PnP and RED algorithms [[295](#bib.bib295),
    [231](#bib.bib231)] and the more recent, diffusion-based, techniques for getting
    high perceptual quality solutions for inverse problems [[145](#bib.bib145), [53](#bib.bib53),
    [195](#bib.bib195)].'
  id: totrans-379
  prefs: []
  type: TYPE_NORMAL
  zh: 图 18：本文主要信息的总结：MMSE 去噪器在图像合成和解决逆问题中是关键的。有趣的是，PnP 和 RED 算法之间存在很大的未被探索的接近性 [[295](#bib.bib295),
    [231](#bib.bib231)]，以及更近期的基于扩散的技术，这些技术用于获取逆问题的高感知质量解决方案 [[145](#bib.bib145), [53](#bib.bib53),
    [195](#bib.bib195)]。
- en: Appendix A Derivation of the MMSE Estimation
  id: totrans-380
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 A MMSE 估计的推导
- en: Consider an ideal image ${\mathbf{x}}$ drawn from the probability density function
    $p({\mathbf{x}})$, and assume that we are given a measurement of it, ${\mathbf{y}}$,
    related to it via the conditional probability $p({\mathbf{y}}|{\mathbf{x}})$.
    Our goal is to find the estimator ${\hat{\mathbf{x}}}=f({\mathbf{y}})$ that minimizes
    the expected mean-squared-error,
  id: totrans-381
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一个从概率密度函数 $p({\mathbf{x}})$ 中抽取的理想图像 ${\mathbf{x}}$，并假设我们得到了与其相关的测量 ${\mathbf{y}}$，通过条件概率
    $p({\mathbf{y}}|{\mathbf{x}})$ 关联。我们的目标是找到一个估计器 ${\hat{\mathbf{x}}}=f({\mathbf{y}})$，以最小化期望均方误差，
- en: '| (34) |  | $\displaystyle MSE=\mathbb{E}\left(\&#124;{\mathbf{x}}-{\hat{\mathbf{x}}}\&#124;_{2}^{2}~{}&#124;~{}{\mathbf{y}}\right)=\mathbb{E}\left(\&#124;{\mathbf{x}}-f({\mathbf{y}})\&#124;_{2}^{2}~{}&#124;~{}{\mathbf{y}}\right)=\int\&#124;{\mathbf{x}}-f({\mathbf{y}})\&#124;_{2}^{2}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  id: totrans-382
  prefs: []
  type: TYPE_TB
  zh: '| (34) |  | $\displaystyle MSE=\mathbb{E}\left(\left\|{\mathbf{x}}-{\hat{\mathbf{x}}}\right\|_{2}^{2}~{}|~{}{\mathbf{y}}\right)=\mathbb{E}\left(\left\|{\mathbf{x}}-f({\mathbf{y}})\right\|_{2}^{2}~{}|~{}{\mathbf{y}}\right)=\int\left\|{\mathbf{x}}-f({\mathbf{y}})\right\|_{2}^{2}p({\mathbf{x}}|{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
- en: Observe that this expectation is taken with respect to the unknown image ${\mathbf{x}}$,
    while considering ${\mathbf{y}}$ as known. In order to minimize the above measure,
    we take a derivative of this expression with respect to $f({\mathbf{y}})$ and
    null it,
  id: totrans-383
  prefs: []
  type: TYPE_NORMAL
  zh: 注意到这个期望是关于未知图像 ${\mathbf{x}}$ 计算的，同时考虑 ${\mathbf{y}}$ 为已知。为了最小化上述度量，我们对这个表达式关于
    $f({\mathbf{y}})$ 求导并使其为零，
- en: '| (35) |  | $\displaystyle\frac{d}{df({\mathbf{y}})}\int\left\&#124;{\mathbf{x}}-f({\mathbf{y}})\right\&#124;_{2}^{2}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=-2\int\left({\mathbf{x}}-f({\mathbf{y}})\right)p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=0.$
    |  |'
  id: totrans-384
  prefs: []
  type: TYPE_TB
  zh: '| (35) |  | $\displaystyle\frac{d}{df({\mathbf{y}})}\int\left\|{\mathbf{x}}-f({\mathbf{y}})\right\|_{2}^{2}p({\mathbf{x}}|{\mathbf{y}})d{\mathbf{x}}=-2\int\left({\mathbf{x}}-f({\mathbf{y}})\right)p({\mathbf{x}}|{\mathbf{y}})d{\mathbf{x}}=0.$
    |  |'
- en: This results in
  id: totrans-385
  prefs: []
  type: TYPE_NORMAL
- en: '| (36) |  | $\displaystyle\int{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\int
    f({\mathbf{y}})p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=f({\mathbf{y}})\int
    p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=f({\mathbf{y}}).$ |  |'
  id: totrans-386
  prefs: []
  type: TYPE_TB
- en: The last step on the right-hand-side relies on the fact that $\int p({\mathbf{x}}|{\mathbf{y}})d{\mathbf{x}}=1$.
    Thus, we get the familiar closed-form solution for the MMSE estimation [[217](#bib.bib217)],
  id: totrans-387
  prefs: []
  type: TYPE_NORMAL
- en: '| (37) |  | $\displaystyle f_{MMSE}({\mathbf{y}})=\int_{\mathbf{x}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}=\mathbb{E}\left({\mathbf{x}}&#124;{\mathbf{y}}\right).$
    |  |'
  id: totrans-388
  prefs: []
  type: TYPE_TB
- en: As a final step, as the posterior is not directly accessible, we may use the
    Bayes rule [[137](#bib.bib137)] and write
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
- en: '| (38) |  | $\displaystyle f_{MMSE}({\mathbf{y}})=\int_{\mathbf{x}}{\mathbf{x}}\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{p({\mathbf{y}})}d{\mathbf{x}}=\int_{\mathbf{x}}{\mathbf{x}}\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{\int_{\mathbf{x}}p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}}d{\mathbf{x}},$
    |  |'
  id: totrans-390
  prefs: []
  type: TYPE_TB
- en: where this formula uses the ingredients we started with – $p({\mathbf{y}}|{\mathbf{x}})$
    and $p({\mathbf{x}})$.
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B A Closer Look at the Evolution of Priors
  id: totrans-392
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using the Gibbs distribution form, $p({\mathbf{x}})=c\cdot\exp\{-\rho({\mathbf{x}})\}$,
    we shift our focus from the probability density function $p({\mathbf{x}})$ to
    it’s corresponding energy function $\rho({\mathbf{x}})$. Table [1](#S3.T1 "Table
    1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") brings a list of
    possible analytical expressions for $\rho({\mathbf{x}})$ as evolved in the image
    processing literature. Below we describe each of these options briefly, adopting
    the context of solving a general linear inverse problem of the form ${\mathbf{y}}={\mathbf{H}}{\mathbf{x}}+{\mathbf{v}}$
    with the assumptions that ${\mathbf{v}}\sim{\cal N}({\mathbf{0}},\sigma^{2}{\mathbf{I}})$
    and ${\mathbf{H}}$ is a full-rank known matrix of size $m\times N$ ($m<N$). The
    MAP estimation in this case is given by'
  id: totrans-393
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{\hat{\mathbf{x}}}_{MAP}$ | $\displaystyle=$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\frac{\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}}{2\sigma^{2}}-\log\left(p({\mathbf{x}})\right)\right]$
    |  |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\operatorname*{arg\,min}_{{\mathbf{x}}}\left[\&#124;{\mathbf{H}}{\mathbf{x}}-{\mathbf{y}}\&#124;_{2}^{2}+c\cdot\rho({\mathbf{x}})\right].$
    |  |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
- en: 'Notice that $2\sigma^{2}$ was absorbed into the constant: $c=2\sigma^{2}$.
    Armed with this expression, let’s consider each of the choices in Table [1](#S3.T1
    "Table 1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image
    Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –") and explore
    its implications. Before diving into these options, observe that without the regularization
    provided by $\rho({\mathbf{x}})$, the above optimization becomes an ill-posed
    Least-Squares problem with infinitely many possible solutions. Thus, the added
    prior serves as an important regularization, pushing towards a single (and hopefully,
    meaningful) solution.'
  id: totrans-396
  prefs: []
  type: TYPE_NORMAL
  zh: '注意 $2\sigma^{2}$ 被吸收到常数中：$c=2\sigma^{2}$。掌握了这个表达式后，让我们考虑表 [1](#S3.T1 "Table
    1 ‣ 3.2 Evolution of Priors ‣ 3 Image Denoising – The Classic Era ‣ Image Denoising:
    The Deep Learning Revolution and Beyond – A Survey Paper –") 中的每一个选项并探索其含义。在深入探讨这些选项之前，请注意，没有
    $\rho({\mathbf{x}})$ 提供的正则化，上述优化变成了一个病态的最小二乘问题，可能有无限多的解。因此，增加的先验作为重要的正则化，有助于推向单一（并且希望是有意义的）解。'
- en: •
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Energy regularization: If ${\mathbf{H}}^{T}{\mathbf{H}}$ cannot be inverted,
    the most obvious algebraic remedy would be to add a constant to its diagonal,
    resulting with the regularized solution ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{I}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    This is exactly the solution offered by the choice $\rho({\mathbf{x}})=\|{\mathbf{x}}\|_{2}^{2}$,
    and when the constant $c$ is taken to $0$, this leads to the familiar pseudo-inverse
    solution ${\hat{\mathbf{x}}}_{MAP}={\mathbf{H}}^{\dagger}{\mathbf{y}}$. While
    mathematically appealing, this option does not yield satisfactory visual results [[251](#bib.bib251)].'
  id: totrans-398
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 能量正则化：如果 ${\mathbf{H}}^{T}{\mathbf{H}}$ 不能被逆，则最明显的代数补救办法是向其对角线添加一个常数，从而得到正则化解
    ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{I}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$。这正是选择
    $\rho({\mathbf{x}})=\|{\mathbf{x}}\|_{2}^{2}$ 提供的解，当常数 $c$ 取 $0$ 时，会得到熟悉的伪逆解 ${\hat{\mathbf{x}}}_{MAP}={\mathbf{H}}^{\dagger}{\mathbf{y}}$。虽然数学上很有吸引力，但这个选项并未产生令人满意的视觉效果
    [[251](#bib.bib251)]。
- en: •
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Spatial Smoothness: It is well-known that adjacent pixels in natural images
    are more likely to be of smoothly varying values. Thus, penalizing a deviation
    from such a smoothness property seems well-justified [[15](#bib.bib15), [154](#bib.bib154)].
    Plugging the option $\rho({\mathbf{x}})=\|{\mathbf{L}}{\mathbf{x}}\|_{2}^{2}$
    into the MAP expression leads to the closed-form solution ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{L}}^{T}{\mathbf{L}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$,
    which is very-closely related to the well-known Wiener filter [[304](#bib.bib304)].'
  id: totrans-400
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 空间平滑性：众所周知，自然图像中的相邻像素更可能具有平滑变化的值。因此，对这种平滑性特征的偏离进行惩罚似乎是合理的 [[15](#bib.bib15),
    [154](#bib.bib154)]。将选项 $\rho({\mathbf{x}})=\|{\mathbf{L}}{\mathbf{x}}\|_{2}^{2}$
    代入 MAP 表达式，得到封闭形式的解 ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{L}}^{T}{\mathbf{L}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$，这与著名的维纳滤波器密切相关
    [[304](#bib.bib304)]。
- en: •
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Optimally Learned Transform: Given a large enough dataset of images, we could
    fit a multivariate Gaussian ${\cal N}({\mathbf{0}},{\mathbf{R}})$ to them by adjusting
    the second moment. The assumed zero mean is easily obtained by subtracting the
    mean image from the given data. PCA [[215](#bib.bib215)] or Karhunen-Loéve Transform
    (KLT) [[174](#bib.bib174), [140](#bib.bib140), [37](#bib.bib37), [136](#bib.bib136)]
    offer a clear computational path towards this moment matrix ${\mathbf{R}}$ as
    the auto-correlation matrix of the available data. When the expression $\rho({\mathbf{x}})={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    is plugged into the MAP estimation, we come back to the Wiener filter, this time
    as ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{R}}^{-1})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    Note that the same treatment could emerge from this formulation – $\rho({\mathbf{x}})=\|{\mathbf{T}}{\mathbf{x}}\|_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$,
    where ${\mathbf{T}}$ is the corresponding transform that should be applied on
    ${\mathbf{x}}$, and clearly ${\mathbf{T}}^{T}{\mathbf{T}}={\mathbf{R}}^{-1}$.'
  id: totrans-402
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Weighted Smoothness: All the above options suffer from the same difficulty
    – they produce overly smoothed results. In retrospect, the reason is obvious:
    non-smooth behavior is heavily penalized and thus not encouraged, which results
    with smeared edges. A way to overcome this difficulty is to produce a weight map
    that describes the local smoothness tendency – regions in which smoothness is
    believed to be correct should be assigned with a high weight, while low weight
    should be given to regions suspected to be textured or edges [[246](#bib.bib246),
    [52](#bib.bib52)]. By constructing a diagonal matrix ${\mathbf{W}}$ that contains
    the above weights as the main diagonal, and using the choice & $\rho({\mathbf{x}})=\|{\mathbf{L}}{\mathbf{x}}\|_{{\mathbf{W}}}^{2}$,
    the MAP estimation becomes ${\hat{\mathbf{x}}}_{MAP}=({\mathbf{H}}^{T}{\mathbf{H}}+c{\mathbf{L}}^{T}{\mathbf{W}}{\mathbf{L}})^{-1}{\mathbf{H}}^{T}{\mathbf{y}}$.
    This is a spatially adaptive solution, dependent on the local weights. One may
    consider an iterative approach where the temporary solution ${\hat{\mathbf{x}}}_{MAP}$
    is leveraged to update the weights and then ${\hat{\mathbf{x}}}_{MAP}$ is re-computed.
    This interesting option leads to the robust statistics alternative discussed next [[20](#bib.bib20)].'
  id: totrans-404
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Before proceeding with the other prior options, we would like to draw the readers’
    attention to the fact that all the above choices correspond to the core assumption
    that the probability density function $p({\mathbf{x}})$ is a multivariate Gaussian.
    The obtained visual results of these techniques expose the fact that this Gaussianity
    assumption is not adequate, and indeed, later research in image processing turned
    to non-Gaussian and heavy-tailed alternative distributions, which we discuss next.
  id: totrans-405
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Robust statistics: Here is a simple experiment – take any natural image, apply
    a Laplacian on it, and gather a histogram of the resulting values. This histogram
    is likely to look as a heavy-tailed probability density function of a form similar
    to $c\cdot\exp(-|x|^{\alpha})$ with $\alpha\ll 2$. This is exactly the deviation
    from Gaussianity referred to above. Thus, the robust statistics alternative [[126](#bib.bib126),
    [97](#bib.bib97), [96](#bib.bib96), [44](#bib.bib44), [238](#bib.bib238)] suggests
    a replacement of the $L_{2}$-norm of ${\mathbf{L}}{\mathbf{x}}$ by $L_{1}$ or,
    more broadly, by functions of the form ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    (e.g. $\mu(x)=|x|^{\alpha}$). Notice that from here on, closed-form MAP solution
    cannot be obtained, and iterative minimization strategies are necessary.'
  id: totrans-407
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 稳健统计：这里有一个简单的实验——取任何自然图像，对其应用拉普拉斯算子，并收集结果值的直方图。这个直方图很可能看起来像 $c\cdot\exp(-|x|^{\alpha})$
    形式的重尾概率密度函数，其中 $\alpha\ll 2$。这正是上述提到的偏离高斯性的现象。因此，稳健统计替代方案[[126](#bib.bib126),
    [97](#bib.bib97), [96](#bib.bib96), [44](#bib.bib44), [238](#bib.bib238)]建议将 ${\mathbf{L}}{\mathbf{x}}$
    的 $L_{2}$ 范数替换为 $L_{1}$，或者更广泛地说，替换为形式为 ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    的函数（例如 $\mu(x)=|x|^{\alpha}$）。请注意，从此处开始，不能获得闭式 MAP 解，必须采用迭代最小化策略。
- en: Adopting a different point of view, robust statistics considers pixel on edges
    and textures regions as outliers to the Gaussian distribution, and thus use robust
    estimation techniques for their better handling.
  id: totrans-408
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采用不同的视角，稳健统计将边缘和纹理区域的像素视为高斯分布的异常值，从而使用稳健估计技术进行更好的处理。
- en: •
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Total-Variation (TV): The same motivation as described above led to this brilliant
    PDE formulation of spatial smoothness, $\rho({\mathbf{x}})=\int_{v\in\Omega}|\nabla{\mathbf{x}}(v)|dv$,
    which accumulates the length of the spatial gradients instead of their squares [[240](#bib.bib240)].
    In its discretized form, its treatment is very similar to the robust-statistics
    option. However, TV has very different roots, providing a geometrically oriented
    edge-preserving measure of smoothness – see various extensions of this line of
    work in [[17](#bib.bib17), [99](#bib.bib99), [39](#bib.bib39), [3](#bib.bib3)].'
  id: totrans-410
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 总变分 (TV)：与上述描述相同的动机导致了这种出色的 PDE 空间平滑度公式 $\rho({\mathbf{x}})=\int_{v\in\Omega}|\nabla{\mathbf{x}}(v)|dv$，它累积了空间梯度的长度而不是它们的平方[[240](#bib.bib240)]。在其离散形式中，其处理方式与稳健统计选项非常相似。然而，TV
    有着非常不同的根源，提供了一种几何导向的保边缘平滑度量——请参见[[17](#bib.bib17), [99](#bib.bib99), [39](#bib.bib39),
    [3](#bib.bib3)]中此工作方向的各种扩展。
- en: •
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Other PDE-based options: While TV applies an $L_{1}$-norm on the spatial gradients,
    more general options can be envisioned, in which the accumulation is spatially
    adaptive, orientation sensitive, geometrically faithful, and more [[216](#bib.bib216),
    [38](#bib.bib38), [255](#bib.bib255), [302](#bib.bib302), [111](#bib.bib111)].
    Starting with the seminal anisotropic diffusion method by Perona and Malik [[216](#bib.bib216)],
    various such methods of the form $\rho({\mathbf{x}})=\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    were proposed and perfected over the years, forming an exciting sub-field of mathematically
    oriented image processing that relies on the vast knowledge in partial differential
    equations.'
  id: totrans-412
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 其他基于 PDE 的选项：虽然 TV 对空间梯度应用了 $L_{1}$ 范数，但可以设想更一般的选项，其中累积是空间自适应的、方向敏感的、几何上真实的，并且更加[[216](#bib.bib216),
    [38](#bib.bib38), [255](#bib.bib255), [302](#bib.bib302), [111](#bib.bib111)]。从
    Perona 和 Malik 的开创性各向异性扩散方法[[216](#bib.bib216)]开始，提出并完善了多种此类方法，其形式为 $\rho({\mathbf{x}})=\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$，形成了一个令人兴奋的数学导向图像处理子领域，依赖于偏微分方程的广泛知识。
- en: •
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Field-of-Experts (FoE): Let us return to the robust statistics option described
    above and enrich it by considering a mixture of such distributions, $\rho({\mathbf{x}})=\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$.
    This implies the need to define a series of functions $\mu_{k}$ and their corresponding
    weights $\lambda_{k}$. FoE suggests to learn these elements from an image dataset,
    thus better fitting the assumed prior to natural images. While earlier work on
    FoE [[236](#bib.bib236)] suggested a patch-based maximum-likelihood learning approach,
    later efforts [[50](#bib.bib50)] brought a deep-learning alternative tools to
    this fitting.'
  id: totrans-414
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Field-of-Experts (FoE): 让我们回到上述提到的强大统计选项，并通过考虑这种分布的混合来丰富它，即 $\rho({\mathbf{x}})=\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$。这意味着需要定义一系列函数
    $\mu_{k}$ 及其对应的权重 $\lambda_{k}$。FoE 建议从图像数据集中学习这些元素，从而更好地将假设的先验拟合到自然图像上。尽管早期关于
    FoE 的工作[[236](#bib.bib236)] 提出了基于补丁的最大似然学习方法，但后来的努力[[50](#bib.bib50)] 带来了深度学习替代工具。'
- en: •
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Wavelet sparsity: The idea of relying on transform coefficients for constructing
    $\rho({\mathbf{x}})$ has already been explored in the context of the KLT. The
    emergence of the Wavelet transform in the late 80’s brought a new way of thinking
    about signals and images, offering an elegant and more effective multi-scale representation
    that relies on non-linear approximation [[77](#bib.bib77), [76](#bib.bib76), [57](#bib.bib57),
    [98](#bib.bib98), [185](#bib.bib185), [177](#bib.bib177), [43](#bib.bib43), [221](#bib.bib221),
    [175](#bib.bib175), [325](#bib.bib325), [108](#bib.bib108)]. Wavelets offer a
    concise description of the data with as few as possible coefficients, this way
    giving birth to the central notion of sparsity. This translates well to the proposed
    prior $\rho({\mathbf{x}})=\|{\mathbf{W}}{\mathbf{x}}\|_{1}$ that promotes fewer
    non-zero dominant Wavelet coefficients.'
  id: totrans-416
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 小波稀疏性：依赖变换系数来构造 $\rho({\mathbf{x}})$ 的思想已经在 KLT 的背景下进行了探索。20 世纪 80 年代末小波变换的出现带来了对信号和图像的新思考方式，提供了一种优雅且更有效的多尺度表示，这种表示依赖于非线性逼近[[77](#bib.bib77),
    [76](#bib.bib76), [57](#bib.bib57), [98](#bib.bib98), [185](#bib.bib185), [177](#bib.bib177),
    [43](#bib.bib43), [221](#bib.bib221), [175](#bib.bib175), [325](#bib.bib325),
    [108](#bib.bib108)]。小波提供了用尽可能少的系数对数据的简明描述，从而孕育了稀疏性的核心概念。这很好地转化为提出的先验 $\rho({\mathbf{x}})=\|{\mathbf{W}}{\mathbf{x}}\|_{1}$，它促进了更少的非零主导小波系数。
- en: 'As an interesting side note, if we are handling the image denoising problem
    – i.e. ${\mathbf{H}}={\mathbf{I}}$ in Equation ([B](#A2.Ex8 "Appendix B A Closer
    Look at the Evolution of Priors ‣ Image Denoising: The Deep Learning Revolution
    and Beyond – A Survey Paper –")) – and the Wavelet transform matrix ${\mathbf{W}}$
    is unitary, the solution ${\hat{\mathbf{x}}}_{MAP}$ has a closed-form solution,
    obtained via a soft-shrinkage [[77](#bib.bib77), [76](#bib.bib76)].'
  id: totrans-417
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 作为一个有趣的附带说明，如果我们处理的是图像去噪问题——即方程 ([B](#A2.Ex8 "附录 B 更深入地看先验的演变 ‣ 图像去噪：深度学习革命及其之后
    – 一项调查论文 –")) 中的 ${\mathbf{H}}={\mathbf{I}}$——并且小波变换矩阵 ${\mathbf{W}}$ 是酉的，则解 ${\hat{\mathbf{x}}}_{MAP}$
    有一个封闭形式的解，通过软阈值方法获得[[77](#bib.bib77), [76](#bib.bib76)]。
- en: •
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Self-similarity: So far we described two primary forces that promote simplicity
    in image content – spatial smoothness and representation sparsity. Self-similarity
    is a third such force that has been recognized as central by series of contributions,
    starting with the seminal Non-Local-Means (NLM) algorithm [[32](#bib.bib32)],
    and heavily relied upon by the famous BM3D [[61](#bib.bib61)] and other algorithms [[181](#bib.bib181),
    [274](#bib.bib274), [187](#bib.bib187), [46](#bib.bib46), [297](#bib.bib297),
    [203](#bib.bib203), [273](#bib.bib273), [248](#bib.bib248), [167](#bib.bib167)].
    Self-similarity stands for the assumption that any given (small-enough) patch
    in an image is likely to find very similar ones in the image support, and thus
    treating these together somehow is likely to lead to better recovery. More specifically,
    the expression we bring here as an illustration,'
  id: totrans-419
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自相似性：到目前为止，我们描述了推动图像内容简洁性的两种主要力量——空间平滑性和表示稀疏性。自相似性是第三种被系列贡献认为是核心的力量，始于开创性的非局部均值
    (NLM) 算法[[32](#bib.bib32)]，并且在著名的 BM3D[[61](#bib.bib61)] 和其他算法[[181](#bib.bib181),
    [274](#bib.bib274), [187](#bib.bib187), [46](#bib.bib46), [297](#bib.bib297),
    [203](#bib.bib203), [273](#bib.bib273), [248](#bib.bib248), [167](#bib.bib167)]
    中被广泛依赖。自相似性代表了一个假设，即图像中任何给定的（足够小的）补丁很可能在图像支持中找到非常相似的补丁，因此将这些补丁一起处理可能会导致更好的恢复。更具体地说，这里提供的表达作为一个例子，
- en: '| (40) |  | $\displaystyle\rho({\mathbf{x}})=\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\},$
    |  |'
  id: totrans-420
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: sweeps through the image support, extract a patch in location $k$ by the operator
    ${\mathbf{R}}_{k}{\mathbf{x}}$, and finds all its corresponding matches $j\in\Omega(k)$.
    Forcing proximity between ${\mathbf{R}}_{k}{\mathbf{x}}$ and the patches ${\mathbf{R}}_{j}{\mathbf{x}}$
    induces a strong regularization over the unknown image ${\mathbf{x}}$.
  id: totrans-421
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sparsity methods: While the notion of sparsity has already been exploited by
    wavelets, later work took this idea and strengthened it by considering redundant
    and learned representations. Under the assumption that ideal images can be described
    as linear combinations of atoms from a pre-specified dictionary ${\mathbf{D}}$,
    i.e., ${\mathbf{x}}={\mathbf{D}}\alpha$, forcing sparsity on the representation
    via the term $\|\alpha\|_{0}$ provides an appealing and computationally feasible
    choice for $\rho({\mathbf{x}})$ [[31](#bib.bib31), [88](#bib.bib88)]. Vast work
    along these lines has been done, considering global dictionaries and later local
    (patch-based) ones, leading to various very successful recovery algorithms [[89](#bib.bib89),
    [90](#bib.bib90), [4](#bib.bib4), [183](#bib.bib183), [182](#bib.bib182), [181](#bib.bib181),
    [81](#bib.bib81), [320](#bib.bib320), [71](#bib.bib71), [74](#bib.bib74), [100](#bib.bib100),
    [72](#bib.bib72), [85](#bib.bib85)].'
  id: totrans-423
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Low-Rank assumption: The last member to enter the Pantheon of image priors
    for image processing relies on a low-rank assumption over groups of similar patches.
    This idea is closely related to the self-similarity force described above, and
    in fact builds on top of it. Given a set of closely related patches, instead of
    forcing proximity between them, one may gather these as columns in a matrix and
    force a low-rank structure, implying that all these patches are spanned by few
    main directions. Several very strong recovery algorithms leveraged this idea in
    various forms, while exploiting theoretical analysis that ties the low-rank requirement
    to the nuclear-norm [[305](#bib.bib305), [35](#bib.bib35)]. By summing these norms
    over such groups, $\rho({\mathbf{x}})=\sum_{k}\|{\mathbf{X}}_{\Omega(k)}\|_{*}$,
    a very potent regularization is obtained [[110](#bib.bib110), [310](#bib.bib310)].'
  id: totrans-425
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table 2: Evolution of priors for images.'
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
- en: '| Years | Core concept | Formulae for $\rho(\cdot)$ | Representative |'
  id: totrans-427
  prefs: []
  type: TYPE_TB
- en: '|  |  |  | Reference |'
  id: totrans-428
  prefs: []
  type: TYPE_TB
- en: '| $\sim$ 1970 | Energy regularization | $\&#124;{\mathbf{x}}\&#124;_{2}^{2}$
    | [[251](#bib.bib251)] |'
  id: totrans-429
  prefs: []
  type: TYPE_TB
- en: '| 1975-1985 | Spatial smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{2}^{2}$
    or $\&#124;{\mathbf{D}}_{v}{\mathbf{x}}\&#124;_{2}^{2}+\&#124;{\mathbf{D}}_{h}{\mathbf{x}}\&#124;_{2}^{2}$
    | [[154](#bib.bib154)] |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
- en: '| 1980-1985 | Optimally Learned Transform | $\&#124;{\mathbf{T}}{\mathbf{x}}\&#124;_{2}^{2}={\mathbf{x}}^{T}{\mathbf{R}}^{-1}{\mathbf{x}}$
    | [[37](#bib.bib37)] |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
- en: '|  |  | where ${\mathbf{T}}/{\mathbf{R}}$ is learned via PCA |  |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
- en: '| 1980-1990 | Weighted smoothness | $\&#124;{\mathbf{L}}{\mathbf{x}}\&#124;_{{\mathbf{W}}}^{2}$
    | [[246](#bib.bib246)] |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
- en: '| 1990-2000 | Robust statistics | ${\mathbf{1}}^{T}\mu\{{\mathbf{L}}{\mathbf{x}}\}$
    | [[20](#bib.bib20)] |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
- en: '|  |  | e.g., Hubber-Markov |  |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
- en: '| 1992-2005 | Total-Variation | $\int_{v\in\Omega}&#124;\nabla{\mathbf{x}}(v)&#124;dv$
    | [[240](#bib.bib240)] |'
  id: totrans-436
  prefs: []
  type: TYPE_TB
- en: '|  |  | or ${\mathbf{1}}^{T}\sqrt{&#124;{\mathbf{D}}_{v}{\mathbf{x}}&#124;^{2}+&#124;{\mathbf{D}}_{h}{\mathbf{x}}&#124;^{2}}$
    |  |'
  id: totrans-437
  prefs: []
  type: TYPE_TB
- en: '| 1987-2005 | Other PDE-based options | $\int_{v\in\Omega}g\left[\nabla{\mathbf{x}}(v),\nabla^{2}{\mathbf{x}}(v)\right]dv$
    | [[302](#bib.bib302)] |'
  id: totrans-438
  prefs: []
  type: TYPE_TB
- en: '| 2005-2009 | Field-of-Experts | $\sum_{k}\lambda_{k}{\mathbf{1}}^{T}\mu_{k}\{{\mathbf{L}}_{k}{\mathbf{x}}\}$
    | [[237](#bib.bib237)] |'
  id: totrans-439
  prefs: []
  type: TYPE_TB
- en: '| 1993-2005 | Wavelet sparsity | $\&#124;{\mathbf{W}}{\mathbf{x}}\&#124;_{1}$
    | [[76](#bib.bib76)] |'
  id: totrans-440
  prefs: []
  type: TYPE_TB
- en: '| 2000-2010 | Self-similarity | $\sum_{k}\sum_{j\in\Omega(k)}d\{{\mathbf{R}}_{k}{\mathbf{x}},{\mathbf{R}}_{j}{\mathbf{x}}\}$
    | [[32](#bib.bib32), [61](#bib.bib61)] |'
  id: totrans-441
  prefs: []
  type: TYPE_TB
- en: '| 2002-2012 | Sparsity methods | $\&#124;\alpha\&#124;_{0}~{}s.t.~{}{\mathbf{x}}={\mathbf{D}}\alpha$
    | [[31](#bib.bib31)] |'
  id: totrans-442
  prefs: []
  type: TYPE_TB
- en: '| 2010-2017 | Low-Rank assumption | $\sum_{k}\&#124;{\mathbf{X}}_{\Omega(k)}\&#124;_{*}$
    | [[110](#bib.bib110)] |'
  id: totrans-443
  prefs: []
  type: TYPE_TB
- en: 'As a summary, the above-described evolution of the priors has served as the
    skeleton of image processing, forming the consistent progress of this field over
    the years. This evolution is characterized by four major and interconnected trends:'
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  id: totrans-445
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A migration from the familiar Gaussian distribution to the less intuitive heavy-tailed
    ones;
  id: totrans-446
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  id: totrans-447
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A departure from $L_{2}$ to sparsity-promoting norms, such as the $L_{1}$;
  id: totrans-448
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  id: totrans-449
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A drift from linear approximation techniques (e.g. PCA) to non-linear ones (e.g.
    wavelets and sparse modeling); and above all,
  id: totrans-450
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '4.'
  id: totrans-451
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: A replacement of axiomatic expressions with learned ones.
  id: totrans-452
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix C Landmark Denoisers over the Years
  id: totrans-453
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Figure [2](#S4.F2 "Figure 2 ‣ 1st item ‣ 4 Image Denoising – The Deep Learning
    Revolution ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey
    Paper –") we brought a graph showing the PSNR performance of landmark denoising
    algorithms over the years. Below we provide more information on these techniques
    for completeness of this study. For each of these we bring the full reference,
    describe the core algorithmic idea, and provide the PSNR denoising performance
    on the BSD68 dataset ($\sigma=25$). We should note that in choosing the methods
    to include in this list we restricted the scope to ones that report of BSD68 results.'
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
- en: •
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'KSVD [[89](#bib.bib89)] [28.28dB]: Elad, M., & Aharon, M. (2006). Image denoising
    via sparse and redundant representations over learned dictionaries. IEEE Transactions
    on Image processing, 15(12), 3736-3745.'
  id: totrans-456
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method decomposes the noisy image into fully overlapping patches, and denoises
    each by sparse approximation via OMP [[214](#bib.bib214)], while learning an over-complete
    dictionary. The denoised image is obtained by returning the cleaned patches to
    their original locations while averaging them over the overlaps and with a weighted
    version of the noisy image.
  id: totrans-457
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'BM3D [[61](#bib.bib61)] [28.57dB]: Dabov, K., Foi, A., Katkovnik, V., & Egiazarian,
    K. (2007). Image denoising by sparse 3-D transform-domain collaborative filtering.
    IEEE Transactions on Image Processing, 16(8), 2080-2095.'
  id: totrans-459
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm extracts all fully overlapping patches from the noisy image and
    gathers similar patches into 3D blocks. Denoising is performed by transforming
    these blocks, forcing sparsity, and then transforming the sparse outcome back
    to the image domain. The denoised image is obtained by returning the patches to
    their original locations while averaging over the overlaps. This process is ran
    twice, where the first round serves for an initial cleaning that improves the
    patch correspondences for the later round.
  id: totrans-460
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FoE [[237](#bib.bib237)] [27.77dB]: Roth, S., & Black, M. J. (2009). Fields
    of experts. International Journal of Computer Vision, 82(2), 205-229.'
  id: totrans-462
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: FoE (appeared originally in 2005 [[236](#bib.bib236)]) builds a generic prior
    that mixes several regularizers (called ”experts”). The prior’s parameters are
    learned via a contrastive divergence penalty and MCMC sampling. The image denoising
    itself is obtained by an iterative algorithm that computes the MAP estimation.
  id: totrans-463
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'LSSC [[181](#bib.bib181)] [28.70dB]: Mairal, J., Bach, F., Ponce, J., Sapiro,
    G., & Zisserman, A. (2009). Non-local sparse models for image restoration. CVPR
    (pp. 2272-2279).'
  id: totrans-465
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm combines the sparse representations (as in KSVD) and non-local
    similarity (as in BM3D) concepts. It decomposes the noisy image into fully overlapping
    patches and groups similar patches together. These groups of patches are denoised
    by a joint sparse approximation that forces the same support over a learned dictionary.
    The denoised image is obtained by returning the patches to their original locations
    and averaging over the overlaps.
  id: totrans-466
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'EPLL [[347](#bib.bib347)] [28.71]: Zoran, D., & Weiss, Y. (2011). From learning
    models of natural image patches to whole image restoration. ICCV (pp. 479-486).'
  id: totrans-468
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: EPLL models the distribution of image patches as a Gaussian Mixture Model (GMM),
    and learns its parameters off-line with a dataset of clean images. Denoising with
    EPLL is a MAP estimation, posed as a minimization problem with a regularizer that
    consists of a sum of patch log-likelihoods. This task is solved by applying quadratic
    half-splitting and iterating over patch denoising and the whole image accumulation
    steps.
  id: totrans-469
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MPL [[33](#bib.bib33)] [28.96dB]: Burger, H. C., Schuler, C. J., & Harmeling,
    S. (2012, June). Image denoising: Can plain neural networks compete with BM3D?.
    CVPR (pp. 2392-2399).'
  id: totrans-471
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the first effective deep-learning based method for image denoising.
    This method extracts all fully overlapped patches as in classical algorithms,
    and filters each patch by applying a multi-layer Perceptron (fully connected network).
    The reconstructed image is obtained by returning the patches to their locations
    and averaging over the overlapping regions.
  id: totrans-472
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'CSF [[252](#bib.bib252)] [28.74dB]: Schmidt, U., & Roth, S. (2014). Shrinkage
    fields for effective image restoration. CVPR (pp. 2774-2781).'
  id: totrans-474
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm poses a MAP estimation problem using a product of cascaded shrinkage
    functions as a local prior. The parameters of these functions are learned from
    a dataset as in FoE. The algorithm solves the obtained optimization by half-quadratic
    splitting and iterating between local and global optimization steps.
  id: totrans-475
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'WNNM [[110](#bib.bib110)] [28.83dB]: Gu, S., Zhang, L., Zuo, W., & Feng, X.
    (2014). Weighted nuclear norm minimization with application to image denoising.
    CVPR (pp. 2862-2869).'
  id: totrans-477
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method decomposes an incoming image into fully overlapping patches and
    groups similar patches arranging them as columns of a matrix. Denoising of the
    patches is performed by forcing the rank of the constructed matrices to be small
    by minimizing the matrix nuclear norm. The reconstructed image is obtained by
    returning the patches to their original locations while averaging the overlaps.
  id: totrans-478
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'TNRD [[50](#bib.bib50)] [28.92dB]: Chen, Y., & Pock, T. (2016). Trainable nonlinear
    reaction diffusion: A flexible framework for fast and effective image restoration.
    IEEE Transactions on Pattern Analysis and Machine Intelligence, 39(6), 1256-1272.'
  id: totrans-480
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method builds on the FoE method, by unfolding the minimization over its
    prior and this way defining a parametric trainable network. Once the architecture
    is defined, TNRD trains this neural network end-to-end in a supervised fashion
    using clean/noisy pairs of images. Denoising is a simple inference of the resulting
    machine.
  id: totrans-481
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DnCNN [[330](#bib.bib330)] [29.23dB]: Zhang, K., Zuo, W., Chen, Y., Meng, D.,
    & Zhang, L. (2017). Beyond a gaussian denoiser: Residual learning of deep cnn
    for image denoising. IEEE Transactions on Image Processing, 26(7), 3142-3155.'
  id: totrans-483
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This is the first deep learning method that outperforms classical algorithms
    by a considerable gap. It filters images by applying a convolutional neural network.
    The network architecture is composed of convolutional layers followed by batch
    normalizations and ReLU. The network is trained end-to-end using a dataset consisting
    of noisy/clean image pairs.
  id: totrans-484
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: IRCNN [[331](#bib.bib331)] [29.15dB] Zhang, K., Zuo, W., Gu, S., & Zhang, L.
    (2017). Learning deep CNN denoiser prior for image restoration. CVPR (pp. 3929-3938).
  id: totrans-486
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method is similar to DnCNN, but uses dilated convolutions within the architecture
    in order to enlarge the receptive field, thus creating an opportunity for a non-local
    processing. The network is trained end-to-end using a dataset consisting of noisy/clean
    image pairs.
  id: totrans-487
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NLRN [[167](#bib.bib167)] [29.41dB]: Liu, D., Wen, B., Fan, Y., Loy, C. C.,
    & Huang, T. S. (2018). Non-local recurrent network for image restoration. NeurIPS.'
  id: totrans-489
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method incorporates the non-local similarity concept into a convolutional
    recurrent neural network in an explicit way. The denoising is done by recurrently
    applying convolutions and weighted averaging of similar regions (as in NLM [[32](#bib.bib32)])
    in the feature space. The network is trained end-to-end using a dataset consisting
    of noisy/clean image pairs.
  id: totrans-490
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'MVCNN [[168](#bib.bib168)] [29.41dB]: Liu, P., Zhang, H., Zhang, K., Lin, L.,
    & Zuo, W. (2018). Multi-level wavelet-CNN for image restoration. CVPR Workshop
    (pp. 773-782).'
  id: totrans-492
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm incorporates the wavelet sparsity concept into the deep learning
    approach by combining the U-Net architecture with the multi-level wavelet transform.
    It replaces the downsampling and upsampling U-Net layers with the 2$D$ discrete
    wavelet transform and it’s inverse. The network is trained end-to-end using a
    dataset consisting of noisy/clean image pairs.
  id: totrans-493
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'N3Net [[218](#bib.bib218)] [29.30dB]: Plötz, T., & Roth, S. (2018). Neural
    nearest neighbors networks. NeurIPS.'
  id: totrans-495
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method combines the deep learning approach with the non-local self-similarity
    concept. This method introduces a differentiable continuous relaxation of the
    $k$-nearest neighbor (KNN) selection rule and uses it as a building block within
    the neural network. N3Net’s architecture interleaves convolutional blocks with
    KNN relaxation blocks. The convolutional blocks perform denoising, while the KNN
    parts augment the feature maps by breaking them into patches, applying patch matching,
    and finding $k$-nearest neighbors for each patch. The network is trained end-to-end
    using a dataset consisting of noisy/clean image pairs.
  id: totrans-496
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FFDNet [[332](#bib.bib332)] [29.19dB]: Zhang, K., Zuo, W., & Zhang, L. (2018).
    FFDNet: Toward a fast and flexible solution for CNN-based image denoising. IEEE
    Transactions on Image Processing, 27(9), 4608-4622.'
  id: totrans-498
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While the architecture of this deep learning method resembles DnCNN, it enlarges
    the receptive field by reshaping the incoming image into four downsampled sub-images
    that are simultaneously fed into the network. The network is trained end-to-end
    using a dataset consisting of noisy/clean image pairs.
  id: totrans-499
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FOCNet [[133](#bib.bib133)] [29.38dB] Jia, X., Liu, S., Feng, X., & Zhang,
    L. (2019). Focnet: A fractional optimal control network for image denoising. CVPR
    (pp. 6054-6063).'
  id: totrans-501
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm suggests a novel architecture to replace the one used by DnCNN,
    relying on an interpretation of residual neural networks as solvers of dynamical
    systems. While DnCNN refers to integer-order ordinary differential equation, FOCNet’s
    architecture poses a fractional optimal control (FOC) problem that translates
    into better connectivity. The algorithm for solving the equation is implemented
    using a feed-forward convolutional neural network whose parameters are learned
    using a dataset of images.
  id: totrans-502
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'RIDNet [[8](#bib.bib8)] [29.34dB]: Anwar, S., & Barnes, N. (2019). Real image
    denoising with feature attention. CVPR (pp. 3155-3164).'
  id: totrans-504
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm introduces attention modules to a neural network whose architecture
    includes convolutional layers and skip connections. This attention is designed
    to capture feature dependencies and enhance the weight of important correspondences.
    The network is trained end-to-end using a dataset of clean/noisy image pairs.
  id: totrans-505
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'GCDN [[292](#bib.bib292)] [29.35dB]: Valsesia, D., Fracastoro, G., & Magli,
    E. (2020). Deep graph-convolutional image denoising. IEEE Transactions on Image
    Processing, 29, 8226-8237.'
  id: totrans-507
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This method combines the deep-learning approach with graph modeling. The GCDN
    architecture includes convolutional and graph-convolutional layers. While regular
    convolutional layers catch local interrelations between pixels, the graph-convolution
    ones are designed to capture the non-local dependencies. Each graph-convolutional
    layer dynamically applies non-local aggregation (graph-convolution). The graph
    is constructed via a $k$-nearest neighbor whose vertices are feature vectors.
    Each vertex is connected to the $k$ most similar ones in terms of the $L_{2}$
    norm. The network is trained using a dataset of images.
  id: totrans-508
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'SwinIR [[165](#bib.bib165)] [29.50dB]: Liang, J., Cao, J., Sun, G., Zhang,
    K., Van Gool, L., & Timofte, R. (2021). Swinir: Image restoration using swin transformer.
    CVPR (pp. 1833-1844).'
  id: totrans-510
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This algorithm incorporates non-locality into convolutional deep learning architecture
    using shifted window (Swin) transformer modules [[171](#bib.bib171)]. These modules
    are designed to compute local self-attention in shifted windows, this way exploitig
    non-local self-similarity. The SwinIR architecture is trained end-to-end using
    a dataset consisting of noisy/clean image pairs.
  id: totrans-511
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'DRUNet [[329](#bib.bib329)] [29.48dB]: Zhang, K., Li, Y., Zuo, W., Zhang, L.,
    Van Gool, L., & Timofte, R. (2021). Plug-and-play image restoration with deep
    denoiser prior. IEEE Transactions on Pattern Analysis and Machine Intelligence.'
  id: totrans-513
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: This denoiser is a bias-free [[201](#bib.bib201)] neural network that combines
    ResNet [[117](#bib.bib117)] and U-Net [[234](#bib.bib234)]. Its architecture includes
    convolutions, downscaling and upscaling layers, and skip connections. The network
    is trained using a dataset of images.
  id: totrans-514
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: Appendix D Approximation of the *Score Function* by an MMSE Denoiser
  id: totrans-515
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Section [7](#S7 "7 Discovery 1: Solving Inverse Problems via Image Denoisers
    ‣ Image Denoising: The Deep Learning Revolution and Beyond – A Survey Paper –")
    we brought the definition of the *score function*, $\nabla_{{\mathbf{x}}}\log
    p({\mathbf{x}})$, and its approximation via a denoiser. Here we bring the derivation
    of this result, following the work by Miyasawa [[200](#bib.bib200)], Stein [[265](#bib.bib265)],
    and Tweedie [[84](#bib.bib84)].'
  id: totrans-516
  prefs: []
  type: TYPE_NORMAL
- en: Consider an ideal image ${\mathbf{x}}\in\mathbb{R}^{N}$ drawn from the Probability
    Density Function (PDF) $p({\mathbf{x}})$. Assume that ${\mathbf{y}}$ is a noisy
    version of it, ${\mathbf{y}}={\mathbf{x}}+{\mathbf{v}}$, where ${\mathbf{v}}\sim{\cal
    N}({\mathbf{0}},\sigma_{0}^{2}{\mathbf{I}})$. The PDF of ${\mathbf{y}}$ can be
    obtained by a marginalization,
  id: totrans-517
  prefs: []
  type: TYPE_NORMAL
- en: '| (41) |  | $\displaystyle p({\mathbf{y}})=\int_{{\mathbf{x}}}p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}=\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}.$
    |  |'
  id: totrans-518
  prefs: []
  type: TYPE_TB
- en: 'In the above we used the fact that $p({\mathbf{y}}|{\mathbf{x}})\sim{\cal N}({\mathbf{x}},\sigma_{0}^{2}{\mathbf{I}})$.
    The obtained relationship expresses $p({\mathbf{y}})$ as a convolution between
    the original prior $p({\mathbf{x}})$ and an isotropic zero-mean Gaussian of width
    $\sigma_{0}$. Taking a derivative of both sides with respect to ${\mathbf{y}}$
    results in the following:'
  id: totrans-519
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\nabla_{{\mathbf{y}}}p({\mathbf{y}})$ | $\displaystyle=$
    | $\displaystyle\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}\nabla_{{\mathbf{y}}}\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}$
    |  |'
  id: totrans-520
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\cdot\left[\frac{1}{2\pi\sigma_{0}^{2}}\right]^{N/2}\int_{{\mathbf{x}}}({\mathbf{y}}-{\mathbf{x}})\exp\left\{\frac{-1}{2\sigma_{0}^{2}}\&#124;{\mathbf{y}}-{\mathbf{x}}\&#124;_{2}^{2}\right\}p({\mathbf{x}})d{\mathbf{x}}$
    |  |'
  id: totrans-521
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{y}}-{\mathbf{x}})p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})d{\mathbf{x}}.$
    |  |'
  id: totrans-522
  prefs: []
  type: TYPE_TB
- en: Dividing both sides by $p({\mathbf{y}})$ leads to
  id: totrans-523
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\frac{\nabla_{{\mathbf{y}}}p({\mathbf{y}})}{p({\mathbf{y}})}=\nabla_{{\mathbf{y}}}\log
    p({\mathbf{y}})$ | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{x}}-{\mathbf{y}})\frac{p({\mathbf{y}}&#124;{\mathbf{x}})p({\mathbf{x}})}{p({\mathbf{y}})}d{\mathbf{x}}$
    |  |'
  id: totrans-524
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=$ | $\displaystyle\frac{1}{\sigma_{0}^{2}}\int_{{\mathbf{x}}}({\mathbf{x}}-{\mathbf{y}})p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}.$
    |  |'
  id: totrans-525
  prefs: []
  type: TYPE_TB
- en: 'Opening and rearranging the above expression leads to our final result:'
  id: totrans-526
  prefs: []
  type: TYPE_NORMAL
- en: '| (44) |  | $\nabla_{{\mathbf{y}}}\log p({\mathbf{y}})=\frac{1}{\sigma_{0}^{2}}\left[\int_{{\mathbf{x}}}{\mathbf{x}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}-{\mathbf{y}}\int_{{\mathbf{x}}}p({\mathbf{x}}&#124;{\mathbf{y}})d{\mathbf{x}}\right]=\frac{1}{\sigma_{0}^{2}}\left[D(\mathbf{y},\sigma_{0})-\mathbf{y}\right],$
    |  |'
  id: totrans-527
  prefs: []
  type: TYPE_TB
- en: where $D(\mathbf{y},\sigma_{0})$ should be the optimal Minimum Mean Squared
    Error (MMSE) denoiser, $\mathbb{E}(\mathbf{x}|\mathbf{y})$. Thus, access to an
    approximation of the score function $\nabla_{{\mathbf{x}}}\log p({\mathbf{x}})$
    can be obtained by using a small value $\sigma_{0}$, and evaluating the above
    expression with a given denoiser.
  id: totrans-528
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-529
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] A. Abdelhamed, S. Lin, and M. S. Brown, A high-quality denoising dataset
    for smartphone cameras, in Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, 2018, pp. 1692–1700.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] A. Abdelhamed, R. Timofte, and M. S. Brown, Ntire 2019 challenge on real
    image denoising: Methods and results, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops, 2019.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] H. K. Aggarwal and A. Majumdar, Hyperspectral image denoising using spatio-spectral
    total variation, IEEE Geoscience and Remote Sensing Letters, 13 (2016), pp. 442–446.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] M. Aharon, M. Elad, and A. Bruckstein, K-SVD: An algorithm for designing
    overcomplete dictionaries for sparse representation, IEEE Transactions on signal
    processing, 54 (2006), pp. 4311–4322.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] R. Ahmad, C. A. Bouman, G. T. Buzzard, S. Chan, S. Liu, E. T. Reehorst,
    and P. Schniter, Plug-and-play methods for magnetic resonance imaging: Using denoisers
    for image recovery, IEEE Signal Processing Magazine, 37 (2020), pp. 105–116.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] T. Amit, E. Nachmani, T. Shaharbany, and L. Wolf, Segdiff: Image segmentation
    with diffusion probabilistic models, arXiv preprint arXiv:2112.00390, (2021).'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] F. J. Anscombe, The transformation of poisson, binomial and negative-binomial
    data, Biometrika, 35 (1948), pp. 246–254.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] S. Anwar and N. Barnes, Real image denoising with feature attention, in
    Proceedings of the IEEE/CVF international conference on computer vision, 2019,
    pp. 3155–3164.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] P. Arias and J.-M. Morel, Video denoising via empirical bayesian estimation
    of space-time patches, Journal of Mathematical Imaging and Vision, 60 (2018),
    pp. 70–93.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] P. Arias and J.-M. Morel, Kalman filtering of patches for frame-recursive
    video denoising, in Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition Workshops, 2019, pp. 0–0.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] M. Arjovsky, S. Chintala, and L. Bottou, Wasserstein generative adversarial
    networks, in Proceedings of the 34th International Conference on Machine Learning,
    vol. 70 of Proceedings of Machine Learning Research, PMLR, 06–11 Aug 2017, pp. 214–223.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] L. Azzari and A. Foi, Variance stabilization for noisy+ estimate combination
    in iterative poisson denoising, IEEE signal processing letters, 23 (2016), pp. 1086–1090.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] U. Bal, Dual tree complex wavelet transform based denoising of optical
    microscopy images, Biomedical optics express, 3 (2012), pp. 3231–3239.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Y. Balaji, S. Nah, X. Huang, A. Vahdat, J. Song, K. Kreis, M. Aittala,
    T. Aila, S. Laine, B. Catanzaro, et al., eDiff-I: Text-to-image diffusion models
    with an ensemble of expert denoisers, arXiv preprint arXiv:2211.01324, (2022).'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] M. R. Banham and A. K. Katsaggelos, Digital image restoration, IEEE signal
    processing magazine, 14 (1997), pp. 24–41.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] J. Batson and L. Royer, Noise2self: Blind denoising by self-supervision,
    in International Conference on Machine Learning, PMLR, 2019, pp. 524–533.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] A. Beck and M. Teboulle, Fast gradient-based algorithms for constrained
    total variation image denoising and deblurring problems, IEEE Transactions on
    image processing, 18 (2009), pp. 2419–2434.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] M. Bertalmío, Denoising of photographic images and video: fundamentals,
    open challenges and new trends, Springer, 2018.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] J. Besag, Markov chain monte carlo for statistical inference, Center for
    Statistics and the Social Sciences, 9 (2001), pp. 24–25.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] M. J. Black, G. Sapiro, D. H. Marimont, and D. Heeger, Robust anisotropic
    diffusion, IEEE Transactions on image processing, 7 (1998), pp. 421–432.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] T. Blau, R. Ganz, B. Kawar, A. Bronstein, and M. Elad, Threat model-agnostic
    adversarial defense using diffusion models, arXiv preprint arXiv:2207.08089, (2022).'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Y. Blau and T. Michaeli, The perception-distortion tradeoff, in Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, 2018, pp. 6228–6237.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] A. Bosco, R. Bruna, D. Giacalone, S. Battiato, and R. Rizzo, Signal-dependent
    raw image denoising using sensor noise characterization via multiple acquisitions,
    in Digital Photography VI, vol. 7537, SPIE, 2010, pp. 34–43.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] L. Bottou et al., Stochastic gradient learning in neural networks, Proceedings
    of Neuro-Nımes, 91 (1991), p. 12.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J. Boulanger, C. Kervrann, P. Bouthemy, P. Elbau, J.-B. Sibarita, and
    J. Salamero, Patch-based nonlocal functional for denoising fluorescence microscopy
    image sequences, IEEE transactions on medical imaging, 29 (2009), pp. 442–454.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] C. Bouman and K. Sauer, A generalized gaussian image model for edge-preserving
    map estimation, IEEE Transactions on image processing, 2 (1993), pp. 296–310.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. Boyd, N. Parikh, E. Chu, B. Peleato, J. Eckstein, et al., Distributed
    optimization and statistical learning via the alternating direction method of
    multipliers, Foundations and Trends® in Machine learning, 3 (2011), pp. 1–122.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] A. Brifman, Y. Romano, and M. Elad, Turning a denoiser into a super-resolver
    using plug and play priors, in 2016 IEEE International Conference on Image Processing
    (ICIP), IEEE, 2016, pp. 1404–1408.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] A. Brock, J. Donahue, and K. Simonyan, Large scale GAN training for high
    fidelity natural image synthesis, in International Conference on Learning Representations,
    2018.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] T. Brooks, B. Mildenhall, T. Xue, J. Chen, D. Sharlet, and J. T. Barron,
    Unprocessing images for learned raw denoising, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2019, pp. 11036–11045.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] A. M. Bruckstein, D. L. Donoho, and M. Elad, From sparse solutions of
    systems of equations to sparse modeling of signals and images, SIAM review, 51
    (2009), pp. 34–81.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] A. Buades, B. Coll, and J.-M. Morel, A non-local algorithm for image denoising,
    in IEEE CVPR, vol. 2, 2005, pp. 60–65.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] H. C. Burger, C. J. Schuler, and S. Harmeling, Image denoising: Can plain
    neural networks compete with BM3D?, in IEEE CVPR, 2012, pp. 2392–2399.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] G. T. Buzzard, S. H. Chan, S. Sreehari, and C. A. Bouman, Plug-and-play
    unplugged: Optimization-free reconstruction using consensus equilibrium, SIAM
    Journal on Imaging Sciences, 11 (2018), pp. 2001–2020.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] E. J. Candès, X. Li, Y. Ma, and J. Wright, Robust principal component
    analysis?, Journal of the ACM (JACM), 58 (2011), pp. 1–37.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] H. Cao, C. Tan, Z. Gao, G. Chen, P.-A. Heng, and S. Z. Li, A survey on
    generative diffusion model, arXiv preprint arXiv:2209.02646, (2022).'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] K. R. Castleman, Digital image processing, Prentice Hall Press, 1996.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] F. Catté, P.-L. Lions, J.-M. Morel, and T. Coll, Image selective smoothing
    and edge detection by nonlinear diffusion, SIAM Journal on Numerical analysis,
    29 (1992), pp. 182–193.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] A. Chambolle and T. Pock, A first-order primal-dual algorithm for convex
    problems with applications to imaging, Journal of mathematical imaging and vision,
    40 (2011), pp. 120–145.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] R. H. Chan, C.-W. Ho, and M. Nikolova, Salt-and-pepper noise removal by
    median-type noise detectors and detail-preserving regularization, IEEE Transactions
    on image processing, 14 (2005), pp. 1479–1485.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S. H. Chan, Performance analysis of plug-and-play admm: A graph signal
    processing perspective, IEEE Transactions on Computational Imaging, 5 (2019),
    pp. 274–286.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] S. H. Chan, X. Wang, and O. A. Elgendy, Plug-and-play ADMM for image restoration:
    Fixed-point convergence and applications, IEEE Transactions on Computational Imaging,
    3 (2016), pp. 84–98.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] S. G. Chang, B. Yu, and M. Vetterli, Adaptive wavelet thresholding for
    image denoising and compression, IEEE transactions on image processing, 9 (2000),
    pp. 1532–1546.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] P. Charbonnier, L. Blanc-Féraud, G. Aubert, and M. Barlaud, Deterministic
    edge-preserving regularization in computed imaging, IEEE Transactions on image
    processing, 6 (1997), pp. 298–311.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] P. Chatterjee and P. Milanfar, Is denoising dead?, IEEE Transactions on
    Image Processing, 19 (2009), pp. 895–911.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] P. Chatterjee and P. Milanfar, Patch-based near-optimal image denoising,
    IEEE Transactions on Image Processing, 21 (2011), pp. 1635–1649.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] C. Chen, Z. Xiong, X. Tian, and F. Wu, Deep boosting for image denoising,
    in Proceedings of the European Conference on Computer Vision (ECCV), 2018, pp. 3–18.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] H. Chen, Y. Zhang, W. Zhang, P. Liao, K. Li, J. Zhou, and G. Wang, Low-dose
    ct denoising with convolutional neural network, in 2017 IEEE 14th International
    Symposium on Biomedical Imaging (ISBI 2017), IEEE, 2017, pp. 143–146.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] W. Chen, D. Wipf, and M. Rodrigues, Deep learning for linear inverse problems
    using the plug-and-play priors framework, in ICASSP 2021-2021 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP), IEEE, 2021, pp. 8098–8102.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] Y. Chen and T. Pock, Trainable nonlinear reaction diffusion: A flexible
    framework for fast and effective image restoration, IEEE transactions on pattern
    analysis and machine intelligence, 39 (2016), pp. 1256–1272.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] B. T. Christian, N. T. Vandehey, J. M. Floberg, and C. A. Mistretta, Dynamic
    pet denoising with hypr processing, Journal of Nuclear Medicine, 51 (2010), pp. 1147–1154.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] C. Chu, I. Glad, F. Godtliebsen, and J. Marron, Edge-preserving smoothers
    for image processing, Journal of the American Statistical Association, 93 (1998),
    pp. 526–541.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] H. Chung, J. Kim, M. T. Mccann, M. L. Klasky, and J. C. Ye, Diffusion
    posterior sampling for general noisy inverse problems, arXiv preprint arXiv:2209.14687,
    (2022).'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] H. Chung, B. Sim, D. Ryu, and J. C. Ye, Improving diffusion models for
    inverse problems using manifold constraints, arXiv preprint arXiv:2206.00941,
    (2022).'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] R. Cohen, Y. Blau, D. Freedman, and E. Rivlin, It has potential: Gradient-driven
    denoisers for convergent solutions to inverse problems, Advances in Neural Information
    Processing Systems, 34 (2021), pp. 18152–18164.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] R. Cohen, M. Elad, and P. Milanfar, Regularization by denoising via fixed-point
    projection (RED-PRO), SIAM Journal on Imaging Sciences, 14 (2021), pp. 1374–1406.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] R. R. Coifman and D. L. Donoho, Translation-invariant de-noising, in Wavelets
    and statistics, Springer, 1995, pp. 125–150.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] M.-C. Corbineau, C. Bertocchi, E. Chouzenoux, M. Prato, and J.-C. Pesquet,
    Learned image deblurring by unfolding a proximal interior point algorithm, in
    2019 IEEE International Conference on Image Processing (ICIP), IEEE, 2019, pp. 4664–4668.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] R. Costantini and S. Susstrunk, Virtual sensor design, in Sensors and
    Camera Systems for Scientific, Industrial, and Digital Photography Applications
    V, vol. 5301, SPIE, 2004, pp. 408–419.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] F.-A. Croitoru, V. Hondru, R. T. Ionescu, and M. Shah, Diffusion models
    in vision: A survey, arXiv preprint arXiv:2209.04747, (2022).'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian, Image denoising by
    sparse 3-D transform-domain collaborative filtering, IEEE Transactions on image
    processing, 16 (2007), pp. 2080–2095.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Dai, O. C. Au, C. Pang, W. Yang, and F. Zou, Film grain noise removal
    and synthesis in video coding, in 2010 IEEE International Conference on Acoustics,
    Speech and Signal Processing, IEEE, 2010, pp. 890–893.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] Y. Dar, A. M. Bruckstein, M. Elad, and R. Giryes, Postprocessing of compressed
    images via sequential denoising, IEEE Transactions on Image Processing, 25 (2016),
    pp. 3044–3058.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] P. Das, C. Pal, A. Chakrabarti, A. Acharyya, and S. Basu, Adaptive denoising
    of 3d volumetric mr images using local variance based estimator, Biomedical Signal
    Processing and Control, 59 (2020), p. 101901.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] C.-A. Deledalle, F. Tupin, and L. Denis, Poisson nl means: Unsupervised
    non local means for poisson noise, in 2010 IEEE international conference on image
    processing, IEEE, 2010, pp. 801–804.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei, ImageNet:
    A large-scale hierarchical image database, in 2009 IEEE Conference on Computer
    Vision and Pattern Recognition, 2009, pp. 248–255.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] R. Dey, D. Bhattacharjee, and M. Nasipuri, Image denoising using generative
    adversarial network, in Intelligent Computing: Image Processing Based Applications,
    Springer, 2020, pp. 73–90.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] P. Dhariwal and A. Q. Nichol, Diffusion models beat GANs on image synthesis,
    in Thirty-Fifth Conference on Neural Information Processing Systems, 2021.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] N. Divakar and R. Venkatesh Babu, Image denoising via CNNs: An adversarial
    approach, in Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition Workshops, 2017, pp. 80–87.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] M. Diwakar, P. Kumar, and A. K. Singh, Ct image denoising using nlm and
    its method noise thresholding, Multimedia Tools and Applications, 79 (2020), pp. 14449–14464.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] W. Dong, X. Li, L. Zhang, and G. Shi, Sparsity-based image denoising via
    dictionary learning and structural clustering, in CVPR 2011, 2011, pp. 457–464.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] W. Dong, G. Shi, Y. Ma, and X. Li, Image restoration via simultaneous
    sparse coding: Where structured sparsity meets Gaussian scale mixture, International
    Journal of Computer Vision, 114 (2015), pp. 217–232.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] W. Dong, P. Wang, W. Yin, G. Shi, F. Wu, and X. Lu, Denoising prior driven
    deep neural network for image restoration, IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 41 (2018), pp. 2305–2318.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] W. Dong, L. Zhang, G. Shi, and X. Li, Nonlocally centralized sparse representation
    for image restoration, IEEE Transactions on Image Processing, 22 (2012), pp. 1620–1630.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] Y. Dong and S. Xu, A new directional weighted median filter for removal
    of random-valued impulse noise, IEEE Signal Processing Letters, 14 (2007), pp. 193–196.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] D. L. Donoho, De-noising by soft-thresholding, IEEE transactions on information
    theory, 41 (1995), pp. 613–627.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] D. L. Donoho and J. M. Johnstone, Ideal spatial adaptation by wavelet
    shrinkage, biometrika, 81 (1994), pp. 425–455.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] A. Dosovitskiy, L. Beyer, A. Kolesnikov, D. Weissenborn, X. Zhai, T. Unterthiner,
    M. Dehghani, M. Minderer, G. Heigold, S. Gelly, et al., An image is worth 16x16
    words: Transformers for image recognition at scale, in International Conference
    on Learning Representations, 2020.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] Y. Du and I. Mordatch, Implicit generation and modeling with energy based
    models, in Advances in Neural Information Processing Systems, vol. 32, 2019.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] A. Dudhane, S. W. Zamir, S. Khan, F. S. Khan, and M.-H. Yang, Burst image
    restoration and enhancement, in Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, 2022, pp. 5759–5768.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] F.-X. Dupé, J. M. Fadili, and J.-L. Starck, A proximal iteration for deconvolving
    poisson noisy images using sparse representations, IEEE Transactions on Image
    Processing, 18 (2009), pp. 310–321.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] J. Dutta, R. M. Leahy, and Q. Li, Non-local means denoising of dynamic
    pet images, PloS one, 8 (2013), p. e81390.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] S. Dutta, A. Basarab, B. Georgeot, and D. Kouamé, Deep unfolding of image
    denoising by quantum interactive patches, in 2022 IEEE International Conference
    on Image Processing (ICIP), IEEE, 2022, pp. 491–495.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] B. Efron, Tweedie’s formula and selection bias, Journal of the American
    Statistical Association, 106 (2011), pp. 1602–1614.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] K. Egiazarian and V. Katkovnik, Single image super-resolution via BM3D
    sparse coding, in IEEE European Signal Processing Conference (EUSIPCO), 2015,
    pp. 2849–2853.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] T. Ehret, A. Davy, P. Arias, and G. Facciolo, Joint demosaicking and denoising
    by fine-tuning of bursts of raw images, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2019, pp. 8868–8877.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] M. Elad, On the origin of the bilateral filter and ways to improve it,
    IEEE Transactions on image processing, 11 (2002), pp. 1141–1151.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] M. Elad, Sparse and redundant representations: from theory to applications
    in signal and image processing, vol. 2, Springer, 2010.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] M. Elad and M. Aharon, Image denoising via sparse and redundant representations
    over learned dictionaries, IEEE Transactions on Image processing, 15 (2006), pp. 3736–3745.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] M. Elad, J.-L. Starck, P. Querre, and D. L. Donoho, Simultaneous cartoon
    and texture image inpainting using morphological component analysis (mca), Applied
    and Computational Harmonic Analysis, 19 (2005), pp. 340–358.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] M. J. Fadili, J.-L. Starck, J. Bobin, and Y. Moudden, Image decomposition
    and separation using sparse representations: an overview, Proceedings of the IEEE,
    98 (2009), pp. 983–994.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] L. Fan, F. Zhang, H. Fan, and C. Zhang, Brief review of image denoising
    techniques, Visual Computing for Industry, Biomedicine, and Art, 2 (2019), pp. 1–12.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] M. A. Figueiredo and J. M. Bioucas-Dias, Restoration of poissonian images
    using alternating direction optimization, IEEE transactions on Image Processing,
    19 (2010), pp. 3133–3145.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] A. K. Fletcher, P. Pandit, S. Rangan, S. Sarkar, and P. Schniter, Plug-in
    estimation in high-dimensional linear inverse problems: A rigorous analysis, in
    Advances in Neural Information Processing Systems, 2018, pp. 7440–7449.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] R. Gal, Y. Alaluf, Y. Atzmon, O. Patashnik, A. H. Bermano, G. Chechik,
    and D. Cohen-Or, An image is worth one word: Personalizing text-to-image generation
    using textual inversion, arXiv preprint arXiv:2208.01618, (2022).'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] D. Geman and G. Reynolds, Constrained restoration and the recovery of
    discontinuities, IEEE Transactions on pattern analysis and machine intelligence,
    14 (1992), pp. 367–383.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] S. Geman, Stochastic relaxation, gibbs distributions and bayesian restoration
    of images. ieee trans, Pattn. Anal. Mach. Intell., 6 (1984), pp. 721–741.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] S. Ghael, A. M. Sayeed, and R. G. Baraniuk, Improved wavelet denoising
    via empirical wiener filtering, in SPIE Technical Conference on Wavelet Applications
    in Signal Processing, 1997.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] G. Gilboa and S. Osher, Nonlocal operators with applications to image
    processing, Multiscale Modeling & Simulation, 7 (2009), pp. 1005–1028.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] R. Giryes and M. Elad, Sparsity-based poisson denoising with dictionary
    learning, IEEE Transactions on Image Processing, 23 (2014), pp. 5057–5069.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] X. Glorot, A. Bordes, and Y. Bengio, Deep sparse rectifier neural networks,
    in Proceedings of the fourteenth international conference on artificial intelligence
    and statistics, JMLR Workshop and Conference Proceedings, 2011, pp. 315–323.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] C. Godard, K. Matzen, and M. Uyttendaele, Deep burst denoising, in Proceedings
    of the European conference on computer vision (ECCV), 2018, pp. 538–554.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] Y. E. Gökdağ, F. Şansal, and Y. D. Gökdel, Image denoising using 2-d
    wavelet algorithm for gaussian-corrupted confocal microscopy images, Biomedical
    Signal Processing and Control, 54 (2019), p. 101594.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] G. H. Golub, P. C. Hansen, and D. P. O’Leary, Tikhonov regularization
    and total least squares, SIAM Journal on Matrix Analysis and Applications, 21
    (1999), pp. 185–194.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] K. Gong, J. Guan, C.-C. Liu, and J. Qi, Pet image denoising using a deep
    neural network through fine tuning, IEEE Transactions on Radiation and Plasma
    Medical Sciences, 3 (2018), pp. 153–161.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] M. Gonzalez, J. Preciozzi, P. Musé, and A. Almansa, Joint denoising and
    decompression using cnn regularization, in Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition Workshops, 2018, pp. 2598–2601.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[107] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
    A. Courville, and Y. Bengio, Generative adversarial nets, Advances in Neural Information
    Processing Systems, 27 (2014).'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[108] B. Goossens, A. Pizurica, and W. Philips, Removal of correlated noise
    by modeling the signal of interest in the wavelet domain, IEEE transactions on
    image processing, 18 (2009), pp. 1153–1165.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[109] K. Gregor and Y. LeCun, Learning fast approximations of sparse coding,
    in Proceedings of the 27th international conference on international conference
    on machine learning, 2010, pp. 399–406.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[110] S. Gu, L. Zhang, W. Zuo, and X. Feng, Weighted nuclear norm minimization
    with application to image denoising, in Proceedings of the IEEE conference on
    computer vision and pattern recognition, 2014, pp. 2862–2869.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[111] F. Guichard, L. Moisan, and J. M. Morel, A review of pde models in image
    processing and image analysis, In Journal de Physique IV, 12 (2002), pp. 137–154.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[112] I. Gulrajani, F. Ahmed, M. Arjovsky, V. Dumoulin, and A. C. Courville,
    Improved training of Wasserstein GANs, Advances in neural information processing
    systems, 30 (2017).'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[113] S. Guo, Z. Liang, and L. Zhang, Joint denoising and demosaicking with
    green channel prior for real-world burst images, IEEE Transactions on Image Processing,
    30 (2021), pp. 6930–6942.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[114] S. Guo, Z. Yan, K. Zhang, W. Zuo, and L. Zhang, Toward convolutional
    blind denoising of real photographs, in Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition, 2019, pp. 1712–1722.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[115] J. Gurrola-Ramos, O. Dalmau, and T. E. Alarcón, A residual dense u-net
    neural network for image denoising, IEEE Access, 9 (2021), pp. 31742–31754.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[116] X. Han, H. Zheng, and M. Zhou, CARD: Classification and regression diffusion
    models, arXiv preprint arXiv:2206.07275, (2022).'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[117] K. He, X. Zhang, S. Ren, and J. Sun, Deep residual learning for image
    recognition, in Proceedings of the IEEE conference on computer vision and pattern
    recognition, 2016, pp. 770–778.'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[118] G. E. Hinton, Training products of experts by minimizing contrastive
    divergence, Neural computation, 14 (2002), pp. 1771–1800.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[119] J. Ho, W. Chan, C. Saharia, J. Whang, R. Gao, A. Gritsenko, D. P. Kingma,
    B. Poole, M. Norouzi, D. J. Fleet, et al., Imagen video: High definition video
    generation with diffusion models, arXiv preprint arXiv:2210.02303, (2022).'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[120] J. Ho, A. Jain, and P. Abbeel, Denoising diffusion probabilistic models,
    in Advances in Neural Information Processing Systems, vol. 33, Curran Associates,
    Inc., 2020, pp. 6840–6851.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[121] J. Ho, C. Saharia, W. Chan, D. J. Fleet, M. Norouzi, and T. Salimans,
    Cascaded diffusion models for high fidelity image generation, Journal of Machine
    Learning Research, 23 (2022), pp. 1–33.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[122] J. Ho and T. Salimans, Classifier-free diffusion guidance, in NeurIPS
    2021 Workshop on Deep Generative Models and Downstream Applications, 2021.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[123] T. Hong, Y. Romano, and M. Elad, Acceleration of RED via vector extrapolation,
    Journal of Visual Communication and Image Representation, 63 (2019), p. 102575.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[124] X. Hu, R. Ma, Z. Liu, Y. Cai, X. Zhao, Y. Zhang, and H. Wang, Pseudo
    3d auto-correlation network for real image denoising, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2021, pp. 16175–16184.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[125] Y. Huang, S. Li, L. Wang, T. Tan, et al., Unfolding the alternating optimization
    for blind super resolution, Advances in Neural Information Processing Systems,
    33 (2020), pp. 5632–5643.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[126] P. Huber, Robust statistics. new-york: John wiley and sons, HuberRobust
    statistics1981, (1981).'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[127] I. A. Ibragimov, I. V. Linnik, and J. F. C. Kingman, Independent and
    stationary sequences of random variables, Monographs and textbooks on pure and
    applied mathematics, Wolters-Noordhoff., 1971.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[128] A. Ignatov, K. Byeoung-Su, R. Timofte, and A. Pouget, Fast camera image
    denoising on mobile gpus with deep learning, mobile ai 2021 challenge: Report,
    in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2021, pp. 2515–2524.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[129] A. Jain, A. Xie, and P. Abbeel, Vectorfusion: Text-to-svg by abstracting
    pixel-based diffusion models, arXiv preprint arXiv:2211.11319, (2022).'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[130] P. Jain and V. Tyagi, A survey of edge-preserving image denoising methods,
    Information Systems Frontiers, 18 (2016), pp. 159–170.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[131] V. Jain and S. Seung, Natural image denoising with convolutional networks,
    Advances in neural information processing systems, 21 (2008).'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[132] E. T. Jaynes, Probability theory: The logic of science, Cambridge university
    press, 2003.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[133] X. Jia, S. Liu, X. Feng, and L. Zhang, Focnet: A fractional optimal control
    network for image denoising, 2019 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition (CVPR), (2019), pp. 6047–6056.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[134] K. H. Jin and J. C. Ye, Annihilating filter-based low-rank hankel matrix
    approach for image inpainting, IEEE Transactions on Image Processing, 24 (2015),
    pp. 3498–3511.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[135] A. Jolicoeur-Martineau, K. Li, R. Piché-Taillefer, T. Kachman, and I. Mitliagkas,
    Gotta go fast when generating data with score-based models, arXiv preprint arXiv:2105.14080,
    (2021).'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[136] I. T. Jolliffe and J. Cadima, Principal component analysis: a review
    and recent developments, Philosophical Transactions of the Royal Society A: Mathematical,
    Physical and Engineering Sciences, 374 (2016), p. 20150202.'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[137] J. Joyce and E. N. Zalta, Bayes’ theorem, The Stanford Encyclopedia of
    Philosophy, 28 (2003).'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[138] Z. Kadkhodaie and E. Simoncelli, Stochastic solutions for linear inverse
    problems using the prior implicit in a denoiser, Advances in Neural Information
    Processing Systems, 34 (2021), pp. 13242–13254.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[139] U. S. Kamilov, H. Mansour, and B. Wohlberg, A plug-and-play priors approach
    for solving nonlinear imaging inverse problems, IEEE Signal Processing Letters,
    24 (2017), pp. 1872–1876.'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[140] K. Karhunen, Über lineare methoden in der wahrscheinlichkeitsrechnung,
    Ann. Acad. Sci. Fennicea, A137 (1947).'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[141] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen, and T. Aila,
    Analyzing and improving the image quality of stylegan, in Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition, 2020, pp. 8110–8119.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[142] B. Kawar, M. Elad, S. Ermon, and J. Song, Denoising diffusion restoration
    models, in Advances in Neural Information Processing Systems, 2022.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[143] B. Kawar, R. Ganz, and M. Elad, Enhancing diffusion-based image synthesis
    with robust classifier guidance, arXiv preprint arXiv:2208.08664, (2022).'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[144] B. Kawar, J. Song, S. Ermon, and M. Elad, JPEG artifact correction using
    denoising diffusion restoration models, in Neural Information Processing Systems
    (NeurIPS) Workshop on Score-Based Methods, 2022.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[145] B. Kawar, G. Vaksman, and M. Elad, SNIPS: solving noisy inverse problems
    stochastically, Advances in Neural Information Processing Systems, 34 (2021),
    pp. 21757–21769.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[146] B. Kawar, G. Vaksman, and M. Elad, Stochastic image denoising by sampling
    from the posterior distribution, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops, 2021, pp. 1866–1875.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[147] B. Kawar, S. Zada, O. Lang, O. Tov, H. Chang, T. Dekel, I. Mosseri, and
    M. Irani, Imagic: Text-based real image editing with diffusion models, arXiv preprint
    arXiv:2210.09276, (2022).'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[148] S. A. Khowaja, B. N. Yahya, and S.-L. Lee, Cascaded and recursive convnets
    (crcnn): An effective and flexible approach for image denoising, Signal Processing:
    Image Communication, 99 (2021), p. 116420.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[149] S.-U. Kim, An image denoising algorithm for the mobile phone cameras,
    The Journal of the Korea institute of electronic communication sciences, 9 (2014),
    pp. 601–608.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[150] D. P. Kingma and P. Dhariwal, Glow: Generative flow with invertible 1x1
    convolutions, Advances in neural information processing systems, 31 (2018).'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[151] D. P. Kingma and M. Welling, Auto-encoding variational bayes, in International
    Conference on Learning Representations, 2014.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[152] A. Krull, T.-O. Buchholz, and F. Jug, Noise2void-learning denoising from
    single noisy images, in Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition, 2019, pp. 2129–2137.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[153] G. Kutyniok and W.-Q. Lim, Image separation using wavelets and shearlets,
    in International Conference on Curves and Surfaces, Springer, 2010, pp. 416–430.'
  id: totrans-682
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[154] R. L. Lagendijk and J. Biemond, Basic methods for image restoration and
    identification, in The Essential Guide to Image Processing, Elsevier, 2009, pp. 323–348.'
  id: totrans-683
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[155] R. Laumont, V. De Bortoli, A. Almansa, J. Delon, A. Durmus, and M. Pereyra,
    Bayesian imaging using plug & play priors: when Langevin meets Tweedie, arXiv
    preprint arXiv:2103.04715, (2021).'
  id: totrans-684
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[156] M. Lebrun, M. Colom, A. Buades, and J.-M. Morel, Secrets of image denoising
    cuisine, Acta Numerica, 21 (2012), pp. 475–576.'
  id: totrans-685
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[157] M. Lebrun, M. Colom, and J.-M. Morel, The noise clinic: A universal blind
    denoising algorithm, in 2014 IEEE International Conference on Image Processing
    (ICIP), IEEE, 2014, pp. 2674–2678.'
  id: totrans-686
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[158] S. Lee, M. Negishi, H. Urakubo, H. Kasai, and S. Ishii, Mu-net: Multi-scale
    u-net for two-photon microscopy image denoising and restoration, Neural Networks,
    125 (2020), pp. 92–103.'
  id: totrans-687
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[159] S. Lefkimmiatis, Universal denoising networks: a novel cnn architecture
    for image denoising, in Proceedings of the IEEE conference on computer vision
    and pattern recognition, 2018, pp. 3204–3213.'
  id: totrans-688
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[160] J. Lehtinen, J. Munkberg, J. Hasselgren, S. Laine, T. Karras, M. Aittala,
    and T. Aila, Noise2noise: Learning image restoration without clean data, in International
    Conference on Machine Learning, PMLR, 2018, pp. 2965–2974.'
  id: totrans-689
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[161] C. Lei, Y. Xing, and Q. Chen, Blind video temporal consistency via deep
    video prior, ArXiv, abs/2010.11838 (2020).'
  id: totrans-690
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[162] A. Levin and B. Nadler, Natural image denoising: Optimality and inherent
    bounds, in IEEE CVPR, 2011, pp. 2833–2840.'
  id: totrans-691
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[163] A. Levin, B. Nadler, F. Durand, and W. T. Freeman, Patch complexity,
    finite pixel correlations and optimal denoising, in European Conference on Computer
    Vision, Springer, 2012, pp. 73–86.'
  id: totrans-692
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[164] Z. Li, L. Yu, J. D. Trzasko, D. S. Lake, D. J. Blezek, J. G. Fletcher,
    C. H. McCollough, and A. Manduca, Adaptive nonlocal means filtering based on local
    noise level for ct denoising, Medical physics, 41 (2014), p. 011908.'
  id: totrans-693
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[165] J. Liang, J. Cao, G. Sun, K. Zhang, L. Van Gool, and R. Timofte, SwinIR:
    Image restoration using swin transformer, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision, 2021, pp. 1833–1844.'
  id: totrans-694
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[166] Z. Liang, S. Guo, H. Gu, H. Zhang, and L. Zhang, A decoupled learning
    scheme for real-world burst denoising from raw images, in European Conference
    on Computer Vision, Springer, 2020, pp. 150–166.'
  id: totrans-695
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[167] D. Liu, B. Wen, Y. Fan, C. C. Loy, and T. S. Huang, Non-local recurrent
    network for image restoration, in Advances in Neural Information Processing Systems,
    2018, pp. 1673–1682.'
  id: totrans-696
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[168] P. Liu, H. Zhang, K. Zhang, L. Lin, and W. Zuo, Multi-level wavelet-cnn
    for image restoration, 2018 IEEE/CVF Conference on Computer Vision and Pattern
    Recognition Workshops (CVPRW), (2018), pp. 886–88609.'
  id: totrans-697
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[169] X. Liu, M. Tanaka, and M. Okutomi, Single-image noise level estimation
    for blind denoising, IEEE transactions on image processing, 22 (2013), pp. 5226–5237.'
  id: totrans-698
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[170] Y. Liu, Z. Qin, S. Anwar, P. Ji, D. Kim, S. Caldwell, and T. Gedeon,
    Invertible denoising network: A light solution for real noise removal, in Proceedings
    of the IEEE/CVF conference on computer vision and pattern recognition, 2021, pp. 13365–13374.'
  id: totrans-699
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[171] Z. Liu, Y. Lin, Y. Cao, H. Hu, Y. Wei, Z. Zhang, S. Lin, and B. Guo,
    Swin transformer: Hierarchical vision transformer using shifted windows, 2021
    IEEE/CVF International Conference on Computer Vision (ICCV), (2021), pp. 9992–10002.'
  id: totrans-700
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[172] Z. Liu, P. Luo, X. Wang, and X. Tang, Deep learning face attributes in
    the wild, in Proceedings of the IEEE International Conference on Computer Vision,
    2015, pp. 3730–3738.'
  id: totrans-701
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[173] Z. Liu, L. Yuan, X. Tang, M. Uyttendaele, and J. Sun, Fast burst images
    denoising, ACM Transactions on Graphics (TOG), 33 (2014), pp. 1–9.'
  id: totrans-702
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[174] M. Loéve, Fonctions aléatoires de second order, CR. Acad. Sci. Paris,
    220 (1945).'
  id: totrans-703
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[175] F. Luisier, T. Blu, and M. Unser, A new sure approach to image denoising:
    Interscale orthonormal wavelet thresholding, IEEE Transactions on image processing,
    16 (2007), pp. 593–606.'
  id: totrans-704
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[176] F. Luisier, T. Blu, and M. Unser, Image denoising in mixed poisson–gaussian
    noise, IEEE Transactions on image processing, 20 (2010), pp. 696–708.'
  id: totrans-705
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[177] F. Luisier, C. Vonesch, T. Blu, and M. Unser, Fast interscale wavelet
    denoising of poisson-corrupted images, Signal processing, 90 (2010), pp. 415–427.'
  id: totrans-706
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[178] S. Luo and W. Hu, Score-based point cloud denoising, in Proceedings of
    the IEEE/CVF International Conference on Computer Vision (ICCV), October 2021,
    pp. 4583–4592.'
  id: totrans-707
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[179] M. Maggioni, G. Boracchi, A. Foi, and K. Egiazarian, Video denoising
    using separable 4d nonlocal spatiotemporal transforms, in Image Processing: Algorithms
    and Systems IX, vol. 7870, International Society for Optics and Photonics, 2011,
    p. 787003.'
  id: totrans-708
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[180] M. Maggioni, Y. Huang, C. Li, S. Xiao, Z. Fu, and F. Song, Efficient
    multi-stage video denoising with recurrent spatio-temporal fusion, 2021 IEEE/CVF
    Conference on Computer Vision and Pattern Recognition (CVPR), (2021), pp. 3465–3474.'
  id: totrans-709
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[181] J. Mairal, F. Bach, J. Ponce, G. Sapiro, and A. Zisserman, Non-local
    sparse models for image restoration, in IEEE 12th international conference on
    computer vision, 2009, pp. 2272–2279.'
  id: totrans-710
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[182] J. Mairal, M. Elad, and G. Sapiro, Sparse representation for color image
    restoration, IEEE Transactions on Image Processing, 17 (2008), pp. 53–69.'
  id: totrans-711
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[183] J. Mairal, G. Sapiro, and M. Elad, Multiscale sparse image representation
    with learned dictionaries, in 2007 IEEE International Conference on Image Processing,
    vol. 3, IEEE, 1997, pp. III–105.'
  id: totrans-712
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[184] M. Makitalo and A. Foi, Optimal inversion of the anscombe transformation
    in low-count poisson image denoising, IEEE transactions on Image Processing, 20
    (2010), pp. 99–109.'
  id: totrans-713
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[185] S. Mallat, A wavelet tour of signal processing, Elsevier, 1999.'
  id: totrans-714
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[186] B. Manifold, E. Thomas, A. T. Francis, A. H. Hill, and D. Fu, Denoising
    of stimulated raman scattering microscopy images via deep learning, Biomedical
    optics express, 10 (2019), pp. 3860–3874.'
  id: totrans-715
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[187] J. V. Manjón, P. Coupé, L. Martí-Bonmatí, D. L. Collins, and M. Robles,
    Adaptive non-local means denoising of mr images with spatially varying noise levels,
    Journal of Magnetic Resonance Imaging, 31 (2010), pp. 192–203.'
  id: totrans-716
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[188] V. Mannam, Y. Zhang, Y. Zhu, E. Nichols, Q. Wang, V. Sundaresan, S. Zhang,
    C. Smith, P. W. Bohn, and S. S. Howard, Real-time image denoising of mixed poisson–gaussian
    noise in fluorescence microscopy images using imagej, Optica, 9 (2022), pp. 335–345.'
  id: totrans-717
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[189] T. Marinč, V. Srinivasan, S. Gül, C. Hellge, and W. Samek, Multi-kernel
    prediction networks for denoising of burst images, in 2019 IEEE International
    Conference on Image Processing (ICIP), IEEE, 2019, pp. 2404–2408.'
  id: totrans-718
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[190] D. R. Martin, C. C. Fowlkes, D. Tal, and J. Malik, A database of human
    segmented natural images and its application to evaluating segmentation algorithms
    and measuring ecological statistics, Proceedings Eighth IEEE International Conference
    on Computer Vision. ICCV 2001, 2 (2001), pp. 416–423 vol.2.'
  id: totrans-719
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[191] E. Martinec, Noise, dynamic range and bit depth in digital slrs, The
    University of Chicago, (2008).'
  id: totrans-720
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[192] G. Mataev, P. Milanfar, and M. Elad, DeepRED: Deep image prior powered
    by RED, in Proceedings of the IEEE International Conference on Computer Vision
    Workshops, 2019, pp. 0–0.'
  id: totrans-721
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[193] M. Matrecano, G. Poggi, and L. Verdoliva, Improved bm3d for correlated
    noise removal., in VISAPP (1), 2012, pp. 129–134.'
  id: totrans-722
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[194] T. Meinhardt, M. Moller, C. Hazirbas, and D. Cremers, Learning proximal
    operators: Using denoising networks for regularizing inverse imaging problems,
    in Proceedings of the IEEE International Conference on Computer Vision, 2017,
    pp. 1781–1790.'
  id: totrans-723
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[195] X. Meng and Y. Kabashima, Diffusion model based posterior sampling for
    noisy linear inverse problems, arXiv preprint arXiv:2211.12343, (2022).'
  id: totrans-724
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[196] C. A. Metzler, A. Maleki, and R. G. Baraniuk, From denoising to compressed
    sensing, IEEE Transactions on Information Theory, 62 (2016), pp. 5117–5144.'
  id: totrans-725
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[197] P. Milanfar, A tour of modern image filtering: New insights and methods,
    both practical and theoretical, IEEE signal processing magazine, 30 (2012), pp. 106–128.'
  id: totrans-726
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[198] B. Mildenhall, J. T. Barron, J. Chen, D. Sharlet, R. Ng, and R. Carroll,
    Burst denoising with kernel prediction networks, in Proceedings of the IEEE conference
    on computer vision and pattern recognition, 2018, pp. 2502–2510.'
  id: totrans-727
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[199] J. Miskin and D. J. MacKay, Ensemble learning for blind image separation
    and deconvolution, in Advances in independent component analysis, Springer, 2000,
    pp. 123–141.'
  id: totrans-728
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[200] K. Miyasawa, An empirical Bayes estimator of the mean of a normal population,
    Bull. Inst. Internat. Statist., 38 (1961), pp. 181–188.'
  id: totrans-729
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[201] S. Mohan, Z. Kadkhodaie, E. P. Simoncelli, and C. Fernandez-Granda, Robust
    and interpretable blind image denoising via bias-free convolutional neural networks,
    in International Conference on Learning Representations, 2019.'
  id: totrans-730
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[202] R. Mokady, A. Hertz, K. Aberman, Y. Pritch, and D. Cohen-Or, Null-text
    inversion for editing real images using guided diffusion models, arXiv preprint
    arXiv:2211.09794, (2022).'
  id: totrans-731
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[203] I. Mosseri, M. Zontak, and M. Irani, Combining the power of internal
    and external denoising, in IEEE international conference on computational photography
    (ICCP), IEEE, 2013, pp. 1–9.'
  id: totrans-732
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[204] C. Mou, Q. Wang, and J. Zhang, Deep generalized unfolding networks for
    image restoration, in Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, 2022, pp. 17399–17410.'
  id: totrans-733
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[205] K. P. Murphy, Machine learning: a probabilistic perspective, MIT press,
    2012.'
  id: totrans-734
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[206] S. Neville and N. Dimopoulos, Wavelet denoising of coarsely quantized
    signals, IEEE Transactions on Instrumentation and Measurement, 55 (2006), pp. 892–901.'
  id: totrans-735
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[207] H. V. Nguyen, M. O. Ulfarsson, and J. R. Sveinsson, Hyperspectral image
    denoising using sure-based unsupervised convolutional neural networks, IEEE Transactions
    on Geoscience and Remote Sensing, 59 (2020), pp. 3369–3382.'
  id: totrans-736
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[208] A. Q. Nichol and P. Dhariwal, Improved denoising diffusion probabilistic
    models, in International Conference on Machine Learning, PMLR, 2021, pp. 8162–8171.'
  id: totrans-737
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[209] W. Nie, B. Guo, Y. Huang, C. Xiao, A. Vahdat, and A. Anandkumar, Diffusion
    models for adversarial purification, in International Conference on Machine Learning
    (ICML), 2022.'
  id: totrans-738
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[210] M. Nikolova, A variational approach to remove outliers and impulse noise,
    Journal of Mathematical Imaging and Vision, 20 (2004), pp. 99–120.'
  id: totrans-739
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[211] G. Ohayon, T. Adrai, M. Elad, and T. Michaeli, Reasons for the superiority
    of stochastic estimators over deterministic ones: Robustness, consistency and
    perceptual quality, arXiv preprint arXiv:2211.08944, (2022).'
  id: totrans-740
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[212] G. Ohayon, T. Adrai, G. Vaksman, M. Elad, and P. Milanfar, High perceptual
    quality image denoising with a posterior sampling CGAN, in Proceedings of the
    IEEE/CVF International Conference on Computer Vision, 2021, pp. 1805–1813.'
  id: totrans-741
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[213] Z. Pan, X. Zhou, and H. Tian, Extreme generative image compression by
    learning text embedding from diffusion models, arXiv preprint arXiv:2211.07793,
    (2022).'
  id: totrans-742
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[214] Y. C. Pati, R. Rezaiifar, and P. S. Krishnaprasad, Orthogonal matching
    pursuit: Recursive function approximation with applications to wavelet decomposition,
    in Proceedings of 27th Asilomar conference on signals, systems and computers,
    IEEE, 1993, pp. 40–44.'
  id: totrans-743
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[215] K. Pearson, On lines and planes of closest fit to systems of points in
    space, The London, Edinburgh, and Dublin philosophical magazine and journal of
    science, 2 (1901), pp. 559–572.'
  id: totrans-744
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[216] P. Perona and J. Malik, Scale-space and edge detection using anisotropic
    diffusion, IEEE Transactions on pattern analysis and machine intelligence, 12
    (1990), pp. 629–639.'
  id: totrans-745
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[217] H. Pishro-Nik, Introduction to probability, statistics and random processes,
    (2014).'
  id: totrans-746
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[218] T. Plötz and S. Roth, Neural nearest neighbors networks, in Neural Information
    Processing Systems, 2018.'
  id: totrans-747
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[219] N. N. Ponomarenko, V. V. Lukin, A. A. Zelensky, J. T. Astola, and K. O.
    Egiazarian, Adaptive dct-based filtering of images corrupted by spatially correlated
    noise, in Image processing: algorithms and systems VI, vol. 6812, SPIE, 2008,
    pp. 285–295.'
  id: totrans-748
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[220] B. Poole, A. Jain, J. T. Barron, and B. Mildenhall, Dreamfusion: Text-to-3d
    using 2d diffusion, arXiv preprint arXiv:2209.14988, (2022).'
  id: totrans-749
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[221] J. Portilla, V. Strela, M. J. Wainwright, and E. P. Simoncelli, Image
    denoising using scale mixtures of gaussians in the wavelet domain, IEEE Transactions
    on Image processing, 12 (2003), pp. 1338–1351.'
  id: totrans-750
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[222] A. Radford, L. Metz, and S. Chintala, Unsupervised representation learning
    with deep convolutional generative adversarial networks, in 4th International
    Conference on Learning Representations, ICLR, 2016.'
  id: totrans-751
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[223] J. Rajan, K. Kannan, and M. Kaimal, An improved hybrid model for molecular
    image denoising, Journal of Mathematical Imaging and Vision, 31 (2008), pp. 73–79.'
  id: totrans-752
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[224] A. Ramesh, P. Dhariwal, A. Nichol, C. Chu, and M. Chen, Hierarchical
    text-conditional image generation with clip latents, arXiv preprint arXiv:2204.06125,
    (2022).'
  id: totrans-753
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[225] E. T. Reehorst and P. Schniter, Regularization by denoising: Clarifications
    and new interpretations, IEEE Transactions on computational imaging, 5 (2018),
    pp. 52–67.'
  id: totrans-754
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[226] T. Remez, O. Litany, R. Giryes, and A. M. Bronstein, Class-aware fully
    convolutional gaussian and poisson denoising, IEEE Transactions on Image Processing,
    27 (2018), pp. 5707–5722.'
  id: totrans-755
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[227] M. P. Reymann, T. Würfl, P. Ritt, B. Stimpel, M. Cachovan, A. H. Vija,
    and A. Maier, U-net for SPECT image denoising, in 2019 IEEE Nuclear Science Symposium
    and Medical Imaging Conference (NSS/MIC), IEEE, 2019, pp. 1–2.'
  id: totrans-756
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[228] D. Rezende and S. Mohamed, Variational inference with normalizing flows,
    in International Conference on Machine Learning, PMLR, 2015, pp. 1530–1538.'
  id: totrans-757
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[229] J. Rick Chang, C.-L. Li, B. Poczos, B. Vijaya Kumar, and A. C. Sankaranarayanan,
    One network to solve them all: Solving linear inverse problems using deep projection
    models, in Proceedings of the IEEE International Conference on Computer Vision,
    2017, pp. 5888–5897.'
  id: totrans-758
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[230] G. O. Roberts, R. L. Tweedie, et al., Exponential convergence of langevin
    distributions and their discrete approximations, Bernoulli, 2 (1996), pp. 341–363.'
  id: totrans-759
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[231] Y. Romano, M. Elad, and P. Milanfar, The little engine that could: Regularization
    by denoising (RED), SIAM Journal on Imaging Sciences, 10 (2017), pp. 1804–1844.'
  id: totrans-760
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[232] R. Rombach, A. Blattmann, D. Lorenz, P. Esser, and B. Ommer, High-resolution
    image synthesis with latent diffusion models, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2022, pp. 10684–10695.'
  id: totrans-761
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[233] A. Rond, R. Giryes, and M. Elad, Poisson inverse problems by the plug-and-play
    scheme, Journal of Visual Communication and Image Representation, 41 (2016), pp. 96–108.'
  id: totrans-762
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[234] O. Ronneberger, P. Fischer, and T. Brox, U-net: Convolutional networks
    for biomedical image segmentation, in International Conference on Medical image
    computing and computer-assisted intervention, Springer, 2015, pp. 234–241.'
  id: totrans-763
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[235] R. J. Rossi, Mathematical statistics: an introduction to likelihood based
    inference, John Wiley & Sons, 2018.'
  id: totrans-764
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[236] S. Roth and M. J. Black, Fields of experts: a framework for learning
    image priors, 2005 IEEE Computer Society Conference on Computer Vision and Pattern
    Recognition (CVPR’05), 2 (2005), pp. 860–867 vol. 2.'
  id: totrans-765
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[237] S. Roth and M. J. Black, Fields of experts, International Journal of
    Computer Vision, 82 (2009), pp. 205–229.'
  id: totrans-766
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[238] P. J. Rousseeuw, F. R. Hampel, E. M. Ronchetti, and W. A. Stahel, Robust
    statistics: the approach based on influence functions, John Wiley & Sons, 2011.'
  id: totrans-767
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[239] D. L. Ruderman, The statistics of natural images, Network: Computation
    in Neural Systems, 5 (1994), pp. 517–548.'
  id: totrans-768
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[240] L. I. Rudin, S. Osher, and E. Fatemi, Nonlinear total variation based
    noise removal algorithms, Physica D: nonlinear phenomena, 60 (1992), pp. 259–268.'
  id: totrans-769
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[241] N. Ruiz, Y. Li, V. Jampani, Y. Pritch, M. Rubinstein, and K. Aberman,
    Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation,
    arXiv preprint arXiv:2208.12242, (2022).'
  id: totrans-770
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[242] D. E. Rumelhart, G. E. Hinton, and R. J. Williams, Learning representations
    by back-propagating errors, nature, 323 (1986), pp. 533–536.'
  id: totrans-771
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[243] C. Saharia, W. Chan, H. Chang, C. Lee, J. Ho, T. Salimans, D. Fleet,
    and M. Norouzi, Palette: Image-to-image diffusion models, in ACM SIGGRAPH 2022
    Conference Proceedings, 2022, pp. 1–10.'
  id: totrans-772
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[244] C. Saharia, W. Chan, S. Saxena, L. Li, J. Whang, E. Denton, S. K. S.
    Ghasemipour, B. K. Ayan, S. S. Mahdavi, R. G. Lopes, et al., Photorealistic text-to-image
    diffusion models with deep language understanding, arXiv preprint arXiv:2205.11487,
    (2022).'
  id: totrans-773
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[245] C. Saharia, J. Ho, W. Chan, T. Salimans, D. J. Fleet, and M. Norouzi,
    Image super-resolution via iterative refinement, IEEE Transactions on Pattern
    Analysis and Machine Intelligence, (2022).'
  id: totrans-774
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[246] P. Saint-Marc, J.-S. Chen, and G. Medioni, Adaptive smoothing: A general
    tool for early vision, IEEE Transactions on Pattern Analysis & Machine Intelligence,
    13 (1991), pp. 514–529.'
  id: totrans-775
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[247] T. Salimans and J. Ho, Progressive distillation for fast sampling of
    diffusion models, arXiv preprint arXiv:2202.00512, (2022).'
  id: totrans-776
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[248] J. Salmon, Z. Harmany, C.-A. Deledalle, and R. Willett, Poisson noise
    reduction with non-local pca, Journal of mathematical imaging and vision, 48 (2014),
    pp. 279–294.'
  id: totrans-777
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[249] A. Sauer, K. Schwarz, and A. Geiger, StyleGAN-XL: Scaling StyleGAN to
    large diverse datasets, arXiv preprint arXiv:2202.00273, (2022).'
  id: totrans-778
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[250] M. Scetbon, M. Elad, and P. Milanfar, Deep K-SVD denoising, IEEE Transactions
    on Image Processing, 30 (2021), pp. 5944–5955.'
  id: totrans-779
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[251] R. W. Schafer, R. M. Mersereau, and M. A. Richards, Constrained iterative
    restoration algorithms, Proceedings of the IEEE, 69 (1981), pp. 432–450.'
  id: totrans-780
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[252] U. Schmidt and S. Roth, Shrinkage fields for effective image restoration,
    2014 IEEE Conference on Computer Vision and Pattern Recognition, (2014), pp. 2774–2781.'
  id: totrans-781
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[253] Y. Shi, V. De Bortoli, G. Deligiannidis, and A. Doucet, Conditional simulation
    using diffusion Schrödinger bridges, arXiv preprint arXiv:2202.13460, (2022).'
  id: totrans-782
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[254] A. Sinha, J. Song, C. Meng, and S. Ermon, D2c: Diffusion-decoding models
    for few-shot conditional generation, Advances in Neural Information Processing
    Systems, 34 (2021), pp. 12533–12548.'
  id: totrans-783
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[255] N. Sochen, R. Kimmel, and R. Malladi, A general framework for low level
    vision, IEEE transactions on image processing, 7 (1998), pp. 310–318.'
  id: totrans-784
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[256] J. W. Soh and N. I. Cho, Deep universal blind image denoising, in 2020
    25th International Conference on Pattern Recognition (ICPR), IEEE, 2021, pp. 747–754.'
  id: totrans-785
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[257] J. Sohl-Dickstein, E. Weiss, N. Maheswaranathan, and S. Ganguli, Deep
    unsupervised learning using nonequilibrium thermodynamics, in International Conference
    on Machine Learning, PMLR, 2015, pp. 2256–2265.'
  id: totrans-786
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[258] J. Song, C. Meng, and S. Ermon, Denoising diffusion implicit models,
    in International Conference on Learning Representations, April 2021.'
  id: totrans-787
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[259] M. Song, Y. Zhang, and T. O. Aydin, Tempformer: Temporally consistent
    transformer for video denoising, in European Conference on Computer Vision, 2022.'
  id: totrans-788
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[260] Y. Song and S. Ermon, Generative modeling by estimating gradients of
    the data distribution, in Advances in Neural Information Processing Systems, 2019,
    pp. 11918–11930.'
  id: totrans-789
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[261] Y. Song and S. Ermon, Improved techniques for training score-based generative
    models, in Advances in Neural Information Processing Systems, 33, 2020.'
  id: totrans-790
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[262] Y. Song, J. Sohl-Dickstein, D. P. Kingma, A. Kumar, S. Ermon, and B. Poole,
    Score-based generative modeling through stochastic differential equations, in
    International Conference on Learning Representations, 2021.'
  id: totrans-791
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[263] S. Sreehari, S. V. Venkatakrishnan, B. Wohlberg, G. T. Buzzard, L. F.
    Drummy, J. P. Simmons, and C. A. Bouman, Plug-and-play priors for bright field
    electron tomography and sparse interpolation, IEEE Transactions on Computational
    Imaging, 2 (2016), pp. 408–423.'
  id: totrans-792
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[264] K. Srinivasan and D. Ebenezer, A new fast and efficient decision-based
    algorithm for removal of high-density impulse noises, IEEE Signal Processing Letters,
    14 (2007), pp. 189–192.'
  id: totrans-793
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[265] C. M. Stein, Estimation of the mean of a multivariate normal distribution,
    The annals of Statistics, (1981), pp. 1135–1151.'
  id: totrans-794
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[266] J. Sun, Y. Du, C. Li, T.-H. Wu, B. Yang, and G. S. Mok, Pix2pix generative
    adversarial network for low dose myocardial perfusion SPECT denoising, Quantitative
    Imaging in Medicine and Surgery, 12 (2022), p. 3539.'
  id: totrans-795
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[267] Y. Sun, J. Liu, and U. Kamilov, Block coordinate regularization by denoising,
    in Advances in Neural Information Processing Systems, 2019, pp. 380–390.'
  id: totrans-796
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[268] Y. Sun, B. Wohlberg, and U. S. Kamilov, An online plug-and-play algorithm
    for regularized image reconstruction, IEEE Transactions on Computational Imaging,
    5 (2019), pp. 395–408.'
  id: totrans-797
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[269] Y. Sun, Z. Wu, X. Xu, B. Wohlberg, and U. S. Kamilov, Scalable plug-and-play
    admm with convergence guarantees, IEEE Transactions on Computational Imaging,
    7 (2021), pp. 849–863.'
  id: totrans-798
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[270] Y. Tai, J. Yang, X. Liu, and C. Xu, Memnet: A persistent memory network
    for image restoration, in Proceedings of the IEEE international conference on
    computer vision, 2017, pp. 4539–4547.'
  id: totrans-799
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[271] H. Takeda, S. Farsiu, and P. Milanfar, Kernel regression for image processing
    and reconstruction, IEEE Transactions on image processing, 16 (2007), pp. 349–366.'
  id: totrans-800
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[272] H. Talbot, H. Phelippeau, M. Akil, and S. Bara, Efficient poisson denoising
    for photography, in 2009 16th IEEE International Conference on Image Processing
    (ICIP), IEEE, 2009, pp. 3881–3884.'
  id: totrans-801
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[273] H. Talebi and P. Milanfar, Global image denoising, IEEE Transactions
    on Image Processing, 23 (2013), pp. 755–768.'
  id: totrans-802
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[274] T. Tasdizen, Principal neighborhood dictionaries for nonlocal means image
    denoising, IEEE Transactions on Image Processing, 18 (2009), pp. 2649–2660.'
  id: totrans-803
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[275] M. Tassano, J. Delon, and T. Veit, Dvdnet: A fast network for deep video
    denoising, in 2019 IEEE International Conference on Image Processing (ICIP), IEEE,
    2019, pp. 1805–1809.'
  id: totrans-804
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[276] M. Tassano, J. Delon, and T. Veit, Fastdvdnet: Towards real-time deep
    video denoising without flow estimation, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2020, pp. 1354–1363.'
  id: totrans-805
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[277] P. Tchebycheff, Sur deux théorèmes relatifs aux probabilités, Acta Mathematica,
    14 (1890), pp. 305 – 315.'
  id: totrans-806
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[278] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, Scene-adapted
    plug-and-play algorithm with convergence guarantees, in IEEE 27th International
    Workshop on Machine Learning for Signal Processing (MLSP), 2017, pp. 1–6.'
  id: totrans-807
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[279] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, A convergent
    image fusion algorithm using scene-adapted Gaussian-mixture-based denoising, IEEE
    Transactions on Image Processing, 28 (2018), pp. 451–463.'
  id: totrans-808
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[280] A. M. Teodoro, J. M. Bioucas-Dias, and M. A. Figueiredo, Image restoration
    and reconstruction using targeted plug-and-play priors, IEEE Transactions on Computational
    Imaging, 5 (2019), pp. 675–686.'
  id: totrans-809
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[281] C. Tian, L. Fei, W. Zheng, Y. Xu, W. Zuo, and C.-W. Lin, Deep learning
    on image denoising: An overview, Neural Networks, 131 (2020), pp. 251–275.'
  id: totrans-810
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[282] A. Tikhonov and V. Arsenin, Solution of Ill-posed Problems, Washington:
    Winston & Sons, 1977.'
  id: totrans-811
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[283] T. Tirer and R. Giryes, Image restoration by iterative denoising and
    backward projections, IEEE Transactions on Image Processing, 28 (2018), pp. 1220–1234.'
  id: totrans-812
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[284] C. Tomasi and R. Manduchi, Bilateral filtering for gray and color images,
    in Sixth international conference on computer vision (IEEE Cat. No. 98CH36271),
    IEEE, 1998, pp. 839–846.'
  id: totrans-813
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[285] L. D. Tran, S. M. Nguyen, and M. Arai, Gan-based noise model for denoising
    real images, in Proceedings of the Asian Conference on Computer Vision, 2020.'
  id: totrans-814
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[286] D. Ulyanov, A. Vedaldi, and V. Lempitsky, Deep image prior, in Proceedings
    of the IEEE CVPR, 2018, pp. 9446–9454.'
  id: totrans-815
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[287] A. Vahdat, K. Kreis, and J. Kautz, Score-based generative modeling in
    latent space, in Neural Information Processing Systems (NeurIPS), 2021.'
  id: totrans-816
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[288] G. Vaksman and M. Elad, Patch-craft self-supervised training for correlated
    image denoising, arXiv preprint arXiv:2211.09919, (2022).'
  id: totrans-817
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[289] G. Vaksman, M. Elad, and P. Milanfar, LIDIA: Lightweight learned image
    denoising with instance adaptation, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition Workshops, 2020, pp. 524–525.'
  id: totrans-818
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[290] G. Vaksman, M. Elad, and P. Milanfar, Patch craft: Video denoising by
    deep modeling and patch matching, 2021 IEEE/CVF International Conference on Computer
    Vision (ICCV), (2021), pp. 2137–2146.'
  id: totrans-819
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[291] G. Vaksman, M. Zibulevsky, and M. Elad, Patch ordering as a regularization
    for inverse problems in image processing, SIAM Journal on Imaging Sciences, 9
    (2016), pp. 287–319.'
  id: totrans-820
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[292] D. Valsesia, G. Fracastoro, and E. Magli, Deep graph-convolutional image
    denoising, IEEE Transactions on Image Processing, 29 (2019), pp. 8226–8237.'
  id: totrans-821
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[293] A. Van Den Oord, N. Kalchbrenner, and K. Kavukcuoglu, Pixel recurrent
    neural networks, in International Conference on Machine Learning, PMLR, 2016,
    pp. 1747–1756.'
  id: totrans-822
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[294] M. Vatsa, R. Singh, and A. Noore, Denoising and segmentation of 3d brain
    images., IPCV, 9 (2009), pp. 561–567.'
  id: totrans-823
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[295] S. V. Venkatakrishnan, C. A. Bouman, and B. Wohlberg, Plug-and-play priors
    for model based reconstruction, in 2013 IEEE Global Conference on Signal and Information
    Processing, IEEE, 2013, pp. 945–948.'
  id: totrans-824
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[296] P. Vincent, A connection between score matching and denoising autoencoders,
    Neural computation, 23 (2011), pp. 1661–1674.'
  id: totrans-825
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[297] C. Wang, J. Zhou, and S. Liu, Adaptive non-local means filter for image
    deblocking, Signal Processing: Image Communication, 28 (2013), pp. 522–530.'
  id: totrans-826
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[298] Y. Wang, H. Huang, Q. Xu, J. Liu, Y. Liu, and J. Wang, Practical deep
    raw image denoising on mobile devices, in European Conference on Computer Vision,
    Springer, 2020, pp. 1–16.'
  id: totrans-827
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[299] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, Image quality
    assessment: from error visibility to structural similarity, IEEE transactions
    on image processing, 13 (2004), pp. 600–612.'
  id: totrans-828
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[300] Z. Wang and D. Zhang, Progressive switching median filter for the removal
    of impulse noise from highly corrupted images, IEEE Transactions on Circuits and
    Systems Ii: Analog and Digital Signal Processing, 46 (1999), pp. 78–80.'
  id: totrans-829
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[301] K. Wei, Y. Fu, J. Yang, and H. Huang, A physics-based noise formation
    model for extreme low-light raw denoising, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2020, pp. 2758–2767.'
  id: totrans-830
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[302] J. Weickert, Anisotropic diffusion in image processing, Stuttgart: Teubner,
    1998.'
  id: totrans-831
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[303] J. Whang, M. Delbracio, H. Talebi, C. Saharia, A. G. Dimakis, and P. Milanfar,
    Deblurring via stochastic refinement, in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2022, pp. 16293–16303.'
  id: totrans-832
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[304] N. Wiener, Extrapolation, interpolation, and smoothing of stationary
    time series: with engineering applications, vol. 113, MIT press Cambridge, MA,
    1949.'
  id: totrans-833
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[305] J. Wright, A. Ganesh, S. Rao, Y. Peng, and Y. Ma, Robust principal component
    analysis: Exact recovery of corrupted low-rank matrices via convex optimization,
    Advances in neural information processing systems, 22 (2009).'
  id: totrans-834
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[306] J. Xie, L. Xu, and E. Chen, Image denoising and inpainting with deep
    neural networks, in NIPS, 2012.'
  id: totrans-835
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[307] J. Xu, L. Zhang, and D. Zhang, A trilateral weighted sparse coding scheme
    for real-world image denoising, in Proceedings of the European conference on computer
    vision (ECCV), 2018, pp. 20–36.'
  id: totrans-836
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[308] Q. Xu, C. Zhang, and L. Zhang, Denoising convolutional neural network,
    in 2015 IEEE International Conference on Information and Automation, IEEE, 2015,
    pp. 1184–1187.'
  id: totrans-837
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[309] X. Xu, Y. Sun, J. Liu, B. Wohlberg, and U. S. Kamilov, Provable convergence
    of plug-and-play priors with MMSE denoisers, arXiv preprint arXiv:2005.07685,
    (2020).'
  id: totrans-838
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[310] N. Yair and T. Michaeli, Multi-scale weighted nuclear norm image restoration,
    in Proceedings of the IEEE conference on computer vision and pattern recognition,
    2018, pp. 3165–3174.'
  id: totrans-839
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[311] J. C. K. Yan, P. Campisi, and D. Hatzinakos, Film grain noise removal
    and generation for color images, in Proceedings of the 1998 IEEE International
    Conference on Acoustics, Speech and Signal Processing, ICASSP’98 (Cat. No. 98CH36181),
    vol. 5, IEEE, 1998, pp. 2957–2960.'
  id: totrans-840
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[312] J. C. K. Yan and D. Hatzinakos, Signal-dependent film grain noise removal
    and generation based on higher-order statistics, Proceedings of the IEEE Signal
    Processing Workshop on Higher-Order Statistics, (1997), pp. 77–81.'
  id: totrans-841
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[313] D. Yang and J. Sun, Proximal dehaze-net: A prior learning-based deep
    network for single image dehazing, in Proceedings of the european conference on
    computer vision (ECCV), 2018, pp. 702–717.'
  id: totrans-842
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[314] L. Yang, Z. Li, R. Ge, J. Zhao, H. Si, and D. Zhang, Low-dose ct denoising
    via sinogram inner-structure transformer, IEEE Transactions on Medical Imaging,
    (2022).'
  id: totrans-843
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[315] L. Yang, Z. Zhang, Y. Song, S. Hong, R. Xu, Y. Zhao, Y. Shao, W. Zhang,
    B. Cui, and M.-H. Yang, Diffusion models: A comprehensive survey of methods and
    applications, arXiv preprint arXiv:2209.00796, (2022).'
  id: totrans-844
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[316] Q. Yang, P. Yan, Y. Zhang, H. Yu, Y. Shi, X. Mou, M. K. Kalra, Y. Zhang,
    L. Sun, and G. Wang, Low-dose ct image denoising using a generative adversarial
    network with wasserstein distance and perceptual loss, IEEE transactions on medical
    imaging, 37 (2018), pp. 1348–1357.'
  id: totrans-845
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[317] C. Yao, S. Jin, M. Liu, and X. Ban, Dense residual transformer for image
    denoising, Electronics, 11 (2022), p. 418.'
  id: totrans-846
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[318] X. Yi and P. Babyn, Sharpness-aware low-dose ct denoising using conditional
    generative adversarial network, Journal of digital imaging, 31 (2018), pp. 655–669.'
  id: totrans-847
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[319] F. Yu, Y. Zhang, S. Song, A. Seff, and J. Xiao, Lsun: Construction of
    a large-scale image dataset using deep learning with humans in the loop, arXiv
    preprint arXiv:1506.03365, (2015).'
  id: totrans-848
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[320] G. Yu, G. Sapiro, and S. Mallat, Solving inverse problems with piecewise
    linear estimators: From Gaussian mixture models to structured sparsity, IEEE Transactions
    on Image Processing, 21 (2011), pp. 2481–2499.'
  id: totrans-849
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[321] Z. Yue, H. Yong, Q. Zhao, D. Meng, and L. Zhang, Variational denoising
    network: Toward blind noise modeling and removal, Advances in neural information
    processing systems, 32 (2019).'
  id: totrans-850
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[322] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, and M.-H. Yang,
    Restormer: Efficient transformer for high-resolution image restoration, in Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022, pp. 5728–5739.'
  id: totrans-851
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[323] S. W. Zamir, A. Arora, S. Khan, M. Hayat, F. S. Khan, M.-H. Yang, and
    L. Shao, Multi-stage progressive image restoration, in Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition, 2021, pp. 14821–14831.'
  id: totrans-852
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[324] J. Zeng, G. Cheung, M. Ng, J. Pang, and C. Yang, 3D point cloud denoising
    using graph laplacian regularization of a low dimensional manifold model, IEEE
    Transactions on Image Processing, PP (2018).'
  id: totrans-853
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[325] B. Zhang, J. M. Fadili, and J.-L. Starck, Wavelets, ridgelets, and curvelets
    for poisson noise removal, IEEE Transactions on image processing, 17 (2008), pp. 1093–1108.'
  id: totrans-854
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[326] B. Zhang, M. Fadili, J.-L. Starck, and J.-C. Olivo-Marin, Multiscale
    variance-stabilizing transform for mixed-poisson-gaussian processes and its applications
    in bioimaging, in 2007 IEEE International Conference on Image Processing, vol. 6,
    IEEE, 2007, pp. VI–233.'
  id: totrans-855
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[327] H. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, Self-attention generative
    adversarial networks, in International Conference on Machine Learning, PMLR, 2019,
    pp. 7354–7363.'
  id: totrans-856
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[328] K. Zhang, L. V. Gool, and R. Timofte, Deep unfolding network for image
    super-resolution, in Proceedings of the IEEE/CVF conference on computer vision
    and pattern recognition, 2020, pp. 3217–3226.'
  id: totrans-857
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[329] K. Zhang, Y. Li, W. Zuo, L. Zhang, L. V. Gool, and R. Timofte, Plug-and-play
    image restoration with deep denoiser prior, IEEE Transactions on Pattern Analysis
    and Machine Intelligence, 44 (2020), pp. 6360–6376.'
  id: totrans-858
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[330] K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, Beyond a Gaussian denoiser:
    Residual learning of deep CNN for image denoising, IEEE Transactions on Image
    Processing, 26 (2017), pp. 3142–3155.'
  id: totrans-859
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[331] K. Zhang, W. Zuo, S. Gu, and L. Zhang, Learning deep CNN denoiser prior
    for image restoration, in Proceedings of the IEEE CVPR, 2017, pp. 3929–3938.'
  id: totrans-860
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[332] K. Zhang, W. Zuo, and L. Zhang, FFDNet: Toward a fast and flexible solution
    for CNN-based image denoising, IEEE Transactions on Image Processing, 27 (2018),
    pp. 4608–4622.'
  id: totrans-861
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[333] K. Zhang, W. Zuo, and L. Zhang, Deep plug-and-play super-resolution for
    arbitrary blur kernels, in Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, 2019, pp. 1671–1681.'
  id: totrans-862
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[334] M. Zhang, F. Zhang, Q. Liu, and S. Wang, Vst-net: Variance-stabilizing
    transformation inspired network for poisson denoising, Journal of Visual Communication
    and Image Representation, 62 (2019), pp. 12–22.'
  id: totrans-863
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[335] R. Zhang, P. Isola, A. A. Efros, E. Shechtman, and O. Wang, The unreasonable
    effectiveness of deep features as a perceptual metric, in Proceedings of the IEEE
    conference on computer vision and pattern recognition, 2018, pp. 586–595.'
  id: totrans-864
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[336] X. Zhang, Z. Xu, N. Jia, W. Yang, Q. Feng, W. Chen, and Y. Feng, Denoising
    of 3d magnetic resonance images by using higher-order singular value decomposition,
    Medical Image Analysis, In press (2014).'
  id: totrans-865
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[337] X.-P. Zhang and M. D. Desai, Adaptive denoising based on sure risk, IEEE
    signal processing letters, 5 (1998), pp. 265–267.'
  id: totrans-866
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[338] Y. Zhang, H. Qin, X. Wang, and H. Li, Rethinking noise synthesis and
    modeling in raw denoising, in Proceedings of the IEEE/CVF International Conference
    on Computer Vision, 2021, pp. 4593–4601.'
  id: totrans-867
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[339] Y. Zhang, Y. Tian, Y. Kong, B. Zhong, and Y. Fu, Residual dense network
    for image restoration, IEEE Transactions on Pattern Analysis and Machine Intelligence,
    (2020).'
  id: totrans-868
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[340] Y. Zhang, Y. Zhu, E. Nichols, Q. Wang, S. Zhang, C. Smith, and S. Howard,
    A poisson-gaussian denoising dataset with real fluorescence microscopy images,
    in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2019, pp. 11710–11718.'
  id: totrans-869
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[341] Z. Zhang, Y. Liu, J. Liu, F. Wen, and C. Zhu, Amp-net: Denoising-based
    deep unfolding for compressive image sensing, IEEE Transactions on Image Processing,
    30 (2020), pp. 1487–1500.'
  id: totrans-870
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[342] H. Zhao, W. Shao, B. Bao, and H. Li, A simple and robust deep convolutional
    approach to blind image denoising, in Proceedings of the IEEE/CVF International
    Conference on Computer Vision Workshops, 2019.'
  id: totrans-871
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[343] L. Zhou, J. D. Schaefferkoetter, I. W. Tham, G. Huang, and J. Yan, Supervised
    learning with cyclegan for low-dose fdg pet image denoising, Medical image analysis,
    65 (2020), p. 101770.'
  id: totrans-872
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[344] Y. Zhou, J. Jiao, H. Huang, Y. Wang, J. Wang, H. Shi, and T. Huang, When
    AWGN-based denoiser meets real noises, in Proceedings of the AAAI Conference on
    Artificial Intelligence, vol. 34, 2020, pp. 13074–13081.'
  id: totrans-873
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[345] F. Zhu, G. Chen, and P.-A. Heng, From noise modeling to blind image denoising,
    in Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    2016, pp. 420–429.'
  id: totrans-874
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[346] Z. Zhu, Y. Wei, J. Wang, Z. Gan, Z. Zhang, L. Wang, G. Hua, L. Wang,
    Z. Liu, and H. Hu, Exploring discrete diffusion models for image captioning, arXiv
    preprint arXiv:2211.11694, (2022).'
  id: totrans-875
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[347] D. Zoran and Y. Weiss, From learning models of natural image patches
    to whole image restoration, in IEEE International Conference on Computer Vision,
    2011, pp. 479–486.'
  id: totrans-876
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
