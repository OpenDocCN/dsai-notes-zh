["```py\n**from** **fastai.imports** **import** *\n**from** **fastai.torch_imports** **import** *\n**from** **fastai.io** **import** *path = 'data/mnist/'**import** **os**\nos.makedirs(path, exist_ok=**True**)\n```", "```py\nURL='http://deeplearning.net/data/mnist/'\nFILENAME='mnist.pkl.gz'**def** load_mnist(filename):\n   **return** pickle.load(gzip.open(filename, 'rb'), encoding='latin-1')\n```", "```py\nget_data(URL+FILENAME, path+FILENAME)\n((x, y), (x_valid, y_valid), _) = load_mnist(path+FILENAME)\n```", "```py\ntype(x), x.shape, type(y), y.shape(numpy.ndarray, (50000, 784), numpy.ndarray, (50000,))\n```", "```py\nmean = x.mean()\nstd = x.std()\n\nx=(x-mean)/std\nmean, std, x.mean(), x.std()*(0.13044983, 0.30728981, -3.1638146e-01, 0.99999934)*\n```", "```py\nx_valid = (x_valid-mean)/std\nx_valid.mean(), x_valid.std()*(-0.0058509219, 0.99243325)*\n```", "```py\nx_valid.shape(10000, 784)\n```", "```py\nx_imgs = np.reshape(x_valid, (-1,28,28)); x_imgs.shape(10000, 28, 28)\n```", "```py\nshow(x_imgs[0], y_valid[0])\n```", "```py\ny_valid.shape(10000,)\n```", "```py\ny_valid[0]3\n```", "```py\nx_imgs[0,10:15,10:15]array([[-0.42452, -0.42452, -0.42452, -0.42452,  0.17294],\n       [-0.42452, -0.42452, -0.42452,  0.78312,  2.43567],\n       [-0.42452, -0.27197,  1.20261,  2.77889,  2.80432],\n       [-0.42452,  1.76194,  2.80432,  2.80432,  1.73651],\n       [-0.42452,  2.20685,  2.80432,  2.80432,  0.40176]], dtype=float32)\n```", "```py\nshow(x_imgs[0,10:15,10:15])\n```", "```py\nplots(x_imgs[:8], titles=y_valid[:8])\n```", "```py\n**def** show(img, title=**None**):\n    plt.imshow(img, cmap=\"gray\")\n    **if** title **is** **not** **None**: plt.title(title)**def** plots(ims, figsize=(12,6), rows=2, titles=**None**):\n    f = plt.figure(figsize=figsize)\n    cols = len(ims)//rows\n    **for** i **in** range(len(ims)):\n        sp = f.add_subplot(rows, cols, i+1)\n        sp.axis('Off')\n        **if** titles **is** **not** **None**: sp.set_title(titles[i], fontsize=16)\n        plt.imshow(ims[i], cmap='gray')\n```", "```py\n**from** **fastai.metrics** **import** *\n**from** **fastai.model** **import** *\n**from** **fastai.dataset** **import** *\n\n**import** **torch.nn** **as** **nn**\n```", "```py\nnet = nn.Sequential(\n    nn.Linear(28*28, 10),\n    nn.LogSoftmax()\n).cuda()\n```", "```py\nmd = ImageClassifierData.from_arrays(path, (x,y),(x_valid, y_valid))\n```", "```py\nloss=nn.NLLLoss()\nmetrics=[accuracy]\nopt=optim.Adam(net.parameters())\n```", "```py\nfit(net, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)\n```", "```py\n**def** binary_loss(y, p):\n    **return** np.mean(-(y * np.log(p) + (1-y)*np.log(1-p)))\n```", "```py\nacts = np.array([1, 0, 0, 1])\npreds = np.array([0.9, 0.1, 0.2, 0.8])\nbinary_loss(acts, preds)*0.164252033486018*\n```", "```py\npreds = predict(net, md.val_dl)\n```", "```py\npreds.shape*(10000, 10)*\n```", "```py\npreds.argmax(axis=1)[:5]*array([3, 8, 6, 9, 6])*\n```", "```py\npreds = preds.argmax(1)np.mean(preds == y_valid)0.91820000000000002\n```", "```py\nplots(x_imgs[:8], titles=preds[:8])\n```", "```py\n**def** get_weights(*dims): \n    **return** nn.Parameter(torch.randn(dims)/dims[0])**def** softmax(x): \n    **return** torch.exp(x)/(torch.exp(x).sum(dim=1)[:,**None**])\n\n**class** **LogReg**(nn.Module):\n    **def** __init__(self):\n        super().__init__()\n        self.l1_w = get_weights(28*28, 10)  *# Layer 1 weights*\n        self.l1_b = get_weights(10)         *# Layer 1 bias*\n\n    **def** forward(self, x):\n        x = x.view(x.size(0), -1)\n        x = (x @ self.l1_w) + self.l1_b  *# Linear Layer*\n        x = torch.log(softmax(x)) *# Non-linear (LogSoftmax) Layer*\n        **return** x\n```", "```py\nnet2 = LogReg().cuda()\nopt=optim.Adam(net2.parameters())fit(net2, md, n_epochs=1, crit=loss, opt=opt, metrics=metrics)*[ 0\\.       0.32209  0.28399  0.92088]*\n```"]