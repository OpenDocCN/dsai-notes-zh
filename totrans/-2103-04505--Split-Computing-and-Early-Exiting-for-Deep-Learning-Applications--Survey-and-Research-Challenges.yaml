- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 19:56:32'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:56:32
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2103.04505] Split Computing and Early Exiting for Deep Learning Applications:
    Survey and Research Challenges'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2103.04505] 深度学习应用中的分裂计算与早期退出：调查与研究挑战'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2103.04505](https://ar5iv.labs.arxiv.org/html/2103.04505)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2103.04505](https://ar5iv.labs.arxiv.org/html/2103.04505)
- en: '02115'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '02115'
- en: 'Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习应用中的分裂计算与早期退出：调查与研究挑战
- en: Yoshitomo Matsubara [yoshitom@uci.edu](mailto:yoshitom@uci.edu) [0000-0002-5620-0760](https://orcid.org/0000-0002-5620-0760
    "ORCID identifier") ,  Marco Levorato [levorato@uci.edu](mailto:levorato@uci.edu)
    University of California, IrvineIrvineCaliforniaUSA92697  and  Francesco Restuccia
    Northeastern University360 Huntington AveBostonMassachusettsUSA [f.restuccia@northeastern.edu](mailto:f.restuccia@northeastern.edu)(2021)
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Yoshitomo Matsubara [yoshitom@uci.edu](mailto:yoshitom@uci.edu) [0000-0002-5620-0760](https://orcid.org/0000-0002-5620-0760
    "ORCID identifier")，Marco Levorato [levorato@uci.edu](mailto:levorato@uci.edu)
    加州大学欧文分校，欧文，加州，美国92697 以及 Francesco Restuccia 东北大学 360 Huntington Ave Boston Massachusetts
    USA [f.restuccia@northeastern.edu](mailto:f.restuccia@northeastern.edu)(2021)
- en: Abstract.
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: Mobile devices such as smartphones and autonomous vehicles increasingly rely
    on DNN s to execute complex inference tasks such as image classification and speech
    recognition, among others. However, continuously executing the entire DNN on mobile
    devices can quickly deplete their battery. Although task offloading to cloud/edge
    servers may decrease the mobile device’s computational burden, erratic patterns
    in channel quality, network, and edge server load can lead to a significant delay
    in task execution. Recently, approaches based on split computing (SC) have been
    proposed, where the DNN is split into a head and a tail model, executed respectively
    on the mobile device and on the edge server. Ultimately, this may reduce bandwidth
    usage as well as energy consumption. Another approach, called early exiting (EE),
    trains models to embed multiple “exits” earlier in the architecture, each providing
    increasingly higher target accuracy. Therefore, the trade-off between accuracy
    and delay can be tuned according to the current conditions or application demands.
    In this paper, we provide a comprehensive survey of the state of the art in SC
    and EE strategies by presenting a comparison of the most relevant approaches.
    We conclude the paper by providing a set of compelling research challenges.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 智能手机和自动驾驶车辆等移动设备越来越依赖于 DNN 来执行图像分类、语音识别等复杂推断任务。然而，持续在移动设备上执行整个 DNN 会迅速耗尽其电池。尽管将任务卸载到云端/边缘服务器可能减少移动设备的计算负担，但信道质量、网络和边缘服务器负载的不稳定模式可能导致任务执行的显著延迟。最近，提出了基于分裂计算（SC）的方法，其中
    DNN 被拆分为头模型和尾模型，分别在移动设备和边缘服务器上执行。*最终*，这可能减少带宽使用以及能源消耗。另一种方法，称为早期退出（EE），训练模型在架构中嵌入多个“退出”点，每个点提供越来越高的目标准确性。因此，可以根据当前条件或应用需求调整准确性与延迟之间的权衡。本文通过展示最相关方法的比较，对
    SC 和 EE 策略的现状进行了全面的调查。我们在文末提供了一系列引人注目的研究挑战。
- en: 'Split Computing, Edge Computing, Early Exit, Neural Networks, Deep Learning^†^†copyright:
    acmcopyright^†^†journalyear: 2021^†^†doi: 10.1145/1122445.1122456^†^†journal:
    CSUR^†^†journalvolume: 37^†^†journalnumber: 4^†^†article: 0^†^†publicationmonth:
    8^†^†ccs: Human-centered computing Ubiquitous and mobile computing^†^†ccs: Computer
    systems organization Embedded and cyber-physical systems^†^†ccs: Computing methodologies Neural
    networks'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂计算、边缘计算、早期退出、神经网络、深度学习^†^†版权：acm 版权^†^†期刊年：2021^†^†doi：10.1145/1122445.1122456^†^†期刊：CSUR^†^†期刊卷号：37^†^†期刊号：4^†^†文章：0^†^†出版月份：8^†^†ccs：以人为中心的计算
    泛在与移动计算^†^†ccs：计算机系统组织 嵌入式与网络物理系统^†^†ccs：计算方法 神经网络
- en: 1\. Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1\. 引言
- en: The field of deep learning (DL) has evolved at an impressive pace over the last
    few years (LeCun et al., [2015](#bib.bib69)), with new breakthroughs continuously
    appearing in domains such as computer vision (CV), natural language processing
    (NLP), digital signal processing (DSP), and wireless networking (Jagannath et al.,
    [2019](#bib.bib57); Restuccia and Melodia, [2020](#bib.bib119)) among others –
    we refer to (Pouyanfar et al., [2018](#bib.bib111)) for a comprehensive survey
    on DL. For example, today’s state of the art deep neural networks (DNNs) can classify
    thousands of images with unprecedented accuracy (Huang et al., [2017](#bib.bib52)),
    while bleeding-edge advances in deep reinforcement learning (DRL) have shown to
    provide near-human capabilities in a multitude of complex optimization tasks,
    from playing dozens of Atari video games (Mnih et al., [2013](#bib.bib100)) to
    winning games of Go against top-tier players (Silver et al., [2017](#bib.bib128)).
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）领域在过去几年中以令人印象深刻的速度发展（LeCun et al., [2015](#bib.bib69)），不断在计算机视觉（CV）、自然语言处理（NLP）、数字信号处理（DSP）和无线网络（Jagannath
    et al., [2019](#bib.bib57); Restuccia 和 Melodia, [2020](#bib.bib119)）等领域取得新突破——我们参考（Pouyanfar
    et al., [2018](#bib.bib111)）以获取有关 DL 的全面综述。例如，今天最先进的深度神经网络（DNNs）能够以前所未有的准确性分类数千张图像（Huang
    et al., [2017](#bib.bib52)），而最前沿的深度强化学习（DRL）进展已显示在多个复杂优化任务中提供接近人类的能力，从玩几十款雅达利电子游戏（Mnih
    et al., [2013](#bib.bib100)）到击败顶级玩家的围棋比赛（Silver et al., [2017](#bib.bib128)）。
- en: As DL-based classifiers improve their predictive accuracy, mobile applications
    such as speech recognition in smartphones (Deng et al., [2013](#bib.bib21); Hinton
    et al., [2012](#bib.bib46)), real-time unmanned navigation (Padhy et al., [2018](#bib.bib106))
    and drone-based surveillance (Singh et al., [2018](#bib.bib130); Zhang et al.,
    [2020](#bib.bib171)) are increasingly using DNN s to perform complex inference
    tasks. However, state-of-the-art DNN models present computational requirements
    that cannot be satisfied by the majority of the mobile devices available today.
    In fact, many state-of-the-art DNN models for difficult tasks – such as computer
    vision and natural language processing – are extremely complex. For instance,
    the EfficientDet (Tan et al., [2020](#bib.bib140)) family offers the best performance
    for object detection tasks. While EfficientDet-D7 achieves a mean average precision
    (mAP) of 52.2%, it involves 52M parameters and will take seconds to be executed
    on strong embedded devices equipped with GPUs such as the NVIDIA Jetson Nano and
    Raspberry Pi. Notably, the execution of such complex models significantly increases
    energy consumption. While lightweight models specifically designed for mobile
    devices exist (Tan et al., [2019](#bib.bib139); Sandler et al., [2018](#bib.bib123)),
    the reduced computational burden usually comes to the detriment of the model accuracy.
    For example, compared to ResNet-152 (He et al., [2016](#bib.bib44)), the networks
    MnasNet (Tan et al., [2019](#bib.bib139)) and MobileNetV2 (Sandler et al., [2018](#bib.bib123))
    present up to 6.4% accuracy loss on the ImageNet dataset. YOLO-Lite (Redmon and
    Farhadi, [2018](#bib.bib117)) achieves a frame rate of 22 frames per second on
    some embedded devices but has a mean average precision (mAP) of 12.36% on the
    COCO dataset (Lin et al., [2014b](#bib.bib84)). To achieve 33.8% mAP on the COCO
    dataset, even the simplest model in the EfficientDet family, EfficientDet-D0,
    requires 3 times more FLOPs (2.5B) ¹¹1In Tan et al. ([2020](#bib.bib140)), FLOP
    denotes number of multiply-adds. than SSD-MobileNetV2 (Sandler et al., [2018](#bib.bib123))
    (0.8B FLOPs). While SSD-MobileNetV2 is a lower-performance DNN specifically designed
    for mobile platforms and can process up to 6 fps, its mAP on COCO dataset is 20%
    and keeping the model running on a mobile device significantly increases power
    consumption. On the other hand, due to excessive end-to-end latency, cloud-based
    approaches are hardly applicable in most of the latency-constrained applications
    where mobile devices usually operate. Most of the techniques we overview in the
    survey can be applied to both mobile device to edge server and edge server to
    cloud offloading. For the sake of clarity, we primarily refer to the former to
    explain the frameworks.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 随着基于深度学习（DL）的分类器在预测准确性上的提升，移动应用程序如智能手机中的语音识别（Deng et al., [2013](#bib.bib21);
    Hinton et al., [2012](#bib.bib46)）、实时无人导航（Padhy et al., [2018](#bib.bib106)）和基于无人机的监视（Singh
    et al., [2018](#bib.bib130); Zhang et al., [2020](#bib.bib171)）越来越多地使用深度神经网络（DNN）来执行复杂的推理任务。然而，最先进的DNN模型存在计算要求，这些要求超出了目前大多数移动设备的能力。实际上，许多用于困难任务（如计算机视觉和自然语言处理）的最先进DNN模型非常复杂。例如，EfficientDet (Tan
    et al., [2020](#bib.bib140))系列在目标检测任务中提供了最佳性能。虽然EfficientDet-D7的平均精度（mAP）达到了52.2%，但它包含52M参数，并且在配备有GPU的强大嵌入式设备上执行需要几秒钟，如NVIDIA
    Jetson Nano和Raspberry Pi。值得注意的是，这些复杂模型的执行显著增加了能耗。尽管专门为移动设备设计的轻量级模型存在 (Tan et al.,
    [2019](#bib.bib139); Sandler et al., [2018](#bib.bib123))，但计算负担的减少通常会损害模型的准确性。例如，与ResNet-152 (He
    et al., [2016](#bib.bib44))相比，网络MnasNet (Tan et al., [2019](#bib.bib139))和MobileNetV2 (Sandler
    et al., [2018](#bib.bib123))在ImageNet数据集上的准确性损失高达6.4%。YOLO-Lite (Redmon and Farhadi,
    [2018](#bib.bib117))在某些嵌入式设备上实现了每秒22帧的帧率，但在COCO数据集上的mAP为12.36% (Lin et al., [2014b](#bib.bib84))。为了在COCO数据集上实现33.8%的mAP，即使是EfficientDet系列中最简单的模型EfficientDet-D0，也需要比SSD-MobileNetV2 (Sandler
    et al., [2018](#bib.bib123))（0.8B FLOPs）多3倍的FLOPs（2.5B）¹¹1在Tan et al. ([2020](#bib.bib140))中，FLOP表示乘加运算的次数。虽然SSD-MobileNetV2是一个专门为移动平台设计的低性能DNN，能处理高达6 fps的数据，但其在COCO数据集上的mAP为20%，且在移动设备上保持模型运行会显著增加功耗。另一方面，由于过高的端到端延迟，基于云的方案在大多数移动设备通常操作的延迟受限应用中很难应用。我们在调查中概述的大多数技术可以应用于从移动设备到边缘服务器以及从边缘服务器到云端的卸载。为清晰起见，我们主要参考前者来解释这些框架。
- en: Recently, edge computing (EC) approaches (Mao et al., [2017](#bib.bib89); Chen
    and Ran, [2019](#bib.bib11)) have attempted to address the “latency vs computation”
    conundrum by completely offloading the DNN execution to servers located very close
    to the mobile device, i.e., at the “edge” of the network. However, canonical EC
    does not consider that the quality of wireless links – although providing high
    throughput on the average – can suddenly fluctuate due to the presence of erratic
    noise and interference patterns, which may impair performance in latency-bound
    applications. For example, mobility and impaired propagation have been shown to
    decrease throughput even in high-bandwidth wireless links (Zhang et al., [2019](#bib.bib170);
    Mateo et al., [2019](#bib.bib90)) while many Internet of Things (IoT) systems
    are based on communication technologies such as Long Range (LoRa) (Samie et al.,
    [2016](#bib.bib122)), which has a maximum data rate of 37.5 Kbps due to duty cycle
    limitations (Adelantado et al., [2017](#bib.bib2)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，边缘计算（EC）方法（Mao et al., [2017](#bib.bib89); Chen 和 Ran, [2019](#bib.bib11)）试图通过将深度神经网络（DNN）执行完全卸载到靠近移动设备的服务器上，即网络的“边缘”，来解决“延迟与计算”的难题。然而，经典的边缘计算没有考虑到无线链路的质量——尽管平均提供了高吞吐量——由于存在不稳定的噪声和干扰模式，这可能会导致性能在延迟敏感的应用中受损。例如，移动性和传播受限已被证明会降低即使是在高带宽无线链路中的吞吐量（Zhang
    et al., [2019](#bib.bib170); Mateo et al., [2019](#bib.bib90)），而许多物联网（IoT）系统基于如长距离（LoRa）（Samie
    et al., [2016](#bib.bib122)）这样的通信技术，由于占空比限制（Adelantado et al., [2017](#bib.bib2)），其最大数据速率为37.5
    Kbps。
- en: The severe offloading limitations of some mobile devices, coupled with the instability
    of the wireless channel (*e.g.*, UAV network (Gupta et al., [2015](#bib.bib37))),
    imply that the amount of data offloaded to edge should be decreased, while at
    the same time keep the model accuracy as close as possible to the original. For
    this reason, split computing (SC) (Kang et al., [2017](#bib.bib61)) and early
    exiting (EE) strategies (Teerapittayanon et al., [2016](#bib.bib141)) have been
    proposed to provide an intermediate option between EC and local computing. The
    key intuition behind SC and EE is similar to the one behind model pruning (Han
    et al., [2016](#bib.bib39); Li et al., [2016](#bib.bib75); He et al., [2017b](#bib.bib45);
    Yang et al., [2017](#bib.bib161)) and knowledge distillation (Hinton et al., [2014](#bib.bib47);
    Kim and Rush, [2016](#bib.bib62); Mirzadeh et al., [2020](#bib.bib99)) – since
    modern DNN s are heavily over-parameterized (Yu et al., [2020](#bib.bib167); Yu
    and Principe, [2019](#bib.bib166)), their accuracy can be preserved even with
    substantial reduction in the number of weights and filters, and thus representing
    the input with fewer parameters. Specifically, SC divide a larger DNN into head
    and tail models, which are respectively executed by the mobile device and edge
    server. EE, on the other hand, proposes the introduction of “subbranches” into
    the early layers of DNN models, so that the full computation of the model can
    be halted – and a prediction result provided – if the classifiers in the current
    subbranches have high confidence with the specific model input.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 一些移动设备严重的卸载限制，加上无线信道的不稳定性（*例如*，无人机网络（Gupta et al., [2015](#bib.bib37)）），意味着卸载到边缘的数据量应当减少，同时尽可能保持模型的准确性。因此，提出了分割计算（SC）（Kang
    et al., [2017](#bib.bib61)）和早期退出（EE）策略（Teerapittayanon et al., [2016](#bib.bib141)），以提供边缘计算和本地计算之间的中间选项。SC和EE的关键直觉与模型剪枝（Han
    et al., [2016](#bib.bib39); Li et al., [2016](#bib.bib75); He et al., [2017b](#bib.bib45);
    Yang et al., [2017](#bib.bib161)）和知识蒸馏（Hinton et al., [2014](#bib.bib47); Kim
    和 Rush, [2016](#bib.bib62); Mirzadeh et al., [2020](#bib.bib99)）背后的直觉相似——由于现代DNN严重过度参数化（Yu
    et al., [2020](#bib.bib167); Yu 和 Principe, [2019](#bib.bib166)），即使在大幅减少权重和滤波器的数量后，其准确性仍可保持，从而用更少的参数表示输入。具体而言，SC将一个较大的DNN分成头部模型和尾部模型，分别由移动设备和边缘服务器执行。而EE则提议在DNN模型的早期层引入“子分支”，以便在当前子分支中的分类器对特定模型输入具有高置信度时，可以中止模型的完整计算并提供预测结果。
- en: 'Motivation and Novel Contributions. The proliferation of DL-based mobile applications
    in the IoT and 5G landscapes implies that techniques such as SC and EE are not
    simply “nice-to-have” features, but will become fundamental computational components
    in the years to come. Although a significant amount of research work has been
    done in SC and EE, to the best of our knowledge, a comprehensive survey of the
    state of the art has not been conducted yet. Moreover, there are still a series
    of research challenges that need to be addressed to take SC and EE to the next
    level. For this reason, this paper makes the following novel contributions:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 动机和创新贡献。在物联网和5G领域中，基于深度学习的移动应用的广泛应用意味着SC和EE等技术不仅仅是“好事”，而将成为未来几年中基本的计算组件。尽管在SC和EE方面已经进行了大量的研究工作，但据我们所知，尚未进行过关于现有技术水平的综合调查。此外，还有一系列研究挑战需要解决，以将SC和EE推向新的水平。因此，本文做出了以下创新贡献：
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We summarize SC and EE studies with respect to approaches, tasks, and models.
    We first provide an overview of local, edge, split computing, and early-exit models
    in Section [2](#S2 "2\. Overview of Local, Edge, Split Computing and Early-Exit
    Models ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges"), by highlighting similarities and difference among them;'
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在第[2](#S2 "2. 本地、边缘、分裂计算和提前退出模型的概述 ‣ 深度学习应用中的分裂计算和提前退出：调查与研究挑战")节对SC和EE的研究进行了总结，包括方法、任务和模型。我们首先对本地、边缘、分裂计算和提前退出模型进行了概述，突出了它们之间的相似性和差异；
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We then discuss and compare the various approaches to SC and EE in Sections
    [4](#S4 "4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for
    Deep Learning Applications: Survey and Research Challenges") and [5](#S5 "5\.
    Early Exiting: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges"), by highlighting the training strategies
    and applications. Since code availability is fundamental for replicability/reproducibility (Gundersen
    and Kjensmo, [2018](#bib.bib35))²²2To address this problem, major machine learning
    venues (*e.g.*, ICML, NeurIPS, CVPR, ECCV, NAACL, ACL, and EMNLP) adopt a reproducibility
    checklist as part of official review process such as ML Code Completeness Checklist.
    See [https://github.com/paperswithcode/releasing-research-code](https://github.com/paperswithcode/releasing-research-code).,
    we provide for each work its corresponding code repository, if available, so that
    interested readers can reproduce and learn from existing studies;'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 然后，我们在第[4](#S4 "4. 分裂计算：一项调查 ‣ 深度学习应用中的分裂计算和提前退出：调查与研究挑战")节和第[5](#S5 "5. 提前退出：一项调查
    ‣ 深度学习应用中的分裂计算和提前退出：调查与研究挑战")节讨论并比较了SC和EE的各种方法，重点介绍了训练策略和应用。由于代码的可用性对于可复制性/可重现性很重要（Gundersen和Kjensmo，[2018](#bib.bib35))²²2为了解决这个问题，主要的机器学习会议（如ICML，NeurIPS，CVPR，ECCV，NAACL，ACL和EMNLP）采用可重复性检查清单作为官方审核流程的一部分，如ML代码完整性清单。参见[https://github.com/paperswithcode/releasing-research-code](https://github.com/paperswithcode/releasing-research-code)。对于每个研究工作，如有可用，我们提供了相应的代码库，以便感兴趣的读者能够复制并学习现有的研究；
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'We conclude the paper by discussing in Section [6](#S6 "6\. Split Computing
    and Early Exiting: Research Challenges ‣ Split Computing and Early Exiting for
    Deep Learning Applications: Survey and Research Challenges") a compelling agenda
    of research challenges in SC and EE, hoping to spur further contributions in these
    exciting and timely fields.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们在第[6](#S6 "6. 分裂计算和提前退出：研究挑战 ‣ 深度学习应用中的分裂计算和提前退出：调查与研究挑战")节中讨论了SC和EE中的一些引人注目的研究挑战，希望能够激发对这些令人兴奋和时机成熟的领域的进一步贡献。
- en: 2\. Overview of Local, Edge, Split Computing and Early-Exit Models
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2. 本地、边缘、分裂计算和提前退出模型的概述
- en: 'In this section, we provide an overview of local, edge, split computing, and
    early-exit models, which are the main computational paradigms that will be discussed
    in the paper. Figure [1](#S2.F1 "Figure 1 ‣ 2\. Overview of Local, Edge, Split
    Computing and Early-Exit Models ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") provides a graphical overview of
    the approaches.'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们提供了关于本地、边缘、分裂计算和提前退出模型的一个概述，这些是本文将要讨论的主要计算范式。图[1](#S2.F1 "图1 ‣ 2. 本地、边缘、分裂计算和提前退出模型
    ‣ 深度学习应用中的分裂计算和提前退出：调查与研究挑战")提供了这些方法的图形概述。
- en: '![Refer to caption](img/fe710448876b88d93ce20c56ef09b93b.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见字幕](img/fe710448876b88d93ce20c56ef09b93b.png)'
- en: 'Figure 1\. Overview of (a) local, (b) edge, (c) split computing, and (d) early
    exiting: image classification as an example.'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 图1\. (a) 本地计算、(b) 边缘计算、(c) 拆分计算和 (d) 提前退出的概述：以图像分类为例。
- en: 'All these techniques operate on a DNN model $\mathcal{M}(\cdot)$ whose task
    is to produce the inference output $\mathbf{y}$ from an input $\mathbf{x}$. Typically,
    $\mathbf{x}$ is a high-dimensional variable, whereas the output $\mathbf{y}$ has
    significantly lower dimensionality (Tishby and Zaslavsky, [2015](#bib.bib144)).
    Split computing and early exit approaches are contextualized in a setting where
    the system is composed of a mobile device and an edge server interconnected via
    a wireless channel. The overall goal of the system is to produce the inference
    output $\mathbf{y}$ from the input $\mathbf{x}$ acquired by the mobile device,
    by means of the DNN $\mathbf{y}{=}\mathcal{M}(\mathbf{x})$ under – possibly time
    varying – constraints on:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 所有这些技术都在一个 DNN 模型 $\mathcal{M}(\cdot)$ 上运行，其任务是从输入 $\mathbf{x}$ 生成推断输出 $\mathbf{y}$。通常，$\mathbf{x}$
    是一个高维变量，而输出 $\mathbf{y}$ 的维度显著较低（Tishby 和 Zaslavsky，[2015](#bib.bib144)）。拆分计算和提前退出方法是在系统由一个移动设备和一个通过无线通道互连的边缘服务器组成的背景下进行的。系统的整体目标是通过
    DNN $\mathbf{y}{=}\mathcal{M}(\mathbf{x})$ 在 – 可能是时间变化的 – 约束条件下，从移动设备获取的输入 $\mathbf{x}$
    生成推断输出 $\mathbf{y}$。
- en: 'Resources: (*i*) the computational capacity (roughly expressed as number operations
    per second) $C_{\rm md}$ and $C_{\rm es}$ of the mobile device and edge server,
    respectively, (*ii*) the capacity $\phi$, in bits per second, of the wireless
    channel connecting the mobile device to the edge server;'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 资源：(*i*) 移动设备和边缘服务器的计算能力（大致表示为每秒操作次数）$C_{\rm md}$ 和 $C_{\rm es}$，(*ii*) 连接移动设备与边缘服务器的无线通道的容量
    $\phi$，以比特每秒为单位；
- en: 'Performance: (*i*) the absolute of average value of the time from the generation
    of $\mathbf{x}$ to the availability of $\mathbf{y}$, (*ii*) the degradation of
    the “quality” of the output $\mathbf{y}$.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 性能：(*i*) 从生成 $\mathbf{x}$ 到 $\mathbf{y}$ 可用的时间的平均值的绝对值，(*ii*) 输出 $\mathbf{y}$
    的“质量”降级。
- en: Split, edge, local, and early-exiting strategies strive to find suitable operating
    points with respect to accuracy, end-to-end delay, and energy consumption, which
    are inevitably influenced by the characteristics of the underlying system. It
    is generally assumed that the computing and energy capacities of the mobile device
    are smaller than that of the edge server. As a consequence, if part of the workload
    is allocated to the mobile device, then the execution time increases while battery
    lifetime decreases. However, as explained later, the workload executed by the
    mobile device may result in a reduced amount of data to be transferred over the
    wireless channel, possibly compensating for the larger execution time and leading
    to smaller end-to-end delays.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 拆分、边缘、本地和提前退出策略努力寻找适合的操作点，以平衡准确性、端到端延迟和能耗，这些因素不可避免地受到底层系统特性的影响。一般假设移动设备的计算和能量能力小于边缘服务器的能力。因此，如果将部分工作负载分配给移动设备，则执行时间增加，而电池寿命减少。然而，正如后面解释的，移动设备执行的工作负载可能会导致需要通过无线通道传输的数据量减少，可能会抵消更长的执行时间，从而导致较小的端到端延迟。
- en: 2.1\. Local and Edge Computing
  id: totrans-32
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1\. 本地计算与边缘计算
- en: 'We start with an overview of local and edge computing. In local computing (LC),
    the function $\mathcal{M}(\mathbf{x})$ is entirely executed by the mobile device.
    This approach eliminates the need to transfer data over the wireless channel.
    However, the complexity of the best performing DNN s most likely exceeds the computing
    capacity and energy consumption available at the mobile device. Usually, simpler
    models $\hat{\mathcal{M}}(\mathbf{x})$ are used, such as MobileNet (Sandler et al.,
    [2018](#bib.bib123)) and MnasNet (Tan et al., [2019](#bib.bib139)) which often
    have a degraded accuracy performance. Besides designing lightweight neural models
    executable on mobile devices, the widely used techniques to reduce the complexity
    of models are knowledge distillation (Hinton et al., [2014](#bib.bib47)) and model
    pruning/quantization (Jacob et al., [2018](#bib.bib56); Li et al., [2018a](#bib.bib74))
    – described in Section [3.2](#S3.SS2 "3.2\. Model Compression ‣ 3\. Background
    of Deep Learning for Mobile Applications ‣ Split Computing and Early Exiting for
    Deep Learning Applications: Survey and Research Challenges"). Some of the techniques
    are also leveraged in SC studies to introduce bottlenecks without sacrificing
    model accuracy as will be described in the following sections.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: '我们首先概述了本地计算和边缘计算。在本地计算（LC）中，函数`$\mathcal{M}(\mathbf{x})$`完全由移动设备执行。这种方法消除了通过无线信道传输数据的需求。然而，表现最佳的DNN的复杂度很可能超过了移动设备的计算能力和能量消耗。通常使用更简单的模型`$\hat{\mathcal{M}}(\mathbf{x})$`，例如
    MobileNet (Sandler et al., [2018](#bib.bib123)) 和 MnasNet (Tan et al., [2019](#bib.bib139))，这些模型通常会有较低的准确度性能。除了设计可在移动设备上执行的轻量级神经模型外，降低模型复杂度的广泛使用的技术还包括知识蒸馏
    (Hinton et al., [2014](#bib.bib47)) 和模型剪枝/量化 (Jacob et al., [2018](#bib.bib56);
    Li et al., [2018a](#bib.bib74)) – 详见第 [3.2](#S3.SS2 "3.2\. Model Compression ‣
    3\. Background of Deep Learning for Mobile Applications ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    节。一些技术在 SC 研究中也被利用，以引入瓶颈而不牺牲模型准确度，这将在接下来的章节中描述。'
- en: In EC, the input $\mathbf{x}$ is transferred to the edge server, which then
    executes the original model $\mathcal{M}(\mathbf{x})$. In this approach, which
    preserves full accuracy, the mobile device is not allocated computing workload,
    but the full input $\mathbf{x}$ needs to be transferred to the edge server. This
    may lead to an excessive end-to-end delay in degraded channel conditions and erasure
    of the task in extreme conditions. A possible approach to reduce the load imposed
    to the wireless channel, and thus also transmission delay and erasure probability,
    is to compress the input $\mathbf{x}$. We define, then, the encoder and decoder
    models $\mathbf{z}{=}F(\mathbf{x})$ and $\hat{\mathbf{x}}{=}G(\mathbf{z})$, which
    are executed at the mobile device and edge server, respectively. The distance
    $d(\mathbf{x},\hat{\mathbf{x}})$ defines the performance of the encoding-decoding
    process $\hat{\mathbf{x}}{=}G(F(\mathbf{x}))$, a metric which is separate, but
    may influence, the accuracy loss of $\mathcal{M}(\hat{\mathbf{x}})$ with respect
    to $\mathcal{M}(\mathbf{x})$, that is, of the model executed with the reconstructed
    input with respect to the model executed with the original input. Clearly, the
    encoding/decoding functions increase the computing load both at the mobile device
    and edge server side. A broad range of different compression approaches exists
    ranging from low-complexity traditional compression (*e.g.*, JPEG compression
    for images in EC (Nakahara et al., [2021](#bib.bib102))) to neural compression
    models (Ballé et al., [2017](#bib.bib5); Ballé et al., [2018](#bib.bib6); Yang
    et al., [2020a](#bib.bib163)). We remark that while the compressed input data
    *e.g.*, JPEG objects, can reduce the data transfer time in EC, those representations
    are designed to allow the accurate reconstruction of the input signal. Therefore,
    these approaches may (*i*) decrease privacy as a “reconstructable” representation
    is transferred to the edge server (Wang et al., [2020a](#bib.bib148)); (*ii*)
    result in larger amount of data to be transmitted over the channel compared to
    representation specifically designed for the computing task as in bottleneck-based
    SC as explained in the following sections.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 在 EC 中，输入 $\mathbf{x}$ 被传输到边缘服务器，该服务器执行原始模型 $\mathcal{M}(\mathbf{x})$。在这种方法中，尽管保持了完全的准确性，但移动设备不承担计算负载，但需要将完整的输入
    $\mathbf{x}$ 传输到边缘服务器。这可能导致在信道条件恶化时出现过长的端到端延迟，并在极端条件下导致任务丢失。为了减少对无线信道的负载，从而减少传输延迟和丢失概率，可以压缩输入
    $\mathbf{x}$。因此，我们定义了在移动设备和边缘服务器上分别执行的编码器和解码器模型 $\mathbf{z}{=}F(\mathbf{x})$ 和
    $\hat{\mathbf{x}}{=}G(\mathbf{z})$。距离 $d(\mathbf{x},\hat{\mathbf{x}})$ 定义了编码解码过程
    $\hat{\mathbf{x}}{=}G(F(\mathbf{x}))$ 的性能，这是一个独立的度量，但可能会影响 $\mathcal{M}(\hat{\mathbf{x}})$
    相对于 $\mathcal{M}(\mathbf{x})$ 的准确性损失，即，相对于使用原始输入执行的模型，使用重建输入执行的模型。显然，编码/解码函数会增加移动设备和边缘服务器端的计算负担。存在广泛的不同压缩方法，从低复杂度的传统压缩（*例如*，EC中的
    JPEG 图像压缩 (Nakahara et al., [2021](#bib.bib102))) 到神经压缩模型 (Ballé et al., [2017](#bib.bib5);
    Ballé et al., [2018](#bib.bib6); Yang et al., [2020a](#bib.bib163))。我们指出，尽管压缩输入数据
    *例如*，JPEG 对象，可以减少 EC 中的数据传输时间，但这些表示是为了准确重建输入信号而设计的。因此，这些方法可能 (*i*) 降低隐私，因为“可重建”的表示被传输到边缘服务器
    (Wang et al., [2020a](#bib.bib148)); (*ii*) 与专门为计算任务设计的表示相比，导致通过信道传输的数据量更大，如以下章节所述的瓶颈型
    SC。
- en: 2.2\. Split Computing and Early Exiting
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 分割计算与提前退出
- en: 'Split computing (SC) aims at achieving the following goals: (*i*) the computing
    load is distributed across the mobile device and edge server; and (*ii*) establishes
    a task-oriented compression to reduce data transfer delays. We consider a neural
    model $\mathcal{M}(\cdot)$ with $L$ layers, and define $\mathbf{z}_{\ell}$ the
    output of the $\ell$-th layer. Early implementations of SC select a layer $\ell$
    and divide the model $\mathcal{M}(\cdot)$ to define the head and tail submodels
    $\mathbf{z}_{\ell}{=}\mathcal{M}_{H}(\mathbf{x})$ and $\mathbf{\hat{y}}{=}\mathcal{M}_{T}(\mathbf{z}_{\ell})$,
    executed at the mobile device and edge server, respectively. In early instances
    of SC, the architecture and weights of the head and tail model are exactly the
    same as the first $\ell$ layers and last $L-\ell$ layers of $\mathcal{M}(\cdot)$.
    This simple approach preserves accuracy but allocates part of the execution of
    $\mathcal{M}(\cdot)$ to the mobile device, whose computing power is expected to
    be smaller than that of the edge server, so that the total execution time may
    be larger. The transmission time of $\mathbf{z}_{\ell}$ may be larger or smaller
    compared to that of transmitting the input $\mathbf{x}$, depending on the size
    of the tensor $\mathbf{z}_{\ell}$. However, we note that in most relevant applications
    the size of $\mathbf{z}_{\ell}$ becomes smaller than that of $\mathbf{x}$ only
    in later layers, which would allocate most of the computing load to the mobile
    device. More recent SC frameworks introduce the notion of *bottleneck* to achieve
    *in-model* compression toward the global task (Matsubara et al., [2019](#bib.bib91)).
    As formally described in the next section, a bottleneck is a compression point
    at one layer in the model, which can be realized by reducing the number of nodes
    of the target layer, and/or by quantizing its output. We note that as SC realizes
    a task-oriented compression, it guarantees a higher degree of privacy compared
    to EC. In fact, the representation may lack information needed to fully reconstruct
    the original input data.'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 分裂计算（SC）旨在实现以下目标：(*i*) 计算负载在移动设备和边缘服务器之间分配；(*ii*) 建立任务导向的压缩以减少数据传输延迟。我们考虑一个神经模型$\mathcal{M}(\cdot)$，具有$L$层，并定义$\mathbf{z}_{\ell}$为第$\ell$层的输出。SC的早期实现选择一个层$\ell$并将模型$\mathcal{M}(\cdot)$划分为头部和尾部子模型$\mathbf{z}_{\ell}{=}\mathcal{M}_{H}(\mathbf{x})$和$\mathbf{\hat{y}}{=}\mathcal{M}_{T}(\mathbf{z}_{\ell})$，分别在移动设备和边缘服务器上执行。在SC的早期实例中，头部和尾部模型的架构和权重与$\mathcal{M}(\cdot)$的前$\ell$层和最后$L-\ell$层完全相同。这种简单的方法保持了准确性，但将$\mathcal{M}(\cdot)$的一部分执行分配到移动设备上，而移动设备的计算能力预期会小于边缘服务器，因此总执行时间可能更长。$\mathbf{z}_{\ell}$的传输时间可能会大于或小于传输输入$\mathbf{x}$的时间，这取决于张量$\mathbf{z}_{\ell}$的大小。然而，我们注意到，在大多数相关应用中，$\mathbf{z}_{\ell}$的大小仅在后期层中小于$\mathbf{x}$的大小，这会将大部分计算负载分配给移动设备。最近的SC框架引入了*bottleneck*的概念，以实现*in-model*压缩以完成全局任务（Matsubara等，[2019](#bib.bib91)）。如下一节正式描述，瓶颈是模型中一个层的压缩点，可以通过减少目标层的节点数和/或对其输出进行量化来实现。我们注意到，由于SC实现了任务导向的压缩，相比EC，它保证了更高的隐私度。实际上，这种表示可能缺少完全重建原始输入数据所需的信息。
- en: Another approach to enable mobile computing is referred to early exiting (EE).
    The core idea is to create models with multiple “exits” across the model, where
    each exit can produce the model output. Then, the first exit providing a target
    confidence on the output is selected. This approach tunes the computational complexity,
    determined by the exit point, to the sample or to system conditions. Formally,
    we can define a sequence of models $\mathcal{M}_{i}$ and $\mathcal{B}_{i}$, $i{=}1,\ldots,N$.
    Model $\mathcal{M}_{i}$ takes as input $\mathbf{z}_{i-1}$ (the output of model
    $\mathcal{M}_{i-1}$) and outputs $\mathbf{z}_{i}$, where we set $\mathbf{z}_{0}{=}\mathbf{x}$.
    The branch models $\mathcal{B}_{i}$ take as input $\mathbf{z}_{i}$ and produce
    the estimate of the desired output $\mathbf{y}_{i}$. Thus, the concatenation of
    $\mathcal{M}_{1},\ldots,\mathcal{M}_{N}$ results into an output analogous to that
    of the original model. Intuitively, the larger the number of models used to produce
    the output $\mathbf{y}_{i}$, the better the accuracy. Thus, while SC optimizes
    intermediate representations to preserve information toward the final task (*e.g.*,
    classification) for the whole dataset, early exit models take a “per sample” control
    perspective. Each sample will be sequentially analyzed by concatenations of $\mathcal{M}_{i}$
    and $\mathcal{B}_{i}$ sections until a predefined confidence level is reached.
    The hope is that a portion of the samples will require a smaller number of sections
    compared to executing the whole sequence.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种使移动计算成为可能的方法是所谓的早期退出（EE）。其核心思想是创建具有多个“出口”的模型，每个出口都可以生成模型输出。然后，选择第一个提供目标置信度的出口。这种方法通过调整由退出点决定的计算复杂度，以适应样本或系统条件。正式地，我们可以定义一系列模型
    $\mathcal{M}_{i}$ 和 $\mathcal{B}_{i}$，$i{=}1,\ldots,N$。模型 $\mathcal{M}_{i}$ 以
    $\mathbf{z}_{i-1}$（模型 $\mathcal{M}_{i-1}$ 的输出）作为输入，并输出 $\mathbf{z}_{i}$，其中我们设定
    $\mathbf{z}_{0}{=}\mathbf{x}$。分支模型 $\mathcal{B}_{i}$ 以 $\mathbf{z}_{i}$ 作为输入，并生成期望输出
    $\mathbf{y}_{i}$ 的估计。因此，$\mathcal{M}_{1},\ldots,\mathcal{M}_{N}$ 的串联结果类似于原始模型的输出。直观地，生成输出
    $\mathbf{y}_{i}$ 所使用的模型数量越多，准确度越高。因此，虽然 SC 优化中间表示以保留信息以完成最终任务（*例如*，分类）的整个数据集，早期退出模型则采取“每个样本”控制的视角。每个样本将通过
    $\mathcal{M}_{i}$ 和 $\mathcal{B}_{i}$ 部分的串联依次进行分析，直到达到预定义的置信水平。希望的是，相较于执行整个序列，部分样本会需要较少的部分。
- en: 3\. Background of Deep Learning for Mobile Applications
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3. 深度学习在移动应用中的背景
- en: 'In this section, we provide an overview of recent approaches to reduce the
    computational complexity of DNN models for resource-constrained mobile devices.
    These approaches can be categorized into two main classes: (*i*) approaches that
    attempt to directly design lightweight models and (*ii*) model compression.'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们概述了最近减少深度神经网络（DNN）模型在资源受限的移动设备上计算复杂度的方法。这些方法可以分为两大类：(*i*) 直接设计轻量级模型的方法和
    (*ii*) 模型压缩。
- en: 3.1\. Lightweight Models
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1. 轻量级模型
- en: From a conceptual perspective, The design of small deep learning models is one
    of the simplest ways to reduce inference cost. However, there is a trade-off between
    model complexity and model accuracy, which makes this approach practically challenging
    when aiming at high model performance. The MobileNet series (Howard et al., [2017](#bib.bib49);
    Sandler et al., [2018](#bib.bib123); Howard et al., [2019](#bib.bib48)) is one
    among the most popular lightweight models for computer vision tasks, where Howard
    et al. ([2017](#bib.bib49)) describes the first version MobileNetV1. By using
    a pair of depth-wise and point-wise convolution layers in place of standard convolution
    layers, the design drastically reduces model size, and thus computing load. Following
    this study, Sandler et al. ([2018](#bib.bib123)) proposed MobileNetV2, which achieves
    an improved accuracy. The design is based on MobileNetV1 (Howard et al., [2017](#bib.bib49)),
    and uses the bottleneck residual block, a resource-efficient block with inverted
    residuals and linear bottlenecks. Howard et al. ([2019](#bib.bib48)) presents
    MobileNetV3, which further improves the model accuracy and is designed by a hardware-aware
    neural architecture search (Tan et al., [2019](#bib.bib139)) with NetAdapt (Yang
    et al., [2018](#bib.bib162)). The largest variant of MobileNetV3, MobileNetV3-Large
    1.0, achieves a comparable accuracy of ResNet-34 (He et al., [2016](#bib.bib44))
    for the ImageNet dataset, while reducing by about 75% the model parameters.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 从概念上看，小型深度学习模型的设计是降低推理成本的最简单方法之一。然而，模型复杂性与模型准确性之间存在权衡，这使得在追求高模型性能时，这种方法在实际应用中具有挑战性。MobileNet系列（Howard
    et al., [2017](#bib.bib49); Sandler et al., [2018](#bib.bib123); Howard et al.,
    [2019](#bib.bib48)）是计算机视觉任务中最受欢迎的轻量级模型之一，其中Howard et al.（[2017](#bib.bib49)）描述了第一版MobileNetV1。通过使用一对深度卷积层和点卷积层替代标准卷积层，该设计大幅度减少了模型大小，从而降低了计算负载。在这项研究之后，Sandler
    et al.（[2018](#bib.bib123)）提出了MobileNetV2，取得了更高的准确性。该设计基于MobileNetV1（Howard et
    al., [2017](#bib.bib49)），并使用了瓶颈残差块，这是一种资源高效的块，具有反向残差和线性瓶颈。Howard et al.（[2019](#bib.bib48)）提出了MobileNetV3，进一步提高了模型准确性，并通过硬件感知神经网络架构搜索（Tan
    et al., [2019](#bib.bib139)）与NetAdapt（Yang et al., [2018](#bib.bib162)）进行了设计。MobileNetV3的最大变体MobileNetV3-Large
    1.0，在ImageNet数据集上达到了与ResNet-34（He et al., [2016](#bib.bib44)）相当的准确性，同时将模型参数减少了约75%。
- en: 'While many of the lightweight neural networks are often manually designed,
    there are also studies on automating the neural architecture search (NAS) (Zoph
    and Le, [2017](#bib.bib174)). For instance, Zoph et al. ([2018](#bib.bib175))
    designs a novel search space through experiments with the CIFAR-10 dataset (Krizhevsky,
    [2009](#bib.bib64)), that is then scaled to larger, higher resolution image datasets
    such as the ImageNet dataset (Russakovsky et al., [2015](#bib.bib121)), to design
    their proposed model: NASNet. Leveraging the concept of NAS, some studies design
    lightweight models in a platform-aware fashion. Dong et al. ([2018](#bib.bib24))
    proposes the Device-aware Progressive Search for Pareto-optimal Neural Architectures
    (DDP-Net) framework, that optimizes the network design with respect to two objectives:
    device-related (*e.g.*, inference latency and memory usage) and device-agnostic
    (*e.g.*, accuracy and model size) objectives. Similarly, Tan et al. ([2019](#bib.bib139))
    propose an automated mobile neural architecture search (MNAS) method and design
    the MnasNet models by optimizing both model accuracy and inference time.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 虽然许多轻量级神经网络通常是手动设计的，但也有研究致力于自动化神经网络架构搜索（NAS）（Zoph and Le, [2017](#bib.bib174)）。例如，Zoph
    et al.（[2018](#bib.bib175)）通过对CIFAR-10数据集（Krizhevsky, [2009](#bib.bib64)）的实验设计了一个新的搜索空间，然后将其扩展到更大、更高分辨率的图像数据集，如ImageNet数据集（Russakovsky
    et al., [2015](#bib.bib121)），以设计其提出的模型：NASNet。利用NAS的概念，一些研究以平台感知的方式设计轻量级模型。Dong
    et al.（[2018](#bib.bib24)）提出了设备感知渐进搜索帕累托最优神经架构（DDP-Net）框架，它在两个目标下优化网络设计：与设备相关的（*例如*，推理延迟和内存使用）和设备无关的（*例如*，准确性和模型大小）目标。类似地，Tan
    et al.（[2019](#bib.bib139)）提出了一种自动化移动神经网络架构搜索（MNAS）方法，并通过优化模型准确性和推理时间设计了MnasNet模型。
- en: 3.2\. Model Compression
  id: totrans-43
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 模型压缩
- en: A different approach to produce small DNN models is to “compress” a large model.
    Model pruning and quantization (Han et al., [2015](#bib.bib40), [2016](#bib.bib39);
    Jacob et al., [2018](#bib.bib56); Li et al., [2020](#bib.bib80)) are the dominant
    model compression approaches. The former removes parameters from the model, while
    the latter uses fewer bits to represent them. In both these approaches, a large
    model is trained first and then compressed, rather than directly designing a lightweight
    model followed by training. In Jacob et al. ([2018](#bib.bib56)), the authors
    empirically show that their quantization technique leads to an improved tradeoff
    between inference time and accuracy on MobileNet (Howard et al., [2017](#bib.bib49))
    for image classification tasks on Qualcomm Snapdragon 835 and 821 compared to
    the original, float-only MobileNet. For what concerns model pruning, Li et al.
    ([2017](#bib.bib76)); Liu et al. ([2021](#bib.bib87)) demonstrates that it is
    difficult for model pruning itself to accelerate inference while achieving strong
    performance guarantees on general-purpose hardware due to the unstructured sparsity
    of the pruned model and/or kernels in layers.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 产生小型深度神经网络（DNN）模型的另一种方法是“压缩”大型模型。模型剪枝和量化（Han et al., [2015](#bib.bib40), [2016](#bib.bib39);
    Jacob et al., [2018](#bib.bib56); Li et al., [2020](#bib.bib80)）是主要的模型压缩方法。前者从模型中移除参数，而后者使用更少的位来表示这些参数。在这两种方法中，首先训练一个大型模型，然后进行压缩，而不是直接设计一个轻量模型然后进行训练。在
    Jacob et al. ([2018](#bib.bib56)) 中，作者实验证明，他们的量化技术在图像分类任务中，相比原始的仅浮点的 MobileNet，在
    Qualcomm Snapdragon 835 和 821 上提高了推理时间和准确度之间的权衡。至于模型剪枝，Li et al. ([2017](#bib.bib76));
    Liu et al. ([2021](#bib.bib87)) 表明，由于剪枝模型和/或层中的内核的无结构稀疏性，模型剪枝本身很难在通用硬件上加速推理，同时保证强大的性能。
- en: 'Knowledge distillation (Buciluǎ et al., [2006](#bib.bib9); Hinton et al., [2014](#bib.bib47))
    is another popular model compression method. While model pruning and quantization
    make trained models smaller, the concept of knowledge distillation is to provide
    outputs extracted from the trained model (called “teacher”) as informative signals
    to train smaller models (called “student”) in order to improve the accuracy of
    predesigned small models. Thus, the goal of the process is that of *distilling
    knowledge of a trained teacher model into a smaller student model* for boosting
    accuracy of the smaller model without increasing model complexity. For instance,
    Ba and Caruana ([2014](#bib.bib4)) proposes a method to train small neural networks
    by mimicking the detailed behavior of larger models. The experimental results
    show that models trained by this mimic learning method achieve performance close
    to that of deeper neural networks on some phoneme recognition and image recognition
    tasks. The formulation of some knowledge distillation methods will be described
    in Section [4.4](#S4.SS4 "4.4\. SC with Bottlenecks: Training Methodologies ‣
    4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges").'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '知识蒸馏（Buciluǎ et al., [2006](#bib.bib9); Hinton et al., [2014](#bib.bib47)）是另一种流行的模型压缩方法。虽然模型剪枝和量化使训练后的模型变小，但知识蒸馏的概念是提供从训练模型（称为“教师”）提取的输出作为信息信号，以训练更小的模型（称为“学生”），以提高预设计小型模型的准确性。因此，这个过程的目标是*将训练好的教师模型的知识蒸馏到更小的学生模型中*，以提升小型模型的准确性，而不增加模型复杂性。例如，Ba
    和 Caruana ([2014](#bib.bib4)) 提出了一种通过模仿大型模型的详细行为来训练小型神经网络的方法。实验结果表明，这种模仿学习方法训练的模型在一些音素识别和图像识别任务上达到的性能接近于更深层次的神经网络。某些知识蒸馏方法的具体描述将在第[4.4](#S4.SS4
    "4.4\. SC with Bottlenecks: Training Methodologies ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges")节中介绍。'
- en: '4\. Split Computing: A Survey'
  id: totrans-46
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 分布式计算：综述
- en: 'This section discusses existing state of of the art in SC. Figure [2](#S4.F2
    "Figure 2 ‣ 4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges") illustrates the existing SC approaches. They can be
    categorized into either (i) *without network modification* or (ii) *with bottleneck
    injection*. We first present SC approaches without DNN modification in Section
    [4.1](#S4.SS1 "4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges"). We then discuss the motivations behind the introduction
    of SC with bottlenecks in Section [4.2](#S4.SS2 "4.2\. The Need for Bottleneck
    Injection ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges"), which are then
    discussed in details in Section [4.3](#S4.SS3 "4.3\. Split Computing with Bottleneck
    Injection ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges"). Since the latter
    require specific training procedures, we devote Section [4.4](#S4.SS4 "4.4\. SC
    with Bottlenecks: Training Methodologies ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges") to their discussion.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: '本节讨论了拆分计算（SC）的现有前沿技术。图 [2](#S4.F2 "Figure 2 ‣ 4.1\. Split Computing without
    DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") 展示了现有的 SC 方法。这些方法可以分为
    (i) *无需网络修改* 或 (ii) *带瓶颈注入*。我们首先在第 [4.1](#S4.SS1 "4.1\. Split Computing without
    DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") 节中介绍无需 DNN 修改的
    SC 方法。然后我们在第 [4.2](#S4.SS2 "4.2\. The Need for Bottleneck Injection ‣ 4\. Split
    Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications:
    Survey and Research Challenges") 节中讨论引入瓶颈的 SC 方法的动机，这些方法在第 [4.3](#S4.SS3 "4.3\.
    Split Computing with Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges") 节中有详细讨论。由于后者需要特定的训练程序，我们在第 [4.4](#S4.SS4 "4.4\. SC with Bottlenecks:
    Training Methodologies ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early
    Exiting for Deep Learning Applications: Survey and Research Challenges") 节中专门讨论这些训练方法。'
- en: 4.1\. Split Computing without DNN Modification
  id: totrans-48
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 无需 DNN 修改的拆分计算
- en: In this class of approaches, the architecture and weights of the head $\mathcal{M}_{H}(\cdot)$
    and tail $\mathcal{M}_{T}(\cdot)$ models are exactly the same as the first $\ell$
    layers and last $L-\ell$ layers of $\mathcal{M}(\cdot)$. To the best of our knowledge, Kang
    et al. ([2017](#bib.bib61)) proposed the first SC approach (called “Neurosurgeon”),
    which searches for the best partitioning layer in a DNN model for minimizing total
    (end-to-end) latency or energy consumption. Formally, inference time in SC is
    the sum of processing time on mobile device, delay of communication between mobile
    device and edge server, and the processing time on edge server.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一类方法中，头部模型 $\mathcal{M}_{H}(\cdot)$ 和尾部模型 $\mathcal{M}_{T}(\cdot)$ 的架构和权重与
    $\mathcal{M}(\cdot)$ 的前 $\ell$ 层和后 $L-\ell$ 层完全相同。根据我们所知，Kang 等人 ([2017](#bib.bib61))
    提出了第一个 SC 方法（称为“Neurosurgeon”），该方法在 DNN 模型中搜索最佳的分区层，以最小化总（端到端）延迟或能量消耗。形式上，SC 的推理时间是移动设备上的处理时间、移动设备与边缘服务器之间通信的延迟以及边缘服务器上的处理时间之和。
- en: '![Refer to caption](img/f268c5d12a52363f0fe614ec74ea34e1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/f268c5d12a52363f0fe614ec74ea34e1.png)'
- en: Figure 2\. Two different SC approaches.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2\. 两种不同的 SC 方法。
- en: 'Interestingly, their experimental results show that the best partitioning (splitting)
    layers in terms of energy consumption and total latency for most of the considered
    models result in either their input or output layers. In other words, deploying
    the whole model on either a mobile device or an edge server (*i.e.,* local computing
    or EC) would be the best option for such DNN models. Following the work by Kang
    et al. ([2017](#bib.bib61)), the research communities explored various SC approaches
    mainly focused on CV tasks such as image classification. Table [1](#S4.T1 "Table
    1 ‣ 4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") summarizes the studies on SC without architectural modifications.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '有趣的是，他们的实验结果表明，大多数考虑中的模型在能耗和总延迟方面的最佳分割层（拆分层）要么是输入层，要么是输出层。换句话说，将整个模型部署在移动设备或边缘服务器上（*即，*本地计算或EC）将是这些DNN模型的最佳选择。继 Kang
    等 ([2017](#bib.bib61)) 的工作之后，研究社区探索了主要集中在计算机视觉任务（如图像分类）上的各种SC方法。表 [1](#S4.T1 "Table
    1 ‣ 4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") 总结了没有架构修改的SC研究。'
- en: Table 1\. Studies on SC without architectural modifications.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1\. 无架构修改的SC研究。
- en: '| Work | Task(s) | Dataset(s) | Model(s) | Metrics | Code |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 任务 | 数据集 | 模型 | 指标 | 代码 |'
- en: '|'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Kang et al. ([2017](#bib.bib61)) &#124;'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Kang 等 ([2017](#bib.bib61)) &#124;'
- en: '&#124; (2017) &#124;'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2017) &#124;'
- en: '| Image classification Speech recognition Part-of-speech tagging Named entity
    recognition Word chunking | N/A (No task-specific metrics) | AlexNet (Krizhevsky
    et al., [2012](#bib.bib65)) VGG-19 (Simonyan and Zisserman, [2015](#bib.bib129))
    DeepFace (Taigman et al., [2014](#bib.bib138)) LeNet-5 (LeCun et al., [1998](#bib.bib70))
    Kaldi (Povey et al., [2011](#bib.bib112)) SENNA (Collobert et al., [2011](#bib.bib18))
    | D, E, L |  |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 语音识别 词性标注 命名实体识别 词块划分 | 不适用（无任务特定指标） | AlexNet (Krizhevsky 等, [2012](#bib.bib65))
    VGG-19 (Simonyan 和 Zisserman, [2015](#bib.bib129)) DeepFace (Taigman 等, [2014](#bib.bib138))
    LeNet-5 (LeCun 等, [1998](#bib.bib70)) Kaldi (Povey 等, [2011](#bib.bib112)) SENNA (Collobert
    等, [2011](#bib.bib18)) | D, E, L |  |'
- en: '|'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Li et al. ([2018b](#bib.bib77)) &#124;'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Li 等 ([2018b](#bib.bib77)) &#124;'
- en: '&#124; (2018) &#124;'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2018) &#124;'
- en: '| Image classification | N/A (No task-specific metrics) | AlexNet (Krizhevsky
    et al., [2012](#bib.bib65)) | C, D |  |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | 不适用（无任务特定指标） | AlexNet (Krizhevsky 等, [2012](#bib.bib65)) | C, D |  |'
- en: '|'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Jeong et al. ([2018](#bib.bib59)) &#124;'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Jeong 等 ([2018](#bib.bib59)) &#124;'
- en: '&#124; (2018) &#124;'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2018) &#124;'
- en: '| Image classification | N/A (No task-specific metrics) | GoogLeNet (Szegedy
    et al., [2015](#bib.bib136)) AgeNet (Levi and Hassner, [2015](#bib.bib73)) GenderNet (Levi
    and Hassner, [2015](#bib.bib73)) | D, L |  |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | 不适用（无任务特定指标） | GoogLeNet (Szegedy 等, [2015](#bib.bib136)) AgeNet (Levi
    和 Hassner, [2015](#bib.bib73)) GenderNet (Levi 和 Hassner, [2015](#bib.bib73))
    | D, L |  |'
- en: '|'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Li et al. ([2018a](#bib.bib74)) &#124;'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Li 等 ([2018a](#bib.bib74)) &#124;'
- en: '&#124; (2018) &#124;'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2018) &#124;'
- en: '| Image classification | ImageNet (Russakovsky et al., [2015](#bib.bib121))
    | AlexNet (Krizhevsky et al., [2012](#bib.bib65)) VGG-16 (Simonyan and Zisserman,
    [2015](#bib.bib129)) ResNet-18 (He et al., [2016](#bib.bib44)) GoogLeNet (Szegedy
    et al., [2015](#bib.bib136)) | A, D, L |  |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | ImageNet (Russakovsky 等, [2015](#bib.bib121)) | AlexNet (Krizhevsky
    等, [2012](#bib.bib65)) VGG-16 (Simonyan 和 Zisserman, [2015](#bib.bib129)) ResNet-18 (He
    等, [2016](#bib.bib44)) GoogLeNet (Szegedy 等, [2015](#bib.bib136)) | A, D, L |  |'
- en: '|'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Choi and Bajić ([2018](#bib.bib14)) &#124;'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Choi 和 Bajić ([2018](#bib.bib14)) &#124;'
- en: '&#124; (2018) &#124;'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2018) &#124;'
- en: '| Object detection | VOC 2007 (Everingham et al., [[n.d.]](#bib.bib29)) | YOLO9000 (Redmon
    and Farhadi, [2017](#bib.bib116)) | A, C, D, L |  |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 | VOC 2007 (Everingham 等, [[n.d.]](#bib.bib29)) | YOLO9000 (Redmon 和
    Farhadi, [2017](#bib.bib116)) | A, C, D, L |  |'
- en: '|'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Eshratifar et al. ([2019a](#bib.bib26)) &#124;'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Eshratifar 等 ([2019a](#bib.bib26)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification Speech recognition | N/A (No task-specific metrics)
    | AlexNet (Krizhevsky et al., [2012](#bib.bib65)) OverFeat (Sermanet et al., [2014](#bib.bib126))
    NiN (Lin et al., [2014a](#bib.bib81)) VGG-16 (Simonyan and Zisserman, [2015](#bib.bib129))
    ResNet-50 (He et al., [2016](#bib.bib44)) | D, E, L |  |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 语音识别 | 不适用（无任务特定指标） | AlexNet (Krizhevsky 等, [2012](#bib.bib65)) OverFeat (Sermanet
    等, [2014](#bib.bib126)) NiN (Lin 等, [2014a](#bib.bib81)) VGG-16 (Simonyan 和 Zisserman,
    [2015](#bib.bib129)) ResNet-50 (He 等, [2016](#bib.bib44)) | D, E, L |  |'
- en: '|'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Zeng et al. ([2019](#bib.bib169)) &#124;'
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Zeng 等 ([2019](#bib.bib169)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | CIFAR-10 (Krizhevsky, [2009](#bib.bib64)) | AlexNet (Krizhevsky
    et al., [2012](#bib.bib65)) | A, D, L |  |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10 (Krizhevsky，[2009](#bib.bib64)) | AlexNet (Krizhevsky 等，[2012](#bib.bib65))
    | A, D, L |  |'
- en: '|'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Cohen et al. ([2020](#bib.bib17)) &#124;'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Cohen 等 ([2020](#bib.bib17)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification Object detection | ImageNet (2012) (Russakovsky et al.,
    [2015](#bib.bib121)) COCO 2017 (Lin et al., [2014b](#bib.bib84)) | VGG-16 (Simonyan
    and Zisserman, [2015](#bib.bib129)) ResNet-50 (He et al., [2016](#bib.bib44))
    YOLOv3 (Redmon and Farhadi, [2018](#bib.bib117)) | A, D |  |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 对象检测 | ImageNet (2012) (Russakovsky 等，[2015](#bib.bib121)) COCO 2017 (Lin
    等，[2014b](#bib.bib84)) | VGG-16 (Simonyan 和 Zisserman，[2015](#bib.bib129)) ResNet-50 (He
    等，[2016](#bib.bib44)) YOLOv3 (Redmon 和 Farhadi，[2018](#bib.bib117)) | A, D |  |'
- en: '|'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Pagliari et al. ([2020](#bib.bib107)) &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Pagliari 等 ([2020](#bib.bib107)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Natural language inference Reading comprehension Sentiment analysis | N/A
    (No task-specific metrics) | RNNs | E, L |  |'
  id: totrans-90
  prefs: []
  type: TYPE_TB
  zh: '| 自然语言推理 阅读理解 情感分析 | 不适用（无任务特定指标） | RNNs | E, L |  |'
- en: '|'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Itahara et al. ([2021](#bib.bib54)) &#124;'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Itahara 等 ([2021](#bib.bib54)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Image classification | CIFAR-10 (Krizhevsky, [2009](#bib.bib64)) | VGG-16 (Simonyan
    and Zisserman, [2015](#bib.bib129)) | A, D |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10 (Krizhevsky，[2009](#bib.bib64)) | VGG-16 (Simonyan 和 Zisserman，[2015](#bib.bib129))
    | A, D |  |'
- en: 'A: Model accuracy, C: Model complexity, D: Transferred data size, E: Energy
    consumption, L: Latency, T: Training cost'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 模型准确率, C: 模型复杂性, D: 传输数据大小, E: 能源消耗, L: 延迟, T: 训练成本'
- en: Jeong et al. ([2018](#bib.bib59)) used this partial offloading approach as a
    privacy-preserving way for computation offloading to blind the edge server to
    the original data captured by client. Leveraging neural network quantization techniques,
    Li et al. ([2018a](#bib.bib74)) discussed best splitting point in DNN models to
    minimize inference latency, and showed quantized DNN models did not degrade accuracy
    comparing to the (pre-quantized) original models. Choi and Bajić ([2018](#bib.bib14))
    proposed a feature compression strategy for object detection models that introduces
    a quantization/video-coding based compressor to the intermediate features in YOLO9000 (Redmon
    and Farhadi, [2017](#bib.bib116)).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: Jeong 等 ([2018](#bib.bib59)) 使用了这种部分卸载方法，作为一种隐私保护的计算卸载方式，以使边缘服务器无法看到客户端捕获的原始数据。利用神经网络量化技术，Li
    等 ([2018a](#bib.bib74)) 讨论了在 DNN 模型中最优的拆分点，以最小化推理延迟，并展示了量化的 DNN 模型在与（预量化）原始模型相比时没有降低准确性。Choi
    和 Bajić ([2018](#bib.bib14)) 提出了一个针对对象检测模型的特征压缩策略，该策略为 YOLO9000 (Redmon 和 Farhadi，[2017](#bib.bib116))
    中的中间特征引入了基于量化/视频编码的压缩器。
- en: Eshratifar et al. ([2019a](#bib.bib26)) propose JointDNN for collaborative computation
    between mobile device and cloud, and demonstrate that using either local computing
    only or cloud computing only is not an optimal solution in terms of inference
    time and energy consumption. Different from (Kang et al., [2017](#bib.bib61)),
    they consider not only discriminative deep learning models (*e.g.*, classifiers),
    but also generative deep learning models and autoencoders as benchmark models
    in their experimental evaluation. Cohen et al. ([2020](#bib.bib17)) introduce
    a technique to code the output of the head portion in a split DNN to a wide range
    of bit-rates, and demonstrate the performance for image classification and object
    detection tasks. Pagliari et al. ([2020](#bib.bib107)) first discuss the collaborative
    inference for simple recurrent neural networks, and their proposed scheme is designed
    to automatically select the best inference device for each input data in terms
    of total latency or end-device energy. Itahara et al. ([2021](#bib.bib54)) use
    dropout layers (Srivastava et al., [2014](#bib.bib134)) to emulate a packet loss
    scenario rather than for the sake of compression and discuss the robustness of
    VGG-based models (Simonyan and Zisserman, [2015](#bib.bib129)) for split computing.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: Eshratifar 等人 ([2019a](#bib.bib26)) 提出了 JointDNN 用于移动设备和云之间的协同计算，并证明仅使用本地计算或仅使用云计算在推理时间和能量消耗方面都不是最佳解决方案。不同于
    (Kang 等人, [2017](#bib.bib61))，他们在实验评估中不仅考虑了判别性深度学习模型 (*例如*，分类器)，还考虑了生成性深度学习模型和自编码器作为基准模型。Cohen
    等人 ([2020](#bib.bib17)) 介绍了一种技术，将分裂 DNN 的头部输出编码为广泛的比特率，并展示了图像分类和目标检测任务的性能。Pagliari
    等人 ([2020](#bib.bib107)) 首次讨论了简单递归神经网络的协同推理，他们提出的方案旨在自动选择每个输入数据的最佳推理设备，以优化总延迟或终端设备能量。Itahara
    等人 ([2021](#bib.bib54)) 使用 dropout 层 (Srivastava 等人, [2014](#bib.bib134)) 模拟数据包丢失场景，而非为了压缩，并讨论了基于
    VGG 的模型 (Simonyan 和 Zisserman, [2015](#bib.bib129)) 在分裂计算中的鲁棒性。
- en: 'While only a few studies in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing
    without DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    heuristically choose splitting points (Choi and Bajić, [2018](#bib.bib14); Cohen
    et al., [2020](#bib.bib17)), most of the other studies (Kang et al., [2017](#bib.bib61);
    Li et al., [2018b](#bib.bib77); Jeong et al., [2018](#bib.bib59); Li et al., [2018a](#bib.bib74);
    Eshratifar et al., [2019a](#bib.bib26); Zeng et al., [2019](#bib.bib169); Pagliari
    et al., [2020](#bib.bib107)) in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing
    without DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    analyze various types of cost (*e.g.*, computational load and energy consumption
    on mobile device, communication cost, and/or privacy risk) to partition DNN models
    at each of their splitting points. Based on the analysis, performance profiles
    of the split DNN models are derived to inform selection. Concerning metrics, many
    of the studies in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without DNN
    Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") do not discuss
    task-specific performance metrics such as accuracy. This is in part because the
    proposed approaches do not modify the input or intermediate representations in
    the models (*i.e.*, the final prediction will not change). On the other hand,
    Li et al. ([2018a](#bib.bib74)); Choi and Bajić ([2018](#bib.bib14)); Cohen et al.
    ([2020](#bib.bib17)) introduce lossy compression techniques to intermediate stages
    in DNN models, which may affect the final prediction results. Thus, discussing
    trade-off between compression rate and task-specific performance metrics would
    be essential for such studies. As shown in the table, such trade-off is discussed
    only for CV tasks, and many of the models considered in such studies have weak
    performance compared with state-of-the-art models and complexity within reach
    of modern mobile devices. Specific to image classification tasks, most of the
    models considered in the studies listed in Table [1](#S4.T1 "Table 1 ‣ 4.1\. Split
    Computing without DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    are more complex and/or the accuracy is comparable to or lower than that of lightweight
    baseline models such as MobileNetV2 (Sandler et al., [2018](#bib.bib123)) and
    MnasNet (Tan et al., [2019](#bib.bib139)). Thus, in future work, more accurate
    models should be considered to discuss the performance trade-off and further motivate
    SC approaches.'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管表格 [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without DNN Modification ‣
    4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") 中只有少数研究（Choi and Bajić, [2018](#bib.bib14);
    Cohen et al., [2020](#bib.bib17)）是从启发式角度选择了分割点，大部分其他研究 (Kang et al., [2017](#bib.bib61);
    Li et al., [2018b](#bib.bib77); Jeong et al., [2018](#bib.bib59); Li et al., [2018a](#bib.bib74);
    Eshratifar et al., [2019a](#bib.bib26); Zeng et al., [2019](#bib.bib169); Pagliari
    et al., [2020](#bib.bib107)) 在表格 [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without
    DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") 中分析了在拆分点处分割 DNN
    模型的各种成本（*例如*，移动设备的计算负载和能量消耗，通信成本和/或隐私风险）。基于这些分析，得出了拆分 DNN 模型的性能概况以供选择参考。在涉及度量标准的研究中，表格 [1](#S4.T1
    "Table 1 ‣ 4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges") 中许多研究并没有讨论诸如准确性之类的特定任务性能度量。部分原因是所提出的方法没有修改模型中的输入或中间表示（*即*，最终预测不会改变）。而
    Li et al. ([2018a](#bib.bib74)); Choi and Bajić ([2018](#bib.bib14)); Cohen et al.
    ([2020](#bib.bib17)) 则介绍了在 DNN 模型的中间阶段使用有损压缩技术，这可能会影响最终的预测结果。因此，讨论压缩率与任务特定性能度量之间的折衷是这类研究中很重要的。正如表格所示，这种折衷仅在
    CV 任务中进行了讨论，并且这类研究中考虑的许多模型与现代移动设备的复杂性相比性能较弱。针对图像分类任务，表格 [1](#S4.T1 "Table 1 ‣
    4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") 中列出的大多数研究考虑的模型更为复杂和/或准确性与轻量基准模型（如 MobileNetV2 (Sandler et al.,
    [2018](#bib.bib123)) 和 MnasNet (Tan et al., [2019](#bib.bib139))）相比可比或较低。因此，在未来的工作中，应该考虑更准确的模型来讨论性能折衷，并进一步推动
    SC 方法。'
- en: 4.2\. The Need for Bottleneck Injection
  id: totrans-99
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 注入瓶颈的必要性
- en: Table 2\. Statistics of image classification datasets in SC studies
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 2\. SC 研究中图像分类数据集的统计信息
- en: '|  | MNIST | CIFAR-10 | CIFAR-100 | ImageNet (2012) |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '|  | MNIST | CIFAR-10 | CIFAR-100 | ImageNet (2012) |'
- en: '| # labeled train/dev(test) samples: | 60k/10k | 50k/10k | 50k/10k | 1,281k/50k
    |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| # 标签训练/开发（测试）样本： | 60k/10k | 50k/10k | 50k/10k | 1,281k/50k |'
- en: '| # object categories | 10 | 10 | 100 | 1,000 |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| # 对象类别 | 10 | 10 | 100 | 1,000 |'
- en: '| Input tensor size | $1\times 32\times 32$ | $3\times 32\times 32$ | $3\times
    32\times 32$ | $3\times 224\times 224$* |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 输入张量大小 | $1\times 32\times 32$ | $3\times 32\times 32$ | $3\times 32\times
    32$ | $3\times 224\times 224$* |'
- en: '| JPEG data size [KB/sample] | 0.9657 | 1.790 | 1.793 | 44.77 |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| JPEG 数据大小 [KB/样本] | 0.9657 | 1.790 | 1.793 | 44.77 |'
- en: '* A standard (resized) input tensor size for DNN models.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '* DNN 模型的标准（调整后）输入张量大小。'
- en: 'While Kang et al. ([2017](#bib.bib61)) empirically show that executing the
    whole model on either mobile device or edge server would be best in terms of total
    inference and energy consumption for most of their considered DNN models, their
    proposed approach find the best partitioning layers inside some of their considered
    CV models (convolutional neural networks (CNNs)) to minimize the total inference
    time. There are a few trends observed from their experimental results: (i) communication
    delay to transfer data from mobile device to edge server is a key component in
    SC to reduce total inference time; (ii) all the neural models they considered
    for NLP tasks are relatively small (consisting of only a few layers), that potentially
    resulted in finding the output layer is the best partition point (*i.e.*, local
    computing) according to their proposed approach; (iii) similarly, not only DNN
    models they considered (except VGG (Simonyan and Zisserman, [2015](#bib.bib129)))
    but also the size of the input data to the models (See Table [2](#S4.T2 "Table
    2 ‣ 4.2\. The Need for Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣
    Split Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges")) are relatively small, which gives more advantage to EC (fully offloading
    computation). In other words, it highlights that complex CV tasks requiring large
    (high-resolution) images for models to achieve high accuracy such as ImageNet
    and COCO datasets would be essential to discuss the trade-off between accuracy
    and execution metrics to be minimized (*e.g.*, total latency, energy consumption)
    for SC studies. The key issue is that straightforward SC approaches like Kang
    et al. ([2017](#bib.bib61)) rely on the existence of *natural bottlenecks* – that
    is, intermediate layers whose output $\mathbf{z}_{\ell}$ tensor size is smaller
    than the input – inside the model. Without such natural bottlenecks in the model,
    straightforward splitting approaches would fail to improve performance in most
    settings (Barbera et al., [2013](#bib.bib7); Guo, [2018](#bib.bib36)).'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '虽然 Kang 等人 ([2017](#bib.bib61)) 实证表明，在大多数他们考虑的 DNN 模型中，整体模型在移动设备或边缘服务器上执行在总推理和能耗方面效果最佳，但他们提出的方法在某些
    CV 模型（卷积神经网络 (CNNs)）内部找到最佳的分割层，以最小化总推理时间。从他们的实验结果中观察到几个趋势：（i）从移动设备到边缘服务器的数据传输通信延迟是减少总推理时间的关键组成部分；（ii）他们考虑的所有用于
    NLP 任务的神经模型都相对较小（仅由几层组成），这可能导致找到输出层作为最佳分割点（*即*，本地计算）；（iii）类似地，他们考虑的 DNN 模型（除了
    VGG（Simonyan 和 Zisserman，[2015](#bib.bib129)））以及输入数据的大小（见表 [2](#S4.T2 "Table 2
    ‣ 4.2\. The Need for Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges")）都相对较小，这为 EC（完全卸载计算）带来了更多优势。换句话说，这突出显示了需要讨论复杂 CV 任务（如 ImageNet 和 COCO
    数据集）中模型使用大（高分辨率）图像以实现高精度的准确性和执行指标之间的权衡（*例如*，总延迟、能耗），以便为 SC 研究提供必要的信息。关键问题是，像 Kang
    等人（[2017](#bib.bib61)）这样的直接 SC 方法依赖于模型中存在的 *自然瓶颈* —— 即，中间层的输出 $\mathbf{z}_{\ell}$
    张量大小小于输入。如果模型中没有这种自然瓶颈，直接分割方法将在大多数设置中无法提高性能（Barbera 等人，[2013](#bib.bib7)；Guo，[2018](#bib.bib36)）。'
- en: Some models, such as AlexNet (Krizhevsky et al., [2012](#bib.bib65)), VGG (Simonyan
    and Zisserman, [2015](#bib.bib129)) and DenseNet (Huang et al., [2017](#bib.bib52)),
    possess such layers (Matsubara et al., [2019](#bib.bib91)). However, recent DNN
    models such as ResNet (He et al., [2016](#bib.bib44)), Inception-v3 (Szegedy et al.,
    [2016](#bib.bib137)), Faster R-CNN (Ren et al., [2015](#bib.bib118)) and Mask
    R-CNN (He et al., [2017a](#bib.bib43)) do not have natural bottlenecks in the
    early layers, that is, splitting the model would result in compression only when
    assigning a large portion of the workload to the mobile device. As discussed earlier,
    reducing the communication delay is a key to minimize total inference time in
    SC. For these reasons, introducing *artificial bottlenecks* to DNN models by modifying
    their architecture is a recent trend and has been attracting attention from the
    research community. Since the main role of such encoders in SC is to compress
    intermediate features rather than to complete inference, the encoders usually
    consist of only a few layers. Also, the resulting encoders in SC to be executed
    on constrained mobile devices are often much smaller (*e.g.,* 10K parameters in
    the encoder of ResNet-based SC model (Matsubara and Levorato, [2021](#bib.bib95))),
    than lightweight models such as MobileNetV2 (Sandler et al., [2018](#bib.bib123))
    (3.5M parameters) and MnasNet (Tan et al., [2019](#bib.bib139)) (4.4M parameters).
    Thus, even if the model accuracy is either degraded or comparable to such small
    models, SC models are still beneficial in terms of computational burden and energy
    consumption at the mobile devices.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 一些模型，如AlexNet (Krizhevsky et al., [2012](#bib.bib65))、VGG (Simonyan and Zisserman,
    [2015](#bib.bib129))和DenseNet (Huang et al., [2017](#bib.bib52))，拥有这样的层 (Matsubara
    et al., [2019](#bib.bib91))。然而，最近的DNN模型如ResNet (He et al., [2016](#bib.bib44))、Inception-v3 (Szegedy
    et al., [2016](#bib.bib137))、Faster R-CNN (Ren et al., [2015](#bib.bib118))和Mask
    R-CNN (He et al., [2017a](#bib.bib43))在早期层中没有自然的瓶颈，即将模型拆分仅会在将大量工作负载分配给移动设备时导致压缩。如前所述，减少通信延迟是最小化SC总推理时间的关键。因此，通过修改架构向DNN模型引入*人工瓶颈*是一种新兴趋势，并且引起了研究界的关注。由于这些编码器在SC中的主要作用是压缩中间特征而不是完成推理，因此编码器通常只包含少数几层。此外，用于在受限的移动设备上执行的SC编码器通常比轻量级模型（如MobileNetV2 (Sandler
    et al., [2018](#bib.bib123))（3.5M参数）和MnasNet (Tan et al., [2019](#bib.bib139))（4.4M参数））要小得多（*例如*，ResNet基础SC模型中的编码器（Matsubara
    and Levorato, [2021](#bib.bib95)）有10K参数）。因此，即使模型准确性较低或与这些小模型相当，SC模型在移动设备上的计算负担和能量消耗方面仍然具有优势。
- en: 4.3\. Split Computing with Bottleneck Injection
  id: totrans-109
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 带瓶颈注入的分布式计算
- en: 'This class of models can be described as composed of $3$ sections: $\mathcal{M}_{E}$,
    $\mathcal{M}_{D}$ and $\mathcal{M}_{T}$. We define $\mathbf{z}_{\ell}|\mathbf{x}$
    as the output of the $\ell$-th layer of the original model given the input $\mathbf{x}$.
    The concatenation of the $\mathcal{M}_{E}$ and $\mathcal{M}_{D}$ models is designed
    to produce a possibly noisy version $\hat{\mathbf{z}}_{\ell}|\mathbf{x}$ of $\mathbf{z}_{\ell}|\mathbf{x}$,
    which is taken as input by $\mathcal{M}_{T}$ to produce the output $\hat{\mathbf{y}}$,
    on which the accuracy degradation with respect to $\mathbf{y}$ is measured. The
    models $\mathcal{M}_{E}$, $\mathcal{M}_{D}$ function as specialized encoders and
    decoders in the form $\hat{\mathbf{z}}_{\ell}{=}\mathcal{M}_{D}(\mathcal{M}_{E}(\mathbf{x}))$,
    where $\mathcal{M}_{E}(\mathbf{x})$ produces the latent variable $\mathbf{z}$.
    In worlds, the two first sections of the modified model transform the input $\mathbf{x}$
    into a version of the output of the $\ell$-th layer via the intermediate representation
    $\mathbf{z}$, thus functioning as encoder/decoder functions. The model is split
    after the first section, that is, $\mathcal{M}_{E}$ is the head model, and the
    concatenation of $\mathcal{M}_{D}$ and $\mathcal{M}_{T}$ is the tail model. Then,
    the tensor $\mathbf{z}$ is transmitted over the channel. The objective of the
    architecture is to minimize the size of $\mathbf{z}$ to reduce the communication
    time while also minimizing the complexity of $\mathcal{M}_{E}$ (that is, the part
    of the model executed at the – weaker – mobile device) and the discrepancy between
    $\mathbf{y}$ and $\hat{\mathbf{y}}$. The layer between $\mathcal{M}_{E}$ and $\mathcal{M}_{D}$
    is the injected bottleneck.'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这一类模型可以描述为由 $3$ 个部分组成：$\mathcal{M}_{E}$、$\mathcal{M}_{D}$ 和 $\mathcal{M}_{T}$。我们定义
    $\mathbf{z}_{\ell}|\mathbf{x}$ 为给定输入 $\mathbf{x}$ 时原始模型第 $\ell$ 层的输出。$\mathcal{M}_{E}$
    和 $\mathcal{M}_{D}$ 模型的连接旨在生成可能带噪声的版本 $\hat{\mathbf{z}}_{\ell}|\mathbf{x}$，该版本
    $\hat{\mathbf{z}}_{\ell}|\mathbf{x}$ 被 $\mathcal{M}_{T}$ 作为输入以产生输出 $\hat{\mathbf{y}}$，并且衡量相对于
    $\mathbf{y}$ 的准确性降级。模型 $\mathcal{M}_{E}$ 和 $\mathcal{M}_{D}$ 作为专门的编码器和解码器，形式为
    $\hat{\mathbf{z}}_{\ell}{=}\mathcal{M}_{D}(\mathcal{M}_{E}(\mathbf{x}))$，其中 $\mathcal{M}_{E}(\mathbf{x})$
    生成潜变量 $\mathbf{z}$。换句话说，修改后的模型的前两个部分通过中间表示 $\mathbf{z}$ 将输入 $\mathbf{x}$ 转换为第
    $\ell$ 层的输出版本，从而充当编码器/解码器功能。模型在第一个部分后被拆分，即 $\mathcal{M}_{E}$ 是头部模型，而 $\mathcal{M}_{D}$
    和 $\mathcal{M}_{T}$ 的连接是尾部模型。然后，张量 $\mathbf{z}$ 被通过通道传输。该架构的目标是最小化 $\mathbf{z}$
    的大小，以减少通信时间，同时也最小化 $\mathcal{M}_{E}$ 的复杂性（即，在较弱的移动设备上执行的模型部分）以及 $\mathbf{y}$ 和
    $\hat{\mathbf{y}}$ 之间的差异。$\mathcal{M}_{E}$ 和 $\mathcal{M}_{D}$ 之间的层是注入的瓶颈。
- en: 'Table [3](#S4.T3 "Table 3 ‣ 4.3\. Split Computing with Bottleneck Injection
    ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") summarizes SC studies with bottleneck
    injected strategies. To the best of our knowledge, the papers in (Eshratifar et al.,
    [2019b](#bib.bib27)) and (Matsubara et al., [2019](#bib.bib91)) were the first
    to propose altering existing DNN architectures to design relatively small bottlenecks
    at early layers in DNN models, instead of introducing compression techniques (*e.g.*,
    quantization, autoencoder) to the models, so that communication delay (cost) and
    total inference time can be further reduced. Following these studies, Hu and Krishnamachari
    ([2020](#bib.bib50)) introduce bottlenecks to MobileNetV2 (Sandler et al., [2018](#bib.bib123))
    (modified for CIFAR datasets) in a similar way for SC, and discuss end-to-end
    performance evaluation. Choi et al. ([2020](#bib.bib15)) combine multiple compression
    techniques such as quantization and tiling besides convolution/deconvolution layers,
    and design a feature compression approach for object detectors. Similar to the
    concept of bottleneck injection, Shao and Zhang ([2020](#bib.bib127)) find that
    over-compression of intermediate features and inaccurate communication between
    computing devices can be tolerated unless the prediction performance of the models
    are significantly degraded by them. Also, Jankowski et al. ([2020](#bib.bib58))
    propose introducing a reconstruction-based bottleneck to DNN models, which is
    similar to the concept of BottleNet (Eshratifar et al., [2019b](#bib.bib27)).
    A comprehensive discussion on the delay/complexity/accuracy tradeoff can be found
    in (Yao et al., [2020](#bib.bib165); Matsubara et al., [2020a](#bib.bib92)).'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 表 [3](#S4.T3 "表 3 ‣ 4.3\. 使用瓶颈注入的分布式计算 ‣ 4\. 分布式计算：综述 ‣ 深度学习应用中的分布式计算和提前退出：综述与研究挑战")
    总结了使用瓶颈注入策略的 SC 研究。根据我们所知，（Eshratifar 等，[2019b](#bib.bib27)）和（Matsubara 等，[2019](#bib.bib91)）的论文首次提出了通过在
    DNN 模型的早期层设计相对较小的瓶颈来改变现有的 DNN 架构，而不是在模型中引入压缩技术（*例如*，量化、自编码器），从而进一步减少通信延迟（成本）和总推理时间。继这些研究之后，Hu
    和 Krishnamachari ([2020](#bib.bib50)) 在类似的 SC 方式中引入了瓶颈到 MobileNetV2 (Sandler 等，[2018](#bib.bib123))（针对
    CIFAR 数据集进行修改），并讨论了端到端性能评估。Choi 等 ([2020](#bib.bib15)) 在卷积/反卷积层之外结合了多种压缩技术，如量化和切片，并为物体检测器设计了一种特征压缩方法。与瓶颈注入的概念类似，Shao
    和 Zhang ([2020](#bib.bib127)) 发现，除非模型的预测性能因过度压缩中间特征和计算设备间不准确的通信而显著下降，否则这些情况是可以容忍的。此外，Jankowski
    等 ([2020](#bib.bib58)) 提出了将基于重建的瓶颈引入 DNN 模型的方案，这类似于 BottleNet (Eshratifar 等，[2019b](#bib.bib27))
    的概念。关于延迟/复杂性/准确性权衡的全面讨论可以在 (Yao 等，[2020](#bib.bib165); Matsubara 等，[2020a](#bib.bib92))
    中找到。
- en: Table 3\. Studies on SC with bottleneck injection strategies.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3\. 关于使用瓶颈注入策略的 SC 研究。
- en: '| Work | Task(s) | Dataset(s) | Base Model(s) | Training | Metrics | Code |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 任务 | 数据集 | 基础模型 | 训练 | 指标 | 代码 |'
- en: '|'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Eshratifar et al. ([2019b](#bib.bib27)) &#124;'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Eshratifar 等 ([2019b](#bib.bib27)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | miniImageNet (Snell et al., [2017](#bib.bib131)) |
    ResNet-50 (He et al., [2016](#bib.bib44)) VGG-16 (Simonyan and Zisserman, [2015](#bib.bib129))
    | CE-based | A, D, L |  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | miniImageNet (Snell 等，[2017](#bib.bib131)) | ResNet-50 (He 等，[2016](#bib.bib44))
    VGG-16 (Simonyan 和 Zisserman，[2015](#bib.bib129)) | CE-based | A, D, L |  |'
- en: '|'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Matsubara et al. (Matsubara et al., [2019](#bib.bib91), [2020a](#bib.bib92))
    &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Matsubara 等 (Matsubara 等，[2019](#bib.bib91)，[2020a](#bib.bib92)) &#124;'
- en: '&#124; (2019, 2020) &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019, 2020) &#124;'
- en: '| Image classification | Caltech 101 (Fei-Fei et al., [2006](#bib.bib30)) ImageNet
    (2012) (Russakovsky et al., [2015](#bib.bib121)) | DenseNet-169 (Huang et al.,
    [2017](#bib.bib52)) DenseNet-201 (Huang et al., [2017](#bib.bib52)) ResNet-152 (He
    et al., [2016](#bib.bib44)) Inception-v3 (Szegedy et al., [2016](#bib.bib137))
    | HND KD CE-based | A, C, D, L, T | [Link](https://github.com/yoshitomo-matsubara/head-network-distillation)
    |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | Caltech 101 (Fei-Fei 等，[2006](#bib.bib30)) ImageNet (2012) (Russakovsky
    等，[2015](#bib.bib121)) | DenseNet-169 (Huang 等，[2017](#bib.bib52)) DenseNet-201 (Huang
    等，[2017](#bib.bib52)) ResNet-152 (He 等，[2016](#bib.bib44)) Inception-v3 (Szegedy
    等，[2016](#bib.bib137)) | HND KD CE-based | A, C, D, L, T | [链接](https://github.com/yoshitomo-matsubara/head-network-distillation)
    |'
- en: '|'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Hu and Krishnamachari ([2020](#bib.bib50)) &#124;'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Hu 和 Krishnamachari ([2020](#bib.bib50)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | MobileNetV2 (Sandler
    et al., [2018](#bib.bib123)) | CE-based | A, D, L |  |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | MobileNetV2 (Sandler
    et al., [2018](#bib.bib123)) | 基于CE | A, D, L |  |'
- en: '|'
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Choi et al. ([2020](#bib.bib15)) &#124;'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Choi et al. ([2020](#bib.bib15)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Object detection | COCO 2014 (Lin et al., [2014b](#bib.bib84)) | YOLOv3 (Redmon
    and Farhadi, [2018](#bib.bib117)) | Reconstruct. | A, D |  |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 | COCO 2014 (Lin et al., [2014b](#bib.bib84)) | YOLOv3 (Redmon and Farhadi,
    [2018](#bib.bib117)) | 重构 | A, D |  |'
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Shao and Zhang ([2020](#bib.bib127)) &#124;'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Shao and Zhang ([2020](#bib.bib127)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) | ResNet-50 (He
    et al., [2016](#bib.bib44)) VGG-16 (Simonyan and Zisserman, [2015](#bib.bib129))
    | CE-based (Multi-stage) | A, C, D |  |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) | ResNet-50 (He et al.,
    [2016](#bib.bib44)) VGG-16 (Simonyan and Zisserman, [2015](#bib.bib129)) | 基于CE
    (多阶段) | A, C, D |  |'
- en: '|'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Jankowski et al. ([2020](#bib.bib58)) &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Jankowski et al. ([2020](#bib.bib58)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) | VGG-16 (Simonyan
    and Zisserman, [2015](#bib.bib129)) | CE + $\mathcal{L}_{2}$ (Multi-stage) | A,
    C, D |  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) | VGG-16 (Simonyan and
    Zisserman, [2015](#bib.bib129)) | CE + $\mathcal{L}_{2}$ (多阶段) | A, C, D |  |'
- en: '|'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Matsubara et al. (Matsubara and Levorato, [2020](#bib.bib94), [2021](#bib.bib95))
    &#124;'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Matsubara et al. (Matsubara and Levorato, [2020](#bib.bib94), [2021](#bib.bib95))
    &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Object detection Keypoint detection | COCO 2017 (Lin et al., [2014b](#bib.bib84))
    | Faster R-CNN (Ren et al., [2015](#bib.bib118)) Mask R-CNN (He et al., [2017a](#bib.bib43))
    Keypoint R-CNN (He et al., [2017a](#bib.bib43)) | HND GHND | A, C, D, L | [Link](https://github.com/yoshitomo-matsubara/hnd-ghnd-object-detectors)
    |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 关键点检测 | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | Faster R-CNN (Ren
    et al., [2015](#bib.bib118)) Mask R-CNN (He et al., [2017a](#bib.bib43)) Keypoint
    R-CNN (He et al., [2017a](#bib.bib43)) | HND GHND | A, C, D, L | [链接](https://github.com/yoshitomo-matsubara/hnd-ghnd-object-detectors)
    |'
- en: '|'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Yao et al. ([2020](#bib.bib165)) &#124;'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Yao et al. ([2020](#bib.bib165)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification Speech recognition | ImageNet (2012) (Russakovsky et al.,
    [2015](#bib.bib121)) LibriSpeech (Panayotov et al., [2015](#bib.bib108)) | ResNet-50 (He
    et al., [2016](#bib.bib44)) Deep Speech (Hannun et al., [2014](#bib.bib41)) |
    Reconstruct. + KD | A, D, E, L, T | [Link](https://github.com/CPS-AI/Deep-Compressive-Offloading)*
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 语音识别 | ImageNet (2012) (Russakovsky et al., [2015](#bib.bib121)) LibriSpeech (Panayotov
    et al., [2015](#bib.bib108)) | ResNet-50 (He et al., [2016](#bib.bib44)) Deep
    Speech (Hannun et al., [2014](#bib.bib41)) | 重构 + KD | A, D, E, L, T | [链接](https://github.com/CPS-AI/Deep-Compressive-Offloading)*
    |'
- en: '|'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Assine et al. ([2021](#bib.bib3)) &#124;'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Assine et al. ([2021](#bib.bib3)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Object detection | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | EfficientDet (Tan
    et al., [2020](#bib.bib140)) | GHND-based | A, C, D | [Link](https://github.com/jsiloto/adaptive-cod)
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | EfficientDet (Tan et al.,
    [2020](#bib.bib140)) | 基于GHND | A, C, D | [链接](https://github.com/jsiloto/adaptive-cod)
    |'
- en: '|'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Sbai et al. ([2021](#bib.bib125)) &#124;'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Sbai et al. ([2021](#bib.bib125)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Image classification | Subset of ImageNet (Russakovsky et al., [2015](#bib.bib121))
    (700 out of 1,000 classes) | MobileNetV1 (Howard et al., [2017](#bib.bib49)) VGG-16 (Simonyan
    and Zisserman, [2015](#bib.bib129)) | Reconstruct. + KD | A, C, D |  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | ImageNet的子集 (Russakovsky et al., [2015](#bib.bib121)) (从1,000个类别中选取700个)
    | MobileNetV1 (Howard et al., [2017](#bib.bib49)) VGG-16 (Simonyan and Zisserman,
    [2015](#bib.bib129)) | 重构 + KD | A, C, D |  |'
- en: '|'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Lee et al. ([2021](#bib.bib71)) &#124;'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Lee et al. ([2021](#bib.bib71)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Object detection | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | YOLOv5 (Ultralytics,
    [[n.d.]](#bib.bib145)) | CE-based | A, C, D, L |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 目标检测 | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | YOLOv5 (Ultralytics,
    [[n.d.]](#bib.bib145)) | 基于CE | A, C, D, L |  |'
- en: '|'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Matsubara et al. ([2022a](#bib.bib93)) &#124;'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Matsubara et al. ([2022a](#bib.bib93)) &#124;'
- en: '&#124; (2022) &#124;'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2022) &#124;'
- en: '| Image Classification | ImageNet (2012) (Russakovsky et al., [2015](#bib.bib121))
    | DenseNet-169 (Huang et al., [2017](#bib.bib52)) DenseNet-201 (Huang et al.,
    [2017](#bib.bib52)) ResNet-152 (He et al., [2016](#bib.bib44)) | Reconst. HND
    GHND CE/KD (Multi-stage) | A, C, D, E  L | [Link](https://github.com/yoshitomo-matsubara/bottlefit-split_computing)
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | ImageNet (2012) (Russakovsky et al., [2015](#bib.bib121)) | DenseNet-169 (Huang
    et al., [2017](#bib.bib52)) DenseNet-201 (Huang et al., [2017](#bib.bib52)) ResNet-152 (He
    et al., [2016](#bib.bib44)) | 重构 HND GHND CE/KD (多阶段) | A, C, D, E  L | [链接](https://github.com/yoshitomo-matsubara/bottlefit-split_computing)
    |'
- en: '|'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Matsubara et al. (Matsubara et al., [2022c](#bib.bib98), [b](#bib.bib97))
    &#124;'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Matsubara 等 (Matsubara 等，[2022c](#bib.bib98), [b](#bib.bib97)) &#124;'
- en: '&#124; (2021, 2022) &#124;'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021, 2022) &#124;'
- en: '| Image Classification Object detection Semantic Segmentation | ImageNet (2012) (Russakovsky
    et al., [2015](#bib.bib121)) COCO 2017 (Lin et al., [2014b](#bib.bib84)) PASCAL
    VOC (2012) (Everingham et al., [2012](#bib.bib28)) | ResNet-50 (He et al., [2016](#bib.bib44))
    ResNet-101 (He et al., [2016](#bib.bib44)) RegNetY-6.4GF (Radosavovic et al.,
    [2020](#bib.bib114)) Hybrid ViT (Steiner et al., [2021](#bib.bib135)) RetinaNet (Lin
    et al., [2017b](#bib.bib83)) Faster R-CNN (Ren et al., [2015](#bib.bib118)) DeepLabv3 (Chen
    et al., [2017](#bib.bib12)) | GHND CE/KD+Rate (Multi-stage) | A, C, D, L | [Link
    (2021)](https://github.com/yoshitomo-matsubara/supervised-compression) [Link (2022)](https://github.com/yoshitomo-matsubara/sc2-benchmark)
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 目标检测 语义分割 | ImageNet (2012) (Russakovsky 等，[2015](#bib.bib121)) COCO
    2017 (Lin 等，[2014b](#bib.bib84)) PASCAL VOC (2012) (Everingham 等，[2012](#bib.bib28))
    | ResNet-50 (He 等，[2016](#bib.bib44)) ResNet-101 (He 等，[2016](#bib.bib44)) RegNetY-6.4GF
    (Radosavovic 等，[2020](#bib.bib114)) Hybrid ViT (Steiner 等，[2021](#bib.bib135))
    RetinaNet (Lin 等，[2017b](#bib.bib83)) Faster R-CNN (Ren 等，[2015](#bib.bib118))
    DeepLabv3 (Chen 等，[2017](#bib.bib12)) | GHND CE/KD+Rate (多阶段) | A, C, D, L | [链接
    (2021)](https://github.com/yoshitomo-matsubara/supervised-compression) [链接 (2022)](https://github.com/yoshitomo-matsubara/sc2-benchmark)
    |'
- en: 'A: Model accuracy, C: Model complexity, D: Transferred data size, E: Energy
    consumption, L: Latency, T: Training cost'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 模型准确性, C: 模型复杂度, D: 传输数据大小, E: 能耗, L: 延迟, T: 训练成本'
- en: '* The repository is incomplete and lacks of instructions to reproduce the reported
    results for vision and speech datasets.'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '* 该存储库不完整，缺乏重现报告结果的说明，尤其是对于视觉和语音数据集。'
- en: 'These studies are all focused on image classification. Other CV tasks present
    further challenges. For instance, state of the art object detectors such as R-CNN
    models have more narrow range of layers that we can introduce bottlenecks due
    to the network architecture, which has multiple forward paths to forward outputs
    from intermediate layers to feature pyramid network (FPN) (Lin et al., [2017a](#bib.bib82)).
    The head network distillation training approach – discussed later in this section
    – was used in Matsubara and Levorato ([2021](#bib.bib95)) to address some of these
    challenges and reduce the amount of data transmitted over the channel by $94$%
    while degrading mAP (mean average precision) loss by $1$ point. Assine et al.
    ([2021](#bib.bib3)) introduce bottlenecks to the EfficientDet-D2 (Tan et al.,
    [2020](#bib.bib140)) object detector, and apply the training method based on the
    generalized head network distillation (Matsubara and Levorato, [2021](#bib.bib95))
    and mutual learning (Yang et al., [2020c](#bib.bib160)) to the modified model.
    Following the studies on SC for resource-constrained edge computing systems (Matsubara
    et al., [2019](#bib.bib91), [2020a](#bib.bib92); Yao et al., [2020](#bib.bib165)),
    Sbai et al. ([2021](#bib.bib125)) introduce autoencoder to small classifiers and
    train them on a subset of the ImageNet dataset in a similar manner. These studies
    discuss the trade-off between accuracy and memory size on mobile devices, considering
    communication constraints based 3G and LoRa technologies (Samie et al., [2016](#bib.bib122)).
    Similar to (Matsubara and Levorato, [2020](#bib.bib94), [2021](#bib.bib95); Assine
    et al., [2021](#bib.bib3)), Lee et al. ([2021](#bib.bib71)) design a lightweight
    encoder for object detector on mobile device followed by both a module to amplify
    the compressed feature and the object detector to be executed on edge server.
    Matsubara et al. ([2022a](#bib.bib93)) empirically show that bottleneck-injected
    models can be further improved by elaborating the methods to train the models.
    The resulting models outperform models with autoencoder-based feature compression
    (*e.g.*, Fig. [5](#S4.F5 "Figure 5 ‣ Reconstruction-based training ‣ 4\. Split
    Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications:
    Survey and Research Challenges")) in terms of the tradeoff between model accuracy
    and transferred data size.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 这些研究都集中在图像分类上。其他计算机视觉任务则提出了更多挑战。例如，最先进的对象检测器如 R-CNN 模型具有更窄的层范围，由于网络架构，可能会引入瓶颈，其中有多个前向路径将中间层的输出传递到特征金字塔网络（FPN）(Lin
    et al., [2017a](#bib.bib82))。后续网络蒸馏训练方法—将在本节稍后讨论—被用于 Matsubara 和 Levorato ([2021](#bib.bib95))，以应对这些挑战，并将通过通道传输的数据量减少
    $94$%，同时 mAP（平均精度均值）损失降低 $1$ 个点。Assine et al. ([2021](#bib.bib3)) 向 EfficientDet-D2
    (Tan et al., [2020](#bib.bib140)) 对象检测器引入瓶颈，并将基于通用头网络蒸馏 (Matsubara 和 Levorato,
    [2021](#bib.bib95)) 和互学习 (Yang et al., [2020c](#bib.bib160)) 的训练方法应用于修改后的模型。根据对资源受限边缘计算系统
    SC 的研究 (Matsubara et al., [2019](#bib.bib91), [2020a](#bib.bib92); Yao et al.,
    [2020](#bib.bib165))，Sbai et al. ([2021](#bib.bib125)) 向小型分类器引入自编码器，并在 ImageNet
    数据集的一个子集上以类似方式进行训练。这些研究讨论了移动设备上准确性和内存大小之间的权衡，考虑了基于 3G 和 LoRa 技术的通信限制 (Samie et
    al., [2016](#bib.bib122))。与 (Matsubara 和 Levorato, [2020](#bib.bib94), [2021](#bib.bib95);
    Assine et al., [2021](#bib.bib3)) 类似，Lee et al. ([2021](#bib.bib71)) 为移动设备上的对象检测器设计了一个轻量级编码器，并在其后添加了一个模块来放大压缩特征，以及一个在边缘服务器上执行的对象检测器。Matsubara
    et al. ([2022a](#bib.bib93)) 实证表明，通过详细化训练模型的方法，可以进一步改进引入瓶颈的模型。最终得到的模型在模型准确性和传输数据大小之间的权衡方面优于基于自编码器的特征压缩模型（*例如*，图
    [5](#S4.F5 "图 5 ‣ 基于重建的训练 ‣ 4\. 分割计算：综述 ‣ 深度学习应用的分割计算和早期退出：综述和研究挑战")）。
- en: 'Matsubara et al. ([2022c](#bib.bib98)) propose a supervised compression method
    for resource-constrained edge computing systems, which adapts ideas from knowledge
    distillation and neural image compression (Ballé et al., [2017](#bib.bib5); Ballé
    et al., [2018](#bib.bib6)). Their student model (namely, *Entropic Student*) contains
    a lightweight encoder with a learnable prior, which quantizes and entropy-codes
    latent representations under a prior probability model for efficiently saving
    the size of data to be offloaded to edge server. By adjusting a balancing weight
    in their loss function during training, we can control the tradeoff between data
    size (rate) and model accuracy (distortion). The performance of the entropic student
    model was demonstrated for three large-scale downstream supervised tasks: image
    classification (ImageNet), object detection (COCO), and semantic segmentation
    (COCO, PASCAL VOC). Notably, the representation produced by a single trained encoder
    of the entropic student model can serve multiple downstream tasks. Following the
    study, Matsubara et al. ([2022b](#bib.bib97)) further investigate this approach
    and empirically show that it generalizes to other reference models (*e.g.*, ResNet-101 (He
    et al., [2016](#bib.bib44)), RegNetY-6.4GF (Radosavovic et al., [2020](#bib.bib114)),
    Hybrid ViT (Steiner et al., [2021](#bib.bib135))). Through experiments, the study
    also points out that simply introducing such bottleneck layers at later layers
    in a model can improve the conventional rate-distortion (R-D) tradeoff, which
    will result in most of the computational load will be assigned to a weak mobile
    device.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: Matsubara 等人 ([2022c](#bib.bib98)) 提出了针对资源受限的边缘计算系统的监督压缩方法，该方法借鉴了知识蒸馏和神经图像压缩的理念（Ballé
    等人，[2017](#bib.bib5); Ballé 等人，[2018](#bib.bib6)）。他们的学生模型（即 *熵学生*）包含一个具有可学习先验的轻量级编码器，该编码器在先验概率模型下对潜在表示进行量化和熵编码，以有效地节省需卸载到边缘服务器的数据大小。通过在训练期间调整损失函数中的平衡权重，我们可以控制数据大小（率）和模型准确性（失真）之间的权衡。熵学生模型在三个大规模下游监督任务中的表现得到了验证：图像分类（ImageNet）、目标检测（COCO）和语义分割（COCO，PASCAL
    VOC）。值得注意的是，熵学生模型的单个训练编码器生成的表示可以服务于多个下游任务。随后，Matsubara 等人 ([2022b](#bib.bib97))
    进一步研究了这一方法，并实验证明它能推广到其他参考模型（*例如*，ResNet-101（He 等人，[2016](#bib.bib44)），RegNetY-6.4GF（Radosavovic
    等人，[2020](#bib.bib114)），Hybrid ViT（Steiner 等人，[2021](#bib.bib135)））。通过实验，该研究还指出，仅在模型的后期层引入这种瓶颈层可以改善传统的率-失真（R-D）权衡，这将导致大部分计算负载被分配到较弱的移动设备上。
- en: 'In contrast to SC studies without bottlenecks in Table [1](#S4.T1 "Table 1
    ‣ 4.1\. Split Computing without DNN Modification ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges"), many of the studies on bottleneck injection strategies
    in Table [3](#S4.T3 "Table 3 ‣ 4.3\. Split Computing with Bottleneck Injection
    ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") are published with code that would
    help the research communities replicate/reproduce the experimental results and
    build on existing studies.'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '与表 [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without DNN Modification ‣ 4\.
    Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") 中没有瓶颈的 SC 研究相比，表 [3](#S4.T3 "Table
    3 ‣ 4.3\. Split Computing with Bottleneck Injection ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") 中的许多瓶颈注入策略研究都发布了代码，这将有助于研究社区复制/重现实验结果并在现有研究基础上进行扩展。'
- en: '4.4\. SC with Bottlenecks: Training Methodologies'
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. **瓶颈下的分布式计算：训练方法**
- en: Given that recent SC studies with bottleneck injection strategies result in
    more or less accuracy loss comparing to the original models (*i.e.*, without injected
    bottlenecks), various training methodologies are used and/or proposed in such
    studies. Some of the training methods are designed specifically for architectures
    with injected bottlenecks. We now summarize the differences between the various
    training methodologies used in recent SC studies.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于最近采用瓶颈注入策略的 SC 研究与原始模型（*即*，没有注入瓶颈）相比会或多或少地导致准确性损失，这些研究中使用和/或提出了各种训练方法。一些训练方法是专门为注入瓶颈的架构设计的。我们现在总结了最近
    SC 研究中使用的各种训练方法之间的差异。
- en: 'We recall that $\mathbf{x}$ and $\mathbf{y}$ are an input (*e.g.*, an RGB image)
    and the corresponding label (*e.g.*, one-hot vector) respectively. Given an input
    $\mathbf{x}$, a DNN model $\mathcal{M}$ returns its output $\mathbf{\hat{y}}=\mathcal{M}(\mathbf{x})$
    such as class probabilities in classification task. Each of the $L$ layers of
    model $\mathcal{M}$ can be either low-level (*e.g.*, convolution (LeCun et al.,
    [1998](#bib.bib70)), batch normalization (Ioffe and Szegedy, [2015](#bib.bib53))),
    ReLU (Nair and Hinton, [2010](#bib.bib101))) or high-level layers (*e.g.*, residual
    block in ResNet (He et al., [2016](#bib.bib44)) and dense block in DenseNet (Huang
    et al., [2017](#bib.bib52))) which are composed by multiple low-level layers.
    $\mathcal{M}(\mathbf{x})$ is a sequence of the $L$ layer functions $\mathrm{f}_{j}$’s,
    and the $j^{\text{th}}$ layer transforms $\mathbf{z}_{j-1}$, the output from the
    previous ${(j-1)}^{\text{th}}$ layer:'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 我们回忆一下，$\mathbf{x}$ 和 $\mathbf{y}$ 是一个输入（*例如*，RGB 图像）和对应的标签（*例如*，one-hot 向量）。给定一个输入
    $\mathbf{x}$，DNN 模型 $\mathcal{M}$ 返回它的输出 $\mathbf{\hat{y}}=\mathcal{M}(\mathbf{x})$，如分类任务中的类别概率。$\mathcal{M}$
    的每个 $L$ 层可以是低层次的（*例如*，卷积 (LeCun et al., [1998](#bib.bib70))，批归一化 (Ioffe and Szegedy,
    [2015](#bib.bib53))），ReLU（Nair and Hinton, [2010](#bib.bib101)）或高层次的（*例如*，ResNet
    中的残差块 (He et al., [2016](#bib.bib44)) 和 DenseNet 中的稠密块 (Huang et al., [2017](#bib.bib52))），它们由多个低层次的层组成。$\mathcal{M}(\mathbf{x})$
    是 $L$ 个层函数 $\mathrm{f}_{j}$ 的序列，第 $j$ 层将从前一个 ${(j-1)}^{\text{th}}$ 层得到的输出 $\mathbf{z}_{j-1}$
    进行变换：
- en: '| (1) |  | <math   alttext="\mathbf{z}_{j}=\left\{\begin{array}[]{ll}\mathbf{x}&amp;j=0\\
    \mathrm{f}_{j}(\mathbf{z}_{j-1},\mathbf{\theta}_{j})&amp;1\leq j<L~{},\\'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '| (1) |  | <math   alttext="\mathbf{z}_{j}=\left\{\begin{array}[]{ll}\mathbf{x}&amp;j=0\\
    \mathrm{f}_{j}(\mathbf{z}_{j-1},\mathbf{\theta}_{j})&amp;1\leq j<L~{},\\'
- en: \mathrm{f}_{L}(\mathbf{z}_{L-1},\mathbf{\theta}_{L})=\mathcal{M}(\mathbf{x})=\mathbf{\hat{y}}&amp;j=L\end{array}\right."
    display="block"><semantics ><mrow  ><msub ><mi  >𝐳</mi><mi >j</mi></msub><mo >=</mo><mrow  ><mo
    >{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt"  ><mtr
    ><mtd  columnalign="left" ><mi  >𝐱</mi></mtd><mtd columnalign="left"  ><mrow ><mi
    >j</mi><mo  >=</mo><mn >0</mn></mrow></mtd></mtr><mtr ><mtd  columnalign="left"
    ><mrow  ><msub ><mi mathvariant="normal" >f</mi><mi >j</mi></msub><mo lspace="0em"
    rspace="0em" >​</mo><mrow ><mo stretchy="false" >(</mo><msub  ><mi >𝐳</mi><mrow
    ><mi >j</mi><mo >−</mo><mn >1</mn></mrow></msub><mo >,</mo><msub  ><mi >θ</mi><mi
    >j</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow></mtd><mtd columnalign="left"  ><mrow
    ><mrow ><mn  >1</mn><mo >≤</mo><mi >j</mi><mo  ><</mo><mi >L</mi></mrow><mo lspace="0.330em"  >,</mo></mrow></mtd></mtr><mtr
    ><mtd  columnalign="left" ><mrow  ><mrow ><msub ><mi mathvariant="normal" >f</mi><mi  >L</mi></msub><mo
    lspace="0em" rspace="0em"  >​</mo><mrow ><mo stretchy="false" >(</mo><msub ><mi
    >𝐳</mi><mrow ><mi >L</mi><mo >−</mo><mn >1</mn></mrow></msub><mo >,</mo><msub
    ><mi  >θ</mi><mi >L</mi></msub><mo stretchy="false"  >)</mo></mrow></mrow><mo
    >=</mo><mrow ><mi >ℳ</mi><mo lspace="0em" rspace="0em" >​</mo><mrow  ><mo stretchy="false"  >(</mo><mi
    >𝐱</mi><mo stretchy="false" >)</mo></mrow></mrow><mo >=</mo><mover accent="true"
    ><mi >𝐲</mi><mo  >^</mo></mover></mrow></mtd><mtd columnalign="left"  ><mrow ><mi
    >j</mi><mo  >=</mo><mi >L</mi></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml
    encoding="MathML-Content" ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci  >𝐳</ci><ci
    >𝑗</ci></apply><apply ><csymbol cd="latexml"  >cases</csymbol><matrix ><matrixrow
    ><ci  >𝐱</ci><apply ><ci >𝑗</ci><cn type="integer" >0</cn></apply></matrixrow><matrixrow
    ><apply  ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >f</ci><ci >𝑗</ci></apply><interval
    closure="open" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝐳</ci><apply
    ><ci >𝑗</ci><cn type="integer" >1</cn></apply></apply><apply ><csymbol cd="ambiguous"
    >subscript</csymbol><ci >𝜃</ci><ci >𝑗</ci></apply></interval></apply><apply ><apply  ><cn
    type="integer"  >1</cn><ci >𝑗</ci></apply><apply ><ci >𝐿</ci></apply></apply></matrixrow><matrixrow
    ><apply  ><apply ><apply ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >f</ci><ci >𝐿</ci></apply><interval closure="open" ><apply  ><csymbol cd="ambiguous"  >subscript</csymbol><ci
    >𝐳</ci><apply ><ci >𝐿</ci><cn type="integer"  >1</cn></apply></apply><apply ><csymbol
    cd="ambiguous"  >subscript</csymbol><ci >𝜃</ci><ci >𝐿</ci></apply></interval></apply><apply
    ><ci >ℳ</ci><ci  >𝐱</ci></apply></apply><apply ><apply ><ci  >^</ci><ci >𝐲</ci></apply></apply></apply><apply
    ><ci >𝑗</ci><ci  >𝐿</ci></apply></matrixrow></matrix></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\mathbf{z}_{j}=\left\{\begin{array}[]{ll}\mathbf{x}&j=0\\
    \mathrm{f}_{j}(\mathbf{z}_{j-1},\mathbf{\theta}_{j})&1\leq j<L~{},\\ \mathrm{f}_{L}(\mathbf{z}_{L-1},\mathbf{\theta}_{L})=\mathcal{M}(\mathbf{x})=\mathbf{\hat{y}}&j=L\end{array}\right.</annotation></semantics></math>
    |  |
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: \mathbf{z}_{j}=\left\{\begin{array}[]{ll}\mathbf{x}&j=0\\ \mathrm{f}_{j}(\mathbf{z}_{j-1},\mathbf{\theta}_{j})&1\leq
    j<L~{},\\ \mathrm{f}_{L}(\mathbf{z}_{L-1},\mathbf{\theta}_{L})=\mathcal{M}(\mathbf{x})=\mathbf{\hat{y}}&j=L\end{array}\right.
- en: where $\mathbf{\theta}_{j}$ denotes the $j^{\text{th}}$ layer’s hyperparameters
    and parameters to be optimized during training.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathbf{\theta}_{j}$ 表示第 $j^{\text{th}}$ 层的超参数和在训练过程中需要优化的参数。
- en: Cross entropy-based training
  id: totrans-177
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于交叉熵的训练
- en: 'To optimize parameters in a DNN model, we first need to define a loss function
    and update the parameters by minimizing the loss value with an optimizer such
    as stochastic gradient descent and Adam (Kingma and Ba, [2015](#bib.bib63)) during
    training. In image classification, a standard method is to train a DNN model $\mathcal{M}$
    in an end-to-end manner using the cross entropy like many of the studies (Eshratifar
    et al., [2019b](#bib.bib27); Hu and Krishnamachari, [2020](#bib.bib50); Matsubara
    et al., [2020a](#bib.bib92)) in Table [3](#S4.T3 "Table 3 ‣ 4.3\. Split Computing
    with Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges").
    For simplicity, here we focus on the categorical cross entropy and assume $c\equiv\mathbf{y}$
    is the correct class index given a model input $\mathbf{x}$. Given a pair of $\mathbf{x}$
    and $c$, we obtain the model output $\mathbf{\hat{y}}=\mathcal{M}(\mathbf{x})$,
    and then the (categorical) cross entropy loss is defined as'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 要优化 DNN 模型中的参数，我们首先需要定义损失函数，并通过最小化损失值来更新参数，使用的优化器包括随机梯度下降和 Adam (Kingma 和 Ba,
    [2015](#bib.bib63))。在图像分类中，标准方法是使用交叉熵以端到端的方式训练 DNN 模型 $\mathcal{M}$，这与许多研究 (Eshratifar
    等人，[2019b](#bib.bib27)；Hu 和 Krishnamachari，[2020](#bib.bib50)；Matsubara 等人，[2020a](#bib.bib92))
    一致，详见表 [3](#S4.T3 "表 3 ‣ 4.3\. 带瓶颈注入的拆分计算 ‣ 4\. 拆分计算：综述 ‣ 深度学习应用的拆分计算和早期退出：综述和研究挑战")。为了简化，这里我们关注分类交叉熵，并假设
    $c\equiv\mathbf{y}$ 是给定模型输入 $\mathbf{x}$ 的正确类索引。给定一对 $\mathbf{x}$ 和 $c$，我们获得模型输出
    $\mathbf{\hat{y}}=\mathcal{M}(\mathbf{x})$，然后定义 (分类) 交叉熵损失为
- en: '| (2) |  | $\mathcal{L}_{\text{CE}}(\mathbf{\hat{y}},c)=-\log\left(\frac{\exp\left(\hat{\mathbf{y}}_{c}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\hat{\mathbf{y}}_{j}\right)}\right),$
    |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| (2) |  | $\mathcal{L}_{\text{CE}}(\mathbf{\hat{y}},c)=-\log\left(\frac{\exp\left(\hat{\mathbf{y}}_{c}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\hat{\mathbf{y}}_{j}\right)}\right),$
    |  |'
- en: where $\hat{\mathbf{y}}_{j}$ is the class probability for the class index $j$,
    and $\mathcal{C}$ is a set of considered classes ($c\in\mathcal{C}$).
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\hat{\mathbf{y}}_{j}$ 是类索引 $j$ 的类概率，$\mathcal{C}$ 是考虑的类的集合（$c\in\mathcal{C}$）。
- en: '![Refer to caption](img/6e68ba06e54a5c5d9cfcdc1cf7113c57.png)'
  id: totrans-181
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/6e68ba06e54a5c5d9cfcdc1cf7113c57.png)'
- en: Figure 3\. Cross entropy-based training for bottleneck-injected DNN.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3\. 基于交叉熵的瓶颈注入 DNN 训练。
- en: 'As shown in Eq. ([2](#S4.E2 "In Cross entropy-based training ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges")), the loss function used in cross entropy-based training
    methods are used as a function of the final output $\mathbf{\hat{y}}$, and thus
    are not designed for SC frameworks. While Eshratifar et al. ([2019b](#bib.bib27));
    Hu and Krishnamachari ([2020](#bib.bib50)); Shao and Zhang ([2020](#bib.bib127));
    Lee et al. ([2021](#bib.bib71)) use cross entropy to train bottleneck-injected
    DNN models in end-to-end manners (Fig. [3](#S4.F3 "Figure 3 ‣ Cross entropy-based
    training ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for
    Deep Learning Applications: Survey and Research Challenges")), Matsubara et al.
    ([2020a](#bib.bib92)) empirically show that these methods cause a larger accuracy
    loss in complex tasks such as ImageNet dataset (Russakovsky et al., [2015](#bib.bib121))
    compared to other more advanced techniques, including knowledge distillation.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 如方程式 ([2](#S4.E2 "在基于交叉熵的训练中 ‣ 4\. 拆分计算：综述 ‣ 深度学习应用的拆分计算和早期退出：综述和研究挑战")) 所示，交叉熵训练方法中使用的损失函数作为最终输出
    $\mathbf{\hat{y}}$ 的函数，因此并未针对 SC 框架设计。虽然 Eshratifar 等人 ([2019b](#bib.bib27))；Hu
    和 Krishnamachari ([2020](#bib.bib50))；Shao 和 Zhang ([2020](#bib.bib127))；Lee 等人
    ([2021](#bib.bib71)) 采用交叉熵以端到端的方式训练瓶颈注入 DNN 模型（图 [3](#S4.F3 "图 3 ‣ 基于交叉熵的训练 ‣
    4\. 拆分计算：综述 ‣ 深度学习应用的拆分计算和早期退出：综述和研究挑战")），Matsubara 等人 ([2020a](#bib.bib92)) 实证表明，与其他更先进的技术（包括知识蒸馏）相比，这些方法在复杂任务（如
    ImageNet 数据集 (Russakovsky 等人，[2015](#bib.bib121))）中造成更大的准确率损失。
- en: Knowledge distillation
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识蒸馏
- en: Complex DNN models are usually trained to learn parameters for discriminating
    between a large number of classes (*e.g.*, $1,000$ in ImageNet dataset), and are
    often overparameterized. Knowledge distillation (KD) (Li et al., [2014](#bib.bib79);
    Ba and Caruana, [2014](#bib.bib4); Hinton et al., [2014](#bib.bib47)) is a training
    scheme to address this problem, and trains a DNN model (called “student”) using
    additional signals from a pretrained DNN model (called “teacher” and often larger
    than the student). In standard cross entropy-based training – that is, using “hard
    targets” (*e.g.*, one-hot vectors) – we face a side-effect that the trained models
    assign probabilities to all of the incorrect classes. From the relative probabilities
    of incorrect classes, we can see how large models tend to generalize.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 复杂的 DNN 模型通常被训练以学习区分大量类别（*例如*，ImageNet 数据集中有 $1,000$ 个类别），且常常存在过度参数化的问题。知识蒸馏（KD）（Li
    等，[2014](#bib.bib79); Ba 和 Caruana，[2014](#bib.bib4); Hinton 等，[2014](#bib.bib47)）是一种解决此问题的训练方案，它使用来自预训练
    DNN 模型（称为“教师”且通常大于学生）的附加信号来训练 DNN 模型（称为“学生”）。在标准的交叉熵基础训练中——即使用“硬目标”（*例如*，独热向量）——我们面临的副作用是训练出的模型对所有不正确的类别分配概率。通过这些不正确类别的相对概率，我们可以看到大型模型的泛化趋势。
- en: '![Refer to caption](img/24482a162a4c4a7ae9fe0a6d2f4b9ca9.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/24482a162a4c4a7ae9fe0a6d2f4b9ca9.png)'
- en: Figure 4\. Knowledge distillation for bottleneck-injected DNN (student), using
    a pretrained model as teacher.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4\. 瓶颈注入 DNN（学生）的知识蒸馏，使用预训练模型作为教师。
- en: 'As illustrated in Fig. [4](#S4.F4 "Figure 4 ‣ Knowledge distillation ‣ 4\.
    Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges"), by distilling the knowledge from
    a pretrained complex model (teacher), a student model can be more generalized
    and avoid overfitting to the training dataset, using the outputs of the teacher
    model as “soft targets” in addition to the hard targets (Hinton et al., [2014](#bib.bib47)).'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [4](#S4.F4 "Figure 4 ‣ Knowledge distillation ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") 所示，通过从预训练的复杂模型（教师）中提取知识，学生模型可以更好地泛化，并避免对训练数据集的过拟合，除了硬目标外，还使用教师模型的输出作为“软目标”（Hinton
    等，[2014](#bib.bib47)）。'
- en: '| (3) |  | $\mathcal{L}_{\text{KD}}(\hat{\mathbf{y}}^{\text{S}},\hat{\mathbf{y}}^{\text{T}},\mathbf{y})=\alpha\mathcal{L}_{\text{task}}(\hat{\mathbf{y}}^{\text{S}},\mathbf{y})+(1-\alpha)\tau^{2}\mathrm{KL}\left(\mathrm{q}(\hat{\mathbf{y}}^{\text{S}}),\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})\right),$
    |  |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| (3) |  | $\mathcal{L}_{\text{KD}}(\hat{\mathbf{y}}^{\text{S}},\hat{\mathbf{y}}^{\text{T}},\mathbf{y})=\alpha\mathcal{L}_{\text{task}}(\hat{\mathbf{y}}^{\text{S}},\mathbf{y})+(1-\alpha)\tau^{2}\mathrm{KL}\left(\mathrm{q}(\hat{\mathbf{y}}^{\text{S}}),\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})\right),$
    |  |'
- en: 'where $\alpha$ is a balancing factor (hyperparameter) between *hard target*
    (left term) and *soft target* (right term) losses, and $\tau$ is another hyperparameter
    called *temperature* to soften the outputs of teacher and student models in Eq. ([4](#S4.E4
    "In Knowledge distillation ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges")).
    $\mathcal{L}_{\text{task}}$ is a task-specific loss function, and it is a cross
    entropy loss in image classification tasks *i.e.*, $\mathcal{L}_{\text{task}}=\mathcal{L}_{\text{CE}}$.
    $\mathrm{KL}$ is the Kullback-Leibler divergence function, where $\mathrm{q}(\hat{\mathbf{y}}^{\text{S}})$
    and $\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})$ are probability distributions of
    student and teacher models for an input $\mathbf{x}$, that is, $\mathrm{q}(\hat{\mathbf{y}}^{\text{S}})=[\mathrm{q}_{1}(\hat{\mathbf{y}}^{\text{S}}),\cdots,\mathrm{q}_{|\mathcal{C}|}(\hat{\mathbf{y}}^{\text{S}})]$
    and $\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})=[\mathrm{p}_{1}(\hat{\mathbf{y}}^{\text{S}}),\cdots,\mathrm{p}_{|C|}(\hat{\mathbf{y}}^{\text{T}})]$:'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '其中 $\alpha$ 是*硬目标*（左项）和*软目标*（右项）损失之间的平衡因子（超参数），$\tau$ 是另一个被称为*温度*的超参数，用于软化教师和学生模型在公式
    ([4](#S4.E4 "In Knowledge distillation ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges")) 中的输出。$\mathcal{L}_{\text{task}}$ 是任务特定的损失函数，在图像分类任务中它是交叉熵损失，即 $\mathcal{L}_{\text{task}}=\mathcal{L}_{\text{CE}}$。$\mathrm{KL}$
    是 Kullback-Leibler 散度函数，其中 $\mathrm{q}(\hat{\mathbf{y}}^{\text{S}})$ 和 $\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})$
    分别是学生和教师模型对输入 $\mathbf{x}$ 的概率分布，即 $\mathrm{q}(\hat{\mathbf{y}}^{\text{S}})=[\mathrm{q}_{1}(\hat{\mathbf{y}}^{\text{S}}),\cdots,\mathrm{q}_{|\mathcal{C}|}(\hat{\mathbf{y}}^{\text{S}})]$
    和 $\mathrm{p}(\hat{\mathbf{y}}^{\text{T}})=[\mathrm{p}_{1}(\hat{\mathbf{y}}^{\text{S}}),\cdots,\mathrm{p}_{|C|}(\hat{\mathbf{y}}^{\text{T}})]$：'
- en: '| (4) |  | $\mathrm{q}_{k}(\hat{\mathbf{y}}^{\text{S}})=\frac{\exp\left(\frac{\hat{\mathbf{y}}^{\text{S}}_{k}}{\tau}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\frac{\hat{\mathbf{y}}^{\text{S}}_{j}}{\tau}\right)},~{}~{}\mathrm{p}_{k}(\hat{\mathbf{y}}^{\text{T}})=\frac{\exp\left(\frac{\hat{\mathbf{y}}^{\text{T}}_{k}}{\tau}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\frac{\hat{\mathbf{y}}^{\text{T}}_{j}}{\tau}\right)},$
    |  |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| (4) |  | $\mathrm{q}_{k}(\hat{\mathbf{y}}^{\text{S}})=\frac{\exp\left(\frac{\hat{\mathbf{y}}^{\text{S}}_{k}}{\tau}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\frac{\hat{\mathbf{y}}^{\text{S}}_{j}}{\tau}\right)},~{}~{}\mathrm{p}_{k}(\hat{\mathbf{y}}^{\text{T}})=\frac{\exp\left(\frac{\hat{\mathbf{y}}^{\text{T}}_{k}}{\tau}\right)}{\sum_{j\in\mathcal{C}}\exp\left(\frac{\hat{\mathbf{y}}^{\text{T}}_{j}}{\tau}\right)},$
    |  |'
- en: Using the ImageNet dataset, it is empirically shown in Matsubara et al. ([2020a](#bib.bib92))
    that all the considered bottleneck-injected student models trained with their
    teacher models (original models without injected bottlenecks) consistently outperform
    those trained without the teacher models. This result matches a widely known trend
    in knowledge distillation reported in Ba and Caruana ([2014](#bib.bib4)). However,
    similar to cross entropy, the knowledge distillation is still not aware of bottlenecks
    we introduce to DNN models and may result in significant accuracy loss as suggested
    by Matsubara et al. ([2020a](#bib.bib92)).
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 ImageNet 数据集，Matsubara 等人（[2020a](#bib.bib92)）通过实证研究表明，所有考虑的瓶颈注入学生模型与其教师模型（未注入瓶颈的原始模型）训练的结果一致优于那些没有教师模型训练的结果。这一结果与
    Ba 和 Caruana（[2014](#bib.bib4)）报告的知识蒸馏中的广泛趋势相符。然而，与交叉熵类似，知识蒸馏仍然未能识别我们对 DNN 模型引入的瓶颈，并可能导致显著的准确度损失，正如
    Matsubara 等人（[2020a](#bib.bib92)）所指出的。
- en: Reconstruction-based training
  id: totrans-193
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 基于重建的训练
- en: 'As illustrated in Fig. [5](#S4.F5 "Figure 5 ‣ Reconstruction-based training
    ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges"), Choi et al. ([2020](#bib.bib15));
    Jankowski et al. ([2020](#bib.bib58)); Yao et al. ([2020](#bib.bib165)); Sbai
    et al. ([2021](#bib.bib125)) inject Autoencoder (AE) models into existing DNN
    models, and train the injected components by minimizing the reconstruction error.
    First manually an intermediate layer in a DNN model (say its $j^{\text{th}}$ layer)
    is chosen, and the output of the $j^{\text{th}}$ layer $\mathbf{z}_{j}$ is fed
    to the encoder $\mathrm{f}_{\text{enc}}$ whose role is to compress $\mathbf{z}_{j}$.
    The encoder’s output $\mathbf{z}_{\text{enc}}$ is a compressed representation,
    *i.e.*, bottleneck to be transferred to edge server and the following decoder
    $\mathrm{f}_{\text{dec}}$ decompresses the compressed representation and returns
    $\mathbf{z}_{\text{dec}}$. As the decoder is designed to reconstruct $\mathbf{z}_{j}$,
    its output $\mathbf{z}_{\text{dec}}$ should share the same dimensionality with
    $\mathbf{z}_{j}$. Then, the injected AE are trained by minimizing the following
    reconstruction loss:'
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: '如图 [5](#S4.F5 "Figure 5 ‣ Reconstruction-based training ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges") 所示，Choi 等人（[2020](#bib.bib15)）；Jankowski 等人（[2020](#bib.bib58)）；Yao
    等人（[2020](#bib.bib165)）；Sbai 等人（[2021](#bib.bib125)）将自编码器（AE）模型注入到现有的 DNN 模型中，并通过最小化重建误差来训练注入的组件。首先，手动选择
    DNN 模型中的一个中间层（假设是第 $j$ 层），然后将第 $j$ 层的输出 $\mathbf{z}_{j}$ 输入到编码器 $\mathrm{f}_{\text{enc}}$
    中，该编码器的作用是压缩 $\mathbf{z}_{j}$。编码器的输出 $\mathbf{z}_{\text{enc}}$ 是压缩表示，即瓶颈，传输到边缘服务器，接下来的解码器
    $\mathrm{f}_{\text{dec}}$ 解压缩压缩表示并返回 $\mathbf{z}_{\text{dec}}$。由于解码器被设计为重建 $\mathbf{z}_{j}$，其输出
    $\mathbf{z}_{\text{dec}}$ 应与 $\mathbf{z}_{j}$ 具有相同的维度。然后，通过最小化以下重建损失来训练注入的 AE：'
- en: '![Refer to caption](img/43bae28bbc07925de9fca3d828939811.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/43bae28bbc07925de9fca3d828939811.png)'
- en: Figure 5\. Reconstruction-based training to compress intermediate output (here
    $\mathbf{z}_{2}$) in DNN by AE (yellow).
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5\. 基于重建的训练，通过 AE（黄色）压缩 DNN 中的中间输出（这里是 $\mathbf{z}_{2}$）。
- en: '|  | $\displaystyle\mathcal{L}_{\text{Recon.}}\left(\mathbf{z}_{j}\right)$
    | $\displaystyle=$ | $\displaystyle\&#124;\mathbf{z}_{j}-\mathrm{f}_{\text{dec}}\left(\mathrm{f}_{\text{enc}}\left(\mathbf{z}_{j};\theta_{\text{enc}}\right);\mathbf{\theta_{\text{dec}}}\right)+\epsilon\&#124;_{n}^{m},$
    |  |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{Recon.}}\left(\mathbf{z}_{j}\right)$
    | $\displaystyle=$ | $\displaystyle\&#124;\mathbf{z}_{j}-\mathrm{f}_{\text{dec}}\left(\mathrm{f}_{\text{enc}}\left(\mathbf{z}_{j};\theta_{\text{enc}}\right);\mathbf{\theta_{\text{dec}}}\right)+\epsilon\&#124;_{n}^{m},$
    |  |'
- en: '|  |  | $\displaystyle=$ | $\displaystyle\&#124;\mathbf{z}_{j}-\mathbf{z}_{\text{dec}}+\epsilon\&#124;_{n}^{m},$
    |  |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle=$ | $\displaystyle\&#124;\mathbf{z}_{j}-\mathbf{z}_{\text{dec}}+\epsilon\&#124;_{n}^{m},$
    |  |'
- en: where $\|\mathbf{z}\|_{n}^{m}$ denotes $m^{\text{th}}$ power of $n$-norm of
    $\mathbf{z}$, and $\epsilon$ is an optional regularization constant. For example,
    Choi et al. ([2020](#bib.bib15)) set $m=1$, $n=2$ and $\epsilon=10^{-6}$, and
    Jankowski et al. ([2020](#bib.bib58)) use $m=n=1$ and $\epsilon=0$. Inspired by
    the idea of knowledge distillation (Hinton et al., [2014](#bib.bib47)), Yao et al.
    ([2020](#bib.bib165)) also consider additional squared errors between intermediate
    feature maps from models with and without bottlenecks as additional loss terms
    like generalized head network distillation (Matsubara and Levorato, [2021](#bib.bib95))
    described later. While Yao et al. ([2020](#bib.bib165)) shows high compression
    rate with small accuracy loss by injecting encoder-decoder architectures to existing
    DNN models, such strategies (Choi et al., [2020](#bib.bib15); Jankowski et al.,
    [2020](#bib.bib58); Yao et al., [2020](#bib.bib165); Sbai et al., [2021](#bib.bib125))
    increase computational complexity as a result. Suppose the encoder and decoder
    consist of $L_{\text{enc}}$ and $L_{\text{dec}}$ layers respectively, then the
    total number of layers in the altered DNN model is $L+L_{\text{enc}}+L_{\text{dec}}$.
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\|\mathbf{z}\|_{n}^{m}$ 表示 $\mathbf{z}$ 的 $n$-范数的 $m^{\text{th}}$ 次方，$\epsilon$
    是一个可选的正则化常数。例如，Choi 等人（[2020](#bib.bib15)）设置 $m=1$、$n=2$ 和 $\epsilon=10^{-6}$，Jankowski
    等人（[2020](#bib.bib58)）使用 $m=n=1$ 和 $\epsilon=0$。受知识蒸馏的启发（Hinton 等人，[2014](#bib.bib47)），Yao
    等人（[2020](#bib.bib165)）还考虑了带有和不带有瓶颈的模型中间特征图之间的额外平方误差，作为类似于后文描述的广义头网络蒸馏（Matsubara
    和 Levorato，[2021](#bib.bib95)）的额外损失项。虽然 Yao 等人（[2020](#bib.bib165)）通过向现有 DNN 模型注入编码器-解码器架构展示了高压缩率和小的准确性损失，但这种策略（Choi
    等人，[2020](#bib.bib15)；Jankowski 等人，[2020](#bib.bib58)；Yao 等人，[2020](#bib.bib165)；Sbai
    等人，[2021](#bib.bib125)）会导致计算复杂性增加。假设编码器和解码器分别由 $L_{\text{enc}}$ 和 $L_{\text{dec}}$
    层组成，则改变后的 DNN 模型的总层数为 $L+L_{\text{enc}}+L_{\text{dec}}$。
- en: Head network distillation
  id: totrans-200
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 头网络蒸馏
- en: 'The training methods described above are focused on either end-to-end or encoder-decoder
    training. The first approach often requires hard targets such as one-hot vectors
    and more training cost while the latter can focus on the injected components (encoder
    and decoder) during training, but the additional components (layers) will increase
    the complexity of the DNN model. To reduce both training cost and model complexity
    while preserving accuracy, it is proposed in Matsubara et al. ([2019](#bib.bib91))
    to use head network distillation (HND) to distill the head portion of the DNN–
    which contains a bottleneck – leveraging pretrained DNN models. Figure [6](#S4.F6
    "Figure 6 ‣ Head network distillation ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges") illustrates this approach.'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '上述训练方法集中在端到端或编码器-解码器训练上。第一种方法通常需要硬目标，如独热向量，并且训练成本更高，而后者可以在训练期间专注于注入的组件（编码器和解码器），但附加组件（层）会增加
    DNN 模型的复杂性。为了在保持准确性的同时减少训练成本和模型复杂性，Matsubara 等人（[2019](#bib.bib91)）提出使用头网络蒸馏（HND）来蒸馏包含瓶颈的
    DNN 的头部部分，利用预训练的 DNN 模型。图[6](#S4.F6 "Figure 6 ‣ Head network distillation ‣ 4\.
    Split Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") 说明了这一方法。'
- en: '![Refer to caption](img/3bc35a9931fd28d13478300dd37786a3.png)'
  id: totrans-202
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/3bc35a9931fd28d13478300dd37786a3.png)'
- en: Figure 6\. Head network distillation for bottleneck-injected DNN (student),
    using a pretrained model as teacher. The student model’s tail portion is copied
    from that of its teacher model with respect to the architecture and pretrained
    parameters.
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 图6\. 针对瓶颈注入的 DNN（学生）的头网络蒸馏，使用预训练模型作为教师。学生模型的尾部部分是根据架构和预训练参数从教师模型复制的。
- en: 'The original pretrained DNN (consisting of $L$ layers) is used as a starting
    point, whose architecture (in the head part) is simplified. As only the teacher’s
    head portion is altered, the tail portion of the student model is identical to
    that of the teacher model with respect to architecture and the same pretrained
    parameters can be maintained. Thus, head network distillation requires only the
    first layers of the teacher and student models in training session as the student
    head model $\mathrm{f}_{\text{head}}^{\text{S}}$ will be trained to mimic behavior
    of teacher’s head model $\mathrm{f}_{\text{head}}^{\text{T}}$ given an input $\mathbf{x}$:'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: 原始预训练的深度神经网络（包含 $L$ 层）作为起点，其架构（头部部分）被简化。由于只有教师的头部部分被改变，学生模型的尾部部分在架构上与教师模型相同，并且可以保持相同的预训练参数。因此，头网络蒸馏只需要在训练过程中使用教师和学生模型的前几层，因为学生头部模型
    $\mathrm{f}_{\text{head}}^{\text{S}}$ 将被训练以模拟教师头部模型 $\mathrm{f}_{\text{head}}^{\text{T}}$
    在给定输入 $\mathbf{x}$ 时的行为：
- en: '| (6) |  | $\mathcal{L}_{\text{HND}}(\mathbf{x})=\&#124;\mathrm{f}_{\text{head}}^{\text{S}}(\mathbf{x};\mathbf{\theta}_{\text{head}}^{\text{S}})-\mathrm{f}_{\text{head}}^{\text{T}}(\mathbf{x};\mathbf{\theta}_{\text{head}}^{\text{T}})\&#124;^{2},$
    |  |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| (6) |  | $\mathcal{L}_{\text{HND}}(\mathbf{x})=\&#124;\mathrm{f}_{\text{head}}^{\text{S}}(\mathbf{x};\mathbf{\theta}_{\text{head}}^{\text{S}})-\mathrm{f}_{\text{head}}^{\text{T}}(\mathbf{x};\mathbf{\theta}_{\text{head}}^{\text{T}})\&#124;^{2},$
    |  |'
- en: where $\mathrm{f}_{\text{head}}^{\text{S}}$ and $\mathrm{f}_{\text{head}}^{\text{T}}$
    are sequences of the first $L_{\text{head}}^{\text{S}}$ and $L_{\text{head}}^{\text{T}}$
    layers in student and teacher models ($L_{\text{head}}^{\text{S}}\ll L^{\text{S}}$,
    and $L_{\text{head}}^{\text{T}}\ll L$ ), respectively.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathrm{f}_{\text{head}}^{\text{S}}$ 和 $\mathrm{f}_{\text{head}}^{\text{T}}$
    是学生模型和教师模型中前 $L_{\text{head}}^{\text{S}}$ 和 $L_{\text{head}}^{\text{T}}$ 层的序列（$L_{\text{head}}^{\text{S}}\ll
    L^{\text{S}}$，$L_{\text{head}}^{\text{T}}\ll L$）。
- en: Experimental results with the ImageNet (ILSVRC 2012) dataset show that given
    a bottleneck-introduced model, the head network distillation method consistently
    outperforms cross entropy-based training (Eshratifar et al., [2019b](#bib.bib27);
    Hu and Krishnamachari, [2020](#bib.bib50); Shao and Zhang, [2020](#bib.bib127))
    and knowledge distillation methods in terms of not only training cost but also
    accuracy of the trained model. This method is extended in Matsubara and Levorato
    ([2021](#bib.bib95)), where the generalized head network distillation technique
    (GHND) is proposed for complex object detection tasks and models. We note that
    these tasks require finer feature maps mimicking those at intermediate layers
    in the original pretrained object detectors. The loss function in this approach
    is
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果表明，使用 ImageNet (ILSVRC 2012) 数据集，在引入瓶颈的模型中，头网络蒸馏方法在训练成本和训练模型的准确性方面均优于基于交叉熵的训练方法（Eshratifar
    et al., [2019b](#bib.bib27); Hu 和 Krishnamachari, [2020](#bib.bib50); Shao 和 Zhang,
    [2020](#bib.bib127)）以及知识蒸馏方法。这种方法在 Matsubara 和 Levorato ([2021](#bib.bib95)) 中得到了扩展，其中提出了一种广义头网络蒸馏技术（GHND）用于复杂的物体检测任务和模型。我们注意到，这些任务需要更精细的特征图，以模拟原始预训练物体检测器中间层的特征图。该方法中的损失函数是
- en: '| (7) |  | $\mathcal{L}_{\text{GHND}}(\mathbf{x})=\sum_{j\in\mathcal{J}}\lambda_{j}\cdot\mathcal{L}_{j}(\mathbf{x},\mathrm{f}_{1-L_{j}^{\text{S}}}^{\text{S}},\mathrm{f}_{1-L_{j}}^{\text{T}}),$
    |  |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| (7) |  | $\mathcal{L}_{\text{GHND}}(\mathbf{x})=\sum_{j\in\mathcal{J}}\lambda_{j}\cdot\mathcal{L}_{j}(\mathbf{x},\mathrm{f}_{1-L_{j}^{\text{S}}}^{\text{S}},\mathrm{f}_{1-L_{j}}^{\text{T}}),$
    |  |'
- en: 'where $j$ is loss index, $\lambda_{j}$ is a scale factor (hyperparameter) associated
    with loss $\mathcal{L}_{j}$, and $\mathrm{f}_{1-L_{j}^{\text{S}}}^{\text{S}}$
    and $\mathrm{f}_{1-L_{j}^{\text{T}}}^{\text{T}}$ indicate the corresponding sequences
    of the first $L_{j}^{\text{S}}$ and $L_{j}^{\text{T}}$ layers in the student and
    teacher models (functions of input data $\mathbf{x}$), respectively. The total
    loss, then, is a linear combination of $|\mathcal{J}|$ weighted losses. Following
    Eq. ([7](#S4.E7 "In Head network distillation ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges")), the previously proposed head network distillation technique (Matsubara
    et al., [2019](#bib.bib91)) can be seen as a special case of generalized head
    network distillation (GHND). GHND significantly improved the object detection
    performance in bottleneck-injected R-CNN models on COCO 2017 dataset while achieving
    a high compression rate.'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $j$ 是损失指数，$\lambda_{j}$ 是与损失 $\mathcal{L}_{j}$ 相关的缩放因子（超参数），而 $\mathrm{f}_{1-L_{j}^{\text{S}}}^{\text{S}}$
    和 $\mathrm{f}_{1-L_{j}^{\text{T}}}^{\text{T}}$ 分别表示学生模型和教师模型中前 $L_{j}^{\text{S}}$
    和 $L_{j}^{\text{T}}$ 层的相应序列（输入数据 $\mathbf{x}$ 的函数）。总损失是 $|\mathcal{J}|$ 个加权损失的线性组合。根据公式
    ([7](#S4.E7 "在头网络蒸馏 ‣ 4\. 拆分计算：综述 ‣ 拆分计算与提前退出在深度学习应用中的挑战和研究"))，以前提出的头网络蒸馏技术（Matsubara
    等， [2019](#bib.bib91)）可以被视为广义头网络蒸馏（GHND）的一个特例。GHND 显著提升了 COCO 2017 数据集中瓶颈注入 R-CNN
    模型的目标检测性能，同时实现了较高的压缩率。
- en: '5\. Early Exiting: A Survey'
  id: totrans-210
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5\. 提前退出：综述
- en: 'This section presents a survey of the state of the art in EE strategies. We
    first provide a compendium of work focused on CV and NLP applications in Sections [5.2](#S5.SS2
    "5.2\. EE for CV Applications ‣ 5\. Early Exiting: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    and [5.3](#S5.SS3 "5.3\. EE for NLP Applications ‣ 5\. Early Exiting: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges"), respectively. Section [5.4](#S5.SS4 "5.4\. Training Methodologies
    for EE Strategies ‣ 5\. Early Exiting: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") summarizes training
    methodologies used in the EE studies.'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 本节综述了 EE 策略的最新进展。我们首先在 [5.2](#S5.SS2 "5.2\. 计算机视觉应用中的 EE ‣ 5\. 提前退出：综述 ‣ 拆分计算与提前退出在深度学习应用中的挑战和研究")
    和 [5.3](#S5.SS3 "5.3\. 自然语言处理应用中的 EE ‣ 5\. 提前退出：综述 ‣ 拆分计算与提前退出在深度学习应用中的挑战和研究")
    中分别提供了针对计算机视觉和自然语言处理应用的工作汇编。第 [5.4](#S5.SS4 "5.4\. EE 策略的训练方法 ‣ 5\. 提前退出：综述 ‣
    拆分计算与提前退出在深度学习应用中的挑战和研究") 节总结了 EE 研究中使用的训练方法。
- en: 5.1\. Rationale behind EE
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1\. EE 背后的基本原理
- en: The core idea of EE, first proposed in Teerapittayanon et al. ([2016](#bib.bib141)),
    is to circumvent the need to make DNN models smaller by introducing early exits
    in the DNN, where execution is terminated at the first exit achieving the desired
    confidence on the input sample. For instance, some samples in test datasets (and
    in real-world problems) will be easy for a DNN model, but others may not be, depending
    on ML models we use. Thus, EE ends the inference process with fewer transforms
    (layers) for such easy samples so that the overall inference time and computation
    cost are reduced.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 提前退出（EE）的核心思想，首次由 Teerapittayanon 等人 ([2016](#bib.bib141)) 提出，是通过在 DNN 中引入提前退出机制来避免将
    DNN 模型缩小的需要，在第一个退出点达到对输入样本的期望置信度时终止执行。例如，测试数据集中的一些样本（以及现实问题中的样本）对于 DNN 模型来说可能很容易，但其他样本可能不易处理，取决于我们使用的
    ML 模型。因此，EE 对于这些容易处理的样本结束推断过程时使用更少的变换（层），从而减少了整体推断时间和计算成本。
- en: '![Refer to caption](img/711803046e7b395bf52aaa0dbfc1f3b5.png)'
  id: totrans-214
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/711803046e7b395bf52aaa0dbfc1f3b5.png)'
- en: Figure 7\. Illustration of two early exits (green) introduced to DNN.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7\. 介绍了在 DNN 中引入的两个提前退出点（绿色）。
- en: 'Figure [7](#S5.F7 "Figure 7 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges") illustrates an example of early classifiers (subbranches)
    introduced in a DNN model. In this example, the second early classifier has sufficient
    confidence in its output (class probability is 0.85 out of 1.0) to terminate the
    inference for the input sample so that the following layers are not executed.
    Note that all the exits are executed until the desired confidence is reached,
    that is, the computational complexity up to that point increases. Thus, the classifiers
    added to the DNN model need to be simple, that is, they need to have fewer layers
    than the layers after the branches. Otherwise, the overall inference cost will
    increase on average rather than decrease. Teerapittayanon et al. ([2017](#bib.bib142))
    also applies this idea to mobile-edge-cloud computing systems; the smallest neural
    model is allocated to the mobile device, and if that model’s confidence for the
    input is not large enough, the intermediate output is forwarded to the edge server,
    where inference will continue using a mid-sized neural model with another exit.
    If the output still does not reach the target confidence, the intermediate layer’s
    output is forwarded to the cloud, which executes the largest neural model. EE
    strategies have been widely investigated in the literature, as summarized in Table [4](#S5.T4
    "Table 4 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges").'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '图[7](#S5.F7 "Figure 7 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges") 展示了在DNN模型中引入的早期分类器（子分支）的示例。在这个例子中，第二个早期分类器对其输出有足够的信心（类别概率为0.85，满分为1.0），以便终止输入样本的推理，从而不执行后续层。请注意，所有的出口在达到所需信心之前都会被执行，即计算复杂性到此为止会增加。因此，添加到DNN模型中的分类器需要简单，即它们需要比分支后的层少。否则，总体推理成本会平均增加而不是减少。Teerapittayanon等人（[2017](#bib.bib142)）也将这一理念应用于移动边缘云计算系统；最小的神经网络模型分配给移动设备，如果该模型对输入的信心不够大，则将中间输出转发到边缘服务器，在那里使用中等规模的神经网络模型继续推理，且还有另一个出口。如果输出仍未达到目标信心，则将中间层的输出转发到云端，云端执行最大的神经网络模型。EE策略在文献中已被广泛研究，见表[4](#S5.T4
    "Table 4 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges")。'
- en: 'As shown in Tables [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without DNN
    Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") and [3](#S4.T3
    "Table 3 ‣ 4.3\. Split Computing with Bottleneck Injection ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges"), most of the studies on SC were focused on computer
    vision. For EE, we can confirm a good balance between the studies with computer
    vision and NLP applications as summarized in Table [4](#S5.T4 "Table 4 ‣ 5.1\.
    Rationale behind EE ‣ 5\. Early Exiting: A Survey ‣ Split Computing and Early
    Exiting for Deep Learning Applications: Survey and Research Challenges"), with
    structural/conceptual differences between the two domains. Moreover, CNN (*e.g.*,
    AlexNet (Krizhevsky et al., [2012](#bib.bib65)) and ResNet (He et al., [2016](#bib.bib44)))
    and Transformer-based models (*e.g.*, BERT (Devlin et al., [2019](#bib.bib22)))
    are mostly discussed in the EE studies for computer vision and NLP, respectively.
    For these reasons, we categorize the EE papers by task domain in Sections [5.2](#S5.SS2
    "5.2\. EE for CV Applications ‣ 5\. Early Exiting: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    and [5.3](#S5.SS3 "5.3\. EE for NLP Applications ‣ 5\. Early Exiting: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges").'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: 如表 [1](#S4.T1 "表 1 ‣ 4.1\. 无 DNN 修改的分割计算 ‣ 4\. 分割计算：调查 ‣ 深度学习应用的分割计算与早期退出：调查与研究挑战")
    和 [3](#S4.T3 "表 3 ‣ 4.3\. 有瓶颈注入的分割计算 ‣ 4\. 分割计算：调查 ‣ 深度学习应用的分割计算与早期退出：调查与研究挑战")
    所示，大多数关于 SC 的研究集中在计算机视觉上。对于 EE，我们可以确认在计算机视觉和 NLP 应用之间有良好的平衡，如表 [4](#S5.T4 "表 4
    ‣ 5.1\. 早期退出的理由 ‣ 5\. 早期退出：调查 ‣ 深度学习应用的分割计算与早期退出：调查与研究挑战") 总结的那样，两者之间存在结构/概念上的差异。此外，CNN
    (*例如*，AlexNet (Krizhevsky 等人, [2012](#bib.bib65)) 和 ResNet (He 等人, [2016](#bib.bib44)))
    和基于 Transformer 的模型 (*例如*，BERT (Devlin 等人, [2019](#bib.bib22))) 在计算机视觉和 NLP 的
    EE 研究中分别被广泛讨论。因此，我们在第 [5.2](#S5.SS2 "5.2\. 用于 CV 应用的 EE ‣ 5\. 早期退出：调查 ‣ 深度学习应用的分割计算与早期退出：调查与研究挑战")
    和 [5.3](#S5.SS3 "5.3\. 用于 NLP 应用的 EE ‣ 5\. 早期退出：调查 ‣ 深度学习应用的分割计算与早期退出：调查与研究挑战")
    节中按任务领域对 EE 论文进行了分类。
- en: Table 4\. Studies on early exiting strategies.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4\. 关于早期退出策略的研究。
- en: '| Work | Task(s) | Dataset(s) | Base Model(s) | Metrics | Code |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 任务 | 数据集 | 基础模型 | 评估指标 | 代码 |'
- en: '|'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Teerapittayanon et al. ([2016](#bib.bib141)) &#124;'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Teerapittayanon 等人 ([2016](#bib.bib141)) &#124;'
- en: '&#124; (2016) &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2016) &#124;'
- en: '| Image classification | MNIST (LeCun et al., [1998](#bib.bib70)) CIFAR-10 (Krizhevsky,
    [2009](#bib.bib64)) | LeNet-5 (LeCun et al., [1998](#bib.bib70)) AlexNet (Krizhevsky
    et al., [2012](#bib.bib65)) ResNet (He et al., [2016](#bib.bib44)) | A, L | [Link](https://gitlab.com/kunglab/branchynet)
    |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | MNIST (LeCun 等人, [1998](#bib.bib70)) CIFAR-10 (Krizhevsky, [2009](#bib.bib64))
    | LeNet-5 (LeCun 等人, [1998](#bib.bib70)) AlexNet (Krizhevsky 等人, [2012](#bib.bib65))
    ResNet (He 等人, [2016](#bib.bib44)) | A, L | [链接](https://gitlab.com/kunglab/branchynet)
    |'
- en: '|'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Teerapittayanon et al. ([2017](#bib.bib142)) &#124;'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Teerapittayanon 等人 ([2017](#bib.bib142)) &#124;'
- en: '&#124; (2017) &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2017) &#124;'
- en: '| Image classification* | Multi-camera multi-object detection (Roig et al.,
    [2011](#bib.bib120)) | Distributed DNNs | A, D | [Link](https://github.com/kunglab/ddnn)
    |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类* | 多摄像头多目标检测 (Roig 等人, [2011](#bib.bib120)) | 分布式 DNNs | A, D | [链接](https://github.com/kunglab/ddnn)
    |'
- en: '|'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Lo et al. ([2017](#bib.bib88)) &#124;'
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Lo 等人 ([2017](#bib.bib88)) &#124;'
- en: '&#124; (2017) &#124;'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2017) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | NiN (Lin
    et al., [2014a](#bib.bib81)) ResNet (He et al., [2016](#bib.bib44)) WRN (Zagoruyko
    and Komodakis, [2016](#bib.bib168)) | A, C |  |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | NiN (Lin 等人, [2014a](#bib.bib81))
    ResNet (He 等人, [2016](#bib.bib44)) WRN (Zagoruyko 和 Komodakis, [2016](#bib.bib168))
    | A, C |  |'
- en: '|'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Neshatpour et al. ([2019](#bib.bib103)) &#124;'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Neshatpour 等人 ([2019](#bib.bib103)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | ImageNet (Russakovsky et al., [2015](#bib.bib121))
    | AlexNet (Krizhevsky et al., [2012](#bib.bib65)) | A, C, L |  |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | ImageNet (Russakovsky 等人, [2015](#bib.bib121)) | AlexNet (Krizhevsky
    等人, [2012](#bib.bib65)) | A, C, L |  |'
- en: '|'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Zeng et al. ([2019](#bib.bib169)) &#124;'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 曾等人 ([2019](#bib.bib169)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | CIFAR-10 (Krizhevsky, [2009](#bib.bib64)) | AlexNet (Krizhevsky
    et al., [2012](#bib.bib65)) | A, D, L |  |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10 (Krizhevsky, [2009](#bib.bib64)) | AlexNet (Krizhevsky et al.,
    [2012](#bib.bib65)) | A, D, L |  |'
- en: '|'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Wang et al. ([2019a](#bib.bib149)) &#124;'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Wang et al. ([2019a](#bib.bib149)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | ResNet (He
    et al., [2016](#bib.bib44)) | A, C |  |'
  id: totrans-243
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) | ResNet (He et al.,
    [2016](#bib.bib44)) | A, C |  |'
- en: '|'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Li et al. ([2019](#bib.bib78)) &#124;'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Li et al. ([2019](#bib.bib78)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) ImageNet
    (2012) (Russakovsky et al., [2015](#bib.bib121)) | MSDNet (Huang et al., [2018](#bib.bib51))
    | A, C | [Link](https://github.com/kalviny/IMTA) |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (2012) (Russakovsky
    et al., [2015](#bib.bib121)) | MSDNet (Huang et al., [2018](#bib.bib51)) | A,
    C | [链接](https://github.com/kalviny/IMTA) |'
- en: '|'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Phuong and Lampert ([2019](#bib.bib109)) &#124;'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Phuong 和 Lampert ([2019](#bib.bib109)) &#124;'
- en: '&#124; (2019) &#124;'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2019) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet
    (2012) (Russakovsky et al., [2015](#bib.bib121)) | MSDNet (Huang et al., [2018](#bib.bib51))
    | A | [Link](https://github.com/mary-phuong/multiexit-distillation) |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (2012) (Russakovsky
    et al., [2015](#bib.bib121)) | MSDNet (Huang et al., [2018](#bib.bib51)) | A |
    [链接](https://github.com/mary-phuong/multiexit-distillation) |'
- en: '|'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Elbayad et al. ([2020](#bib.bib25)) &#124;'
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Elbayad et al. ([2020](#bib.bib25)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Machine translation | IWSLT’14 De-En WMT’14 En-Fr | Transformer (Vaswani
    et al., [2017](#bib.bib146)) | A, C |  |'
  id: totrans-255
  prefs: []
  type: TYPE_TB
  zh: '| 机器翻译 | IWSLT’14 De-En WMT’14 En-Fr | Transformer (Vaswani et al., [2017](#bib.bib146))
    | A, C |  |'
- en: '|'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Wang et al. ([2020b](#bib.bib151)) &#124;'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Wang et al. ([2020b](#bib.bib151)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet
    (2012) (Russakovsky et al., [2015](#bib.bib121)) | ResNet (He et al., [2016](#bib.bib44))
    DenseNet (Huang et al., [2017](#bib.bib52)) | A, C, E |  |'
  id: totrans-259
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (2012) (Russakovsky
    et al., [2015](#bib.bib121)) | ResNet (He et al., [2016](#bib.bib44)) DenseNet (Huang
    et al., [2017](#bib.bib52)) | A, C, E |  |'
- en: '|'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Yang et al. ([2020b](#bib.bib159)) &#124;'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Yang et al. ([2020b](#bib.bib159)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (Russakovsky
    et al., [2015](#bib.bib121)) | RANet | A, C | [Link](https://github.com/yangle15/RANet-pytorch)
    |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (Russakovsky
    et al., [2015](#bib.bib121)) | RANet | A, C | [链接](https://github.com/yangle15/RANet-pytorch)
    |'
- en: '|'
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Soldaini and Moschitti ([2020](#bib.bib133)) &#124;'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Soldaini 和 Moschitti ([2020](#bib.bib133)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Text ranking | WikiQA (Yang et al., [2015](#bib.bib164)), TREC QA (Wang et al.,
    [2007](#bib.bib150)), ASNQ (Garg et al., [2020](#bib.bib33)), GPD | RoBERTa (Liu
    et al., [2019](#bib.bib86)) | A, C | [Link](https://github.com/alexa/wqa-cascade-transformers)
    |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
  zh: '| 文本排名 | WikiQA (Yang et al., [2015](#bib.bib164)), TREC QA (Wang et al., [2007](#bib.bib150)),
    ASNQ (Garg et al., [2020](#bib.bib33)), GPD | RoBERTa (Liu et al., [2019](#bib.bib86))
    | A, C | [链接](https://github.com/alexa/wqa-cascade-transformers) |'
- en: '|'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Liu et al. ([2020](#bib.bib85)) &#124;'
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Liu et al. ([2020](#bib.bib85)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Text classification | ChnSentiCorp, Book review (Qiu et al., [2018](#bib.bib113)),
    Shopping review, Weibo, THUCNews, Ag.News, Amz.F, DBpedia, Yahoo, Yelp.F, Yelp.P (Zhang
    et al., [2015](#bib.bib172)) | BERT (Devlin et al., [2019](#bib.bib22)) | A, C,
    T | [Link](https://github.com/autoliuweijie/FastBERT) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 文本分类 | ChnSentiCorp, 图书评论 (Qiu et al., [2018](#bib.bib113)), 购物评论, 微博, THUCNews,
    Ag.News, Amz.F, DBpedia, Yahoo, Yelp.F, Yelp.P (Zhang et al., [2015](#bib.bib172))
    | BERT (Devlin et al., [2019](#bib.bib22)) | A, C, T | [链接](https://github.com/autoliuweijie/FastBERT)
    |'
- en: '|'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Xin et al. ([2020b](#bib.bib157)) &#124;'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Xin et al. ([2020b](#bib.bib157)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| GLUE (Wang et al., [2019b](#bib.bib147)) | SST-2 (Socher et al., [2013](#bib.bib132)),
    MRPC (Dolan and Brockett, [2005](#bib.bib23)), QQP (Iyer et al., [[n.d.]](#bib.bib55)),
    MNLI (Williams et al., [2018](#bib.bib153)), QNLI (Rajpurkar et al., [2016](#bib.bib115)),
    RTE (Dagan et al., [2005](#bib.bib19); Haim et al., [2006](#bib.bib38); Giampiccolo
    et al., [2007](#bib.bib34); Bentivogli et al., [2009](#bib.bib8)) | BERT (Devlin
    et al., [2019](#bib.bib22)) RoBERTa (Liu et al., [2019](#bib.bib86)) | A, C |
    [Link](https://github.com/castorini/DeeBERT) |'
  id: totrans-275
  prefs: []
  type: TYPE_TB
  zh: '| GLUE (Wang et al., [2019b](#bib.bib147)) | SST-2 (Socher et al., [2013](#bib.bib132)),
    MRPC (Dolan and Brockett, [2005](#bib.bib23)), QQP (Iyer et al., [[n.d.]](#bib.bib55)),
    MNLI (Williams et al., [2018](#bib.bib153)), QNLI (Rajpurkar et al., [2016](#bib.bib115)),
    RTE (Dagan et al., [2005](#bib.bib19); Haim et al., [2006](#bib.bib38); Giampiccolo
    et al., [2007](#bib.bib34); Bentivogli et al., [2009](#bib.bib8)) | BERT (Devlin
    et al., [2019](#bib.bib22)) RoBERTa (Liu et al., [2019](#bib.bib86)) | A, C |
    [链接](https://github.com/castorini/DeeBERT) |'
- en: '|'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Xing et al. ([2020](#bib.bib158)) &#124;'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Xing et al. ([2020](#bib.bib158)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Quality enhancement | RAISE (Dang-Nguyen et al., [2015](#bib.bib20)) | Dynamic
    DNN | A, C | [Link](https://github.com/RyanXingQL/RBQE) |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| 质量提升 | RAISE (Dang-Nguyen et al., [2015](#bib.bib20)) | 动态 DNN | A, C | [链接](https://github.com/RyanXingQL/RBQE)
    |'
- en: '|'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Laskaridis et al. ([2020](#bib.bib68)) &#124;'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Laskaridis et al. ([2020](#bib.bib68)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet
    (2012) (Russakovsky et al., [2015](#bib.bib121)) | ResNet-56 (He et al., [2016](#bib.bib44))
    ResNet-50 (He et al., [2016](#bib.bib44)) Inception-v3 (Szegedy et al., [2016](#bib.bib137))
    | A, E, L |  |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) ImageNet (2012) (Russakovsky
    et al., [2015](#bib.bib121)) | ResNet-56 (He et al., [2016](#bib.bib44)) ResNet-50 (He
    et al., [2016](#bib.bib44)) Inception-v3 (Szegedy et al., [2016](#bib.bib137))
    | A, E, L |  |'
- en: '|'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Xin et al. ([2020a](#bib.bib156)) &#124;'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Xin et al. ([2020a](#bib.bib156)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Text ranking | MS MARCO (Nguyen et al., [2016](#bib.bib105)) ASNQ (Garg et al.,
    [2020](#bib.bib33)) | BERT (Devlin et al., [2019](#bib.bib22)) | A, L | [Link](https://github.com/castorini/earlyexiting-monobert)
    |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| 文本排序 | MS MARCO (Nguyen et al., [2016](#bib.bib105)) ASNQ (Garg et al., [2020](#bib.bib33))
    | BERT (Devlin et al., [2019](#bib.bib22)) | A, L | [链接](https://github.com/castorini/earlyexiting-monobert)
    |'
- en: '|'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Zhou et al. ([2020](#bib.bib173)) &#124;'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Zhou et al. ([2020](#bib.bib173)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| GLUE (Wang et al., [2019b](#bib.bib147)) | CoLA (Warstadt et al., [2019](#bib.bib152)),
    SST-2 (Socher et al., [2013](#bib.bib132)), MRPC (Dolan and Brockett, [2005](#bib.bib23)),
    STS-B (Cer et al., [2017](#bib.bib10)), QQP (Iyer et al., [[n.d.]](#bib.bib55)),
    MNLI (Williams et al., [2018](#bib.bib153)), QNLI (Rajpurkar et al., [2016](#bib.bib115)),
    WNLI (Levesque et al., [2012](#bib.bib72)), RTE (Dagan et al., [2005](#bib.bib19);
    Haim et al., [2006](#bib.bib38); Giampiccolo et al., [2007](#bib.bib34); Bentivogli
    et al., [2009](#bib.bib8)) | BERT (Devlin et al., [2019](#bib.bib22)) ALBERT (Lan
    et al., [2019](#bib.bib67)) | A, C, L, T | [Link](https://github.com/JetRunner/PABEE)
    |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| GLUE (Wang et al., [2019b](#bib.bib147)) | CoLA (Warstadt et al., [2019](#bib.bib152)),
    SST-2 (Socher et al., [2013](#bib.bib132)), MRPC (Dolan and Brockett, [2005](#bib.bib23)),
    STS-B (Cer et al., [2017](#bib.bib10)), QQP (Iyer et al., [[n.d.]](#bib.bib55)),
    MNLI (Williams et al., [2018](#bib.bib153)), QNLI (Rajpurkar et al., [2016](#bib.bib115)),
    WNLI (Levesque et al., [2012](#bib.bib72)), RTE (Dagan et al., [2005](#bib.bib19);
    Haim et al., [2006](#bib.bib38); Giampiccolo et al., [2007](#bib.bib34); Bentivogli
    et al., [2009](#bib.bib8)) | BERT (Devlin et al., [2019](#bib.bib22)) ALBERT (Lan
    et al., [2019](#bib.bib67)) | A, C, L, T | [链接](https://github.com/JetRunner/PABEE)
    |'
- en: '|'
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Matsubara and Levorato ([2021](#bib.bib95)) &#124;'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Matsubara 和 Levorato ([2021](#bib.bib95)) &#124;'
- en: '&#124; (2020) &#124;'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2020) &#124;'
- en: '| Keypoint detection | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | Keypoint
    R-CNN (He et al., [2017a](#bib.bib43)) | A, D, L | [Link](https://github.com/yoshitomo-matsubara/hnd-ghnd-object-detectors)
    |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| 关键点检测 | COCO 2017 (Lin et al., [2014b](#bib.bib84)) | Keypoint R-CNN (He
    et al., [2017a](#bib.bib43)) | A, D, L | [链接](https://github.com/yoshitomo-matsubara/hnd-ghnd-object-detectors)
    |'
- en: '|'
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Garg and Moschitti ([2021](#bib.bib32)) &#124;'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Garg 和 Moschitti ([2021](#bib.bib32)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Text ranking Question answering | WikiQA (Yang et al., [2015](#bib.bib164)),
    ASNQ (Garg et al., [2020](#bib.bib33)) SQuAD 1.1 (Rajpurkar et al., [2016](#bib.bib115))
    | BERT (Devlin et al., [2019](#bib.bib22)) RoBERTa (Liu et al., [2019](#bib.bib86))
    ELECTRA (Clark et al., [2019](#bib.bib16)) | A, L | [Link](https://github.com/alexa/wqa-question-filtering)
    |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| 文本排序 问答 | WikiQA (Yang et al., [2015](#bib.bib164)), ASNQ (Garg et al., [2020](#bib.bib33))
    SQuAD 1.1 (Rajpurkar et al., [2016](#bib.bib115)) | BERT (Devlin et al., [2019](#bib.bib22))
    RoBERTa (Liu et al., [2019](#bib.bib86)) ELECTRA (Clark et al., [2019](#bib.bib16))
    | A, L | [链接](https://github.com/alexa/wqa-question-filtering) |'
- en: '|'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Wołczyk et al. ([2021](#bib.bib154)) &#124;'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Wołczyk et al. ([2021](#bib.bib154)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Image classification | CIFAR-10/100 (Krizhevsky, [2009](#bib.bib64)), Tiny
    ImageNet | ResNet-56 (He et al., [2016](#bib.bib44)) MobileNet (Howard et al.,
    [2017](#bib.bib49)) WideResNet (Zagoruyko and Komodakis, [2016](#bib.bib168))
    VGG-16BN (Simonyan and Zisserman, [2015](#bib.bib129)) | A, L | [Link](https://github.com/gmum/Zero-Time-Waste)
    |'
  id: totrans-303
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-10/100 （Krizhevsky, [2009](#bib.bib64)），Tiny ImageNet | ResNet-56 （He
    et al., [2016](#bib.bib44)），MobileNet （Howard et al., [2017](#bib.bib49)），WideResNet （Zagoruyko
    and Komodakis, [2016](#bib.bib168)），VGG-16BN （Simonyan and Zisserman, [2015](#bib.bib129)）
    | A, L | [链接](https://github.com/gmum/Zero-Time-Waste) |'
- en: '|'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Chiang et al. ([2021](#bib.bib13)) &#124;'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Chiang et al. ([2021](#bib.bib13)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Image classification | CIFAR-100 (Krizhevsky, [2009](#bib.bib64)) | VGG-11 (Simonyan
    and Zisserman, [2015](#bib.bib129)) VGG-13 (Simonyan and Zisserman, [2015](#bib.bib129))
    VGG-16 (Simonyan and Zisserman, [2015](#bib.bib129)) VGG-19 (Simonyan and Zisserman,
    [2015](#bib.bib129)) | A, L |  |'
  id: totrans-307
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | CIFAR-100 （Krizhevsky, [2009](#bib.bib64)） | VGG-11 （Simonyan and
    Zisserman, [2015](#bib.bib129)），VGG-13 （Simonyan and Zisserman, [2015](#bib.bib129)），VGG-16 （Simonyan
    and Zisserman, [2015](#bib.bib129)），VGG-19 （Simonyan and Zisserman, [2015](#bib.bib129)）
    | A, L |  |'
- en: '|'
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Pomponi et al. ([2021](#bib.bib110)) &#124;'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Pomponi et al. ([2021](#bib.bib110)) &#124;'
- en: '&#124; (2021) &#124;'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; (2021) &#124;'
- en: '| Image classification | SVHN (Netzer et al., [[n.d.]](#bib.bib104)), CIFAR-10/100 (Krizhevsky,
    [2009](#bib.bib64)) | AlexNet (Krizhevsky et al., [2012](#bib.bib65)) VGG-11 (Simonyan
    and Zisserman, [2015](#bib.bib129)) ResNet-20 (He et al., [2016](#bib.bib44))
    | A | [Link](https://github.com/jaryP/ConfidenceBranchNetwok) |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
  zh: '| 图像分类 | SVHN （Netzer et al., [[n.d.]](#bib.bib104)），CIFAR-10/100 （Krizhevsky,
    [2009](#bib.bib64)） | AlexNet （Krizhevsky et al., [2012](#bib.bib65)），VGG-11 （Simonyan
    and Zisserman, [2015](#bib.bib129)），ResNet-20 （He et al., [2016](#bib.bib44)）
    | A | [链接](https://github.com/jaryP/ConfidenceBranchNetwok) |'
- en: 'A: Model accuracy, C: Model complexity, D: Transferred data size, E: Energy
    consumption, L: Latency, T: Training cost'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 'A: 模型准确性，C: 模型复杂度，D: 传输数据大小，E: 能源消耗，L: 延迟，T: 训练成本'
- en: '*  The authors extract annotated objects from the original dataset for multi-camera
    object detection, and use the extracted images for an image classification task.'
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: '*  作者从原始数据集中提取注释对象用于多摄像头目标检测，并使用提取的图像进行图像分类任务。'
- en: 5.2\. EE for CV Applications
  id: totrans-314
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2\. 计算机视觉应用中的能效
- en: 'Similar to the SC studies we discussed in Session [4](#S4 "4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges"), the research community mainly focused on EE approaches
    applied to CV tasks.'
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: '与我们在[4](#S4 "4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges")节讨论的SC研究类似，研究界主要关注应用于计算机视觉任务的能效方法。'
- en: Design approaches
  id: totrans-316
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 设计方法
- en: 'Wang et al. ([2020b](#bib.bib151)) propose a unified Dual Dynamic Inference
    that introduces the following features to a DNN model: Input-Adaptive Dynamic
    Inference (IADI) and Resource-Adaptive Dynamic Inference (RADI). The IADI dynamically
    determines which sub-networks to be executed for cost-efficient inference, and
    the RADI leverages the concept of EE to offer “anytime classification”. Using
    the concept of EE, Lo et al. ([2017](#bib.bib88)) proposes two different methods:
    (i) authentic operation, and (ii) dynamic network sizing. The first approach is
    used to determine whether the model input is transferred to the edge server, and
    the latter dynamically adjusts the number of layers to be used as an auxiliary
    neural model deployed on mobile device for efficient usage of communication channels
    in EC systems. Neshatpour et al. ([2019](#bib.bib103)) decomposes a DNN’s inference
    pipeline into multiple stages, and introduce EE (termination) points for energy-efficient
    inference.'
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: Wang et al. ([2020b](#bib.bib151)) 提出了统一的双重动态推理，引入了以下功能到DNN模型中：输入自适应动态推理（IADI）和资源自适应动态推理（RADI）。IADI动态确定需要执行哪些子网络以实现成本效益的推理，而RADI利用能效概念提供“随时分类”。利用能效概念，Lo
    et al. ([2017](#bib.bib88)) 提出了两种不同的方法：（i）真实操作，以及（ii）动态网络尺寸。第一种方法用于确定模型输入是否传输到边缘服务器，第二种方法动态调整层的数量，以便作为在移动设备上部署的辅助神经模型，以有效使用EC系统中的通信通道。Neshatpour
    et al. ([2019](#bib.bib103)) 将DNN的推理管道分解为多个阶段，并引入能效（终止）点以实现能源高效的推理。
- en: Training approaches
  id: totrans-318
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 训练方法
- en: Wang et al. ([2019a](#bib.bib149)) focus on training methods for DNN s with
    an early exit and observes that prior EE approaches suffered from the burden of
    manually tuning balancing weights of early exit losses to find a good trade-off
    between computational complexity and overall accuracy. To address this problem,
    the authors propose a strategy to dynamically adjust the loss weights for the
    ResNet models they consider. Li et al. ([2019](#bib.bib78)) and Phuong and Lampert
    ([2019](#bib.bib109)) introduce multiple early exits to DNN models and apply knowledge
    distillation to each of the early exits as students, using their final classifiers
    as teacher models. Similar to other studies, the DNN s with early exits are designed
    to finish inference for “easy” samples by early sub-classifiers based on confidence
    thresholds defined beforehand.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: Wang等人（[2019a](#bib.bib149)）专注于具有早期退出的DNN训练方法，并观察到先前的EE方法在手动调整早期退出损失的平衡权重以找到计算复杂性和整体准确性之间的良好折衷时存在负担。为了解决这个问题，作者提出了一种动态调整他们考虑的ResNet模型损失权重的策略。Li等人（[2019](#bib.bib78)）和Phuong与Lampert（[2019](#bib.bib109)）将多个早期退出引入DNN模型，并对每个早期退出应用知识蒸馏，将其最终分类器作为教师模型。类似于其他研究，具有早期退出的DNN设计用于通过基于预先定义的置信度阈值的早期子分类器完成“简单”样本的推理。
- en: Inference approaches
  id: totrans-320
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 推理方法
- en: Yang et al. ([2020b](#bib.bib159)) leverage EE strategies for multi-scale inputs,
    and propose an approach to classify “easy” samples with smaller neural models.
    Different from prior studies, their proposed approach scales up the input image
    (use higher-resolution image as input), depending on the classification difficulty
    of the sample. Laskaridis et al. ([2020](#bib.bib68)) design a distributed inference
    system that employs synergistic device-cloud computation for collaborative inference,
    including an EE strategy (referred to as progressive inference in their work).
    Xing et al. ([2020](#bib.bib158)) apply EE strategies to quality enhancement tasks
    and propose a resource-efficient blind quality enhancement approach for compressed
    images. By identifying “easy” samples in the tasks, they dynamically process input
    samples with/without early exits. Zeng et al. ([2019](#bib.bib169)) combine EE
    and SC approaches, and propose a framework named Boomerang, which is designed
    to automate end-to-end DNN inference planning for IoT scenarios; they introduce
    multiple early exits in AlexNet (Krizhevsky et al., [2012](#bib.bib65)). Their
    proposed framework profiles the model to decide its partition (splitting) point.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: Yang等人（[2020b](#bib.bib159)）利用EE策略处理多尺度输入，并提出了一种使用较小神经网络模型来分类“简单”样本的方法。与之前的研究不同，他们提出的方法通过扩大输入图像（使用高分辨率图像作为输入），根据样本的分类难度来进行调整。Laskaridis等人（[2020](#bib.bib68)）设计了一个分布式推理系统，利用协同设备-云计算进行联合推理，包括一种EE策略（在他们的工作中称为渐进推理）。Xing等人（[2020](#bib.bib158)）将EE策略应用于质量增强任务，并提出了一种资源高效的压缩图像盲质量增强方法。通过识别任务中的“简单”样本，他们动态处理带有/不带早期退出的输入样本。Zeng等人（[2019](#bib.bib169)）将EE和SC方法结合，提出了一个名为Boomerang的框架，该框架旨在为IoT场景自动化端到端DNN推理规划；他们在AlexNet（Krizhevsky等人，[2012](#bib.bib65)）中引入了多个早期退出。他们提出的框架对模型进行分析，以决定其划分（拆分）点。
- en: In addition to introducing and training bottleneck points for object detector,
    Matsubara and Levorato ([2021](#bib.bib95)) introduce a *neural filter* in an
    early stage of the head-distilled Keypoint R-CNN model. Similarly to EE frameworks,
    the filter identifies pictures without objects of interest and trigger termination
    of the execution before the output of the bottleneck is forwarded. Wołczyk et al.
    ([2021](#bib.bib154)) propose Zero Time Waste, a method in which each early exit
    reuses predictions returned by its predecessors. The method adds direct connections
    between early exits and combines outputs of the previous early exits like an ensemble
    model. Through experiments with multiple image classification datasets and model
    architectures, they demonstrate that their proposed method improves a tradeoff
    between accuracy and inference time comparing to other early exit methods. Extending
    the idea of BranchyNet (Teerapittayanon et al., [2016](#bib.bib141)), Chiang et al.
    ([2021](#bib.bib13)) formulate the early-exit (branch) placement problem. They
    propose a dynamic programming algorithm to address the problem and discuss the
    tradeoff between model accuracy and inference time. Pomponi et al. ([2021](#bib.bib110))
    introduce multiple early exits to a classifier and train the entire multi-exit
    model jointly. Using multiple base models, they discuss various early-exit stopping
    criteria. Many studies on EE for CV tasks publish their source code to ensure
    replicability of their work.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
  zh: 除了为目标检测器引入和训练瓶颈点外，Matsubara 和 Levorato ([2021](#bib.bib95)) 在头部蒸馏 Keypoint R-CNN
    模型的早期阶段引入了 *神经滤波器*。类似于 EE 框架，该滤波器识别不含感兴趣对象的图片，并在瓶颈输出之前触发终止执行。Wołczyk 等人 ([2021](#bib.bib154))
    提出了 Zero Time Waste，一种在每次早期退出时重用其前驱预测的方法。该方法在早期退出之间添加了直接连接，并像集成模型一样结合了先前早期退出的输出。通过在多个图像分类数据集和模型架构上的实验，他们展示了其提出的方法在准确性和推断时间之间的权衡，相较于其他早期退出方法有显著改善。扩展
    BranchyNet (Teerapittayanon et al., [2016](#bib.bib141)) 的思路，Chiang 等人 ([2021](#bib.bib13))
    形成了早期退出（分支）放置问题。他们提出了一种动态编程算法来解决这个问题，并讨论了模型准确性和推断时间之间的权衡。Pomponi 等人 ([2021](#bib.bib110))
    向分类器引入了多个早期退出，并联合训练整个多退出模型。利用多个基础模型，他们讨论了各种早期退出停止标准。许多关于 CV 任务 EE 的研究公开了其源代码，以确保其工作的可重复性。
- en: 5.3\. EE for NLP Applications
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3\. NLP 应用中的 EE
- en: 'Interestingly, EE approaches have been widely studied not only in CV tasks
    – the main application of SC– but also NLP tasks. Recent studies introduce subbranches
    (early exits) to transformer-based models such as BERT (Devlin et al., [2019](#bib.bib22)).
    While these transformer-based models achieve state of the art performance in NLP
    tasks, they have an extremely large number of parameters, *e.g.*, BERT (Devlin
    et al., [2019](#bib.bib22)) has up to 355 million parameters where the largest
    image classification model used in SC studies (Tables  [1](#S4.T1 "Table 1 ‣ 4.1\.
    Split Computing without DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges") and  [3](#S4.T3 "Table 3 ‣ 4.3\. Split Computing with Bottleneck
    Injection ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges")), ResNet-152,
    has 60 million parameters.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: '有趣的是，EE 方法不仅在 CV 任务中（SC 的主要应用）被广泛研究，而且在 NLP 任务中也得到了关注。近期研究在基于 Transformer 的模型如
    BERT (Devlin et al., [2019](#bib.bib22)) 中引入了子分支（早期退出）。尽管这些基于 Transformer 的模型在
    NLP 任务中达到了最先进的性能，但它们的参数数量极其庞大，例如 BERT (Devlin et al., [2019](#bib.bib22)) 具有高达
    3.55 亿个参数，而 SC 研究中使用的最大图像分类模型（表 [1](#S4.T1 "Table 1 ‣ 4.1\. Split Computing without
    DNN Modification ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges") 和 [3](#S4.T3
    "Table 3 ‣ 4.3\. Split Computing with Bottleneck Injection ‣ 4\. Split Computing:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges")），ResNet-152，具有 6000 万个参数。'
- en: In Elbayad et al. ([2020](#bib.bib25)) an EE technique for NLP tasks is developed
    for transformer sequence-to-sequence models (Vaswani et al., [2017](#bib.bib146))
    in machine translation tasks. The decoder networks in the considered transformer
    models can be trained by either aligned training or mixed training methods. The
    former method optimizes all classifiers in the decoder network simultaneously.
    However, when a different classifier (exit) is chosen for each token (*e.g.*,
    word) at test time, some of the hidden states from previous time steps may be
    missed and then the input states to the following decoder network will be misaligned
    (mismatched). The latter method addresses this issue. In mixed sample training,
    several paths of random exits are sampled at which the model is assumed to have
    exited for reducing the mismatch by feeding hidden states from different decoder
    depths of previous time steps.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在 Elbayad 等人 ([2020](#bib.bib25)) 的研究中，为 transformer 序列到序列模型（Vaswani 等人，[2017](#bib.bib146)）在机器翻译任务中开发了一种
    EE 技术。所考虑的 transformer 模型中的解码器网络可以通过对齐训练或混合训练方法进行训练。前者方法同时优化解码器网络中的所有分类器。然而，当在测试时为每个标记（*例如*，单词）选择不同的分类器（退出）时，可能会遗漏来自先前时间步的一些隐藏状态，从而使输入状态到后续解码器网络不对齐（不匹配）。后者方法解决了这个问题。在混合样本训练中，从不同的解码器深度的先前时间步中馈送隐藏状态，以减少不匹配，模型被假定在随机退出的多个路径上退出。
- en: For different tasks, Soldaini and Moschitti ([2020](#bib.bib133)), Xin et al.
    ([2020b](#bib.bib157)) and Liu et al. ([2020](#bib.bib85)) propose EE frameworks
    based on BERT (Devlin et al., [2019](#bib.bib22)) and RoBERTa (Liu et al., [2019](#bib.bib86))
    that share almost the same network architecture. Focused on text ranking, specifically
    answer sentence selection tasks with question answering datasets, Soldaini and
    Moschitti ([2020](#bib.bib133)) add classification layers to intermediate stages
    of RoBERTa to build sequential (neural) rerankers (Matsubara et al., [2020b](#bib.bib96))
    inside as early exits, and propose the Cascade Transformer models. Focusing on
    powerful transformer models for industrial scenarios, Liu et al. ([2020](#bib.bib85))
    discuss the effectiveness on twelve (six English and six Chinese) NLP datasets
    of BERT models when early classifiers are introduced. Similar to the studies by
    Li et al. ([2019](#bib.bib78)) and Phuong and Lampert ([2019](#bib.bib109)), Liu
    et al. ([2020](#bib.bib85)) leverage knowledge distillation (Hinton et al., [2014](#bib.bib47))
    to train early classifiers, treating the final classifier of the BERT model and
    their introduced early classifiers as a teacher and student classifiers, respectively.
    Xin et al. ([2020b](#bib.bib157)) target general language understanding evaluation
    (GLUE) tasks (Wang et al., [2019b](#bib.bib147)), and introduce early exits after
    each of 12 transformer blocks in BERT and RoBERTa models.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 对于不同的任务，Soldaini 和 Moschitti ([2020](#bib.bib133))、Xin 等人 ([2020b](#bib.bib157))
    和 Liu 等人 ([2020](#bib.bib85)) 提出了基于 BERT（Devlin 等人，[2019](#bib.bib22)）和 RoBERTa（Liu
    等人，[2019](#bib.bib86)）的 EE 框架，这些框架几乎共享相同的网络架构。针对文本排序，特别是回答句子选择任务（使用问答数据集），Soldaini
    和 Moschitti ([2020](#bib.bib133)) 在 RoBERTa 的中间阶段添加了分类层，以构建作为早期退出的顺序（神经）重排序器（Matsubara
    等人，[2020b](#bib.bib96)），并提出了 Cascade Transformer 模型。针对工业场景中的强大 transformer 模型，Liu
    等人 ([2020](#bib.bib85)) 讨论了在引入早期分类器时 BERT 模型在十二个（六个英文和六个中文）NLP 数据集上的有效性。类似于 Li
    等人 ([2019](#bib.bib78)) 和 Phuong 与 Lampert ([2019](#bib.bib109)) 的研究，Liu 等人 ([2020](#bib.bib85))
    利用知识蒸馏（Hinton 等人，[2014](#bib.bib47)）来训练早期分类器，将 BERT 模型的最终分类器与他们引入的早期分类器分别视为教师分类器和学生分类器。Xin
    等人 ([2020b](#bib.bib157)) 针对通用语言理解评估（GLUE）任务（Wang 等人，[2019b](#bib.bib147)），并在
    BERT 和 RoBERTa 模型中的每个 12 个 transformer 块后引入早期退出。
- en: While the Cascade Transformer (Soldaini and Moschitti, [2020](#bib.bib133))
    disregards a fixed portion of candidates (samples) given a query in answer sentence
    selection tasks, Xin et al. ([2020a](#bib.bib156)) use a score-based EE strategy
    for a BERT architecture for text ranking tasks. Zhou et al. ([2020](#bib.bib173))
    introduce early classifiers to BERT and ALBERT (Lan et al., [2019](#bib.bib67))
    models and discusses adversarial robustness using the ALBERT models with and without
    the early exits. Using an adversarial attack method (Jin et al., [2020](#bib.bib60)),
    the authors feed perturbed input data (called adversarial examples (Kurakin et al.,
    [2016](#bib.bib66))) to their trained models and show how robust their models
    are against the adversarial attack, compared to those without early classifiers.
    Garg and Moschitti ([2021](#bib.bib32)) propose an approach to filter out questions
    in answer sentence selection and question answering tasks. Leveraging the concept
    of knowledge distillation, they train a question filter model (student), whose
    input is a query, by mimicking the top-1 candidate score of the answer model (teacher),
    whose input is a pair of query and the list of the candidate answers. When the
    trained question filter model finds a query answerable for the answer model, the
    subsequent inference pipeline will be executed. Otherwise, the question filter
    model terminates the inference process for the query (*i.e.*, early exit) to save
    the overall inference cost.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管Cascade Transformer (Soldaini和Moschitti, [2020](#bib.bib133))在答案句子选择任务中忽略了给定查询的固定候选样本，Xin
    et al. ([2020a](#bib.bib156))为文本排序任务使用了基于评分的EE策略应用于BERT架构。Zhou et al. ([2020](#bib.bib173))引入了早期分类器到BERT和ALBERT (Lan
    et al., [2019](#bib.bib67))模型中，并讨论了使用带或不带早期退出的ALBERT模型的对抗性鲁棒性。使用对抗攻击方法 (Jin et al.,
    [2020](#bib.bib60))，作者向其训练的模型输入了扰动数据（称为对抗样本 (Kurakin et al., [2016](#bib.bib66)))，并展示了他们的模型在对抗攻击下的鲁棒性，相比于那些没有早期分类器的模型。Garg和Moschitti
    ([2021](#bib.bib32)) 提出了在答案句子选择和问题回答任务中过滤问题的方法。利用知识蒸馏的概念，他们训练了一个问题过滤模型（学生），其输入是一个查询，通过模仿答案模型（教师）的top-1候选分数来实现，答案模型的输入是一个查询和候选答案列表。当训练的问答过滤模型找到一个答案模型可回答的查询时，后续的推理流程将会执行。否则，问题过滤模型将终止查询的推理过程（*即*，早期退出）以节省整体推理成本。
- en: 'Most of the studies on EE for NLP tasks in Table [4](#S5.T4 "Table 4 ‣ 5.1\.
    Rationale behind EE ‣ 5\. Early Exiting: A Survey ‣ Split Computing and Early
    Exiting for Deep Learning Applications: Survey and Research Challenges") are published
    with source code to assure replicable results. Notably, this application domain
    enjoys a well-generalized open source framework – Huggingface’s Transformers (Wolf
    et al., [2020](#bib.bib155)) – which provides state-of-the-art (pretrained) Transformer
    models, including the BERT, RoBERTa, and ALBERT models used in the above studies.'
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 表[4](#S5.T4 "表4 ‣ 5.1\. EE的基本原理 ‣ 5\. 早期退出：综述 ‣ 深度学习应用中的分割计算与早期退出：综述与研究挑战")中大多数关于NLP任务的EE研究都发布了源代码，以确保结果可重复。值得注意的是，这个应用领域享有一个广泛应用的开源框架——Huggingface的Transformers (Wolf
    et al., [2020](#bib.bib155))——提供了最先进的（预训练）Transformer模型，包括在上述研究中使用的BERT、RoBERTa和ALBERT模型。
- en: 5.4\. Training Methodologies for EE Strategies
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.4\. EE策略的训练方法
- en: 'To introduce EE strategies, the early classifiers need to be trained in addition
    to the base models. We can categorize the training methodologies used in EE studies
    into two main classes: *joint training* and *separate training*, illustrated in
    Fig. [8](#S5.F8 "Figure 8 ‣ 5.4\. Training Methodologies for EE Strategies ‣ 5\.
    Early Exiting: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges") and described in the next sections.'
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 为了引入EE策略，除了基本模型之外，还需要训练早期分类器。我们可以将EE研究中使用的训练方法分类为两大类：*联合训练*和*独立训练*，如图[8](#S5.F8
    "图8 ‣ 5.4\. EE策略的训练方法 ‣ 5\. 早期退出：综述 ‣ 深度学习应用中的分割计算与早期退出：综述与研究挑战")所示，并在下一节中进行描述。
- en: '![Refer to caption](img/08e6990391de97ac011da0dbdc0dc170.png)'
  id: totrans-331
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/08e6990391de97ac011da0dbdc0dc170.png)'
- en: Figure 8\. Examples of joint and separate training methods for DNN with early
    exits.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 图8\. 具有早期退出的DNN的联合和独立训练方法示例。
- en: Joint training
  id: totrans-333
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 联合训练
- en: 'Most of the training methods used in existing works belong to this category.
    Joint training trains all the (early) classifiers in a model simultaneously (left
    part of Fig. [8](#S5.F8 "Figure 8 ‣ 5.4\. Training Methodologies for EE Strategies
    ‣ 5\. Early Exiting: A Survey ‣ Split Computing and Early Exiting for Deep Learning
    Applications: Survey and Research Challenges")). Specifically, these studies (Teerapittayanon
    et al., [2016](#bib.bib141), [2017](#bib.bib142); Lo et al., [2017](#bib.bib88);
    Zeng et al., [2019](#bib.bib169); Wang et al., [2019a](#bib.bib149); Elbayad et al.,
    [2020](#bib.bib25); Wang et al., [2020b](#bib.bib151); Yang et al., [2020b](#bib.bib159);
    Soldaini and Moschitti, [2020](#bib.bib133); Xing et al., [2020](#bib.bib158);
    Laskaridis et al., [2020](#bib.bib68); Xin et al., [2020a](#bib.bib156); Zhou
    et al., [2020](#bib.bib173); Pomponi et al., [2021](#bib.bib110)) define a loss
    function for each of the classifier, and minimize the weighted sum of cross entropy
    losses per sample as follows:'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: '现有作品中使用的大多数训练方法属于这一类别。联合训练同时训练模型中的所有（早期）分类器（图. [8](#S5.F8 "Figure 8 ‣ 5.4\.
    Training Methodologies for EE Strategies ‣ 5\. Early Exiting: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges")左侧）。具体而言，这些研究（Teerapittayanon et al., [2016](#bib.bib141), [2017](#bib.bib142);
    Lo et al., [2017](#bib.bib88); Zeng et al., [2019](#bib.bib169); Wang et al.,
    [2019a](#bib.bib149); Elbayad et al., [2020](#bib.bib25); Wang et al., [2020b](#bib.bib151);
    Yang et al., [2020b](#bib.bib159); Soldaini and Moschitti, [2020](#bib.bib133);
    Xing et al., [2020](#bib.bib158); Laskaridis et al., [2020](#bib.bib68); Xin et al.,
    [2020a](#bib.bib156); Zhou et al., [2020](#bib.bib173); Pomponi et al., [2021](#bib.bib110)）为模型中的每个分类器定义损失函数，并最小化每个样本的交叉熵损失的加权和，如下所示：'
- en: '| (8) |  | $\mathcal{L}_{\text{Joint}}([\mathbf{\hat{y}}^{1},\cdots,\mathbf{\hat{y}}^{N}],c)=\sum_{j=1}^{N}\lambda_{j}\mathcal{L}_{\text{CE}}(\mathbf{\hat{y}}^{j},c),$
    |  |'
  id: totrans-335
  prefs: []
  type: TYPE_TB
  zh: '| (8) |  | $\mathcal{L}_{\text{联合}}([\mathbf{\hat{y}}^{1},\cdots,\mathbf{\hat{y}}^{N}],c)=\sum_{j=1}^{N}\lambda_{j}\mathcal{L}_{\text{CE}}(\mathbf{\hat{y}}^{j},c),$
    |  |'
- en: where $[\mathbf{\hat{y}}^{1},\cdots,\mathbf{\hat{y}}^{N}]$ indicates outputs
    from $N$ (early) classifiers, and the correct label $c$ is shared across all the
    classifiers in a model. Note that the base model (final classifier) is also counted
    as one of the $N$ classifiers, and $N-1$ early classifiers are introduced to the
    base model.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $[\mathbf{\hat{y}}^{1},\cdots,\mathbf{\hat{y}}^{N}]$ 表示来自 $N$ 个（早期）分类器的输出，而正确标签
    $c$ 在模型的所有分类器之间共享。请注意，基础模型（最终分类器）也算作 $N$ 个分类器之一，基础模型引入了 $N-1$ 个早期分类器。
- en: 'Instead, Li et al. ([2019](#bib.bib78)); Phuong and Lampert ([2019](#bib.bib109))
    use a knowledge distillation-based loss such as Eq. ([3](#S4.E3 "In Knowledge
    distillation ‣ 4\. Split Computing: A Survey ‣ Split Computing and Early Exiting
    for Deep Learning Applications: Survey and Research Challenges")) by treating
    the final classifier (last exit) as teacher model and all the early classifiers
    as student models. This approach is based on the assumption that the last classifier
    will achieve the highest accuracy among all the (early) classifiers in the model,
    and early classifiers (students) could learn from the last classifier as a teacher
    model.'
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: '反而，Li等人([2019](#bib.bib78)); Phuong and Lampert ([2019](#bib.bib109)) 使用基于知识蒸馏的损失，如等式([3](#S4.E3
    "In Knowledge distillation ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges"))，将最终分类器（最后退出）视为教师模型，而将所有早期分类器视为学生模型。该方法基于这样的假设，即最后的分类器将在模型中获得最高的准确性，并且早期分类器（学生）可以从最后的分类器作为教师模型中学习。'
- en: Separate training
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分开训练
- en: 'A few studies (Liu et al., [2020](#bib.bib85); Xin et al., [2020b](#bib.bib157);
    Matsubara and Levorato, [2021](#bib.bib95); Garg and Moschitti, [2021](#bib.bib32))
    suggest training the early classifiers separately. This approach can be interpreted
    as a two-stage training paradigm that trains a model in the first stage and then
    trains the early classifiers introduced to the pretrained model whose parameters
    are fixed in the second stage (See Fig. [8](#S5.F8 "Figure 8 ‣ 5.4\. Training
    Methodologies for EE Strategies ‣ 5\. Early Exiting: A Survey ‣ Split Computing
    and Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    (right)). For instance, Xin et al. ([2020b](#bib.bib157)) fine-tune a BERT model
    in the first stage following Devlin et al. ([2019](#bib.bib22)). Then, the early
    classifiers are introduced in the model and trained while all the parameters of
    the BERT model learnt in the first stage are kept frozen. Liu et al. ([2020](#bib.bib85))
    adopt a similar approach, but in the second training stage, knowledge distillation
    is used to train the early classifiers. Different from SC studies using knowledge
    distillation, the teacher model is fixed, and only the additional parameters corresponding
    to the early classifiers are trained. Wołczyk et al. ([2021](#bib.bib154)) introduce
    early exits to a pretrained model. Using the cross entropy loss, they train the
    introduced early exits.'
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: '一些研究（刘等，[2020](#bib.bib85)；辛等，[2020b](#bib.bib157)；松原和莱沃拉托，[2021](#bib.bib95)；加格和莫斯基提，[2021](#bib.bib32)）建议分别训练早期分类器。这种方法可以被理解为一种两阶段训练范式：第一阶段训练一个模型，然后在第二阶段将早期分类器引入到预训练模型中，模型参数在第二阶段保持固定（见图[8](#S5.F8
    "Figure 8 ‣ 5.4\. Training Methodologies for EE Strategies ‣ 5\. Early Exiting:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges")（右））。例如，辛等（[2020b](#bib.bib157)）在第一阶段根据德夫林等（[2019](#bib.bib22)）微调了BERT模型。然后，将早期分类器引入模型中进行训练，同时保持在第一阶段学习到的BERT模型的所有参数不变。刘等（[2020](#bib.bib85)）采用类似的方法，但在第二阶段训练早期分类器时使用了知识蒸馏。与使用知识蒸馏的SC研究不同，教师模型是固定的，只有与早期分类器对应的附加参数被训练。Wołczyk等（[2021](#bib.bib154)）将早期退出引入预训练模型中。他们使用交叉熵损失训练引入的早期退出。'
- en: '6\. Split Computing and Early Exiting: Research Challenges'
  id: totrans-340
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6\. 分割计算与早期退出：研究挑战
- en: In this section, we describe some of the research challenges in the SC and EE
    domains.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们描述了SC和EE领域的一些研究挑战。
- en: Evaluation of SC and EE in more practical settings
  id: totrans-342
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 在更实际的环境中对SC和EE的评估
- en: 'Due to the cross-disciplinary nature of this research area, it is essential
    to design practical and convincing evaluation settings to demonstrate the effectiveness
    of proposed approaches. As shown in Tables [3](#S4.T3 "Table 3 ‣ 4.3\. Split Computing
    with Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣ Split Computing and
    Early Exiting for Deep Learning Applications: Survey and Research Challenges")
    and [4](#S5.T4 "Table 4 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges"), the techniques proposed in many of the recent related studies
    are validated only on small-scale datasets such as MNIST and CIFAR datasets, which
    leads to some concerns on the input data size in relation with compression. Indeed,
    Table [2](#S4.T2 "Table 2 ‣ 4.2\. The Need for Bottleneck Injection ‣ 4\. Split
    Computing: A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications:
    Survey and Research Challenges") suggests that the input data size in many of
    such datasets is relatively small (*e.g.*, smaller than 2 kilobytes per image
    with a resolution of $32\times 32$ pixels). The low-resolution of the input size
    may enable conventional EC, where the mobile device fully offloads the computing
    task by transferring the input data to an edge server. In fact, the transmission
    of such a small amount of data would require a short time even in settings with
    limited communication capacity. As a consequence, executing even small head models
    on a resource-limited mobile device could lead to an overall delay increase.'
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: '由于该研究领域的跨学科性质，设计切实可行且令人信服的评估设置以展示提出的方法的有效性至关重要。如表[3](#S4.T3 "Table 3 ‣ 4.3\.
    Split Computing with Bottleneck Injection ‣ 4\. Split Computing: A Survey ‣ Split
    Computing and Early Exiting for Deep Learning Applications: Survey and Research
    Challenges")和[4](#S5.T4 "Table 4 ‣ 5.1\. Rationale behind EE ‣ 5\. Early Exiting:
    A Survey ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey
    and Research Challenges")所示，许多近期相关研究中提出的技术仅在小规模数据集如MNIST和CIFAR数据集上进行验证，这引发了对输入数据规模与压缩相关性的担忧。实际上，表[2](#S4.T2
    "Table 2 ‣ 4.2\. The Need for Bottleneck Injection ‣ 4\. Split Computing: A Survey
    ‣ Split Computing and Early Exiting for Deep Learning Applications: Survey and
    Research Challenges")表明，许多此类数据集的输入数据规模相对较小（*例如*，每张图像小于2千字节，分辨率为$32\times 32$像素）。输入尺寸的低分辨率可能使得传统的早期退出（EC）成为可能，其中移动设备通过将输入数据传输到边缘服务器来完全卸载计算任务。实际上，即使在通信能力有限的环境中，传输如此少量的数据也需要很短的时间。因此，在资源有限的移动设备上执行即便是小型头部模型也可能导致整体延迟增加。'
- en: Based on the above discussion, it becomes apparent that the models and datasets,
    in addition to the wireless and computing environments, are of paramount importance
    when assessing the performance of SC and EE schemes. Of particular relevance is
    the evaluation of accuracy, which is not provided in some of the early studies
    (*e.g.*, (Sandler et al., [2018](#bib.bib123); He et al., [2016](#bib.bib44);
    Simonyan and Zisserman, [2015](#bib.bib129))) and the consideration of state-of-the-art
    models and datasets which are largely used in the machine learning community.
    For instance, the use of small models, such as MobileNetV2, ResNet-50, VGG-16,
    which are likely overparameterized for simple classification tasks, could lead
    to wrong conclusions when injecting bottlenecks. Conversely, it was shown in (Matsubara
    et al., [2019](#bib.bib91)) how challenging it is to inject bottlenecks when considering
    complex vision tasks such as classification on the ImageNet dataset (Russakovsky
    et al., [2015](#bib.bib121)).
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 基于上述讨论，显然，模型和数据集，以及无线和计算环境，在评估分割计算（SC）和早期退出（EE）方案的性能时至关重要。特别相关的是准确性评估，在一些早期研究中并未提供（*例如*，（Sandler等，[2018](#bib.bib123)；He等，[2016](#bib.bib44)；Simonyan和Zisserman，[2015](#bib.bib129)））以及考虑在机器学习社区广泛使用的最先进模型和数据集。例如，使用像MobileNetV2、ResNet-50、VGG-16这样的较小模型，它们可能对简单的分类任务来说参数过多，可能会在注入瓶颈时得出错误结论。相反，（Matsubara等，[2019](#bib.bib91)）展示了在考虑复杂视觉任务如在ImageNet数据集（Russakovsky等，[2015](#bib.bib121)）上进行分类时，注入瓶颈的挑战。
- en: Optimization of bottleneck design and placement in SC
  id: totrans-345
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 分割计算中瓶颈设计和放置的优化
- en: 'The study of the architecture and placement of the bottleneck in a DNN model
    is also of considerable importance. As suggested in (Matsubara et al., [2022b](#bib.bib97)),
    important metrics include: (i) bottleneck data size (or compression rate), (ii)
    complexity of head model executed on mobile device, and (iii) resulting model
    accuracy. As a principle, the smaller the bottleneck representation is, the lower
    the communication cost between mobile device and edge server will be. In general,
    the objective of SC is to generate a bottleneck whose data size is smaller than
    that of input data such as JPEG file size of input data, which is in turn much
    smaller than data size of input tensor (32-bit floating point), as the communication
    delay is a key component to reduce overall inference time (Matsubara et al., [2019](#bib.bib91);
    Yang et al., [2020b](#bib.bib159); Matsubara et al., [2020a](#bib.bib92); Matsubara
    and Levorato, [2021](#bib.bib95)). Secondly, since mobile devices often have limited
    computing resources and may have other constraints such as energy consumption
    due to their battery capacities, SC should aim at minimizing their computational
    load by making head models as lightweight as possible. For instance, designing
    a small bottleneck at a very early stage of the DNN model enables a reduction
    in the computational complexity of the head model (Matsubara and Levorato, [2020](#bib.bib94),
    [2021](#bib.bib95)).'
  id: totrans-346
  prefs: []
  type: TYPE_NORMAL
  zh: 对于DNN模型中瓶颈的架构和位置的研究也非常重要。如(Matsubara et al., [2022b](#bib.bib97))所建议，重要的指标包括：(i)瓶颈数据大小（或压缩率），(ii)在移动设备上执行的头模型复杂性，以及(iii)结果模型的准确性。原则上，瓶颈表示越小，移动设备与边缘服务器之间的通信成本就越低。一般来说，SC的目标是生成一个瓶颈，其数据大小小于输入数据的大小，例如JPEG文件的大小，这比输入张量（32位浮点数）的数据大小要小得多，因为通信延迟是减少整体推断时间的关键组成部分
    (Matsubara et al., [2019](#bib.bib91); Yang et al., [2020b](#bib.bib159); Matsubara
    et al., [2020a](#bib.bib92); Matsubara and Levorato, [2021](#bib.bib95))。其次，由于移动设备通常计算资源有限，且可能存在电池容量等其他约束条件，SC应致力于通过尽可能简化头模型来最小化计算负载。例如，在DNN模型的早期阶段设计一个小瓶颈可以减少头模型的计算复杂性
    (Matsubara and Levorato, [2020](#bib.bib94), [2021](#bib.bib95))。
- en: On top of these two criteria, the resulting model accuracy by the bottleneck
    injection should not be compromised as the introduced bottleneck removes more
    or less information at the placement compared to the original model. A reasonable
    lower bound of the model accuracy in SC would be that of widely recognized lightweight
    models *e.g.,* MobileNetV2 (Sandler et al., [2018](#bib.bib123)) for ImageNet
    dataset, considering a local computing system where such lightweight models can
    be efficiently executed. In general, it is challenging to optimize bottleneck
    design and placement with respect to all the three different metrics, and existing
    studies empirically design the bottlenecks and determine the placements. Thus,
    theoretical discussion on bottleneck design and placement should be an interesting
    research topic for future work.
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 除了这两个标准外，瓶颈注入后模型的准确性不应受到损害，因为引入的瓶颈在位置上会比原始模型多或少地去除信息。在SC中，模型准确性的合理下限应为广泛认可的轻量级模型*例如*，MobileNetV2
    (Sandler et al., [2018](#bib.bib123))，适用于ImageNet数据集，考虑到可以高效执行这些轻量级模型的本地计算系统。一般来说，很难在所有三个不同的指标上优化瓶颈设计和位置，现有研究经验性地设计瓶颈并确定位置。因此，瓶颈设计和位置的理论讨论应成为未来工作的有趣研究主题。
- en: Dynamic control of exits in EE
  id: totrans-348
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: EE中的退出动态控制
- en: In most of the recent studies, early exits are used when one of the introduced
    early classifiers (exits) is confident enough in its prediction. However, users
    are required to determine a threshold for each of the classifiers beforehand at
    least for one early classifier in the original model where we introduce the early
    classifier to. For example, if the first classifier’s prediction score is greater
    than 0.9 in range of 0.0 and 1.0, then the inference for the input is terminated.
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数近期研究中，当引入的早期分类器（出口）对其预测足够自信时，通常会使用早期退出。然而，用户需要为原始模型中每个分类器预先确定一个阈值，至少要为一个早期分类器设定。例如，如果第一个分类器的预测分数在0.0到1.0的范围内大于0.9，则会终止对输入的推断。
- en: To achieve more efficient inference without significantly sacrificing the accuracy
    of the original model, the system needs to find a balance between (early) classifiers.
    As recent studies introduce multiple early exits to a model at different stages,
    such optimizations are challenging. In addition to manually defining such a threshold
    for each of the classifiers based on empirical results, a possibly interesting
    direction is the optimization of the decision-making process, that is, at which
    (early) classifier we should terminate the inference for a given input, without
    a set of thresholds defined beforehand based on system characteristics.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在不显著牺牲原始模型准确性的情况下实现更高效的推断，系统需要在（早期）分类器之间找到平衡。由于最近的研究在不同阶段向模型引入了多个早期退出点，这样的优化是具有挑战性的。除了基于经验结果手动为每个分类器定义这样的阈值外，一个可能有趣的方向是决策过程的优化，即对于给定输入，我们应该在哪个（早期）分类器终止推断，而无需根据系统特性事先定义一组阈值。
- en: Expanding the Application Domain of SC and EE
  id: totrans-351
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 扩展 SC 和 EE 的应用领域
- en: The application domains of SC and (in minor part) EE remain primarily focused
    on image classification. This focus may be explained by the size of the input,
    which makes compression a relevant problem in many settings and the complexity
    of the models and tasks. However, there are many other unexplored domains which
    SC would benefit. Real-time health conditions monitoring via wearable sensors
    is a notable example of application where a significant amount of data is transferred
    from sensors to edge servers such as cellular phones and home hubs. For instance,
    the detection and monitoring of heart anomalies (*e.g.*, arrhythmia) from (ECG) (Gadaleta
    et al., [2018](#bib.bib31)) require the processing of high-rate samples (*e.g.*,
    $100$-$1000$ per heart cycle) using high complexity DNN models(Hannun et al.,
    [2019](#bib.bib42)). Health monitoring applications pose different challenges
    compared to CV-based applications. Indeed, in the former, both the computing capacity
    and the bandwidth available to the system are often smaller compared to the latter
    scenario, and conceptual advancements are required.
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: SC 和（部分）EE 的应用领域仍主要集中在图像分类上。这种关注可以通过输入的大小来解释，这使得压缩在许多环境中成为一个相关的问题，以及模型和任务的复杂性。然而，还有许多其他未被探索的领域，SC
    将从中受益。通过可穿戴传感器进行实时健康状况监测是一个显著的应用实例，其中大量数据从传感器传输到边缘服务器，如手机和家庭中心。例如，从（ECG）（Gadaleta
    et al., [2018](#bib.bib31)）中检测和监测心脏异常（*例如*，心律失常）需要处理高频样本（*例如*，每心脏周期$100$-$1000$）使用高复杂度的
    DNN 模型（Hannun et al., [2019](#bib.bib42)）。健康监测应用面临的挑战与基于 CV 的应用不同。确实，在前者中，系统的计算能力和带宽通常小于后者场景，并且需要概念上的进展。
- en: Toward an Information-Theoretic Perspective
  id: totrans-353
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 朝信息理论的视角发展
- en: 'The key intuition behind the success of SC and EE is similar to what has led
    to the success of techniques such as model pruning (Han et al., [2016](#bib.bib39);
    Li et al., [2016](#bib.bib75); He et al., [2017b](#bib.bib45); Yang et al., [2017](#bib.bib161))
    and knowledge distillation (Hinton et al., [2014](#bib.bib47); Kim and Rush, [2016](#bib.bib62);
    Mirzadeh et al., [2020](#bib.bib99)): most state-of-the-art DNN s are significantly
    over-parameterized (Yu et al., [2020](#bib.bib167); Yu and Principe, [2019](#bib.bib166)).
    A possible approach to justify SC and EE can be found in the study of *information
    bottlenecks* (IB), which were introduced in (Tishby et al., [2000](#bib.bib143))
    as a compression technique in which a random variable $\mathbf{X}$ is compressed
    while preserving relevant information about another random variable $\mathbf{Y}$.
    The IB method has been applied in (Tishby and Zaslavsky, [2015](#bib.bib144))
    to quantify mutual information between the network layers and derive an information
    theory limit on DNN efficiency. This has led to attempts at explaining the behavior
    of deep neural networks with the information bottleneck formalism (Saxe et al.,
    [2019](#bib.bib124)).'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: SC 和 EE 成功的关键直觉类似于导致模型剪枝 (Han et al., [2016](#bib.bib39); Li et al., [2016](#bib.bib75);
    He et al., [2017b](#bib.bib45); Yang et al., [2017](#bib.bib161)) 和知识蒸馏 (Hinton
    et al., [2014](#bib.bib47); Kim and Rush, [2016](#bib.bib62); Mirzadeh et al.,
    [2020](#bib.bib99)) 等技术成功的原因：大多数最先进的 DNNs 是显著过度参数化的 (Yu et al., [2020](#bib.bib167);
    Yu and Principe, [2019](#bib.bib166))。解释 SC 和 EE 的一种可能方法可以在 *信息瓶颈* (IB) 的研究中找到，IB
    是一种在压缩随机变量 $\mathbf{X}$ 的同时保持关于另一个随机变量 $\mathbf{Y}$ 相关信息的压缩技术，最早由 (Tishby et al.,
    [2000](#bib.bib143)) 引入。IB 方法已在 (Tishby and Zaslavsky, [2015](#bib.bib144)) 中应用于量化网络层之间的互信息并推导出
    DNN 效率的信息理论极限。这导致了尝试用信息瓶颈形式化方法解释深度神经网络的行为 (Saxe et al., [2019](#bib.bib124))。
- en: Despite these early attempts, a strong connection between this relatively new
    perspective and the techniques described in this paper is still elusive. Some
    of the approaches and architectures discussed in this paper are meaningful attempts
    to efficiently extract a compressed representation of the input and provide sufficient
    information toward a certain task early in the network layers. The emerging IB
    formalism is a promising approach to enable the first moves in the information
    theoretic analysis of neural networks-based transformations. We believe that this
    interpretation could serve as a foundation for an in-depth study of structural
    properties for both SC and EE.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管有这些早期尝试，但这种相对新颖的视角与本文中描述的技术之间的强联系仍然难以捉摸。本文讨论的一些方法和架构是有效提取输入的压缩表示并在网络层早期提供足够信息以实现某项任务的有意义尝试。新兴的信息瓶颈
    (IB) 形式化方法是启用基于神经网络的变换信息理论分析的有前景的方法。我们相信这种解释可以作为对 SC 和 EE 结构性质深入研究的基础。
- en: 7\. Conclusions
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7\. 结论
- en: Mobile devices such as smartphones and drones have now become an integral part
    of our daily lives. These devices increasingly utilize deep neural networks (DNNs)
    to execute complex inference tasks such as image classification and speech recognition,
    among others. For this reason, in this paper, we provided a comprehensive survey
    of the state of the art in split computing (SC) and early exiting (EE) by presenting
    a thorough comparison of the most relevant approaches. We also provided a set
    of compelling research challenges that need to be addressed to improve existing
    work in the field. We hope this survey will elicit further research in these emerging
    fields.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 像智能手机和无人机这样的移动设备现在已经成为我们日常生活的一个重要组成部分。这些设备越来越多地利用深度神经网络 (DNNs) 执行复杂的推理任务，如图像分类和语音识别等。因此，本文通过对分割计算
    (SC) 和早期退出 (EE) 的最新研究进行全面综述，展示了最相关方法的详细比较。我们还提供了一系列需要解决的有吸引力的研究挑战，以改进该领域的现有工作。我们希望这项综述能激发对这些新兴领域的进一步研究。
- en: Acknowledgements.
  id: totrans-358
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 致谢。
- en: This work was partially supported by the NSF under grant IIS-1724331, MLWiNS-2003237,
    CCF-2140154, and CNS-2134567.
  id: totrans-359
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作部分得到了 NSF 的资助，资助号 IIS-1724331, MLWiNS-2003237, CCF-2140154 和 CNS-2134567。
- en: References
  id: totrans-360
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: Adelantado et al. (2017) Ferran Adelantado, Xavier Vilajosana, Pere Tuset-Peiro,
    Borja Martinez, Joan Melia-Segui, and Thomas Watteyne. 2017. Understanding the
    Limits of LoRaWAN. *IEEE Communications Magazine* 55, 9 (2017), 34–40.
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adelantado 等人 (2017) Ferran Adelantado, Xavier Vilajosana, Pere Tuset-Peiro,
    Borja Martinez, Joan Melia-Segui, 和 Thomas Watteyne. 2017. 理解 LoRaWAN 的限制. *IEEE
    Communications Magazine* 55, 9 (2017), 34–40.
- en: Assine et al. (2021) Juliano S Assine, Eduardo Valle, et al. 2021. Single-Training
    Collaborative Object Detectors Adaptive to Bandwidth and Computation. *arXiv preprint
    arXiv:2105.00591* (2021).
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Assine 等 (2021) Juliano S Assine, Eduardo Valle 等. 2021. 单次训练的协作目标检测器适应带宽和计算。*arXiv预印本
    arXiv:2105.00591* (2021)。
- en: Ba and Caruana (2014) Jimmy Ba and Rich Caruana. 2014. Do deep nets really need
    to be deep?. In *NIPS 2014*. 2654–2662.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ba 和 Caruana (2014) Jimmy Ba 和 Rich Caruana. 2014. 深度网络真的需要深度吗？发表于 *NIPS 2014*。2654–2662。
- en: Ballé et al. (2017) Johannes Ballé, Valero Laparra, and Eero P Simoncelli. 2017.
    End-to-end Optimized Image Compression. In *International Conference on Learning
    Representations*.
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ballé 等 (2017) Johannes Ballé, Valero Laparra, 和 Eero P Simoncelli. 2017. 端到端优化图像压缩。发表于
    *国际学习表征会议*。
- en: Ballé et al. (2018) Johannes Ballé, David Minnen, Saurabh Singh, Sung Jin Hwang,
    and Nick Johnston. 2018. Variational image compression with a scale hyperprior.
    In *International Conference on Learning Representations*.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ballé 等 (2018) Johannes Ballé, David Minnen, Saurabh Singh, Sung Jin Hwang,
    和 Nick Johnston. 2018. 带有尺度超先验的变分图像压缩。发表于 *国际学习表征会议*。
- en: Barbera et al. (2013) Marco V Barbera, Sokol Kosta, Alessandro Mei, and Julinda
    Stefa. 2013. To offload or not to offload? the bandwidth and energy costs of mobile
    cloud computing. In *Proceedings of IEEE INFOCOM 2013*. 1285–1293.
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barbera 等 (2013) Marco V Barbera, Sokol Kosta, Alessandro Mei, 和 Julinda Stefa.
    2013. 是卸载还是不卸载？移动云计算的带宽和能量成本。发表于 *IEEE INFOCOM 2013会议论文集*。1285–1293。
- en: Bentivogli et al. (2009) Luisa Bentivogli, Peter Clark, Ido Dagan, and Danilo
    Giampiccolo. 2009. The Fifth PASCAL Recognizing Textual Entailment Challenge..
    In *Proceedings of Text Analysis Conference (TAC’09*.
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bentivogli 等 (2009) Luisa Bentivogli, Peter Clark, Ido Dagan, 和 Danilo Giampiccolo.
    2009. 第五届PASCAL文本蕴含识别挑战赛。发表于 *文本分析会议 (TAC’09)*。
- en: Buciluǎ et al. (2006) Cristian Buciluǎ, Rich Caruana, and Alexandru Niculescu-Mizil.
    2006. Model compression. In *Proceedings of the 12th ACM SIGKDD international
    conference on Knowledge discovery and data mining*. 535–541.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Buciluǎ 等 (2006) Cristian Buciluǎ, Rich Caruana, 和 Alexandru Niculescu-Mizil.
    2006. 模型压缩。发表于 *第12届ACM SIGKDD国际知识发现与数据挖掘会议论文集*。535–541。
- en: 'Cer et al. (2017) Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio,
    and Lucia Specia. 2017. SemEval-2017 Task 1: Semantic Textual Similarity Multilingual
    and Cross-lingual Focused Evaluation. In *Proceedings of the 11th International
    Workshop on Semantic Evaluation (SemEval-2017)*. 1–14.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cer 等 (2017) Daniel Cer, Mona Diab, Eneko Agirre, Iñigo Lopez-Gazpio, 和 Lucia
    Specia. 2017. SemEval-2017任务1：语义文本相似性多语言和跨语言的重点评估。发表于 *第11届语义评估国际研讨会 (SemEval-2017)*。1–14。
- en: 'Chen and Ran (2019) Jiasi Chen and Xukan Ran. 2019. Deep Learning With Edge
    Computing: A Review. *Proc. IEEE* 107, 8 (2019), 1655–1674.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 和 Ran (2019) Jiasi Chen 和 Xukan Ran. 2019. 边缘计算下的深度学习：综述。*IEEE期刊* 107,
    8 (2019)，1655–1674。
- en: Chen et al. (2017) Liang-Chieh Chen, George Papandreou, Florian Schroff, and
    Hartwig Adam. 2017. Rethinking Atrous Convolution for Semantic Image Segmentation.
    *arXiv preprint arXiv:1706.05587* (2017).
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen 等 (2017) Liang-Chieh Chen, George Papandreou, Florian Schroff, 和 Hartwig
    Adam. 2017. 重新思考用于语义图像分割的空洞卷积。*arXiv预印本 arXiv:1706.05587* (2017)。
- en: Chiang et al. (2021) Chang-Han Chiang, Pangfeng Liu, Da-Wei Wang, Ding-Yong
    Hong, and Jan-Jan Wu. 2021. Optimal Branch Location for Cost-effective Inference
    on Branchynet. In *2021 IEEE International Conference on Big Data (Big Data)*.
    IEEE, 5071–5080.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chiang 等 (2021) Chang-Han Chiang, Pangfeng Liu, Da-Wei Wang, Ding-Yong Hong,
    和 Jan-Jan Wu. 2021. Branchynet上成本效益推理的最优分支位置。发表于 *2021 IEEE国际大数据会议 (Big Data)*。IEEE，5071–5080。
- en: Choi and Bajić (2018) Hyomin Choi and Ivan V Bajić. 2018. Deep Feature Compression
    for Collaborative Object Detection. In *2018 25th IEEE International Conference
    on Image Processing (ICIP)*. IEEE, 3743–3747.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi 和 Bajić (2018) Hyomin Choi 和 Ivan V Bajić. 2018. 协作目标检测的深度特征压缩。发表于 *2018年第25届IEEE国际图像处理会议
    (ICIP)*。IEEE，3743–3747。
- en: Choi et al. (2020) Hyomin Choi, Robert A Cohen, and Ivan V Bajić. 2020. Back-And-Forth
    Prediction for Deep Tensor Compression. In *ICASSP 2020-2020 IEEE International
    Conference on Acoustics, Speech and Signal Processing (ICASSP)*. IEEE, 4467–4471.
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Choi 等 (2020) Hyomin Choi, Robert A Cohen, 和 Ivan V Bajić. 2020. 深度张量压缩的前后预测。发表于
    *ICASSP 2020-2020 IEEE国际声学、语音与信号处理会议 (ICASSP)*。IEEE，4467–4471。
- en: 'Clark et al. (2019) Kevin Clark, Minh-Thang Luong, Quoc V Le, and Christopher D
    Manning. 2019. ELECTRA: Pre-training Text Encoders as Discriminators Rather Than
    Generators. In *International Conference on Learning Representations*.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Clark 等 (2019) Kevin Clark, Minh-Thang Luong, Quoc V Le, 和 Christopher D Manning.
    2019. ELECTRA: 将文本编码器预训练为判别器而非生成器。发表于 *国际学习表征会议*。'
- en: Cohen et al. (2020) Robert A Cohen, Hyomin Choi, and Ivan V Bajić. 2020. Lightweight
    Compression Of Neural Network Feature Tensors For Collaborative Intelligence.
    In *2020 IEEE International Conference on Multimedia and Expo (ICME)*. IEEE, 1–6.
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cohen 等人（2020）Robert A Cohen, Hyomin Choi 和 Ivan V Bajić. 2020. 神经网络特征张量的轻量级压缩用于协同智能。在
    *2020 IEEE 国际多媒体与博览会（ICME）*。IEEE，1–6。
- en: Collobert et al. (2011) Ronan Collobert, Jason Weston, Léon Bottou, Michael
    Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing
    (almost) from scratch. *Journal of machine learning research* 12 (2011), 2493–2537.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Collobert 等人（2011）Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen,
    Koray Kavukcuoglu 和 Pavel Kuksa. 2011. 自然语言处理（几乎）从头开始。*机器学习研究期刊* 12（2011），2493–2537。
- en: 'Dagan et al. (2005) Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The
    PASCAL recognising textual entailment challenge. In *Proceedings of the First
    international conference on Machine Learning Challenges: evaluating Predictive
    Uncertainty Visual Object Classification, and Recognizing Textual Entailment*.
    177–190.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dagan 等人（2005）Ido Dagan, Oren Glickman 和 Bernardo Magnini. 2005. PASCAL 识别文本蕴涵挑战。在
    *首次国际机器学习挑战会议：评估预测不确定性、视觉对象分类与识别文本蕴涵的论文集*。177–190。
- en: 'Dang-Nguyen et al. (2015) Duc-Tien Dang-Nguyen, Cecilia Pasquini, Valentina
    Conotter, and Giulia Boato. 2015. RAISE: A raw images dataset for digital image
    forensics. In *Proceedings of the 6th ACM multimedia systems conference*. 219–224.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dang-Nguyen 等人（2015）Duc-Tien Dang-Nguyen, Cecilia Pasquini, Valentina Conotter
    和 Giulia Boato. 2015. RAISE：用于数字图像取证的原始图像数据集。在 *第六届 ACM 多媒体系统会议论文集*。219–224。
- en: 'Deng et al. (2013) Li Deng, Geoffrey Hinton, and Brian Kingsbury. 2013. New
    types of deep neural network learning for speech recognition and related applications:
    An overview. In *2013 IEEE international conference on acoustics, speech and signal
    processing*. IEEE, 8599–8603.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng 等人（2013）Li Deng, Geoffrey Hinton 和 Brian Kingsbury. 2013. 语音识别及相关应用的新型深度神经网络学习方法概述。在
    *2013 IEEE 国际声学、语音与信号处理会议*。IEEE，8599–8603。
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language
    Understanding. In *Proceedings of the 2019 Conference of the North American Chapter
    of the Association for Computational Linguistics: Human Language Technologies,
    Volume 1 (Long and Short Papers)*. 4171–4186.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Devlin 等人（2019）Jacob Devlin, Ming-Wei Chang, Kenton Lee 和 Kristina Toutanova.
    2019. BERT：用于语言理解的深度双向变换器预训练。在 *2019年北美计算语言学协会年会：人类语言技术，第1卷（长文和短文）*。4171–4186。
- en: Dolan and Brockett (2005) William B Dolan and Chris Brockett. 2005. Automatically
    constructing a corpus of sentential paraphrases. In *Proceedings of the Third
    International Workshop on Paraphrasing (IWP2005)*.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dolan 和 Brockett（2005）William B Dolan 和 Chris Brockett. 2005. 自动构建句子释义语料库。在
    *第三届国际释义研讨会（IWP2005）论文集*。
- en: 'Dong et al. (2018) Jin-Dong Dong, An-Chieh Cheng, Da-Cheng Juan, Wei Wei, and
    Min Sun. 2018. DPP-Net: Device-aware Progressive Search for Pareto-optimal Neural
    Architectures. In *Proceedings of the European Conference on Computer Vision (ECCV)*.
    517–531.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong 等人（2018）Jin-Dong Dong, An-Chieh Cheng, Da-Cheng Juan, Wei Wei 和 Min Sun.
    2018. DPP-Net：设备感知的渐进搜索帕累托最优神经架构。在 *欧洲计算机视觉会议（ECCV）论文集*。517–531。
- en: Elbayad et al. (2020) Maha Elbayad, Jiatao Gu, E. Grave, and M. Auli. 2020.
    Depth-Adaptive Transformer. In *International Conference on Learning Representations*.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Elbayad 等人（2020）Maha Elbayad, Jiatao Gu, E. Grave 和 M. Auli. 2020. 深度自适应变换器。在
    *国际学习表征会议*。
- en: 'Eshratifar et al. (2019a) Amir Erfan Eshratifar, Mohammad Saeed Abrishami,
    and Massoud Pedram. 2019a. JointDNN: An Efficient Training and Inference Engine
    for Intelligent Mobile Cloud Computing Services. *IEEE Transactions on Mobile
    Computing* (2019).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eshratifar 等人（2019a）Amir Erfan Eshratifar, Mohammad Saeed Abrishami 和 Massoud
    Pedram. 2019a. JointDNN：一种高效的智能移动云计算服务训练和推理引擎。*IEEE移动计算学报*（2019）。
- en: 'Eshratifar et al. (2019b) Amir Erfan Eshratifar, Amirhossein Esmaili, and Massoud
    Pedram. 2019b. BottleNet: A Deep Learning Architecture for Intelligent Mobile
    Cloud Computing Services. In *2019 IEEE/ACM Int. Symposium on Low Power Electronics
    and Design (ISLPED)*. 1–6.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eshratifar 等人（2019b）Amir Erfan Eshratifar, Amirhossein Esmaili 和 Massoud Pedram.
    2019b. BottleNet：一种用于智能移动云计算服务的深度学习架构。在 *2019 IEEE/ACM 低功耗电子与设计国际研讨会（ISLPED）*。1–6。
- en: Everingham et al. (2012) Mark Everingham, Luc Van Gool, CKI Williams, John Winn,
    and Andrew Zisserman. 2012. The PASCAL Visual Object Classes Challenge 2012 (VOC2012).
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everingham 等（2012）Mark Everingham、Luc Van Gool、CKI Williams、John Winn 和 Andrew
    Zisserman。2012年。《PASCAL 视觉对象类别挑战 2012（VOC2012）》。
- en: Everingham et al. ([n.d.]) M. Everingham, L. Van Gool, C. K. I. Williams, J.
    Winn, and A. Zisserman. [n.d.]. The PASCAL Visual Object Classes Challenge 2007
    (VOC2007) Results. http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Everingham 等（[n.d.]）M. Everingham、L. Van Gool、C. K. I. Williams、J. Winn 和 A.
    Zisserman。[n.d.]。《PASCAL 视觉对象类别挑战 2007（VOC2007）结果》。http://www.pascal-network.org/challenges/VOC/voc2007/workshop/index.html。
- en: Fei-Fei et al. (2006) Li Fei-Fei, Rob Fergus, and Pietro Perona. 2006. One-shot
    learning of object categories. *IEEE transactions on pattern analysis and machine
    intelligence* 28, 4 (2006), 594–611.
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fei-Fei 等（2006）Li Fei-Fei、Rob Fergus 和 Pietro Perona。2006年。《物体类别的一次性学习》。*IEEE
    模式分析与机器智能交易* 28，4（2006），594–611。
- en: Gadaleta et al. (2018) Matteo Gadaleta, Michele Rossi, Steven R Steinhubl, and
    Giorgio Quer. 2018. Deep learning to detect atrial fibrillation from short noisy
    ECG segments measured with wireless sensors. *Circulation* 138, Suppl_1 (2018),
    A16177–A16177.
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gadaleta 等（2018）Matteo Gadaleta、Michele Rossi、Steven R Steinhubl 和 Giorgio Quer。2018年。《利用深度学习从无线传感器测量的短噪声
    ECG 段中检测房颤》。*循环* 138，Suppl_1（2018），A16177–A16177。
- en: Garg and Moschitti (2021) Siddhant Garg and Alessandro Moschitti. 2021. Will
    this Question be Answered? Question Filtering via Answer Model Distillation for
    Efficient Question Answering. In *Proceedings of the 2021 Conference on Empirical
    Methods in Natural Language Processing*. 7329–7346.
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garg 和 Moschitti（2021）Siddhant Garg 和 Alessandro Moschitti。2021年。《这个问题会得到回答吗？通过回答模型蒸馏进行问题过滤，以实现高效的问题回答》。在
    *2021 年自然语言处理经验方法会议论文集* 中，7329–7346。
- en: 'Garg et al. (2020) Siddhant Garg, Thuy Vu, and Alessandro Moschitti. 2020.
    TANDA: Transfer and adapt pre-trained transformer models for answer sentence selection.
    In *Proceedings of the AAAI Conference on Artificial Intelligence*, Vol. 34\.
    7780–7788.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garg 等（2020）Siddhant Garg、Thuy Vu 和 Alessandro Moschitti。2020年。《TANDA：转移和适配预训练的变换器模型以进行回答句子选择》。在
    *AAAI 人工智能会议论文集*，第 34 卷，7780–7788。
- en: Giampiccolo et al. (2007) Danilo Giampiccolo, Bernardo Magnini, Ido Dagan, and
    William B Dolan. 2007. The third pascal recognizing textual entailment challenge.
    In *Proceedings of the ACL-PASCAL workshop on textual entailment and paraphrasing*.
    1–9.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Giampiccolo 等（2007）Danilo Giampiccolo、Bernardo Magnini、Ido Dagan 和 William B
    Dolan。2007年。《第三届 Pascal 识别文本蕴含挑战》。在 *ACL-PASCAL 研讨会论文集：文本蕴含与改写* 中，1–9。
- en: 'Gundersen and Kjensmo (2018) Odd Erik Gundersen and Sigbjørn Kjensmo. 2018.
    State of the Art: Reproducibility in Artificial Intelligence. In *Proceedings
    of the AAAI Conference on Artificial Intelligence*, Vol. 32.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gundersen 和 Kjensmo（2018）Odd Erik Gundersen 和 Sigbjørn Kjensmo。2018年。《前沿技术：人工智能的可重复性》。在
    *AAAI 人工智能会议论文集*，第 32 卷。
- en: 'Guo (2018) Tian Guo. 2018. Cloud-Based or On-Device: An Empirical Study of
    Mobile Deep Inference. In *2018 IEEE Int. Conference on Cloud Engineering (IC2E)*.
    IEEE, 184–190.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo（2018）Tian Guo。2018年。《基于云还是本地设备：移动深度推理的实证研究》。在 *2018 IEEE 云工程国际会议（IC2E）*
    中。IEEE，184–190。
- en: Gupta et al. (2015) Lav Gupta, Raj Jain, and Gabor Vaszkun. 2015. Survey of
    Important Issues in UAV Communication Networks. *IEEE Communications Surveys &
    Tutorials* 18, 2 (2015), 1123–1152.
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gupta 等（2015）Lav Gupta、Raj Jain 和 Gabor Vaszkun。2015年。《无人机通信网络中的重要问题调查》。*IEEE
    通信调查与教程* 18，2（2015），1123–1152。
- en: Haim et al. (2006) R Bar Haim, Ido Dagan, Bill Dolan, Lisa Ferro, Danilo Giampiccolo,
    Bernardo Magnini, and Idan Szpektor. 2006. The second pascal recognising textual
    entailment challenge. In *Proceedings of the Second PASCAL Challenges Workshop
    on Recognising Textual Entailment*.
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haim 等（2006）R Bar Haim、Ido Dagan、Bill Dolan、Lisa Ferro、Danilo Giampiccolo、Bernardo
    Magnini 和 Idan Szpektor。2006年。《第二届 Pascal 识别文本蕴含挑战》。在 *第二届 PASCAL 挑战研讨会：识别文本蕴含*
    中。
- en: 'Han et al. (2016) Song Han, Huizi Mao, and William J Dally. 2016. Deep Compression:
    Compressing Deep Neural Networks with Pruning, Trained Quantization and Huffman
    Coding. In *Fourth International Conference on Learning Representations*.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等（2016）Song Han、Huizi Mao 和 William J Dally。2016年。《深度压缩：通过剪枝、训练量化和霍夫曼编码压缩深度神经网络》。在
    *第四届国际学习表示会议* 中。
- en: Han et al. (2015) Song Han, Jeff Pool, John Tran, and William Dally. 2015. Learning
    both Weights and Connections for Efficient Neural Network. *Advances in Neural
    Information Processing Systems* 28 (2015).
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等（2015）Song Han、Jeff Pool、John Tran 和 William Dally。2015年。《同时学习权重和连接以提高神经网络效率》。*神经信息处理系统进展*
    28（2015）。
- en: 'Hannun et al. (2014) Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro,
    Greg Diamos, Erich Elsen, Ryan Prenger, Sanjeev Satheesh, Shubho Sengupta, Adam
    Coates, et al. 2014. Deep speech: Scaling up end-to-end speech recognition. *arXiv
    preprint arXiv:1412.5567* (2014).'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hannun 等（2014）Awni Hannun、Carl Case、Jared Casper、Bryan Catanzaro、Greg Diamos、Erich
    Elsen、Ryan Prenger、Sanjeev Satheesh、Shubho Sengupta、Adam Coates 等。2014。深度语音：扩展端到端语音识别。*arXiv
    预印本 arXiv:1412.5567*（2014）。
- en: Hannun et al. (2019) Awni Y Hannun, Pranav Rajpurkar, Masoumeh Haghpanahi, Geoffrey H
    Tison, Codie Bourn, Mintu P Turakhia, and Andrew Y Ng. 2019. Cardiologist-level
    arrhythmia detection and classification in ambulatory electrocardiograms using
    a deep neural network. *Nature medicine* 25, 1 (2019), 65–69.
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hannun 等（2019）Awni Y Hannun、Pranav Rajpurkar、Masoumeh Haghpanahi、Geoffrey H
    Tison、Codie Bourn、Mintu P Turakhia 和 Andrew Y Ng。2019。使用深度神经网络在便携式心电图中进行心脏病专家级的心律失常检测和分类。*自然医学*
    25, 1（2019），65–69。
- en: He et al. (2017a) Kaiming He, Georgia Gkioxari, Piotr Dollár, and Ross Girshick.
    2017a. Mask R-CNN. In *Proceedings of the IEEE International Conference on Computer
    Vision*. 2961–2969.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2017a）Kaiming He、Georgia Gkioxari、Piotr Dollár 和 Ross Girshick。2017a。Mask
    R-CNN。在*IEEE 国际计算机视觉大会论文集*。2961–2969。
- en: He et al. (2016) Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.
    Deep residual learning for image recognition. In *Proceedings of the IEEE conference
    on computer vision and pattern recognition*. 770–778.
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2016）Kaiming He、Xiangyu Zhang、Shaoqing Ren 和 Jian Sun。2016。用于图像识别的深度残差学习。在*IEEE
    计算机视觉与模式识别会议论文集*。770–778。
- en: He et al. (2017b) Yihui He, Xiangyu Zhang, and Jian Sun. 2017b. Channel Pruning
    for Accelerating Very Deep Neural Networks. In *Proceedings of the IEEE International
    Conference on Computer Vision*. 1389–1397.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2017b）Yihui He、Xiangyu Zhang 和 Jian Sun。2017b。通道剪枝以加速非常深的神经网络。在*IEEE 国际计算机视觉大会论文集*。1389–1397。
- en: 'Hinton et al. (2012) Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman
    Mohamed, Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N
    Sainath, et al. 2012. Deep neural networks for acoustic modeling in speech recognition:
    The shared views of four research groups. *IEEE Signal processing magazine* 29,
    6 (2012), 82–97.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton 等（2012）Geoffrey Hinton、Li Deng、Dong Yu、George E Dahl、Abdel-rahman Mohamed、Navdeep
    Jaitly、Andrew Senior、Vincent Vanhoucke、Patrick Nguyen、Tara N Sainath 等。2012。用于语音识别的深度神经网络：四个研究组的共同观点。*IEEE
    信号处理杂志* 29, 6（2012），82–97。
- en: 'Hinton et al. (2014) Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. 2014. Distilling
    the Knowledge in a Neural Network. In *Deep Learning and Representation Learning
    Workshop: NIPS 2014*.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hinton 等（2014）Geoffrey Hinton、Oriol Vinyals 和 Jeff Dean。2014。提取神经网络中的知识。在*深度学习与表示学习研讨会：NIPS
    2014*。
- en: Howard et al. (2019) Andrew Howard, Mark Sandler, Grace Chu, Liang-Chieh Chen,
    Bo Chen, Mingxing Tan, Weijun Wang, Yukun Zhu, Ruoming Pang, Vijay Vasudevan,
    et al. 2019. Searching for MobileNetV3\. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*. 1314–1324.
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Howard 等（2019）Andrew Howard、Mark Sandler、Grace Chu、Liang-Chieh Chen、Bo Chen、Mingxing
    Tan、Weijun Wang、Yukun Zhu、Ruoming Pang、Vijay Vasudevan 等。2019。寻找 MobileNetV3。*IEEE/CVF
    国际计算机视觉大会论文集*。1314–1324。
- en: 'Howard et al. (2017) Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko,
    Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. 2017. MobileNets:
    Efficient Convolutional Neural Networks for Mobile Vision Applications. *arXiv
    preprint arXiv:1704.04861* (2017).'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Howard 等（2017）Andrew G Howard、Menglong Zhu、Bo Chen、Dmitry Kalenichenko、Weijun
    Wang、Tobias Weyand、Marco Andreetto 和 Hartwig Adam。2017。MobileNets：高效卷积神经网络用于移动视觉应用。*arXiv
    预印本 arXiv:1704.04861*（2017）。
- en: Hu and Krishnamachari (2020) Diyi Hu and Bhaskar Krishnamachari. 2020. Fast
    and Accurate Streaming CNN Inference via Communication Compression on the Edge.
    In *2020 IEEE/ACM Fifth Int. Conference on Internet-of-Things Design and Implementation
    (IoTDI)*. IEEE, 157–163.
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu 和 Krishnamachari（2020）Diyi Hu 和 Bhaskar Krishnamachari。2020。通过边缘通信压缩进行快速准确的流式
    CNN 推理。在*2020 IEEE/ACM 第五届物联网设计与实施国际会议（IoTDI）*。IEEE，157–163。
- en: Huang et al. (2018) Gao Huang, Danlu Chen, T. Li, Felix Wu, L. V. D. Maaten,
    and Kilian Q. Weinberger. 2018. Multi-Scale Dense Networks for Resource Efficient
    Image Classification. In *International Conference on Learning Representations*.
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等（2018）Gao Huang、Danlu Chen、T. Li、Felix Wu、L. V. D. Maaten 和 Kilian Q.
    Weinberger。2018。用于资源高效图像分类的多尺度密集网络。在*国际学习表示会议*。
- en: Huang et al. (2017) Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q
    Weinberger. 2017. Densely connected convolutional networks. In *Proceedings of
    the IEEE conference on computer vision and pattern recognition*. 4700–4708.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等（2017）Gao Huang, Zhuang Liu, Laurens Van Der Maaten, 和 Kilian Q Weinberger。2017年。《密集连接的卷积网络》。发表于*IEEE
    计算机视觉与模式识别会议论文集*，4700–4708。
- en: 'Ioffe and Szegedy (2015) Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization:
    Accelerating Deep Network Training by Reducing Internal Covariate Shift. In *International
    Conference on Machine Learning*. PMLR, 448–456.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe 和 Szegedy（2015）Sergey Ioffe 和 Christian Szegedy。2015年。《批量归一化：通过减少内部协变量偏移加速深度网络训练》。发表于*国际机器学习会议*。PMLR,
    448–456。
- en: Itahara et al. (2021) Sohei Itahara, Takayuki Nishio, and Koji Yamamoto. 2021.
    Packet-Loss-Tolerant Split Inference for Delay-Sensitive Deep Learning in Lossy
    Wireless Networks. *arXiv preprint arXiv:2104.13629* (2021).
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Itahara 等（2021）Sohei Itahara, Takayuki Nishio, 和 Koji Yamamoto。2021年。《延迟敏感深度学习在有损无线网络中的分割推理的包丢失容忍》。*arXiv
    预印本 arXiv:2104.13629*（2021）。
- en: 'Iyer et al. ([n.d.]) Shankar Iyer, Nikhil Dandekar, and Kornél Csernai. [n.d.].
    First Quora Dataset Release: Question Pairs. [https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)
    [Online; Accessed on Januray 25, 2021].'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iyer 等（[n.d.]）Shankar Iyer, Nikhil Dandekar, 和 Kornél Csernai。[n.d.]。《第一次 Quora
    数据集发布：问题对》。 [https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs](https://www.quora.com/q/quoradata/First-Quora-Dataset-Release-Question-Pairs)
    [在线; 访问日期：2021年1月25日]。
- en: Jacob et al. (2018) Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu,
    Matthew Tang, Andrew Howard, Hartwig Adam, and Dmitry Kalenichenko. 2018. Quantization
    and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference.
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.
    2704–2713.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacob 等（2018）Benoit Jacob, Skirmantas Kligys, Bo Chen, Menglong Zhu, Matthew
    Tang, Andrew Howard, Hartwig Adam, 和 Dmitry Kalenichenko。2018年。《高效整数算术推理的神经网络量化和训练》。发表于*IEEE
    计算机视觉与模式识别会议论文集*，2704–2713。
- en: 'Jagannath et al. (2019) Jithin Jagannath, Nicholas Polosky, Anu Jagannath,
    Francesco Restuccia, and Tommaso Melodia. 2019. Machine Learning for Wireless
    Communications in the Internet of Things: A Comprehensive Survey. *Ad Hoc Networks*
    93 (2019), 101913.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jagannath 等（2019）Jithin Jagannath, Nicholas Polosky, Anu Jagannath, Francesco
    Restuccia, 和 Tommaso Melodia。2019年。《物联网无线通信中的机器学习：全面调查》。*Ad Hoc Networks* 93 (2019),
    101913。
- en: Jankowski et al. (2020) Mikolaj Jankowski, Deniz Gündüz, and Krystian Mikolajczyk.
    2020. Joint Device-Edge Inference over Wireless Links with Pruning. In *2020 IEEE
    21st International Workshop on Signal Processing Advances in Wireless Communications
    (SPAWC)*. IEEE, 1–5.
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jankowski 等（2020）Mikolaj Jankowski, Deniz Gündüz, 和 Krystian Mikolajczyk。2020年。《通过修剪的无线链路联合设备边缘推理》。发表于*2020
    IEEE 第21届无线通信信号处理进展国际研讨会（SPAWC）*。IEEE, 1–5。
- en: Jeong et al. (2018) Hyuk-Jin Jeong, InChang Jeong, Hyeon-Jae Lee, and Soo-Mook
    Moon. 2018. Computation Offloading for Machine Learning Web Apps in the Edge Server
    Environment. In *2018 IEEE 38th International Conference on Distributed Computing
    Systems (ICDCS)*. 1492–1499.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jeong 等（2018）Hyuk-Jin Jeong, InChang Jeong, Hyeon-Jae Lee, 和 Soo-Mook Moon。2018年。《边缘服务器环境中的机器学习
    Web 应用计算卸载》。发表于*2018 IEEE 第38届国际分布式计算系统会议（ICDCS）*。1492–1499。
- en: Jin et al. (2020) Di Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits.
    2020. Is BERT Really Robust? A Strong Baseline for Natural Language Attack on
    Text Classification and Entailment. In *Proceedings of the AAAI conference on
    artificial intelligence*, Vol. 34\. 8018–8025.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jin 等（2020）Di Jin, Zhijing Jin, Joey Tianyi Zhou, 和 Peter Szolovits。2020年。《BERT
    是否真的鲁棒？自然语言攻击文本分类和推理的强基线》。发表于*AAAI 人工智能会议论文集*，第34卷，8018–8025。
- en: 'Kang et al. (2017) Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski,
    Trevor Mudge, Jason Mars, and Lingjia Tang. 2017. Neurosurgeon: Collaborative
    Intelligence Between the Cloud and Mobile Edge. In *Proceedings of the Twenty-Second
    International Conference on Architectural Support for Programming Languages and
    Operating Systems* (Xi’an, China). 615–629. [https://doi.org/10.1145/3037697.3037698](https://doi.org/10.1145/3037697.3037698)'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等（2017）Yiping Kang, Johann Hauswald, Cao Gao, Austin Rovinski, Trevor Mudge,
    Jason Mars, 和 Lingjia Tang。2017年。《神经外科医生：云与移动边缘之间的协作智能》。发表于*第二十二届国际编程语言和操作系统架构支持会议论文集*（中国西安）。615–629。
    [https://doi.org/10.1145/3037697.3037698](https://doi.org/10.1145/3037697.3037698)
- en: Kim and Rush (2016) Yoon Kim and Alexander M Rush. 2016. Sequence-Level Knowledge
    Distillation. In *Proceedings of the 2016 Conference on Empirical Methods in Natural
    Language Processing*. 1317–1327.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Rush（2016）Yoon Kim 和 Alexander M Rush. 2016. 序列级知识蒸馏。见 *2016年自然语言处理经验方法会议论文集*，1317–1327。
- en: 'Kingma and Ba (2015) Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method
    for Stochastic Optimization. In *Third International Conference on Learning Representations*.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma 和 Ba（2015）Diederik P. Kingma 和 Jimmy Ba. 2015. Adam: 一种随机优化方法。见 *第三届国际学习表示会议*。'
- en: Krizhevsky (2009) Alex Krizhevsky. 2009. Learning Multiple Layers of Features
    from Tiny Images. (2009).
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky（2009）Alex Krizhevsky. 2009. 从小图像中学习多个特征层。（2009）。
- en: Krizhevsky et al. (2012) Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.
    2012. ImageNet Classification with Deep Convolutional Neural Networks. In *Advances
    in Neural Information Processing Systems 25*, F. Pereira, C. J. C. Burges, L. Bottou,
    and K. Q. Weinberger (Eds.). 1097–1105.
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krizhevsky 等（2012）Alex Krizhevsky, Ilya Sutskever 和 Geoffrey E Hinton. 2012.
    基于深度卷积神经网络的ImageNet分类。见 *神经信息处理系统进展 25*，F. Pereira, C. J. C. Burges, L. Bottou
    和 K. Q. Weinberger（编），1097–1105。
- en: Kurakin et al. (2016) Alexey Kurakin, Ian Goodfellow, and Samy Bengio. 2016.
    Adversarial examples in the physical world. *arXiv preprint arXiv:1607.02533*
    (2016).
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kurakin 等（2016）Alexey Kurakin, Ian Goodfellow 和 Samy Bengio. 2016. 物理世界中的对抗样本。*arXiv
    预印本 arXiv:1607.02533*（2016）。
- en: 'Lan et al. (2019) Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel,
    Piyush Sharma, and Radu Soricut. 2019. ALBERT: A Lite BERT for Self-supervised
    Learning of Language Representations. In *International Conference on Learning
    Representations*.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lan 等（2019）Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush
    Sharma 和 Radu Soricut. 2019. ALBERT: 用于自监督学习语言表示的轻量级BERT。见 *国际学习表示会议*。'
- en: 'Laskaridis et al. (2020) Stefanos Laskaridis, Stylianos I Venieris, Mario Almeida,
    Ilias Leontiadis, and Nicholas D Lane. 2020. SPINN: Synergistic Progressive Inference
    of Neural Networks over Device and Cloud. In *Proceedings of the 26th Annual International
    Conference on Mobile Computing and Networking*. 1–15.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Laskaridis 等（2020）Stefanos Laskaridis, Stylianos I Venieris, Mario Almeida,
    Ilias Leontiadis 和 Nicholas D Lane. 2020. SPINN: 设备与云上的神经网络的协同渐进推断。见 *第26届国际移动计算与网络会议论文集*，1–15。'
- en: LeCun et al. (2015) Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep
    learning. *Nature* 521, 7553 (2015), 436.
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等（2015）Yann LeCun, Yoshua Bengio 和 Geoffrey Hinton. 2015. 深度学习。*自然* 521,
    7553 (2015), 436。
- en: LeCun et al. (1998) Yann LeCun, Léon Bottou, Yoshua Bengio, and Patrick Haffner.
    1998. Gradient-based learning applied to document recognition. *Proc. IEEE* 86,
    11 (1998), 2278–2324.
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等（1998）Yann LeCun, Léon Bottou, Yoshua Bengio 和 Patrick Haffner. 1998.
    应用于文档识别的基于梯度的学习。*IEEE学报* 86, 11 (1998)，2278–2324。
- en: Lee et al. (2021) Joo Chan Lee, Yongwoo Kim, SungTae Moon, and Jong Hwan Ko.
    2021. A Splittable DNN-Based Object Detector for Edge-Cloud Collaborative Real-Time
    Video Inference. In *2021 17th IEEE International Conference on Advanced Video
    and Signal Based Surveillance (AVSS)*. IEEE, 1–8.
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等（2021）Joo Chan Lee, Yongwoo Kim, SungTae Moon 和 Jong Hwan Ko. 2021. 基于DNN的可拆分对象检测器，用于边缘-云协作实时视频推断。见
    *2021年第17届IEEE国际高级视频和信号基监控会议（AVSS）*。IEEE，1–8。
- en: Levesque et al. (2012) Hector J Levesque, Ernest Davis, and Leora Morgenstern.
    2012. The Winograd schema challenge. In *Proceedings of the Thirteenth International
    Conference on Principles of Knowledge Representation and Reasoning*. 552–561.
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Levesque 等（2012）Hector J Levesque, Ernest Davis 和 Leora Morgenstern. 2012. Winograd
    语义挑战。见 *第十三届知识表示与推理原理国际会议论文集*，552–561。
- en: Levi and Hassner (2015) Gil Levi and Tal Hassner. 2015. Age and gender classification
    using convolutional neural networks. In *Proceedings of the IEEE conference on
    computer vision and pattern recognition workshops*. 34–42.
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Levi 和 Hassner（2015）Gil Levi 和 Tal Hassner. 2015. 使用卷积神经网络进行年龄和性别分类。见 *IEEE计算机视觉与模式识别研讨会论文集*，34–42。
- en: Li et al. (2018a) Guangli Li, Lei Liu, Xueying Wang, Xiao Dong, Peng Zhao, and
    Xiaobing Feng. 2018a. Auto-tuning Neural Network Quantization Framework for Collaborative
    Inference Between the Cloud and Edge. In *Int. Conference on Artificial Neural
    Networks*. 402–411.
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2018a）Guangli Li, Lei Liu, Xueying Wang, Xiao Dong, Peng Zhao 和 Xiaobing
    Feng. 2018a. 用于云与边缘协作推断的神经网络量化框架的自动调优。见 *国际人工神经网络会议*，402–411。
- en: Li et al. (2016) Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter
    Graf. 2016. Pruning Filters for Efficient ConvNets. In *Fourth International Conference
    on Learning Representations*.
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2016）李浩、阿西姆·卡达夫、伊戈尔·杜尔达诺维奇、哈南·萨梅特和汉斯·彼得·格拉夫。2016。《用于高效 ConvNets 的滤波器剪枝》。在
    *第四届国际学习表征会议* 中。
- en: Li et al. (2017) Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter
    Graf. 2017. Pruning Filters for Efficient ConvNets. In *Fifth International Conference
    on Learning Representations*.
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2017）李浩、阿西姆·卡达夫、伊戈尔·杜尔达诺维奇、哈南·萨梅特和汉斯·彼得·格拉夫。2017。《用于高效 ConvNets 的滤波器剪枝》。在
    *第五届国际学习表征会议* 中。
- en: 'Li et al. (2018b) He Li, Kaoru Ota, and Mianxiong Dong. 2018b. Learning IoT
    in edge: Deep learning for the Internet of Things with edge computing. *IEEE network*
    32, 1 (2018), 96–101.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2018b）李赫、尾田薰和董勉雄。2018b。《边缘计算中的物联网学习：深度学习与物联网结合》。*IEEE 网络* 32, 1（2018），96–101。
- en: Li et al. (2019) Hao Li, Hong Zhang, Xiaojuan Qi, Ruigang Yang, and Gao Huang.
    2019. Improved Techniques for Training Adaptive Deep Networks. In *2019 IEEE/CVF
    International Conference on Computer Vision (ICCV)*. 1891–1900.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2019）李浩、张洪、齐晓娟、杨瑞刚和黄高。2019。《改进的自适应深度网络训练技术》。在 *2019 IEEE/CVF 国际计算机视觉大会（ICCV）*
    中，1891–1900。
- en: Li et al. (2014) Jinyu Li, Rui Zhao, Jui-Ting Huang, and Yifan Gong. 2014. Learning
    Small-Size DNN with Output-Distribution-Based Criteria. In *Fifteenth annual conference
    of the international speech communication association*.
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2014）李金宇、赵瑞、黄钰婷和龚一凡。2014。《基于输出分布标准的小尺寸 DNN 学习》。在 *第十五届国际语音通信协会年会* 中。
- en: 'Li et al. (2020) Zhuohan Li, Eric Wallace, Sheng Shen, Kevin Lin, Kurt Keutzer,
    Dan Klein, and Joey Gonzalez. 2020. Train big, then compress: Rethinking model
    size for efficient training and inference of transformers. In *International Conference
    on Machine Learning*. PMLR, 5958–5968.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等（2020）李卓涵、埃里克·华莱士、申盛、凯文·林、库尔特·克特泽、丹·克莱因和乔伊·冈萨雷斯。2020。《先训练大模型，再压缩：重新思考模型大小以实现高效的训练和变换器推理》。在
    *国际机器学习大会* 中。PMLR，5958–5968。
- en: Lin et al. (2014a) Min Lin, Qiang Chen, and Shuicheng Yan. 2014a. Network in
    network. (2014).
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2014a）林敏、陈强和闫水成。2014a。《网络中的网络》。 (2014)。
- en: Lin et al. (2017a) Tsung-Yi Lin, Piotr Dollár, Ross Girshick, Kaiming He, Bharath
    Hariharan, and Serge Belongie. 2017a. Feature pyramid networks for object detection.
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.
    2117–2125.
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2017a）林宗义、皮奥特·多拉尔、罗斯·吉尔希克、何恺明、巴拉斯·哈里哈兰和塞尔日·贝隆吉。2017a。《用于目标检测的特征金字塔网络》。在
    *IEEE 计算机视觉与模式识别会议论文集* 中，2117–2125。
- en: Lin et al. (2017b) Tsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and
    Piotr Dollár. 2017b. Focal Loss for Dense Object Detection. In *Proceedings of
    the IEEE international conference on computer vision*. 2980–2988.
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2017b）林宗义、普里娅·戈亚尔、罗斯·吉尔希克、何恺明和皮奥特·多拉尔。2017b。《用于密集目标检测的焦点损失》。在 *IEEE 国际计算机视觉会议论文集*
    中，2980–2988。
- en: 'Lin et al. (2014b) Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays,
    Pietro Perona, Deva Ramanan, Piotr Dollár, and C Lawrence Zitnick. 2014b. Microsoft
    coco: Common objects in context. In *European conference on computer vision*.
    Springer, 740–755.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等（2014b）林宗义、迈克尔·迈尔、塞尔日·贝隆吉、詹姆斯·海斯、皮特罗·佩罗纳、德瓦·拉马南、皮奥特·多拉尔和C·劳伦斯·齐特尼克。2014b。《微软
    COCO：上下文中的常见对象》。在 *欧洲计算机视觉会议* 中。施普林格，740–755。
- en: 'Liu et al. (2020) Weijie Liu, Peng Zhou, Zhiruo Wang, Zhe Zhao, Haotang Deng,
    and QI JU. 2020. FastBERT: a Self-distilling BERT with Adaptive Inference Time.
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*. 6035–6044.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2020）刘伟杰、周鹏、王志若、赵哲、邓浩堂和居奇。2020。《FastBERT：一种具有自我蒸馏的自适应推理时间的 BERT》。在 *第58届计算语言学协会年会论文集*
    中，6035–6044。
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi,
    Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019.
    RoBERTa: A robustly optimized bert pretraining approach. *arXiv preprint arXiv:1907.11692*
    (2019).'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2019）刘隐汉、迈尔·奥特、纳曼·戈亚尔、景飞·杜、曼达尔·乔希、丹奇·陈、奥梅尔·利维、迈克·刘易斯、卢克·泽特尔莫耶和维塞林·斯托亚诺夫。2019。《RoBERTa：一种稳健优化的
    BERT 预训练方法》。*arXiv 预印本 arXiv:1907.11692*（2019）。
- en: 'Liu et al. (2021) Zejian Liu, Fanrong Li, Gang Li, and Jian Cheng. 2021. EBERT:
    Efficient BERT Inference with Dynamic Structured Pruning. In *Findings of the
    Association for Computational Linguistics: ACL-IJCNLP 2021*. 4814–4823.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等（2021）刘泽建、李繁荣、李刚和程健。2021。《EBERT：一种具有动态结构剪枝的高效 BERT 推理》。在 *计算语言学协会发现：ACL-IJCNLP
    2021* 中，4814–4823。
- en: Lo et al. (2017) Chi Lo, Yu-Yi Su, Chun-Yi Lee, and Shih-Chieh Chang. 2017.
    A Dynamic Deep Neural Network Design for Efficient Workload Allocation in Edge
    Computing. In *2017 IEEE International Conference on Computer Design (ICCD)*.
    273–280.
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lo 等人（2017）Chi Lo、Yu-Yi Su、Chun-Yi Lee 和 Shih-Chieh Chang。2017。在边缘计算中进行高效工作负载分配的动态深度神经网络设计。发表于
    *2017 IEEE 计算机设计国际会议（ICCD）*。第 273–280 页。
- en: 'Mao et al. (2017) Yuyi Mao, Changsheng You, Jun Zhang, Kaibin Huang, and Khaled B
    Letaief. 2017. A Survey on Mobile Edge Computing: The Communication Perspective.
    *IEEE Communications Surveys & Tutorials* 19, 4 (2017), 2322–2358.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mao 等人（2017）Yuyi Mao、Changsheng You、Jun Zhang、Kaibin Huang 和 Khaled B Letaief。2017。移动边缘计算的调查：通信视角。*IEEE
    通信调查与教程* 19，第 4 期（2017年），第 2322–2358 页。
- en: Mateo et al. (2019) Pablo Jiménez Mateo, Claudio Fiandrino, and Joerg Widmer.
    2019. Analysis of TCP performance in 5G mm-wave mobile networks. In *2019 IEEE
    International Conference on Communications (IEEE ICC)*. IEEE, 1–7.
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mateo 等人（2019）Pablo Jiménez Mateo、Claudio Fiandrino 和 Joerg Widmer。2019。5G毫米波移动网络中
    TCP 性能的分析。发表于 *2019 IEEE国际通信会议（IEEE ICC）*。IEEE，第 1–7 页。
- en: Matsubara et al. (2019) Yoshitomo Matsubara, Sabur Baidya, Davide Callegaro,
    Marco Levorato, and Sameer Singh. 2019. Distilled Split Deep Neural Networks for
    Edge-Assisted Real-Time Systems. In *Proc. of the 2019 MobiCom Workshop on Hot
    Topics in Video Analytics and Intelligent Edges*. 21–26.
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2019）Yoshitomo Matsubara、Sabur Baidya、Davide Callegaro、Marco Levorato
    和 Sameer Singh。2019。用于边缘辅助实时系统的蒸馏分割深度神经网络。发表于 *2019 MobiCom 研讨会：视频分析与智能边缘热点问题*。第
    21–26 页。
- en: 'Matsubara et al. (2020a) Yoshitomo Matsubara, Davide Callegaro, Sabur Baidya,
    Marco Levorato, and Sameer Singh. 2020a. Head Network Distillation: Splitting
    Distilled Deep Neural Networks for Resource-Constrained Edge Computing Systems.
    *IEEE Access* 8 (2020), 212177–212193. [https://doi.org/10.1109/ACCESS.2020.3039714](https://doi.org/10.1109/ACCESS.2020.3039714)'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2020a）Yoshitomo Matsubara、Davide Callegaro、Sabur Baidya、Marco Levorato
    和 Sameer Singh。2020a。头部网络蒸馏：为资源受限的边缘计算系统分割蒸馏深度神经网络。*IEEE Access* 8（2020年），第 212177–212193
    页。 [https://doi.org/10.1109/ACCESS.2020.3039714](https://doi.org/10.1109/ACCESS.2020.3039714)
- en: 'Matsubara et al. (2022a) Yoshitomo Matsubara, Davide Callegaro, Sameer Singh,
    Marco Levorato, and Francesco Restuccia. 2022a. BottleFit: Learning Compressed
    Representations in Deep Neural Networks for Effective and Efficient Split Computing.
    *arXiv preprint arXiv:2201.02693* (2022).'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2022a）Yoshitomo Matsubara、Davide Callegaro、Sameer Singh、Marco Levorato
    和 Francesco Restuccia。2022a。BottleFit：在深度神经网络中学习压缩表示以实现有效且高效的分割计算。*arXiv 预印本 arXiv:2201.02693*（2022年）。
- en: 'Matsubara and Levorato (2020) Yoshitomo Matsubara and Marco Levorato. 2020.
    Split Computing for Complex Object Detectors: Challenges and Preliminary Results.
    In *Proceedings of the 4th International Workshop on Embedded and Mobile Deep
    Learning*. 7–12.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 和 Levorato（2020）Yoshitomo Matsubara 和 Marco Levorato。2020。复杂目标检测器的分割计算：挑战与初步结果。发表于
    *第 4 届国际嵌入式与移动深度学习研讨会论文集*。第 7–12 页。
- en: Matsubara and Levorato (2021) Yoshitomo Matsubara and Marco Levorato. 2021.
    Neural Compression and Filtering for Edge-assisted Real-time Object Detection
    in Challenged Networks. In *2020 25th International Conference on Pattern Recognition
    (ICPR)*. 2272–2279.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 和 Levorato（2021）Yoshitomo Matsubara 和 Marco Levorato。2021。神经压缩与过滤：在受限网络中的边缘辅助实时目标检测。发表于
    *2020年第25届国际模式识别大会（ICPR）*。第 2272–2279 页。
- en: Matsubara et al. (2020b) Yoshitomo Matsubara, Thuy Vu, and Alessandro Moschitti.
    2020b. Reranking for efficient transformer-based answer selection. In *Proceedings
    of the 43rd International ACM SIGIR Conference on Research and Development in
    Information Retrieval*. 1577–1580.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2020b）Yoshitomo Matsubara、Thuy Vu 和 Alessandro Moschitti。2020b。基于
    Transformer 的答案选择的重排序。发表于 *第 43 届国际 ACM SIGIR 信息检索研究与开发会议论文集*。第 1577–1580 页。
- en: 'Matsubara et al. (2022b) Yoshitomo Matsubara, Ruihan Yang, Marco Levorato,
    and Stephan Mandt. 2022b. SC2: Supervised Compression for Split Computing. *arXiv
    preprint arXiv:2203.08875* (2022).'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2022b）Yoshitomo Matsubara、Ruihan Yang、Marco Levorato 和 Stephan
    Mandt。2022b。SC2：面向分割计算的有监督压缩。*arXiv 预印本 arXiv:2203.08875*（2022年）。
- en: Matsubara et al. (2022c) Yoshitomo Matsubara, Ruihan Yang, Marco Levorato, and
    Stephan Mandt. 2022c. Supervised Compression for Resource-Constrained Edge Computing
    Systems. In *Proceedings of the IEEE/CVF Winter Conference on Applications of
    Computer Vision*. 2685–2695.
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Matsubara 等人（2022c）Yoshitomo Matsubara、Ruihan Yang、Marco Levorato 和 Stephan
    Mandt。2022c。在资源受限的边缘计算系统中进行有监督压缩。发表于 *IEEE/CVF 计算机视觉应用冬季会议论文集*。第 2685–2695 页。
- en: Mirzadeh et al. (2020) Seyed Iman Mirzadeh, Mehrdad Farajtabar, Ang Li, Nir
    Levine, Akihiro Matsukawa, and Hassan Ghasemzadeh. 2020. Improved Knowledge Distillation
    via Teacher Assistant. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    Vol. 34. 5191–5198.
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mirzadeh 等人 (2020) Seyed Iman Mirzadeh、Mehrdad Farajtabar、Ang Li、Nir Levine、Akihiro
    Matsukawa 和 Hassan Ghasemzadeh。2020年。通过教师助手改进知识蒸馏。在 *Proceedings of the AAAI Conference
    on Artificial Intelligence* 中，第 34 卷，5191–5198。
- en: Mnih et al. (2013) Volodymyr Mnih, Koray Kavukcuoglu, David Silver, Alex Graves,
    Ioannis Antonoglou, Daan Wierstra, and Martin Riedmiller. 2013. Playing Atari
    with Deep Reinforcement Learning. *arXiv preprint arXiv:1312.5602* (2013).
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mnih 等人 (2013) Volodymyr Mnih、Koray Kavukcuoglu、David Silver、Alex Graves、Ioannis
    Antonoglou、Daan Wierstra 和 Martin Riedmiller。2013年。使用深度强化学习玩 Atari 游戏。*arXiv 预印本
    arXiv:1312.5602* (2013)。
- en: Nair and Hinton (2010) Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear
    units improve restricted boltzmann machines. In *Proceedings of the 27th International
    Conference on International Conference on Machine Learning*. 807–814.
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nair 和 Hinton (2010) Vinod Nair 和 Geoffrey E Hinton。2010年。整流线性单元改善限制玻尔兹曼机。在
    *Proceedings of the 27th International Conference on International Conference
    on Machine Learning* 中，807–814。
- en: Nakahara et al. (2021) Mutsuki Nakahara, Daisuke Hisano, Mai Nishimura, Yoshitaka
    Ushiku, Kazuki Maruta, and Yu Nakayama. 2021. Retransmission Edge Computing System
    Conducting Adaptive Image Compression Based on Image Recognition Accuracy. In
    *2021 IEEE 94rd Vehicular Technology Conference (VTC2021-Fall)*. IEEE, 1–5.
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nakahara 等人 (2021) Mutsuki Nakahara、Daisuke Hisano、Mai Nishimura、Yoshitaka Ushiku、Kazuki
    Maruta 和 Yu Nakayama。2021年。基于图像识别准确性的自适应图像压缩的再传输边缘计算系统。在 *2021 IEEE 94rd Vehicular
    Technology Conference (VTC2021-Fall)* 中，IEEE，1–5。
- en: Neshatpour et al. (2019) Katayoun Neshatpour, Farnaz Behnia, Houman Homayoun,
    and Avesta Sasan. 2019. Exploiting Energy-Accuracy Trade-off through Contextual
    Awareness in Multi-Stage Convolutional Neural Networks. In *20th International
    Symposium on Quality Electronic Design (ISQED)*. 265–270.
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neshatpour 等人 (2019) Katayoun Neshatpour、Farnaz Behnia、Houman Homayoun 和 Avesta
    Sasan。2019年。通过上下文意识在多阶段卷积神经网络中利用能量-准确性权衡。在 *20th International Symposium on Quality
    Electronic Design (ISQED)* 中，265–270。
- en: Netzer et al. ([n.d.]) Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco,
    Bo Wu, and Andrew Y Ng. [n.d.]. Reading digits in natural images with unsupervised
    feature learning. In *NIPS Workshop on Deep Learning and Unsupervised Feature
    Learning 2011*.
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Netzer 等人 ([n.d.]) Yuval Netzer、Tao Wang、Adam Coates、Alessandro Bissacco、Bo
    Wu 和 Andrew Y Ng。[n.d.] 在 *NIPS Workshop on Deep Learning and Unsupervised Feature
    Learning 2011* 中，讨论了自然图像中的数字阅读与无监督特征学习。
- en: 'Nguyen et al. (2016) Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao, Saurabh
    Tiwary, Rangan Majumder, and Li Deng. 2016. MS MARCO: A human generated machine
    reading comprehension dataset. In *CoCo@ NIPS*.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen 等人 (2016) Tri Nguyen、Mir Rosenberg、Xia Song、Jianfeng Gao、Saurabh Tiwary、Rangan
    Majumder 和 Li Deng。2016年。MS MARCO：一个由人类生成的机器阅读理解数据集。在 *CoCo@ NIPS* 中。
- en: Padhy et al. (2018) Ram Prasad Padhy, Sachin Verma, Shahzad Ahmad, Suman Kumar
    Choudhury, and Pankaj Kumar Sa. 2018. Deep Neural Network for Autonomous UAV Navigation
    in Indoor Corridor Environments. *Procedia computer science* 133 (2018), 643–650.
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Padhy 等人 (2018) Ram Prasad Padhy、Sachin Verma、Shahzad Ahmad、Suman Kumar Choudhury
    和 Pankaj Kumar Sa。2018年。用于室内走廊环境中自主 UAV 导航的深度神经网络。*Procedia computer science*
    133 (2018), 643–650。
- en: 'Pagliari et al. (2020) Daniele Jahier Pagliari, Roberta Chiaro, Enrico Macii,
    and Massimo Poncino. 2020. CRIME: Input-Dependent Collaborative Inference for
    Recurrent Neural Networks. *IEEE Trans. Comput.* (2020).'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pagliari 等人 (2020) Daniele Jahier Pagliari、Roberta Chiaro、Enrico Macii 和 Massimo
    Poncino。2020年。CRIME：基于输入的协作推断用于递归神经网络。*IEEE Trans. Comput.* (2020)。
- en: 'Panayotov et al. (2015) Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev
    Khudanpur. 2015. LibriSpeech: An ASR corpus based on public domain audio books.
    In *2015 IEEE International Conference on Acoustics, Speech and Signal Processing
    (ICASSP)*. IEEE, 5206–5210.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Panayotov 等人 (2015) Vassil Panayotov、Guoguo Chen、Daniel Povey 和 Sanjeev Khudanpur。2015年。LibriSpeech：一个基于公共领域有声书的
    ASR 语料库。在 *2015 IEEE International Conference on Acoustics, Speech and Signal
    Processing (ICASSP)* 中，IEEE，5206–5210。
- en: Phuong and Lampert (2019) Mary Phuong and Christoph H. Lampert. 2019. Distillation-Based
    Training for Multi-Exit Architectures. In *2019 IEEE/CVF International Conference
    on Computer Vision (ICCV)*. 1355–1364.
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Phuong 和 Lampert (2019) Mary Phuong 和 Christoph H. Lampert。2019年。基于蒸馏的多退出架构训练。在
    *2019 IEEE/CVF International Conference on Computer Vision (ICCV)* 中，1355–1364。
- en: Pomponi et al. (2021) Jary Pomponi, Simone Scardapane, and Aurelio Uncini. 2021.
    A Probabilistic Re-Intepretation of Confidence Scores in Multi-Exit Models. *Entropy*
    24, 1 (2021), 1.
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pomponi 等人 (2021) Jary Pomponi、Simone Scardapane 和 Aurelio Uncini。2021年。多退出模型中置信度分数的概率再解释。*Entropy*
    24, 1 (2021), 1。
- en: 'Pouyanfar et al. (2018) Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian,
    Yudong Tao, Maria Presa Reyes, Mei-Ling Shyu, Shu-Ching Chen, and SS Iyengar.
    2018. A Survey on Deep Learning: Algorithms, Techniques, and Applications. *ACM
    Computing Surveys (CSUR)* 51, 5 (2018), 1–36.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pouyanfar 等（2018）Samira Pouyanfar, Saad Sadiq, Yilin Yan, Haiman Tian, Yudong
    Tao, Maria Presa Reyes, Mei-Ling Shyu, Shu-Ching Chen 和 SS Iyengar. 2018. 深度学习综述：算法、技术及应用。*ACM
    Computing Surveys (CSUR)* 51, 5 (2018), 1–36。
- en: Povey et al. (2011) Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget,
    Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr
    Schwarz, et al. 2011. The Kaldi speech recognition toolkit. In *IEEE 2011 workshop
    on automatic speech recognition and understanding*. IEEE Signal Processing Society.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Povey 等（2011）Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej
    Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz
    等。2011. Kaldi 语音识别工具包。载于 *IEEE 2011 自动语音识别与理解研讨会*。IEEE 信号处理学会。
- en: Qiu et al. (2018) Y. Qiu, Hongzheng Li, Shen Li, Yingdi Jiang, Renfen Hu, and
    L. Yang. 2018. Revisiting Correlations between Intrinsic and Extrinsic Evaluations
    of Word Embeddings. In *CCL*.
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qiu 等（2018）Y. Qiu, Hongzheng Li, Shen Li, Yingdi Jiang, Renfen Hu 和 L. Yang.
    2018. 重新审视词嵌入的内在与外在评估之间的关联。载于 *CCL*。
- en: Radosavovic et al. (2020) Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick,
    Kaiming He, and Piotr Dollár. 2020. Designing Network Design Spaces. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 10428–10436.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radosavovic 等（2020）Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming
    He 和 Piotr Dollár. 2020. 网络设计空间的设计。载于 *IEEE/CVF 计算机视觉与模式识别会议论文集*。10428–10436。
- en: 'Rajpurkar et al. (2016) Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and
    Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text.
    In *Proceedings of the 2016 Conference on Empirical Methods in Natural Language
    Processing*. 2383–2392.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rajpurkar 等（2016）Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev 和 Percy Liang.
    2016. SQuAD：用于机器理解文本的 100,000+ 问题。载于 *2016 年自然语言处理经验方法会议论文集*。2383–2392。
- en: 'Redmon and Farhadi (2017) Joseph Redmon and Ali Farhadi. 2017. YOLO9000: better,
    faster, stronger. In *Proceedings of the IEEE conference on computer vision and
    pattern recognition*. 7263–7271.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon 和 Farhadi（2017）Joseph Redmon 和 Ali Farhadi. 2017. YOLO9000：更好、更快、更强。载于
    *IEEE 计算机视觉与模式识别会议论文集*。7263–7271。
- en: 'Redmon and Farhadi (2018) Joseph Redmon and Ali Farhadi. 2018. YOLOv3: An incremental
    improvement. *arXiv preprint arXiv:1804.02767* (2018).'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Redmon 和 Farhadi（2018）Joseph Redmon 和 Ali Farhadi. 2018. YOLOv3：渐进改进。*arXiv
    预印本 arXiv:1804.02767*（2018）。
- en: 'Ren et al. (2015) Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. 2015.
    Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.
    In *Advances in neural information processing systems*. 91–99.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 等（2015）Shaoqing Ren, Kaiming He, Ross Girshick 和 Jian Sun. 2015. Faster
    R-CNN：通过区域建议网络实现实时目标检测。载于 *神经信息处理系统进展*。91–99。
- en: 'Restuccia and Melodia (2020) Francesco Restuccia and Tommaso Melodia. 2020.
    Deep Learning at the Physical Layer: System Challenges and Applications to 5G
    and Beyond. *IEEE Communications Magazine* 58, 10 (2020), 58–64. [https://doi.org/10.1109/MCOM.001.2000243](https://doi.org/10.1109/MCOM.001.2000243)'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Restuccia 和 Melodia（2020）Francesco Restuccia 和 Tommaso Melodia. 2020. 物理层的深度学习：系统挑战及其在
    5G 及更远领域的应用。*IEEE 通信杂志* 58, 10 (2020), 58–64。 [https://doi.org/10.1109/MCOM.001.2000243](https://doi.org/10.1109/MCOM.001.2000243)
- en: Roig et al. (2011) Gemma Roig, Xavier Boix, Horesh Ben Shitrit, and Pascal Fua.
    2011. Conditional random fields for multi-camera object detection. In *2011 International
    Conference on Computer Vision*. IEEE, 563–570.
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Roig 等（2011）Gemma Roig, Xavier Boix, Horesh Ben Shitrit 和 Pascal Fua. 2011.
    用于多摄像头目标检测的条件随机场。载于 *2011 国际计算机视觉会议*。IEEE，563–570。
- en: Russakovsky et al. (2015) Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause,
    Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael
    Bernstein, Alexander C. Berg, and Li Fei-Fei. 2015. ImageNet Large Scale Visual
    Recognition Challenge. *International Journal of Computer Vision* 115, 3 (2015),
    211–252.
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky 等（2015）Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev
    Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein,
    Alexander C. Berg 和 Li Fei-Fei. 2015. ImageNet 大规模视觉识别挑战。*计算机视觉国际期刊* 115, 3 (2015),
    211–252。
- en: 'Samie et al. (2016) Farzad Samie, Lars Bauer, and Jörg Henkel. 2016. IoT Technologies
    for Embedded Computing: A Survey. In *2016 International Conference on Hardware/Software
    Codesign and System Synthesis (CODES+ ISSS)*. IEEE, 1–10.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Samie 等（2016）Farzad Samie, Lars Bauer 和 Jörg Henkel. 2016. 嵌入式计算的物联网技术：综述。载于
    *2016 国际硬件/软件共同设计与系统综合会议（CODES+ ISSS）*。IEEE，1–10。
- en: 'Sandler et al. (2018) Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov,
    and Liang-Chieh Chen. 2018. MobileNetV2: Inverted Residuals and Linear Bottlenecks.
    In *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.
    4510–4520.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '桑德勒等（2018）马克·桑德勒、安德鲁·霍华德、孟龙·朱、安德雷·日莫金诺夫和梁志杰。2018年。《MobileNetV2: 反向残差和线性瓶颈》。在*IEEE计算机视觉与模式识别会议论文集*中，第4510–4520页。'
- en: 'Saxe et al. (2019) Andrew M Saxe, Yamini Bansal, Joel Dapello, Madhu Advani,
    Artemy Kolchinsky, Brendan D Tracey, and David D Cox. 2019. On the information
    bottleneck theory of deep learning. *Journal of Statistical Mechanics: Theory
    and Experiment* 2019, 12 (2019), 124020.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 萨克斯等（2019）安德鲁·M·萨克斯、亚米尼·班萨尔、乔尔·达佩洛、马杜·阿德瓦尼、阿尔泰米·科尔钦斯基、布伦丹·D·特雷西和大卫·D·考克斯。2019年。《深度学习的信息瓶颈理论》。*统计力学期刊：理论与实验*
    2019，第12期（2019年），124020。
- en: 'Sbai et al. (2021) Marion Sbai, Muhamad Risqi U Saputra, Niki Trigoni, and
    Andrew Markham. 2021. Cut, Distil and Encode (CDE): Split Cloud-Edge Deep Inference.
    In *2021 18th Annual IEEE International Conference on Sensing, Communication,
    and Networking (SECON)*. IEEE, 1–9.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯巴伊等（2021）马里昂·斯巴伊、穆罕默德·里斯基·U·萨普特拉、尼基·特里戈尼和安德鲁·马尔卡姆。2021年。《切分、蒸馏和编码（CDE）：拆分云-边缘深度推理》。在*2021年第18届IEEE国际传感、通信和网络会议（SECON）*中。IEEE，第1–9页。
- en: 'Sermanet et al. (2014) Pierre Sermanet, David Eigen, Xiang Zhang, Michaël Mathieu,
    Rob Fergus, and Yann LeCun. 2014. OverFeat: Integrated recognition, localization
    and detection using convolutional networks. In *Second International Conference
    on Learning Representations*.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '萨梅内特等（2014）皮埃尔·萨梅内特、大卫·艾根、项张、米歇尔·马修、罗布·费格斯和扬·勒昆。2014年。《OverFeat: 使用卷积网络进行集成识别、定位和检测》。在*第二届国际学习表示大会*中。'
- en: 'Shao and Zhang (2020) Jiawei Shao and Jun Zhang. 2020. BottleNet++: An End-to-End
    Approach for Feature Compression in Device-Edge Co-Inference Systems. In *2020
    IEEE International Conference on Communications Workshops (ICC Workshops)*. IEEE,
    1–6.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '邵和张（2020）贾伟·邵和俊·张。2020年。《BottleNet++: 端到端的设备-边缘协同推理系统中的特征压缩方法》。在*2020 IEEE国际通信会议研讨会（ICC
    Workshops）*中。IEEE，第1–6页。'
- en: Silver et al. (2017) David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis
    Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian
    Bolton, et al. 2017. Mastering the Game of Go Without Human Knowledge. *Nature*
    550, 7676 (2017), 354.
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西尔弗等（2017）大卫·西尔弗、朱利安·施里特维塞尔、凯伦·西蒙尼安、伊奥尼斯·安东诺格卢、阿贾·黄、亚瑟·盖兹、托马斯·休伯特、卢卡斯·贝克、马修·莱、阿德里安·博尔顿等。2017年。《在没有人类知识的情况下掌握围棋》。*自然*
    550，第7676期（2017年），354页。
- en: Simonyan and Zisserman (2015) Karen Simonyan and Andrew Zisserman. 2015. Very
    deep convolutional networks for large-scale image recognition. In *Third International
    Conference on Learning Representations*.
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 西蒙尼安和齐瑟曼（2015）凯伦·西蒙尼安和安德鲁·齐瑟曼。2015年。《用于大规模图像识别的非常深的卷积网络》。在*第三届国际学习表示大会*中。
- en: 'Singh et al. (2018) Amarjot Singh, Devendra Patil, and SN Omkar. 2018. Eye
    in the sky: Real-time Drone Surveillance System (DSS) for violent individuals
    identification using ScatterNet Hybrid Deep Learning network. In *Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition Workshops*.
    1629–1637.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 辛格等（2018）阿玛尔乔特·辛格、德文德拉·帕蒂尔和SN·奥姆卡尔。2018年。《天眼：用于暴力个体识别的实时无人机监控系统（DSS），采用ScatterNet混合深度学习网络》。在*IEEE计算机视觉与模式识别会议研讨会论文集*中，第1629–1637页。
- en: Snell et al. (2017) Jake Snell, Kevin Swersky, and Richard Zemel. 2017. Prototypical
    networks for few-shot learning. In *Advances in neural information processing
    systems*. 4077–4087.
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 斯内尔等（2017）杰克·斯内尔、凯文·斯维尔斯基和理查德·泽梅尔。2017年。《少样本学习的原型网络》。在*神经信息处理系统进展*中，第4077–4087页。
- en: Socher et al. (2013) Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang,
    Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep
    models for semantic compositionality over a sentiment treebank. In *Proceedings
    of the 2013 conference on empirical methods in natural language processing*. 1631–1642.
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索切尔等（2013）理查德·索切尔、亚历克斯·佩雷尔金、简·吴、杰森·庄、克里斯托弗·D·曼宁、安德鲁·Y·吴和克里斯托弗·波茨。2013年。《语义组合的递归深度模型在情感树库上的应用》。在*2013年自然语言处理领域实证方法会议论文集*中，第1631–1642页。
- en: 'Soldaini and Moschitti (2020) Luca Soldaini and Alessandro Moschitti. 2020.
    The Cascade Transformer: an Application for Efficient Answer Sentence Selection.
    In *Proceedings of the 58th Annual Meeting of the Association for Computational
    Linguistics*. 5697–5708.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 索尔达尼和莫斯基提（2020）卢卡·索尔达尼和亚历山德罗·莫斯基提。2020年。《级联变换器：高效回答句子选择的应用》。在*第58届计算语言学协会年会论文集*中，第5697–5708页。
- en: 'Srivastava et al. (2014) Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky,
    Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A Simple Way to Prevent
    Neural Networks from Overfitting. *The journal of machine learning research* 15,
    1 (2014), 1929–1958.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Srivastava 等人 (2014) **Nitish Srivastava**, **Geoffrey Hinton**, **Alex Krizhevsky**,
    **Ilya Sutskever** 和 **Ruslan Salakhutdinov**。2014年。《Dropout: 一种防止神经网络过拟合的简单方法》。*机器学习研究期刊*
    15, 1 (2014), 1929–1958。'
- en: Steiner et al. (2021) Andreas Steiner, Alexander Kolesnikov, Xiaohua Zhai, Ross
    Wightman, Jakob Uszkoreit, and Lucas Beyer. 2021. How to train your ViT? Data,
    Augmentation, and Regularization in Vision Transformers. *arXiv preprint arXiv:2106.10270*
    (2021).
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Steiner 等人 (2021) **Andreas Steiner**, **Alexander Kolesnikov**, **Xiaohua Zhai**,
    **Ross Wightman**, **Jakob Uszkoreit** 和 **Lucas Beyer**。2021年。《如何训练你的ViT？视觉变换器中的数据、增强和正则化》。*arXiv
    预印本 arXiv:2106.10270* (2021)。
- en: Szegedy et al. (2015) Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet,
    Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich.
    2015. Going deeper with convolutions. In *Proceedings of the IEEE conference on
    computer vision and pattern recognition*. 1–9.
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人 (2015) **Christian Szegedy**, **Wei Liu**, **Yangqing Jia**, **Pierre
    Sermanet**, **Scott Reed**, **Dragomir Anguelov**, **Dumitru Erhan**, **Vincent
    Vanhoucke** 和 **Andrew Rabinovich**。2015年。《深入卷积》。在*IEEE计算机视觉与模式识别会议论文集*中，1–9。
- en: Szegedy et al. (2016) Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon
    Shlens, and Zbigniew Wojna. 2016. Rethinking the inception architecture for computer
    vision. In *Proceedings of the IEEE conference on computer vision and pattern
    recognition*. 2818–2826.
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人 (2016) **Christian Szegedy**, **Vincent Vanhoucke**, **Sergey Ioffe**,
    **Jon Shlens** 和 **Zbigniew Wojna**。2016年。《重新思考计算机视觉中的Inception架构》。在*IEEE计算机视觉与模式识别会议论文集*中，2818–2826。
- en: 'Taigman et al. (2014) Yaniv Taigman, Ming Yang, Marc’Aurelio Ranzato, and Lior
    Wolf. 2014. Deepface: Closing the gap to human-level performance in face verification.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*.
    1701–1708.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Taigman 等人 (2014) **Yaniv Taigman**, **Ming Yang**, **Marc’Aurelio Ranzato**
    和 **Lior Wolf**。2014年。《Deepface: 缩小人脸验证中的人类水平性能差距》。在*IEEE计算机视觉与模式识别会议论文集*中，1701–1708。'
- en: 'Tan et al. (2019) Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark
    Sandler, Andrew Howard, and Quoc V Le. 2019. MnasNet: Platform-Aware Neural Architecture
    Search for Mobile. In *Proceedings of the IEEE Conf. on Computer Vision and Pattern
    Recognition*. 2820–2828.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tan 等人 (2019) **Mingxing Tan**, **Bo Chen**, **Ruoming Pang**, **Vijay Vasudevan**,
    **Mark Sandler**, **Andrew Howard** 和 **Quoc V Le**。2019年。《MnasNet: 面向移动的平台感知神经架构搜索》。在*IEEE计算机视觉与模式识别会议论文集*中，2820–2828。'
- en: 'Tan et al. (2020) Mingxing Tan, Ruoming Pang, and Quoc V Le. 2020. EfficientDet:
    Scalable and Efficient Object Detection. In *Proceedings of the IEEE/CVF conference
    on computer vision and pattern recognition*. 10781–10790.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tan 等人 (2020) **Mingxing Tan**, **Ruoming Pang** 和 **Quoc V Le**。2020年。《EfficientDet:
    可扩展且高效的目标检测》。在*IEEE/CVF计算机视觉与模式识别会议论文集*中，10781–10790。'
- en: 'Teerapittayanon et al. (2016) Surat Teerapittayanon, Bradley McDanel, and Hsiang-Tsung
    Kung. 2016. BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks.
    In *2016 23rd International Conference on Pattern Recognition (ICPR)*. IEEE, 2464–2469.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Teerapittayanon 等人 (2016) **Surat Teerapittayanon**, **Bradley McDanel** 和
    **Hsiang-Tsung Kung**。2016年。《BranchyNet: 通过早期退出实现快速推理》。在*2016年第23届国际模式识别大会（ICPR）*中。IEEE,
    2464–2469。'
- en: Teerapittayanon et al. (2017) Surat Teerapittayanon, Bradley McDanel, and H. T.
    Kung. 2017. Distributed Deep Neural Networks Over the Cloud, the Edge and End
    Devices. In *2017 IEEE 37th International Conference on Distributed Computing
    Systems (ICDCS)*. 328–339.
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Teerapittayanon 等人 (2017) **Surat Teerapittayanon**, **Bradley McDanel** 和 **H.
    T. Kung**。2017年。《分布式深度神经网络：云端、边缘和终端设备》。在*2017 IEEE第37届国际分布式计算系统会议（ICDCS）*中，328–339。
- en: Tishby et al. (2000) Naftali Tishby, Fernando C Pereira, and William Bialek.
    2000. The information bottleneck method. *arXiv preprint physics/0004057* (2000).
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tishby 等人 (2000) **Naftali Tishby**, **Fernando C Pereira** 和 **William Bialek**。2000年。《信息瓶颈方法》。*arXiv
    预印本 physics/0004057* (2000)。
- en: Tishby and Zaslavsky (2015) Naftali Tishby and Noga Zaslavsky. 2015. Deep learning
    and the information bottleneck principle. In *2015 IEEE Information Theory Workshop
    (ITW)*. IEEE, 1–5.
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tishby 和 Zaslavsky (2015) **Naftali Tishby** 和 **Noga Zaslavsky**。2015年。《深度学习与信息瓶颈原理》。在*2015
    IEEE信息理论研讨会（ITW）*中。IEEE, 1–5。
- en: Ultralytics ([n.d.]) Ultralytics. [n.d.]. YOLOv5. https://github.com/ultralytics/yolov5.
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ultralytics ([n.d.]) **Ultralytics**。 [n.d.]。《YOLOv5》。https://github.com/ultralytics/yolov5。
- en: Vaswani et al. (2017) Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit,
    Llion Jones, Aidan N Gomez, Ł ukasz Kaiser, and Illia Polosukhin. 2017. Attention
    is All you Need. In *Advances in Neural Information Processing Systems*, I. Guyon,
    U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett
    (Eds.), Vol. 30\. Curran Associates, Inc., 5998–6008.
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vaswani 等（2017）Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion
    Jones、Aidan N Gomez、Ł ukasz Kaiser 和 Illia Polosukhin。2017。《注意力即一切》。在*神经信息处理系统进展*中，I.
    Guyon、U. V. Luxburg、S. Bengio、H. Wallach、R. Fergus、S. Vishwanathan 和 R. Garnett（编），第30卷。Curran
    Associates, Inc.，5998–6008。
- en: 'Wang et al. (2019b) Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill,
    Omer Levy, and Samuel R Bowman. 2019b. GLUE: A Multi-Task Benchmark and Analysis
    Platform for Natural Language Understanding. In *International Conference on Learning
    Representations*.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2019b）Alex Wang、Amanpreet Singh、Julian Michael、Felix Hill、Omer Levy 和
    Samuel R Bowman。2019b。《GLUE：自然语言理解的多任务基准和分析平台》。在*国际学习表征会议*。
- en: Wang et al. (2020a) Fei Wang, Boyu Diao, Tao Sun, and Yongjun Xu. 2020a. Data
    security and privacy challenges of computing offloading in fins. *IEEE Network*
    34, 2 (2020), 14–20.
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2020a）Fei Wang、Boyu Diao、Tao Sun 和 Yongjun Xu。2020a。《鳍片计算卸载的数据安全和隐私挑战》。*IEEE
    网络* 34, 2（2020），14–20。
- en: 'Wang et al. (2019a) Meiqi Wang, Jianqiao Mo, Jun Lin, Zhongfeng Wang, and Li
    Du. 2019a. DynExit: A Dynamic Early-Exit Strategy for Deep Residual Networks.
    In *2019 IEEE International Workshop on Signal Processing Systems (SiPS)*. IEEE,
    178–183.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2019a）Meiqi Wang、Jianqiao Mo、Jun Lin、Zhongfeng Wang 和 Li Du。2019a。《DynExit：深度残差网络的动态早期退出策略》。在*2019
    IEEE 国际信号处理系统研讨会（SiPS）*。IEEE，178–183。
- en: Wang et al. (2007) Mengqiu Wang, Noah A Smith, and Teruko Mitamura. 2007. What
    is the Jeopardy model? A quasi-synchronous grammar for QA. In *Proceedings of
    the 2007 Joint Conference on Empirical Methods in Natural Language Processing
    and Computational Natural Language Learning (EMNLP-CoNLL)*. 22–32.
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2007）Mengqiu Wang、Noah A Smith 和 Teruko Mitamura。2007。《什么是Jeopardy模型？一种准同步语法用于问答》。在*2007年自然语言处理和计算自然语言学习联合会议（EMNLP-CoNLL）*。22–32。
- en: 'Wang et al. (2020b) Yue Wang, Jianghao Shen, Ting-Kuei Hu, P. Xu, Tan Nguyen,
    Richard Baraniuk, Zhangyang Wang, and Yingyan Lin. 2020b. Dual Dynamic Inference:
    Enabling More Efficient, Adaptive, and Controllable Deep Inference. *IEEE Journal
    of Selected Topics in Signal Processing* 14 (2020), 623–633.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等（2020b）Yue Wang、Jianghao Shen、Ting-Kuei Hu、P. Xu、Tan Nguyen、Richard Baraniuk、Zhangyang
    Wang 和 Yingyan Lin。2020b。《双动态推断：实现更高效、适应性强且可控的深度推断》。*IEEE 选择信号处理主题期刊* 14（2020），623–633。
- en: Warstadt et al. (2019) Alex Warstadt, Amanpreet Singh, and Samuel Bowman. 2019.
    Neural Network Acceptability Judgments. *Transactions of the Association for Computational
    Linguistics* 7 (2019), 625–641.
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Warstadt 等（2019）Alex Warstadt、Amanpreet Singh 和 Samuel Bowman。2019。《神经网络可接受性判断》。*计算语言学协会会刊*
    7（2019），625–641。
- en: 'Williams et al. (2018) Adina Williams, Nikita Nangia, and Samuel Bowman. 2018.
    A Broad-Coverage Challenge Corpus for Sentence Understanding through Inference.
    In *Proceedings of the 2018 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)*.
    1112–1122.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Williams 等（2018）Adina Williams、Nikita Nangia 和 Samuel Bowman。2018。《一个用于通过推理进行句子理解的广覆盖挑战语料库》。在*2018年北美计算语言学协会年会：人类语言技术会议论文集第一卷（长篇论文）*。1112–1122。
- en: 'Wołczyk et al. (2021) Maciej Wołczyk, Bartosz Wójcik, Klaudia Bałazy, Igor
    Podolak, Jacek Tabor, Marek Śmieja, and Tomasz Trzcinski. 2021. Zero Time Waste:
    Recycling Predictions in Early Exit Neural Networks. *Advances in Neural Information
    Processing Systems* 34 (2021).'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wołczyk 等（2021）Maciej Wołczyk、Bartosz Wójcik、Klaudia Bałazy、Igor Podolak、Jacek
    Tabor、Marek Śmieja 和 Tomasz Trzcinski。2021。《零时间浪费：早期退出神经网络中的回收预测》。*神经信息处理系统进展*
    34（2021）。
- en: 'Wolf et al. (2020) Thomas Wolf, Julien Chaumond, Lysandre Debut, Victor Sanh,
    Clement Delangue, Anthony Moi, Pierric Cistac, Morgan Funtowicz, Joe Davison,
    Sam Shleifer, et al. 2020. Transformers: State-of-the-art natural language processing.
    In *Proceedings of the 2020 Conference on Empirical Methods in Natural Language
    Processing: System Demonstrations*. 38–45.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wolf 等（2020）Thomas Wolf、Julien Chaumond、Lysandre Debut、Victor Sanh、Clement Delangue、Anthony
    Moi、Pierric Cistac、Morgan Funtowicz、Joe Davison、Sam Shleifer 等。2020。《Transformers：最先进的自然语言处理》。在*2020年自然语言处理经验方法会议：系统演示*。38–45。
- en: 'Xin et al. (2020a) Ji Xin, Rodrigo Nogueira, Yaoliang Yu, and Jimmy Lin. 2020a.
    Early Exiting BERT for Efficient Document Ranking. In *Proceedings of SustaiNLP:
    Workshop on Simple and Efficient Natural Language Processing*. 83–88.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xin et al. (2020a) Ji Xin, Rodrigo Nogueira, Yaoliang Yu, 和 Jimmy Lin. 2020a.
    高效文档排名的早期退出BERT。在 *SustaiNLP：简单高效自然语言处理研讨会*。83–88。
- en: 'Xin et al. (2020b) Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, and Jimmy
    Lin. 2020b. DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference. In
    *Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics*.
    2246–2251.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Xin et al. (2020b) Ji Xin, Raphael Tang, Jaejun Lee, Yaoliang Yu, 和 Jimmy Lin.
    2020b. DeeBERT: 动态提前退出加速BERT推断。在 *第58届计算语言学协会年会论文集*。2246–2251。'
- en: 'Xing et al. (2020) Qunliang Xing, Mai Xu, Tianyi Li, and Zhenyu Guan. 2020.
    Early Exit Or Not: Resource-Efficient Blind Quality Enhancement for Compressed
    Images. In *Computer Vision – ECCV 2020*. Springer International Publishing.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xing et al. (2020) Qunliang Xing, Mai Xu, Tianyi Li, 和 Zhenyu Guan. 2020. 提前退出还是不退出：资源高效的盲质量增强用于压缩图像。在
    *计算机视觉 – ECCV 2020*。Springer International Publishing。
- en: Yang et al. (2020b) L. Yang, Yizeng Han, X. Chen, Shiji Song, Jifeng Dai, and
    Gao Huang. 2020b. Resolution Adaptive Networks for Efficient Inference. In *2020
    IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)*. 2366–2375.
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2020b) L. Yang, Yizeng Han, X. Chen, Shiji Song, Jifeng Dai, 和
    Gao Huang. 2020b. 用于高效推断的分辨率自适应网络。在 *2020 IEEE/CVF计算机视觉与模式识别会议 (CVPR)*。2366–2375。
- en: 'Yang et al. (2020c) Taojiannan Yang, Sijie Zhu, Chen Chen, Shen Yan, Mi Zhang,
    and Andrew Willis. 2020c. MutualNet: Adaptive convnet via mutual learning from
    network width and resolution. In *European conference on computer vision*. Springer,
    299–315.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2020c) Taojiannan Yang, Sijie Zhu, Chen Chen, Shen Yan, Mi Zhang,
    和 Andrew Willis. 2020c. MutualNet: 通过网络宽度和分辨率的互学习进行自适应卷积网络。在 *欧洲计算机视觉会议*。Springer,
    299–315。'
- en: Yang et al. (2017) Tien-Ju Yang, Yu-Hsin Chen, and Vivienne Sze. 2017. Designing
    energy-efficient convolutional neural networks using energy-aware pruning. In
    *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition*.
    5687–5695.
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2017) Tien-Ju Yang, Yu-Hsin Chen, 和 Vivienne Sze. 2017. 设计节能卷积神经网络的方法，采用能量感知剪枝。在
    *IEEE计算机视觉与模式识别会议论文集*。5687–5695。
- en: 'Yang et al. (2018) Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go,
    Mark Sandler, Vivienne Sze, and Hartwig Adam. 2018. NetAdapt: Platform-Aware Neural
    Network Adaptation for Mobile Applications. In *Proceedings of the European Conference
    on Computer Vision (ECCV)*. 285–300.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2018) Tien-Ju Yang, Andrew Howard, Bo Chen, Xiao Zhang, Alec Go,
    Mark Sandler, Vivienne Sze, 和 Hartwig Adam. 2018. NetAdapt: 针对移动应用的跨平台神经网络适配。在
    *欧洲计算机视觉会议 (ECCV) 论文集*。285–300。'
- en: Yang et al. (2020a) Yibo Yang, Robert Bamler, and Stephan Mandt. 2020a. Variational
    bayesian quantization. In *International Conference on Machine Learning*. PMLR,
    10670–10680.
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2020a) Yibo Yang, Robert Bamler, 和 Stephan Mandt. 2020a. 变分贝叶斯量化。在
    *国际机器学习会议*。PMLR, 10670–10680。
- en: 'Yang et al. (2015) Yi Yang, Wen-tau Yih, and Christopher Meek. 2015. WikiQA:
    A challenge dataset for open-domain question answering. In *Proceedings of the
    2015 conference on empirical methods in natural language processing*. 2013–2018.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yang et al. (2015) Yi Yang, Wen-tau Yih, 和 Christopher Meek. 2015. WikiQA:
    一个用于开放领域问答的挑战数据集。在 *2015年自然语言处理实证方法会议论文集*。2013–2018。'
- en: 'Yao et al. (2020) Shuochao Yao, Jinyang Li, Dongxin Liu, Tianshi Wang, Shengzhong
    Liu, Huajie Shao, and Tarek Abdelzaher. 2020. Deep compressive offloading: speeding
    up neural network inference by trading edge computation for network latency. In
    *Proceedings of the 18th Conference on Embedded Networked Sensor Systems*. 476–488.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2020) Shuochao Yao, Jinyang Li, Dongxin Liu, Tianshi Wang, Shengzhong
    Liu, Huajie Shao, 和 Tarek Abdelzaher. 2020. 深度压缩卸载：通过将边缘计算与网络延迟交换来加速神经网络推断。在 *第18届嵌入式网络传感系统会议论文集*。476–488。
- en: Yu and Principe (2019) Shujian Yu and Jose C Principe. 2019. Understanding autoencoders
    with information theoretic concepts. *Neural Networks* 117 (2019), 104–123.
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu and Principe (2019) Shujian Yu 和 Jose C Principe. 2019. 使用信息理论概念理解自动编码器。*神经网络*
    117 (2019), 104–123。
- en: 'Yu et al. (2020) Shujian Yu, Kristoffer Wickstrøm, Robert Jenssen, and José C
    Príncipe. 2020. Understanding convolutional neural networks with information theory:
    An initial exploration. *IEEE transactions on neural networks and learning systems*
    (2020).'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu et al. (2020) Shujian Yu, Kristoffer Wickstrøm, Robert Jenssen, 和 José C
    Príncipe. 2020. 使用信息理论理解卷积神经网络：初步探索。*IEEE神经网络与学习系统汇刊* (2020)。
- en: Zagoruyko and Komodakis (2016) Sergey Zagoruyko and Nikos Komodakis. 2016. Wide
    Residual Networks. In *Proceedings of the British Machine Vision Conference (BMVC)*.
    BMVA Press, 87.1–87.12.
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zagoruyko和Komodakis（2016）谢尔盖·扎戈鲁伊科和尼科斯·科莫达基斯。2016年。《宽残差网络》。在*英国机器视觉会议（BMVC）论文集*中。BMVA出版社，87.1–87.12。
- en: 'Zeng et al. (2019) Liekang Zeng, En Li, Zhi Zhou, and X. Chen. 2019. Boomerang:
    On-Demand Cooperative Deep Neural Network Inference for Edge Intelligence on the
    Industrial Internet of Things. *IEEE Network* 33 (2019), 96–103.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng等（2019）李康·曾、恩·李、智·周和X. 陈。2019年。《回旋镖：工业物联网边缘智能的按需协作深度神经网络推理》。*IEEE网络* 33（2019），96–103。
- en: Zhang et al. (2019) Menglei Zhang, Michele Polese, Marco Mezzavilla, Jing Zhu,
    Sundeep Rangan, Shivendra Panwar, and Michele Zorzi. 2019. Will TCP work in mmWave
    5G cellular networks? *IEEE Communications Magazine* 57, 1 (2019), 65–71.
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2019）孟磊·张、米歇尔·波雷塞、马尔科·梅扎维拉、靖·朱、桑迪普·兰甘、希文德拉·潘瓦尔和米歇尔·佐尔齐。2019年。《TCP在毫米波5G蜂窝网络中的表现如何？》*IEEE通讯杂志*
    57，1（2019），65–71。
- en: Zhang et al. (2020) Shizhou Zhang, Qi Zhang, Yifei Yang, Xing Wei, Peng Wang,
    Bingliang Jiao, and Yanning Zhang. 2020. Person Re-identification in Aerial imagery.
    *IEEE Transactions on Multimedia* 23 (2020), 281–291.
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2020）石周·张、齐·张、伊飞·杨、邢·魏、彭·王、冰亮·焦和延宁·张。2020年。《空中图像中的人物重识别》。*IEEE多媒体学报*
    23（2020），281–291。
- en: Zhang et al. (2015) X. Zhang, J. Zhao, and Y. LeCun. 2015. Character-level Convolutional
    Networks for Text Classification. In *NIPS*.
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang等（2015）X. 张、J. 赵和Y. LeCun。2015年。《字符级卷积网络用于文本分类》。在*NIPS*会议上。
- en: 'Zhou et al. (2020) Wangchunshu Zhou, Canwen Xu, Tao Ge, Julian McAuley, Ke
    Xu, and Furu Wei. 2020. BERT Loses Patience: Fast and Robust Inference with Early
    Exit. *Advances in Neural Information Processing Systems* 33 (2020).'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou等（2020）王春树·周、岑文·徐、陶·葛、朱利安·麦考利、柯·徐和傅如·魏。2020年。《BERT失去耐心：通过早期退出实现快速且鲁棒的推理》。*神经信息处理系统进展*
    33（2020）。
- en: Zoph and Le (2017) Barret Zoph and Quoc Le. 2017. Neural Architecture Search
    with Reinforcement Learning. In *International Conference on Learning Representations*.
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zoph和Le（2017）巴雷特·佐普和阮国。2017年。《使用强化学习进行神经架构搜索》。在*国际学习表征会议*上。
- en: Zoph et al. (2018) Barret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V
    Le. 2018. Learning Transferable Architectures for Scalable Image Recognition.
    In *Proceedings of the IEEE conference on computer vision and pattern recognition*.
    8697–8710.
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zoph等（2018）巴雷特·佐普、维贾伊·瓦苏德万、乔纳森·施伦斯和阮国·V·Le。2018年。《学习可转移架构以实现可扩展图像识别》。在*IEEE计算机视觉与模式识别会议论文集*中。8697–8710。
