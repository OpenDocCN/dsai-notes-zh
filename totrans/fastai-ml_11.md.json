["```py\nif y == 1: return -log(\u0177)\nelse: return -log(1-\u0177)\n```", "```py\nveczr =  CountVectorizer(ngram_range=(1,3), tokenizer=tokenize, \n                         max_features=800000)\ntrn_term_doc = veczr.fit_transform(trn)\nval_term_doc = veczr.transform(val)trn_term_doc.shape*(25000, 800000)*vocab = veczr.get_feature_names()vocab[200000:200005]*['by vast', 'by vengeance', 'by vengeance .', 'by vera', 'by vera miles']*\n```", "```py\ny=trn_y\nx=trn_term_doc.sign()\nval_x = val_term_doc.sign()\np = x[y==1].sum(0)+1\nq = x[y==0].sum(0)+1\nr = np.log((p/p.sum())/(q/q.sum()))\nb = np.log(len(p)/len(q))\n```", "```py\nm = LogisticRegression(C=0.1, dual=**True**)\nm.fit(x, y);\n\npreds = m.predict(val_x)\n(preds.T==val_y).mean()*0.90500000000000003*\n```", "```py\nr.shape, r((1, 800000),\n matrix([[-0.05468, -0.161  , -0.24784, ...,  1.09861, -0.69315, -0.69315]]))\n```", "```py\nnp.exp(r)matrix([[ 0.94678,  0.85129,  0.78049, ...,  3\\.  ,  0.5 ,  0.5  ]])\n```", "```py\nx_nb = x.multiply(r)\nm = LogisticRegression(dual=**True**, C=0.1)\nm.fit(x_nb, y);\n\nval_x_nb = val_x.multiply(r)\npreds = m.predict(val_x_nb)\n(preds.T==val_y).mean()*0.91768000000000005*\n```", "```py\nsl=2000*# Here is how we get a model from a bag of words*\nmd = TextClassifierData.from_bow(trn_term_doc, trn_y, val_term_doc,\n                                 val_y, sl)\n```", "```py\nlearner = md.dotprod_nb_learner()\nlearner.fit(0.02, 1, wds=1e-6, cycle_len=1)*[ 0\\.       0.0251   0.12003  0.91552]*learner.fit(0.02, 2, wds=1e-6, cycle_len=1)*[ 0\\.       0.02014  0.11387  0.92012]                         \n[ 1\\.       0.01275  0.11149  0.92124]*learner.fit(0.02, 2, wds=1e-6, cycle_len=1)[ 0\\.       0.01681  0.11089  0.92129]                           \n[ 1\\.       0.00949  0.10951  0.92223]\n```", "```py\ntrain.StateHoliday = train.StateHoliday!='0'\ntest.StateHoliday = test.StateHoliday!='0'\n```", "```py\n**def** join_df(left, right, left_on, right_on=**None**, suffix='_y'):\n    **if** right_on **is** **None**: right_on = left_on\n    **return** left.merge(right, how='left', left_on=left_on,\n                      right_on=right_on, suffixes=(\"\", suffix))\n```", "```py\nstore = join_df(store, store_states, \"Store\")\nlen(store[store.State.isnull()])\n```", "```py\nweather = join_df(weather, state_names, \"file\", \"StateName\")\n```", "```py\ngoogletrend['Date']=googletrend.week.str.split(' - ',expand=**True**)[0]\ngoogletrend['State']=googletrend.file.str.split('_', expand=**True**)[2]\ngoogletrend.loc[googletrend.State=='NI', \"State\"] = 'HB,NI'\n```", "```py\nadd_datepart(weather, \"Date\", drop=**False**)\nadd_datepart(googletrend, \"Date\", drop=**False**)\nadd_datepart(train, \"Date\", drop=**False**)\nadd_datepart(test, \"Date\", drop=**False**)\n```", "```py\ntrend_de = googletrend[googletrend.file == 'Rossmann_DE']\n```", "```py\nstore = join_df(store, store_states, \"Store\")\nlen(store[store.State.isnull()])*0*joined = join_df(train, store, \"Store\")\njoined_test = join_df(test, store, \"Store\")\nlen(joined[joined.StoreType.isnull()]),len(joined_test[joined_test.StoreType.isnull()])(0, 0)joined = join_df(joined, googletrend, [\"State\",\"Year\", \"Week\"])\njoined_test = join_df(joined_test, googletrend, [\"State\",\"Year\", \"Week\"])\nlen(joined[joined.trend.isnull()]),len(joined_test[joined_test.trend.isnull()])(0, 0)joined = joined.merge(trend_de, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\njoined_test = joined_test.merge(trend_de, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\nlen(joined[joined.trend_DE.isnull()]),len(joined_test[joined_test.trend_DE.isnull()])(0, 0)joined = join_df(joined, weather, [\"State\",\"Date\"])\njoined_test = join_df(joined_test, weather, [\"State\",\"Date\"])\nlen(joined[joined.Mean_TemperatureC.isnull()]),len(joined_test[joined_test.Mean_TemperatureC.isnull()])(0, 0)\n```", "```py\n**for** df **in** (joined, joined_test):\n    **for** c **in** df.columns:\n        **if** c.endswith('_y'):\n            **if** c **in** df.columns: df.drop(c, inplace=**True**, axis=1)**for** df **in** (joined,joined_test):\n  df['CompetitionOpenSinceYear'] = \n          df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n  df['CompetitionOpenSinceMonth'] = \n          df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n  df['Promo2SinceYear'] = \n          df.Promo2SinceYear.fillna(1900).astype(np.int32)\n  df['Promo2SinceWeek'] = \n          df.Promo2SinceWeek.fillna(1).astype(np.int32)\n```", "```py\n**for** df **in** (joined,joined_test):\n  df[\"CompetitionOpenSince\"] = \n          pd.to_datetime(dict(year=df.CompetitionOpenSinceYear,\n                        month=df.CompetitionOpenSinceMonth, day=15))\n  df[\"CompetitionDaysOpen\"] = \n          df.Date.subtract(df.CompetitionOpenSince).dt.days\n```", "```py\n**for** df **in** (joined,joined_test):\n    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n    df.loc[df.CompetitionOpenSinceYear<1990,\"CompetitionDaysOpen\"]=0\n```", "```py\n**for** df **in** (joined,joined_test):\n    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"]//30\n    df.loc[df.CompetitionMonthsOpen>24,\"CompetitionMonthsOpen\"] = 24\njoined.CompetitionMonthsOpen.unique()*array([24,  3, 19,  9,  0, 16, 17,  7, 15, 22, 11, 13,  2, 23, 12,  4, 10,  1, 14, 20,  8, 18,  6, 21,  5])*\n```"]