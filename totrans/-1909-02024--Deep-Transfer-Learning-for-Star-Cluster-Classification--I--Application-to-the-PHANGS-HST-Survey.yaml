- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:05:13'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[1909.02024] Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1909.02024](https://ar5iv.labs.arxiv.org/html/1909.02024)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Wei Wei,^(1,2) E. A. Huerta,^(1,3) Bradley C. Whitmore,⁴ Janice C. Lee,⁵ Stephen
    Hannon,⁶ Rupali Chandar,⁷ Daniel A. Dale,⁸ Kirsten L. Larson,⁵ David A. Thilker,⁹
    Leonardo Ubeda,⁴ Médéric Boquien,^(10) Mélanie Chevance,^(11) J. M. Diederik Kruijssen,^(11)
    Andreas Schruba^(12), Guillermo Blanc^(13,14,15), Enrico Congiu^(16,13)
  prefs: []
  type: TYPE_NORMAL
- en: ¹NCSA, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA
  prefs: []
  type: TYPE_NORMAL
- en: ²Department of Physics, University of Illinois at Urbana-Champaign, Urbana,
    Illinois 61801, USA
  prefs: []
  type: TYPE_NORMAL
- en: ³Department of Astronomy, University of Illinois at Urbana-Champaign, Urbana,
    Illinois 61801, USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁴Space Telescope Science Institute, 3700 San Martin Drive, Baltimore, MD, USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁵Caltech/IPAC, California Institute of Technology, Pasadena, CA, USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁶Department of Physics and Astronomy, University of California, Riverside, CA,
    USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁷Department of Physics and Astronomy, University of Toledo, Toledo, OH USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁸Department of Physics and Astronomy, University of Wyoming, Laramie, WY, USA
  prefs: []
  type: TYPE_NORMAL
- en: ⁹Department of Physics and Astronomy, The Johns Hopkins University, Baltimore,
    MD, USA
  prefs: []
  type: TYPE_NORMAL
- en: ^(10)Unidad de Astronomía, Universidad de Antofagasta, Antofagasta, Chile
  prefs: []
  type: TYPE_NORMAL
- en: ^(11)Astronomisches Rechen-Institut, Zentrum für Astronomie der Universität
    Heidelberg, Heidelberg, Germany
  prefs: []
  type: TYPE_NORMAL
- en: ^(12)Max-Planck-Institut für extraterrestrische Physik, Garching, Germany
  prefs: []
  type: TYPE_NORMAL
- en: ^(13)Observatories of the Carnegie Institution for Science, Pasadena, CA, USA
  prefs: []
  type: TYPE_NORMAL
- en: ^(14)Departamento de Astronomía, Universidad de Chile, Las Condes, Santiago,
    Chile
  prefs: []
  type: TYPE_NORMAL
- en: ^(15)Centro de Astrofísica y Tecnologías Afines (CATA), Las Condes, Santiago,
    Chile
  prefs: []
  type: TYPE_NORMAL
- en: '^(16)Las Campanas Observatory, La Serena, Chile Contact e-mail: [weiw2@illinois.edu](mailto:weiw2@illinois.edu)(Accepted
    XXX. Received YYY; in original form ZZZ)'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'We present the results of a proof-of-concept experiment which demonstrates
    that deep learning can successfully be used for production-scale classification
    of compact star clusters detected in HST UV-optical imaging of nearby spiral galaxies
    ($D\lesssim 20\,\textrm{Mpc}$) in the PHANGS-HST survey. Given the relatively
    small nature of existing, human-labelled star cluster samples, we transfer the
    knowledge of state-of-the-art neural network models for real-object recognition
    to classify star clusters candidates into four morphological classes. We perform
    a series of experiments to determine the dependence of classification performance
    on: neural network architecture (ResNet18 and VGG19-BN); training data sets curated
    by either a single expert or three astronomers; and the size of the images used
    for training. We find that the overall classification accuracies are not significantly
    affected by these choices. The networks are used to classify star cluster candidates
    in the PHANGS-HST galaxy NGC 1559, which was not included in the training samples.
    The resulting prediction accuracies are 70%, 40%, 40-50%, 50-70% for class 1,
    2, 3 star clusters, and class 4 non-clusters respectively. This performance is
    competitive with consistency achieved in previously published human and automated
    quantitative classification of star cluster candidate samples (70-80%, 40-50%,
    40-50%, and 60-70%). The methods introduced herein lay the foundations to automate
    classification for star clusters at scale, and exhibit the need to prepare a standardized
    dataset of human-labelled star cluster classifications, agreed upon by a full
    range of experts in the field, to further improve the performance of the networks
    introduced in this study.'
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'galaxies : star clusters : general^†^†pubyear: 2019^†^†pagerange: Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey–[C](#A3
    "Appendix C Batch normalization ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Human visual classification of electromagnetic signals from astronomical sources
    is a core task in observational research with a long established history (Cannon
    & Pickering, [1912](#bib.bib14), [1918](#bib.bib15); Hubble, [1926](#bib.bib34),
    [1936](#bib.bib35); de Vaucouleurs, [1963](#bib.bib67)). It has been an essential
    means by which progress has been made in understanding the formation and evolution
    of structures from stars to galaxies. However, in the modern era of “Big Data"
    in Astronomy, with unprecedented growth in electromagnetic survey area, field
    of view, sensitivity, resolution, wavelength coverage, cadence, and transient
    alert production, it has become apparent that human classification is no longer
    scalable (Abbott et al., [2016](#bib.bib1); LSST Science Collaboration et al.,
    [2009](#bib.bib43)). This realization has motivated the use of machine learning
    techniques to automate image classification (Ball et al., [2008](#bib.bib5); Banerji
    et al., [2010](#bib.bib6); Carrasco Kind & Brunner, [2013](#bib.bib16); Ishak,
    [2017](#bib.bib36); Kamdar et al., [2016](#bib.bib37); Kim & Brunner, [2017](#bib.bib39)).
    Some of these machine learning algorithms have been integrated into widely-used
    methods for image processing, such as the neural networks trained for star/galaxy
    separation in the automated source detection and photometry software SEXTRACTOR (Bertin
    & Arnouts, [1996a](#bib.bib10)). Other applications of machine learning for image
    classification include the use of so-called decision trees (Weir et al., [1995](#bib.bib62);
    Suchkov et al., [2005](#bib.bib59); Ball et al., [2006](#bib.bib4); Vasconcellos
    et al., [2011](#bib.bib61); Sevilla-Noarbe & Etayo-Sotos, [2015](#bib.bib54))
    and support vector machines (Fadely et al., [2012](#bib.bib25); Solarz et al.,
    [2017](#bib.bib58); Małek & et al, [2013](#bib.bib46)).
  prefs: []
  type: TYPE_NORMAL
- en: Visual object recognition has also been a core research activity in the computer
    science community. For instance, the PASCAL VOC challenge was initiated to develop
    software to accurately classify about 20,000 images divided into twenty object
    classes (Everingham et al., [2015](#bib.bib24)). Over the last decade deep learning
    algorithms have rapidly evolved to become the state-of-the-art signal-processing
    tools for computer vision, to the point of surpassing human performance. The success
    of deep learning algorithms for image classification can be broadly attributed
    to the combination of increasing processing speed and the availability of very
    large datasets for training; i.e., Graphics Processing Units (GPUs) to train,
    validate and test neural network models; and curation of high-quality, human-labeled
    datasets, such as the ImageNet dataset (Deng et al., [2009](#bib.bib21)), which
    has over 14 million images divided into more than 1000 object categories.
  prefs: []
  type: TYPE_NORMAL
- en: The ImageNet Large Scale Visual Recognition Challenge (Russakovsky et al., [2015](#bib.bib50))
    has driven the development of deep learning models that have achieved breakthroughs
    for image classification. In 2012, the network architecture AlexNet (Krizhevsky
    et al., [2012](#bib.bib41)) achieved a $\sim 50\%$ reduction in error rate in
    the ImageNet challenge—a remarkable feat at that time that relied on the use of
    GPUs for the training of the model, data augmentation (image translations, horizontal
    reflections and mean subtraction), as well as other novel algorithm improvements
    that are at the core of state-of-the-art neural network models today, e.g., using
    successive convolution and pooling layers followed by fully-connected layers at
    the end of the neural network architecture.
  prefs: []
  type: TYPE_NORMAL
- en: Within the next two years, the architectures VGGNet (Simonyan & Zisserman, [2014b](#bib.bib57))
    and GoogLeNet (Szegedy et al., [2014](#bib.bib60)) continued to improve the discriminative
    power of deep learning algorithms for image classification using deeper and wider
    neural network models, and innovating data augmentation techniques such as scale
    jittering. Furthermore, GoogLeNet provided the means to further improve image
    classification analysis by introducing multi-scale processing, i.e., allowing
    the neural network model to recover local features through smaller convolutions,
    and abstract features with larger convolutions. In 2015, the ResNet (He et al.,
    [2015](#bib.bib31)) model was the first architecture to surpass human performance
    on the ImageNet challenge. In addition to this milestone in computer vision, ResNet
    was also used to demonstrate that a naive stacking of layers does not guarantee
    enhanced performance in ultra deep neural network models, and may actually lead
    to sub-optimal performance for image classification.
  prefs: []
  type: TYPE_NORMAL
- en: 'In view of the aforementioned accomplishments, research in deep learning for
    image classification has become a booming enterprise in science and technology.
    This vigorous program has led to innovative ways to leverage state-of-the-art
    neural network models to classify disparate datasets. This approach is required
    because most applications of deep learning for image classification rely on supervised
    learning. That is, neural network models are trained using large datasets of labelled
    data, such as the ImageNet dataset. In astronomical research, to enable the morphological
    classification of galaxies, the deep neural network model developed by (Dieleman
    et al., [2015](#bib.bib22)) was trained on $\sim$55,000 galaxy images, each with
    40-50 human classifications from the Galaxy Zoo 2 (Willett et al., [2013](#bib.bib66))
    online crowdsourcing project. This model was developed for the Galaxy Challenge
    competition in 2013-14 on the Kaggle platform, and took first place out of 326
    entries. \colorblack Given that datasets of that nature are challenging to obtain,
    deep “transfer” learning has provided the means to classify entirely new datasets
    by fine-tuning a pre-trained neural network model with the ImageNet dataset.¹¹1A
    brief overview of transfer learning is presented in Appendix [B](#A2 "Appendix
    B Deep transfer learning ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: While deep transfer learning was initially explored to classify datasets that
    were of similar nature to those used to train state-of-the-art neural network
    models, the first application of deep transfer learning of a pre-trained ImageNet
    neural network model to classify small datasets of entirely different nature was
    presented in George et al. ([2018](#bib.bib27), [2017](#bib.bib26)), where a variety
    of neural network models were used to report state-of-the-art image classification
    accuracy of noise anomalies in gravitational wave data. That study triggered a
    variety of applications of pre-trained ImageNet deep learning algorithms to classify
    images of galactic mergers (Ackermann et al., [2018](#bib.bib2)), and galaxies (Khan
    et al., [2019](#bib.bib38); Barchi et al., [2019](#bib.bib7); Domínguez Sánchez
    et al., [2018](#bib.bib23)), to mention a few examples.
  prefs: []
  type: TYPE_NORMAL
- en: 'Building upon these recent successful applications of deep transfer learning
    for image classification in physics and astronomy, in this paper we demonstrate
    that deep transfer learning provides the means to classify images of compact star
    clusters in nearby galaxies obtained with the Hubble Space Telescope (HST). We
    show that this approach yields classification accuracies on par with work performed
    by humans, and has the potential to \colorblack outperform humans and traditional
    machine learning. A major motivation of this work is to determine whether these
    deep transfer learning techniques can be used to automate production-scale classification
    of candidate star clusters in data from the Cycle 26 HST-PHANGS (Physics at High
    Angular Resolution in Nearby GalaxieS²²2[www.phangs.org](www.phangs.org)) Survey
    (PI: J.C. Lee, GO-15654) for which observations commenced in April 2019\. HST-PHANGS
    is anticipated to yield several tens of thousands of star cluster candidates for
    classification, only about a half of which will be true clusters. Encoding classification
    systems in neural networks will also improve the consistency of the classifications,
    and reduce the implicit impacts of subjectivity and subtle differences in classification
    systems adopted by different individuals (i.e., it can reduce both random and
    systematic errors in the classifcations).\colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: 'This paper is organized as follows. In Section [2](#S2 "2 Classification of
    Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we summarize the objectives
    of star cluster classification, and describe the current classification system,
    which we employ in this paper. A review of the consistency between human classifications
    across prior studies is provided to establish the accuracy level to be achieved
    or surpassed by deep learning in this initial proof-of-concept experiment. In
    Section [3](#S3 "3 Data and Methods ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we describe the imaging
    data and classifications used to train our neural network (NN) models, and then
    provide an overview of the NN models employed in this work. We report our results
    in Section [4](#S4 "4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"). We conclude in Section [5](#S5 "5 Discussion
    & Conclusions ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") with a summary of the results and next steps for future
    work.'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Classification of Compact Star Clusters in Nearby Galaxies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The objects of interest in this study are compact star clusters and stellar
    associations in galaxies at distances between 4 Mpc to 20 Mpc. The physical sizes
    of compact clusters are characterized by effective radii between 0.5pc to about
    10pc (Portegies Zwart et al., [2010](#bib.bib49); Ryon et al., [2017](#bib.bib52)).
    Ryon et al. ([2014](#bib.bib51)) report that the distribution of effective radii
    of young ($\lesssim$10 Myr), massive compact star clusters peaks between 2-3 pc
    based on HST LEGUS observations of NGC1313 (D$\sim$4 Mpc) and NGC628 (D$\sim$10
    Mpc). Hence, only with the resolution of HST³³3The WFC3/UVIS point source function
    FWHM is 0$\aas@@fstack{\prime\prime}$067 at 5000Å. can such objects be distinguished
    from individual stars and separated from other star clusters in galaxies beyond
    the Local Group. ⁴⁴4We note that for a high signal-to-noise cluster it is possible
    to measure the broadening of the image (and hence the size of the source) to a
    fraction of the FWHM of the PSF of a star. The FWHM of a star using WFC3 is about
    1.8 pix (1.3 pc at D=4 Mpc, and 6.4 pc at 20 Mpc). A significant amount of testing
    has been done on ACS and WFC3 images using software like ISHAPE (Larson1999),
    and much published work (including Chandar et al. 2017, Ryon et al. 2017) has
    confirmed that this broadening can be measured down to about 0.2 pixels, corresponding
    to size limits of $\sim$0.3 pc, $\sim$0.6 pc at distances of 5 Mpc, 10 Mpc. Extending
    to 15 and 20 Mpc, the upper end of distance range covered by the PHANGS survey,
    the cluster size limits are 0.8 and 1.1 pc. Per the ISHAPE manual, at 5 Mpc, this
    is calculated as: 0.2 pix * 0.04 (arcsec/pix)* 24 pc/arcsec * 1.48 = 0.28 pc (where
    1.48 is a conversion factor given in the ISHAPE manual when assuming a King profile
    specifically). Hence, if the peak sizes for clusters are in the 2-3 pc range,
    the vast majority of cluster will be resolved for most of the galaxies in PHANGS-HST.
    The sizes of stellar associations, which dominate the young stellar population,
    span a wider range with sizes from a few pc to $\sim$100 pc  (Portegies Zwart
    et al., [2010](#bib.bib49); Gouliermis, [2018](#bib.bib29)).\colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: Early attempts at classifying clusters in external galaxies with HST imaging
    focused mainly on old globular clusters, for example, the swarm of thousands of
    globular clusters around the central elliptical galaxy in the Virgo Cluster, M87
     (Whitmore et al., [1995](#bib.bib63)). This was a fairly straightforward process
    since the background was smooth and the clusters were well separated. With the
    discovery of super star clusters in merging galaxies (e.g, Holtzman et al., [1992](#bib.bib33)),
    the enterprise of the identification and study of clusters in star-forming galaxies
    using HST began, despite the fact that crowding and variable backgrounds in such
    galaxies make the process far more challenging. Studies of normal spiral galaxies
    pushed the limits to fainter and more common clusters (e.g, Larsen, [2002](#bib.bib44);
    Chandar et al., [2010](#bib.bib17)). In all these early studies, the primary objective
    was to distinguish true clusters from individual stars and image artifacts, and
    there were essentially no attempts to further segregate the clusters into different
    classes.
  prefs: []
  type: TYPE_NORMAL
- en: 'An exception, and one of the first attempts at a more detailed classification,
    was performed by Schweizer et al. ([1996](#bib.bib53)), who defined 9 object types
    and then grouped them into two classes: candidate globular clusters and extended
    stellar associations. More recently, Bastian et al. ([2012](#bib.bib8)), who studied
    clusters using HST imaging of the M83 galaxy, classified star clusters as either
    symmetric or asymmetric. Their analysis retained only symmetric clusters, which
    they posited were more likely to be gravitationally bound. Following this work,
    many studies in the field, most notably the Legacy ExtraGalactic UV Survey (LEGUS) (Calzetti
    et al., [2015a](#bib.bib12)) began differentiating clusters into two or three
    different categories, so that they could be studied separately or together depending
    on the goals of the project (see also the review by Krumholz et al., [2018](#bib.bib42),
    and their discussion of “exclusive" versus “inclusive" cluster catalogs).'
  prefs: []
  type: TYPE_NORMAL
- en: The LEGUS project also employed machine learning techniques for some of their
    cluster classification work Messa et al. ([2018](#bib.bib47)); Grasha et al. ([2019](#bib.bib30)).
    This pioneering work will be discussed in Section 5.
  prefs: []
  type: TYPE_NORMAL
- en: 'In LEGUS, cluster candidates are sorted into four classes as follows (Adamo
    et al., [2017](#bib.bib3); Cook et al., [2019](#bib.bib20)):'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 1: compact, symmetric, single central peak, radial profile more extended
    relative to point source'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 2: compact, asymmetric or non-circular (e.g., elongated), single central
    peak'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 3: asymmetric, multiple peaks, sometimes superimposed on diffuse extended
    source'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Class 4: not a star cluster (image artifacts, background galaxies, pairs and
    multiple stars in crowded regions, stars)'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'We adopt the same classification system for this paper. In general, we refer
    to class 1, 2, and 3 as “compact symmetric cluster," “compact asymmetric cluster,"
    and “compact association" respectively. Examples of objects in each of these classes
    are shown in Figure [1](#S2.F1 "Figure 1 ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c853e41278f0c98a7008015b82f50075.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Examples of each of the four cluster classifications illustrated
    with HST/WFC3 imaging. The top four rows show star clusters from NGC 4656, which
    are part of the training set, while the bottom four rows show clusters from recent
    PHANGS-HST observations of the spiral galaxy NGC 1559, which form our proof-of-concept
    test sample, and are not used for training. The first two columns show false-color
    RGB images for context: the first column displays a 299p x 299p RGB image (R =
    F814W, G = F438W + F555W, B = F275W + F336W) and the second column shows only
    the center 50p x 50p of the RGB image (184pc x 184pc for NGC1559, for example).
    The center 50p x 50p of individual NUV-U-B-V-I HST images, which are used as input
    to the pre-trained neural network models for further training (tuning) and evaluation,
    are shown in grayscale in the last 5 columns (from left to right, 50p x 50p images
    taken with filters F275W, F336W, F438W, F555W, and F814W). We also experiment
    with 25p x 25p and 100p x 100p images, as discussed in Sections 3 and 4.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Consistency among Classifications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black The stated goal of the current work is to provide cluster classifications
    via deep transfer learning models that achieve accuracy levels at least
  prefs: []
  type: TYPE_NORMAL
- en: as good as other star cluster classifications in the literature, both by human
    visual inspection and by application of quantitative selection criteria. \colorblack
    In this section we establish this “accuracy" level, which we define as the consistency
    between different classifications for the same cluster populations as reported
    in the literature, as well as relative to classifications homogeneously performed
    by one of us (Bradley C. Whitmore, hereafter BCW.).
  prefs: []
  type: TYPE_NORMAL
- en: A first look at the overall consistency between the clusters cataloged by different
    studies, but based on the same data and same limiting magnitude, is provided by
    the work on M83 by Bastian et al. ([2012](#bib.bib8)); Whitmore et al. ([2014](#bib.bib64));
    Chandar et al. ([2014](#bib.bib18)). Comparisons reported in those papers show
    that about $\sim$70% of the clusters are in common between the studies. Later,
    Adamo et al. ([2017](#bib.bib3)) performed a similar comparison for the spiral
    galaxy NGC 628 for the catalogs from LEGUS and Whitmore et al. ([2014](#bib.bib64)),
    and finds an overlap
  prefs: []
  type: TYPE_NORMAL
- en: of $\sim$75%. Finally, the LEGUS study of M51 by Messa et al. ([2018](#bib.bib47))
    find
  prefs: []
  type: TYPE_NORMAL
- en: an overlap of 73% in common with a study by Chandar et al. ([2016](#bib.bib19)).
  prefs: []
  type: TYPE_NORMAL
- en: These results are not based only upon detailed analysis of human-vs-human cluster
    classifications for individual objects; they are statistical measures of overlap
    between samples where a mix of human classification/identification, and automated
    star/cluster separation based on the concentration index (i.e., the difference
    in magnitude in a 1 pixel vs. 3 pixel radius) were used across the studies.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/94c84b11f318d8c2e0c1760799ec058f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Comparisons between star cluster candidate classifications made by
    BCW and the mode of classifications made by three other LEGUS team members (trained
    by BCW, A. Adamo, and H. Kim) provided in the LEGUS public star cluster catalog
    for NGC 4656\. Each panel shows the distribution of classifications given in the
    LEGUS catalog for BCW labelled class 1 (top, symmetric compact clusters), class
    2 (upper middle, asymmetric compact clusters), class 3 (lower middle, compact
    associations) and class 4 (bottom, non-clusters) objects.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To more directly evaluate human-vs-human cluster classifications alone we start
    with a comparison of the NGC 3351 cluster catalog from the LEGUS sample (performed
    by BCW and team member Sean Linden, who was trained by BCW) with a new version
    of the NGC3351 cluster catalog independently constructed by PHANGS-HST⁵⁵5PHANGS-HST
    has expanded imaging coverage of NGC3351 to produce greater overlap with PHANGS-ALMA
    CO observations of the galaxy, and is developing new star cluster catalogs for
    the fields. See Section [3.1](#S3.SS1 "3.1 Star Cluster Catalogs ‣ 3 Data and
    Methods ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") for an overview of the catalog construction. (performed
    by BCW alone). This might be viewed as a test of the consistency that might be
    expected if the same (or very similar) classifiers return to the same data set
    after a passage of several years. We find a 80 % agreement between category 1
    objects, 53 % for category 2, 56 % for category 3\. If we combine category 1 and
    2 objects (which is what many authors do for their analysis), the agreement is
    88 %.'
  prefs: []
  type: TYPE_NORMAL
- en: 'We next compare classifications assigned by BCW for NGC 4656 to those provided
    in the LEGUS public cluster catalog, which provides the mode of classifications
    made by three other LEGUS team members (trained by BCW, A. Adamo, and H. Kim).
    Results are shown in Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: If we combine only the class $1+2$ clusters (to exclude compact associations
    which has a higher rate of confusion with class 4 non-clusters), the total match
    fraction is 67%. For the individual classes, the consistency of the assignments
    vary from 66%, 37%, 40%, 61% for class 1, 2, 3, and 4, respectively. Hence, the
    agreement for the BCW classifications versus the mode of classifications from
    three LEGUS team members for NGC 4656 are slightly lower than the comparisons
    between BCW and BCW (and Linden) for NGC 3351. Other galaxies where a similar
    comparison has been made between the BCW classifications and LEGUS 3-person (“consensus”)
    classifications (i.e., NGC 4242, NGC 4395N, and M51) result in similar numbers.
  prefs: []
  type: TYPE_NORMAL
- en: In summary, comparing between a wide range of different cluster classification
    methods, but for the same data sets, we find typical agreements in the range 40
    % (e.g., when comparing class 2 or class 3 objects alone) to 90 % (e.g. when combining
    class 1 + 2 for repeat classifications of
  prefs: []
  type: TYPE_NORMAL
- en: cluster catalogs by the same, or very similar, classifiers). For the individual
    classes, the “accuracy" levels that we adopt to be achieved or surpassed for our
    deep learning studies proof-of-concept demonstration are 70-80%, 40-50%, 40-50%,
    and 60-70% for class 1, 2, 3, 4 objects respectively.
  prefs: []
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black
  prefs: []
  type: TYPE_NORMAL
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC3351¹ | 10.0 | 118 | 80 | 95 | 325 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC3627 | 10.1 | 403 | 175 | 164 | 837 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4242¹ | 5.8 | 117 | 60 | 14 | 42 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4395N² | 4.3 | 8 | 19 | 21 | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4449 | 4.31 | 120 | 261 | 213 | 0 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC45¹ | 6.61 | 45 | 52 | 20 | 43 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4656² | 5.5 | 83 | 125 | 47 | 173 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC5457C | 6.7 | 287 | 108 | 81 | 436 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC5474¹ | 6.8 | 48 | 95 | 34 | 144 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC6744N | 7.1 | 164 | 143 | 58 | 210 |'
  prefs: []
  type: TYPE_TB
- en: '| Total |  | 1393 | 1118 | 747 | 2230 |'
  prefs: []
  type: TYPE_TB
- en: '| N $\geq$ 4 |  | 1271 | 1013 | 738 | 2125 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Number of sources in each of the ten HST LEGUS fields which have been
    primarily classified by BCW. The number in each of morphological classes described
    in Section [2](#S2 "2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") is given. The total number of clusters with detection in at
    least four filters (a requirement for inclusion in the training and testing) are
    given in the last row of the table. 80% of the latter (randomly selected) are
    used for training, and the remaining 20% are reserved for validation testing.
    Distances compiled by (Calzetti et al., [2015a](#bib.bib12)) are listed.'
  prefs: []
  type: TYPE_NORMAL
- en: ¹ Classification primarily determined by BCW are available in the public release
    of the LEGUS cluster catalogs.
  prefs: []
  type: TYPE_NORMAL
- en: '² Independent classifications determined by BCW for fields for which LEGUS
    consensus classifications are available through the LEGUS public archive (Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1313E | 4.39 | 42 | 95 | 122 | 386 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1313W | 4.39 | 85 | 191 | 210 | 373 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1433 | 8.3 | 51 | 61 | 56 | 138 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1566 | 18.0 | 258 | 214 | 261 | 328 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1705 | 5.1 | 16 | 13 | 13 | 54 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC3344 | 7.0 | 119 | 118 | 159 | 161 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC3738 | 4.9 | 49 | 93 | 86 | 214 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4656 | 5.5 | 93 | 91 | 78 | 169 |'
  prefs: []
  type: TYPE_TB
- en: '| M51 | 7.66 | 363 | 502 | 365 | 1261 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC5253 | 3.15 | 20 | 37 | 23 | 154 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC628C | 9.9 | 334 | 357 | 326 | 542 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC628E | 9.9 | 92 | 80 | 87 | 122 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC6503 | 5.27 | 71 | 96 | 131 | 172 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC7793E | 3.44 | 32 | 76 | 83 | 62 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC7793W | 3.44 | 51 | 84 | 86 | 78 |'
  prefs: []
  type: TYPE_TB
- en: '| IC4247 | 5.1 | 1 | 4 | 3 | 37 |'
  prefs: []
  type: TYPE_TB
- en: '| IC559 | 5.3 | 9 | 12 | 4 | 18 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4395N | 4.3 | 8 | 12 | 19 | 19 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC4395S | 4.3 | 31 | 64 | 42 | 31 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC5238 | 4.51 | 4 | 4 | 1 | 9 |'
  prefs: []
  type: TYPE_TB
- en: '| NGC5477 | 6.4 | 5 | 9 | 9 | 49 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC1249 | 6.9 | 13 | 35 | 40 | 133 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC4305 | 3.05 | 16 | 29 | 40 | 147 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC4459 | 3.66 | 2 | 5 | 3 | 20 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC5139 | 3.98 | 2 | 7 | 7 | 23 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC685 | 4.83 | 7 | 4 | 3 | 6 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC695 | 10.9 | 4 | 7 | 6 | 94 |'
  prefs: []
  type: TYPE_TB
- en: '| UGC7408 | 6.7 | 19 | 16 | 11 | 32 |'
  prefs: []
  type: TYPE_TB
- en: '| UGCA281 | 5.9 | 2 | 9 | 4 | 34 |'
  prefs: []
  type: TYPE_TB
- en: '| Total |  | 1799 | 2325 | 2278 | 4866 |'
  prefs: []
  type: TYPE_TB
- en: '| N $\geq$ 4 |  | 1795 | 2315 | 2265 | 4841 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Same as Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    but for the 29 HST LEGUS fields which have been classified by three people, and
    have star cluster catalogs available through the LEGUS public archive. The number
    in each of the morphological classes, as determined by the mode of these three
    people’s classifications, is given.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Field | D (Mpc) | Class 1 | Class 2 | Class 3 | Class 4 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| NGC1559 | 19.0 | 302 | 252 | 162 | 710 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Number of sources in the PHANGS-HST observation of NGC 1559 which
    have been classified by BCW. This cluster sample is used to test the neural networks
    trained as described in Section [4.1](#S4.SS1 "4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey") as a proof-of-concept
    demonstration for production scale classification of PHANGS-HST compact clusters
    and associations.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Data and Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section we describe the data sets used to train, validate and test our
    deep learning algorithms, and give an overview of the neural network models used.
    We approach this initial work as a proof of concept demonstration, with the intention
    of performing further optimization and more detailed tests in future work.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Star Cluster Catalogs
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A key point is that the training and testing of the neural networks presented
    here are based on a pre-selected sample of cluster candidates where a large fraction
    of unresolved (point) sources have been first discarded. In past work, such candidate
    samples have served as the starting point for visual classification by humans
    to remove remaining interlopers, and to characterize the morphologies of verified
    clusters as described above. The construction and selection methodolgy for cluster
    candidate samples used here follow most of the procedures adopted for the LEGUS
    project (Calzetti et al., [2015b](#bib.bib13)) as described in Adamo et al. ([2017](#bib.bib3)).
  prefs: []
  type: TYPE_NORMAL
- en: To briefly review, the procedure includes detection using the SExtractor program (Bertin
    & Arnouts, [1996b](#bib.bib11)) on a white light image; filtering out most stars
    by requiring the concentration index⁶⁶6(CI = difference in magnitude between an
    aperture with 1 or 3 pixels) to be greater than a value determined based on training
    set of isolated point sources and clusters for each galaxy; requiring detections
    with photometric errors less than 0.3 mag in at least 4 filters; and selecting
    objects brighter than -6 mag in F555W (total Vega magnitude). Again, this results
    in a cluster candidate list which is then examined visually to remove artifacts
    (e.g., close pairs of stars, saturated stars and diffraction spikes, background
    galaxies, etc.). The primary tool used for the visual classification is the IMEXAMINE
    task in IRAF. See Figure 3 in Adamo et al. ([2017](#bib.bib3)) for a graphic description
    of the use of IMEXAMINE and the classification into four categories.
  prefs: []
  type: TYPE_NORMAL
- en: 'For most of the LEGUS star cluster catalogs which have been publicly released
    through the MAST archive, ⁷⁷7[https://archive.stsci.edu/prepds/legus/dataproducts-public.html](https://archive.stsci.edu/prepds/legus/dataproducts-public.html)
    classifications are performed by three different team members and the mode is
    recorded as the final consensus value (i.e., the 29 fields in Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")). The LEGUS classifiers, were trained
    by BCW, A. Adamo, and H. Kim. For an additional 8 fields, classifications were
    performed primarily by a single team member, i.e., coauthor BCW.⁸⁸8S. Linden who
    was trained by BCW, assisted in classifications for sources in NGC 3351, NGC 3627,
    and NGC 5457) As of July 2019, classifications for 4 of the 8 HST fields primarily
    inspected by BCW are available from the LEGUS public archive (Table [1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey")). BCW also independently classified
    two fields with LEGUS consensus classifications to enable consistency checks (e.g.,
    Figure [2](#S2.F2 "Figure 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")), bringing the
    total to 10 galaxies in the sample with BCW classifications.'
  prefs: []
  type: TYPE_NORMAL
- en: The construction of a preliminary cluster catalog for the first galaxy observed
    in the PHANGS-HST program NGC 1559 generally follow the methods used for LEGUS.
    The primary differences are that a F555W image was used instead of a white light
    image (which is more prone to small differences in alignment of different filters
    and the presence of very close pairs of stars with different colors),
  prefs: []
  type: TYPE_NORMAL
- en: 'and a false-color image from the Hubble Legacy Archive (Whitmore et al., [2016](#bib.bib65))
    was simultaneously examined to help classify the clusters. A magnitude limit of
    -7.5 in the V band was used for NGC 1559, reflecting its larger distance (19 Mpc:
    A. Reiss, private communication) relative to the average distance of the LEGUS
    galaxies. A detailed presentation of the PHANGS-HST star cluster and association
    candidate selection methods will be provided in the PHANGS-HST survey paper (Lee
    et al. 2020) and catalog papers (e.g., Whitmore et al. 2020, Thilker et al. 2020,
    Larson et al. 2020).'
  prefs: []
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Image data & curation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As input for the neural network training, we use postage stamps extracted from
    HST imaging taken in five broadband filters. Sample postage stamps are presented
    in the last five columns of Figure [1](#S2.F1 "Figure 1 ‣ 2 Classification of
    Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: LEGUS obtained HST observations with WFC3 in 2013-2014 (GO-13364; PI Calzetti),
    and combined those data with ACS data taken in previous cycles by other programs
    to provide NUV-U-B-V-I coverage for a sample of 50 galaxies with 63 fields.
  prefs: []
  type: TYPE_NORMAL
- en: PHANGS-HST (GO-15654; PI Lee) began observations on April 6, 2019 and is also
    obtaining observations with similar exposure times in the NUV-U-B-V-I filters.
    The first galaxy to be observed is NGC 1559.
  prefs: []
  type: TYPE_NORMAL
- en: Bearing in mind that the neural network models used in this study (i.e., VGG19-BN
    and ResNet18; see next section) were pre-trained with the ImageNet dataset, in
    which images are resized to $299\times 299\times 3$, we follow best coding practices
    of neural network training, and curate our datasets so that star cluster images
    have size $299\times 299$ pixels.
  prefs: []
  type: TYPE_NORMAL
- en: 'However, given that star clusters subtend only about several to a dozen HST
    WFC3 pixels, we focus the training on a small area (see Figure [1](#S2.F1 "Figure
    1 ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: We first extract regions of 50 x 50 HST/WFC3 pixels centered on the star cluster
    candidate, which are then resized to fit in an 299 x 299 pixel area for the training.
    With WFC3’s pixel size of 0.04 arcseconds, each region corresponds to a physical
    width between $\sim$40-100pc for our sample of galaxies. To test whether the size
    of the cropped HST image influences the accuracy, we also extract regions which
    are half and twice as large as 50 HST/WFC3 pixels across.
  prefs: []
  type: TYPE_NORMAL
- en: Procedurally, from the HST mosaics, a .fits image “postage stamp" centered on
    each target cluster is cropped from each of the NUV-U-B-V-I bands.
  prefs: []
  type: TYPE_NORMAL
- en: The five resultant stamps for each cluster candidate are then stored in individual
    header data units (HDUs) within a single MEF file. We note that if there was no
    observation of the cluster in one of the filters, all pixel values for that particular
    filter’s postage stamp were set to zero. If there was no observation in more than
    one filter, the cluster was removed from our sample, consistent with the candidate
    selection criteria.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Neural network models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The available star cluster data sets are small compared to the datasets used
    to successfully train state-of-the-art neural network models for image classification.
    Thus, we use two neural network models, VGG19 (Simonyan & Zisserman, [2014a](#bib.bib56))
    with batch normalization (VGG19-BN) and ResNet18 (He et al., [2016](#bib.bib32)),
    pre-trained with the ImageNet dataset (see Section [1](#S1 "1 Introduction ‣ Deep
    Transfer Learning for Star Cluster Classification: I. Application to the PHANGS-HST
    Survey")), and then use deep transfer learning⁹⁹9A brief overview of transfer
    learning is presented in Appendix [B](#A2 "Appendix B Deep transfer learning ‣
    Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey"). to leverage the knowledge of these models to classify real-object
    images to our task at hand, namely, the morphological classification of star clusters.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Regarding batch normalization for VGG19: the weights of each layer in a neural
    network model change throughout the training phase, which implies that the activations
    of each layer will also change. Given that the activations of any given layer
    are the inputs to the subsequent layer, this means that the input distribution
    changes at every step. This is far from ideal because it forces each intermediate
    layer to continuously adapt to changing inputs. Batch normalization is used to
    ameliorate this problem by normalizing the activations of each layer. In practice
    this is accomplished by adding two trainable parameters to each layer, so the
    normalized output is multiplied by a standard deviation parameter, and then shifted
    by a mean parameter. With this approach only two parameters are changed for each
    activation, as opposed to losing the stability of the network by changing all
    the weights. It is expected that through this method each layer will learn on
    a more stable distribution of inputs, which may accelerate the training stage.'
  prefs: []
  type: TYPE_NORMAL
- en: Both neural network architectures, VGG19-BN and ResNet18 have 3 input channels.
    However, since the star cluster candidates have images taken in 5 broadband filters,
  prefs: []
  type: TYPE_NORMAL
- en: 'we concatenate two copies of the same neural network architecture. The merged
    neural networks have 6 input channels in total, so we set the input to the last
    channel to be constant zeros. We also apply one more matrix multiplication and
    an element-wise softmax function (see Appendix [A](#A1 "Appendix A Statistical
    foundations of Deep Learning Classifiers ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey")) (Goodfellow et al.,
    [2016](#bib.bib28)) to make sure that for each'
  prefs: []
  type: TYPE_NORMAL
- en: candidate cluster the output is a vector of size 4, representing the probability
    distribution over the 4 classes under consideration. We choose this particular
    combination given its simplicity and its expected performance for image classification.
  prefs: []
  type: TYPE_NORMAL
- en: We use the pre-trained weights, except those for the last layers, of VGG19-BN
    and ResNet18 provided by PyTorch (Paszke et al., [2017](#bib.bib48)) as the initial
    values for the weights in our models. The weights for the last layers in VGG19-BN
    and ResNet18 and the last fully connected layers are randomly initialized. We
    use cross-entropy as the loss function^(10)^(10)10A loss function is used to evaluate
    and diagnose model optimization during training. The penalty for errors in the
    cross-entropy loss function is logarithmic, i.e., large errors are more strongly
    penalized. and Adam (Kingma & Ba, [2014](#bib.bib40)) for optimization. The learning
    rate is set to $10^{-4}$. The batch size for ResNet18 is 32, and for VGG19-BN
    is 16.
  prefs: []
  type: TYPE_NORMAL
- en: 'Batch size and batch normalization refer to two distinct concepts. One epoch
    corresponds to all the training examples being passed both forward and backward
    through the neural network only once, while the batch size is the number of training
    examples in one forward/backward pass. For instance, we may divide a training
    data set of 100 images into 4 batches, so that the batch size is 25 sample images,
    and 4 iterations will complete one epoch. On the other hand, batch normalization
    is a technique used to improve the stability of the learning algorithms. The details
    are described in Appendix [C](#A3 "Appendix C Batch normalization ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: Finally, following deep learning best practices, we quantify the variance in
    classification performance of our models by training them ten times independently
    and then presenting the mean accuracies and the corresponding standard deviations.
    We also compute the Shannon entropy  Shannon ([1948](#bib.bib55)) of the output
    distribution over the four star cluster classes to quantify the uncertainty in
    each individual neural network model’s prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Training Experiments
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We perform a series of experiments to test how the accuracy of the neural network
    model for predicting the morphological classification of candidate star clusters
    depends on the following characteristics of the training sample:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'origin of classifications: primarily classified by BCW (Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")) or the mode of 3 LEGUS classifiers (Table [2](#S2.T2
    "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"))'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'size of images used for training: 25p x 25p, 50p x 50p, 100p x 100p'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'imaging filters: NUV, U, B, V, I'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Transfer learning is used to train the neural network models using a random
    selection of 80% of the samples described in Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") and Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")
    separately, and the remaining 20% are reserved for validation. In total, this
    results in training samples of about 1000, 800, 600, and 1700 class 1, 2, 3, 4
    objects primarily classified by BCW, and about 1400, 1800, 1800, 3900 objects
    with LEGUS consensus classifications.'
  prefs: []
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black
  prefs: []
  type: TYPE_NORMAL
- en: Absolute values of pixels are rescaled to be in the range [0, 1], to avoid the
    brightness of the sources from becoming a parameter in the classification. During
    training we use several standard data augmentation strategies, such as random
    flips, and random rotations in the range [$0,\,2\pi$] to make sure that the trained
    neural networks are robust against those transformations. Taking into account
    the batch size mentioned above for ResNet18 and VGG19-BN, and bearing in mind
    that we trained the models using about 10,000 batches, this means that the nets
    were exposed to 320,000 and 160,000 images, respectively. Note, however, that
    the data augmentation techniques used during the training stage may produce very
    similar images to the actual star cluster images curated for this analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'To investigate whether networks trained in this manner can be used to automate
    classification of star clusters in the PHANGS-HST dataset in the future, we test
    the networks on the first observations obtained by PHANGS-HST of the spiral galaxy
    NGC 1559. The PHANGS-HST NGC1559 observations provide 302, 252, 162, and 710 class
    1, 2, 3, 4 objects, as classified by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We present four sets of results in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [4.1](#S4.SS1 "4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), we present the classification
    accuracy for the four categories of star clusters candidates relative to classifications
    primarily determined by BCW and those based on the mode of classifications performed
    by three LEGUS team members. We also present the uncertainty quantification analysis
    of those models (i.e., due to random weight initialization).'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [4.2](#S4.SS2 "4.2 How accurately can the models predict classifications
    for clusters in galaxies not included in the training sample? ‣ 4 Results ‣ Deep
    Transfer Learning for Star Cluster Classification: I. Application to the PHANGS-HST
    Survey"), we quantify the robustness of our neural network models to generalize
    to star cluster images in different galaxies, choosing the PHANGS-HST observations
    of NGC 1559 as the driver of this exercise as discussed above.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [4.3](#S4.SS3 "4.3 How does classification accuracy depend on size
    of training images? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey"), we report on whether the classification
    accuracy depends on the size of the images used for network training.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Section [4.4](#S4.SS4 "4.4 Classification accuracy as a function of imaging
    filter ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey"), we report on relative importance of different
    filters for image classification in our resulting deep learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Does prediction accuracy depend on the origin of the classifications?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is often useful to approach a problem using multiple methods to check how
    sensitive the results are to the chosen method. For example, the use of both ResNet18
    and VGG19-BN architectures in this paper allows us to see which one provides better
    results, but as we will show below, the results are quite robust no matter which
    is used. We use a similar strategy in this section by examining the results from
    training using two different classification samples, namely the BCW sample (see
    Table 1) and the LEGUS-consensus (3 classifiers) sample (see Table 2). While the
    BCW sample might be expected to have greater internal self-consistency since it
    was performed by a single experienced classifier, averaging the results of three
    less-experienced classifiers might be expected to reduce the random noise. Hence
    it is not obvious which approach might give better results in this pilot project.
    In the long run, the development of a much larger standardized database using
    a full range of experienced classifiers, as discussed in Section 5, may be required
    to make significant improvements.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, we quantify the performance of our models for classification accuracy
    when we fine-tune the models to determine whether the transfer learning was effective
    at learning the morphological features that tell apart the four classes of star
    clusters, and to assess the robustness of the optimization procedure for image
    classification. As described above, to fine-tune the models pre-trained with the
    ImageNet dataset, the weights of the last layers and the last fully connected
    layers of the VGG19-BN and ResNet18 models are randomly initialized. The process
    is performed separately for the datasets described in Tables [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey") and  [2](#S2.T2 "Table 2 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey") to examine the dependence of the results on the origin of
    the classifications. \colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: 'The results based on training with classifications primarily determined by
    BCW are presented in the top row of confusion matrices in Figure [3](#S4.F3 "Figure
    3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), for both the ResNet18 and VGG19-BN models, with mean
    classification accuracy taken as the average over ten individual trainings from
    scratch. As a reminder, the reported accuracies are based on classification of
    a random set of 20% of the overall sample that was not included in the training
    (the "validation" sample). Likewise, the results based on training with the mode
    of classifications performed by three LEGUS team members are presented in the
    bottom row in Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey").\colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: 'The main result is that the classification accuracies for the validation samples
    are comparable for both ResNet18 and VGG19-BN networks, as well as for both training
    samples. Reading along the diagonal of the confusion matrices presented in Figure [3](#S4.F3
    "Figure 3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), for the models trained on the objects primarily classified
    by BCW, the accuracies for ResNet18 are 76%, 58%, 60%, 71% for class 1, 2 ,3,
    and 4 objects respectively, and 71%, 64%, 60%, 69% for VGG19-BN. Similarly, for
    the networks trained on the mode of classifications performed by three LEGUS members
    the accuracies are 78%, 54%, 58%, 66% for ResNet18 and 76%, 54%, 57%, 69% for
    VGG19-BN. This provides evidence that our proof-of-concept neural network models
    are resilient to the choice of data used for training and validation despite the
    fact that the two samples were (i) labelled by different classifiers; and (ii)
    include different parent galaxies at a wide range of distances (4-10 Mpc for the
    objects primarily classified by BCW, and 4-18 Mpc for the sample with LEGUS consensus
    classifications.) Our findings indicate that notwithstanding these seemingly important
    differences, the prediction accuracies using these two independent datasets are
    fairly consistent. \colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: 'The variance in the ten independent classification measurements provide measure
    of the robustness of the models. The variances for our neural network models trained
    on the classifications primarily determined by BCW are given in Tables [4](#S4.T4
    "Table 4 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") and [5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey"). In
    all cases, the variances are between 4-8%. The variances for LEGUS classifications
    are comparable.\colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4567db5f268c49e76d55f8f3546a4bcd.png) ![Refer to caption](img/caea1fb11003ed8e590943ffdbc42bae.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/52df57ef2c562900a2ce06c66f22c50b.png) ![Refer to caption](img/b9768b5c417d5332624be7df6a18ee36.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Top panels: Prediction, averaged over 10 models, of ResNet18 (left)
    and VGG19-BN (right) trained on 80% of the data described in Table [1](#S2.T1
    "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact
    Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") and then tested on 20% of the data reserved
    for validation testing and not used for training. Note that in these confusion
    matrices each column corresponds to a predicted class, whereas each row corresponds
    to an actual class. Correct classification results are given along the diagonal
    from the top left to bottom-right of the matrices. The color bar indicates the
    number of evaluation images used. Bottom panels: Same as top panels, but for data
    in Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/994a383b574e29ecc085681f023f9650.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/e724f62daf93f6c6d5cef9e77312dc96.png) ![Refer to caption](img/9e670a0de98e8afffd1cf471310d6623.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/07cd97af1a900a867b6cb1d3a45cd335.png) ![Refer to caption](img/e015af6d693f9c230bc8c34589ff8bdb.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Top panels: Same as Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction
    accuracy depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    but now the models trained on the classifications primarily determined by BCW
    (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")) are applied
    to predict classifications for candidates in PHANGS-HST observations of NGC 1559,
    a galaxy which was not included in the training samples. As before, results were
    obtained after averaging over 10 models. Bottom panels: Same as top row, but for
    models trained on the mode of classifications performed by three LEGUS team members
    (Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications ‣ 2 Classification
    of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 1 | 76.0$\pm$ 4.2 | 17.9$\pm$ 4.4 | 1.7$\pm$0.7 | 4.4$\pm$1.4 |
    254 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 2 | 19.4 $\pm$3.5 | 58.2$\pm$5.3 | 7.9$\pm$3.5 | 14.6$\pm$3.0 |
    202 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 3 | 0.3 $\pm$0.5 | 16.3$\pm$5.4 | 59.9$\pm$6.8 | 23.4$\pm$5.6 |
    147 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 4 | 7.0$\pm$2.1 | 6.9$\pm$2.9 | 15.2$\pm$3.1 | 70.9$\pm$4.8 | 425
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 4: Prediction of ResNet18 on 20% of the data in Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey") reserved for validation testing and not
    included in the training, averaged over 10 models. The averaged predictions from
    Figure [3](#S4.F3 "Figure 3 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey") are repeated, but now
    the standard deviations are also shown. The number of validation images for each
    class are listed in the final column. \colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 1 | 70.9$\pm$6.2 | 23.0$\pm$4.8 | 1.1$\pm$0.7 | 5.0$\pm$1.9 | 254
    |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 2 | 13.3$\pm$4.3 | 63.8$\pm$4.8 | 9.4$\pm$2.9 | 13.6$\pm$3.6 |
    202 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 3 | 0.5$\pm$0.7 | 14.0$\pm$6.3 | 59.8$\pm$7.5 | 25.6$\pm$7.4 |
    147 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 4 | 6.5$\pm$2.4 | 8.1$\pm$2.6 | 16.3$\pm$3.8 | 69.1$\pm$6.8 | 425
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: As Table [4](#S4.T4 "Table 4 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey"), but now
    using VGG19-BN.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 1 | 72.8$\pm$ 7.6 | 11.2$\pm$ 3.8 | 1.4$\pm$0.6 | 14.6$\pm 5.1$
    | 302 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 2 | 23.8$\pm$4.3 | 38.1$\pm$5.9 | 9.0$\pm$4.0 | 29.2$\pm$4.7 |
    252 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 3 | 1.0$\pm$0.5 | 9.8$\pm$4.2 | 40.1$\pm$7.1 | 49.1$\pm$6.1 | 162
    |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 4 | 4.6$\pm$1.4 | 6.5$\pm$1.8 | 14.1$\pm$3.1 | 74.8$\pm$3.5 | 710
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 6: Prediction of ResNet18 trained on star clusters primarily classified
    by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency among Classifications ‣ 2
    Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey")) for
    candidates in spiral galaxy NGC 1559 from the PHANGS-HST program, averaged over
    10 models. Each row shows the averaged predictions (same as shown in top left
    panel of Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy depend on
    the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey")), but now together
    with the standard deviations from the 10 models. The numbers of objects classified
    are given in the last column. This experiment was performed to test the ability
    of this neural network model to generalize to images from galaxies not included
    in the training sample. It is notable that NGC 1559 is roughly twice as far away
    as any of galaxies in the BCW training sample.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Class 1 [%] | Class 2 [%] | Class 3 [%] | Class 4 [%] | Total |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 1 | 73.8$\pm$4.8 | 10.4$\pm$3.5 | 3.1$\pm$1.3 | 12.7$\pm$4.4 |
    302 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 2 | 20.9$\pm$6.4 | 42.3$\pm$7.9 | 13.3$\pm$2.6 | 23.5$\pm$8.0 |
    252 |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 3 | 0.7$\pm$0.6 | 8.3$\pm$3.3 | 52.2$\pm$5.9 | 38.9$\pm$7.5 | 162
    |'
  prefs: []
  type: TYPE_TB
- en: '| BCW Class 4 | 6.1$\pm$2.4 | 8.3$\pm$3.3 | 18.3$\pm$3.0 | 67.3$\pm$6.8 | 710
    |'
  prefs: []
  type: TYPE_TB
- en: 'Table 7: As Table [6](#S4.T6 "Table 6 ‣ 4.1 Does prediction accuracy depend
    on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for
    Star Cluster Classification: I. Application to the PHANGS-HST Survey"), but now
    using VGG19-BN.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 How accurately can the models predict classifications for clusters in galaxies
    not included in the training sample?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To further assess the robustness and resilience of our neural network models,
    we use them to classify images from a galaxy not included in the original training
    dataset, namely the PHANGS-HST target NGC 1559\. This galaxy is about two to four
    times further away than the galaxies in either of the training samples, with the
    notable exception of NGC1566, which is at a comparable distance to NGC 1559 (18
    Mpc vs. 19 Mpc), and included the sample with consensus classifications from three
    LEGUS team members (Table [2](#S2.T2 "Table 2 ‣ 2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).
    Results are presented in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey") and
    Tables [6](#S4.T6 "Table 6 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey") and [7](#S4.T7 "Table
    7 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey").'
  prefs: []
  type: TYPE_NORMAL
- en: 'Notwithstanding these differences, we again notice that all models produce
    comparable results. Reading along the diagonal of the confusion matrices presented
    in Figure [4](#S4.F4 "Figure 4 ‣ 4.1 Does prediction accuracy depend on the origin
    of the classifications? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster
    Classification: I. Application to the PHANGS-HST Survey"), for the models trained
    on the objects primarily classified by BCW, the accuracies for ResNet18 are 73%,
    38%, 40%, 75% for class 1, 2 ,3, and 4 objects respectively, and 74%, 42%, 52%,
    67% for VGG19-BN. Likewise, for the networks trained on the mode of classifications
    performed by three LEGUS members the accuracies are 70%, 41%, 48%, 62% for ResNet18
    and 70%, 45%, 52%, 52% for VGG19-BN.'
  prefs: []
  type: TYPE_NORMAL
- en: 'For all models, the performance for NGC1559 class 1 star clusters is at or
    above the 70% level. The classification accuracy of the BCW-based models is similar
    to their performance on the validation samples (i.e., Figure [3](#S4.F3 "Figure
    3 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey")). Meanwhile for NGC1559 class 1 star clusters the performance
    of the models trained on the LEGUS consensus classifications are 6-8% lower relative
    to the classification of the validation samples. On the other hand for class 2
    star clusters, the accuracies hover around the 40% level, and are the lowest of
    the four classes. The accuracies for the models trained on the objects primarily
    classified by BCW drop by $\sim$20%: from 58% (test subset sample) to 38% (NGC
    1559) for ResNet18, and from 64% to 42% for VGG19-BN. Similarly, those trained
    on the LEGUS consensus classifications drop, although by only $\sim$10%: from
    54% to 41% for ResNet18, and from 54% to 45% for VGG19-BN. The accuracies for
    the NGC 1559 class 3 star clusters are at the 40-50% level, a $\sim$10% drop for
    all models relative to the performance on the test subsets. Finally, for the class
    4 non-clusters, the models trained on the objects primarily classified by BCW
    perform comparably, i.e., at the 70% level, while those trained on the LEGUS consensus
    classifications drop to the 50-60% level.'
  prefs: []
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Uncertainty calculations through entropy analysis
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Another method to investigate the uncertainty in the models’ predictions is
    through the computation of entropy by using the probability distributions for
    each of the cluster classes we are trying to classify, which is an output of the
    models. Intuitively, the more pronounced the peak is in the probability distribution,
    the more confident the neural network is about its prediction, and in this case,
    the entropy calculated from the prediction probability distribution will be lower.
    For example, if the probability distribution is only concentrated on one class,
    the network network in this case is $100\%$ certain about its prediction and the
    entropy would be zero, i.e., there is no uncertainty. On the other hand, if the
    prediction assigned the same probability for all the 4 classes under consideration
    equally, we would have maximum uncertainty in this case, since for the given input
    image, all the 4 classes are equally possible to be the predicted classes, and
    in this case, the maximum entropy is $\ln(4)\approx 1.39$. Figure [5](#S4.F5 "Figure
    5 ‣ 4.2.1 Uncertainty calculations through entropy analysis ‣ 4.2 How accurately
    can the models predict classifications for clusters in galaxies not included in
    the training sample? ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") shows the distribution of the entropies
    for the predictions of VGG19-BN when tested on NGC 1559 images.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/873c50c72771e20d8ca75674048a0f8c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The uncertainty in the neural network’s prediction is quantified
    by the entropy of the predicted probability distribution over the 4 star cluster
    image classes considered in this analysis. For a random guess over the 4 classes,
    the entropy is $\ln(4)\approx 1.39$. The lower the entropy, the higher the confidence
    the neural network has about its prediction. The panel shows the predicted entropy
    value for each NGC1559 image with which we classified with our VGG19-BN model,
    trained on the objects primarily classified by BCW given in Table [1](#S2.T1 "Table
    1 ‣ 2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey"). The x-axis shows the binned values of
    the entropy values, whose frequency of occurrence is indicated on the y-axis.
    To make clear that the area of each histogram is normalized to one, the y-axis
    label is explicitly labeled “Normalized distribution."'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 How does classification accuracy depend on size of training images?
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To quantify the importance of image size for star cluster classification, we
    train our neural network models again, but with two additional cropping sizes:
    $25\times 25$ pixels and $100\times 100$ pixels. In Figure [6](#S4.F6 "Figure
    6 ‣ 4.3 How does classification accuracy depend on size of training images? ‣
    4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey"), we present results from training on the sample with
    LEGUS consensus classifications (again, where 80% of the sample is used for training
    and 20% for testing), where the results presented earlier from our fiducial experiments
    with $50\times 50$ pixels postage stamps are repeated to facilitate comparison.
    We present results based on the LEGUS consensus classifications as the range of
    distances of the galaxies (from 3.1 Mpc to 18 Mpc; Table [2](#S2.T2 "Table 2 ‣
    2.1 Consistency among Classifications ‣ 2 Classification of Compact Star Clusters
    in Nearby Galaxies ‣ Deep Transfer Learning for Star Cluster Classification: I.
    Application to the PHANGS-HST Survey")) is inclusive of the range spanned by the
    sample primarily classified by BCW (Table [1](#S2.T1 "Table 1 ‣ 2.1 Consistency
    among Classifications ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies
    ‣ Deep Transfer Learning for Star Cluster Classification: I. Application to the
    PHANGS-HST Survey")). Hence, the physical scales subtended by the cropped images
    span from 16 pc (for $25\times 25$ pixel images at 3.1 Mpc) to 360 pc (for $100\times
    100$ pixel images at 18 Mpc).'
  prefs: []
  type: TYPE_NORMAL
- en: 'There are no significant differences between the results for the different
    cropping sizes. These results indicate that our neural network models are resilient
    to this particular data curation choice. We see variations at the level of $\sim
    5\%$, which is within the expected variation in the performance of the neural
    network models due to random weight initialization, as indicated in Tables [4](#S4.T4
    "Table 4 ‣ 4.1 Does prediction accuracy depend on the origin of the classifications?
    ‣ 4 Results ‣ Deep Transfer Learning for Star Cluster Classification: I. Application
    to the PHANGS-HST Survey") and [5](#S4.T5 "Table 5 ‣ 4.1 Does prediction accuracy
    depend on the origin of the classifications? ‣ 4 Results ‣ Deep Transfer Learning
    for Star Cluster Classification: I. Application to the PHANGS-HST Survey"). Results
    for the models trained with objects primarily classified by BCW are consistent.
    The results also do not change if the neural network models are trained with postage
    stamps using random cropping sizes ranging from $25\times 25$ pixels to $100\times
    100$ pixels (i.e., a random cropping size is chosen for each object in the training
    and testing sample). \colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0f18d266dc234084f25231b6c865a674.png) ![Refer to caption](img/966dbc019b69e5408e72cad34a923152.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/939cd8d188af28dc728e52aebf5dbb41.png) ![Refer to caption](img/6118cbd4af29068569ce039eef4e8014.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/c0e7355a71780e7f23fe90eb449fd76e.png) ![Refer to caption](img/d839ac299766c0e7797c63d205e6475d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Left column: VGG19-BN model classification results for cropping size
    $25\times 25$, $50\times 50$ and $100\times 100$. Right column: as before, but
    now for ResNet.\colorblack'
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Classification accuracy as a function of imaging filter
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We have also quantified what filter has the leading contribution for classification
    accuracy. To do so, we perform the following experiment: using NGC 1559 images
    as testing dataset, we produced five different testing datasets in which one filter
    was set to zero. We then fed these 5 different testing datasets, one at a time,
    to our neural network models trained with objects primarily classified by BCW
    and quantified which missing filter leads to the most significant drop in classification
    accuracy. As shown in Figure [7](#S4.F7 "Figure 7 ‣ 4.4 Classification accuracy
    as a function of imaging filter ‣ 4 Results ‣ Deep Transfer Learning for Star
    Cluster Classification: I. Application to the PHANGS-HST Survey"), the key filter
    is F555W.'
  prefs: []
  type: TYPE_NORMAL
- en: This finding is expected, since the human classifications primarily rely on
    the F555W image (e.g., using DS9 and imexamine), with color images (F814, F555,
    F336W) generated by the Hubble Legacy Archive providing supporting morphological
    information. Therefore, our neural network models seem to use insights similar
    to human vision to classify star cluster images.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/53812323f9d3f129d6f60271378e7676.png) ![Refer to caption](img/fec5c09d4b903d86740bbe3a8353db90.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/9e7ac5c384ea9008628c7ef6f6a17f5a.png) ![Refer to caption](img/590cf61fa2785c9a68ef68fcbc941965.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/cfa2d9e6d99291a656b6601bbd16c677.png) ![Refer to caption](img/c05a0135d0ec7b5406b671c1e0e49ff5.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/e0b0b0d34793a8e81f48af5eba866894.png) ![Refer to caption](img/5c4a724cabf6dad2bae6a23d3720f294.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/e7b5ee4fb8873ae8cd02bedd648d14a8.png) ![Refer to caption](img/a6574c8fb4caa47492e7eb0ff7c29687.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Left column: ResNet model classification results when the indicated
    filter is removed from the composite image. Right column: as before, but now for
    VGG19-BN. The greatest drop in the accuracies occurs when the V-band filter is
    removed.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Discussion & Conclusions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Using homogeneous datasets of human-labeled star cluster images from the Hubble
    Space Telescope, we have leveraged a new generation of neural network models and
    deep transfer learning techniques for morphological classification of compact
    star clusters in nearby galaxies to distances of $\sim$ 20 Mpc. These results
    are very promising.
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Through all of the experiments presented here with multiple training sweeps
    for each neural network model, we see that the classification accuracy is similar
    for both architectures studied: i.e., ResNet18 and VGG19-BN pre-trained with the
    ImageNet dataset where the weights of the last layers and the last fully connected
    layers are randomly initialized.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Somewhat surprisingly, the performance of the models is relatively robust to
    the origin of the human classifications used, the particular galaxies included
    in the training sample, and the cropping size of the training images (spanning
    physical sizes of 16pc to 360pc). Irrespective of whether the models are trained
    on a sample primarily classified by one expert (BCW) with galaxies at distances
    2-4 times closer than the star cluster candidates to be evaluated in PHANGS-HST
    galaxy NGC 1559; or trained on the mode of classifications from three individuals
    where the sample does includes a galaxy at a distance similar to NGC 1559; the
    results are comparable. The prediction accuracies for NGC 1559, which was not
    included in the training samples, are at the level of 70%:40%40-50% for the class
    1, 2, and 3 star clusters. However, the BCW-trained networks have a higher performance
    in classification of the class 4 non-clusters in NGC 1559 (70% vs. 50-60%). This
    might be expected since the classifications for NGC 1559 were also performed by
    BCW, and may be due to a higher level of self-consistency in the training and
    testing classification datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Most importantly, despite training with relatively small datasets, the performance
    of the networks presented here is competitive with the consistency achieved in
    previous human and quantitative automated classification of the same star cluster
    candidate samples (Section [2.1](#S2.SS1 "2.1 Consistency among Classifications
    ‣ 2 Classification of Compact Star Clusters in Nearby Galaxies ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey")).
    Thus, this work provides a proof-of-concept demonstration that deep transfer learning
    can be successfully used to automate morphological classification of star cluster
    candidate samples using HST UV-optical imaging being obtained by PHANGS-HST.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: \color
  prefs: []
  type: TYPE_NORMAL
- en: black
  prefs: []
  type: TYPE_NORMAL
- en: This work represents a milestone in the use of deep transfer learning for this
    area of research, and represents progress from initial machine learning experiments
    described in Grasha et al. ([2019](#bib.bib30)) and also discussed in Messa et al.
    ([2018](#bib.bib47)). Grasha et al. ([2019](#bib.bib30)) experimented with the
    use of an ML algorithm for classifying the approximately eleven thousand clusters
    in the spiral galaxy M51, based on a human classified training set with $\sim$2500
    clusters from the LEGUS sample. While the recovery of class 1 and 2 clusters is
    fairly good (in the range 60 - 75 % in the Grasha and Messa studies, and comparable
    to the prediction accuracies presented here \colorblack) recovery of class 3 clusters
    is poor, with an apparently significant anti-correlation.
  prefs: []
  type: TYPE_NORMAL
- en: To attempt to further improve upon the models presented here, future work will
    include training with the largest star cluster candidate sample possible (i.e.,
    combining all samples used for this proof-of-concept demonstration plus classifications
    for objects in several galaxies in PHANGS-HST). \colorblack Improvement in classification
    accuracy also requires the development of a standarized dataset of human-labelled
    star cluster classifications, with classifications agreed upon by a full range
    of experts in the field, to be used as the basis for future network training.
    This effort would benefit from a classification challenge, where experts can come
    to detailed agreement on the morphological features that constitute the criteria
    for classification (e.g., to establish full decision trees, such as those used
    for Galaxy Zoo by citizen scientists), \colorblack and explicitly describe where
    they disagree and why. A review of differences in star cluster definitions between
    research groups, and their possible impact on conclusions about star cluster formation
    and evolution, can be found in Krumholz et al. ([2018](#bib.bib42)). The ultimate
    goal is to use deep learning techniques to not only rapidly produce reliable classifications
    and speed the time to science, but to significantly advance the field of star
    cluster evolution. Given the discussion in Krumholz et al. ([2018](#bib.bib42)),
    this requires that deep learning networks are trained on such standardized datasets,
    broadly adopted by workers in the field.
  prefs: []
  type: TYPE_NORMAL
- en: With this study we open a new chapter to explore in earnest the use of deep
    transfer learning for the classification of very large datasets of star cluster
    galaxies in ongoing and future electromagnetic surveys, and application to the
    new PHANGS-HST data being obtained now.
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We thank the referee for feedback which significantly improved the paper, and
    in particular, motivated the expansion of our experiments to investigate potential
    differences in outcome when training with classifications by a single individual
    (BCW) versus using LEGUS consensus classifications from multiple individuals.
    Initially, our experiments were based solely on the classifications of BCW.
  prefs: []
  type: TYPE_NORMAL
- en: We also thank the LEGUS team, and in particular Daniela Calzetti and Kathryn
    Grasha, for their pioneering efforts in the field of classifying star clusters
    using machine learning techniques, and for making results available via the LEGUS
    public website. We thank Sean Linden for assisting BCW in classifications for
    star cluster candidates in NGC 3351, NGC 3627, and NGC 5457.
  prefs: []
  type: TYPE_NORMAL
- en: Based on observations made with the NASA/ESA Hubble Space Telescope, obtained
    from the data archive at the Space Telescope Science Institute. STScI is operated
    by the Association of Universities for Research in Astronomy, Inc. under NASA
    contract NAS 5-26555\. Support for Program number 15654 was provided through a
    grant from the STScI under NASA contract NAS5- 26555.
  prefs: []
  type: TYPE_NORMAL
- en: This research has made use of the NASA/IPAC Extragalactic Database (NED) which
    is operated by the Jet Propulsion Laboratory, California Institute of Technology,
    under contract with NASA.
  prefs: []
  type: TYPE_NORMAL
- en: EAH and WW gratefully acknowledge National Science Foundation (NSF) awards OAC-1931561
    and OAC-1934757.
  prefs: []
  type: TYPE_NORMAL
- en: This research is part of the Blue Waters sustained-petascale computing project,
    which is supported by NSF awards OCI-0725070 and ACI-1238993, and the State of
    Illinois. Blue Waters is a joint effort of the University of Illinois at Urbana-Champaign
    and its National Center for Supercomputing Applications.
  prefs: []
  type: TYPE_NORMAL
- en: This work utilized resources supported by the NSF’s Major Research Instrumentation
    program, grant OAC-1725729, as well as the University of Illinois at Urbana-Champaign.
  prefs: []
  type: TYPE_NORMAL
- en: We are grateful to NVIDIA for donating several Tesla P100 and V100 GPUs that
    we used for our analysis, and the NSF grants NSF-1550514, NSF-1659702 and TG-PHY160053.
  prefs: []
  type: TYPE_NORMAL
- en: This research used resources of the Argonne Leadership Computing Facility, which
    is a DOE Office of Science User Facility supported under Contract DE-AC02-06CH11357\.
    We thank the [NCSA Gravity Group](http://gravity.ncsa.illinois.edu) for useful
    feedback.
  prefs: []
  type: TYPE_NORMAL
- en: MC and JMDK gratefully acknowledge funding from the Deutsche Forschungsgemeinschaft
    (DFG) through an Emmy Noether Research Group (grant number KR4801/1-1) and the
    DFG Sachbeihilfe (grant number KR4801/2-1). JMDK gratefully acknowledges funding
    from the European Research Council (ERC) under the European Union’s Horizon 2020
    research and innovation programme via the ERC Starting Grant MUSTANG (grant agreement
    number 714907).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Abbott et al. (2016) Abbott T., et al., 2016, [Mon. Not. Roy. Astron. Soc.](http://dx.doi.org/10.1093/mnras/stw641),
    460, 1270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ackermann et al. (2018) Ackermann S., Schawinski K., Zhang C., Weigel A. K.,
    Turp M. D., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/sty1398), 479, 415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Adamo et al. (2017) Adamo A., et al., 2017, [ApJ](http://dx.doi.org/10.3847/1538-4357/aa7132),
    [841, 131](http://adsabs.harvard.edu/abs/2017ApJ...841..131A)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ball et al. (2006) Ball N. M., Brunner R. J., Myers A. D., Tcheng D., 2006,
    [ApJ](http://dx.doi.org/10.1086/507440), 650, 497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ball et al. (2008) Ball N. M., Brunner R. J., Myers A. D., Strand N. E., Alberts
    S. L., Tcheng D., 2008, [ApJ](http://dx.doi.org/10.1086/589646), 683, 12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Banerji et al. (2010) Banerji M., et al., 2010, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x),
    406, 342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Barchi et al. (2019) Barchi P. H., de Carvalho R. R., Rosa R. R., Sautter R.,
    Soares-Santos M., Marques B. A. D., Clua E., 2019, arXiv e-prints, p. arXiv:1901.07047
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bastian et al. (2012) Bastian N., et al., 2012, [MNRAS](http://dx.doi.org/10.1111/j.1365-2966.2011.19909.x),
    [419, 2606](http://adsabs.harvard.edu/abs/2012MNRAS.419.2606B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bengio (2011) Bengio Y., 2011, in Proceedings of the 2011 International Conference
    on Unsupervised and Transfer Learning workshop-Volume 27\. pp 17–37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bertin & Arnouts (1996a) Bertin E., Arnouts S., 1996a, [A&AS](http://dx.doi.org/10.1051/aas:1996164),
    [117, 393](https://ui.adsabs.harvard.edu/abs/1996A%26AS..117..393B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bertin & Arnouts (1996b) Bertin E., Arnouts S., 1996b, A&AS, [117, 393](http://adsabs.harvard.edu/abs/1996A%26AS..117..393B)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calzetti et al. (2015a) Calzetti D., et al., 2015a, [AJ](http://dx.doi.org/10.1088/0004-6256/149/2/51),
    [149, 51](http://adsabs.harvard.edu/abs/2015AJ....149...51C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Calzetti et al. (2015b) Calzetti D., et al., 2015b, [ApJ](http://dx.doi.org/10.1088/0004-637X/811/2/75),
    [811, 75](http://adsabs.harvard.edu/abs/2015ApJ...811...75C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cannon & Pickering (1912) Cannon A. J., Pickering E. C., 1912, Annals of Harvard
    College Observatory, [56, 65](https://ui.adsabs.harvard.edu/abs/1912AnHar..56...65C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cannon & Pickering (1918) Cannon A. J., Pickering E. C., 1918, Annals of Harvard
    College Observatory, [91, 1](https://ui.adsabs.harvard.edu/abs/1918AnHar..91....1C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Carrasco Kind & Brunner (2013) Carrasco Kind M., Brunner R. J., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt574),
    432, 1483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chandar et al. (2010) Chandar R., et al., 2010, [ApJ](http://dx.doi.org/10.1088/0004-637X/719/1/966),
    [719, 966](http://adsabs.harvard.edu/abs/2010ApJ...719..966C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chandar et al. (2014) Chandar R., Whitmore B. C., Calzetti D., O’Connell R.,
    2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/787/1/17), [787, 17](https://ui.adsabs.harvard.edu/abs/2014ApJ...787...17C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chandar et al. (2016) Chandar R., Whitmore B. C., Dinino D., Kennicutt R. C.,
    Chien L. H., Schinnerer E., Meidt S., 2016, [ApJ](http://dx.doi.org/10.3847/0004-637X/824/2/71),
    [824, 71](https://ui.adsabs.harvard.edu/abs/2016ApJ...824...71C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cook et al. (2019) Cook D. O., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/stz331),
    [484, 4897](http://adsabs.harvard.edu/abs/2019MNRAS.484.4897C)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng et al. (2009) Deng J., Dong W., Socher R., Li L.-J., Li K., Fei-Fei L.,
    2009, in CVPR09\. [http://www.image-net.org/](http://www.image-net.org/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dieleman et al. (2015) Dieleman S., Willett K. W., Dambre J., 2015, [MNRAS](http://dx.doi.org/10.1093/mnras/stv632),
    [450, 1441](https://ui.adsabs.harvard.edu/abs/2015MNRAS.450.1441D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domínguez Sánchez et al. (2018) Domínguez Sánchez H., Huertas-Company et al.,
    2018, preprint, p. arXiv:1807.00807 ([arXiv:1807.00807](http://arxiv.org/abs/1807.00807))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Everingham et al. (2015) Everingham M., Eslami S. M. A., Van Gool L., Williams
    C. K. I., Winn J., Zisserman A., 2015, International Journal of Computer Vision,
    111, 98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fadely et al. (2012) Fadely R., Hogg D. W., Willman B., 2012, [ApJ](http://dx.doi.org/10.1088/0004-637X/760/1/15),
    760, 15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: George et al. (2017) George D., Shen H., Huerta E. A., 2017, arXiv e-prints,
    p. arXiv:1711.07468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: George et al. (2018) George D., Shen H., Huerta E. A., 2018, [Phys. Rev. D](http://dx.doi.org/10.1103/PhysRevD.97.101501),
    97, 101501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2016) Goodfellow I., Bengio Y., Courville A., 2016, Deep
    Learning. MIT Press
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gouliermis (2018) Gouliermis D. A., 2018, [PASP](http://dx.doi.org/10.1088/1538-3873/aac1fd),
    [130, 072001](https://ui.adsabs.harvard.edu/abs/2018PASP..130g2001G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Grasha et al. (2019) Grasha K., et al., 2019, [MNRAS](http://dx.doi.org/10.1093/mnras/sty3424),
    [483, 4707](https://ui.adsabs.harvard.edu/abs/2019MNRAS.483.4707G)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2015) He K., Zhang X., Ren S., Sun J., 2015, arXiv e-prints, [p.
    arXiv:1512.03385](https://ui.adsabs.harvard.edu/abs/2015arXiv151203385H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) He K., Zhang X., Ren S., Sun J., 2016, in Proceedings of the
    IEEE conference on computer vision and pattern recognition. pp 770–778, [https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html](https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Holtzman et al. (1992) Holtzman J. A., et al., 1992, [AJ](http://dx.doi.org/10.1086/116094),
    [103, 691](https://ui.adsabs.harvard.edu/abs/1992AJ....103..691H)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hubble (1926) Hubble E. P., 1926, [ApJ](http://dx.doi.org/10.1086/143018), 64,
    321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hubble (1936) Hubble E. P., 1936, Realm of the Nebulae
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ishak (2017) Ishak B., 2017, [Contemporary Physics](http://dx.doi.org/10.1080/00107514.2016.1246478),
    58, 99
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kamdar et al. (2016) Kamdar H., Turk M., Brunner R., 2016, [Monthly Notices
    of the Royal Astronomical Society](http://dx.doi.org/10.1093/mnras/stv2310), 455,
    642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Khan et al. (2019) Khan A., Huerta E. A., Wang S., Gruendl R., Jennings E.,
    Zheng H., 2019, Phys. Lett., B795, 248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim & Brunner (2017) Kim E. J., Brunner R. J., 2017, [MNRAS](http://dx.doi.org/10.1093/mnras/stw2672),
    464, 4463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kingma & Ba (2014) Kingma D. P., Ba J., 2014, Adam: A Method for Stochastic
    Optimization ([arXiv:1412.6980](http://arxiv.org/abs/1412.6980))'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krizhevsky et al. (2012) Krizhevsky A., Sutskever I., Hinton G. E., 2012, in
    Proceedings of the 25th International Conference on Neural Information Processing
    Systems - Volume 1. NIPS’12. Curran Associates Inc., USA, pp 1097–1105, [http://dl.acm.org/citation.cfm?id=2999134.2999257](http://dl.acm.org/citation.cfm?id=2999134.2999257)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krumholz et al. (2018) Krumholz M. R., McKee C. F., Bland -Hawthorn J., 2018,
    arXiv e-prints, [p. arXiv:1812.01615](https://ui.adsabs.harvard.edu/abs/2018arXiv181201615K)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSST Science Collaboration et al. (2009) LSST Science Collaboration et al.,
    2009, preprint ([arXiv:0912.0201](http://arxiv.org/abs/0912.0201))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Larsen (2002) Larsen S. S., 2002, [AJ](http://dx.doi.org/10.1086/342381), [124,
    1393](http://adsabs.harvard.edu/abs/2002AJ....124.1393L)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (2015) LeCun Y., Bengio Y., Hinton G., 2015, nature, 521, 436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Małek & et al (2013) Małek K., et al 2013, [A&A](http://dx.doi.org/10.1051/0004-6361/201321447),
    557, A16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Messa et al. (2018) Messa M., et al., 2018, [MNRAS](http://dx.doi.org/10.1093/mnras/stx2403),
    [473, 996](https://ui.adsabs.harvard.edu/abs/2018MNRAS.473..996M)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paszke et al. (2017) Paszke A., et al., 2017, in NIPS-W.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Portegies Zwart et al. (2010) Portegies Zwart S. F., McMillan S. L. W., Gieles
    M., 2010, [ARA&A](http://dx.doi.org/10.1146/annurev-astro-081309-130834), [48,
    431](https://ui.adsabs.harvard.edu/abs/2010ARA&A..48..431P)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky et al. (2015) Russakovsky O., et al., 2015, [International Journal
    of Computer Vision (IJCV)](http://dx.doi.org/10.1007/s11263-015-0816-y), 115,
    211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ryon et al. (2014) Ryon J. E., et al., 2014, [AJ](http://dx.doi.org/10.1088/0004-6256/148/2/33),
    [148, 33](http://adsabs.harvard.edu/abs/2014AJ....148...33R)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ryon et al. (2017) Ryon J. E., et al., 2017, [The Astrophysical Journal](http://dx.doi.org/10.3847/1538-4357/aa719e),
    841, 92
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schweizer et al. (1996) Schweizer F., Miller B. W., Whitmore B. C., Fall S. M.,
    1996, [AJ](http://dx.doi.org/10.1086/118146), [112, 1839](https://ui.adsabs.harvard.edu/abs/1996AJ....112.1839S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sevilla-Noarbe & Etayo-Sotos (2015) Sevilla-Noarbe I., Etayo-Sotos P., 2015,
    [Astronomy and Computing](http://dx.doi.org/10.1016/j.ascom.2015.03.010), 11,
    64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shannon (1948) Shannon C. E., 1948, Bell system technical journal, 27, 379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan & Zisserman (2014a) Simonyan K., Zisserman A., 2014a, arXiv preprint
    arXiv:1409.1556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan & Zisserman (2014b) Simonyan K., Zisserman A., 2014b, arXiv e-prints,
    [p. arXiv:1409.1556](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.1556S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Solarz et al. (2017) Solarz A., Bilicki M., Gromadzki M., Pollo A., Durkalec
    A., Wypych M., 2017, [A&A](http://dx.doi.org/10.1051/0004-6361/201730968), 606,
    A39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Suchkov et al. (2005) Suchkov A. A., Hanisch R. J., Margon B., 2005, [AJ](http://dx.doi.org/10.1086/497363),
    130, 2439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2014) Szegedy C., et al., 2014, arXiv e-prints, [p. arXiv:1409.4842](https://ui.adsabs.harvard.edu/abs/2014arXiv1409.4842S)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vasconcellos et al. (2011) Vasconcellos E. C., de Carvalho R. R., Gal R. R.,
    LaBarbera F. L., Capelato H. V., Frago Campos Velho H., Trevisan M., Ruiz R. S. R.,
    2011, [AJ](http://dx.doi.org/10.1088/0004-6256/141/6/189), 141, 189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Weir et al. (1995) Weir N., Fayyad U. M., Djorgovski S., 1995, [AJ](http://dx.doi.org/10.1086/117459),
    109, 2401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whitmore et al. (1995) Whitmore B. C., Sparks W. B., Lucas R. A., Macchetto
    F. D., Biretta J. A., 1995, [ApJ](http://dx.doi.org/10.1086/309788), [454, L73](https://ui.adsabs.harvard.edu/abs/1995ApJ...454L..73W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whitmore et al. (2014) Whitmore B. C., et al., 2014, [ApJ](http://dx.doi.org/10.1088/0004-637X/795/2/156),
    [795, 156](http://adsabs.harvard.edu/abs/2014ApJ...795..156W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Whitmore et al. (2016) Whitmore B. C., et al., 2016, [AJ](http://dx.doi.org/10.3847/0004-6256/151/6/134),
    [151, 134](https://ui.adsabs.harvard.edu/abs/2016AJ....151..134W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Willett et al. (2013) Willett K. W., et al., 2013, [MNRAS](http://dx.doi.org/10.1093/mnras/stt1458),
    [435, 2835](https://ui.adsabs.harvard.edu/abs/2013MNRAS.435.2835W)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Vaucouleurs (1963) de Vaucouleurs G., 1963, [ApJS](http://dx.doi.org/10.1086/190084),
    [8, 31](https://ui.adsabs.harvard.edu/abs/1963ApJS....8...31D)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Statistical foundations of Deep Learning Classifiers
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Within the framework of statistical learning, an image $X$ can be modeled as
    a random matrix that takes value in set $\mathcal{X}$, and the corresponding class
    can be treated as a random variable $Y$ that takes value in set $\mathcal{Y}$.
    Since we use $299\times 299$ images with 5 channels, we treat a cluster image
    as random matrix of size $299\times 299\times 5$. Similarly, as we are trying
    to classify the images into 4 classes, $Y$ is a discrete random variable that
    takes values in $\mathcal{Y}$ with cardinality $|\mathcal{Y}|=4$.
  prefs: []
  type: TYPE_NORMAL
- en: We assume that the star images and the corresponding class labels follow some
    unknown but fixed joint probability distribution, with the probability density
    function (pdf) $f_{XY}(x,y)$. We also use $\Delta_{\mathcal{Y}}$ to denote set
    of all possible distribution over $\mathcal{Y}$. Since in our case, $|\mathcal{Y}|=4$,
    we have $\Delta_{\mathcal{Y}}=\{\pi=(\pi_{1},\pi_{2},\pi_{3},\pi_{4}):\sum_{i=1}^{4}\pi_{i}=1,\pi_{i}\geq
    0,\forall i\in[4]\}$
  prefs: []
  type: TYPE_NORMAL
- en: Under these conventions, the goal of classification is to find a classifier
    or function $h:X\rightarrow\Delta_{\mathcal{Y}}$ that minimizes the expectation
    of the cross entropy between the predicted and the ground truth probability mass
    distribution (pmf) over the classes given the input image $X$, namely,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle L(h)$ | $\displaystyle=\mathbf{E}[H(h(X),f_{Y&#124;X}(\cdot&#124;X))]$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\int H(h(X),f_{Y&#124;X}(\cdot&#124;x))f_{X}(x)dx\,,$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: where $f_{X}(x)$ is the marginal distribution of $X$ over $\mathcal{X}$, and
    $H$ is the cross entropy between the predicted and the ground truth pmf over classes,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle H(h(x),f_{Y&#124;Y}(\cdot&#124;x))=-\sum_{i=1}^{4}f_{Y&#124;X}(Y=i&#124;x)\log([h(x)]_{i}),$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: and the $f_{Y|X}(y|x)$ is the conditional distribution of $Y$ given $X$.
  prefs: []
  type: TYPE_NORMAL
- en: In most cases, we only know the empirical distribution $\hat{f}_{XY}(x,y)$ of
    $(X,Y)$ and $\hat{f}_{Y|X}(y|x)$ of $Y$, which are determined by the empirical
    data. So the quantity we can directly minimize is
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\hat{L}(h)$ | $\displaystyle=\hat{\mathbf{E}}[H(h_{X}(\cdot),\hat{f}_{Y&#124;X}(\cdot&#124;X))]$
    |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | $\displaystyle=\int H(h_{x}(\cdot),\hat{f}_{Y&#124;X}(\cdot&#124;x))\hat{f}_{X}(x)dx\,,$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: In practice, if the choice of $h(\cdot)$ is arbitrary, then finding an optimal
    solution is computationally unfeasible. Therefore, we often restrict the searching
    space to a class of parameterized functions, $h_{\mathbf{w}}(\cdot)$, where $\mathbf{w}$
    is a vector of parameters. In this case, the optimization problem can be posed
    as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\mathbf{w}^{*}=\operatorname*{arg\,min}_{\mathbf{w}}\hat{L}(h_{\mathbf{w}})\,.$
    |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: The choice of the parameterized function class is critical to the success of
    any statistical learning algorithm. In recent years, a deep-layered structure
    of functions has received much attention  (LeCun et al., [2015](#bib.bib45); Goodfellow
    et al., [2016](#bib.bib28)),
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{}h_{\mathbf{w}}(\mathbf{x})=h_{\mathbf{w}_{n}}(h_{\mathbf{w}_{n-1}}(\cdots
    h_{\mathbf{w}_{1}}(\mathbf{x}))),$ |  | (7) |'
  prefs: []
  type: TYPE_TB
- en: where $n$ is the number of layers or the depth. Usually, we choose, $h_{\mathbf{w}_{i}}(\mathbf{x})=g(\mathbf{w}_{i}\mathbf{x})$,
    where $\mathbf{w}_{i}$ is a matrix, $\mathbf{x}$ is an input vector, and $g(\cdot)$
    is a fixed non-linear function, e.g., $\max\{\cdot,0\}$ (also known as ReLU),
    $\tanh(\cdot)$, etc, that is applied element-wise. For the classification problems,
    we usually apply the so-called softmax function after the last linear transformation.
    The softmax function on a vector $\mathbf{x}$ is a normalization after an element-wise
    exponentiation,
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle\text{softmax}(\mathbf{x})_{i}=\frac{\exp(x_{i})}{\sum_{i=1}^{n}{\exp(x_{i})}},\
    \ \ \ \forall i=1,...,n,$ |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: where $n$ is the length of $\mathbf{x}$.
  prefs: []
  type: TYPE_NORMAL
- en: This function class and its extensions, also dubbed neural networks, combined
    with simple first-order optimization algorithms such as stochastic gradient descent
    (SGD), and improved computing hardware, has lead to disruptive applications of
    deep learning (LeCun et al., [2015](#bib.bib45); Goodfellow et al., [2016](#bib.bib28)).
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Deep transfer learning
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In practice, Eq. [6](#A1.E6 "In Appendix A Statistical foundations of Deep
    Learning Classifiers ‣ Deep Transfer Learning for Star Cluster Classification:
    I. Application to the PHANGS-HST Survey") is usually iteratively solved by using
    variants of SGD. Thus, the choice of initial value for weights $\mathbf{w}$ is
    critical to the success of the training algorithm. If we have some prior knowledge
    about what initial wights $\mathbf{w}_{0}$ works better, then it is highly possible
    that the numerical iteration can converge faster and return better weights $\mathbf{w}$.
    This is the idea behind deep transfer learning (Bengio, [2011](#bib.bib9); Goodfellow
    et al., [2016](#bib.bib28)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'For a deep learning neural network, such as the one defined by Eq. [7](#A1.E7
    "In Appendix A Statistical foundations of Deep Learning Classifiers ‣ Deep Transfer
    Learning for Star Cluster Classification: I. Application to the PHANGS-HST Survey"),
    the layered structure can be intuitively interpreted as different levels of abstraction
    for the learned features. In other words, layers that are close to the input learn
    lower-level features, such as different shapes and curves in the image, and layers
    that are close to the final output layer learn higher-level features, such as
    the type of the input image. Suppose we have a trained model that works well in
    one setting, with probability distribution $f^{(1)}_{XY}$, and now we would like
    to train another model in a different setting, with with probability distribution
    $f^{(2)}_{XY}$. If the images drawn from the distributions $f^{(1)}_{XY}$ and
    $f^{(2)}_{XY}$ share some features, then it is possible to transfer weights from
    the model trained on images sampled from $f^{(1)}_{XY}$, to the model that we
    would like to train, using images sampled from $f^{(2)}_{XY}$, with the assumption
    that the weights from the model trained on images sampled from $f^{(1)}_{XY}$,
    can also be useful in extracting features from images drawn from the distribution
    $f^{(2)}_{XY}$. So, instead of training the second model from scratch, we can
    initialize the weights of the second model to those of the first model that we
    trained in a different setting (e.g., distribution $f^{(1)}_{XY}$), and utilize
    the common features we have already learned in the previous setting.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Batch normalization
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The weights of each layer in a neural network model change throughout the training
    phase, which implies that the activations of each layer will also change. Given
    that the activations of any given layer are the inputs to the subsequent layer,
    this means that the input distribution changes at every step. This is far from
    ideal because it forces each intermediate layer to continuously adapt to its changing
    inputs.Batch normalization is used to ameliorate this problem by normalizing the
    activations of each layer.In practice this is accomplished by adding two trainable
    parameters to each layer, so the normalized output is multiplied by a standard
    deviation parameter, and then shifted by a mean parameter. With this approach
    only two parameters are changed for each activation, as opposed to losing the
    stability of the network by changing all the weights. It is expected that through
    this method each layer will learn on a more stable distribution of inputs, which
    may accelerate the training stage.
  prefs: []
  type: TYPE_NORMAL
