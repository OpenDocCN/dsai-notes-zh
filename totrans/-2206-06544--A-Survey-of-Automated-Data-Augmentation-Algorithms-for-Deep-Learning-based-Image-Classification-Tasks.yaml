- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:45:37'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:45:37
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2206.06544] A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2206.06544] 深度学习图像分类任务的自动数据增强算法综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2206.06544](https://ar5iv.labs.arxiv.org/html/2206.06544)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2206.06544](https://ar5iv.labs.arxiv.org/html/2206.06544)
- en: \jyear
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \jyear
- en: '2022'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: '2022'
- en: '[1]\fnmZihan \surYang'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]\fnm子涵 \sur杨'
- en: '[1]\orgdivFaculty of Engineering and Information Technology, \orgnameThe University
    of Melbourne, \orgaddress\street700 Swanston Street, \cityMelbourne, \postcode3010,
    \stateVictoria, \countryAustralia'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[1]\orgdiv工程与信息技术学院, \orgname墨尔本大学, \orgaddress\street700 Swanston Street,
    \city墨尔本, \postcode3010, \state维多利亚, \country澳大利亚'
- en: A Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习图像分类任务的自动数据增强算法综述
- en: '[zihany1@student.unimelb.edu.au](mailto:zihany1@student.unimelb.edu.au)   
    \fnmRichard O. \surSinnott [rsinnott@unimelb.edu.au](mailto:rsinnott@unimelb.edu.au)
       \fnmJames \surBailey [baileyj@unimelb.edu.au](mailto:baileyj@unimelb.edu.au)
       \fnmQiuhong \surKe [qiuhong.ke@unimelb.edu.au](mailto:qiuhong.ke@unimelb.edu.au)
    *'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[zihany1@student.unimelb.edu.au](mailto:zihany1@student.unimelb.edu.au)   
    \fnm理查德·O. \sur辛诺特 [rsinnott@unimelb.edu.au](mailto:rsinnott@unimelb.edu.au)   
    \fnm詹姆斯 \sur贝利 [baileyj@unimelb.edu.au](mailto:baileyj@unimelb.edu.au)    \fnm秋红
    \sur柯 [qiuhong.ke@unimelb.edu.au](mailto:qiuhong.ke@unimelb.edu.au) *'
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: 'In recent years, one of the most popular techniques in the computer vision
    community has been the deep learning technique. As a data-driven technique, deep
    model requires enormous amounts of accurately labelled training data, which is
    often inaccessible in many real-world applications. A data-space solution is Data
    Augmentation (DA), that can artificially generate new images out of original samples.
    Image augmentation strategies can vary by dataset, as different data types might
    require different augmentations to facilitate model training. However, the design
    of DA policies has been largely decided by the human experts with domain knowledge,
    which is considered to be highly subjective and error-prone. To mitigate such
    problem, a novel direction is to automatically learn the image augmentation policies
    from the given dataset using Automated Data Augmentation (AutoDA) techniques.
    The goal of AutoDA models is to find the optimal DA policies that can maximize
    the model performance gains. This survey discusses the underlying reasons of the
    emergence of AutoDA technology from the perspective of image classification. We
    identify three key components of a standard AutoDA model: a search space, a search
    algorithm and an evaluation function. Based on their architecture, we provide
    a systematic taxonomy of existing image AutoDA approaches. This paper presents
    the major works in AutoDA field, discussing their pros and cons, and proposing
    several potential directions for future improvements.'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，计算机视觉领域最受欢迎的技术之一是深度学习技术。作为一种数据驱动的技术，深度模型需要大量准确标记的训练数据，而这些数据在许多实际应用中往往无法获得。数据空间解决方案之一是数据增强（DA），它可以通过原始样本人工生成新的图像。图像增强策略因数据集而异，不同的数据类型可能需要不同的增强方法以促进模型训练。然而，DA策略的设计在很大程度上由具备领域知识的人类专家决定，这被认为是高度主观且容易出错的。为了解决这一问题，一种新兴的方向是使用自动化数据增强（AutoDA）技术从给定的数据集中自动学习图像增强策略。AutoDA模型的目标是找到能够最大化模型性能提升的最佳DA策略。本综述从图像分类的角度讨论了AutoDA技术出现的根本原因。我们确定了标准AutoDA模型的三个关键组件：搜索空间、搜索算法和评估函数。基于其架构，我们提供了现有图像AutoDA方法的系统分类。本论文介绍了AutoDA领域的主要工作，讨论了它们的优缺点，并提出了若干潜在的未来改进方向。
- en: 'keywords:'
  id: totrans-14
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Automated Data Augmentation, Deep Learning, Image Classification, Big Data
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 自动数据增强，深度学习，图像分类，大数据
- en: 1 Introduction
  id: totrans-16
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Promoted by recent advances in neural network architectures, deep learning has
    made great progress in Computer Vision (CV) [krizhevsky2012imagenet](#bib.bib1)
    ; [szegedy2015going](#bib.bib2) ; [simonyan2014very](#bib.bib3) ; [he2016deep](#bib.bib4)
    . In particular, deep learning models have been successfully applied to image
    classification tasks in diverse areas from medical imaging [esteva2017dermatologist](#bib.bib5)
    ; [shin2016deep](#bib.bib6) to agriculture [zheng2019cropdeep](#bib.bib7) ; [kamilaris2018deep](#bib.bib8)
    . However, to achieve enhanced performance, deep learning, as a data-driven technology,
    places significant demands on both the quantity and quality of data for model
    training and testing. Effectively training a supervised model highly relies on
    enormous amounts of annotated data, which is often challenging for most practical
    applications [shijie2017research](#bib.bib9) .
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络架构的最新进展的推动下，深度学习在计算机视觉（Computer Vision，CV）领域取得了重大进展[krizhevsky2012imagenet](#bib.bib1)；[szegedy2015going](#bib.bib2)；[simonyan2014very](#bib.bib3)；[he2016deep](#bib.bib4)。特别是，深度学习模型已成功应用于从医学成像[esteva2017dermatologist](#bib.bib5)；[shin2016deep](#bib.bib6)到农业[zheng2019cropdeep](#bib.bib7)；[kamilaris2018deep](#bib.bib8)等多个领域的图像分类任务。然而，为了实现更好的性能，深度学习作为一种数据驱动技术，对数据的数量和质量提出了较高要求。有效训练一个监督模型高度依赖大量标注数据，这对大多数实际应用来说通常是具有挑战性的[shijie2017research](#bib.bib9)。
- en: To address the issue of data insufficiency, Data Augmentation (DA) is widely
    utilized. In general, data augmentation refers to the process of artificially
    generating data samples to increase the size of training data [lemley2017smart](#bib.bib10)
    . In the imaging domain, this is usually done by applying image Transformation
    Functions (TFs), such as translation, rotation or flipping. For computer vision
    tasks, image DA has been utilised in nearly all supervised neural network architectures
    to increase data volume and variety, including traditional data-driven models
    [cirecsan2010deep](#bib.bib11) ; [dosovitskiy2015discriminative](#bib.bib12) ;
    [graham2014fractional](#bib.bib13) ; [sajjadi2016regularization](#bib.bib14) ,
    and few/zero-shot learning [rios2018few](#bib.bib15) . Besides supervised approaches,
    DA techniques are also extensively applied in the field of unsupervised learning.
    For example, contrastive self-supervised learning relies on image transformations
    to incorporate data invariance in the representation space across various augmentations
    [bachman2019learning](#bib.bib16) .
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决数据不足的问题，数据增强（Data Augmentation，DA）被广泛应用。一般来说，数据增强指的是通过人工生成数据样本来增加训练数据的规模[lemley2017smart](#bib.bib10)。在成像领域，这通常通过应用图像变换函数（Transformation
    Functions，TFs），如平移、旋转或翻转来实现。对于计算机视觉任务，图像增强几乎在所有的监督神经网络架构中得到应用，以增加数据的量和多样性，包括传统的数据驱动模型[cirecsan2010deep](#bib.bib11)；[dosovitskiy2015discriminative](#bib.bib12)；[graham2014fractional](#bib.bib13)；[sajjadi2016regularization](#bib.bib14)，以及少样本/零样本学习[rios2018few](#bib.bib15)。除了监督学习方法，DA
    技术也广泛应用于无监督学习领域。例如，对比自监督学习依赖于图像变换，在不同的增强方式下在表示空间中引入数据不变性[bachman2019learning](#bib.bib16)。
- en: In the context of image augmentation, a DA policy refers to a set of image operations,
    which are used to transform the image data. When applying image DA, choosing a
    carefully designed augmentation scheme (i.e. DA policy) is necessary to improve
    the effectiveness of DA and hence the associated network training [krizhevsky2012imagenet](#bib.bib1)
    ; [paschali2019data](#bib.bib17) . For instance, data augmented by random image
    operations can be redundant. But overly aggressive TFs might corrupt the original
    semantics, and introduce potential biases into the training dataset [graham2014fractional](#bib.bib13)
    . Therefore, different datasets or domains may require different types of augmentations.
    Specifically, when standard supervised approaches are applied, classification
    tasks with limited data may require label-preserving augmentations to provide
    direct semantic supervision. However, for few/zero-shot learning models, more
    emphasis is placed on increasing data diversity in order to generate an enriched
    training set [wang2020generalizing](#bib.bib18) , which might promote more aggressive
    augmentation TFs.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在图像增强的背景下，DA 策略指的是一组图像操作，用于变换图像数据。在应用图像 DA 时，选择一个精心设计的增强方案（即 DA 策略）是必要的，以提高
    DA 的效果，从而提升相关网络训练的效果 [krizhevsky2012imagenet](#bib.bib1) ; [paschali2019data](#bib.bib17)
    。例如，由随机图像操作增强的数据可能会冗余。但过于激进的 TF 可能会破坏原始语义，并向训练数据集引入潜在偏差 [graham2014fractional](#bib.bib13)
    。因此，不同的数据集或领域可能需要不同类型的增强。具体来说，当应用标准的监督方法时，分类任务中的有限数据可能需要保持标签的增强，以提供直接的语义监督。然而，对于少样本/零样本学习模型，更加注重提高数据多样性，以生成更丰富的训练集
    [wang2020generalizing](#bib.bib18) ，这可能促进更激进的增强 TF。
- en: In spite of the ubiquity and importance of DA techniques, there is little selection
    strategy in DA policy design when given certain datasets. Unlike other machine
    learning topics that have been thoroughly explored, less attention has been put
    into finding effective DA policies to benefit particular dataset, and hence improve
    the model accuracy. Instead, DA policies are often intuitively decided based on
    past experience or limited trials [dao2019kernel](#bib.bib19) . Decisions on augmentation
    strategies are still made by human experts, based on prior knowledge. For example,
    the standard augmentation policy on ImageNet data was proposed in 2012 [krizhevsky2012imagenet](#bib.bib1)
    . This is still widely used in most contemporary networks without much modification
    [cubuk2019autoaugment](#bib.bib20) . Furthermore, criteria for selecting good
    augmentation methods on different datasets may greatly vary due to the nature
    of given tasks. The traditional trial-and-error approach based on training loss
    or accuracy can give rise to extensive, redundant data collections, wasting computational
    efforts and resources.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管 DA 技术无处不在且重要，但在给定特定数据集时，DA 策略设计中的选择策略仍然很少。与已经被彻底探索的其他机器学习主题不同，寻找有效的 DA 策略以便于特定数据集并提高模型准确性关注较少。相反，DA
    策略通常是基于过去的经验或有限的试验直观决定的 [dao2019kernel](#bib.bib19) 。关于增强策略的决策仍由人类专家基于先前知识做出。例如，ImageNet
    数据上的标准增强策略是在 2012 年提出的 [krizhevsky2012imagenet](#bib.bib1) 。这一策略在大多数现代网络中仍被广泛使用，几乎没有修改
    [cubuk2019autoaugment](#bib.bib20) 。此外，由于给定任务的性质，不同数据集上选择好的增强方法的标准可能大相径庭。基于训练损失或准确率的传统试错方法可能会产生大量冗余数据，浪费计算资源和努力。
- en: Motivated by progress in Automated Machine Learning (AutoML), there has been
    a rising interest in automatically searching effective augmentation policies from
    training data [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ;
    [hataya2020faster](#bib.bib22) ; [ho2019population](#bib.bib23) . Such technique
    are often referred to as Automated Data Augmentation (AutoDA). Recent research
    has found that instead of manually design the DA schemes, directly learning a
    DA strategy from the target dataset has the potential to significantly improve
    model performance [lemley2017smart](#bib.bib10) ; [tran2017bayesian](#bib.bib24)
    ; [devries2017dataset](#bib.bib25) ; [zoph2020learning](#bib.bib26) . Specifically,
    the DA policy that can yield the most performance gain on classification model
    is regarded as the optimal augmentation policy for a given dataset. Among various
    contemporary works, AutoAugment (AA) stands out as the first AutoDA model, achieving
    state-of-the-art results on several popular image classification datasets, including
    CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) , ImageNet [deng2009imagenet](#bib.bib28)
    and SVHN [netzer2011reading](#bib.bib29) . More importantly, AA provides essential
    theoretical foundation for later works that support automated augmentation [lim2019fast](#bib.bib21)
    ; [ho2019population](#bib.bib23) ; [hataya2020faster](#bib.bib22) ; [tian2020improving](#bib.bib30)
    ; [cubuk2020randaugment](#bib.bib31) .
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 受到自动化机器学习（AutoML）进展的激励，自动从训练数据中搜索有效的增强策略的兴趣不断上升 [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ; [hataya2020faster](#bib.bib22) ; [ho2019population](#bib.bib23)
    。这种技术通常被称为自动化数据增强（AutoDA）。最近的研究发现，与其手动设计数据增强（DA）方案，不如直接从目标数据集中学习DA策略，这有可能显著提升模型性能
    [lemley2017smart](#bib.bib10) ; [tran2017bayesian](#bib.bib24) ; [devries2017dataset](#bib.bib25)
    ; [zoph2020learning](#bib.bib26) 。具体而言，能够在分类模型上带来最大性能提升的DA策略被认为是给定数据集的最佳增强策略。在各种现代工作中，AutoAugment
    (AA) 脱颖而出，成为第一个AutoDA模型，在多个流行的图像分类数据集上取得了最先进的结果，包括CIFAR-10/100 [krizhevsky2009learning](#bib.bib27)
    、ImageNet [deng2009imagenet](#bib.bib28) 和SVHN [netzer2011reading](#bib.bib29)
    。更重要的是，AA为后续支持自动化增强的工作提供了重要的理论基础 [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    ; [hataya2020faster](#bib.bib22) ; [tian2020improving](#bib.bib30) ; [cubuk2020randaugment](#bib.bib31)
    。
- en: The progress of automating DA policy search can potentially change the existing
    process of model training. AutoDA model can automatically select the most effective
    combination of augmentation transformations to form the final DA policy. Once
    the optimal augmentation policy is found, the training set augmented by the learned
    policy can dramatically boost the model performance without extra input. Furthermore,
    AutoDA methods can be designed to be directly applied on the datasets of interest.
    The optimal DA policy learned from the data is regarded as the best augmentation
    formula for the target task, and hence it should guarantee the best model performance.
    Another desirable aspect of AutoDA techniques is their transferability. According
    to the findings in [cubuk2019autoaugment](#bib.bib20) , learned DA policies can
    also be applied on other similar datasets with promising results.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 自动化DA策略搜索的进展可能会改变现有的模型训练过程。AutoDA模型可以自动选择最有效的增强变换组合以形成最终的DA策略。一旦找到最佳的增强策略，利用所学策略增强的训练集可以在无需额外输入的情况下显著提升模型性能。此外，AutoDA方法可以设计为直接应用于感兴趣的数据集。从数据中学习到的最佳DA策略被视为目标任务的最佳增强公式，因此它应当保证最佳的模型性能。AutoDA技术的另一个可取之处是其可迁移性。根据
    [cubuk2019autoaugment](#bib.bib20) 的发现，学习到的DA策略也可以应用于其他类似数据集，并取得令人满意的结果。
- en: Although considerable progress has been made for DA policy search, there is
    still a lack of comprehensive survey that can systematically summarize the diverse
    methods. To the best of our knowledge, no one has conducted a qualitative comparison
    of existing AutoDA methods or provided a systematic evaluation of their advantages
    and disadvantages. To fill this gap, this paper aims to identify the current state
    of research in the field of Automated Data Augmentation (AutoDA), especially for
    image classification tasks.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在DA策略搜索方面取得了相当大的进展，但仍缺乏全面的调查来系统总结各种方法。据我们所知，尚无对现有AutoDA方法进行定性比较或提供系统评估其优缺点的研究。为填补这一空白，本文旨在识别自动化数据增强（AutoDA）领域的研究现状，尤其是针对图像分类任务。
- en: In this paper, we mainly review contemporary AutoDA works in imaging domain.
    We provide a systematic analysis, identifying three key components of standard
    AutoDA techniques, i.e. search space, search algorithm and evaluation function.
    Based on the different choices on search algorithms in reviewed works, we then
    propose a two-layer taxonomy of all AutoDA approaches. We also evaluate AutoDA
    approaches in terms of the efficiency of search algorithm, as well as the final
    performance of trained classification model. Through comparative analysis, we
    identify major contributions and limitations of these methods. Lastly, we summarise
    several main challenges and propose potential future directions in AutoDA field.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 本文主要回顾了成像领域的当代AutoDA工作。我们提供了系统的分析，识别了标准AutoDA技术的三个关键组成部分，即搜索空间、搜索算法和评估函数。基于审查工作中对搜索算法的不同选择，我们提出了所有AutoDA方法的两层分类法。我们还评估了AutoDA方法在搜索算法效率以及训练分类模型的最终性能方面。通过比较分析，我们识别了这些方法的主要贡献和局限性。最后，我们总结了几个主要挑战，并提出了AutoDA领域的潜在未来方向。
- en: 'Our main contributions can be summarized as follows:'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的主要贡献可以总结如下：
- en: '[1.]'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1.]'
- en: '1.'
  id: totrans-27
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: background on image data augmentation, including traditional approaches and
    Automated Data Augmentation (AutoDA) models (Section [2](#S2 "2 Background ‣ A
    Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks"));
  id: totrans-28
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像数据增强的背景，包括传统方法和自动数据增强（AutoDA）模型（第[2](#S2 "2 Background ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")节）；
- en: '2.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: introduction of three key components within standard AutoDA models, along with
    evaluation metrics and benchmarks used in most works (Section [3](#S3 "3 Automated
    Data Augmentation Techniques ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks"));
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 标准AutoDA模型中的三个关键组成部分的介绍，以及大多数工作中使用的评估指标和基准（第[3](#S3 "3 Automated Data Augmentation
    Techniques ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks")节）
- en: '3.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: a hierarchical taxonomy of the mainstream AutoDA algorithms for image classification
    tasks from the perspective of hyper-parameter optimization (Sections [4](#S4 "4
    Taxonomy of Image AutoDA Methods ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks"));
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从超参数优化的角度对主流AutoDA算法进行的层级分类（第[4](#S4 "4 Taxonomy of Image AutoDA Methods ‣ A
    Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks")节）；
- en: '4.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: thorough review of each AutoDA method in the taxonomy, detailing the search
    algorithm applied (Section [5](#S5 "5 Two-stage Approaches ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")
    and Section [6](#S6 "6 One-stage Approaches ‣ A Survey of Automated Data Augmentation
    Algorithms for Deep Learning-based Image Classification Tasks"));
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对分类法中的每种AutoDA方法进行了全面审查，详细描述了应用的搜索算法（第[5](#S5 "5 Two-stage Approaches ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks)和第[6](#S6 "6 One-stage Approaches ‣ A Survey of Automated Data Augmentation
    Algorithms for Deep Learning-based Image Classification Tasks")节）；
- en: '5.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: discussion about the current state of AutoDA technique, as well as the existing
    challenges and potential opportunities in future (Section [7](#S7 "7 Discussion
    ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks")).
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 关于当前AutoDA技术的状态讨论，以及未来存在的挑战和潜在机会（第[7](#S7 "7 Discussion ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")节）。
- en: 2 Background
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 背景
- en: This section introduces background information about data augmentation in the
    computer vision field with focus on image classification tasks. We first provide
    a general overview of how DA technique developed and been applied to computer
    vision tasks. Then we briefly describe several traditional image processing operations
    that are involved in most AutoDA models. Finally, we discuss the recent advances
    in AutoDA techniques and how such techniques relate to Automated Machine Learning
    (AutoML).
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了计算机视觉领域数据增强的背景信息，重点是图像分类任务。我们首先提供了数据增强技术的发展和应用于计算机视觉任务的一般概述。然后简要描述了大多数AutoDA模型涉及的几种传统图像处理操作。最后，我们讨论了AutoDA技术的最新进展以及这些技术与自动化机器学习（AutoML）的关系。
- en: 2.1 Historical Overview of Image Data Augmentation
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 图像数据增强的历史概述
- en: The early application of image augmentation can be traced back to LeNet-5 [lecun1998gradient](#bib.bib32)
    , where a Data Augmentation (DA) technique was applied by distorting images for
    recognizing handwritten and machine-printed characters. This work was one of the
    earliest pre-trained Convolutional Neural Networks (CNNs) that used DA for image
    classification tasks. Generally, DA can be regarded as an oversampling method.
    The objective of oversampling is to mitigate the negative influence of limited
    data or class imbalances by increasing data samples. A naive approach for oversampling
    is random oversampling, which randomly duplicates data points in minority classes
    until a desired data amount or data distribution is achieved. However, the duplicate
    images created by this technique can result in model overfitting towards the minority
    class. This problem becomes even more notable when deep learning technique is
    used. To add more variety to generated samples, DA via image transformations has
    emerged.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 早期图像增强技术的应用可以追溯到 LeNet-5 [lecun1998gradient](#bib.bib32)，在这里使用了一种数据增强（DA）技术，通过扭曲图像来识别手写和机器打印字符。这项工作是最早使用
    DA 进行图像分类任务的预训练卷积神经网络（CNN）之一。通常，DA 可以被视为一种过采样方法。过采样的目标是通过增加数据样本来减轻有限数据或类别不平衡的负面影响。一种简单的过采样方法是随机过采样，它会随机复制少数类中的数据点，直到达到所需的数据量或数据分布。然而，通过这种技术创建的重复图像可能导致模型过度拟合到少数类。当使用深度学习技术时，这个问题变得更加显著。为了给生成的样本增加更多的变化，通过图像变换的数据增强技术应运而生。
- en: The most early famous use case of image DA was AlexNet model [krizhevsky2012imagenet](#bib.bib1)
    . AlexNet significantly improved classification results on ImageNet data [deng2009imagenet](#bib.bib28)
    through the use of a revolutionary CNN architecture. In their work, image augmentation
    was used to artificially expand the dataset. Multiple image operations were applied
    to the original training set, including random cropping, horizontal flipping and
    colour adjustment in RGB space. These transformation functions helped mitigate
    overfitting problems during model training. According to the experimental results
    in [krizhevsky2012imagenet](#bib.bib1) , image DA reduced the final error rate
    by approximately $1\%$. Since then, image augmentation has been regarded as a
    necessary pre-processing procedure before training complex CNNs, from VGG [simonyan2014very](#bib.bib3)
    to ResNet [he2016deep](#bib.bib4) and Inception [szegedy2016rethinking](#bib.bib33)
    .
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图像数据增强最早的著名案例是 AlexNet 模型 [krizhevsky2012imagenet](#bib.bib1)。AlexNet 通过使用革命性的
    CNN 架构显著改善了在 ImageNet 数据上的分类结果 [deng2009imagenet](#bib.bib28)。在他们的工作中，使用了图像增强来人为扩展数据集。多种图像操作被应用于原始训练集，包括随机裁剪、水平翻转和在
    RGB 空间中的颜色调整。这些转换函数有助于减轻模型训练中的过拟合问题。根据 [krizhevsky2012imagenet](#bib.bib1) 中的实验结果，图像数据增强将最终的错误率减少了约
    $1\%$。从那时起，图像增强被视为在训练复杂的 CNNs（从 VGG [simonyan2014very](#bib.bib3) 到 ResNet [he2016deep](#bib.bib4)
    和 Inception [szegedy2016rethinking](#bib.bib33) ）之前必要的预处理程序。
- en: Image augmentation is not limited to the basic image processing. Following the
    proposal of Generative Adversarial Network (GAN) in [goodfellow2014generative](#bib.bib34)
    , related works flourished in the following decade. Among them, the most influential
    technique was Neural Architecture Search (NAS) [zoph2016neural](#bib.bib35) .
    NAS is a type of AutoML technique, which is the process of searching for model
    architectures through automation. The advancement of NAS greatly promoted the
    development of DA technology in the imaging field. Applying concepts and techniques
    from NAS and AutoML has gained increasing interest in the CV community. Recent
    progress include Neural Augmentation [perez2017effectiveness](#bib.bib36) , which
    tests the effectiveness of GANs in image augmentation; Smart Augmentation [lemley2017smart](#bib.bib10)
    , which generates synthetic image data using neural networks; and AA [cubuk2019autoaugment](#bib.bib20)
    , which is aimed at the automation of image transformation selection for DA. The
    latter work forms the basis for AutoDA and is the focus of this survey.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强不仅限于基本的图像处理。在 [goodfellow2014generative](#bib.bib34) 提出生成对抗网络（GAN）后，相关工作在接下来的十年中蓬勃发展。其中，最具影响力的技术是神经架构搜索（NAS）
    [zoph2016neural](#bib.bib35)。NAS是一种AutoML技术，旨在通过自动化搜索模型架构。NAS的进步极大推动了图像领域DA技术的发展。从NAS和AutoML中获得的概念和技术在计算机视觉（CV）社区中获得了越来越多的关注。近期进展包括神经增强
    [perez2017effectiveness](#bib.bib36)，测试GAN在图像增强中的有效性；智能增强 [lemley2017smart](#bib.bib10)，使用神经网络生成合成图像数据；以及AA
    [cubuk2019autoaugment](#bib.bib20)，旨在自动化图像变换选择以用于DA。这项工作为AutoDA奠定了基础，也是本综述的重点。
- en: Most of the augmentation methods mentioned before were designed for image classification.
    The ultimate goal of image DA in classification tasks is to improve the predication
    accuracy of discriminative models. However, the same technique is applicable for
    other computer vision tasks, for example Object Detection (OD), where image augmentation
    can be combined with advanced deep neural networks including YOLO [redmon2016you](#bib.bib37)
    and R-CNN series [girshick2014rich](#bib.bib38) ; [girshick2015fast](#bib.bib39)
    ; [ren2015faster](#bib.bib40) . Semantic segmentation task [long2015fully](#bib.bib41)
    can also benefit from DA before training complex networks such as U-Net [ronneberger2015u](#bib.bib42)
    . In this study, we particularly focus on the application of Automated DA (AutoDA)
    for image classification tasks, as there exists more published datasets in this
    domain that allow to conduct a fair evaluation. For some AutoDA methods, we also
    discuss the possibilities of applying them in object detection tasks if there
    are experimental results available.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 之前提到的大多数增强方法是为图像分类设计的。图像DA在分类任务中的终极目标是提高判别模型的预测准确性。然而，相同的技术也适用于其他计算机视觉任务，例如目标检测（OD），在这种情况下，图像增强可以与包括YOLO
    [redmon2016you](#bib.bib37) 和R-CNN系列 [girshick2014rich](#bib.bib38) ; [girshick2015fast](#bib.bib39)
    ; [ren2015faster](#bib.bib40) 等先进的深度神经网络相结合。语义分割任务 [long2015fully](#bib.bib41)
    也可以从DA中受益，在训练复杂网络如U-Net [ronneberger2015u](#bib.bib42) 之前。在这项研究中，我们特别关注自动化DA（AutoDA）在图像分类任务中的应用，因为这个领域存在更多已发布的数据集，允许进行公平评估。对于一些AutoDA方法，我们还讨论了如果有实验结果可用，将其应用于目标检测任务的可能性。
- en: 2.2 Traditional Image Augmentation Techniques
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 传统图像增强技术
- en: Image augmentation aims to enhance both the quantity and quality of datasets
    so that neural networks can be better trained [shorten2019survey](#bib.bib43)
    . Usually, DA does this in two ways, either through traditional image operations
    or based on deep learning technology. Traditional augmentation often emphasizes
    on preserving the image’s original label and transforms existing images into a
    new form [shorten2019survey](#bib.bib43) . This method can be achieved through
    various image processing approaches, including but not limited to geometric transformations,
    adjustment in colour space or even combinations of them.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图像增强旨在提高数据集的数量和质量，以便更好地训练神经网络 [shorten2019survey](#bib.bib43)。通常，数据增强通过两种方式实现：一种是传统图像操作，另一种是基于深度学习技术。传统增强通常强调保留图像的原始标签，并将现有图像转化为新的形式
    [shorten2019survey](#bib.bib43)。这种方法可以通过各种图像处理方法实现，包括但不限于几何变换、色彩空间调整或它们的组合。
- en: Another augmentation technique based on deep learning attempts to generate synthetic
    images as the training set. Major techniques involve Mixup augmentation [zhang2017mixup](#bib.bib44)
    , GANs and transformations in feature space [devries2017dataset](#bib.bib25) .
    Due to the complexity of deep learning DA, only the basic image processing operations
    are considered in recent automated DA methods. Hence, we focus on the basic image
    transformations that can be easily parameterized. The rest of this section briefly
    introduces several basic image processing functions that are usually considered
    in AutoDA models, including geometric transformations, flipping, rotation, cropping,
    colour adjustment and kernel filters. Another two augmentation algorithms are
    also covered due to their presence in AutoAugment work [cubuk2019autoaugment](#bib.bib20)
    , namely Cutout [devries2017improved](#bib.bib45) and SamplePairing [inoue2018data](#bib.bib46)
    .
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种基于深度学习的增强技术试图生成合成图像作为训练集。主要技术包括 Mixup 增强 [zhang2017mixup](#bib.bib44)、生成对抗网络（GANs）以及特征空间中的变换
    [devries2017dataset](#bib.bib25)。由于深度学习数据增强的复杂性，最近的自动数据增强方法仅考虑了基本的图像处理操作。因此，我们专注于可以轻松参数化的基本图像变换。本节其余部分简要介绍了通常在自动数据增强模型中考虑的几种基本图像处理功能，包括几何变换、翻转、旋转、裁剪、颜色调整和核过滤器。此外，还介绍了另外两种增强算法，因为它们出现在
    AutoAugment 工作中 [cubuk2019autoaugment](#bib.bib20)，即 Cutout [devries2017improved](#bib.bib45)
    和 SamplePairing [inoue2018data](#bib.bib46)。
- en: 2.2.1 Geometric Transformations
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1 几何变换
- en: The simplest place to start image augmentation is using geometric transformation
    functions, such as image translation or scaling. These operations are easy to
    implement and can also be combined with other transformations to form more advanced
    DA algorithms. One important thing when applying such operations is whether they
    can preserve the original image label after the transformation [bagherinezhad2018label](#bib.bib47)
    . From the perspective of image augmentation, the ability to keep label consistency
    can also be called safety feature of transformation functions [shorten2019survey](#bib.bib43)
    . In other words, transformations that may risk corrupting annotation information
    are considered to be unsafe. In general, geometric transformations tend to preserve
    the labels as they only change the position of key features. However, depending
    on the magnitude of the transformation function, the application of the chosen
    operation might not always be safe. For example, translation of the $y$ axis with
    a high magnitude may end up completely shifting the object-of-interest outside
    of the visible area, therefore it fails to preserve the label of the post-processed
    image.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 开始图像增强的最简单方法是使用几何变换函数，如图像平移或缩放。这些操作易于实现，并且可以与其他变换结合形成更高级的数据增强算法。应用这些操作时，一个重要的方面是它们是否能在变换后保留原始图像标签
    [bagherinezhad2018label](#bib.bib47)。从图像增强的角度来看，保持标签一致性的能力也可以称为变换函数的安全特性 [shorten2019survey](#bib.bib43)。换句话说，可能会破坏注释信息的变换被认为是不安全的。一般而言，几何变换倾向于保留标签，因为它们只是改变了关键特征的位置。然而，取决于变换函数的大小，所选操作的应用可能并不总是安全的。例如，高幅度的
    $y$ 轴平移可能会将感兴趣的对象完全移出可见区域，因此无法保留后处理图像的标签。
- en: 2.2.2 Rotation
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2 旋转
- en: Rotating the image by a given angle is another common DA technique. It is a
    special type of geometric transformation, which also has the risk of removing
    meaningful semantic information from the visible area. Aggressive operations with
    a large rotation angle are usually unsafe, especially for text-related data, e.g.
    ”6” and ”9” in SVHN data [netzer2011reading](#bib.bib29) . However, according
    to [shorten2019survey](#bib.bib43) , slight rotation within the range of $1^{\circ}$
    to $30^{\circ}$ can be helpful for most image classification tasks.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 以给定角度旋转图像是另一种常见的数据增强技术。这是一种特殊的几何变换类型，也有可能会从可见区域中去除有意义的语义信息。对于具有较大旋转角度的激进操作，通常是不安全的，特别是对于与文本相关的数据，例如
    SVHN 数据中的 ”6” 和 ”9” [netzer2011reading](#bib.bib29)。然而，根据 [shorten2019survey](#bib.bib43)
    的研究，在 $1^{\circ}$ 到 $30^{\circ}$ 范围内的轻微旋转对大多数图像分类任务是有帮助的。
- en: 2.2.3 Flipping
  id: totrans-51
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3 翻转
- en: Flipping is different from rotation augmentation as it generates mirror images.
    Flipping can be done either horizontally or vertically, while the former is more
    commonly used in computer vision [shorten2019survey](#bib.bib43) . This is one
    of the simple yet most effective augmentation techniques on image data, especially
    for CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) and ImageNet [deng2009imagenet](#bib.bib28)
    . The safety feature of flipping largely depends on the type of input data. For
    normal classification or object detection tasks, flipping augmentation preserves
    the original label. But it can be unsafe for data involving digits or texts, such
    as SVHN data [netzer2011reading](#bib.bib29) .
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 翻转不同于旋转增强，因为它生成的是镜像图像。翻转可以是水平或垂直的，前者在计算机视觉中更为常用 [shorten2019survey](#bib.bib43)。这是一种简单但非常有效的图像数据增强技术，尤其适用于
    CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) 和 ImageNet [deng2009imagenet](#bib.bib28)。翻转的安全性主要取决于输入数据的类型。对于普通分类或目标检测任务，翻转增强能保持原始标签。但是，对于涉及数字或文本的数据，如
    SVHN 数据 [netzer2011reading](#bib.bib29)，翻转可能会不安全。
- en: 2.2.4 Cropping
  id: totrans-53
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4 裁剪
- en: Cropping is not only a basic DA method, but also an important pre-processing
    step before training when there are various sizes of image samples in the input
    data. Before being fed into the model, training data needs to be cropped into
    a unified $x\times y$ dimension for later matrix calculations. As an augmentation
    technique, cropping has a similar effect to geometric translation. Both augmentation
    methods remove part of the original image patch, while image translation keeps
    the same spatial resolution of the input and output image. In contrast, cropping
    will reduce the size of processed image. As described previously, cropping can
    be a safe/unsafe depends on its associated magnitude value. Aggressive operations
    might crop the distinguishable features, affecting label consistency, whereas
    a reasonable magnitude value helps to improve the quality of the training data.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 裁剪不仅是基本的数据增强方法，也是当输入数据中的图像样本大小不一时，训练前的重要预处理步骤。在输入模型之前，训练数据需要裁剪为统一的 $x\times
    y$ 尺寸，以便进行后续的矩阵计算。作为一种增强技术，裁剪与几何平移有类似的效果。这两种增强方法都移除了原始图像的一部分，而图像平移保持输入和输出图像的相同空间分辨率。相比之下，裁剪会减少处理后图像的大小。如前所述，裁剪的安全性可能会因其相关的幅度值而有所不同。激进的操作可能会裁剪掉可区分的特征，影响标签一致性，而合理的幅度值有助于提高训练数据的质量。
- en: 2.2.5 Colour Adjustment
  id: totrans-55
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.5 色彩调整
- en: Adjusting values in colour space is another practical augmentation strategy
    that has been commonly adopted. Through the value jitters of single colour channels,
    it is possible to quickly obtain different colour representations of an image.
    These RGB values can also be manipulated through matrix operations to mimic different
    lighting conditions. Alternatively, self-defined rules on pixel values can be
    applied to implement transformations such as Solarize, Equalize, Posterize functions
    using in Python Image Library (PIL) [umesh2012image](#bib.bib48) . Different from
    previous DA transformations, colour adjustment preserves the original size and
    content of input images. However, it might discard some colour information and
    thus might raise safety issues. For example, if colour is a discrimitative feature
    of an object of interest, when manipulating the colour values, the distinctive
    colour of the object may be hard to observe and hence confuse the model. The magnitude
    of colour transformation is again the determining factor that affects its safety
    property.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在色彩空间中调整数值是另一种常见的实际增强策略。通过单色通道的值抖动，可以快速获得图像的不同色彩表现。这些 RGB 值也可以通过矩阵操作来模拟不同的光照条件。或者，可以应用自定义规则在像素值上实现转换，例如使用
    Python 图像库（PIL）中的 Solarize、Equalize、Posterize 函数 [umesh2012image](#bib.bib48)。与之前的数据增强变换不同，色彩调整保留了输入图像的原始大小和内容。然而，它可能会丢弃一些色彩信息，从而可能引发安全问题。例如，如果色彩是对象的区分特征，当操控色彩值时，对象的独特颜色可能难以观察，从而混淆模型。色彩变换的幅度再次是决定其安全性的重要因素。
- en: 2.2.6 Kernel Filters
  id: totrans-57
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.6 核滤镜
- en: Instead of directly changing pixel values in colour space, they can be manipulated
    via kernel filters. This is a widely used technique in computer vision field for
    image processing. A filter is usually a matrix of self-defined numbers, with much
    smaller size than the input image. Depending on the element values in the matrix,
    kernel filters can provide various functionalities. The most common kernel filters
    include blurring and sharpening. To apply the kernel filter on on input image,
    we treat it as a sliding window, and scroll it over the whole image to get the
    pixel values out of matrix multiplications as our final output. A Gaussian kernel
    can cause blurring effect on the filtered image, which can better prepare the
    model for low-quality images with limited resolution. In contrast, a sharpening
    filter emphasizes the details in the image, which can help the model gain more
    information about the key features.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 与直接改变颜色空间中的像素值不同，可以通过核滤波器进行操作。这是计算机视觉领域中广泛使用的图像处理技术。滤波器通常是一个自定义数字的矩阵，其尺寸远小于输入图像。根据矩阵中的元素值，核滤波器可以提供各种功能。最常见的核滤波器包括模糊和锐化。要将核滤波器应用于输入图像，我们将其视为一个滑动窗口，滚动它遍历整个图像，以通过矩阵乘法获得最终输出的像素值。高斯核可以对滤波后的图像产生模糊效果，这可以更好地为模型准备低质量、分辨率有限的图像。相反，锐化滤波器强调图像中的细节，这有助于模型获得更多关于关键特征的信息。
- en: 2.2.7 Cutout
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.7 Cutout
- en: Besides simple transformations, another interesting augmentation technique is
    Cutout [devries2017improved](#bib.bib45) . Cutout is inspired by the concept of
    dropout regularisation, performed on input data instead of embedded units within
    neural network [zhong2020random](#bib.bib49) . This algorithm is specifically
    designed for object occlusion problems. Occlusion happens when some parts of the
    object are vague or occluded (hidden) by other non-relevant objects, in which
    case, only partial observation of the object is possible. This is a common problem
    especially in real-world scenarios. Cutout augmentation combats this by randomly
    cropping a small patch out of the original image to simulate the occlusion cases.
    Training on such transformed data, models are forced to learn from the whole picture
    rather than just a section of it, which enhances its ability to distinguish object
    features. Another convenient feature of the Cutout algorithm is that it can be
    applied along with other image augmentation methods, such as geometric or colour
    transformation, to generate more diverse training data.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 除了简单的变换，另一个有趣的增强技术是 Cutout [devries2017improved](#bib.bib45)。Cutout 的灵感来源于 dropout
    正则化的概念，该方法是在输入数据上执行，而不是在神经网络中的嵌入单元上 [zhong2020random](#bib.bib49)。该算法专门为物体遮挡问题设计。当物体的某些部分模糊或被其他不相关的物体遮挡时，就会发生遮挡，此时只能对物体进行部分观察。这在现实世界中尤其常见。Cutout
    增强通过从原始图像中随机裁剪出一小块来模拟遮挡情况，从而应对这一问题。在这样的变换数据上进行训练，模型被迫从整体上学习，而不是仅仅从图像的某一部分学习，这增强了模型区分物体特征的能力。Cutout
    算法的另一个便捷特性是，它可以与其他图像增强方法（如几何变换或颜色变换）一起应用，以生成更多样化的训练数据。
- en: 2.2.8 SamplePairing
  id: totrans-61
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.8 SamplePairing
- en: SamplePairing [inoue2018data](#bib.bib46) is an example of a complex augmentation
    algorithm that combines several simple transformations. It creates a completely
    new image by randomly choosing two data samples from the training set and mixing
    them. In standard SamplePairing, such combination is done by calculating the average
    of pixel values in two samples. The label of the generated images follows the
    first image and ignores the annotation of the second sample in the input pair.
    One of the advantages of SamplePairing augmentation is that it can create up to
    $N^{2}$ new data points out of dataset of size $N$ via simple permutation. SamplePairing
    is straightforward augmentation method that generates synthetic data points out
    of the original data. The enhancement of data quantity and variety significantly
    improves model performance and avoids model overfitting problems. This technique
    is especially helpful for computer vision tasks with limited training data.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: SamplePairing [inoue2018data](#bib.bib46) 是一种复杂的增强算法示例，它结合了几种简单的变换。它通过从训练集中随机选择两个数据样本并将它们混合来创建一张全新的图像。在标准的
    SamplePairing 中，这种组合是通过计算两个样本中像素值的平均值来完成的。生成图像的标签遵循第一张图像，并忽略输入对中第二个样本的注释。SamplePairing
    增强的一个优点是它可以通过简单的排列从大小为 $N$ 的数据集中创建多达 $N^{2}$ 个新的数据点。SamplePairing 是一种直接的增强方法，可以生成源数据之外的合成数据点。数据数量和多样性的增加显著提升了模型性能，并避免了模型过拟合的问题。这种技术对于训练数据有限的计算机视觉任务特别有帮助。
- en: 2.3 Development of Automated Data Augmentation (AutoDA)
  id: totrans-63
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 自动化数据增强 (AutoDA) 的发展
- en: With various image augmentation operations available, the question is how to
    choose an effective DA policy from these transformations for CV tasks. A naive
    solution is to apply random augmentations, generating vast amounts of transformed
    data for training. However, without appropriate control on the type and magnitude
    of augmentation TFs, the augmented data points might be simple duplicates or even
    semantically corrupted, which can lead to performance loss. Furthermore, overly
    augmented data might require excessive computational resources during model training,
    causing efficiency issues. A systematic selection strategy for a DA policy is
    therefore needed. A DA policy refers to a composition of various image distortion
    functions, which can be applied to training data for data augmentation.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在各种图像增强操作可用的情况下，问题是如何从这些变换中选择一个有效的 DA 策略用于 CV 任务。一个简单的解决方案是应用随机增强，生成大量的变换数据用于训练。然而，如果没有对增强
    TF 的类型和幅度进行适当控制，增强的数据点可能只是简单的重复，甚至可能在语义上出现损坏，从而导致性能损失。此外，过度增强的数据可能在模型训练过程中需要过多的计算资源，导致效率问题。因此，需要一个系统化的选择策略来确定
    DA 策略。DA 策略是指各种图像失真函数的组合，可以应用于训练数据进行数据增强。
- en: Despite extensive research on DA transformations, the selection of a given augmentation
    policy usually relies on human experts. Especially in the context of CV tasks,
    the decision on which image operations to use is mainly made by machine learning
    engineers based on past experience or domain knowledge. Therefore, the optimal
    strength of a given DA policy is highly task-specific. For example, geometric
    and colour transformations are commonly used in standard classification datasets,
    including CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) and ImageNet [deng2009imagenet](#bib.bib28)
    . While resizing and elastic deformations are more popular on digit images such
    as MNIST [sato2015apac](#bib.bib50) ; [simard2003best](#bib.bib51) and SVHN [netzer2011reading](#bib.bib29)
    datasets. There is no universal agreement on augmentation strategies for all types
    of CV tasks. In most cases, DA policies need to be manually selected based on
    prior knowledge. However, human effort involved in deep learning is usually considered
    biased and error-prone. There is no theoretical evidence to support the optimal
    human-decided DA policies. It is infeasible to manually search for the optimal
    DA policy that can achieve the best model performance. Additionally, without the
    help of advanced ML technique, finding an effective DA policy must rely on empirical
    results from multiple experiments, which can be excessively time-consuming.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管对 DA 转换进行了广泛研究，选择给定的增强策略通常依赖于人工专家。特别是在计算机视觉（CV）任务的背景下，关于使用哪些图像操作的决策主要由机器学习工程师根据过去的经验或领域知识做出。因此，给定
    DA 策略的最优强度具有很强的任务特异性。例如，几何和颜色转换通常用于标准分类数据集，包括 CIFAR-10/100 [krizhevsky2009learning](#bib.bib27)
    和 ImageNet [deng2009imagenet](#bib.bib28) 。而调整大小和弹性形变则在数字图像如 MNIST [sato2015apac](#bib.bib50)
    ; [simard2003best](#bib.bib51) 和 SVHN [netzer2011reading](#bib.bib29) 数据集上更为流行。对于所有类型的
    CV 任务，没有统一的增强策略。在大多数情况下，DA 策略需要根据先验知识手动选择。然而，深度学习中的人工努力通常被认为存在偏见和易出错。没有理论证据支持最优的人为决定
    DA 策略。手动搜索能够实现最佳模型性能的最优 DA 策略是不现实的。此外，如果没有先进的机器学习技术的帮助，找到有效的 DA 策略必须依赖于多个实验的经验结果，这可能会耗费大量时间。
- en: To reduce the potential bias and accelerate the design process, there has been
    increasing interest in automating the selection of DA policies. This technique
    is known as Automated Data Augmentation (AutoDA). The development of AutoDA is
    motivated by the advancements in Neural Architecture Search (NAS) [zoph2016neural](#bib.bib35)
    , which automatically searches for the optimal architecture for deep neural networks
    instead of by manual approach. The majority of AutoDA techniques rely on different
    search algorithms to search for the most effective (optimal) augmentation policy
    for a given dataset. In the context of AutoDA, an optimal DA policy is the augmentation
    scheme that can yield the most performance gain and highest accuracy score.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少潜在的偏差并加快设计过程，人们越来越关注自动化选择数据增强（DA）策略。这种技术被称为自动化数据增强（AutoDA）。AutoDA 的发展受到神经架构搜索（NAS）[zoph2016neural](#bib.bib35)
    的推动，该技术可以自动搜索最优的深度神经网络架构，而不是依赖人工方法。大多数 AutoDA 技术依赖于不同的搜索算法，以寻找给定数据集的最有效（最优）增强策略。在
    AutoDA 的背景下，最优 DA 策略是能够带来最大性能提升和最高准确率的增强方案。
- en: The earliest AutoDA work can be traced back to Transformation Adversarial Networks
    for Data Augmentations (TANDA) [ratner2017learning](#bib.bib52) in 2017\. This
    was the first attempt to automatically construct and tune DA policies according
    to provided data. The parameterization in TANDA inspired the design of search
    space in AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) , and provided a
    standard problem formulation to the AutoDA field. AA used Reinforcement Learning
    (RL) to perform the augmentation search. During the search, augmentation policies
    were sampled via a Recurrent Neural Network (RNN) controller and then used for
    model training. Instead of directly searching on the target data, AA created a
    subset out of original training set as a proxy task. The evaluation of augmentation
    policies were also conducted on a simplified network instead of the final classification
    model. Unfortunately, searching in AA requires thousands of GPU hours to complete
    even under reduced setting.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 最早的AutoDA工作可以追溯到2017年的数据增强的变换对抗网络（TANDA）[ratner2017learning](#bib.bib52)。这是首次尝试根据提供的数据自动构建和调整DA策略。TANDA中的参数化激发了AutoAugment（AA）[cubuk2019autoaugment](#bib.bib20)中搜索空间的设计，并为AutoDA领域提供了标准问题的表述。AA使用强化学习（RL）进行增强搜索。在搜索过程中，增强策略通过递归神经网络（RNN）控制器进行采样，然后用于模型训练。AA不是直接在目标数据上进行搜索，而是从原始训练集中创建一个子集作为代理任务。增强策略的评估也在简化的网络上进行，而不是最终的分类模型。不幸的是，即使在减少设置下，AA的搜索也需要数千个GPU小时才能完成。
- en: With the establishment of augmentation search space, efficiency problems have
    become the focus of later AutoDA works. Fast AutoAugment (Fast AA) [lim2019fast](#bib.bib21)
    is one of the most popular improved versions of the original AA. Instead of RNN,
    Fast AA applies Bayesian optimization to sample the next augmentation policy to
    be evaluated, which greatly reduces the search cost. Additionally, Fast AA firstly
    uses density matching for policy evaluation, which completely eliminates the need
    for repeated training. Another approach to improve search efficiency is via parallel
    computation. Population Based Augmentation (PBA) [ho2019population](#bib.bib23)
    adopts Population Based Training to optimize the augmentation policy using several
    subsets of the target data simultaneously. The search goal in PBA is also slightly
    different than previous approaches. PBA aims to find a dynamic schedule during
    model training, rather than a static policy. Both Fast AA and PBA substantially
    reduce the complexity of the AA algorithm, and maintain comparable performance
    at the same time. However, there is still an expensive searching phase in these
    models especially when faced with large datasets or complicated models, which
    inevitably leads to poor efficiency.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 随着增强搜索空间的建立，效率问题已成为后续AutoDA工作的重点。快速AutoAugment（Fast AA）[lim2019fast](#bib.bib21)是原始AA最受欢迎的改进版本之一。Fast
    AA不再使用RNN，而是应用贝叶斯优化来采样下一个待评估的增强策略，从而大大降低了搜索成本。此外，Fast AA首次使用密度匹配进行策略评估，这完全消除了重复训练的需要。另一种提高搜索效率的方法是通过并行计算。基于人群的增强（PBA）[ho2019population](#bib.bib23)采用基于人群的训练来优化增强策略，同时使用目标数据的多个子集。PBA中的搜索目标与以前的方法也略有不同。PBA旨在找到模型训练中的动态调度，而不是静态策略。Fast
    AA和PBA都大大减少了AA算法的复杂性，同时保持了相当的性能。然而，在这些模型中，尤其是面对大数据集或复杂模型时，仍然存在昂贵的搜索阶段，这不可避免地导致了效率低下。
- en: To further enhance the scalability of AutoDA models, techniques such as gradient-based
    hyper-parameter optimization have been explored recently. AutoDA based on gradient
    is usually achieved by various gradient approximators to estimate the gradient
    of augmentation hyper-parameters with regard to model performance. This process
    ensures the hyper-parameters can be differentiated and hence optimized along with
    the model training. Adversarial AutoAugment (AAA) [zhang2019adversarial](#bib.bib53)
    and Online Hyper-parameter Learning AutoAugment (OHL-AA) [lin2019online](#bib.bib54)
    apply the REINFORCE gradient estimator [williams1992simple](#bib.bib55) to achieve
    gradient approximation. Other gradient estimators are also applicable in AutoDA.
    For example, DARTS [liu2018darts](#bib.bib56) is employed in Faster AutoAugment
    (Faster) [hataya2020faster](#bib.bib22) and Differentiable Automatic Data Augmentation
    (DADA) [li2020dada](#bib.bib57) . Using the same policy model as in Fast AA [lim2019fast](#bib.bib21)
    , OHL-AA optimizes augmentation policies in an online fashion during model training.
    There is no separate stage for searching in OHL-AA. Instead, it adopts a bi-level
    optimization framework, where the algorithm updates the weights of the classification
    model and hyper-parameters of augmentation policy at the same time. This scheme
    significantly reduces the search time. Similarly, there are two optimization objectives
    in AAA, one of which is the minimization of training loss, and the other is the
    minimization of adversarial loss [zhang2019adversarial](#bib.bib53) . Two objectives
    are optimized simultaneously in AAA, providing a much more computationally-affordable
    solution.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提升 AutoDA 模型的可扩展性，最近探索了如基于梯度的超参数优化等技术。基于梯度的 AutoDA 通常通过各种梯度近似器来估计增广超参数对模型性能的梯度。这个过程确保了超参数可以被区分，从而在模型训练过程中进行优化。对抗性
    AutoAugment (AAA) [zhang2019adversarial](#bib.bib53) 和在线超参数学习 AutoAugment (OHL-AA)
    [lin2019online](#bib.bib54) 采用 REINFORCE 梯度估计器 [williams1992simple](#bib.bib55)
    来实现梯度近似。其他梯度估计器在 AutoDA 中也适用。例如，DARTS [liu2018darts](#bib.bib56) 被应用于 Faster AutoAugment
    (Faster) [hataya2020faster](#bib.bib22) 和可微分自动数据增广 (DADA) [li2020dada](#bib.bib57)。使用与
    Fast AA [lim2019fast](#bib.bib21) 相同的策略模型，OHL-AA 在模型训练过程中以在线方式优化增广策略。OHL-AA 没有单独的搜索阶段，而是采用了双层优化框架，在这个框架中，算法同时更新分类模型的权重和增广策略的超参数。这种方案显著减少了搜索时间。同样，AAA
    中有两个优化目标，其中一个是最小化训练损失，另一个是最小化对抗性损失 [zhang2019adversarial](#bib.bib53)。在 AAA 中，这两个目标同时被优化，提供了一种计算上更为经济的解决方案。
- en: Even though gradient-based approaches are more efficient in comparison to vanilla
    AA, these methods are still based on an expensive policy search. The bi-level
    setting also increases the complexity of the model training stage. Recent advancements
    in AutoDA aim to further enhance the efficiency of augmentation design by excluding
    the need for search. Proposed in 2020, RandAugment (RA) [cubuk2020randaugment](#bib.bib31)
    reparameterizes the classical search space. It replaces the individual parameter
    for each transformation with two global variables. A simple grid search is performed
    in RA to optimize two hyper-parameters. The findings in RA not only suggest that
    the traditional search phase may not be necessary, but also indicate that the
    search using surrogate models could be sub-optimal. It was found that the effectiveness
    of the DA policy was relevant to the size of the model and training set, thus
    challenges all previous approaches based on proxy tasks. Another AutoDA model
    that does not rely on searching is UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58)
    . UA further simplifies the augmentation space through invariance theory. The
    authors hypothesize an approximate invariant augmentation space. Any augmentation
    policy sampled from that space could lead to similar model performances, thus
    completely removing the search phase. Despite the promising speed, the model performance
    is a bottleneck in these search-free methods. Neither approach is able to make
    significant progress on model accuracy when compared with previous approaches.
    To apply AutoDA techniques in practice, further research and experiments are required.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于梯度的方法相较于传统的 AA 更为高效，这些方法仍然依赖于昂贵的策略搜索。双层设置也增加了模型训练阶段的复杂性。近年来，AutoDA 的进展旨在通过排除搜索的需要来进一步提高增强设计的效率。2020
    年提出的 RandAugment (RA) [cubuk2020randaugment](#bib.bib31) 对经典的搜索空间进行了重新参数化。它用两个全局变量代替了每个变换的单独参数。在
    RA 中进行简单的网格搜索以优化两个超参数。RA 的发现不仅表明传统的搜索阶段可能不是必需的，还指出使用代理模型进行的搜索可能是次优的。研究发现，DA 策略的有效性与模型和训练集的大小相关，这挑战了所有基于代理任务的先前方法。另一个不依赖于搜索的
    AutoDA 模型是 UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58)。UA 通过不变性理论进一步简化了增强空间。作者假设了一个近似的不变增强空间。任何从该空间中抽样的增强策略都可能导致类似的模型性能，从而完全去除搜索阶段。尽管速度很有前景，但模型性能在这些无搜索方法中仍然是一个瓶颈。与之前的方法相比，这些方法都未能在模型准确性上取得显著进展。要在实践中应用
    AutoDA 技术，还需要进一步的研究和实验。
- en: 3 Automated Data Augmentation Techniques
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 自动化数据增强技术
- en: 'This section aims at introducing the basic concepts and terminologies of Automated
    Data Augmentation (AutoDA) techniques. In general, finding an optimal DA policy
    is formulated as a standard search problem in most works [cubuk2019autoaugment](#bib.bib20)
    ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21) ; [hataya2020faster](#bib.bib22)
    ; [lin2019online](#bib.bib54) ; [li2020dada](#bib.bib57) . A standard AutoDA model
    consists of three major components: a search space, a search algorithm and an
    evaluation function. In this section, the functionalities and relationships of
    three component are discussed. We also describe how to assess the proposed AutoDA
    models, including two different evaluations based on direct and indirect approaches.
    Lastly, we introduce several commonly used datasets and benchmarks for comparative
    analysis.'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在介绍自动化数据增强（AutoDA）技术的基本概念和术语。一般来说，在大多数工作中，寻找最佳 DA 策略被表述为一个标准的搜索问题 [cubuk2019autoaugment](#bib.bib20)
    ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21) ; [hataya2020faster](#bib.bib22)
    ; [lin2019online](#bib.bib54) ; [li2020dada](#bib.bib57)。一个标准的 AutoDA 模型由三个主要组成部分构成：搜索空间、搜索算法和评估函数。在本节中，我们将讨论这三个组件的功能和相互关系。我们还描述了如何评估提出的
    AutoDA 模型，包括基于直接和间接方法的两种不同评估方式。最后，我们介绍了几个常用的数据集和基准，用于比较分析。
- en: 3.1 Key Components
  id: totrans-73
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 关键组成部分
- en: 'For image classification tasks, the major objective of AutoDA models is to
    achieve the best classification accuracy using an optimal DA policy automatically
    learned from a given dataset. Inspired by the DA strategy modelling in Transformation
    Adversarial Networks for Data Augmentations (TANDA) [ratner2017learning](#bib.bib52)
    , AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) is considered to be the
    first work that attempted to automate the augmentation policy search. AA formulates
    the AutoDA task as a search problem, and provided basic parameterization for the
    search space. The parameterization in AA is largely adopted in later AutoDA works,
    and is regarded as the de facto standard [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    ; [wei2020circumventing](#bib.bib59) . Specifically, there are three key components
    within a standard AutoDA formulation:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 对于图像分类任务，AutoDA模型的主要目标是使用从给定数据集中自动学习的最佳DA策略来实现最佳分类准确性。受到用于数据增强（TANDA）的变换对抗网络中的DA策略建模的启发[ratner2017learning](#bib.bib52)，AutoAugment
    (AA) [cubuk2019autoaugment](#bib.bib20) 被认为是首个尝试自动化增强策略搜索的工作。AA将AutoDA任务表述为一个搜索问题，并为搜索空间提供了基本参数化。AA中的参数化在后来的AutoDA工作中被广泛采用，被视为事实上的标准[lim2019fast](#bib.bib21)；[ho2019population](#bib.bib23)；[wei2020circumventing](#bib.bib59)。具体来说，标准AutoDA表述中有三个关键组件：
- en: Definition 1  (Search Space).
  id: totrans-75
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义1（搜索空间）。
- en: is regarded as the domain of DA policies to be optimized where all candidate
    solutions via augmentation hyper-parameters are defined.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 被视为DA策略的优化领域，其中定义了通过增强超参数的所有候选解决方案。
- en: Definition 2  (Search Algorithm).
  id: totrans-77
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义2（搜索算法）。
- en: is used to retrieve augmentation policies from the search space and to sample
    the next search point based on a reward signal returned by an evaluation function.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 用于从搜索空间中检索增强策略，并根据评估函数返回的奖励信号来采样下一个搜索点。
- en: Definition 3  (Evaluation Function).
  id: totrans-79
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义3（评估函数）。
- en: is the procedure of assessing or ranking sampled DA policies by assigning reward
    values. This usually relies on the training of the classification model.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 是通过分配奖励值来评估或排名采样的DA策略的过程。这通常依赖于分类模型的训练。
- en: 3.1.1 Search Space
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 搜索空间
- en: 'The search space defines how DA policies are formed for subsequent searches.
    Specifically for image classification tasks, the augmentation policy refers to
    a composition of several image operations, which can be described by augmentation
    hyper-parameters. Generally, a complete augmentation policy consists of multiple
    sub-policies, each of which is used to augment one training batch. A sub-policy
    is composed of several basic image Transformation Functions (TFs). An augmentation
    policy is usually parameterized by two hyper-parameters: the application probability
    and the operation magnitude. The probability describes the probability of applying
    a certain transformation function on input images, while the magnitude determines
    the strength of the operation. Each TF within a DA policy is associated with a
    pair of probability and magnitude hyper-parameters. Depending on the choice of
    search or optimization algorithm, the formulation of the search space can vary
    greatly. For example, some works completely re-parameterize the search space to
    reduce the search complexity [cubuk2020randaugment](#bib.bib31) ; [lingchen2020uniformaugment](#bib.bib58)
    . However, the DA policy parameterization proposed in AA [cubuk2019autoaugment](#bib.bib20)
    has been widely used in later works with little or no modification.'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 搜索空间定义了如何形成用于后续搜索的DA策略。特别是对于图像分类任务，增强策略是指多个图像操作的组合，这可以通过增强超参数来描述。通常，一个完整的增强策略由多个子策略组成，每个子策略用于增强一个训练批次。一个子策略由几个基本图像变换函数（TFs）组成。增强策略通常由两个超参数进行参数化：应用概率和操作强度。概率描述了在输入图像上应用某一变换函数的概率，而强度决定了操作的强度。在DA策略中的每个TF都与一对概率和强度超参数相关联。根据搜索或优化算法的选择，搜索空间的表述可以大相径庭。例如，一些工作完全重新参数化搜索空间以减少搜索复杂度[cubuk2020randaugment](#bib.bib31)；[lingchen2020uniformaugment](#bib.bib58)。然而，AA
    [cubuk2019autoaugment](#bib.bib20) 提出的DA策略参数化在后续工作中被广泛使用，几乎没有修改。
- en: 3.1.2 Evaluation Functions
  id: totrans-83
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 评估函数
- en: The evaluation of augmentation policies is conducted from two perspectives,
    including the effectiveness and safety. The former feature emphasizes the impacts
    of DA on final classification results, while the safety feature focuses on the
    label preservation of the transformed data. Generally, the efficacy of augmentations
    is judged by the performance of classification models based on training loss or
    accuracy values. Such procedures can also be called direct evaluation functions,
    since the strength of the DA strategy is directly reflected in how much performance
    gains this augmentation policy can produce. The higher the classification accuracy,
    the better the associated DA policy.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 增强策略的评估从两个角度进行，包括有效性和安全性。前者特征强调数据增强对最终分类结果的影响，而安全性特征则关注于转换数据的标签保持情况。通常，增强的效果通过基于训练损失或准确率的分类模型性能来判断。这些程序也可以称为直接评估函数，因为数据增强策略的强度直接反映在这种增强策略能带来多少性能提升上。分类准确率越高，相关的数据增强策略越好。
- en: Another alternative evaluation is an indirect method, emphasizing the safety
    feature of data augmentation. Examining the safety of DA policy often resorts
    to the use of density matching [lim2019fast](#bib.bib21) . The main objective
    of density matching is to match the distribution of the augmented data to the
    original training data. The basic idea behind this indirect evaluation is to treat
    the transformed images as missing data points of the input data, thereby improving
    the generalizability of the classification model. Smaller density differences
    indicate higher similarity of data distributions, which can lead to better augmentation
    strategies. Using density matching, the policy evaluation does not require back-propagation
    of the model training. Such algorithms can be regarded as the indirect evaluation
    function of AutoDA tasks.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种替代评估方法是间接方法，强调数据增强的安全性特征。检查数据增强策略的安全性通常依赖于密度匹配[lim2019fast](#bib.bib21)。密度匹配的主要目标是将增强数据的分布与原始训练数据匹配。这种间接评估的基本思路是将转换后的图像视为输入数据的缺失数据点，从而提高分类模型的泛化能力。较小的密度差异表示数据分布的相似性更高，这可能导致更好的增强策略。使用密度匹配时，策略评估不需要反向传播模型训练。这些算法可以被视为AutoDA任务的间接评估函数。
- en: 3.2 Overall Workflow
  id: totrans-86
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 整体工作流程
- en: '![Refer to caption](img/d4a9df771a51a8cde14e3f383af0ee68.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/d4a9df771a51a8cde14e3f383af0ee68.png)'
- en: 'Figure 1: General workflow of a standard AutoDA model involving three key components.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：标准AutoDA模型的总体工作流程，包括三个关键组件。
- en: The relationship between these components is depicted in Fig. [1](#S3.F1 "Figure
    1 ‣ 3.2 Overall Workflow ‣ 3 Automated Data Augmentation Techniques ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks"). Firstly, the AutoDA model specifies the parameterization of DA policies
    for the given task, providing a finite number of potential solutions to be searched
    and evaluated. Within the defined search space, the search algorithm then samples
    DA policies and passes the candidates to the evaluation section. In earlier AutoDA
    works, augmentation policies were sampled one by one [cubuk2019autoaugment](#bib.bib20)
    ; [naghizadeh2020greedy](#bib.bib60) , while later approaches tend to employ multi-threaded
    processes, sampling multiple candidates and evaluating them in a distributed fashion.
    This substantially improves the search efficiency. After a DA policy is selected
    by the search algorithm, it is then rated by the evaluation function to compute
    the reward signal. Each augmentation strategy is associated with a reward value,
    indicating its effectiveness in improving model performance. Finally, the reward
    information is used to update the search algorithm, guiding the sampling of the
    next DA policy to be evaluated. The entire search recursion process ends when
    the optimal policy is found. This can be determined by examining the difference
    in performance gain between the current search point and the previous point. However,
    the stopping criteria might lead to excessive searching with little improvement,
    especially in the later phases, resulting in a waste of resources. In most practical
    implementations of AutoDA algorithms, the search algorithm will stop when a self-defined
    stopping condition is fulfilled, for example after a certain number of search
    epochs [niu2019automatically](#bib.bib61) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    .
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 这些组件之间的关系如图[1](#S3.F1 "Figure 1 ‣ 3.2 Overall Workflow ‣ 3 Automated Data Augmentation
    Techniques ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks")所示。首先，AutoDA模型为给定任务指定DA策略的参数化，提供有限数量的潜在解决方案供搜索和评估。在定义的搜索空间内，搜索算法会采样DA策略，并将候选策略传递给评估部分。在早期的AutoDA工作中，数据增强策略是逐一采样的[cubuk2019autoaugment](#bib.bib20)
    ; [naghizadeh2020greedy](#bib.bib60) ，而后来方法倾向于采用多线程处理，采样多个候选策略并以分布式方式进行评估。这大大提高了搜索效率。在搜索算法选择DA策略后，会通过评估函数对其进行评分以计算奖励信号。每种增强策略都有一个奖励值，表示其在提高模型性能方面的有效性。最后，奖励信息用于更新搜索算法，指导下一次要评估的DA策略的采样。整个搜索递归过程在找到最佳策略后结束。这可以通过检查当前搜索点和前一个点之间的性能增益差异来确定。然而，停止标准可能导致过度搜索而几乎没有改进，特别是在后期阶段，从而浪费资源。在大多数实际实现的AutoDA算法中，搜索算法会在满足自定义停止条件时停止，例如在经过一定数量的搜索周期后[niu2019automatically](#bib.bib61)
    ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)。
- en: 3.3 Two Stages of AutoDA
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 AutoDA的两个阶段
- en: 'The standard AutoDA pipeline can be divided into two major stages:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 标准AutoDA流程可以分为两个主要阶段：
- en: Definition 4  (Generation stage).
  id: totrans-92
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义4（生成阶段）。
- en: is the process of generating the optimal augmentation policy when given certain
    datasets. A DA policy is typically described by a sequence of augmentation hyper-parameters.
    Usually, the final DA solution is generated by a search or optimization algorithm,
    which samples various candidate strategies from the defined search space, and
    relies on a evaluation function to assess efficacy of the searched policies.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 是在给定特定数据集时生成最佳增强策略的过程。DA策略通常通过一系列增强超参数来描述。通常，最终的DA解决方案是通过搜索或优化算法生成的，该算法从定义的搜索空间中采样各种候选策略，并依赖评估函数来评估搜索策略的有效性。
- en: Definition 5  (Application stage).
  id: totrans-94
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 定义5（应用阶段）。
- en: is the process of applying the policy learned in the generation stage. This
    is done by augmenting the target dataset using the obtained DA policy to artificially
    increase both the data quantity and variety, and then train the classification
    model on the transformed training set.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 是应用生成阶段所学策略的过程。这是通过使用获得的DA策略来增强目标数据集，从而人为地增加数据的数量和多样性，然后在变换后的训练集上训练分类模型。
- en: 'With the aim of finding the best augmentation strategy for the target dataset,
    a typical AutoDA problem is mainly solved in the policy generation stage. The
    best DA policy here specifically refers to the hyper-parameter setting that can
    maximize the classification model accuracy or minimize the training loss in the
    later phase, i.e. it can best solve the classification task in application phase.
    We identify several criterion used in published studies to determine the completion
    of policy generation:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 为了找到针对目标数据集的最佳增强策略，典型的AutoDA问题主要在策略生成阶段解决。这里的最佳DA策略特指能够在后期最大化分类模型准确性或最小化训练损失的超参数设置，即它可以在应用阶段最佳地解决分类任务。我们识别出一些在已发布研究中用于确定策略生成完成的标准：
- en: '[1.]'
  id: totrans-97
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '[1.]'
- en: '1.'
  id: totrans-98
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: the sampled DA policy can help train the classification model to achieve the
    highest accuracy scores;
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采样的DA策略可以帮助训练分类模型以达到最高的准确性分数；
- en: '2.'
  id: totrans-100
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: the sampled DA policy can provide comparable performance gains to the optimal
    policy; or
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 采样的DA策略可以提供与最优策略相当的性能增益；或者
- en: '3.'
  id: totrans-102
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: a certain number of training/searching epochs has been completed.
  id: totrans-103
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 已完成一定数量的训练/搜索周期。
- en: Theoretically, the policy generation stage can only end when the first criterion
    is achieved, i.e. the sampled policy is evaluated to be the optimal augmentation
    strategy for the given dataset. However, it is often impractical to thoroughly
    explore the entire search space to identify the best DA policy. A potential solution
    is to set a specific threshold for model accuracy or training loss to help decide
    whether the policy is optimal. However, in application scenarios, the optimal
    strength of data augmentation for classification models is often unknown. It is
    therefore tricky to set such thresholds as success criteria.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 从理论上讲，策略生成阶段只有在达到第一个标准时才会结束，即采样策略被评估为给定数据集的最优增强策略。然而，彻底探索整个搜索空间以确定最佳DA策略通常是不切实际的。一个潜在的解决方案是为模型准确性或训练损失设置一个特定的阈值，以帮助决定策略是否最优。然而，在实际应用中，分类模型的数据增强的最优强度通常是未知的。因此，设置这样的阈值作为成功标准是有挑战的。
- en: An alternative strategy to stop the generation phase is to relax the optimal
    criteria. In other words, if the sampled policy can produce comparable improvement
    in model performance to the optimal DA strategy, it is considered to be optimal.
    This idea has been widely adopted in many existing AutoDA works [lim2019fast](#bib.bib21)
    ; [gudovskiy2021autodo](#bib.bib62) ; [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    . It can be implemented by using the performance difference. For example, if the
    difference in performance gains between the sampled policy and the best rewarded
    one is smaller than a certain value, then this policy can be treated as the final
    output of the generation stage [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    . A more popular alternative is to use density matching. Instead of directly training
    the classification model, density matching compares the distribution/density of
    the original data and the augmented samples. The assumption of density matching
    is that the optimal DA policy can best generalize the classification model by
    matching the density of given data with the density of the transformed data [lim2019fast](#bib.bib21)
    ; [gudovskiy2021autodo](#bib.bib62) .
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 停止生成阶段的另一种策略是放宽最优标准。换句话说，如果采样的策略能够在模型性能上产生与最优DA策略相当的改进，那么它被视为最优。这一思想在许多现有的AutoDA研究中得到了广泛采用
    [lim2019fast](#bib.bib21) ; [gudovskiy2021autodo](#bib.bib62) ; [naghizadeh2020greedy](#bib.bib60)
    ; [naghizadeh2021greedy](#bib.bib63) 。可以通过使用性能差异来实现。例如，如果采样策略与最佳奖励策略之间的性能增益差异小于某个值，那么这个策略可以被视为生成阶段的最终输出
    [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63) 。一种更为流行的替代方法是使用密度匹配。密度匹配不是直接训练分类模型，而是比较原始数据与增强样本的分布/密度。密度匹配的假设是最优DA策略可以通过匹配给定数据的密度与转换后数据的密度，来最佳地推广分类模型
    [lim2019fast](#bib.bib21) ; [gudovskiy2021autodo](#bib.bib62)。
- en: In practice, the most commonly used stopping criteria is to manually decide
    the search limit. Once the training has been conducted after a certain number
    of epochs, policy generation will be forced to stop and output the DA policy with
    the best model performance so far. The selection of epoch number usually depends
    on the available computational resources as well as the complexity of the given
    task. There is no universal agreement on the stopping criteria.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 在实践中，最常用的停止准则是手动决定搜索限制。一旦训练在一定数量的周期后完成，策略生成将被迫停止，并输出当前模型性能最好的DA策略。周期数量的选择通常取决于可用的计算资源以及任务的复杂性。对停止准则没有普遍的共识。
- en: 3.4 Datasets
  id: totrans-107
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 数据集
- en: This section aims at providing a brief overview of the datasets employed in
    the considered approaches. Annotated datasets are generally used as benchmarks
    to provide a fair comparison among different AutoDA algorithms and architectures.
    Furthermore, the growth in size of data and complexity of application scenarios
    increases the challenge, resulting in constant development of new and improved
    techniques.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 本节旨在提供所考虑方法中使用的数据集的简要概述。标注数据集通常用作基准，以便对不同的AutoDA算法和架构进行公平比较。此外，数据量的增长和应用场景的复杂性增加了挑战，导致不断发展出新的和改进的技术。
- en: 'The most used datasets for the task of automated augmentation search are: (i)
    CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) , (ii) SVHN [netzer2011reading](#bib.bib29)
    , (iii) ImageNet [russakovsky2015imagenet](#bib.bib64) . CIFAR stands for Canadian
    Institute for Advanced Research. CIFAR-10 and CIFAR-100 share the same name as
    both are used for CIFAR research, while the numbers specifies the total number
    of classes in the dataset. SVHN refers to Street View House Numbers (SVHN). ImageNet
    is used in the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [russakovsky2015imagenet](#bib.bib64)
    . The characteristics of each dataset are shown in Table [1](#S3.T1 "Table 1 ‣
    3.4 Datasets ‣ 3 Automated Data Augmentation Techniques ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks"),
    while their statistics are summarized in Table [2](#S3.T2 "Table 2 ‣ 3.4 Datasets
    ‣ 3 Automated Data Augmentation Techniques ‣ A Survey of Automated Data Augmentation
    Algorithms for Deep Learning-based Image Classification Tasks").'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 用于自动数据增强搜索任务的最常用数据集有：(i) CIFAR-10/100 [krizhevsky2009learning](#bib.bib27) ，(ii)
    SVHN [netzer2011reading](#bib.bib29) ，(iii) ImageNet [russakovsky2015imagenet](#bib.bib64)
    。CIFAR 代表加拿大高级研究院。CIFAR-10 和 CIFAR-100 同名，因它们都用于CIFAR研究，而数字指定数据集中的总类别数。SVHN 代表街景房屋号码（SVHN）。ImageNet
    用于 ImageNet 大规模视觉识别挑战（ILSVRC） [russakovsky2015imagenet](#bib.bib64) 。每个数据集的特点见表[1](#S3.T1
    "Table 1 ‣ 3.4 Datasets ‣ 3 Automated Data Augmentation Techniques ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks")，其统计信息总结在表[2](#S3.T2 "Table 2 ‣ 3.4 Datasets ‣ 3 Automated Data Augmentation
    Techniques ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks")中。
- en: 'Table 1: Main characteristics of datasets for AutoDA tasks'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 表1：AutoDA任务的数据集主要特征
- en: '| Dataset | Classes | Images per class | Image size | Year |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 类别 | 每类图像数 | 图像大小 | 年份 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| CIFAR-10 | 10 | 6,000 | $32\times 32$ | 2009 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | 10 | 6,000 | $32\times 32$ | 2009 |'
- en: '| CIFAR-100 | 100 | 600 | $32\times 32$ | 2009 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-100 | 100 | 600 | $32\times 32$ | 2009 |'
- en: '| SVHN | 10 | 630,420 | $32\times 32$ | 2011 |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| SVHN | 10 | 630,420 | $32\times 32$ | 2011 |'
- en: '| ImageNet | varying¹¹1The complete ImageNet is too large for an augmentation
    search. Instead, a trimmed subset of ImageNet is usually used in AutoDA works,
    while such set is constructed differently in each work. | varying¹¹1The complete
    ImageNet is too large for an augmentation search. Instead, a trimmed subset of
    ImageNet is usually used in AutoDA works, while such set is constructed differently
    in each work. | varying¹¹1The complete ImageNet is too large for an augmentation
    search. Instead, a trimmed subset of ImageNet is usually used in AutoDA works,
    while such set is constructed differently in each work. | 2009 |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| ImageNet | varying¹¹1完整的ImageNet数据集对于增强搜索来说过于庞大。相反，AutoDA工作中通常使用ImageNet的裁剪子集，而这样的子集在每个工作中构建方式有所不同。
    | varying¹¹1完整的ImageNet数据集对于增强搜索来说过于庞大。相反，AutoDA工作中通常使用ImageNet的裁剪子集，而这样的子集在每个工作中构建方式有所不同。
    | varying¹¹1完整的ImageNet数据集对于增强搜索来说过于庞大。相反，AutoDA工作中通常使用ImageNet的裁剪子集，而这样的子集在每个工作中构建方式有所不同。
    | 2009 |'
- en: '| \botrule |  |  |  |  |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |'
- en: 'Table 2: Statistics of datasets for AutoDA tasks'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 表2：AutoDA任务的数据集统计信息
- en: '|  | Number of images | Number of images per class |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | 图像数量 | 每类图像数量 |'
- en: '| --- | --- | --- |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Dataset | Train | Test | Extra ¹¹1Extra set consists of the same type of
    annotated images as training data, but with slightly lower quality. These data
    are often used as extra training samples for the model. Extra set is only available
    in SVHN data [netzer2011reading](#bib.bib29) . | Train | Test | Extra ¹¹1Extra
    set consists of the same type of annotated images as training data, but with slightly
    lower quality. These data are often used as extra training samples for the model.
    Extra set is only available in SVHN data [netzer2011reading](#bib.bib29) . |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 训练 | 测试 | 额外¹¹1额外集由与训练数据相同类型的标注图像组成，但质量稍低。这些数据通常用作模型的额外训练样本。额外集仅在SVHN数据中可用
    [netzer2011reading](#bib.bib29) 。 | 训练 | 测试 | 额外¹¹1额外集由与训练数据相同类型的标注图像组成，但质量稍低。这些数据通常用作模型的额外训练样本。额外集仅在SVHN数据中可用
    [netzer2011reading](#bib.bib29) 。 |'
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- | --- |'
- en: '| CIFAR-10 | 50,000 | 10,000 | - | 5,000 | 1,000 | - |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-10 | 50,000 | 10,000 | - | 5,000 | 1,000 | - |'
- en: '| CIFAR-100 | 50,000 | 10,000 | - | 500 | 100 | - |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| CIFAR-100 | 50,000 | 10,000 | - | 500 | 100 | - |'
- en: '| SVHN | 73,257 | 26,032 | 531,131 | 5,000 - 14,000 | 1,800 - 5,000 | 35,000
    - 90,000 |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| SVHN | 73,257 | 26,032 | 531,131 | 5,000 - 14,000 | 1,800 - 5,000 | 35,000
    - 90,000 |'
- en: '| \botrule |  |  |  |  |  |  |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |  |  |'
- en: The CIFAR and ImageNet dataset are published at the same year, both present
    standard image classification task and are commonly used in computer vision researches.
    However, ImageNet is much larger than the CIFAR series in scale and diversity.
    There are over $5,000$ different categories in the original ImageNet set, with
    $3.2$ million images that have been hand-annotated [deng2009imagenet](#bib.bib28)
    . For the AutoDA search problem, the enormous quantity of ImageNet data might
    require significant amounts of computational resources. Training on the complete
    ImageNet is usually infeasible in practice. Instead, it is often more suitable
    to use a reduced ImageNet subset for the target task. Additionally, the distribution
    of instances among different classes can also vary considerably, which can decrease
    the performance of AutoDA models. To address these issues, each AutoDA work that
    conducts experiments using ImageNet data uses a distinctive trimming method to
    set up a smaller and cleaner subset for model evaluation. Nevertheless, due to
    the diversity of data and imbalanced class distribution, the classification on
    ImageNet subset is still considered to be a relatively difficult task when compared
    with other datasets (for augmentation search). In AutoDA works, the reduced ImageNet
    datasets are constructed differently, with varying sizes and class numbers. Each
    of them will be described in the works where they are employed.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR 和 ImageNet 数据集是在同一年发布的，均提供标准图像分类任务，且在计算机视觉研究中广泛使用。然而，ImageNet 在规模和多样性上远大于
    CIFAR 系列。原始 ImageNet 数据集中有超过 $5,000$ 个不同类别，共有 $3.2$ 百万张经过手工标注的图像 [deng2009imagenet](#bib.bib28)
    。对于 AutoDA 搜索问题，庞大的 ImageNet 数据量可能需要大量的计算资源。在实践中，通常无法对完整的 ImageNet 进行训练。相反，通常更适合使用一个较小的
    ImageNet 子集来进行目标任务。此外，不同类别之间的实例分布也可能变化很大，这可能降低 AutoDA 模型的性能。为了解决这些问题，每个使用 ImageNet
    数据进行实验的 AutoDA 工作都使用独特的修剪方法来设置一个较小、更干净的子集以进行模型评估。然而，由于数据的多样性和类别分布的不平衡，与其他数据集（用于增强搜索）相比，分类
    ImageNet 子集仍被认为是相对困难的任务。在 AutoDA 工作中，减少的 ImageNet 数据集有不同的构建方式，具有不同的大小和类别数量。每个数据集将会在它们被使用的工作中进行描述。
- en: The CIFAR series consists of much fewer categories, designated by their number
    [krizhevsky2009learning](#bib.bib27) . The CIFAR-10 dataset consists of $60,000$
    $32\times 32$ colour images in total. The data distribution among classes in CIFAR-10
    is more controlled and unified. $60,000$ images are evenly distributed into $10$
    classes, providing $6,000$ images per class. The splitting ration of train:test
    data is $5:1$. In CIFAR-10 dataset, the test batch contains $10,000$ images, randomly
    selected from the full dataset, but each class contains exactly $1,000$ images.
    The training set contains the remaining $50,000$ instances. The formulation of
    CIFAR-100 dataset is similar to CIFAR-10, except there are $100$ classes in CIFAR-100,
    each of which comprises $600$ images. The train:test ratio is also $5:1$, providing
    $500$ training images and $100$ test images per class. With a more balanced data
    distribution and limited class number, CIFAR data is usually more suitable to
    benchmark proposed AutoDA algorithms.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: CIFAR系列包含的类别要少得多，其编号为[krizhevsky2009learning](#bib.bib27)。CIFAR-10数据集总共包含$60,000$张$32\times
    32$彩色图像。CIFAR-10中各类别的数据分布更加控制和统一。$60,000$张图像均匀分布在$10$个类别中，每个类别提供$6,000$张图像。训练集和测试集的数据划分比例为$5:1$。在CIFAR-10数据集中，测试批次包含$10,000$张图像，从整个数据集中随机选择，但每个类别正好包含$1,000$张图像。训练集包含剩余的$50,000$个实例。CIFAR-100数据集的构成与CIFAR-10类似，只是CIFAR-100中有$100$个类别，每个类别包含$600$张图像。训练集和测试集的比例也是$5:1$，每个类别提供$500$张训练图像和$100$张测试图像。由于数据分布更为平衡且类别数量有限，CIFAR数据通常更适合用于基准测试提出的AutoDA算法。
- en: SVHN refers to Street View House Numbers. It is also collected from real-world
    scenarios, widely used for deep learning related researches. Similar to MNIST
    data [lecun1998gradient](#bib.bib32) , images in SVHN are also digits, cropped
    from house numbers in Google Street View images [netzer2011reading](#bib.bib29)
    . The major task of SVHN is to recognize numbers in natural scene images. There
    are $10$ categories in total, each of which represents one digit, e.g. digit 1
    has label 1\. In SVHN, there are $73,257$ digits for training, $26,032$ digits
    for testing, and $531,131$ additional data tiems that can be used as extra training
    data. In contrast to previous datasets, SVHN specifically emphasizes the pictures
    of digits and numbers. This might reveal the relationship between DA selection
    strategy and data types. However, unlike CIFAR, the SVHN data distribution among
    classes is biased. There are more 0 and 1 digits present in the data, resulting
    in a skewed class distribution in both training and test set. Seen in Table. [2](#S3.T2
    "Table 2 ‣ 3.4 Datasets ‣ 3 Automated Data Augmentation Techniques ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks"), for SVHN, the number of images per class ranges from $5,000$ to $14,000$.
    Such imbalance can be considered as a challenge to better assess AutoDA models
    from different perspectives.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: SVHN指的是街景房号数据集。它同样是从实际场景中收集的，广泛用于深度学习相关研究。与MNIST数据[lecun1998gradient](#bib.bib32)类似，SVHN中的图像也是数字，裁剪自Google街景图像中的房号[netzer2011reading](#bib.bib29)。SVHN的主要任务是识别自然场景图像中的数字。总共有$10$个类别，每个类别表示一个数字，例如，数字1的标签为1。在SVHN中，训练集有$73,257$个数字，测试集有$26,032$个数字，还有$531,131$个额外数据项可以用作额外的训练数据。与之前的数据集相比，SVHN特别强调数字和数字的图像。这可能揭示了DA选择策略与数据类型之间的关系。然而，与CIFAR不同的是，SVHN的类别间数据分布存在偏差。数据中0和1的数字较多，导致训练集和测试集中类别分布不均。如表[2](#S3.T2
    "Table 2 ‣ 3.4 Datasets ‣ 3 Automated Data Augmentation Techniques ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks")所示，对于SVHN，每个类别的图像数量从$5,000$到$14,000$不等。这种不平衡被认为是从不同角度更好地评估AutoDA模型的挑战。
- en: 4 Taxonomy of Image AutoDA Methods
  id: totrans-130
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 图像AutoDA方法的分类
- en: 'Table [3](#S4.T3 "Table 3 ‣ 4 Taxonomy of Image AutoDA Methods ‣ A Survey of
    Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks") shows a summary of primary works in the AutoDA field. The column Key technique
    describes the most important technique adapted in each AutoDA model to formulate
    augmentation search problems. These methods are usually borrowed from other ML-related
    field, such as NAS or hyper-parameter optimization. Policy optimizer indicates
    the algorithm or controller that is used to optimize or update the augmentation
    policy during the search. These AutoDA approaches are classified into two major
    types based on the stage involved to solve the classification task using the learned
    DA policy, namely one-stage or two-stage. Additionally, from the perspective of
    hyper-parameter optimization, these methods can be further categorized into three
    classes: gradient-based, gradient-free and search-free. Table [3](#S4.T3 "Table
    3 ‣ 4 Taxonomy of Image AutoDA Methods ‣ A Survey of Automated Data Augmentation
    Algorithms for Deep Learning-based Image Classification Tasks") provides a categorization
    that projects the underlying optimization algorithm used by each of the methods.'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 [3](#S4.T3 "Table 3 ‣ 4 Taxonomy of Image AutoDA Methods ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")
    显示了 AutoDA 领域主要工作的总结。列“关键技术”描述了每个 AutoDA 模型中采用的最重要技术，用于制定增强搜索问题。这些方法通常借用自其他 ML
    相关领域，如 NAS 或超参数优化。策略优化器指示在搜索过程中用于优化或更新增强策略的算法或控制器。这些 AutoDA 方法根据使用学习到的 DA 策略解决分类任务所涉及的阶段，分为两种主要类型，即单阶段或双阶段。此外，从超参数优化的角度，这些方法可以进一步分为三类：基于梯度的、无梯度的和无搜索的。表格
    [3](#S4.T3 "Table 3 ‣ 4 Taxonomy of Image AutoDA Methods ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")
    提供了一个分类，展示了每种方法使用的基础优化算法。
- en: 'Based on the application sequence of the two stages of the AutoDA model, we
    classify all existing works into two major categories: one-stage and two-stage
    approaches. Two-stage approaches conduct both the generation and application respectively.
    In a typical two-stage method, the optimal augmentation policy is generated according
    to the task dataset from the first stage. After that, the learned augmentation
    strategies is applied on the training set to train the discriminative model. There
    are two separate stages required when utilizing a two-stage algorithm. The one-stage
    approaches combine the generation and application together through the use of
    gradient approximation methods. By estimating the gradient of a DA policy with
    regard to model performance, one-stage approaches are able to optimize augmentation
    policy and classification model simultaneously. As a result, they can obtain the
    final results and trained model through a single run. Such algorithms usually
    achieve better efficiency than traditional two-stage approaches.'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 根据 AutoDA 模型的两个阶段的应用序列，我们将所有现有工作分为两个主要类别：单阶段方法和双阶段方法。双阶段方法分别进行生成和应用。在典型的双阶段方法中，根据第一阶段的任务数据集生成最佳增强策略。之后，将学到的增强策略应用于训练集，以训练判别模型。使用双阶段算法时需要两个独立的阶段。单阶段方法通过使用梯度近似方法将生成和应用结合在一起。通过估计
    DA 策略相对于模型性能的梯度，单阶段方法能够同时优化增强策略和分类模型。因此，它们可以通过一次运行获得最终结果和训练好的模型。这些算法通常比传统的双阶段方法具有更好的效率。
- en: \sidewaystablefn
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: \sidewaystablefn
- en: 'Table 3: Summary table of major AutoDA works reviewed for image classification
    task'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3：图像分类任务中主要 AutoDA 研究的总结表
- en: '|  |  |  | Stage ²²2Classification based on the application sequence of two
    stages involved. Policy generation and application are performed simultaneously
    in an one-stage approach, but sequentially in a two-stage method. | Policy optimization
    ³³3Classification based on the type of policy optimization. Gradient-free methods
    optimize augmentation policies without approximating the gradients of policy hyper-parameters.
    Gradient-based methods estimates such gradients for policy optimization. Search-free
    methods re-parameterize the search space to exclude the need of search. |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 基于两个阶段应用序列的分类。单阶段方法中，策略生成和应用同时进行，而双阶段方法中，策略生成和应用是顺序进行的。 | 策略优化 ³³3
    分类基于策略优化类型。无梯度方法在不近似策略超参数梯度的情况下优化增强策略。基于梯度的方法估计这些梯度以进行策略优化。无搜索方法重新参数化搜索空间以排除搜索的需要。
    |'
- en: '| Method | Key technique | Policy optimizer ¹¹1Policy optimizer is the algorithm
    or controller used by AutoDA model to update augmentation strategies during the
    policy generation stage. | two-stage | one-stage | gradient-free | gradient-based
    | search-free |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 关键技术 | 策略优化器¹¹策略优化器是AutoDA模型在策略生成阶段用于更新增强策略的算法或控制器。 | 两阶段 | 单阶段 | 无梯度
    | 有梯度 | 无搜索 |'
- en: '| TANDA⁴⁴4Transformation Adversarial Networks for Data Augmentations[ratner2017learning](#bib.bib52)
    | Generative | Long short-term | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '| TANDA⁴⁴4数据增强的变换对抗网络[ratner2017learning](#bib.bib52) | 生成 | 长短期记忆 | $\checkmark$
    |  | $\checkmark$ |  |  |'
- en: '| adversarial network | memory network |  |  |  |  |  |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '| 对抗网络 | 记忆网络 |  |  |  |  |  |'
- en: '| AA⁵⁵5AutoAugment[cubuk2019autoaugment](#bib.bib20) | Reinforcement | Recurrent
    neural | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '| AA⁵⁵5自动增强[cubuk2019autoaugment](#bib.bib20) | 强化 | 循环神经 | $\checkmark$ |  |
    $\checkmark$ |  |  |'
- en: '| learning (RL) | network controller |  |  |  |  |  |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
  zh: '| 学习（RL） | 网络控制器 |  |  |  |  |  |'
- en: '| AWS⁶⁶6Augmentation-WiseWeight Sharing[tian2020improving](#bib.bib30) | Weight
    sharing; | Proximal policy | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
  zh: '| AWS⁶⁶6增强方法-明智的权重共享[tian2020improving](#bib.bib30) | 权重共享; | 近端策略 | $\checkmark$
    |  | $\checkmark$ |  |  |'
- en: '| RL | optimization |  |  |  |  |  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| RL | 优化 |  |  |  |  |  |'
- en: '| \botrule |  |  |  |  |  |  |  |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |  |  |  |'
- en: \sidewaystablefn
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: \sidewaystablefn
- en: 'Table 3: (continued)'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 表3:（续）
- en: '|  |  |  | Stage ²²footnotemark: 2 | Policy optimization ³³footnotemark: 3
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 阶段²²脚注标记: 2 | 策略优化³³脚注标记: 3 |'
- en: '| Method | Key technique | Policy optimizer ¹¹footnotemark: 1 | two-stage |
    one-stage | gradient-free | gradient-based | search-free |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 关键技术 | 策略优化器¹¹脚注标记: 1 | 两阶段 | 单阶段 | 无梯度 | 有梯度 | 无搜索 |'
- en: '| GAA⁷⁷7Greedy AutoAugment[naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    | Greedy breadth | Breadth-first | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| GAA⁷⁷7贪婪自动增强[naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    | 贪婪广度 | 广度优先 | $\checkmark$ |  | $\checkmark$ |  |  |'
- en: '| first search | search |  |  |  |  |  |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| 首次搜索 | 搜索 |  |  |  |  |  |'
- en: '| PBA⁸⁸8Population-Based Augmentation[ho2019population](#bib.bib23) | Population-based
    | Truncation | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| PBA⁸⁸8基于人口的增强[ho2019population](#bib.bib23) | 基于人口 | 截断 | $\checkmark$ |  |
    $\checkmark$ |  |  |'
- en: '| training | selection |  |  |  |  |  |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| 训练 | 选择 |  |  |  |  |  |'
- en: '| Fast AA⁹⁹9Fast AutoAugment[lim2019fast](#bib.bib21) | Density matching; |
    Bayesian | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| 快速AA⁹⁹9快速自动增强[lim2019fast](#bib.bib21) | 密度匹配; | 贝叶斯 | $\checkmark$ |  |
    $\checkmark$ |  |  |'
- en: '| RL | optimization |  |  |  |  |  |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| RL | 优化 |  |  |  |  |  |'
- en: '| PAA^(10)^(10)10Patch AutoAugment[lin2021local](#bib.bib65) | Multi-agent
    | Advantage actor | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| PAA^(10)^(10)10补丁自动增强[lin2021local](#bib.bib65) | 多智能体 | 优势演员 | $\checkmark$
    |  | $\checkmark$ |  |  |'
- en: '| RL | critic algorithm |  |  |  |  |  |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| RL | 评论算法 |  |  |  |  |  |'
- en: '| AA-KD^(11)^(11)11AutoAugment with Knowledge Distillation[wei2020circumventing](#bib.bib59)
    | Knowledge | - | $\checkmark$ |  | $\checkmark$ |  |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| AA-KD^(11)^(11)11带知识蒸馏的自动增强[wei2020circumventing](#bib.bib59) | 知识 | - |
    $\checkmark$ |  | $\checkmark$ |  |  |'
- en: '| distillation |  |  |  |  |  |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 蒸馏 |  |  |  |  |  |  |'
- en: '| \botrule |  |  |  |  |  |  |  |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |  |  |  |'
- en: \sidewaystablefn
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: \sidewaystablefn
- en: 'Table 3: (continued)'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 表3:（续）
- en: '|  |  |  | Stage ²²footnotemark: 2 | Policy optimization ³³footnotemark: 3
    |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 阶段²²脚注标记: 2 | 策略优化³³脚注标记: 3 |'
- en: '| Method | Key technique | Policy optimizer ¹¹footnotemark: 1 | two-stage |
    one-stage | gradient-free | gradient-based | search-free |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 关键技术 | 策略优化器¹¹脚注标记: 1 | 两阶段 | 单阶段 | 无梯度 | 有梯度 | 无搜索 |'
- en: '| Faster AA^(12)^(12)12Faster AutoAugment[hataya2020faster](#bib.bib22) | Gradient
    estimation; | Stochastic | $\checkmark$ |  |  | $\checkmark$ |  |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| 更快的AA^(12)^(12)12更快的自动增强[hataya2020faster](#bib.bib22) | 梯度估计; | 随机 | $\checkmark$
    |  |  | $\checkmark$ |  |'
- en: '| Density matching | gradient descent |  |  |  |  |  |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 密度匹配 | 梯度下降 |  |  |  |  |  |'
- en: '| RA^(13)^(13)13RandAugment[cubuk2020randaugment](#bib.bib31) | Search space
    | Grid search | $\checkmark$ |  |  |  | $\checkmark$ |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| RA^(13)^(13)13随机增强[cubuk2020randaugment](#bib.bib31) | 搜索空间 | 网格搜索 | $\checkmark$
    |  |  |  | $\checkmark$ |'
- en: '| reparameterization |  |  |  |  |  |  |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 重新参数化 |  |  |  |  |  |  |'
- en: '| UA^(14)^(14)14UniformAugment[lingchen2020uniformaugment](#bib.bib58) | Augmentation
    | Uniform | $\checkmark$ |  |  |  | $\checkmark$ |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| UA^(14)^(14)14均匀增强[lingchen2020uniformaugment](#bib.bib58) | 增强 | 均匀 | $\checkmark$
    |  |  |  | $\checkmark$ |'
- en: '| invariance | sampling |  |  |  |  |  |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| 不变性 | 采样 |  |  |  |  |  |'
- en: '| OHL-AA^(15)^(15)15Online Hyper-parameter Learning for Auto-Augmentation[lin2019online](#bib.bib54)
    | Gradient estimation | Stochastic |  | $\checkmark$ |  | $\checkmark$ |  |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| OHL-AA^(15)^(15)15在线超参数学习用于自动增强[lin2019online](#bib.bib54) | 梯度估计 | 随机 |  |
    $\checkmark$ |  | $\checkmark$ |  |'
- en: '|  | gradient descent |  |  |  |  |  |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '|  | 梯度下降 |  |  |  |  |  |'
- en: '| Adv AA^(16)^(16)16Adversarial AutoAugment[zhang2019adversarial](#bib.bib53)
    | Gradient estimation; | Recurrent |  | $\checkmark$ |  | $\checkmark$ |  |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| Adv AA^(16)^(16)16对抗性 AutoAugment[zhang2019adversarial](#bib.bib53) | 梯度估计；
    | 循环 |  | $\checkmark$ |  | $\checkmark$ |  |'
- en: '| Adversarial learning | neural network |  |  |  |  |  |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| 对抗学习 | 神经网络 |  |  |  |  |  |'
- en: '| \botrule |  |  |  |  |  |  |  |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |  |  |  |'
- en: \sidewaystablefn
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: \sidewaystablefn
- en: 'Table 3: (continued)'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3:（续）
- en: '|  |  |  | Stage ²²footnotemark: 2 | Policy optimization ³³footnotemark: 3
    |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '|  |  |  | 阶段²²脚注标记: 2 | 策略优化³³脚注标记: 3 |'
- en: '| Method | Key technique | Policy optimizer ¹¹footnotemark: 1 | two-stage |
    one-stage | gradient-free | gradient-based | search-free |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 方法 | 关键技术 | 策略优化器¹¹脚注标记: 1 | 两阶段 | 一阶段 | 无梯度 | 基于梯度 | 无搜索 |'
- en: '| DADA^(17)^(17)17Differentiable Automatic Data Augmentation[li2020dada](#bib.bib57)
    | Unbiased | Stochastic |  | $\checkmark$ |  | $\checkmark$ |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| DADA^(17)^(17)17可微分自动数据增强[li2020dada](#bib.bib57) | 无偏 | 随机 |  | $\checkmark$
    |  | $\checkmark$ |  |'
- en: '| gradient estimator | gradient descent |  |  |  |  |  |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 梯度估计器 | 梯度下降 |  |  |  |  |  |'
- en: '| AutoDO^(18)^(18)18Automated Dataset Optimization[gudovskiy2021autodo](#bib.bib62)
    | Gradient estimation; | Stochastic |  |  |  |  |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| AutoDO^(18)^(18)18自动数据集优化[gudovskiy2021autodo](#bib.bib62) | 梯度估计； | 随机 |  |  |  |  |  |'
- en: '| Loss reweighting; | gradient descent |  | $\checkmark$ |  | $\checkmark$
    |  |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 损失重标定； | 梯度下降 |  | $\checkmark$ |  | $\checkmark$ |  |'
- en: '| Soft labelling |  |  |  |  |  |  |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 软标记 |  |  |  |  |  |  |'
- en: '| \botrule |  |  |  |  |  |  |  |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| \botrule |  |  |  |  |  |  |  |'
- en: 4.1 Two-stage Methods
  id: totrans-184
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 两阶段方法
- en: There are two steps involved in applying AutoDA to discriminative tasks in the
    imaging domain. Generally, an AutoDA model searches for the optimal augmentation
    strategy and then applies the obtained policy on the target data for model training.
    Due to the separate processes of searching and training, this kind of approach
    is described as two-stage in this paper. The general framework of a typical (two-stage)
    approach is displayed in Fig. [2](#S4.F2 "Figure 2 ‣ 4.1 Two-stage Methods ‣ 4
    Taxonomy of Image AutoDA Methods ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks"). In the first stage, given
    a specific dataset, the search algorithm looks for the best composition of image
    transformation functions, also known as the DA policy. The generation stage ends
    once the optimal policy is identified by the evaluation function or the searching
    reaches a given time limit. In the second stage, the learnt policy is applied
    on the target training set - ideally with additional data of increased quantity
    and targeted variety. Then the augmented training samples are fed into the classification
    model for final training.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
  zh: 在成像领域将 AutoDA 应用于判别任务时涉及两个步骤。通常，AutoDA 模型首先搜索最佳的数据增强策略，然后将获得的策略应用于目标数据进行模型训练。由于搜索和训练是分开的过程，这种方法在本文中被描述为两阶段方法。典型（两阶段）方法的一般框架如图
    [2](#S4.F2 "图 2 ‣ 4.1 两阶段方法 ‣ 4 图像 AutoDA 方法的分类 ‣ 深度学习图像分类任务的自动化数据增强算法综述") 所示。在第一阶段，给定特定的数据集，搜索算法寻找最佳的图像转换函数组合，也称为
    DA 策略。一旦通过评估函数确定了最佳策略或搜索达到给定的时间限制，生成阶段结束。在第二阶段，学习到的策略应用于目标训练集——理想情况下，还包括增加数量和有针对性的多样性的数据。然后将增强后的训练样本输入到分类模型中进行最终训练。
- en: '![Refer to caption](img/c3f0d3538b2a183580eb8af7d10a6d9d.png)'
  id: totrans-186
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c3f0d3538b2a183580eb8af7d10a6d9d.png)'
- en: 'Figure 2: Overall framework of two-stage AutoDA approaches.'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '图 2: 两阶段 AutoDA 方法的总体框架。'
- en: The algorithm used to find the best scheme for data augmentation has been explored
    in a wide range of existing works. We categorize them into three different classes
    according to the problem formulation. Some works treat augmentation searching
    as a standard gradient-free optimization problem [ratner2017learning](#bib.bib52)
    ; [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21)
    ; [tian2020improving](#bib.bib30) ; [naghizadeh2020greedy](#bib.bib60) ; [wei2020circumventing](#bib.bib59)
    , whilst other methods approach it from the gradient perspective by means of various
    gradient approximation algorithms [hataya2020faster](#bib.bib22) . Other options
    re-parameterize the entire AutoDA problem in a way that eliminates the need for
    searching - so called search-free approaches.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 用于寻找数据增强最佳方案的算法已经在广泛的现有工作中得到了探讨。我们根据问题的公式化将它们分为三类。一些工作将增强搜索视为标准的无梯度优化问题 [ratner2017learning](#bib.bib52)
    ; [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21)
    ; [tian2020improving](#bib.bib30) ; [naghizadeh2020greedy](#bib.bib60) ; [wei2020circumventing](#bib.bib59)
    ，而其他方法则从梯度角度入手，通过各种梯度近似算法来处理 [hataya2020faster](#bib.bib22) 。其他选项则通过重新参数化整个AutoDA问题的方式来消除搜索需求，即所谓的无搜索方法。
- en: 4.1.1 Gradient-free
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 无梯度方法
- en: Gradient-free approaches search for the best parameters of the augmentation
    policy based on model hyper-parameter optimization without gradient approximation.
    Intuitively, such optimizations can be accomplished by selecting several values
    for each hyper-parameter, completing a model training for each combination on
    the target task, and then computing the evaluation metrics of the model performance
    using all hyper-parameter values. The first attempt to automate such a search
    process was Transformation Adversarial Networks for Data Augmentations (TANDA)
    [ratner2017learning](#bib.bib52) , which utilizes a Generative Adversarial Network
    (GAN) architecture at its core. The objective of the generator is to propose appropriate
    sequences of arbitrary augmentation operations, which are then sent to a discriminator
    for effectiveness assessment. The problem formulation in [hu2019learning](#bib.bib66)
    motivated the deep learning community to explore other methods such as AA [cubuk2019autoaugment](#bib.bib20)
    . AA inherits the augmentation sequence modeling in [lemley2017smart](#bib.bib10)
    , but applies a different strategy based on Reinforcement Learning (RL). Several
    possible augmentation policies are sampled via a Recurrent Neural Network (RNN)
    controller, that are then assessed through training a simplified child model instead
    of given classification model. Despite its promising performance in terms of model
    improvement, AA has a non-negligible limitation, which is the extremely low efficiency.
    It can take up to $15,000$ GPU hours to complete a search over ImageNet data.
    Even with the smallest CIFAR-10 set, AA still requires thousands of GPU hours
    to complete a single run.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 无梯度方法通过模型超参数优化在没有梯度近似的情况下搜索最佳的增强策略参数。从直观上看，这种优化可以通过为每个超参数选择几个值，完成每个组合在目标任务上的模型训练，然后使用所有超参数值计算模型性能评估指标来实现。第一次尝试自动化这种搜索过程的是用于数据增强的变换对抗网络（TANDA）
    [ratner2017learning](#bib.bib52) ，其核心利用了生成对抗网络（GAN）架构。生成器的目标是提出适当的任意增强操作序列，然后将其发送给判别器进行效果评估。在
    [hu2019learning](#bib.bib66) 中的问题公式化促使深度学习社区探索其他方法，如AA [cubuk2019autoaugment](#bib.bib20)
    。AA继承了 [lemley2017smart](#bib.bib10) 中的增强序列建模，但基于强化学习（RL）应用了不同的策略。通过递归神经网络（RNN）控制器采样几个可能的增强策略，然后通过训练简化的子模型而不是给定的分类模型来进行评估。尽管在模型改进方面表现出色，AA仍有一个不可忽视的限制，即效率极低。在ImageNet数据集上完成一次搜索可能需要高达$15,000$
    GPU小时。即使在最小的CIFAR-10数据集上，AA仍需要数千个GPU小时来完成一次运行。
- en: The majority of the later works on this topic aim to contribute to efficiency
    enhancements and computational cost reductions. For example, [tian2020improving](#bib.bib30)
    utilizes a similar reinforcement learning method, but slightly modifies the search
    procedure by sharing the same augmentation parameters from earlier stages. Such
    auto-augment techniques can be further improved through the application of advanced
    evolutionary algorithms such as Population Based Training (PBT) [jaderberg2017population](#bib.bib67)
    . Some simple searching algorithms have also been found to be beneficial to accelerate
    the first stage. For instance, [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    replace the original RNN controller with a traditional Greedy Breadth First Search
    algorithm to simplify the process, and therefore reduce the overall computation
    cost. In addition to the selection of the search algorithm, modification of the
    evaluation function can also greatly reduce the computational demands. A landmark
    work in this direction is Fast AutoAugment (Fast AA) [lim2019fast](#bib.bib21)
    , which takes advantage of the variable kernel density [terrell1992variable](#bib.bib68)
    and proposes an efficient density matching algorithm as a substitute. In the AutoDA
    context, the data density represents the overall distribution of data. Instead
    of a training classification model, density matching evaluates DA policies by
    comparing the distribution of the original training set and the transformed data.
    Such algorithms eliminate the need for re-training the model and hence result
    in a significant efficiency boost.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 后续的大多数研究工作旨在提高效率和降低计算成本。例如，[tian2020improving](#bib.bib30) 利用了一种类似的强化学习方法，但通过共享来自早期阶段的相同增强参数稍微修改了搜索过程。这种自动增强技术可以通过应用先进的进化算法，如基于种群的训练（PBT）[jaderberg2017population](#bib.bib67)，得到进一步改进。一些简单的搜索算法也被发现对加速第一阶段有利。例如，[naghizadeh2020greedy](#bib.bib60)；[naghizadeh2021greedy](#bib.bib63)
    用传统的贪婪宽度优先搜索算法替代了原始的RNN控制器，从而简化了过程，并降低了整体计算成本。除了搜索算法的选择，评估函数的修改也可以大大减少计算需求。一个在这一方向上具有里程碑意义的工作是快速自动增强（Fast
    AA）[lim2019fast](#bib.bib21)，它利用了可变核密度[terrell1992variable](#bib.bib68)并提出了一种高效的密度匹配算法作为替代。在AutoDA的背景下，数据密度代表数据的总体分布。密度匹配通过比较原始训练集和转换数据的分布来评估DA策略，而不是训练分类模型。这些算法消除了重新训练模型的需要，从而显著提高了效率。
- en: Another approach is to focus on the effectiveness or precision of the learned
    augmentation policy. All of the aforementioned methods focus on the resources
    and time consumption of the search phase. Not much progress has been made in terms
    of the improvement of classification accuracy. To fill this gap, [lin2021local](#bib.bib65)
    proposes a more fine-grained Patch AutoAugment (PAA) technique which optimizes
    the augmentation transformations targeted to local regions of images rather than
    the whole image. Other state-of-the-art methods in the Network Architecture Search
    (NAS) field help to increase the augmentation precision. One example is Knowledge
    Distillation (KD) [hinton2015distilling](#bib.bib69) as used in [wei2020circumventing](#bib.bib59)
    .
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种方法是关注学习到的增强策略的有效性或精度。上述所有方法都侧重于搜索阶段的资源和时间消耗。在分类准确性提升方面进展不大。为填补这一空白，[lin2021local](#bib.bib65)
    提出了更精细化的Patch AutoAugment（PAA）技术，该技术优化了针对图像局部区域的增强转换，而不是整个图像。网络架构搜索（NAS）领域的其他先进方法有助于提高增强精度。其中一个例子是知识蒸馏（KD）[hinton2015distilling](#bib.bib69)，如在[wei2020circumventing](#bib.bib59)中所使用。
- en: 4.1.2 Gradient-based
  id: totrans-193
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 基于梯度的方法
- en: In contrast to gradient-free algorithms, approaches that approximate the gradient
    of hyper-parameters to be searched are referred to as gradient-based optimizations.
    So far, the only two-stage approach based on gradients is Faster AutoAugment (Faster
    AA) [hataya2020faster](#bib.bib22) . This achieves a more efficient augmentation
    search for image classification tasks than prior methods including AutoAugment
    [cubuk2019autoaugment](#bib.bib20) , Fast AA [lim2019fast](#bib.bib21) and PBA
    [ho2019population](#bib.bib23) . The authors of Faster AA adapt an innovative
    gradient approximation method, namely Relaxed Bernoulli distribution [jang2016categorical](#bib.bib70)
    , to relax the non-differentiable distributions of hyper-parameters and use their
    gradients as input to a standard optimization algorithm. The consecutive two phases
    can therefore be done within a single pass. Faster AA model jointly optimizes
    the hyper-parameters of the augmentation policy (i.e. generation phase) and weights
    of the classification model (i.e. application phase). The simplification of the
    policy search space significantly reduces the search cost especially when compared
    to previous algorithms whilst maintaining the performance. What should be emphasized
    here is that the model trained during the search in Faster AA is actually abandoned
    later. To get the final classification result, the learned policy is applied to
    train the target classification model again. Hence there are still two stages
    involved in the Faster AA scheme.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 与无梯度算法相比，近似超参数梯度的算法称为基于梯度的优化。目前唯一基于梯度的两阶段方法是 Faster AutoAugment（Faster AA）[hataya2020faster](#bib.bib22)。与之前的方法相比，包括
    AutoAugment [cubuk2019autoaugment](#bib.bib20)、Fast AA [lim2019fast](#bib.bib21)
    和 PBA [ho2019population](#bib.bib23)，Faster AA 在图像分类任务中实现了更高效的增强搜索。Faster AA 的作者采用了一种创新的梯度近似方法，即
    Relaxed Bernoulli 分布 [jang2016categorical](#bib.bib70)，以放宽超参数的非可微分分布，并将其梯度作为输入传递给标准优化算法。因此，连续的两个阶段可以在一次通过中完成。Faster
    AA 模型联合优化增强策略的超参数（即生成阶段）和分类模型的权重（即应用阶段）。与以前的算法相比，策略搜索空间的简化显著降低了搜索成本，同时保持了性能。需要强调的是，在
    Faster AA 搜索过程中训练的模型实际上会在后期被弃用。为了获得最终的分类结果，需要将学习到的策略应用于再次训练目标分类模型。因此，Faster AA
    方案中仍涉及两个阶段。
- en: 4.1.3 Search-free
  id: totrans-195
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 无需搜索
- en: Despite the advantages of the aforementioned approaches, the added complexity
    of standard two-stage AutoDA methods might need prohibitive computing resources,
    for example the original implementation of AA in [cubuk2019autoaugment](#bib.bib20)
    . Subsequent works mainly aim to accelerate the search cost [lim2019fast](#bib.bib21)
    ; [ho2019population](#bib.bib23) and utilize gradient approximation [hataya2020faster](#bib.bib22)
    . However, these approaches still require an expensive search stage, which usually
    relies on a simplified proxy task to alleviate efficiency issues. This setting
    presumes that the learned DA policy based on the proxy task can be transferred
    to the larger target dataset. However, such assumptions are challenged in [cubuk2020randaugment](#bib.bib31)
    . According to the findings in [cubuk2020randaugment](#bib.bib31) , a proxy task
    might produce sub-optimal DA policies.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述方法有其优势，但标准的两阶段 AutoDA 方法的附加复杂性可能需要高昂的计算资源，例如 [cubuk2019autoaugment](#bib.bib20)
    中的原始实现。后续工作主要旨在加速搜索成本 [lim2019fast](#bib.bib21)；[ho2019population](#bib.bib23)
    和利用梯度近似 [hataya2020faster](#bib.bib22)。然而，这些方法仍需要昂贵的搜索阶段，这通常依赖于简化的代理任务来缓解效率问题。这个设置假定基于代理任务学习到的
    DA 策略可以转移到更大的目标数据集。然而，这种假设在 [cubuk2020randaugment](#bib.bib31) 中受到了挑战。根据 [cubuk2020randaugment](#bib.bib31)
    的发现，代理任务可能会产生次优的 DA 策略。
- en: To solve the aforementioned problems, several works aim to re-formulate the
    search problem in AutoDA. These approaches are acknowledged as search-free methods
    due to the complete exclusion of the search phase. By challenging the optimality
    of traditional AutoDA methods, search-free approaches re-parameterize the entire
    search space, resulting in ea small number of hyper-parameters, which can be manually
    adjusted. Therefore, there is no need to conduct the search anymore [gudovskiy2021autodo](#bib.bib62)
    . Additionally, it is now feasible to directly learn from the full target dataset
    instead of a reduced proxy task. Therefore, AutoDA models may learn an augmentation
    policy more tailored to the task of interest instead of through small proxy tasks.
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决上述问题，一些研究旨在重新制定 AutoDA 中的搜索问题。这些方法被称为无搜索方法，因为它们完全排除了搜索阶段。通过挑战传统 AutoDA 方法的最优性，无搜索方法重新参数化了整个搜索空间，从而减少了超参数的数量，这些超参数可以手动调整。因此，不再需要进行搜索
    [gudovskiy2021autodo](#bib.bib62)。此外，现在可以直接从完整的目标数据集中进行学习，而不是从减少的代理任务中学习。因此，AutoDA
    模型可能会学习到更适合于感兴趣任务的增强策略，而不是通过小的代理任务来学习。
- en: Existing works such as [lingchen2020uniformaugment](#bib.bib58) and [cubuk2020randaugment](#bib.bib31)
    both belong to the search-free category. Both approaches completely re-parameterize
    the entire search space so that there is no need to perform resource-intensive
    searches at all. RandAugment (RA) replaces the enormous search space with a small
    search space controlled by only two parameters. Both parameters are human-interpretable
    such that a simple grid search is quite effective. Inspired by RA, UniformAugment
    (UA) further reduces the complexity of the search space by assuming the approximate
    invariance of the augmentation space, where uniform sampling is sufficient. Both
    methods completely avoid a search phase and dramatically increase the efficiency
    of AutoDA algorithms while maintaining their performance.
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的研究如 [lingchen2020uniformaugment](#bib.bib58) 和 [cubuk2020randaugment](#bib.bib31)
    都属于无搜索类别。这两种方法完全重新参数化了整个搜索空间，从而完全不需要进行资源密集型的搜索。RandAugment (RA) 将巨大的搜索空间替换为仅由两个参数控制的小搜索空间。这两个参数是人类可解释的，因此简单的网格搜索效果相当好。受到
    RA 的启发，UniformAugment (UA) 通过假设增强空间的近似不变性，进一步减少了搜索空间的复杂性，其中均匀采样是足够的。这两种方法完全避免了搜索阶段，显著提高了
    AutoDA 算法的效率，同时保持了其性能。
- en: 4.2 One-stage Methods
  id: totrans-199
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 一阶段方法
- en: The biggest difference between two-stage and one-stage approaches is the joint
    optimization process in the latter. Previous approaches in the two-stage category
    mainly rely on an additional surrogate model for policy sampling. They then evaluate
    the sampled policies via full training on another classification network. The
    expensive training and evaluation procedure leads to efficiency bottlenecks of
    AutoDA techniques. To mitigate this issue, one-stage approaches complete the policy
    generation and application in one single step, eliminating the need for repetitive
    model training. In standard one-stage schemes, the weights of the classification
    network and the hyper-parameters of the augmentation policy are optimized simultaneously.
    This is implemented by a bi-level optimization scheme [colson2007overview](#bib.bib71)
    .
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: 两阶段方法和一阶段方法之间最大的区别在于后者的联合优化过程。之前的两阶段方法主要依赖于额外的代理模型来进行策略采样。然后，他们通过对另一个分类网络进行完整训练来评估采样的策略。昂贵的训练和评估过程导致了
    AutoDA 技术的效率瓶颈。为了解决这个问题，一阶段方法在一个步骤中完成策略生成和应用，消除了重复模型训练的需要。在标准的一阶段方案中，分类网络的权重和增强策略的超参数同时进行优化。这是通过双层优化方案实现的
    [colson2007overview](#bib.bib71)。
- en: At the inner level, they seek to optimize the weights of the discriminative
    networks, whilst at the outer level looking for hyper-parameters that describe
    the optimal augmentation policy, under which they can obtain the best performed
    model as solution to the inner problem. Due to the dependency of inner and outer
    level optimization, the learning of these two goals are conducted in an interleaved
    way. Specifically, a separate augmentation network is adapted to describe the
    probability distribution of sampled policies. The parameters of such a policy
    model are regarded as hyper-parameters, which are updated after a given number
    of epochs of inner training [lin2019online](#bib.bib54) ; [zhang2019adversarial](#bib.bib53)
    . In this bi-level framework, the distribution hyper-parameters and network weights
    are optimized simultaneously. The minimization of training loss (inner objective)
    can be easily achieved through classical Stochastic Gradient Descent (SGD), while
    the vanilla gradient of outer objective is relatively hard to obtain, as the model
    accuracy is non-differentiable with regard to augmentation hyper-parameters. Therefore,
    one-stage AutoDA models need to leverage gradient approximation to estimate such
    gradients for later optimization. In other words, all one-stage approaches in
    AutoDA are based on gradients.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: 在内层，他们寻求优化判别网络的权重，而在外层则寻找描述最佳数据增强策略的超参数，在这种策略下，他们可以获得最佳表现的模型作为内层问题的解决方案。由于内层和外层优化的依赖关系，这两个目标的学习是交替进行的。具体来说，一个独立的数据增强网络被调整以描述采样策略的概率分布。这种策略模型的参数被视为超参数，在内层训练经过一定数量的周期后进行更新[lin2019online](#bib.bib54)；[zhang2019adversarial](#bib.bib53)
    。在这个双层框架中，分布超参数和网络权重被同时优化。训练损失（内层目标）的最小化可以通过经典的随机梯度下降（SGD）轻松实现，而外层目标的原始梯度则相对难以获得，因为模型准确性对于增强超参数是不可微分的。因此，一阶段的AutoDA模型需要利用梯度近似来估计这些梯度以进行后续优化。换句话说，AutoDA中的所有一阶段方法都是基于梯度的。
- en: 4.2.1 Gradient-based
  id: totrans-202
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 基于梯度的方法
- en: As its name suggests, gradient-based models optimize the augmentation policy
    from the perspective of gradients. The reason it has to rely on gradient approximation
    is because the original model accuracy is non-differentiable with regard to augmentation
    policy distribution. Only after the relaxation of distribution, can the gradient
    of validation accuracy or training loss with regard to hyper-parameters be obtained.
    There are several advantages of gradient-based approaches. Due to the differentiable
    accuracy, gradient-based method can directly optimize the hyper-parameters according
    to the estimated gradient. There is no need to invest a significant amount of
    time in training child models to test sampled policies. This substantially reduces
    the workload of policy evaluation. The removal of expensive evaluation procedures
    also enables the AutoDA algorithm to scale up to even larger datasets and deeper
    models. The first one-stage AutoDA work based on gradients was Online Hyper-parameter
    Learning AutoAugment (OHL-AA) [lin2019online](#bib.bib54) in 2019, based on the
    REINFORCE gradient estimator [williams1992simple](#bib.bib55) . The augmentation
    policy model in OHL-AA is similar to previous works [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) , while the original search problem is reformulated
    as a bi-level optimization task. Published in the same year, Adversarial AutoAugment
    (AAA) [zhang2019adversarial](#bib.bib53) employs the same gradient approximator
    in an adversarial framework, which further eases the efficiency issue. As the
    NAS technique develops in 2020, Differentiable Automatic Data Augmentation (DADA)
    [li2020dada](#bib.bib57) and Automated Dataset Optimization (AutoDO) [gudovskiy2021autodo](#bib.bib62)
    use the more advanced DARTS estimator [liu2018darts](#bib.bib56) .
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，基于梯度的模型从梯度的角度优化增强策略。它必须依赖梯度近似的原因是原始模型的准确性在增强策略分布方面是不可微分的。只有在分布松弛之后，才能获得验证准确性或训练损失相对于超参数的梯度。基于梯度的方法有几个优点。由于准确性是可微分的，基于梯度的方法可以根据估计的梯度直接优化超参数。不需要花费大量时间训练子模型以测试采样策略。这大大减少了策略评估的工作量。去除昂贵的评估程序还使AutoDA算法能够扩展到更大的数据集和更深的模型。基于梯度的第一个单阶段AutoDA工作是2019年的Online
    Hyper-parameter Learning AutoAugment (OHL-AA) [lin2019online](#bib.bib54)，基于REINFORCE梯度估计器
    [williams1992simple](#bib.bib55)。OHL-AA中的增强策略模型类似于之前的工作 [cubuk2019autoaugment](#bib.bib20)；
    [lim2019fast](#bib.bib21)，而原始搜索问题被重新表述为一个双层优化任务。同年发表的Adversarial AutoAugment (AAA)
    [zhang2019adversarial](#bib.bib53)在对抗框架中使用相同的梯度近似器，进一步缓解了效率问题。随着2020年NAS技术的发展，Differentiable
    Automatic Data Augmentation (DADA) [li2020dada](#bib.bib57) 和Automated Dataset
    Optimization (AutoDO) [gudovskiy2021autodo](#bib.bib62) 使用了更先进的DARTS估计器 [liu2018darts](#bib.bib56)。
- en: 5 Two-stage Approaches
  id: totrans-204
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 两阶段方法
- en: In this section, we review two-stage strategies in detail, with focus on the
    pipeline of the algorithms. We start from the fundamental definition of the augmentation
    parameters and corresponding search space used in each method. After that, the
    core algorithms are explored along with their overall workflow. Following that,
    the major contribution of each method is covered based on experimental results
    provided in the original paper. Then, we provide a systematic analysis and evaluate
    the pros and cons of the different two-stage category approaches. Finally, we
    compare all available two-stage algorithms from the perspective of their accuracy
    and efficiency, and give suggestions on model selection from a practical application
    perspective.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们详细回顾了两阶段策略，重点关注算法的管道。我们从增强参数的基本定义和每种方法中使用的对应搜索空间开始。之后，探索核心算法及其整体工作流程。接下来，根据原始论文提供的实验结果，介绍每种方法的主要贡献。然后，我们提供系统分析，评估不同两阶段分类方法的优缺点。最后，从准确性和效率的角度比较所有可用的两阶段算法，并从实际应用的角度提供模型选择建议。
- en: 5.1 Gradient-free Optimization
  id: totrans-206
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 无梯度优化
- en: 5.1.1 Transformation Adversarial Networks for Data Augmentations (TANDA)
  id: totrans-207
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.1 用于数据增强的变换对抗网络 (TANDA)
- en: TANDA is considered to be the earliest work supporting automatic discovery of
    optimised data augmentation policies. Even though other works aimed at automating
    data augmentation, most of them focused on either creating innovative augmentation
    algorithms [lemley2017smart](#bib.bib10) , or generating synthetic training data
    based on a given set of starting images [tran2017bayesian](#bib.bib24) . TANDA,
    on the other hand, used only the basic image operations based on a user’s specification,
    and output a sequence of transformation functions as the final augmentation policy.
    This made it more relevant to many scenarios with diverse data augmentation demands.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: TANDA 被认为是最早支持自动发现优化数据增强策略的工作之一。尽管其他工作也致力于自动化数据增强，但它们大多集中于创建创新的增强算法 [lemley2017smart](#bib.bib10)
    ，或基于一组给定的起始图像生成合成训练数据 [tran2017bayesian](#bib.bib24) 。而 TANDA 则只使用基于用户指定的基本图像操作，并输出一系列变换函数作为最终的增强策略。这使得它更适用于具有多样化数据增强需求的许多场景。
- en: An augmentation policy is represented as a sequence of image processing operations
    in [ratner2017learning](#bib.bib52) . Users need to specify a range of augmentation
    operations for the TANDA model to select from, which are also called as Transformation
    Functions (TFs). In order to support various types of TFs, TANDA regards them
    as black-box functions that ignores application details, and only emphasizes the
    final effect of such transformations. For instance, a $30^{\circ}$ rotation can
    be achieved with one single TF, or alternatively it can be split into a combination
    of three $10^{\circ}$ rotation transformations. The policy modelling in TANDA
    might not be deterministic or differentiable, but it provides an applicable way
    of tuning the TF hyper-parameters.
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 增强策略在 [ratner2017learning](#bib.bib52) 中被表示为一系列图像处理操作。用户需要为 TANDA 模型指定一系列增强操作，这些操作也称为变换函数（TFs）。为了支持各种类型的
    TFs，TANDA 将它们视为忽略应用细节的黑箱函数，只强调这些变换的最终效果。例如，$30^{\circ}$ 的旋转可以通过一个单一的 TF 实现，或者可以将其拆分为三个
    $10^{\circ}$ 旋转变换的组合。TANDA 中的策略建模可能不是确定性的或可微分的，但它提供了一种调节 TF 超参数的可行方法。
- en: The major objective of TANDA is to learn a model that can generate augmentation
    policies composed of a fixed number of TFs. Depending on the types of TFs, the
    DA policy is modelled in two different ways. The first policy model, namely the
    straightforward mean field model, assumes each TF in an augmentation policy is
    selected independently. Therefore, the probability of each operation is optimized
    individually. Mean field modelling largely reduces the number of learnable hyper-parameters
    during the search. However, this independent representation can be biased, especially
    when TFs affect each other. In practical scenarios, a certain image processing
    operation can lead to totally different effects if applied with other TFs. The
    actual sequence of TF application also matters when some of the TFs are not commutative.
    To fully represent the interaction among augmentation TFs, TANDA offers another
    option to model DA policies, the Long Short-Term Memory (LSTM) network. The LSTM
    model in TANDA outputs probability distributions over all TFs, which emphases
    the relationship among searched TFs.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: TANDA 的主要目标是学习一个可以生成由固定数量的 TFs 组成的增强策略的模型。根据 TFs 的类型，数据增强策略可以通过两种不同的方式建模。第一种策略模型，即简单的均值场模型，假设增强策略中的每个
    TF 是独立选择的。因此，每个操作的概率是单独优化的。均值场建模大大减少了搜索过程中的可学习超参数数量。然而，这种独立表示可能存在偏差，特别是当 TFs 互相影响时。在实际场景中，某些图像处理操作如果与其他
    TFs 一起应用，可能会产生完全不同的效果。当一些 TFs 不是可交换的时，TF 应用的实际顺序也很重要。为了全面表示增强 TFs 之间的互动，TANDA
    提供了另一种建模 DA 策略的选项，即长短期记忆（LSTM）网络。TANDA 中的 LSTM 模型输出所有 TFs 的概率分布，这强调了所搜索 TFs 之间的关系。
- en: '![Refer to caption](img/fb33627c22977bf14479c18eaa49828e.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fb33627c22977bf14479c18eaa49828e.png)'
- en: 'Figure 3: TANDA workflow [ratner2017learning](#bib.bib52) . Upper/lower sections
    indicate the policy generation/application stage respectively.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: TANDA 工作流 [ratner2017learning](#bib.bib52) 。上/下部分分别表示策略生成/应用阶段。'
- en: 'The TANDA model applies standard theGAN architecture, consisting of a generator
    $G$ and a discriminative model $D$. The general workflow of TANDA is illustrated
    in Fig. [3](#S5.F3 "Figure 3 ‣ 5.1.1 Transformation Adversarial Networks for Data
    Augmentations (TANDA) ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage Approaches
    ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks"). There are two stages involved in TANDA: policy generation
    and application. The policy generation phase can be viewed as a classical min-max
    game in GAN. The goal of sequence generator model $G$ is to sample DA policies
    that are most likely to fool the discriminator model $D$, while the $D$ tries
    to distinguish the transformed images out of the original data. This is done by
    assigning reward values to the input data. Ideally, in-distribution data points
    will get higher values whereas the images generated via augmentation will be assigned
    lower rewards. The reward information is then used to update $G$ for the next
    policy sampling. After the searching is completed, the final generator is used
    to augment the original training set to better train the classification network.'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: TANDA 模型采用了标准的 theGAN 架构，由一个生成器 $G$ 和一个判别模型 $D$ 组成。TANDA 的一般工作流程如图 [3](#S5.F3
    "Figure 3 ‣ 5.1.1 Transformation Adversarial Networks for Data Augmentations (TANDA)
    ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage Approaches ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")
    所示。TANDA 包括两个阶段：策略生成和应用。策略生成阶段可以看作是 GAN 中的经典最小-最大博弈。序列生成模型 $G$ 的目标是采样最可能欺骗判别模型
    $D$ 的数据增强（DA）策略，而 $D$ 则试图区分原始数据中的变换图像。这是通过为输入数据分配奖励值来完成的。理想情况下，分布内的数据点将获得较高的值，而通过增强生成的图像将获得较低的奖励。然后利用奖励信息来更新
    $G$ 以进行下一次策略采样。搜索完成后，最终生成器将用于增强原始训练集，以更好地训练分类网络。
- en: There are various advantages of TANDA. Firstly, the performance improvement
    out of TANDA is convincing. From the experimental results in [ratner2017learning](#bib.bib52)
    , TANDA outperforms most contemporaneous heuristic DA approaches. In terms of
    problem formulation, the LSTM policy model tends to be more effective than mean
    field representation in most cases, which empirically encourages the sequence
    modelling in the AutoDA scheme. The proposal of these two policy models is considered
    to be the most significant contribution of TANDA. The representation of augmentation
    transformations inspired AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) ,
    which also utilized the LSTM model for policy prediction. Furthermore, the positive
    influence resulted from sequential modelling provides empirical support for later
    Population-Based Augmentation (PBA) [ho2019population](#bib.bib23) , which outputs
    application schedules rather than a fixed policy. The use of unlabelled data is
    also a favorable characteristic especially for tasks with limited data. Additionally,
    a trained TANDA model shows a certain degree of robustness against TF mis-specification.
    In TANDA, there is no limitation on the selection of the TF range or requirement
    for safety property of available transformations, therefore it is much easier
    for users to use in practice. More importantly, TANDA is open-source and can be
    adapted and applied to any task with limited datasets, not only in the imaging
    domain but also for text data.
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: TANDA 具有多种优势。首先，TANDA 带来的性能提升是令人信服的。从 [ratner2017learning](#bib.bib52) 的实验结果来看，TANDA
    超过了大多数同时期的启发式 DA 方法。在问题表述方面，LSTM 策略模型在大多数情况下比均值场表示更为有效，这在经验上鼓励了 AutoDA 方案中的序列建模。这两个策略模型的提出被认为是
    TANDA 的最重要贡献。增强变换的表示启发了 AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20)，该方法也利用
    LSTM 模型进行策略预测。此外，序列建模带来的积极影响为后来的基于人群的增强（PBA）[ho2019population](#bib.bib23) 提供了实证支持，后者输出应用计划而不是固定策略。使用无标签数据也是一个有利特性，特别是对于数据有限的任务。此外，训练好的
    TANDA 模型表现出对 TF 错误规格的某种程度的鲁棒性。在 TANDA 中，对 TF 范围的选择没有限制，也不要求现有变换具有安全属性，因此用户在实际使用中更加方便。更重要的是，TANDA
    是开源的，可以适应并应用于任何有限数据集的任务，不仅仅是在成像领域，还包括文本数据。
- en: 5.1.2 AutoAugment (AA)
  id: totrans-215
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.2 AutoAugment (AA)
- en: AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) is one of the most popular
    AutoDA approaches. The majority of subsequent works in this field [lim2019fast](#bib.bib21)
    ; [ho2019population](#bib.bib23) ; [hataya2020faster](#bib.bib22) adapt a similar
    setup as AA, especially the definition of the search space and policy model. However,
    the AA algorithm itself does not provide an optimal solution to the policy search
    problem due to its severe efficiency issues. However, as the authors of AA emphasize,
    the fundamental contribution of AA lies in the automated approach to DA and the
    development of the search space, rather than the search strategy.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) 是最受欢迎的AutoDA方法之一。该领域的大多数后续工作
    [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) ; [hataya2020faster](#bib.bib22)
    采用了与AA类似的设置，特别是在搜索空间和策略模型的定义上。然而，AA算法本身由于其严重的效率问题，并未提供对策略搜索问题的最终解决方案。然而，正如AA的作者强调的，AA的根本贡献在于其自动化的DA方法和搜索空间的发展，而不是搜索策略。
- en: AA formulates the automation of DA policy design as a discrete search problem.
    In AA, an augmentation policy is a composition of $5$ sub-policies, each of which
    is applied to one training batch. One sub-policy consists of two sequential transformation
    functions, such as geometric translation, flipping or colour distortion. Each
    TF in an augmentation policy is described by two hyper-parameters, i.e. the probability
    of applying this transformation and the magnitude of the application. Inspired
    by TANDA, the application sequence of these TFs is emphasized. For simplification,
    the range of probability and magnitude is discrete. The probability is evenly
    discretized into $11$ values, ranging from $0$ to $1$, whilst the magnitude is
    selected from positive integers between $1$ to $10$. The $14$ operations implemented
    in AA are all from standard Python Image Library (PIL). Two additional augmentation
    techniques, Cutout [devries2017improved](#bib.bib45) and SamplePairing [inoue2018data](#bib.bib46)
    , are also considered due to their effectiveness in classification tasks. Overall,
    there are $16$ distinct TFs in AA’s search space. Finding an augmentation policy
    via AA thus has $(16\times 10\times 11)^{10}\approx 2.9\times 10^{32}$ possibilities.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: AA 将DA策略设计的自动化形式化为一个离散搜索问题。在AA中，增强策略是由$5$个子策略组成，每个子策略应用于一个训练批次。一个子策略包括两个连续的变换函数，如几何变换、翻转或颜色失真。增强策略中的每个TF由两个超参数描述，即应用该变换的概率和应用的幅度。受TANDA的启发，这些TF的应用顺序被强调。为了简化，概率和幅度的范围是离散的。概率均匀离散为$11$个值，范围从$0$到$1$，而幅度从$1$到$10$的正整数中选择。AA中实现的$14$种操作均来自标准的Python图像库（PIL）。由于其在分类任务中的有效性，两个额外的增强技术，Cutout
    [devries2017improved](#bib.bib45) 和SamplePairing [inoue2018data](#bib.bib46) ，也被考虑在内。总体而言，AA的搜索空间中有$16$种不同的TF。因此，通过AA寻找一个增强策略有$(16\times
    10\times 11)^{10}\approx 2.9\times 10^{32}$种可能性。
- en: '![Refer to caption](img/4a37a11040e8c14515a92e5cdafa5267.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4a37a11040e8c14515a92e5cdafa5267.png)'
- en: 'Figure 4: AutoAugment workflow [cubuk2019autoaugment](#bib.bib20) . Upper/lower
    sections indicate the policy generation/application stage respectively.'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：AutoAugment工作流程 [cubuk2019autoaugment](#bib.bib20)。上/下部分分别表示策略生成/应用阶段。
- en: To automate the process of constructing DA policy, AA has to search over an
    enormous search space. It now becomes a discrete search problem using the aforementioned
    formulation. At a high level, the workflow of AA is displayed in Fig. [4](#S5.F4
    "Figure 4 ‣ 5.1.2 AutoAugment (AA) ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage
    Approaches ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks"). One of the key components in the AutoDA model is
    the search algorithm. In the search phase, the search algorithm is used to generate
    an augmentation policy, which is then evaluated for updates. AA chooses a simple
    Recurrent Neural Network (RNN) as its search algorithm/controller to sample policy
    $P$. The evaluation procedure is done through model training, but using reduced
    data and a simplified model. Such a model is also called a child model, due to
    its similar but much simpler architecture when compared to the final classification
    network. After testing the trained child model on a validation set, the validation
    accuracy is regarded as reward $R$ to update the search controller. Generally,
    the reward signal $R$ reflects how effective a policy $P$ is in improving the
    performance of a child model. The training of the child model has to be done multiple
    times, because $R$ is not differentiable over policy hyper-parameters, i.e. probability
    and magnitude.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 为了自动化构建 DA 策略的过程，AA 必须在巨大的搜索空间中进行搜索。现在，这变成了一个离散搜索问题，使用前述的公式。在高层次上，AA 的工作流程如图
    [4](#S5.F4 "图 4 ‣ 5.1.2 AutoAugment (AA) ‣ 5.1 无梯度优化 ‣ 5 两阶段方法 ‣ 深度学习图像分类任务的自动数据增强算法调查")
    所示。AutoDA 模型中的一个关键组件是搜索算法。在搜索阶段，搜索算法用于生成增强策略，然后对其进行评估以进行更新。AA 选择了一个简单的递归神经网络（RNN）作为其搜索算法/控制器，以采样策略
    $P$。评估过程通过模型训练完成，但使用了减少的数据和简化的模型。这样的模型也称为子模型，因为它与最终的分类网络相比具有类似但更简单的架构。在验证集上测试训练后的子模型后，验证准确性被视为奖励
    $R$ 以更新搜索控制器。一般来说，奖励信号 $R$ 反映了策略 $P$ 在提高子模型性能方面的有效性。子模型的训练必须多次进行，因为 $R$ 在策略超参数，即概率和幅度上不可微分。
- en: Through extensive experiments, AA achieves excellent results. It can be directly
    applied on the target data and achieves competitive model accuracy. Experiments
    in [cubuk2019autoaugment](#bib.bib20) report state-of-the-art results for common
    datasets, including CIFAR-10/100, ImageNet and SVHN. AA not only shows superiority
    in terms of DA policy design, but also provides the option of transferring the
    searched policy to other similar data. For example, the augmentation policy leaned
    on CIFAR-10 can function well on similar data CIFAR-100\. There is no need to
    conduct expensive searches on the later, as the policies discovered by AA are
    able to be generalized over multiple models and datasets. This is a viable alternative
    especially when direct search is unaffordable. Another advantage of AA is its
    simple structure and procedure. The search phase is actually conducted over a
    subset of data, using a simplified child model. Those simplifications provide
    direct evaluation of augmentation policies, without the recourse to any complicated
    approximation algorithms. More importantly, AA standardizes the modelling of the
    augmentation policy and search space in the AutoDA field. The policy model it
    designs has been widely acknowledged as the de facto solution.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 通过广泛的实验，AA 取得了优秀的结果。它可以直接应用于目标数据，并实现了具有竞争力的模型准确性。实验 [cubuk2019autoaugment](#bib.bib20)
    报告了在 CIFAR-10/100、ImageNet 和 SVHN 等常见数据集上的最先进结果。AA 不仅在 DA 策略设计方面显示了优越性，还提供了将搜索到的策略转移到其他类似数据的选项。例如，基于
    CIFAR-10 训练的增强策略在类似数据 CIFAR-100 上也能很好地发挥作用。对于后者，无需进行昂贵的搜索，因为 AA 发现的策略能够在多个模型和数据集上进行泛化。这是一种可行的替代方案，特别是当直接搜索不可承受时。AA
    的另一个优点是其简单的结构和过程。搜索阶段实际上是在数据的一个子集上进行的，使用简化的子模型。这些简化提供了对增强策略的直接评估，而无需使用任何复杂的近似算法。更重要的是，AA
    标准化了 AutoDA 领域中的增强策略和搜索空间建模。它设计的策略模型已被广泛认可为事实上的解决方案。
- en: However, AA has serious disadvantages. The choice of algorithms in AA can be
    substantially improved. It applies Reinforcement Learning as the search algorithm,
    but this selection is made mainly out of convenience. The authors of AA also indicate
    that other search algorithms, such as genetic programming [real2019regularized](#bib.bib72)
    or even random search [bergstra2012random](#bib.bib73) ; [mania2018simple](#bib.bib74)
    , may further improve the final performance. Furthermore, the reduced dataset
    and simplified model used during the search phase can result in sub-optimal results.
    According to [cubuk2020randaugment](#bib.bib31) , the power of an augmentation
    policy largely depends on the size of model and dataset. Therefore, simplification
    in AA is likely to introduce bias into the found policy. Additionally, the final
    policy is formed by a simple concatenation of the $5$ best policies found in the
    data batch. The application schedule of these policies is not considered in AA.
    The greatest shortcoming of AA lies in its efficiency. Evaluation of augmentation
    policies relies on expensive model training. Due to the stochasiticity of DA policies
    introduced by the probability hyper-parameter, such training has to be conducted
    for a certain number of epochs till the policy starts to take effect. In most
    cases, running AA is extremely resource-intensive, which raises timing and cost
    issues. This also becomes the major challenge for AutoDA tasks and promotes multiple
    later methods aiming at efficiency improvement.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，AA存在严重的缺陷。AA中的算法选择可以大大改进。它应用了强化学习作为搜索算法，但这一选择主要是出于便利。AA的作者还指出，其他搜索算法，如遗传编程
    [real2019regularized](#bib.bib72) 或甚至随机搜索 [bergstra2012random](#bib.bib73) ; [mania2018simple](#bib.bib74)
    ，可能会进一步提升最终性能。此外，搜索阶段使用的简化数据集和模型可能导致次优结果。根据 [cubuk2020randaugment](#bib.bib31)
    ，增强策略的效果在很大程度上依赖于模型和数据集的大小。因此，AA中的简化可能会引入偏差。除此之外，最终策略是通过简单地将数据批次中找到的 $5$ 个最佳策略串联而成的。这些策略的应用调度在AA中没有考虑。AA最大的缺点在于其效率。增强策略的评估依赖于昂贵的模型训练。由于DA策略由概率超参数引入的随机性，这种训练必须进行一定数量的周期，直到策略开始生效。在大多数情况下，运行AA极其耗费资源，这引发了时间和成本问题。这也成为AutoDA任务的主要挑战，并推动了多个后续方法以提高效率。
- en: 5.1.3 Augmentation-wise Weight Sharing (AWS)
  id: totrans-223
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.3 Augmentation-wise Weight Sharing（AWS）
- en: A major reason for the inefficiency of AA is the repeated training process during
    policy evaluation. To enhance the efficiency of evaluation, some methods [ho2019population](#bib.bib23)
    ; [lin2019online](#bib.bib54) ; [zhang2019adversarial](#bib.bib53) sacrifice reliability
    to some extent. On the contrary, Augmentation-wise Weight Sharing (AWS) designs
    a proxy task based on the weight sharing concept in NAS, proposing a faster but
    still accurate evaluation process. The augmentation policies found by AWS also
    achieve competitive accuracy when compared to other AutoDA methods.
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: AA效率低下的主要原因是策略评估期间的重复训练过程。为了提高评估效率，一些方法 [ho2019population](#bib.bib23) ; [lin2019online](#bib.bib54)
    ; [zhang2019adversarial](#bib.bib53) 在某种程度上牺牲了可靠性。相反，Augmentation-wise Weight
    Sharing（AWS）基于NAS中的权重共享概念设计了一个代理任务，提出了一种更快但仍然准确的评估过程。AWS找到的增强策略与其他AutoDA方法相比，也达到了具有竞争力的准确性。
- en: '![Refer to caption](img/ae2d16cf451800991a3035c28c3d7c2a.png)'
  id: totrans-225
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ae2d16cf451800991a3035c28c3d7c2a.png)'
- en: 'Figure 5: Augmentation-wise Weight Sharing workflow [tian2020improving](#bib.bib30)
    . Upper/lower sections indicate the policy generation/application stage respectively.'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：Augmentation-wise Weight Sharing工作流程 [tian2020improving](#bib.bib30)。上部/下部部分分别表示策略生成/应用阶段。
- en: Inspired by the idea of early stopping, the authors of AWS hypothesize that
    the benefit of DA is mainly shown in the later phase of training. This assumption
    is supported through empirical observations in [tian2020improving](#bib.bib30)
    . Motivated by this observation, AWS proposes a new proxy task to test the sampled
    policies. In this proxy task, the original search stage is split into two parts.
    The AWS pipeline is displayed in Fig. [5](#S5.F5 "Figure 5 ‣ 5.1.3 Augmentation-wise
    Weight Sharing (AWS) ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage Approaches
    ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based Image
    Classification Tasks"). In the early stage, the child model is trained using a
    fixed augmentation strategy, i.e. a shared policy. During this phase, the search
    controller will not sample policies or be updated. Only the child model used for
    policy evaluation will be trained for a certain number of epochs. The network
    weights obtained after the first part of training will be shared and reused during
    the later evaluation, so that AWS model does not need to repeat the full training
    for each of the sampled policies. The major challenge here is to select a representative
    shared policy for the initial stage. According to the findings in [tian2020improving](#bib.bib30)
    , simple uniform sampling can work for most tasks.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 受到早停法思想的启发，AWS的作者们假设DA的好处主要体现在训练的后期。这个假设通过在[tian2020improving](#bib.bib30)中的经验观察得到了支持。受这一观察启发，AWS提出了一种新的代理任务来测试采样策略。在这个代理任务中，原始的搜索阶段被分为两个部分。AWS管道如图[5](#S5.F5
    "Figure 5 ‣ 5.1.3 Augmentation-wise Weight Sharing (AWS) ‣ 5.1 Gradient-free Optimization
    ‣ 5 Two-stage Approaches ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks")所示。在早期阶段，子模型使用固定的增强策略进行训练，即共享策略。在此阶段，搜索控制器不会采样策略或进行更新。只有用于策略评估的子模型会训练若干个周期。在训练的第一部分获得的网络权重将在后续评估中共享和重用，因此AWS模型不需要为每个采样策略重复完整训练。这里的主要挑战是选择一个具有代表性的共享策略作为初始阶段。根据[tian2020improving](#bib.bib30)的发现，简单的均匀采样可以适用于大多数任务。
- en: In the second part of searching, AWS samples augmentation policies via a controller,
    and updates the model according to an associated accuracy reward. The reward information
    is obtained from the shared model, instead of an untrained child model. Therefore,
    in order to evaluate the sampled policies, it is only necessary to resume training
    for a few epochs using these policies. Since the training of the child model in
    AWS is divided into two parts based on the different DA policies utilized, AWS
    is an augmentation-wise algorithm. The idea of weight sharing originates from
    NAS, where training from scratch is prohibitively expensive. This scheme substantially
    accelerates the overall evaluation procedure. The design of proxy tasks in AWS
    is flexible, so it can be combined with other search algorithms. Standard AWS
    follows a similar setting to the original AA [cubuk2019autoaugment](#bib.bib20)
    applying Reinforcement Learning (RL) techniques.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 在搜索的第二部分，AWS通过控制器采样增强策略，并根据相关的准确度奖励更新模型。奖励信息是从共享模型中获得的，而不是未训练的子模型。因此，为了评估采样策略，仅需使用这些策略恢复训练若干个周期。由于AWS中的子模型训练基于不同的DA策略被分为两个部分，AWS是一种增强-wise算法。权重共享的思想来源于NAS，其中从头开始训练成本极高。这种方案显著加速了整体评估过程。AWS中的代理任务设计具有灵活性，因此可以与其他搜索算法结合使用。标准的AWS遵循类似于原始AA[cubuk2019autoaugment](#bib.bib20)应用强化学习（RL）技术的设置。
- en: The major contribution of AWS is the effective period of the data augmentation
    technique. The empirical conclusion in [tian2020improving](#bib.bib30) is that
    the DA policies mainly improve the model in the late training phase. This phenomenon
    reflects the greatest innovation in AWS, its unique augmentation-wise proxy task
    that substitutes the traditional evaluation procedure. By sharing the policy at
    the early phase of searching, the child model only needs to be pre-trained once.
    The selection of the shared augmentation policy in the first-part searching is
    done via a uniform sampling on the search space. The network weights are then
    re-used in the later application stage to evaluate each of the sampled augmentation
    policies. There is no need to conduct child model training from scratch thousands
    of times. Compared to the original AA [cubuk2019autoaugment](#bib.bib20) , it
    is much more efficient to obtain reward signals in AWS through the use of weight-sharing
    strategies. The efficiency gains of AWS makes it have the potential to scale on
    even larger datasets. Moreover, according to [tian2020improving](#bib.bib30) ,
    the evaluation process in AWS is still reliable. This is because in the second
    part of searching, the child model will be fine-tuned by DA policies to reflect
    the strength of each of the policies.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: AWS的主要贡献在于数据增强技术的有效期。在[tian2020improving](#bib.bib30)中的实证结论是，DA策略主要在训练后期改善模型。这一现象反映了AWS中最大的创新，即其独特的增强代理任务替代了传统的评估过程。通过在搜索的早期阶段共享策略，子模型仅需预训练一次。第一阶段搜索中共享增强策略的选择通过对搜索空间的均匀采样完成。然后，在后续应用阶段，网络权重被重新使用来评估每一个采样的增强策略。无需从头开始进行数千次子模型训练。与原始AA
    [cubuk2019autoaugment](#bib.bib20) 相比，通过使用权重共享策略，AWS获得奖励信号的效率更高。AWS的效率提升使其在更大数据集上具有扩展的潜力。此外，根据[tian2020improving](#bib.bib30)的说法，AWS中的评估过程仍然可靠。这是因为在搜索的第二阶段，子模型将通过DA策略进行微调，以反映每个策略的强度。
- en: The disadvantages of AWS cannot be ignored however. Overall, there are excessive
    simplifications in AWS, aimed to increasing search efficiency. For example, sampled
    policies are evaluated by child models on the reduced data, and the early stage
    of training is substituted by shared model weights. Such settings however might
    lead to sub-optimal results. The final policy AWS model outputs may be more designed
    to the proxy task rather than the target dataset according to the findings in
    [cubuk2020randaugment](#bib.bib31) . In terms of the search algorithm, AWS utilizes
    the same RL framework as in AA, bringing not much improvement, especially when
    compared with methods such as Fast AA [lim2019fast](#bib.bib21) and PBA [ho2019population](#bib.bib23)
    . Lastly, AWS is not open-source, which makes it less accessible for users.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，AWS的缺点不能被忽视。总体而言，AWS中存在过度简化的问题，这些简化旨在提高搜索效率。例如，采样的策略通过在减少的数据上使用子模型进行评估，训练的早期阶段则由共享的模型权重代替。然而，这些设置可能导致次优的结果。根据在[cubuk2020randaugment](#bib.bib31)中的发现，最终的AWS模型输出的策略可能更多地设计为代理任务，而非目标数据集。
- en: 5.1.4 Greedy AutoAugment (GAA)
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.4 贪婪自动增强（GAA）
- en: To improve the search efficiency, Greedy AutoAugment (GAA) [naghizadeh2020greedy](#bib.bib60)
    ; [naghizadeh2021greedy](#bib.bib63) adapts a completely different algorithm.
    The GAA model applies a greedy search algorithm to exponentially reduce its complexity
    when sampling the next policy to be searched. From the experiments conducted in
    [naghizadeh2020greedy](#bib.bib60) , the TFs learned by GAA are able to further
    enhance the generalization ability of the classification. Moreover, the greedy
    idea in GAA can be a reliable complement to other search approaches in AutoDA
    tasks.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高搜索效率，贪婪自动增强（GAA）[naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    采用了一种完全不同的算法。GAA模型应用贪婪搜索算法来指数级减少采样下一个待搜索策略的复杂性。根据在[naghizadeh2020greedy](#bib.bib60)中进行的实验，GAA学习到的TF能够进一步增强分类的泛化能力。此外，GAA中的贪婪思想可以作为AutoDA任务中其他搜索方法的可靠补充。
- en: 'The policy model of GAA follows a similar setup in AA [cubuk2019autoaugment](#bib.bib20)
    . A complete augmentation policy is comprised of $k$ sub-policies, each of which
    contains two consecutive TFs. Each TF is described by two essential hyper-parameters:
    probability and magnitude. The values of these two parameters are modeled following
    the same discretization as described earlier. There are $11$ values for probability
    parameter, ranging from $0$ to $1$ with uniform spacing, whilst the discrete values
    for magnitude are positive integers, range from $1$ to $10$. However, GAA employs
    a wider range of augmentation transformations. There are $20$ available image
    transformation functions in GAA that can be selected to form the DA policy, including
    $4$ extra operations compared to original AA. Assuming each augmentation policy
    contains $L$ image operations, where $L$ is a positive integer greater than $0$,
    then the search space can be defined as $(20\times 11\times 10)^{L}$. In this
    setup, the expansion of the search space is exponential to the value of $L$, which
    can be infeasible when using larger $L$ values.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: GAA 的策略模型遵循 AA [cubuk2019autoaugment](#bib.bib20) 中类似的设置。完整的增强策略由 $k$ 个子策略组成，每个子策略包含两个连续的
    TF。每个 TF 由两个基本的超参数描述：概率和幅度。这两个参数的值采用与之前描述的相同的离散化方法。概率参数有 $11$ 个值，范围从 $0$ 到 $1$，间隔均匀，而幅度的离散值为正整数，范围从
    $1$ 到 $10$。然而，GAA 采用了更广泛的增强转换范围。GAA 中有 $20$ 个可用的图像变换函数可供选择以形成 DA 策略，比原始 AA 多出
    $4$ 个额外操作。假设每个增强策略包含 $L$ 个图像操作，其中 $L$ 是大于 $0$ 的正整数，那么搜索空间可以定义为 $(20\times 11\times
    10)^{L}$。在这种设置下，搜索空间的扩展是指数级的，使用较大的 $L$ 值时可能不可行。
- en: To tackle this problem, the search space in GAA is re-formulated into a much
    simpler setup. It has been argued in [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    that using separate probability parameters for each TF may not be necessary, especially
    when dealing with small amounts of data. Instead, all images in the original training
    set should be fully augmented till the enhancement of model performance becomes
    obvious. Therefore, GAA completely discards the probability hyper-parameter of
    each TF. Moreover, it adapts constant a value $1$ to represent the application
    probability of all available augmentation functions. Rather than optimising the
    probability hyper-parameter for each TF, GAA simply selects the TF that can give
    the best accuracy results. This is quite different from other AutoDA methods in
    how an augmentation policy is formed. By doing so, GAA successfully reduces the
    search space to $(20\times 10)^{L}$.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决这个问题，GAA 中的搜索空间被重新定义为一个简单的设置。研究指出，在处理小量数据时，使用每个 TF 的单独概率参数可能并不必要，[naghizadeh2020greedy](#bib.bib60)
    ; [naghizadeh2021greedy](#bib.bib63) 中认为。相反，应该对原始训练集中的所有图像进行充分的增强，直到模型性能的提升变得明显。因此，GAA
    完全舍弃了每个 TF 的概率超参数。此外，它采用常量值 $1$ 来表示所有可用增强函数的应用概率。GAA 不再为每个 TF 优化概率超参数，而是简单地选择能够提供最佳准确度结果的
    TF。这与其他 AutoDA 方法在形成增强策略方面有很大不同。通过这种方式，GAA 成功地将搜索空间减少到了 $(20\times 10)^{L}$。
- en: However, even with the reduced search space, the growth of such space is still
    exponential. GAA employs tree-based Breadth-First Search (BFS) to tackle this
    problem. In a standard BFS pipeline, the next search point is sampled in a greedy
    way, which means GAA will choose the TF that can bring the most performance gain
    to the child model. GAA only needs to evaluate the best image operation at each
    epoch, rather than all available TFs in the augmentation space. The greedy BFS
    changes the exponential growth of search space from $(20\times 10)^{L}$ to a linear
    one. The size of final search space in GAA is $20\times 10\times k$, where $k$
    is the number of sub-policies within one DA policy. By default, $k$ is set to
    $5$ in GAA for a fair comparison with AA.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管搜索空间已减少，但这种空间的增长仍然是指数级的。GAA 使用基于树的广度优先搜索（BFS）来解决这个问题。在标准的 BFS 流程中，下一个搜索点以贪婪的方式进行采样，这意味着
    GAA 将选择能够为子模型带来最大性能提升的 TF。GAA 只需在每个时期评估最佳的图像操作，而不是所有可用的 TF。贪婪的 BFS 将搜索空间的指数增长从
    $(20\times 10)^{L}$ 转变为线性增长。GAA 中最终的搜索空间大小为 $20\times 10\times k$，其中 $k$ 是一个 DA
    策略中的子策略数量。默认情况下，GAA 中的 $k$ 设置为 $5$ 以便与 AA 进行公平比较。
- en: The search process of GAA is conducted as follows. Firstly, it goes through
    all possible TFs and their magnitude values, while the probabilities are all set
    to $1$. Then, each operation is scored with its respective accuracy value obtained
    from the training of child model. As discussed before, searching in GAA is conducted
    in a greedy manner. Accordingly, only the TF with the highest score/accuracy will
    be stored. It is then concatenated to the next operation. This search procedure
    will be repeated $k$ times to find the top $k$ best sub-policies. Each of these
    selected sub-policies will be concatenated with all previously learned TFs to
    form the final policy of GAA.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: GAA的搜索过程如下进行。首先，它会遍历所有可能的TF及其幅值，而概率均设置为$1$。然后，每个操作会根据子模型训练得到的准确性值进行评分。如前所述，GAA中的搜索是贪婪方式进行的。因此，只有得分/准确性最高的TF会被存储。它随后会被连接到下一个操作。这一搜索过程会重复$k$次，以找到前$k$个最佳子策略。每一个选定的子策略将与所有先前学习到的TF连接，形成GAA的最终策略。
- en: The efficiency of GAA is substantially improved without a performance drop.
    From the experiments in [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    , GAA requires $360$ times less computational cost than the original AA [cubuk2019autoaugment](#bib.bib20)
    while still maintaining comparable model accuracy. Though the improvement in search
    speed is appealing, GAA has several limitations. The most significant disadvantage
    of GAA comes from its simplification of the search space. In GAA, the augmentation
    policy is formed by selecting TFs one after another, solely based on the performance
    of the selected operation. This setting assumes that each TF is independent even
    though they might affect each other in practice. As discussed in [ratner2017learning](#bib.bib52)
    , certain image operations might have pretty different results depending on which
    other TFs are applied together. This conclusion is also supported by experiments
    in [ho2019population](#bib.bib23) . However, due to the greedy nature of BFS,
    GAA only looks one step forward during the search, and hence can be easily trapped
    in local maximum that results in sub-optimal solutions. In addition, most of the
    hyper-parameters in GAA are mainly selected manually. There is also a lack of
    empirical evidence supporting such decisions.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: GAA的效率在没有性能下降的情况下得到了显著提升。从实验结果来看，[naghizadeh2020greedy](#bib.bib60)；[naghizadeh2021greedy](#bib.bib63)，GAA所需的计算成本比原始的AA
    [cubuk2019autoaugment](#bib.bib20)少$360$倍，同时保持了相当的模型准确性。尽管搜索速度的提升很吸引人，但GAA也存在一些局限性。GAA最显著的缺点在于其简化了搜索空间。在GAA中，增强策略是通过一个接一个地选择TF来形成的，仅仅基于所选操作的性能。这种设置假设每个TF是独立的，尽管它们在实际应用中可能会互相影响。如在[ratner2017learning](#bib.bib52)中讨论的那样，某些图像操作可能会根据其他TF的组合产生截然不同的结果。这一结论也得到了[ho2019population](#bib.bib23)中的实验支持。然而，由于BFS的贪婪性质，GAA在搜索过程中只向前看一步，因此容易陷入局部最优，从而导致次优解。此外，GAA中的大多数超参数主要是手动选择的，缺乏支持这些决定的实证证据。
- en: 5.1.5 Population-Based Augmentation (PBA)
  id: totrans-238
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.5 基于人群的增强（PBA）
- en: Population-Based Augment (PBA) [jaderberg2017population](#bib.bib67) is one
    of the most widely accepted AutoDA approaches. Unlike GAA that models DA policies
    as independent TFs, PBA emphasizes the relationship between them. In PBA, the
    standard augmentation policy search problem is treated as a special hyper-parameter
    optimization, where the schedule of these parameters is stressed. The schedule
    here refers to the application sequence of TFs. The augmentation policy is not
    a fixed setting. Instead, it changes as training progresses. To accommodate additional
    sequential information, PBA leverages the Population Based Training (PBT) [jaderberg2017population](#bib.bib67)
    technique. This algorithm optimizes the hyper-parameters along with the network
    weights simultaneously to achieve optimal performance. The final output of PBA
    is not a fixed configuration, but an application schedule of selected TFs when
    training the classification model. However, due to efficiency considerations,
    searching in PBA is still conducted on a simplified child model instead of the
    target network. PBA discards the trained child model as other AutoDA methods.
    The searched DA schedule is then adapted to the target training set to help train
    more complicated models.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 基于人口的增强（PBA） [jaderberg2017population](#bib.bib67) 是最被广泛接受的AutoDA方法之一。与将DA策略建模为独立TF的GAA不同，PBA
    强调它们之间的关系。在PBA中，标准的增强策略搜索问题被视为一种特殊的超参数优化，其中着重于这些参数的调度。这里的调度指的是TF的应用顺序。增强策略不是固定的设置，而是随着训练的进展而变化。为了适应额外的序列信息，PBA利用了基于人口的训练（PBT）
    [jaderberg2017population](#bib.bib67) 技术。该算法同时优化超参数和网络权重，以实现**最佳**性能。PBA的最终输出不是固定的配置，而是训练分类模型时所选择TF的应用调度。然而，由于效率考虑，PBA中的搜索仍然是在简化的子模型上进行，而不是目标网络。PBA像其他AutoDA方法一样丢弃训练过的子模型。然后，将搜索到的DA调度适配到目标训练集，以帮助训练更复杂的模型。
- en: In order to directly compare with AA, PBA retains similar settings as much as
    possible. The same $15$ augmentation TFs are available in PBA except SamplePairing
    [inoue2018data](#bib.bib46) . The discretion of policy hyper-parameters follows
    the same formulation, allowing $11$ values for magnitude and $10$ for probability.
    In PBA, a sub-policy still consists of two TFs, which are applied on one of the
    training batches. The policy modelling in PBA is motivated by the need for fair
    comparison with AA, rather than achieving optimal performance. Since the order
    of augmentation TFs in policy matters, PBA has an enormous search space even when
    compared with AA. For a single augmentation function, there are $(10\times 11)^{15\times
    2}\approx 1.75\times 10^{61}$ possibilities, much more than $(16\times 10\times
    11)^{10}\approx 2.9\times 10^{32}$ in AA [cubuk2019autoaugment](#bib.bib20) .
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 为了与AA进行直接比较，PBA 尽可能保留了相似的设置。除了 SamplePairing [inoue2018data](#bib.bib46) 外，PBA
    中也提供相同的$15$种增强TF。策略超参数的自由度遵循相同的公式，允许$11$个幅度值和$10$个概率值。在PBA中，一个子策略仍由两个TF组成，这些TF应用于其中一个训练批次。PBA中的策略建模受到与AA公平比较的需求驱动，而不是为了实现**最佳**性能。由于策略中增强TF的顺序很重要，PBA即使与AA相比也有一个巨大的搜索空间。对于一个单独的增强函数，有$(10\times
    11)^{15\times 2}\approx 1.75\times 10^{61}$种可能性，这比AA [cubuk2019autoaugment](#bib.bib20)
    中的$(16\times 10\times 11)^{10}\approx 2.9\times 10^{32}$多得多。
- en: Despite having a larger search space, PBA demonstrates that searching for a
    schedule is considerably more efficient than enforcing a fixed regulation. This
    is due to several factors. In traditional AutoDA methods such as AA, evaluating
    the sampled policies is extremely time-consuming. Such process needs to be conducted
    via a full training of a child model, because data augmentation techniques primarily
    take effect in the later stage of model training. In order to estimate the effectiveness
    of a fixed policy, the child model has to be trained for a certain number of epochs
    till the model can actually benefit from the policy. However, it is totally different
    when testing a policy with an application schedule. If two newly sampled policies
    share the same prefix TFs, the evaluation algorithm can reuse the prior training
    weights for the evaluation of both policies. This is similar to weight-sharing
    idea in AWS [tian2020improving](#bib.bib30) but it is more reliable. Moreover,
    it is also argued in [ho2019population](#bib.bib23) that DA can provide better
    accuracy results when utilizing schedule information. Different types of augmentation
    TFs may be appropriate for different epochs during model training. It is a natural
    thought to choose the most suitable augmentation functions according to the training
    stage.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管搜索空间较大，PBA 表明，搜索调度要比强制执行固定规则效率高得多。这是由于几个因素。在传统的 AutoDA 方法（如 AA）中，评估采样策略极为耗时。这一过程需要通过对一个子模型进行完整训练来完成，因为数据增强技术主要在模型训练的后期生效。为了估计固定策略的有效性，子模型必须训练一定数量的周期，直到模型能够真正从该策略中受益。然而，测试应用调度策略则完全不同。如果两个新采样的策略共享相同的前缀
    TFs，评估算法可以重用之前的训练权重来评估这两个策略。这类似于 AWS [tian2020improving](#bib.bib30) 中的权重共享思想，但更为可靠。此外，[ho2019population](#bib.bib23)
    还指出，利用调度信息可以提供更好的准确性结果。不同类型的增强 TFs 可能适用于模型训练中的不同周期。根据训练阶段选择最合适的增强函数是一个自然的想法。
- en: '![Refer to caption](img/34ee0c80c44bbeb73f625214e51f8e1b.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![参考图注](img/34ee0c80c44bbeb73f625214e51f8e1b.png)'
- en: 'Figure 6: Population Based Augmentation workflow [ho2019population](#bib.bib23)
    . Upper/lower sections indicate the policy generation/application stage respectively.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：基于人口的增强工作流程 [ho2019population](#bib.bib23)。上部/下部区域分别表示策略生成/应用阶段。
- en: The basic workflow of PBA is displayed in Fig. [6](#S5.F6 "Figure 6 ‣ 5.1.5
    Population-Based Augmentation (PBA) ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage
    Approaches ‣ A Survey of Automated Data Augmentation Algorithms for Deep Learning-based
    Image Classification Tasks"). To start, several child models, i.e. population,
    are initialized and trained concurrently. Each child model is responsible for
    evaluating a single augmentation policy. After $3$ epochs of training, PBA runs
    one epoch of Gradient Descent (GD) by testing all child models on the validation
    dataset. The validation accuracy estimates the performance of each policy used
    to train a child model respectively. After obtaining the performance rank of all
    child models and corresponding DA policies, PBA employs a classical “exploit-and-explore”
    procedure to update policies, where the lower ranked models copy the parameters
    of the higher ranker ones. Specifically, PBA uses Truncation Selection [jaderberg2017population](#bib.bib67)
    for exploitation. For exploration, PBA randomly perturbs the parameter values
    during sampling and exploiting. PBA does not re-initialize the child model from
    scratch, which greatly reduces the computational cost.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: PBA 的基本工作流程如图 [6](#S5.F6 "Figure 6 ‣ 5.1.5 Population-Based Augmentation (PBA)
    ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage Approaches ‣ A Survey of Automated
    Data Augmentation Algorithms for Deep Learning-based Image Classification Tasks")
    所示。首先，初始化并同时训练多个子模型，即人口。每个子模型负责评估一个单一的增强策略。在 $3$ 个训练周期后，PBA 通过在验证数据集上测试所有子模型来运行一个梯度下降（GD）周期。验证准确率估计了用于训练每个子模型的各个策略的性能。在获得所有子模型及其对应
    DA 策略的性能排名后，PBA 采用经典的“利用与探索”程序来更新策略，其中低排名的模型复制高排名模型的参数。具体而言，PBA 使用 Truncation
    Selection [jaderberg2017population](#bib.bib67) 进行利用。为了探索，PBA 在采样和利用过程中随机扰动参数值。PBA
    不会从头开始重新初始化子模型，这大大降低了计算成本。
- en: The improvement of PBA for search efficiency is substantial. It is approximately
    $1,000$ times faster than AA while still preserving similar accuracy. This is
    mainly due to the joint optimization of the child model and policy hyper-parameters.
    Even though the trained model is discarded after the search, re-using the network
    weights without repetitive training requires much less computational resources.
    The output of PBA is an application schedule for the augmentation policy. This
    can be represented as an augmentation function $f(t)$, with training epoch $t$
    as a variable. The final output of PBA reports moderate probability values of
    all operations. This may be due to the random perturbation when updating the policies.
    The magnitude values of all augmentation TFs also share a pattern. In the early
    phase of training, the increase in magnitude values is rapid. As training progresses,
    all magnitudes will reach a stable state. explaining this phenomenon, the authors
    of PBA argue that an effective evaluation procedure should be conducted for at
    least a certain number of epochs till the DA policies fully function on the model
    [ho2019population](#bib.bib23) . Moreover, the experimental results in [ho2019population](#bib.bib23)
    also suggest that simple TFs might be more suitable in the initial stage, while
    more complicated DA operations can be applied later.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: PBA在搜索效率上的改进是显著的。它比AA快大约$1,000$倍，同时保持类似的准确性。这主要归功于子模型和策略超参数的联合优化。尽管在搜索后训练模型被丢弃，但重复使用网络权重而无需重复训练所需的计算资源要少得多。PBA的输出是增强策略的应用计划。这可以表示为一个增强函数$f(t)$，其中训练周期$t$是一个变量。PBA的最终输出报告了所有操作的中等概率值。这可能是由于更新策略时的随机扰动。所有增强TF的幅度值也表现出一定的模式。在训练的早期阶段，幅度值的增长迅速。随着训练的进展，所有幅度值将达到稳定状态。解释这一现象时，PBA的作者认为应进行有效的评估程序，至少经过一定数量的周期，直到DA策略在模型上完全发挥作用[ho2019population](#bib.bib23)。此外，[ho2019population](#bib.bib23)中的实验结果还表明，简单的TF可能在初始阶段更合适，而更复杂的DA操作可以在后期应用。
- en: 5.1.6 Fast AutoAugment (Fast AA)
  id: totrans-246
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.6 Fast AutoAugment（Fast AA）
- en: Besides PBA, another widely accepted AutoDA is Fast AutoAugment (Fast AA) [lim2019fast](#bib.bib21)
    . This method is motivated by Bayesian Data Augmentation [tran2017bayesian](#bib.bib24)
    to solve the AutoDA problem. However, the objective of search phase in Fast AA
    is no longer focused on the highest model accuracy. Instead, Fast AA treats the
    augmented images as the data points from the original data distribution, which
    can best enhance the generalization ability of the model to be trained. Therefore,
    in Fast AA, the modified optimization objective focuses on minimizing the distribution
    distance between the original data and new data generated by DA policies. This
    is realized by adapting a density matching algorithm. This algorithm operates
    by matching the density of the original and the generated data, and hence completely
    eliminates the need for re-training the child model.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 除了PBA，另一种广泛接受的自动数据增强方法是Fast AutoAugment（Fast AA）[lim2019fast](#bib.bib21)。该方法受到贝叶斯数据增强[tran2017bayesian](#bib.bib24)的启发，用于解决AutoDA问题。然而，Fast
    AA的搜索阶段的目标不再专注于最高的模型准确性。相反，Fast AA将增强后的图像视为来自原始数据分布的数据点，这可以最好地增强待训练模型的泛化能力。因此，在Fast
    AA中，修改后的优化目标专注于最小化原始数据与由DA策略生成的新数据之间的分布距离。这是通过适应密度匹配算法实现的。该算法通过匹配原始数据和生成数据的密度来操作，从而完全消除了重新训练子模型的需要。
- en: Similar to the aforementioned methods, Fast AA employs the same problem formulation
    as in AA [cubuk2019autoaugment](#bib.bib20) , but uses continuous values instead.
    The two hyper-parameters of augmentation TF (probability and magnitude) have far
    more possibilities in Fast AA. However, in contrast to PBA [ho2019population](#bib.bib23)
    , the application of Fast AA policies is random and without any sequential order.
    The final policy of Fast AA is a combination of $5$ sub-policies. Each sub-policy
    is a conjunction of $2$ TFs, following the same experimental setting of AA. The
    authors of Fast AA emphasize that the number of sub-policies can be further tuned
    during the search [lim2019fast](#bib.bib21) because of the efficiency of the approach.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述方法类似，Fast AA 使用与 AA [cubuk2019autoaugment](#bib.bib20) 相同的问题公式，但使用的是连续值。Fast
    AA 中的两个超参数增强 TF（概率和幅度）具有更多的可能性。然而，与 PBA [ho2019population](#bib.bib23) 相比，Fast
    AA 策略的应用是随机的，没有任何顺序。Fast AA 的最终策略是 $5$ 个子策略的组合。每个子策略是 $2$ 个 TF 的结合，遵循与 AA 相同的实验设置。Fast
    AA 的作者强调，由于该方法的效率，子策略的数量可以在搜索过程中进一步调整 [lim2019fast](#bib.bib21)。
- en: '![Refer to caption](img/0d4a0b8492a273e51553ba68a991a83a.png)'
  id: totrans-249
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/0d4a0b8492a273e51553ba68a991a83a.png)'
- en: 'Figure 7: Fast AutoAugment workflow [lim2019fast](#bib.bib21) . Upper/lower
    sections indicate the policy generation/application stage respectively.'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: '图 7: Fast AutoAugment 工作流程 [lim2019fast](#bib.bib21) 。上/下部分分别表示策略生成/应用阶段。'
- en: Fast AA optimizes the augmentation policy during the process of density matching
    between training data pairs. Fig. [7](#S5.F7 "Figure 7 ‣ 5.1.6 Fast AutoAugment
    (Fast AA) ‣ 5.1 Gradient-free Optimization ‣ 5 Two-stage Approaches ‣ A Survey
    of Automated Data Augmentation Algorithms for Deep Learning-based Image Classification
    Tasks") displays the general workflow of Fast AA. The target data is divided into
    two sets, namely the training data $D_{train}$ and validation data $D_{valid}$.
    At a high level, the goal of the search algorithm is to find a DA policy $P$ that
    can best match the density of $D_{train}$ and $P(D_{valid})$ augmented by $P$.
    Unfortunately, it is infeasible to directly compare data distributions for each
    of the sampled policies. Fast AA tackles this problem by approximating the data
    distribution via model predictions. Specifically, if the same model can achieve
    equally promising results over two datasets, it is reasonable to consider that
    two sets might share a similar distribution.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: Fast AA 在训练数据对之间进行密度匹配的过程中优化增强策略。图 [7](#S5.F7 "图 7 ‣ 5.1.6 Fast AutoAugment
    (Fast AA) ‣ 5.1 无梯度优化 ‣ 5 双阶段方法 ‣ 深度学习图像分类任务的自动数据增强算法调查") 显示了 Fast AA 的总体工作流程。目标数据被分成两个数据集，即训练数据
    $D_{train}$ 和验证数据 $D_{valid}$。在高层次上，搜索算法的目标是找到一个数据增强策略 $P$，使得 $D_{train}$ 和 $P(D_{valid})$
    经过 $P$ 增强后能最佳匹配。不幸的是，直接比较每个采样策略的数据分布是不可行的。Fast AA 通过模型预测来近似数据分布，从而解决了这个问题。具体来说，如果相同的模型在两个数据集上能取得同样有希望的结果，那么可以合理地认为这两个数据集可能具有相似的分布。
- en: In detail, Fast AA first splits the full data into several folds, each of which
    is assigned to a classification model $M$ and processed in parallel. Every data
    fold consists of two separated datasets $D_{train}$ and $D_{valid}$. Training
    data is used to pre-train the model $M$, while the validation data will be retained
    for the subsequent policy search. After pre-training, the Fast AA model starts
    to sample augmentation policies via a classical Bayes Optimization [tran2017bayesian](#bib.bib24)
    . These policies are then evaluated based on the performance of the trained model
    $M$ on augmented data $P(D_{valid})$. Specifically, the policy that can generate
    data to maximize the performance of $M$ is desired. During the evaluation process
    in Fast AA, there is no training step involved at all. As such, it is a much more
    efficient and approach than other training-based evaluation methods.
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，Fast AA 首先将完整的数据分成若干个折，每个折分配给一个分类模型 $M$ 并进行并行处理。每个数据折包含两个分开的数据集 $D_{train}$
    和 $D_{valid}$。训练数据用于对模型 $M$ 进行预训练，而验证数据将保留用于后续的策略搜索。预训练之后，Fast AA 模型开始通过经典的贝叶斯优化
    [tran2017bayesian](#bib.bib24) 采样增强策略。这些策略然后根据训练模型 $M$ 在增强数据 $P(D_{valid})$ 上的表现进行评估。具体而言，期望能够生成最大化
    $M$ 性能的数据的策略。在 Fast AA 的评估过程中，没有涉及任何训练步骤。因此，它是一种比其他基于训练的评估方法更高效的方法。
- en: The experimental results in [lim2019fast](#bib.bib21) show that this evaluation
    setup leads to superior speed, and provide competitive accuracy to AA on various
    data. Fast AA achieves promising results not only for direct policy search, but
    also the transfer of learned policies to new data. The evidence presented in [lim2019fast](#bib.bib21)
    suggests that the transferability of Fast AA far exceeds the original AA. This
    is because Fast AA conducts the search directly on full datasets using target
    classifications, which minimizes the sub-optimality of learned policies. Therefore,
    Fast AA also has the potential to achieve better results when given more complex
    tasks. Making use of the efficiency of Fast AA model, the total number of sub-policies
    contained in an augmentation policy can be more than original setting. The experiments
    in [lim2019fast](#bib.bib21) show an improved generalization performance with
    more sub-policies searched by Fast AA. Moreover, it is also possible for Fast
    AA to search augmentation policies for each class. By doing so, Fast AA also obtains
    a slightly improved performance.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 实验结果表明 [lim2019fast](#bib.bib21) ，这种评估设置带来了更快的速度，并且在各种数据上提供了与AA竞争的准确性。快速AA不仅在直接策略搜索方面取得了令人满意的结果，而且在将学习到的策略迁移到新数据方面也表现良好。[lim2019fast](#bib.bib21)
    中提供的证据表明，快速AA的可迁移性远远超过了原始AA。这是因为快速AA直接在完整数据集上使用目标分类进行搜索，从而最小化了学习策略的次优性。因此，快速AA在面对更复杂的任务时也有可能取得更好的结果。利用快速AA模型的高效性，增强策略中包含的子策略总数可以超过原始设置。[lim2019fast](#bib.bib21)
    中的实验显示，通过快速AA搜索到更多子策略可以提高泛化性能。此外，快速AA还可以为每个类别搜索增强策略。通过这种方式，快速AA也获得了略微改善的性能。
- en: The biggest advantage of Fast AA lies in its efficiency. After introducing density
    matching into the evaluation process, Fast AA does not need to train the child
    model at all. As a result, Fast AA achieves a significantly faster search speed
    than the vanilla AA [cubuk2019autoaugment](#bib.bib20) . Moreover, contrary to
    all previous AutoDA approaches [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23)
    ; [tian2020improving](#bib.bib30) , Fast AA does not necessarily simplify the
    given task by searching on a proxy task. This avoids possible sub-optimiality,
    and hence guarantees the competitive performance of Fast AA. Another benefit of
    Fast AA is its continuous search space instead of discrete values, which finds
    more candidate policies during the search and potentially enhances the final result.
    Furthermore, the operations in Fast AA can be conducted in parallel, making it
    more practical to implement for ordinary users.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: 快速AA的最大优势在于其效率。在将密度匹配引入评估过程中后，快速AA完全不需要训练子模型。因此，快速AA实现了比原始AA [cubuk2019autoaugment](#bib.bib20)
    快得多的搜索速度。此外，与所有先前的AutoDA方法 [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23)
    ; [tian2020improving](#bib.bib30) 相比，快速AA并不一定通过在代理任务上进行搜索来简化给定任务。这避免了可能的次优性，从而保证了快速AA的竞争性能。快速AA的另一个好处是其连续的搜索空间，而不是离散值，这在搜索过程中发现了更多候选策略，并有可能增强最终结果。此外，快速AA中的操作可以并行进行，使其更易于普通用户实现。
- en: 5.1.7 AutoAugment with Knowledge Distillation (AA-KD)
  id: totrans-255
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.7 带有知识蒸馏的AutoAugment (AA-KD)
- en: Although AA-based algorithms have been a powerful augmentation method for many
    classification tasks, they are often sensitive to the choice of TFs. An inappropriate
    DA policy may even deteriorate the model performance. In traditional AutoDA methods
    [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    , usually there exists a trade-off between data diversity and label safety. Aggressive
    TFs can give more diverse training data that may better generalize the model,
    but they can potentially corrupt annotation information. In contrast, mild augmentation
    operations preserve the original image label, while the diversity of augmented
    data might be constrained and only lead to limited performance improvements.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于AA的算法在许多分类任务中已成为强大的数据增强方法，但它们往往对TF的选择非常敏感。不适当的DA策略甚至可能会恶化模型性能。在传统的AutoDA方法中
    [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    ，数据多样性与标签安全性之间通常存在权衡。激进的TF可以提供更多样化的训练数据，可能更好地泛化模型，但它们可能会破坏注释信息。相比之下，温和的增强操作保留了原始图像标签，而增强数据的多样性可能受到限制，仅能带来有限的性能提升。
- en: This has been investigated in AutoAugment with Knowledge Distillation (AA-KD)
    [wei2020circumventing](#bib.bib59) . Examples in [wei2020circumventing](#bib.bib59)
    show that some aggressive TFs can remove important semantics from the training
    data, which results in augment ambiguity. Augment ambiguity happens when the original
    label of a given image is no longer the most suitable annotation for the augmented
    data. Such phenomenon might confuse the classification model and result in performance
    drops. AA-KD approaches this problem by utilizing a Knowledge Distillation (KD)
    technique, which provides label correction after augmentation.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 这在 AutoAugment 与知识蒸馏（AA-KD）[wei2020circumventing](#bib.bib59)中已经被研究过。在 [wei2020circumventing](#bib.bib59)
    的示例中显示，一些激进的变换函数（TFs）可能会从训练数据中去除重要的语义，这会导致增强歧义。增强歧义发生在给定图像的原始标签不再是增强数据的最合适注释时。这种现象可能会混淆分类模型，导致性能下降。AA-KD
    通过利用知识蒸馏（KD）技术来解决这个问题，该技术在增强后提供标签修正。
- en: The authors of KD-AA point out that aggressive transformations can still be
    helpful for model training, only under the premise that associated labels are
    adjusted accordingly. Using the original labels of all transformed images is not
    the best option. Therefore, each of the data samples should be treated differently
    based on the different effects of an augmentation operation. KD-AA leverages the
    idea of Knowledge Distillation to gain more diverse data as possible, while still
    providing accurate annotations. In KD-AA, a teacher model is used to generate
    complementary information for label corrections. Each transformed image is described
    by the original label as well as the teacher signal. The latter is also called
    a soft label, as the ground-truth label is slightly softened by the associated
    teacher signal. Such soft labels are then used during the training of student
    models in the policy application phase. The teacher-student framework in KD-AA
    is mainly designed to filter out biased or noisy annotations resulted from DA
    to further enhance the later model training.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: KD-AA 的作者指出，激进的变换在模型训练中仍然可以有帮助，但前提是相关标签也要相应调整。使用所有变换图像的原始标签不是最佳选择。因此，每个数据样本应该根据增强操作的不同效果进行不同处理。KD-AA
    利用知识蒸馏的理念来获得尽可能多的多样数据，同时提供准确的注释。在 KD-AA 中，教师模型用于生成用于标签修正的补充信息。每个变换图像由原始标签以及教师信号来描述。后者也称为软标签，因为真实标签被关联的教师信号略微软化。这些软标签在策略应用阶段用于学生模型的训练。KD-AA
    中的教师-学生框架主要设计用于过滤掉因 DA 而产生的偏差或噪声注释，以进一步增强后续的模型训练。
- en: The major contribution of KD-AA is to recognise that KD is a useful technique
    to enhance traditional AutoDA methods. It is a complement to augmentation search
    algorithms rather than a complete AutoDA model. The effectiveness of KD-AA is
    demonstrated via experiments using AA [cubuk2019autoaugment](#bib.bib20) and RandAugment
    [cubuk2020randaugment](#bib.bib31) in [wei2020circumventing](#bib.bib59) . With
    much larger magnitude values, AutoDA supported by KD produces consistent improvements
    in model accuracy. The authors of KD-AA also report the possibility of employing
    semi-supervised learning techniques with KD in AutoDA [tarvainen2017mean](#bib.bib75)
    ; [thornton2013auto](#bib.bib76) ; [xie2020adversarial](#bib.bib77) , where the
    input data is mostly unlabelled.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: KD-AA 的主要贡献在于认识到 KD 是增强传统 AutoDA 方法的有效技术。它是对增强搜索算法的补充，而不是一个完整的 AutoDA 模型。KD-AA
    的有效性通过在 [wei2020circumventing](#bib.bib59) 中使用 AA [cubuk2019autoaugment](#bib.bib20)
    和 RandAugment [cubuk2020randaugment](#bib.bib31) 的实验得到了验证。通过支持 KD 的 AutoDA，模型精度得到了一致的提升。KD-AA
    的作者还报告了在 AutoDA [tarvainen2017mean](#bib.bib75) ; [thornton2013auto](#bib.bib76)
    ; [xie2020adversarial](#bib.bib77) 中结合半监督学习技术的可能性，其中输入数据大多数是未标记的。
- en: 5.1.8 Patch AutoAugment (PAA)
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.1.8 Patch AutoAugment (PAA)
- en: Generally, AutoDA methods search for the augmentation policies at the image
    level. The same DA policy is used to transform the entire image. However, depending
    on different content within various regions of an image, the optimal TF may be
    different. Treating an image as a whole might ignore the difference in its internal
    regions, which constrains the diversity of augmented data [gontijo2020affinity](#bib.bib78)
    . Moreover, overly aggressive augmentation functions may potentially modify or
    remove semantic features, causing safety concerns in terms of label preservation.
    To address the above-mentioned problem, a more fine-grained approach, Patch AutoAugment
    (PAA) [lin2021local](#bib.bib65) has been proposed. PAA considers an image as
    a combination of several patches, and optimizes DA policies at patch level. To
    fully represent the inner relationship between each patch, PAA formulates AutoDA
    tasks as a Multi-Agent Reinforcement Learning (MARL) problem, where each agent
    handles a single patch and updates the final DA policies corporately.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 通常，AutoDA方法在图像级别上搜索增强策略。相同的DA策略用于转换整个图像。然而，根据图像中不同区域的内容，最佳TF可能会有所不同。将图像视为一个整体可能忽略其内部区域的差异，这限制了增强数据的多样性
    [gontijo2020affinity](#bib.bib78) 。此外，过于激进的增强函数可能会修改或移除语义特征，造成标签保留方面的安全隐患。为了解决上述问题，提出了一种更精细化的方法——Patch
    AutoAugment (PAA) [lin2021local](#bib.bib65) 。PAA将图像视为若干补丁的组合，并在补丁级别上优化DA策略。为了充分表示每个补丁之间的内在关系，PAA将AutoDA任务表述为一个多代理强化学习（MARL）问题，其中每个代理处理一个单独的补丁，并共同更新最终的DA策略。
- en: Similar to AA, the problem modelling in PAA follows the basic use of Reinforcement
    Learning (RL) model. In a standard RL framework, given a current state, the agent/controller
    samples a DA policy and receives the corresponding reward signal from the child
    model training. Then the PAA model updates the policy according to the reward
    and moves to the next state. The optimization objective of an agent in PAA is
    the maximization of reward to search for the best performing DA policy. Moreover,
    PAA employs the idea from MARL [boutilier1996planning](#bib.bib79) , using multiple
    agents to search over a single image. Each agent handles a sub-region out of the
    original picture, and shares a global reward to cooperatively update the next
    augmentation strategy.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 与AA类似，PAA中的问题建模遵循强化学习（RL）模型的基本使用。在标准的RL框架中，给定当前状态，代理/控制器会采样一个DA策略，并从子模型训练中接收相应的奖励信号。然后，PAA模型根据奖励更新策略，并移动到下一个状态。PAA中代理的优化目标是最大化奖励，以寻找最佳表现的DA策略。此外，PAA借鉴了MARL的思想
    [boutilier1996planning](#bib.bib79) ，使用多个代理在单个图像上进行搜索。每个代理处理原始图片中的一个子区域，并共享一个全局奖励，以协同更新下一个增强策略。
- en: In PAA, the augmentation policy model consists of a global state, local observations
    and actions. Firstly, an input image is divided into several non-overlapping patches
    of equal size. Each patch is controlled by one policy agent for the policy optimization.
    To accommodate the contextual relationship between other patches, a global state
    is shared among all agents, representing the semantics of the whole image. The
    global state is obtained by extracting the deep features of the entire input image
    through a standard CNN model. In PAA, the ResNet-18 network [he2016deep](#bib.bib4)
    pre-trained on ImageNet data [deng2009imagenet](#bib.bib28) is used. In addition
    to the global state, each agent also utilizes local information, i.e. observations,
    to update its own DA policy. Local observations are also described by the deep
    features of the associated patches. Unlike global information, this information
    is unavailable to other agents. During the search, each of the agents update its
    policy based on both global and local information. The action of the policy model
    in PAA represents standard TF techniques, controlled by the probability and magnitude.
    There are $15$ operations defined in PAA. Similar to PBA [ho2019population](#bib.bib23)
    , PAA outputs an application schedule of TFs instead of fixed policies. However,
    since the search in PAA is conducted on a child model for a limited number of
    epochs, such schedule needs to be linearly scaled up when applied to target networks
    in the second stage.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 在PAA中，增强策略模型包括一个全局状态、局部观测和动作。首先，将输入图像分成几个大小相等且不重叠的区域。每个区域由一个策略代理控制，用于策略优化。为了适应其他区域之间的上下文关系，所有代理共享一个全局状态，代表整个图像的语义。全局状态通过标准的CNN模型提取整个输入图像的深层特征获得。在PAA中，使用了在ImageNet数据上预训练的ResNet-18网络
    [he2016deep](#bib.bib4)。除了全局状态外，每个代理还利用局部信息，即观测，来更新其自身的DA策略。局部观测也通过相关区域的深层特征来描述。与全局信息不同，这些信息对其他代理不可用。在搜索过程中，每个代理基于全局和局部信息更新其策略。PAA中策略模型的动作代表标准TF技术，由概率和幅度控制。在PAA中定义了$15$种操作。类似于PBA
    [ho2019population](#bib.bib23)，PAA输出TF的应用调度，而不是固定的策略。然而，由于PAA中的搜索是在子模型上进行的，并且周期数有限，因此在第二阶段应用于目标网络时，需要对这种调度进行线性缩放。
- en: The optimal strength of PAA is its patch-based policy search. Through the use
    of Grad-CAM [selvaraju2017grad](#bib.bib80) , the importance of each region in
    the image is clearly shown in [lin2021local](#bib.bib65) . This further shows
    that the optimal augmentation strategy for each patch can vary depending on the
    different semantics. It is therefore reasonable to perform the augmentation search
    at a more fine-grained level. Different patches might prefer totally different
    TFs during the training. For example, regions that contain important features
    may prefer mild TFs, which can better preserve the semantics. However for less
    important patches that do not include objects of interest, aggressive operations
    with larger magnitude values might provide a higher level of variety in the augmented
    data. Overall, a fine-grained PAA can not only provide sufficient variety for
    the proposed policies, but also further enhance model performance.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: PAA的最终优势在于其基于补丁的策略搜索。通过使用Grad-CAM [selvaraju2017grad](#bib.bib80)，图像中每个区域的重要性在
    [lin2021local](#bib.bib65) 中得到了清晰展示。这进一步表明，每个区域的最佳增强策略可能会根据不同的语义有所不同。因此，在更细粒度的层面进行增强搜索是合理的。不同的区域在训练过程中可能偏好完全不同的TF。例如，包含重要特征的区域可能更倾向于温和的TF，这可以更好地保留语义。然而，对于不包含感兴趣对象的较不重要的区域，较大的幅度值的激进操作可能提供更高水平的增强数据多样性。总体而言，细粒度的PAA不仅可以为提出的策略提供足够的多样性，还可以进一步提高模型性能。
- en: 5.2 Gradient-based Optimization
  id: totrans-265
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于梯度的优化
- en: 5.2.1 Faster AutoAugment (Faster AA)
  id: totrans-266
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.2.1 更快的AutoAugment（Faster AA）
- en: From the perspective of hyper-parameter optimization, all of the aforementioned
    two-stage AutoDA methods do not directly optimize augmentation policies via gradients.
    This is because the augmentation operations are usually not differentiable with
    respect to the hyper-parameters of policy probability and magnitude [hataya2020faster](#bib.bib22)
    . As a result, it is often tricky to obtain the gradient information of validation
    accuracy with regard to policy hyper-parameters [lin2019online](#bib.bib54) .
    However, several works have proposed to approximate the hyper-parameters as probability
    distributions, and relax such distributions in a way that a DA policy can be optimized
    based on gradients [hataya2020faster](#bib.bib22) ; [lin2019online](#bib.bib54)
    ; [gudovskiy2021autodo](#bib.bib62) ; [li2020dada](#bib.bib57) . Faster AutoAugment
    (Faster AA) [hataya2020faster](#bib.bib22) is the only two-stage approach that
    is based on gradient optimization.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 从超参数优化的角度来看，前面提到的所有两阶段 AutoDA 方法都没有通过梯度直接优化增强策略。这是因为增强操作通常对策略概率和幅度的超参数不可微分 [hataya2020faster](#bib.bib22)。因此，获得关于策略超参数的验证准确性的梯度信息通常很棘手
    [lin2019online](#bib.bib54)。然而，已有一些研究提出将超参数近似为概率分布，并以一种可以基于梯度优化 DA 策略的方式来放宽这些分布
    [hataya2020faster](#bib.bib22)；[lin2019online](#bib.bib54)；[gudovskiy2021autodo](#bib.bib62)；[li2020dada](#bib.bib57)。Faster
    AutoAugment (Faster AA) [hataya2020faster](#bib.bib22) 是唯一基于梯度优化的两阶段方法。
- en: 'Faster AA also employs a similar policy model as in previous works [cubuk2019autoaugment](#bib.bib20)
    ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21) . In Faster AA, a
    DA policy consists of several sub-policies, where a single sub-policy contains
    $2$ consecutive augmentation TFs. Each TF is described by two hyper-parameters:
    the probability and magnitude. Operations used in Faster AA are the same $16$
    image TFs from the original AA work, including $14$ basic image transformations
    functions implemented in PIL library and $2$ extra augmentation algorithms, i.e.
    Cutout [devries2017improved](#bib.bib45) and SamplePairing [inoue2018data](#bib.bib46)
    . Since a DA policy is often non-differentiable based on its hyper-parameters,
    traditional AutoDA models have to conduct a full training on child model to evaluate
    a policy. Even after the discretization of policy hyper-parameters, this formulation
    still requires exorbitant computational resources [cubuk2019autoaugment](#bib.bib20)
    ; [tian2020improving](#bib.bib30) ; [ho2019population](#bib.bib23) . To address
    this challenge, Faster AA approximates the original search space into a differentiable
    setting and directly optimizes the gradient, which significantly reduces the search
    cost.'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Faster AA 还使用了与之前研究类似的策略模型 [cubuk2019autoaugment](#bib.bib20)；[ho2019population](#bib.bib23)；[lim2019fast](#bib.bib21)。在
    Faster AA 中，一个 DA 策略由若干子策略组成，其中一个子策略包含 $2$ 个连续的增强 TF。每个 TF 由两个超参数描述：概率和幅度。Faster
    AA 中使用的操作与原始 AA 工作中的 $16$ 种图像 TF 相同，包括 PIL 库中实现的 $14$ 种基本图像转换函数和 $2$ 种额外的增强算法，即
    Cutout [devries2017improved](#bib.bib45) 和 SamplePairing [inoue2018data](#bib.bib46)。由于
    DA 策略通常基于其超参数是非微分的，传统的 AutoDA 模型必须对子模型进行完整的训练以评估策略。即使在对策略超参数进行离散化之后，这种形式仍然需要大量的计算资源
    [cubuk2019autoaugment](#bib.bib20)；[tian2020improving](#bib.bib30)；[ho2019population](#bib.bib23)。为了解决这一挑战，Faster
    AA 将原始搜索空间近似为可微设置，并直接优化梯度，从而显著降低了搜索成本。
- en: Inspired by the bi-level optimization in OHL-AA [lin2019online](#bib.bib54)
    , Faster AA adapts a differentiable framework for DA policy search, which substantially
    accelerates the search. The key modification in Faster AA is the approximation
    of policy gradient via a straight-through estimator [bengio2013estimating](#bib.bib81)
    ; [oord2017neural](#bib.bib82) inspired by DARTS [williams1992simple](#bib.bib55)
    . The success of DARTS in NAS fields makes it suitable to AutoDA tasks. In Faster
    AA, the distribution of augmentation hyper-parameters are approximated as Relaxed
    Bernoulli distribution [jang2016categorical](#bib.bib70) . After the relaxation
    of search space, each TF within an augmentation policy can be differentiable with
    regard to the probability and magnitude hyper-parameters [bengio2013estimating](#bib.bib81)
    ; [oord2017neural](#bib.bib82) . This makes it easier to calculate their gradients
    in Faster AA. Using gradient estimation techniques, Faster AA can directly optimise
    DA policies based on gradient. This makes DA policy optimization end-to-end differentiable,
    and thus provides much more control over the entire process especially when compared
    to previous black-box optimizations, such as Reinforcement Learning in AA [cubuk2019autoaugment](#bib.bib20)
    .
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 受到OHL-AA中二级优化的启发，[lin2019online](#bib.bib54) ，Faster AA 采用了一个可微分的框架来进行 DA 策略搜索，这大大加快了搜索速度。Faster
    AA 的关键修改是通过直通估计器 [bengio2013estimating](#bib.bib81) ; [oord2017neural](#bib.bib82)
    近似策略梯度，这一思想源于 DARTS [williams1992simple](#bib.bib55) 。DARTS 在 NAS 领域的成功使其适用于 AutoDA
    任务。在 Faster AA 中，增强超参数的分布被近似为放松伯努利分布 [jang2016categorical](#bib.bib70) 。在搜索空间放松后，每个增强策略中的
    TF 可以针对概率和幅度超参数 [bengio2013estimating](#bib.bib81) ; [oord2017neural](#bib.bib82)
    进行可微分。这使得在 Faster AA 中更容易计算它们的梯度。使用梯度估计技术，Faster AA 可以直接基于梯度优化 DA 策略。这使得 DA 策略优化具有端到端的可微性，从而相比于之前的黑箱优化方法（如
    AA 中的强化学习 [cubuk2019autoaugment](#bib.bib20) ）提供了更高的控制力。
- en: '![Refer to caption](img/af181b41aaed0845d53626c64e64190f.png)'
  id: totrans-270
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/af181b41aaed0845d53626c64e64190f.png)'
- en: 'Figure 8: Faster AutoAugment workflow [hataya2020faster](#bib.bib22) . Upper/lower
    sections indicate the policy generation/application stage respectively.'
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: '图 8: Faster AutoAugment 工作流程 [hataya2020faster](#bib.bib22) 。上/下部分分别表示策略生成/应用阶段。'
- en: 'To further reduce the search cost, inspired by Fast AA [lim2019fast](#bib.bib21)
    , Faster AA also applies a density matching technique during policy evaluation.
    The objective of optimization is to minimize the distance between data distributions
    of the original and the augmented data. Faster AA also employs an adversarial
    framework to help the policy sampling. Due to the use of Density Matching, the
    overall workflow of Faster AA is similar to Fast AA as displayed in Fig. [8](#S5.F8
    "Figure 8 ‣ 5.2.1 Faster AutoAugment (Faster AA) ‣ 5.2 Gradient-based Optimization
    ‣ 5 Two-stage Approaches ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks"). However, Faster AA uses
    a reduced dataset $D$ as its input to further improve the search efficiency. Input
    data $D$ is firstly split into two sets: a training set $D_{M}$ to prepare the
    evaluation model and an augmentation set $D_{A}$ for policy searching. The pre-trained
    model $M$ is then used to estimate the performance of sampled DA policies $P$
    in the first stage of Faster AA. The Faster AA model examines the search space
    in a gradient-based manner to identify the optimal DA policies. After searching,
    the final policy will be applied to augmented the full dataset and train the classification
    model $M$. During both the searching and training phase, Faster AA trains the
    same target model $M$ to provide more reliable evaluation.'
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步降低搜索成本，受到 Fast AA [lim2019fast](#bib.bib21) 的启发，Faster AA 在策略评估期间还应用了密度匹配技术。优化的目标是最小化原始数据和增强数据之间的数据分布距离。Faster
    AA 还采用了对抗框架来帮助策略采样。由于使用了密度匹配，Faster AA 的整体工作流程与 Fast AA 相似，如图 [8](#S5.F8 "Figure
    8 ‣ 5.2.1 Faster AutoAugment (Faster AA) ‣ 5.2 Gradient-based Optimization ‣ 5
    Two-stage Approaches ‣ A Survey of Automated Data Augmentation Algorithms for
    Deep Learning-based Image Classification Tasks") 所示。然而，Faster AA 使用了一个减少的数据集 $D$
    作为输入，以进一步提高搜索效率。输入数据 $D$ 首先被分成两部分：用于准备评估模型的训练集 $D_{M}$ 和用于策略搜索的增强集 $D_{A}$。预训练模型
    $M$ 被用于估计 Faster AA 第一阶段中采样的 DA 策略 $P$ 的性能。Faster AA 模型以基于梯度的方式检查搜索空间，以识别最佳 DA
    策略。搜索完成后，最终策略将应用于增强整个数据集并训练分类模型 $M$。在搜索和训练阶段，Faster AA 训练相同的目标模型 $M$ 以提供更可靠的评估。
- en: Faster AA is the first two-stage AutoDA model that resorts to gradient approximation
    to achieve faster searches than other state-of-the-art algorithms, such as Fast
    AA [lim2019fast](#bib.bib21) and PBA [ho2019population](#bib.bib23) . Importantly,
    it introduces straight-through estimators [bengio2013estimating](#bib.bib81) to
    approximate the gradient of non-differentiable AutoDA task. By relaxing the original
    distributions of policy hyper-parameters, Faster AA can directly back-propagate
    the augmentation process and optimize DA policies based on the gradient. The black-box
    optimization used in traditional two-stage AutoDA models is therefore transformed
    into a more transparent and controlled process to significantly improve the search
    speed. In addition, Faster AA follows the density matching idea of Fast AA [lim2019fast](#bib.bib21)
    , completely removing the repetitive training of the model in the first stage.
    Instead, policy evaluation is conducted by minimizing the distribution distance
    between the original and the augmented data. As a result, Faster AA can substantially
    reduce the required computational resources compared to AA [cubuk2019autoaugment](#bib.bib20)
    . The experimental results in [hataya2020faster](#bib.bib22) shows the competitive
    performance of Faster AA compared to other AutoDA methods, in terms of both search
    efficiency and final accuracy.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: Faster AA 是第一个两阶段的 AutoDA 模型，通过梯度近似实现比其他先进算法（如 Fast AA [lim2019fast](#bib.bib21)
    和 PBA [ho2019population](#bib.bib23)）更快的搜索。重要的是，它引入了直通估计器 [bengio2013estimating](#bib.bib81)
    来近似不可微分的 AutoDA 任务的梯度。通过放宽策略超参数的原始分布，Faster AA 可以直接反向传播增强过程，并基于梯度优化 DA 策略。因此，传统两阶段
    AutoDA 模型中使用的黑箱优化被转化为一个更加透明和可控的过程，从而显著提高了搜索速度。此外，Faster AA 遵循了 Fast AA [lim2019fast](#bib.bib21)
    的密度匹配思想，完全去除了第一阶段中重复训练模型的过程。相反，通过最小化原始数据和增强数据之间的分布距离来进行策略评估。因此，与 AA [cubuk2019autoaugment](#bib.bib20)
    相比，Faster AA 可以显著减少所需的计算资源。实验结果 [hataya2020faster](#bib.bib22) 显示，Faster AA 在搜索效率和最终准确性方面与其他
    AutoDA 方法相比具有竞争力的性能。
- en: 5.3 Search-free
  id: totrans-274
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 无需搜索
- en: 5.3.1 RandAugment (RA)
  id: totrans-275
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 RandAugment (RA)
- en: RandAugment (RA) [cubuk2020randaugment](#bib.bib31) is the first search-free
    scheme in the AutoDA field. To reduce the cost of the search phase, the parameter
    space in RA is significantly smaller, defined by only two hyper-parameters. This
    reduced space allows RA to learn DA policies directly from the full dataset without
    resorting to a separate proxy task. In fact, the simplification of policy hyper-parameters
    in RA is so dramatic, that a simple grid search is sufficient to output an effective
    DA policy. Therefore, the policy generation stage in RA is quite different from
    the classical search scheme in other approaches, where the latter usually involves
    selective sampling and expensive evaluation. According to [cubuk2020randaugment](#bib.bib31)
    , it is possible to apply more advanced sampling methods instead of a naive grid
    search, which may further reduce the computational cost. Therefore, RA can be
    recognised as a search-free AutoDA model. Additionally, RA is also able to optimize
    DA policies based on different sizes of classification models and training data.
    The experimental results in [cubuk2020randaugment](#bib.bib31) also show that
    RA can produce competitive accuracy result when compared with other search-based
    AutoDA approaches.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: RandAugment (RA) [cubuk2020randaugment](#bib.bib31) 是 AutoDA 领域中第一个无需搜索的方案。为了降低搜索阶段的成本，RA
    中的参数空间显著较小，仅由两个超参数定义。这一简化的空间使 RA 能够直接从完整的数据集中学习 DA 策略，而无需依赖单独的代理任务。事实上，RA 中策略超参数的简化程度非常高，以至于简单的网格搜索就足以输出有效的
    DA 策略。因此，RA 中的策略生成阶段与其他方法中的经典搜索方案有很大不同，后者通常涉及选择性采样和昂贵的评估。根据 [cubuk2020randaugment](#bib.bib31)
    的说法，可以使用更先进的采样方法而非简单的网格搜索，这可能进一步降低计算成本。因此，RA 可以被认为是一个无需搜索的 AutoDA 模型。此外，RA 还能够根据不同规模的分类模型和训练数据优化
    DA 策略。实验结果 [cubuk2020randaugment](#bib.bib31) 也表明，与其他基于搜索的 AutoDA 方法相比，RA 可以产生具有竞争力的准确性结果。
- en: The primary goal of RA is to reduce the complexity caused by the separate policy
    search stage in the earlier two-stage AutoDA methods. To do so, RA eliminates
    the need for expensive policy searches by greatly simplifying the search problem.
    The entire search phase in traditional AutoDA method is removed in RA out of efficiency
    considerations. This is because most of the computational workload comes from
    the first stage when the model repetitively samples DA policies and evaluates
    them. It is also a complicated bi-level optimization problem to conduct the policy
    search and network training simultaneously. Another downside of prior search-based
    methods lies on the proxy task used during searching. In the proxy task, AutoDA
    models search on a reduced sub-set of the original training data, and evaluate
    sampled augmentation policies using a simpler network. Both simplifications are
    applied in order to decrease the search cost. A major premise of this framework
    is that such a proxy task can reflect some core features of the target task, so
    that the final policy is also the optimal augmentation scheme for the full training
    data. While the DA policy found through the proxy task is able to produce promising
    performance [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23)
    ; [lim2019fast](#bib.bib21) ; [zoph2020learning](#bib.bib26) , it is likely to
    be a sub-optimal result [cubuk2020randaugment](#bib.bib31) . According to [cubuk2020randaugment](#bib.bib31)
    , the optimal strength of an augmentation policy depends on the size of both the
    training set and network. Therefore, searching for DA policies on a proxy task
    can only produce results suitable to solve the proxy task instead of the target
    task, which leads to sub-optimal solutions.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: RA 的主要目标是减少早期两阶段 AutoDA 方法中由单独策略搜索阶段引起的复杂性。为此，RA 通过大幅简化搜索问题，消除了对昂贵策略搜索的需求。在
    RA 中，出于效率考虑，传统 AutoDA 方法中的整个搜索阶段被移除。这是因为大多数计算工作负载来自第一阶段，当模型重复采样 DA 策略并进行评估时。进行策略搜索和网络训练同时进行也是一个复杂的双层优化问题。先前基于搜索的方法的另一个缺点在于搜索过程中使用的代理任务。在代理任务中，AutoDA
    模型在原始训练数据的一个简化子集上进行搜索，并使用一个更简单的网络评估采样的增广策略。这两种简化措施旨在降低搜索成本。该框架的一个主要前提是，代理任务能够反映目标任务的一些核心特征，从而使最终策略也是全量训练数据的最佳增广方案。虽然通过代理任务找到的
    DA 策略能够产生有前景的性能 [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23)
    ; [lim2019fast](#bib.bib21) ; [zoph2020learning](#bib.bib26) ，但它很可能是一个次优结果 [cubuk2020randaugment](#bib.bib31)
    。根据 [cubuk2020randaugment](#bib.bib31) 的说法，增广策略的最佳强度取决于训练集和网络的大小。因此，在代理任务上搜索 DA
    策略只能产生适合解决代理任务的结果，而不是目标任务，这导致次优解决方案。
- en: To avoid sub-optimal results, AutoDA models need to directly search for DA policies
    over the full training set. However, this is usually computationally infeasible
    in practice as the traditional search space in AA [cubuk2019autoaugment](#bib.bib20)
    is extremely large. In order to mitigate such efficiency issues, RA substantially
    reduces the number of hyper-parameters to optimise. In RA, the reduction in the
    size of search space is tackled in two ways, including the simplification on the
    existing formulation and the proposal of new parameters. In prior methods [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) , each TF in an augmentation
    policy is controlled by two hyper-parameters, probability and magnitude. While
    in RA, all image operations are selected with uniform probability, which depends
    entirely on the total number of available TFs in the search space. For instance,
    given $K$ different TFs in RA, the probability of applying each operation is $\frac{1}{K}$.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 为了避免次优结果，AutoDA 模型需要在整个训练集上直接搜索 DA 策略。然而，在实践中，这通常计算上不可行，因为传统的 AA [cubuk2019autoaugment](#bib.bib20)
    搜索空间极其庞大。为了缓解这种效率问题，RA 大大减少了需要优化的超参数数量。在 RA 中，搜索空间的缩减通过两种方式解决，包括对现有公式的简化和新参数的提出。在先前的方法
    [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    中，增广策略中的每个 TF 都由两个超参数控制，即概率和幅度。而在 RA 中，所有图像操作以均匀概率进行选择，这完全依赖于搜索空间中可用 TF 的总数。例如，在
    RA 中给定 $K$ 个不同的 TF，每个操作的概率是 $\frac{1}{K}$。
- en: To further reduce the search space, RA simplifies the magnitude hyper-parameter
    as well. The value range of the magnitude hyper-parameter follows the same setting
    as in original AA [cubuk2019autoaugment](#bib.bib20) , with $11$ discrete values
    in total, ranging from $0$ to $10$. In previous AutoDA models, the scale of each
    transformation function is also specified by its respective magnitude. However,
    after examining changes in each operation magnitude during searching [ho2019population](#bib.bib23)
    , the authors of RA point out that all magnitude values follow a similar schedule
    over time. Therefore, RA postulates that it may be sufficient to use a shared
    magnitude hyper-parameter $M$ for all TFs. As a result, in RA, all image operations
    within DA policies share the same probability and magnitude hyper-parameters,
    which significantly reduces the parameter space. Besides reformulating the search
    space, RA also proposes a new free parameter to improve the performance gain,
    namely the number of TFs $N$ within one augmentation policy. $N$ is predominantly
    manually decided in most popular AutoDA methods [cubuk2019autoaugment](#bib.bib20)
    ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21) due to limited computational
    resources. While in RA, automating the search of $N$ becomes feasible because
    of the extremely reduced parameter space. Optimizing the TF number $N$ can eliminate
    human bias and further improve performance.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步减少搜索空间，RA也简化了幅度超参数。幅度超参数的值范围与原始AA中的设置相同 [cubuk2019autoaugment](#bib.bib20)，共有$11$个离散值，范围从$0$到$10$。在之前的AutoDA模型中，每个变换函数的规模也由其相应的幅度指定。然而，在检查每个操作幅度在搜索过程中的变化
    [ho2019population](#bib.bib23) 后，RA的作者指出所有幅度值都遵循类似的时间表。因此，RA假设使用一个共享的幅度超参数$M$对所有TF可能是足够的。因此，在RA中，所有DA策略中的图像操作共享相同的概率和幅度超参数，这大大减少了参数空间。除了重新定义搜索空间，RA还提出了一个新的自由参数以提升性能增益，即一个增强策略中的TF数量$N$。$N$在大多数流行的AutoDA方法中
    [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23) ; [lim2019fast](#bib.bib21)
    通常是人工决定的，因为计算资源有限。而在RA中，由于参数空间极大地减少，$N$的自动搜索变得可行。优化TF数量$N$可以消除人为偏差，并进一步提高性能。
- en: 'After the re-parameterization of parameter space, there are only two hyper-parameters
    to optimize in RA: the number of TFs $N$ to form a complete augmentation policy,
    and the global magnitude value $M$ to control all TFs. Both hyper-parameters can
    be easily interpreted by humans so that larger values of $N$ and $M$ indicate
    more aggressive augmentation strategies, while smaller values represent more conservative
    schemes. After RA has reformulated the entire search problem, various advanced
    algorithms can be applied to perform standard hyper-parameter optimization [snoek2012practical](#bib.bib83)
    . However, since the final search space in RA is extremely small, the authors
    of RA suggest that a simple grid search can yield sufficient performance gains,
    which is supported by experiment [cubuk2020randaugment](#bib.bib31) .'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 在参数空间重新参数化之后，RA中只需要优化两个超参数：形成完整增强策略的TF数量$N$和控制所有TF的全局幅度值$M$。这两个超参数都容易被人类解释，因此较大的$N$和$M$值表示更激进的增强策略，而较小的值则代表更保守的方案。在RA重新定义了整个搜索问题之后，各种先进的算法可以用于执行标准的超参数优化
    [snoek2012practical](#bib.bib83)。然而，由于RA中的最终搜索空间极小，RA的作者建议简单的网格搜索就能获得足够的性能提升，这一点得到了实验的支持
    [cubuk2020randaugment](#bib.bib31)。
- en: RA makes several noteworthy contributions to the AutoDA task. Via re-parameterization
    of standard AutoDA problem, RA employs a reduced search space, which is only controlled
    by two hyper-parameters, $N$ and $M$. $N$ indicates how many TFs are contained
    within a single DA policy, and $M$ refers to the uniform distortion parameter
    for all image operations. In RA, the optimization of $N$ and $M$ is achieved by
    naive grid search. This feature allows RA to easily scale to larger datasets and
    deeper models without significantly increasing the search cost. Moreover, RA shows
    promising performance on various datasets, matching or even outperforming previous
    AutoDA models including AA [cubuk2019autoaugment](#bib.bib20) , Fast AA [lim2019fast](#bib.bib21)
    and PBA [ho2019population](#bib.bib23) . This finding demonstrates the limitations
    of prior approaches based on proxy tasks. The experimental results in [cubuk2020randaugment](#bib.bib31)
    are also in agreement with this finding, which shows that the optimal DA policy
    depends on the size of training data and discriminative network. Transferring
    a DA policy learned from a simplified proxy task can lead to performance degradation.
    After removing the expensive search phase, RA avoids the sub-optimality of learned
    DA policies through direct searches on the target dataset and classification model.
    Finally, the results in [cubuk2020randaugment](#bib.bib31) reveals the relationship
    between augmentation policy and the size of dataset and model. Most existing AutoDA
    methods optimize DA policies using reduced data and smaller models to accelerate
    the search [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    , however this leads to sub-optimal performance. In practical applications, searching
    a full dataset can be computationally infeasible. Therefore, the findings in [cubuk2020randaugment](#bib.bib31)
    have stimulated future innovations, aimed at balancing effectiveness and efficiency.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: RA 对 AutoDA 任务做出了几个值得注意的贡献。通过对标准 AutoDA 问题的重新参数化，RA 采用了一个仅由两个超参数 $N$ 和 $M$ 控制的简化搜索空间。$N$
    表示单个 DA 策略中包含的 TF 数量，而 $M$ 指的是所有图像操作的统一失真参数。在 RA 中，$N$ 和 $M$ 的优化是通过简单的网格搜索实现的。这一特性使
    RA 能够轻松扩展到更大的数据集和更深的模型，而不会显著增加搜索成本。此外，RA 在各种数据集上表现出色，与之前的 AutoDA 模型包括 AA [cubuk2019autoaugment](#bib.bib20)、Fast
    AA [lim2019fast](#bib.bib21) 和 PBA [ho2019population](#bib.bib23) 相匹配甚至超越。这一发现展示了基于代理任务的先前方法的局限性。[cubuk2020randaugment](#bib.bib31)
    中的实验结果也与这一发现一致，表明最佳 DA 策略取决于训练数据和判别网络的规模。从简化的代理任务中学到的 DA 策略可能会导致性能下降。在移除昂贵的搜索阶段后，RA
    通过对目标数据集和分类模型进行直接搜索，避免了学习到的 DA 策略的次优性。最后，[cubuk2020randaugment](#bib.bib31) 中的结果揭示了增强策略与数据集和模型规模之间的关系。大多数现有的
    AutoDA 方法通过使用减少的数据和较小的模型来优化 DA 策略，以加速搜索 [cubuk2019autoaugment](#bib.bib20)；[lim2019fast](#bib.bib21)；[ho2019population](#bib.bib23)，然而这导致了次优的性能。在实际应用中，搜索完整数据集可能在计算上不可行。因此，[cubuk2020randaugment](#bib.bib31)
    中的发现刺激了未来的创新，旨在平衡效果和效率。
- en: 5.3.2 UniformAugment (UA)
  id: totrans-282
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 UniformAugment (UA)
- en: UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58) is another search-free
    method that also significantly reduces the parameter space. Unlike RA which employs
    a grid search to tune its augmentation parameters, UA completely eliminates the
    need for hyper-parameter optimization. Instead, UA restricts the range of values
    over which the policy hyper-parameters can be sampled, so that all DA policies
    falling into this range can preserve the original label of most of the data. Such
    a range is defined as an approximately invariant augmentation space in UA. A simple
    uniform sampling from the invariant space can produce effective DA policies, and
    eventually lead to sufficient performance gains. As a result, UA greatly surpasses
    all existing AutoDA models in terms of efficiency. The efficacy of UA is also
    demonstrated by extensive experiments [cubuk2020randaugment](#bib.bib31) . Using
    the same $15$ augmentation TFs that are implemented in AA [cubuk2019autoaugment](#bib.bib20)
    and other approaches [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)
    ; [cubuk2020randaugment](#bib.bib31) , UA achieves comparable improvements in
    model accuracy. Furthermore, due to the removal of the search phase, UA is by
    far the most scalable AutoDA method, and can be easily applied to different tasks
    in the real world.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58) 是另一种无需搜索的方法，也显著减少了参数空间。与RA通过网格搜索调整增广参数不同，UA完全消除了超参数优化的需要。相反，UA限制了策略超参数可以采样的值范围，以便所有落在该范围内的DA策略可以保留大多数数据的原始标签。这样的范围在UA中被定义为一个近似不变的增广空间。从不变空间中进行简单的均匀采样可以生成有效的DA策略，并最终带来足够的性能提升。因此，UA在效率方面大大超越了所有现有的AutoDA模型。UA的有效性也通过广泛的实验
    [cubuk2020randaugment](#bib.bib31) 得到了证明。使用与AA [cubuk2019autoaugment](#bib.bib20)
    和其他方法 [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) ; [cubuk2020randaugment](#bib.bib31)
    中实现的相同的$15$个增广TF，UA在模型准确性上达到了可比的改进。此外，由于去除了搜索阶段，UA迄今为止是最具可扩展性的AutoDA方法，可以轻松应用于现实世界中的不同任务。
- en: The key concept in UA is the introduction of invariant augmentation space. In
    [lingchen2020uniformaugment](#bib.bib58) , an approximately invariant space is
    defined as a selected value range for the policy hyper-parameters. Each DA policy
    sampled from such a space is able to retain the representative features of the
    original data after transformation. In other words, most of the augmented data
    can still remain within the distribution of the original training set, without
    change of label information. From the perspective of Group Theory [chen2020group](#bib.bib84)
    , when given such an invariant augmentation space, further optimizing policy hyper-parameters
    within this space can only yield limited performance gains, and is therefore unnecessary
    in practice. In that case, a naive random sampling approach might also lead to
    effective strategies, thus avoiding expensive computing cost. The experiments
    in [lingchen2020uniformaugment](#bib.bib58) demonstrates the promising performance
    of UA, supporting the invariance assumption. However, UA is based on the premise
    that an invariant augmentation space is already known. While in UA, the invariant
    range is actually manually decided via empirical evidence from prior works [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) ; [cubuk2020randaugment](#bib.bib31)
    .
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: UA中的关键概念是引入不变增广空间。在 [lingchen2020uniformaugment](#bib.bib58) 中，近似不变空间被定义为策略超参数的选定值范围。从这样一个空间中采样的每个DA策略在变换后能够保留原始数据的代表性特征。换句话说，大多数增广数据仍然可以保持在原始训练集的分布范围内，标签信息不会改变。从群论的角度
    [chen2020group](#bib.bib84) 看，给定这样的不变增广空间，在这个空间内进一步优化策略超参数只能带来有限的性能提升，因此在实践中是没有必要的。在这种情况下，简单的随机采样方法也可能导致有效的策略，从而避免昂贵的计算成本。[lingchen2020uniformaugment](#bib.bib58)
    的实验展示了UA的良好性能，支持了不变性假设。然而，UA的前提是已经知道一个不变增广空间。而在UA中，不变范围实际上是通过前期工作的经验证据手动决定的 [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) ; [cubuk2020randaugment](#bib.bib31)。
- en: Similar to RA [cubuk2020randaugment](#bib.bib31) , UA also explores the influence
    of two hyper-parameters $M$ and $N$, where $M$ refers to the operation magnitude
    and $N$ is the total number of TFs in a given policy. According to empirical evidence
    and theoretical analysis [perez2017effectiveness](#bib.bib36) ; [deng2009imagenet](#bib.bib28)
    , a good augmentation policy should be approximately invariant in order to generate
    in-distribution data, while being able to maximize data variety at the same time
    [lingchen2020uniformaugment](#bib.bib58) . Usually, the generalizability of a
    classification network can be improved if the model is trained on more diverse
    data. This assumption emphasizes the importance of the value range for the magnitude
    $M$. Constraining $M$ within a narrow range can result in limited data diversity,
    whereas sampling policies from a wide $M$ range may produce overly aggressive
    TFs, which can remove original label information. Both results are considered
    sub-optimal, which suggests that there is a trade-off between diversity and correctness
    of learned DA policies.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于RA [cubuk2020randaugment](#bib.bib31)，UA也探讨了两个超参数$M$和$N$的影响，其中$M$指操作幅度，$N$是给定策略中的TF总数。根据实证证据和理论分析
    [perez2017effectiveness](#bib.bib36) ; [deng2009imagenet](#bib.bib28)，一个好的增强策略应该在生成分布内数据时近似不变，同时能够最大化数据多样性
    [lingchen2020uniformaugment](#bib.bib58)。通常，如果模型在更多样化的数据上进行训练，则分类网络的泛化能力可以得到提高。这一假设强调了幅度$M$值范围的重要性。将$M$限制在狭窄范围内可能会导致数据多样性有限，而从较宽的$M$范围中采样的策略可能会产生过于激进的TF，从而删除原始标签信息。这两种结果都被认为是次优的，这表明在数据增强策略的多样性和正确性之间存在权衡。
- en: A similar trade-off can be found during the experiments on hyper-parameter $N$.
    Usually, optimizing $N$ is impractical in most prior AutoDA methods due to limited
    computational resources. However, it is possible to examine various $N$ values
    in search-free models such as RA [cubuk2020randaugment](#bib.bib31) and UA. From
    the results in [lingchen2020uniformaugment](#bib.bib58) , a smaller $N$ value
    usually indicates safer augmentation policies with less TFs applied on the image
    data. The transformed data tend to be less diverse. In contrast, a larger $N$
    value might impose stronger DA operations on the training data and hence has the
    possibility of corrupting the original labels. In order to obtain the optimal
    strength of data augmentation, AutoDA models need to balance between effectiveness
    and safety feature when choosing $N$. After systematic experiments on $N$ values
    in [lingchen2020uniformaugment](#bib.bib58) , $N$ in UA is set to $2$. This is
    sufficient to effectively improve model performance, while maintaining the same
    data distribution after augmentation. Moreover, $N=2$ is also in line with the
    original proposal of AA [cubuk2019autoaugment](#bib.bib20) .
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 在超参数$N$的实验中可以发现类似的权衡。通常，由于计算资源的限制，大多数先前的AutoDA方法中优化$N$是不切实际的。然而，可以在无搜索模型如RA
    [cubuk2020randaugment](#bib.bib31) 和UA中检查各种$N$值。从[lingchen2020uniformaugment](#bib.bib58)中的结果来看，较小的$N$值通常表示安全性更高的增强策略，对图像数据应用的TF较少。转换后的数据往往较少多样化。相反，较大的$N$值可能对训练数据施加更强的DA操作，从而有可能破坏原始标签。为了获得最佳的数据增强强度，AutoDA模型在选择$N$时需要在效果和安全性特征之间取得平衡。在[lingchen2020uniformaugment](#bib.bib58)中对$N$值进行系统实验后，UA中的$N$设置为$2$。这足以有效提高模型性能，同时在增强后保持相同的数据分布。此外，$N=2$也符合AA
    [cubuk2019autoaugment](#bib.bib20)的最初提议。
- en: The contribution of UA has been revolutionary in the field of AutoDA. It not
    only proposes an effective automated DA scheme, but also substantially surpasses
    all existing approaches in terms of efficiency. More importantly, the hypothesis
    of augmentation invariance in [lingchen2020uniformaugment](#bib.bib58) challenges
    the central premise of the AutoDA field. Most prior AutoDA models are motivated
    by the need for automatically searching for optimal augmentation hyper-parameters
    on given datasets, replacing biased and sub-optimal manual design. However, the
    necessity of such searching is questioned in [lingchen2020uniformaugment](#bib.bib58)
    . Authors of UA propose the definition of an invariant augmentation space, in
    such a way that optimising DA hyper-parameters within that space is not necessary.
    This assumption is theoretically supported by group theory in [chen2020group](#bib.bib84)
    . The comparable performance of UA also provides empirical evidence for the validity
    of the invariance hypothesis in data augmentation.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: UA 的贡献在 AutoDA 领域具有革命性。它不仅提出了一个有效的自动化 DA 方案，而且在效率上大大超越了现有的所有方法。更重要的是，[lingchen2020uniformaugment](#bib.bib58)
    中的增强不变性假设挑战了 AutoDA 领域的核心前提。大多数之前的 AutoDA 模型是为了在给定数据集上自动搜索最佳增强超参数，以取代有偏且次优的手动设计。然而，[lingchen2020uniformaugment](#bib.bib58)
    对这种搜索的必要性提出了质疑。UA 的作者提出了一个不变增强空间的定义，以便在该空间内优化 DA 超参数变得不再必要。这个假设在 [chen2020group](#bib.bib84)
    中得到了群论的理论支持。UA 的可比性能也为数据增强中不变性假设的有效性提供了实证证据。
- en: However, how to decide an approximately invariant space for augmentation policy
    remains an open question. The efficacy of UA is mainly based on the application
    of domain knowledge, adapted from previous works [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23) ; [cubuk2020randaugment](#bib.bib31)
    . However, in the real-world scenarios, a given task and domain might be unknown.
    In addition, the pre-defined space of UA is also not guaranteed to be invariant,
    due to the lack of theoretical supports for its selection strategy. Even though
    UA yields positive results in empirical research, it is very likely that the final
    performance of a classification model can be further improved through the use
    of a more reliable policy space. According to [cubuk2020randaugment](#bib.bib31)
    , it is important to develop a systematic methodology to determine an invariant
    policy space when given a specific dataset. Once such a range is decided, it is
    no longer necessary to perform an expensive search for DA hyper-parameters. Any
    augmentation strategy sampled from a invariant space should be effective enough
    for the given task to produce promising performance gains.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，如何为增强策略决定一个大致不变的空间仍然是一个悬而未决的问题。UA 的有效性主要基于领域知识的应用，该知识来源于之前的工作 [cubuk2019autoaugment](#bib.bib20)；[lim2019fast](#bib.bib21)；[ho2019population](#bib.bib23)；[cubuk2020randaugment](#bib.bib31)。然而，在实际场景中，给定的任务和领域可能是未知的。此外，由于缺乏对其选择策略的理论支持，UA
    预定义的空间也不能保证是不变的。尽管 UA 在实证研究中取得了积极结果，但通过使用更可靠的策略空间，分类模型的最终性能很可能会进一步提高。根据 [cubuk2020randaugment](#bib.bib31)，在给定特定数据集时，开发一个系统的方法来确定不变的策略空间是重要的。一旦确定了这样的范围，就不再需要对
    DA 超参数进行昂贵的搜索。从不变空间中采样的任何增强策略应该足够有效，以便在给定任务中产生令人满意的性能提升。
- en: 6 One-stage Approaches
  id: totrans-289
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 一阶段方法
- en: After the pioneering AutoDA works such as AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20)
    , it is intuitive to approach AutoDA problems from a two-stage perspective. In
    the first policy generation phase, AutoDA models generate the optimal DA policy
    for a given dataset. In the second stage, the learned policy is then applied on
    the training set for model training. Optimization of policy hyper-parameters and
    network weights are performed in strict order. However, the separate generation
    stage in two-stage approaches results in additional computational complexity,
    which is also the major reason for their efficiency issues. For example, the original
    AA [cubuk2019autoaugment](#bib.bib20) requires thousands of GPU hours to learn
    an effective augmentation policy better than the baseline.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在开创性的 AutoDA 工作如 AutoAugment (AA) [cubuk2019autoaugment](#bib.bib20) 之后，从两阶段的角度处理
    AutoDA 问题是直观的。在第一个策略生成阶段，AutoDA 模型为给定数据集生成最佳 DA 策略。在第二阶段，学习到的策略随后在训练集上应用以进行模型训练。策略超参数和网络权重的优化是严格顺序执行的。然而，两阶段方法中的单独生成阶段导致了额外的计算复杂性，这也是它们效率问题的主要原因。例如，原始的
    AA [cubuk2019autoaugment](#bib.bib20) 需要数千小时的 GPU 时间才能学习到比基线更有效的增强策略。
- en: To improve the efficiency of AutoDA models, one idea is to perform the policy
    generation and application simultaneously, thus forgoing the extra computation
    in two stages. Despite inefficiency of the two-stage methods, it is inherently
    impractical to merge two stages and optimize the DA policy along with the classification
    model. This is because tuning policy hyper-parameters based on model performance
    is not a differentiable optimization problem. In other words, the gradients of
    augmentation hyper-parameters cannot be directly calculated nor optimized, thus
    precluding the possibility of joint optimization. However, with advances of gradient
    approximation techniques from Hyper-parameter Optimization (HPO) field, it is
    feasible to relax the original distribution and estimate policy gradients, allowing
    for one-stage AutoDA models.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高 AutoDA 模型的效率，一个想法是同时进行策略生成和应用，从而省略两个阶段的额外计算。尽管两阶段方法效率低下，但将两个阶段合并并优化 DA
    策略与分类模型本质上是不切实际的。这是因为根据模型性能调优策略超参数并不是一个可微分优化问题。换句话说，增强超参数的梯度无法直接计算或优化，从而排除了联合优化的可能性。然而，随着梯度近似技术在超参数优化（HPO）领域的进步，放宽原始分布并估计策略梯度是可行的，从而实现了一阶段的
    AutoDA 模型。
- en: This section reviews existing one-stage AutoDA methods including Online Hyper-parameter
    Learning AutoAugment (OHL-AA) [lin2019online](#bib.bib54) , Adversarial AutoAugment
    (AAA) [zhang2019adversarial](#bib.bib53) , Differentiable Automatic Data Augmentation
    (DADA) [li2020dada](#bib.bib57) and Automated Dataset Optimization (AutoDO) [gudovskiy2021autodo](#bib.bib62)
    . All of these approaches are based on gradient approximation through the use
    of differentiable frameworks. We discuss the formulation of optimization problem
    in each method. In particular, we focus on gradient approximation, which is the
    core technique in one-stage models. Lastly, we discuss the main contributions
    and limitations of each method.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本节回顾了现有的一阶段 AutoDA 方法，包括 Online Hyper-parameter Learning AutoAugment (OHL-AA)
    [lin2019online](#bib.bib54)，Adversarial AutoAugment (AAA) [zhang2019adversarial](#bib.bib53)，Differentiable
    Automatic Data Augmentation (DADA) [li2020dada](#bib.bib57) 和 Automated Dataset
    Optimization (AutoDO) [gudovskiy2021autodo](#bib.bib62)。这些方法都基于通过使用可微分框架的梯度近似。我们讨论了每种方法中的优化问题的公式。特别地，我们关注梯度近似，这是一个阶段模型中的核心技术。最后，我们讨论了每种方法的主要贡献和局限性。
- en: 6.1 Gradient-based Optimization
  id: totrans-293
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.1 基于梯度的优化
- en: 6.1.1 Online Hyper-parameter Learning AutoAugment (OHL-AA)
  id: totrans-294
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.1 Online Hyper-parameter Learning AutoAugment (OHL-AA)
- en: Before the proposal of Online Hyper-parameter Learning AutoAugment (OHL-AA)
    [lin2019online](#bib.bib54) , the majority of the works in automated DA optimization
    followed the basic two-stage procedure [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21)
    ; [ho2019population](#bib.bib23) . Despite promising performance, most two-stage
    methods have serious bottlenecks in search time and cost. The authors of OHL-AA
    argue that the major cause of efficiency issues is the offline search, i.e. policy
    searching is performed independently of the final model training. In contrast,
    OHL-AA model applies an online scheme, where the policy hyper-parameters and network
    weights are optimized jointly in a single pass. In OHL-AA, policy hyper-parameters
    are formulated as probability distributions. Additionally, the gradients of DA
    policy are approximated via the use of the REINFORCE estimator [williams1992simple](#bib.bib55)
    , which allows for direct optimization during model training. The final outputs
    of OHL-AA not only include the optimal DA policy for given task, but also contain
    the completely trained classification network. By combining the searching and
    training stages, the OHL-AA model reduces additional computational costs resulting
    from two stages, while still maintaining comparable performance.
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在提出在线超参数学习 AutoAugment（OHL-AA）[lin2019online](#bib.bib54)之前，大多数自动化数据增强（DA）优化工作都遵循基本的两阶段程序
    [cubuk2019autoaugment](#bib.bib20) ; [lim2019fast](#bib.bib21) ; [ho2019population](#bib.bib23)。尽管表现令人鼓舞，但大多数两阶段方法在搜索时间和成本方面存在严重瓶颈。OHL-AA的作者认为，效率问题的主要原因是离线搜索，即策略搜索与最终模型训练是独立进行的。相比之下，OHL-AA模型采用在线方案，其中策略超参数和网络权重在单次传递中联合优化。在OHL-AA中，策略超参数被制定为概率分布。此外，DA策略的梯度通过使用REINFORCE估计器
    [williams1992simple](#bib.bib55) 进行近似，这允许在模型训练期间进行直接优化。OHL-AA的最终输出不仅包括给定任务的最佳DA策略，还包含完全训练好的分类网络。通过结合搜索和训练阶段，OHL-AA模型减少了由于两个阶段而产生的额外计算成本，同时仍然保持了可比的性能。
- en: Following the problem formulation in AA [cubuk2019autoaugment](#bib.bib20) ,
    OHL-AA also approaches AutoDA problem from the perspective of hyper-parameter
    optimization, but using a different optimization framework. Specifically, the
    DA policy in OHL-AA is sampled from a parameterized probability distribution,
    whose parameters are regarded as DA hyper-parameters that are optimized along
    with network weights. The joint optimization is achieved via a bi-level framework
    [colson2007overview](#bib.bib71) . There are two layers of optimization in this
    bi-level setting. The inner objective is the training of classification model,
    while the outer objective is the optimization of the policy hyper-parameters through
    the use of REINFORCE gradient approximator [williams1992simple](#bib.bib55) .
    Due to this bi-level optimization, OHL-AA is also acknowledged as an online AutoDA
    model, where the DA policy is updated together with the classification network.
    By optimizing the DA policy and task model simultaneously, OHL-AA completely discards
    the searching on small proxy tasks. Unlike previous two-stage methods [cubuk2019autoaugment](#bib.bib20)
    ; [ho2019population](#bib.bib23) , policy optimization in OHL-AA no longer requires
    thousands of evaluations, e.g. training of surrogate models. OHL-AA can directly
    optimize the DA policy through classical gradient descent algorithm, which substantially
    improves the search efficiency.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 在AA [cubuk2019autoaugment](#bib.bib20)的问问题形式化之后，OHL-AA也从超参数优化的角度处理AutoDA问题，但使用了不同的优化框架。具体而言，OHL-AA中的DA策略是从参数化概率分布中采样的，其参数被视为与网络权重一起优化的DA超参数。通过双层框架
    [colson2007overview](#bib.bib71) 实现联合优化。在这种双层设置中，有两个优化层次。内层目标是分类模型的训练，而外层目标是通过使用REINFORCE梯度近似器
    [williams1992simple](#bib.bib55) 来优化策略超参数。由于这种双层优化，OHL-AA也被认为是一个在线AutoDA模型，其中DA策略与分类网络一起更新。通过同时优化DA策略和任务模型，OHL-AA完全抛弃了在小代理任务上的搜索。与先前的两阶段方法
    [cubuk2019autoaugment](#bib.bib20) ; [ho2019population](#bib.bib23) 不同，OHL-AA中的策略优化不再需要成千上万的评估，例如替代模型的训练。OHL-AA可以通过经典的梯度下降算法直接优化DA策略，这大大提高了搜索效率。
- en: '![Refer to caption](img/aa8aebfb1c2cadb875b5b01396466d9b.png)'
  id: totrans-297
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/aa8aebfb1c2cadb875b5b01396466d9b.png)'
- en: 'Figure 9: Online Hyper-parameter Learning AutoAugment (OHL-AA) workflow [lin2019online](#bib.bib54)
    .'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：在线超参数学习 AutoAugment（OHL-AA）工作流程 [lin2019online](#bib.bib54)。
- en: Inspired by [franceschi2017forward](#bib.bib85) , policy hyper-parameters in
    OHL-AA are updated in a forward manner. Specifically, the network weights after
    a certain number $I$ of epochs of inner optimization are forwarded to the outer
    optimization for an update at the outer level. In other words, the inner objective
    is updated for $I$ steps between two adjacent updates at the outer level. The
    overall workflow of OHL-AA is illustrated in Fig. [9](#S6.F9 "Figure 9 ‣ 6.1.1
    Online Hyper-parameter Learning AutoAugment (OHL-AA) ‣ 6.1 Gradient-based Optimization
    ‣ 6 One-stage Approaches ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks"). The bi-level optimization
    problem in OHL-AA is represented by two overlapping loops. In the inner loop,
    a group of the same classification models are trained in parallel using different
    DA policies, each of which is designed to evaluate the efficacy of the associated
    augmentation policy. After $I$ training epochs, all models are evaluated on the
    validation set. Among these models, the one with the highest validation accuracy
    is selected and broadcast to other models to synchronize network weights.
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
  zh: 受到 [franceschi2017forward](#bib.bib85) 启发，OHL-AA中的策略超参数以前向方式进行更新。具体而言，经过一定数量$I$的内部优化周期后，网络权重会被转发到外部优化中进行更新。在其他
    words，内部目标在两个相邻的外部级别更新之间更新了$I$步。OHL-AA的整体工作流程如图 [9](#S6.F9 "Figure 9 ‣ 6.1.1 Online
    Hyper-parameter Learning AutoAugment (OHL-AA) ‣ 6.1 Gradient-based Optimization
    ‣ 6 One-stage Approaches ‣ A Survey of Automated Data Augmentation Algorithms
    for Deep Learning-based Image Classification Tasks") 所示。OHL-AA中的双层优化问题由两个重叠的循环表示。在内部循环中，使用不同的DA策略并行训练一组相同的分类模型，每个模型设计用于评估相关增强策略的效果。在$I$个训练周期后，所有模型在验证集上进行评估。在这些模型中，选择验证准确度最高的模型，并将其广播到其他模型以同步网络权重。
- en: Outer optimization is performed along with the inner procedures. In the outer
    loop, after the same $I$ number of inner updates, accuracy values are used to
    optimize the probability distributions of the DA policy. To be specific, after
    obtaining the validation accuracies of models, OHL-AA first calculates the average
    gradient of them using the distribution hyper-parameters (via the REINFORCE algorithm
    [williams1992simple](#bib.bib55) ). Such gradients are then used to update the
    policy distributions as a one step of gradient ascent. After the update, new augmentation
    policies are sampled from the updated distributions, and then used to train a
    group of synchronized networks. The whole process continues iteratively until
    the network or policy distribution finally converges. Overall, OHL-AA aims to
    find the optimal policy distribution that can generate the best DA policy. This
    framework drastically reduces the search cost, as the policy hyper-parameters
    are updated using only $I$ steps of model optimization instead of a complete training.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 外部优化与内部程序同时进行。在外部循环中，在经过相同数量的内部更新后，使用准确度值来优化DA策略的概率分布。具体而言，在获得模型的验证准确度后，OHL-AA首先使用分布超参数（通过REINFORCE算法
    [williams1992simple](#bib.bib55)）计算它们的平均梯度。然后，利用这些梯度来更新策略分布，作为梯度上升的一步。更新后，从更新后的分布中采样新的增强策略，然后用这些策略训练一组同步网络。整个过程会迭代进行，直到网络或策略分布最终收敛。总体而言，OHL-AA旨在找到可以生成最佳DA策略的最优策略分布。这个框架大大减少了搜索成本，因为策略超参数是通过仅仅$I$步模型优化而不是完整训练来更新的。
- en: The biggest contribution of OHL-AA is the proposal of the bi-level framework.
    It is also considered to be the first one-stage AutoDA model that optimizes both
    the DA policy and the network weights in a single pass. The removal of repetitive
    model training and proxy tasks significantly reduces the overall search cost.
    According to the results in [lin2019online](#bib.bib54) , OHL-AA is $60\times$
    faster than the original AA [cubuk2019autoaugment](#bib.bib20) on CIFAR-10 and
    $24\times$ faster on ImageNet data, while still maintaining comparable model performance.
    In addition, the probability distribution of the DA policy in OHL-AA provides
    a feasible differentiation method for estimating policy gradients of AutoDA problems,
    which stimulates innovations in later one-stage approaches, such as DADA [li2020dada](#bib.bib57)
    and AutoDO [gudovskiy2021autodo](#bib.bib62) .
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: OHL-AA 的最大贡献是提出了双层框架。它还被认为是第一个在单次操作中优化 DA 策略和网络权重的单阶段 AutoDA 模型。通过去除重复的模型训练和代理任务，显著降低了整体搜索成本。根据
    [lin2019online](#bib.bib54) 的结果，OHL-AA 在 CIFAR-10 上比原始的 AA [cubuk2019autoaugment](#bib.bib20)
    快 $60\times$，在 ImageNet 数据上快 $24\times$，同时保持了相当的模型性能。此外，OHL-AA 中 DA 策略的概率分布为估计
    AutoDA 问题的策略梯度提供了可行的区分方法，这刺激了后续单阶段方法的创新，如 DADA [li2020dada](#bib.bib57) 和 AutoDO
    [gudovskiy2021autodo](#bib.bib62)。
- en: 6.1.2 Adversarial AutoAugment (AAA)
  id: totrans-302
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.2 对抗性 AutoAugment (AAA)
- en: Adversarial AutoAugment (AAA) [zhang2019adversarial](#bib.bib53) is another
    one-stage AutoDA model that simultaneously optimizes the target network and augmentation
    policy. In additional to gradient approximation of DA policy, AAA innovatively
    employs adversarial concepts of GANs, leading to a more computationally efficient
    AutoDA approach. The ultimate goal of the AAA method is to best train the target
    classification model, rather than searching for the optimal DA policy. Similar
    to OHL-AA [lin2019online](#bib.bib54) , training and searching in AAA are conducted
    in an online way, where the augmentation policy is dynamically updated along the
    training of discriminative model. Such procedures in AAA avoid the need for re-training
    the classification model, which significantly decreases the computational cost.
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: 对抗性 AutoAugment (AAA) [zhang2019adversarial](#bib.bib53) 是另一个同时优化目标网络和增强策略的单阶段
    AutoDA 模型。除了 DA 策略的梯度近似外，AAA 创新性地采用了 GAN 的对抗性概念，从而实现了更具计算效率的 AutoDA 方法。AAA 方法的最终目标是最佳地训练目标分类模型，而不是搜索最优的
    DA 策略。与 OHL-AA [lin2019online](#bib.bib54) 类似，AAA 的训练和搜索以在线方式进行，其中增强策略在辨别模型训练的过程中动态更新。这种过程避免了重新训练分类模型，从而显著降低了计算成本。
- en: AAA preserves the standard formulation of the AutoDA problem in AA [cubuk2019autoaugment](#bib.bib20)
    . In AAA, a complete augmentation policy for full dataset contains $5$ sub-policies.
    Each sub-policy is applied on one data batch before training the target model.
    A sub-policy is composed of two separate augmentation transformation functions,
    each of which is controlled by two hyper-parameters, i.e. probability and magnitude.
    To obtain better performance and easily compare with the original AA [cubuk2019autoaugment](#bib.bib20)
    , AAA precludes the probability factor of augmentation operations during training.
    According to [zhang2019adversarial](#bib.bib53) , such hyper-parameter requires
    a certain number of training epochs to take effect. This is effective for offline
    frameworks such as AA [cubuk2019autoaugment](#bib.bib20) , because policy models
    are updated based on the result of full training on a child model. However, in
    an online AAA model, DA policy is dynamically evolved along with the training
    of target networks. The number of training epochs for each update is not sufficient
    to fully demonstrate the randomness of image operations, which may constrain the
    optimal strength of reward signal.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: AAA 保留了 AA [cubuk2019autoaugment](#bib.bib20) 中 AutoDA 问题的标准公式。在 AAA 中，完整数据集的增强策略包含
    $5$ 个子策略。每个子策略在训练目标模型之前应用于一个数据批次。一个子策略由两个独立的增强变换函数组成，每个函数由两个超参数控制，即概率和幅度。为了获得更好的性能并便于与原始
    AA [cubuk2019autoaugment](#bib.bib20) 进行比较，AAA 在训练过程中排除了增强操作的概率因子。根据 [zhang2019adversarial](#bib.bib53)，这种超参数需要一定数量的训练轮次才能生效。这对像
    AA [cubuk2019autoaugment](#bib.bib20) 这样的离线框架有效，因为策略模型是基于对子模型的全面训练结果更新的。然而，在在线
    AAA 模型中，DA 策略随着目标网络的训练动态演变。每次更新的训练轮次不足以充分展示图像操作的随机性，这可能会限制奖励信号的最佳强度。
- en: In AAA, network training and DA policy generation is performed simultaneously.
    Different from standard two-stage approaches, the augmentation policy is dynamically
    updated rather than fixed during model training. As with other one-stage AutoDA
    methods, AAA also needs to perform gradient approximation on DA hyper-parameters
    to support joint optimization in a non-differentiable framework [wang2017fast](#bib.bib86)
    ; [peng2018jointly](#bib.bib87) . Specifically, the REINFORCE algorithm [williams1992simple](#bib.bib55)
    is applied in AAA to estimate the policy gradient. The overall framework of AAA
    follows a standard GAN structure, consisting of a policy model as well as a target
    model. The training of these two models is formulated as a min-max game in an
    adversarial way. The policy model here is regarded as an adversary. During the
    training, the target network aims to minimize the training loss over the input
    data, while the objective of the policy network is to maximize the training loss
    of the target model by generating adversarial DA policies. These adversarial policies
    force the target model to learn from harder data samples and thus substantially
    improve its generalizability. When updating the policy network, the reward signal
    used comes from the training losses of target network after normalization. These
    loss values are associated with different augmentation strategies to indicate
    the efficacy of DA policies respectively.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 在AAA中，网络训练和DA策略生成是同时进行的。不同于标准的两阶段方法，增强策略在模型训练过程中是动态更新的，而不是固定的。与其他单阶段AutoDA方法一样，AAA还需要对DA超参数进行梯度近似，以支持在不可微分框架中的联合优化
    [wang2017fast](#bib.bib86) ; [peng2018jointly](#bib.bib87) 。具体而言，AAA中应用了REINFORCE算法
    [williams1992simple](#bib.bib55) 来估计策略梯度。AAA的整体框架遵循标准的GAN结构，包括一个策略模型和一个目标模型。这两个模型的训练被表述为一种对抗性最小-最大游戏。这里的策略模型被视为对手。在训练过程中，目标网络的目标是最小化输入数据上的训练损失，而策略网络的目标是通过生成对抗性DA策略来最大化目标模型的训练损失。这些对抗性策略迫使目标模型从更困难的数据样本中学习，从而显著提高其泛化能力。在更新策略网络时，使用的奖励信号来自经过归一化后的目标网络训练损失。这些损失值与不同的增强策略相关联，以分别指示DA策略的有效性。
- en: The major motivation for proposing AAA is the limited randomness of traditional
    policy search. Although the enormous search space in most AA-based approaches
    allows for a large variety of policy candidates [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) , fixing the sampled policy during the entire model
    training often leads to an inevitable overfitting problem [ho2019population](#bib.bib23)
    . To tackle this issue, AAA chooses to use a dynamic augmentation policy, which
    is updated based on the state of the target model during training. The concept
    of dynamic DA policy was first proposed in PBA [ho2019population](#bib.bib23)
    , where the application schedule of TFs was especially emphasized by sharing TF
    prefixes. While in AAA, the stochasticity of the policy search was further enhanced,
    as the entire DA policy was updated along with model training, rather than just
    a subset of TFs within one policy. The increased randomness in policy sampling
    provides the augmented data with more diversity, and thus can better train the
    target model.
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
  zh: 提出AAA的主要动机是传统策略搜索的随机性有限。尽管大多数基于AA的方法的庞大搜索空间允许多种策略候选 [cubuk2019autoaugment](#bib.bib20)
    ; [lim2019fast](#bib.bib21) ，在整个模型训练过程中固定采样的策略通常会导致不可避免的过拟合问题 [ho2019population](#bib.bib23)
    。为了解决这个问题，AAA选择使用动态增强策略，该策略基于训练期间目标模型的状态进行更新。动态DA策略的概念最早在PBA中提出 [ho2019population](#bib.bib23)
    ，其中特别强调了通过共享TF前缀来应用TF的时间表。而在AAA中，策略搜索的随机性得到了进一步增强，因为整个DA策略在模型训练过程中不断更新，而不仅仅是一个策略中的部分TF。策略采样的随机性增加为增强数据提供了更多的多样性，从而更好地训练目标模型。
- en: Another motivation of AAA is the efficiency problem existing in most AutoDA
    methods. The first AutoDA model AA [cubuk2019autoaugment](#bib.bib20) was largely
    criticized due to its excessive training time. Later works such as PBA [ho2019population](#bib.bib23)
    manage to accelerate the whole process by trading time with space. Although the
    overall search time is substantially decreased, training a large population of
    child models simultaneously still requires significant computational resources.
    AAA, however, is considered to be computation-efficient and resource-friendly.
    During the search in AAA, the target model only needs to be trained once. By reusing
    the prior computation in training, policy networks are updated based on the intermediate
    state of target models instead of the final result. By the end of training, the
    target network is supposed to be optimized via combating adversarial policies.
    Due to the reduced computational cost and time overheads, AAA can directly perform
    searching on the full data using the target network. A direct search not only
    guarantees the effectiveness of AAA, but also eliminates the potential sub-optimality
    that may result from employing proxy tasks.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: AAA的另一个动机是大多数AutoDA方法中存在的效率问题。第一个AutoDA模型AA[cubuk2019autoaugment](#bib.bib20)由于训练时间过长而受到广泛批评。后来如PBA[ho2019population](#bib.bib23)等工作通过以时间换空间加速了整个过程。尽管整体搜索时间显著减少，但同时训练大量子模型仍需大量计算资源。然而，AAA被认为是计算高效且资源友好的。在AAA的搜索过程中，目标模型只需要训练一次。通过重用训练中的先前计算，策略网络基于目标模型的中间状态而非最终结果进行更新。在训练结束时，目标网络应该通过对抗策略得到优化。由于计算成本和时间开销的减少，AAA可以直接在完整数据上使用目标网络进行搜索。直接搜索不仅保证了AAA的有效性，还消除了使用代理任务可能导致的潜在次优性。
- en: The most significant innovation in AAA is its adversarial framework. In fact,
    adversarial learning is not the first time it has been utilized in AutoDA problems.
    The earliest TANDA approach [ratner2017learning](#bib.bib52) also employed standard
    GAN structures, which used policy models as generators to sample DA policies,
    while another discriminative network was used to identify augmented samples out
    of the original data for policy evaluation. On the contrary, AAA uses policy model
    as an adversary against the training of the target model. The policy model in
    AAA produces aggressive DA policies that maximize the training loss. The data
    transformed by these policies are often more distorted, making it more difficult
    for target models to distinguish, which in turn allows the target model to learn
    more robust features via adversarial learning. The final goal of AAA is not just
    finding the optimal policy on given dataset. Instead, AAA places more emphasis
    on the final result of target model training. By feeding deformed examples, AAA
    trains the classification network, allowing it to be more resilient to a variety
    of data points, thereby greatly enhancing its ability of generalization.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: AAA中最重要的创新是其对抗框架。实际上，对抗学习并不是第一次在AutoDA问题中被利用。最早的TANDA方法[ratner2017learning](#bib.bib52)也使用了标准的GAN结构，该结构使用策略模型作为生成器来采样DA策略，而另一个判别网络则用于从原始数据中识别增强样本以进行策略评估。相反，AAA将策略模型作为对抗目标模型训练的对手。在AAA中，策略模型生成的对抗性DA策略会最大化训练损失。这些策略转化的数据通常更为扭曲，使目标模型更难区分，从而通过对抗学习让目标模型学习到更强健的特征。AAA的最终目标不仅仅是找到给定数据集上的最佳策略。相反，AAA更强调目标模型训练的最终结果。通过输入变形的示例，AAA训练分类网络，使其对各种数据点更加有弹性，从而大大增强了其泛化能力。
- en: In addition, AAA also outperforms previous AutoDA methods in terms of evaluation.
    AAA directly evaluates the performance of target model via training loss, while
    in methods such as TANDA [ratner2017learning](#bib.bib52) or Fast AA [lim2019fast](#bib.bib21)
    , the effectiveness of DA policies is estimated using the similarity of the augmented
    data to the original data. Generally, it is considered to be an effective policy
    if transformed pictures resemble the original samples. Such approximation might
    result in potential performance degradation due to the lack of variety in the
    learned policies. However, this issue can be substantially mitigated in AAA as
    the training loss is used as an intuitive criteria to evaluate the target model.
    The experimental results in [xie2020adversarial](#bib.bib77) also show that classification
    networks trained in AAA have higher accuracy than previous methods.
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，AAA在评估方面也优于之前的AutoDA方法。AAA通过训练损失直接评估目标模型的性能，而在如TANDA [ratner2017learning](#bib.bib52)
    或Fast AA [lim2019fast](#bib.bib21) 等方法中，DA策略的有效性是通过增强数据与原始数据的相似性来估计的。一般认为，如果转换后的图像类似于原始样本，则该策略是有效的。然而，这种近似可能由于学习策略缺乏多样性而导致性能下降。尽管如此，AAA通过使用训练损失作为直观标准来评估目标模型，能够在很大程度上缓解这个问题。[xie2020adversarial](#bib.bib77)中的实验结果也表明，AAA训练的分类网络比之前的方法具有更高的准确率。
- en: 6.1.3 Differentiable Automatic Data Augmentation (DADA)
  id: totrans-310
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.3 可微分自动数据增强（DADA）
- en: Motivated by the development of differentiable NAS [dong2019searching](#bib.bib88)
    ; [liu2018darts](#bib.bib56) ; [simonyan2014very](#bib.bib3) , a number of one-stage
    AutoDA approaches have been proposed following OHL-AA [lin2019online](#bib.bib54)
    . Differentiable Automatic Data Augmentation (DADA) is another effective method
    that relies on gradient approximation to optimize model weights and DA policy
    at the same time. The basic gradient estimator utilized in DADA is the Gumbel-Softmax
    gradient estimator [jang2016categorical](#bib.bib70) . Additionally, DADA also
    proposes a new estimator named RELAX, which is designed to solve the imbalance
    problem of training data. By combining two gradient approximators, DADA suggests
    an effective and efficient DA policy learning, which is more robust to biased
    or noisy data.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 受可微分NAS [dong2019searching](#bib.bib88) ; [liu2018darts](#bib.bib56) ; [simonyan2014very](#bib.bib3)
    的发展激励，提出了多个单阶段AutoDA方法，继承了OHL-AA [lin2019online](#bib.bib54) 。可微分自动数据增强（DADA）是一种有效的方法，它依赖于梯度近似来同时优化模型权重和DA策略。DADA中使用的基本梯度估计器是Gumbel-Softmax梯度估计器
    [jang2016categorical](#bib.bib70) 。此外，DADA还提出了一种名为RELAX的新估计器，旨在解决训练数据的不平衡问题。通过结合两种梯度近似器，DADA提出了一种有效且高效的DA策略学习方法，更能抵抗偏倚或噪声数据。
- en: The formulation of the DA policy in DADA follows the standard setting of AA
    [cubuk2019autoaugment](#bib.bib20) . A complete augmentation policy is comprised
    of $25$ sub-policies, each of which will be used to augment one data batch of
    training set. One sub-policy contains two TFs, which are described by two hyper-parameters
    (probability and magnitude). Similar to AAA [zhang2019adversarial](#bib.bib53)
    , DADA also uses the probability distributions to encode augmentation TFs when
    sampling DA policies. The sub-policy is sampled from the categorical distribution,
    and the hyper-parameters of each transformation are approximated as Bernoulli
    distributions. After the re-parameterization of the search space, the AutoDA task
    is formulated as a Monte-Carlo optimization problem [mohamed2020monte](#bib.bib89)
    in DADA. The search of the DA policy and training of classification can be conducted
    simultaneously within this bi-level optimization framework. However, both categorical
    and Bernoulli distributions are not differentiable. To directly optimize policy
    hyper-parameters, it is necessary to perform gradient approximation on these non-differentiable
    prior to policy search. Inspired by DARTS [liu2018darts](#bib.bib56) , DADA employs
    the Gumbel-Softmax gradient estimator [jang2016categorical](#bib.bib70) , which
    is also known as a concrete distribution [maddison2016concrete](#bib.bib90) .
    Such a gradient estimator is used to relax the distributions of augmentation operations.
    As for the operation hyper-parameters, i.e. operation probability and magnitude,
    an unbiased estimator RELAX [grathwohl2017backpropagation](#bib.bib91) is applied
    to obtain their gradients with regard to model performance.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: DADA中DA策略的制定遵循了AA [cubuk2019autoaugment](#bib.bib20) 的标准设置。完整的增强策略由$25$个子策略组成，每个子策略将用于增强一个训练集的数据批次。一个子策略包含两个TF，这两个TF由两个超参数（概率和幅度）描述。类似于AAA
    [zhang2019adversarial](#bib.bib53) ，DADA在采样DA策略时也使用概率分布来编码增强TF。子策略是从类别分布中采样的，每个变换的超参数被近似为伯努利分布。经过搜索空间的重新参数化，AutoDA任务在DADA中被公式化为蒙特卡罗优化问题
    [mohamed2020monte](#bib.bib89) 。在这个双层优化框架内，可以同时进行DA策略的搜索和分类训练。然而，类别分布和伯努利分布都不可导。为了直接优化策略超参数，有必要在策略搜索之前对这些不可导分布进行梯度近似。受DARTS
    [liu2018darts](#bib.bib56) 启发，DADA采用了Gumbel-Softmax梯度估计器 [jang2016categorical](#bib.bib70)
    ，它也被称为具体分布 [maddison2016concrete](#bib.bib90) 。这种梯度估计器用于放松增强操作的分布。至于操作超参数，即操作概率和幅度，使用无偏估计器RELAX
    [grathwohl2017backpropagation](#bib.bib91) 来获得它们相对于模型性能的梯度。
- en: The gradient relaxation in DADA consists of two parts, including the re-parameterization
    of categorical distribution for sub-policy selection, and the approximation of
    Bernoulli distributions for image operation hyper-parameters. In DADA, the sub-policy
    to augment data batches is selected from a categorical distribution. The preference
    for each sub-policy is defined using a probability parameter. After optimizing
    the parameter for categorical distribution, the sub-policies associated with higher
    probability will be selected to form the final DA policy. However, the parameter
    of sub-policy conforms to a non-differentiable distribution. Inspired by its success
    in the NAS field [xie2018snas](#bib.bib92) ; [dong2019searching](#bib.bib88) ,
    DADA employs the Gumbel-Softmax estimator [jang2016categorical](#bib.bib70) to
    approximate the gradient of parameters for sub-policy selection. For hyper-parameters
    to describe augmentation TFs, both application probability and magnitude are sampled
    from Bernoulli distributions. Similar to categorical distribution, Bernoulli distributions
    are not differentiable. To overcome the gradient issue, the same relaxation procedure
    is applied on Bernoulli distributions to obtain the gradient of TF hyper-parameters.
    Moreover, to mitigate the bias resulting from gradient approximations, DADA employs
    the RELAX estimator [grathwohl2017backpropagation](#bib.bib91) , to achieve an
    unbiased gradient estimation, which further improves the policy search.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: DADA中的梯度放松包括两个部分：类别分布的再参数化用于子策略选择，以及对图像操作超参数的Bernoulli分布的近似。在DADA中，数据批次的增广子策略是从类别分布中选择的。每个子策略的偏好使用概率参数定义。在优化了类别分布的参数后，与较高概率相关的子策略将被选中以形成最终的DA策略。然而，子策略的参数符合非可微分的分布。受到其在NAS领域成功的启发
    [xie2018snas](#bib.bib92)；[dong2019searching](#bib.bib88)，DADA采用了Gumbel-Softmax估计器
    [jang2016categorical](#bib.bib70) 来近似子策略选择参数的梯度。对于描述增广TF的超参数，应用概率和幅度都从Bernoulli分布中采样。类似于类别分布，Bernoulli分布是不可微的。为克服梯度问题，对Bernoulli分布应用相同的放松过程以获得TF超参数的梯度。此外，为了减轻梯度近似带来的偏差，DADA采用了RELAX估计器
    [grathwohl2017backpropagation](#bib.bib91) 实现无偏梯度估计，进一步改进了策略搜索。
- en: The major contribution of DADA is the innovation regarding gradient approximation.
    Instead of using a standard Gumbel-Softmax approximator, DADA applies unbiased
    RELAX estimator [grathwohl2017backpropagation](#bib.bib91) , which estimates gradients
    more accurately. Through extensive experiments [li2020dada](#bib.bib57) , DADA
    models using the RELAX gradient estimator achieve higher accuracy especially when
    compared with models using Gumbel-Softmax. DADA provides not only enhanced model
    performance, but also offers a significant speedup of the search process over
    alternative AutoDA approaches. Due to its increased efficiency, the search of
    DA policy in DADA is conducted on the full dataset instead of a reduced subset,
    which also improves the final results. In the field of automated DA policy search,
    the common sense is that using more data for the policy search will provide more
    information about the target task, and thus lead to a better final policy. On
    the other hand, a large amount of data will slow down the searching and raise
    time issues. This results in a trade-off between performance and efficiency in
    most AutoDA models. However, unlike prior methods such as AA [cubuk2019autoaugment](#bib.bib20)
    and Fast AA [lim2019fast](#bib.bib21) , DADA is able to well balance model accuracy
    and search costs in resource-constrained environment. Due to its efficiency, DADA
    is considered to be a feasible AutoDA approach for practical application.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
  zh: DADA的主要贡献在于梯度近似的创新。DADA不使用标准的Gumbel-Softmax近似器，而是应用了无偏的RELAX估计器 [grathwohl2017backpropagation](#bib.bib91)，该估计器能更准确地估计梯度。通过大量实验
    [li2020dada](#bib.bib57)，使用RELAX梯度估计器的DADA模型实现了更高的准确性，特别是相比于使用Gumbel-Softmax的模型。DADA不仅提供了增强的模型性能，还显著加速了搜索过程，相比于其他AutoDA方法。由于其提高的效率，DADA中的DA策略搜索是在完整数据集上进行的，而不是在减少的子集上，这也提升了最终结果。在自动化DA策略搜索领域，常识是使用更多的数据进行策略搜索将提供更多关于目标任务的信息，从而得到更好的最终策略。另一方面，大量数据会减慢搜索速度并引发时间问题。这导致大多数AutoDA模型在性能和效率之间存在权衡。然而，与先前的方法如AA
    [cubuk2019autoaugment](#bib.bib20) 和 Fast AA [lim2019fast](#bib.bib21) 不同，DADA能够在资源受限的环境中很好地平衡模型准确性和搜索成本。由于其效率，DADA被认为是一种可行的AutoDA方法，适用于实际应用。
- en: 6.1.4 Automated Dataset Optimization (AutoDO)
  id: totrans-315
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 6.1.4 自动数据集优化（AutoDO）
- en: 'The majority of recent works in the AutoDA field focus on the reduction of
    the search cost, while Automated Dataset Optimization (AutoDO) [gudovskiy2021autodo](#bib.bib62)
    evolves in the direction of mitigating the negative impacts of noisy or imbalanced
    data. To achieve a robust policy search, AutoDO adapts the idea of density matching
    [lim2019fast](#bib.bib21) in a bi-level optimization framework. Specifically,
    the AutoDO model optimizes a set of augmentation hyper-parameters for each data
    point instead of a batch of data, allowing for more flexibility in tuning distributions
    of transformed data. In addition, AutoDO further refines the policy estimate by
    generalizing the training loss and softening the original labels. Through implicit
    differentiation, AutoDO jointly optimizes the results from three sub-models: the
    policy sub-model, the loss weighting sub-model and the soft label sub-model. Moreover,
    by using Fisher information [domingos2020every](#bib.bib93) ; [gudovskiy2020deep](#bib.bib94)
    , AutoDO provides theoretical proof that the complexity of AutoDA problem scales
    linearly with the size of the dataset.'
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
  zh: 最近在AutoDA领域的大多数研究专注于降低搜索成本，而**自动数据集优化（AutoDO）** [gudovskiy2021autodo](#bib.bib62)
    则朝着减轻噪声或不平衡数据负面影响的方向发展。为了实现稳健的策略搜索，AutoDO在双层优化框架中采用了密度匹配的思想 [lim2019fast](#bib.bib21)。具体来说，AutoDO模型优化每个数据点的一组增强超参数，而不是一批数据，这使得调整变换数据分布时更加灵活。此外，AutoDO通过概括训练损失和软化原始标签来进一步细化策略估计。通过隐式微分，AutoDO联合优化来自三个子模型的结果：策略子模型、损失加权子模型和软标签子模型。此外，利用Fisher信息
    [domingos2020every](#bib.bib93) ; [gudovskiy2020deep](#bib.bib94)，AutoDO提供了理论证明，AutoDA问题的复杂度随着数据集大小线性增长。
- en: The proposal of AutoDO is mainly motivated by data problems present in training
    sets, including biased distributions and noisy labels. This issue becomes more
    predominant when existing approaches apply the same DA strategy on all data points
    for augmentation. For instance, data distributions of different classes are usually
    uneven in practice. However, by sharing the same augmentation policy among the
    entire training set, data samples in all categories are evenly augmented to increase
    diversity. Since the intensity of augmentation remains the same, classes with
    more data points might be over-augmented after transformation, while minority
    classes may be under-augmented. After data augmentation, an imbalanced or biased
    training set transformed by shared policy may potentially mislead the classification
    model. A shared DA policy is therefore not robust enough for data with distortions.
    For multi-class classification tasks, the overfitting issue may deteriorate significantly
    [terhorst2021comprehensive](#bib.bib95) , especially when there exists noise in
    the original data labels [zhang2021understanding](#bib.bib96) . This phenomenon
    is defined as the dilemma of shared-policy in [gudovskiy2021autodo](#bib.bib62)
    . To overcome this limitation, AutoDO estimates DA hyper-parameters for each training
    data point, rather than the entire dataset. Additionally, the AutoDO algorithm
    considers loss weights to constrain distribution biases and soft labels to address
    label noises.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: AutoDO的提案主要是受到训练集中存在的数据问题的激励，包括偏倚的分布和噪声标签。当现有方法对所有数据点应用相同的DA策略进行增强时，这个问题变得更为突出。例如，实践中不同类别的数据分布通常是不均匀的。然而，通过在整个训练集中共享相同的增强策略，各类别的数据样本被均匀增强以增加多样性。由于增强的强度保持不变，数据点较多的类别在变换后可能会过度增强，而少数类别可能会增强不足。在数据增强之后，由共享策略转换的不平衡或偏倚训练集可能会误导分类模型。因此，共享的DA策略对于存在失真的数据来说不够稳健。对于多类分类任务，过拟合问题可能会显著恶化
    [terhorst2021comprehensive](#bib.bib95)，尤其是当原始数据标签存在噪声时 [zhang2021understanding](#bib.bib96)。这一现象在
    [gudovskiy2021autodo](#bib.bib62) 中被定义为共享策略的困境。为了克服这一限制，AutoDO为每个训练数据点估计DA超参数，而不是整个数据集。此外，AutoDO算法考虑了损失权重来约束分布偏差，并使用软标签来解决标签噪声。
- en: 'A complete AutoDO model is composed of three sub-models: augmentation, loss
    re-weighting and soft-labelling sub-models. The overall workflow of AutoDO can
    be described as follows. Firstly, data are sampled as input to the augmentation
    sub-model, where the original data points are transformed by a set of point-wise
    augmentation operations. Each data sample is separately augmented by a sequence
    of specific transformation functions. The augmentation hyper-parameters for each
    image are defined and updated in the augmentation sub-model as well. To be more
    specific, application probabilities are binary values, while the magnitudes are
    sampled from a continuous Gaussian distribution. After data augmentation, the
    distorted data output from the augmentation block is used to train the classification
    network. During the training, the loss re-weighting sub-model and soft label sub-model
    are propagated at the same time. Specifically, the loss sub-model is used to normalize
    the training loss at certain training epoch, restraining the negative impacts
    of biased distributions. As for the soft label sub-model, it softens the original
    label of transformed data based on noise-free validation data. A soft labelling
    technique is applied in AutoDO to preclude potential noises oof data notation
    resulting from aggressive augmentation [tanaka2018joint](#bib.bib97) ; [yi2019probabilistic](#bib.bib98)
    . Lastly, the reward signal produced by loss re-weighting block, along with the
    soft labels from soft-labelling model are then back-propagated to update the augmentation
    hyper-parameters accordingly.'
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
  zh: 完整的 AutoDO 模型由三个子模型组成：数据增强、损失重加权和软标签子模型。AutoDO 的整体工作流程如下。首先，数据被采样作为输入到数据增强子模型，其中原始数据点通过一系列逐点的数据增强操作进行转换。每个数据样本都通过一系列特定的变换函数进行单独增强。每张图像的数据增强超参数也在数据增强子模型中定义和更新。具体来说，应用概率是二进制值，而幅度则从连续的高斯分布中采样。数据增强之后，从增强块输出的扭曲数据用于训练分类网络。在训练过程中，损失重加权子模型和软标签子模型同时传播。具体来说，损失子模型用于在某一训练周期内规范化训练损失，抑制偏差分布的负面影响。至于软标签子模型，它基于无噪声的验证数据来软化变换数据的原始标签。AutoDO
    中应用了软标签技术，以防止由于激进增强而导致的数据标注潜在噪声 [tanaka2018joint](#bib.bib97)；[yi2019probabilistic](#bib.bib98)。最后，损失重加权块产生的奖励信号以及来自软标签模型的软标签会被反向传播，以相应地更新数据增强超参数。
- en: In AutoDO, the optimization of the classification network and augmentation policy
    are conducted simultaneously. Inspired by prior works [hataya2020faster](#bib.bib22)
    ; [li2020dada](#bib.bib57) ; [lin2019online](#bib.bib54) , AutoDO employs a bi-level
    setting, where the inner objective is to find the optimal network weights for
    target tasks, while the outer objective is to search for the optimal DA policy
    by hyper-parameter optimization. Such joint optimization is realized by gradient
    differentiation [lorraine2020optimizing](#bib.bib99) . However, directly solving
    the bi-level problem is usually computationally infeasible, especially when AutoDO
    aims to optimize augmentation hyper-parameters per data point. To accommodate
    the search for large-scale hyper-parameters, AutoDO combines density matching
    techniques [lim2019fast](#bib.bib21) to develop an implicit differentiation method.
    To be more specific, the major objective of searching in AutoDO is to minimize
    the distribution difference between the augmented data and an unbiased and clean
    validation set. According to analysis in [gudovskiy2021autodo](#bib.bib62) and
    using the Fisher information, the modified differentiation framework can yield
    equivalent results to the DARTS gradient approximator [liu2018darts](#bib.bib56)
    from previous methods [hataya2020faster](#bib.bib22) ; [li2020dada](#bib.bib57)
    . Furthermore, the use of Fisher information suggests a linear relationship between
    the complexity of AutoDA search and the size of task data.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 在 AutoDO 中，分类网络和增强策略的优化是同时进行的。受到先前工作的启发 [hataya2020faster](#bib.bib22) ; [li2020dada](#bib.bib57)
    ; [lin2019online](#bib.bib54) ，AutoDO 采用了双层设置，其中内部目标是为目标任务寻找最佳网络权重，而外部目标是通过超参数优化来搜索最佳的
    DA 策略。这种联合优化通过梯度微分 [lorraine2020optimizing](#bib.bib99) 实现。然而，直接解决双层问题通常在计算上是不可行的，尤其是当
    AutoDO 旨在为每个数据点优化增强超参数时。为了适应大规模超参数的搜索，AutoDO 结合了密度匹配技术 [lim2019fast](#bib.bib21)
    来开发一种隐式微分方法。更具体来说，AutoDO 搜索的主要目标是最小化增强数据与无偏且干净的验证集之间的分布差异。根据 [gudovskiy2021autodo](#bib.bib62)
    中的分析，并使用 Fisher 信息，修改后的微分框架可以产生与先前方法 [hataya2020faster](#bib.bib22) ; [li2020dada](#bib.bib57)
    的 DARTS 梯度近似器 [liu2018darts](#bib.bib56) 相同的结果。此外，使用 Fisher 信息表明 AutoDA 搜索的复杂性与任务数据的大小之间存在线性关系。
- en: 'The effectiveness of AutoDO can be evaluated from two perspectives: class imbalance
    and label noise. Before being fed into AutoDO model, training data is distorted
    by adjusting the class distribution and associated labels. To display the strength
    of DA policy, t-SNE clustering method [van2008visualizing](#bib.bib100) is employed
    to visualise the embedded features of test data in the classification model. The
    distance between data clusters represents the difference between data categories
    from the perspective of the model. Usually, larger margins or clear boundaries
    between clusters are preferable. When compared with gradient-based Fast AA [lim2019fast](#bib.bib21)
    , the AutoDO model produces larger margins between data clusters in t-SNE plots.
    This result suggests that point-wise augmentation in AutoDO might achieve better
    performance.'
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: AutoDO 的有效性可以从两个方面进行评估：类别不平衡和标签噪声。在输入 AutoDO 模型之前，训练数据通过调整类别分布和相关标签进行扭曲。为了展示
    DA 策略的强度，采用 t-SNE 聚类方法 [van2008visualizing](#bib.bib100) 来可视化分类模型中测试数据的嵌入特征。数据集群之间的距离表示模型视角下数据类别之间的差异。通常，集群之间的较大间距或清晰边界更为理想。与基于梯度的
    Fast AA [lim2019fast](#bib.bib21) 相比，AutoDO 模型在 t-SNE 图中产生了数据集群之间更大的间距。这一结果表明，AutoDO
    中的点对点增强可能实现了更好的性能。
- en: The extensive experiments in [gudovskiy2021autodo](#bib.bib62) further confirms
    that AutoDO is more robust to distorted data. When compared with prior AutoDA
    approaches, AutoDO avoids overfitting to the majority data by optimizing point-wise
    hyper-parameters instead of a single shared policy. As a result, the augmentation
    policy learned by AutoDO can better separate images in different classes, mitigating
    the impacts of biased class distributions. The issue of noisy label is solved
    by using re-weighted loss and soft labels. From the experimental results, when
    trained by noisy data, AutoDO achieves superior results compared to other AutoDA
    models. Additionally, the smooth labels provided by the soft-labelling sub-model
    further enlarge the margins between data clusters in t-SNE plots, enhancing the
    generation ability of the model. More importantly, such improvements can be found
    in both well- and under-represented classes, aligning the accuracy of minority
    categories. The greatest advantage of AutoDO is its resilience to low-quality
    data. Overall, AutoDO is considered more applicable for real-world tasks with
    imperfect data.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 在[gudovskiy2021autodo](#bib.bib62)中的广泛实验进一步确认了AutoDO对失真数据的鲁棒性。与先前的AutoDA方法相比，AutoDO通过优化逐点超参数而不是单一共享策略，避免了对主要数据的过拟合。因此，AutoDO学习到的数据增强策略能够更好地区分不同类别的图像，减轻了偏斜类别分布的影响。噪声标签的问题通过使用重新加权的损失和软标签得到解决。从实验结果来看，当训练数据有噪声时，AutoDO相比其他AutoDA模型取得了优越的结果。此外，软标签子模型提供的平滑标签进一步扩大了t-SNE图中的数据簇之间的间隔，提高了模型的生成能力。更重要的是，这种改进在表现良好和表现不足的类别中都能体现，从而提高了少数类别的准确性。AutoDO的最大优势在于其对低质量数据的韧性。总体而言，AutoDO被认为更适合处理不完美数据的实际任务。
- en: 7 Discussion
  id: totrans-322
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 讨论
- en: Following the categorization in Fig. LABEL:Fig:_taxonomy, a wide range of AutoDA
    methods have been covered in this survey. However, automation of data augmentation
    is still a relatively new concept and has not been fully addressed. The development
    of AutoDA techniques are still in their infancy. Although AutoDA models have the
    potential to become an essential component of the standard deep learning pipelines,
    there are still a number of difficulties to overcome in the future. In this section,
    we provide a discussion focusing on the current challenges in existing AutoDA
    methods, as well as some directions we believe important for future work.
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 根据图 LABEL:Fig:_taxonomy 中的分类，本次调查涵盖了广泛的AutoDA方法。然而，数据增强的自动化仍然是一个相对较新的概念，尚未得到充分解决。AutoDA技术的发展仍处于初期阶段。尽管AutoDA模型有潜力成为标准深度学习管道的核心组成部分，但未来仍面临许多困难。在这一部分，我们将讨论现有AutoDA方法中的当前挑战，以及我们认为未来工作中重要的一些方向。
- en: 7.1 Search Space Formulation
  id: totrans-324
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.1 搜索空间的定义
- en: The policy search space defined by AA [cubuk2019autoaugment](#bib.bib20) has
    been widely accepted as the standard setting. Most of the later AutoDA works reuse
    the same formulation as the basis of their search model. However, without any
    modification, the parameterization in AA can result in an enormous search space.
    Even with a limited range of available TFs, the search process of AA still requires
    extensive computational resources, so it is not feasible in practice and has serious
    issues when scaling to larger datasets or models.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 由AA[cubuk2019autoaugment](#bib.bib20)定义的策略搜索空间已被广泛接受为标准设置。大多数后来的AutoDA工作都重复使用了相同的公式作为其搜索模型的基础。然而，没有任何修改的情况下，AA中的参数化会导致巨大的搜索空间。即使在可用TF的范围有限的情况下，AA的搜索过程仍然需要大量的计算资源，因此在实践中不可行，并且在扩展到更大数据集或模型时存在严重问题。
- en: As AutoDA techniques evolve, traditional settings of the search space in AA-based
    models is challenged by search-free approaches. These methods aim to avoid the
    search phase by re-parameterization. For example, in RandAugment (RA) [cubuk2020randaugment](#bib.bib31)
    , instead of optimizing the application probability, all TFs share the same global
    probability value. Moreover, based on empirical evidence, the magnitude is set
    to be a global variable for all transformations. The final search space in RA
    is controlled by only two hyper-parameters, the size of classification models
    and training sets. None of these requires significant computation to be optimized.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 随着AutoDA技术的发展，传统AA模型中的搜索空间设置正受到无搜索方法的挑战。这些方法通过重新参数化来避免搜索阶段。例如，在RandAugment (RA)
    [cubuk2020randaugment](#bib.bib31) 中，所有TF共享相同的全局概率值，而不是优化应用概率。此外，根据经验数据，幅度被设为所有变换的全局变量。RA中的最终搜索空间仅由两个超参数控制，即分类模型和训练集的大小。这些都不需要大量计算来优化。
- en: UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58) also re-formulates
    the search space. Instead of optimizing hyper-parameters, UA proposes the invariance
    hypothesis. Sampling any policies from an invariant policy space can retain the
    original label information for the majority of the augmented data. The authors
    of UA argue that if an augmentation space is approximately invariant, then optimizing
    the augmentation policy within that space is unnecessary. Therefore, a simple
    uniform sampling of the invariant space is sufficient to effectively enhance the
    model performance, which completely eliminates the need for searching.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: UniformAugment (UA) [lingchen2020uniformaugment](#bib.bib58) 也重新定义了搜索空间。UA提出了不变性假设，而不是优化超参数。
    从不变政策空间中抽取任何策略可以保留大多数增强数据的原始标签信息。 UA的作者认为，如果增强空间大致上是不变的，那么在该空间内优化增强政策是没有必要的。因此，对不变空间的简单均匀抽样就足以有效提升模型性能，完全消除了搜索的必要性。
- en: The emerge of RA and UA has been revolutionary. The removal of the search stage
    raises questions on the necessity and optimality of searching in traditional AutoDA
    methods. Particularly, the hypothesis of invariant augmentation space has the
    potential to completely solve the current efficiency bottleneck of search-based
    methods. Hence, we believe a viable topic for future research is to discover a
    methodology for finding invariant augmentation spaces in certain domains. Furthermore,
    it is worth trying to explore other ways of defining augmentation policy searches
    for even more simplified search spaces.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: RA和UA的出现具有革命性。去除搜索阶段引发了对传统AutoDA方法中搜索的必要性和最优性的质疑。特别是，不变增强空间的假设有可能完全解决基于搜索的方法当前的效率瓶颈。因此，我们认为未来研究的一个可行课题是发现某些领域中不变增强空间的发现方法。此外，值得尝试探索定义增强策略搜索的其他方法，以实现更简化的搜索空间。
- en: 7.2 Optimal Augmentation Transformations
  id: totrans-329
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.2 最优增强变换
- en: Though extensive efforts have been put into the search of the hyper-parameters
    that describe image transformation functions, less attention has been paid to
    the selection of TFs to be applied. Conventionally, the available image operations
    in AutoDA models are from the PIL Python library. Nearly all image transformation
    functions in PIL are considered in later search phases. In AA, two additional
    augmentation techniques, Cutout [devries2017improved](#bib.bib45) and SamplePairing
    [inoue2018data](#bib.bib46) are also used.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在描述图像变换函数的超参数搜索上投入了大量精力，但对应用的TF选择关注较少。传统上，AutoDA模型中的可用图像操作来自PIL Python库。PIL中的几乎所有图像变换函数都在后续搜索阶段被考虑。在AA中，还使用了两种额外的增强技术：Cutout
    [devries2017improved](#bib.bib45) 和 SamplePairing [inoue2018data](#bib.bib46)。
- en: In the majority of later works, similar selections are made for fair comparison
    purposes. A few of them remove some image operations from the search list [tian2020improving](#bib.bib30)
    ; [ho2019population](#bib.bib23) while others add several new augmentation technique
    into their model [naghizadeh2020greedy](#bib.bib60) ; [naghizadeh2021greedy](#bib.bib63)
    . The decision of image operations is made empirically, with little theoretical
    selection strategy. Though there is discussion around the different impact of
    each TF in terms of different datasets or sub-regions, no one has systematically
    investigate the optimal augmentation transformation functions for AutoDA to search.
    We argue that the optimization of available image operations in AutoDA with various
    data may be another interesting direction for researchers to explore. When searching
    for augmentation policies, future users might have the option to switch on or
    off a certain type of transformation in different application scenarios, so that
    the obtained augmentation policy can be more tailored to the given task.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 在大多数后续研究中，为了公平比较，通常会做出类似的选择。其中一些从搜索列表中移除了某些图像操作 [tian2020improving](#bib.bib30)
    ; [ho2019population](#bib.bib23)，而其他的则将几种新的增强技术添加到他们的模型中 [naghizadeh2020greedy](#bib.bib60)
    ; [naghizadeh2021greedy](#bib.bib63)。图像操作的选择主要是基于经验的，理论上的选择策略很少。尽管有关于不同数据集或子区域中每种TF的不同影响的讨论，但尚未有人系统地研究AutoDA中最优的增强转换函数。我们认为，优化AutoDA中可用的图像操作以适应各种数据可能是研究人员可以探索的另一个有趣方向。在搜索增强策略时，未来的用户可能可以在不同的应用场景中选择开启或关闭某种类型的转换，以便使获得的增强策略能够更好地适应特定任务。
- en: 7.3 Unsupervised Evaluation
  id: totrans-332
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.3 无监督评估
- en: The existing AutoDA methods extensively use supervised evaluation to determine
    which augmentation policies to use for training. Normally, the most generalized
    model is trained by applying the best augmentation policy. The optimal DA policy
    is supposed to provide the most enhancement in data variety and quantity while
    still retaining salient image features. However, in practice, it can be difficult
    or impossible to obtain accurately labeled data, especially for sensitive tasks
    [shin2011autoencoder](#bib.bib101) . This is a great challenge for existing AutoDA
    methods, and gives rise to the emergence of self-supervised AutoDA. This possibility
    is also discussed in [wei2020circumventing](#bib.bib59) . So far, only a few of
    AutoDA models support semi-supervised learning, such as SelfAugment [reed2021selfaugment](#bib.bib102)
    . However, with the rapid development in AutoDA field, this may be different in
    the future.
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 现有的AutoDA方法广泛使用监督评估来确定用于训练的增强策略。通常，通过应用最佳增强策略来训练最通用的模型。最优的DA策略应该在提供数据多样性和数量的同时，仍然保留显著的图像特征。然而，在实际操作中，获得准确标注的数据可能是困难的，尤其是对于敏感任务
    [shin2011autoencoder](#bib.bib101)。这是现有AutoDA方法面临的重大挑战，并催生了自监督AutoDA的出现。这一可能性也在
    [wei2020circumventing](#bib.bib59) 中进行了讨论。目前，只有少数AutoDA模型支持半监督学习，例如 SelfAugment
    [reed2021selfaugment](#bib.bib102)。然而，随着AutoDA领域的快速发展，未来可能会有所不同。
- en: 7.4 Biased or Noisy Data
  id: totrans-334
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.4 偏差或噪声数据
- en: When evaluating the effectiveness of AutoDA models, most existing works presume
    that the training data is clean and balanced. This happens with no doubt when
    using benchmark datasets such as CIFAR-10/100 [krizhevsky2009learning](#bib.bib27)
    and ImageNet [deng2009imagenet](#bib.bib28) . But in real-world scenarios, things
    could be totally different. It is an all too common case when training dataset
    is not only insufficient but extremely biased with label noise. Experimental results
    in [gudovskiy2021autodo](#bib.bib62) show that the distorted training data with
    imbalanced distribution and noisy label can bring negative impacts to AutoDA models
    and eventually lead to overfitting problems. Additionally, findings in [wei2020circumventing](#bib.bib59)
    also indicate that aggressive augmentation transformations might introduce label
    noise even though the original annotation is correct.
  id: totrans-335
  prefs: []
  type: TYPE_NORMAL
  zh: 在评估AutoDA模型的有效性时，大多数现有工作假设训练数据是干净且平衡的。在使用像 CIFAR-10/100 [krizhevsky2009learning](#bib.bib27)
    和 ImageNet [deng2009imagenet](#bib.bib28) 这样的基准数据集时，这种情况毫无疑问是成立的。但在现实世界的场景中，情况可能完全不同。训练数据不仅不足，而且常常存在标签噪声，这是一种极其常见的情况。实验结果
    [gudovskiy2021autodo](#bib.bib62) 显示，具有不平衡分布和噪声标签的失真训练数据可能对AutoDA模型产生负面影响，并最终导致过拟合问题。此外，
    [wei2020circumventing](#bib.bib59) 的研究结果也表明，激进的增强转换可能会引入标签噪声，即使原始标注是正确的。
- en: Dealing with biased or noisy data is a great challenge for AutoDA model. AA-KD
    [wei2020circumventing](#bib.bib59) is the first AutoDA work targeting this issue.
    By leveraging the idea of KD, a stand-alone model is applied in AA-KD to provide
    extra guidance for model training. During the training, the model receives supervision
    from both ground-truth label and teacher signal, in case the discriminative information
    is accidentally removed by aggressive augmentation. AutoDO [gudovskiy2021autodo](#bib.bib62)
    uses a similar idea to KD by softening the original label to better train the
    model. Additionally, AutoDO contains another re-weighting sub-model which is used
    to normalize the training loss. The combination of all three sub-models makes
    AutoDO much more robust than other AutoDA algorithms when given biased or noisy
    data.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 处理有偏或嘈杂的数据是AutoDA模型面临的重大挑战。AA-KD [wei2020circumventing](#bib.bib59) 是第一个针对这个问题的AutoDA工作。通过利用KD的思想，AA-KD应用了一个独立模型来为模型训练提供额外的指导。在训练过程中，该模型接受来自真实标签和教师信号的监督，以防在激进的数据增强过程中丢失判别信息。AutoDO
    [gudovskiy2021autodo](#bib.bib62) 使用了类似KD的思想，通过软化原始标签来更好地训练模型。此外，AutoDO还包含另一个重新加权的子模型，用于归一化训练损失。这三个子模型的组合使AutoDO在处理有偏或嘈杂的数据时比其他AutoDA算法更具鲁棒性。
- en: Overall, both methods outperform other AutoDA methods especially when dealing
    with imbalanced data with label noise. This further proves that AutoDA model can
    benefit from the extra handling of label noises. In the future, we expect that
    more research could tackle this topic. Such developments would greatly improve
    the applicability of AutoDA methods in real-world tasks.
  id: totrans-337
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，这两种方法在处理带标签噪声的失衡数据时优于其他AutoDA方法。这进一步证明了AutoDA模型可以通过额外处理标签噪声获得好处。未来，我们希望更多的研究能够解决这一话题。这些发展将大大提高AutoDA方法在实际任务中的适用性。
- en: 7.5 Application Domains
  id: totrans-338
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 7.5 应用领域
- en: Though the major focus of this paper is on the image classification tasks, we
    identify several other domains which might greatly benefit from the AutoDA technique.
    One is Object Detection (OD) tasks, which has already been partly explored in
    recently published works, including AutoAugment for OD [zoph2020learning](#bib.bib26)
    , DADA [li2020dada](#bib.bib57) , RandAugment [cubuk2020randaugment](#bib.bib31)
    , SelfAugment [reed2021selfaugment](#bib.bib102) and Scale-aware AutoAugment (SA)
    [chen2021scale](#bib.bib103) . Data augmentation may be even more important for
    OD tasks, especially when annotation is much more time-consuming. The experimental
    results in [zoph2020learning](#bib.bib26) demonstrate that even a direct transfer
    of DA policies obtained from classification data can be useful for OD tasks. However,
    according to their findings, such improvement cmay be limited. Moreover, the extremely
    long searching time is also a serious problem in terms of applicability.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管本文的主要重点是图像分类任务，但我们识别出几个可能从AutoDA技术中受益的其他领域。其中之一是目标检测（OD）任务，最近的工作已经部分探讨了这一领域，包括针对OD的AutoAugment
    [zoph2020learning](#bib.bib26) 、DADA [li2020dada](#bib.bib57) 、RandAugment [cubuk2020randaugment](#bib.bib31)
    、SelfAugment [reed2021selfaugment](#bib.bib102) 和尺度感知AutoAugment (SA) [chen2021scale](#bib.bib103)
    。数据增强对于OD任务可能更加重要，尤其是当注释工作更为耗时时。[zoph2020learning](#bib.bib26) 中的实验结果表明，即使直接转移从分类数据获得的DA策略也对OD任务有用。然而，根据他们的发现，这种改进可能是有限的。此外，极长的搜索时间也是适用性方面的一个严重问题。
- en: To further improve the overall model performance, additional adjustment to the
    original AutoDA scheme must be done. Later works such as RA [cubuk2020randaugment](#bib.bib31)
    concentrate more on the improvement in efficiency, which provides competitive
    accuracy with AA and superior search speed. Self-supervised evaluation is also
    found useful for detection training [reed2021selfaugment](#bib.bib102) . DADA
    shows another possibility of tweaking the pre-trained backbone network used for
    detection, instead of directly operating on the detection model. The experimental
    results in [li2020dada](#bib.bib57) indicate that pre-training the backbone network
    using DADA can improve the model performance for later detection tasks. Scale-aware
    Augmentation [chen2021scale](#bib.bib103) is specifically designed for detection
    tasks by incorporating bounding-box level augmentations. Such design is more fine-grained
    and thus leads to considerable improvements to various OD networks.
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进一步提高整体模型性能，必须对原始AutoDA方案进行额外的调整。后续工作如RA [cubuk2020randaugment](#bib.bib31)
    更加关注效率的提升，提供了与AA相当的准确性和更优的搜索速度。自监督评估在检测训练中也被发现非常有用 [reed2021selfaugment](#bib.bib102)
    。DADA展示了另一种可能性，即调整用于检测的预训练骨干网络，而不是直接操作检测模型。[li2020dada](#bib.bib57) 的实验结果表明，使用DADA对骨干网络进行预训练可以提高模型在后续检测任务中的性能。Scale-aware
    Augmentation [chen2021scale](#bib.bib103) 专门为检测任务设计，通过结合边界框级别的增强实现了更精细的设计，从而显著提高了各种OD网络的性能。
- en: While the aforementioned research mainly focuses on computer vision tasks, Natural
    Language Processing (NLP) is another field that can greatly benefit from the application
    of AutoDA techniques. Traditional data augmentation has been used extensively
    in NLP research. Automating the augmentation procedure in text-based tasks can
    be another promising research direction. Several studies already take a step on
    the application of AutoDA to linguistic problems, including the earliest TANDA
    [ratner2017learning](#bib.bib52) , Text AutoAugment [ren2021text](#bib.bib104)
    and works such as [niu2019automatically](#bib.bib61) ; [hu2019learning](#bib.bib66)
    . The adaptation of AutoDA methods in NLP yields competitive performance gains
    by improving the quantity and quality of training data.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述研究主要集中在计算机视觉任务上，自然语言处理（Natural Language Processing, NLP）也是一个可以从AutoDA技术应用中大大受益的领域。传统的数据增强已经在NLP研究中得到了广泛应用。在基于文本的任务中自动化增强过程可以成为另一个有前景的研究方向。一些研究已经在将AutoDA应用于语言学问题方面迈出了第一步，包括最早的TANDA
    [ratner2017learning](#bib.bib52) 、Text AutoAugment [ren2021text](#bib.bib104)
    和如 [niu2019automatically](#bib.bib61) ; [hu2019learning](#bib.bib66) 的工作。在NLP中采用AutoDA方法可以通过改善训练数据的数量和质量，带来竞争性的性能提升。
- en: 8 Conclusion
  id: totrans-342
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 8 结论
- en: With the increasing development of deep learning, training performant deep model
    efficiently largely depends on the quantity and quality of available training
    data. Data Augmentation (DA) is an essential tool for solving data problems, and
    been widely used in various computer vision tasks. However, designing an effective
    DA policy still highly relies on human efforts. It is difficult to select the
    optimal augmentation policy when given a specific dataset without domain knowledge.
    Therefore, researchers seek to solve this problem by automating the search of
    augmentation policies via deep learning, which stimulates the development of Automated
    Data Augmentation (AutoDA) techniques.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 随着深度学习的不断发展，高效地训练表现优秀的深度模型在很大程度上依赖于可用训练数据的数量和质量。数据增强（Data Augmentation, DA）是解决数据问题的一个重要工具，已广泛应用于各种计算机视觉任务。然而，设计一个有效的DA策略仍然高度依赖于人工努力。在没有领域知识的情况下，选择最优的增强策略是困难的。因此，研究人员通过深度学习自动化搜索增强策略，以解决这一问题，这推动了自动数据增强（Automated
    Data Augmentation, AutoDA）技术的发展。
- en: This survey provides a comprehensive overview of AutoDA techniques for image
    classification tasks in the computer vision field. The focus of this paper is
    on various search algorithms in AutoDA. In order to describe and categorize approaches
    for augmentation policy optimization, we introduce searching and training phases
    for a standard AutoDA pipeline. Based on different optimization approaches, all
    AutoDA methods can be divided into two-stage or one-stage approaches. The searching
    process in AutoDA can be further classified into gradient-free, gradient-based
    or search-free methods. The associated qualitative evaluation describes AutoDA
    methods in terms of the complexity of the search space, the computational cost,
    the available augmentation transformations, as well as the reported performance
    improvements on classification models. In the future, we expect more research
    in the AutoDA field aimed at balancing between accuracy and efficiency of the
    proposed models, and providing better solutions to trade-off between safety and
    variety of the obtained augmentation policies.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查提供了AutoDA技术在计算机视觉领域图像分类任务中的全面概述。本文的重点是AutoDA中的各种搜索算法。为了描述和分类增强策略优化的方法，我们介绍了标准AutoDA管道的搜索和训练阶段。基于不同的优化方法，所有AutoDA方法可以分为两阶段或单阶段方法。AutoDA中的搜索过程可以进一步分类为无梯度、基于梯度或无搜索方法。相关的定性评估描述了AutoDA方法在搜索空间的复杂性、计算成本、可用的增强变换以及分类模型上报告的性能改进等方面的表现。未来，我们期望AutoDA领域能有更多的研究，旨在平衡提出模型的准确性和效率，并提供更好的解决方案，以权衡安全性和增强策略的多样性。
- en: References
  id: totrans-345
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: \bibcommenthead
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: \bibcommenthead
- en: '(1) Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with
    deep convolutional neural networks. Advances in neural information processing
    systems 25, 1097–1105 (2012)'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(1) Krizhevsky, A., Sutskever, I., Hinton, G.E.: 使用深度卷积神经网络进行Imagenet分类。神经信息处理系统进展
    25, 1097–1105 (2012)'
- en: '(2) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,
    D., Vanhoucke, V., Rabinovich, A.: Going deeper with convolutions. In: Proceedings
    of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1–9 (2015)'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(2) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov, D., Erhan,
    D., Vanhoucke, V., Rabinovich, A.: 通过卷积深入研究。发表于：IEEE计算机视觉与模式识别会议论文集, pp. 1–9 (2015)'
- en: '(3) Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
    image recognition. arXiv preprint arXiv:1409.1556 (2014)'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(3) Simonyan, K., Zisserman, A.: 用于大规模图像识别的非常深的卷积网络。arXiv预印本 arXiv:1409.1556
    (2014)'
- en: '(4) He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition.
    In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition,
    pp. 770–778 (2016)'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(4) He, K., Zhang, X., Ren, S., Sun, J.: 图像识别的深度残差学习。发表于：IEEE计算机视觉与模式识别会议论文集,
    pp. 770–778 (2016)'
- en: '(5) Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M.,
    Thrun, S.: Dermatologist-level classification of skin cancer with deep neural
    networks. nature 542(7639), 115–118 (2017)'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(5) Esteva, A., Kuprel, B., Novoa, R.A., Ko, J., Swetter, S.M., Blau, H.M.,
    Thrun, S.: 通过深度神经网络进行皮肤癌的皮肤科医生级分类。自然 542(7639), 115–118 (2017)'
- en: '(6) Shin, H.-C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J.,
    Mollura, D., Summers, R.M.: Deep convolutional neural networks for computer-aided
    detection: Cnn architectures, dataset characteristics and transfer learning. IEEE
    transactions on medical imaging 35(5), 1285–1298 (2016)'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(6) Shin, H.-C., Roth, H.R., Gao, M., Lu, L., Xu, Z., Nogues, I., Yao, J.,
    Mollura, D., Summers, R.M.: 计算机辅助检测的深度卷积神经网络：CNN架构、数据集特征和迁移学习。IEEE医学影像学事务 35(5),
    1285–1298 (2016)'
- en: '(7) Zheng, Y.-Y., Kong, J.-L., Jin, X.-B., Wang, X.-Y., Su, T.-L., Zuo, M.:
    Cropdeep: The crop vision dataset for deep-learning-based classification and detection
    in precision agriculture. Sensors 19(5), 1058 (2019)'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(7) Zheng, Y.-Y., Kong, J.-L., Jin, X.-B., Wang, X.-Y., Su, T.-L., Zuo, M.:
    Cropdeep: 精准农业中基于深度学习的分类与检测的作物视觉数据集。传感器 19(5), 1058 (2019)'
- en: '(8) Kamilaris, A., Prenafeta-Boldú, F.X.: Deep learning in agriculture: A survey.
    Computers and electronics in agriculture 147, 70–90 (2018)'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(8) Kamilaris, A., Prenafeta-Boldú, F.X.: 农业中的深度学习：一项调查。农业计算机与电子学 147, 70–90
    (2018)'
- en: '(9) Shijie, J., Ping, W., Peiyi, J., Siping, H.: Research on data augmentation
    for image classification based on convolution neural networks. In: 2017 Chinese
    Automation Congress (CAC), pp. 4165–4170 (2017). IEEE'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(9) Shijie, J., Ping, W., Peiyi, J., Siping, H.: 基于卷积神经网络的图像分类数据增强研究。发表于：2017中国自动化大会（CAC），pp.
    4165–4170 (2017). IEEE'
- en: '(10) Lemley, J., Bazrafkan, S., Corcoran, P.: Smart augmentation learning an
    optimal data augmentation strategy. Ieee Access 5, 5858–5869 (2017)'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(10) Lemley, J., Bazrafkan, S., Corcoran, P.: 智能增强学习最优数据增强策略。IEEE Access 5,
    5858–5869 (2017)'
- en: '(11) Cireşan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Deep, big,
    simple neural nets for handwritten digit recognition. Neural computation 22(12),
    3207–3220 (2010)'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(11) Cireşan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: 深度、大型、简单的神经网络用于手写数字识别。神经计算
    22(12), 3207–3220 (2010)'
- en: '(12) Dosovitskiy, A., Fischer, P., Springenberg, J.T., Riedmiller, M., Brox,
    T.: Discriminative unsupervised feature learning with exemplar convolutional neural
    networks. IEEE transactions on pattern analysis and machine intelligence 38(9),
    1734–1747 (2015)'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(12) Dosovitskiy, A., Fischer, P., Springenberg, J.T., Riedmiller, M., Brox,
    T.: 具有示例卷积神经网络的判别性无监督特征学习。IEEE 模式分析与机器智能学报 38(9), 1734–1747 (2015)'
- en: '(13) Graham, B.: Fractional max-pooling. arXiv preprint arXiv:1412.6071 (2014)'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(13) Graham, B.: 分数最大池化。arXiv 预印本 arXiv:1412.6071 (2014)'
- en: '(14) Sajjadi, M., Javanmardi, M., Tasdizen, T.: Regularization with stochastic
    transformations and perturbations for deep semi-supervised learning. Advances
    in neural information processing systems 29, 1163–1171 (2016)'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(14) Sajjadi, M., Javanmardi, M., Tasdizen, T.: 用随机变换和扰动进行深度半监督学习的正则化。神经信息处理系统进展
    29, 1163–1171 (2016)'
- en: '(15) Rios, A., Kavuluru, R.: Few-shot and zero-shot multi-label learning for
    structured label spaces. In: Proceedings of the Conference on Empirical Methods
    in Natural Language Processing. Conference on Empirical Methods in Natural Language
    Processing, vol. 2018, p. 3132 (2018). NIH Public Access'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(15) Rios, A., Kavuluru, R.: 结构化标签空间的少样本和零样本多标签学习。自然语言处理经验方法会议论文集，第 2018 卷，第
    3132 页 (2018)。NIH Public Access'
- en: '(16) Bachman, P., Hjelm, R.D., Buchwalter, W.: Learning representations by
    maximizing mutual information across views. Advances in neural information processing
    systems 32 (2019)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(16) Bachman, P., Hjelm, R.D., Buchwalter, W.: 通过最大化视图间的互信息学习表示。神经信息处理系统进展
    32 (2019)'
- en: '(17) Paschali, M., Simson, W., Roy, A.G., Naeem, M.F., Göbl, R., Wachinger,
    C., Navab, N.: Data augmentation with manifold exploring geometric transformations
    for increased performance and robustness. arXiv preprint arXiv:1901.04420 (2019)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(17) Paschali, M., Simson, W., Roy, A.G., Naeem, M.F., Göbl, R., Wachinger,
    C., Navab, N.: 通过流形探索几何变换进行数据扩增，以提高性能和鲁棒性。arXiv 预印本 arXiv:1901.04420 (2019)'
- en: '(18) Wang, Y., Yao, Q., Kwok, J.T., Ni, L.M.: Generalizing from a few examples:
    A survey on few-shot learning. ACM computing surveys (csur) 53(3), 1–34 (2020)'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(18) Wang, Y., Yao, Q., Kwok, J.T., Ni, L.M.: 从少量示例中泛化：少样本学习的综述。ACM 计算调查（csur）
    53(3), 1–34 (2020)'
- en: '(19) Dao, T., Gu, A., Ratner, A., Smith, V., De Sa, C., Ré, C.: A kernel theory
    of modern data augmentation. In: International Conference on Machine Learning,
    pp. 1528–1537 (2019). PMLR'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(19) Dao, T., Gu, A., Ratner, A., Smith, V., De Sa, C., Ré, C.: 现代数据扩增的核理论。机器学习国际会议论文集，第
    1528–1537 页 (2019)。PMLR'
- en: '(20) Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: Autoaugment:
    Learning augmentation strategies from data. In: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 113–123 (2019)'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(20) Cubuk, E.D., Zoph, B., Mane, D., Vasudevan, V., Le, Q.V.: 自动增强：从数据中学习增强策略。IEEE/CVF
    计算机视觉与模式识别会议论文集，第 113–123 页 (2019)'
- en: '(21) Lim, S., Kim, I., Kim, T., Kim, C., Kim, S.: Fast autoaugment. Advances
    in Neural Information Processing Systems 32, 6665–6675 (2019)'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(21) Lim, S., Kim, I., Kim, T., Kim, C., Kim, S.: 快速自动增强。神经信息处理系统进展 32, 6665–6675
    (2019)'
- en: '(22) Hataya, R., Zdenek, J., Yoshizoe, K., Nakayama, H.: Faster autoaugment:
    Learning augmentation strategies using backpropagation. In: European Conference
    on Computer Vision, pp. 1–16 (2020). Springer'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(22) Hataya, R., Zdenek, J., Yoshizoe, K., Nakayama, H.: 更快的自动增强：使用反向传播学习增强策略。欧洲计算机视觉会议论文集，第
    1–16 页 (2020)。Springer'
- en: '(23) Ho, D., Liang, E., Chen, X., Stoica, I., Abbeel, P.: Population based
    augmentation: Efficient learning of augmentation policy schedules. In: International
    Conference on Machine Learning, pp. 2731–2741 (2019). PMLR'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(23) Ho, D., Liang, E., Chen, X., Stoica, I., Abbeel, P.: 基于人群的增强：高效学习增强策略计划。机器学习国际会议论文集，第
    2731–2741 页 (2019)。PMLR'
- en: '(24) Tran, T., Pham, T., Carneiro, G., Palmer, L., Reid, I.: A bayesian data
    augmentation approach for learning deep models. arXiv preprint arXiv:1710.10564
    (2017)'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(24) Tran, T., Pham, T., Carneiro, G., Palmer, L., Reid, I.: 一种贝叶斯数据扩增方法用于学习深度模型。arXiv
    预印本 arXiv:1710.10564 (2017)'
- en: '(25) DeVries, T., Taylor, G.W.: Dataset augmentation in feature space. arXiv
    preprint arXiv:1702.05538 (2017)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(25) DeVries, T., Taylor, G.W.: 特征空间中的数据集扩增。arXiv 预印本 arXiv:1702.05538 (2017)'
- en: '(26) Zoph, B., Cubuk, E.D., Ghiasi, G., Lin, T.-Y., Shlens, J., Le, Q.V.: Learning
    data augmentation strategies for object detection. In: European Conference on
    Computer Vision, pp. 566–583 (2020). Springer'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(26) Zoph, B., Cubuk, E.D., Ghiasi, G., Lin, T.-Y., Shlens, J., Le, Q.V.: 学习对象检测的数据增强策略。见：欧洲计算机视觉会议，第566–583页（2020）。Springer'
- en: '(27) Krizhevsky, A., Hinton, G., et al.: Learning multiple layers of features
    from tiny images (2009)'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(27) Krizhevsky, A., Hinton, G., 等: 从小图像中学习多个特征层次（2009）'
- en: '(28) Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L.: Imagenet:
    A large-scale hierarchical image database. In: 2009 IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 248–255 (2009). Ieee'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(28) Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., Fei-Fei, L.: ImageNet：一个大规模层次图像数据库。见：2009
    IEEE计算机视觉与模式识别会议，第248–255页（2009）。IEEE'
- en: '(29) Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: Reading
    digits in natural images with unsupervised feature learning (2011)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(29) Netzer, Y., Wang, T., Coates, A., Bissacco, A., Wu, B., Ng, A.Y.: 用无监督特征学习读取自然图像中的数字（2011）'
- en: '(30) Tian, K., Lin, C., Sun, M., Zhou, L., Yan, J., Ouyang, W.: Improving auto-augment
    via augmentation-wise weight sharing. arXiv preprint arXiv:2009.14737 (2020)'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(30) Tian, K., Lin, C., Sun, M., Zhou, L., Yan, J., Ouyang, W.: 通过增强-wise权重共享改进自动增强。arXiv预印本arXiv:2009.14737（2020）'
- en: '(31) Cubuk, E.D., Zoph, B., Shlens, J., Le, Q.V.: Randaugment: Practical automated
    data augmentation with a reduced search space. In: Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition Workshops, pp. 702–703 (2020)'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(31) Cubuk, E.D., Zoph, B., Shlens, J., Le, Q.V.: RandAugment：具有简化搜索空间的实用自动数据增强。见：IEEE/CVF计算机视觉与模式识别会议工作坊论文集，第702–703页（2020）'
- en: '(32) LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning
    applied to document recognition. Proceedings of the IEEE 86(11), 2278–2324 (1998)'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(32) LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: 应用于文档识别的基于梯度的学习。IEEE期刊86(11)，2278–2324（1998）'
- en: '(33) Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking
    the inception architecture for computer vision. In: Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pp. 2818–2826 (2016)'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(33) Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: 重新思考计算机视觉的Inception架构。见：IEEE计算机视觉与模式识别会议论文集，第2818–2826页（2016）'
- en: '(34) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., Bengio, Y.: Generative adversarial nets. Advances in
    neural information processing systems 27, 2672–2680 (2014)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(34) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley, D.,
    Ozair, S., Courville, A., Bengio, Y.: 生成对抗网络。神经信息处理系统进展27，第2672–2680页（2014）'
- en: '(35) Zoph, B., Le, Q.V.: Neural architecture search with reinforcement learning.
    arXiv preprint arXiv:1611.01578 (2016)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(35) Zoph, B., Le, Q.V.: 使用强化学习进行神经网络架构搜索。arXiv预印本arXiv:1611.01578（2016）'
- en: '(36) Perez, L., Wang, J.: The effectiveness of data augmentation in image classification
    using deep learning. arXiv preprint arXiv:1712.04621 (2017)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(36) Perez, L., Wang, J.: 使用深度学习进行图像分类的数据增强效果。arXiv预印本arXiv:1712.04621（2017）'
- en: '(37) Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: You only look once:
    Unified, real-time object detection. In: Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition, pp. 779–788 (2016)'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(37) Redmon, J., Divvala, S., Girshick, R., Farhadi, A.: 你只需看一次：统一的实时目标检测。见：IEEE计算机视觉与模式识别会议论文集，第779–788页（2016）'
- en: '(38) Girshick, R., Donahue, J., Darrell, T., Malik, J.: Rich feature hierarchies
    for accurate object detection and semantic segmentation. In: Proceedings of the
    IEEE Conference on Computer Vision and Pattern Recognition, pp. 580–587 (2014)'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(38) Girshick, R., Donahue, J., Darrell, T., Malik, J.: 用于准确目标检测和语义分割的丰富特征层次结构。见：IEEE计算机视觉与模式识别会议论文集，第580–587页（2014）'
- en: '(39) Girshick, R.: Fast r-cnn. In: Proceedings of the IEEE International Conference
    on Computer Vision, pp. 1440–1448 (2015)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(39) Girshick, R.: Fast R-CNN。见：IEEE国际计算机视觉会议论文集，第1440–1448页（2015）'
- en: '(40) Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time
    object detection with region proposal networks. Advances in neural information
    processing systems 28 (2015)'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(40) Ren, S., He, K., Girshick, R., Sun, J.: Faster R-CNN：利用区域提议网络实现实时目标检测。神经信息处理系统进展28（2015）'
- en: '(41) Long, J., Shelhamer, E., Darrell, T.: Fully convolutional networks for
    semantic segmentation. In: Proceedings of the IEEE Conference on Computer Vision
    and Pattern Recognition, pp. 3431–3440 (2015)'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(41) Long, J., Shelhamer, E., Darrell, T.: 用于语义分割的全卷积网络。见：IEEE计算机视觉与模式识别会议论文集，第3431–3440页（2015）'
- en: '(42) Ronneberger, O., Fischer, P., Brox, T.: U-net: Convolutional networks
    for biomedical image segmentation. In: International Conference on Medical Image
    Computing and Computer-assisted Intervention, pp. 234–241 (2015). Springer'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (42) Ronneberger, O., Fischer, P., Brox, T.：U-net：用于生物医学图像分割的卷积网络。在：医学图像计算与计算机辅助干预国际会议，pp.
    234–241 (2015). Springer
- en: '(43) Shorten, C., Khoshgoftaar, T.M.: A survey on image data augmentation for
    deep learning. Journal of Big Data 6(1), 1–48 (2019)'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (43) Shorten, C., Khoshgoftaar, T.M.：深度学习中的图像数据增强综述。大数据期刊 6(1)，1–48 (2019)
- en: '(44) Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.: mixup: Beyond empirical
    risk minimization. arXiv preprint arXiv:1710.09412 (2017)'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (44) Zhang, H., Cisse, M., Dauphin, Y.N., Lopez-Paz, D.：mixup：超越经验风险最小化。arXiv预印本
    arXiv:1710.09412 (2017)
- en: '(45) DeVries, T., Taylor, G.W.: Improved regularization of convolutional neural
    networks with cutout. arXiv preprint arXiv:1708.04552 (2017)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (45) DeVries, T., Taylor, G.W.：通过cutout改进卷积神经网络的正则化。arXiv预印本 arXiv:1708.04552
    (2017)
- en: '(46) Inoue, H.: Data augmentation by pairing samples for images classification.
    arXiv preprint arXiv:1801.02929 (2018)'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (46) Inoue, H.：通过配对样本进行图像分类的数据增强。arXiv预印本 arXiv:1801.02929 (2018)
- en: '(47) Bagherinezhad, H., Horton, M., Rastegari, M., Farhadi, A.: Label refinery:
    Improving imagenet classification through label progression. arXiv preprint arXiv:1805.02641
    (2018)'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (47) Bagherinezhad, H., Horton, M., Rastegari, M., Farhadi, A.：标签精炼：通过标签进化改进imagenet分类。arXiv预印本
    arXiv:1805.02641 (2018)
- en: '(48) Umesh, P.: Image processing in python. CSI Communications 23 (2012)'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (48) Umesh, P.：Python中的图像处理。CSI通讯 23 (2012)
- en: '(49) Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y.: Random erasing data
    augmentation. In: AAAI, pp. 13001–13008 (2020)'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (49) Zhong, Z., Zheng, L., Kang, G., Li, S., Yang, Y.：随机擦除数据增强。在：AAAI，pp. 13001–13008
    (2020)
- en: '(50) Sato, I., Nishimura, H., Yokoi, K.: Apac: Augmented pattern classification
    with neural networks. arXiv preprint arXiv:1505.03229 (2015)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (50) Sato, I., Nishimura, H., Yokoi, K.：Apac：使用神经网络的增强模式分类。arXiv预印本 arXiv:1505.03229
    (2015)
- en: '(51) Simard, P.Y., Steinkraus, D., Platt, J.C., et al.: Best practices for
    convolutional neural networks applied to visual document analysis. In: Icdar,
    vol. 3 (2003)'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (51) Simard, P.Y., Steinkraus, D., Platt, J.C., 等：应用于视觉文档分析的卷积神经网络最佳实践。在：Icdar，第3卷
    (2003)
- en: '(52) Ratner, A.J., Ehrenberg, H.R., Hussain, Z., Dunnmon, J., Ré, C.: Learning
    to compose domain-specific transformations for data augmentation. Advances in
    neural information processing systems 30, 3239 (2017)'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (52) Ratner, A.J., Ehrenberg, H.R., Hussain, Z., Dunnmon, J., Ré, C.：学习组合领域特定转换以进行数据增强。神经信息处理系统进展
    30, 3239 (2017)
- en: '(53) Zhang, X., Wang, Q., Zhang, J., Zhong, Z.: Adversarial autoaugment. arXiv
    preprint arXiv:1912.11188 (2019)'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (53) Zhang, X., Wang, Q., Zhang, J., Zhong, Z.：对抗性autoaugment。arXiv预印本 arXiv:1912.11188
    (2019)
- en: '(54) Lin, C., Guo, M., Li, C., Yuan, X., Wu, W., Yan, J., Lin, D., Ouyang,
    W.: Online hyper-parameter learning for auto-augmentation strategy. In: Proceedings
    of the IEEE/CVF International Conference on Computer Vision, pp. 6579–6588 (2019)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (54) Lin, C., Guo, M., Li, C., Yuan, X., Wu, W., Yan, J., Lin, D., Ouyang, W.：用于自动增强策略的在线超参数学习。在：IEEE/CVF国际计算机视觉会议论文集中，pp.
    6579–6588 (2019)
- en: '(55) Williams, R.J.: Simple statistical gradient-following algorithms for connectionist
    reinforcement learning. Machine learning 8(3), 229–256 (1992)'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (55) Williams, R.J.：用于连接主义强化学习的简单统计梯度跟随算法。机器学习 8(3)，229–256 (1992)
- en: '(56) Liu, H., Simonyan, K., Yang, Y.: Darts: Differentiable architecture search.
    arXiv preprint arXiv:1806.09055 (2018)'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (56) Liu, H., Simonyan, K., Yang, Y.：Darts：可微分架构搜索。arXiv预印本 arXiv:1806.09055
    (2018)
- en: '(57) Li, Y., Hu, G., Wang, Y., Hospedales, T., Robertson, N.M., Yang, Y.: Dada:
    Differentiable automatic data augmentation. arXiv preprint arXiv:2003.03780 (2020)'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (57) Li, Y., Hu, G., Wang, Y., Hospedales, T., Robertson, N.M., Yang, Y.：Dada：可微分自动数据增强。arXiv预印本
    arXiv:2003.03780 (2020)
- en: '(58) LingChen, T.C., Khonsari, A., Lashkari, A., Nazari, M.R., Sambee, J.S.,
    Nascimento, M.A.: Uniformaugment: A search-free probabilistic data augmentation
    approach. arXiv preprint arXiv:2003.14348 (2020)'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (58) LingChen, T.C., Khonsari, A., Lashkari, A., Nazari, M.R., Sambee, J.S.,
    Nascimento, M.A.：Uniformaugment：一种无搜索的概率数据增强方法。arXiv预印本 arXiv:2003.14348 (2020)
- en: '(59) Wei, L., Xiao, A., Xie, L., Zhang, X., Chen, X., Tian, Q.: Circumventing
    outliers of autoaugment with knowledge distillation. In: Computer Vision–ECCV
    2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
    Part III 16, pp. 608–625 (2020). Springer'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (59) Wei, L., Xiao, A., Xie, L., Zhang, X., Chen, X., Tian, Q.：通过知识蒸馏绕过autoaugment的异常值。在：计算机视觉–ECCV
    2020：第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，论文集，第III部分 16，pp. 608–625 (2020). Springer
- en: '(60) Naghizadeh, A., Abavisani, M., Metaxas, D.N.: Greedy autoaugment. Pattern
    Recognition Letters 138, 624–630 (2020)'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (60) Naghizadeh, A., Abavisani, M., Metaxas, D.N.：贪婪自动增强。《模式识别通讯》 138，624–630
    (2020)
- en: '(61) Niu, T., Bansal, M.: Automatically learning data augmentation policies
    for dialogue tasks. arXiv preprint arXiv:1909.12868 (2019)'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (61) Niu, T., Bansal, M.：自动学习对话任务的数据增强策略。arXiv 预印本 arXiv:1909.12868 (2019)
- en: '(62) Gudovskiy, D., Rigazio, L., Ishizaka, S., Kozuka, K., Tsukizawa, S.: Autodo:
    Robust autoaugment for biased data with label noise via scalable probabilistic
    implicit differentiation. In: Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition, pp. 16601–16610 (2021)'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (62) Gudovskiy, D., Rigazio, L., Ishizaka, S., Kozuka, K., Tsukizawa, S.：Autodo：通过可扩展的概率隐式微分对带标签噪声的偏差数据进行稳健的自动增强。在：IEEE/CVF
    计算机视觉与模式识别会议论文集，第 16601–16610 页 (2021)
- en: '(63) Naghizadeh, A., Metaxas, D.N., Liu, D.: Greedy auto-augmentation for n-shot
    learning using deep neural networks. Neural Networks 135, 68–77 (2021)'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (63) Naghizadeh, A., Metaxas, D.N., Liu, D.：使用深度神经网络的贪婪自动增强用于 n-shot 学习。《神经网络》
    135，68–77 (2021)
- en: '(64) Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,
    Z., Karpathy, A., Khosla, A., Bernstein, M., et al.: Imagenet large scale visual
    recognition challenge. International journal of computer vision 115(3), 211–252
    (2015)'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (64) Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang,
    Z., Karpathy, A., Khosla, A., Bernstein, M., 等：Imagenet 大规模视觉识别挑战。《计算机视觉国际期刊》
    115(3)，211–252 (2015)
- en: '(65) Lin, S., Yu, T., Feng, R., Li, X., Jin, X., Chen, Z.: Local patch autoaugment
    with multi-agent collaboration. arXiv preprint arXiv:2103.11099 (2021)'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (65) Lin, S., Yu, T., Feng, R., Li, X., Jin, X., Chen, Z.：局部补丁自增强与多智能体协作。arXiv
    预印本 arXiv:2103.11099 (2021)
- en: '(66) Hu, Z., Tan, B., Salakhutdinov, R., Mitchell, T., Xing, E.P.: Learning
    data manipulation for augmentation and weighting. arXiv preprint arXiv:1910.12795
    (2019)'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (66) Hu, Z., Tan, B., Salakhutdinov, R., Mitchell, T., Xing, E.P.：学习数据操作以进行增强和加权。arXiv
    预印本 arXiv:1910.12795 (2019)
- en: '(67) Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.M., Donahue, J.,
    Razavi, A., Vinyals, O., Green, T., Dunning, I., Simonyan, K., et al.: Population
    based training of neural networks. arXiv preprint arXiv:1711.09846 (2017)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (67) Jaderberg, M., Dalibard, V., Osindero, S., Czarnecki, W.M., Donahue, J.,
    Razavi, A., Vinyals, O., Green, T., Dunning, I., Simonyan, K., 等：基于人群的神经网络训练。arXiv
    预印本 arXiv:1711.09846 (2017)
- en: '(68) Terrell, G.R., Scott, D.W.: Variable kernel density estimation. The Annals
    of Statistics, 1236–1265 (1992)'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (68) Terrell, G.R., Scott, D.W.：变量核密度估计。《统计年鉴》，1236–1265 (1992)
- en: '(69) Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural
    network. arXiv preprint arXiv:1503.02531 (2015)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (69) Hinton, G., Vinyals, O., Dean, J.：提炼神经网络中的知识。arXiv 预印本 arXiv:1503.02531
    (2015)
- en: '(70) Jang, E., Gu, S., Poole, B.: Categorical reparameterization with gumbel-softmax.
    arXiv preprint arXiv:1611.01144 (2016)'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (70) Jang, E., Gu, S., Poole, B.：使用 gumbel-softmax 的类别重参数化。arXiv 预印本 arXiv:1611.01144
    (2016)
- en: '(71) Colson, B., Marcotte, P., Savard, G.: An overview of bilevel optimization.
    Annals of operations research 153(1), 235–256 (2007)'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (71) Colson, B., Marcotte, P., Savard, G.：双层优化概述。《运筹学年鉴》 153(1)，235–256 (2007)
- en: '(72) Real, E., Aggarwal, A., Huang, Y., Le, Q.V.: Regularized evolution for
    image classifier architecture search. In: Proceedings of the Aaai Conference on
    Artificial Intelligence, vol. 33, pp. 4780–4789 (2019)'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (72) Real, E., Aggarwal, A., Huang, Y., Le, Q.V.：图像分类器架构搜索的正则化进化。在：AAAI 人工智能大会论文集，第
    33 卷，第 4780–4789 页 (2019)
- en: '(73) Bergstra, J., Bengio, Y.: Random search for hyper-parameter optimization.
    Journal of machine learning research 13(2) (2012)'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (73) Bergstra, J., Bengio, Y.：超参数优化的随机搜索。《机器学习研究杂志》 13(2) (2012)
- en: '(74) Mania, H., Guy, A., Recht, B.: Simple random search provides a competitive
    approach to reinforcement learning. arXiv preprint arXiv:1803.07055 (2018)'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (74) Mania, H., Guy, A., Recht, B.：简单随机搜索提供了一个具有竞争力的强化学习方法。arXiv 预印本 arXiv:1803.07055
    (2018)
- en: '(75) Tarvainen, A., Valpola, H.: Mean teachers are better role models: Weight-averaged
    consistency targets improve semi-supervised deep learning results. arXiv preprint
    arXiv:1703.01780 (2017)'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (75) Tarvainen, A., Valpola, H.：平均教师是更好的榜样：加权平均一致性目标提高了半监督深度学习结果。arXiv 预印本 arXiv:1703.01780
    (2017)
- en: '(76) Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.: Auto-weka: Combined
    selection and hyperparameter optimization of classification algorithms. In: Proceedings
    of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data
    Mining, pp. 847–855 (2013)'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (76) Thornton, C., Hutter, F., Hoos, H.H., Leyton-Brown, K.：Auto-weka：分类算法的组合选择与超参数优化。在：第
    19 届 ACM SIGKDD 国际知识发现与数据挖掘会议论文集，第 847–855 页 (2013)
- en: '(77) Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A.L., Le, Q.V.: Adversarial
    examples improve image recognition. In: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 819–828 (2020)'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(77) Xie, C., Tan, M., Gong, B., Wang, J., Yuille, A.L., Le, Q.V.: 对抗样本提升图像识别。在:
    IEEE/CVF 计算机视觉与模式识别会议论文集, 页 819–828 (2020)'
- en: '(78) Gontijo-Lopes, R., Smullin, S.J., Cubuk, E.D., Dyer, E.: Affinity and
    diversity: Quantifying mechanisms of data augmentation. arXiv preprint arXiv:2002.08973
    (2020)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(78) Gontijo-Lopes, R., Smullin, S.J., Cubuk, E.D., Dyer, E.: 亲和力与多样性：量化数据增强的机制。arXiv
    预印本 arXiv:2002.08973 (2020)'
- en: '(79) Boutilier, C.: Planning, learning and coordination in multiagent decision
    processes. In: TARK, vol. 96, pp. 195–210 (1996). Citeseer'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(79) Boutilier, C.: 多智能体决策过程中的规划、学习与协调。在: TARK, 卷 96, 页 195–210 (1996). Citeseer'
- en: '(80) Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra,
    D.: Grad-cam: Visual explanations from deep networks via gradient-based localization.
    In: Proceedings of the IEEE International Conference on Computer Vision, pp. 618–626
    (2017)'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(80) Selvaraju, R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D., Batra,
    D.: Grad-cam: 通过基于梯度的定位从深度网络中获得的视觉解释。在: IEEE 国际计算机视觉会议论文集, 页 618–626 (2017)'
- en: '(81) Bengio, Y., Léonard, N., Courville, A.: Estimating or propagating gradients
    through stochastic neurons for conditional computation. arXiv preprint arXiv:1308.3432
    (2013)'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(81) Bengio, Y., Léonard, N., Courville, A.: 估计或传播通过随机神经元的梯度以进行条件计算。arXiv 预印本
    arXiv:1308.3432 (2013)'
- en: '(82) Oord, A.v.d., Vinyals, O., Kavukcuoglu, K.: Neural discrete representation
    learning. arXiv preprint arXiv:1711.00937 (2017)'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(82) Oord, A.v.d., Vinyals, O., Kavukcuoglu, K.: 神经离散表示学习。arXiv 预印本 arXiv:1711.00937
    (2017)'
- en: '(83) Snoek, J., Larochelle, H., Adams, R.P.: Practical bayesian optimization
    of machine learning algorithms. Advances in neural information processing systems
    25 (2012)'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(83) Snoek, J., Larochelle, H., Adams, R.P.: 机器学习算法的实用贝叶斯优化。神经信息处理系统进展 25 (2012)'
- en: '(84) Chen, S., Dobriban, E., Lee, J.: A group-theoretic framework for data
    augmentation. Advances in Neural Information Processing Systems 33, 21321–21333
    (2020)'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(84) Chen, S., Dobriban, E., Lee, J.: 用于数据增强的群论框架。神经信息处理系统进展 33, 21321–21333
    (2020)'
- en: '(85) Franceschi, L., Donini, M., Frasconi, P., Pontil, M.: Forward and reverse
    gradient-based hyperparameter optimization. In: International Conference on Machine
    Learning, pp. 1165–1173 (2017). PMLR'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(85) Franceschi, L., Donini, M., Frasconi, P., Pontil, M.: 前向和反向梯度优化超参数。在:
    国际机器学习会议, 页 1165–1173 (2017). PMLR'
- en: '(86) Wang, X., Shrivastava, A., Gupta, A.: A-fast-rcnn: Hard positive generation
    via adversary for object detection. In: Proceedings of the IEEE Conference on
    Computer Vision and Pattern Recognition, pp. 2606–2615 (2017)'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(86) Wang, X., Shrivastava, A., Gupta, A.: A-fast-rcnn: 通过对抗生成硬样本用于物体检测。在:
    IEEE 计算机视觉与模式识别会议论文集, 页 2606–2615 (2017)'
- en: '(87) Peng, X., Tang, Z., Yang, F., Feris, R.S., Metaxas, D.: Jointly optimize
    data augmentation and network training: Adversarial data augmentation in human
    pose estimation. In: Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pp. 2226–2234 (2018)'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(87) Peng, X., Tang, Z., Yang, F., Feris, R.S., Metaxas, D.: 联合优化数据增强和网络训练：人类姿态估计中的对抗性数据增强。在:
    IEEE 计算机视觉与模式识别会议论文集, 页 2226–2234 (2018)'
- en: '(88) Dong, X., Yang, Y.: Searching for a robust neural architecture in four
    gpu hours. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern
    Recognition, pp. 1761–1770 (2019)'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(88) Dong, X., Yang, Y.: 在四个 GPU 小时内寻找鲁棒的神经架构。在: IEEE/CVF 计算机视觉与模式识别会议论文集,
    页 1761–1770 (2019)'
- en: '(89) Mohamed, S., Rosca, M., Figurnov, M., Mnih, A.: Monte carlo gradient estimation
    in machine learning. J. Mach. Learn. Res. 21(132), 1–62 (2020)'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(89) Mohamed, S., Rosca, M., Figurnov, M., Mnih, A.: 机器学习中的蒙特卡洛梯度估计。J. Mach.
    Learn. Res. 21(132), 1–62 (2020)'
- en: '(90) Maddison, C.J., Mnih, A., Teh, Y.W.: The concrete distribution: A continuous
    relaxation of discrete random variables. arXiv preprint arXiv:1611.00712 (2016)'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(90) Maddison, C.J., Mnih, A., Teh, Y.W.: 具体分布：离散随机变量的连续放松。arXiv 预印本 arXiv:1611.00712
    (2016)'
- en: '(91) Grathwohl, W., Choi, D., Wu, Y., Roeder, G., Duvenaud, D.: Backpropagation
    through the void: Optimizing control variates for black-box gradient estimation.
    arXiv preprint arXiv:1711.00123 (2017)'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(91) Grathwohl, W., Choi, D., Wu, Y., Roeder, G., Duvenaud, D.: 穿越空白的反向传播：优化黑箱梯度估计的控制变量。arXiv
    预印本 arXiv:1711.00123 (2017)'
- en: '(92) Xie, S., Zheng, H., Liu, C., Lin, L.: Snas: stochastic neural architecture
    search. arXiv preprint arXiv:1812.09926 (2018)'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(92) Xie, S., Zheng, H., Liu, C., Lin, L.: Snas: 随机神经网络结构搜索。arXiv 预印本 arXiv:1812.09926
    (2018)'
- en: '(93) Domingos, P.: Every model learned by gradient descent is approximately
    a kernel machine. arXiv preprint arXiv:2012.00152 (2020)'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(93) Domingos, P.: 通过梯度下降学习的每个模型大致上是一个核机器。arXiv预印本 arXiv:2012.00152（2020年）'
- en: '(94) Gudovskiy, D., Hodgkinson, A., Yamaguchi, T., Tsukizawa, S.: Deep active
    learning for biased datasets via fisher kernel self-supervision. In: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 9041–9049
    (2020)'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(94) Gudovskiy, D., Hodgkinson, A., Yamaguchi, T., Tsukizawa, S.: 通过Fisher核自监督进行有偏数据集的深度主动学习。在：IEEE/CVF计算机视觉与模式识别会议论文集，页码9041–9049（2020年）'
- en: '(95) Terhörst, P., Kolf, J.N., Huber, M., Kirchbuchner, F., Damer, N., Morales,
    A., Fierrez, J., Kuijper, A.: A comprehensive study on face recognition biases
    beyond demographics. arXiv preprint arXiv:2103.01592 (2021)'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(95) Terhörst, P., Kolf, J.N., Huber, M., Kirchbuchner, F., Damer, N., Morales,
    A., Fierrez, J., Kuijper, A.: 关于面部识别偏差的全面研究，超越人口统计数据。arXiv预印本 arXiv:2103.01592（2021年）'
- en: '(96) Zhang, C., Bengio, S., Hardt, M., Recht, B., Vinyals, O.: Understanding
    deep learning (still) requires rethinking generalization. Communications of the
    ACM 64(3), 107–115 (2021)'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(96) Zhang, C., Bengio, S., Hardt, M., Recht, B., Vinyals, O.: 理解深度学习（仍然）需要重新思考泛化。ACM通讯
    64(3)，107–115（2021年）'
- en: '(97) Tanaka, D., Ikami, D., Yamasaki, T., Aizawa, K.: Joint optimization framework
    for learning with noisy labels. In: Proceedings of the IEEE Conference on Computer
    Vision and Pattern Recognition, pp. 5552–5560 (2018)'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(97) Tanaka, D., Ikami, D., Yamasaki, T., Aizawa, K.: 带有噪声标签学习的联合优化框架。在：IEEE计算机视觉与模式识别会议论文集，页码5552–5560（2018年）'
- en: '(98) Yi, K., Wu, J.: Probabilistic end-to-end noise correction for learning
    with noisy labels. In: Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, pp. 7017–7025 (2019)'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(98) Yi, K., Wu, J.: 用于有噪声标签学习的概率性端到端噪声校正。在：IEEE/CVF计算机视觉与模式识别会议论文集，页码7017–7025（2019年）'
- en: '(99) Lorraine, J., Vicol, P., Duvenaud, D.: Optimizing millions of hyperparameters
    by implicit differentiation. In: International Conference on Artificial Intelligence
    and Statistics, pp. 1540–1552 (2020). PMLR'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(99) Lorraine, J., Vicol, P., Duvenaud, D.: 通过隐式微分优化数百万个超参数。在：国际人工智能与统计学会议，页码1540–1552（2020年）。PMLR'
- en: '(100) Van der Maaten, L., Hinton, G.: Visualizing data using t-sne. Journal
    of machine learning research 9(11) (2008)'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(100) Van der Maaten, L., Hinton, G.: 使用t-SNE可视化数据。机器学习研究期刊 9(11)（2008年）'
- en: '(101) Shin, H.-C., Orton, M., Collins, D.J., Doran, S., Leach, M.O.: Autoencoder
    in time-series analysis for unsupervised tissues characterisation in a large unlabelled
    medical image dataset. In: 2011 10th International Conference on Machine Learning
    and Applications and Workshops, vol. 1, pp. 259–264 (2011). IEEE'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(101) Shin, H.-C., Orton, M., Collins, D.J., Doran, S., Leach, M.O.: 用于大规模未标记医学图像数据集的时间序列分析中的自编码器，以实现无监督组织特征化。在：2011年第10届国际机器学习与应用会议及研讨会，卷1，页码259–264（2011年）。IEEE'
- en: '(102) Reed, C.J., Metzger, S., Srinivas, A., Darrell, T., Keutzer, K.: Selfaugment:
    Automatic augmentation policies for self-supervised learning. In: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 2674–2683
    (2021)'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(102) Reed, C.J., Metzger, S., Srinivas, A., Darrell, T., Keutzer, K.: Selfaugment：用于自监督学习的自动增强策略。在：IEEE/CVF计算机视觉与模式识别会议论文集，页码2674–2683（2021年）'
- en: '(103) Chen, Y., Li, Y., Kong, T., Qi, L., Chu, R., Li, L., Jia, J.: Scale-aware
    automatic augmentation for object detection. In: Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, pp. 9563–9572 (2021)'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(103) Chen, Y., Li, Y., Kong, T., Qi, L., Chu, R., Li, L., Jia, J.: 面向尺度的自动增强用于目标检测。在：IEEE/CVF计算机视觉与模式识别会议论文集，页码9563–9572（2021年）'
- en: '(104) Ren, S., Zhang, J., Li, L., Sun, X., Zhou, J.: Text autoaugment: Learning
    compositional augmentation policy for text classification. arXiv preprint arXiv:2109.00523
    (2021)'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '(104) Ren, S., Zhang, J., Li, L., Sun, X., Zhou, J.: 文本自动增强：为文本分类学习组合增强策略。arXiv预印本
    arXiv:2109.00523（2021年）'
