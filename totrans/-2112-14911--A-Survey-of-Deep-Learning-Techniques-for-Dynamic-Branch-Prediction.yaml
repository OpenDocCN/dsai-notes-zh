- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:48:49'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
- en: '[2112.14911] A Survey of Deep Learning Techniques for Dynamic Branch Prediction'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2112.14911](https://ar5iv.labs.arxiv.org/html/2112.14911)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: A Survey of Deep Learning Techniques for Dynamic Branch Prediction
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Rinu Joseph Rinu Joseph Department of Electrical and Computer Engineering,
    College of Engineering and University of Texas at San Antonio, San Antonio Texas
    USA, e-mail: rinu.joseph@my.utsa.edu'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Branch prediction is an architectural feature that speeds up the execution of
    branch instruction on pipeline processors and reduces the cost of branching. Recent
    advancements of Deep Learning (DL) in the post Moore’s Law era is accelerating
    areas of automated chip design, low-power computer architectures, and much more.
    Traditional computer architecture design and algorithms could benefit from dynamic
    predictors based on deep learning algorithms which learns from experience by optimizing
    its parameters on large number of data. In this survey paper, we focus on traditional
    branch prediction algorithms, analyzes its limitations, and presents a literature
    survey of how deep learning techniques can be applied to create dynamic branch
    predictors capable of predicting conditional branch instructions. Prior surveys
    in this field [[1](#bib.bib1)] focus on dynamic branch prediction techniques based
    on neural network perceptrons. We plan to improve the survey based on latest research
    in DL and advanced Machine Learning (ML) based branch predictors.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Deep Learning, Machine Learning, Computer Architecture, Branch Prediction
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Microprocessors with superscalar and very long instruction word (VLIW) architecture
    adapts instruction level parallelism (ILP) to achieve high performance. ILP executes
    multiple instructions of a program concurrently in one CPU cycle (clock cycle)
    to accelerate memory references and computation [[2](#bib.bib2)] which can result
    in improved performance of the processors. But one of the limitations in exploiting
    ILP is the high frequency of branching instructions in a program. According to
    Haque et al. in [[3](#bib.bib3)] 15% to 25% of all instructions in a program are
    branch instructions. Three types of branch instructions are 1) jump, 2) call and
    3) return. Each of these instructions can be classified as conditional and unconditional
    branch instructions. Branch instructions can interrupt the sequential flow of
    instruction execution and instead of incrementing the instruction pointer (IP)
    to next instruction, IP is loaded with the address of an instruction in a specified
    location in the memory. This interruption in execution flow can result in control
    hazards which causes delay by filling up the pipeline with instructions which
    need to be discarded subsequently.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: To mitigate the issues caused by branching instructions in the code, an approach
    known as Branch Prediction (BP) is implemented in modern architectural designs.
    Branch prediction increases the instruction execution speed on processors by minimizing
    pipeline penalties. In BP, before the completing the execution of a branch instruction
    the outcome is predicted (whether the branch is taken or not-taken) and then starts
    executing the instructions from the predicted path prematurely. If prediction
    of BP process is correct then it is referred as branch hit. One of the advantage
    of branch hit is the effective usage of instruction pipeline. if the speculation
    is wrong (branch miss or branch penalty) the executed instructions from the wrongly
    predicted path must be discarded and instructions from right path need to be fetched
    to the pipeline. This wrong prediction can causes a branch overhead which will
    slowdown the process [[4](#bib.bib4)],[[5](#bib.bib5)].
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 为了缓解代码中分支指令引发的问题，现代架构设计中实现了一种称为分支预测（BP）的方法。分支预测通过最小化流水线惩罚来提高处理器上的指令执行速度。在分支预测中，在完成分支指令的执行之前，预测结果（分支是否被采取）并提前开始执行预测路径上的指令。如果分支预测过程的预测是正确的，则称为分支命中。分支命中的一个优点是指令流水线的有效利用。如果预测错误（分支未命中或分支惩罚），则需要丢弃从错误预测路径上执行的指令，并从正确路径上获取指令进入流水线。这种错误预测可能导致分支开销，从而减慢处理过程[[4](#bib.bib4)],[[5](#bib.bib5)]。
- en: Emerging technologies like machine learning and deep learning played a vital
    role in the advancements in the field of computer architecture. Deep Learning,
    a branch of Artificial Intelligence (AI), uses representation learning methods
    to process the raw data to discover representations required for classification
    problems. DL comes with multiple levels of representations that are obtained by
    the composition of non-linear modules that transform representation at each level.
    With these composition of transformations complex functions can be learned. DL
    is applicable to domains like science, business and government etc [[6](#bib.bib6)].
    Machine learning another sub-field of AI, enables computers and machines to learn
    the structure of input data and enable them to make decisions based on the complex
    data patterns without programming them explicitly [[7](#bib.bib7)],[[8](#bib.bib8)].
    The advancements in the field of ML and DL over the past few decades resulted
    in building more accurate systems. The increased applicability of DL models on
    real-world problems lead to a demand for high system performance [[9](#bib.bib9)].
    Researchers, system engineers and computer architects continue to design appropriate
    hardware which meets the computational requirement for training deep neural networks
    and ML algorithms on large dataset [[10](#bib.bib10)]. While the efficiency of
    computer systems are improved for training purposes, there has been some research
    done on how to utilize ML/DL techniques to enhance the system performance. Some
    of the research works were focused on the area of cache replacement, CPU scheduling,
    branch prediction and workload performance prediction on an x86 processor [[11](#bib.bib11)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 新兴技术如机器学习和深度学习在计算机架构领域的进步中发挥了重要作用。深度学习，作为人工智能（AI）的一个分支，使用表示学习方法来处理原始数据，以发现分类问题所需的表示。深度学习具有多层次的表示，这些表示通过非线性模块的组合获得，这些模块在每一层转换表示。通过这些转换组合，可以学习复杂的函数。深度学习适用于科学、商业和政府等领域[[6](#bib.bib6)]。机器学习，作为人工智能的另一个子领域，使计算机和机器能够学习输入数据的结构，并基于复杂的数据模式做出决策，而无需明确编程[[7](#bib.bib7)],[[8](#bib.bib8)]。过去几十年中，机器学习和深度学习领域的进展导致了更精确系统的构建。深度学习模型在现实世界问题上的应用增加了对高系统性能的需求[[9](#bib.bib9)]。研究人员、系统工程师和计算机架构师继续设计满足训练深度神经网络和机器学习算法的大型数据集计算要求的适当硬件[[10](#bib.bib10)]。虽然计算机系统在训练目的上的效率得到了提高，但也有一些研究致力于如何利用机器学习/深度学习技术来提升系统性能。部分研究工作集中在x86处理器上的缓存替换、CPU调度、分支预测和工作负载性能预测领域[[11](#bib.bib11)]。
- en: This research report on various ML/DL techniques for branch prediction is organised
    as follows. The following section (section 2) gives a background information about
    branch prediction and different branch prediction strategies and its functionalities.
    In section 3 we analyze various ML/DL methodologies proposed for branch prediction.
    Section 5 discusses about the current limitations and scope of new advancements.
    This report is concluded in section 6.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
- en: II Branch Prediction Strategies
  id: totrans-17
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To reduce the delay caused by the branch instructions in instruction fetching,
    instruction decoding and instruction execution, the outcome of branch i.e whether
    the branch will be taken or not, if it is take what is the direction of branch
    is predicted before the branch is executed and decision is made. This prediction
    is known as Branch Prediction mechanism [[12](#bib.bib12)]. The two main techniques
    of branch prediction are:'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
- en: II-A Static Branch Prediction
  id: totrans-19
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: It is software based prediction strategy. This approach assumes either the branch
    is always take on branch is always not taken. This is a very simple and cost effective
    prediction technique. Since this approach does not maintains a history table of
    previous branch decisions it takes only less energy for instruction execution
    when compared to other branch prediction techniques [[13](#bib.bib13)]. Following
    are the schemes of static (software-based) branch prediction.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
- en: II-A1 Single direction prediction
  id: totrans-21
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this scheme, the direction of all branch instructions will be in a similar
    way whether or not the branch is taken. This approach has simple implementation
    but low accuracy.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
- en: II-A2 Backward taken forward not taken (BTFT)
  id: totrans-23
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The target address of backward branch is lower than the current address. This
    approach presumes that all the backward loops are taken and forward branches are
    not taken.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: II-A3 Program based prediction
  id: totrans-25
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The prediction of direction of the branch instructions is based on some heuristics
    which are derived from opcode, operand and information of branch instructions
    which are executed.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
- en: II-A4 Profile-based branch prediction
  id: totrans-27
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this scheme of static branch prediction the information from program’s previous
    execution is used to determine the direction of branch instruction.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
- en: II-B Dynamic Branch Prediction
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This hardware-based prediction strategy is based on the history of branch executions.
    Dynamic branch predictions are complex compared to static prediction approach
    but has high accuracy rate. The performance is based on the prediction accuracy
    and penalty rate. Different dynamic (hardware-based) branch prediction strategies
    are:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
- en: II-B1 One-bit branch prediction buffer
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this prediction mechanism, if one assumption goes wrong branch predictor
    changes its prediction. i.e if a branch instruction is predicted as taken but
    actually the instruction is not taken, then next time predictor hardware assumes
    the instruction to be no taken.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
- en: II-B2 Two-bit branch prediction buffer
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This prediction method is similar to one-bit branch prediction buffer. The difference
    is that assumption is changed only after two consecutive miss-predictions [[14](#bib.bib14)].
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: II-B3 Correlation-based branch predictor
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: It is also known as two-level branch predictor. Accuracy of one-bit and two-bit
    branch prediction buffers are low. In correlating branch prediction accuracy is
    significantly improved by considering behaviour of recently executed branches
    for making prediction. It uses previously fetched branch target address, a local
    history table and a local prediction table to make accurate predictions for branch
    instructions [[14](#bib.bib14)].
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: III Deep Learning/Machine Learning for Dynamic Branch Prediction
  id: totrans-37
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: III-A Perceptron Based Dynamic Branch Prediction
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In 1957 Frank Rosenblatt introduced perceptrons which was inspired by learning
    abilities of a biological neuron [[15](#bib.bib15)]. Perceptron is a single layer
    neural network which consists of a processor that takes multiple inputs with weights
    and biases to generate single output. As illustrated in Figure [1](#S3.F1 "Figure
    1 ‣ III-A Perceptron Based Dynamic Branch Prediction ‣ III Deep Learning/Machine
    Learning for Dynamic Branch Prediction ‣ A Survey of Deep Learning Techniques
    for Dynamic Branch Prediction") Perceptrons work by multiplying inputs with weights
    and weighted sum of all multiplied values are taken and applied to an activation
    function.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/784d04d838220830c40797e418dfbed8.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Perceptron'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Jimenez et al. [[16](#bib.bib16)] proposed a perceptron based branch prediction
    method which can be used as an alternative to traditional two-bit branch prediction
    buffers. The proposed perceptron predictor is the first dynamic predictor to use
    neural networks for branch prediction.The predictor make use of long branch history
    which is made possible by the hardware resources which can scale the history length
    linearly to improve the accuracy of prediction method. Basically the design space
    of two-level branch predictor (correlation-based branch predictor) is explored
    and instead of pattern history table, table with perceptrons are used.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6f2f4aeec8a1c7603fcb14b3ed6214ad.png)'
  id: totrans-43
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Perceptron Predictor Block Diagram [[16](#bib.bib16)]'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
- en: In this study the branch behaviour is classified as linearly separable or linearly
    inseparable. Perceptron predictor’s performance was better with linearly separable
    branches. Decisions made by perceptrons are easy to understand when compared to
    complex neural networks. Another factor is choosing perceptron as predictor is
    because of efficient hardware implementation. Other popular neural architectures
    like ADALINE and Hebb were used in this study but performance was low due to low
    hardware efficiency and low accuracy.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: Figure [2](#S3.F2 "Figure 2 ‣ III-A Perceptron Based Dynamic Branch Prediction
    ‣ III Deep Learning/Machine Learning for Dynamic Branch Prediction ‣ A Survey
    of Deep Learning Techniques for Dynamic Branch Prediction") is the block diagram
    for proposed perceptron predictor. The system processor maintains a table of perceptrons
    in SRAM like two-bit counters. Based on number of weights the and budget for hardware
    the number of perceptrons in the table is fixed. When a branch instruction is
    fetched an index is produced in the perceptrons table by hashing the branch address
    and the perceptron at this index is moved to a vector register of weights (In
    this experiment signed weights are used).The dot product of weight and global
    history register is computed to produce output. If the output value is negative
    then the branch is predicted to be not taken or if the value is positive then
    branch is taken. When actual outcome is known, the weights are updated based on
    the actual result and predicted value by the training algorithm.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: To achieve best performance three parameters are considered and tuned, 1) History
    Length, 2) Weight Representations, 3) Threshold. The increase in history length
    yielded more accuracy in predictions. history lengths from 12 to 62 reported best
    outcome for this training algorithms. As mentioned earlier the weights are signed
    integers and they simplify the architecture design.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/0a9e46190bc21f22e74380d17f754ff4.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Performance vs History Length [[16](#bib.bib16)]'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e1e45af010f170cf7d8aa335979bed01.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Performance vs Linear Separability [[16](#bib.bib16)]'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: In [[16](#bib.bib16)] two dynamic predictors gshare and bi-mode were chosen
    to compare with perceptron predictor. As seen in the figure [3](#S3.F3 "Figure
    3 ‣ III-A Perceptron Based Dynamic Branch Prediction ‣ III Deep Learning/Machine
    Learning for Dynamic Branch Prediction ‣ A Survey of Deep Learning Techniques
    for Dynamic Branch Prediction"), when longer histories are considered gshare shows
    poor performance and perceptron predictor improves the performance. This paper
    is concluded by stating that although perceptrons are not capable of learning
    linearly inseparable behaviour of branches (Figure [4](#S3.F4 "Figure 4 ‣ III-A
    Perceptron Based Dynamic Branch Prediction ‣ III Deep Learning/Machine Learning
    for Dynamic Branch Prediction ‣ A Survey of Deep Learning Techniques for Dynamic
    Branch Prediction")) and they are complex when compared to two-bit counters, perceptrons
    can use long history tables without any exponential resources and also achieve
    a low misprediction rates and higher accuracy when compared to existing dynamic
    predictors.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: Akkary et al. in [[17](#bib.bib17)] proposed a perceptron based branch confidence
    estimator to reduce the misprediction of branch instructions. One of the factor
    that contribute to high performance of a system is execution of unresolved branches
    based on some speculations made by branch prediction techniques. Mispredicted
    executions negatively impact the system by taking up the resources, creating stalls
    in execution and also affect the power of the system because more instructions
    are executed when there is mis-speculation occurs. In deeper pipeline processors,
    pipelining gating plays a vital role in reducing wasted executions based on wrong
    speculative decisions made by predictors. With perceptron-based branch confidence
    estimator predictions provide multi-valued outputs. i.e the classify the branch
    instructions into “strongly low confident” and “weakly low confident”.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
- en: With confidence estimation, instruction fetching can be stalled when low confidence
    unresolved branch instructions are encountered. Estimation is correct when low
    confident branch is actually mispredicted. This correct estimation can reduce
    the execution wastage. When estimation is wrong (i.e low confident branch is correctly
    predicted) there will be a pipeline stall which can lead to performance loss.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7718a12d565070d0576f3439052bdd76.png)'
  id: totrans-55
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: Perceptron based confidence estimator [[17](#bib.bib17)]'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: As seen in the figure [5](#S3.F5 "Figure 5 ‣ III-A Perceptron Based Dynamic
    Branch Prediction ‣ III Deep Learning/Machine Learning for Dynamic Branch Prediction
    ‣ A Survey of Deep Learning Techniques for Dynamic Branch Prediction"), index
    of array of perceptrons are based on conditional branch memory address. In this
    method global history register which contains taken branch represented as 1 and
    not-taken branch represented as -1 is passed as a input vector tho the perceptron.
    Dot product of weight vector in perceptron and this input vector is used to generate
    the output. As mentioned earlier the output of this approach is multi-valued.
    i.e, branches can be further classified as low or high confidence. The generated
    output is then compared against a specific threshold $\lambda$ . When output is
    larger then prediction can be wrong or if the output is smaller than the threshold
    then the prediction is more likely to be correct.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
- en: Specificity and Predictive value of a negative test (PVN) are the primary metrics
    used for perceptron based branch confidence estimator. Specificity is the percentage
    of mispredicted branches which were classified as low confidence by branch confidence
    estimator. PVN is the probability of correctly mispredicted low confidence branches
    (as a measure of accuracy).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: III-B Branch Prediction with Convolutional Neural Networks and Deep Belief Networks
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Tarsa et al. in [[18](#bib.bib18)] says that although branch prediction attained
    99% accuracy in prediction static branches, Hard-to -predict(H2P) branches are
    still a major bottleneck in the system performance. Authors suggested machine
    learning approach to that could work along with standard branch predictors to
    predict H2P. They developed helper predictors mainly convolutional neural network
    based helpers to improve the process of pattern matching in global history data.
    Unlike the TAGE and preceptron based BPs, CNN based helper predictors are deployed
    offline.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
- en: This paper illustrated two examples of program in which the data dependency
    of iteration counts creates H2Ps. Variations available in data can confuse the
    state-of-the-art predictors but are handled by convolutional filters. The global
    history (instruction pointer and direction of previous branches) are converted
    to vector representations. The input to CNN is generated by concatenating the
    vectors to from a matrix for global history. CNN calculates the dot product of
    data vector, weight vector,filter and bias to perform the pattern matching. Score
    computer by each filter against the each history matrix column are passed to filter
    in the linear layer (similar to perceptron layer) to match the output of layer
    1 in two-layer CNN. If the output of layer 2 is ¿ 0 then the branch is taken or
    it is not-taken. the first layer (layer 1) in CNN identifies which instruction
    pointer and direction in history table correlates with the h2P’s direction and
    layer 2 identifies which position in history contribute to branch prediction process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
- en: This paper concluded by stating the how two-layer CNN along with the branch
    predictors can reduce the positional variants in global history data which can
    lead to branch mispredictions. They also provided some insights like passing more
    data like register values to network to improve the accuracy for future development
    of ML-based branch predictors.
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
- en: Based on the work [[18](#bib.bib18)] by Tarsa et al, Zangeneh et al. developed
    a convolutional neural network called as BranchNet [[19](#bib.bib19)] for hard-to-predict
    branches in 2020\. As mentioned in [[18](#bib.bib18)] traditional branch predictors
    are updated in run-time which makes it difficult to find the correlations in branch
    history. Exisiting predictors cannot find correlations from a noisy history while
    CNN can identify those correlations correctly. This capability of CNN improves
    the prediction rates but requires high computational cost and large dataset for
    training. BranchNet can be trained offline and this models are attached to the
    program so that the predictors can use this model in runtime. Authors [[19](#bib.bib19)]
    popose CNN architecture in two-ways. 1)Using geometric history length as input
    to the model, 2)Sum-pooling for the compression of global history information.
    The designed CNN architecture is storage efficient and same latency as TAGE-SC-L.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7ad4c96034749d6d83659989cf8bc6ac.png)'
  id: totrans-64
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Big-BranchNet Network Architecture [[19](#bib.bib19)]'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b13aefad352ee76fb29859236f457289.png)'
  id: totrans-66
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Mini-BranchNet Network Architecture [[19](#bib.bib19)]'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
- en: In this paper two-variants of BranchNet are proposed. *Big-BranchNet*, consists
    of two fully-connected layers and five feature extraction layers (slice) (see
    [6](#S3.F6 "Figure 6 ‣ III-B Branch Prediction with Convolutional Neural Networks
    and Deep Belief Networks ‣ III Deep Learning/Machine Learning for Dynamic Branch
    Prediction ‣ A Survey of Deep Learning Techniques for Dynamic Branch Prediction")).
    Slice consists of embedding layer, sum-pooling layer and convolutional layer for
    feature extraction from branch history. Each slice works on different history
    length to form a geometric series. Concatenated output from all slices are passed
    to FC layer for prediction output. Authors do not recommend the practical use
    of this variant as a branch predictor as this is a software model. Another variant
    of BranchNet is *mini-BranchNet* is co-designed with an inference engine. The
    architecture of min-BranchNet is similar to big-BranchNet except that it has knobs
    that can be tuned to reduce the latency and storage. Mini-BranchNet can work as
    a branch predictor.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
- en: The key achievement described in this paper is that with BranchNet deep learning
    network architectures can be trained in offline mode and this approach is very
    useful in eliminating the issues of state-of-the-art branch predictors when executed
    in runtime.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
- en: '*Deep Belief Networks* (DBN) are stack of Restricted Boltzmann Machine(RBM)
    or Autoencoders which can be used as a solution to mitigate the vanishing gradient
    problem caused by backpropagation process. DBNs can be defined as a combination
    of probability and statistics with neural network architectures. The two layers
    (top) in this generative hybrid model are undirected and the layers are connected
    to next following layers [[20](#bib.bib20)]. Figure [8](#S3.F8 "Figure 8 ‣ III-B
    Branch Prediction with Convolutional Neural Networks and Deep Belief Networks
    ‣ III Deep Learning/Machine Learning for Dynamic Branch Prediction ‣ A Survey
    of Deep Learning Techniques for Dynamic Branch Prediction") is commonly used DBN
    architecture. It has four RBM layers and an output layer. Layer 1 and layer 3
    has same size. Size of input layer and layer 4 are also same. The last layer in
    the network architecture is a perceptron (single layer neural network). Deep Belief
    Networks uses unsupervised leaning techinque, where it trains the network layers
    to reconstruct the input data in last RBM layer. The inner layer extract the features
    from input to regenerate it with minimum error.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2b7813b57135ba62fd733fb79dcd6d07.png)'
  id: totrans-71
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Deep Belief Network Architecture [[21](#bib.bib21)]'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
- en: In 2017 Mao et al. proposed the idea of using neural networks with deep belief
    networks for branch prediction [[22](#bib.bib22)] which could outperform perceptron
    based BPs in terms of reducing misprediction rate. Later in 2017 [[21](#bib.bib21)]
    Mao et al. discuss about the possibility of using advanced deep neural networks
    like convolutional neural network along with deep belief network for branch prediction.
    Branch prediction problem is considered as a classification problem to implement
    different deep learning network architectures and impact of global history register
    (GHR), branch global address, length of program counter of the classifier on the
    rate of mis-speculated branch is studied . 90% of data is used for training set
    and remaining 10% is used for testing and validation purpose. For branch prediction
    two CNN and one DBN models were created.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/37be55eb9898af0d0c69c01dac27d14c.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Deep Belief Network Architecture for Branch Prediction [[21](#bib.bib21)]'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/549d4129f6ce8cca8c604c56c5605efc.png)'
  id: totrans-76
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Convolutional Network Network Architecture for Branch Prediction
    [[21](#bib.bib21)]'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
- en: Figure [9](#S3.F9 "Figure 9 ‣ III-B Branch Prediction with Convolutional Neural
    Networks and Deep Belief Networks ‣ III Deep Learning/Machine Learning for Dynamic
    Branch Prediction ‣ A Survey of Deep Learning Techniques for Dynamic Branch Prediction")
    is the DBN architecture. Neurons in the fully connected layers (FC) 1 and 3 are
    same (630). Layer 4 is same as the input layer. Figure [10](#S3.F10 "Figure 10
    ‣ III-B Branch Prediction with Convolutional Neural Networks and Deep Belief Networks
    ‣ III Deep Learning/Machine Learning for Dynamic Branch Prediction ‣ A Survey
    of Deep Learning Techniques for Dynamic Branch Prediction") shows the 2 differnt
    CNN architectures used for this experiment. First CNN architecture is based on
    *LeNet* and second one is based on *AlexNet*. The results of these network architectures
    are compared against state-of-the-art branch predictors.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
- en: This paper is concluded by stating that performance of deep neural network architecture
    based branch predictors are better than perceptron based BPs. Deeper CNN architectures
    can outperform state-of-the-art branch predictors like Multi-poTAGE+SC and MTAGE+SC.
    When the performance of DBN and CNN are compared, CNN architecture outperformed
    DBN based branch predictors.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
- en: III-C Reinforcement Learning for Branch Prediction
  id: totrans-80
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '*Reinforcement Learning* is a machine learning methodology in which the training
    algorithm estimates the error based on the penalty or reward in particular situation.
    The penalty is high and reward is low when the error is high. Reward is high when
    the calculated error is low.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
- en: In [[23](#bib.bib23)] Zouzias et al. proposed the idea of using machine learning
    technique Reinforcement Learning (RL) formulation in improving branch predictor
    designs. Today branch predictors in high-end processors are perceptron based or
    variants of TAGE. But there are not significant improvements in recent years to
    the prediction mechanism of these two variants. [[23](#bib.bib23)] suggests that
    branch prediction can be viewed as reinforcement learning problem because they
    have similar theoretical principles.We can consider branch predictor as an agent
    which can closely observe the control flow of the code (i.e the history of branch
    results) and learns a policy to improve the accuracy in future predictions. Execution
    environment of processor is considered as environment for branch predictor agent.
    Branch prediction with RL enables to explore design of branch predictor in the
    aspects of predictor’s decision making policy, state representation and misprediction
    minimization strategy.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
- en: The environment communicates with the agent (branch predictor) so that agent
    can choose and action from state space. Later, based on the correctness of the
    action selected by agent environment responds back with a reward. This reward
    helps to update the predictor. Normally the state space from where agent selects
    action contains PC address of branch, local/global history of branch instructions.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6aad9b571a9c5eda9be4fe243909b9f1.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: Classification of branch predictors based on RL methods [[23](#bib.bib23)]'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
- en: Based on the RL methods, the branch predictors are classified into two class
    categories 1) tabular, 2) functional. TAGE based predicors, gshare and bimodal
    predictors are categorized as tabular and perceptron based predictors are categorized
    as functional (O-GHEL, hased perceptron and multiperspective predictors). From
    figure [11](#S3.F11 "Figure 11 ‣ III-C Reinforcement Learning for Branch Prediction
    ‣ III Deep Learning/Machine Learning for Dynamic Branch Prediction ‣ A Survey
    of Deep Learning Techniques for Dynamic Branch Prediction") tabular predictors
    can be formulated with Q-learning and functional predictors with policy-gradient
    methods.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: 'This paper provide information on how to use reinforcement learning in designing
    future branch predictors. Key aspects to be considered for the development are:'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
- en: III-C1 Policy
  id: totrans-88
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: A function which can be represented as linear or non-linear model from current
    state to branch result. One of the advantage of this model is the easy hardware
    implementation . As mentioned in [[16](#bib.bib16)] perceptron based models cannot
    capture non-linear correlations. But in non-linear models micro-architectural
    implementations are hard and expensive.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: III-C2 State Representation
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: State for branch predictions may contain branch address, local/global history
    and loop counters.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
- en: III-C3 Loss function
  id: totrans-92
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: For branch predictors loss function (objective function) plays a vital role
    in achieving goal i.e reducing the mispredictions or reducing misprediction probability.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
- en: III-C4 Optimization Strategy
  id: totrans-94
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The optimizer in RL methodology tunes learning rate to minimize the loss functions
    to reduce the miprediction probability. Online gradient descent optimizer is used
    in perceptron based branch predictors to minimize hinge loss function to adjust
    the learning rate.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
- en: Authors illustrated how RL methods can be applied in BP design by applying policy
    gradient to design perceptron based predictor. The RL based predictor is known
    as Policy Gradient Agent BP (PolGAg).
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: IV Discussion
  id: totrans-97
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Advancements in machine learning and deep learning has benefited computer architecture
    in many ways. Different neural networks has enhanced the branch prediction methodolgies.
    In [[16](#bib.bib16)] and [[17](#bib.bib17)] we have seen that single layer neural
    network called perceptron could be used for branch prediction and branch confidence
    estimator. Variants of state-of-the-art branch predictor TAGE and perceptron based
    branch predictor have latency and higher misprediction rate in hard-to-predict
    branches (H2P). To overcome this issue Tarsa et al. in [[18](#bib.bib18)] proposed
    a convolutional neural network based architecture which could be trained offline
    to predict H2Ps. Later in 2020 based on [[18](#bib.bib18)] work another convolutional
    network called BranchNet was proposed in [[19](#bib.bib19)] for the same purpose.
    This paper designed 2 architecture Big-BranchNet and Mini-BranchNet for H2Ps.
    In [[22](#bib.bib22)] two architectures similar to *LeNet* and *AlexNet* are implemented.
    Although we have seen some of the researches on this topic, more study can be
    conducted on dynamic branch prediction and improve efficiency. Possibility of
    popular deep learning architectures like *ResNet* and *VGGnet* can be studied
    to implement them with branch preditors.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: V Conclusion
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This survey focused on how different machine learning techniques and deep learning
    network architectures can be used to enhance the predictive ability of branch
    predictors. Many state-of-the-art predictors have achieved significant accuracy
    in branch outcome prediction. But the papers reviewed in this survey shows that,
    with different network architectures like perceptron, convolutional neural networks,
    deep, belied networks the performance of the system can be improved significantly
    by reducing the latency and misprediction rate.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-101
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Sparsh Mittal. A survey of techniques for dynamic branch prediction. Concurrency
    and Computation: Practice and Experience, 31(1):e4666, 2019.'
  id: totrans-102
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] Vijay Sadananda Pai. Exploiting Instruction-Level Parallelism for Memory
    System Performance. Rice University, 2000.'
  id: totrans-103
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] Md Sarwar M Haque, Md Rafiul Hassan, Muhammad Sulaiman, Salami Onoruoiza,
    Joarder Kamruzzaman, and Md Arifuzzaman. Enhancing branch predictors using genetic
    algorithm. In 2019 8th International Conference on Modeling Simulation and Applied
    Optimization (ICMSAO), pages 1–5, 2019.'
  id: totrans-104
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] Jim Kukunas. Power and Performance: Software Analysis and Optimization.
    Morgan Kaufmann, 2015.'
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] Brad Calder, Dirk Grunwald, and Joel Emer. A system level perspective on
    branch architecture performance. In Proceedings of the 28th Annual International
    Symposium on Microarchitecture, pages 199–206\. IEEE, 1995.'
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature 521
    (7553), 436-444. Google Scholar Google Scholar Cross Ref Cross Ref, 2015.'
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] Introduction to machine learning and deep learning. — by sanchit tanwar
    — medium. https://medium.com/@sanchittanwar75/introduction-to-machine-learning-and-deep-learning-bd25b792e488.
    (Accessed on 11/25/2021).'
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] An introduction to machine learning — digitalocean. https://www.digitalocean.com/community/tutorials/an-introduction-to-machine-learning.
    (Accessed on 11/25/2021).'
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Jeffrey Dean. 1.1 the deep learning revolution and its implications for
    computer architecture and chip design. In 2020 IEEE International Solid- State
    Circuits Conference - (ISSCC), pages 8–14, 2020.'
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Jeff Dean, David Patterson, and Cliff Young. A new golden age in computer
    architecture: Empowering the machine-learning revolution. IEEE Micro, 38(2):21–29,
    2018.'
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Daniel Nemirovsky, Tugberk Arkose, Nikola Markovic, Mario Nemirovsky,
    Osman Unsal, Adrian Cristal, and Mateo Valero. A general guide to applying machine
    learning to computer architecture. Supercomputing Frontiers and Innovations, 5(1):95–115,
    2018.'
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] Gang Luo and Hongfei Guo. Software-based and hardware-based branch prediction
    strategies and performance evaluation.'
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Sweety and Prachi Chaudhary. Implemented static branch prediction schemes
    for the parallelism processors. In 2019 International Conference on Machine Learning,
    Big Data, Cloud and Parallel Computing (COMITCon), pages 79–83, 2019.'
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Correlating branch prediction - geeksforgeeks. https://www.geeksforgeeks.org/correlating-branch-prediction/.
    (Accessed on 11/30/2021).'
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] Frank Rosenblatt. The perceptron: a probabilistic model for information
    storage and organization in the brain. Psychological review, 65(6):386, 1958.'
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Daniel A Jiménez and Calvin Lin. Dynamic branch prediction with perceptrons.
    In Proceedings HPCA Seventh International Symposium on High-Performance Computer
    Architecture, pages 197–206\. IEEE, 2001.'
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] H. Akkary, S.T. Srinivasan, R. Koltur, Y. Patil, and W. Refaai. Perceptron-based
    branch confidence estimation. In 10th International Symposium on High Performance
    Computer Architecture (HPCA’04), pages 265–265, 2004.'
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Stephen J Tarsa, Chit-Kwan Lin, Gokce Keskin, Gautham Chinya, and Hong
    Wang. Improving branch prediction by modeling global history with convolutional
    neural networks. arXiv preprint arXiv:1906.09889, 2019.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Siavash Zangeneh, Stephen Pruett, Sangkug Lym, and Yale N. Patt. Branchnet:
    A convolutional neural network to predict hard-to-predict branches. In 2020 53rd
    Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pages 118–130,
    2020.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Deep learning — deep belief network (dbn) — by renu khandelwal — datadriveninvestor.
    https://medium.datadriveninvestor.com/deep-learning-deep-belief-network-dbn-ab715b5b8afc.
    (Accessed on 12/04/2021).'
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Yonghua Mao, Z Huiyang, and Xiaolin Gui. Exploring deep neural networks
    for branch prediction. ECE Department, NC University, 2017.'
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Yonghua Mao, Junjie Shen, and Xiaolin Gui. A study on deep belief net
    for branch prediction. IEEE Access, 6:10779–10786, 2018.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] Anastasios Zouzias, Kleovoulos Kalaitzidis, and Boris Grot. Branch prediction
    as a reinforcement learning problem: Why, how and case studies. arXiv preprint
    arXiv:2106.13429, 2021.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
