["```py\ntfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, \n                       aug_tfms=augs)\nmd = Image**Classifier**Data.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n                                  **continuous=True**, bs=4)\n```", "```py\naugs = [RandomFlip(), \n        RandomRotate(30),\n        RandomLighting(0.1,0.1)]\n```", "```py\ntfms = tfms_from_model(f_model, sz, crop_type=CropType.NO,\n                       aug_tfms=augs)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms,\n                       continuous=True, bs=4)idx=3\nfig,axes = plt.subplots(3,3, figsize=(9,9))\nfor i,ax in enumerate(axes.flat):\n    x,y=next(iter(md.aug_dl))\n    ima=md.val_ds.denorm(to_np(x))[idx]\n    b = bb_hw(to_np(y[idx]))\n    print(b)\n    show_img(ima, ax=ax)\n    draw_rect(ax, b)*[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]\n[ 115\\.   63\\.  240\\.  311.]*\n```", "```py\naugs = [RandomFlip(tfm_y=TfmType.COORD),\n        RandomRotate(30, tfm_y=TfmType.COORD),\n        RandomLighting(0.1,0.1, tfm_y=TfmType.COORD)]tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO,\n                       tfm_y=TfmType.COORD, aug_tfms=augs)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, \n                       continuous=True, bs=4)\n```", "```py\nidx=3\nfig,axes = plt.subplots(3,3, figsize=(9,9))\nfor i,ax in enumerate(axes.flat):\n    x,y=next(iter(md.aug_dl))\n    ima=md.val_ds.denorm(to_np(x))[idx]\n    b = bb_hw(to_np(y[idx]))\n    print(b)\n    show_img(ima, ax=ax)\n    draw_rect(ax, b)*[  48\\.   34\\.  112\\.  188.]\n[  65\\.   36\\.  107\\.  185.]\n[  49\\.   27\\.  131\\.  195.]\n[  24\\.   18\\.  147\\.  204.]\n[  61\\.   34\\.  113\\.  188.]\n[  55\\.   31\\.  121\\.  191.]\n[  52\\.   19\\.  144\\.  203.]\n[   7\\.    0\\.  193\\.  222.]\n[  52\\.   38\\.  105\\.  182.]*\n```", "```py\ntfm_y = TfmType.COORD\naugs = [RandomFlip(tfm_y=tfm_y),\n        RandomRotate(**3**, **p=0.5**, tfm_y=tfm_y),\n        RandomLighting(0.05,0.05, tfm_y=tfm_y)]tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, \n                 tfm_y=tfm_y, aug_tfms=augs)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, BB_CSV, tfms=tfms, \n                 continuous=True)\n```", "```py\nhead_reg4 = nn.Sequential(Flatten(), nn.Linear(25088,4))\nlearn = ConvLearner.pretrained(f_model, md, custom_head=head_reg4)\nlearn.opt_fn = optim.Adam\nlearn.crit = nn.L1Loss()\n```", "```py\nf_model=resnet34\nsz=224\nbs=64val_idxs = get_cv_idxs(len(trn_fns))\ntfms = tfms_from_model(f_model, sz, crop_type=CropType.NO, \n                       tfm_y=TfmType.COORD, aug_tfms=augs)md = ImageClassifierData.from_csv(PATH, JPEGS, **BB_CSV**, tfms=tfms, \n                       continuous=True, val_idxs=val_idxs)md2 = ImageClassifierData.from_csv(PATH, JPEGS, **CSV**,\n                       tfms=tfms_from_model(f_model, sz))\n```", "```py\n**class** **ConcatLblDataset**(Dataset):\n    **def** __init__(self, ds, y2): self.ds,self.y2 = ds,y2\n    **def** __len__(self): **return** len(self.ds)\n\n    **def** __getitem__(self, i):\n        x,y = self.ds[i]\n        **return** (x, (y,self.y2[i]))\n```", "```py\ntrn_ds2 = ConcatLblDataset(md.trn_ds, md2.trn_y)\nval_ds2 = ConcatLblDataset(md.val_ds, md2.val_y)\n```", "```py\nval_ds2[0][1]*(array([   0.,   49.,  205.,  180.], dtype=float32), 14)*\n```", "```py\nmd.trn_dl.dataset = trn_ds2\nmd.val_dl.dataset = val_ds2\n```", "```py\nx,y = next(iter(md.val_dl))\nidx = 3\nima = md.val_ds.ds.denorm(to_np(x))[idx]\nb = bb_hw(to_np(y[0][idx])); b*array([  52.,   38.,  106.,  184.], dtype=float32)*ax = show_img(ima)\ndraw_rect(ax, b)\ndraw_text(ax, b[:2], md2.classes[y[1][idx]])\n```", "```py\nhead_reg4 = nn.Sequential(\n    Flatten(),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(25088,256),\n    nn.ReLU(),\n    nn.BatchNorm1d(256),\n    nn.Dropout(0.5),\n    nn.Linear(256,**4+len(cats)**),\n)\nmodels = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\n\nlearn = ConvLearner(md, models)\nlearn.opt_fn = optim.Adam\n```", "```py\n**def** detn_loss(input, target):\n    bb_t,c_t = target\n    bb_i,c_i = input[:, :4], input[:, 4:]\n    bb_i = F.sigmoid(bb_i)*224\n *# I looked at these quantities separately first then picked a \n    # multiplier to make them approximately equal*\n    **return** F.l1_loss(bb_i, bb_t) + F.cross_entropy(c_i, c_t)*20**def** detn_l1(input, target):\n    bb_t,_ = target\n    bb_i = input[:, :4]\n    bb_i = F.sigmoid(bb_i)*224\n    **return** F.l1_loss(V(bb_i),V(bb_t)).data**def** detn_acc(input, target):\n    _,c_t = target\n    c_i = input[:, 4:]\n    **return** accuracy(c_i, c_t)learn.crit = detn_loss\nlearn.metrics = [detn_acc, detn_l1]\n```", "```py\nlr=1e-2\nlearn.fit(lr, 1, cycle_len=3, use_clr=(32,5))*epoch      trn_loss   val_loss   detn_acc   detn_l1       \n    0      72.036466  45.186367  0.802133   32.647586 \n    1      51.037587  36.34964   0.828425   25.389733     \n    2      41.4235    35.292709  0.835637   24.343577**[35.292709, 0.83563701808452606, 24.343576669692993]*\n```", "```py\nlearn.save('reg1_0')\nlearn.freeze_to(-2)\nlrs = np.array([lr/100, lr/10, lr])\nlearn.fit(lrs/5, 1, cycle_len=5, use_clr=(32,10))epoch      trn_loss   val_loss   detn_acc   detn_l1       \n    0      34.448113  35.972973  0.801683   22.918499 \n    1      28.889909  33.010857  0.830379   21.689888     \n    2      24.237017  30.977512  0.81881    20.817996     \n    3      21.132993  30.60677   0.83143    20.138552     \n    4      18.622983  30.54178   0.825571   19.832196[30.54178, 0.82557091116905212, 19.832195997238159]learn.unfreeze()\nlearn.fit(lrs/10, 1, cycle_len=10, use_clr=(32,10))epoch      trn_loss   val_loss   detn_acc   detn_l1       \n    0      15.957164  31.111507  0.811448   19.970753 \n    1      15.955259  32.597153  0.81235    20.111022     \n    2      15.648723  32.231941  0.804087   19.522853     \n    3      14.876172  30.93821   0.815805   19.226574     \n    4      14.113872  31.03952   0.808594   19.155093     \n    5      13.293885  29.736671  0.826022   18.761728     \n    6      12.562566  30.000023  0.827524   18.82006      \n    7      11.885125  30.28841   0.82512    18.904158     \n    8      11.498326  30.070133  0.819712   18.635296     \n    9      11.015841  30.213772  0.815805   18.551489[30.213772, 0.81580528616905212, 18.551488876342773]\n```", "```py\n%matplotlib inline\n%reload_ext autoreload\n%autoreload 2**from** **fastai.conv_learner** **import** *\n**from** **fastai.dataset** **import** *\n\n**import** **json**, **pdb**\n**from** **PIL** **import** ImageDraw, ImageFont\n**from** **matplotlib** **import** patches, patheffects\ntorch.backends.cudnn.benchmark=**True**\n```", "```py\nPATH = Path('data/pascal')\ntrn_j = json.load((PATH / 'pascal_train2007.json').open())\nIMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', \n                                 'categories']\nFILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id', \n                                  'category_id','bbox'\n\ncats = dict((o[ID], o['name']) **for** o **in** trn_j[CATEGORIES])\ntrn_fns = dict((o[ID], o[FILE_NAME]) **for** o **in** trn_j[IMAGES])\ntrn_ids = [o[ID] **for** o **in** trn_j[IMAGES]]\n\nJPEGS = 'VOCdevkit/VOC2007/JPEGImages'\nIMG_PATH = PATH/JPEGS**def** get_trn_anno():\n    trn_anno = collections.defaultdict(**lambda**:[])\n    **for** o **in** trn_j[ANNOTATIONS]:\n        **if** **not** o['ignore']:\n            bb = o[BBOX]\n            bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, \n                           bb[2]+bb[0]-1])\n            trn_anno[o[IMG_ID]].append((bb,o[CAT_ID]))\n    **return** trn_anno\n\ntrn_anno = get_trn_anno()**def** show_img(im, figsize=**None**, ax=**None**):\n    **if** **not** ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im)\n    ax.set_xticks(np.linspace(0, 224, 8))\n    ax.set_yticks(np.linspace(0, 224, 8))\n    ax.grid()\n    ax.set_yticklabels([])\n    ax.set_xticklabels([])\n    **return** ax\n\n**def** draw_outline(o, lw):\n    o.set_path_effects([patheffects.Stroke(\n        linewidth=lw, foreground='black'), patheffects.Normal()])\n\n**def** draw_rect(ax, b, color='white'):\n    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], \n                         fill=**False**, edgecolor=color, lw=2))\n    draw_outline(patch, 4)\n\n**def** draw_text(ax, xy, txt, sz=14, color='white'):\n    text = ax.text(*xy, txt,\n        verticalalignment='top', color=color, fontsize=sz, \n        weight='bold')\n    draw_outline(text, 1)**def** bb_hw(a): **return** np.array([a[1],a[0],a[3]-a[1],a[2]-a[0]])\n\n**def** draw_im(im, ann):\n    ax = show_img(im, figsize=(16,8))\n    **for** b,c **in** ann:\n        b = bb_hw(b)\n        draw_rect(ax, b)\n        draw_text(ax, b[:2], cats[c], sz=16)\n\n**def** draw_idx(i):\n    im_a = trn_anno[i]\n    im = open_image(IMG_PATH/trn_fns[i])\n    draw_im(im, im_a)\n```", "```py\nMC_CSV = PATH/'tmp/mc.csv'trn_anno[12]*[(array([ 96, 155, 269, 350]), 7)]*mc = [set([cats[p[1]] **for** p **in** trn_anno[o]]) **for** o **in** trn_ids]\nmcs = [' '.join(str(p) **for** p **in** o) **for** o **in** mc]df = pd.DataFrame({'fn': [trn_fns[o] **for** o **in** trn_ids], \n                   'clas': mcs}, columns=['fn','clas'])\ndf.to_csv(MC_CSV, index=**False**)\n```", "```py\nf_model=resnet34\nsz=224\nbs=64tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO)\nmd = ImageClassifierData.from_csv(PATH, JPEGS, MC_CSV, tfms=tfms)learn = ConvLearner.pretrained(f_model, md)\nlearn.opt_fn = optim.Adamlr = 2e-2learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))*epoch      trn_loss   val_loss   <lambda>                  \n    0      0.104836   0.085015   0.972356  \n    1      0.088193   0.079739   0.972461                   \n    2      0.072346   0.077259   0.974114**[0.077258907, 0.9741135761141777]*lrs = np.array([lr/100, lr/10, lr])learn.freeze_to(-2)learn.fit(lrs/10, 1, cycle_len=5, use_clr=(32,5))*epoch      trn_loss   val_loss   <lambda>                   \n    0      0.063236   0.088847   0.970681  \n    1      0.049675   0.079885   0.973723                   \n    2      0.03693    0.076906   0.975601                   \n    3      0.026645   0.075304   0.976187                   \n    4      0.018805   0.074934   0.975165**[0.074934497, 0.97516526281833649]*learn.save('mclas')learn.load('mclas')y = learn.predict()\nx,_ = next(iter(md.val_dl))\nx = to_np(x)fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n**for** i,ax **in** enumerate(axes.flat):\n    ima=md.val_ds.denorm(x)[i]\n    ya = np.nonzero(y[i]>0.4)[0]\n    b = '**\\n**'.join(md.classes[o] **for** o **in** ya)\n    ax = show_img(ima, ax=ax)\n    draw_text(ax, (0,0), b)\nplt.tight_layout()\n```", "```py\nmc = [**set**([cats[p[1]] **for** p **in** trn_anno[o]]) **for** o **in** trn_ids]\n```", "```py\n**class** **StdConv**(nn.Module):\n    **def** __init__(self, nin, nout, stride=2, drop=0.1):\n        super().__init__()\n        self.conv = nn.Conv2d(nin, nout, 3, stride=stride, \n                              padding=1)\n        self.bn = nn.BatchNorm2d(nout)\n        self.drop = nn.Dropout(drop)\n\n    **def** forward(self, x): \n        **return** self.drop(self.bn(F.relu(self.conv(x))))\n\n**def** flatten_conv(x,k):\n    bs,nf,gx,gy = x.size()\n    x = x.permute(0,2,3,1).contiguous()\n    **return** x.view(bs,-1,nf//k)**class** **OutConv**(nn.Module):\n    **def** __init__(self, k, nin, bias):\n        super().__init__()\n        self.k = k\n        self.oconv1 = nn.Conv2d(nin, (len(id2cat)+1)*k, 3, \n                                padding=1)\n        self.oconv2 = nn.Conv2d(nin, 4*k, 3, padding=1)\n        self.oconv1.bias.data.zero_().add_(bias)\n\n    **def** forward(self, x):\n        **return** [flatten_conv(self.oconv1(x), self.k),\n                flatten_conv(self.oconv2(x), self.k)]**class** **SSD_Head**(nn.Module):\n    **def** __init__(self, k, bias):\n        super().__init__()\n        self.drop = nn.Dropout(0.25)\n        self.sconv0 = StdConv(512,256, stride=1)\n        self.sconv2 = StdConv(256,256)\n        self.out = OutConv(k, 256, bias)\n\n    **def** forward(self, x):\n        x = self.drop(F.relu(x))\n        x = self.sconv0(x)\n        x = self.sconv2(x)\n        **return** self.out(x)\n\nhead_reg4 = SSD_Head(k, -3.)\nmodels = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\nlearn = ConvLearner(md, models)\nlearn.opt_fn = optim.Adam\n```", "```py\nx,y = next(iter(md.val_dl))\nx,y = V(x),V(y)\nlearn.model.eval()\nbatch = learn.model(x)\nb_clas,b_bb = batch\nb_clas.size(),b_bb.size()*(torch.Size([64, 16, 21]), torch.Size([64, 16, 4]))*\n```", "```py\nidx=7\nb_clasi = b_clas[idx]\nb_bboxi = b_bb[idx]\nima=md.val_ds.ds.denorm(to_np(x))[idx]\nbbox,clas = get_y(y[0][idx], y[1][idx])\nbbox,clas*(Variable containing:\n  0.6786  0.4866  0.9911  0.6250\n  0.7098  0.0848  0.9911  0.5491\n  0.5134  0.8304  0.6696  0.9063\n [torch.cuda.FloatTensor of size 3x4 (GPU 0)], Variable containing:\n   8\n  10\n  17\n [torch.cuda.LongTensor of size 3 (GPU 0)])*\n```", "```py\n**def** torch_gt(ax, ima, bbox, clas, prs=**None**, thresh=0.4):\n    **return** show_ground_truth(ax, ima, to_np((bbox*224).long()),\n         to_np(clas), \n         to_np(prs) **if** prs **is** **not** **None** **else** **None**, thresh)fig, ax = plt.subplots(figsize=(7,7))\ntorch_gt(ax, ima, bbox, clas)\n```", "```py\nfig, ax = plt.subplots(figsize=(7,7))\ntorch_gt(ax, ima, anchor_cnr, b_clasi.max(1)[1])\n```", "```py\nanchors*Variable containing:\n 0.1250  0.1250  0.2500  0.2500\n 0.1250  0.3750  0.2500  0.2500\n 0.1250  0.6250  0.2500  0.2500\n 0.1250  0.8750  0.2500  0.2500\n 0.3750  0.1250  0.2500  0.2500\n 0.3750  0.3750  0.2500  0.2500\n 0.3750  0.6250  0.2500  0.2500\n 0.3750  0.8750  0.2500  0.2500\n 0.6250  0.1250  0.2500  0.2500\n 0.6250  0.3750  0.2500  0.2500\n 0.6250  0.6250  0.2500  0.2500\n 0.6250  0.8750  0.2500  0.2500\n 0.8750  0.1250  0.2500  0.2500\n 0.8750  0.3750  0.2500  0.2500\n 0.8750  0.6250  0.2500  0.2500\n 0.8750  0.8750  0.2500  0.2500\n[torch.cuda.FloatTensor of size 16x4 (GPU 0)]*\n```", "```py\noverlaps = jaccard(bbox.data, anchor_cnr.data)\noverlapsColumns 0 to 7   \n0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000    0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000 Columns 8 to 15   \n0.0000  0.0091 0.0922  0.0000  0.0000  0.0315  0.3985  0.0000  0.0356  0.0549 0.0103  0.0000  0.2598  0.4538  0.0653  0.0000  0.0000  0.0000 0.0000  0.1897  0.0000  0.0000  0.0000  0.0000 [torch.cuda.FloatTensor of size 3x16 (GPU 0)]\n```", "```py\noverlaps.max(1)*(\n  0.3985\n  0.4538\n  0.1897\n [torch.cuda.FloatTensor of size 3 (GPU 0)], \n  14\n  13\n  11\n [torch.cuda.LongTensor of size 3 (GPU 0)])*\n```", "```py\noverlaps.max(0)*(\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0356\n  0.0549\n  0.0922\n  0.1897\n  0.2598\n  0.4538\n  0.3985\n  0.0000\n [torch.cuda.FloatTensor of size 16 (GPU 0)], \n  0\n  0\n  0\n  0\n  0\n  0\n  0\n  0\n  1\n  1\n  0\n  2\n  1\n  1\n  0\n  0\n [torch.cuda.LongTensor of size 16 (GPU 0)])*\n```", "```py\ngt_overlap,gt_idx = map_to_ground_truth(overlaps)\ngt_overlap,gt_idx*(\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0000\n  0.0356\n  0.0549\n  0.0922\n  1.9900\n  0.2598\n  1.9900\n  1.9900\n  0.0000\n [torch.cuda.FloatTensor of size 16 (GPU 0)], \n  0\n  0\n  0\n  0\n  0\n  0\n  0\n  0\n  1\n  1\n  0\n  2\n  1\n  1\n  0\n  0\n [torch.cuda.LongTensor of size 16 (GPU 0)])*\n```", "```py\ngt_clas = clas[gt_idx]; gt_clas*Variable containing:\n  8\n  8\n  8\n  8\n  8\n  8\n  8\n  8\n 10\n 10\n  8\n 17\n 10\n 10\n  8\n  8\n[torch.cuda.LongTensor of size 16 (GPU 0)]*\n```", "```py\nthresh = 0.5\npos = gt_overlap > thresh\npos_idx = torch.nonzero(pos)[:,0]\nneg_idx = torch.nonzero(1-pos)[:,0]\npos_idx *11\n 13\n 14\n[torch.cuda.LongTensor of size 3 (GPU 0)]*\n```", "```py\ngt_clas[1-pos] = len(id2cat)\n[id2cat[o] **if** o<len(id2cat) **else** 'bg' **for** o **in** gt_clas.data]*['bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'bg',\n 'sofa',\n 'bg',\n 'diningtable',\n 'chair',\n 'bg']*\n```", "```py\ngt_bbox = bbox[gt_idx]\nloc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\nclas_loss  = F.cross_entropy(b_clasi, gt_clas)\nloc_loss,clas_loss*(Variable containing:\n 1.00000e-02 *\n   6.5887\n [torch.cuda.FloatTensor of size 1 (GPU 0)], Variable containing:\n  1.0331\n [torch.cuda.FloatTensor of size 1 (GPU 0)])*\n```", "```py\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\n**for** idx,ax **in** enumerate(axes.flat):\n    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    ima=md.val_ds.ds.denorm(to_np(x))[idx]\n    bbox,clas = get_y(bbox,clas); bbox,clas\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], \n             b_clas[idx].max(1)[0].sigmoid(), 0.01)\nplt.tight_layout()\n```", "```py\n**def** actn_to_bb(actn, anchors):\n    actn_bbs = torch.tanh(actn)\n    actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]\n    actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]\n    **return** hw2corners(actn_centers, actn_hw)\n```", "```py\n**class** **BCE_Loss**(nn.Module):\n    **def** __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n\n    **def** forward(self, pred, targ):\n        t = one_hot_embedding(targ, self.num_classes+1)\n        t = V(t[:,:-1].contiguous())*#.cpu()*\n        x = pred[:,:-1]\n        w = self.get_weight(x,t)\n        **return** F.binary_cross_entropy_with_logits(x, t, w, \n                            size_average=**False**)/self.num_classes\n\n    **def** get_weight(self,x,t): **return** **None**\n```", "```py\n**def** ssd_1_loss(b_c,b_bb,bbox,clas,print_it=**False**):\n    bbox,clas = get_y(bbox,clas)\n    a_ic = actn_to_bb(b_bb, anchors)\n    overlaps = jaccard(bbox.data, anchor_cnr.data)\n    gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)\n    gt_clas = clas[gt_idx]\n    pos = gt_overlap > 0.4\n    pos_idx = torch.nonzero(pos)[:,0]\n    gt_clas[1-pos] = len(id2cat)\n    gt_bbox = bbox[gt_idx]\n    loc_loss = ((a_ic[pos_idx] - gt_bbox[pos_idx]).abs()).mean()\n    clas_loss  = loss_f(b_c, gt_clas)\n    **return** loc_loss, clas_loss\n\n**def** ssd_loss(pred,targ,print_it=**False**):\n    lcs,lls = 0.,0.\n    **for** b_c,b_bb,bbox,clas **in** zip(*pred,*targ):\n        loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)\n        lls += loc_loss\n        lcs += clas_loss\n    **if** print_it: print(f'loc: **{lls.data[0]}**, clas: **{lcs.data[0]}**')\n    **return** lls+lcs\n```", "```py\n**def** get_y(bbox,clas):\n    bbox = bbox.view(-1,4)/sz\n    bb_keep = ((bbox[:,2]-bbox[:,0])>0).nonzero()[:,0]\n    **return** bbox[bb_keep],clas[bb_keep]\n```", "```py\nlearn.crit = ssd_loss\nlr = 3e-3\nlrs = np.array([lr/100,lr/10,lr])learn.lr_find(lrs/1000,1.)\nlearn.sched.plot(1)*epoch      trn_loss   val_loss                            \n    0      44.232681  21476.816406*\n```", "```py\nlearn.lr_find(lrs/1000,1.)\nlearn.sched.plot(1)*epoch      trn_loss   val_loss                            \n    0      86.852668  32587.789062*\n```", "```py\nlearn.fit(lr, 1, cycle_len=5, use_clr=(20,10))*epoch      trn_loss   val_loss                            \n    0      45.570843  37.099854 \n    1      37.165911  32.165031                           \n    2      33.27844   30.990122                           \n    3      31.12054   29.804482                           \n    4      29.305789  28.943184**[28.943184]*learn.fit(lr, 1, cycle_len=5, use_clr=(20,10))*epoch      trn_loss   val_loss                            \n    0      43.726979  33.803085 \n    1      34.771754  29.012939                           \n    2      30.591864  27.132868                           \n    3      27.896905  26.151638                           \n    4      25.907382  25.739273**[25.739273]*learn.save('0')learn.load('0')\n```", "```py\nanc_grids = [4, 2, 1]\nanc_zooms = [0.75, 1., 1.3]\nanc_ratios = [(1., 1.), (1., 0.5), (0.5, 1.)]\n\nanchor_scales = [(anz*i,anz*j) **for** anz **in** anc_zooms \n                                    **for** (i,j) **in** anc_ratios]\nk = len(anchor_scales)\nanc_offsets = [1/(o*2) **for** o **in** anc_grids]anc_x = np.concatenate([np.repeat(np.linspace(ao, 1-ao, ag), ag)\n                        **for** ao,ag **in** zip(anc_offsets,anc_grids)])\nanc_y = np.concatenate([np.tile(np.linspace(ao, 1-ao, ag), ag)\n                        **for** ao,ag **in** zip(anc_offsets,anc_grids)])\nanc_ctrs = np.repeat(np.stack([anc_x,anc_y], axis=1), k, axis=0)anc_sizes = np.concatenate([np.array([[o/ag,p/ag] \n              **for** i **in** range(ag*ag) **for** o,p **in** anchor_scales])\n                 **for** ag **in** anc_grids])\ngrid_sizes = V(np.concatenate([np.array([ 1/ag \n              **for** i **in** range(ag*ag) **for** o,p **in** anchor_scales])\n                  **for** ag **in** anc_grids]), \n                      requires_grad=**False**).unsqueeze(1)\nanchors = V(np.concatenate([anc_ctrs, anc_sizes], axis=1), \n              requires_grad=**False**).float()\nanchor_cnr = hw2corners(anchors[:,:2], anchors[:,2:])\n```", "```py\ndrop=0.4\n\n**class** **SSD_MultiHead**(nn.Module):\n    **def** __init__(self, k, bias):\n        super().__init__()\n        self.drop = nn.Dropout(drop)\n        self.sconv0 = StdConv(512,256, stride=1, drop=drop)\n        self.sconv1 = StdConv(256,256, drop=drop)\n        self.sconv2 = StdConv(256,256, drop=drop)\n        self.sconv3 = StdConv(256,256, drop=drop)\n        self.out1 = OutConv(k, 256, bias)\n        self.out2 = OutConv(k, 256, bias)\n        self.out3 = OutConv(k, 256, bias)\n\n    **def** forward(self, x):\n        x = self.drop(F.relu(x))\n        x = self.sconv0(x)\n        x = self.sconv1(x)\n        o1c,o1l = self.out1(x)\n        x = self.sconv2(x)\n        o2c,o2l = self.out2(x)\n        x = self.sconv3(x)\n        o3c,o3l = self.out3(x)\n        **return** [torch.cat([o1c,o2c,o3c], dim=1),\n                torch.cat([o1l,o2l,o3l], dim=1)]\n\nhead_reg4 = SSD_MultiHead(k, -4.)\nmodels = ConvnetBuilder(f_model, 0, 0, 0, custom_head=head_reg4)\nlearn = ConvLearner(md, models)\nlearn.opt_fn = optim.Adam\n```", "```py\nlearn.crit = ssd_loss\nlr = 1e-2\nlrs = np.array([lr/100,lr/10,lr])learn.lr_find(lrs/1000,1.)\nlearn.sched.plot(n_skip_end=2)\n```", "```py\nlearn.fit(lrs, 1, cycle_len=4, use_clr=(20,8))*epoch      trn_loss   val_loss                            \n    0      15.124349  15.015433 \n    1      13.091956  10.39855                            \n    2      11.643629  9.4289                              \n    3      10.532467  8.822998**[8.822998]*learn.save('tmp')learn.freeze_to(-2)\nlearn.fit(lrs/2, 1, cycle_len=4, use_clr=(20,8))*epoch      trn_loss   val_loss                            \n    0      9.821056   10.335152 \n    1      9.419633   11.834093                           \n    2      8.78818    7.907762                            \n    3      8.219976   7.456364**[7.4563637]*x,y = next(iter(md.val_dl))\ny = V(y)\nbatch = learn.model(V(x))\nb_clas,b_bb = batch\nx = to_np(x)\n\nfig, axes = plt.subplots(3, 4, figsize=(16, 12))\n**for** idx,ax **in** enumerate(axes.flat):\n    ima=md.val_ds.ds.denorm(x)[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    torch_gt(ax, ima, a_ic, b_clas[idx].max(1)[1], \n             b_clas[idx].max(1)[0].sigmoid(), **0.2**)\nplt.tight_layout()\n```", "```py\n**class** **BCE_Loss**(nn.Module):\n    **def** __init__(self, num_classes):\n        super().__init__()\n        self.num_classes = num_classes\n\n    **def** forward(self, pred, targ):\n        t = one_hot_embedding(targ, self.num_classes+1)\n        t = V(t[:,:-1].contiguous())*#.cpu()*\n        x = pred[:,:-1]\n        w = self.get_weight(x,t)\n        **return** F.binary_cross_entropy_with_logits(x, t, w, \n                          size_average=**False**)/self.num_classes\n\n    **def** get_weight(self,x,t): **return** **None**\n```", "```py\n**class** **FocalLoss**(BCE_Loss):\n    **def** get_weight(self,x,t):\n        alpha,gamma = 0.25,2.\n        p = x.sigmoid()\n        pt = p*t + (1-p)*(1-t)\n        w = alpha*t + (1-alpha)*(1-t)\n        **return** w * (1-pt).pow(gamma)\n```", "```py\nlearn.lr_find(lrs/1000,1.)\nlearn.sched.plot(n_skip_end=2)\n```", "```py\nlearn.fit(lrs, 1, cycle_len=10, use_clr=(20,10))*epoch      trn_loss   val_loss                            \n    0      24.263046  28.975235 \n    1      20.459562  16.362392                           \n    2      17.880827  14.884829                           \n    3      15.956896  13.676485                           \n    4      14.521345  13.134197                           \n    5      13.460941  12.594139                           \n    6      12.651842  12.069849                           \n    7      11.944972  11.956457                           \n    8      11.385798  11.561226                           \n    9      10.988802  11.362164**[11.362164]*learn.save('fl0')\nlearn.load('fl0')learn.freeze_to(-2)\nlearn.fit(lrs/4, 1, cycle_len=10, use_clr=(20,10))*epoch      trn_loss   val_loss                            \n    0      10.871668  11.615532 \n    1      10.908461  11.604334                           \n    2      10.549796  11.486127                           \n    3      10.130961  11.088478                           \n    4      9.70691    10.72144                            \n    5      9.319202   10.600481                           \n    6      8.916653   10.358334                           \n    7      8.579452   10.624706                           \n    8      8.274838   10.163422                           \n    9      7.994316   10.108068**[10.108068]*learn.save('drop4')\nlearn.load('drop4')plot_results(0.75)\n```", "```py\n**def** nms(boxes, scores, overlap=0.5, top_k=100):\n    keep = scores.new(scores.size(0)).zero_().long()\n    **if** boxes.numel() == 0: **return** keep\n    x1 = boxes[:, 0]\n    y1 = boxes[:, 1]\n    x2 = boxes[:, 2]\n    y2 = boxes[:, 3]\n    area = torch.mul(x2 - x1, y2 - y1)\n    v, idx = scores.sort(0)  *# sort in ascending order*\n    idx = idx[-top_k:]  *# indices of the top-k largest vals*\n    xx1 = boxes.new()\n    yy1 = boxes.new()\n    xx2 = boxes.new()\n    yy2 = boxes.new()\n    w = boxes.new()\n    h = boxes.new()\n\n    count = 0\n    **while** idx.numel() > 0:\n        i = idx[-1]  *# index of current largest val*\n        keep[count] = i\n        count += 1\n        **if** idx.size(0) == 1: **break**\n        idx = idx[:-1]  *# remove kept element from view*\n        *# load bboxes of next highest vals*\n        torch.index_select(x1, 0, idx, out=xx1)\n        torch.index_select(y1, 0, idx, out=yy1)\n        torch.index_select(x2, 0, idx, out=xx2)\n        torch.index_select(y2, 0, idx, out=yy2)\n        *# store element-wise max with next highest score*\n        xx1 = torch.clamp(xx1, min=x1[i])\n        yy1 = torch.clamp(yy1, min=y1[i])\n        xx2 = torch.clamp(xx2, max=x2[i])\n        yy2 = torch.clamp(yy2, max=y2[i])\n        w.resize_as_(xx2)\n        h.resize_as_(yy2)\n        w = xx2 - xx1\n        h = yy2 - yy1\n        *# check sizes of xx1 and xx2.. after each iteration*\n        w = torch.clamp(w, min=0.0)\n        h = torch.clamp(h, min=0.0)\n        inter = w*h\n        *# IoU = i / (area(a) + area(b) - i)*\n        rem_areas = torch.index_select(area, 0, idx)  \n        *# load remaining areas)*\n        union = (rem_areas - inter) + area[i]\n        IoU = inter/union  *# store result in iou*\n        *# keep only elements with an IoU <= overlap*\n        idx = idx[IoU.le(overlap)]\n    **return** keep, count**def** show_nmf(idx):\n    ima=md.val_ds.ds.denorm(x)[idx]\n    bbox,clas = get_y(y[0][idx], y[1][idx])\n    a_ic = actn_to_bb(b_bb[idx], anchors)\n    clas_pr, clas_ids = b_clas[idx].max(1)\n    clas_pr = clas_pr.sigmoid()\n\n    conf_scores = b_clas[idx].sigmoid().t().data\n\n    out1,out2,cc = [],[],[]\n    **for** cl **in** range(0, len(conf_scores)-1):\n        c_mask = conf_scores[cl] > 0.25\n        **if** c_mask.sum() == 0: **continue**\n        scores = conf_scores[cl][c_mask]\n        l_mask = c_mask.unsqueeze(1).expand_as(a_ic)\n        boxes = a_ic[l_mask].view(-1, 4)\n        ids, count = nms(boxes.data, scores, 0.4, 50)\n        ids = ids[:count]\n        out1.append(scores[ids])\n        out2.append(boxes.data[ids])\n        cc.append([cl]*count)\n    cc = T(np.concatenate(cc))\n    out1 = torch.cat(out1)\n    out2 = torch.cat(out2)\n\n    fig, ax = plt.subplots(figsize=(8,8))\n    torch_gt(ax, ima, out2, cc, out1, 0.1)**for** i **in** range(12): show_nmf(i)\n```"]