- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:52:57'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:52:57
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2107.05599] Active Divergence with Generative Deep Learning - A Survey and
    Taxonomy'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2107.05599] 利用生成深度学习进行主动分歧 - 调查与分类'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2107.05599](https://ar5iv.labs.arxiv.org/html/2107.05599)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2107.05599](https://ar5iv.labs.arxiv.org/html/2107.05599)
- en: Active Divergence with Generative Deep Learning - A Survey and Taxonomy
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 利用生成深度学习进行主动分歧 - 调查与分类
- en: Terence Broad ^(1, 2), Sebastian Berns ³, Simon Colton ^(3, 4)    Mick Grierson ²
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Terence Broad ^(1, 2), Sebastian Berns ³, Simon Colton ^(3, 4)    Mick Grierson ²
- en: ¹ Department of Computing, Goldsmiths, University of London, UK
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: ¹ 伦敦大学金史密斯学院计算系，英国
- en: ² Creative Computing Institute, University of The Arts London, UK
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: ² 伦敦艺术大学创意计算研究所，英国
- en: ³ School of Electronic Engineering and Computer Science, Queen Mary University
    of London, UK
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: ³ 伦敦大学玛丽女王学院电子工程与计算机科学学院，英国
- en: ⁴ SensiLab, Faculty of IT, Monash University, Melbourne, Australia
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: ⁴ 澳大利亚莫纳什大学信息技术学院SensiLab
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Generative deep learning systems offer powerful tools for artefact generation,
    given their ability to model distributions of data and generate high-fidelity
    results. In the context of computational creativity, however, a major shortcoming
    is that they are unable to explicitly diverge from the training data in creative
    ways and are limited to fitting the target data distribution. To address these
    limitations, there have been a growing number of approaches for optimising, hacking
    and rewriting these models in order to actively diverge from the training data.
    We present a taxonomy and comprehensive survey of the state of the art of *active
    divergence* techniques, highlighting the potential for computational creativity
    researchers to advance these methods and use deep generative models in truly creative
    systems.
  id: totrans-13
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 生成深度学习系统提供了强大的工具来生成艺术品，鉴于它们能够建模数据分布并生成高保真结果。然而，在计算创意的背景下，一个主要的缺陷是它们无法以创造性的方式明确地偏离训练数据，且仅限于拟合目标数据分布。为了克服这些限制，越来越多的方法被提出，以优化、破解和重写这些模型，以便主动偏离训练数据。我们展示了*主动分歧*技术的分类法和综合调查，突出了计算创意研究者在推进这些方法并在真正创造性的系统中使用深度生成模型的潜力。
- en: Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 介绍
- en: Generative deep learning methods, and in particular deep generative models,
    have become very powerful at producing high quality artefacts and have garnered
    a huge amount of interest in machine learning, computer graphics and audio signal
    processing communities. In addition, because they are capable of producing artefacts
    of high cultural value, they are also of interest to artists and for the development
    of creativity support tools.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 生成深度学习方法，特别是深度生成模型，已在生成高质量艺术品方面变得非常强大，并在机器学习、计算机图形学和音频信号处理领域引起了极大关注。此外，由于它们能够生成具有高文化价值的艺术品，它们也受到艺术家和创意支持工具开发者的关注。
- en: One of the main goals of researchers in computational creativity and by artists
    and others using generative deep learning systems, is to find ways to get generative
    models to produce novel outcomes that diverge from the training data. In some
    respects, attempting to create a generative model that does not model the training
    data is an oxymoron, as by definition a generative model must model some existing
    data distribution. However, generative neural networks are powerful tools with
    the unique capability of learning to render entire distributions of complex high
    dimensional data with ever-increasing fidelity. It is no wonder then, that there
    have been a large number of approaches developed in order tweak, manipulate and
    optimise these models in order to actively diverge from the training data, or
    any existing data distribution.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 计算创意领域的研究者以及使用生成深度学习系统的艺术家等的主要目标之一是寻找方法使生成模型产生与训练数据不同的新颖结果。在某些方面，试图创建一个不建模训练数据的生成模型是一种矛盾，因为生成模型的定义就是建模某种现有数据分布。然而，生成神经网络是强大的工具，具有学习呈现复杂高维数据的整个分布的独特能力，且这种能力不断提高。因此，不难理解，为了主动偏离训练数据或任何现有数据分布，已经开发了大量方法来调整、操控和优化这些模型。
- en: The term active divergence (Berns and Colton, [2020](#bib.bib8)) describes methods
    for utilising generative deep learning in ways that do not simply reproduce the
    training data. Methods for this have been developed within the field of computational
    creativity, but also a goal commonly shared by neighbouring communities, such
    as those building creativity support tools and artists, researchers and other
    pracitioners publishing and sharing results under the ‘CreativeAI’ banner (Cook
    and Colton, [2018](#bib.bib23)). This paper offers a comprehensive survey and
    taxonomy of the state of the art with respect to methods developed across these
    fields.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: “活跃发散”一词（Berns 和 Colton，[2020](#bib.bib8)）描述了利用生成深度学习的方法，这些方法不仅仅是复制训练数据。这些方法在计算创造力领域内得到了发展，同时也是相邻社区普遍共享的目标，如那些构建创造力支持工具的社区，以及艺术家、研究人员和其他从业者在“CreativeAI”旗帜下发布和分享成果的群体（Cook
    和 Colton，[2018](#bib.bib23)）。本文提供了对这些领域中发展起来的最先进方法的全面调查和分类。
- en: Additionally, this paper outlines some of the possible applications, and outlines
    key opportunities for computational creativity research to advance active divergence
    methods beyond tricks and hacks, towards more automated and autonomous creative
    systems. Many of the research directions presented are still very nascent and
    a lot of work is still to be done in regards to evaluating and benchmarking these
    methods. Better ways of measuring and evaluating these techniques will go a long
    way to advancing understanding and allowing more creative responsibility to be
    handed over to the systems. The comparative account of the methods, use-cases
    and future research directions for active divergence is offered as a resource
    to inform future research in generative deep learning tools and systems that take
    creative leaps beyond reproducing the training data.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，本文概述了一些可能的应用，并指出了计算创造力研究在超越技巧和窍门方面，向更自动化和自主的创造性系统发展的关键机会。许多提出的研究方向仍处于非常初步的阶段，评估和基准测试这些方法的工作仍然任重道远。更好的测量和评估这些技术的方法将有助于推进理解，并使更多创造性责任转交给系统。对活跃发散方法的比较账户，包括方法、应用案例和未来研究方向，作为资源提供，以指导生成深度学习工具和系统的未来研究，这些工具和系统在创造性飞跃方面超越了训练数据的复制。
- en: Technical Overview
  id: totrans-19
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 技术概述
- en: 'While not all generative models rely on generative deep learning, we refer
    here to those that build on artificial neural networks¹¹1For further reading,
    a comprehensive overview of generative models is given in Harshvardhan et al.
    ([2020](#bib.bib37)).. Given a data distribution $P$, a generative model will
    model an approximate distribution $P^{\prime}$. The parameters for the approximate
    distribution can be learned by an artificial neural network. This learning task
    is tackled differently by different architectures and training schemes. E.g. autoencoders
    (Rumelhart, Hinton, and Williams, [1985](#bib.bib67)) and variational autoencoders
    (VAE) (Kingma and Welling, [2013](#bib.bib48); Rezende, Mohamed, and Wierstra,
    [2014](#bib.bib65)) learn to approximate the data through reconstruction via an
    encoding and a decoding network, while generative adversarial networks (GAN) (Goodfellow
    et al., [2014](#bib.bib32)) consists of a generator that is guided by a discriminating
    network. In most cases, the network learns a mapping from a lower-dimensional
    latent distribution $X$ to the complex high-dimensional feature space of a domain.
    The model, thus, generates a sample $p^{\prime}$ given an input vector $x$ which
    should resemble samples drawn from the target distribution $P$. In the simplest
    case of a one layer network the generated sample $p^{\prime}$ is generated using
    the function: $p^{\prime}=\sigma(Wx+b)$ where $x$ is the input vector from the
    latent distribution $x\in X$, $\sigma$ is a non-linear activation function, $W$
    and $b$ are the learned association matrix and bias vector for generating samples
    in the approximate distribution $p^{\prime}\in P^{\prime}$. The model parameters
    $W$ and $b$, are typically learned through gradient-based optimisation process.
    In this process, a loss function will require the model to maximise the likelihood
    of the data either: (i) explicitly, as in the case of autoencoders, autoregressive
    (Frey et al., [1996](#bib.bib28)) and flow-based generative models (Dinh, Krueger,
    and Bengio, [2014](#bib.bib24)); (ii) approximately, as is the case in VAEs; (iii)
    or implicitly, as in the case of GANs. Generative models can also be conditioned
    on labelled data. In the conditional case, the generative model takes two inputs
    $x$ and $y$, where $y$ represents the class label vector. Another form of conditional
    generative models are translation models, such as pix2pix (Isola et al., [2017](#bib.bib43)),
    that takes a (high dimensional) data distribution as input $Q$ and learns a mapping
    to $P^{\prime}$ which is an approximation of the true target function $f:Q\rightarrow
    P$.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 并非所有生成模型都依赖于生成深度学习，这里我们指的是那些基于人工神经网络的模型¹¹1有关更多阅读内容，Harshvardhan等人提供了生成模型的全面概述（[2020](#bib.bib37)）。给定一个数据分布$P$，生成模型将建模一个近似分布$P^{\prime}$。这个近似分布的参数可以通过人工神经网络来学习。不同的架构和训练方案以不同的方式解决这个学习任务。例如，自动编码器（Rumelhart,
    Hinton, and Williams, [1985](#bib.bib67)）和变分自动编码器（VAE）（Kingma和Welling，[2013](#bib.bib48)；Rezende,
    Mohamed和Wierstra，[2014](#bib.bib65)）通过编码和解码网络学习对数据进行重建，从而近似数据，而生成对抗网络（GAN）（Goodfellow等人，[2014](#bib.bib32)）则由一个生成器和一个判别网络组成。在大多数情况下，网络从一个低维潜在分布$X$学习到一个复杂的高维特征空间的映射。因此，模型根据输入向量$x$生成一个样本$p^{\prime}$，这个样本应当类似于从目标分布$P$中抽取的样本。在最简单的单层网络情况下，生成的样本$p^{\prime}$使用以下函数生成：$p^{\prime}=\sigma(Wx+b)$，其中$x$是来自潜在分布$x\in
    X$的输入向量，$\sigma$是一个非线性激活函数，$W$和$b$是用于生成近似分布$p^{\prime}\in P^{\prime}$样本的学习关联矩阵和偏置向量。模型参数$W$和$b$通常通过基于梯度的优化过程来学习。在这个过程中，损失函数将要求模型最大化数据的似然性：（i）显式地，如在自动编码器、自动回归（Frey等人，[1996](#bib.bib28)）和基于流的生成模型（Dinh,
    Krueger, and Bengio，[2014](#bib.bib24)）的情况；（ii）近似地，如在VAEs的情况；（iii）或隐式地，如在GANs的情况。生成模型也可以基于标记数据进行条件生成。在条件生成的情况下，生成模型接受两个输入$x$和$y$，其中$y$表示类别标签向量。另一种形式的条件生成模型是翻译模型，如pix2pix（Isola等人，[2017](#bib.bib43)），它接受一个（高维的）数据分布作为输入$Q$，并学习一个到$P^{\prime}$的映射，该映射是对真实目标函数$f:Q\rightarrow
    P$的近似。
- en: All deep generative models, and in particular ones that generate high dimensional
    data domains like images, audio and natural language, will have some level of
    divergence $D(P||P^{\prime})\geq 0$ between the target distribution $P$ and the
    approximate distribution $P^{\prime}$, because of the complexity and stochasticity
    inherent in high dimensional data. The goal of all generative models is to minimise
    that level of divergence, by maximising the likelihood of generating the given
    data domain. Active divergence methods however, intentionally seek to create a
    new distribution $U$ that does not directly approximate a given distribution $P$,
    or resemble any other known data distribution. This is either done by seeking
    to find model parameters $W^{*}$ and $b^{*}$ (in the single layer case) that generate
    novel samples $u=\sigma(W^{*}x+b^{*})$, or by making other kinds of interventions
    to the chain of computations.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 所有深度生成模型，特别是那些生成高维数据领域（如图像、音频和自然语言）的模型，都将存在某种程度的偏差 $D(P||P^{\prime})\geq 0$，这是因为高维数据固有的复杂性和随机性。所有生成模型的目标是通过最大化生成给定数据领域的可能性来最小化这种偏差。然而，主动偏差方法则有意地寻求创建一个新的分布
    $U$，该分布既不直接近似给定的分布 $P$，也不像其他已知的数据分布。这可以通过寻找模型参数 $W^{*}$ 和 $b^{*}$（在单层情况下）来生成新样本
    $u=\sigma(W^{*}x+b^{*})$，或者通过对计算链进行其他干预来实现。
- en: Survey of Active Divergence Methods
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 主动偏差方法的调查
- en: We present a comprehensive overview and taxonomy of the state of the art in
    methods for achieving active divergence. In this survey, we will use the term
    divergence in the statistical sense, as being the distance (or difference) between
    two distributions. There are other definitions of divergence relevant to research
    in creativity, such as Guildford’s dimensions of divergent thought (Hocevar, [1980](#bib.bib41)).
    While there are some parallels that can be drawn between some of the active divergence
    methods, and theories of divergent thinking; for the clarity of technical exposition,
    we will be sticking strictly to the statistical definition of divergence in this
    overview of active divergence methods.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提供了一个关于实现主动偏差的前沿方法的全面概述和分类。在这次调查中，我们将使用统计学中的“偏差”一词，即两个分布之间的距离（或差异）。还有其他与创造力研究相关的偏差定义，如Guildford的发散思维维度（Hocevar,
    [1980](#bib.bib41)）。尽管一些主动偏差方法与发散思维理论之间可以找到某些相似之处，但为了技术阐述的清晰性，我们将严格按照统计定义来概述主动偏差方法。
- en: '![Refer to caption](img/dc24f82ecaa5752f1e504828a548b981.png)'
  id: totrans-24
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dc24f82ecaa5752f1e504828a548b981.png)'
- en: (a) divergent fine-tuning
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 发散微调
- en: '![Refer to caption](img/2c104b3d541299f56894a071f736b782.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2c104b3d541299f56894a071f736b782.png)'
- en: (b) chaining models
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 链式模型
- en: '![Refer to caption](img/4176049c1ec175d866618d949babb6dd.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4176049c1ec175d866618d949babb6dd.png)'
- en: (c) network bending
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 网络弯曲
- en: '![Refer to caption](img/77d39e52b709028551344a153a0ed76e.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/77d39e52b709028551344a153a0ed76e.png)'
- en: (d) network blending
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 网络混合
- en: 'Figure 1: Some visual examples of results produced using various active divergence
    methods. (a) An image from Strange Fruit by Mal Som (Som, [2020](#bib.bib79)),
    that was created by fine-tuning a pre-trained model towards a continously shifting
    domain. (b) A frame from the video artwork You Are Here by Derrick Schultz (Schultz,
    [2020b](#bib.bib73)), created by chaining multiple models and technniques including:
    a custom GAN, network bending, image translation, and super-resolution. (c) An
    image from the series of artworks Teratome (Broad, [2020b](#bib.bib17)), that
    was created using network bending techniques (Broad, Leymarie, and Grierson, [2021](#bib.bib15)).
    (d) An example of network blending (Pinkney and Adler, [2020](#bib.bib58)), where
    the image provided has been generated from a model which combines the photorealistic
    textures from the FFHQ StyleGAN2 model, but the spatial structure from a model
    trained on an Ukiyo-e dataset (Pinkney, [2020a](#bib.bib59)). All images are reproduced
    with permission from their respective creators.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '图 1：使用各种主动分歧方法生成的结果的一些视觉示例。（a）由 Mal Som（Som，[2020](#bib.bib79)）创作的《奇异果实》中的一张图像，通过对经过预训练模型进行微调以获得一个不断变化的领域。(b)
    Derrick Schultz（Schultz，[2020b](#bib.bib73)）的视频艺术作品《你在这里》，通过链接多个模型和技术，包括: 一个自定义的
    GAN，网络弯曲，图像翻译和超分辨率。(c) 艺术作品系列《畸胎瘤》（Broad，[2020b](#bib.bib17)）中的一张图像，通过网络弯曲技术（Broad，Leymarie
    和 Grierson，[2021](#bib.bib15)）创建。(d) 网络混合的示例（Pinkney 和 Adler，[2020](#bib.bib58)），其中提供的图像是从一个模型生成的，该模型结合了来自
    FFHQ StyleGAN2 模型的照片级纹理和来自在浮世绘数据集上训练的模型的空间结构（Pinkney，[2020a](#bib.bib59)）。所有图像均经过其各自创建者的许可复制。'
- en: Novelty search over learned representations
  id: totrans-33
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 学习表示中的新颖性搜索
- en: Methods in this category take existing generative models trained using standard
    maximum likelihood regimes and then specifically search for the subset of learned
    representations that do not resemble the training data by systematically sampling
    from the model²²2An overview of methods for sampling generative models is given
    in White ([2016](#bib.bib84)).. Taking account of the fact that any approximate
    distribution $P^{\prime}$ will be somewhat divergent from the true distribution
    $P$, these methods seek to find the subset $U$ of the approximate distribution
    which is not contained in the true distribution $U\subset P^{\prime}\wedge U\not\subset
    P$. Kazakçı, Mehdi, and Kégl ([2016](#bib.bib46)) present an algorithm for searching
    for novelty in the latent space of a sparse autoencoder trained on the MNIST dataset
    (LeCun et al., [1998](#bib.bib51)). They start by creating a sample of random
    noise and by using a Markov chain monte carlo (MCMC) method of iteratively re-encoding
    the sample through the encoder, then refining the sample until it produces a stable
    representation. They use this approach to map out all the representations the
    model can generate, then perform k-means clustering on the latent space encoding
    of these representations. By disregarding clusters that correspond to real digits,
    they are left with clusters of representations of digits that do not exist in
    the original data distribution. It has been argued that these ‘spurious samples’
    are the inevitable outcome of generative models that learn to generalise from
    given data distributions (Kégl, Cherti, and Kazakçı, [2018](#bib.bib47)) and that
    there is a trade off between the ability to generalise to every mode in the dataset
    and the ratio of spurious samples in the resulting distribution.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 此类方法采用使用标准极大似然率进行训练的现有生成模型，并具体搜索不与训练数据相似的学习表示的子集，方法是通过从模型中系统地对样本进行采样²²2有关采样生成模型的方法的概述请参见
    White（[2016](#bib.bib84)）.. 考虑到任何近似分布$P^{\prime}$与真实分布$P$之间会有一定的差异，这些方法试图找到近似分布的子集$U$，该子集不包含在真实分布中$U\subset
    P^{\prime}\wedge U\not\subset P$。Kazakçı，Mehdi 和 Kégl（[2016](#bib.bib46)）提出了一种在
    MNIST 数据集（LeCun 等，[1998](#bib.bib51)）上稀疏自编码器的潜在空间中搜索新颖性的算法。他们首先创建一个随机噪声样本，并使用
    Markov chain monte carlo (MCMC) 方法通过编码器迭代地重新对样本进行编码，然后对样本进行优化，直到产生稳定的表示。他们使用这种方法来映射模型能够生成的所有表示，并在这些表示的潜在空间编码上执行
    k-means 聚类。通过忽略与真实数字对应的簇，他们得到了不在原始数据分布中存在的数字表示簇。有人认为，这些“虚假样本”是从给定数据分布中学习泛化的生成模型的不可避免的结果（Kégl，Cherti
    和 Kazakçı，[2018](#bib.bib47)），并且在生成分布中 spurious 样本的比例和对数据集中每个模式进行泛化的能力之间存在权衡。
- en: Novelty generation from an inspiring set
  id: totrans-35
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从激发性集合中生成新颖性
- en: The methods in this section train a model from scratch using a training dataset,
    but do not attempt to model the data directly, rather using it as reference material
    to draw inspiration from. We therefore refer to this training set (the given distribution
    $P$) as the inspiring set (Ritchie, [2007](#bib.bib66)).
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 本节的方法从头开始使用训练数据集训练模型，但并不直接对数据进行建模，而是将其作为参考材料以获得灵感。因此，我们将该训练集（给定的分布 $P$）称为启发集（Ritchie,
    [2007](#bib.bib66)）。
- en: An approach for novel glyph generation utilises a class-conditional generative
    model trained on the MNIST dataset (LeCun et al., [1998](#bib.bib51)), but in
    this case they train the model with ‘hold-out classes’ (Cherti, Kégl, and Kazakçı,
    [2017](#bib.bib19)), additional classes that do not exist in the training data
    distribution. These hold-out classes can then sampled during inference, which
    encapsulate the subset $U$ of the approximate distribution $P^{\prime}$ that is
    not included in the target distribution $U\subset P^{\prime}\wedge U\not\subset
    P$. These divergent samples can then be generated directly by conditioning the
    generator with the hold-out class label, without the need for searching the latent
    space.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 一种新颖的字形生成方法利用了在 MNIST 数据集上训练的类别条件生成模型（LeCun et al., [1998](#bib.bib51)），但在这种情况下，他们使用了“保留类”（Cherti,
    Kégl, and Kazakçı, [2017](#bib.bib19)），这些额外的类在训练数据分布中不存在。这些保留类可以在推断过程中进行采样，这些采样包含了近似分布
    $P^{\prime}$ 中未包含在目标分布中的子集 $U$，即 $U\subset P^{\prime}\wedge U\not\subset P$。这些不同的样本可以通过使用保留类标签对生成器进行条件化而直接生成，无需搜索潜在空间。
- en: An approach that directly generates a new distribution $U$ from an inspiring
    set $P$ is the creative adversarial networks (CAN) algorithm (Elgammal et al.,
    [2017](#bib.bib25)). The algorithm uses the WikiArt dataset (Saleh and Elgammal,
    [2016](#bib.bib69)), a labelled dataset of paintings classified by ‘style’ (historical
    art movement). This algorithm draws inspiration from the GAN training procedure
    (Goodfellow et al., [2014](#bib.bib32)), but adapts it such that the discriminator
    has to classify real and generated samples by style, and the generator is then
    optimised to maximise the likelihood of the generated results being classified
    as ‘artworks’ (samples that fit the training distribution of existing artworks)
    but maximise their deviation from existing styles in order to produce the novel
    distribution $U$.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 从启发集 $P$ 直接生成新分布 $U$ 的一种方法是创造性对抗网络（CAN）算法（Elgammal et al., [2017](#bib.bib25)）。该算法使用
    WikiArt 数据集（Saleh and Elgammal, [2016](#bib.bib69)），这是一个按“风格”（历史艺术运动）分类的标记绘画数据集。该算法从
    GAN 训练程序（Goodfellow et al., [2014](#bib.bib32)）中获得灵感，但对其进行了调整，使得判别器必须按风格分类真实和生成样本，而生成器则被优化以最大化生成结果被分类为“艺术作品”（符合现有艺术作品训练分布的样本）的可能性，同时最大化其与现有风格的偏差，从而生成新颖的分布
    $U$。
- en: Training without data
  id: totrans-39
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 无数据训练
- en: Training a model from a random initial starting point without any training data,
    almost certainly guarantees novelty in the resulting generated distribution. Existing
    approaches to doing this all rely on the dynamics between multiple models to produce
    emergent behaviours through which novel data distributions can be generated.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 从随机初始点开始训练模型而没有任何训练数据，几乎可以确保生成的分布具有新颖性。现有的所有方法都依赖于多个模型之间的动态关系，通过这些动态关系产生新颖的数据分布。
- en: Multi-generator dynamics
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 多生成器动态
- en: Broad and Grierson ([2019a](#bib.bib12)) present an approach to training generative
    deep learning models without any training data, by using two generator networks,
    and relying on the dynamics between them for an open-ended optimisation process.
    This approach took inspiration from the GAN framework, but instead of a generator
    mimicking real data, two generators attempt to mimic each other while the discriminator
    attempts to tell them apart. In order to have some level of diversity in the final
    results, the two generators are simultaneously trying to produce more colours
    in the generated output than the other generator network, leading to the generation
    of two novel, yet closely related distributions $U$ and $V$.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: Broad 和 Grierson ([2019a](#bib.bib12)) 提出了一种在没有任何训练数据的情况下训练生成深度学习模型的方法，通过使用两个生成器网络，并依赖它们之间的动态关系进行开放式优化过程。这种方法受到
    GAN 框架的启发，但与生成器模仿真实数据不同，两生成器试图相互模仿，同时判别器则试图区分它们。为了在最终结果中获得某种程度的多样性，这两个生成器同时试图在生成的输出中产生比另一个生成器网络更多的颜色，从而生成两个新颖但紧密相关的分布
    $U$ 和 $V$。
- en: Generation via communication
  id: totrans-43
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 通过通信生成
- en: An alternative approach to generating without data uses a single generator network,
    and uses the generated distribution $U$ as a channel for communication between
    two networks, which together learn to generate and classify images that represent
    numerical and textual information from a range of existing datasets (Simon, [2019](#bib.bib77)).
    In subsequent work, by constraining the generator with a strong inductive bias
    for generating line drawings, this approach can be utilised for novel glyph generation
    (Park, [2020](#bib.bib57)).
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 一种生成数据的替代方法使用单一生成器网络，并将生成的分布$U$作为两个网络之间的通信渠道，这两个网络共同学习生成和分类表示来自一系列现有数据集的数值和文本信息的图像（Simon，[2019](#bib.bib77)）。在后续工作中，通过对生成器施加强的归纳偏置以生成线条图，这种方法可以用于生成新的字形（Park，[2020](#bib.bib57)）。
- en: Divergent fine-tuning
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: '**分歧微调**'
- en: Divergent fine-tuning methods take pre-trained models that generate an approximate
    distribution $P^{\prime}$ and fine-tune the model away from the original training
    data. This can either be done by optimising on new training data, or by using
    auxiliary models and custom loss functions. The goal being to find a new set of
    model parameters that generate a novel distribution $U$, that is significantly
    divergent from the approximate distribution $P^{\prime}$ and the original distribution
    $P$.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '**分歧微调**方法采用生成近似分布$P^{\prime}$的预训练模型，并将模型从原始训练数据中微调出来。这可以通过优化新的训练数据或使用辅助模型和自定义损失函数来完成。其目标是找到一组新的模型参数，这些参数生成一种新的分布$U$，该分布与近似分布$P^{\prime}$和原始分布$P$有显著的差异。'
- en: Cross domain training
  id: totrans-47
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**跨领域训练**'
- en: In cross domain training, transfer learning is performed to a pre-trained model
    that generates the approximate distribution $P^{\prime}$ and is then trained to
    approximate the new data distribution $Q$. This transfer learning procedure will
    eventually lead to the model learning a set of parameters that generate the approximate
    distribution $Q^{\prime}$. However, by picking an iteration of the model mid-way
    through this process, a set of parameters can be found that produced a blend between
    the two approximate distributions $P^{\prime}$ and $Q^{\prime}$, resulting in
    the producing the novel distribution $U$ (Schultz, [2020a](#bib.bib72)). This
    method, was discovered by many artists and practitioners independently, who were
    performing transfer learning with GAN models for training efficiency, but noted
    that the iterations of the model part-way through produced the most interesting,
    surprising and sometimes horrifying results (Adler, [2020](#bib.bib2); Black,
    [2020](#bib.bib10); Mariansky, [2020](#bib.bib53); Shane, [2020](#bib.bib76)).
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 在跨领域训练中，迁移学习被应用于一个预训练的模型，该模型生成近似分布$P^{\prime}$，然后该模型被训练以近似新的数据分布$Q$。这一迁移学习过程最终会使模型学习一组生成近似分布$Q^{\prime}$的参数。然而，通过选择模型在这一过程中的某个迭代步骤，可以找到一组参数，这些参数产生了两个近似分布$P^{\prime}$和$Q^{\prime}$之间的混合，进而生成新的分布$U$（Schultz，[2020a](#bib.bib72)）。这一方法被许多艺术家和从业者独立发现，他们在使用GAN模型进行迁移学习以提高训练效率时发现，模型在中途的迭代产生了最有趣、最惊讶且有时令人恐惧的结果（Adler，[2020](#bib.bib2)；Black，[2020](#bib.bib10)；Mariansky，[2020](#bib.bib53)；Shane，[2020](#bib.bib76)）。
- en: Continual domain shift
  id: totrans-49
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: '**持续领域转移**'
- en: Going beyond simply mixing two domains, one approach that gives more opportunity
    to steer the resulting distribution in the fine-tuning procedure, is to optimise
    on a domain that is continually shifting. In creating the artworks Strange Fruit
    (Som, [2020](#bib.bib79)), the artist Mal Som “iterate[s] on the dataset with
    augmenting, duplicating and looping in generated images from previous ticks” to
    steer the training of the generator model (Som, [2021](#bib.bib80)). In this process,
    the target distribution $Q_{t}$ at step $t$ may contain samples $q^{\prime}_{t-n}$
    generated from earlier iterations of the model at any previous time step $t-n$
    where $0<n<t$. Additionally, the target distribution $Q_{t}$, may no longer include
    samples, or may have duplicates of samples $q_{t-n}$ from previous iterations
    of the target distribution. Using this process, the target distribution can be
    continually shaped and guided.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 超越单纯地混合两个领域，一种可以在微调过程中提供更多调节最终分布的机会的方法是，在不断变化的领域上进行优化。在创作艺术作品《奇异果实》（Som，[2020](#bib.bib79)）时，艺术家Mal
    Som “在数据集中迭代，增强、复制并循环利用来自先前时间点的生成图像”，以指导生成器模型的训练（Som，[2021](#bib.bib80)）。在这一过程中，目标分布$Q_{t}$在步骤$t$可能包含从任何先前时间步$t-n$（其中$0<n<t$）生成的样本$q^{\prime}_{t-n}$。此外，目标分布$Q_{t}$可能不再包括样本，或可能有来自目标分布先前迭代的样本$q_{t-n}$的重复。使用这一过程，目标分布可以不断地被塑造和引导。
- en: This process of modelling a continually shifting domain often leads to the —generally
    unwanted— phenomenon of mode collapse (Thanh-Tung and Tran, [2020](#bib.bib81)).
    However, in Som’s practice, this is induced deliberately. After a model has collapsed,
    Som explores its previous iterations to find the last usable instance right before
    collapse. Som likens this practice to the artistic technique of defamiliarisation,
    where common things are presented in unfamiliar ways so audiences can gain new
    perspectives and see the world differently (Som, [2021](#bib.bib80)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 建模不断变化的领域的过程通常会导致—一般不希望的—模式崩溃现象（Thanh-Tung 和 Tran，[2020](#bib.bib81)）。然而，在Som的实践中，这是一种刻意引发的现象。在模型崩溃后，Som会探索其先前的迭代，寻找崩溃前最后一个可用的实例。Som将这一实践比作艺术技巧的陌生化，即将常见事物以陌生的方式呈现，以便观众获得新的视角，看到不同的世界（Som，[2021](#bib.bib80)）。
- en: Loss hacking
  id: totrans-52
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 损失黑客技术
- en: An alternative strategy, is to fine-tune a model without any training data.
    Instead a loss function is used that directly transforms the approximate distribution
    $P^{\prime}$ into a novel distribution $U$ without requiring any other target
    distribution. Broad, Leymarie, and Grierson ([2020](#bib.bib14)) use the frozen
    weights of the discriminator to directly optimise away from the likelihood of
    the data, by using the inverse of the adversarial loss function. This process
    reverses the normal objective of the generator to generate ‘real’ data and instead
    to generate samples that the discriminator deems to be ‘fake’. By applying this
    process to a GAN that can produce photo-realistic images of faces, this fine-tuning
    procedure crosses the uncanny valley in reverse, taking images indistinguishable
    from real images, and amplifying the uncanniness of the images before eventually
    leading to mode collapse. In a similar fashion to Som’s practice (see previous
    sub-section), one instance of the model before mode collapse was hand-selected
    and a selection of its outputs turned into the series of artworks Being Foiled
    (Broad, [2020a](#bib.bib16)).
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 一种替代策略是对没有任何训练数据的模型进行微调。相反，使用一种损失函数将近似分布$P^{\prime}$直接转化为新分布$U$，而不需要任何其他目标分布。Broad、Leymarie
    和 Grierson ([2020](#bib.bib14)) 使用对抗损失函数的逆函数，通过使用判别器的冻结权重，直接优化数据的可能性。这一过程颠倒了生成器的正常目标，从生成“真实”数据改为生成判别器认为是“虚假”的样本。通过将这一过程应用于能够生成照片级真实人脸图像的生成对抗网络（GAN），这一微调过程会在反向穿越恐怖谷的过程中，将图像从真实图像中几乎无法区分，并放大图像的不适感，最终导致模式崩溃。类似于Som的实践（见前一小节），在模式崩溃之前手动选择模型的一个实例，并将其输出转化为艺术作品系列《被击败的》（Broad，[2020a](#bib.bib16)）。
- en: Infusing external knowledge
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 注入外部知识
- en: By harnessing the learned knowledge of externally trained models, it is possible
    to fine-tune models to infuse that knowledge to transform the original domain
    data with characteristics defined using the auxiliary model. Broad and Grierson
    ([2019b](#bib.bib13)) utilise a classifier model $C_{classifier}$ trained to differentiate
    between datasets, in conjunction with the frozen weights of the discriminator
    $D_{frozen}$ to fine-tune a pre-trained GAN generator model $G$ away from the
    original distribution and towards a new local minimum defined by the loss function
    $L$. $L$ is defined as the weighted sum of the two auxiliary models $L=\alpha
    C_{classifier}(G(x))+\beta D_{frozen}(G(x))$ given the random latent vector $x$,
    and $\alpha$ and $\beta$ being the hyper-parameters defining the weightings for
    the two components of the loss function.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 通过利用外部训练模型的学习知识，可以对模型进行微调，将这些知识融入原始领域数据，并使用辅助模型定义的特征进行转换。Broad和Grierson ([2019b](#bib.bib13))
    利用一个分类器模型 $C_{classifier}$ 训练以区分数据集，并结合冻结权重的判别器 $D_{frozen}$，对预训练的GAN生成器模型 $G$
    进行微调，使其从原始分布偏离，朝向由损失函数 $L$ 定义的新局部最小值。$L$ 被定义为两个辅助模型的加权和 $L=\alpha C_{classifier}(G(x))+\beta
    D_{frozen}(G(x))$，其中随机潜在向量 $x$，以及 $\alpha$ 和 $\beta$ 是定义损失函数两个部分的超参数。
- en: The StyleGAN-NADA framework (Gal, [2021](#bib.bib29)) takes advantage of the
    external knowledge of a contrastive language–image pre-training model (CLIP) (Radford
    et al., [2021](#bib.bib63)). CLIP has been trained on billions of text and image
    pairs from the internet and provides a joint-embedding space of both images and
    text, allowing for similarity estimation of images and text prompts. In StyleGAN-NADA,
    pretrained StyleGAN2 models (Karras et al., [2020](#bib.bib45)) can be fine-tuned
    using user-specified text prompts, the CLIP model $C_{clip}$ is then used to encode
    the text prompts and the generated samples in order to provide a loss function
    where the cosine similarity $S$ between the clip encodings of the text string
    $t$ and the generated image embedding $G(x)$ given random latent $x$, can be minimised
    using the loss $L=S(C_{clip}(t),C_{clip}(G(x))$. This training procedure, guides
    the generator towards infusing characteristics from an unseen domain defined by
    the user as text prompts.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: StyleGAN-NADA 框架（Gal，[2021](#bib.bib29)）利用了对比语言–图像预训练模型（CLIP）的外部知识（Radford et
    al., [2021](#bib.bib63)）。CLIP 已经在互联网上的数十亿对文本和图像上进行了训练，提供了图像和文本的联合嵌入空间，允许对图像和文本提示进行相似度估计。在
    StyleGAN-NADA 中，预训练的 StyleGAN2 模型（Karras et al., [2020](#bib.bib45)）可以使用用户指定的文本提示进行微调，然后使用
    CLIP 模型 $C_{clip}$ 对文本提示和生成样本进行编码，以提供一个损失函数，在该函数中，可以最小化文本字符串 $t$ 的 CLIP 编码与生成图像嵌入
    $G(x)$ 之间的余弦相似度 $S$，损失函数为 $L=S(C_{clip}(t),C_{clip}(G(x))$。该训练过程引导生成器向用户定义的文本提示的未见领域中融入特征。
- en: Chaining models
  id: totrans-57
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 链接模型
- en: An approach that is widely used by artists who incorporate generative models
    into their practice, but not well documented in academic literature, is the practice
    of chaining multiple custom models trained on datasets curated by the artists.
    The ensembles used will often utilise standard unconditional generative models,
    such as GANs, in combination with other conditional generative models such as
    image-to-image translation networks, such as pix2pix (Isola et al., [2017](#bib.bib43))
    and CycleGAN (Zhu et al., [2017](#bib.bib85)), along with other approaches for
    altering the aesthetic outcomes of results such as style transfer (Gatys, Ecker,
    and Bethge, [2016](#bib.bib31)). Artists will often train many models on small
    custom datasets and test out many combinations of different models, with the aim
    of finding a configuration that produces unique and expressive results. The artist
    Helena Sarin will often chain multiple CycleGAN models into one ensemble, and
    will reuse training data during inference, as the goal of this practice “is not
    generalization, my goal is to create appealing art” (Sarin, [2018](#bib.bib70)).
    The artist Derrick Schultz draws parallels between the practice of chaining models
    and Robin Sloan’s concept of ‘flip-flopping’ (Schultz, [2021](#bib.bib74)), where
    creative outcomes can be achieved by “pushing a work of art or craft from the
    physical world to the digital world and back, often more than once” (Sloan, [2012](#bib.bib78)).
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 一种艺术家广泛使用但在学术文献中记录不多的方法是将多个在艺术家策划的数据集上训练的定制模型链式连接起来。这些使用的集成模型通常会结合标准的无条件生成模型，例如GANs，以及其他条件生成模型，如图像到图像转换网络，例如pix2pix（Isola等，[2017](#bib.bib43)）和CycleGAN（Zhu等，[2017](#bib.bib85)），还有其他改变结果美学效果的方法，如风格迁移（Gatys、Ecker和Bethge，[2016](#bib.bib31)）。艺术家通常会在小型定制数据集上训练多个模型，并测试不同模型的多种组合，旨在找到能产生独特且富有表现力结果的配置。艺术家Helena
    Sarin常常将多个CycleGAN模型链成一个集成，并在推理过程中重复使用训练数据，因为这种做法的目标“不是泛化，我的目标是创造有吸引力的艺术”（Sarin，[2018](#bib.bib70)）。艺术家Derrick
    Schultz将模型链式连接的做法与Robin Sloan的‘flip-flopping’概念（Schultz，[2021](#bib.bib74)）进行比较，在这种做法中，通过“将一件艺术品或工艺品从物理世界推向数字世界并再返回，通常不止一次”来实现创造性的成果（Sloan，[2012](#bib.bib78)）。
- en: Network bending
  id: totrans-59
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络弯曲
- en: Network bending (Broad, Leymarie, and Grierson, [2021](#bib.bib15)) is a framework
    that allows for active divergence using individual pre-trained models without
    making any changes to the weights or topology of the model. Instead, additional
    layers that implement standard image filters are inserted into the computational
    graph of a model and applied during inference to the activation maps of the convolutional
    features³³3Inserting filters into GANs was also developed independently in the
    Matlab StyleGAN playground (Pinkney, [2020c](#bib.bib61)).. As the computational
    graph of the model has been altered, the model which previously generated samples
    from the approximate distribution $P^{\prime}$, now produces novel samples from
    the new distribution $U$, without any changes being made to the parameters of
    the model. In the simplest case of a two layer model an association weight matrix
    $W_{l}$ and bias $b_{l}$ vector for each layer $l$. Which generates sample $p^{\prime}=\sigma(W_{2}(\sigma(W_{1}x+b_{1}))+b_{2})$
    from input vector $x$ and using a non-linear activation function $\sigma$. In
    the network bending framework, a deterministic function $f$ (controlled by the
    parameter $y$) is inserted into the computational graph of the model and applied
    to the internal activations of the model $u=\sigma(W_{2}(f(\sigma(W_{1}x+b_{1}),y))+b_{2})$,
    allowing the model to produce new samples $u$ from the new distribution $u\in
    U$. Beyond the simplest case of a transformation being applied to all features
    in a layer, the transformation layer can also be applied to a random sub-section
    of features, or to a pre-selected set of features. Broad, Leymarie, and Grierson
    ([2021](#bib.bib15)) present a clustering algorithm, that in an unsupervised fashion,
    groups together sets of features within a layer based on the spatial similarity
    of their activation maps. This clustering algorithm is capable of finding sets
    of features responsible for the generation of various semantically meaningful
    components of the generated output across the network (and semantic) hierarchy,
    which can then be manipulated in tandem allowing for semantic manipulation of
    the internal representations of the generative model.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 网络弯曲（Broad、Leymarie 和 Grierson，[2021](#bib.bib15)）是一个框架，允许通过使用单独的预训练模型进行主动分歧，而无需更改模型的权重或拓扑结构。相反，在模型的计算图中插入了实现标准图像滤镜的额外层，并在推断过程中应用于卷积特征的激活图³³3将滤镜插入GAN中也在Matlab
    StyleGAN playground中独立开发（Pinkney，[2020c](#bib.bib61)）。由于模型的计算图已经被改变，之前从近似分布 $P^{\prime}$
    生成样本的模型，现在从新的分布 $U$ 中生成新样本，而模型的参数没有任何更改。在最简单的情况下，两个层的模型为每个层 $l$ 生成一个关联权重矩阵 $W_{l}$
    和偏置 $b_{l}$ 向量。这生成样本 $p^{\prime}=\sigma(W_{2}(\sigma(W_{1}x+b_{1}))+b_{2})$，其中使用输入向量
    $x$ 和非线性激活函数 $\sigma$。在网络弯曲框架中，一个确定性函数 $f$（由参数 $y$ 控制）被插入到模型的计算图中，并应用于模型的内部激活
    $u=\sigma(W_{2}(f(\sigma(W_{1}x+b_{1}),y))+b_{2})$，使模型能够从新的分布 $u\in U$ 中生成新的样本
    $u$。除了将变换应用于层中的所有特征的最简单情况外，变换层还可以应用于特征的随机子集或预选特征集。Broad、Leymarie 和 Grierson（[2021](#bib.bib15)）提出了一种聚类算法，该算法以无监督的方式根据激活图的空间相似性将层内特征集合分组。该聚类算法能够找到负责生成各种语义上有意义的组件的特征集合，这些特征集合可以在网络（和语义）层次结构中进行操作，从而允许对生成模型的内部表示进行语义操作。
- en: In addition to applying filters to the activation maps, it is also possible
    to enlarge samples by increasing the size of the activation maps and interpolating
    and tiling them (Pouliot, [2020](#bib.bib62)). The network bending framework has
    been extended into the domain of audio synthesis (McCallum and Yee-King, [2020](#bib.bib54))
    where it has been applied to neural vocoder models using the differential digital
    signal processing (DDSP) approach (Engel et al., [2020](#bib.bib26)). In order
    to adapt the framework for the audio domain, McCallum and Yee-King ([2020](#bib.bib54))
    implement a number of filters that operate in the time domain, such as oscillators.
    Network bending has also been applied in the domain of audio-reactive visual synthesis
    using generative models (Brouwer, [2020](#bib.bib18)), with the deterministic
    transformations being controlled automatically using features extracted from audio
    analysis.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对激活图应用滤镜之外，还可以通过增大激活图的尺寸并进行插值和拼接来放大样本（Pouliot, [2020](#bib.bib62)）。网络弯曲框架已经扩展到音频合成领域（McCallum
    和 Yee-King, [2020](#bib.bib54)），在使用差分数字信号处理（DDSP）方法的神经声码器模型中得到了应用（Engel 等, [2020](#bib.bib26)）。为了使框架适应音频领域，McCallum
    和 Yee-King ([2020](#bib.bib54)) 实现了一些在时间域操作的滤镜，如振荡器。网络弯曲也被应用于使用生成模型的音频反应视觉合成领域（Brouwer,
    [2020](#bib.bib18)），其中确定性变换通过自动控制，从音频分析中提取的特征来进行。
- en: Network blending
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 网络混合
- en: Blending multiple models trained on different dataset allows for more control
    over the combination of learned features from different domains. This can either
    be done by blending the predictions of the models, or by blending the parameters
    of the models themselves.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 对多个在不同数据集上训练的模型进行混合，允许更好地控制来自不同领域的学习特征的组合。这可以通过混合模型的预测结果，或者通过混合模型本身的参数来实现。
- en: Blending model predictions
  id: totrans-64
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型预测混合
- en: Akten and Grierson ([2016](#bib.bib4)) present an interactive tool for text
    generation allowing for the realtime blending of the predicted outputs of an ensemble
    of long-short term memory network (LSTM) models (Hochreiter and Schmidhuber, [1997](#bib.bib42))
    trained to perform next character prediction from different text sources. A graphical
    user interface allows the user to dynamically shift the mixture weights for the
    weighted sum for the predictions of all of the models in the ensemble, prior to
    the one hot vector encoding which is used to determine the final predicted character
    value.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Akten 和 Grierson ([2016](#bib.bib4)) 提出了一个交互式文本生成工具，允许实时混合从不同文本来源训练的长短期记忆网络（LSTM）模型（Hochreiter
    和 Schmidhuber, [1997](#bib.bib42)）的预测输出。图形用户界面允许用户在进行一热编码（用于确定最终预测字符值）之前，动态调整所有模型预测的加权和的混合权重。
- en: Blending model parameters
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 模型参数混合
- en: A number of approaches, all demonstrated with StyleGAN2 (Karras et al., [2020](#bib.bib45)),
    take advantage of the large number of pre-trained models that have been shared
    on the internet (Pinkney, [2020b](#bib.bib60)). Of these almost all have been
    transfer-learned from the official model weights trained on the Flickr-Faces High
    Quality (FFHQ) dataset. It has been shown that the parameters of models transfer-learned
    $p_{transfer}$ from the same original source $p_{base}$ share commonalities in
    the way their weights are structured. This makes it possible to meaningfully interpolate
    between the parameters of the models directly (Aydao, [2020](#bib.bib6)). By using
    an interpolation weighting $\alpha$, it is possible to control the interpolation
    for the creation of a set of parameters $p_{interp}=(1-\alpha)p_{base}+\alpha
    p_{transfer}$.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法（所有这些方法都在 StyleGAN2 上演示，Karras 等, [2020](#bib.bib45)）利用了大量在互联网上共享的预训练模型（Pinkney,
    [2020b](#bib.bib60)）。这些模型几乎都从在 Flickr-Faces 高质量（FFHQ）数据集上训练的官方模型权重中进行迁移学习。已经显示，从相同原始来源
    $p_{base}$ 迁移学习得到的模型参数 $p_{transfer}$ 在权重结构上有共性。这使得可以直接在模型参数之间进行有意义的插值（Aydao,
    [2020](#bib.bib6)）。通过使用插值权重 $\alpha$，可以控制插值以创建一组参数 $p_{interp}=(1-\alpha)p_{base}+\alpha
    p_{transfer}$。
- en: Layers can also be swapped from one model to another (Pinkney and Adler, [2020](#bib.bib58)),
    allowing the combination of higher level features of one model with lower level
    features of another. This layer swapping technique was used to make the popular
    ‘toonification’ method, which can be used to find the corresponding sample to
    a real photograph of a person in a Disney-Pixar-esque ‘toonified’ model, simply
    by sampling from the same latent vector that has been found as the closest match
    to the person in FFHQ latent space (Abdal, Qin, and Wonka, [2019](#bib.bib1)).
    A generalised approach that combines both weight interpolation and layer-swapping
    methods for multiple models, uses a cascade of different weightings of interpolation
    for the various layers of the model (Arfafax, [2020](#bib.bib5)).
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 层也可以从一个模型交换到另一个模型（Pinkney和Adler，[2020](#bib.bib58)），从而将一个模型的高层特征与另一个模型的低层特征结合起来。这种层交换技术被用来制作流行的“卡通化”方法，这种方法可以通过从FFHQ潜在空间中找到与人最接近的潜在向量，简单地从中取样，将一个人真实照片对应到一个迪士尼-皮克斯风格的“卡通化”模型中（Abdal,
    Qin, 和 Wonka，[2019](#bib.bib1)）。一种通用的方法结合了权重插值和层交换方法，通过对模型的不同层使用不同的权重插值级联（Arfafax，[2020](#bib.bib5)）。
- en: Colton ([2021](#bib.bib21)) presents an evolutionary approach for exploring
    and finding effective and customisable neural style transfer blends. Upwards of
    1000 neural style transfer models trained on 1-10 style images each, can be blended
    through model interpolation, using an interface that is controlled by the user.
    MAP-Elites (Mouret and Clune, [2015](#bib.bib56)) in combination with a fitness
    function calculated using the output from a ResNet model (He et al., [2016](#bib.bib38))
    were used in evolutionary searches for optimal neural style transfer blends.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Colton ([2021](#bib.bib21)) 提出了一个进化方法，用于探索和找到有效且可定制的神经风格迁移混合。通过模型插值，用户可以使用一个由用户控制的界面混合超过1000个在1-10种风格图像上训练的神经风格迁移模型。MAP-Elites（Mouret和Clune，[2015](#bib.bib56)）结合使用从ResNet模型（He等人，[2016](#bib.bib38)）输出计算的适应度函数，在进化搜索中用于寻找最佳的神经风格迁移混合。
- en: Model rewriting
  id: totrans-70
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 模型重写
- en: Model rewriting encompasses approaches where either the weights or network topology
    are altered in a targeted way, through manual intervention or by using some form
    of heuristic based optimisation algorithm.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重写包括通过手动干预或使用某种启发式优化算法以有针对性的方式更改权重或网络拓扑的方法。
- en: Stochastic rewriting
  id: totrans-72
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 随机重写
- en: To create the series of artworks Neural Glitch the artist Mario Klingemann randomly
    altered, deleteed or exchanged the trained weights of pre-trained GANs (Klingemann,
    [2018](#bib.bib49)). In a similar fashion, the convolutional layer reconnection
    technique (Růžička, [2020](#bib.bib68)) randomly swaps convolutional features
    within layers of pre-trained GANs. This technique is applied in the Remixing AIs
    audiovisual synthesis framework (Collins, Růžička, and Grierson, [2020](#bib.bib20)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 为了创建系列艺术作品《Neural Glitch》，艺术家Mario Klingemann随机更改、删除或交换了预训练GAN的训练权重（Klingemann，[2018](#bib.bib49)）。类似地，卷积层重连技术（Růžička，[2020](#bib.bib68)）在预训练GAN的层内随机交换卷积特征。此技术应用于Remixing
    AIs视听合成框架（Collins, Růžička 和 Grierson，[2020](#bib.bib20)）。
- en: Targeted rewriting
  id: totrans-74
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 有针对性的重写
- en: Bau et al. ([2020](#bib.bib7)) present a targeted approach to model rewriting.
    Here, a sample is taken from the model and manipulated using standard image editing
    techniques (referred to as a ‘copy-paste’ interface). Once the sample has been
    altered corresponding to the desired goal (such as removing watermarks from the
    image, or getting horses to wear hats), a process of constrained optimisation
    is performed. All of the layers but one are frozen, and the weights of that layer
    are updated using gradient descent optimisation until the generated sample matches
    the new target. After this optimisation process is complete, the weights of the
    model are modified such that the targeted change becomes present in all the samples
    that the model generates.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: Bau等人（[2020](#bib.bib7)）提出了一种有针对性的模型重写方法。在这里，从模型中提取一个样本，并使用标准图像编辑技术（称为“复制粘贴”界面）进行操控。一旦样本被修改以符合期望目标（例如去除图像中的水印或让马匹戴上帽子），则执行受约束优化。除一个层外，所有层都被冻结，该层的权重通过梯度下降优化进行更新，直到生成的样本与新目标匹配。在这个优化过程完成后，模型的权重被修改，使得有针对性的变化在模型生成的所有样本中都能出现。
- en: The CombiNets framework (Guzdial and Riedl, [2018](#bib.bib35)), informed by
    prior reseach in combinational creativity (Boden, [2004](#bib.bib11)), can be
    utilised to create a new model by combining parameters from a number of pre-trained
    models in a targeted fashion. The parameters of existing models are recombined
    to take into account a new mode of generation that was not present in the training
    data (an example given would be a unicorn for a model trained on photographs of
    non-mythical beings). In this framework, a small number of new samples is provided
    (not enough to train a model directly) and then heuristic search is used to recombine
    parameters from existing models to account for this new mode of generation.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: CombiNets框架（Guzdial和Riedl，[2018](#bib.bib35)），基于组合创造性领域的先前研究（Boden，[2004](#bib.bib11)），可以通过有针对性地结合多个预训练模型的参数来创建新模型。现有模型的参数被重新组合，以考虑训练数据中不存在的新生成模式（举例来说，对于一个训练在非神话生物照片上的模型，可能会出现一个独角兽）。在这个框架中，提供少量的新样本（不足以直接训练模型），然后使用启发式搜索重新组合现有模型的参数，以适应这种新的生成模式。
- en: Further Demarcations
  id: totrans-77
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 进一步的划分
- en: In this section, we highlight demarcations that can be used to classify methods
    for active divergence. The following categories serve as criteria for further
    discussion and method comparison.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们强调了可以用于分类活跃发散方法的划分。这些类别作为进一步讨论和方法比较的标准。
- en: Training from scratch vs. using pre-trained models
  id: totrans-79
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 从零开始训练与使用预训练模型
- en: Finding stable, effective ways of training generative models, in particular
    GANs, is difficult and, depending on the training scheme, there are only a handful
    of methods that have been found to work successfully. Few methods for active divergence
    train a model completely from scratch. Instead, most take pre-trained models as
    their starting point for interventions. This way, training from scratch can be
    avoided, but fine-tuning may still be required.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 找到稳定、有效的生成模型训练方法，特别是GANs，是困难的，根据训练方案的不同，只有少数方法被发现能够成功地工作。很少有活跃发散的方法完全从零开始训练模型。相反，大多数方法以预训练模型作为干预的起点。这样可以避免从零开始训练，但可能仍需要微调。
- en: Utilising data vs. dataless approaches
  id: totrans-81
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用数据与无数据方法
- en: Most of the approaches described utilise data in some way, whether as an inspiring
    set for novelty generation, or for combining features from different datasets
    (divergent fine-tuning, network blending and chaining models). Even methods for
    model rewriting use very small amounts of example data to guide optimisation algorithms
    that alter the model weights. However, methods like network bending, show how
    models can be analysed in ways that don’t rely on any data, and are used for intelligent
    manipulation of the models —an approach which could be applied to other methods
    like model rewriting. Methods that train and fine-tune models without data also
    show how auxiliary networks and the dynamics between models can be utilised for
    achieving active divergence.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数描述的方法以某种方式利用数据，无论是作为新颖性生成的灵感集，还是用于结合来自不同数据集的特征（发散微调、网络混合和链式模型）。即使是模型重写的方法也使用非常少量的示例数据来指导优化算法，从而改变模型权重。然而，像网络弯曲的方法，展示了如何以不依赖任何数据的方式分析模型，并用于智能操控模型——这种方法可以应用于模型重写等其他方法。没有数据训练和微调模型的方法也展示了如何利用辅助网络和模型之间的动态来实现活跃发散。
- en: Human direction vs. creative autonomy
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 人工指导与创造性自主
- en: Very few of the approaches described have been developed with the expressed
    intention of handing over creative agency to the systems themselves. Most of the
    methods have been developed by artists or researchers in order to allow people
    to manipulate, experiment with and explore the unintended uses of these models
    for creative expression. However, the methods described that are currently designed
    for, or rely on a high degree of human curation and intervention, could easily
    be adapted and used in co-creative or autonomous creative systems in the future
    (Berns et al., [2021](#bib.bib9)).
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 很少有描述的方法是为了将创造性自主权交给系统本身而开发的。大多数方法由艺术家或研究人员开发，目的是让人们操控、实验和探索这些模型在创意表达中的意外用途。然而，目前设计用于或依赖高度人工策划和干预的方法，很容易在未来被改编并用于共同创造或自主创造系统（Berns等人，[2021](#bib.bib9)）。
- en: Applications of Active Divergence
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 活跃发散的应用
- en: In this section we outline some of the applications for active divergence methods.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们概述了活跃发散方法的一些应用。
- en: Novelty generation
  id: totrans-87
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 新颖性生成
- en: Generative deep learning techniques are capable of generalisation, such that
    they can produce new artefacts of high typicality and value, but are rarely capable
    of producing novel outputs that do not resemble the training data. Active divergence
    techniques play an important role in getting generative deep learning systems
    to generate truly novel artefacts, especially when there may be limited or even
    no data to draw from.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 生成深度学习技术能够进行泛化，从而产生具有高典型性和价值的新工件，但很少能产生与训练数据不相似的新输出。活跃发散技术在使生成深度学习系统生成真正新颖的工件中发挥着重要作用，特别是在可能没有或仅有有限数据可供借鉴的情况下。
- en: Creativity support and co-creation
  id: totrans-89
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创造力支持和共同创作
- en: Some of the frameworks presented are already explicitly designed as creativity
    support tools, such as the network bending framework, designed to allow for expressive
    manipulation of deep generative models. The Style Done Quick (Colton, [2021](#bib.bib21))
    application where many style transfer models have been evolved, was built as a
    casual creator application (Compton and Mateas, [2015](#bib.bib22)). Though many
    of the other methods described are still preliminary artistic and research experiments,
    there is a lot of potential for these methods to become better understood and
    eventually adapted and applied in more easily accessible creativity support tools
    and co-creation frameworks.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 提出的某些框架已经明确设计为创造力支持工具，例如网络弯曲框架，旨在允许对深度生成模型进行表达性操作。许多风格迁移模型已在Style Done Quick
    (Colton, [2021](#bib.bib21)) 应用中得到发展，该应用被构建为一种休闲创作者应用 (Compton and Mateas, [2015](#bib.bib22))。虽然许多其他描述的方法仍处于初步的艺术和研究实验阶段，但这些方法具有很大的潜力，最终可能会被更好地理解，并在更易于访问的创造力支持工具和共同创作框架中得到应用。
- en: Knowledge recombination
  id: totrans-91
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识重组
- en: Reusing and recombining knowledge in efficient ways is an important use-case
    of active divergence methods. While impressive generalisation can be ascertained
    from extremely large models trained on corpuses extracted from large portions
    of the internet (Ramesh et al., [2021](#bib.bib64)), this is out of the capabilities
    for all but a handful of large tech companies. Instead of relying on ever expanding
    computational resources, active divergence methods allow for the recombination
    of styles, aesthetic characteristics and higher level concepts in a much more
    efficient fashion. Methods like chaining models, network blending and model rewriting
    offer alternatives routes to achieving flexible knowledge recombination and generalisation
    to unseen domains without the need for extremely large models or data sources.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 以高效的方式重用和重组知识是活跃发散方法的重要应用场景。尽管可以从在互联网上大部分数据中提取的极大模型中获得令人印象深刻的泛化能力 (Ramesh et
    al., [2021](#bib.bib64))，但这仅限于少数大型科技公司。活跃发散方法允许以更高效的方式重组风格、美学特征和更高级别的概念，而无需依赖不断扩展的计算资源。像链式模型、网络混合和模型重写等方法提供了在没有极大模型或数据源的情况下实现灵活知识重组和泛化到未见领域的替代路径。
- en: Unseen domain adaptation
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 未见领域适应
- en: Active divergence methods allow for the possibility of adapting to and exploring
    unseen domains, for which there is little to no data available. The network blending
    approach presented by Pinkney and Adler ([2020](#bib.bib58)) can be used for the
    translation of faces while maintaining recognisable identity into a completely
    synthesised data domain, something which would not be possible with standard techniques
    for image translation (Zhu et al., [2017](#bib.bib85)).
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 活跃发散方法允许适应和探索未见领域，其中几乎没有可用的数据。Pinkney 和 Adler ([2020](#bib.bib58)) 提出的网络混合方法可以在保持可识别身份的情况下，将面孔翻译到完全合成的数据领域，这在标准图像翻译技术
    (Zhu et al., [2017](#bib.bib85)) 中是无法实现的。
- en: The model rewriting and network bending approaches offer the possibility of
    reusing and manipulating existing knowledge in a controlled fashion to create
    new data from a small number of given examples, or theoretically without any prior
    examples if external knowledge sources are integrated, as discussed further below.
    This approach could also be utilised by agents looking to explore hypothetical
    situations, by reorganising learned knowledge from world models (Ha and Schmidhuber,
    [2018](#bib.bib36)) to explore hypothetical situations or relations.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 模型重写和网络弯曲方法提供了在受控条件下重用和操作现有知识的可能性，从少量给定示例中生成新数据，或者理论上如果集成外部知识源，则无需任何先前示例，如下文进一步讨论。这种方法也可以被寻求探索假设情况的代理利用，通过重新组织世界模型（Ha
    和 Schmidhuber，[2018](#bib.bib36)）中的学习知识来探索假设情况或关系。
- en: A benchmark for creativity
  id: totrans-96
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 创造力的基准
- en: Generative models represent large knowledge bases that can produce high quality
    artefacts. There is a lot of unexplored potential for how the information and
    relationships they contain can be reused and rewritten with frameworks for manipulating
    them such as network bending and model re-writing. Active divergence frameworks
    could make good candidates for exploring and evaluating modes of creativity, such
    as combinational creativity (Boden, [2004](#bib.bib11)) and conceptual blending
    (Fauconnier and Turner, [2008](#bib.bib27)). These could be used to inform how
    the features in the model could be re-organised, and then evaluated by examining
    the artefacts generated from the altered models.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 生成模型代表了大量的知识库，这些知识库可以生成高质量的人工制品。关于如何利用这些信息和它们包含的关系，尚有很多未开发的潜力，可以通过网络弯曲和模型重写等操作框架进行再利用和重写。主动发散框架可能是探索和评估创造力模式的良好候选者，例如组合创造力（Boden，[2004](#bib.bib11)）和概念融合（Fauconnier
    和 Turner，[2008](#bib.bib27)）。这些框架可以用于指导如何重新组织模型中的特征，然后通过检查从修改后的模型生成的人工制品来评估这些特征。
- en: Future Research Directions
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 未来研究方向
- en: In this section we discuss possible future research directions and applications
    for developing, evaluating and utilising methods for active divergence.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们讨论了未来可能的研究方向以及开发、评估和利用主动发散方法的应用。
- en: Metrics for quantitative evaluation
  id: totrans-100
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 定量评估指标
- en: For the advancment of research on active divergence, methods for quantitative
    evaluation will be critical in order to keep track of progress, to compare techniques
    and for benchmarking. Metrics for active divergence will have to go beyond measuring
    the similarity or dissimilarity between distributions, as is usually done in the
    evaluation of generative models (Gretton, Sutherland, and Jitkrittum, [2019](#bib.bib34)).
    Active divergence metrics should contribute to a better understanding of how the
    distributions diverge. Therefore, various changes to the modelled distribution
    should be taken into consideration when looking to measure divergence between
    distributions in creative contexts. These include increases or decreases in diversity,
    the consistency and concurrency of change across the whole distribution and whether
    changes primarily effect low or high level features.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 对于主动发散研究的推进，定量评估方法至关重要，以便跟踪进展、比较技术和进行基准测试。主动发散的指标必须超越通常在生成模型评估中进行的分布相似性或不相似性的测量（Gretton,
    Sutherland 和 Jitkrittum，[2019](#bib.bib34)）。主动发散指标应有助于更好地理解分布的发散方式。因此，在创意背景下测量分布间的发散时，应考虑对建模分布的各种变化，包括多样性的增加或减少、整个分布的变化一致性和并发性，以及这些变化主要影响低层次还是高层次特征。
- en: Automating qualitative evaluation
  id: totrans-102
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 自动化定性评估
- en: 'In addition to quantitative evaluation, other metrics are needed for evaluating
    active divergence metrics. In order to rely less on qualitative evaluation for
    guiding decisions in creating new models, and do this in computational fashion
    so that these aspects of the process can be handed over to the computational systems.
    For instance, a recently developed metric for measuring visual indeterminacy (Wang
    et al., [2020b](#bib.bib83)), which is argued as being one of the key drivers
    for what people find interesting in GAN generated art (Hertzmann, [2020](#bib.bib39)),
    could be used for replacing the qualitative evaluation and curation step done
    by humans. Other metrics that could be used are: novelty metrics (Grace and Maher,
    [2019](#bib.bib33)), bayesian surprise (Itti and Baldi, [2009](#bib.bib44)), aesthetic
    evaluation (Galanter, [2012](#bib.bib30)), or measurements for optimal blends
    between data domains and evaluating the novelty of changes made to semantic relationships.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 除了定量评估，还需要其他指标来评估主动发散指标。为了减少对定性评估的依赖，以便以计算方式指导新模型的创建，从而将这些过程的某些方面交给计算系统。例如，最近开发的视觉不确定性测量指标（Wang
    等，[2020b](#bib.bib83)），被认为是人们在GAN生成艺术中发现有趣的关键驱动因素之一（Hertzmann，[2020](#bib.bib39)），可以用来替代由人类完成的定性评估和策展步骤。其他可以使用的指标包括：新颖性指标（Grace
    和 Maher，[2019](#bib.bib33)）、贝叶斯惊奇（Itti 和 Baldi，[2009](#bib.bib44)）、美学评估（Galanter，[2012](#bib.bib30)），或用于数据领域之间的最佳融合和评估对语义关系变化的新颖性的测量。
- en: Inventing new objective functions
  id: totrans-104
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 发明新的目标函数
- en: None of the methods presented to date that are based on generative deep learning
    have been capable of inventing their own objective functions. Instead, methods
    such as creative adversarial networks (Elgammal et al., [2017](#bib.bib25)) rely
    on hand crafted variations of well established objective functions. This will
    be one of most challenging future research directions to overcome, as generative
    deep learning systems rely on a small handful of objectives that result in stable
    convergence. However, in conjunction with the development of new evaluation metrics,
    it may be possible to explore whole new categories of objective functions that
    diverge from existing data representations and produce artefacts of high-value.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，基于生成深度学习的方法都未能发明自己的目标函数。相反，像创意对抗网络（Elgammal 等，[2017](#bib.bib25)）这样的技术依赖于精心制作的已建立目标函数的变体。这将是未来最具挑战性的研究方向之一，因为生成深度学习系统依赖于少量目标函数以实现稳定收敛。然而，结合新评估指标的发展，可能有机会探索完全不同的目标函数类别，这些类别与现有的数据表示有所不同，并产生高价值的人工制品。
- en: Utilising external knowledge
  id: totrans-106
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 利用外部知识
- en: Harnessing expert knowledge external to the dataset, which may come from separate
    domains or symbolic knowledge representations will allow much more flexibility
    in how generative models are manipulated in combinational creativity (Boden, [2004](#bib.bib11))
    and conceptual blending frameworks (Fauconnier and Turner, [2008](#bib.bib27)).
    Combining research into analysing the semantic purpose and relationship between
    features, and creating mappings of those to external data sources or knowledge
    graphs, would allow for more flexibility in controlling techniques which currently
    rely on human intervention (network bending, model rewriting). This could be adapted
    to be controlled and manipulated computationally, allowing for some creative decision
    making to be handed over to the computer.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 利用来自数据集外部的专家知识，这些知识可能来自不同领域或符号知识表示，将在生成模型的组合创造力（Boden，[2004](#bib.bib11)）和概念融合框架（Fauconnier
    和 Turner，[2008](#bib.bib27)）中提供更大的灵活性。将研究分析特征的语义目的和关系，并创建这些特征与外部数据源或知识图谱之间的映射，将使得控制技术更加灵活，这些技术目前依赖于人工干预（网络弯曲、模型重写）。这可以适应为可计算控制和操纵，使得一些创造性决策可以交给计算机处理。
- en: Formulating and realising intentions
  id: totrans-108
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 制定和实现意图
- en: For many of the methods described, a system that could formulate and realise
    its intentions would have to be capable of sourcing and creating its own dataset.
    For instance, a system that wants to create a model that generates hybrids between
    cats and dogs, would have to be capable of collecting data of cats and dogs separately,
    and then decide to use some method for network blending to get the desired results.
    Alternatively, utilising external knowledge sources in combination with semantic
    analysis of features, would allow computational systems more flexibility in generating
    new models by altering the semantic relationships between features in model rewriting
    or network bending approaches.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 对于许多描述的方法，能够制定和实现意图的系统必须能够获取和创建自己的数据集。例如，一个想要创建生成猫狗混合模型的系统，需要能够分别收集猫和狗的数据，然后决定使用某种网络混合方法来获得所需的结果。或者，利用外部知识源结合特征的语义分析，将允许计算系统通过改变模型重写或网络弯曲方法中特征之间的语义关系，从而在生成新模型时具有更大的灵活性。
- en: Multi-agent systems
  id: totrans-110
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 多代理系统
- en: It has been argued the the GAN framework is the simplest example of a multi-agent
    system (Agüera y Arcas, [2019](#bib.bib3)), and frameworks such as neural cellular
    automata (Mordvintsev et al., [2020](#bib.bib55)) offer new possibilities for
    multi-agent approaches in generative deep learning. The active divergence methods
    for training without data described in this paper all rely on the dynamics of
    multiple agents to produce interesting results, but this could be taken much further.
    It has been argued that art is fundamentally social (Hertzmann, [2021](#bib.bib40))
    and exploring more complex social dynamics between agents (Saunders, [2019](#bib.bib71))
    could be a fruitful avenue for exploration in the development of these approaches.
    There is a large body of work in emergent languages from co-operative multi-agent
    systems (Lazaridou, Peysakhovich, and Baroni, [2017](#bib.bib50)) that could be
    drawn from in furthering the work in generative multi-agent systems.
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 有人认为GAN框架是多代理系统的最简单示例（Agüera y Arcas, [2019](#bib.bib3)），而神经元细胞自动机（Mordvintsev
    et al., [2020](#bib.bib55)）等框架为生成深度学习中的多代理方法提供了新可能。本文描述的无需数据训练的主动发散方法都依赖于多个代理的动态来产生有趣的结果，但这可以更进一步。有人认为艺术本质上是社会性的（Hertzmann,
    [2021](#bib.bib40)），探索代理之间更复杂的社会动态（Saunders, [2019](#bib.bib71)）可能是发展这些方法的一个有益途径。合作多代理系统中的紧急语言研究（Lazaridou,
    Peysakhovich, and Baroni, [2017](#bib.bib50)）可以为推进生成多代理系统的工作提供借鉴。
- en: Open-ended reinforcement learning
  id: totrans-112
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 开放式强化学习
- en: Open-ended reinforcement learning, where there is no set goal (Wang et al.,
    [2020a](#bib.bib82)), offers possibilities for new more autonomous approaches
    to achieving active divergence. Reinforcement learning has not been discussed
    in this survey, but has been used in generative settings (Luo, [2020](#bib.bib52))
    in nascent research. Reinforcement learning approaches offer many opportunities
    for frameworks of creativity to be explored that are not available to standard
    generative deep learning methods, as they take actions in response to their environment,
    rather than just fitting functions. Paradigms like intrinsic motivation (Shaker,
    [2016](#bib.bib75)), cooperating or competing with other agents, formulating and
    acting on intentions are all concepts that conventional generative deep learning
    systems alone cannot explore, but these paradigms could be explored in open-ended
    systems utilising reinforcement learning.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 开放式强化学习，没有设定目标（Wang et al., [2020a](#bib.bib82)），为实现主动发散提供了新型更自主的方法的可能性。虽然本调查中没有讨论强化学习，但它在生成设置中（Luo,
    [2020](#bib.bib52)）在新兴研究中得到了应用。强化学习方法为创意框架的探索提供了许多机会，而这些机会是标准生成深度学习方法所无法提供的，因为它们对环境采取行动，而不仅仅是拟合函数。诸如内在动机（Shaker,
    [2016](#bib.bib75)）、与其他代理的合作或竞争、制定和执行意图等范式，都是传统生成深度学习系统无法单独探索的概念，但这些范式可以在利用强化学习的开放式系统中进行探索。
- en: Conclusion
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 结论
- en: We have presented a taxonomy and survey of the state of the art in methods for
    achieving active divergence from a range of sources, including artistic experiments,
    creativity support tools and in computational creativity research. Many of these
    methods represent nascent areas of research and there is a lot of scope for future
    work utilising them in co-creative and automated creative systems as they overcome
    a key shortcoming of mainstream generative deep learning approaches, which are
    unable to diverge from reproducing the training data in creative ways. In addition,
    we outline a number of the key future research directions needed in order to advance
    the state of the art for creativity support tools and computationally creative
    generative deep learning systems.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 我们提出了一个分类法和关于从各种来源实现主动差异的方法的调查，包括艺术实验，创造性支持工具和计算创造力研究。其中许多方法代表了研究的新生领域，并且有很多的空间可以用它们在协作创意和自动化创造性系统方面的未来工作中进行研究，因为它们克服了主流生成深度学习方法的一个主要缺点，无法以创新的方式偏离训练数据的复制。此外，我们在文中概述了一些未来研究方向，以推动创造性支持工具和计算创造性生成深度学习系统的最前沿技术。
- en: Acknowledgements
  id: totrans-116
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 致谢
- en: We thank our reviewers for their helpful comments. This work has been supported
    by UK’s EPSRC Centre for Doctoral Training in Intelligent Games and Game Intelligence
    (IGGI; grants EP/L015846/1 and EP/S022325/1).
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 感谢我们的评论者提供的有益评论。此工作得到了英国的智能游戏和游戏智能博士培养中心（IGGI；津贴号EP/L015846/1和EP/S022325/1）的支持。
- en: References
  id: totrans-118
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abdal, Qin, and Wonka (2019) Abdal, R.; Qin, Y.; and Wonka, P. 2019. Image2StyleGAN:
    How to embed images into the StyleGAN latent space? In IEEE International Conference
    on Computer Vision, 4432–4441.'
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdal, Qin, and Wonka (2019) Abdal, R.; Qin, Y.; and Wonka, P. 2019. 图像到StyleGAN潜空间的嵌入方式是什么？
    在IEEE国际计算机视觉会议（ICCV）上，4432–4441。
- en: 'Adler (2020) Adler, D. 2020. Deliberate stylegan2 ffhq corruption. fine tuned
    upon a tiny set […]. https://twitter.com/Norod78/status/1218282356391530496. Accessed:
    2021-02-05.'
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Adler (2020) Adler, D. 2020. 故意的stylegan2 ffhq破坏。在一个小数据集上进行微调[...]。[链接](https://twitter.com/Norod78/status/1218282356391530496)。访问日期：2021年02月05日。
- en: Agüera y Arcas (2019) Agüera y Arcas, B. 2019. Social intelligence. In Advances
    in Neural Information Processing Systems [Keynote address].
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Agüera y Arcas (2019) Agüera y Arcas, B. 2019. 社交智能。在《进展》中神经信息处理系统[重点演讲]。
- en: Akten and Grierson (2016) Akten, M., and Grierson, M. 2016. Real-time interactive
    sequence generation and control with recurrent neural network ensembles. Recurrent
    Neural Networks Symposium, NIPS 2016.
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akten and Grierson (2016) Akten, M., and Grierson, M. 2016. 基于循环神经网络合奏的实时交互式序列生成和控制。循环神经网络研讨会，NIPS
    2016。
- en: 'Arfafax (2020) Arfafax. 2020. Barycentric cross-network interpolation with
    different layer interpolation rates. https://colab.research.google.com/drive/1FwOYqtU0kVYDwHrddFKBhDKcs0jJ_zuK.
    Accessed: 2020-02-05.'
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arfafax (2020) Arfafax. 2020. 不同层插值率的质心式跨网络插值。[链接](https://colab.research.google.com/drive/1FwOYqtU0kVYDwHrddFKBhDKcs0jJ_zuK)。访问日期：2020年02月05日。
- en: 'Aydao (2020) Aydao. 2020. Yeah stochastic weight averaging of neural networks
    is wild […]. https://twitter.com/AydaoAI/status/1234614081413406720. Accessed:
    2021-02-05.'
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aydao (2020) Aydao. 2020. 是的，神经网络的随机权重平均是很疯狂的[...]。[链接](https://twitter.com/AydaoAI/status/1234614081413406720)。访问日期：2021年02月05日。
- en: Bau et al. (2020) Bau, D.; Liu, S.; Wang, T.; Zhu, J.-Y.; and Torralba, A. 2020.
    Rewriting a deep generative model. In Proc. European Conference on Computer Vision
    (ECCV).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bau et al. (2020) Bau, D.; Liu, S.; Wang, T.; Zhu, J.-Y.; and Torralba, A. 2020.
    对深度生成模型进行重写。在Proc. European Conference on Computer Vision (ECCV)上。
- en: Berns and Colton (2020) Berns, S., and Colton, S. 2020. Bridging generative
    deep learning and computational creativity. In Proc. 11th International Conference
    on Computational Creativity.
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berns and Colton (2020) Berns, S., and Colton, S. 2020. 架起生成深度学习和计算创造之间的桥梁。在第11届国际计算创造会议上。
- en: 'Berns et al. (2021) Berns, S.; Broad, T.; Guckelsberger, C.; and Colton, S.
    2021. Automating Generative Deep Learning for Artistic Purposes: Challenges and
    Opportunities. In Proc. 12th International Conference on Computational Creativity.'
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Berns et al. (2021) Berns, S.; Broad, T.; Guckelsberger, C.; and Colton, S.
    2021. 用于艺术目的生成深度学习的自动化：挑战与机会。在第12届国际计算创造会议上。
- en: 'Black (2020) Black, S. 2020. Thanks! it’s trained on faces then trained a little
    while […]. https://twitter.com/realmeatyhuman/status/1257733313885765638. Accessed:
    2021-02-05.'
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Black (2020) Black, S. 2020. 谢谢！它是在面部上训练的，然后训练了一小段时间[...]。[链接](https://twitter.com/realmeatyhuman/status/1257733313885765638)。访问日期：2021年02月05日。
- en: 'Boden (2004) Boden, M. A. 2004. The creative mind: Myths and mechanisms. Psychology
    Press.'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Boden (2004) Boden, M. A. 2004. 创造性思维：神话与机制。Psychology Press。
- en: 'Broad and Grierson (2019a) Broad, T., and Grierson, M. 2019a. Searching for
    an (un)stable equilibrium: experiments in training generative models without data.
    NeurIPS 2019 Workshop on Machine Learning for Creativity and Design.'
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad和Grierson（2019a）Broad, T., 和 Grierson, M. 2019a. 寻找（不）稳定的平衡：在没有数据的情况下训练生成模型的实验。NeurIPS
    2019 创意和设计机器学习研讨会。
- en: Broad and Grierson (2019b) Broad, T., and Grierson, M. 2019b. Transforming the
    output of GANs by fine-tuning them with features from different datasets. arXiv
    preprint arXiv:1910.02411.
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad和Grierson（2019b）Broad, T., 和 Grierson, M. 2019b. 通过用不同数据集的特征微调GANs来转换GAN的输出。arXiv预印本arXiv:1910.02411。
- en: Broad, Leymarie, and Grierson (2020) Broad, T.; Leymarie, F. F.; and Grierson,
    M. 2020. Amplifying the uncanny. Proc. 8th Conference on Computation, Communication,
    Aesthetics and X (xCoAx).
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad, Leymarie和Grierson（2020）Broad, T.; Leymarie, F. F.; 和 Grierson, M. 2020.
    放大不安。第8届计算、通信、审美与X会议（xCoAx）论文集。
- en: 'Broad, Leymarie, and Grierson (2021) Broad, T.; Leymarie, F. F.; and Grierson,
    M. 2021. Network bending: Expressive manipulation of deep generative models. Proc.
    10th International Conference on Artificial Intelligence in Music, Sound, Art
    and Design (EvoMUSART).'
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad, Leymarie和Grierson（2021）Broad, T.; Leymarie, F. F.; 和 Grierson, M. 2021.
    网络弯曲：深度生成模型的表现力操控。第10届人工智能在音乐、声音、艺术和设计中的国际会议（EvoMUSART）论文集。
- en: 'Broad (2020a) Broad, T. 2020a. Being Foiled. https://terencebroad.com/works/being-foiled.
    Accessed: 2021-06-30.'
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad（2020a）Broad, T. 2020a. Being Foiled. https://terencebroad.com/works/being-foiled.
    访问时间：2021-06-30。
- en: 'Broad (2020b) Broad, T. 2020b. Teratome. https://terencebroad.com/works/teratome.
    Accessed: 2021-06-28.'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Broad（2020b）Broad, T. 2020b. Teratome. https://terencebroad.com/works/teratome.
    访问时间：2021-06-28。
- en: Brouwer (2020) Brouwer, H. 2020. Audio-reactive latent interpolations with StyleGAN.
    NeurIPS 2020 Workshop on Machine Learning for Creativity and Design.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brouwer（2020）Brouwer, H. 2020. 与StyleGAN的音频反应性潜在插值。NeurIPS 2020 创意和设计机器学习研讨会。
- en: 'Cherti, Kégl, and Kazakçı (2017) Cherti, M.; Kégl, B.; and Kazakçı, A. 2017.
    Out-of-class novelty generation: an experimental foundation. In Proc. IEEE 29th
    International Conference on Tools with Artificial Intelligence (ICTAI).'
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cherti, Kégl和Kazakçı（2017）Cherti, M.; Kégl, B.; 和 Kazakçı, A. 2017. 类外新颖性生成：实验基础。在IEEE第29届人工智能工具国际会议论文集中。
- en: 'Collins, Růžička, and Grierson (2020) Collins, N.; Růžička, V.; and Grierson,
    M. 2020. Remixing ais: mind swaps, hybrainity, and splicing musical models. In
    Proc. The Joint Conference on AI Music Creativity.'
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Collins, Růžička和Grierson（2020）Collins, N.; Růžička, V.; 和 Grierson, M. 2020.
    Remixing ais: 思维交换、混合脑力和音乐模型拼接。在人工智能音乐创造力联合会议论文集中。'
- en: Colton (2021) Colton, S. 2021. Evolving neural style transfer blends. Proc.
    10th International Conference on Artificial Intelligence in Music, Sound, Art
    and Design (EvoMUSART).
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Colton（2021）Colton, S. 2021. 进化神经风格迁移混合。第10届人工智能在音乐、声音、艺术和设计中的国际会议（EvoMUSART）论文集。
- en: Compton and Mateas (2015) Compton, K., and Mateas, M. 2015. Casual creators.
    In Proc. 6th International Conference on Computational Creativity.
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Compton和Mateas（2015）Compton, K., 和 Mateas, M. 2015. 随意创作者。在第6届国际计算创造力会议论文集中。
- en: 'Cook and Colton (2018) Cook, M., and Colton, S. 2018. Neighbouring communities:
    Interaction, lessons and opportunities. Association for Computational Creativity
    (ACC).'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cook和Colton（2018）Cook, M., 和 Colton, S. 2018. 邻近社区：互动、教训和机遇。计算创造力协会（ACC）。
- en: 'Dinh, Krueger, and Bengio (2014) Dinh, L.; Krueger, D.; and Bengio, Y. 2014.
    Nice: Non-linear independent components estimation. arXiv preprint arXiv:1410.8516.'
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dinh, Krueger和Bengio（2014）Dinh, L.; Krueger, D.; 和 Bengio, Y. 2014. Nice: 非线性独立成分估计。arXiv预印本arXiv:1410.8516。'
- en: 'Elgammal et al. (2017) Elgammal, A.; Liu, B.; Elhoseiny, M.; and Mazzone, M.
    2017. CAN: Creative adversarial networks, generating” art” by learning about styles
    and deviating from style norms. Proc. 8th International Conference on Computational
    Creativity.'
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Elgammal等（2017）Elgammal, A.; Liu, B.; Elhoseiny, M.; 和 Mazzone, M. 2017. CAN:
    创意对抗网络，通过学习风格和偏离风格规范生成“艺术”。第8届国际计算创造力会议论文集。'
- en: 'Engel et al. (2020) Engel, J.; Hantrakul, L.; Gu, C.; and Roberts, A. 2020.
    DDSP: Differentiable digital signal processing. International Conference on Learning
    Representations.'
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Engel等（2020）Engel, J.; Hantrakul, L.; Gu, C.; 和 Roberts, A. 2020. DDSP: 可微分数字信号处理。国际学习表示会议。'
- en: 'Fauconnier and Turner (2008) Fauconnier, G., and Turner, M. 2008. The way we
    think: Conceptual blending and the mind’s hidden complexities. Basic Books.'
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fauconnier和Turner（2008）Fauconnier, G., 和 Turner, M. 2008. 我们的思维方式：概念融合和心智的隐藏复杂性。Basic
    Books。
- en: Frey et al. (1996) Frey, B. J.; Hinton, G. E.; Dayan, P.; et al. 1996. Does
    the wake-sleep algorithm produce good density estimators? In Advances in neural
    information processing systems, 661–670. Citeseer.
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Frey 等（1996）Frey, B. J.; Hinton, G. E.; Dayan, P.; 等. 1996. 唤醒-睡眠算法是否能产生良好的密度估计器？在《神经信息处理系统进展》中，661–670。Citeseer。
- en: 'Gal (2021) Gal, R. 2021. StyleGAN2-NADA. https://github.com/rinongal/StyleGAN-nada.
    Accessed: 2021-06-28.'
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gal（2021）Gal, R. 2021. StyleGAN2-NADA。https://github.com/rinongal/StyleGAN-nada.
    访问日期：2021-06-28。
- en: 'Galanter (2012) Galanter, P. 2012. Computational aesthetic evaluation: past
    and future. Computers and creativity 255–293.'
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Galanter（2012）Galanter, P. 2012. 计算美学评估：过去与未来。《计算机与创造力》255–293。
- en: Gatys, Ecker, and Bethge (2016) Gatys, L.; Ecker, A.; and Bethge, M. 2016. A
    neural algorithm of artistic style. Journal of Vision 16(12):326–326.
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gatys, Ecker, 和 Bethge（2016）Gatys, L.; Ecker, A.; 和 Bethge, M. 2016. 一种艺术风格的神经算法。Journal
    of Vision 16(12):326–326。
- en: Goodfellow et al. (2014) Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.;
    Warde-Farley, D.; Ozair, S.; Courville, A.; and Bengio, Y. 2014. Generative adversarial
    nets. In Advances in neural information processing systems.
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等（2014）Goodfellow, I.; Pouget-Abadie, J.; Mirza, M.; Xu, B.; Warde-Farley,
    D.; Ozair, S.; Courville, A.; 和 Bengio, Y. 2014. 生成对抗网络。在《神经信息处理系统进展》中。
- en: Grace and Maher (2019) Grace, K., and Maher, M. L. 2019. Expectation-based models
    of novelty for evaluating computational creativity. In Computational Creativity.
    Springer. 195–209.
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Grace 和 Maher（2019）Grace, K., 和 Maher, M. L. 2019. 基于期望的创新模型用于评估计算创造力。在《计算创造力》。Springer.
    195–209。
- en: Gretton, Sutherland, and Jitkrittum (2019) Gretton, A.; Sutherland, D.; and
    Jitkrittum, W. 2019. Interpretable comparison of distributions and models. In
    Advances in Neural Information Processing Systems [Tutorial].
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gretton, Sutherland, 和 Jitkrittum（2019）Gretton, A.; Sutherland, D.; 和 Jitkrittum,
    W. 2019. 可解释的分布和模型比较。在《神经信息处理系统进展》[教程]。
- en: 'Guzdial and Riedl (2018) Guzdial, M., and Riedl, M. O. 2018. Combinets: Creativity
    via recombination of neural networks. Proc. 9th International Conference on Computational
    Creativity.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Guzdial 和 Riedl（2018）Guzdial, M., 和 Riedl, M. O. 2018. Combinets: 通过神经网络的重组实现创造力。第九届国际计算创造力会议论文集。'
- en: Ha and Schmidhuber (2018) Ha, D., and Schmidhuber, J. 2018. Recurrent world
    models facilitate policy evolution. Advances in Neural Information Processing
    Systems 31.
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ha 和 Schmidhuber（2018）Ha, D., 和 Schmidhuber, J. 2018. 循环世界模型促进策略演化。《神经信息处理系统进展》31。
- en: Harshvardhan et al. (2020) Harshvardhan, G.; Gourisaria, M. K.; Pandey, M.;
    and Rautaray, S. S. 2020. A comprehensive survey and analysis of generative models
    in machine learning. Computer Science Review 38:100285.
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harshvardhan 等（2020）Harshvardhan, G.; Gourisaria, M. K.; Pandey, M.; 和 Rautaray,
    S. S. 2020. 机器学习中生成模型的综合调查和分析。Computer Science Review 38:100285。
- en: He et al. (2016) He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual
    learning for image recognition. In Proc. IEEE conference on computer vision and
    pattern recognition.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2016）He, K.; Zhang, X.; Ren, S.; 和 Sun, J. 2016. 深度残差学习用于图像识别。在 IEEE 计算机视觉与模式识别会议论文集。
- en: Hertzmann (2020) Hertzmann, A. 2020. Visual indeterminacy in GAN art. Leonardo
    53(4):424–428.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hertzmann（2020）Hertzmann, A. 2020. GAN 艺术中的视觉不确定性。Leonardo 53(4):424–428。
- en: 'Hertzmann (2021) Hertzmann, A. 2021. Art is fundamentally social. https://aaronhertzmann.com/2021/03/22/art-is-social.html.
    Accessed: 2020-03-29.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hertzmann（2021）Hertzmann, A. 2021. 艺术从本质上讲是社会性的。https://aaronhertzmann.com/2021/03/22/art-is-social.html.
    访问日期：2020-03-29。
- en: Hocevar (1980) Hocevar, D. 1980. Intelligence, divergent thinking, and creativity.
    Intelligence 4(1):25–40.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hocevar（1980）Hocevar, D. 1980. 智力、发散思维和创造力。Intelligence 4(1):25–40。
- en: Hochreiter and Schmidhuber (1997) Hochreiter, S., and Schmidhuber, J. 1997.
    Long short-term memory. Neural computation 9(8).
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter 和 Schmidhuber（1997）Hochreiter, S., 和 Schmidhuber, J. 1997. 长短期记忆。Neural
    computation 9(8)。
- en: Isola et al. (2017) Isola, P.; Zhu, J.-Y.; Zhou, T.; and Efros, A. A. 2017.
    Image-to-image translation with conditional adversarial networks. In Proc. IEEE
    Conference on Computer Vision and Pattern Recognition.
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isola 等（2017）Isola, P.; Zhu, J.-Y.; Zhou, T.; 和 Efros, A. A. 2017. 使用条件对抗网络进行图像到图像的翻译。在
    IEEE 计算机视觉与模式识别会议论文集。
- en: Itti and Baldi (2009) Itti, L., and Baldi, P. 2009. Bayesian surprise attracts
    human attention. Vision research 49(10):1295–1306.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Itti 和 Baldi（2009）Itti, L., 和 Baldi, P. 2009. 贝叶斯惊讶吸引人类注意力。Vision research 49(10):1295–1306。
- en: Karras et al. (2020) Karras, T.; Laine, S.; Aittala, M.; Hellsten, J.; Lehtinen,
    J.; and Aila, T. 2020. Analyzing and improving the image quality of StyleGAN.
    Proc. IEEE Conference on Computer Vision and Pattern Recognition.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras 等（2020）Karras, T.; Laine, S.; Aittala, M.; Hellsten, J.; Lehtinen, J.;
    和 Aila, T. 2020. 分析和改进 StyleGAN 的图像质量。IEEE 计算机视觉与模式识别会议论文集。
- en: 'Kazakçı, Mehdi, and Kégl (2016) Kazakçı, A.; Mehdi, C.; and Kégl, B. 2016.
    Digits that are not: Generating new types through deep neural nets. In Proc. 7th
    International Conference on Computational Creativity.'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazakçı, Mehdi, 和 Kégl (2016) Kazakçı, A.; Mehdi, C.; 和 Kégl, B. 2016. 非数字的数字：通过深度神经网络生成新类型。第七届国际计算创造力会议论文集。
- en: 'Kégl, Cherti, and Kazakçı (2018) Kégl, B.; Cherti, M.; and Kazakçı, A. 2018.
    Spurious samples in deep generative models: bug or feature? arXiv preprint arXiv:1810.01876.'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kégl, Cherti, 和 Kazakçı (2018) Kégl, B.; Cherti, M.; 和 Kazakçı, A. 2018. 深度生成模型中的虚假样本：是错误还是特性？arXiv
    预印本 arXiv:1810.01876。
- en: Kingma and Welling (2013) Kingma, D. P., and Welling, M. 2013. Auto-encoding
    variational Bayes. In International Conference on Learning Representations.
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Welling (2013) Kingma, D. P., 和 Welling, M. 2013. 自编码变分贝叶斯。在国际学习表征会议上。
- en: 'Klingemann (2018) Klingemann, M. 2018. Neural glitch / mistaken identity. https://underdestruction.com/2018/10/28/neural-glitch/.
    Accessed: 2021-02-05.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Klingemann (2018) Klingemann, M. 2018. 神经网络故障/错误身份。https://underdestruction.com/2018/10/28/neural-glitch/。访问日期：2021-02-05。
- en: Lazaridou, Peysakhovich, and Baroni (2017) Lazaridou, A.; Peysakhovich, A.;
    and Baroni, M. 2017. Multi-agent cooperation and the emergence of (natural) language.
    International Conference on Learning Representations.
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lazaridou, Peysakhovich, 和 Baroni (2017) Lazaridou, A.; Peysakhovich, A.; 和
    Baroni, M. 2017. 多智能体合作与（自然）语言的出现。国际学习表征会议。
- en: LeCun et al. (1998) LeCun, Y.; Bottou, L.; Bengio, Y.; and Haffner, P. 1998.
    Gradient-based learning applied to document recognition. Proc. of the IEEE 86(11).
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等 (1998) LeCun, Y.; Bottou, L.; Bengio, Y.; 和 Haffner, P. 1998. 应用于文档识别的梯度学习。IEEE
    会议录 86(11)。
- en: Luo (2020) Luo, J. 2020. Reinforcement Learning for Generative Art. University
    of California, Santa Barbara.
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Luo (2020) Luo, J. 2020. 生成艺术的强化学习。加州大学圣塔芭芭拉分校。
- en: 'Mariansky (2020) Mariansky, M. 2020. Transfer learning StyleGAN from ffhq faces
    to beetles is super weird. https://twitter.com/mmariansky/status/1226756838613491713.
    Accessed: 2021-02-04.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mariansky (2020) Mariansky, M. 2020. 从 ffhq 面孔到甲虫的迁移学习 StyleGAN 超级奇怪。https://twitter.com/mmariansky/status/1226756838613491713。访问日期：2021-02-04。
- en: McCallum and Yee-King (2020) McCallum, L., and Yee-King, M. 2020. Network bending
    neural vocoders. NeurIPS 2020 Workshop on Machine Learning for Creativity and
    Design.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: McCallum 和 Yee-King (2020) McCallum, L., 和 Yee-King, M. 2020. 网络弯曲神经声码器。NeurIPS
    2020 创意与设计机器学习研讨会。
- en: Mordvintsev et al. (2020) Mordvintsev, A.; Randazzo, E.; Niklasson, E.; and
    Levin, M. 2020. Growing neural cellular automata. Distill 5(2):e23.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mordvintsev 等 (2020) Mordvintsev, A.; Randazzo, E.; Niklasson, E.; 和 Levin,
    M. 2020. 生长的神经细胞自动机。Distill 5(2):e23。
- en: Mouret and Clune (2015) Mouret, J.-B., and Clune, J. 2015. Illuminating search
    spaces by mapping elites. arXiv preprint arXiv:1504.04909.
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mouret 和 Clune (2015) Mouret, J.-B., 和 Clune, J. 2015. 通过映射精英来照亮搜索空间。arXiv 预印本
    arXiv:1504.04909。
- en: Park (2020) Park, S.-w. 2020. Generating novel glyph without human data by learning
    to communicate. NeurIPS 2020 Workshop on Machine Learning For Creativity and Design.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Park (2020) Park, S.-w. 2020. 通过学习交流生成无人工数据的新字形。NeurIPS 2020 创意与设计机器学习研讨会。
- en: Pinkney and Adler (2020) Pinkney, J. N. M., and Adler, D. 2020. Resolution dependent
    GAN interpolation for controllable image synthesis between domains. NeurIPS 2020
    Workshop on Machine Learning for Creativity and Design.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinkney 和 Adler (2020) Pinkney, J. N. M., 和 Adler, D. 2020. 分辨率依赖的 GAN 插值用于可控图像合成。NeurIPS
    2020 创意与设计机器学习研讨会。
- en: 'Pinkney (2020a) Pinkney, J. N. M. 2020a. Aligned ukiyo-e faces dataset. https://www.justinpinkney.com/ukiyoe-dataset/.
    Accessed: 2021-06-28.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinkney (2020a) Pinkney, J. N. M. 2020a. 对齐的浮世绘面孔数据集。https://www.justinpinkney.com/ukiyoe-dataset/。访问日期：2021-06-28。
- en: 'Pinkney (2020b) Pinkney, J. N. M. 2020b. Awesome pretrained StyleGAN2. https://github.com/justinpinkney/awesome-pretrained-stylegan2.
    Accessed: 2020-02-05.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinkney (2020b) Pinkney, J. N. M. 2020b. 精彩的预训练 StyleGAN2。https://github.com/justinpinkney/awesome-pretrained-stylegan2。访问日期：2020-02-05。
- en: 'Pinkney (2020c) Pinkney, J. N. M. 2020c. MATLAB StyleGAN playground. https://www.justinpinkney.com/matlab-stylegan/.
    Accessed: 2021-02-05.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pinkney (2020c) Pinkney, J. N. M. 2020c. MATLAB StyleGAN 游乐场。https://www.justinpinkney.com/matlab-stylegan/。访问日期：2021-02-05。
- en: 'Pouliot (2020) Pouliot, A. 2020. GAN bending. https://darknoon.com/2020/03/03/gan-hacking/.
    Accessed: 2021-03-27.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pouliot (2020) Pouliot, A. 2020. GAN 弯曲。https://darknoon.com/2020/03/03/gan-hacking/。访问日期：2021-03-27。
- en: Radford et al. (2021) Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh,
    G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; et al. 2021.
    Learning transferable visual models from natural language supervision. arXiv preprint
    arXiv:2103.00020.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Radford et al. (2021) Radford, A.; Kim, J. W.; Hallacy, C.; Ramesh, A.; Goh,
    G.; Agarwal, S.; Sastry, G.; Askell, A.; Mishkin, P.; Clark, J.; 等. 2021. 从自然语言监督中学习可转移的视觉模型。arXiv
    预印本 arXiv:2103.00020。
- en: Ramesh et al. (2021) Ramesh, A.; Pavlov, M.; Goh, G.; Gray, S.; Voss, C.; Radford,
    A.; Chen, M.; and Sutskever, I. 2021. Zero-shot text-to-image generation. arXiv
    preprint arXiv:2102.12092.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramesh et al. (2021) Ramesh, A.; Pavlov, M.; Goh, G.; Gray, S.; Voss, C.; Radford,
    A.; Chen, M.; 和 Sutskever, I. 2021. 零样本文本到图像生成。arXiv 预印本 arXiv:2102.12092。
- en: Rezende, Mohamed, and Wierstra (2014) Rezende, D. J.; Mohamed, S.; and Wierstra,
    D. 2014. Stochastic backpropagation and approximate inference in deep generative
    models. In Proc. 31st International Conference on Machine Learning.
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rezende, Mohamed, and Wierstra (2014) Rezende, D. J.; Mohamed, S.; 和 Wierstra,
    D. 2014. 深度生成模型中的随机反向传播和近似推断。在第31届国际机器学习会议论文集中。
- en: Ritchie (2007) Ritchie, G. 2007. Some empirical criteria for attributing creativity
    to a computer program. Minds and Machines 17(1):67–99.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ritchie (2007) Ritchie, G. 2007. 用于将创造力归因于计算机程序的一些实证标准。*思想与机器* 17(1):67–99。
- en: Rumelhart, Hinton, and Williams (1985) Rumelhart, D. E.; Hinton, G. E.; and
    Williams, R. J. 1985. Learning internal representations by error propagation.
    Technical report, California Univ San Diego La Jolla Inst for Cognitive Science.
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rumelhart, Hinton, and Williams (1985) Rumelhart, D. E.; Hinton, G. E.; 和 Williams,
    R. J. 1985. 通过误差传播学习内部表示。技术报告，加州大学圣地亚哥分校拉霍亚认知科学研究所。
- en: 'Růžička (2020) Růžička, V. 2020. GAN explorer. https://github.com/previtus/GAN_explorer.
    Accessed: 2020-12-17.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Růžička (2020) Růžička, V. 2020. GAN 探索者。 https://github.com/previtus/GAN_explorer.
    访问日期：2020-12-17。
- en: 'Saleh and Elgammal (2016) Saleh, B., and Elgammal, A. 2016. Large-scale classification
    of fine-art paintings: Learning the right metric on the right feature. International
    Journal for Digital Art History.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saleh and Elgammal (2016) Saleh, B., 和 Elgammal, A. 2016. 大规模美术画作分类：在正确特征上学习正确的度量。*数字艺术史国际期刊*。
- en: 'Sarin (2018) Sarin, H. 2018. Playing a game of GANstruction. https://thegradient.pub/playing-a-game-of-ganstruction/.
    Accessed: 2020-12-15.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarin (2018) Sarin, H. 2018. 玩 GANstruction 游戏。 https://thegradient.pub/playing-a-game-of-ganstruction/.
    访问日期：2020-12-15。
- en: Saunders (2019) Saunders, R. 2019. Multi-agent-based models of social creativity.
    In Computational Creativity. Springer. 305–326.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saunders (2019) Saunders, R. 2019. 基于多智能体的社会创造力模型。在*计算创造力*。Springer. 305–326。
- en: 'Schultz (2020a) Schultz, D. 2020a. Demo: How to mix models in StyleGAN2. https://www.youtube.com/watch?v=kbRkznsv9dk.
    Accessed: 2020-02-07.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schultz (2020a) Schultz, D. 2020a. 演示：如何在 StyleGAN2 中混合模型。 https://www.youtube.com/watch?v=kbRkznsv9dk.
    访问日期：2020-02-07。
- en: 'Schultz (2020b) Schultz, D. 2020b. You Are Here. https://artificial-images.com/project/you-are-here-machine-learning-film/.
    Accessed: 2021-06-28.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schultz (2020b) Schultz, D. 2020b. 你在这里。 https://artificial-images.com/project/you-are-here-machine-learning-film/.
    访问日期：2021-06-28。
- en: Schultz (2021) Schultz, D. 2021. Personal communication.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schultz (2021) Schultz, D. 2021. 个人通信。
- en: 'Shaker (2016) Shaker, N. 2016. Intrinsically motivated reinforcement learning:
    A promising framework for procedural content generation. In 2016 IEEE Conference
    on Computational Intelligence and Games (CIG), 1–8. IEEE.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shaker (2016) Shaker, N. 2016. 内在驱动的强化学习：用于程序生成内容的一个有前景的框架。在 2016 年 IEEE 计算智能与游戏会议
    (CIG)，1–8。IEEE。
- en: 'Shane (2020) Shane, J. 2020. Trained a neural net on my cat and regret everything.
    https://aiweirdness.com/post/615654447163621376/trained-a-neural-net-on-my-cat-and-regret.
    Accessed: 2020-02-05.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shane (2020) Shane, J. 2020. 训练了一个神经网络在我的猫身上，并对一切感到后悔。 https://aiweirdness.com/post/615654447163621376/trained-a-neural-net-on-my-cat-and-regret.
    访问日期：2020-02-05。
- en: 'Simon (2019) Simon, J. 2019. Dimensions of dialogue. https://www.joelsimon.net/dimensions-of-dialogue.html.
    Accessed: 2020-12-15.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simon (2019) Simon, J. 2019. 对话的维度。 https://www.joelsimon.net/dimensions-of-dialogue.html.
    访问日期：2020-12-15。
- en: 'Sloan (2012) Sloan, R. 2012. Dancing the flip flop. https://www.robinsloan.com/notes/flip-flop/.
    Accessed: 2021-03-27.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sloan (2012) Sloan, R. 2012. 跳舞的翻转。 https://www.robinsloan.com/notes/flip-flop/.
    访问日期：2021-03-27。
- en: 'Som (2020) Som, M. 2020. Strange Fruit. http://www.aiartonline.com/highlights-2020/mal-som-errthangisalive/.
    Accessed: 2021-02-05.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Som (2020) Som, M. 2020. 奇异果实。 http://www.aiartonline.com/highlights-2020/mal-som-errthangisalive/.
    访问日期：2021-02-05。
- en: Som (2021) Som, M. 2021. Personal communication.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Som (2021) Som, M. 2021. 个人通信。
- en: Thanh-Tung and Tran (2020) Thanh-Tung, H., and Tran, T. 2020. Catastrophic forgetting
    and mode collapse in GANs. In Proc. International Joint Conference on Neural Networks
    (IJCNN).
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Thanh-Tung 和 Tran（2020）Thanh-Tung, H. 和 Tran, T. 2020. GANs 中的灾难性遗忘和模式崩溃。在国际神经网络联合会议（IJCNN）论文集中。
- en: 'Wang et al. (2020a) Wang, R.; Lehman, J.; Rawal, A.; Zhi, J.; Li, Y.; Clune,
    J.; and Stanley, K. 2020a. Enhanced poet: Open-ended reinforcement learning through
    unbounded invention of learning challenges and their solutions. In Proc. International
    Conference on Machine Learning.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2020a）Wang, R.; Lehman, J.; Rawal, A.; Zhi, J.; Li, Y.; Clune, J.; 和
    Stanley, K. 2020a. 增强型诗人：通过无限创造学习挑战及其解决方案的开放式强化学习。在国际机器学习大会论文集中。
- en: Wang et al. (2020b) Wang, X.; Bylinskii, Z.; Hertzmann, A.; and Pepperell, R.
    2020b. Towards quantifying ambiguities in artistic images. ACM Trans. Appl. Percept.
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang 等人（2020b）Wang, X.; Bylinskii, Z.; Hertzmann, A.; 和 Pepperell, R. 2020b.
    旨在量化艺术图像中的歧义性。《ACM 应用感知学报》。
- en: White (2016) White, T. 2016. Sampling generative networks. arXiv preprint arXiv:1609.04468.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: White（2016）White, T. 2016. 生成网络的采样。arXiv 预印本 arXiv:1609.04468。
- en: Zhu et al. (2017) Zhu, J.-Y.; Park, T.; Isola, P.; and Efros, A. A. 2017. Unpaired
    image-to-image translation using cycle-consistent adversarial networks. In Proc.
    IEEE international conference on computer vision.
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2017）Zhu, J.-Y.; Park, T.; Isola, P.; 和 Efros, A. A. 2017. 使用循环一致对抗网络进行非配对图像到图像的转换。在
    IEEE 国际计算机视觉大会论文集中。
