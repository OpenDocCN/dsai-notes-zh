- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:36:25'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:36:25
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2310.09822] Turn Passive to Active: A Survey on Active Intellectual Property
    Protection of Deep Learning Models'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2310.09822] 从被动到主动：深度学习模型的主动知识产权保护综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2310.09822](https://ar5iv.labs.arxiv.org/html/2310.09822)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2310.09822](https://ar5iv.labs.arxiv.org/html/2310.09822)
- en: 'Turn Passive to Active: A Survey on Active Intellectual Property Protection
    of Deep Learning Models'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 从被动到主动：深度学习模型的主动知识产权保护综述
- en: 'Mingfu Xue, Leo Yu Zhang, Yushu Zhang, and Weiqiang Liu M. Xue, Y. Zhang are
    with the College of Computer Science and Technology, Nanjing University of Aeronautics
    and Astronautics, Nanjing, 211106, China (email: mingfu.xue@nuaa.edu.cn; yushu@nuaa.edu.cn).L.Y.
    Zhang is with the School of Information and Communication Technology, Griffith
    University, QLD, Australia (e-mail: leocityu@gmail.com).W. Liu is with the College
    of Electronic and Information Engineering, Nanjing University of Aeronautics and
    Astronautics, Nanjing, 211106, China (e-mail: liuweiqiang@nuaa.edu.cn).'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 徐名福、张乐优、张玉舒和刘伟强 M. Xue, Y. Zhang 在中国南京航空航天大学计算机科学与技术学院（电子邮件：mingfu.xue@nuaa.edu.cn;
    yushu@nuaa.edu.cn）工作。L.Y. Zhang 在澳大利亚格里菲斯大学信息与通信技术学院（电子邮件：leocityu@gmail.com）工作。W.
    Liu 在中国南京航空航天大学电子与信息工程学院（电子邮件：liuweiqiang@nuaa.edu.cn）工作。
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The intellectual property protection of deep learning (DL) models has attracted
    increasing serious concerns. Many works on intellectual property protection for
    Deep Neural Networks (DNN) models have been proposed. The vast majority of existing
    work uses DNN watermarking to verify the ownership of the model after piracy occurs,
    which is referred to as passive verification. On the contrary, we focus on a new
    type of intellectual property protection method named active copyright protection,
    which refers to active authorization control and user identity management of the
    DNN model. As of now, there is relatively limited research in the field of active
    DNN copyright protection. In this review, we attempt to clearly elaborate on the
    connotation, attributes, and requirements of active DNN copyright protection,
    provide evaluation methods and metrics for active copyright protection, review
    and analyze existing work on active DL model intellectual property protection,
    discuss potential attacks that active DL model copyright protection techniques
    may face, and provide challenges and future directions for active DL model intellectual
    property protection. This review is helpful to systematically introduce the new
    field of active DNN copyright protection and provide reference and foundation
    for subsequent work.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）模型的知识产权保护引起了越来越多的关注。许多关于深度神经网络（DNN）模型知识产权保护的研究已经提出。现有的大多数工作使用 DNN 水印来验证模型的所有权，这被称为被动验证。相反，我们关注一种新型的知识产权保护方法，称为主动版权保护，涉及
    DNN 模型的主动授权控制和用户身份管理。目前，主动 DNN 版权保护领域的研究相对有限。在这篇综述中，我们尝试清晰阐述主动 DNN 版权保护的内涵、属性和要求，提供主动版权保护的评估方法和指标，回顾和分析现有的主动
    DL 模型知识产权保护工作，讨论主动 DL 模型版权保护技术可能面临的潜在攻击，并提供挑战和未来方向。这篇综述有助于系统地介绍主动 DNN 版权保护的新领域，并为后续工作提供参考和基础。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Intellectual property protection of deep learning models, Deep Neural Networks,
    active intellectual property protection, copyright management, active authorization
    control, user identity authentication and management.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习模型的知识产权保护，深度神经网络，主动知识产权保护，版权管理，主动授权控制，用户身份认证与管理。
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Since 2017, the intellectual property (IP) protection of deep learning (DL)
    models has attracted more and more concerns [[1](#bib.bib1), [2](#bib.bib2)].
    Unlike traditional IP protection in the multimedia field, DL model IP protection
    is a new and challenging area where existing techniques cannot be directly applied
    [[2](#bib.bib2)]. As an emerging cutting-edge research direction, Deep Neural
    Networks (DNN) IP protection is still in its early stages. As the deep neural
    networks are applied widely, studying DNN copyright protection has urgent need
    and important significance. In recent years, various deep learning model IP protection
    methods have been proposed [[3](#bib.bib3), [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8), [1](#bib.bib1), [9](#bib.bib9), [10](#bib.bib10),
    [11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16), [17](#bib.bib17), [18](#bib.bib18), [19](#bib.bib19)], most
    of which belong to the category of “passive verification”, which involves embedding
    watermarks in deep learning models or extracting model signatures, and then verifying
    the ownership of suspicious models after piracy and infringement occur. However,
    this kind of passive verification method afterward cannot proactively prevent
    the occurrence of piracy and infringement in the first place. Recently, a small
    number of scholars have paid attention to proactive deep learning model IP protection
    methods, offering promising directions in this emerging research field.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 自2017年以来，深度学习（DL）模型的知识产权（IP）保护引起了越来越多的关注[[1](#bib.bib1), [2](#bib.bib2)]。与多媒体领域的传统知识产权保护不同，深度学习模型知识产权保护是一个新兴且具有挑战性的领域，现有技术不能直接应用[[2](#bib.bib2)]。作为一种前沿研究方向，深度神经网络（DNN）知识产权保护仍处于初期阶段。随着深度神经网络的广泛应用，研究DNN版权保护具有迫切的需求和重要意义。近年来，提出了各种深度学习模型知识产权保护方法[[3](#bib.bib3),
    [4](#bib.bib4), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8),
    [1](#bib.bib1), [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11), [12](#bib.bib12),
    [13](#bib.bib13), [14](#bib.bib14), [15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17),
    [18](#bib.bib18), [19](#bib.bib19)]，其中大多数属于“被动验证”类别，这涉及在深度学习模型中嵌入水印或提取模型签名，然后在发生盗版和侵权后验证可疑模型的所有权。然而，这种被动验证方法不能主动防止盗版和侵权的发生。最近，少数学者开始关注主动深度学习模型知识产权保护方法，提供了这一新兴研究领域的有希望的方向。
- en: In this review, we attempt to clearly and systematically elaborate on the connotation,
    attributes, and requirements of active DL intellectual property protection, provide
    evaluation methods and metrics for active DL copyright protection, review and
    analyze existing active DL model IP protection work, and discuss potential attacks
    that active DL model copyright protection may face. Finally, we will provide insights
    into the challenges and future directions for active DL model IP protection.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中，我们试图清晰且系统地阐述主动深度学习（DL）知识产权保护的内涵、属性和要求，提供主动深度学习版权保护的评估方法和指标，回顾并分析现有的主动深度学习模型知识产权保护工作，并讨论主动深度学习模型版权保护可能面临的潜在攻击。最后，我们将对主动深度学习模型知识产权保护的挑战和未来方向提供见解。
- en: 'The contributions of this work are multi-fold:'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 本工作的贡献有多个方面：
- en: •
  id: totrans-16
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We present the first review focusing on active DL model IP protection, which
    fills a gap in the existing literature.
  id: totrans-17
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首次提出了以主动深度学习模型知识产权保护为重点的综述，填补了现有文献中的空白。
- en: •
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The connotation, attributes, requirements, objectives, evaluation suggestions
    and evaluation metrics of active DL model IP protection have been systematically
    proposed for the first time, providing valuable insights for future research.
  id: totrans-19
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主动深度学习模型知识产权保护的内涵、属性、要求、目标、评估建议和评估指标首次被系统地提出，为未来研究提供了宝贵的见解。
- en: •
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: We conduct a comprehensive review of existing active DL model IP protection
    methods, highlighting their respective advantages and disadvantages.
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对现有的主动深度学习模型知识产权保护方法进行了全面的回顾，突出其各自的优缺点。
- en: •
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Potential attacks that active DL model IP protection may face are thoroughly
    discussed, enhancing the understanding of the security challenges in this domain.
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 彻底讨论了主动深度学习模型知识产权保护可能面临的潜在攻击，增强了对这一领域安全挑战的理解。
- en: •
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The challenges and future directions of active DL model IP protection are presented.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 主动深度学习模型知识产权保护的挑战和未来方向被提出。
- en: 'This paper is organized as follows. The connotation, attributes, requirements,
    objectives and special metrics of active DL IP protection are proposed in Section
    [II](#S2 "II The Connotation, Requirements, and Metrics of Active IP Protection
    for DL Models ‣ Turn Passive to Active: A Survey on Active Intellectual Property
    Protection of Deep Learning Models"). The review of existing active DL model IP
    protection work is presented in Section [III](#S3 "III Overview of Existing DL
    Active Copyright Protection Work ‣ Turn Passive to Active: A Survey on Active
    Intellectual Property Protection of Deep Learning Models"). Section [IV](#S4 "IV
    Attacks Faced by Active DL IP Protection ‣ Turn Passive to Active: A Survey on
    Active Intellectual Property Protection of Deep Learning Models") discusses potential
    specific attacks targeted at active DL IP protection. Section [V](#S5 "V Future
    Directions ‣ Turn Passive to Active: A Survey on Active Intellectual Property
    Protection of Deep Learning Models") presents the challenges and future directions
    of active DL model IP protection. This paper is summarized in Section [VI](#S6
    "VI Conclusion ‣ Turn Passive to Active: A Survey on Active Intellectual Property
    Protection of Deep Learning Models").'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '本文组织如下。第[II](#S2 "II The Connotation, Requirements, and Metrics of Active IP
    Protection for DL Models ‣ Turn Passive to Active: A Survey on Active Intellectual
    Property Protection of Deep Learning Models")节提出了主动DL IP保护的内涵、属性、要求、目标及特殊指标。第[III](#S3
    "III Overview of Existing DL Active Copyright Protection Work ‣ Turn Passive to
    Active: A Survey on Active Intellectual Property Protection of Deep Learning Models")节回顾了现有的主动DL模型IP保护工作。第[IV](#S4
    "IV Attacks Faced by Active DL IP Protection ‣ Turn Passive to Active: A Survey
    on Active Intellectual Property Protection of Deep Learning Models")节讨论了针对主动DL
    IP保护的潜在特定攻击。第[V](#S5 "V Future Directions ‣ Turn Passive to Active: A Survey on
    Active Intellectual Property Protection of Deep Learning Models")节介绍了主动DL模型IP保护的挑战和未来方向。第[VI](#S6
    "VI Conclusion ‣ Turn Passive to Active: A Survey on Active Intellectual Property
    Protection of Deep Learning Models")节对本文进行了总结。'
- en: II The Connotation, Requirements, and Metrics of Active IP Protection for DL
    Models
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 主动DL模型IP保护的内涵、要求和指标
- en: II-A What is Active DL Model IP Protection?
  id: totrans-28
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 什么是主动DL模型IP保护？
- en: 'The work [[2](#bib.bib2)] provides a taxonomy of DNN IP protection methods.
    From a “type” perspective, the taxonomy includes two categories: (i) Passive verification,
    which refers to embedding watermarks in the model and passively verifying the
    model’s copyright when the model is suspected to be pirated. The vast majority
    of existing DNN IP protection works fall under this category. (ii) Active authorization
    control, which focuses on managing and controlling model usage. Only authorized
    users are allowed access, preventing unauthorized use. This paper specifically
    concentrates on this area.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 工作[[2](#bib.bib2)]提供了DNN IP保护方法的分类。从“类型”角度来看，该分类包括两类：(i) 被动验证，即在模型中嵌入水印，并在模型被怀疑被盗版时被动验证模型的版权。绝大多数现有的DNN
    IP保护工作都属于这一类别。(ii) 主动授权控制，重点在于管理和控制模型使用。仅授权用户可以访问，防止未经授权的使用。本文特别集中于这一领域。
- en: 'From a “function” perspective, DNN copyright protection methods can be divided
    into [[2](#bib.bib2)]: (i) Copyright verification, which means verifying the model
    ownership, and most existing work belongs to this category; (ii) Copyright management,
    which involves authentication and management of users’ identities, as well as
    active authorization control of users’ usage. This is a necessary function of
    commercial DNN and also the focus and innovation point of this paper. The illustration
    of passive ownership verification and active authorization control is shown in
    Fig. [1](#S2.F1 "Figure 1 ‣ II-A What is Active DL Model IP Protection? ‣ II The
    Connotation, Requirements, and Metrics of Active IP Protection for DL Models ‣
    Turn Passive to Active: A Survey on Active Intellectual Property Protection of
    Deep Learning Models").'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '从“功能”角度来看，DNN版权保护方法可以分为[[2](#bib.bib2)]： (i) 版权验证，即验证模型所有权，大多数现有工作属于这一类别；(ii)
    版权管理，涉及用户身份的认证和管理，以及对用户使用的主动授权控制。这是商业DNN的必要功能，也是本文的重点和创新点。图[1](#S2.F1 "Figure
    1 ‣ II-A What is Active DL Model IP Protection? ‣ II The Connotation, Requirements,
    and Metrics of Active IP Protection for DL Models ‣ Turn Passive to Active: A
    Survey on Active Intellectual Property Protection of Deep Learning Models")展示了被动所有权验证和主动授权控制的示意图。'
- en: '![Refer to caption](img/a9dbe0df6a403e1c44670f2c12d04aae.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/a9dbe0df6a403e1c44670f2c12d04aae.png)'
- en: 'Figure 1: Illustration of passive ownership verification and active authorization
    control.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：被动所有权验证和主动授权控制的示意图。
- en: Numerous methods for protecting DNN copyright have emerged, yet a significant
    portion relies on passive verification, unable to proactively prevent piracy and
    infringement. While many concentrate on model ownership verification, few address
    user authentication and management of unique identities. This is a necessary and
    key function of commercial copyright management. Besides, it is vulnerable to
    attacks by dishonest users, such as collusion attacks. Such vulnerabilities hinder
    the broad commercial use and deployment of DL models.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管出现了许多保护DNN版权的方法，但相当一部分依赖于被动验证，无法主动防止盗版和侵权。虽然许多方法集中在模型所有权验证上，但很少涉及用户身份认证和唯一身份管理。这是商业版权管理的必要和关键功能。此外，它还容易受到不诚实用户的攻击，例如串通攻击。这些漏洞阻碍了深度学习模型的广泛商业使用和部署。
- en: 'Given the escalating application demands for deep learning copyright protection
    and the need to overcome existing challenges, we deem the exploration of proactive
    protection methods for deep learning models imperative and vital. This review
    is committed to addressing the following challenges and attaining the ensuing
    objectives:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于深度学习版权保护的应用需求不断升级，并且需要克服现有挑战，我们认为探索深度学习模型的主动保护方法是至关重要的。本综述致力于解决以下挑战，并实现相应的目标：
- en: •
  id: totrans-35
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Most of the existing work uses DNN watermarks to verify the copyright of DNN
    after the occurrence of piracy and infringement. Can we proactively prevent the
    occurrence of piracy and infringement in advance — active authorization control?
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数现有工作使用DNN水印在发生盗版和侵权后验证DNN版权。我们能否主动防止盗版和侵权的发生——主动授权控制？
- en: •
  id: totrans-37
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to distinguish different DNN users in order to meet the needs of commercial
    DNN copyright protection — user identity authentication and management (i.e. copyright
    management)?
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何区分不同的深度神经网络（DNN）用户，以满足商业DNN版权保护的需求——用户身份认证与管理（即版权管理）？
- en: •
  id: totrans-39
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The various attacks considered in existing work are mostly aimed at DNN watermarks
    (passive copyright verification). In response to the new direction discussed in
    this study — active authorization control, what attacks and bypass mechanisms
    may exist?
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现有工作的各种攻击主要针对DNN水印（被动版权验证）。针对本研究讨论的新方向——主动授权控制，可能存在哪些攻击和绕过机制？
- en: •
  id: totrans-41
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: How to evaluate DNN copyright protection methods based on the needs of commercial
    applications, in particular, how to evaluate the new direction — DNN active authorization
    control?
  id: totrans-42
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 如何根据商业应用的需求评估DNN版权保护方法，特别是如何评估新方向——DNN主动授权控制？
- en: 'In order to achieve the aforementioned objectives, it becomes imperative to
    study and solve the following technical difficulties/challenges in active authorization
    control schemes: (i) how to construct unique users’ identities; (ii) how to generate
    imperceptible users’ fingerprints to resist attacks or fingerprint leakage; (iii)
    how to enable the DNN model to distinguish between authorized and unauthorized
    users; (iv) how to distinguish different authorized users; (v) how to control
    the functionality and performance of DNN models differently based on different
    users.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 为实现上述目标，必须研究并解决主动授权控制方案中的以下技术难题/挑战：（i）如何构建唯一用户身份；（ii）如何生成隐形用户指纹以抵御攻击或指纹泄漏；（iii）如何使DNN模型区分授权用户与未授权用户；（iv）如何区分不同的授权用户；（v）如何根据不同用户控制DNN模型的功能和性能。
- en: 'An active DL model copyright protection method possesses the capacity to proactively
    thwart piracy. In addition, most existing methods embed watermarks or extract
    fingerprints from the model to verify the ownership of the model, but do not consider
    copyright management. Addressing the pressing requirement for robust commercial
    DNN copyright protection necessitates the effective authentication and management
    of user identities. To this end, the DL model active IP protection (also known
    as copyright management) framework includes two modules: user identity authentication
    and management, and active authorization control, as shown in Fig. [2](#S2.F2
    "Figure 2 ‣ II-A What is Active DL Model IP Protection? ‣ II The Connotation,
    Requirements, and Metrics of Active IP Protection for DL Models ‣ Turn Passive
    to Active: A Survey on Active Intellectual Property Protection of Deep Learning
    Models").'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: '主动深度学习模型版权保护方法具备主动抵御盗版的能力。此外，大多数现有方法嵌入水印或从模型中提取指纹以验证模型的所有权，但并未考虑版权管理。解决对强大商业深度神经网络版权保护的迫切需求需要有效的用户身份认证和管理。为此，深度学习模型主动IP保护（也称为版权管理）框架包括两个模块：用户身份认证和管理，以及主动授权控制，如图[2](#S2.F2
    "Figure 2 ‣ II-A What is Active DL Model IP Protection? ‣ II The Connotation,
    Requirements, and Metrics of Active IP Protection for DL Models ‣ Turn Passive
    to Active: A Survey on Active Intellectual Property Protection of Deep Learning
    Models")所示。'
- en: '![Refer to caption](img/64ea32c3c25d5998ba9a2eabd7a8dbfe.png)'
  id: totrans-45
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/64ea32c3c25d5998ba9a2eabd7a8dbfe.png)'
- en: 'Figure 2: The framework of active IP protection for DL models.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：深度学习模型的主动IP保护框架。
- en: 'The active authorization control module involves:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 主动授权控制模块涉及：
- en: •
  id: totrans-48
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Distinguish between authorized and unauthorized users: The model must differentiate
    between authorized and unauthorized users.'
  id: totrans-49
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 区分授权用户和未授权用户：模型必须能够区分授权用户和未授权用户。
- en: •
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Distinguish between different authorized users: The model should be able to
    distinguish between different authorized users.'
  id: totrans-51
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 区分不同的授权用户：模型应能够区分不同的授权用户。
- en: •
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Differentiate the functionality and performance of the DL model based on different
    users: The DL model should be able to provide different functions and performance
    based on the identity of users. Authorized users can use the DL model normally
    and achieve normal performance, while unauthorized users cannot use the model
    or can only achieve extremely low model performance.'
  id: totrans-53
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于不同用户区分深度学习模型的功能和性能：深度学习模型应根据用户的身份提供不同的功能和性能。授权用户可以正常使用深度学习模型并获得正常性能，而未授权用户则无法使用该模型或只能获得极低的模型性能。
- en: 'The user identity authentication and management module involves:'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 用户身份认证和管理模块涉及：
- en: •
  id: totrans-55
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'User fingerprint generation: Generate a unique user fingerprint/identity for
    each authorized user. Besides, in order to resist attacks or fingerprint leakages,
    the ideal user fingerprint should be visually imperceptible.'
  id: totrans-56
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户指纹生成：为每个授权用户生成唯一的用户指纹/身份。此外，为了抵御攻击或指纹泄漏，理想的用户指纹应当是视觉上不可察觉的。
- en: •
  id: totrans-57
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'User fingerprint allocation: Each authorized user is assigned a unique user
    fingerprint, which should be able to resist collusion attacks, forgery attacks,
    etc.'
  id: totrans-58
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户指纹分配：每个授权用户被分配一个唯一的用户指纹，该指纹应能够抵御串通攻击、伪造攻击等。
- en: •
  id: totrans-59
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'User fingerprint authentication and tracking: The model can extract the user’s
    fingerprint from the input for authentication, and can track the user’s identity.'
  id: totrans-60
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户指纹认证和追踪：模型可以从输入中提取用户的指纹进行认证，并可以追踪用户的身份。
- en: 'To address the pressing need for commercial DNN copyright protection, and to
    overcome current research limitations, it is imperative to explore proactive DNN
    copyright protection mechanisms. These mechanisms should be based on active authorization
    control and user identity authentication and management (copyright management).
    Key components of this endeavor include: (i) Study unique user fingerprint generation,
    allocation, authentication and management methods for DNN; (ii) Establish an active
    authorization control mechanism that distinguishes between authorized and unauthorized
    users for DNN models; (iii) Study the attack and bypass mechanisms against DNN
    active authorization control (all existing attacks are targeted at DNN watermark),
    and carry out hierarchical attack mechanism research according to the capabilities
    of different attackers; (iv) Establish a comprehensive evaluation framework for
    DNN copyright protection methods, covering basic functional metrics and attack
    resistance metrics, with a particular focus on evaluation methods for newly proposed
    active authorization control mechanisms (the evaluation metrics for active authorization
    control are different from those of existing DNN watermarks). Active copyright
    protection can solve bottlenecks such as passivity in DNN watermarks and difficulty
    in copy management. It also addresses intricate issues such as active authorization
    control, authentication and tracking of DNN user identities, thus can lay a theoretical
    foundation for constructing an active, secure, and robust DNN copyright protection
    mechanism, and provide theoretical and technical support for DNN’s commercial
    applications.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了应对商业深度神经网络（DNN）版权保护的迫切需求，并克服当前研究的局限性，探索主动的DNN版权保护机制至关重要。这些机制应基于主动授权控制和用户身份认证与管理（版权管理）。该工作的关键组成部分包括：
    (i) 研究DNN的独特用户指纹生成、分配、认证和管理方法； (ii) 建立一个主动授权控制机制，用于区分DNN模型的授权用户和未授权用户； (iii) 研究针对DNN主动授权控制的攻击和绕过机制（所有现有攻击均针对DNN水印），并根据不同攻击者的能力进行分层攻击机制研究；
    (iv) 建立一个全面的DNN版权保护方法评估框架，涵盖基本功能指标和抗攻击指标，特别关注新提出的主动授权控制机制的评估方法（主动授权控制的评估指标与现有DNN水印的评估指标不同）。主动版权保护可以解决DNN水印的被动性和拷贝管理难度等瓶颈问题，同时解决主动授权控制、DNN用户身份认证和跟踪等复杂问题，从而为构建一个主动、安全且稳健的DNN版权保护机制奠定理论基础，并为DNN的商业应用提供理论和技术支持。
- en: II-B Unique Metrics for Active DL IP Protection
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 独特的主动深度学习知识产权保护度量
- en: The assessment of existing DNN IP protection methods has predominantly revolved
    around metrics tailored to DNN watermarking, leaving a research gap in terms of
    evaluation metrics for DNN active authorization control. This paper introduces
    a novel aspect by formulating evaluation metrics for DNN active authorization
    control, distinct from conventional DNN watermarking approaches. Furthermore,
    the existing focus on functional metrics has often overshadowed the need for robust
    attack-resistance metrics. This paper discusses the unique metrics for active
    DL IP protection, which are divided into basic functional metrics and attack-resistance
    metrics. The proposed functional metrics for active authorization control include
    cost, user authentication success rate, model performance that authorized users
    can obtain, model performance that unauthorized users can obtain, uniqueness of
    user identity, number of supported users, convenience of deployment, knowledge
    of the target model, interpretability, etc. The proposed attack-resistance metrics
    for active authorization control include user identity concealment, resistance
    to sample modification attacks, user identity unforgeability, resistance to adaptive
    attacks, and resistance to reverse analysis, etc. The unique metrics for active
    DL IP protection proposed in this study can provide evaluation references for
    subsequent related work in this field, and can also provide feedback on improving
    active copyright protection mechanisms based on the evaluation results.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 现有DNN IP保护方法的评估主要围绕DNN水印定制的指标展开，这在DNN主动授权控制的评估指标方面留下了研究空白。本文通过制定DNN主动授权控制的评估指标，引入了一种新颖的视角，这些指标不同于传统的DNN水印方法。此外，现有的功能指标关注常常掩盖了对强大攻击抵抗指标的需求。本文讨论了用于主动深度学习IP保护的独特指标，这些指标分为基本功能指标和攻击抵抗指标。针对主动授权控制提出的功能指标包括：成本、用户认证成功率、授权用户能够获得的模型性能、未经授权用户能够获得的模型性能、用户身份的唯一性、支持的用户数量、部署便利性、对目标模型的了解、可解释性等。针对主动授权控制提出的攻击抵抗指标包括：用户身份隐蔽性、抵抗样本修改攻击、用户身份不可伪造性、抵抗自适应攻击以及抵抗逆向分析等。本文提出的主动深度学习IP保护的独特指标可以为后续相关工作的评估提供参考，也可以根据评估结果提供改进主动版权保护机制的反馈。
- en: Specifically, this paper proposes the following unique metrics for DNN active
    authorization control, which are different from the common metrics for DNN watermarks.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 具体来说，本文提出了针对DNN主动授权控制的以下独特指标，这些指标不同于常见的DNN水印指标。
- en: 'Basic functional metrics include:'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 基本功能指标包括：
- en: •
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Overhead: The overhead introduced by the active authorization control scheme
    should be low or no overhead, within the range that model owners and users can
    afford.'
  id: totrans-67
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开销：主动授权控制方案引入的开销应当低或没有开销，保持在模型所有者和用户可以接受的范围内。
- en: •
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Success rate of user identity authentication: In the active authorization control
    scheme, user identity authentication and management are introduced, and the success
    rate of user identity authentication needs to be evaluated.'
  id: totrans-69
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户身份认证成功率：在主动授权控制方案中，介绍了用户身份认证和管理，需要评估用户身份认证的成功率。
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model performance that authorized users can obtain: In the active authorization
    control scheme, the model usage and model performance of authorized and unauthorized
    users are differentiated, and authorized users should be able to achieve high
    model performance.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 授权用户能够获得的模型性能：在主动授权控制方案中，区分了授权和未经授权用户的模型使用情况和模型性能，授权用户应能够获得高水平的模型性能。
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Model performance that unauthorized users can obtain: In the active authorization
    control scheme, the model usage and performance of authorized and unauthorized
    users are differentiated, and unauthorized users should achieve extremely low
    model performance, or even be unable to use the model.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 未经授权用户能够获得的模型性能：在主动授权控制方案中，区分了授权和未经授权用户的模型使用情况和性能，未经授权的用户应当只能获得极低的模型性能，甚至无法使用该模型。
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Uniqueness of user identity: In the active authorization control scheme, user
    identity authentication and management are included, and each user’s identity
    should be unique.'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户身份的唯一性：在主动授权控制方案中，包含了用户身份认证和管理，每个用户的身份应当是唯一的。
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Number of supported users: In the active authorization control scheme, unique
    identities are generated for users for authorization control, and the scheme should
    be able to support a large number of users’ identities generation.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 支持用户的数量：在主动授权控制方案中，为用户生成唯一身份进行授权控制，该方案应能够支持大量用户身份的生成。
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Convenience of deployment: Does the active authorization control scheme require
    training from scratch to be implemented, or can it be implemented through fine-tuning?'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 部署的便利性：主动授权控制方案是否需要从头开始进行培训才能实施，还是可以通过微调实现？
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Knowledge of the target model: The ideal scenario is that the solution can
    be applied to black-box scenarios, rather than only white-box scenarios.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 目标模型的知识：理想的情况是解决方案可以应用于黑箱场景，而不仅仅是白箱场景。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Interpretability: The interpretability of the protection scheme is a requirement
    in some commercial applications.'
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 可解释性：保护方案的可解释性在一些商业应用中是一个要求。
- en: 'Attack-resistance metrics include:'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 抵御攻击的指标包括：
- en: •
  id: totrans-85
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'The concealment of user identity: In active authorization control schemes,
    in order to prevent attacks or leakage of user identities, the user identities
    embedded in images and samples should be visually imperceptible and have good
    concealment.'
  id: totrans-86
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户身份的隐蔽性：在主动授权控制方案中，为了防止攻击或用户身份泄露，嵌入在图像和样本中的用户身份应具备视觉隐蔽性，且隐蔽性良好。
- en: •
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Resistance to sample modification attacks: In active authorization control
    schemes, legitimate samples or samples containing user identities should be able
    to resist malicious modifications to the samples.'
  id: totrans-88
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 抵御样本修改攻击：在主动授权控制方案中，合法样本或包含用户身份的样本应能够抵御对样本的恶意修改。
- en: •
  id: totrans-89
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'User identity unforgeability: In active authorization control schemes, the
    identity of authorized users should be unforgeable, making it difficult for attackers
    to forge a legitimate user identity, and the user identity forged by the attacker
    cannot pass the authentication of the model.'
  id: totrans-90
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 用户身份不可伪造性：在主动授权控制方案中，授权用户的身份应不可伪造，使攻击者难以伪造合法用户身份，并且攻击者伪造的用户身份无法通过模型的认证。
- en: •
  id: totrans-91
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Resistance to adaptive attacks: In the worst-case scenario, the attacker knows
    the mechanism of active copyright protection, and the active authorization control
    scheme should be able to resist such adaptive attacks.'
  id: totrans-92
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 对自适应攻击的抵抗：在最坏的情况下，攻击者了解主动版权保护机制，主动授权控制方案应能够抵御此类自适应攻击。
- en: •
  id: totrans-93
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Reverse analysis resistance: The attacker attempts to reverse the active authorization
    control mechanism and disrupt it, and the active IP protection scheme should be
    able to resist reverse analysis.'
  id: totrans-94
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 反向分析抵抗：攻击者尝试逆向分析主动授权控制机制并进行破坏，主动IP保护方案应能够抵御反向分析。
- en: III Overview of Existing DL Active Copyright Protection Work
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 现有深度学习主动版权保护工作的概述
- en: 'The majority of existing DL copyright protection methods fall within the category
    of passive DNN watermark verification. These techniques are reactive in nature,
    as they verify model copyright after piracy or infringement have occurred. However,
    there is a growing body of research dedicated to proactive DL copyright protection,
    aiming to prevent piracy and infringement proactively. These proactive DL active
    copyright protection efforts mostly focus on providing active authorization control
    for the model, which can distinguish between authorized and unauthorized users
    (authorized users can use the model or achieve high performance, while unauthorized
    users cannot use the model or achieve low performance), but do not consider user
    identity authentication and management, which cannot track the identity of authorized
    users and distinguish different authorized users. In the following, we will review
    the existing DL active copyright protection work from two aspects: (i) active
    authorization control; (ii) both active authorization control and user identity
    management. The overview of existing active DL copyright protection work is shown
    in Table [I](#S3.T1 "TABLE I ‣ III Overview of Existing DL Active Copyright Protection
    Work ‣ Turn Passive to Active: A Survey on Active Intellectual Property Protection
    of Deep Learning Models").'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '现有的深度学习版权保护方法大多属于被动 DNN 水印验证类别。这些技术本质上是反应性的，因为它们在盗版或侵权发生后才验证模型版权。然而，越来越多的研究致力于主动深度学习版权保护，旨在主动防止盗版和侵权。这些主动的深度学习版权保护工作主要集中在为模型提供主动授权控制，能够区分授权用户和未授权用户（授权用户可以使用模型或获得高性能，而未授权用户无法使用模型或只能获得低性能），但未考虑用户身份认证和管理，无法追踪授权用户的身份并区分不同的授权用户。接下来，我们将从两个方面回顾现有的深度学习主动版权保护工作：（i）主动授权控制；（ii）既有主动授权控制又有用户身份管理。现有主动深度学习版权保护工作的概述见表
    [I](#S3.T1 "TABLE I ‣ III Overview of Existing DL Active Copyright Protection
    Work ‣ Turn Passive to Active: A Survey on Active Intellectual Property Protection
    of Deep Learning Models")。'
- en: 'TABLE I: Existing Active DL Copyright Protection Work'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 现有主动深度学习版权保护工作'
- en: '| Work | Mechanism | Authorization control | User identity authentication and
    management |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 工作 | 机制 | 授权控制 | 用户身份认证和管理 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Chen and Wu [[20](#bib.bib20)] | preprocess the input via a conversion module
    based on adversarial perturbation | ✓ | – |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| Chen 和 Wu [[20](#bib.bib20)] | 通过基于对抗性扰动的转换模块对输入进行预处理 | ✓ | – |'
- en: '| Fan et al. [[21](#bib.bib21)] | unless a valid passport is provided, the
    DNN model will not function properly | ✓ | – |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| Fan 等人 [[21](#bib.bib21)] | 除非提供有效的护照，否则 DNN 模型将无法正常运行 | ✓ | – |'
- en: '| Ren et al. [[22](#bib.bib22)] | lock the model, and only specific tokens
    can unlock the model | ✓ | – |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| Ren 等人 [[22](#bib.bib22)] | 锁定模型，仅特定的令牌可以解锁模型 | ✓ | – |'
- en: '| Lin et al. [[23](#bib.bib23)] | model encryption based on chaotic weights
    | ✓ | – |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| Lin 等人 [[23](#bib.bib23)] | 基于混沌权重的模型加密 | ✓ | – |'
- en: '| AprilPyone and Kiya [[24](#bib.bib24)] | applying block transformation with
    a key to feature maps for authorization control | ✓ | – |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| AprilPyone 和 Kiya [[24](#bib.bib24)] | 使用带有密钥的块变换对特征图进行授权控制 | ✓ | – |'
- en: '| Xue et al. [[25](#bib.bib25)] | based on gradients, the few parameters that
    have the greatest impact on model performance are slightly perturbed, thereby
    encrypting the model | ✓ | – |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| Xue 等人 [[25](#bib.bib25)] | 基于梯度，对对模型性能影响最大的少量参数进行微小扰动，从而对模型进行加密 | ✓ | –
    |'
- en: '| Luo et al. [[26](#bib.bib26)] | perturb the output of the model to varying
    degrees to achieve hierarchical performance | ✓ | – |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| Luo 等人 [[26](#bib.bib26)] | 对模型的输出进行不同程度的扰动，以实现分层性能 | ✓ | – |'
- en: '| Pan et al. [[27](#bib.bib27)] | the model weights were encrypted/decrypted
    based on permutation and diffusion, and a key bound to the device was generated
    based on PUF | ✓ | – |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| Pan 等人 [[27](#bib.bib27)] | 模型权重基于置换和扩散进行加密/解密，并生成了一个与设备绑定的基于 PUF 的密钥 | ✓
    | – |'
- en: '| Chakraborty et al. [[28](#bib.bib28)] | confusion framework for hardware
    NN, which requires authorization through the key in the hardware | ✓ | – |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| Chakraborty 等人 [[28](#bib.bib28)] | 针对硬件神经网络的混淆框架，需要通过硬件中的密钥进行授权 | ✓ | –
    |'
- en: '| Xue et al. [[29](#bib.bib29)] | a user fingerprint management and DNN authorization
    control framework based on multi-trigger backdoor | ✓ | ✓ |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| Xue 等人 [[29](#bib.bib29)] | 基于多触发后门的用户指纹管理和 DNN 授权控制框架 | ✓ | ✓ |'
- en: '| Tang et al. [[30](#bib.bib30)] | teacher-student model, in which the customer
    DNN can only function properly when the customer enters a valid serial number
    | ✓ | ✓ |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| Tang et al. [[30](#bib.bib30)] | 教师-学生模型，其中客户DNN仅在客户输入有效序列号时才能正常工作 | ✓ |
    ✓ |'
- en: '| Wang et al. [[31](#bib.bib31)] | embed different backdoors into the model
    to generate a number of user model instances for different users | ✓ | ✓ |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| Wang et al. [[31](#bib.bib31)] | 将不同的后门嵌入模型中，为不同用户生成多个用户模型实例 | ✓ | ✓ |'
- en: '| Chen et al. [[32](#bib.bib32)] | encoding each constructed user fingerprint
    in the probability density function of the weights | ✓ | ✓ |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| Chen et al. [[32](#bib.bib32)] | 在权重的概率密度函数中编码每个构造的用户指纹 | ✓ | ✓ |'
- en: '| Xue et al. [[33](#bib.bib33)] | using carefully crafted adversarial examples
    (with specific categories and specific confidences) as user fingerprints | ✓ |
    ✓ |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| Xue et al. [[33](#bib.bib33)] | 使用精心制作的对抗样本（具有特定类别和特定置信度）作为用户指纹 | ✓ | ✓ |'
- en: '| Xue et al. [[34](#bib.bib34)] | using an additional class and user identity
    information embedded through steganography to support both user identity authentication
    and model ownership verification | ✓ | ✓ |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| Xue et al. [[34](#bib.bib34)] | 使用额外类别和通过隐写术嵌入的用户身份信息，以支持用户身份验证和模型所有权验证 |
    ✓ | ✓ |'
- en: '| Fan et al. [[35](#bib.bib35)] | using an additional class, authorization
    control, and image perceptual hash | ✓ | ✓ |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| Fan et al. [[35](#bib.bib35)] | 使用额外类别、授权控制和图像感知哈希 | ✓ | ✓ |'
- en: '| Wu et al. [[36](#bib.bib36)] | reverse and multiple use of sample-specific
    backdoors for authorization control and embed imperceptible user identity information
    | ✓ | ✓ |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| Wu et al. [[36](#bib.bib36)] | 反向和多次使用样本特定的后门进行授权控制，并嵌入不可感知的用户身份信息 | ✓ |
    ✓ |'
- en: III-A Active Authorization Control
  id: totrans-117
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 主动授权控制
- en: Chen et al. [[20](#bib.bib20)] propose a DNN access control framework so that
    only authorized users can use the model normally. They design a conversion module
    based on adversarial examples to provide authorized input, where adversarial disturbance
    is added to the input. Authorized users can use conversion modules to preprocess
    inputs, resulting in high model performance. In contrast, unauthorized users who
    directly provide input to the model will result in poor model performance.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: Chen et al. [[20](#bib.bib20)] 提出了一个DNN访问控制框架，使得只有授权用户才能正常使用模型。他们设计了一个基于对抗样本的转换模块来提供授权输入，其中对抗扰动被添加到输入中。授权用户可以使用转换模块来预处理输入，从而获得高模型性能。相反，未经授权的用户直接将输入提供给模型将导致模型性能差。
- en: Fan et al. [[21](#bib.bib21)] propose embedding specific passports into neural
    networks. The inference performance of the DNN model is adjusted based on the
    provided passport, that is, the inference performance of the pre-trained DNN model
    will remain unchanged in the presence of a valid passport, or significantly deteriorate
    due to passport modification or forgery. Unless a valid passport is provided,
    the DNN model will not function properly, thus preventing illegal use of the model.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Fan et al. [[21](#bib.bib21)] 提出了将特定护照嵌入神经网络的方法。DNN模型的推断性能会根据提供的护照进行调整，即在存在有效护照的情况下，预训练的DNN模型的推断性能将保持不变，或者由于护照的修改或伪造而显著恶化。除非提供有效的护照，否则DNN模型将无法正常工作，从而防止模型的非法使用。
- en: Ren et al. [[22](#bib.bib22)] propose a model-locking scheme for deep learning,
    aimed at preventing attackers from achieving high prediction accuracy even if
    they pirate the model. If a specific token does not exist in the input, the locked
    DNN model will provide poor prediction accuracy. When the input contains the specifically
    designed authorization token, the model can make normal predictions.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: Ren et al. [[22](#bib.bib22)] 提出了一个针对深度学习的模型锁定方案，旨在防止攻击者即使盗取模型也能实现高预测精度。如果输入中不存在特定的令牌，则锁定的DNN模型将提供较差的预测精度。当输入中包含特定设计的授权令牌时，模型可以正常预测。
- en: Lin et al. [[23](#bib.bib23)] propose a chaotic weight framework based on chaotic
    mapping theory, which achieves an encryption effect by exchanging weight positions,
    making the kernel of convolutional or fully connected layers chaotic. Unless the
    model is decrypted, an incorrect prediction result will be returned. These encryption-based
    implementations may affect the performance of the model or introduce high overhead.
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: Lin et al. [[23](#bib.bib23)] 提出了基于混沌映射理论的混沌权重框架，通过交换权重位置实现加密效果，使卷积层或全连接层的核心变得混沌。除非模型被解密，否则将返回错误的预测结果。这些基于加密的实现可能会影响模型性能或引入较高的开销。
- en: AprilPyone and Kiya [[24](#bib.bib24)] propose a protection method with keys
    for convolutional neural network (CNN) models, which applies block transformations
    with keys to feature maps, enabling authorized users to achieve high classification
    accuracy while unauthorized users achieve low classification accuracy.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: AprilPyone 和 Kiya [[24](#bib.bib24)] 提出了一个带密钥的卷积神经网络（CNN）模型保护方法，该方法对特征图应用了带密钥的块变换，使授权用户能够实现高分类准确率，而未经授权的用户则实现低分类准确率。
- en: 'Xue et al. [[25](#bib.bib25)] propose an active DNN copyright protection based
    on parameter perturbation, as shown in Fig. [3](#S3.F3 "Figure 3 ‣ III-A Active
    Authorization Control ‣ III Overview of Existing DL Active Copyright Protection
    Work ‣ Turn Passive to Active: A Survey on Active Intellectual Property Protection
    of Deep Learning Models"). The extremely small number of parameters that have
    the greatest impact on model performance are slightly perturbed based on gradient.
    By encrypting a very low number of parameters, the accuracy of the model can be
    significantly reduced. Authorized users can decrypt models in MLaaS and achieve
    high-accuracy model performance.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: Xue 等人 [[25](#bib.bib25)] 提出了基于参数扰动的主动 DNN 版权保护，如图 [3](#S3.F3 "图 3 ‣ III-A 主动授权控制
    ‣ III 现有 DL 主动版权保护工作概述 ‣ 从被动到主动：深度学习模型主动知识产权保护的调查") 所示。对对模型性能影响最大的极少量参数进行基于梯度的轻微扰动。通过加密极少量的参数，可以显著降低模型的准确性。授权用户可以在
    MLaaS 中解密模型并实现高精度的模型性能。
- en: '![Refer to caption](img/77474de7729ccb5f0812b0c265fd82c8.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/77474de7729ccb5f0812b0c265fd82c8.png)'
- en: 'Figure 3: DNN active authorization control based on parameter perturbation
    [[25](#bib.bib25)].'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：基于参数扰动的 DNN 主动授权控制 [[25](#bib.bib25)]。
- en: Luo et al. [[26](#bib.bib26)] propose a multi-user hierarchical authorization
    for CNN, which can help owners control output results based on different levels
    of access permissions. They refer to differential privacy and use the Laplace
    mechanism to perturb the output of the model to different degrees to achieve the
    hierarchical performance.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: Luo 等人 [[26](#bib.bib26)] 提出了一个用于 CNN 的多用户分层授权方法，该方法可以帮助所有者根据不同级别的访问权限控制输出结果。他们参考了差分隐私，并使用拉普拉斯机制对模型的输出进行不同程度的扰动，以实现分层性能。
- en: Pan et al. [[27](#bib.bib27)] encrypt/decrypt the model weights based on permutation
    and diffusion to achieve IP protection, and a key bound to the device was generated
    based on Physical Unclonable Function (PUF). This method is targeted at DL hardware
    and has a high overhead.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: Pan 等人 [[27](#bib.bib27)] 基于置换和扩散对模型权重进行加密/解密，以实现知识产权保护，并生成了一个基于物理不可克隆功能（PUF）的设备绑定密钥。这种方法针对
    DL 硬件，并且开销较高。
- en: Chakraborty et al. [[28](#bib.bib28)] propose a hardware neural network confusion
    framework that requires a key in hardware for authorization to be used. The model
    owner first uses the key-based backpropagation to train the DNN architecture,
    which blurs the weight space of the model, and then hosts the deep learning model
    in the shared platform. Only authorized users with hardware-trusted roots (on-chip
    memory with an embedded key) can use the deep learning model. The above-mentioned
    hardware DNN copyright protection work focuses on the copyright protection of
    DNN hardware devices, and requires hardware platforms for support, such as hardware
    trusted roots, resulting in high costs.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: Chakraborty 等人 [[28](#bib.bib28)] 提出了一个硬件神经网络混淆框架，该框架要求硬件中有一个密钥用于授权。模型所有者首先使用基于密钥的反向传播来训练
    DNN 架构，这会模糊模型的权重空间，然后将深度学习模型托管在共享平台上。只有拥有硬件信任根（带嵌入密钥的片上存储器）的授权用户才能使用深度学习模型。上述硬件
    DNN 版权保护工作关注 DNN 硬件设备的版权保护，并且需要硬件平台的支持，如硬件信任根，这导致了高成本。
- en: III-B User Identity Authentication and Management
  id: totrans-129
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 用户身份认证和管理
- en: The DL copyright protection methods discussed earlier prioritize authorization
    control but do not address user identity authentication and management. Consequently,
    they do not fully align with the requirements of commercial DL copyright management.
    Furthermore, they are also susceptible to attacks initiated by dishonest users,
    such as collusion attacks. Recently, a limited body of research focus on the development
    of active copyright protection techniques that support both authorization control
    and user identity authentication and management.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的DL版权保护方法优先考虑授权控制，但未涉及用户身份认证和管理。因此，它们未能完全符合商业DL版权管理的要求。此外，它们也容易受到不诚实用户发起的攻击，例如勾结攻击。最近，有限的研究集中于开发支持授权控制和用户身份认证及管理的主动版权保护技术。
- en: Xue et al. [[29](#bib.bib29)] propose a user fingerprint management and DNN
    authorization control framework based on multi-trigger backdoors [[37](#bib.bib37)].
    First, $N$ sub-backdoors are implanted in the DNN model. Then, a small group of
    images with $n$ ($n<N$) subbackdoor triggers corresponding to moderate confidence
    are assigned to authorized users as their unique fingerprints. Only the model
    owner has all the $N$ backdoor triggers corresponding to high confidence, which
    are used to verify the ownership of the model. In this way, both user identity
    authentication and ownership verification can be achieved.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 薛等人[[29](#bib.bib29)]提出了一种基于多触发后门[[37](#bib.bib37)]的用户指纹管理和DNN授权控制框架。首先，在DNN模型中植入$N$个子后门。然后，将一小组图像（具有$n$
    ($n<N$)个子后门触发器对应于中等置信度）分配给授权用户作为其唯一的指纹。只有模型所有者拥有所有$N$个对应于高置信度的后门触发器，用于验证模型的所有权。通过这种方式，既可以实现用户身份认证，也可以实现所有权验证。
- en: Tang et al. [[30](#bib.bib30)] propose a watermarking method based on deep serial
    numbers. First, a private teacher DNN model was trained, and then their knowledge
    was extracted and transferred to a series of customized student DNN models. During
    the distillation process, each customer DNN has a unique serial number, which
    is an encrypted 0/1 trigger pattern. The customer DNN can only function properly
    when the customer enters a valid serial number.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 唐等人[[30](#bib.bib30)]提出了一种基于深度序列号的水印方法。首先，训练了一个私有教师DNN模型，然后将其知识提取并转移到一系列定制的学生DNN模型中。在蒸馏过程中，每个客户DNN具有一个唯一的序列号，这是一个加密的0/1触发模式。客户DNN只有在客户输入有效的序列号时才能正常工作。
- en: Wang et al. [[31](#bib.bib31)] propose a buyer-traceable DNN model IP protection
    method. They embed different backdoors defined by owners into the model through
    training data poisoning with dirty labels, and generate a large number of user
    model instances that maintain accuracy for different buyers. Each backdoor training
    model can be triggered by a set of special validation images. Model instances
    sold to different buyers can be uniquely distinguished by triggering their specific
    backdoors.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 王等人[[31](#bib.bib31)]提出了一种买家可追溯的DNN模型IP保护方法。他们通过带有脏标签的训练数据中毒将不同的后门嵌入到模型中，并生成大量保持准确性的用户模型实例，以供不同买家使用。每个后门训练模型可以通过一组特殊的验证图像触发。售给不同买家的模型实例可以通过触发其特定的后门唯一区分。
- en: Chen et al. [[32](#bib.bib32)] state that in large-scale model distribution
    systems, multiple users can use their respective watermarked models to collaborate
    and construct an unmarked high-performance model, known as fingerprint collusion
    attacks. They propose a secure fingerprint framework for digital rights management
    for deep learning models. They design unique fingerprints for individual users.
    By combining the specific regularization loss of fingerprints during DNN retraining,
    each constructed fingerprint is encoded in the probability density function of
    the weight, so that the owner can verify the information of the model owner and
    the unique identity of the user, and can resist fingerprint collusion attacks.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 陈等人[[32](#bib.bib32)]指出，在大规模模型分发系统中，多位用户可以使用各自的水印模型进行合作，构建一个未标记的高性能模型，这被称为指纹勾结攻击。他们提出了一种用于深度学习模型数字版权管理的安全指纹框架。他们为每个用户设计了独特的指纹。通过在DNN重新训练过程中结合指纹的特定正则化损失，每个构建的指纹都被编码在权重的概率密度函数中，从而使所有者能够验证模型所有者的信息和用户的独特身份，并能够抵御指纹勾结攻击。
- en: Xue et al. [[33](#bib.bib33)] propose an active DNN copyright protection method
    through adversarial example-based user fingerprinting. It can provide DNN with
    active authorization control, user identity management, and ownership verification.
    Specifically, they use carefully crafted adversarial examples (specific categories
    with specific confidence levels) as users’ fingerprints. Authorized users can
    input their fingerprints into DNN for authentication and obtain normal usage,
    while unauthorized users will achieve significantly poor model performance. In
    addition, model owners embed watermarks into the weights of DNN for ownership
    verification.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: Xue 等人 [[33](#bib.bib33)] 提出了通过对抗样本进行用户指纹识别的主动 DNN 版权保护方法。它可以为 DNN 提供主动授权控制、用户身份管理和所有权验证。具体而言，他们使用精心设计的对抗样本（具有特定置信度的特定类别）作为用户的指纹。授权用户可以将他们的指纹输入
    DNN 进行认证并获得正常使用，而未经授权的用户将获得显著差的模型性能。此外，模型所有者将水印嵌入 DNN 的权重中以进行所有权验证。
- en: 'Xue et al. [[34](#bib.bib34)] propose a DNN model active copyright protection
    method based on hidden backdoor and user identity authentication, as shown in
    Fig. [4](#S3.F4 "Figure 4 ‣ III-B User Identity Authentication and Management
    ‣ III Overview of Existing DL Active Copyright Protection Work ‣ Turn Passive
    to Active: A Survey on Active Intellectual Property Protection of Deep Learning
    Models"). They utilize an additional class to support both user identity authentication
    and model ownership verification. In order to embed hidden backdoor (watermark)
    in DNN, a small number of images are selected from outside the training set as
    watermark key samples. Then, the fingerprint information representing the user’s
    identity is embedded into the watermark key sample, and an additional class label
    is assigned to the watermark key sample [[34](#bib.bib34)]. Next, they add the
    watermark key sample to the training dataset of DNN for model training. After
    training, DNN will be embedded with the watermark. In the testing phase, DNN always
    predicts watermark key samples as the additional class. In addition, since the
    watermark key samples originate from samples outside the dataset (rather than
    samples with obvious watermark patterns), and the watermark is embedded through
    an additional class, a strong connection is established between the watermark
    key samples and the watermark, which can resist query modification attack. In
    order to support user authentication, steganography is used to hide user fingerprint
    information into the watermark key sample, so that the user fingerprint information
    is imperceptible [[34](#bib.bib34)]. In the user authentication stage, the watermark
    key sample is used as the user fingerprint and submitted to DNN for identity verification.'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 'Xue 等人 [[34](#bib.bib34)] 提出了基于隐藏后门和用户身份认证的深度神经网络（DNN）模型主动版权保护方法，如图 [4](#S3.F4
    "Figure 4 ‣ III-B User Identity Authentication and Management ‣ III Overview of
    Existing DL Active Copyright Protection Work ‣ Turn Passive to Active: A Survey
    on Active Intellectual Property Protection of Deep Learning Models") 所示。他们利用一个额外的类别来支持用户身份认证和模型所有权验证。为了在
    DNN 中嵌入隐藏后门（水印），从训练集之外选择少量图像作为水印密钥样本。然后，将表示用户身份的指纹信息嵌入到水印密钥样本中，并为水印密钥样本分配一个额外的类别标签
    [[34](#bib.bib34)]。接下来，他们将水印密钥样本添加到 DNN 的训练数据集中进行模型训练。训练后，DNN 将嵌入水印。在测试阶段，DNN
    总是将水印密钥样本预测为额外的类别。此外，由于水印密钥样本来源于数据集之外的样本（而非具有明显水印模式的样本），并且水印是通过额外的类别嵌入的，因此水印密钥样本与水印之间建立了强联系，可以抵御查询修改攻击。为了支持用户认证，使用隐写术将用户指纹信息隐藏在水印密钥样本中，使用户指纹信息不可察觉
    [[34](#bib.bib34)]。在用户认证阶段，水印密钥样本作为用户指纹提交给 DNN 进行身份验证。'
- en: Fan et al. [[35](#bib.bib35)] propose an active copyright protection and traceability
    framework for DNN. Combining authorization control strategies and image perceptual
    hash algorithms, an authorization control center is constructed. In this framework,
    the detector detects whether the key image input by the user is legal, and the
    authenticator verifies whether the user’s identity information is legal.
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: Fan 等人 [[35](#bib.bib35)] 提出了一个用于 DNN 的主动版权保护和追溯框架。结合授权控制策略和图像感知哈希算法，构建了一个授权控制中心。在该框架中，检测器检测用户输入的关键图像是否合法，认证器验证用户身份信息是否合法。
- en: '![Refer to caption](img/9c2cdb0b7ebf57674879b434562b3abb.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/9c2cdb0b7ebf57674879b434562b3abb.png)'
- en: 'Figure 4: DNN active authorization control and user identity authentication
    based on extra class and steganography [[34](#bib.bib34)].'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: '图 4: 基于额外类别和隐写术的 DNN 活跃授权控制和用户身份认证 [[34](#bib.bib34)]。'
- en: 'Wu et al. [[36](#bib.bib36)] use a specific backdoor to provide both authorization
    control and user identity management for the DNN model, as shown in Fig. [5](#S3.F5
    "Figure 5 ‣ III-B User Identity Authentication and Management ‣ III Overview of
    Existing DL Active Copyright Protection Work ‣ Turn Passive to Active: A Survey
    on Active Intellectual Property Protection of Deep Learning Models"). The backdoor
    trigger is used as an authorization key in this scheme, and there are hidden fingerprints
    that can be extracted to verify the user’s identity. They reversely utilize the
    characteristics of sample-specific backdoor attacks, where backdoor triggers are
    used to guide images from the wrong class to the correct class, thereby achieving
    authorization control [[36](#bib.bib36)]. In this way, the model copyright protection
    method can achieve normal model performance only for authorized users (who have
    the U-Net model), and unauthorized users cannot use the model normally. At the
    same time, the backdoor trigger is not a fixed pattern, but is generated through
    the U-Net model. Therefore, the user with the trigger generation model can use
    the target model normally. In this method, for different clean images, the corresponding
    trigger is imperceptible and image related, that is, the generated backdoor trigger
    is related to the content of the corresponding clean image, and different images
    correspond to different backdoor triggers. In addition, each backdoor trigger
    hides a unique fingerprint corresponding to an authorized user, and the model
    owner can verify and track the user’s identity by extracting the fingerprint from
    the backdoor instance. When distributing the U-Net model to authorized users,
    the U-Net model can be set to embed any string into the image. They hide the user’s
    unique fingerprint as a string into the U-Net model and assign this U-Net to the
    corresponding authorized user [[36](#bib.bib36)]. In the inference stage, when
    authorized users generate backdoor instances through the U-Net model, their fingerprints
    are embedded into the image along with the backdoor trigger. Subsequently, the
    model owner can extract this fingerprint from the submitted backdoor instance
    to verify and track the user’s identity.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 吴等人 [[36](#bib.bib36)] 使用特定的后门提供 DNN 模型的授权控制和用户身份管理，如图 [5](#S3.F5 "图 5 ‣ III-B
    用户身份认证与管理 ‣ III 现有深度学习活跃版权保护工作的概述 ‣ 从被动到主动：深度学习模型知识产权保护的调查") 所示。该方案中的后门触发器被用作授权密钥，并且有隐藏的指纹可以提取以验证用户的身份。他们反向利用样本特定后门攻击的特点，其中后门触发器用于将图像从错误类别引导到正确类别，从而实现授权控制
    [[36](#bib.bib36)]。通过这种方式，模型版权保护方法仅能为授权用户（拥有 U-Net 模型的用户）提供正常的模型性能，而未经授权的用户则无法正常使用模型。同时，后门触发器不是固定模式，而是通过
    U-Net 模型生成的。因此，拥有触发器生成模型的用户可以正常使用目标模型。在这种方法中，对于不同的干净图像，相应的触发器是不可察觉的且与图像相关，即生成的后门触发器与相应的干净图像的内容相关，不同的图像对应不同的后门触发器。此外，每个后门触发器隐藏了一个与授权用户相关的唯一指纹，模型所有者可以通过从后门实例中提取指纹来验证和追踪用户的身份。在将
    U-Net 模型分发给授权用户时，可以将任何字符串嵌入到图像中。他们将用户的唯一指纹作为字符串隐藏到 U-Net 模型中，并将这个 U-Net 分配给相应的授权用户
    [[36](#bib.bib36)]。在推理阶段，当授权用户通过 U-Net 模型生成后门实例时，他们的指纹会与后门触发器一起嵌入到图像中。随后，模型所有者可以从提交的后门实例中提取这个指纹来验证和追踪用户的身份。
- en: '![Refer to caption](img/29b9e5d7634724c0de3706479b01b938.png)'
  id: totrans-141
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/29b9e5d7634724c0de3706479b01b938.png)'
- en: 'Figure 5: Sample-specific backdoor based active DNN IP protection [[36](#bib.bib36)].'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 基于样本特定后门的活跃 DNN 知识产权保护 [[36](#bib.bib36)]。'
- en: III-C Challenges
  id: totrans-143
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 挑战
- en: 'As reflected by the discussions above, in the realm of DNN copyright protection,
    there are several pressing challenges and bottleneck difficulties that require
    attention:'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所述，在 DNN 版权保护领域存在若干紧迫的挑战和瓶颈问题，需要引起关注：
- en: •
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Most existing DNN copyright protection methods rely on passive verification,
    which means they ascertain the ownership of DNN models only after instances of
    piracy and infringement have occurred. This post-verification method cannot proactively
    prevent the occurrence of piracy and infringement. To achieve large-scale commercial
    applications of the DNN model, there is an urgent need for active copyright protection
    mechanisms.
  id: totrans-146
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数现有的DNN版权保护方法依赖于被动验证，这意味着它们仅在发生盗版和侵权实例后才确认DNN模型的所有权。这种后验证方法无法主动防止盗版和侵权的发生。为了实现DNN模型的大规模商业应用，迫切需要主动版权保护机制。
- en: •
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Most existing DNN copyright protection methods only focus on verifying model
    copyright, without managing the unique identity of users, thereby lacking effective
    copyright management, which is a necessary and core requirement for commercial
    DNN copyright protection. Further, they are vulnerable to several attacks, such
    as collusion attacks.
  id: totrans-148
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 大多数现有的DNN版权保护方法仅关注模型版权的验证，而不管理用户的唯一身份，因此缺乏有效的版权管理，这是商业DNN版权保护所必需的核心要求。此外，它们还容易受到多种攻击，例如勾结攻击。
- en: •
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The various attacks considered in existing work are all aimed at DNN watermarks
    (post-verification copyright protection). Regarding the new direction studied
    in this paper — active authorization control, the possible attack and bypass mechanisms
    are still blank.
  id: totrans-150
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 现有工作中考虑的各种攻击都针对的是DNN水印（后验证版权保护）。对于本文研究的新方向——主动授权控制，可能的攻击和绕过机制仍然是空白的。
- en: •
  id: totrans-151
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Lack of a systematic evaluation methodology. As an emerging cutting-edge research
    direction, DNN copyright protection is still in its infancy and lacks a comprehensive
    evaluation method. This gap is particularly evident in the case of active authorization
    control, where evaluation metrics and methods are yet to be developed.
  id: totrans-152
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 缺乏系统的评估方法。作为一个新兴的前沿研究方向，DNN版权保护仍处于起步阶段，缺乏全面的评估方法。这一缺口在主动授权控制的情况下尤为明显，评估指标和方法尚未开发。
- en: IV Attacks Faced by Active DL IP Protection
  id: totrans-153
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 主动深度学习知识产权保护面临的攻击
- en: The existing attacks on DNN copyright protection are all targeted at DNN watermarks,
    including model modification attacks, evasion/removal attacks, and some more aggressive
    attack scenarios [[2](#bib.bib2)].
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 对DNN版权保护的现有攻击都针对DNN水印，包括模型修改攻击、规避/移除攻击以及一些更具攻击性场景 [[2](#bib.bib2)]。
- en: 'This paper focuses on studying attacks and bypass mechanisms against DL active
    authorization control, including but not limited to the following:'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 本文专注于研究针对深度学习主动授权控制的攻击和绕过机制，包括但不限于以下内容：
- en: 'Query modification attack [[38](#bib.bib38)]: Query modification attack is
    a strong attack method. This attack aims to use an autoencoder to detect and remove
    watermarks in the watermark key sample, thereby invalidating the watermark query
    during ownership verification. We believe that autoencoders can be used to attack
    watermark key samples. The work [[34](#bib.bib34)] claims that their scheme is
    robust to query modification attacks for the following reasons. First, in the
    scheme, the watermark key sample is generated from clean images in a different
    dataset. This design choice ensures that the watermark trigger pattern becomes
    virtually indistinguishable from that of clean images. As a result, attackers
    are unable to detect watermarks by searching for distinctive watermark trigger
    patterns within the images. Second, the scheme establishes a robust connection
    between the watermark key sample and an additional class label. This connection
    is resilient, so even if the watermark key sample undergoes slight modifications
    as a result of the autoencoder attack, the DNN can still classify the altered
    watermark sample into the additional class [[34](#bib.bib34)].'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: '查询修改攻击 [[38](#bib.bib38)]: 查询修改攻击是一种强有力的攻击方法。这种攻击旨在使用自动编码器检测和移除水印密钥样本中的水印，从而使在所有权验证期间水印查询失效。我们认为自动编码器可以用于攻击水印密钥样本。工作
    [[34](#bib.bib34)] 认为他们的方案在以下原因下对查询修改攻击具有鲁棒性。首先，在该方案中，水印密钥样本是从不同数据集中的干净图像生成的。这一设计选择确保了水印触发模式与干净图像的模式几乎无法区分。因此，攻击者无法通过在图像中寻找独特的水印触发模式来检测水印。其次，该方案建立了水印密钥样本与附加类别标签之间的鲁棒连接。这一连接具有韧性，因此即使水印密钥样本因自动编码器攻击而发生轻微修改，DNN仍能将更改后的水印样本分类到附加类别中
    [[34](#bib.bib34)]。'
- en: 'Adaptive attack: Adaptive attack refers to the fact that an attacker knows
    the details of the protection mechanism and attempts to bypass it, which is the
    worst-case attack scenario. We will take the active authorization control mechanism
    in the work [[36](#bib.bib36)] as an example for discussion. In practical applications,
    unauthorized users are unable to access protected models and U-Net models. In
    order to discuss the robustness of the scheme, they consider the worst-case scenario,
    assuming that the attacker knows that the proposed method is based on backdoor
    and unintentionally obtains a pair of clean images and corresponding backdoor
    instances. In this way, the attacker attempts to obtain the corresponding trigger
    by subtracting the clean image from the backdoor instance. Then the attacker adds
    the trigger to another clean image to forge a “backdoor instance”. The analysis
    of the work [[36](#bib.bib36)] shows that the clean accuracy of the protected
    model under adaptive attacks remains at a relatively low level. Therefore, these
    “fake backdoor instances” will still be predicted as incorrect classes by the
    protected model. The reason is that this scheme generates different triggers for
    different clean images. Meanwhile, the generated sample-specific trigger is only
    effective for the corresponding clean image. Therefore, when a trigger generated
    for a clean image $x_{1}$ is used for another clean image $x_{2}$, the trigger
    will be invalid, and the protected model will still consider the image as a clean
    image and output the wrong class. In summary, when attackers use forged triggers
    to perform adaptive attacks, the method [[36](#bib.bib36)] still has robustness.'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 自适应攻击：自适应攻击指的是攻击者了解保护机制的细节并尝试绕过它，这是一种最坏情况下的攻击场景。我们将以工作中的主动授权控制机制[[36](#bib.bib36)]为例进行讨论。在实际应用中，未经授权的用户无法访问受保护的模型和U-Net模型。为了讨论该方案的鲁棒性，他们考虑了最坏的情况，假设攻击者知道所提议的方法基于后门，并且无意中获得了一对干净图像和相应的后门实例。这样，攻击者试图通过从后门实例中减去干净图像来获得相应的触发器。然后，攻击者将触发器添加到另一张干净图像中以伪造一个“后门实例”。对工作[[36](#bib.bib36)]的分析表明，受保护模型在自适应攻击下的干净准确性保持在相对较低的水平。因此，这些“伪造的后门实例”仍会被受保护模型预测为错误类别。原因在于该方案为不同的干净图像生成不同的触发器。同时，生成的样本特定触发器仅对相应的干净图像有效。因此，当用于干净图像$x_{1}$的触发器用于另一张干净图像$x_{2}$时，该触发器将失效，受保护模型仍会将图像视为干净图像并输出错误类别。总之，当攻击者使用伪造触发器进行自适应攻击时，方法[[36](#bib.bib36)]仍具有鲁棒性。
- en: 'Compression attack: Attackers may use image compression to disrupt validation
    or authentication samples. Using the scheme in the work [[36](#bib.bib36)] as
    an example, the image processed by the U-Net model in the scheme may be compressed
    during transmission, and the compression operation will remove redundant pixels
    in an image. The work [[36](#bib.bib36)] uses common JPEG compression method to
    evaluate the robustness of the scheme in the face of compression attacks. The
    image processed by U-Net is subjected to JPEG compression, and then the compressed
    backdoor instance is fed into the protected model for prediction. It is shown
    that the model prediction accuracy obtained by authorized users under JPEG compression
    attacks is close to the accuracy obtained without JPEG compression attacks. During
    the process of image transmission, even if the image is compressed by JPEG, authorized
    users can still achieve normal prediction accuracy. In addition, even if the image
    has been compressed using JPEG compression, the method can still effectively extract
    and verify the user’s fingerprint. Therefore, the method [[36](#bib.bib36)] is
    robust to JPEG compression attacks.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 压缩攻击：攻击者可能利用图像压缩来干扰验证或认证样本。以工作中的方案[[36](#bib.bib36)]为例，该方案中的U-Net模型处理的图像可能在传输过程中被压缩，而压缩操作会去除图像中的多余像素。工作[[36](#bib.bib36)]使用常见的JPEG压缩方法来评估该方案在面对压缩攻击时的鲁棒性。处理后的U-Net图像经历JPEG压缩，然后将压缩后的后门实例输入受保护模型进行预测。结果表明，授权用户在JPEG压缩攻击下获得的模型预测准确性接近于没有JPEG压缩攻击下的准确性。在图像传输过程中，即使图像被JPEG压缩，授权用户仍然可以实现正常的预测准确性。此外，即使图像经过JPEG压缩，方法仍然可以有效提取和验证用户的指纹。因此，方法[[36](#bib.bib36)]对JPEG压缩攻击具有鲁棒性。
- en: 'Collusion attack: A group of authorized users with the same host DNN and different
    fingerprints may engage in collusion attacks, attempting to construct a model
    with the same functionality [[32](#bib.bib32)], or colluding with unauthorized
    users to provide authorized use for multiple unauthorized users.'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 勾结攻击：一组拥有相同主机深度神经网络（DNN）和不同指纹的授权用户可能会进行勾结攻击，试图构建一个具有相同功能的模型[[32](#bib.bib32)]，或者与未经授权的用户勾结，为多个未经授权的用户提供授权使用。
- en: 'User fingerprint forgery: Attackers attempt to forge legitimate user fingerprints
    in the input image to pass identity authentication and obtain model authorization.
    Taking the work [[34](#bib.bib34)] as an example, if an attacker wants to successfully
    forge a fingerprint, he needs to know the additional class, the steganography
    used, and the specific format of the fingerprint. Due to the fact that the above
    information is also black-boxed and unknown to authorized users, it is difficult
    for attackers to obtain the above information, making it difficult to forge legitimate
    user fingerprints. Taking the work [[36](#bib.bib36)] as an example, an attacker
    wants to successfully forge a user fingerprint. However, the user fingerprint
    is associated with each sample, and is visually imperceptible. Authorized users
    cannot obtain fingerprint information, and if they are lucky enough to crack the
    corresponding fingerprint of one sample, it cannot be applied to other samples.
    Therefore, it is difficult for attackers to forge legitimate user fingerprints.'
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 用户指纹伪造：攻击者试图伪造输入图像中的合法用户指纹，以通过身份认证并获得模型授权。以文献[[34](#bib.bib34)]为例，如果攻击者想要成功伪造指纹，他需要了解额外的类别、使用的隐写术和指纹的具体格式。由于上述信息对授权用户也是黑箱且未知的，攻击者很难获取这些信息，这使得伪造合法用户指纹变得困难。以文献[[36](#bib.bib36)]为例，攻击者想要成功伪造用户指纹。然而，用户指纹与每个样本相关联，并且在视觉上不可感知。授权用户无法获取指纹信息，如果他们幸运地破解了一个样本的对应指纹，这个指纹不能应用于其他样本。因此，攻击者很难伪造合法用户指纹。
- en: 'Cracking authorization control module: Attackers attempt to crack the core
    of an active DL IP protection scheme — the active authorization control module.
    Taking the work [[36](#bib.bib36)] as an example, attackers attempt to crack the
    specially trained U-Net module. However, the U-Net module is jointly trained with
    the model, and it is specially trained by four loss functions. Moreover, a unique
    fingerprint is embedded in the U-Net module. Cracking and forging such a U-Net
    model is more difficult than stealing a commercial DNN model.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 破解授权控制模块：攻击者试图破解活跃的深度学习（DL）IP保护方案的核心——活跃授权控制模块。以文献[[36](#bib.bib36)]为例，攻击者试图破解特殊训练的U-Net模块。然而，U-Net模块与模型共同训练，并且由四个损失函数专门训练。此外，在U-Net模块中嵌入了独特的指纹。破解和伪造这样的U-Net模型比窃取商业深度神经网络（DNN）模型更困难。
- en: 'From a defense perspective, strategies for enhancing the robustness of these
    DL IP protection schemes include (but are not limited to): (i) Customized defense
    strategies for specific attacks. For example, to combat watermark removal attacks,
    it is suggested to embed watermarks by training from scratch, and embedding the
    watermarks as inseparable from the main task, so that if the attacker wants to
    remove the watermark, it will inevitably damage the performance of the original
    model; (ii) A defense mechanism based on generative adversarial networks, in which
    the training process of embedding watermarks is the generator, while the detector
    that integrates multiple watermark detection methods is the discriminator, which
    can embed hidden watermarks with strong attack resistance. Overall, what attacks
    might exist and how to defend against them remain open questions.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 从防御角度来看，增强这些深度学习（DL）IP保护方案鲁棒性的策略包括（但不限于）：（i）针对特定攻击的定制防御策略。例如，为了对抗水印去除攻击，建议通过从头开始训练嵌入水印，并将水印嵌入到与主要任务不可分割的地方，这样攻击者如果想去除水印，就会不可避免地损害原始模型的性能；（ii）基于生成对抗网络的防御机制，其中嵌入水印的训练过程作为生成器，而集成多种水印检测方法的检测器作为判别器，可以嵌入具有强攻击抗性的隐藏水印。总体而言，存在的攻击可能是什么以及如何防御仍然是开放性问题。
- en: V Future Directions
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 未来方向
- en: V-A An Active Authorization Control Method against Query Modification Attack
    with Lossless Model Performance
  id: totrans-164
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 针对查询修改攻击的无损模型性能的主动授权控制方法
- en: In existing work, embedding watermarks in the model may affect the performance
    of the model on the main task. In the active authorization control scheme, how
    to ensure that the constructed user identity authentication-based active authorization
    control method does not affect the performance of the model on the main task,
    and how to construct key samples or authentication samples that can resist query
    modification attack [[38](#bib.bib38)], are key challenges.
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: 在现有工作中，将水印嵌入模型可能会影响模型在主要任务上的性能。在主动授权控制方案中，如何确保构建的基于用户身份认证的主动授权控制方法不会影响模型在主要任务上的性能，以及如何构建能够抵御查询修改攻击的关键样本或认证样本[[38](#bib.bib38)]，是关键挑战。
- en: V-B Distinguish between Different Authorized Users
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 区分不同的授权用户
- en: Most of the existing DL model active copyright protection schemes focus on providing
    active authorization control for model owners, which can distinguish between authorized
    and unauthorized users, but do not consider user identity authentication and management,
    which cannot track the identity of authorized users and distinguish different
    authorized users.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的深度学习（DL）模型主动版权保护方案侧重于为模型所有者提供主动授权控制，这可以区分授权用户和未授权用户，但未考虑用户身份认证和管理，无法追踪授权用户的身份和区分不同的授权用户。
- en: V-C Unique and Imperceptible Fingerprint Generation Method for Authorized Users,
    and Model Performance Differentiation Control Method
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-C 授权用户的独特且不易察觉的指纹生成方法，以及模型性能差异化控制方法
- en: Most of the existing DNN copyright protection methods are passive which verify
    copyright after piracy and infringement occur. The active DNN copyright protection
    method can lock the model and actively prevent piracy. Besides, most existing
    methods embed watermarks or extract fingerprints from the model to verify the
    ownership of the model, but do not consider copyright management. In order to
    meet the urgent need for commercial DNN copyright protection, it is necessary
    to effectively authenticate and manage the identities of users. In the active
    authorization control scheme, how to construct unique and imperceptible fingerprint
    generation method for authorized users, and how to control the functionality and
    performance of DNN models differently based on different users, are the difficulties/challenges
    to be solved in the future.
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 目前大多数现有的深度神经网络（DNN）版权保护方法都是被动的，它们在盗版和侵权发生后才进行版权验证。主动的DNN版权保护方法可以锁定模型并主动防止盗版。此外，大多数现有方法嵌入水印或从模型中提取指纹以验证模型的所有权，但未考虑版权管理。为了满足商业DNN版权保护的迫切需求，必须有效地认证和管理用户身份。在主动授权控制方案中，如何为授权用户构建独特且不易察觉的指纹生成方法，以及如何根据不同用户控制DNN模型的功能和性能，是未来需要解决的难点/挑战。
- en: V-D Attack Mechanism for Active Authorization Control
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-D 活动授权控制的攻击机制
- en: Most of the existing DNN copyright protection work has evaluated the robustness
    of model modification, while a small amount of work has considered watermark removal
    attacks or evasion attacks. Regarding the new direction of this study — active
    authorization control, the research on possible attacks and bypass mechanisms
    is still lacking. What targeted attack methods will attackers adopt under the
    DNN active authorization control framework? How active authorization control schemes
    can overcome strong attack methods such as adaptive attacks, query modification
    attacks, compression attacks, collusion attacks, user fingerprint forgery attacks,
    and authorization control module cracking attacks, is a future research direction.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数现有的DNN版权保护工作已评估了模型修改的鲁棒性，而只有少量工作考虑了水印移除攻击或规避攻击。针对本研究的新方向——主动授权控制，关于可能的攻击和绕过机制的研究仍然不足。在DNN主动授权控制框架下，攻击者会采取什么针对性的攻击方法？主动授权控制方案如何克服自适应攻击、查询修改攻击、压缩攻击、串通攻击、用户指纹伪造攻击和授权控制模块破解攻击等强攻击方法，是未来的研究方向。
- en: V-E Evaluation Methods for Active Authorization Control Considering Attack Resistance
  id: totrans-172
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-E 考虑攻击抵抗的主动授权控制评估方法
- en: There is still a lack of research on the evaluation of DNN active authorization
    control. In addition, most of the existing evaluations of DNN copyright protection
    work focus on the functional metrics of DNN watermarks, and there is insufficient
    research on attack-resistance metrics. For active authorization control frameworks,
    how to construct evaluation methods and metrics that consider attack resistance
    is a future research direction.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 对DNN主动授权控制的评估研究仍然不足。此外，现有的大多数DNN版权保护评估工作集中于DNN水印的功能性指标，攻击抵抗指标的研究则不足。对于主动授权控制框架，如何构建考虑攻击抵抗的评估方法和指标是未来的研究方向。
- en: V-F Active Authorization Control for Datasets
  id: totrans-174
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-F 数据集的主动授权控制
- en: In addition to active authorization control for the DL models, there have been
    very few researchers recently paying attention to the authorization control of
    the datasets [[39](#bib.bib39), [40](#bib.bib40)]. Datasets also have high value
    and are widely used in more and more scenarios. How to construct authorization
    control for the usage of datasets is also a potential research direction.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 除了对DL模型的主动授权控制外，最近关注数据集授权控制的研究者很少 [[39](#bib.bib39), [40](#bib.bib40)]。数据集同样具有高价值，并在越来越多的场景中被广泛使用。如何构建数据集使用的授权控制也是一个潜在的研究方向。
- en: VI Conclusion
  id: totrans-176
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 结论
- en: For the first time, this review focuses on cutting-edge active DL copyright
    protection methods, analyzes current bottlenecks, discusses the goal and connotation
    of proactive copyright protection — providing active copyright protection (actively
    prevent piracy) and copyright management (user identity authentication) functions,
    and calls for studies on the attack mechanisms and evaluation of active DL authorization
    control. Studying proactive DNN copyright protection is expected to break through
    the bottlenecks and cutting-edge challenges faced by deep neural network copyright
    protection, and provide effective copyright protection mechanisms and lay a theoretical
    foundation for the commercial implementation of deep neural network models, which
    has significant significance.
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述首次聚焦于前沿的主动DL版权保护方法，分析当前瓶颈，讨论主动版权保护的目标与内涵——提供主动版权保护（主动防止盗版）和版权管理（用户身份认证）功能，并呼吁研究主动DL授权控制的攻击机制和评估。研究主动DNN版权保护预计能突破深度神经网络版权保护面临的瓶颈和前沿挑战，提供有效的版权保护机制，并为深度神经网络模型的商业实施奠定理论基础，这具有重要意义。
- en: References
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Y. Uchida, Y. Nagai, S. Sakazawa, and S. Satoh, “Embedding watermarks into
    deep neural networks,” in *Proceedings of the ACM on International Conference
    on Multimedia Retrieval*, 2017, pp. 269–277.'
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Y. 内田, Y. 永井, S. 坂泽, 和 S. 佐藤, “将水印嵌入深度神经网络中，” 见 *ACM国际多媒体检索会议论文集*，2017年，第269–277页。'
- en: '[2] M. Xue, Y. Zhang, J. Wang, and W. Liu, “Intellectual property protection
    for deep learning models: Taxonomy, methods, attacks, and evaluations,” *IEEE
    Transactions on Artificial Intelligence*, vol. 3, no. 6, pp. 908–923, 2022.'
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] M. 薛, Y. 张, J. 王, 和 W. 刘, “深度学习模型的知识产权保护：分类、方法、攻击与评估，” *IEEE人工智能学报*，第3卷，第6期，第908–923页，2022年。'
- en: '[3] J. Zhang, D. Chen, J. Liao, H. Fang, W. Zhang, W. Zhou, H. Cui, and N. Yu,
    “Model watermarking for image processing networks,” in *The Thirty-Fourth AAAI
    Conference on Artificial Intelligence,*, 2020, pp. 12 805–12 812.'
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] J. 张, D. 陈, J. 廖, H. 方, W. 张, W. 周, H. 崔, 和 N. 于, “用于图像处理网络的模型水印，” 见 *第34届AAAI人工智能会议*，2020年，第12 805–12 812页。'
- en: '[4] H. Wu, G. Liu, Y. Yao, and X. Zhang, “Watermarking neural networks with
    watermarked images,” *IEEE Transactions on Circuits and Systems for Video Technology*,
    vol. 31, no. 7, pp. 2591–2601, 2021.'
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] H. 吴, G. 刘, Y. 姚, 和 X. 张, “用水印图像对神经网络进行水印化，” *IEEE视频技术电路与系统学报*，第31卷，第7期，第2591–2601页，2021年。'
- en: '[5] G. Zhao, C. Qin, H. Yao, and Y. Han, “DNN self-embedding watermarking:
    Towards tampering detection and parameter recovery for deep neural network,” *Pattern
    Recognition Letters*, vol. 164, pp. 16–22, 2022.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] G. 赵, C. 秦, H. 姚, 和 Y. 韩, “DNN自嵌入水印：面向深度神经网络的篡改检测与参数恢复，” *模式识别通讯*，第164卷，第16–22页，2022年。'
- en: '[6] L. Wang, Z. Wang, X. Li, and C. Qin, “Robust watermarking for neural network
    models using residual network,” in *24th IEEE International Workshop on Multimedia
    Signal Processing*, 2022, pp. 1–6.'
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] L. 王, Z. 王, X. 李, 和 C. 秦, “使用残差网络对神经网络模型进行鲁棒水印化，” 见 *第24届IEEE国际多媒体信号处理研讨会*，2022年，第1–6页。'
- en: '[7] Y. Quan, H. Teng, Y. Chen, and H. Ji, “Watermarking deep neural networks
    in image processing,” *IEEE Transactions on Neural Networks and Learning Systems*,
    vol. 32, no. 5, pp. 1852–1865, 2021.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Y. Quan, H. Teng, Y. Chen, 和 H. Ji，“图像处理中的深度神经网络水印技术，” *IEEE神经网络与学习系统交易*，第32卷，第5期，第1852–1865页，2021年。'
- en: '[8] X. Guan, H. Feng, W. Zhang, H. Zhou, J. Zhang, and N. Yu, “Reversible watermarking
    in deep convolutional neural networks for integrity authentication,” in *The 28th
    ACM International Conference on Multimedia*, 2020, pp. 2273–2280.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] X. Guan, H. Feng, W. Zhang, H. Zhou, J. Zhang, 和 N. Yu，“深度卷积神经网络中的可逆水印技术用于完整性认证，”
    *第28届ACM国际多媒体会议*，2020年，第2273–2280页。'
- en: '[9] B. D. Rouhani, H. Chen, and F. Koushanfar, “DeepSigns: An end-to-end watermarking
    framework for ownership protection of deep neural networks,” in *Proceedings of
    the Twenty-Fourth International Conference on Architectural Support for Programming
    Languages and Operating Systems*, 2019, pp. 485–497.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] B. D. Rouhani, H. Chen, 和 F. Koushanfar，“DeepSigns：用于深度神经网络所有权保护的端到端水印框架，”
    *第二十四届编程语言和操作系统架构支持国际会议论文集*，2019年，第485–497页。'
- en: '[10] J. Zhang, Z. Gu, J. Jang, H. Wu, M. P. Stoecklin, H. Huang, and I. M.
    Molloy, “Protecting intellectual property of deep neural networks with watermarking,”
    in *Proceedings of the Asia Conference on Computer and Communications Security*,
    2018, pp. 159–172.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] J. Zhang, Z. Gu, J. Jang, H. Wu, M. P. Stoecklin, H. Huang, 和 I. M. Molloy，“通过水印技术保护深度神经网络的知识产权，”
    *亚太计算机与通信安全会议论文集*，2018年，第159–172页。'
- en: '[11] Y. Adi, C. Baum, M. Cissé, B. Pinkas, and J. Keshet, “Turning your weakness
    into a strength: Watermarking deep neural networks by backdooring,” in *27th USENIX
    Security Symposium*, 2018, pp. 1615–1631.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Y. Adi, C. Baum, M. Cissé, B. Pinkas, 和 J. Keshet，“将劣势转化为优势：通过后门技术对深度神经网络进行水印处理，”
    *第27届USENIX安全研讨会*，2018年，第1615–1631页。'
- en: '[12] Y. Zheng, S. Wang, and C. Chang, “A DNN fingerprint for non-repudiable
    model ownership identification and piracy detection,” *IEEE Transactions on Information
    Forensics and Security*, vol. 17, pp. 2977–2989, 2022.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] Y. Zheng, S. Wang, 和 C. Chang，“用于不可否认的模型所有权识别和盗版检测的DNN指纹，” *IEEE信息取证与安全交易*，第17卷，第2977–2989页，2022年。'
- en: '[13] M. Xue, X. Wang, Y. Wu, S. Ni, Y. Zhang, and W. Liu, “InFIP: An explainable
    DNN intellectual property protection method based on intrinsic features,” *CoRR*,
    vol. abs/2210.07481, 2022.'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] M. Xue, X. Wang, Y. Wu, S. Ni, Y. Zhang, 和 W. Liu，“InFIP：一种基于内在特征的可解释DNN知识产权保护方法，”
    *CoRR*，第abs/2210.07481卷，2022年。'
- en: '[14] Z. Yin, H. Yin, and X. Zhang, “Neural network fragile watermarking with
    no model performance degradation,” in *IEEE International Conference on Image
    Processing*, 2022, pp. 3958–3962.'
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] Z. Yin, H. Yin, 和 X. Zhang，“无模型性能下降的神经网络脆弱水印，” *IEEE国际图像处理会议*，2022年，第3958–3962页。'
- en: '[15] H. Chen, H. Zhou, J. Zhang, D. Chen, W. Zhang, K. Chen, G. Hua, and N. Yu,
    “Perceptual hashing of deep convolutional neural networks for model copy detection,”
    *ACM Transactions on Multimedia Computing Communications and Applications*, vol. 19,
    no. 3, pp. 123:1–123:20, 2023.'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] H. Chen, H. Zhou, J. Zhang, D. Chen, W. Zhang, K. Chen, G. Hua, 和 N. Yu，“深度卷积神经网络的感知哈希用于模型复制检测，”
    *ACM多媒体计算通信与应用交易*，第19卷，第3期，第123:1–123:20页，2023年。'
- en: '[16] H. Chen, W. Zhang, K. Liu, K. Chen, H. Fang, and N. Yu, “Speech pattern
    based black-box model watermarking for automatic speech recognition,” in *IEEE
    International Conference on Acoustics, Speech and Signal Processing*, 2022, pp.
    3059–3063.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] H. Chen, W. Zhang, K. Liu, K. Chen, H. Fang, 和 N. Yu，“基于语音模式的黑箱模型水印技术用于自动语音识别，”
    *IEEE国际声学、语音与信号处理会议*，2022年，第3059–3063页。'
- en: '[17] L. Lin and H. Wu, “Verifying integrity of deep ensemble models by lossless
    black-box watermarking with sensitive samples,” in *10th International Symposium
    on Digital Forensics and Security*, 2022, pp. 1–6.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] L. Lin 和 H. Wu，“通过无损黑箱水印和敏感样本验证深度集成模型的完整性，” *第10届国际数字取证与安全研讨会*，2022年，第1–6页。'
- en: '[18] T. Qiao, Y. Ma, N. Zheng, H. Wu, Y. Chen, M. Xu, and X. Luo, “A novel
    model watermarking for protecting generative adversarial network,” *Computers
    & Security*, vol. 127, p. 103102, 2023.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] T. Qiao, Y. Ma, N. Zheng, H. Wu, Y. Chen, M. Xu, 和 X. Luo，“保护生成对抗网络的新型模型水印，”
    *计算机与安全*，第127卷，第103102页，2023年。'
- en: '[19] X. Zhao, H. Wu, and X. Zhang, “Watermarking graph neural networks by random
    graphs,” in *9th International Symposium on Digital Forensics and Security*, 2021,
    pp. 1–6.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] X. Zhao, H. Wu, 和 X. Zhang，“通过随机图对图神经网络进行水印处理，” *第9届国际数字取证与安全研讨会*，2021年，第1–6页。'
- en: '[20] M. Chen and M. Wu, “Protect your deep neural networks from piracy,” in
    *IEEE International Workshop on Information Forensics and Security*, 2018, pp.
    1–7.'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] M. Chen 和 M. Wu，“保护您的深度神经网络免受盗版，”发表于*IEEE 信息取证与安全国际研讨会*，2018年，页码1–7。'
- en: '[21] L. Fan, K. W. Ng, C. S. Chan, and Q. Yang, “DeepIPR: Deep neural network
    ownership verification with passports,” *IEEE Transactions on Pattern Analysis
    and Machine Intelligence*, vol. 44, no. 10, pp. 6122–6139, 2022.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] L. Fan, K. W. Ng, C. S. Chan 和 Q. Yang，“DeepIPR：使用护照进行深度神经网络所有权验证，”*IEEE
    模式分析与机器智能汇刊*，第44卷，第10期，页码6122–6139，2022年。'
- en: '[22] G. Ren, J. Wu, G. Li, S. Li, and M. Guizani, “Protecting intellectual
    property with reliable availability of learning models in AI-based cybersecurity
    services,” *IEEE Transactions on Dependable and Secure Computing*, pp. 1–18, 2022.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] G. Ren, J. Wu, G. Li, S. Li 和 M. Guizani，“在基于 AI 的网络安全服务中，通过可靠的学习模型可用性来保护知识产权，”*IEEE
    可靠性与安全计算汇刊*，页码1–18，2022年。'
- en: '[23] N. Lin, X. Chen, H. Lu, and X. Li, “Chaotic weights: A novel approach
    to protect intellectual property of deep neural networks,” *IEEE Transactions
    on Computer-Aided Design of Integrated Circuits and Systems*, vol. 40, no. 7,
    pp. 1327–1339, 2021.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] N. Lin, X. Chen, H. Lu 和 X. Li，“混沌权重：一种保护深度神经网络知识产权的新方法，”*IEEE 计算机辅助设计集成电路与系统汇刊*，第40卷，第7期，页码1327–1339，2021年。'
- en: '[24] M. AprilPyone and H. Kiya, “A protection method of trained CNN model using
    feature maps transformed with secret key from unauthorized access,” in *Asia-Pacific
    Signal and Information Processing Association Annual Summit and Conference*, 2021,
    pp. 1851–1857.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] M. AprilPyone 和 H. Kiya，“一种使用由秘密密钥转换的特征图来保护训练过的 CNN 模型免受未经授权访问的方法，”发表于*亚太信号与信息处理协会年会暨会议*，2021年，页码1851–1857。'
- en: '[25] M. Xue, Z. Wu, Y. Zhang, J. Wang, and W. Liu, “Advparams: An active dnn
    intellectual property protection technique via adversarial perturbation based
    parameter encryption,” *IEEE Transactions on Emerging Topics in Computing*, vol. 11,
    no. 3, pp. 664–678, 2023.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] M. Xue, Z. Wu, Y. Zhang, J. Wang 和 W. Liu，“Advparams：一种通过对抗扰动基于参数加密的主动
    DNN 知识产权保护技术，”*IEEE 新兴计算主题汇刊*，第11卷，第3期，页码664–678，2023年。'
- en: '[26] Y. Luo, G. Feng, and X. Zhang, “Hierarchical authorization of convolutional
    neural networks for multi-user,” *IEEE Signal Processing Letters*, vol. 28, pp.
    1560–1564, 2021.'
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Y. Luo, G. Feng 和 X. Zhang，“多用户卷积神经网络的分层授权，”*IEEE 信号处理快报*，第28卷，页码1560–1564，2021年。'
- en: '[27] Q. Pan, M. Dong, K. Ota, and J. Wu, “Device-bind key-storageless hardware
    AI model IP protection: A PUF and permute-diffusion encryption-enabled approach,”
    *CoRR*, vol. abs/2212.11133, 2022.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Q. Pan, M. Dong, K. Ota 和 J. Wu，“设备绑定无密钥存储硬件 AI 模型知识产权保护：一种基于 PUF 和置换扩散加密的方法，”*CoRR*，第abs/2212.11133卷，2022年。'
- en: '[28] A. Chakraborty, A. Mondai, and A. Srivastava, “Hardware-assisted intellectual
    property protection of deep learning models,” in *57th ACM/IEEE Design Automation
    Conference*, 2020, pp. 1–6.'
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] A. Chakraborty, A. Mondai 和 A. Srivastava，“硬件辅助的深度学习模型知识产权保护，”发表于*第57届
    ACM/IEEE 设计自动化会议*，2020年，页码1–6。'
- en: '[29] M. Xue, Z. Wu, C. He, J. Wang, and W. Liu, “Active DNN IP protection:
    A novel user fingerprint management and DNN authorization control technique,”
    in *IEEE 19th International Conference on Trust, Security and Privacy in Computing
    and Communications*, 2020, pp. 975–982.'
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] M. Xue, Z. Wu, C. He, J. Wang 和 W. Liu，“主动 DNN 知识产权保护：一种新型用户指纹管理和 DNN
    授权控制技术，”发表于*IEEE 第19届计算与通信信任、安全与隐私国际会议*，2020年，页码975–982。'
- en: '[30] R. Tang, M. Du, and X. Hu, “Deep serial number: Computational watermark
    for DNN intellectual property protection,” in *Machine Learning and Knowledge
    Discovery in Databases: Applied Data Science and Demo Track - European Conference*,
    vol. 14174, 2023, pp. 157–173.'
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] R. Tang, M. Du 和 X. Hu，“深度序列号：用于 DNN 知识产权保护的计算水印，”发表于*机器学习与知识发现数据库：应用数据科学与演示轨道
    - 欧洲会议*，第14174卷，2023年，页码157–173。'
- en: '[31] S. Wang, C. Xu, Y. Zheng, and C. Chang, “A buyer-traceable DNN model IP
    protection method against piracy and misappropriation,” in *4th IEEE International
    Conference on Artificial Intelligence Circuits and Systems*, 2022, pp. 308–311.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] S. Wang, C. Xu, Y. Zheng 和 C. Chang，“一种防盗版和挪用的买家可追踪 DNN 模型知识产权保护方法，”发表于*第4届
    IEEE 人工智能电路与系统国际会议*，2022年，页码308–311。'
- en: '[32] H. Chen, B. D. Rouhani, C. Fu, J. Zhao, and F. Koushanfar, “DeepMarks:
    A secure fingerprinting framework for digital rights management of deep learning
    models,” in *International Conference on Multimedia Retrieval*, 2019, pp. 105–113.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] H. Chen, B. D. Rouhani, C. Fu, J. Zhao 和 F. Koushanfar，“DeepMarks：用于深度学习模型数字版权管理的安全指纹框架，”发表于*国际多媒体检索会议*，2019年，页码105–113。'
- en: '[33] M. Xue, S. Sun, C. He, D. Gu, Y. Zhang, J. Wang, and W. Liu, “ActiveGuard:
    An active intellectual property protection technique for deep neural networks
    by leveraging adversarial examples as users’ fingerprints,” *IET Computers & Digital
    Techniques*, vol. 17, no. 3-4, pp. 111–126, 2023.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] M. Xue, S. Sun, C. He, D. Gu, Y. Zhang, J. Wang, 和 W. Liu, “ActiveGuard：一种利用对抗样本作为用户指纹的深度神经网络主动知识产权保护技术，”
    *IET Computers & Digital Techniques*, vol. 17, no. 3-4, 页码 111–126, 2023年。'
- en: '[34] M. Xue, S. Sun, Y. Zhang, J. Wang, and W. Liu, “Active intellectual property
    protection for deep neural networks through stealthy backdoor and users’ identities
    authentication,” *Applied Intelligence*, vol. 52, no. 14, pp. 16 497–16 511, 2022.'
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] M. Xue, S. Sun, Y. Zhang, J. Wang, 和 W. Liu, “通过隐蔽后门和用户身份认证的深度神经网络主动知识产权保护，”
    *Applied Intelligence*, vol. 52, no. 14, 页码 16 497–16 511, 2022年。'
- en: '[35] X. Fan, H. Gui, and X. Zhou, “PCPT and ACPT: copyright protection and
    traceability scheme for DNN model,” *CoRR*, vol. abs/2206.02541, 2022.'
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] X. Fan, H. Gui, 和 X. Zhou, “PCPT 和 ACPT：DNN模型的版权保护与追踪方案，” *CoRR*, vol.
    abs/2206.02541, 2022年。'
- en: '[36] Y. Wu, M. Xue, D. Gu, Y. Zhang, and W. Liu, “Sample-specific backdoor
    based active intellectual property protection for deep neural networks,” in *4th
    IEEE International Conference on Artificial Intelligence Circuits and Systems*,
    2022, pp. 316–319.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Y. Wu, M. Xue, D. Gu, Y. Zhang, 和 W. Liu, “基于样本特定后门的深度神经网络主动知识产权保护，” 见
    *第4届IEEE人工智能电路与系统国际会议*, 2022年, 页码 316–319。'
- en: '[37] M. Xue, C. He, J. Wang, and W. Liu, “One-to-N & N-to-One: Two advanced
    backdoor attacks against deep learning models,” *IEEE Transactions on Dependable
    and Secure Computing*, vol. 19, no. 3, pp. 1562–1578, 2022.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] M. Xue, C. He, J. Wang, 和 W. Liu, “一对多与多对一：针对深度学习模型的两种高级后门攻击，” *IEEE Transactions
    on Dependable and Secure Computing*, vol. 19, no. 3, 页码 1562–1578, 2022年。'
- en: '[38] R. Namba and J. Sakuma, “Robust watermarking of neural network with exponential
    weighting,” in *Proceedings of the ACM Asia Conference on Computer and Communications
    Security*, 2019, pp. 228–240.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] R. Namba 和 J. Sakuma, “具有指数加权的神经网络鲁棒水印，” 见 *ACM亚洲计算机与通信安全会议论文集*, 2019年,
    页码 228–240。'
- en: '[39] M. Xue, Y. Wu, Y. Zhang, J. Wang, and W. Liu, “Dataset authorization control:
    protect the intellectual property of dataset via reversible feature space adversarial
    examples,” *Applied Intelligence*, vol. 53, no. 6, pp. 7298–7309, 2023.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] M. Xue, Y. Wu, Y. Zhang, J. Wang, 和 W. Liu, “数据集授权控制：通过可逆特征空间对抗样本保护数据集知识产权，”
    *Applied Intelligence*, vol. 53, no. 6, 页码 7298–7309, 2023年。'
- en: '[40] Y. Lu, Z. Tang, X. Chai, M. Wang, and S. Song, “A hierarchical protection
    scheme for intellectual property of semi-open source datasets based on double
    watermarking,” *Optik*, vol. 269, p. 169931, 2022.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Y. Lu, Z. Tang, X. Chai, M. Wang, 和 S. Song, “一种基于双重水印的半开放源数据集知识产权分级保护方案，”
    *Optik*, vol. 269, 页码 169931, 2022年。'
