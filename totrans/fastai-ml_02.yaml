- en: 'Machine Learning 1: Lesson 2'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-2-d9aebd7dd0b0](https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-2-d9aebd7dd0b0)
  id: totrans-1
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*My personal notes from* [*machine learning class*](http://forums.fast.ai/t/another-treat-early-access-to-intro-to-machine-learning-videos/6826/1)*.
    These notes will continue to be updated and improved as I continue to review the
    course to “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
- en: Random Forest Deep Dive
  id: totrans-3
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb)
    / [Video](https://youtu.be/blyXCk4sgEg)'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
- en: 'For the next couple lessons, we will look at:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
- en: how random forests actually work
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: what to do if they do not work properly
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: what the pros and cons are
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: what we can tune
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: how to interpret the result
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fastai library is a collections of best techniques to achieve state-of-the-art
    result. For structured data analysis, scikit-learn has a lot of great code. So
    what fastai does is to help us get things into scikit-learn and then interpret
    things out from scikit-learn.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
- en: As we noted, it is very important to deeply understand the evaluation metric
    [[06:00](https://youtu.be/blyXCk4sgEg?t=6m)].
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
- en: 'Root Mean Squared Logarithmic Error (RMSLE):'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/b6096d278b7d3e91fd23b0a3e16b2be2.png)![](../Images/245b2c6ebf7b745151e81658ebc3b92b.png)'
  id: totrans-14
  prefs: []
  type: TYPE_IMG
- en: So we took the log of the price and use root mean squared error (RMSE).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-16
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'Then we made everything in the dataset to numbers by doing the following:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
- en: '`add_datepart` — extract date-time features `Elapsed` represents how many days
    are elapsed since January 1st, 1970.'
  id: totrans-18
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`train_cats` — converts `string` to pandas `category` data type. We then replace
    categorical columns with category codes by running `**proc_df**`'
  id: totrans-19
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proc_df` also replaces missing values of the continuous columns with the median
    and adds the column called `[column name]_na` and sets it to true to indicate
    it was missing.'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-21
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: What is R² [[10:50](https://youtu.be/blyXCk4sgEg?t=10m50s)]?
  id: totrans-22
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Jeremy’s answer [[11:47](https://youtu.be/blyXCk4sgEg?t=11m47s)]
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
- en: '[![](../Images/4bbfef2b89e27803811534320a1898a3.png)](https://en.wikipedia.org/wiki/Coefficient_of_determination)'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
- en: '*yi* : actual/target data'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*ȳ* : the average (mean)'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SStot`: how much the data vary'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The simplest non-stupid model we came up with last week was create a column
    of the mean and submit that to Kaggle. In that case, RMSE = `SStot` (i.e. RMSE
    of a naïve model)
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*fi*: predictions'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`SSres` is RMSE of the actual model'
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we were exactly as effective as just predicting the mean, `SSres/SStot` =
    1 and R² = 0
  id: totrans-31
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If we were perfect (i.e. *yi* = *fi* for all cases), `SSres/SStot` = 0 and R²
    = 1
  id: totrans-32
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: What is the possible range of R² [[14:43](https://youtu.be/blyXCk4sgEg?t=14m43s)]?
  id: totrans-33
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Correct answer: Anything equal to or less than 1\. If you predicted infinity
    for every row, R² = 1 −∞'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
- en: So when your R² is negative, it means your model is worse than predicting the
    mean.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
- en: R² is not necessarily what you are actually trying to optimize, but it is a
    number you can use for every model and you can start to get a feel of what .8
    looks like or what .9 looks like. Something you may find interesting is to create
    synthetic 2D datasets with different amounts of random noise, and see what they
    look like on a scatterplot and their R² to get a feel of how close they are to
    the actual value.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
- en: R² is the ratio between how good your model is (RMSE)vs. how good is the naïve
    mean model (RMSE).
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
- en: Overfitting [[17:33](https://youtu.be/blyXCk4sgEg?t=17m33s)]
  id: totrans-38
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In our case, R²= 0.98 is a very good model. However, it might be the case that
    it looks like the one on the right:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46b9cf6077e1962a6a2dec160380826e.png)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
- en: It is good at running through points we gave it, but it is not going to be very
    good at running through points we didn’t give it. That is why we always want to
    have a validation set.
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
- en: Creating a validation set is the most important thing you need to do when you
    are doing a machine learning project. What you need to do is to come up with a
    dataset where the score of your model on that dataset is going to be representative
    of how well your model is going to do in the real world.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
- en: 'If your dataset has a time piece in it (as is in Blue Book competition), you
    would likely want to predict future prices/values/etc. What Kaggle did was to
    give us data representing a particular date range in the training set, and then
    the test set presented a future set of dates that wasn’t represented in the training
    set. So we need to create a validation set that has the same properties:'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-44
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: We now have something which hopefully looks like Kaggle test set — close enough
    that using this would give us reasonably accurate scores. The reason we want this
    is because on Kaggle, you can only submit so many times and if you submit too
    often, you will end up fitting to the leaderboard anyway. In real life, we want
    to build a model that is going to work well in the production.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Could you explain the difference between a validation set and
    a test set [[20:58](https://youtu.be/blyXCk4sgEg?t=20m58s)]? One of the things
    we are going to learn today is how to set hyper parameters. Hyper parameters are
    tuning parameters that are going to change how your model behaves. If you just
    have one holdout set (i.e. one set of data that you are not using to train with)
    and we use that to decide which set of hyper parameter to use. If we try a thousand
    different sets of hyper parameters, we may end up overfitting to that holdout
    set. So what we want to do is to have a second holdout set (the test set) where
    we can say I have done the best I can and now just once right at the end, I am
    going to see whether it works.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
- en: You *must* actually remove the second holdout set (test set) from the data,
    give it to somebody else, and tell them not let you look at it until you promise
    you are finished. Otherwise it is so hard not to look at it. In the world of psychology
    and sociology, it is known as replication crisis or P-hacking. That is why we
    want to have a test set.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: We have converted categorical variable into numbers but other
    models convert it to different columns using one hot encoding — which approach
    should we use [[22:55](https://youtu.be/blyXCk4sgEg?t=22m55s)]? We are going to
    tackle that today.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
- en: Base model [[23:42](https://youtu.be/blyXCk4sgEg?t=23m42s)]
  id: totrans-49
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![](../Images/ed28604123c57f9aec898c749cd722e1.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
- en: As you see, R² is .982 on the training set, and only .887 on the validation
    set which makes us think that we are overfitting quite badly. But not too badly
    as RMSE of 0.25 would have put us in the top 25% of the competition.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Why not choose random set of rows as a validation set[[24:19](https://youtu.be/blyXCk4sgEg?t=24m19s)]?
    Because if we did that, we would not be replicating the test set. If you actually
    look at the dates in the test set, they are a set of dates that are more recent
    than any date in the training set. So if we used a validation set that was a random
    sample, that is much easier because we are predicting the value of a piece of
    industrial equipment on this day when we already have some observations from that
    day. In general, anytime you are building a model that has a time element, you
    want your test set to be a separate time period and therefore you really need
    your validation set to be of separate time period as well.'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Wouldn’t it eventually overfit to the validation set? [[25:30](https://youtu.be/blyXCk4sgEg?t=25m30s)]
    Yes, actually that is the issue. That would eventually have the possibility of
    overfitting on the validation set and when you try it on the test set or submit
    it to Kaggle, it turns out not to be very good. This happens in Kaggle competitions
    all the time and they actually have a fourth dataset which is called the private
    leader board set. Every time you submit to Kaggle, you actually only get feedback
    on how well it does on the public leader board set and you do not know which rows
    they are. At the end of the competition, you get judged on a different dataset
    entirely called the private leader board set. The only way to avoid this is to
    actually be a good machine learning practitioner and know how to set these parameters
    as effectively as possible which we are going to be doing partly today and over
    the next few weeks.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：最终不会过拟合验证集吗？[[25:30](https://youtu.be/blyXCk4sgEg?t=25m30s)] 是的，实际上这就是问题所在。最终可能会在验证集上过拟合，当你在测试集上尝试或提交到Kaggle时，结果可能并不好。这在Kaggle竞赛中经常发生，他们实际上有第四个数据集，称为私人排行榜集。每次提交到Kaggle时，你实际上只会得到在公共排行榜集上的表现反馈，你不知道它们是哪些行。在比赛结束时，你将根据完全不同的数据集进行评判，称为私人排行榜集。避免这种情况的唯一方法是成为一个优秀的机器学习从业者，并尽可能有效地设置这些参数，这部分我们今天和未来几周将会做。'
- en: PEP8 [[27:09](https://youtu.be/blyXCk4sgEg?t=27m9s)]
  id: totrans-54
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: PEP8[[27:09](https://youtu.be/blyXCk4sgEg?t=27m9s)]
- en: '[PRE3]'
  id: totrans-55
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: This is one of these examples where the code does not follow PEP8\. Being able
    to look at something in one go with your eyes and over time learn to immediately
    see what is going on has a lot of values. Also consistently use particular letters
    or abbreviation to mean particular things works well in data science. But if you
    are doing take-home interview test, follow PEP8 standard.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 这是一个代码不符合PEP8规范的例子。能够用眼睛一次看到某些东西，并随着时间学会立即看出发生了什么具有很大的价值。在数据科学中，始终使用特定的字母或缩写表示特定的含义是有效的。但是如果你在家里面试中测试，要遵循PEP8标准。
- en: Execution Time [[29:29](https://youtu.be/blyXCk4sgEg?t=29m29s)]
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 执行时间[[29:29](https://youtu.be/blyXCk4sgEg?t=29m29s)]
- en: If you put `%time`, it will tell you how long things took. The rule of thumb
    is that if something takes more than 10 seconds to run, it is too long to do interactive
    analysis with it. So what we do is we try to make sure that things can run in
    a reasonable time. And then when we are finished at the end of the day, we can
    say ok, this feature engineering, these hyper parameters, etc are all working
    well, and we will now re-run it the big slow precise way.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你加上`%time`，它会告诉你花了多长时间。经验法则是，如果某个操作花费超过10秒，那么用它进行交互式分析就太长了。所以我们要确保事情能在合理的时间内运行。然后当我们一天结束时，我们可以说好了，这个特征工程，这些超参数等都运行良好，我们现在将以大慢精确的方式重新运行它。
- en: 'One way to speed things up is to pass in the subset parameter to proc_df which
    will randomly sample the data:'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 加快速度的一种方法是将subset参数传递给proc_df，这将随机抽样数据：
- en: '[PRE4]'
  id: totrans-60
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: Be careful to make sure that validation set does not change
  id: totrans-61
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 请确保验证集不会改变
- en: Also make sure that training set does not overlap with the dates
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 还要确保训练集与日期不重叠
- en: As you see above, when calling `split_vals`, we do not put the result to a validation
    set. `_` indicates that we are throwing away the return value. We want to keep
    validation set the same all the time.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 如上所示，在调用`split_vals`时，我们没有将结果放入验证集。`_`表示我们丢弃了返回值。我们希望保持验证集始终相同。
- en: After resampling the training set into the first 20,000 out of a 30,000 subsets,
    it runs in 621 milliseconds.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 在将训练集重新采样为30,000个子集中的前20,000个后，运行时间为621毫秒。
- en: Building a single tree [[31:50](https://youtu.be/blyXCk4sgEg?t=31m50s)]
  id: totrans-65
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 构建单棵树[[31:50](https://youtu.be/blyXCk4sgEg?t=31m50s)]
- en: We are going to build a forest made of trees. Let’s start by looking at trees.
    In scikit-learn, they do not call them trees but **estimators**.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将建立由树组成的森林。让我们从树开始。在scikit-learn中，他们不称之为树，而是**估计器**。
- en: '[PRE5]'
  id: totrans-67
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '`n_estimators=1` — create a forest with just one tree'
  id: totrans-68
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`n_estimators=1` — 创建只有一棵树的森林'
- en: '`max_depth=3` — to make it a small tree'
  id: totrans-69
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`max_depth=3` — 使其成为一棵小树'
- en: '`bootstrap=False` — random forest randomizes bunch of things, we want to turn
    that off by this parameter'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`bootstrap=False` — 随机森林会随机化很多东西，我们希望通过这个参数关闭它'
- en: 'This small deterministic tree has R² of 0.4028 after fitting so this is not
    a good model but better than the mean model since it is greater than 1 and we
    can actually draw [[33:00](https://youtu.be/blyXCk4sgEg?t=33m)]:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 这棵小的确定性树在拟合后的R²为0.4028，所以这不是一个好模型，但比平均模型好，因为它大于1，我们实际上可以绘制[[33:00](https://youtu.be/blyXCk4sgEg?t=33m)]：
- en: '![](../Images/0bb2022511c4fb60bbef16a8257ab857.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/0bb2022511c4fb60bbef16a8257ab857.png)'
- en: A tree consists of a sequence of binary decisions.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 一棵树由一系列二进制决策组成。
- en: The first line indicates the binary split criteria
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 第一行表示二进制分割标准
- en: '`samples` at the root is 20,000 since that is what we specified when splitting
    the data.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 根节点的`samples`为20,000，因为这是我们在拆分数据时指定的。
- en: Darker color indicates higher `value`
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 较深的颜色表示较高的`value`
- en: '`value` is average of the log of price, and if we built a model where we just
    used the average all the time, then the mean squared error `mse` would be 0.495'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`value`是价格的对数的平均值，如果我们构建了一个模型，只使用平均值，那么均方误差`mse`将为0.495'
- en: The best single binary split we can make turns out to be `Coupler_system ≤ 0.5`
    which will improve `mse` to 0.109 in false path; 0.414 in true path.
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们能够做出的最佳单一二进制分割结果是`Coupler_system ≤ 0.5`，这将使`mse`在错误路径上提高到0.109；在正确路径上为0.414。
- en: We want to start building a random forest from scratch [[36:28](https://youtu.be/blyXCk4sgEg?t=36m28s)].
    The first step is to create a tree. The first step to create a tree is to create
    the first binary decision. How are you going to do it?
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 我们想要从头开始构建一个随机森林[[36:28](https://youtu.be/blyXCk4sgEg?t=36m28s)]。第一步是创建一棵树。创建树的第一步是创建第一个二进制决策。你打算如何做？
- en: We need to pick a variable and the value to split on such that the two groups
    are as different to each other as possible
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 我们需要选择一个变量和一个值来分割，使得这两个组尽可能不同
- en: For each variable, for each possible value of the possible value of that variable
    see whether it is better.
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 对于每个变量，对于该变量的每个可能值，看看哪个更好。
- en: How to determine if it is better? Take weighted average of two new nodes
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 如何确定哪个更好？取两个新节点的加权平均值
- en: The resulting model will be similar to the naïve model of means — we have a
    model with a single binary decision. For everybody with coupler_system greater
    than 0.5, we will fill in 10.345, for everybody else, we will put 9.363\. Then
    we will calculate RMSE of this model.
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 得到的模型将类似于平均模型——我们有一个具有单一二进制决策的模型。对于所有`coupler_system`大于0.5的人，我们将填入10.345，对于其他人，我们将填入9.363。然后我们将计算这个模型的RMSE。
- en: We now have a single number that represents how good a split is which is the
    weighted average of the mean squared errors of the two groups that creates [[42:13](https://youtu.be/blyXCk4sgEg?t=42m13s)].
    We also have a way to find the best split which is to try try every variable and
    to try every possible value of that variable and see which variable and which
    value gives us a split with the best score.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有一个单一数字来表示一个分割有多好，这个数字是创建这两个组的均方误差的加权平均值。我们还有一种找到最佳分割的方法，就是尝试每个变量和每个可能的值，看哪个变量和哪个值给出了最佳得分的分割。
- en: '**Question**: Are there circumstances when it is better to split into 3 groups
    [[45:12](https://youtu.be/blyXCk4sgEg?t=45m12s)]? It is never necessary to do
    more than one split at a level because you can just split them again.'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：是否有情况下最好分成3组？在一个级别上永远不需要做多次分割，因为你可以再次分割它们。'
- en: 'This is the entirety of creating a decision tree. Stopping condition:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 这就是创建决策树的全部过程。停止条件：
- en: When you hit the limit that was requested (`max_depth`)
  id: totrans-87
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当达到所请求的限制（`max_depth`）
- en: When your leaf nodes only have one thing in them
  id: totrans-88
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 当你的叶节点只有一个元素时
- en: Let’s make our decision tree better [[46:10](https://youtu.be/blyXCk4sgEg?t=46m10s)]
  id: totrans-89
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 让我们的决策树更好
- en: Right now, our decision tree has R² of 0.4\. Let’s make it better by removing
    `max_depth=3`. By doing so, the training R² becomes 1 (as expected since each
    leaf node contains exactly one element) and validation R² is 0.73 — which is better
    than the shallow tree but not as good as we would like.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，我们的决策树的R²为0.4。让我们通过去掉`max_depth=3`来使其更好。这样做后，训练R²变为1（因为每个叶节点只包含一个元素），验证R²为0.73——比浅树好，但不如我们希望的那么好。
- en: '[PRE6]'
  id: totrans-91
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: To make these trees better, we will create a forest. To create a forest, we
    will use a statistical technique called **bagging**.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让这些树更好，我们将创建一个森林。要创建一个森林，我们将使用一种称为**bagging**的统计技术。
- en: Bagging [[47:12](https://youtu.be/blyXCk4sgEg?t=47m12s)]
  id: totrans-93
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: Bagging
- en: Michael Jordan developed a technique called the **Bag of Little Bootstraps**
    in which he shows how to use bagging for absolutely any kind of model to make
    it more robust and also to give you confidence intervals.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 迈克尔·乔丹开发了一种称为**小自助袋**的技术，他展示了如何对任何类型的模型使用bagging，使其更加稳健，并为您提供置信区间。
- en: Random forest — a way of bagging trees.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 随机森林——一种bagging树的方法。
- en: So what is bagging? Bagging is an interesting idea which is what if we created
    five different models each of which was only somewhat predictive but the models
    gave predictions that were not correlated with each other. That would mean that
    the five models would have profound different insights into the relationships
    in the data. If you took the average of those five models, you are effectively
    bringing in the insights from each of them. So this idea of averaging models is
    a technique for **Ensembling**.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 那么什么是bagging？Bagging是一个有趣的想法，即如果我们创建了五个不同的模型，每个模型只是有些预测性，但这些模型给出的预测彼此之间没有相关性。这意味着这五个模型对数据中的关系有着截然不同的见解。如果你取这五个模型的平均值，你实际上是将每个模型的见解带入其中。因此，平均模型的这种想法是一种**集成**技术。
- en: What if we created a whole a lot of trees — big, deep, massively overfit trees
    but each one, let’s say, we only pick a random 1/10 of the data. Let’s say we
    do that a hundred times (different random sample every time). They are overfitting
    terribly but since they are all using different random samples, they all overfit
    in different ways on different things. In other words, they all have errors but
    the errors are random. The average of a bunch of random errors is zero. If we
    take the average of these trees each of which have been trained on a different
    random subset, the error will average out to zero and what is left is the true
    relationship — and that’s the random forest.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们创建了很多树——大的、深的、过度拟合的树，但每棵树只选择数据的随机1/10。假设我们这样做了一百次（每次使用不同的随机样本）。它们都过度拟合了，但由于它们都使用不同的随机样本，它们在不同的方面以不同的方式过度拟合。换句话说，它们都有错误，但这些错误是随机的。一堆随机错误的平均值是零。如果我们取这些树的平均值，每棵树都是在不同的随机子集上训练的，那么错误将平均为零，剩下的就是真正的关系——这就是随机森林。
- en: '[PRE7]'
  id: totrans-98
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: '`n_estimators` by default is 10 (remember, estimators are trees).'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '`n_estimators`默认为10（记住，estimators就是树）。'
- en: '**Question**: Are you saying we average 10 crappy models and we get a good
    model? [[51:25](https://youtu.be/blyXCk4sgEg?t=51m25s)] Exactly. Because the crappy
    models are based on different random subsets and their errors are not correlated
    with each other. If the errors were correlated, this will not work.'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：你是在说我们平均了10个糟糕的模型，然后得到了一个好模型吗？确实是这样。因为这些糟糕的模型是基于不同的随机子集，它们的错误之间没有相关性。如果错误是相关的，这种方法就行不通。'
- en: The key insight here is to construct multiple models which are better than nothing
    and where the errors are, as much as possible, not correlated with each other.
  id: totrans-101
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 这里的关键见解是构建多个比没有好的模型，而且错误尽可能不相关的模型。
- en: The number of trees to use is the first of our **hyper parameters** we are going
    to tune to achieve higher metric.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 要使用的树的数量是我们要调整的第一个**超参数**，以实现更高的度量。
- en: '**Question**: The subset you are selecting, are they exclusive? Can there be
    overlaps? [[52:27](https://youtu.be/blyXCk4sgEg?t=52m27s)] We talked about picking
    1/10 at random, but what scikit-learn does by default is for *n* rows, it picks
    out *n* rows with replacement — which is called **bootstrapping**. If memory serves
    correctly, on average, 63.2% of the rows will be represented and many of them
    will be appear multiple times.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：您选择的子集，它们是互斥的吗？是否可以重叠？[[52:27](https://youtu.be/blyXCk4sgEg?t=52m27s)]我们讨论了随机选择1/10，但scikit-learn默认情况下是对*n*行进行替换选择*n*行——这称为**自助法**。如果记忆无误，平均而言，63.2%的行将被表示，其中许多行将多次出现。'
- en: The entire purpose of modeling in machine learning is to find a model which
    tells you which variables are important and how do they interact together to drive
    your dependent variable. In practice, the difference between using the random
    forest space to find your nearest neighbors vs. Euclidean space is the difference
    between a model that makes good predictions and the model that makes meaningless
    predictions.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 机器学习中建模的整个目的是找到一个模型，告诉您哪些变量很重要，它们如何相互作用以驱动您的因变量。在实践中，使用随机森林空间来找到最近邻居与欧几里得空间之间的区别是一个模型做出良好预测和做出无意义预测之间的区别。
- en: The effective machine learning model is accurate at finding the relationships
    in the training data and generalizes well to new data [[55:53](https://youtu.be/blyXCk4sgEg?t=55m53s)].
    In bagging, that means that each of your individual estimators, you want them
    to be as predictive as possible but for the predictions of your individual trees
    to be as uncorrelated as possible. The research community found that the more
    important thing seems to be creating uncorrelated trees rather than more accurate
    trees. In scikit-learn, there is another class called `ExtraTreeClassifier` which
    is an extremely randomized tree model. Rather than trying every split of every
    variable, it randomly tries a few splits of a few variables which makes training
    much faster and it can build more trees — better generalization. If you have crappy
    individual models, you just need more trees to get a good end model.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的机器学习模型能够准确地找到训练数据中的关系，并且能够很好地泛化到新数据[[55:53](https://youtu.be/blyXCk4sgEg?t=55m53s)]。在装袋中，这意味着您希望每个单独的估计器尽可能具有预测性，但希望每棵树的预测尽可能不相关。研究界发现，更重要的事情似乎是创建不相关的树，而不是更准确的树。在scikit-learn中，还有另一个称为`ExtraTreeClassifier`的类，它是一种极端随机树模型。它不是尝试每个变量的每个分割，而是随机尝试几个变量的几个分割，这样训练速度更快，可以构建更多的树——更好的泛化。如果您有糟糕的单独模型，您只需要更多的树来获得一个好的最终模型。
- en: Coming up with predictions [[1:04:30](https://youtu.be/blyXCk4sgEg?t=1h4m30s)]
  id: totrans-106
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 提出预测[[1:04:30](https://youtu.be/blyXCk4sgEg?t=1h4m30s)]
- en: '[PRE8]'
  id: totrans-107
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: Each tree is stored in an attribute called `estimators_` . For each tree, we
    will call `predict` with our validation set. `np.stack` concatenates them together
    on a new axis, so the resulting `preds` has the shape of `(10, 12000)` (10 trees,
    12000 validation set). The mean of 10 predictions for the first data is 9.07,
    and the actual value is 9.10\. As you can see, none of the individual prediction
    is close to 9.10, but the mean ends up pretty good.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 每棵树都存储在名为`estimators_`的属性中。对于每棵树，我们将使用验证集调用`predict`。`np.stack`将它们连接在一起形成一个新轴，因此结果`preds`的形状为`(10,
    12000)`（10棵树，12000个验证集）。对于第一个数据的10个预测的平均值为9.07，实际值为9.10。正如你所看到的，没有一个单独的预测接近9.10，但平均值最终相当不错。
- en: '![](../Images/1d0b209325d7fb2cb781d086d1d8c22f.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/1d0b209325d7fb2cb781d086d1d8c22f.png)'
- en: Here is a plot of R² values given first *i* trees. As we add more trees, R²
    improves. But it seems as though it has flattened out.
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是给定前*i*棵树的R²值的图。随着我们添加更多的树，R²值会提高。但似乎已经趋于平缓。
- en: '![](../Images/6ec01506b6187930a5a6d97842773ba8.png)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/6ec01506b6187930a5a6d97842773ba8.png)'
- en: As you see, adding more trees do not help much. It will not get worse but it
    will stop improving things much. This is the first hyper parameter to learn to
    set — a number of estimators. A method of setting is, as many as you have time
    to fit and that actually seems to be helping.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 正如你所看到的，添加更多的树并没有太大帮助。它不会变得更糟，但也不会显著改善事情。这是要学会设置的第一个超参数——估计器的数量。一种设置的方法是，尽可能多地拟合，而且实际上似乎有所帮助。
- en: Adding more trees slows it down, but with less trees you can still get the same
    insights. So when Jeremy builds most of his models, he starts with 20 or 30 trees
    and at the end of the project or at the end of the day’s work, he will use 1000
    trees and run it over night.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 添加更多的树会减慢速度，但使用更少的树仍然可以获得相同的见解。所以当Jeremy构建大部分模型时，他从20或30棵树开始，项目结束或当天工作结束时，他会使用1000棵树并在夜间运行。
- en: Out-of-bag (OOB) score [[1:10:04](https://youtu.be/blyXCk4sgEg?t=1h10m4s)]
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 袋外（OOB）得分[[1:10:04](https://youtu.be/blyXCk4sgEg?t=1h10m4s)]
- en: Sometimes your dataset will be small and you will not want to pull out a validation
    set because doing so means you now do not have enough data to build a good model.
    However, random forests have a very clever trick called *out-of-bag (OOB) error*
    which can handle this (and more!)
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 有时您的数据集会很小，您不想提取验证集，因为这样做意味着您现在没有足够的数据来构建一个好的模型。然而，随机森林有一个非常聪明的技巧，称为*袋外（OOB）误差*，可以处理这种情况（以及更多！）
- en: What we could do is to recognize that in our first tree, some of the rows did
    not get used for training. What we could do is to pass those unused rows through
    the first tree and treat it as a validation set. For the second tree, we could
    pass through the rows that were not used for the second tree, and so on. Effectively,
    we would have a different validation set for each tree. To calculate our prediction,
    we would average all the trees where that row is not used for training. If you
    have hundreds of trees, it is very likely that all of the rows are going to appear
    many times in these out-of-bag samples. You can then calculate RMSE, R², etc on
    these out-of-bag predictions.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以意识到，在我们的第一棵树中，一些行没有用于训练。我们可以通过第一棵树传递那些未使用的行，并将其视为验证集。对于第二棵树，我们可以通过未用于第二棵树的行，依此类推。实际上，我们将为每棵树创建一个不同的验证集。为了计算我们的预测，我们将对所有未用于训练的行进行平均。如果您有数百棵树，那么很可能所有行都会在这些袋外样本中多次出现。然后，您可以在这些袋外预测上计算RMSE、R²等。
- en: '[PRE9]'
  id: totrans-117
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Setting `oob_score` to true will do exactly this and create an attribute called
    `oob_score_` to the model and as you see in the print_score function, if it has
    this attributes, it will print it out at the end.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 将`oob_score`设置为true将执行此操作，并为模型创建一个名为`oob_score_`的属性，如您在print_score函数中看到的，如果具有此属性，它将在最后打印出来。
- en: '**Question**: Wouldn’t `oob_score_` always lower than the one for the entire
    forest [[1:12:51](https://youtu.be/blyXCk4sgEg?t=1h12m51s)]? The accuracy tends
    to be lower because each row appears in less trees in the OOB samples than it
    does in the full set of trees. So OOB R² will slightly underestimate how generalizable
    the model is, but the more trees you add, the less serious that underestimation
    is.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：`oob_score_`难道不总是低于整个森林的分数吗[[1:12:51](https://youtu.be/blyXCk4sgEg?t=1h12m51s)]？准确率往往较低，因为在OOB样本中，每行出现的树较少，而在完整树集中出现的次数较多。因此，OOB
    R²会稍微低估模型的泛化能力，但是您添加的树越多，这种低估就越不严重。'
- en: OOB score will come in handy when setting hyper parameters [[1:13:47](https://youtu.be/blyXCk4sgEg?t=1h13m47s)].
    There will be quite a few hyper parameters that we are going to set and we would
    like to find some automated say to set them. One way to do that is to do **grid
    search**. Scikit-learn has a function called grid search and you pass in a list
    of all the hyper parameters you want to tune and all of the values of these hyper
    parameters you want to try. It will run your model on every possible combination
    of all these hyper parameters and tell you which one is the best. OOB score is
    a great choice for getting it to tell you which one is the best.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 在设置超参数时，OOB分数会派上用场[[1:13:47](https://youtu.be/blyXCk4sgEg?t=1h13m47s)]。我们将设置相当多的超参数，并希望找到一种自动化的方法来设置它们。一种方法是进行**网格搜索**。Scikit-learn有一个名为网格搜索的函数，您可以传入要调整的所有超参数的列表以及要尝试的所有这些超参数的值。它将在所有这些超参数的所有可能组合上运行您的模型，并告诉您哪一个是最佳的。OOB分数是一个很好的选择，可以告诉您哪一个是最佳的。
- en: Subsampling [[1:14:52](https://youtu.be/blyXCk4sgEg?t=1h14m52s)]
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 子采样[[1:14:52](https://youtu.be/blyXCk4sgEg?t=1h14m52s)]
- en: Earlier, we took 30,000 rows and created all the models which used a different
    subset of that 30,000 rows. Why not take a totally different subset of 30,000
    each time? In other words, let’s leave the entire 389,125 records as is, and if
    we want to make things faster, pick a different subset of 30,000 each time. So
    rather than bootstrapping the entire set of rows, just randomly sample a subset
    of the data.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 之前，我们取了30,000行，并创建了使用该30,000行不同子集的所有模型。为什么不每次取一个完全不同的30,000子集？换句话说，让我们保留全部389,125条记录，如果我们想加快速度，每次选择一个不同的30,000子集。因此，而不是对整个行集进行自助抽样，只需随机抽取数据的一个子集。
- en: '[PRE10]'
  id: totrans-123
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: '`set_rf_samples` : Just as before, we use 20,000 of them in our training set
    (before it was out of 30,000, this time it is out of 389,125).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: '`set_rf_samples`：与之前一样，我们在训练集中使用20,000个样本（之前是30,000，这次是389,125）。'
- en: '![](../Images/817b6f2671f11939883ea5af40d7abce.png)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
  zh: '![](../Images/817b6f2671f11939883ea5af40d7abce.png)'
- en: This will take the same amount of time to run as before, but every tree has
    an access to the entire dataset. After using 40 estimators, we get the R² score
    of 0.876.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 这将花费与之前相同的时间来运行，但是每棵树都可以访问整个数据集。在使用40个估计器后，我们得到了R²分数为0.876。
- en: '**Question**: What samples is this OOB score calculated on [[1:18:26](https://youtu.be/blyXCk4sgEg?t=1h18m26s)]?
    Scikit-learn does not support this out of box, so `set_rf_samples` is a custom
    function. So OOB score needs to be turned off when using `set_rf_samples` as they
    are not compatible. `reset_rf_samples()` will turn it back to the way it was.'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '**问题**：这个OOB分数是在哪些样本上计算的[[1:18:26](https://youtu.be/blyXCk4sgEg?t=1h18m26s)]？Scikit-learn不支持这个功能，因此`set_rf_samples`是一个自定义函数。因此，在使用`set_rf_samples`时，需要关闭OOB分数，因为它们不兼容。`reset_rf_samples()`将把它恢复到原来的状态。'
- en: '**The biggest tip [**[**1:20:30**](https://youtu.be/blyXCk4sgEg?t=1h20m30s)**]**:
    Most people run all of their models on all of the data all of the time using their
    best possible parameters which is just pointless. If you are trying to find out
    which feature is important and how they are related to each other, having that
    4th decimal place of accuracy is not going to change any of your insights at all.
    Do most of your models on a large enough sample size that your accuracy is reasonable
    (within a reasonable distance of the best accuracy you can get) and taking a small
    number of seconds to train so that you can interactively do your analysis.'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: '**最重要的提示[**[**1:20:30**](https://youtu.be/blyXCk4sgEg?t=1h20m30s)**]**：大多数人总是使用最佳参数在所有时间内在所有数据上运行所有模型，这是毫无意义的。如果您想找出哪些特征重要以及它们之间的关系，那么准确度的第四位小数点根本不会改变您的任何见解。在足够大的样本量上运行大多数模型，使得您的准确度合理（在最佳准确度的合理距离内），并且训练时间短，以便您可以交互式地进行分析。'
- en: A couple more parameters [[1:21:18](https://youtu.be/blyXCk4sgEg?t=1h21m18s)]
  id: totrans-129
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 另外两个参数[[1:21:18](https://youtu.be/blyXCk4sgEg?t=1h21m18s)]
- en: 'Let’s get a baseline for this full set to compare to:'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们为这个完整集合建立一个基准来进行比较：
- en: '[PRE11]'
  id: totrans-131
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: Here OOB is higher than validation set. This is because our validation set is
    a different time period whereas OOB samples are random. It is much harder to predict
    a different time period.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: min_sample
  id: totrans-133
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-134
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '`min_sample_leaf=3` : Stop training the tree further when a leaf node has 3
    or less samples (before we were going all the way down to 1). This means there
    will be one or two less levels of decision being made which means there are half
    the number of actual decision criteria we have to train (i.e. faster training
    time).'
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For each tree, rather than just taking one point, we are taking the average
    of at least three points that we would expect the each tree to generalize better.
    But each tree is going to be slightly less powerful on its own.
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The numbers that work well are 1, 3, 5, 10, 25, but it is relative to your overall
    dataset size.
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By using 3 instead of 1, validation R² improved from 0.89 to 0.90
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: max_feature [[1:24:07](https://youtu.be/blyXCk4sgEg?t=1h24m7s)]
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: '`max_features=0.5` : The idea is that the less correlated your trees are with
    each other, the better. Imagine you had one column that was so much better than
    all of the other columns of being predictive that every single tree you built
    always started with that column. But there might be some interaction of variables
    where that interaction is more important than the individual column. So if every
    tree always splits on the same thing the first time, you will not get much variation
    in those trees.'
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In addition to taking a subset of rows, at every single split point, take a
    different subset of columns.
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For row sampling, each new tree is based on a random set of rows, for column
    sampling, every individual binary split, we choose from a different subset of
    columns.
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 0.5 means randomly choose a half of them. There are special values you can use
    such as `sqrt` or `log2`
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Good values to use are `1`, `0.5`, `log2`, or `sqrt`
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The RMSLE of 0.2286 would get us to the top 20 of this competition — with brainless
    random forest with some brainless minor hyper parameter tuning. This is why Random
    Forest is such an important not just first step but often only step of machine
    learning. It is hard to screw up.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: Why Random Forest works so well [[1:30:21](https://youtu.be/blyXCk4sgEg?t=1h30m21s)]
  id: totrans-147
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Let’s take a look at one of the split point in the small single tree.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '`fiProductClassDesc ≤ 7.5` will split:'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '![](../Images/46ae37683485345da711862364122c3c.png)'
  id: totrans-150
  prefs: []
  type: TYPE_IMG
- en: Why does this even work? Imagine the only thing that mattered was `Hydraulic
    Excavator, Track − 0.0 to 2.0 Metric Tons` and nothing else mattered. It can pick
    out a single element by first splitting `fiProductClassDesc ≤ 5.5` then `fiProductClassDesc
    > 4.5` . With just two splits, we can pull out a single category. Tree is infinitely
    flexible even with a categorical variable. If there is a particular category which
    has different level of price, it can gradually zoom in on those group by using
    multiple splits. Random forest is very easy to use and very resilient.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: Next lesson, we will learn about how to analyze the model to learn more about
    the data to make it even better.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
