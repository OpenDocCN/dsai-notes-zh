- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:31:43'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2406.04867] Deep learning for precipitation nowcasting: A survey from the
    perspective of time series forecasting'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2406.04867](https://ar5iv.labs.arxiv.org/html/2406.04867)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep learning for precipitation nowcasting:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A survey from the perspective of time series forecasting
  prefs: []
  type: TYPE_NORMAL
- en: Sojung An [sojungan@kiaps.org](mailto:sojungan@kiaps.org) Tae-Jin Oh [oht@kiaps.org](mailto:oht@kiaps.org)
    Eunha Sohn [soneh0431@korea.kr](mailto:soneh0431@korea.kr) Donghyun Kim [d_kim@korea.ac.kr](mailto:d_kim@korea.ac.kr)
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Deep learning-based time series forecasting has dominated the short-term precipitation
    forecasting field with the help of its ability to estimate motion flow in high-resolution
    datasets. The growing interest in precipitation nowcasting offers substantial
    opportunities for the advancement of current forecasting technologies. Nevertheless,
    there has been a scarcity of in-depth surveys of time series precipitation forecasting
    using deep learning. Thus, this paper systemically reviews recent progress in
    time series precipitation forecasting models. Specifically, we investigate the
    following key points within background components, covering: i) preprocessing,
    ii) objective functions, and iii) evaluation metrics. We then categorize forecasting
    models into recursive and multiple strategies based on their approaches to predict
    future frames, investigate the impacts of models using the strategies, and performance
    assessments. Finally, we evaluate current deep learning-based models for precipitation
    forecasting on a public benchmark, discuss their limitations and challenges, and
    present some promising research directions. Our contribution lies in providing
    insights for a better understanding of time series precipitation forecasting and
    in aiding the development of robust AI solutions for the future.'
  prefs: []
  type: TYPE_NORMAL
- en: \affiliation
  prefs: []
  type: TYPE_NORMAL
- en: '[label1]organization=Korea Institute of Atmospheric Prediction Systems, addressline=35,
    Boramae-ro, Dongjak-gu, city=Seoul, postcode=07071, country=Republic of Korea
    \affiliation[label2]organization=National Meteorological Satellite Center, addressline=61-18,
    Guam-gil, Gwanghyewon-myeon, city=Jincheon-gun, postcode=27803, country=Republic
    of Korea \affiliation[label3]organization=Korea University, addressline=145, Anam-ro,
    Seongbuk-gu, city=Seoul, postcode=02841, country=Republic of Korea'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Over the past decades, the world has relied on weather forecasts to warn the
    public about hazardous weather, agriculture, and energy use. Accurate precipitation
    nowcasting, in particular, has gained more attention for preventing severe weather-related
    damage due to the high degree of uncertainty in extreme precipitation cases. The
    concept of precipitation nowcasting emerged with the advancement of radar sensor
    (Browning and Collier, [1989](#bib.bib14)).
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S1.p2.pic1" class="ltx_picture" height="69.42" overflow="visible" version="1.1"
    width="600"><g transform="translate(0,69.42) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 21.65 13.78)"><foreignobject width="556.69" height="41.86" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible" color="#000000">Precipitation Nowcasting is
    the short-term precipitation forecasting (up to 6 hours) of providing highly detailed
    predictions of localized weather phenomena that undergo significant changes.</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: Traditional nowcasting models primarily relied on extrapolating radar observations
    with the Lagrangian advection assumption (Germann and Zawadzki, [2002](#bib.bib33)).
    The systems limit their ability to forecast the formation or dissipation of rainfall,
    resulting in predictions primarily focused on rainfall movement. With the increasing
    demand for accurate precipitation forecasting to mitigate potential damages, the
    research scope has expanded to apply machine learning (Shi et al., [2015](#bib.bib81);
    Wang et al., [2017](#bib.bib94)). This expansion aligns with the broader trend
    seen in recent decades, where deep learning (DL) has increasingly been utilized
    across various domains, with precipitation nowcasting being no exception.
  prefs: []
  type: TYPE_NORMAL
- en: DL-based techniques for time series forecasting have acted as a significant
    milestone in precipitation forecasting. For the problem of precipitation nowcasting,
    Shi et al. ([2015](#bib.bib81)) formulated precipitation nowcasting from radar
    observations as a time series forecasting task. They proposed ConvLSTM which estimates
    motion flow from high-resolution datasets, thereby enhancing the prediction accuracy
    of extreme weather events. Subsequent studies have leveraged DL for precipitation
    nowcasting, achieving better performance compared to the traditional methods.
    For example, DGMR (Ravuri et al., [2021](#bib.bib72)), a 90-minute (min) prediction
    system, demonstrated its potential in time series forecasting. However, radar-based
    nowcasting models face scalability limitations due to the fixed locations of radar
    systems. Moreover, the installation of radar systems is expensive and requires
    agreements with local authorities and communities, as well as trained personnel
    for operation. From this perspective, combining satellite imagery with radar data
    has surfaced as a promising approach to overcome the constraints of radar-based
    nowcasting (Lebedev et al., [2019](#bib.bib53); Sønderby et al., [2020](#bib.bib84);
    Horváth et al., [2021](#bib.bib41)). Although satellites primarily observe clouds
    rather than precipitation directly, satellite imagery exhibits features that significantly
    influence precipitation. By leveraging satellite data, it is possible to address
    these limitations and expand the scope of nowcasting to cover larger territories.
  prefs: []
  type: TYPE_NORMAL
- en: With increasing datasets becoming publicly available, researchers are exploring
    innovative approaches to predict precipitation from the point of view of time
    series forecasting. While precipitation forecasting has attracted the attention
    of the research community, few technical surveys have been conducted in this area.
    Indeed, it is still challenging to find datasets for precipitation nowcasting
    and to stay aware of the latest developments. This requires a review on concepts
    involving process, dataset information, evaluation, and many others that are relevant
    to the nowcasting and its strategy of designing DL models. Through the extensive
    examination conducted in our survey, we advocate fostering faster and more comprehensive
    progress in exploring the domain of precipitation forecasting. The main contributions
    of this survey can be summarized in five-fold.
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze key challenges caused by real-world datasets and provide practical implications
    for preprocessing observation data. Observation data (e.g., radar reflectivity
    and satellites) have been less investigated than commonly used images. This limited
    exploration hinders broader application and advancement of knowledge in this area,
    thus confining the domain of precipitation forecasting to specific research groups.
    To improve the capability of precipitation forecasting, we made greater efforts
    to bridge the knowledge between data preprocessing (e.g., normalization and sampling)
    and different sensor datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Outline effective objective functions in precipitation forecasting and provide
    basic evaluation criteria. As numerous research works have been published on precipitation
    forecasting models, we analyze approaches to precipitation forecasting and review
    them depending on how previous literature design objective functions for scientific
    modeling. We then provide an overview to generalize the methods of reliability
    assessment of precipitation forecasting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Present a comprehensive review of relevant works categorized based on operational
    principles, summarizing the current state-of-the-art. In comparison with other
    related reviews, our work surveys up-to-date technology of applications and is
    not restricted to a few network frameworks. In the context of architecture, this
    study reviews various applications, encompassing Diffusion- and Transformer-based
    models for precipitation forecasting.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (4)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Compare the performance of precipitation forecasting models and offers insights
    into their methodologies. We conduct a comparison of prominent models to assist
    researchers interested in extending their capabilities to real-life systems. Moreover,
    we evaluate the effectiveness of the models across various thresholds and over
    time, highlighting unresolved challenges within this field. To the best of our
    knowledge, this is the first review paper to present comparison results for DL
    models using benchmark datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (5)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Engage in a discussion of various research directions and outline prevailing
    challenges in the field. While many researchers are making progress in precipitation
    forecasting, there is still room for further advancements. Precipitation forecasting
    models simulate the dynamics of natural phenomena, and learning representations
    from sparse precipitation data degrades the performance of AI models. Additionally,
    predicting changes in long-term trends or fusing the multi-sensor dataset remains
    an unsolved problem. Therefore we discuss potential solutions to address these
    problems, exploring in a discussion of various research directions.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The structure of the paper is as follows: Section [2](#S2 "2 Background and
    related works ‣ Deep learning for precipitation nowcasting: A survey from the
    perspective of time series forecasting") presents the background on time series
    precipitation forecasting and compares related surveys. Section [3](#S3 "3 Datasets
    for precipitation nowcasting ‣ Deep learning for precipitation nowcasting: A survey
    from the perspective of time series forecasting") provides a prominent dataset
    in precipitation nowcasting and Section [4](#S4 "4 Preprocessing ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")
    reviews preprocessing techniques for observation data from different sensors.
    Section [5](#S5 "5 Objective functions ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting") introduces the proposed
    objective function for precipitation forecasting and Section [6](#S6 "6 Evaluation
    metrics ‣ Deep learning for precipitation nowcasting: A survey from the perspective
    of time series forecasting") gives an overview of the basic evaluation functions.
    Next, Section [7](#S7 "7 Recursive strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting") and Section [8](#S8
    "8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting") present a comprehensive review that
    categorizes existing literature on DL-based models. Then, Section [9](#S9 "9 Methodology
    comparison and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting") provides the comparison and evaluation
    on a public benchmark, and Section [10](#S10 "10 Future challenges and opportunities
    ‣ 9.2 Performance evaluation ‣ 9 Methodology comparison and evaluation ‣ 8.3.3
    Periodic component ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting") discusses future research directions. Finally, the conclusions are
    presented in Section [11](#S11 "11 Conclusion ‣ 10.4 Standard evaluation protocols
    ‣ 10 Future challenges and opportunities ‣ 9.2 Performance evaluation ‣ 9 Methodology
    comparison and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting").'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Background and related works
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section introduces preliminaries relevant to this survey, including the
    taxonomy of precipitation nowcasting (Section [2.1](#S2.SS1 "2.1 Preliminaries
    of time series precipitation forecasting ‣ 2 Background and related works ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting")), and provides an analysis of the existing surveys in deep learning
    applied to nowcasting (Section [2.2](#S2.SS2 "2.2 Related surveys ‣ 2 Background
    and related works ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting")).'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S2.F1.pic1" class="ltx_picture ltx_centering" height="345.24" overflow="visible"
    version="1.1" width="471.07"><g transform="translate(0,345.24) matrix(1 0 0 -1
    0 0) translate(225.08,0) translate(0,210.76)"><g stroke="#000000" fill="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -167.95 -129.86)" fill="#000000"
    stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 219.03)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 178.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 64 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 172.19)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 175.65)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="203.67" height="12.3" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">Precipitation nowcasting problem</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 259.72)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="335.9"
    height="81.38" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">| $x_{1}$
    | $\cdots$ | $x_{m}$ | $\rightarrow$ | $x_{m+1}$ | $\cdots$ | $x_{m+n}$ |
  prefs: []
  type: TYPE_NORMAL
- en: '| ![Refer to caption](img/48c0fd6eba078b0c47baf38e7d62b60f.png) | ![Refer to
    caption](img/48c0fd6eba078b0c47baf38e7d62b60f.png) | ![Refer to caption](img/68945325518daf2f7c6d3581035d6c3f.png)
    | ![Refer to caption](img/68945325518daf2f7c6d3581035d6c3f.png) |</foreignobject></g></g></g></g>
    <g transform="matrix(1.0 0.0 0.0 1.0 -164.02 -205.52)" fill="#000000" stroke="#000000"
    color="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 196.19)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 178.19)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 172.115)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 175.5)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="111.89" height="12.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Recursive strategy</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 214.19)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 10.75 0)"><foreignobject width="90"
    height="36" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/db9cc728e07ea09e796aa23f7b62819b.png)</foreignobject></g></g></g></g>
    <g stroke="#000000" fill="#000000" stroke-dasharray="3.0pt,3.0pt" stroke-dashoffset="0.0pt"
    color="#000000"><g transform="matrix(1.0 0.0 0.0 1.0 -220.47 -161.09)" fill="#000000"
    stroke="#000000"><foreignobject width="137.8" height="12.15" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible"><svg id="S2.F1.pic1.13.13.13.13.13.13.13.13.13.13.13.13.13.13.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.pic1"
    class="ltx_picture ltx_align_left" height="12.15" overflow="visible" version="1.1"
    width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">N</foreignobject></g></g></svg> Non-adversarial
    <g stroke="#000000" fill="#000000"><path d="M -168.91 -181.1 L -143.54 -146.51"
    style="fill:none"></path></g><g stroke="#000000" fill="#000000"><g transform="matrix(1.0
    0.0 0.0 1.0 -107.45 -163.56)"><g class="ltx_nestedsvg" transform="matrix(1 0 0
    1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#CCE5FF"
    fill-opacity="1.0"><path d="M 0 4.15 L 0 8 C 0 10.3 1.86 12.15 4.15 12.15 L 8.65
    12.15 C 10.94 12.15 12.8 10.3 12.8 8 L 12.8 4.15 C 12.8 1.86 10.94 0 8.65 0 L
    4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g fill="#CCE5FF"
    fill-opacity="1.0"><path d="M 1.38 4.15 L 1.38 8 C 1.38 9.53 2.62 10.77 4.15 10.77
    L 8.65 10.77 C 10.18 10.77 11.42 9.53 11.42 8 L 11.42 4.15 C 11.42 2.62 10.18
    1.38 8.65 1.38 L 4.15 1.38 C 2.62 1.38 1.38 2.62 1.38 4.15 Z" style="stroke:none"></path></g><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">A</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="69.34" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Adversarial</foreignobject></g></g><path d="M
    -47.63 -181.1 L -73 -146.51" style="fill:none"></path></g><g transform="matrix(1.0
    0.0 0.0 1.0 55.94 -205.6)" fill="#000000" stroke="#000000" color="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 196.34)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 178.34)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 172.19)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 175.65)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="104.66" height="12.3" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible">Multiple strategy</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 214.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.33 0)"><foreignobject width="90"
    height="36" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/6283ec7fe9ff2eb344173448af895b46.png)</foreignobject></g></g></g></g><g
    stroke="#000000" fill="#000000" color="#000000"><path d="M 148.07 -134.75 L 51.05
    -46.44" style="fill:none"></path></g> <g transform="matrix(1.0 0.0 0.0 1.0 -1.97
    -158.86)" fill="#000000" stroke="#000000" color="#000000"><foreignobject width="47.24"
    height="16.6" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><svg id="S2.F1.pic1.15.15.15.15.15.15.15.15.15.15.15.15.15.2.2.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.pic1"
    class="ltx_picture ltx_align_left" height="12.15" overflow="visible" version="1.1"
    width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">U</foreignobject></g></g></svg> UNet</foreignobject></g>
    <g stroke="#000000" fill="#000000" color="#000000"><path d="M 51.05 -137.41 L
    40.99 -144.29" style="fill:none"></path></g> <g transform="matrix(1.0 0.0 0.0
    1.0 72.83 -158.86)" fill="#000000" stroke="#000000" color="#000000"><foreignobject
    width="70.87" height="16.6" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"><svg
    id="S2.F1.pic1.16.16.16.16.16.16.16.16.16.16.16.16.16.3.3.3.3.2.2.1.1.1.1.1.1.1.1.1.1.1.1.1.pic1"
    class="ltx_picture ltx_align_left" height="12.15" overflow="visible" version="1.1"
    width="12.93"><g transform="translate(0,12.15) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.4" height="6.62" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">D</foreignobject></g></g></svg> Diffusion</foreignobject></g>
    <g stroke="#000000" fill="#000000" color="#000000"><path d="M 108.27 -210.49 L
    108.27 -144.29" style="fill:none"></path></g><g stroke="#000000" fill="#000000"
    color="#000000"><g transform="matrix(1.0 0.0 0.0 1.0 148.39 -163.56)"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill="#FFE5CC" fill-opacity="1.0"><path d="M 0 4.15 L 0 8 C 0 10.3 1.86 12.15
    4.15 12.15 L 8.38 12.15 C 10.67 12.15 12.53 10.3 12.53 8 L 12.53 4.15 C 12.53
    1.86 10.67 0 8.38 0 L 4.15 0 C 1.86 0 0 1.86 0 4.15 Z" style="stroke:none"></path></g><g
    fill="#FFE5CC" fill-opacity="1.0"><path d="M 1.38 4.15 L 1.38 8 C 1.38 9.53 2.62
    10.77 4.15 10.77 L 8.38 10.77 C 9.91 10.77 11.15 9.53 11.15 8 L 11.15 4.15 C 11.15
    2.62 9.91 1.38 8.38 1.38 L 4.15 1.38 C 2.62 1.38 1.38 2.62 1.38 4.15 Z" style="stroke:none"></path></g><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">T</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="73.99" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Transformer</foreignobject></g></g><path d="M
    165.49 -137.42 L 178.81 -146.51" style="fill:none"></path></g><g transform="matrix(1.0
    0.0 0.0 1.0 -183.6 -106.06)" fill="#000000" stroke="#000000"><foreignobject width="20.74"
    height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$x_{1:m}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -113.65 -107.94)" fill="#000000" stroke="#000000"><foreignobject
    width="10.77" height="11.99" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$h_{t}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -53.62 -105.74)" fill="#000000" stroke="#000000"><foreignobject
    width="44.25" height="9.1" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$x_{m+1:m+n}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 32.94 -106.06)" fill="#000000" stroke="#000000"><foreignobject
    width="20.74" height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$x_{1:m}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 104.28 -109.13)" fill="#000000" stroke="#000000"><foreignobject
    width="7.97" height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$h$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 162.92 -105.74)" fill="#000000" stroke="#000000"><foreignobject
    width="44.25" height="9.1" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$x_{m+1:m+n}$</foreignobject></g><g
    stroke-width="0.8pt" fill="#000000" stroke="#000000" color="#000000"><path d="M
    -84.65 -110.24 M -78.74 -110.24 C -64.76 -115.23 -66.94 -122.68 -83.59 -126.88
    C -100.25 -131.07 -125.08 -130.42 -139.06 -125.42 C -151.34 -121.03 -151.34 -114.63
    -145.61 -112.58" style="fill:none"><g transform="matrix(0.94164 0.33665 -0.33665
    0.94164 -145.35 -112.49)" stroke-dasharray="none" stroke-dashoffset="0.0pt" stroke-linejoin="miter"><path
    d="M 5.73 0 L 0.55 3.03 L 0 0 L 0.55 -3.03 Z"></path></g></path></g>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: Paradigms in precipitation nowcasting. We classify forecasting models
    at the first level based on two training strategies: the recursive strategy and
    the multiple strategy. While the recursive strategy predicts future time steps
    sequentially at each step $t$, the multiple strategy predicts future frames simultaneously.
    At the second sub-level, models of the recursive strategy are classified into
    non-adversarial and adversarial-based categories, and multiple strategy models
    are categorized into UNet, Diffusion, and Transformer.'
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Preliminaries of time series precipitation forecasting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Time series precipitation forecasting aims to predict future time steps using
    historical observations. Given historical observation data $\mathbf{X}=\left\{x_{1},x_{2},\cdots,x_{m}\right\}\in\mathbb{R}^{c\times
    m\times h\times w}$, we denote the number of variates, the input frames, height,
    and width as $c,m,h$, and $w$, respectively. Time series forecasting aims to predict
    $\mathbf{Y}=\left\{x_{m+1},x_{m+2},\cdots,x_{m+n}\right\}\in\mathbb{R}^{n\times
    h\times w}$, where $n$ refers to future time frames. There are two different approaches
    to predicting future time frames in time series data: univariate input data ($c$=1),
    which involves a series with a single time-dependent radar dataset (Ravuri et al.,
    [2021](#bib.bib72); Zhang et al., [2023](#bib.bib107)), and multivariate input
    data ($c>$1), which incorporates satellite datasets or additional weather variables
    (Sønderby et al., [2020](#bib.bib84); Fernández and Mehrkanoon, [2021](#bib.bib25)).
    Note that we define the forecasting problem as the same for both types of data.
    The ground-truth pairs are set to GT = $\bigl{\{}x_{1:m},\,x_{m+1:m+n}\bigl{\}}$.
    Let the forecasting model $G_{\theta}$ with parameters $\theta$ have the objective
    function (denoted $\mathcal{L}(\theta)$) that minimizes future ground-truth time
    series observations and prediction results, as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}(\theta)=\mathbb{E}(G_{\theta}(h;x_{1:m}-x_{m+1:m+n}),$ |  |
    (1) |'
  prefs: []
  type: TYPE_TB
- en: where $h$ represents hidden states. Many DL models widely used in computer vision
    tasks have been proposed to boost the performance of nowcasting, such as convolutional
    neural networks (Sønderby et al., [2020](#bib.bib84); Zhang et al., [2023](#bib.bib107)),
    recurrent neural networks (Wang et al., [2022](#bib.bib95); She et al., [2023](#bib.bib79)),
    Transformers (Gao et al., [2022](#bib.bib30); Ning et al., [2023](#bib.bib66)),
    and so on. Recently, with the boom of generating radar frames with realistic radar
    frames, generative models have attracted much attention various models came out,
    such as adversarial-based models, e.g., DGMR (Ravuri et al., [2021](#bib.bib72))
    and diffusion-based models, e.g., Prediff (Gao et al., [2023](#bib.bib28)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure [1](#S2.F1 "Figure 1 ‣ 2 Background and related works ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")
    summarizes the precipitation nowcasting approaches categorized by two strategies
    and some relevant subsets of the categories. The recursive strategy recursively
    predicts future time steps one at a time and updates the forecast at each time
    step. Given a sample time step $t\in\{m+1,\cdots,m+n\}$, a model $G_{\theta}$
    involves to predict the value at the next time step $x_{t+1}=G_{\theta}(h_{t};x_{1:t})$,
    where $h_{t}$ represents hidden state at time step $t$. To be more specific, the
    recursive learning problem can be represented as:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(Y&#124;X)=\prod_{t=m+1}^{m+n}P(x_{t}&#124;x_{1},\cdots,x_{t-1}).$ |  |
    (2) |'
  prefs: []
  type: TYPE_TB
- en: 'This approach updates the hidden states at each time step and repeats the process
    until the final time step is reached. In the multiple strategy, the future time
    steps are predicted with a hidden state $h$ as follows: $x_{\forall t}=G_{\theta}(h;x_{1:m})$.
    The approach aims to forecast multiple time steps ahead at once, and can be expressed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $P(Y&#124;X)=P(x_{m+1},\cdots,x_{m+n}&#124;x_{1},\cdots,x_{m}).$ |  |
    (3) |'
  prefs: []
  type: TYPE_TB
- en: This means that models learn the time dependence based on a hidden state to
    estimate $n$ future steps with respect to $m$ time steps, not each individual
    time step.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Related surveys
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In recent years, several surveys surfaced on the topic of precipitation nowcasting
    to explore the methods that have been used in this field and to identify areas
    for future improvement in performance. Existing surveys on precipitation nowcasting
    can be categorized into two groups.
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'High-level overview: Most surveys emphasize the ongoing challenge of balancing
    model accuracy with computational efficiency in weather nowcasting, particularly
    regarding the limitations of current approaches in predicting extreme weather
    events (Ashok and Pekkat, [2022](#bib.bib7); Verma et al., [2023](#bib.bib92);
    Upadhyay et al., [2024](#bib.bib90); Salcedo-Sanz et al., [2024](#bib.bib75)).
    However, these papers provide a comprehensive overview rather than a technical
    comparison of DL-based precipitation forecasting, arranged with statistical methods
    and numerical weather prediction (NWP)-based approaches. Therefore, they omit
    methodological discussions regarding strengths and weaknesses, leading to a limited
    understanding of practical constraints when constructing DL models.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Methodological analysis: These surveys categorized nowcasting models into stochastic
    and deterministic methods, aiming to enhance understanding of the research field
    by reviewing DL-based models from a technical standpoint (Prudden et al., [2020](#bib.bib71);
    Gao et al., [2021](#bib.bib29)). The studies highlight key research areas with
    pointers to the relevant sections, but the surveys are previous methods. The absence
    of recent architectures in existing literature restricts the comprehensive analysis
    of state-of-the-art nowcasting models. This limitation requires the need for a
    survey paper to fill the gap and provide a more inclusive examination of recent
    nowcasting methodologies.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: After conducting an analysis of existing survey papers, we identified a gap
    in the literature - a lack of an in-depth survey on precipitation nowcasting that
    investigates their performances across recent methodological approaches. Not only
    does our research aim to provide a more theoretically and practically grounded
    understanding of precipitation nowcasting, but it also offers a systematic review
    of the overall process for initiating nowcasting research. Note that the majority
    of the work presented is related to modeling for sensor datasets and that many
    varieties of DL frameworks are often based on radar-based nowcasting. This survey
    does not differentiate between univariate forecasting using radar sensors and
    multivariate forecasting by combining other sensors, and review nowcasting applications.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S2.F2.pic1" class="ltx_picture ltx_centering" height="230.22" overflow="visible"
    version="1.1" width="701.66"><g transform="translate(0,230.22) matrix(1 0 0 -1
    0 0) translate(350.33,0) translate(0,115.11)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -286.69 -90.07)" fill="#000000"
    stroke="#000000"><foreignobject width="100.93" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">(a) Precipitation</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -101.8 -90.07)" fill="#000000" stroke="#000000"><foreignobject width="46.12"
    height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(b) VIS</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 55.68 -90.07)" fill="#000000" stroke="#000000"><foreignobject
    width="46.12" height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">(c)
    WV</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 217.1 -90.07)" fill="#000000"
    stroke="#000000"><foreignobject width="38.24" height="13.84" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">(d) IR</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -345.72 -110.5)" fill="#000000" stroke="#000000"><foreignobject width="219"
    height="221" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/51c2200ad1b161d86b3f9f06703368c2.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -188.24 -110.5)" fill="#000000" stroke="#000000"><foreignobject width="219"
    height="221" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/d770321876d0cb01879ae156a3534805.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -30.76 -110)" fill="#000000" stroke="#000000"><foreignobject width="219"
    height="220" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/8166ee7236b874762aa6c7d2ae944cc7.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 125.72 -110.5)" fill="#000000" stroke="#000000"><foreignobject width="221"
    height="221" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/ce4b1b1ae05127cbc2118b7ff1a4c418.png)</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: Visualization of the SEVIR dataset from April 30, 2019, at 18 UTC.
    The images depicting weather events captured over the contiguous US. (a) Vertically
    integrated liquid of NEXRAD radar. (b) GOES-16 satellite channel 2 visible (VIS).
    (c) GOES-16 satellite channel 9 water vapor (WV). (d) GOES-16 satellite channel
    13 infrared (IR). (Source) The images were obtained from the SEVIR official page.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Datasets for precipitation nowcasting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section discusses the properties of the sensory dataset used for precipitation
    nowcasting. We specifically explore the data processing for weather radar (Section [3.1](#S3.SS1
    "3.1 Weather radar ‣ 3 Datasets for precipitation nowcasting ‣ Deep learning for
    precipitation nowcasting: A survey from the perspective of time series forecasting"))
    and for the weather satellites (Section [3.2](#S3.SS2 "3.2 Weather satellite ‣
    3 Datasets for precipitation nowcasting ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting")). Then, we highlight
    how the two different sensory datasets are combined (Section [3.3](#S3.SS3 "3.3
    Sensor fusion ‣ 3 Datasets for precipitation nowcasting ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")), and a
    comprehensive review of the available datasets for each sensor type is presented
    (Section [3.4](#S3.SS4 "3.4 Available datasets ‣ 3 Datasets for precipitation
    nowcasting ‣ Deep learning for precipitation nowcasting: A survey from the perspective
    of time series forecasting")). Figure [2](#S2.F2 "Figure 2 ‣ 2.2 Related surveys
    ‣ 2 Background and related works ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting") shows an example of
    an RGB composite image in the SEVIR dataset (Veillette et al., [2020](#bib.bib91)),
    which is visualized across four different data types: (a) composite radar imagery,
    (b) visible satellite imagery, (c) Water vapor satellite imagery, and (d) Infrared
    satellite imagery'
  prefs: []
  type: TYPE_NORMAL
- en: '|   | HKO-7 | IowaRain | RYDL | MRMS | Shanghai | SEVIR | OPERA | Meteonet
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | (Shi et al., [2017](#bib.bib82)) | (Sit et al., [2021](#bib.bib83)) |
    (Ayzel et al., [2020](#bib.bib8)) | (NCEP, [2018](#bib.bib65)) | (Chen et al.,
    [2020](#bib.bib19)) | (Veillette et al., [2020](#bib.bib91)) | (Herruzo et al.,
    [2021](#bib.bib39)) | (Larvor et al., [2020](#bib.bib52)) |'
  prefs: []
  type: TYPE_TB
- en: '| Year | 09–15 | 16–19 | 14–15 | 17–17 | 15–18 | 17–19 | 19–21 | 16–18 |'
  prefs: []
  type: TYPE_TB
- en: '| Frequency | 6 min | 5 min | 5 min | 2 min | 6 min | 5 min | 15 min | 5–15
    min |'
  prefs: []
  type: TYPE_TB
- en: '| Resolution | 2 km | 0.5 km | 1 km | 1 km | 1 km | 0.5–8 km | 2 km | 1 km
    |'
  prefs: []
  type: TYPE_TB
- en: '| Coverage | Hong Kong | US | Germany | US | Shanghai | US | Europe | France
    |'
  prefs: []
  type: TYPE_TB
- en: '| Format | png | binary | hdf5 | grib2 | binary | hdf5 | hdf5 | hdf5 |'
  prefs: []
  type: TYPE_TB
- en: '| Type | Ⓡ | Ⓡ | Ⓡ | Ⓡ | Ⓡ | ⓇⓈ | ⓇⓈ | ⓇⓈ |'
  prefs: []
  type: TYPE_TB
- en: '| URL | [[link]](https://github.com/sxjscience/HKO-7) | [[link]](https://github.com/uihilab/IowaRain)
    | [[link]](https://zenodo.org/records/3629951) | [[link]](https://data.eol.ucar.edu/dataset/541.033)
    | [[link]](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2GKMQJ)
    | [[link]](https://registry.opendata.aws/sevir/) | [[link]](https://github.com/agruca-polsl/weather4cast-2023)
    | [[link]](https://meteonet.umr-cnrm.fr) |'
  prefs: []
  type: TYPE_TB
- en: '|   |  |  |  |  |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Summary of publicly available sensor dataset resources. Year: data
    collected years (represented as the last two digits of the year), Frequency: time-frequency,
    Resolution: spatial resolution of data, Coverage: observed coverage, Format: data
    file format, Type: Radar Ⓡ, Satellite Ⓢ, URL: data URL link. [link] directs to
    dataset websites.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Weather radar
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Weather radar sends pulses into the air to detect rainfall and estimate its
    type (e.g., rain, snow, etc). The radar sensors can provide reflectivity data
    consisting of one channel in decibels (dBZ). Rainfall intensity can be categorized
    based on the radar reflectivity values; $[-35,20)$: small hydrometeors, $[20,35)$:
    light rain, $[35,50)$: medium rain, and $[50,\infty]$: heavy precipitation (Binetti
    et al., [2022](#bib.bib12)). Small hydrometeors are useful for detecting very
    dry light snow or drizzle that has lower reflectivity. Typically, the Z-R relationship
    is a step in radar-based quantitative precipitation estimation that involves converting
    reflectivity values into rainfall intensity. The reflectivity is converted by
    the Z-R relationship between the radar reflectivity factor $Z\ (\text{mm}^{6}\
    \text{m}^{-3})$ and rain rate $R\ (\text{mm}\ \text{h}^{-1})$ as follows: $Z=aR^{b},$
    where $a$ and $b$ are parameters obtained empirically depending on the precipitation
    type. A fixed Z-R relationship, such as $a=200$ and $b=1.6$ (Marshall and Palmer,
    [1948](#bib.bib63)) can be used; however, Kim et al. ([2021](#bib.bib47)) indicates
    that calibrating the relationship variability via Bayesian regression for each
    radar-gauge pair can produce a better fit.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Weather satellite
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Weather satellites monitor the weather and climate of the Earth and detect the
    movement of storm systems and other cloud patterns. Currently, there are more
    than 4000¹¹1 [https://www.ucsusa.org/resources/satellite-database](https://www.ucsusa.org/resources/satellite-database)
    satellites orbiting the Earth, each with its unique data-gathering sensor. Geostationary
    satellites used in time series forecasting are equipped with calibrated sensors
    to detect two-dimensional channels, including infrared, visible, and water vapor.
    It is important to note that visible is only available during the daytime, as
    the data represent solar radiation in albedo. Why is satellite data, which detects
    cloud information, important in precipitation forecasting? Satellites highlight
    specific phenomena provide signals related to precipitation and provide global
    coverage that complements radar observations. Metnet-v2 (Espeholt et al., [2022](#bib.bib24))
    found that satellites play an important role not only in precipitation nowcasting
    but also in longer predictions, contributing to atmospheric moisture corrections
    and improving cloud detection. Lee et al. ([2021](#bib.bib54)) used high-resolution
    satellite imagery from GEOS-16 with brightness temperature to detect convection.
    Global data were available at 1–2 km resolution at 10–15 min intervals, whereas
    higher resolution local data were available at 500 m resolution at 2 min intervals.
    Satellite-based precipitation products can complement the radar data by providing
    coverage over larger geographical areas. This can involve adjusting the rainfall
    features data based on the various angles of elevation of satellite (Niu et al.,
    [2024](#bib.bib67)), or using the satellite data to fill in gaps where radar coverage
    is limited (An, [2023](#bib.bib3)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Sensor fusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sensor fusion is a crucial technique for achieving accurate precipitation nowcasting
    by combining observations from ground-based radars and satellites. Radars and
    satellites often provide observations at different times and frequencies depending
    on data resolution. In addition, fusing high-resolution radar and satellite data
    over large areas requires significant computational resources. The key challenge
    in sensor fusion for nowcasting is aligning the different spatial and temporal
    characteristics of radar and satellite observations to produce a coherent, high-resolution
    precipitation forecast. Here, we highlight the key points about data fusion for
    precipitation nowcasting for the same (Sønderby et al., [2020](#bib.bib84); Seo
    et al., [2022a](#bib.bib77)) or different (An, [2023](#bib.bib3)) coverage areas.
    When both sets of observational data cover the same area, images are merged by
    concatenating them along the channel axis. Assuming there are $d$ channels in
    the satellite data, the input size would be $X\in\mathbb{R}^{(d+1)\times h\times
    w}$ (Sønderby et al., [2020](#bib.bib84); Seo et al., [2022a](#bib.bib77)). For
    a longer forecasting lead time, An ([2023](#bib.bib3)) merged satellite data,
    which is four times larger than the radar dataset, by tokenizing the satellite
    data to align with the radar dimensions. The model incorporates positional information
    via periodic functions to enhance the data fusion process, resulting in a combined
    input of $X\in\mathbb{R}^{5\times h\times w}$. Considering cloudiness as an additional
    layer of information helps investigate the influence of different cloud and atmospheric
    parameters (Andrychowicz et al., [2023](#bib.bib5)). This approach also allows
    us to assess the likelihood of precipitation persistence in these regions and
    to identify the interactions of additional external climate forcings like radiation
    (Samset et al., [2016](#bib.bib76)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 Available datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3 Datasets for precipitation nowcasting ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting") summarizes the radar and satellite data used in previous studies.
    We have the following data type summaries for precipitation forecasting: ① radar
    (HKO-7, IowaRain, RYDL, MRMS, and Shanghai) and ② radar & satellite (SEVIR, OPERA,
    and MeteoNet). Publicly available data typically consists of high-resolution images
    captured at short intervals (5 to 6 min) with diverse data formats. The benchmark
    dataset was collected from the original data sources by minimizing data bias and
    noise. The benchmark datasets were conducted in data selection processes (Shi
    et al., [2015](#bib.bib81); Chen et al., [2020](#bib.bib19); Veillette et al.,
    [2020](#bib.bib91); Sit et al., [2021](#bib.bib83)) based on reflectivity intensity.
    For instance, only rain days were chosen for the dataset (Shi et al., [2015](#bib.bib81)),
    or those with at least 0.5 mm precipitation over 10% of the domain (Sit et al.,
    [2021](#bib.bib83)). Careful data selection helps mitigate selection alleviate
    the bias of the dataset and enhance generalize to the broader population. Noise
    reduction techniques, such as removing pixels with low correlation coefficients
    or applying consecutive snapshot requirements, were implemented to improve data
    quality (Chen et al., [2019](#bib.bib18); Ayzel et al., [2020](#bib.bib8); Sit
    et al., [2021](#bib.bib83)). In the case of the Shanghai dataset (Chen et al.,
    [2020](#bib.bib19)), the authors removed pixels with correlation coefficients
    of less than 0.85 (Kumjian et al., [2010](#bib.bib49)) to eliminate anomalies.
    In terms of data types, the gathered data can be in binary or PNG data formats.
    Datasets with PNG format are visual representations of this data which can provide
    valuable insights and help improve the interpretation of the radar data; however,
    the dataset is hard to use as scientific ground-truth. Non-uniform color mapping
    in radar-derived images can pose challenges for precise precipitation prediction,
    as it may affect the interpretation of intensity levels. There is a lack of widely
    accepted standards for evaluating radar reflectivity datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Preprocessing
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Real-world datasets often do not follow a normal distribution, and imbalanced
    data with noise can cause performance issues. When some class is sparsely distributed
    compared to others, the model tends to overfit the majority class during training,
    resulting in poor performance of the minority class. Preprocessing is important
    for the efficient and accurate comparison of AI models using noisy real-world
    data, and this process contributes to improving the performance of the models.
    This section presents the effective techniques for precipitation data: ① clipping
    (Section [4.1](#S4.SS1 "4.1 Clipping ‣ 4 Preprocessing ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")), ② scaling
    (Section [4.2](#S4.SS2 "4.2 Scaling ‣ 4 Preprocessing ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")), ③ sampling
    (Section [4.3](#S4.SS3 "4.3 Sampling ‣ 4 Preprocessing ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")), and ④
    sliding window (Section [4.4](#S4.SS4 "4.4 Sliding window ‣ 4 Preprocessing ‣
    Deep learning for precipitation nowcasting: A survey from the perspective of time
    series forecasting")). To refine the radar dataset in constructing datasets, several
    preprocessing steps, as delineated in Table [2](#S4.T2 "Table 2 ‣ 4.1 Clipping
    ‣ 4 Preprocessing ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting"), are commonly applied.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Clipping
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The dataset undergoes clipping to maximum rainfall or reflectivity, which addresses
    the sparsity of rainfall data and imbalance issues. Real-world datasets often
    exhibit high-class imbalance, with the majority of instances concentrated near
    zero. A study in Beijing (Ma et al., [2019](#bib.bib60)) found that raindrops
    of diameter 0.9–2.5 mm contributed most to accumulated rainfall. In other regions,
    precipitation exceeding 10 mm is scarce, accounting for less than 1% (Choi and
    Kim, [2022](#bib.bib21); Kim et al., [2022](#bib.bib46)). These imbalanced datasets
    are problematic, as they often contain much higher error rates in the tail of
    the distribution. Researchers often set the maximum rainfall or reflectivity values
    to 100 to 128 (Ravuri et al., [2021](#bib.bib72); Zhang et al., [2023](#bib.bib107))
    or 70 to 76 (Larvor et al., [2020](#bib.bib52); Yu et al., [2023a](#bib.bib105)),
    respectively. This approach enables the handling of sparse datasets, spanning
    from the maximum output setting to the highest rainfall levels. When the dataset
    with high variance, occurs when a model fits too closely to the training data
    and is then unable to generalize to unseen dataset (Ravuri et al., [2021](#bib.bib72)).
  prefs: []
  type: TYPE_NORMAL
- en: '| Components | Methods |'
  prefs: []
  type: TYPE_TB
- en: '| Clipping | 100 mm^a , 128 mm^b , 70 dBZ^c , 76 dBZ^d |'
  prefs: []
  type: TYPE_TB
- en: '| Scaler | $z$-score^e , minmax^f , logarithmic^g |'
  prefs: []
  type: TYPE_TB
- en: '| Sampling | ① $\mathcal{P}r^{1}(X)=\frac{1}{(m+n)hw}\sum_{\forall x^{\prime}_{t}\subset
    X^{\prime}}x^{\prime}_{t}$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | ② $\mathcal{P}r^{2}(X)=\sum(1-exp^{-x_{t}})+\epsilon$ |'
  prefs: []
  type: TYPE_TB
- en: '| Sliding window | 20 min^h , 60 min^i , 120 min^j |'
  prefs: []
  type: TYPE_TB
- en: '$\bullet$ Clip:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: a
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An ([2023](#bib.bib3))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: b
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravuri et al. ([2021](#bib.bib72)); Zhang et al. ([2023](#bib.bib107))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: c
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Larvor et al. ([2020](#bib.bib52))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: d
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. ([2023a](#bib.bib105))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '$\bullet$ Scaler:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: e
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jeong et al. ([2021](#bib.bib43)); Bakkay et al. ([2022](#bib.bib10))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: f
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. ([2015](#bib.bib81)); Wang et al. ([2017](#bib.bib94))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: g
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. ([2021](#bib.bib56)); Espeholt et al. ([2022](#bib.bib24)); Geng et al.
    ([2023](#bib.bib31))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '$\bullet$ Sampling:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ① $\mathcal{P}r_{min}^{1}$=3$\times 10^{-2}$  An ([2023](#bib.bib3)), $\mathcal{P}r_{min}^{1}$=1$\times
    10^{-1}$  Ayzel et al. ([2020](#bib.bib8))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: ② $\mathcal{P}r_{min}^{2}$=2$\times 10^{-4}$  Ravuri et al. ([2021](#bib.bib72))  Zhang
    et al. ([2023](#bib.bib107))^#
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '$\bullet$ Sliding:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: h
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fernández and Mehrkanoon ([2021](#bib.bib25)); Zhang et al. ([2023](#bib.bib107));
    Leinonen et al. ([2023](#bib.bib55))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: i
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fernández and Mehrkanoon ([2021](#bib.bib25)); Reulen and Mehrkanoon ([2024](#bib.bib73));
    Gao et al. ([2022](#bib.bib30))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: j
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shi et al. ([2015](#bib.bib81)); Larvor et al. ([2020](#bib.bib52))
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Table 2: Brief details of preprocessing approaches in the literature. Clip:
    clipping value to handle imbalanced data setting to maximum rainfall. Scaler:
    data normalization methods (minmax: min-max scaler, log: logarithmic scaler).
    Sampling: sampling methods to prevent overfitting in sparse datasets. Zhang${}^{\text{\#}}$
    conducted hierarchical sampling in training, which involves first sampling from
    the full image and then sampling the cropped. Sliding: sliding window.'
  prefs: []
  type: TYPE_NORMAL
- en: Notation. Let the $X^{\prime}$ be a conditional matrix of input frames $X$,
    where the value is 1 if the value exists and 0 otherwise. Given the probability
    score of sampling as $\mathcal{P}r(X)$, the training dataset is sampled to sequences
    as $\mathcal{P}r(X)\geq\mathcal{P}r_{min}$, where $\mathcal{P}r_{min}$ is a minimum
    probability for controlling the overall inclusion rate. Here, $x_{t}$ represents
    an input frame, and $\epsilon$ is a small constant.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Scaling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Data scaling can improve the performance of DL models by making the learning
    process stable, especially on time series forecasting tasks where the data is
    highly non-linear and dynamic. The scaling techniques for data normalization put
    all features on a similar scale, allowing the model to learn from a more balanced
    distribution and making the optimization process more robust for DL models (Huang
    et al., [2023](#bib.bib42)). Three commonly used techniques for nowcasting include:
    $z$-score normalization, logarithmic transformation, and min-max normalization.
    To train satellite and radar sensor data with different ranges, it is common to
    normalize variables by applying $z$-score to them. Sensory datasets have a heavy-tailed
    distribution, as the sensory images contain values that can have extreme outliers
    or values in the tail ends of the distribution (Achim et al., [2003](#bib.bib1)).
    To handle satellite datasets, it is better to use percentile-based normalization
    techniques, like $z$-score normalization, rather than simple min-max normalization
    (Herruzo et al., [2021](#bib.bib39)). These existing scaling methods are just
    done to ensure that features with different scales don’t unduly influence the
    training process (Jeong et al., [2021](#bib.bib43); Li et al., [2023](#bib.bib57)),
    while the ML models may still encounter challenges in adequately handling outliers.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Sampling
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sampling methods are another way to address the data imbalance problem, encompassing
    both over-sampling and under-sampling approaches. These techniques modify the
    training distribution in order to decrease the level of imbalance or alleviate
    data noise by anomalies. In their simplest forms, the dataset is applied to over-sampling
    with rainy cases (Shi et al., [2015](#bib.bib81)). Or, recent studies have presented
    that sample by grouping a distribution bin or adjusting the proportion of rainy
    pixels (Ayzel et al., [2020](#bib.bib8); Zhang et al., [2023](#bib.bib107)). For
    example, DGMR (Ravuri et al., [2021](#bib.bib72)) proposed a sampling strategy
    using acceptance score. They remove samples from the over-represented class by
    using a defined sampling probability. Given the probability of $i$-th element
    of a sample data $x$ as $q_{x_{i}}=\sum 1-exp(-x_{i})$, samples above the $q_{x_{i}}$
    are included in the training set. Fitting data distribution into equal-width bins
    is one of the keys to robust model performance in diverse precipitation cases.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4 Sliding window
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The sliding window approach is a widely used term in time series forecasting
    tasks. The term refers to a technique where a fixed-size window of consecutive
    time steps is used as input to predict the next time step or a sequence of future
    time steps. The window size is an important hyperparameter that needs to be tuned
    in the forecasting task, which is typically set between 20 min (Ravuri et al.,
    [2021](#bib.bib72)) to 2 hours (h) (Larvor et al., [2020](#bib.bib52)) in nowcasting
    models. Building on previous studies, DL models can effectively capture temporal
    dependency and patterns within precipitation data by adopting the sliding window
    with intervals exceeding 20 min and considering a fixed number of previous time
    steps as input to forecast future rainfall intensity.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Objective functions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The effectiveness of deep learning models is largely dependent on their objective
    functions, which are crucial for precipitation forecasting. The objective function
    is a decisive component for precipitation nowcasting, as it shapes the learning
    process and determines the quality of the forecasts in terms of accuracy, and
    the ability to capture important high-intensity precipitation events. In this
    context, certain challenges, such as data imbalance, blurriness, and data sparsity,
    need to be taken into account.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Weighted loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The weighted loss function assigns weights to the learning objective function
    based on precipitation intensity. In precipitation forecasting, where data imbalance
    is addressed, applying weights can prioritize high-intensity rainfall. This means
    that errors made on predictions of heavy rainfall will contribute more to the
    overall loss function than errors made on predictions of light rainfall. In TrajGRU
    (Shi et al., [2017](#bib.bib82)), they implemented a strategy of dividing rainfall
    intensity into bins and assigning weights accordingly. By applying a weighting
    loss and clipping the precipitation data to a range of [0, 24], DGMR (Ravuri et al.,
    [2021](#bib.bib72)) focused on improve performance in forecasting heavy precipitation
    events. The tricks help maintain the balance between large and small portions
    in real-world datasets, contributing to its widespread adoption in predicting
    precipitation. Given a predicted future time step $x_{t}\in\mathbb{R}^{h\times
    w}$ and the number of elements $N$ in $x_{t}$, the weighted loss functions are
    formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{weighted}=\dfrac{1}{N}\sum_{t=m+1}^{m+n}\&#124;(x_{t}-G(x_{t}))\odot
    w(x_{t})\&#124;_{L_{1}\ or\ L_{2}},$ |  | (4) |'
  prefs: []
  type: TYPE_TB
- en: where $w(x_{t})\in\mathbb{R}^{h\times w}$ denotes the weights corresponding
    to rainfall and $\odot$ represents matrix multiplication. Researchers commonly
    adopted mean squared error (MSE) (Shi et al., [2017](#bib.bib82); Cambier et al.,
    [2023](#bib.bib16)) and mean absolute error (MAE) (Ravuri et al., [2021](#bib.bib72);
    Zhang et al., [2023](#bib.bib107)) for basis loss function. Recent studies used
    a loss function that combining these metrics improves performance in learning
    outliers (Wu et al., [2021](#bib.bib101); Wang et al., [2022](#bib.bib95); Ma
    et al., [2024](#bib.bib62)).
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Pooling loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The purpose of the pooling loss function is to measure the differences between
    the actual and predicted values in the larger receptive field by max-pooling before
    applying the objective function. Given a number of pixels $N$ of a batch, the
    learning objective is formulated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{pooling}=\dfrac{1}{N}\sum_{t=m+1}^{m+n}\&#124;(Q(x_{t})-Q(G(x_{t})))\&#124;_{1},$
    |  | (5) |'
  prefs: []
  type: TYPE_TB
- en: where $Q$ denotes max-pooling. Max-pooling is a type of operation that selects
    the maximum value within a receptive field from the region of the feature map
    covered by the filter. The loss function aims to capture how well the model predicts
    the overall spatial patterns or features in the data rather than focusing on individual
    data points. This aggregation step helps address the sparse problem and extract
    the most salient features, which can improve the capture of spatial patterns in
    various precipitation cases. In other real-world problems, datasets often exhibit
    long-tail distributions, making the loss function a powerful technique to improve
    performance on such datasets (Bulo et al., [2017](#bib.bib15)). Adjusting the
    max-pooling in the loss function helps the model focus more on the important features.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Motion loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Precipitation forecasting models frequently exhibit limitations in accurately
    predicting precipitation spatial scales that refer to the horizontal extent and
    organization of precipitation systems within a model grid. For predicting high-resolution
    precipitation, a motion regularization term was designed to enhance the smoothness
    of motion fields associated with heavy precipitation events. Let $\nabla\text{v}^{1,2}\in\mathbb{R}^{n\times
    h\times w}$ denote the x- and y-axis gradients obtained by the Sobel filter, and
    the motion loss is given by:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{motion}=\dfrac{1}{N}\sum_{t=m+1}^{m+n}\underbrace{\&#124;\nabla\text{v}_{t}^{1}\odot\sqrt{w(x_{t})}\&#124;_{2}}_{\text{x-axis
    velocity $\odot$ density}}+\underbrace{\&#124;\nabla\text{v}_{t}^{2}\odot\sqrt{w(x_{t})}\&#124;_{2}}_{\text{y-axis
    velocity $\odot$ density}},$ |  | (6) |'
  prefs: []
  type: TYPE_TB
- en: where $N$ is the number of elements. This term incorporates considerations of
    both the continuity equation and the observed tendency for larger precipitation
    patterns to persist for longer durations compared to smaller ones. Larger precipitation
    patterns like mesoscale convective systems have more moisture and energy available,
    allowing them to sustain precipitation over a wider area and longer time period
    (Hatsuzuka et al., [2021](#bib.bib37); Henny et al., [2022](#bib.bib38)). For
    example, about 40% of days with extreme precipitation over 250 mm in the tropics
    are associated with long-lived convective systems lasting more than 24 h (Roca
    and Fiolleau, [2020](#bib.bib74)). This method improves to affect past radar fields
    to predict the persistence of precipitation events. The regularization term is
    formulated as the spatial gradient of the motion vector, multiplied by the square
    root of the precipitation intensity.
  prefs: []
  type: TYPE_NORMAL
- en: 5.4 Nowcasting loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The nowcasting loss (Ko et al., [2022](#bib.bib48)) addresses the class imbalance
    problem by designing probability distributions from a DL model to approximate
    each class according to the rainfall threshold. The intrinsic complexities of
    real-world data often lead to scenarios where certain classes are sparse, creating
    significant challenges for training models. This issue arises when there is an
    imbalance in the class distribution within the dataset, potentially biasing the
    training process towards the majority classes (Salcedo-Sanz et al., [2024](#bib.bib75)).
    For handling the class imbalance problem, the nowcasting loss function prevents
    them from being biased toward the majority classes for learning to focus on heavy
    rain. Given a threshold $\gamma$ of a class $c$ and a $i$-th element in $x$, $TP(c)$
    (true positive), $FP(c)$ (false positive), and $FN(c)$ (false negative) are one-hot
    matrices indicating whether the value is over $c$ or not. For differentiability,
    the result transforms the one-hot values into probability distributions as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  |  $\widetilde{TP}_{i}(c),\widetilde{FN}_{i}(c),\widetilde{FP}_{i}(c)=\begin{cases}P(x_{i,c}),1-P(x_{i,c}),0&amp;\text{if}\
    x_{i}\geq\gamma,\\ 1-P(x_{i,c}),0,P(x_{i,c})&amp;\text{otherwise.}\end{cases}$  |  |
    (7) |'
  prefs: []
  type: TYPE_TB
- en: 'Let the nowcasting loss function be denoted by $\mathcal{L}_{nowcasting}$,
    the probability between classes can be learned by:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\begin{split}\mathcal{L}_{nowcasting}=-\dfrac{1}{2}\left(\dfrac{\widetilde{TP}(\text{R})}{\widetilde{TP}(\text{R})+\widetilde{FP}(\text{R})+\widetilde{FN}(\text{R})}\right.\\
    \left.+\dfrac{\widetilde{TP}(\text{H})}{\widetilde{TP}(\text{H})+\widetilde{FP}(\text{H})+\widetilde{FN}(\text{H})}\right)\end{split}$
    |  | (8) |'
  prefs: []
  type: TYPE_TB
- en: where R and H denote a class defined as the union of light and heavy rain, respectively.
    In this case, for heavy rain, the loss function is calculated twice for the criteria
    R and H, which mitigates the class imbalance problem as it is trained on a relatively
    focused basis.
  prefs: []
  type: TYPE_NORMAL
- en: 5.5 Plotting position loss
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The plotting position (PP) loss function (Xu et al., [2024](#bib.bib102)) is
    designed to solve the imbalanced regression task for precipitation nowcasting.
    The cost function computes a weight for each sample that is inversely proportional
    to the probability of occurrence. This means that samples with rare target values
    will be given higher weights, while samples with common target values will have
    lower weights. In traditional loss function, each sample contributes equally to
    the overall loss function, regardless of how common or rare its target value is.
    The PP loss is defined by reformulating Eq. [9](#S5.E9 "In 5.5 Plotting position
    loss ‣ 5 Objective functions ‣ Deep learning for precipitation nowcasting: A survey
    from the perspective of time series forecasting"), [10](#S5.E10 "In 5.5 Plotting
    position loss ‣ 5 Objective functions ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting"), and [11](#S5.E11 "In
    5.5 Plotting position loss ‣ 5 Objective functions ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting") as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\mathcal{L}_{pp}=\dfrac{1}{N}\sum_{t=m+1}^{m+n}\underbrace{f_{w}(x_{i})}_{\text{weight
    function}}\odot\underbrace{\mathcal{L}(\hat{x}_{i},x_{i})}_{\text{an objective
    function}},$ |  | (9) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $f_{w}(x_{i})=\dfrac{PP(x_{i})}{\frac{1}{N}\sum_{t=m+1}^{m+n}PP(x_{i})},$
    |  | (10) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $PP(x_{i})=\dfrac{1+\left&#124;\left\{\sum_{j=1}^{c}s_{j}:s_{j}<s_{i}\right\}\right&#124;}{N+1},$
    |  | (11) |'
  prefs: []
  type: TYPE_TB
- en: where $s_{j}$ denotes the number of elements in each class of the precipitation
    dataset, $s_{i}$ represents the number of elements in $x_{i}$, and $r_{k}$ denotes
    the ranking function. $r_{k}(x_{t})$ denotes the sequence of permutations containing
    the ordering of the $i$-th element in $x_{i}$. $N$ denotes the number of elements
    in $x_{i}$, and $s_{i}$ represents the number of elements in the interval where
    the elements of $x_{t}$ are contained. $f_{w}$ represents a weight function for
    the rarity of the target value. This formula ensures that rare data points have
    a greater impact on the loss and gradient calculations, helping the model to better
    learn from these important but scarce samples.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Evaluation metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The evaluation metrics play a critical role in evaluating the performance of
    the proposed method. As the number of precipitation forecasting models increases,
    it is necessary to evaluate different algorithms to verify the models uniformly
    using common evaluation metrics. This section introduces benchmark evaluation
    metrics commonly used in precipitation forecasting. Table [3](#S6.T3 "Table 3
    ‣ 6.1 Global-level accuracy ‣ 6 Evaluation metrics ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting") shows categorized
    evaluation metrics for the verification from different perspectives. This comparative
    analysis helps in understanding which models are most suitable for specific forecasting
    tasks and provides valuable insights for further research and development efforts.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Global-level accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The evaluation metrics for the global-level assessment determine how close forecasts
    are to the observation data for all the pixels, playing an important role in the
    overall performance verification of the forecasts. The mean square error (MSE)
    (Shi et al., [2015](#bib.bib81)) and mean absolute error (MAE) (Shi et al., [2017](#bib.bib82))
    are important metrics for evaluating the overall frames of a model. A small value
    indicates that the prediction model performed better. The Pearson correlation
    coefficient (PCC) (Ravuri et al., [2021](#bib.bib72)) is widely used as a metric
    to measure the statistical links between observational and predictive results.
  prefs: []
  type: TYPE_NORMAL
- en: '|   Category | Metrics |'
  prefs: []
  type: TYPE_TB
- en: '| Global-level | MAE, MSE, PCC |'
  prefs: []
  type: TYPE_TB
- en: '| Binary^† | Accuracy, CSI, FAR, FSS, F1-score, |'
  prefs: []
  type: TYPE_TB
- en: '| POD, Precision, HSS, Recall |'
  prefs: []
  type: TYPE_TB
- en: '| Downscale | CSI-neighborhood, FSS, Pooled CRPS |'
  prefs: []
  type: TYPE_TB
- en: '| Sharpness | GDL, LPIPS, PSNR, SSIM |'
  prefs: []
  type: TYPE_TB
- en: '|   |  |'
  prefs: []
  type: TYPE_TB
- en: †
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rainfall thresholds (mm): 0.2, 0.5, 1, 2, 4, 8, 10, 20'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Reflectivity thresholds (dBZ): 20, 30, 35, 40, 50'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Image thresholds (0–255): 16, 74, 133, 160, 181, 219'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Table 3: Overview of the evaluation metrics for precipitation. Bold font signifies
    the most frequently used metrics in our survey literature. In binary accuracy,
    the average point of thresholds is also used as the criterion for verification.'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Binary accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Binary accuracy verifies the pixel-by-pixel precipitation intensity using confusion
    metrics based on rainfall thresholds. The key to verifying the forecasting model
    is to evaluate at each pixel where and to what extent precipitation will fall.
    This verification process involves the use of confusion metrics, which are calculated
    based on predefined rainfall thresholds. The rainfall thresholds are typically
    defined in association with the distribution of rainfall intensity. Representative
    examples include the critical success index (CSI), accuracy, F1-score (F1), precision,
    recall, probability of detection (POD), equivalent threat score (ETS), and false
    alarm ratio (FAR) (Ravuri et al., [2021](#bib.bib72); Trebing et al., [2021](#bib.bib89);
    Ma et al., [2024](#bib.bib62)). The point to note is that, in the case of precipitation,
    instead of evaluating on a mini-batch basis, one should compute the confusion
    matrix for the entire batch, taking into account cases where there is no rain
    (TP=0).
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Downscale accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Both global accuracy and binary accuracy are assessed on a pixel-level basis,
    such that even a slight spatial deviation will result in a penalty. Thus models
    will tend to unrealistically smooth out with increasing lead time in order to
    minimize the loss while sharp predictions will be over-penalized despite their
    capability of preserving structural coherency with observations. For non-blurring
    models like GANs, alternate evaluation metrics such as the fraction skill score
    (FSS) (An, [2023](#bib.bib3)) are more appropriate which evaluates the model by
    expanding the spatial scale. The CSI-neighborhood (Zhang et al., [2023](#bib.bib107))
    or pooled continuous ranked probability score (CRPS) (Ravuri et al., [2021](#bib.bib72)),
    measured at a lower spatial scale, is used for the same purpose.
  prefs: []
  type: TYPE_NORMAL
- en: 6.4 Sharpness accuracy
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Sharpness refers to the sensitivity in generating realistic predictions, which
    is a crucial criterion for evaluating both the boundary quality of precipitation
    areas and the blurring issue. Given that extreme precipitation events often entail
    small-scale convective features, the sharpness at which an image is generated
    serves as an important metric for evaluating the quality of generated images.
    The degree of blurring of DL models was evaluated using the gradient difference
    loss (GDL) (Wu et al., [2021](#bib.bib101)), learned perceptual image patch similarity
    (LPIPS) (Yu et al., [2023a](#bib.bib105)), peak signal-to-noise ratio (PSNR) (Wu
    et al., [2023](#bib.bib100)), and structural similarity index (SSIM) (Wu et al.,
    [2023](#bib.bib100); Ning et al., [2023](#bib.bib66)). However, they have a limitation
    on whether sharpness reflects physical patterns, thereby we should complement
    it with other evaluation techniques to capture the performance.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Recursive strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In the following sub-section, we provide further details regarding the DL models
    according to recursive strategy. Here, the goal is to examine and provide an overview
    of recent advances and discoveries in precipitation forecasting. We include publications
    that propose DL techniques to address precipitation nowcasting for understanding
    patterns and trends of state-of-the-art models, even if they have not undergone
    a peer-review process. We will chronologically review the technical challenges
    and their corresponding solutions for each application. The DL models with recursive
    strategy discussed in the following subsections are organized in Figure [3](#S7.F3
    "Figure 3 ‣ 7 Recursive strategy ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting").'
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages. (+) efficiently estimates movement by characterizing
    the stochastic dependency in time series, (-) but is computationally intensive
    and suffers from accumulative error over longer forecasting time.
  prefs: []
  type: TYPE_NORMAL
- en: 'The recursive strategy is commonly used for predicting hazardous weather over
    a very short term and has been studied with a focus on predicting spatiotemporal
    motion since leading to biased and suboptimal forecasts, especially for longer
    forecast lead time. However, the advantage of the recursive forecasting strategy
    is that it can effectively capture temporal dependency in the time series, which
    is commonly composed of recurrent neural networks (Shi et al., [2015](#bib.bib81);
    Wang et al., [2017](#bib.bib94)). The strategy can be classified into two types:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Non-adversarial-based methods. (+) efficiently capture space-time dependency,
    (-) but tend to become increasingly blurred with longer lead time.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Adversarial-based methods. (+) show strength in generating future frames with
    sharpness, (-) but are comparatively prone to instability, encountering the mode
    collapse problem.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure [4](#S7.F4 "Figure 4 ‣ 7 Recursive strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting") illustrates
    two distinct network architectures, each representing a different category within
    the defined structures. The figure offers a visual understanding of the architectures
    employed in the categorized structures to facilitate the comparison between the
    two different structures.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S7.F3.pic1" class="ltx_picture ltx_centering" height="316.79" overflow="visible"
    version="1.1" width="652.81"><g transform="translate(0,316.79) matrix(1 0 0 -1
    0 0) translate(318.1,0) translate(0,306.1)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    transform="matrix(1.0 0.0 0.0 1.0 -55.75 -3.38)" fill="#000000" stroke="#000000"><foreignobject
    width="111.89" height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Recursive
    strategy</foreignobject></g><g stroke="#FF0000" fill="#FF0000" color="#FF0000"><g
    transform="matrix(1.0 0.0 0.0 1.0 -217.59 -66.55)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#FF0000" stroke="#FF0000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="10.38" height="9.46"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">N</foreignobject></g></g><g
    stroke="#FF0000" fill="#FF0000"><foreignobject width="95.48" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Non adversarial</foreignobject></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -309.44 -213.59)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    34.03 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.1.1](#S7.SS1.SSS1
    "7.1.1 Spatiotemporal ‣ 7.1 Non-adversarial-based methods ‣ 7 Recursive strategy
    ‣ Deep learning for precipitation nowcasting: A survey from the perspective of
    time series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="83.06" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Spatiotemporal</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -313.48 -296.49)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 193.195)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 187.12)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    4.23 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 181.585)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.06)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 171.055)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 176.05)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="70.62" height="10.01" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">$\text{ConvLSTM}^{a}$’15</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 184.71)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.87 0)"><foreignobject width="67.75"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">TrajGRU’17</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 199.27)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="91.54"
    height="12.15" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">$\text{ConvLSTM}^{b}$’19</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -219.87 -213.59)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    54.7 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.1.2](#S7.SS1.SSS2
    "7.1.2 Long-term dependency ‣ 7.1 Non-adversarial-based methods ‣ 7 Recursive
    strategy ‣ Deep learning for precipitation nowcasting: A survey from the perspective
    of time series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="124.74" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Long-term
    dependency</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    -200.98 -301.49)" fill="#000000" stroke="#000000" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 204.955)" color="#000000"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 200.64)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 196.315)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0.24 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 187.665)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 179.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="86.52" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">PredRNN-v1’17</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 19.56 0)"><foreignobject width="47.39"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MIM’19</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 7.28 0)"><foreignobject width="71.95"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Metnet-v1’20</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 200.64)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="87"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MotionRNN’21</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 209.29)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0.24 0)"><foreignobject width="86.52"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">PredRNN-v2’22</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -74.31 -213.59)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    19.38 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.1.3](#S7.SS1.SSS3
    "7.1.3 Sharpness ‣ 7.1 Non-adversarial-based methods ‣ 7 Recursive strategy ‣
    Deep learning for precipitation nowcasting: A survey from the perspective of time
    series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="54.14" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Sharpness</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -86.44 -288.52)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 179.015)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="78.35" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">ModeRNN’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 6.07 0)"><foreignobject width="66.24"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">DB-RNN’24</foreignobject></g></g></g></g><g
    stroke="#FF0000" fill="#FF0000" color="#FF0000"><g transform="matrix(1.0 0.0 0.0
    1.0 110.43 -66.55)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)" fill="#FF0000"
    stroke="#FF0000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="10.38" height="9.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">A</foreignobject></g></g><g stroke="#FF0000"
    fill="#FF0000"><foreignobject width="69.34" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Adversarial</foreignobject></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 20.18 -213.59)" fill="#0000FF" stroke="#0000FF" color="#FF0000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)" color="#0000FF"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 19.38 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.2.1](#S7.SS2.SSS1 "7.2.1 Sharpness
    ‣ 7.2 Adversarial-based methods ‣ 7 Recursive strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="54.14"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Sharpness</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -5.29 -298.38)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 197.525)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    14.44 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 187.665)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 179.015)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 11.89 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="52.41"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">AENN’19</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="76.19"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MPL-GAN’20</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 8.13 0)"><foreignobject width="59.93"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">DGMR’21</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 200.64)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="105.07"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">PCT-CycleGAN’23</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 120.67 -212.37)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 184.205)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    29.12 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.2.2](#S7.SS2.SSS2
    "7.2.2 Diverse mode ‣ 7.2 Adversarial-based methods ‣ 7 Recursive strategy ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="73.27" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Diverse
    mode</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 110.3
    -288.52)" fill="#000000" stroke="#000000" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 179.015)" color="#000000"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="94.35" height="8.65" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">TS-RainGAN’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 6.96 0)"><foreignobject width="80.43"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">ClusterCast’24</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 205.33 -213.59)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    54.7 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[7.2.3](#S7.SS2.SSS3
    "7.2.3 Long-term dependency ‣ 7.2 Adversarial-based methods ‣ 7 Recursive strategy
    ‣ Deep learning for precipitation nowcasting: A survey from the perspective of
    time series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="124.74" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Long-term
    dependency</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    227.69 -288.52)" fill="#000000" stroke="#000000" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 179.015)" color="#000000"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0.38 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="79.41" height="8.65" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">TransGAN’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="80.08"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">SAC-LSTM’24</foreignobject></g></g></g></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Overview of the recursive strategy. Methods in the recursive strategy
    can be categorized into non-adversarial and adversarial. We group the applications
    based on the above category and then order them chronologically. <svg id="S7.F3.3.1.1.pic1"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="14.87"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.34" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg> effectively
    learn the temporal dependency using recurrent frameworks. <svg id="S7.F3.4.2.2.pic2"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="14.87"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.34" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">A</foreignobject></g></g></svg> realistically
    predict future frames based on GANs. The subcategories were classified based on
    the core keywords intended to address previous issues in precipitation nowcasting.'
  prefs: []
  type: TYPE_NORMAL
- en: (a) Schematic of the non-adversarial-based PredRNN2 (Wang et al., [2022](#bib.bib95)).
    (Left) The PredRNN2 overview. (Right) The structure of an ST-LSTM cell. (Source)
    The figure is adapted from the original paper. $\hat{x}$, $m$, and $t$ represent
    a predicted frame, input frames, and any time step, respectively. Wang et al.
    ([2022](#bib.bib95)) adds the convolution layer upon the increments of $C^{l}_{t}$
    and $M^{l}_{t}$ (memory bank) at every time step, and employs a decoupling loss
    to explicitly extend the distance between them in latent space to focus on different
    aspects of spatiotemporal variations.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S7.F4.sf2.pic1" class="ltx_picture ltx_centering" height="201.22" overflow="visible"
    version="1.1" width="458.22"><g transform="translate(0,201.22) matrix(1 0 0 -1
    0 0) translate(229.11,0) translate(0,100.61) matrix(1.0 0.0 0.0 1.0 -224.5 -96)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject width="449"
    height="192" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/c63a1f11a3b5d9a6e4d9a5ce6731915f.png)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Schematic of the adversarial-based DGMR (Ravuri et al., [2021](#bib.bib72)).
    (Left) A generator with a latent vector. (Right) Discriminators. The conditions
    of precipitation observations are represented from the input frames and applied
    to the latent vector by the generator for predicting future time steps. For the
    temporal discriminator, 3D convolution is used to learn the temporal distribution.
    To learn the spatial distribution, a single frame is randomly selected multiple
    times from the frames, and 2D convolution is applied in each loop.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 4: Examples of the model architectures with the recursive strategy'
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Non-adversarial-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 7.1.1 Spatiotemporal
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: First appearing in 2015, $\text{ConvLSTM}^{a}$ (Shi et al., [2015](#bib.bib81))
    was presented as a network for predicting space-time patterns by applying convolutions
    to the recurrent state transitions of a long-short term memory (LSTM) cell. With
    the $\text{ConvLSTM}^{a}$ showing better performance than traditional statistical
    models in short-term precipitation forecasting within 2 h, DL-based systems have
    attracted the attention of researchers. As the network computes the weights in
    cells with fixed resolution, there is a limitation to learning the non-linear
    representations of motion flow. TrajGRU (Shi et al., [2017](#bib.bib82)) and $\text{ConvLSTM}^{b}$
    (Tran and Song, [2019](#bib.bib88)) have been proposed as hierarchical convolution
    recurrent neural network (ConvRNN) cells capable of better predicting varying
    motions and learning nonlinear patterns. This hierarchical learning helps capture
    intricate moving patterns and represent diverse physical patterns. ConvRNN cells
    process recursively, one frame at a time, allowing them to incorporate the order
    and context of the data into their networks. The sequential structure enables
    the networks to understand and capture the spatiotemporal dependency between frames.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Long-term dependency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The disadvantage of the recursive strategy lies in long-term dependency. Chaotic
    dynamics in temporal rainfall transform the joint distributions over time. This
    results in complex non-stationarity of the precipitation data, manifesting in
    the variability of rainfall patterns across different temporal scales. To address
    the intrinsic variation in consecutive contexts, MetNet-v1 (Sønderby et al., [2020](#bib.bib84))
    and ModeRNN (Yao et al., [2023](#bib.bib103)) introduced ConvRNN cells with an
    attention mechanism, a framework designed to enable the memory state to interact
    between the states. Designing attention modules helps aggregate large contexts
    and interact with the input state and the previous hidden state. From inside a
    memory cell, there have been studies on binding cells to capture non-stationarity
    by memorizing the top layer from each time step (Wang et al., [2017](#bib.bib94),
    [2019](#bib.bib96); Wu et al., [2021](#bib.bib101)). For example, RNN cells interconnected
    in a cascaded structure (Wang et al., [2019](#bib.bib96)) are used to handle space-time
    non-stationarity and capture differential information, or a motion-highway method
    (Wu et al., [2021](#bib.bib101)) is presented, which decomposes transient variations
    and motion trends. PredRNNs (Wang et al., [2017](#bib.bib94), [2022](#bib.bib95))
    learned the non-stationarity of deformations within time steps by adopting nonlinear
    neurons between time-adjacent RNN states. PredRNN-v2 (Wang et al., [2022](#bib.bib95))
    addressed the issue of accumulated error in long-term forecasting, proposed through
    reverse scheduled sampling, which learns the long-term dynamics from historical
    observations by randomly hiding real observations with decreasing probabilities.
    The PredRNN-v2 structure is shown in Figure [4(a)](#S7.F4.sf1 "In Figure 4 ‣ 7
    Recursive strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting"), where the spatiotemporal cells can
    enhance increments of memory states between RNN cells.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.3 Sharpness
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The predicted future frames from the non-adversarial-based models tend to blur
    as the forecast lead times increase. The MSE function is commonly used for precipitation
    nowcasting, but such global-level loss functions have some limitations that can
    lead to blurry outputs. When minimizing MSE loss, the model tends to generate
    overly blurry predictions by averaging out high-frequency details of precipitation.
    To address the blurring issue, the DB-RNN (Ma et al., [2024](#bib.bib62)) involves
    two steps: forecasting network (MS-RNN) and deblurring network (DB-RNN) with skip
    connections. The deblurring mechanism can mitigate autoregressive error accumulation,
    enhancing frame-by-frame deblurring effectiveness over time. In order to optimize
    the networks, they added regularization terms of GDL and cross-entropy (CE) loss
    to enhance prediction clarity and partially mitigate blurring. Another approach
    to mitigate blurring issues is to learn diverse representations across various
    types of precipitation. While mode collapse might not directly impact blurring
    in regression tasks, ModeRNN (Yao et al., [2023](#bib.bib103)) contributes to
    generating realistic predictions by uncovering the compositional structures of
    latent modes. The authors introduced adaptive fusion weights, which disentangle
    features within each cell, facilitating a wide spectrum of mode representations
    and adaptive weighting to accommodate different spatiotemporal dynamics.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Adversarial-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 7.2.1 Sharpness
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The outputs predicted by recursive strategy tend to blur with increasing forecast
    times (Whang et al., [2022](#bib.bib97)) when DL models are trained with global-level
    loss functions, e.g., MAE or MSE. While some approaches may reduce the extent
    of blurriness, it remains challenging to generate outputs that sharply represent
    real-world scenarios. Several studies have demonstrated the potential of generative
    adversarial networks (GANs) (Creswell et al., [2018](#bib.bib22)) by solving the
    blurriness problem and demonstrating reliable predictive performance (Kupyn et al.,
    [2018](#bib.bib50); Brock et al., [2018](#bib.bib13)). Many studies have presented
    GAN-based methods that realistically predict future frames, including vanilla
    GAN (Jing et al., [2019](#bib.bib45)), Conditional GAN (Liu and Lee, [2020](#bib.bib59)),
    and CycleGAN (Choi et al., [2023](#bib.bib20)). Upon analyzing the commonalities
    among most GAN models, it is observed that they typically consist of two discriminators
    to learn the spatiotemporal distribution. The development of adversarial-based
    models, especially DGMR (Ravuri et al., [2021](#bib.bib72)) showed promising results
    by utilizing a hierarchical ConvGRU generator and mapping multivariate Gaussian
    noise to precipitation fields, as illustrated in Figure [4(b)](#S7.F4.sf2 "In
    Figure 4 ‣ 7 Recursive strategy ‣ Deep learning for precipitation nowcasting:
    A survey from the perspective of time series forecasting"). The DGMR tends to
    show low variance even with perturbations added to the input frames (Leinonen
    et al., [2023](#bib.bib55)). This suggests that the DGMR can effectively learn
    precipitation physics representations and reliably predict future data, despite
    learning the spatiotemporal distribution from random noise.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.2 Diverse mode
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Many GANs suffer from mode collapse due to instability during the adversarial
    training process, caused by the discriminator becoming too powerful or issues
    with gradient updates (Wiatrak et al., [2019](#bib.bib98)). The mode collapse
    refers to the condition where a generator fails to capture the diversity mode
    of the data and produces highly similar, representing only a limited subset of
    the true data distribution. Precipitation is influenced by the complex interaction
    of regional, seasonal, and even plant and soil types, and heterogeneous learning
    and dynamic factors contribute to the temporal variability of precipitation distribution
    (Shi et al., [2022](#bib.bib80)). When predictive models are applied to precipitation
    datasets with highly mixed dynamics, the DL models often constrain diverse space-time
    deformations (Yao et al., [2023](#bib.bib103)). TS-RainGAN (Wang et al., [2023](#bib.bib93))
    is a task-segmented framework designed to improve heavy rainfall prediction by
    capturing the complexities of precipitation systems. They proposed two distinct
    models: one predicts spatiotemporal features to understand rainfall evolution,
    and the other generates high-quality images for accurate heavy rain detail capture.
    This approach enhances predictive accuracy and detailed visualization, preventing
    GAN mode collapse. ClusterCast (An et al., [2024](#bib.bib4)) introduced a GAN
    model with a self-cluster network for forecasting precipitation and capturing
    transient movement changes. Learning representations of distinct modes improves
    flexibility across precipitation types, further aiding in stable representation.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.2.3 Long-term dependency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Adversarial-based models with the recursive strategy struggle to capture long-term
    dependency due to the vanishing and exploding gradient problem. SAC-LSTM (She
    et al., [2023](#bib.bib79)) aggregates spatiotemporal features and captures the
    representation of input over many time steps by applying an attention module in
    the LSTM cell. After predicting future frames, the connected discriminator estimates
    whether the frames are generated or real by CE loss. While recursive strategy
    in theory can model strong temporal dependency, in practice various architectural
    innovations and training techniques are required to effectively address the underlying
    long-term dependency. ConvLSTM-TransGAN (Yu et al., [2023b](#bib.bib106)) is a
    framework that addresses blurring issues while preserving temporal dependency
    by merging ConvLSTM and TransGAN. TransGAN (Jiang et al., [2021](#bib.bib44)),
    a GAN model built upon the Transformer architecture, enhances feature resolution
    progressively and incorporates a multi-scale discriminator capable of capturing
    both high-level semantics and fine-grained textures.
  prefs: []
  type: TYPE_NORMAL
- en: '<svg id="S7.F5.pic1" class="ltx_picture ltx_centering" height="316.35" overflow="visible"
    version="1.1" width="659.93"><g transform="translate(0,316.35) matrix(1 0 0 -1
    0 0) translate(310.66,0) translate(0,305.59)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -52.33 -3.46)" fill="#000000"
    stroke="#000000"><foreignobject width="104.66" height="12.3" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Multiple strategy</foreignobject></g><g stroke="#FF0000"
    fill="#FF0000" color="#FF0000"><g transform="matrix(1.0 0.0 0.0 1.0 -236.03 -66.55)"><g
    class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)" fill="#FF0000" stroke="#FF0000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="10.38" height="9.46" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible">U</foreignobject></g></g><g stroke="#FF0000" fill="#FF0000"><foreignobject
    width="29.6" height="9.46" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Unet</foreignobject></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -306.04 -233.27)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    42.45 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[8.1.1](#S8.SS1.SSS1
    "8.1.1 Multivariate input ‣ 8.1 UNet-based methods ‣ 8 Multiple strategy ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="101.04" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Multivariate
    input</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0 -305.48
    -300.97)" fill="#000000" stroke="#000000" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 202.025)" color="#000000"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 195.79)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 191.465)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 187.15)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 182.825)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 178.5)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 172.275)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 175.38)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="98.76" height="12.45" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">(Lebedev et al)’21</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 187.15)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 19.3 0)"><foreignobject width="60.54"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">SIANet’22</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 195.8)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 4.28 0)"><foreignobject width="90.98"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">SmaAt-UNet’22</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 205.13)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 10.83 0)"><foreignobject width="77.49"
    height="12.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">(Kim
    et al)’22</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    -193.26 -238.81)" fill="#0000FF" stroke="#0000FF" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 196.485)" color="#0000FF"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 190.95)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 3.85 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 185.415)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    20.31 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[8.1.2](#S8.SS1.SSS2
    "8.1.2 Temporal dependency ‣ 8.1 UNet-based methods ‣ 8 Multiple strategy ‣ Deep
    learning for precipitation nowcasting: A survey from the perspective of time series
    forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="56.07" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Temporal</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 199.6)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="63.65"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">dependency</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -203.96 -292.84)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 187.665)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 179.015)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 5.53 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="74.03" height="8.65" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">MSSTNet’22</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="85.51"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">NowcastNet’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 4.75 0)"><foreignobject width="75.58"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MSLKNet’23</foreignobject></g></g></g></g>
    <g stroke="#FF0000" fill="#FF0000" color="#FF0000"><g transform="matrix(1.0 0.0
    0.0 1.0 -63.52 -66.55)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)"
    fill="#FF0000" stroke="#FF0000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="10.57" height="9.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">D</foreignobject></g></g><g stroke="#FF0000"
    fill="#FF0000"><foreignobject width="54.46" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Diffusion</foreignobject></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 -97.93 -233.27)" fill="#0000FF" stroke="#0000FF" color="#FF0000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)" color="#0000FF"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 19.38 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible" color="#FF0000">[8.2.1](#S8.SS2.SSS1 "8.2.1 Sharpness
    ‣ 8.2 Diffusion-based methods ‣ 8 Multiple strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="54.14"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Sharpness</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -107.36 -290.42)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 180.925)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    5.33 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="62.34" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">LDCast’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 184.03)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="72.99"
    height="12.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">(Nai
    et al’24)</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    -22.71 -233.27)" fill="#0000FF" stroke="#0000FF" color="#FF0000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 185.415)" color="#0000FF"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 179.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 38.65 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 176.42)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">[8.2.2](#S8.SS2.SSS2 "8.2.2 Physics-informed
    ‣ 8.2 Diffusion-based methods ‣ 8 Multiple strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting")</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="93.05"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Physics-informed</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -6.89 -292.84)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 187.665)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    1.5 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 179.015)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 2.07 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="53.76" height="8.65" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">Prediff’23</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="58.01"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Diffcast’23</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="61.02"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">CasCast’24</foreignobject></g></g></g></g><g
    stroke="#FF0000" fill="#FF0000" color="#FF0000"><g transform="matrix(1.0 0.0 0.0
    1.0 159.29 -66.55)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1 0 0)" fill="#FF0000"
    stroke="#FF0000" stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0
    0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.99" height="9.46" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">T</foreignobject></g></g><g stroke="#FF0000"
    fill="#FF0000"><foreignobject width="73.99" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Transformer</foreignobject></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 82.33 -238.74)" fill="#0000FF" stroke="#0000FF" color="#FF0000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 196.345)" color="#0000FF"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 190.81)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 1.3 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 185.345)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 179.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 22.86 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37"
    height="13.84" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[8.3.1](#S8.SS3.SSS1
    "8.3.1 Long-term dependency ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy
    ‣ Deep learning for precipitation nowcasting: A survey from the perspective of
    time series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.39)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="61.09" height="10.93"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Long-term</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 199.46)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="63.65"
    height="11.07" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">dependency</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 58.83 -292.84)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 187.665)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    14.58 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 179.015)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="81.53" height="8.65" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible" color="#FF0000">Rainformer’22</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 1.25 0)"><foreignobject width="79.04"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MIMO-VP’23</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 191.99)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="111.84"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">MS-RadarFormer’24</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 162.33 -233.27)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 185.415)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 179.88)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    38.65 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 176.42)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="15.37" height="13.84"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">[8.3.2](#S8.SS3.SSS2
    "8.3.2 Physics-informed ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy
    ‣ Deep learning for precipitation nowcasting: A survey from the perspective of
    time series forecasting")</foreignobject></g></g></g></g></g><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="93.05" height="11.07"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Physics-informed</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 165.11 -288.52)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 179.015)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 174.69)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="87.1" height="8.65"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Earthformer’22</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 183.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 14.91 0)"><foreignobject width="57.32"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Pastnet’23</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 273.4 -237.1)" fill="#0000FF" stroke="#0000FF"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 193.57)"
    color="#0000FF"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 188.53)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    5.43 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 184.205)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 179.88)"><g class="ltx_tikzmatrix_col ltx_nopad_l
    ltx_nopad_r" transform="matrix(1 0 0 -1 16.63 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 172.96)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 176.42)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="15.37" height="13.84" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">[8.3.3](#S8.SS3.SSS3 "8.3.3 Periodic
    component ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")</foreignobject></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 188.53)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="48.29"
    height="8.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">Periodic</foreignobject></g></g></g></g></g>
    <g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 196.19)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="59.5"
    height="10.08" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#FF0000">component</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 261.64 -284.2)" fill="#000000" stroke="#000000"
    color="#FF0000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 170.365)"
    color="#000000"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 174.69)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="83.02" height="8.65" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#FF0000">Earthfarseer’24</foreignobject></g></g></g></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 5: Overview of multiple strategy. Applications are categorized into
    UNet, Diffusion, and Transformer. Models are characterized based on the methods
    they report results on and are ordered chronologically. <svg id="S7.F5.4.1.1.pic1"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="14.87"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.34" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg> effectively
    capture channel-wise dependency in multivariate input data. <svg id="S7.F5.5.2.2.pic2"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="15.05"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.51" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg> realistically
    predict future frames. <svg id="S7.F5.6.3.3.pic3" class="ltx_picture" height="14.04"
    overflow="visible" version="1.1" width="14.53"><g transform="translate(0,14.04)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="8.99" height="8.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">T</foreignobject></g></g></svg> robust long-term dependency. The
    subcategories were classified based on the core keywords intended to address previous
    issues in precipitation nowcasting.'
  prefs: []
  type: TYPE_NORMAL
- en: 8 Multiple strategy
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section provides additional details about DL models based on direct multiple
    strategy. We review publications that reflect trends in state-of-the-art models
    listed in three frameworks as UNet, Diffusion, and Transformer. We summarize what
    attempts have been made to solve existing problems in precipitation nowcasting
    based on each network structure. Figure [5](#S7.F5 "Figure 5 ‣ 7.2.3 Long-term
    dependency ‣ 7.2 Adversarial-based methods ‣ 7 Recursive strategy ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")
    shows a diagram organizing the proposed models for each of the categorized architectures.'
  prefs: []
  type: TYPE_NORMAL
- en: Advantages and disadvantages. (+) robust against such accumulating errors, (-)
    but leads to difficulties in capturing temporal dependency between each frame.
  prefs: []
  type: TYPE_NORMAL
- en: 'The key advantage of the direct multiple strategy lies in its ability to directly
    model the entire forecast time, thereby avoiding issues of error accumulation
    and demonstrating robustness for datasets with high variance over time. This indicates
    that this approach is better suited for handling the increased uncertainty and
    complexity of long-term forecasting compared to the recursive strategy. However,
    this approach may struggle to adequately capture such dependency compared to temporal
    stochastic prediction models. In this regard, the multiple strategy can provide
    the disadvantages of learning temporal dependency in short-term trajectory prediction.
    Multiple strategy can be categorized into three types based on designed architecture:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'UNet-based methods: (+) achieve high-performance for multivariate forecasting,
    (-) but struggle with learning temporal dependency.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Transformer-based methods: (+) address the long-range dependency problem in
    time series forecasting, (-) but they have computational complexity that scales
    quadratically with the sequence length.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Diffusion-based methods: (+) generate future frames with sharpness and reliability
    in quantifying uncertainty, (-) but involve sequentially denoising the input over
    multiple steps is computationally expensive.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'Figure [6](#S8.F6 "Figure 6 ‣ 8.2.1 Sharpness ‣ 8.2 Diffusion-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting") demonstrates example architectures
    of three distinct networks within the multiple strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.1 UNet-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 8.1.1 Multivariate input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The UNet structure can efficiently learn the mapping between multivariate input
    data and radar output frames. Successful forecasting applications based on multivariate
    input data have been developed (Lebedev et al., [2019](#bib.bib53); Seo et al.,
    [2022a](#bib.bib77)). NowCasting-nets (Ehsani et al., [2022](#bib.bib23)) compared
    the performance of UNet-based and RNN-based models for 90 min forecasting using
    satellite and radar inputs. They found that the UNet-based model outperformed
    the RNN-based model and that overall performance remained stable over time. In
    the Weather4cast competition (Gruca et al., [2023](#bib.bib35)) for predicting
    high-resolution radar data from low-resolution satellites and radar data, the
    winners were models based on 3D-UNet (Seo et al., [2022a](#bib.bib77); Kim et al.,
    [2022](#bib.bib46)). SIANet, the winner of the 2022 competition (Seo et al., [2022a](#bib.bib77)),
    focused on radar detection of water droplets larger than 2 mm based on sensor
    fusing, which are mature cloud particles that may be overlooked during convective
    initiation. To address this, they proposed a UNet with a large spatial-context
    aggregation module based on matrix decomposition. Another competitor, presented
    by Kim et al. ([2022](#bib.bib46)), also introduced a UNet with a region-conditioned
    network that integrates region information into feature maps using orthogonal
    convolutional layers. In summary, UNet demonstrated strength in learning dependency
    between variables by effectively fusing information from different sensors.
  prefs: []
  type: TYPE_NORMAL
- en: 8.1.2 Temporal dependency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Deep convolution structure is strong for preserving the global spatial information,
    but previous UNet models often struggle with non-stationarity and the accompanying
    variation in data distributions. The UNet model prioritizes analyzing variable
    correlations over capturing motion trends over time, which makes it less attractive
    for radar-based univariate forecasting. However, NowcastNet (Zhang et al., [2023](#bib.bib107))
    leveraged a sub-network (Evolution Network) to capture temporal dependency, as
    described in Figure [6(a)](#S8.F6.sf1 "In Figure 6 ‣ 8.2.1 Sharpness ‣ 8.2 Diffusion-based
    methods ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A
    survey from the perspective of time series forecasting"). This mitigates the drawbacks
    of the multiple strategy and has been reported to outperform DGMR. The sub-network
    of NowcastNet employs a UNet that estimates changes in motion and intensity of
    radar echoes. These findings suggest that a multi-strategy approach can be a powerful
    tool for precipitation nowcasting with univariate data, provided a network can
    be designed to learn temporal dependency. An alternative method is attention mechanisms
    that capture the temporal dependency in UNets (Sønderby et al., [2020](#bib.bib84);
    Trebing et al., [2021](#bib.bib89); Tian et al., [2023](#bib.bib87)). For example,
    MSLKNet (Tian et al., [2023](#bib.bib87)) encodes features by stacking time-wise
    attention modules within a UNet latent space, enabling the model to capture both
    space-time dependency and global patterns. Combining attention modules into UNet
    networks avoids iterative computation, as these networks do not rely on recursive
    modules.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2 Diffusion-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 8.2.1 Sharpness
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: GANs often struggle to reach a balance point where both the generator and discriminator
    cannot improve further, resulting in non-convergence (Chen, [2021](#bib.bib17)).
    Researchers have actively utilized diffusion (Leinonen et al., [2023](#bib.bib55);
    Nai et al., [2024](#bib.bib64)), which is advantageous for its freedom from discriminators
    and has shown promising results in various real-world applications (Ho et al.,
    [2020](#bib.bib40); Song and Ermon, [2020](#bib.bib85)). LDCast (Leinonen et al.,
    [2023](#bib.bib55)) was the first to apply a latent diffusion model to precipitation
    forecasting. The model was designed using a two-step approach comprising a forecast
    network to predict future time-step frames and a denoising network for a noise
    estimation. The denoising network refers to the iterative process of gradually
    removing noise from an input image, which can learn the data distribution and
    generate diverse and high-quality samples. LDCast aims to reduce uncertainty by
    utilizing ensemble members for the average precipitation. However, in previous
    diffusion-based models, sample variations occur during precipitation forecasting.
    The variance of samples can lead to the selection of samples that deviate significantly
    from the ground truth, and ensemble methods may degrade performance (Yu et al.,
    [2023a](#bib.bib105)). While diffusion models excel at generating high-quality
    samples, they might lack the fine-grained control required for specific tasks
    or applications. Generative models may deviate from physical behaviors by generating
    plausible noise or disregarding domain-specific expertise (Gao et al., [2023](#bib.bib28)).
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.F6.sf1.pic1" class="ltx_picture ltx_centering" height="161.22" overflow="visible"
    version="1.1" width="458.22"><g transform="translate(0,161.22) matrix(1 0 0 -1
    0 0) translate(229.11,0) translate(0,80.61) matrix(1.0 0.0 0.0 1.0 -224.5 -76)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject width="449"
    height="152" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/852d8f14fe2bd32904a1c9affefcc8cf.png)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (a) Schematic of the UNet-based NowcastNet (Zhang et al., [2023](#bib.bib107)).
    (Left) NowcastNet overview based on UNet (Encoder and Decoder) structure. (Right)
    A temporal discriminator using multiple convolution kernels. The architecture
    focuses on a UNet-based model designed to learn space-time dependency. This is
    achieved through an evolution network that enables the model to learn both motion
    flow and intensity change. By combining these sub-networks, the model can effectively
    capture the dynamic changes in the data over time and space.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.F6.sf2.pic1" class="ltx_picture ltx_centering" height="173.22" overflow="visible"
    version="1.1" width="488.22"><g transform="translate(0,173.22) matrix(1 0 0 -1
    0 0) translate(244.11,0) translate(0,86.61) matrix(1.0 0.0 0.0 1.0 -239.5 -82)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject width="479"
    height="164" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/129f583bf60d2cc8027091b9190af227.png)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (b) Schematic of the Diffusion-based Prediff (Gao et al., [2023](#bib.bib28)).
    (Left) Prediff overview during training. (center) Encoder-Decoder structure based
    on attention mechanism. (Right) Denoising module for estimating observation distribution.
    Prediff has the advantage of enforcing the spread of the distributions based on
    knowledge alignment in denoising steps. This model can effectively model the complex,
    high-dimensional distribution of natural observations without the need for adversarial
    training, improving the overall learning process and ensuring a more accurate
    representation.
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.F6.sf3.pic1" class="ltx_picture ltx_centering" height="202.22" overflow="visible"
    version="1.1" width="338.22"><g transform="translate(0,202.22) matrix(1 0 0 -1
    0 0) translate(169.11,0) translate(0,101.11) matrix(1.0 0.0 0.0 1.0 -164.5 -96.5)"
    fill="#000000" stroke="#000000" stroke-width="0.4pt"><foreignobject width="329"
    height="193" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/90d17704209b6131c3fd16b2f3f54b52.png)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: (c) Schematic of the Transformer-based MIMO-VP (Ning et al., [2023](#bib.bib66)).
    (Left) MIMO-VP overview for predicting future time steps. (Right) Encoder-Decoder
    structure. The architecture combines convolution with time-wise attention to learn
    space-time dependency. By leveraging the self-attention mechanism with convolution
    layers, the model can understand and predict space-time relationships, enabling
    it to capture complex patterns and dynamics in temporal data. This framework also
    provides robustness to long-range dependency, allowing the model to effectively
    capture complex correlations and patterns.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 6: Examples of the model architectures with the multiple strategy'
  prefs: []
  type: TYPE_NORMAL
- en: 8.2.2 Physics-informed
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'There have been attempts to address existing uncontrolled problems and to predict
    precipitation with a physics-informed generative model in diffusion-based models.
    Prediff (Gao et al., [2023](#bib.bib28)) proposed a network that parameterizes
    an energy function to adjust transition probabilities, thereby controlling the
    condition vector during denoising steps. To extract conditional features from
    the input, Prediff employs the UNet structure of Earthformer (Gao et al., [2022](#bib.bib30)).
    Before denoising steps, the network takes the weather conditions as the basis
    of noise and aims to minimize discrepancies with the future temporal distribution.
    Then, the Prediff parameterizes an energy function to adjust the transition probabilities
    during each denoising step, resulting in predicted future frames that are rich
    in detail. A simple Prediff framework for enforcing the distribution of images
    with physical alignment is visualized in Figure [6(b)](#S8.F6.sf2 "In Figure 6
    ‣ 8.2.1 Sharpness ‣ 8.2 Diffusion-based methods ‣ 8 Multiple strategy ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting").
    DiffCast (Yu et al., [2023a](#bib.bib105)) and CastCast (Gong et al., [2024](#bib.bib34))
    combine deterministic and stochastic diffusion components to capture global and
    local motion trends. The deterministic component predicts the global pattern,
    whereas the stochastic diffusion component provides more detail. Configuring only
    the stochastic model resulted in instability and constrained the capability to
    decompose precipitation into both global trends and local stochastic components
    (Yu et al., [2023a](#bib.bib105)). This indicates that uncontrolled evolution
    models may struggle to capture the physical distribution of precipitation. Diffcast
    leverages residual blocks as a diffusion component to effectively exploit multi-scale
    temporal features. In the case of Cascast, the network emphasizes reducing the
    complexity of denoising conditioned by a sequence of blurry predictions by adopting
    an attention mechanism. While diffusion models can be computationally expensive,
    they can effectively capture intricate patterns present in time series data by
    estimating perturbations with physics alignment. Diffusion models can enhance
    representations to preserve coherence when generating long-term forecasts with
    a high frequency of precipitation and facilitate the modeling of complex temporal
    distributions.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.3 Transformer-based methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 8.3.1 Long-term dependency
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Transformer-based nowcasting models have achieved remarkable success, demonstrating
    their ability to effectively capture long-range spatiotemporal dependency in precipitation
    nowcasting. Transformer efficiently robust long-range dependency by tokenizing
    data into small patches and learning weights for each patch using self-attention.
    The self-attention mechanism in the Transformer, while powerful for capturing
    long-range dependency, may struggle to effectively model short-term local patterns
    and variations in the data (Lin et al., [2022](#bib.bib58)). Rainformer (Bai et al.,
    [2022](#bib.bib9)) and MS-RadarFormer (Geng et al., [2024](#bib.bib32)) applied
    a Swin Transformer by tokenizing time series frames to learn both global and local
    features. They introduced a fully convolutional network with an attention module
    that effectively extracts local features from rainfall information, which aids
    in low-to-medium rainfall intensity prediction. However, precipitation data is
    to fluid masses spreading in various directions, unlike standard videos which
    often depict moving objects against a stationary background (Fovell and Tan, [1998](#bib.bib27)).
    To overcome this drawback, MIMO-VP (Ning et al., [2023](#bib.bib66)) introduced
    a spatiotemporal block aimed at learning high-order relationships between time
    step queries and their corresponding output sequences. As described in Figure
    [6(c)](#S8.F6.sf3 "In Figure 6 ‣ 8.2.1 Sharpness ‣ 8.2 Diffusion-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting"), the approach involves obtaining
    sequence-level feature maps using a placeholder embedding method to capture global
    dependency within the frames. The proposed solution effectively addresses the
    challenge of global space-time dependency and error accumulation by adopting temporal
    attention modules with convolution layers. To tackle the permutation-invariant
    issue inherent to transformers, the network applies temporal positional encoding
    to input sequences, ensuring smooth and effective processing.'
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.2 Physics-informed
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Recent studies have strived to enhance model performance by reflecting weather-related
    knowledge into Transformer-based architectures. Nowformer (Park et al., [2022](#bib.bib68))
    proposed global dynamic attention to learn both local and global information of
    each frame. For learning the intensity of the moving fluid changes continuously,
    they proposed Transformer-based global dynamic attention to learn both local and
    global information of each frame. The Nowformer locally extracts temporal dependency
    through the local dynamic attention module, facilitating the learning of how the
    intensity of fluids changes at each point in the frames. Meanwhile, one of the
    characteristics of weather data is that combining low and high-resolution data
    can enhance weather forecasting accuracy. By using a combination of low and high-resolution
    data, weather models can leverage the strengths of each. The broad context from
    low-resolution data and the local detail from high-resolution data. Earthformers
    (Gao et al., [2022](#bib.bib30)) employed a hierarchical mechanism for multi-resolution
    attention using image decomposition and connected local and global. They explored
    the sharing of space-time information in the transformer, as well as designed
    an efficient computational complexity. MS-RadarFormer (Geng et al., [2024](#bib.bib32))
    proposed a multi-scale patch embedding layer, enabling it to obtain the multiple
    spatial and temporal scales of the high-resolution precipitation dataset. They
    applied padding operations to adjust the output dimensions and concatenate embedded
    tokens. By embedding multi-resolution information, they addressed the issue of
    underestimating while also achieving slightly sharper predictions for radar output
    frames.
  prefs: []
  type: TYPE_NORMAL
- en: 8.3.3 Periodic component
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: As scientific data substantiates the importance of Fourier analysis, it is a
    well-known fact that the decomposition of complex weather signals into their constituent
    frequency components can better identify and represent important meteorological
    phenomena (Amon, [1993](#bib.bib2)). The Fourier series representation within
    the spectral elements enables the efficient handling of periodic or quasi-periodic
    phenomena, such as those encountered in transitional and turbulent flows (Fournier
    et al., [2005](#bib.bib26)). The Fourier-based precipitation nowcasting, such
    as fast Fourier transform (FFT), can help extract relevant features and improve
    the performance of forecasting models (Wu et al., [2023](#bib.bib100), [2024](#bib.bib99)).
    The Fourier representation allows the model to capture complex periodic behaviors
    through the combination of sine and cosine terms. Passing input points through
    a Fourier feature mapping enables networks to learn high-frequency functions in
    a low-dimensional setting. The FFT module is utilized to capture high-dimensional
    nonlinear physical features, enabling the capture of intricate dynamics within
    systems without relying on differential equation-based nonlinear features (Wu
    et al., [2023](#bib.bib100)). Unlike discrete static frames, the FFT approach
    transforms data from the continuous time domain to the frequency domain, thereby
    better preserving long-term dependency in spatiotemporal data (Wu et al., [2024](#bib.bib99)).
    Fourier transforms have gained prominence in the field of precipitation nowcasting,
    providing a method to discern intricate physical patterns and capture system dynamics
    without the need for differential equation-based nonlinear features.
  prefs: []
  type: TYPE_NORMAL
- en: '{NiceTabular}'
  prefs: []
  type: TYPE_NORMAL
- en: p4.5cmC3emC5emC5emC3emC4emC2em*2C2emC2emC8em \CodeBefore1 \BodyApplications  Norm.  Loss  Data  Size  Param.  m  n  dt  Z-R  Metrics
    (A) Recursive strategy
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.1.1.1.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    $\text{ConvLSTM}^{a}$ (Shi et al., [2015](#bib.bib81)) [[link]](https://github.com/ndrplz/ConvLSTM_pytorch)
    minmax MSE HKO-7 100 487 K 5 15 6 O MSE, PCC, CSI, FAR, POD
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.3.3.3.3.3.3.pic2" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    TrajGRU (Shi et al., [2017](#bib.bib82)) [[link]](https://github.com/Hzzone/Precipitation-Nowcasting)
    minmax $\mathcal{L}_{w}$ HKO-7 480 1.9 M 5 20 6 O MSE, CSI, HSS
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.5.5.5.5.5.5.pic3" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    PredRNN (Wang et al., [2017](#bib.bib94)) [[link]](https://github.com/thuml/predrnn-pytorch)
    minmax MAE, MSE Guangzhou 100 23.6 M 10 10 6 O MSE
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.6.6.6.6.6.6.pic4" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    MIM (Wang et al., [2019](#bib.bib96)) [[link]](https://github.com/Yunbo426/MIM)
    minmax MSE Guangzhou 64 28.5 M 10 10 6 X MSE, CSI
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.7.7.7.7.7.7.pic5" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    Metnet-v1 (Sønderby et al., [2020](#bib.bib84)) [[link]](https://github.com/openclimatefix/metnet)
    log - MRMS 1024 225 M 6 32 15 O F1
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.8.8.8.8.8.8.pic6" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    MotionRNN (Wu et al., [2021](#bib.bib101)) [[link]](https://github.com/thuml/MotionRNN)
    - MAE, MSE Shanghai 64 5.2 M 5 10 12 X MSE, CSI, GDL, SSIM
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.9.9.9.9.9.9.pic7" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    PredRNN2 (Wang et al., [2022](#bib.bib95)) [[link]](https://github.com/thuml/predrnn-pytorch)
    minmax MAE, MSE Guangzhou 128 23.8 M 10 10 6 X MSE, CSI
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.10.10.10.10.10.10.pic8" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">A</foreignobject></g></g></svg> DGMR (Ravuri et al., [2021](#bib.bib72))
    [[link]](https://github.com/openclimatefix/skillful_nowcasting) clip $\mathcal{L}_{w}$,
    Hinge UK, US 256 98.5 M 4 18 5 O CSI, PCC, PSD, CRPS
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.12.12.12.12.12.12.pic9" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">A</foreignobject></g></g></svg> SAC-LSTM (She et al., [2023](#bib.bib79))
    [[link]](https://github.com/LeiShe1/SAC-LSTM-MindSpore) minmax MSE, CE CIKM 128
    31.1 M 5 10 6 X CSI, HSS, MSE (B) Multiple strategy
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.13.13.13.13.13.13.pic1" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">U</foreignobject></g></g></svg> Broad-UNet (Fernández and Mehrkanoon,
    [2021](#bib.bib25)) [[link]](https://github.com/jesusgf96/Broad-UNet) binary MSE
    Netherlands 288 11 M 12 6 5 O MSE, Accuracy, Precision, Recall
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.14.14.14.14.14.14.pic2" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">U</foreignobject></g></g></svg> SmaAt-UNet (Trebing et al., [2021](#bib.bib89))
    [[link]](https://github.com/HansBambel/SmaAt-UNet) minmax MSE Netherlands 256
    4 M 4 6 15 O MSE, ACC, CSI, FAR, F1, HSS, Precision, Recall
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.15.15.15.15.15.15.pic3" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">U</foreignobject></g></g></svg> NowcastNet (Zhang et al., [2023](#bib.bib107))
    [[link]](https://codeocean.com/capsule/3935105) clip CE, $\mathcal{L}_{pool}$,
    $\mathcal{L}_{motion}$ China, UK 256 29.1 M 4 18 10 O CSI, PSD
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.18.18.18.18.18.18.pic4" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.93"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.4" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">D</foreignobject></g></g></svg> LDCast (Leinonen et al., [2023](#bib.bib55))
    [[link]](https://github.com/MeteoSwiss/ldcast) log MSE, KL MeteoSwiss 256 671
    M 4 18 5 X FSS, CRPS
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.19.19.19.19.19.19.pic5" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.93"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.4" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">D</foreignobject></g></g></svg> Prediff (Gao et al., [2023](#bib.bib28))
    [[link]](https://github.com/gaozhihan/PreDiff) MSE, adv, KL SEVIR 128 120 M 6
    7 10 O CSI, Bias
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.20.20.20.20.20.20.pic6" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.93"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.4" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">D</foreignobject></g></g></svg> Diffcast (Yu et al., [2023a](#bib.bib105))
    [[link]](https://github.com/DeminYu98/DiffCast) clip MSE, KL SEVIR, MetoNet, Shanghai,
    CIKM 128 66.4 M 5 20 5 X CSI, HSS, LPIPS, SSIM
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.21.21.21.21.21.21.pic7" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.53"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">T</foreignobject></g></g></svg> Earthformer (Gao et al., [2022](#bib.bib30))
    [[link]](https://github.com/amazon-science/earth-forecasting-transformer) minmax
    MSE SEVIR 384 7.6 M 12 13 5 X MSE, CSI
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.22.22.22.22.22.22.pic8" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.53"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">T</foreignobject></g></g></svg> Pastnet (Wu et al., [2023](#bib.bib100))
    [[link]](https://github.com/easylearningscores/pastnet) - MSE SEVIR 384 54 M 10
    10 5 X MAE, MSE, PSNR, SSIM
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S8.SS3.SSS3.23.23.23.23.23.23.pic9" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.53"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">T</foreignobject></g></g></svg> MIMO-VP (Ning et al., [2023](#bib.bib66))
    [[link]](https://github.com/ningshuliang/MIMO-VP) - MAE, MSE China 128 20.2 M
    10 10 - X MAE, CSI, SSIM
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4: Overview of applications. We grouped their applications based on their
    strategy and model architectures. <svg id="S8.SS3.SSS3.33.33.1.pic1" class="ltx_picture"
    height="14.04" overflow="visible" version="1.1" width="14.87"><g transform="translate(0,14.04)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="9.34" height="8.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">N</foreignobject></g></g></svg>: Non-adversarial, <svg id="S8.SS3.SSS3.34.34.2.pic2"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="14.87"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.34" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">A</foreignobject></g></g></svg>: Adversarial,
    <svg id="S8.SS3.SSS3.35.35.3.pic3" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg>:
    UNet, <svg id="S8.SS3.SSS3.36.36.4.pic4" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="15.05"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.51" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>:
    Diffusion, <svg id="S8.SS3.SSS3.37.37.5.pic5" class="ltx_picture" height="14.04"
    overflow="visible" version="1.1" width="14.53"><g transform="translate(0,14.04)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="8.99" height="8.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">T</foreignobject></g></g></svg>: Transformer. Norm: data normalization
    (ref. Table [2](#S4.T2 "Table 2 ‣ 4.1 Clipping ‣ 4 Preprocessing ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")),
    Loss: loss function for object functions (adv and KL represent an adversarial
    loss and Kullback-Leibler divergence, respectively.), Data: Used dataset, param:
    number of parameters, Size: image height & width, $\bm{m}$: the number of input
    frames, $\bm{n}$: the number of output frames, $\bm{dt}$: forecasting time interval
    ($\Delta t$), Z-R: application of the Z-R relationship, Metrics: evaluation metrics.
    PSD represents radially-averaged power spectral density for analyzing variations
    in spatial frequency content in an image. The URLs in name tags are publicly accessible
    codes. Param is written under our reproduction process for cases that are not
    addressed in their paper. Information not included in the paper is represented
    by dashes. [link] directs to code websites.'
  prefs: []
  type: TYPE_NORMAL
- en: 9 Methodology comparison and evaluation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Leveraging our previous discussion of attributes within an interrelated system
    of DL models, we compare the properties of DL models in this section. For aiming
    to review key applications on two strategies, we present two levels of comparison:
    the methodology-level comparison (Section [9.1](#S9.SS1 "9.1 Methodology comparison
    ‣ 9 Methodology comparison and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based
    methods ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A
    survey from the perspective of time series forecasting")) and the performance-level
    comparison (Section [9.2](#S9.SS2 "9.2 Performance evaluation ‣ 9 Methodology
    comparison and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting")).'
  prefs: []
  type: TYPE_NORMAL
- en: 9.1 Methodology comparison
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this subsection, we survey various applications by drawing upon the insights
    and methodologies outlined in the preceding sections, thereby providing a structured
    examination of their respective uses and implications. These categories refer
    to either the dataset used in the applications, objective function, evaluation
    metric, or additional information. Table [8.3.3](#S8.SS3.SSS3 "8.3.3 Periodic
    component ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")
    summarizes the key highlights of these applications. The papers examined in this
    work were collected from various popular benchmark databases, and state-of-the-art
    were compared with popular applications with publicly available code. From the
    survey, we can derive the following insights:'
  prefs: []
  type: TYPE_NORMAL
- en: (1)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Preprocessing: By normalizing the data with min-max normalization and clipping,
    previous studies aim to reduce the impact of non-normality. Both radar reflectivity
    and rainfall intensity have been used effectively in precipitation nowcasting,
    with the choice depending on the specific application and modeling approach. Predicting
    reflectivity directly can be advantageous as it is the original radar signal,
    but it requires an additional step to convert from reflectivity using the Z-R
    relationship for detailed assessment (Han et al., [2023](#bib.bib36)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (2)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Objective function: One of the most widely used objective functions for precipitation
    nowcasting is MSE. Recent research indicates that both MAE and MSE are adopted
    as loss functions. MSE penalizes larger errors more heavily, resulting in smoother
    nowcasts, while MAE treats all errors equally and can better represent intense
    precipitation at the cost of higher overall errors (Ashesh et al., [2022](#bib.bib6)).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: (3)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Evaluation metric: The MSE is one of the most commonly used metrics for evaluating
    the performance of precipitation nowcasting models. Several other metrics are
    also frequently employed to assess different aspects of the nowcasts. SSIM and
    PSNR are used as evaluation metrics to evaluate the sharpness of predicting frames.
    CRPS, which evaluates the entire predictive distribution, is also used in nowcasting
    models. The choice of metrics depends on the specific application requirements
    and characteristics of the precipitation events being forecasted.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: While significant progress has been achieved in precipitation forecasting, the
    absence of an established baseline makes a limitation of the ability to conduct
    sophisticated model comparisons. We hope that our study contributes to the dissemination
    of technology and the revitalization of research by providing a comparison of
    various applications.
  prefs: []
  type: TYPE_NORMAL
- en: '| Applications | Moving MNIST | Weather data |'
  prefs: []
  type: TYPE_TB
- en: '|  | #Param. (M) | FLOPS (G) | MSE $\downarrow$ | SSIM $\uparrow$ | Dataset
    | MSE ($10^{-3}$) $\downarrow$ | CSI (dBZ) $\uparrow$ |'
  prefs: []
  type: TYPE_TB
- en: '| Persistence |  |  |  |  | SEVIR | 11.53 | 0.261 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| \cdashline1-8 <svg id="S9.T5.6.6.1.1.1.pic1" class="ltx_picture" height="12.15"
    overflow="visible" version="1.1" width="12.8"><g transform="translate(0,12.15)
    matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">N</foreignobject></g></g></svg>  $\text{ConvLSTM}^{a}$  (Shi et al.,
    [2015](#bib.bib81)) | 14.0 | 30.1 | 182.9 | 0.707 | SEVIR | 9.76 | 0.354 (30)
    |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.8.8.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    TrajGRU (Shi et al., [2017](#bib.bib82)) | - | - | 103.3 | 0.713 | SEVIR | 8.92
    | 0.357 (30) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.9.9.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    PredRNN (Wang et al., [2017](#bib.bib94)) | 23.85 | 115.9 | 56.8 | 0.867 | SEVIR
    | - | 0.404 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.10.10.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    MIM (Wang et al., [2019](#bib.bib96)) | 37.37 | 181.7 | 101.1 | 0.910 | Guangzhou
    | 27.8 | 0.429 (30) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.11.11.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg>
    UNet (Veillette et al., [2020](#bib.bib91)) | 16.6 | 0.9 | 110.4 | 0.617 | SEVIR
    | - | 0.359 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.12.12.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    MotionRNN (Wu et al., [2021](#bib.bib101)) | 7.01 | 49.5 | 25.1 | 0.920 | Guangzhou
    | - | 0.678 (30) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.13.13.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">A</foreignobject></g></g></svg>
    DGMR (Ravuri et al., [2021](#bib.bib72)) | - | - | - | - | SEVIR | - | 0.268 (30)
    |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.14.14.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg>
    MSSTNet (Ye et al., [2022](#bib.bib104)) | - | - | 21.4 | 0.953 | - | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.15.15.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    PredRNN2 (Wang et al., [2022](#bib.bib95)) | 23.86 | 116.6 | 48.4 | 0.891 | SEVIR
    | 3.9 | 0.480 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.16.16.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    MS-RNN (Ma et al., [2022](#bib.bib61)) | 5.6 | 163.7 | 46.6 | 0.892 | Germany
    | - | - |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.17.17.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.53"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>
    Rainformer (Bai et al., [2022](#bib.bib9)) | 19.2 | 1.2 | 85.83 | 0.730 | SEVIR
    | 4.0 | 0.366 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.18.18.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.53"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>
    Earthformer (Gao et al., [2022](#bib.bib30)) | 7.6 | 34 | 41.79 | 0.896 | SEVIR
    | 3.7 | 0.442 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.19.19.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.8"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>
    ModeRNN (Yao et al., [2023](#bib.bib103)) | 3.15 | - | 44.7 | 0.898 | Guangzhou
    | 65.1 | 0.428 (30) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.20.20.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.93"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.4" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>
    Prediff (Gao et al., [2023](#bib.bib28)) | - | - | - | - | SEVIR | - | 0.407 (M)
    |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.21.21.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.93"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.4" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>
    Diffcast (Yu et al., [2023a](#bib.bib105)) | - | - | - | - | SEVIR | - | 0.282
    (10, 21, 33) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.22.22.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.53"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>
    Pastnet (Wu et al., [2023](#bib.bib100)) | - | - | 31.77 | - | SEVIR | 6.6 | -
    |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.23.23.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.53"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>
    MIMO-VP (Ning et al., [2023](#bib.bib66)) | 20.2 | - | 17.7 | 0.964 | China |
    - | 0.400 (30) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.24.24.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.53"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>
    Eartgfarseer (Wu et al., [2024](#bib.bib99)) | - | - | 14.9 | - | SEVIR | 2.8
    | 0.471 (M) |'
  prefs: []
  type: TYPE_TB
- en: '| <svg id="S9.T5.25.25.1.1.1.pic1" class="ltx_picture" height="12.15" overflow="visible"
    version="1.1" width="12.93"><g transform="translate(0,12.15) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.4" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>
    CasCast (Gong et al., [2024](#bib.bib34)) | - | - | - | - | SEVIR | - | 0.440
    (M) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 5: Comparison of experimental results on benchmark data. The weather
    data is organized into 6 min intervals for predicting 10 frames (1 h). FLOPS,
    or floating point operations per second, are measured to quantify and compare
    the computational cost of different models and their resource usage. The SSIM
    function refers to the structural similarity index measure for assessing the human
    visual perception and similarity between two images. (M) represents the average
    score of threshold values 16, 74, 133, 160, 181, and 219\. <svg id="S9.T5.31.1.pic1"
    class="ltx_picture" height="14.04" overflow="visible" version="1.1" width="14.87"><g
    transform="translate(0,14.04) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77
    2.77)"><foreignobject width="9.34" height="8.51" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>: Non-adversarial,
    <svg id="S9.T5.32.2.pic2" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">A</foreignobject></g></g></svg>:
    Adversarial, <svg id="S9.T5.33.3.pic3" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg>:
    UNet, <svg id="S9.T5.34.4.pic4" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="15.05"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.51" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>:
    Diffusion, <svg id="S9.T5.35.5.pic5" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.53"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="8.99" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>:
    Transformer.'
  prefs: []
  type: TYPE_NORMAL
- en: 9.2 Performance evaluation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'To evaluate the performance of models across different settings, we defined
    two benchmark datasets in this study: Moving the MNIST dataset (Srivastava et al.,
    [2015](#bib.bib86)) and SEVIR dataset (Veillette et al., [2020](#bib.bib91)).
    The reason for selecting the two benchmark datasets is that they are widely used
    and among the most commonly used in precipitation nowcasting. The SEVIR dataset
    offers the advantage of enabling comparisons of computational complexity. Moving
    MNIST is a synthetic dataset with grayscale images for video prediction. The benchmark
    dataset consists of 10 frames input and 10 frames output to compare the nowcasting
    models. We summarized the performance of applications that include at least one
    of these datasets chronologically in Table [5](#S9.T5 "Table 5 ‣ 9.1 Methodology
    comparison ‣ 9 Methodology comparison and evaluation ‣ 8.3.3 Periodic component
    ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy ‣ Deep learning for precipitation
    nowcasting: A survey from the perspective of time series forecasting"). Note that
    we included cases where the code was officially released and experiments comparing
    performance on the same data were conducted in other studies. For the threshold
    of CSI, comparisons were written based on the average, and in cases where the
    average value was not provided, we used the most commonly used threshold of 30
    as the reference. We set up the criteria for comparing computational complexity
    and model performance using the Moving MNIST dataset, based on the number of parameters,
    FLOPS, MSE, and SSIM.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In Figure [7](#S9.F7 "Figure 7 ‣ 9.2 Performance evaluation ‣ 9 Methodology
    comparison and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods
    ‣ 8 Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting"), we present a summary of evaluations
    conducted over time and across different thresholds. Note that the datasets used
    are different from each other. Based on the results, two might pose the following
    questions: i) How can we improve the accuracy of heavy rainfall prediction? Increasing
    the threshold leads to a discernible performance discrepancy, particularly in
    degradation for thresholds exceeding 4 mm and 40 dBZ. This outcome commonly arises
    due to biases in precipitation data, presenting a challenge for researchers to
    mitigate the data imbalance problem. ii) What approaches are available for enhancing
    lead time in precipitation forecasting? DL-based forecasting models demonstrate
    performance degradation over time, as observed in previous literature. While many
    models focus on forecasting rainfall within a 1 h window, the lead time presents
    limitations in decision-making, both socially and economically. The findings highlight
    the necessity for frameworks and benchmark datasets capable of developing models
    with longer lead times.'
  prefs: []
  type: TYPE_NORMAL
- en: <svg id="S9.F7.pic1" class="ltx_picture ltx_centering" height="411.95" overflow="visible"
    version="1.1" width="721.8"><g transform="translate(0,411.95) matrix(1 0 0 -1
    0 0) translate(152.21,0) translate(0,311.22)" fill="#000000" stroke="#000000"
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -126.64 85.35)"><g class="ltx_nestedsvg"
    transform="matrix(1 0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g
    fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject
    width="7.26" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible"
    color="#000000">N</foreignobject></g></g><g stroke="#000000" fill="#000000"><foreignobject
    width="186.78" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">MIM
    (Wang et al., [2019](#bib.bib96))</foreignobject></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 106.86 85.35)"><g class="ltx_nestedsvg" transform="matrix(1 0 0 1
    0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="200.09" height="9.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">RainNet (Ayzel et al., [2020](#bib.bib8))</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 347.02 85.35)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">A</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="200.08" height="9.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">DGMR (Ravuri et al., [2021](#bib.bib72))</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -144.29 -119.04)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.26" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="222.08" height="9.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Metnet-v2 (Espeholt et al., [2022](#bib.bib24))</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 104.82 -119.04)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="204.45" height="9.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Rainformer (Bai et al., [2022](#bib.bib9))</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 370.29 -119.04)"><g class="ltx_nestedsvg" transform="matrix(1
    0 0 1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="7.4" height="6.62"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g><g
    stroke="#000000" fill="#000000"><foreignobject width="153.41" height="9.69" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">(Nai et al., [2024](#bib.bib64))</foreignobject></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -116.62 -69.5)" fill="#000000" stroke="#000000"><foreignobject
    width="186" height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer
    to caption](img/743d4554cb3fcc0f54b1950a73f7bbd1.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 123.54 -69.5)" fill="#000000" stroke="#000000"><foreignobject width="186"
    height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/381156f0aaa1121f94ee8d65063a771b.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 363.69 -69.5)" fill="#000000" stroke="#000000"><foreignobject width="186"
    height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/ae097b3790dcc048a3d807392d1fb0d4.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -116.62 -274.22)" fill="#000000" stroke="#000000"><foreignobject width="186"
    height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/f435680e3b4adc4d711cf060e9264d34.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 123.54 -274.22)" fill="#000000" stroke="#000000"><foreignobject width="186"
    height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/58ca258565e030caa59ea9dab15c9f6e.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 363.69 -274.22)" fill="#000000" stroke="#000000"><foreignobject width="186"
    height="139" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">![Refer to
    caption](img/f50cca1841a35fb9e7581ef321bc1bdd.png)</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 8.08 -23.05)" fill="#000000" stroke="#000000"><foreignobject width="31.08"
    height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">30 dBZ</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -47.03 -46.67)" fill="#000000" stroke="#000000"><foreignobject
    width="31.08" height="6.73" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">40
    dBZ</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -117.9 -26.99)" fill="#000000"
    stroke="#000000"><foreignobject width="31.08" height="6.73" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">50 dBZ</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 184.01 59.87)" fill="#000000" stroke="#000000"><foreignobject width="41.43"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">0.125 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 188.68 20.5)" fill="#000000" stroke="#000000"><foreignobject
    width="24.21" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 188.68 -18.87)" fill="#000000"
    stroke="#000000"><foreignobject width="24.21" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">5 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 190.2 -54.3)" fill="#000000" stroke="#000000"><foreignobject width="29.06"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">10 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 146.89 -66.11)" fill="#000000" stroke="#000000"><foreignobject
    width="29.06" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">15
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 440.65 28.38)" fill="#000000"
    stroke="#000000"><foreignobject width="24.21" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">1 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 440.65 -22.81)" fill="#000000" stroke="#000000"><foreignobject width="24.21"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">4 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 420.96 -46.43)" fill="#000000" stroke="#000000"><foreignobject
    width="24.21" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">8
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -59.18 -168.48)" fill="#000000"
    stroke="#000000"><foreignobject width="31.75" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.2 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 11.51 -223.59)" fill="#000000" stroke="#000000"><foreignobject width="24.21"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -106.6 -192.1)" fill="#000000" stroke="#000000"><foreignobject
    width="24.21" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 27.26 -249.18)" fill="#000000"
    stroke="#000000"><foreignobject width="24.21" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">4 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -90.85 -245.25)" fill="#000000" stroke="#000000"><foreignobject width="24.21"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">8 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -116.89 -266.9)" fill="#000000" stroke="#000000"><foreignobject
    width="29.06" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">20
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 180.98 -152.73)" fill="#000000"
    stroke="#000000"><foreignobject width="31.75" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 184.74 -203.91)" fill="#000000" stroke="#000000"><foreignobject width="24.21"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">2 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 184.74 -243.28)" fill="#000000" stroke="#000000"><foreignobject
    width="24.21" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">5
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 162.64 -262.96)" fill="#000000"
    stroke="#000000"><foreignobject width="29.06" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">10 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 121.3 -270.84)" fill="#000000" stroke="#000000"><foreignobject width="29.06"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">30 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 420.96 -148.79)" fill="#000000" stroke="#000000"><foreignobject
    width="24.21" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1
    mm</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 460.33 -215.72)" fill="#000000"
    stroke="#000000"><foreignobject width="24.21" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">4 mm</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 428.84 -243.28)" fill="#000000" stroke="#000000"><foreignobject width="24.21"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">8 mm</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 -100.85)" fill="#000000" stroke="#000000"><foreignobject
    width="58.79" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead
    time (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -37.68 -89.74)"
    fill="#000000" stroke="#000000"><foreignobject width="12.38" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 72.38 -89.74)" fill="#000000" stroke="#000000"><foreignobject width="4.84"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.14 -100.85)" fill="#000000" stroke="#000000"><foreignobject
    width="58.79" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead
    time (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 202.47 -89.74)"
    fill="#000000" stroke="#000000"><foreignobject width="12.38" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 312.54 -89.74)" fill="#000000" stroke="#000000"><foreignobject width="4.84"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 427.3 -100.85)" fill="#000000" stroke="#000000"><foreignobject
    width="58.79" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead
    time (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 411.13 -89.74)"
    fill="#000000" stroke="#000000"><foreignobject width="12.38" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 485.77 -89.74)" fill="#000000" stroke="#000000"><foreignobject width="4.84"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 548.93 -89.74)" fill="#000000" stroke="#000000"><foreignobject
    width="12.38" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">1.5</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -41.21 -305.57)" fill="#000000" stroke="#000000"><foreignobject
    width="58.79" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead
    time (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 -87.07 -294.46)"
    fill="#000000" stroke="#000000"><foreignobject width="4.84" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">3</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 -35.89 -294.46)" fill="#000000" stroke="#000000"><foreignobject width="4.84"
    height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">6</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 19.23 -294.46)" fill="#000000" stroke="#000000"><foreignobject
    width="4.84" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">9</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 69.96 -294.46)" fill="#000000" stroke="#000000"><foreignobject
    width="9.69" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">12</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 187.14 -305.57)" fill="#000000" stroke="#000000"><foreignobject
    width="58.79" height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead
    time (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 233.97 -294.46)"
    fill="#000000" stroke="#000000"><foreignobject width="12.38" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5</foreignobject></g><g transform="matrix(1.0
    0.0 0.0 1.0 427.3 -305.57)" fill="#000000" stroke="#000000"><foreignobject width="58.79"
    height="9.69" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Lead time
    (h)</foreignobject></g><g transform="matrix(1.0 0.0 0.0 1.0 548.93 -294.46)" fill="#000000"
    stroke="#000000"><foreignobject width="12.38" height="6.24" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">0.5</foreignobject></g><g transform="matrix(0.0
    1.0 -1.0 0.0 -142.36 -7.94)" fill="#000000" stroke="#000000"><foreignobject width="15.87"
    height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -50.36)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.3</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -14.93)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 16.56)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.5</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 52)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 97.8 -7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -73.99)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.0</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -42.49)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.2</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -9.03)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 20.5)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 53.97)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.8</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 337.96 -7.94)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -62.18)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.1</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -34.62)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.2</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -10.99)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.3</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 10.66)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 34.28)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.5</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 57.9)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 -142.36 -212.66)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -286.59)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.0</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -262.96)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.1</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -237.37)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.2</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -211.78)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.3</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -190.13)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -164.54)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.5</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -141.56 -140.92)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 97.8 -212.66)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -278.71)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.0</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -243.28)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.2</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -207.85)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -174.38)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 98.6 -138.95)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.8</foreignobject></g><g
    transform="matrix(0.0 1.0 -1.0 0.0 337.96 -212.66)" fill="#000000" stroke="#000000"><foreignobject
    width="15.87" height="6.62" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CSI</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -262.96)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.2</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -241.31)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.3</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -219.66)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.4</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -196.03)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.5</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -174.38)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.6</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -152.73)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.7</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 338.75 -131.07)" fill="#000000" stroke="#000000"><foreignobject
    width="7.53" height="6.24" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">.8</foreignobject></g></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 7: Comparison of CSI scores ($\uparrow$) according to each threshold.
    The x-axis represents the time with a unit of hour, and the y-axis represents
    the CSI scores. <svg id="S9.F7.8.2.pic1" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">N</foreignobject></g></g></svg>:
    Non-adversarial, <svg id="S9.F7.9.3.pic2" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">A</foreignobject></g></g></svg>:
    Adversarial, <svg id="S9.F7.10.4.pic3" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.87"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.34" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">U</foreignobject></g></g></svg>:
    UNet, <svg id="S9.F7.11.5.pic4" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="15.05"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="9.51" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">D</foreignobject></g></g></svg>:
    Diffusion, <svg id="S9.F7.12.6.pic5" class="ltx_picture" height="14.04" overflow="visible"
    version="1.1" width="14.53"><g transform="translate(0,14.04) matrix(1 0 0 -1 0
    0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill-opacity="1.0"
    transform="matrix(1.0 0.0 0.0 1.0 2.77 2.77)"><foreignobject width="8.99" height="8.51"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">T</foreignobject></g></g></svg>:
    Transformer. DL models in precipitation nowcasting commonly degrade performance
    over time, particularly for higher thresholds. The atmosphere is a chaotic system
    where small perturbations in natural conditions can lead to vastly non-linear
    outcomes over time, a phenomenon known as the ‘butterfly effect’. This inherent
    unpredictability limits the accuracy of long-term forecasting.'
  prefs: []
  type: TYPE_NORMAL
- en: 10 Future challenges and opportunities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Time series forecasting has led to discernible advancements in precipitation
    prediction. However, the full potential of DL for enhancing precipitation forecasting
    has yet to be investigated. Four challenges still need to be addressed: ① long
    lead time (Section [10.1](#S10.SS1 "10.1 Long lead time ‣ 10 Future challenges
    and opportunities ‣ 9.2 Performance evaluation ‣ 9 Methodology comparison and
    evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods ‣ 8 Multiple
    strategy ‣ Deep learning for precipitation nowcasting: A survey from the perspective
    of time series forecasting")), ② multi-sensor data fusion (Section [10.2](#S10.SS2
    "10.2 Multi-sensor data fusion ‣ 10 Future challenges and opportunities ‣ 9.2
    Performance evaluation ‣ 9 Methodology comparison and evaluation ‣ 8.3.3 Periodic
    component ‣ 8.3 Transformer-based methods ‣ 8 Multiple strategy ‣ Deep learning
    for precipitation nowcasting: A survey from the perspective of time series forecasting")),
    ③ data augmentation (Section [10.3](#S10.SS3 "10.3 Data augmentation ‣ 10 Future
    challenges and opportunities ‣ 9.2 Performance evaluation ‣ 9 Methodology comparison
    and evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods ‣ 8
    Multiple strategy ‣ Deep learning for precipitation nowcasting: A survey from
    the perspective of time series forecasting")) and ④ standard evaluation protocols
    (Section [10.4](#S10.SS4 "10.4 Standard evaluation protocols ‣ 10 Future challenges
    and opportunities ‣ 9.2 Performance evaluation ‣ 9 Methodology comparison and
    evaluation ‣ 8.3.3 Periodic component ‣ 8.3 Transformer-based methods ‣ 8 Multiple
    strategy ‣ Deep learning for precipitation nowcasting: A survey from the perspective
    of time series forecasting")). In this section, we discuss the remaining challenges
    and possible directions.'
  prefs: []
  type: TYPE_NORMAL
- en: 10.1 Long lead time
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most studies of time series rainfall prediction using radar have focused on
    forecasting within a 2 h window. The main reason for this is that predicting precipitation
    for more than 2 h requires high-resolution data over a wide area and significant
    computing resources. An observational context information radius of 72 km/h ×
    2 h from the target area is required to predict 2 h precipitation (Espeholt et al.,
    [2022](#bib.bib24)). To incorporate a larger observational context, lowering the
    spatial resolution may be tempting, but it comes at the cost of losing a detailed
    analysis of local precipitation for the model which is not advisable. Alternative
    model structures may be required to address the lead time bottleneck. Full global
    model emulators such as FourCastNet (Pathak et al., [2022](#bib.bib69)), Pangu-Weather
    (Bi et al., [2022](#bib.bib11)), GraphCast (Lam et al., [2022](#bib.bib51)), and
    Gencast (Price et al., [2023](#bib.bib70)) are capable of predicting three-dimensional
    atmospheric fields for medium range time scale (typically 5 – 10 days) although
    precipitation forecast has not been their strong point. Their long lead time prediction
    is possible because their models do not have to deal with horizontal lateral boundary
    condition updates.
  prefs: []
  type: TYPE_NORMAL
- en: 10.2 Multi-sensor data fusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most studies have employed radar-only models for short-term precipitation forecasting.
    This choice stems from the fact that satellite data exhibit a nonlinear relationship
    with precipitation, making them prone to introducing noise into precipitation
    forecasting. Satellites equipped with multi-sensors offer valuable information
    on clouds at various altitudes, which is a crucial advantage for capturing rapidly
    changing precipitation phenomena. Thus, how can two sensor datasets complement
    each other? Addressing this question necessitates resolving key issues pertaining
    to the optimal fusion of diverse sensor datasets, including determining where
    and how to perform such a fusion. To address this effectively, ideal data fusion
    methods should demonstrate potent feature representations, enabling robust learning
    of diverse precipitation patterns by the model.
  prefs: []
  type: TYPE_NORMAL
- en: 10.3 Data augmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Precipitation data have imbalanced data distributions, which significantly degrade
    the performance of existing methods. To address this, data augmentation procedures
    are required for precipitation forecasting. Data augmentation enhances knowledge
    learning by providing additional information or details, potentially improving
    the accuracy or reliability of the model. Seo et al. ([2022b](#bib.bib78)) experimented
    with random color jittering, random cropping, and random rotation augmentation
    to verify the effectiveness of data augmentation. They found that most procedures
    improved performance, but the rotation augmentation method showed a gap in the
    results. Augmenting the data in the opposite direction to the optical flow led
    to performance degradation. Designing data augmentation by considering possible
    constraints on data characteristics can help in learning representations, thereby
    enhancing the performance of real-world applications in atmospheric science.
  prefs: []
  type: TYPE_NORMAL
- en: 10.4 Standard evaluation protocols
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: With the increasing number of time series precipitation forecasting models,
    there is a growing need for a standardized baseline against which different algorithms
    can be uniformly evaluated. Standardizing the evaluation process is essential
    to ensure fair and consistent comparisons between different algorithms. In this
    regard, what should the test period, rainfall thresholds, and forecast lead time
    be? How can we compare new models to the cutting-edge models, such as different
    resolution models? Is there agreement on whether radar data is the best ground
    truth for precipitation? Perhaps an estimated value by radar is not the true rainfall,
    despite the radar-obtained precipitation value potentially being the closest to
    the actual value. By comparing the performance of different models using standardized
    evaluation metrics, researchers can identify the strengths and weaknesses of each
    approach more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: 11 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In recent years, many successful attempts have been made to develop time series
    models to boost precipitation forecasting. To compensate for the lack of a systematic
    summary and discourse on the practical review of precipitation forecasting, we
    provide a comprehensive survey of forecasting approaches while discussing the
    interactions and differences among them. This survey is expected to serve as a
    starting point for new researchers in this area and an inspiration for future
    research.
  prefs: []
  type: TYPE_NORMAL
- en: 12 Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work was carried out through the R&D project “Development of a Next-Generation
    Operational System by the Korea Institute of Atmospheric Prediction Systems (KIAPS)”,
    funded by the Korea Meteorological Administration (KMA2020-02213). This work was
    supported by Institute of Information & communications Technology Planning & Evaluation
    (IITP) grant funded by the Korea government(MSIT) (No. RS-2019-II190079, Artificial
    Intelligence Graduate School Program(Korea University)).
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Achim et al. (2003) Achim, A., Tsakalides, P., Bezerianos, A., 2003. Sar image
    denoising via bayesian wavelet shrinkage based on heavy-tailed modeling. IEEE
    Transactions on Geoscience and Remote sensing 41, 1773–1784.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amon (1993) Amon, C.H., 1993. Spectra element-fourier method for transitional
    flows in complex geometries. AIAA journal 31, 42–48.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An (2023) An, S., 2023. Nowcast-to-forecast: Token-based multiple remote sensing
    data fusion for precipitation forecast, in: Proceedings of the 32nd ACM International
    Conference on Information and Knowledge Management, pp. 4495–4501.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An et al. (2024) An, S., Oh, T.J., Kim, S.W., Jung, J.J., 2024. Self-clustered
    gan for precipitation nowcasting. Scientific Reports 14.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrychowicz et al. (2023) Andrychowicz, M., Espeholt, L., Li, D., Merchant,
    S., Merose, A., Zyda, F., Agrawal, S., Kalchbrenner, N., 2023. Deep learning for
    day forecasts from sparse observations. arXiv preprint arXiv:2306.06079 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ashesh et al. (2022) Ashesh, A., Chang, C.T., Chen, B.F., Lin, H.T., Chen, B.,
    Huang, T.S., 2022. Accurate and clear quantitative precipitation nowcasting based
    on a deep learning model with consecutive attention and rain-map discrimination.
    Artificial Intelligence for the Earth Systems 1, e210005.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ashok and Pekkat (2022) Ashok, S.P., Pekkat, S., 2022. A systematic quantitative
    review on the performance of some of the recent short-term rainfall forecasting
    techniques. Journal of Water and Climate Change 13, 3004–3029.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ayzel et al. (2020) Ayzel, G., Scheffer, T., Heistermann, M., 2020. Rainnet
    v1\. 0: a convolutional neural network for radar-based precipitation nowcasting.
    Geoscientific Model Development 13, 2631–2644.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bai et al. (2022) Bai, C., Sun, F., Zhang, J., Song, Y., Chen, S., 2022. Rainformer:
    Features extraction balanced network for radar-based precipitation nowcasting.
    IEEE Geoscience and Remote Sensing Letters 19, 1–5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bakkay et al. (2022) Bakkay, M.C., Serrurier, M., Burda, V.K., Dupuy, F., Cabrera-Gutierrez,
    N.C., Zamo, M., Mader, M.A., Mestre, O., Oller, G., Jouhaud, J.C., et al., 2022.
    Precipitaion nowcasting using deep neural network. arXiv preprint arXiv:2203.13263
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bi et al. (2022) Bi, K., Xie, L., Zhang, H., Chen, X., Gu, X., Tian, Q., 2022.
    Pangu-weather: A 3d high-resolution model for fast and accurate global weather
    forecast. arXiv preprint arXiv:2211.02556 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Binetti et al. (2022) Binetti, M.S., Campanale, C., Massarelli, C., Uricchio,
    V.F., 2022. The use of weather radar data: possibilities, challenges and advanced
    applications. Earth 3, 157–171.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brock et al. (2018) Brock, A., Donahue, J., Simonyan, K., 2018. Large scale
    gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Browning and Collier (1989) Browning, K., Collier, C., 1989. Nowcasting of precipitation
    systems. Reviews of Geophysics 27, 345–370.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bulo et al. (2017) Bulo, R.S., Neuhold, G., Kontschieder, P., 2017. Loss max-pooling
    for semantic image segmentation, in: Proceedings of the IEEE conference on computer
    vision and pattern recognition, pp. 2126–2135.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cambier et al. (2023) Cambier, v.N.C., Schreurs, K., Wijnands, J.S., Leijnse,
    H., Schmeits, M., Whan, K., Shapovalova, Y., 2023. Improving precipitation nowcasting
    for high-intensity events using deep generative models with balanced loss and
    temperature data: A case study in the netherlands. Artificial Intelligence for
    the Earth Systems 2, e230017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen (2021) Chen, H., 2021. Challenges and corresponding solutions of generative
    adversarial networks (gans): a survey study, in: Journal of Physics: Conference
    Series, IOP Publishing. p. 012066.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2019) Chen, H., Chandrasekar, V., Cifelli, R., Xie, P., 2019. A
    machine learning system for precipitation estimation using satellite and ground
    radar network observations. IEEE Transactions on Geoscience and Remote Sensing
    58, 982–994.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. (2020) Chen, L., Cao, Y., Ma, L., Zhang, J., 2020. A deep learning-based
    methodology for precipitation nowcasting with radar. Earth and Space Science 7,
    e2019EA000812.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi et al. (2023) Choi, J., Kim, Y., Kim, K.H., Jung, S.H., Cho, I., 2023.
    Pct-cyclegan: Paired complementary temporal cycle-consistent adversarial networks
    for radar-based precipitation nowcasting, in: Proceedings of the 32nd ACM International
    Conference on Information and Knowledge Management, pp. 348–358.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi and Kim (2022) Choi, S., Kim, Y., 2022. Rad-cgan v1\. 0: Radar-based precipitation
    nowcasting model with conditional generative adversarial networks for multiple
    dam domains. Geoscientific Model Development 15, 5967–5985.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Creswell et al. (2018) Creswell, A., White, T., Dumoulin, V., Arulkumaran,
    K., Sengupta, B., Bharath, A.A., 2018. Generative adversarial networks: An overview.
    IEEE signal processing magazine 35, 53–65.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ehsani et al. (2022) Ehsani, M.R., Zarei, A., Gupta, H.V., Barnard, K., Lyons,
    E., Behrangi, A., 2022. Nowcasting-nets: Representation learning to mitigate latency
    gap of satellite precipitation products using convolutional and recurrent neural
    networks. IEEE Transactions on Geoscience and Remote Sensing 60, 1–21.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Espeholt et al. (2022) Espeholt, L., Agrawal, S., Sønderby, C., Kumar, M., Heek,
    J., Bromberg, C., Gazen, C., Carver, R., Andrychowicz, M., Hickey, J., et al.,
    2022. Deep learning for twelve hour precipitation forecasts. Nature communications
    13, 5145.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fernández and Mehrkanoon (2021) Fernández, J.G., Mehrkanoon, S., 2021. Broad-unet:
    Multi-scale feature learning for nowcasting tasks. Neural Networks 144, 419–427.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fournier et al. (2005) Fournier, A., Bunge, H.P., Hollerbach, R., Vilotte, J.P.,
    2005. A fourier-spectral element algorithm for thermal convection in rotating
    axisymmetric containers. Journal of Computational Physics 204, 462–489.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fovell and Tan (1998) Fovell, R.G., Tan, P.H., 1998. The temporal behavior
    of numerically simulated multicell-type storms. part ii: The convective cell life
    cycle and cell regeneration. Monthly Weather Review 126, 551–577.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2023) Gao, Z., Shi, X., Han, B., Wang, H., Jin, X., Maddix, D.,
    Zhu, Y., Li, M., Wang, Y., 2023. Prediff: Precipitation nowcasting with latent
    diffusion models. arXiv preprint arXiv:2307.10422 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2021) Gao, Z., Shi, X., Wang, H., Yeung, D.Y., Woo, W.c., Wong,
    W.K., 2021. Deep learning and the weather forecasting problem: Precipitation nowcasting.
    Deep Learning for the Earth Sciences: A Comprehensive Approach to Remote Sensing,
    Climate Science, and Geosciences , 218–239.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gao et al. (2022) Gao, Z., Shi, X., Wang, H., Zhu, Y., Wang, Y.B., Li, M.,
    Yeung, D.Y., 2022. Earthformer: Exploring space-time transformers for earth system
    forecasting. Advances in Neural Information Processing Systems 35, 25390–25403.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geng et al. (2023) Geng, H., Ge, X., Xie, B., Min, J., Zhuang, X., 2023. Lstmatu-net:
    A precipitation nowcasting model based on ecsa module. Sensors 23, 5785.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geng et al. (2024) Geng, H., Wu, F., Zhuang, X., Geng, L., Xie, B., Shi, Z.,
    2024. The ms-radarformer: A transformer-based multi-scale deep learning model
    for radar echo extrapolation. Remote Sensing 16, 274.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Germann and Zawadzki (2002) Germann, U., Zawadzki, I., 2002. Scale-dependence
    of the predictability of precipitation from continental radar images. part i:
    Description of the methodology. Monthly Weather Review 130, 2859–2873.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gong et al. (2024) Gong, J., Bai, L., Ye, P., Xu, W., Liu, N., Dai, J., Yang,
    X., Ouyang, W., 2024. Cascast: Skillful high-resolution precipitation nowcasting
    via cascaded modelling. arXiv preprint arXiv:2402.04290 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gruca et al. (2023) Gruca, A., Serva, F., Lliso, P., Calbet, X., Herruzo, P.,
    Pihrt, P., Choma, M., et al., 2023. Weather4cast at neurips 2022: Super-resolution
    rain movie prediction under spatio-temporal shifts, in: NeurIPS 2022 Competition
    Track, PMLR. pp. 292–313.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Han et al. (2023) Han, D., Shin, Y., Im, J., Lee, J., 2023. Key factors for
    quantitative precipitation nowcasting using ground weather radar data based on
    deep learning. Geoscientific Model Development Discussions 2023, 1–43.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hatsuzuka et al. (2021) Hatsuzuka, D., Sato, T., Higuchi, Y., 2021. Sharp rises
    in large-scale, long-duration precipitation extremes with higher temperatures
    over japan. npj Climate and Atmospheric Science 4, 29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henny et al. (2022) Henny, L., Thorncroft, C.D., Bosart, L.F., 2022. Changes
    in large-scale fall extreme precipitation in the mid-atlantic and northeast united
    states, 1979–2019. Journal of Climate 35, 6647–6670.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Herruzo et al. (2021) Herruzo, P., Gruca, A., Lliso, L., Calbet, X., Rípodas,
    P., Hochreiter, S., Kopp, M., Kreil, D.P., 2021. High-resolution multi-channel
    weather forecasting–first insights on transfer learning from the weather4cast
    competitions 2021, in: 2021 IEEE International Conference on Big Data (Big Data),
    IEEE. pp. 5750–5757.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ho et al. (2020) Ho, J., Jain, A., Abbeel, P., 2020. Denoising diffusion probabilistic
    models. Advances in neural information processing systems 33, 6840–6851.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Horváth et al. (2021) Horváth, J., Baireddy, S., Hao, H., Montserrat, D.M.,
    Delp, E.J., 2021. Manipulation detection in satellite images using vision transformer,
    in: Proceedings of the IEEE/CVF conference on computer vision and pattern recognition,
    pp. 1032–1041.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. (2023) Huang, L., Qin, J., Zhou, Y., Zhu, F., Liu, L., Shao, L.,
    2023. Normalization techniques in training dnns: Methodology, analysis and application.
    IEEE transactions on pattern analysis and machine intelligence 45, 10173–10196.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jeong et al. (2021) Jeong, C.H., Kim, W., Joo, W., Jang, D., Yi, M.Y., 2021.
    Enhancing the encoding-forecasting model for precipitation nowcasting by putting
    high emphasis on the latest data of the time step. Atmosphere 12, 261.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jiang et al. (2021) Jiang, Y., Chang, S., Wang, Z., 2021. Transgan: Two pure
    transformers can make one strong gan, and that can scale up. Advances in Neural
    Information Processing Systems 34, 14745–14758.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jing et al. (2019) Jing, J., Li, Q., Ding, X., Sun, N., Tang, R., Cai, Y.,
    2019. Aenn: A generative adversarial neural network for weather radar echo extrapolation.
    The International Archives of Photogrammetry, Remote Sensing and Spatial Information
    Sciences 42, 89–94.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2022) Kim, T., Kang, S., Shin, H., Yoon, D., Eom, S., Shin, K.,
    Yun, S.Y., 2022. Region-conditioned orthogonal 3d u-net for weather4cast competition.
    arXiv preprint arXiv:2212.02059 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kim et al. (2021) Kim, T.J., Kwon, H.H., Kim, K.B., 2021. Calibration of the
    reflectivity-rainfall rate (z-r) relationship using long-term radar reflectivity
    factor over the entire south korea region in a bayesian perspective. Journal of
    Hydrology 593, 125790.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ko et al. (2022) Ko, J., Lee, K., Hwang, H., Oh, S.G., Son, S.W., Shin, K.,
    2022. Effective training strategies for deep-learning-based precipitation nowcasting
    and estimation. Computers & Geosciences 161, 105072.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kumjian et al. (2010) Kumjian, M.R., Ryzhkov, A.V., Melnikov, V.M., Schuur,
    T.J., 2010. Rapid-scan super-resolution observations of a cyclic supercell with
    a dual-polarization wsr-88d. Monthly weather review 138, 3762–3786.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kupyn et al. (2018) Kupyn, O., Budzan, V., Mykhailych, M., Mishkin, D., Matas,
    J., 2018. Deblurgan: Blind motion deblurring using conditional adversarial networks,
    in: Proceedings of the IEEE conference on computer vision and pattern recognition,
    pp. 8183–8192.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lam et al. (2022) Lam, R., Sanchez-Gonzalez, A., Willson, M., Wirnsberger,
    P., Fortunato, M., Alet, F., Ravuri, S., Ewalds, T., Eaton-Rosen, Z., Hu, W.,
    et al., 2022. Graphcast: Learning skillful medium-range global weather forecasting.
    arXiv preprint arXiv:2212.12794 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Larvor et al. (2020) Larvor, G., Berthomier, L., Chabot, V., Pape, B.L., Pradel,
    B., Perez, L., 2020. Meteonet, an open reference weather dataset by meteo france.
    [https://meteonet.umr-cnrm.fr/](https://meteonet.umr-cnrm.fr/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lebedev et al. (2019) Lebedev, V., Ivashkin, V., Rudenko, I., Ganshin, A.,
    Molchanov, A., Ovcharenko, S., Grokhovetskiy, R., Bushmarinov, I., Solomentsev,
    D., 2019. Precipitation nowcasting with satellite imagery, in: Proceedings of
    the 25th ACM SIGKDD international conference on knowledge discovery & data mining,
    pp. 2680–2688.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee et al. (2021) Lee, Y., Kummerow, C.D., Zupanski, M., 2021. A simplified
    method for the detection of convection using high-resolution imagery from goes-16.
    Atmos. Meas. Tech. 14, 3755–3771.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leinonen et al. (2023) Leinonen, J., Hamann, U., Nerini, D., Germann, U., Franch,
    G., 2023. Latent diffusion models for generative precipitation nowcasting with
    accurate uncertainty quantification. arXiv preprint arXiv:2304.12891 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2021) Li, D., Liu, Y., Chen, C., 2021. Msdm v1\. 0: A machine learning
    model for precipitation nowcasting over eastern china using multisource data.
    Geoscientific Model Development 14, 4019–4034.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2023) Li, Y., Liu, Y., Sun, R., Guo, F., Xu, X., Xu, H., 2023. Convective
    storm vil and lightning nowcasting using satellite and weather radar measurements
    based on multi-task learning models. Advances in Atmospheric Sciences 40, 887–899.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. (2022) Lin, T., Wang, Y., Liu, X., Qiu, X., 2022. A survey of transformers.
    AI open 3, 111–132.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu and Lee (2020) Liu, H.B., Lee, I., 2020. Mpl-gan: Toward realistic meteorological
    predictive learning using conditional gan. IEEE Access 8, 93179–93186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2019) Ma, Y., Ni, G., Chandra, C.V., Tian, F., Chen, H., 2019. Statistical
    characteristics of raindrop size distribution during rainy seasons in the beijing
    urban area and implications for radar rainfall estimation. Hydrology and Earth
    System Sciences 23, 4153–4170.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2022) Ma, Z., Zhang, H., Liu, J., 2022. Ms-rnn: A flexible multi-scale
    framework for spatiotemporal predictive learning. arXiv preprint arXiv:2206.03010
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ma et al. (2024) Ma, Z., Zhang, H., Liu, J., 2024. Db-rnn: A rnn for precipitation
    nowcasting deblurring. IEEE Journal of Selected Topics in Applied Earth Observations
    and Remote Sensing .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Marshall and Palmer (1948) Marshall, J.S., Palmer, W.M., 1948. The distribution
    of raindrops with size. Journal of Meteorology 5, 165–166.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nai et al. (2024) Nai, C., Pan, B., Chen, X., Tang, Q., Ni, G., Duan, Q., Lu,
    B., Xiao, Z., Liu, X., 2024. Reliable precipitation nowcasting using probabilistic
    diffusion models. Environmental Research Letters .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NCEP (2018) NCEP, 2018. Multi-Radar/Multi-Sensor (MRMS) Precipitation Data.
    Version 1.0 [Data set]. UCAR/NCAR - Earth Observing Laboratory. [https://doi.org/10.26023/R5QJ-VEPF-P00D](https://doi.org/10.26023/R5QJ-VEPF-P00D)
    Accessed 15 Jan 2024.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ning et al. (2023) Ning, S., Lan, M., Li, Y., Chen, C., Chen, Q., Chen, X.,
    Han, X., Cui, S., 2023. Mimo is all you need: A strong multi-in-multi-out baseline
    for video prediction, in: Proceedings of the AAAI Conference on Artificial Intelligence,
    pp. 1975–1983.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Niu et al. (2024) Niu, D., Li, Y., Wang, H., Zang, Z., Jiang, M., Chen, X.,
    Huang, Q., 2024. Fsrgan: A satellite and radar-based fusion prediction network
    for precipitation nowcasting. IEEE Journal of Selected Topics in Applied Earth
    Observations and Remote Sensing .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Park et al. (2022) Park, J., Lee, I., Son, M., Cho, S., Kim, C., 2022. Nowformer:
    A locally enhanced temporal learner for precipitation nowcasting, in: Proceedings
    of the NeurIPS 2022 Workshop on Tackling Climate Change with Machine Learning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Pathak et al. (2022) Pathak, J., Subramanian, S., Harrington, P., Raja, S.,
    Chattopadhyay, A., Mardani, M., Kurth, T., Hall, D., Li, Z., Azizzadenesheli,
    K., et al., 2022. Fourcastnet: A global data-driven high-resolution weather model
    using adaptive fourier neural operators. arXiv preprint arXiv:2202.11214 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Price et al. (2023) Price, I., Sanchez-Gonzalez, A., Alet, F., Ewalds, T.,
    El-Kadi, A., Stott, J., Mohamed, S., Battaglia, P., Lam, R., Willson, M., 2023.
    Gencast: Diffusion-based ensemble forecasting for medium-range weather. arXiv
    preprint arXiv:2312.15796 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Prudden et al. (2020) Prudden, R., Adams, S., Kangin, D., Robinson, N., Ravuri,
    S., Mohamed, S., Arribas, A., 2020. A review of radar-based nowcasting of precipitation
    and applicable machine learning techniques. arXiv preprint arXiv:2005.04988 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ravuri et al. (2021) Ravuri, S., Lenc, K., Willson, M., Kangin, D., Lam, R.,
    Mirowski, P., Fitzsimons, M., Athanassiadou, M., Kashem, S., Madge, S., et al.,
    2021. Skilful precipitation nowcasting using deep generative models of radar.
    Nature 597, 672–677.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Reulen and Mehrkanoon (2024) Reulen, E., Mehrkanoon, S., 2024. Ga-smaat-gnet:
    Generative adversarial small attention gnet for extreme precipitation nowcasting.
    arXiv preprint arXiv:2401.09881 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Roca and Fiolleau (2020) Roca, R., Fiolleau, T., 2020. Extreme precipitation
    in the tropics is closely associated with long-lived convective systems. Communications
    Earth & Environment 1, 18.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Salcedo-Sanz et al. (2024) Salcedo-Sanz, S., Pérez-Aracil, J., Ascenso, G.,
    Del Ser, J., Casillas-Pérez, D., Kadow, C., Fister, D., Barriopedro, D., García-Herrera,
    R., Giuliani, M., et al., 2024. Analysis, characterization, prediction, and attribution
    of extreme atmospheric events with machine learning and deep learning techniques:
    a review. Theoretical and Applied Climatology 155, 1–44.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Samset et al. (2016) Samset, B., Myhre, G., Forster, P., Hodnebrog, Ø., Andrews,
    T., Faluvegi, G., Flaeschner, D., Kasoar, M., Kharin, V., Kirkevåg, A., et al.,
    2016. Fast and slow precipitation responses to individual climate forcers: A pdrmip
    multimodel study. Geophysical research letters 43, 2782–2791.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seo et al. (2022a) Seo, M., Kim, D., Shin, S., Kim, E., Ahn, S., Choi, Y., 2022a.
    Domain generalization strategy to train classifiers robust to spatial-temporal
    shift. arXiv preprint arXiv:2212.02968 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Seo et al. (2022b) Seo, M., Kim, D., Shin, S., Kim, E., Ahn, S., Choi, Y., 2022b.
    Simple baseline for weather forecasting using spatiotemporal context aggregation
    network. arXiv preprint arXiv:2212.02952 .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'She et al. (2023) She, L., Zhang, C., Man, X., Luo, X., Shao, J., 2023. A self-attention
    causal lstm model for precipitation nowcasting, in: 2023 IEEE International Conference
    on Multimedia and Expo Workshops (ICMEW), IEEE. pp. 470–473.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2022) Shi, L., Lin, Z., Wei, X., Peng, C., Yao, Z., Han, B., Xiao,
    Q., Zhou, H., Deng, Y., Liu, K., et al., 2022. Precipitation increase counteracts
    warming effects on plant and soil c: N: P stoichiometry in an alpine meadow. Frontiers
    in Plant Science 13, 1044173.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2015) Shi, X., Chen, Z., Wang, H., Yeung, D.Y., Wong, W.K., Woo,
    W.c., 2015. Convolutional lstm network: A machine learning approach for precipitation
    nowcasting. Advances in neural information processing systems 28.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shi et al. (2017) Shi, X., Gao, Z., Lausen, L., Wang, H., Yeung, D.Y., Wong,
    W.k., Woo, W.c., 2017. Deep learning for precipitation nowcasting: A benchmark
    and a new model. Advances in neural information processing systems 30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sit et al. (2021) Sit, M., Seo, B.C., Demir, I., 2021. Iowarain: A statewide
    rain event dataset based on weather radars and quantitative precipitation estimation.
    arXiv preprint arXiv:2107.03432 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sønderby et al. (2020) Sønderby, C.K., Espeholt, L., Heek, J., Dehghani, M.,
    Oliver, A., Salimans, T., Agrawal, S., Hickey, J., Kalchbrenner, N., 2020. Metnet:
    A neural weather model for precipitation forecasting. arXiv preprint arXiv:2003.12140.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song and Ermon (2020) Song, Y., Ermon, S., 2020. Improved techniques for training
    score-based generative models. Advances in neural information processing systems
    33, 12438–12448.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Srivastava et al. (2015) Srivastava, N., Mansimov, E., Salakhudinov, R., 2015.
    Unsupervised learning of video representations using lstms, in: International
    conference on machine learning, PMLR. pp. 843–852.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tian et al. (2023) Tian, W., Wang, C., Shen, K., Zhang, L., Lim Kam Sian, K.T.C.,
    2023. Mslknet: A multi-scale large kernel convolutional network for radar extrapolation.
    Atmosphere 15, 52.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tran and Song (2019) Tran, Q.K., Song, S.k., 2019. Computer vision in precipitation
    nowcasting: Applying image quality assessment metrics for training deep neural
    networks. Atmosphere 10, 244.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Trebing et al. (2021) Trebing, K., Stańczyk, T., Mehrkanoon, S., 2021. Smaat-unet:
    Precipitation nowcasting using a small attention-unet architecture. Pattern Recognition
    Letters 145, 178–186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Upadhyay et al. (2024) Upadhyay, A.B., Shah, S.R., Thakkar, R.A., 2024. Theoretical
    assessment for weather nowcasting using deep learning methods. Archives of Computational
    Methods in Engineering , 1–10.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Veillette et al. (2020) Veillette, M., Samsi, S., Mattioli, C., 2020. Sevir:
    A storm event imagery dataset for deep learning applications in radar and satellite
    meteorology. Advances in Neural Information Processing Systems 33, 22009–22019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Verma et al. (2023) Verma, S., Srivastava, K., Tiwari, A., Verma, S., 2023.
    Deep learning techniques in extreme weather events: A review. arXiv preprint arXiv:2308.10995
    .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2023) Wang, R., Su, L., Wong, W.K., Lau, A.K., Fung, J.C., 2023.
    Skillful radar-based heavy rainfall nowcasting using task-segmented generative
    adversarial network. IEEE Transactions on Geoscience and Remote Sensing .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2017) Wang, Y., Long, M., Wang, J., Gao, Z., Yu, P.S., 2017. Predrnn:
    Recurrent neural networks for predictive learning using spatiotemporal lstms.
    Advances in neural information processing systems 30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2022) Wang, Y., Wu, H., Zhang, J., Gao, Z., Wang, J., Philip,
    S.Y., Long, M., 2022. Predrnn: A recurrent neural network for spatiotemporal predictive
    learning. IEEE Transactions on Pattern Analysis and Machine Intelligence 45, 2208–2225.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2019) Wang, Y., Zhang, J., Zhu, H., Long, M., Wang, J., Yu, P.S.,
    2019. Memory in memory: A predictive neural network for learning higher-order
    non-stationarity from spatiotemporal dynamics, in: Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition, pp. 9154–9162.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whang et al. (2022) Whang, J., Delbracio, M., Talebi, H., Saharia, C., Dimakis,
    A.G., Milanfar, P., 2022. Deblurring via stochastic refinement, in: Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pp. 16293–16303.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wiatrak et al. (2019) Wiatrak, M., Albrecht, S.V., Nystrom, A., 2019. Stabilizing
    generative adversarial networks: A survey. arXiv preprint arXiv:1910.00927 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2024) Wu, H., Liang, Y., Xiong, W., Zhou, Z., Huang, W., Wang, S.,
    Wang, K., 2024. Earthfarsser: Versatile spatio-temporal dynamical systems modeling
    in one model, in: Proceedings of the AAAI Conference on Artificial Intelligence,
    pp. 15906–15914.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2023) Wu, H., Xion, W., Xu, F., Luo, X., Chen, C., Hua, X.S., Wang,
    H., 2023. Pastnet: Introducing physical inductive biases for spatio-temporal video
    prediction. arXiv preprint arXiv:2305.11421 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu et al. (2021) Wu, H., Yao, Z., Wang, J., Long, M., 2021. Motionrnn: A flexible
    model for video prediction with spacetime-varying motions, in: Proceedings of
    the IEEE/CVF conference on computer vision and pattern recognition, pp. 15435–15444.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. (2024) Xu, L., Li, X., Yu, H., Du, W., Chen, Z., Chen, N., 2024.
    PP-Loss: An imbalanced regression loss based on plotting position for improved
    precipitation nowcasting. Theoretical and Applied Climatology , 1–15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yao et al. (2023) Yao, Z., Wang, Y., Wu, H., Wang, J., Long, M., 2023. Modernn:
    Harnessing spatiotemporal mode collapse in unsupervised predictive learning. IEEE
    Transactions on Pattern Analysis and Machine Intelligence .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ye et al. (2022) Ye, Y., Gao, F., Cheng, W., Liu, C., Zhang, S., 2022. Msstnet:
    A multi-scale spatiotemporal prediction neural network for precipitation nowcasting.
    Remote Sensing 15, 137.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yu et al. (2023a) Yu, D., Li, X., Ye, Y., Zhang, B., Luo, C., Dai, K., Wang,
    R., Chen, X., 2023a. Diffcast: A unified framework via residual diffusion for
    precipitation nowcasting. arXiv preprint arXiv:2312.06734 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yu et al. (2023b) Yu, W., Wang, S., Zhang, C., Chen, Y., Sheng, X., Yao, Y.,
    Liu, J., Liu, G., 2023b. Integrating spatio-temporal and generative adversarial
    networks for enhanced nowcasting performance. Remote Sensing 15, 3720.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. (2023) Zhang, Y., Long, M., Chen, K., Xing, L., Jin, R., Jordan,
    M.I., Wang, J., 2023. Skilful nowcasting of extreme precipitation with nowcastnet.
    Nature 619, 526–532.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
