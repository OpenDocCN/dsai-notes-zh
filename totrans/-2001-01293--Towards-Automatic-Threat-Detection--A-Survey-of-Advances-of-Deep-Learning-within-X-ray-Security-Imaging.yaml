- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:03:11'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2001.01293] Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2001.01293](https://ar5iv.labs.arxiv.org/html/2001.01293)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Samet Akcay Toby Breckon Intel R&D, UK Department of Computer Science, Durham
    University, Durham, UK
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: X-ray security screening is widely used to maintain aviation/transport security,
    and its significance poses a particular interest in automated screening systems.
    This paper aims to review computerised X-ray security imaging algorithms by taxonomising
    the field into conventional machine learning and contemporary deep learning applications.
    The first part briefly discusses the classical machine learning approaches utilised
    within X-ray security imaging, while the latter part thoroughly investigates the
    use of modern deep learning algorithms. The proposed taxonomy sub-categorises
    the use of deep learning approaches into supervised and unsupervised learning,
    with a particular focus on object classification, detection, segmentation and
    anomaly detection tasks. The paper further explores well-established X-ray datasets
    and provides a performance benchmark. Based on the current and future trends in
    deep learning, the paper finally presents a discussion and future directions for
    X-ray security imagery.
  prefs: []
  type: TYPE_NORMAL
- en: 'keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Review , Survey , X-ray Security Imaging , Deep Learning^†^†journal: Pattern
    Recognition\newunicodechar'
  prefs: []
  type: TYPE_NORMAL
- en: fifi \newunicodecharffff
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: X-ray security screening is one of the most widely used security measures for
    maintaining airport and transport security, whereby manual screening by human
    operators plays the vital role. Although experience and knowledge are the key
    factors for confident detection, external variables such as emotional exhaustion
    and job satisfaction adversely impact the manual screening [[1](#bib.bib1)].
  prefs: []
  type: TYPE_NORMAL
- en: Cluttered nature of X-ray bags also negatively affects the decision time and
    detection performance of the human operators [[2](#bib.bib2), [3](#bib.bib3)].
    For instance, the threat detection performance of human screeners significantly
    reduces when laptops are left inside the bags. This is due to the compact structure
    of laptops, limiting detection capability of the screeners [[4](#bib.bib4)]. All
    these issues necessitate the use of automated object detection algorithms within
    X-ray security imaging, which would maintain the alertness and improve detection
    and response time of human operators [[5](#bib.bib5)].
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/8a32bfa1b8a0ef265a1ecc4d59eefbf2.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Statistics for the recent papers published in X-ray security imaging.
    (a) Distribution of machine learning vs. deep learning papers over the years.
    (b) Distribution of the papers based on the task'
  prefs: []
  type: TYPE_NORMAL
- en: Despite the surge of interest in X-ray screening [[6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10)], automated computer-aided screening
    is understudied, particularly due to the lack of data, and the need for advanced
    learning algorithms. Previous work in the field have focused more on conventional
    image analysis [[11](#bib.bib11), [12](#bib.bib12), [13](#bib.bib13)] and machine
    learning methods, spanning classification [[14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)], detection [[17](#bib.bib17), [18](#bib.bib18)] and segmentation
    [[19](#bib.bib19), [20](#bib.bib20)] tasks. Notable surveys within the field [[21](#bib.bib21),
    [22](#bib.bib22)] thoroughly review these approaches and categorize the existing
    literature within image processing and understanding.
  prefs: []
  type: TYPE_NORMAL
- en: More recently, on the other hand, deep-learning-based algorithms have been adopted
    in X-ray security imaging [[23](#bib.bib23), [24](#bib.bib24), [25](#bib.bib25)],
    especially after convolutional neural networks (CNN) significantly outperform
    the conventional machine learning methods. To this end, as of 2017, the use of
    deep learning algorithms is in the official US Government technology road-map
    for use across the US; and as of 2019/20, several early commercial systems have
    emerged from the academic research [[26](#bib.bib26)].
  prefs: []
  type: TYPE_NORMAL
- en: <svg   height="1" overflow="visible"
    version="1.1" width="1"><g transform="translate(0,1) matrix(1 0 0 -1 0 0)" fill="#000000"
    stroke="#000000" stroke-width="0.4pt"><foreignobject width="-15.37" height="0"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">\Tree[27](#bib.bib27),
    [11](#bib.bib11), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31)[32](#bib.bib32),
    [33](#bib.bib33), [34](#bib.bib34)[35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37),
    [38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42),
    [43](#bib.bib43), [44](#bib.bib44), [42](#bib.bib42), [43](#bib.bib43), [18](#bib.bib18),
    [14](#bib.bib14), [45](#bib.bib45), [46](#bib.bib46), [14](#bib.bib14), [15](#bib.bib15),
    [16](#bib.bib16)[47](#bib.bib47), [41](#bib.bib41), [48](#bib.bib48), [49](#bib.bib49),
    [50](#bib.bib50), [51](#bib.bib51), [52](#bib.bib52), [53](#bib.bib53), [54](#bib.bib54),
    [55](#bib.bib55), [24](#bib.bib24), [56](#bib.bib56)[57](#bib.bib57), [18](#bib.bib18)[17](#bib.bib17),
    [18](#bib.bib18)[58](#bib.bib58), [59](#bib.bib59), [60](#bib.bib60), [61](#bib.bib61),
    [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)[23](#bib.bib23), [62](#bib.bib62),
    [25](#bib.bib25), [63](#bib.bib63), [64](#bib.bib64), [65](#bib.bib65), [66](#bib.bib66),
    [67](#bib.bib67), [68](#bib.bib68), [69](#bib.bib69), [70](#bib.bib70), [71](#bib.bib71)[72](#bib.bib72),
    [73](#bib.bib73), [74](#bib.bib74)[73](#bib.bib73), [75](#bib.bib75), [70](#bib.bib70),
    [76](#bib.bib76), [74](#bib.bib74), [77](#bib.bib77), [78](#bib.bib78)[79](#bib.bib79),
    [80](#bib.bib80), [81](#bib.bib81)[82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84)[85](#bib.bib85),
    [86](#bib.bib86), [87](#bib.bib87), [88](#bib.bib88), [89](#bib.bib89), [90](#bib.bib90),
    [91](#bib.bib91)</foreignobject></g></svg>
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 2: A Taxonomy of the X-ray security imaging papers.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Following this trend change, this literature survey reviews the published work
    within various computer vision tasks (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")B) in X-ray security screening, with a particular focus
    on the deep learning applications. We use the following keywords and operators
    in Google Scholar search to search the relevant papers: ‘((x-ray security) OR
    (x-ray baggage) OR (x-ray luggage)) AND ((detection) OR classification OR segmentation)’.
    We also conduct a backward search based on the citations and related papers, and
    overall identify approximately 213 relevant articles, of which 36 employ deep-learning-based
    algorithms (Figure [1](#S1.F1 "Figure 1 ‣ 1 Introduction ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")A).
    Based on the scope of the work, we finally reduce the number of relevant papers
    to 130\. The main contributions of this work, therefore, are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*taxonomy* — an extensive overview of classical machine learning and contemporary
    deep learning within X-ray security imaging (Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")).'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*datasets* — an overview of the large datasets used to train deep learning
    approaches within the field.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '3.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*open problems* — discussion of the open problems, current challenges, and
    future directions based on the current trends within computer vision.'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'The rest of the paper is as follows: Section [2](#S2 "2 Background: X-ray Imaging
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") provides a brief background regarding the principle of
    X-ray imaging. Sections [3](#S3 "3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") and [4](#S4
    "4 Evaluation Criteria ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") introduce datasets and evaluation
    criterion used to measure the performance of the methods. Sections [5](#S5 "5
    Conventional Image Analysis ‣ Towards Automatic Threat Detection: A Survey of
    Advances of Deep Learning within X-ray Security Imaging") and [6](#S6 "6 Machine
    Learning Approaches in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") explore
    conventional image analysis and machine learning algorithms. Section [7](#S7 "7
    Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") reviews
    the applications of the deep learning algorithms within X-ray security imaging.
    Section [8](#S8 "8 Discussion and Future Directions ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    discusses the open problems, current challenges and Section [9](#S9 "9 Conclusion
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") finally concludes the paper.'
  prefs: []
  type: TYPE_NORMAL
- en: '2 Background: X-ray Imaging'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/5e6db09bc682a6def379ef36fe07f668.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: High-level overview of X-ray imaging. RGB and X-ray images are from
    COMPASS-XP dataset [[92](#bib.bib92)].'
  prefs: []
  type: TYPE_NORMAL
- en: 'As depicted in Figure [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣
    Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging")A, the main principle of X-ray imaging is that an X-ray
    tube generates beams that penetrate the scanned object. Depending on its material
    density, the object attenuates the X-ray signal. This attenuation is formulated
    as $I_{x}=I_{0}e^{\mu x}$, where $I_{x}$ is the intensity at $x$ cm, $I_{0}$ is
    the initial intensity, and $\mu$ is the linear attenuation coefficient based on
    the thickness of the material. This formulation shows that material density and
    measured intensity are inversely proportional —for instance, a high-density material
    yields high attenuation and low measured intensity.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Modern X-ray machines are equipped with multiple ($m$)-energy that produces
    $m$ X-ray images via different energies (Figure [3](#S2.F3 "Figure 3 ‣ 2 Background:
    X-ray Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging")B), identifying the objects’ density and
    effective atomic number ($Z_{eff}$). The estimated intensity and $Z_{eff}$ values
    are converted to pseudo-colored images via a look-up table [[29](#bib.bib29)].
    In addition to multiple energy levels, the state-of-the art machines generates
    X-ray scans from multiple view-points to view the objects of interest from various
    angles (Figure [3](#S2.F3 "Figure 3 ‣ 2 Background: X-ray Imaging ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging")C). For more details regarding the X-ray image generation process, the
    reader is referred to [[93](#bib.bib93)].'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section explores X-ray security imaging datasets that are widely used in
    the literature.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Durham Baggage (DB) Patch/Full Image Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This dataset comprises $15,449$ X-ray samples with associated false color materials
    mapping from dual-energy four-view Smiths 6040i machine. Originally, samples have
    the following class distributions: $494$ camera, $1,596$ ceramic knife, $3,208$
    knife, $3,192$ firearms, $1,203$ firearm parts, $2,390$ laptop and $3,366$ benign
    images. Several variants of this dataset is constructed for classification (DBP2
    and DBP6) [[23](#bib.bib23), [15](#bib.bib15), [73](#bib.bib73)] and detection
    (DBF2 and DBF6) [[72](#bib.bib72), [73](#bib.bib73)]. The dataset is well-balanced
    with wide variety of threat objects. However, being a private dataset, it’s usage
    is limited within the literature.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 GDXray
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Grima X-ray Dataset ($\mathbb{GDX}$RAY) [[94](#bib.bib94)] comprises $19,407$
    X-ray samples from five various subsets including castings ($2,727$), welds ($88$),
    baggage ($8,150$), natural images ($8,290$), and settings ($152$). The baggage
    subset is mainly used for security applications and comprises images from multiple-views.
    The limitation of this dataset is its non-complex content, which is non-ideal
    to train for real-time deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 UCL TIP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This dataset comprises $120,000$ benign images, scanned with Rapiscan^® R60\.
    Each sample is 16-bit grayscale with sizes varying between $1920\times 850$ and
    $2570\times 850$. The train and test split of the dataset is $110000$ : $10000$,
    where the training images are $256\times 256$ patches randomly sub-sampled from
    $110,000$ images and the test set comprises $5000$ benign and $5000$ threat images.
    The threat images are synthetically generated via the TIP algorithm proposed in
    [[33](#bib.bib33)], where, depending on the application, small metallic threats
    (SMT) or car images are projected into the benign samples. With several variants,
    this dataset is used in several studies such as [[87](#bib.bib87), [88](#bib.bib88),
    [63](#bib.bib63), [65](#bib.bib65), [25](#bib.bib25), [64](#bib.bib64), [66](#bib.bib66)].'
  prefs: []
  type: TYPE_NORMAL
- en: 3.4 SIXray
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With unknown machine specification, this dataset is acquired from subway stations
    and released by [[71](#bib.bib71)], SIXray dataset comprises $1,059,231$ X-ray
    images, $8929$ of which are manually annotated for $6$ different classes: gun,
    knife, wrench, pliers, scissors, hammer, and background. The dataset consists
    of objects with a wide variety in scale, viewpoint and mostly overlapping, making
    it a suitable dataset for real-time classification, detection and segmentation
    applications.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.5 Durham Baggage Anomaly Dataset –DBA
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This in-house dataset comprises $230,275$ dual energy X-ray security image patches
    extracted via a $64\times 64$ overlapping sliding window approach. The dataset
    contains 3 abnormal sub-classes —knife ($63,496$), gun ($45,855$) and gun component
    ($13,452$). Normal class comprises $107,472$ benign X-ray patches, split via $80:20$
    train-test ratio. DBA dataset is used in [[89](#bib.bib89)] and [[90](#bib.bib90)]
    for unsupervised anomaly detection. Similar to DB dataset varians, this dataset
    is not publicly available, limiting its use in the literature.
  prefs: []
  type: TYPE_NORMAL
- en: 3.6 Full firearm vs Operational Benign –FFOB
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: As presented in [[73](#bib.bib73), [89](#bib.bib89), [90](#bib.bib90), [91](#bib.bib91)],
    this dataset contains samples from the UK government evaluation dataset [[95](#bib.bib95)],
    comprising both expertly concealed firearm (threat) items and operational benign
    (non-threat) imagery from commercial X-ray security screening operations (baggage/parcels).
    Denoted as FFOB, this dataset comprises $4,680$ firearm full-weapons as full abnormal
    and $67,672$ operational benign as full normal images, respectively. The main
    drawback of this dataset is its restricted access.
  prefs: []
  type: TYPE_NORMAL
- en: 3.7 Compass - XP Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This dataset [[92](#bib.bib92)] is collected using $501$ objects from $369$
    object classes that are a subset of ImageNet classes. The dataset includes $1901$
    image pairs such that each pair has an X-ray image scanned with Gilardoni FEP
    ME 536 and its photographic version is taken with a Sony DSC-W800 digital camera.
    Besides, each X-ray image has its low-energy, high-energy, material density, grey-scale
    (the combination of low and high energy) and pseudo-coloured RGB versions. This
    dataset is well-suited to X-ray imaging research; however, its non-cluttered nature
    limits its use for real-time applications.
  prefs: []
  type: TYPE_NORMAL
- en: 3.8 OPIXray Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: OPIXray dataset [[96](#bib.bib96)] is an airport inspection dataset manually
    annotated by the security personnel. The dataset comprises 8885 X-ray images (7019
    training, 1776 testing) from five sharp objects, including folding knife (1,993),
    straight knife (1,044), scissor (1,863), utility knife (1,978) and multi-tool
    knife (2,042).
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Domain | Task | # Samples | Classes | Performance | Reference |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| DBP2 | Baggage | Classification | 19,938 | firearm, background | ACC: 0.994
    | [[23](#bib.bib23), [73](#bib.bib73)] |'
  prefs: []
  type: TYPE_TB
- en: '| DBP6 | Baggage | Classification | 10,137 | firearm, firearm parts, camera,
    | ACC: 0.937 | [[23](#bib.bib23), [73](#bib.bib73)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | knife, ceramic knife, laptop |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| UCL TIP | Cargo | Classification | 120,000 | small metallic threat (SMT),
    car | ACC: 0.970 | [[65](#bib.bib65), [87](#bib.bib87), [67](#bib.bib67), [66](#bib.bib66),
    [88](#bib.bib88), [64](#bib.bib64)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Detection |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Anomaly Detection |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| GDXRay | Baggage | Classification | 19,407 | gun, shuriken, razor blade |
    ACC: 0.963 | [[24](#bib.bib24), [97](#bib.bib97), [70](#bib.bib70), [98](#bib.bib98)]
    |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Detection |  |  |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| DBF2 | Baggage | Detection | 15,449 | firearm, background | mAP: 0.974 |
    [[72](#bib.bib72), [73](#bib.bib73)] |'
  prefs: []
  type: TYPE_TB
- en: '| DBF6 | Baggage | Detection | 15,449 | firearm, firearm parts, camera, | mAP:
    0.885 | [[72](#bib.bib72), [73](#bib.bib73)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | knife, ceramic knife, laptop |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| PBOD | Baggage | Classification | 9,520 | Explosives | AUC: 0.950 | [[99](#bib.bib99)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| MV-Xray | Baggage | Detection | 16,724 | Glass Bottle, TIP Weapon, Real Weapon
    | mAP: 0.956 | [[79](#bib.bib79)] |'
  prefs: []
  type: TYPE_TB
- en: '| SASC | Baggage | Detection | 3,250 | Scissors, Aerosols | mAP: 0.945 | [[75](#bib.bib75)]
    |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao *et al.* | Baggage | Classification | 1,600 | wrench, pliers, blade,
    lighter, | ACC: 0.992 | [[69](#bib.bib69)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | knife, screwdriver, hammer |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| Smiths-Duke | Baggage | Detection | 16,312 | gun, pocket knife, mixed sharp
    | mAP: 0.938 | [[100](#bib.bib100)] |'
  prefs: []
  type: TYPE_TB
- en: '| SIXray | Baggage | Detection | 1,059,231 | gun, knife, wrench, pliers, |
    mAP: 0.439 | [[71](#bib.bib71)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | scissors, hammer, background |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| UBA | Baggage | Anomaly Detection | 230,275 | gun, gun part, knife | AUC:
    0.940 | [[89](#bib.bib89), [90](#bib.bib90)] |'
  prefs: []
  type: TYPE_TB
- en: '| FFOB | Baggage | Anomaly Detection | 72,352 | full-weapon, benign | ACC:
    0.998 | [[89](#bib.bib89), [90](#bib.bib90)] |'
  prefs: []
  type: TYPE_TB
- en: '| Yang *et al.* | Baggage | Classification | 2,000 | wrench, fork, handgun,
    power bank, | ACC: 0.991 | [[101](#bib.bib101)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | lighter, pliers, knife, liquid, umbrella, screwdriver |  |  |'
  prefs: []
  type: TYPE_TB
- en: '| OPIXray | Baggage | Detection | 8,885 | Folding Knife, Straight Knife, |
    mAP: 0.753 | [[96](#bib.bib96)] |'
  prefs: []
  type: TYPE_TB
- en: '|  |  |  |  | lighter, Scissor, Utility Knife, Multi-tool Knife |  |  |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Datasets used in deep learning applications within X-ray security
    imaging'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Evaluation Criteria
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Before reviewing the papers, it is essential to introduce the various performance
    metrics used in the field. All of the metrics shown here are computed based on
    true positives ($TP$), false positives ($FP$), true negatives ($TN$) and false
    negatives ($FN$).
  prefs: []
  type: TYPE_NORMAL
- en: Accuracy
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: (ACC) is defined as the number of correctly predicted samples over the the total
    number of predictions, which is mathematically shown as $ACC=(TP+TN)/(TP+TN+FP+FN)$.
  prefs: []
  type: TYPE_NORMAL
- en: True Positive Rate
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '(TPR) is the proportion of correctly predicted positive samples: $TPR=TP/(TP+FN)$'
  prefs: []
  type: TYPE_NORMAL
- en: False Positive Rate
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: '(FPR) is calculated as the ratio of the negative samples predicted as positive:
    $FPR=FP/(FP+TN)$.'
  prefs: []
  type: TYPE_NORMAL
- en: Mean Average Precision
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: (mAP) is defined as the mean of the average precision, a metric evaluated by
    the area under the precision and recall curve, where precision is $TP/(TP+FP)$,
    and recall is $TP/(FN+TP)$.
  prefs: []
  type: TYPE_NORMAL
- en: Area Under the Curve
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: (AUC) is the area under the curve of the receiver operating characteristics
    (ROC), plotted by the true positive rates and false positives rates.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [1](#S3.T1 "Table 1 ‣ 3.8 OPIXray Dataset ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") shows the benchmark statistics based on the datasets and evaluation
    criteria discussed in Sections [3](#S3 "3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    and [4](#S4 "4 Evaluation Criteria ‣ Towards Automatic Threat Detection: A Survey
    of Advances of Deep Learning within X-ray Security Imaging"). The best performing
    models will be explained in the following sections.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Conventional Image Analysis
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section explores the conventional image analysis techniques that perform
    image enhancement and threat image projection.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Image Enhancement
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Preprocessing the input data plays a substantial role to yield higher-quality
    images that increase the readability by both screener and computer. Common approach
    in literature is to [[11](#bib.bib11)] fuse low and high energy X-ray images and
    apply background subtraction for noise reduction, followed by either manual [[27](#bib.bib27)]
    or adaptive [[28](#bib.bib28)] threshold selection. Pseudo-colouring [[11](#bib.bib11),
    [29](#bib.bib29), [102](#bib.bib102)] is another enhancement technique that colours
    grey scale X-ray images, improving the detection performance and alertness level
    of the operators.
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Threat Image Projection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Threat image projection (TIP) [[32](#bib.bib32)] is another method that could
    be categorised within conventional image analysis. TIP is used to generate a synthetic
    dataset to either train human screeners [[103](#bib.bib103)] or machine/deep learning
    models. A common TIP approach is to project a binary threat mask onto a benign
    input X-ray image via multiplication, yielding an output X-ray image with the
    threat item. Application of affine [[33](#bib.bib33)] or logarithmic [[34](#bib.bib34)]
    transformations adds various threat projections onto the benign image. Empirical
    studies show that the use of TIP improves the overall detection performance of
    models [[33](#bib.bib33), [34](#bib.bib34), [104](#bib.bib104)].
  prefs: []
  type: TYPE_NORMAL
- en: 6 Machine Learning Approaches in X-ray Security Imaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section explores the applications of conventional machine learning approaches
    in X-ray security imaging. The literature is reviewed based on three tasks: classification,
    detection, and segmentation. For an alternative perspective for this section,
    the reader could refer to the related reviews of Mery [[93](#bib.bib93)] and Rogers
    *et al.*[[22](#bib.bib22)].'
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Object Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Prior to the dominance of the deep learning within the field, the bag of visual
    words (BoVW) approach was prevalent. A common approach is to (i) perform feature
    extraction via detector/descriptors, (ii) cluster the features via k-means [[105](#bib.bib105),
    [38](#bib.bib38)] and (iii) classify RF[[106](#bib.bib106)], SVM [[107](#bib.bib107)]
    or sparse-representation [[38](#bib.bib38), [49](#bib.bib49), [39](#bib.bib39),
    [43](#bib.bib43), [42](#bib.bib42), [45](#bib.bib45), [46](#bib.bib46), [16](#bib.bib16),
    [15](#bib.bib15)].
  prefs: []
  type: TYPE_NORMAL
- en: 'Despite the BoVW dominance, other computer vision/machine learning techniques
    have also been studied for X-ray object classification task. Mery *et al.*[[49](#bib.bib49)]
    utilize structure estimation and segmentation together with a general tracking
    algorithm to detect X-ray objects. Similar works [[41](#bib.bib41), [54](#bib.bib54),
    [55](#bib.bib55), [62](#bib.bib62), [24](#bib.bib24), [108](#bib.bib108)] exhaustively
    evaluate various computer vision techniques, with a specific focus on k-NN based
    sparse representation, achieving comparable accuracy to deep models on [GDXray](#S3.SS2
    "3.2 GDXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") ($94.7\%$ vs. $96.3\%$).'
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Object Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section reviews the conventional X-ray object detection models presented
    in the literature. Being a challenging task, where the bounding box coordinates
    and class labels are to be predicted simultaneously, conventional object detection
    algorithms in the literature is relatively limited in the field.
  prefs: []
  type: TYPE_NORMAL
- en: 'Similar to classification methods explored in Section [6.1](#S6.SS1 "6.1 Object
    Classification ‣ 6 Machine Learning Approaches in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging"), conventional detection algorithms also primarily employ BoVW
    approach. Evaluation works of [[57](#bib.bib57), [40](#bib.bib40), [18](#bib.bib18)]
    exhaustively investigate the use of BoVW for the X-ray object detection. Evaluating
    various feature descriptors with SVM classifier [[107](#bib.bib107)] shows that
    (i) sparse intensity domain image descriptor (SPIN) [[109](#bib.bib109)] achieves
    the highest detection performance (mAP: $46.1\%$).'
  prefs: []
  type: TYPE_NORMAL
- en: Unlike classification, here the models also utilise multiple-view imagery, which
    generally improves the performance when rotation and superimposition hinder the
    viewability of the objects from one view [[110](#bib.bib110)]. Despite its computational
    complexity, multi-view imaging help human operators and machines to improve the
    detection performance [[111](#bib.bib111), [17](#bib.bib17), [18](#bib.bib18)].
    A general multi-staged approach proposed in the works of [[112](#bib.bib112),
    [50](#bib.bib50), [52](#bib.bib52), [48](#bib.bib48)] initially performs feature
    extraction via feature descriptors and k-NN classifier [[113](#bib.bib113)]. Features
    matched from different views are classified by the k-NN classifier [[113](#bib.bib113)]
    ($95.7\%$ precision).
  prefs: []
  type: TYPE_NORMAL
- en: 6.3 Object Segmentation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explores various segmentation techniques presented in the literature.
    Early work in the field [[58](#bib.bib58), [59](#bib.bib59)] investigates simplistic
    pixel-based segmentation with a fixed absolute threshold and region grouping.
    Subsequent work, on the other hand, focuses more on pre-segmentation via nearest
    neighbour, overlapping background removal and final classification [[60](#bib.bib60),
    [61](#bib.bib61), [13](#bib.bib13), [19](#bib.bib19), [20](#bib.bib20)].
  prefs: []
  type: TYPE_NORMAL
- en: Another approach is to utilize graph-based algorithms for the segmentation.
    Early work concentrates on fuzzy similarity distance between attribute relational
    graphs [[114](#bib.bib114), [61](#bib.bib61)], while more recent investigates
    spectral clustering and variational image segmentation [[115](#bib.bib115)].
  prefs: []
  type: TYPE_NORMAL
- en: Despite the promising detection performance reported, these techniques are generally
    experimented on a small datasets, limiting their scalability for real-time applications.
  prefs: []
  type: TYPE_NORMAL
- en: 7 Deep Learning in X-ray Security Imaging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This section reviews the X-ray security applications utilising deep learning
    algorithms. As shown in Figure [2](#S1.F2 "Figure 2 ‣ 1 Introduction ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging") and Table [2](#S7.T2 "Table 2 ‣ 7.2 Unsupervised Approaches
    ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging"), we categorise
    the algorithms as supervised (classification, detection and segmentation) and
    unsupervised (anomaly detection) approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: 7.1 Supervised Approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Supervised approaches are grouped within classification, detection and segmentation
    tasks, where the models utilise the ground-truth global, bounding-box and pixel-wise
    labels, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1f6326cbbd18179ac52dd47cece3b7d1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: An input X-ray image, and the outputs depending on the deep learning
    task, (a) classification via ResNet-50 [[116](#bib.bib116)], (b) detection with
    YOLOv3 [[117](#bib.bib117)] and segmentation via Mask RCNN [[118](#bib.bib118)]'
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.1 Classification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The study of [[23](#bib.bib23)] is one of the first research applying CNN to
    X-ray security imagery as a classification task, where the model predicts the
    global image label (Figure [4](#S7.F4 "Figure 4 ‣ 7.1 Supervised Approaches ‣
    7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging")B). The authors
    examine the use of CNN via transfer learning to evaluate to what extent transfer
    learning helps classify X-ray objects within the problem domain, where the availability
    of the datasets is somewhat limited. Freezing AlexNet weights layer by layer on
    a two-class (gun vs. no-gun) X-ray classification problem shows that CNN significantly
    outperforms the BoVW approach (SIFT+SURF), trained with SVM or RF, even when the
    layers of the network are all frozen. Another set of experimentation analyses
    the use of CNN within a challenging 6-class classification problem, whose results
    show a great promise of the use of CNN in the field.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar work [[25](#bib.bib25)] compares the use of deep learning against
    the conventional machine learning to classify non-empty cargo containers with
    cars or SMT. A multi-stage approach first classifies cargo containers as empty
    vs. non-empty. The second stage is the classification of cars from the containers
    classified as non-empty, achieved via oBIF + RF. By using [UCL TIP](#S3.SS3 "3.3
    UCL TIP ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") dataset, the authors evaluate
    the performance of 9 and 19-layer networks [[63](#bib.bib63)] that are similar
    to [[119](#bib.bib119)] and [[120](#bib.bib120)], and show that even the worst-performing
    CNN outperforms the conventional machine learning approach (oBIF + RF).'
  prefs: []
  type: TYPE_NORMAL
- en: 'A follow-up work [[64](#bib.bib64)] further investigates the detection of cars
    from X-ray cargo images. A sliding window splits [UCL TIP](#S3.SS3 "3.3 UCL TIP
    ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging") images into patches. Authors then explore
    various features including intensity, oBIF [[121](#bib.bib121)], Pyramid of Histogram
    of Visual Words (PHOW) [[122](#bib.bib122)] and CNN features. Training these features
    on SVM [[107](#bib.bib107)], RF [[106](#bib.bib106)], and soft-max (CNN) shows
    that a RF classifier trained on the VGG-18 [[120](#bib.bib120)] features extracted
    from log-transform images achieves the highest performance (FPR: $0.22$%).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Additional work by Jaccard *et al.*[[65](#bib.bib65)] evaluate the impact of
    input types on CNN performance by training single-channel raw image and dual-channel
    data that contains the raw image and its log-transformed image on VGG [[120](#bib.bib120)]
    variants. The quantitive analysis demonstrates that VGG-19 model trained from
    scratch by using dual-channel raw and log-transformed images outperforms the other
    variants (AUC: $97\%$, FPR: $6\%$).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Rogers *et al.*[[66](#bib.bib66)] explore the use of dual-energy X-ray images
    for automated threat detection. Authors investigate varying transformations applied
    to high-energy ($H$) and low-energy($L$) X-ray images captured via the dual-energy
    X-ray machine. Using [UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") dataset, 640,000 image patches are generated via a $256\times 256$ sliding-window.
    Training this dataset with a fixed VGG-19 network [[120](#bib.bib120)] with varying
    input channels, including single-channel ($H$), dual-channel($\{H,-\log{H}\}$,
    $\{-\log{H},-\log{L}\}$) and four-channels $(\{-\log{L},L,H,\allowbreak-\log{H}\})$
    shows that dual and four-channels always achieves superior detection performance
    compared to their single-channel variants (ACC: $95\%$–dual vs $90\%$–single).'
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by the limited availability of X-ray datasets, a three-stage algorithm
    by Zhao *et al.*[[69](#bib.bib69)] initially classifies and labels the input X-ray
    dataset via the angle information of the foreground objects extracted from the
    input image. The second stage generates new X-ray objects via an adversarial network
    similar to [[123](#bib.bib123)]. Additional use of [[124](#bib.bib124)] improves
    the quality of the generated images. Finally, a small classification network confirms
    whether the generated image belongs to the correct class. In a follow-up study,
    Yang *et al.*[[101](#bib.bib101)] further investigate the ways to improve the
    GAN training to produce better X-ray images. The quantitative evaluation shows
    that the proposed GAN approach in the paper generates visually superior prohibited
    items.
  prefs: []
  type: TYPE_NORMAL
- en: 'Miao *et al.*[[71](#bib.bib71)] introduce a model (CHR) to classify/detect
    X-ray images from [SIXray](#S3.SS4 "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging"). The model copes with class imbalance and clutter issue by extracting
    image features from three consecutive layers, where subsequent layers are upsampled
    and concatenated with the previous layers. A refinement function $g()$ removes
    the redundant information from the concatenated feature map. The objective of
    the work is to minimize the loss of the weighted sum of the classification of
    the refined mid-level features from the three consecutive layers ($\{h(\tilde{x}_{n}^{(l-1)}),\allowbreak
    h(\tilde{x}_{n}^{(l)}),h(\tilde{x}_{n}^{(l+1)})\}$). Training the model with the
    proposed loss yields $2.13\%$ mAP improvement when used with ResNet-101 on [SIXray](#S3.SS4
    "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging") ($36.01$ vs. $38.14$). A similar
    approach [[96](#bib.bib96)] introduces a plug and play module that utilises edge
    and material information to localise objects via attention mechanism.'
  prefs: []
  type: TYPE_NORMAL
- en: An evaluation work [[99](#bib.bib99)] investigates the use of CNN for the task
    of explosive detection. An initial stage process the input data by fixing the
    image size, cropping the irrelevant background object where $Z_{eff}=0$ and applying
    data augmentation transformations. Evaluation of random initialization vs. pre-training
    on VGG19[[120](#bib.bib120)], Xception [[125](#bib.bib125)], and InceptionV3 [[126](#bib.bib126)]
    networks shows that randomly initialized models achieves superior accuracy for
    binary classification task. To study the impact of intensity and Z-eff values
    on the performance, the authors train three VGG-19 networks on both intensity
    and Z-effective, the intensity only and Z-effective only. Training the model with
    only Z-eff is shown to yield the highest accuracy. The final set of experiments
    investigates localization via heatmaps and shows that pre-trained networks achieves
    superior performance since randomly initialized networks tend to overfit on small
    datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Caldwell *et al.*[[67](#bib.bib67)] study the generalisation capability of models
    trained with different datasets from various scanners. The authors create training
    and test splits from both single or multiple domains to investigate the impact
    of transferring between other modalities. Quantitative analysis reveals that transferring
    information is challenging due to unknown parameters of the scanners and generalisability
    of CNN to the unseen target dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.2 Detection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: This section explores CNN-based object detection algorithms by a categorisation
    of single and multi-view object detection.
  prefs: []
  type: TYPE_NORMAL
- en: Single-View Detection
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'After the success of CNN for classification, the work of [[72](#bib.bib72)]
    trains sliding-window based CNN, Faster RCNN [[127](#bib.bib127)] and R-FCN [[128](#bib.bib128)]
    models on [DBF2/6](#S3.SS1 "3.1 Durham Baggage (DB) Patch/Full Image Dataset ‣
    3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging") datasets for firearm and multi-class
    detection problems. Experiments demonstrate that Faster RCNN [[127](#bib.bib127)]
    with VGG16 [[120](#bib.bib120)] yield $88.3\%$ mAP on 6-class [DBF6](#S3.SS1 "3.1
    Durham Baggage (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") dataset, while R-FCN with ResNet-101 achieves the highest performance
    ($96.3$ mAP) on 2-class (gun vs no-gun) on [DBF2](#S3.SS1 "3.1 Durham Baggage
    (DB) Patch/Full Image Dataset ‣ 3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging") dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Sigman *et al.*[[129](#bib.bib129)] utilise an adversarial domain adaptation
    technique to match the distribution of the background of a sizeable unlabelled
    stream of commerce (SoC) dataset. By doing so helps to detect the objects in the
    SoC dataset by training a Faster RCNN [[127](#bib.bib127)] on a small labelled
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Subramani *et al.*[[77](#bib.bib77)] investigate the use of SSD [[130](#bib.bib130)]
    and RetinaNet [[131](#bib.bib131)] trained on SIXray10 dataset, achieving $60.5\%$
    and $60.9\%$, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Liu *et al.*[[75](#bib.bib75)] also performs object detection via YOLOv2 [[117](#bib.bib117)]
    to detect scissors and aeorosols on SASC dataset. Training YOLO v2 for 6000 iterations
    yield $94.5\%$ average precision and $92.6\%$ recall rates with $68$ FPS run-time
    speed.
  prefs: []
  type: TYPE_NORMAL
- en: Cui and Oztan [[76](#bib.bib76)] argue that RetinaNet [[131](#bib.bib131)] achieves
    comparable detection performance, while being considerably faster than traditional
    sliding window classification when trained with 30,000 images synthetically generated
    via TIP with $5000$ X-ray cargo containers and $544$ firearms.
  prefs: []
  type: TYPE_NORMAL
- en: 'Hassan *et al.*[[74](#bib.bib74)] proposes an object detection algorithm, whereby
    the RoI is generated via cascaded multi-scale structure tensors that extracts
    based on the variations of the orientations of the object. The extracted RoI is
    then passed into a CNN, which quantitatively and computationally outperforms RetinaNet,
    YOLOv2 and F-RCNN on [GDXray](#S3.SS2 "3.2 GDXray ‣ 3 Datasets ‣ Towards Automatic
    Threat Detection: A Survey of Advances of Deep Learning within X-ray Security
    Imaging") and [SIXray](#S3.SS4 "3.4 SIXray ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")
    datasets. A similar approach in [[78](#bib.bib78), [132](#bib.bib132)] produces
    contour-based object proposals, which are subsequently forward-passed into a CNN,
    achieving $96\%$ mAP on SIXray10 dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Motivated by the lack of annotated X-ray datasets, Xu *et al.*[[70](#bib.bib70)],
    make use of attention mechanisms for the localization of threat materials. The
    first stage forward-passes an input and finds the corresponding class probability.
    The back-propagation step identifies the interconnected neurons activated during
    the decision of the output class. Activations from the first convolutional layer
    generate a heatmap. The final stage refines the activation map by normalizing
    the layers with the activations of the previous layer. Comparison against the
    traditional deconvolution method (mAP: $34.3\%$) shows that the proposed method
    achieves superior detection ($56.6\%$) without requiring bounding box information.'
  prefs: []
  type: TYPE_NORMAL
- en: Similar to [[67](#bib.bib67)], generalisation capability of CNN is studied by
    Gaus *et al.*[[82](#bib.bib82)] by training/validating CNN on different datasets
    (DBF3 ($88\%$ mAP) $\rightarrow$ SIXray ($85\%$ mAP)).
  prefs: []
  type: TYPE_NORMAL
- en: Multi-View Detection
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: There are number of papers utilising the multi-view X-ray imagery to improve
    the detection performance of their models. An evaluation work [[100](#bib.bib100)]
    explores the performance of F-RCNN, R-FCN [[128](#bib.bib128)] and SSD [[130](#bib.bib130)]
    within single/multi-view X-ray imagery. Utilizing OR-gate detection by merging
    object detection outputs from individual views shows that multi-view outperforms
    that of single-view ($0.938$ vs. $0.798$ when trained with R-FCN and ResNet-101).
    A two-stage approach by Liu *et al.*[[133](#bib.bib133)] first extracts foreground
    objects and subsequently utilises F-RCNN to detect $32,253$ subway X-ray images,
    with an mAP of $77\%$ for 6 object classes.
  prefs: []
  type: TYPE_NORMAL
- en: A similar study [[80](#bib.bib80)] explores SSD and F-RCNN by training on a
    dataset containing 4 threat classes, each of which comprises approximately $3,400$
    images. F-RCNN with Inception ResNet v2 backbone yields the highest mAP ($92.2$
    and $97.7$ on single and multi-view images, respectively). Another work [[79](#bib.bib79)]
    utilize multi-view by modifying F-RCNN. A multi-view pooling layer constructs
    3D feature 2D extracted from the convolutional layers. 3D region proposal network
    generates the RoI. Classification and bounding box prediction is performed after
    3D RoI pooling layer. Experiments show that multi-view yields an improvement compared
    to single-view imagery ($95.56\%$ vs. $91.23\%$).
  prefs: []
  type: TYPE_NORMAL
- en: 'Isaac-Medina *et al.*[[81](#bib.bib81)] train a YOLOv3 [[117](#bib.bib117)]
    detector by utilising epipolar constraints of multiple-views of X-ray images,
    which outperforms the single-view by 2.2% (Figure [4](#S7.F4 "Figure 4 ‣ 7.1 Supervised
    Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging")C).'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, these results suggest that the use of multiple-view imagery aids improving
    the detection performance of the deep learning models.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1.3 Segmentation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Due to the scarcity of datasets with pixel-level annotation, the task of segmentation
    is understudied within the field. One of the published work [[83](#bib.bib83)]
    addresses segmentation and anomaly detection tasks together, whereby a dual-CNN
    pipeline initially segments RoI via Mask RCNN [[118](#bib.bib118)] and classifies
    the regions as benign/abnormal via ResNet-18 [[116](#bib.bib116)], achieving $97.6\%$
    segmentation mAP and $66.0\%$ anomaly detection accuracy (Figure [4](#S7.F4 "Figure
    4 ‣ 7.1 Supervised Approaches ‣ 7 Deep Learning in X-ray Security Imaging ‣ Towards
    Automatic Threat Detection: A Survey of Advances of Deep Learning within X-ray
    Security Imaging")D). Another work [[134](#bib.bib134)] proposes three-stage approach,
    whereby (i) object-level segmentation is achieved by the use of Mask RCNN [[118](#bib.bib118)],
    (ii) sub-component regions are segmented via super-pixel segmentation and (iii)
    final object classification is performed via fine-grained CNN classification,
    which overall yields $97.91\%$ anomaly detection accuracy on $7,878$ electronic
    items. An *et al.*[[135](#bib.bib135)] propose a segmentation model that utilises
    dual attention mechanism within an encoder-decoder segmentation network. The former
    attention module classifies the RoI, while the latter localises the object. Experiments
    on PASCAL alike structured X-ray dataset containing $7,532$ augmented images from
    7-classes yield $99.3$ accuracy and $68.3$ mean intersection over union (mIoU).'
  prefs: []
  type: TYPE_NORMAL
- en: Hassan *et al.*[[84](#bib.bib84)] propose a single-stage instance segmentation
    algorithm. The method initially extracts transitional patterns via trainable structure
    tensors, which are subsequently passed to an encoder-decoder to construct the
    binary segmentation masks. mAP evaluation on GDXray ($96.7$), SIXray ($96.16$),
    OPIXray($75.32$) and COMPASS XP ($58.4$) datasets show that the model achieves
    the state-of-the-art instance segmentation performance on benchmarks.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2 Unsupervised Approaches
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This section explores unsupervised deep learning models, where the proposed
    algorithms mainly investigate the anomaly detection task. Human operators tend
    to perform better detection when focusing on benign objects rather than threat
    items. Besides, the knowledge of every-day benign objects leads to a much better
    detection performance [[136](#bib.bib136)]. The same concept is applied in anomaly
    detection, where the model is only trained with normal samples, and tested on
    normal/abnormal examples.
  prefs: []
  type: TYPE_NORMAL
- en: An anomaly detection approach [[86](#bib.bib86)] employs sparse feed-forward
    autoencoders in an unsupervised manner to learn the feature encoding of normal
    and abnormal data. An SVM [[107](#bib.bib107)] then classifies the images either
    anomalous or benign. Validation on MNIST [[137](#bib.bib137)] and freight container
    dataset (empty vs non-empty) shows that hidden layer representation extracted
    from the autoencoder, is significant for the detection of abnormalities in the
    images. When fused with the raw-input and residual error, features encoding from
    the hidden layers yield even better detection performance.
  prefs: []
  type: TYPE_NORMAL
- en: 'A follow-up work utilizes intensity, log-intensity and VGG-19 [[120](#bib.bib120)]
    features extracted from patches from [UCL TIP](#S3.SS3 "3.3 UCL TIP ‣ 3 Datasets
    ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") dataset and train normal images via forest of random
    split trees anomaly detector [[138](#bib.bib138)]. Testing the model on normal
    + abnormal data yields $64$% AUC.'
  prefs: []
  type: TYPE_NORMAL
- en: 'A similar study [[89](#bib.bib89)], in which image and latent vector spaces
    are optimized for anomaly detection, utilizes an adversarial network such that
    the generator comprises encoder-decoder-encoder sub-networks. The objective of
    the model is to minimize the distance between both real/generated images and their
    latent representations jointly, which overall outperforms the previous state-of-the-art
    both statistically and computationally ([UBA](#S3.SS5 "3.5 Durham Baggage Anomaly
    Dataset –DBA ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances
    of Deep Learning within X-ray Security Imaging"): $64.3\%$, [FFOB](#S3.SS6 "3.6
    Full firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat
    Detection: A Survey of Advances of Deep Learning within X-ray Security Imaging"):
    $88.2\%$ – AUC). A follow-up work [[90](#bib.bib90)] improves the performance
    of [[89](#bib.bib89)] further by (i) utilizing skip-connections in the generator
    network to cope with higher resolution images, and (ii) learning the latent representations
    within the discriminator network ([UBA](#S3.SS5 "3.5 Durham Baggage Anomaly Dataset
    –DBA ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of
    Deep Learning within X-ray Security Imaging"): $94.0\%$, [FFOB](#S3.SS6 "3.6 Full
    firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat Detection:
    A Survey of Advances of Deep Learning within X-ray Security Imaging"): $90.3\%$
    – AUC).'
  prefs: []
  type: TYPE_NORMAL
- en: '| Reference | Domain | Problem | Method |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Akçay *et al.*[[23](#bib.bib23)] | Baggage | Object Classification | CNN
    with transfer learning |'
  prefs: []
  type: TYPE_TB
- en: '| Svec [[62](#bib.bib62)] | Baggage | Object Classification | CNN with transfer
    learning |'
  prefs: []
  type: TYPE_TB
- en: '| Andrews *et al.*[[88](#bib.bib88)] | Cargo | Anomaly Detection | Train CNN
    features with Random Split Trees |'
  prefs: []
  type: TYPE_TB
- en: '| Jaccard *et al.*[[25](#bib.bib25)] | Cargo | Object Classification | oBIF+RF
    for non-empty cargo detection, followed by CNN for car detection |'
  prefs: []
  type: TYPE_TB
- en: '| Jaccard *et al.*[[63](#bib.bib63)] | Cargo | Object Classification | CNN
    from scratch outperforms RF |'
  prefs: []
  type: TYPE_TB
- en: '| Rogers *et al.*[[66](#bib.bib66)] | Cargo | Object Classification | Evaluation
    of high and low energy x-ray imagery |'
  prefs: []
  type: TYPE_TB
- en: '| Caldwell *et al.*[[67](#bib.bib67)] | Cargo, Baggage | Object Classification
    | Transferability between domains |'
  prefs: []
  type: TYPE_TB
- en: '| Yuan and Gui [[68](#bib.bib68)] | Tera Hertz | Object Classification | Two-stage.
    Classify from RGB, then Tera-Hertz images. |'
  prefs: []
  type: TYPE_TB
- en: '| Zhao *et al.*[[69](#bib.bib69)] | Baggage | Image Generation, | Generate
    X-ray objects via GAN, and classify with CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Object Classification |  |'
  prefs: []
  type: TYPE_TB
- en: '| Yang *et al.*[[101](#bib.bib101)] | Baggage | Image Generation | Generate
    X-ray objects via GAN, and classify with CNN |'
  prefs: []
  type: TYPE_TB
- en: '|  |  | Object Classification |  |'
  prefs: []
  type: TYPE_TB
- en: '| Miao *et al.*[[71](#bib.bib71)] | Baggage | Object Classification | with
    class-balanced hierarchical refinement |'
  prefs: []
  type: TYPE_TB
- en: '| Morris *et al.*[[99](#bib.bib99)] | Baggage | Object Classification | Region-based
    detection with Z-effective |'
  prefs: []
  type: TYPE_TB
- en: '| Akçay and Breckon [[72](#bib.bib72)] | Baggage | Object Detection | Object
    Detection, Faster-RCNN is the best. |'
  prefs: []
  type: TYPE_TB
- en: '| Liang *et al.*[[100](#bib.bib100)] | Baggage | Object Detection | RFCN is
    the best. Multi-view outperforms single view. |'
  prefs: []
  type: TYPE_TB
- en: '| Liang *et al.*[[80](#bib.bib80)] | Baggage | Object Detection | Explores
    various detection algorithms, F-RCNN with Inception ResNet v2 achieves the highest
    performance |'
  prefs: []
  type: TYPE_TB
- en: '| Steitz *et al.*[[79](#bib.bib79)] | Baggage | Object Detection | F-RCNN with
    multi view pooling is superior to single view only. |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.*[[75](#bib.bib75)] | Baggage | Object Detection | YOLOv2 achieves
    real time performance. |'
  prefs: []
  type: TYPE_TB
- en: '| Xu *et al.*[[70](#bib.bib70)] | Baggage | Object Detection | Localizes the
    threat material from the X-ray images via attention mechanisms |'
  prefs: []
  type: TYPE_TB
- en: '| Islam *et al.*[[139](#bib.bib139)] | Baggage | Object Detection | track passengers
    and their belongings in airports while passing X-ray security checkpoints |'
  prefs: []
  type: TYPE_TB
- en: '| Liu *et al.*[[133](#bib.bib133)] | Baggage | Object Detection | Foreground
    object segmentation via material info, followed by a F-RCNN |'
  prefs: []
  type: TYPE_TB
- en: '| Gauss *et al.*[[82](#bib.bib82)] | Baggage | Object Detection | F-RCNN to
    investigate the tranferrability between various X-ray scanners. |'
  prefs: []
  type: TYPE_TB
- en: '| Cui and Oztan [[76](#bib.bib76)] | Baggage | Object Detection | RetinaNet
    trained on a TIP dataset achieves considerable faster detection than sliding window
    CNN. |'
  prefs: []
  type: TYPE_TB
- en: '| Hassan *et al.*[[74](#bib.bib74)] | Baggage | Object Detection | RoI are
    extracted via cascaded multiscale structure tensors, which are then classified
    via a CNN |'
  prefs: []
  type: TYPE_TB
- en: '| Bhowmik *et al.*[[104](#bib.bib104)] | Baggage | Object Detection | Explores
    the generalisation capability of the models trained on TIP datasets. |'
  prefs: []
  type: TYPE_TB
- en: '| Andrews *et al.*[[86](#bib.bib86)] | Cargo | Anomaly Detection | Fusion of
    the raw-input and residual error with feature encoding from the hidden layers.
    |'
  prefs: []
  type: TYPE_TB
- en: '| Akçay *et al.*[[89](#bib.bib89)] | Baggage | Anomaly Detection | encoder-
    decoder-encoder sub-networks. Minimize latent vector and image space. |'
  prefs: []
  type: TYPE_TB
- en: '| Akçay *et al.*[[90](#bib.bib90)] | Baggage | Anomaly Detection | Use of skip
    connections. Minimize latent vector in the discriminator network. |'
  prefs: []
  type: TYPE_TB
- en: '| Griffin *et al.*[[91](#bib.bib91)] | Baggage | Anomaly Detection | Feature
    Extraction with CNN, then train with Gaussian model. |'
  prefs: []
  type: TYPE_TB
- en: '| Gauss *et al.*[[83](#bib.bib83)] | Baggage | Object Segmentation | Mask-RCNN
    to segment RoI, and CNN classification for anomaly detection |'
  prefs: []
  type: TYPE_TB
- en: '| Bhowmik *et al.*[[134](#bib.bib134)] | Baggage | Object Segmentation | Mask-RCNN
    to segment RoI, superpixel for sub-component level analysis, fine-grained CNN
    for classification |'
  prefs: []
  type: TYPE_TB
- en: '| An *et al.*[[140](#bib.bib140)] | Baggage | Object Segmentation | Dual attention
    mechanism within an encoder decoder segmentation network. |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Overview of deep learning approaches applied within X-ray security
    imaging.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Another anomaly detection algorithm [[91](#bib.bib91)] (i) first extract the
    feature of the normal images from Inception v3 [[141](#bib.bib141)] alike network,
    (ii) subsequently trains a multivariate Gaussian model to capture the normal distribution
    of [CAST](#S3.SS6 "3.6 Full firearm vs Operational Benign –FFOB ‣ 3 Datasets ‣
    Towards Automatic Threat Detection: A Survey of Advances of Deep Learning within
    X-ray Security Imaging") dataset. Anomaly score of a test sample is based on its
    likelihood that is relative to the model, which overall yields $92.5\%$ AUC.'
  prefs: []
  type: TYPE_NORMAL
- en: 8 Discussion and Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the promising performance of the proposed approaches, there are still
    some identifiable limitations. This section discusses the challenges and future
    directions based on the weaknesses and strengths of the current approaches presented
    in this paper and the broader literature including concurrent work to that presented
    here.
  prefs: []
  type: TYPE_NORMAL
- en: Dataset
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'Although the use of transfer learning improves the performance of small X-ray
    datasets, the lack of large datasets limits contemporary deep model training.
    Relatively large datasets in the field such as [SIXray](#S3.SS4 "3.4 SIXray ‣
    3 Datasets ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep
    Learning within X-ray Security Imaging"), [FFOB](#S3.SS6 "3.6 Full firearm vs
    Operational Benign –FFOB ‣ 3 Datasets ‣ Towards Automatic Threat Detection: A
    Survey of Advances of Deep Learning within X-ray Security Imaging") are highly
    biased towards certain classes, limiting to train reliable supervised methods.
    Hence, it is essential to build large, homogeneous, realistic and publicly available
    datasets, collected either by (i) manually scanning numerous bags with different
    objects and orientations in a lab environment or (ii) generating synthetic datasets
    via contemporary algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: There are advantages and disadvantages of both methods. Although manual data
    collection enables to gather realistic samples with the flexibility to produce
    any combination, it is rather expensive, requiring tremendous human effort and
    time.
  prefs: []
  type: TYPE_NORMAL
- en: Synthetic dataset generation, on that hand, is another method, currently achieved
    by TIP [[33](#bib.bib33), [34](#bib.bib34)] or GAN [[69](#bib.bib69), [101](#bib.bib101)].
    A recent study [[104](#bib.bib104)] empirically demonstrates that using a TIP
    dataset for a detection task adversely impacts the detection performance on real
    examples. In future work, therefore, more advanced algorithms such as image translation
    or domain adaptation [[124](#bib.bib124), [142](#bib.bib142)] could be considered
    such that the model would learn to translate between benign and threat domains,
    which overall would yield superior projection/translation to TIP.
  prefs: []
  type: TYPE_NORMAL
- en: The literature has also seen another type of synthetic datasets generated by
    GAN algorithms. The limitation of current GAN datasets [[69](#bib.bib69), [101](#bib.bib101)],
    however, is that the models are currently incapable of producing full X-ray images.
    Moreover, the quality of the generated images is far from being realistic. Further
    studies, taking these issues into account, will need to be undertaken. It might
    be feasible to create more realistic X-ray images by using contemporary GAN algorithms
    [[143](#bib.bib143)].
  prefs: []
  type: TYPE_NORMAL
- en: Exploiting Multiple-View Information
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: Existing research recognizes the critical role played by multiple-view imagery,
    especially when the detection of an object from a particular viewpoint is challenging
    [[110](#bib.bib110), [79](#bib.bib79), [100](#bib.bib100)].
  prefs: []
  type: TYPE_NORMAL
- en: Few studies [[100](#bib.bib100), [79](#bib.bib79), [81](#bib.bib81)] investigate
    utilizing multiple-view integration inside/outside a CNN. Despite the incremental
    performance improvement reported, further work is required to investigate other
    possible ways to utilise multiple-view imagery better.
  prefs: []
  type: TYPE_NORMAL
- en: Domain Adaptation between X-ray Scanners
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: As pointed out in [[67](#bib.bib67), [82](#bib.bib82)], transferring models
    between different scanners could be challenging due to the unknown intrinsics
    of the scanners. Future work would utilize domain adaptation [[142](#bib.bib142)],
    where the source domain contains images from one scanner, and the target domain
    would be of another X-ray scanner. Training with even unbalanced datasets would
    learn the intrinsic, and map from one to the other.
  prefs: []
  type: TYPE_NORMAL
- en: Improving Unsupervised Anomaly Detection Approaches
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: 'The performance of the current anomaly detection algorithms presented in Section
    [7.2](#S7.SS2 "7.2 Unsupervised Approaches ‣ 7 Deep Learning in X-ray Security
    Imaging ‣ Towards Automatic Threat Detection: A Survey of Advances of Deep Learning
    within X-ray Security Imaging") is somewhat limited to be deployed for a real-world
    scenario. Therefore, more research on this topic needs to be undertaken to design
    better reconstruction techniques that thoroughly learn the characteristics of
    the normality from which the abnormality would be detected.'
  prefs: []
  type: TYPE_NORMAL
- en: Use of the Material Information
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
- en: In dual-energy X-ray systems attenuation between high and low energies yields
    a unique value for different materials, which could be utilized further for more
    accurate object classification/detection [[144](#bib.bib144), [145](#bib.bib145)].
    Even though recent research [[99](#bib.bib99), [66](#bib.bib66)] have examined
    the use of material information, the research outcome present inconsistent results.
    Hence, a further study thoroughly investigating the material information is suggested.
  prefs: []
  type: TYPE_NORMAL
- en: 9 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This paper taxonomises conventional machine and modern deep learning algorithms
    utilised within X-ray security imaging. Traditional approaches are sub-categorised
    based on computer vision tasks such as image enhancement, threat image projection,
    object segmentation, feature extraction, object classification, and detection.
    Review of the deep learning approaches includes classification, detection, segmentation
    and unsupervised anomaly detection algorithms applied within the field.
  prefs: []
  type: TYPE_NORMAL
- en: Based on this review, several conclusion can be drawn for the future directions
    of the field. Despite the recently emerging datasets, the lack of large, well-balanced
    datasets limits the design of deep learning algorithms that are generalisable
    enough to be deployed in a real-time environment. Besides, since the public datasets
    are mostly from various machines with different intrinsic, the use of domain adaptation
    techniques could improve the generalisation capability of the algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Unlike the abundance of studies in conventional machine learning, most of the
    recent approaches do not fully utilise X-ray imaging such as multiple-view geometry
    and high-low energy. Despite the existence of a few studies, there is room for
    further research. Moreover, further research in unsupervised learning could further
    utilise the existing X-ray datasets that are not labelled and not in use.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, this paper reviews the strengths and weaknesses of the current techniques,
    and provides a thorough discussion for open challenges and envisions the future
    directions of the field.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chavaillaz et al. [2019] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer,
    Expertise, Automation and Trust in X-Ray Screening of Cabin Baggage, Frontiers
    in Psychology 10 (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schwaninger et al. [2008] A. Schwaninger, A. Bolfing, T. Halbherr, S. Helman,
    A. Belyavin, L. Hay, The Impact of Image Based Factors and Training on Threat
    Detection Performance in X-ray Screening, in: International Conference on Research
    in Air Transportation, p. 8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wales et al. [2009] A. Wales, T. Halbherr, A. Schwaninger, Using speed measures
    to predict performance in x-ray luggage screening tasks, in: International Carnahan
    Conference on Security Technology, IEEE, 2009, pp. 212–215.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mendes et al. [2013] M. Mendes, A. Schwaninger, S. Michel, Can Laptops Be Left
    Inside Passenger Bags If Motion Imaging Is Used in X-ray Security Screening?,
    Frontiers in Human Neuroscience 7 (2013).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chavaillaz et al. [2018] A. Chavaillaz, A. Schwaninger, S. Michel, J. Sauer,
    Automation in Visual Inspection Tasks: X-ray Luggage Screening Supported by A
    System Of Direct, Indirect or Adaptable Cueing with Low and High System Reliability,
    Ergonomics 61 (2018) 1395–1408.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Murray and Riordan [1995] N. C. Murray, K. Riordan, Evaluation of Automatic
    Explosive Detection Systems, in: International Carnahan Conference on Security
    Technology, IEEE, 1995, pp. 175–179.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zentai [2008] G. Zentai, X-ray Imaging for Homeland Security, in: International
    Workshop on Imaging Systems and Techniques, IEEE, 2008, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wells and Bradley [2012] K. Wells, D. Bradley, A Review of X-ray Explosives
    Detection Techniques for Checked Baggage, Applied Radiation and Isotopes 70 (2012)
    1729–1746.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caygill et al. [2012] J. S. Caygill, F. Davis, S. P. J. Higson, Current Trends
    in Explosive Detection Techniques, Talanta 88 (2012) 14–29.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Singh and Singh [2003] S. Singh, M. Singh, Explosives Detection Systems (EDS)
    for Aviation Security, Signal Processing 83 (2003) 31–55.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abidi et al. [2005] B. R. Abidi, D. L. Page, M. A. Abidi, A Combinational Approach
    to the Fusion, De-noising and Enhancement of Dual-Energy X-Ray Luggage Images,
    in: Conference on Computer Vision and Pattern Recognition (CVPR) Workshops, volume 3,
    IEEE, 2005, p. 2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abidi et al. [2006] B. R. Abidi, Y. Zheng, A. V. Gribok, M. A. Abidi, Improving
    Weapon Detection In Single Energy X-ray Images Through Pseudocoloring, IEEE Transactions
    on Systems, Man and Cybernetics Part C: Applications and Reviews 36 (2006) 784–796.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lu and Conners [2006] Q. Lu, R. Conners, Using Image Processing Methods to Improve
    the Explosive Detection Accuracy, IEEE Transactions on Systems, Man and Cybernetics,
    Part C (Applications and Reviews) 36 (2006) 750–760.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Morton et al. [2015] E. Morton, T. Rogers, L. Griffin, N. Jaccard, Detection
    Of Cargo Container Loads From X-ray Images, in: International Conference on Intelligent
    Signal Processing 2015 (ISP), IET, 2015, pp. 6 .–6 .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kundegorski et al. [2016] M. Kundegorski, S. Akçay, M. Devereux, A. Mouton,
    T. Breckon, On using Feature Descriptors as Visual Words for Object Detection
    within X-ray Baggage Security Screening, in: International Conference on Imaging
    for Crime Detection and Prevention (ICDP), IET, 2016, pp. 12 (6 .)–12 (6 .).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery et al. [2016] D. Mery, E. Svec, M. Arias, Object Recognition in Baggage
    Inspection Using Adaptive Sparse Representations of X-ray Images, in: Pacific-Rim
    Symposium on Image and Video Technology (PSIVT), Springer, Cham, 2016, pp. 709–720.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Franzel et al. [2012] T. Franzel, U. Schmidt, S. Roth, Object Detection in
    Multi-view X-Ray Images, in: Pattern Recognition: Joint DAGM and OAGM Symposium,
    Springer Berlin Heidelberg, 2012, pp. 144–154.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bastan [2015] M. Bastan, Multi-view Object Detection In Dual-energy X-ray Images,
    Machine Vision and Applications 26 (2015) 1045–1060.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heitz and Chechik [2010] G. Heitz, G. Chechik, Object Separation in X-ray Image
    Sets, in: Conference on Computer Vision and Pattern Recognition (CVPR), IEEE,
    2010, pp. 2093–2100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kechagias-Stamatis et al. [2017] O. Kechagias-Stamatis, N. Aouf, C. Belloni,
    D. Nam, Automatic X-ray Image Segmentation And Clustering For Threat Detection,
    in: Target and Background Signatures III, SPIE, 2017, p. 24.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mouton and Breckon [2015] A. Mouton, T. P. Breckon, A Review of Automated Image
    Understanding within 3D Baggage Computed Tomography Security Screening, Journal
    of X-Ray Science and Technology 23 (2015) 531–555.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rogers et al. [2017] T. W. Rogers, N. Jaccard, E. J. Morton, L. D. Griffin,
    Automated X-ray Image Analysis for Cargo Security: Critical Review and Future
    Promise, Journal of X-Ray Science and Technology 25 (2017) 33–56.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akçay et al. [2016] S. Akçay, M. E. Kundegorski, M. Devereux, T. P. Breckon,
    Transfer Learning Using Convolutional Neural Networks for Object Classification
    within X-ray Baggage Security Imagery, in: International Conference on Image Processing
    (ICIP), IEEE, 2016, pp. 1057–1061.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery et al. [2017] D. Mery, E. Svec, M. Arias, V. Riffo, J. M. Saavedra, S. Banerjee,
    Modern Computer Vision Techniques for X-Ray Testing in Baggage Inspection, IEEE
    Transactions on Systems, Man, and Cybernetics: Systems 47 (2017) 682–692.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jaccard et al. [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin,
    Tackling The X-ray Cargo Inspection Challenge Using Machine Learning, in: A. Ashok,
    M. A. Neifeld, M. E. Gehm (Eds.), Anomaly Detection and Imaging with X-Rays, volume
    9847, SPIE, 2016, p. 98470N.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Departmenf of Homeland Security [2018] Departmenf of Homeland Security, Advanced
    Integrated Passenger and Baggage Screening Technologies, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abidi et al. [2004] B. R. Abidi, J. Liang, M. Mitckes, M. A. Abidi, Improving
    The Detection Of Low-density Weapons In X-ray Luggage Scans Using Image Enhancement
    And Novel Scene-decluttering Techniques, Journal of Electronic Imaging 13 (2004)
    523–539.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singh and Singh [2005] M. Singh, S. Singh, Optimizing Image Enhancement For
    Screening Luggage At Airports, in: International Conference on Computational Intelligence
    for Homeland Security and Personal Safety (CIHSPS), IEEE, 2005, pp. 131–136.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abidi et al. [2005] B. Abidi, Y. Zheng, A. Gribok, M. Abidi, Screener Evaluation
    of Pseudo-Colored Single Energy X-ray Luggage Images, in: Conference on Computer
    Vision and Pattern Recognition (CVPR) - Workshops, volume 3, IEEE, 2005, pp. 35–35.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rogers et al. [2014] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin,
    Reduction Of Wobble Artefacts In Images From Mobile Transmission X-ray Vehicle
    Scanners, in: International Conference on Imaging Systems and Techniques (IST),
    IEEE, 2014, pp. 356–360.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rogers et al. [2017] T. W. Rogers, J. Ollier, E. J. Morton, L. D. Griffin, Measuring
    And Correcting Wobble In Large-scale Transmission Radiography, Journal of X-ray
    Science and Technology 25 (2017) 57–77.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mitckes [2003] M. Mitckes, Threat Image Projection – An Overview, Technical
    Report, 2003.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rogers et al. [2016] T. W. Rogers, N. Jaccard, E. D. Protonotarios, J. Ollier,
    E. J. Morton, L. D. Griffin, Threat Image Projection (TIP) into X-ray Images of
    Cargo Containers for Training Humans and Machines, in: International Carnahan
    Conference on Security Technology (ICCST), IEEE, 2016, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery and Katsaggelos [2017] D. Mery, A. K. Katsaggelos, A Logarithmic X-Ray
    Imaging Model for Baggage Inspection: Simulation and Object Detection, in: Conference
    on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE, 2017, pp.
    251–259.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Oertel and Bock [2006] C. Oertel, P. Bock, Identification of Objects-of-Interest
    in X-Ray Images, in: Applied Imagery and Pattern Recognition Workshop (AIPR),
    IEEE, 2006, pp. 17–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gesick et al. [2009] R. Gesick, C. Saritac, C.-C. Hung, Automatic image analysis
    process for the detection of concealed weapons, in: Annual Workshop on Cyber Security
    and Information Intelligence Research Cyber Security and Information Intelligence
    Challenges and Strategies (CSIIRW), ACM Press, 2009, p. 1.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. [2009] K. Fu, C. Guest, P. Das, Segmentation of suspicious objects
    in an x-ray image using automated region filling approach, in: Signal and Data
    Processing of Small Targets 2009, volume 7445, International Society for Optics
    and Photonics, 2009, p. 744510.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baştan et al. [2011] M. Baştan, M. R. Yousefi, T. M. Breuel, Visual Words on
    Baggage X-Ray Images, in: International Conference on Computer Analysis of Images
    and Patterns, Lecture Notes in Computer Science, Springer Berlin Heidelberg, 2011,
    pp. 360–368.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Turcsany et al. [2013] D. Turcsany, A. Mouton, T. P. Breckon, Improving feature-based
    object recognition for X-ray baggage security screening using primed visualwords,
    in: International Conference on Industrial Technology (ICIT), IEEE, 2013, pp.
    1140–1145.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bastan et al. [2013] M. Bastan, W. Byeon, T. M. Breuel, Object Recognition in
    Multi-View Dual Energy X-ray Images – Executive summary, British Machine Vision
    Conference (BMVC) (2013) 1–11.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zheng and Elmaghraby [2013] Y. Zheng, A. Elmaghraby, A Vehicle Threat Detection
    System Using Correlation Analysis And Synthesized X-ray Images, in: Detection
    and Sensing of Mines, Explosive Objects, and Obscured Targets XVIII, volume 8709,
    International Society for Optics and Photonics, 2013, p. 87090V.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2014] J. Zhang, L. Zhang, Z. Zhao, Y. Liu, J. Gu, Q. Li, D. Zhang,
    Joint Shape and Texture Based X-Ray Cargo Image Classification, in: Conference
    on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE, 2014, pp.
    266–273.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jaccard et al. [2014] N. Jaccard, T. W. Rogers, L. D. Griffin, Automated Detection
    Of Cars In Transmission X-ray Images Of Freight Containers, in: International
    Conference on Advanced Video and Signal Based Surveillance (AVSS), IEEE, 2014,
    pp. 387–392.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kolkoori et al. [2014] S. Kolkoori, N. Wrobel, A. Deresch, B. Redmer, U. Ewert,
    Dual High-energy X-ray Digital Radiography For Material Discrimination In Cargo
    Containers, in: European Conference on Non-Destructive Testing (ECNDT), pp. 6–10.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Zhu [2015] N. Zhang, J. Zhu, A Study Of X-ray Machine Image Local
    Semantic Features Extraction Model Based On Bag-ofwords For Airport Security,
    International Journal on Smart Sensing and Intelligent Systems 8 (2015) 45–64.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang [2015] N. Zhang, A Study On Optimization Methods Of X-ray Machine Recognition
    For Aviation Security System, International Journal on Smart Sensing and Intelligent
    Systems 8 (2015) 1313–1332.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Abusaeeda et al. [2011] O. Abusaeeda, J. Evans, D. Downes, J. Chan, View Synthesis
    Of KDEX Imagery For 3d Security X-ray Imaging, in: International Conference on
    Imaging for Crime Detection and Prevention (ICDP), IET, 2011, pp. P40–P40.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery [2011] D. Mery, Automated Detection In Complex Objects Using A Tracking
    Algorithm In Multiple X-ray Views, in: Conference on Computer Vision and Pattern
    Recognition Workshops (CVPRW), IEEE, 2011, pp. 41–48.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery et al. [2013a] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, Detection Of
    Regular Objects In Baggage Using Multiple X-ray Views, Insight - Non-Destructive
    Testing and Condition Monitoring 55 (2013a) 16–20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery et al. [2013b] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, Automated X-Ray
    Object Recognition Using an Efficient Search Algorithm in Multiple Views, in:
    Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE,
    2013b, pp. 368–374.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery and Riffo [2013] D. Mery, V. Riffo, Automated Object Recognition In Baggage
    Screening Using Multiple X-ray Views, Annual Conference of the British Institute
    of Non-Destructive Testing (NDT) 4860 (2013) 1–12.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery et al. [2013] D. Mery, G. Mondragon, V. Riffo, I. Zuccar, Detection of
    regular objects in baggage using multiple X-ray views, Insight - Non-Destructive
    Testing and Condition Monitoring 55 (2013) 16–20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery [2015] D. Mery, Inspection of Complex Objects Using Multiple-X-Ray Views,
    IEEE/ASME Transactions on Mechatronics 20 (2015) 338–347.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery et al. [2016] D. Mery, E. Svec, M. Arias, Object Recognition in X-ray Testing
    Using Adaptive Sparse Representations, Journal of Nondestructive Evaluation 35
    (2016) 45.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Riffo and Mery [2016] V. Riffo, D. Mery, Automated Detection of Threat Objects
    Using Adapted Implicit Shape Model, IEEE Transactions on Systems, Man, and Cybernetics:
    Systems 46 (2016) 472–482.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cañizares et al. [2018] P. C. Cañizares, M. G. Merayo, A. Núñez, FORTIFIER:
    a FORmal disTrIbuted Framework to Improve the dEtection of thReatening objects
    in baggage, Journal of Information and Telecommunication 2 (2018) 2–18.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schmidt-Hackenberg et al. [2012] L. Schmidt-Hackenberg, M. R. Yousefi, T. M.
    Breuel, Visual Cortex Inspired Features For Object Detection In X-ray Images,
    in: International Conference on Pattern Recognition (ICPR), IEEE, Tsukuba, Japan,
    2012, pp. 2573–2576.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paranjape et al. [1998] R. Paranjape, M. Sluser, E. Runtz, Segmentation of
    handguns in dual energy X-ray imagery of passenger carry-on baggage, in: Canadian
    Conference on Electrical and Computer Engineering, volume 1, IEEE, 1998, pp. 377–380.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sluser and Paranjape [1999] M. Sluser, R. Paranjape, Model-based Probabilistic
    Relaxation Segmentation Applied To Threat Detection In Airport X-ray Imagery,
    in: Canadian Conference on Electrical and Computer Engineering, volume 2, IEEE,
    1999, pp. 720–726.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Singh and Singh [2004] M. Singh, S. Singh, Image Segmentation Optimisation
    For X-ray Images Of Airline Luggage, in: International Conference on Computational
    Intelligence for Homeland Security and Personal Safety (CIHSPS), IEEE, 2004, pp.
    10–17.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ding et al. [2006] J. Ding, Y. Li, X. Xu, L. Wang, X-ray Image Segmentation
    by Attribute Relational Graph Matching, in: International Conference on Signal
    Processing, IEEE, 2006.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Svec P. [2016] E. Svec P., Sparse KNN - A Method For Object Recognition Over
    X-ray Images Using Knn Based In Sparse Reconstruction, Ph.D. thesis, Pontificia
    Universidad Catolica De Chile, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jaccard et al. [2016] N. Jaccard, T. W. Rogers, E. J. Morton, L. D. Griffin,
    Using Deep Learning On X-ray Images To Detect Threats, in: Defence and Security
    Doctoral Symposium Paper, Cranfield University, 2016, pp. 1–12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaccard et al. [2017] N. Jaccard, T. W. Rogers, E. J. Morton, Detection Of Concealed
    Cars In Complex Cargo X-ray Imagery Using Deep Learning, Journal of X-Ray Science
    and Technology 25 (2017) 323–339.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jaccard et al. [2016] N. Jaccard, T. Rogers, E. Morton, L. Griffin, Automated
    Detection Of Smuggled High-risk Security Threats Using Deep Learning, in: International
    Conference on Imaging for Crime Detection and Prevention (ICDP), IET, 2016, pp.
    11 (4 .)–11 (4 .).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rogers et al. [2017] T. W. Rogers, N. Jaccard, L. D. Griffin, A Deep Learning
    Framework For The Automated Inspection Of Complex Dual-energy X-ray Cargo Imagery,
    in: Conference on Anomaly Detection and Imaging with X-Rays (ADIX) II, SPIE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Caldwell et al. [2017] M. Caldwell, M. Ransley, T. W. Rogers, L. D. Griffin,
    Transferring X-ray Based Automated Threat Detection Between Scanners With Different
    Energies And Resolution, in: Counterterrorism, Crime Fighting, Forensics, and
    Surveillance Technologies, SPIE, 2017, p. 15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yuan and Guo [2018] J. Yuan, C. Guo, A Deep Learning Method for Detection of
    Dangerous Equipment, in: International Conference on Information Science and Technology
    (ICIST), IEEE, 2018, pp. 159–164.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. [2018] Z. Zhao, H. Zhang, J. Yang, A GAN-Based Image Generation
    Method for X-Ray Security Prohibited Items, in: Chinese Conference on Pattern
    Recognition and Computer Vision (PRCV), Lecture Notes in Computer Science, Springer
    International Publishing, 2018, pp. 420–430.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2018] M. Xu, H. Zhang, J. Yang, Prohibited Item Detection in Airport
    X-Ray Security Images via Attention Mechanism Based CNN, in: Chinese Conference
    on Pattern Recognition and Computer Vision (PRCV), Lecture Notes in Computer Science,
    Springer International Publishing, 2018, pp. 429–439.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Miao et al. [2019] C. Miao, L. Xie, F. Wan, C. Su, H. Liu, J. Jiao, Q. Ye,
    SIXray : A Large-scale Security Inspection X-ray Benchmark for Prohibited Item
    Discovery in Overlapping Images, in: Conference on Computer Vision and Pattern
    Recognition (CVPR), IEEE, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akçay and Breckon [2017] S. Akçay, T. P. Breckon, An Evaluation Of Region-Based
    Object Detection Strategies Within X-ray Baggage Security Imagery, in: IEEE International
    Conference on Image Processing (ICIP), IEEE, 2017, pp. 1337–1341.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Akçay et al. [2018] S. Akçay, M. E. Kundegorski, C. G. Willcocks, T. P. Breckon,
    Using Deep Convolutional Neural Network Architectures for Object Classification
    and Detection within X-ray Baggage Security Imagery, IEEE Transactions on Information
    Forensics and Security (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hassan et al. [2019] T. Hassan, S. H. Khan, S. Akcay, M. Bennamoun, N. Werghi,
    Deep CMST Framework for the Autonomous Recognition of Heavily Occluded and Cluttered
    Baggage Items from Multivendor Security Radiographs, CoRR (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2018] Z. Liu, J. Li, Y. Shu, D. Zhang, Detection and Recognition
    of Security Detection Object Based on Yolo9000, in: International Conference on
    Systems and Informatics (ICSAI), IEEE, 2018, pp. 278–282.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cui and Oztan [2019] Y. Cui, B. Oztan, Automated firearms detection in cargo
    x-ray images using RetinaNet, in: A. Ashok, M. E. Gehm, J. A. Greenberg (Eds.),
    Anomaly Detection and Imaging with X-Rays (ADIX) IV, SPIE, 2019, p. 24.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Subramani et al. [2020] M. Subramani, K. Rajaduari, S. D. Choudhury, A. Topkar,
    V. Ponnusamy, Evaluating One Stage Detector Architecture of Convolutional Neural
    Network for Threat Object Detection Using X-Ray Baggage Security Imaging, Revue
    d’Intelligence Artificielle 34 (2020) 495–500.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hassan et al. [2020] T. Hassan, M. Bettayeb, S. Akcay, S. Khan, M. Bennamoun,
    N. Werghi, Detecting Prohibited Items in X-Ray Images: a Contour Proposal Learning
    Approach, in: 2020 IEEE International Conference on Image Processing (ICIP), IEEE,
    2020, pp. 2016–2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Steitz et al. [2019] J.-M. O. Steitz, F. Saeedan, S. Roth, Multi-view X-Ray
    R-CNN, in: German Conference on Pattern Recognition (GCPR), 2019, pp. 153–168.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liang et al. [2019] K. J. Liang, J. B. Sigman, G. P. Spell, D. Strellis, W. Chang,
    F. Liu, T. Mehta, L. Carin, Toward Automatic Threat Recognition for Airport X-ray
    Baggage Screening with Deep Convolutional Object Detection, CoRR (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Isaac-Medina et al. [2020] B. Isaac-Medina, C. Willcocks, T. Breckon, Multi-view
    Object Detection Using Epipolar Constraints within Cluttered X-ray Security Imagery,
    in: Proceedings of the International Conference on Pattern Recognition (ICPR),
    IEEE, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaus et al. [2019a] Y. Gaus, N. Bhowmik, S. Akcay, T. Breckon, Evaluating the
    Transferability and Adversarial Discrimination of Convolutional Neural Networks
    for Threat Object Detection and Classification within X-Ray Security Imagery,
    in: Procedings of the International Conference on Machine Learning Applications
    (ICMLA), IEEE, 2019a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaus et al. [2019b] Y. F. A. Gaus, N. Bhowmik, S. Akçay, P. M. Guillen-Garcia,
    J. W. Barker, T. P. Breckon, Evaluation of a Dual Convolutional Neural Network
    Architecture for Object-wise Anomaly Detection in Cluttered X-ray Security Imagery,
    in: International Joint Conference on Neural Networks (IJCNN), IEEE, 2019b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hassan et al. [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi,
    Trainable Structure Tensors for Autonomous Baggage Threat Detection Under Extreme
    Occlusion, in: Asian Conference on Computer Vision - ACCV, Springer, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tuszynski et al. [2013] J. Tuszynski, J. T. Briggs, J. Kaufhold, A Method For
    Automatic Manifest Verification Of Container Cargo Using Radiography Images, Journal
    of Transportation Security 6 (2013) 339–356.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrews et al. [2016a] J. T. A. Andrews, E. J. Morton, L. D. Griffin, Detecting
    Anomalous Data Using Auto-encoders, International Journal of Machine Learning
    and Computing 6 (2016a) 21.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Andrews et al. [2016b] J. T. A. Andrews, N. Jaccard, T. W. Rogers, T. Tanay,
    L. D. Griffin, Anomaly Detection for Security Imaging, in: Defence and Security
    Doctoral Symposium, Cranfield University, 2016b.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Andrews et al. [2017] J. T. A. Andrews, N. Jaccard, T. W. Rogers, L. D. Griffin,
    Representation-learning For Anomaly Detection In Complex X-ray Cargo Imagery,
    in: Anomaly Detection and Imaging with X-Rays (ADIX) II, SPIE, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akcay et al. [2019a] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, GANomaly:
    Semi-supervised Anomaly Detection via Adversarial Training, in: Asian Conference
    on Computer Vision - ACCV, Springer, 2019a, pp. 622–637.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Akcay et al. [2019b] S. Akcay, A. Atapour-Abarghouei, T. P. Breckon, Skip-GANomaly:
    Skip Connected and Adversarially Trained Encoder-Decoder Anomaly Detection, in:
    International Joint Conference on Neural Networks (IJCNN), IEEE, 2019b, pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Griffin et al. [2019] L. D. Griffin, M. Caldwell, J. T. A. Andrews, H. Bohler,
    “Unexpected Item in the Bagging Area”: Anomaly Detection in X-Ray Security Images,
    IEEE Transactions on Information Forensics and Security 14 (2019) 1539–1553.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Caldwell and Griffin [2019] M. Caldwell, L. D. Griffin, Limits on transfer learning
    from photographic image data to X-ray threat detection, Journal of X-Ray Science
    and Technology (2019) 1–14.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery [2015] D. Mery, Computer Vision for X-Ray Testing, Springer International
    Publishing, Cham, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery et al. [2015] D. Mery, V. Riffo, U. Zscherpel, G. Mondragón, I. Lillo,
    I. Zuccar, H. Lobel, M. Carrasco, GDXray: The Database of X-ray Images for Nondestructive
    Testing, Journal of Nondestructive Evaluation 34 (2015) 42.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Centre for Applied Scienceand Technology (2016) [CAST] Centre for Applied Scienceand
    Technology (CAST), OSCT Borders X-ray Image Library, Technical Report, UK Home
    Office, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. [2020] Y. Wei, R. Tao, Z. Wu, Y. Ma, L. Zhang, X. Liu, Occluded
    Prohibited Items Detection: An X-ray Security Inspection Benchmark and De-occlusion
    Attention Module, in: Proceedings of the 28th ACM International Conference on
    Multimedia, ACM, New York, NY, USA, 2020, pp. 138–146.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mery and Arteta [2017] D. Mery, C. Arteta, Automatic Defect Recognition in
    X-Ray Testing Using Computer Vision, in: Winter Conference on Applications of
    Computer Vision (WACV), IEEE, 2017, pp. 1026–1035.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dhiraj and Jain [2019] Dhiraj, D. K. Jain, An Evaluation Of Deep Learning-Based
    Object Detection Strategies For Threat Object Detection In Baggage Security Imagery,
    Pattern Recognition Letters 120 (2019) 112–119.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Morris et al. [2018] T. Morris, T. Chien, E. Goodman, Convolutional Neural
    Networks for Automatic Threat Detection in Security X-Ray Images, in: International
    Conference on Machine Learning and Applications (ICMLA), IEEE, 2018, pp. 285–292.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liang et al. [2018] K. Liang, C. Gregory, S. O. Diallo, K. Roe, G. Heilmann,
    L. Carin, D. Carlson, G. Spell, J. Sigman, Automatic Threat Recognition Of Prohibited
    Items At Aviation Checkpoint With X-ray Imaging: A Deep Learning Approach, in:
    A. Ashok, M. A. Neifeld, M. E. Gehm, J. A. Greenberg (Eds.), Anomaly Detection
    and Imaging with X-Rays (ADIX) III, SPIE, 2018, p. 2.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. [2019] J. Yang, Z. Zhao, H. Zhang, Y. Shi, Data Augmentation for
    X-Ray Prohibited Item Images Using Generative Adversarial Networks, IEEE Access
    (2019) 1–1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chan et al. [2010] J. Chan, P. Evans, X. Wang, Enhanced Color Coding Scheme
    For Kinetic Depth Effect X-ray (KDEX) Imaging, in: International Carnahan Conference
    on Security Technology, IEEE, 2010, pp. 155–160.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cutler and Paddock [2009] V. Cutler, S. Paddock, Use Of Threat Image Projection
    (TIP) To Enhance Security Performance, in: International Carnahan Conference on
    Security Technology, IEEE, 2009, pp. 46–51.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhowmik et al. [2019] N. Bhowmik, Q. Wang, Y. F. A. Gaus, M. Szarek, T. P.
    Breckon, The Good, the Bad and the Ugly: Evaluating Convolutional Neural Networks
    for Prohibited Item Detection Using Real and Synthetically Composited X-ray Imagery,
    in: British Machine Vision Conference (BMVC) Workshops.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Hartigan and Wong [1979] J. A. Hartigan, M. A. Wong, Algorithm AS 136: A K-Means
    Clustering Algorithm, Applied Statistics 28 (1979) 100.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Breiman [2001] L. Breiman, Random Forests, Machine Learning 45 (2001) 5–32.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hearst et al. [1998] M. Hearst, S. Dumais, E. Osuna, J. Platt, B. Scholkopf,
    Support Vector Machines, IEEE Intelligent Systems and their Applications 13 (1998)
    18–28.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu et al. [2019] Z. Xu, S. Lyu, W. Jin, Y. Lu, Modified Adaptive Implicit Shape
    Model for Object Detection, in: Communications in Computer and Information Science,
    Springer, 2019, pp. 144–151.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lazebnik et al. [2005] S. Lazebnik, C. Schmid, J. Ponce, A sparse texture representation
    using local affine regions, IEEE Transactions on Pattern Analysis and Machine
    Intelligence 27 (2005) 1265–1278.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Michel and Schwaninger [2009] S. Michel, A. Schwaninger, Human-machine Interaction
    In X-ray Screening, in: International Carnahan Conference on Security Technology,
    IEEE, 2009, pp. 13–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bastian et al. [2008] C. C. V. Bastian, A. Schwaninger, S. Michel, Do Multi-view
    X-ray Systems Improve X-ray Image In- Terpretation In Airport Security Screening
    ?, Zeitschrift für Arbeitswissenschaft 3 (2008) 166–173.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mery et al. [2017] D. Mery, V. Riffo, I. Zuccar, C. Pieringer, Object Recognition
    In X-ray Testing Using An Efficient Search Algorithm In Multiple Views, Insight
    - Non-Destructive Testing and Condition Monitoring 59 (2017) 85–92.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cover and Hart [1967] T. Cover, P. Hart, Nearest Neighbor Pattern Classification,
    IEEE Transactions on Information Theory 13 (1967) 21–27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2005] L. Wang, Y. Li, J. Ding, K. Li, Structural X-ray Image Segmentation
    for Threat Detection by Attribute Relational Graph Matching, in: 2005 International
    Conference on Neural Networks and Brain, IEEE, 2005, pp. 1206–1211.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mallia-Parfitt and Giasemidis [2019] N. Mallia-Parfitt, G. Giasemidis, Graph
    clustering and variational image segmentation for automated firearm detection
    in X-ray images, IET Image Processing 13 (2019) 1105–1114.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. [2016] K. He, X. Zhang, S. Ren, J. Sun, Deep Residual Learning for
    Image Recognition, in: Conference on Computer Vision and Pattern Recognition (CVPR),
    volume 7, IEEE, 2016, pp. 770–778.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Redmon and Farhadi [2018] J. Redmon, A. Farhadi, YOLOv3: An Incremental Improvement,
    Technical Report, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'He et al. [2017] K. He, G. Gkioxari, P. Dollar, R. Girshick, Mask R-CNN, in:
    International Conference on Computer Vision (ICCV), IEEE, 2017, pp. 2961–2969.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Krizhevsky et al. [2012] A. Krizhevsky, I. Sutskever, G. E. Hinton, ImageNet
    Classification with Deep Convolutional Neural Networks, in: Conference on Neural
    Information Processing Systems (NeurIPS), Curran Associates, Inc., 2012, pp. 1097–1105.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Simonyan and Zisserman [2015] K. Simonyan, A. Zisserman, Very Deep Convolutional
    Networks for Large-Scale Image Recognition, in: International Conference on Learning
    Representations (ICLR).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Griffin et al. [2009] L. D. Griffin, M. Lillholm, M. Crosier, J. van Sande,
    Basic Image Features (BIFs) Arising from Approximate Symmetry Type, Springer,
    Berlin, Heidelberg, 2009, pp. 343–355.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bosch et al. [2007] A. Bosch, A. Zisserman, X. Munoz, Representing Shape With
    A Spatial Pyramid Kernel, in: International Conference On Image And Video Retrieval
    (CIVR), ACM Press, 2007, pp. 401–408.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arjovsky et al. [2017] M. Arjovsky, S. Chintala, L. Bottou, Wasserstein GAN,
    in: International Conference on Machine Learning (ICML), PMLR, 2017, pp. 214–223.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Isola et al. [2017] P. Isola, J.-Y. Zhu, T. Zhou, A. A. Efros, Image-to-Image
    Translation with Conditional Adversarial Networks, in: Conference on Computer
    Vision and Pattern Recognition (CVPR), IEEE, 2017, pp. 5967–5976.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chollet [2017] F. Chollet, Xception: Deep Learning with Depthwise Separable
    Convolutions, in: Conference on Computer Vision and Pattern Recognition (CVPR),
    IEEE, 2017, pp. 1800–1807.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. [2016] C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, Z. Wojna,
    Rethinking the Inception Architecture for Computer Vision, in: Conference on Computer
    Vision and Pattern Recognition (CVPR), IEEE, 2016, pp. 2818–2826.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. [2017] S. Ren, K. He, R. Girshick, J. Sun, Faster R-CNN: Towards
    Real-Time Object Detection with Region Proposal Networks, IEEE Transactions on
    Pattern Analysis and Machine Intelligence (PAMI) 39 (2017) 1137–1149.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dai et al. [2016] J. Dai, Y. Li, K. He, J. Sun, R-FCN: Object Detection via
    Region-based Fully Convolutional Networks, in: International Conference on Neural
    Information Processing Systems (NeurIPS), pp. 379–387.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sigman et al. [2020] J. B. Sigman, G. P. Spell, K. J. Liang, L. Carin, Background
    adaptive faster R-CNN for semi-supervised convolutional object detection of threats
    in x-ray images, in: A. Ashok, M. E. Gehm, J. A. Greenberg (Eds.), Anomaly Detection
    and Imaging with X-Rays (ADIX) V, SPIE, 2020, p. 5.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. [2016] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. Reed, C.-Y.
    Fu, A. C. Berg, SSD: Single Shot MultiBox Detector, in: European Conference on
    Computer Vision (ECCV), Springer, Cham, 2016, pp. 21–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lin et al. [2018] T. Y. Lin, P. Goyal, R. Girshick, K. He, P. Dollar, Focal
    loss for dense object detection, IEEE Transactions on Pattern Analysis and Machine
    Intelligence (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hassan et al. [2020] T. Hassan, S. Akcay, M. Bennamoun, S. Khan, N. Werghi,
    Cascaded Structure Tensor Framework for Robust Identification of Heavily Occluded
    Baggage Items from X-ray Scans, arXiv (2020).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jinyi et al. [2019] L. Jinyi, J. Leng, Y. Liu, Deep Convolutional Neural Network
    Based Object Detector for X-Ray Baggage Security Imagery, in: Proceedings of the
    International Conference on Tools with Artificial Intelligence (ICTAI), IEEE,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bhowmik et al. [2019] N. Bhowmik, Y. F. A. Gaus, S. Akcay, J. W. Barker, T. P.
    Breckon, On the Impact of Object and Sub-component Level Segmentation Strategies
    for Supervised Anomaly Detection within X-ray Security Imagery, in: Procedings
    of the International Conference on Machine Learning Applications (ICMLA), IEEE,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An et al. [2019] J. An, H. Zhang, Y. Zhu, J. Yang, Semantic Segmentation for
    Prohibited Items in Baggage Inspection, in: Lecture Notes in Computer Science,
    Springer, 2019, pp. 495–505.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sterchi et al. [2017] Y. Sterchi, N. Hättenschwiler, S. Michel, A. Schwaninger,
    Relevance of visual inspection strategy and knowledge about everyday objects for
    X-ray baggage screening, in: International Carnahan Conference on Security Technology
    (ICCST), IEEE, 2017, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lecun et al. [1998] Y. Lecun, L. Bottou, Y. Bengio, P. Haffner, Gradient-based
    Learning Applied To Document Recognition, Proceedings of the IEEE 86 (1998) 2278–2324.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. [2012] F. T. Liu, K. M. Ting, Z.-H. Zhou, Isolation-Based Anomaly
    Detection, ACM Transactions on Knowledge Discovery from Data 6 (2012) 1–39.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Islam et al. [2018] A. Islam, Y. Zhang, D. Yin, O. Camps, R. J. Radke, Correlating
    Belongings with Passengers in a Simulated Airport Security Checkpoint, in: International
    Conference on Distributed Smart Cameras (ICDSC), ACM Press, 2018, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'An et al. [2019] J. An, H. Zhang, Y. Zhu, J. Yang, Semantic Segmentation for
    Prohibited Items in Baggage Inspection, in: Lecture Notes in Computer Science,
    Springer, 2019, pp. 495–505.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Szegedy et al. [2017] C. Szegedy, S. Ioffe, V. Vanhoucke, A. Alemi, Inception-v4,
    Inception-ResNet and the Impact of Residual Connections on Learning, in: AAAI
    Conference on Artificial Intelligence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhu et al. [2017] J.-Y. Zhu, T. Park, P. Isola, A. A. Efros, Unpaired Image-to-Image
    Translation, in: International Conference on Computer Vision (ICCV), IEEE, 2017,
    pp. 2223–2232.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Karras et al. [2019] T. Karras, S. Laine, M. Aittala, J. Hellsten, J. Lehtinen,
    T. Aila, Analyzing and Improving the Image Quality of StyleGAN, CoRR (2019).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2007] G. Chen, G. Bennett, D. Perticone, Dual-energy X-ray Radiography
    For Automatic High- Z Material Detection, Nuclear Instruments and Methods in Physics
    Research B 261 (2007) 356–359.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fu et al. [2010] K. Fu, D. Ranta, P. Das, C. Guest, Layer Separation For Material
    Discrimination Cargo Imaging System, in: Image Processing: Machine Vision Applications
    III, volume 7538, SPIE, 2010, p. 75380Y.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
