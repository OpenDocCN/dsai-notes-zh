- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:07:05'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[1812.02183] Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1812.02183](https://ar5iv.labs.arxiv.org/html/1812.02183)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Deep Learning at Scale
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: for the Construction of Galaxy Catalogs
  prefs: []
  type: TYPE_NORMAL
- en: in the Dark Energy Survey
  prefs: []
  type: TYPE_NORMAL
- en: Asad Khan NCSA, University of Illinois at Urbana-Champaign, Urbana, Illinois
    61801, USA Department of Physics, University of Illinois at Urbana-Champaign,
    Urbana, Illinois 61801, USA    E. A. Huerta NCSA, University of Illinois at Urbana-Champaign,
    Urbana, Illinois 61801, USA Department of Astronomy, University of Illinois at
    Urbana-Champaign, Urbana, Illinois 61801, USA    Sibo Wang NCSA, University of
    Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA    Robert Gruendl NCSA,
    University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA Department
    of Astronomy, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801,
    USA    Elise Jennings Argonne National Laboratory, Leadership Computing Facility,
    Lemont, Illinois 60439, USA    Huihuo Zheng Argonne National Laboratory, Leadership
    Computing Facility, Lemont, Illinois 60439, USA
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The scale of ongoing and future electromagnetic surveys pose formidable challenges
    to classify astronomical objects. Pioneering efforts on this front include citizen
    science campaigns adopted by the Sloan Digital Sky Survey (SDSS). SDSS datasets
    have been recently used to train neural network models to classify galaxies in
    the Dark Energy Survey (DES) that overlap the footprint of both surveys. Herein,
    we demonstrate that knowledge from deep learning algorithms, pre-trained with
    real-object images, can be transferred to classify galaxies that overlap both
    SDSS and DES surveys, achieving state-of-the-art accuracy $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99.6\%$. We demonstrate
    that this process can be completed within just eight minutes using distributed
    training. While this represents a significant step towards the classification
    of DES galaxies that overlap previous surveys, we need to initiate the characterization
    of unlabelled DES galaxies in new regions of parameter space. To accelerate this
    program, we use our neural network classifier to label over ten thousand unlabelled
    DES galaxies, which do not overlap previous surveys. Furthermore, we use our neural
    network model as a feature extractor for unsupervised clustering and find that
    unlabeled DES images can be grouped together in two distinct galaxy classes based
    on their morphology, which provides a heuristic check that the learning is successfully
    transferred to the classification of unlabelled DES images. We conclude by showing
    that these newly labeled datasets can be combined with unsupervised recursive
    training to create large-scale DES galaxy catalogs in preparation for the Large
    Synoptic Survey Telescope era.
  prefs: []
  type: TYPE_NORMAL
- en: 'pacs:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Valid PACS appear here
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords: Deep Learning, Convolutional Neural Networks, Sloan Digital Sky Survey,
    Dark Energy Survey, Large Synoptic Survey Telescope, Galaxy Catalogs, Unsupervised
    Learning, Data Clustering'
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Electromagnetic surveys provide key insights into the large scale structure
    of the Universe, its geometry and evolution in cosmic time. As the depth and scale
    of these surveys continue to increase in years to come, they will push back the
    frontiers of our understanding of dark matter and dark energy Riess *et al.* ([1998](#bib.bib1));
    Perlmutter *et al.* ([1999](#bib.bib2)); Tonry *et al.* ([2003](#bib.bib3)); Knop *et al.*
    ([2003](#bib.bib4)).
  prefs: []
  type: TYPE_NORMAL
- en: The classification of astrophysical objects has been pursued in the past using
    a diverse set of tools. For instance, galaxies have been classified using their
    photometric properties, achieving classification accuracies $\sim 85\%$ Doi *et al.*
    ([1993](#bib.bib5)). Other methods to classify galaxies according to their morphology
    have taken into account their physical properties across multiple wavelengths.
    For instance, the method introduced in Wijesinghe *et al.* ([2010](#bib.bib6)),
    considered a sample of galaxies from the Sloan Digital Sky Survey (SDSS) Eisenstein *et al.*
    ([2011](#bib.bib7)), using the five SDSS filters $(u,\,g,\,r,\,i,\,z)$, and then
    used a combination of shapelet decomposition and Principal Components Analysis
    (PCA). Other methods for galaxy classification include Concentration-Asymmetry-Smoothness
    (CAS) Conselice ([2003](#bib.bib8)), and machine learning, including artificial
    neural networks and PCAs Lahav *et al.* ([1995](#bib.bib9), [1996](#bib.bib10));
    Banerji *et al.* ([2010](#bib.bib11)).
  prefs: []
  type: TYPE_NORMAL
- en: In recent years, citizen science campaigns have played a key role to classify
    thousands of celestial objects in astronomical surveys. SDSS is an archetypical
    example of a successful approach to classify hundreds of thousands of galaxies.
    As electromagnetic surveys continue to increase their depth and coverage, campaigns
    of this nature may lack scalability. For instance, within six years of operation,
    the Dark Energy Survey (DES) Dark Energy Survey Collaboration *et al.* ([2016](#bib.bib12))
    observed over three hundred million galaxies, a number that will be surpassed
    by the observing capabilities of the Large Synoptic Survey Telescope (LSST) LSST
    Dark Energy Science Collaboration ([2012](#bib.bib13)). In brief, there is a pressing
    need to explore new approaches to maximize the science throughput of next-generation
    electromagnetic surveys. A promising paradigm is the convergence of deep learning
    and large scale computing to address the imminent increase in data volume, complexity,
    and latency of observations of LSST-type surveys, the theme of this paper.
  prefs: []
  type: TYPE_NORMAL
- en: An innovative idea to accomplish this prospect consists of leveraging what SDSS
    has already done, and try to use it as seed information to classify objects in
    DES data. Such idea has been explored in Domínguez Sánchez *et al.* ([2018](#bib.bib14)),
    where SDSS galaxies that overlap the DES footprint were used to train neural network
    models to classify DES galaxies that were also observed by SDSS, reporting classification
    accuracies $\sim 95\%$ Domínguez Sánchez *et al.* ([2018](#bib.bib14)).
  prefs: []
  type: TYPE_NORMAL
- en: 'While the aforementioned approach provides a way to classify DES galaxies that
    overlap previous surveys, key issues remain: (i) deep learning algorithms for
    image classification have been trained with hundreds of millions of images to
    achieve state-of-the-art classification accuracy Chollet ([2016](#bib.bib15)).
    If one attempts to train a neural network model from the ground up using just
    a few tens of thousands of SDSS galaxies, then the fully trained neural network
    model may not achieve state-of-the-art classification accuracy, or exhibit overfitting George *et al.*
    ([2018](#bib.bib16)); (ii) while training a neural network model with SDSS galaxies,
    and then applying it to classify DES galaxies that overlap the footprint of both
    SDSS and DES is an important validation study for the applicability of deep learning
    for classification analyses, we also need to demonstrate the applicability of
    this approach for DES galaxies that have not yet been observed in previous surveys.
    This can only be accomplished once more DES galaxies are labeled; (iii) newly
    labelled DES galaxies, that do not overlap previous surveys, can be used as training
    datasets to enhance the classification accuracy of deep learning algorithms. One
    can easily realize that this approach will lead to the creation of TB-size training
    datasets. In this scenario, it will be essential to design distributed algorithms
    to reduce the training stage at a minimum, while retaining state-of-the-art classification
    accuracy.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In this article we describe an approach to address the aforementioned challenges
    by bringing together several deep learning methods in an innovative manner. Key
    highlights of this study include:'
  prefs: []
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We transfer knowledge from the state-of-the-art neural network model for image
    classification, Xception Chollet ([2016](#bib.bib15)), trained with the ImageNet
    dataset Deng *et al.* ([2009](#bib.bib17)), to classify SDSS galaxy images, achieving
    state-of-the-art accuracies $99.8\%$. Note that transfer learning between similar
    datasets, such as SDSS and DES, has been traditionally used in the computer science
    literature Tan *et al.* ([2018](#bib.bib18)). In stark contrast, we use a pre-trained
    model for real-world object recognition, and then transfer its knowledge to classify
    SDSS and DES galaxies. To the best of our knowledge this is the first application
    of deep transfer learning for galaxy classification¹¹1While this paper was under
    review, a study on SDSS galaxy classification was presented in which disparate
    datasets for transfer learning are used Barchi *et al.* ([2019](#bib.bib19))..
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: To streamline and accelerate this method, we introduce the first application
    of deep transfer learning and distributed training in cosmology, reducing the
    training stage of the Xception model with galaxy image datasets from five hours
    to just eight minutes, using 64 K80 GPUs in the Cooley supercomputer.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We show that our neural network model trained by transfer learning achieves
    state-of-the-art accuracy, $99.6\%$, to classify DES galaxies that overlap the
    footprint of the SDSS survey.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We use our neural network classifier to label over ten thousand unlabeled DES
    galaxies that have not been observed in previous surveys. We then turn our neural
    network model into a feature extractor to show that these unlabeled datasets can
    be clustered according to their morphology, forming two distinct datasets.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: $\bullet$
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Finally, we use the newly labelled DES images and do unsupervised recursive
    training to retrain our deep transfer learning model, boosting its accuracy to
    classify unlabeled DES galaxies in bulk in new regions of parameter space.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: The combination of all the aforementioned deep learning methods lays the foundations
    to exploit deep transfer learning at scale, data clustering and recursive training
    to produce large-scale galaxy catalogs in the LSST era LSST Dark Energy Science
    Collaboration ([2012](#bib.bib13)).
  prefs: []
  type: TYPE_NORMAL
- en: This paper is organized as follows. Section [II](#S2 "II Methods ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") presents
    the approach followed to curate the datasets and deep learning algorithms designed
    and trained for our analyses. In section [III](#S3 "III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey"),
    we demonstrate the applicability of our methods to classify galaxies in SDSS,
    galaxies that overlap SDSS and DES, and finally, the applicability of our approach
    to correctly classify thousands of unlabelled DES galaxies. Finally, section [IV](#S4
    "IV Conclusion ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey") summarizes our findings and future directions of work.
  prefs: []
  type: TYPE_NORMAL
- en: II Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section we describe the SDSS and DES datasets we have curated for our
    studies, the neural network model we use for deep transfer learning, and how we
    can use unsupervised recursive training to create galaxy catalogs at scale.
  prefs: []
  type: TYPE_NORMAL
- en: II.1 Data Curation for SDSS and DES
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use a subset of SDSS Data Release (DR) 7 images for which we have high confidence
    classifications through the Galaxy Zoo project, i.e., we only choose galaxies
    with debiased probability greater than 0.985 for combined spirals, and 0.926 for
    ellipticals, respectively, as shown in Table 2 of  Lintott *et al.* ([2011](#bib.bib20)).
    We choose these cutoff thresholds to ensure that; (i) the galaxies used for training
    the neural network have robust and accurate classifications; and (ii) the representation
    of both classes in the training and test datasets are balanced. We then divide
    these images into three separate datasets for training, validation and testing.
    The validation set is used to monitor the accuracy and loss when training and
    fine-tuning our deep neural network, and hence serves to optimize hyperparameters,
    such as learning rate and number of epochs, for training.
  prefs: []
  type: TYPE_NORMAL
- en: Two test sets are carefully constructed so that the images in each set lie in
    both the SDSS and DES footprints. The first test set consists of images with Galazy
    Zoo classification confidence similar to that of the training set, i.e., a high
    probability cut-off is introduced. This test set is hence labelled High Probability
    (HP) Test Set, and there are two versions, one for each survey, i.e., HP SDSS
    and HP DES. Just as in the training set, the images for SDSS are obtained from
    (DR) 7 and the corresponding images for DES are obtained from the DES DR1 data
    release. Furthermore, a second test set is created without introducing any probability
    thresholds on Galaxy Zoo classification confidence. This set consists of almost
    all galaxies lying in both the SDSS and DES footprints, and
  prefs: []
  type: TYPE_NORMAL
- en: '|       Dataset |       Spirals |       Ellipticals |'
  prefs: []
  type: TYPE_TB
- en: '|       Training set |       18,352 |       18,268 |'
  prefs: []
  type: TYPE_TB
- en: '|       HP SDSS Test Set |       516 |       550 |'
  prefs: []
  type: TYPE_TB
- en: '|       HP DES    Test Set |       516 |       550 |'
  prefs: []
  type: TYPE_TB
- en: '|       FO SDSS Test Set |       6,677 |       5,904 |'
  prefs: []
  type: TYPE_TB
- en: '|       FO DES    Test Set |       6,677 |       5,904 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: Summary of the SDSS and DES datasets used for training and testing.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/24a96a2b01918f1c9e2b785e5c583b3a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Violin Plots of Galaxy Zoo Probability Distributions for galaxies
    in each dataset. Probability threshold cutoffs, 98.5% for spiral and 92.6% for
    elliptical, are shown as red dashed lines. These cutoffs have been selected to
    ensure that the datasets of both galaxy types are balanced.'
  prefs: []
  type: TYPE_NORMAL
- en: hence is labelled Full Overlap (FO) Test Set. Again there are two versions,
    FO SDSS and FO DES. The motivation behind creating this second test set is that
    the galaxy profiles in the unlabelled DES dataset will more closely match those
    in FO test sets. Hence FO test set serves as a good evaluation metric of the performance
    of our neural net on the ultimate task of classifying all unlabelled galaxies
    in the DES catalogue.
  prefs: []
  type: TYPE_NORMAL
- en: 'The properties of these datasets are summarized in Table [1](#S2.T1 "Table
    1 ‣ II.1 Data Curation for SDSS and DES ‣ II Methods ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey"), while their
    probability distributions are presented in Fig. [1](#S2.F1 "Figure 1 ‣ II.1 Data
    Curation for SDSS and DES ‣ II Methods ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey"). A sample of the training SDSS
    dataset, and the HP Test set images are presented in the top and bottom panels
    of Fig. [2](#S2.F2 "Figure 2 ‣ II.2 Deep Learning: Model and Methodology ‣ II
    Methods ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey"), respectively.'
  prefs: []
  type: TYPE_NORMAL
- en: SDSS Dataset We used the de-biased probabilities for elliptical and combined
    spiral classes described in Table 2 of Lintott *et al.* ([2011](#bib.bib20)) to
    create labels for the two classes of our training and test sets. After selecting
    the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926
    for spirals and ellipticals respectively, we submit SQL queries to the SDSS Skyserver SDSS
    ([2018](#bib.bib21)) to obtain g, r and i-band images and metadata from the PhotoObj
    table. Thereafter, each galaxy is ‘cut-out’ from the downloaded telescope fits
    files for each band, and then the bands are stacked together to create a color
    image.
  prefs: []
  type: TYPE_NORMAL
- en: We developed the scripts to download and preprocess data as open source Python
    software stacks ²²2The code is publicly available in a github repository at [https://github.com/khanx169/DL_DES](https://github.com/khanx169/DL_DES).
    To facilitate and streamline these tasks at scale, we incorporated Message Passing
    Interface (MPI) Gropp *et al.* ([1999](#bib.bib22)) to exploit multiple nodes
    on supercomputers for a fast parallel computation. In our case, the data extraction
    and curation was done using the Blue Waters Supercomputer Kramer *et al.* ([2015](#bib.bib23)).
  prefs: []
  type: TYPE_NORMAL
- en: DES Dataset The same steps are repeated to first select the DES DR1 metadata
    and images from the NCSA DESaccess web DES ([2018](#bib.bib24)), and then to cut-out,
    preprocess and stack the filters together to create RGB color images. Additionally,
    the Astropy package match_to_catalog_sky is used to crossmatch DES and SDSS catalogues
    to within 1 arcsec. Finally we pick a random sample of $\sim 10,000$ bright DES
    galaxies to quantify the classification and clustering performance of our neural
    network model.
  prefs: []
  type: TYPE_NORMAL
- en: 'II.2 Deep Learning: Model and Methodology'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We use open source software stacks for our studies. The deep learning APIs
    used are Keras Keras ([2018](#bib.bib25)) and Tensorflow Abadi *et al.* ([2016](#bib.bib26)).
    For the classification problem we do transfer learning starting with the Xception
    model Chollet ([2016](#bib.bib15)), which has been pre-trained with the ImageNet Russakovsky *et al.*
    ([2014](#bib.bib27)) dataset. We choose this neural network model because it outperforms
    many other state-of-the-art neural network models, including Inception-v3 Szegedy *et al.*
    ([2015](#bib.bib28)), ResNet-152 He *et al.* ([2015](#bib.bib29)) and VGG16 Simonyan and Zisserman
    ([2014](#bib.bib30)) on ImageNet validation dataset, and it has been suggested
    that better ImageNet architectures are capable of learning better transferable
    representations  Kornblith *et al.* ([2018](#bib.bib31)). More importantly, we
    carried out several experiments and found that Xception exhibits either as good
    or nominally better performance on our validation and testing galaxy datasets
    compared to many other state of the art architectures (see Fig. [3](#S2.F3 "Figure
    3 ‣ II.2 Deep Learning: Model and Methodology ‣ II Methods ‣ Deep Learning at
    Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: Bearing in mind that the Xception model Chollet ([2016](#bib.bib15)) was originally
    trained on the ImageNet Russakovsky *et al.* ([2014](#bib.bib27)) dataset, with
    images resized to $299\times 299\times 3$, we have followed best practices of
    neural network training Andrej Karpathy ([2018](#bib.bib32)), and have resized
    all the galaxy sub-images to be $299\times 299$ pixels, and then stacked the three
    filters together to create a color image of size $299\times 299\times 3$. Finally,
    these sub-images are mean subtracted and normalized to convert the pixel values
    to -1 to 1 range centered around 0\. These curated datasets serve as the input
    tensor into our deep neural network model.
  prefs: []
  type: TYPE_NORMAL
- en: For training, we first extract the feature maps from the second last layer of
    the pretrained model for a single epoch and feed them into a few custom defined
    fully connected layers added at the end of the pre-trained model (see Figure [7](#A1.F7
    "Figure 7 ‣ Appendix A Neural network architecture ‣ Deep Learning at Scale for
    the Construction of Galaxy Catalogs in the Dark Energy Survey") in [A](#A1 "Appendix
    A Neural network architecture ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey")). Then we progressively unfreeze the
    earlier layers of the whole network and fine tune their weights for a few epochs
    of training.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a90131496c7a0191c5198610f2d60e42.png)![Refer to caption](img/4c2497e6b2d75c5027bb022e945d4a99.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/5f4e20d911e309a89d258440f37cc6e7.png)![Refer to caption](img/bf1da76e0dd0ae8692170d5fffad7251.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Top panels: labelled images of the SDSS training set. Bottom panels:
    sample of galaxies from SDSS-DR7 and the corresponding crossmatched galaxies from
    DES DR1.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/067b59cb52d811d9e0f98fad40b4e4dd.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/8491eb5a309dc3de0bdaad9830398877.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: Performance of several different fine-tuned architectures pre-trained
    on ImageNet. Top panels: Receiver Operating Characteristic (ROC) for galaxies
    in the FO SDSS test set. Bottom panels: ROC for galaxies in the FO DES test set.
    The smaller insets show the difference in True Positive Rate between Xception
    and each of the other four models on a log scale.'
  prefs: []
  type: TYPE_NORMAL
- en: The rationale behind this approach is that the earlier layers of a trained network
    are very versatile filters able to pick up simple abstract features like lines
    and edges relevant to any image detection or classification problem. However,
    deeper into the network, the weights of the layers become less interpretable and
    more specific to the given problem at hand Zeiler and Fergus ([2014](#bib.bib33)).
    Hence, by training the last layers first and then progressively fine tuning the
    earlier layers we make sure that the useful weights learned on millions of ImageNet Deng *et al.*
    ([2009](#bib.bib17)) images are not destroyed while the neural network learns
    and adapts to the galaxy classification problem Yosinski *et al.* ([2014](#bib.bib34)).
    Deep transfer learning has been explored in physics and astronomy classification
    problems, including noise anomaly classification in gravitational wave data George *et al.*
    ([2018](#bib.bib16)), galaxy merger classification Ackermann *et al.* ([2018](#bib.bib35)),
    and galaxy classification Barchi *et al.* ([2019](#bib.bib19)); Domínguez Sánchez *et al.*
    ([2018](#bib.bib14)).
  prefs: []
  type: TYPE_NORMAL
- en: Single-GPU Training We train the network using Tesla P100 GPUs on XSEDE (Bridges) XSEDE
    ([2018](#bib.bib36)). The training process for the dataset of 36500 images is
    completed within 5 hours. We use categorical cross entropy as the loss function
    together with ADAM optimizer Kingma and Ba ([2014](#bib.bib37)). To avoid over-fitting,
    we monitor both training and validation losses, add a dropout rate of 70% between
    our fully connected layers, and also use early-stopping, i.e., we stop training
    once validation loss stops decreasing. Additionally we use the learning rate scheduler,
    i.e., we reduce the learning rate when training loss stops decreasing to do a
    more fine-grained search of the loss function’s minima, and data augmentation.
    For data augmentation we use random flips, rotations, zooms and shifts as shown
    in Figure [8](#A2.F8 "Figure 8 ‣ Appendix B Data Augmentation ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") in [B](#A2
    "Appendix B Data Augmentation ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey"). After training, all the weights are
    frozen and saved, and inference on about 10,000 test images is completed within
    10 minutes using a single Tesla P100 GPU.
  prefs: []
  type: TYPE_NORMAL
- en: 'Distributed Training Figure [4](#S2.F4 "Figure 4 ‣ II.2 Deep Learning: Model
    and Methodology ‣ II Methods ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") shows the parallel training performance
    for the Xception model using up to 64 K80 GPUs (see Table [3](#A4.T3 "Table 3
    ‣ Appendix D Scaling Results ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") for a detailed breakdown of these
    results). The code was distributed across multiple GPUs using the Horovod distributed
    framework for Keras Sergeev and Balso ([2018](#bib.bib38)).³³3These results were
    obtained on the Intel Haswell and NVIDIA K80 based supercomputer, Cooley, at Argonne
    Leadership Computing Facility using a data parallelization scheme through Horovod.
    We find that distributing the workload decreases the time per epoch linearly,
    and significantly reduces the training of 36,620 images from $\sim 5$ hours using
    a single GPU to 8m using 64 GPUs, with similar accuracy. ⁴⁴4 The base learning
    rate was 0.0001 and was scaled by the number of GPUs, $N$, following Goyal *et al.*
    ([2017](#bib.bib39)) while keeping the mini-batch size the same on each worker.
    In addition we used a technique of “warmup” epochs where we set the learning rate
    to be the base learning rate and increase to $0.0001*N$ after 2 warmup epochs.'
  prefs: []
  type: TYPE_NORMAL
- en: The last layer of the network has two softmax nodes, which provide the output
    probability that the input image belongs to a given galaxy class. To quantify
    the over-all accuracy of the neural network, we extract the output probabilities
    from this last layer for our two HP and FO test sets, and compare them against
    the ground truth labels provided through the Galaxy Zoo project. While these probabilities
    can be directly tested for cross-matched DES sets by comparing to the SDSS-Galaxy
    Zoo probabilities, for the rest of the unlabelled DES images this is not possible.
    For large-scale galaxy catalogs it would be unfeasible to inspect individual images
    to determine what class they belong to and check against the neural networks out-put
    probabilities to check for consistency. In practice, we can use the nodes of the
    second last layer of the neural network to determine what combination of them
    is activated for each galaxy type. In this approach, the activation vectors of
    this layer would form two distinct clusters, for each galaxy type in a 1024-D
    space. Checking whether similar combinations of neurons are activated, i.e., similar
    clusters are formed for the unlabelled DES data as the FO and HP test sets, will
    serve as a heuristic check that the learning is successfully transferred to the
    classification of unlabelled DES images for the purpose of constructing a catalog.
    For example, if there is a lack of distinct clusters, or more than two clusters
    are seen, then that would suggest unknown types that are forced into being classified
    as spiral or elliptical because the output layer has only two nodes.
  prefs: []
  type: TYPE_NORMAL
- en: In order to visualize these 1024-D clusters, we embed them into a 3-D parameter
    space using the sklearn library implementation of t-Distributed Stochastic Neighbor
    Embedding (t-SNE) van der Maaten and Hinton ([2008](#bib.bib40)). t-SNE is a nonlinear
    dimensionality reduction technique that is particularly apt for visualizing high-dimensional
    datasets by finding a faithful representation in a low dimensional embedding,
    typically 2-D or 3-D. It is important to note that t-SNE adjusts its notion of
    distance to regional density variations in the dataset, and hence bounding boxes
    of clusters in the low dimensional representation don’t correspond to their relative
    sizes. Similarly, distances between clusters may not be meaningful since they
    are affected by a number of hyper-parameters such as perplexity and number of
    iterations.
  prefs: []
  type: TYPE_NORMAL
- en: As a final step, we introduce an application of unsupervised/semi-supervised
    learning in the form of recursive training, where we introduce into the training
    set newly labelled DES galaxies and retrain our model. It has been suggested in Domínguez
    Sánchez *et al.* ([2018](#bib.bib14)) that once trained with a particular dataset
    from one survey, neural networks can quickly adapt to new instrument characteristics
    (e.g., PSF, seeing, depth), reducing by almost one order of magnitude the necessary
    training sample from a different survey for morphological classification. However
    instead of manually labelling new DES images, we extract the out-put classification
    probabilities for them through our fine-tuned neural network. We use a sample
    of  10,000 unlabelled bright DES galaxies and then by introducing a threshold
    on the neural networks classification confidence, we select the 1000 most confident
    predictions for spiral and elliptical respectively to further fine tune our network
    on.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bf074fecb24f9411db388bf5ce7d355.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Speed up in training using up to 64 K80 GPUs for the Xception model.'
  prefs: []
  type: TYPE_NORMAL
- en: III Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To check the performance of our neural network model on HP and FO test sets,
    we use standard evaluation metrics: precision, recall, accuracy and F1 score.
    For binary classification, precision is the number of true positives divided by
    the total number of predicted positives, i.e., true positives plus false positives.
    Similarly, recall is the number of true positives divided by the total number
    of actual positives, i.e., true positives plus false negatives. The F1 score is
    a single number statistical evaluation metric that measures the accuracy of binary
    classification by taking a weighted average of precision and recall. It varies
    between its worst performance value of 0 and best performance value of 1, and
    is given by'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\textrm{F1\, score}=2\,\frac{\textrm{precision}\times\textrm{recall}}{\textrm{precision}+\textrm{recall}}\,.$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: The performance of these metrics on the various test sets is summarized in Table [2](#S3.T2
    "Table 2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey"). As can be seen in Table [2](#S3.T2 "Table
    2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey"), deep transfer learning from everyday object classification
    in the ImageNet dataset to morphological classification of galaxies in SDSS and
    DES leads to state of the art accuracies and F1 scores. Our fine tuned Xception
    model attains accuracies $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$
    for the HP SDSS and HP DES test sets. Unlike HP test sets, the FO test sets do
    not entirely consist of galaxies with robust ground truth classifications. Hence,
    instead of applying a threshold on the ground truth probabilities, we apply a
    confidence threshold on the predictions of the neural network. In Table [2](#S3.T2
    "Table 2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") we pick the top half most confident predictions,
    for which the neural network attains $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower
    4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$ accuracies and F1 scores. Additionally,
    the accuracies and F1 scores obtained by applying various different thresholds
    are also summarized in Fig [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey"),
    while the Receiver Operating Characteristic (ROC) curves are shown in Fig [10](#A5.F10
    "Figure 10 ‣ Appendix E Recursive Training ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey") [E](#A5 "Appendix E Recursive Training
    ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey").
  prefs: []
  type: TYPE_NORMAL
- en: '| Dataset | Precision | Recall | FPR | Accuracy | F1 score |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| Training set |  |  |  | 99.81% | 0.9998 |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| HP SDSS Test Set | 0.996 | 1 | 0.004 | 99.81% | 0.9980 |'
  prefs: []
  type: TYPE_TB
- en: '| HP DES    Test Set | 0.998 | 0.995 | 0.002 | 99.62% | 0.9961 |'
  prefs: []
  type: TYPE_TB
- en: '| FO SDSS Test Set | 0.945 | 0.991 | 0.055 | 96.76% | 0.9675 |'
  prefs: []
  type: TYPE_TB
- en: '| FO DES    Test Set | 0.965 | 0.946 | 0.025 | 96.32% | 0.9685 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Classification accuracy for each test dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Having quantified the accuracy of our neural network model on DES test sets
    that overlap the SDSS footprint, we now feed our model with bright, unlabelled
    DES galaxies that do not overlap the SDSS footprint, and predict their classes,
    thereby labelling them. A random sample of high confidence predictions for these
    is shown in Figure [9](#A3.F9 "Figure 9 ‣ Appendix C Classification predictions
    for unlabelled DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") in [C](#A3 "Appendix C Classification predictions
    for unlabelled DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3a9f514173b64a77f1c3942ad0d5f5bb.png) ![Refer to caption](img/7f1792ee2a3273aff315d4fc85b8c032.png)
    ![Refer to caption](img/f9bebc231cd35a812a4288ebebc945fe.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: t-SNE visualization of the clustering of HP SDSS and DES test sets,
    and unlabelled DES test.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/44fb4d1ea37ce02f877be031dd234bf5.png) ![Refer to caption](img/6c3eb578ec55335b3fb6de83bfb50075.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/17792cd1c6eb73d21cf8a1fe4b8aaa8d.png) ![Refer to caption](img/0f4dcfcf812f0e466bf0e43497d3e58b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Top panels: SDSS datasets. Bottom panels: DES datasets. Accuracy
    (left panels) and F1 score (right panels) vs N high confidence predictions as
    a fraction of total full overlap test datasets (0th recursion). We also show the
    improvement in classification accuracy and F1 score after 2000 newly labelled
    DES images are added to the SDSS training dataset (1st recursion). These results
    have been obtained by averaging over ten different models.'
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, using our neural network model as a feature extractor, we obtain the
    activation maps of the second last layer and embed them in 3-D using t-SNE. The
    left and middle panels of Figure [5](#S3.F5 "Figure 5 ‣ III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") show
    the output of t-SNE when applied to the HP SDSS and HP DES test sets. We labelled
    the points using the ground-truth label of each galaxy, and found that the points
    neatly cluster into two groups with accuracies $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower
    4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$. For unlabelled DES set, shown in the
    right panel of Figure [5](#S3.F5 "Figure 5 ‣ III Results ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey"), we find again
    that two distinct clusters are formed. Based on the accuracy of the FO DES test
    set, we heuristically know that these clusters have accuracies $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$ for the top-half
    most confident predictions. These results indicate that the neural network model
    has extracted the necessary information from the training dataset to enable t-SNE
    to clearly identify two distinct classes of galaxies based on their morphology.
    A scientific visualization of this clustering algorithm for the FO DES test set
    is presented in NCSA ([2018a](#bib.bib41)). The astute reader may realize that
    using t-SNE as a visualization tool requires training to prevent common misreadings
    of the visualizations. Furthermore, t-SNE does not always produce similar outputs
    on successive runs, and it requires the user to determine a few hyperparamters
    related to the optimization process. Much work has been presented in the literature
    to ensure that new users make a proper use of this tool Wattenberg *et al.* ([2016](#bib.bib42)),
    and to automate hyperparamter selection Cao and Wang ([2017](#bib.bib43)).
  prefs: []
  type: TYPE_NORMAL
- en: Recursive training Having labeled about 10,000 DES galaxies with our neural
    network classifier, we pick the top 1000 spiral and top 1000 elliptical galaxies.
    We then add them to our original SDSS training dataset, and use deep transfer
    learning again to re-train the neural network model. The top- and bottom-left
    panels in Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at Scale for
    the Construction of Galaxy Catalogs in the Dark Energy Survey") show the initial
    (0th recursion) accuracy of our classifier, and the accuracy attained once the
    newly labelled DES images are added to the SDSS training dataset (1st recursion).
    We notice that the accuracy for classification for FO SDSS and DES test sets improves
    up to $1.5\%$. In particular, we notice that the classification accuracy for the
    FO DES test set is now boosted up to $98.5\%$ when 50% of the dataset is considered.
    These results are rather significant from a machine learning perspective [Benchmarks.AI](#bib.bib44)
    , since these accuracies are already high and this newly labelled DES dataset
    represents $\sim 5\%$ of the the original SDSS training dataset. We have also
    computed ROC curves (see Figure [10](#A5.F10 "Figure 10 ‣ Appendix E Recursive
    Training ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey")) to provide an additional metric to quantify the improvement
    in classification accuracy due to recursive training.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, recursive training provides the means to continually enhance the
    classification accuracy of a neural network as new data becomes available. We
    have found that, averaging over ten models, the mean classification accuracies
    do improve when we retrain the model.
  prefs: []
  type: TYPE_NORMAL
- en: This novel approach provides us with the means to enhance SDSS galaxy classification,
    as shown in the top left panel of Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣
    Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey"). More importantly, it provides a way forward to gradually replace SDSS
    galaxy images in the training dataset that we need to construct DES galaxy catalogs
    at scale. A DES-only image training dataset will better capture the nature of
    images observed by DES, and would also enable us to better use data augmentations
    to model the effects of noise, making our neural network model more resilient
    to accurately classify galaxies at higher redshift, or that are contaminated by
    various sources of noise.
  prefs: []
  type: TYPE_NORMAL
- en: IV Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have presented the first application of deep transfer learning combined with
    distributed training for the classification of DES galaxies that overlap the footprint
    of the SDSS survey, achieving state-of-the-art accuracies $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99.6\%$. We described
    how to use our neural network classifier to label over 10,000 unlabelled DES galaxies
    that had not been observed in previous surveys. By truncating our neural network
    model, we used it as a feature extractor, and once combined with t-SNE, we presented
    visualizations which show that, through transfer learning, the neural network
    abstracted morphological information to clearly identify two distinct classes
    of galaxies in the unlabeled DES dataset. To get insights into the inner workings
    of our clustering algorithm, we have presented scientific visualizations of the
    clustering of the FO DES test set, which are available at NCSA ([2018a](#bib.bib41))
    and NCSA ([2018b](#bib.bib45)) .
  prefs: []
  type: TYPE_NORMAL
- en: We have also used t-SNE to inspect seemingly incorrect labels provided by our
    neural network model, and have found that these errors actually correspond to
    inaccurate human classifications in our SDSS testing dataset. We present an example
    of this nature in the visualization available at  NCSA ([2018a](#bib.bib41)),
    and in Figure [12](#A6.F12 "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep
    Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey").
  prefs: []
  type: TYPE_NORMAL
- en: Furthermore, adding the most confident predictions from our newly labeled DES
    galaxies, we have done recursive training, boosting the classification accuracy
    for the FO SDSS and DES test datasets. Averaging over ten models, we find improved
    accuracies as high as 99.5% for SDSS and 99% for DES.
  prefs: []
  type: TYPE_NORMAL
- en: This analysis provides a path forward to construct galaxy catalogs in DES using
    actual DES galaxies as training datasets. The combination of deep transfer learning
    with distributed training, and recursive training presents an alternative to do
    this analysis at scale in the LSST era.
  prefs: []
  type: TYPE_NORMAL
- en: V Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This research is part of the Blue Waters sustained-petascale computing project,
    which is supported by the National Science Foundation (awards OCI-0725070 and
    ACI-1238993) and the State of Illinois. Blue Waters is a joint effort of the University
    of Illinois at Urbana-Champaign and its National Center for Supercomputing Applications.
    We acknowledge support from the NCSA. We thank the [NCSA Gravity Group](http://gravity.ncsa.illinois.edu)
    for useful feedback, and Vlad Kindratenko for granting us access to state-of-the-art
    GPUs and HPC resources at the Innovative Systems Lab at NCSA. We are grateful
    to NVIDIA for donating several Tesla P100 and V100 GPUs that we used for our analysis.
    We thank the anonymous referee for carefully reading this manuscript, and providing
    constructive feedback to improve the presentation of our results.
  prefs: []
  type: TYPE_NORMAL
- en: This work used the Extreme Science and Engineering Discovery Environment (XSEDE),
    which is supported by National Science Foundation grant number ACI-1548562\. Specifically,
    it used the Bridges system, which is supported by NSF award number ACI-1445606,
    at the Pittsburgh Supercomputing Center (PSC). We gratefully acknowledge grant
    TG-PHY160053\. This research used resources of the Argonne Leadership Computing
    Facility, which is a DOE Office of Science User Facility supported under Contract
    DE-AC02-06CH11357.
  prefs: []
  type: TYPE_NORMAL
- en: This project used public archival data from the Dark Energy Survey (DES). Funding
    for the DES Projects has been provided by the U.S. Department of Energy, the U.S.
    National Science Foundation, the Ministry of Science and Education of Spain, the
    Science and Technology Facilities Council of the United Kingdom, the Higher Education
    Funding Council for England, the National Center for Supercomputing Applications
    at the University of Illinois at Urbana-Champaign, the Kavli Institute of Cosmological
    Physics at the University of Chicago, the Center for Cosmology and Astro-Particle
    Physics at the Ohio State University, the Mitchell Institute for Fundamental Physics
    and Astronomy at Texas A&M University, Financiadora de Estudos e Projetos, Fundação
    Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro, Conselho
    Nacional de Desenvolvimento Científico e Tecnológico and the Ministério da Ciência,
    Tecnologia e Inovação, the Deutsche Forschungsgemeinschaft and the Collaborating
    Institutions in the Dark Energy Survey.
  prefs: []
  type: TYPE_NORMAL
- en: The Collaborating Institutions are Argonne National Laboratory, the University
    of California at Santa Cruz, the University of Cambridge, Centro de Investigaciones
    Energéticas, Medioambientales y Tecnológicas–Madrid, the University of Chicago,
    University College London, the DES-Brazil Consortium, the University of Edinburgh,
    the Eidgenössische Technische Hochschule (ETH) Zürich, Fermi National Accelerator
    Laboratory, the University of Illinois at Urbana-Champaign, the Institut de Ciències
    de l’Espai (IEEC/CSIC), the Institut de Física d’Altes Energies, Lawrence Berkeley
    National Laboratory, the Ludwig-Maximilians Universität München and the associated
    Excellence Cluster Universe, the University of Michigan, the National Optical
    Astronomy Observatory, the University of Nottingham, The Ohio State University,
    the OzDES Membership Consortium, the University of Pennsylvania, the University
    of Portsmouth, SLAC National Accelerator Laboratory, Stanford University, the
    University of Sussex, and Texas A&M University. Based in part on observations
    at Cerro Tololo Inter-American Observatory, National Optical Astronomy Observatory,
    which is operated by the Association of Universities for Research in Astronomy
    (AURA) under a cooperative agreement with the National Science Foundation.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Riess *et al.* (1998) A. G. Riess, A. V. Filippenko, P. Challis, A. Clocchiatti,
    A. Diercks, P. M. Garnavich, R. L. Gilliland, C. J. Hogan, S. Jha, R. P. Kirshner,
    B. Leibundgut, M. M. Phillips, D. Reiss, B. P. Schmidt, R. A. Schommer, R. C. Smith,
    J. Spyromilio, C. Stubbs, N. B. Suntzeff,  and J. Tonry, [The Astronomical Journal  116, 1009
    (1998)](http://dx.doi.org/10.1086/300499), [astro-ph/9805201](http://arxiv.org/abs/astro-ph/9805201)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perlmutter *et al.* (1999) S. Perlmutter, G. Aldering, *et al.*, [Astrophys.
    J. 517, 565 (1999)](http://dx.doi.org/10.1086/307221), [astro-ph/9812133](http://arxiv.org/abs/astro-ph/9812133)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tonry *et al.* (2003) J. L. Tonry, B. P. Schmidt, B. Barris, P. Candia, P. Challis,
    A. Clocchiatti, A. L. Coil, A. V. Filippenko, P. Garnavich, C. Hogan, S. T. Holland,
    S. Jha, R. P. Kirshner, K. Krisciunas, B. Leibundgut, W. Li, T. Matheson, M. M. Phillips,
    A. G. Riess, R. Schommer, R. C. Smith, J. Sollerman, J. Spyromilio, C. W. Stubbs,
     and N. B. Suntzeff, [Astrophys. J. 594, 1 (2003)](http://dx.doi.org/10.1086/376865), [astro-ph/0305008](http://arxiv.org/abs/astro-ph/0305008)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Knop *et al.* (2003) R. A. Knop, G. Aldering, *et al.*, [Astrophys. J. 598, 102
    (2003)](http://dx.doi.org/10.1086/378560), [arXiv:astro-ph/0309368 [astro-ph]](http://arxiv.org/abs/astro-ph/0309368)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doi *et al.* (1993) M. Doi, M. Fukugita,  and S. Okamura, [MNRAS  264, 832 (1993)](http://dx.doi.org/10.1093/mnras/264.4.832).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wijesinghe *et al.* (2010) D. B. Wijesinghe, A. M. Hopkins, B. C. Kelly, N. Welikala,
     and A. J. Connolly, [MNRAS  404, 2077 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16424.x), [arXiv:1001.5322
    [astro-ph.GA]](http://arxiv.org/abs/1001.5322) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eisenstein *et al.* (2011) D. J. Eisenstein, D. H. Weinberg, E. Agol, H. Aihara,
    C. Allende Prieto, S. F. Anderson, J. A. Arns, É. Aubourg, S. Bailey, E. Balbinot,
     and et al., [The Astronomical Journal  142, 72 (2011)](http://dx.doi.org/10.1088/0004-6256/142/3/72), [arXiv:1101.1529
    [astro-ph.IM]](http://arxiv.org/abs/1101.1529) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conselice (2003) C. J. Conselice, [ApJS 147, 1 (2003)](http://dx.doi.org/10.1086/375001), [astro-ph/0303065](http://arxiv.org/abs/astro-ph/0303065)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lahav *et al.* (1995) O. Lahav, A. Naim, R. J. Buta, H. G. Corwin, G. de Vaucouleurs,
    A. Dressler, J. P. Huchra, S. van den Bergh, S. Raychaudhury, L. Sodre, Jr.,  and M. C. Storrie-Lombardi, [Science 267, 859
    (1995)](http://dx.doi.org/10.1126/science.267.5199.859), [astro-ph/9412027](http://arxiv.org/abs/astro-ph/9412027)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lahav *et al.* (1996) O. Lahav, A. Naim, L. Sodré, Jr.,  and M. C. Storrie-Lombardi, [MNRAS  283, 207
    (1996)](http://dx.doi.org/10.1093/mnras/283.1.207), [astro-ph/9508012](http://arxiv.org/abs/astro-ph/9508012)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Banerji *et al.* (2010) M. Banerji, O. Lahav, C. J. Lintott, F. B. Abdalla,
    K. Schawinski, S. P. Bamford, D. Andreescu, P. Murray, M. J. Raddick, A. Slosar,
    A. Szalay, D. Thomas,  and J. Vandenberg, [MNRAS  406, 342 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x), [arXiv:0908.2033](http://arxiv.org/abs/0908.2033)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dark Energy Survey Collaboration *et al.* (2016) Dark Energy Survey Collaboration
    *et al.*, [MNRAS  460, 1270 (2016)](http://dx.doi.org/10.1093/mnras/stw641), [arXiv:1601.00329](http://arxiv.org/abs/1601.00329)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LSST Dark Energy Science Collaboration (2012) LSST Dark Energy Science Collaboration, ArXiv
    e-prints  (2012), [arXiv:1211.0310 [astro-ph.CO]](http://arxiv.org/abs/1211.0310)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Domínguez Sánchez *et al.* (2018) H. Domínguez Sánchez, Huertas-Company, *et al.*, ArXiv
    e-prints , arXiv:1807.00807 (2018), [arXiv:1807.00807 [astro-ph.GA]](http://arxiv.org/abs/1807.00807)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chollet (2016) F. Chollet, ArXiv e-prints , arXiv:1610.02357 (2016), [arXiv:1610.02357
    [cs.CV]](http://arxiv.org/abs/1610.02357) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: George *et al.* (2018) D. George, H. Shen,  and E. A. Huerta, [Phys. Rev. D 97, 101501
    (2018)](http://dx.doi.org/10.1103/PhysRevD.97.101501).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Deng *et al.* (2009) J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li,  and L. Fei-Fei, in *Proc.
    CVPR* (2009).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tan *et al.* (2018) C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang,  and C. Liu, arXiv
    e-prints , arXiv:1808.01974 (2018), [arXiv:1808.01974 [cs.LG]](http://arxiv.org/abs/1808.01974)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Barchi *et al.* (2019) P. H. Barchi, R. R. de Carvalho, R. R. Rosa, R. Sautter,
    M. Soares-Santos, B. A. D. Marques,  and E. Clua, arXiv e-prints , arXiv:1901.07047
    (2019), [arXiv:1901.07047 [astro-ph.IM]](http://arxiv.org/abs/1901.07047) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lintott *et al.* (2011) C. Lintott, K. Schawinski, S. Bamford, A. Slosar, K. Land,
    D. Thomas, E. Edmondson, K. Masters, R. C. Nichol, M. J. Raddick, A. Szalay, D. Andreescu,
    P. Murray,  and J. Vandenberg, [MNRAS  410, 166 (2011)](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x), [arXiv:1007.3265
    [astro-ph.GA]](http://arxiv.org/abs/1007.3265) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: SDSS (2018) SDSS, “SDSS Skyserver,”  (2018), [http://skyserver.sdss.org/dr7/en/tools/search/sql.asp](http://skyserver.sdss.org/dr7/en/tools/search/sql.asp).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gropp *et al.* (1999) W. Gropp, E. Lusk,  and A. Skjellum, *Using MPI: Portable
    Programming with the Message-Passing Interface (2nd ed.), by William Gropp, Ewing
    Lusk and Anthony Skjellum, Scientific and Engineering Computation Series, MIT
    Press, Cambridge, MA, 1999.* (1999).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kramer *et al.* (2015) W. Kramer, M. Butler, G. Bauer, K. Chadalavada,  and C. Mendes, in *High
    Performance Parallel I/O*, edited by Prabhat and Q. Koziol (CRC Publications,
    Taylor and Francis Group, 2015) pp. 17–32\.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DES (2018) DES, “NCSA DESaccess Web,”  (2018), [https://deslabs.ncsa.illinois.edu/](https://deslabs.ncsa.illinois.edu/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Keras (2018) Keras, “Keras: The Python Deep Learning library,”  (2018), [https://keras.io/](https://keras.io/).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Abadi *et al.* (2016) M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro,
    G. S. Corrado, A. Davis, J. Dean,  and M. Devin, arXiv preprint arXiv:1603.04467 
    (2016).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Russakovsky *et al.* (2014) O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
    S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg,  and L. Fei-Fei, ArXiv
    e-prints , arXiv:1409.0575 (2014), [arXiv:1409.0575 [cs.CV]](http://arxiv.org/abs/1409.0575)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy *et al.* (2015) C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens,  and Z. Wojna, ArXiv
    e-prints , arXiv:1512.00567 (2015), [arXiv:1512.00567 [cs.CV]](http://arxiv.org/abs/1512.00567)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He *et al.* (2015) K. He, X. Zhang, S. Ren,  and J. Sun, ArXiv e-prints , arXiv:1512.03385
    (2015), [arXiv:1512.03385 [cs.CV]](http://arxiv.org/abs/1512.03385) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonyan and Zisserman (2014) K. Simonyan and A. Zisserman, ArXiv e-prints , arXiv:1409.1556
    (2014), [arXiv:1409.1556 [cs.CV]](http://arxiv.org/abs/1409.1556) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kornblith *et al.* (2018) S. Kornblith, J. Shlens,  and Q. V. Le, “Do better
    imagenet models transfer better?”  (2018), [arXiv:1805.08974](http://arxiv.org/abs/arXiv:1805.08974)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Andrej Karpathy (2018) Andrej Karpathy, “Convolutional Neural Networks for Visual
    Recognition,”  (2018), [http://cs231n.github.io/neural-networks-2/](http://cs231n.github.io/neural-networks-2/).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zeiler and Fergus (2014) M. D. Zeiler and R. Fergus, in *ECCV* (2014).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yosinski *et al.* (2014) J. Yosinski, J. Clune, Y. Bengio,  and H. Lipson, in [*Proceedings
    of the 27th International Conference on Neural Information Processing Systems
    - Volume 2*](http://dl.acm.org/citation.cfm?id=2969033.2969197), NIPS’14 (MIT
    Press, Cambridge, MA, USA, 2014) pp. 3320–3328\.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ackermann *et al.* (2018) S. Ackermann, K. Schawinski, C. Zhang, A. K. Weigel,
     and M. D. Turp, [MNRAS  479, 415 (2018)](http://dx.doi.org/10.1093/mnras/sty1398), [arXiv:1805.10289
    [astro-ph.IM]](http://arxiv.org/abs/1805.10289) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: XSEDE (2018) XSEDE, “The Approach to Bridges,”  (2018), [https://www.psc.edu/bridges](https://www.psc.edu/bridges).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kingma and Ba (2014) D. P. Kingma and J. Ba, [CoRR abs/1412.6980 (2014)](http://arxiv.org/abs/1412.6980).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sergeev and Balso (2018) A. Sergeev and M. D. Balso, arXiv preprint arXiv:1802.05799 
    (2018).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goyal *et al.* (2017) P. Goyal, P. Dollár, R. B. Girshick, P. Noordhuis, L. Wesolowski,
    A. Kyrola, A. Tulloch, Y. Jia,  and K. He, [CoRR abs/1706.02677 (2017)](http://arxiv.org/abs/1706.02677), [arXiv:1706.02677](http://arxiv.org/abs/1706.02677)
    .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: van der Maaten and Hinton (2008) L. van der Maaten and G. Hinton, Journal of
    Machine Learning Research 9, 2579 (2008).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NCSA (2018a) NCSA, “Unsupervised learning and data clustering for the construction
    of Galaxy Catalogs in the Dark Energy Survey,”  (2018a), [https://www.youtube.com/watch?v=n5rI573i6ws](https://www.youtube.com/watch?v=n5rI573i6ws).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wattenberg *et al.* (2016) M. Wattenberg, F. ViÃ©gas,  and I. Johnson, [Distill 
    (2016), 10.23915/distill.00002](http://dx.doi.org/10.23915/distill.00002).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao and Wang (2017) Y. Cao and L. Wang, arXiv e-prints , arXiv:1708.03229 (2017), [arXiv:1708.03229
    [cs.AI]](http://arxiv.org/abs/1708.03229) .
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: (44) Benchmarks.AI, “MNIST. Classify handwritten digits,” [https://benchmarks.ai/mnist](https://benchmarks.ai/mnist).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: NCSA (2018b) NCSA, “Deep transfer learning at scale for cosmology,”  (2018b), [https://www.youtube.com/watch?v=1F3q7M8QjTQ](https://www.youtube.com/watch?v=1F3q7M8QjTQ).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Neural network architecture
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The top panel in Figure [7](#A1.F7 "Figure 7 ‣ Appendix A Neural network architecture
    ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey") presents the architecture of the pre-trained Xception model Chollet ([2016](#bib.bib15))
    used in these studies. The bottom panel of Figure [7](#A1.F7 "Figure 7 ‣ Appendix
    A Neural network architecture ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") shows the fully connected layers,
    and classifier added at the second-to-last layer of the pre-trained Xception model.
    This is labeled as 2048-dimensional vectors in the Exit flow diagram. Following
    this procedure, we truncate our neural network classifier and turn it into a feature
    extractor, which we can use in combination with t-SNE to do unsupervised clustering.
    Note that we use t-SNE just as a visual aid. The labelling of unlabeled DES datasets
    is done using our neural network classifier.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2b260eb7e8ee43f4ec7e627d7d4f7a96.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Top panel: Xception model Chollet ([2016](#bib.bib15)). Bottom panel:
    fully connected layers, and classifier added at the bottleneck of the pre-trained
    Xception model.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix B Data Augmentation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b50be3be06bbbafa92bf119f0c58c827.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: Data augmentations include random rotations of up to 45 degrees,
    random flips, height and width shifts and zooms of up to a factor of 1.3'
  prefs: []
  type: TYPE_NORMAL
- en: To expose the neural network to a variety of potential scenarios for classification,
    we augment original galaxy images with random vertical and horizontal flips, random
    rotations, height and width shifts and zooms, as shown in Figure [8](#A2.F8 "Figure
    8 ‣ Appendix B Data Augmentation ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey"). The range for random rotations
    is set up to a maximum of 45^∘, i.e. for each iteration of training the neural
    net sees the input image rotated randomly between -45^∘ and 45^∘. Similarly the
    maximum range for random height and width shifts, as well as zooming factor is
    set to 0.3\. Note that for each iteration of training all these image transformations
    are applied but with random values within the defined ranges.
  prefs: []
  type: TYPE_NORMAL
- en: This approach not only synthetically increases the training dataset, but also
    makes the neural network invariant to rotations, shifts, flips and combinations
    of these, and also introduces scale invariance.
  prefs: []
  type: TYPE_NORMAL
- en: Appendix C Classification predictions for unlabelled DES galaxies
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Figure [9](#A3.F9 "Figure 9 ‣ Appendix C Classification predictions for unlabelled
    DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey") presents high-confidence neural network predictions
    for unlabelled DES galaxies. The robustness of these predictions were tested with
    our unsupervised clustering algorithm, finding that these classifications, based
    on the morphological features extracted from the DES images in three filters,
    are meaningful, as shown in the t-SNE projections in Figure [5](#S3.F5 "Figure
    5 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey").
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dfa896728d366964477e35bd30a93c21.png)    ![Refer to
    caption](img/1992d574fe5a6ded936ce2e433df6637.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Sample of high confidence predictions for spiral (left panel) and
    elliptical galaxies (right panel) on an unlabelled DES set.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix D Scaling Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In Table[3](#A4.T3 "Table 3 ‣ Appendix D Scaling Results ‣ Deep Learning at
    Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") the
    training is comprised of three stages: (1) freeze the base model and train added
    dense layers; (2) freeze layers 0-39, and train layers 40+; (3) freeze layers
    0-1 and train all layers 2+. The number of epochs for each stage is given in the
    third column. The total time only includes the time for the training (all three
    stages), but not the time for initialization (launching jobs, loading Python modules,
    data preparation, etc), which we found was minimal compared to the training time.'
  prefs: []
  type: TYPE_NORMAL
- en: '| GPUs | Time per epoch (s) | # epochs | Total time | Accuracy | Val Accuracy
    |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 1 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 410 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 922 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1626 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 11 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 4 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 4h 44 m | 0.9992 | 0.9979 |'
  prefs: []
  type: TYPE_TB
- en: '| 2 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 231 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 481 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 830 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 6 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 4 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1h 47m | 0.9993 | 0.9990 |'
  prefs: []
  type: TYPE_TB
- en: '| 4 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 119 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 246 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 427 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 5 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 7 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1h 12m | 0.9995 | 0.9990 |'
  prefs: []
  type: TYPE_TB
- en: '| 8 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 64 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 124 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 214 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 6 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 8 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 42m | 0.9991 | 0.9979 |'
  prefs: []
  type: TYPE_TB
- en: '| 16 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 35 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 63 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 109 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 4 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 17 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 36m | 0.9993 | 0.9980 |'
  prefs: []
  type: TYPE_TB
- en: '| 32 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 20 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 31 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 53 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 6 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 12 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 14m | 0.9993 | 0.9990 |'
  prefs: []
  type: TYPE_TB
- en: '| 64 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 13 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 15 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 27 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 5 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 15 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 8m | 0.9993 | 0.9990 |'
  prefs: []
  type: TYPE_TB
- en: 'Table 3: Training results and timings using different numbers of K80 GPUs for
    the Xception model. Validation Accuracy results are given in the final column.
    The training includes three stages: (1) train the dense layers (base layers are
    frozen); (2) train layer 40+ (layers 0-39 are frozen); (3) train Layer 2+ (layer
    0-1 are frozen). The number of epochs shown are for each training stage. The batch
    size is set to be 16\. The benchmarks was done on Cooley supercomputer at Argonne
    Leadership Computer Facility (https://www.alcf.anl.gov/user-guides/cooley).'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix E Recursive Training
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In addition to providing results for recursive training using ten different
    models (see Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey")), herein we
    also provide ROC results for a typical model out of our ten samples. These ROC
    results indicate that recursive training indeed leads to an increase in classification
    accuracy both for SDSS and DES.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e5145fe36c092fe692ea9d16cee83885.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/0e6991dae23c0dd1c220f579f8ed7851.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: Top panels: FO SDSS test sets. Bottom panels: FO DES test sets.'
  prefs: []
  type: TYPE_NORMAL
- en: Appendix F Misclassified Examples
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We present a gallery of misclassified examples from our high probability (HP)
    test sets. As shown in Figure [11](#A6.F11 "Figure 11 ‣ Appendix F Misclassified
    Examples ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey"), we have only four instances of this nature, all from HP
    DES test set, and one of these corresponds to a noise artifact in the telescope.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6875505ae4d413cf1f9f34dad1dc7b3a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: There are only four misclassified examples from HP test sets. Of
    these four images, one is a noise artifact in the telescope.'
  prefs: []
  type: TYPE_NORMAL
- en: In Figure [12](#A6.F12 "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep
    Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")
    we present a sample of inaccurate predictions on the full overlap (FO) test sets.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9358f4964bb2f04f6a383922984b69a7.png) ![Refer to caption](img/dde6e8b58c076f7171bfb64a1a18b9fa.png)'
  prefs: []
  type: TYPE_IMG
- en: '![Refer to caption](img/26ccd8e183cc4f23a0317f66281efdf4.png) ![Refer to caption](img/7778ee366689020f2bfd3d9a4eb1292c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: A sample of misclassification on FO test sets. The debiased galaxy
    zoo probabilities used to produce the ground truth labels for each image are shown.
    Notice that the debiased galaxy zoo probabilities for each class are very low
    and close to each other, i.e., these samples represent low confidence ground truth
    labels.'
  prefs: []
  type: TYPE_NORMAL
