- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 分类：未分类
- en: 'date: 2024-09-06 20:07:05'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:07:05
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1812.02183] Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1812.02183] 大规模深度学习用于构建暗能量调查中的星系目录'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1812.02183](https://ar5iv.labs.arxiv.org/html/1812.02183)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1812.02183](https://ar5iv.labs.arxiv.org/html/1812.02183)
- en: Deep Learning at Scale
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 大规模深度学习
- en: for the Construction of Galaxy Catalogs
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 用于构建星系目录
- en: in the Dark Energy Survey
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: 在暗能量调查中
- en: Asad Khan NCSA, University of Illinois at Urbana-Champaign, Urbana, Illinois
    61801, USA Department of Physics, University of Illinois at Urbana-Champaign,
    Urbana, Illinois 61801, USA    E. A. Huerta NCSA, University of Illinois at Urbana-Champaign,
    Urbana, Illinois 61801, USA Department of Astronomy, University of Illinois at
    Urbana-Champaign, Urbana, Illinois 61801, USA    Sibo Wang NCSA, University of
    Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA    Robert Gruendl NCSA,
    University of Illinois at Urbana-Champaign, Urbana, Illinois 61801, USA Department
    of Astronomy, University of Illinois at Urbana-Champaign, Urbana, Illinois 61801,
    USA    Elise Jennings Argonne National Laboratory, Leadership Computing Facility,
    Lemont, Illinois 60439, USA    Huihuo Zheng Argonne National Laboratory, Leadership
    Computing Facility, Lemont, Illinois 60439, USA
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Asad Khan NCSA, 伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那 61801，美国 物理系，伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那
    61801，美国    E. A. Huerta NCSA, 伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那 61801，美国 天文学系，伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那
    61801，美国    Sibo Wang NCSA, 伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那 61801，美国    Robert Gruendl
    NCSA, 伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那 61801，美国 天文学系，伊利诺伊大学厄本那-香槟分校，伊利诺伊州厄本那 61801，美国   
    Elise Jennings 阿贡国家实验室，领导计算设施，伊利诺伊州莱蒙特 60439，美国    Huihuo Zheng 阿贡国家实验室，领导计算设施，伊利诺伊州莱蒙特
    60439，美国
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The scale of ongoing and future electromagnetic surveys pose formidable challenges
    to classify astronomical objects. Pioneering efforts on this front include citizen
    science campaigns adopted by the Sloan Digital Sky Survey (SDSS). SDSS datasets
    have been recently used to train neural network models to classify galaxies in
    the Dark Energy Survey (DES) that overlap the footprint of both surveys. Herein,
    we demonstrate that knowledge from deep learning algorithms, pre-trained with
    real-object images, can be transferred to classify galaxies that overlap both
    SDSS and DES surveys, achieving state-of-the-art accuracy $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99.6\%$. We demonstrate
    that this process can be completed within just eight minutes using distributed
    training. While this represents a significant step towards the classification
    of DES galaxies that overlap previous surveys, we need to initiate the characterization
    of unlabelled DES galaxies in new regions of parameter space. To accelerate this
    program, we use our neural network classifier to label over ten thousand unlabelled
    DES galaxies, which do not overlap previous surveys. Furthermore, we use our neural
    network model as a feature extractor for unsupervised clustering and find that
    unlabeled DES images can be grouped together in two distinct galaxy classes based
    on their morphology, which provides a heuristic check that the learning is successfully
    transferred to the classification of unlabelled DES images. We conclude by showing
    that these newly labeled datasets can be combined with unsupervised recursive
    training to create large-scale DES galaxy catalogs in preparation for the Large
    Synoptic Survey Telescope era.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 进行中的和未来的电磁调查规模对分类天文对象提出了严峻挑战。前沿的努力包括由斯隆数字天空调查（SDSS）采用的公民科学活动。SDSS数据集最近被用来训练神经网络模型，以分类在暗能量调查（DES）中与两个调查重叠的星系。在这里，我们展示了通过深度学习算法获得的知识，可以转移到分类同时重叠SDSS和DES调查的星系，实现了**99.6%**的最先进准确率。我们展示了这一过程可以在八分钟内通过分布式训练完成。虽然这代表了对重叠以前调查的DES星系分类的重大进展，但我们需要开始对新参数空间区域中未标记的DES星系进行表征。为了加速这一程序，我们使用我们的神经网络分类器来标记超过一万多个未标记的DES星系，这些星系不与以前的调查重叠。此外，我们将神经网络模型用作无监督聚类的特征提取器，并发现未标记的DES图像可以根据其形态分为两种不同的星系类别，这提供了一个启发式检查，表明学习已成功转移到未标记的DES图像分类中。我们通过展示这些新标记的数据集可以与无监督递归训练结合起来，为大规模DES星系目录的创建做准备，为大型同步巡天望远镜时代做好准备。
- en: 'pacs:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 'pacs:'
- en: Valid PACS appear here
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 有效的PACS在此出现
- en: 'Keywords: Deep Learning, Convolutional Neural Networks, Sloan Digital Sky Survey,
    Dark Energy Survey, Large Synoptic Survey Telescope, Galaxy Catalogs, Unsupervised
    Learning, Data Clustering'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 关键词：深度学习，卷积神经网络，斯隆数字天空调查，暗能量调查，大宽场巡天望远镜，星系目录，无监督学习，数据聚类
- en: I Introduction
  id: totrans-15
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Electromagnetic surveys provide key insights into the large scale structure
    of the Universe, its geometry and evolution in cosmic time. As the depth and scale
    of these surveys continue to increase in years to come, they will push back the
    frontiers of our understanding of dark matter and dark energy Riess *et al.* ([1998](#bib.bib1));
    Perlmutter *et al.* ([1999](#bib.bib2)); Tonry *et al.* ([2003](#bib.bib3)); Knop *et al.*
    ([2003](#bib.bib4)).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 电磁调查提供了对宇宙大尺度结构、几何和宇宙时间演化的关键见解。随着这些调查的深度和规模在未来几年中不断增加，它们将推动我们对暗物质和暗能量的理解的前沿*Riess
    et al.* ([1998](#bib.bib1)); *Perlmutter et al.* ([1999](#bib.bib2)); *Tonry et
    al.* ([2003](#bib.bib3)); *Knop et al.* ([2003](#bib.bib4))。
- en: The classification of astrophysical objects has been pursued in the past using
    a diverse set of tools. For instance, galaxies have been classified using their
    photometric properties, achieving classification accuracies $\sim 85\%$ Doi *et al.*
    ([1993](#bib.bib5)). Other methods to classify galaxies according to their morphology
    have taken into account their physical properties across multiple wavelengths.
    For instance, the method introduced in Wijesinghe *et al.* ([2010](#bib.bib6)),
    considered a sample of galaxies from the Sloan Digital Sky Survey (SDSS) Eisenstein *et al.*
    ([2011](#bib.bib7)), using the five SDSS filters $(u,\,g,\,r,\,i,\,z)$, and then
    used a combination of shapelet decomposition and Principal Components Analysis
    (PCA). Other methods for galaxy classification include Concentration-Asymmetry-Smoothness
    (CAS) Conselice ([2003](#bib.bib8)), and machine learning, including artificial
    neural networks and PCAs Lahav *et al.* ([1995](#bib.bib9), [1996](#bib.bib10));
    Banerji *et al.* ([2010](#bib.bib11)).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 天体物理对象的分类过去使用了多种工具。例如，星系的分类通过其光度特性实现，达到了约85%的分类准确率*Doi et al.* ([1993](#bib.bib5))。其他根据星系形态进行分类的方法则考虑了它们在多个波长下的物理特性。例如，*Wijesinghe
    et al.* ([2010](#bib.bib6)) 引入的方法，考虑了来自斯隆数字天空调查（SDSS）*Eisenstein et al.* ([2011](#bib.bib7))
    的星系样本，使用了五个SDSS滤光片 $(u,\,g,\,r,\,i,\,z)$，然后结合了形状分解和主成分分析（PCA）。其他星系分类方法包括集中度-不对称度-光滑度（CAS）*Conselice*
    ([2003](#bib.bib8))，以及机器学习，包括人工神经网络和主成分分析（PCA）*Lahav et al.* ([1995](#bib.bib9),
    [1996](#bib.bib10)); *Banerji et al.* ([2010](#bib.bib11))。
- en: In recent years, citizen science campaigns have played a key role to classify
    thousands of celestial objects in astronomical surveys. SDSS is an archetypical
    example of a successful approach to classify hundreds of thousands of galaxies.
    As electromagnetic surveys continue to increase their depth and coverage, campaigns
    of this nature may lack scalability. For instance, within six years of operation,
    the Dark Energy Survey (DES) Dark Energy Survey Collaboration *et al.* ([2016](#bib.bib12))
    observed over three hundred million galaxies, a number that will be surpassed
    by the observing capabilities of the Large Synoptic Survey Telescope (LSST) LSST
    Dark Energy Science Collaboration ([2012](#bib.bib13)). In brief, there is a pressing
    need to explore new approaches to maximize the science throughput of next-generation
    electromagnetic surveys. A promising paradigm is the convergence of deep learning
    and large scale computing to address the imminent increase in data volume, complexity,
    and latency of observations of LSST-type surveys, the theme of this paper.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，公民科学项目在分类天文调查中的数千个天体方面发挥了关键作用。SDSS 是成功分类数十万星系的典型例子。随着电磁调查不断增加其深度和覆盖范围，这类项目可能缺乏可扩展性。例如，在六年的运行时间内，暗能量调查（DES）*Dark
    Energy Survey Collaboration* ([2016](#bib.bib12)) 观测了超过三亿个星系，这一数字将被大宽场巡天望远镜（LSST）*LSST
    Dark Energy Science Collaboration* ([2012](#bib.bib13)) 的观测能力所超越。简而言之，迫切需要探索新方法，以最大化下一代电磁调查的科学产出。一个有前景的范式是深度学习和大规模计算的融合，以应对LSST类型调查中数据量、复杂性和延迟的迅速增加，这是本文的主题。
- en: An innovative idea to accomplish this prospect consists of leveraging what SDSS
    has already done, and try to use it as seed information to classify objects in
    DES data. Such idea has been explored in Domínguez Sánchez *et al.* ([2018](#bib.bib14)),
    where SDSS galaxies that overlap the DES footprint were used to train neural network
    models to classify DES galaxies that were also observed by SDSS, reporting classification
    accuracies $\sim 95\%$ Domínguez Sánchez *et al.* ([2018](#bib.bib14)).
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 实现这一前景的一个创新想法是利用SDSS已经完成的工作，并尝试将其作为种子信息来分类DES数据中的对象。这一想法在Domínguez Sánchez *et al.*
    ([2018](#bib.bib14))中得到了探讨，其中使用了重叠DES区域的SDSS星系来训练神经网络模型，以分类那些也被SDSS观测到的DES星系，报告了分类准确度约为$\sim
    95\%$ Domínguez Sánchez *et al.* ([2018](#bib.bib14))。
- en: 'While the aforementioned approach provides a way to classify DES galaxies that
    overlap previous surveys, key issues remain: (i) deep learning algorithms for
    image classification have been trained with hundreds of millions of images to
    achieve state-of-the-art classification accuracy Chollet ([2016](#bib.bib15)).
    If one attempts to train a neural network model from the ground up using just
    a few tens of thousands of SDSS galaxies, then the fully trained neural network
    model may not achieve state-of-the-art classification accuracy, or exhibit overfitting George *et al.*
    ([2018](#bib.bib16)); (ii) while training a neural network model with SDSS galaxies,
    and then applying it to classify DES galaxies that overlap the footprint of both
    SDSS and DES is an important validation study for the applicability of deep learning
    for classification analyses, we also need to demonstrate the applicability of
    this approach for DES galaxies that have not yet been observed in previous surveys.
    This can only be accomplished once more DES galaxies are labeled; (iii) newly
    labelled DES galaxies, that do not overlap previous surveys, can be used as training
    datasets to enhance the classification accuracy of deep learning algorithms. One
    can easily realize that this approach will lead to the creation of TB-size training
    datasets. In this scenario, it will be essential to design distributed algorithms
    to reduce the training stage at a minimum, while retaining state-of-the-art classification
    accuracy.'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管上述方法提供了一种分类与之前调查重叠的DES星系的方法，但仍存在关键问题：(i) 用于图像分类的深度学习算法已经通过数亿张图像的训练，达到了最先进的分类准确度 Chollet
    ([2016](#bib.bib15))。如果尝试从头开始使用仅仅几万张SDSS星系图像来训练一个神经网络模型，那么训练完成的神经网络模型可能无法达到最先进的分类准确度，或可能出现过拟合 George *et al.*
    ([2018](#bib.bib16))；(ii) 在用SDSS星系训练神经网络模型后，再将其应用于分类与SDSS和DES都有重叠区域的DES星系，是验证深度学习分类分析适用性的重要研究，我们还需要展示这种方法在尚未被之前调查观测到的DES星系中的适用性。这只能在更多DES星系被标注之后实现；(iii)
    新标注的、未与之前调查重叠的DES星系可以作为训练数据集来提高深度学习算法的分类准确度。可以很容易地意识到，这种方法将导致TB级别的训练数据集的创建。在这种情况下，设计分布式算法以尽可能减少训练阶段，同时保持最先进的分类准确度，将是至关重要的。
- en: 'In this article we describe an approach to address the aforementioned challenges
    by bringing together several deep learning methods in an innovative manner. Key
    highlights of this study include:'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们描述了一种以创新的方式结合多种深度学习方法来解决上述挑战的方法。该研究的主要亮点包括：
- en: $\bullet$
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We transfer knowledge from the state-of-the-art neural network model for image
    classification, Xception Chollet ([2016](#bib.bib15)), trained with the ImageNet
    dataset Deng *et al.* ([2009](#bib.bib17)), to classify SDSS galaxy images, achieving
    state-of-the-art accuracies $99.8\%$. Note that transfer learning between similar
    datasets, such as SDSS and DES, has been traditionally used in the computer science
    literature Tan *et al.* ([2018](#bib.bib18)). In stark contrast, we use a pre-trained
    model for real-world object recognition, and then transfer its knowledge to classify
    SDSS and DES galaxies. To the best of our knowledge this is the first application
    of deep transfer learning for galaxy classification¹¹1While this paper was under
    review, a study on SDSS galaxy classification was presented in which disparate
    datasets for transfer learning are used Barchi *et al.* ([2019](#bib.bib19))..
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们将用于图像分类的最先进神经网络模型Xception Chollet ([2016](#bib.bib15))，通过训练ImageNet数据集 Deng *et al.*
    ([2009](#bib.bib17))的知识迁移到SDSS银河图像分类中，达到了最先进的准确率$99.8\%$。需要注意的是，类似数据集之间的迁移学习，例如SDSS和DES，传统上在计算机科学文献中已被使用 Tan *et al.*
    ([2018](#bib.bib18))。与此形成鲜明对比的是，我们使用一个预训练模型进行现实世界物体识别，然后将其知识迁移到SDSS和DES银河分类中。据我们所知，这是首次将深度迁移学习应用于银河分类¹¹1在本文审稿期间，出现了一项关于SDSS银河分类的研究，其中使用了不同的数据集进行迁移学习 Barchi *et al.*
    ([2019](#bib.bib19))。
- en: $\bullet$
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: To streamline and accelerate this method, we introduce the first application
    of deep transfer learning and distributed training in cosmology, reducing the
    training stage of the Xception model with galaxy image datasets from five hours
    to just eight minutes, using 64 K80 GPUs in the Cooley supercomputer.
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了简化和加速这一方法，我们首次在宇宙学中引入深度迁移学习和分布式训练，将使用64个K80 GPU在Cooley超级计算机上训练Xception模型的银河图像数据集的时间从五小时缩短至仅八分钟。
- en: $\bullet$
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We show that our neural network model trained by transfer learning achieves
    state-of-the-art accuracy, $99.6\%$, to classify DES galaxies that overlap the
    footprint of the SDSS survey.
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们展示了通过迁移学习训练的神经网络模型在分类与SDSS调查重叠的DES银河时达到了最先进的准确率$99.6\%$。
- en: $\bullet$
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: We use our neural network classifier to label over ten thousand unlabeled DES
    galaxies that have not been observed in previous surveys. We then turn our neural
    network model into a feature extractor to show that these unlabeled datasets can
    be clustered according to their morphology, forming two distinct datasets.
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们使用神经网络分类器对超过一万颗在先前调查中未被观测的未标注DES银河进行标注。然后我们将神经网络模型转化为特征提取器，显示这些未标注的数据集可以根据其形态进行聚类，形成两个不同的数据集。
- en: $\bullet$
  id: totrans-30
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: $\bullet$
- en: Finally, we use the newly labelled DES images and do unsupervised recursive
    training to retrain our deep transfer learning model, boosting its accuracy to
    classify unlabeled DES galaxies in bulk in new regions of parameter space.
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最终，我们使用新标注的DES图像进行无监督递归训练，以重新训练我们的深度迁移学习模型，提高其在新参数空间区域批量分类未标注DES银河的准确率。
- en: The combination of all the aforementioned deep learning methods lays the foundations
    to exploit deep transfer learning at scale, data clustering and recursive training
    to produce large-scale galaxy catalogs in the LSST era LSST Dark Energy Science
    Collaboration ([2012](#bib.bib13)).
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 所有上述深度学习方法的结合为在LSST时代利用大规模深度迁移学习、数据聚类和递归训练生成大规模银河目录奠定了基础LSST Dark Energy Science
    Collaboration ([2012](#bib.bib13))。
- en: This paper is organized as follows. Section [II](#S2 "II Methods ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") presents
    the approach followed to curate the datasets and deep learning algorithms designed
    and trained for our analyses. In section [III](#S3 "III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey"),
    we demonstrate the applicability of our methods to classify galaxies in SDSS,
    galaxies that overlap SDSS and DES, and finally, the applicability of our approach
    to correctly classify thousands of unlabelled DES galaxies. Finally, section [IV](#S4
    "IV Conclusion ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey") summarizes our findings and future directions of work.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的组织如下。在第 [II](#S2 "II Methods ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey") 部分，介绍了用于整理数据集以及为我们的分析设计和训练的深度学习算法的方法。在第
    [III](#S3 "III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") 部分，我们演示了我们的方法适用于对SDSS中的星系、SDSS和DES重叠的星系以及最终应用我们的方法正确分类成千上万个未标记的DES星系。最后，在第
    [IV](#S4 "IV Conclusion ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") 部分，总结了我们的发现和未来的工作方向。
- en: II Methods
  id: totrans-34
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 方法
- en: In this section we describe the SDSS and DES datasets we have curated for our
    studies, the neural network model we use for deep transfer learning, and how we
    can use unsupervised recursive training to create galaxy catalogs at scale.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们描述了为我们的研究精选的SDSS和DES数据集，我们用于深度迁移学习的神经网络模型，以及如何使用无监督递归训练来大规模创建星系目录。
- en: II.1 Data Curation for SDSS and DES
  id: totrans-36
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II.1 SDSS和DES数据整理
- en: We use a subset of SDSS Data Release (DR) 7 images for which we have high confidence
    classifications through the Galaxy Zoo project, i.e., we only choose galaxies
    with debiased probability greater than 0.985 for combined spirals, and 0.926 for
    ellipticals, respectively, as shown in Table 2 of  Lintott *et al.* ([2011](#bib.bib20)).
    We choose these cutoff thresholds to ensure that; (i) the galaxies used for training
    the neural network have robust and accurate classifications; and (ii) the representation
    of both classes in the training and test datasets are balanced. We then divide
    these images into three separate datasets for training, validation and testing.
    The validation set is used to monitor the accuracy and loss when training and
    fine-tuning our deep neural network, and hence serves to optimize hyperparameters,
    such as learning rate and number of epochs, for training.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 我们使用了SDSS数据发布（DR）7图像的子集，通过Galaxy Zoo项目对其进行高置信度分类，即我们只选择具有联合螺旋的偏向概率大于0.985和椭圆的偏向概率大于0.926的星系，分别如
    [2011](#bib.bib20) 中的表2所示。我们选择这些截断阈值是为了确保：（i）用于训练神经网络的星系具有健壮和准确的分类；（ii）训练和测试数据集中两个类别的表示是平衡的。然后，我们将这些图像分成三个单独的数据集，用于训练、验证和测试。验证集用于在训练和微调深度神经网络时监控准确性和损失，因此用于优化超参数，例如学习速率和训练的时期数。
- en: Two test sets are carefully constructed so that the images in each set lie in
    both the SDSS and DES footprints. The first test set consists of images with Galazy
    Zoo classification confidence similar to that of the training set, i.e., a high
    probability cut-off is introduced. This test set is hence labelled High Probability
    (HP) Test Set, and there are two versions, one for each survey, i.e., HP SDSS
    and HP DES. Just as in the training set, the images for SDSS are obtained from
    (DR) 7 and the corresponding images for DES are obtained from the DES DR1 data
    release. Furthermore, a second test set is created without introducing any probability
    thresholds on Galaxy Zoo classification confidence. This set consists of almost
    all galaxies lying in both the SDSS and DES footprints, and
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 两个测试集都经过精心构建，以使每个集合中的图像都位于SDSS和DES的区域内。第一个测试集由具有与训练集类似的Galaxy Zoo分类信心的图像组成，即引入了高概率截断。因此，此测试集标记为高概率（HP）测试集，每个调查都有两个版本，即HP
    SDSS和HP DES。与训练集一样，SDSS的图像来自（DR）7，对应的DES图像来自DES DR1数据发布。此外，第二个测试集是在Galaxy Zoo分类信心上没有引入任何概率阈值而创建的。该集合包含几乎所有位于SDSS和DES区域内的星系，以及
- en: '|       Dataset |       Spirals |       Ellipticals |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|       数据集 |       螺旋形 |       椭圆形 |'
- en: '|       Training set |       18,352 |       18,268 |'
  id: totrans-40
  prefs: []
  type: TYPE_TB
  zh: '|       训练集 |       18,352 |       18,268 |'
- en: '|       HP SDSS Test Set |       516 |       550 |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|       HP SDSS 测试集 |       516 |       550 |'
- en: '|       HP DES    Test Set |       516 |       550 |'
  id: totrans-42
  prefs: []
  type: TYPE_TB
  zh: '|       HP DES    测试集 |       516 |       550 |'
- en: '|       FO SDSS Test Set |       6,677 |       5,904 |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|       FO SDSS 测试集 |       6,677 |       5,904 |'
- en: '|       FO DES    Test Set |       6,677 |       5,904 |'
  id: totrans-44
  prefs: []
  type: TYPE_TB
  zh: '|       FO DES 测试集 |       6,677 |       5,904 |'
- en: 'Table 1: Summary of the SDSS and DES datasets used for training and testing.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：用于训练和测试的 SDSS 和 DES 数据集的总结。
- en: '![Refer to caption](img/24a96a2b01918f1c9e2b785e5c583b3a.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/24a96a2b01918f1c9e2b785e5c583b3a.png)'
- en: 'Figure 1: Violin Plots of Galaxy Zoo Probability Distributions for galaxies
    in each dataset. Probability threshold cutoffs, 98.5% for spiral and 92.6% for
    elliptical, are shown as red dashed lines. These cutoffs have been selected to
    ensure that the datasets of both galaxy types are balanced.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：每个数据集中星系 Zoo 概率分布的小提琴图。概率阈值截断线，螺旋星系为 98.5%，椭圆星系为 92.6%，以红色虚线表示。这些截断值已经选择，以确保两个星系类型的数据集平衡。
- en: hence is labelled Full Overlap (FO) Test Set. Again there are two versions,
    FO SDSS and FO DES. The motivation behind creating this second test set is that
    the galaxy profiles in the unlabelled DES dataset will more closely match those
    in FO test sets. Hence FO test set serves as a good evaluation metric of the performance
    of our neural net on the ultimate task of classifying all unlabelled galaxies
    in the DES catalogue.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 因此被标记为全重叠（FO）测试集。再次有两个版本，FO SDSS 和 FO DES。创建第二个测试集的动机是，未标记的 DES 数据集中的星系特征会更接近
    FO 测试集中的特征。因此，FO 测试集作为我们神经网络在最终任务——对 DES 目录中所有未标记星系进行分类——性能的良好评估指标。
- en: 'The properties of these datasets are summarized in Table [1](#S2.T1 "Table
    1 ‣ II.1 Data Curation for SDSS and DES ‣ II Methods ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey"), while their
    probability distributions are presented in Fig. [1](#S2.F1 "Figure 1 ‣ II.1 Data
    Curation for SDSS and DES ‣ II Methods ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey"). A sample of the training SDSS
    dataset, and the HP Test set images are presented in the top and bottom panels
    of Fig. [2](#S2.F2 "Figure 2 ‣ II.2 Deep Learning: Model and Methodology ‣ II
    Methods ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey"), respectively.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: '这些数据集的属性总结在表 [1](#S2.T1 "Table 1 ‣ II.1 Data Curation for SDSS and DES ‣ II
    Methods ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey")中，而它们的概率分布在图 [1](#S2.F1 "Figure 1 ‣ II.1 Data Curation for
    SDSS and DES ‣ II Methods ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey")中呈现。训练 SDSS 数据集的样本以及 HP 测试集图像分别呈现在图 [2](#S2.F2
    "Figure 2 ‣ II.2 Deep Learning: Model and Methodology ‣ II Methods ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")的顶部和底部面板中。'
- en: SDSS Dataset We used the de-biased probabilities for elliptical and combined
    spiral classes described in Table 2 of Lintott *et al.* ([2011](#bib.bib20)) to
    create labels for the two classes of our training and test sets. After selecting
    the OBJIDs from Table 2 based on the probability thresholds of 0.985 and 0.926
    for spirals and ellipticals respectively, we submit SQL queries to the SDSS Skyserver SDSS
    ([2018](#bib.bib21)) to obtain g, r and i-band images and metadata from the PhotoObj
    table. Thereafter, each galaxy is ‘cut-out’ from the downloaded telescope fits
    files for each band, and then the bands are stacked together to create a color
    image.
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: SDSS 数据集 我们使用了表 2 中描述的椭圆形和组合螺旋类的去偏置概率来为我们训练集和测试集的两个类别创建标签。在根据螺旋和椭圆形的概率阈值 0.985
    和 0.926 从表 2 中选择 OBJIDs 后，我们向 SDSS Skyserver SDSS ([2018](#bib.bib21)) 提交 SQL
    查询，以从 PhotoObj 表中获取 g、r 和 i 波段的图像和元数据。之后，从下载的望远镜 fits 文件中为每个波段“剪切”出每个星系，然后将各个波段叠加在一起，创建一张彩色图像。
- en: We developed the scripts to download and preprocess data as open source Python
    software stacks ²²2The code is publicly available in a github repository at [https://github.com/khanx169/DL_DES](https://github.com/khanx169/DL_DES).
    To facilitate and streamline these tasks at scale, we incorporated Message Passing
    Interface (MPI) Gropp *et al.* ([1999](#bib.bib22)) to exploit multiple nodes
    on supercomputers for a fast parallel computation. In our case, the data extraction
    and curation was done using the Blue Waters Supercomputer Kramer *et al.* ([2015](#bib.bib23)).
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 我们开发了用于下载和预处理数据的脚本，这些脚本作为开源 Python 软件栈发布²²2代码可以在 [https://github.com/khanx169/DL_DES](https://github.com/khanx169/DL_DES)
    的 github 仓库中公开获取。为了方便和简化大规模处理这些任务，我们引入了消息传递接口（MPI） Gropp *et al.*（[1999](#bib.bib22)）以利用超级计算机上的多个节点进行快速并行计算。在我们的案例中，数据提取和整理是使用
    Blue Waters 超级计算机 Kramer *et al.*（[2015](#bib.bib23)）完成的。
- en: DES Dataset The same steps are repeated to first select the DES DR1 metadata
    and images from the NCSA DESaccess web DES ([2018](#bib.bib24)), and then to cut-out,
    preprocess and stack the filters together to create RGB color images. Additionally,
    the Astropy package match_to_catalog_sky is used to crossmatch DES and SDSS catalogues
    to within 1 arcsec. Finally we pick a random sample of $\sim 10,000$ bright DES
    galaxies to quantify the classification and clustering performance of our neural
    network model.
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: DES 数据集 采用相同的步骤，首先从 NCSA DESaccess 网站上选择 DES DR1 元数据和图像 DES ([2018](#bib.bib24))，然后剪裁、预处理并堆叠滤波器，创建
    RGB 彩色图像。此外，使用 Astropy 包中的 match_to_catalog_sky 进行 DES 和 SDSS 目录的交叉匹配，精确到 1 角秒。最后，我们随机挑选约
    $\sim 10,000$ 个明亮的 DES 星系，以量化我们神经网络模型的分类和聚类性能。
- en: 'II.2 Deep Learning: Model and Methodology'
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II.2 深度学习：模型与方法
- en: 'We use open source software stacks for our studies. The deep learning APIs
    used are Keras Keras ([2018](#bib.bib25)) and Tensorflow Abadi *et al.* ([2016](#bib.bib26)).
    For the classification problem we do transfer learning starting with the Xception
    model Chollet ([2016](#bib.bib15)), which has been pre-trained with the ImageNet Russakovsky *et al.*
    ([2014](#bib.bib27)) dataset. We choose this neural network model because it outperforms
    many other state-of-the-art neural network models, including Inception-v3 Szegedy *et al.*
    ([2015](#bib.bib28)), ResNet-152 He *et al.* ([2015](#bib.bib29)) and VGG16 Simonyan and Zisserman
    ([2014](#bib.bib30)) on ImageNet validation dataset, and it has been suggested
    that better ImageNet architectures are capable of learning better transferable
    representations  Kornblith *et al.* ([2018](#bib.bib31)). More importantly, we
    carried out several experiments and found that Xception exhibits either as good
    or nominally better performance on our validation and testing galaxy datasets
    compared to many other state of the art architectures (see Fig. [3](#S2.F3 "Figure
    3 ‣ II.2 Deep Learning: Model and Methodology ‣ II Methods ‣ Deep Learning at
    Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")).'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '我们使用开源软件堆栈进行研究。使用的深度学习 API 包括 Keras Keras ([2018](#bib.bib25)) 和 Tensorflow Abadi *等人*
    ([2016](#bib.bib26))。对于分类问题，我们使用迁移学习，从 Xception 模型 Chollet ([2016](#bib.bib15))
    开始，该模型已使用 ImageNet Russakovsky *等人* ([2014](#bib.bib27)) 数据集进行预训练。我们选择这个神经网络模型，因为它在
    ImageNet 验证数据集上的表现优于许多其他最先进的神经网络模型，包括 Inception-v3 Szegedy *等人* ([2015](#bib.bib28))、ResNet-152 He *等人*
    ([2015](#bib.bib29)) 和 VGG16 Simonyan 和 Zisserman ([2014](#bib.bib30))，而且有建议认为，更好的
    ImageNet 架构能够学习到更好的可迁移表示 Kornblith *等人* ([2018](#bib.bib31))。更重要的是，我们进行了一些实验，发现
    Xception 在我们的验证和测试星系数据集上表现与许多其他最先进的架构相当或略好（见图 [3](#S2.F3 "Figure 3 ‣ II.2 Deep
    Learning: Model and Methodology ‣ II Methods ‣ Deep Learning at Scale for the
    Construction of Galaxy Catalogs in the Dark Energy Survey")）。'
- en: Bearing in mind that the Xception model Chollet ([2016](#bib.bib15)) was originally
    trained on the ImageNet Russakovsky *et al.* ([2014](#bib.bib27)) dataset, with
    images resized to $299\times 299\times 3$, we have followed best practices of
    neural network training Andrej Karpathy ([2018](#bib.bib32)), and have resized
    all the galaxy sub-images to be $299\times 299$ pixels, and then stacked the three
    filters together to create a color image of size $299\times 299\times 3$. Finally,
    these sub-images are mean subtracted and normalized to convert the pixel values
    to -1 to 1 range centered around 0\. These curated datasets serve as the input
    tensor into our deep neural network model.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 需要注意的是，Xception 模型 Chollet ([2016](#bib.bib15)) 最初是在 ImageNet Russakovsky *等人*
    ([2014](#bib.bib27)) 数据集上训练的，图像被调整为 $299\times 299\times 3$ 尺寸。我们遵循了神经网络训练的最佳实践 Andrej
    Karpathy ([2018](#bib.bib32))，将所有星系子图像调整为 $299\times 299$ 像素，然后将三个滤波器堆叠在一起，创建一个
    $299\times 299\times 3$ 尺寸的彩色图像。最后，这些子图像进行均值减去和归一化处理，将像素值转换为范围在 -1 到 1 之间，以 0
    为中心。这些整理后的数据集作为输入张量输入到我们的深度神经网络模型中。
- en: For training, we first extract the feature maps from the second last layer of
    the pretrained model for a single epoch and feed them into a few custom defined
    fully connected layers added at the end of the pre-trained model (see Figure [7](#A1.F7
    "Figure 7 ‣ Appendix A Neural network architecture ‣ Deep Learning at Scale for
    the Construction of Galaxy Catalogs in the Dark Energy Survey") in [A](#A1 "Appendix
    A Neural network architecture ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey")). Then we progressively unfreeze the
    earlier layers of the whole network and fine tune their weights for a few epochs
    of training.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们首先从预训练模型的倒数第二层提取特征图，进行一个周期的训练，并将其输入到预训练模型末尾添加的几个自定义全连接层中（见图 [7](#A1.F7
    "图 7 ‣ 附录 A 神经网络架构 ‣ 大规模深度学习用于黑暗能量调查中的星系目录建设") 在 [A](#A1 "附录 A 神经网络架构 ‣ 大规模深度学习用于黑暗能量调查中的星系目录建设")）。然后，我们逐步解冻整个网络的早期层，并对它们的权重进行几轮训练的微调。
- en: '![Refer to caption](img/a90131496c7a0191c5198610f2d60e42.png)![Refer to caption](img/4c2497e6b2d75c5027bb022e945d4a99.png)'
  id: totrans-57
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a90131496c7a0191c5198610f2d60e42.png)![参见说明](img/4c2497e6b2d75c5027bb022e945d4a99.png)'
- en: '![Refer to caption](img/5f4e20d911e309a89d258440f37cc6e7.png)![Refer to caption](img/bf1da76e0dd0ae8692170d5fffad7251.png)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/5f4e20d911e309a89d258440f37cc6e7.png)![参见说明](img/bf1da76e0dd0ae8692170d5fffad7251.png)'
- en: 'Figure 2: Top panels: labelled images of the SDSS training set. Bottom panels:
    sample of galaxies from SDSS-DR7 and the corresponding crossmatched galaxies from
    DES DR1.'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：上面部分：标记的 SDSS 训练集图像。下面部分：来自 SDSS-DR7 的星系样本以及对应的 DES DR1 交叉匹配星系。
- en: '![Refer to caption](img/067b59cb52d811d9e0f98fad40b4e4dd.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/067b59cb52d811d9e0f98fad40b4e4dd.png)'
- en: '![Refer to caption](img/8491eb5a309dc3de0bdaad9830398877.png)'
  id: totrans-61
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8491eb5a309dc3de0bdaad9830398877.png)'
- en: 'Figure 3: Performance of several different fine-tuned architectures pre-trained
    on ImageNet. Top panels: Receiver Operating Characteristic (ROC) for galaxies
    in the FO SDSS test set. Bottom panels: ROC for galaxies in the FO DES test set.
    The smaller insets show the difference in True Positive Rate between Xception
    and each of the other four models on a log scale.'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：在 ImageNet 上预训练的几种不同微调架构的性能。上面部分：FO SDSS 测试集中的星系接收者操作特征 (ROC)。下面部分：FO DES
    测试集中的星系 ROC。较小的插图显示了 Xception 与其他四种模型之间的真正正例率差异的对数尺度。
- en: The rationale behind this approach is that the earlier layers of a trained network
    are very versatile filters able to pick up simple abstract features like lines
    and edges relevant to any image detection or classification problem. However,
    deeper into the network, the weights of the layers become less interpretable and
    more specific to the given problem at hand Zeiler and Fergus ([2014](#bib.bib33)).
    Hence, by training the last layers first and then progressively fine tuning the
    earlier layers we make sure that the useful weights learned on millions of ImageNet Deng *et al.*
    ([2009](#bib.bib17)) images are not destroyed while the neural network learns
    and adapts to the galaxy classification problem Yosinski *et al.* ([2014](#bib.bib34)).
    Deep transfer learning has been explored in physics and astronomy classification
    problems, including noise anomaly classification in gravitational wave data George *et al.*
    ([2018](#bib.bib16)), galaxy merger classification Ackermann *et al.* ([2018](#bib.bib35)),
    and galaxy classification Barchi *et al.* ([2019](#bib.bib19)); Domínguez Sánchez *et al.*
    ([2018](#bib.bib14)).
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法背后的理由是，训练网络的早期层是非常通用的过滤器，能够捕捉到与任何图像检测或分类问题相关的简单抽象特征，如线条和边缘。然而，随着网络层次的加深，层的权重变得不那么可解释，并且更专注于当前问题的特定方面 Zeiler 和 Fergus
    ([2014](#bib.bib33))。因此，通过首先训练最后几层，然后逐步微调早期层，我们可以确保在神经网络学习和适应星系分类问题时，从数百万张 ImageNet Deng *et al.*
    ([2009](#bib.bib17)) 图像中学到的有用权重不会被破坏 Yosinski *et al.* ([2014](#bib.bib34))。深度迁移学习已经在物理学和天文学分类问题中得到探索，包括引力波数据中的噪声异常分类 George *et al.*
    ([2018](#bib.bib16))，星系合并分类 Ackermann *et al.* ([2018](#bib.bib35))，以及星系分类 Barchi *et al.*
    ([2019](#bib.bib19))；Domínguez Sánchez *et al.* ([2018](#bib.bib14))。
- en: Single-GPU Training We train the network using Tesla P100 GPUs on XSEDE (Bridges) XSEDE
    ([2018](#bib.bib36)). The training process for the dataset of 36500 images is
    completed within 5 hours. We use categorical cross entropy as the loss function
    together with ADAM optimizer Kingma and Ba ([2014](#bib.bib37)). To avoid over-fitting,
    we monitor both training and validation losses, add a dropout rate of 70% between
    our fully connected layers, and also use early-stopping, i.e., we stop training
    once validation loss stops decreasing. Additionally we use the learning rate scheduler,
    i.e., we reduce the learning rate when training loss stops decreasing to do a
    more fine-grained search of the loss function’s minima, and data augmentation.
    For data augmentation we use random flips, rotations, zooms and shifts as shown
    in Figure [8](#A2.F8 "Figure 8 ‣ Appendix B Data Augmentation ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") in [B](#A2
    "Appendix B Data Augmentation ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey"). After training, all the weights are
    frozen and saved, and inference on about 10,000 test images is completed within
    10 minutes using a single Tesla P100 GPU.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 单GPU训练 我们使用XSEDE（Bridges）上的Tesla P100 GPU进行网络训练 XSEDE（[2018](#bib.bib36)）。36500张图像的数据集训练过程在5小时内完成。我们使用分类交叉熵作为损失函数，并配合ADAM优化器 Kingma 和 Ba（[2014](#bib.bib37)）。为了避免过拟合，我们监控训练和验证损失，添加了70%的丢弃率在我们的全连接层之间，并且使用早期停止，即一旦验证损失停止下降，我们就停止训练。此外，我们使用学习率调度器，即当训练损失停止下降时，我们降低学习率以对损失函数的最小值进行更精细的搜索，并进行数据增强。对于数据增强，我们使用随机翻转、旋转、缩放和移动，如图 [8](#A2.F8
    "Figure 8 ‣ Appendix B Data Augmentation ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey") 所示，详细见[B](#A2 "Appendix B Data
    Augmentation ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey")。训练完成后，所有权重被冻结并保存，使用单个Tesla P100 GPU在约10,000张测试图像上进行推断，完成时间在10分钟内。
- en: 'Distributed Training Figure [4](#S2.F4 "Figure 4 ‣ II.2 Deep Learning: Model
    and Methodology ‣ II Methods ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") shows the parallel training performance
    for the Xception model using up to 64 K80 GPUs (see Table [3](#A4.T3 "Table 3
    ‣ Appendix D Scaling Results ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") for a detailed breakdown of these
    results). The code was distributed across multiple GPUs using the Horovod distributed
    framework for Keras Sergeev and Balso ([2018](#bib.bib38)).³³3These results were
    obtained on the Intel Haswell and NVIDIA K80 based supercomputer, Cooley, at Argonne
    Leadership Computing Facility using a data parallelization scheme through Horovod.
    We find that distributing the workload decreases the time per epoch linearly,
    and significantly reduces the training of 36,620 images from $\sim 5$ hours using
    a single GPU to 8m using 64 GPUs, with similar accuracy. ⁴⁴4 The base learning
    rate was 0.0001 and was scaled by the number of GPUs, $N$, following Goyal *et al.*
    ([2017](#bib.bib39)) while keeping the mini-batch size the same on each worker.
    In addition we used a technique of “warmup” epochs where we set the learning rate
    to be the base learning rate and increase to $0.0001*N$ after 2 warmup epochs.'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '分布式训练 图 [4](#S2.F4 "Figure 4 ‣ II.2 Deep Learning: Model and Methodology ‣
    II Methods ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in
    the Dark Energy Survey") 展示了使用最多64个K80 GPU的Xception模型的并行训练性能（有关这些结果的详细分解，请参见表 [3](#A4.T3
    "Table 3 ‣ Appendix D Scaling Results ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey")）。代码通过Horovod分布式框架在多个GPU上分发，Horovod是为Keras开发的 Sergeev 和 Balso（[2018](#bib.bib38)）。这些结果是在Intel
    Haswell和NVIDIA K80基础的超级计算机Cooley上，通过Horovod的数据并行方案获得的。我们发现，分发工作负载线性地减少了每个周期的时间，并显著将36,620张图像的训练时间从单GPU的$\sim
    5$小时减少到使用64个GPU的8分钟，同时保持相似的准确性。基础学习率为0.0001，并根据GPU的数量$N$进行缩放，遵循Goyal *et al.*（[2017](#bib.bib39)），同时保持每个工作节点的迷你批量大小不变。此外，我们使用了一种“热身”周期的技术，我们将学习率设置为基础学习率，并在经过2个热身周期后增加到$0.0001*N$。'
- en: The last layer of the network has two softmax nodes, which provide the output
    probability that the input image belongs to a given galaxy class. To quantify
    the over-all accuracy of the neural network, we extract the output probabilities
    from this last layer for our two HP and FO test sets, and compare them against
    the ground truth labels provided through the Galaxy Zoo project. While these probabilities
    can be directly tested for cross-matched DES sets by comparing to the SDSS-Galaxy
    Zoo probabilities, for the rest of the unlabelled DES images this is not possible.
    For large-scale galaxy catalogs it would be unfeasible to inspect individual images
    to determine what class they belong to and check against the neural networks out-put
    probabilities to check for consistency. In practice, we can use the nodes of the
    second last layer of the neural network to determine what combination of them
    is activated for each galaxy type. In this approach, the activation vectors of
    this layer would form two distinct clusters, for each galaxy type in a 1024-D
    space. Checking whether similar combinations of neurons are activated, i.e., similar
    clusters are formed for the unlabelled DES data as the FO and HP test sets, will
    serve as a heuristic check that the learning is successfully transferred to the
    classification of unlabelled DES images for the purpose of constructing a catalog.
    For example, if there is a lack of distinct clusters, or more than two clusters
    are seen, then that would suggest unknown types that are forced into being classified
    as spiral or elliptical because the output layer has only two nodes.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 网络的最后一层有两个 softmax 节点，这些节点提供输入图像属于特定银河系类别的输出概率。为了量化神经网络的总体准确性，我们从最后一层提取这些输出概率，针对我们的
    HP 和 FO 测试集，并与通过 Galaxy Zoo 项目提供的真实标签进行比较。虽然这些概率可以通过与 SDSS-Galaxy Zoo 概率进行比较直接测试交叉匹配的
    DES 数据集，但对于其余未标记的 DES 图像，这种方法不可行。对于大规模银河系目录，检查单个图像以确定其所属类别并与神经网络的输出概率进行一致性检查是不切实际的。在实际操作中，我们可以使用神经网络倒数第二层的节点来确定每种银河系类型激活的节点组合。在这种方法中，该层的激活向量将在
    1024 维空间中形成两个不同的簇。检查未标记的 DES 数据是否与 FO 和 HP 测试集形成类似的簇，即相似的神经元组合是否被激活，将作为启发式检查，以验证学习是否成功转移到未标记
    DES 图像的分类中，以构建目录。例如，如果没有明显的簇，或者看到的簇数量超过两个，那么这将表明存在未知类型，这些类型被强制归类为螺旋状或椭圆状，因为输出层只有两个节点。
- en: In order to visualize these 1024-D clusters, we embed them into a 3-D parameter
    space using the sklearn library implementation of t-Distributed Stochastic Neighbor
    Embedding (t-SNE) van der Maaten and Hinton ([2008](#bib.bib40)). t-SNE is a nonlinear
    dimensionality reduction technique that is particularly apt for visualizing high-dimensional
    datasets by finding a faithful representation in a low dimensional embedding,
    typically 2-D or 3-D. It is important to note that t-SNE adjusts its notion of
    distance to regional density variations in the dataset, and hence bounding boxes
    of clusters in the low dimensional representation don’t correspond to their relative
    sizes. Similarly, distances between clusters may not be meaningful since they
    are affected by a number of hyper-parameters such as perplexity and number of
    iterations.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 为了可视化这些 1024 维簇，我们使用 sklearn 库中 t-分布随机邻域嵌入（t-SNE）的实现将它们嵌入到 3-D 参数空间中，van der
    Maaten 和 Hinton ([2008](#bib.bib40))。t-SNE 是一种非线性降维技术，特别适用于通过在低维嵌入（通常是 2-D 或 3-D）中找到忠实表示来可视化高维数据集。值得注意的是，t-SNE
    调整其对数据集区域密度变化的距离概念，因此低维表示中的簇的边界框与其相对大小不一致。类似地，簇之间的距离可能没有意义，因为它们受到困惑度和迭代次数等多个超参数的影响。
- en: As a final step, we introduce an application of unsupervised/semi-supervised
    learning in the form of recursive training, where we introduce into the training
    set newly labelled DES galaxies and retrain our model. It has been suggested in Domínguez
    Sánchez *et al.* ([2018](#bib.bib14)) that once trained with a particular dataset
    from one survey, neural networks can quickly adapt to new instrument characteristics
    (e.g., PSF, seeing, depth), reducing by almost one order of magnitude the necessary
    training sample from a different survey for morphological classification. However
    instead of manually labelling new DES images, we extract the out-put classification
    probabilities for them through our fine-tuned neural network. We use a sample
    of  10,000 unlabelled bright DES galaxies and then by introducing a threshold
    on the neural networks classification confidence, we select the 1000 most confident
    predictions for spiral and elliptical respectively to further fine tune our network
    on.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 最后一步，我们引入了一种无监督/半监督学习的应用形式，即递归训练，在这种形式中，我们将新标记的 DES 银河引入训练集，并重新训练我们的模型。根据 Domínguez
    Sánchez *et al.* ([2018](#bib.bib14)) 的建议，一旦用某个调查的数据集进行训练，神经网络可以快速适应新的仪器特性（例如，点扩散函数、观测条件、深度），将来自不同调查的必要训练样本减少近一个数量级。然而，我们没有手动标记新的
    DES 图像，而是通过我们微调的神经网络提取它们的输出分类概率。我们使用了一批 10,000 个未标记的明亮 DES 银河，然后通过对神经网络分类信心设置阈值，我们选择了
    1,000 个最有信心的螺旋星系和椭圆星系的预测结果，进一步对我们的网络进行微调。
- en: '![Refer to caption](img/7bf074fecb24f9411db388bf5ce7d355.png)'
  id: totrans-69
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7bf074fecb24f9411db388bf5ce7d355.png)'
- en: 'Figure 4: Speed up in training using up to 64 K80 GPUs for the Xception model.'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：使用最多 64 个 K80 GPU 加速 Xception 模型的训练。
- en: III Results
  id: totrans-71
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 结果
- en: 'To check the performance of our neural network model on HP and FO test sets,
    we use standard evaluation metrics: precision, recall, accuracy and F1 score.
    For binary classification, precision is the number of true positives divided by
    the total number of predicted positives, i.e., true positives plus false positives.
    Similarly, recall is the number of true positives divided by the total number
    of actual positives, i.e., true positives plus false negatives. The F1 score is
    a single number statistical evaluation metric that measures the accuracy of binary
    classification by taking a weighted average of precision and recall. It varies
    between its worst performance value of 0 and best performance value of 1, and
    is given by'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 为了检查我们神经网络模型在 HP 和 FO 测试集上的表现，我们使用了标准的评估指标：精确度、召回率、准确度和 F1 分数。对于二分类问题，精确度是正确预测的正样本数除以预测为正样本的总数，即正确预测的正样本加上错误预测的正样本。同样，召回率是正确预测的正样本数除以实际正样本的总数，即正确预测的正样本加上漏掉的正样本。F1
    分数是一个单一的统计评估指标，通过精确度和召回率的加权平均来衡量二分类的准确性。它的取值范围从最差表现值 0 到最佳表现值 1，计算公式为
- en: '|  | $\textrm{F1\, score}=2\,\frac{\textrm{precision}\times\textrm{recall}}{\textrm{precision}+\textrm{recall}}\,.$
    |  | (1) |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '|  | $\textrm{F1\, score}=2\,\frac{\textrm{precision}\times\textrm{recall}}{\textrm{precision}+\textrm{recall}}\,.$
    |  | (1) |'
- en: The performance of these metrics on the various test sets is summarized in Table [2](#S3.T2
    "Table 2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey"). As can be seen in Table [2](#S3.T2 "Table
    2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey"), deep transfer learning from everyday object classification
    in the ImageNet dataset to morphological classification of galaxies in SDSS and
    DES leads to state of the art accuracies and F1 scores. Our fine tuned Xception
    model attains accuracies $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$
    for the HP SDSS and HP DES test sets. Unlike HP test sets, the FO test sets do
    not entirely consist of galaxies with robust ground truth classifications. Hence,
    instead of applying a threshold on the ground truth probabilities, we apply a
    confidence threshold on the predictions of the neural network. In Table [2](#S3.T2
    "Table 2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") we pick the top half most confident predictions,
    for which the neural network attains $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower
    4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$ accuracies and F1 scores. Additionally,
    the accuracies and F1 scores obtained by applying various different thresholds
    are also summarized in Fig [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey"),
    while the Receiver Operating Characteristic (ROC) curves are shown in Fig [10](#A5.F10
    "Figure 10 ‣ Appendix E Recursive Training ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey") [E](#A5 "Appendix E Recursive Training
    ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey").
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 这些指标在各测试集上的表现总结见表 [2](#S3.T2 "Table 2 ‣ III Results ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey")。从表 [2](#S3.T2
    "Table 2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") 可以看出，深度迁移学习从 ImageNet 数据集的日常物体分类到 SDSS 和
    DES 中的星系形态分类，达到了最先进的准确率和 F1 分数。我们精细调优的 Xception 模型在 HP SDSS 和 HP DES 测试集上取得了$\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$的准确率。与 HP 测试集不同，FO
    测试集并不完全由具有可靠真实分类的星系组成。因此，我们没有对真实概率应用阈值，而是对神经网络的预测应用了置信度阈值。在表 [2](#S3.T2 "Table
    2 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey")中，我们选择了置信度最高的一半预测，这些预测的准确率和 F1 分数均达到了$\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$。此外，通过应用不同阈值获得的准确率和
    F1 分数也在图 [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey")中进行了总结，而接收操作特性（ROC）曲线则显示在图 [10](#A5.F10
    "Figure 10 ‣ Appendix E Recursive Training ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey") [E](#A5 "Appendix E Recursive Training
    ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey") 中。
- en: '| Dataset | Precision | Recall | FPR | Accuracy | F1 score |'
  id: totrans-75
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 精确度 | 召回率 | FPR | 准确率 | F1 分数 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-76
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| Training set |  |  |  | 99.81% | 0.9998 |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| 训练集 |  |  |  | 99.81% | 0.9998 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| HP SDSS Test Set | 0.996 | 1 | 0.004 | 99.81% | 0.9980 |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| HP SDSS 测试集 | 0.996 | 1 | 0.004 | 99.81% | 0.9980 |'
- en: '| HP DES    Test Set | 0.998 | 0.995 | 0.002 | 99.62% | 0.9961 |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| HP DES    测试集 | 0.998 | 0.995 | 0.002 | 99.62% | 0.9961 |'
- en: '| FO SDSS Test Set | 0.945 | 0.991 | 0.055 | 96.76% | 0.9675 |'
  id: totrans-81
  prefs: []
  type: TYPE_TB
  zh: '| FO SDSS 测试集 | 0.945 | 0.991 | 0.055 | 96.76% | 0.9675 |'
- en: '| FO DES    Test Set | 0.965 | 0.946 | 0.025 | 96.32% | 0.9685 |'
  id: totrans-82
  prefs: []
  type: TYPE_TB
  zh: '| FO DES    测试集 | 0.965 | 0.946 | 0.025 | 96.32% | 0.9685 |'
- en: 'Table 2: Classification accuracy for each test dataset.'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：各测试数据集的分类准确率。
- en: Having quantified the accuracy of our neural network model on DES test sets
    that overlap the SDSS footprint, we now feed our model with bright, unlabelled
    DES galaxies that do not overlap the SDSS footprint, and predict their classes,
    thereby labelling them. A random sample of high confidence predictions for these
    is shown in Figure [9](#A3.F9 "Figure 9 ‣ Appendix C Classification predictions
    for unlabelled DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey") in [C](#A3 "Appendix C Classification predictions
    for unlabelled DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey").
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在量化我们神经网络模型在与 SDSS 足迹重叠的 DES 测试集上的准确性后，我们现在用亮的、未标记的 DES 星系（这些星系不重叠 SDSS 足迹）来喂养我们的模型，并预测它们的类别，从而对它们进行标记。图 [9](#A3.F9
    "图 9 ‣ 附录 C 未标记 DES 星系的分类预测 ‣ 深度学习规模化构建暗能量调查中的星系目录")中展示了一组高置信度预测的随机样本，见 [C](#A3
    "附录 C 未标记 DES 星系的分类预测 ‣ 深度学习规模化构建暗能量调查中的星系目录")。
- en: '![Refer to caption](img/3a9f514173b64a77f1c3942ad0d5f5bb.png) ![Refer to caption](img/7f1792ee2a3273aff315d4fc85b8c032.png)
    ![Refer to caption](img/f9bebc231cd35a812a4288ebebc945fe.png)'
  id: totrans-85
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/3a9f514173b64a77f1c3942ad0d5f5bb.png) ![参见标题](img/7f1792ee2a3273aff315d4fc85b8c032.png)
    ![参见标题](img/f9bebc231cd35a812a4288ebebc945fe.png)'
- en: 'Figure 5: t-SNE visualization of the clustering of HP SDSS and DES test sets,
    and unlabelled DES test.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：HP SDSS 和 DES 测试集以及未标记 DES 测试集的 t-SNE 聚类可视化。
- en: '![Refer to caption](img/44fb4d1ea37ce02f877be031dd234bf5.png) ![Refer to caption](img/6c3eb578ec55335b3fb6de83bfb50075.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/44fb4d1ea37ce02f877be031dd234bf5.png) ![参见标题](img/6c3eb578ec55335b3fb6de83bfb50075.png)'
- en: '![Refer to caption](img/17792cd1c6eb73d21cf8a1fe4b8aaa8d.png) ![Refer to caption](img/0f4dcfcf812f0e466bf0e43497d3e58b.png)'
  id: totrans-88
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/17792cd1c6eb73d21cf8a1fe4b8aaa8d.png) ![参见标题](img/0f4dcfcf812f0e466bf0e43497d3e58b.png)'
- en: 'Figure 6: Top panels: SDSS datasets. Bottom panels: DES datasets. Accuracy
    (left panels) and F1 score (right panels) vs N high confidence predictions as
    a fraction of total full overlap test datasets (0th recursion). We also show the
    improvement in classification accuracy and F1 score after 2000 newly labelled
    DES images are added to the SDSS training dataset (1st recursion). These results
    have been obtained by averaging over ten different models.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：上面面板：SDSS 数据集。下面面板：DES 数据集。准确性（左侧面板）和 F1 分数（右侧面板）与 N 高置信度预测占总完全重叠测试数据集的比例（0
    次递归）。我们还展示了在将 2000 张新标记的 DES 图像添加到 SDSS 训练数据集后（第 1 次递归），分类准确性和 F1 分数的提升。这些结果是通过对十个不同模型的平均值得到的。
- en: Lastly, using our neural network model as a feature extractor, we obtain the
    activation maps of the second last layer and embed them in 3-D using t-SNE. The
    left and middle panels of Figure [5](#S3.F5 "Figure 5 ‣ III Results ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") show
    the output of t-SNE when applied to the HP SDSS and HP DES test sets. We labelled
    the points using the ground-truth label of each galaxy, and found that the points
    neatly cluster into two groups with accuracies $\mathrel{\hbox{\hbox to0.0pt{\hbox{\lower
    4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$. For unlabelled DES set, shown in the
    right panel of Figure [5](#S3.F5 "Figure 5 ‣ III Results ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey"), we find again
    that two distinct clusters are formed. Based on the accuracy of the FO DES test
    set, we heuristically know that these clusters have accuracies $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$ for the top-half
    most confident predictions. These results indicate that the neural network model
    has extracted the necessary information from the training dataset to enable t-SNE
    to clearly identify two distinct classes of galaxies based on their morphology.
    A scientific visualization of this clustering algorithm for the FO DES test set
    is presented in NCSA ([2018a](#bib.bib41)). The astute reader may realize that
    using t-SNE as a visualization tool requires training to prevent common misreadings
    of the visualizations. Furthermore, t-SNE does not always produce similar outputs
    on successive runs, and it requires the user to determine a few hyperparamters
    related to the optimization process. Much work has been presented in the literature
    to ensure that new users make a proper use of this tool Wattenberg *et al.* ([2016](#bib.bib42)),
    and to automate hyperparamter selection Cao and Wang ([2017](#bib.bib43)).
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，使用我们的神经网络模型作为特征提取器，我们获得了倒数第二层的激活图，并通过t-SNE将其嵌入到3维空间中。图[5](#S3.F5 "Figure
    5 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey")的左侧和中间面板显示了应用于HP SDSS和HP DES测试集的t-SNE输出。我们使用每个星系的真实标签对点进行了标注，发现这些点整齐地聚类成两个组，准确率达到$\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99\%$。对于未标记的DES数据集，见图[5](#S3.F5
    "Figure 5 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy
    Catalogs in the Dark Energy Survey")右侧面板，我们再次发现形成了两个明显的簇。根据FO DES测试集的准确率，我们可以启发性地知道这些簇在最可信的前半部分预测中的准确率为$\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}96\%$。这些结果表明，神经网络模型从训练数据集中提取了必要的信息，使得t-SNE能够清晰地区分基于形态的两个不同类型的星系。FO
    DES测试集的这种聚类算法的科学可视化展示在NCSA ([2018a](#bib.bib41))中。机智的读者可能会意识到，使用t-SNE作为可视化工具需要训练，以防止对可视化结果的常见误读。此外，t-SNE在连续运行中并不总是产生相似的输出，它要求用户确定与优化过程相关的一些超参数。文献中已经提出了很多工作，以确保新用户正确使用此工具 Wattenberg *et al.*
    ([2016](#bib.bib42))，并自动化超参数选择 Cao and Wang ([2017](#bib.bib43))。
- en: Recursive training Having labeled about 10,000 DES galaxies with our neural
    network classifier, we pick the top 1000 spiral and top 1000 elliptical galaxies.
    We then add them to our original SDSS training dataset, and use deep transfer
    learning again to re-train the neural network model. The top- and bottom-left
    panels in Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at Scale for
    the Construction of Galaxy Catalogs in the Dark Energy Survey") show the initial
    (0th recursion) accuracy of our classifier, and the accuracy attained once the
    newly labelled DES images are added to the SDSS training dataset (1st recursion).
    We notice that the accuracy for classification for FO SDSS and DES test sets improves
    up to $1.5\%$. In particular, we notice that the classification accuracy for the
    FO DES test set is now boosted up to $98.5\%$ when 50% of the dataset is considered.
    These results are rather significant from a machine learning perspective [Benchmarks.AI](#bib.bib44)
    , since these accuracies are already high and this newly labelled DES dataset
    represents $\sim 5\%$ of the the original SDSS training dataset. We have also
    computed ROC curves (see Figure [10](#A5.F10 "Figure 10 ‣ Appendix E Recursive
    Training ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey")) to provide an additional metric to quantify the improvement
    in classification accuracy due to recursive training.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 递归训练：在使用我们的神经网络分类器标记了大约 10,000 个 DES 星系后，我们挑选了前 1000 个螺旋星系和前 1000 个椭圆星系。然后我们将它们添加到原始的
    SDSS 训练数据集中，并再次使用深度迁移学习重新训练神经网络模型。图 [6](#S3.F6 "图 6 ‣ III 结果 ‣ 深度学习在暗能量巡天中的星系目录构建")
    中的左上角和左下角面板显示了我们分类器的初始 (第0次递归) 准确性，以及在将新标记的 DES 图像添加到 SDSS 训练数据集后 (第1次递归) 达到的准确性。我们注意到
    FO SDSS 和 DES 测试集的分类准确性提高了最多 $1.5\%$。特别是，当考虑到 50% 的数据集时，FO DES 测试集的分类准确性现在提高到了
    $98.5\%$。从机器学习的角度来看，这些结果相当显著 [Benchmarks.AI](#bib.bib44)，因为这些准确性已经很高，而这份新标记的 DES
    数据集代表了原 SDSS 训练数据集的 $\sim 5\%$。我们还计算了 ROC 曲线（见图 [10](#A5.F10 "图 10 ‣ 附录 E 递归训练
    ‣ 深度学习在暗能量巡天中的星系目录构建")），以提供一个额外的指标来量化递归训练带来的分类准确性提升。
- en: Intuitively, recursive training provides the means to continually enhance the
    classification accuracy of a neural network as new data becomes available. We
    have found that, averaging over ten models, the mean classification accuracies
    do improve when we retrain the model.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 直观地说，递归训练提供了一种手段，使得随着新数据的出现，神经网络的分类准确性能够不断提升。我们发现，当我们重新训练模型时，十个模型的平均分类准确性确实有所提高。
- en: This novel approach provides us with the means to enhance SDSS galaxy classification,
    as shown in the top left panel of Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣
    Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey"). More importantly, it provides a way forward to gradually replace SDSS
    galaxy images in the training dataset that we need to construct DES galaxy catalogs
    at scale. A DES-only image training dataset will better capture the nature of
    images observed by DES, and would also enable us to better use data augmentations
    to model the effects of noise, making our neural network model more resilient
    to accurately classify galaxies at higher redshift, or that are contaminated by
    various sources of noise.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 这种新颖的方法为我们提供了提升 SDSS 星系分类的手段，如图 [6](#S3.F6 "图 6 ‣ III 结果 ‣ 深度学习在暗能量巡天中的星系目录构建")
    左上角面板所示。更重要的是，它提供了一种逐步替代训练数据集中 SDSS 星系图像的方法，以便我们可以大规模构建 DES 星系目录。仅使用 DES 图像的训练数据集将更好地捕捉
    DES 观测到的图像特征，并且还将使我们能够更好地利用数据增强技术来模拟噪声效应，使我们的神经网络模型在高红移或被各种噪声源污染的星系分类时更加稳健。
- en: IV Conclusion
  id: totrans-94
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 结论
- en: We have presented the first application of deep transfer learning combined with
    distributed training for the classification of DES galaxies that overlap the footprint
    of the SDSS survey, achieving state-of-the-art accuracies $\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99.6\%$. We described
    how to use our neural network classifier to label over 10,000 unlabelled DES galaxies
    that had not been observed in previous surveys. By truncating our neural network
    model, we used it as a feature extractor, and once combined with t-SNE, we presented
    visualizations which show that, through transfer learning, the neural network
    abstracted morphological information to clearly identify two distinct classes
    of galaxies in the unlabeled DES dataset. To get insights into the inner workings
    of our clustering algorithm, we have presented scientific visualizations of the
    clustering of the FO DES test set, which are available at NCSA ([2018a](#bib.bib41))
    and NCSA ([2018b](#bib.bib45)) .
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们首次展示了将深度迁移学习与分布式训练相结合应用于分类DES星系的方法，这些星系与SDSS调查的覆盖范围重叠，实现了最先进的准确率$\mathrel{\hbox{\hbox
    to0.0pt{\hbox{\lower 4.0pt\hbox{$\sim$}}\hss}\hbox{$>$}}}99.6\%$。我们描述了如何使用我们的神经网络分类器标记超过10,000个在以前调查中未观察到的未标记DES星系。通过截断我们的神经网络模型，我们将其用作特征提取器，并结合t-SNE，我们展示了通过迁移学习，神经网络抽象了形态信息，清晰地识别了未标记DES数据集中两种不同类型的星系。为了深入了解我们的聚类算法的内部工作，我们展示了FO
    DES测试集的科学可视化，这些可视化可在NCSA（[2018a](#bib.bib41)）和NCSA（[2018b](#bib.bib45)）上获取。
- en: We have also used t-SNE to inspect seemingly incorrect labels provided by our
    neural network model, and have found that these errors actually correspond to
    inaccurate human classifications in our SDSS testing dataset. We present an example
    of this nature in the visualization available at  NCSA ([2018a](#bib.bib41)),
    and in Figure [12](#A6.F12 "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep
    Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey").
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还使用t-SNE检查了神经网络模型提供的似乎不正确的标签，发现这些错误实际上对应于我们SDSS测试数据集中的不准确人工分类。我们在NCSA（[2018a](#bib.bib41)）的可视化中展示了这种性质的一个示例，并在图[12](#A6.F12
    "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep Learning at Scale for the
    Construction of Galaxy Catalogs in the Dark Energy Survey")中展示。
- en: Furthermore, adding the most confident predictions from our newly labeled DES
    galaxies, we have done recursive training, boosting the classification accuracy
    for the FO SDSS and DES test datasets. Averaging over ten models, we find improved
    accuracies as high as 99.5% for SDSS and 99% for DES.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，通过添加我们新标记的DES星系中最可信的预测，我们进行了递归训练，提高了FO SDSS和DES测试数据集的分类准确率。在十个模型的平均值中，我们发现SDSS的准确率提高到99.5%，DES的准确率提高到99%。
- en: This analysis provides a path forward to construct galaxy catalogs in DES using
    actual DES galaxies as training datasets. The combination of deep transfer learning
    with distributed training, and recursive training presents an alternative to do
    this analysis at scale in the LSST era.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 这项分析提供了一条前进的道路，用实际的DES星系作为训练数据集来构建DES中的星系目录。深度迁移学习与分布式训练的结合，以及递归训练，提供了一种在LSST时代以规模化方式进行分析的替代方法。
- en: V Acknowledgements
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 致谢
- en: This research is part of the Blue Waters sustained-petascale computing project,
    which is supported by the National Science Foundation (awards OCI-0725070 and
    ACI-1238993) and the State of Illinois. Blue Waters is a joint effort of the University
    of Illinois at Urbana-Champaign and its National Center for Supercomputing Applications.
    We acknowledge support from the NCSA. We thank the [NCSA Gravity Group](http://gravity.ncsa.illinois.edu)
    for useful feedback, and Vlad Kindratenko for granting us access to state-of-the-art
    GPUs and HPC resources at the Innovative Systems Lab at NCSA. We are grateful
    to NVIDIA for donating several Tesla P100 and V100 GPUs that we used for our analysis.
    We thank the anonymous referee for carefully reading this manuscript, and providing
    constructive feedback to improve the presentation of our results.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 这项研究是Blue Waters持续超大规模计算项目的一部分，该项目由国家科学基金会（奖项OCI-0725070和ACI-1238993）和伊利诺伊州政府资助。Blue
    Waters是伊利诺伊大学香槟分校及其国家超级计算应用中心的联合努力成果。我们感谢NCSA的支持。我们感谢[NCSA Gravity Group](http://gravity.ncsa.illinois.edu)提供有用的反馈，以及Vlad
    Kindratenko授权我们使用NCSA创新系统实验室的最新GPU和HPC资源。我们对NVIDIA捐赠的几台Tesla P100和V100 GPU表示感谢，这些GPU用于我们的分析。我们感谢匿名评审仔细阅读了这篇手稿，并提供了建设性的反馈以改善结果的展示。
- en: This work used the Extreme Science and Engineering Discovery Environment (XSEDE),
    which is supported by National Science Foundation grant number ACI-1548562\. Specifically,
    it used the Bridges system, which is supported by NSF award number ACI-1445606,
    at the Pittsburgh Supercomputing Center (PSC). We gratefully acknowledge grant
    TG-PHY160053\. This research used resources of the Argonne Leadership Computing
    Facility, which is a DOE Office of Science User Facility supported under Contract
    DE-AC02-06CH11357.
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究使用了极端科学与工程发现环境（XSEDE），该项目由国家科学基金会资助，资助编号ACI-1548562。具体来说，它使用了布里奇斯系统，该系统由NSF奖项编号ACI-1445606资助，位于匹兹堡超级计算中心（PSC）。我们感激地承认资助TG-PHY160053。本研究使用了阿贡领导计算设施的资源，该设施是一个DOE科学办公室用户设施，受合同DE-AC02-06CH11357的支持。
- en: This project used public archival data from the Dark Energy Survey (DES). Funding
    for the DES Projects has been provided by the U.S. Department of Energy, the U.S.
    National Science Foundation, the Ministry of Science and Education of Spain, the
    Science and Technology Facilities Council of the United Kingdom, the Higher Education
    Funding Council for England, the National Center for Supercomputing Applications
    at the University of Illinois at Urbana-Champaign, the Kavli Institute of Cosmological
    Physics at the University of Chicago, the Center for Cosmology and Astro-Particle
    Physics at the Ohio State University, the Mitchell Institute for Fundamental Physics
    and Astronomy at Texas A&M University, Financiadora de Estudos e Projetos, Fundação
    Carlos Chagas Filho de Amparo à Pesquisa do Estado do Rio de Janeiro, Conselho
    Nacional de Desenvolvimento Científico e Tecnológico and the Ministério da Ciência,
    Tecnologia e Inovação, the Deutsche Forschungsgemeinschaft and the Collaborating
    Institutions in the Dark Energy Survey.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 本项目使用了来自暗能量调查（DES）的公共档案数据。DES项目的资助来自美国能源部，美国国家科学基金会，西班牙科学与教育部，英国科学与技术设施委员会，英格兰高等教育资助委员会，伊利诺伊大学厄尔巴纳-香槟分校的国家超级计算应用中心，芝加哥大学的卡夫里宇宙物理研究所，俄亥俄州立大学的宇宙学与天体粒子物理中心，德克萨斯农工大学的基本物理与天文学米切尔研究所，Financiadora
    de Estudos e Projetos，里约热内卢州卡洛斯·查加斯·菲略研究资助基金会，国家科学技术发展委员会和科学、技术与创新部，德意志研究基金会以及暗能量调查的合作机构。
- en: The Collaborating Institutions are Argonne National Laboratory, the University
    of California at Santa Cruz, the University of Cambridge, Centro de Investigaciones
    Energéticas, Medioambientales y Tecnológicas–Madrid, the University of Chicago,
    University College London, the DES-Brazil Consortium, the University of Edinburgh,
    the Eidgenössische Technische Hochschule (ETH) Zürich, Fermi National Accelerator
    Laboratory, the University of Illinois at Urbana-Champaign, the Institut de Ciències
    de l’Espai (IEEC/CSIC), the Institut de Física d’Altes Energies, Lawrence Berkeley
    National Laboratory, the Ludwig-Maximilians Universität München and the associated
    Excellence Cluster Universe, the University of Michigan, the National Optical
    Astronomy Observatory, the University of Nottingham, The Ohio State University,
    the OzDES Membership Consortium, the University of Pennsylvania, the University
    of Portsmouth, SLAC National Accelerator Laboratory, Stanford University, the
    University of Sussex, and Texas A&M University. Based in part on observations
    at Cerro Tololo Inter-American Observatory, National Optical Astronomy Observatory,
    which is operated by the Association of Universities for Research in Astronomy
    (AURA) under a cooperative agreement with the National Science Foundation.
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 合作机构包括阿贡国家实验室，加州大学圣克鲁斯分校，剑桥大学，马德里能源环境技术研究中心，芝加哥大学，伦敦大学学院，DES-巴西联盟，爱丁堡大学，瑞士联邦理工学院（ETH），费米国家加速器实验室，伊利诺伊大学厄尔巴纳-香槟分校，太空科学研究所（IEEC/CSIC），高能物理研究所，劳伦斯伯克利国家实验室，慕尼黑路德维希-马克西米利安大学及其相关的宇宙卓越集群，密歇根大学，国家光学天文台，诺丁汉大学，俄亥俄州立大学，OzDES会员联盟，宾夕法尼亚大学，朴茨茅斯大学，SLAC国家加速器实验室，斯坦福大学，萨塞克斯大学和德克萨斯农工大学。部分基于在塞罗托洛洛国际天文台的观测，国家光学天文台由天文研究大学协会（AURA）在与国家科学基金会的合作协议下运营。
- en: References
  id: totrans-104
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: Riess *et al.* (1998) A. G. Riess, A. V. Filippenko, P. Challis, A. Clocchiatti,
    A. Diercks, P. M. Garnavich, R. L. Gilliland, C. J. Hogan, S. Jha, R. P. Kirshner,
    B. Leibundgut, M. M. Phillips, D. Reiss, B. P. Schmidt, R. A. Schommer, R. C. Smith,
    J. Spyromilio, C. Stubbs, N. B. Suntzeff,  and J. Tonry, [The Astronomical Journal  116, 1009
    (1998)](http://dx.doi.org/10.1086/300499), [astro-ph/9805201](http://arxiv.org/abs/astro-ph/9805201)
    .
  id: totrans-105
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Riess *et al.* (1998) A. G. Riess, A. V. Filippenko, P. Challis, A. Clocchiatti,
    A. Diercks, P. M. Garnavich, R. L. Gilliland, C. J. Hogan, S. Jha, R. P. Kirshner,
    B. Leibundgut, M. M. Phillips, D. Reiss, B. P. Schmidt, R. A. Schommer, R. C.
    Smith, J. Spyromilio, C. Stubbs, N. B. Suntzeff, 和 J. Tonry，[The Astronomical
    Journal 116, 1009 (1998)](http://dx.doi.org/10.1086/300499)，[astro-ph/9805201](http://arxiv.org/abs/astro-ph/9805201)。
- en: Perlmutter *et al.* (1999) S. Perlmutter, G. Aldering, *et al.*, [Astrophys.
    J. 517, 565 (1999)](http://dx.doi.org/10.1086/307221), [astro-ph/9812133](http://arxiv.org/abs/astro-ph/9812133)
    .
  id: totrans-106
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Perlmutter *et al.* (1999) S. Perlmutter, G. Aldering, *et al.*，[Astrophys.
    J. 517, 565 (1999)](http://dx.doi.org/10.1086/307221)，[astro-ph/9812133](http://arxiv.org/abs/astro-ph/9812133)。
- en: Tonry *et al.* (2003) J. L. Tonry, B. P. Schmidt, B. Barris, P. Candia, P. Challis,
    A. Clocchiatti, A. L. Coil, A. V. Filippenko, P. Garnavich, C. Hogan, S. T. Holland,
    S. Jha, R. P. Kirshner, K. Krisciunas, B. Leibundgut, W. Li, T. Matheson, M. M. Phillips,
    A. G. Riess, R. Schommer, R. C. Smith, J. Sollerman, J. Spyromilio, C. W. Stubbs,
     and N. B. Suntzeff, [Astrophys. J. 594, 1 (2003)](http://dx.doi.org/10.1086/376865), [astro-ph/0305008](http://arxiv.org/abs/astro-ph/0305008)
    .
  id: totrans-107
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tonry *et al.* (2003) J. L. Tonry, B. P. Schmidt, B. Barris, P. Candia, P. Challis,
    A. Clocchiatti, A. L. Coil, A. V. Filippenko, P. Garnavich, C. Hogan, S. T. Holland,
    S. Jha, R. P. Kirshner, K. Krisciunas, B. Leibundgut, W. Li, T. Matheson, M. M.
    Phillips, A. G. Riess, R. Schommer, R. C. Smith, J. Sollerman, J. Spyromilio,
    C. W. Stubbs, 和 N. B. Suntzeff，[Astrophys. J. 594, 1 (2003)](http://dx.doi.org/10.1086/376865)，[astro-ph/0305008](http://arxiv.org/abs/astro-ph/0305008)。
- en: Knop *et al.* (2003) R. A. Knop, G. Aldering, *et al.*, [Astrophys. J. 598, 102
    (2003)](http://dx.doi.org/10.1086/378560), [arXiv:astro-ph/0309368 [astro-ph]](http://arxiv.org/abs/astro-ph/0309368)
    .
  id: totrans-108
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Knop *et al.* (2003) R. A. Knop, G. Aldering, *et al.*，[Astrophys. J. 598, 102
    (2003)](http://dx.doi.org/10.1086/378560)，[arXiv:astro-ph/0309368 [astro-ph]](http://arxiv.org/abs/astro-ph/0309368)。
- en: Doi *et al.* (1993) M. Doi, M. Fukugita,  and S. Okamura, [MNRAS  264, 832 (1993)](http://dx.doi.org/10.1093/mnras/264.4.832).
  id: totrans-109
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doi *et al.* (1993) M. Doi, M. Fukugita, 和 S. Okamura，[MNRAS 264, 832 (1993)](http://dx.doi.org/10.1093/mnras/264.4.832)。
- en: Wijesinghe *et al.* (2010) D. B. Wijesinghe, A. M. Hopkins, B. C. Kelly, N. Welikala,
     and A. J. Connolly, [MNRAS  404, 2077 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16424.x), [arXiv:1001.5322
    [astro-ph.GA]](http://arxiv.org/abs/1001.5322) .
  id: totrans-110
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wijesinghe *et al.* (2010) D. B. Wijesinghe, A. M. Hopkins, B. C. Kelly, N.
    Welikala, 和 A. J. Connolly，[MNRAS 404, 2077 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16424.x)，[arXiv:1001.5322
    [astro-ph.GA]](http://arxiv.org/abs/1001.5322)。
- en: Eisenstein *et al.* (2011) D. J. Eisenstein, D. H. Weinberg, E. Agol, H. Aihara,
    C. Allende Prieto, S. F. Anderson, J. A. Arns, É. Aubourg, S. Bailey, E. Balbinot,
     and et al., [The Astronomical Journal  142, 72 (2011)](http://dx.doi.org/10.1088/0004-6256/142/3/72), [arXiv:1101.1529
    [astro-ph.IM]](http://arxiv.org/abs/1101.1529) .
  id: totrans-111
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eisenstein *et al.* (2011) D. J. Eisenstein, D. H. Weinberg, E. Agol, H. Aihara,
    C. Allende Prieto, S. F. Anderson, J. A. Arns, É. Aubourg, S. Bailey, E. Balbinot,
    和 *et al.*，[The Astronomical Journal 142, 72 (2011)](http://dx.doi.org/10.1088/0004-6256/142/3/72)，[arXiv:1101.1529
    [astro-ph.IM]](http://arxiv.org/abs/1101.1529)。
- en: Conselice (2003) C. J. Conselice, [ApJS 147, 1 (2003)](http://dx.doi.org/10.1086/375001), [astro-ph/0303065](http://arxiv.org/abs/astro-ph/0303065)
    .
  id: totrans-112
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Conselice (2003) C. J. Conselice，[ApJS 147, 1 (2003)](http://dx.doi.org/10.1086/375001)，[astro-ph/0303065](http://arxiv.org/abs/astro-ph/0303065)。
- en: Lahav *et al.* (1995) O. Lahav, A. Naim, R. J. Buta, H. G. Corwin, G. de Vaucouleurs,
    A. Dressler, J. P. Huchra, S. van den Bergh, S. Raychaudhury, L. Sodre, Jr.,  and M. C. Storrie-Lombardi, [Science 267, 859
    (1995)](http://dx.doi.org/10.1126/science.267.5199.859), [astro-ph/9412027](http://arxiv.org/abs/astro-ph/9412027)
    .
  id: totrans-113
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lahav *et al.* (1995) O. Lahav, A. Naim, R. J. Buta, H. G. Corwin, G. de Vaucouleurs,
    A. Dressler, J. P. Huchra, S. van den Bergh, S. Raychaudhury, L. Sodre, Jr., 和
    M. C. Storrie-Lombardi，[Science 267, 859 (1995)](http://dx.doi.org/10.1126/science.267.5199.859)，[astro-ph/9412027](http://arxiv.org/abs/astro-ph/9412027)。
- en: Lahav *et al.* (1996) O. Lahav, A. Naim, L. Sodré, Jr.,  and M. C. Storrie-Lombardi, [MNRAS  283, 207
    (1996)](http://dx.doi.org/10.1093/mnras/283.1.207), [astro-ph/9508012](http://arxiv.org/abs/astro-ph/9508012)
    .
  id: totrans-114
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lahav *et al.* (1996) O. Lahav, A. Naim, L. Sodré, Jr., 和 M. C. Storrie-Lombardi，[MNRAS
    283, 207 (1996)](http://dx.doi.org/10.1093/mnras/283.1.207)，[astro-ph/9508012](http://arxiv.org/abs/astro-ph/9508012)。
- en: Banerji *et al.* (2010) M. Banerji, O. Lahav, C. J. Lintott, F. B. Abdalla,
    K. Schawinski, S. P. Bamford, D. Andreescu, P. Murray, M. J. Raddick, A. Slosar,
    A. Szalay, D. Thomas,  and J. Vandenberg, [MNRAS  406, 342 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x), [arXiv:0908.2033](http://arxiv.org/abs/0908.2033)
    .
  id: totrans-115
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Banerji *et al.* (2010) M. Banerji, O. Lahav, C. J. Lintott, F. B. Abdalla,
    K. Schawinski, S. P. Bamford, D. Andreescu, P. Murray, M. J. Raddick, A. Slosar,
    A. Szalay, D. Thomas, 和 J. Vandenberg，[MNRAS 406, 342 (2010)](http://dx.doi.org/10.1111/j.1365-2966.2010.16713.x)，[arXiv:0908.2033](http://arxiv.org/abs/0908.2033)。
- en: Dark Energy Survey Collaboration *et al.* (2016) Dark Energy Survey Collaboration
    *et al.*, [MNRAS  460, 1270 (2016)](http://dx.doi.org/10.1093/mnras/stw641), [arXiv:1601.00329](http://arxiv.org/abs/1601.00329)
    .
  id: totrans-116
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dark Energy Survey Collaboration *et al.* (2016) Dark Energy Survey Collaboration
    *et al.*，[MNRAS 460, 1270 (2016)](http://dx.doi.org/10.1093/mnras/stw641)，[arXiv:1601.00329](http://arxiv.org/abs/1601.00329)。
- en: LSST Dark Energy Science Collaboration (2012) LSST Dark Energy Science Collaboration, ArXiv
    e-prints  (2012), [arXiv:1211.0310 [astro-ph.CO]](http://arxiv.org/abs/1211.0310)
    .
  id: totrans-117
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LSST Dark Energy Science Collaboration (2012) LSST Dark Energy Science Collaboration，ArXiv
    e-prints (2012)，[arXiv:1211.0310 [astro-ph.CO]](http://arxiv.org/abs/1211.0310)。
- en: Domínguez Sánchez *et al.* (2018) H. Domínguez Sánchez, Huertas-Company, *et al.*, ArXiv
    e-prints , arXiv:1807.00807 (2018), [arXiv:1807.00807 [astro-ph.GA]](http://arxiv.org/abs/1807.00807)
    .
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Domínguez Sánchez *et al.* (2018) H. Domínguez Sánchez, Huertas-Company, *et
    al.*，ArXiv e-prints，arXiv:1807.00807 (2018)，[arXiv:1807.00807 [astro-ph.GA]](http://arxiv.org/abs/1807.00807)。
- en: Chollet (2016) F. Chollet, ArXiv e-prints , arXiv:1610.02357 (2016), [arXiv:1610.02357
    [cs.CV]](http://arxiv.org/abs/1610.02357) .
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet (2016) F. Chollet，ArXiv e-prints，arXiv:1610.02357 (2016)，[arXiv:1610.02357
    [cs.CV]](http://arxiv.org/abs/1610.02357)。
- en: George *et al.* (2018) D. George, H. Shen,  and E. A. Huerta, [Phys. Rev. D 97, 101501
    (2018)](http://dx.doi.org/10.1103/PhysRevD.97.101501).
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: George *et al.* (2018) D. George, H. Shen, 和 E. A. Huerta，[Phys. Rev. D 97,
    101501 (2018)](http://dx.doi.org/10.1103/PhysRevD.97.101501)。
- en: Deng *et al.* (2009) J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li,  and L. Fei-Fei, in *Proc.
    CVPR* (2009).
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng *et al.* (2009) J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, 和 L. Fei-Fei，在
    *Proc. CVPR* (2009)。
- en: Tan *et al.* (2018) C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang,  and C. Liu, arXiv
    e-prints , arXiv:1808.01974 (2018), [arXiv:1808.01974 [cs.LG]](http://arxiv.org/abs/1808.01974)
    .
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tan *et al.* (2018) C. Tan, F. Sun, T. Kong, W. Zhang, C. Yang, 和 C. Liu，arXiv
    e-prints，arXiv:1808.01974 (2018)，[arXiv:1808.01974 [cs.LG]](http://arxiv.org/abs/1808.01974)。
- en: Barchi *et al.* (2019) P. H. Barchi, R. R. de Carvalho, R. R. Rosa, R. Sautter,
    M. Soares-Santos, B. A. D. Marques,  and E. Clua, arXiv e-prints , arXiv:1901.07047
    (2019), [arXiv:1901.07047 [astro-ph.IM]](http://arxiv.org/abs/1901.07047) .
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barchi *et al.* (2019) P. H. Barchi, R. R. de Carvalho, R. R. Rosa, R. Sautter,
    M. Soares-Santos, B. A. D. Marques, 和 E. Clua，arXiv e-prints，arXiv:1901.07047
    (2019)，[arXiv:1901.07047 [astro-ph.IM]](http://arxiv.org/abs/1901.07047)。
- en: Lintott *et al.* (2011) C. Lintott, K. Schawinski, S. Bamford, A. Slosar, K. Land,
    D. Thomas, E. Edmondson, K. Masters, R. C. Nichol, M. J. Raddick, A. Szalay, D. Andreescu,
    P. Murray,  and J. Vandenberg, [MNRAS  410, 166 (2011)](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x), [arXiv:1007.3265
    [astro-ph.GA]](http://arxiv.org/abs/1007.3265) .
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lintott *et al.* (2011) C. Lintott, K. Schawinski, S. Bamford, A. Slosar, K.
    Land, D. Thomas, E. Edmondson, K. Masters, R. C. Nichol, M. J. Raddick, A. Szalay,
    D. Andreescu, P. Murray, 和 J. Vandenberg，[MNRAS 410, 166 (2011)](http://dx.doi.org/10.1111/j.1365-2966.2010.17432.x)，[arXiv:1007.3265
    [astro-ph.GA]](http://arxiv.org/abs/1007.3265)。
- en: SDSS (2018) SDSS, “SDSS Skyserver,”  (2018), [http://skyserver.sdss.org/dr7/en/tools/search/sql.asp](http://skyserver.sdss.org/dr7/en/tools/search/sql.asp).
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: SDSS (2018) SDSS，“SDSS Skyserver，” (2018)，[http://skyserver.sdss.org/dr7/en/tools/search/sql.asp](http://skyserver.sdss.org/dr7/en/tools/search/sql.asp)。
- en: 'Gropp *et al.* (1999) W. Gropp, E. Lusk,  and A. Skjellum, *Using MPI: Portable
    Programming with the Message-Passing Interface (2nd ed.), by William Gropp, Ewing
    Lusk and Anthony Skjellum, Scientific and Engineering Computation Series, MIT
    Press, Cambridge, MA, 1999.* (1999).'
  id: totrans-126
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gropp *et al.* (1999) W. Gropp, E. Lusk, 和 A. Skjellum，*Using MPI: Portable
    Programming with the Message-Passing Interface (2nd ed.), by William Gropp, Ewing
    Lusk and Anthony Skjellum, Scientific and Engineering Computation Series, MIT
    Press, Cambridge, MA, 1999.* (1999)。'
- en: Kramer *et al.* (2015) W. Kramer, M. Butler, G. Bauer, K. Chadalavada,  and C. Mendes, in *High
    Performance Parallel I/O*, edited by Prabhat and Q. Koziol (CRC Publications,
    Taylor and Francis Group, 2015) pp. 17–32\.
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kramer *et al.* (2015) W. Kramer, M. Butler, G. Bauer, K. Chadalavada, 和 C.
    Mendes，在 *High Performance Parallel I/O*，由 Prabhat 和 Q. Koziol 编辑 (CRC Publications,
    Taylor and Francis Group, 2015) 第17–32页。
- en: DES (2018) DES, “NCSA DESaccess Web,”  (2018), [https://deslabs.ncsa.illinois.edu/](https://deslabs.ncsa.illinois.edu/).
  id: totrans-128
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: DES (2018) DES，“NCSA DESaccess Web，” (2018)，[https://deslabs.ncsa.illinois.edu/](https://deslabs.ncsa.illinois.edu/)。
- en: 'Keras (2018) Keras, “Keras: The Python Deep Learning library,”  (2018), [https://keras.io/](https://keras.io/).'
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Keras (2018) Keras，“Keras: The Python Deep Learning library，” (2018)，[https://keras.io/](https://keras.io/)。'
- en: Abadi *et al.* (2016) M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro,
    G. S. Corrado, A. Davis, J. Dean,  and M. Devin, arXiv preprint arXiv:1603.04467 
    (2016).
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abadi *et al.* (2016) M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C.
    Citro, G. S. Corrado, A. Davis, J. Dean, 和 M. Devin, arXiv 预印本 arXiv:1603.04467
    (2016)。
- en: Russakovsky *et al.* (2014) O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
    S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg,  and L. Fei-Fei, ArXiv
    e-prints , arXiv:1409.0575 (2014), [arXiv:1409.0575 [cs.CV]](http://arxiv.org/abs/1409.0575)
    .
  id: totrans-131
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Russakovsky *et al.* (2014) O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh,
    S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, 和 L. Fei-Fei,
    ArXiv 电子预印本, arXiv:1409.0575 (2014), [arXiv:1409.0575 [cs.CV]](http://arxiv.org/abs/1409.0575)。
- en: Szegedy *et al.* (2015) C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens,  and Z. Wojna, ArXiv
    e-prints , arXiv:1512.00567 (2015), [arXiv:1512.00567 [cs.CV]](http://arxiv.org/abs/1512.00567)
    .
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy *et al.* (2015) C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, 和 Z.
    Wojna, ArXiv 电子预印本, arXiv:1512.00567 (2015), [arXiv:1512.00567 [cs.CV]](http://arxiv.org/abs/1512.00567)。
- en: He *et al.* (2015) K. He, X. Zhang, S. Ren,  and J. Sun, ArXiv e-prints , arXiv:1512.03385
    (2015), [arXiv:1512.03385 [cs.CV]](http://arxiv.org/abs/1512.03385) .
  id: totrans-133
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He *et al.* (2015) K. He, X. Zhang, S. Ren, 和 J. Sun, ArXiv 电子预印本, arXiv:1512.03385
    (2015), [arXiv:1512.03385 [cs.CV]](http://arxiv.org/abs/1512.03385)。
- en: Simonyan and Zisserman (2014) K. Simonyan and A. Zisserman, ArXiv e-prints , arXiv:1409.1556
    (2014), [arXiv:1409.1556 [cs.CV]](http://arxiv.org/abs/1409.1556) .
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonyan 和 Zisserman (2014) K. Simonyan 和 A. Zisserman, ArXiv 电子预印本, arXiv:1409.1556
    (2014), [arXiv:1409.1556 [cs.CV]](http://arxiv.org/abs/1409.1556)。
- en: Kornblith *et al.* (2018) S. Kornblith, J. Shlens,  and Q. V. Le, “Do better
    imagenet models transfer better?”  (2018), [arXiv:1805.08974](http://arxiv.org/abs/arXiv:1805.08974)
    .
  id: totrans-135
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kornblith *et al.* (2018) S. Kornblith, J. Shlens, 和 Q. V. Le, “更好的 ImageNet
    模型是否能更好地迁移？” (2018), [arXiv:1805.08974](http://arxiv.org/abs/arXiv:1805.08974)。
- en: Andrej Karpathy (2018) Andrej Karpathy, “Convolutional Neural Networks for Visual
    Recognition,”  (2018), [http://cs231n.github.io/neural-networks-2/](http://cs231n.github.io/neural-networks-2/).
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Andrej Karpathy (2018) Andrej Karpathy, “卷积神经网络在视觉识别中的应用，” (2018), [http://cs231n.github.io/neural-networks-2/](http://cs231n.github.io/neural-networks-2/)。
- en: Zeiler and Fergus (2014) M. D. Zeiler and R. Fergus, in *ECCV* (2014).
  id: totrans-137
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeiler 和 Fergus (2014) M. D. Zeiler 和 R. Fergus, 在 *ECCV* (2014)。
- en: Yosinski *et al.* (2014) J. Yosinski, J. Clune, Y. Bengio,  and H. Lipson, in [*Proceedings
    of the 27th International Conference on Neural Information Processing Systems
    - Volume 2*](http://dl.acm.org/citation.cfm?id=2969033.2969197), NIPS’14 (MIT
    Press, Cambridge, MA, USA, 2014) pp. 3320–3328\.
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yosinski *et al.* (2014) J. Yosinski, J. Clune, Y. Bengio, 和 H. Lipson, 在 [*第27届国际神经信息处理系统会议论文集
    - 第2卷*](http://dl.acm.org/citation.cfm?id=2969033.2969197), NIPS’14 (MIT Press,
    剑桥, MA, USA, 2014) pp. 3320–3328。
- en: Ackermann *et al.* (2018) S. Ackermann, K. Schawinski, C. Zhang, A. K. Weigel,
     and M. D. Turp, [MNRAS  479, 415 (2018)](http://dx.doi.org/10.1093/mnras/sty1398), [arXiv:1805.10289
    [astro-ph.IM]](http://arxiv.org/abs/1805.10289) .
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ackermann *et al.* (2018) S. Ackermann, K. Schawinski, C. Zhang, A. K. Weigel,
    和 M. D. Turp, [MNRAS 479, 415 (2018)](http://dx.doi.org/10.1093/mnras/sty1398),
    [arXiv:1805.10289 [astro-ph.IM]](http://arxiv.org/abs/1805.10289)。
- en: XSEDE (2018) XSEDE, “The Approach to Bridges,”  (2018), [https://www.psc.edu/bridges](https://www.psc.edu/bridges).
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: XSEDE (2018) XSEDE, “关于桥梁的介绍，” (2018), [https://www.psc.edu/bridges](https://www.psc.edu/bridges)。
- en: Kingma and Ba (2014) D. P. Kingma and J. Ba, [CoRR abs/1412.6980 (2014)](http://arxiv.org/abs/1412.6980).
  id: totrans-141
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 和 Ba (2014) D. P. Kingma 和 J. Ba, [CoRR abs/1412.6980 (2014)](http://arxiv.org/abs/1412.6980)。
- en: Sergeev and Balso (2018) A. Sergeev and M. D. Balso, arXiv preprint arXiv:1802.05799 
    (2018).
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sergeev 和 Balso (2018) A. Sergeev 和 M. D. Balso, arXiv 预印本 arXiv:1802.05799
    (2018)。
- en: Goyal *et al.* (2017) P. Goyal, P. Dollár, R. B. Girshick, P. Noordhuis, L. Wesolowski,
    A. Kyrola, A. Tulloch, Y. Jia,  and K. He, [CoRR abs/1706.02677 (2017)](http://arxiv.org/abs/1706.02677), [arXiv:1706.02677](http://arxiv.org/abs/1706.02677)
    .
  id: totrans-143
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goyal *et al.* (2017) P. Goyal, P. Dollár, R. B. Girshick, P. Noordhuis, L.
    Wesolowski, A. Kyrola, A. Tulloch, Y. Jia, 和 K. He, [CoRR abs/1706.02677 (2017)](http://arxiv.org/abs/1706.02677),
    [arXiv:1706.02677](http://arxiv.org/abs/1706.02677)。
- en: van der Maaten and Hinton (2008) L. van der Maaten and G. Hinton, Journal of
    Machine Learning Research 9, 2579 (2008).
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: van der Maaten 和 Hinton (2008) L. van der Maaten 和 G. Hinton, 机器学习研究期刊 9, 2579
    (2008)。
- en: NCSA (2018a) NCSA, “Unsupervised learning and data clustering for the construction
    of Galaxy Catalogs in the Dark Energy Survey,”  (2018a), [https://www.youtube.com/watch?v=n5rI573i6ws](https://www.youtube.com/watch?v=n5rI573i6ws).
  id: totrans-145
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NCSA (2018a) NCSA, “用于暗能量调查中银河系目录构建的无监督学习和数据聚类，” (2018a), [https://www.youtube.com/watch?v=n5rI573i6ws](https://www.youtube.com/watch?v=n5rI573i6ws)。
- en: Wattenberg *et al.* (2016) M. Wattenberg, F. ViÃ©gas,  and I. Johnson, [Distill 
    (2016), 10.23915/distill.00002](http://dx.doi.org/10.23915/distill.00002).
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wattenberg *et al.* (2016) M. Wattenberg, F. Viégas, 和 I. Johnson, [Distill
    (2016), 10.23915/distill.00002](http://dx.doi.org/10.23915/distill.00002)。
- en: Cao and Wang (2017) Y. Cao and L. Wang, arXiv e-prints , arXiv:1708.03229 (2017), [arXiv:1708.03229
    [cs.AI]](http://arxiv.org/abs/1708.03229) .
  id: totrans-147
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 和 Wang (2017) Y. Cao 和 L. Wang, arXiv 电子预印本, arXiv:1708.03229 (2017), [arXiv:1708.03229
    [cs.AI]](http://arxiv.org/abs/1708.03229)。
- en: (44) Benchmarks.AI, “MNIST. Classify handwritten digits,” [https://benchmarks.ai/mnist](https://benchmarks.ai/mnist).
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (44) Benchmarks.AI, “MNIST. 分类手写数字，” [https://benchmarks.ai/mnist](https://benchmarks.ai/mnist)。
- en: NCSA (2018b) NCSA, “Deep transfer learning at scale for cosmology,”  (2018b), [https://www.youtube.com/watch?v=1F3q7M8QjTQ](https://www.youtube.com/watch?v=1F3q7M8QjTQ).
  id: totrans-149
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: NCSA (2018b) NCSA, “大规模宇宙学深度迁移学习，” (2018b), [https://www.youtube.com/watch?v=1F3q7M8QjTQ](https://www.youtube.com/watch?v=1F3q7M8QjTQ)。
- en: Appendix A Neural network architecture
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录A 神经网络架构
- en: The top panel in Figure [7](#A1.F7 "Figure 7 ‣ Appendix A Neural network architecture
    ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy
    Survey") presents the architecture of the pre-trained Xception model Chollet ([2016](#bib.bib15))
    used in these studies. The bottom panel of Figure [7](#A1.F7 "Figure 7 ‣ Appendix
    A Neural network architecture ‣ Deep Learning at Scale for the Construction of
    Galaxy Catalogs in the Dark Energy Survey") shows the fully connected layers,
    and classifier added at the second-to-last layer of the pre-trained Xception model.
    This is labeled as 2048-dimensional vectors in the Exit flow diagram. Following
    this procedure, we truncate our neural network classifier and turn it into a feature
    extractor, which we can use in combination with t-SNE to do unsupervised clustering.
    Note that we use t-SNE just as a visual aid. The labelling of unlabeled DES datasets
    is done using our neural network classifier.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 图[7](#A1.F7 "图7 ‣ 附录A 神经网络架构 ‣ 深度学习规模下的暗能量调查星系目录构建")中的顶部面板展示了在这些研究中使用的预训练Xception模型
    Chollet ([2016](#bib.bib15)) 的架构。图[7](#A1.F7 "图7 ‣ 附录A 神经网络架构 ‣ 深度学习规模下的暗能量调查星系目录构建")的底部面板显示了全连接层和在预训练Xception模型的倒数第二层添加的分类器。这在Exit流图中标记为2048维向量。按照这一过程，我们将神经网络分类器截断，转变为特征提取器，可以与t-SNE结合用于无监督聚类。注意，我们使用t-SNE仅作为视觉辅助工具。未标记DES数据集的标注是使用我们的神经网络分类器完成的。
- en: '![Refer to caption](img/2b260eb7e8ee43f4ec7e627d7d4f7a96.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2b260eb7e8ee43f4ec7e627d7d4f7a96.png)'
- en: 'Figure 7: Top panel: Xception model Chollet ([2016](#bib.bib15)). Bottom panel:
    fully connected layers, and classifier added at the bottleneck of the pre-trained
    Xception model.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：顶部面板：Xception模型 Chollet ([2016](#bib.bib15))。底部面板：在预训练的Xception模型的瓶颈处添加了全连接层和分类器。
- en: Appendix B Data Augmentation
  id: totrans-154
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录B 数据增强
- en: '![Refer to caption](img/b50be3be06bbbafa92bf119f0c58c827.png)'
  id: totrans-155
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b50be3be06bbbafa92bf119f0c58c827.png)'
- en: 'Figure 8: Data augmentations include random rotations of up to 45 degrees,
    random flips, height and width shifts and zooms of up to a factor of 1.3'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：数据增强包括最多45度的随机旋转、随机翻转、高度和宽度的位移，以及最多1.3倍的缩放。
- en: To expose the neural network to a variety of potential scenarios for classification,
    we augment original galaxy images with random vertical and horizontal flips, random
    rotations, height and width shifts and zooms, as shown in Figure [8](#A2.F8 "Figure
    8 ‣ Appendix B Data Augmentation ‣ Deep Learning at Scale for the Construction
    of Galaxy Catalogs in the Dark Energy Survey"). The range for random rotations
    is set up to a maximum of 45^∘, i.e. for each iteration of training the neural
    net sees the input image rotated randomly between -45^∘ and 45^∘. Similarly the
    maximum range for random height and width shifts, as well as zooming factor is
    set to 0.3\. Note that for each iteration of training all these image transformations
    are applied but with random values within the defined ranges.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 为了将神经网络暴露于多种潜在分类场景中，我们通过随机的垂直和水平翻转、随机旋转、高度和宽度位移以及缩放来增强原始星系图像，如图[8](#A2.F8 "图8
    ‣ 附录B 数据增强 ‣ 深度学习规模下的暗能量调查星系目录构建")所示。随机旋转的范围设置为最多45^∘，即在每次训练迭代中，神经网络看到的输入图像在-45^∘和45^∘之间随机旋转。同样，随机高度和宽度位移以及缩放因子的最大范围设置为0.3。注意，在每次训练迭代中，所有这些图像变换都应用，但在定义的范围内使用随机值。
- en: This approach not only synthetically increases the training dataset, but also
    makes the neural network invariant to rotations, shifts, flips and combinations
    of these, and also introduces scale invariance.
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 这种方法不仅合成性地增加了训练数据集，还使神经网络对旋转、位移、翻转及其组合不变，同时引入了尺度不变性。
- en: Appendix C Classification predictions for unlabelled DES galaxies
  id: totrans-159
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录C 未标记DES星系的分类预测
- en: Figure [9](#A3.F9 "Figure 9 ‣ Appendix C Classification predictions for unlabelled
    DES galaxies ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey") presents high-confidence neural network predictions
    for unlabelled DES galaxies. The robustness of these predictions were tested with
    our unsupervised clustering algorithm, finding that these classifications, based
    on the morphological features extracted from the DES images in three filters,
    are meaningful, as shown in the t-SNE projections in Figure [5](#S3.F5 "Figure
    5 ‣ III Results ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs
    in the Dark Energy Survey").
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 图[9](#A3.F9 "图 9 ‣ 附录 C 对未标记 DES 星系的分类预测 ‣ 大规模深度学习用于构建暗能量调查中的星系目录")展示了对未标记 DES
    星系的高置信度神经网络预测。这些预测的鲁棒性通过我们的无监督聚类算法进行了测试，结果发现这些基于从 DES 图像中提取的形态特征的分类是有意义的，如图[5](#S3.F5
    "图 5 ‣ III 结果 ‣ 大规模深度学习用于构建暗能量调查中的星系目录")中的 t-SNE 投影所示。
- en: '![Refer to caption](img/dfa896728d366964477e35bd30a93c21.png)    ![Refer to
    caption](img/1992d574fe5a6ded936ce2e433df6637.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dfa896728d366964477e35bd30a93c21.png)    ![参见说明](img/1992d574fe5a6ded936ce2e433df6637.png)'
- en: 'Figure 9: Sample of high confidence predictions for spiral (left panel) and
    elliptical galaxies (right panel) on an unlabelled DES set.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：在未标记的 DES 数据集中对螺旋星系（左面板）和椭圆星系（右面板）的高置信度预测样本。
- en: Appendix D Scaling Results
  id: totrans-163
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录 D 缩放结果
- en: 'In Table[3](#A4.T3 "Table 3 ‣ Appendix D Scaling Results ‣ Deep Learning at
    Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey") the
    training is comprised of three stages: (1) freeze the base model and train added
    dense layers; (2) freeze layers 0-39, and train layers 40+; (3) freeze layers
    0-1 and train all layers 2+. The number of epochs for each stage is given in the
    third column. The total time only includes the time for the training (all three
    stages), but not the time for initialization (launching jobs, loading Python modules,
    data preparation, etc), which we found was minimal compared to the training time.'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在表[3](#A4.T3 "表 3 ‣ 附录 D 缩放结果 ‣ 大规模深度学习用于构建暗能量调查中的星系目录")中，训练分为三个阶段：（1）冻结基础模型并训练新增的密集层；（2）冻结第
    0-39 层，训练第 40 层及以上；（3）冻结第 0-1 层，训练所有第 2 层及以上。每个阶段的训练轮次见第三列。总时间仅包括训练时间（三个阶段的时间），不包括初始化时间（启动作业、加载
    Python 模块、数据准备等），我们发现这部分时间与训练时间相比非常少。
- en: '| GPUs | Time per epoch (s) | # epochs | Total time | Accuracy | Val Accuracy
    |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| GPUs | 每轮次时间（秒） | 轮次 | 总时间 | 准确率 | 验证准确率 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 1 |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 1 |'
- en: '&#124; 410 &#124;'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 410 &#124;'
- en: '&#124; 922 &#124;'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 922 &#124;'
- en: '&#124; 1626 &#124;'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1626 &#124;'
- en: '|'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 11 &#124;'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 11 &#124;'
- en: '&#124; 4 &#124;'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 &#124;'
- en: '| 4h 44 m | 0.9992 | 0.9979 |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '| 4小时 44分钟 | 0.9992 | 0.9979 |'
- en: '| 2 |'
  id: totrans-176
  prefs: []
  type: TYPE_TB
  zh: '| 2 |'
- en: '&#124; 231 &#124;'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 231 &#124;'
- en: '&#124; 481 &#124;'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 481 &#124;'
- en: '&#124; 830 &#124;'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 830 &#124;'
- en: '|'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 6 &#124;'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 6 &#124;'
- en: '&#124; 4 &#124;'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 &#124;'
- en: '| 1h 47m | 0.9993 | 0.9990 |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 1小时 47分钟 | 0.9993 | 0.9990 |'
- en: '| 4 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 4 |'
- en: '&#124; 119 &#124;'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 119 &#124;'
- en: '&#124; 246 &#124;'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 246 &#124;'
- en: '&#124; 427 &#124;'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 427 &#124;'
- en: '|'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 5 &#124;'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 5 &#124;'
- en: '&#124; 7 &#124;'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 7 &#124;'
- en: '| 1h 12m | 0.9995 | 0.9990 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| 1小时 12分钟 | 0.9995 | 0.9990 |'
- en: '| 8 |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| 8 |'
- en: '&#124; 64 &#124;'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 64 &#124;'
- en: '&#124; 124 &#124;'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 124 &#124;'
- en: '&#124; 214 &#124;'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 214 &#124;'
- en: '|'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 6 &#124;'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 6 &#124;'
- en: '&#124; 8 &#124;'
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 8 &#124;'
- en: '| 42m | 0.9991 | 0.9979 |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 42分钟 | 0.9991 | 0.9979 |'
- en: '| 16 |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 16 |'
- en: '&#124; 35 &#124;'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 35 &#124;'
- en: '&#124; 63 &#124;'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 63 &#124;'
- en: '&#124; 109 &#124;'
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 109 &#124;'
- en: '|'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 4 &#124;'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 4 &#124;'
- en: '&#124; 17 &#124;'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 17 &#124;'
- en: '| 36m | 0.9993 | 0.9980 |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| 36分钟 | 0.9993 | 0.9980 |'
- en: '| 32 |'
  id: totrans-212
  prefs: []
  type: TYPE_TB
  zh: '| 32 |'
- en: '&#124; 20 &#124;'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 20 &#124;'
- en: '&#124; 31 &#124;'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 31 &#124;'
- en: '&#124; 53 &#124;'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 53 &#124;'
- en: '|'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 6 &#124;'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 6 &#124;'
- en: '&#124; 12 &#124;'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 12 &#124;'
- en: '| 14m | 0.9993 | 0.9990 |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 14分钟 | 0.9993 | 0.9990 |'
- en: '| 64 |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| 64 |'
- en: '&#124; 13 &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 13 &#124;'
- en: '&#124; 15 &#124;'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 15 &#124;'
- en: '&#124; 27 &#124;'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 27 &#124;'
- en: '|'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; 1 &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 1 &#124;'
- en: '&#124; 5 &#124;'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 5 &#124;'
- en: '&#124; 15 &#124;'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 15 &#124;'
- en: '| 8m | 0.9993 | 0.9990 |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| 8分钟 | 0.9993 | 0.9990 |'
- en: 'Table 3: Training results and timings using different numbers of K80 GPUs for
    the Xception model. Validation Accuracy results are given in the final column.
    The training includes three stages: (1) train the dense layers (base layers are
    frozen); (2) train layer 40+ (layers 0-39 are frozen); (3) train Layer 2+ (layer
    0-1 are frozen). The number of epochs shown are for each training stage. The batch
    size is set to be 16\. The benchmarks was done on Cooley supercomputer at Argonne
    Leadership Computer Facility (https://www.alcf.anl.gov/user-guides/cooley).'
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：使用不同数量的K80 GPU训练Xception模型的结果和时间。验证准确率结果在最后一列中给出。训练包括三个阶段：（1）训练密集层（基础层被冻结）；（2）训练第40层及以上（第0-39层被冻结）；（3）训练第2层及以上（第0-1层被冻结）。显示的纪元数是每个训练阶段的。批处理大小设置为16。基准测试在阿贡领导计算设施的Cooley超级计算机上进行（https://www.alcf.anl.gov/user-guides/cooley）。
- en: Appendix E Recursive Training
  id: totrans-231
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录E 递归训练
- en: In addition to providing results for recursive training using ten different
    models (see Figure [6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at Scale
    for the Construction of Galaxy Catalogs in the Dark Energy Survey")), herein we
    also provide ROC results for a typical model out of our ten samples. These ROC
    results indicate that recursive training indeed leads to an increase in classification
    accuracy both for SDSS and DES.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 除了提供使用十种不同模型的递归训练结果（见图[6](#S3.F6 "Figure 6 ‣ III Results ‣ Deep Learning at
    Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")），我们还提供了十个样本中的一个典型模型的ROC结果。这些ROC结果表明，递归训练确实提高了SDSS和DES的分类准确率。
- en: '![Refer to caption](img/e5145fe36c092fe692ea9d16cee83885.png)'
  id: totrans-233
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e5145fe36c092fe692ea9d16cee83885.png)'
- en: '![Refer to caption](img/0e6991dae23c0dd1c220f579f8ed7851.png)'
  id: totrans-234
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0e6991dae23c0dd1c220f579f8ed7851.png)'
- en: 'Figure 10: Top panels: FO SDSS test sets. Bottom panels: FO DES test sets.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：上面面板：FO SDSS测试集。下面面板：FO DES测试集。
- en: Appendix F Misclassified Examples
  id: totrans-236
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 附录F 错误分类示例
- en: We present a gallery of misclassified examples from our high probability (HP)
    test sets. As shown in Figure [11](#A6.F11 "Figure 11 ‣ Appendix F Misclassified
    Examples ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey"), we have only four instances of this nature, all from HP
    DES test set, and one of these corresponds to a noise artifact in the telescope.
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
  zh: 我们展示了来自高概率（HP）测试集的错误分类示例画廊。如图[11](#A6.F11 "Figure 11 ‣ Appendix F Misclassified
    Examples ‣ Deep Learning at Scale for the Construction of Galaxy Catalogs in the
    Dark Energy Survey")所示，我们只有四个这种性质的实例，全部来自HP DES测试集，其中一个对应于望远镜中的噪声伪影。
- en: '![Refer to caption](img/6875505ae4d413cf1f9f34dad1dc7b3a.png)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6875505ae4d413cf1f9f34dad1dc7b3a.png)'
- en: 'Figure 11: There are only four misclassified examples from HP test sets. Of
    these four images, one is a noise artifact in the telescope.'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：来自HP测试集的错误分类示例仅有四个。其中一张是望远镜中的噪声伪影。
- en: In Figure [12](#A6.F12 "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep
    Learning at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")
    we present a sample of inaccurate predictions on the full overlap (FO) test sets.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 在图[12](#A6.F12 "Figure 12 ‣ Appendix F Misclassified Examples ‣ Deep Learning
    at Scale for the Construction of Galaxy Catalogs in the Dark Energy Survey")中，我们展示了全重叠（FO）测试集中的不准确预测示例。
- en: '![Refer to caption](img/9358f4964bb2f04f6a383922984b69a7.png) ![Refer to caption](img/dde6e8b58c076f7171bfb64a1a18b9fa.png)'
  id: totrans-241
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9358f4964bb2f04f6a383922984b69a7.png) ![参见说明](img/dde6e8b58c076f7171bfb64a1a18b9fa.png)'
- en: '![Refer to caption](img/26ccd8e183cc4f23a0317f66281efdf4.png) ![Refer to caption](img/7778ee366689020f2bfd3d9a4eb1292c.png)'
  id: totrans-242
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/26ccd8e183cc4f23a0317f66281efdf4.png) ![参见说明](img/7778ee366689020f2bfd3d9a4eb1292c.png)'
- en: 'Figure 12: A sample of misclassification on FO test sets. The debiased galaxy
    zoo probabilities used to produce the ground truth labels for each image are shown.
    Notice that the debiased galaxy zoo probabilities for each class are very low
    and close to each other, i.e., these samples represent low confidence ground truth
    labels.'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 图12：FO测试集上的错误分类示例。用于生成每个图像的真实标签的去偏银河动物园概率显示出来。请注意，每个类别的去偏银河动物园概率非常低且接近，即这些样本代表了低置信度的真实标签。
