- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:39:30'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2305.12000] Deep Learning Approaches to Lexical Simplification: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.12000](https://ar5iv.labs.arxiv.org/html/2305.12000)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Deep Learning Approaches to Lexical Simplification: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Kai North¹, Tharindu Ranasinghe², Matthew Shardlow³, Marcos Zampieri¹
  prefs: []
  type: TYPE_NORMAL
- en: ¹George Mason University, USA, ²Aston University, UK
  prefs: []
  type: TYPE_NORMAL
- en: ³Manchester Metropolitan University, UK
  prefs: []
  type: TYPE_NORMAL
- en: knorth8@gmu.edu
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Lexical Simplification (LS) is the task of replacing complex for simpler words
    in a sentence whilst preserving the sentence’s original meaning. LS is the lexical
    component of Text Simplification (TS) with the aim of making texts more accessible
    to various target populations. A past survey Paetzold and Specia ([2017b](#bib.bib38))
    has provided a detailed overview of LS. Since this survey, however, the AI/NLP
    community has been taken by storm by recent advances in deep learning, particularly
    with the introduction of large language models (LLM) and prompt learning. The
    high performance of these models sparked renewed interest in LS. To reflect these
    recent advances, we present a comprehensive survey of papers published between
    2017 and 2023 on LS and its sub-tasks with a special focus on deep learning. We
    also present benchmark datasets for the future development of LS systems.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: LS improves the readability of any given text with the aim of helping vocabulary
    and literacy development. LS achieves this by replacing complex words in a sentence
    with simpler alternatives. LS returns a simplified sentence which can be passed
    to a TS system for further syntactic and grammatical simplification. The replaced
    complex words are those words which a general or targeted population found to
    be hard to read, interpret, or understand. Previous LS systems have been designed
    to simplify complex words for children, second language learners, individuals
    with reading disabilities or low-literacy Paetzold and Specia ([2017b](#bib.bib38)).
    LS therefore provides both developers and users with a degree of personalization
    that is unattainable through seq2seq or generative TS systems Yeung and Lee ([2018](#bib.bib59));
    Lee and Yeung ([2018a](#bib.bib24)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep learning, and latterly, LLM and prompt learning, have revolutionized the
    way we approach many NLP tasks, including LS. Previous LS systems have relied
    upon lexicons, rule-based, statistical, n-gram, and word embedding models to identify
    and then simplify complex words Paetzold and Specia ([2017b](#bib.bib38)). These
    approaches would identify a complex word, for example, “bombardment” as being
    in need of simplification and would suggest “attack” as a suitable alternative
    (Figure [1](#S2.F1 "Figure 1 ‣ 2 Pipeline ‣ Deep Learning Approaches to Lexical
    Simplification: A Survey")), hereby referred to as a candidate substitution.'
  prefs: []
  type: TYPE_NORMAL
- en: State-of-the-art deep learning models, such as BERT Devlin et al. ([2019](#bib.bib15)),
    RoBERTa Liu et al. ([2019](#bib.bib27)), GPT-3 Brown et al. ([2020](#bib.bib10)),
    and others, automatically generate, select, and rank candidate substitutions with
    performances superior to traditional approaches. These include relying on pre-existing
    lexicons, simplification rules, or engineered features Saggion et al. ([2022](#bib.bib46)).
    There have been no surveys published on deep learning approaches for LS. The paper
    by Paetzold and Specia ([2017b](#bib.bib38)) is the most recent survey on LS but
    it precedes studies that demonstrate the headway made by state-of-the-art deep
    learning approaches. A broad comprehensive survey on TS was published in 2021Al-Thanyyan
    and Azmi ([2021](#bib.bib1)). However, this survey likewise does not cover recent
    advances in the field nor does it focus specifically on LS. This paper therefore
    continues pre-existing literature by providing an updated survey of the latest
    deep learning approaches for LS and its sub-tasks of substitute generation (SG),
    selection (SS), and ranking (SR).
  prefs: []
  type: TYPE_NORMAL
- en: 2 Pipeline
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We structure this survey around the main components of the LS pipeline: SG,
    SS, and SR (Section [3](#S3 "3 Deep Learning Approaches ‣ Deep Learning Approaches
    to Lexical Simplification: A Survey")). We also provide an overview of recent
    datasets (Section [4](#S4 "4 Resources ‣ Deep Learning Approaches to Lexical Simplification:
    A Survey")), and discuss open challenges in LS (Section [5.1](#S5.SS1 "5.1 Open
    Challenges in LS ‣ 5 Discussion and Conclusion ‣ Deep Learning Approaches to Lexical
    Simplification: A Survey")). Normally, an LS pipeline starts with complex word
    identification (CWI). However, since it is often considered as a standalone precursor,
    we refer the reader to North et al. ([2022b](#bib.bib35)), for a detailed survey
    on CWI methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '<svg  class="ltx_picture" height="381.9" overflow="visible"
    version="1.1" width="453.86"><g transform="translate(0,381.9) matrix(1 0 0 -1
    0 0) translate(108.54,0) translate(0,281.69)" fill="#000000" stroke="#000000"><g
    stroke-width="0.4pt"><g transform="matrix(1.0 0.0 0.0 1.0 -94.36 -95.32)" fill="#000000"
    stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 184.49)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 178.34)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 39.01 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 178.34)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 178.34)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 172.19)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 175.65)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="110.7"
    height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">Complex Sentence</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 187.95)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1
    0 0 -1 0 0)">Bombardment by regime forces</text></g></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 -88.04 -186.06)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 46.635)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 41.83)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 41.83)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 41.83)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 35.68)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="177.61" height="12.3" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">Complex Word Identification</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 51.44)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 26.23 0)"><foreignobject width="123.61"
    height="9.61" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">CWI: Bombardment</foreignobject></g></g></g></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -73.56 -276.8)" fill="#000000" stroke="#000000"><g
    class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 45.29)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 6.57 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 39.14)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 39.14)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 34.335)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><foreignobject width="133.97" height="9.61" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">Substitute Generation</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.75)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="147.11"
    height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SG: assault,
    raid, attack</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0 0.0 1.0
    165.01 -22.14)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 38.13)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 31.98)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    12.95 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 31.98)"><g class="ltx_tikzmatrix_row"
    transform="matrix(1 0 0 1 0 31.98)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r"
    transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix" transform="matrix(1
    0 0 -1 0 25.83)"><g class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 29.3)"><g
    class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1
    0 0)"><foreignobject width="117.61" height="12.3" transform="matrix(1 0 0 -1 0
    16.6)" overflow="visible">Simplified Sentence</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 41.59)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><text transform="matrix(1
    0 0 -1 0 0)">Attack by regime forces</text></g></g></g></g><g transform="matrix(1.0
    0.0 0.0 1.0 152.81 -118.35)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 47.98)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 41.83)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 25.21 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 41.83)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 41.83)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 35.68)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="117.5" height="12.3" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">Substitute Ranking</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 51.44)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="167.93"
    height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SR: #1\.
    attack, #2\. assault</foreignobject></g></g></g></g><g transform="matrix(1.0 0.0
    0.0 1.0 164.8 -209.09)" fill="#000000" stroke="#000000"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 45.29)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 11.59 0)"><g class="ltx_tikzmatrix" transform="matrix(1 0 0 -1 0 39.14)"><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><g class="ltx_tikzmatrix"
    transform="matrix(1 0 0 -1 0 34.335)"><g class="ltx_tikzmatrix_row" transform="matrix(1
    0 0 1 0 39.14)"><g class="ltx_tikzmatrix_col ltx_nopad_l ltx_nopad_r" transform="matrix(1
    0 0 -1 0 0)"><foreignobject width="120.77" height="9.61" transform="matrix(1 0
    0 -1 0 16.6)" overflow="visible">Substitute Selection</foreignobject></g></g></g></g></g></g></g></g><g
    class="ltx_tikzmatrix_row" transform="matrix(1 0 0 1 0 48.75)"><g class="ltx_tikzmatrix_col
    ltx_nopad_l ltx_nopad_r" transform="matrix(1 0 0 -1 0 0)"><foreignobject width="143.94"
    height="12.3" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">SS: assault,
    raid, attack</foreignobject></g></g></g></g></g></g></svg>'
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: LS Pipeline. SG, SS, and SR are the main components of LS.'
  prefs: []
  type: TYPE_NORMAL
- en: Substitute Generation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'SG returns a number: k, of candidates substitutions that are suitable replacements
    for a previously identified complex word. Usually, an LS system will generate
    candidate substitution in the range of k = [1, 3, 5, or 10] with top-k referring
    to the most appropriate candidates. These candidate substitutions need to be more
    simple, hence easier to read, interpret, or understand than the original complex
    word. The candidate substitutions also need to preserve the original complex word’s
    meaning, especially in its provided context.'
  prefs: []
  type: TYPE_NORMAL
- en: Substitute Selection
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SS filters the generated top-k candidate substitutions and removes those which
    are not suitable. For instance, candidate substitutions which are not synonymous
    to the original complex word or that are more complex are often removed.
  prefs: []
  type: TYPE_NORMAL
- en: Substitute Ranking
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: SR orders the remaining top-k candidate substitutions from the most to the least
    appropriate simplification. The original complex word is then replaced with the
    most suitable candidate substitution.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Evaluation Metrics
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'All sub-tasks of the LS pipeline are evaluated using precision, accuracy, recall,
    and F1-score. Several additional metrics have also been used: potential, mean
    average precision (MAP), and accuracy at top-k. Potential is the ratio of predicted
    candidate substitutions for which at least one of the top-k candidate substitutions
    generated was among the gold labels Saggion et al. ([2022](#bib.bib46)). MAP evaluates
    whether the returned top-k candidate substitutions match the gold labels as well
    as whether they have the same positional rank. Accuracy at top-k = [1, 2, or 3]
    is the ratio of instances where at least one of the candidate substitutions at
    k is among the gold labels.'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Deep Learning Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '| Deep Learning Approaches | ACC | ACC@1 | ACC@3 | MAP@3 | Potential@3 | Paper
    |'
  prefs: []
  type: TYPE_TB
- en: '| SG | SS & SR | TSAR-2022 (EN) |  |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3+Prompts | GPT-3 | 0.8096 | 0.4289 | 0.6863 | 0.5834 | 0.9624 | Aumiller
    and Gertz ([2022](#bib.bib7)) |'
  prefs: []
  type: TYPE_TB
- en: '| MLM | LLM+Embeddings+Freq | 0.6568 | 0.3190 | 0.5388 | 0.4730 | 0.8766 |
    Li et al. ([2022](#bib.bib26)) |'
  prefs: []
  type: TYPE_TB
- en: '| LLM+Prompt | MLM Prediction Score | 0.6353 | 0.2895 | 0.5308 | 0.4244 | 0.8739
    | Vásquez-Rodríguez et al. ([2022](#bib.bib55)) |'
  prefs: []
  type: TYPE_TB
- en: '| SG | SS & SR | TSAR-2022 (ES) |  |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3+Prompts | GPT-3 | 0.6521 | 0.3505 | 0.5788 | 0.4281 | 0.8206 | Aumiller
    and Gertz ([2022](#bib.bib7)) |'
  prefs: []
  type: TYPE_TB
- en: '| MLM | Embeddings+POS | 0.3695 | 0.2038 | 0.3288 | 0.2145 | 0.5842 | Whistely
    et al. ([2022](#bib.bib56)) |'
  prefs: []
  type: TYPE_TB
- en: '| LLM+Prompt | MLM Prediction Score | 0.3668 | 0.160 | 0.2690 | 0.2128 | 0.5326
    | Vásquez-Rodríguez et al. ([2022](#bib.bib55)) |'
  prefs: []
  type: TYPE_TB
- en: '| SG | SS & SR | TSAR-2022 (PT) |  |'
  prefs: []
  type: TYPE_TB
- en: '| GPT-3+Prompts | GPT-3 | 0.7700 | 0.4358 | 0.6299 | 0.5014 | 0.9171 | Aumiller
    and Gertz ([2022](#bib.bib7)) |'
  prefs: []
  type: TYPE_TB
- en: '| MLM | MLM Prediction Score | 0.4812 | 0.2540 | 0.3957 | 0.2816 | 0.6871 |
    North et al. ([2022a](#bib.bib34)) |'
  prefs: []
  type: TYPE_TB
- en: '| MLM | Freq+BinaryClassifier | 0.3689 | 0.1737 | 0.2673 | 0.1983 | 0.5240
    | Wilkens et al. ([2022](#bib.bib57)) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 1: The top 3 deep learning approaches across the TSAR-2022 datasets.
    Best performances in bold.'
  prefs: []
  type: TYPE_NORMAL
- en: Prior to deep learning approaches, lexicon, rule-based, statistical, n-gram,
    and word embedding models were state-of-the-art for SG, SS, and SR. As previously
    mentioned, Paetzold and Specia ([2017b](#bib.bib38)) have provided a comprehensive
    survey detailing these approaches, their performances, as well as their impact
    on LS literature. The following sections provide an extension of the work carried
    out by Paetzold and Specia ([2017b](#bib.bib38)). We introduce new deep learning
    approaches for LS and begin our survey of the LS pipeline at the SG phase. The
    recent developments in the CWI step of the pipeline have been extensively surveyed
    by North et al. ([2022b](#bib.bib35)).
  prefs: []
  type: TYPE_NORMAL
- en: 3.1 Substitute Generation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In 2017, word embedding models were state-of-the-art for SG. Word embedding
    models, such as Word2Vec Mikolov et al. ([2013](#bib.bib32)), were used alongside
    more traditional approaches, such as querying a lexicon, or generating candidate
    substitutions based on certain rules Paetzold and Specia ([2017b](#bib.bib38)).
    Word embedding models conducted SG by converting potential candidate substitutions
    into vectors, hence word embeddings, and then calculating which of these vectors
    had the highest cosine similarity, or lowest cosine distance, with the vector
    of the target complex word. These vectors were then converted back into their
    word forms and were considered the top-k candidate substitutions.
  prefs: []
  type: TYPE_NORMAL
- en: Word Embeddings + LLMs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Post 2017, word embedding models continued to be implemented for SG. However,
    they were now combined with the word embeddings produced by LLMs or by a LLM’s
    prediction scores. Alarcón et al. ([2021a](#bib.bib2)) experimented with various
    word embeddings models for generating Spanish candidate substitutions. They used
    word embeddings models, such as Word2Vec, Sense2Vec Trask et al. ([2015](#bib.bib53)),
    and FastText Bojanowski et al. ([2016](#bib.bib9)), along with the pre-trained
    LLM BERT, to generate these word embeddings. It was discovered that a more traditional
    approach that produced candidate substitutions by querying a pre-existing lexicon
    outperformed these word embedding models in terms of both potential and recall
    yet slightly under-performed these word embedding models in regards to precision.
    The traditional approach achieved a potential of 0.898, a recall of 0.597, and
    a precision of 0.043 on the EASIER dataset Alarcón et al. ([2021b](#bib.bib3)).
    The highest performing word embedding model (Sense2Vec), on the other hand, attained
    a potential, recall, and precision score of 0.506, 0.282, and 0.056, respectively.
    Surprisingly, this went against the assumption that word embedding models would
    have achieved a superior performance given their state-of-the-art reputation demonstrated
    by Paetzold and Specia ([2017a](#bib.bib37)). During error analysis, it was found
    that these word embeddings models often produced antonyms of the target complex
    word as potential candidate substitutions. This is due to how word embedding models
    calculate word similarity between vectors.
  prefs: []
  type: TYPE_NORMAL
- en: 'Seneviratne et al. ([2022](#bib.bib47)) used a word embedding model and a pre-trained
    LLM: XLNet Yang et al. ([2019](#bib.bib58)), to produce an embedding similarity
    score and a prediction score for SG. They followed a similar approach conducted
    by Arefyev et al. ([2020](#bib.bib6)). Arefyev et al. ([2020](#bib.bib6)) utilized
    context2vec Melamud et al. ([2016](#bib.bib30)) and ELMo Peters et al. ([2018](#bib.bib41))
    to encode the context of the target complex word to gain a probability distribution
    of each word belonging to that particular context. They then used this probability
    distribution to estimate the likelihood, or appropriateness, of a potential candidate
    substitution replacing the target complex word. This score was used alongside
    a LLM prediction score from either BERT, RoBERTa, or XLNet, to produce a final
    list of top-k candidate substitutions. Both Seneviratne et al. ([2022](#bib.bib47))
    and Arefyev et al. ([2020](#bib.bib6)) discovered that their combined approach
    of using a word embedding model alongside a pre-trained LLM prediction score failed
    to surpass the performance of using a single pre-trained LLM. For instance, Seneviratne
    et al. ([2022](#bib.bib47)) was outperformed by North et al. ([2022a](#bib.bib34))
    on the TSAR-2022 dataset.'
  prefs: []
  type: TYPE_NORMAL
- en: Masked Language Modeling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The introduction of pre-trained LLMs, also saw the arrival of Masked Language
    Modeling (MLM) for SG. Przybyła and Shardlow ([2020](#bib.bib42)) used LLMs trained
    on a MLM objective for multi-word LS, whereas Qiang et al. ([2020](#bib.bib43))
    were the first to use MLM for Spanish SG. MLM has subsequently become a popular
    approach to SG. 7 out of the 11 system reports submitted to TSAR-2022 Saggion
    et al. ([2022](#bib.bib46)), described their approach as consisting of a MLM objective.
  prefs: []
  type: TYPE_NORMAL
- en: Known as LSBert, the model introduced by Qiang et al. ([2020](#bib.bib43)),
    used the pre-trained LLM BERT. Sentences were taken from the LS datasets LexMTurkHorn
    et al. ([2014](#bib.bib20)), BenchLS Paetzold and Specia ([2016b](#bib.bib39)),
    and NNSeval Paetzold and Specia ([2016c](#bib.bib40)). Two versions of each sentence
    were then concatenated, being separated by the [SEP] special token. They were
    then fed into the LLM. The first sentence was identical to that extracted from
    the datasets, whereas the second sentence had its complex word replaced with the
    [MASK] special token. The LLM then attempted to predict the word replaced by the
    [MASK] special token by taking into consideration its left and right context as
    well as the prior original sentence. In this way, LLMs provide candidate substitutions
    with the highest probability (highest prediction score) of fitting into the surrounding
    context and that are also similar to the target complex word in the original sentence.
    For the top-k=1 candidate substitution, LSBert achieved F1-scores for SG of 0.259,
    0.272, and 0.218 on the three datasets LexMTurk Horn et al. ([2014](#bib.bib20)),
    BenchLS Paetzold and Specia ([2016b](#bib.bib39)), and NNSeval Paetzold and Specia
    ([2016c](#bib.bib40)) respectively. These performances surpassed that of all prior
    approaches Paetzold and Specia ([2017b](#bib.bib38)). The previous highest F1-score
    was achieved by a word-embedding model Paetzold and Specia ([2017a](#bib.bib37)),
    which produced F1-scores of 0.195, 0.236, and 0.218 for each dataset, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before the release of the TSAR-2022 shared-task Saggion et al. ([2022](#bib.bib46)),
    Ferres and Saggion ([2022](#bib.bib18)) introduced a new dataset: ALEXSIS (TSAR-2022
    ES), that would later make up (along with an additional English and Portuguese
    dataset) the TSAR-2022 dataset Saggion et al. ([2022](#bib.bib46)). Using their
    Spanish dataset, they experimented with a number of monolingual LLMs pre-trained
    on either Spanish data as well as several multilingual LLMs, such as mBERT and
    RoBERTa. Ferres and Saggion ([2022](#bib.bib18)) adopted the MLM approach used
    by LSBert. They experimented with the Spanish LLMs: BETO Cañete et al. ([2020](#bib.bib11)),
    BERTIN De la Rosa and Fernández ([2022](#bib.bib14)), RoBERTa-base-BNE, and RoBERTA-large-BNE
    Fandiño et al. ([2022](#bib.bib17)) for SG. They discovered that their largest
    pre-trained Spanish LLM: RoBERTA-large-BNE, achieved the greatest SG performance
    after having also removed candidate substitutions equal to the complex word, regardless
    of capitalization or accentuation and being less than 2 characters long.'
  prefs: []
  type: TYPE_NORMAL
- en: 'North et al. ([2022a](#bib.bib34)) was inspired by the success of the monolingual
    LLMs shown by Ferres and Saggion ([2022](#bib.bib18)). They likewise tested a
    range of LLMs for SG with a MLM objective, including multilingual LLLMs: mBERT,
    and XLM-R Conneau et al. ([2020](#bib.bib13)), and several monolingual LLMs, including
    Electra for English Clark et al. ([2020](#bib.bib12)), RoBERTA-large-BNE for Spanish,
    and BERTimbau Souza et al. ([2020](#bib.bib51)) for Portuguese. Their monolingual
    LLMs scored an acc@1 score of 0.517, 0.353, and 0.481 on the English, Spanish,
    and Portuguese TSAR-2022 datasets respectively. Whistely et al. ([2022](#bib.bib56))
    also experimented with similar monolingual LLMs for SG. They used BERT for English,
    BETO for Spanish, and BERTimbau for Portuguese. Interestingly, their models’ performances
    were lower compared to that of North et al. ([2022a](#bib.bib34)), despite their
    Portuguese LS system consisting of the same language model. Whistely et al. ([2022](#bib.bib56))
    achieved acc@1 scores of 0.378, 0.250, and 0.3074 for English, Spanish, and Portuguese,
    respectively. This is likely due to the additional SS and SR steps implemented
    by Whistely et al. ([2022](#bib.bib56)) and the lack thereof shown within the
    LS system provided by North et al. ([2022a](#bib.bib34)) (Section [3.2](#S3.SS2
    "3.2 Substitute Selection and Ranking ‣ 3 Deep Learning Approaches ‣ Deep Learning
    Approaches to Lexical Simplification: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Wilkens et al. ([2022](#bib.bib57)) also used a range of monolingual LLMs for
    SG. However, they used an ensemble of BERT-like models with three different masking
    strategies: 1). copy, 2). query expansion, and 3). paraphrase. The copy strategy
    replicated that of LSBert Qiang et al. ([2020](#bib.bib43)), whereby two sentences
    were inputted into a LLM concatenated with the [SEP] special token. The first
    sentence being an unaltered version of the original sentence, and the second sentence
    having its complex word masked. The query expansion strategy used FastText to
    generate five related words with the highest cosine similarity to the target complex
    word. For iteration 2a). of the query expansion strategy, the first sentence was
    the original unaltered sentence, the second sentence replaced the complex word
    with one of the suggested similar words produced by FastText, and sentence 3 was
    the masked sentence. Iteration 2b). of this strategy was the same as iteration
    2a)., however, sentence 2 now consisted of all five suggested words. Lastly, the
    paraphrase strategy generated 10 new contexts for each complex word composed of
    paraphrases of the original sentence. These new contexts were limited to 512 tokens.
    The ensembles used for these three masking strategies consisted of BERT and RoBERTa
    LLMs for English, several BETO LLMs for Spanish, and several BERTimbau LLMs for
    Portuguese. The paraphrase strategy showed the worst performance with a joint
    MAP/Potential@1 score of 0.217, whereas the query expansion strategy obtained
    a MAP/Potential@1 score of 0.528, 0.477, and 0.476 for English, Spanish, and Portuguese,
    respectively. This surpassed the performance of the paraphrase strategy and the
    original copy strategy used by LSBert, regardless of the LLMs used.'
  prefs: []
  type: TYPE_NORMAL
- en: Prompt Learning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Prompt learning has also been used for SG and is currently state-of-the-art
    (Table [3](#S3 "3 Deep Learning Approaches ‣ Deep Learning Approaches to Lexical
    Simplification: A Survey")). Prompt learning involves feeding into a LLM input
    that is presented in such a way as to provide a description of the task as well
    as to return a desired output. PromptLS is an example of prompt learning applied
    to SG. Created by Vásquez-Rodríguez et al. ([2022](#bib.bib55)), PromptLS consisted
    of a variety of pre-trained LLMs fine-tuned on several LS datasets. These fined-tuned
    LLMs were then presented with four combinations of prompts: a). “a easier word
    for bombardment is”, b). “a simple word for bombardment is”, c). “a easier synonym
    for bombardment is”, and lastly, d). “a simple synonym for bombardment is”. These
    prompt combinations were supplied to a RoBERTa LLM on all of the English data
    extracted from the LexMTurk Horn et al. ([2014](#bib.bib20)), BenchLS Paetzold
    and Specia ([2016b](#bib.bib39)), NNSeval Paetzold and Specia ([2016c](#bib.bib40)),
    and CERF-LS Uchida et al. ([2018](#bib.bib54)) LS datasets. They were also translated
    and fed into BERTIN fine-tuned on the Spanish data obtained from EASIER, along
    with BR-BERTo fine-tuned on all of the Portuguese data taken from SIMPLEX-PB Hartmann
    and Aluísio ([2020](#bib.bib19)). Vásquez-Rodríguez et al. ([2022](#bib.bib55))
    also used these prompts on a zero-shot condition. It was discovered that the fine-tuned
    LLMs outperformed the zero-shot models on all conditions by an average increase
    in performance between 0.3 to 0.4 across all metrics: acc@1, acc@3, MAP@3, and
    Precision@3\. The prompt combinations that produced the best candidate substitutions
    were “easier word” for English, “palabra simple” and “palabra fácil” for Spanish,
    and “palavra simples” and “sinônimo simples” for Portuguese.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Prompt learning has likewise been applied to causal language models for SG,
    such as GPT-3\. Aumiller and Gertz ([2022](#bib.bib7)) experimented with a variety
    of different prompts, which they fed into a GPT-3\. These prompts were of four
    types: 1). zero-shot with context, 2). single-shot with context, two-shot with
    context, 3). zero-shot without context, and 4). single-shot without context. The
    size of each shot: n, refers to how many times a prompt is inputted into GPT-3\.
    For instance, those shots with context would input a given sentence and then ask
    the question, “Given the above context, list ten alternative words for $<$complex
    word$>$ that are easier to understand.”, n number of times. Those without context,
    however, would input n times the following:“Give me ten simplified synonyms for
    the following word: $<$complex word$>$”. Aumiller and Gertz ([2022](#bib.bib7))
    also combined all types of prompts in an ensemble, generating candidate substitutions
    from each prompt type and then deciding upon final candidate substations through
    plurality voting and additional SS and SR steps (Section [3.2](#S3.SS2 "3.2 Substitute
    Selection and Ranking ‣ 3 Deep Learning Approaches ‣ Deep Learning Approaches
    to Lexical Simplification: A Survey")). Their ensemble approach outperformed all
    other prompt types and SG models submitted to TSAR-2022 Saggion et al. ([2022](#bib.bib46))
    (Table [3](#S3 "3 Deep Learning Approaches ‣ Deep Learning Approaches to Lexical
    Simplification: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.2 Substitute Selection and Ranking
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Traditional approaches to SS are still implemented post SG. Methods such as
    POS-tag and antonym filtering, semantic or sentence thresholds have been used
    to remove inappropriate candidate substitutions after having been generating from
    the above deep learning approaches Saggion et al. ([2022](#bib.bib46)). Nevertheless,
    the majority of modern deep learning approaches have minimal SS, with SS often
    being simultaneously conducted during SG or SR. For instance, the metric used
    to generate the top-k candidate substitutions, by it either similarity between
    word embeddings, or a pre-train LLM’s prediction score, tends not to suggest candidate
    substitutions that are deemed as being inappropriate by other SS methods. Likewise,
    SR techniques that rank candidate substitutions in order of their appropriateness
    will in turn move inappropriate simplifications further down the list of top-k
    candidate substitutions to the point that they are no longer considered.
  prefs: []
  type: TYPE_NORMAL
- en: Word Embeddings
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Word embedding models continued to be used for SS without LLMs, regardless of
    the arrival of pre-trained LLMs, such as BERT. For instance, Song et al. ([2020](#bib.bib50))
    created a unique LS system that filtered candidate substitutions by applying a
    semantic similarity threshold, matching only those candidate substitutions with
    the same POS tag as the target complex word, calculating contextual relevance,
    being a measure of how reasonable and fluent a sentence is after the complex word
    had been replaced, and by using cosine similarity between word embeddings to rank
    candidate substitutions. They generated word embeddings by Word2Vec and evaluated
    their model’s performance on the LS-2007 dataset McCarthy and Navigli ([2007](#bib.bib29)).
    It was found that the use of Word2Vec improved their model’s performance having
    achieved an acc@1 of 0.269\. Their second highest performing model, without the
    use of Word2Vec embeddings, produced an acc@1 of 0.218.
  prefs: []
  type: TYPE_NORMAL
- en: Neural Regression
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Maddela and Xu ([2018](#bib.bib28)) created the neural readability ranker (NNR)
    for SR. Consisting of a feature extraction, a Gaussian-based feature vectorization
    layer, and a task specific output node, NNR is a deep learning algorithm capable
    of ranking candidate substitutions based on their perceived complexity. It performances
    regression, whereby having been trained on the Word Complexity Lexicon (WCL),
    as well as several features and character n-grams converted into Gaussian vectors,
    it is able to provide a value between 0 and 1 corresponding to the complexity
    of any given word. It achieves this by conducting pairwise aggregation. For each
    pair of potential candidate substitutions, the model predicts a value that defines
    which candidate substitution is more or less complex than the other. A return
    positive value indicates that the first candidate substitution is more complex
    than the second, whereas a negative value dictates that the second candidate substitution
    is more complex than the first. This is applied to all combinations of candidate
    substitutions given a complex word. Each candidate substitution is then ranked
    in accordance to its comparative complexity with all other potential candidate
    substitutions. Maddela and Xu ([2018](#bib.bib28)) applied their NNR model to
    the LS-2012 dataset and outperformed prior word embedding techniques for SR. They
    achieved an Prec@1 of 0.673, whereas the previous state-of-the-art model provided
    by Paetzold and Specia ([2017a](#bib.bib37)) achieved an Prec@1 of 0.656.
  prefs: []
  type: TYPE_NORMAL
- en: Word Embeddings + LLMs
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One of the most common approaches to SS and SR involves the use of word embeddings
    and LLMs. Seneviratne et al. ([2022](#bib.bib47)) filtered and ranked top-k=20
    candidate substitutions based on the same combined score that they used for SG.
    It consisted of their MLM model’s prediction score of the generated candidate
    together with the inner product of the target word’s embedding and the embedding
    of the potential candidate substitution. These top-k=20 candidate substitutions
    were then subject to one of three additional ranking metrics. The first ranking
    metric (CILex_1) ranked candidate substitutions on their cosine similarity between
    the original sentence and a copy of the original sentence with the candidate substitution
    in place of its complex word. The second and third ranking metrics made use of
    dictionary definitions of the target complex word and its candidate substitutions.
    They calculated the cosine similarity between each embedding of each definition
    and the embedding of the sentence of the target complex word. Those with the highest
    cosine similarities between a). the definition of the target complex word and
    the definition of the candidate substitution (CILex_2), or b). the definition
    of the target complex word and the word embedding of the original sentence with
    the candidate substitution in place of its complex word (CILex_3), were used to
    determine the rank of each candidate substitution. They discovered that all three
    metrics produced similar performances on the TSAR-2022 dataset with CILex 1, 2,
    and 3 achieving acc@1 scores of 0.375, 0.380, and 0.386, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: Li et al. ([2022](#bib.bib26)) used a set of features taken from LSBert combined
    with what they referred to as an equivalence score. Equivalence score was created
    to gauge semantic similarity between candidate substitution and complex word to
    an extent that was more expressive than the cosine similarity between word embeddings.
    To obtain this equivalence score, they used a pre-trained RoBERTa LLM trained
    for natural language inference (NLI) which predicts the likelihood of one sentence
    entailing another. The model was trained on a multi-genre corpus with a MLM objective.
    The product of the returned likelihood of the original sentence with the candidate
    substitution preceding the original sentence and vice-versa equated to the equivalence
    score. Since Li et al. ([2022](#bib.bib26)) used the same method of SG as LSBert,
    having only changed their LLM to RoBERTa, they concluded that their system’s superior
    performance was a consequence of its unique SR. They achieved an acc@1 of 0.659,
    whereas LSBert attained an acc@1 of 0.598 on the English TSAR-2022 dataset Saggion
    et al. ([2022](#bib.bib46)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Aleksandrova and Brochu Dufour ([2022](#bib.bib4)) ranked candidate substitutions
    on three metrics: a). grammaticality, b). meaning preservation, and c). simplicity.
    Grammaticality was calculated by firstly determining whether the candidate substitution
    had the same POS tag in terms of person, number, mood, tense, and so forth. Those
    that matched on all POS-tag categories were assigned the value of 1 or 0 if at
    least one category did not match. Preservation was determined by using BERTScore
    to generate cosine similarities between the embeddings of the original sentence
    and the embeddings of the original sentence, having replaced the target complex
    word with the candidate substitution. Lastly, preservation was obtained by using
    a CEFR vocabulary classifier trained on data from the English Vocabulary Profile
    (EVP). The data used to train the CEFR classifier was first masked and fed into
    a pre-trained LLM: BERT. The outputted encodings were then used to train an SVM
    model resulting in their CEFR classifier. Their model failed to surpass the baseline
    LSBert models at TSAR-2022 in terms of acc@1, having achieved a score of 0.544.'
  prefs: []
  type: TYPE_NORMAL
- en: MLM Prediction Scores
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'LS systems have also relied entirely on MLM prediction scores for SS and SR.
    North et al. ([2022a](#bib.bib34)) and Vásquez-Rodríguez et al. ([2022](#bib.bib55))
    adopt this approach. They have no additional SR steps and rank their candidate
    substitutions per their generated MLM prediction scores. They do, however, apply
    some basic filtering with both studies removing duplicates as well as candidate
    substitutions equal to the complex word. Surprisingly, minimal SR has been shown
    to surpass other more technical approaches (Table [3](#S3 "3 Deep Learning Approaches
    ‣ Deep Learning Approaches to Lexical Simplification: A Survey")). North et al.
    ([2022a](#bib.bib34)) has achieved state-of-the-art performance on the TSAR-2022
    Portuguese dataset, whereas Vásquez-Rodríguez et al. ([2022](#bib.bib55)) has
    consistently produced high performances across the English and Spanish TSAR-2022
    datasets. Only GPT-3 based-models have surpassed these performances Aumiller and
    Gertz ([2022](#bib.bib7)) (Table [3](#S3 "3 Deep Learning Approaches ‣ Deep Learning
    Approaches to Lexical Simplification: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 4 Resources
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Post 2017 LS datasets have been created for either all sub-tasks within the
    LS pipeline or for a specific purpose (Appendix, Table [2](#A1.T2 "Table 2 ‣ Appendix
    A Appendix ‣ Deep Learning Approaches to Lexical Simplification: A Survey")).
    Recent international competitions (shared-tasks) have also provided their own
    LS datasets (*). LS resources are available for multiple languages, predominately
    English (EN), Spanish (ES), Portuguese (PT), French (FR), Japanese (JP), and Chinese
    (ZH).'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 English
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Personalized-LS
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lee and Yeung ([2018b](#bib.bib25)) constructed a dataset of 12,000 English
    words for personalized LS. These words were ranked on a five-point Likert scale.
    15 native Japanese speakers were tasked with rating the complexity of each word.
    These complexity rating were then applied to BenchLS, in turn personalizing the
    dataset for Japanese speakers.
  prefs: []
  type: TYPE_NORMAL
- en: WCL
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Maddela and Xu ([2018](#bib.bib28)) introduced the Word Complexity Lexicon (WCL).
    The WCL is a dataset made up of 15,000 English words annotated with complexity
    ratings. Annotators were 11 non-native English speakers using a six-point Likert
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: LCP-2021*
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The dataset provided at the LCP-2021 shared-task (CompLex) Shardlow et al. ([2020](#bib.bib49)),
    was developed using crowd sourcing. 10,800 complex words in context were selected
    from three corpora covering the Bible, biomedical articles, and European Parliamentary
    proceedings. Their lexical complexities were annotated using a 5-point Likert
    scale.
  prefs: []
  type: TYPE_NORMAL
- en: SimpleText-2021*
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The SimpleText-2021 shared-task Ermakova et al. ([2021](#bib.bib16)) introduced
    three pilot tasks: 1). to select passages to be simplified, 2). to identify complex
    concepts within these passages, and 3). to simplify these complex concepts to
    generate an easier to understand passage. They provided their participants with
    two sources of data, these being the Citation Network Dataset, DBLP+Citation,
    ACM Citation network, together with titles extracted from The Guardian newspaper
    with manually annotated keywords.'
  prefs: []
  type: TYPE_NORMAL
- en: TSAR-2022*
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: TSAR-2022 Saggion et al. ([2022](#bib.bib46)) supplied datasets in English,
    Spanish, and Portuguese. These datasets contained target words in contexts taken
    from journalistic texts and Wikipedia articles, along with 10 candidate substitutions
    (approx. 20 in raw data) provided by crowd-sourced annotators located in the UK,
    Spain, and Brazil. The candidate substitutions were ranked per their suggestion
    frequency. The English, Spanish, and Portuguese datasets contained 386, 381, and
    386 instances, respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Datasets in Other Languages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Spanish
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The ALexS-2020 shared-task Zambrano and Ráez ([2020](#bib.bib61)) included a
    Spanish dataset consisting of 723 complex words from recorded transcripts. Merejildo
    ([2021](#bib.bib31)) provided the Spanish CWI corpus (ES-CWI). A group of 40 native-speaking
    Spanish annotators identified complex words within 3,887 academic texts. The EASIER
    corpus Alarcón et al. ([2021b](#bib.bib3)) contains 5,310 Spanish complex words
    in contexts taken from newspapers with 7,892 candidate substitutions. A small
    version of the corpus is also provided with 500 instances (EASIER-500).
  prefs: []
  type: TYPE_NORMAL
- en: Portuguese
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The PorSimples dataset Aluísio and Gasperin ([2010](#bib.bib5)) consists of
    extracts taken from Brazilian newspapers. The dataset is divided into nine sub-corpora
    separated by degree of simplification and source text. The PorSimplesSent dataset
    Leal et al. ([2018](#bib.bib23)) was adapted from the previous PorSimples dataset.
    It contains strong and natural simplifications of PorSimples’s original sentences.
    SIMPLEX-PB Hartmann and Aluísio ([2020](#bib.bib19)) provides a selection of features
    for each of its candidate substitutions.
  prefs: []
  type: TYPE_NORMAL
- en: French
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'ReSyf contains French synonyms that have been ranked in regards to their reading
    difficulty using a SVM Billami et al. ([2018](#bib.bib8)). It consists of 57,589
    instances with a total of 148,648 candidate substitutions. FrenchLys is a LS tool
    designed by Rolin et al. ([2021](#bib.bib45)). It provides its own dataset that
    contains sentences sampled from a French TS dataset: ALECTOR, and french schoolbooks.
    Substitute candidates were provided by 20 French speaking annotators.'
  prefs: []
  type: TYPE_NORMAL
- en: Japanese
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The Japanese Lexical Substitution (JLS) dataset Kajiwara and Yamamoto ([2015](#bib.bib21))
    contains 243 target words, each with 10 contexts (2,430 instances in total). Crowd-sourced
    annotators provided and ranked candidate substitutions. The JLS Balanced Dataset
    Kodaira et al. ([2016](#bib.bib22)) expanded the previous JLS dataset to make
    it more representative of different genres and contains 2,010 generalized instances.
    Nishihara and Kajiwara ([2020](#bib.bib33)) created a new dataset (JWCL & JSSL)
    that increased the Japanese Education Vocabulary List (JEV). It houses 18,000
    Japanese words divided into three levels of difficulty: easy, medium, or difficult.'
  prefs: []
  type: TYPE_NORMAL
- en: Chinese
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Personalized-ZH Lee and Yeung ([2018a](#bib.bib24)) consists of 600 Chinese
    words. Each word’s complexity was ranked by eight learners of Chinese on a 5-point
    lickert-scale. HanLS was constructed by Qiang et al. ([2021](#bib.bib44)). It
    contains 534 Chinese complex words. 5 native-speaking annotators gave and ranked
    candidate substitutions. Each complex word has on average 8 candidate substitutions.
  prefs: []
  type: TYPE_NORMAL
- en: 5 Discussion and Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Since the 2017 survey on LS Paetzold and Specia ([2017b](#bib.bib38)), deep
    learning approaches have provided new headway within the field. MLM is now the
    go to method for SG, with the majority of recent LS studies having employed a
    MLM objective. The casual language model: GPT-3, surpasses the performance of
    all other approaches when subjected to prompt learning, especially when an ensemble
    of prompts are taken into consideration (Table [3](#S3 "3 Deep Learning Approaches
    ‣ Deep Learning Approaches to Lexical Simplification: A Survey")). The prediction
    scores of MLM or casual language modeling have replaced various SS and SR techniques.
    LS systems that employ minimal SS and no SR apart from ranking their LLM’s prediction
    scores, have outperformed more technical, feature-oriented, and unsupervised ranking
    methods (Table [3](#S3 "3 Deep Learning Approaches ‣ Deep Learning Approaches
    to Lexical Simplification: A Survey")). However, an exception is made with regards
    to equivalence score Li et al. ([2022](#bib.bib26)), which has been shown to be
    effective at SR.'
  prefs: []
  type: TYPE_NORMAL
- en: Future LS systems will make use of new advances in deep learning. We believe
    prompt learning and models, such as GPT-3, will become increasingly popular, given
    their state-of-the-art performance at SG. Using an ensemble of various prompts
    for SS and SR may advance LS performance. In addition, the creation of new metrics
    similar to equivalence score will likewise be beneficial.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Open Challenges in LS
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: LS has a number of open research areas that are either unaddressed, or the current
    body of work is inconclusive. In this brief section, we conclude this survey by
    outlining a few key areas for future development of LS research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Evaluation:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The metrics we use to evaluate LS are not perfect (Section [2.1](#S2.SS1 "2.1
    Evaluation Metrics ‣ 2 Pipeline ‣ Deep Learning Approaches to Lexical Simplification:
    A Survey")). Automated metrics that condense a wide problem into a single numerical
    score can harm outcomes with human participants. Development of more faithful
    resources, as well as direct evaluation with intended user groups of simplification
    systems is a fruitful avenue for future work. This can be done by taking into
    consideration variation in data annotation instead of labels produced by aggregating
    unique annotations as in most datasets currently available.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Explainability:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lexical simplifications are inherently more explainable than sentence simplification
    as the operations are directly applied at the lexeme level. However, the decision
    process on whether to simplify and which word to choose is increasingly hidden
    behind the black-box of a model. Work to explain and interpret these decisions
    will allow researchers to better understand the opportunities and threats of applying
    modern NLP techniques to LS research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Personalization:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: One model does not fit all. The simplification needs of a language learner compared
    to a stroke victim, compared to a child are each very different. Modeling these
    needs and using them to personalize LS systems will allow for personalized simplification
    output more adequate the needs of particular user groups.
  prefs: []
  type: TYPE_NORMAL
- en: 'Perspectivism:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Even within a population of common characteristics, each individual will bring
    a unique perspective on what and how to simplify. Systems which can alter their
    outputs to each user’s needs will provide adaptive simplifications that go beyond
    our current technology. This will, in turn, improve the evaluation of LS models
    as previously discussed in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'Integration:'
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: LS is only one part of the wider simplification puzzle. Integrating LS systems
    with explanation generation, redundancy removal, and sentence splitting will further
    accelerate the adoption of automated simplification practices beyond the halls
    of research allowing such technology to reach a wider audience.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Al-Thanyyan and Azmi (2021) Suha S. Al-Thanyyan and Aqil M. Azmi. 2021. Automated
    Text Simplification: A Survey. *ACM Comput. Surv.*, 54(2).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alarcón et al. (2021a) Rodrigo Alarcón, Lourdes Moreno, and Paloma Martínez.
    2021a. Exploration of Spanish Word Embeddings for Lexical Simplification. In *Proceedings
    of CTTS*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alarcón et al. (2021b) Rodrigo Alarcón, Lourdes Moreno, and Paloma Martínez.
    2021b. Lexical Simplification System to Improve Web Accessibility. *IEEE Access*,
    9:58755–58767.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aleksandrova and Brochu Dufour (2022) Desislava Aleksandrova and Olivier Brochu Dufour.
    2022. RCML at TSAR-2022 Shared Task: Lexical Simplification With Modular Substitution
    Candidate Ranking. In *Proceedings of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aluísio and Gasperin (2010) Sandra Maria Aluísio and Caroline Gasperin. 2010.
    Fostering digital inclusion and accessibility: The porsimples project for simplification
    of portuguese texts. In *Proceedings of YIWCALA*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Arefyev et al. (2020) Nikolay Arefyev, Boris Sheludko, Alexander Podolskiy,
    and Alexander Panchenko. 2020. Always Keep your Target in Mind: Studying Semantics
    and Improving Performance of Neural Lexical Substitution. In *Proceedings of COLING*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aumiller and Gertz (2022) Dennis Aumiller and Michael Gertz. 2022. UniHD at
    TSAR-2022 Shared Task: Is Compute All We Need for Lexical Simplification? In *Proceedings
    of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Billami et al. (2018) Mokhtar B. Billami, Thomas François, and Núria Gala.
    2018. ReSyf: a French lexicon with ranked synonyms. In *Proceedings of ACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bojanowski et al. (2016) Piotr Bojanowski, Edouard Grave, Armand Joulin, and
    Tomas Mikolov. 2016. Enriching Word Vectors with Subword Information. *arXiv preprint
    arXiv:1607.04606*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Brown et al. (2020) Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah,
    Jared Kaplan, Prafulla Dhariwal, and Others. 2020. Language Models Are Few-Shot
    Learners. In *Proceedings of NeurIPS*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cañete et al. (2020) José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui
    Ho, Hojin Kang, and Jorge Pérez. 2020. Spanish pre-trained bert model and evaluation
    data. In *Proceedings of PML4DC at ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Clark et al. (2020) Kevin Clark, Minh-Thang Luong, Quoc Le, and Christopher
    Manning. 2020. ELECTRA: Pre-training text encoders as discriminators rather than
    generators. In *Proceedings of ICLR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Conneau et al. (2020) Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav
    Chaudhary, and Others. 2020. Unsupervised cross-lingual representation learning
    at scale. In *Proceedings of ACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: De la Rosa and Fernández (2022) Javier De la Rosa and Andres Fernández. 2022.
    Zero-shot reading comprehension and reasoning for spanish with BERTIN GPT-J-6B.
    In *Proceedings of SEPLN*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Devlin et al. (2019) Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina
    Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language
    understanding. In *Proceedings of NAACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ermakova et al. (2021) Liana Ermakova, Patrice Bellot, Pavel Braslavski, Jaap
    Kamps, Josiane Mothe, and Others. 2021. Overview of SimpleText CLEF 2021 Workshop
    and Pilot Tasks. In *Proceedings of LREC*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fandiño et al. (2022) Asier Gutiérrez Fandiño, Jordi Armengol Estapé, Marc
    Pàmies, Joan Llop Palao, Joaquin Silveira Ocampo, and Others. 2022. Maria: Spanish
    language models. *Procesamiento del Lenguaje Natural*, 68.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ferres and Saggion (2022) Daniel Ferres and Horacio Saggion. 2022. ALEXSIS:
    A dataset for lexical simplification in Spanish. In *Proceedings of LREC*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hartmann and Aluísio (2020) Nathan Siegle Hartmann and Sandra Maria Aluísio.
    2020. Adaptação lexical automática em textos informativos do português brasileiro
    para o ensino fundamental. *Linguamática*, 12(2):3–27.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Horn et al. (2014) Colby Horn, Cathryn Manduca, and David Kauchak. 2014. Learning
    a lexical simplifier using Wikipedia. In *Proceedings of ACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kajiwara and Yamamoto (2015) Tomoyuki Kajiwara and Kazuhide Yamamoto. 2015.
    Evaluation Dataset and System for Japanese Lexical Simplification. In *Proceedings
    of ACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kodaira et al. (2016) Tomonori Kodaira, Tomoyuki Kajiwara, and Mamoru Komachi.
    2016. Controlled and Balanced Dataset for Japanese Lexical Simplification. In
    *Proceedings of ACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Leal et al. (2018) Sidney Evaldo Leal, Magali Sanches Duran, and Sandra Maria
    Aluísio. 2018. A nontrivial sentence corpus for the task of sentence readability
    assessment in Portuguese. In *Proceedings of COLING*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee and Yeung (2018a) John Lee and Chak Yan Yeung. 2018a. Automatic prediction
    of vocabulary knowledge for learners of chinese as a foreign language. In *Proceedings
    of ICNLSP*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lee and Yeung (2018b) John Lee and Chak Yan Yeung. 2018b. Personalizing lexical
    simplification. In *Proceedings of COLING*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Li et al. (2022) Xiaofei Li, Daniel Wiechmann, Yu Qiao, and Elma Kerz. 2022.
    MANTIS at TSAR-2022 Shared Task: Improved Unsupervised Lexical Simplification
    with Pretrained Encoders. In *Proceedings of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2019) Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, and Others.
    2019. Roberta: A robustly optimized bert pretraining approach. *arXiv preprint
    arXiv:1907.11692*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maddela and Xu (2018) Mounica Maddela and Wei Xu. 2018. A word-complexity lexicon
    and a neural readability ranking model for lexical simplification. In *Proceedings
    of EMNLP*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'McCarthy and Navigli (2007) Diana McCarthy and Roberto Navigli. 2007. SemEval-2007
    Task 10: English Lexical Substitution Task. In *Proceedings of SemEval*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Melamud et al. (2016) Oren Melamud, Jacob Goldberger, and Ido Dagan. 2016.
    context2vec: Learning Generic Context Embedding with Bidirectional LSTM. In *Proceedings
    of SIGNLL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Merejildo (2021) Borbor Merejildo. 2021. Creación de un corpus de textos universitarios
    en español para la identificación de palabras complejas en el área de la simplificación
    léxica. Master’s thesis, Universidad de Guayaquil.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mikolov et al. (2013) Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean.
    2013. Efficient Estimation of word Representations in Vector Space. In *Proceedings
    of ICLR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Nishihara and Kajiwara (2020) Daiki Nishihara and Tomoyuki Kajiwara. 2020. Word
    Complexity Estimation for Japanese Lexical Simplification. In *Proceedings of
    LREC*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'North et al. (2022a) Kai North, Alphaeus Dmonte, Tharindu Ranasinghe, and Marcos
    Zampieri. 2022a. GMU-WLV at TSAR-2022 Shared Task: Evaluating Lexical Simplification
    Models. In *Proceedings of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'North et al. (2022b) Kai North, Marcos Zampieri, and Matthew Shardlow. 2022b.
    Lexical Complexity Prediction: An Overview. *ACM Computing Surveys*, 55(9).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paetzold and Specia (2016a) Gustavo Paetzold and Lucia Specia. 2016a. SemEval
    2016 Task 11: Complex Word Identification. In *Proceedings of SemEval*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paetzold and Specia (2017a) Gustavo Paetzold and Lucia Specia. 2017a. Lexical
    simplification with neural ranking. In *Proceedings of EACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paetzold and Specia (2017b) Gustavo H. Paetzold and Lucia Specia. 2017b. A Survey
    on Lexical Simplification. *J. Artif. Int. Res.*, 60(1):549–593.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paetzold and Specia (2016b) Gustavo Henrique Paetzold and Lucia Specia. 2016b.
    Benchmarking Lexical Simplification Systems. In *Proceedings of LREC*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paetzold and Specia (2016c) Gustavo Henrique Paetzold and Lucia Specia. 2016c.
    Unsupervised lexical simplification for non-native speakers. In *Proceedings of
    AAAI*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Peters et al. (2018) Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner,
    Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized
    Word Representations. In *Proceedings of NAACL*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Przybyła and Shardlow (2020) Piotr Przybyła and Matthew Shardlow. 2020. Multi-Word
    Lexical Simplification. In *Proceedings of COLING*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiang et al. (2020) Jipeng Qiang, Yun Li, Zhu Yi, Yunhao Yuan, and Xindong Wu.
    2020. Lexical simplification with pretrained encoders. In *Proceedings of AAAI*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qiang et al. (2021) Jipeng Qiang, Xinyu Lu, Yun Li, Yunhao Yuan, and Xindong
    Wu. 2021. Chinese Lexical Simplification. *IEEE/ACM Transactions on Audio, Speech,
    and Language Processing*, 29:1819–1828.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rolin et al. (2021) Eva Rolin, Quentin Langlois, Patrick Watrin, and Thomas
    François. 2021. FrenLyS: A Tool for the Automatic Simplification of French General
    Language Texts. In *Proceedings of RANLP*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saggion et al. (2022) Horacio Saggion, Sanja Štajner, Daniel Ferrés, Kim Cheng
    Sheang, Matthew Shardlow, Kai North, and Marcos Zampieri. 2022. Findings of the
    TSAR-2022 Shared Task on Multilingual Lexical Simplification. In *Proceedings
    of TSAR*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Seneviratne et al. (2022) Sandaru Seneviratne, Elena Daskalaki, and Hanna Suominen.
    2022. CILS at TSAR-2022 Shared Task: Investigating the Applicability of Lexical
    Substitution Methods for Lexical Simplification. In *Proceedings of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shardlow (2013) Matthew Shardlow. 2013. The CW Corpus: A New Resource for Evaluating
    the Identification of Complex Words. In *Proceedings of ACL*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shardlow et al. (2020) Matthew Shardlow, Michael Cooper, and Marcos Zampieri.
    2020. CompLex — a new corpus for lexical complexity prediction from Likert Scale
    data. In *Proceedings of READI*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Song et al. (2020) Jiayin Song, Jingyue Hu, Leung-Pun Wong, Lap-Kei Lee, and
    Tianyong Hao. 2020. A New Context-Aware Method Based on Hybrid Ranking for Community-Oriented
    Lexical Simplification. In *Proceedings of DASFAA*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Souza et al. (2020) Fábio Souza, Rodrigo Nogueira, and Roberto Lotufo. 2020.
    BERTimbau: pretrained BERT models for Brazilian Portuguese. In *Proceedings of
    BRACIS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Specia et al. (2012) Lucia Specia, Kumar Jauhar, Sujay, and Rada Mihalcea.
    2012. Semeval - 2012 task 1: English lexical simplification. In *Proceedings of
    SemEval*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Trask et al. (2015) Andrew Trask, Phil Michalak, and John Liu. 2015. sense2vec
    - A Fast and Accurate Method for Word Sense Disambiguation In Neural Word Embeddings.
    *ArXiv*, abs/1511.06388.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uchida et al. (2018) Satoru Uchida, Shohei Takada, and Yuki Arase. 2018. CEFR-based
    Lexical Simplification Dataset. In *Proceedings of LREC*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vásquez-Rodríguez et al. (2022) Laura Vásquez-Rodríguez, Nhung Nguyen, Sophia
    Ananiadou, and Matthew Shardlow. 2022. UoM&MMU at TSAR-2022 Shared Task: Prompt
    Learning for Lexical Simplification. In *Proceedings of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Whistely et al. (2022) Peniel John Whistely, Sandeep Mathias, and Galiveeti
    Poornima. 2022. PresiUniv at TSAR-2022 Shared Task: Generation and Ranking of
    Simplification Substitutes of Complex Words in Multiple Languages. In *Proceedings
    of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wilkens et al. (2022) Rodrigo Wilkens, David Alfter, Rémi Cardon, Isabelle
    Gribomont, and Others. 2022. CENTAL at TSAR-2022 Shared Task: How Does Context
    Impact BERT-Generated Substitutions for Lexical Simplification? In *Proceedings
    of TSAR*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2019) Zhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan
    Salakhutdinov, and Quoc V. Le. 2019. XLNet: Generalized Autoregressive Pretraining
    for Language Understanding. In *Proceedings of NeurIPS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yeung and Lee (2018) Chak Yan Yeung and John Lee. 2018. Personalized text retrieval
    for learners of Chinese as a foreign language. In *Proceedings of COLING*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yimam et al. (2018) Seid Muhie Yimam, Chris Biemann, Shervin Malmasi, Gustavo
    Paetzold, Luci Specia, Sanja Štajner, Anaïs Tack, and Marcos Zampieri. 2018. A
    Report on the Complex Word Identification Shared Task 2018. In *Proceedings of
    BEA*.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zambrano and Ráez (2020) Jenny Alexandra Ortiz Zambrano and Arturo Montejo
    Ráez. 2020. Overview of ALexS 2020: First Workshop on Lexical Analysis at SEPLN.
    In *Proceedings of ALexS*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Appendix A Appendix
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '|  | Dataset | LS Pipeline | Languages | # CWs | Avg. # Subs | Domain | Annotators
    | Paper |'
  prefs: []
  type: TYPE_TB
- en: '| Pre-2017 | LS–2007* | SG, SS | EN | 201 | 1 | Mix | 5 UK-based. | McCarthy
    and Navigli ([2007](#bib.bib29)) |'
  prefs: []
  type: TYPE_TB
- en: '| PorSimples | SG, SS | PT | 3066 | 1 | News | 1 Linguist. | Aluísio and Gasperin
    ([2010](#bib.bib5)) |'
  prefs: []
  type: TYPE_TB
- en: '| LS–2012* | SG, SS, SR | EN | 201 | 5 | Mix | L1 English Speakers. | Specia
    et al. ([2012](#bib.bib52)) |'
  prefs: []
  type: TYPE_TB
- en: '| CW Corpus | SS | EN | 731 | 0 | Wikipedia | Wikipedia Edits. | Shardlow ([2013](#bib.bib48))
    |'
  prefs: []
  type: TYPE_TB
- en: '| LexMTurk | SG, SS, SR | EN | 500 | 50 | Wikipedia | 50 US-based. | Horn et al.
    ([2014](#bib.bib20)) |'
  prefs: []
  type: TYPE_TB
- en: '| JLS | SG, SS, SR | JP | 243 | 5 | Mix | 5 L1 JP Speakers. | Kajiwara and
    Yamamoto ([2015](#bib.bib21)) |'
  prefs: []
  type: TYPE_TB
- en: '| JLS Balanced | SG, SS, SR | JP | 2,010 | 5 | Mix | L1 JP Speakers | Kodaira
    et al. ([2016](#bib.bib22)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWI–2016* | SS | EN | 90,458 | 0 | News | 400 L2 EN Speakers. | Paetzold
    and Specia ([2016a](#bib.bib36)) |'
  prefs: []
  type: TYPE_TB
- en: '| BenchLS | SG, SS, SR | EN | 929 | 7 | Mix | US-Based. | Paetzold and Specia
    ([2016b](#bib.bib39)) |'
  prefs: []
  type: TYPE_TB
- en: '| NNSeval | SG, SS, SR | EN | 239 | 7 | Mix | 400 L2 EN Speakers. | Paetzold
    and Specia ([2016c](#bib.bib40)) |'
  prefs: []
  type: TYPE_TB
- en: '| Post-2017 | CERF-LS | SG, SS, SR | EN | 406 | 12 | Academic | 1 L1 EN Speaker.
    | Uchida et al. ([2018](#bib.bib54)) |'
  prefs: []
  type: TYPE_TB
- en: '| Personalized-ZH | SG, SS, SR | ZH | 600 | 7 | Mix | 8 L1 ZH Speakers | Lee
    and Yeung ([2018a](#bib.bib24)) |'
  prefs: []
  type: TYPE_TB
- en: '| WCL | SS, SR | EN | 15,000 | 0 | Mix | 11 L2 EN Speakers. | Maddela and Xu
    ([2018](#bib.bib28)) |'
  prefs: []
  type: TYPE_TB
- en: '| ReSyf | SG, SS | FR | 57,589 | 3 | Mix | L1 FR Speakers. | Billami et al.
    ([2018](#bib.bib8)) |'
  prefs: []
  type: TYPE_TB
- en: '| Personalized-LS | SG, SS, SR | EN | 929 | 7 | Mix | 15 L2 EN Speakers. |
    Lee and Yeung ([2018b](#bib.bib25)) |'
  prefs: []
  type: TYPE_TB
- en: '| CWI–2018* | SS, SR | EN, FR, GR, ES | 62,550 | 0 | News | L1&L2 EN Speakers.
    | Yimam et al. ([2018](#bib.bib60)) |'
  prefs: []
  type: TYPE_TB
- en: '| PorSimplesSent | SG, SS | PT | 6109 | 1 | News | 3 Linguists. | Leal et al.
    ([2018](#bib.bib23)) |'
  prefs: []
  type: TYPE_TB
- en: '| LCP-2021* | SS, SR | EN | 10,800 | 0 | Mix | 7 US/UK/AUS-based. | Shardlow
    et al. ([2020](#bib.bib49)) |'
  prefs: []
  type: TYPE_TB
- en: '| SIMPLEX-PB | SG, SS, SR | PT | 730 | 5 | Academic | pt-BR Speakers. | Hartmann
    and Aluísio ([2020](#bib.bib19)) |'
  prefs: []
  type: TYPE_TB
- en: '| JWCL-JSSL | SG | JP | 18,000 | 0 | Mix | 5 L1 JP Speakers. | Nishihara and
    Kajiwara ([2020](#bib.bib33)) |'
  prefs: []
  type: TYPE_TB
- en: '| ALexS-2020* | SG | ES | 723 | 0 | Academic | 430 ES Speakers. | Zambrano
    and Ráez ([2020](#bib.bib61)) |'
  prefs: []
  type: TYPE_TB
- en: '| SimpleText-2021* | SG, SS, SR | EN | 1000 | 10 | Academic | Participating
    Teams. | Ermakova et al. ([2021](#bib.bib16)) |'
  prefs: []
  type: TYPE_TB
- en: '| ES-CWI | SG | ES | 3,887 | 0 | Academic | 40 L1 ES speakers. | Merejildo
    ([2021](#bib.bib31)) |'
  prefs: []
  type: TYPE_TB
- en: '| EASIER | SG, SS | ES | 5,310 | 3 | News | L1 ES speakers. | Alarcón et al.
    ([2021b](#bib.bib3)) |'
  prefs: []
  type: TYPE_TB
- en: '| FrenLys | SG, SS, SR | FR | 57,589 | 3 | Mix | 20 L1 FR Speakers. | Rolin
    et al. ([2021](#bib.bib45)) |'
  prefs: []
  type: TYPE_TB
- en: '| HanLS | SG, SS, SR | ZH | 534 | 8 | Mix | 5 L1 ZH Speakers. | Qiang et al.
    ([2021](#bib.bib44)) |'
  prefs: []
  type: TYPE_TB
- en: '| TSAR-2022* | SG, SS, SR | EN, ES, PT | 1153 | 20 | News | 21 UK/ES/BR-based.
    | Saggion et al. ([2022](#bib.bib46)) |'
  prefs: []
  type: TYPE_TB
- en: 'Table 2: Datasets that can be used for LS arranged in chronological order.
    Marked datasets (*) were used in benchmark competitions. L1 and L2 refers to first
    and second language speakers.'
  prefs: []
  type: TYPE_NORMAL
