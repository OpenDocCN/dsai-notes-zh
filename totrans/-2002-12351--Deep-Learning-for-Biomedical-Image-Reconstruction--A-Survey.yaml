- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 20:02:17'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2002.12351] Deep Learning for Biomedical Image Reconstruction: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2002.12351](https://ar5iv.labs.arxiv.org/html/2002.12351)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '¹¹institutetext: H. Ben Yedder ²²institutetext: ²²email: hbenyedd@sfu.ca ³³institutetext:
    B. Cardoen ⁴⁴institutetext: ⁴⁴email: bcardoen@sfu.ca ⁵⁵institutetext: G. Hamarneh
    ⁶⁶institutetext: ⁶⁶email: hamarneh@sfu.ca ⁷⁷institutetext: School of Computing
    Science, Simon Fraser University, Canada'
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Learning for Biomedical Image Reconstruction: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Hanene Ben Yedder    Ben Cardoen    Ghassan Hamarneh
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Medical imaging is an invaluable resource in medicine as it enables to peer
    inside the human body and provides scientists and physicians with a wealth of
    information indispensable for understanding, modelling, diagnosis, and treatment
    of diseases. Reconstruction algorithms entail transforming signals collected by
    acquisition hardware into interpretable images. Reconstruction is a challenging
    task given the ill-posed of the problem and the absence of exact analytic inverse
    transforms in practical cases. While the last decades witnessed impressive advancements
    in terms of new modalities, improved temporal and spatial resolution, reduced
    cost, and wider applicability, several improvements can still be envisioned such
    as reducing acquisition and reconstruction time to reduce patient’s exposure to
    radiation and discomfort while increasing clinics throughput and reconstruction
    accuracy. Furthermore, the deployment of biomedical imaging in handheld devices
    with small power requires a fine balance between accuracy and latency. The design
    of fast, robust, and accurate reconstruction algorithms is a desirable, yet challenging,
    research goal. While the classical image reconstruction algorithms approximate
    the inverse function relying on expert-tuned parameters to ensure reconstruction
    performance, deep learning (DL) allows automatic feature extraction and real-time
    inference. Hence, DL presents a promising approach to image reconstruction with
    artifact reduction and reconstruction speed-up reported in recent works as part
    of a rapidly growing field. We review state-of-the-art image reconstruction algorithms
    with a focus on DL-based methods. First, we examine common reconstruction algorithm
    designs, applied metrics, and datasets used in the literature. Then, key challenges
    are discussed as potentially promising strategic directions for future research.
  prefs: []
  type: TYPE_NORMAL
- en: 'Keywords:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Image reconstruction modality deep learning inverse problem analytical approach
    iterative approach limited data representation.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Biomedical image reconstruction translates signals acquired by a wide range
    of sensors into images that can be used for diagnosis and discovery of biological
    processes in cell and organ tissue. Each biomedical imaging modality leverages
    signals in different bands of the electromagnetic spectrum, e.g. from gamma rays
    ( Positron emission tomography PET/SPECT)), X-rays (computed tomography (CT)),
    visible light (microscopy, endoscopy), infrared (thermal images), and radio-frequency
    (Nuclear magnetic resonance imaging (MRI)), as well as pressure sound waves (in
    ultrasound (US) imaging) (Webb and Kagadis, [2003](#bib.bib84)). Reconstruction
    algorithms transform the collected signals into a 2, 3 or 4-dimensional image.
  prefs: []
  type: TYPE_NORMAL
- en: The accuracy of each reconstruction is critical for discovery and diagnosis.
    Robustness to noise and generalization cross modality specifications’ (e.g., sampling
    pattern, rate, etc.) and imaging devices parameters’ allow a reconstruction algorithm
    to be used in wider applications. The time required for each reconstruction determines
    the number of subjects that can be diagnosed as well as the suitability of the
    technique in operating theatres and emergency situations. The number of measurements
    needed for a high quality reconstruction impacts the exposure a patient or sample
    will have to endure. Finally, the hardware requirements define whether a reconstruction
    algorithm can be used only in a dedicated facility or in portable devices thus
    dictating the flexibility of deployment.
  prefs: []
  type: TYPE_NORMAL
- en: 'The study of image reconstruction is an active area of research in modern applied
    mathematics, engineering and computer science. It forms one of the most active
    interdisciplinary fields of science (Fessler, [2017](#bib.bib25)) given that improvement
    in the quality of reconstructed images offers scientists and clinicians an unprecedented
    insight into the biological processes underlying disease. Fig. [1](#S1.F1 "Figure
    1 ‣ 1 Introduction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")
    provides an illustration of the reconstruction problem and shows a typical data
    flow in a medical imaging system.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Over the past few years, researchers have begun to apply machine learning techniques
    to biomedical reconstruction to enable real-time inference and improved image
    quality in a clinical setting. Here, we first provide an overview of the image
    reconstruction problem and outline its characteristics and challenges (Section [1.1](#S1.SS1
    "1.1 Inverse Problem and Challenges ‣ 1 Introduction ‣ Deep Learning for Biomedical
    Image Reconstruction: A Survey")) and then outline the purpose, scope, and the
    layout of this review (Section [1.2](#S1.SS2 "1.2 Scope of this survey ‣ 1 Introduction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/6c3ec6fc113f9f82d16b300508fc6679.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 1: Data flow in a medical imaging and image interpretation system. Forward
    model encodes the physics of the imaging system. The inverse model transforms
    the collected signals by the acquisition hardware into a meaningful image. The
    success of a diagnosis, evaluation, and treatment rely on accurate reconstruction,
    image visualization and processing algorithms.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Inverse Problem and Challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 1.1.1 From Output to Input
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Image reconstruction is the process of forming an interpretable image from
    the raw data (signals) collected by the imaging device. It is known as an inverse
    problem where given a set of measurements, the goal is to determine the original
    structure influencing the signal collected by a receiver given some signal transmission
    medium properties (Fig. [2](#S1.F2 "Figure 2 ‣ 1.1.1 From Output to Input ‣ 1.1
    Inverse Problem and Challenges ‣ 1 Introduction ‣ Deep Learning for Biomedical
    Image Reconstruction: A Survey")). Let $y$ represent a set of raw acquired sensor
    measurements and subject to some noise $\mathcal{N}$ intrinsic to the acquisition
    process. The objective is to recover the spatial-domain (or spatio-temporal) image
    ${x}$ such that:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $y=\mathcal{A}(\mathcal{F}(x),\mathcal{N})$ |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{F}(\cdot)$ is the forward model operator that models the physics
    of image-formation, which can include signal propagation, attenuation, scattering,
    reflection and other transforms, e.g. Radon or Fourier transform. $\mathcal{F}(\cdot)$
    can be a linear or a nonlinear operator depending on the imaging modality. $\mathcal{A}$
    is an aggregation operation representing the interaction between noise and signal,
    in the assumption of additive noise $\mathcal{A}=+$.
  prefs: []
  type: TYPE_NORMAL
- en: While imaging systems are usually well approximated using mathematical models
    that define the forward model, an exact analytic inverse transform $\mathcal{A}^{-1}(\cdot)$
    is not always possible. Reconstruction approaches usually resort to iteratively
    approximate the inverse function and often involve expert-tuned parameters and
    prior domain knowledge considerations to optimize reconstruction performance.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9509aa18bc3ab3db17b4b5ed0750864c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: Propagation of signals from sender to receiver. While passing through
    a transmission channel, signals $s$ pick up noise (assuming additive) along the
    way, until a measurement $M$ = s+$\mathcal{N}$ reaches the receiver. The properties
    of the received signal may, via a feedback loop, affect properties of future signal
    transmission. Sender and receiver modeling differ within modalities. For example
    the lower figure illustrates in the left ultrasound probe used to send and collect
    signals (S=R); in the middle: X-ray signal propagates through subject toward detector
    (S $\rightarrow$ R); and in the right the laser power is tuned on a feedback loop
    during acquisition in super resolution microscopy (S $\leftrightarrow$ R)'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c0251bf5d77aa40df37761bc60e6ec1a.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 3: (A) A problem is ill-conditioned when two different objects produce
    very close observed signals. When the observed signals are identical and hence
    identical reconstructed images, inverse solution is non-unique. Prior knowledge
    can be leveraged to rules out certain solutions that conflict with the additional
    knowledge about the object beyond the measurement vectors. (B) A use case toy
    example of two objects with the same acquired signals. Prior knowledge about homogeneity
    of object rules out the second object.'
  prefs: []
  type: TYPE_NORMAL
- en: 1.1.2 An Ill-Posed Problem
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Image reconstruction is an ill-posed problem as there may be significantly
    fewer measurements $(M)$ than the number of unknowns $(N)$. Mathematically, the
    problem is highly under-determined as there would be fewer equations to describe
    the model than unknowns ($M\ll N$) and therefore, there may be infinite consistent
    images that map to the same measurements (Fig. [3](#S1.F3 "Figure 3 ‣ 1.1.1 From
    Output to Input ‣ 1.1 Inverse Problem and Challenges ‣ 1 Introduction ‣ Deep Learning
    for Biomedical Image Reconstruction: A Survey")). Thus, one challenge for the
    reconstruction algorithm is to select the best solution among a set of potential
    solutions (McCann and Unser, [2019](#bib.bib49)). One way to reduce the solution
    space is to leverage domain specific knowledge by encoding priors, i.e. regularization.'
  prefs: []
  type: TYPE_NORMAL
- en: Reducing data representation, such as sub-sampling in MRI or sparse-view, limited-angle
    data in CT, to accelerate acquisition or reduce radiation dose typically decreases
    the size $N$ of the measured signal $y$ while increasing its sparsity and noise
    level. As a consequence the ill-posedness and complexity of the reconstruction
    problem increase. This brings up the need for sophisticated reconstruction algorithms
    with high feature extraction power to make the best use of the collected signal,
    capture modality-specific imaging features, and leverage prior knowledge. Furthermore,
    developing high-quality reconstruction algorithms requires not only a deep understanding
    of both the physics of the imaging systems and the biomedical structures but also
    specially designed algorithms that can account for the statistical properties
    of the measurements and tolerate errors in the measured data.
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Scope of this survey
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The field of biomedical image reconstruction have undergone significant advances
    over the past few decades and can be broadly classified into two categories: conventional
    methods (analytical and optimization based methods) and data-driven or learning-based
    methods. Conventional methods (discussed in section [2](#S2 "2 Conventional Image
    Reconstruction Approaches ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey")) are the most dominant and have been extensively studied over the last
    few decades with a focus on how to improve their results (Vandenberghe et al.,
    [2001](#bib.bib76); Jhamb et al., [2015](#bib.bib43); Assili, [2018](#bib.bib6))
    and reduce their computational cost (Despres and Jia, [2017](#bib.bib21)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'Researchers have recently investigated deep learning (DL) approaches for various
    biomedical image reconstruction problems (discussed in section [3](#S3 "3 Deep
    Learning Based Image Reconstruction ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey")) inspired by the success of deep learning in computer vision problems.
    This topic is relatively new and has gained a lot of interest over the last few
    years, as shown in Fig. [4](#S1.F4 "Figure 4 ‣ 1.2 Scope of this survey ‣ 1 Introduction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-A and listed in
    Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and
    Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey"),
    and forms a very active field of research with numerous special journal issues (Wang,
    [2016](#bib.bib78); Wang et al., [2018](#bib.bib80); Ravishankar et al., [2019](#bib.bib60)).
    MRI and CT received the most attention among studied modalities, as illustrated
    in Fig. [4](#S1.F4 "Figure 4 ‣ 1.2 Scope of this survey ‣ 1 Introduction ‣ Deep
    Learning for Biomedical Image Reconstruction: A Survey")-B, given their widespread
    clinical usage, the availability of analytic inverse transform and the availability
    of public (real) datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7bbe5203c316d30f60cf02fe82f40f74.png)![Refer to caption](img/ab4aa3d034f98236c23ebe997aeb1881.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: (A) Number of studies, covered in this survey, on the topic of machine
    learning for biomedical image reconstruction versus year of publication. (B) The
    pie chart represents the number of studies per modality.'
  prefs: []
  type: TYPE_NORMAL
- en: 'To date, few surveys on machine learning-based image reconstruction approaches
    have been conducted. Fessler ([2017](#bib.bib25)) wrote a brief chronological
    overview on image reconstruction methods highlighting an evolution from basic
    analytical to data-driven models. Recently, McCann et al. [2019](#bib.bib49) wrote
    a survey on image reconstruction approaches where they presented a toolbox of
    operators that can be used to build imaging systems model’s and showed how forward
    model and sparsity-based regularization can be used to solve reconstruction problems.
    While their review is more focused on the mathematical foundations of conventional
    methods, they briefly discussed data-driven approaches, their theoretical underpinning,
    and performance. As illustrated in Fig. [5](#S1.F5 "Figure 5 ‣ 1.2 Scope of this
    survey ‣ 1 Introduction ‣ Deep Learning for Biomedical Image Reconstruction: A
    Survey") since its publication a great deal of work has been done warranting a
    review. Similarly, Zhang et al. ([2019](#bib.bib97)) provided a conceptual review
    of some recent DL-based methods for CT with a focus on methods inspired by iterative
    optimization approaches and their theoretical underpinning from the perspective
    of representation learning and differential equations.'
  prefs: []
  type: TYPE_NORMAL
- en: This survey provides an overview of biomedical image reconstruction methods
    with a focus on DL-based strategies, discusses their different paradigms (e.g., image
    domain, sensor domain (raw data) or end to end learning, architecture, loss, etc.
    ) and how such methods can help overcome the weaknesses of conventional non-learning
    methods. The theoretical foundation was not emphasized in this work as it was
    well investigated in the aforementioned surveys. Common evaluation metrics and
    training dataset challenges are also discussed.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/48fbf911aaa4c168db862af94af06274.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The marked increase in publications on biomedical image reconstruction
    and deep learning in the past 10 years (Results obtained by PubMed query that
    can be found at: [http://bit.ly/image_recon](http://bit.ly/38ELjuz)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'The remainder of this paper is organized as follows: in Section [2](#S2 "2
    Conventional Image Reconstruction Approaches ‣ Deep Learning for Biomedical Image
    Reconstruction: A Survey") we give an overview of conventional methods discussing
    their advantages and limitations. We then introduce the key machine learning paradigms
    and how they are being adapted in this field complementing and improving on conventional
    methods. A review of available data-sets and performance metrics is detailed in
    Section [3](#S3 "3 Deep Learning Based Image Reconstruction ‣ Deep Learning for
    Biomedical Image Reconstruction: A Survey"). Finally, we conclude by summarizing
    the current state-of-the-art and outlining strategic future research directions
    (Section [6](#S6 "6 Conclusion, Discussion and Future Direction ‣ Deep Learning
    for Biomedical Image Reconstruction: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 2 Conventional Image Reconstruction Approaches
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A wide variety of reconstruction algorithms have been proposed during the past
    few decades, having evolved from analytical methods to iterative or optimization-based
    methods that account for the statistical properties of the measurements and noise
    as well as the hardware of the imaging system (Fessler, [2017](#bib.bib25)). While
    these methods have resulted in significant improvements in reconstruction accuracy
    and artifact reduction, are in routine clinical use currently, they still present
    some weaknesses. A brief overview of these methods’ principles is presented in
    this section outlining their weaknesses.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Analytical Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Analytical methods are based on a continuous representation of the reconstruction
    problem and use simple mathematical models for the imaging system. Classical examples
    are the inverse of the Radon transform such as filtered back-projection (FBP)
    for CT and the inverse Fourier transform (IFT) for MRI. These methods are usually
    computationally inexpensive (in the order of ms) and can generate good image quality
    in the absence of noise and under the assumption of full sampling/all angles projection (McCann
    and Unser, [2019](#bib.bib49)). They typically consider only the geometry and
    sampling properties of the imaging system while ignoring the details of the system
    physics and measurement noise (Fessler, [2017](#bib.bib25)).
  prefs: []
  type: TYPE_NORMAL
- en: When dealing with noisy or incomplete measured data e.g., reducing the measurement
    sampling rate, analytical methods results are highly deteriorated as the signal
    becomes weaker. Thus, the quality of the produced image is compromised. Thaler
    et al. ([2018](#bib.bib75)) provided examples of a CT image reconstruction using
    the FBP method for different limited projection angles and showed that analytical
    methods are unable to recover the loss in the signal, resulting in compromised
    diagnostic performance.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Iterative Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Iterative reconstruction methods, based on more sophisticated models for the
    imaging system’s physics, sensors and noise statistics, have attracted a lot of
    attention over the past few decades. They combine the statistical properties of
    data in the sensor domain (raw measurement data), prior information in the image
    domain, and sometimes parameters of the imaging system into their objective function (McCann
    and Unser, [2019](#bib.bib49)). Compared to analytical methods iterative reconstruction
    algorithms offer a more flexible reconstruction framework and better robustness
    to noise and incomplete data representation problems at the cost of increased
    computation  (Ravishankar et al., [2019](#bib.bib60)).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/9d9b631ccb928fa88a51f213a0246196.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Iterative image reconstruction workflow example. (A) Diffuse optical
    tomography (DOT) fibers brain probe consisting of a set of fibers for illumination
    and outer bundle fibers for detection. (B) Probe scheme and light propagation
    modelling in the head, used by the forward model. (C) Iterative approach pipeline.
    (D) DOT reconstructed image shows the total Hemoglobin (Hb) concentrations in
    the brain. (Figure licensed under CC-BY 4.0 Creative Commons license.)'
  prefs: []
  type: TYPE_NORMAL
- en: 'Iterative reconstruction methods involve minimizing an objective function that
    usually consists of a data term and a regularization terms imposing some prior:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\hat{x}^{*}=\arg\!\min_{\hat{x}}\&#124;\mathcal{F}(\hat{x})-y\&#124;+\lambda\mathcal{R}(\hat{x})$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: 'where $||\mathcal{F}(\hat{x})-y\|$ is a data fidelity term that measures the
    consistency of the approximate solution to the measured signal y, $\mathcal{R}(\cdot)$
    is a regularization term encoding the prior information about the data, and $\lambda$
    is a hyper-parameter that controls the contribution of the regularization term.
    The reconstruction error is minimized iteratively until convergence. The regularization
    term is often the most important part of the modeling and what researchers have
    mostly focused on in the literature as it vastly reduces the solution space by
    accounting for assumptions based on the underlying data (e.g., smoothness, sparsity,
    spatio-temporal redundancy). The interested reader can refer to (Dong and Shen,
    [2015](#bib.bib22); McCann and Unser, [2019](#bib.bib49)) for more details on
    regularization modeling. Fig. [6](#S2.F6 "Figure 6 ‣ 2.2 Iterative Methods ‣ 2
    Conventional Image Reconstruction Approaches ‣ Deep Learning for Biomedical Image
    Reconstruction: A Survey") shows an example of an iterative approach workflow
    for diffuse optical tomography (DOT) imaging.'
  prefs: []
  type: TYPE_NORMAL
- en: Several image priors were formulated as sparse transforms to deal with incomplete
    data issues. The sparsity idea, representing a high dimensional image $x$ by only
    a small number of nonzero coefficients, is one dominant paradigm that has been
    shown to drastically improve the reconstruction quality especially when the number
    of measurements $N$ or theirs signal to noise ratio (SNR) is low. Given the assumption
    that an image can be represented with a few nonzero coefficients (instead of its
    number of pixels), it is possible to recover it from a much smaller number of
    measurements. A popular choice for a sparsifying transform is total variation
    (TV) that is widely studied in academic literature. The interested reader is referred
    to Rodriguez et al. (Rodríguez, [2013](#bib.bib62)) for TV based algorithms modeling
    details. While TV imposes a strong assumption on the gradient sparsity via the
    non-smooth absolute value that is more suited to piece-wise constant images, TV
    tends to cause artifacts such as blurred details and undesirable patchy texture
    in the final reconstructions. Recent work aimed at exploiting richer feature knowledge
    overcomes TV’s weaknesses, for example TV-type variants (Zhang et al., [2016a](#bib.bib99)),
    non-local means (NLM) (Zhang et al., [2016b](#bib.bib100)), wavelet approaches (Gao
    et al., [2011](#bib.bib26)), and dictionary learning (Xu et al., [2012](#bib.bib89)).
    Non-local means filtering methods, widely used for CT (Zhang et al., [2017](#bib.bib98)),
    are operational in the image domain and allow the estimation of the noise component
    based on multiple patches extracted at different locations in the image (Sun et al.,
    [2016](#bib.bib69)).
  prefs: []
  type: TYPE_NORMAL
- en: 'Overall, although iterative reconstruction methods showed substantial accuracy
    improvements and artifact reductions over the analytical ones, they still face
    three major weaknesses: First, iterative reconstruction techniques tend to be
    vendor-specific since the details of the scanner geometry and correction steps
    are not always available to users and other vendors. Second, there are substantial
    computational overhead costs associated with popular iterative reconstruction
    techniques due to the load of the projection and back-projection operations required
    at each iteration. The computational cost of these methods is often several orders
    of magnitude higher than analytical methods, even when using highly-optimized
    implementations. A trade-off between real-time performance and quality is made
    in favor of quality in iterative reconstruction methods due to their non-linear
    complexity of quality in function of the processing time. Finally, the reconstruction
    quality is highly dependent on the regularization function form and the related
    hyper-parameters settings as they are problem-specific and require non-trivial
    manual adjustments. Over-imposing sparsity ($\mathcal{L}1$ penalties) for instance
    can lead to cartoon-like artifacts. Proposing a robust iterative algorithm is
    still an active research area (Sun et al., [2019c](#bib.bib73); Moslemi et al.,
    [2020](#bib.bib51)).'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f02e4ee9bd8d31f5d0c22845d200fd7e.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: Visualization of common deep learning-based reconstruction paradigms
    from raw sensor data. (A) A two-step processing model is shown where deep learning
    complements conventional methods (Section [3.1](#S3.SS1 "3.1 Deep Learning as
    Processing Step: Two Step Image Reconstruction Models ‣ 3 Deep Learning Based
    Image Reconstruction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")).
    A typical example would be to pre-process the raw sensor data using a conventional
    approach and enhance the resulting image with a deep learning model or vise versa.
    (B) An end-to-end model is shown: The image is directly estimated from the raw
    sensor data with a deep learning model (Section [3.2](#S3.SS2 "3.2 End-to-End
    Image Reconstruction: Direct Estimation ‣ 3 Deep Learning Based Image Reconstruction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")).(C) Task results
    can be directly inferred with or without explicit image reconstruction (Section
    [3.3](#S3.SS3 "3.3 Raw-to-task Methods ‣ 3 Deep Learning Based Image Reconstruction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")).'
  prefs: []
  type: TYPE_NORMAL
- en: 3 Deep Learning Based Image Reconstruction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To further advance biomedical image reconstruction, a more recent trend is to
    exploit deep learning techniques for solving the inverse problem to improve resolution
    accuracy and speed-up reconstruction results. As a deep neural network represents
    a complex mapping, it can detect and leverage features in the input space and
    build increasingly abstract representations useful for the end-goal. Therefore,
    it can better exploit the measured signals by extracting more contextual information
    for reconstruction purposes. In this section, we summarize works using DL for
    inverse problems in imaging.
  prefs: []
  type: TYPE_NORMAL
- en: 'Learning-based image reconstruction is driven by data where a training dataset
    is used to tune a parametric reconstruction algorithm that approximates the solution
    to the inverse problem with a significant one-time, offline training cost that
    is offset by a fast inference time. There is a variety of these algorithms, with
    some being closely related to conventional methods and others not. While some
    methods considered machine learning as a reconstruction step by combining a traditional
    model with deep modeling to recover the missing details in the input signal or
    enhance the resulting image (Section [3.1](#S3.SS1 "3.1 Deep Learning as Processing
    Step: Two Step Image Reconstruction Models ‣ 3 Deep Learning Based Image Reconstruction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey"), some others considered
    a more elegant solution to reconstruct an image from its equivalent initial measurements
    directly by learning all the parameters of a deep neural network, in an end-to-end
    fashion, and therefore approximating the underlying physics of the inverse problem
    (Section [3.2](#S3.SS2 "3.2 End-to-End Image Reconstruction: Direct Estimation
    ‣ 3 Deep Learning Based Image Reconstruction ‣ Deep Learning for Biomedical Image
    Reconstruction: A Survey")), or even going further and solving for the target
    task directly (Section [3.3](#S3.SS3 "3.3 Raw-to-task Methods ‣ 3 Deep Learning
    Based Image Reconstruction ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey")). Fig. [7](#S2.F7 "Figure 7 ‣ 2.2 Iterative Methods ‣ 2 Conventional
    Image Reconstruction Approaches ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey") shows a generic example of the workflow of these approaches. Table [2](#S6.T1
    "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey") surveys various
    papers based on these different paradigms and provides a comparison in terms of
    used data (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion
    and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Column
    ”Mod.”,”Samp.”,”D”), architecture (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions
    ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep Learning for Biomedical
    Image Reconstruction: A Survey")-Column ”TA”,”Arch.”), loss and regularization
    (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion
    and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Column
    ”Loss”,”Reg.”), augmentation (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions
    ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep Learning for Biomedical
    Image Reconstruction: A Survey")-Column ”Aug.”), etc .'
  prefs: []
  type: TYPE_NORMAL
- en: '3.1 Deep Learning as Processing Step: Two Step Image Reconstruction Models'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Complementing a conventional image reconstruction approach with a DL-model
    enables improved accuracy while reducing the computational cost. The problem can
    be addressed either in the sensor domain (pre-processing) or the image domain
    (post-processing) (Fig. [7](#S2.F7 "Figure 7 ‣ 2.2 Iterative Methods ‣ 2 Conventional
    Image Reconstruction Approaches ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey")-A, Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion,
    Discussion and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey")-Column ”E2E”).'
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.1 A Pre-Processing Step (Sensor Domain)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The problem is formulated as a regression in the sensor domain from incomplete
    data representation (e.g., sub-sampling, limited view, low dose) to complete data
    (full dose or view) using DL methods and has led to enhanced results (Hyun et al.,
    [2018](#bib.bib42); Liang et al., [2018](#bib.bib47); Cheng et al., [2018](#bib.bib18)).
    The main goal is to estimate, using a DL model, missing parts of the signal that
    have not been acquired during the acquisition phase in order to input a better
    signal to an analytical approach for further reconstruction.
  prefs: []
  type: TYPE_NORMAL
- en: Hyun et al.([2018](#bib.bib42)) proposed a k-space correction based U-Net to
    recover the unsampled data followed by an IFT to obtain the final output image.
    They demonstrated artifact reduction and morphological information preservation
    when only 30% of the k-space data is acquired. Similarly, Liang et al. ([2018](#bib.bib47))
    proposed a CT angular resolution recovery based on deep residual convolutional
    neural networks (CNNs) for accurate full view estimation from unmeasured views
    while reconstructing images using filtered back projection. Reconstruction demonstrated
    speed-up with fewer streaking artifacts along with the retrieval of additional
    important image details. Unfortunately, since noise is not only present in the
    incomplete data acquisition case, but also in the full data as well, minimizing
    the error between the reference and the predicted values can cause the model to
    learn to predict the mean of these values. As a result, the reconstructed images
    can suffer from lack of texture detail.
  prefs: []
  type: TYPE_NORMAL
- en: Huang et al. ([2019b](#bib.bib40)) argue that DL-based methods can fail to generalize
    to new test instances given the limited training dataset and DL’s vulnerability
    to small perturbations especially in noisy and incomplete data case. By constraining
    the reconstructed images to be consistent with the measured projection data, while
    the unmeasured information is complemented by learning based methods, reconstruction
    quality can be improved. DL predicted images are used as prior images to provide
    information in missing angular ranges first followed by a conventional reconstruction
    algorithm to integrate the prior information in the missing angular ranges and
    constrain the reconstruction images to be consistent to the measured data in the
    acquired angular range.
  prefs: []
  type: TYPE_NORMAL
- en: Signal regression in the sensor domain reduces signal loss enabling improved
    downstream results from the coupled analytic method. However, the features extracted
    by DL methods are limited to the sensor domain only while analytical methods’
    weaknesses are still present in afterword processing.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1.2 A Post-Processing Step (Image Domain)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The regression task is to learn the mapping between the low-quality reconstructed
    image and its high-quality counterpart. Although existing iterative reconstruction
    methods improved the reconstructed image quality, they remain computationally
    expensive and may still present reconstruction artifacts in the presence of noise
    or incomplete information, e.g. sparse sampling of data. The main difficulty arises
    from the non-stationary nature of the noise and serious streaking artifacts due
    to information loss (Chen et al., [2012](#bib.bib17); Al-Shakhrah and Al-Obaidi,
    [2003](#bib.bib3)). These noise and artifacts are challenging to isolate as they
    may have strong magnitudes and do not obey specific model distributions in the
    image domain (Wang et al., [2016](#bib.bib82)). The automatic learning and detection
    of complex patterns offered by deep neural networks offers a clear advantage in
    this use case over handcrafted filters.
  prefs: []
  type: TYPE_NORMAL
- en: Given an initial reconstruction estimate from a direct inverse operator e.g., FBP
    (Sun et al., [2018](#bib.bib72); Gupta et al., [2018](#bib.bib34); Chen et al.,
    [2017a](#bib.bib15)), IFT (Wang et al., [2016](#bib.bib82)), or few iterative
    approach steps (Jin et al., [2017](#bib.bib44); Cui et al., [2019](#bib.bib19);
    Xu et al., [2017](#bib.bib88)), deep learning is used to refine the initialized
    reconstruction and produce the final reconstructed image. For example, Chen et
    al. ([2017b](#bib.bib16)) used an autoencoder to improve FBP results on a limited
    angle CT projection. Similarly, Jin et al. ([2017](#bib.bib44)) enhanced a direct
    inversion formula extracted from a spectral iterative algorithm via subsequent
    filtering by a U-Net to reduce artifacts. These architectures are feasible ways
    to capture images structure as dimensionality reduction.
  prefs: []
  type: TYPE_NORMAL
- en: Generative adversarial networks (GAN) (Goodfellow et al., [2014](#bib.bib32))
    were leveraged to improve the quality of reconstructed images. Wolterink et al. ([2017](#bib.bib85))
    proposed to train an adversarial network to estimate full-dose CT images from
    low-dose CT ones and showed empirically that an adversarial network improves the
    model’s ability to generate images with reduced aliasing artifacts. Interestingly,
    they showed that combining squared error loss with adversarial loss can lead to
    a noise distribution similar to that in the reference full-dose image even when
    no spatially aligned full-dose and low dose scans are available.
  prefs: []
  type: TYPE_NORMAL
- en: Yang et al. ([2017a](#bib.bib90)) proposed a deep de-aliasing GAN (DAGAN) for
    compressed sensing MRI reconstruction that resulted in reduced aliasing artifacts
    while preserving texture and edges in the reconstruction. Remarkably, a combined
    loss function based on content loss ( consisting of a pixel-wise image domain
    loss, a frequency domain loss and a perceptual VGG loss) and adversarial loss
    were used. While frequency domain information was incorporated to enforce similarity
    in both the spatial (image) and the frequency domains, a perceptual VGG coupled
    to a pixel-wise loss helped preserve texture and edges in the image domain.
  prefs: []
  type: TYPE_NORMAL
- en: Combining DL and conventional methods reduce the computational cost but has
    its own downsides. For instance, the features extracted by DL methods are highly
    impacted by the results of the conventional methods, especially in case of limited
    measurements and the presence of noise where the initially reconstructed image
    may contain significant and complex artifacts that may be difficult to remove
    even by DL models. In addition, the information missing from the initial reconstruction
    is challenging to be reliably recovered by post-processing like many inverse problems
    in the computer vision literature such as image inpainting. Furthermore, the number
    of iterations required to obtain a reasonable initial image estimate using an
    iterative method can be hard to define and generally requires a long run-time
    (in the order of several min) to be considered for real-time scanning. Therefore,
    the post-processing approach may be more suitable to handle initial reconstructions
    that are of relatively good quality and not drastically different from the high-quality
    one.
  prefs: []
  type: TYPE_NORMAL
- en: '3.2 End-to-End Image Reconstruction: Direct Estimation'
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'An end-to-end solution leverages the image reconstruction task directly from
    sensor-domain data using a deep neural network by mapping sensor measurements
    to image domain while approximating the underlying physics of the inverse problem.
    (Fig. [7](#S2.F7 "Figure 7 ‣ 2.2 Iterative Methods ‣ 2 Conventional Image Reconstruction
    Approaches ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-B).
    This direct estimation model may represent a better alternative as it benefits
    from the multiple levels of abstraction and the automatic feature extraction capabilities
    of deep learning models.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Given pairs of measurement vectors $y$ and their corresponding ground truth
    images $x$ (that produce $y$), the goal is to optimize the parameters $\theta$
    of a neural network in an end-to-end manner to learn the mapping between the measurement
    vector $y$ and its reconstructed tomographic image $x$, which recovers the parameters
    of underlying imaged tissue. Therefore, we seek the inverse function $\mathcal{A}^{-1}(\cdot)$
    that solves:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\theta{{}^{*}}=\arg\!\min_{\theta}\mathcal{L}\left(\mathcal{A}^{-1}(y,\theta),x\right)+\lambda\mathcal{R}(\mathcal{A}^{-1}(y,\theta))$
    |  | (3) |'
  prefs: []
  type: TYPE_TB
- en: where $\mathcal{L}$ is the loss function of the network that, broadly, penalizes
    the dissimilarity between the estimated reconstruction and the ground truth. The
    regularization term $\mathcal{R}$ is often introduced to prevent over-fitting
    with $\mathcal{L}1$ or $\mathcal{L}2$ norms being the most common choices.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, several paradigms have emerged for end-to-end DL-based reconstruction
    the most common of which are generic DL models and DL models that unroll an iterative
    optimization.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.1 Generic Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Although some proposed models rely on multilayer perceptron (MLP) feed-forward
    artificial neural network (Pelt and Batenburg, [2013](#bib.bib57); Boublil et al.,
    [2015](#bib.bib10); Feng et al., [2018](#bib.bib24); Wang et al., [2019](#bib.bib81)),
    CNNs remain the most popular generic reconstruction models mainly due to their
    data filtering and features extraction capabilities. Specifically, encoder-decoder (Nehme
    et al., [2018](#bib.bib53); Häggström et al., [2019](#bib.bib36)), U-Net (Waibel
    et al., [2018](#bib.bib77)), ResNet (Cai et al., [2018](#bib.bib12)) and decoder
    like architecture (Yoon et al., [2018](#bib.bib95); Wu et al., [2018](#bib.bib86);
    Zhu et al., [2018](#bib.bib102)) are the most dominant architectures as they rely
    on a large number of stacked layers to enrich the level of features extraction.
    A set of skip connections enables the later layers to reconstruct the feature
    maps with both the local details and the global texture and facilitates stable
    training when the network is very deep.
  prefs: []
  type: TYPE_NORMAL
- en: 'The common building blocks of neural network architectures are convolutional
    layers, batch normalization layers, and rectified linear units (ReLU). ReLU is
    usually used to enforce information non-negativity properties, given that the
    resulting pixels values represent tissue properties e.g., chromophores concentration
    maps (Yoo et al., [2019](#bib.bib94)), refractive index (Sun et al., [2016](#bib.bib69)),
    and more examples in Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion,
    Discussion and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction:
    A Survey"). Batch normalization is used to reduce the internal covariate shift
    and accelerates convergence. The resulting methods can produce relatively good
    reconstructions in a short time and can be adapted to other modalities but require
    a large training dataset and good initialization parameters. Table [2](#S6.T1
    "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Column ”E2E” (check-marked)
    surveys many papers with various architecture, loss, and regularization for 2D,3D
    and 4D different modalities.'
  prefs: []
  type: TYPE_NORMAL
- en: Zhu et al.([2018](#bib.bib102)) proposed a manifold learning framework based
    decoder neural network to emulate the fast-Fourier transform (FFT) and learn an
    end-to-end mapping between k-space data and image domains where they showed artifact
    reduction and reconstruction speed up. However, when trained with an $\mathcal{L}1$
    or $\mathcal{L}2$ loss only, a DL-based reconstructed image still exhibits blurring
    and information loss, especially when used with incomplete data. Similarly, Ben
    Yedder et al. ([2018](#bib.bib92)) proposed a decoder like model for DOT image
    reconstruction. While increased reconstruction speed and lesion localization accuracy
    are shown, some artifacts are still present in the reconstructed image when training
    with $\mathcal{L}2$ loss only. This motivated an improved loss function in their
    follow-up work (Yedder et al., [2019](#bib.bib93)) where they suggested combining
    $\mathcal{L}2$ with a Jaccard loss component to reduce reconstructing false-positive
    pixels.
  prefs: []
  type: TYPE_NORMAL
- en: Thaler et al. (Thaler et al., [2018](#bib.bib75)) proposed a Wasserstein GAN
    (WGAN) based architecture for improving the image quality for 2D CT image slice
    reconstruction from a limited number of projection images using a combination
    of $\mathcal{L}1$ and adversarial losses. Similarly, Ouyang et al. ([2019](#bib.bib55))
    used a GAN based architecture with a task-specific perceptual and $\mathcal{L}1$
    losses to synthesize PET images of high quality and accurate pathological features.
  prefs: []
  type: TYPE_NORMAL
- en: 'To further enhance results and reduce artifacts due to motion and corruption
    of k-space signal, Clough et al. ([2019](#bib.bib54)) proposed a recurrent convolutional
    neural network (RCNN) to reconstruct high quality dynamic cardiac MR images while
    automatically detecting and correcting motion-related artifacts and exploiting
    the temporal dependencies within the sequences. Proposed architecture included
    two sub-networks trained jointly: an artifact detection network that identifies
    potentially corrupted k-space lines and an RCNN for reconstruction.'
  prefs: []
  type: TYPE_NORMAL
- en: To relax the requirement of a large number of training samples, a challenging
    requirement in a medical setting, simulating data was proposed as an alternative
    source of training data. However, creating a realistic synthetic dataset is a
    challenging task in itself as it requires careful modeling of the complex interplay
    of factors influencing real-world acquisition environment. To bridge the gap between
    the real and in silico worlds, transfer learning provides a potential remedy as
    it helps transfer the measurements from the simulation domain to the real domain
    by keeping the general attenuation profile while accounting for real-world factors
    such as scattering, etc.
  prefs: []
  type: TYPE_NORMAL
- en: Ben Yedder et al.([2019](#bib.bib93)) proposed a supervised sensor data distribution
    adaptation based MLP to take advantage of cross-domain learning and reported accuracy
    enhancement in detecting tissue abnormalities. Zhou et al. ([2019](#bib.bib101))
    proposed unsupervised CT sinograms adaptation, based on CycleGAN and content consistent
    regularization, to further alleviate the need for real measurement-reconstruction
    pairs. Interestingly, the proposed method integrated the measurement adaptation
    network and the reconstruction network in an end-to-end network to jointly optimize
    the whole network.
  prefs: []
  type: TYPE_NORMAL
- en: Although several generic DL architectures and loss functions have been explored
    to further enhance reconstruction results in different ways (resolution, lesion
    localization, artifact reduction, etc.), a DL-based method inherently remains
    a black-box that can be hard to interpret. Interpretability is key not only for
    trust and accountability in a medical setting but also to correct and improve
    the DL model.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Unrolling Iterative Methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Unrolling conventional optimization algorithms into a DL model has been suggested
    by several works (Qin et al., [2018](#bib.bib58); Schlemper et al., [2017a](#bib.bib65);
    Würfl et al., [2018](#bib.bib87); Sun et al., [2016](#bib.bib69); Adler and Öktem,
    [2018](#bib.bib1)) in order to combine the benefits of traditional iterative methods
    and the expressive power of deep models (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future
    Directions ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep Learning for
    Biomedical Image Reconstruction: A Survey")-Column ”E2E”). Rajagopal et al.([2019](#bib.bib59))
    proposed a theoretical framework demonstrating how to leverage iterative methods
    to bootstrap network performance while preserving network convergence and interpretability
    featured by the conventional approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: Deep ADMM-Net (Sun et al., [2016](#bib.bib69)) was the first proposed model
    reformulating the iterative reconstruction ADMM (alternating direction method
    of multipliers) algorithm into a deep network for accelerating MRI reconstruction,
    where each stage of the architecture corresponds to an iteration in the ADMM algorithm.
    In its iterative scheme, the ADMM algorithm requires tuning of a set of parameters
    that are difficult to determine adaptively for a given data set. By unrolling
    the ADMM algorithm into a deep model, the tuned parameters are now all learnable
    from the training data. The ADMM-Net was later further improved to Generic-ADMM-Net (Yang
    et al., [2017b](#bib.bib91)) where a different variable splitting strategy was
    adopted in the derivation of the ADMM algorithm and demonstrated state-of-the-art
    results with a significant margin over the BM3D-based algorithm (Dabov et al.,
    [2007](#bib.bib20)).
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, the PD-Net (Adler and Öktem, [2018](#bib.bib1)) adopted neural networks
    to approximate the proximal operator by unrolling the primal-dual hybrid gradient
    algorithm (Chambolle and Pock, [2011](#bib.bib14)) and demonstrated performance
    boost compared with FBP and handcrafted reconstruction models.
  prefs: []
  type: TYPE_NORMAL
- en: In like manner, Schlemper et al. ([2017a](#bib.bib65)) proposed a cascade convolutional
    network that embeds the structure of the dictionary learning-based method while
    allowing end-to-end parameter learning. The proposed model enforces data consistency
    in the sensor and image domain simultaneously, reducing the aliasing artifacts
    due to sub-sampling. An extension for dynamic MR reconstructions (Schlemper et al.,
    [2017b](#bib.bib66)) exploits the inherent redundancy of MR data.
  prefs: []
  type: TYPE_NORMAL
- en: While, the majority of the aforementioned methods used shared parameters over
    iterations only, Qin et al. ([2018](#bib.bib58)) proposed to propagate learnt
    representations across both iteration and time. Bidirectional recurrent connections
    over optimization iterations are used to share and propagate learned representations
    across all stages of the reconstruction process and learn the spatio–temporal
    dependencies. The proposed deep learning based iterative algorithm can benefit
    from information extracted at all processing stages and mine the temporal information
    of the sequences to improve reconstruction accuracy. The advantages of leveraging
    temporal information was also demonstrated in single molecule localization microscopy (Cardoen
    et al., [2019](#bib.bib13)). An LSTM was able to learn an unbiased emission density
    prediction in a highly variable frame sequence of spatio-temporally separated
    fluorescence emissions. In other words, joint learning over the temporal domain
    of each sequence and across iterations leads to improved de-aliasing.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f46b45e4c7da07cce5b3f294ff437925.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: (A) Biomedical image processing workflow usually involves two steps
    optimized independently (reconstruction and image analysis) for diagnosis purposes.
    (B) Jointly solving these tasks using a unified model allows joint parameters
    tuning and feature sharing.'
  prefs: []
  type: TYPE_NORMAL
- en: 3.3 Raw-to-task Methods
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Typical data flow in biomedical imaging involves solving the image reconstruction
    task followed by preforming an image processing task (e.g., segmentation, classification)
    (Fig [8](#S3.F8 "Figure 8 ‣ 3.2.2 Unrolling Iterative Methods ‣ 3.2 End-to-End
    Image Reconstruction: Direct Estimation ‣ 3 Deep Learning Based Image Reconstruction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-A). Although each
    of these two tasks (reconstruction and image processing) is solved separately,
    the useful clinical information extracted for diagnosis by the second task is
    highly dependent on the reconstruction results. In the raw-to-task paradigm, task
    results are directly inferred from raw data, where image reconstruction and processing
    are lumped together and reconstructed image may not be necessarily outputted (Fig. [7](#S2.F7
    "Figure 7 ‣ 2.2 Iterative Methods ‣ 2 Conventional Image Reconstruction Approaches
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-C, Fig [8](#S3.F8
    "Figure 8 ‣ 3.2.2 Unrolling Iterative Methods ‣ 3.2 End-to-End Image Reconstruction:
    Direct Estimation ‣ 3 Deep Learning Based Image Reconstruction ‣ Deep Learning
    for Biomedical Image Reconstruction: A Survey")-B)'
  prefs: []
  type: TYPE_NORMAL
- en: Jointly solving for different tasks using a unified model is frequently considered
    in the computer vision field, especially for image restoration (Sbalzarini, [2016](#bib.bib64)),
    and has lead to improved results than solving tasks sequentially (Paul et al.,
    [2013](#bib.bib56)). The advantages explain the recent attention this approach
    received in biomedical image reconstruction (Sun et al., [2019a](#bib.bib70);
    Huang et al., [2019a](#bib.bib39)). For instance, a unified framework allows joint
    parameters tuning for both tasks and feature sharing where the two problems regularize
    each other when considered jointly. In addition, when mapping is performed directly
    from the sensor domain, the joint task can even leverage sensor domain features
    for further results enhancing while it can be regarded as a task-based image quality
    metric that is learned from the data. Furthermore, Sbalzarini ([2016](#bib.bib64))
    argues that solving ill-posed problems in sequence can be more efficient than
    in isolation. Since the output space of a method solving an inverse problem is
    constrained by forming the input space of the next method, the overall solution
    space contracts. Computational resources can then be focused on this more limited
    space improving runtime, solution quality or both.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Medical Training Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The performance of learning-based methods is dictated to a large extent by the
    size and diversity of the training dataset. In a biomedical setting, the need
    for large, diverse, and generic datasets is non-trivial to satisfy given constraints
    such as patient privacy, access to acquisition equipment and the problem of divesting
    medical practitioners to annotate accurately the existing data. In this section,
    we will discuss how researchers address the trade-offs in this dilemma and survey
    the various publicly available dataset type used in biomedical image reconstruction
    literature.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion
    and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Columns
    ”Data”, ”Site” and ”Size” summarise details about dataset used by different surveyed
    papers, which are broadly classified into clinical (real patient), physical phantoms,
    and simulated data. The sources of used datasets have been marked in the last
    column of Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion
    and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Columns
    ”Pub”. Data” in case of their public availability to other researchers. Since
    phantom data are not commonly made publicly available, the focus was mainly given
    to real and simulated data whether they are publicly available or as part of challenges.
    Used augmentation techniques have been mentioned in Table [2](#S6.T1 "Table 2
    ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep
    Learning for Biomedical Image Reconstruction: A Survey")-Columns ”Aug”. Remarkably,
    augmentation is not always possible in image reconstruction task especially in
    sensor domain given the non-symmetries of measurements in some case, the nonlinear
    relationship between raw and image data, and the presence of other phenomena(e.g., scattering).
    We herein survey the most common source of data and discuss their pros and cons.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Real-World Datasets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some online platforms (e.g.,  [Lung Cancer Alliance](#bib.bib48),  [Mridata](#bib.bib52),
    MGH-USC HCP ([2016](#bib.bib23)), and  [Biobank](#bib.bib9)) made the initiative
    to share datasets between researchers for image reconstruction task.  [Mridata](#bib.bib52),
    for example, is an open platform for sharing clinical MRI raw k-space datasets.
    The dataset is sourced from acquisitions of different manufacturers, allowing
    researchers to test the sensitivity of their methods to overfitting on a single
    machine’s output while may require the application of transfer-learning techniques
    to handle different distributions. As of writing, only a subset of organs for
    well known modalities e.g., MRI and CT are included (Table [2](#S6.T1 "Table 2
    ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep
    Learning for Biomedical Image Reconstruction: A Survey")-Columns ”Site”). Representing
    the best reconstruction images acquired for a specific modality, the pairs of
    signal-image form a gold standard for reconstruction algorithms. Releasing such
    data, while extremely valuable for researchers, is a non-trivial endeavour where
    legal and privacy concerns have to be taken into account by, for example, de-anonymization
    of the data to make sure no single patient or ethnographically distinct subset
    of patients can ever be identified in the dataset. Source of real-word used datasets
    on surveyed papers has been marked in Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions
    ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep Learning for Biomedical
    Image Reconstruction: A Survey")-Columns ”Pub. Data” where they sizes remain relatively
    limited to allow a good generalization of DL-based methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Physics-Based Simulation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Physics-based simulation (Schweiger and Arridge, [2014](#bib.bib67); Harrison,
    [2010](#bib.bib37); Häggström et al., [2016](#bib.bib35)) provides an alternative
    source of training data that allows generating a large and diversified dataset.
    The accuracy of a physical simulation with respect to real-world acquisitions
    increases at the cost of an often super-linear increase in computational resources.
    In addition, creating realistic synthetic datasets is a nontrivial task as it
    requires careful modeling of the complex interplay of factors influencing real-world
    acquisition environment. With a complete model of the acquisition far beyond computational
    resources, a practitioner needs to determine how close to reality the simulation
    needs to be in order to allow the method under development to work effectively.
    Transfer learning provides a potential remedy to bridge the gap between real and
    in silico worlds and alleviates the need for a large clinical dataset (Zhu et al.,
    [2018](#bib.bib102); Yedder et al., [2019](#bib.bib93)). In contrast, the approach
    of not aiming for complete realism but rather using the simulation as a tool to
    sharpen the research question can be appropriate. Simulation is a designed rather
    than a learned model. For both overfitting to available data is undesirable. The
    assumptions underlying the design of the simulation are more easily verified or
    shown not to hold if the simulation is not fit to the data, but represents a contrasting
    view. For example, simulation allows the recreation and isolation of edge cases
    where a current approach is performing sub-par. As such simulation is a key tool
    for hypothesis testing and validation of methods during development. For DL-based
    methods the key advantage simulation offers is the almost unlimited volume of
    data that can be generated to augment limited real-world data in training. With
    the size of datasets as one of the keys determining factors for DL-based methods
    leveraging simulation is essential. Surveyed papers that used simulated data as
    a training or augmentation data have been marked in Table [2](#S6.T1 "Table 2
    ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep
    Learning for Biomedical Image Reconstruction: A Survey")-Columns ”Pub”.'
  prefs: []
  type: TYPE_NORMAL
- en: 4.3 Challenge Dataset
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'There are only a few challenge (competition) datasets for image reconstruction
    task e.g., LowDoseCT ([2014](#bib.bib74)) FastMRI (Zbontar et al., [2018](#bib.bib96)),
    Fresnel (Geffrin et al., [2005](#bib.bib28)) and SMLM challenge (Holden and Sage,
    [2016](#bib.bib38)) that includes raw measurements. Simulating incomplete signals
    by degrading the high-quality acquired signals while keeping their corresponding
    high-quality images pair was also explored. Alternatively, researchers collect
    high-quality images from other medical imaging challenges, e.g., segmentation
    (MRBrainS challenge (Mendrik et al., [2015](#bib.bib50)), Bennett and Simon ([2013](#bib.bib8))),
    and use simulation, using a well known forward model, to generate full and/or
    incomplete sensor domain pairs. Here again, only a subset of body scans and diseases
    for well-studied modalities are publicly available as highlighted in Table [2](#S6.T1
    "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion and Future Direction
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Columns ”Site”
    and ”Pub. Data” .'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Reconstruction Evaluation Metrics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 5.1 Quality
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Measuring the performance of the reconstruction approaches is usually performed
    using three metrics, commonly applied in computer vision, in order to access the
    quality of the reconstructed images. These metrics are the root mean squared error
    (RMSE) or normalized mean squared error, structural similarity index (SSIM) or
    its extended version multiscale structural similarity (Wang et al., [2003](#bib.bib83)),
    and peak signal to noise ratio (PSNR).
  prefs: []
  type: TYPE_NORMAL
- en: While RMSE measures the pixel-wise intensity difference between ground truth
    and reconstructed images by evaluating pixels independently, ignoring the overall
    image structure, SSIM, a perceptual metric, quantifies visually perceived image
    quality and captures structural distortion. SSIM combines luminance, contrast,
    and image structure measurements and ranges between [0,1] where the higher SSIM
    value the better and SSIM = 1 means that the two compared images are identical.
  prefs: []
  type: TYPE_NORMAL
- en: 'PSNR (Eq. [4](#S5.E4 "In 5.1 Quality ‣ 5 Reconstruction Evaluation Metrics
    ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")) is a well-known
    metric for image quality assessment which provides similar information as the
    RMSE but in units of dB while measuring the degree to which image information
    rises above background noise. Higher values of PSNR indicate a better reconstruction.'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $PSNR=20.{\log_{10}{\left(\frac{X_{max}}{\sqrt{MSE}}\right)}}$ |  | (4)
    |'
  prefs: []
  type: TYPE_TB
- en: where $X_{max}$ is the maximum pixel value of the ground truth image.
  prefs: []
  type: TYPE_NORMAL
- en: 'Illustrating modality specific reconstruction quality is done by less frequently
    used metrics such as contrast to noise ratio (CNR) (Wu et al., [2018](#bib.bib86))
    for US. Normalized mutual information (NMI) is a metric used to determine the
    mutual information shared between two variables, in this context image ground
    truth and reconstruction (Wu et al., [2018](#bib.bib86); Zhou et al., [2019](#bib.bib101)).
    When there is no shared information NMI is 0, whereas if both are identical a
    score of 1 is obtained. To illustrate NMI’s value, consider two images X, Y with
    random values. When generated from two different random sources, X and Y are independent,
    yet RMSE(X,Y) can be quite small. When the loss function minimizes RMSE, such
    cases can induce stalled convergence at a suboptimal solution due to a constant
    gradient. NMI, on the other hand, would return zero (or a very small value), as
    expected. The intersection over union, or Jaccard index, is leveraged to ensure
    detailed accurate reconstruction (Yedder et al., [2018](#bib.bib92); Sun et al.,
    [2019a](#bib.bib70)). In cases where the object of interest is of variable size
    and small with respect to the background, an RMSE score is biased by matching
    the background rather than the target of interest. In a medical context, it is
    often small deviations (e.g. tumors, lesions, deformations) that are critical
    to diagnosis. Thus, unlike computer vision problems where little texture changes
    might not alter the overall observer’s satisfaction, in medical reconstruction,
    further care should be taken to ensure that practitioners are not misled by a
    plausible but not necessarily correct reconstruction. Care should be taken to
    always adjust metrics with respect to their expected values under an appropriate
    random model (Gates and Ahn, [2017](#bib.bib27)). The understanding of how a metric
    responds to its input should be a guideline to its use. As one example, the normalization
    method in NMI has as of writing no less than 6 (Gates and Ahn, [2017](#bib.bib27))
    alternatives with varying effect on the metric. Table [2](#S6.T1 "Table 2 ‣ 6.2
    Future Directions ‣ 6 Conclusion, Discussion and Future Direction ‣ Deep Learning
    for Biomedical Image Reconstruction: A Survey")-Columns ”Metrics” surveys the
    most frequently used metrics on surveyed papers.'
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Inference Speed
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With reconstruction algorithms constituting a key component in time-critical
    diagnosis or intervention settings, the time complexity is an important metric
    in selecting methods. Two performance criteria are important in the context of
    time: Throughput measures how many problem instances can be solved over a time
    period, and latency measures the time needed to process a single problem instance.
    In a non-urgent medical setting, a diagnosing facility will value throughput more
    than latency. In an emergency setting where even small delays can be lethal, latency
    is critical above all. For example, if a reconstruction algorithm is deployed
    on a single device it is not unexpected for there to be waiting times for processing.
    As a result latency, if the waiting time is included, will be high and variable,
    while throughput is constant. In an emergency setting there are limits as to how
    many devices can be deployed, computing results on scale in a private cloud on
    the other hand can have high throughput, but higher latency as there will be a
    need to transfer data offsite for processing. In this regard it is critical for
    latency sensitive applications to allow deployment on mobile (low-power) devices.
    To minimize latency (including wait-time), in addition to parallel deployment,
    the reconstruction algorithm should have a predictable and constant inference
    time, which is not necessarily true for iterative approaches.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Unfortunately, while some papers reported their training and inference times,
    (Table [2](#S6.T1 "Table 2 ‣ 6.2 Future Directions ‣ 6 Conclusion, Discussion
    and Future Direction ‣ Deep Learning for Biomedical Image Reconstruction: A Survey")-Columns
    ”Metrics-IS”) it is not obvious to compare their time complexity given the variability
    in datasets, sampling patterns, hardware, and DL frameworks. Overall, the offline
    training of DL methods bypasses the laborious online optimization procedure of
    conventional methods, and has the advantage of lower inference time over all but
    the simplest analytical.'
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion, Discussion and Future Direction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Literature shows that DL-based image reconstruction methods have gained popularity
    over the last few years and demonstrated image quality improvements when compared
    to conventional image reconstruction techniques especially in the presence of
    noisy and limited data representation. DL-based methods address the noise sensitivity
    and incompleteness of analytical methods and the computational inefficiency of
    iterative methods.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1 Discussion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Learning: Unlike conventional approaches that work on a single image in isolation
    and require prior knowledge, DL-based reconstruction methods leverage the availability
    of large-scale datasets and the expressive power of DL to impose implicit constraints
    on the reconstruction problem. While DL-based approaches do not require prior
    knowledge, their performance can improve with it. By not being dependent on prior
    knowledge, DL-based methods are more decoupled from a specific imaging (sub)modality
    and thus can be more generalizable. Real-time reconstruction is offered by DL-based
    methods by performing the optimization or learning stage offline, unlike conventional
    algorithms that require iterative optimization for each new image. The diagnostician
    can thus shorten diagnosis time increasing the throughput in patients treated.
    In operating theatres and emergency settings this advantage can be life saving.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Interpretability: While the theoretical understanding and the interpretability
    of conventional reconstruction methods are well established and strong (e.g.,
    one can prove a method’s optimality for a certain problem class), it is weak for
    the DL-based methods (due to the black-box nature of DL) despite the effort in
    explaining the operation of DL-based methods on many imaging processing tasks.
    However, one may accept the possibility that interpretabilty is secondary to performance
    as fully understanding DL-based approaches may never become practical.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Complexity: On the one hand, conventional methods can be straightforward to
    implement, albeit not necessarily to design. On the other, they are often dependent
    on parameters requiring manual intervention for optimal results. DL-based approaches
    can be challenging to train with a large if not intractable hyper-parameter space
    (e.g., learning rate, initialization, network design). In both cases, the hyper-parameters
    are critical to results and require a large time investment from the developer
    and the practitioner. In conclusion, there is a clear need for robust self-tuning
    algorithms, for both DL-based and conventional methods.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Robustness: Conventional methods can provide good reconstruction quality when
    the measured signal is complete and the noise level is low, their results are
    consistent across datasets and degrade as the data representation and/or the signal
    to noise ratio is reduced by showing noise or artifacts (e.g., streaks, aliasing).
    However, a slight change in the imaging parameters (e.g., noise level, body part,
    signal distribution, adversarial examples, and noise) can severely reduce the
    DL-based approaches’ performances and might lead to the appearance of structures
    that are not supported by the measurements (Antun et al., [2019](#bib.bib5); Gottschling
    et al., [2020](#bib.bib33)). DL based approaches still leave many unsolved technical
    challenges regarding their convergence and stability that in turn raise questions
    about their reliability as a clinical tool. A careful fusion between DL-based
    and conventional approaches can help mitigate these issues and achieve the performance
    and robustness required for biomedical imaging.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Speed: DL-based methods have the advantage in processing time over all but
    the most simple analytical methods at inference time. As a result, latency will
    be low for DL-based methods. However, one must be careful in this analysis. DL-based
    methods achieve fast inference by training for a long duration, up to weeks, during
    development. If any changes to the method are needed and retraining is required,
    even partial, a significant downtime can ensue. Typical DL-based methods are not
    designed to be adjusted at inference time. Furthermore, when a practitioner discovers
    that, at diagnosis time, the end result is sub-par, an iterative method can be
    tuned by changing its hyper-parameters. For a DL-based approach, this is non-trivial
    if not infeasible.'
  prefs: []
  type: TYPE_NORMAL
- en: A final if not less important distinction is adaptive convergence. At deployment,
    a DL-based method has a fixed architecture and weights with a deterministic output.
    Iterative methods can be run iterations until acceptable performance is achieved.
    This is a double-edged sword as convergence is not always guaranteed and the practitioner
    might not know exactly how many more iterations are needed.
  prefs: []
  type: TYPE_NORMAL
- en: 'Training Dataset: Finally, the lack of large scale biomedical image datasets
    for training due to privacy, legal, and intellectual property related concerns,
    limits the application of DL-based methods on health care. Training DL-based models
    often require scalable high performance hardware provided by cloud based offerings.
    However, deploying on cloud computing and transmitting the training data risks
    the security, authenticity, and privacy of that data. Training on encrypted data
    offers a way to ensure privacy during training Gilad-Bachrach et al. ([2016](#bib.bib31)).
    More formally a homomorphic encryption algorithm Rivest et al. ([1978](#bib.bib61))
    can ensure evaluation (reconstruction) on the encrypted data results are identical
    after decryption to reconstruction on the non-encrypted data. In practice, this
    results in an increase in dataset size as compression becomes less effective,
    a performance penalty is induced by the encryption and decryption routines, and
    interpretability and debugging the learning algorithm becomes more complex since
    it operates on human unreadable data.'
  prefs: []
  type: TYPE_NORMAL
- en: The concept of federated learning, where improvements of a model (weights) are
    shared between distributed clients without having to share datasets, has seen
    initial success in ensuring privacy while enabling improvements in quality Geyer
    et al. ([2017](#bib.bib30)). However a recent work Zhu et al. ([2019](#bib.bib103))
    has shown that if an attacker has access to the network architecture and the shared
    weights, the training data can be reconstructed with high fidelity from the gradients
    alone. Data sharing security in a federated setting still presents a concern that
    requires further investigations.
  prefs: []
  type: TYPE_NORMAL
- en: Simulating a suitable training set also remains a challenge that requires careful
    tuning and more realistic physical models to improve DL-based algorithm generalization.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2 Future Directions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The future of the field will be to produce higher quality images given the most
    limited resource budget such as radiation dose, scanning time, and scanner complexity
    as well as from online real patient inputs using algorithms with the fewest hand-tuned
    parameters and lowest power consumption.
  prefs: []
  type: TYPE_NORMAL
- en: There remain a vast range of challenges and opportunities in the field. So far,
    most approaches focus on CT and MR image reconstruction while only a handful of
    approaches exist for the reconstruction of the remaining modalities. Hence, the
    applicability of deep learning models to these problems is yet to be fully explored.
    In addition, proposed deep learning architectures are often generic and are not
    fully optimized for specific applications. For instance, how to optimally exploit
    spatio-temporal redundancy, or how to exploit multi-spectral data. By addressing
    these core questions and designing network layers to efficiently learn such data
    representation, the network architecture can gain a boost in performance and reliability.
  prefs: []
  type: TYPE_NORMAL
- en: Joint multi-modal image reconstruction, such as DOT/CT (Baikejiang et al., [2017](#bib.bib7))
    and PET/ MRI (Wang et al., [2015](#bib.bib79)), has been proposed on several iterative
    approaches to take advantage of both imaging modalities and led to improving the
    overall imaging performance, especially avoiding the spatio-temporal artifacts
    due to the scanning with different devices at different times and positions. The
    idea relies on leveraging the information provided by feature similarity between
    multiple modalities. While this direction has great interest, it has only just
    begun to receive consideration (Cui et al., [2019](#bib.bib19)) and remains a
    direction for further exploration. Collecting suitably calibrated and registered
    data on hybrid multi-modality imaging systems remains a key challenge as well.
  prefs: []
  type: TYPE_NORMAL
- en: Attention driven sampling received increasing interest recently especially in
    a limited data representation context. While adapting the sampling to the reconstruction
    algorithm showed improved image quality compared to conventional sampling strategies (Jin
    et al., [2019](#bib.bib45)), it could be computationally more expensive with unknown
    convergence behavior. The development of efficient sampling learning algorithms
    would be a promising research direction. In optical coherence tomography the application
    of wavelet based compressive sensing has been shown capable to reconstruct with
    a little as 20% of the samples (Lebed et al., [2013](#bib.bib46)). The potential
    demonstrated through handcrafted sampling strategies indicates that DL-based methods
    could also exploit this opportunity.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning models require computationally powerful machines (GPU) to provide
    online reconstruction and achieve promised performance. Network pruning and sparsifying,
    recently proposed for computer vision tasks (Alford et al., [2018](#bib.bib4);
    Aghasi et al., [2017](#bib.bib2); Huang and Wang, [2018](#bib.bib41)), present
    a promising direction yet to be explored on image reconstruction tasks in order
    to allow DL-based model processing on CPU and mobile devices. This will be of
    great interest to emergent mobile scanners (e.g., DOT (Shokoufi and Golnaraghi,
    [2016](#bib.bib68)), US (Georgeson and Safai, [2017](#bib.bib29)),CT  (Rykkje
    et al., [2019](#bib.bib63))).
  prefs: []
  type: TYPE_NORMAL
- en: Reducing the encoding size in bits of network weights without altering the quality
    of the prediction has been demonstrated on several references deep learning image
    processing networks Sun et al. ([2019b](#bib.bib71)). A reported decrease in training
    time of 30-60% is only one benefit. By reducing network weights from 64 or 32
    bits to 8 or smaller (i.e., weights quantization) the network requires a smaller
    memory footprint. As a result, networks that are at the time of writing too large
    to fit on a single GPU can be reduced to fit on a single GPU. Conversely, networks
    too large to deploy on edge devices (handheld scanner, mobile phones, etc.) can
    become easily deployable in the field without changing their architecture. Finally
    and not least important, the reduction in training time results in a significant
    reduction in the environmental impact of the training procedure.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, as performance evaluation metrics are more computer vision task-oriented,
    they tend to be insufficient in the biomedical imaging context as they do not
    provide real diagnostic accuracy significance. We advocate a shift toward task-oriented
    evaluations given that reconstructed images are usually used for a specific diagnosis
    or treatment purpose. While such a measure may be expensive, especially if they
    require human experts’ feedback, they will be critical in creating algorithms
    that can advance the biomedical imaging practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Comparison between different papers that have applied machine learning
    to the biomedical image reconstruction problem. Mod.: modality; Samp.: signal
    sampling (F: full sampling, SS: sub-sampling, LA: limited angle data, SV: sparse
    viev, LD: low dose data); MS: multi-spectral input signal; TA: consideration of
    temporal aspect; D: dimension (PC: point clouds); Site: type of tissue (soft tissue
    like brain and breast, mix: different part of the body, Abdom: abdominal area,
    Bio Samp: biological samples, Sim: simulated data); Arch: architecture model;
    E2E: whether the approach is end-to-end or combined (Pos: DL as post-processing,
    Pre: DL as pre-processing, R2T: Raw-to-task); Loss: used loss function (Comb.loss:
    combined loss, Perc: perceptual loss, Adver: adversarial loss, CE: cross entropy,
    Jacc: Jaccard loss, MMD: maximum mean discrepancy); Reg: regularization; Inp:
    input data (M.Spec Meas: multi-spectral measurements, RF: radio frequencies measurements,
    PA Meas: photo-acoustic measurements); Out: output data (Chrom Maps: chromophore
    concentration map, Ref index: refractive index, Img: intensity image, Seg: segmentation
    mask); Metrics: evaluation metrics (M: MSE or RMSE, P: PSNR, S: SSIM, D: lesion
    detection metric like Dice and Jaccard, C: contrast to noise ratio and IT: reconstruction
    inference speed) Aug: used augmentation technique (A: affine, E: elastic, R: rotation
    transformations); Data: used training data (Sim: simulated data, Clini: clinical
    data, Phan: phantom data) Pub. Data: public data used.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Ref | Mod. | Year | Samp. | MS | TA | D | Site | Arch. | E2E | Loss | Reg.
    | Inp. | Out. | Aug. | Metrics M$&#124;$P$&#124;$S$&#124;$D$&#124;$C$&#124;$IS
    | Data | Size | Pub. Data |  |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  [Cai et al.](#bib.bib12) | PA | 2018 | F | ✓ |  | 2D | Mix | ResU-Net |
    ✓ | MSE |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; M.Spec &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Meas &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓ | Sim | $\sim$2000 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Yoon et al.](#bib.bib95) | US | 2019 | SS |  |  | 3D | Abdom | Decoder
    | ✓ | MSE | L2 | RF | Img |  | -$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓
    | Clini | 500 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Wu et al.](#bib.bib86) | US | 2018 | F |  | ✓ | 2D | Mix | CNN | ✓ | MAE
    |  | RF |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Elast &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; dist &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$✓$&#124;$ - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Phan &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\sim$100 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Gupta et al.](#bib.bib34) | CT | 2018 | SV |  |  | 2D | Mix | CNN | Pos
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Comb. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | FBP | Img |  | -$&#124;$✓$&#124;$✓$&#124;$-$&#124;$-$&#124;$- | Clini
    | $\sim$1000 | LowDoseCT |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Sun et al.](#bib.bib72) |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Mult. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Scat &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2018 | F |  |  | 2D |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Bio &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Samp. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ResU-Net | Pos | MSE |  | FBP |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Ref &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; index &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | -$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Phan &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1550 | Fresnel |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Zhu et al.](#bib.bib102) | MRI | 2018 | SS |  |  | 2D | Brain | Decoder
    | ✓ | MSE | L2 | k-space | Img | A | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$
    - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; ImagNet &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\sim$10K | MGH-USCHCP |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Chen et al.](#bib.bib16) | CT | 2017 | LD |  |  | 2D | Mix | Residual AE
    | Pos | MSE |  | FBP | Img | A+R | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$
    - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\sim$10K | LowDoseCT |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Würfl et al.](#bib.bib87) | CT | 2018 | LA |  |  | 3D | Mix |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Unrolling &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Iterative &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE |  | Sinogram | Img |  | -$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$
    - | Clini | $\sim$10K | LowDoseCT |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Feng et al.](#bib.bib24) | DOT | 2019 | F |  |  | 2D | Soft | MLP | ✓ |
    MSE |  | Scattering |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ - | Sim | $\sim$20K |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Yoo et al.](#bib.bib94) | DOT | 2019 | F |  |  | 3D | Mix | Decoder | ✓
    | MSE |  | Scattering |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| $\sim$1500 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Cui et al.](#bib.bib19) | PET | 2019 | F |  |  | 3D | Mix | 3DU-Net | Pos
    | MSE |  | Sinogram | Img |  | -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓$&#124;$
    - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 30 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Hyun et al.](#bib.bib42) | MRI | 2018 | SS |  |  | 2D | Brain | U-Net |
    Pre | MSE |  | k-space |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Full &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; k-space &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$ -$&#124;$ ✓$&#124;$ -$&#124;$ -$&#124;$ - | Clini | 1400 |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Waibel et al.](#bib.bib77) | PA | 2018 | LV |  |  | 2D | Vessels | U-Net
    | ✓ | MAE |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; PA &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Meas &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Maps | R | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ - | Sim | 3600
    |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Cheng et al.](#bib.bib18) | MRI | 2018 | SS |  |  | 2D | Soft | CNN | Pre
    | MSE |  | k-space | Img |  | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$✓
    | Clini | 65K |  |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Liang et al.](#bib.bib47) | CT | 2018 | SV |  |  | 2D | Mix | ResNet |
    Pre | MSE |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sparse &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Sinogram &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Sinog. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ - | Clini | 17K | giveascan
    |  |'
  prefs: []
  type: TYPE_TB
- en: '| Ref | Mod. | Year | Samp. | MS | TA | D | Site | Arch. | E2E | Loss | Reg.
    | Inp. | Out. | Aug. | Metrics M$&#124;$P$&#124;$S$&#124;$D$&#124;$C$&#124;$IS
    | Data | Size | Pub. Data |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | ---
    | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  [Jin et al.](#bib.bib44) | CT | 2017 | SV |  |  | 2D | Mix | U-Net | Pos
    | MSE |  | FBP | Img | A | -$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 1000 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Wolterink et al.](#bib.bib85) | CT | 2017 | LD |  |  | 2D |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Thorax &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; cardiac &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| GAN | Pos | Adver | L2 | FBP | Img |  | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$
    -$&#124;$✓ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 500 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Yang et al.](#bib.bib90) | MRI | 2017 | SS |  |  | 2D | Brain |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Condi &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GAN. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Pos |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Adver &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Perc &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | k-space | Img | A+E | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓
    | Clini | 21K | MICCAI2013 |'
  prefs: []
  type: TYPE_TB
- en: '|  [Qin et al.](#bib.bib58) | MRI | 2019 | SS |  | ✓ | 3D+t | Cardiac | RCNN
    | ✓ | MSE |  | k-space | Img |'
  prefs: []
  type: TYPE_TB
- en: '&#124; A+E &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; +R &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$✓ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| NA |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Sun et al.](#bib.bib69) | MRI | 2016 | SS |  |  | 2D |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Brain &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Chest &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Unrolling &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; ADMM &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | NMSE |  | k-space | Img |  | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓
    | Clini | 150 | MICCAI2013 |'
  prefs: []
  type: TYPE_TB
- en: '|  [Schlemper et al.](#bib.bib66) | MRI | 2018 | SS |  | ✓ | 2D | Cardiac |
    CNNs | ✓ | MSE |  | k-space | Img | A+E | ✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$
    -$&#124;$✓ | Sim | 300 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Nehme et al.](#bib.bib53) | SMLM | 2018 |  |  |  | 2D | Sim |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Encoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Decoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE | L1 |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Fluophore &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; emission &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SR &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Img &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$✓ | Sim | 100K | SMLM
    |'
  prefs: []
  type: TYPE_TB
- en: '|  [Schlemper et al.](#bib.bib65) | MRI | 2017 | SS |  |  | 2D | Cardiac |
    CNNs | ✓ | MSE |  | k-space | Img | A | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$
    -$&#124;$✓ | Sim | 300 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Boublil et al.](#bib.bib10) | CT | 2015 | LD |  |  | 2D | Mix | MLP | Pos
    | MSE |  | FBP | img |  | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ - |
    Clini | 100K |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Thaler et al.](#bib.bib75) | CT | 2018 | SV |  |  | 2D | Mix | wGAN | ✓
    | Adver |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; LD &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Sinogram &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Img | R+A | ✓$&#124;$ -$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ - | Clini |
    NA |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Zhou et al.](#bib.bib101) | CT | 2019 | LA |  |  | 3D | Mix | GAN | ✓ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; MSE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Adver. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Cor &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; coef &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; LD &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Sinogram &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; FBP &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Img |  | ✓$&#124;$ -$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$✓ | Clini | 5436
    | LowDoseCT |'
  prefs: []
  type: TYPE_TB
- en: '|  [Yedder et al.](#bib.bib92) | DOT | 2018 | LA |  |  | 2D | Breast |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Decoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE | L2 | Scattering |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$✓ | Phan | 4000 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Wang et al.](#bib.bib82) | MRI | 2016 | SS |  |  | 2D | Brain | Decoder
    | Pos | MSE |  | IFT | Img |  | -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$
    - | Clini | 500 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Sun et al.](#bib.bib70) | MRI | 2019 | SS |  |  | 2D | Brain | Enc-Dec
    | R2T |'
  prefs: []
  type: TYPE_TB
- en: '&#124; MSE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | IFT |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Img &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; seg &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| A+E | ✓$&#124;$✓$&#124;$ -$&#124;$✓$&#124;$ -$&#124;$ - | Clini | 192 | MRBrainS
    |'
  prefs: []
  type: TYPE_TB
- en: '|  [Yedder et al.](#bib.bib93) | DOT | 2019 | LA |  |  | 2D | Breast |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Decoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; MSE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Jacc. &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| L2 | Scattering |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$✓ | Phan | 20K |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Boyd et al.](#bib.bib11) | SMLM | 2018 | SS |  |  | PC | NA | CNN | ✓ |
    MMD |  |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Fluophore &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; emission &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; 3D &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Localiz &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| A | ✓$&#124;$ -$&#124;$ -$&#124;$✓$&#124;$✓$&#124;$ - | Sim | 100K | SMLM
    |'
  prefs: []
  type: TYPE_TB
- en: '|  [Häggström et al.](#bib.bib36) | PET | 2019 | F |  |  | 2D | Sim |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Encoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Decoder &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE |  | Sinogram | Img | A+R | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$
    -$&#124;$✓ | Sim | 291K |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Oksuz et al.](#bib.bib54) | MRI | 2019 | SS |  | ✓ | 2D+t | Cardiac |'
  prefs: []
  type: TYPE_TB
- en: '&#124; 3D CNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; RCNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ |'
  prefs: []
  type: TYPE_TB
- en: '&#124; MSE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CE &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | k-space | Img |  | ✓$&#124;$✓$&#124;$✓$&#124;$ -$&#124;$ -$&#124;$ - |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Sim &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Clini &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 300 | mridata.org |'
  prefs: []
  type: TYPE_TB
- en: '|  [Rajagopal et al.](#bib.bib59) | CT | 2019 | SS |  |  | 3D | Phan |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Unrolling &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Iterative &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE |  | Sinogram | Img |  | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$
    -$&#124;$ - | Phan | 50K |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Huang et al.](#bib.bib40) | CT | 2019 | LA |  |  | 2D | abdomen |'
  prefs: []
  type: TYPE_TB
- en: '&#124; U-Net &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Iterative &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| ✓ | MSE |  | FBP |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Artifact &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Img &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ✓$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ -$&#124;$ - | Clini | 500 |  |'
  prefs: []
  type: TYPE_TB
- en: '|  [Wang et al.](#bib.bib81) | DOT | 2019 | LA |  |  | 2D | Phan | Stacked
    AE | ✓ | MSE |  | Scattering |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Chrom &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Maps &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | -$&#124;$-$&#124;$-$&#124;$✓$&#124;$ -$&#124;$- | Sim | NA |  |'
  prefs: []
  type: TYPE_TB
- en: Acknowledgments We thank the Natural Sciences and Engineering Research Council
    of Canada (NSERC) for partial funding.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Adler and Öktem [2018] J. Adler and O. Öktem. Learned primal-dual reconstruction.
    *IEEE Transactions on Medical Imaging*, 37(6):1322–1332, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Aghasi et al. [2017] A. Aghasi, A. Abdi, N. Nguyen, and J. Romberg. Net-trim:
    Convex pruning of deep neural networks with performance guarantee. In *Advances
    in Neural Information Processing Systems*, pages 3177–3186, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Al-Shakhrah and Al-Obaidi [2003] I. Al-Shakhrah and T. Al-Obaidi. Common artifacts
    in computerized tomography: a review. *Applied Radiology*, 32(8):25–32, 2003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Alford et al. [2018] S. Alford, R. Robinett, L. Milechin, and J. Kepner. Pruned
    and structurally sparse neural networks. *arXiv preprint arXiv:1810.00299*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Antun et al. [2019] V. Antun, F. Renna, C. Poon, B. Adcock, and A. C. Hansen.
    On instabilities of deep learning in image reconstruction-does AI come at a cost?
    *arXiv preprint arXiv:1902.05300*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Assili [2018] S. Assili. A review of tomographic rconstruction techniques for
    computed tomography. *arXiv preprint arXiv:1808.09172*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baikejiang et al. [2017] R. Baikejiang, W. Zhang, and C. Li. Diffuse optical
    tomography for breast cancer imaging guided by computed tomography: A feasibility
    study. *Journal of X-ray Science and Technology*, 25(3):341–355, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bennett and Simon [2013] L. Bennett and W. Simon. 2013 cardiac atlas project
    standard challenge-miccai 2013 grand challenge, 2013. Available at http://masiweb.vuse.vanderbilt.edu/workshop2013/index.php/.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Biobank [2014] U. Biobank. About uk biobank. *Available at https://www.ukbiobank.ac.uk/about-biobank-uk*,
    2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Boublil et al. [2015] D. Boublil, M. Elad, J. Shtok, and M. Zibulevsky. Spatially-adaptive
    reconstruction in computed tomography using neural networks. *IEEE Transactions
    on Medical Imaging*, 34(7):1474–1485, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Boyd et al. [2018] N. Boyd, E. Jonas, H. P. Babcock, and B. Recht. Deeploco:
    Fast 3D localization microscopy using neural networks. *BioRxiv*, page 267096,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cai et al. [2018] C. Cai, K. Deng, C. Ma, and J. Luo. End-to-end deep neural
    network for optical inversion in quantitative photoacoustic imaging. *Optics Letters*,
    43(12):2752–2755, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cardoen et al. [2019] B. Cardoen, H. B. Yedder, A. Sharma, K. C. Chou, I. R.
    Nabi, and G. Hamarneh. ERGO: Efficient recurrent graph optimized emitter density
    estimation in single molecule localization microscopy. *IEEE Transactions on Medical
    Imaging*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chambolle and Pock [2011] A. Chambolle and T. Pock. A first-order primal-dual
    algorithm for convex problems with applications to imaging. *Journal of Mathematical
    Imaging and Vision*, 40(1):120–145, 2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2017a] H. Chen, Y. Zhang, M. K. Kalra, F. Lin, Y. Chen, P. Liao,
    J. Zhou, and G. Wang. Low-dose CT with a residual encoder-decoder convolutional
    neural network. *IEEE Transactions on Medical Imaging*, 36(12):2524–2535, 2017a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2017b] H. Chen, Y. Zhang, W. Zhang, P. Liao, K. Li, J. Zhou, and
    G. Wang. Low-dose CT via convolutional neural network. *Biomedical Optics Express*,
    8(2):679–694, 2017b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chen et al. [2012] Y. Chen, Z. Yang, Y. Hu, G. Yang, Y. Zhu, Y. Li, W. Chen,
    C. Toumoulin, et al. Thoracic low-dose CT image processing using an artifact suppressed
    large-scale nonlocal means. *Physics in Medicine & Biology*, 57(9):2667, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. [2018] J. Y. Cheng, F. Chen, M. T. Alley, J. M. Pauly, and S. S.
    Vasanawala. Highly scalable image reconstruction using deep neural networks with
    bandpass filtering. *arXiv preprint arXiv:1805.03300*, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cui et al. [2019] J. Cui, K. Gong, N. Guo, K. Kim, H. Liu, and Q. Li. CT-guided
    PET parametric image reconstruction using deep neural network without prior training
    data. In *Medical Imaging 2019: Physics of Medical Imaging*, volume 10948, page
    109480Z. International Society for Optics and Photonics, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dabov et al. [2007] K. Dabov, A. Foi, V. Katkovnik, and K. Egiazarian. Image
    denoising by sparse 3-D transform-domain collaborative filtering. *IEEE Transactions
    on Image Processing*, 16(8):2080–2095, 2007.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Despres and Jia [2017] P. Despres and X. Jia. A review of GPU-based medical
    image reconstruction. *Physica Medica*, 42:76–92, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dong and Shen [2015] B. Dong and Z. Shen. Image restoration: a data-driven
    perspective. In *Proceedings of the International Congress of Industrial and Applied
    Mathematics (ICIAM)*, pages 65–108\. Citeseer, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. [2016] Q. Fan, T. Witzel, A. Nummenmaa, K. R. Van Dijk, J. D. Van Horn,
    M. K. Drews, L. H. Somerville, M. A. Sheridan, R. M. Santillana, J. Snyder, et al.
    MGH–USC human connectome project datasets with ultra-high b-value diffusion MRI.
    *Neuroimage*, 124:1108–1114, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Feng et al. [2018] J. Feng, Q. Sun, Z. Li, Z. Sun, and K. Jia. Back-propagation
    neural network-based reconstruction algorithm for diffuse optical tomography.
    *Journal of Biomedical Optics*, 24(5):051407, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fessler [2017] J. A. Fessler. Medical image reconstruction: a brief overview
    of past milestones and future directions. *arXiv preprint arXiv:1707.05927*, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gao et al. [2011] H. Gao, H. Yu, S. Osher, and G. Wang. Multi-energy CT based
    on a prior rank, intensity and sparsity model (prism). *Inverse problems*, 27(11):115012,
    2011.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gates and Ahn [2017] A. J. Gates and Y.-Y. Ahn. The impact of random models
    on clustering similarity. *The Journal of Machine Learning Research*, 18(1):3049–3076,
    2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geffrin et al. [2005] J.-M. Geffrin, P. Sabouroux, and C. Eyraud. Free space
    experimental scattering database continuation: experimental set-up and measurement
    precision. *Inverse Problems*, 21(6):S117, 2005.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Georgeson and Safai [2017] G. Georgeson and M. Safai. Portable X-ray backscattering
    imaging system including a radioactive source, May 23 2017. US Patent 9,658,173.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Geyer et al. [2017] R. C. Geyer, T. Klein, and M. Nabi. Differentially private
    federated learning: A client level perspective. *arXiv preprint arXiv:1712.07557*,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gilad-Bachrach et al. [2016] R. Gilad-Bachrach, N. Dowlin, K. Laine, K. Lauter,
    M. Naehrig, and J. Wernsing. Cryptonets: Applying neural networks to encrypted
    data with high throughput and accuracy. In *International Conference on Machine
    Learning*, pages 201–210, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. [2014] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
    S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In *Advances
    in neural information processing systems*, pages 2672–2680, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gottschling et al. [2020] N. M. Gottschling, V. Antun, B. Adcock, and A. C.
    Hansen. The troublesome kernel: why deep learning for inverse problems is typically
    unstable. *arXiv preprint arXiv:2001.01258*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Gupta et al. [2018] H. Gupta, K. H. Jin, H. Q. Nguyen, M. T. McCann, and M. Unser.
    CNN-based projected gradient descent for consistent ct image reconstruction. *IEEE
    Transactions on Medical Imaging*, 37(6):1440–1453, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Häggström et al. [2016] I. Häggström, B. J. Beattie, and C. R. Schmidtlein.
    Dynamic PET simulator via tomographic emission projection for kinetic modeling
    and parametric image studies. *Medical Physics*, 43(6Part1):3104–3116, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Häggström et al. [2019] I. Häggström, C. R. Schmidtlein, G. Campanella, and
    T. J. Fuchs. Deeppet: A deep encoder–decoder network for directly solving the
    PET image reconstruction inverse problem. *Medical Image Analysis*, 54:253–262,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Harrison [2010] R. L. Harrison. Monte carlo simulation of emission tomography
    and other medical imaging techniques. In *AIP conference proceedings*, volume
    1204, pages 126–132. AIP, 2010.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Holden and Sage [2016] S. Holden and D. Sage. Imaging: super-resolution fight
    club. *Nature Photonics*, 10(3):152, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Huang et al. [2019a] Q. Huang, D. Yang, J. Yi, L. Axel, and D. Metaxas. FR-Net:
    Joint reconstruction and segmentation in compressed sensing cardiac MRI. In *International
    Conference on Functional Imaging and Modeling of the Heart*, pages 352–360\. Springer,
    2019a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang et al. [2019b] Y. Huang, A. Preuhs, G. Lauritsch, M. Manhart, X. Huang,
    and A. Maier. Data consistent artifact reduction for limited angle tomography
    with deep learning prior. In *International Workshop on Machine Learning for Medical
    Image Reconstruction*, pages 101–112\. Springer, 2019b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huang and Wang [2018] Z. Huang and N. Wang. Data-driven sparse structure selection
    for deep neural networks. In *Proceedings of the European Conference on Computer
    Vision (ECCV)*, pages 304–320, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hyun et al. [2018] C. M. Hyun, H. P. Kim, S. M. Lee, S. Lee, and J. K. Seo.
    Deep learning for undersampled MRI reconstruction. *Physics in Medicine & Biology*,
    63(13):135007, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jhamb et al. [2015] T. K. Jhamb, V. Rejathalal, and V. Govindan. A review on
    image reconstruction through MRI k-space data. *International Journal of Image,
    Graphics and Signal Processing*, 7(7):42, 2015.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jin et al. [2017] K. H. Jin, M. T. McCann, E. Froustey, and M. Unser. Deep convolutional
    neural network for inverse problems in imaging. *IEEE Transactions on Image Processing*,
    26(9):4509–4522, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jin et al. [2019] K. H. Jin, M. Unser, and K. M. Yi. Self-supervised deep active
    accelerated MRI. *arXiv preprint arXiv:1901.04547*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lebed et al. [2013] E. Lebed, S. Lee, M. V. Sarunic, and M. F. Beg. Rapid radial
    optical coherence tomography image acquisition. *Journal of Biomedical Optics*,
    18(3):036004, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liang et al. [2018] K. Liang, H. Yang, K. Kang, and Y. Xing. Improve angular
    resolution for sparse-view CT with residual convolutional neural network. In *Medical
    Imaging 2018: Physics of Medical Imaging*, volume 10573, page 105731K. International
    Society for Optics and Photonics, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Lung Cancer Alliance [2017] Lung Cancer Alliance. Give a scan, Fact Sheet N^o282,
    2017. [http://www.giveascan.org](http://www.giveascan.org), Last accessed on 2020-2-20.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McCann and Unser [2019] M. T. McCann and M. Unser. Algorithms for biomedical
    image reconstruction. *arXiv preprint arXiv:1901.03565*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Mendrik et al. [2015] A. M. Mendrik, K. L. Vincken, H. J. Kuijf, M. Breeuwer,
    W. H. Bouvy, J. De Bresser, A. Alansary, M. De Bruijne, A. Carass, A. El-Baz,
    et al. MRbrains challenge: online evaluation framework for brain image segmentation
    in 3T MRI scans. *Computational Intelligence and Neuroscience*, 2015:1, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Moslemi et al. [2020] V. Moslemi, V. Erfanian, and M. Ashoor. Estimation of
    optimized timely system matrix with improved image quality in iterative reconstruction
    algorithm: A simulation study. *Heliyon*, 6(1):e03279, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Mridata. mridata.org. [http://mridata.org](http://mridata.org), Last accessed
    on 2019-11-30.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nehme et al. [2018] E. Nehme, L. E. Weiss, T. Michaeli, and Y. Shechtman. Deep-storm:
    super-resolution single-molecule microscopy by deep learning. *Optica*, 5(4):458–464,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oksuz et al. [2019] I. Oksuz, J. Clough, B. Ruijsink, E. Puyol-Antón, A. Bustin,
    G. Cruz, C. Prieto, D. Rueckert, A. P. King, and J. A. Schnabel. Detection and
    correction of cardiac MRI motion artefacts during reconstruction from k-space.
    In *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*, pages 695–703\. Springer, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ouyang et al. [2019] J. Ouyang, K. T. Chen, E. Gong, J. Pauly, and G. Zaharchuk.
    Ultra-low-dose PET reconstruction using generative adversarial network with feature
    matching and task-specific perceptual loss. *Medical Physics*, 46(8):3555–3564,
    2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Paul et al. [2013] G. Paul, J. Cardinale, and I. F. Sbalzarini. Coupling image
    restoration and segmentation: a generalized linear model/bregman perspective.
    *International Journal of Computer Vision*, 104(1):69–93, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pelt and Batenburg [2013] D. M. Pelt and K. J. Batenburg. Fast tomographic reconstruction
    from limited data using artificial neural networks. *IEEE Transactions on Image
    Processing*, 22(12):5238–5251, 2013.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Qin et al. [2018] C. Qin, J. Schlemper, J. Caballero, A. N. Price, J. V. Hajnal,
    and D. Rueckert. Convolutional recurrent neural networks for dynamic MR image
    reconstruction. *IEEE Transactions on Medical Imaging*, 38(1):280–290, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rajagopal et al. [2019] A. Rajagopal, N. Stier, J. Dey, M. A. King, and S. Chandrasekaran.
    Towards deep iterative-reconstruction algorithms for computed tomography (CT)
    applications. In *Medical Imaging 2019: Physics of Medical Imaging*, volume 10948,
    page 1094856\. International Society for Optics and Photonics, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ravishankar et al. [2019] S. Ravishankar, J. C. Ye, and J. A. Fessler. Image
    reconstruction: From sparsity to data-adaptive methods and machine learning. *arXiv
    preprint arXiv:1904.02816*, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rivest et al. [1978] R. L. Rivest, L. Adleman, M. L. Dertouzos, et al. On data
    banks and privacy homomorphisms. *Foundations of Secure Computation*, 4(11):169–180,
    1978.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rodríguez [2013] P. Rodríguez. Total variation regularization algorithms for
    images corrupted with different noise models: a review. *Journal of Electrical
    and Computer Engineering*, 2013:10, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rykkje et al. [2019] A. Rykkje, J. F. Carlsen, and M. B. Nielsen. Hand-held
    ultrasound devices compared with high-end ultrasound systems: A systematic review.
    *Diagnostics*, 9(2):61, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sbalzarini [2016] I. F. Sbalzarini. Seeing is believing: Quantifying is convincing:
    Computational image analysis in biology. In *Focus on Bio-Image Informatics*,
    pages 1–39\. Springer, 2016.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schlemper et al. [2017a] J. Schlemper, J. Caballero, J. V. Hajnal, A. Price,
    and D. Rueckert. A deep cascade of convolutional neural networks for MR image
    reconstruction. In *International Conference on Information Processing in Medical
    Imaging*, pages 647–658\. Springer, 2017a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schlemper et al. [2017b] J. Schlemper, J. Caballero, J. V. Hajnal, A. N. Price,
    and D. Rueckert. A deep cascade of convolutional neural networks for dynamic MR
    image reconstruction. *IEEE Transactions on Medical Imaging*, 37(2):491–503, 2017b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Schweiger and Arridge [2014] M. Schweiger and S. R. Arridge. The toast++ software
    suite for forward and inverse modeling in optical tomography. *Journal of Biomedical
    Optics*, 19(4):040801, 2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shokoufi and Golnaraghi [2016] M. Shokoufi and F. Golnaraghi. Development of
    a handheld diffuse optical breast cancer assessment probe. *Journal of Innovative
    Optical Health Sciences*, 9(02):1650007, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2016] J. Sun, H. Li, Z. Xu, et al. Deep ADMM-Net for compressive
    sensing MRI. In *Advances in neural information processing systems*, pages 10–18,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2019a] L. Sun, Z. Fan, X. Ding, Y. Huang, and J. Paisley. Joint
    CS-MRI reconstruction and segmentation with a unified deep network. In *International
    Conference on Information Processing in Medical Imaging*, pages 492–504\. Springer,
    2019a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2019b] X. Sun, J. Choi, C.-Y. Chen, N. Wang, S. Venkataramani, V. V.
    Srinivasan, X. Cui, W. Zhang, and K. Gopalakrishnan. Hybrid 8-bit floating point
    (HFP8) training and inference for deep neural networks. In *Advances in Neural
    Information Processing Systems*, pages 4901–4910, 2019b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2018] Y. Sun, Z. Xia, and U. S. Kamilov. Efficient and accurate
    inversion of multiple scattering with deep learning. *Optics Express*, 26(11):14678–14688,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. [2019c] Y. Sun, B. Wohlberg, and U. S. Kamilov. An online plug-and-play
    algorithm for regularized image reconstruction. *IEEE Transactions on Computational
    Imaging*, 5(3):395–408, 2019c.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: t [2014] M. C. D. t. Low dose CT grand challenge. *Available at https://www.aapm.org/GrandChallenge/LowDoseC/*,
    2014.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Thaler et al. [2018] F. Thaler, K. Hammernik, C. Payer, M. Urschler, and D. Štern.
    Sparse-view CT reconstruction using wasserstein GANs. In *International Workshop
    on Machine Learning for Medical Image Reconstruction*, pages 75–82\. Springer,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vandenberghe et al. [2001] S. Vandenberghe, Y. D’Asseler, R. Van de Walle, T. Kauppinen,
    M. Koole, L. Bouwens, K. Van Laere, I. Lemahieu, and R. Dierckx. Iterative reconstruction
    algorithms in nuclear medicine. *Computerized Medical Imaging and Graphics*, 25(2):105–111,
    2001.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Waibel et al. [2018] D. Waibel, J. Gröhl, F. Isensee, T. Kirchner, K. Maier-Hein,
    and L. Maier-Hein. Reconstruction of initial pressure from limited view photoacoustic
    images using deep learning. In *Photons Plus Ultrasound: Imaging and Sensing 2018*,
    volume 10494, page 104942S. International Society for Optics and Photonics, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang [2016] G. Wang. A perspective on deep imaging. *IEEE Access*, 4:8914–8924,
    2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. [2015] G. Wang, M. Kalra, V. Murugan, Y. Xi, L. Gjesteby, M. Getzin,
    Q. Yang, W. Cong, and M. Vannier. Vision 20/20: Simultaneous CT-MRI—Next chapter
    of multimodality imaging. *Medical Physics*, 42(10):5879–5889, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2018] G. Wang, J. C. Ye, K. Mueller, and J. A. Fessler. Image reconstruction
    is a new frontier of machine learning. *IEEE Transactions on Medical Imaging*,
    37(6):1289–1296, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2019] H. Wang, N. Wu, Y. Cai, L. Ren, Z. Zhao, G. Han, and J. Wang.
    Optimization of reconstruction accuracy of anomaly position based on stacked auto-encoder
    neural networks. *IEEE Access*, 7:116578–116584, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2016] S. Wang, Z. Su, L. Ying, X. Peng, S. Zhu, F. Liang, D. Feng,
    and D. Liang. Accelerating magnetic resonance imaging via deep learning. In *2016
    IEEE 13th International Symposium on Biomedical Imaging (ISBI)*, pages 514–517\.
    IEEE, 2016.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. [2003] Z. Wang, E. P. Simoncelli, and A. C. Bovik. Multiscale structural
    similarity for image quality assessment. In *The Thrity-Seventh Asilomar Conference
    on Signals, Systems & Computers, 2003*, volume 2, pages 1398–1402\. Ieee, 2003.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Webb and Kagadis [2003] A. Webb and G. C. Kagadis. Introduction to biomedical
    imaging. *Medical Physics*, 30(8):2267–2267, 2003.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wolterink et al. [2017] J. M. Wolterink, T. Leiner, M. A. Viergever, and I. Išgum.
    Generative adversarial networks for noise reduction in low-dose CT. *IEEE Transactions
    on Medical Imaging*, 36(12):2536–2545, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. [2018] S. Wu, Z. Gao, Z. Liu, J. Luo, H. Zhang, and S. Li. Direct
    reconstruction of ultrasound elastography using an end-to-end deep neural network.
    In *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*, pages 374–382\. Springer, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Würfl et al. [2018] T. Würfl, M. Hoffmann, V. Christlein, K. Breininger, Y. Huang,
    M. Unberath, and A. K. Maier. Deep learning computed tomography: Learning projection-domain
    weights from image domain in limited angle problems. *IEEE Transactions on Medical
    Imaging*, 37(6):1454–1463, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. [2017] J. Xu, E. Gong, J. Pauly, and G. Zaharchuk. 200x low-dose PET
    reconstruction using deep learning. *arXiv preprint arXiv:1712.04119*, 2017.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Xu et al. [2012] Q. Xu, H. Yu, X. Mou, L. Zhang, J. Hsieh, and G. Wang. Low-dose
    X-ray CT reconstruction via dictionary learning. *IEEE Transactions on Medical
    Imaging*, 31(9):1682–1697, 2012.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2017a] G. Yang, S. Yu, H. Dong, G. Slabaugh, P. L. Dragotti, X. Ye,
    F. Liu, S. Arridge, J. Keegan, Y. Guo, et al. DAGAN: deep de-aliasing generative
    adversarial networks for fast compressed sensing MRI reconstruction. *IEEE Transactions
    on Medical Imaging*, 37(6):1310–1321, 2017a.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. [2017b] Y. Yang, J. Sun, H. Li, and Z. Xu. ADMM-Net: A deep learning
    approach for compressive sensing MRI. *CoRR*, abs/1705.06869, 2017b. URL [http://arxiv.org/abs/1705.06869](http://arxiv.org/abs/1705.06869).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yedder et al. [2018] H. B. Yedder, A. BenTaieb, M. Shokoufi, A. Zahiremami,
    F. Golnaraghi, and G. Hamarneh. Deep learning based image reconstruction for diffuse
    optical tomography. In *International Workshop on Machine Learning for Medical
    Image Reconstruction*, pages 112–119\. Springer, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yedder et al. [2019] H. B. Yedder, M. Shokoufi, B. Cardoen, F. Golnaraghi, and
    G. Hamarneh. Limited-angle diffuse optical tomography image reconstruction using
    deep learning. In *International Conference on Medical Image Computing and Computer-Assisted
    Intervention*, pages 66–74\. Springer, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoo et al. [2019] J. Yoo, S. Sabir, D. Heo, K. H. Kim, A. Wahab, Y. Choi, S.-I.
    Lee, E. Y. Chae, H. H. Kim, Y. M. Bae, et al. Deep learning diffuse optical tomography.
    *IEEE Transactions on Medical Imaging*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yoon et al. [2018] Y. H. Yoon, S. Khan, J. Huh, and J. C. Ye. Efficient b-mode
    ultrasound image reconstruction from sub-sampled RF data using deep learning.
    *IEEE Transactions on Medical Imaging*, 38(2):325–336, 2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zbontar et al. [2018] J. Zbontar, F. Knoll, A. Sriram, M. J. Muckley, M. Bruno,
    A. Defazio, M. Parente, K. J. Geras, J. Katsnelson, H. Chandarana, et al. FastMRI:
    An open dataset and benchmarks for accelerated MRI. *arXiv preprint arXiv:1811.08839*,
    2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang and Dong [2019] H. Zhang and B. Dong. A review on deep learning in medical
    image reconstruction. *arXiv preprint arXiv:1906.10643*, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. [2017] H. Zhang, D. Zeng, H. Zhang, J. Wang, Z. Liang, and J. Ma.
    Applications of nonlocal means algorithm in low-dose X-ray CT image processing
    and reconstruction: A review. *Medical physics*, 44(3):1168–1185, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2016a] Y. Zhang, Y. Wang, W. Zhang, F. Lin, Y. Pu, and J. Zhou.
    Statistical iterative reconstruction using adaptive fractional order regularization.
    *Biomedical Optics Express*, 7(3):1015–1029, 2016a.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang et al. [2016b] Y. Zhang, Y. Xi, Q. Yang, W. Cong, J. Zhou, and G. Wang.
    Spectral CT reconstruction with image sparsity and spectral mean. *IEEE Transactions
    on Computational Imaging*, 2(4):510–523, 2016b.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhou et al. [2019] B. Zhou, X. Lin, and B. Eck. Limited angle tomography reconstruction:
    Synthetic reconstruction via unsupervised sinogram adaptation. In *International
    Conference on Information Processing in Medical Imaging*, pages 141–152\. Springer,
    2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2018] B. Zhu, J. Z. Liu, S. F. Cauley, B. R. Rosen, and M. S. Rosen.
    Image reconstruction by domain-transform manifold learning. *Nature*, 555(7697):487,
    2018.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. [2019] L. Zhu, Z. Liu, and S. Han. Deep leakage from gradients. In
    *Advances in Neural Information Processing Systems*, pages 14747–14756, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
