- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:45:46'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:45:46
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2206.05394] Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2206.05394] 深度学习在鱼类栖息地监测中的应用：教程与调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2206.05394](https://ar5iv.labs.arxiv.org/html/2206.05394)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2206.05394](https://ar5iv.labs.arxiv.org/html/2206.05394)
- en: 'Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在鱼类栖息地监测中的应用：教程与调查
- en: Alzayat Saleh alzayat.saleh@my.jcu.edu.au    Marcus Sheaves marcus.sheaves@jcu.edu.au
       Dean Jerry dean.jerry@jcu.edu.au    Mostafa Rahimi Azghadi mostafa.rahimiazghadi@jcu.edu.au
    College of Science and Engineering, James Cook University, 1 James Cook Drive,
    Townsville, 4811, QLD, Australia ARC Research Hub for Supercharging Tropical Aquaculture
    through Genetic Solutions, James Cook University, 1 James Cook Drive, Townsville,
    4811, QLD, Australia
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Alzayat Saleh alzayat.saleh@my.jcu.edu.au    Marcus Sheaves marcus.sheaves@jcu.edu.au
       Dean Jerry dean.jerry@jcu.edu.au    Mostafa Rahimi Azghadi mostafa.rahimiazghadi@jcu.edu.au
    詹姆斯·库克大学科学与工程学院，詹姆斯·库克大道1号，汤斯维尔，4811，昆士兰州，澳大利亚 ARC热带水产养殖基因解决方案研究中心，詹姆斯·库克大学，詹姆斯·库克大道1号，汤斯维尔，4811，昆士兰州，澳大利亚
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Marine ecosystems and their fish habitats are becoming increasingly important
    due to their integral role in providing a valuable food source and conservation
    outcomes. Due to their remote and difficult to access nature, marine environments
    and fish habitats are often monitored using underwater cameras to record videos
    and images for understanding fish life and ecology, as well as for preserving
    the environment. There are currently many permanent underwater camera systems
    deployed at different places around the globe. In addition, there exists numerous
    studies that use temporary cameras to survey fish habitats. These cameras generate
    a massive volume of digital data, which cannot be efficiently analysed by current
    manual processing methods, which involve a human observer. Deep Learning (DL)
    is a cutting-edge Artificial Intelligence (AI) technology that has demonstrated
    unprecedented performance in analysing visual data. Despite its application to
    a myriad of domains, its use in underwater fish habitat monitoring remains under
    explored. In this paper, we provide a tutorial that covers the key concepts of
    DL, which help the reader grasp a high-level understanding of how DL works. The
    tutorial also explains a step-by-step procedure on how DL algorithms should be
    developed for challenging applications such as underwater fish monitoring. In
    addition, we provide a comprehensive survey of key deep learning techniques for
    fish habitat monitoring including classification, counting, localization, and
    segmentation. Furthermore, we survey publicly available underwater fish datasets,
    and compare various DL techniques in the underwater fish monitoring domains. We
    also discuss some challenges and opportunities in the emerging field of deep learning
    for fish habitat processing. This paper is written to serve as a tutorial for
    marine scientists who would like to grasp a high-level understanding of DL, develop
    it for their applications by following our step-by-step tutorial, and see how
    it is evolving to facilitate their research efforts. At the same time, it is suitable
    for computer scientists who would like to survey state-of-the-art DL-based methodologies
    for fish habitat monitoring.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 海洋生态系统及其鱼类栖息地由于在提供宝贵的食物来源和保护成果方面发挥的重要作用，变得越来越重要。由于其偏远且难以接近的特点，海洋环境和鱼类栖息地通常通过水下摄像机进行监测，以记录视频和图像，帮助理解鱼类生活和生态，以及保护环境。目前，全球各地已部署了许多永久性水下摄像系统。此外，还存在许多使用临时摄像机调查鱼类栖息地的研究。这些摄像机产生了大量的数字数据，而当前的人工处理方法（需要人工观察者）无法高效地分析这些数据。深度学习（DL）是一种前沿的人工智能（AI）技术，在分析视觉数据方面表现出前所未有的性能。尽管它已应用于许多领域，但在水下鱼类栖息地监测中的应用仍未得到充分探索。在本文中，我们提供了一个涵盖深度学习关键概念的教程，帮助读者高层次地理解深度学习的工作原理。教程还解释了如何为具有挑战性的应用（如水下鱼类监测）开发深度学习算法的逐步过程。此外，我们提供了一个关于鱼类栖息地监测的关键深度学习技术的全面调查，包括分类、计数、定位和分割。此外，我们调查了公开可用的水下鱼类数据集，并比较了水下鱼类监测领域的各种深度学习技术。我们还讨论了深度学习在鱼类栖息地处理新兴领域中的一些挑战和机会。本文旨在为希望高层次理解深度学习的海洋科学家提供教程，帮助他们通过遵循我们的逐步教程开发深度学习应用，并了解它如何演变以促进他们的研究工作。同时，它也适合希望调查鱼类栖息地监测最先进的基于深度学习的方法的计算机科学家。
- en: 'keywords:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '关键词:'
- en: Marine Science\sepComputer Vision\sepConvolutional Neural Networks\sepImage
    and Video Processing\sepMachine Learning\sepDeep Learning\sepDeep Neural Networks.\UseRawInputEncoding\cortext
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 海洋科学\sep计算机视觉\sep卷积神经网络\sep图像和视频处理\sep机器学习\sep深度学习\sep深度神经网络。\UseRawInputEncoding\cortext
- en: '[cor1]Corresponding author.'
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: '[cor1]通讯作者。'
- en: 1 Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: Proper understanding of our planet and its ecosystems is not possible unless
    suitable tools are developed to explore and learn about our largest ecosystem,
    the marine environment. Computer Vision (CV) technology through deployment of
    its underwater cameras can help us better comprehend and manage remote marine
    fish habitats. However, due to the sheer volume of their visual data, manual processing
    is time- and cost-prohibitive, requiring a new radical shift in data analysis,
    through advanced technologies such as Deep Learning (DL).
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 只有开发出合适的工具来探索和了解我们最大的生态系统——海洋环境，才能正确理解我们的星球及其生态系统。通过部署水下摄像机的计算机视觉（CV）技术可以帮助我们更好地理解和管理遥远的海洋鱼类栖息地。然而，由于其视觉数据的庞大体量，手动处理在时间和成本上都不可行，这需要通过先进技术如深度学习（DL）进行数据分析的根本转变。
- en: DL is at the frontier of computer vision. Its deep neural network architectures
    are capable of learning complex mappings from high-dimensional data to interpretable
    feature representations, hence, DL has been successfully applied to various challenging
    computer vision tasks such as semantic image segmentation (Jing et al., [2020](#bib.bib46);
    Pathak et al., [2015](#bib.bib96); Laradji et al., [2021a](#bib.bib66); [Qi et al.,](#bib.bib98)
    ; Chuang et al., [2011](#bib.bib18)), visual object detection (Wang et al., [2018](#bib.bib126);
    Villon et al., [2016](#bib.bib123); Kim et al., [2016](#bib.bib53); Pathak et al.,
    [2018](#bib.bib95)), and tracking (Garcia et al., [2016](#bib.bib28); Duan and
    Deng, [2019](#bib.bib25); Kang et al., [2018](#bib.bib49); Lumauag and Nava, [2019](#bib.bib81)).
    These applications have the potential to radically alter the way we interact with
    the world through computers. Recently, the applications of DL and its underlying
    Deep Neural Networks for underwater visual processing have received significant
    attention (Saleh et al., [2020a](#bib.bib108); Laradji et al., [2021b](#bib.bib68);
    Villon et al., [2018](#bib.bib124); Chuang et al., [2016](#bib.bib17); Nilssen
    et al., [2017](#bib.bib91); Mandal et al., [2018](#bib.bib84); Naseer et al.,
    [2020](#bib.bib89); Salman et al., [2020](#bib.bib113); Siddiqui et al., [2018](#bib.bib118)).
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）处于计算机视觉的前沿。其深度神经网络架构能够从高维数据中学习复杂的映射到可解释的特征表示，因此，深度学习已经成功应用于各种具有挑战性的计算机视觉任务，如语义图像分割（Jing
    等，[2020](#bib.bib46)；Pathak 等，[2015](#bib.bib96)；Laradji 等，[2021a](#bib.bib66)；[Qi
    等，](#bib.bib98)；Chuang 等，[2011](#bib.bib18)），视觉对象检测（Wang 等，[2018](#bib.bib126)；Villon
    等，[2016](#bib.bib123)；Kim 等，[2016](#bib.bib53)；Pathak 等，[2018](#bib.bib95)），以及跟踪（Garcia
    等，[2016](#bib.bib28)；Duan 和 Deng，[2019](#bib.bib25)；Kang 等，[2018](#bib.bib49)；Lumauag
    和 Nava，[2019](#bib.bib81)）。这些应用有潜力从根本上改变我们通过计算机与世界的互动方式。最近，深度学习及其基础的深度神经网络在水下视觉处理中的应用受到了极大关注（Saleh
    等，[2020a](#bib.bib108)；Laradji 等，[2021b](#bib.bib68)；Villon 等，[2018](#bib.bib124)；Chuang
    等，[2016](#bib.bib17)；Nilssen 等，[2017](#bib.bib91)；Mandal 等，[2018](#bib.bib84)；Naseer
    等，[2020](#bib.bib89)；Salman 等，[2020](#bib.bib113)；Siddiqui 等，[2018](#bib.bib118)）。
- en: The main advantage of deep learning is its ability to learn features in different
    data types, such as underwater fish images, through end-to-end training. Training
    of DNNs is often thought to be easy. Many frameworks take delight in providing
    few lines of code that solve some CV tasks, providing the misleading impression
    that all that is needed is then plug and play, using some general Application
    Programming Interfaces (APIs). In these APIs, the developers have lifted the burden
    from us and, in doing so, disguised the complexity behind a few lines of code
    needed to achieve the task at hand. The framework developers have achieved the
    purpose of "providing a few lines of code" but we, the end-users, have been fooled
    to believe we need to spend only a few hours learning the intricacies of the provided
    APIs.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习的主要优势在于其通过端到端训练学习不同数据类型的特征，例如水下鱼类图像。训练深度神经网络（DNNs）通常被认为是简单的。许多框架喜欢提供几行代码来解决一些计算机视觉任务，给人一种误导性的印象，以为只需插入并使用某些通用的应用程序编程接口（APIs）。在这些API中，开发者将负担从我们身上移除了，从而掩盖了完成任务所需的几行代码背后的复杂性。框架开发者实现了“提供几行代码”的目的，但我们这些最终用户被误导认为只需要花费几个小时学习所提供API的复杂性。
- en: However, when it comes to training a DL algorithm, things become more complicated.
    The task of training a DNN is actually as complicated as the problem it is intended
    to solve. In fish monitoring for example, the number of input images you use,
    how you pre-process your images, how you build your models, how you fine-tune
    the model (using dropout or regularization, for example), how you extract the
    features, how you combine them to produce final predictions, what metric you use
    to report your model performance, and your choice of which layer to extract features
    from to feed to your classifier, are among some of the many variables to consider
    when training a DNN. You can include any number of variations on these factors
    to further optimize your model and to achieve the best possible accuracy.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，训练深度学习算法时，情况变得更加复杂。训练DNN的任务实际上与其旨在解决的问题一样复杂。例如，在鱼类监测中，你使用的输入图像数量、图像的预处理方法、模型的构建方式、如何对模型进行微调（例如使用dropout或正则化）、特征的提取方式、如何将它们组合以生成最终预测、报告模型性能时使用的度量指标、以及选择从哪个层提取特征以供分类器使用，都是训练DNN时需要考虑的众多变量之一。你可以在这些因素上进行各种变动，以进一步优化你的模型并达到最佳的准确性。
- en: Due to the above intricacies, most of the time DNNs are not simply an "off-the-shelf"
    technology that works with all kind of datasets, even those similar to the one
    that has been meticulously customised for it. The fact that training a customised
    high-performance DNN is rigorous and challenging is now widely accepted. However,
    this challenging process can be facilitated by being patient, paying attention
    to details, and working systematically. Developing customised DNNs with a specific
    application, for example, for underwater fish monitoring, should follow the same
    systematic steps of developing any other computer vision applications ( e.g. detection
    of vehicles in traffic). The only difference lies in the type of data being fed
    to the DNN.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 由于上述复杂性，大多数情况下，深度神经网络（DNN）并非一种能够与所有类型数据集兼容的“现成”技术，即使是那些类似于为其精心定制的数据集。训练一个定制的高性能DNN的过程是严谨而具有挑战性的，这一点现在已被广泛接受。然而，通过保持耐心、注意细节以及系统性地工作，这一挑战性过程可以得到一定的缓解。例如，开发用于水下鱼类监测的定制DNN，应遵循与开发任何其他计算机视觉应用（例如交通中车辆检测）相同的系统步骤。唯一的区别在于馈送给DNN的数据类型。
- en: In this paper, we first present a tutorial that covers the background of DL
    to help understand the above-mentioned common DL terminologies. The tutorial also
    provides a comprehensive overview of the essential systematic steps to help better
    develop a supervised DL model, with a focus on underwater fish habitat monitoring.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 在这篇论文中，我们首先提供了一个教程，涵盖了深度学习的背景，以帮助理解上述常见的深度学习术语。该教程还提供了关于开发监督式深度学习模型的基本系统步骤的全面概述，重点关注水下鱼类栖息地监测。
- en: In the second part of the paper, we survey state-of-the-art research and development
    on the use of DL for fish monitoring. We synthesize the literature into four main
    categories covering the common CV tasks of classification, counting, localization,
    and segmentation of fish images. We investigate different deep learning architectures
    and their performance. We also survey publicly available underwater fish image
    datasets. Finally, we provide a comprehensive overview of the challenges in applying
    DL to marine fish monitoring domains. We also draw a roadmap for future research
    works.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 在论文的第二部分，我们对使用深度学习（DL）进行鱼类监测的最新研究和发展进行了综述。我们将文献汇总成四个主要类别，涵盖了鱼类图像的分类、计数、定位和分割等常见计算机视觉任务。我们探讨了不同的深度学习架构及其性能。我们还调查了公开可用的水下鱼类图像数据集。最后，我们提供了将深度学习应用于海洋鱼类监测领域的挑战的全面概述，并为未来的研究工作绘制了一条路线图。
- en: Although a number of previous relevant review articles (Goodwin et al., [2022](#bib.bib32);
    Li and Du, [2021](#bib.bib73); Zhao et al., [2021](#bib.bib138); Yang et al.,
    [2021](#bib.bib135); Li et al., [2020](#bib.bib76); Moniruzzaman et al., [2017](#bib.bib88);
    Saleh et al., [2022](#bib.bib111)) exist, our paper has a different approach and
    motivation that compliments prior surveys. Compared to (Goodwin et al., [2022](#bib.bib32)),
    which provides a survey of the general domain of ecological data analysis, covering
    a wide array of studies on plankton, fish, marine mammals, pollution, and nutrient
    cycling, we focus only on fish monitoring. We also provide a detailed analysis
    of fish datasets and comprehensively review the literature on four key tasks in
    underwater fish video and image processing. This detailed analysis and review
    is not provided in (Goodwin et al., [2022](#bib.bib32)), or any of the previous
    works, making our paper useful for readers who would like to study fish monitoring
    using DL in more details and depth, while seeing a comprehensive literature review.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管存在大量相关的综述文章（Goodwin et al., [2022](#bib.bib32); Li and Du, [2021](#bib.bib73);
    Zhao et al., [2021](#bib.bib138); Yang et al., [2021](#bib.bib135); Li et al.,
    [2020](#bib.bib76); Moniruzzaman et al., [2017](#bib.bib88); Saleh et al., [2022](#bib.bib111)），我们的论文具有不同的视角和动机，补充了之前的综述。与
    (Goodwin et al., [2022](#bib.bib32)) 提供的关于生态数据分析的一般领域的综述相比，我们只关注鱼类监测。我们还对鱼类数据集进行了详细分析，并全面回顾了水下鱼类视频和图像处理中的四个关键任务。这种详细的分析和回顾在
    (Goodwin et al., [2022](#bib.bib32)) 或其他以往工作中没有提供，使我们的论文对于那些希望深入研究鱼类监测的读者来说尤为有用，并且提供了全面的文献综述。
- en: In addition, (Li and Du, [2021](#bib.bib73)) provides a review of studies on
    fish condition, growth, and behavior monitoring in aquaculture settings. It briefly
    covers and reviews various DL architectures and their aquaculture applications,
    unlike the present communication that is focused mainly on Convolutional Neural
    Network (CNN) and provides a detailed survey and analysis of the underwater fish
    monitoring literature.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，(Li and Du, [2021](#bib.bib73)) 提供了关于水产养殖环境中鱼类状况、成长和行为监测的研究综述。它简要地涵盖了各种深度学习架构及其在水产养殖中的应用，与本篇通讯主要集中在卷积神经网络（CNN）并对水下鱼类监测文献进行了详细的调查和分析不同。
- en: The work presented in (Zhao et al., [2021](#bib.bib138)) covers the general
    domain of Machine Learning, as opposed to the specific domain of DL in our paper.
    This is done for aquaculture applications as wide as fish biomass and behavior
    analysis to water quality predictions, while also briefly covering and reviewing
    fish classification and detection methods.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: (Zhao et al., [2021](#bib.bib138)) 中展示的工作涵盖了机器学习的一般领域，而不是我们论文中深度学习的具体领域。该工作涉及了广泛的水产养殖应用，从鱼类生物量和行为分析到水质预测，同时还简要地涵盖了鱼类分类和检测方法的回顾。
- en: A survey of computer vision models for fish detection and behavior analysis
    in digital aquaculture is provided in (Yang et al., [2021](#bib.bib135)). An interested
    reader should study (Yang et al., [2021](#bib.bib135)) before reading our paper,
    due to the background technical details provided on image acquisition, which are
    key to developing effective DL datasets and models, as we discussed in our paper.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (Yang et al., [2021](#bib.bib135)) 中提供了针对数字水产养殖中的鱼类检测和行为分析的计算机视觉模型的综述。感兴趣的读者应在阅读我们的论文之前研究
    (Yang et al., [2021](#bib.bib135))，因为其中提供了关于图像采集的背景技术细节，这些细节对于开发有效的深度学习数据集和模型至关重要，这在我们的论文中也有讨论。
- en: Furthermore, the DL-based studies presented in (Li et al., [2020](#bib.bib76))
    and (Moniruzzaman et al., [2017](#bib.bib88)) are mainly around the two specific
    tasks of underwater fish tracking, and underwater object detection, respectively.
    These applications are different to our study. However, since our underwater fish
    monitoring task are related to these applications, our paper can complement these
    works.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，(Li et al., [2020](#bib.bib76)) 和 (Moniruzzaman et al., [2017](#bib.bib88))
    中展示的基于深度学习的研究主要围绕水下鱼类跟踪和水下物体检测这两个具体任务。这些应用与我们的研究不同。然而，由于我们的水下鱼类监测任务与这些应用相关，我们的论文可以补充这些工作。
- en: In (Saleh et al., [2022](#bib.bib111)), we have provided a historical survey
    of fish classification methods between the years 2003-2021\. These methods cover
    traditional CV techniques and modern DL methods, only for fish classification
    in underwater habitats and not for the general domain of underwater fish habitat
    monitoring.
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 在 (Saleh et al., [2022](#bib.bib111)) 中，我们提供了2003-2021年间鱼类分类方法的历史回顾。这些方法涵盖了传统的CV技术和现代的DL方法，仅用于水下栖息地的鱼类分类，而非一般的水下鱼类栖息地监测领域。
- en: 2 Deep Learning
  id: totrans-27
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度学习
- en: Deep learning is a sub-field of machine learning composed of interrelated algorithms
    and concepts used in training a deep neural network (Saleh et al., [2022](#bib.bib111)).
    One of the main reasons behind the extereme popularity of deep learning is the
    unprecedented and unparalleled performance it has achieved across different fields
    especially image recognition.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习是机器学习的一个子领域，由相互关联的算法和概念组成，用于训练深度神经网络（Saleh et al., [2022](#bib.bib111)）。深度学习极受欢迎的主要原因之一是其在不同领域，特别是图像识别中的前所未有的性能。
- en: Deep learning utilizes multi-layered neural networks for automatic learning
    of input features. Features are distinguishing properties of learning inputs e.g.
    the color or shape of different fish. The deep learning concept was first proposed
    based on the idea that the traditional multi-layer artificial neural networks,
    could learn complex nonlinear features and their relations with more generalization
    and at a rapid speed. To learn deep features efficiently, researchers found that
    a modified version of neural networks, i.e. CNN, works very well in the image
    processing field (Saleh et al., [2022](#bib.bib111)). In the following sections,
    we will first introduce the basic concepts of neural networks in general and then
    describe CNNs and explain how they learn and then process input images.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习利用多层神经网络自动学习输入特征。特征是学习输入的区别属性，例如不同鱼类的颜色或形状。深度学习概念首次提出的基础是传统的多层人工神经网络能够以更快的速度和更好的泛化能力学习复杂的非线性特征及其关系。为了高效地学习深度特征，研究人员发现神经网络的一个修改版本，即CNN，在图像处理领域表现非常好（Saleh
    et al., [2022](#bib.bib111)）。在接下来的部分中，我们将首先介绍神经网络的一般基本概念，然后描述CNN，并解释它们如何学习和处理输入图像。
- en: 2.1 Neural Networks
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 神经网络
- en: A ’neural network’ is a computational model that is inspired by biological neural
    systems and uses simple, non-linear, computational rules to mimic these systems.
    Neural networks are composed of simple processing elements called, neurons. By
    organising neurons in a layered structure, interconnecting them and changing the
    weights associated with each interconnection, a ’neural network’ can be trained
    to solve a complex problem, such as recognising if a fish is present in an image.
    It is then possible to store the connections between neurons for later use. Training
    a neural network to perform different tasks e.g. recognizing fish in an image,
    or determining where a fish is in an underwater image, is called the ’learning
    process’. During supervised learning (explained later), the inputs to the network
    are presented with each input having a desired output. The learning process determines
    which interconnections (weights) are most important to the system for learning
    the task at hand and mapping all the inputs to all their desired outputs, as best
    as possible.
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: “神经网络”是一个受生物神经系统启发的计算模型，使用简单的非线性计算规则来模拟这些系统。神经网络由称为神经元的简单处理元素组成。通过将神经元组织在分层结构中，互相连接并更改每个连接的权重，一个“神经网络”可以被训练以解决复杂的问题，例如识别图像中是否存在鱼。然后可以存储神经元之间的连接以供以后使用。训练神经网络执行不同任务，例如识别图像中的鱼，或确定水下图像中鱼的位置，称为“学习过程”。在监督学习（稍后解释）过程中，网络的输入会被呈现，并且每个输入都有一个期望的输出。学习过程确定哪些互连（权重）对系统学习任务最重要，并尽可能地将所有输入映射到所有期望的输出。
- en: The general idea of neural networks is to have layers of neurons for learning
    the input data. There are three consecutive layer types in a neural network, i.e.
    input, hidden, and output. The hidden layers can learn the patterns in the data
    passed to the network through the input layer. It is within the hidden layers
    that classification, or in some cases regression, of the input data takes place.
    The hidden layers can learn abstract patterns and features in the data on their
    own. In general, there will be more layers in a DNN compared to artificial (shallow)
    networks for image classification tasks, and this is why DNNs are called deep
    and can achieve higher accuracies.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的基本思想是通过层叠的神经元来学习输入数据。神经网络中有三种连续的层类型，即输入层、隐藏层和输出层。隐藏层可以学习通过输入层传递给网络的数据中的模式。分类（或在某些情况下回归）就在隐藏层中进行。隐藏层可以自主学习数据中的抽象模式和特征。一般来说，深度神经网络（DNN）的层数会比用于图像分类任务的人工（浅层）网络更多，这也是为什么DNN被称为深度网络并且能够实现更高准确率的原因。
- en: 2.1.1 Neuron
  id: totrans-33
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 神经元
- en: 'The neuron, also known as a node or perceptron in a neural network, is its
    basic unit of computing. The neuron takes inputs from other nodes and produces
    an output. Every input has a weight $w$ that is allocated based on its relative
    significance to other inputs. As depicted in Figure [1](#S2.F1 "Figure 1 ‣ 2.1.4
    Loss Function ‣ 2.1 Neural Networks ‣ 2 Deep Learning ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey"), the node applies the activation
    function $f$ (described below) on the weighted sum of its inputs.'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '神经元，也称为节点或感知器，是神经网络中的基本计算单元。神经元从其他节点接收输入并产生输出。每个输入都有一个权重 $w$，根据其相对重要性分配。正如图
    [1](#S2.F1 "Figure 1 ‣ 2.1.4 Loss Function ‣ 2.1 Neural Networks ‣ 2 Deep Learning
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey")
    中所示，节点对其输入的加权总和应用激活函数 $f$（如下所述）。'
- en: 2.1.2 Activation Functions
  id: totrans-35
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 激活函数
- en: 'The activation function (Vogels et al., [2005](#bib.bib125)) in a neural network
    defines whether a given node is "activated" or not based on the weighted sum of
    input features. The sigmoid function is one of the most commonly used activation
    functions. It is defined as:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络中的激活函数（Vogels et al., [2005](#bib.bib125)）定义了一个节点是否根据输入特征的加权总和被“激活”。Sigmoid
    函数是最常用的激活函数之一。其定义为：
- en: '|  | $S(x)=\frac{1}{1+e^{-x}}$ |  | (1) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | $S(x)=\frac{1}{1+e^{-x}}$ |  | (1) |'
- en: where $S(x)$ is the sigmoid function output that will be used as the input for
    the following node and $x$ is the weighted sum of input features from the previous
    layer. The sigmoid function is non-linear and its value ranges between 0 and 1\.
    Sigmoid is popular in image classification because its 0-1 range can be represented
    as the probability of "activating" each output class. The output with the largest
    "activation" value is then selected, thus facilitating the network’s ability to
    classify the image.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $S(x)$ 是将用作下一节点输入的 sigmoid 函数输出，$x$ 是来自前一层的输入特征的加权总和。Sigmoid 函数是非线性的，其值范围在
    0 到 1 之间。Sigmoid 在图像分类中很受欢迎，因为它的 0-1 范围可以表示“激活”每个输出类别的概率。然后选择具有最大“激活”值的输出，从而促进网络对图像的分类能力。
- en: 2.1.3 Bias Node
  id: totrans-39
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.3 偏置节点
- en: 'Another important component in successful neural networks are the "bias" nodes,
    which, as shown in Fig. [1](#S2.F1 "Figure 1 ‣ 2.1.4 Loss Function ‣ 2.1 Neural
    Networks ‣ 2 Deep Learning ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey"), add a bias value $b$ to the sum of input-weight multiplications
    to increase the model’s flexibility. In particular, when all input features equal
    to 0, the network can adjust to the data and decrease the distance between the
    fitted values in other data spaces.'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '成功神经网络中的另一个重要组成部分是“偏置”节点，如图 [1](#S2.F1 "Figure 1 ‣ 2.1.4 Loss Function ‣ 2.1
    Neural Networks ‣ 2 Deep Learning ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") 所示，它向输入权重乘积的总和中添加一个偏置值 $b$，以增加模型的灵活性。特别是，当所有输入特征等于
    0 时，网络可以调整数据，减少其他数据空间中拟合值之间的距离。'
- en: 2.1.4 Loss Function
  id: totrans-41
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.4 损失函数
- en: 'In machine learning, there is always a function that needs to be decreased
    or increased to reach the closest possible mapping between the input and output
    domains. This function is usually known as the objective function. When it needs
    to be minimised, for instance for the case of neural network supervised learning,
    we might refer to it as the cost, loss, or error function. Although different
    DL publications may define specific meanings for some of these terms, we use them
    indiscriminately in this paper. In general, loss functions measure the performance
    of a data-based Machine Learning (ML) model. The loss function is important to
    consider, as it measures and presents learning error in the form of a single real
    number between predicted values and expected values. As an example, the loss function
    for linear regression is defined as:'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 在机器学习中，总是有一个函数需要被减少或增加，以达到输入和输出域之间尽可能接近的映射。这个函数通常称为目标函数。当它需要被最小化时，例如在神经网络的监督学习中，我们可能将其称为成本、损失或误差函数。虽然不同的深度学习（DL）文献可能对这些术语中的某些定义有具体的含义，但我们在本文中不加区分地使用它们。一般来说，损失函数衡量了基于数据的机器学习（ML）模型的性能。损失函数的重要性在于，它以预测值和期望值之间的单个实数形式来度量和呈现学习误差。例如，线性回归的损失函数定义为：
- en: '|  | $L=\frac{1}{2m}\sum_{i=1}^{m}(\hat{y}-y)^{2},$ |  | (2) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $L=\frac{1}{2m}\sum_{i=1}^{m}(\hat{y}-y)^{2},$ |  | (2) |'
- en: where $m$ is the number of training examples, $\hat{y}$ is the predicted value
    of the model, and $y$ is the true value of the inputs in the training data.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $m$ 是训练样本的数量，$\hat{y}$ 是模型的预测值，$y$ 是训练数据中输入的真实值。
- en: For classification tasks, such as fish species classification, the loss function
    $L$ is generally a cross-entropy loss function. Cross-entropy loss measures the
    performance of a classification model with a probability value ranging from 0
    to 1\. The loss of cross-entropy functions will increase as the predicted probability
    differs from the ground truth. Another classification loss is Hinge Loss. In Hinge
    Loss, the correct category score should, by some safety margin, be higher than
    the sum of values for all incorrect categories.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 对于分类任务，例如鱼类种类分类，损失函数 $L$ 通常是交叉熵损失函数。交叉熵损失衡量了分类模型的性能，其概率值范围从 0 到 1。当预测的概率与真实值有差异时，交叉熵损失函数的损失会增加。另一种分类损失是铰链损失（Hinge
    Loss）。在铰链损失中，正确类别的分数应比所有错误类别的值之和高出一定的安全边际。
- en: <svg   height="212.99" overflow="visible" version="1.1" width="291.73"><g transform="translate(0,212.99)
    matrix(1 0 0 -1 0 0) translate(145.87,0) translate(0,67.13)"><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 116.38)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{1}$</foreignobject></g><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 37.64)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{2}$</foreignobject></g><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 -41.1)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{3}$</foreignobject></g><g stroke-width="0.85358pt"
    fill="#0000FF" stroke="#0000FF" transform="matrix(1.0 0.0 0.0 1.0 -44.75 41.1)"
    color="#0000FF"><foreignobject width="89.5" height="24.21" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$f(\sum_{i=1}^{n}{x_{i}w_{i}+b})$</foreignobject></g><g
    stroke-width="0.28453pt" fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 112.56 34.64)" color="#000000"><foreignobject width="11.11" height="9.46"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$Y$</foreignobject></g><g
    stroke="#000000" fill="#000000"><g stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 -77.94 96.69)" fill="#000000" stroke="#000000"><foreignobject width="14.15"
    height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{1}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -77.94 47.48)" fill="#000000" stroke="#000000"><foreignobject
    width="14.15" height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{2}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -77.94 6.14)" fill="#000000" stroke="#000000"><foreignobject
    width="14.15" height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{3}$</foreignobject></g></g></g></g></svg>
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: <svg   height="212.99" overflow="visible" version="1.1" width="291.73"><g transform="translate(0,212.99)
    matrix(1 0 0 -1 0 0) translate(145.87,0) translate(0,67.13)"><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 116.38)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{1}$</foreignobject></g><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 37.64)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{2}$</foreignobject></g><g stroke-width="0.28453pt"
    fill="#000000" stroke="#000000" transform="matrix(1.0 0.0 0.0 1.0 -124 -41.1)"
    color="#000000"><foreignobject width="11.78" height="8.45" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$x_{3}$</foreignobject></g><g stroke-width="0.85358pt"
    fill="#0000FF" stroke="#0000FF" transform="matrix(1.0 0.0 0.0 1.0 -44.75 41.1)"
    color="#0000FF"><foreignobject width="89.5" height="24.21" transform="matrix(1
    0 0 -1 0 16.6)" overflow="visible">$f(\sum_{i=1}^{n}{x_{i}w_{i}+b})$</foreignobject></g><g
    stroke-width="0.28453pt" fill="#000000" stroke="#000000" transform="matrix(1.0
    0.0 0.0 1.0 112.56 34.64)" color="#000000"><foreignobject width="11.11" height="9.46"
    transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$Y$</foreignobject></g><g
    stroke="#000000" fill="#000000"><g stroke-width="0.4pt"><g transform="matrix(1.0
    0.0 0.0 1.0 -77.94 96.69)" fill="#000000" stroke="#000000"><foreignobject width="14.15"
    height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{1}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -77.94 47.48)" fill="#000000" stroke="#000000"><foreignobject
    width="14.15" height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{2}$</foreignobject></g><g
    transform="matrix(1.0 0.0 0.0 1.0 -77.94 6.14)" fill="#000000" stroke="#000000"><foreignobject
    width="14.15" height="8.45" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible">$w_{3}$</foreignobject></g></g></g></g></svg>
- en: 'Figure 1: Diagram of the perceptron neuron. Inputs $x_{i}$ are multiplied in
    the weights $w_{i}$. The neuron body (blue) accumulates the sum of all multiplication
    inputs and then fires an output signal $Y$ according to its activation function
    $f$.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：感知器神经元示意图。输入 $x_{i}$ 与权重 $w_{i}$ 相乘。神经元主体（蓝色）累加所有乘法输入的和，然后根据其激活函数 $f$ 发出输出信号
    $Y$。
- en: 2.1.5 Optimization
  id: totrans-48
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.5 优化
- en: In supervised learning, the learning task can be reduced to an optimization
    problem in the form of
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在监督学习中，学习任务可以归结为一个形式的优化问题
- en: '|  | $\theta^{*}=\arg\min_{\theta}g(\theta),$ |  | (3) |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '|  | $\theta^{*}=\arg\min_{\theta}g(\theta),$ |  | (3) |'
- en: where $\theta$ is a parameter vector, at which the loss function $g(\theta)$
    that usually represent the average loss for all training examples, reaches its
    minimum. $g$ can be represented as
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\theta$ 是一个参数向量，在该点，损失函数 $g(\theta)$ 通常代表所有训练样本的平均损失，达到其最小值。$g$ 可以表示为
- en: '|  | $g(\theta)=\frac{1}{n}\sum_{i=1}^{n}L\left(f_{\theta}\left(x_{i}\right),y_{i}\right),$
    |  | (4) |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '|  | $g(\theta)=\frac{1}{n}\sum_{i=1}^{n}L\left(f_{\theta}\left(x_{i}\right),y_{i}\right),$
    |  | (4) |'
- en: where $(x_{i},y_{i})$ represents a (input, desired output) training pair.
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $(x_{i},y_{i})$ 代表一个（输入，期望输出）训练对。
- en: Similarly, in DL, an optimization method is used to train the neural network
    by minimising the error function $E$ that is defined as
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 同样，在深度学习中，使用一种优化方法来训练神经网络，通过最小化定义为
- en: '|  | $E(W,b)=\sum_{i=1}^{m}L\left(\hat{y}_{i},{y}_{i}\right)$ |  | (5) |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '|  | $E(W,b)=\sum_{i=1}^{m}L\left(\hat{y}_{i},{y}_{i}\right)$ |  | (5) |'
- en: where $W$ and $b$ are the weights and biases of the network, respectively. The
    value of the error function $E$ is thus the sum of the mean squared loss $L$ between
    the predicted value $\hat{y}$ and true value $y$, for m training examples. The
    value of $\hat{y}$ is obtained during the forward propagation step and makes use
    of the previously-mentioned weights and biases of the network, which can be initialised
    in different ways. Optimization minimizes the value of the error function $E$
    by updating the values of the trainable parameters $W$ and $b$.
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 的错误函数$E$，其中$W$和$b$分别是网络的权重和偏置。错误函数$E$的值即为预测值$\hat{y}$和真实值$y$之间的均方损失$L$的总和，适用于m个训练样本。$\hat{y}$的值在前向传播步骤中获得，利用了之前提到的网络权重和偏置，这些权重和偏置可以以不同的方式初始化。优化通过更新可训练参数$W$和$b$的值来最小化错误函数$E$的值。
- en: The error function $E$ is usually minimised by using its gradient slopes for
    the parameters. The most commonly used optimization method is Gradient Descent
    (Sun et al., [2019](#bib.bib119)), in which the gradient is optimized by calculating
    a matrix of partial derivatives (computed using backpropagation, as detailed in
    the next subsection). These derivatives provide the slope of $g$ simultaneously
    at each dimension of $\theta$. Therefore, the gradient is used to determine the
    next direction to search for the Global Optimum. To enhance $\theta$ and reach
    a lower $g$, a small quantity is subtracted from $\theta$ in the optimal direction
    (since the gradient provides the direction of the rise and conversely the descent
    in $g$), such that the global optimum is eventually reached and $g$ is minimized.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 错误函数$E$通常通过使用其梯度斜率来最小化参数。最常用的优化方法是梯度下降（Sun et al., [2019](#bib.bib119)），其中通过计算偏导数矩阵（使用反向传播计算，详见下一小节）来优化梯度。这些偏导数同时提供了$\theta$每个维度的$g$的斜率。因此，梯度用于确定下一步搜索全球最优解的方向。为了增强$\theta$并达到更低的$g$，从$\theta$中减去一个小量，在最佳方向上（因为梯度提供了$g$的上升方向和相反的下降方向），最终达到全局最优解并最小化$g$。
- en: 2.1.6 Backpropagation
  id: totrans-58
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.6 反向传播
- en: Backpropagation is probably the most important part of learning in neural networks.
    It is performed after a forward propagation or pass, in which a subset of the
    training dataset (named a batch) $\left\{\left(x_{i},y_{i}\right)\right\}_{i=1}^{m}$
    and the current network parameters $\theta$ are used to calculate the final layer
    output and the loss. During the forward pass, the data input is passed to the
    first layer to process according to its activation function and their values are
    passed on to the next layer, hence the term "forward pass". After the forward
    pass and calculating the final layer loss, backpropagation happens, through which
    we start to calculate the loss backwards, layer by layer, and the layer derivatives
    are then "chained" by the local gradients to minimise the overall loss, $g$.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播可能是神经网络学习中最重要的部分。它在前向传播或前向传递之后进行，在此过程中，训练数据集的一个子集（称为一个批次）$\left\{\left(x_{i},y_{i}\right)\right\}_{i=1}^{m}$和当前网络参数$\theta$用于计算最终层输出和损失。在前向传递期间，数据输入传递给第一层，根据其激活函数进行处理，并将其值传递给下一层，因此称为“前向传递”。在前向传递和计算最终层损失后，进行反向传播，通过它我们开始逐层计算损失，层导数随后通过局部梯度“链式”相连，以最小化整体损失$g$。
- en: 2.1.7 Regularization
  id: totrans-60
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.7 正则化
- en: 'Regularization is another important concept in neural networks learning. It
    is a technique that makes small changes to the learning algorithm to improve the
    performance of the model on testing or out-of-sample data (Bisong and Bisong,
    [2019](#bib.bib8)). In other words, it avoids the risk of over-fitting the training
    data by discouraging the formation of complex mapping functions or models. Model
    regularization involves a regularization term being added to the general model
    loss function, which takes into account the loss function value for all the training
    dataset examples. Thus, when using regularization, the loss function $g(\theta)$
    (described in Eq. [4](#S2.E4 "In 2.1.5 Optimization ‣ 2.1 Neural Networks ‣ 2
    Deep Learning ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey")) becomes'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 正则化是神经网络学习中的另一个重要概念。它是一种通过对学习算法进行小幅调整来提高模型在测试或样本外数据上的性能的技术（Bisong and Bisong,
    [2019](#bib.bib8)）。换句话说，它通过阻止复杂映射函数或模型的形成来避免过拟合训练数据的风险。模型正则化涉及在通用模型损失函数中添加正则化项，该函数考虑了所有训练数据集样本的损失函数值。因此，当使用正则化时，损失函数
    $g(\theta)$（在方程 [4](#S2.E4 "在 2.1.5 优化 ‣ 2.1 神经网络 ‣ 2 深度学习 ‣ 深度学习在鱼类栖息地监测中的应用：教程与调查")
    中描述）变为
- en: '|  | $g(\theta)=\frac{1}{n}\sum_{i=1}^{n}L\left(f_{\theta}\left(x_{i}\right),y_{i}\right)+R\left(f_{\theta}\right),$
    |  | (6) |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '|  | $g(\theta)=\frac{1}{n}\sum_{i=1}^{n}L\left(f_{\theta}\left(x_{i}\right),y_{i}\right)+R\left(f_{\theta}\right),$
    |  | (6) |'
- en: where, $R\left(f_{\theta}\right)$ is the added regularization function.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 其中，$R\left(f_{\theta}\right)$ 是添加的正则化函数。
- en: The most common forms of regularization are L1 and L2 (Ng, [2004](#bib.bib90)).
    The difference between them is that L2 is the sum of the square of the weights,
    while L1 is the sum of the weights.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的正则化形式是 L1 和 L2（Ng, [2004](#bib.bib90)）。它们之间的区别在于 L2 是权重的平方和，而 L1 是权重的和。
- en: 2.2 Convolutional Neural Network (CNN)
  id: totrans-65
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 卷积神经网络（CNN）
- en: The most powerful class of DNNs are convolutional neural networks. As their
    name infers, convolutional networks work by performing a convolution (filtering)
    operation on the input data. A CNN is usually composed of several convolution
    layers, which extract useful features from the input data by sliding convolution
    filters across the input image represented to the network as matrices. One of
    the first successful examples of the use of CNNs in computer vision was AlexNet
    proposed by Krizhevsky *et al.* in 2012\. AlexNet achieved great success only
    using four convolutional layers. Since 2012, many different flavours of CNNs have
    been proposed using different architectures and count of convolutional and other
    complementary layers. These architectures have revolutionized computer vision
    and image processing in different domains from agriculture (Olsen et al., [2019](#bib.bib93))
    to medicine (Saleh et al., [2021](#bib.bib110)). CNNs have also been widely applied
    in underwater visual monitoring and processing for counting, localizing, classifying,
    and segmenting objects of interest such as fish (Saleh et al., [2020b](#bib.bib109)).
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最强大的 DNN 类型是卷积神经网络。顾名思义，卷积网络通过对输入数据执行卷积（过滤）操作来工作。CNN 通常由几个卷积层组成，这些层通过在表示为矩阵的输入图像上滑动卷积滤波器来提取有用的特征。CNN
    在计算机视觉中的第一个成功例子之一是 Krizhevsky *et al.* 在 2012 年提出的 AlexNet。AlexNet 仅使用四个卷积层便取得了巨大成功。自
    2012 年以来，已经提出了许多不同类型的 CNN，采用不同的架构和卷积层及其他辅助层的数量。这些架构在不同领域的计算机视觉和图像处理方面引发了革命，从农业（Olsen
    et al., [2019](#bib.bib93)）到医学（Saleh et al., [2021](#bib.bib110)）。CNN 还广泛应用于水下视觉监测和处理，用于计数、定位、分类和分割感兴趣的物体，如鱼类（Saleh
    et al., [2020b](#bib.bib109)）。
- en: '![Refer to caption](img/2b4cf941d5aaa31c95ca23e67ac8038b.png)'
  id: totrans-67
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2b4cf941d5aaa31c95ca23e67ac8038b.png)'
- en: 'Figure 2: Schematic diagram of a CNN architecture used for the classification
    of fish images. The architecture consists of five convolutional layers that include
    the batch norm operation within them, followed by pooling layers (conv1-conv5).
    In this model, the feature maps from convolutional layers are pooled through pooling
    layers then flattened through two fully connected layers (fc6 and fc7). The classification
    output is the result of a fully connected layer and a softmax activation layer
    (fc8+softmax).'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：用于鱼类图像分类的 CNN 结构示意图。该结构包括五个卷积层，这些层内包含批量归一化操作，后面跟着池化层（conv1-conv5）。在这个模型中，来自卷积层的特征图通过池化层进行池化，然后通过两个全连接层（fc6
    和 fc7）进行展平。分类输出是一个全连接层和一个 softmax 激活层（fc8+softmax）的结果。
- en: 'A typical CNN architecture is composed of convolutional layers, pooling layers,
    non-linear activation layers, and final output layers, as shown in Figure [2](#S2.F2
    "Figure 2 ‣ 2.2 Convolutional Neural Network (CNN) ‣ 2 Deep Learning ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey"). It is through
    the filtering convolution operation combined with other parts of the CNN that
    useful features of the input data are extracted and learned automatically. The
    learning of a CNN usually involves finding the appropriate number, size, and structure
    of convolution filters, pooling layers, and activation functions and their parameters
    during training and seeing various examples of the inputs. In the below subsections,
    we will cover these basic building blocks and layers of a typical CNN.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '一个典型的CNN架构由卷积层、池化层、非线性激活层和最终输出层组成，如图[2](#S2.F2 "Figure 2 ‣ 2.2 Convolutional
    Neural Network (CNN) ‣ 2 Deep Learning ‣ Applications of Deep Learning in Fish
    Habitat Monitoring: A Tutorial and Survey")所示。通过与CNN的其他部分结合的过滤卷积操作，可以自动提取和学习输入数据的有用特征。CNN的学习通常涉及在训练过程中找到适当的卷积滤波器的数量、大小和结构、池化层和激活函数及其参数，并查看各种输入示例。在以下小节中，我们将深入探讨这些典型CNN的基本构建块和层。'
- en: •
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Convolutional layer: As already mentioned, a convolutional layer applies a
    filtering (convolution) operation on its input matrix data to generate another
    matrix called a feature map. The input matrix can contain the input image information
    or the feature map generated by a previous CNN layer. The feature maps are the
    core of a CNN, where useful features of an input are extracted and learned across
    several convolutional layers.'
  id: totrans-71
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 卷积层：如前所述，卷积层对其输入矩阵数据应用过滤（卷积）操作，以生成另一个矩阵，称为特征图。输入矩阵可以包含输入图像信息或由前一CNN层生成的特征图。特征图是CNN的核心，其中提取和学习输入的有用特征跨越多个卷积层。
- en: •
  id: totrans-72
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Batch Normalization: The goal of this operation, which follows the convolutional
    operation, is to normalize the learning of the network across the current set
    of training data (batch), hence the name batch normalization. This is done to
    improve the speed of learning and the convergence of the deep learning model,
    because otherwise, the network may see very wide variety of features extracted
    in its convolutional layers, due to wide input variations. Batch normalization
    happens by subtracting its input mean and dividing the result by its standard
    deviation.'
  id: totrans-73
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 批量归一化：这一操作跟随卷积操作，其目标是对当前训练数据集（批次）进行归一化，因此称为批量归一化。这是为了提高学习速度和深度学习模型的收敛性，否则，由于输入变异广泛，网络可能会看到在卷积层中提取的各种特征。批量归一化通过减去输入的均值并将结果除以标准差来完成。
- en: •
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Activation layer: This layer that follows the batch normalization layer is
    the normal neuron activation function explained earlier. It is used to increase
    the non-linearity of the convolutional layer output and increase its power in
    learning complex data. The most common activation functions used in conjunction
    with convolutional layers are Rectified Linear Unit (ReLU) and Sigmoid. Activation
    functions are also used in the final non-convolutional fully-connected layers
    of a CNN. A common output activation function is Softmax.'
  id: totrans-75
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 激活层：这一层跟随批量归一化层，是之前解释的标准神经元激活函数。它用于增加卷积层输出的非线性，并提高其在学习复杂数据中的能力。与卷积层配合使用的最常见激活函数是修正线性单元（ReLU）和Sigmoid。激活函数也用于CNN的最终非卷积全连接层。一个常见的输出激活函数是Softmax。
- en: •
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Pooling layer: The output feature map of the convolutional layer that is batch
    normalized and passed the activation function, is often too big for the next convolutional
    layer to handle. To reduce its size and improve the efficiency of computation,
    it can be pooled in a pooling layer to generate a reduced sized feature map, while
    keeping important features. Pooling is a common operation in CNNs and is used
    in almost all practical convolutional networks. The most common pooling layers
    are max pooling and average pooling.'
  id: totrans-77
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 池化层：卷积层的输出特征图经过批量归一化和激活函数处理后，通常过于庞大，不适合下一个卷积层处理。为了减少其大小并提高计算效率，可以在池化层中对其进行池化，以生成缩小的特征图，同时保留重要特征。池化是CNN中的常见操作，几乎在所有实际的卷积网络中都有使用。最常见的池化层是最大池化和平均池化。
- en: •
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dropout: To avoid overfitting to the training data, dropout operations is introduced
    after the pooling layers. Their task is to cut the network’s dependence to a single
    data instance at each traing step, by randomly removing (dropping out) features
    extracted using the previous convolutional layer.'
  id: totrans-79
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: Dropout：为了避免对训练数据的过拟合，在池化层后引入了 dropout 操作。它们的任务是在每次训练步骤中随机移除（丢弃）通过先前卷积层提取的特征，以减少网络对单个数据实例的依赖。
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Fully connected layer: Fully connected layer, also known as dense layer, is
    the second last layer of a CNN, before the output layer. This layer contains a
    small number of neurons, each of which connected to every neuron in the previous
    layer. So the network is said to be fully connected. The fully connected layer
    takes all the inputs and weights from the previous layer, and combines them together
    into a single vector or matrix. This vector is then passed through an activation
    function, such as the sigmoid, to calculate output values of the CNN generated
    by its final output layer.'
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 全连接层：全连接层，也称为密集层，是卷积神经网络（CNN）中的倒数第二层，在输出层之前。该层包含少量的神经元，每个神经元都连接到上一层的每个神经元。因此，网络被称为全连接的。全连接层接收来自上一层的所有输入和权重，并将它们组合成一个单一的向量或矩阵。然后，这个向量通过激活函数，如
    sigmoid，来计算 CNN 生成的最终输出层的输出值。
- en: 2.3 Supervised Learning
  id: totrans-82
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3 监督学习
- en: There are two main approaches to learning in general DL. These include unsupervised
    and supervised learning. Unsupervised learning is often used to discover the structure
    and composition of the input and output domains without explicit and supervised
    target domain. This approach enables generalization from one input domain to another
    by transforming data representations that are not directly related to the data
    distribution of target domain.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 一般来说，深度学习的学习方法主要有两种：无监督学习和监督学习。无监督学习通常用于发现输入和输出领域的结构和组成，而不需要明确的监督目标领域。这种方法通过转换与目标领域数据分布无直接关系的数据表示，实现从一个输入领域到另一个领域的泛化。
- en: The supervised learning approach, on the other hand, is designed to explicitly
    map data from the input domain to its output domain via training pairs that exhibit
    matching representations. These pairs are carefully crafted by a human (supervisor),
    hence the name. The training process of supervised learning can suffer from instability
    and is less effective than the unsupervised learning method, because it learns
    with an accurate target distribution without domain-specific knowledge.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 另一方面，监督学习方法旨在通过展示匹配表示的训练对，明确将数据从输入领域映射到输出领域。这些对由人工（监督者）精心制作，因此得名。监督学习的训练过程可能会遭遇不稳定性，并且不如无监督学习方法有效，因为它以准确的目标分布进行学习，而没有领域特定的知识。
- en: Supervised deep learning uses a subtle deep neural network mechanism to extract
    useful features from large amounts of input training data that are labelled to
    show their desired output domain. The learning is done by using the repetitive
    backpropagation process (Rojas and Rojas, [1996](#bib.bib105)) explained earlier,
    to adjust the DL architecture internal parameters, such as the shape, number,
    and size of convolutional, pooling, and fully connected layers, that have been
    used to determine the representation in each layer from the representation in
    the preceding layer. In general, adjusting the DL architecture and its parameters
    to do the best mapping of the input training data to their desired output, as
    best as possible, is the same as optimising a function $f$, through backpropagation,
    to map the input domain $X$, to its matching output domain $Y$, i.e. ($f:X\mapsto
    Y$).
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 监督式深度学习使用一种微妙的深度神经网络机制，从大量标记了期望输出领域的输入训练数据中提取有用的特征。学习通过前面解释的重复反向传播过程（Rojas 和
    Rojas，[1996](#bib.bib105)）来进行，以调整深度学习（DL）架构的内部参数，例如卷积层、池化层和全连接层的形状、数量和大小，这些参数用于从前一层的表示确定每一层的表示。一般来说，将
    DL 架构及其参数调整到最佳的输入训练数据到期望输出的映射，实际上就是通过反向传播来优化一个函数 $f$，将输入领域 $X$ 映射到匹配的输出领域 $Y$，即
    ($f:X\mapsto Y$)。
- en: 3 Developing Deep Learning Models
  id: totrans-86
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 开发深度学习模型
- en: '![Refer to caption](img/a71bbdc093c9a88f6304a86954a60b11.png)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a71bbdc093c9a88f6304a86954a60b11.png)'
- en: 'Figure 3: A schematic diagram showing the steps and components required for
    training a deep learning model.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：一个示意图，展示了训练深度学习模型所需的步骤和组件。
- en: 'A comprehensive overview of the essential systematic steps for training a DL
    model is summarized in Figure [3](#S3.F3 "Figure 3 ‣ 3 Developing Deep Learning
    Models ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey"). Even though these steps are general in DL training, we included
    useful tips arising from our experience in developing DL applications in various
    domains from medical imaging to marine science applications. Nevertheless, we
    put an emphasis on the development of DL for underwater fish habitat monitoring.'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '训练深度学习模型的基本系统步骤的综合概述总结在图 [3](#S3.F3 "Figure 3 ‣ 3 Developing Deep Learning
    Models ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey") 中。虽然这些步骤在深度学习训练中是通用的，但我们根据在医学影像到海洋科学应用等各个领域开发深度学习应用的经验，提供了一些有用的提示。然而，我们特别强调了用于水下鱼类栖息地监测的深度学习开发。'
- en: 3.1 Training Dataset
  id: totrans-90
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 训练数据集
- en: The available training data is essential for developing an efficient DL model.
    Datasets are becoming increasingly crucial, even more so than algorithms. Perhaps,
    the most important factor when considering a supervised learning dataset is its
    size. The requirement for a large training dataset to achieve high accuracy is
    often a big obstacle. Because visual algorithms are trained by pairs of images
    and labels, in a supervised manner, they can only identify what has already been
    given to them. As a result, depending on the project, the number of objects to
    identify, and the required performance, training datasets might contain hundreds
    to millions of images. However, smaller training datasets with only a few hundred
    samples per class may also achieve good results (Saleh et al., [2020b](#bib.bib109);
    Konovalov et al., [2019a](#bib.bib56), [2018](#bib.bib57), [b](#bib.bib58)). Nevertheless,
    the larger the training dataset, the greater the recognition accuracy.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 可用的训练数据对于开发高效的深度学习模型至关重要。数据集变得越来越重要，甚至比算法更为重要。考虑到监督学习数据集时，最重要的因素可能是其大小。为了实现高准确率，通常需要大规模的训练数据集，这往往是一个巨大的障碍。由于视觉算法是通过图像和标签对进行训练的，采用监督学习的方式，它们只能识别已经提供给它们的内容。因此，根据项目、要识别的对象数量以及所需的性能，训练数据集可能包含数百到数百万张图像。然而，只有几百个样本的较小训练数据集也可能获得良好的结果（Saleh
    et al., [2020b](#bib.bib109); Konovalov et al., [2019a](#bib.bib56), [2018](#bib.bib57),
    [b](#bib.bib58)）。尽管如此，训练数据集越大，识别准确率越高。
- en: 'Because of the scarcity of datasets and the difficulty of acquiring reliable
    data, approaches for boosting the accuracy rate from small samples will inevitably
    become a focus of future studies. The problem of limited sample data can be also
    alleviated by transfer learning (Mathur et al., [2020](#bib.bib85); Molchanov
    et al., [2016](#bib.bib87); Lee et al., [2018](#bib.bib71)). Furthermore, data
    augmentation will become increasingly critical. Section [5.3](#S5.SS3 "5.3 Dataset
    Limitation ‣ 5 Challenges in underwater fish monitoring ‣ Applications of Deep
    Learning in Fish Habitat Monitoring: A Tutorial and Survey") covers some challenges
    of limited data and some approaches to address these challenges.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '由于数据集稀缺以及获取可靠数据的难度，从小样本中提升准确率的方法将不可避免地成为未来研究的重点。样本数据有限的问题也可以通过迁移学习得到缓解（Mathur
    et al., [2020](#bib.bib85); Molchanov et al., [2016](#bib.bib87); Lee et al.,
    [2018](#bib.bib71)）。此外，数据增强将变得越来越重要。第 [5.3](#S5.SS3 "5.3 Dataset Limitation ‣
    5 Challenges in underwater fish monitoring ‣ Applications of Deep Learning in
    Fish Habitat Monitoring: A Tutorial and Survey") 节涵盖了有限数据的一些挑战及解决这些挑战的方法。'
- en: The second factor to consider when preparing a dataset for DL training is having
    a balance. This is critical to ensure that each class to be identified contains
    a sufficient number of instances to minimise class imbalance biases. These biases
    happen when the DL favours one or more classes due to seeing them more often when
    being trained.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 准备深度学习训练数据集时需要考虑的第二个因素是平衡性。这对于确保每个要识别的类别包含足够数量的实例，以减少类别不平衡偏差至关重要。这些偏差发生在深度学习因看到某些类别的频率较高而偏向于这些类别时。
- en: Also, the training dataset is typically divided into two subsets, the training
    subset for efficiently training the model and the validation/test subset for assessing
    the trained model’s performance. For the training subset, a subset of the training
    dataset is reserved for training the model. If the training subset is too large,
    it can prolong the model training. If, on the other hand, the training subset
    is too small, the resulting model may not generalise well to unseen inputs. The
    validation/test subset is typically used to avoid overfitting, which is a common
    problem in machine learning and happens when the developed model simply memorises
    the inputs rather than properly learning them. Cross-validation is another widely
    used methodology for testing a DL model’s training performance, by splitting the
    training dataset into multiple mutually exclusive subsets of training and testing
    data. One method of cross-validation is called $k-fold$ cross-validation, in which
    the training dataset is split into $k$ equally sized subsets. In this method,
    $k-1$ folds are used for training the model, while the remaining fold is used
    to test the learning performance. This process is repeated until all the folds
    have been used once as a test/validation set.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，训练数据集通常分为两个子集，一个是用于高效训练模型的训练子集，另一个是用于评估已训练模型性能的验证/测试子集。对于训练子集，一部分训练数据集被保留用于训练模型。如果训练子集过大，可能会延长模型训练时间。另一方面，如果训练子集过小，最终模型可能无法很好地推广到未见过的输入。验证/测试子集通常用于避免过拟合，这是机器学习中的常见问题，发生在开发的模型仅仅记住输入而不是正确学习输入时。交叉验证是另一种广泛使用的测试深度学习模型训练性能的方法，通过将训练数据集分割成多个互不重叠的训练和测试数据子集。一种交叉验证方法称为
    $k$-折交叉验证，其中训练数据集被分成 $k$ 个大小相等的子集。在这种方法中，使用 $k-1$ 个折进行模型训练，而剩下的一个折用于测试学习性能。这个过程会重复，直到所有折都被用作测试/验证集一次。
- en: In addition to the above, it is usually vital to, initially and before embarking
    on code development, perform a comprehensive inspection of the dataset. This will
    help to clean the dataset, for instance by finding and removing duplicate data
    instances. It also helps identify imbalances and biases, as well as data distribution,
    trends, or outliers, which will help in better model design and understanding
    of possible wrong DNN predictions.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述内容，通常在开始代码开发之前，进行全面的数据集检查是至关重要的。这将有助于清理数据集，例如通过查找和删除重复的数据实例。它还帮助识别不平衡和偏差，以及数据分布、趋势或异常值，这将有助于更好的模型设计和对可能错误的深度神经网络（DNN）预测的理解。
- en: 'Fortunately, in the domain of fish habitat monitoring, researchers currently
    have access to a variety of datasets. Table [1](#S3.T1 "Table 1 ‣ 3.2 Development
    framework ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey") lists publicly available underwater
    fish datasets, their sources, and where to get them, in addition to a summary
    of their features, their labels, and their sizes. The main point to note about
    these datasets is that they differ in both size and the number of features. Although
    the number of these fish datasets is still small (17), the diversity of aquatic
    species they cover is already quite wide. They cover a large number of aquatic
    species, as indicated in Fig.  [4](#S3.F4 "Figure 4 ‣ 3.2 Development framework
    ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey"). Moreover, each dataset features a different
    number of images that have varying resolutions. For each image, there is also
    a ground truth annotated by a human expert, which make them very useful. For instance,
    these datasets can be used by researchers to test their DL models or to pre-train
    them, as the first step, for their more specific fish monitoring tasks.'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: '幸运的是，在鱼类栖息地监测领域，研究人员目前可以访问各种数据集。表格 [1](#S3.T1 "Table 1 ‣ 3.2 Development framework
    ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") 列出了公开可用的水下鱼类数据集，它们的来源以及获取方式，并附有其特征、标签和大小的总结。需要注意的是，这些数据集在大小和特征数量上有所不同。尽管这些鱼类数据集的数量仍然较少（17
    个），但它们涵盖的水生物种类已经相当广泛。如图 [4](#S3.F4 "Figure 4 ‣ 3.2 Development framework ‣ 3 Developing
    Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey") 所示，它们覆盖了大量水生物种类。此外，每个数据集包含不同数量和分辨率的图像。每张图像还配有由人工专家标注的真实值，这使得这些数据集非常有用。例如，研究人员可以使用这些数据集来测试他们的深度学习（DL）模型或作为首步进行预训练，以便更具体的鱼类监测任务。'
- en: After preparing the training dataset or utilising alternative approaches to
    addressing insufficient data challenge, one can start developing their DL model
    using a machine-learning development framework.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 在准备好训练数据集或利用其他方法解决数据不足的问题后，可以开始使用机器学习开发框架来开发其深度学习模型。
- en: 3.2 Development framework
  id: totrans-98
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 开发框架
- en: 'The rapid evolution of DL has led to the creation of a vast number of development
    libraries and packages that enable the setting up of DNNs with insignificant effort.
    Usability and availability of resources, architectural support, customisability,
    and hardware support are all various benefits of using existing machine-learning
    frameworks. The most commonly used frameworks are PyTorch, Tensorflow, MATLAB,
    Microsoft Cognitive Toolkit (CNTK) and Apache MXNET. In the context of DL for
    marine research, as will be shown later in Tables [3](#S4.T3 "Table 3 ‣ 4.2 Counting
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey") to [5](#S4.T5
    "Table 5 ‣ 4.4 Segmentation ‣ 4 Applications of Deep Learning in Underwater Fish
    Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey"), PyTorch and TensorFlow are the dominant frameworks, while Matlab
    and Caffe have been used only in a few works. Overall, details such as the project
    needs and the programmer and developer preference should be taken into account,
    when choosing the development framework.'
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: '深度学习的快速发展导致了大量开发库和包的创建，这些库和包可以用微不足道的努力设置深度神经网络。使用现有机器学习框架的各种好处包括可用性和资源的可用性、架构支持、可定制性以及硬件支持。最常用的框架有
    PyTorch、TensorFlow、MATLAB、Microsoft Cognitive Toolkit (CNTK) 和 Apache MXNET。在海洋研究的深度学习背景下，如表
    [3](#S4.T3 "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning in Underwater
    Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A
    Tutorial and Survey") 到 [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation ‣ 4 Applications
    of Deep Learning in Underwater Fish Monitoring ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey") 所示，PyTorch 和 TensorFlow 是主流框架，而
    MATLAB 和 Caffe 仅在少数工作中使用。总的来说，选择开发框架时应考虑项目需求以及程序员和开发者的偏好。'
- en: When the development framework is chosen, the next step is to find the most
    suitable network architecture for the task at hand. This sometimes depends on
    the framework, as some recent methods may not immediately be supported by all
    frameworks.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 选择开发框架后，下一步是找到最适合当前任务的网络架构。这有时取决于框架，因为一些新方法可能不会立即被所有框架支持。
- en: 'Table 1: Summary of some publicly available datasets containing fish for training
    and testing deep learning models.'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1：包含鱼类的公共数据集汇总，用于训练和测试深度学习模型。
- en: '| Dataset | Summary | Labels | Dataset size | Website |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 数据集 | 汇总 | 标签 | 数据集大小 | 网站 |'
- en: '| A - Deepfish | Videos from coastal habitats in north-eastern and western
    Australia | fish/no fish | 40k classification labels, 3.2k images with point-level
    annotations, 310 segmentation masks | [github.com/alzayats/DeepFish](https://github.com/alzayats/DeepFish)
    |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| A - Deepfish | 来自澳大利亚东北部和西部沿海栖息地的视频 | 鱼/非鱼 | 40k 分类标签，3.2k 图像有点级注释，310 个分割掩码
    | [github.com/alzayats/DeepFish](https://github.com/alzayats/DeepFish) |'
- en: '| B - Croatian Fish Dataset | 12 species of fish found in Croatian waters |
    species names | 794 classification labels | [www.inf-cv.uni-jena.de/fine_grained_recognition.html#datasets](http://www.inf-cv.uni-jena.de/fine_grained_recognition.html#datasets)
    |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| B - 克罗地亚鱼类数据集 | 克罗地亚水域发现的 12 种鱼类 | 物种名称 | 794 分类标签 | [www.inf-cv.uni-jena.de/fine_grained_recognition.html#datasets](http://www.inf-cv.uni-jena.de/fine_grained_recognition.html#datasets)
    |'
- en: '| C - Fish in seagrass habitats | RUV taken in Australian seagrass habitat
    of 2 species | species | 9k classification labels, bounding boxes and segmentation
    masks | [github.com/globalwetlands/luderick-seagrass](https://github.com/globalwetlands/luderick-seagrass)
    |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| C - 海草栖息地中的鱼类 | 在澳大利亚海草栖息地拍摄的 2 种鱼类的 RUV | 物种 | 9k 分类标签、边界框和分割掩码 | [github.com/globalwetlands/luderick-seagrass](https://github.com/globalwetlands/luderick-seagrass)
    |'
- en: '| D - Fish4Knowledge | Fish detection and tracking dataset, 17 videos at 10
    min long, rate of 5 fps. | fish/no fish | 3.5k bounding boxes | [groups.inf.ed.ac.uk/f4k/index.html](https://groups.inf.ed.ac.uk/f4k/index.html)
    |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| D - Fish4Knowledge | 鱼类检测和跟踪数据集，17 个视频，每个视频长 10 分钟，帧率为 5 fps。 | 鱼/非鱼 | 3.5k
    边界框 | [groups.inf.ed.ac.uk/f4k/index.html](https://groups.inf.ed.ac.uk/f4k/index.html)
    |'
- en: '| E - Fish-Pak | Image dataset of 6 different fish species from 3 locations
    in Pakistan | species | 1k classification labels | [data.mendeley.com/datasets/n3ydw29sbz/3](https://data.mendeley.com/datasets/n3ydw29sbz/3)
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| E - Fish-Pak | 来自巴基斯坦 3 个地点的 6 种不同鱼类的图像数据集 | 物种 | 1k 分类标签 | [data.mendeley.com/datasets/n3ydw29sbz/3](https://data.mendeley.com/datasets/n3ydw29sbz/3)
    |'
- en: '| F - Labeled Fishes in the Wild | Rockfish (Sebastes spp.) and other species
    (non-fish) near the seabed | fish/non-fish | 1k bounding boxes (fish), 3k (non-fish)
    | [swfscdata.nmfs.noaa.gov/labeled-fishes-in-the-wild/](https://swfscdata.nmfs.noaa.gov/labeled-fishes-in-the-wild/)
    |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| F - 野外标记鱼类 | 岩鱼（Sebastes spp.）及其他底栖生物（非鱼类） | 鱼/非鱼 | 1k 边界框（鱼），3k（非鱼） | [swfscdata.nmfs.noaa.gov/labeled-fishes-in-the-wild/](https://swfscdata.nmfs.noaa.gov/labeled-fishes-in-the-wild/)
    |'
- en: '| G - OzFish | Large data set comprising of 507 species of fish. | species,
    fish/no fish | 80k labeled cropped images, 45k bounding box annotations (fish/no
    fish) | [github.com/open-AIMS/ozfish](https://github.com/open-AIMS/ozfish) |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| G - OzFish | 大型数据集，包括 507 种鱼类 | 物种，鱼/非鱼 | 80k 标记裁剪图像，45k 边界框注释（鱼/非鱼） | [github.com/open-AIMS/ozfish](https://github.com/open-AIMS/ozfish)
    |'
- en: '| H - QUT Fish Dataset | 468 species in varying ex-situ and in-situ habitats.
    | species name | 4k classification images | [www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip?dl=0](https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip?dl=0)
    |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| H - QUT 鱼类数据集 | 468 种鱼类在不同的外地和本地栖息地 | 物种名称 | 4k 分类图像 | [www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip?dl=0](https://www.dropbox.com/s/e2xya1pzr2tm9xr/QUT_fish_data.zip?dl=0)
    |'
- en: '| I - Whale Shark ID | 543 individual whale sharks (Rhincodon typus) | individuals
    | 7.8k bounding boxes | [http://lila.science/datasets/whale-shark-id](http://lila.science/datasets/whale-shark-id)
    |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| I - 鲸鲨识别 | 543 只个体鲸鲨（Rhincodon typus） | 个体 | 7.8k 边界框 | [http://lila.science/datasets/whale-shark-id](http://lila.science/datasets/whale-shark-id)
    |'
- en: '| J - Large Scale Fish Dataset | 9 different seafood types collected from a
    supermarket in Izmir, Turkey | species name | For each class, there are 1000 augmented
    images and their pair-wise augmented ground truths | [www.kaggle.com/crowww/a-large-scale-fish-dataset](https://www.kaggle.com/crowww/a-large-scale-fish-dataset)
    |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| J - 大规模鱼类数据集 | 从土耳其伊兹密尔超市收集的 9 种不同海鲜 | 物种名称 | 每个类别有 1000 张增强图像及其成对增强的真实图像
    | [www.kaggle.com/crowww/a-large-scale-fish-dataset](https://www.kaggle.com/crowww/a-large-scale-fish-dataset)
    |'
- en: '| K - NCFM | Image dataset of 8 different fish species | species name | ~16000
    classification images | [www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data)
    |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| K - NCFM | 8 种不同鱼类的图像数据集 | 物种名称 | ~16000 张分类图像 | [www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data](https://www.kaggle.com/c/the-nature-conservancy-fisheries-monitoring/data)
    |'
- en: '| L - Mugil liza sonar | Sonar-based underwater videos of schools of migratory
    mullets (Mugil liza) | number of fish | 500 counting images | [zenodo.org/record/4751942#.YKzfUKgzayk](https://zenodo.org/record/4751942#.YKzfUKgzayk)
    |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| L - Mugil liza 声纳数据 | 基于声纳的迁徙鲻鱼（Mugil liza）群体水下视频 | 鱼的数量 | 500 张计数图像 | [zenodo.org/record/4751942#.YKzfUKgzayk](https://zenodo.org/record/4751942#.YKzfUKgzayk)
    |'
- en: '| M - MSRB Dataset | Real underwater images without marine snow and synthesized
    with marine snow | NA | ~6000 images | [github.com/ychtanaka/marine-snow](https://github.com/ychtanaka/marine-snow)
    |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| M - MSRB 数据集 | 真实的水下图像，没有海洋雪，并合成了海洋雪 | NA | ~6000 张图像 | [github.com/ychtanaka/marine-snow](https://github.com/ychtanaka/marine-snow)
    |'
- en: '| N - WildFish | 1,000 fish categories | species name | ~54000 classification
    images | [github.com/PeiqinZhuang/WildFish](https://github.com/PeiqinZhuang/WildFish)
    |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| N - WildFish | 1000 种鱼类类别 | 物种名称 | ~54000 张分类图像 | [github.com/PeiqinZhuang/WildFish](https://github.com/PeiqinZhuang/WildFish)
    |'
- en: '| O - SUIM | Image dataset of 8 different underwater objects | object name
    | ~1500 annotated images semantic segmentation mask | [github.com/xahidbuffon/SUIM](https://github.com/xahidbuffon/SUIM)
    |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| O - SUIM | 8 种不同水下物体的图像数据集 | 物体名称 | ~1500 张注释图像语义分割掩码 | [github.com/xahidbuffon/SUIM](https://github.com/xahidbuffon/SUIM)
    |'
- en: '| P - DZPeru fish-datasets | Several species in varying ex-situ and in-situ
    habitats. | species name | ~17000 annotated images segmentation mask | [github.com/DZPeru/fish-datasets](https://github.com/DZPeru/fish-datasets)
    |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| P - DZPeru 鱼类数据集 | 在不同的外地和本地栖息地的多种鱼类 | 物种名称 | ~17000 张注释图像分割掩码 | [github.com/DZPeru/fish-datasets](https://github.com/DZPeru/fish-datasets)
    |'
- en: '| Q - LifeCLEF | 10 different fish species | species name | ~1000 annotated
    videos | [www.imageclef.org/](https://www.imageclef.org/) | ![Refer to caption](img/377a6bb4ef0649359ca147eb9de0b61f.png)'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '| Q - LifeCLEF | 10 种不同的鱼类 | 物种名称 | ~1000 个注释视频 | [www.imageclef.org/](https://www.imageclef.org/)
    | ![Refer to caption](img/377a6bb4ef0649359ca147eb9de0b61f.png)'
- en: 'Figure 4: Sample images from publicly available datasets detailed in Table
    [1](#S3.T1 "Table 1 ‣ 3.2 Development framework ‣ 3 Developing Deep Learning Models
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey").'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: '图4：来自公开可用数据集的示例图像，详见表 [1](#S3.T1 "Table 1 ‣ 3.2 Development framework ‣ 3 Developing
    Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey")。'
- en: 3.3 Network Architecture
  id: totrans-121
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3 网络架构
- en: Network architecture is the structure of the DL model, which depends on what
    it intends to achieve and its expected input and output. Therefore, the type of
    training dataset and the expected outcome influence the architecture’s choice
    and its performance. DL network architectures can differ in a variety of ways
    such as the type and number of layers, their structure, and their order. Before
    selecting a network architecture, it is critical to understand the dataset you
    have and the task you are going to complete. For example, convolutional neural
    networks or CNNs are known to learn higher-order features, such as colours and
    shapes, from data within their convolution layers. Therefore, they are ideally
    adapted in image-based object recognition. On the other hand, Recurrent Neural
    Networks (RNNs) have the capability of processing temporal information or sequential
    data, such as the order of words in a sentence. This feature is ideal for tasks
    such as handwriting or speech recognition.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 网络架构是深度学习模型的结构，取决于它打算实现的目标以及预期的输入和输出。因此，训练数据集的类型和预期的结果会影响架构的选择及其性能。深度学习网络架构在各种方面可能有所不同，例如层的类型和数量、它们的结构和顺序。在选择网络架构之前，了解你拥有的数据集和你要完成的任务是至关重要的。例如，卷积神经网络（CNNs）能够从其卷积层中的数据中学习高阶特征，如颜色和形状。因此，它们在基于图像的物体识别中最为适用。另一方面，递归神经网络（RNNs）具有处理时间信息或序列数据的能力，例如句子中的词序。这一特性非常适合用于手写或语音识别等任务。
- en: In the context of fish habitat monitoring, if you are working on a task that
    requires you to learn temporal information of the input sequence, for example
    fish image sequence analysis, the DL architecture you choose can be very important.
    For example, a CNNs architecture is more suited for *image-based* object recognition
    such as fish classification, while the RNN architecture is more suitable for tasks
    where the input sequence is temporal in nature such as generating fish habitat
    descriptions.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 在鱼类栖息地监测的背景下，如果你的任务需要学习输入序列的时间信息，例如鱼类图像序列分析，你选择的深度学习架构可能非常重要。例如，CNNs 架构更适合用于*基于图像*的物体识别，如鱼类分类，而
    RNN 架构则更适合用于输入序列具有时间性质的任务，如生成鱼类栖息地描述。
- en: 'To find a suitable architecture, you first need to define your problem. This
    problem is defined by two questions: (1) What features will you extract? (2) How
    will you label these features? The features you extract are defined by your data.
    In other words, you are interested in the representation of the data you have.
    The number of features you choose to extract is defined by the task you are trying
    to solve. As described above, the DL architectures can learn features such as
    colours and shapes from image-based object recognition. Before trying to construct
    your network, you first need to decide what data type you will use and how will
    you encode the information. After you have defined your task, you should think
    about what features are important for the task. You will need to define this in
    order to construct your network. For example, if the features you want to extract
    are fish shape and fish location, then you could define a convolutional architecture.
    The features you choose to define should be a subset of all the features in the
    data. For example, for an image-based object recognition network, you would extract
    features such as fish species. However, your extracted features will also need
    to cover all the data. For example, you will also need features of the type of
    water or the type of background. It is important to take all these features into
    account when defining your network. For a complete discussion on different DL
    architectures see (Khan et al., [2020](#bib.bib50)).'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 要找到合适的架构，你首先需要定义你的问题。这个问题由两个问题定义：(1) 你将提取哪些特征？(2) 你将如何标记这些特征？你提取的特征由你的数据定义。换句话说，你关心的是你拥有数据的表示。你选择提取的特征数量由你试图解决的任务定义。如上所述，DL架构可以从基于图像的对象识别中学习特征，如颜色和形状。在尝试构建你的网络之前，你需要首先决定将使用什么数据类型以及如何编码这些信息。在定义了任务后，你应该考虑哪些特征对任务是重要的。你需要定义这些特征以构建你的网络。例如，如果你想提取的特征是鱼的形状和鱼的位置，那么你可以定义一个卷积架构。你选择定义的特征应是数据中所有特征的一个子集。例如，对于一个基于图像的对象识别网络，你会提取像鱼的种类这样的特征。然而，你提取的特征还需要涵盖所有数据。例如，你还需要水的类型或背景的类型的特征。在定义你的网络时，考虑所有这些特征是很重要的。关于不同DL架构的完整讨论请参见
    (Khan et al., [2020](#bib.bib50))。
- en: 3.4 Network Model
  id: totrans-125
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4 网络模型
- en: When a general network architecture is selected, the next step is to select,
    or sometimes develop, a network model of that architecture. For instance, when
    you decided to use a CNN, you can use different varieties of CNN models. The rule
    of thumb for selecting a CNN is to choose a model that results in a satisfactory
    training loss for your dataset. Creating an exotic and creative model is not recommended
    at this stage. It is usually recommended to avoid the temptation and choose a
    model big enough to overfit your dataset, and then regularise it properly to improve
    the validation loss.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 选择了一般网络架构后，下一步是选择或有时开发该架构的网络模型。例如，当你决定使用CNN时，你可以使用不同种类的CNN模型。选择CNN的经验法则是选择一个能够为你的数据集带来令人满意的训练损失的模型。在这个阶段不建议创建一个独特而富有创意的模型。通常建议避免这种诱惑，选择一个足够大的模型来过拟合你的数据集，然后适当地正则化以改善验证损失。
- en: 'For example, one may pick a well-known CNN model, e.g. ResNet, which can be
    used out-of-the-box, if their task is simple, e.g. fish classification. In later
    stages, they can customise their model to adequately capture their dataset. We
    show in Tables [3](#S4.T3 "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning
    in Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") to [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey") in the next
    section that ResNet is the most commonly used model for fish counting (Table [3](#S4.T3
    "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey")),
    fish localization (Table [4](#S4.T4 "Table 4 ‣ 4.3 Localization ‣ 4 Applications
    of Deep Learning in Underwater Fish Monitoring ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey")), and fish segmentation (Table
    [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation ‣ 4 Applications of Deep Learning in Underwater
    Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A
    Tutorial and Survey")).'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，如果任务简单，如鱼类分类，可以选择一个现成的知名CNN模型，如ResNet。在后期，他们可以定制模型以适当地捕捉数据集。我们在下一节的表[3](#S4.T3
    "表 3 ‣ 4.2 计数 ‣ 深度学习在水下鱼类监测中的应用 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")至[5](#S4.T5 "表 5 ‣ 4.4
    分割 ‣ 深度学习在水下鱼类监测中的应用 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")展示了ResNet是鱼类计数（表[3](#S4.T3 "表 3
    ‣ 4.2 计数 ‣ 深度学习在水下鱼类监测中的应用 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")）、鱼类定位（表[4](#S4.T4 "表 4 ‣
    4.3 定位 ‣ 深度学习在水下鱼类监测中的应用 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")）和鱼类分割（表[5](#S4.T5 "表 5 ‣ 4.4
    分割 ‣ 深度学习在水下鱼类监测中的应用 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")）中最常用的模型。
- en: 3.5 Training the model
  id: totrans-128
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5 训练模型
- en: After choosing the best model is the time to set up a full train/validation
    pipeline. The below steps are recommended at this stage of development.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 选择最佳模型后，是时候建立一个完整的训练/验证管道了。此阶段推荐以下步骤。
- en: •
  id: totrans-130
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Start with a simple model (i.e. a small number of convolutional layers) that
    can hardly go wrong and visualise the model performance metrics. Do not use an
    out-of-the-box large model like ResNet, just yet. It is recommended to plot training
    loss to see how the network is progressing during learning and if the loss is
    getting smaller. This also shows the speed of learning.
  id: totrans-131
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从一个简单的模型开始（即较少的卷积层），这种模型不容易出错，并可视化模型性能指标。此时不要使用现成的大型模型，如ResNet。建议绘制训练损失图，以查看网络在学习过程中是否有所进展，以及损失是否在减少。这也显示了学习的速度。
- en: •
  id: totrans-132
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: To better understand the process, it is recommended to use a fixed random seed
    (for randomly initialising the network parameters) to ensure that the same results
    can be achieved when running the code twice.
  id: totrans-133
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 为了更好地理解过程，建议使用固定的随机种子（用于随机初始化网络参数），以确保在两次运行代码时能得到相同的结果。
- en: •
  id: totrans-134
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Do not perform any data augmentation at this stage as it may introduce errors.
    You can do data augmentation at a later stage after confirming that your network
    works properly. You can see a brief introduction to data augmentation and other
    methods at subsection [5.2](#S5.SS2 "5.2 Model Generalisation ‣ 5 Challenges in
    underwater fish monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey").'
  id: totrans-135
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 此阶段不要进行任何数据增强，因为这可能会引入错误。你可以在确认网络正常工作后，稍后再进行数据增强。你可以在[5.2](#S5.SS2 "5.2 模型泛化
    ‣ 水下鱼类监测中的挑战 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")小节中看到数据增强和其他方法的简要介绍。
- en: •
  id: totrans-136
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Use ADAM algorithm (Kingma and Ba, [2014](#bib.bib54)), which helps the learning
    by applying adaptive optimisation to the learning rate of the network.
  id: totrans-137
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 使用ADAM算法（Kingma和Ba，[2014](#bib.bib54)），该算法通过对网络学习率应用自适应优化来帮助学习。
- en: •
  id: totrans-138
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The learning rate is an important hyperparameter of a deep learning model. It
    is usually the most crucial value during training and should be configured using
    trial and error. Depending on the size of your dataset, a specific learning rate
    decay may be needed. The learning rate decay is a technique that allows the learning
    rate to fall during successive training epochs, until it converges. A high learning
    rate at the start prevents the network from memorising noisy data, whereas decaying
    the learning rate improves complex pattern learning.
  id: totrans-139
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 学习率是深度学习模型中的一个重要超参数。它通常是训练过程中最关键的值，应该通过反复试验进行配置。根据数据集的大小，可能需要特定的学习率衰减。学习率衰减是一种允许学习率在连续的训练周期中逐渐降低直到收敛的技术。开始时较高的学习率可以防止网络记住噪声数据，而衰减学习率则有助于改进复杂模式的学习。
- en: •
  id: totrans-140
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Implement early stopping and monitor the learning process by looking at the
    training loss plot to prevent overfitting.
  id: totrans-141
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 实施早期停止，并通过查看训练损失图来监控学习过程，以防止过拟合。
- en: •
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Add complexity to your model gradually, e.g. add more layers or use off-the-shelf
    CNN models, and obtain a performance improvement over time.
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 逐步增加模型的复杂性，例如，添加更多层或使用现成的 CNN 模型，并随着时间推移获得性能提升。
- en: 3.6 Testing the model
  id: totrans-144
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.6 测试模型
- en: When the model is trained, its accuracy and performance should be tested using
    the test subset of the training dataset. A test set can also be independent to
    the training dataset to evaluate the model performance. The main point to remember
    is that the test set should not have been used for the training or evaluation
    of the model, at all.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练模型时，应使用训练数据集的测试子集来测试其准确性和性能。测试集也可以独立于训练数据集，以评估模型性能。主要要记住的是，测试集在模型训练或评估中不应被使用。
- en: 'The model’s performance should be measured by computing appropriate metrics
    suitable to the task at hand. A list of most common metrics used in testing fish
    monitoring models are given in Tabel [2](#S3.T2 "Table 2 ‣ 3.8 Deploying the model
    ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey"). For classification tasks, Classification
    Accuracy (CA), Precision and Recall rates are appropriate metrics, while F1-score,
    which is a combination of precision and recall, can provide a better measure of
    model performance and is used in fish counting and localization tasks as shown
    in Tables [3](#S4.T3 "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning
    in Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") and [4](#S4.T4 "Table 4 ‣ 4.3 Localization
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey"). The Intersection-Over-Union
    (IoU) is the appropriate metric for segmentation tasks, while the mean average
    precision (mAP) metric suits pixel-wise localization of fish in images. Looking
    at Tables [3](#S4.T3 "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning
    in Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") to [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey"), other metrics
    such as Mean Square Error (MSE) and Root MSE (RMSE) have also been used in the
    marine fish monitoring literature. These can be considered and used if required.'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
  zh: '模型的性能应通过计算适合当前任务的指标来衡量。用于测试鱼类监测模型的常见指标列表见表 [2](#S3.T2 "Table 2 ‣ 3.8 Deploying
    the model ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey")。对于分类任务，分类准确率 (CA)、精度和召回率是合适的指标，而
    F1 分数是精度和召回率的结合，可以更好地衡量模型性能，并在鱼类计数和定位任务中使用，如表 [3](#S4.T3 "Table 3 ‣ 4.2 Counting
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey") 和 [4](#S4.T4
    "Table 4 ‣ 4.3 Localization ‣ 4 Applications of Deep Learning in Underwater Fish
    Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey") 所示。交并比 (IoU) 是分割任务的合适指标，而平均精度 (mAP) 适用于图像中的像素级鱼类定位。参考表 [3](#S4.T3
    "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey")
    到 [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation ‣ 4 Applications of Deep Learning in
    Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey")，海洋鱼类监测文献中也使用了均方误差 (MSE) 和均方根误差 (RMSE) 等其他指标。如有需要，可以考虑使用这些指标。'
- en: 3.7 Fine Tuning the model
  id: totrans-147
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.7 微调模型
- en: The performance and accuracy of the model could be improved if needed. The amount
    of this improvement is, though, strongly influenced by its current accuracy. This
    step may quickly become complicated, since increasing the model accuracy might
    require several steps such as adjusting the learning rate, collecting new data,
    or fully modifying the model’s architecture. You should keep this fine tuning
    step to a reasonable level. Otherwise, the model might overfit the data.
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: 如果需要，可以提高模型的性能和准确性。不过，这种改进的幅度受当前准确性的强烈影响。这个步骤可能会很快变得复杂，因为提高模型准确性可能需要多个步骤，如调整学习率、收集新数据或完全修改模型架构。你应该将这个微调步骤保持在合理的范围内，否则模型可能会过拟合数据。
- en: 3.8 Deploying the model
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.8 模型部署
- en: Finally, the model deployment mode should be chosen. This depends on the application
    and the deployment requirements. The model can be deployed to run on a local or
    remote device (on a web server, a docker container, a virtual private server (VPS),
    etc). This will determine whether the results can be accessed remotely or only
    within the local network. It is recommended to use a cross-platform deployment
    method to avoid issues such as input/output data format, or the type of files
    used for storing data.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，应选择模型部署模式。这取决于应用程序和部署要求。模型可以部署在本地或远程设备上（如网络服务器、Docker 容器、虚拟私人服务器（VPS）等）。这将决定结果是可以远程访问还是仅在本地网络内访问。建议使用跨平台部署方法，以避免如输入/输出数据格式或用于存储数据的文件类型等问题。
- en: The most commonly used cross-platform model deployment method is Docker (Potdar
    et al., [2020](#bib.bib97); Abdul et al., [2019](#bib.bib1)), which is a virtualization
    software that allows setting-up and running other software environments on top
    of a base Linux distribution without the need to set-up virtual machines. Docker
    helps build, configure, and run applications using the same Docker file. Typically,
    Docker is the recommended approach for web applications. In this method, you can
    use Docker container or Docker host on your development machine. Docker container
    may be the easiest option for web applications. You can also deploy your network
    to a remote machine via Docker. The advantage of using a container is that you
    can share the development environment and run tests of your model using multiple
    docker containers. You can also install the Docker tool on your local machine
    to manage containers, so it is convenient.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 最常用的跨平台模型部署方法是 Docker（Potdar 等，[2020](#bib.bib97); Abdul 等，[2019](#bib.bib1)），它是一种虚拟化软件，允许在基础
    Linux 发行版上设置和运行其他软件环境，而无需设置虚拟机。Docker 帮助使用相同的 Docker 文件构建、配置和运行应用程序。通常，Docker
    是推荐的 web 应用程序方法。在这种方法中，你可以在开发机器上使用 Docker 容器或 Docker 主机。Docker 容器可能是 web 应用程序的最简单选项。你也可以通过
    Docker 将网络部署到远程机器上。使用容器的好处是可以共享开发环境，并使用多个 Docker 容器运行模型测试。你还可以在本地机器上安装 Docker
    工具以管理容器，这样会更方便。
- en: '![Refer to caption](img/8251d3cc46434c73d6c19e0cbe1c5c7a.png)'
  id: totrans-152
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8251d3cc46434c73d6c19e0cbe1c5c7a.png)'
- en: 'Figure 5: Illustration of four typical fish monitoring tasks. From left: Fish
    Classification (i.e. is there a fish in the image, or what type (class) of fish
    is in the image?); Fish Detection/Localization/Counting; Fish Semantic Segmentation,
    and Fish Instance Segmentation.'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: '图 5: 四种典型的鱼类监测任务的示意图。从左到右：鱼类分类（即图像中是否有鱼，或者图像中是什么类型（类别）的鱼？）；鱼类检测/定位/计数；鱼类语义分割，鱼类实例分割。'
- en: 'Table 2: Performance metrics used to compare various surveyed works.'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: '表 2: 用于比较各种调查工作的性能指标。'
- en: '| Performance Metric | Symbol Used | Description |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| 性能指标 | 使用的符号 | 描述 |'
- en: '| Classification Accuracy | CA | The percentage of correct predictions. For
    multi-class classification, CA is averaged among all the classes. $CA=(TP+TN)/(TP+TN+FP+FN)$
    |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| 分类准确率 | CA | 正确预测的百分比。对于多类分类，CA 在所有类别之间取平均值。 $CA=(TP+TN)/(TP+TN+FP+FN)$ |'
- en: '| Precision | P | The fraction of true positives ($TP$), to the sum of $TP$
    and false positives ($FP$). $P=TP/(TP+FP)$ |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| 精确度 | P | 真正例 (TP) 与 TP 和假正例 (FP) 之和的比例。 $P=TP/(TP+FP)$ |'
- en: '| Recall | R | The fraction of true positives (TP) to the sum of TP and false
    negatives (FN). $R=TP/(TP+FN)$ |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| 召回率 | R | 真正例 (TP) 与 TP 和假阴性 (FN) 之和的比例。 $R=TP/(TP+FN)$ |'
- en: '| F1 score | F1 | The harmonic mean of precision and recall. $F1=2~{}\times(P\times
    R)/(P+R)$ |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| F1 分数 | F1 | 精确度和召回率的调和均值。 $F1=2~{}\times(P\times R)/(P+R)$ |'
- en: '| Mean Square Error | MSE | Mean of the square of the errors between predicted
    and observed values |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| 均方误差 | MSE | 预测值与观测值之间误差的平方的均值 |'
- en: '| Root Mean Square Error | RMSE | Is the square root of the mean of the square
    of all of the errors. |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| 均方根误差 | RMSE | 所有误差的平方均值的平方根。 |'
- en: '| Mean Relative Error | MRE | The mean error between predicted and observed
    values, in percentage |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| 平均相对误差 | MRE | 预测值与观测值之间的平均误差，以百分比表示 |'
- en: '| L2 error | L2 | Root of the squares of the sums of the differences between
    predicted counts and the actual counts |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| L2 错误 | L2 | 预测计数与实际计数之间差异平方和的平方根 |'
- en: '| Intersection over Union | IoU | A metric that evaluates how similar the predicted
    bounding box is to the ground truth bounding box.  by dividing the area of overlap
    between the predicted and the ground truth boxes, by the area of their union.
    |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| 交并比 | IoU | 一种评估预测边界框与实际边界框的相似性的指标，通过将预测框和实际框重叠区域的面积除以它们的并集面积来计算。 |'
- en: '| The maximum number | MaxN | MaxN, the maximum number of the target species
    in any one frame. |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| 最大数量 | MaxN | MaxN，任何一个帧中目标物种的最大数量。 |'
- en: '| Mean average precision | mAP | Depending on the detection difficulty, the
    mean $AP$ across all classes and/or total $IoU$ thresholds are used. |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| 平均精度 | mAP | 根据检测难度，使用所有类别和/或总$IoU$阈值的平均 $AP$。 |'
- en: '| Classification Error | CE | Is how often is the classifier incorrect and
    also known as "Misclassification Rate". $CE=(FP+FN)/(TP+TN+FP+FN)$ |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| 分类错误 | CE | 分类器错误的频率，也称为“错误分类率”。 $CE=(FP+FN)/(TP+TN+FP+FN)$ |'
- en: 4 Applications of Deep Learning in Underwater Fish Monitoring
  id: totrans-168
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 深度学习在水下鱼类监测中的应用
- en: 'Deep learning has been widely used in marine environments with applications
    spanning from deep-sea mineral exploration (Juliani and Juliani, [2021](#bib.bib48))
    to automatic vessel detection (Chen et al., [2019](#bib.bib15)). However, we confine
    the scope of this paper to only marine fish image processing, which typically
    includes four tasks of classification, counting, localization, and segmentation
    of underwater fish images, as shown in Fig. [5](#S3.F5 "Figure 5 ‣ 3.8 Deploying
    the model ‣ 3 Developing Deep Learning Models ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey").'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习已广泛应用于海洋环境，从深海矿产勘探（Juliani 和 Juliani，[2021](#bib.bib48)）到自动船只检测（Chen 等，[2019](#bib.bib15)）。然而，我们将本文的范围限定于海洋鱼类图像处理，这通常包括四个任务：分类、计数、定位和分割水下鱼类图像，如图[5](#S3.F5
    "图 5 ‣ 3.8 部署模型 ‣ 3 开发深度学习模型 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")所示。 |
- en: Here, the goal is to assist the reader in understanding the similarities and
    differences across these tasks and their relevant DL models and techniques. We
    provide a background of what each task involves, what previous works have been
    published toward addressing it using deep learning, and synthesize the literature
    on each task.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，目标是帮助读者了解这些任务及其相关的深度学习模型和技术之间的相似性和差异。我们提供了每个任务的背景信息，探讨了之前在使用深度学习解决这些任务方面发表的工作，并综合了每个任务的文献。
- en: 4.1 Classification
  id: totrans-171
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 分类
- en: 'As its name infers, in visual processing, classification is the task of classifying
    images into different categories. There can be only two categories, i.e. a binary
    classification, in which the images are classified into two groups, e.g. "fish"
    and "no fish", depending on the presence or absence of fish in an image (e.g.
    Deepfish dataset described in the first row of Table [1](#S3.T1 "Table 1 ‣ 3.2
    Development framework ‣ 3 Developing Deep Learning Models ‣ Applications of Deep
    Learning in Fish Habitat Monitoring: A Tutorial and Survey")). The classification
    can also involve multiple "classes" or groups. For instance, consider assigning
    different underwater fish images into different groups based on the species (e.g.
    FishPak dataset in Table [1](#S3.T1 "Table 1 ‣ 3.2 Development framework ‣ 3 Developing
    Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey")) present in them.'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 正如其名称所示，在视觉处理中的分类任务是将图像分类到不同的类别中。可以只有两个类别，即二分类，将图像分类为两组，例如“鱼”和“非鱼”，具体取决于图像中是否存在鱼（例如，表[1](#S3.T1
    "表 1 ‣ 3.2 发展框架 ‣ 3 开发深度学习模型 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")中描述的Deepfish数据集）。分类也可以涉及多个“类别”或组。例如，考虑根据物种（例如表[1](#S3.T1
    "表 1 ‣ 3.2 发展框架 ‣ 3 开发深度学习模型 ‣ 深度学习在鱼类栖息地监测中的应用：教程和调查")中的FishPak数据集）将不同的水下鱼类图像分配到不同的组中。
- en: Consider a manual procedure, in which images in a dataset are compared and relative
    ones are classified based on similar features, but without necessarily knowing
    what you are searching for in advance. This is a difficult assignment as there
    could be thousands of images in the dataset. Moreover, many image classification
    tasks involve images of different objects. It rapidly becomes clear that an automatic
    system, such as a DNN, is required to complete this task quickly and efficiently.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑一种手动程序，其中数据集中图像的比较和相对分类是基于相似特征进行的，但不一定需要事先知道你在寻找什么。这是一个困难的任务，因为数据集中可能有成千上万的图像。此外，许多图像分类任务涉及不同对象的图像。显然，需要一个自动系统，如DNN，以便快速而高效地完成此任务。
- en: Classification is the most widely-used and -studied underwater image processing
    task using DL. In a previous work, we have covered the use of DNNs specifically
    for the task of underwater fish classification. We refer the reader to (Saleh
    et al., [2022](#bib.bib111)) for a comprehensive review of prior art on classification.
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 分类是使用深度学习（DL）进行水下图像处理任务中最广泛使用和研究的任务。在之前的工作中，我们已经涵盖了DNN在水下鱼类分类任务中的具体应用。我们建议读者参考（Saleh
    et al., [2022](#bib.bib111)）以获取关于分类的全面回顾。
- en: 4.2 Counting
  id: totrans-175
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 计数
- en: The purpose of the counting task is to predict the number of objects existing
    in an image or video. Object counting is a key part of the workflow in many major
    CV applications, such as traffic monitoring (Khazukov et al., [2020](#bib.bib51);
    Zhang et al., [2017](#bib.bib136)). In the context of marine application and fish
    monitoring, counting may be used to map distinct species and monitor fish populations
    for effective conservation. With the use of commercially available underwater
    cameras, data gathering can be done more comprehensively. It is, however, difficult
    to correctly count fish in underwater habitats. To perform effective counting,
    models must understand the diversity of the items in terms of posture, shape,
    dimension, and features, which makes them complex. Meanwhile, manual counting
    is very time-consuming, costly, and prone to human error.
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 计数任务的目的是预测图像或视频中存在的对象数量。对象计数是许多主要计算机视觉应用工作流的关键部分，如交通监控（Khazukov et al., [2020](#bib.bib51);
    Zhang et al., [2017](#bib.bib136)）。在海洋应用和鱼类监控的背景下，计数可以用来映射不同的物种并监测鱼类种群，以便有效保护。借助商业可用的水下摄像机，数据收集可以更全面。然而，在水下栖息地正确计数鱼类是很困难的。为了进行有效的计数，模型必须理解项目在姿势、形状、尺寸和特征上的多样性，这使得计数变得复杂。同时，人工计数非常耗时、昂贵且容易出错。
- en: 'DL affords a faster, less expensive, and more accurate alternative to the manual
    data processing methods currently employed to monitor and analyse fish counts.
    Table [3](#S4.T3 "Table 3 ‣ 4.2 Counting ‣ 4 Applications of Deep Learning in
    Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey") lists several of the recent DL techniques used for fish
    counting. Saleh et al. (Saleh et al., [2020a](#bib.bib108)) created a novel large-scale
    dataset of fish from 20 underwater habitats. They used Fully Convolutional Networks
    for several monitoring tasks including fish counting and reported a Mean Average
    Error (MAE) of $0.38\%$. DL has the potential to be a more accurate method for
    assessing fish abundance than humans, with results that are stable and transferable
    between survey locations. Ditria et al. (Ditria et al., [2021](#bib.bib22), [2020a](#bib.bib23),
    [2020b](#bib.bib24)) compared the accuracy and speed of DL algorithms for estimating
    fish population in underwater pictures and video recordings to human counterparts
    in order to test their efficacy and usability. In single image test datasets,
    a DL method performed $7.1\%$ better than human marine specialists and $13.4\%$
    better than citizen scientists. For video datasets, DL was better by $1.5\%$ and
    $7.8\%$ compared to marine and citizen scientists, respectively.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习提供了一种比目前用于监测和分析鱼类数量的手动数据处理方法更快、更便宜、更准确的替代方案。表[3](#S4.T3 "表3 ‣ 4.2 计数 ‣ 4
    水下鱼类监测中的深度学习应用 ‣ 鱼类栖息地监测中的深度学习应用：教程和调查")列出了几种最近用于鱼类计数的深度学习技术。Saleh 等（Saleh 等，[2020a](#bib.bib108)）创建了一个来自20个水下栖息地的大规模新数据集。他们使用全卷积网络进行包括鱼类计数在内的多个监测任务，并报告了$0.38\%$的均值绝对误差（MAE）。深度学习有潜力成为比人工更准确的鱼类丰度评估方法，其结果在调查地点之间稳定且可转移。Ditria
    等（Ditria 等，[2021](#bib.bib22)，[2020a](#bib.bib23)，[2020b](#bib.bib24)）比较了深度学习算法在水下图片和视频记录中估计鱼类数量的准确性和速度与人工对照的差异，以测试其有效性和可用性。在单图像测试数据集中，深度学习方法比人类海洋专家表现好$7.1\%$，比公民科学家表现好$13.4\%$。在视频数据集方面，深度学习分别比海洋专家和公民科学家好$1.5\%$和$7.8\%$。
- en: 'Table 3: Summary of recent DL research works performing the task of fish counting'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：最近深度学习研究工作的鱼类计数任务总结
- en: '| Article | DL Model | Framework | Data | Annotation/Pre-processing/Augmentation
    | Classes and Labels | Perf. Metric | Metric Value | Comparisons with other methods
    |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 深度学习模型 | 框架 | 数据 | 注释/预处理/数据增强 | 类别和标签 | 性能指标 | 指标值 | 与其他方法的比较 |'
- en: '| A realistic fish-habitat dataset to evaluate algorithms for underwater visual
    analysis Saleh et al. ([2020a](#bib.bib108)) | ResNet-50 CNN | Pytorch | Authors-created
    database containing 39,766 images for 20 habitats from remote coastal marine environments
    of tropical Australia and split to sub-dataset for four computer vision tasks:
    classification, counting, localization, and segmentation. | Each image was annotated
    by point-level and semantic segmentation labels | 20 classes of 20 different fish
    habitat. | MAE | 0.38 | NA |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 评估水下视觉分析算法的现实鱼类栖息地数据集 Saleh 等 ([2020a](#bib.bib108)) | ResNet-50 CNN | Pytorch
    | 作者创建的数据库，包含39,766张图像，涵盖来自热带澳大利亚远程沿海海域的20种栖息地，并分割成子数据集用于四个计算机视觉任务：分类、计数、定位和分割。
    | 每张图像都进行了点级和语义分割标签的注释 | 20种不同鱼类栖息地的20个类别。 | MAE | 0.38 | NA |'
- en: '| Annotated Video Footage for Automated Identification and Counting of Fish
    in Unconstrained Seagrass Habitats Ditria et al. ([2021](#bib.bib22)) | ResNet-50
    CNN | Pytorch | The dataset consists of 4,281 images and 9,429 annotations (9,304
    luderick, 125 bream) at the standard high resolution (1920 x 1080 p). | Each image
    was annotated by drawing a bounding box and segmentation mask | 2 classes of fish
    | F1 | 92% | NA |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| 用于在不受约束的海草栖息地中自动识别和计数鱼类的注释视频片段 Ditria 等 ([2021](#bib.bib22)) | ResNet-50
    CNN | Pytorch | 数据集包括4,281张图像和9,429个注释（9,304条luderick，125条bream），分辨率为标准高分辨率（1920
    x 1080 p）。 | 每张图像通过绘制边界框和分割掩码进行注释 | 2类鱼类 | F1 | 92% | NA |'
- en: '| Automating the Analysis of Fish Abundance Using Object Detection Optimizing
    Animal Ecology With Deep Learning Ditria et al. ([2020a](#bib.bib23)) | Mask R-CNN
    ResNet50 | Pytorch | Authors-created database containing 6,080 fish images from
    20 habitats from Tweed River Estuary in southeast Queensland | Each image was
    annotated by segmentation mask | 1 class of fish | F1 | Image (95.4%) Video (86.8%)
    | The computer’s performance in determining abundance was 7.1% better than human
    marine experts and 13.4% better than citizen scientists in single image test datasets,
    and 1.5% and 7.8% higher in video datasets, respectively. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| 使用目标检测自动化分析鱼类丰度：优化动物生态学与深度学习 Ditria et al. ([2020a](#bib.bib23)) | Mask R-CNN
    ResNet50 | Pytorch | 作者创建了一个包含6080张来自昆士兰州东南部Tweed河口20个栖息地的鱼类图像的数据库 | 每张图像通过分割掩模进行了注释
    | 1类鱼 | F1 | 图像 (95.4%) 视频 (86.8%) | 计算机在确定丰度方面比人类海洋专家高出7.1%，比公民科学家高出13.4%（在单图像测试数据集），在视频数据集中分别高出1.5%和7.8%。'
- en: '| Deep learning for automated analysis of fish abundance: the benefits of training
    across multiple habitats Ditria et al. ([2020b](#bib.bib24)) | Mask R-CNN ResNet50
    | Pytorch | Authors created five datasets, each consisting of 4700 annotated luderick,
    total of 23500 images | Each image was annotated by drawing a Polygonal segmentation
    masks around the region of interest (ROI) | 1 fish class | F1 | 87–92% | NA |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| 自动分析鱼类丰度的深度学习：跨多个栖息地训练的好处 Ditria et al. ([2020b](#bib.bib24)) | Mask R-CNN
    ResNet50 | Pytorch | 作者创建了五个数据集，每个数据集包含4700张注释的鲁德里克鱼图像，总共23500张图像 | 每张图像通过绘制多边形分割掩模围绕感兴趣区域（ROI）进行了注释
    | 1类鱼 | F1 | 图像 (95.4%) 视频 (86.8%) | NA |'
- en: '| Deep learning with self-supervision and uncertainty regularization to count
    fish in underwater images Tarling et al. ([2021](#bib.bib122)) | ResNet50 CNN
    | Tensorflow | Authors created a data set of 500 labelled sonar images from video
    sequences | Each image was annotated by dot annotation | 3 classes of fish according
    to number of fish | MAE | 0.30% | Comparison between DeepFish dataset 0.38% and
    authors’ benchmark result and their model 0.30%. |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| 使用自监督和不确定性正则化的深度学习来计数水下图像中的鱼类 Tarling et al. ([2021](#bib.bib122)) | ResNet50
    CNN | Tensorflow | 作者创建了一个包含500个标注声纳图像的数据集，这些图像来自视频序列 | 每张图像通过点标注进行了注释 | 根据鱼的数量划分的3类鱼
    | MAE | 0.30% | DeepFish数据集0.38%与作者基准结果和他们的模型0.30%的比较 |'
- en: '| Counting Fish and Dolphins in Sonar Images Using Deep Learning Schneider
    and Zhuang ([2020](#bib.bib115)) | CNN | NA | Authors created a data set of 143
    labeled sonar images from the Amazon River | Each image was annotated by counting
    number of fishes | 35 classes for fish and 4 for dolphin | MSE | Fish 2.11% Dolphins
    0.133% | Comparing four Network Architectures, DenseNet201, InceptionNetV2, Xception,
    and MobileNetV2 |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度学习在声纳图像中计数鱼类和海豚 Schneider 和 Zhuang ([2020](#bib.bib115)) | CNN | NA |
    作者创建了一个包含143张标注声纳图像的数据集，这些图像来自亚马逊河 | 每张图像通过计算鱼的数量进行了注释 | 35类鱼和4类海豚 | MSE | 鱼2.11%
    海豚0.133% | 比较四种网络架构：DenseNet201、InceptionNetV2、Xception和MobileNetV2 |'
- en: '| Counting Fish in Sonar Images Liu et al. ([2018](#bib.bib80)) | CNN | NA
    | Authors created a dataset of 537 labelled sonar images from video sequences
    | Each image was annotated by dot annotation | 1 class of fish | RMSE | 16.48%
    | Comparison with other state-of-the-art approaches |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| 在声纳图像中计数鱼类 Liu et al. ([2018](#bib.bib80)) | CNN | NA | 作者创建了一个包含537个标注声纳图像的数据集，这些图像来自视频序列
    | 每张图像通过点标注进行了注释 | 1类鱼 | RMSE | 16.48% | 与其他最先进方法的比较 |'
- en: '| Assessing fish abundance from underwater video using deep neural networks
    Mandal et al. ([2018](#bib.bib84)) | Faster R-CNN | Caffe | Authors created a
    dataset of 4909 labelled images from video sequences | Each image was annotated
    by drawing a bounding box | 50 classes from 50 Different fish habitat. | mAP |
    82.4% | NA |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度神经网络评估水下视频中的鱼类数量 Mandal et al. ([2018](#bib.bib84)) | Faster R-CNN |
    Caffe | 作者创建了一个包含4909个标注图像的数据集，这些图像来自视频序列 | 每张图像通过绘制边界框进行了注释 | 来自50种不同鱼类栖息地的50个类别
    | mAP | 82.4% | NA |'
- en: Despite this high potential, DL has not been thoroughly investigated for counting
    underwater fish. One possible reason for the lack of comprehensive research for
    fish counting is the scarcity of large publicly available underwater fish datasets.
    In addition, properly annotating fish datasets to train robust DL models is time-prohibitive
    and expensive. Although the underwater fish counting is limited in the literature,
    several previous works have advanced the field in this area. For instance, Tarling
    et al. (Tarling et al., [2021](#bib.bib122)) created a novel dataset of sonar
    video footage of mullet fish labelled manually with point annotations and developed
    a density-based DL model to count fish from sonar images. They counted fish by
    using a regression method (Xue et al., [2016](#bib.bib134)) and achieved a MAE
    of $0.30\%$. Other researchers (Schneider and Zhuang, [2020](#bib.bib115); Liu
    et al., [2018](#bib.bib80)) used sonar images as well because they present substantially
    different visual characteristics compared to natural images. Counting fish in
    sonar images, however, is substantially different from counting fish in underwater
    video surveillance (Mandal et al., [2018](#bib.bib84)). Unlike natural images,
    sonar images present unique visual characteristics and are in lower resolution
    due to the specific imaging forming principle.
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管具有很高的潜力，但深度学习（DL）在水下鱼类计数方面尚未得到彻底研究。鱼类计数研究不全面的一个可能原因是缺乏大规模公开的水下鱼类数据集。此外，为了训练稳健的DL模型，正确标注鱼类数据集既耗时又昂贵。虽然水下鱼类计数在文献中有限，但之前的几项工作在这一领域取得了进展。例如，Tarling等人（Tarling
    et al., [2021](#bib.bib122)）创建了一个新的鱼类声呐视频数据集，手动标注了点注释，并开发了一种基于密度的DL模型来从声呐图像中计数鱼类。他们使用回归方法（Xue
    et al., [2016](#bib.bib134)）进行计数，达到了$0.30\%$的平均绝对误差（MAE）。其他研究人员（Schneider和Zhuang,
    [2020](#bib.bib115)；Liu et al., [2018](#bib.bib80)）也使用了声呐图像，因为这些图像与自然图像相比，视觉特征有显著不同。然而，在声呐图像中计数鱼类与在水下视频监控中计数鱼类有实质性区别（Mandal
    et al., [2018](#bib.bib84)）。与自然图像不同，声呐图像由于特定的成像原理，呈现出独特的视觉特征，并且分辨率较低。
- en: 'Using DL, a computer can be taught to identify fish in underwater images, thus
    eliminating the subjectivity of humans in counting fish. However, its use for
    fish population and count analysis is dependent on the model performance on a
    set of well-defined performance metrics and parameters, which is in itself a challenge.
    In section [3](#S3 "3 Developing Deep Learning Models ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey"), we discussed how one can
    train high-performance DL models, how the use of the current DL pipeline (and
    other methodologies) can be improved, and how future DL models can be designed
    for better assessing fish population including their abundance and their location,
    which is the subject of the next subsection.'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
  zh: '使用深度学习（DL），计算机可以被教会识别水下图像中的鱼类，从而消除人工计数鱼类的主观性。然而，其在鱼类种群和计数分析中的应用依赖于模型在一组定义明确的性能指标和参数上的表现，这本身就是一项挑战。在第[3](#S3
    "3 Developing Deep Learning Models ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey")节中，我们讨论了如何训练高性能的DL模型、如何改进当前DL流程（及其他方法）的使用，以及如何设计未来的DL模型以更好地评估鱼类种群，包括其丰度和位置，这是下一小节的主题。'
- en: 4.3 Localization
  id: totrans-190
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3 本地化
- en: Object localization is an essential task in CV, where the goal is to locate
    all instances of specified objects (e.g. fish, aquatic plants and coral reef)
    in images. Marine scientists assess the relative abundance of fish species in
    their environments regularly and track population variations. Various CV-based
    fish sample methods in underwater videos have been offered as an alternative to
    this tedious manual assessment. Though, there is no perfect method for automated
    fish localization. This is mostly owing to the difficulties that underwater videos
    bring, such as illumination fluctuations, fish movements, vibrant backgrounds,
    shape deformations, and variety of fish species.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
  zh: 目标本地化是计算机视觉（CV）中的一项重要任务，其目标是在图像中定位所有指定对象的实例（例如鱼类、水生植物和珊瑚礁）。海洋科学家定期评估其环境中鱼类物种的相对丰度，并跟踪种群变化。各种基于CV的鱼类样本方法在水下视频中被提出，作为这种繁琐人工评估的替代方法。然而，目前还没有完美的自动化鱼类本地化方法。这主要是由于水下视频带来的困难，例如光照波动、鱼类运动、背景复杂、形状变形和鱼类物种多样性。
- en: 'To address these issues, several research works have been carried out, which
    are listed in Table [4](#S4.T4 "Table 4 ‣ 4.3 Localization ‣ 4 Applications of
    Deep Learning in Underwater Fish Monitoring ‣ Applications of Deep Learning in
    Fish Habitat Monitoring: A Tutorial and Survey"). Saleh et al. (Saleh et al.,
    [2020a](#bib.bib108)) have developed a fully convolutional neural network that
    performs localizing of fish in realistic fish-habitat images with a high accuracy.
    Jalal et al. (Jalal et al., [2020](#bib.bib45)) introduced a hybrid method based
    on motion-based feature extraction that combines optical flow (Beauchemin and
    Barron, [1995](#bib.bib7)) and Gaussian mixture models (Zivkovic and van der Heijden,
    [2006](#bib.bib142)) with the YOLO deep learning technique (Chaudhari et al.,
    [2020](#bib.bib13)) to identify and categorise fish in unconstrained underwater
    videos using temporal information. They achieved fish detection F-scores of $95.47\%$
    and $91.2\%$ on LifeCLEF 2015 benchmark (Joly et al., [2014](#bib.bib47)) and
    their own dataset, respectively. Gaussian mixture is an unsupervised generative
    modelling approach that may be used to learn first and second order statistical
    estimates of input data features (Zivkovic and van der Heijden, [2006](#bib.bib142)).
    Within an overall population, this is used to indicate Normally Distributed subpopulations.
    The weakness of Gaussian mixture is when trained on videos with some fish but
    no pure background, the fish are modelled as background as well, resulting in
    misdetections in subsequent video frames (Salman et al., [2019](#bib.bib112)).
    In order to compensate for the Gaussian mixture’s weakness, optical flow can be
    used to extract features which are solely caused by underwater video motion. The
    pattern of apparent motion of objects, surfaces, and edges in a visual scene generated
    by the relative motion of an observer and a scene is known as optic flow (Beauchemin
    and Barron, [1995](#bib.bib7)).'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: '为了解决这些问题，已经进行了几项研究工作，见表 [4](#S4.T4 "Table 4 ‣ 4.3 Localization ‣ 4 Applications
    of Deep Learning in Underwater Fish Monitoring ‣ Applications of Deep Learning
    in Fish Habitat Monitoring: A Tutorial and Survey")。Saleh 等人（Saleh et al., [2020a](#bib.bib108)）开发了一种全卷积神经网络，在逼真的鱼类栖息地图像中具有高精度地定位鱼类。Jalal
    等人（Jalal et al., [2020](#bib.bib45)）提出了一种基于运动特征提取的混合方法，该方法将光流（Beauchemin and Barron,
    [1995](#bib.bib7)）和高斯混合模型（Zivkovic and van der Heijden, [2006](#bib.bib142)）与
    YOLO 深度学习技术（Chaudhari et al., [2020](#bib.bib13)）相结合，利用时间信息识别和分类水下视频中的鱼类。他们在 LifeCLEF
    2015 基准（Joly et al., [2014](#bib.bib47)）和他们自己的数据集上分别达到了 $95.47\%$ 和 $91.2\%$ 的鱼类检测
    F 值。高斯混合是一种无监督生成建模方法，可用于学习输入数据特征的一阶和二阶统计估计（Zivkovic and van der Heijden, [2006](#bib.bib142)）。在总体群体中，这用于指示正态分布的子群体。高斯混合的弱点是，当在某些鱼类存在但没有纯背景的视频上进行训练时，鱼类也被建模为背景，从而导致后续视频帧中的误检测（Salman
    et al., [2019](#bib.bib112)）。为了弥补高斯混合的弱点，可以使用光流来提取仅由水下视频运动引起的特征。由观察者和场景相对运动产生的视觉场景中物体、表面和边缘的表观运动模式被称为光流（Beauchemin
    and Barron, [1995](#bib.bib7)）。'
- en: Knausgard et al. (Knausgård et al., [2021](#bib.bib55)) also implemented YOLO
    (Chaudhari et al., [2020](#bib.bib13)) for fish localization. To overcome their
    small training samples, they employed transfer learning (explained in the next
    Section). The YOLO technique achieved Mean Average Precision (mAP) of $86.96\%$
    on the Fish4Knowledge dataset (Giordano et al., [2016](#bib.bib29)). YOLO-based
    object detection systems have been also used in several other research to robustly
    localize and count fish (Jalal et al., [2020](#bib.bib45); Xu and Matzner, [2018](#bib.bib133);
    Knausgård et al., [2021](#bib.bib55)). To test how well Yolo could generalise
    to new datasets, (Xu and Matzner, [2018](#bib.bib133)) used it to localize fish
    in underwater video using three very different datasets. The model was trained
    using examples from only two of the datasets and then tested on examples from
    all three datasets. However, the resulting model could not recognise fish in the
    dataset that was not part of the training set.
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: Knausgård 等人（Knausgård et al., [2021](#bib.bib55)）也实现了 YOLO（Chaudhari et al.,
    [2020](#bib.bib13)）用于鱼类定位。为了克服训练样本少的问题，他们采用了迁移学习（将在下一节中解释）。YOLO 技术在 Fish4Knowledge
    数据集（Giordano et al., [2016](#bib.bib29)）上实现了 $86.96\%$ 的平均精度均值（mAP）。基于 YOLO 的物体检测系统还在其他几项研究中被用于稳健地定位和计数鱼类（Jalal
    et al., [2020](#bib.bib45); Xu and Matzner, [2018](#bib.bib133); Knausgård et
    al., [2021](#bib.bib55)）。为了测试 YOLO 对新数据集的泛化能力，（Xu and Matzner, [2018](#bib.bib133)）使用它在三个非常不同的数据集上进行水下视频中的鱼类定位。模型仅使用了两个数据集的示例进行训练，然后在所有三个数据集的示例上进行测试。然而，结果模型无法识别训练集之外的数据集中的鱼类。
- en: Other CNN models have also been adapted to robustly detect fish under a variety
    of benthic background and illumination conditions. For instance, (Villon et al.,
    [2016](#bib.bib123)) and ([Choi,](#bib.bib16) ) used GoogLeNet (Szegedy et al.,
    [2015a](#bib.bib120)), while (Labao and Naval, [2019a](#bib.bib63)) used an ensemble
    of Region-based Convolutional Neural Networks (Ren et al., [2015](#bib.bib103))
    that are linked in a cascade structure by Long Short-Term Memory networks (Hochreiter
    and Schmidhuber, [1997](#bib.bib35)). In addition, Inception (Szegedy et al.,
    [2015b](#bib.bib121)) and ResNet-50 (He et al., [2015](#bib.bib34)) were examined
    in (Zhuang et al., [2017](#bib.bib141)) for fish detection and recognition based
    on weakly-labelled images. Furthermore, (Han et al., [2020](#bib.bib33)) and (Li
    et al., [2015](#bib.bib75)) used Fast R-CNN (Region-based Convolutional Neural
    Network) (Ren et al., [2015](#bib.bib103)) to detect and count fish.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
  zh: 其他卷积神经网络模型也已被调整用于在各种底栖背景和光照条件下鲁棒地检测鱼。例如，（Villon 等， [2016](#bib.bib123)）和（[Choi,](#bib.bib16)）使用了
    GoogLeNet（Szegedy 等，[2015a](#bib.bib120)），而（Labao 和 Naval，[2019a](#bib.bib63)）使用了一个由区域卷积神经网络（Ren
    等，[2015](#bib.bib103)）组成的集成模型，这些网络通过长短期记忆网络（Hochreiter 和 Schmidhuber，[1997](#bib.bib35)）连接成级联结构。此外，（Szegedy
    等，[2015b](#bib.bib121)）的 Inception 和（He 等，[2015](#bib.bib34)）的 ResNet-50 在（Zhuang
    等，[2017](#bib.bib141)）中被用于基于弱标记图像的鱼检测和识别。此外，（Han 等，[2020](#bib.bib33)）和（Li 等，[2015](#bib.bib75)）使用了
    Fast R-CNN（区域卷积神经网络）（Ren 等，[2015](#bib.bib103)）来检测和计数鱼。
- en: 'Table [4](#S4.T4 "Table 4 ‣ 4.3 Localization ‣ 4 Applications of Deep Learning
    in Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") demonstrates that state-of-the-art methods
    (e.g. YOLO and Fast R-CNN) can achieve high accuracy in localization tasks. These
    methods generally train object detectors from a wide variety of training images
    (Felzenszwalb et al., [2010](#bib.bib26); Girshick et al., [2014](#bib.bib30))
    in a fully supervised manner. The drawback is that these models depend on instance-level
    annotations, e.g. tight bounding boxes need to be drawn around fish in training
    datasets. This is time-consuming and labour-intensive and make the use of DL in
    marine research very challenging, if not impossible. In Section [5.3.4](#S5.SS3.SSS4
    "5.3.4 Weakly-Supervised Learning ‣ 5.3 Dataset Limitation ‣ 5 Challenges in underwater
    fish monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A
    Tutorial and Survey") we discuss how this critical issue can be addressed using
    weakly supervised localization of objects, where only binary image-level labels
    showing the existence or absence of an object type are needed for training.'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: '表 [4](#S4.T4 "Table 4 ‣ 4.3 Localization ‣ 4 Applications of Deep Learning
    in Underwater Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey") 证明了最先进的方法（例如 YOLO 和 Fast R-CNN）可以在定位任务中实现高准确率。这些方法通常从各种训练图像（Felzenszwalb
    等，[2010](#bib.bib26); Girshick 等，[2014](#bib.bib30)）中完全监督地训练目标检测器。缺点是这些模型依赖于实例级别的注释，例如，需要在训练数据集中绘制紧密的边界框围绕鱼。这是耗时且劳动密集的，这使得在海洋研究中使用深度学习变得非常具有挑战性，甚至是不可能的。在第
    [5.3.4](#S5.SS3.SSS4 "5.3.4 Weakly-Supervised Learning ‣ 5.3 Dataset Limitation
    ‣ 5 Challenges in underwater fish monitoring ‣ Applications of Deep Learning in
    Fish Habitat Monitoring: A Tutorial and Survey") 节中，我们讨论了如何通过使用弱监督的物体定位来解决这一关键问题，其中只需要显示物体类型存在或不存在的二值图像级标签来进行训练。'
- en: Similar to fish classification, counting, and localization, fish segmentation,
    i.e. detecting the entire body of fish in an image is a critical task in marine
    research and applications. In the next subsection, we discuss how DL can be used
    to perform fish segmentation and how it is useful in marine research.
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于鱼的分类、计数和定位，鱼的分割，即检测图像中鱼的整个身体，是海洋研究和应用中的一项关键任务。在下一小节中，我们讨论了深度学习如何用于执行鱼的分割以及它在海洋研究中的重要性。
- en: 'Table 4: Summary of recent DL research works performing the task of fish localization'
  id: totrans-197
  prefs: []
  type: TYPE_NORMAL
  zh: 表 4：总结了近期在鱼的定位任务中应用深度学习的研究工作
- en: '| Article | DL Model | Framework | Data | Annotation/Pre-processing/Augmentation
    | Classes and Labels | Perf. Metric | Metric Value | Comparisons with other methods
    |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | 深度学习模型 | 框架 | 数据 | 注释/预处理/增强 | 类别和标签 | 性能指标 | 指标值 | 与其他方法的比较 |'
- en: '| Marine Animal Detection and Recognition with Advanced Deep Learning Models
    (Zhuang et al., [2017](#bib.bib141)) | ResNet-10 CNN | NA | The dataset is made
    of 73 videos from the public datasets Fish4Knowledge | Each image was annotated
    by drawing a bounding box | 1 class of fish | F1 | 0.07% | NA |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| 使用先进深度学习模型进行海洋动物检测和识别（Zhuang等，[2017](#bib.bib141)） | ResNet-10 CNN | NA |
    数据集由公共数据集Fish4Knowledge中的73个视频组成 | 每张图像通过绘制边界框进行了注释 | 1种鱼类 | F1 | 0.07% | NA |'
- en: '| Fish detection and species classification in underwater environments using
    deep learning with temporal information (Jalal et al., [2020](#bib.bib45)) | Yolo
    - CNN | TensorFlow | The dataset is made of two datasets 93 videos from LifeCLEF
    2015 fish dataset And an authors-created database containing 4418 videos | Each
    image was annotated by drawing a bounding box and species name | 15 classes of
    15 different fish species. | F1 | LCF-15 95.47% UWA 91.2% | Comparison with other
    state-of-the-art approaches |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度学习和时间信息进行水下环境中的鱼类检测和物种分类（Jalal等，[2020](#bib.bib45)） | Yolo - CNN | TensorFlow
    | 数据集由两个数据集组成，分别是LifeCLEF 2015鱼类数据集中的93个视频和一个作者创建的数据库，包含4418个视频 | 每张图像通过绘制边界框和物种名称进行了注释
    | 15种不同鱼类的15个类别。 | F1 | LCF-15 95.47% UWA 91.2% | 与其他先进方法的比较 |'
- en: '| Automatic fish detection in underwater videos by a deep neural network-based
    hybrid motion learning system (Salman et al., [2019](#bib.bib112)) | ResNet-152
    CNN | TensorFlow | The dataset is made of 110 videos from two public datasets
    Fish4Knowledge and LifeCLEF 2015 fish dataset | Each image was annotated by drawing
    a bounding box | 15 classes of 15 different fish species. | F1 | 87.44% and 80.02%
    respectively | NA |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| 通过基于深度神经网络的混合运动学习系统在水下视频中自动检测鱼类（Salman等，[2019](#bib.bib112)） | ResNet-152
    CNN | TensorFlow | 数据集由两个公共数据集中的110个视频组成，分别是Fish4Knowledge和LifeCLEF 2015鱼类数据集
    | 每张图像通过绘制边界框进行了注释 | 15种不同鱼类的15个类别。 | F1 | 分别为87.44%和80.02% | NA |'
- en: '| Temperate fish detection and classification: a deep learning based approach
    (Knausgård et al., [2021](#bib.bib55)) | YoloV3 - CNN | Pytorch | total of 27230
    images catalogued into 23 different species from the public datasets Fish4Knowledge
    | Each image was annotated by drawing a bounding box | 23 classes of 23 different
    fish species. | mAP | 86.96% | NA |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| 温带鱼类检测和分类：基于深度学习的方法（Knausgård等，[2021](#bib.bib55)） | YoloV3 - CNN | Pytorch
    | 总共有27230张图像，归类为来自公共数据集Fish4Knowledge的23种不同物种 | 每张图像通过绘制边界框进行了注释 | 23种不同鱼类的23个类别。
    | mAP | 86.96% | NA |'
- en: '| Underwater Fish Detection Using Deep Learning for Water Power Applications
    (Xu and Matzner, [2018](#bib.bib133)) | YoloV3 - CNN | Keras - TensorFlow | Authors-created
    database of underwater video sequences for a total of 70000 train/test frame |
    Each image was annotated by drawing a bounding box | 3 classes of fish | mAP |
    54.74% | NA |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度学习进行水下鱼类检测以用于水电应用（Xu和Matzner，[2018](#bib.bib133)） | YoloV3 - CNN | Keras
    - TensorFlow | 作者创建的水下视频序列数据库，总共70000帧用于训练/测试 | 每张图像通过绘制边界框进行了注释 | 3种鱼类 | mAP
    | 54.74% | NA |'
- en: '| Coral Reef Fish Detection and Recognition in Underwater Videos by Supervised
    Machine Learning: Comparison Between Deep Learning and HOG+SVM Methods (Villon
    et al., [2016](#bib.bib123)) | GoogLeNet CNN | NA | Authors-created database containing
    13000 fish thumbnails from videos | Each image was annotated by drawing a bounding
    box | 11 classes of 8 different fish species. | F1 | 98 % | Compare HOG+SVM With
    Deep Learning |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| 使用监督机器学习进行水下视频中的珊瑚礁鱼类检测和识别：深度学习与HOG+SVM方法的比较（Villon等，[2016](#bib.bib123)）
    | GoogLeNet CNN | NA | 作者创建的数据库，包含13000个来自视频的鱼类缩略图 | 每张图像通过绘制边界框进行了注释 | 11种不同鱼类的8个类别。
    | F1 | 98% | 比较HOG+SVM与深度学习 |'
- en: '| Fish identification in underwater video with deep convolutional neural network:
    SNUMedinfo at LifeCLEF fish task 2015 ([Choi,](#bib.bib16) ) | GoogLeNet CNN |
    NA | 20 videos from LifeCLEF 2015 fish dataset | Each image was annotated by drawing
    a bounding box | 15 classes of 15 different fish species. | AP | 81% | NA |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度卷积神经网络进行水下视频中的鱼类识别：SNUMedinfo在LifeCLEF鱼类任务2015中的表现（[Choi](#bib.bib16)）
    | GoogLeNet CNN | NA | LifeCLEF 2015鱼类数据集中的20个视频 | 每张图像通过绘制边界框进行了注释 | 15种不同鱼类的15个类别。
    | AP | 81% | NA |'
- en: '| Cascaded deep network systems with linked ensemble components for underwater
    fish detection in the wild (Labao and Naval, [2019a](#bib.bib63)) | RNN- LSTM
    | NA | Authors-created database containing 18 underwater video sequences for a
    total of 327 train/test frame | Each image was annotated by drawing a bounding
    box and species name | 1 class of fish | F1 | 67.76% | Comparison with R-CNN Baseline
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 具有链接的深度网络系统用于野外水下鱼类检测（Labao 和 Naval，[2019a](#bib.bib63)） | RNN-LSTM | NA
    | 作者创建的数据库包含18个水下视频序列，共327个训练/测试帧 | 每张图像通过绘制边界框和物种名称进行标注 | 1类鱼 | F1 | 67.76% |
    与 R-CNN 基线的比较 |'
- en: '| A realistic fish-habitat dataset to evaluate algorithms for underwater visual
    analysis (Saleh et al., [2020a](#bib.bib108)) | ResNet-50 CNN | Pytorch | Authors-created
    database containing 39,766 images for 20 habitats from remote coastal marine environments
    of tropical Australia and split to sub-dataset for classification, counting, localization,
    and segmentation. | Each image was annotated by point-level and semantic segmentation
    labels | 20 classes of 20 different fish habitat. | MAE | 0.38 | NA |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 评估水下视觉分析算法的现实鱼类栖息地数据集（Saleh 等，[2020a](#bib.bib108)） | ResNet-50 CNN | Pytorch
    | 作者创建的数据库包含39,766张图像，覆盖来自热带澳大利亚远程沿海海洋环境的20种栖息地，并拆分为子数据集用于分类、计数、定位和分割。 | 每张图像通过点级别和语义分割标签进行标注
    | 20种不同鱼类栖息地的20个类别。 | MAE | 0.38 | NA |'
- en: '| Marine Organism Detection and Classification from Underwater Vision Based
    on the Deep CNN Method (Han et al., [2020](#bib.bib33)) | VGG16 -RCNN | NA | The
    dataset is obtained from the video provided by the Underwater Robot Picking Contest,
    test set contains 8800 images. | Each image was annotated by drawing a bounding
    box | 3 classes of fish | mAP | 91.2% | NA |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '| 基于深度 CNN 方法的水下视觉海洋生物检测与分类（Han 等，[2020](#bib.bib33)） | VGG16-RCNN | NA | 数据集来源于水下机器人捡拾竞赛提供的视频，测试集包含8800张图像。
    | 每张图像通过绘制边界框进行标注 | 3类鱼 | mAP | 91.2% | NA |'
- en: 4.4 Segmentation
  id: totrans-209
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4 分割
- en: 'Semantic segmentation task is to predict a label from a set of pre-defined
    object classes for each pixel in an image (Shelhamer et al., [2017](#bib.bib116)).
    In the context of marine research, fish segmentation provides a visual representation
    of fish contour, which might be helpful for human expert visual verification or
    to estimate fish size and weight. Table [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation
    ‣ 4 Applications of Deep Learning in Underwater Fish Monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey") lists a number
    of research addressing the task of fish segmentation.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '语义分割任务是从一组预定义的物体类别中为图像中的每个像素预测标签（Shelhamer 等，[2017](#bib.bib116)）。在海洋研究的背景下，鱼类分割提供了鱼类轮廓的视觉表示，这可能有助于专家的视觉验证或估算鱼类的大小和重量。表
    [5](#S4.T5 "Table 5 ‣ 4.4 Segmentation ‣ 4 Applications of Deep Learning in Underwater
    Fish Monitoring ‣ Applications of Deep Learning in Fish Habitat Monitoring: A
    Tutorial and Survey") 列出了若干研究，涉及鱼类分割任务。'
- en: Saleh et al. (Saleh et al., [2020a](#bib.bib108)) developed a FCN model that
    performs fish Segmentation in realistic fish-habitat images with a high accuracy.
    Labao et al. (Labao and Naval, [2019b](#bib.bib64)) proposed a DL model that can
    simultaneously localize fish, estimate bounding boxes around them and segment
    them using a unified multi-task CNN in underwater videos. Unlike previous approaches
    (Qian et al., [2016](#bib.bib99); Wang and Kanwar, [2021](#bib.bib129)) that relied
    on motion information to identify fish body, their proposed method predicts fish
    object spatial coordinates and per-pixel segmentation using just video frames
    independent of motion information. Their suggested approach is more resilient
    to camera motions or jitters since it is not dependent on motion information,
    making it more suitable for processing underwater videos captured by Autonomous
    Underwater Vehicles (AUVs). Region Proposal Networks (RPN) (Ren et al., [2017](#bib.bib104))
    have been also used for fish segmentation in underwater videos (Alshdaifat et al.,
    [2020](#bib.bib3)). RPN is a FCN that generates boxes around identified objects
    and gives them confidence scores of belonging to a specific class, simultaneously.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: Saleh 等（Saleh 等，[2020a](#bib.bib108)）开发了一种 FCN 模型，该模型在现实的鱼类栖息地图像中进行鱼类分割，具有高精度。Labao
    等（Labao 和 Naval，[2019b](#bib.bib64)）提出了一种 DL 模型，该模型能够在水下视频中同时定位鱼类、估计其周围的边界框并进行分割，使用统一的多任务
    CNN。与以往依赖运动信息识别鱼体的方案（Qian 等，[2016](#bib.bib99)；Wang 和 Kanwar，[2021](#bib.bib129)）不同，他们提出的方法通过仅使用视频帧而不依赖运动信息来预测鱼对象的空间坐标和每像素分割。他们建议的方法对摄像机运动或抖动更具鲁棒性，因为它不依赖于运动信息，使其更适合处理由自主水下航行器（AUV）捕捉的水下视频。Region
    Proposal Networks（RPN）（Ren 等，[2017](#bib.bib104)）也被用于水下视频中的鱼类分割（Alshdaifat 等，[2020](#bib.bib3)）。RPN
    是一个 FCN，它在识别的对象周围生成框，并同时给出它们属于特定类别的置信度评分。
- en: 'Table 5: Summary of recent DL research works performing the task of fish segmentation'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 表 5：近期 DL 研究工作总结，涉及鱼类分割任务
- en: '| Article | DL Model | Framework | Data | Annotation/Pre-processing/Augmentation
    | Classes and Labels | Perf. Metric | Metric Value | Comparisons with other methods
    |'
  id: totrans-213
  prefs: []
  type: TYPE_TB
  zh: '| 文章 | DL 模型 | 框架 | 数据 | 注释/预处理/增强 | 类别和标签 | 性能指标 | 指标值 | 与其他方法的比较 |'
- en: '| A realistic fish-habitat dataset to evaluate algorithms for underwater visual
    analysis (Saleh et al., [2020a](#bib.bib108)) | ResNet-50 CNN | Pytorch | Authors-created
    database containing 39,766 images from 20 habitats from remote coastal marine
    environments of tropical Australia and split to sub-dataset for classification,
    counting and localization, and segmentation. | Each image was annotated by point-level
    and semantic segmentation labels | 20 classes of 20 Different fish habitat. |
    mIoU | 0.93% | NA |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 用于评估水下视觉分析算法的真实鱼类栖息地数据集（Saleh 等，[2020a](#bib.bib108)） | ResNet-50 CNN | Pytorch
    | 作者创建的数据库包含来自热带澳大利亚偏远沿海海洋环境的 20 个栖息地的 39,766 张图像，并拆分为用于分类、计数、定位和分割的子数据集。 | 每张图像都进行了点级和语义分割标签的标注
    | 20 类的 20 种不同鱼类栖息地。 | mIoU | 0.93% | 无 |'
- en: '| Weakly supervised underwater fish segmentation using affinity LCFCN (Laradji
    et al., [2021b](#bib.bib68)) | ResNet-CNN | Pytorch | Public DeepFish dataset
    (Saleh et al., [2020b](#bib.bib109)) | Each image was annotated by segmentation
    labels | 20 classes of 20 Different fish habitat | mIoU | 0.749% | NA |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '| 弱监督水下鱼类分割使用亲和 LCFCN（Laradji 等，[2021b](#bib.bib68)） | ResNet-CNN | Pytorch
    | 公开的 DeepFish 数据集（Saleh 等，[2020b](#bib.bib109)） | 每张图像都进行了分割标签的标注 | 20 类的 20
    种不同鱼类栖息地 | mIoU | 0.749% | 无 |'
- en: '| Simultaneous Localization and Segmentation of Fish Objects Using Multi-task
    CNN and Dense CRF (Labao and Naval, [2019b](#bib.bib64)) | ResNet-CNN | TensorFlow
    | Authors-created dataset containing 1525 images from ten 10 different sites in
    central Philippines | Each image was annotated by drawing a bounding box and segmentation
    labels | 1 class of fish | AP | 93.77% | NA |'
  id: totrans-216
  prefs: []
  type: TYPE_TB
  zh: '| 使用多任务 CNN 和稠密 CRF 进行鱼类目标的同时定位与分割（Labao 和 Naval，[2019b](#bib.bib64)） | ResNet-CNN
    | TensorFlow | 作者创建的数据集包含来自菲律宾中部 10 个不同地点的 1525 张图像 | 每张图像都通过绘制边界框和分割标签进行标注 |
    1 类鱼类 | AP | 93.77% | 无 |'
- en: '| Semantic Segmentation of Underwater Imagery: Dataset and Benchmark (Islam
    et al., [2020](#bib.bib43)) | VGG16 -CNN | Keras - TensorFlow | Authors-created
    dataset containing 1525 images of 8 object categories | Each image was annotated
    by segmentation labels | 8 classes of 8 different object categories. | mIoU |
    84.14% | NA |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 水下图像的语义分割：数据集和基准（Islam 等，[2020](#bib.bib43)） | VGG16 -CNN | Keras - TensorFlow
    | 作者创建的数据集包含 1525 张 8 类目标的图像 | 每张图像都进行了分割标签的标注 | 8 类的 8 种不同目标类别。 | mIoU | 84.14%
    | 无 |'
- en: '| DPANet: Dual Pooling-aggregated Attention Network for fish segmentation (Zhang
    et al., [2022](#bib.bib137)) | ResNet-50 CNN | Pytorch, | Two public datasets
    DeepFish (Saleh et al., [2020b](#bib.bib109)) and SUIM (Islam et al., [2020](#bib.bib43))
    | Each image was annotated by segmentation labels | 20 classes: 20 Different fish
    habitat. | mIoU | 91.08%, 85.39% | Comparison with other state-of-the-art approaches
    |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '| DPANet：用于鱼类分割的双重池化聚合注意力网络（Zhang 等， [2022](#bib.bib137)） | ResNet-50 CNN |
    Pytorch | 两个公共数据集 DeepFish（Saleh 等， [2020b](#bib.bib109)）和 SUIM（Islam 等， [2020](#bib.bib43)）
    | 每张图像都标注了分割标签 | 20 类：20 种不同的鱼类栖息地。 | mIoU | 91.08%，85.39% | 与其他最先进方法的比较 |'
- en: '| Weakly-Labelled semantic segmentation of fish objects in underwater videos
    using a deep residual network (Labao and Naval, [2017](#bib.bib62)) | ResNet-FCN
    | TensorFlow | Authors-created dataset containing several underwater videos from
    six different sites in Verde Island Passage, Philippines. | Each image was annotated
    with weakly-labelled ground truth derived from a motion-based background subtraction
    (BGS) | 1 class of fish | AP | 65.91% | NA |'
  id: totrans-219
  prefs: []
  type: TYPE_TB
  zh: '| 使用深度残差网络进行水下视频中鱼类对象的弱标签语义分割（Labao 和 Naval， [2017](#bib.bib62)） | ResNet-FCN
    | TensorFlow | 作者创建的数据集包含来自菲律宾 Verde Island Passage 六个不同地点的多个水下视频。 | 每张图像都使用来自基于运动的背景减除（BGS）的弱标签真实数据进行了标注
    | 1 类鱼 | AP | 65.91% | NA |'
- en: '| Improved deep learning framework for fish segmentation in underwater videos
    (Alshdaifat et al., [2020](#bib.bib3)) | ResNet-CNN | TensorFlow | Two datasets
    extracted from the Fish4Knowledge to produce 2000 frames | Each image was annotated
    by drawing a bounding box and segmentation labels | 15 classes of 15 different
    fish species. | AP | 95.20% | NA |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '| 用于水下视频中的鱼类分割的改进深度学习框架（Alshdaifat 等， [2020](#bib.bib3)） | ResNet-CNN | TensorFlow
    | 从 Fish4Knowledge 提取的两个数据集生成 2000 帧 | 每张图像都通过绘制边界框和分割标签进行了标注 | 15 类：15 种不同的鱼类。
    | AP | 95.20% | NA |'
- en: Computational efficiency is essential in the autonomy pipeline of visually-guided
    underwater robots. For this reason, (Islam et al., [2020](#bib.bib43)) developed
    SUIM-Net, a fully-convolutional encoder-decoder model that balances the trade-off
    between performance and computational efficiency. On the other hand, for higher
    performance, (Zhang et al., [2022](#bib.bib137)) proposed Dual Pooling-aggregated
    Attention Network (DPANet) to adaptively capture long-range dependencies through
    a computationally friendly manner to enhance feature representation and improve
    not only the segmentation performance, but also its computational resources and
    time.
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 计算效率在视觉引导的水下机器人自主系统中至关重要。为此，（Islam 等， [2020](#bib.bib43)）开发了 SUIM-Net，一种全卷积编码器-解码器模型，平衡了性能和计算效率之间的权衡。另一方面，为了获得更高的性能，（Zhang
    等， [2022](#bib.bib137)）提出了双重池化聚合注意力网络（DPANet），通过计算友好的方式自适应地捕捉长距离依赖关系，以增强特征表示并提高分割性能，同时优化计算资源和时间。
- en: 'All previously discussed models use fully-supervised methods that require a
    large amount of pixel-wise annotations, which is very time-consuming and expensive,
    because a human expert must segment and label, for example, each fish in an image.
    To overcome this serious issue, weakly-supervised semantic segmentation models
    are used. These models do not need to be trained with pixel-wise annotation (Rajchl
    et al., [2016](#bib.bib101)). However, due to a lower level of supervision, training
    weakly-supervised semantic segmentation models is often a more challenging task.
    Applying weakly labelled ground truth derived from motion-based adaptive Mixture
    of Gaussians Background Subtraction, (Labao and Naval, [2017](#bib.bib62)) managed
    to get an average precision of 65.91%, and an average recall of 83.99%. Recently,
    several other weakly-supervised methods have been introduced to overcome the cost
    of a large amount of pixel-wise annotations. These new methods include bounding
    boxes (Khoreva et al., [2017](#bib.bib52); Dai et al., [2015](#bib.bib19)), scribbles
    (Lin et al., [2016](#bib.bib77)), points (Laradji et al., [2021b](#bib.bib68);
    Bearman et al., [2016](#bib.bib6)), and even image-level annotation (Pathak et al.,
    [2015](#bib.bib96); Wang et al., [2018](#bib.bib126); Ahn and Kwak, [2018](#bib.bib2);
    Huang et al., [2018](#bib.bib39); Wei et al., [2018](#bib.bib130)). Since weakly-supervised
    methods are integral to success of important DL-based segmentation tasks, in Section
    [5.3](#S5.SS3 "5.3 Dataset Limitation ‣ 5 Challenges in underwater fish monitoring
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey"),
    we discuss them further.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: 之前讨论的所有模型都使用了完全监督的方法，这需要大量的像素级标注，这非常耗时且昂贵，因为人类专家必须对图像中的每条鱼进行分割和标注。为了克服这一严重问题，使用了弱监督语义分割模型。这些模型不需要进行像素级标注训练（Rajchl
    等，[2016](#bib.bib101)）。然而，由于监督水平较低，训练弱监督语义分割模型通常是一项更具挑战性的任务。应用从基于运动的自适应高斯混合背景减除法（Labao
    和 Naval，[2017](#bib.bib62)）获得的弱标注真值，成功获得了65.91%的平均精度和83.99%的平均召回率。最近，出现了几种其他的弱监督方法，以克服大量像素级标注的成本。这些新方法包括边界框（Khoreva
    等，[2017](#bib.bib52); Dai 等，[2015](#bib.bib19)）、涂鸦（Lin 等，[2016](#bib.bib77)）、点（Laradji
    等，[2021b](#bib.bib68); Bearman 等，[2016](#bib.bib6)），甚至图像级标注（Pathak 等，[2015](#bib.bib96);
    Wang 等，[2018](#bib.bib126); Ahn 和 Kwak，[2018](#bib.bib2); Huang 等，[2018](#bib.bib39);
    Wei 等，[2018](#bib.bib130)）。由于弱监督方法对于深度学习基础的分割任务至关重要，在第[5.3节](#S5.SS3 "5.3 数据集限制
    ‣ 5 水下鱼类监测中的挑战 ‣ 深度学习在鱼类栖息地监测中的应用：教程与调查")中，我们将进一步讨论这些方法。
- en: In the previous subsections, we discussed how DL is useful in a number of key
    applications in fish habitat monitoring. In the following Section, we discuss
    the many challenges on the way of developing DL models for such applications.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 在前面的子章节中，我们讨论了深度学习（DL）在鱼类栖息地监测中几个关键应用的作用。在接下来的章节中，我们将讨论在开发这些应用的深度学习模型时所面临的诸多挑战。
- en: 5 Challenges in underwater fish monitoring
  id: totrans-224
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 水下鱼类监测中的挑战
- en: .
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: .
- en: Underwater fish monitoring presents a series of challenges for DL, which have
    been the focus of many research works. In this section, we first introduce the
    major enviromental challenges faced when developing underwater fish monitoring
    models. We then show that one of the approaches to properly address these enviromental
    challenges is to use DL. However, DL training for fish monitoring has its own
    challenges, which will be discussed in details.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 水下鱼类监测对深度学习提出了一系列挑战，这些挑战已成为许多研究工作的重点。在本节中，我们首先介绍了开发水下鱼类监测模型时面临的主要环境挑战。然后，我们展示了应对这些环境挑战的一种方法是使用深度学习。然而，鱼类监测的深度学习训练也有其自身的挑战，这些将在详细讨论中展开。
- en: 5.1 Environmental challenges
  id: totrans-227
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 环境挑战
- en: 'In order to work in underwater environments, monitoring models must be able
    to recognize objects and scenes in complex, non-trivial backgrounds. This presents
    both a challenge in the development and training of these models and in robustly
    testing them. The main environmental challenges in underwater visual fish monitoring
    can be categorized as follows:'
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了在水下环境中工作，监测模型必须能够识别复杂且非平凡背景中的物体和场景。这既是这些模型开发和训练的挑战，也是对它们进行稳健测试的挑战。水下视觉鱼类监测中的主要环境挑战可以归纳如下：
- en: '1.'
  id: totrans-229
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The environment is noisy including very large lighting variation. An object
    viewed from a distance is much less bright than a close-up object. These problems
    become more acute when the background is not uniform.
  id: totrans-230
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 环境噪声大，包括非常大的光照变化。从远处看到的物体比近处的物体要暗得多。当背景不均匀时，这些问题会变得更加严重。
- en: '2.'
  id: totrans-231
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: Underwater scenes are highly dynamic, i.e. the scene’s content and objects change
    very quickly. The background can change from being completely occluded to being
    visible and vice versa.
  id: totrans-232
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 水下场景高度动态，即场景的内容和物体变化非常快。背景可以从完全遮挡变为可见，反之亦然。
- en: '3.'
  id: totrans-233
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: Depth and distance perception can be incorrect due to refraction. This is more
    severe for short distances.
  id: totrans-234
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 深度和距离感知可能因折射而不正确。这在短距离下更为严重。
- en: '4.'
  id: totrans-235
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Images are affected by water turbidity, light scattering, shading, and multiple
    scattering.
  id: totrans-236
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图像受到水体浑浊、光散射、阴影和多重散射的影响。
- en: '5.'
  id: totrans-237
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: The image data are frequently under-sampled due to low-resolution cameras and
    power constraints underwater.
  id: totrans-238
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 由于低分辨率摄像头和水下电力限制，图像数据经常被欠采样。
- en: One of the main approaches used in literature to address these challenges is
    for the monitoring models to use hand-crafted features (Rova et al., [2007](#bib.bib106);
    Hu et al., [2012](#bib.bib37); Fouad et al., [2014](#bib.bib27); Huang et al.,
    [2014](#bib.bib38); Chuang et al., [2016](#bib.bib17); Ogunlana et al., [2015](#bib.bib92);
    Hossain et al., [2016](#bib.bib36); Wang et al., [2017](#bib.bib127); Islam et al.,
    [2019](#bib.bib42)). Hand-crafted features are defined by a human to describe
    a fish image. For example, a low-level feature can be the histogram of a texture
    or a Gabor filter response. As a more complex and representative feature, a mid-level
    feature can be a Scale-Invariant Feature Transform (SIFT) (Lindeberg, [2012](#bib.bib79)),
    or a Histogram of Oriented Gradient (HOG) (Dalal and Triggs, [2005](#bib.bib20)).
    However, human-defined features cannot be applied to other datasets, and the definition
    of a human-defined feature is a time-consuming task, which restricts real-time
    detection and requires manual effort. Moreover, hand-crafted features are limited
    by human experiences, which may contain noise and are difficult to design. For
    example, a SIFT descriptor doesn’t work well with lighting changes and blur.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中应对这些挑战的主要方法之一是让监控模型使用手工设计的特征（Rova 等，[2007](#bib.bib106)；Hu 等，[2012](#bib.bib37)；Fouad
    等，[2014](#bib.bib27)；Huang 等，[2014](#bib.bib38)；Chuang 等，[2016](#bib.bib17)；Ogunlana
    等，[2015](#bib.bib92)；Hossain 等，[2016](#bib.bib36)；Wang 等，[2017](#bib.bib127)；Islam
    等，[2019](#bib.bib42)）。手工设计的特征是由人定义的，用于描述鱼类图像。例如，低级特征可以是纹理的直方图或 Gabor 滤波器的响应。作为更复杂和具有代表性的特征，中级特征可以是尺度不变特征变换（SIFT）（Lindeberg，[2012](#bib.bib79)），或方向梯度直方图（HOG）（Dalal
    和 Triggs，[2005](#bib.bib20)）。然而，人为定义的特征不能应用于其他数据集，而且定义这些特征是一个耗时的任务，这限制了实时检测，并需要人工努力。此外，手工设计的特征受到人类经验的限制，可能包含噪声，并且设计起来困难。例如，SIFT
    描述符在光照变化和模糊的情况下表现不佳。
- en: Therefore, a fish image is transformed into a feature space that a computer
    can understand. The feature space is often based on a combination of low-level
    image features (for example, colour distribution and gradient), and other features
    in the image such as edges, shapes, and textures. Models using hand-crafted features,
    however, do not perform well under varying environmental conditions, and the feature
    space cannot be easily or robustly created. Additionally, the features created
    are too low-level and cannot be easily used for processing images from different
    sources.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，鱼类图像被转化为计算机可以理解的特征空间。特征空间通常基于低级图像特征的组合（例如，颜色分布和梯度），以及图像中的其他特征，如边缘、形状和纹理。然而，使用手工设计特征的模型在环境条件变化下表现不佳，特征空间不能被轻易或稳健地创建。此外，创建的特征过于低级，无法轻松用于处理来自不同来源的图像。
- en: An alternative way to build prediction models capable of working in the presence
    of these significant environmental challenges is to use DNNs. However, training
    effective DNNs require resolving some other challenges, which we discuss in the
    below subsections. We also describe some of the approaches in literature addressing
    them. The reviewed approaches in addressing these common challenges can provide
    a quick reference for future researchers developing DL-based fish monitoring models.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 在面对这些显著环境挑战时，构建能够进行预测的模型的另一种方法是使用深度神经网络（DNN）。然而，训练有效的DNN需要解决一些其他挑战，我们将在以下小节中讨论这些挑战。我们还描述了文献中解决这些问题的一些方法。回顾这些应对常见挑战的方法可以为未来开发基于深度学习的鱼类监测模型的研究人员提供快速参考。
- en: 5.2 Model Generalisation
  id: totrans-242
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 模型泛化
- en: Improving the generalization abilities of DNNs is one of the most difficult
    tasks in DL. Generalization refers to the gap between a model’s performance on
    previously observed data (i.e training data) and data it has never seen before
    (i.e testing data). This is a fundamental problem, with implications for any applications
    using deep neural networks to process image data, videos, etc. This challenge
    is even more pronounced when more difficult tasks such as fish recognition in
    underwater environments.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 提高深度神经网络（DNN）的泛化能力是深度学习中最困难的任务之一。泛化指的是模型在以前观察过的数据（即训练数据）和从未见过的数据（即测试数据）上的表现差距。这是一个根本性问题，对使用深度神经网络处理图像数据、视频等的任何应用都有影响。当面对更困难的任务，例如水下环境中的鱼类识别时，这一挑战尤为突出。
- en: Generalization problem happens usually because during training the network over-fits
    to the training data. In other words, the weights of the network are adapted to
    produce a response that is best suited for reproducing the training examples.
    During testing, the network produces a response that is a compromise between the
    different training examples. This mismatch is a common cause of poor performance
    on test data, which is often referred to as a network over-fitting to the training
    data, even when the network has been trained for many epochs. The reason it occurs
    is that the network "memorizes" the training data during the training. The training
    data can become quite large, consisting of hundreds of thousands or millions of
    examples. This makes the issue of network over-fitting quite significant. In the
    last few years, there has been significant research efforts toward solving the
    problem of over-fitting to improve model generalization.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 泛化问题通常发生是因为在训练过程中网络对训练数据进行了过拟合。换句话说，网络的权重被调整以产生最适合重现训练样本的响应。在测试过程中，网络产生的响应是不同训练样本之间的折中。这种不匹配是测试数据表现不佳的常见原因，这通常被称为网络对训练数据的过拟合，即使网络已经训练了很多轮次。这种现象的发生原因是网络在训练过程中“记住”了训练数据。训练数据可能非常庞大，包含成千上万或百万个样本。这使得网络过拟合的问题变得相当重要。在过去几年里，已经进行了大量的研究工作来解决过拟合问题，以改善模型泛化能力。
- en: Previous works have shown that it is possible to prevent the network from over-fitting
    using techniques called regularisation (Kukačka et al., [2017](#bib.bib60)). There
    are also some theoretical techniques to make the network more robust to training
    data. Below, we provide a brief overview of some of these techniques and how they
    have been applied to solve the problem of deep network over-fitting to training
    data, to improve generalisation in DL.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 之前的研究表明，可以使用称为正则化的技术来防止网络过拟合（Kukačka 等， [2017](#bib.bib60)）。还有一些理论技术可以使网络对训练数据更加鲁棒。以下，我们简要概述了这些技术中的一些以及它们如何应用于解决深度网络对训练数据过拟合的问题，以提高深度学习的泛化能力。
- en: •
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Regularisation Term: It is hypothesised that neural networks with fewer weight
    matrices can result in simpler models with the same capability as the complete
    model. A regularisation term is, therefore, added to the model loss function to
    remove some of the weight matrices components. The most popular methods of regularisation
    are L1 and L2. For example, Tarling et al. (Tarling et al., [2021](#bib.bib122))
    showed that incorporating uncertainty regularisation improves performance of their
    multi-task network with ResNet-50 (He et al., [2015](#bib.bib34)) backend to count
    fish in underwater images.'
  id: totrans-247
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 正则化项：假设具有较少权重矩阵的神经网络可以生成与完整模型具有相同能力的更简单模型。因此，正则化项被添加到模型损失函数中，以去除一些权重矩阵组件。最常见的正则化方法是L1和L2。例如，Tarling等人（Tarling
    et al., [2021](#bib.bib122)）展示了引入不确定性正则化提高了他们的多任务网络的性能，该网络使用ResNet-50（He et al.,
    [2015](#bib.bib34)）作为后台来计算水下图像中的鱼类数量。
- en: •
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Batch normalisation: Introduced in Section [2.2](#S2.SS2 "2.2 Convolutional
    Neural Network (CNN) ‣ 2 Deep Learning ‣ Applications of Deep Learning in Fish
    Habitat Monitoring: A Tutorial and Survey") as part of the convolutional layer
    in CNNs, batch normalisation was first introduced by Ioffe and Szegedy (Ioffe
    and Szegedy, [2015](#bib.bib40)) to decrease the effect of internal covariate
    shift. Internal covariate shift is the shift in the mean and covariance of inputs
    and network parameters across a batch of examples. Internal covariate shift can
    impede the training of deep neural networks. Batch normalisation is used in almost
    any DL model training, to improve the model generalisation. In the fish monitoring
    domain, for instance, Islam et al. (Islam et al., [2020](#bib.bib43)) proposed
    an optional residual skip block consisting of three convolutional layers with
    batch normalisation and ReLU non-linearity after each convolutional layer to perform
    effective semantic segmentation of underwater imagery.'
  id: totrans-249
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '批量归一化：在第[2.2节](#S2.SS2 "2.2 Convolutional Neural Network (CNN) ‣ 2 Deep Learning
    ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey")中作为CNN卷积层的一部分引入，批量归一化最初由Ioffe和Szegedy（Ioffe
    and Szegedy, [2015](#bib.bib40)）提出，以减少内部协变量偏移的影响。内部协变量偏移是指输入和网络参数在一批示例中的均值和协方差的变化。内部协变量偏移会妨碍深度神经网络的训练。批量归一化几乎在任何深度学习模型训练中都会使用，以改善模型的泛化能力。例如，在鱼类监测领域，Islam等人（Islam
    et al., [2020](#bib.bib43)）提出了一个可选的残差跳过块，由三个卷积层组成，每个卷积层后都有批量归一化和ReLU非线性，以实现对水下图像的有效语义分割。'
- en: •
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Dropout: Introduced in Section [2.2](#S2.SS2 "2.2 Convolutional Neural Network
    (CNN) ‣ 2 Deep Learning ‣ Applications of Deep Learning in Fish Habitat Monitoring:
    A Tutorial and Survey") as a common operation in CNNs, dropout reduces the network
    dependency to a small selection of neurons and encourages more useful and robust
    properties and features of the dataset to be learnt. When working with a complex
    neural network structure, dropout is frequently recommended to introduce additional
    randomisation, which helps with the generalisation capability of the network.
    For example, Iqpal et al. (Iqbal et al., [2021](#bib.bib41)) claimed that the
    inclusion of dropout layer has enhanced the overall performance of their proposed
    model for automatic fish classification.'
  id: totrans-251
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 'Dropout（丢弃法）：在第[2.2节](#S2.SS2 "2.2 Convolutional Neural Network (CNN) ‣ 2 Deep
    Learning ‣ Applications of Deep Learning in Fish Habitat Monitoring: A Tutorial
    and Survey")中作为CNN中的常见操作引入，Dropout通过减少网络对少量神经元的依赖，鼓励学习数据集的更多有用和鲁棒的特性。当处理复杂的神经网络结构时，通常建议引入额外的随机化，以帮助网络的泛化能力。例如，Iqpal等人（Iqbal
    et al., [2021](#bib.bib41)）声称，加入Dropout层提高了他们提出的自动鱼类分类模型的整体性能。'
- en: 5.3 Dataset Limitation
  id: totrans-252
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 数据集限制
- en: Preparing training datasets is one of the central and most time-consuming bottlenecks
    in developing DL models, which require a large amount of data, e.g. a variety
    of underwater fish images in different environmental conditions, which should
    also be labelled and analyzed by humans for supervised learning. Due to these
    requirements, making a large dataset is most of the time, very challenging, which
    makes the datasets limited and small. However, When compared with DL models trained
    with a large dataset, the convergence speed and training accuracy of the models
    trained with small datasets are much lower. Generally, increasing the size of
    training datasets by adding more data to them is the classic way to accelerate
    the training and improved accuracy of DL models, but it is expensive. Therefore,
    in recent years, researchers have tackled the dataset limitation challenge by
    devising new ways described below.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 准备训练数据集是开发深度学习模型的一个核心且最耗时的瓶颈之一，这需要大量的数据，例如在不同环境条件下的各种水下鱼类图像，这些图像还需由人类标记和分析以进行监督学习。由于这些要求，制作大规模数据集大多是非常具有挑战性的，这使得数据集受限且较小。然而，与使用大规模数据集训练的深度学习模型相比，使用小数据集训练的模型的收敛速度和训练准确性要低得多。通常，通过向训练数据集中添加更多数据来增加训练数据集的大小是加速训练和提高深度学习模型准确性的经典方法，但这很昂贵。因此，近年来，研究人员通过设计下述新方法来应对数据集限制挑战。
- en: 5.3.1 Data Augmentation
  id: totrans-254
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.1 数据增强
- en: Data augmentation is a technique to increase the number of labelled examples
    required for DL training. It artificially enlarges the original training dataset
    by introducing various transformations such as translation, rotation, scaling,
    and even noise, to the original data instances, to make new instances. It is particularly
    relevant to the challenge posed when the quantity or quality of labelled data
    is insufficient to train a DL model. At the same time, data augmentation can be
    used to reduce the probability of overfitting and increase model generalisability.
    In contrast to the techniques listed above for improving model generalisation,
    data Augmentation addresses overfitting from the source of the problem (i.e. the
    original dataset). This is done under the notion that augmentations can extract
    additional information from the original dataset by artificially increasing the
    size of the training dataset. It is also critical to consider data augmentation’s
    "safety" (i.e. the possibility of misleading the network post-transformation).
    For example, rotation and horizontal flipping are typically safe data augmentation
    techniques for fish classification tasks (Saleh et al., [2020a](#bib.bib108);
    Sarigül and Avci, [2017](#bib.bib114)) but not safe on digit classification tasks,
    due to the similarities between 6 and 9. A data augmentation technique is to use
    the super-resolution reconstruction method (Ledig et al., [2017](#bib.bib70))
    based on Generative Adversarial Network (GAN) (Goodfellow et al., [2014](#bib.bib31))
    to enlarge the dataset with high-quality images. This has been previously used
    to improve small-scale fine-grained fish classification (Qiu et al., [2018](#bib.bib100)),
    and to increase models predictive performance (i.e. ability to generalise to new
    data) (Konovalov et al., [2019a](#bib.bib56)) for underwater fish detection and
    automatic fish classification (Chen et al., [2018](#bib.bib14)).
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 数据增强是一种增加深度学习训练所需标记样本数量的技术。它通过对原始数据实例引入各种变换，如平移、旋转、缩放甚至噪声，来人工扩大原始训练数据集，从而生成新的实例。这对于标记数据数量或质量不足以训练深度学习模型时尤其相关。同时，数据增强可以用来减少过拟合的概率，并提高模型的泛化能力。与上述改进模型泛化的技术相比，数据增强从问题的根源（即原始数据集）解决过拟合问题。这是在假设增强可以通过人工增加训练数据集的大小来从原始数据集中提取额外信息的理念下进行的。同时，也需要考虑数据增强的“安全性”（即变换后误导网络的可能性）。例如，旋转和水平翻转通常是对鱼类分类任务安全的数据增强技术（Saleh
    et al., [2020a](#bib.bib108); Sarigül and Avci, [2017](#bib.bib114)），但对数字分类任务不安全，因为6和9之间存在相似性。一个数据增强技术是使用基于生成对抗网络（GAN）（Goodfellow
    et al., [2014](#bib.bib31)）的超分辨率重建方法（Ledig et al., [2017](#bib.bib70)）来用高质量图像扩大数据集。这已被用于提高小规模精细化鱼类分类（Qiu
    et al., [2018](#bib.bib100)）以及提高模型预测性能（即对新数据的泛化能力）（Konovalov et al., [2019a](#bib.bib56)）用于水下鱼类检测和自动鱼类分类（Chen
    et al., [2018](#bib.bib14)）。
- en: Using augmentation techniques such as cropping, flipping, colour changes, and
    random erasing together can result in enormously inflated dataset sizes. For example,
    Islam et al. (Islam et al., [2020](#bib.bib43)) used rotation, width shift, height
    shift, shear, zoom and horizontal flip for semantic segmentation of underwater
    imagery to significantly increase their dataset size. Another data augmentation
    technique used during training DL models is scale jittering, which has been used
    in (Mandal et al., [2018](#bib.bib84)) for assessing fish abundance in underwater
    videos. Gaussian filtering to blur images and different degrees of rotation for
    fish recognition in underwater-drone with a panoramic camera is another augmentation
    technique used in the marine monitoring domain (Meng et al., [2018](#bib.bib86)).
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 使用如裁剪、翻转、颜色变化和随机擦除等增强技术的组合可以显著增加数据集的大小。例如，Islam et al.（Islam et al., [2020](#bib.bib43)）使用了旋转、宽度偏移、高度偏移、剪切、缩放和水平翻转，用于水下图像的语义分割，以显著增加他们的数据集大小。在训练深度学习模型时使用的另一种数据增强技术是尺度抖动，这在（Mandal
    et al., [2018](#bib.bib84)）中用于评估水下视频中的鱼类丰度。高斯滤波用于模糊图像，以及不同程度的旋转用于水下无人机的鱼类识别，这些都是在海洋监测领域使用的其他增强技术（Meng
    et al., [2018](#bib.bib86)）。
- en: However, augmentation is not always favourable, as it might lead to large overfitting
    in cases with very few data samples. As a result, it is critical to determine
    the best subset of augmentation techniques to train your DL model using a limited
    dataset.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，增强并不总是有利的，因为在数据样本非常少的情况下，它可能导致严重的过拟合。因此，确定最佳的增强技术子集以使用有限的数据集训练深度学习模型是至关重要的。
- en: 5.3.2 Transfer Learning
  id: totrans-258
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.2 转移学习
- en: Transfer Learning is preserving information obtained while solving one problem,
    and transferring the learned knowledge to another similar problem. For instance,
    one may initially train a network on a large object dataset, such as ImageNet
    that includes 1000 different object classes, and then utilise the learned network
    parameters from that training as the initial learning parameters in a new classification
    task, e.g. fish classification. In most cases, just the weights in convolutional
    layers are transferred, rather than the complete network, including fully connected
    layers. This is extremely useful since many image datasets have low-level spatial
    features and properties that are better learnt in massive datasets. For example,
    Zurowietz *et al.* (Zurowietz and Nattkemper, [2020](#bib.bib143)) presented unsupervised
    knowledge transfer to use their limited amount of training data in order to avoid
    time-consuming annotation for object detection in marine environmental monitoring
    and exploration.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 转移学习是保存解决一个问题时获得的信息，并将学习到的知识转移到另一个类似的问题上。例如，可以先在一个包含1000种不同对象类别的大型对象数据集上训练一个网络，比如ImageNet，然后将从该训练中学到的网络参数作为新分类任务（例如鱼类分类）的初始学习参数。在大多数情况下，仅转移卷积层中的权重，而不是包括全连接层在内的整个网络。这非常有用，因为许多图像数据集具有低级空间特征和属性，这些特征和属性在大规模数据集中更容易学习。例如，Zurowietz
    *et al.*（Zurowietz 和 Nattkemper，[2020](#bib.bib143)）提出了无监督知识转移，以利用他们有限的训练数据，从而避免在海洋环境监测和探索中进行耗时的标注。
- en: 5.3.3 Hybrid Features
  id: totrans-260
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.3 混合特征
- en: DL architectures have demonstrated excellent capabilities in capturing semantic
    knowledge that is latent in image features. Handcrafted features, on the other
    hand, can provide specific physical descriptions if they are carefully chosen.
    In addition, attributes of natural images have been demonstrated to be described
    differently by CNN features and hand-crafted features. This means a feature’s
    discriminative ability may behave differently on different datasets. Therefore,
    these two types of features may complement each other for better learning.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习架构在捕捉图像特征中潜在的语义知识方面表现出色。另一方面，精心选择的手工特征可以提供特定的物理描述。此外，已经证明，自然图像的属性由CNN特征和手工特征的描述方式有所不同。这意味着特征的区分能力在不同的数据集上可能表现不同。因此，这两种特征类型可以互补，以实现更好的学习。
- en: However, increasing feature dimensions by fusing hand-crafted and DL-generated
    features can result in increased computational requirement. One way to avoid this
    is to initially utilise DL features for a particular dataset, and later add hybrid
    features to enhance the performance. As a result, when working with difficult
    datasets, such as uncommon and rare marine species, more sophisticated algorithms
    and techniques based on hybrid features may be required. In fact, several research
    groups have used such strategies to improve the performance of marine species
    recognition tasks.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，通过融合手工设计的特征和深度学习（DL）生成的特征来增加特征维度可能会导致计算需求增加。避免这种情况的一种方法是最初仅使用DL特征来处理特定数据集，然后再添加混合特征以提高性能。因此，当处理困难的数据集时，例如不常见和稀有的海洋物种，可能需要更复杂的基于混合特征的算法和技术。实际上，一些研究小组已经采用了这些策略来提高海洋物种识别任务的性能。
- en: For instance, Mahmood et al. (Mahmood et al., [2016](#bib.bib83)) used texture-
    and colour-based hand-crafted features extracted from their CNN training data
    to complement generic CNN-extracted features and achieved a classification accuracy
    higher than when using only generic CNN features when classifying corals. A combination
    of CNN and hand-designed features have also been used in (Cao et al., [2016](#bib.bib12))
    for marine animal classification, again showing that their method achieves higher
    accuracy than applying CNN alone. In another work, Blanchet et al. showed that
    aggregation of multiple features outperforms models using single feature-extraction
    techniques, for automated coral annotation in natural scenes (Blanchet et al.,
    [2016](#bib.bib9)).
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Mahmood等（Mahmood et al., [2016](#bib.bib83)）使用从其CNN训练数据中提取的纹理和颜色基的手工设计特征来补充通用CNN提取的特征，并在对珊瑚进行分类时取得了比仅使用通用CNN特征更高的分类准确率。CNN和手工设计特征的组合也被用于（Cao
    et al., [2016](#bib.bib12)）中的海洋动物分类，再次显示出其方法比单独应用CNN更高的准确性。在另一项研究中，Blanchet等展示了多特征的聚合优于使用单一特征提取技术的模型，用于自然场景中的自动珊瑚注释（Blanchet
    et al., [2016](#bib.bib9)）。
- en: 5.3.4 Weakly-Supervised Learning
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.4 弱监督学习
- en: DL methods (LeCun et al., [2015](#bib.bib69)) have consistently achieved state-of-the-art
    results in a variety of applications, specifically in fully supervised learning
    tasks like classification and regression (Li et al., [2009](#bib.bib74); Lin et al.,
    [2014](#bib.bib78)). Fully supervised learning methods create predictive algorithms
    by learning from a vast amount of training patterns, where each pattern has a
    label showing its ground-truth output (Kotsiantis, [2007](#bib.bib59)). Although
    the current fully supervised methods have been very successful in certain activities
    (De Vos et al., [2017](#bib.bib21); Wörz and Rohr, [2006](#bib.bib131); Mader
    et al., [2018](#bib.bib82)), they come with a caveat of requiring a large portion
    of the data to be labelled, and it is sometimes difficult or extremely time consuming
    to obtain ground-truth labels for the dataset. Thus, it is desirable to develop
    learning algorithms that are able to work with less labelled data (i.e. weakly
    supervised) (Zhou, [2018](#bib.bib140); Oquab et al., [2015](#bib.bib94)).
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习方法（LeCun et al., [2015](#bib.bib69)）在各种应用中始终取得了最先进的结果，特别是在完全监督学习任务中，如分类和回归（Li
    et al., [2009](#bib.bib74); Lin et al., [2014](#bib.bib78)）。完全监督学习方法通过从大量训练样本中学习来创建预测算法，每个样本都有一个标签显示其真实输出（Kotsiantis,
    [2007](#bib.bib59)）。尽管目前的完全监督方法在某些活动中非常成功（De Vos et al., [2017](#bib.bib21); Wörz
    and Rohr, [2006](#bib.bib131); Mader et al., [2018](#bib.bib82)），但它们需要大量的数据进行标注，有时获取数据集的真实标签既困难又极为耗时。因此，开发能够处理较少标注数据（即弱监督）的学习算法是非常可取的（Zhou,
    [2018](#bib.bib140); Oquab et al., [2015](#bib.bib94)）。
- en: Weak supervision in particular can be very useful in underwater fish monitoring,
    where the limited dataset size and the time- and cost-prohibitive nature of labelling
    limits achieving a useful dataset for developing effective, smart, and automated
    habitat monitoring tools and techniques. A number of works in literature have
    already used weak supervision for underwater fish habitat monitoring. For example,
    Laradji et al. (Laradji et al., [2020](#bib.bib67)) proposed a segmentation model
    that can efficiently train on underwater fish images, not manually segmented for
    training, but only labeled with simple point-level supervision. This work demonstrated
    that in the marine monitoring context, weakly-supervised learning can effectively
    improve the accuracy and speed of model development with limited dataset sizes
    and limited labelling budget.
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 弱监督尤其在水下鱼类监测中非常有用，因为有限的数据集规模和标注的时间及成本限制了有效、智能和自动化栖息地监测工具和技术的开发。一些文献中的工作已经使用了弱监督进行水下鱼类栖息地监测。例如，Laradji
    et al. (Laradji et al., [2020](#bib.bib67)) 提出了一个可以高效训练水下鱼类图像的分割模型，该模型未进行手动分割，仅使用简单的点级监督进行标注。这项工作展示了在海洋监测背景下，弱监督学习可以有效提高模型开发的准确性和速度，同时在数据集规模和标注预算有限的情况下。
- en: '![Refer to caption](img/1e4893ef8fef581cdd37e67fd525d71c.png)'
  id: totrans-267
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/1e4893ef8fef581cdd37e67fd525d71c.png)'
- en: 'Figure 6: Schematic diagram of Active Learning'
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：主动学习的示意图
- en: 5.3.5 Active Learning
  id: totrans-269
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 5.3.5 主动学习
- en: 'Active learning is a sub-field of ML and, more broadly, of AI. In active learning,
    the proposed algorithm is allowed to be "inquisitive", that is, it is allowed
    to pick the data to learn, which in theory means the algorithm can do more with
    less guidance, similar to weak supervision. Active learning systems are seeking
    to solve the constraint of labelling by posing a questionnaire in the context
    of unlabeled examples to be labelled by an oracle (e.g. a human annotator). In
    this manner, the goal of the active learner is to attain high precision by using
    as few labelled examples as possible, thus minimising the expense of acquiring
    labelled data; see Figure [6](#S5.F6 "Figure 6 ‣ 5.3.4 Weakly-Supervised Learning
    ‣ 5.3 Dataset Limitation ‣ 5 Challenges in underwater fish monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey").'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 主动学习是机器学习和更广泛的人工智能的一个子领域。在主动学习中，所提出的算法被允许“好奇”，即可以选择要学习的数据，这在理论上意味着算法可以在较少的指导下做更多的事情，类似于弱监督。主动学习系统试图通过在未标记示例的背景下提出一个问卷，让神谕（例如人工标注者）进行标记，从而解决标注的限制。通过这种方式，主动学习者的目标是通过使用尽可能少的标记示例来达到高精度，从而最小化获取标记数据的费用；参见图
    [6](#S5.F6 "图6 ‣ 5.3.4 弱监督学习 ‣ 5.3 数据集限制 ‣ 5 水下鱼类监测中的挑战 ‣ 鱼类栖息地监测中的深度学习应用：教程与调查")。
- en: In many cases, the labels come for little or no cost, like the "spam" label
    that is used to mark spam emails, or the five-star rating that a user could post
    for a movie on a social networking platform. Learning methods use these labels
    and scores to help screen your spam email and recommend movies that you might
    enjoy. In these cases, certain labels are given free of charge, but for more sophisticated
    supervised learning tasks, such as when you need to segment a fish in an underwater
    environment, this is not the case. For example, in (Nilssen et al., [2017](#bib.bib91))
    active learning has been used for the classification of species in underwater
    images from a fixed observatory. The authors proposed an active learning method
    that assigns taxonomic categories to single patches based on a set of human expert
    annotations, making use of cluster structures and relevance scores. This active
    learning method, compared to traditional sampling strategies, used significantly
    fewer manual labels to train a classifier.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 在许多情况下，标签几乎是免费的，比如用于标记垃圾邮件的“垃圾邮件”标签，或者用户在社交网络平台上为电影评分的五星评级。学习方法利用这些标签和评分来帮助筛选垃圾邮件和推荐你可能喜欢的电影。在这些情况下，某些标签是免费的，但对于更复杂的监督学习任务，例如在水下环境中需要对鱼进行分割的情况，则并非如此。例如，在
    (Nilssen et al., [2017](#bib.bib91)) 中，主动学习被用于从固定观测站的水下图像中分类物种。作者提出了一种主动学习方法，根据一组人工专家标注，为单个图块分配分类类别，利用集群结构和相关性评分。与传统的采样策略相比，这种主动学习方法使用了显著更少的手动标签来训练分类器。
- en: '![Refer to caption](img/8f7b4ca6b5fdac3a072a75d898e17024.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/8f7b4ca6b5fdac3a072a75d898e17024.png)'
- en: 'Figure 7: Schematic diagram of knowledge distillation'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：知识蒸馏的示意图
- en: 6 Opportunities in applications of DL to underwater fish monitoring
  id: totrans-274
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 深度学习在水下鱼类监测应用中的机会
- en: New methodologies and strategies should be developed to advance DL models for
    various underwater visual monitoring applications, including fish monitoring,
    and to bring them closer to their terrestrial monitoring equivalents. In a previous
    study that was focused on the task of fish classification (Saleh et al., [2022](#bib.bib111)),
    we have discussed some of the future research opportunities including (i) utilizing
    spatio-temporal data to add space and time domain information to the current training
    algorithms that mainly learn fish images regardless of their spatial and/or temporal
    correlation; (ii) Developing efficient and compact DL models that can be deployed
    underwater for real-time parsing of the fish images at the collection edge; (iii)
    Combining image data from multiple collection platforms for improved multi-faceted
    learning; and (iv) Automated fish measurement and monitoring from underwater captured
    images. Below, we expand on some of the previously discussed opportunities in
    (Saleh et al., [2022](#bib.bib111)) and explore a few other prospective research
    areas for increasing the performance and usability of visual fish monitoring tasks.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 应该开发新的方法和策略，以推进DL模型在各种水下视觉监测应用中的应用，包括鱼类监测，并使其更接近陆地监测的等效模型。在一项专注于鱼类分类任务的研究中（Saleh
    et al., [2022](#bib.bib111)），我们讨论了一些未来的研究机会，包括（i）利用时空数据将空间和时间域信息添加到当前主要学习鱼类图像的训练算法中，而忽略其空间和/或时间相关性；（ii）开发高效紧凑的DL模型，可在水下实时解析鱼类图像；（iii）将来自多个采集平台的图像数据结合起来，以提高多方面学习；以及（iv）自动化水下捕获图像的鱼类测量和监测。以下，我们将扩展（Saleh
    et al., [2022](#bib.bib111)）中讨论的一些机会，并探索其他潜在的研究领域，以提高视觉鱼类监测任务的性能和可用性。
- en: 6.1 Knowledge Distillation for Underwater Embedded and Edge Processing
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 知识蒸馏用于水下嵌入式和边缘处理
- en: DL models used for fish monitoring applications are usually very large containing
    millions of parameters and requiring extensive computational power. To deploy
    these models on resource-limited devices and in resource-constrained environments
    such as undersea monitoring sites, different hardware-emabled compression techniques
    such as quantizing and binarizing DNN parameters (Lammie et al., [2019](#bib.bib65))
    can be used, as discussed in (Saleh et al., [2022](#bib.bib111)). Another method
    that has seen a lot of interest and attention for compressing large-scale DL models
    is knowledge distillation.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 用于鱼类监测应用的深度学习（DL）模型通常非常庞大，包含数百万个参数，并且需要大量的计算能力。为了在资源有限的设备和资源受限的环境中（如水下监测站点）部署这些模型，可以使用各种硬件启用的压缩技术，例如量化和二值化深度神经网络（DNN）参数（Lammie
    et al., [2019](#bib.bib65)），如（Saleh et al., [2022](#bib.bib111)）中所讨论的。另一种受到广泛关注的大规模DL模型压缩方法是知识蒸馏。
- en: 'Knowledge distillation is a technique for training a student (i.e. a small
    network) to emulate a teacher (i.e. ensemble of networks), as shown in Figure
    [7](#S5.F7 "Figure 7 ‣ 5.3.5 Active Learning ‣ 5.3 Dataset Limitation ‣ 5 Challenges
    in underwater fish monitoring ‣ Applications of Deep Learning in Fish Habitat
    Monitoring: A Tutorial and Survey"). The primary assumption is that in order to
    achieve a competitive or even superior performance, the student model should imitate
    the teacher model. The main issue is, however, transferring the knowledge from
    a large teacher to a smaller student. To that end, Bucilua et al. (Bucilǎ et al.,
    [2006](#bib.bib11)) proposed model compression as a way to transfer knowledge
    from a large model into a small model without sacrificing accuracy. In addition,
    several other model compression approaches have been developed, and the community
    has shown an increasing interest in knowledge distillation, due to its potentials
    (Amadori, [2019](#bib.bib4); Wang et al., [2020](#bib.bib128); Rassadin and Savchenko,
    [2017](#bib.bib102); Kushawaha et al., [2021](#bib.bib61)).'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: '知识蒸馏是一种训练学生（即小型网络）模仿教师（即网络集成）的方法，如图[7](#S5.F7 "Figure 7 ‣ 5.3.5 Active Learning
    ‣ 5.3 Dataset Limitation ‣ 5 Challenges in underwater fish monitoring ‣ Applications
    of Deep Learning in Fish Habitat Monitoring: A Tutorial and Survey")所示。主要假设是为了实现竞争力甚至更优的性能，学生模型应模仿教师模型。然而，主要问题在于如何将知识从大型教师模型转移到较小的学生模型。为此，Bucilua
    et al. (Bucilǎ et al., [2006](#bib.bib11)) 提出了模型压缩作为将知识从大型模型转移到小型模型的方式，而不会牺牲准确性。此外，已经开发了几种其他模型压缩方法，社区对知识蒸馏的兴趣日益增加，因为它的潜力
    (Amadori, [2019](#bib.bib4); Wang et al., [2020](#bib.bib128); Rassadin and Savchenko,
    [2017](#bib.bib102); Kushawaha et al., [2021](#bib.bib61))。'
- en: A significant research opportunity lies in applying Knowledge distillation into
    embedded devices and underwater video processors to achieve online and more effective
    surveillance with high accuracy while using limited resources. This is particularly
    useful because of the limitations of transferring data from underwater sensors
    and cameras, and due to the challenging underwater communication in the Internet
    of Underwater Things  (Jahanbakht et al., [2021](#bib.bib44)).
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: 一个重要的研究机会在于将知识蒸馏应用于嵌入式设备和水下视频处理器，以在使用有限资源的情况下实现高准确度的在线和更有效的监控。这一点特别有用，因为从水下传感器和相机传输数据存在限制，并且在水下物联网中通信具有挑战性
    (Jahanbakht et al., [2021](#bib.bib44))。
- en: 6.2 Merging Image Data from Multiple Sources
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.2 合并来自多个来源的图像数据
- en: As discussed in (Saleh et al., [2022](#bib.bib111)), to train more effective
    DNNs, multiple data collection platforms like Autonomous Underwater Vehicles (AUVs)
    or inhabited submarines can give varied visual data from the same monitoring subject.
    This can provide additional monitoring information, such as fish distribution
    patterns. Although it is straightforward to combine multiple data sources for
    training a DL network, several issues should be addressed in future research.
    These include possible preprocessing on part of data to make it compatible with
    the rest of the training dataset, class-wise weights (i.e. when you have an imbalanced
    dataset), and the number of outputs of a network. In addition, multiple training
    data sources, in particular, when using AUVs or submarines, incurs significant
    data collection and manual labelling cost, which is not always viable.
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
  zh: 正如(Saleh et al., [2022](#bib.bib111))中讨论的，为了训练更有效的深度神经网络，多种数据收集平台，如自主水下航行器 (AUVs)
    或载人潜艇，可以提供来自相同监控对象的不同视觉数据。这可以提供额外的监控信息，例如鱼类分布模式。尽管将多个数据来源结合用于训练深度学习网络是直接的，但未来的研究应解决一些问题。这些包括对部分数据进行预处理以使其与其余训练数据集兼容、类别权重（即当数据集不平衡时）以及网络的输出数量。此外，多个训练数据源，特别是使用
    AUVs 或潜艇时，涉及显著的数据收集和手动标注成本，这并不总是可行的。
- en: For this reason, some researchers have focused on learning from data with the
    least amount of human-labeling. To reduce human-labelled data cost, several methods
    have been proposed to train models on data that are unlabeled (Shimada et al.,
    [2021](#bib.bib117)) or only have pseudo-labels (Wu and Prasad, [2018](#bib.bib132)).
    Future research can advance this further by developing faster and cheaper annotating
    tools for underwater fish images.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一些研究人员专注于从最少的人类标注数据中学习。为了减少人工标注数据的成本，提出了几种方法来训练没有标签的数据 (Shimada et al., [2021](#bib.bib117))
    或仅有伪标签的数据 (Wu and Prasad, [2018](#bib.bib132))。未来的研究可以通过开发更快、更便宜的水下鱼类图像标注工具来进一步推动这一领域的发展。
- en: 6.3 Automatic Fish Phenotyping From Underwater Images
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.3 从水下图像中自动提取鱼类表型
- en: Automatic fish phenotyping, i.e. extracting their weight, size, and length,
    in their natural habitats can provide invaluable information in better understanding
    marine echosystems and fish ecology (Goodwin et al., [2022](#bib.bib32)). Although
    many studies have addressed fish monitoring in aquaculture and fish farm settings
    (Li and Du, [2021](#bib.bib73); Zhao et al., [2021](#bib.bib138)), monitoring
    fish for measurement in natural habitats remain mostly unexplored, and can be
    investigated in future research. These research should address problems such as
    low visibility and light, fish occlusion and overlap, which are shared with aquculture
    monitoring. However, other problems unique to natural habitats such as cluttered
    background environments and underwater distance measurement should be addressed
    too.
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 自动鱼类表型分析，即在其自然栖息地提取鱼的体重、体型和长度，可以提供宝贵的信息，以更好地理解海洋生态系统和鱼类生态学（Goodwin et al., [2022](#bib.bib32)）。尽管许多研究已经关注了水产养殖和鱼类养殖场的鱼类监测（Li
    and Du, [2021](#bib.bib73); Zhao et al., [2021](#bib.bib138)），但在自然栖息地进行鱼类测量的监测仍然基本未被探索，可以在未来的研究中进行调查。这些研究应解决诸如能见度低和光线不足、鱼类遮挡和重叠等问题，这些问题也存在于水产养殖监测中。然而，像杂乱的背景环境和水下距离测量等自然栖息地独有的问题也应加以解决。
- en: 6.4 Visual Monitoring of Fish Behavior and Movements
  id: totrans-285
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 6.4 鱼类行为和运动的视觉监测
- en: Although some telemetry and satellite tracking devices can be used in limited
    settings (Lennox et al., [2017](#bib.bib72)), fish monitoring in their natural
    habitats over a period of time is not achievable using these techniques mainly
    due to the hostile underwater signal communication medium (Jahanbakht et al.,
    [2021](#bib.bib44)). For instance for tracking fish movements, schooling, and
    behavior, new visual monitoring techniques should be devised. A possible direction
    for future studies is to devise better understanding of fish vision characteristics
    (Boudhane and Nsiri, [2016](#bib.bib10)) and their implications in the current
    and next generation of automated DL-based tracking systems (Li et al., [2020](#bib.bib76))
    and marine object detection (Moniruzzaman et al., [2017](#bib.bib88)). An example
    of an alternative tracking method is presented in (Zhao et al., [2019](#bib.bib139)),
    where the image-based identification and tracking method for fish is designed
    based on biological water quality monitoring. To improve the fish tracking task,
    some techniques can also be combined with visual image enhancement algorithms.
    For instance, when the image enhancement methods are used, the underwater images
    can be corrected for distortion and noise, and the fish tracking task can be easily
    performed. In (Saberioon and Cisar, [2016](#bib.bib107)), the authors studied
    the potential of underwater fish monitoring by using visual and underwater sensing
    methods.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管一些遥测和卫星跟踪设备可以在有限的环境中使用（Lennox et al., [2017](#bib.bib72)），但由于恶劣的水下信号通信介质（Jahanbakht
    et al., [2021](#bib.bib44)），在自然栖息地中长时间进行鱼类监测是不可能实现的。例如，为了跟踪鱼类的运动、成群和行为，需要制定新的视觉监测技术。未来研究的一个可能方向是更好地理解鱼类视觉特性（Boudhane
    and Nsiri, [2016](#bib.bib10)）及其在当前和下一代基于深度学习的跟踪系统（Li et al., [2020](#bib.bib76)）和海洋物体检测（Moniruzzaman
    et al., [2017](#bib.bib88)）中的应用。例如，在（Zhao et al., [2019](#bib.bib139)）中提出了一种替代的跟踪方法，该方法基于生物水质监测设计了基于图像的鱼类识别和跟踪方法。为了改进鱼类跟踪任务，还可以将一些技术与视觉图像增强算法相结合。例如，当使用图像增强方法时，可以校正水下图像的失真和噪声，从而更容易完成鱼类跟踪任务。在（Saberioon
    and Cisar, [2016](#bib.bib107)）中，作者研究了通过视觉和水下传感方法进行水下鱼类监测的潜力。
- en: Another challenging research area is developing novel underwater fish tracking
    algorithms, using DL or other technologies, with low power consumption and real-time
    speed. For this, various hardware technologies and techniques used in other domains
    such as biomedical applications  (Azghadi et al., [2020](#bib.bib5)) can be explored.
    Of course, any automated vision-based tracking system should be validated through
    real-world trials, which is a significant undertaking requiring many resources,
    in order to ensure the accurate and real-time tracking of fish.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个具有挑战性的研究领域是开发新颖的水下鱼类跟踪算法，利用深度学习或其他技术，实现低功耗和实时速度。为此，可以探索在生物医学应用等其他领域使用的各种硬件技术和方法（Azghadi
    et al., [2020](#bib.bib5)）。当然，任何自动化视觉跟踪系统都应通过实际试验进行验证，这是一个需要大量资源的重要工作，以确保鱼类的准确和实时跟踪。
- en: 7 Summary and Conclusion
  id: totrans-288
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 7 总结与结论
- en: The goal of this article was to provide researchers and practitioners a summary
    of the contemporary applications of DL in underwater visual monitoring of fish,
    as well as to make it easier to apply DL to tackle real challenges in fish-related
    marine science.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的目标是为研究人员和从业者提供有关深度学习在鱼类水下视觉监测中的当代应用的总结，并简化深度学习在解决鱼类相关海洋科学实际挑战中的应用。
- en: DL has progressed as a technology capable of providing unprecedented benefits
    to various aspects of marine research and fish habitat monitoring. We envision
    a future where DL, complemented by many other advances in monitoring hardware
    and underwater communication technologies (Jahanbakht et al., [2021](#bib.bib44)),
    is widely used in marine habitat monitoring for (1) data collection and feature
    extraction to improve the quality of automatic monitoring tools; and (2) to provide
    a reliable means of surveying fish habitats and understanding their dynamics.
    We expect that such a future will allow marine ecosystem researchers and practitioners
    to increase the efficiency of their monitoring efforts. To achieve this, we need
    concentrated and coordinated data collection, model development, and model deployment
    efforts. We also need transparent and reproducible research data and tools, which
    help us reach our target sooner.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习 (DL) 技术在海洋研究和鱼类栖息地监测的各个方面已取得前所未有的进展。我们设想一个未来，在这个未来中，DL 加上许多其他监测硬件和水下通信技术的进步（Jahanbakht
    等人，[2021](#bib.bib44)），将广泛用于海洋栖息地监测，以便 (1) 数据收集和特征提取，以提高自动监测工具的质量；以及 (2) 提供可靠的鱼类栖息地调查和理解其动态的手段。我们期望这样的未来将使海洋生态系统研究人员和从业者能够提高监测工作的效率。为实现这一目标，我们需要集中和协调的数据收集、模型开发和模型部署工作。我们还需要透明且可重复的研究数据和工具，这将帮助我们更快地实现目标。
- en: Acknowledgement
  id: totrans-291
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 致谢
- en: This research is supported by an Australian Research Training Program (RTP)
    Scholarship and Food Agility HDR Top-Up Scholarship. We also acknowledge the Australian
    Research Council for funding awarded under their Industrial Transformation Research
    Program.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究得到了澳大利亚研究培训项目 (RTP) 奖学金和食品敏捷 HDR 补充奖学金的支持。我们还感谢澳大利亚研究委员会对其工业转型研究计划下提供的资助。
- en: References
  id: totrans-293
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abdul et al. (2019) Abdul, M.S., Sam, S.M., Mohamed, N., Kamardin, K., Dziyauddin,
    R.A., 2019. Docker Containers Usage in the Internet of Things: A Survey. Open
    International Journal of Informatics (OIJI) 7, 208–220. URL: [http://apps.razak.utm.my/ojs/index.php/oiji/article/view/233](http://apps.razak.utm.my/ojs/index.php/oiji/article/view/233).'
  id: totrans-294
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdul 等人 (2019) Abdul, M.S., Sam, S.M., Mohamed, N., Kamardin, K., Dziyauddin,
    R.A., 2019. 物联网中的Docker容器使用：一项调查。开放国际信息学期刊 (OIJI) 7, 208–220。网址：[http://apps.razak.utm.my/ojs/index.php/oiji/article/view/233](http://apps.razak.utm.my/ojs/index.php/oiji/article/view/233)。
- en: 'Ahn and Kwak (2018) Ahn, J., Kwak, S., 2018. Learning Pixel-Level Semantic
    Affinity with Image-Level Supervision for Weakly Supervised Semantic Segmentation,
    in: Proceedings of the IEEE Computer Society Conference on Computer Vision and
    Pattern Recognition. doi:[10.1109/CVPR.2018.00523](https:/doi.org/10.1109/CVPR.2018.00523).'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ahn 和 Kwak (2018) Ahn, J., Kwak, S., 2018. 使用图像级监督进行像素级语义相似度学习，用于弱监督语义分割，见于：IEEE计算机协会计算机视觉与模式识别会议论文集。doi：[10.1109/CVPR.2018.00523](https:/doi.org/10.1109/CVPR.2018.00523)。
- en: Alshdaifat et al. (2020) Alshdaifat, N.F.F., Talib, A.Z., Osman, M.A., 2020.
    Improved deep learning framework for fish segmentation in underwater videos. Ecological
    Informatics 59, 101121. doi:[10.1016/j.ecoinf.2020.101121](https:/doi.org/10.1016/j.ecoinf.2020.101121).
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alshdaifat 等人 (2020) Alshdaifat, N.F.F., Talib, A.Z., Osman, M.A., 2020. 改进的深度学习框架用于水下视频中的鱼类分割。生态信息学
    59, 101121。doi：[10.1016/j.ecoinf.2020.101121](https:/doi.org/10.1016/j.ecoinf.2020.101121)。
- en: Amadori (2019) Amadori, A., 2019. Distilling knowledge from Neural Networks
    to build smaller and faster models.
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Amadori (2019) Amadori, A., 2019. 从神经网络中提炼知识以构建更小、更快的模型。
- en: Azghadi et al. (2020) Azghadi, M.R., Lammie, C., Eshraghian, J.K., Payvand,
    M., Donati, E., Linares-Barranco, B., Indiveri, G., 2020. Hardware Implementation
    of Deep Network Accelerators towards Healthcare and Biomedical Applications. IEEE
    Transactions on Biomedical Circuits and Systems 14, 1138–1159. doi:[10.1109/TBCAS.2020.3036081](https:/doi.org/10.1109/TBCAS.2020.3036081).
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azghadi 等人 (2020) Azghadi, M.R., Lammie, C., Eshraghian, J.K., Payvand, M.,
    Donati, E., Linares-Barranco, B., Indiveri, G., 2020. 面向医疗保健和生物医学应用的深度网络加速器的硬件实现。IEEE生物医学电路与系统汇刊
    14, 1138–1159。doi：[10.1109/TBCAS.2020.3036081](https:/doi.org/10.1109/TBCAS.2020.3036081)。
- en: 'Bearman et al. (2016) Bearman, A.L., Russakovsky, O., Ferrari, V., Fei-Fei,
    L., Bearman, A.L., Ferrari, V., Li, F.F., Russakovsky, O., Ferrari, V., Fei-Fei,
    L., 2016. What’s the point: Semantic segmentation with point supervision. ECCV
    abs/1506.0.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比尔曼等（2016）比尔曼，A.L.，拉萨科夫斯基，O.，费拉里，V.，费伊-费伊，L.，比尔曼，A.L.，费拉里，V.，李，F.F.，拉萨科夫斯基，O.，费拉里，V.，费伊-费伊，L.，2016。关键点：使用点监督的语义分割。ECCV
    abs/1506.0。
- en: 'Beauchemin and Barron (1995) Beauchemin, S.S., Barron, J.L., 1995. The Computation
    of Optical Flow. ACM Computing Surveys (CSUR) 27, 433–466. URL: [https://dl.acm.org/doi/abs/10.1145/212094.212141](https://dl.acm.org/doi/abs/10.1145/212094.212141),
    doi:[10.1145/212094.212141](https:/doi.org/10.1145/212094.212141).'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '博肖门和巴伦（1995）博肖门，S.S.，巴伦，J.L.，1995。光流计算。ACM计算机调查（CSUR）27，433–466。URL: [https://dl.acm.org/doi/abs/10.1145/212094.212141](https://dl.acm.org/doi/abs/10.1145/212094.212141)，doi：[10.1145/212094.212141](https:/doi.org/10.1145/212094.212141)。'
- en: 'Bisong and Bisong (2019) Bisong, E., Bisong, E., 2019. Regularization for Deep
    Learning, in: Building Machine Learning and Deep Learning Models on Google Cloud
    Platform. doi:[10.1007/978-1-4842-4470-8_34](https:/doi.org/10.1007/978-1-4842-4470-8_34).'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 比松和比松（2019）比松，E.，比松，E.，2019。深度学习的正则化，见：在Google Cloud Platform上构建机器学习和深度学习模型。doi：[10.1007/978-1-4842-4470-8_34](https:/doi.org/10.1007/978-1-4842-4470-8_34)。
- en: Blanchet et al. (2016) Blanchet, J.N., Déry, S., Landry, J.A., Osborne, K.,
    2016. Automated annotation of corals in natural scene images using multiple texture
    representations. PeerJ doi:[10.7287/peerj.preprints.2026](https:/doi.org/10.7287/peerj.preprints.2026).
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布朗谢等（2016）布朗谢，J.N.，德里，S.，兰德里，J.A.，奥斯本，K.，2016。使用多重纹理表示的自然场景图像中珊瑚的自动标注。PeerJ
    doi：[10.7287/peerj.preprints.2026](https:/doi.org/10.7287/peerj.preprints.2026)。
- en: 'Boudhane and Nsiri (2016) Boudhane, M., Nsiri, B., 2016. Underwater image processing
    method for fish localization and detection in submarine environment. Journal of
    Visual Communication and Image Representation 39, 226–238. URL: [https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840](https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840),
    doi:[10.1016/j.jvcir.2016.05.017](https:/doi.org/10.1016/j.jvcir.2016.05.017).'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '布杜汉和恩西里（2016）布杜汉，M.，恩西里，B.，2016。在水下环境中用于鱼类定位和检测的图像处理方法。视觉通信与图像表示期刊 39，226–238。URL:
    [https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840](https://linkinghub.elsevier.com/retrieve/pii/S1047320316300840)，doi：[10.1016/j.jvcir.2016.05.017](https:/doi.org/10.1016/j.jvcir.2016.05.017)。'
- en: 'Bucilǎ et al. (2006) Bucilǎ, C., Caruana, R., Niculescu-Mizil, A., 2006. Model
    compression, in: Proceedings of the ACM SIGKDD International Conference on Knowledge
    Discovery and Data Mining. doi:[10.1145/1150402.1150464](https:/doi.org/10.1145/1150402.1150464).'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 布西拉等（2006）布西拉，C.，卡鲁阿纳，R.，尼库莱斯库-米齐尔，A.，2006。模型压缩，见：ACM SIGKDD国际知识发现与数据挖掘会议论文集。doi：[10.1145/1150402.1150464](https:/doi.org/10.1145/1150402.1150464)。
- en: 'Cao et al. (2016) Cao, Z., Principe, J.C., Ouyang, B., Dalgleish, F., Vuorenkoski,
    A., 2016. Marine animal classification using combined CNN and hand-designed image
    features, in: OCEANS 2015 - MTS/IEEE Washington. doi:[10.23919/oceans.2015.7404375](https:/doi.org/10.23919/oceans.2015.7404375).'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 曹等（2016）曹哲，普林西普，J.C.，欧阳波，达格利什，F.，沃伦科斯基，A.，2016。使用结合的CNN和手工设计图像特征进行海洋动物分类，见：OCEANS
    2015 - MTS/IEEE华盛顿。doi：[10.23919/oceans.2015.7404375](https:/doi.org/10.23919/oceans.2015.7404375)。
- en: Chaudhari et al. (2020) Chaudhari, S., Malkan, N., Momin, A., Bonde, M., 2020.
    Yolo Real Time Object Detection. International Journal of Computer Trends and
    Technology doi:[10.14445/22312803/ijctt-v68i6p112](https:/doi.org/10.14445/22312803/ijctt-v68i6p112).
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 乔杜哈里等（2020）乔杜哈里，S.，马尔坎，N.，莫敏，A.，邦德，M.，2020。YOLO实时物体检测。国际计算机趋势与技术期刊 doi：[10.14445/22312803/ijctt-v68i6p112](https:/doi.org/10.14445/22312803/ijctt-v68i6p112)。
- en: 'Chen et al. (2018) Chen, G., Sun, P., Shang, Y., 2018. Automatic fish classification
    system using deep learning, in: Proceedings - International Conference on Tools
    with Artificial Intelligence, ICTAI. doi:[10.1109/ICTAI.2017.00016](https:/doi.org/10.1109/ICTAI.2017.00016).'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2018）陈广，孙鹏，尚亚，2018。使用深度学习的自动鱼类分类系统，见：国际人工智能工具会议（ICTAI）论文集。doi：[10.1109/ICTAI.2017.00016](https:/doi.org/10.1109/ICTAI.2017.00016)。
- en: 'Chen et al. (2019) Chen, L., Xia, Y., Pan, D., Wang, C., 2019. Deep learning
    based active monitoring for anti-collision between vessels and bridges, in: IABSE
    Symposium, Guimaraes 2019: Towards a Resilient Built Environment Risk and Asset
    Management - Report. doi:[10.2749/guimaraes.2019.0487](https:/doi.org/10.2749/guimaraes.2019.0487).'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 陈等（2019）陈琳，夏一，潘栋，王超，2019。基于深度学习的船舶与桥梁碰撞防止的主动监测，见：IABSE研讨会，吉马良斯2019：走向有弹性的建筑环境风险与资产管理
    - 报告。doi：[10.2749/guimaraes.2019.0487](https:/doi.org/10.2749/guimaraes.2019.0487)。
- en: '(16) Choi, S., . Fish identification in underwater video with deep convolutional
    neural network: SNUMedinfo at LifeCLEF fish task 2015. Technical Report. other.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (16) Choi, S., . 水下视频中的鱼类识别使用深度卷积神经网络：SNUMedinfo 在 LifeCLEF 鱼类任务 2015. 技术报告。其他.
- en: Chuang et al. (2016) Chuang, M.C., Hwang, J.N., Williams, K., 2016. A feature
    learning and object recognition framework for underwater fish images. IEEE Trans.
    Image Process. 25, 1862–1872. doi:[10.1109/TIP.2016.2535342](https:/doi.org/10.1109/TIP.2016.2535342).
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chuang 等人 (2016) Chuang, M.C., Hwang, J.N., Williams, K., 2016. 用于水下鱼类图像的特征学习和对象识别框架。IEEE
    图像处理汇刊 25, 1862–1872. doi:[10.1109/TIP.2016.2535342](https:/doi.org/10.1109/TIP.2016.2535342).
- en: 'Chuang et al. (2011) Chuang, M.C., Hwang, J.N., Williams, K., Towler, R., 2011.
    Automatic fish segmentation via double local thresholding for trawl-based underwater
    camera systems, in: Proceedings - International Conference on Image Processing,
    ICIP, pp. 3145–3148. doi:[10.1109/ICIP.2011.6116334](https:/doi.org/10.1109/ICIP.2011.6116334).'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chuang 等人 (2011) Chuang, M.C., Hwang, J.N., Williams, K., Towler, R., 2011.
    通过双重局部阈值法实现自动鱼类分割，用于拖网式水下摄像系统, in: Proceedings - International Conference on Image
    Processing, ICIP, pp. 3145–3148. doi:[10.1109/ICIP.2011.6116334](https:/doi.org/10.1109/ICIP.2011.6116334).'
- en: 'Dai et al. (2015) Dai, J., He, K., Sun, J., 2015. Boxsup: Exploiting bounding
    boxes to supervise convolutional networks for semantic segmentation, in: ICCV,
    pp. 1635–1643.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dai 等人 (2015) Dai, J., He, K., Sun, J., 2015. Boxsup：利用边界框来监督卷积网络进行语义分割, in:
    ICCV, pp. 1635–1643.'
- en: 'Dalal and Triggs (2005) Dalal, N., Triggs, B., 2005. Histograms of oriented
    gradients for human detection, in: Proceedings - 2005 IEEE Computer Society Conference
    on Computer Vision and Pattern Recognition, CVPR 2005, pp. 886–893. doi:[10.1109/CVPR.2005.177](https:/doi.org/10.1109/CVPR.2005.177).'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dalal 和 Triggs (2005) Dalal, N., Triggs, B., 2005. 用于人类检测的方向梯度直方图, in: Proceedings
    - 2005 IEEE 计算机学会计算机视觉与模式识别会议, CVPR 2005, pp. 886–893. doi:[10.1109/CVPR.2005.177](https:/doi.org/10.1109/CVPR.2005.177).'
- en: De Vos et al. (2017) De Vos, B.D., Wolterink, J.M., De Jong, P.A., Leiner, T.,
    Viergever, M.A., Isgum, I., 2017. ConvNet-Based Localization of Anatomical Structures
    in 3-D Medical Images. IEEE Transactions on Medical Imaging doi:[10.1109/TMI.2017.2673121](https:/doi.org/10.1109/TMI.2017.2673121).
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Vos 等人 (2017) De Vos, B.D., Wolterink, J.M., De Jong, P.A., Leiner, T., Viergever,
    M.A., Isgum, I., 2017. 基于 ConvNet 的三维医学图像解剖结构定位。IEEE 医学成像汇刊 doi:[10.1109/TMI.2017.2673121](https:/doi.org/10.1109/TMI.2017.2673121).
- en: 'Ditria et al. (2021) Ditria, E.M., Connolly, R.M., Jinks, E.L., Lopez-Marcano,
    S., 2021. Annotated Video Footage for Automated Identification and Counting of
    Fish in Unconstrained Seagrass Habitats. Frontiers in Marine Science 8. URL: [https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full](https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full),
    doi:[10.3389/fmars.2021.629485](https:/doi.org/10.3389/fmars.2021.629485).'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ditria 等人 (2021) Ditria, E.M., Connolly, R.M., Jinks, E.L., Lopez-Marcano,
    S., 2021. 用于无约束海草栖息地中鱼类自动识别和计数的注释视频资料。海洋科学前沿 8. URL: [https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full](https://www.frontiersin.org/articles/10.3389/fmars.2021.629485/full),
    doi:[10.3389/fmars.2021.629485](https:/doi.org/10.3389/fmars.2021.629485).'
- en: 'Ditria et al. (2020a) Ditria, E.M., Lopez-Marcano, S., Sievers, M., Jinks,
    E.L., Brown, C.J., Connolly, R.M., 2020a. Automating the Analysis of Fish Abundance
    Using Object Detection: Optimizing Animal Ecology With Deep Learning. Frontiers
    in Marine Science 7. URL: [https://www.frontiersin.org/article/10.3389/fmars.2020.00429/full](https://www.frontiersin.org/article/10.3389/fmars.2020.00429/full),
    doi:[10.3389/fmars.2020.00429](https:/doi.org/10.3389/fmars.2020.00429).'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ditria 等人 (2020a) Ditria, E.M., Lopez-Marcano, S., Sievers, M., Jinks, E.L.,
    Brown, C.J., Connolly, R.M., 2020a. 使用目标检测自动化分析鱼类丰度：利用深度学习优化动物生态学。海洋科学前沿 7. URL:
    [https://www.frontiersin.org/article/10.3389/fmars.2020.00429/full](https://www.frontiersin.org/article/10.3389/fmars.2020.00429/full),
    doi:[10.3389/fmars.2020.00429](https:/doi.org/10.3389/fmars.2020.00429).'
- en: 'Ditria et al. (2020b) Ditria, E.M., Sievers, M., Lopez-Marcano, S., Jinks,
    E.L., Connolly, R.M., 2020b. Deep learning for automated analysis of fish abundance:
    the benefits of training across multiple habitats. Environmental Monitoring and
    Assessment doi:[10.1007/s10661-020-08653-z](https:/doi.org/10.1007/s10661-020-08653-z).'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ditria 等人 (2020b) Ditria, E.M., Sievers, M., Lopez-Marcano, S., Jinks, E.L.,
    Connolly, R.M., 2020b. 用于自动化分析鱼类丰度的深度学习：跨多个栖息地训练的好处。环境监测与评估 doi:[10.1007/s10661-020-08653-z](https:/doi.org/10.1007/s10661-020-08653-z).
- en: 'Duan and Deng (2019) Duan, Z., Deng, J., 2019. Automatic video tracking of
    chinese mitten crab using particle filter based on multi features, in: 2019 IEEE
    3rd International Conference on Electronic Information Technology and Computer
    Engineering, EITCE 2019. doi:[10.1109/EITCE47263.2019.9095032](https:/doi.org/10.1109/EITCE47263.2019.9095032).'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Duan 和 Deng (2019) Duan, Z., Deng, J., 2019. 基于多特征的粒子滤波器的中国绒螯蟹自动视频跟踪，见：2019
    IEEE 第三届电子信息技术与计算机工程国际会议，EITCE 2019。doi:[10.1109/EITCE47263.2019.9095032](https:/doi.org/10.1109/EITCE47263.2019.9095032).
- en: Felzenszwalb et al. (2010) Felzenszwalb, P.F., Girshick, R.B., McAllester, D.,
    Ramanan, D., 2010. Object detection with discriminatively trained part-based models.
    IEEE Transactions on Pattern Analysis and Machine Intelligence doi:[10.1109/TPAMI.2009.167](https:/doi.org/10.1109/TPAMI.2009.167).
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Felzenszwalb 等 (2010) Felzenszwalb, P.F., Girshick, R.B., McAllester, D., Ramanan,
    D., 2010. 基于区分性训练的部分模型的目标检测。IEEE 模式分析与机器智能汇刊 doi:[10.1109/TPAMI.2009.167](https:/doi.org/10.1109/TPAMI.2009.167).
- en: 'Fouad et al. (2014) Fouad, M.M.M., Zawbaa, H.M., El-Bendary, N., Hassanien,
    A.E., 2014. Automatic Nile Tilapia fish classification approach using machine
    learning techniques, in: 13th International Conference on Hybrid Intelligent Systems,
    HIS 2013, pp. 173–178. doi:[10.1109/HIS.2013.6920477](https:/doi.org/10.1109/HIS.2013.6920477).'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fouad 等 (2014) Fouad, M.M.M., Zawbaa, H.M., El-Bendary, N., Hassanien, A.E.,
    2014. 使用机器学习技术的自动尼罗罗非鱼分类方法，见：第十三届混合智能系统国际会议，HIS 2013，第173–178页。doi:[10.1109/HIS.2013.6920477](https:/doi.org/10.1109/HIS.2013.6920477).
- en: 'Garcia et al. (2016) Garcia, J.A., Masip, D., Sbragaglia, V., Aguzzi, J., 2016.
    Automated identification and tracking of nephrops norvegicus (L.) using infrared
    and monochromatic blue light, in: Frontiers in Artificial Intelligence and Applications.
    doi:[10.3233/978-1-61499-696-5-9](https:/doi.org/10.3233/978-1-61499-696-5-9).'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Garcia 等 (2016) Garcia, J.A., Masip, D., Sbragaglia, V., Aguzzi, J., 2016. 使用红外线和单色蓝光的挪威文蛤
    (L.) 的自动识别与跟踪，见：人工智能与应用前沿。doi:[10.3233/978-1-61499-696-5-9](https:/doi.org/10.3233/978-1-61499-696-5-9).
- en: 'Giordano et al. (2016) Giordano, D., Palazzo, S., Spampinato, C., 2016. Fish4Knowledge:
    Collecting and Analyzing Massive Coral Reef Fish Video Data. Intelligent Systems
    Reference Library .'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Giordano 等 (2016) Giordano, D., Palazzo, S., Spampinato, C., 2016. Fish4Knowledge:
    收集和分析大量珊瑚礁鱼类视频数据。智能系统参考库。'
- en: 'Girshick et al. (2014) Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014.
    Rich feature hierarchies for accurate object detection and semantic segmentation,
    in: Proceedings of the IEEE Computer Society Conference on Computer Vision and
    Pattern Recognition. doi:[10.1109/CVPR.2014.81](https:/doi.org/10.1109/CVPR.2014.81).'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Girshick 等 (2014) Girshick, R., Donahue, J., Darrell, T., Malik, J., 2014. 精确目标检测和语义分割的丰富特征层次，见：IEEE
    计算机学会计算机视觉与模式识别会议论文集。doi:[10.1109/CVPR.2014.81](https:/doi.org/10.1109/CVPR.2014.81).
- en: Goodfellow et al. (2014) Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu,
    B., Warde-Farley, D., Ozair, S., Courville, A.C., Bengio, Y., 2014. Generative
    Adversarial Networks. ArXiv abs/1406.2.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等 (2014) Goodfellow, I.J., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A.C., Bengio, Y., 2014. 生成对抗网络。ArXiv abs/1406.2.
- en: 'Goodwin et al. (2022) Goodwin, M., Halvorsen, K.T., Jiao, L., Knausgård, K.M.,
    Martin, A.H., Moyano, M., Oomen, R.A., Rasmussen, J.H., Sørdalen, T.K., Thorbjørnsen,
    S.H., 2022. Unlocking the potential of deep learning for marine ecology: overview,
    applications, and outlook. ICES Journal of Marine Science 79, 319–336. URL: [https://arxiv.org/abs/2109.14737v1](https://arxiv.org/abs/2109.14737v1),
    doi:[10.1093/icesjms/fsab255](https:/doi.org/10.1093/icesjms/fsab255).'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Goodwin 等 (2022) Goodwin, M., Halvorsen, K.T., Jiao, L., Knausgård, K.M., Martin,
    A.H., Moyano, M., Oomen, R.A., Rasmussen, J.H., Sørdalen, T.K., Thorbjørnsen,
    S.H., 2022. 深度学习在海洋生态学中的潜力：概述、应用与展望。ICES 海洋科学杂志 79, 319–336。URL: [https://arxiv.org/abs/2109.14737v1](https://arxiv.org/abs/2109.14737v1)，doi:[10.1093/icesjms/fsab255](https:/doi.org/10.1093/icesjms/fsab255).'
- en: Han et al. (2020) Han, F., Yao, J., Zhu, H., Wang, C., 2020. Marine Organism
    Detection and Classification from Underwater Vision Based on the Deep CNN Method.
    Mathematical Problems in Engineering doi:[10.1155/2020/3937580](https:/doi.org/10.1155/2020/3937580).
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Han 等 (2020) Han, F., Yao, J., Zhu, H., Wang, C., 2020. 基于深度 CNN 方法的水下视觉中的海洋生物检测与分类。工程中的数学问题
    doi:[10.1155/2020/3937580](https:/doi.org/10.1155/2020/3937580).
- en: He et al. (2015) He, K., Zhang, X., Ren, S., Sun, J., 2015. Deep Residual Learning
    for Image Recognition. Computer Vision and Pattern Recognition (CVPR) .
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等 (2015) He, K., Zhang, X., Ren, S., Sun, J., 2015. 深度残差学习用于图像识别。计算机视觉与模式识别
    (CVPR)。
- en: Hochreiter and Schmidhuber (1997) Hochreiter, S., Schmidhuber, J., 1997. Long
    Short-Term Memory. Neural Computation 9, 1735–1780. doi:[https://doi.org/10.1162/neco.1997.9.8.1735](https:/doi.org/https://doi.org/10.1162/neco.1997.9.8.1735).
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hochreiter和Szegedy（1997）Hochreiter, S., Schmidhuber, J., 1997. 《长短期记忆》。神经计算
    9, 1735–1780。doi:[https://doi.org/10.1162/neco.1997.9.8.1735](https:/doi.org/https://doi.org/10.1162/neco.1997.9.8.1735)。
- en: 'Hossain et al. (2016) Hossain, E., Alam, S.M., Ali, A.A., Amin, M.A., 2016.
    Fish activity tracking and species identification in underwater video, in: 2016
    5th International Conference on Informatics, Electronics and Vision, ICIEV 2016,
    pp. 62–66. doi:[10.1109/ICIEV.2016.7760189](https:/doi.org/10.1109/ICIEV.2016.7760189).'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hossain等（2016）Hossain, E., Alam, S.M., Ali, A.A., Amin, M.A., 2016. 《水下视频中的鱼类活动追踪与物种识别》，在：2016年第五届信息学、电子学与视觉国际会议（ICIEV
    2016），第62–66页。doi:[10.1109/ICIEV.2016.7760189](https:/doi.org/10.1109/ICIEV.2016.7760189)。
- en: Hu et al. (2012) Hu, Y., Mian, A.S., Owens, R., 2012. Face Recognition Using
    Sparse Approximated Nearest Points between Image Sets. IEEE Transactions on Pattern
    Analysis and Machine Intelligence 34, 1992–2004. doi:[10.1109/TPAMI.2011.283](https:/doi.org/10.1109/TPAMI.2011.283).
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu等（2012）Hu, Y., Mian, A.S., Owens, R., 2012. 《使用稀疏逼近最近点进行面部识别》。IEEE模式分析与机器智能汇刊
    34, 1992–2004。doi:[10.1109/TPAMI.2011.283](https:/doi.org/10.1109/TPAMI.2011.283)。
- en: 'Huang et al. (2014) Huang, P.X., Boom, B.J., Fisher, R.B., 2014. GMM improves
    the reject option in hierarchical classification for fish recognition, in: IEEE
    Winter Conference on Applications of Computer Vision, IEEE. pp. 371–376. URL:
    [https://ieeexplore.ieee.org/document/6836076](https://ieeexplore.ieee.org/document/6836076),
    doi:[10.1109/WACV.2014.6836076](https:/doi.org/10.1109/WACV.2014.6836076).'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Huang等（2014）Huang, P.X., Boom, B.J., Fisher, R.B., 2014. 《GMM在鱼类识别的层次分类中的拒绝选项改进》，在：IEEE计算机视觉应用冬季会议，IEEE。第371–376页。网址:
    [https://ieeexplore.ieee.org/document/6836076](https://ieeexplore.ieee.org/document/6836076)，doi:[10.1109/WACV.2014.6836076](https:/doi.org/10.1109/WACV.2014.6836076)。'
- en: Huang et al. (2018) Huang, Z., XinggangWang, J., Liu, W., Wang, J., 2018. Weakly-supervised
    semantic segmentation network with deep seeded region growing, pp. 7014–7023.
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang等（2018）Huang, Z., XinggangWang, J., Liu, W., Wang, J., 2018. 《弱监督语义分割网络与深度种子区域生长》，第7014–7023页。
- en: 'Ioffe and Szegedy (2015) Ioffe, S., Szegedy, C., 2015. Batch Normalization:
    Accelerating Deep Network Training by Reducing Internal Covariate Shift, in: International
    Conference on Machine Learning.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ioffe和Szegedy（2015）Ioffe, S., Szegedy, C., 2015. 《批量归一化：通过减少内部协变量偏移加速深度网络训练》，在：国际机器学习会议。
- en: Iqbal et al. (2021) Iqbal, M.A., Wang, Z., Ali, Z.A., Riaz, S., 2021. Automatic
    Fish Species Classification Using Deep Convolutional Neural Networks. Wireless
    Personal Communications doi:[10.1007/s11277-019-06634-1](https:/doi.org/10.1007/s11277-019-06634-1).
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Iqbal等（2021）Iqbal, M.A., Wang, Z., Ali, Z.A., Riaz, S., 2021. 《使用深度卷积神经网络的自动鱼类物种分类》。无线个人通信
    doi:[10.1007/s11277-019-06634-1](https:/doi.org/10.1007/s11277-019-06634-1)。
- en: 'Islam et al. (2019) Islam, M.A., Howlader, M.R., Habiba, U., Faisal, R.H.,
    Rahman, M.M., 2019. Indigenous Fish Classification of Bangladesh using Hybrid
    Features with SVM Classifier, in: 5th International Conference on Computer, Communication,
    Chemical, Materials and Electronic Engineering, IC4ME2 2019. doi:[10.1109/IC4ME247184.2019.9036679](https:/doi.org/10.1109/IC4ME247184.2019.9036679).'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Islam等（2019）Islam, M.A., Howlader, M.R., Habiba, U., Faisal, R.H., Rahman, M.M.,
    2019. 《使用混合特征和SVM分类器对孟加拉国本土鱼类进行分类》，在：2019年第五届计算机、通信、化学、材料与电子工程国际会议（IC4ME2 2019）。doi:[10.1109/IC4ME247184.2019.9036679](https:/doi.org/10.1109/IC4ME247184.2019.9036679)。
- en: 'Islam et al. (2020) Islam, M.J., Edge, C., Xiao, Y., Luo, P., Mehtaz, M., Morse,
    C., Enan, S.S., Sattar, J., 2020. Semantic Segmentation of Underwater Imagery:
    Dataset and Benchmark. http://arxiv.org/abs/2004.01241 URL: [http://arxiv.org/abs/2004.01241](http://arxiv.org/abs/2004.01241).'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Islam等（2020）Islam, M.J., Edge, C., Xiao, Y., Luo, P., Mehtaz, M., Morse, C.,
    Enan, S.S., Sattar, J., 2020. 《水下图像的语义分割：数据集和基准》。http://arxiv.org/abs/2004.01241
    网址: [http://arxiv.org/abs/2004.01241](http://arxiv.org/abs/2004.01241)。'
- en: 'Jahanbakht et al. (2021) Jahanbakht, M., Xiang, W., Hanzo, L., Azghadi, M.R.,
    2021. Internet of Underwater Things and Big Marine Data Analytics - A Comprehensive
    Survey. IEEE Communications Surveys and Tutorials 23, 904–956. URL: [https://ieeexplore.ieee.org/document/9328873/](https://ieeexplore.ieee.org/document/9328873/),
    doi:[10.1109/COMST.2021.3053118](https:/doi.org/10.1109/COMST.2021.3053118).'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Jahanbakht等（2021）Jahanbakht, M., Xiang, W., Hanzo, L., Azghadi, M.R., 2021.
    《水下物联网与大规模海洋数据分析——综合调查》。IEEE通讯调查与教程 23, 904–956。网址: [https://ieeexplore.ieee.org/document/9328873/](https://ieeexplore.ieee.org/document/9328873/)，doi:[10.1109/COMST.2021.3053118](https:/doi.org/10.1109/COMST.2021.3053118)。'
- en: Jalal et al. (2020) Jalal, A., Salman, A., Mian, A., Shortis, M., Shafait, F.,
    2020. Fish detection and species classification in underwater environments using
    deep learning with temporal information. Ecological Informatics 57, 101088. doi:[10.1016/j.ecoinf.2020.101088](https:/doi.org/10.1016/j.ecoinf.2020.101088).
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jalal 等人 (2020) Jalal, A., Salman, A., Mian, A., Shortis, M., Shafait, F., 2020.
    在水下环境中使用深度学习和时间信息进行鱼类检测和物种分类。生态信息学 57, 101088。doi:[10.1016/j.ecoinf.2020.101088](https:/doi.org/10.1016/j.ecoinf.2020.101088)。
- en: Jing et al. (2020) Jing, L., Chen, Y., Tian, Y., 2020. Coarse-to-Fine Semantic
    Segmentation from Image-Level Labels. IEEE Transactions on Image Processing doi:[10.1109/TIP.2019.2926748](https:/doi.org/10.1109/TIP.2019.2926748).
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jing 等人 (2020) Jing, L., Chen, Y., Tian, Y., 2020. 从图像级标签到粗到精的语义分割。IEEE 图像处理学报
    doi:[10.1109/TIP.2019.2926748](https:/doi.org/10.1109/TIP.2019.2926748)。
- en: 'Joly et al. (2014) Joly, A., Goëau, H., Glotin, H., Spampinato, C., Bonnet,
    P., Vellinga, W.P., Planque, R., Rauber, A., Fisher, R., Müller, H., 2014. LifeCLEF
    2014: Multimedia Life Species Identification Challenges, in: Kanoulas, E., Lupu,
    M., Clough, P., Sanderson, M., Hall, M., Hanbury, A., Toms, E. (Eds.), Information
    Access Evaluation. Multilinguality, Multimodality, and Interaction, Springer International
    Publishing, Cham. pp. 229–249.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Joly 等人 (2014) Joly, A., Goëau, H., Glotin, H., Spampinato, C., Bonnet, P.,
    Vellinga, W.P., Planque, R., Rauber, A., Fisher, R., Müller, H., 2014. LifeCLEF
    2014: 多媒体生命物种识别挑战，在：Kanoulas, E., Lupu, M., Clough, P., Sanderson, M., Hall, M.,
    Hanbury, A., Toms, E. (编.), 信息访问评估。多语言性、多模态性和交互，Springer International Publishing，Cham。第229–249页。'
- en: Juliani and Juliani (2021) Juliani, C., Juliani, E., 2021. Deep learning of
    terrain morphology and pattern discovery via network-based representational similarity
    analysis for deep-sea mineral exploration. Ore Geology Reviews doi:[10.1016/j.oregeorev.2020.103936](https:/doi.org/10.1016/j.oregeorev.2020.103936).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Juliani 和 Juliani (2021) Juliani, C., Juliani, E., 2021. 基于网络的表征相似性分析在深海矿产勘探中的地形形态和模式发现的深度学习。矿石地质评论
    doi:[10.1016/j.oregeorev.2020.103936](https:/doi.org/10.1016/j.oregeorev.2020.103936)。
- en: 'Kang et al. (2018) Kang, D., Ma, Z., Chan, A.B., 2018. Beyond counting: comparisons
    of density maps for crowd analysis tasks-counting, detection, and tracking. IEEE
    Transactions on Circuits and Systems for Video Technology .'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kang 等人 (2018) Kang, D., Ma, Z., Chan, A.B., 2018. 超越计数：用于人群分析任务的密度图比较——计数、检测和跟踪。IEEE
    计算机视觉与模式识别学报。
- en: Khan et al. (2020) Khan, A., Sohail, A., Zahoora, U., Qureshi, A.S., 2020. A
    survey of the recent architectures of deep convolutional neural networks. Artificial
    Intelligence Review 53, 5455–5516. doi:[10.1007/s10462-020-09825-6](https:/doi.org/10.1007/s10462-020-09825-6).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等人 (2020) Khan, A., Sohail, A., Zahoora, U., Qureshi, A.S., 2020. 近年来深度卷积神经网络的架构综述。人工智能评论
    53, 5455–5516。doi:[10.1007/s10462-020-09825-6](https:/doi.org/10.1007/s10462-020-09825-6)。
- en: Khazukov et al. (2020) Khazukov, K., Shepelev, V., Karpeta, T., Shabiev, S.,
    Slobodin, I., Charbadze, I., Alferova, I., 2020. Real-time monitoring of traffic
    parameters. Journal of Big Data 7. doi:[10.1186/s40537-020-00358-x](https:/doi.org/10.1186/s40537-020-00358-x).
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khazukov 等人 (2020) Khazukov, K., Shepelev, V., Karpeta, T., Shabiev, S., Slobodin,
    I., Charbadze, I., Alferova, I., 2020. 实时监测交通参数。大数据期刊 7。doi:[10.1186/s40537-020-00358-x](https:/doi.org/10.1186/s40537-020-00358-x)。
- en: 'Khoreva et al. (2017) Khoreva, A., Benenson, R., Hosang, J.H., Hein, M., Schiele,
    B., 2017. Simple Does It: Weakly Supervised Instance and Semantic Segmentation.
    CVPR , 876–885.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khoreva 等人 (2017) Khoreva, A., Benenson, R., Hosang, J.H., Hein, M., Schiele,
    B., 2017. 简单即是最好：弱监督实例和语义分割。计算机视觉与模式识别会议，876–885。
- en: 'Kim et al. (2016) Kim, S., Park, B., Song, B.S., Yang, S., 2016. Deep belief
    network based statistical feature learning for fingerprint liveness detection.
    Pattern Recognition Letters 77, 58–65. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198](https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198),
    doi:[10.1016/j.patrec.2016.03.015](https:/doi.org/10.1016/j.patrec.2016.03.015).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kim 等人 (2016) Kim, S., Park, B., Song, B.S., Yang, S., 2016. 基于深度信念网络的指纹活性检测的统计特征学习。模式识别通讯
    77, 58–65。网址: [https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198](https://linkinghub.elsevier.com/retrieve/pii/S0167865516300198)，doi:[10.1016/j.patrec.2016.03.015](https:/doi.org/10.1016/j.patrec.2016.03.015)。'
- en: 'Kingma and Ba (2014) Kingma, D.P., Ba, J., 2014. Adam: A method for stochastic
    optimization. arXiv preprint arXiv:1412.6980 .'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Kingma 和 Ba (2014) Kingma, D.P., Ba, J., 2014. Adam: 一种随机优化方法。arXiv 预印本 arXiv:1412.6980。'
- en: 'Knausgård et al. (2021) Knausgård, K.M., Wiklund, A., Sørdalen, T.K., Halvorsen,
    K.T., Kleiven, A.R., Jiao, L., Goodwin, M., 2021. Temperate fish detection and
    classification: a deep learning based approach. Applied Intelligence doi:[10.1007/s10489-020-02154-9](https:/doi.org/10.1007/s10489-020-02154-9).'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Knausgård 等人（2021）Knausgård, K.M., Wiklund, A., Sørdalen, T.K., Halvorsen, K.T.,
    Kleiven, A.R., Jiao, L., Goodwin, M., 2021. 温带鱼类检测与分类：一种基于深度学习的方法。应用智能 doi:[10.1007/s10489-020-02154-9](https:/doi.org/10.1007/s10489-020-02154-9)。
- en: 'Konovalov et al. (2019a) Konovalov, D.A., Saleh, A., Bradley, M., Sankupellay,
    M., Marini, S., Sheaves, M., 2019a. Underwater Fish Detection with Weak Multi-Domain
    Supervision, in: 2019 International Joint Conference on Neural Networks (IJCNN),
    IEEE. pp. 1–8. URL: [https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/),
    doi:[10.1109/IJCNN.2019.8851907](https:/doi.org/10.1109/IJCNN.2019.8851907).'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Konovalov 等人（2019a）Konovalov, D.A., Saleh, A., Bradley, M., Sankupellay, M.,
    Marini, S., Sheaves, M., 2019a. 使用弱多领域监督进行水下鱼类检测，见：2019国际神经网络联合会议（IJCNN），IEEE，第1–8页。网址:
    [https://ieeexplore.ieee.org/document/8851907/](https://ieeexplore.ieee.org/document/8851907/)，doi:[10.1109/IJCNN.2019.8851907](https:/doi.org/10.1109/IJCNN.2019.8851907)。'
- en: Konovalov et al. (2018) Konovalov, D.A., Saleh, A., Domingos, J.A., White, R.D.,
    Jerry, D.R., 2018. Estimating Mass of Harvested Asian Seabass Lates calcarifer
    from Images. World Journal of Engineering and Technology 6, 15. doi:[10.4236/wjet.2018.63b003](https:/doi.org/10.4236/wjet.2018.63b003).
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konovalov 等人（2018）Konovalov, D.A., Saleh, A., Domingos, J.A., White, R.D., Jerry,
    D.R., 2018. 从图像中估算收获的亚洲鲈鱼 Lates calcarifer 的质量。世界工程与技术杂志 6, 15。doi:[10.4236/wjet.2018.63b003](https:/doi.org/10.4236/wjet.2018.63b003)。
- en: 'Konovalov et al. (2019b) Konovalov, D.A., Saleh, A., Efremova, D.B., Domingos,
    J.A., Jerry, D.R., 2019b. Automatic weight estimation of harvested fish from images,
    in: Digital Image Computing: Techniques and Applications (DICTA), pp. 1–7.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Konovalov 等人（2019b）Konovalov, D.A., Saleh, A., Efremova, D.B., Domingos, J.A.,
    Jerry, D.R., 2019b. 从图像中自动估算收获鱼的重量，见：数字图像计算：技术与应用（DICTA），第1–7页。
- en: 'Kotsiantis (2007) Kotsiantis, S.B., 2007. Supervised machine learning: A review
    of classification techniques. doi:[10.31449/inf.v31i3.148](https:/doi.org/10.31449/inf.v31i3.148).'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kotsiantis（2007）Kotsiantis, S.B., 2007. 监督式机器学习：分类技术综述。doi:[10.31449/inf.v31i3.148](https:/doi.org/10.31449/inf.v31i3.148)。
- en: 'Kukačka et al. (2017) Kukačka, J., Golkov, V., Cremers, D., 2017. Regularization
    for deep learning: A taxonomy. arXiv preprint arXiv:1710.10686 .'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kukačka 等人（2017）Kukačka, J., Golkov, V., Cremers, D., 2017. 深度学习的正则化：一个分类法。arXiv
    预印本 arXiv:1710.10686。
- en: 'Kushawaha et al. (2021) Kushawaha, R.K., Kumar, S., Banerjee, B., Velmurugan,
    R., 2021. Distilling Spikes: Knowledge Distillation in Spiking Neural Networks.
    doi:[10.1109/icpr48806.2021.9412147](https:/doi.org/10.1109/icpr48806.2021.9412147).'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kushawaha 等人（2021）Kushawaha, R.K., Kumar, S., Banerjee, B., Velmurugan, R.,
    2021. 生成尖峰：尖峰神经网络中的知识蒸馏。doi:[10.1109/icpr48806.2021.9412147](https:/doi.org/10.1109/icpr48806.2021.9412147)。
- en: 'Labao and Naval (2017) Labao, A.B., Naval, P.C., 2017. Weakly-Labelled semantic
    segmentation of fish objects in underwater videos using a deep residual network,
    in: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
    Intelligence and Lecture Notes in Bioinformatics). doi:[10.1007/978-3-319-54430-4_25](https:/doi.org/10.1007/978-3-319-54430-4_25).'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Labao 和 Naval（2017）Labao, A.B., Naval, P.C., 2017. 使用深度残差网络对水下视频中的鱼类物体进行弱标签语义分割，见：计算机科学讲义（包括人工智能讲义和生物信息学讲义）。doi:[10.1007/978-3-319-54430-4_25](https:/doi.org/10.1007/978-3-319-54430-4_25)。
- en: Labao and Naval (2019a) Labao, A.B., Naval, P.C., 2019a. Cascaded deep network
    systems with linked ensemble components for underwater fish detection in the wild.
    Ecological Informatics doi:[10.1016/j.ecoinf.2019.05.004](https:/doi.org/10.1016/j.ecoinf.2019.05.004).
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Labao 和 Naval（2019a）Labao, A.B., Naval, P.C., 2019a. 用于野外水下鱼类检测的级联深度网络系统与链接集成组件。生态信息学
    doi:[10.1016/j.ecoinf.2019.05.004](https:/doi.org/10.1016/j.ecoinf.2019.05.004)。
- en: 'Labao and Naval (2019b) Labao, A.B., Naval, P.C., 2019b. Simultaneous Localization
    and Segmentation of Fish Objects Using Multi-task CNN and Dense CRF, in: Lecture
    Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence
    and Lecture Notes in Bioinformatics). doi:[10.1007/978-3-030-14799-0_52](https:/doi.org/10.1007/978-3-030-14799-0_52).'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Labao 和 Naval（2019b）Labao, A.B., Naval, P.C., 2019b. 使用多任务CNN和稠密CRF同时进行鱼类物体的定位与分割，见：计算机科学讲义（包括人工智能讲义和生物信息学讲义）。doi:[10.1007/978-3-030-14799-0_52](https:/doi.org/10.1007/978-3-030-14799-0_52)。
- en: Lammie et al. (2019) Lammie, C., Olsen, A., Carrick, T., Rahimi Azghadi, M.,
    2019. Low-power and high-speed deep FPGA inference engines for weed classification
    at the edge. IEEE Access doi:[10.1109/ACCESS.2019.2911709](https:/doi.org/10.1109/ACCESS.2019.2911709).
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lammie 等人 (2019) Lammie, C., Olsen, A., Carrick, T., Rahimi Azghadi, M., 2019.
    用于边缘杂草分类的低功耗高速深度FPGA推理引擎. IEEE Access doi:[10.1109/ACCESS.2019.2911709](https:/doi.org/10.1109/ACCESS.2019.2911709).
- en: 'Laradji et al. (2021a) Laradji, I., Rodriguez, P., Manas, O., Lensink, K.,
    Law, M., Kurzman, L., Parker, W., Vazquez, D., Nowrouzezahrai, D., 2021a. A Weakly
    Supervised Consistency-based Learning Method for COVID-19 Segmentation in CT Images,
    in: WACV.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Laradji 等人 (2021a) Laradji, I., Rodriguez, P., Manas, O., Lensink, K., Law,
    M., Kurzman, L., Parker, W., Vazquez, D., Nowrouzezahrai, D., 2021a. 基于一致性弱监督学习的方法用于CT图像中的COVID-19分割，收录于:
    WACV.'
- en: 'Laradji et al. (2020) Laradji, I., Saleh, A., Rodriguez, P., Nowrouzezahrai,
    D., Azghadi, M.R., Vazquez, D., 2020. Affinity LCFCN: Learning to Segment Fish
    with Weak Supervision URL: [http://arxiv.org/abs/2011.03149](http://arxiv.org/abs/2011.03149).'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Laradji 等人 (2020) Laradji, I., Saleh, A., Rodriguez, P., Nowrouzezahrai, D.,
    Azghadi, M.R., Vazquez, D., 2020. Affinity LCFCN: 学习通过弱监督分割鱼类. URL: [http://arxiv.org/abs/2011.03149](http://arxiv.org/abs/2011.03149).'
- en: 'Laradji et al. (2021b) Laradji, I.H., Saleh, A., Rodriguez, P., Nowrouzezahrai,
    D., Azghadi, M.R., Vazquez, D., 2021b. Weakly supervised underwater fish segmentation
    using affinity LCFCN. Scientific reports 11, 17379. URL: [https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733](https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733),
    doi:[10.1038/s41598-021-96610-2](https:/doi.org/10.1038/s41598-021-96610-2).'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Laradji 等人 (2021b) Laradji, I.H., Saleh, A., Rodriguez, P., Nowrouzezahrai,
    D., Azghadi, M.R., Vazquez, D., 2021b. 使用Affinity LCFCN的弱监督水下鱼类分割. 《科学报告》11, 17379.
    URL: [https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733](https://www.nature.com/articles/s41598-021-96610-2http://www.ncbi.nlm.nih.gov/pubmed/34462458http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC8405733),
    doi:[10.1038/s41598-021-96610-2](https:/doi.org/10.1038/s41598-021-96610-2).'
- en: 'LeCun et al. (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. Deep learning.
    Nature 521, 436–444. URL: [http://www.nature.com/articles/nature14539](http://www.nature.com/articles/nature14539),
    doi:[10.1038/nature14539](https:/doi.org/10.1038/nature14539).'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'LeCun 等人 (2015) LeCun, Y., Bengio, Y., Hinton, G., 2015. 深度学习. 《自然》521, 436–444.
    URL: [http://www.nature.com/articles/nature14539](http://www.nature.com/articles/nature14539),
    doi:[10.1038/nature14539](https:/doi.org/10.1038/nature14539).'
- en: 'Ledig et al. (2017) Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham,
    A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., Shi, W., 2017. Photo-realistic
    single image super-resolution using a generative adversarial network, in: Proceedings
    - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017,
    pp. 105–114. doi:[10.1109/CVPR.2017.19](https:/doi.org/10.1109/CVPR.2017.19).'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ledig 等人 (2017) Ledig, C., Theis, L., Huszár, F., Caballero, J., Cunningham,
    A., Acosta, A., Aitken, A., Tejani, A., Totz, J., Wang, Z., Shi, W., 2017. 使用生成对抗网络进行照片级真实感单图像超分辨率，收录于:
    第30届IEEE计算机视觉与模式识别会议论文集, CVPR 2017, 页 105–114. doi:[10.1109/CVPR.2017.19](https:/doi.org/10.1109/CVPR.2017.19).'
- en: 'Lee et al. (2018) Lee, K.H., He, X., Zhang, L., Yang, L., 2018. CleanNet: Transfer
    Learning for Scalable Image Classifier Training with Label Noise, in: Proceedings
    of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition.
    doi:[10.1109/CVPR.2018.00571](https:/doi.org/10.1109/CVPR.2018.00571).'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lee 等人 (2018) Lee, K.H., He, X., Zhang, L., Yang, L., 2018. CleanNet: 用于标注噪声的可扩展图像分类器训练的迁移学习，收录于:
    IEEE计算机学会计算机视觉与模式识别会议论文集. doi:[10.1109/CVPR.2018.00571](https:/doi.org/10.1109/CVPR.2018.00571).'
- en: 'Lennox et al. (2017) Lennox, R.J., Aarestrup, K., Cooke, S.J., Cowley, P.D.,
    Deng, Z.D., Fisk, A.T., Harcourt, R.G., Heupel, M., Hinch, S.G., Holland, K.N.,
    Hussey, N.E., Iverson, S.J., Kessel, S.T., Kocik, J.F., Lucas, M.C., Flemming,
    J.M., Nguyen, V.M., Stokesbury, M.J., Vagle, S., Vanderzwaag, D.L., Whoriskey,
    F.G., Young, N., 2017. Envisioning the Future of Aquatic Animal Tracking: Technology,
    Science, and Application. doi:[10.1093/biosci/bix098](https:/doi.org/10.1093/biosci/bix098).'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lennox 等人 (2017) Lennox, R.J., Aarestrup, K., Cooke, S.J., Cowley, P.D., Deng,
    Z.D., Fisk, A.T., Harcourt, R.G., Heupel, M., Hinch, S.G., Holland, K.N., Hussey,
    N.E., Iverson, S.J., Kessel, S.T., Kocik, J.F., Lucas, M.C., Flemming, J.M., Nguyen,
    V.M., Stokesbury, M.J., Vagle, S., Vanderzwaag, D.L., Whoriskey, F.G., Young,
    N., 2017. 展望水生动物跟踪的未来: 技术、科学与应用. doi:[10.1093/biosci/bix098](https:/doi.org/10.1093/biosci/bix098).'
- en: 'Li and Du (2021) Li, D., Du, L., 2021. Recent advances of deep learning algorithms
    for aquacultural machine vision systems with emphasis on fish. Artificial Intelligence
    Review , 1–40URL: [https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3](https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3),
    doi:[10.1007/s10462-021-10102-3](https:/doi.org/10.1007/s10462-021-10102-3).'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Du (2021) Li, D., Du, L., 2021. 深度学习算法在水产养殖机器视觉系统中的近期进展，重点关注鱼类。人工智能评论，1–40，网址：[https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3](https://link.springer.com/article/10.1007/s10462-021-10102-3https://link.springer.com/10.1007/s10462-021-10102-3)，doi：[10.1007/s10462-021-10102-3](https:/doi.org/10.1007/s10462-021-10102-3)。
- en: 'Li et al. (2009) Li, L.J., Li, K., Li, F.F., Deng, J., Dong, W., Socher, R.,
    Fei-Fei, L., 2009. ImageNet: a Large-Scale Hierarchical Image Database Shrimp
    Project View project hybrid intrusion detction systems View project ImageNet:
    A Large-Scale Hierarchical Image Database. 2009 IEEE Conference on Computer Vision
    and Pattern Recognition .'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Li 等 (2009) Li, L.J., Li, K., Li, F.F., Deng, J., Dong, W., Socher, R., Fei-Fei,
    L., 2009. ImageNet: 大规模层次化图像数据库虾项目查看项目混合入侵检测系统查看项目ImageNet: 大规模层次化图像数据库。2009 IEEE
    计算机视觉与模式识别会议。'
- en: 'Li et al. (2015) Li, X., Shang, M., Qin, H., Chen, L., 2015. Fast accurate
    fish detection and recognition of underwater images with Fast R-CNN, in: OCEANS
    2015 - MTS/IEEE Washington, pp. 1–5. doi:[https://doi.org/10.23919/OCEANS.2015.7404464](https:/doi.org/https://doi.org/10.23919/OCEANS.2015.7404464).'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2015) Li, X., Shang, M., Qin, H., Chen, L., 2015. 使用 Fast R-CNN 进行水下图像的快速准确鱼类检测与识别，发表于：OCEANS
    2015 - MTS/IEEE 华盛顿，页码 1–5。doi：[https://doi.org/10.23919/OCEANS.2015.7404464](https:/doi.org/https://doi.org/10.23919/OCEANS.2015.7404464)。
- en: 'Li et al. (2020) Li, Z., Li, W., Li, F., Yuan, M., 2020. A Review of Computer
    Vision Technologies for Fish Tracking URL: [https://arxiv.org/abs/2110.02551v3](https://arxiv.org/abs/2110.02551v3),
    doi:[10.48550/arxiv.2110.02551](https:/doi.org/10.48550/arxiv.2110.02551).'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2020) Li, Z., Li, W., Li, F., Yuan, M., 2020. 计算机视觉技术在鱼类跟踪中的综述，网址：[https://arxiv.org/abs/2110.02551v3](https://arxiv.org/abs/2110.02551v3)，doi：[10.48550/arxiv.2110.02551](https:/doi.org/10.48550/arxiv.2110.02551)。
- en: 'Lin et al. (2016) Lin, D., Dai, J., Jia, J., He, K., Sun, J., 2016. Scribblesup:
    Scribble-supervised convolutional networks for semantic segmentation, pp. 3159–3167.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Lin 等 (2016) Lin, D., Dai, J., Jia, J., He, K., Sun, J., 2016. Scribblesup:
    基于涂鸦的卷积网络进行语义分割，页码 3159–3167。'
- en: 'Lin et al. (2014) Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P.,
    Ramanan, D., Dollár, P., Zitnick, C.L., 2014. Microsoft COCO: Common objects in
    context, in: Lecture Notes in Computer Science (including subseries Lecture Notes
    in Artificial Intelligence and Lecture Notes in Bioinformatics). doi:[10.1007/978-3-319-10602-1_48](https:/doi.org/10.1007/978-3-319-10602-1_48).'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等 (2014) Lin, T.Y., Maire, M., Belongie, S., Hays, J., Perona, P., Ramanan,
    D., Dollár, P., Zitnick, C.L., 2014. 微软 COCO：上下文中的常见物体，发表于：计算机科学讲义（包括人工智能讲义和生物信息学讲义）。doi：[10.1007/978-3-319-10602-1_48](https:/doi.org/10.1007/978-3-319-10602-1_48)。
- en: 'Lindeberg (2012) Lindeberg, T., 2012. Scale Invariant Feature Transform. Scholarpedia
    7, 10491. URL: [http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform](http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform),
    doi:[10.4249/scholarpedia.10491](https:/doi.org/10.4249/scholarpedia.10491).'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lindeberg (2012) Lindeberg, T., 2012. 尺度不变特征变换。Scholarpedia 7, 10491。网址：[http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform](http://www.scholarpedia.org/article/Scale_Invariant_Feature_Transform)，doi：[10.4249/scholarpedia.10491](https:/doi.org/10.4249/scholarpedia.10491)。
- en: 'Liu et al. (2018) Liu, L., Lu, H., Cao, Z., Xiao, Y., 2018. Counting Fish in
    Sonar Images, in: Proceedings - International Conference on Image Processing,
    ICIP. doi:[10.1109/ICIP.2018.8451154](https:/doi.org/10.1109/ICIP.2018.8451154).'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等 (2018) Liu, L., Lu, H., Cao, Z., Xiao, Y., 2018. 声纳图像中的鱼类计数，发表于：国际图像处理会议论文集，ICIP。doi：[10.1109/ICIP.2018.8451154](https:/doi.org/10.1109/ICIP.2018.8451154)。
- en: 'Lumauag and Nava (2019) Lumauag, R., Nava, M., 2019. Fish tracking and counting
    using image processing, in: 2018 IEEE 10th International Conference on Humanoid,
    Nanotechnology, Information Technology, Communication and Control, Environment
    and Management, HNICEM 2018. doi:[10.1109/HNICEM.2018.8666369](https:/doi.org/10.1109/HNICEM.2018.8666369).'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lumauag 和 Nava (2019) Lumauag, R., Nava, M., 2019. 使用图像处理进行鱼类跟踪和计数，发表于：2018
    IEEE 第十届国际人形机器人、纳米技术、信息技术、通信与控制、环境与管理会议，HNICEM 2018。doi：[10.1109/HNICEM.2018.8666369](https:/doi.org/10.1109/HNICEM.2018.8666369)。
- en: Mader et al. (2018) Mader, A.O., Lorenz, C., Bergtholdt, M., von Berg, J., Schramm,
    H., Modersitzki, J., Meyer, C., 2018. Detection and localization of spatially
    correlated point landmarks in medical images using an automatically learned conditional
    random field. Computer Vision and Image Understanding doi:[10.1016/j.cviu.2018.09.009](https:/doi.org/10.1016/j.cviu.2018.09.009).
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mader 等（2018）Mader, A.O., Lorenz, C., Bergtholdt, M., von Berg, J., Schramm,
    H., Modersitzki, J., Meyer, C., 2018. 使用自动学习的条件随机场在医学图像中检测和定位空间相关的点标记。Computer
    Vision and Image Understanding doi:[10.1016/j.cviu.2018.09.009](https:/doi.org/10.1016/j.cviu.2018.09.009)。
- en: 'Mahmood et al. (2016) Mahmood, A., Bennamoun, M., An, S., Sohel, F., Boussaid,
    F., Hovey, R., Kendrick, G., Fisher, R.B., 2016. Coral classification with hybrid
    feature representations, in: Proceedings - International Conference on Image Processing,
    ICIP. doi:[10.1109/ICIP.2016.7532411](https:/doi.org/10.1109/ICIP.2016.7532411).'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mahmood 等（2016）Mahmood, A., Bennamoun, M., An, S., Sohel, F., Boussaid, F.,
    Hovey, R., Kendrick, G., Fisher, R.B., 2016. 使用混合特征表示进行珊瑚分类，见：国际图像处理会议论文集，ICIP。doi:[10.1109/ICIP.2016.7532411](https:/doi.org/10.1109/ICIP.2016.7532411)。
- en: 'Mandal et al. (2018) Mandal, R., Connolly, R.M., Schlacher, T.A., Stantic,
    B., 2018. Assessing fish abundance from underwater video using deep neural networks,
    in: Proceedings of the International Joint Conference on Neural Networks. doi:[10.1109/IJCNN.2018.8489482](https:/doi.org/10.1109/IJCNN.2018.8489482).'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mandal 等（2018）Mandal, R., Connolly, R.M., Schlacher, T.A., Stantic, B., 2018.
    使用深度神经网络从水下视频中评估鱼类丰度，见：国际神经网络联合会议论文集。doi:[10.1109/IJCNN.2018.8489482](https:/doi.org/10.1109/IJCNN.2018.8489482)。
- en: 'Mathur et al. (2020) Mathur, M., Vasudev, D., Sahoo, S., Jain, D., Goel, N.,
    2020. Crosspooled FishNet: transfer learning based fish species classification
    model. Multimedia Tools and Applications doi:[10.1007/s11042-020-09371-x](https:/doi.org/10.1007/s11042-020-09371-x).'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Mathur 等（2020）Mathur, M., Vasudev, D., Sahoo, S., Jain, D., Goel, N., 2020.
    Crosspooled FishNet: 基于迁移学习的鱼类物种分类模型。Multimedia Tools and Applications doi:[10.1007/s11042-020-09371-x](https:/doi.org/10.1007/s11042-020-09371-x)。'
- en: Meng et al. (2018) Meng, L., Hirayama, T., Oyanagi, S., 2018. Underwater-Drone
    with Panoramic Camera for Automatic Fish Recognition Based on Deep Learning. IEEE
    Access doi:[10.1109/ACCESS.2018.2820326](https:/doi.org/10.1109/ACCESS.2018.2820326).
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Meng 等（2018）Meng, L., Hirayama, T., Oyanagi, S., 2018. 基于深度学习的全景摄像头水下无人机自动鱼类识别。IEEE
    Access doi:[10.1109/ACCESS.2018.2820326](https:/doi.org/10.1109/ACCESS.2018.2820326)。
- en: 'Molchanov et al. (2016) Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz,
    J., 2016. Pruning Convolutional Neural Networks for Resource Efficient Transfer
    Learning. CoRR abs/1611.0. URL: [http://arxiv.org/abs/1611.06440](http://arxiv.org/abs/1611.06440).'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Molchanov 等（2016）Molchanov, P., Tyree, S., Karras, T., Aila, T., Kautz, J.,
    2016. 剪枝卷积神经网络以实现资源高效的迁移学习。CoRR abs/1611.0. URL: [http://arxiv.org/abs/1611.06440](http://arxiv.org/abs/1611.06440)。'
- en: 'Moniruzzaman et al. (2017) Moniruzzaman, M., Islam, S.M.S., Bennamoun, M.,
    Lavery, P., 2017. Deep learning on underwater marine object detection: A survey,
    in: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
    Intelligence and Lecture Notes in Bioinformatics), Springer Verlag. pp. 150–160.
    URL: [http://link.springer.com/10.1007/978-3-319-70353-4_13](http://link.springer.com/10.1007/978-3-319-70353-4_13),
    doi:[10.1007/978-3-319-70353-4_13](https:/doi.org/10.1007/978-3-319-70353-4_13).'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Moniruzzaman 等（2017）Moniruzzaman, M., Islam, S.M.S., Bennamoun, M., Lavery,
    P., 2017. 水下海洋物体检测中的深度学习：综述，见：计算机科学讲义（包括人工智能和生物信息学子系列），Springer Verlag。pp. 150–160.
    URL: [http://link.springer.com/10.1007/978-3-319-70353-4_13](http://link.springer.com/10.1007/978-3-319-70353-4_13),
    doi:[10.1007/978-3-319-70353-4_13](https:/doi.org/10.1007/978-3-319-70353-4_13)。'
- en: 'Naseer et al. (2020) Naseer, A., Baro, E.N., Khan, S.D., Gordillo, Y.V., 2020.
    Automatic Detection of Nephrops norvegicus Burrows in Underwater Images Using
    Deep Learning, in: 2020 Global Conference on Wireless and Optical Technologies,
    GCWOT 2020. doi:[10.1109/GCWOT49901.2020.9391590](https:/doi.org/10.1109/GCWOT49901.2020.9391590).'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Naseer 等（2020）Naseer, A., Baro, E.N., Khan, S.D., Gordillo, Y.V., 2020. 使用深度学习自动检测水下图像中的诺氏龙虾洞穴，见：2020
    全球无线和光纤技术大会，GCWOT 2020。doi:[10.1109/GCWOT49901.2020.9391590](https:/doi.org/10.1109/GCWOT49901.2020.9391590)。
- en: 'Ng (2004) Ng, A.Y., 2004. Feature selection, L1 vs. L2 regularization, and
    rotational invariance, in: Proceedings, Twenty-First International Conference
    on Machine Learning, ICML 2004. doi:[10.1145/1015330.1015435](https:/doi.org/10.1145/1015330.1015435).'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ng（2004）Ng, A.Y., 2004. 特征选择、L1 与 L2 正则化及旋转不变性，见：第二十一届国际机器学习会议论文集，ICML 2004。doi:[10.1145/1015330.1015435](https:/doi.org/10.1145/1015330.1015435)。
- en: 'Nilssen et al. (2017) Nilssen, I., Moller, T., Nattkemper, T.W., 2017. Active
    Learning for the Classification of Species in Underwater Images from a Fixed Observatory,
    in: Proceedings - 2017 IEEE International Conference on Computer Vision Workshops,
    ICCVW 2017, pp. 2891–2897. doi:[10.1109/ICCVW.2017.341](https:/doi.org/10.1109/ICCVW.2017.341).'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nilssen 等人 (2017) Nilssen, I., Moller, T., Nattkemper, T.W., 2017. 基于固定观测点的水下图像物种分类的主动学习，载于：2017年IEEE国际计算机视觉会议研讨会论文集，ICCVW
    2017，第2891–2897页。doi:[10.1109/ICCVW.2017.341](https:/doi.org/10.1109/ICCVW.2017.341)。
- en: Ogunlana et al. (2015) Ogunlana, S.O., Olabode, O., Oluwadare, S.A.A., 2015.
    Fish Classification Using Support Vector Machine. African Journal of Computing
    & ICT 8, 75–82.
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ogunlana 等人 (2015) Ogunlana, S.O., Olabode, O., Oluwadare, S.A.A., 2015. 使用支持向量机进行鱼类分类。《非洲计算与信息通信技术杂志》8,
    75–82。
- en: 'Olsen et al. (2019) Olsen, A., Konovalov, D.A., Philippa, B., Ridd, P., Wood,
    J.C., Johns, J., Banks, W., Girgenti, B., Kenny, O., Whinney, J., Calvert, B.,
    Azghadi, M.R., White, R.D., 2019. DeepWeeds: A Multiclass Weed Species Image Dataset
    for Deep Learning. Scientific Reports 9, 2058. URL: [https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3](https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3),
    doi:[10.1038/s41598-018-38343-3](https:/doi.org/10.1038/s41598-018-38343-3).'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Olsen 等人 (2019) Olsen, A., Konovalov, D.A., Philippa, B., Ridd, P., Wood, J.C.,
    Johns, J., Banks, W., Girgenti, B., Kenny, O., Whinney, J., Calvert, B., Azghadi,
    M.R., White, R.D., 2019. DeepWeeds：一个用于深度学习的多类别杂草物种图像数据集。《科学报告》9, 2058。网址：[https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3](https://www.nature.com/articles/s41598-018-38343-3http://www.nature.com/articles/s41598-018-38343-3)，doi:[10.1038/s41598-018-38343-3](https:/doi.org/10.1038/s41598-018-38343-3)。
- en: 'Oquab et al. (2015) Oquab, M., Bottou, L., Laptev, I., Sivic, J., 2015. Is
    object localization for free? - Weakly-supervised learning with convolutional
    neural networks, in: Proceedings of the IEEE Computer Society Conference on Computer
    Vision and Pattern Recognition. doi:[10.1109/CVPR.2015.7298668](https:/doi.org/10.1109/CVPR.2015.7298668).'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oquab 等人 (2015) Oquab, M., Bottou, L., Laptev, I., Sivic, J., 2015. 目标定位是否免费？-
    使用卷积神经网络的弱监督学习，载于：IEEE计算机学会计算机视觉与模式识别会议论文集。doi:[10.1109/CVPR.2015.7298668](https:/doi.org/10.1109/CVPR.2015.7298668)。
- en: 'Pathak et al. (2018) Pathak, A.R., Pandey, M., Rautaray, S., 2018. Application
    of Deep Learning for Object Detection, in: Procedia Computer Science. doi:[10.1016/j.procs.2018.05.144](https:/doi.org/10.1016/j.procs.2018.05.144).'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pathak 等人 (2018) Pathak, A.R., Pandey, M., Rautaray, S., 2018. 深度学习在目标检测中的应用，载于：《计算机科学学报》。doi:[10.1016/j.procs.2018.05.144](https:/doi.org/10.1016/j.procs.2018.05.144)。
- en: Pathak et al. (2015) Pathak, D., Krähenbühl, P., Darrell, T., Krahenbuhl, P.,
    Darrell, T., 2015. Constrained Convolutional Neural Networks for Weakly Supervised
    Segmentation. 2015 IEEE International Conference on Computer Vision (ICCV) , 1796–1804.
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pathak 等人 (2015) Pathak, D., Krähenbühl, P., Darrell, T., Krahenbuhl, P., Darrell,
    T., 2015. 用于弱监督分割的约束卷积神经网络。2015年IEEE国际计算机视觉会议 (ICCV)，1796–1804。
- en: 'Potdar et al. (2020) Potdar, A.M., Narayan, D.G., Kengond, S., Mulla, M.M.,
    2020. Performance Evaluation of Docker Container and Virtual Machine, in: Procedia
    Computer Science, pp. 1419–1428. doi:[10.1016/j.procs.2020.04.152](https:/doi.org/10.1016/j.procs.2020.04.152).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Potdar 等人 (2020) Potdar, A.M., Narayan, D.G., Kengond, S., Mulla, M.M., 2020.
    Docker容器与虚拟机的性能评估，载于：《计算机科学学报》，第1419–1428页。doi:[10.1016/j.procs.2020.04.152](https:/doi.org/10.1016/j.procs.2020.04.152)。
- en: '(98) Qi, X., Liu, Z., Shi, J., Zhao, H., Jia, J., . Augmented feedback in semantic
    segmentation under image level supervision, in: European Conference on Computer
    Vision, Springer. pp. 90–105.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (98) Qi, X., Liu, Z., Shi, J., Zhao, H., Jia, J., . 在图像级监督下的语义分割中的增强反馈，载于：欧洲计算机视觉会议，Springer，第90–105页。
- en: 'Qian et al. (2016) Qian, Z.M., Wang, S.H., Cheng, X.E., Chen, Y.Q., 2016. An
    effective and robust method for tracking multiple fish in video image based on
    fish head detection. BMC Bioinformatics 17, 251. URL: [http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1138-y](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1138-y),
    doi:[10.1186/s12859-016-1138-y](https:/doi.org/10.1186/s12859-016-1138-y).'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Qian 等人 (2016) Qian, Z.M., Wang, S.H., Cheng, X.E., Chen, Y.Q., 2016. 基于鱼头检测的多鱼追踪的有效且稳健的方法。《BMC生物信息学》17,
    251。网址：[http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1138-y](http://bmcbioinformatics.biomedcentral.com/articles/10.1186/s12859-016-1138-y)，doi:[10.1186/s12859-016-1138-y](https:/doi.org/10.1186/s12859-016-1138-y)。
- en: Qiu et al. (2018) Qiu, C., Zhang, S., Wang, C., Yu, Z., Zheng, H., Zheng, B.,
    2018. Improving transfer learning and squeeze- and-excitation networks for small-scale
    fine-grained fish image classification. IEEE Access 6, 78503–78512. doi:[10.1109/ACCESS.2018.2885055](https:/doi.org/10.1109/ACCESS.2018.2885055).
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rajchl et al. (2016) Rajchl, M., Lee, M.C.H., Oktay, O., Kamnitsas, K., Passerat-Palmbach,
    J., Bai, W., Damodaram, M., Rutherford, M.A., Hajnal, J.V., Kainz, B., 2016. Deepcut:
    Object segmentation from bounding box annotations using convolutional neural networks.
    IEEE transactions on medical imaging 36, 683.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rassadin and Savchenko (2017) Rassadin, A.G., Savchenko, A.V., 2017. Compressing
    deep convolutional neural networks in visual emotion recognition, in: CEUR Workshop
    Proceedings. doi:[10.18287/1613-0073-2017-1901-207-213](https:/doi.org/10.18287/1613-0073-2017-1901-207-213).'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Ren, S., He, K., Girshick, R., Sun, J., 2015. Faster r-cnn:
    Towards real-time object detection with region proposal networks, in: NIPS.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2017) Ren, S., He, K., Girshick, R., Sun, J., 2017. Faster R-CNN:
    Towards Real-Time Object Detection with Region Proposal Networks. IEEE Trans.
    Pattern Anal. Mach. Intell. 39, 1137–1149. URL: [https://doi.org/10.1109/TPAMI.2016.2577031](https://doi.org/10.1109/TPAMI.2016.2577031),
    doi:[10.1109/TPAMI.2016.2577031](https:/doi.org/10.1109/TPAMI.2016.2577031).'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rojas and Rojas (1996) Rojas, R., Rojas, R., 1996. The Backpropagation Algorithm,
    in: Neural Networks. doi:[10.1007/978-3-642-61068-4_7](https:/doi.org/10.1007/978-3-642-61068-4_7).'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rova et al. (2007) Rova, A., Mori, G., Dill, L.M., 2007. One fish, two fish,
    butterfish, trumpeter: Recognizing fish in underwater video, in: Proceedings of
    IAPR Conference on Machine Vision Applications, MVA 2007, pp. 404–407.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saberioon and Cisar (2016) Saberioon, M.M., Cisar, P., 2016. Automated multiple
    fish tracking in three-Dimension using a Structured Light Sensor. Computers and
    Electronics in Agriculture doi:[10.1016/j.compag.2015.12.014](https:/doi.org/10.1016/j.compag.2015.12.014).
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saleh et al. (2020a) Saleh, A., Laradji, I.H., Konovalov, D.A., Bradley, M.,
    Vazquez, D., Sheaves, M., 2020a. A realistic fish-habitat dataset to evaluate
    algorithms for underwater visual analysis. Scientific Reports 10, 14671. URL:
    [http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x](http://www.ncbi.nlm.nih.gov/pubmed/32887922http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC7473859https://www.nature.com/articles/s41598-020-71639-x),
    doi:[10.1038/s41598-020-71639-x](https:/doi.org/10.1038/s41598-020-71639-x).'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saleh et al. (2020b) Saleh, A., Laradji, I.H., Konovalov, D.A., Bradley, M.,
    Vazquez, D., Sheaves, M., 2020b. A realistic fish-habitat dataset to evaluate
    algorithms for underwater visual analysis. Scientific Reports 10, 14671. URL:
    [https://www.nature.com/articles/s41598-020-71639-x](https://www.nature.com/articles/s41598-020-71639-x),
    doi:[10.1038/s41598-020-71639-x](https:/doi.org/10.1038/s41598-020-71639-x).'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saleh et al. (2021) Saleh, A., Laradji, I.H., Lammie, C., Vazquez, D., Flavell,
    C.A., Azghadi, M.R., 2021. A Deep Learning Localization Method for Measuring Abdominal
    Muscle Dimensions in Ultrasound Images. IEEE Journal of Biomedical and Health
    Informatics 25, 3865–3873. URL: [https://ieeexplore.ieee.org/document/9444630/](https://ieeexplore.ieee.org/document/9444630/),
    doi:[10.1109/JBHI.2021.3085019](https:/doi.org/10.1109/JBHI.2021.3085019).'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Saleh et al. (2022) Saleh, A., Sheaves, M., Rahimi Azghadi, M., 2022. Computer
    vision and deep learning for fish classification in underwater habitats: A survey.
    Fish and Fisheries URL: [https://onlinelibrary.wiley.com/doi/10.1111/faf.12666](https://onlinelibrary.wiley.com/doi/10.1111/faf.12666),
    doi:[10.1111/faf.12666](https:/doi.org/10.1111/faf.12666).'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salman et al. (2019) Salman, A., Siddiqui, S.A., Shafait, F., Mian, A., Shortis,
    M.R., Khurshid, K., Ulges, A., Schwanecke, U., 2019. Automatic fish detection
    in underwater videos by a deep neural network-based hybrid motion learning system.
    ICES Journal of Marine Science .
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salman et al. (2020) Salman, A., Siddiqui, S.A., Shafait, F., Mian, A., Shortis,
    M.R., Khurshid, K., Ulges, A., Schwanecke, U., 2020. Automatic fish detection
    in underwater videos by a deep neural network-based hybrid motion learning system.
    ICES Journal of Marine Science doi:[10.1093/icesjms/fsz025](https:/doi.org/10.1093/icesjms/fsz025).
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sarigül and Avci (2017) Sarigül, M., Avci, M., 2017. Comparison of Different
    Deep Structures for Fish Classification. International Journal of Computer Theory
    and Engineering doi:[10.7763/ijcte.2017.v9.1167](https:/doi.org/10.7763/ijcte.2017.v9.1167).
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schneider and Zhuang (2020) Schneider, S., Zhuang, A., 2020. Counting Fish
    and Dolphins in Sonar Images Using Deep Learning. arXiv preprint arXiv:2007.12808
    URL: [http://arxiv.org/abs/2007.12808](http://arxiv.org/abs/2007.12808).'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shelhamer et al. (2017) Shelhamer, E., Long, J., Darrell, T., 2017. Fully Convolutional
    Networks for Semantic Segmentation. IEEE Transactions on Pattern Analysis and
    Machine Intelligence 39, 640–651. doi:[10.1109/TPAMI.2016.2572683](https:/doi.org/10.1109/TPAMI.2016.2572683).
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shimada et al. (2021) Shimada, T., Bao, H., Sato, I., Sugiyama, M., 2021. Classification
    From Pairwise Similarities/Dissimilarities and Unlabeled Data via Empirical Risk
    Minimization. Neural Computation 33, 1234–1268. URL: [https://direct.mit.edu/neco/article/33/5/1234/97483/Classification-From-Pairwise-Similarities](https://direct.mit.edu/neco/article/33/5/1234/97483/Classification-From-Pairwise-Similarities),
    doi:[10.1162/neco_a_01373](https:/doi.org/10.1162/neco_a_01373).'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Shimada 等人 (2021) Shimada, T., Bao, H., Sato, I., Sugiyama, M., 2021. 基于成对相似性/不相似性和未标记数据的分类通过经验风险最小化。神经计算
    33, 1234–1268。网址: [https://direct.mit.edu/neco/article/33/5/1234/97483/Classification-From-Pairwise-Similarities](https://direct.mit.edu/neco/article/33/5/1234/97483/Classification-From-Pairwise-Similarities),
    doi:[10.1162/neco_a_01373](https:/doi.org/10.1162/neco_a_01373).'
- en: 'Siddiqui et al. (2018) Siddiqui, S.A., Salman, A., Malik, M.I., Shafait, F.,
    Mian, A., Shortis, M.R., Harvey, E.S., 2018. Automatic fish species classification
    in underwater videos: Exploiting pre-trained deep neural network models to compensate
    for limited labelled data. ICES Journal of Marine Science doi:[10.1093/icesjms/fsx109](https:/doi.org/10.1093/icesjms/fsx109).'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Siddiqui 等人 (2018) Siddiqui, S.A., Salman, A., Malik, M.I., Shafait, F., Mian,
    A., Shortis, M.R., Harvey, E.S., 2018. 水下视频中的鱼类种类自动分类：利用预训练的深度神经网络模型来弥补标注数据的不足。ICES
    海洋科学期刊 doi:[10.1093/icesjms/fsx109](https:/doi.org/10.1093/icesjms/fsx109).
- en: Sun et al. (2019) Sun, S., Cao, Z., Zhu, H., Zhao, J., 2019. A Survey of Optimization
    Methods From a Machine Learning Perspective. IEEE Transactions on Cybernetics
    , 1–14doi:[10.1109/tcyb.2019.2950779](https:/doi.org/10.1109/tcyb.2019.2950779).
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等人 (2019) Sun, S., Cao, Z., Zhu, H., Zhao, J., 2019. 从机器学习的角度审视优化方法。IEEE
    网络学报 , 1–14 doi:[10.1109/tcyb.2019.2950779](https:/doi.org/10.1109/tcyb.2019.2950779).
- en: 'Szegedy et al. (2015a) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S.,
    Anguelov, D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2015a. Going deeper with
    convolutions, in: 2015 IEEE Conference on Computer Vision and Pattern Recognition
    (CVPR), pp. 1–9.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人 (2015a) Szegedy, C., Liu, W., Jia, Y., Sermanet, P., Reed, S., Anguelov,
    D., Erhan, D., Vanhoucke, V., Rabinovich, A., 2015a. 深度卷积网络，见：2015 IEEE 计算机视觉与模式识别会议
    (CVPR), pp. 1–9.
- en: Szegedy et al. (2015b) Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna,
    Z., 2015b. Rethinking the Inception Architecture for Computer Vision. CoRR abs/1512.0.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Szegedy 等人 (2015b) Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna,
    Z., 2015b. 重新思考计算机视觉中的 Inception 架构。CoRR abs/1512.0.
- en: 'Tarling et al. (2021) Tarling, P., Cantor, M., Clapés, A., Escalera, S., 2021.
    DEEP LEARNING WITH SELF-SUPERVISION AND UNCERTAINTY REGULARIZATION TO COUNT FISH
    IN UNDERWATER IMAGES. Technical Report. Other. URL: [http://www.echoview.com.](http://www.echoview.com.)'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Tarling 等人 (2021) Tarling, P., Cantor, M., Clapés, A., Escalera, S., 2021.
    使用自监督学习和不确定性正则化进行深度学习以计数水下图像中的鱼类。技术报告。其他。网址: [http://www.echoview.com.](http://www.echoview.com.)'
- en: 'Villon et al. (2016) Villon, S., Chaumont, M., Subsol, G., Villéger, S., Claverie,
    T., Mouillot, D., 2016. Coral reef fish detection and recognition in underwater
    videos by supervised machine learning: Comparison between deep learning and HOG+SVM
    methods, in: Lecture Notes in Computer Science (including subseries Lecture Notes
    in Artificial Intelligence and Lecture Notes in Bioinformatics). doi:[10.1007/978-3-319-48680-2_15](https:/doi.org/10.1007/978-3-319-48680-2_15).'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Villon 等人 (2016) Villon, S., Chaumont, M., Subsol, G., Villéger, S., Claverie,
    T., Mouillot, D., 2016. 通过监督机器学习在水下视频中检测和识别珊瑚礁鱼类：深度学习与 HOG+SVM 方法的比较，见：计算机科学讲义（包括人工智能讲义和生物信息学讲义）。doi:[10.1007/978-3-319-48680-2_15](https:/doi.org/10.1007/978-3-319-48680-2_15).
- en: Villon et al. (2018) Villon, S., Mouillot, D., Chaumont, M., Darling, E.S.,
    Subsol, G., Claverie, T., Villéger, S., 2018. A Deep learning method for accurate
    and fast identification of coral reef fishes in underwater images. Ecological
    Informatics doi:[10.1016/j.ecoinf.2018.09.007](https:/doi.org/10.1016/j.ecoinf.2018.09.007).
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Villon 等人 (2018) Villon, S., Mouillot, D., Chaumont, M., Darling, E.S., Subsol,
    G., Claverie, T., Villéger, S., 2018. 一种深度学习方法用于在水下图像中准确且快速地识别珊瑚礁鱼类。生态信息学期刊 doi:[10.1016/j.ecoinf.2018.09.007](https:/doi.org/10.1016/j.ecoinf.2018.09.007).
- en: Vogels et al. (2005) Vogels, T.P., Rajan, K., Abbott, L.F., 2005. Neural network
    dynamics. doi:[10.1146/annurev.neuro.28.061604.135637](https:/doi.org/10.1146/annurev.neuro.28.061604.135637).
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vogels 等人 (2005) Vogels, T.P., Rajan, K., Abbott, L.F., 2005. 神经网络动态。doi:[10.1146/annurev.neuro.28.061604.135637](https:/doi.org/10.1146/annurev.neuro.28.061604.135637).
- en: Wang et al. (2018) Wang, D., Vinson, R., Holmes, M., Seibel, G., 2018. Convolutional
    neural network guided blue crab knuckle detection for autonomous crab meat picking
    machine. Optical Engineering doi:[10.1117/1.oe.57.4.043103](https:/doi.org/10.1117/1.oe.57.4.043103).
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2017) Wang, G., Hwang, J.N., Williams, K., Wallace, F., Rose,
    C.S., 2017. Shrinking encoding with two-level codebook learning for fine-grained
    fish recognition, in: Proceedings - 2nd Workshop on Computer Vision for Analysis
    of Underwater Imagery, CVAUI 2016 - In Conjunction with International Conference
    on Pattern Recognition, ICPR 2016, pp. 31–36. doi:[10.1109/CVAUI.2016.18](https:/doi.org/10.1109/CVAUI.2016.18).'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang et al. (2020) Wang, P., Chen, Q., He, X., Cheng, J., 2020. Towards Accurate
    Post-training Network Quantization via Bit-Split and Stitching, in: PMLR. PMLR,
    pp. 9847–9856. URL: [http://proceedings.mlr.press/v119/wang20c.html](http://proceedings.mlr.press/v119/wang20c.html).'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wang and Kanwar (2021) Wang, S., Kanwar, P., 2021. BFloat16: The secret to
    high performance on Cloud TPUs {$\vert$} Google Cloud Blog. URL: [https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus](https://cloud.google.com/blog/products/ai-machine-learning/bfloat16-the-secret-to-high-performance-on-cloud-tpus).'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wei et al. (2018) Wei, Y., Xiao, H., Shi, H., Jie, Z., Feng, J., Huang, T.S.,
    2018. Revisiting dilated convolution: A simple approach for weakly-and semi-supervised
    semantic segmentation, pp. 7268–7277.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wörz and Rohr (2006) Wörz, S., Rohr, K., 2006. Localization of anatomical point
    landmarks in 3D medical images by fitting 3D parametric intensity models. Medical
    Image Analysis doi:[10.1016/j.media.2005.02.003](https:/doi.org/10.1016/j.media.2005.02.003).
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Wu and Prasad (2018) Wu, H., Prasad, S., 2018. Semi-Supervised Deep Learning
    Using Pseudo Labels for Hyperspectral Image Classification. IEEE Transactions
    on Image Processing 27, 1259–1270. URL: [http://ieeexplore.ieee.org/document/8105856/](http://ieeexplore.ieee.org/document/8105856/),
    doi:[10.1109/TIP.2017.2772836](https:/doi.org/10.1109/TIP.2017.2772836).'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xu and Matzner (2018) Xu, W., Matzner, S., 2018. Underwater Fish Detection
    Using Deep Learning for Water Power Applications, in: 2018 International Conference
    on Computational Science and Computational Intelligence (CSCI), IEEE. pp. 313–318.
    URL: [https://ieeexplore.ieee.org/document/8947884/](https://ieeexplore.ieee.org/document/8947884/),
    doi:[10.1109/CSCI46756.2018.00067](https:/doi.org/10.1109/CSCI46756.2018.00067).'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Xue et al. (2016) Xue, Y., Ray, N., Hugh, J., Bigras, G., 2016. Cell counting
    by regression using convolutional neural network, in: Lecture Notes in Computer
    Science (including subseries Lecture Notes in Artificial Intelligence and Lecture
    Notes in Bioinformatics). doi:[10.1007/978-3-319-46604-0_20](https:/doi.org/10.1007/978-3-319-46604-0_20).'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yang et al. (2021) Yang, L., Liu, Y., Yu, H., Fang, X., Song, L., Li, D., Chen,
    Y., 2021. Computer Vision Models in Intelligent Aquaculture with Emphasis on Fish
    Detection and Behavior Analysis: A Review. Archives of Computational Methods in
    Engineering 28, 2785–2816. URL: [https://link.springer.com/10.1007/s11831-020-09486-2](https://link.springer.com/10.1007/s11831-020-09486-2),
    doi:[10.1007/s11831-020-09486-2](https:/doi.org/10.1007/s11831-020-09486-2).'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2017) Zhang, S., Wu, G., Costeira, J.P., Moura, J.M.F., 2017.
    Understanding Traffic Density from Large-Scale Web Camera Data, in: 2017 IEEE
    Conference on Computer Vision and Pattern Recognition (CVPR), pp. 5898–5907. doi:[https://doi.org/10.1109/CVPR.2017.454](https:/doi.org/https://doi.org/10.1109/CVPR.2017.454).'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhang et al. (2022) Zhang, W., Wu, C., Bao, Z., 2022. DPANet: Dual Pooling-aggregated
    Attention Network for fish segmentation. IET Computer Vision 16, 67–82. URL: [https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065](https://onlinelibrary.wiley.com/doi/10.1049/cvi2.12065),
    doi:[10.1049/cvi2.12065](https:/doi.org/10.1049/cvi2.12065).'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhao et al. (2021) Zhao, S., Zhang, S., Liu, J., Wang, H., Zhu, J., Li, D.,
    Zhao, R., 2021. Application of machine learning in intelligent fish aquaculture:
    A review. Aquaculture 540, 736724. URL: [https://linkinghub.elsevier.com/retrieve/pii/S0044848621003860](https://linkinghub.elsevier.com/retrieve/pii/S0044848621003860),
    doi:[10.1016/j.aquaculture.2021.736724](https:/doi.org/10.1016/j.aquaculture.2021.736724).'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhao et al. (2019) Zhao, X., Yan, S., Gao, Q., 2019. An Algorithm for Tracking
    Multiple Fish Based on Biological Water Quality Monitoring. IEEE Access doi:[10.1109/ACCESS.2019.2895072](https:/doi.org/10.1109/ACCESS.2019.2895072).
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhou (2018) Zhou, Z.H., 2018. A brief introduction to weakly supervised learning.
    doi:[10.1093/nsr/nwx106](https:/doi.org/10.1093/nsr/nwx106).
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zhuang et al. (2017) Zhuang, P., Xing, L., Liu, Y., Guo, S., Qiao, Y., 2017.
    Marine Animal detection and Recognition with advanced deep learning models, in:
    CEUR Workshop Proceedings.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zivkovic and van der Heijden (2006) Zivkovic, Z., van der Heijden, F., 2006.
    Efficient adaptive density estimation per image pixel for the task of background
    subtraction. Pattern Recognition Letters 27, 773–780. doi:[https://doi.org/10.1016/j.patrec.2005.11.005](https:/doi.org/https://doi.org/10.1016/j.patrec.2005.11.005).
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zurowietz and Nattkemper (2020) Zurowietz, M., Nattkemper, T.W., 2020. Unsupervised
    Knowledge Transfer for Object Detection in Marine Environmental Monitoring and
    Exploration. IEEE Access 8, 143558–143568. doi:[10.1109/ACCESS.2020.3014441](https:/doi.org/10.1109/ACCESS.2020.3014441).
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
