- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:53:34'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:53:34
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2107.00272] A Survey on Graph-Based Deep Learning for Computational Histopathology'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2107.00272] 基于图的深度学习在计算病理学中的调查'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2107.00272](https://ar5iv.labs.arxiv.org/html/2107.00272)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2107.00272](https://ar5iv.labs.arxiv.org/html/2107.00272)
- en: A Survey on Graph-Based Deep Learning
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 关于基于图的深度学习的调查
- en: for Computational Histopathology
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 计算病理学
- en: 'David Ahmedt-Aristizabal, Mohammad Ali Armin, Simon Denman, Clinton Fookes,
    Lars Petersson D. Ahmedt-Aristizabal, A. Armin and L. Petersson are with the Imaging
    and Computer Vision group, CSIRO Data61, Canberra, Australia. (Corresponding author:
    david.ahmedtaristizabal@data61.csiro.au)D. Ahmedt-Aristizabal, S. Denman and C.
    Fookes are with SAIVT, Queensland University of Technology, Brisbane, Australia.'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: David Ahmedt-Aristizabal、Mohammad Ali Armin、Simon Denman、Clinton Fookes、Lars
    Petersson D. Ahmedt-Aristizabal、A. Armin 和 L. Petersson 隶属于澳大利亚堪培拉 CSIRO Data61
    的成像与计算机视觉组。（通讯作者：david.ahmedtaristizabal@data61.csiro.au）D. Ahmedt-Aristizabal、S.
    Denman 和 C. Fookes 还隶属于澳大利亚布里斯班昆士兰科技大学的 SAIVT。
- en: Abstract
  id: totrans-9
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: With the remarkable success of representation learning for prediction problems,
    we have witnessed a rapid expansion of the use of machine learning and deep learning
    for the analysis of digital pathology and biopsy image patches. However, learning
    over patch-wise features using convolutional neural networks limits the ability
    of the model to capture global contextual information and comprehensively model
    tissue composition. The phenotypical and topological distribution of constituent
    histological entities play a critical role in tissue diagnosis. As such, graph
    data representations and deep learning have attracted significant attention for
    encoding tissue representations, and capturing intra- and inter- entity level
    interactions. In this review, we provide a conceptual grounding for graph analytics
    in digital pathology, including entity-graph construction and graph architectures,
    and present their current success for tumor localization and classification, tumor
    invasion and staging, image retrieval, and survival prediction. We provide an
    overview of these methods in a systematic manner organized by the graph representation
    of the input image, scale, and organ on which they operate. We also outline the
    limitations of existing techniques, and suggest potential future research directions
    in this domain.
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 随着表示学习在预测问题中的显著成功，我们见证了机器学习和深度学习在数字病理学和活检图像块分析中的快速扩展。然而，使用卷积神经网络在图像块特征上进行学习限制了模型捕捉全局上下文信息和全面建模组织成分的能力。组织诊断中，组织成分的表型和拓扑分布起着关键作用。因此，图数据表示和深度学习在编码组织表示以及捕捉内部和外部实体级交互方面吸引了大量关注。在这篇综述中，我们为数字病理学中的图分析提供了概念基础，包括实体图构建和图架构，并展示了它们在肿瘤定位和分类、肿瘤侵袭和分期、图像检索和生存预测方面的当前成功。我们以系统化的方式概述了这些方法，按输入图像的图表示、尺度和操作的器官进行组织。我们还概述了现有技术的局限性，并建议了该领域的潜在未来研究方向。
- en: 'Index Terms:'
  id: totrans-11
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 关键词：
- en: Digital pathology, Cancer classification, Cell-graph, Tissue-graph, Hierarchical
    graph representation, Graph Convolutional Networks, Deep learning.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 数字病理学、癌症分类、细胞图、组织图、层次图表示、图卷积网络、深度学习。
- en: I Introduction
  id: totrans-13
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: Recent advances in deep learning techniques have rapidly transformed these approaches
    into the methodology of choice for analyzing medical images, and in particular
    for histology image classification problems [[1](#bib.bib1)]. Because of the increasing
    availability of large scale high-resolution whole-slide images (WSI) of tissue
    specimens, digital pathology and microscopy have become appealing application
    areas for deep learning algorithms. Given wide variations in pathology and the
    often time-consuming diagnosis process, clinical experts have begun to benefit
    from computer-aided detection and diagnosis methods capable of learning features
    that optimally represent the data [[2](#bib.bib2)]. This thorough survey serves
    as an accurate guide to biomedical engineering and clinical research communities
    interested in discovering the tissue composition-to-functionality relationship
    using image-to-graph translation and deep learning.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，深度学习技术的进步迅速将这些方法转变为分析医学图像的首选方法，尤其是在组织学图像分类问题中 [[1](#bib.bib1)]。由于大规模高分辨率组织样本全切片图像（WSI）的日益普及，数字病理学和显微镜学已成为深度学习算法的吸引人应用领域。考虑到病理学的广泛变异和常常耗时的诊断过程，临床专家开始从能够学习最优数据特征的计算机辅助检测和诊断方法中受益 [[2](#bib.bib2)]。这篇详尽的综述作为生物医学工程和临床研究社区感兴趣于使用图像到图的翻译和深度学习发现组织成分与功能关系的准确指南。
- en: There are several review papers available that analyse the benefits of deep
    learning for providing reliable support for microscopic and digital pathology
    diagnosis and treatment decisions [[3](#bib.bib3), [4](#bib.bib4), [1](#bib.bib1),
    [5](#bib.bib5), [6](#bib.bib6)], and specifically for cancer diagnosis [[7](#bib.bib7)].
    Compared to other medical fields such as dermatology, ophthalmology, neurology,
    cardiology, and radiology, digital pathology and microscopy is one of the most
    dominant medical applications of deep learning. One driving force behind innovation
    in computational pathology has been the introduction of grand challenges (e.g.
    NuCLS [[8](#bib.bib8)], BACH [[9](#bib.bib9)], MoNuSeg [[10](#bib.bib10)]). Developed
    techniques that offer decision support to human pathologists have shown bright
    prospects for detecting, segmenting, and classifying the cell and nucleus; and
    detecting and classifying diseases such as cancer.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 有几篇综述论文分析了深度学习在提供可靠支持以进行显微镜和数字病理学诊断及治疗决策方面的好处 [[3](#bib.bib3), [4](#bib.bib4),
    [1](#bib.bib1), [5](#bib.bib5), [6](#bib.bib6)]，特别是在癌症诊断方面 [[7](#bib.bib7)]。与皮肤科、眼科、神经科、心脏病学和放射学等其他医学领域相比，数字病理学和显微镜学是深度学习最具主导地位的医学应用之一。推动计算病理学创新的一个重要因素是重大挑战的引入（如NuCLS [[8](#bib.bib8)]、BACH [[9](#bib.bib9)]、MoNuSeg [[10](#bib.bib10)]）。开发的技术为人类病理学家提供决策支持，展示了在检测、分割和分类细胞及细胞核方面的光明前景；并且在检测和分类疾病如癌症方面也展现了潜力。
- en: '![Refer to caption](img/c5b360083e0ee42d7c1199cc4803f008.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/c5b360083e0ee42d7c1199cc4803f008.png)'
- en: 'Figure 1: Traditional CNNs excel at modelling local relations in grid representation,
    where the topology of the neighborhood is constant (Left). GCNs can take into
    account different neighbouring relations (global relation) by going beyond the
    local pixel neighbourhoods used by convolutions. On a graph, the neighbours of
    a node are unordered and variable in size (Right).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：传统的卷积神经网络（CNN）在网格表示中擅长建模局部关系，其中邻域的拓扑结构是恒定的（左）。图卷积网络（GCN）可以通过超越卷积使用的局部像素邻域来考虑不同的邻接关系（全局关系）。在图上，节点的邻居是无序的且大小可变的（右）。
- en: Deep learning techniques such as convolutional neural networks (CNNs) have demonstrated
    success in extracting image-level representations, however, they are inefficient
    when dealing with relation-aware representations. Modern deep learning variations
    of graph neural networks (GNNs) have made a significant impact in many technological
    domains for describing relationships. Graphs, by definition, capture relationships
    between entities and can thus be used to encode relational information between
    variables [[11](#bib.bib11)]. As a result, special emphasis has been placed on
    the generalisation of GNNs into non-structured and structured scenarios. Traditional
    CNNs analyse local areas based on fixed connectivity (determined by the convolutional
    kernel), leading to limited performance, and difficulty in interpreting the structures
    being modeled. Graphs, on the other hand, offer more flexibility to analyse unordered
    data by preserving neighboring relations. This difference is illustrated in Fig. [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology").
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习技术，如卷积神经网络（CNNs），在提取图像级表示方面已取得成功，但在处理关系感知表示时效率较低。现代深度学习图神经网络（GNNs）的变体在许多技术领域中对描述关系产生了重大影响。图定义上捕捉实体之间的关系，因此可以用于编码变量之间的关系信息 [[11](#bib.bib11)]。因此，特意强调了将GNNs推广到非结构化和结构化场景中的一般化。传统的CNNs基于固定连接（由卷积核决定）分析局部区域，导致性能有限，并且难以解释所建模的结构。另一方面，图提供了更多的灵活性来分析无序数据，通过保留邻接关系。这种差异在图 [1](#S1.F1
    "Figure 1 ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology")中进行了说明。
- en: '![Refer to caption](img/64c408407a4265e075e1ff5770b8b47f.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![请参见说明](img/64c408407a4265e075e1ff5770b8b47f.png)'
- en: 'Figure 2: Top: Graph-based representation of images for relation-aware human-object
    interaction, image segmentation, and human pose estimation (left-to-right). Images
    adapted from [[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)]. Bottom: A.
    Cell-graph representation for prostate cancer. B. Tissue-graph representation
    for colorectal cancer. C. Hierarchical cell-to-tissue graph representation for
    breast cancer. Images adapted from [[15](#bib.bib15), [16](#bib.bib16), [17](#bib.bib17)].'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：上：用于关系感知人机交互、图像分割和人体姿态估计的基于图的图像表示（从左到右）。图像改编自 [[12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14)]。下：A. 前列腺癌的细胞图表示。B. 结直肠癌的组织图表示。C. 乳腺癌的层次细胞到组织图表示。图像改编自 [[15](#bib.bib15),
    [16](#bib.bib16), [17](#bib.bib17)]。
- en: The adaptation of deep learning from images to graphs has received increased
    attention, leading to a new cross-domain field of graph-based deep learning which
    seeks to learn informative representations of graphs in an end-to-end manner.
    This field has exhibited remarkable success for various tasks as discussed by
    recent surveys on graph deep learning frameworks and their applications [[18](#bib.bib18),
    [19](#bib.bib19), [11](#bib.bib11), [20](#bib.bib20)]. Graph embeddings have appeared
    in computer vision tasks where graphs can efficiently define relationships between
    objects, or for the purpose of graph-structured image analysis. Interesting results
    have been obtained for object detection, semantic segmentation, skeleton-based
    action recognition, image classification and human-object interaction tasks as
    illustrated in Fig. [2](#S1.F2 "Figure 2 ‣ I Introduction ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology") (Top).
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习从图像到图的适应已受到越来越多的关注，形成了一个新的跨领域图基深度学习领域，旨在以端到端的方式学习图的有用表示。该领域在各种任务中表现出了显著的成功，正如最近关于图深度学习框架及其应用的调查所讨论的 [[18](#bib.bib18),
    [19](#bib.bib19), [11](#bib.bib11), [20](#bib.bib20)]。图嵌入已出现在计算机视觉任务中，其中图可以有效地定义对象之间的关系，或用于图结构图像分析。对于对象检测、语义分割、基于骨架的动作识别、图像分类和人机交互任务已获得有趣的结果，如图 [2](#S1.F2
    "Figure 2 ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology")（上所示）。
- en: Medical applications have benefited from rapid progress in the field of computer
    vision and GNNs. The development of GNNs has seen the application of deep learning
    methods to GNNs, such as graph convolutional networks (GCNs). These models have
    been proposed as a powerful tool to model functional and anatomical structures,
    brain electrical activity, and segmentation of the vasculature system and organs [[21](#bib.bib21)].
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 医学应用已经从计算机视觉和GNNs领域的快速进展中受益。GNNs的发展见证了深度学习方法应用于GNNs，例如图卷积网络（GCNs）。这些模型被提出作为一种强大的工具，用于建模功能和解剖结构、大脑电活动以及血管系统和器官的分割 [[21](#bib.bib21)]。
- en: Histological images depict the micro-anatomy of a tissue sample, and pathologists
    use histological images to make diagnoses based on morphological changes in tissues,
    the spatial relationship between cells, cell density, and other factors. Graph-based
    methods, which can capture geometrical and topological properties, are able to
    model cell-level information and overall tissue micro-architecture. Prior to the
    advent of deep learning, numerous approaches for processing histopathological
    images as graphs were investigated [[22](#bib.bib22)]. These methods used classical
    machine learning approaches, which are less accurate for graph classification
    compared to GCNs. The capabilities of graph-based deep learning, which bridges
    the gap between deep learning methods and traditional cell graphs for disease
    diagnosis, are yet to be sufficiently investigated.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 组织学图像描绘了组织样本的微观解剖结构，病理学家使用组织学图像根据组织的形态变化、细胞之间的空间关系、细胞密度和其他因素做出诊断。基于图的方法能够捕捉几何和拓扑属性，从而建模细胞级信息和整体组织微结构。在深度学习出现之前，已经研究了许多将组织病理学图像处理为图的方法 [[22](#bib.bib22)]。这些方法使用了经典的机器学习方法，相较于GCNs，图分类的准确性较低。基于图的深度学习的能力，将深度学习方法与传统细胞图桥接，用于疾病诊断，尚需充分探讨。
- en: In this survey, we analyse how graph embeddings are employed in histopathology
    diagnosis and analysis. While graphs are not directly expressed within this data,
    they can efficiently describe relationships between tissue regions and cells.
    This setting offers a very different task for GNNs in comparison to analysis of
    unstructured data such as electrophysiological and neuroimaging recordings where
    the data can be directly mapped to a graph [[21](#bib.bib21)]. Selected samples
    of graph representations in digital pathology (cell-graph, patch-graph, tissue-graph
    and cell-tissue representation) used to capture and learn relevant morphological
    regions that will be covered in this review are illustrated in Fig. [2](#S1.F2
    "Figure 2 ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology") (Bottom).
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 在本综述中，我们分析了图嵌入在组织病理学诊断和分析中的应用。虽然图在这些数据中没有直接表达，但它们可以有效地描述组织区域和细胞之间的关系。这种设置为GNNs提供了与分析如电生理和神经影像记录等非结构化数据不同的任务，其中数据可以直接映射到图 [[21](#bib.bib21)]。用于捕捉和学习相关形态学区域的数字病理学中图表示的选定样本（细胞图、补丁图、组织图和细胞-组织表示）将在本综述中介绍，如图 [2](#S1.F2
    "Figure 2 ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology")（底部）所示。
- en: This survey offers a comprehensive overview of preprocessing, graph models and
    explainability tools used in computational pathology, highlighting the capability
    of GNNs to detect and associate key tissue architectures, regions of interest,
    and their interdependence. Although some papers have surveyed conventional cell
    graphs with handcrafted features to characterize the entities [[22](#bib.bib22),
    [23](#bib.bib23)], and others have briefly touched upon the benefits of GCNs in
    biology and medicine [[24](#bib.bib24)], to the best of our knowledge, no systematic
    review exists that presents and discusses all relevant works concerning graph-based
    representations and deep learning models for computational pathology.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述提供了计算病理学中预处理、图模型和解释工具的全面概述，突出了GNNs检测和关联关键组织结构、兴趣区域及其相互依赖性的能力。虽然一些论文调查了使用手工特征的传统细胞图来表征实体 [[22](#bib.bib22),
    [23](#bib.bib23)]，其他论文则简要讨论了GCNs在生物学和医学中的好处 [[24](#bib.bib24)]，但据我们所知，尚无系统综述对基于图的表示和深度学习模型在计算病理学中的所有相关工作进行呈现和讨论。
- en: I-A Why graph-based deep learning for characterizing diseases through histopathology
    slides?
  id: totrans-26
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-A 为什么选择基于图的深度学习来通过组织病理学切片来表征疾病？
- en: Deep learning has increased the potential of medical image analysis by enabling
    the discovery of morphological and textural representations in images solely from
    the data. Although CNNs have shown impressive performance in the field of histopathology
    analysis, they are unable to capture complex neighborhood information as they
    analyse local areas determined by the convolutional kernel. To extract interaction
    information between objects, a CNN needs to reach sufficient depth by stacking
    multiple convolutional layers, which is inefficient. This leads to limitations
    in the performance and interpretability of the analysis of anatomical structures
    and microscopic samples.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习通过仅从数据中发现图像中的形态学和纹理表示，提高了医学图像分析的潜力。尽管卷积神经网络（CNNs）在组织病理分析领域表现出色，但由于它们只能分析由卷积核确定的局部区域，因此无法捕捉复杂的邻域信息。为了提取对象之间的交互信息，CNN需要通过堆叠多个卷积层达到足够的深度，这效率较低。这导致了解剖结构和显微样本分析性能和解释性的限制。
- en: 'Graph convolutional networks (GCNs) are a deep learning-based method that operate
    over graphs, and are becoming increasingly useful for medical diagnosis and analysis [[21](#bib.bib21)].
    GCNs can better exploit irregular relationships and preserve neighboring relations
    compared with CNN-based models [[11](#bib.bib11)]. Below we outline the reasons
    why current research in histopathology has shifted the analytical paradigm from
    pixel to entity-graph processing:'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图卷积网络（GCNs）是一种基于深度学习的方法，专门用于图形处理，正变得越来越有用于医学诊断和分析[[21](#bib.bib21)]。与基于CNN的模型相比，GCNs能够更好地利用不规则关系并保持邻近关系[[11](#bib.bib11)]。以下是当前组织病理学研究为何将分析范式从像素转向实体图处理的原因：
- en: '1.'
  id: totrans-29
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: The potential correlations among images are ignored during traditional CNN feature
    learning, however, a GCN can be introduced to estimate the dependencies between
    images and enhance the discriminative ability of CNN features [[25](#bib.bib25)].
  id: totrans-30
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 在传统的CNN特征学习过程中，图像之间的潜在相关性被忽视，而GCN可以用于估计图像之间的依赖关系，并增强CNN特征的区分能力[[25](#bib.bib25)]。
- en: '2.'
  id: totrans-31
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: CNNs have been commonly used for the analysis of whole slide images (WSI) by
    classifying fixed-sized biopsy image patches using fixed fusion rules such as
    averaging features or class scores, or weighted averaging with learnable weights
    to obtain an image-level classification score. Aggregation using a CNN also includes
    excessive whitespace, putting undue reliance on the orientation and location of
    the tissue segment. Even though CNN-based models have practical merits through
    considering important patches for prediction, they dismiss the spatial relationships
    between patches, or global contextual information. Architectures are required
    to be capable of dealing with size and shape variation in region-of-interests
    (ROIs), and must encode the spatial context of individual patches and their collective
    contribution to the diagnosis, which can be addressed with graph-based representations [[26](#bib.bib26),
    [27](#bib.bib27)].
  id: totrans-32
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: CNNs通常用于通过使用固定的融合规则（如特征或类别分数的平均，或使用可学习权重的加权平均）对固定大小的活检图像块进行分类，从而分析整个幻灯片图像（WSI）。使用CNN的聚合还包括过多的空白，过度依赖组织片段的方向和位置。尽管基于CNN的模型通过考虑重要的图像块进行预测具有实际优点，但它们忽略了图像块之间的空间关系或全局上下文信息。需要能够处理感兴趣区域（ROIs）大小和形状变化的架构，并且必须编码单个图像块的空间上下文及其对诊断的集体贡献，这可以通过基于图的表示来解决[[26](#bib.bib26),
    [27](#bib.bib27)]。
- en: '3.'
  id: totrans-33
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: A robust computer-aided detection system should be able to capture multi-scale
    contextual features in tissues, which can be difficult with traditional CNN-based
    models. A pathological image can be transformed into a graph representation to
    capture the cellular morphology and topology (cell-graph) [[28](#bib.bib28)],
    and the attributes of the tissue parts and their spatial relationships (tissue-graph) [[29](#bib.bib29),
    [17](#bib.bib17)].
  id: totrans-34
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 一个可靠的计算机辅助检测系统应该能够捕捉组织中的多尺度上下文特征，而这在传统的基于CNN的模型中可能很困难。可以将病理图像转换为图形表示，以捕捉细胞形态和拓扑（细胞图）[[28](#bib.bib28)]，以及组织部分的属性及其空间关系（组织图）[[29](#bib.bib29),
    [17](#bib.bib17)]。
- en: '4.'
  id: totrans-35
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: Graph representations can enhance the interpretation of the final representation
    by modeling relations among different regions of interest. Graph-based models
    offer a new way to verify existing observations in pathology. Attention mechanisms
    with GCNs, for example, highlight informative nuclei and inter-nuclear interactions,
    allowing the production of interpretable maps of tissue images displaying the
    contribution of each nucleus and its surroundings to the final diagnosis [[30](#bib.bib30)].
  id: totrans-36
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 图表示法可以通过建模不同感兴趣区域之间的关系来增强最终表示的解释。基于图的模型提供了一种新方式来验证病理学中的现有观察结果。例如，带有GCN的注意机制能够突出信息丰富的细胞核及其相互作用，从而生成可解释的组织图像地图，展示每个细胞核及其周围环境对最终诊断的贡献 [[30](#bib.bib30)]。
- en: '5.'
  id: totrans-37
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: By incorporating any task-specific prior pathological information, an entity-graph
    can be customized in various ways. As a result, pathology-specific interpretability
    and human-machine co-learning are enabled by the graph format [[31](#bib.bib31)].
  id: totrans-38
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 通过整合任何任务特定的先前病理信息，实体图可以以各种方式进行定制。因此，图形格式使得病理学特定的可解释性和人机协同学习成为可能 [[31](#bib.bib31)]。
- en: '6.'
  id: totrans-39
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: GCNs are a complimentary method to CNNs for morphological feature extraction,
    and they can be employed instead of, or in addition to CNNs during multimodal
    fusion for fine-grained patient stratification [[32](#bib.bib32)].
  id: totrans-40
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: GCN（图卷积网络）是一种补充CNN（卷积神经网络）的形态特征提取方法，它们可以在多模态融合过程中替代或补充CNN，以实现精细化的患者分层 [[32](#bib.bib32)]。
- en: I-B Contribution and organisation
  id: totrans-41
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-B 贡献和组织
- en: Compared to other recent reviews on traditional deep learning in histopathology
    slides, our manuscript captures the current efforts relating to entity-graphs
    and recent advancements in GCNs for characterizing diseases and pathology tasks.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 与其他关于传统深度学习在组织病理切片中的最新综述相比，我们的稿件捕捉了与实体图相关的当前努力和GCN在疾病和病理任务中应用的最新进展。
- en: Papers included in the survey are obtained from various journals, conference
    proceedings and open-access repositories. Table [I](#S1.T1 "TABLE I ‣ I-B Contribution
    and organisation ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for
    Computational Histopathology") outlines the applications that were addressed across
    all reviewed publications. It is noted that breast cancer analysis constitutes
    the major application in digital pathology that has been analyzed using graph-based
    deep learning techniques.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 调查中包括的论文来自各种期刊、会议论文集和开放获取的文献库。表 [I](#S1.T1 "TABLE I ‣ I-B Contribution and organisation
    ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")
    概述了所有评审出版物中涉及的应用。值得注意的是，乳腺癌分析构成了在数字病理学中主要的应用，该应用使用了基于图的深度学习技术进行分析。
- en: 'This review is divided into three major sections. In Section [II](#S2 "II Graph
    representation learning in digital pathology: Background ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology") we provide a technical overview
    of the prevailing tools for entity-graph representation and graph architectures
    used in accelerating digital pathology research. In Section [III](#S3 "III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology") we introduce the current applications of deep
    graph representation learning and cluster these proposals based on the graph construction
    (cell-graph, patch-graph, tissue-graph, hierarchical graph) and feature level
    fusion methods followed by the task or organ on which they operate. Finally, Section [IV](#S4
    "IV Discussion and open challenges ‣ A Survey on Graph-Based Deep Learning for
    Computational Histopathology") highlights open problems and perspectives regarding
    the shifting analytical paradigm from pixel to entity-based processing. Specifically,
    we discuss the topics of graph construction, embedding expert knowledge, complexity
    of graph models, training paradigms, and graph model interpretability.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 本综述分为三个主要部分。在第[II](#S2 "II 图形表示学习在数字病理学中的背景 ‣ 基于图的深度学习在计算组织病理学中的调查")节中，我们提供了加速数字病理学研究所用的实体图表示和图形架构的技术概述。在第[III](#S3
    "III 图形深度学习在数字病理学中的应用 ‣ 基于图的深度学习在计算组织病理学中的调查")节中，我们介绍了深度图表示学习的当前应用，并根据图的构建（细胞图、补丁图、组织图、层次图）和特征级融合方法对这些提案进行分类，随后按其操作的任务或器官分类。最后，第[IV](#S4
    "IV 讨论与开放挑战 ‣ 基于图的深度学习在计算组织病理学中的调查")节重点介绍了从像素到基于实体的处理分析范式转变的开放问题和前景。具体而言，我们讨论了图的构建、嵌入专家知识、图模型的复杂性、训练范式和图模型的可解释性等主题。
- en: 'TABLE I: Summary of applications of graph-based deep learning in histopathology
    covered in this survey.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '表 I: 本调查中覆盖的基于图的深度学习在组织病理学中的应用总结。'
- en: '| Application | #Applications | Reference |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 应用 | #Applications | 参考 |'
- en: '| --- | --- | --- |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- |'
- en: '| Breast cancer | 11 | [[33](#bib.bib33), [34](#bib.bib34), [30](#bib.bib30),
    [28](#bib.bib28), [35](#bib.bib35), [36](#bib.bib36), [26](#bib.bib26), [37](#bib.bib37),
    [31](#bib.bib31), [17](#bib.bib17), [29](#bib.bib29)] |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 乳腺癌 | 11 | [[33](#bib.bib33), [34](#bib.bib34), [30](#bib.bib30), [28](#bib.bib28),
    [35](#bib.bib35), [36](#bib.bib36), [26](#bib.bib26), [37](#bib.bib37), [31](#bib.bib31),
    [17](#bib.bib17), [29](#bib.bib29)] |'
- en: '| Colorectal cancer | 6 | [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40),
    [27](#bib.bib27), [41](#bib.bib41), [16](#bib.bib16)] |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| 结直肠癌 | 6 | [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [27](#bib.bib27),
    [41](#bib.bib41), [16](#bib.bib16)] |'
- en: '| Prostate cancer | 3 | [[15](#bib.bib15), [42](#bib.bib42), [30](#bib.bib30)]
    |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| 前列腺癌 | 3 | [[15](#bib.bib15), [42](#bib.bib42), [30](#bib.bib30)] |'
- en: '| Lung cancer | 3 | [[43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)]
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| 肺癌 | 3 | [[43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45)] |'
- en: '| Cervical cancer | 2 | [[46](#bib.bib46), [25](#bib.bib25)] |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 宫颈癌 | 2 | [[46](#bib.bib46), [25](#bib.bib25)] |'
- en: '| Lymphoma | 1 | [[16](#bib.bib16)] |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| 淋巴瘤 | 1 | [[16](#bib.bib16)] |'
- en: '| Skin cancer | 1 | [[47](#bib.bib47)] |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| 皮肤癌 | 1 | [[47](#bib.bib47)] |'
- en: '| Renal cancer | 1 | [[32](#bib.bib32)] |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| 肾癌 | 1 | [[32](#bib.bib32)] |'
- en: '| Total | 28 |  | ![Refer to caption](img/961fa285b2c4f45162c2cbc4ff223ec5.png)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '| 总计 | 28 |  | ![参见说明](img/961fa285b2c4f45162c2cbc4ff223ec5.png)'
- en: 'Figure 3: Overview of a standard graph-based workflow in computational pathology.
    The WSI image is first transformed into one or more graphs. 1. The entities can
    be nuclei, patches or tissue regions. 2. Node features comprise handcrafted or
    deep learning features to characterize the entities. 3. The edges encode intrinsic
    relationships (spatial or semantic) among the entities. 4. Graph encoding and
    classification (node-level or graph-level prediction): the graph representation
    is processed using GNNs and its variants such as ChebNet, GCN, GraphSAGE, GAT,
    and GIN, including different graph pooling strategies (global or hierarchical
    pooling). 5. Graph interpretations: a set of GNN model interpretability tools
    such as graph attentions or post-hoc graph explainers (e.g. GNNExplainer and GraphGrad-CAM.)'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3：计算病理学中标准图形工作流的概述。WSI图像首先转换为一个或多个图形。1. 实体可以是细胞核、补丁或组织区域。2. 节点特征包括手工制作或深度学习特征，用于表征实体。3.
    边缘编码实体之间的内在关系（空间或语义）。4. 图编码和分类（节点级或图级预测）：图形表示通过GNN及其变体（如ChebNet、GCN、GraphSAGE、GAT和GIN）处理，包括不同的图池策略（全局或层次池）。5.
    图解释：一组GNN模型解释工具，如图注意力或事后图解释器（例如GNNExplainer和GraphGrad-CAM）。
- en: II Graph representation learning
  id: totrans-58
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 图表示学习
- en: 'in digital pathology: Background'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字病理学中：背景
- en: Translating patient histopathological images into graphs to encode the spatial
    context of cells and tissues for a given patient has been used to improve prediction
    accuracy of various pathology tasks. Graph representations followed by GNN-based
    models and interpretability approaches allows pathologists to directly comprehend
    and reason for the outcomes. GNNs can also serve a variety of prediction purposes
    by adapting different designs, such as performing node-level and graph-level predictions.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 将患者的组织病理图像转换为图形，以编码细胞和组织的空间背景，这一方法已被用于提高各种病理任务的预测准确性。图形表示后，基于GNN的模型和解释性方法使病理学家能够直接理解和推理结果。GNN还可以通过适应不同的设计来服务于各种预测目的，如执行节点级和图级预测。
- en: 'A standard entity-graph based pathological workflow requires several phases,
    such as node and graph topology definition, as well as the choice of GNN architecture.
    In this section, we provide technical insights of these phases that are required
    for graph analytics in computational pathology: (1) Graph representation (entity,
    embeddings and edges definition); (2) Graph models (graph structures for processing
    graph-structured); and (3) Explainability (a set of interpretation methodologies
    such as model-based and post-hoc interpretability). A traditional framework with
    aforementioned phases is illustrated in Fig. [3](#S1.F3 "Figure 3 ‣ I-B Contribution
    and organisation ‣ I Introduction ‣ A Survey on Graph-Based Deep Learning for
    Computational Histopathology"). A deep analysis of each GNN model can be found
    in survey papers that deal with graph architectures [[11](#bib.bib11), [20](#bib.bib20)].'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 标准实体-图形病理工作流需要多个阶段，如节点和图形拓扑定义，以及GNN架构的选择。在本节中，我们提供了这些阶段的技术见解，这些阶段是计算病理学中图形分析所必需的：(1)
    图形表示（实体、嵌入和边缘定义）；(2) 图模型（处理图结构的图形结构）；(3) 可解释性（如模型基础和事后解释的解释方法）。图 [3](#S1.F3 "图
    3 ‣ I-B 贡献和组织 ‣ I 引言 ‣ 基于图的深度学习在计算组织病理学中的调查") 说明了具有上述阶段的传统框架。关于每个GNN模型的深入分析可以在处理图形架构的调查论文中找到[[11](#bib.bib11),
    [20](#bib.bib20)]。
- en: II-A Histopathology graph representation
  id: totrans-62
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A 组织病理学图形表示
- en: II-A1 Preliminaries
  id: totrans-63
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A1 基础知识
- en: A graph can be represented by $G=(\mathcal{V},\mathcal{E},W)$, where $V$ is
    a vertex set with $|\mathcal{V}|=n$ nodes and $\mathcal{E}$ denotes the set of
    edges connecting these nodes. Data in $\mathcal{V}$ can be represented by a feature
    matrix $\mathrm{X}\in\mathbb{R}^{n\times d}$, where $n$ and $d$ denote the input
    feature dimensions. $W\in\mathbb{R}^{n\times n}$ is a binary or weighted adjacency
    matrix describing the connections between any two nodes in $\mathcal{V}$, in which
    the importance of the connections between the i-th and the j-th nodes is measured
    by the entry $W$ in the i-th row and j-th column, and denoted $w_{ij}$. Commonly
    used methods to determine the entries, $w_{ij}$, of $W$ include Pearson correlation-based
    graph, the K-nearest neighbor (KNN) method, and the distance-based graph [[48](#bib.bib48)].
    In general, GNNs learn a feature transformation function for $\mathrm{X}$ and
    produce output $Z\in\mathbb{R}^{n\times d^{{}^{\prime}}}$ , where $d^{{}^{\prime}}$
    denotes the output feature dimension.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图可以用 $G=(\mathcal{V},\mathcal{E},W)$ 表示，其中 $V$ 是一个包含 $|\mathcal{V}|=n$ 个节点的顶点集合，$\mathcal{E}$
    表示连接这些节点的边的集合。$\mathcal{V}$ 中的数据可以用特征矩阵 $\mathrm{X}\in\mathbb{R}^{n\times d}$
    表示，其中 $n$ 和 $d$ 表示输入特征维度。$W\in\mathbb{R}^{n\times n}$ 是一个二进制或加权邻接矩阵，描述 $\mathcal{V}$
    中任意两个节点之间的连接，其中第 i 行第 j 列的 $W$ 条目表示第 i 个和第 j 个节点之间连接的重要性，记作 $w_{ij}$。常用的确定 $W$
    条目 $w_{ij}$ 的方法包括皮尔逊相关图、K 最近邻（KNN）方法和基于距离的图 [[48](#bib.bib48)]。一般来说，GNNs 学习一个特征变换函数
    $\mathrm{X}$ 并生成输出 $Z\in\mathbb{R}^{n\times d^{{}^{\prime}}}$，其中 $d^{{}^{\prime}}$
    表示输出特征维度。
- en: Presented graph methods in digital pathology typically use data in one of two
    forms. Whole slide images (WSI), also known as virtual microscopy, are high-resolution
    images generated by combining many smaller image tiles or strips and tiling them
    to form a single image. Tissue microarrays (TMAs) consist of paraffin blocks produced
    by extracting cylindrical tissue cores and inserting them into a single recipient
    block (microarray) in a precisely spaced pattern. With this technique, up to 1000
    tissue cores can be assembled in a single paraffin block to allow multiplex histological
    analysis.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字病理学中，呈现的图方法通常使用两种形式的数据之一。全切片图像（WSI），也称为虚拟显微镜，是通过将许多较小的图像块或条带组合并铺成单一图像而生成的高分辨率图像。组织微阵列（TMA）由石蜡块组成，这些石蜡块是通过提取圆柱形组织芯并将其插入到一个单一的接收块（微阵列）中，以精确的间距模式排列而成。通过这种技术，最多可以将1000个组织芯组装在一个石蜡块中，从而进行多重组织学分析。
- en: II-A2 Graph construction
  id: totrans-66
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A2 图构建
- en: Graph representations have been used in digital pathology for multiple tasks
    where a histology image is described as an entity-graph, and nodes and edges of
    a graph denote biological entities and inter-entity interactions respectively.
    The entities can be biologically-defined such as nuclei and tissue regions, or
    can be defined patch-wise. Therefore, constructing an entity-graph for graph analytics
    in computational pathology demands the following pre-processing steps.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 图表示法在数字病理学中已被用于多个任务，其中组织学图像被描述为实体图，图的节点和边分别表示生物实体和实体间的相互作用。实体可以是生物学定义的，如细胞核和组织区域，也可以是按块定义的。因此，为了进行计算病理学中的图分析，构建实体图需要以下预处理步骤。
- en: Node definition
  id: totrans-68
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 节点定义
- en: WSI usually includes significant non-tissue regions. To identify tissue regions
    the foreground is segmented with Gaussian smoothing and OTSU thresholding [[49](#bib.bib49)].
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: WSI 通常包括显著的非组织区域。为了识别组织区域，前景使用高斯平滑和 OTSU 阈值分割 [[49](#bib.bib49)]。
- en: One of the most common graph representation, cell-graphs, requires model training
    and fine-tuning for cell detection or segmentation. To detect nuclei several methods
    have been used such as Hover-Net [[50](#bib.bib50)], CIA-Net [[51](#bib.bib51)],
    UNet [[52](#bib.bib52)] and cGANs [[53](#bib.bib53)], that are trained on multi-organ
    nuclei segmentation datasets (MoNuSeg [[54](#bib.bib54)], PanNuke [[55](#bib.bib55)],
    CoNSep [[50](#bib.bib50)]). The entities can also be calculated using agglomerative
    clustering [[56](#bib.bib56)] of detected cells.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的图表示之一，细胞图，需要对细胞检测或分割进行模型训练和微调。为检测细胞核，已使用多种方法，如 Hover-Net [[50](#bib.bib50)]、CIA-Net [[51](#bib.bib51)]、UNet [[52](#bib.bib52)]
    和 cGANs [[53](#bib.bib53)]，这些方法在多个器官细胞核分割数据集（MoNuSeg [[54](#bib.bib54)]、PanNuke [[55](#bib.bib55)]、CoNSep [[50](#bib.bib50)]）上进行了训练。也可以通过对检测到的细胞进行凝聚聚类 [[56](#bib.bib56)]
    来计算这些实体。
- en: The nodes in a graph can also be represented by fixed-sized patches (patch-graphs)
    randomly sampled from the raw WSI or by using a patch selection method where non-tissue
    regions are removed [[57](#bib.bib57)]. Important patches can be sampled from
    segmented tissues using color thresholds where patches with similar features (tissue
    cluster) are modeled as a node. Pre-trained deep learning models on tissue datasets
    (e.g. NCT-CRC-HE-100 [[58](#bib.bib58)]) have also been used to detect the tumor
    region of the specific pathological task.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 图中的节点也可以通过从原始WSI中随机采样的固定大小的补丁（补丁图）表示，或者通过使用去除非组织区域的补丁选择方法[[57](#bib.bib57)]表示。可以使用颜色阈值从分割的组织中采样重要的补丁，其中具有相似特征（组织簇）的补丁被建模为一个节点。在组织数据集（例如NCT-CRC-HE-100
    [[58](#bib.bib58)]）上预训练的深度学习模型也被用来检测特定病理任务的肿瘤区域。
- en: Meaningful tissue regions have been also used as nodes to capture the tissue
    distribution (tissue-graphs). To separate tissue structures, superpixels [[59](#bib.bib59)]
    obtained using unsupervised algorithms such as simple linear iterative clustering
    (SLIC) [[60](#bib.bib60)]) become nodes.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 有意义的组织区域也被用作节点来捕捉组织分布（组织图）。为了分离组织结构，使用无监督算法（如简单线性迭代聚类（SLIC）[[60](#bib.bib60)]）获得的超像素[[59](#bib.bib59)]成为节点。
- en: Node embeddings
  id: totrans-73
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 节点嵌入
- en: Node features can comprise hand-crafted features including morphological and
    topological properties (e.g. shape, size, orientation, nuclei intensity, and the
    chromaticity using the gray-level co-occurrence matrix). For cell-graph representations,
    some works include learned features extracted from the trained model used to localise
    the nuclei.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 节点特征可以包括手工制作的特征，包括形态学和拓扑属性（例如形状、大小、方向、核强度，以及使用灰度共生矩阵的色度）。对于细胞图表示，一些研究包括从用于定位核的训练模型中提取的学习特征。
- en: In patch-graph methods, deep neural networks are used to automatically learn
    a feature representation from patches around the centroids of the nuclei and tissue
    regions. If the entity is larger than the specified patch size, multiple patches
    inside the entity are processed, and the final feature is computed as the mean
    of the patch-level deep features. Some works have aggregated features from neighboring
    patches and combined them to obtain a central node representation to increase
    feature learning performance. Authors have adopted CNNs (MobileNetV2, DenseNet,
    ResNet-18 or ResNet-50 [[61](#bib.bib61)]), and encoder-decoder segmentation models
    (UNet [[52](#bib.bib52)]) for the purpose of deep feature extraction. To generate
    patch-level embeddings, ImageNet-pretrained CNN as well as a CNN pretrained for
    tissue sub-compartment classification task have been used.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 在补丁图方法中，深度神经网络用于自动学习来自细胞核和组织区域质心周围补丁的特征表示。如果实体大于指定的补丁大小，则处理实体内部的多个补丁，最终特征计算为补丁级深度特征的均值。一些研究聚合了来自相邻补丁的特征，并将其组合以获得中心节点表示，从而提高特征学习性能。作者采用了CNN（MobileNetV2、DenseNet、ResNet-18或ResNet-50
    [[61](#bib.bib61)]）和编码器-解码器分割模型（UNet [[52](#bib.bib52)]）用于深度特征提取。为了生成补丁级嵌入，使用了ImageNet预训练的CNN以及用于组织子区域分类任务的预训练CNN。
- en: Edge definition
  id: totrans-76
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 边缘定义
- en: The edge configuration encodes the cellular or tissue interactions, i.e. how
    likely two nearby entities will interact and consequently form an edge. This topology
    is often defined heuristically using a pre-defined proximity threshold, a nearest
    neighbor rule, a probabilistic model, or a Waxman model [[22](#bib.bib22)]. The
    graph topology can also be computed by constructing a region adjacency graph (RAG)
     [[62](#bib.bib62)] by using the spatial centroids of superpixels.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 边缘配置编码了细胞或组织的交互，即两个相邻实体交互并形成边缘的可能性。该拓扑结构通常使用预定义的邻近阈值、最近邻规则、概率模型或Waxman模型[[22](#bib.bib22)]进行启发式定义。图拓扑结构也可以通过使用超像素的空间质心构建区域邻接图（RAG）[[62](#bib.bib62)]来计算。
- en: II-A3 Training paradigms
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-A3 训练范式
- en: From the perspective of supervision, we can categorize graph learning tasks
    into different training settings. Such approaches have also been used to extract
    effective representations from data.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 从监督的角度来看，我们可以将图学习任务分类为不同的训练设置。这些方法也被用来从数据中提取有效的表示。
- en: •
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: The Supervised learning setting provides labeled data for training.
  id: totrans-81
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 监督学习设置提供标注数据进行训练。
- en: •
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Weakly or partially supervised learning refers to models that are trained using
    examples that are only partially annotated.
  id: totrans-83
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 弱监督或部分监督学习指的是使用仅部分标注的示例来训练模型。
- en: •
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Semi-supervised learning trains a model using a small set of annotated samples,
    then generates pseudo-labels for a large set of samples without annotations, and
    learns a final model by mixing both sets of samples.
  id: totrans-85
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 半监督学习使用一小部分标注样本训练模型，然后为大量未标注样本生成伪标签，通过混合这两组样本来学习最终模型。
- en: •
  id: totrans-86
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Self-supervised learning is a form of unsupervised learning in which the data
    provides supervisory signals when learning a representation via a proxy task.
    Annotated data is used to fine-tune the representation once it has been learned.
    Some self-supervised approaches adopted as feature extractors include contrastive
    predictive coding (CPC) [[63](#bib.bib63)], texture auto encoder (Deep Ten) [[64](#bib.bib64)],
    and variational autoencoders (VAE) [[65](#bib.bib65)].
  id: totrans-87
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 自监督学习是一种无监督学习形式，在这种学习方式中，数据通过代理任务提供监督信号来学习表示。一旦表示被学习，就使用标注数据来微调表示。一些作为特征提取器的自监督方法包括对比预测编码
    (CPC) [[63](#bib.bib63)]、纹理自编码器 (Deep Ten) [[64](#bib.bib64)] 和变分自编码器 (VAE) [[65](#bib.bib65)]。
- en: II-B Graph neural networks models
  id: totrans-88
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 图神经网络模型
- en: Following graph building, the entity graph is processed using a graph-based
    deep learning model that works with graph-structured data to perform analysis.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 在图构建之后，实体图使用图结构数据的图深度学习模型进行处理，以执行分析。
- en: GCNs can be broadly categorised as spectral-based [[66](#bib.bib66), [67](#bib.bib67)]
    and spatial-based [[68](#bib.bib68)]. Spectral-based GCNs use spectral convolutional
    neural networks, that build upon the graph Fourier transform and the normalized
    Laplacian matrix of the graph. Spatial-based GCNs define a graph convolution operation
    based on spatial relationships that exist among graph nodes.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: GCNs 可以大致分为基于谱的方法[[66](#bib.bib66), [67](#bib.bib67)]和基于空间的方法[[68](#bib.bib68)]。基于谱的方法使用谱卷积神经网络，建立在图的傅里叶变换和图的标准化拉普拉斯矩阵之上。基于空间的方法定义了一种基于图节点之间空间关系的图卷积操作。
- en: Graph convolutional networks, similar to CNNs, learn abstract feature representations
    for each feature at a node via message passing, in which nodes successively aggregate
    feature vectors from their neighborhood to compute a new feature vector at the
    next hidden layer in the network.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图卷积网络类似于 CNN，通过消息传递为每个节点的特征学习抽象特征表示，在消息传递过程中，节点逐步从其邻域聚合特征向量，以计算网络中下一个隐藏层的新特征向量。
- en: 'A basic GNN consists of two components: The AGGREGATE operation can aggregate
    neighboring node representations of the center node, whereas the COMBINE operation
    combines the neighborhood node representation with the center node representation
    to generate the updated center node representation. The Aggregate and Combine
    at each $l-th$ layer of the GNN can be defined as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 一个基本的 GNN 由两个组件组成：AGGREGATE 操作可以聚合中心节点的邻居节点表示，而 COMBINE 操作则将邻域节点表示与中心节点表示结合起来，生成更新后的中心节点表示。GNN
    的每个 $l$ 层的 Aggregate 和 Combine 可以定义如下：
- en: '|  | $h_{\mathcal{N}_{v}}^{(t)}=\text{AGGREGATE}^{(l)}\left(\big{\{}h_{u}^{l-1},\forall
    u\in\mathcal{N}_{v}\big{\}}\right),$ |  | (1) |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '|  | $h_{\mathcal{N}_{v}}^{(t)}=\text{AGGREGATE}^{(l)}\left(\big{\{}h_{u}^{l-1},\forall
    u\in\mathcal{N}_{v}\big{\}}\right),$ |  | (1) |'
- en: where $h_{\mathcal{N}_{v}}^{(t)}$ is the aggregated node feature of the neighbourhood,
    $h_{u}^{l-1}$ is the node feature in neighbourhood $\mathcal{N}(\cdot)$ of node
    $v$.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $h_{\mathcal{N}_{v}}^{(t)}$ 是邻域的聚合节点特征，$h_{u}^{l-1}$ 是节点 $v$ 的邻域 $\mathcal{N}(\cdot)$
    中的节点特征。
- en: '|  | $\leavevmode\resizebox{186.45341pt}{}{$h_{v}^{(t)}=\text{COMBINE}^{(l)}\left(h_{v}^{t-1},h_{\mathcal{N}_{v}}^{(t)}\right)=\sigma(W^{t}\cdot[h_{v}^{t-1}\&#124;h_{\mathcal{N}_{v}}^{t}])$},$
    |  | (2) |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '|  | $\leavevmode\resizebox{186.45341pt}{}{$h_{v}^{(t)}=\text{COMBINE}^{(l)}\left(h_{v}^{t-1},h_{\mathcal{N}_{v}}^{(t)}\right)=\sigma(W^{t}\cdot[h_{v}^{t-1}\&#124;h_{\mathcal{N}_{v}}^{t}])$},$
    |  | (2) |'
- en: where $h_{v}^{(t)}$ is the node representation at the $l-th$ iteration. $h_{v}^{(0)}=x_{v}$
    where $x_{v}$ is the initial feature vector for the node, $\sigma$ denotes the
    logistic sigmoid function, and $\|$ denotes vector concatenation.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $h_{v}^{(t)}$ 是第 $l$ 次迭代中的节点表示。$h_{v}^{(0)}=x_{v}$ 其中 $x_{v}$ 是节点的初始特征向量，$\sigma$
    表示逻辑 sigmoid 函数，$\|$ 表示向量连接。
- en: 'With the network structure and node content information as inputs, the outputs
    of GNNs can focus on various graph analytic tasks using one of the processes listed
    below:'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 网络结构和节点内容信息作为输入，GNN 的输出可以专注于以下列出的各种图分析任务：
- en: •
  id: totrans-98
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Node-level prediction: A GNN operating at the node-level computes values for
    each node in the graph and is thus useful for node classification and regression
    purposes. In node classification, the task is to predict the node label for every
    node in a graph. To compute the node-level predictions, the node embedding is
    input to a Multi-Layer Perceptron (MLP) (See Fig. [4](#S2.F4 "Figure 4 ‣ II-B1
    ChebNet ‣ II-B Graph neural networks models ‣ II Graph representation learning
    in digital pathology: Background ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology")).'
  id: totrans-99
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '节点级预测：在节点级操作的GNN计算图中每个节点的值，因此适用于节点分类和回归目的。在节点分类中，任务是预测图中每个节点的标签。为了计算节点级预测，将节点嵌入输入到多层感知器（MLP）中（见图 [4](#S2.F4
    "Figure 4 ‣ II-B1 ChebNet ‣ II-B Graph neural networks models ‣ II Graph representation
    learning in digital pathology: Background ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology")）。'
- en: •
  id: totrans-100
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Graph-level prediction: Refers to GNNs that predict a single value for an entire
    graph. This is mostly used to classify entire graphs, or compute similarities
    between graphs. To compute graph-level predictions, the same node embedding used
    in node-level prediction is input to a pooling process followed by a separate
    MLP (See Fig. [5](#S2.F5 "Figure 5 ‣ II-B6 Other GNN architectures in histopathology
    ‣ II-B Graph neural networks models ‣ II Graph representation learning in digital
    pathology: Background ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology")).'
  id: totrans-101
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '图级预测：指的是GNN对整个图预测一个单一值。这通常用于分类整个图，或计算图之间的相似性。为了计算图级预测，输入到一个池化过程中的节点嵌入与节点级预测中使用的相同，然后是一个独立的MLP（见图 [5](#S2.F5
    "Figure 5 ‣ II-B6 Other GNN architectures in histopathology ‣ II-B Graph neural
    networks models ‣ II Graph representation learning in digital pathology: Background
    ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")）。'
- en: In the following subsections, we describe in more detail the GNN architectures
    considered in digital pathology analysis methods. Different GNN variants employ
    different aggregators to acquire information from each node’s neighbors, as well
    as different techniques to update the nodes’ hidden states. In GNNs, the number
    of parameters is dependent on the number of node and edge features, as their aggregation
    is learned.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 在以下小节中，我们将更详细地描述在数字病理分析方法中考虑的GNN架构。不同的GNN变体采用不同的聚合器从每个节点的邻居处获取信息，以及不同的技术来更新节点的隐藏状态。在GNN中，参数的数量取决于节点和边特征的数量，因为它们的聚合是通过学习得到的。
- en: II-B1 ChebNet
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B1 ChebNet
- en: The convolution operation for spectral-based GCNs is defined in the Fourier
    domain by determining the eigen decomposition of the graph Laplacian [[69](#bib.bib69)].
    The normalized graph Laplacian is defined as $L=I_{N}-D^{-1/2}AD^{-1/2}=U\Lambda
    U^{T}$ ($D$ is the degree matrix and $A$ is the adjacency matrix of the graph),
    where the columns of $U$ are the matrix of eigenvectors and $\Lambda$ is a diagonal
    matrix of its eigenvalues. The operation can be defined as the multiplication
    of a signal $x\in\mathbb{R}^{N}$ (a scalar for each node) with a filter $g_{\theta}=\text{diag}(\theta)$,
    parameterized by $\theta\in\mathbb{R}^{N}$,
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 谱基GCNs的卷积操作在傅里叶域中通过确定图拉普拉斯算子的特征分解来定义[[69](#bib.bib69)]。标准化图拉普拉斯算子定义为$L=I_{N}-D^{-1/2}AD^{-1/2}=U\Lambda
    U^{T}$（$D$是度矩阵，$A$是图的邻接矩阵），其中$U$的列是特征向量矩阵，$\Lambda$是特征值的对角矩阵。该操作可以定义为将信号$x\in\mathbb{R}^{N}$（每个节点的标量）与参数为$\theta\in\mathbb{R}^{N}$的滤波器$g_{\theta}=\text{diag}(\theta)$进行相乘，
- en: '|  | $g_{\theta}\star x=Ug_{\theta}(\Lambda)U^{T}x.$ |  | (3) |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '|  | $g_{\theta}\star x=Ug_{\theta}(\Lambda)U^{T}x.$ |  | (3) |'
- en: Defferrard et al. [[66](#bib.bib66)] proposed a Chebyshev spectral CNN (ChebNet),
    which approximates the spectral filters by truncated Chebyshev polynomials, avoiding
    the calculation of the eigenvectors of the Laplacian matrix, and thus reducing
    the computational cost. A Chebyshev polynomial $T_{m}(x)$ of order $m$ evaluated
    at $\tilde{L}$ is used. Thus the operation is defined as,
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: Defferrard等人[[66](#bib.bib66)]提出了一种Chebyshev谱CNN（ChebNet），它通过截断的Chebyshev多项式来近似谱滤波器，避免了计算拉普拉斯矩阵的特征向量，从而减少了计算成本。使用了在$\tilde{L}$上评估的Chebyshev多项式$T_{m}(x)$。因此，操作定义为，
- en: '|  | $g_{\theta}\star x\approx\sum_{m=0}^{M-1}\theta_{m}T_{m}(\tilde{L})x,$
    |  | (4) |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  | $g_{\theta}\star x\approx\sum_{m=0}^{M-1}\theta_{m}T_{m}(\tilde{L})x,$
    |  | (4) |'
- en: where $\tilde{L}$ is a diagonal matrix of scaled eigenvalues defined as $\tilde{L}=\nicefrac{{2L}}{{\lambda_{\text{max}}}}-I_{N}$.
    $\lambda_{\text{max}}$ denotes the largest eigenvalue of $L$. The Chebyshev polynomials
    are defined as $T_{m}(x)=2xT_{k-1}(x)-T_{k-2}(x)$ with $T_{0}(x)=1$ and $T_{1}(x)=x$.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\tilde{L}$ 是一个对角矩阵，缩放特征值定义为 $\tilde{L}=\nicefrac{{2L}}{{\lambda_{\text{max}}}}-I_{N}$。$\lambda_{\text{max}}$
    表示 $L$ 的最大特征值。切比雪夫多项式定义为 $T_{m}(x)=2xT_{k-1}(x)-T_{k-2}(x)$，其中 $T_{0}(x)=1$ 和
    $T_{1}(x)=x$。
- en: '![Refer to caption](img/c0b9d1892bf1e3d3a25f37d703d7e565.png)'
  id: totrans-109
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/c0b9d1892bf1e3d3a25f37d703d7e565.png)'
- en: 'Figure 4: Representation of graph architectures for node-level classification.
    Recreated from [[11](#bib.bib11)].'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：节点级分类的图架构表示。重建自 [[11](#bib.bib11)]。
- en: II-B2 GCN
  id: totrans-111
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B2 GCN
- en: 'A GCN is a spectral-based GNN with mean pooling aggregation. Kipf and Welling [[67](#bib.bib67)]
    presented the GCN using a localized first-order approximation of ChebNet. It limits
    the layer-wise convolution filter to $K=1$ and uses a further approximation of
    $\lambda\approx 2$, to avoid overfitting and limit the number of parameters. Thus,
    Equation [4](#S2.E4 "In II-B1 ChebNet ‣ II-B Graph neural networks models ‣ II
    Graph representation learning in digital pathology: Background ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology") can be simplified to,'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: GCN 是一种基于谱的 GNN，具有均值池化聚合。Kipf 和 Welling [[67](#bib.bib67)] 使用切比雪夫网络的局部一阶近似提出了
    GCN。它将层级卷积滤波器限制为 $K=1$，并使用 $\lambda\approx 2$ 的进一步近似，以避免过拟合并限制参数数量。因此，方程 [4](#S2.E4
    "在 II-B1 ChebNet ‣ II-B 图神经网络模型 ‣ II 图表示学习在数字病理学中的背景 ‣ 图形深度学习在计算病理学中的调查") 可以简化为，
- en: '|  | $g_{\theta}\star x\approx\theta_{0}^{{}^{\prime}}x+\theta_{1}^{{}^{\prime}}x(L-I_{N})x=\theta_{0}^{{}^{\prime}}x+\theta_{1}^{{}^{\prime}}D^{-1/2}AD^{-1/2}x.$
    |  | (5) |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '|  | $g_{\theta}\star x\approx\theta_{0}^{{}^{\prime}}x+\theta_{1}^{{}^{\prime}}x(L-I_{N})x=\theta_{0}^{{}^{\prime}}x+\theta_{1}^{{}^{\prime}}D^{-1/2}AD^{-1/2}x.$
    |  | (5) |'
- en: 'Here, $\theta_{0}^{{}^{\prime}},\theta_{1}^{{}^{\prime}}$ are two unconstrained
    variables. A GCN further assumes that $\theta=\theta_{0}^{{}^{\prime}}=-\theta_{1}^{{}^{\prime}}$,
    leading to the following definition of a graph convolution:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 这里，$\theta_{0}^{{}^{\prime}},\theta_{1}^{{}^{\prime}}$ 是两个不受约束的变量。GCN 进一步假设
    $\theta=\theta_{0}^{{}^{\prime}}=-\theta_{1}^{{}^{\prime}}$，从而得到以下图卷积的定义：
- en: '|  | $g_{\theta}\star x\approx\theta(I_{N}+D^{-1/2}AD^{-1/2})x$ |  | (6) |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '|  | $g_{\theta}\star x\approx\theta(I_{N}+D^{-1/2}AD^{-1/2})x$ |  | (6) |'
- en: The definition to a signal $X\in\mathbb{R}^{N\times C}$ with $C$ input channels
    and $F$ filters for feature maps is generalized as follows,
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 对信号 $X\in\mathbb{R}^{N\times C}$ 的定义，其中 $C$ 是输入通道，$F$ 是特征图滤波器，可以概括为以下形式，
- en: '|  | $Z=\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}X\Theta,$ |  | (7) |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '|  | $Z=\tilde{D}^{-1/2}\tilde{A}\tilde{D}^{-1/2}X\Theta,$ |  | (7) |'
- en: 'where $\Theta\in\mathbb{R}^{C\times F}$ is the matrix formed by the filter
    bank parameters, and $Z\in\mathbb{R}^{N\times F}$ is the signal matrix obtained
    by convolution. From a spatial-based perspective, Equation [7](#S2.E7 "In II-B2
    GCN ‣ II-B Graph neural networks models ‣ II Graph representation learning in
    digital pathology: Background ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology") is reformulated in [[70](#bib.bib70)] as a message passing layer
    which updates the node’s representation $x_{i}^{k}$ as follows:'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\Theta\in\mathbb{R}^{C\times F}$ 是由滤波器组参数形成的矩阵，$Z\in\mathbb{R}^{N\times
    F}$ 是通过卷积获得的信号矩阵。从基于空间的角度来看，方程 [7](#S2.E7 "在 II-B2 GCN ‣ II-B 图神经网络模型 ‣ II 图表示学习在数字病理学中的背景
    ‣ 图形深度学习在计算病理学中的调查") 被重新表述为 [[70](#bib.bib70)] 中的消息传递层，它按照以下方式更新节点的表示 $x_{i}^{k}$：
- en: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)\cup i}\frac{x_{j}^{k}}{\sqrt{&#124;N(J)&#124;&#124;N(i)&#124;}},\\
    x_{i}^{k+1}=\sigma(W^{k}m_{i}^{k+1}),\end{split}$ |  | (8) |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)\cup i}\frac{x_{j}^{k}}{\sqrt{&#124;N(J)&#124;&#124;N(i)&#124;}},\\
    x_{i}^{k+1}=\sigma(W^{k}m_{i}^{k+1}),\end{split}$ |  | (8) |'
- en: where $m_{i}^{k}$ is the output of a message passing iteration, $|N(J)|$ and
    $|N(i)|$ denote the node degree of node $j$ and $i$ respectively, $W^{k}$ denotes
    a layer-specific trainable weight matrix and $\sigma$ is a non-linearity function.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $m_{i}^{k}$ 是消息传递迭代的输出，$|N(J)|$ 和 $|N(i)|$ 分别表示节点 $j$ 和 $i$ 的节点度，$W^{k}$
    表示特定层的可训练权重矩阵，$\sigma$ 是一个非线性函数。
- en: II-B3 GraphSAGE
  id: totrans-121
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B3 GraphSAGE
- en: 'GraphSAGE is a spatial-GCN which uses a node embedding with max-pooling aggregation.
    Hamilton et al. [[68](#bib.bib68)] offer an extension of GCNs for inductive unsupervised
    representation learning with trainable aggregation functions instead of simple
    convolutions applied to neighborhoods as in a GCN. The authors propose a batch-training
    algorithm for GCNs to save memory at the cost of sacrificing time efficiency.
    In [[68](#bib.bib68)] three aggregating functions are proposed: the element-wise
    mean, an LSTM, and max-pooling. The mean aggregator is an approximation of the
    convolutional operation from the transductive GCN framework [[67](#bib.bib67)].
    An LSTM is adapted to operate on an unordered set by permuting the neighbors of
    the node. In the pooling aggregator, each neighbor’s hidden state is fed through
    a fully-connected layer, and then a max-pooling operation is applied to the set
    of the node’s neighbors. These aggregator functions are denoted as,'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: GraphSAGE 是一种空间-GCN，它使用带有最大池化聚合的节点嵌入。Hamilton 等人 [[68](#bib.bib68)] 提供了一种 GCN
    扩展，用于具有可训练聚合函数的归纳无监督表示学习，而不是应用于邻域的简单卷积。作者提出了一种批量训练算法，用于节省内存，但牺牲了时间效率。在 [[68](#bib.bib68)]
    中提出了三种聚合函数：逐元素均值、LSTM 和最大池化。均值聚合器是来自传导性 GCN 框架 [[67](#bib.bib67)] 的卷积操作的近似。LSTM
    经过调整，以对无序集合进行操作，通过对节点的邻居进行排列。在池化聚合器中，每个邻居的隐藏状态通过一个全连接层，然后对节点邻居的集合应用最大池化操作。这些聚合函数表示为，
- en: '|  | $h_{\mathcal{N}_{v}}^{t}=\text{max}\big{\{}\sigma(W_{\text{pool}}h_{u}^{t-1}+b_{\text{pool}}),\forall
    u\in\mathcal{N}_{v}\big{\}},$ |  | (9) |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '|  | $h_{\mathcal{N}_{v}}^{t}=\text{max}\big{\{}\sigma(W_{\text{pool}}h_{u}^{t-1}+b_{\text{pool}}),\forall
    u\in\mathcal{N}_{v}\big{\}},$ |  | (9) |'
- en: 'where $\mathcal{N}_{v}$ is the neighborhood set of node $v$, $W_{\text{pool}}$
    and $b_{\text{pool}}$ are the parameters to be learned, and $\text{max}\{\cdot\}$
    is the element-wise maximum. Hence, following the message passing formulation
    in Equation [8](#S2.E8 "In II-B2 GCN ‣ II-B Graph neural networks models ‣ II
    Graph representation learning in digital pathology: Background ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology"), the node representation is updated
    according to,'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{N}_{v}$ 是节点 $v$ 的邻域集合，$W_{\text{pool}}$ 和 $b_{\text{pool}}$ 是待学习的参数，$\text{max}\{\cdot\}$
    是逐元素的最大值。因此，按照公式 [8](#S2.E8 "在 II-B2 GCN ‣ II-B 图神经网络模型 ‣ II 数字病理学中的图表示学习：背景 ‣
    关于计算组织病理学的图基深度学习的调查") 中的消息传递公式，节点表示根据以下方式更新，
- en: '|  | $\begin{split}m_{i}^{k+1}=MEAN_{j\in N(i)\cup i}(x_{j}^{k}),\\ x_{i}^{k+1}=\sigma(W^{k}m_{i}^{k+1}),\end{split}$
    |  | (10) |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}m_{i}^{k+1}=MEAN_{j\in N(i)\cup i}(x_{j}^{k}),\\ x_{i}^{k+1}=\sigma(W^{k}m_{i}^{k+1}),\end{split}$
    |  | (10) |'
- en: II-B4 GAT
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B4 GAT
- en: Inspired by the self-attention mechanism [[71](#bib.bib71)], graph attention
    networks (GAT) [[72](#bib.bib72)] incorporate the attention mechanism into the
    propagation steps by modifying the convolution operation. GAT is a spatial-GCN
    model that incorporates masked self-attention layers into graph convolutions and
    uses a neural network architecture to learn neighbor-specific weights. Veličković
    et al. [[72](#bib.bib72)] constructed a graph attention network by stacking a
    single graph attention layer, $a$, which is a single-layer feed-forward neural
    network, parametrized by a weight vector $\vec{a}\in\mathbb{R}^{2F^{i}}$. The
    layer computes the coefficients in the attention mechanisms of the node pair $(i,j)$
    by,
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 受到自注意力机制 [[71](#bib.bib71)] 的启发，图注意力网络 (GAT) [[72](#bib.bib72)] 将注意力机制引入传播步骤中，通过修改卷积操作实现。GAT
    是一种空间-GCN 模型，它将掩蔽自注意力层集成到图卷积中，并使用神经网络架构学习邻居特定的权重。Veličković 等人 [[72](#bib.bib72)]
    通过堆叠一个单一的图注意力层 $a$ 来构建图注意力网络，该层是一个单层前馈神经网络，由权重向量 $\vec{a}\in\mathbb{R}^{2F^{i}}$
    参数化。该层通过以下方式计算节点对 $(i,j)$ 的注意力机制中的系数，
- en: '|  | $\alpha_{i,j}=\frac{\text{exp}(\text{LeakyReLu}(\vec{a}^{T}[W\vec{h}_{i}\mathbin{\&#124;}W\vec{h}_{j}]))}{\sum_{k\in
    N_{i}\mathbb{N}}\text{exp}(\text{LeakyReLu}(\vec{a}^{T}[W\vec{h}_{i}\mathbin{\&#124;}W\vec{h}_{k}]))},$
    |  | (11) |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '|  | $\alpha_{i,j}=\frac{\text{exp}(\text{LeakyReLu}(\vec{a}^{T}[W\vec{h}_{i}\mathbin{\&#124;}W\vec{h}_{j}]))}{\sum_{k\in
    N_{i}\mathbb{N}}\text{exp}(\text{LeakyReLu}(\vec{a}^{T}[W\vec{h}_{i}\mathbin{\&#124;}W\vec{h}_{k}]))},$
    |  | (11) |'
- en: where $\mathbin{\|}$ represents the concatenation operation. The attention layer
    takes as input a set of node features $h=\{\vec{h_{1}},\vec{h_{2}},...,\vec{h_{N}}\},\vec{h_{i}}\in
    R^{F}$, where $N$ is the number of nodes of the input graph and $F$ the number
    of features for each node, and produces a new set of node features $h^{{}^{\prime}}=\{\vec{h_{1}}^{{}^{\prime}},\vec{h_{2}}^{{}^{\prime}},...,\vec{h_{N}}^{{}^{\prime}}\},\vec{h_{i}}^{{}^{\prime}}\in
    R^{F}$ as its output. To generate higher-level features, as an initial step a
    shared linear transformation, parametrized by a weight matrix $W\in R^{F^{\prime}*F}$,
    is applied to every node and subsequently a masked attention mechanism is applied
    to every node, resulting in the following scores,
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$\mathbin{\|}$表示连接操作。注意力层以一组节点特征$h=\{\vec{h_{1}},\vec{h_{2}},...,\vec{h_{N}}\},\vec{h_{i}}\in
    R^{F}$作为输入，其中$N$是输入图的节点数量，$F$是每个节点的特征数量，并生成一组新的节点特征$h^{{}^{\prime}}=\{\vec{h_{1}}^{{}^{\prime}},\vec{h_{2}}^{{}^{\prime}},...,\vec{h_{N}}^{{}^{\prime}}\},\vec{h_{i}}^{{}^{\prime}}\in
    R^{F}$作为输出。为了生成更高层次的特征，作为初步步骤，应用一个由权重矩阵$W\in R^{F^{\prime}*F}$参数化的共享线性变换到每个节点，随后对每个节点应用掩码注意力机制，得到以下分数，
- en: '|  | $e_{ij}=a(W\vec{h_{i}},W\vec{h_{j}}),$ |  | (12) |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '|  | $e_{ij}=a(W\vec{h_{i}},W\vec{h_{j}}),$ |  | (12) |'
- en: that indicates the importance of node $j^{{}^{\prime}}s$ features to node $i$.
    The final output feature of each node can be obtained by applying a non-linearity,
    $\sigma$,
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 这表示节点$j^{{}^{\prime}}$特征对节点$i$的重要性。每个节点的最终输出特征可以通过应用非线性函数$\sigma$获得，
- en: '|  | $h_{i}^{{}^{\prime}}=\sigma(\sum_{j\in N_{i}}\alpha_{ij}Wh_{j}).$ |  |
    (13) |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '|  | $h_{i}^{{}^{\prime}}=\sigma(\sum_{j\in N_{i}}\alpha_{ij}Wh_{j}).$ |  |
    (13) |'
- en: The layer also uses multi-head attention to stabilise the learning process.
    $K$ different attention heads are applied to compute mutually independent features
    in parallel, and then their features are concatenated.
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: 该层还使用多头注意力来稳定学习过程。$K$个不同的注意力头被应用于并行计算互相独立的特征，然后将这些特征连接起来。
- en: The attention coefficients are used to update the node representation according
    to the following message passing formulation,
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力系数用于根据以下消息传递公式更新节点表示，
- en: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)}\alpha_{i,j}^{k}W^{k}x_{j}^{k},\\
    x_{i}^{k+1}=\sigma(\alpha_{i,j}^{k}W^{k}x_{j}^{k}+m_{i}^{k+1}),\end{split}$ |  |
    (14) |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)}\alpha_{i,j}^{k}W^{k}x_{j}^{k},\\
    x_{i}^{k+1}=\sigma(\alpha_{i,j}^{k}W^{k}x_{j}^{k}+m_{i}^{k+1}),\end{split}$ |  |
    (14) |'
- en: II-B5 GIN
  id: totrans-136
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B5 GIN
- en: The graph isomorphism network (GIN) [[73](#bib.bib73)] is a spatial-GCN that
    aggregates neighborhood information by summing the representations of neighboring
    nodes. Isomorphism graph-based models are designed to interpret graphs with different
    nodes and edges. The representation of node $i$ itself is then updated using a
    MLP,
  id: totrans-137
  prefs: []
  type: TYPE_NORMAL
  zh: 图同构网络（GIN）[[73](#bib.bib73)]是一个空间-GCN，通过对邻居节点的表示进行求和来聚合邻域信息。基于同构图的模型旨在解释具有不同节点和边的图。节点$i$自身的表示随后通过MLP进行更新，
- en: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)}x_{j}^{k},\\ x_{i}^{k+1}=F((1+\epsilon)\cdot
    x_{i}^{k}+m_{i}^{k+1}),\end{split}$ |  | (15) |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
  zh: '|  | $\begin{split}m_{i}^{k+1}=\sum_{j\in N(i)}x_{j}^{k},\\ x_{i}^{k+1}=F((1+\epsilon)\cdot
    x_{i}^{k}+m_{i}^{k+1}),\end{split}$ |  | (15) |'
- en: where $F$ is the MLP and $\epsilon$ is either a learnable parameter or fixed.
    GIN’s aggregation and readout functions are injective, and thus are designed to
    achieve maximum discriminative power [[73](#bib.bib73)].
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$F$是MLP，$\epsilon$可以是可学习的参数或固定的。GIN的聚合和读出函数是单射的，因此设计上旨在实现最大辨别能力[[73](#bib.bib73)]。
- en: II-B6 Other GNN architectures in histopathology
  id: totrans-140
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-B6 组织病理学中的其他GNN架构
- en: 'Other GNN architectures considered for entity-graph evaluation in digital pathology
    that were proposed by the surveyed works include:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 其他在数字病理学中用于实体图评估的GNN架构包括：
- en: •
  id: totrans-142
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Edge graph neural network (EGNN) [[38](#bib.bib38), [74](#bib.bib74)]: Edge
    features are included when leveraging the graph structure in the network.'
  id: totrans-143
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '边缘图神经网络（EGNN）[[38](#bib.bib38), [74](#bib.bib74)]: 在利用网络中的图结构时包含边缘特征。'
- en: •
  id: totrans-144
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Robust spatial filtering (RSF) [[30](#bib.bib30), [28](#bib.bib28), [75](#bib.bib75)]:
    These spatial-based models are more flexible when dealing with heterogenous graphs
    as the graph inputs can be easily incorporated into the aggregation function.'
  id: totrans-145
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '鲁棒空间滤波（RSF）[[30](#bib.bib30), [28](#bib.bib28), [75](#bib.bib75)]: 这些基于空间的模型在处理异质图时更加灵活，因为图输入可以很容易地纳入聚合函数中。'
- en: •
  id: totrans-146
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Adaptive GraphSAGE [[27](#bib.bib27), [39](#bib.bib39)]: Graph networks with
    the ability to more effectively learn the embedding feature between nodes, by
    using a learnable pattern to adaptively aggregate multi-level embedding features
    for each node. 3'
  id: totrans-147
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '自适应GraphSAGE[[27](#bib.bib27), [39](#bib.bib39)]: 具有更有效地学习节点间嵌入特征能力的图网络，通过使用可学习的模式自适应地聚合每个节点的多级嵌入特征。'
- en: •
  id: totrans-148
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: Jumping Knowledge Network (JK-Net) Xu et al. [[76](#bib.bib76)] proposed the
    Jumping Knowledge (JK) approach to adaptively leverage, for each node, different
    neighborhood ranges to better represent feature.
  id: totrans-149
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 跳跃知识网络（JK-Net）Xu等人[[76](#bib.bib76)] 提出了跳跃知识（JK）方法，通过为每个节点自适应地利用不同的邻域范围，以更好地表示特征。
- en: •
  id: totrans-150
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Feature-enhanced spatial-GCN (FENet) [[41](#bib.bib41), [73](#bib.bib73)]:
    This model is proposed to analyse non-isomorphic graphs, distinct from isomorphic
    graphs which strictly share the same adjacency neighborhood matrix. The feature-enhance
    mechanism adaptively selects the node representation from different graph convolution
    layers. The model adopts sum-pooling to capture the full structural information
    of the entire graph representation.'
  id: totrans-151
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '特征增强空间GCN（FENet）[[41](#bib.bib41), [73](#bib.bib73)]: 该模型旨在分析非同构图，这与严格共享相同邻接矩阵的同构图不同。特征增强机制自适应地从不同的图卷积层中选择节点表示。该模型采用求和池化来捕捉整个图表示的全部结构信息。'
- en: •
  id: totrans-152
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'Multi-scale graph wavelet neural network (MS-GWNN)  [[29](#bib.bib29), [77](#bib.bib77)]:
    This spectral model leverages the localization property of graph wavelets to perform
    multi-scale analysis with a variety of scaling parameters in parallel, offering
    high efficiency and good interpretability for graph convolution.'
  id: totrans-153
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: '多尺度图小波神经网络（MS-GWNN）[[29](#bib.bib29), [77](#bib.bib77)]: 该谱模型利用图小波的定位特性进行多尺度分析，具有多种缩放参数并行处理，提供高效性和良好的图卷积解释性。'
- en: '![Refer to caption](img/479a8941119ef889c741e396cfc70a26.png)'
  id: totrans-154
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/479a8941119ef889c741e396cfc70a26.png)'
- en: 'Figure 5: Representation of graph models for graph-level classification. Recreated
    from [[11](#bib.bib11)].'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: 图5：图模型用于图级分类的表示。重新创建自[[11](#bib.bib11)]。
- en: II-C Graph pooling
  id: totrans-156
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C 图池化
- en: Different graph pooling strategies have been developed to minimise the graph
    size in order to learn hierarchical features for improved graph-level classification,
    and reduce computational complexity.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 不同的图池化策略已被开发出来，以最小化图的大小，从而学习分层特征以改善图级分类，并减少计算复杂性。
- en: Global pooling
  id: totrans-158
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 全局池化
- en: The most fundamental type of signal pooling on a graph is global pooling. It
    is also referred to as a readout layer in the literature. Similar to CNNs, mean,
    max, and sum functions are often utilized as basic pooling methods. Other approaches,
    instead of employing these simple aggregators, transform the vertex representation
    to a permutation invariant graph-level representation or embedding. In particular,
    Li et al. [[78](#bib.bib78)] proposed a global attention pooling system that uses
    a soft attention mechanism to determine which nodes are relevant to the present
    graph-level task and returns the pooled feature vector from all nodes.
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 图上最基本的信号池化类型是全局池化。文献中也称为读出层。类似于卷积神经网络（CNN），均值、最大值和求和函数通常作为基本池化方法。其他方法则不使用这些简单的聚合器，而是将顶点表示转换为排列不变的图级表示或嵌入。特别是，Li等人[[78](#bib.bib78)]
    提出了一个全局注意力池化系统，使用软注意力机制来确定哪些节点与当前图级任务相关，并从所有节点返回池化特征向量。
- en: Hierarchical pooling
  id: totrans-160
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 分层池化
- en: 'A graph pooling layer in the GCN pools information from multiple vertices to
    one vertex, to reduce graph size and expand the receptive field of the graph filters.
    Many graph classification methods use hierarchical pooling in conjunction with
    a final global pooling or readout layer to represent the graph as illustrated
    in Fig. [5](#S2.F5 "Figure 5 ‣ II-B6 Other GNN architectures in histopathology
    ‣ II-B Graph neural networks models ‣ II Graph representation learning in digital
    pathology: Background ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology") Below we outline the most common hierarchical pooling techniques
    used in digital pathology.'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: '图卷积网络（GCN）中的图池化层将多个顶点的信息汇聚到一个顶点，以减少图的大小并扩展图滤波器的感受野。许多图分类方法使用分层池化方法，并结合最终的全局池化或读出层来表示图，如图[5](#S2.F5
    "Figure 5 ‣ II-B6 Other GNN architectures in histopathology ‣ II-B Graph neural
    networks models ‣ II Graph representation learning in digital pathology: Background
    ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")所示。下面我们概述了在数字病理学中常用的分层池化技术。'
- en: •
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: 'DiffPool: Ying et al. [[79](#bib.bib79)] introduced the differentiable graph
    pooling operator (DiffPool) which uses another graph convolution layer to generate
    the assignment matrix for each node (i.e. DiffPool does not simply cluster the
    nodes in a graph, but learns a cluster assignment matrix).'
  id: totrans-163
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: DiffPool：Ying等人[[79](#bib.bib79)]提出了可微图池化操作符（DiffPool），它使用另一种图卷积层生成每个节点的分配矩阵（即DiffPool不仅仅对图中的节点进行聚类，而是学习一个集群分配矩阵）。
- en: •
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: •
- en: SAGPool The self-attention graph pooling (SAGPool) introduced by Lee et al. [[80](#bib.bib80)]
    is a hierarchical pooling method that performs local pooling operations over node
    embeddings in a graph. The pooling module considers both node features and graph
    topology and learns to pool features via a self-attention mechanism, which can
    reduce computational complexity.
  id: totrans-165
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: SAGPool 由Lee等人[[80](#bib.bib80)]提出的自注意图池化（SAGPool）是一种分层池化方法，对图中的节点嵌入进行局部池化操作。池化模块考虑了节点特征和图拓扑，通过自注意力机制学习池化特征，从而降低计算复杂度。
- en: II-D Graph interpretations
  id: totrans-166
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-D 图解释
- en: Graph representations embed biological entities and their interactions, but
    their explainability for digital pathology is less explored. While cells and their
    spatial interactions are visible in great detail, identifying relevant visual
    features is difficult. To undertake due diligence on model outputs and improve
    understanding of disease mechanisms and therapies, the medical community requires
    interpretable models.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 图表示嵌入了生物实体及其相互作用，但其在数字病理学中的解释性较少探索。虽然细胞及其空间相互作用可以非常详细地看到，但识别相关的视觉特征却很困难。为了对模型输出进行尽职调查，并改善对疾病机制和疗法的理解，医学界需要可解释的模型。
- en: The two most popular types of interpretation methodologies are model-based and
    post-hoc interpretability. The former constrains the model so that it can quickly
    deliver meaningful details about the relationships that have been discovered (such
    as sparsity, modularity, etc). Here, internal model information such as weights
    or structural information can be accessed and used to infer group-level patterns
    across training instances. The latter seeks to extract information about the learnt
    relationships in the model. These post-hoc methods are typically used to analyze
    individual feature input and output pairs, limiting their explainability to the
    individual sample level.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 两种最流行的解释方法是基于模型的和事后解释。前者约束模型，使其能够快速提供关于已发现关系的有意义细节（如稀疏性、模块化等）。在这里，可以访问和使用内部模型信息（如权重或结构信息）来推断训练实例之间的群体级模式。后者则旨在提取关于模型中学习到的关系的信息。这些事后方法通常用于分析单个特征输入和输出对，将解释性限制在单个样本级别。
- en: '![Refer to caption](img/37e905a301a6e24a1316420a0c254d7d.png)'
  id: totrans-169
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/37e905a301a6e24a1316420a0c254d7d.png)'
- en: 'Figure 6: Cell-graph based representation. Nucleus detection is conducted using
    fully convolutional networks. Then, edge and vertex features are computed to obtain
    an entity-graph representation as input to a GCN for cancer classification. Recreated
    from [[28](#bib.bib28)].'
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：基于细胞图的表示。使用全卷积网络进行细胞核检测。然后计算边和顶点特征，以获得输入到GCN的实体图表示，用于癌症分类。重新创建自[[28](#bib.bib28)]。
- en: II-D1 Attention mechanisms
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-D1 注意力机制
- en: Graph-structured data can be both massive and noisy, and not all portions of
    the graph are equally important. As such, attention mechanisms can direct a network
    to focus on the most relevant parts of the input, suppressing uninformative features,
    reducing computational cost and enhancing accuracy. A gate-based attention mechanism [[81](#bib.bib81)]
    controls, for example, the expressiveness of each feature. Attention has also
    been used as an explanation technique where the attention weights highlight the
    nodes and edges in their relative order of importance, and can be used for discovering
    the underlying dependencies that have been learnt. The activation map and gradient
    sensitivity of GAT models are used to interpret the salient input features at
    both the group and individual levels.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 图结构数据既可能庞大又嘈杂，图的各部分重要性也不尽相同。因此，注意力机制可以引导网络集中在输入的最相关部分，抑制无信息特征，减少计算成本并提高准确性。例如，基于门控的注意力机制[[81](#bib.bib81)]控制每个特征的表达能力。注意力也被用作解释技术，其中注意力权重突出显示节点和边的相对重要性，并可以用来发现已经学习到的潜在依赖关系。GAT模型的激活图和梯度敏感度用于解释群体和个体层面的显著输入特征。
- en: In a graph model with attention, selected layers of the graph are connected
    to an attention layer, and all attention layers are jointly trained with the network.
    A traditional attention mechanism that can be learned by gradient-based methods [[82](#bib.bib82)]
    can be formulated as,
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个包含注意力机制的图模型中，选定的图层与一个注意力层相连接，所有注意力层与网络一起进行联合训练。可以用梯度基方法学习的传统注意力机制[[82](#bib.bib82)]可以表述为：
- en: '|  | <math   alttext="\begin{split}u_{t}=\tanh(Wh_{t}+b),\\ \alpha_{t}=\dfrac{\exp(u_{t}^{T}u_{w})}{\sum_{j=1}^{n}\exp(u_{t}^{T}u_{w})},\\'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '|  | <math   alttext="\begin{split}u_{t}=\tanh(Wh_{t}+b),\\ \alpha_{t}=\dfrac{\exp(u_{t}^{T}u_{w})}{\sum_{j=1}^{n}\exp(u_{t}^{T}u_{w})},\\'
- en: s_{t}=\sum_{t}\alpha_{t}h_{t},\end{split}" display="block"><semantics ><mtable
    displaystyle="true" rowspacing="0pt" ><mtr ><mtd columnalign="right" ><mrow ><mrow
    ><msub ><mi >u</mi><mi >t</mi></msub><mo >=</mo><mrow ><mi >tanh</mi><mo >⁡</mo><mrow
    ><mo stretchy="false" >(</mo><mrow ><mrow ><mi >W</mi><mo lspace="0em" rspace="0em"
    >​</mo><msub ><mi >h</mi><mi >t</mi></msub></mrow><mo >+</mo><mi  >b</mi></mrow><mo
    stretchy="false" >)</mo></mrow></mrow></mrow><mo >,</mo></mrow></mtd></mtr><mtr
    ><mtd columnalign="right" ><mrow ><mrow ><msub ><mi >α</mi><mi >t</mi></msub><mo
    >=</mo><mfrac ><mrow  ><mi >exp</mi><mo >⁡</mo><mrow ><mo stretchy="false"  >(</mo><mrow
    ><msubsup ><mi >u</mi><mi >t</mi><mi >T</mi></msubsup><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >u</mi><mi >w</mi></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow><mrow
    ><msubsup ><mo >∑</mo><mrow ><mi >j</mi><mo >=</mo><mn >1</mn></mrow><mi >n</mi></msubsup><mrow
    ><mi >exp</mi><mo >⁡</mo><mrow ><mo stretchy="false"  >(</mo><mrow ><msubsup ><mi
    >u</mi><mi >t</mi><mi >T</mi></msubsup><mo lspace="0em" rspace="0em"  >​</mo><msub
    ><mi >u</mi><mi >w</mi></msub></mrow><mo stretchy="false"  >)</mo></mrow></mrow></mrow></mfrac></mrow><mo
    >,</mo></mrow></mtd></mtr><mtr ><mtd columnalign="right" ><mrow ><mrow ><msub
    ><mi >s</mi><mi >t</mi></msub><mo rspace="0.111em" >=</mo><mrow ><munder ><mo
    movablelimits="false" >∑</mo><mi >t</mi></munder><mrow ><msub ><mi  >α</mi><mi
    >t</mi></msub><mo lspace="0em" rspace="0em" >​</mo><msub ><mi  >h</mi><mi >t</mi></msub></mrow></mrow></mrow><mo
    >,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" ><apply
    ><csymbol cd="ambiguous" >formulae-sequence</csymbol><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑢</ci><ci >𝑡</ci></apply><apply ><apply
    ><apply ><ci >𝑊</ci><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci >ℎ</ci><ci
    >𝑡</ci></apply></apply><ci >𝑏</ci></apply></apply></apply><apply ><csymbol cd="ambiguous"
    >formulae-sequence</csymbol><apply ><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝛼</ci><ci >𝑡</ci></apply><apply ><apply ><apply ><apply ><csymbol cd="ambiguous"
    >superscript</csymbol><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑢</ci><ci >𝑡</ci></apply><ci >𝑇</ci></apply><apply ><csymbol cd="ambiguous" >subscript</csymbol><ci
    >𝑢</ci><ci >𝑤</ci></apply></apply></apply><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><apply ><ci >𝑗</ci><cn type="integer"  >1</cn></apply></apply><ci
    >𝑛</ci></apply><apply ><apply ><apply ><csymbol cd="ambiguous"  >superscript</csymbol><apply
    ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑢</ci><ci >𝑡</ci></apply><ci
    >𝑇</ci></apply><apply ><csymbol cd="ambiguous"  >subscript</csymbol><ci >𝑢</ci><ci
    >𝑤</ci></apply></apply></apply></apply></apply></apply><apply ><apply ><csymbol
    cd="ambiguous" >subscript</csymbol><ci >𝑠</ci><ci >𝑡</ci></apply><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝑡</ci></apply><apply ><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >𝛼</ci><ci >𝑡</ci></apply><apply
    ><csymbol cd="ambiguous" >subscript</csymbol><ci >ℎ</ci><ci >𝑡</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation
    encoding="application/x-tex" >\begin{split}u_{t}=\tanh(Wh_{t}+b),\\ \alpha_{t}=\dfrac{\exp(u_{t}^{T}u_{w})}{\sum_{j=1}^{n}\exp(u_{t}^{T}u_{w})},\\
    s_{t}=\sum_{t}\alpha_{t}h_{t},\end{split}</annotation></semantics></math> |  |
    (16) |
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: where $h_{t}$ is the output of a layer; and $W$, $u_{w}$ and $b$ are trainable
    weights and bias. The importance of each element in $h_{t}$ is measured by estimating
    the similarity between $u_{t}$ and $h_{t}$, which is randomly initialized. $\alpha_{t}$
    is a softmax function. The scores are multiplied by the hidden states to calculate
    the weighted combination, $s_{t}$ (the attention-weighted final output).
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $h_{t}$ 是一层的输出；$W$、$u_{w}$ 和 $b$ 是可训练的权重和偏差。通过估计 $u_{t}$ 和 $h_{t}$ 之间的相似性来衡量
    $h_{t}$ 中每个元素的重要性，其中 $u_{t}$ 是随机初始化的。$\alpha_{t}$ 是一个 softmax 函数。分数乘以隐藏状态以计算加权组合
    $s_{t}$（注意力加权的最终输出）。
- en: II-D2 Graph explainers
  id: totrans-177
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: II-D2 图解释器
- en: Several post-hoc feature attribution graph explainers have been presented in
    the literature including excitation backpropagation [[83](#bib.bib83)], a node
    pruning-based explainer (GNNExplainer) [[84](#bib.bib84)], gradient-based explainers
    (GraphGrad-CAM [[85](#bib.bib85)] and GraphGrad-CAM++ [[86](#bib.bib86)]), a layerwise
    relevance propagation explainer (GraphLRP) [[87](#bib.bib87), [88](#bib.bib88)],
    and deep graph mapper [[89](#bib.bib89)].
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 文献中提出了几种后置特征归因图解释器，包括激活反向传播 [[83](#bib.bib83)]、基于节点修剪的解释器（GNNExplainer）[[84](#bib.bib84)]、基于梯度的解释器（GraphGrad-CAM
    [[85](#bib.bib85)] 和 GraphGrad-CAM++ [[86](#bib.bib86)]）、逐层相关传播解释器（GraphLRP）[[87](#bib.bib87),
    [88](#bib.bib88)] 和深度图映射器 [[89](#bib.bib89)]。
- en: 'TABLE II: Summary of applications and graphs models in computational pathology.'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 表 II：计算病理学中的应用和图模型总结。
- en: '| Authors | Topic | Application | Entity-graph | GNN Model + Explainer | Input;
    Training (Node detection/embeddings); Training (GNN model/pathology task); Datasets;
    Additional remarks |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| 作者 | 主题 | 应用 | 实体图 | GNN 模型 + 解释器 | 输入；训练（节点检测/嵌入）；训练（GNN 模型/病理任务）；数据集；附加备注
    |'
- en: '| Jaume et al. (2021) [[33](#bib.bib33)] | Classification | Breast cancer |
    CG | GIN + Post-hoc explainers | WSI; Supervised; Supervised; BRACS [[17](#bib.bib17)]
    (5 classes); Post-hoc explainers: GNNExplainer, GraphGrad-CAM, GraphGrad-CAM++,
    GraphLRP. |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| Jaume 等人（2021）[[33](#bib.bib33)] | 分类 | 乳腺癌 | CG | GIN + 后置解释器 | WSI；有监督；有监督；BRACS
    [[17](#bib.bib17)]（5 类）；后置解释器：GNNExplainer、GraphGrad-CAM、GraphGrad-CAM++、GraphLRP。
    |'
- en: '| Jaume et al. (2020) [[34](#bib.bib34)] | Classification | Breast cancer |
    CG | GIN + CGExplainer | WSI; Supervised; Supervised; BRACS [[17](#bib.bib17)]
    (5 classes); Customized cell-graph explainer based on GNNExplainer. |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| Jaume 等人（2020）[[34](#bib.bib34)] | 分类 | 乳腺癌 | CG | GIN + CGExplainer | WSI；有监督；有监督；BRACS
    [[17](#bib.bib17)]（5 类）；基于 GNNExplainer 的定制细胞图解释器。 |'
- en: '| Sureka et al. (2020) [[30](#bib.bib30)] | Classification | Breast cancer
    / Prostate cancer | CG | GCN, RSF + Attention/Node occlusion | WSI, TMAs; Supervised;
    Supervised; Breast cancer: BACH [[9](#bib.bib9)] (2 classes), Prostate cancer:
    TM [[90](#bib.bib90)] (2 classes); Gleason grade. |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| Sureka 等人（2020）[[30](#bib.bib30)] | 分类 | 乳腺癌 / 前列腺癌 | CG | GCN，RSF + 注意力/节点遮挡
    | WSI，TMAs；有监督；有监督；乳腺癌：BACH [[9](#bib.bib9)]（2 类），前列腺癌：TM [[90](#bib.bib90)]（2
    类）；Gleason 级别。 |'
- en: '| Anand et al. (2020) [[28](#bib.bib28)] | Classification | Breast cancer |
    CG | GCN, RSF | WSI; Supervised; Supervised; BACH [[9](#bib.bib9)] (4 classes).  |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| Anand 等人（2020）[[28](#bib.bib28)] | 分类 | 乳腺癌 | CG | GCN，RSF | WSI；有监督；有监督；BACH
    [[9](#bib.bib9)]（4 类）。 |'
- en: '| Studer et al. (2021) [[38](#bib.bib38)] | Classification | Colorectal cancer
    | CG | GCN, GraphSAGE, GAT, GIN, ENN, JK-Net | WSI; Supervised; Supervised; pT1-Gland
    Graph [[91](#bib.bib91)] (2 classes); Graph-level output. Concatenation of global
    add, mean and max pooling). Dysplasia of intestinal glands. |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| Studer 等人（2021）[[38](#bib.bib38)] | 分类 | 结直肠癌 | CG | GCN，GraphSAGE，GAT，GIN，ENN，JK-Net
    | WSI；有监督；有监督；pT1-腺体图 [[91](#bib.bib91)]（2 类）；图级输出。全局加、均值和最大池化的串联）。肠腺体的发育不良。 |'
- en: '| Zhou et al. (2019) [[39](#bib.bib39)] | Classification | Colorectal cancer
    | CG | Adaptive GraphSAGE, JK-Net, Graph clustering | WSI; Supervised; Supervised;
    CRC dataset [[92](#bib.bib92)] (3 classes); Graph-level output. Hierarchical representation
    of cells based on graph clustering method from DiffPool). |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| Zhou 等人（2019）[[39](#bib.bib39)] | 分类 | 结直肠癌 | CG | 自适应 GraphSAGE，JK-Net，图聚类
    | WSI；有监督；有监督；CRC 数据集 [[92](#bib.bib92)]（3 类）；图级输出。基于图聚类方法的细胞层次表示（来自 DiffPool）。
    |'
- en: '| Wang et al. (2020) [[15](#bib.bib15)] | Classification | Prostate cancer
    | CG | GraphSAGE, SAGPool | TMA; Self-supervised; Weakly-supervised; UZH prostate
    TMAs [[93](#bib.bib93)] (2 classes); Graph-level output. Grade classification
    (low and high-risk). |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| Wang 等人（2020）[[15](#bib.bib15)] | 分类 | 前列腺癌 | CG | GraphSAGE，SAGPool | TMA；自监督；弱监督；UZH
    前列腺 TMAs [[93](#bib.bib93)]（2 类）；图级输出。等级分类（低风险和高风险）。 |'
- en: '| Ozen et al. (2020) [[35](#bib.bib35)] | ROI Retrieval | Breast cancer | PG
    | GCN, DiffPool | WSI; Supervised; Self-Supervised; Department of Pathology at
    Hacettepe University (private) (4 classes); Histopathological image retrieval
    (slide-level and ROI-level). |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| Ozen et al. (2020) [[35](#bib.bib35)] | ROI 检索 | 乳腺癌 | PG | GCN, DiffPool
    | WSI; 监督; 自监督; Hacettepe 大学病理科（私人）(4 类); 组织病理图像检索（切片级和 ROI 级）。 |'
- en: '| Lu et al. (2020) [[36](#bib.bib36)] | Classification | Breast cancer (HER2,
    PR) | TG | GIN | WSI; Supervised; Supervised; TCGA-BRCA [[94](#bib.bib94)] (2
    classes); Graph-level. Status of Human epidermal growth factor receptor 2 (HER2)
    and Progesterone receptor (PR). |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| Lu et al. (2020) [[36](#bib.bib36)] | 分类 | 乳腺癌 (HER2, PR) | TG | GIN | WSI;
    监督; 监督; TCGA-BRCA [[94](#bib.bib94)] (2 类); 图级。人类表皮生长因子受体 2 型 (HER2) 和孕激素受体 (PR)
    状态。 |'
- en: '| Aygüneş et al. (2020) [[26](#bib.bib26)] | Classification | Breast cancer
    | PG | GCN | WSI; Supervised; Weakly-supervised; Department of Pathology at Hacettepe
    University (private) (4 classes). ROI-level classification. |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| Aygüneş et al. (2020) [[26](#bib.bib26)] | 分类 | 乳腺癌 | PG | GCN | WSI; 监督;
    弱监督; Hacettepe 大学病理科（私人）(4 类)。ROI 级分类。 |'
- en: '| Ye et al. (2019) [[37](#bib.bib37)] | Classification | Breast cancer | PG
    | GCN | WSI; Supervised; Supervised; BACH [[9](#bib.bib9)] (4 classes); Graph
    construction based on the ROI segmentation map. |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| Ye et al. (2019) [[37](#bib.bib37)] | 分类 | 乳腺癌 | PG | GCN | WSI; 监督; 监督;
    BACH [[9](#bib.bib9)] (4 类); 基于 ROI 分割图的图构建。 |'
- en: '| Zhao et al. (2020) [[40](#bib.bib40)] | Classification | Colorectal cancer
    | PG | ChebNet, SAGPool | WSI; Self-Supervised; Weakly-supervised; TCGA-COAD [[95](#bib.bib95)]
    (2 classes); Multiple instance learning. Graph-level output. |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| Zhao et al. (2020) [[40](#bib.bib40)] | 分类 | 结直肠癌 | PG | ChebNet, SAGPool
    | WSI; 自监督; 弱监督; TCGA-COAD [[95](#bib.bib95)] (2 类); 多实例学习。图级输出。 |'
- en: '| Raju et al. (2020) [[27](#bib.bib27)] | Classification | Colorectal cancer
    | TG | Adaptive GraphSage + Attention | WSI; Self-Supervised; Weakly-supervised;
    MCO [[96](#bib.bib96)] (4 classes); Multiple instance learning. Cluster embedding
    (Siamese architecture); Tumor node metastasis staging. |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| Raju et al. (2020) [[27](#bib.bib27)] | 分类 | 结直肠癌 | TG | 自适应 GraphSage +
    注意力 | WSI; 自监督; 弱监督; MCO [[96](#bib.bib96)] (4 类); 多实例学习。聚类嵌入（Siamese 架构）；肿瘤节点转移分期。
    |'
- en: '| Ding et al. (2020) [[41](#bib.bib41)] | Classification | Colorectal cancer
    | PG | Spatial-GCN (FENet) | WSI; Supervised; Supervised; TCGA-COAD and TCGA-READ [[97](#bib.bib97)]
    (2 classes); Genetic mutational prediction. |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| Ding et al. (2020) [[41](#bib.bib41)] | 分类 | 结直肠癌 | PG | Spatial-GCN (FENet)
    | WSI; 监督; 监督; TCGA-COAD 和 TCGA-READ [[97](#bib.bib97)] (2 类); 遗传突变预测。 |'
- en: '| Adnan et al. (2020) [[43](#bib.bib43)] | Classification | Lung cancer | PG
    | ChebNet, GraphSAGE + Global attention pooling | WSI; Supervised; Supervised;
    TCGA-LUSC [[98](#bib.bib98)] (2 classes), MUSK1 [[99](#bib.bib99)]; Adjacency
    learning layer. Multiple instance learning. |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| Adnan et al. (2020) [[43](#bib.bib43)] | 分类 | 肺癌 | PG | ChebNet, GraphSAGE
    + 全局注意力池化 | WSI; 监督; 监督; TCGA-LUSC [[98](#bib.bib98)] (2 类), MUSK1 [[99](#bib.bib99)];
    邻接学习层。多实例学习。'
- en: '| Zheng et al. (2019) [[44](#bib.bib44)] | Retrieval | Lung cancer | PG | GNN,
    DiffPool (GNN-Hash) | WSI; Supervised; Similarity (Hamming distance); ACDC-LungHP [[98](#bib.bib98)];
    Hashing methods and binary encoding. Histopathological image retrieval. |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| Zheng et al. (2019) [[44](#bib.bib44)] | 检索 | 肺癌 | PG | GNN, DiffPool (GNN-Hash)
    | WSI; 监督; 相似性（汉明距离）；ACDC-LungHP [[98](#bib.bib98)]; 哈希方法和二进制编码。组织病理图像检索。 |'
- en: '| Li et al. (2018) [[45](#bib.bib45)] | Classification | Lung cancer | PG |
    ChebNet + Attention | WSI; Self-Supervised; Supervised; TCGA-LUSC [[98](#bib.bib98)]
    (2 classes), NLST [[100](#bib.bib100)] (2 classes); Survival prediction. |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| Li et al. (2018) [[45](#bib.bib45)] | 分类 | 肺癌 | PG | ChebNet + 注意力 | WSI;
    自监督; 监督; TCGA-LUSC [[98](#bib.bib98)] (2 类), NLST [[100](#bib.bib100)] (2 类);
    生存预测。 |'
- en: '| Wu et al. (2019) [[47](#bib.bib47)] | Classification | Skin cancer | PG |
    GCN | WSI; Supervised; Weakly- and Semi-supervised; BCC data collected from 2
    different hospitals (private) (4 classes). |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
  zh: '| Wu et al. (2019) [[47](#bib.bib47)] | 分类 | 皮肤癌 | PG | GCN | WSI; 监督; 弱监督和半监督;
    从 2 家不同医院收集的 BCC 数据（私人）(4 类)。 |'
- en: '| Anklin et al. (2021) [[42](#bib.bib42)] | Segmentation / Classification |
    Prostate cancer | TG | GIN (SegGini) + GraphGrad-CAM | TMA, WSI; Supervised; Weakly-supervised;
    UZH prostate TMAs [[93](#bib.bib93)] (4 classes), SICAPv2 [[101](#bib.bib101)]
    (4 classes); Gleason grade, Post-hoc interpretability. |'
  id: totrans-199
  prefs: []
  type: TYPE_TB
  zh: '| Anklin et al. (2021) [[42](#bib.bib42)] | 分割 / 分类 | 前列腺癌 | TG | GIN (SegGini)
    + GraphGrad-CAM | TMA, WSI; 监督; 弱监督; UZH 前列腺 TMA [[93](#bib.bib93)] (4 类), SICAPv2 [[101](#bib.bib101)]
    (4 类); Gleason 级别，后验解释性。 |'
- en: '| Pati et al. (2021) [[31](#bib.bib31)] | Classification | Breast cancer |
    CG, TG, HR | GIN-PNA (HACT-Net) + GraphGrad-CAM | WSI; Supervised; Supervised;
    BRACS [[17](#bib.bib17)] (7 classes), BACH [[9](#bib.bib9)] (4 classes); Cell-to-Tissue
    Hierarchies. |'
  id: totrans-200
  prefs: []
  type: TYPE_TB
  zh: '| Pati 等（2021）[[31](#bib.bib31)] | 分类 | 乳腺癌 | CG, TG, HR | GIN-PNA（HACT-Net）+
    GraphGrad-CAM | WSI；监督；监督；BRACS [[17](#bib.bib17)]（7 类），BACH [[9](#bib.bib9)]（4
    类）；细胞到组织的层级结构。 |'
- en: '| Pati et al. (2020) [[17](#bib.bib17)] | Classification | Breast cancer |
    CG, TG, HR | GIN (HACT-Net) | WSI; Supervised; Supervised; BRACS [[17](#bib.bib17)]
    (5 classes); Cell-to-Tissue Hierarchies.  |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
  zh: '| Pati 等（2020）[[17](#bib.bib17)] | 分类 | 乳腺癌 | CG, TG, HR | GIN（HACT-Net） |
    WSI；监督；监督；BRACS [[17](#bib.bib17)]（5 类）；细胞到组织的层级结构。 |'
- en: '| Zhang and Li (2020) [[29](#bib.bib29)] | Classification | Breast cancer |
    PG, HR | MS-GWNN | WSI; Supervised; Supervised; BACH [[9](#bib.bib9)] (4 classes),
    BreakHis [[102](#bib.bib102)] (2 classes); Multi-scale graph feature learning
    (node-level and graph-level prediction). |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '| Zhang 和 Li（2020）[[29](#bib.bib29)] | 分类 | 乳腺癌 | PG, HR | MS-GWNN | WSI；监督；监督；BACH
    [[9](#bib.bib9)]（4 类），BreakHis [[102](#bib.bib102)]（2 类）；多尺度图形特征学习（节点级和图形级预测）。
    |'
- en: '| Levy et al. (2021) [[16](#bib.bib16)] | Regression | Colorectal cancer /
    lymphoma | PG, HR | GAT, TDA + Graph Mapper | WSI; Supervised; Supervised; Dartmouth
    Hitchcock Medical Center (private): colon (9 classes), lymph (4 classes); Hierarchical
    representation. Tumor invasion score and staging. |'
  id: totrans-203
  prefs: []
  type: TYPE_TB
  zh: '| Levy 等（2021）[[16](#bib.bib16)] | 回归 | 结直肠癌/淋巴瘤 | PG, HR | GAT，TDA + 图形映射器
    | WSI；监督；监督；达特茅斯希切科克医学中心（私人）：结肠（9 类），淋巴（4 类）；分层表示。肿瘤侵袭评分和分期。 |'
- en: '| Shi et al. (2020) [[46](#bib.bib46)] | Classification | Cervical cancer |
    CCG | Fusion CNN-GCN | RGB; Supervised; Semi-supervised; SIPaKMed [[103](#bib.bib103)]
    (5 classes), Motic [[25](#bib.bib25)] (7 classes); Population analyis of isolated
    cell images. |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
  zh: '| Shi 等（2020）[[46](#bib.bib46)] | 分类 | 宫颈癌 | CCG | 融合 CNN-GCN | RGB；监督；半监督；SIPaKMed
    [[103](#bib.bib103)]（5 类），Motic [[25](#bib.bib25)]（7 类）；孤立细胞图像的群体分析。 |'
- en: '| Shi et al. (2019) [[25](#bib.bib25)] | Classification | Cervical cancer |
    CCG | Fusion CNN-GCN | RGB; Supervised; Supervised; SIPaKMed [[103](#bib.bib103)]
    (5 classes), Motic [[25](#bib.bib25)] (7 classes); Population analyis of isolated
    cell images. |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
  zh: '| Shi 等（2019）[[25](#bib.bib25)] | 分类 | 宫颈癌 | CCG | 融合 CNN-GCN | RGB；监督；监督；SIPaKMed
    [[103](#bib.bib103)]（5 类），Motic [[25](#bib.bib25)]（7 类）；孤立细胞图像的群体分析。 |'
- en: '| Chen et al. (2020) [[32](#bib.bib32)] | Classification | Renal Cancer | CG
    | GraphSAGE, SAGPool + Attention | Fusion: WSI+Genome; Self-Supervised; Self-Supervised;
    TCGA-GBMLGG, TCGA-KIRC [[98](#bib.bib98)]; Survival outcome, Integrated gradient
    method. |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| Chen 等（2020）[[32](#bib.bib32)] | 分类 | 肾癌 | CG | GraphSAGE, SAGPool + Attention
    | 融合：WSI+基因组；自监督；自监督；TCGA-GBMLGG，TCGA-KIRC [[98](#bib.bib98)]; 生存结果，集成梯度方法。 |'
- en: '| Graph representation: Cell-Graph (CG); Patch-Graph (PG); Tissue-Graph (TG);
    Hierarchical Representation (HR); Cluster-Centroids-Graph (CCG) |'
  id: totrans-207
  prefs: []
  type: TYPE_TB
  zh: '| 图形表示：细胞图（CG）；块状图（PG）；组织图（TG）；分层表示（HR）；簇心图（CCG） |'
- en: III Applications of graph deep learning
  id: totrans-208
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 图形深度学习的应用
- en: in digital pathology
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
  zh: 在数字病理学中
- en: 'The case studies presented in this section are organised according to the methodology
    adopted for the graph representation and the clinical application. The graph model,
    training paradigm, and datasets used in all applications are detailed in Table [II](#S2.T2
    "TABLE II ‣ II-D2 Graph explainers ‣ II-D Graph interpretations ‣ II Graph representation
    learning in digital pathology: Background ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology"). Rather than providing an exhaustive review
    of the literature, we present prominent highlights concerning the pre-processing,
    graph construction and graph models adopted, and their benefits in addressing
    various pathology tasks.'
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: '本节中介绍的案例研究是根据所采用的图形表示方法和临床应用进行组织的。所有应用中使用的图形模型、训练范式和数据集详见表[II](#S2.T2 "TABLE
    II ‣ II-D2 Graph explainers ‣ II-D Graph interpretations ‣ II Graph representation
    learning in digital pathology: Background ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology")。我们不是提供文献的详尽回顾，而是展示关于预处理、图形构建和所采用的图形模型的主要亮点，以及它们在处理各种病理任务中的好处。'
- en: With the development of TMAs and WSI scanning techniques, as well as access
    to massive digital datasets of tissue images, deep learning methods for tumor
    localization, survival prediction and cancer recurrence prediction have made substantial
    progress [[104](#bib.bib104)]. Both the spatial arrangement of cells of various
    types (macro features), and the details of specific cells (micro features) are
    important for detecting and characterizing cancers. Thus, a valuable representation
    of histopathology data must capture micro features and macro spatial relationships.
    Graphs are powerful representational data structures, and have attracted significant
    attention in analysis of histopathological images [[105](#bib.bib105)] due to
    their ability to represent tissue architectures. The paradigm change from pixel-based
    to entity-based research has the potential to improve deep learning techniques’
    interpretability in digital pathology, which is relevant for diagnostics.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 随着TMA和WSI扫描技术的发展，以及对大量数字化组织图像数据集的访问，肿瘤定位、生存预测和癌症复发预测的深度学习方法取得了显著进展 [[104](#bib.bib104)]。细胞的各种类型的空间排列（宏观特征）和特定细胞的细节（微观特征）对于癌症的检测和表征都是重要的。因此，有价值的组织病理数据表示必须捕捉微观特征和宏观空间关系。图形是强大的表示数据结构，因其能够表示组织结构而在组织病理图像分析中引起了广泛关注 [[105](#bib.bib105)]。从基于像素的研究转向基于实体的研究有可能提高深度学习技术在数字病理学中的可解释性，这对诊断具有重要意义。
- en: III-A Cell-graph representation
  id: totrans-212
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 细胞图表示
- en: Most of these works follow a similar framework where a cell-graphs is introduced
    using cells as the entities to capture the cell micro-environment. The image is
    converted into a graph representation with the locations of identified cells serving
    as graph vertices and edges constructed depending on spatial distance. Cell-level
    features are extracted as the initial node embedding. The cell-graph is fed to
    a GCN to perform image-wise classification.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 这些工作大多遵循一个类似的框架，其中通过将细胞作为实体引入细胞图以捕捉细胞微环境。图像被转换为图形表示，识别出的细胞的位置作为图形顶点，边缘则根据空间距离构建。细胞级特征被提取为初始节点嵌入。细胞图被输入到图卷积网络（GCN）中以执行图像级分类。
- en: III-A1 Breast cancer
  id: totrans-214
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 乳腺癌
- en: Breast cancer is the most commonly diagnosed cancer and registers the highest
    number of cancer deaths among women. A majority of breast lesions are diagnosed
    along a spectrum of cancer classes that ranges from benign to invasive. Cancer
    diagnosis and the detection of breast cancer is one of the most common applications
    of machine learning and computer vision within digital pathology analysis. CNNs
    have been used for various digital pathology tasks in breast cancer diagnosis
    such as nucleus segmentation and classification, and tumor detection and staging.
    However, these patch-wise approaches do not explicitly capture the inter-nuclear
    relationships and limit access to global information.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 乳腺癌是最常被诊断的癌症，并且在女性中登记了最多的癌症死亡病例。大多数乳腺病变在从良性到侵袭性的一系列癌症类别中被诊断。癌症诊断和乳腺癌的检测是数字病理学分析中机器学习和计算机视觉最常见的应用之一。卷积神经网络（CNN）已被用于乳腺癌诊断中的各种数字病理学任务，例如细胞核分割和分类，以及肿瘤检测和分期。然而，这些基于补丁的方法并未明确捕捉细胞核间的关系，且限制了对全球信息的访问。
- en: 'Anand et al. [[28](#bib.bib28)] proposed the use of GCNs to classify WSIs represented
    by graphs of their constituent cells. Micro-level features (nuclear morphology)
    were incorporated as vertex features using local image descriptors, while macro-level
    features (gland formation) were included as edge attributes based on a mapping
    of Euclidean distances between nearby nuclei. The vertex features are represented
    by the average RGB intensity, morphological features and learned features extracted
    from a pre-trained CNN applied to a window around the nuclei centroid. Finally,
    each tissue image is classified by giving its cell-graph as an input to the GCN
    which is trained in a supervised manner. The authors adopted a spatial GCN known
    as robust spatial filtering (RSF) [[75](#bib.bib75)], which can take heterogeneous
    graphs as input. This framework is depicted in Fig. [6](#S2.F6 "Figure 6 ‣ II-D
    Graph interpretations ‣ II Graph representation learning in digital pathology:
    Background ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology").
    The authors demonstrate competitive performance compared to conventional patch-based
    CNN approaches to classify patients into cancerous or non-cancerous groups using
    the Breast Cancer Histology Challenge (BACH) dataset [[9](#bib.bib9)].'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: Anand 等人[[28](#bib.bib28)] 提出了使用 GCN 来对由其组成细胞的图表示的 WSIs 进行分类。通过局部图像描述符将微观级别特征（核形态）作为顶点特征纳入，同时基于相邻核之间的欧氏距离映射将宏观级别特征（腺体形成）作为边属性纳入。顶点特征由平均
    RGB 强度、形态特征和从应用于核质心周围窗口的预训练 CNN 中提取的学习特征表示。最终，通过将细胞图作为输入传递给以监督方式训练的 GCN 来对每个组织图像进行分类。作者采用了一种被称为鲁棒空间滤波（RSF）[[75](#bib.bib75)]
    的空间 GCN，这种 GCN 可以接受异质图作为输入。该框架如图[6](#S2.F6 "图 6 ‣ II-D 图形解释 ‣ II 图形表示学习在数字病理学中的背景
    ‣ 图基深度学习在计算组织病理学中的调查")所示。作者展示了与传统的基于补丁的 CNN 方法相比，使用乳腺癌组织挑战赛（BACH）数据集[[9](#bib.bib9)]对患者进行癌性或非癌性分组的竞争性表现。
- en: Sureka et al. [[30](#bib.bib30)] modeled histology tissue as a graph of nuclei
    and employed the RSF with a GCN [[75](#bib.bib75)] with attention mechanisms and
    node occlusion to highlight the relative cell contributions in the image, which
    fits the mental model used by pathologists. In the first approach, the authors
    occluded nuclei clusters to assess the drop in the probability of the correct
    class, while also including a method based on [[106](#bib.bib106)] to learn enhanced
    vertex and edge features. In a second approach, an attention layer is introduced
    before the first pooling operation for visualization of important nuclei for the
    binary classification of breast cancer on the BACH dataset and Gleason grade classification
    on a prostate cancer [[90](#bib.bib90)] dataset.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
  zh: Sureka 等人[[30](#bib.bib30)] 将组织学组织建模为一个核的图，并采用带有注意机制和节点遮挡的 RSF 与 GCN[[75](#bib.bib75)]
    来突出图像中相对的细胞贡献，这符合病理学家使用的心理模型。在第一种方法中，作者遮挡了核簇，以评估正确类别概率的下降，同时还包括基于[[106](#bib.bib106)]
    的方法来学习增强的顶点和边特征。在第二种方法中，引入了一个注意层，在第一次池化操作之前，用于可视化乳腺癌 BACH 数据集的二分类和前列腺癌[[90](#bib.bib90)]
    数据集的 Gleason 级别分类中重要的核。
- en: '![Refer to caption](img/3cf7a6556be1b7256f1aef899960866e.png)'
  id: totrans-218
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3cf7a6556be1b7256f1aef899960866e.png)'
- en: 'Figure 7: For a ductal carcinoma, examples of explanations given by graph-based
    (Left) and pixel-based (Right) explainability algorithms. Recreated from [[33](#bib.bib33)].'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：对于导管癌，图示了基于图形（左）和基于像素（右）的可解释性算法给出的解释示例。重绘自[[33](#bib.bib33)]。
- en: Several explainers have been applied in digital pathology, inspired by explainability
    techniques for CNN model predictions on images. However, pixel-level explanations
    fail to encode tumor macro-environment information, and result in ill-defined
    visual heatmaps of important locations as illustrated in Fig. [7](#S3.F7 "Figure
    7 ‣ III-A1 Breast cancer ‣ III-A Cell-graph representation ‣ III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology"). Thus, graph representations are relevant for
    both diagnostics and interpretation. Generating intuitive explanations for pathologists
    is critical to quantify the quality of the explanation. To address this, Jaume
    et al. [[33](#bib.bib33)] introduced a framework using entity-based graph analysis
    to provide pathologically-understandable concepts (i.e. to make the graph decisions
    understandable to pathologists). The authors proposed a set of quantitative metrics
    based on pathologically measurable cellular properties to characterize explainability
    techniques in cell-graph representations for breast cancer sub-typing.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 受到 CNN 模型在图像上预测的可解释性技术的启发，多个解释器已被应用于数字病理学。然而，像素级解释未能编码肿瘤宏观环境信息，导致重要位置的视觉热图定义不明确，如图
    [7](#S3.F7 "Figure 7 ‣ III-A1 Breast cancer ‣ III-A Cell-graph representation
    ‣ III Applications of graph deep learning in digital pathology ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology") 所示。因此，图表示对诊断和解释都很相关。为病理学家生成直观的解释对于量化解释的质量至关重要。为此，Jaume
    等人 [[33](#bib.bib33)] 引入了一种基于实体的图分析框架，以提供病理上可理解的概念（即使图决策对病理学家可理解）。作者提出了一套基于病理可测量细胞属性的定量指标，以表征乳腺癌亚型细胞图表示中的解释技术。
- en: 'In [[33](#bib.bib33)], the authors first transform the histology image into
    a cell-graph, and a GIN model is used to map the corresponding class level. Then,
    a post-hoc graph explainer generates an explanation per entity graph. Finally,
    the proposed metrics are used to assess explanation quality in identifying the
    nuclei driving the prediction (nuclei importance maps). Four graph explainers
    were considered in this analysis: GNNExplainer [[84](#bib.bib84)], GraphGrad-CAM [[85](#bib.bib85)],
    GraphGrad-CAM++ [[86](#bib.bib86)], and GraphLRP [[87](#bib.bib87)]. The results
    on the Breast Carcinoma Subtyping (BRACS) dataset [[17](#bib.bib17)] confirm that
    GraphGrad-CAM++ produces the best overall agreement with pathologists. The proposed
    metrics, which include domain-specific user-understandable terminology, could
    be useful for quantitative evaluation of graph explainability.'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[33](#bib.bib33)] 中，作者首先将组织学图像转换为细胞图，然后使用 GIN 模型映射到相应的类别级别。接着，事后图解释器为每个实体图生成解释。最后，使用提出的指标评估在识别推动预测的细胞核（细胞核重要性图）中解释质量。此分析考虑了四种图解释器：GNNExplainer
    [[84](#bib.bib84)]，GraphGrad-CAM [[85](#bib.bib85)]，GraphGrad-CAM++ [[86](#bib.bib86)]，以及
    GraphLRP [[87](#bib.bib87)]。在乳腺癌亚型（BRACS）数据集 [[17](#bib.bib17)] 上的结果确认 GraphGrad-CAM++
    与病理学家的整体一致性最好。提出的指标，包括领域特定的用户可理解术语，可用于图解释性的定量评估。
- en: Jaume et al. [[34](#bib.bib34)] focused on the analysis of cells and cellular
    interactions in breast cancer sub-typing classification, and introduced an instance-level
    post-hoc graph-pruning explainer to identify decisive cells and interactions from
    the input graph in the BRACS dataset [[17](#bib.bib17)]. To create the cell-graph,
    nuclei are detected with segmentation algorithms and hand-crafted features including
    shape, texture and color attributes are extracted to represent each nucleus. The
    cell-graph topology uses the KNN algorithm and is based on the assumption that
    that spatially close cells encode biological relationships and, as a result, should
    create an edge. The cell-graph is processed by a GIN model, followed by a MLP
    to predict the cancer stages.
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: Jaume 等人 [[34](#bib.bib34)] 专注于乳腺癌亚型分类中细胞及细胞相互作用的分析，并引入了一种实例级的事后图剪枝解释器，以从 BRACS
    数据集中识别决定性细胞和相互作用。为了创建细胞图，使用分割算法检测细胞核，并提取包括形状、纹理和颜色属性在内的手工特征来表示每个细胞核。细胞图拓扑使用 KNN
    算法，并基于空间上接近的细胞编码生物学关系的假设，因此应该创建一个边。细胞图通过 GIN 模型处理，之后使用 MLP 预测癌症阶段。
- en: Jaume et al. [[34](#bib.bib34)] designed a cell-graph explainer (CGExplainer),
    based on the GNNExplainer, to remove redundant and uninformative graph components,
    and the resulting sub-graph will be responsible for class-specific patterns that
    will aid disease comprehension. This module aims to learn a mask at the node-level
    that activates or deactivates parts of the graph. Fig. [8](#S3.F8 "Figure 8 ‣
    III-A1 Breast cancer ‣ III-A Cell-graph representation ‣ III Applications of graph
    deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning for
    Computational Histopathology") provides an overview of the explainer module. The
    proposed explainer was shown to prune a substantial percentage of nodes and edges
    to extract valuable information while retaining prediction accuracy (e.g. the
    explanations retain relevant tumor epithelial nuclei for cancer diagnosis).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: Jaume等人[[34](#bib.bib34)]设计了一个细胞图解释器（CGExplainer），基于GNNExplainer，旨在去除冗余和无信息的图组件，结果的子图将负责特定类别模式，从而有助于疾病理解。该模块旨在学习一个在节点级别激活或停用图部分的掩模。图[8](#S3.F8
    "Figure 8 ‣ III-A1 Breast cancer ‣ III-A Cell-graph representation ‣ III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology")提供了解释器模块的概述。提出的解释器被证明修剪了大量节点和边，以提取有价值的信息，同时保留预测准确性（例如，解释保留了相关的肿瘤上皮细胞核用于癌症诊断）。
- en: '![Refer to caption](img/7d6fd9474a3b3b3d5c10b9a65491eefc.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7d6fd9474a3b3b3d5c10b9a65491eefc.png)'
- en: 'Figure 8: Cell-graph explainer (CGExplainer): a customized post-hoc graph explainer
    based on graph pruning optimization. Recreated from [[34](#bib.bib34)].'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 图8：细胞图解释器（CGExplainer）：基于图修剪优化的定制后处理图解释器。重新制作自[[34](#bib.bib34)]。
- en: III-A2 Colorectal cancer
  id: totrans-226
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 结直肠癌
- en: Colorectal cancer (CRC) grading is a critical task since it plays a key role
    in determining the appropriate follow-up treatment, and is also indicative of
    overall patient outcome. The grade of a cancer is determined, for example, by
    assessing the degree of glandular formation in the tumour. Nevertheless, automatic
    CNN-based methods for grading CRC typically use image patches which fail to include
    information on the micro-architecture of the entire tissue sample, and do not
    capture correspondence between the tissue morphology and glandular structure.
    To model nuclear features along with their cellular interactions, Zhou et al. [[39](#bib.bib39)]
    proposed a cell-graph model for grading CRC, in which each node is represented
    by a nucleus within the original image, and cellular interactions are captured
    as graph edges based on node similarity. A nuclear instance segmentation model
    is used to detect the nucleus and to extract accurate node features including
    nucleus shape and appearance features. Spatial features such as centroid coordinates,
    nuclei intensity and dissimilarity extracted from the grey level co-occurrence
    matrix were used as descriptors for predicting the grade of cancer. To reduce
    the number of nodes and edges based on the relative inter-node distance, an additional
    sampling strategy was used.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 结直肠癌（CRC）分级是一项关键任务，因为它在确定适当的后续治疗中发挥了关键作用，并且还指示了患者的整体预后。癌症的分级例如通过评估肿瘤中的腺体形成程度来确定。然而，基于自动CNN的CRC分级方法通常使用的图像块未能包括整个组织样本的微观结构信息，也未能捕捉组织形态学与腺体结构之间的对应关系。为建模核特征及其细胞交互，Zhou等人[[39](#bib.bib39)]提出了一种用于分级CRC的细胞图模型，其中每个节点由原始图像中的一个细胞核表示，细胞交互通过基于节点相似性的图边来捕捉。使用核实例分割模型来检测细胞核并提取准确的节点特征，包括核形状和外观特征。诸如质心坐标、细胞核强度和从灰度共现矩阵中提取的相似度等空间特征被用作预测癌症分级的描述符。为了减少基于相对节点间距的节点和边的数量，使用了额外的采样策略。
- en: To conduct the graph-level classification, the authors in [[39](#bib.bib39)]
    proposed the Adaptive GraphSAGE model, which is inspired by GraphSAGE [[68](#bib.bib68)]
    and JK-Net [[76](#bib.bib76)], to obtain multi-level features (i.e. capturing
    the gland structure at various scales). To achieve multi-scale feature fusion,
    Adaptive GraphSAGE employs an attention technique which allows the network to
    adaptively generate an effective node representation.
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: 为了进行图级分类，[[39](#bib.bib39)]的作者提出了自适应GraphSAGE模型，该模型受GraphSAGE[[68](#bib.bib68)]和JK-Net[[76](#bib.bib76)]的启发，以获取多层级特征（即捕捉不同尺度的腺体结构）。为了实现多尺度特征融合，自适应GraphSAGE采用了一种注意力技术，允许网络自适应生成有效的节点表示。
- en: A graph clustering operation, which can be considered as an extension of DiffPool [[79](#bib.bib79)],
    is used to group cells according to their appearance and tissue type, and to extract
    more abstract features for hierarchical representation. However, since the tissue
    hierarchy is inaccessible via this approach, the representation does not include
    high-level tissue features. Based on the degree of gland differentiation, the
    graph model categorises each image as normal, low-grade, or high-grade. In comparison
    with a traditional CNN, the proposed model achieves better accuracy by incorporating
    both nuclear and graph-level features.
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
  zh: 一种图聚类操作，可以看作是DiffPool [[79](#bib.bib79)] 的扩展，用于根据细胞的外观和组织类型进行分组，并提取更抽象的特征以进行层次表示。然而，由于通过这种方法无法获取组织层级，因此表示中不包括高级组织特征。基于腺体分化的程度，图模型将每张图像分类为正常、低级别或高级别。与传统CNN相比，所提出的模型通过结合核特征和图级特征实现了更好的准确性。
- en: '![Refer to caption](img/dc011856b24b862814334e3b353928e5.png)'
  id: totrans-230
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/dc011856b24b862814334e3b353928e5.png)'
- en: 'Figure 9: The nuclei that have been detected are segmented, and a graph is
    constructed using the centroid of each nuclei. For each node, morphological, texture
    and contrastive predictive coding features are extracted, and GCNs are used as
    the graph representation. Recreated from [[15](#bib.bib15)].'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: 图9：已检测到的细胞核被分割，并使用每个细胞核的质心构建图。对于每个节点，提取了形态学、纹理和对比预测编码特征，并使用GCNs作为图表示。重建自 [[15](#bib.bib15)]。
- en: Dysplasia of intestinal glands is especially important in pT1 colorectal cancer,
    the earliest stage of invasive colorectal cancer. Studer et al. [[91](#bib.bib91)]
    introduced the pT1 Gland graph (pT1-GG) dataset that consists of cell-graphs of
    healthy and dysplastic intestinal glands. In this work, the authors established
    a baseline for gland classification using labelled cell-graphs and the graph edit
    distance (GED), which is an error-tolerant measurement of similarity between two
    graphs. This technique is an improved version of the bipartite graph-matching
    method (BP2) [[107](#bib.bib107)] combined with a KNN algorithm to perform classification.
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 胶质腺体的异常在pT1期结直肠癌中尤为重要，这是侵袭性结直肠癌的最早阶段。Studer等人 [[91](#bib.bib91)] 引入了pT1腺体图（pT1-GG）数据集，该数据集包含了健康和异常腺体的细胞图。在这项工作中，作者使用标记的细胞图和图编辑距离（GED）建立了腺体分类的基准，GED是一种对图之间相似度的容错测量。该技术是将改进版的二分图匹配方法（BP2） [[107](#bib.bib107)]与KNN算法结合起来进行分类。
- en: Later, the same authors investigated different graph-based architectures [[38](#bib.bib38)]
    to classify healthy gland tissue and dysplastic glandular areas on the pT1-GG
    dataset. The GNN architectures evaluated for cell-graph classification are GCN [[67](#bib.bib67)],
    GraphSAGE [[68](#bib.bib68)], GAT [[72](#bib.bib72)], GIN [[73](#bib.bib73)],
    EGNN [[74](#bib.bib74)] and a 1-dimensional GNN [[108](#bib.bib108)]. All models
    are trained using three graph convolution layers where GraphSAGE and GCN are also
    trained with jumping knowledge (JK) [[76](#bib.bib76)] to allow for an adaptive
    neighborhood range by aggregating representations across different layers. A concatenation
    of global sum-pooling, global mean-pooling and global max-pooling is used to get
    the graph-level output, followed by a MLP to classify an input graph. The results
    demonstrated that graph-based deep learning methods outperformed classical graph-based
    and CNN-based methods. It should be emphasised, however, that each node is only
    linked to its two spatially closest neighbors, resulting in very restricted information
    sharing during message passing.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，同样的作者研究了不同的基于图的架构 [[38](#bib.bib38)]，用于在pT1-GG数据集上对健康腺体组织和异常腺体区域进行分类。评估的用于细胞图分类的GNN架构包括
    GCN [[67](#bib.bib67)]、GraphSAGE [[68](#bib.bib68)]、GAT [[72](#bib.bib72)]、GIN [[73](#bib.bib73)]、EGNN [[74](#bib.bib74)]
    和 1维GNN [[108](#bib.bib108)]。所有模型都使用了三个图卷积层进行训练，其中GraphSAGE和GCN还使用了跳跃知识（JK） [[76](#bib.bib76)]，通过在不同层之间聚合表示来实现自适应的邻域范围。使用全局和池化、全局均值池化和全局最大池化的连接来获得图级输出，随后使用MLP对输入图进行分类。结果表明，基于图的深度学习方法优于传统的基于图的方法和基于CNN的方法。然而，需要强调的是，每个节点仅与其两个空间上最接近的邻居连接，导致在消息传递过程中信息共享非常受限。
- en: III-A3 Prostate cancer
  id: totrans-234
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A3 前列腺癌
- en: The commonly used Gleason score, which is based on the architectural pattern
    of tumor tissues and the distribution of glands, determines the aggressiveness
    of prostate cancer. CNNs have been used for histology image classification including
    Gleason score assignment, but CNNs are unable to capture the dense spatial relationships
    between cells and require detailed pixel level annotations for training.
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: 常用的Gleason评分基于肿瘤组织的结构模式和腺体的分布，用于确定前列腺癌的侵袭性。CNN已被用于组织学图像分类，包括Gleason评分分配，但CNN无法捕捉细胞之间的密集空间关系，并且需要详细的像素级注释进行训练。
- en: To analyse the spatial distribution of the glands in prostate TMAs, Wang et
    al. [[15](#bib.bib15)] proposed a weakly-supervised approach for grade classification
    and to stratify low and high-risk cases (Gleason score $<6$ is normal tissue;
    Gleason score $\geq 6$ is abnormal tissue or high-risk). The authors segmented
    the nuclei and construct a cell-graph for each image with nuclei as the nodes,
    and the distance between neighboring nuclei as the edges, as illustrated in Fig. [9](#S3.F9
    "Figure 9 ‣ III-A2 Colorectal cancer ‣ III-A Cell-graph representation ‣ III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology"). Using prostate TMAs with only image-level
    labels rather than pixel-level labels, a GCN is used to identify high-risk patients
    via a self-supervised technique known as contrastive predictive coding (CPC) [[63](#bib.bib63)].
    Features for each node are generated by extracting morphological (area, roundness)
    and texture features (dissimilarity, homogeneity) as well as features from CPC-based
    learning. A GraphSAGE convolution and a self-attention graph pooling (SAGPool) [[80](#bib.bib80)]
    are applied to the graph representation to learn from the global distribution
    of cell nuclei, cell morphology and spatial features. The proposed method can
    calculate attention scores, focus on the more significant node attributes, and
    aggregate information at different levels.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 为了分析前列腺TMAs中腺体的空间分布，Wang等人[[15](#bib.bib15)] 提出了一种弱监督方法用于分级分类，并对低风险和高风险病例进行分层（Gleason评分$<6$为正常组织；Gleason评分$\geq
    6$为异常组织或高风险）。作者对每张图像进行细胞核分割，并构建了一个以细胞核为节点、邻近细胞核之间的距离为边的细胞图，如图[9](#S3.F9 "图 9 ‣
    III-A2 结直肠癌 ‣ III-A 细胞图表示 ‣ III 图深度学习在数字病理中的应用 ‣ 基于图的深度学习在计算病理学中的调研")所示。利用仅有图像级标签而非像素级标签的前列腺TMAs，通过一种称为对比预测编码（CPC）[[63](#bib.bib63)]的自监督技术来识别高风险患者。通过提取形态学（面积、圆度）和纹理特征（差异性、均匀性）以及CPC学习中的特征来生成每个节点的特征。对图表示应用了GraphSAGE卷积和自注意力图池化（SAGPool）[[80](#bib.bib80)]，以从细胞核的全球分布、细胞形态和空间特征中学习。所提出的方法能够计算注意力分数，关注更重要的节点属性，并在不同层次上聚合信息。
- en: III-B Patch-graphs and Tissue-graphs representations
  id: totrans-237
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B Patch-graphs 和 Tissue-graphs 表示
- en: The majority of the following works transform pathological images into patch-graphs,
    where nodes are important patches, and edges encode the intrinsic relationships
    between these patches. These patches are sampled using methods such as color-based,
    cell density or attention mechanisms. Then, CNNs are used to extract features
    from these patches to generate a feature vector for the node embedding of the
    graph representation. Given the constructed graph, a graph deep learning model
    is used to conduct node or graph classification. It is important to make the distinction
    between tissue-graphs, which are biologically-defined and capture relevant morphological
    regions; while patch-graphs connect patches of interest, where each patch can
    contain multiple biological entities, with each other.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数后续工作将病理图像转换为补丁图，其中节点是重要的补丁，边缘编码这些补丁之间的内在关系。这些补丁通过颜色基础、细胞密度或注意机制等方法进行采样。然后，CNN用于从这些补丁中提取特征，以生成图表示的节点嵌入的特征向量。给定构建的图，使用图深度学习模型进行节点或图分类。重要的是区分组织图（生物学上定义的，捕捉相关的形态区域）和补丁图（连接感兴趣的补丁，每个补丁可以包含多个生物实体）。
- en: '![Refer to caption](img/fc23a84725f92c5544fa6b140c418418.png)'
  id: totrans-239
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fc23a84725f92c5544fa6b140c418418.png)'
- en: 'Figure 10: Slide Graph Model which constructs a graph from the nuclei level
    to the entire WSI-level. The main steps are as follows: segmenting and classification
    of nuclei; clustering; constructing the graph and graph classification. Recreated
    from [[36](#bib.bib36)].'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: 图10：幻灯片图模型，该模型从核级别构建图到整个WSI级别。主要步骤如下：核的分割和分类；聚类；构建图和图分类。重建自[[36](#bib.bib36)]。
- en: III-B1 Breast cancer
  id: totrans-241
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 乳腺癌
- en: Multi-class classification of arbitrarily sized ROIs is an important problem
    that serves as a necessary step in the diagnostic process for breast cancer. Aygüneş
    et al. [[26](#bib.bib26)] proposed to incorporate local context through a graph-based
    ROI representation over a variable number of patches (nodes) and their spatial
    proximity relationships (edges). A CNN is used to extract a feature vector for
    each node represented by fixed-sized patches of the ROI. Then, to propagate information
    across patches and incorporate local contextual information, two consecutive GCNs
    are used, which also aggregate the patch representation to classify the whole
    ROI into a diagnostic class. The classification is conducted in a weakly-supervised
    manner over the patches and ROI-level annotations, without having access to patch-level
    labels. Results on a private data collected from the Department of Pathology at
    Hacettepe University outperformed CNN-based models that incorporated majority-voting,
    learned-fusion and base-penultimate methods.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 任意大小ROI的多类别分类是乳腺癌诊断过程中一个重要的问题。Aygüneş等人[[26](#bib.bib26)]提出通过基于图的ROI表示来结合局部上下文，涉及可变数量的补丁（节点）及其空间邻近关系（边）。使用CNN提取每个节点的特征向量，该节点由固定大小的ROI补丁表示。然后，为了在补丁之间传播信息并结合局部上下文信息，使用了两个连续的GCN，它们还聚合补丁表示以将整个ROI分类到诊断类别中。分类是在补丁和ROI级别注释的弱监督方式下进行的，而没有访问补丁级标签。结果表明，在Hacettepe大学病理学系收集的私人数据上表现优于采用多数投票、学习融合和基础-倒数第二方法的CNN模型。
- en: Some traditional CNN-based models have proposed to jointly segment a ROI of
    an image and classify WSIs and that enabled the classifier to better predict the
    image class [[109](#bib.bib109)]. Ye et al. [[37](#bib.bib37)] captured the topological
    structure of a ROI image through a GCN where a graph is constructed with segmentation
    masks of image patches that contain high levels of semantic information. The segmentation
    mask for each image patch is obtained using an encoder-decoder semantic segmentation
    framework where each pixel is classified as one of the four classes of tissue
    samples (normal, benign, in situ, and invasive) of the BACH [[9](#bib.bib9)] dataset.
    The combined segmentation masks of the image patches yield the total ROI segmentation
    mask. The area ratio of each lesion is calculated as the value of the unit node
    in each picture patch. Then, a graph is constructed to capture the spatial dependencies
    using the features of the image patch segmentation masks. Finally, the ROI image
    is classified based on the features learned by the GCNs.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 一些传统的基于CNN的模型建议联合分割图像的ROI（感兴趣区域）和分类WSI，这使分类器能更好地预测图像类别[[109](#bib.bib109)]。Ye等人[[37](#bib.bib37)]通过GCN捕捉ROI图像的拓扑结构，其中使用包含高语义信息的图像补丁的分割掩膜构建图。每个图像补丁的分割掩膜是使用编码器-解码器语义分割框架获得的，其中每个像素被分类为BACH[[9](#bib.bib9)]数据集中四类组织样本（正常、良性、原位和侵袭性）之一。图像补丁的组合分割掩膜产生了总的ROI分割掩膜。每个病变的面积比率计算为每个图像补丁中单位节点的值。然后，构建一个图来捕捉空间依赖关系，使用图像补丁分割掩膜的特征。最后，基于GCN学习的特征对ROI图像进行分类。
- en: One limitation of previous works is that they construct graphs using small patches
    of the WSI. Lu et al. [[36](#bib.bib36)] overcome this challenge by introducing
    a pipeline to construct a graph from the entire WSI using the nuclei level information,
    including geometry and cellular organization in tissue slides (termed the histology
    landscape). After building the graph, the authors used a GIN model to predict
    the positive or negative human epidermal growth factor receptor 2 (HER2), and
    the progesterone receptor (PR), which are two valuable biomarkers for breast cancer
    prognosis.
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: 之前研究的一个局限是它们使用小的WSI（全组织切片）补丁来构建图。Lu等人[[36](#bib.bib36)]通过引入一个管道，从整个WSI中使用核级信息来构建图，克服了这一挑战，包括组织切片中的几何形状和细胞组织（称为组织学景观）。在构建图后，作者使用了GIN模型来预测人表皮生长因子受体2（HER2）和孕激素受体（PR），这两者是乳腺癌预后的重要生物标志物。
- en: The proposed method in [[36](#bib.bib36)] consists of four steps as illustrated
    in Fig. [10](#S3.F10 "Figure 10 ‣ III-B Patch-graphs and Tissue-graphs representations
    ‣ III Applications of graph deep learning in digital pathology ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology"). This work first used Hover-Net [[50](#bib.bib50)]
    to simultaneously segment and classify the individual nuclei and extract their
    features. Then, agglomerative clustering [[56](#bib.bib56)] is used to group spatially
    neighboring nuclei into clusters which results in reduced computational cost for
    downstream analysis. Using these clusters, a graph is generated by assigning the
    tissue clusters to nodes and the edges of the graph encode the cellular topology
    of the WSI. Lastly, the graph generated from the entire WSI is used as an input
    to a GCN to predict HER2 or PR status at the WSI-level. The performance of this
    method is evaluated on the hematoxylin and eosin (H&E) stained WSI images from
    the TCGA-BRCA [[94](#bib.bib94)] dataset, which consist of 608 HER2 negative and
    101 HER2 positive, and 452 PR positive and 256 PR negative samples.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[36](#bib.bib36)]中提出的方法包括四个步骤，如图[10](#S3.F10 "Figure 10 ‣ III-B Patch-graphs
    and Tissue-graphs representations ‣ III Applications of graph deep learning in
    digital pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")所示。该工作首先使用
    Hover-Net[[50](#bib.bib50)] 同时对单个细胞核进行分割和分类，并提取它们的特征。然后，使用聚合聚类[[56](#bib.bib56)]
    将空间上相邻的细胞核分组到簇中，从而减少下游分析的计算成本。利用这些簇，通过将组织簇分配给节点生成图，图的边编码 WSI 的细胞拓扑。最后，将从整个 WSI
    生成的图用作 GCN 的输入，以预测 WSI 级别的 HER2 或 PR 状态。该方法的性能在 TCGA-BRCA[[94](#bib.bib94)] 数据集的苏木精-伊红
    (H&E) 染色 WSI 图像上进行了评估，该数据集包含 608 个 HER2 阴性和 101 个 HER2 阳性样本，以及 452 个 PR 阳性和 256
    个 PR 阴性样本。
- en: Content-based histopathological image retrieval has also been investigated for
    decision support in digital pathology. This system scans a pre-existing WSI database
    for regions that the pathologist is interested in and returns related regions
    to the pathologists for comparison. These methods can provide valuable information
    including diagnosis reports from experts for similar regions. Retrieval methods
    can also be used for classification by considering the most likely diagnosis [[110](#bib.bib110)].
    However the amount of manually labelled training data limits their power. Ozen
    et al. [[35](#bib.bib35)] suggested a generic method that combines GNNs with a
    self-supervised training method that employs a contrastive loss function without
    requiring labeled data. In this framework, fixed-size patches and their spatial
    proximity relations are represented by undirected graphs. The simple framework
    for constrastive learning of visual representation (SimCLR) [[111](#bib.bib111)]
    is adopted for learning representations of ROIs. Using the contrastive loss, the
    GNN encoder and MLP projection head are trained to maximise the agreement between
    the representations. A GCN followed by a DiffPool operation is selected as the
    model configuration.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 基于内容的组织病理图像检索也已被研究用于数字病理学中的决策支持。该系统扫描预先存在的 WSI 数据库，查找病理学家感兴趣的区域，并返回相关区域以供病理学家比较。这些方法可以提供有价值的信息，包括专家对类似区域的诊断报告。检索方法也可以用于分类，考虑最可能的诊断[[110](#bib.bib110)]。然而，人工标注训练数据的数量限制了它们的能力。Ozen
    等人[[35](#bib.bib35)] 提出了一种通用方法，将 GNN 与自监督训练方法相结合，使用对比损失函数而不需要标注数据。在这个框架中，固定大小的补丁及其空间邻近关系通过无向图进行表示。采用视觉表示的对比学习简单框架（SimCLR）[[111](#bib.bib111)]
    来学习 ROI 的表示。通过对比损失，GNN 编码器和 MLP 投影头被训练以最大化表示之间的一致性。选择 GCN 作为模型配置，并由 DiffPool 操作跟随。
- en: For content-based retrieval tasks, this GNN is trained in a self-supervised
    setting and is used to extract ROI representations where the Euclidean distance
    between the extracted representations is used to determine how similar two ROIs
    are. Quantitative results demonstrated that contrastive learning can improve the
    quality of learned representations, and despite not utilizing class labels could
    outperforming supervised classification methods.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于内容的检索任务，这种 GNN 在自监督环境中进行训练，用于提取 ROI 表示，其中提取的表示之间的欧几里得距离用于确定两个 ROI 的相似程度。定量结果表明，对比学习可以提高学习表示的质量，尽管不使用类别标签，却能够优于监督分类方法。
- en: '![Refer to caption](img/e6f64e8840795141381b6bec115e6a38.png)'
  id: totrans-248
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e6f64e8840795141381b6bec115e6a38.png)'
- en: 'Figure 11: Representation of a GCN-based MIL method. Once the bag of patches
    are extracted, instance-level feature extraction and selection is conducted followed
    by a bag-level classification. Recreated from [[40](#bib.bib40)].'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 图 11：GCN 基于 MIL 方法的表示。一旦提取了区域的袋，进行实例级特征提取和选择，然后进行袋级分类。重建自 [[40](#bib.bib40)]。
- en: '![Refer to caption](img/173b38d6200c13f235f46fc9efd2b0fa.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/173b38d6200c13f235f46fc9efd2b0fa.png)'
- en: 'Figure 12: The proposed FENet architecture. For each WSI, patches are randomly
    selected. Each patch corresponds to a node in each non-isomorphic subgraph where
    a CNN is used to extract node attributes. A feature-enhanced mechanism is adopted
    to consider all topological structural information. An ensemble approach used
    majority voting to aggregate all subgraphs’ prediction outcomes. Recreated from [[41](#bib.bib41)].'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：提出的 FENet 架构。对于每个 WSI，随机选择区域。每个区域对应于每个非同构子图中的一个节点，其中使用 CNN 提取节点属性。采用特征增强机制以考虑所有拓扑结构信息。采用集成方法使用多数投票来汇总所有子图的预测结果。重建自
    [[41](#bib.bib41)]。
- en: III-B2 Colorectal cancer
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 结直肠癌
- en: Although CNN-based approaches have practical merits when identifying important
    patches for predicting CRC, they do not take into account the spatial relationships
    between patches, which is important for determining the stage of the tumor. The
    size and the relative location of the tumor in relation to other tissue partitions
    are used for tumor node metastasis staging estimation. Furthermore, traditional
    approaches require the presence of expert pathologists to annotate each WSI. Weakly-supervised
    learning is an important and potentially viable solution to dealing with sparse
    annotations in medical imagery. Multiple instance learning (MIL) is well-suited
    to histology slide classification, as it is designed to operate on weakly-labeled
    data [[4](#bib.bib4)].
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管基于 CNN 的方法在识别预测 CRC 重要区域方面具有实际优势，但它们没有考虑区域之间的空间关系，而这一点对于确定肿瘤的阶段至关重要。肿瘤的大小及其相对于其他组织区域的位置用于肿瘤淋巴结转移分期估计。此外，传统方法需要专家病理学家对每个全切片图像
    (WSI) 进行注释。弱监督学习是一种应对医学影像稀疏注释的重要且潜在可行的解决方案。多实例学习 (MIL) 非常适合组织学切片分类，因为它旨在处理弱标注的数据
    [[4](#bib.bib4)]。
- en: Raju et al. [[27](#bib.bib27)] considered the spatial relationship between tumor
    and other tissue partitions with a graph attention multi-instance learning framework
    to predict colorectal tumor node metastasis staging. Each graph with nodes representing
    different tissues serves as an instance, and the multiple instances for a WSI
    form a bag that aids in tumour stage prediction.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: Raju 等人 [[27](#bib.bib27)] 采用图注意力多实例学习框架考虑了肿瘤与其他组织区域之间的空间关系，以预测结直肠肿瘤淋巴结转移分期。每个节点表示不同组织的图作为一个实例，多个实例组成的
    WSI 包有助于肿瘤阶段预测。
- en: In [[27](#bib.bib27)], given a WSI, a texture autoencoder [[64](#bib.bib64)]
    is used to encode the texture from random sample patches. Then a cluster embedding
    network based on a Siamese architecture [[112](#bib.bib112)] is trained on a binary
    classification task to group similar texture features into multiple graphs. Each
    WSI is divided into multiple graphs and each graph has features from all cluster
    labels. The authors used a tissue wise annotated CRC dataset [[113](#bib.bib113)]
    to assign cluster labels for similar image patches. The authors consider the multiple
    graphs as multiple instances in a bag which are used to predict the tumor staging
    using an attention MIL method [[114](#bib.bib114)]. The authors adopted an Adaptive
    GraphSage [[39](#bib.bib39)] approach with learnable attention weights to assign
    more importance to instances which contain more information towards predicting
    the tumor stage. The authors demonstrated that graph attention multi-instance
    learning can perform better than a GCN on the Molecular and Cellular Oncology
    (MCO) [[96](#bib.bib96)] dataset.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 在 [[27](#bib.bib27)] 中，给定一个 WSI，使用纹理自动编码器 [[64](#bib.bib64)] 对随机样本区域的纹理进行编码。然后，基于
    Siamese 架构的集群嵌入网络 [[112](#bib.bib112)] 在二分类任务上进行训练，以将相似的纹理特征分组到多个图中。每个 WSI 被划分为多个图，每个图具有来自所有集群标签的特征。作者使用组织学标注的
    CRC 数据集 [[113](#bib.bib113)] 来为相似的图像区域分配集群标签。作者将多个图视为一个袋中的多个实例，用于通过注意力 MIL 方法
    [[114](#bib.bib114)] 预测肿瘤分期。作者采用带有可学习注意力权重的自适应 GraphSage [[39](#bib.bib39)] 方法，以便对包含更多预测肿瘤阶段信息的实例赋予更多重要性。作者展示了图注意力多实例学习在分子与细胞肿瘤学
    (MCO) [[96](#bib.bib96)] 数据集上表现优于 GCN。
- en: Colorectal cancer lymph node metastasis (LNM) is a crucial factor in patient
    management and prognosis, and its identification suggests the need for dissection
    to avoid further spread. Zhao et al. [[40](#bib.bib40)] introduced a GCN-based
    multiple instance learning method combined with a feature selection strategy to
    predict LNM in the colon adenocarcinoma (COAD) cohort of the Cancer Genome Atlas
    (TCGA) project [[95](#bib.bib95)]. Following the MIL approach, the training dataset
    is composed of bags where each bag contains a set of instances. The goal of this
    work is to teach a model to predict the bag label, where only the bag-level label
    is available.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 结直肠癌淋巴结转移（LNM）是患者管理和预后中的一个关键因素，其识别表明需要进行手术切除以避免进一步扩散。赵等人[[40](#bib.bib40)]引入了一种基于GCN的多实例学习方法，并结合特征选择策略，以预测癌症基因组图谱（TCGA）项目中的结肠腺癌（COAD）队列中的LNM。遵循MIL方法，训练数据集由多个包含一组实例的袋子组成。本研究的目标是训练模型以预测袋子标签，其中仅提供袋子级别的标签。
- en: 'The overall framework has three major components: instance-level feature extraction,
    instance-level feature selection, and bag-level classification, as illustrated
    in Fig. [11](#S3.F11 "Figure 11 ‣ III-B1 Breast cancer ‣ III-B Patch-graphs and
    Tissue-graphs representations ‣ III Applications of graph deep learning in digital
    pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology").
    First, non-overlapping patches are extracted from a WSI which is represented as
    a bag of patches. Since instance labels are unavailable, the authors introduced
    a combination of a variational autoencoder (VAE) [[65](#bib.bib65)] and a generative
    adversarial network (GAN) for fine-tunning the encoder component as an instance-level
    feature extractor in a self-supervised manner. In this VAE-GAN model, the architecture
    of the network for the decoder of the VAE and generator of the GAN is the same
    network.  Then, a feature selection component is incorporated to remove redundant
    and unhelpful features to alleviate the workload when generating the bag representation.
    The maximum mean discrepancy is used to evaluate the feature importance. Finally,
    the authors employed ChebNet [[66](#bib.bib66)] followed by SAGPool [[80](#bib.bib80)]
    to generate the bag representation and perform the bag-level classification. The
    authors demonstrated that the proposed model outperformed CNN-based and attention-based
    MIL models.'
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 整体框架包括三个主要组件：实例级特征提取、实例级特征选择和袋子级分类，如图[11](#S3.F11 "Figure 11 ‣ III-B1 Breast
    cancer ‣ III-B Patch-graphs and Tissue-graphs representations ‣ III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology")所示。首先，从WSI中提取非重叠的补丁，这些补丁被表示为补丁的袋子。由于实例标签不可用，作者引入了变分自编码器（VAE）[[65](#bib.bib65)]和生成对抗网络（GAN）的组合，以自监督的方式对编码器组件进行微调，作为实例级特征提取器。在这个VAE-GAN模型中，VAE的解码器网络和GAN的生成器网络是相同的网络。接下来，引入了特征选择组件以去除冗余和无用的特征，从而减轻生成袋子表示时的工作负担。使用最大均值差异来评估特征的重要性。最后，作者采用了ChebNet[[66](#bib.bib66)]，接着是SAGPool[[80](#bib.bib80)]来生成袋子表示并执行袋子级分类。作者证明了所提出的模型优于基于CNN和注意力的MIL模型。
- en: Colon adenoma and carcinoma may occur as a result of a series of histopathological
    changes due to key genetic alterations. Thus, the ability to predict genetic mutations
    is important for the diagnosis of colon cancer. Ding et al. [[41](#bib.bib41)]
    proposed a feature-enhanced graph network (FENet) using a spatial-GCNs, based
    on GIN, to predict gene mutations across all three key mutational prediction tasks
    (APC, KRAS, and TP53) that are associated with colon cancer evolution. In this
    approach, multiple spatial graphs are created using randomly selected image patches
    from each patient’s WSI.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 结肠腺瘤和癌症可能由于关键的遗传改变而发生一系列组织病理学变化。因此，预测遗传突变的能力对于结肠癌的诊断非常重要。丁等人[[41](#bib.bib41)]提出了一种特征增强图网络（FENet），使用基于GIN的空间-GCN来预测与结肠癌演变相关的所有三个关键突变预测任务（APC、KRAS和TP53）。在这种方法中，使用从每个患者的WSI中随机选择的图像补丁创建多个空间图。
- en: The feature-enhanced mechanism aggregates features from neighboring patches
    and combines them as the central node representation to increase feature learning
    performance. The authors introduced GlobalAddPooling as a READOUT function to
    convert the node representation into a graph representation. The prediction outcome
    for each sub-graph is classified by fully-connected layers. Finally, an ensemble
    strategy combines the prediction results of all sub-graphs to predict mutated
    and non-mutated classes. Fig. [12](#S3.F12 "Figure 12 ‣ III-B1 Breast cancer ‣
    III-B Patch-graphs and Tissue-graphs representations ‣ III Applications of graph
    deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning for
    Computational Histopathology") illustrates the proposed FENet networks. The authors
    demonstrated that the integration of multiple sub-graph outcomes in the proposed
    model leads to a significant improvement in prediction performance on the Cancer
    Genome Atlas Colon Adenocarcinoma dataset [[97](#bib.bib97)], outperforming graph-based
    baseline models such as ChebNet, GraphSAGE and GAT.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 特征增强机制通过聚合邻近补丁的特征，并将其组合为中心节点表示，以提高特征学习性能。作者引入了 GlobalAddPooling 作为 READOUT 函数，将节点表示转换为图表示。每个子图的预测结果通过全连接层进行分类。最后，集成策略将所有子图的预测结果结合起来，以预测突变和非突变类别。图
    [12](#S3.F12 "Figure 12 ‣ III-B1 Breast cancer ‣ III-B Patch-graphs and Tissue-graphs
    representations ‣ III Applications of graph deep learning in digital pathology
    ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology") 说明了提出的
    FENet 网络。作者展示了在提出的模型中，多个子图结果的整合显著提高了 Cancer Genome Atlas Colon Adenocarcinoma
    数据集的预测性能[[97](#bib.bib97)]，超越了基于图的基线模型，如 ChebNet、GraphSAGE 和 GAT。
- en: '![Refer to caption](img/b8c5483d286fbb10e7b46d09b81b6bf0.png)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b8c5483d286fbb10e7b46d09b81b6bf0.png)'
- en: 'Figure 13: Representation of the retrieval framework. Patch-graphs are constructed
    based on spatial relationships and feature distances between patches, and are
    fed into the developed GNN-Hash model for graph encoding. When retrieving, the
    query region is converted into a patch-graph and a binary code for similarity
    comparison with samples in the database. Recreated from [[44](#bib.bib44)].'
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13：检索框架的表示。基于空间关系和补丁之间的特征距离构建补丁图，并输入到开发的 GNN-Hash 模型中进行图编码。在检索时，查询区域被转换为补丁图和二进制代码，以便与数据库中的样本进行相似性比较。重建自
    [[44](#bib.bib44)]。
- en: III-B3 Lung cancer
  id: totrans-262
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 肺癌
- en: Lung adenocarcinoma and lung squamous cell carcinoma are the most common subtypes
    of lung cancer, and distinguishing between them requires a visual examination
    by an experienced pathologist. Efficient mining of survival-related structural
    features on a WSI is a promising way to improve survival analysis. Li et al. [[45](#bib.bib45)]
    introduced a GCN-based survival prediction model that integrated local patch features
    with global topological structures (patch-graph) through spectral graph convolution
    operators (ChebNet) using the TCGA-LUSC [[98](#bib.bib98)] and NLST [[100](#bib.bib100)]
    datasets. The model utilized a survival-specific graph trained under supervision
    using survival labels. A parallel graph attention mechanism is used to learn attention
    node features to improve model robustness by reducing the randomness of patch
    sampling (i.e. an adaptive patch selection by learning the importance of individual
    patches). This attention network is trained jointly with the prediction network.
    The authors demonstrated that topological features fine-tuned with survival-specific
    labels outperformed CNN-based models.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 肺腺癌和肺鳞状细胞癌是最常见的肺癌亚型，区分它们需要经验丰富的病理学家进行视觉检查。在 WSI 上有效挖掘与生存相关的结构特征是提高生存分析的有前途的方法。Li
    等人 [[45](#bib.bib45)] 介绍了一种基于 GCN 的生存预测模型，该模型通过使用 TCGA-LUSC [[98](#bib.bib98)]
    和 NLST [[100](#bib.bib100)] 数据集的谱图卷积算子 (ChebNet) 将局部补丁特征与全局拓扑结构（补丁图）集成。该模型利用带有生存标签的生存特定图进行监督训练。并行图注意机制用于学习注意节点特征，通过减少补丁采样的随机性（即通过学习单个补丁的重要性进行自适应补丁选择）来提高模型的鲁棒性。这个注意网络与预测网络联合训练。作者展示了用生存特定标签微调的拓扑特征优于基于
    CNN 的模型。
- en: Adnan et al. [[43](#bib.bib43)] explored the application of GNNs for MIL. The
    authors sampled important patches from a WSI and model them as a fully-connected
    graph where the graph is converted to a vector representation for classification.
    Each instance is treated as a node of the graph in order to learn end-to-end relationships
    between nodes. In this approach, a DenseNet is used to extract features from all
    important patches sampled from a segmented tissue using color thresholds [[57](#bib.bib57)].
    Then, an adjacency learning layer which uses global information about the patches
    is adopted to define the connections within nodes in an end-to-end manner. The
    adjacency matrix is calculated by an adjacency learning block using a series of
    dense layers and cross-correlation. The constructed graph is passed through two
    types of graph models (ChebNet and GraphSAGE), followed by a graph pooling layer
    to get a single feature vector to compare the discrimination of sub-types of lung
    cancer on the TCGA [[98](#bib.bib98)] and MUSK1 [[99](#bib.bib99)] datasets. With
    the adopted global attention pooling [[78](#bib.bib78)] which uses a soft attention
    mechanism, it is possible to visualise the importance that the network places
    on each patch when making the prediction. The pooled representation is fed to
    two fully connected dense layers to achieve the final classification between lung
    adenocarcinoma and lung squamous cell carcinoma. The proposed model outperformed
    CNN-based models that use attention-MIL.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
  zh: Adnan等人[[43](#bib.bib43)]探讨了GNN在MIL中的应用。作者从WSI中采样重要的小块，并将其建模为一个完全连接的图，其中图被转换为向量表示进行分类。每个实例被视为图的一个节点，以学习节点之间的端到端关系。在这种方法中，使用DenseNet从通过颜色阈值分割的组织中提取所有重要小块的特征[[57](#bib.bib57)]。然后，采用使用全局信息关于小块的邻接学习层，以端到端的方式定义节点之间的连接。邻接矩阵通过邻接学习块使用一系列密集层和交叉相关计算。构建的图通过两种类型的图模型（ChebNet和GraphSAGE）进行处理，然后通过图池化层获得单一特征向量，以比较TCGA[[98](#bib.bib98)]和MUSK1[[99](#bib.bib99)]数据集中肺癌亚型的鉴别。采用的全局注意力池化[[78](#bib.bib78)]使用软注意力机制，能够可视化网络在做出预测时对每个小块的重要性。池化后的表示被送入两个全连接密集层，以实现肺腺癌和肺鳞状细胞癌的最终分类。所提出的模型优于使用注意力-MIL的CNN模型。
- en: '![Refer to caption](img/c965413bff9851096bdfb58d5441c504.png)'
  id: totrans-265
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c965413bff9851096bdfb58d5441c504.png)'
- en: 'Figure 14: Representation of the proposed SegGini methodology. a) Tissue graph
    construction with tissue superpixels as nodes, and edges computed using a region
    adjacency graph from the spatial connectivity of superpixels. A GNN is used to
    learn discriminative node embeddings to perform semantic segmentation. b) Graph-head:
    graph classification and feature atribution based on GraphGrad-CAM. c) Node-head:
    node classification. Recreated from [[42](#bib.bib42)].'
  id: totrans-266
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：所提出的SegGini方法的表示。a) 组织图构建，使用组织超像素作为节点，并通过从超像素空间连通性计算的区域邻接图计算边。使用GNN学习判别性节点嵌入以执行语义分割。b)
    图头：基于GraphGrad-CAM的图分类和特征归因。c) 节点头：节点分类。重建自[[42](#bib.bib42)]。
- en: As discussed previously, content-based image retrieval seeks to find images
    that have morphological characteristics that are most similar to a query image.
    Binary encoding and hashing techniques have been successfully adopted to speed
    up the retrieval process in order to satisfy efficiency requirements [[115](#bib.bib115)].
    However, WSI are commonly divided into small patches to index WSIs for region-level
    retrieval. This process does not consider the contextual information from a broad
    region surrounding the nuclei and the adjacency relationships that exist for different
    types of biopsy.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，基于内容的图像检索旨在找到与查询图像具有最相似形态特征的图像。二进制编码和哈希技术已成功应用于加快检索过程，以满足效率要求[[115](#bib.bib115)]。然而，WSI通常被分成小块以便于区域级检索。该过程未考虑来自核周围广泛区域的上下文信息以及不同类型活检之间存在的邻接关系。
- en: Zheng et al. [[44](#bib.bib44)] proposed a retrieval framework for a large-scale
    WSI database based on GNNs and hashing, which is illustrated in Fig. [13](#S3.F13
    "Figure 13 ‣ III-B2 Colorectal cancer ‣ III-B Patch-graphs and Tissue-graphs representations
    ‣ III Applications of graph deep learning in digital pathology ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology"). Patch-graphs are first built
    in an offline stage based on patch spatial adjacency, and feature similarity extracted
    with a pre-trained CNN. Then, the patch-graphs are processed by a GNN-Hash model
    designed to use a graph encoding, and stored in the retrieval database. The GNN-Hash
    structure was created by stacking GNN modules and a DiffPool module [[79](#bib.bib79)].
    The output of the hierarchical GNN-Hash is modified with a binary encoding layer
    in the final graph embedding layer. Finally, the relevant regions are retrieved
    and returned to pathologists after the region the pathologist queries is converted
    to a binary code. The similarities between the query code and those in the database
    are measured using Hamming distance. Experiments to estimate the adjacency relationships
    between local regions in WSIs and the similarities with query regions were conducted
    using the lung cancer ACDC-LungHP [[98](#bib.bib98)] dataset. The results demonstrated
    that the proposed retrieval model is scalable to different query region sizes
    and shapes, and returns tissue samples with similar content and structure.
  id: totrans-268
  prefs: []
  type: TYPE_NORMAL
  zh: Zheng等人[[44](#bib.bib44)] 提出了一个基于GNN和哈希的大规模WSI数据库检索框架，如图[13](#S3.F13 "Figure
    13 ‣ III-B2 结直肠癌 ‣ III-B 补丁图和组织图表示 ‣ III 图形深度学习在数字病理学中的应用 ‣ 基于图的深度学习在计算组织病理学中的调查")所示。补丁图首先在离线阶段根据补丁空间邻接关系和通过预训练CNN提取的特征相似性建立。然后，通过GNN-Hash模型处理补丁图，该模型设计为使用图编码，并存储在检索数据库中。GNN-Hash结构是通过堆叠GNN模块和DiffPool模块[[79](#bib.bib79)]创建的。分层GNN-Hash的输出在最终图嵌入层中经过二进制编码层的修改。最后，在路径学家查询的区域转换为二进制代码后，相关区域被检索并返回给病理学家。查询代码与数据库中代码的相似性使用汉明距离进行测量。使用肺癌ACDC-LungHP[[98](#bib.bib98)]数据集进行估计WSI中局部区域之间的邻接关系和与查询区域的相似性的实验。结果表明，所提出的检索模型可以扩展到不同查询区域的大小和形状，并返回具有相似内容和结构的组织样本。
- en: III-B4 Skin cancer
  id: totrans-269
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B4 皮肤癌
- en: One of the most common types of skin cancer is basal cell carcinoma (BCC) which
    can look similar to open sores, red patches and shiny bumps. Several studies have
    demonstrated the ability to identify BCC from pathological images. Wu et al. [[47](#bib.bib47)]
    introduced a model that predicted BCC on WSI using a weakly- and semi-supervised
    formulation by combining prior knowledge from expert observations, and structural
    information between patches into a graph-based model. A sample of this prior knowledge
    is the fact that a dense patch with predictive cancer cells is more likely to
    have a cluster of cancer cells, and more patches with high cancer likelihoods
    increase the overall likelihood of an image being positive.
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 最常见的皮肤癌类型之一是基底细胞癌（BCC），它可能类似于开放性溃疡、红色斑块和光滑的隆起。几项研究已经证明了从病理图像中识别BCC的能力。Wu等人[[47](#bib.bib47)]
    引入了一种模型，通过将来自专家观察的先验知识和补丁之间的结构信息结合到基于图的模型中，以弱监督和半监督形式预测WSI中的BCC。该先验知识的一个示例是，具有预测癌细胞的密集补丁更有可能有一个癌细胞簇，更多具有高癌症可能性的补丁增加了图像为阳性的整体可能性。
- en: The framework consists of two modules, a GCN that propagates supervisory information
    over patches to learn patch-aware interpretabililty in the form of a probability
    score; and an aggregation function that connects patch-level and image-level predictions
    using prior knowledge. The proposed model makes full use of different levels of
    supervision, using a mix of weak supervision from image-level labels and available
    pixel-wise segmentation labels as a semi-supervised signal. By incorporating prior
    knowledge and structure information, both image-level classification and patch-level
    interpretation are significantly improved.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
  zh: 该框架包括两个模块，一个是GCN，用于在补丁之间传播监督信息，以学习以概率分数形式呈现的补丁感知可解释性；另一个是一个聚合函数，利用先验知识连接补丁级别和图像级别的预测。该模型充分利用了不同级别的监督，通过将图像级别标签和可用的像素级分割标签的弱监督混合作为半监督信号。通过结合先验知识和结构信息，图像级分类和补丁级解释都有显著提高。
- en: III-B5 Prostate cancer
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B5 前列腺癌
- en: Pathologists must go above and beyond normal clinical demands and norms when
    precisely annotating image data. As a result, a semantic segmentation method should
    be able to learn from inexact, coarse, and image-level annotations without complex
    task-specific post-processing steps. To this end, Anklin et al. [[42](#bib.bib42)]
    proposed a weakly-supervised semantic segmentation method based on graphs (SegGini)
    that incorporates both local and global inter-tissue-region relations to perform
    contextualized segmentation using inexact and incomplete labels. The model is
    evaluated on the UZH (TMAs) [[93](#bib.bib93)] and SICAPv2 (WSI) [[101](#bib.bib101)]
    prostate cancer datasets for Gleason pattern segmentation and Gleason grade classification.
    Fig. [14](#S3.F14 "Figure 14 ‣ III-B3 Lung cancer ‣ III-B Patch-graphs and Tissue-graphs
    representations ‣ III Applications of graph deep learning in digital pathology
    ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology") depicts
    the proposed SegGini methodology. A tissue-graph representation for an input histology
    image is constructed as proposed in [[17](#bib.bib17)], where the graph nodes
    depict tissue superpixels. As the rectangular patches can span multiple distinct
    structures, superpixels are used [[59](#bib.bib59)]. To characterize the nodes,
    morphological and spatial features are extracted, and the graph topology is computed
    with a region adjacency graph (RAG) [[62](#bib.bib62)], using the spatial connectivity
    of superpixels.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: 病理学家在精确标注图像数据时，必须超越正常的临床要求和标准。因此，语义分割方法应能从不精确、粗略和图像级别的标注中学习，而无需复杂的任务特定后处理步骤。为此，Anklin
    等人 [[42](#bib.bib42)] 提出了基于图的弱监督语义分割方法（SegGini），该方法结合了局部和全局的组织区域关系，以便使用不精确和不完整的标签进行上下文分割。该模型在
    UZH (TMAs) [[93](#bib.bib93)] 和 SICAPv2 (WSI) [[101](#bib.bib101)] 前列腺癌数据集上进行评估，针对
    Gleason 模式分割和 Gleason 级别分类。图 [14](#S3.F14 "Figure 14 ‣ III-B3 Lung cancer ‣ III-B
    Patch-graphs and Tissue-graphs representations ‣ III Applications of graph deep
    learning in digital pathology ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology") 展示了提出的 SegGini 方法。输入组织图像的组织图表示按照 [[17](#bib.bib17)] 的提议进行构建，其中图节点描绘了组织超像素。由于矩形补丁可以跨越多个不同的结构，因此使用了超像素 [[59](#bib.bib59)]。为了描述这些节点，提取了形态学和空间特征，并使用区域邻接图
    (RAG) [[62](#bib.bib62)] 计算图的拓扑结构，利用超像素的空间连接性。
- en: Given a tissue graph, a GIN model learns contextualized features from the tissue
    microenvironment and inter-tissue interactions to perform semantic segmentation,
    where the proposed SegGini model assigns a class label to each node. The resulting
    node features are processed by a graph-head (image label), a node-head (node label),
    or both, based on the type of weak supervision. The graph-head consists of a graph
    classification and a feature attribution technique. The authors employed GraphGrad-CAM
    to measure importance scores towards the classification of each class, where the
    node attribution maps determine the node labels. Further, the authors in [[42](#bib.bib42)]
    found that the node-head simplifies image segmentation into classifying nodes
    where the node labels are extracted by assigning the most prevalent class within
    each node. For inexact image label and incomplete scribbles, both heads are jointly
    trained to improve the individual classification tasks. The outcomes of the heads
    are used to segment Gleason patterns. Finally, to identify image-level Gleason
    grades from the segmentation map, a classification approach [[90](#bib.bib90)]
    is used. SegGini outperforms prior models such as HistoSegNet [[116](#bib.bib116)]
    in terms of per-class and average segmentation, as well as classification metrics.
    This model also provides comparable segmentation performance for both inexact
    and complete supervision; and can be applied to a variety of tissues, organs,
    and histology tasks.
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: 给定一个组织图，GIN模型从组织微环境和组织间相互作用中学习上下文特征以进行语义分割，其中提出的SegGini模型为每个节点分配一个类别标签。根据弱监督的类型，得到的节点特征会由图头（图像标签）、节点头（节点标签）或两者处理。图头包含图分类和特征归属技术。作者使用了GraphGrad-CAM来测量每个类别分类的重要性得分，其中节点归属图确定节点标签。此外，作者在[[42](#bib.bib42)]中发现，节点头将图像分割简化为节点分类，其中节点标签通过在每个节点内分配最常见的类别来提取。对于不准确的图像标签和不完整的涂鸦，两种头部联合训练以改善各自的分类任务。头部的结果用于分割Gleason模式。最后，为了从分割图中识别图像级别的Gleason等级，采用了分类方法[[90](#bib.bib90)]。SegGini在每类和平均分割以及分类指标方面超越了先前的模型，如HistoSegNet[[116](#bib.bib116)]。该模型在不准确和完整监督下提供了可比的分割性能，并且可以应用于各种组织、器官和组织学任务。
- en: III-C Hierarchical graph representation (macro and micro architectures)
  id: totrans-275
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 层次图表示（宏观和微观架构）
- en: In previous approaches, pathological images have been represented by cell-graphs,
    patch-graphs or tissue-graphs. However, cellular or tissue interactions alone
    are insufficient to fully represent pathological structures. A cell-graph incorporates
    only the cellular morphology and topology, and discards tissue distribution information
    that is vital for appropriate representation of histopathological structures.
    A tissue-graph made up of a collection of tissue areas, on the other hand, is
    unable to portray the cell microenvironment. Thus, to learn the intrinsic characteristics
    of cancerous tissue it is necessary to aggregate multilevel structural information,
    which seeks to replicate the tissue diagnostic process followed by a pathologist
    when analyzing images at different magnification levels.
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
  zh: 在以前的方法中，病理图像被表示为细胞图、补丁图或组织图。然而，单独的细胞或组织交互不足以完全表示病理结构。细胞图仅包含细胞形态和拓扑，并丢弃对适当表示组织病理结构至关重要的组织分布信息。由一系列组织区域组成的组织图则无法描绘细胞微环境。因此，为了学习癌症组织的内在特征，有必要汇总多层次的结构信息，这旨在模拟病理学家在不同放大级别分析图像时遵循的组织诊断过程。
- en: III-C1 Breast cancer
  id: totrans-277
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C1 乳腺癌
- en: Early detection of cancer can significantly reduce the mortality rate of breast
    cancer, where it is crucial to capture multi-scale contextual features in cancerous
    tissue. Combinations of CNNs have been used to encode multi-scale information
    in pathology images via multi-scale feature fusion, where scale is often associated
    with spatial location.
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
  zh: 早期发现癌症可以显著降低乳腺癌的死亡率，在癌症组织中捕捉多尺度的上下文特征至关重要。CNNs的组合被用来通过多尺度特征融合对病理图像中的多尺度信息进行编码，其中尺度通常与空间位置相关。
- en: 'Zhang and Li [[29](#bib.bib29)] introduced a multi-scale graph wavelet neural
    network (MS-GWNN) that uses graph wavelets with different scaling parameters in
    parallel to obtain multilevel tissue structural information in a graph topology.
    The graph wavelet neural network (GWNN) [[77](#bib.bib77)] replaces the graph
    convolution in a spectral GCN with the wavelet transform which has an excellent
    localization capability. For breast cancer classification, the authors first transformed
    pathological images into graph structures where nodes are non-overlapping patches.
    Then, node classification is performed via a GWNN at different scales in parallel
    (node-level prediction). After that, multi-level node representations are incorporated
    to perform graph-level classification. The results and the visualization of the
    learned node embeddings demonstrated the strong capacity of the model to encode
    different structural information on two public datasets: BACH [[9](#bib.bib9)]
    and BreakHis [[102](#bib.bib102)]. However, this approach is limited by the manual
    selection of the appropriate scaling parameter.'
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
  zh: Zhang 和 Li[[29](#bib.bib29)]引入了一种多尺度图小波神经网络（MS-GWNN），该网络并行使用不同尺度参数的图小波，以在图拓扑中获得多层次的组织结构信息。图小波神经网络（GWNN）[[77](#bib.bib77)]用具有优秀定位能力的小波变换替代了光谱
    GCN 中的图卷积。对于乳腺癌分类，作者首先将病理图像转换为图结构，其中节点是非重叠的图像块。然后，通过不同尺度的 GWNN 进行节点分类（节点级预测）。之后，将多层次的节点表示结合起来进行图级分类。结果和学习到的节点嵌入的可视化展示了模型在两个公开数据集：BACH[[9](#bib.bib9)]
    和 BreakHis[[102](#bib.bib102)] 上编码不同结构信息的强大能力。然而，该方法受限于手动选择适当的尺度参数。
- en: A hierarchy defined from the cells with learned pooling layers [[39](#bib.bib39)]
    does not include high-level tissue features and approaches that concatenate cell-level
    and tissue-level information [[32](#bib.bib32)] cannot leverage the hierarchy
    between the levels of the tissue representation. To address these issues, Pati
    et al. [[17](#bib.bib17)] proposed a hierarchical-cell-to-tissue (HACT) representation
    that utilizes both nuclei and tissue distribution properties for breast cancer
    subtype classification. The HACT representation consists of a low-level cell-graph
    (CG) that captures the cellular morphology and topology; a tissue-graph (TG) at
    a high-level that captures the properties of the tissue sections as well as their
    spatial distribution; and the hierarchy between the cell-graph and the tissue-graph
    that captures the cells’ relative distribution within the tissue.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 从具有学习池化层的细胞定义的层级结构[[39](#bib.bib39)]不包括高级组织特征，而将细胞级别和组织级别信息连接起来的方法[[32](#bib.bib32)]无法利用组织表示层级之间的关系。为了解决这些问题，Pati
    等人[[17](#bib.bib17)]提出了一种层次细胞到组织（HACT）表示方法，该方法利用细胞核和组织分布特性进行乳腺癌亚型分类。HACT 表示包括一个低层次的细胞图（CG），捕捉细胞的形态和拓扑；一个高层次的组织图（TG），捕捉组织切片的特性及其空间分布；以及细胞图和组织图之间的层级结构，捕捉细胞在组织中的相对分布。
- en: '![Refer to caption](img/71d146625b503cb671e50a410262a6e5.png)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/71d146625b503cb671e50a410262a6e5.png)'
- en: 'Figure 15: Representation of a) CG, b) TG, and c) Hierarchical-cell-to-tissue.
    Image adapted from [[17](#bib.bib17)].'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15：a) CG, b) TG 和 c) 层次细胞到组织的表示。图像改编自[[17](#bib.bib17)]。
- en: Fig. [15](#S3.F15 "Figure 15 ‣ III-C1 Breast cancer ‣ III-C Hierarchical graph
    representation (macro and micro architectures) ‣ III Applications of graph deep
    learning in digital pathology ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology") illustrates samples of the CG, the TG and the hierarchical cell-to-tissue
    representation. To construct a CG, each node represents a cell and edges encode
    cellular interactions, where for each nucleus hand-crafted features such as shape,
    texture and spatial location are extracted. Then, a KNN algorithm is adopted to
    build the initial topology based on the assumption that a close cell should be
    connected and a distant cell should remain disconnected. The Euclidean distances
    between nuclei centroids in the image space are used to quantify cellular distances.
    The TG is constructed by first identifying tissue regions (e.g., epithelium, stroma,
    lumen, necrosis) by detecting non-overlapping homogeneous superpixels of the tissue
    and iteratively merging neighboring superpixels that have similar colour attributes.
    The TG topology is generated assuming that adjacent tissue parts should be connected
    by constructing a region adjacency graph [[62](#bib.bib62)] with the spatial centroids
    of the superpixels. The HACT representation, that jointly represents the low-level
    (CG) and high-level (TG) relationships, is processed with a hierarchical model
    (HACT-Net) that employs two GIN models [[73](#bib.bib73)]. The learned cell-node
    embeddings are combined with the corresponding tissue-node embeddings to predict
    the classes.
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: 图 [15](#S3.F15 "图 15 ‣ III-C1 乳腺癌 ‣ III-C 层次图表示（宏观和微观架构） ‣ III 图深度学习在数字病理学中的应用
    ‣ 基于图的深度学习在计算组织病理学中的综述") 展示了CG、TG和层次细胞到组织表示的样本。为了构建CG，每个节点代表一个细胞，边表示细胞间的相互作用，其中每个细胞核提取了手工制作的特征，如形状、纹理和空间位置。然后，采用KNN算法来建立初始拓扑，假设相邻的细胞应该连接，而距离较远的细胞应该保持断开。使用图像空间中细胞核质心之间的欧氏距离来量化细胞距离。TG的构建首先通过检测组织的非重叠均匀超像素并迭代地合并具有相似颜色属性的邻近超像素来识别组织区域（例如上皮、基质、腔隙、坏死）。TG拓扑的生成假设相邻的组织部分应通过构建一个区域邻接图[[62](#bib.bib62)]来连接，其中包括超像素的空间质心。HACT表示联合表示低级（CG）和高级（TG）关系，采用层次模型（HACT-Net）处理，该模型使用两个GIN模型[[73](#bib.bib73)]。学习到的细胞节点嵌入与相应的组织节点嵌入结合，用于预测类别。
- en: 'To demonstrate the hierarchical-learning, the authors introduce the BRACS dataset
    to classify five breast cancer subtypes: normal, benign, atypical, ductal carcinoma
    in situ, and invasive. The authors also evaluate the generalizability to unseen
    data by splitting the data at the WSI-level (two images from the same slide do
    not belong to different splits) different from previous approaches that split
    at the image-level [[15](#bib.bib15), [39](#bib.bib39)]. The enriched multi-level
    HACT representation for classification outperformed CNN-based models and standalone
    cell-graph and tissue-graph models, confirming that for better structure-function
    mapping, the link between low-level and high-level information must be modelled
    at the local node level rather than at the graph level.'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 为了展示层次学习，作者引入了BRACS数据集来分类五种乳腺癌亚型：正常、良性、非典型、原位导管癌和侵袭性癌。作者还通过在WSI级别拆分数据（来自同一切片的两张图像不属于不同的拆分）来评估对未知数据的泛化能力，这与以往在图像级别拆分的方法不同[[15](#bib.bib15),
    [39](#bib.bib39)]。用于分类的丰富多级HACT表示优于基于CNN的模型和独立的细胞图模型及组织图模型，确认了为了更好的结构-功能映射，低级和高级信息之间的联系必须在局部节点级别建模，而不是在图级别。
- en: Later, Pati et al. [[31](#bib.bib31)] exploited hierarchical modeling for interpretability
    in digital pathology, aiming to map the tissue structure to tissue functionality.
    The authors adopt the hierarchical entity-graph representation of a tissue which
    is processed via a hierarchical GNN to learn the mapping from tissue compositions
    to respective tissue categories. In this work, Pati et al. [[31](#bib.bib31)]
    improved the HACT representation and the HACT-Net model. HACT-Net is modeled using
    principal neighborhood aggregation (PNA) [[117](#bib.bib117)] layers, which use
    a combination of aggregators to replace the sum operation in GIN and adopt degree-scalers
    to amplify or dampen neighboring aggregated messages based on the degree of a
    node. Graph normalization followed by batch normalization is incorporated after
    each PNA layer [[118](#bib.bib118)], which aids the network in learning discriminative
    topological patterns when the number of nodes within a class varies dramatically.
    To further assess the quality of the methodology, a comparison with independent
    pathologists is conducted. Three board-certified pathologists were recruited to
    annotate the BRACS test set without having access to the respective WSIs. The
    results indicate that the model outperforms the domain experts in the 7-class
    classification task. The authors employed the GraphGrad-CAM to highlight the nuclei
    and tissue region nodes to show what the HACT-Net focuses on while classifying
    the tumor regions-of-interest.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 后来，Pati等人[[31](#bib.bib31)]利用层次建模提高数字病理学的可解释性，旨在将组织结构映射到组织功能。作者采用了组织的层次实体图表示，通过层次GNN处理以学习从组织成分到相应组织类别的映射。在这项工作中，Pati等人[[31](#bib.bib31)]改进了HACT表示和HACT-Net模型。HACT-Net使用主邻域聚合（PNA）[[117](#bib.bib117)]层建模，这些层使用多种聚合器组合替代GIN中的和操作，并采用度缩放器根据节点的度来放大或抑制邻域聚合消息。每个PNA层后都加入图归一化和批量归一化[[118](#bib.bib118)]，这帮助网络在类内节点数量差异较大时学习区分性的拓扑模式。为了进一步评估方法的质量，进行了与独立病理学家的比较。招募了三位认证病理学家来标注BRACS测试集，但没有访问相应的WSI。结果表明，该模型在7类分类任务中优于领域专家。作者使用GraphGrad-CAM突出显示了细胞核和组织区域节点，以展示HACT-Net在分类肿瘤感兴趣区域时关注的内容。
- en: '![Refer to caption](img/2459bfc44cd51274036e0971d103ec6f.png)'
  id: totrans-286
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2459bfc44cd51274036e0971d103ec6f.png)'
- en: 'Figure 16: A-C. Patch-level embeddings, graph representation and classification
    via a GCN. A refinement phase is incorporated through estimation of uncertainty.
    D-E. The Graph Mapper summarizes high-order relationships over a WSI as a graph,
    where meaningful histology regions are captured. F-G. Tumor invasion scores are
    used in the prediction model to form an interpretable staging score. Image adapted
    from [[16](#bib.bib16)].'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：A-C。补丁级别嵌入、图表示及通过GCN的分类。通过不确定性估计来纳入一个细化阶段。D-E。图映射器将WSI上的高阶关系总结为图，其中捕捉到有意义的组织学区域。F-G。肿瘤侵袭评分用于预测模型，以形成可解释的分期评分。图像改编自[[16](#bib.bib16)]。
- en: '![Refer to caption](img/f863263eee6c759394a02c8de6bbbb81.png)'
  id: totrans-288
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/f863263eee6c759394a02c8de6bbbb81.png)'
- en: 'Figure 17: Classification framework for cervical cell images. Features are
    extracted with a CNN pre-trained on a cervical cell classification task. K-means
    clustering is performed on these CNN features. A graph of cluster centroid correlations
    is built based on intrinsic similarities, and is the input to a GCN model. The
    encoded representations are incorporated into the CNN features for classification.
    Image reproduced from [[25](#bib.bib25), [46](#bib.bib46)].'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：宫颈细胞图像的分类框架。特征通过在宫颈细胞分类任务上预训练的CNN提取。对这些CNN特征进行K均值聚类。基于内在相似性构建一个簇质心相关性的图，并作为GCN模型的输入。编码的表示被纳入CNN特征中用于分类。图像改编自[[25](#bib.bib25)，[46](#bib.bib46)]。
- en: III-C2 Colorectal cancer
  id: totrans-290
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C2 结直肠癌
- en: Tumor staging includes both tissue and nodal stages, with higher numbers indicating
    a greater depth of invasion and a greater number of lymph nodes implicated in
    the tumor, respectively. Levy et al. [[16](#bib.bib16)] introduced a framework
    that used varied levels of structure to learn both local and global patterns from
    histological images for determining the degree of tumor invasion. Fig. [16](#S3.F16
    "Figure 16 ‣ III-C1 Breast cancer ‣ III-C Hierarchical graph representation (macro
    and micro architectures) ‣ III Applications of graph deep learning in digital
    pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")
    illustrates the proposed framework where the authors combined GCNs to explain
    the mechanisms by which tissue regions interact, and topological feature extraction
    methods [[119](#bib.bib119)] to extract essential contextual information. Patch-level
    classification of colon sub-compartments was conducted via a GCN as well as a
    refinement of patch-level predictions, in which nodes with high uncertainty were
    deleted, and the remaining class labels were propagated to unlabeled patches.
    A topological data analysis (TDA) tool for graphs known as Graph Mapper [[89](#bib.bib89)]
    was adopted as a post-hoc model explanation technique to elucidate the high-level
    topology of the WSI. The mapper generates a graph in which each node represents
    a cluster of WSI patches and each edge represents the degree of shared patches
    between the clusters. This tool can offer higher level information flow descriptors
    in a GNN model, substantially simplifying analysis. With the regions of interest
    (collection of patches) extracted with the mapper, the authors compute tumor invasion
    scores that measure the degree of overlap between the tumor and adjacent tissue
    region. Finally, cancer staging is predicted via derived invasion scores using
    a private colon and lymph node dataset collected from the Dartmouth Hitchcock
    Medical Center, where the results demonstrated the potential of topological methods
    in the analysis of GNN models.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 肿瘤分期包括组织阶段和淋巴结阶段，较高的数字表示更深的侵袭程度和更多的淋巴结受累。Levy 等人[[16](#bib.bib16)] 提出了一个框架，该框架利用不同的结构层次从组织学图像中学习局部和全局模式，以确定肿瘤侵袭的程度。图
    [16](#S3.F16 "Figure 16 ‣ III-C1 Breast cancer ‣ III-C Hierarchical graph representation
    (macro and micro architectures) ‣ III Applications of graph deep learning in digital
    pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")
    说明了提出的框架，其中作者结合了 GCNs 来解释组织区域之间的相互作用机制，以及拓扑特征提取方法[[119](#bib.bib119)] 来提取重要的上下文信息。通过
    GCN 进行了结肠子区域的块级分类，并对块级预测进行了精炼，其中高不确定性的节点被删除，剩余的类别标签被传播到未标记的块。图形数据分析 (TDA) 工具 Graph
    Mapper[[89](#bib.bib89)] 被采用作为后验模型解释技术，以阐明 WSI 的高级拓扑结构。映射器生成一个图，其中每个节点代表 WSI 块的聚类，每条边代表这些聚类之间共享块的程度。该工具可以在
    GNN 模型中提供更高层次的信息流描述，显著简化分析。利用映射器提取的感兴趣区域（块的集合），作者计算了肿瘤侵袭评分，以测量肿瘤与相邻组织区域之间的重叠程度。最后，通过使用从达特茅斯希切克医疗中心收集的私有结肠和淋巴结数据集的侵袭评分来预测癌症分期，结果展示了拓扑方法在
    GNN 模型分析中的潜力。
- en: '![Refer to caption](img/4f902a300b9abed53d89b10e5a6f9439.png)'
  id: totrans-292
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4f902a300b9abed53d89b10e5a6f9439.png)'
- en: 'Figure 18: An integrated framework for multi-modal fusion of histology and
    genomics features for survival outcome prediction. Image-based features using
    CNNs, and graph-based features using GCNs. Recreated from [[32](#bib.bib32)].'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：用于预测生存结果的组织学和基因组特征的多模态融合集成框架。图像基于 CNN 特征，图形基于 GCN 特征。重新创建自[[32](#bib.bib32)]。
- en: III-D Unimodal and multi-modal feature level fusion
  id: totrans-294
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 单模态和多模态特征级融合
- en: 'In this subsection we introduce works that have used fusion techniques to extract
    and combined multiple rich visual representations of the same input data (unimodal
    fusion), or integrate information from various input modalities (multi-modal fusion)
    to enable more accurate and robust decisions. The former involves integrating
    several feature sets acquired from different networks into a single vector, which
    is then used for classification. This fusion occurs in two stages: normalization
    of a feature, and selection of a feature. The latter seeks to correlate and combine
    disparate heterogeneous modalities, such that the model can learn pairwise feature
    interactions and control the expressiveness of each modality. The main challenges
    in multi-modal data fusion are the dissimilarity of the data types being fused,
    and the interpretation of the results.'
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
  zh: 在本小节中，我们介绍了使用融合技术提取和结合相同输入数据的多个丰富视觉表示（单模态融合），或整合来自不同输入模态的信息（多模态融合），以实现更准确和更可靠的决策。前者涉及将从不同网络获取的几个特征集集成到一个向量中，然后用于分类。这种融合发生在两个阶段：特征的归一化和特征的选择。后者旨在关联和结合不同的异质模态，以便模型可以学习成对的特征交互并控制每种模态的表达能力。多模态数据融合的主要挑战是融合的数据类型之间的差异，以及结果的解释。
- en: III-D1 Unimodal fusion (Cervical cancer)
  id: totrans-296
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D1 单模态融合（宫颈癌）
- en: Cervical cancer is one of the most common causes of cancer death in women, and
    screening for abnormal cells from a cervical cytology slide is a common procedure
    for early detection of cervical cancer. In contrast with conventional CNNs which
    learn multi-level features through hierarchical deep architectures, Shi et al. [[25](#bib.bib25)]
    combined a GCN output with deep CNN features to classify images of isolated cervical
    cells into five and seven classes using the SIPakMeD [[103](#bib.bib103)] and
    Motic (liquid-based cytology image) [[46](#bib.bib46)] datasets, respectively.
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
  zh: 宫颈癌是女性癌症死亡的主要原因之一，而从宫颈细胞学切片中筛查异常细胞是早期检测宫颈癌的常见程序。与通过分层深度架构学习多层次特征的传统 CNN 相比，Shi
    等人[[25](#bib.bib25)]将 GCN 输出与深度 CNN 特征结合，使用 SIPakMeD [[103](#bib.bib103)] 和 Motic（液基细胞学图像）[[46](#bib.bib46)]
    数据集将孤立的宫颈细胞图像分类为五类和七类。
- en: First a CNN model pretrained for a cervical cell classification task is used
    to extract features of each individual cervical cell image. Then, K-means clustering
    is computed on the extracted features from all images to construct a graph where
    the centre of each cluster represents a node. The constructed graph of intrinsic
    similarities can be used to further investigate the potential relationships between
    images. Consequently, a stacked two-layer GCN generates a relation-aware representation
    which is encoded into CNN features for classification, as illustrated in Fig. [17](#S3.F17
    "Figure 17 ‣ III-C1 Breast cancer ‣ III-C Hierarchical graph representation (macro
    and micro architectures) ‣ III Applications of graph deep learning in digital
    pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology").
    The authors demonstrated that the relation-aware representation generated by the
    GCN greatly enhances the classification performance. Extensive experiments to
    validate the performance of cervical cytology classification with a GCN were also
    published by the same authors in [[46](#bib.bib46)].
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，使用一个为宫颈细胞分类任务预训练的 CNN 模型来提取每个宫颈细胞图像的特征。然后，对所有图像中提取的特征进行 K-means 聚类，构建一个图，其中每个簇的中心表示一个节点。构建的内在相似性的图可以用于进一步调查图像之间的潜在关系。因此，一个堆叠的两层
    GCN 生成一个关系感知的表示，并将其编码为 CNN 特征以进行分类，如图 Fig. [17](#S3.F17 "Figure 17 ‣ III-C1 Breast
    cancer ‣ III-C Hierarchical graph representation (macro and micro architectures)
    ‣ III Applications of graph deep learning in digital pathology ‣ A Survey on Graph-Based
    Deep Learning for Computational Histopathology") 所示。作者展示了 GCN 生成的关系感知表示大大提升了分类性能。同一作者还发布了大量实验，以验证使用
    GCN 进行宫颈细胞学分类的性能[[46](#bib.bib46)]。
- en: III-D2 Multi-modal fusion (Renal cancer)
  id: totrans-299
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D2 多模态融合（肾癌）
- en: To predict clinical outcomes, oncologists often use both quantitative and qualitative
    information from genomics and histology [[120](#bib.bib120)]. However, current
    automated histology methods do not take genomic details into account. The following
    work exploits the complementary knowledge within morphological information and
    molecular information from genomics to better quantify tumors using graph-based
    methods.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: 为了预测临床结果，肿瘤科医生通常使用来自基因组学和组织学的定量和定性信息 [[120](#bib.bib120)]。然而，当前的自动化组织学方法并未考虑基因组细节。以下工作利用形态学信息和基因组学中的分子信息中的互补知识，通过基于图的方法更好地量化肿瘤。
- en: Renal cell carcinoma is the most common malignant tumor of the kidney, and it
    is a diverse category of tumor with varying histology, clinical outcomes, and
    therapeutic responses. Renal cell carcinoma subtypes can be automatically classified
    through Deep learning frameworks. These algorithms can also identify features
    that predict survival outcomes from digital histopathological images. Several
    authors have used GCNs for cancer histology classification, however, its application
    to survival outcome prediction is less explored. Chen et al. [[32](#bib.bib32)]
    proposed a framework for multi-modal fusion of histology and genomic features
    for renal cancer survival outcome prediction on the TCGA datasets (glioma and
    clear cell renal cell carcinoma) [[98](#bib.bib98)], which contains paired whole
    slide images, genotype, and transcriptome data. Their model fuses the histology
    image (patch features), cell-graph and genomic features into a multi-modal tensor
    that models interactions between the different modalities and outperforms deep
    learning-based feature fusion for survival outcome prediction. This framework
    is illustrated in Fig. [18](#S3.F18 "Figure 18 ‣ III-C2 Colorectal cancer ‣ III-C
    Hierarchical graph representation (macro and micro architectures) ‣ III Applications
    of graph deep learning in digital pathology ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology").
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: 肾细胞癌是最常见的恶性肾脏肿瘤，属于一个多样化的肿瘤类别，具有不同的组织学特征、临床结果和治疗反应。肾细胞癌亚型可以通过深度学习框架自动分类。这些算法还可以从数字化组织病理图像中识别出预测生存结果的特征。一些作者已经使用GCNs进行癌症组织学分类，然而其在生存结果预测中的应用尚不多见。陈等人 [[32](#bib.bib32)]
    提出了一个多模态融合组织学和基因组特征的框架，用于在TCGA数据集（胶质瘤和透明细胞肾细胞癌）上预测肾癌生存结果 [[98](#bib.bib98)]，该数据集包含配对的全切片图像、基因型和转录组数据。他们的模型将组织学图像（补丁特征）、细胞图谱和基因组特征融合成一个多模态张量，建模不同模态之间的相互作用，并且在生存结果预测上优于基于深度学习的特征融合。该框架在图 [18](#S3.F18
    "Figure 18 ‣ III-C2 Colorectal cancer ‣ III-C Hierarchical graph representation
    (macro and micro architectures) ‣ III Applications of graph deep learning in digital
    pathology ‣ A Survey on Graph-Based Deep Learning for Computational Histopathology")中进行了说明。
- en: The authors first extract morphological features from image-based features using
    CNNs, and graph-based features using GCNs, to learn cell-to-cell interactions
    in WSI. Cells are represented as nodes in a graph, with cells segregated using
    a nuclei segmentation method and connections established using KNN. CPC is also
    adopted as a self-supervised method for cell feature extraction. The authors adopted
    the aggregating functions of the GraphSAGE architecture. The hierarchical self-attention
    pooling strategy, SAGPool [[80](#bib.bib80)], is adopted to encode the hierarchical
    structure of cell graphs. Then, to monitor the expressiveness of each modality,
    a gating-based attention system is used to perform uni-modal function fusion.
    Multi-modal interpretability was considered by adopting an integrated gradient
    method for visualizing image saliency feature importance.
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: 作者首先使用CNNs从基于图像的特征中提取形态学特征，并使用GCNs提取基于图谱的特征，以学习WSI中的细胞间相互作用。细胞在图中表示为节点，细胞通过核分割方法进行分离，并使用KNN建立连接。CPC也被采用作为细胞特征提取的自监督方法。作者采用了GraphSAGE架构的聚合函数。层次自注意力池化策略SAGPool [[80](#bib.bib80)]
    被用于编码细胞图谱的层次结构。然后，为了监控每种模态的表现力，使用基于门控的注意力系统进行单模态功能融合。通过采用集成梯度方法来可视化图像显著性特征重要性，以考虑多模态的可解释性。
- en: IV Discussion and open challenges
  id: totrans-303
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 讨论与开放挑战
- en: Beyond generating predictions relating to biology and medicine at molecular,
    genomic and therapeutic levels [[24](#bib.bib24)], graph representation learning
    has also been used to support medical diagnosis through the representation of
    patient records as graphs by using information including brain electrical activity,
    functional connectivity and anatomical structures [[21](#bib.bib21)]. As demonstrated
    throughout this review, graph-based deep learning has been successfully used to
    capture phenotypical and topological distributions in histopathology to better
    enable precision medicine. Numerous entity-graph based tissue representations
    and GNN models have been proposed for computer-aided detection and diagnosis of
    breast, colorectal, prostate, lung, lymphoma, skin, colon, cervical and renal
    cancers.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
  zh: 除了在分子、基因组和治疗水平生成与生物学和医学相关的预测[[24](#bib.bib24)]，图表示学习还被用于通过将患者记录表示为图来支持医学诊断，这些记录包括脑电活动、功能连接和解剖结构[[21](#bib.bib21)]。正如本综述所展示的那样，基于图的深度学习已成功用于捕捉组织病理学中的表型和拓扑分布，从而更好地促进精准医学。已经提出了许多基于实体图的组织表示和GNN模型，用于计算机辅助检测和诊断乳腺癌、结直肠癌、前列腺癌、肺癌、淋巴瘤、皮肤癌、结肠癌、宫颈癌和肾癌。
- en: 'Given the utility of graphs across biomedical domains, especially to model
    the histology of cancer tissue, there has been a major push to exploit recent
    developments in deep learning for graphs in this domain. However, these applications
    are still in their nascent stages compared to existing research concerning conventional
    deep learning methods. There are challenges associated with the adoption of GNNs,
    and there are graph approaches yet to be explored in this domain that potentially
    allow a more robust and comprehensive investigation of complex biological processes
    that merit further investigation. In this section, we discuss several future research
    directions that need to be addressed to unlock the full power of graph deep learning
    in digital pathology: 1) Entity graph construction; 2) Embedding expert knowledge
    and clinical adoption of graph analytics; 3) Complexity of graph models; 4) Training
    paradigms; and 5) Explainability of graph models.'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于图在生物医学领域的实用性，特别是用于建模癌症组织的组织学，近期对图深度学习的最新进展进行了重大推动。然而，与现有的传统深度学习方法相比，这些应用仍处于起步阶段。采用GNN面临挑战，还有许多图方法在该领域尚待探索，这些方法可能允许对复杂生物过程进行更稳健和全面的调查，值得进一步研究。在本节中，我们讨论了几个未来研究方向，这些方向需要解决以释放图深度学习在数字病理学中的全部潜力：1）实体图构建；2）嵌入专家知识和图分析的临床应用；3）图模型的复杂性；4）训练范式；以及5）图模型的可解释性。
- en: IV-A Entity-graph construction
  id: totrans-306
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 实体图构建
- en: Defining an appropriate graph representation where vertices correspond to entities,
    and edges represent the connectivity of these entities, is highly relevant. Given
    a pathology task, different choices of entities in histology images can be selected
    as the relevant biological structures. Several graph representations have been
    customized according to the relevant entity such as nuclei, tissue regions, glands
    or just traditional patches. However, in the majority of methods discussed in
    this survey, graph structures are designed manually.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: 定义适当的图表示，其中顶点对应于实体，边表示这些实体之间的连接，是非常相关的。对于病理任务，可以从组织学图像中选择不同的实体作为相关的生物结构。根据相关实体（如细胞核、组织区域、腺体或传统的图像块），已经定制了几种图表示。然而，在本调查中讨论的大多数方法中，图结构是手动设计的。
- en: IV-A1 Pros and cons of current preprocessing steps for entity-graph construction
  id: totrans-308
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 当前实体图构建预处理步骤的优缺点
- en: Entity definition
  id: totrans-309
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 实体定义
- en: Cell-graphs have been one of the most popular graph representations, where cells
    are the entities used to encode cell microenvironments, including morphology of
    cells and cellular interactions. Such cell-graph representations were proposed
    in [[33](#bib.bib33), [34](#bib.bib34), [30](#bib.bib30), [28](#bib.bib28), [38](#bib.bib38),
    [39](#bib.bib39), [15](#bib.bib15), [32](#bib.bib32)]. However, modeling a WSI
    as a cell-graph is non-trivial due to the large number of cells and the many possibly
    isolated cells and weak nuclear boundaries. This representation relies heavily
    on cell detection or segmentation methods. Although some works have used representative
    node sampling [[39](#bib.bib39)] or agglomerative clustering [[36](#bib.bib36)]
    to remove redundancy in the graph and reduce computation cost, the majority of
    cell-graph based proposals assume that cell-cell interactions are the most salient
    sources of information. Cell-graphs do not exploit tissue macro-architectural
    structures, or the hierarchical nature of the tissue.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: 细胞图（cell-graphs）已成为最流行的图表示之一，其中细胞作为用于编码细胞微环境的实体，包括细胞的形态和细胞间的相互作用。这种细胞图表示在[[33](#bib.bib33),
    [34](#bib.bib34), [30](#bib.bib30), [28](#bib.bib28), [38](#bib.bib38), [39](#bib.bib39),
    [15](#bib.bib15), [32](#bib.bib32)]中被提出。然而，由于细胞数量众多以及许多可能被孤立的细胞和弱核边界，将WSI建模为细胞图并非易事。这种表示法在很大程度上依赖于细胞检测或分割方法。尽管一些工作使用了代表性节点采样[[39](#bib.bib39)]或聚合聚类[[36](#bib.bib36)]来去除图中的冗余并降低计算成本，但大多数基于细胞图的提议假设细胞-细胞相互作用是最显著的信息来源。细胞图没有利用组织宏观结构或组织的层次特征。
- en: Another traditional technique for analysing WSI that include context information
    of ROIs is patch-graphs. Although patch-graph representations have been adopted
    in a number of studies [[35](#bib.bib35), [26](#bib.bib26), [37](#bib.bib37),
    [40](#bib.bib40), [41](#bib.bib41), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45),
    [47](#bib.bib47)], not all entities are biologically-defined and methods are limited
    by the patch definition. The resolution and optimal size of each image patch and
    the level of context offered are trade-off against one another, and are determined
    by the data. For example, variations in glandular morphology and size make determining
    an acceptable image patch size problematic. Operating at lower magnification levels
    may not capture cell-level features, and higher resolutions limits the ability
    to capture the tissue micro-environment. Thus, an automated technique that defines
    these patch regions and an appropriate scaling parameter from the input data is
    vital.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种分析包含感兴趣区域（ROIs）上下文信息的WSI的传统技术是补丁图（patch-graphs）。尽管补丁图表示法已在许多研究中被采用[[35](#bib.bib35),
    [26](#bib.bib26), [37](#bib.bib37), [40](#bib.bib40), [41](#bib.bib41), [43](#bib.bib43),
    [44](#bib.bib44), [45](#bib.bib45), [47](#bib.bib47)]，但并非所有实体都是生物学上定义的，且方法受到补丁定义的限制。每个图像补丁的分辨率和最佳大小以及所提供的上下文水平相互权衡，并由数据决定。例如，腺体形态和大小的变化使得确定可接受的图像补丁大小成为问题。较低的放大倍率可能无法捕捉到细胞级别的特征，而较高的分辨率则限制了捕捉组织微环境的能力。因此，定义这些补丁区域和从输入数据中确定适当缩放参数的自动化技术至关重要。
- en: To improve the tissue structure-function mapping, graph representations based
    on tissue regions have been proposed, which can also deal with one of the limitations
    of cell-graph as important regions may not need to only contain cells [[36](#bib.bib36),
    [27](#bib.bib27), [42](#bib.bib42)]. Tissue-graphs represent well-defined tissue
    regions and are used to propagate information across neighboring nodes in a progressive
    manner at a gland or region level. Although superpixel-based approaches are proposed
    to address patch-graph limitations, a tissue-graph alone cannot capture local
    cellular information. A combination of cell-level and patch-level features was
    proposed to capture local and global patterns from histological images [[32](#bib.bib32)].
    However, this fusion approach cannot take advantage of the hierarchy between levels.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 为了改进组织结构-功能映射，基于组织区域的图表示法被提出，这也可以解决细胞图的一个限制，即重要区域可能不仅仅包含细胞[[36](#bib.bib36),
    [27](#bib.bib27), [42](#bib.bib42)]。组织图（tissue-graphs）代表了明确定义的组织区域，并用于在腺体或区域级别以逐步的方式传播信息。尽管提出了基于超像素的方法来解决补丁图的限制，但单独使用组织图无法捕捉局部细胞信息。提出了结合细胞级和补丁级特征的方法来捕捉来自组织学图像的局部和全局模式[[32](#bib.bib32)]。然而，这种融合方法无法利用层级之间的关系。
- en: Hierarchical graph representations were proposed as an adequate tissue representation
    as histological structures cannot be fully represented by cellular or tissue interactions
    alone. It has been shown that cell-graphs and tissue-graphs provide valuable complementary
    information (cellular and tissue interactions) to learn the intrinsic characteristics
    of cancerous tissues. Such hierarchical analysis that captures multivariate tissue
    information at multiple levels has been addressed only by [[29](#bib.bib29), [17](#bib.bib17),
    [31](#bib.bib31), [16](#bib.bib16)]. Nevertheless, this approach is still dependent
    on the construction of a cell-centered graph, which itself is limited by cell
    detection accuracy and is subjected to the complexity constraints of the model
    driven by the number of nodes. Other works have dealt with cell detection limitations
    by exploiting graph wavelets with different scaling parameters [[29](#bib.bib29)]
    to obtain multilevel tissue structural information in a tissue-graph. Further,
    in [[16](#bib.bib16)] micro- and macro architectures of histology images were
    captured with the combination of a topological data analysis tool (cell-level)
    and GCN (tissue-level).
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
  zh: 层次化图表示被提出作为一种适当的组织表示，因为组织结构不能仅通过细胞或组织交互完全表示。研究表明，细胞图和组织图提供了有价值的补充信息（细胞和组织交互），有助于学习癌变组织的内在特征。这种捕捉多层次组织信息的层次分析仅由[[29](#bib.bib29),
    [17](#bib.bib17), [31](#bib.bib31), [16](#bib.bib16)]解决。然而，这种方法仍然依赖于细胞中心图的构建，而细胞检测的准确性限制了这一图的构建，并且模型的复杂性受节点数量的约束。其他工作通过利用具有不同缩放参数的图小波[[29](#bib.bib29)]解决了细胞检测的限制，以获取组织图中的多层次组织结构信息。此外，在[[16](#bib.bib16)]中，组织图像的微观和宏观结构通过结合拓扑数据分析工具（细胞级别）和GCN（组织级别）进行捕捉。
- en: Feature extraction
  id: totrans-314
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 特征提取
- en: Handcrafted and CNN-based features have been the typical methods to characterize
    entities. Such deep feature extraction allows use of features from a pre-trained
    deep architecture. However, the performance of these methods is compromised because
    the authors usually utilize a pre-trained model (e.g., trained on ImageNet) due
    to a lack of patch labels to fine-tune the network, and thus suffer from the domain
    gap between natural scene images and histopathological images. To address this
    limitation, a small number of works trained a feature extractor using self-supervised
    approaches such as CPC, VAE-GAN and auto encoder in [[15](#bib.bib15), [32](#bib.bib32),
    [40](#bib.bib40), [27](#bib.bib27)].
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
  zh: 手工制作的特征和基于CNN的特征是表征实体的典型方法。这种深度特征提取允许使用预训练深度架构的特征。然而，这些方法的性能受到限制，因为作者通常利用预训练模型（例如，在ImageNet上训练）来进行网络的微调，而缺乏补丁标签，因此面临自然场景图像与组织病理图像之间的领域差距。为了解决这一限制，一些工作使用自监督方法如CPC、VAE-GAN和自编码器训练了特征提取器[[15](#bib.bib15),
    [32](#bib.bib32), [40](#bib.bib40), [27](#bib.bib27)]。
- en: Graph topology
  id: totrans-316
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 图拓扑
- en: On current entity-graphs, each node is only connected to its spatially nearest
    neighbors, resulting in relatively limited information exchange during the message
    passing phase. Only one approach to date has computed the connections between
    nodes by using an adjacency learning layer in an end-to-end manner that considered
    the global context of all patches [[43](#bib.bib43)]. Edge embeddings in cell-graph
    and tissue-graph topologies are a poorly studied field with few approaches. Learning
    takes place primarily at the vertices, with edge attributes serving as auxiliary
    information. The EGNN has only been applied in [[38](#bib.bib38)] for colorectal
    cancer classification, and shows similar performance to the best model based on
    a 1-dimensional GNN [[108](#bib.bib108)]. Edge attributes can also directly inform
    the message passing phase operating over the vertices. In the MEGNet [[121](#bib.bib121)]
    model, vertices are updated by an aggregation of features from adjacent edges.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
  zh: 在当前的实体图中，每个节点仅与其空间上最近的邻居连接，这导致在消息传递阶段信息交换相对有限。迄今为止，只有一种方法通过使用端到端的邻接学习层计算节点之间的连接，考虑了所有补丁的全局上下文[[43](#bib.bib43)]。在细胞图和组织图拓扑中的边嵌入是一个研究较少的领域，只有少数方法在研究中。学习主要发生在顶点处，边属性作为辅助信息。EGNN仅在[[38](#bib.bib38)]中用于结直肠癌分类，其性能与基于一维GNN的最佳模型[[108](#bib.bib108)]相似。边属性还可以直接影响在顶点上进行的消息传递阶段。在MEGNet[[121](#bib.bib121)]模型中，顶点通过从邻接边聚合特征进行更新。
- en: IV-A2 Automated graph generation
  id: totrans-318
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 自动化图生成
- en: Automated graph structure estimation aims to find a suitable graph to represent
    the data as input to the GNN model. By modeling graph generation as a sequential
    process, the graph representation (nodes, edges and embeddings) can be inferred
    directly from data which would be especially useful when representing tissues
    with a variety of complex micro- and macro environments. However, the majority
    of methods surveyed follow a standard sequential workflow which is highly dependent
    on the individual performance of each preprocessing step, including tissue mask
    detection, nuclei detection, super-pixel detection, deep feature extraction, and
    graph building. The use of neural networks to build generative graph models is
    gaining popularity to capture both their topology and their attributes, which
    can in turn lead to more robust algorithms and help to provide more accurate results.
    However, the effectiveness of such algorithms have not been investigated for histopathology
    images. Therefore, several requirements are still needed to enable the generation
    process.
  id: totrans-319
  prefs: []
  type: TYPE_NORMAL
  zh: 自动图结构估计旨在找到适合的数据图以作为GNN模型的输入。通过将图生成建模为一个序列过程，图表示（节点、边和嵌入）可以直接从数据中推断出来，这在表示具有多种复杂微观和宏观环境的组织时特别有用。然而，大多数调查的方法遵循标准的序列工作流程，这高度依赖于每个预处理步骤的个体表现，包括组织掩膜检测、细胞核检测、超像素检测、深度特征提取和图构建。使用神经网络构建生成图模型越来越受欢迎，以捕捉其拓扑和属性，这可以导致更强健的算法并帮助提供更准确的结果。然而，此类算法在组织病理图像中的有效性尚未得到研究。因此，仍需满足一些要求以实现生成过程。
- en: Several works that have adopted GCNs for brain electrical activity analysis
    tasks  [[21](#bib.bib21)] have demonstrated that learning the graph structure
    from data improves classification performance in comparison to approaches where
    a pre-defined graph topology is used. In digital pathology these predefined parameters
    per histology task are represented by fixed threshold to differentiate non-tissue
    pixels; patch size and number of patches for nuclei detection, and nuclei and
    tissue feature extraction; sample ratio of representative nuclei; thresholded
    KNN and distance that define topology and edges; the number of superpixels and
    downsampling factor per image; and selection of handcrafted features and CNN layer
    from which deep features are extracted. Such definitions limit the generalization
    of entity-graphs to different tissues, organs, and histology tasks. Some graph
    generation approaches that are worthy of exploration within histopathology diagnosis
    are GraphGAN [[122](#bib.bib122)], DGMG [[123](#bib.bib123)], and GCPN [[124](#bib.bib124)].
    For instance, DGMG [[123](#bib.bib123)] can be used to generate one node at a
    time from each histopathology patch and then create edges one by one, to connect
    each node to the existing partial graph using probabilistic dependencies among
    nodes.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
  zh: 采用GCNs进行脑电活动分析任务的若干研究[[21](#bib.bib21)]已经证明，从数据中学习图结构比使用预定义图拓扑的方法能提高分类性能。在数字病理学中，这些预定义参数包括用于区分非组织像素的固定阈值；用于细胞核检测的补丁大小和数量，以及细胞核和组织特征提取；代表性细胞核的样本比例；定义拓扑和边的阈值KNN和距离；每张图像的超像素数量和下采样因子；以及选择手工特征和从中提取深度特征的CNN层。这些定义限制了实体图在不同组织、器官和组织学任务中的泛化能力。一些在组织病理学诊断中值得探索的图生成方法包括GraphGAN
    [[122](#bib.bib122)]、DGMG [[123](#bib.bib123)] 和GCPN [[124](#bib.bib124)]。例如，DGMG
    [[123](#bib.bib123)]可以从每个组织病理学补丁中一次生成一个节点，然后逐一创建边，使用节点之间的概率依赖关系将每个节点连接到现有的部分图中。
- en: In summary, the preceding discussion exemplified the difficulties in estimating
    a graph structure with the desired properties from data. While there is emerging
    work in this field, it is ripe for further investigation. In digital pathology,
    automated graph generation, in which a graph model infers structural content from
    data, and the integration of domain knowledge, are also underutilised.
  id: totrans-321
  prefs: []
  type: TYPE_NORMAL
  zh: 总之，上述讨论展示了从数据中估计具有期望属性的图结构的困难。尽管该领域有新兴的工作，但仍需进一步研究。在数字病理学中，自动图生成，其中图模型从数据中推断结构内容，以及领域知识的整合，也未得到充分利用。
- en: IV-B Embedding expert knowledge and clinical adoption of graph analytics
  id: totrans-322
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 嵌入专家知识和图分析的临床应用
- en: Incorporating domain knowledge into the model has emerged as a promising method
    for improving medical image analysis [[125](#bib.bib125)]. The use of graph-based
    mappings with label representations (word embeddings) have been investigated to
    guide information propagation among nodes [[126](#bib.bib126)]. For example, in
    basal cell carcinoma classification [[47](#bib.bib47)], the embedding knowledge
    is represented by encoding patches based on prior expert knowledge, which bridges
    the gap between patch-level and image-level predictions and results in better
    performance. Further, pathologists’ feedback can help to improve the graph representation
    in terms of how to best mirror the biological relationship between cells and tissues.
    Thus, graph-based analysis motivates exploring the inclusion of task-specific
    pathological prior knowledge in the construction of the graph representations [[17](#bib.bib17)].
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
  zh: 将领域知识融入模型已经成为一种提升医学图像分析的有前景的方法[[125](#bib.bib125)]。使用基于图的映射和标签表示（词嵌入）已被研究用来指导节点间的信息传播[[126](#bib.bib126)]。例如，在基底细胞癌分类中[[47](#bib.bib47)]，嵌入知识通过基于先前专家知识对图像块进行编码来表示，这弥合了图像块级别和图像级别预测之间的差距，从而提高了性能。此外，病理学家的反馈可以帮助改进图的表示，以最佳方式反映细胞和组织之间的生物关系。因此，基于图的分析激发了探索在图表示构建中加入任务特定病理学先验知识的动机[[17](#bib.bib17)]。
- en: Another open research question is how to incorporate interdisciplinary knowledge
    in a principled way, rather than on a case-by-case basis. Integrating electronic
    health records for personalized medicine can also boost the diagnostic power of
    digital pathology. The hierarchical information inherent in medical ontologies
    naturally lends itself to creating a rich network of medical knowledge, and other
    data types such as symptoms and genomics [[127](#bib.bib127)]. Thus, by integrating
    patient records into the graph representation learning environment, tailored predictions
    can be generated for individual patients.
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
  zh: 另一个尚未解决的研究问题是如何以有原则的方式整合跨学科知识，而不是逐案处理。整合电子健康记录以实现个性化医学也可以提升数字病理学的诊断能力。医学本体中固有的层级信息自然有助于创建丰富的医学知识网络，以及其他数据类型，如症状和基因组学[[127](#bib.bib127)]。因此，通过将患者记录整合到图表示学习环境中，可以为个体患者生成量身定制的预测。
- en: Among the AI-techniques, graph-based tissue image analysis demonstrated performance
    superior or comparable to domain experts in breast cancer analysis [[31](#bib.bib31)].
    These results combined with studies examining the effect of explanations on clinical
    end-user decisions [[33](#bib.bib33)] show generally positive results in the translation
    of this technology into diagnostic pathology. Such translation will require to
    considered integration of standardised technologies into digital pathology workflows,
    resulting in an integrated approach to diagnosis and offering pathologists new
    tools that accelerate their workflow, increase diagnostic consistency, and reduce
    errors.
  id: totrans-325
  prefs: []
  type: TYPE_NORMAL
  zh: 在人工智能技术中，基于图的组织图像分析在乳腺癌分析中表现出优于或可与领域专家相媲美的性能[[31](#bib.bib31)]。这些结果与研究解释对临床最终用户决策影响的研究[[33](#bib.bib33)]结合，显示了将该技术转化为诊断病理学的一般积极结果。这种转化将需要考虑将标准化技术整合到数字病理学工作流程中，从而实现诊断的一体化方法，为病理学家提供加速工作流程、提高诊断一致性和减少错误的新工具。
- en: While, there is considerable promise for graph analytics in digital pathology,
    there are some challenges ahead. These include, for example, the ability to generalize
    a diagnosis technique to a large population of patients which contain outliers;
    and to develop problem-solving skills that demand complex interactions with other
    medical disciplines. Thus, more work should be conducted to investigate how a
    pathologist could refine a graph model decision via a human-in-the-loop system [[128](#bib.bib128),
    [129](#bib.bib129)] Such approaches provide an important safety mechanism for
    detecting and correcting algorithmic errors that may occur. A remaining challenge
    here is to provide frameworks with the above functionalities with reduced complexity
    to lower the barriers between the systems and clinicians, to help facilitate system
    uptake.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在数字病理学中图形分析显示出相当大的潜力，但仍面临一些挑战。这些挑战包括，例如，将诊断技术推广到包含异常值的大量患者群体的能力；以及发展需要与其他医学学科复杂互动的问题解决技能。因此，应进行更多研究，以调查病理学家如何通过“人机协同”系统来完善图模型决策[[128](#bib.bib128),
    [129](#bib.bib129)]。这些方法提供了一个重要的安全机制，用于检测和纠正可能发生的算法错误。一个尚待解决的挑战是提供具有上述功能的框架，同时减少复杂性，以降低系统与临床医生之间的障碍，帮助促进系统的应用。
- en: Entity-graph analysis has the ability to transform pathology by providing applications
    that speed up workflow, improve diagnosis, and improve patient clinical outcomes.
    However, there is still a gap between research studies and the effort required
    to deliver reliable graph analytics that incorporate expert knowledge into the
    system, and can be integrated into existing clinical workflows.
  id: totrans-327
  prefs: []
  type: TYPE_NORMAL
  zh: 实体图分析有能力通过提供加快工作流程、改善诊断和提高患者临床结果的应用来改变病理学。然而，研究与实现可靠的图形分析之间仍然存在差距，这些分析应将专家知识纳入系统，并能够集成到现有的临床工作流程中。
- en: IV-C Complexity of graph models
  id: totrans-328
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 图模型的复杂性
- en: Graph-based approaches for histology analysis have a high representational power,
    and can describe topological and geometric properties of multiple types of cancers.
    When compared to pixel-based approaches, the graph representation can more seamlessly
    describe a large tissue region. However, classical graph-based models have a high
    computational complexity. As a result, in the suggested learning approach, the
    choice of GNN architecture should be handled as a hyper-parameter.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图的组织学分析方法具有很高的表征能力，可以描述多种癌症的拓扑和几何属性。与基于像素的方法相比，图形表示可以更无缝地描述大范围的组织区域。然而，经典的图形模型具有很高的计算复杂性。因此，在建议的学习方法中，GNN（图神经网络）架构的选择应作为一个超参数进行处理。
- en: The most common GNNs used by methods in this survey include ChebNet [[66](#bib.bib66)],
    GCN [[67](#bib.bib67)], GraphSAGE [[68](#bib.bib68)], GAT [[72](#bib.bib72)],
    GIN [[73](#bib.bib73)], and variants such as Adaptive GraphSAGE [[39](#bib.bib39)],
    RSF [[75](#bib.bib75)], MS-GWNN [[29](#bib.bib29)] and FENet [[41](#bib.bib41)].
    Spatial-GCNs such as GraphSAGE and GIN demonstrated their learning ability using
    max-, mean-, or sum-pooling aggregators. GIN has been particularly effective in
    computational pathology with a provably strong expressive power to learn fixed-size
    discriminative graph embeddings from cellular and tissue architectures in WSIs,
    which demonstrate translation and rotation invariance. However, it is noted that
    these GNN models inherit considerable complexity from their deep learning lineage,
    which can be burdensome when scaling and deploying GNNs. This is likely one of
    the reasons that has seen patch-based approaches remain a popular approach for
    many problems.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查中使用的最常见的GNN包括ChebNet[[66](#bib.bib66)]、GCN[[67](#bib.bib67)]、GraphSAGE[[68](#bib.bib68)]、GAT[[72](#bib.bib72)]、GIN[[73](#bib.bib73)]以及变体如Adaptive
    GraphSAGE[[39](#bib.bib39)]、RSF[[75](#bib.bib75)]、MS-GWNN[[29](#bib.bib29)]和FENet[[41](#bib.bib41)]。空间-GCN如GraphSAGE和GIN通过使用max-、mean-或sum-pooling聚合器展示了它们的学习能力。GIN在计算病理学中尤其有效，具有可证明的强表达能力，能够从WSI（全视野图像）中的细胞和组织结构中学习固定大小的区分图嵌入，表现出平移和旋转不变性。然而，需要注意的是，这些GNN模型继承了深度学习谱系中的相当复杂性，这在扩展和部署GNN时可能会造成负担。这可能是导致许多问题仍然保持基于补丁的方法流行的原因之一。
- en: The training of GNNs remains one of the most difficult tasks due to their high
    memory consumption and inference latency compared to patch-based deep learning
    approaches. GNNs usually require the whole graph and the intermediate states of
    all nodes to be saved in memory. However, the adoption of an efficient training
    approach is uncommon in the applications surveyed. Various graph sampling approaches
    have been proposed as a way to alleviate the cost of training GNNs. Rather than
    training over the full graph, each iteration is run over a sampled sub-graph,
    whether they are sampled node-wise (GraphSage [[68](#bib.bib68)]), layer-wise
    (FastGCN [[130](#bib.bib130)], $L^{2}$-GCN [[131](#bib.bib131)]), or by clustering
    (Cluster-GCN [[132](#bib.bib132)]).
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
  zh: 由于GNNs相比基于补丁的深度学习方法具有较高的内存消耗和推理延迟，因此其训练仍然是最困难的任务之一。GNNs通常需要将整个图以及所有节点的中间状态保存在内存中。然而，调查的应用中采用高效训练方法的情况并不常见。各种图采样方法已被提出，以缓解训练GNNs的成本。与其在完整图上训练，不如在每次迭代中在采样的子图上运行，无论是采样节点级（GraphSage
    [[68](#bib.bib68)]）、层级（FastGCN [[130](#bib.bib130)]，$L^{2}$-GCN [[131](#bib.bib131)]）还是通过聚类（Cluster-GCN
    [[132](#bib.bib132)]）。
- en: Some works have proposed more efficient and simple architectures that deserve
    attention for their potential to be adopted in computational histopathology. The
    simple graph convolution (SGC) [[133](#bib.bib133)] reduces the complexity of
    GCNs by repeatedly removing the non-linearities between GCN layers and collapsing
    multiple weight matrices into a single linear transformation. This model was adopted
    for emotion recognition and increased the performance speed with a comparable
    classification accuracy in comparison to other networks [[134](#bib.bib134)].
    The simple scalable inception GNN (SIGN) [[135](#bib.bib135)] is explicitly designed
    as a shallow architecture that combines graph convolutional filters of different
    sizes that allow efficient pre-computation. The efficient graph convolution (EGC) [[136](#bib.bib136)]
    method does not require trading accuracy for runtime memory or latency reductions
    based on an adaptive filtering approach. GNNs can also deliver high performance
    for feature matching across images [[137](#bib.bib137)], which can be incorporated
    for content-based histopathological image retrieval.
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 一些研究提出了更高效且简单的架构，这些架构因其在计算组织病理学中的潜在应用而值得关注。简单图卷积（SGC）[[133](#bib.bib133)]通过反复移除图卷积网络（GCNs）层之间的非线性，并将多个权重矩阵合并为一个线性变换，从而降低了GCNs的复杂性。该模型被应用于情感识别，并提高了性能速度，同时在分类准确性方面与其他网络相当[[134](#bib.bib134)]。简单可扩展的Inception图神经网络（SIGN）[[135](#bib.bib135)]明确设计为一种浅层架构，结合了不同尺寸的图卷积滤波器，以实现高效的预计算。高效图卷积（EGC）[[136](#bib.bib136)]方法不需要在自适应滤波方法的基础上在准确性与运行时内存或延迟减少之间做出权衡。GNNs还可以在图像特征匹配中提供高性能[[137](#bib.bib137)]，这可以被纳入基于内容的组织病理图像检索中。
- en: It is also important to highlight that some works exploit the cell-graph representation
    without the complexity of GCN processing. The tissue classification problem was
    proposed in [[138](#bib.bib138)] as a cellular community detection based on cell
    detection and classification into distinct cellular components (cell-graphs),
    and clustering of image patches (patch-level graphs) into biologically meaningful
    communities (specific tissue phenotype). The concept of constructing a graph and
    then using geodesic distance for community detection has outperformed deep neural
    networks and graph-based deep leaning methods such as ChebNet, GCNs and deep graph
    infomax learning (DGI) [[139](#bib.bib139)].
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
  zh: 还需强调的是，一些研究利用了无需GCN处理复杂性的细胞图表示。组织分类问题在[[138](#bib.bib138)]中被提出为基于细胞检测和分类到不同细胞组件（细胞图）的细胞社区检测，以及图像补丁（补丁级图）的聚类到生物学上有意义的社区（特定组织表型）。构建图形并使用测地距离进行社区检测的概念已超越了深度神经网络和基于图的深度学习方法，如ChebNet、GCNs和深度图信息最大化学习（DGI）[[139](#bib.bib139)]。
- en: In the coming years, a key research topic will be how to effectively learn and
    compute GNNs in order to realise their full potential. Deep learning on graphs
    is inherently difficult due to the graphs’ complex topological structure, which
    can be made up of many different types of entities and interactions. As such,
    the appropriate selection of key parameters of a model prior to representation
    learning is essential to capture the structural information of the histopathology
    slides.
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 在未来几年，一个关键的研究课题将是如何有效地学习和计算GNN，以实现其*最终*潜力。由于图的复杂拓扑结构，图上的深度学习本质上很困难，这些结构可以由许多不同类型的实体和交互组成。因此，在表示学习之前适当选择模型的关键参数对于捕捉组织病理切片的结构信息至关重要。
- en: IV-D Training paradigms
  id: totrans-335
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 训练范式
- en: 'As stated in previous sections, training paradigms can be divided into two
    main categories: training a network to learn the node embeddings used in the graph
    representation; and the training of the GNN model.'
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，训练范式可以分为两个主要类别：训练网络以学习用于图表示的节点嵌入；以及GNN模型的训练。
- en: IV-D1 Node embeddings
  id: totrans-337
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D1 节点嵌入
- en: The node embeddings are the features that are learned to represent the defined
    node (e.g. cells, nucleus, patches, super-pixels). Some of the embedding features
    extracted through attribute networks require labeled datasets and need to be trained
    in a supervised manner as explained in [[33](#bib.bib33), [34](#bib.bib34), [30](#bib.bib30),
    [28](#bib.bib28), [38](#bib.bib38), [39](#bib.bib39), [35](#bib.bib35), [36](#bib.bib36),
    [26](#bib.bib26), [37](#bib.bib37), [41](#bib.bib41), [43](#bib.bib43), [44](#bib.bib44),
    [47](#bib.bib47), [31](#bib.bib31), [17](#bib.bib17), [29](#bib.bib29), [16](#bib.bib16),
    [46](#bib.bib46), [25](#bib.bib25)]. However, one of the main challenges in deep
    learning is the lack of large corpora of manually labeled data for training, which
    often imposes a limitation on problems in the medical domain. Thus, self-supervised
    methods are gaining interest to improve the quality of learned node embeddings [[15](#bib.bib15),
    [40](#bib.bib40), [27](#bib.bib27), [45](#bib.bib45), [32](#bib.bib32)] by learning
    embedding features directly from histopathology images, rather than relying on
    extracting features using transfer learning, which is discussed in Subsection [IV-A](#S4.SS1
    "IV-A Entity-graph construction ‣ IV Discussion and open challenges ‣ A Survey
    on Graph-Based Deep Learning for Computational Histopathology").
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 节点嵌入是学习到的特征，用于表示定义的节点（例如细胞、细胞核、补丁、超级像素）。一些通过属性网络提取的嵌入特征需要标注的数据集，并需要以监督方式训练，如[[33](#bib.bib33)、[34](#bib.bib34)、[30](#bib.bib30)、[28](#bib.bib28)、[38](#bib.bib38)、[39](#bib.bib39)、[35](#bib.bib35)、[36](#bib.bib36)、[26](#bib.bib26)、[37](#bib.bib37)、[41](#bib.bib41)、[43](#bib.bib43)、[44](#bib.bib44)、[47](#bib.bib47)、[31](#bib.bib31)、[17](#bib.bib17)、[29](#bib.bib29)、[16](#bib.bib16)、[46](#bib.bib46)、[25](#bib.bib25)]中解释的那样。然而，深度学习的主要挑战之一是缺乏大量人工标注的数据进行训练，这通常对医学领域的问题构成限制。因此，自监督方法正受到关注，以通过直接从组织病理图像中学习嵌入特征来提高学习到的节点嵌入的质量[[15](#bib.bib15)、[40](#bib.bib40)、[27](#bib.bib27)、[45](#bib.bib45)、[32](#bib.bib32)]，而不是依赖于使用迁移学习提取特征，这在子节[IV-A](#S4.SS1
    "IV-A 实体-图构建 ‣ IV 讨论和开放挑战 ‣ 图基深度学习在计算组织病理学中的调查")中进行了讨论。
- en: IV-D2 Node/graph classification
  id: totrans-339
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-D2 节点/图分类
- en: Training a GCN for node or graph level classification can be performed in supervised,
    semi-supervised or even in a self-supervised manner. If sufficient labels are
    available for nodes or graph data, the common practice is a supervised training
    approach, such as the methods of [[33](#bib.bib33), [34](#bib.bib34), [30](#bib.bib30),
    [28](#bib.bib28), [38](#bib.bib38), [39](#bib.bib39), [36](#bib.bib36), [37](#bib.bib37),
    [41](#bib.bib41), [45](#bib.bib45), [31](#bib.bib31), [17](#bib.bib17), [29](#bib.bib29),
    [16](#bib.bib16), [25](#bib.bib25), [43](#bib.bib43)].
  id: totrans-340
  prefs: []
  type: TYPE_NORMAL
  zh: 对于节点或图级分类的GCN训练可以通过监督、半监督甚至自监督的方式进行。如果节点或图数据有足够的标签，常见的做法是采用监督训练方法，例如[[33](#bib.bib33)、[34](#bib.bib34)、[30](#bib.bib30)、[28](#bib.bib28)、[38](#bib.bib38)、[39](#bib.bib39)、[36](#bib.bib36)、[37](#bib.bib37)、[41](#bib.bib41)、[45](#bib.bib45)、[31](#bib.bib31)、[17](#bib.bib17)、[29](#bib.bib29)、[16](#bib.bib16)、[25](#bib.bib25)、[43](#bib.bib43)]所示的方法。
- en: Though supervised methods can achieve high performance, they can place limitations
    on model complexity and can suffer when annotations are inconsistent or imprecise.
    In the absence of sufficient labeled data, weakly-supervised or semi-supervised
    frameworks are proposed to better capture the structure of histopathology data
    and reduce the human annotation workload. Although the issue of missing labels
    is not specific to the graph domain, only a few works have adopted such frameworks
    (pixel or patch level labels).
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管监督方法可以实现高性能，但它们可能对模型复杂性施加限制，并且在标注不一致或不精确时可能表现不佳。在缺乏足够标记数据的情况下，提出了弱监督或半监督框架，以更好地捕捉组织病理数据的结构并减少人工标注工作量。虽然缺失标签的问题并非图域特有，但只有少数工作采用了这些框架（像素或补丁级标签）。
- en: In semi- or weakly-supervised approach, the node embeddings are learnt from
    few labeled samples per class [[46](#bib.bib46), [15](#bib.bib15), [26](#bib.bib26),
    [47](#bib.bib47)]. For example, in a weakly supervised learning approach, the
    contributions of the individual patches to the ROI-level diagnosis are not known
    during training [[26](#bib.bib26)].
  id: totrans-342
  prefs: []
  type: TYPE_NORMAL
  zh: 在半监督或弱监督方法中，节点嵌入是从每类少量标记样本中学习的[[46](#bib.bib46), [15](#bib.bib15), [26](#bib.bib26),
    [47](#bib.bib47)]。例如，在弱监督学习方法中，训练期间无法知道各个补丁对ROI级诊断的贡献[[26](#bib.bib26)]。
- en: In addition to the above, extensive research over past years in deep learning [[140](#bib.bib140),
    [141](#bib.bib141), [142](#bib.bib142)] showed that a decision classifier based
    on Multiple Instance Learning (MIL) can boost the performance in classifying cancer
    by aggregating instance-level predictions. MIL only requires labels for the bag
    of instances rather than individual instances, which makes it well-suited for
    histology slide classification. One example is CLAM (Clustering-constrained attention
    multiple instance learning [[143](#bib.bib143)]). Even though these approaches
    have practical merits and can consider the important patches for predicting the
    staging, they do not consider the spatial relationships between patches. Current
    multiple instance learning approaches using deep graphs [[27](#bib.bib27), [40](#bib.bib40),
    [43](#bib.bib43)] follow this line of research. They can seamlessly scale to arbitrary
    tissue dimensions by incorporating an arbitrary number of entities and interactions,
    thus offering an alternative to traditional MIL [[143](#bib.bib143)]. MIL methods
    can be incorporated with a GCN to take advantage of the structural information
    among instances [[4](#bib.bib4)]. For example, the SegGini model [[42](#bib.bib42)]
    outperforms several traditional state-of-the-art methods such as CLAM [[143](#bib.bib143)]
    and Context-Aware CNN (CACNN) [[144](#bib.bib144)] for weakly-supervised classification
    of prostate cancer.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述内容，过去几年在深度学习方面的大量研究[[140](#bib.bib140), [141](#bib.bib141), [142](#bib.bib142)]表明，基于多实例学习（MIL）的决策分类器通过聚合实例级预测可以提升癌症分类的性能。MIL仅需要对实例包进行标记，而不是单个实例，这使其非常适合组织学切片分类。一个例子是CLAM（聚类约束注意力多实例学习[[143](#bib.bib143)]）。尽管这些方法具有实际优点，可以考虑预测分期的重要补丁，但它们未考虑补丁之间的空间关系。目前的多实例学习方法使用深度图[[27](#bib.bib27),
    [40](#bib.bib40), [43](#bib.bib43)]遵循这一研究方向。通过整合任意数量的实体和交互，它们可以无缝扩展到任意组织维度，因此提供了传统MIL[[143](#bib.bib143)]的替代方案。MIL方法可以与GCN结合，以利用实例之间的结构信息[[4](#bib.bib4)]。例如，SegGini模型[[42](#bib.bib42)]在前列腺癌的弱监督分类中优于CLAM[[143](#bib.bib143)]和Context-Aware
    CNN (CACNN)[[144](#bib.bib144)]等几种传统的最先进方法。
- en: Self supervised methods have also been successfully deployed as a training paradigm
    for GCNs. For example, Ozen et al. [[35](#bib.bib35)] adopted a SimCLR framework [[111](#bib.bib111)]
    along with contrastive loss to learn a representation of ROIs and perform classification.
    Although the aforementioned training paradigms demonstrate remarkable performance,
    few works [[43](#bib.bib43)] have considered end-to-end training and the challenge
    that brings such as dealing with complexity of constructing a graph or labeled
    data, and thus this requires investigation in future works.
  id: totrans-344
  prefs: []
  type: TYPE_NORMAL
  zh: 自监督方法也已成功应用于GCNs的训练范式。例如，Ozen等人[[35](#bib.bib35)]采用了SimCLR框架[[111](#bib.bib111)]以及对比损失来学习ROI的表示并进行分类。尽管上述训练范式表现出色，但很少有工作[[43](#bib.bib43)]考虑了端到端训练及其带来的挑战，如构建图或标记数据的复杂性，因此这需要在未来的工作中进一步探讨。
- en: Training paradigms are dependent on the availability of manually labeled data.
    In medical imaging and specifically histopathology obtaining a large set of labeled
    data is a tedious process and so weakly- and self-supervised algorithms are receiving
    increasing interest for learning node embeddings and performing graph classification.
    It is expected that in future, further research carry out on a large-scale to
    analyse histopathology data using GCNs in a weakly- or self-supervised manner.
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: 训练范式依赖于手动标记的数据。在医学影像，尤其是组织病理学中，获得大量标记数据是一个繁琐的过程，因此，弱监督和自监督算法在学习节点嵌入和进行图分类方面越来越受到关注。预计未来会有更多的大规模研究，利用GCNs以弱监督或自监督的方式分析组织病理数据。
- en: IV-E Explainability of graph models
  id: totrans-346
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 图模型的可解释性
- en: To effectively translate graph models into clinical practise, clinicians’ trust
    must be established. Explainability, or a model’s ability to justify its outcomes
    and therefore assist clinicians in understanding a model’s prediction, has long
    been seen as crucial to building trust. Understanding model behaviour beyond traditional
    performance indicators has thus become an important part of machine learning research,
    particularly in healthcare [[145](#bib.bib145)].
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 为了有效将图模型转化为临床实践，必须建立临床医生的信任。可解释性，即模型能够解释其结果并因此帮助临床医生理解模型的预测，一直被视为建立信任的关键。因此，理解模型行为超越传统性能指标已经成为机器学习研究中的一个重要部分，特别是在医疗保健领域[[145](#bib.bib145)]。
- en: Explainability in deep models has focused on providing input-dependent explanations
    and understanding model behavior from different perspectives, including visual
    explanations and highlighting salient regions. We can examine the sensitivity
    between the input features and the predictions, for example, by looking at the
    gradients or weights. We can also highlight important features or regions of an
    image by incorporating attention mechanisms [[146](#bib.bib146)]. Nevertheless,
    compared with traditional image domains, explainability and visualization of deep
    learning for graphs is less explored [[84](#bib.bib84)], yet explanability is
    critical to highlight informative structural compositions of tissue and inter-nuclear
    relationships, as is desired for computational histopathology.
  id: totrans-348
  prefs: []
  type: TYPE_NORMAL
  zh: 深度模型的可解释性集中于提供依赖输入的解释，并从不同的角度理解模型行为，包括视觉解释和突出显著区域。例如，我们可以通过查看梯度或权重来检查输入特征与预测之间的敏感性。我们还可以通过结合注意机制来突出图像中的重要特征或区域[[146](#bib.bib146)]。然而，与传统图像领域相比，深度学习图的可解释性和可视化尚未得到充分探讨[[84](#bib.bib84)]，但可解释性对于突出组织的结构成分和细胞核间关系至关重要，这在计算组织病理学中是所期望的。
- en: 'While interpretability approaches are generally lacking within most graph network
    methods, it is worth noting that a few methods exist and incorporate such explanations
    in digital pathology as illustrated in Table [II](#S2.T2 "TABLE II ‣ II-D2 Graph
    explainers ‣ II-D Graph interpretations ‣ II Graph representation learning in
    digital pathology: Background ‣ A Survey on Graph-Based Deep Learning for Computational
    Histopathology"): i) In [[47](#bib.bib47)] a GCN propagated supervisory information
    over patches to learn patch-aware interpretability in the form of a probability
    score. ii) A robust spatial filtering with an attention-based architecture and
    node occlusion was used to capture the contribution of each nucleus and its neighborhood
    to the prediction [[30](#bib.bib30)]. iii) The Graph Mapper, a topological data
    analysis tool, was adopted to compress histological information to its essential
    structures, where meaningful histology regions are captured [[16](#bib.bib16)].
    iv) In [[32](#bib.bib32)], an integrated gradient method was used to visualise
    image saliency feature importance. v) A graph clustering visualization was used
    in [[39](#bib.bib39)] to group cells with similar tissue structures. vi) A post-hoc
    graph-pruning explainer, GCExplainer, was designed to identify decisive cells
    and interactions from the input graph [[34](#bib.bib34)]. vii) The gradient-based
    saliency method, GraphGrad-CAM, was adopted in [[31](#bib.bib31)] and [[42](#bib.bib42)]
    to measure importance scores and regions that contributed towards the classification
    of each class.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管大多数图网络方法普遍缺乏可解释性方法，但值得注意的是，存在一些方法在数字病理学中纳入了这种解释，如表[II](#S2.T2 "TABLE II ‣
    II-D2 Graph explainers ‣ II-D Graph interpretations ‣ II Graph representation
    learning in digital pathology: Background ‣ A Survey on Graph-Based Deep Learning
    for Computational Histopathology")所示：i) 在[[47](#bib.bib47)]中，GCN在图块上传播监督信息，以学习以概率评分形式的图块感知可解释性。ii)
    使用了一种基于注意力的架构和节点遮挡的强大空间过滤来捕捉每个细胞核及其邻域对预测的贡献[[30](#bib.bib30)]。iii) 采用了图Mapper，一个拓扑数据分析工具，压缩组织学信息至其基本结构，捕捉到有意义的组织学区域[[16](#bib.bib16)]。iv)
    在[[32](#bib.bib32)]中，使用了集成梯度方法来可视化图像显著性特征的重要性。v) 在[[39](#bib.bib39)]中，使用图聚类可视化来对具有相似组织结构的细胞进行分组。vi)
    设计了一个后验图剪枝解释器GCExplainer，以识别输入图中的关键细胞和相互作用[[34](#bib.bib34)]。vii) 梯度基础的显著性方法GraphGrad-CAM在[[31](#bib.bib31)]和[[42](#bib.bib42)]中被采用，以测量对每个类别分类作出贡献的重要性评分和区域。'
- en: The majority of approaches that have incorporated explainers are limited to
    cell-graph analysis. Considering the pathologically aligned multi-level hierarchical
    tissue attributes [[31](#bib.bib31)], the interpretability can reveal crucial
    entities such as nuclei, tissue parts and interactions which can mimic the pathologist’s
    assessment and therefore, increase the level of trust between experts and AI frameworks.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数纳入解释器的方法仅限于细胞图分析。考虑到病理上对齐的多层次分层组织属性[[31](#bib.bib31)]，可解释性可以揭示重要实体，如细胞核、组织部分和相互作用，这些可以模拟病理学家的评估，从而增加专家与AI框架之间的信任度。
- en: Existing works however lack the definition of objectives to validate a model
    in terms of effective explainability, and only a single work has looked at the
    quality and utility of the proposed explanation methods for the intended audience
    (i.e. clinicians). In [[33](#bib.bib33)], the authors evaluated several graph
    explainers (GNNExplainer, GraphGrad-CAM, GraphGrad-CAM++, GraphLRP) to provide
    domain-understandable quantitative metrics based on pathologically measurable
    cellular properties, to make graph decisions understandable to pathologists. The
    authors found that at the concept-level, GraphGrad-CAM++ has the highest overall
    agreement with the pathologists, followed by GraphGrad-CAM and GNNExplainer.
  id: totrans-351
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，现有的研究缺乏定义有效可解释性模型的目标，只有一项工作研究了为目标受众（即临床医生）提出的解释方法的质量和效用。在[[33](#bib.bib33)]中，作者评估了几种图解释器（GNNExplainer、GraphGrad-CAM、GraphGrad-CAM++、GraphLRP），以基于病理上可测量的细胞属性提供领域可理解的定量指标，使图决策对病理学家易于理解。作者发现，在概念层面上，GraphGrad-CAM++与病理学家的整体一致性最高，其次是GraphGrad-CAM和GNNExplainer。
- en: 'Other methods not investigated in this survey that focus on instance-level
    interpretation of deep graph models that deserve attention in digital pathology
    for explainability at the node, edge, or node feature levels are: excitation BP [[83](#bib.bib83)],
    PGM-explainer [[147](#bib.bib147)], GraphMask [[148](#bib.bib148)], Graphlime [[149](#bib.bib149)],
    and Relex [[150](#bib.bib150)]. Other methods such as SubgraphX [[151](#bib.bib151)]
    provide subgraph-level explanations which may be more intuitive and human-intelligible
    for digital pathology.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查中未探讨的其他方法包括：excitation BP [[83](#bib.bib83)]、PGM-explainer [[147](#bib.bib147)]、GraphMask [[148](#bib.bib148)]、Graphlime [[149](#bib.bib149)]
    和 Relex [[150](#bib.bib150)]，这些方法专注于深度图模型的实例级解释，并值得在数字病理学中关注，用于节点、边或节点特征级别的可解释性。其他方法如SubgraphX [[151](#bib.bib151)]提供了子图级解释，这可能对数字病理学更具直观性和易于理解。
- en: Knowing the subset of features from which the model outcome is derived is critical.
    This allows clinicians to compare model decisions with clinical judgement, which
    is especially useful when there is a discrepancy. It is also worth noting that
    clinicians expect variation in the importance of inputs to exist both across patients
    and populations [[145](#bib.bib145)]. However, the explanations provided by methods
    discussed in this survey using gradient-based (GraphGrad-CAM) and perturbation-based
    methods (GNNExplainer) are limited to single instances. To verify and understand
    a deep model, pathologists need to check explanations for all input graphs, which
    is time-consuming and impractical. Models that interpret each instance independently,
    as previously stated, are insufficient to provide a global understanding of the
    trained model [[152](#bib.bib152)]. Thus, methods to provide GNN predictions on
    a group of instances collectively (i.e. a population) and provide a global understanding
    of GNN predictions is less explored in the literature.
  id: totrans-353
  prefs: []
  type: TYPE_NORMAL
  zh: 了解模型结果所依据的特征子集至关重要。这使临床医生能够将模型决策与临床判断进行比较，特别是在存在差异时尤为有用。还值得注意的是，临床医生期望输入的重要性在患者和人群之间存在差异 [[145](#bib.bib145)]。然而，本调查中讨论的方法提供的解释仅限于单一实例，这些方法使用基于梯度的方法（GraphGrad-CAM）和基于扰动的方法（GNNExplainer）。为了验证和理解深度模型，病理学家需要检查所有输入图的解释，这既费时又不切实际。正如之前所述，单独解释每个实例的方法不足以提供对训练模型的全局理解 [[152](#bib.bib152)]。因此，提供GNN对一组实例（即人群）的预测并提供GNN预测的全局理解的方法在文献中探索较少。
- en: Instance-level methods explain GNNs with respect to each input graph, whereas
    model-level methods explain GNNs without regard for any specific input example.
    The latter specifically investigates what input graph patterns can lead to a specific
    GNN behaviour, such as maximising a target prediction. However, no research on
    interpreting GNNs at the model-level exists in digital pathology. XGNN [[153](#bib.bib153)]
    provides model-level explanations by training a graph generator to build graph
    patterns that optimize a specific model prediction. The authors formulated graph
    creation as a reinforcement learning problem, with the graph generator predicting
    how to add an edge to a given graph and build a new graph at each step. The generator
    is then trained using a policy gradient based on feedback from the trained graph
    models. Several graph rules are also used to ensure that the explanations are
    both valid and human-readable. PGExplainer [[154](#bib.bib154)] can also provide
    an explanation for each instance with a global view of the GNN model by incorporating
    a generative probabilistic model. Nonetheless, it is unknown whether XGNN and
    PGExplainer can be used to perform node classification tasks for histopathology
    analysis, which is an important area for future research.
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 实例级方法根据每个输入图解释GNN，而模型级方法则不考虑任何特定输入示例来解释GNN。后者特别研究了哪些输入图模式可以导致特定的GNN行为，例如最大化目标预测。然而，数字病理学中尚无关于模型级GNN解释的研究。XGNN [[153](#bib.bib153)]
    通过训练图生成器来构建优化特定模型预测的图模式，从而提供模型级解释。作者将图创建表述为强化学习问题，通过图生成器预测如何在给定图上添加边，并在每一步构建新图。然后，使用基于训练图模型反馈的策略梯度来训练生成器。还使用了若干图规则，以确保解释既有效又易于理解。PGExplainer [[154](#bib.bib154)]
    也可以通过结合生成概率模型为每个实例提供全局视角的解释。然而，目前尚不清楚XGNN和PGExplainer是否可以用于进行组织病理分析的节点分类任务，这是未来研究的重要领域。
- en: Given the trend of graph-based processing for a variety of applications in computational
    pathology, graph explainability and quantitative evaluation with a focus on clinician
    usability are critical. Interpretability is essential because it can aid, for
    example, in informed decision-making during cancer diagnosis and treatment planning.
    However, interpretability of GNNs within digital pathology has received insufficient
    attention to date.
  id: totrans-355
  prefs: []
  type: TYPE_NORMAL
  zh: 鉴于图基处理在计算病理学中各种应用的趋势，图解释性和以临床医生可用性为重点的定量评估至关重要。可解释性是必不可少的，因为它可以帮助，例如，在癌症诊断和治疗计划中的知情决策。然而，目前为止，数字病理学中GNNs的可解释性尚未受到足够关注。
- en: V Conclusion
  id: totrans-356
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 结论
- en: Through the use of whole-slide images (WSIs) and tissue microarrays (TMAs),
    digital pathology has transformed pathology diagnosis. The growing use of this
    data has also given rise to a new field of study known as computational pathology,
    which aims to develop machine learning techniques to provide more objective and
    reproducible results. Deep learning, in particular Convolutional Neural Networks
    (CNNs), have demonstrated efficacy in visual representation learning in digital
    pathology. To obtain image-level representations, mainstream CNN architectures
    typically aggregate feature representations over fixed-sized patches of the WSI.
    However, the patch-wise and pixel-based processing used by CNNs lacks the ability
    to capture global contextual information relating to meaningful entities such
    as cells, glands, and tissue types. As demonstrated throughout this review, histopathology
    knowledge graphs enable the capture of more comprehensive and interpretable information
    relating to the underlying mechanisms of a disease. Several works have attempted
    to adopt graph-based deep learning models to learn both local and global patterns.
    Entity-based analysis has the potential to improve the interpretability of deep
    learning techniques by identifying decisive nuclei, tissue regions and interactions.
    This can also potentially replicate holistic and context aware parts of a pathologist’s
    assessment.
  id: totrans-357
  prefs: []
  type: TYPE_NORMAL
  zh: 通过使用全切片图像（WSIs）和组织微阵列（TMAs），数字病理学已转变了病理诊断。这些数据的日益使用也催生了一个新的研究领域，称为计算病理学，其旨在开发机器学习技术以提供更客观和可重复的结果。深度学习，特别是卷积神经网络（CNNs），在数字病理学中的视觉表示学习中表现出了有效性。为了获得图像级别的表示，主流的CNN架构通常在固定大小的WSI补丁上汇总特征表示。然而，CNNs使用的补丁级和像素级处理缺乏捕捉与细胞、腺体和组织类型等有意义实体相关的全局上下文信息的能力。正如本综述所示，组织病理学知识图谱能够捕捉与疾病潜在机制相关的更全面和可解释的信息。一些研究尝试采用基于图的深度学习模型来学习局部和全局模式。基于实体的分析有潜力通过识别决定性的细胞核、组织区域和相互作用来提高深度学习技术的可解释性。这也可能潜在地复制病理学家评估的整体和上下文感知部分。
- en: Our survey has provided a detailed overview of a new rapidly growing field of
    representation learning for computational histopathology. The enriched graph representation
    and learning in digital pathology has resulted in superior performance for diverse
    types of cancer analysis. Nevertheless, we highlight open research directions
    concerning the adoption of graph-based deep learning, including the explainability
    of graph representation learning, methods of graph construction, and the complexity
    of graph models and their limited training efficiency.
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 我们的调查提供了对计算组织病理学中快速增长的新兴领域的详细概述。数字病理中的丰富图表示和学习在各种癌症分析中带来了卓越的表现。然而，我们强调了关于图基深度学习的开放研究方向，包括图表示学习的可解释性、图构建的方法以及图模型的复杂性和其有限的训练效率。
- en: VI Conflict of interest statement
  id: totrans-359
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 利益冲突声明
- en: The authors report no conflicts of interest.
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 作者报告没有利益冲突。
- en: References
  id: totrans-361
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] S. Deng, X. Zhang, W. Yan, I. Eric, C. Chang, Y. Fan, M. Lai, and Y. Xu,
    “Deep learning in digital pathology image analysis: a survey,” *Front. Med.*,
    pp. 1–18, 2020.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] S. Deng, X. Zhang, W. Yan, I. Eric, C. Chang, Y. Fan, M. Lai, 和 Y. Xu，“数字病理图像分析中的深度学习：综述，”
    *Front. Med.*，第1–18页，2020年。'
- en: '[2] D. Shen, G. Wu, and H.-I. Suk, “Deep learning in medical image analysis,”
    *Annu. Rev.Biomed. Eng.*, vol. 19, pp. 221–248, 2017.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] D. Shen, G. Wu, 和 H.-I. Suk，“医学图像分析中的深度学习，” *Annu. Rev.Biomed. Eng.*，第19卷，第221–248页，2017年。'
- en: '[3] J. van der Laak, G. Litjens, and F. Ciompi, “Deep learning in histopathology:
    the path to the clinic,” *Nat. Med.*, vol. 27, no. 5, pp. 775–784, 2021.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] J. van der Laak, G. Litjens, 和 F. Ciompi，“组织病理学中的深度学习：通向临床的路径，” *Nat. Med.*，第27卷，第5期，第775–784页，2021年。'
- en: '[4] C. L. Srinidhi, O. Ciga, and A. L. Martel, “Deep neural network models
    for computational histopathology: A survey,” *Med. Image Anal.*, p. 101813, 2020.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] C. L. Srinidhi, O. Ciga, 和 A. L. Martel, “用于计算组织病理学的深度神经网络模型：综述，” *医学影像分析*，页101813，2020年。'
- en: '[5] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, and C. I. Sánchez, “A survey on deep learning
    in medical image analysis,” *Med. Image Anal.*, vol. 42, pp. 60–88, 2017.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] G. Litjens, T. Kooi, B. E. Bejnordi, A. A. A. Setio, F. Ciompi, M. Ghafoorian,
    J. A. Van Der Laak, B. Van Ginneken, 和 C. I. Sánchez, “医学图像分析中的深度学习综述，” *医学影像分析*，第42卷，页60–88，2017年。'
- en: '[6] F. Xing, Y. Xie, H. Su, F. Liu, and L. Yang, “Deep learning in microscopy
    image analysis: A survey,” *IEEE Trans. Neural Netw. Learn. Syst.*, vol. 29, no. 10,
    pp. 4550–4568, 2017.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] F. Xing, Y. Xie, H. Su, F. Liu, 和 L. Yang, “显微镜图像分析中的深度学习：综述，” *IEEE神经网络与学习系统汇刊*，第29卷，第10期，页4550–4568，2017年。'
- en: '[7] Y. He, H. Zhao, and S. T. Wong, “Deep learning powers cancer diagnosis
    in digital pathology,” *Comput. Med. Imaging Graph.*, p. 101820, 2020.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] Y. He, H. Zhao, 和 S. T. Wong, “深度学习推动数字病理中的癌症诊断，” *计算机医学影像图形*，页101820，2020年。'
- en: '[8] M. Amgad, L. A. Atteya, H. Hussein, K. H. Mohammed, E. Hafiz, M. A. Elsebaie,
    A. M. Alhusseiny, M. A. AlMoslemany, A. M. Elmatboly, P. A. Pappalardo *et al.*,
    “Nucls: A scalable crowdsourcing, deep learning approach and dataset for nucleus
    classification, localization and segmentation,” *arXiv preprint arXiv:2102.09099*,
    2021.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] M. Amgad, L. A. Atteya, H. Hussein, K. H. Mohammed, E. Hafiz, M. A. Elsebaie,
    A. M. Alhusseiny, M. A. AlMoslemany, A. M. Elmatboly, P. A. Pappalardo *等*，“Nucls：一种可扩展的众包深度学习方法和用于细胞核分类、定位和分割的数据集，”
    *arXiv预印本 arXiv:2102.09099*，2021年。'
- en: '[9] G. Aresta, T. Araújo, S. Kwok, S. S. Chennamsetty, M. Safwan, V. Alex,
    B. Marami, M. Prastawa, M. Chan, M. Donovan *et al.*, “Bach: Grand challenge on
    breast cancer histology images,” *Med. Image Anal.*, vol. 56, pp. 122–139, 2019.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] G. Aresta, T. Araújo, S. Kwok, S. S. Chennamsetty, M. Safwan, V. Alex,
    B. Marami, M. Prastawa, M. Chan, M. Donovan *等*，“Bach：乳腺癌组织学图像的重大挑战，” *医学影像分析*，第56卷，页122–139，2019年。'
- en: '[10] N. Kumar, R. Verma, D. Anand, Y. Zhou, O. F. Onder, E. Tsougenis, H. Chen,
    P.-A. Heng, J. Li, Z. Hu *et al.*, “A multi-organ nucleus segmentation challenge,”
    *IEEE Trans. Med. Imaging*, vol. 39, no. 5, pp. 1380–1391, 2019.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] N. Kumar, R. Verma, D. Anand, Y. Zhou, O. F. Onder, E. Tsougenis, H. Chen,
    P.-A. Heng, J. Li, Z. Hu *等*，“多脏器细胞核分割挑战赛，” *IEEE医学影像汇刊*，第39卷，第5期，页1380–1391，2019年。'
- en: '[11] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and S. Y. Philip, “A comprehensive
    survey on graph neural networks,” *IEEE Trans. Neural Netw. Learn. Syst.*, 2020.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, 和 S. Y. Philip, “图神经网络的全面调查，”
    *IEEE神经网络与学习系统汇刊*，2020年。'
- en: '[12] S. Qi, W. Wang, B. Jia, J. Shen, and S.-C. Zhu, “Learning human-object
    interactions by graph parsing neural networks,” in *Proc. Eur. Conf. Comput. Vis.
    (ECCV)*, 2018, pp. 401–417.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] S. Qi, W. Wang, B. Jia, J. Shen, 和 S.-C. Zhu, “通过图解析神经网络学习人类-物体交互，” 见于
    *欧洲计算机视觉会议（ECCV）*，2018年，页401–417。'
- en: '[13] Y. Chen, M. Rohrbach, Z. Yan, Y. Shuicheng, J. Feng, and Y. Kalantidis,
    “Graph-based global reasoning networks,” in *Proc. IEEE Conf. Comput. Vis. Pattern
    Recog. (CVPR)*, 2019, pp. 433–442.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] Y. Chen, M. Rohrbach, Z. Yan, Y. Shuicheng, J. Feng, 和 Y. Kalantidis,
    “基于图的全局推理网络，” 见于 *IEEE计算机视觉与模式识别会议（CVPR）*，2019年，页433–442。'
- en: '[14] J. Li, X. Xie, Z. Zhao, Y. Cao, Q. Pan, and G. Shi, “Temporal graph modeling
    for skeleton-based action recognition,” *arXiv preprint arXiv:2012.08804*, 2020.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] J. Li, X. Xie, Z. Zhao, Y. Cao, Q. Pan, 和 G. Shi, “基于时间图的骨架动作识别建模，” *arXiv预印本
    arXiv:2012.08804*，2020年。'
- en: '[15] J. Wang, R. J. Chen, M. Y. Lu, A. Baras, and F. Mahmood, “Weakly supervised
    prostate tma classification via graph convolutional networks,” in *Proc. IEEE
    Int. Symp. Biomed. Imaging (ISBI)*, 2020, pp. 239–243.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] J. Wang, R. J. Chen, M. Y. Lu, A. Baras, 和 F. Mahmood, “通过图卷积网络的弱监督前列腺TMA分类，”
    见于 *IEEE国际生物医学影像会议（ISBI）*，2020年，页239–243。'
- en: '[16] J. Levy, C. Haudenschild, C. Bar, B. Christensen, and L. Vaickus, “Topological
    feature extraction and visualization of whole slide images using graph neural
    networks,” in *Proc. Pac. Symp. Biocomput. (PSB)*, vol. 26, 2021, pp. 285–296.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] J. Levy, C. Haudenschild, C. Bar, B. Christensen, 和 L. Vaickus, “使用图神经网络的全切片图像的拓扑特征提取和可视化，”
    见于 *太平洋生物计算研讨会（PSB）*，第26卷，2021年，页285–296。'
- en: '[17] P. Pati, G. Jaume, L. A. Fernandes, A. Foncubierta-Rodríguez, F. Feroce,
    A. M. Anniciello, G. Scognamiglio, N. Brancati, D. Riccio, M. Di Bonito *et al.*,
    “Hact-net: A hierarchical cell-to-tissue graph neural network for histopathological
    image classification,” in *UNSURE and GRAIL in conjunction with MICCAI*, 2020,
    pp. 208–219.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] P. Pati, G. Jaume, L. A. Fernandes, A. Foncubierta-Rodríguez, F. Feroce,
    A. M. Anniciello, G. Scognamiglio, N. Brancati, D. Riccio, M. Di Bonito *等*，“Hact-net：一种用于组织病理图像分类的层次细胞到组织图神经网络”，发表于
    *UNSURE 和 GRAIL 与 MICCAI 联合举办*，2020年，第208–219页。'
- en: '[18] I. Makarov, D. Kiselev, N. Nikitinsky, and L. Subelj, “Survey on graph
    embeddings and their applications to machine learning problems on graphs,” *PeerJ
    Comput. Sci.*, vol. 7, 2021.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] I. Makarov, D. Kiselev, N. Nikitinsky, 和 L. Subelj，“关于图嵌入及其在图上的机器学习问题中的应用的综述”，*PeerJ
    Comput. Sci.*，第7卷，2021年。'
- en: '[19] S. Georgousis, M. Kenning, and X. Xie, “Graph deep learning: State of
    the art and challenges,” *IEEE Access*, 2021.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] S. Georgousis, M. Kenning, 和 X. Xie，“图深度学习：现状与挑战”，*IEEE Access*，2021年。'
- en: '[20] Z. Zhang, P. Cui, and W. Zhu, “Deep learning on graphs: A survey,” *IEEE
    Trans. Knowl. Data Eng.*, 2020.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Z. Zhang, P. Cui, 和 W. Zhu，“图上的深度学习：综述”，*IEEE Trans. Knowl. Data Eng.*，2020年。'
- en: '[21] D. Ahmedt-Aristizabal, M. A. Armin, S. Denman, C. Fookes, and L. Petersson,
    “Graph-based deep learning for medical diagnosis and analysis: Past, present and
    future,” *Sensors*, vol. 21, no. 14, 2021.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] D. Ahmedt-Aristizabal, M. A. Armin, S. Denman, C. Fookes, 和 L. Petersson，
    “基于图的深度学习用于医学诊断与分析：过去、现在和未来”，*Sensors*，第21卷，第14期，2021年。'
- en: '[22] H. Sharma, N. Zerbe, S. Lohmann, K. Kayser, O. Hellwich, and P. Hufnagl,
    “A review of graph-based methods for image analysis in digital histopathology,”
    *Diagnostic Pathol.*, vol. 1, no. 1, 2015.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] H. Sharma, N. Zerbe, S. Lohmann, K. Kayser, O. Hellwich, 和 P. Hufnagl，“基于图的方法在数字组织病理学图像分析中的回顾”，*Diagnostic
    Pathol.*，第1卷，第1期，2015年。'
- en: '[23] H. Irshad, A. Veillard, L. Roux, and D. Racoceanu, “Methods for nuclei
    detection, segmentation, and classification in digital histopathology: a review—current
    status and future potential,” *IEEE Rev. Biomed. Eng.*, vol. 7, pp. 97–114, 2013.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] H. Irshad, A. Veillard, L. Roux, 和 D. Racoceanu，“数字组织病理学中细胞核检测、分割和分类的方法：回顾—现状与未来潜力”，*IEEE
    Rev. Biomed. Eng.*，第7卷，第97–114页，2013年。'
- en: '[24] M. M. Li, K. Huang, and M. Zitnik, “Representation learning for networks
    in biology and medicine: Advancements, challenges, and opportunities,” *arXiv
    preprint arXiv:2104.04883*, 2021.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] M. M. Li, K. Huang, 和 M. Zitnik，“生物学和医学中网络的表示学习：进展、挑战和机遇”，*arXiv 预印本 arXiv:2104.04883*，2021年。'
- en: '[25] J. Shi, R. Wang, Y. Zheng, Z. Jiang, and L. Yu, “Graph convolutional networks
    for cervical cell classification,” in *Proc. Med. Image Comput. Comput.-Assist.
    Interv. (MICCAI)*, 2019.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] J. Shi, R. Wang, Y. Zheng, Z. Jiang, 和 L. Yu，“用于宫颈细胞分类的图卷积网络”，发表于 *Proc.
    Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*，2019年。'
- en: '[26] B. Aygüneş, S. Aksoy, R. G. Cinbiş, K. Kösemehmetoğlu, S. Önder, and A. Üner,
    “Graph convolutional networks for region of interest classification in breast
    histopathology,” in *Med. Imaging 2020: Digit. Pathol.*, vol. 11320, 2020, p.
    113200K.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] B. Aygüneş, S. Aksoy, R. G. Cinbiş, K. Kösemehmetoğlu, S. Önder, 和 A.
    Üner，“用于乳腺组织病理学中的感兴趣区域分类的图卷积网络”，发表于 *Med. Imaging 2020: Digit. Pathol.*，第11320卷，2020年，第113200K页。'
- en: '[27] A. Raju, J. Yao, M. M. Haq, J. Jonnagaddala, and J. Huang, “Graph attention
    multi-instance learning for accurate colorectal cancer staging,” in *Proc. Med.
    Image Comput. Comput.-Assist. Interv. (MICCAI)*, 2020, pp. 529–539.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] A. Raju, J. Yao, M. M. Haq, J. Jonnagaddala, 和 J. Huang，“图注意力多实例学习用于准确的结直肠癌分期”，发表于
    *Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*，2020年，第529–539页。'
- en: '[28] D. Anand, S. Gadiya, and A. Sethi, “Histographs: graphs in histopathology,”
    in *Med. Imaging 2020: Digit. Pathol.*, vol. 11320, 2020, p. 113200O.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] D. Anand, S. Gadiya, 和 A. Sethi，“Histographs：组织病理学中的图”，发表于 *Med. Imaging
    2020: Digit. Pathol.*，第11320卷，2020年，第113200O页。'
- en: '[29] M. Zhang and Q. Li, “Ms-gwnn: multi-scale graph wavelet neural network
    for breast cancer diagnosis,” *arXiv preprint arXiv:2012.14619*, 2020.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] M. Zhang 和 Q. Li，“Ms-gwnn：用于乳腺癌诊断的多尺度图小波神经网络”，*arXiv 预印本 arXiv:2012.14619*，2020年。'
- en: '[30] M. Sureka, A. Patil, D. Anand, and A. Sethi, “Visualization for histopathology
    images using graph convolutional neural networks,” in *Proc. IEEE Int. Conf. Bioinform.
    BioEng. (BIBE)*, 2020, pp. 331–335.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] M. Sureka, A. Patil, D. Anand, 和 A. Sethi，“使用图卷积神经网络进行组织病理图像的可视化”，发表于
    *Proc. IEEE Int. Conf. Bioinform. BioEng. (BIBE)*，2020年，第331–335页。'
- en: '[31] P. Pati, G. Jaume, A. Foncubierta, F. Feroce, A. M. Anniciello, G. Scognamiglio,
    N. Brancati, M. Fiche, E. Dubruc, D. Riccio *et al.*, “Hierarchical cell-to-tissue
    graph representations for breast cancer subtyping in digital pathology,” *arXiv
    preprint arXiv:2102.11057*, 2021.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] P. Pati, G. Jaume, A. Foncubierta, F. Feroce, A. M. Anniciello, G. Scognamiglio,
    N. Brancati, M. Fiche, E. Dubruc, D. Riccio *等*，“用于乳腺癌亚型分类的层次化细胞-组织图表示在数字病理学中的应用，”*arXiv预印本
    arXiv:2102.11057*，2021年。'
- en: '[32] R. J. Chen, M. Y. Lu, J. Wang, D. F. Williamson, S. J. Rodig, N. I. Lindeman,
    and F. Mahmood, “Pathomic fusion: an integrated framework for fusing histopathology
    and genomic features for cancer diagnosis and prognosis,” *IEEE Trans. Med. Imaging*,
    2020.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] R. J. Chen, M. Y. Lu, J. Wang, D. F. Williamson, S. J. Rodig, N. I. Lindeman,
    和 F. Mahmood，“Pathomic fusion：融合组织病理学和基因组特征的癌症诊断和预后集成框架，”*IEEE医学成像汇刊*，2020年。'
- en: '[33] G. Jaume, P. Pati, B. Bozorgtabar, A. Foncubierta, A. M. Anniciello, F. Feroce,
    T. Rau, J.-P. Thiran, M. Gabrani, and O. Goksel, “Quantifying explainers of graph
    neural networks in computational pathology,” in *Proc. IEEE Conf. Comput. Vis.
    Pattern Recog. (CVPR)*, 2021, pp. 8106–8116.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] G. Jaume, P. Pati, B. Bozorgtabar, A. Foncubierta, A. M. Anniciello, F.
    Feroce, T. Rau, J.-P. Thiran, M. Gabrani, 和 O. Goksel，“计算病理学中图神经网络的解释量化，”见于*IEEE计算机视觉与模式识别会议（CVPR）*，2021年，第8106–8116页。'
- en: '[34] G. Jaume, P. Pati, A. Foncubierta-Rodriguez, F. Feroce, G. Scognamiglio,
    A. M. Anniciello, J.-P. Thiran, O. Goksel, and M. Gabrani, “Towards explainable
    graph representations in digital pathology,” in *Proc. Int. Conf. Mach. Learn.
    (ICML) Workshop CompBio*, 2020, pp. 5453–5462.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] G. Jaume, P. Pati, A. Foncubierta-Rodriguez, F. Feroce, G. Scognamiglio,
    A. M. Anniciello, J.-P. Thiran, O. Goksel, 和 M. Gabrani，“迈向可解释的图表示在数字病理学中的应用，”见于*国际机器学习会议（ICML）生物计算研讨会*，2020年，第5453–5462页。'
- en: '[35] Y. Ozen, S. Aksoy, K. Kösemehmetoğlu, S. Önder, and A. Üner, “Self-supervised
    learning with graph neural networks for region of interest retrieval in histopathology,”
    in *Proc. Int. Conf. Pattern. Recogn. (ICPR)*, 2021, pp. 6329–6334.'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Y. Ozen, S. Aksoy, K. Kösemehmetoğlu, S. Önder, 和 A. Üner，“用于组织病理学中感兴趣区域检索的自监督学习图神经网络，”见于*国际模式识别会议（ICPR）*，2021年，第6329–6334页。'
- en: '[36] W. Lu, S. Graham, M. Bilal, N. Rajpoot, and F. Minhas, “Capturing cellular
    topology in multi-gigapixel pathology images,” in *Proc. IEEE Conf. Comput. Vis.
    Pattern Recog. (CVPR)*, 2020, pp. 260–261.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] W. Lu, S. Graham, M. Bilal, N. Rajpoot, 和 F. Minhas，“在多千兆像素病理图像中捕获细胞拓扑结构，”见于*IEEE计算机视觉与模式识别会议（CVPR）*，2020年，第260–261页。'
- en: '[37] H. Ye, D.-H. Wang, J. Li, S. Zhu, and C. Zhu, “Improving histopathological
    image segmentation and classification using graph convolution network,” in *Proc.
    Int. Conf. Comput. Pattern Recog. (ICCPR)*, 2019, pp. 192–198.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] H. Ye, D.-H. Wang, J. Li, S. Zhu, 和 C. Zhu，“使用图卷积网络改进组织病理图像的分割和分类，”见于*国际计算模式识别会议（ICCPR）*，2019年，第192–198页。'
- en: '[38] L. Studer, J. Wallau, H. Dawson, I. Zlobec, and A. Fischer, “Classification
    of intestinal gland cell-graphs using graph neural networks,” in *Proc. Int. Conf.
    Pattern. Recogn. (ICPR)*, 2021, pp. 3636–3643.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] L. Studer, J. Wallau, H. Dawson, I. Zlobec, 和 A. Fischer，“使用图神经网络分类肠腺细胞图，”见于*国际模式识别会议（ICPR）*，2021年，第3636–3643页。'
- en: '[39] Y. Zhou, S. Graham, N. Alemi Koohbanani, M. Shaban, P.-A. Heng, and N. Rajpoot,
    “Cgc-net: Cell graph convolutional network for grading of colorectal cancer histology
    images,” in *Proc. IEEE Int. Conf. Comput. Vis. (ICCV)*, 2019, pp. 0–0.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Y. Zhou, S. Graham, N. Alemi Koohbanani, M. Shaban, P.-A. Heng, 和 N. Rajpoot，“Cgc-net：用于结直肠癌组织学图像分级的细胞图卷积网络，”见于*IEEE国际计算机视觉会议（ICCV）*，2019年，第0–0页。'
- en: '[40] Y. Zhao, F. Yang, Y. Fang, H. Liu, N. Zhou, J. Zhang, J. Sun, S. Yang,
    B. Menze, X. Fan *et al.*, “Predicting lymph node metastasis using histopathological
    images based on multiple instance learning with deep graph convolution,” in *Proc.
    IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*, 2020, pp. 4837–4846.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Y. Zhao, F. Yang, Y. Fang, H. Liu, N. Zhou, J. Zhang, J. Sun, S. Yang,
    B. Menze, X. Fan *等*，“基于深度图卷积的多实例学习预测淋巴结转移，”见于*IEEE计算机视觉与模式识别会议（CVPR）*，2020年，第4837–4846页。'
- en: '[41] K. Ding, Q. Liu, E. Lee, M. Zhou, A. Lu, and S. Zhang, “Feature-enhanced
    graph networks for genetic mutational prediction using histopathological images
    in colon cancer,” in *Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*,
    2020, pp. 294–304.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] K. Ding, Q. Liu, E. Lee, M. Zhou, A. Lu, 和 S. Zhang，“基于特征增强图网络的遗传突变预测在结肠癌组织病理图像中的应用，”见于*医学图像计算与计算机辅助手术会议（MICCAI）*，2020年，第294–304页。'
- en: '[42] V. Anklin, P. Pati, G. Jaume, B. Bozorgtabar, A. Foncubierta-Rodríguez,
    J.-P. Thiran, M. Sibony, M. Gabrani, and O. Goksel, “Learning whole-slide segmentation
    from inexact and incomplete labels using tissue graphs,” *arXiv preprint arXiv:2103.03129*,
    2021.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] V. Anklin, P. Pati, G. Jaume, B. Bozorgtabar, A. Foncubierta-Rodríguez,
    J.-P. Thiran, M. Sibony, M. Gabrani, 和 O. Goksel，“使用组织图从不准确和不完整的标签中学习全切片分割，” *arXiv预印本
    arXiv:2103.03129*，2021年。'
- en: '[43] M. Adnan, S. Kalra, and H. R. Tizhoosh, “Representation learning of histopathology
    images using graph neural networks,” in *Proc. IEEE Conf. Comput. Vis. Pattern
    Recog. (CVPR)*, 2020, pp. 988–989.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] M. Adnan, S. Kalra, 和 H. R. Tizhoosh，“使用图神经网络对组织病理图像进行表示学习，” 在 *IEEE计算机视觉与模式识别会议（CVPR）*，2020年，第988–989页。'
- en: '[44] Y. Zheng, B. Jiang, J. Shi, H. Zhang, and F. Xie, “Encoding histopathological
    wsis using gnn for scalable diagnostically relevant regions retrieval,” in *Proc.
    Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*, 2019, pp. 550–558.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] Y. Zheng, B. Jiang, J. Shi, H. Zhang, 和 F. Xie，“使用GNN对组织病理学WSI进行编码，以便可扩展的诊断相关区域检索，”
    在 *医学图像计算与计算机辅助干预会议（MICCAI）*，2019年，第550–558页。'
- en: '[45] R. Li, J. Yao, X. Zhu, Y. Li, and J. Huang, “Graph cnn for survival analysis
    on whole slide pathological images,” in *Proc. Med. Image Comput. Comput.-Assist.
    Interv. (MICCAI)*, 2018, pp. 174–182.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] R. Li, J. Yao, X. Zhu, Y. Li, 和 J. Huang，“图CNN在全切片病理图像上的生存分析，” 在 *医学图像计算与计算机辅助干预会议（MICCAI）*，2018年，第174–182页。'
- en: '[46] J. Shi, R. Wang, Y. Zheng, Z. Jiang, H. Zhang, and L. Yu, “Cervical cell
    classification with graph convolutional network,” *Comput. Methods Programs Biomed.*,
    vol. 198, p. 105807, 2020.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] J. Shi, R. Wang, Y. Zheng, Z. Jiang, H. Zhang, 和 L. Yu，“基于图卷积网络的宫颈细胞分类，”
    *计算方法与程序生物医学*，第198卷，第105807页，2020年。'
- en: '[47] J. Wu, J.-X. Zhong, E. Z. Chen, J. Zhang, J. Y. Jay, and L. Yu, “Weakly-and
    semi-supervised graph cnn for identifying basal cell carcinoma on pathological
    images,” in *Proc. Int. Workshop Graph Learn. Med. Imaging (GLMI)*, 2019, pp.
    112–119.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] J. Wu, J.-X. Zhong, E. Z. Chen, J. Zhang, J. Y. Jay, 和 L. Yu，“用于识别病理图像中基底细胞癌的弱监督和半监督图CNN，”
    在 *国际图学习医学成像研讨会（GLMI）*，2019年，第112–119页。'
- en: '[48] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, and P. Vandergheynst,
    “The emerging field of signal processing on graphs: Extending high-dimensional
    data analysis to networks and other irregular domains,” *IEEE Signal Process.
    Mag.*, vol. 30, no. 3, pp. 83–98, 2013.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] D. I. Shuman, S. K. Narang, P. Frossard, A. Ortega, 和 P. Vandergheynst，“图上的信号处理新兴领域：将高维数据分析扩展到网络和其他不规则领域，”
    *IEEE信号处理杂志*，第30卷，第3期，第83–98页，2013年。'
- en: '[49] N. Otsu, “A threshold selection method from gray-level histograms,” *IEEE
    Trans. Syst. Man Cybern.*, vol. 9, no. 1, pp. 62–66, 1979.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] N. Otsu，“一种从灰度直方图中选择阈值的方法，” *IEEE系统、人机与控制汇刊*，第9卷，第1期，第62–66页，1979年。'
- en: '[50] S. Graham, Q. D. Vu, S. E. A. Raza, A. Azam, Y. W. Tsang, J. T. Kwak,
    and N. Rajpoot, “Hover-net: Simultaneous segmentation and classification of nuclei
    in multi-tissue histology images,” *Med. Image Anal.*, vol. 58, p. 101563, 2019.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] S. Graham, Q. D. Vu, S. E. A. Raza, A. Azam, Y. W. Tsang, J. T. Kwak,
    和 N. Rajpoot，“Hover-net：在多组织组织学图像中同时进行细胞核分割和分类，” *医学图像分析*，第58卷，第101563页，2019年。'
- en: '[51] Y. Zhou, O. F. Onder, Q. Dou, E. Tsougenis, H. Chen, and P.-A. Heng, “Cia-net:
    Robust nuclei instance segmentation with contour-aware information aggregation,”
    in *Proc. Int. Conf. Inf. Process. Med. Imaging (IPMI)*, 2019, pp. 682–693.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] Y. Zhou, O. F. Onder, Q. Dou, E. Tsougenis, H. Chen, 和 P.-A. Heng，“Cia-net：通过轮廓感知信息聚合进行鲁棒的细胞核实例分割，”
    在 *国际医学图像处理信息处理会议（IPMI）*，2019年，第682–693页。'
- en: '[52] O. Ronneberger, P. Fischer, and T. Brox, “U-net: Convolutional networks
    for biomedical image segmentation,” in *Proc. Med. Image Comput. Comput.-Assist.
    Interv. (MICCAI)*, 2015, pp. 234–241.'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] O. Ronneberger, P. Fischer, 和 T. Brox，“U-net：用于生物医学图像分割的卷积网络，” 在 *医学图像计算与计算机辅助干预会议（MICCAI）*，2015年，第234–241页。'
- en: '[53] F. Mahmood, D. Borders, R. J. Chen, G. N. McKay, K. J. Salimian, A. Baras,
    and N. J. Durr, “Deep adversarial training for multi-organ nuclei segmentation
    in histopathology images,” *IEEE Trans. Med. Imaging*, vol. 39, no. 11, pp. 3257–3267,
    2019.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] F. Mahmood, D. Borders, R. J. Chen, G. N. McKay, K. J. Salimian, A. Baras,
    和 N. J. Durr，“深度对抗训练用于组织病理图像中的多脏器细胞核分割，” *IEEE医学成像汇刊*，第39卷，第11期，第3257–3267页，2019年。'
- en: '[54] N. Kumar, R. Verma, S. Sharma, S. Bhargava, A. Vahadane, and A. Sethi,
    “A dataset and a technique for generalized nuclear segmentation for computational
    pathology,” *IEEE Trans. Med. Imaging*, vol. 36, no. 7, pp. 1550–1560, 2017.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] N. Kumar, R. Verma, S. Sharma, S. Bhargava, A. Vahadane, 和 A. Sethi，“用于计算病理学的广义核分割的数据集和技术，”
    *IEEE医学成像汇刊*，第36卷，第7期，第1550–1560页，2017年。'
- en: '[55] J. Gamper, N. A. Koohbanani, K. Benet, A. Khuram, and N. Rajpoot, “Pannuke:
    an open pan-cancer histology dataset for nuclei instance segmentation and classification,”
    in *Eur. Congr. Digit. Pathol.*, 2019, pp. 11–19.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] J. Gamper, N. A. Koohbanani, K. Benet, A. Khuram, 和 N. Rajpoot，“Pannuke:
    一个用于核实例分割和分类的开放式全癌症组织学数据集，”发表于 *Eur. Congr. Digit. Pathol.*, 2019年, 页 11–19。'
- en: '[56] D. Müllner, “Modern hierarchical, agglomerative clustering algorithms,”
    *arXiv preprint arXiv:1109.2378*, 2011.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] D. Müllner，“现代层次聚合聚类算法，” *arXiv preprint arXiv:1109.2378*, 2011年。'
- en: '[57] S. Kalra, H. R. Tizhoosh, C. Choi, S. Shah, P. Diamandis, C. J. Campbell,
    and L. Pantanowitz, “Yottixel–an image search engine for large archives of histopathology
    whole slide images,” *Med. Image Anal.*, vol. 65, p. 101757, 2020.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] S. Kalra, H. R. Tizhoosh, C. Choi, S. Shah, P. Diamandis, C. J. Campbell,
    和 L. Pantanowitz，“Yottixel——一个用于大型组织病理全切片图像档案的图像搜索引擎，” *Med. Image Anal.*, 卷 65,
    页 101757, 2020年。'
- en: '[58] J. N. Kather, N. Halama, and A. Marx, “100,000 histological images of
    human colorectal cancer and healthy tissue,” Apr. 2018\. [Online]. Available:
    https://doi.org/10.5281/zenodo.1214456'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] J. N. Kather, N. Halama, 和 A. Marx，“10万张人类结直肠癌及健康组织的组织学图像，”2018年4月。[在线].
    可用: https://doi.org/10.5281/zenodo.1214456'
- en: '[59] B. E. Bejnordi, G. Litjens, M. Hermsen, N. Karssemeijer, and J. A. van der
    Laak, “A multi-scale superpixel classification approach to the detection of regions
    of interest in whole slide histopathology images,” in *Med. Imaging 2015: Digit.
    Pathol.*, vol. 9420, 2015, p. 94200H.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] B. E. Bejnordi, G. Litjens, M. Hermsen, N. Karssemeijer, 和 J. A. van der
    Laak，“一种多尺度超像素分类方法用于检测全切片组织病理图像中的感兴趣区域，”发表于 *Med. Imaging 2015: Digit. Pathol.*,
    卷 9420, 2015年, 页 94200H。'
- en: '[60] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, and S. Süsstrunk, “Slic
    superpixels compared to state-of-the-art superpixel methods,” *IEEE Trans. Pattern
    Anal. Mach. Intell*, vol. 34, no. 11, pp. 2274–2282, 2012.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] R. Achanta, A. Shaji, K. Smith, A. Lucchi, P. Fua, 和 S. Süsstrunk，“Slic
    超像素与最先进超像素方法的比较，” *IEEE Trans. Pattern Anal. Mach. Intell*, 卷 34, 第 11 期, 页 2274–2282,
    2012年。'
- en: '[61] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
    recognition,” in *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*, 2016,
    pp. 770–778.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] K. He, X. Zhang, S. Ren, 和 J. Sun，“用于图像识别的深度残差学习，”发表于 *Proc. IEEE Conf.
    Comput. Vis. Pattern Recog. (CVPR)*, 2016年, 页 770–778。'
- en: '[62] F. K. Potjer, “Region adjacency graphs and connected morphological operators,”
    in *Math. Morphol. Appl. Image Signal Process.*, 1996, pp. 111–118.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] F. K. Potjer，“区域邻接图与连接形态学运算符，”发表于 *Math. Morphol. Appl. Image Signal Process.*,
    1996年, 页 111–118。'
- en: '[63] A. v. d. Oord, Y. Li, and O. Vinyals, “Representation learning with contrastive
    predictive coding,” *arXiv preprint arXiv:1807.03748*, 2018.'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] A. v. d. Oord, Y. Li, 和 O. Vinyals，“通过对比预测编码进行表征学习，” *arXiv preprint arXiv:1807.03748*,
    2018年。'
- en: '[64] H. Zhang, J. Xue, and K. Dana, “Deep ten: Texture encoding network,” in
    *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*, 2017, pp. 708–717.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] H. Zhang, J. Xue, 和 K. Dana，“Deep ten: 纹理编码网络，”发表于 *Proc. IEEE Conf. Comput.
    Vis. Pattern Recog. (CVPR)*, 2017年, 页 708–717。'
- en: '[65] D. P. Kingma and M. Welling, “Auto-encoding variational bayes,” *arXiv
    preprint arXiv:1312.6114*, 2013.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] D. P. Kingma 和 M. Welling，“自编码变分贝叶斯，” *arXiv preprint arXiv:1312.6114*,
    2013年。'
- en: '[66] M. Defferrard, X. Bresson, and P. Vandergheynst, “Convolutional neural
    networks on graphs with fast localized spectral filtering,” in *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*, 2016, pp. 3844–3852.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] M. Defferrard, X. Bresson, 和 P. Vandergheynst，“在图上使用快速局部谱滤波的卷积神经网络，”发表于
    *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*, 2016年, 页 3844–3852。'
- en: '[67] T. N. Kipf and M. Welling, “Semi-supervised classification with graph
    convolutional networks,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2017.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] T. N. Kipf 和 M. Welling，“基于图卷积网络的半监督分类，”发表于 *Proc. Int. Conf. Learn. Repr.
    (ICLR)*, 2017年。'
- en: '[68] W. Hamilton, Z. Ying, and J. Leskovec, “Inductive representation learning
    on large graphs,” in *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*, 2017, pp.
    1024–1034.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] W. Hamilton, Z. Ying, 和 J. Leskovec，“在大规模图上的归纳表征学习，”发表于 *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*, 2017年, 页 1024–1034。'
- en: '[69] J. Bruna, W. Zaremba, A. Szlam, and Y. LeCun, “Spectral networks and locally
    connected networks on graphs,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2014.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] J. Bruna, W. Zaremba, A. Szlam, 和 Y. LeCun，“图上的谱网络和局部连接网络，”发表于 *Proc.
    Int. Conf. Learn. Repr. (ICLR)*, 2014年。'
- en: '[70] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, and G. E. Dahl,
    “Neural message passing for quantum chemistry,” in *Proc. Int. Conf. Mach. Learn.
    (ICML)*, 2017, pp. 1263–1272.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] J. Gilmer, S. S. Schoenholz, P. F. Riley, O. Vinyals, 和 G. E. Dahl，“用于量子化学的神经消息传递，”发表于
    *Proc. Int. Conf. Mach. Learn. (ICML)*, 2017年, 页 1263–1272。'
- en: '[71] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, and I. Polosukhin, “Attention is all you need,” in *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*, 2017, pp. 5998–6008.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    Ł. Kaiser, 和 I. Polosukhin, “注意力机制就是你所需要的，”发表于 *先进神经信息处理系统会议（NeurIPS）*，2017年，第5998–6008页。'
- en: '[72] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio,
    “Graph attention networks,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2018.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, 和 Y. Bengio,
    “图注意力网络，”发表于 *国际学习表征会议（ICLR）*，2018年。'
- en: '[73] K. Xu, W. Hu, J. Leskovec, and S. Jegelka, “How powerful are graph neural
    networks?” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2019.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] K. Xu, W. Hu, J. Leskovec, 和 S. Jegelka, “图神经网络的强大程度如何？”发表于 *国际学习表征会议（ICLR）*，2019年。'
- en: '[74] L. Gong and Q. Cheng, “Exploiting edge features for graph neural networks,”
    in *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*, 2019, pp. 9211–9219.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] L. Gong 和 Q. Cheng, “利用边缘特征的图神经网络，”发表于 *IEEE计算机视觉与模式识别会议（CVPR）*，2019年，第9211–9219页。'
- en: '[75] F. P. Such, S. Sah, M. A. Dominguez, S. Pillai, C. Zhang, A. Michael,
    N. D. Cahill, and R. Ptucha, “Robust spatial filtering with graph convolutional
    neural networks,” *IEEE J. Sel. Top. Signal Process.*, vol. 11, no. 6, pp. 884–896,
    2017.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] F. P. Such, S. Sah, M. A. Dominguez, S. Pillai, C. Zhang, A. Michael,
    N. D. Cahill, 和 R. Ptucha, “使用图卷积神经网络的鲁棒空间滤波，” *IEEE选择性信号处理杂志*，第11卷，第6期，第884–896页，2017年。'
- en: '[76] K. Xu, C. Li, Y. Tian, T. Sonobe, K.-i. Kawarabayashi, and S. Jegelka,
    “Representation learning on graphs with jumping knowledge networks,” in *Proc.
    Int. Conf. Mach. Learn. (ICML)*, 2018, pp. 5453–5462.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] K. Xu, C. Li, Y. Tian, T. Sonobe, K.-i. Kawarabayashi, 和 S. Jegelka, “基于跳跃知识网络的图表示学习，”发表于
    *国际机器学习会议（ICML）*，2018年，第5453–5462页。'
- en: '[77] B. Xu, H. Shen, Q. Cao, Y. Qiu, and X. Cheng, “Spherical cnns on unstructured
    grids,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2019.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] B. Xu, H. Shen, Q. Cao, Y. Qiu, 和 X. Cheng, “在非结构化网格上的球形卷积神经网络，”发表于 *国际学习表征会议（ICLR）*，2019年。'
- en: '[78] Y. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, “Gated graph sequence
    neural networks,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2016.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Y. Li, D. Tarlow, M. Brockschmidt, 和 R. Zemel, “门控图序列神经网络，”发表于 *国际学习表征会议（ICLR）*，2016年。'
- en: '[79] R. Ying, J. You, C. Morris, X. Ren, W. L. Hamilton, and J. Leskovec, “Hierarchical
    graph representation learning with differentiable pooling,” in *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*, 2018.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] R. Ying, J. You, C. Morris, X. Ren, W. L. Hamilton, 和 J. Leskovec, “具有可微分池化的分层图表示学习，”发表于
    *先进神经信息处理系统会议（NeurIPS）*，2018年。'
- en: '[80] J. Lee, I. Lee, and J. Kang, “Self-attention graph pooling,” in *Proc.
    Int. Conf. Mach. Learn. (ICML)*.   PMLR, 2019, pp. 3734–3743.'
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] J. Lee, I. Lee, 和 J. Kang, “自注意力图池化，”发表于 *国际机器学习会议（ICML）*。PMLR, 2019年，第3734–3743页。'
- en: '[81] J. Arevalo, T. Solorio, M. Montes-y Gómez, and F. A. González, “Gated
    multimodal units for information fusion,” *arXiv preprint arXiv:1702.01992*, 2017.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] J. Arevalo, T. Solorio, M. Montes-y Gómez, 和 F. A. González, “用于信息融合的门控多模态单元，”
    *arXiv预印本 arXiv:1702.01992*，2017年。'
- en: '[82] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, “Hierarchical
    attention networks for document classification,” in *NAACL HLT*, 2016, pp. 1480–1489.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, 和 E. Hovy, “用于文档分类的分层注意力网络，”发表于
    *北美计算语言学协会高级会议（NAACL HLT）*，2016年，第1480–1489页。'
- en: '[83] P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, and H. Hoffmann, “Explainability
    methods for graph convolutional neural networks,” in *Proc. IEEE Conf. Comput.
    Vis. Pattern Recog. (CVPR)*, 2019, pp. 10 772–10 781.'
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] P. E. Pope, S. Kolouri, M. Rostami, C. E. Martin, 和 H. Hoffmann, “图卷积神经网络的可解释性方法，”发表于
    *IEEE计算机视觉与模式识别会议（CVPR）*，2019年，第10772–10781页。'
- en: '[84] R. Ying, D. Bourgeois, J. You, M. Zitnik, and J. Leskovec, “Gnnexplainer:
    Generating explanations for graph neural networks,” *Proc. Adv Neural Inf. Process.
    Syst (NeurIPS)*, vol. 32, p. 9240, 2019.'
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] R. Ying, D. Bourgeois, J. You, M. Zitnik, 和 J. Leskovec, “Gnnexplainer：生成图神经网络的解释，”
    *先进神经信息处理系统会议（NeurIPS）*，第32卷，第9240页，2019年。'
- en: '[85] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra,
    “Grad-cam: Visual explanations from deep networks via gradient-based localization,”
    in *Proc. IEEE Int. Conf. Comput. Vis. (ICCV)*, 2017, pp. 618–626.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] R. R. Selvaraju, M. Cogswell, A. Das, R. Vedantam, D. Parikh, 和 D. Batra,
    “Grad-cam：通过基于梯度的定位进行深度网络的可视化解释，”发表于 *IEEE国际计算机视觉会议（ICCV）*，2017年，第618–626页。'
- en: '[86] A. Chattopadhay, A. Sarkar, P. Howlader, and V. N. Balasubramanian, “Grad-cam++:
    Generalized gradient-based visual explanations for deep convolutional networks,”
    in *Proc. IEEE Winter Conf. Appl Comput. Vis. (WACV)*, 2018, pp. 839–847.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] A. Chattopadhay, A. Sarkar, P. Howlader, 和 V. N. Balasubramanian, “Grad-cam++：深度卷积网络的广义梯度可视化解释，”发表于
    *IEEE冬季计算机视觉应用会议（WACV）*，2018年，第839–847页。'
- en: '[87] R. Schwarzenberg, M. Hübner, D. Harbecke, C. Alt, and L. Hennig, “Layerwise
    relevance visualization in convolutional text graph classifiers,” in *Proc. Graph-based
    methods Nat. Lang. Process. (TextGraphs)*, 2019, pp. 58–62.'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] R. Schwarzenberg, M. Hübner, D. Harbecke, C. Alt, 和 L. Hennig，“卷积文本图分类器中的逐层相关性可视化，”
    见于 *Proc. Graph-based methods Nat. Lang. Process. (TextGraphs)*，2019年，第58–62页。'
- en: '[88] F. Baldassarre and H. Azizpour, “Explainability techniques for graph convolutional
    networks,” in *Proc. Int. Conf. Mach. Learn. (ICML)*, 2019.'
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] F. Baldassarre 和 H. Azizpour，“图卷积网络的可解释性技术，” 见于 *Proc. Int. Conf. Mach.
    Learn. (ICML)*，2019年。'
- en: '[89] C. Bodnar, C. Cangea, and P. Liò, “Deep graph mapper: Seeing graphs through
    the neural lens,” in *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*, 2020.'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] C. Bodnar, C. Cangea, 和 P. Liò，“深度图映射器：通过神经视角观察图，” 见于 *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*，2020年。'
- en: '[90] E. Arvaniti, K. S. Fricker, M. Moret, N. Rupp, T. Hermanns, C. Fankhauser,
    N. Wey, P. J. Wild, J. H. Rueschoff, and M. Claassen, “Automated gleason grading
    of prostate cancer tissue microarrays via deep learning,” *Sci. Rep.*, vol. 8,
    no. 1, pp. 1–11, 2018.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] E. Arvaniti, K. S. Fricker, M. Moret, N. Rupp, T. Hermanns, C. Fankhauser,
    N. Wey, P. J. Wild, J. H. Rueschoff, 和 M. Claassen，“通过深度学习对前列腺癌组织微阵列进行自动化 Gleason
    分级，” *Sci. Rep.*，第8卷，第1期，第1–11页，2018年。'
- en: '[91] L. Studer, S. Toneyan, I. Zlobec, H. Dawson, and A. Fischer, “Graph-based
    classification of intestinal glands in colorectal cancer tissue images,” in *Proc.
    Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*, 2019.'
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] L. Studer, S. Toneyan, I. Zlobec, H. Dawson, 和 A. Fischer，“基于图的结直肠癌组织图像中的肠腺分类，”
    见于 *Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*，2019年。'
- en: '[92] R. Awan, K. Sirinukunwattana, D. Epstein, S. Jefferyes, U. Qidwai, Z. Aftab,
    I. Mujeeb, D. Snead, and N. Rajpoot, “Glandular morphometrics for objective grading
    of colorectal adenocarcinoma histology images,” *Sci. Rep.*, vol. 7, no. 1, pp.
    1–12, 2017.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] R. Awan, K. Sirinukunwattana, D. Epstein, S. Jefferyes, U. Qidwai, Z. Aftab,
    I. Mujeeb, D. Snead, 和 N. Rajpoot，“用于客观评分结直肠腺癌组织学图像的腺体形态测量，” *Sci. Rep.*，第7卷，第1期，第1–12页，2017年。'
- en: '[93] Q. Zhong, T. Guo, M. Rechsteiner, J. H. Rüschoff, N. Rupp, C. Fankhauser,
    K. Saba, A. Mortezavi, C. Poyet, T. Hermanns *et al.*, “A curated collection of
    tissue microarray images and clinical outcome data of prostate cancer patients,”
    *Sci. Data*, vol. 4, no. 1, pp. 1–9, 2017.'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Q. Zhong, T. Guo, M. Rechsteiner, J. H. Rüschoff, N. Rupp, C. Fankhauser,
    K. Saba, A. Mortezavi, C. Poyet, T. Hermanns *等*，“前列腺癌患者组织微阵列图像和临床结果数据的精选集合，”
    *Sci. Data*，第4卷，第1期，第1–9页，2017年。'
- en: '[94] C. G. A. Network *et al.*, “Comprehensive molecular portraits of human
    breast tumours,” *Nature*, vol. 490, no. 7418, p. 61, 2012.'
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] C. G. A. Network *等*，“人类乳腺肿瘤的全面分子肖像，” *Nature*，第490卷，第7418期，第61页，2012年。'
- en: '[95] C. Kandoth, M. D. McLellan, F. Vandin, K. Ye, B. Niu, C. Lu, M. Xie, Q. Zhang,
    J. F. McMichael, M. A. Wyczalkowski *et al.*, “Mutational landscape and significance
    across 12 major cancer types,” *Nature*, vol. 502, no. 7471, pp. 333–339, 2013.'
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] C. Kandoth, M. D. McLellan, F. Vandin, K. Ye, B. Niu, C. Lu, M. Xie, Q. Zhang,
    J. F. McMichael, M. A. Wyczalkowski *等*，“12 种主要癌症类型的突变图谱及其意义，” *Nature*，第502卷，第7471期，第333–339页，2013年。'
- en: '[96] R. L. Ward and N. J. Hawkins, “Molecular and cellular oncology (mco) study
    tumour collection,” *UNSW Australia*, 2015.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] R. L. Ward 和 N. J. Hawkins，“分子与细胞肿瘤学 (mco) 研究肿瘤收集，” *UNSW Australia*，2015年。'
- en: '[97] S. Kirk, Y. Lee, C. Sadow, S. Levine, C. Roche, E. Bonaccio, and J. Filiippini,
    “Radiology data from the cancer genome atlas colon adenocarcinoma [tcga-coad]
    collection,” *The Cancer Imaging Archive*, 2016.'
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] S. Kirk, Y. Lee, C. Sadow, S. Levine, C. Roche, E. Bonaccio, 和 J. Filiippini，“来自癌症基因组图谱结肠腺癌
    [tcga-coad] 集合的放射学数据，” *The Cancer Imaging Archive*，2016年。'
- en: '[98] K. Tomczak, P. Czerwińska, and M. Wiznerowicz, “The cancer genome atlas
    (tcga): an immeasurable source of knowledge,” *Contemp. Oncol.*, vol. 19, no. 1A,
    p. A68, 2015.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] K. Tomczak, P. Czerwińska, 和 M. Wiznerowicz，“癌症基因组图谱 (tcga)：不可估量的知识源，”
    *Contemp. Oncol.*，第19卷，第1A期，第A68页，2015年。'
- en: '[99] D. Dua and C. Graff, “UCI machine learning repository,” 2017\. [Online].
    Available: http://archive.ics.uci.edu/ml'
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] D. Dua 和 C. Graff，“UCI 机器学习库，” 2017年。[在线]. 可用: http://archive.ics.uci.edu/ml'
- en: '[100] B. S. Kramer, C. D. Berg, D. R. Aberle, and P. C. Prorok, “Lung cancer
    screening with low-dose helical ct: results from the national lung screening trial
    (NLST),” 2011.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] B. S. Kramer, C. D. Berg, D. R. Aberle, 和 P. C. Prorok，“低剂量螺旋 CT 进行肺癌筛查：来自国家肺筛查试验
    (NLST) 的结果，” 2011年。'
- en: '[101] J. Silva-Rodríguez, A. Colomer, M. A. Sales, R. Molina, and V. Naranjo,
    “Going deeper through the gleason scoring scale: An automatic end-to-end system
    for histology prostate grading and cribriform pattern detection,” *Comput. Methods
    Programs Biomed.*, vol. 195, p. 105637, 2020.'
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] J. Silva-Rodríguez, A. Colomer, M. A. Sales, R. Molina, 和 V. Naranjo，“通过
    Gleason 评分尺度深入探讨：一个自动化的全链路系统用于组织学前列腺分级和筛状模式检测，” *Comput. Methods Programs Biomed.*，第195卷，第105637页，2020年。'
- en: '[102] F. A. Spanhol, L. S. Oliveira, C. Petitjean, and L. Heutte, “A dataset
    for breast cancer histopathological image classification,” *IEEE Trans. Biomed.
    Eng.*, vol. 63, no. 7, pp. 1455–1462, 2015.'
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] F. A. Spanhol, L. S. Oliveira, C. Petitjean, 和 L. Heutte，“用于乳腺癌组织病理图像分类的数据集，”
    *IEEE Trans. Biomed. Eng.*，第63卷，第7期，第1455–1462页，2015年。'
- en: '[103] M. E. Plissiti, P. Dimitrakopoulos, G. Sfikas, C. Nikou, O. Krikoni,
    and A. Charchanti, “Sipakmed: A new dataset for feature and image based classification
    of normal and pathological cervical cells in pap smear images,” in *Proc. IEE
    Int. Conf. Image Process. (ICIP)*, 2018, pp. 3144–3148.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] M. E. Plissiti, P. Dimitrakopoulos, G. Sfikas, C. Nikou, O. Krikoni,
    和 A. Charchanti，“Sipakmed：一个用于正常和病理性宫颈细胞特征及图像分类的新数据集，” 见于 *Proc. IEE Int. Conf.
    Image Process. (ICIP)*，2018年，第3144–3148页。'
- en: '[104] K. Bera, K. A. Schalper, D. L. Rimm, V. Velcheti, and A. Madabhushi,
    “Artificial intelligence in digital pathology—new tools for diagnosis and precision
    oncology,” *Nat. Rev. Clin. Oncol.*, vol. 16, no. 11, pp. 703–715, 2019.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] K. Bera, K. A. Schalper, D. L. Rimm, V. Velcheti, 和 A. Madabhushi，“数字病理学中的人工智能—用于诊断和精准肿瘤学的新工具，”
    *Nat. Rev. Clin. Oncol.*，第16卷，第11期，第703–715页，2019年。'
- en: '[105] H. Sharma, N. Zerbe, D. Heim, S. Wienert, S. Lohmann, O. Hellwich, and
    P. Hufnagl, “Cell nuclei attributed relational graphs for efficient representation
    and classification of gastric cancer in digital histopathology,” in *Med. Imaging
    2016: Digit. Pathol.*, vol. 9791, 2016, p. 97910X.'
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] H. Sharma, N. Zerbe, D. Heim, S. Wienert, S. Lohmann, O. Hellwich, 和
    P. Hufnagl，“细胞核属性关系图用于数字病理学中胃癌的高效表示和分类，” 见于 *Med. Imaging 2016: Digit. Pathol.*，第9791卷，2016年，第97910X页。'
- en: '[106] S. Gadiya, D. Anand, and A. Sethi, “Some new layer architectures for
    graph cnn,” *arXiv preprint arXiv:1811.00052*, 2018.'
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] S. Gadiya, D. Anand, 和 A. Sethi，“图 CNN 的一些新层架构，” *arXiv 预印本 arXiv:1811.00052*，2018年。'
- en: '[107] A. Fischer, K. Riesen, and H. Bunke, “Improved quadratic time approximation
    of graph edit distance by combining hausdorff matching and greedy assignment,”
    *Pattern Recog. Lett.*, vol. 87, pp. 55–62, 2017.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] A. Fischer, K. Riesen, 和 H. Bunke，“通过结合 Hausdorff 匹配和贪婪分配改进的图编辑距离二次时间近似，”
    *Pattern Recog. Lett.*，第87卷，第55–62页，2017年。'
- en: '[108] C. Morris, M. Ritzert, M. Fey, W. L. Hamilton, J. E. Lenssen, G. Rattan,
    and M. Grohe, “Weisfeiler and leman go neural: Higher-order graph neural networks,”
    in *Proc. AAAI Conf. Artif. Intell.*, vol. 33, no. 01, 2019, pp. 4602–4609.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] C. Morris, M. Ritzert, M. Fey, W. L. Hamilton, J. E. Lenssen, G. Rattan,
    和 M. Grohe，“Weisfeiler 和 Leman 变为神经网络：高阶图神经网络，” 见于 *Proc. AAAI Conf. Artif. Intell.*，第33卷，第01期，2019年，第4602–4609页。'
- en: '[109] S. Mehta, E. Mercan, J. Bartlett, D. Weaver, J. G. Elmore, and L. Shapiro,
    “Y-net: joint segmentation and classification for diagnosis of breast biopsy images,”
    in *Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*, 2018, pp. 893–901.'
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] S. Mehta, E. Mercan, J. Bartlett, D. Weaver, J. G. Elmore, 和 L. Shapiro，“Y-net：乳腺活检图像的联合分割和分类诊断，”
    见于 *Proc. Med. Image Comput. Comput.-Assist. Interv. (MICCAI)*，2018年，第893–901页。'
- en: '[110] Y. Zheng, Z. Jiang, H. Zhang, F. Xie, Y. Ma, H. Shi, and Y. Zhao, “Histopathological
    whole slide image analysis using context-based cbir,” *IEEE Trans. Med. Imaging*,
    vol. 37, no. 7, pp. 1641–1652, 2018.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Y. Zheng, Z. Jiang, H. Zhang, F. Xie, Y. Ma, H. Shi, 和 Y. Zhao，“使用基于上下文的
    CBIR 进行组织病理学全幻灯片图像分析，” *IEEE Trans. Med. Imaging*，第37卷，第7期，第1641–1652页，2018年。'
- en: '[111] T. Chen, S. Kornblith, M. Norouzi, and G. Hinton, “A simple framework
    for contrastive learning of visual representations,” in *Proc. Int. Conf. Mach.
    Learn. (ICML)*, 2020, pp. 1597–1607.'
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] T. Chen, S. Kornblith, M. Norouzi, 和 G. Hinton，“一种简单的对比学习视觉表示框架，” 见于
    *Proc. Int. Conf. Mach. Learn. (ICML)*，2020年，第1597–1607页。'
- en: '[112] M. Ye, X. Zhang, P. C. Yuen, and S.-F. Chang, “Unsupervised embedding
    learning via invariant and spreading instance feature,” in *Proc. IEEE Conf. Comput.
    Vis. Pattern Recog. (CVPR)*, 2019, pp. 6210–6219.'
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] M. Ye, X. Zhang, P. C. Yuen, 和 S.-F. Chang，“通过不变和扩展实例特征进行无监督嵌入学习，” 见于
    *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*，2019年，第6210–6219页。'
- en: '[113] P. Gupta, S.-F. Chiang, P. K. Sahoo, S. K. Mohapatra, J.-F. You, D. D.
    Onthoni, H.-Y. Hung, J.-M. Chiang, Y. Huang, and W.-S. Tsai, “Prediction of colon
    cancer stages and survival period with machine learning approach,” *Cancers*,
    vol. 11, no. 12, p. 2007, 2019.'
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] P. 古普塔, S.-F. 蒋, P. K. 萨胡, S. K. 莫哈帕特拉, J.-F. 尤, D. D. 安索尼, H.-Y. 洪,
    J.-M. 蒋, Y. 黄, 和 W.-S. 蔡，“通过机器学习方法预测结肠癌阶段和生存期，” *癌症*，第11卷，第12期，第2007页，2019年。'
- en: '[114] M. Ilse, J. Tomczak, and M. Welling, “Attention-based deep multiple instance
    learning,” in *Proc. Int. Conf. Mach. Learn. (ICML)*, 2018, pp. 2127–2136.'
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] M. 伊尔塞, J. 汤姆查克, 和 M. 韦林，“基于注意力的深度多实例学习，”发表于 *国际机器学习会议（ICML）论文集*，2018年，第2127–2136页。'
- en: '[115] Z. Li, X. Zhang, H. Müller, and S. Zhang, “Large-scale retrieval for
    medical image analytics: A comprehensive review,” *Med. Image Anal.*, vol. 43,
    pp. 66–84, 2018.'
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Z. 李, X. 张, H. 米勒, 和 S. 张，“大规模医学图像分析检索：综述，” *医学图像分析*，第43卷，第66–84页，2018年。'
- en: '[116] L. Chan, M. S. Hosseini, C. Rowsell, K. N. Plataniotis, and S. Damaskinos,
    “Histosegnet: Semantic segmentation of histological tissue type in whole slide
    images,” in *Proc. IEEE Int. Conf. Comput. Vis. (ICCV)*, 2019, pp. 10 662–10 671.'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] L. 陈, M. S. 霍塞尼, C. 罗塞尔, K. N. 普拉塔尼奥蒂斯, 和 S. 达马斯基诺斯，“Histosegnet：全切片图像中的组织类型语义分割，”发表于
    *IEEE国际计算机视觉会议（ICCV）论文集*，2019年，第10 662–10 671页。'
- en: '[117] G. Corso, L. Cavalleri, D. Beaini, P. Liò, and P. Veličković, “Principal
    neighbourhood aggregation for graph nets,” in *Proc. Adv Neural Inf. Process.
    Syst (NeurIPS)*, 2020.'
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] G. 科尔索, L. 卡瓦列里, D. 比尼, P. 李奥, 和 P. 维利克诺维奇，“图网络的主要邻域聚合，”发表于 *神经信息处理系统会议（NeurIPS）论文集*，2020年。'
- en: '[118] V. P. Dwivedi, C. K. Joshi, T. Laurent, Y. Bengio, and X. Bresson, “Benchmarking
    graph neural networks,” *arXiv preprint arXiv:2003.00982*, 2020.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] V. P. 德维维迪, C. K. 乔希, T. 劳伦特, Y. 本吉奥, 和 X. 布雷森，“图神经网络基准测试，” *arXiv预印本
    arXiv:2003.00982*，2020年。'
- en: '[119] F. Chazal and B. Michel, “An introduction to topological data analysis:
    fundamental and practical aspects for data scientists,” *arXiv preprint arXiv:1710.04019*,
    2017.'
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] F. 查扎尔 和 B. 米歇尔，“拓扑数据分析简介：数据科学家的基础和实际方面，” *arXiv预印本 arXiv:1710.04019*，2017年。'
- en: '[120] O. Gallego, “Nonsurgical treatment of recurrent glioblastoma,” *Curr.
    Oncol.*, vol. 22, no. 4, p. e273, 2015.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] O. 加列戈，“复发性胶质母细胞瘤的非手术治疗，” *当前肿瘤学*，第22卷，第4期，第e273页，2015年。'
- en: '[121] C. Chen, W. Ye, Y. Zuo, C. Zheng, and S. P. Ong, “Graph networks as a
    universal machine learning framework for molecules and crystals,” *Chemistry of
    Materials*, vol. 31, no. 9, pp. 3564–3572, 2019.'
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] C. 陈, W. 叶, Y. 左, C. 郑, 和 S. P. 王，“图网络作为分子和晶体的通用机器学习框架，” *材料化学*，第31卷，第9期，第3564–3572页，2019年。'
- en: '[122] H. Wang, J. Wang, J. Wang, M. Zhao, W. Zhang, F. Zhang, X. Xie, and M. Guo,
    “Graphgan: Graph representation learning with generative adversarial nets,” in
    *Proc. AAAI Conf. Artif. Intell.*, vol. 32, no. 1, 2018.'
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] H. 王, J. 王, J. 王, M. 赵, W. 张, F. 张, X. 谢, 和 M. 郭，“Graphgan：基于生成对抗网络的图表示学习，”发表于
    *AAAI人工智能会议*，第32卷，第1期，2018年。'
- en: '[123] Y. Li, O. Vinyals, C. Dyer, R. Pascanu, and P. Battaglia, “Learning deep
    generative models of graphs,” *arXiv preprint arXiv:1803.03324*, 2018.'
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] Y. 李, O. 维尼亚尔斯, C. 代尔, R. 帕斯卡努, 和 P. 巴塔利亚，“学习图的深度生成模型，” *arXiv预印本 arXiv:1803.03324*，2018年。'
- en: '[124] J. You, B. Liu, R. Ying, V. Pande, and J. Leskovec, “Graph convolutional
    policy network for goal-directed molecular graph generation,” in *Proc. Adv Neural
    Inf. Process. Syst (NeurIPS)*, 2018.'
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] J. 尤, B. 刘, R. 英, V. 潘德, 和 J. 莱斯科维奇，“用于目标导向分子图生成的图卷积策略网络，”发表于 *神经信息处理系统会议（NeurIPS）论文集*，2018年。'
- en: '[125] X. Xie, J. Niu, X. Liu, Z. Chen, and S. Tang, “A survey on domain knowledge
    powered deep learning for medical image analysis,” *arXiv preprint arXiv:2004.12150*,
    2020.'
  id: totrans-486
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] X. 谢, J. 牛, X. 刘, Z. 陈, 和 S. 唐，“领域知识驱动的深度学习在医学图像分析中的应用综述，” *arXiv预印本
    arXiv:2004.12150*，2020年。'
- en: '[126] Z.-M. Chen, X.-S. Wei, P. Wang, and Y. Guo, “Multi-label image recognition
    with graph convolutional networks,” in *Proc. IEEE Conf. Comput. Vis. Pattern
    Recog. (CVPR)*, 2019, pp. 5177–5186.'
  id: totrans-487
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] Z.-M. 陈, X.-S. 魏, P. 王, 和 Y. 郭，“基于图卷积网络的多标签图像识别，”发表于 *IEEE计算机视觉与模式识别会议（CVPR）论文集*，2019年，第5177–5186页。'
- en: '[127] E. Choi, M. T. Bahadori, L. Song, W. F. Stewart, and J. Sun, “Gram: graph-based
    attention model for healthcare representation learning,” in *Proc. Int. Conf.
    Knowledge Discov. Data Mining (KDD)*, 2017, pp. 787–795.'
  id: totrans-488
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] E. 崔, M. T. 巴哈多里, L. 宋, W. F. 斯图尔特, 和 J. 孙，“Gram: 基于图的注意力模型用于医疗保健表示学习，”发表于
    *国际知识发现与数据挖掘会议（KDD）论文集*，2017年，第787–795页。'
- en: '[128] A. Singh, S. Sengupta, and V. Lakshminarayanan, “Explainable deep learning
    models in medical image analysis,” *J. Imaging*, vol. 6, no. 6, p. 52, 2020.'
  id: totrans-489
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] A. 辛格, S. 森古普塔, 和 V. 拉克什米纳亚南，“医学图像分析中的可解释深度学习模型，” *成像杂志*，第6卷，第6期，第52页，2020年。'
- en: '[129] W. Bulten, M. Balkenhol, J.-J. A. Belinga, A. Brilhante, A. Çakır, L. Egevad,
    M. Eklund, X. Farré, K. Geronatsiou, V. Molinié *et al.*, “Artificial intelligence
    assistance significantly improves gleason grading of prostate biopsies by pathologists,”
    *Modern Pathology*, vol. 34, no. 3, pp. 660–671, 2021.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] W. Bulten, M. Balkenhol, J.-J. A. Belinga, A. Brilhante, A. Çakır, L.
    Egevad, M. Eklund, X. Farré, K. Geronatsiou, V. Molinié *等*，“人工智能辅助显著提高了病理学家对前列腺活检的
    Gleason 分级”，*Modern Pathology*，第 34 卷，第 3 期，页码 660–671，2021。'
- en: '[130] J. Chen, T. Ma, and C. Xiao, “Fastgcn: Fast learning with graph convolutional
    networks via importance sampling,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*,
    2018.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] J. Chen, T. Ma 和 C. Xiao，“Fastgcn：通过重要性采样实现图卷积网络的快速学习”，在 *Proc. Int.
    Conf. Learn. Repr. (ICLR)*，2018。'
- en: '[131] Y. You, T. Chen, Z. Wang, and Y. Shen, “L2-gcn: Layer-wise and learned
    efficient training of graph convolutional networks,” in *Proc. IEEE Conf. Comput.
    Vis. Pattern Recog. (CVPR)*, 2020, pp. 2127–2135.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Y. You, T. Chen, Z. Wang 和 Y. Shen，“L2-gcn：图卷积网络的层级和学习高效训练”，在 *Proc.
    IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*，2020，页码 2127–2135。'
- en: '[132] W.-L. Chiang, X. Liu, S. Si, Y. Li, S. Bengio, and C.-J. Hsieh, “Cluster-gcn:
    An efficient algorithm for training deep and large graph convolutional networks,”
    in *Proc. Int. Conf. Knowledge Discov. Data Mining (KDD)*, 2019, pp. 257–266.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] W.-L. Chiang, X. Liu, S. Si, Y. Li, S. Bengio 和 C.-J. Hsieh，“Cluster-gcn：一种高效的深度和大规模图卷积网络训练算法”，在
    *Proc. Int. Conf. Knowledge Discov. Data Mining (KDD)*，2019，页码 257–266。'
- en: '[133] F. Wu, A. Souza, T. Zhang, C. Fifty, T. Yu, and K. Weinberger, “Simplifying
    graph convolutional networks,” in *Proc. Int. Conf. Mach. Learn. (ICML)*, 2019,
    pp. 6861–6871.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] F. Wu, A. Souza, T. Zhang, C. Fifty, T. Yu 和 K. Weinberger，“简化图卷积网络”，在
    *Proc. Int. Conf. Mach. Learn. (ICML)*，2019，页码 6861–6871。'
- en: '[134] P. Zhong, D. Wang, and C. Miao, “Eeg-based emotion recognition using
    regularized graph neural networks,” *IEEE Trans. Affect. Comput.*, 2020.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] P. Zhong, D. Wang 和 C. Miao，“基于 EEG 的情感识别使用正则化图神经网络”，*IEEE Trans. Affect.
    Comput.*，2020。'
- en: '[135] E. Rossi, F. Frasca, B. Chamberlain, D. Eynard, M. Bronstein, and F. Monti,
    “Sign: Scalable inception graph neural networks,” *arXiv preprint arXiv:2004.11198*,
    2020.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] E. Rossi, F. Frasca, B. Chamberlain, D. Eynard, M. Bronstein 和 F. Monti，“Sign：可扩展的起始图神经网络”，*arXiv
    预印本 arXiv:2004.11198*，2020。'
- en: '[136] S. A. Tailor, F. L. Opolka, P. Liò, and N. D. Lane, “Adaptive filters
    and aggregator fusion for efficient graph convolutions,” *arXiv preprint arXiv:2104.01481*,
    2021.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] S. A. Tailor, F. L. Opolka, P. Liò 和 N. D. Lane，“自适应滤波器和聚合器融合用于高效图卷积”，*arXiv
    预印本 arXiv:2104.01481*，2021。'
- en: '[137] P.-E. Sarlin, D. DeTone, T. Malisiewicz, and A. Rabinovich, “Superglue:
    Learning feature matching with graph neural networks,” in *Proc. IEEE Conf. Comput.
    Vis. Pattern Recog. (CVPR)*, 2020, pp. 4938–4947.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] P.-E. Sarlin, D. DeTone, T. Malisiewicz 和 A. Rabinovich，“Superglue：使用图神经网络学习特征匹配”，在
    *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*，2020，页码 4938–4947。'
- en: '[138] S. Javed, A. Mahmood, M. M. Fraz, N. A. Koohbanani, K. Benes, Y.-W. Tsang,
    K. Hewitt, D. Epstein, D. Snead, and N. Rajpoot, “Cellular community detection
    for tissue phenotyping in colorectal cancer histology images,” *Med. Image Anal.*,
    vol. 63, p. 101696, 2020.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] S. Javed, A. Mahmood, M. M. Fraz, N. A. Koohbanani, K. Benes, Y.-W. Tsang,
    K. Hewitt, D. Epstein, D. Snead 和 N. Rajpoot，“用于结直肠癌组织学图像的细胞社区检测”，*Med. Image
    Anal.*，第 63 卷，文章编号 101696，2020。'
- en: '[139] P. Velickovic, W. Fedus, W. L. Hamilton, P. Liò, Y. Bengio, and R. D.
    Hjelm, “Deep graph infomax,” in *Proc. Int. Conf. Learn. Repr. (ICLR)*, 2019.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] P. Velickovic, W. Fedus, W. L. Hamilton, P. Liò, Y. Bengio 和 R. D. Hjelm，“深度图信息最大化”，在
    *Proc. Int. Conf. Learn. Repr. (ICLR)*，2019。'
- en: '[140] J. N. Kather, A. T. Pearson, N. Halama, D. Jäger, J. Krause, S. H. Loosen,
    A. Marx, P. Boor, F. Tacke, U. P. Neumann *et al.*, “Deep learning can predict
    microsatellite instability directly from histology in gastrointestinal cancer,”
    *Nat. Med.*, vol. 25, no. 7, pp. 1054–1056, 2019.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] J. N. Kather, A. T. Pearson, N. Halama, D. Jäger, J. Krause, S. H. Loosen,
    A. Marx, P. Boor, F. Tacke, U. P. Neumann *等*，“深度学习可以直接从组织学中预测胃肠道癌症的微卫星不稳定性”，*Nat.
    Med.*，第 25 卷，第 7 期，页码 1054–1056，2019。'
- en: '[141] G. Campanella, M. G. Hanna, L. Geneslaw, A. Miraflor, V. W. K. Silva,
    K. J. Busam, E. Brogi, V. E. Reuter, D. S. Klimstra, and T. J. Fuchs, “Clinical-grade
    computational pathology using weakly supervised deep learning on whole slide images,”
    *Nat. Med.*, vol. 25, no. 8, pp. 1301–1309, 2019.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] G. Campanella, M. G. Hanna, L. Geneslaw, A. Miraflor, V. W. K. Silva,
    K. J. Busam, E. Brogi, V. E. Reuter, D. S. Klimstra 和 T. J. Fuchs，“使用弱监督深度学习进行临床级计算病理学分析全幻灯片图像”，*Nat.
    Med.*，第 25 卷，第 8 期，页码 1301–1309，2019。'
- en: '[142] L. Hou, D. Samaras, T. M. Kurc, Y. Gao, J. E. Davis, and J. H. Saltz,
    “Patch-based convolutional neural network for whole slide tissue image classification,”
    in *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*, 2016, pp. 2424–2433.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] L. Hou, D. Samaras, T. M. Kurc, Y. Gao, J. E. Davis, 和 J. H. Saltz, “基于补丁的卷积神经网络用于全切片组织图像分类，”
    见 *Proc. IEEE Conf. Comput. Vis. Pattern Recog. (CVPR)*，2016 年，页 2424–2433。'
- en: '[143] M. Y. Lu, D. F. Williamson, T. Y. Chen, R. J. Chen, M. Barbieri, and
    F. Mahmood, “Data-efficient and weakly supervised computational pathology on whole-slide
    images,” *Nat. Biomed. Eng.*, vol. 5, no. 6, pp. 555–570, 2021.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] M. Y. Lu, D. F. Williamson, T. Y. Chen, R. J. Chen, M. Barbieri, 和 F.
    Mahmood, “数据高效且弱监督的全切片图像计算病理学，” *Nat. Biomed. Eng.*，第 5 卷，第 6 期，页 555–570，2021
    年。'
- en: '[144] M. Shaban, R. Awan, M. M. Fraz, A. Azam, Y.-W. Tsang, D. Snead, and N. M.
    Rajpoot, “Context-aware convolutional neural network for grading of colorectal
    cancer histology images,” *IEEE Trans. Med. Imaging*, vol. 39, no. 7, pp. 2395–2405,
    2020.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] M. Shaban, R. Awan, M. M. Fraz, A. Azam, Y.-W. Tsang, D. Snead, 和 N.
    M. Rajpoot, “用于结直肠癌组织学图像分级的上下文感知卷积神经网络，” *IEEE Trans. Med. Imaging*，第 39 卷，第 7
    期，页 2395–2405，2020 年。'
- en: '[145] S. Tonekaboni, S. Joshi, M. D. McCradden, and A. Goldenberg, “What clinicians
    want: contextualizing explainable machine learning for clinical end use,” in *Proc.
    Mach. Learn. Healthc. Conf.*, 2019, pp. 359–380.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] S. Tonekaboni, S. Joshi, M. D. McCradden, 和 A. Goldenberg, “临床医生的需求：将可解释的机器学习情境化为临床终端使用，”
    见 *Proc. Mach. Learn. Healthc. Conf.*，2019 年，页 359–380。'
- en: '[146] M. Du, N. Liu, and X. Hu, “Techniques for interpretable machine learning,”
    *Commun. ACM*, vol. 63, no. 1, pp. 68–77, 2019.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] M. Du, N. Liu, 和 X. Hu, “可解释机器学习的技术，” *Commun. ACM*，第 63 卷，第 1 期，页 68–77，2019
    年。'
- en: '[147] M. N. Vu and M. T. Thai, “Pgm-explainer: Probabilistic graphical model
    explanations for graph neural networks,” in *Proc. Adv Neural Inf. Process. Syst
    (NeurIPS)*, 2020.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] M. N. Vu 和 M. T. Thai, “Pgm-explainer: 图神经网络的概率图模型解释器，” 见 *Proc. Adv
    Neural Inf. Process. Syst (NeurIPS)*，2020 年。'
- en: '[148] M. S. Schlichtkrull, N. De Cao, and I. Titov, “Interpreting graph neural
    networks for nlp with differentiable edge masking,” in *Proc. Int. Conf. Learn.
    Repr. (ICLR)*, 2021.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] M. S. Schlichtkrull, N. De Cao, 和 I. Titov, “通过可微分边缘遮蔽解释图神经网络，” 见 *Proc.
    Int. Conf. Learn. Repr. (ICLR)*，2021 年。'
- en: '[149] Q. Huang, M. Yamada, Y. Tian, D. Singh, D. Yin, and Y. Chang, “Graphlime:
    Local interpretable model explanations for graph neural networks,” *arXiv preprint
    arXiv:2001.06216*, 2020.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Q. Huang, M. Yamada, Y. Tian, D. Singh, D. Yin, 和 Y. Chang, “Graphlime:
    图神经网络的局部可解释模型解释，” *arXiv 预印本 arXiv:2001.06216*，2020 年。'
- en: '[150] Y. Zhang, D. Defazio, and A. Ramesh, “Relex: A model-agnostic relational
    model explainer,” in *Proc. AAAI Conf. AI Ethics Soc.*, 2021, pp. 1042–1049.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] Y. Zhang, D. Defazio, 和 A. Ramesh, “Relex: 一种模型无关的关系模型解释器，” 见 *Proc.
    AAAI Conf. AI Ethics Soc.*，2021 年，页 1042–1049。'
- en: '[151] H. Yuan, H. Yu, J. Wang, K. Li, and S. Ji, “On explainability of graph
    neural networks via subgraph explorations,” *arXiv preprint arXiv:2102.05152*,
    2021.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] H. Yuan, H. Yu, J. Wang, K. Li, 和 S. Ji, “通过子图探索图神经网络的可解释性，” *arXiv 预印本
    arXiv:2102.05152*，2021 年。'
- en: '[152] W. Guo, S. Huang, Y. Tao, X. Xing, and L. Lin, “Explaining deep learning
    models-a bayesian non-parametric approach,” in *Proc. Adv Neural Inf. Process.
    Syst (NeurIPS)*, 2018, pp. 4514–4524.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] W. Guo, S. Huang, Y. Tao, X. Xing, 和 L. Lin, “解释深度学习模型—一种贝叶斯非参数方法，” 见
    *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*，2018 年，页 4514–4524。'
- en: '[153] H. Yuan, J. Tang, X. Hu, and S. Ji, “Xgnn: Towards model-level explanations
    of graph neural networks,” in *Proc. Int. Conf. Knowledge Discov. Data Mining
    (KDD)*, 2020, pp. 430–438.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] H. Yuan, J. Tang, X. Hu, 和 S. Ji, “Xgnn: 迈向图神经网络的模型级解释，” 见 *Proc. Int.
    Conf. Knowledge Discov. Data Mining (KDD)*，2020 年，页 430–438。'
- en: '[154] D. Luo, W. Cheng, D. Xu, W. Yu, B. Zong, H. Chen, and X. Zhang, “Parameterized
    explainer for graph neural network,” in *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*,
    2020.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] D. Luo, W. Cheng, D. Xu, W. Yu, B. Zong, H. Chen, 和 X. Zhang, “图神经网络的参数化解释器，”
    见 *Proc. Adv Neural Inf. Process. Syst (NeurIPS)*，2020 年。'
