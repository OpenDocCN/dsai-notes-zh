- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:56:17'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2103.09316] Are deep learning models superior for missing data imputation
    in surveys? Evidence from an empirical comparison'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2103.09316](https://ar5iv.labs.arxiv.org/html/2103.09316)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Are deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Zhenhua Wang, Olanrewaju Akande, Jason Poulos and Fan Li ¹¹1Zhenhua Wang is
    PhD student in the Department of Statistics, University of Missouri, Columbia,
    MO 65211 (E-mail: [zhenhua.wang@mail.missouri.edu](mailto:zhenhua.wang@mail.missouri.edu));
    Olanrewaju Akande is research scientist at Meta Platforms, Inc. (E-mail: [akandelanre13@gmail.com](mailto:akandelanre13@gmail.com));
    Jason Poulos is Postdoctoral Associate in the Department of Health Care Policy,
    Harvard Medical School, Boston, MA (E-mail: [poulos@hcp.med.harvard.edu](mailto:poulos@hcp.med.harvard.edu));
    and Fan Li is Professor in the Department of Statistical Science, Box 90251, Duke
    University, Durham, NC 27708 (E-mail: [fl35@duke.edu](mailto:fl35@duke.edu)).'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'Multiple imputation (MI) is a popular approach for dealing with missing data
    arising from non-response in sample surveys. Multiple imputation by chained equations
    (MICE) is one of the most widely used MI algorithms for multivariate data, but
    it lacks theoretical foundation and is computationally intensive. Recently, missing
    data imputation methods based on deep learning models have been developed with
    encouraging results in small studies. However, there has been limited research
    on evaluating their performance in realistic settings compared to MICE, particularly
    in big surveys. We conduct extensive simulation studies based on a subsample of
    the American Community Survey to compare the repeated sampling properties of four
    machine learning based MI methods: MICE with classification trees, MICE with random
    forests, generative adversarial imputation networks, and multiple imputation using
    denoising autoencoders. We find the deep learning imputation methods are superior
    to MICE in terms of computational time. However, with the default choice of hyperparameters
    in the common software packages, MICE with classification trees consistently outperforms,
    often by a large margin, the deep learning imputation methods in terms of bias,
    mean squared error, and coverage under a range of realistic settings.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Key words:*: Deep learning; hyperparameter selection; missing data; multiple
    imputation by chained equations; simulation studies; survey data.'
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Many sample surveys suffer from missing data, arising from unit nonresponse,
    where a subset of participants do not complete the survey, or item nonresponse,
    where missing values are concentrated on particular questions. In opinion polls,
    nonresponse may reflect either refusal to reveal a preference or lack of a preference
    [[11](#bib.bibx11)]. If not properly handled, missing data patterns can lead to
    biased statistical analyses, especially when there are systematic differences
    between the observed data and the missing data [[41](#bib.bibx41), [31](#bib.bibx31)].
    Complete case analysis on units with completely observed data is often infeasible
    and may lead to large bias in most situations [[31](#bib.bibx31)]. As a result,
    many analysts account for the missing data by imputing missing values and then
    proceeding as if the imputed values are true values.
  prefs: []
  type: TYPE_NORMAL
- en: Multiple imputation (MI) [[42](#bib.bibx42)] is a popular approach for handling
    missing values. In MI, an analyst creates $L>1$ completed datasets by replacing
    the missing values in the sample data with plausible draws generated from the
    predictive distribution of probabilistic models based on the observed data. In
    each completed dataset, the analyst can then compute sample estimates for population
    estimands of interest, and combine the sample estimates across all $L$ datasets
    using MI inference methods developed by [[42](#bib.bibx42)], and more recently,
    [[43](#bib.bibx43), [3](#bib.bibx3), [39](#bib.bibx39)], and [[20](#bib.bibx20)].
    In MI, the estimated variance of an estimand consists of both within-imputation
    and between-imputation variances, and thus takes into account the inherent variability
    of the imputed values. Note that in survey studies, single imputation, e.g. via
    matching or regression, remains to be common for dealing with missing data, where
    the variance is estimated via the delta method or resampling methods [[10](#bib.bibx10),
    [22](#bib.bibx22)].
  prefs: []
  type: TYPE_NORMAL
- en: 1.1 Model-based imputation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There are two general modeling strategies for MI. The first strategy, known
    as *joint modeling* (JM), is to specify a joint distribution for all variables
    in the data, and then generate imputations from the implied conditional (predictive)
    distributions of the variables with missing values [[44](#bib.bibx44)]. The JM
    strategy aligns with the theoretical foundation of [[42](#bib.bibx42)], but it
    can be challenging to specify a joint model with high-dimensional variables of
    different types. Indeed, most popular JM approaches, such as “PROC MI” in SAS
    [[59](#bib.bibx59)], and “AMELIA” [[23](#bib.bibx23)] and “norm” in R [[44](#bib.bibx44)],
    make a simplifying assumption that the data follow multivariate Gaussian distributions,
    even for categorical variables, which can lead to bias [[24](#bib.bibx24)]. Recent
    research developed flexible JM models based on advanced Bayesian nonparametric
    models such as Dirichlet Process mixtures [[34](#bib.bibx34), [37](#bib.bibx37)].
    However, these methods are computationally expensive, and often struggle to scale
    up to high-dimensional cases.
  prefs: []
  type: TYPE_NORMAL
- en: The second strategy is called *fully conditional specification* (FCS, [[51](#bib.bibx51)]),
    where one separately specifies a univariate conditional distribution for each
    variable with missing values given all the other variables and imputes the missing
    values variable-by-variable iteratively, akin to a Gibbs sampler. The most popular
    FCS method is multiple imputation by chained equations (MICE) [[52](#bib.bibx52)],
    usually implemented with specifying generalized linear models (GLMs) for the univariate
    conditional distributions [[38](#bib.bibx38), [40](#bib.bibx40), [47](#bib.bibx47)].
    Recent research indicates that specifying the conditional models by classification
    and regression trees (CART, [[6](#bib.bibx6), [7](#bib.bibx7)]) comprehensively
    outperforms MICE with GLM [[1](#bib.bibx1)]. A natural extension of MICE with
    CART is to use ensemble tree methods such as random forests, rather than a single
    tree [[5](#bib.bibx5), [12](#bib.bibx12)].
  prefs: []
  type: TYPE_NORMAL
- en: MICE is appealing in large-scale survey data because it is simple and flexible
    in imputing different types of variables. However, MICE has a key theoretical
    drawback that the specified conditional distributions may be incompatible, that
    is, they do not correspond to a joint distribution [[2](#bib.bibx2), [15](#bib.bibx15),
    [27](#bib.bibx27)]. Despite this drawback, MICE works remarkably well in real
    applications and numerous simulations have demonstrated it outperforms many theoretically
    sound JM-based methods; see [[50](#bib.bibx50)] for case studies. However, MICE
    is also computationally intensive [[55](#bib.bibx55)] and generally cannot be
    parallelized. Moreover, popular software packages for implementing MICE with GLMs,
    e.g. mice in R [[52](#bib.bibx52)], often crash in settings with high dimensional
    non-continuous variables, e.g., categorical variables with many categories [[1](#bib.bibx1)].
  prefs: []
  type: TYPE_NORMAL
- en: 1.2 Imputation with deep learning models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Recent advances in deep learning greatly expand the scope of complex models
    for high-dimensional data. This advancement brings the hope that a new generation
    of missing data imputation methods based on deep learning models may address the
    theoretical and computational limitations of existing statistical methods. For
    example, deep generative models such as generative adversarial networks (GANs,
    [[18](#bib.bibx18)]) are naturally suitable for producing multiple imputations
    because they are designed to generate data that resemble the observed data as
    much as possible. A method in this stream is the generative adversarial imputation
    network (GAIN) of [[57](#bib.bibx57)]. Multiple imputation using denoising autoencoders
    (MIDA, [[17](#bib.bibx17), [32](#bib.bibx32)]), is another generative method based
    on deep neural networks trained on corrupted input data in order to force the
    networks to learn a useful low-dimensional representation of the input data, rather
    than its identity function [[53](#bib.bibx53), [54](#bib.bibx54)]. Several methods
    have been proposed for missing value imputation in time-series data using variational
    autoencoders [[14](#bib.bibx14)] or recurrent neural networks [[29](#bib.bibx29),
    [36](#bib.bibx36), [8](#bib.bibx8), [9](#bib.bibx9), [58](#bib.bibx58)].
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning based MI methods have several advantages, at least theoretically,
    over the traditional statistical models, including (i) they avoid making distributional
    assumptions; (ii) can readily handle mixed data types; (iii) can model nonlinear
    relationships between variables; (iv) are expected to perform well in high-dimensional
    settings; and (v) can leverage graphics processing unit (GPU) power for faster
    computation. Several papers report encouraging performance of deep learning based
    MI methods compared to MICE [[57](#bib.bibx57), e.g.]. However, such conclusions
    are made based on limited evidence. First, the studies are usually based on small
    simulations or several well-studied public “benchmark” datasets, such as those
    described in Section [5](#S5 "5 Evaluation based on “benchmark” datasets ‣ Are
    deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison"), which do not resemble survey data. Second, the
    evaluations are usually based on a few overall performance metric, e.g., the overall
    predictive mean squared error or accuracy. Such metrics may not give a full picture
    of the comparisons and sometimes can be even misleading, as will be illustrated
    later. Third, given the uncertainty of the missing data process, it is crucial
    to examine the repeated sampling properties of imputation methods, but these have
    been rarely evaluated. Finally, hyperparameter tuning is crucial for machine learning
    models and different tuning can result in dramatically different results, but
    few details are provided on hyperparameter tuning and its consequences on the
    performance of imputation methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Motivated by these limitations, in this paper we carry out extensive simulations
    based on real survey data to evaluate MI methods with a range performance metrics.
    Specifically, we conduct simulations based on a subsample from the American Community
    Survey to compare repeated sampling properties of four aforementioned MI methods:
    MICE with CART (MICE-CART), MICE with random forests (MICE-RF), GAIN, and MIDA.
    We find that deep learning based MI methods are superior to MICE in terms of computational
    time. However, MICE-CART consistently outperforms, often by a large margin, the
    deep learning methods in terms of bias, mean squared error, and coverage, under
    a range of realistic settings. This contradicts previous findings in the machine
    learning literature, and raises questions on the appropriate metrics for evaluating
    imputation methods. It also highlights the importance of assessing repeated-sampling
    properties of imputation methods. Though we focus on multiple imputation in this
    paper, we note that the aforementioned MI methods are readily applicable to generate
    single imputation when $L$ is set to 1\. Extensive empirical evidences suggest
    that the within-imputation variance usually dominates the between-imputation variance
    in MI. As such, we expect the patterns between different imputation methods observed
    here also stand if these methods are used for single imputation.'
  prefs: []
  type: TYPE_NORMAL
- en: The remainder of this article is organized as follows. In Section [2](#S2 "2
    Missing Data Imputation Methods ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison"), we review
    the four MI methods used in our evaluation. In Section [3](#S3 "3 Simulation-based
    evaluation of imputation methods ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison"), we describe
    a framework with several metrics for evaluating imputation methods. In Section
    [4](#S4 "4 Evaluation based on ACS ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison"), we describe
    the simulation design and results with large-scale survey data, and in Section
    [5](#S5 "5 Evaluation based on “benchmark” datasets ‣ Are deep learning models
    superior for missing data imputation in surveys? Evidence from an empirical comparison")
    we summarize evaluation results on the benchmark datasets used in machine learning
    literature. Finally, in Section [6](#S6 "6 Conclusion ‣ Are deep learning models
    superior for missing data imputation in surveys? Evidence from an empirical comparison"),
    we conclude with a practical guide for implementation in real applications.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Missing Data Imputation Methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We first introduce notation. Consider a sample with $n$ units, each of which
    is associated with $p$ variables. Let $Y_{ij}$ be the value of variable $j$ for
    individual $i$, where $j=1,\dots,p$ and $i=1,\dots,n$. Here, $Y$ can be continuous,
    binary, categorical or mixed binary-continuous. For each individual $i$, let ${\bf
    Y}_{i}=(Y_{i1},\dots,Y_{ip})$. For each variable $j$, let ${\bf Y}_{j}=(Y_{1j},\dots,Y_{nj})$.
    Let ${\bf Y}=({\bf Y}_{1},\ldots,{\bf Y}_{n})$ be the $n\times p$ matrix comprising
    the data for all records included in the sample. We write ${\bf Y}=({\bf Y}_{\textrm{obs}},{\bf
    Y}_{\textrm{mis}})$, where ${\bf Y}_{\textrm{obs}}$ and ${\bf Y}_{\textrm{mis}}$
    are respectively the observed and missing parts of ${\bf Y}$. We write ${\bf Y}_{\textrm{mis}}=({\bf
    Y}_{\textrm{mis},1},\dots,{\bf Y}_{\textrm{mis},p})$, where ${\bf Y}_{\textrm{mis},j}$
    represents all missing values for variable $j$, with $j=1,\dots,p$. Similarly,
    we write ${\bf Y}_{\textrm{obs}}=({\bf Y}_{\textrm{obs},1},\dots,{\bf Y}_{\textrm{obs},p})$
    for the corresponding observed data.
  prefs: []
  type: TYPE_NORMAL
- en: In MI, the analyst generates values of the missing data ${\bf Y}_{\textrm{mis}}$
    using pre-specified models estimated with ${\bf Y}_{\textrm{obs}}$, resulting
    in a completed dataset. The analyst then repeats the process to generate $L$ completed
    datasets, $\{{\bf Y}^{(l)}:l=1,\dots,L\}$, that are available for inference or
    dissemination. For inference, the analyst can compute sample estimates for population
    estimands in each completed dataset $\textbf{Y}^{(l)}$, and combine them using
    MI inference rules developed by [[42](#bib.bibx42)], which will be reviewed in
    Section [3](#S3 "3 Simulation-based evaluation of imputation methods ‣ Are deep
    learning models superior for missing data imputation in surveys? Evidence from
    an empirical comparison").
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 MICE with classification tree models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Under MICE, the analyst begins by specifying a separate univariate conditional
    model for each variable with missing values. The analyst then specifies an order
    to iterate through the sequence of the conditional models, when doing imputation.
    We write the ordered list of the variables as $(\textbf{Y}_{(1)},\dots,\textbf{Y}_{(p)})$.
    Next, the analyst initializes each ${\bf Y}_{\textrm{mis},(j)}$. The most popular
    options are to sample from (i) the marginal distribution of the corresponding
    ${\bf Y}_{\textrm{obs},(j)}$, or (ii) the conditional distribution of ${\bf Y}_{(j)}$
    given all the other variables, constructed using only available cases.
  prefs: []
  type: TYPE_NORMAL
- en: After initialization, the MICE algorithm follows an iterative process that cycles
    through the sequence of univariate models. For each variable $j$ at each iteration
    $t$, one fits the conditional model $(\textbf{Y}_{(j)}|\textbf{Y}_{\textrm{obs},(j)},\{\textbf{Y}_{(k)}^{(t)}:k<j\},\{\textbf{Y}_{(k)}^{(t-1)}:k>j\})$.
    Next, one replaces ${\bf Y}_{\textrm{mis},(j)}^{(t)}$ with draws from the implied
    model $({\bf Y}_{\textrm{mis},(j)}^{(t)}|\textbf{Y}_{\textrm{obs},(j)},\{\textbf{Y}_{(k)}^{(t)}:k<j\},\{\textbf{Y}_{(k)}^{(t-1)}:k>j\})$.
    The iterative process continues for $T$ total iterations until convergence, and
    the values at the final iteration make up a completed dataset ${\bf Y}^{(l)}=({\bf
    Y}_{\textrm{obs}},{\bf Y}_{\textrm{mis}}^{(T)})$. The entire process is then repeated
    $L$ times to create the $L$ completed datasets. We provide pseudocode detailing
    each step of the MICE algorithm in the supplementary material.
  prefs: []
  type: TYPE_NORMAL
- en: Under MICE-CART, the analyst uses CART [[6](#bib.bibx6)] for the univariate
    conditional models in the MICE algorithm. CART follows a decision tree structure
    that uses recursive binary splits to partition the predictor space into distinct
    non-overlapping regions. The top of the tree often represents its root and each
    successive binary split divides the predictor space into two new branches as one
    moves down the tree. The splitting criterion at each leaf is usually chosen to
    minimize an information theoretic entropy measure. Splits that do not decrease
    the lack of fit by an reasonable amount based on a set threshold are pruned off.
    The tree is then built until a stopping criterion is met; e.g., minimum number
    of observations in each leaf.
  prefs: []
  type: TYPE_NORMAL
- en: Once the tree has been fully constructed, one generates ${\bf Y}_{\textrm{mis},(j)}^{(t)}$
    by traversing down the tree to the appropriate leaf using the combinations in
    $(\{\textbf{Y}_{k}^{(t)}:k<j\},\{\textbf{Y}_{k}^{(t-1)}:k>j\})$, and then sampling
    from the $\textbf{Y}_{(j)}^{\textrm{obs}}$ values in that leaf. That is, given
    any combination in $(\{\textbf{Y}_{k}^{(t)}:k<j\},\{\textbf{Y}_{k}^{(t-1)}:k>j\})$,
    one uses the proportion of values of $\textbf{Y}_{j}^{\textrm{obs}}$ in the corresponding
    leaf to approximate the conditional distribution $(\textbf{Y}_{(j)}|\textbf{Y}_{\textrm{obs},(j)},\{\textbf{Y}_{(k)}^{(t)}:k<j\},\{\textbf{Y}_{(k)}^{(t-1)}:k>j\})$.
    The iterative process again continues for $T$ total iterations, and the values
    at the final iteration make up a completed dataset.
  prefs: []
  type: TYPE_NORMAL
- en: MICE-RF instead uses random forests for the univariate conditional models in
    MICE [[46](#bib.bibx46), [45](#bib.bibx45), e.g.,]. Random forests [[49](#bib.bibx49),
    [5](#bib.bibx5)] is an ensemble tree method which builds multiple decision trees
    to the data, instead of a single tree like CART. Specifically, random forests
    constructs multiple decision trees using bootstrapped samples of the original,
    and only uses a sample of the predictors for the recursive partitions in each
    tree. This approach can reduce the prevalence of unstable trees as well as the
    correlation among individual trees significantly, since it prevents the same variables
    from dominating the partitioning process across all trees. Theoretically, this
    decorrelation should result in predictions with less variance [[21](#bib.bibx21)].
  prefs: []
  type: TYPE_NORMAL
- en: For imputation, the analyst first trains a random forests model for each $\textbf{Y}_{(j)}$
    using available cases, given all other variables. Next, the analyst generates
    predictions for ${\bf Y}_{\textrm{mis},j}$ under that model. Specifically, for
    any categorical $\textbf{Y}_{(j)}$, and given any particular combination in $(\{\textbf{Y}_{k}^{(t)}:k<j\},\{\textbf{Y}_{k}^{(t-1)}:k>j\})$,
    the analyst first generates predictions for each tree based on the values $\textbf{Y}_{j}^{\textrm{obs}}$
    in the corresponding leaf for that tree, and then uses the most commonly occurring
    majority level of among all predictions from all the trees. For a continuous $\textbf{Y}_{(j)}$,
    the analyst instead uses the average of all the predictions from all the trees.
    The iterative process again cycles through all the variables, for $T$ total iterations,
    and the values at the final iteration make up a completed dataset. A particularly
    important hyperparameter in random forests is the maximum number of trees $d$.
  prefs: []
  type: TYPE_NORMAL
- en: For our evaluations, we use the mice R package to implement both MICE-CART and
    MICE-RF, and retain the default hyperparameter setting in the package to mimic
    the common practice in real world applications. Specifically, we set the minimum
    number of observations in each terminal leaf to 5 and the pruning threshold to
    0.0001 in MICE-CART. In MICE-RF, the maximum number of trees $d$ is set to be
    10.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 Generative Adversarial Imputation Network (GAIN)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GAIN [[57](#bib.bibx57)] is an imputation method based on GANs [[18](#bib.bibx18)],
    which consist of a generator function G and a discriminator function D. For any
    data matrix ${\bf Y}=({\bf Y}_{\textrm{obs}},{\bf Y}_{\textrm{mis}})$, we replace
    ${\bf Y}_{\textrm{mis}}$ with random noise, $Z_{ij}$, sampled from a uniform distribution.
    The generator G inputs this initialized data and a mask matrix ${\bf M}$, with
    $M_{ij}\in\{0,1\}$ indicating observed values of ${\bf Y}$, and outputs predicted
    values for both the observed data and missing data, $\hat{\bf Y}$. The discriminator
    D utilizes $\hat{\bf Y}$ = (${\bf Y}_{\textrm{obs}}$, $\hat{\bf Y}_{\textrm{mis}}$)
    and a hint matrix ${\bf H}$ of the same dimension to identify which values are
    observed or imputed by G, which results in a predicted mask matrix $\hat{\bf M}$.
    The hint matrix, sampled from the Bernoulli distribution with $p$ equal to a “hint
    rate” hyperparameter, reveals to D partial information about ${\bf M}$ in order
    to help guide G to learn the underlying distribution of ${\bf Y}$.
  prefs: []
  type: TYPE_NORMAL
- en: 'We first train D to minimize the loss function, ${L}_{D}({\bf M},\hat{\bf M})$,
    for each mini-batch of size $n_{i}$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | ${L}_{D}({\bf M},\hat{\bf M})=\sum_{i=1}^{n_{i}}\sum_{j=1}^{J}M_{ij}\,\text{log}(\hat{M}_{ij})+(1-M_{ij})\,\text{log}(1-\hat{M}_{ij}).$
    |  | (2.1) |'
  prefs: []
  type: TYPE_TB
- en: 'Next, G is trained to minimize the loss function ([2.2](#S2.E2 "In 2.2 Generative
    Adversarial Imputation Network (GAIN) ‣ 2 Missing Data Imputation Methods ‣ Are
    deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison")), which is composed of a generator loss, ${L}_{G}({\bf
    M},\hat{\bf M})$, and a reconstruction loss, ${L}_{M}({\bf Y},\hat{\bf Y},{\bf
    M})$. The generator loss ([2.3](#S2.E3 "In 2.2 Generative Adversarial Imputation
    Network (GAIN) ‣ 2 Missing Data Imputation Methods ‣ Are deep learning models
    superior for missing data imputation in surveys? Evidence from an empirical comparison"))
    is minimized when D incorrectly identifies imputed values as being observed. The
    reconstruction loss ([2.4](#S2.E4 "In 2.2 Generative Adversarial Imputation Network
    (GAIN) ‣ 2 Missing Data Imputation Methods ‣ Are deep learning models superior
    for missing data imputation in surveys? Evidence from an empirical comparison"))
    is minimized when the predicted values are similar to the observed values, and
    is weighted by the hyperparameter $\beta$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\displaystyle{L}({\bf Y},\hat{\bf Y},{\bf M},\hat{\bf M})$ | $\displaystyle={L}_{G}({\bf
    M},\hat{\bf M})+\beta{L}_{M}({\bf Y},\hat{\bf Y},{\bf M}),$ |  | (2.2) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle{L}_{G}({\bf M},\hat{\bf M})$ | $\displaystyle=\sum_{i=1}^{n_{i}}\sum_{j=1}^{J}M_{ij}\,\text{log}(1-\hat{M}_{ij}),$
    |  | (2.3) |'
  prefs: []
  type: TYPE_TB
- en: '|  | $\displaystyle{L}_{M}({\bf Y},\hat{\bf Y},{\bf M})$ | $\displaystyle=\sum_{i=1}^{n_{i}}\sum_{j=1}^{J}(1-M_{ij})\,L_{\textrm{rec}}(Y_{ij},\hat{Y}_{ij}),$
    |  | (2.4) |'
  prefs: []
  type: TYPE_TB
- en: where
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L_{\textrm{rec}}(Y_{ij},\hat{Y}_{ij})=\begin{cases}(\hat{Y}_{ij}-Y_{ij})^{2}&amp;\text{if
    $Y_{ij}$ is continuous}\\ -Y_{ij}\,\text{log}\hat{Y}_{ij}&amp;\text{if $Y_{ij}$
    is categorical}.\end{cases}$ |  | (2.5) |'
  prefs: []
  type: TYPE_TB
- en: 'In our experiments, we model both G and D as fully-connected neural networks,
    each with three hidden layers, and $\theta$ hidden units per hidden layer. The
    hidden layer weights are initialized uniformly at random with the Xavier initialization
    method [[16](#bib.bibx16)]. We use leaky ReLU activation function [[33](#bib.bibx33)]
    for each hidden layer, and a softmax activation function for the output layer
    for G in the case of categorical variables, or a sigmoid activation function in
    the case of numerical variables and for the output of D. We facilitate this choice
    of output layer for numerical variables by transforming all continuous variables
    to be within range (0, 1) using the MinMax normalization: $Y_{ij}^{*}=\{Y_{ij}-\text{min}(Y_{\cdot
    j})\}/\{\text{max}(Y_{\cdot j})-\text{min}(Y_{\cdot j})\}$, where $\text{min}(Y_{\cdot
    j})$ and $\text{max}(Y_{\cdot j})$ are the minimum and maximum of variable $j$,
    respectively. After imputation, we transform each value back to its original scale.
    We generate multiple imputations using several runs of the model with varying
    initial imputation of the missing values.'
  prefs: []
  type: TYPE_NORMAL
- en: To implement GAIN in our evaluations, we use the same architecture as the one
    in [[57](#bib.bibx57)]. We set $\beta=100$, $\theta$ equal to the number of features
    of the input data, and tune the hint rate on a single simulation. Following the
    common practice in the GAN literature [[4](#bib.bibx4), [19](#bib.bibx19)], we
    track the evolution of GAIN’s generator and discriminator losses, and manually
    tune the hint rate so that the two losses are qualitatively similar. Specifically,
    we first coarsely select the hint rate among {0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7,
    0.8, 0.9 }. Then we determine the final value by an additional fine tuning step.
    In the MAR scenario, for example, after observing that the optimal value is in
    the range (0.1, 0.2), we perform a search among { 0.11, 0.12, 0.13, 0.14, 0.15,
    0.16, 0.17, 0.18, 0.19 }. Finally, we set the optimal hint rate for MCAR and MAR
    scenarios to be 0.3 and 0.13, respectively. We train the networks for 200 epochs
    using stochastic gradient descent (SGD) and mini-batches of size 512 to learn
    the parameter weights. We use the Adam optimizer to adapt the learning rate, with
    an initial rate of 0.001 [[26](#bib.bibx26)].
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 Multiple Imputation using Denoising Autoencoders (MIDA)
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: MIDA [[17](#bib.bibx17), [32](#bib.bibx32)] extends a class of neural networks,
    denoising autoencoders, for MI. An autoencoder is a neural network model trained
    to learn the identity function of the input data. Denoising autoencoders intentionally
    corrupt the input data in order to prevent the networks from learning the identity
    function, but rather a useful low-dimensional representation of the input data.
    The MIDA architecture consists of an encoder and decoder, each modeled as a fully-connected
    neural network with three hidden layers, with $\theta$ hidden units per hidden
    layer. We first perform an initial imputation on missing values using the mean
    for continuous variables and the most frequent label for categorical variables,
    which results in a completed data ${\bf Y}_{0}$. The encoder inputs ${\bf Y}_{0}$,
    and corrupts the input data by randomly dropping out half of the variables. The
    corrupted input data is mapped to a higher dimensional representation by adding
    $\Theta$ hidden units to each successive hidden layer of the encoder. The decoder
    receives output from the encoder, and symmetrically scales the encoding back to
    the original input dimension. All hidden layers use a hyperbolic tangent (tanh)
    activation function, while the output layer of the decoder uses a softmax (sigmoid)
    activation function in the case of categorical (numerical) variables. Multiple
    imputations are generated by using multiple runs with the hidden layer weights
    initialized as a Gaussian random variable.
  prefs: []
  type: TYPE_NORMAL
- en: 'Following [[32](#bib.bibx32)], we train MIDA in two phases: a primary phase
    and fine-tuning phase. In the primary phase, we feed the initially imputed data
    to MIDA and train for $N_{\textrm{prime}}$ epochs. In the fine-tuning phase, MIDA
    is trained for $N_{\textrm{tune}}$ epochs on the output in the primary phase,
    and produces the outcome. The loss function is used in both phases and closely
    resembles the reconstruction loss in GAIN:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $L({Y}_{{ij}_{0}},\hat{Y}_{ij},M_{ij})=\begin{cases}(1-M_{ij})({Y}_{{ij}_{0}}-\hat{Y}_{ij})^{2}&amp;\text{if
    $Y_{ij}$ is continuous}\\ -(1-M_{ij}){Y}_{{ij}_{0}}\,\text{log}\hat{\bf Y}_{{ij}}&amp;\text{if
    $Y_{ij}$ is categorical}.\end{cases}$ |  | (2.6) |'
  prefs: []
  type: TYPE_TB
- en: To implement MIDA in our evaluations, we use the same architecture and tune
    the hyperparameters in a single simulation as in [[32](#bib.bibx32)]. We plot
    the evolution of loss function $L$, and select the number of additional units
    $\Theta$ among {1, 2, 3, 4, 5, 6, 7 ,8, 9, 10 } to reduce the loss. In our experiments,
    we set $\theta$ equal to the number of features of the input data and add $\Theta=7$
    hidden units to each of the three hidden layers of the encoder. We train the model
    for $N_{\textrm{prime}}=100$ epochs in the primary phase and $N_{\textrm{tune}}=2$
    epochs in the fine-tuning phase. Similar as in GAIN, we learn the model parameters
    using SGD with mini-batches of size 512, and use the Adam optimizer to adapt the
    learning rate with the initial rate being 0.001.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Simulation-based evaluation of imputation methods
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Methods for missing data imputation are usually evaluated via real-data based
    simulations [[50](#bib.bibx50)]. Namely, one creates missing values from a complete
    dataset according to a missing data mechanism [[30](#bib.bibx30)], imputes the
    missing values by a specific method, and then compares these imputed values with
    the original “true” values based on some metrics.
  prefs: []
  type: TYPE_NORMAL
- en: We first give a quick review of Rubin’s MI combination rules. Let $Q$ be the
    target estimand in the population, and $q^{(l)}$ and $u^{(l)}$ be the point and
    variance estimate of $Q$ based on the $l$th imputed dataset, respectively. The
    MI point estimate of $Q$ is $\bar{q}_{L}=\sum_{l=1}^{L}q^{(l)}/L$, and the corresponding
    estimate of the variance is equal to $T_{L}=(1+1/L)b_{L}+\bar{u}_{L}$, where $b_{L}=\sum_{l=1}^{L}(q^{(l)}-\bar{q}_{L})^{2}/(L-1)$,
    and $\bar{u}_{L}=\sum_{l=1}^{L}u^{(l)}/L$. The confidence interval of $Q$ is constructed
    using $(\bar{q}_{L}-Q)\sim t_{\nu}(0,T_{L})$, where $t_{v}$ is a $t$-distribution
    with $\nu=(L-1)(1+\bar{u}_{L}/[(1+1/L)b_{L}])^{2}$ degrees of freedom.
  prefs: []
  type: TYPE_NORMAL
- en: The first step in our simulation-based evaluation procedure is choosing a dataset
    with all values observed, which is taken as the “population.” We then choose a
    set of target estimands $Q$ and compute their values from this population data,
    which are taken as the “ground truth.” The estimands are usually summary statistics
    of the variables or parameters in a down-stream analysis model, e.g., a coefficient
    in a regression model [[48](#bib.bibx48), [25](#bib.bibx25)]. Second, we randomly
    draw without replacement $H$ samples of size $n$ from the population data, and
    in each of sample ($h=1,...,H$) create missing data according to a specific missing
    data mechanism and pre-fixed proportion of missingness. Third, for each simulated
    sample with missing data, we create $L$ imputed datasets using the imputation
    method under consideration and construct the point and interval estimate of each
    estimand using Rubin’s rules. Lastly, we compute performance metrics of each estimand
    from the quantities obtained in the previous step.
  prefs: []
  type: TYPE_NORMAL
- en: In the empirical application, we select a large complete subsample from the
    American Community Survey (ACS) — a national survey that bears the hallmarks of
    many big survey data — as our population. Since discrete variables are prevalent
    in the ACS, as well as in most survey data, we focus on the marginal probabilities
    of binary and categorical variables; e.g., a categorical variable with $K$ categories
    has $K-1$ estimands. To evaluate how well the imputation methods preserve the
    multivariate distributional properties, similar to [[1](#bib.bibx1)], we also
    consider the bivariate probabilities of all two-way combinations of categories
    in binary and categorical variables. Another useful metric is the finite-sample
    pairwise correlations between continuous variables. For continuous variables,
    the common estimands are mean, median or variance. To facilitate meaningful comparisons
    of the results between the categorical and continuous variables, we propose to
    discretize each continuous variable into $K$ categories based on the sample quantiles.
    We then evaluate these binned continuous variables as categorical variables based
    on the aforementioned estimands of marginal and bivariate probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'For each estimand $Q$, we consider three metrics. The first metric focuses
    on bias. To accommodate close-to-zero estimands that are prevalent in probabilities
    of categorical variables, we consider the absolute standardized bias (ASB) of
    each estimand $Q$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{ASB}={\sum_{h=1}^{H}&#124;\bar{q}^{(h)}_{L}-Q}&#124;/{(H\cdot Q)},$
    |  | (3.1) |'
  prefs: []
  type: TYPE_TB
- en: where $\bar{q}^{(h)}_{L}$ is the MI point estimate of $Q$ in simulation $h$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The second metric is the relative mean squared error (Rel.MSE), which is the
    ratio between the MSE of estimating $Q$ from the imputed data and that from the
    sampled data before introducing the missing data:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{Rel.MSE}=\frac{\sum_{h=1}^{H}(\bar{q}^{(h)}_{L}-Q)^{2}}{\sum_{h=1}^{H}(\widetilde{Q}^{(h)}-Q)^{2}},$
    |  | (3.2) |'
  prefs: []
  type: TYPE_TB
- en: where $\bar{q}^{(h)}_{L}$ is defined earlier, and $\widetilde{Q}^{(h)}$ is the
    prototype estimator of $Q$, i.e. the point estimate from the complete sampled
    data in simulation $h$.
  prefs: []
  type: TYPE_NORMAL
- en: 'The third metric is coverage rate, which is the proportion of the $\alpha\%$
    (e.g. 95%) confidence intervals, denoted by $\mbox{CI}_{h}^{\alpha}$ ($h=1,...,H$),
    in the $H$ simulations that contain the true $Q$:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{Coverage}=\sum_{h=1}^{H}\mathbf{1}\{Q\in\mbox{CI}_{h}^{\alpha}\}/H.$
    |  | (3.3) |'
  prefs: []
  type: TYPE_TB
- en: 'We recommend conducting a large number of simulations (e.g. $H\geq 100$) to
    obtain reliable estimates of MSE and coverage. This would not be a problem for
    deep learning algorithms, which can be typically completed in seconds even with
    large sample sizes. However, it can be computationally prohibitive for the MICE
    algorithms when each of the simulated data is large (e.g. $n=100,000$ in some
    of our simulations). In the situation that one has to rely on only a few or even
    a single simulation for evaluation, we propose a modified metric of bias. Specifically,
    for each categorical variable or binned continuous variable $j$ , we define the
    weighted absolute bias (WAB) as the sum of the absolute bias weighted by the true
    marginal probability in each category:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{Weighted absolute bias}=\sum_{k=1}^{K}Q_{jk}\left&#124;\bar{q}^{(h)}_{jk}-Q_{jk}\right&#124;,$
    |  | (3.4) |'
  prefs: []
  type: TYPE_TB
- en: where $K$ is the total number of categories, $Q_{jk}$ is the population marginal
    probability of category $k$ in variable $j$, and $\bar{q}^{(h)}_{jk}$ is its corresponding
    point estimate in simulation $h$. We can also average the weighted absolute bias
    over a number of repeatedly simulated samples.
  prefs: []
  type: TYPE_NORMAL
- en: The above procedure and metrics differ from the common practice in the machine
    learning literature. For example, many machine learning papers on missing data
    imputation conduct simulations on benchmark datasets, but these data often have
    vastly different structure and features from survey data and thus are less informative
    for the goal of this paper. One such dataset is the Breast Cancer dataset in the
    UCI Machine Learning Repository [[13](#bib.bibx13)], which has only 569 sample
    units and no categorical variables. Also, these simulations are usually based
    on randomly creating missing values of a single dataset repeatedly rather than
    on drawing repeated samples from a population, and thus fails to account for the
    sampling mechanism. Moreover, these evaluations often use metrics focusing on
    accuracy of individual predictions rather than distributional features. Specifically,
    the most commonly used metrics are the root mean squared error (RMSE) and accuracy
    [[17](#bib.bibx17), [57](#bib.bibx57), [32](#bib.bibx32)]. Both metrics can be
    defined in an overall or variable-specific fashion, but the machine learning literature
    usually focuses on the overall version. The overall RMSE is defined as
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{RMSE}=\sqrt{\frac{\sum^{n}_{i=1}\sum_{j}M_{ij}(\hat{Y}_{ij}-Y_{ij})^{2}}{\sum^{n}_{i=1}\sum_{j}M_{ij}}},$
    |  | (3.5) |'
  prefs: []
  type: TYPE_TB
- en: 'where $Y_{ij}$ is the value of continuous variable $j$ for individual $i$ in
    the complete data before introducing missing data, and $\hat{Y}_{ij}$ is the corresponding
    imputed value. For non-missing values (i.e. $M_{ij}=1$), $Y_{ij}=\hat{Y}_{ij}$.
    The (overall) accuracy is defined for categorical variables, namely it is the
    proportion of the imputed values being equal to the corresponding original “true”
    value:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\text{Accuracy}=\frac{\sum^{n}_{i=1}\sum_{j\in S_{cat}}M_{ij}\mathbbm{1}(\hat{Y}_{ij}=Y_{ij})}{\sum^{n}_{i=1}\sum_{j\in
    S_{cat}}M_{ij}},$ |  | (3.6) |'
  prefs: []
  type: TYPE_TB
- en: where $S_{cat}$ is the set of categorical variables.
  prefs: []
  type: TYPE_NORMAL
- en: A number of caveats are in order for the RMSE and accuracy metrics. First, they
    are usually computed on a single imputed sample as an overall measure of an imputation
    method, but this ignores the uncertainty of imputations. Second, both RMSE and
    accuracy are single value summaries and do not capture the multivariate distributional
    feature of data. Third, RMSE does not adjust for the different scale of variables
    and can be be easily dominated by a few outliers; also, it is often computed without
    differentiating between continuous and categorical variables. Lastly, when there
    are multiple ($L$) imputed data, a common way is to use the mean of the $L$ imputed
    value as $\hat{Y}_{ij}$ in ([3.5](#S3.E5 "In 3 Simulation-based evaluation of
    imputation methods ‣ Are deep learning models superior for missing data imputation
    in surveys? Evidence from an empirical comparison")), but the statistical meaning
    of the resulting metrics is opaque. This is particularly problematic for categorical
    variables. For these reasons, we warn against using the overall RMSE and accuracy
    as the only metrics for comparing imputation methods, and one should exercise
    caution when interpreting them.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Evaluation based on ACS
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we evaluate the four imputation methods described in Section
    [2](#S2 "2 Missing Data Imputation Methods ‣ Are deep learning models superior
    for missing data imputation in surveys? Evidence from an empirical comparison")
    following the procedure and metrics described in Section [3](#S3 "3 Simulation-based
    evaluation of imputation methods ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison"). For simplicity,
    in the following discussions we use CART and RF to denote MICE-CART and MICE-RF,
    respectively.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 The “population” data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We use the one-year Public Use Microdata Sample from the 2018 ACS to construct
    our population. The 2018 ACS data contains both household-level variables — for
    example, whether or not a house is owned or rented — and individual-level variables
    — for example, age, income and sex of the individuals within each household. Since
    individuals nested within a household are often dependent, and the imputation
    methods we evaluate generally assume independence across all observations, we
    set our unit of observation at the household-level, where independence is more
    likely to hold. We first remove units corresponding to vacant houses. Next, we
    delete units with any missing values, so that we only keep the complete cases.
    Within each household, we also retain individual-level data corresponding only
    to the household head and merge them with the household-level variables, resulting
    in a rich set of variables with potentially complex joint relationships.
  prefs: []
  type: TYPE_NORMAL
- en: It is often challenging to generate plausible imputations for ordinal variables
    with many levels when there is very low mass at the highest levels, as is the
    case for some variables in the ACS data. Following [[28](#bib.bibx28)], we treat
    ordinal variables with more than 10 levels as continuous variables. We also follow
    the approach in [[1](#bib.bibx1)] to exclude binary variables where the marginal
    probabilities violate $np>10$ or $n(1-p)>10$; this eliminates estimands where
    the central limit theorem is not likely to hold. For each categorical variable
    with more than two levels but less than 10 levels where this might also be a problem,
    we merge the levels with a small number of observations in the population data.
    For example, for the household language variable, we recode the levels from five
    to three (English, Spanish, and other), because the probability of speaking neither
    English nor Spanish in the full population is less than 8.8%.
  prefs: []
  type: TYPE_NORMAL
- en: The final population data contains 1,257,501 units, with 18 binary variables,
    20 categorical variables with 3 to 9 levels, and 8 continuous variables. We describe
    the variables in more detail in the supplementary material. We compute the population
    values of the estimands $Q$ described in Section [3](#S3 "3 Simulation-based evaluation
    of imputation methods ‣ Are deep learning models superior for missing data imputation
    in surveys? Evidence from an empirical comparison"), including all marginal and
    bivariate probabilities of discrete and binned continuous variables. We vary the
    size of the simulated samples from 10,000 to 100,000, and simulate missing data
    according to either missing completely at random (MCAR) or missing at random (MAR)
    mechanisms in each of these scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Simulations with n=10,000
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We first randomly draw $H=100$ samples of size $n=10,000$, and set $30\%$ of
    each sample to be missing under either MCAR or MAR. CART or RF takes around 2.8
    and 9.2 hours, respectively, to create $L=10$ imputed datasets with default parameters
    on a standard desktop computer with a single central processing unit (CPU). The
    deep learning methods are much faster because they leverage GPU computing power
    when implemented on the GPU-enabled TensorFlow software framework [[35](#bib.bibx35)].
    GAIN takes roughly 1.5 minutes and MIDA takes roughly 4 minutes to create $L=10$
    completed datasets using a GeForce GTX 1660 Ti GPU. Note that it is infeasible
    to manually tune the hyperparameter in each of the 100 simulations in each scenario
    for the deep learning models. So for each scenario, we have randomly selected
    one simulation, and tune the hyperparameters using the procedure described in
    Section [2](#S2 "2 Missing Data Imputation Methods ‣ Are deep learning models
    superior for missing data imputation in surveys? Evidence from an empirical comparison").
    We then apply these selected hyperparameters to all simulations.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 MCAR scenario
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To create the MCAR scenario, we randomly set 30% of the values of each variable
    to be missing independently. Table [4.1](#S4.T1 "Table 4.1 ‣ 4.2.1 MCAR scenario
    ‣ 4.2 Simulations with n=10,000 ‣ 4 Evaluation based on ACS ‣ Are deep learning
    models superior for missing data imputation in surveys? Evidence from an empirical
    comparison") displays the distributions of the estimated ASB and relative MSE
    of all the marginal and bivariate probabilities in the imputed data by the four
    imputation methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4.1: Distributions of absolute standardized bias $(\times 100)$ and relative
    mean squared error of all marginal and bivariate probabilities based on the imputations
    by the four MI methods, when $n=10,000$ and 30% values MCAR. “Cat.” means categorical
    variables and “B.Cont.” means binned continuous variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Quantiles | Marginal |  | Bivariate |'
  prefs: []
  type: TYPE_TB
- en: '| CART | RF | GAIN | MIDA |  | CART | RF | GAIN | MIDA |'
  prefs: []
  type: TYPE_TB
- en: '| ASB $(\times 100)$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 0.05 | 0.47 | 0.76 | 0.98 |  | 0.15 | 1.14 | 1.21 | 1.54 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 0.13 | 1.25 | 1.48 | 2.22 |  | 0.40 | 2.83 | 3.08 | 3.93 |'
  prefs: []
  type: TYPE_TB
- en: '| Cat. | 50% | 0.27 | 2.80 | 3.22 | 4.69 |  | 1.05 | 6.74 | 7.14 | 8.47 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 0.64 | 5.86 | 7.18 | 8.86 |  | 2.51 | 13.59 | 17.03 | 15.23 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 1.14 | 10.01 | 19.55 | 14.41 |  | 5.34 | 22.33 | 26.92 | 21.90 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 0.06 | 0.24 | 7.25 | 2.73 |  | 0.19 | 1.30 | 6.05 | 4.80 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 0.10 | 1.05 | 12.86 | 8.36 |  | 0.43 | 3.24 | 17.61 | 12.01 |'
  prefs: []
  type: TYPE_TB
- en: '| B.Cont. | 50% | 0.21 | 3.59 | 27.30 | 18.51 |  | 1.02 | 6.61 | 34.29 | 24.07
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 0.43 | 5.43 | 30.21 | 26.84 |  | 1.90 | 11.76 | 49.38 | 39.54 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 0.81 | 8.49 | 46.41 | 31.36 |  | 3.42 | 20.79 | 90.90 | 64.65 |'
  prefs: []
  type: TYPE_TB
- en: '| Rel.MSE |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 1.05 | 1.67 | 2.50 | 3.38 |  | 0.96 | 1.11 | 2.75 | 2.98 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 1.16 | 2.40 | 4.97 | 9.03 |  | 1.08 | 1.61 | 4.33 | 4.75 |'
  prefs: []
  type: TYPE_TB
- en: '| Cat. | 50% | 1.37 | 5.99 | 10.37 | 14.89 |  | 1.25 | 3.35 | 7.40 | 8.16 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 1.49 | 10.25 | 27.73 | 26.16 |  | 1.48 | 9.07 | 14.87 | 15.80 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 1.62 | 16.22 | 97.33 | 40.16 |  | 1.89 | 23.91 | 36.37 | 27.92 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 1.19 | 1.50 | 44.06 | 4.35 |  | 0.82 | 0.86 | 7.40 | 2.05 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 1.30 | 1.77 | 74.42 | 13.82 |  | 0.92 | 1.11 | 14.80 | 4.90 |'
  prefs: []
  type: TYPE_TB
- en: '| B.Cont. | 50% | 1.44 | 3.31 | 139.24 | 72.57 |  | 1.07 | 1.90 | 32.26 | 13.76
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 1.55 | 6.71 | 284.00 | 150.35 |  | 1.26 | 4.09 | 88.78 | 47.56 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 1.64 | 19.69 | 603.38 | 451.44 |  | 1.54 | 10.80 | 282.29 | 127.15
    |'
  prefs: []
  type: TYPE_TB
- en: Overall, for the estimands of marginal and bivariate probabilities of the categorical
    and binned continuous variables, MICE with CART significantly outperforms all
    other three methods, with consistently yielding the smallest ASB and relative
    MSE. RF is the second best, also consistently outperforming the deep learning
    methods. The advantage of the MICE algorithms is particularly pronounced in the
    upper (e.g. 75% and 90%) quantiles, indicating that GAIN and MIDA imputations
    have large variations over repeated samples and variables. Indeed, MIDA and GAIN
    lead to ultra long tails in estimating the summary statistics of the variables.
    For example, for bivariate probabilities of binned continuous variables, the 90%
    percentile of the ASB from MIDA and GAIN is approximately 20 and 27 times, respectively,
    of that from CART. The discrepancy is even bigger for relative MSE. There is no
    consistent pattern in comparing MIDA and GAIN. Specifically, for continuous variables,
    MIDA generally outperforms GAIN, but the difference is small except for the upper
    percentiles, where GAIN tends to produce very large bias and relative MSE. For
    categorical variables, GAIN outperforms MIDA half of the time, but again leads
    to the largest variation in imputations across the variables. Moreover, an interesting
    and somewhat surprising observation is that MICE with CART consistently outperforms
    RF—sometimes by a large magnitude—regardless of the choice of estimand or metric.
  prefs: []
  type: TYPE_NORMAL
- en: All methods generally yield less biased estimates (i.e. smaller ASB) of the
    marginal probabilities than the bivariate probabilities. This illustrates preserving
    multivariate distributional features is more challenging than univariate ones.
    The advantage of CART over the other methods is comparatively larger when estimating
    bivariate estimands than univariate ones. Interestingly, the relative MSE tends
    to be higher for the marginal probabilities than the bivariate probabilities.
    This is likely due to the fact that the denominator in the definition of relative
    MSE in ([3.2](#S3.E2 "In 3 Simulation-based evaluation of imputation methods ‣
    Are deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison")) is the MSE from the sampled data before introducing
    missing data, which tends to be smaller for marginal probabilities than bivariate
    probabilities. CART yields MSEs that are very close to the corresponding MSEs
    from the sampled data before introducing missing data; i.e., the relative MSE
    is close to 1\. On the contrary, both deep learning methods, and GAIN in particular,
    can result in exceedingly large relative MSE for many estimands.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f4062de7ffe73be405a1c58ad3a9dee1.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.1: Coverage rate of the 95% confidence interval for all marginal and
    bivariate probabilities obtained from the four imputation methods in the simulations
    with $n=10,000$ and 30% values MCAR. The red dashed line is 0.95.'
  prefs: []
  type: TYPE_NORMAL
- en: Figures [4.1](#S4.F1 "Figure 4.1 ‣ 4.2.1 MCAR scenario ‣ 4.2 Simulations with
    n=10,000 ‣ 4 Evaluation based on ACS ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison") displays the
    estimated coverage rates of the $95\%$ confidence intervals for the marginal and
    bivariate probabilities. The patterns on coverage between different methods is
    similar to those on bias and MSE. Specifically, CART tends to result in coverage
    rates that are close to the nominal $95\%$ level, with the median consistently
    being around 95% and tight interquartile range. In contrast, RF, GAIN and MIDA
    all result in coverage rates that are much farther off from the nominal $95\%$
    level. For example, the median coverage rates under both GAIN and MIDA are all
    under 0.60, and are even less than 0.30 for continuous variables. A closer look
    into the prediction accuracy of each variable reveals that GAIN and MIDA tend
    to generate imputations that are biased toward the most frequent levels, and GAIN
    in particular generally produces narrower intervals than the other methods. This
    once again provides evidence of significant bias under the deep learning methods.
    All methods tend to result in higher median coverage rates for the bivariate probabilities
    than the marginal probabilities, although the left tails are generally longer
    for the former than the latter.
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 MAR scenario
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We also consider a MAR scenario, which is more plausible than MCAR in practice.
    We set six variables — age, gender, marital status, race, educational attainment
    and class of worker — to be fully observed. It would be cumbersome to specify
    different MAR mechanism for each of the remaining 40 variables, so we randomly
    divide them into three groups, consisting of 10, 15, and 15 variables. We then
    specify a separate nonresponse model by which to generate the missing data for
    the variables in each group. Specifically, we postulate a logistic model per group,
    conditional on the fully observed six variables, based on which we then generate
    binary missing data indicators for each variable in that group. This process results
    in approximately 30% missing rate for each of the 40 variables. We describe the
    models in more detail in the supplementary material.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4.2: Distributions of absolute standardized bias $(\times 100)$ and relative
    mean squared error for all methods, when $n=10,000$ and 30% values MAR, over all
    possible marginal and bivariate probabilities. “Cat.” means categorical variables
    and “B.Cont.” means binned continuous variables.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Quantiles | Marginal |  | Bivariate |'
  prefs: []
  type: TYPE_TB
- en: '| CART | RF | GAIN | MIDA |  | CART | RF | GAIN | MIDA |'
  prefs: []
  type: TYPE_TB
- en: '| ASB $(\times 100)$ |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 0.05 | 0.13 | 0.15 | 0.14 |  | 0.15 | 0.71 | 0.76 | 0.89 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 0.11 | 0.44 | 0.62 | 0.61 |  | 0.40 | 2.23 | 2.55 | 3.20 |'
  prefs: []
  type: TYPE_TB
- en: '| Cat. | 50% | 0.29 | 2.13 | 3.05 | 4.55 |  | 1.08 | 6.06 | 6.85 | 8.14 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 1.04 | 4.98 | 6.63 | 10.22 |  | 2.49 | 13.43 | 16.78 | 16.19 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 1.80 | 10.49 | 18.91 | 17.00 |  | 5.68 | 24.06 | 28.04 | 25.36 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 0.07 | 0.29 | 0.33 | 0.33 |  | 0.27 | 1.17 | 10.87 | 6.18 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 0.17 | 1.07 | 9.64 | 3.13 |  | 0.69 | 3.49 | 23.67 | 16.26 |'
  prefs: []
  type: TYPE_TB
- en: '| B.Cont. | 50% | 0.67 | 3.14 | 32.86 | 23.85 |  | 1.58 | 7.83 | 38.52 | 31.17
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 1.20 | 6.95 | 39.57 | 36.09 |  | 3.40 | 15.20 | 53.59 | 47.34 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 3.40 | 12.39 | 63.45 | 41.99 |  | 5.94 | 25.16 | 97.47 | 85.44 |'
  prefs: []
  type: TYPE_TB
- en: '| Rel.MSE |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 1.00 | 1.00 | 1.00 | 1.00 |  | 0.97 | 1.00 | 1.53 | 1.93 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 1.08 | 1.82 | 2.56 | 4.75 |  | 1.04 | 1.39 | 3.78 | 4.03 |'
  prefs: []
  type: TYPE_TB
- en: '| Cat. | 50% | 1.33 | 4.33 | 19.03 | 15.13 |  | 1.25 | 3.00 | 10.42 | 8.38
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 1.72 | 13.08 | 55.07 | 33.36 |  | 1.59 | 9.56 | 27.45 | 16.95 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 2.27 | 18.70 | 101.91 | 48.44 |  | 2.23 | 27.44 | 64.01 | 32.85
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 10% | 1.00 | 1.00 | 1.00 | 1.00 |  | 0.88 | 0.90 | 11.19 | 2.96 |'
  prefs: []
  type: TYPE_TB
- en: '|  | 25% | 1.38 | 1.83 | 90.98 | 8.49 |  | 1.00 | 1.16 | 20.15 | 6.87 |'
  prefs: []
  type: TYPE_TB
- en: '| B.Cont. | 50% | 1.70 | 4.57 | 207.58 | 96.08 |  | 1.18 | 2.29 | 45.25 | 21.33
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 75% | 2.12 | 11.47 | 692.67 | 239.69 |  | 1.50 | 6.95 | 125.39 | 70.90
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | 90% | 3.12 | 50.56 | 1342.23 | 806.43 |  | 2.12 | 18.07 | 459.78 | 205.14
    |'
  prefs: []
  type: TYPE_TB
- en: Table [4.2](#S4.T2 "Table 4.2 ‣ 4.2.2 MAR scenario ‣ 4.2 Simulations with n=10,000
    ‣ 4 Evaluation based on ACS ‣ Are deep learning models superior for missing data
    imputation in surveys? Evidence from an empirical comparison") displays the distributions
    of the ASB and relative MSE of all the marginal and bivariate probabilities from
    the four methods. All methods yield larger ASB and relative MSE under the MAR
    scenario than the previous MCAR scenario. This is expected because MAR is a stronger
    assumption than MCAR that requires conditioning on more information. Nonetheless,
    the overall patterns of relative performance between the methods remain the same
    as those under MCAR. Specifically, CART once again produces estimates with the
    least ASB and relative MSE — by an even larger margin then under MCAR — among
    the four methods, followed by RF, and then MIDA and GAIN. One notable observation
    is the deteriorating performance of the deep learning methods, particularly GAIN,
    in imputing continuous variables, sometimes resulting in several hundreds fold
    of relative MSE than CART. This indicates the huge uncertainties associated with
    GAIN in imputing continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/3683d387833d781e2e8e0bf98ea57e4d.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.2: Coverage rates of the 95% confidence intervals for all marginal
    and bivariate probabilities obtained from four methods in the simulations with
    $n=10,000$ and 30% values MAR. The red dashed line is 0.95.'
  prefs: []
  type: TYPE_NORMAL
- en: Figures [4.2](#S4.F2 "Figure 4.2 ‣ 4.2.2 MAR scenario ‣ 4.2 Simulations with
    n=10,000 ‣ 4 Evaluation based on ACS ‣ Are deep learning models superior for missing
    data imputation in surveys? Evidence from an empirical comparison") displays the
    estimated coverage rates of the $95\%$ confidence intervals for the marginal and
    bivariate probabilities, under each method. Similar as the case of bias and MSE,
    all methods generally result in lower coverage rates under MAR than MCAR, with
    visibly longer left tails in some cases, but the overall patterns comparing between
    the methods remain the same. Specifically, CART still tends to result in coverage
    rates that are above 90%, while the other three methods have consistently lower
    coverage rate. In particular, both GAIN and MIDA result in extremely low—below
    7%– median coverage rates for continuous variables. This is closely related to
    the previous observation of the large uncertainty of the deep learning methods
    in imputing continuous variables.
  prefs: []
  type: TYPE_NORMAL
- en: Finally, to illustrate that evaluating only the overall RMSE and accuracy metrics
    may be misleading, we display the mean and empirical standard errors of the overall
    RMSE and accuracy over the 100 simulations in Table [4.3](#S4.T3 "Table 4.3 ‣
    4.2.2 MAR scenario ‣ 4.2 Simulations with n=10,000 ‣ 4 Evaluation based on ACS
    ‣ Are deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison"), where MCAR is in the top panel and MAR is in the
    bottom panel. Under both missing data mechanisms, for the continuous variables,
    MIDA leads to the smallest overall RMSE, followed by CART, and with RF and GAIN
    being last. For the categorical variables, CART and GAIN lead to the highest overall
    accuracy, with MIDA being closely behind and RF last. These patterns, not surprisingly,
    differ from those reported earlier based on marginal and bivariate probabilities
    and different metrics. As discussed in Section [3](#S3 "3 Simulation-based evaluation
    of imputation methods ‣ Are deep learning models superior for missing data imputation
    in surveys? Evidence from an empirical comparison"), overall RMSE and accuracy
    do not capture the distributional features of multivariate data or the repeated
    sampling properties of the imputation methods.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4.3: Overall RMSE on continuous variables and overall accuracy on categorical
    variables averaged over 100 simulations, with the empirical standard errors in
    the parenthesis. The top panel is under MCAR and the bottom panel is under MAR,
    all with 30% missing data.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Mechanism | Metric | CART | RF | GAIN | MIDA |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '|  | RMSE | 0.128 (0.002) | 0.159 (0.003) | 0.161 (0.008) | 0.112 (0.002) |'
  prefs: []
  type: TYPE_TB
- en: '| MCAR | Accuracy | 0.785 (0.001) | 0.658 (0.003) | 0.782 (0.002) | 0.752 (0.004)
    |'
  prefs: []
  type: TYPE_TB
- en: '|  | RMSE | 0.130 (0.003) | 0.154 (0.004) | 0.145 (0.009) | 0.110 (0.002) |'
  prefs: []
  type: TYPE_TB
- en: '| MAR | Accuracy | 0.819 (0.001) | 0.704 (0.003) | 0.820 (0.002) | 0.780 (0.007)
    |'
  prefs: []
  type: TYPE_TB
- en: 4.3 Simulations with n=100,000 and 30% MCAR
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Deep learning models usually require a large sample size to train. Therefore,
    to give MIDA and GAIN a more favorable setting as well as to investigate the sensitivity
    of our results to variations in sample size, we generate a simulation scenario
    of $H=10$ samples with $n=100,000$ under MCAR. That is, we randomly set 30% of
    the values of each variable to be missing independently. Here we only generate
    10 simulations due to the huge computational cost of MICE for samples with this
    size. In this scenario, we omit RF because the previous results in Section [4.2](#S4.SS2
    "4.2 Simulations with n=10,000 ‣ 4 Evaluation based on ACS ‣ Are deep learning
    models superior for missing data imputation in surveys? Evidence from an empirical
    comparison") have shown that RF is consistently inferior to CART in terms of performance
    and computation. We use CART, GAIN, and MIDA to create $L=10$ completed datasets.
  prefs: []
  type: TYPE_NORMAL
- en: Because it usually requires a much larger number of simulations to reliably
    calculate MSE and coverage, here we focus on the weighted absolute bias metric
    ([3.4](#S3.E4 "In 3 Simulation-based evaluation of imputation methods ‣ Are deep
    learning models superior for missing data imputation in surveys? Evidence from
    an empirical comparison")). Table [4.4](#S4.T4 "Table 4.4 ‣ 4.3 Simulations with
    n=100,000 and 30% MCAR ‣ 4 Evaluation based on ACS ‣ Are deep learning models
    superior for missing data imputation in surveys? Evidence from an empirical comparison")
    displays the distributions of the estimated weighted absolute bias, averaged over
    10 simulations, of the marginal probabilities of the categorical and binned continuous
    variables. Overall, the patterns comparing between the four methods remain consistent
    with those observed in Section [4.2](#S4.SS2 "4.2 Simulations with n=10,000 ‣
    4 Evaluation based on ACS ‣ Are deep learning models superior for missing data
    imputation in surveys? Evidence from an empirical comparison"). Specifically,
    CART again results in the smallest weighted absolute difference in both categorical
    and continuous variables, and the advantage is particularly pronounced with continuous
    variables. For example, for categorical variables, MIDA and GAIN result in a median
    of weighted absolute bias at least 9 and 11 times, respectively, larger than CART.
    The advantage of CART grows to about 30 and 60 times over MIDA and GAIN, respectively,
    for continuous variables. Moreover, CART performs robustly across variables, evident
    from the small variation in the weighted absolute bias, e.g. 0.07 for 10% percentile
    and 0.33 for 90% percentile among the categorical variables. In contrast, both
    deep learning models result in much larger variation across variables; e.g., 0.57
    for 10% percentile and 2.92 for 90% percentile among the categorical variables
    under MIDA, and even larger for GAIN. In summary, other than computational time,
    MICE with CART significantly outperforms MIDA and GAIN in terms of bias and variance
    regardless of the sample size.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 4.4: Distributions of the weighted absolute bias $(\times 100)$ averaged
    over 10 simulated samples, each with $n=100,000$ and 30% values MCAR.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Quantiles | Categorical |  | Binned Continuous |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| CART | GAIN | MIDA |  | CART | GAIN | MIDA |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 10% | 0.07 | 0.43 | 0.57 |  | 0.10 | 5.52 | 1.98 |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 0.11 | 1.11 | 1.02 |  | 0.11 | 6.65 | 2.78 |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 0.15 | 1.74 | 1.40 |  | 0.12 | 7.36 | 4.04 |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 0.24 | 3.77 | 2.07 |  | 0.13 | 9.40 | 6.50 |'
  prefs: []
  type: TYPE_TB
- en: '| 90% | 0.33 | 4.63 | 2.92 |  | 0.15 | 11.31 | 7.72 |'
  prefs: []
  type: TYPE_TB
- en: 4.4 Role of hyperparameters in tree-based MICE
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The pattern that CART outperforms RF is surprising, because the common knowledge
    is that ensemble methods are usually superior to single tree methods. But the
    same pattern was also observed in another recent study [[56](#bib.bibx56)]. We
    investigate the role of the key hyperparameter in RF—the maximum number of trees
    $d$—in the simulations. We randomly selected a simulated data of size $n=10,000$
    and 30% of entries being MCAR. We use the mice package to fit RF with different
    number of trees: $d=2,5,10,15,20$, where $d=10$ is the default setting. The relative
    MSE of the imputed categorical variables fitted using each $d$ value, as well
    as that using CART, is shown as trajectories in Figure [4.3](#S4.F3 "Figure 4.3
    ‣ 4.4 Role of hyperparameters in tree-based MICE ‣ 4 Evaluation based on ACS ‣
    Are deep learning models superior for missing data imputation in surveys? Evidence
    from an empirical comparison"), which reveals a consistent pattern: the upper
    quantiles —particularly those above 50%—of the relative MSE deteriorates rapidly
    as the maximum number of trees in RF increases, while the lower quantiles, e.g.,
    10%, 25%, remain stable. We found a similar pattern with the standardized bias
    metric and continuous variables, and thus the results are omitted here. This suggests
    that larger number of trees in RF—at least as implemented in the mice package—leads
    to much longer tail in the distribution of the bias and MSEs. This is likely due
    to overfitting. We cannot exclude the possibility that a more customized hyperparameter
    tuning of RF may outperform CART in some applications. However, such case-specific
    fine-tuning of the MICE algorithm is generally not available for the vast majority
    of MI consumers who relies on the default setting of popular packages like mice.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c8456985090b23bea055d2c03cfd308c.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4.3: Quantiles of the relative mean squared error over all marginal
    and bivariate probabilities of categorical variables, under CART and RF with various
    number of trees, for a simulation sample with $n=10,000$ and $30\%$ values MCAR.'
  prefs: []
  type: TYPE_NORMAL
- en: 5 Evaluation based on “benchmark” datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To verify the evaluations in the GAIN and MIDA papers [[17](#bib.bibx17), [57](#bib.bibx57),
    [32](#bib.bibx32)], we also compared the two deep learning models with CART based
    on the five benchmark datasets and simulation procedure (different from our proposed
    framework) used in these papers. Details of these datasets and simulations are
    presented in the supplementary material. The sample sizes of these data are generally
    not large enough to be considered as population data from which we can repeatedly
    sample from without replacement, so we are unable to evaluate them in a meaningful
    way using absolute standardized bias, relative MSE or coverage. We therefore evaluate
    the methods primarily on the weighted absolute bias metric. In summary, CART again
    consistently and significantly outperforms MIDA and GAIN in terms of weighted
    absolute bias for both categorical and continuous variables, across all five benchmark
    datasets. The difference in performance is particularly pronounced with continuous
    variables. We also calculated the overall MSE and accuracy as those papers did.
    Except for one dataset, we could not reproduce the results reported in these papers,
    even with the authors’ code. One possible reason is that the process of tuning
    and selecting model hyperparameters may not be clearly documented, which is true
    in the present case. More details are provided in the online supplementary material.
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Recent years have seen the development of many machine learning based methods
    for imputing missing data, raising the hope of improving over the more traditional
    imputation methods such as MICE. However, efforts in evaluating these methods
    in real world situations remain scarce. In this paper, we adopt an evaluation
    framework real-data-based simulations. We conduct extensive simulation studies
    based on the American Community Survey to compare repeated sampling properties
    of two MICE methods and two deep learning imputation methods based on GAN (GAIN)
    and denoising autoencoders (MIDA).
  prefs: []
  type: TYPE_NORMAL
- en: We find that the deep learning models hold a vast computational advantage over
    MICE methods, partially because they can leverage GPU power for high-performance
    computing. However, our simulations as well as evaluation on several “benchmark"
    data suggest that MICE with CART specification of the conditional models consistently
    outperforms, usually by a substantial margin, the deep learning models in terms
    of bias, mean squared error, and coverage under a wide range of realistic settings.
    In particular, GAIN and MIDA tend to generate unstable imputations with enormous
    variations over repeated samples compared with MICE. One possible explanation
    is that deep neural networks excel at detecting complex sub-structures of big
    data, but may not suit for data with simple structure, such as the simulated data
    used here. Another possibility is that the sample sizes in our simulations are
    not adequate to train deep neural networks, which usually required much more data
    compared to traditional statistical models.
  prefs: []
  type: TYPE_NORMAL
- en: These results contradict previous findings based on the single performance metric
    of overall mean squared error in the machine learning literature [[17](#bib.bibx17),
    [57](#bib.bibx57), [32](#bib.bibx32), e.g.]. This discrepancy highlights the pitfalls
    of the common practice in the machine learning literature of evaluating imputation
    methods. It also demonstrates the importance of assessing repeated-sampling properties
    on multiple estimands of MI methods. An interesting finding is that ensemble trees
    (e.g. RF) do not improve over a single tree (e.g. CART) in the context of MICE,
    which matches the findings in another recent study [[56](#bib.bibx56)]. Combined
    with the fact that the former is more computationally intensive than the latter,
    we recommend using MICE with CART instead of RF in practice.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our study has a few limitations. First, there are many deep learning methods
    that can be adapted to missing data imputation and all may have different operating
    characteristics. We choose GAIN and MIDA because both generative adversarial network
    and denoising autoencoders are immensely popular deep learning methods, and the
    imputation methods based on them have been advertised as superior to MICE. Nonetheless,
    it would be desirable to examine other deep learning based imputation methods
    in future research. Second, performance of machine learning methods is highly
    dependent on hyperparameter selection. So it can be argued that the inferior performance
    of GAIN and MIDA may be at least partially due to sub-optimal hyperparameter selection.
    However, practitioners would most likely rely on default hyperparameter values
    for any machine learning based imputation methods, which is indeed what we have
    adopted in our simulations and thus represents the real practice. Third, we did
    not consider the joint distribution between any categorical and continuous variables,
    but our evaluations within categorical and continuous variables have yielded consistent
    conclusions. Lastly, as any simulation study, one should exercise caution in generalizing
    the conclusions. By carefully selecting the data and metrics, we have attempted
    to closely mimic the settings representative of real survey data so that our conclusions
    are informative for practitioners who deal with similar situations. Additional
    evaluation studies based on different data are desired to shed more insights on
    the operating characteristics and comparative performances of different missing
    data imputation methods. Data, code, and supplementary material for the paper
    are available at: [https://github.com/zhenhua-wang/MissingData_DL](https://github.com/zhenhua-wang/MissingData_DL).'
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Poulos and Li’s research is supported by the National Science Foundation under
    Grant DMS-1638521 to the Statistical and Applied Mathematical Sciences Institute.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Olanrewaju Akande, Fan Li and Jerome Reiter “An empirical comparison of
    multiple imputation methods for categorical data” In *The American Statistician*
    71.2 Taylor & Francis, 2017, pp. 162–170'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] B.. Arnold and S.. Press “Compatible Conditional Distributions” In *Journal
    of the American Statistical Association* 84, 1989, pp. 152–156'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] John Barnard and Xiao-Li Meng “Applications of multiple imputation in medical
    studies: from AIDS to NHANES” In *Statistical Methods in Medical Research* 8.1
    Sage Publications Sage CA: Thousand Oaks, CA, 1999, pp. 17–36'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] David Berthelot, Tom Schumm and Luke Metz “BEGAN: Boundary Equilibrium
    Generative Adversarial Networks” In *CoRR* abs/1703.10717, 2017 arXiv: [http://arxiv.org/abs/1703.10717](http://arxiv.org/abs/1703.10717)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] L. Breiman “Random forests” In *Machine Learning* 45, 2001, pp. 5–32'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] L. Breiman, J.. Friedman, R.. Olshen and C.. Stone “Classification and
    Regression Trees” Belmont, CA: Wadsworh, Inc., 1984'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] L. Burgette and J.. Reiter “Multiple imputation via sequential regression
    trees” In *American Journal of Epidemiology* 172, 2010, pp. 1070–1076'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li and Yitan Li “BRITS: Bidirectional
    recurrent imputation for time series” In *Advances in Neural Information Processing
    Systems*, 2018, pp. 6775–6785'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag and Yan
    Liu “Recurrent neural networks for multivariate time series with missing values”
    In *Scientific Reports* 8.1 Nature Publishing Group, 2018, pp. 1–12'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] Sixia Chen and David Haziza “Recent developments in dealing with item
    non-response in surveys: a critical review” In *International Statistical Review*
    87 Wiley Online Library, 2019, pp. S192–S218'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] Edith D De Leeuw, Joop Hox and Mark Huisman “Prevention and treatment
    of item nonresponse” In *Journal of Official Statistics-Stockholm* 19.2 ALMQVIST
    & WIKSELL INTERNATIONAL, 2003, pp. 153–176'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] L.L. Doove, S. Van Buuren and E. Dusseldorp “Recursive partitioning for
    missing data imputation in the presence of interaction effects” In *Computational
    Statistics & Data Analysis* 72, 2014, pp. 92–104'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] Dheeru Dua and Casey Graff “UCI Machine Learning Repository”, 2017 URL:
    [http://archive.ics.uci.edu/ml](http://archive.ics.uci.edu/ml)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] Vincent Fortuin, Dmitry Baranchuk, Gunnar Rätsch and Stephan Mandt “GP-VAE:
    Deep probabilistic time series imputation” In *International Conference on Artificial
    Intelligence and Statistics*, 2020, pp. 1651–1661 PMLR'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] A. Gelman and T. Speed “Characterizing a joint probability distribution
    by conditionals” In *Journal of the Royal Statistical Society Series B: Statistical
    Methodology* 55, 1993, pp. 185–188'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Xavier Glorot and Yoshua Bengio “Understanding the Difficulty of Training
    Deep Feedforward Neural Networks.” In *Artificial Intelligence and Statistics*
    9, 2010, pp. 249–256'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] Lovedeep Gondara and Ke Wang “MIDA: Multiple imputation using denoising
    autoencoders” In *Pacific-Asia Conference on Knowledge Discovery and Data Mining*,
    2018, pp. 260–272 Springer'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
    Sherjil Ozair, Aaron Courville and Yoshua Bengio “Generative adversarial nets”
    In *Advances in Neural Information Processing Systems*, 2014, pp. 2672–2680'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Hyungrok Ham, Tae Joon Jun and Daeyoung Kim “Unbalanced gans: Pre-training
    the generator of generative adversarial network using variational autoencoder”
    In *arXiv preprint arXiv:2002.02112*, 2020'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] Ofer Harel and Xiao-Hua Zhou “Multiple imputation: Review of theory, implementation
    and software” In *Statistics in Medicine* 26.16 Wiley Online Library, 2007, pp.
    3057–3077'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Trevor Hastie, Robert Tibshirani and Jerome Friedman “The elements of
    statistical learning: data mining, inference and prediction” Springer, 2009'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] David Haziza and Audrey-Anne Vallée “Variance estimation procedures in
    the presence of singly imputed survey data: a critical review” In *Japanese Journal
    of Statistics and Data Science* 3.2 Springer, 2020, pp. 583–623'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] James Honaker, Gary King and Matthew Blackwell “Amelia II: A program for
    missing data” In *Journal of Statistical Software* 45.7, 2011, pp. 1–47'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] Nicholas J Horton, Stuart R Lipsitz and Michael Parzen “A potential for
    bias when rounding in multiple imputation” In *The American Statistician* 57.4
    Taylor & Francis, 2003, pp. 229–232'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] Md Hamidul Huque, John B Carlin, Julie A Simpson and Katherine J Lee “A
    comparison of multiple imputation methods for missing data in longitudinal studies”
    In *BMC medical research methodology* 18.1 BioMed Central, 2018, pp. 1–16'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] Diederik Kingma and Jimmy Ba “Adam: A Method for Stochastic Optimization”
    In *arXiv:1412.6980*, 2014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] F Li, Y Yu and DB Rubin “Imputing missing data by fully conditional models:
    Some cautionary examples and guidelines”, 2012, pp. 1–35'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] Fan Li, Michela Baccini, Fabrizia Mealli, Elizabeth R. Zell, Constantine
    E. Frangakis and Donald B. Rubin “Multiple Imputation by Ordered Monotone Blocks
    With Application to the Anthrax Vaccine Research Program” In *Journal of Computational
    and Graphical Statistics* 23.3 Taylor & Francis, 2014, pp. 877–892'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] Zachary C Lipton, David C Kale and Randall Wetzel “Modeling missing data
    in clinical time series with RNNs” In *Machine Learning for Healthcare* 56, 2016'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Roderick JA Little and Donald B Rubin “Statistical Analysis with Missing
    Data” Hoboken, NJ: John Wiley & Sons, 2014'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] Roderick JA Little and Donald B Rubin “Statistical Analysis with Missing
    Data, 3rd Edition” New York: John Wiley & Sons, 2019'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] Haw-minn Lu, Giancarlo Perrone and José Unpingco “Multiple imputation
    with denoising autoencoder using metamorphic truth and imputation feedback” In
    *arXiv preprint arXiv:2002.08338*, 2020'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] Andrew L Maas, Awni Y Hannun and Andrew Y Ng “Rectifier nonlinearities
    improve neural network acoustic models” In *Proc. ICML*, 30 1, 2013, pp. 3'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] D Manrique-Vallier and J Reiter “Bayesian estimation of discrete multivariate
    truncated latent structure models” In *Journal of Computational and Graphical
    Statistics* 23, 2014, pp. 1061–1079'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen,
    Craig Citro, Greg S., Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat,
    Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal
    Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dandelion Mané, Rajat
    Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens,
    Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke,
    Vijay Vasudevan, Fernanda Viégas, Oriol Vinyals, Pete Warden, Martin Wattenberg,
    Martin Wicke, Yuan Yu and Xiaoqiang Zheng “TensorFlow: Large-Scale Machine Learning
    on Heterogeneous Systems” Software available from tensorflow.org, 2015 URL: [https://www.tensorflow.org/](https://www.tensorflow.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Federico Monti, Michael Bronstein and Xavier Bresson “Geometric matrix
    completion with recurrent multi-graph neural networks” In *Advances in Neural
    Information Processing Systems*, 2017, pp. 3697–3707'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Jared S Murray and Jerome P Reiter “Multiple imputation of missing categorical
    and continuous values via Bayesian mixture models with local dependence” In *Journal
    of the American Statistical Association* 111.516 Taylor & Francis, 2016, pp. 1466–1479'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] Trivellore E Raghunathan, James M Lepkowski, John Van Hoewyk and Peter
    Solenberger “A multivariate technique for multiply imputing missing values using
    a sequence of regression models” In *Survey Methodology* 27.1, 2001, pp. 85–96'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] Jerome P Reiter and Trivellore E Raghunathan “The multiple adaptations
    of multiple imputation” In *Journal of the American Statistical Association* 102.480
    Taylor & Francis, 2007, pp. 1462–1471'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] Patrick Royston and Ian R White “Multiple imputation by chained equations
    (MICE): implementation in Stata” In *J Statistical Software* 45.4, 2011, pp. 1–20'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] D.. Rubin “Inference and Missing data (with discussion)” In *Biometrika*
    63, 1976, pp. 581–592'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] D.. Rubin “Multiple Imputation for Nonresponse in Surveys” New York: John
    Wiley & Sons, 1987, pp. 258'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] Donald B Rubin “Multiple imputation after 18+ years” In *Journal of the
    American Statistical Association* 91.434 Taylor & Francis Group, 1996, pp. 473–489'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] Joseph L Schafer “Analysis of Incomplete Multivariate Data” Chapman &
    Hall: London, 1997'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Anoop Shah, Jonathan Bartlett, James Carpenter, Owen Nicholas and Harry
    Hemingway “Comparison of random forest and parametric imputation models for imputing
    missing data using MICE: A CALIBER study” In *American Journal of Epidemiology*
    179, 2014, pp. 764–74'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] Daniel J Stekhoven and Peter Bühlmann “MissForest—non-parametric missing
    value imputation for mixed-type data” In *Bioinformatics* 28.1 Oxford University
    Press, 2012, pp. 112–118'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] Yu-Sung Su, Andrew E Gelman, Jennifer Hill and Masanao Yajima “Multiple
    imputation with diagnostics (mi) in R: Opening windows into the black box” In
    *Journal of Statistical Software* 45, 2011'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] Lingqi Tang, Juwon Song, Thomas R Belin and Jürgen Unützer “A comparison
    of imputation methods in a longitudinal randomized clinical trial” In *Statistics
    in medicine* 24.14 Wiley Online Library, 2005, pp. 2111–2128'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] Tin Kam Ho “Random decision forests” In *Proceedings of 3rd International
    Conference on Document Analysis and Recognition* 1, 1995, pp. 278–282 vol.1'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] S. Buuren “Flexible Imputation of Missing Data”, Chapman & Hall/CRC Interdisciplinary
    Statistics CRC Press LLC, 2018'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] S. Buuren, J… Brand, C… Groothuis-Oudshoorn and D.. Rubin “Fully conditional
    specification in multivariate imputation” In *Journal of Statistical Computation
    and Simulation* 76.12 Taylor & Francis, 2006, pp. 1049–1064'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] Stef Buuren and Karin Groothuis-Oudshoorn “mice: Multivariate Imputation
    by Chained Equations in R” In *Journal of Statistical Software* 45.3, 2011, pp.
    1–67'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Pascal Vincent, Hugo Larochelle, Yoshua Bengio and Pierre-Antoine Manzagol
    “Extracting and composing robust features with denoising autoencoders” In *Proceedings
    of the 25th international conference on Machine learning*, 2008, pp. 1096–1103'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine
    Manzagol and Léon Bottou “Stacked denoising autoencoders: Learning useful representations
    in a deep network with a local denoising criterion.” In *Journal of Machine Learning
    Research* 11.12, 2010'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] Ian R. White, Patrick Royston and Angela M. Wood “Multiple imputation
    using chained equations: Issues and guidance for practice” In *Statistics in Medicine*
    30.4 John Wiley & Sons, Ltd., 2011, pp. 377–399'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] Chayut Wongkamthong and Olanrewaju Akande “A Comparative Study of Imputation
    Methods for Multivariate Ordinal Data” In *Journal of Survey Statistics and Methodology*
    in press, 2021'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] Jinsung Yoon, James Jordon and Mihaela Schaar “Gain: Missing data imputation
    using generative adversarial nets” In *International conference on machine learning*,
    2018, pp. 5689–5698 PMLR'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] Jinsung Yoon, William R Zame and Mihaela Schaar “Estimating missing data
    in temporal data streams using multi-directional recurrent neural networks” In
    *IEEE Transactions on Biomedical Engineering* 66.5 IEEE, 2018, pp. 1477–1490'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] Yang Yuan “Multiple imputation using SAS software” In *Journal of Statistical
    Software* 45.6, 2011, pp. 1–25'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
