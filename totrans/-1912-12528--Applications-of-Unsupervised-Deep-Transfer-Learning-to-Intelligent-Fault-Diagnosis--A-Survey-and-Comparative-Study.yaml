- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 20:03:17'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 20:03:17
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1912.12528] Applications of Unsupervised Deep Transfer Learning to Intelligent
    Fault Diagnosis: A Survey and Comparative Study'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1912.12528] 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1912.12528](https://ar5iv.labs.arxiv.org/html/1912.12528)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1912.12528](https://ar5iv.labs.arxiv.org/html/1912.12528)
- en: 'Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究
- en: 'Zhibin Zhao, Qiyang Zhang, Xiaolei Yu, Chuang Sun, Shibin Wang, Ruqiang Yan, 
    and Xuefeng Chen Z. Zhao, Q. Zhang, X. Yu, C. Sun, S. Wang, R. Yan and X. Chen
    are with the State Key Laboratory for Manufacturing Systems Engineering, Xi’an
    Jiaotong University, Xi’an 710049, China. E-mail: (zhaozhibin@xjtu.edu.cn; zhangqiyang@stu.xjtu.edu.cn;
    yxl007@stu.xjtu.edu.cn; ch.sun@xjtu.edu.cn; wangshibin2008@gmail.com; yanruqiang@xjtu.edu.cn; chenxf@mail.xjtu.edu.cn)
    This work was supported by the Natural Science Foundation of China (No. 52105116)
    and by the China Postdoctoral Science Foundation (No. 2021M692557 and No. 2021TQ0263).
    R. Yan is the corresponding author.'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 赵志斌、张启扬、于晓雷、孙闯、王士斌、闫如强、陈雪峰 Z. Zhao, Q. Zhang, X. Yu, C. Sun, S. Wang, R. Yan
    和 X. Chen 现于中国西安交通大学制造系统工程国家重点实验室，西安 710049，中国。电子邮件：(zhaozhibin@xjtu.edu.cn; zhangqiyang@stu.xjtu.edu.cn;
    yxl007@stu.xjtu.edu.cn; ch.sun@xjtu.edu.cn; wangshibin2008@gmail.com; yanruqiang@xjtu.edu.cn;
    chenxf@mail.xjtu.edu.cn) 本研究得到了中国自然科学基金（编号：52105116）和中国博士后科学基金（编号：2021M692557
    和 2021TQ0263）的资助。闫如强为通讯作者。
- en: Abstract
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Recent progress on intelligent fault diagnosis (IFD) has greatly depended on
    deep representation learning and plenty of labeled data. However, machines often
    operate with various working conditions or the target task has different distributions
    with the collected data used for training (the domain shift problem). Besides,
    the newly collected test data in the target domain are usually unlabeled, leading
    to unsupervised deep transfer learning based (UDTL-based) IFD problem. Although
    it has achieved huge development, a standard and open source code framework as
    well as a comparative study for UDTL-based IFD are not yet established. In this
    paper, we construct a new taxonomy and perform a comprehensive review of UDTL-based
    IFD according to different tasks. Comparative analysis of some typical methods
    and datasets reveals some open and essential issues in UDTL-based IFD which are
    rarely studied, including transferability of features, influence of backbones,
    negative transfer, physical priors, etc. To emphasize the importance and reproducibility
    of UDTL-based IFD, the whole test framework will be released to the research community
    to facilitate future research. In summary, the released framework and comparative
    study can serve as an extended interface and basic results to carry out new studies
    on UDTL-based IFD. The code framework is available at [https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL).
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 智能故障诊断（IFD）的最新进展在很大程度上依赖于深度表示学习和大量标注数据。然而，机器经常在不同的工作条件下运行，或者目标任务的分布与用于训练的收集数据存在差异（领域转移问题）。此外，目标领域中新收集的测试数据通常未标注，导致基于无监督深度迁移学习（UDTL）的
    IFD 问题。尽管取得了巨大进展，但尚未建立标准和开源代码框架以及 UDTL 基于的 IFD 的比较研究。本文构建了新的分类法，并根据不同任务对 UDTL
    基于的 IFD 进行全面综述。对一些典型方法和数据集的比较分析揭示了 UDTL 基于的 IFD 中一些鲜有研究的开放和重要问题，包括特征的迁移性、骨干网的影响、负迁移、物理先验等。为了强调
    UDTL 基于的 IFD 的重要性和可重复性，整个测试框架将向研究界发布，以促进未来的研究。总之，发布的框架和比较研究可以作为扩展接口和基础结果，以开展新的
    UDTL 基于的 IFD 研究。代码框架可以在 [https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL)
    获取。
- en: 'Index Terms:'
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Intelligent fault diagnosis; Unsupervised deep transfer learning; Taxonomy and
    survey; Comparative study; Reproducibility
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 智能故障诊断；无监督深度迁移学习；分类与综述；比较研究；可重复性
- en: I Introduction
  id: totrans-12
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 引言
- en: With the rapid development of industrial big data and Internet of Things, Prognostic
    and Health Management (PHM) for industrial equipments, such as aero-engine, helicopter
    and high-speed train, is becoming increasingly popular, bringing out many intelligent
    maintenance systems. Intelligent fault diagnosis (IFD) is becoming an essential
    branch among PHM systems. IFD based on traditional machine learning methods [[1](#bib.bib1)],
    including random forest [[2](#bib.bib2)] and support vector machine [[3](#bib.bib3)],
    has been widely applied in research and industry scenarios. However, these methods
    often need to extract features manually or to combine with other advanced signal
    processing techniques, such as time frequency analysis [[4](#bib.bib4)] and sparse
    representation [[5](#bib.bib5), [6](#bib.bib6)]. While, with the increment of
    available data, data-driven methods with the representation learning ability are
    also becoming more and more important. Thus, Deep Learning (DL) [[7](#bib.bib7)],
    which can extract useful features automatically from original signals, gradually
    becomes a hot research topic for many fields [[8](#bib.bib8), [9](#bib.bib9),
    [10](#bib.bib10), [11](#bib.bib11)] as well as PHM [[12](#bib.bib12), [13](#bib.bib13),
    [14](#bib.bib14)]. Effective DL models, such as Convolutional Neural Network (CNN)
    [[15](#bib.bib15)], Sparse Autoencoder (SAE) [[16](#bib.bib16)], etc., for tasks
    in PHM have been validated successfully in current research, and a benchmark study
    is also given in [[17](#bib.bib17)] for better comparison and development.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 随着工业大数据和物联网的快速发展，工业设备如航空发动机、直升机和高速列车的预测与健康管理（PHM）变得越来越受欢迎，催生了许多智能维护系统。智能故障诊断（IFD）正在成为PHM系统中的一个重要分支。基于传统机器学习方法的IFD
    [[1](#bib.bib1)]，包括随机森林 [[2](#bib.bib2)] 和支持向量机 [[3](#bib.bib3)]，已广泛应用于研究和工业场景。然而，这些方法通常需要手动提取特征或结合其他先进的信号处理技术，如时频分析
    [[4](#bib.bib4)] 和稀疏表示 [[5](#bib.bib5), [6](#bib.bib6)]。随着可用数据的增加，具有表示学习能力的数据驱动方法也变得越来越重要。因此，能够从原始信号中自动提取有用特征的深度学习（DL）
    [[7](#bib.bib7)]，逐渐成为许多领域 [[8](#bib.bib8), [9](#bib.bib9), [10](#bib.bib10), [11](#bib.bib11)]
    以及PHM [[12](#bib.bib12), [13](#bib.bib13), [14](#bib.bib14)] 的热门研究话题。有效的DL模型，如卷积神经网络（CNN）
    [[15](#bib.bib15)]、稀疏自编码器（SAE） [[16](#bib.bib16)] 等，已在当前研究中成功验证了其在PHM任务中的应用，同时[[17](#bib.bib17)]也提供了基准研究以便于更好的比较和发展。
- en: 'Behind the effectiveness of DL-based IFD, there exist two necessary assumptions:
    1) samples from the training dataset (source domain) should have the same distribution
    with that from the test dataset (target domain); 2) plenty of labeled data are
    available during the training phase. Although the labeled data might be generated
    by dynamic simulations or fault seeding experiments, the generated data are not
    strictly consistent with the test data in the real scenario. That is, DL models
    based on the training dataset only possess a weak generalization ability, when
    deployed to the test dataset from real applications. In addition, rotating machinery
    often operates with varying working conditions, such as loads and speeds, which
    also requires that trained models using the dataset from one working condition
    can successfully transfer to the test dataset from another working condition.
    In short, these factors make models trained in the source domain hard to be generalized
    or transferred to the target domain, directly.'
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 在DL基础的IFD的有效性背后，存在两个必要的假设：1）训练数据集（源领域）中的样本应与测试数据集（目标领域）中的样本具有相同的分布；2）在训练阶段有大量标记数据可用。虽然标记数据可能通过动态仿真或故障种植实验生成，但生成的数据与实际场景中的测试数据并不完全一致。也就是说，基于训练数据集的DL模型在部署到真实应用的测试数据集时，仅具备较弱的泛化能力。此外，旋转机械往往在不同的工作条件下运行，例如负载和速度，这也要求使用一种工作条件下的数据集训练的模型能够成功转移到另一种工作条件下的测试数据集。简而言之，这些因素使得在源领域训练的模型难以直接泛化或迁移到目标领域。
- en: Shared features existing in these two domains due to the intrinsic similarity
    in different application scenarios or different working conditions allow this
    domain shift manageable. Hence, to let DL models trained in the source domain
    be able to be transferred well to the target domain, a new paradigm, called deep
    transfer learning (DTL) should be introduced into IFD. One of the effective and
    direct DTL is to fine-tune DL models with a few labeled data in the target domain,
    and then the fine-tuned model can be used to diagnose the test samples. However,
    the newly collected data or the data under different working conditions are usually
    unlabeled and it is sometimes very difficult, or even impossible to label these
    data. Therefore, in this paper, we investigate the unsupervised version of DTL,
    called unsupervised deep transfer learning-based (UDTL-based) IFD, which is to
    make predictions for unlabeled data on a target domain given labeled data on a
    source domain. It is worth mentioning that UDTL is sometimes called unsupervised
    domain adaptation, and in this paper, we do not make a strict distinction between
    two concepts.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 由于在不同应用场景或不同工作条件下的内在相似性，这两个领域之间存在的共享特性使得领域迁移变得可管理。因此，为了让在源领域训练的深度学习（DL）模型能够很好地迁移到目标领域，应该在图像故障检测（IFD）中引入一种新的范式，称为深度迁移学习（DTL）。一种有效且直接的DTL方法是使用目标领域中少量标记数据对DL模型进行微调，然后可以使用微调后的模型来诊断测试样本。然而，新收集的数据或在不同工作条件下的数据通常是未标记的，有时标记这些数据非常困难，甚至不可能。因此，本文探讨了DTL的无监督版本，即基于无监督深度迁移学习（UDTL-based）的IFD，其目的是在给定源领域标记数据的情况下对目标领域的未标记数据进行预测。值得一提的是，UDTL有时被称为无监督领域适应，本文不对这两个概念做严格区分。
- en: 'UDTL is widely used and has achieved tremendous success in the field of computer
    vision and natural language processing, due to the application value, open source
    codes, and the baseline accuracy. However, there are few open source codes or
    the baseline accuracy in the field of UDTL-based IFD, plenty of research has been
    published for UDTL-based IFD via simply using models that already have been published
    in other fields. Due to the lack of open source codes, results in these papers
    are very hard to repeat for further comparisons. This is not beneficial to identify
    the state-of-the-art methods, and furthermore, it is unfavorable to the advancement
    of this field on a long view. Hence, it is very important to perform a comparative
    study, provide a baseline accuracy, and release open source codes of UDTL-based
    algorithms. For testing UDTL-based algorithms, the unified test framework, parameter
    settings, and datasets are three important aspects to affect fairness and effectiveness
    of comparisons. While, due to the inconsistency of these factors, there are a
    lot of unfair and unsuitable comparisons. It seems that scholars are continuing
    to combine new techniques, and the proposed algorithms always have better performance
    than other former algorithms, which comes to the question: Is the improvement
    beneficial to IFD or just depends on the excessive parameter adjustment? However,
    the open and essential issues in UDTL-based IFD are rarely studied, such as transferability
    of the features, influence of backbones, etc.'
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: UDTL在计算机视觉和自然语言处理领域得到了广泛应用，并取得了巨大的成功，这得益于其应用价值、开源代码和基准准确率。然而，在UDTL-based IFD领域，开源代码和基准准确率较少，很多研究通过简单使用在其他领域已发布的模型来进行UDTL-based
    IFD。由于缺乏开源代码，这些论文中的结果很难重复进行进一步比较。这不利于识别最先进的方法，进一步来说，也不利于该领域的长期发展。因此，进行比较研究、提供基准准确率和发布UDTL-based算法的开源代码非常重要。在测试UDTL-based算法时，统一的测试框架、参数设置和数据集是影响比较公平性和有效性的三个重要方面。然而，由于这些因素的不一致，存在很多不公平和不合适的比较。似乎学者们继续结合新技术，提出的算法总是比以前的算法表现更好，这就引出了一个问题：这种改进对IFD有益还是仅仅依赖于过度的参数调整？然而，UDTL-based
    IFD中开放和关键的问题，如特征的可迁移性、骨干网的影响等，鲜有研究。
- en: There are already some good review papers about transfer learning in IFD. Zheng
    et al. [[18](#bib.bib18)] summarized the cross-domain fault diagnosis using the
    knowledge transfer strategy based on transfer learning and presented some open
    source datasets, which could be used to verify the performance of diagnosis methods.
    Yan et al. [[19](#bib.bib19)] reviewed recent development of knowledge transfer
    for rotary machine fault diagnosis via using different transfer learning methods
    and provided four case studies to compare the performance of different methods.
    Lei et al. [[20](#bib.bib20)] reviewed IFD based on machine learning methods with
    the emphasis on transfer learning theories, which adopt diagnosis knowledge from
    one or multiple datasets to other related ones, and also pointed out that transfer
    learning theories might be the essential way to narrow the gap between experimental
    verification and real applications. However, all above review papers did not focus
    on UDTL-based IFD and provide the open source test framework for fair and suitable
    comparisons. They all payed more attention to label-consistent (also called closed
    set) UDTL-based IFD, which assumes that the source domain has the same label space
    with the target domain, but many recent research papers focused on label-inconsistent
    or multi-domain UDTL, which is closer to the engineering scenarios. Thus, a comprehensive
    review is still required to cover the advanced development of UDTL-based IFD from
    the cradle to the bloom and to guide the future development.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 已经有一些关于IFD中迁移学习的优秀综述论文。郑等人[[18](#bib.bib18)]总结了基于迁移学习的知识迁移策略在跨域故障诊断中的应用，并提供了一些开源数据集，可以用于验证诊断方法的性能。严等人[[19](#bib.bib19)]回顾了通过使用不同的迁移学习方法进行旋转机械故障诊断的最新发展，并提供了四个案例研究来比较不同方法的性能。雷等人[[20](#bib.bib20)]回顾了基于机器学习方法的IFD，重点讨论了迁移学习理论，该理论将一个或多个数据集的诊断知识迁移到其他相关数据集中，并指出迁移学习理论可能是缩小实验验证与实际应用之间差距的关键方法。然而，上述综述论文均未集中于UDTL-based
    IFD，也未提供用于公平和适当比较的开源测试框架。它们都更关注标签一致（也称为封闭集）UDTL-based IFD，假设源域与目标域具有相同的标签空间，但许多最近的研究论文关注标签不一致或多域UDTL，更接近工程场景。因此，仍需进行全面的综述，以涵盖UDTL-based
    IFD从起步到成熟的先进发展，并指导未来的发展。
- en: In this paper, to fill in this gap, commonly used UDTL-based settings and algorithms
    are discussed and a new taxonomy of UDTL-based IFD is constructed. In each separate
    category, we also give a comprehensive review about recent development of UDTL-based
    IFD. Some typical methods are integrated into a unified test framework, which
    is tested on five datasets. This test framework with source codes will be released
    to the research community to facilitate the research on UDTL-based IFD. With this
    comparative study and open source codes, the authors try to give a depth discussion
    (it is worth mentioning that results are just a lower bound of the accuracy) of
    current algorithms and attempt to find the core that determines the transfer performance.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 本文为填补这一空白，讨论了常用的UDTL-based设置和算法，并构建了UDTL-based IFD的新分类法。在每个单独的类别中，我们还对UDTL-based
    IFD的最新发展进行了全面的综述。一些典型的方法被整合到一个统一的测试框架中，该框架在五个数据集上进行了测试。这个测试框架及其源代码将发布给研究社区，以促进对UDTL-based
    IFD的研究。通过这项比较研究和开源代码，作者试图深入探讨当前算法（值得一提的是，结果仅为准确性的下界），并尝试找出决定迁移性能的核心因素。
- en: 'The main contributions of this paper are summarized as follows:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的主要贡献总结如下：
- en: 1)
  id: totrans-20
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'New taxonomy and review: we establish a new taxonomy of UDTL-based IFD according
    to different tasks of UDTL. The hierarchical order follows the number of source
    domains, the usage of target data in the training phase, the label consistence
    of source and target domains, inclusion relationship between label sets of source
    and target domains, and a transfer methodological level. We also provide the most
    comprehensive overview of UDTL-based IFD for each type of categories.'
  id: totrans-21
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 新的分类法和综述：我们根据UDTL的不同任务建立了基于UDTL的IFD的新分类法。层级顺序遵循源域的数量、训练阶段目标数据的使用、源域和目标域标签的一致性、源域和目标域标签集之间的包含关系，以及转移方法论水平。我们还提供了每种类别的UDTL-based
    IFD的最全面的概述。
- en: 2)
  id: totrans-22
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Various datasets and data splitting: We collect most of the publicly available
    datasets suitable for UDTL-based IFD and provide a detailed discussion about its
    adaptability. We also discuss the way of data splitting and explain that it is
    more appropriate to split data into training and test datasets regardless of whether
    they are in source or target domains.'
  id: totrans-23
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 各种数据集和数据划分：我们收集了大多数适用于基于UDTL的IFD的公开数据集，并详细讨论了其适应性。我们还讨论了数据划分的方式，并解释了无论数据处于源领域还是目标领域，将数据划分为训练集和测试集更为合适。
- en: 3)
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Comparative study and further discussion: We evaluate various UDTL-based IFD
    methods and provide a systematic and comparative analysis from several perspectives
    to make the future studies more comparable and meaningful. We also discuss the
    transferability of features, influence of backbones, negative transfer, etc.'
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 比较研究与进一步讨论：我们评估了各种基于UDTL的IFD方法，并从多个角度提供系统化的比较分析，以使未来的研究更加可比和有意义。我们还讨论了特征的可迁移性、骨干网络的影响、负迁移等。
- en: 4)
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4)
- en: 'Open source codes: To emphasize the importance and reproducibility of UDTL-based
    IFD, we release the whole evaluation code framework that implements all UDTL-based
    methods discussed in this paper. Meanwhile, this is an extensible framework that
    retains an extended interface for everyone to combine different algorithms and
    load their own datasets to carry out new studies. The code framework is available
    at [https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL).'
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 开源代码：为了强调UDTL-based IFD的重要性和可重复性，我们发布了实现本文讨论的所有UDTL-based方法的完整评价代码框架。同时，这是一个可扩展的框架，保留了一个扩展接口，供大家结合不同的算法并加载自己的数据集以进行新的研究。代码框架可在[https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL)获得。
- en: 'The rest of this paper is organized as follows: Section [II](#S2 "II Background
    and Definition ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent
    Fault Diagnosis: A Survey and Comparative Study") provides background and definition
    of UDTL-based IFD. Basic concepts, evaluation algorithms and comprehensive review
    of UDTL-based IFD are introduced in Section [III](#S3 "III Label-consistent UDTL
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study") to [V](#S5 "V Multi-domain UDTL ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"). After that, in Section [VI](#S6 "VI Datasets ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study") to [VIII](#S8 "VIII Further discussions ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"), datasets, evaluation results and further discussions
    are investigated, followed by the conclusion part in Section [IX](#S9 "IX Conclusion
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study").'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: '本文其余部分组织如下：第[II](#S2 "II Background and Definition ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")节提供了基于UDTL的IFD的背景和定义。基本概念、评价算法以及对基于UDTL的IFD的综合评述在第[III](#S3 "III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")节至[V](#S5 "V Multi-domain UDTL ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")节中介绍。之后，在第[VI](#S6 "VI Datasets ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")节至第[VIII](#S8 "VIII Further discussions ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")节中，讨论了数据集、评价结果和进一步讨论，最后在第[IX](#S9 "IX Conclusion ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")节给出了结论部分。'
- en: II Background and Definition
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 背景与定义
- en: II-A The Definition of UDTL
  id: totrans-30
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-A UDTL的定义
- en: 'To briefly describe the definition of UDTL, we introduce some basic symbols.
    It is assumed that labels in the source domain are all available, and the source
    domain can be defined as follows:'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简要描述UDTL的定义，我们介绍了一些基本符号。假设源领域中的标签都是可用的，源领域可以定义如下：
- en: '|  | $\displaystyle\mathcal{D}_{s}=\left\{{\left({x_{i}^{s},y_{i}^{s}}\right)}\right\}_{i=1}^{{n_{s}}}\quad
    x_{i}^{s}\in{X_{s}},\;y_{i}^{s}\in{Y_{s}},$ |  | (1) |'
  id: totrans-32
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{D}_{s}=\left\{{\left({x_{i}^{s},y_{i}^{s}}\right)}\right\}_{i=1}^{{n_{s}}}\quad
    x_{i}^{s}\in{X_{s}},\;y_{i}^{s}\in{Y_{s}},$ |  | (1) |'
- en: 'where $\mathcal{D}_{s}$ represents the source domain, $x_{i}^{s}\in\mathbb{R}^{d}$
    is the $i$-th sample, $X_{s}$ is the union of all samples, $y_{i}^{s}$ is the
    $i$-th label of the $i$-th sample, $Y_{s}$ is the union of all different labels,
    and $n_{s}$ means the total number of source samples. Besides, it is assumed that
    labels in the target domain are unavailable, and thus the target domain can be
    defined as follows:'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{D}_{s}$ 代表源领域，$x_{i}^{s}\in\mathbb{R}^{d}$ 是第 $i$ 个样本，$X_{s}$ 是所有样本的并集，$y_{i}^{s}$
    是第 $i$ 个样本的标签，$Y_{s}$ 是所有不同标签的并集，$n_{s}$ 表示源样本的总数。此外，假设目标领域中的标签不可用，因此目标领域可以定义如下：
- en: '|  | $\displaystyle\mathcal{D}_{t}=\left\{{\left({x_{i}^{t}}\right)}\right\}_{i=1}^{{n_{t}}}\quad
    x_{i}^{t}\in{X_{t}},$ |  | (2) |'
  id: totrans-34
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{D}_{t}=\left\{{\left({x_{i}^{t}}\right)}\right\}_{i=1}^{{n_{t}}}\quad
    x_{i}^{t}\in{X_{t}},$ |  | (2) |'
- en: where $\mathcal{D}_{t}$ represents the target domain, $x_{i}^{t}\in\mathbb{R}^{d}$
    is the $i$-th sample, $X_{t}$ is the union of all samples, and $n_{t}$ means the
    total number of target samples.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{D}_{t}$ 代表目标领域，$x_{i}^{t}\in\mathbb{R}^{d}$ 是第 $i$ 个样本，$X_{t}$
    是所有样本的并集，$n_{t}$ 表示目标样本的总数。
- en: 'The source and target domains follow the probability distributions $P$ and
    $Q$, respectively. We hope to build a model $\beta(\cdot)$ which can classify
    unlabeled samples $x$ in the target domain:'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 源领域和目标领域分别遵循概率分布 $P$ 和 $Q$。我们希望建立一个模型 $\beta(\cdot)$，该模型可以对目标领域中的未标记样本 $x$ 进行分类：
- en: '|  | $\displaystyle\hat{y}=\beta\left(x\right),$ |  | (3) |'
  id: totrans-37
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{y}=\beta\left(x\right),$ |  | (3) |'
- en: 'where $\hat{y}$ is the prediction. Thus, UDTL is aimed to minimize the target
    risk ${\varepsilon}_{t}\left(\beta\right)$ using source data supervision [[21](#bib.bib21)]:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\hat{y}$ 是预测值。因此，UDTL 旨在通过源数据监督来最小化目标风险 ${\varepsilon}_{t}\left(\beta\right)$
    [[21](#bib.bib21)]：
- en: '|  | $\displaystyle{\varepsilon}_{t}\left(\beta\right)=\Pr_{\left({x,y}\right)\sim
    Q}\left[{\beta\left(x\right)\neq y}\right].$ |  | (4) |'
  id: totrans-39
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle{\varepsilon}_{t}\left(\beta\right)=\Pr_{\left({x,y}\right)\sim
    Q}\left[{\beta\left(x\right)\neq y}\right].$ |  | (4) |'
- en: 'Also, the total loss of UDTL can be written as:'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，UDTL的总损失可以写作：
- en: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda\mathcal{L}_{\text{UDTL}},$
    |  | (5) |'
  id: totrans-41
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda\mathcal{L}_{\text{UDTL}},$
    |  | (5) |'
- en: 'where $\mathcal{L}_{c}$ is the Softmax cross-entropy loss shown in ([6](#S2.E6
    "In II-A The Definition of UDTL ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")), $\lambda$ is the trade-off parameter, and $\mathcal{L}_{\text{UDTL}}$
    represents the partial loss to reduce the feature difference between source and
    target domains.'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{L}_{c}$ 是在 ([6](#S2.E6 "在II-A UDTL的定义 ‣ II 背景与定义 ‣ 无监督深度迁移学习在智能故障诊断中的应用：一项调查与比较研究"))
    中展示的Softmax交叉熵损失，$\lambda$ 是权衡参数，$\mathcal{L}_{\text{UDTL}}$ 代表减少源领域和目标领域之间特征差异的部分损失。
- en: '|  | $\displaystyle\mathcal{L}_{c}=-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[\beta\left(x_{i}^{s}\right)\right],$
    |  | (6) |'
  id: totrans-43
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{c}=-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[\beta\left(x_{i}^{s}\right)\right],$
    |  | (6) |'
- en: where $C$ is the number of all possible classes, $\mathbb{E}$ denotes the mathematical
    expectation, and $\mathbf{1}$ is the indicator function.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $C$ 是所有可能类别的数量，$\mathbb{E}$ 表示数学期望，$\mathbf{1}$ 是指示函数。
- en: II-B Taxonomy of UDTL-based IFD
  id: totrans-45
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-B 基于UDTL的IFD分类
- en: 'In this section, we present our taxonomy of UDTL-based IFD, as shown in Fig. [1](#S2.F1
    "Figure 1 ‣ II-B Taxonomy of UDTL-based IFD ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"). We categorize UDTL-based IFD into single-domain and multi-domain
    UDTL according to the number of source domains from a macro perspective. In the
    following, we give a brief introduction of each category and detailed description
    is given in the next part.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 在本节中，我们展示了基于UDTL的IFD分类，如图[1](#S2.F1 "图1 ‣ II-B 基于UDTL的IFD分类 ‣ II 背景与定义 ‣ 无监督深度迁移学习在智能故障诊断中的应用：一项调查与比较研究")所示。我们从宏观角度根据源领域的数量将基于UDTL的IFD分为单领域和多领域UDTL。在下面，我们简要介绍每个类别，详细描述将在下一部分给出。
- en: 'Figure 1: A taxonomy of UDTL-based methods.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：基于UDTL的方法分类。
- en: '1) Single-domain UDTL: These can be further categorized into label-consistent
    (closed set) and label-inconsistent UDTL. As shown in Fig. [2](#S2.F2 "Figure
    2 ‣ II-B Taxonomy of UDTL-based IFD ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"), label-consistent UDTL represents the label sets of source
    and target domains are consistent. According to Tan et al. [[22](#bib.bib22)],
    label-consistent UDTL can be classified into four categories: network-based, instanced-based,
    mapping-based, and adversarial-based methods from a methodological level. Additionally,
    We categorize label-inconsistent UDTL into partial, open set, and universal tasks
    based on the inclusion relationship between label sets. As shown in Fig. [2](#S2.F2
    "Figure 2 ‣ II-B Taxonomy of UDTL-based IFD ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"), partial UDTL means that the target label set is a subspace
    of the source label set; open set UDTL means that the target label set contains
    unknown labels; universal UDTL is a combination of the first two conditions. It
    is worth mentioning that three tasks can be further divided into the above four
    methods from a methodological level.'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '1) 单领域 UDTL：这些可以进一步分为标签一致（封闭集）和标签不一致的 UDTL。如图 [2](#S2.F2 "Figure 2 ‣ II-B Taxonomy
    of UDTL-based IFD ‣ II Background and Definition ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")所示，标签一致的 UDTL 表示源领域和目标领域的标签集是一致的。根据 Tan 等人 [[22](#bib.bib22)] 的研究，标签一致的
    UDTL 可以从方法论层面分为四类：基于网络的方法、基于实例的方法、基于映射的方法和基于对抗的方法。此外，我们将标签不一致的 UDTL 按照标签集之间的包含关系分为部分、开放集和通用任务。如图 [2](#S2.F2
    "Figure 2 ‣ II-B Taxonomy of UDTL-based IFD ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")所示，部分 UDTL 意味着目标标签集是源标签集的一个子空间；开放集 UDTL 意味着目标标签集包含未知标签；通用
    UDTL 是前两种情况的结合。值得一提的是，这三种任务从方法论层面上可以进一步细分为上述四种方法。'
- en: '2) Multi-domain UDTL: These can be further categorized into multi-domain adaptation
    and domain generalization (DG) based on the usage of the target data in the training
    phase. Multi-domain adaptation means that the unlabeled samples from the target
    domain participate into the training phase, and DG is the opposite. Besides, these
    two conditions can also be further categorized into label-consistent and label-inconsistent
    UDTL.'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 2) 多领域 UDTL：这些可以进一步分为多领域适应和领域泛化（DG），具体取决于目标数据在训练阶段的使用情况。多领域适应意味着来自目标领域的未标记样本参与训练阶段，而
    DG 则相反。此外，这两种情况还可以进一步细分为标签一致和标签不一致的 UDTL。
- en: '![Refer to caption](img/c7337e1f567b9b415ebf94e97d2ba7cd.png)'
  id: totrans-50
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c7337e1f567b9b415ebf94e97d2ba7cd.png)'
- en: 'Figure 2: Visualization explanation of different transfer settings. Additionally,
    different colors represent different domains and dotted lines denote that this
    domain does not participate in training.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：不同迁移设置的可视化说明。此外，不同的颜色表示不同的领域，虚线表示该领域未参与训练。
- en: II-C Motivation of UDTL-based IFD
  id: totrans-52
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-C UDTL 基于 IFD 的动机
- en: 'Distributions of training and test samples are often different, due to the
    influence of working conditions, fault sizes, fault types, etc. Consequently,
    UDTL-based IFD has been introduced recently to tackle this domain shift problem
    since there are some shared features in the specific space. Using these shared
    features, applications of UDTL-based IFD can be mainly classified into four categories:
    different working conditions, different types of faults, different locations,
    and different machines.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 由于工作条件、故障大小、故障类型等因素的影响，训练样本和测试样本的分布通常不同。因此，最近引入了基于 UDTL 的 IFD 来解决这个领域迁移问题，因为在特定空间中存在一些共享特征。利用这些共享特征，基于
    UDTL 的 IFD 的应用主要可以分为四类：不同的工作条件、不同类型的故障、不同的位置和不同的机器。
- en: '1) Different working conditions: Due to the influence of speed, load, temperature,
    etc., working conditions often vary during the monitoring period. Collected signals
    may contain domain shift, which means that the distribution of data may differ
    significantly under different working conditions [[23](#bib.bib23)]. The aim of
    UDTL-based IFD is that the model trained using signals under one working condition
    can be transferred to signals under another different working condition.'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 不同工作条件：由于速度、负载、温度等因素的影响，工作条件在监测期间往往会有所变化。收集到的信号可能包含领域转移，这意味着在不同工作条件下数据的分布可能显著不同[[23](#bib.bib23)]。基于UDTL的IFD的目标是使使用一种工作条件下的信号训练的模型能够转移到另一种不同工作条件下的信号。
- en: '2) Different types of faults: Label difference between source and target domains
    may exist since different types of faults would happen on the same component.
    Therefore, there are three cases in UDTL-based IFD. The first one is that unknown
    fault types appear in the target domain (open set transfer). The second one is
    that partial fault types of the source domain appear in the target domain (partial
    transfer). The third one is that the first two cases occur at the same time (universal
    transfer). The aim of UDTL-based IFD is that the model trained with some types
    of faults can be transferred to the target domain with different types of faults.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 不同类型的故障：由于不同类型的故障可能发生在同一组件上，源领域和目标领域之间可能存在标签差异。因此，基于UDTL的IFD有三种情况。第一种情况是目标领域出现未知故障类型（开放集转移）。第二种情况是目标领域出现源领域的部分故障类型（部分转移）。第三种情况是前两种情况同时发生（通用转移）。基于UDTL的IFD的目标是使使用某些类型故障训练的模型能够转移到具有不同类型故障的目标领域。
- en: '3) Different locations: Because sensors installed on the same machine are often
    responsible for monitoring different components, and sensors located near the
    fault component are more suitable to indicate the fault information. However,
    key components have different probabilities of failure rates, leading to the situation
    where signals from different locations have different numbers of labeled data.
    The aim of UDTL-based IFD is that the model trained with plenty of labeled data
    from one location can be transferred to the target domain with unlabeled data
    from other locations.'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 不同位置：由于安装在同一台机器上的传感器通常负责监测不同的组件，并且靠近故障组件的传感器更适合指示故障信息。然而，关键组件的故障率概率不同，导致不同位置的信号具有不同数量的标注数据。基于UDTL的IFD的目标是使使用大量标注数据训练的模型能够转移到具有来自其他位置的未标注数据的目标领域。
- en: '4) Different machines: Enough labeled fault samples of real machines are difficult
    to collect due to the test cost and security. Besides, enough labeled data can
    be generated from dynamic simulations or fault seeding experiments. However, distributions
    of data from dynamic simulations or fault seeding experiments are different but
    similar to those from real machines, due to the similar structure and measurement
    situations. Thus, the aim of UDTL-based IFD is that the model can be transferred
    to test data gathered from real machines.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 不同机器：由于测试成本和安全问题，收集足够的标注故障样本非常困难。此外，可以通过动态模拟或故障种植实验生成足够的标注数据。然而，由于结构和测量情况相似，动态模拟或故障种植实验的数据分布与真实机器的数据分布不同但相似。因此，基于UDTL的IFD的目标是使模型能够转移到从真实机器收集的测试数据上。
- en: II-D The structure of backbone
  id: totrans-58
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: II-D 骨干结构
- en: One of the most important parts of UDTL-based IFD is the structure of the backbone,
    which acts as feature extraction and has a huge impact on the test accuracy. For
    example, in the field of image classification, different backbones, such as VGG
    [[24](#bib.bib24)], ResNet [[25](#bib.bib25)], etc., have different abilities
    of feature extraction, leading to different classification performance.
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 基于UDTL的IFD最重要的部分之一是骨干结构，它作为特征提取具有巨大的测试准确度影响。例如，在图像分类领域，不同的骨干网络，如VGG [[24](#bib.bib24)]、ResNet
    [[25](#bib.bib25)]等，具有不同的特征提取能力，从而导致不同的分类性能。
- en: However, for UDTL-based IFD, different studies have their own backbones, and
    it is difficult to determine whose backbone is better. Therefore, direct comparisons
    with the results listed in other published papers are unfair and unsuitable due
    to different representative capacities of backbones. In this paper, we try to
    verify the performance of different UDTL-based IFD methods using the same CNN
    backbone to ensure a fair comparison.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于基于UDTL的IFD，不同的研究有各自的骨干网，因此很难确定哪个骨干网更好。因此，由于骨干网的代表性能力不同，与其他已发布论文中的结果进行直接比较是不公平和不合适的。在本文中，我们尝试使用相同的CNN骨干网来验证不同基于UDTL的IFD方法的性能，以确保公平比较。
- en: 'As shown in Fig. [3](#S2.F3 "Figure 3 ‣ II-D The structure of backbone ‣ II
    Background and Definition ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"), the CNN backbone
    consists of four one dimension (1D) convolutional layers that come with an 1D
    Batch Normalization (BN) layer and a ReLU activation function. Besides, the second
    combination comes with an 1D Max Pooling layer, and the fourth combination comes
    with an 1D Adaptive Max Pooling layer to realize the adaptation of the input length.
    The convolutional output is then flattened and passed through a fully-connected
    (Fc) layer, a ReLU activation function, and a Dropout layer. The detailed parameters
    are listed in Table [I](#S2.T1 "TABLE I ‣ II-D The structure of backbone ‣ II
    Background and Definition ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study").'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '如图[3](#S2.F3 "Figure 3 ‣ II-D The structure of backbone ‣ II Background and
    Definition ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent
    Fault Diagnosis: A Survey and Comparative Study")所示，CNN骨干网由四个一维（1D）卷积层组成，这些层配备了一个1D批量归一化（BN）层和一个ReLU激活函数。此外，第二组合配备了一个1D最大池化层，第四组合配备了一个1D自适应最大池化层，以实现输入长度的自适应。卷积输出随后被展平，通过一个全连接（Fc）层，一个ReLU激活函数和一个Dropout层。详细参数列在表[I](#S2.T1
    "TABLE I ‣ II-D The structure of backbone ‣ II Background and Definition ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")中。'
- en: '![Refer to caption](img/4407fab246f96d407ce5fda3413efc13.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/4407fab246f96d407ce5fda3413efc13.png)'
- en: 'Figure 3: The structure of the backbone.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：骨干网的结构。
- en: 'TABLE I: Parameters of the backbone.'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 表I：骨干网的参数。
- en: '| Layers | Parameters |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| 层 | 参数 |'
- en: '| --- | --- |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Conv1 | out_channels=16, kernel_size=15 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| Conv1 | out_channels=16, kernel_size=15 |'
- en: '| Conv2 | out_channels=32, kernel_size=3 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Conv2 | out_channels=32, kernel_size=3 |'
- en: '| Max Pooling | kernel_size=2, stride=2 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| 最大池化 | kernel_size=2, stride=2 |'
- en: '| Conv3 | out_channels=64, kernel_size=3 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| Conv3 | out_channels=64, kernel_size=3 |'
- en: '| Conv4 | out_channels=128, kernel_size=3 |'
  id: totrans-71
  prefs: []
  type: TYPE_TB
  zh: '| Conv4 | out_channels=128, kernel_size=3 |'
- en: '| Adaptive Max Pooling | output_size=4 |'
  id: totrans-72
  prefs: []
  type: TYPE_TB
  zh: '| 自适应最大池化 | output_size=4 |'
- en: '| Fc | out_features=256 |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| Fc | out_features=256 |'
- en: '| Dropout | p=0.5 |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| Dropout | p=0.5 |'
- en: III Label-consistent UDTL
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 标签一致的UDTL
- en: Label-consistent (also called closed set) UDTL-based IFD assumes that the source
    domain has the same label space with the target domain. In this section, we categorize
    label-consistent UDTL into network-based, instanced-based, mapping-based, and
    adversarial-based methods from a methodological level.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 标签一致（也称为闭集）基于UDTL的IFD假设源领域与目标领域具有相同的标签空间。在本节中，我们从方法论的层面将标签一致的UDTL分类为网络基础、实例基础、映射基础和对抗基础方法。
- en: III-A Network-based UDTL
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 网络基础的UDTL
- en: III-A1 Basic concepts
  id: totrans-78
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 基本概念
- en: 'Network-based DTL means that partial network parameters pre-trained in the
    source domain are transferred directly to be partial network parameters of the
    test procedure or network parameters are fine-tuned with a few labeled data in
    the target domain. The most popular network-based DTL method is to fine-tune the
    trained model utilizing a few labeled data in the target domain. However, for
    UDTL-based IFD, labels in the target domain are unavailable. We use the backbone
    coming with a bottleneck layer, consisting of a Fc layer (out_features=256), a
    ReLU activation function, a Dropout layer ($p=0.5$), and a basic Softmax classifier
    to construct our basic model (we call it Basis), which is shown in Fig. [4](#S3.F4
    "Figure 4 ‣ III-A1 Basic concepts ‣ III-A Network-based UDTL ‣ III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study"). The trained model is used to test
    samples in the target domain directly, which means that source and target domains
    share the same model and parameters.'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: '基于网络的DTL（深度迁移学习）指的是将源领域中预训练的部分网络参数直接转移到测试过程的部分网络参数中，或者使用少量标记数据在目标领域微调网络参数。最流行的基于网络的DTL方法是利用目标领域中少量标记数据对训练模型进行微调。然而，对于基于UDTL的IFD（智能故障诊断），目标领域中的标签是不可用的。我们使用带有瓶颈层的主干网络，包含一个Fc层（out_features=256）、一个ReLU激活函数、一个Dropout层（$p=0.5$）和一个基本的Softmax分类器来构建我们的基本模型（我们称之为Basis），如图[4](#S3.F4
    "Figure 4 ‣ III-A1 Basic concepts ‣ III-A Network-based UDTL ‣ III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")所示。训练好的模型直接用于测试目标领域中的样本，这意味着源领域和目标领域共享相同的模型和参数。'
- en: '![Refer to caption](img/7e83fc5e2c328e7672c3ee84e5d39196.png)'
  id: totrans-80
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/7e83fc5e2c328e7672c3ee84e5d39196.png)'
- en: 'Figure 4: The structure of the basic model.'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 图4：基本模型的结构。
- en: III-A2 Applications to IFD
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 应用于IFD
- en: Pre-trained deep neural networks using the source data were used in [[26](#bib.bib26),
    [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29), [30](#bib.bib30), [31](#bib.bib31),
    [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36),
    [37](#bib.bib37)] via frozing their partial parameters, and then part of network
    parameters were transferred to the target network and other parameters were fine-tuned
    with a small amount of target data. Pre-trained deep neural networks on ImageNet
    were used in [[38](#bib.bib38), [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41),
    [42](#bib.bib42)] and were fine-tuned with limited target data to adapt the domain
    of engineering applications. Ensemble techniques and multi-channel signals were
    used in [[43](#bib.bib43), [44](#bib.bib44)] to initialize the target network
    which was fine-tuned by a few training samples from the target domain. Two-dimensional
    images, such as grey images [[45](#bib.bib45)], time-frequency images [[46](#bib.bib46)],
    and thermal images [[47](#bib.bib47)], were used to pre-train the specific-designed
    networks, which were transferred to the target tasks via fine-tuning.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 使用源数据进行预训练的深度神经网络被用于[[26](#bib.bib26), [27](#bib.bib27), [28](#bib.bib28), [29](#bib.bib29),
    [30](#bib.bib30), [31](#bib.bib31), [32](#bib.bib32), [33](#bib.bib33), [34](#bib.bib34),
    [35](#bib.bib35), [36](#bib.bib36), [37](#bib.bib37)]，通过冻结其部分参数，然后将部分网络参数转移到目标网络，其他参数则使用少量目标数据进行微调。在[[38](#bib.bib38),
    [39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42)]上使用了在ImageNet上预训练的深度神经网络，并使用有限的目标数据对其进行微调，以适应工程应用领域。集成技术和多通道信号被用于[[43](#bib.bib43),
    [44](#bib.bib44)]来初始化目标网络，然后通过来自目标领域的少量训练样本对其进行微调。二维图像，如灰度图像[[45](#bib.bib45)]、时频图像[[46](#bib.bib46)]和热图像[[47](#bib.bib47)]，被用来预训练特定设计的网络，这些网络通过微调被转移到目标任务中。
- en: 'Qureshi et al. [[48](#bib.bib48)] pre-trained nine deep sparse auto-encoders
    on one wind farm, and predictions on another wind farm were taken by fine-tuning
    the pre-trained networks. Zhong et al. [[49](#bib.bib49)] trained a CNN on enough
    normal samples and then replaced Fc layers with support vector machine as the
    target model. Han et al. [[50](#bib.bib50)] discussed and compared three fine-tuning
    strategies: only fine-tuning the classifier, fine-tuning the feature descriptor,
    and fine-tuning both the feature descriptor and the classifier for diagnosing
    unseen machine conditions. Xu et al. [[51](#bib.bib51)] pre-trained the offline
    CNN on the source domain and directly transferred them to the shallow layers of
    the online CNN via fine-tuning the online CNN on the target domain for online
    IFD. Zhao et al. [[52](#bib.bib52)] proposed a multi-scale convolutional transfer
    learning network pre-trained on the source domain, and then the model was transferred
    to the other different but similar domains with proper fine-tuning.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: Qureshi等人[[48](#bib.bib48)] 在一个风电场上预训练了九个深度稀疏自编码器，并通过微调预训练的网络对另一个风电场进行预测。Zhong等人[[49](#bib.bib49)]
    在足够的正常样本上训练了一个CNN，然后用支持向量机替换Fc层作为目标模型。Han等人[[50](#bib.bib50)] 讨论并比较了三种微调策略：仅微调分类器、微调特征描述符，以及同时微调特征描述符和分类器以诊断未见过的机器条件。Xu等人[[51](#bib.bib51)]
    在源领域上对离线CNN进行预训练，并通过微调目标领域的在线CNN直接转移到在线CNN的浅层，以进行在线IFD。Zhao等人[[52](#bib.bib52)]
    提出了一个在源领域上预训练的多尺度卷积转移学习网络，然后通过适当的微调将模型转移到其他不同但类似的领域。
- en: III-B Instanced-based UDTL
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 基于实例的UDTL
- en: III-B1 Basic concepts
  id: totrans-86
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 基本概念
- en: Instanced-based UDTL refers to re-weight instances in the source domain to assist
    the classifier to predict labels or use statistics of instances to help align
    the target domain, such as TrAdaBoost [[53](#bib.bib53)] and adaptive Batch Normalization
    (AdaBN) [[54](#bib.bib54)]. In this paper, we use AdaBN to represent one of instanced-based
    UDTL methods, which does not require labels from the target domain.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 基于实例的UDTL指的是在源领域重新加权实例以帮助分类器预测标签，或使用实例统计信息来帮助对齐目标领域，例如TrAdaBoost[[53](#bib.bib53)]
    和自适应批归一化（AdaBN）[[54](#bib.bib54)]。在本文中，我们使用AdaBN来表示一种基于实例的UDTL方法，它不需要来自目标领域的标签。
- en: BN, which can be used to avoid the issue of the internal covariate shifting,
    is one of the most important techniques. BN can promote much faster training speed
    since it makes the input distribution more stable. Detailed descriptions and properties
    can be referred to [[55](#bib.bib55)]. It is worth mentioning that BN layers are
    only updated in the training procedure and the global statistics of training samples
    are used to normalize test samples during the test procedure.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: BN，作为一种避免内部协变量偏移问题的技术，是最重要的技术之一。BN可以显著提高训练速度，因为它使输入分布更加稳定。详细描述和属性可以参考[[55](#bib.bib55)]。值得一提的是，BN层仅在训练过程中更新，测试过程中使用训练样本的全局统计信息来标准化测试样本。
- en: AdaBN, which is a simple and parameter-free technique for the domain shift problem,
    was proposed in [[54](#bib.bib54)] to enhance the generalization ability. The
    main idea of AdaBN is that the global statistics of each BN layer are replaced
    with statistics in the target domain during the test phase. In our AdaBN realization,
    after training, we provide two updating strategies to fine-tune statistics of
    BN layers using target data, including updating via each batch and the whole data.
    In this paper, we update statistics of BN layers via each batch considering the
    memory limit.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: AdaBN，是一种简单且无参数的领域迁移问题技术，在[[54](#bib.bib54)]中提出，用于增强泛化能力。AdaBN的主要思想是，在测试阶段，用目标领域的统计数据替代每个BN层的全局统计数据。在我们的AdaBN实现中，训练后，我们提供了两种更新策略以使用目标数据微调BN层的统计数据，包括通过每个批次和整个数据进行更新。在本文中，考虑到内存限制，我们通过每个批次更新BN层的统计数据。
- en: III-B2 Applications to IFD
  id: totrans-90
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 应用于IFD
- en: Xiao et al. [[56](#bib.bib56)] used TrAdaBoost to enhance the diagnostic capability
    of the fault classifier by adjusting the weight factor of each training sample.
    Zhang et al. [[57](#bib.bib57)] and Qian et al. [[58](#bib.bib58)] used AdaBN
    to improve the domain adaptation ability of the model by ensuring that each layer
    receives data from a similar distribution.
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: Xiao等人[[56](#bib.bib56)] 使用TrAdaBoost通过调整每个训练样本的权重因子来增强故障分类器的诊断能力。Zhang等人[[57](#bib.bib57)]
    和Qian等人[[58](#bib.bib58)] 使用AdaBN通过确保每一层接收来自类似分布的数据来提高模型的领域适应能力。
- en: III-C Mapping-based UDTL
  id: totrans-92
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-C 基于映射的UDTL
- en: III-C1 Basic concepts
  id: totrans-93
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C1 基本概念
- en: Mapping-based UDTL refers to map instances from both source and target domains
    to the feature space via a feature extractor. There are many methods belonging
    to mapping-based UDTL, such as Euclidean distance, Minkowski distance, Kullback-Leibler,
    correlation alignment (CORAL) [[59](#bib.bib59)], maximum mean discrepancy (MMD)
    [[60](#bib.bib60), [61](#bib.bib61)], multi kernels MMD (MK-MMD) [[62](#bib.bib62),
    [21](#bib.bib21)], joint distribution adaptation (JDA) [[63](#bib.bib63)], balanced
    distribution adaptation (BDA) [[64](#bib.bib64)], and Joint Maximum Mean Discrepancy
    (JMMD) [[65](#bib.bib65)]. In this paper, we use MK-MMD, JMMD, and CORAL to represent
    mapping-based methods and test their performance.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 基于映射的 UDTL 指的是通过特征提取器将源域和目标域的实例映射到特征空间。基于映射的 UDTL 有许多方法，例如欧几里得距离、明可夫斯基距离、Kullback-Leibler、相关对齐
    (CORAL) [[59](#bib.bib59)]、最大均值差异 (MMD) [[60](#bib.bib60), [61](#bib.bib61)]、多核
    MMD (MK-MMD) [[62](#bib.bib62), [21](#bib.bib21)]、联合分布适应 (JDA) [[63](#bib.bib63)]、平衡分布适应
    (BDA) [[64](#bib.bib64)] 和联合最大均值差异 (JMMD) [[65](#bib.bib65)]。在本文中，我们使用 MK-MMD、JMMD
    和 CORAL 来表示基于映射的方法并测试其性能。
- en: 'MK-MMD: To introduce the definition of MK-MMD, we briefly explain the concept
    of MMD. MMD was first proposed in [[60](#bib.bib60)] and was used in transfer
    learning by many other scholars [[66](#bib.bib66), [67](#bib.bib67)]. MMD defined
    in Reproducing Kernel Hilbert Space (RKHS) is a squared distance between the kernel
    embedding of marginal distributions $P(X_{s})$ and $Q(X_{t})$. RKHS is a Hilbert
    space of functions in which point evaluation is a continuous linear functional,
    and some examples can be found in [[68](#bib.bib68)]. The formula of MMD can be
    written as follows:'
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: MK-MMD：为了介绍 MK-MMD 的定义，我们简要解释 MMD 的概念。MMD 首次在 [[60](#bib.bib60)] 中提出，并被许多其他学者在迁移学习中使用
    [[66](#bib.bib66), [67](#bib.bib67)]。在再生核希尔伯特空间 (RKHS) 中定义的 MMD 是边际分布 $P(X_{s})$
    和 $Q(X_{t})$ 的核嵌入之间的平方距离。RKHS 是一个函数的希尔伯特空间，其中点评估是一个连续的线性泛函，一些例子可以在 [[68](#bib.bib68)]
    中找到。MMD 的公式可以写作：
- en: '|  | $\displaystyle\mathcal{L}_{\text{MMD}}\left(P,Q\right)=\left\&#124;\mathbb{E}_{P}\left({\phi\left({x^{s}}\right)}\right)-\mathbb{E}_{Q}\left({\phi\left({x^{t}}\right)}\right)\right\&#124;^{2}_{\mathcal{H}_{k}},$
    |  | (7) |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{MMD}}\left(P,Q\right)=\left\&#124;\mathbb{E}_{P}\left({\phi\left({x^{s}}\right)}\right)-\mathbb{E}_{Q}\left({\phi\left({x^{t}}\right)}\right)\right\&#124;^{2}_{\mathcal{H}_{k}},$
    |  | (7) |'
- en: where $\mathcal{H}_{k}$ is RKHS using the kernel $k$ (in general, Gaussian kernel
    is used as the kernel), and $\phi(\cdot)$ is the mapping to RKHS.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\mathcal{H}_{k}$ 是使用核 $k$ 的 RKHS（通常使用高斯核作为核），$\phi(\cdot)$ 是映射到 RKHS。
- en: Parameter selection of each kernel is crucial to the final performance. To tackle
    this problem, MK-MMD, which could maximize the two-sample test power and minimize
    the Type II error jointly, was proposed by Gretton et al [[62](#bib.bib62)]. For
    MK-MMD, scholars often use the convex combination of $m$ kernels $\left\{k_{u}\right\}$
    to provide effective estimations of the mapping.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 每个核的参数选择对最终性能至关重要。为了解决这个问题，Gretton 等人提出了 MK-MMD，该方法能够最大化双样本检验的效能并共同最小化第二类错误[[62](#bib.bib62)]。对于
    MK-MMD，学者们通常使用 $m$ 个核 $\left\{k_{u}\right\}$ 的凸组合来提供有效的映射估计。
- en: '|  | $\displaystyle K\mathop{=}\limits^{\Delta}\left\{{k=\sum\limits_{u=1}^{m}{{\alpha_{u}}{k_{u}}:\sum\limits_{u=1}^{m}{{\alpha_{u}}=1},\alpha\geq
    0,\forall u}}\right\},$ |  | (8) |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle K\mathop{=}\limits^{\Delta}\left\{{k=\sum\limits_{u=1}^{m}{{\alpha_{u}}{k_{u}}:\sum\limits_{u=1}^{m}{{\alpha_{u}}=1},\alpha\geq
    0,\forall u}}\right\},$ |  | (8) |'
- en: where $\left\{\alpha_{u}\right\}$ are weighted parameters of different kernels
    (in this paper, all $\alpha_{u}=\frac{1}{m}$).
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\left\{\alpha_{u}\right\}$ 是不同核的加权参数（在本文中，所有 $\alpha_{u}=\frac{1}{m}$）。
- en: 'Inspired by deep adaptation networks (DAN) proposed in [[21](#bib.bib21)],
    we design an UDTL-based IFD model by adding MK-MMD into the loss function to realize
    the feature alignment shown in Fig. [5](#S3.F5 "Figure 5 ‣ III-C1 Basic concepts
    ‣ III-C Mapping-based UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"). In addition, the final loss function is defined as follows:'
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: '受 [[21](#bib.bib21)] 中提出的深度适应网络 (DAN) 的启发，我们通过将 MK-MMD 添加到损失函数中来设计基于 UDTL 的
    IFD 模型，以实现图中的特征对齐 [5](#S3.F5 "Figure 5 ‣ III-C1 Basic concepts ‣ III-C Mapping-based
    UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study")。此外，最终的损失函数定义如下：'
- en: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{MK-MMD}}\mathcal{L}_{\text{MK-MMD}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (9) |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{MK-MMD}}\mathcal{L}_{\text{MK-MMD}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (9) |'
- en: where $\lambda_{\text{MK-MMD}}$ is a trade-off parameter and $\mathcal{L}_{\text{MK-MMD}}$
    means the multi-kernel version of MMD. Besides, we simply use the Gaussian kernel
    and the number of kernels is equal to five. The bandwidth of each kernel is set
    to be median pairwise distances on training data according to the median heuristic
    [[62](#bib.bib62)].
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{MK-MMD}}$ 是一个权衡参数，$\mathcal{L}_{\text{MK-MMD}}$ 表示 MMD 的多核版本。此外，我们简单地使用高斯核，核的数量为五个。每个核的带宽设置为训练数据中的中位数成对距离，根据中位数启发式
    [[62](#bib.bib62)]。
- en: '![Refer to caption](img/aefa33b49e4e7497ac86a4c2fd94c347.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/aefa33b49e4e7497ac86a4c2fd94c347.png)'
- en: 'Figure 5: The UDTL-based IFD model based on MK-MMD.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：基于 MK-MMD 的 UDTL 模型。
- en: 'JMMD: MMD and MK-MMD, which are defined to solve the problem $P(X_{s})\neq
    Q(X_{t})$, cannot be used to tackle the domain shift generated by joint distributions
    (e.g. $P(X_{s},Y_{s})\neq Q(X_{t},Y_{t})$). Thus, JMMD, proposed in [[65](#bib.bib65)],
    was designed to measure the distance of empirical joint distributions $P(X_{s},Y_{s})$
    and $Q(X_{t},Y_{t})$. The formula of JMMD is written as follows [[65](#bib.bib65)]:'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: JMMD：MMD 和 MK-MMD 被定义用来解决问题 $P(X_{s})\neq Q(X_{t})$，但不能解决由联合分布生成的领域转移（例如 $P(X_{s},Y_{s})\neq
    Q(X_{t},Y_{t})$）。因此，JMMD，提出于 [[65](#bib.bib65)]，旨在衡量经验联合分布 $P(X_{s},Y_{s})$ 和
    $Q(X_{t},Y_{t})$ 之间的距离。JMMD 的公式如下 [[65](#bib.bib65)]：
- en: '|  |  | $\displaystyle\mathcal{L}_{\text{JMMD}}\left(P,Q\right)=$ |  | (10)
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathcal{L}_{\text{JMMD}}\left(P,Q\right)=$ |  | (10)
    |'
- en: '|  |  | $\displaystyle\left\&#124;\mathbb{E}_{P}\left({\otimes_{l=1}^{&#124;L&#124;}\phi^{l}\left({z_{l}^{s}}\right)}\right)-\mathbb{E}_{Q}\left(\otimes_{l=1}^{&#124;L&#124;}{\phi^{l}\left({z_{l}^{t}}\right)}\right)\right\&#124;^{2}_{\otimes_{l=1}^{&#124;L&#124;}{\mathcal{H}^{l}}},$
    |  |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\left\&#124;\mathbb{E}_{P}\left({\otimes_{l=1}^{&#124;L&#124;}\phi^{l}\left({z_{l}^{s}}\right)}\right)-\mathbb{E}_{Q}\left(\otimes_{l=1}^{&#124;L&#124;}{\phi^{l}\left({z_{l}^{t}}\right)}\right)\right\&#124;^{2}_{\otimes_{l=1}^{&#124;L&#124;}{\mathcal{H}^{l}}},$
    |  |'
- en: where $\otimes_{l=1}^{|L|}\phi^{l}\left({z_{l}}\right)=\phi^{1}\left({z_{1}}\right)\otimes\dots\otimes\phi^{|L|}\left({z_{|L|}}\right)$
    is the feature mapping in the tensor product Hilbert space, $L$ is the set of
    higher network layers, $|L|$ is the number of layers, $z_{l}^{s}$ means the activation
    of the $l-$th layer generated by the source domain, and $z_{l}^{t}$ means the
    activation of the $l-$th layer generated by the target domain.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\otimes_{l=1}^{|L|}\phi^{l}\left({z_{l}}\right)=\phi^{1}\left({z_{1}}\right)\otimes\dots\otimes\phi^{|L|}\left({z_{|L|}}\right)$
    是张量积希尔伯特空间中的特征映射，$L$ 是高层网络层的集合，$|L|$ 是层数，$z_{l}^{s}$ 表示由源领域生成的第 $l-$ 层激活，$z_{l}^{t}$
    表示由目标领域生成的第 $l-$ 层激活。
- en: 'Inspired by Joint Adaptation Network (JAN) which uses JMMD to align the domain
    shift [[65](#bib.bib65)], we design an UDTL-based IFD method by adding JMMD into
    the loss function to realize feature alignment shown in Fig. [6](#S3.F6 "Figure
    6 ‣ III-C1 Basic concepts ‣ III-C Mapping-based UDTL ‣ III Label-consistent UDTL
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study"). The final loss function is defined as follows:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '受使用 JMMD 对齐领域转移的联合适应网络（JAN） [[65](#bib.bib65)] 的启发，我们通过将 JMMD 添加到损失函数中设计了一种基于
    UDTL 的 IFD 方法，以实现图 [6](#S3.F6 "Figure 6 ‣ III-C1 Basic concepts ‣ III-C Mapping-based
    UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study") 所示的特征对齐。最终的损失函数定义如下：'
- en: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{JMMD}}\mathcal{L}_{\text{JMMD}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (11) |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{JMMD}}\mathcal{L}_{\text{JMMD}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (11) |'
- en: where $\lambda_{\text{JMMD}}$ is a trade-off parameter. Additionally, the parameter
    setting of JMMD is the same as that in JAN.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{JMMD}}$ 是一个权衡参数。此外，JMMD 的参数设置与 JAN 相同。
- en: '![Refer to caption](img/dee7f9a868370940c5d6c42177d550cc.png)'
  id: totrans-113
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/dee7f9a868370940c5d6c42177d550cc.png)'
- en: 'Figure 6: The UDTL-based IFD model based on JMMD.'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6：基于 JMMD 的 UDTL 模型。
- en: 'CORAL: The CORAL loss, which aims to align the second-order statistics of source
    and target distributions, was first proposed in [[69](#bib.bib69)] and was further
    used in UDTL [[59](#bib.bib59)]. First of all, following [[69](#bib.bib69)] and
    [[59](#bib.bib59)], we give the basic definition of the CORAL loss as:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: CORAL：CORAL 损失旨在对齐源领域和目标领域分布的二阶统计量，首次提出于 [[69](#bib.bib69)]，并在 UDTL [[59](#bib.bib59)]
    中进一步使用。首先，参考 [[69](#bib.bib69)] 和 [[59](#bib.bib59)]，我们给出 CORAL 损失的基本定义如下：
- en: '|  | $\displaystyle\mathcal{L}_{\text{CORAL}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right)=\dfrac{1}{4d^{2}}&#124;&#124;C^{s}-C^{t}&#124;&#124;_{F}^{2},$
    |  | (12) |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{CORAL}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right)=\dfrac{1}{4d^{2}}&#124;&#124;C^{s}-C^{t}&#124;&#124;_{F}^{2},$
    |  | (12) |'
- en: 'where $||\cdot||_{F}$ is the Frobenius norm and $d$ is the dimension of each
    sample. $C^{s}$ and $C^{t}$ defined in ([13](#S3.E13 "In III-C1 Basic concepts
    ‣ III-C Mapping-based UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")) are covariance matrices.'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $||\cdot||_{F}$ 是 Frobenius 范数，$d$ 是每个样本的维度。定义在 ([13](#S3.E13 "在 III-C1 基本概念
    ‣ III-C 基于映射的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")) 中的 $C^{s}$
    和 $C^{t}$ 是协方差矩阵。
- en: '|  | $\displaystyle C^{s}$ | $\displaystyle=\dfrac{1}{n_{s}-1}\left(X_{s}^{T}X_{s}-\dfrac{1}{n_{s}}(\textbf{1}^{T}X_{s})^{T}(\textbf{1}^{T}X_{s})\right),$
    |  | (13) |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle C^{s}$ | $\displaystyle=\dfrac{1}{n_{s}-1}\left(X_{s}^{T}X_{s}-\dfrac{1}{n_{s}}(\textbf{1}^{T}X_{s})^{T}(\textbf{1}^{T}X_{s})\right),$
    |  | (13) |'
- en: '|  | $\displaystyle C^{t}$ | $\displaystyle=\dfrac{1}{n_{t}-1}\left(X_{t}^{T}X_{t}-\dfrac{1}{n_{t}}(\textbf{1}^{T}X_{t})^{T}(\textbf{1}^{T}X_{t})\right),$
    |  |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle C^{t}$ | $\displaystyle=\dfrac{1}{n_{t}-1}\left(X_{t}^{T}X_{t}-\dfrac{1}{n_{t}}(\textbf{1}^{T}X_{t})^{T}(\textbf{1}^{T}X_{t})\right),$
    |  |'
- en: where 1 represents the column vector whose elements are all equal to one.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 1 表示元素均为 1 的列向量。
- en: 'Inspired by Deep CORAL proposed in [[59](#bib.bib59)], we design an UDTL-based
    IFD method by adding the CORAL loss into the loss function to realize the feature
    transfer shown in Fig. [7](#S3.F7 "Figure 7 ‣ III-C1 Basic concepts ‣ III-C Mapping-based
    UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study"). Also,
    the final loss function is defined as follows:'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 受 [[59](#bib.bib59)] 中提出的 Deep CORAL 启发，我们设计了一种基于 UDTL 的 IFD 方法，通过将 CORAL 损失添加到损失函数中来实现特征迁移，如图
    [7](#S3.F7 "图 7 ‣ III-C1 基本概念 ‣ III-C 基于映射的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    所示。此外，最终的损失函数定义如下：
- en: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{CORAL}}\mathcal{L}_{\text{CORAL}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (14) |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}=\mathcal{L}_{c}+\lambda_{\text{CORAL}}\mathcal{L}_{\text{CORAL}}\left(\mathcal{D}_{s},\mathcal{D}_{t}\right),$
    |  | (14) |'
- en: where $\lambda_{\text{CORAL}}$ is a trade-off parameter.
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{CORAL}}$ 是一个权衡参数。
- en: '![Refer to caption](img/5655f24ff777c5a4c57328dffe9492d8.png)'
  id: totrans-124
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/5655f24ff777c5a4c57328dffe9492d8.png)'
- en: 'Figure 7: The UDTL-based IFD model based on CORAL.'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 图 7：基于 CORAL 的 UDTL 训练的 IFD 模型。
- en: III-C2 Applications to IFD
  id: totrans-126
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-C2 应用到 IFD
- en: BDA was used in [[70](#bib.bib70), [71](#bib.bib71)] to adaptively balance the
    importance of the marginal and conditional distribution discrepancy between feature
    domains learned by deep neural networks for IFD. The CORAL loss [[72](#bib.bib72),
    [73](#bib.bib73)] and maximum variance discrepancy (MVD) [[74](#bib.bib74)] were
    used to reduce the distribution discrepancy between different domains. Qian et
    al. [[58](#bib.bib58), [75](#bib.bib75)] considered the higher-order moments and
    proposed an HKL divergence to adjust domain distributions for rotating machine
    fault diagnosis. The distance designed to measure source and target tensor representations
    was proposed in [[76](#bib.bib76)] to align tensor representations into the invariant
    tensor subspace for bearing fault diagnosis.
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: BDA 被用来[[70](#bib.bib70), [71](#bib.bib71)]自适应地平衡由深度神经网络学习的特征领域之间的边际和条件分布差异。CORAL
    损失 [[72](#bib.bib72), [73](#bib.bib73)] 和最大方差差异 (MVD) [[74](#bib.bib74)] 被用来减少不同领域之间的分布差异。Qian
    等人 [[58](#bib.bib58), [75](#bib.bib75)] 考虑了高阶矩，并提出了一种 HKL 散度来调整领域分布以进行旋转机器故障诊断。[[76](#bib.bib76)]
    提出了用于测量源和目标张量表示的距离，以将张量表示对齐到不变张量子空间，以进行轴承故障诊断。
- en: Another metric distance, called MMD, was widely used in the field of intelligent
    diagnosis [[77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79), [80](#bib.bib80),
    [81](#bib.bib81), [82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84), [85](#bib.bib85)].
    Tong et al. [[86](#bib.bib86), [87](#bib.bib87)] reduced marginal and conditional
    distributions simultaneously across domains based on MMD in the feature space
    by refining pseudo test labels for bearing fault diagnosis. Wang et al. [[88](#bib.bib88)]
    proposed a conditional MMD based on estimated pseudo labels to shorten the conditional
    distribution distance for bearing fault diagnosis. The marginal and conditional
    distributions were aligned simultaneously in multiple layers via minimizing MMD
    [[89](#bib.bib89), [90](#bib.bib90)]. Yang et al. [[91](#bib.bib91)] replaced
    the Gaussian kernel with a polynomial kernel in MMD for better aligning the distribution
    discrepancy. Cao et al. [[92](#bib.bib92)] proposed a pseudo-categorized MMD to
    narrow the intra-class cross-domain distribution discrepancy. MMD was also combined
    with other techniques, such as Grassmann manifold [[93](#bib.bib93)], locality
    preserving projection [[94](#bib.bib94)], and graph Laplacian regularization [[95](#bib.bib95),
    [96](#bib.bib96)], to boost the performance of distribution alignment.
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 另一种度量距离，称为 MMD，在智能诊断领域广泛使用 [[77](#bib.bib77), [78](#bib.bib78), [79](#bib.bib79),
    [80](#bib.bib80), [81](#bib.bib81), [82](#bib.bib82), [83](#bib.bib83), [84](#bib.bib84),
    [85](#bib.bib85)]。Tong 等人 [[86](#bib.bib86), [87](#bib.bib87)] 通过改进伪测试标签来减少特征空间中跨领域的边际和条件分布，同时用于轴承故障诊断。Wang
    等人 [[88](#bib.bib88)] 提出了基于估计伪标签的条件 MMD，以缩短轴承故障诊断中的条件分布距离。通过最小化 MMD [[89](#bib.bib89),
    [90](#bib.bib90)]，在多个层中同时对齐边际和条件分布。Yang 等人 [[91](#bib.bib91)] 用多项式核替代 MMD 中的高斯核，以更好地对齐分布差异。Cao
    等人 [[92](#bib.bib92)] 提出了伪分类 MMD，以缩小同类跨领域的分布差异。MMD 还与其他技术结合使用，如 Grassmann 流形 [[93](#bib.bib93)]、局部保持投影
    [[94](#bib.bib94)] 和图拉普拉斯正则化 [[95](#bib.bib95), [96](#bib.bib96)]，以提升分布对齐的性能。
- en: MK-MMD was used in [[97](#bib.bib97), [98](#bib.bib98), [99](#bib.bib99), [23](#bib.bib23),
    [100](#bib.bib100), [101](#bib.bib101)] to better transfer the distribution of
    learned features in the source domain to that in the target domain for IFD. Han
    et al. [[102](#bib.bib102)] and Qian et al. [[103](#bib.bib103)] used JDA to align
    both conditional and marginal distributions simultaneously to construct a more
    effective and robust feature representation for substantial distribution difference.
    Wu et al. [[104](#bib.bib104)] further used the grey wolf optimization algorithm
    to learn the parameters of JDA. Based on JMMD, Cao et al. [[105](#bib.bib105)]
    proposed a soft JMMD to reduce both the marginal and conditional distribution
    discrepancy with the enhancement of auxiliary soft labels.
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: MK-MMD 被用于 [[97](#bib.bib97), [98](#bib.bib98), [99](#bib.bib99), [23](#bib.bib23),
    [100](#bib.bib100), [101](#bib.bib101)]，以更好地将源领域中学习到的特征分布转移到目标领域中的分布，用于 IFD。Han
    等人 [[102](#bib.bib102)] 和 Qian 等人 [[103](#bib.bib103)] 使用 JDA 同时对齐条件和边际分布，以构建更有效且稳健的特征表示来应对显著的分布差异。Wu
    等人 [[104](#bib.bib104)] 进一步使用了灰狼优化算法来学习 JDA 的参数。基于 JMMD，Cao 等人 [[105](#bib.bib105)]
    提出了一个软 JMMD，通过增强辅助软标签来减少边际和条件分布的不一致。
- en: III-D Adversarial-based UDTL
  id: totrans-130
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-D 基于对抗的 UDTL
- en: III-D1 Basic concepts
  id: totrans-131
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D1 基本概念
- en: Adversarial-based UDTL refers to an adversarial method using a domain discriminator
    to reduce the feature distribution discrepancy between source and target domains
    produced by a feature extractor. In this paper, we use two commonly used methods
    including domain adversarial neural network (DANN) [[106](#bib.bib106)] and conditional
    domain adversarial network (CDAN) [[107](#bib.bib107)] to represent adversarial-based
    methods and test the corresponding accuracy.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 基于对抗的 UDTL 指使用领域判别器的对抗方法，以减少由特征提取器产生的源领域与目标领域之间的特征分布差异。在本文中，我们使用两种常用的方法，包括领域对抗神经网络
    (DANN) [[106](#bib.bib106)] 和条件领域对抗网络 (CDAN) [[107](#bib.bib107)]，来代表基于对抗的方法并测试相应的准确性。
- en: 'DANN: Similar to MMD and MK-MMD, DANN is defined to solve the problem $P(X_{s})\neq
    Q(X_{t})$. It aims to train a feature extractor, a domain discriminator distinguishing
    source and target domains, and a class predictor, simultaneously to align source
    and target distributions. That is, DANN trains the feature extractor to prevent
    the domain discriminator from distinguishing differences between two domains.
    Let $G_{f}$ be the feature extractor whose parameters are $\theta_{f}$, $G_{c}$
    be the class predictor whose parameters are $\theta_{c}$, and $G_{d}$ be the domain
    discriminator whose parameters are $\theta_{d}$. After that, the prediction loss
    and the adversarial loss (the binary cross-entropy loss) can be rewritten as follows:'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: DANN：类似于 MMD 和 MK-MMD，DANN 被定义为解决 $P(X_{s})\neq Q(X_{t})$ 的问题。它旨在同时训练特征提取器、区分源领域和目标领域的领域判别器以及分类预测器，以对齐源领域和目标领域的分布。也就是说，DANN
    训练特征提取器，以防止领域判别器区分两个领域之间的差异。设 $G_{f}$ 为特征提取器，其参数为 $\theta_{f}$，$G_{c}$ 为分类预测器，其参数为
    $\theta_{c}$，$G_{d}$ 为领域判别器，其参数为 $\theta_{d}$。之后，预测损失和对抗损失（二元交叉熵损失）可以重新写为：
- en: '|  |  | $\displaystyle\mathcal{L}_{c}(\theta_{f},\theta_{c})=$ |  | (15) |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathcal{L}_{c}(\theta_{f},\theta_{c})=$ |  | (15) |'
- en: '|  |  | $\displaystyle-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[G_{c}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{c}\right)\right],$
    |  |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[G_{c}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{c}\right)\right],$
    |  |'
- en: '|  | $\displaystyle\mathcal{L}_{\text{DANN}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (16) |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{DANN}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (16) |'
- en: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right].$
    |  |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right].$
    |  |'
- en: 'To sum up, the total loss of DANN can be defined as:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 总结来说，DANN 的总损失可以定义为：
- en: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{DANN}}\mathcal{L}_{\text{DANN}}\left(\theta_{f},\theta_{d}\right),$
    |  | (17) |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{DANN}}\mathcal{L}_{\text{DANN}}\left(\theta_{f},\theta_{d}\right),$
    |  | (17) |'
- en: where $\lambda_{\text{DANN}}$ is a trade-off parameter.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{DANN}}$ 是一个权衡参数。
- en: 'During the training procedure, we need to minimize the prediction loss to allow
    the class predictor to predict true labels as much as possible. Additionally,
    we also need to maximize the adversarial loss to make the domain discriminator
    difficult to distinguish differences. Thus, solving the saddle point problem ($\hat{\theta}_{f},\hat{\theta}_{c},\hat{\theta}_{d}$)
    is equivalent to the following minimax optimization problem:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 在训练过程中，我们需要最小化预测损失，以使分类预测器尽可能准确地预测真实标签。此外，我们还需要最大化对抗损失，使领域判别器难以区分差异。因此，解决鞍点问题
    ($\hat{\theta}_{f},\hat{\theta}_{c},\hat{\theta}_{d}$) 等同于以下的极小极大优化问题：
- en: '|  | $\displaystyle\left(\hat{\theta_{f}},\hat{\theta_{c}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{f},\theta_{c}}\mathcal{L}\left(\theta_{f},\theta_{c},\hat{\theta}_{d}\right),$
    |  | (18) |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left(\hat{\theta_{f}},\hat{\theta_{c}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{f},\theta_{c}}\mathcal{L}\left(\theta_{f},\theta_{c},\hat{\theta}_{d}\right),$
    |  | (18) |'
- en: '|  | $\displaystyle\left(\hat{\theta_{d}}\right)$ | $\displaystyle=\arg\max\limits_{\theta_{d}}\mathcal{L}\left(\hat{\theta}_{f},\hat{\theta}_{c},\theta_{d}\right).$
    |  |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left(\hat{\theta_{d}}\right)$ | $\displaystyle=\arg\max\limits_{\theta_{d}}\mathcal{L}\left(\hat{\theta}_{f},\hat{\theta}_{c},\theta_{d}\right).$
    |  |'
- en: Following the statement in [[106](#bib.bib106)], we can simply add a special
    gradient reversal layer (GRL), which changes signs of the gradient from the subsequent
    level and is parameter-free, to solve the above optimization problem.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 根据[[106](#bib.bib106)]中的说法，我们可以简单地添加一个特殊的梯度反转层（GRL），它会改变来自后续层的梯度符号，并且没有参数，以解决上述优化问题。
- en: 'We design an UDTL-based IFD model via adding the adversarial idea into the
    loss function to realize the feature transfer between source and target domains
    shown in Fig. [8](#S3.F8 "Figure 8 ‣ III-D1 Basic concepts ‣ III-D Adversarial-based
    UDTL ‣ III Label-consistent UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study"). It
    can be observed that we use a three-layer Fc binary classifier as our domain discriminator
    which is the same as [[106](#bib.bib106)]. The output features of these Fc layers
    are 1024 (Fc1), 1024 (Fc2), and 2 (Fc3), respectively. The parameter of a Dropout
    layer is $p=0.5$.'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一个基于 UDTL 的 IFD 模型，通过将对抗思想添加到损失函数中，实现源领域和目标领域之间的特征转移，如图 [8](#S3.F8 "图 8
    ‣ III-D1 基本概念 ‣ III-D 基于对抗的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    所示。可以观察到，我们使用了一个三层 Fc 二分类器作为我们的领域鉴别器，这与 [[106](#bib.bib106)] 中的相同。这些 Fc 层的输出特征分别为
    1024（Fc1）、1024（Fc2）和 2（Fc3）。Dropout 层的参数为 $p=0.5$。
- en: '![Refer to caption](img/a48484e84fa19dfbb0fdfc7461fa5396.png)'
  id: totrans-146
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a48484e84fa19dfbb0fdfc7461fa5396.png)'
- en: 'Figure 8: The UDTL-based IFD model based on DANN.'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：基于 DANN 的 UDTL 领域智能故障诊断模型。
- en: 'CDAN: Although DANN can align the distributions of two domains efficiently,
    there may still exist some bottlenecks. As stated in [[107](#bib.bib107)], DANN
    cannot capture complex multi-modal structures and it is hard to condition the
    domain discriminator safely. Based on this statement, Long et al. [[107](#bib.bib107)]
    proposed a new adversarial-based UDTL model called CDAN to solve the problem $P(X_{s},Y_{s})\neq
    Q(X_{t},Y_{t})$. To briefly introduce the main idea inside CDAN, we first need
    to define the multi-linear map $\otimes$, which means the outer product of multiple
    random vectors. If two random vectors $x$ and $y$ are given, the mean mapping
    $x\otimes y$ can capture the complex multi-modal structures inside the data completely.
    Besides, the cross-covariance $\mathbb{E}_{xy}[\phi(x)\otimes\phi(y)]$ can be
    used to model the joint distribution $P(x,y)$ successfully. Thus, the conditional
    adversarial loss is defined as follows:'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
  zh: CDAN：虽然 DANN 能够有效对齐两个领域的分布，但仍可能存在一些瓶颈。如[[107](#bib.bib107)]所述，DANN 无法捕捉复杂的多模态结构，并且难以安全地调整领域鉴别器。基于这一点，Long
    等人[[107](#bib.bib107)] 提出了一个新的基于对抗的 UDTL 模型，称为 CDAN，以解决问题 $P(X_{s},Y_{s})\neq
    Q(X_{t},Y_{t})$。要简要介绍 CDAN 的主要思想，我们首先需要定义多线性映射 $\otimes$，它表示多个随机向量的外积。如果给定两个随机向量
    $x$ 和 $y$，均值映射 $x\otimes y$ 可以完全捕捉数据中的复杂多模态结构。此外，交叉协方差 $\mathbb{E}_{xy}[\phi(x)\otimes\phi(y)]$
    可以成功地建模联合分布 $P(x,y)$。因此，条件对抗损失定义如下：
- en: '|  | $\displaystyle\mathcal{L}_{\text{CDAN}}$ | $\displaystyle(\theta_{f},\theta_{d})=-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d}\left(G_{f}(x_{i}^{s})\otimes
    G_{c}\left(G_{f}(x_{i}^{s})\right)\right)\right]$ |  | (19) |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{CDAN}}$ | $\displaystyle(\theta_{f},\theta_{d})=-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d}\left(G_{f}(x_{i}^{s})\otimes
    G_{c}\left(G_{f}(x_{i}^{s})\right)\right)\right]$ |  | (19) |'
- en: '|  |  | $\displaystyle-\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}(x_{i}^{t})\otimes
    G_{c}\left(G_{f}(x_{i}^{t})\right)\right)\right],$ |  |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle-\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}(x_{i}^{t})\otimes
    G_{c}\left(G_{f}(x_{i}^{t})\right)\right)\right],$ |  |'
- en: 'and the prediction loss is the same as that in ([15](#S3.E15 "In III-D1 Basic
    concepts ‣ III-D Adversarial-based UDTL ‣ III Label-consistent UDTL ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")).'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 预测损失与 ([15](#S3.E15 "在 III-D1 基本概念 ‣ III-D 基于对抗的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究"))
    中的相同。
- en: 'To relax the influence with uncertain predictions, the entropy criterion $H(p)=-\sum_{c=0}^{C-1}p_{c}\log
    p_{c}$ is used to define the uncertainty of predictions by classifiers, where
    $p_{c}$ is the probability of the predicted result corresponding to the label
    $c$. According to the defined entropy-aware weight function shown in ([20](#S3.E20
    "In III-D1 Basic concepts ‣ III-D Adversarial-based UDTL ‣ III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")), those hard-to-transfer samples are
    re-weighted with lower weights in the modified conditional adversarial loss ([21](#S3.E21
    "In III-D1 Basic concepts ‣ III-D Adversarial-based UDTL ‣ III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")):'
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减轻不确定预测的影响，采用熵准则 $H(p)=-\sum_{c=0}^{C-1}p_{c}\log p_{c}$ 来定义分类器预测的不确定性，其中
    $p_{c}$ 是预测结果对应标签 $c$ 的概率。根据在 ([20](#S3.E20 "在 III-D1 基本概念 ‣ III-D 基于对抗的 UDTL
    ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")) 中定义的熵感知权重函数，那些难以迁移的样本在修改后的条件对抗损失中被重新加权为较低的权重
    ([21](#S3.E21 "在 III-D1 基本概念 ‣ III-D 基于对抗的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究"))：
- en: '|  | $\displaystyle w\left(H\left(p\right)\right)=1+e^{-H\left(p\right)}.$
    |  | (20) |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle w\left(H\left(p\right)\right)=1+e^{-H\left(p\right)}.$
    |  | (20) |'
- en: '|  | $\displaystyle\mathcal{L}_{\text{CDAN}}(\theta_{f},\theta_{d})=$ | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}w\left(H\left(p_{i}^{s}\right)\right)$
    |  | (21) |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{CDAN}}(\theta_{f},\theta_{d})=$ | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}w\left(H\left(p_{i}^{s}\right)\right)$
    |  | (21) |'
- en: '|  |  | $\displaystyle\log\left[G_{d}\left(G_{f}(x_{i}^{s})\otimes G_{c}\left(G_{f}(x_{i}^{s})\right)\right)\right]$
    |  |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\log\left[G_{d}\left(G_{f}(x_{i}^{s})\otimes G_{c}\left(G_{f}(x_{i}^{s})\right)\right)\right]$
    |  |'
- en: '|  |  | $\displaystyle-\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}w\left(H\left(p_{i}^{t}\right)\right)$
    |  |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle-\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}w\left(H\left(p_{i}^{t}\right)\right)$
    |  |'
- en: '|  |  | $\displaystyle\log\left[1-G_{d}\left(G_{f}(x_{i}^{t})\otimes G_{c}\left(G_{f}(x_{i}^{t})\right)\right)\right].$
    |  |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\log\left[1-G_{d}\left(G_{f}(x_{i}^{t})\otimes G_{c}\left(G_{f}(x_{i}^{t})\right)\right)\right].$
    |  |'
- en: 'We design an UDTL-based IFD model via embedding the conditional adversarial
    idea into the loss function to realize the feature transfer shown in Fig. [9](#S3.F9
    "Figure 9 ‣ III-D1 Basic concepts ‣ III-D Adversarial-based UDTL ‣ III Label-consistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study"). Also, the final loss function is
    defined as follows:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一种基于 UDTL 的 IFD 模型，通过将条件对抗思想嵌入损失函数中，实现了特征迁移，如图 [9](#S3.F9 "图 9 ‣ III-D1
    基本概念 ‣ III-D 基于对抗的 UDTL ‣ III 标签一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究") 所示。此外，最终的损失函数定义如下：
- en: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{CDAN}}\mathcal{L}_{\text{CDAN}}\left(\theta_{f},\theta_{d}\right),$
    |  | (22) |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{CDAN}}\mathcal{L}_{\text{CDAN}}\left(\theta_{f},\theta_{d}\right),$
    |  | (22) |'
- en: where $\lambda_{\text{CDAN}}$ is a trade-off parameter.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{CDAN}}$ 是一个权衡参数。
- en: '![Refer to caption](img/e3f1bf7d525a26bf43115bd4ec006b3a.png)'
  id: totrans-161
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/e3f1bf7d525a26bf43115bd4ec006b3a.png)'
- en: 'Figure 9: The UDTL-based IFD model based on CDAN.'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：基于 CDAN 的 UDTL IFD 模型。
- en: III-D2 Applications to IFD
  id: totrans-163
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-D2 应用于 IFD
- en: In [[108](#bib.bib108), [109](#bib.bib109), [110](#bib.bib110), [111](#bib.bib111),
    [112](#bib.bib112), [113](#bib.bib113), [114](#bib.bib114), [115](#bib.bib115)],
    the feature extractor was pre-trained with the labeled source data and was used
    to generate target features. After that, features from source and target domains
    were trained to maximize the domain discriminator loss, leading to distribution
    alignment for IFD. Classifier discrepancy [[116](#bib.bib116), [117](#bib.bib117),
    [118](#bib.bib118)], which means using separate classifiers for source and target
    domains, was introduced in UDTL-based IFD via an adversarial training process.
    Meanwhile, adversarial training was also combined with other metric distances,
    such as L1 alignment [[119](#bib.bib119)], MMD [[120](#bib.bib120)], MK-MMD [[121](#bib.bib121)],
    and JMMD [[122](#bib.bib122)], to better match the feature distributions between
    different domains for IFD. Li et al. [[123](#bib.bib123)] used two feature extractors
    and classifiers trained using MMD and domain adversarial training, respectively,
    and meanwhile ensemble learning was further utilized to obtain the final results.
    Qin et al. [[124](#bib.bib124)] proposed a multiscale transfer voting mechanism
    (MSTVM) to improve the classical domain adaption models and the verified model
    was trained by MMD and domain adversarial training. In addition, Qin et al. also
    proposed the parameter sharing [[125](#bib.bib125)] and multiscale [[126](#bib.bib126)]
    ideologies to reduce the complexity of network structures and extract more domain-invariant
    features. The verified models were trained by domain adversarial training embedded
    with metric distances, like MMD and CORAL.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[108](#bib.bib108)、[109](#bib.bib109)、[110](#bib.bib110)、[111](#bib.bib111)、[112](#bib.bib112)、[113](#bib.bib113)、[114](#bib.bib114)、[115](#bib.bib115)]中，特征提取器经过预训练，使用标记的源数据，并用于生成目标特征。之后，源域和目标域的特征被训练以最大化领域判别器损失，从而实现IFD的分布对齐。分类器差异[[116](#bib.bib116)、[117](#bib.bib117)、[118](#bib.bib118)]，即为源域和目标域使用不同的分类器，通过对抗训练过程引入到基于UDTL的IFD中。同时，对抗训练也与其他度量距离结合，如L1对齐[[119](#bib.bib119)]、MMD[[120](#bib.bib120)]、MK-MMD[[121](#bib.bib121)]和JMMD[[122](#bib.bib122)]，以更好地匹配不同域之间的特征分布以用于IFD。Li等人[[123](#bib.bib123)]使用了两个特征提取器和使用MMD和领域对抗训练分别训练的分类器，同时进一步利用集成学习获得最终结果。Qin等人[[124](#bib.bib124)]提出了一种多尺度迁移投票机制（MSTVM）来改进经典的领域适应模型，并通过MMD和领域对抗训练对验证模型进行了训练。此外，Qin等人还提出了参数共享[[125](#bib.bib125)]和多尺度[[126](#bib.bib126)]理念，以减少网络结构的复杂性并提取更多领域不变特征。验证模型通过嵌入度量距离的领域对抗训练进行训练，如MMD和CORAL。
- en: Wasserstein distance was used in [[127](#bib.bib127), [128](#bib.bib128), [129](#bib.bib129),
    [130](#bib.bib130)] to guide adversarial training for aligning the discrepancy
    of distributions for IFD. Yu et al. [[131](#bib.bib131)] combined conditional
    adversarial DA with a center-based discriminative loss to realize both distribution
    discrepancy and feature discrimination for locomotive fault diagnosis. Li et al.
    [[132](#bib.bib132)] proposed a strategy for bearing fault diagnosis based on
    minimizing the joint distribution domain-adversarial loss which embedded the pseudo-label
    information into the adversarial training process. Besides, another strategy using
    adversarial-based methods contained adopting GAN to generate samples for the target
    domain [[133](#bib.bib133), [134](#bib.bib134)].
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
  zh: Wasserstein距离在[[127](#bib.bib127)、[128](#bib.bib128)、[129](#bib.bib129)、[130](#bib.bib130)]中用于指导对抗训练，以对齐IFD的分布差异。Yu等人[[131](#bib.bib131)]将条件对抗DA与基于中心的判别损失结合起来，实现了对分布差异和特征判别的联合优化，用于机车故障诊断。Li等人[[132](#bib.bib132)]提出了一种基于最小化联合分布领域对抗损失的策略，该策略将伪标签信息嵌入到对抗训练过程中。此外，另一种使用对抗方法的策略包括采用GAN生成目标域样本[[133](#bib.bib133)、[134](#bib.bib134)]。
- en: IV Label-inconsistent UDTL
  id: totrans-166
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 标签不一致的UDTL
- en: Considering that the label sets of source and target domains are hard to be
    consistent in real application, it is significant to study the label-inconsistent
    UDTL. In this paper, three label-inconsistent transfer settings, including partial
    UDTL, open set UDTL, and universal UDTL, are studied.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到源域和目标域的标签集在实际应用中难以一致，研究标签不一致的UDTL是重要的。在本文中，研究了三种标签不一致的迁移设置，包括部分UDTL、开放集UDTL和通用UDTL。
- en: IV-A Partial UDTL
  id: totrans-168
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 部分 UDTL
- en: IV-A1 Basic concepts
  id: totrans-169
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A1 基本概念
- en: Partial UDTL, which was proposed in [[135](#bib.bib135)], is a transfer learning
    paradigm where the target label set ${{\cal C}_{t}}$ is a subspace of the source
    label set ${{\cal C}_{s}}$, i.e. ${{\cal C}_{t}}\subset{{\cal C}_{s}}$.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
  zh: 部分UDTL是在[[135](#bib.bib135)]中提出的一种转移学习范式，其中目标标签集${{\cal C}_{t}}$是源标签集${{\cal
    C}_{s}}$的子空间，即${{\cal C}_{t}}\subset{{\cal C}_{s}}$。
- en: IV-A2 Partial adversarial domain adaptation (PADA)
  id: totrans-171
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A2 部分对抗领域自适应（PADA）
- en: One of popular partial UDTL methods named partial adversarial domain adaptation
    (PADA) was proposed by Cao et. al [[136](#bib.bib136)]. The model of PADA is similar
    to DANN and further considers that probabilities of assigning target data to the
    source-private classes would be small, and label predictions on all target data
    are average to quantify the contribution of each source class.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 一种流行的部分UDTL方法，名为部分对抗领域自适应（PADA），是由Cao等人提出的[[136](#bib.bib136)]。PADA的模型类似于DANN，并进一步考虑将目标数据分配给来源私有类的概率很小，并且对所有目标数据的标签预测进行平均以量化每个来源类的贡献。
- en: '|  | $\displaystyle\gamma=\frac{1}{n_{t}}\sum\limits_{i=1}^{n_{t}}{y_{i}^{t}}.$
    |  | (23) |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\gamma=\frac{1}{n_{t}}\sum\limits_{i=1}^{n_{t}}{y_{i}^{t}}.$
    |  | (23) |'
- en: 'After normalizing $\gamma$ by its maximum value, $\hat{\gamma}$ is served as
    a class-level weight:'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: 将$\gamma$归一化后，$\hat{\gamma}$作为类级权重：
- en: '|  | $\displaystyle\hat{\gamma}=\frac{\gamma}{\max\left(\gamma\right)}.$ |  |
    (24) |'
  id: totrans-175
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\hat{\gamma}=\frac{\gamma}{\max\left(\gamma\right)}.$ |  |
    (24) |'
- en: 'Via applying this class-level weight to the loss of the class predictor and
    domain discriminator, contributions of source samples belonging to source-private
    classes can be reduced. The prediction and adversarial losses are rewritten as
    follows:'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
  zh: 通过将这种类级权重应用到类预测器和域鉴别器的损失中，可以减少属于源私有类的源样本的贡献。预测和对抗损失重写如下：
- en: '|  | $\displaystyle\mathcal{L}_{c}(\theta_{f},\theta_{c})=$ | $\displaystyle-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}{\hat{\gamma}_{y_{i}^{s}}}$
    |  | (25) |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{c}(\theta_{f},\theta_{c})=$ | $\displaystyle-\mathbb{E}_{\left(x_{i}^{s},y_{i}^{s}\right)\in\mathcal{D}_{s}}{\hat{\gamma}_{y_{i}^{s}}}$
    |  | (25) |'
- en: '|  |  | $\displaystyle\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[G_{c}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{c}\right)\right].$
    |  |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\sum_{c=0}^{C-1}\mathbf{1}_{[y_{i}^{s}=c]}\log\left[G_{c}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{c}\right)\right].$
    |  |'
- en: '|  | $\displaystyle\mathcal{L}_{\text{PADA}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}{\hat{\gamma}_{y_{i}^{s}}}\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (26) |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{PADA}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}{\hat{\gamma}_{y_{i}^{s}}}\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (26) |'
- en: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right],$
    |  |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right],$
    |  |'
- en: where $y_{i}^{s}$ is the truth label of source sample $x_{i}^{s}$, $\hat{\gamma}_{y_{i}^{s}}$
    is the normalized class weight, and $\lambda_{\text{PADA}}$ is a trade-off parameter.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 其中$y_{i}^{s}$是源样本$x_{i}^{s}$的真实标签，$\hat{\gamma}_{y_{i}^{s}}$是归一化的类权重，$\lambda_{\text{PADA}}$是一个权衡参数。
- en: '![Refer to caption](img/a4305db3ff04881b7d2ce7a4d1bde976.png)'
  id: totrans-182
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/a4305db3ff04881b7d2ce7a4d1bde976.png)'
- en: 'Figure 10: The UDTL-based model based on PADA.'
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10：基于PADA的UDTL模型。
- en: 'We design an UDTL-based model via applying the class-level weight to the loss
    function to reduce the influence of outlier source classes as shown in Fig. [10](#S4.F10
    "Figure 10 ‣ IV-A2 Partial adversarial domain adaptation (PADA) ‣ IV-A Partial
    UDTL ‣ IV Label-inconsistent UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study"). The
    final loss function is defined as follows:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: '我们设计了一个基于UDTL的模型，通过将类级权重应用到损失函数中，减少离群源类的影响，如图 [10](#S4.F10 "Figure 10 ‣ IV-A2
    Partial adversarial domain adaptation (PADA) ‣ IV-A Partial UDTL ‣ IV Label-inconsistent
    UDTL ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")所示。最终的损失函数定义如下：'
- en: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{PADA}}\mathcal{L}_{\text{PADA}}\left(\theta_{f},\theta_{d}\right).$
    |  | (27) |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{PADA}}\mathcal{L}_{\text{PADA}}\left(\theta_{f},\theta_{d}\right).$
    |  | (27) |'
- en: IV-A3 Applications to IFD
  id: totrans-186
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-A3 应用到IFD
- en: In [[137](#bib.bib137)], two classification networks were constructed and the
    class-level weights for the source domain were calculated using the target label
    predictions of two networks, and then weights were applied to the source classification
    loss to down-weight the influence of outlier source samples. Li et al. [[138](#bib.bib138)]
    added weight modules to the adversarial transfer network and a weighting learning
    strategy was constructed to quantify the transferability of source samples. Via
    filtering out irrelevant source samples, the distribution discrepancy across domains
    in the shared label space could be reduced. Li et al. [[139](#bib.bib139)] proposed
    a conditional data alignment technique to align distributions of healthy data
    and a prediction consistency technique to align the distributions of other classes
    in two domains. In [[140](#bib.bib140)], to facilitate the positive transfer of
    shared classes and reduce the negative transfer of outlier classes, the average
    domain prediction loss of each source class was used as the class-level weight.
    To avoid the potential negative effect and preserve the inter-class relationships,
    Wang et al. [[141](#bib.bib141)] proposed to unilaterally align the target domain
    to the source domain via adding a consistency loss which forces aligned source
    features to be close to pre-trained source features. Deng et al. [[142](#bib.bib142)]
    constructed sub-domain discriminator for each class to achieve better flexibility.
    A double layer attention mechanism was proposed to assign different attentions
    to sub-domain discriminators and different attentions to samples for selecting
    relevant samples. Yang et al. [[143](#bib.bib143)] proposed to learn domain-asymmetry
    factors via training a domain discriminator and source samples were weighted in
    the distribution adaptation to block irrelevant knowledge.
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
  zh: 在[[137](#bib.bib137)]中，构建了两个分类网络，并使用两个网络的目标标签预测计算了源领域的类别级权重，然后将权重应用于源分类损失，以减少异常源样本的影响。Li等人[[138](#bib.bib138)]为对抗转移网络添加了权重模块，并构建了一种加权学习策略来量化源样本的可转移性。通过筛选不相关的源样本，可以减少共享标签空间中领域间的分布差异。Li等人[[139](#bib.bib139)]提出了一种条件数据对齐技术，用于对齐健康数据的分布，并提出了一种预测一致性技术来对齐两个领域中其他类别的分布。在[[140](#bib.bib140)]中，为了促进共享类别的正向转移并减少异常类别的负向转移，每个源类别的平均领域预测损失被用作类别级权重。为了避免潜在的负面影响并保持类别间的关系，Wang等人[[141](#bib.bib141)]提出通过添加一致性损失单方面对齐目标领域与源领域，这种损失迫使对齐的源特征接近于预训练的源特征。Deng等人[[142](#bib.bib142)]为每个类别构建了子领域判别器，以实现更好的灵活性。提出了一种双层注意机制，为子领域判别器和样本分配不同的注意力，以选择相关样本。Yang等人[[143](#bib.bib143)]提出通过训练领域判别器来学习领域不对称因素，并在分布适应中对源样本进行加权，以阻止不相关知识。
- en: IV-B Open set UDTL
  id: totrans-188
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 开放集UDTL
- en: IV-B1 Basic concepts
  id: totrans-189
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B1 基本概念
- en: Considering that the label space of target domain is uncertain for UDTL, Saito
    et al. proposed open set domain adaptation (OSDA) that the target domain could
    contain samples of classes which were absent in the source domain [[144](#bib.bib144)],
    i.e. ${{\cal C}_{s}}\subset{{\cal C}_{t}}$. The goal of OSDA is to correctly classify
    known-class target samples and recognize unknown-class target samples as an additional
    class.
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到目标领域的标签空间对UDTL而言是不确定的，Saito等人提出了开放集领域适应（OSDA），目标领域可能包含源领域中不存在的类别样本[[144](#bib.bib144)]，即${{\cal
    C}_{s}}\subset{{\cal C}_{t}}$。OSDA的目标是正确分类已知类别的目标样本，并将未知类别的目标样本识别为额外类别。
- en: IV-B2 Open set back-propagation (OSBP)
  id: totrans-191
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B2 开放集反向传播（OSBP）
- en: Saito et al. [[144](#bib.bib144)] proposed an adversarial-based UDTL method,
    named OSBP, which aimed to make a pseudo decision boundary for unknown class.
    The model of OSBP is composed of a feature extractor $G_{f}$ and a $C+1$ classifier
    $G_{c}$, where $C$ denotes the number of source classes. The outputs of $G_{c}$
    are then input into Softmax to obtain class probabilities. The probability of
    $x$ being classified into class $c$ is defined as $p_{c}^{t}=\frac{\exp\left(G_{c}\left(G_{f}(x)\right)\right)}{\sum_{k=0}^{C}\exp\left(G_{k}\left(G_{f}(x)\right)\right)}$.
    1$\sim{C}$ and $C+1$ dimensions indicate the probability of known and unknown
    classes, respectively.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
  zh: Saito等人[[144](#bib.bib144)]提出了一种基于对抗的UDTL方法，称为OSBP，旨在为未知类别创建伪决策边界。OSBP模型由特征提取器$G_{f}$和一个$C+1$分类器$G_{c}$组成，其中$C$表示源类别的数量。$G_{c}$的输出然后输入到Softmax中以获得类别概率。$x$被分类为类别$c$的概率定义为$p_{c}^{t}=\frac{\exp\left(G_{c}\left(G_{f}(x)\right)\right)}{\sum_{k=0}^{C}\exp\left(G_{k}\left(G_{f}(x)\right)\right)}$。1$\sim{C}$和$C+1$维度分别表示已知和未知类别的概率。
- en: 'To correctly classify source samples, the feature extractor and classifier
    are trained using the prediction loss $\mathcal{L}_{c}$ in ([6](#S2.E6 "In II-A
    The Definition of UDTL ‣ II Background and Definition ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")). Moreover, the classifier is trained to recognize target samples as an
    unknown class via training the classifier to output $p_{C+1}^{t}=\tau$, where
    $\tau$ ranges from 0 to 1. While the feature extractor is trained to deceive the
    classifier via training the feature extractor to allow $p_{C+1}^{t}$ higher or
    lower than $\tau$. In this way, a good boundary between known and unknown target
    samples can be constructed. A binary cross-entropy loss is used for the adversarial
    training:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
  zh: 为了正确分类源样本，特征提取器和分类器通过使用预测损失$\mathcal{L}_{c}$进行训练（参见[6](#S2.E6 "在II-A UDTL的定义
    ‣ II 背景与定义 ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")）。此外，分类器被训练以将目标样本识别为未知类别，通过训练分类器使其输出$p_{C+1}^{t}=\tau$，其中$\tau$的范围是0到1。同时，特征提取器通过训练使得$p_{C+1}^{t}$高于或低于$\tau$，从而欺骗分类器。这样可以构建一个良好的已知和未知目标样本之间的边界。对抗训练使用了二元交叉熵损失：
- en: '|  | $\displaystyle{{\cal L}_{\text{OSBP}}}\left({{\theta_{f}},{\theta_{c}}}\right)=-\tau\log\left({p_{C+1}^{t}}\right)-\left({1-\tau}\right)\log\left({1-p_{C+1}^{t}}\right).$
    |  | (28) |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle{{\cal L}_{\text{OSBP}}}\left({{\theta_{f}},{\theta_{c}}}\right)=-\tau\log\left({p_{C+1}^{t}}\right)-\left({1-\tau}\right)\log\left({1-p_{C+1}^{t}}\right).$
    |  | (28) |'
- en: 'We design an UDTL-based model via introducing the $C+1$ classifier and adding
    the adversarial idea to the loss function to make a pseudo decision boundary for
    the unknown class as shown in Fig. [11](#S4.F11 "Figure 11 ‣ IV-B2 Open set back-propagation
    (OSBP) ‣ IV-B Open set UDTL ‣ IV Label-inconsistent UDTL ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"). The saddle point ($\hat{\theta}_{f},\hat{\theta}_{c}$) is solved using
    the following min-max optimization problem:'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
  zh: 我们设计了一种基于UDTL的模型，通过引入$C+1$分类器并将对抗思想添加到损失函数中，以便为未知类别创建伪决策边界，如图[11](#S4.F11 "图11
    ‣ IV-B2 开放集反向传播（OSBP） ‣ IV-B 开放集UDTL ‣ IV 标签不一致UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")所示。鞍点($\hat{\theta}_{f},\hat{\theta}_{c}$)通过以下的最小-最大优化问题来解决：
- en: '|  | $\displaystyle\left({\hat{{\theta_{f}}}}\right)$ | $\displaystyle=\arg\mathop{\max}\limits_{{\theta_{f}}}{{\cal
    L}_{\rm{c}}}\left({{\theta_{f}},{\hat{\theta}}_{c}}\right)-\lambda_{\text{OSBP}}{\cal
    L}_{\text{OSBP}}\left(\theta_{f},{\hat{\theta}}_{c}\right),$ |  | (29) |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left({\hat{{\theta_{f}}}}\right)$ | $\displaystyle=\arg\mathop{\max}\limits_{{\theta_{f}}}{{\cal
    L}_{\rm{c}}}\left({{\theta_{f}},{\hat{\theta}}_{c}}\right)-\lambda_{\text{OSBP}}{\cal
    L}_{\text{OSBP}}\left(\theta_{f},{\hat{\theta}}_{c}\right),$ |  | (29) |'
- en: '|  | $\displaystyle\left({\hat{{\theta_{c}}}}\right)$ | $\displaystyle=\arg\mathop{\min}\limits_{{\theta_{c}}}{{\cal
    L}_{c}}\left({\hat{{\theta_{f}}},{\theta_{c}}}\right)+{\lambda_{\text{OSBP}}}{{\cal
    L}_{\text{OSBP}}}\left({\hat{{\theta_{f}}},{\theta_{c}}}\right).$ |  |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left({\hat{{\theta_{c}}}}\right)$ | $\displaystyle=\arg\mathop{\min}\limits_{{\theta_{c}}}{{\cal
    L}_{c}}\left({\hat{{\theta_{f}}},{\theta_{c}}}\right)+{\lambda_{\text{OSBP}}}{{\cal
    L}_{\text{OSBP}}}\left({\hat{{\theta_{f}}},{\theta_{c}}}\right).$ |  |'
- en: '![Refer to caption](img/2cda4c3c3663dc54234bdfeb223c8858.png)'
  id: totrans-198
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/2cda4c3c3663dc54234bdfeb223c8858.png)'
- en: 'Figure 11: The UDTL-based model based on OSBP.'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
  zh: 图11：基于OSBP的UDTL模型。
- en: IV-B3 Applications to IFD
  id: totrans-200
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-B3 应用于IFD
- en: Li et al. [[145](#bib.bib145)] proposed a new fault classifier to detect the
    unknown class, and a convolutional auto-encoder model was further built to recognize
    the number of new fault types in [[146](#bib.bib146)]. Zhang et al. [[147](#bib.bib147)]
    proposed an instance-level weighted UDTL method to apply similarities of target
    samples during feature alignment. To identify target samples with outlier classes,
    an outlier classifier was trained using target instances with pseudo outlier labels.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
  zh: Li 等人 [[145](#bib.bib145)] 提出了一个新的故障分类器来检测未知类别，并进一步建立了一个卷积自编码器模型，以识别新故障类型的数量
    [[146](#bib.bib146)]。Zhang 等人 [[147](#bib.bib147)] 提出了一个实例级加权 UDTL 方法，在特征对齐过程中应用目标样本的相似性。为了识别具有异常类别的目标样本，使用具有伪异常标签的目标实例训练了一个异常分类器。
- en: IV-C Universal UDTL
  id: totrans-202
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 通用 UDTL
- en: IV-C1 Basic concepts
  id: totrans-203
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 基本概念
- en: You et al. [[148](#bib.bib148)] proposed universal domain adaptation (UDA) which
    imposed no prior knowledge on label sets. In UDA, for a given source label set
    and a target label set, they might contain a common label set and hold a private
    label set, respectively. UDA requires the model to either classify the target
    sample correctly if it is associated with a label in the common label set, or
    mark it as “unknown” otherwise. Let ${\cal C}_{s}$ denotes the source label set,
    ${\cal C}_{t}$ denotes the target label set, and ${\cal C}={\cal C}_{s}\cap{\cal
    C}_{t}$ denotes the common label set. $\overline{\cal C}_{s}={\cal C}_{s}\backslash\cal
    C$ and $\overline{\cal C}_{t}={\cal C}_{t}\backslash\cal C$ represent the source
    and target private label sets, respectively.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: You 等人 [[148](#bib.bib148)] 提出了通用领域适应（UDA），该方法不对标签集施加先验知识。在 UDA 中，给定源标签集和目标标签集，它们可能包含一个共同的标签集，并分别持有一个私有标签集。UDA
    要求模型要么对共同标签集中的标签正确分类目标样本，要么标记为“未知”。设 ${\cal C}_{s}$ 表示源标签集，${\cal C}_{t}$ 表示目标标签集，${\cal
    C}={\cal C}_{s}\cap{\cal C}_{t}$ 表示共同标签集。$\overline{\cal C}_{s}={\cal C}_{s}\backslash\cal
    C$ 和 $\overline{\cal C}_{t}={\cal C}_{t}\backslash\cal C$ 分别表示源和目标的私有标签集。
- en: IV-C2 Universal adaptation network (UAN)
  id: totrans-205
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 通用适应网络（UAN）
- en: You et al. [[148](#bib.bib148)] proposed UAN and designed an instance-level
    transferability criterion, exploiting the domain similarity and prediction uncertainty.
    The model of UAN is similar to that of DANN, while the difference is that UAN
    adds a non-adversarial domain discriminator $G_{d}^{\prime}$. The non-adversarial
    domain discriminator $G_{d}^{\prime}$ obtains the domain similarity $d^{\prime}=G_{d}^{\prime}(G_{f}(x))$.
    They assumed that ${\mathbb{E}_{x\sim{p_{{{\overline{\cal C}}_{s}}}}}}d^{\prime}>{\mathbb{E}_{x\sim{p_{{}_{\cal
    C}}}}}d^{\prime}>{\mathbb{E}_{x\sim{q_{{}_{\cal C}}}}}d^{\prime}>{\mathbb{E}_{x\sim{q_{{{\overline{\cal
    C}}_{t}}}}}}d^{\prime}$, where ${p_{{{\overline{\cal C}}_{s}}}}$ is the distribution
    of source data belonging to the label set ${\overline{C}_{s}}$ and ${q_{{{\overline{\cal
    C}}_{t}}}}$ is the distribution of target data belonging to label set ${\overline{C}_{t}}$.
    ${p_{\cal C}}$ and ${q_{\cal C}}$ are the distributions of source and target data
    belonging to ${\cal C}$, respectively. Considering that entropy can quantify the
    prediction uncertainty, they assumed that ${\mathbb{E}_{x\sim{q_{{{\overline{\cal
    C}}_{t}}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{q_{{}_{\cal C}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{p_{{}_{\cal
    C}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{p_{{{\overline{\cal C}}_{s}}}}}}H\left(p\right)$.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: You 等人 [[148](#bib.bib148)] 提出了 UAN 并设计了一个实例级的可转移性标准，利用领域相似性和预测不确定性。UAN 的模型类似于
    DANN，但不同之处在于 UAN 增加了一个非对抗性领域鉴别器 $G_{d}^{\prime}$。非对抗性领域鉴别器 $G_{d}^{\prime}$ 获得领域相似性
    $d^{\prime}=G_{d}^{\prime}(G_{f}(x))$。他们假设 ${\mathbb{E}_{x\sim{p_{{{\overline{\cal
    C}}_{s}}}}}}d^{\prime}>{\mathbb{E}_{x\sim{p_{{}_{\cal C}}}}}d^{\prime}>{\mathbb{E}_{x\sim{q_{{}_{\cal
    C}}}}}d^{\prime}>{\mathbb{E}_{x\sim{q_{{{\overline{\cal C}}_{t}}}}}}d^{\prime}$，其中
    ${p_{{{\overline{\cal C}}_{s}}}}$ 是属于标签集 ${\overline{C}_{s}}$ 的源数据分布，${q_{{{\overline{\cal
    C}}_{t}}}}$ 是属于标签集 ${\overline{C}_{t}}$ 的目标数据分布。${p_{\cal C}}$ 和 ${q_{\cal C}}$
    分别是属于 ${\cal C}$ 的源数据和目标数据分布。他们假设熵可以量化预测不确定性，因此 ${\mathbb{E}_{x\sim{q_{{{\overline{\cal
    C}}_{t}}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{q_{{}_{\cal C}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{p_{{}_{\cal
    C}}}}}H\left(p\right)>{\mathbb{E}_{x\sim{p_{{{\overline{\cal C}}_{s}}}}}}H\left(p\right)$。
- en: 'The instance-level transferability criterion for source and target samples
    can be defined as follows:'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: 源样本和目标样本的实例级可转移性标准可以定义如下：
- en: '|  | $\displaystyle\omega\left({x_{i}^{s}}\right)=\frac{{H\left({p\left({x_{i}^{s}}\right)}\right)}}{{\log\left&#124;{{{\cal
    C}_{s}}}\right&#124;}}-d^{\prime}\left({x_{i}^{s}}\right),$ |  | (30) |'
  id: totrans-208
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\omega\left({x_{i}^{s}}\right)=\frac{{H\left({p\left({x_{i}^{s}}\right)}\right)}}{{\log\left&#124;{{{\cal
    C}_{s}}}\right&#124;}}-d^{\prime}\left({x_{i}^{s}}\right),$ |  | (30) |'
- en: '|  | $\displaystyle\omega\left({x_{i}^{t}}\right)=d^{\prime}\left({x_{i}^{t}}\right)-\frac{{H\left({p\left({x_{i}^{t}}\right)}\right)}}{{\log\left&#124;{{{\cal
    C}_{s}}}\right&#124;}},$ |  | (31) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\omega\left({x_{i}^{t}}\right)=d^{\prime}\left({x_{i}^{t}}\right)-\frac{{H\left({p\left({x_{i}^{t}}\right)}\right)}}{{\log\left&#124;{{{\cal
    C}_{s}}}\right&#124;}},$ |  | (31) |'
- en: where $\omega\left({x_{i}^{s}}\right)$ and $\omega\left({x_{i}^{t}}\right)$
    indicate the probability of a source sample $x_{i}^{s}$ and a target sample $x_{i}^{t}$
    belonging to the common label set ${\cal C}$.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\omega\left({x_{i}^{s}}\right)$ 和 $\omega\left({x_{i}^{t}}\right)$ 表示源样本
    $x_{i}^{s}$ 和目标样本 $x_{i}^{t}$ 属于共同标签集 ${\cal C}$ 的概率。
- en: '![Refer to caption](img/b2f0ba488c966261227b80e89c12ba1d.png)'
  id: totrans-211
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/b2f0ba488c966261227b80e89c12ba1d.png)'
- en: 'Figure 12: The UDTL-based model based on UAN.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12：基于 UAN 的 UDTL 模型。
- en: 'The loss of domain discriminator $G_{d}$ in ([16](#S3.E16 "In III-D1 Basic
    concepts ‣ III-D Adversarial-based UDTL ‣ III Label-consistent UDTL ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")) is modified to:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 领域鉴别器 $G_{d}$ 的损失在 ([16](#S3.E16 "在 III-D1 基本概念 ‣ III-D 基于对抗的 UDTL ‣ III 标签一致的
    UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")) 中被修改为：
- en: '|  | $\displaystyle\mathcal{L}_{\text{UAN}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\omega\left({x_{i}^{s}}\right)\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (32) |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{\text{UAN}}\left(\theta_{f},\theta_{d}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\omega\left({x_{i}^{s}}\right)\log\left[G_{d}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d}\right)\right]-$
    |  | (32) |'
- en: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\omega\left({x_{i}^{t}}\right)\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right].$
    |  |'
  id: totrans-215
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\omega\left({x_{i}^{t}}\right)\log\left[1-G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right].$
    |  |'
- en: 'The loss of non-adversarial domain discriminator $G_{d^{\prime}}$ is:'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: 非对抗性领域鉴别器 $G_{d^{\prime}}$ 的损失为：
- en: '|  | $\displaystyle\mathcal{L}_{d^{\prime}}\left(\theta_{f},\theta_{d^{\prime}}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d^{\prime}}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d^{\prime}}\right)\right]-$
    |  | (33) |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}_{d^{\prime}}\left(\theta_{f},\theta_{d^{\prime}}\right)=$
    | $\displaystyle-\mathbb{E}_{x_{i}^{s}\in\mathcal{D}_{s}}\log\left[G_{d^{\prime}}\left(G_{f}\left(x_{i}^{s};\theta_{f}\right);\theta_{d^{\prime}}\right)\right]-$
    |  | (33) |'
- en: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d^{\prime}}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d^{\prime}}\right)\right].$
    |  |'
  id: totrans-218
  prefs: []
  type: TYPE_TB
  zh: '|  |  | $\displaystyle\mathbb{E}_{x_{i}^{t}\in\mathcal{D}_{t}}\log\left[1-G_{d^{\prime}}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d^{\prime}}\right)\right].$
    |  |'
- en: 'where $\theta_{d^{\prime}}$ is the parameters of non-adversarial domain discriminator
    $G_{d^{\prime}}$. The saddle point ($\hat{\theta}_{f},\hat{\theta}_{c},\hat{\theta}_{d},\hat{\theta}_{d^{\prime}}$)
    can be solved using the following min-max optimization problem:'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\theta_{d^{\prime}}$ 是非对抗性领域鉴别器 $G_{d^{\prime}}$ 的参数。鞍点 ($\hat{\theta}_{f},\hat{\theta}_{c},\hat{\theta}_{d},\hat{\theta}_{d^{\prime}}$)
    可以通过以下的最优化问题来解决：
- en: '|  | $\displaystyle\left(\hat{\theta_{f}},\hat{\theta_{c}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{f},\theta_{c}}{\cal
    L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{UAN}}{\cal L}_{\text{UAN}}\left(\theta_{f},{\hat{\theta}}_{d}\right),$
    |  | (34) |'
  id: totrans-220
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left(\hat{\theta_{f}},\hat{\theta_{c}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{f},\theta_{c}}{\cal
    L}_{c}\left(\theta_{f},\theta_{c}\right)-\lambda_{\text{UAN}}{\cal L}_{\text{UAN}}\left(\theta_{f},{\hat{\theta}}_{d}\right),$
    |  | (34) |'
- en: '|  | $\displaystyle\left(\hat{\theta_{d}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{d}}{\cal
    L}_{\text{UAN}}\left({\hat{\theta}}_{f},{\hat{\theta}}_{c},{\theta_{d}}\right),$
    |  |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left(\hat{\theta_{d}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{d}}{\cal
    L}_{\text{UAN}}\left({\hat{\theta}}_{f},{\hat{\theta}}_{c},{\theta_{d}}\right),$
    |  |'
- en: '|  | $\displaystyle\left(\hat{\theta_{d^{\prime}}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{d^{\prime}}}{\cal
    L}_{d^{\prime}}\left({\hat{\theta}}_{f},\theta_{d^{\prime}}\right).$ |  |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\left(\hat{\theta_{d^{\prime}}}\right)$ | $\displaystyle=\arg\min\limits_{\theta_{d^{\prime}}}{\cal
    L}_{d^{\prime}}\left({\hat{\theta}}_{f},\theta_{d^{\prime}}\right).$ |  |'
- en: Via training UAN, distributions of source and target data in the shared label
    set can be maximally aligned and the category gap can be reduced. In the test
    phase, for a target sample $x_{i}^{t}$, if its $\omega(x_{i}^{t})$ is higher than
    the threshold $\omega_{0}$, it is regarded as the unknown class, otherwise it
    is predicted by its label prediction.
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: 通过训练UAN，可以最大限度地对齐共享标签集中的源数据和目标数据的分布，从而减少类别差距。在测试阶段，对于目标样本$x_{i}^{t}$，如果其$\omega(x_{i}^{t})$高于阈值$\omega_{0}$，则被视为未知类别，否则根据其标签预测结果进行预测。
- en: IV-C3 Applications to IFD
  id: totrans-224
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C3 应用于IFD
- en: Zhang et al. [[149](#bib.bib149)] proposed a selective UDTL method. Class-wise
    weights were applied to the source domain and instance-wise weights were applied
    to the target domain. An outlier identifier was trained to recognize unknown fault
    modes. Yu et al. [[150](#bib.bib150)] proposed a bilateral weighted adversarial
    network to align feature distributions of shared-class source and target samples,
    and to disentangle shared-class and outlier-class samples. After model training,
    the extreme value theory (EVT) model was established on the feature representation
    of source samples and was further used to detect unknown-class samples in the
    target domain.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: 张等人[[149](#bib.bib149)]提出了一种选择性UDTL方法。源领域应用了类别权重，目标领域应用了实例权重。训练了一个异常值识别器以识别未知故障模式。于等人[[150](#bib.bib150)]提出了一种双边加权对抗网络，以对齐共享类别源样本和目标样本的特征分布，并区分共享类别和异常类别样本。在模型训练后，基于源样本的特征表示建立了极值理论（EVT）模型，并进一步用于检测目标领域中的未知类别样本。
- en: V Multi-domain UDTL
  id: totrans-226
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: V 多领域 UDTL
- en: Considering that a single source domain might not be enough for UDTL in real
    applications, it is also important to consider multi-domain UDTL, which can help
    learn domain-invariant features. In this paper, two kinds of multi-domain UDTL
    settings, including multi-domain adaptation (using the target data in the training
    phase) and domain generalization (not using the target data in the training phase),
    are studied. Because there are multiple source domains in multi-domain UDTL, we
    first need to redefine some basic symbols. Let $\left\{\mathcal{D}_{s,n}\right\}_{0}^{n_{sd}-1}$
    denote the source domains, where $n_{sd}$ denotes the number of source domains.
    $\mathcal{D}_{t}$ denotes the target domain. $\mathcal{D}_{s,n}$ means the $n$-th
    source domain. $x_{i,n}^{s}$ and $y_{i,n}^{s}$ are the $i$-th sample and its corresponding
    label. Besides, $d_{i,n}^{s}$ is the domain label of $x_{i,n}^{s}$ and $d_{i}^{t}$
    ($d_{i}^{t}={n}_{sd}$) is the domain label of $x_{i}^{t}$.
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到单一源领域可能不足以支持实际应用中的UDTL，因此多领域UDTL也很重要，它可以帮助学习领域不变特征。本文研究了两种多领域UDTL设置，包括多领域适应（在训练阶段使用目标数据）和领域泛化（在训练阶段不使用目标数据）。由于多领域UDTL涉及多个源领域，我们首先需要重新定义一些基本符号。设$\left\{\mathcal{D}_{s,n}\right\}_{0}^{n_{sd}-1}$表示源领域，其中$n_{sd}$表示源领域的数量。$\mathcal{D}_{t}$表示目标领域。$\mathcal{D}_{s,n}$表示第$n$个源领域。$x_{i,n}^{s}$和$y_{i,n}^{s}$分别是第$i$个样本及其对应标签。此外，$d_{i,n}^{s}$是$x_{i,n}^{s}$的领域标签，$d_{i}^{t}$（$d_{i}^{t}={n}_{sd}$）是$x_{i}^{t}$的领域标签。
- en: V-A Multi-domain adaptation
  id: totrans-228
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-A 多领域适应
- en: V-A1 Basic concepts
  id: totrans-229
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A1 基本概念
- en: The traditional UDTL based on one single source domain cannot make full use
    of the data from multi-source domains, which might fail to find the private relationship
    and domain-invariant features. Thus, multi-domain adaptation aims to utilize labeled
    multi-source domains and unlabeled target domains to dig the relationship and
    domain-invariant features.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
  zh: 基于单一源领域的传统UDTL不能充分利用多源领域的数据，这可能导致无法找到私有关系和领域不变特征。因此，多领域适应旨在利用标记的多源领域和未标记的目标领域来挖掘关系和领域不变特征。
- en: V-A2 Multi-source unsupervised adversarial domain adaptation (MS-UADA)
  id: totrans-231
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A2 多源无监督对抗性领域适应（MS-UADA）
- en: 'There are mainly two ways to realize multi-domain adaptation. One is that features
    should be domain-invariant [[151](#bib.bib151)], that is, the gap between different
    domains, including source and target domains in the feature space should be as
    small as possible. The other way is to find a source domain, which is the most
    similar to the target domain [[152](#bib.bib152), [153](#bib.bib153)]. The second
    way requires a distance to measure the similarity among domains. In this paper,
    we used the method proposed in [[151](#bib.bib151)] called multi-source unsupervised
    adversarial adaptation (MS-UADA) to realize multi-domain adaptation, and the structure
    is shown in Fig. [13](#S5.F13 "Figure 13 ‣ V-A2 Multi-source unsupervised adversarial
    domain adaptation (MS-UADA) ‣ V-A Multi-domain adaptation ‣ V Multi-domain UDTL
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study"). The loss of MS-UADA for the domain discriminator
    $G_{d}$ is defined as follows:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: 实现多领域适应主要有两种方式。一种是特征应该具有领域不变性 [[151](#bib.bib151)]，即不同领域之间，包括源领域和目标领域在特征空间中的差距应尽可能小。另一种方法是找到一个与目标领域最相似的源领域
    [[152](#bib.bib152), [153](#bib.bib153)]。第二种方法需要一个距离度量领域之间的相似性。本文采用了[[151](#bib.bib151)]中提出的方法，即多源无监督对抗适应（MS-UADA），来实现多领域适应，结构如图
    [13](#S5.F13 "图 13 ‣ V-A2 多源无监督对抗领域适应 (MS-UADA) ‣ V-A 多领域适应 ‣ V 多领域 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")所示。MS-UADA
    对领域判别器 $G_{d}$ 的损失定义如下：
- en: '|  | $\displaystyle\begin{split}&amp;\mathcal{L}{{}_{\text{MS-UADA}}}=-{{\mathbb{E}}_{x_{i}^{t}\in{\mathcal{D}_{t}}}}\mathbf{1}_{[d_{i}^{t}=n_{sd}]}\log\left[G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right]\\
    &amp;-\sum\limits_{n=0}^{{{n}_{sd}}-1}{{\mathbb{E}}_{x_{i,n}^{s}\in{\mathcal{D}_{s,n}}}}\sum\limits_{d=0}^{{{n}_{sd}}-1}{{\mathbf{1}_{[d_{i,n}^{s}=d]}}\log\left[G_{d}\left(G_{f}\left(x_{i,n}^{s};\theta_{f}\right);\theta_{d}\right)\right]}.\end{split}$
    |  | (35) |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\begin{split}&\mathcal{L}{{}_{\text{MS-UADA}}}=-{{\mathbb{E}}_{x_{i}^{t}\in{\mathcal{D}_{t}}}}\mathbf{1}_{[d_{i}^{t}=n_{sd}]}\log\left[G_{d}\left(G_{f}\left(x_{i}^{t};\theta_{f}\right);\theta_{d}\right)\right]\\
    &-\sum\limits_{n=0}^{{{n}_{sd}}-1}{{\mathbb{E}}_{x_{i,n}^{s}\in{\mathcal{D}_{s,n}}}}\sum\limits_{d=0}^{{{n}_{sd}}-1}{{\mathbf{1}_{[d_{i,n}^{s}=d]}}\log\left[G_{d}\left(G_{f}\left(x_{i,n}^{s};\theta_{f}\right);\theta_{d}\right)\right]}.\end{split}$
    |  | (35) |'
- en: 'To reduce the gap, the features from ${{G}_{f}}$ should confuse ${{G}_{d}}$,
    which means ${{G}_{d}}$ cannot realize domain classification. Thus the training
    processing can be seen as a minimax game, and the total loss is:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
  zh: 为了减少差距，来自 ${{G}_{f}}$ 的特征应使 ${{G}_{d}}$ 感到困惑，这意味着 ${{G}_{d}}$ 无法实现领域分类。因此，训练过程可以看作是一个最小最大游戏，总损失为：
- en: '|  | $\displaystyle\mathcal{L}\left({{\theta}_{f}},{{\theta}_{c}},{{\theta}_{d}}\right)=\mathcal{L}_{c}-{{\lambda}_{\text{MS-UADA}}}\mathcal{L}{{}_{\text{MS-UADA}}},$
    |  | (36) |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}\left({{\theta}_{f}},{{\theta}_{c}},{{\theta}_{d}}\right)=\mathcal{L}_{c}-{{\lambda}_{\text{MS-UADA}}}\mathcal{L}{{}_{\text{MS-UADA}}},$
    |  | (36) |'
- en: where ${{\lambda}_{\text{MS-UADA}}}$ is the trade-off parameter. The way to
    optimize $\mathcal{L}\left({{\theta}_{f}},{{\theta}_{c}},{{\theta}_{d}}\right)$
    is consistent with the DANN.
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 ${{\lambda}_{\text{MS-UADA}}}$ 是权衡参数。优化 $\mathcal{L}\left({{\theta}_{f}},{{\theta}_{c}},{{\theta}_{d}}\right)$
    的方式与 DANN 一致。
- en: '![Refer to caption](img/333d27ac97724626a0e0995cb7b745a2.png)'
  id: totrans-237
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/333d27ac97724626a0e0995cb7b745a2.png)'
- en: 'Figure 13: The UDTL-based model based on MS-UADA.'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
  zh: '图 13: 基于 MS-UADA 的 UDTL 模型。'
- en: V-A3 Applications to IFD
  id: totrans-239
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-A3 应用于 IFD
- en: Zhu et al. [[154](#bib.bib154)] proposed an adversarial learning strategy in
    multi-domain adaptation to capture the fault feature representation. Rezaeianjouybari
    et al. [[155](#bib.bib155)] proposed a novel multi-source adaptation framework,
    which could realize the alignment in both feature and task levels. Zhang et al.
    [[156](#bib.bib156)] proposed an adversarial multi-domain adaptation according
    to a classifier alignment method to capture domain-invariant features from multiple
    source domains. He et al. [[157](#bib.bib157)] proposed a method based on K-means
    and space transformation in multi-source domains. Wei et al. [[158](#bib.bib158)]
    proposed a multi-source adaptation framework to learn domain-invariant features
    on the basis of distributional similarities. Zhang et al. [[74](#bib.bib74)] proposed
    an enhanced transfer joint matching approach based on MVD and MMD for multi-domain
    adaptation. Li et al. [[159](#bib.bib159)] proposed a multi-domain adaptation
    method to learn the diagnostic knowledge via domain adversarial training. Huang
    et al. [[160](#bib.bib160)] proposed a multi-source dense adaptation adversarial
    network to realize fault diagnosis from various working conditions.
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: Zhu 等人[[154](#bib.bib154)] 提出了在多领域适应中捕捉故障特征表示的对抗学习策略。Rezaeianjouybari 等人[[155](#bib.bib155)]
    提出了一个新颖的多源适应框架，该框架能够实现特征和任务级别的对齐。Zhang 等人[[156](#bib.bib156)] 提出了一个基于分类器对齐方法的对抗多领域适应，以从多个源领域中捕捉领域不变特征。He
    等人[[157](#bib.bib157)] 提出了一个基于 K-means 和空间变换的多源领域方法。Wei 等人[[158](#bib.bib158)]
    提出了一个多源适应框架，以基于分布相似性学习领域不变特征。Zhang 等人[[74](#bib.bib74)] 提出了一个基于 MVD 和 MMD 的增强传输联合匹配方法用于多领域适应。Li
    等人[[159](#bib.bib159)] 提出了一个通过领域对抗训练学习诊断知识的多领域适应方法。Huang 等人[[160](#bib.bib160)]
    提出了一个多源密集适应对抗网络，以实现来自各种工作条件的故障诊断。
- en: V-B Domain generalization (DG)
  id: totrans-241
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: V-B 域泛化（DG）
- en: V-B1 Basic concepts
  id: totrans-242
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B1 基本概念
- en: 'Domain generalization (DG) is to learn shared knowledge from multiple source
    domains and generalize knowledge to the target domain which is unseen in the training
    phase. The biggest difference of DG is that unlabeled samples in the target domain
    only appear in the test phase. Based on the discussion in [[161](#bib.bib161)],
    the core idea of DG is that learned domain-invariant features should satisfy the
    following two properties: 1) Features extracted by ${{G}_{f}}$ should be discriminative.
    2) Features extracted from different source domains should be domain-invariant.
    More detailed information can be referred to [[161](#bib.bib161)].'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: 域泛化（DG）旨在从多个源领域学习共享知识，并将知识推广到训练阶段未见过的目标领域。DG 的最大区别在于目标领域中的未标记样本只出现在测试阶段。根据[[161](#bib.bib161)]中的讨论，DG
    的核心思想是学习到的领域不变特征应满足以下两个性质：1）由 ${{G}_{f}}$ 提取的特征应具有区分性。2）从不同源领域提取的特征应具有领域不变性。更详细的信息请参见[[161](#bib.bib161)]。
- en: V-B2 Invariant adversarial network (IAN)
  id: totrans-244
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B2 不变对抗网络（IAN）
- en: 'According to the above description, the performance of DG depends on discriminative
    and domain-invariant features. Domain-invariant features require diagnosis models
    to reduce the feature gap among different domains. As described in the previous
    section, adversarial training can reduce the gap of features among different domains.
    In this paper, a simple adversarial training method called invariant adversarial
    network (IAN) [[162](#bib.bib162), [163](#bib.bib163)] based on DANN is used in
    DG to help ${{G}_{f}}$ extract domain-invariant features via aligning the marginal
    distribution. The structure of IAN is shown in Fig. [13](#S5.F13 "Figure 13 ‣
    V-A2 Multi-source unsupervised adversarial domain adaptation (MS-UADA) ‣ V-A Multi-domain
    adaptation ‣ V Multi-domain UDTL ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study") and
    the loss of IAN for the domain discriminator $G_{d}$ is defined as follows:'
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
  zh: '根据上述描述，DG 的性能依赖于区分性和领域不变特征。领域不变特征要求诊断模型减少不同领域之间的特征差距。如前一节所述，对抗训练可以减少不同领域之间的特征差距。在本文中，使用了一种简单的对抗训练方法称为不变对抗网络（IAN）[[162](#bib.bib162),
    [163](#bib.bib163)]，它基于 DANN，用于 DG 以帮助 ${{G}_{f}}$ 通过对齐边际分布来提取领域不变特征。IAN 的结构如图
    [13](#S5.F13 "Figure 13 ‣ V-A2 Multi-source unsupervised adversarial domain adaptation
    (MS-UADA) ‣ V-A Multi-domain adaptation ‣ V Multi-domain UDTL ‣ Applications of
    Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and
    Comparative Study") 所示，IAN 对领域判别器 $G_{d}$ 的损失定义如下：'
- en: '|  | $\displaystyle\begin{split}\mathcal{L}_{\text{IAN}}=&amp;-\sum\limits_{n=0}^{{{n}_{sd}}-1}{{\mathbb{E}}_{x_{i,n}^{s}\in{\mathcal{D}_{s,n}}}}\sum\limits_{d=0}^{{{n}_{sd}}-1}\\
    &amp;{{\mathbf{1}_{[d_{i,n}^{s}=d]}}\log\left[G_{d}\left(G_{f}\left(x_{i,n}^{s};\theta_{f}\right);\theta_{d}\right)\right]}.\end{split}$
    |  | (37) |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\begin{split}\mathcal{L}_{\text{IAN}}=&amp;-\sum\limits_{n=0}^{{{n}_{sd}}-1}{{\mathbb{E}}_{x_{i,n}^{s}\in{\mathcal{D}_{s,n}}}}\sum\limits_{d=0}^{{{n}_{sd}}-1}\\
    &amp;{{\mathbf{1}_{[d_{i,n}^{s}=d]}}\log\left[G_{d}\left(G_{f}\left(x_{i,n}^{s};\theta_{f}\right);\theta_{d}\right)\right]}.\end{split}$
    |  | (37) |'
- en: '${{G}_{f}}$ should confuse ${{G}_{d}}$. Thus the total loss of IAN is a minimax
    game:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: ${{G}_{f}}$ 应该使 ${{G}_{d}}$ 混淆。因此，IAN的总损失是一个最小最大游戏：
- en: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}-\lambda_{\text{IAN}}\mathcal{L}_{\text{IAN}},$
    |  | (38) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
  zh: '|  | $\displaystyle\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)=\mathcal{L}_{c}-\lambda_{\text{IAN}}\mathcal{L}_{\text{IAN}},$
    |  | (38) |'
- en: where $\lambda_{\text{IAN}}$ is the trade-off parameter. The way to optimize
    $\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)$ is consistent with
    DANN.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 其中 $\lambda_{\text{IAN}}$ 是权衡参数。优化 $\mathcal{L}\left(\theta_{f},\theta_{c},\theta_{d}\right)$
    的方法与DANN一致。
- en: '![Refer to caption](img/758ea46e18ccdab471180d4f62a5e6b9.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/758ea46e18ccdab471180d4f62a5e6b9.png)'
- en: 'Figure 14: The UDTL-based model based on IAN.'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 图14：基于IAN的UDTL模型。
- en: V-B3 Applications to IFD
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: V-B3 应用于IFD
- en: Zheng et al. [[164](#bib.bib164)] proposed a DG network based on a priori diagnosis
    knowledge and preprocessing techniques for IFD. Liao et al. [[165](#bib.bib165)]
    proposed a deep semi-supervised DG network to use unlabeled and labeled source
    data by the Earth-mover distance. Li et al. [[162](#bib.bib162)] proposed a DG
    method in IFD by a combination of data augmentation, adversarial training, and
    distance-based metric. Yang et al. [[166](#bib.bib166)] used a center loss to
    learn domain-invariant features across various source domains to realize DG. Zhang
    et al. [[167](#bib.bib167)] proposed a conditional adversarial DG method based
    on a single discriminator for better transfer and low computational complexity.
    Han et al. [[168](#bib.bib168)] proposed a DG based hybrid diagnosis network for
    deploying to unseen working conditions via the triplet loss and adversarial training.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 郑等人[[164](#bib.bib164)] 提出了基于先验诊断知识和IFD预处理技术的DG网络。廖等人[[165](#bib.bib165)] 提出了一个深度半监督DG网络，通过地球搬运工距离来使用未标记和标记的源数据。李等人[[162](#bib.bib162)]
    提出了一种通过数据增强、对抗训练和基于距离的度量相结合的IFD DG方法。杨等人[[166](#bib.bib166)] 使用中心损失来学习各种源领域中的领域不变特征，以实现DG。张等人[[167](#bib.bib167)]
    提出了基于单一判别器的条件对抗DG方法，以实现更好的迁移和较低的计算复杂性。韩等人[[168](#bib.bib168)] 提出了基于三元组损失和对抗训练的DG混合诊断网络，以部署到未知工作条件。
- en: VI Datasets
  id: totrans-254
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VI 数据集
- en: VI-A Open source Datasets
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-A 开源数据集
- en: 'Open source datasets are very important for development, comparisons, and evaluation
    of different algorithms. In this comparative study, we mainly test five datasets
    to verify the performance of different UDTL methods. The detailed description
    of five datasets is given as follows:'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 开源数据集对于不同算法的开发、比较和评估非常重要。在这项比较研究中，我们主要测试了五个数据集，以验证不同UDTL方法的性能。以下是五个数据集的详细描述：
- en: VI-A1 Case Western Reserve University (CWRU) dataset
  id: totrans-257
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A1 凯斯西储大学（CWRU）数据集
- en: 'The CWRU dataset provided by Case Western Reserve University Bearing Data Center
    [[169](#bib.bib169)] is one of the most famous open source datasets in IFD and
    has been already used by tremendous published papers. Following other papers,
    this paper also uses the drive end bearing fault data whose sampling frequency
    is equal to 12 kHz and ten bearing conditions are listed in Table [II](#S6.T2
    "TABLE II ‣ VI-A1 Case Western Reserve University (CWRU) dataset ‣ VI-A Open source
    Datasets ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning to
    Intelligent Fault Diagnosis: A Survey and Comparative Study"). In Table [II](#S6.T2
    "TABLE II ‣ VI-A1 Case Western Reserve University (CWRU) dataset ‣ VI-A Open source
    Datasets ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning to
    Intelligent Fault Diagnosis: A Survey and Comparative Study"), one normal bearing
    (NA) and three fault types including inner fault (IF), ball fault (BF) and outer
    fault (OF) are classified into ten categories (one health state and nine fault
    states) according to different fault sizes.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: '由凯斯西储大学轴承数据中心提供的CWRU数据集[[169](#bib.bib169)]是故障诊断领域最著名的开源数据集之一，已经被大量发表的论文使用。遵循其他论文，本文也使用驱动端轴承故障数据，采样频率为12
    kHz，十种轴承状态列在表[II](#S6.T2 "TABLE II ‣ VI-A1 Case Western Reserve University (CWRU)
    dataset ‣ VI-A Open source Datasets ‣ VI Datasets ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")中。在表[II](#S6.T2 "TABLE II ‣ VI-A1 Case Western Reserve University (CWRU)
    dataset ‣ VI-A Open source Datasets ‣ VI Datasets ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")中，根据不同的故障大小，一个正常轴承（NA）和三种故障类型，包括内故障（IF）、球故障（BF）和外故障（OF）被分类为十类（一个健康状态和九个故障状态）。'
- en: 'Besides, as shown in Table [III](#S6.T3 "TABLE III ‣ VI-A1 Case Western Reserve
    University (CWRU) dataset ‣ VI-A Open source Datasets ‣ VI Datasets ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"), CWRU consists of four motor loads corresponding to four
    operating speeds. For the transfer learning task, this paper considers these working
    conditions as different tasks including 0, 1, 2, and 3. For example, task 0 $\longrightarrow$
    1 means that the source domain with a motor load 0 HP transfers to the target
    domain with a motor load 1 HP. In total, there are twelve transfer learning tasks.'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: '此外，如表[III](#S6.T3 "TABLE III ‣ VI-A1 Case Western Reserve University (CWRU)
    dataset ‣ VI-A Open source Datasets ‣ VI Datasets ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")所示，CWRU数据集包括四种电机负载，分别对应四种操作速度。对于迁移学习任务，本文将这些工作条件视为不同的任务，包括0、1、2和3。例如，任务0
    $\longrightarrow$ 1表示源领域中电机负载为0 HP转移到目标领域中电机负载为1 HP。总共有十二个迁移学习任务。'
- en: 'TABLE II: The description of class labels of CWRU.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: 表II：CWRU类别标签描述。
- en: '| Class Label | 0 | 1 | 2 | 3 | 4 |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
  zh: '| 类别标签 | 0 | 1 | 2 | 3 | 4 |'
- en: '| Fault Location | NA | IF | BF | OF | IF |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
  zh: '| 故障位置 | NA | IF | BF | OF | IF |'
- en: '| Fault Size (mils) | 0 | 7 | 7 | 7 | 14 |'
  id: totrans-263
  prefs: []
  type: TYPE_TB
  zh: '| 故障大小（mil） | 0 | 7 | 7 | 7 | 14 |'
- en: '| Class Label | 5 | 6 | 7 | 8 | 9 |'
  id: totrans-264
  prefs: []
  type: TYPE_TB
  zh: '| 类别标签 | 5 | 6 | 7 | 8 | 9 |'
- en: '| Fault Location | BF | OF | IF | BF | OF |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
  zh: '| 故障位置 | BF | OF | IF | BF | OF |'
- en: '| Fault Size (mils) | 14 | 14 | 21 | 21 | 21 |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
  zh: '| 故障大小（mil） | 14 | 14 | 21 | 21 | 21 |'
- en: 'TABLE III: The transfer learning tasks of CWRU.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 表III：CWRU的迁移学习任务。
- en: '| Task | 0 | 1 | 2 | 3 |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 0 | 1 | 2 | 3 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-269
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Load (HP) | 0 | 1 | 2 | 3 |'
  id: totrans-270
  prefs: []
  type: TYPE_TB
  zh: '| 负载（HP） | 0 | 1 | 2 | 3 |'
- en: '| Speed (rpm) | 1797 | 1772 | 1750 | 1730 |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
  zh: '| 速度（rpm） | 1797 | 1772 | 1750 | 1730 |'
- en: VI-A2 Paderborn University (PU) dataset
  id: totrans-272
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A2 帕德博恩大学（PU）数据集
- en: 'The PU dataset acquired from Paderborn University is a bearing dataset [[170](#bib.bib170),
    [171](#bib.bib171)] which consists of artificially induced and real damages. The
    sampling frequency is equal to 64 kHz. Via changing the rotating speed of the
    drive system, the radial force onto the test bearing and the load torque on the
    drive train, the PU dataset consists of four operating conditions as shown in
    Table [IV](#S6.T4 "TABLE IV ‣ VI-A2 Paderborn University (PU) dataset ‣ VI-A Open
    source Datasets ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study").'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
  zh: '从帕德博恩大学获得的PU数据集是一个轴承数据集[[170](#bib.bib170), [171](#bib.bib171)]，其中包含人工引发的和真实的损伤。采样频率为64
    kHz。通过改变驱动系统的旋转速度、施加在测试轴承上的径向力和驱动系统上的负载扭矩，PU数据集包含四种操作条件，如表[IV](#S6.T4 "TABLE IV
    ‣ VI-A2 Paderborn University (PU) dataset ‣ VI-A Open source Datasets ‣ VI Datasets
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study")所示。'
- en: 'Thirteen bearings with real damages caused by accelerated lifetime tests [[170](#bib.bib170)]
    are used to study transfer learning tasks among different working conditions (twenty
    experiments were performed on each bearing code, and each experiment sustained
    four seconds). The categorization information is presented in Table [V](#S6.T5
    "TABLE V ‣ VI-A2 Paderborn University (PU) dataset ‣ VI-A Open source Datasets
    ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent
    Fault Diagnosis: A Survey and Comparative Study") (the meaning of contents is
    explained in [[170](#bib.bib170)]). In total, there are twelve transfer learning
    settings.'
  id: totrans-274
  prefs: []
  type: TYPE_NORMAL
  zh: '使用由加速寿命测试引起的真实损伤的十三个轴承[[170](#bib.bib170)]，研究不同工作条件下的传递学习任务（每个轴承代码进行二十次实验，每次实验持续四秒）。分类信息在表[V](#S6.T5
    "TABLE V ‣ VI-A2 Paderborn University (PU) dataset ‣ VI-A Open source Datasets
    ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent
    Fault Diagnosis: A Survey and Comparative Study")中呈现（内容的含义在[[170](#bib.bib170)]中解释）。总共有十二个传递学习设置。'
- en: 'TABLE IV: The transfer learning tasks and operating parameters of PU.'
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 表IV：PU的传递学习任务和操作参数。
- en: '| Task | 0 | 1 | 2 | 3 |'
  id: totrans-276
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 0 | 1 | 2 | 3 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-277
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Load Torque (Nm) | 0.7 | 0.7 | 0.1 | 0.7 |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
  zh: '| 载荷扭矩（Nm） | 0.7 | 0.7 | 0.1 | 0.7 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-279
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| Radial Force (N) | 1000 | 1000 | 1000 | 400 |'
  id: totrans-280
  prefs: []
  type: TYPE_TB
  zh: '| 径向力（N） | 1000 | 1000 | 1000 | 400 |'
- en: '| Speed (rpm) | 1500 | 900 | 1500 | 1500 |'
  id: totrans-281
  prefs: []
  type: TYPE_TB
  zh: '| 转速（rpm） | 1500 | 900 | 1500 | 1500 |'
- en: 'TABLE V: The information of bearings with real damages.'
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 表V：带有真实损伤的轴承信息。
- en: '|'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Bearing &#124;'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 轴承 &#124;'
- en: '&#124; Code &#124;'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 代号 &#124;'
- en: '| Damage | Bearing Element | Combination | Characteristic of Damage | Label
    |'
  id: totrans-286
  prefs: []
  type: TYPE_TB
  zh: '| 损伤 | 轴承元件 | 结合 | 损伤特征 | 标签 |'
- en: '| KA04 | fatigue: pitting | OR | S | single point | 0 |'
  id: totrans-287
  prefs: []
  type: TYPE_TB
  zh: '| KA04 | 疲劳：齿痕 | OR | S | 单点 | 0 |'
- en: '| KA15 | plastic deform: indentations | OR | S | single point | 1 |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
  zh: '| KA15 | 塑性变形：凹痕 | OR | S | 单点 | 1 |'
- en: '| KA16 | fatigue: pitting | OR | R | single point | 2 |'
  id: totrans-289
  prefs: []
  type: TYPE_TB
  zh: '| KA16 | 疲劳：齿痕 | OR | R | 单点 | 2 |'
- en: '| KA22 | fatigue: pitting | OR | S | single point | 3 |'
  id: totrans-290
  prefs: []
  type: TYPE_TB
  zh: '| KA22 | 疲劳：齿痕 | OR | S | 单点 | 3 |'
- en: '| KA30 | plastic deform: indentations | OR | R | distributed | 4 |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
  zh: '| KA30 | 塑性变形：凹痕 | OR | R | 分布式 | 4 |'
- en: '| KB23 | fatigue: pitting | IR(+OR) | M | single point | 5 |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
  zh: '| KB23 | 疲劳：齿痕 | IR（+OR） | M | 单点 | 5 |'
- en: '| KB24 | fatigue: pitting | IR(+OR) | M | distributed | 6 |'
  id: totrans-293
  prefs: []
  type: TYPE_TB
  zh: '| KB24 | 疲劳：齿痕 | IR（+OR） | M | 分布式 | 6 |'
- en: '| KB27 | plastic deform: indentations | OR+IR | M | distributed | 7 |'
  id: totrans-294
  prefs: []
  type: TYPE_TB
  zh: '| KB27 | 塑性变形：凹痕 | OR+IR | M | 分布式 | 7 |'
- en: '| KI14 | fatigue: pitting | IR | M | single point | 8 |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
  zh: '| KI14 | 疲劳：齿痕 | IR | M | 单点 | 8 |'
- en: '| KI16 | fatigue: pitting | IR | S | single point | 9 |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
  zh: '| KI16 | 疲劳：齿痕 | IR | S | 单点 | 9 |'
- en: '| KI17 | fatigue: pitting | IR | R | single point | 10 |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
  zh: '| KI17 | 疲劳：齿痕 | IR | R | 单点 | 10 |'
- en: '| KI18 | fatigue: pitting | IR | S | single point | 11 |'
  id: totrans-298
  prefs: []
  type: TYPE_TB
  zh: '| KI18 | 疲劳：齿痕 | IR | S | 单点 | 11 |'
- en: '| KI21 | fatigue: pitting | IR | S | single point | 12 |'
  id: totrans-299
  prefs: []
  type: TYPE_TB
  zh: '| KI21 | 疲劳：齿痕 | IR | S | 单点 | 12 |'
- en: '|'
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; OR: outer ring; IR: inner ring; &#124;'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; OR: 外环；IR: 内环；&#124;'
- en: '&#124; S: single damage; R: repetitive damage; M: multiple damages &#124;'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; S: 单一损伤；R: 重复损伤；M: 多个损伤 &#124;'
- en: '|'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: VI-A3 JiangNan University (JNU) dataset
  id: totrans-304
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A3江南大学（JNU）数据集
- en: The JNU dataset is a bearing dataset acquired by Jiang Nan University, China.
    JNU can be downloaded from [[172](#bib.bib172)] and scholars can refer to [[173](#bib.bib173)]
    for more detailed information. Four kinds of health conditions, including NA,
    IF, OF, and BF, were carried out. Vibration signals were sampled under three rotating
    speeds (600 rpm, 800 rpm, and 1000 rpm) with the sampling frequency 50 kHz. Four
    rotating speeds set to be 600 rpm, 800 rpm, and 1000 rpm are considered as different
    tasks denoted as task 0, 1, and 2. In total, there are six transfer learning settings.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
  zh: JNU数据集是中国江南大学收集的轴承数据集。JNU可以从[[172](#bib.bib172)]下载，学者可以参考[[173](#bib.bib173)]获取更详细的信息。进行了NA、IF、OF和BF四种健康状态。振动信号在三个转速（600
    rpm、800 rpm和1000 rpm）下进行采样，采样频率为50 kHz。将转速设置为600 rpm、800 rpm和1000 rpm的四个转速被视为不同的任务，分别表示为任务0、1和2。总共有六个传递学习设置。
- en: VI-A4 PHM Data Challenge on 2009 (PHM2009) dataset
  id: totrans-306
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A4 PHM Data Challenge on 2009（PHM2009）数据集
- en: The PHM2009 dataset is a generic industrial gearbox dataset provided by the
    PHM Data Challenge competition [[174](#bib.bib174)]. The sampling frequency is
    set to 200 KHz/3. Fourteen experiments (eight for spur gears and six for helical
    gears) were performed.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
  zh: PHM2009数据集是由PHM Data Challenge比赛提供的通用工业齿轮箱数据集[[174](#bib.bib174)]。采样频率设置为200
    kHz/3。进行了十四个实验（八个用于直齿轮，六个用于斜齿轮）。
- en: In this paper, we utilize the helical gears dataset (six conditions) collected
    from accelerometers mounted on input shaft retaining plates. PHM2009 contains
    five rotating speeds and two loads, but only data collected from the former four
    shaft speeds under a high load are considered. Four rotating speeds set to be
    30 Hz, 35 Hz, 40 Hz, and 45 Hz are considered as different tasks denoted as task
    0, 1, 2, and 3. In total, there are twelve transfer learning settings.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
  zh: 本文利用了从安装在输入轴保持板上的加速度计收集的螺旋齿轮数据集（六种条件）。PHM2009 包含五种转速和两种负载，但仅考虑前四种轴速在高负载下的数据。四种转速设置为
    30 Hz、35 Hz、40 Hz 和 45 Hz，视为不同的任务，分别标记为任务 0、1、2 和 3。总共有十二种迁移学习设置。
- en: VI-A5 Southeast University (SEU) dataset
  id: totrans-309
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-A5 东南大学 (SEU) 数据集
- en: 'The Southeast University (SEU) dataset is a gearbox dataset provided by Southeast
    University, China [[33](#bib.bib33), [175](#bib.bib175)]. This dataset consists
    of two sub-datasets, including the bearing and gear datasets, which were both
    collected from Drivetrain Dynamics Simulator. Eight channels were collected, and
    we use the data from the channel 2. As shown in Table [VI](#S6.T6 "TABLE VI ‣
    VI-A5 Southeast University (SEU) dataset ‣ VI-A Open source Datasets ‣ VI Datasets
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study"), each sub-dataset consists of five conditions:
    one health state and four fault states.'
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
  zh: '东南大学 (SEU) 数据集是由中国东南大学提供的齿轮箱数据集 [[33](#bib.bib33), [175](#bib.bib175)]。该数据集由两个子数据集组成，包括轴承和齿轮数据集，均从传动系统动力学模拟器收集。共收集了八个通道的数据，我们使用来自通道
    2 的数据。如表 [VI](#S6.T6 "TABLE VI ‣ VI-A5 Southeast University (SEU) dataset ‣ VI-A
    Open source Datasets ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study") 所示，每个子数据集包括五种状态：一种健康状态和四种故障状态。'
- en: Two kinds of working conditions with rotating speed - load configuration set
    to be 20 Hz - 0 V and 30 Hz - 2 V are considered as different tasks denoted as
    task 0 and 1. In total, there are two transfer learning settings.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
  zh: 两种不同的工作条件，转速 - 负载配置分别为 20 Hz - 0 V 和 30 Hz - 2 V，视为不同的任务，分别标记为任务 0 和 1。总共有两种迁移学习设置。
- en: 'TABLE VI: The transfer learning tasks of SEU.'
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
  zh: 表 VI：SEU 的迁移学习任务。
- en: '| Label | Location | Type | Description |'
  id: totrans-313
  prefs: []
  type: TYPE_TB
  zh: '| 标签 | 位置 | 类型 | 描述 |'
- en: '| --- | --- | --- | --- |'
  id: totrans-314
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| 0 | Gear | Health |  |'
  id: totrans-315
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 齿轮 | 健康 |  |'
- en: '| Bearing |'
  id: totrans-316
  prefs: []
  type: TYPE_TB
  zh: '| 轴承 |'
- en: '| 1 | Bearing | Ball | Crack in the ball |'
  id: totrans-317
  prefs: []
  type: TYPE_TB
  zh: '| 1 | 轴承 | 球体 | 球体中的裂纹 |'
- en: '| 2 | Bearing | Outer | Crack in the outer ring |'
  id: totrans-318
  prefs: []
  type: TYPE_TB
  zh: '| 2 | 轴承 | 外圈 | 外圈的裂纹 |'
- en: '| 3 | Bearing | Inner | Crack in the inner ring |'
  id: totrans-319
  prefs: []
  type: TYPE_TB
  zh: '| 3 | 轴承 | 内圈 | 内圈的裂纹 |'
- en: '| 4 | Bearing | Combination | Crack in the inner and outer rings |'
  id: totrans-320
  prefs: []
  type: TYPE_TB
  zh: '| 4 | 轴承 | 组合 | 内外圈的裂纹 |'
- en: '| 5 | Gear | Chipped | Crack in the gear feet |'
  id: totrans-321
  prefs: []
  type: TYPE_TB
  zh: '| 5 | 齿轮 | 削片 | 齿轮脚上的裂纹 |'
- en: '| 6 | Gear | Miss | Missing feet in the gear |'
  id: totrans-322
  prefs: []
  type: TYPE_TB
  zh: '| 6 | 齿轮 | 缺失 | 齿轮中的缺失脚 |'
- en: '| 7 | Gear | Surface | Wear in the surface of the gear |'
  id: totrans-323
  prefs: []
  type: TYPE_TB
  zh: '| 7 | 齿轮 | 表面 | 齿轮表面的磨损 |'
- en: '| 8 | Gear | Root | Crack in the root of the gear feet |'
  id: totrans-324
  prefs: []
  type: TYPE_TB
  zh: '| 8 | 齿轮 | 根部 | 齿轮脚根部的裂纹 |'
- en: VI-B Data preprocessing and splitting
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VI-B 数据预处理与划分
- en: Data preprocessing and splitting are two important aspects in terms of performance
    of UDTL-based IFD. Although UDTL-based methods often possess automatic feature
    learning capabilities, some data processing steps can help models achieve better
    performance, such as Short-time Fourier Transform (STFT) in speech signal classification
    and the data normalization in image classification. Besides, there often exist
    some pitfalls in the training phase, especially test leakage. That is, test samples
    are unheedingly used in the training phase.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
  zh: 数据预处理和划分是 UDTL 基于 IFD 性能的两个重要方面。尽管 UDTL 基于的方法通常具有自动特征学习能力，但一些数据处理步骤可以帮助模型实现更好的性能，例如语音信号分类中的短时傅里叶变换
    (STFT) 和图像分类中的数据归一化。此外，训练阶段往往存在一些陷阱，特别是测试泄漏。也就是说，测试样本不经意地用于训练阶段。
- en: VI-B1 Input types
  id: totrans-327
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B1 输入类型
- en: There are two kinds of input types tested in this paper, including the time
    domain input and the frequency domain input. For the former one, signals are used
    as the input directly and the sample length is 1024 without any overlapping. For
    the latter one, signals are first transformed into the frequency domain and the
    sample length is 512 due to the symmetry of spectral coefficients.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
  zh: 本文测试了两种输入类型，包括时域输入和频域输入。对于前者，信号直接用作输入，样本长度为 1024，无任何重叠。对于后者，信号首先转换到频域，样本长度为
    512 由于谱系数的对称性。
- en: VI-B2 Normalization
  id: totrans-329
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B2 归一化
- en: Data normalization is the basic procedure in UDTL-based IFD, which can keep
    input values into a certain range. In this paper, we use the Z-score normalization.
  id: totrans-330
  prefs: []
  type: TYPE_NORMAL
  zh: 数据归一化是基于 UDTL 的 IFD 中的基本过程，可以将输入值保持在一定范围内。本文中，我们使用 Z-score 归一化。
- en: VI-B3 Data splitting
  id: totrans-331
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VI-B3 数据划分
- en: 'Since this paper does not use the validation set to select the best model,
    the splitting of the validation set is ignored here. In UDTL-based IFD, data in
    the target domain are used in the training procedure to realize the domain alignment
    and are also used as the test sets. In fact, data in these two situations should
    not overlap, otherwise there would exist test leakage. Therefore, as shown in
    Fig. [15](#S6.F15 "Figure 15 ‣ VI-B3 Data splitting ‣ VI-B Data preprocessing
    and splitting ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"), we take 80%
    of total samples as the training set and 20% of total samples as the test set
    in source and target domains to avoid this test leakage.'
  id: totrans-332
  prefs: []
  type: TYPE_NORMAL
  zh: 由于本文没有使用验证集来选择最佳模型，因此忽略了验证集的划分。在基于 UDTL 的 IFD 中，目标域中的数据在训练过程中用于实现领域对齐，并且也用作测试集。实际上，这两种情况的数据不应重叠，否则会存在测试泄漏。因此，如图
    [15](#S6.F15 "图 15 ‣ VI-B3 数据划分 ‣ VI-B 数据预处理和划分 ‣ VI 数据集 ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")
    所示，我们将源域和目标域的总样本的 80% 作为训练集，将 20% 作为测试集，以避免这种测试泄漏。
- en: '![Refer to caption](img/a238c1605124eeba067379361da02c2b.png)'
  id: totrans-333
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/a238c1605124eeba067379361da02c2b.png)'
- en: 'Figure 15: Data splitting for UDTL-based IFD.'
  id: totrans-334
  prefs: []
  type: TYPE_NORMAL
  zh: 图 15：基于 UDTL 的 IFD 数据划分。
- en: VII Comparative studies
  id: totrans-335
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VII 比较研究
- en: We will discuss evaluation results, which are shown in Appendix A. To make the
    accuracy more readable, we use some visualization methods to present the results.
  id: totrans-336
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将讨论评估结果，结果显示在附录 A 中。为了使准确度更具可读性，我们使用了一些可视化方法来呈现结果。
- en: VII-A Training details
  id: totrans-337
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-A 训练细节
- en: We implement all UDTL-based IFD methods in Pytorch and put them into a unified
    code framework. Each model is trained for 300 epochs and model training and test
    processes are alternated during the training procedure. We adapt mini-batch Adam
    optimizer and the batch size is equal to 64. The “step” strategy in Pytorch is
    used as the learning rate annealing method and the initial learning rate is 0.001
    with a decay (multiplied by 0.1) in the epoch 150 and 250, respectively. We use
    a progressive training method increasing the trade-off parameter from 0 to 1 via
    multiplying by $\frac{1-\exp(-\zeta\kappa)}{1+\exp(-\zeta\kappa)}$ [[107](#bib.bib107)],
    where $\zeta=10$ and $\kappa$ means the training progress changing from 0 to 1
    after transfer learning strategies are activated.
  id: totrans-338
  prefs: []
  type: TYPE_NORMAL
  zh: 我们在 Pytorch 中实现了所有基于 UDTL 的 IFD 方法，并将它们放入一个统一的代码框架中。每个模型训练 300 个周期，并且模型训练和测试过程在训练过程中交替进行。我们采用了小批量
    Adam 优化器，批量大小为 64。在 Pytorch 中使用“step”策略作为学习率衰减方法，初始学习率为 0.001，并在第 150 和 250 个周期分别进行衰减（乘以
    0.1）。我们使用渐进训练方法，通过乘以 $\frac{1-\exp(-\zeta\kappa)}{1+\exp(-\zeta\kappa)}$ [[107](#bib.bib107)]
    将权衡参数从 0 增加到 1，其中 $\zeta=10$，$\kappa$ 表示在迁移学习策略激活后，训练进度从 0 变化到 1。
- en: All experiments are executed under Window 10 and Pytorch 1.3 running on a computer
    with an Intel Core i7-9700K, GeForce RTX 2080Ti, and 16G RAM.
  id: totrans-339
  prefs: []
  type: TYPE_NORMAL
  zh: 所有实验均在 Windows 10 和 Pytorch 1.3 上执行，运行在一台配备 Intel Core i7-9700K、GeForce RTX
    2080Ti 和 16G RAM 的计算机上。
- en: VII-B Label-consistent UDTL
  id: totrans-340
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-B 标签一致性 UDTL
- en: For MK-MMD, JMMD, CORAL, DANN, and CDAN, we train models with source samples
    in the former 50 epochs to get a so-called pre-trained model, and then transfer
    learning strategies are activated. For AdaBN, we update the statistics of BN layers
    via each batch for 3 extra epochs.
  id: totrans-341
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 MK-MMD、JMMD、CORAL、DANN 和 CDAN，我们在前 50 个周期内使用源样本训练模型以获得所谓的预训练模型，然后激活迁移学习策略。对于
    AdaBN，我们通过每个批次更新 BN 层的统计信息，额外训练 3 个周期。
- en: VII-B1 Evaluation metrics
  id: totrans-342
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-B1 评估指标
- en: For simplicity, we use the overall accuracy, which is the number of correctly
    classified samples divided by the total number of samples in test data, to verify
    the performance of different models. To avoid the randomness, we perform experiments
    five times, and mean as well as maximum values of the overall accuracy are used
    to evaluate the final performance because variance of five experiments is not
    statistically useful. In this paper, we use mean and maximum accuracy in the last
    epoch denoted as Last-Mean and Last-Max to represent the test accuracy without
    any test leakage. Meanwhile, we also list mean and maximum accuracy denoted as
    Best-Mean and Best-Max in the epoch where models achieve the best performance.
  id: totrans-343
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化，我们使用整体准确率，即正确分类样本的数量除以测试数据中的总样本数，来验证不同模型的性能。为了避免随机性，我们进行了五次实验，使用整体准确率的均值和最大值来评估最终性能，因为五次实验的方差在统计上没有意义。在本文中，我们使用最后一个周期的均值和最大值，称为Last-Mean和Last-Max，来表示没有测试泄漏的测试准确率。同时，我们还列出了在模型达到最佳性能的周期中的均值和最大值，称为Best-Mean和Best-Max。
- en: VII-B2 Results of datasets
  id: totrans-344
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-B2 数据集结果
- en: 'To make comparisons clearer, we summarize the highest average accuracy of different
    datasets among all methods, and results are shown in Fig. [16](#S7.F16 "Figure
    16 ‣ VII-B2 Results of datasets ‣ VII-B Label-consistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study"). We can observe that CWRU and JNU
    can achieve the accuracy over 95% and other datasets can only achieve an accuracy
    of around 60%. It is also worth mentioning that the accuracy is just a lower bound
    due to the fact that it is very hard to fine-tune every parameter in detail.'
  id: totrans-345
  prefs: []
  type: TYPE_NORMAL
  zh: '为了使比较更加清晰，我们总结了所有方法在不同数据集上的最高平均准确率，结果如图[16](#S7.F16 "Figure 16 ‣ VII-B2 Results
    of datasets ‣ VII-B Label-consistent UDTL ‣ VII Comparative studies ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")所示。我们可以观察到，CWRU和JNU的准确率超过95%，而其他数据集的准确率仅约为60%。还值得一提的是，由于很难详细调整每个参数，准确率仅为下限。'
- en: '![Refer to caption](img/34b25e7cd6e07f049b17a9ae1db081bf.png)'
  id: totrans-346
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/34b25e7cd6e07f049b17a9ae1db081bf.png)'
- en: 'Figure 16: The highest average accuracy of different datasets among all methods.'
  id: totrans-347
  prefs: []
  type: TYPE_NORMAL
  zh: 图16：所有方法在不同数据集上的最高平均准确率。
- en: VII-B3 Results of models
  id: totrans-348
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-B3 模型结果
- en: 'Results of different methods are shown in Fig. [17](#S7.F17 "Figure 17 ‣ VII-B3
    Results of models ‣ VII-B Label-consistent UDTL ‣ VII Comparative studies ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study") to Fig. [21](#S7.F21 "Figure 21 ‣ VII-B3 Results of models
    ‣ VII-B Label-consistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"), and Fig. [21](#S7.F21 "Figure 21 ‣ VII-B3 Results of models ‣ VII-B Label-consistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") is not set as
    the radar chart because two transfer tasks are not suitable for this visualization.
    For all datasets, methods discussed in this paper can improve the accuracy of
    Basis, except CORAL. For CORAL, it can only improve the accuracy in CWRU with
    the frequency domain input or in some transfer tasks. For AdaBN, the improvement
    is much smaller than other methods.'
  id: totrans-349
  prefs: []
  type: TYPE_NORMAL
  zh: '不同方法的结果如图[17](#S7.F17 "Figure 17 ‣ VII-B3 Results of models ‣ VII-B Label-consistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study")至图[21](#S7.F21
    "Figure 21 ‣ VII-B3 Results of models ‣ VII-B Label-consistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")所示，其中图[21](#S7.F21 "Figure 21 ‣ VII-B3
    Results of models ‣ VII-B Label-consistent UDTL ‣ VII Comparative studies ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")没有设置为雷达图，因为两个迁移任务不适合这种可视化。对于所有数据集，本文讨论的方法可以提高Basis的准确性，除了CORAL。对于CORAL，它只能在CWRU中使用频域输入或在某些迁移任务中提高准确性。对于AdaBN，改进幅度远小于其他方法。'
- en: In general, results of JMMD are better than those of MK-MMD, which indicates
    that the assumption of joint distribution in source and target domains is useful
    for improving the performance. Results of DANN and CDAN are generally better than
    those of MK-MMD, which indicates that adversarial training is helpful for aligning
    the domain shift.
  id: totrans-350
  prefs: []
  type: TYPE_NORMAL
  zh: 总体而言，JMMD的结果优于MK-MMD，这表明源领域和目标领域的联合分布假设有助于提高性能。DANN和CDAN的结果通常优于MK-MMD，这表明对抗训练有助于对齐领域偏移。
- en: '![Refer to caption](img/46027de21b9fff925c1178e83eb02700.png)'
  id: totrans-351
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/46027de21b9fff925c1178e83eb02700.png)'
- en: 'Figure 17: The accuracy comparisons of different methods in CWRU.'
  id: totrans-352
  prefs: []
  type: TYPE_NORMAL
  zh: 图17：不同方法在CWRU中的准确率比较。
- en: '![Refer to caption](img/1bc86d5e768c75c7f25400e93159bc4c.png)'
  id: totrans-353
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/1bc86d5e768c75c7f25400e93159bc4c.png)'
- en: 'Figure 18: The accuracy comparisons of different methods in PU.'
  id: totrans-354
  prefs: []
  type: TYPE_NORMAL
  zh: 图18：不同方法在PU中的准确率比较。
- en: '![Refer to caption](img/d1405b1f6a9bc5989d2e9db94cc37fea.png)'
  id: totrans-355
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d1405b1f6a9bc5989d2e9db94cc37fea.png)'
- en: 'Figure 19: The accuracy comparisons of different methods in JNU.'
  id: totrans-356
  prefs: []
  type: TYPE_NORMAL
  zh: 图19：不同方法在JNU中的准确率比较。
- en: '![Refer to caption](img/a8a8b81723c095e686d604ad45eccd72.png)'
  id: totrans-357
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a8a8b81723c095e686d604ad45eccd72.png)'
- en: 'Figure 20: The accuracy comparisons of different methods in PHM2009.'
  id: totrans-358
  prefs: []
  type: TYPE_NORMAL
  zh: 图20：不同方法在PHM2009中的准确率比较。
- en: '![Refer to caption](img/377d993665a132e5e5824a679a08dc71.png)'
  id: totrans-359
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/377d993665a132e5e5824a679a08dc71.png)'
- en: 'Figure 21: The accuracy comparisons of different methods in SEU.'
  id: totrans-360
  prefs: []
  type: TYPE_NORMAL
  zh: 图21：不同方法在SEU中的准确率比较。
- en: VII-B4 Results of input types
  id: totrans-361
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-B4 输入类型的结果
- en: 'Accuracy comparisons of two input types are shown in Fig. [22](#S7.F22 "Figure
    22 ‣ VII-B4 Results of input types ‣ VII-B Label-consistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study"), and it can be concluded that the
    time domain input achieves better accuracy in CWRU, JNU, and SEU, while the frequency
    domain input gets better accuracy in PU and PHM2009. Besides, the accuracy gap
    between these two input types is relatively large, and we cannot simply infer
    which one is better due to the influence of backbones.'
  id: totrans-362
  prefs: []
  type: TYPE_NORMAL
  zh: '两种输入类型的准确率比较见图 [22](#S7.F22 "Figure 22 ‣ VII-B4 Results of input types ‣ VII-B
    Label-consistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study")，可以得出结论：时域输入在CWRU、JNU和SEU中取得了更好的准确率，而频域输入在PU和PHM2009中取得了更好的准确率。此外，这两种输入类型之间的准确率差距较大，由于骨干网络的影响，我们不能简单推断哪一种更好。'
- en: Thus, for a new dataset, we should test results of different input types instead
    of just using the more advanced techniques to improve the performance of one input
    type, because using a different input type might improve the accuracy more efficient
    than using advanced techniques.
  id: totrans-363
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，对于一个新的数据集，我们应该测试不同输入类型的结果，而不是仅仅使用更先进的技术来提高一种输入类型的性能，因为使用不同的输入类型可能比使用先进的技术更有效地提高准确率。
- en: '![Refer to caption](img/c72412c9450e989d0486e3356d41aab3.png)'
  id: totrans-364
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c72412c9450e989d0486e3356d41aab3.png)'
- en: 'Figure 22: The accuracy comparisons of two input types with different datasets.
    (F) means the frequency domain input, and (T) means the time domain input.'
  id: totrans-365
  prefs: []
  type: TYPE_NORMAL
  zh: 图22：两种输入类型在不同数据集中的准确率比较。（F）表示频域输入，（T）表示时域输入。
- en: VII-B5 Results of accuracy types
  id: totrans-366
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-B5 准确率类型的结果
- en: 'As mentioned in Section [VII](#S7 "VII Comparative studies ‣ Applications of
    Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and
    Comparative Study"), we use four kinds of accuracy including Best-Mean, Best-Max,
    Last-Mean, and Last-Max to evaluate the performance. As shown in Fig. [23](#S7.F23
    "Figure 23 ‣ VII-B5 Results of accuracy types ‣ VII-B Label-consistent UDTL ‣
    VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"), the fluctuation
    of different experiments is sometimes large, especially for those datasets whose
    overall accuracy is not very high, which indicates that the used algorithms are
    not very stable and robust. Besides, it seems that the fluctuation of the time
    domain input is smaller than that of the frequency domain input, and the reason
    might be that the backbone used in this paper is more suitable for the time domain
    input.'
  id: totrans-367
  prefs: []
  type: TYPE_NORMAL
  zh: 如第 [VII](#S7 "VII 比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究") 节所述，我们使用包括最佳均值（Best-Mean）、最佳最大值（Best-Max）、最后均值（Last-Mean）和最后最大值（Last-Max）在内的四种准确率来评估性能。如图
    [23](#S7.F23 "图 23 ‣ VII-B5 准确度类型的结果 ‣ VII-B 标签一致的 UDTL ‣ VII 比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    所示，不同实验的波动有时很大，特别是对于那些整体准确率不是很高的数据集，这表明所使用的算法不是很稳定和鲁棒。此外，时间域输入的波动似乎小于频率域输入的波动，原因可能是本文中使用的骨干网更适合时间域输入。
- en: 'As shown in Fig. [24](#S7.F24 "Figure 24 ‣ VII-B5 Results of accuracy types
    ‣ VII-B Label-consistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"), the fluctuation of different experiments is also large, which is dangerous
    for evaluating the true performance. Since Best uses the test set to choose the
    best model (it is a kind of test leakage), Last may be more suitable for representing
    the generalization accuracy.'
  id: totrans-368
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [24](#S7.F24 "图 24 ‣ VII-B5 准确度类型的结果 ‣ VII-B 标签一致的 UDTL ‣ VII 比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    所示，不同实验的波动也很大，这对于评估真实性能是危险的。由于最佳（Best）使用测试集来选择最佳模型（这是一种测试泄漏），因此最后（Last）可能更适合表示泛化准确率。
- en: Thus, on the one hand, the stability and robustness of UDTL-based IFD need more
    attention instead of just improving the accuracy. On the other hand, as we analyze
    above, the accuracy of the last epoch (Last) is more suitable for representing
    the generalization ability of algorithms when the fluctuation between Best and
    Last is large.
  id: totrans-369
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，一方面，基于 UDTL 的 IFD 的稳定性和鲁棒性需要更多关注，而不仅仅是提高准确率。另一方面，正如我们上面分析的那样，当最佳（Best）与最后（Last）之间的波动较大时，最后一个时期（Last）的准确率更适合表示算法的泛化能力。
- en: '![Refer to caption](img/96488a8fc3d2da06d24c0c6556d6cf77.png)'
  id: totrans-370
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/96488a8fc3d2da06d24c0c6556d6cf77.png)'
- en: 'Figure 23: The difference between Max and Mean according to Best average.'
  id: totrans-371
  prefs: []
  type: TYPE_NORMAL
  zh: 图 23：根据最佳均值，最大值与均值之间的差异。
- en: '![Refer to caption](img/caf701b07ef7d984a902c3935b8549cf.png)'
  id: totrans-372
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/caf701b07ef7d984a902c3935b8549cf.png)'
- en: 'Figure 24: The difference between Best average and Last average according to
    Mean.'
  id: totrans-373
  prefs: []
  type: TYPE_NORMAL
  zh: 图 24：根据均值，最佳均值与最后均值之间的差异。
- en: VII-C Label-inconsistent UDTL
  id: totrans-374
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-C 标签不一致的 UDTL
- en: In these methods, the transfer learning strategies are activated from the beginning.
    For UAN, the trade-off parameter of the loss of non-adversarial domain discriminator
    is fixed as 1. The value $\tau$ of OSBP and the threshold $\omega_{0}$ of UAN
    are both set to 0.5 for all tasks.
  id: totrans-375
  prefs: []
  type: TYPE_NORMAL
  zh: 在这些方法中，迁移学习策略从一开始就被激活。对于 UAN，非对抗性领域鉴别器的损失的折中参数固定为 1。OSBP 的值 $\tau$ 和 UAN 的阈值
    $\omega_{0}$ 都设置为 0.5 以适用于所有任务。
- en: VII-C1 Evaluation metrics
  id: totrans-376
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C1 评价指标
- en: For partial-based transfer learning, the evaluation metrics are the same as
    that of label-consistent UDTL, including Last-Mean, Last-Max, Best-Mean, and Best-Max.
    For open set and universal transfer learning, due to the existence of unknown
    classes, only the overall accuracy is not sufficient for evaluating the model
    performance. To clearly explain evaluation metrics, several mathematical notations
    are defined. $M_{S}$ and $M_{U}$ are the number of correctly classified shared-class
    and successfully detected unknown-class test samples, respectively. $N_{S}$ and
    $N_{U}$ are the number of all shared-class and unknown-class test samples, respectively.
    $Acc_{c}$ is the accuracy of test samples from the $c$-th class.
  id: totrans-377
  prefs: []
  type: TYPE_NORMAL
  zh: 对于基于部分的迁移学习，评估指标与标签一致的 UDTL 相同，包括 Last-Mean、Last-Max、Best-Mean 和 Best-Max。对于开放集和通用迁移学习，由于存在未知类别，仅依赖总体准确率不足以评估模型性能。为了清楚说明评估指标，定义了几个数学符号。$M_{S}$
    和 $M_{U}$ 分别是正确分类的共享类别和成功检测的未知类别测试样本数量。$N_{S}$ 和 $N_{U}$ 分别是所有共享类别和未知类别测试样本的数量。$Acc_{c}$
    是来自第 $c$ 类的测试样本的准确率。
- en: 'Following previous work in [[150](#bib.bib150), [176](#bib.bib176), [144](#bib.bib144),
    [177](#bib.bib177)], five evaluation metrics are employed:'
  id: totrans-378
  prefs: []
  type: TYPE_NORMAL
  zh: 根据之前的工作[[150](#bib.bib150), [176](#bib.bib176), [144](#bib.bib144), [177](#bib.bib177)]，采用了五个评估指标：
- en: 1)
  id: totrans-379
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 1)
- en: 'Accuracy of shared classes: $\text{ALL}^{*}=\frac{M_{S}}{N_{S}}$'
  id: totrans-380
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 共享类别的准确率：$\text{ALL}^{*}=\frac{M_{S}}{N_{S}}$
- en: 2)
  id: totrans-381
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 2)
- en: 'Accuracy of unknown classes: $\text{UNK}=\frac{M_{U}}{N_{U}}$'
  id: totrans-382
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 未知类别的准确率：$\text{UNK}=\frac{M_{U}}{N_{U}}$
- en: 3)
  id: totrans-383
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 3)
- en: 'Averaged accuracy of all classes: $\text{OS}=\frac{1}{C+1}\sum_{c=0}^{C}{Acc_{c}}$'
  id: totrans-384
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有类别的平均准确率：$\text{OS}=\frac{1}{C+1}\sum_{c=0}^{C}{Acc_{c}}$
- en: 4)
  id: totrans-385
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 4)
- en: 'Accuracy of all test samples: $\text{ALL}=\frac{M_{S}+M_{U}}{N_{S}+N_{U}}$'
  id: totrans-386
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 所有测试样本的准确率：$\text{ALL}=\frac{M_{S}+M_{U}}{N_{S}+N_{U}}$
- en: 5)
  id: totrans-387
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: 5)
- en: 'Harmonic mean: $\text{H-score}=\frac{2\text{ALL}^{*}\;\text{UNK}}{\text{ALL}^{*}+\text{UNK}}$'
  id: totrans-388
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 调和平均数：$\text{H-score}=\frac{2\text{ALL}^{*}\;\text{UNK}}{\text{ALL}^{*}+\text{UNK}}$
- en: Similar to the label-consistent UDTL, mean and maximum values of the overall
    accuracy are used to evaluate the final performance. We use the mean accuracy
    of all five evaluation metrics in the last epoch denoted as Last-Mean-ALL*, Last-Mean-UNK,
    Last-Mean-OS, Last-Mean-ALL, and Last-Mean-H-score. We use the accuracy when models
    perform the best H-score among five tests in the last epoch, denoted as Last-Max-ALL*,
    Last-Max-UNK, Last-Max-OS, Last-Max-ALL, and Last-Max-H-score. Meanwhile, we also
    list the mean accuracy denoted as Best-Mean-ALL*, Best-Mean-UNK, Best-Mean-OS,
    Best-Mean-ALL, and Best-Mean-H-score in the epoch where models achieve the best
    performance on H-score. We also list the accuracy denoted as Best-Max-ALL*, Best-Max-UNK,
    Best-Max-OS, Best-Max-ALL, and Best-Max-H-score where models achieve the best
    performance on H-score among five tests.
  id: totrans-389
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于标签一致的 UDTL，整体准确率的均值和最大值用于评估最终性能。我们使用最后一轮所有五个评估指标的均值准确率，表示为 Last-Mean-ALL*、Last-Mean-UNK、Last-Mean-OS、Last-Mean-ALL
    和 Last-Mean-H-score。我们使用模型在最后一轮五次测试中表现最佳 H-score 的准确率，表示为 Last-Max-ALL*、Last-Max-UNK、Last-Max-OS、Last-Max-ALL
    和 Last-Max-H-score。同时，我们还列出了模型在 H-score 上表现最佳的轮次的均值准确率，表示为 Best-Mean-ALL*、Best-Mean-UNK、Best-Mean-OS、Best-Mean-ALL
    和 Best-Mean-H-score。我们还列出了模型在五次测试中 H-score 表现最佳的准确率，表示为 Best-Max-ALL*、Best-Max-UNK、Best-Max-OS、Best-Max-ALL
    和 Best-Max-H-score。
- en: VII-C2 Dataset settings
  id: totrans-390
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C2 数据集设置
- en: 'CWRU is selected for testing the performance. Following recent works in [[150](#bib.bib150)],
    different classes are randomly selected to form transfer learning tasks to validate
    the effectiveness of models on different label sets. The fault diagnosis tasks
    for partial, open set, and universal transfer learning are presented in Table
    [VII](#S7.T7 "TABLE VII ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL
    ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") respectively.'
  id: totrans-391
  prefs: []
  type: TYPE_NORMAL
  zh: 'CWRU 被选用于测试性能。根据最近的研究[[150](#bib.bib150)]，随机选择不同类别来形成迁移学习任务，以验证模型在不同标签集上的有效性。部分、开放集和通用迁移学习的故障诊断任务分别在表
    [VII](#S7.T7 "TABLE VII ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL
    ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study")中给出。'
- en: 'TABLE VII: The fault diagnosis tasks of CWRU.'
  id: totrans-392
  prefs: []
  type: TYPE_NORMAL
  zh: 表 VII：CWRU 的故障诊断任务。
- en: '| Task | Partial UDTL | Open Set UDTL | Universal UDTL |'
  id: totrans-393
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 部分 UDTL | 开放集 UDTL | 通用 UDTL |'
- en: '| --- | --- | --- | --- |'
  id: totrans-394
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- |'
- en: '| Source Label Set | Target Label Set | Source Label Set | Target Label Set
    | Source Label Set | Target Label Set |'
  id: totrans-395
  prefs: []
  type: TYPE_TB
  zh: '| 源标签集 | 目标标签集 | 源标签集 | 目标标签集 | 源标签集 | 目标标签集 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-396
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0-1 | 0$\sim$9 | 0,1,2,4,5,7,8,9 | 0,2,3,5,6,7,8,9 | 0$\sim$9 | 0,1,2,4,5,6,7,8,9
    | 1,2,3,4,5,7,8,9 |'
  id: totrans-397
  prefs: []
  type: TYPE_TB
  zh: '| 0-1 | 0$\sim$9 | 0,1,2,4,5,7,8,9 | 0,2,3,5,6,7,8,9 | 0$\sim$9 | 0,1,2,4,5,6,7,8,9
    | 1,2,3,4,5,7,8,9 |'
- en: '| 0-2 |'
  id: totrans-398
  prefs: []
  type: TYPE_TB
  zh: '| 0-2 |'
- en: '| 0-3 | 0$\sim$9 | 1,2,4,6,7,8,9 | 0,1,2,3,4,5,6 | 0$\sim$9 | 0,1,2,3,4,5,7,8
    | 0,2,3,4,5,6,7,8,9 |'
  id: totrans-399
  prefs: []
  type: TYPE_TB
  zh: '| 0-3 | 0$\sim$9 | 1,2,4,6,7,8,9 | 0,1,2,3,4,5,6 | 0$\sim$9 | 0,1,2,3,4,5,7,8
    | 0,2,3,4,5,6,7,8,9 |'
- en: '| 1-0 |'
  id: totrans-400
  prefs: []
  type: TYPE_TB
  zh: '| 1-0 |'
- en: '| 1-2 | 0$\sim$9 | 0,1,3,7,9 | 1,3,4,5,7,8 | 0$\sim$9 | 1,2,4,5,7,8,9 | 1,3,6,8
    |'
  id: totrans-401
  prefs: []
  type: TYPE_TB
  zh: '| 1-2 | 0$\sim$9 | 0,1,3,7,9 | 1,3,4,5,7,8 | 0$\sim$9 | 1,2,4,5,7,8,9 | 1,3,6,8
    |'
- en: '| 1-3 |'
  id: totrans-402
  prefs: []
  type: TYPE_TB
  zh: '| 1-3 |'
- en: '| 2-0 | 0$\sim$9 | 1,2,4,7 | 0,2,4,5,6,9 | 0$\sim$9 | 1,3,4,6,7,8 | 0,1,2,3,5,6,8,9
    |'
  id: totrans-403
  prefs: []
  type: TYPE_TB
  zh: '| 2-0 | 0$\sim$9 | 1,2,4,7 | 0,2,4,5,6,9 | 0$\sim$9 | 1,3,4,6,7,8 | 0,1,2,3,5,6,8,9
    |'
- en: '| 2-1 |'
  id: totrans-404
  prefs: []
  type: TYPE_TB
  zh: '| 2-1 |'
- en: '| 2-3 | 0$\sim$9 | 0,2,6 | 0,1,2,5,7 | 0$\sim$9 | 0,1,2,7,8 | 1,2,6,9 |'
  id: totrans-405
  prefs: []
  type: TYPE_TB
  zh: '| 2-3 | 0$\sim$9 | 0,2,6 | 0,1,2,5,7 | 0$\sim$9 | 0,1,2,7,8 | 1,2,6,9 |'
- en: '| 3-0 |'
  id: totrans-406
  prefs: []
  type: TYPE_TB
  zh: '| 3-0 |'
- en: '| 3-1 | 0$\sim$9 | 5,8 | 4,8,9 | 0$\sim$9 | 0,1,5,7,8 | 0,4,8 |'
  id: totrans-407
  prefs: []
  type: TYPE_TB
  zh: '| 3-1 | 0$\sim$9 | 5,8 | 4,8,9 | 0$\sim$9 | 0,1,5,7,8 | 0,4,8 |'
- en: '| 3-2 |'
  id: totrans-408
  prefs: []
  type: TYPE_TB
  zh: '| 3-2 |'
- en: '![Refer to caption](img/6e01e6b0c309626cf5ea8820c4321e74.png)'
  id: totrans-409
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/6e01e6b0c309626cf5ea8820c4321e74.png)'
- en: 'Figure 25: The overall accuracy of PADA with the time domain input.'
  id: totrans-410
  prefs: []
  type: TYPE_NORMAL
  zh: 图25：PADA在时间域输入下的整体准确率。
- en: '![Refer to caption](img/b680cd4c67a3e2839d9f9ff6e110fee3.png)'
  id: totrans-411
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b680cd4c67a3e2839d9f9ff6e110fee3.png)'
- en: 'Figure 26: The overall accuracy of OSBP with the time domain input: (a) Best-Mean
    and (b) Last-Mean.'
  id: totrans-412
  prefs: []
  type: TYPE_NORMAL
  zh: 图26：OSBP在时间域输入下的整体准确率：（a）Best-Mean和（b）Last-Mean。
- en: '![Refer to caption](img/30021a77279fb161cf1be9f49cf13c15.png)'
  id: totrans-413
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/30021a77279fb161cf1be9f49cf13c15.png)'
- en: 'Figure 27: The overall accuracy of UAN with the time domain input: (a) Best-Mean
    and (b) Last-Mean.'
  id: totrans-414
  prefs: []
  type: TYPE_NORMAL
  zh: 图27：UAN在时间域输入下的整体准确率：（a）Best-Mean和（b）Last-Mean。
- en: VII-C3 Results of partial UDTL
  id: totrans-415
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C3 部分 UDTL 的结果
- en: 'For simplicity, as shown in Fig. [25](#S7.F25 "Figure 25 ‣ VII-C2 Dataset settings
    ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"), we only list Best-Mean and Last-Mean of PADA with the time domain input
    due to the similarity between time and frequency domain inputs. We can observe
    that PADA can achieve good performance on most tasks according to the overall
    training phase. But for tasks 3-1, 2-3, and 3-2, Last-Mean is obviously lower
    than Best-Mean, indicating that negative transfer resulting from extra source
    labels cannot be addressed totally by PADA and there exist the overfitting problem
    during the training procedure.'
  id: totrans-416
  prefs: []
  type: TYPE_NORMAL
  zh: '为了简单起见，如图[25](#S7.F25 "Figure 25 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study")所示，由于时间域输入和频率域输入之间的相似性，我们仅列出了PADA在时间域输入下的Best-Mean和Last-Mean。我们可以观察到，根据整体训练阶段，PADA在大多数任务上能够取得良好的表现。但是对于任务3-1、2-3和3-2，Last-Mean明显低于Best-Mean，这表明由额外源标签导致的负迁移不能完全通过PADA解决，并且在训练过程中存在过拟合问题。'
- en: VII-C4 Results of open set UDTL
  id: totrans-417
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C4 开集 UDTL 的结果
- en: 'Best-Mean and Last-Mean accuracy of OSBP with the time domain input are shown
    in Fig. [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"). From Fig. [26](#S7.F26
    "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study") (a), it can be seen that OSBP can
    achieve relatively good performance on most transfer tasks. However as shown in
    Fig. [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") (b), performance
    obviously degrades on the later stage, especially for UNK, which reveals that
    the model overfits on the source samples, and thus unknown-class samples cannot
    be effectively recognized. Moreover, the lowest $\text{ALL}^{*}$ is only about
    50 %, which means that only half of shared-class samples can be correctly classified.
    Therefore, more effective models, which not only have the ability to detect unknown-class
    samples but also ensure accurate shared-class classification, are required.'
  id: totrans-418
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") 显示了带有时间域输入的 OSBP
    的最佳均值和最后均值准确率。从图 [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") (a) 中可以看出，OSBP
    在大多数迁移任务中可以实现相对较好的性能。然而，如图 [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣
    VII-C Label-inconsistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study") (b) 所示，性能在后期明显下降，尤其是在未知类（UNK）上，这表明模型对源样本过拟合，因此无法有效识别未知类样本。此外，最低的 $\text{ALL}^{*}$
    仅约为 50%，这意味着只有一半的共享类样本可以被正确分类。因此，需要更有效的模型，这些模型不仅能够检测未知类样本，还能确保准确的共享类分类。'
- en: VII-C5 Results of universal UDTL
  id: totrans-419
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C5 通用 UDTL 的结果
- en: 'Best-Mean and Last-Mean accuracy of UAN with the time domain input are shown
    in Fig. [27](#S7.F27 "Figure 27 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"). Generally speaking,
    UAN can achieve excellent performance on the CWRU dataset according to Fig. [27](#S7.F27
    "Figure 27 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study") (a). Similar to the results of OSBP,
    the performance of UAN also degrades on the later stage because of the overfitting
    problem and wrong feature alignment. In addition, the shared-class classification
    accuracy still need be improved. It is still difficult for the model to separate
    extra source classes and detect unknown classes from the target domain.'
  id: totrans-420
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [27](#S7.F27 "Figure 27 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") 显示了带有时间域输入的 UAN
    的最佳均值和最后均值准确率。一般来说，根据图 [27](#S7.F27 "Figure 27 ‣ VII-C2 Dataset settings ‣ VII-C
    Label-inconsistent UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study") (a)，UAN 可以在 CWRU 数据集上实现优异的性能。与 OSBP 的结果类似，UAN 的性能在后期也因过拟合问题和错误的特征对齐而下降。此外，共享类分类准确率仍需提高。模型仍然难以从目标域中分离额外的源类并检测未知类。'
- en: VII-C6 Results of multi-criterion evaluation metric
  id: totrans-421
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-C6 多标准评估指标结果
- en: 'Due to the fact that we have five evaluation metrics for open set UDTL and
    universal UDTL, it is better to have a final score concerning different metrics
    for a better understanding of the result. Thus, we use Technique for Order Preference
    by Similarity to an Ideal Solution (TOPSIS), which is a famous method in the multi-criterion
    evluation metric, as the final score. Meanwhile, TOPSIS was also widely applied
    to the field of fault diagnosis[[178](#bib.bib178), [179](#bib.bib179), [180](#bib.bib180)].
    In this paper, we use $\text{ALL}^{*}$, UNK, OS, ALL, and H-score to calculate
    TOPSIS for the multi-criterion evaluation. For the sake of simplicity, the weight
    of every index is set to 0.25 in TOPSIS. As shown in Fig. [28](#S7.F28 "Figure
    28 ‣ VII-C6 Results of multi-criterion evaluation metric ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study"), we can observe
    the TOPSIS comparsions of OSBP and UAN for different transfer learning tasks.
    It is not unexpected that the evaluation using TOPSIS is similar to these metrics
    in Fig. [26](#S7.F26 "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study") and Fig. [27](#S7.F27
    "Figure 27 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study"). The overall performance also degrades
    at the later stage due to the overfitting problem and wrong feature alignment.
    The shared-class classification accuracy has a relatively large space to be promoted.
    In addition, separating extra source classes and detecting unknown classes in
    the target domain are still not well solved.'
  id: totrans-422
  prefs: []
  type: TYPE_NORMAL
  zh: '由于我们有五个评估指标用于开放集UDTL和通用UDTL，为了更好地理解结果，最好有一个关于不同指标的最终得分。因此，我们使用理想解排序技术（TOPSIS），这是一种在多标准评估指标中著名的方法，作为最终得分。同时，TOPSIS也广泛应用于故障诊断领域[[178](#bib.bib178),
    [179](#bib.bib179), [180](#bib.bib180)]。在本文中，我们使用$\text{ALL}^{*}$、UNK、OS、ALL和H-score来计算TOPSIS的多标准评估。为了简便起见，TOPSIS中每个指标的权重设为0.25。如图[28](#S7.F28
    "Figure 28 ‣ VII-C6 Results of multi-criterion evaluation metric ‣ VII-C Label-inconsistent
    UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study")所示，我们可以观察到不同转移学习任务中OSBP和UAN的TOPSIS比较。使用TOPSIS进行的评估与图[26](#S7.F26
    "Figure 26 ‣ VII-C2 Dataset settings ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative
    studies ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault
    Diagnosis: A Survey and Comparative Study")和图[27](#S7.F27 "Figure 27 ‣ VII-C2
    Dataset settings ‣ VII-C Label-inconsistent UDTL ‣ VII Comparative studies ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study")中的这些指标类似并不意外。由于过拟合问题和特征对齐错误，整体性能在后期也有所下降。共享类别分类准确度还有相对较大的提升空间。此外，额外源类别的分离和目标领域未知类别的检测仍未得到很好的解决。'
- en: '![Refer to caption](img/edd8def60ce23fbd780acf71311f74e4.png)'
  id: totrans-423
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/edd8def60ce23fbd780acf71311f74e4.png)'
- en: 'Figure 28: The TOPSIS of OSBP and UAN: (a) Best-Mean of OSBP, (b) Last-Mean
    of OSBP, (c) Best-Mean of UAN, and (d) Last-Mean of UAN.'
  id: totrans-424
  prefs: []
  type: TYPE_NORMAL
  zh: 图 28：OSBP和UAN的TOPSIS：（a）OSBP的最佳均值，（b）OSBP的最后均值，（c）UAN的最佳均值，以及（d）UAN的最后均值。
- en: VII-D Multi-domain UDTL
  id: totrans-425
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VII-D 多领域UDTL
- en: For multi-domain UDTL, the evaluation metrics are the same as that of label-consistent
    UDTL, including Last-Mean, Last-Max, Best-mean, and Best-Max.
  id: totrans-426
  prefs: []
  type: TYPE_NORMAL
  zh: 对于多领域UDTL，评估指标与标签一致UDTL相同，包括最后均值、最后最大值、最佳均值和最佳最大值。
- en: VII-D1 Dataset settings
  id: totrans-427
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-D1 数据集设置
- en: 'Similarity to label-inconsistent UDTL, CWRU is selected to test the performance
    of multi-domain UDTL, including MS-UADA and IAN. The types of inputs consist of
    the time and frequency domain inputs. The fault diagnosis tasks for multi-domain
    UDTL are listed in Table [VIII](#S7.T8 "TABLE VIII ‣ VII-D1 Dataset settings ‣
    VII-D Multi-domain UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"). For example, 123-0_T means that task 1, 2, and 3 (shown in Table [III](#S6.T3
    "TABLE III ‣ VI-A1 Case Western Reserve University (CWRU) dataset ‣ VI-A Open
    source Datasets ‣ VI Datasets ‣ Applications of Unsupervised Deep Transfer Learning
    to Intelligent Fault Diagnosis: A Survey and Comparative Study")) are used as
    multiple source domains; task 0 is used as the target domain; the time domain
    input is used as the model input. It should be mentioned that we do not use the
    target data in the training phase when testing the performance of DG.'
  id: totrans-428
  prefs: []
  type: TYPE_NORMAL
  zh: 类似于标签不一致的 UDTL，CWRU 被选用于测试多领域 UDTL 的性能，包括 MS-UADA 和 IAN。输入类型包括时间域和频率域输入。多领域
    UDTL 的故障诊断任务列在表 [VIII](#S7.T8 "TABLE VIII ‣ VII-D1 数据集设置 ‣ VII-D 多领域 UDTL ‣ VII
    比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究") 中。例如，123-0_T 表示任务 1、2 和 3（如表 [III](#S6.T3
    "TABLE III ‣ VI-A1 Case Western Reserve University (CWRU) 数据集 ‣ VI-A 开源数据集 ‣ VI
    数据集 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究") 中所示）作为多个源领域；任务 0 作为目标领域；时间域输入作为模型输入。应提到的是，在测试
    DG 性能时，我们不使用目标数据进行训练。
- en: 'TABLE VIII: The task of multi-domain UDTL.'
  id: totrans-429
  prefs: []
  type: TYPE_NORMAL
  zh: '表 VIII: 多领域 UDTL 的任务。'
- en: '| Task | Source 1 | Source 2 | Source 3 | Target |'
  id: totrans-430
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 来源 1 | 来源 2 | 来源 3 | 目标 |'
- en: '| --- | --- | --- | --- | --- |'
  id: totrans-431
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- |'
- en: '| 012-3 | 0 | 1 | 2 | 3 |'
  id: totrans-432
  prefs: []
  type: TYPE_TB
  zh: '| 012-3 | 0 | 1 | 2 | 3 |'
- en: '| 123-0 | 1 | 2 | 3 | 0 |'
  id: totrans-433
  prefs: []
  type: TYPE_TB
  zh: '| 123-0 | 1 | 2 | 3 | 0 |'
- en: '| 013-2 | 0 | 1 | 3 | 2 |'
  id: totrans-434
  prefs: []
  type: TYPE_TB
  zh: '| 013-2 | 0 | 1 | 3 | 2 |'
- en: '| 230-1 | 2 | 3 | 0 | 1 |'
  id: totrans-435
  prefs: []
  type: TYPE_TB
  zh: '| 230-1 | 2 | 3 | 0 | 1 |'
- en: '![Refer to caption](img/9a79db5c78859bdddb61caa2da2e5fb2.png)'
  id: totrans-436
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/9a79db5c78859bdddb61caa2da2e5fb2.png)'
- en: 'Figure 29: The overall accuracy of multi-domain UDTL (F and T mean the time
    domain and the frequency domain inputs, respectively): (a) Best-Mean, (b) Last-Mean.'
  id: totrans-437
  prefs: []
  type: TYPE_NORMAL
  zh: '图 29: 多领域 UDTL 的总体准确性（F 和 T 分别表示时间域和频率域输入）：(a) 最佳均值，(b) 最后均值。'
- en: VII-D2 Results of multi-domain adaptation
  id: totrans-438
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-D2 多领域适应的结果
- en: 'As shown in Fig. [29](#S7.F29 "Figure 29 ‣ VII-D1 Dataset settings ‣ VII-D
    Multi-domain UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep
    Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study")
    (a) and (b), we can observe that MS-UADA can always improve the accuracy of CWRU
    compared with Basis which directly transfers the trained model using multiple
    source domains to the target domain. Performance of the time domain input is slightly
    better than that of the frequency domain input, but the overall difference is
    very tiny.'
  id: totrans-439
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [29](#S7.F29 "Figure 29 ‣ VII-D1 数据集设置 ‣ VII-D 多领域 UDTL ‣ VII 比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    (a) 和 (b) 所示，我们可以观察到，与直接将经过训练的模型从多个源领域迁移到目标领域的 Basis 相比，MS-UADA 始终可以提高 CWRU 的准确性。时间域输入的性能稍好于频率域输入，但总体差异非常微小。
- en: VII-D3 Results of DG
  id: totrans-440
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: VII-D3 DG 的结果
- en: 'As shown in Fig. [29](#S7.F29 "Figure 29 ‣ VII-D1 Dataset settings ‣ VII-D
    Multi-domain UDTL ‣ VII Comparative studies ‣ Applications of Unsupervised Deep
    Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study")
    (a) and (b), we can observe that the performance of IAN for CWRU is similar to
    that of Basis in most tasks. However, for the task 012-3_F, the accuracy of IAN
    decreases greatly. The main reason might be that IAN only uses multiple sources
    to find the domain-invariant features, which is not suitable for the unseen target
    domain. Thus, more complex DG methods should be further designed to dig the discriminative
    and domain-invariant features.'
  id: totrans-441
  prefs: []
  type: TYPE_NORMAL
  zh: 如图 [29](#S7.F29 "Figure 29 ‣ VII-D1 数据集设置 ‣ VII-D 多领域 UDTL ‣ VII 比较研究 ‣ 无监督深度迁移学习在智能故障诊断中的应用：调查与比较研究")
    (a) 和 (b) 所示，我们可以观察到，IAN 对于 CWRU 的性能在大多数任务中与 Basis 相似。然而，对于任务 012-3_F，IAN 的准确性大幅下降。主要原因可能是
    IAN 仅使用多个来源来寻找领域不变特征，这不适用于未见过的目标领域。因此，应进一步设计更复杂的 DG 方法来挖掘判别性和领域不变的特征。
- en: VIII Further discussions
  id: totrans-442
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: VIII 进一步讨论
- en: VIII-A Transferability of features
  id: totrans-443
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-A 特征的可迁移性
- en: The reason why DL models embedded transfer learning methods can achieve breakthrough
    performance in computer vision is that many studies have shown and proved that
    DL models can learn more transferable features for these tasks than traditional
    hand-crafted features [[181](#bib.bib181), [182](#bib.bib182)]. In spite of the
    ability to learn general and transferable features, DL models also exist transition
    from general features to specific features and their transferability drops significantly
    in the last layers [[182](#bib.bib182)]. Therefore, fine-tuning DL models or adding
    various transfer learning strategies into the training process need to be investigated
    for realizing the valid transfer.
  id: totrans-444
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习（DL）模型嵌入的迁移学习方法能够在计算机视觉中取得突破性性能的原因是，许多研究已经显示并证明DL模型可以为这些任务学习到比传统手工设计特征更具可迁移性的特征[[181](#bib.bib181),
    [182](#bib.bib182)]。尽管具备学习一般性和可迁移特征的能力，DL模型在最后几层中也存在从一般特征到特定特征的过渡，其可迁移性显著下降[[182](#bib.bib182)]。因此，需要研究对DL模型进行微调或在训练过程中添加各种迁移学习策略，以实现有效的迁移。
- en: However, for IFD, there is no research about how transferable are features in
    DL models, and actually, answering this problem is the most important cornerstone
    in UDTL-based IFD. Since the aim of this paper is to give a comparative accuracy
    and release a code library, we just assume that the bottleneck layer is the task-specific
    layer and its output features are restrained with various transfer learning strategies.
    Thus, it is imperative and vital for scholars to study transferability of features
    and answer the question about how transferable features are learned. In order
    to make transferability of features more reasonable, we suggest that scholars
    might need to visualize neurons to analyze learned features by existing visualization
    algorithms [[183](#bib.bib183), [184](#bib.bib184)].
  id: totrans-445
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于IFD，目前尚无关于深度学习（DL）模型中特征可迁移性的研究，实际上，回答这个问题是基于UDTL的IFD中的最重要的基础。由于本文的目标是提供比较准确性并发布代码库，我们仅假设瓶颈层是任务特定的层，其输出特征受到各种迁移学习策略的约束。因此，学者们研究特征的迁移性并回答特征的可迁移性问题是迫切而重要的。为了使特征的迁移性更具合理性，我们建议学者们可能需要通过现有的可视化算法[[183](#bib.bib183),
    [184](#bib.bib184)]可视化神经元以分析学习到的特征。
- en: VIII-B Influence of backbones and bottleneck
  id: totrans-446
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-B 主干网和瓶颈的影响
- en: In the field of computer vision, many strong CNN models (also called backbones),
    such as VGG [[24](#bib.bib24)] and ResNet [[25](#bib.bib25)] can be extended without
    caring about the model selection. Scholars often use the same backbones to test
    the performance of proposed algorithms and can pay more attention to construct
    specific algorithms to align source and target domains.
  id: totrans-447
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉领域，许多强大的CNN模型（也称为主干网），如VGG [[24](#bib.bib24)] 和 ResNet [[25](#bib.bib25)]，可以在不考虑模型选择的情况下进行扩展。学者们通常使用相同的主干网来测试提出算法的性能，并可以更多地关注于构建特定的算法以对齐源域和目标域。
- en: However, backbones of published UDTL-based IFD are often different, which makes
    results hard to compare directly, and influence of different backbones has never
    been studied thoroughly. Whereas, backbones of UDTL-based algorithms do have a
    huge impact on results from comparisons between CWRU with the frequency domain
    input and “Table II” in [[111](#bib.bib111)] (the main difference is the backbone
    used in this paper and [[111](#bib.bib111)]). We can observe that the accuracy
    related to the task 3 in CWRU with the frequency domain input is much worse than
    that in “Table II” [[111](#bib.bib111)]. However, the backbone used in this paper
    can achieve excellent results with the time domain input and some accuracies are
    even higher than those in [[111](#bib.bib111)].
  id: totrans-448
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，已发布的基于UDTL的IFD的主干网往往不同，这使得结果难以直接比较，而不同主干网的影响从未被彻底研究。然而，UDTL算法的主干网确实对CWRU与频域输入的比较结果以及“表
    II”[[111](#bib.bib111)]（主要区别在于本文使用的主干网与[[111](#bib.bib111)]中的主干网）有巨大的影响。我们可以观察到，CWRU中与频域输入相关的任务3的准确性远低于“表
    II”[[111](#bib.bib111)]中的准确性。然而，本文使用的主干网能够在时域输入下取得优异的结果，某些准确性甚至高于[[111](#bib.bib111)]中的结果。
- en: 'To make a stronger statement, we also use the well-known backbone called ResNet18
    (we modify the structure of ResNet18 to adapt one dimensional input) to test SEU
    and PHM2009 datasets for explaining the huge impact of backbones. From comparisons
    of PHM2009 shown in Fig. [30](#S8.F30 "Figure 30 ‣ VIII-B Influence of backbones
    and bottleneck ‣ VIII Further discussions ‣ Applications of Unsupervised Deep
    Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study"),
    ResNet18 can improve the accuracy of each algorithm significantly. Besides, from
    comparisons of SEU shown in Fig. [31](#S8.F31 "Figure 31 ‣ VIII-B Influence of
    backbones and bottleneck ‣ VIII Further discussions ‣ Applications of Unsupervised
    Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative
    Study"), ResNet18 with the time domain input actually reduces the accuracy, and
    on the contrary, ResNet18 with the frequency domain input improve the accuracy
    significantly. In summary, different backbones behave differently with variant
    datasets and input types.'
  id: totrans-449
  prefs: []
  type: TYPE_NORMAL
  zh: '为了做出更强的声明，我们还使用了一个知名的主干网络，称为 ResNet18（我们修改了 ResNet18 的结构以适应一维输入），来测试 SEU 和
    PHM2009 数据集，以解释主干网络的巨大影响。从图 [30](#S8.F30 "Figure 30 ‣ VIII-B Influence of backbones
    and bottleneck ‣ VIII Further discussions ‣ Applications of Unsupervised Deep
    Transfer Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study")
    显示的 PHM2009 比较中，ResNet18 可以显著提高每个算法的准确性。此外，从图 [31](#S8.F31 "Figure 31 ‣ VIII-B
    Influence of backbones and bottleneck ‣ VIII Further discussions ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study") 显示的 SEU 比较中，使用时间域输入的 ResNet18 实际上降低了准确性，相反，使用频域输入的 ResNet18
    显著提高了准确性。总之，不同的主干网络在不同的数据集和输入类型下表现不同。'
- en: '![Refer to caption](img/53d413f94616df13422020ae0569d31a.png)'
  id: totrans-450
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/53d413f94616df13422020ae0569d31a.png)'
- en: 'Figure 30: Comparisons of PHM2009.'
  id: totrans-451
  prefs: []
  type: TYPE_NORMAL
  zh: '图 30: PHM2009 的比较。'
- en: '![Refer to caption](img/8ecf1b6d4fabd6b5f5ee677bdbd46365.png)'
  id: totrans-452
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8ecf1b6d4fabd6b5f5ee677bdbd46365.png)'
- en: 'Figure 31: Comparisons of SEU.'
  id: totrans-453
  prefs: []
  type: TYPE_NORMAL
  zh: '图 31: SEU 的比较。'
- en: Therefore, finding a strong and suitable backbone, which can learn more transferable
    features for IFD, is also very important for UDTL-based methods (sometimes choosing
    a more effective backbone is even more important than using a more advanced algorithm)
    We suggest that scholars should first find a strong backbone and then use the
    same backbone to compare results for avoiding unfair comparisons.
  id: totrans-454
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，寻找一个强大且适合的主干网络，这样它可以为 IFD 学习到更多可迁移的特征，对基于 UDTL 的方法也非常重要（有时选择一个更有效的主干网络甚至比使用更先进的算法更重要）。我们建议学者们首先找到一个强大的主干网络，然后使用相同的主干网络来比较结果，以避免不公平的比较。
- en: In the top comparsion, we discuss the influence of backbones. However, in our
    designed structure, the bottleneck layer in the source domain also shares parameters
    with that in the target domain. Thus, it is necessary to discuss the influence
    of the bottleneck layer during the transfer learning procedure. For the sake of
    simplicity, we only use CWRU with two different inputs to test two representative
    UDTL methods, including MK-MMD and DANN.
  id: totrans-455
  prefs: []
  type: TYPE_NORMAL
  zh: 在顶部的比较中，我们讨论了主干网络的影响。然而，在我们设计的结构中，源域中的瓶颈层也与目标域中的瓶颈层共享参数。因此，有必要讨论在迁移学习过程中瓶颈层的影响。为了简单起见，我们只使用
    CWRU 的两个不同输入来测试两个代表性的 UDTL 方法，包括 MK-MMD 和 DANN。
- en: 'We use Type I to represent original models in this paper, Type II to represent
    models without the bottleneck layer, and Type III to represent models with fixed
    parameters of backbones (their parameters are pretrained by the source data) when
    starting transfer learning (only updating parameters of the bottleneck layer during
    the transfer learning procedure). The comparison results are shown in Fig. [32](#S8.F32
    "Figure 32 ‣ VIII-B Influence of backbones and bottleneck ‣ VIII Further discussions
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study"). We can observe that for the time domain input,
    it is almost the same with and without the bottleneck layer. Likewise, for the
    frequency domain input, it is also difficult to judge which one is better. Thus,
    choosing a suitable network (according to datasets, transfer learning methods,
    input types, etc.), which can learn more transferable features, is very important
    for UDTL-based methods. In addition, it is clear that when parameters of backbones
    are fixed during the transfer learning procedure, the accuracy in the target domain
    decreases dramatically, which means that backbones trained using the source data
    cannot be transferred directly to the target domain.'
  id: totrans-456
  prefs: []
  type: TYPE_NORMAL
  zh: 本文中我们用类型 I 表示原始模型，用类型 II 表示没有瓶颈层的模型，用类型 III 表示在开始迁移学习时具有固定骨干网络参数的模型（其参数由源数据预训练，仅在迁移学习过程中更新瓶颈层参数）。比较结果如图
    [32](#S8.F32 "图 32 ‣ VIII-B 骨干网络和瓶颈层的影响 ‣ VIII 进一步讨论 ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")
    所示。我们可以观察到，对于时间域输入，有无瓶颈层几乎没有区别。同样，对于频域输入，也很难判断哪种更好。因此，选择合适的网络（根据数据集、迁移学习方法、输入类型等），以学习更多可迁移特征，对于基于
    UDTL 的方法非常重要。此外，显然，当迁移学习过程中骨干网络的参数固定时，目标领域的准确性显著下降，这意味着使用源数据训练的骨干网络不能直接迁移到目标领域。
- en: '![Refer to caption](img/c260a2a4f237283f05410244198f1cd8.png)'
  id: totrans-457
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c260a2a4f237283f05410244198f1cd8.png)'
- en: 'Figure 32: Comparisons of three conditions related to the bottleneck layer.'
  id: totrans-458
  prefs: []
  type: TYPE_NORMAL
  zh: 图 32：与瓶颈层相关的三种条件比较。
- en: VIII-C Negative transfer
  id: totrans-459
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-C 负迁移
- en: 'As we discussed in Section [IV](#S4 "IV Label-inconsistent UDTL ‣ Applications
    of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis: A Survey
    and Comparative Study"), there are mainly four kinds of scenarios of UDTL-based
    IFD, but all experiments with five datasets are about transfer between different
    working conditions. To state that these scenarios are not always suitable for
    generating the positive transfer, we use the PU dataset to design another transfer
    task considering the transfer between different methods of generating damages.
    Each task consists of three health conditions, and detailed information is listed
    in Table [IX](#S8.T9 "TABLE IX ‣ VIII-C Negative transfer ‣ VIII Further discussions
    ‣ Applications of Unsupervised Deep Transfer Learning to Intelligent Fault Diagnosis:
    A Survey and Comparative Study"). There are two transfer learning settings in
    total.'
  id: totrans-460
  prefs: []
  type: TYPE_NORMAL
  zh: 正如我们在第 [IV](#S4 "IV 标签不一致的 UDTL ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究") 节中讨论的那样，基于
    UDTL 的 IFD 主要有四种场景，但所有五个数据集的实验都是关于不同工作条件之间的迁移。为了说明这些场景并不总是适合生成正向迁移，我们使用 PU 数据集设计了另一个迁移任务，考虑不同的损伤生成方法之间的迁移。每个任务包含三种健康状态，详细信息列在表
    [IX](#S8.T9 "表 IX ‣ VIII-C 负迁移 ‣ VIII 进一步讨论 ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究") 中。总共有两种迁移学习设置。
- en: 'TABLE IX: The information of bearings with artificial damages.'
  id: totrans-461
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IX：带有人为损伤的轴承信息。
- en: '| Task | Precast Method | Damage Location | Damage Extent | Bearing Code |
    Label |'
  id: totrans-462
  prefs: []
  type: TYPE_TB
  zh: '| 任务 | 预制方法 | 损伤位置 | 损伤程度 | 轴承编码 | 标签 |'
- en: '| --- | --- | --- | --- | --- | --- |'
  id: totrans-463
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- | --- | --- | --- | --- |'
- en: '| 0 | Electric Engraver | OR | 1 | KA05 | 0 |'
  id: totrans-464
  prefs: []
  type: TYPE_TB
  zh: '| 0 | 电动雕刻机 | OR | 1 | KA05 | 0 |'
- en: '| Electric Engraver | OR | 2 | KA03 | 1 |'
  id: totrans-465
  prefs: []
  type: TYPE_TB
  zh: '| 电动雕刻机 | OR | 2 | KA03 | 1 |'
- en: '| Electric Engraver | IR | 1 | KI03 | 2 |'
  id: totrans-466
  prefs: []
  type: TYPE_TB
  zh: '| 电动雕刻机 | IR | 1 | KI03 | 2 |'
- en: '| 1 | EDM and Drilling | OR | 1 | KA01 and KA07 | 0 |'
  id: totrans-467
  prefs: []
  type: TYPE_TB
  zh: '| 1 | EDM 和钻孔 | OR | 1 | KA01 和 KA07 | 0 |'
- en: '| Drilling | OR | 2 | KA08 | 1 |'
  id: totrans-468
  prefs: []
  type: TYPE_TB
  zh: '| 钻孔 | OR | 2 | KA08 | 1 |'
- en: '| EDM | IR | 1 | KI01 | 2 |'
  id: totrans-469
  prefs: []
  type: TYPE_TB
  zh: '| EDM | IR | 1 | KI01 | 2 |'
- en: 'The transfer results are shown in Fig. [33](#S8.F33 "Figure 33 ‣ VIII-C Negative
    transfer ‣ VIII Further discussions ‣ Applications of Unsupervised Deep Transfer
    Learning to Intelligent Fault Diagnosis: A Survey and Comparative Study") and
    Appendix A called PU-Types. We can observe that each method has a negative transfer
    with the time or frequency domain inputs, and this phenomenon indicates that this
    constructed task may not be suitable for the transfer learning task. Actually,
    there are also some published papers designing transfer learning tasks which tackle
    transferring the gear samples to the bearing samples (it may not be a reliable
    transfer task) or transferring the experimental data to the real data (if structures
    of two machines are different, it also may not be a reliable transfer task). Thus,
    it is very important to first figure out whether this task is suitable for transfer
    learning and whether two domains do have shared features.'
  id: totrans-470
  prefs: []
  type: TYPE_NORMAL
  zh: 迁移结果如图 [33](#S8.F33 "图 33 ‣ VIII-C 负迁移 ‣ VIII 进一步讨论 ‣ 无监督深度迁移学习在智能故障诊断中的应用：综述与比较研究")
    和附录 A 中所示的 PU-Types。我们可以观察到，每种方法在时域或频域输入下都有负迁移，这表明构建的任务可能不适合迁移学习任务。实际上，还有一些已发表的论文设计了迁移学习任务，这些任务处理将齿轮样本迁移到轴承样本（这可能不是一个可靠的迁移任务）或将实验数据迁移到实际数据（如果两台机器的结构不同，这也可能不是一个可靠的迁移任务）。因此，首先弄清楚这个任务是否适合迁移学习以及两个领域是否确实具有共享特征是非常重要的。
- en: '![Refer to caption](img/c2e56b5cf2d1b4abd204927664c38663.png)'
  id: totrans-471
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/c2e56b5cf2d1b4abd204927664c38663.png)'
- en: 'Figure 33: The accuracy biases of these five methods corresponding to Basis.
    (F) means the frequency domain input, and (T) means the time domain input.'
  id: totrans-472
  prefs: []
  type: TYPE_NORMAL
  zh: 图 33：这五种方法在 Basis 下的准确率偏差。（F）表示频域输入，（T）表示时域输入。
- en: VIII-D Physical priors
  id: totrans-473
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-D 物理先验
- en: In the field of computer vision and natural language processing, new transfer
    learning methods often use the existing knowledge or laws to provide a meaningful
    explanation, such as attention mechanism [[185](#bib.bib185)] and multi-modal
    structures [[107](#bib.bib107)].
  id: totrans-474
  prefs: []
  type: TYPE_NORMAL
  zh: 在计算机视觉和自然语言处理领域，新的迁移学习方法通常利用现有的知识或规律来提供有意义的解释，例如注意力机制 [[185](#bib.bib185)] 和多模态结构
    [[107](#bib.bib107)]。
- en: However, for UDTL-based IFD, many scholars only introduce methods, which have
    already existed in other fields, to perform IFD tasks and pay less attention to
    the prior knowledge behind the data (lack of using special phenomena or rules
    in physical systems). Therefore, we suggest that scholars can learn from core
    ideas in the field of transfer learning (not just use the existing methods) and
    introduce prior knowledge of physical systems into the proposed method to construct
    more targeted and suitable diagnostic models with higher recognition rates in
    industrial applications.
  id: totrans-475
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，对于基于 UDTL 的 IFD，许多学者仅仅引入了在其他领域已经存在的方法来执行 IFD 任务，而较少关注数据背后的先验知识（缺乏利用物理系统中的特殊现象或规则）。因此，我们建议学者可以借鉴迁移学习领域的核心思想（不仅仅是使用现有方法），并将物理系统的先验知识引入所提出的方法中，以构建在工业应用中具有更高识别率的更有针对性和适用的诊断模型。
- en: VIII-E Label-inconsistent transfer
  id: totrans-476
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-E 标签不一致的迁移
- en: Recently, some scholars have considered the label-inconsistent scenario and
    proposed some specific methods to allow the model to adapt to this situation (detailed
    references can be found in the above review). However, as discussed in comparative
    results of label-inconsistent transfer, selected methods often face the risk of
    overfitting. That is, although the best average accuracy is acceptable, the last
    average accuracy often has a big drop. The main reason might be that models cannot
    focus on shared classes effectively, leading to poor domain alignment.
  id: totrans-477
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，一些学者考虑了标签不一致的情况，并提出了一些具体的方法，以便模型能够适应这种情况（详细参考文献可以在上述综述中找到）。然而，正如在标签不一致迁移的比较结果中所讨论的，所选方法往往面临过拟合的风险。也就是说，尽管最佳的平均准确率可以接受，但最后的平均准确率通常会大幅下降。主要原因可能是模型无法有效地专注于共享类别，导致领域对齐较差。
- en: Hence, more attention should be paid to the label-inconsistent scenario to realize
    effective extra source classes separation and unknown classes detection from the
    target domain. A possible solution is to combine other valid open set recognition
    algorithms for better unknown class detection [[186](#bib.bib186), [150](#bib.bib150)].
    For example, an EVT model using deep features of source samples, was applied to
    detect unknown-class samples [[150](#bib.bib150)].
  id: totrans-478
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，应更多关注标签不一致的情况，以实现有效的额外源类分离和目标领域中的未知类检测。一个可能的解决方案是结合其他有效的开放集识别算法，以更好地检测未知类[[186](#bib.bib186),
    [150](#bib.bib150)]。例如，使用源样本深度特征的EVT模型被应用于检测未知类别样本[[150](#bib.bib150)]。
- en: VIII-F Multi-domain transfer
  id: totrans-479
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-F 多领域迁移
- en: Most of published papers are based on a single source domain, but in real applications,
    the labeled data might be from multiple source domains. These domains often follow
    different distributions, but shared or related features exist among multiple source
    domains. A common step is to align the shared features via multi-domain adaptation
    or DG. However, how to balance contributions of multiple source domains is still
    not well solved. For example, in comparative analysis, we simply assume that each
    domain contributes equally to transfer learning. Thus, suitable weights should
    be carefully designed and added into the process of multi-domain transfer.
  id: totrans-480
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数已发布的论文都基于单一源领域，但在实际应用中，标记数据可能来自多个源领域。这些领域通常遵循不同的分布，但多个源领域之间存在共享或相关的特征。一个常见的步骤是通过多领域适应或DG来对齐共享特征。然而，如何平衡多个源领域的贡献仍未得到很好解决。例如，在比较分析中，我们简单地假设每个领域对迁移学习的贡献是相等的。因此，适当的权重应该被仔细设计并加入到多领域迁移的过程中。
- en: Additionally, to make better use of some data in unlabeled source domains, semi-supervised
    multi-domain learning [[165](#bib.bib165)] might also be worth focusing on. To
    further improve the accuracy, minimizing the gap of conditional distributions
    might be an effective way to align shared features [[167](#bib.bib167), [163](#bib.bib163)].
  id: totrans-481
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，为了更好地利用某些未标记源领域中的数据，*半监督多领域学习*[[165](#bib.bib165)]也值得关注。为了进一步提高准确性，最小化条件分布的差距可能是对齐共享特征的有效方法[[167](#bib.bib167),
    [163](#bib.bib163)]。
- en: VIII-G Other aspects
  id: totrans-482
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: VIII-G 其他方面
- en: Although a large amount of data in different conditions can be collected, fault
    data in some conditions are still scarce. Due to the fact that most machines operate
    in a normal condition, the class-imbalanced problem often naturally exists in
    real applications. Thus, imbalanced learning or few shot learning combined with
    transfer learning methods [[187](#bib.bib187)] might also be an important direction
    for better getting constructed algorithms off the ground.
  id: totrans-483
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管可以收集到大量不同条件下的数据，但某些条件下的故障数据仍然稀缺。由于大多数机器在正常条件下运行，因此类不平衡问题在实际应用中往往自然存在。因此，结合迁移学习方法的*不平衡学习*或*少样本学习*[[187](#bib.bib187)]也可能是使构建的算法更好地发挥作用的重要方向。
- en: Federated transfer learning (FTL) [[188](#bib.bib188)] provides a safer and
    more reliable approach for specific industries. At the same time, based on characteristics
    of transfer learning, FTL participants can own their own feature space without
    requiring all participants to own or use the same feature data, which makes FTL
    suitable for more application scenarios. FTL was initially used in IFD [[189](#bib.bib189)]
    and more in-depth research is required.
  id: totrans-484
  prefs: []
  type: TYPE_NORMAL
  zh: 联邦迁移学习（FTL）[[188](#bib.bib188)]为特定行业提供了更安全、更可靠的方法。同时，基于迁移学习的特性，FTL参与者可以拥有自己的特征空间，而不需要所有参与者拥有或使用相同的特征数据，这使得FTL适用于更多的应用场景。FTL最初在IFD中使用[[189](#bib.bib189)]，需要更多深入的研究。
- en: Uncertainty quantification plays a critical role in assessing the safety of
    DL models during construction, optimization, and decision making procedures. Bayesian
    networks [[190](#bib.bib190)] and ensemble learning techniques [[191](#bib.bib191)]
    are two widely-used uncertainty quantification methods, and their effectiveness
    has been verified by different kinds of applications, such as bioinformatics,
    self-driving car, etc. Thus, uncertainty as an auxiliary term can be used to further
    correct some inappropriate predictions or results during the transfer learning.
    For example, the prediction uncertainty is explicitly estimated during training
    to rectify the pseudo label learning for UDTL of semantic segmentation [[192](#bib.bib192)].
  id: totrans-485
  prefs: []
  type: TYPE_NORMAL
  zh: 不确定性量化在评估 DL 模型在构建、优化和决策过程中的安全性方面起着关键作用。贝叶斯网络 [[190](#bib.bib190)] 和集成学习技术 [[191](#bib.bib191)]
    是两种广泛使用的不确定性量化方法，其有效性已通过各种应用得到验证，例如生物信息学、自动驾驶等。因此，不确定性作为辅助项可以用于进一步纠正转移学习中的一些不适当预测或结果。例如，在训练过程中显式估计预测不确定性，以修正
    UDTL 语义分割的伪标签学习 [[192](#bib.bib192)]。
- en: IX Conclusion
  id: totrans-486
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IX 结论
- en: In this paper, we construct a new taxonomy and perform a comprehensive review
    of UDTL-based IFD according to different tasks of UDTL. Five publicly available
    datasets are gathered to perform a comparative analysis of different UDTL-based
    IFD methods from several perspectives. Based on the systematically comparative
    study, we conclude that some useful results might be helpful for further research.
    Firstly, the accuracy of CWRU and JNU is larger than 95%. Secondly, results of
    different methods indicate that the assumption of joint distributions and adversarial
    training are two helpful techniques for promoting the accuracy. Thirdly, different
    input types often behave differently on each dataset, and choosing a suitable
    input type might also be important to improve the accuracy. Finally, the stability
    and robustness of UDTL-based IFD need to be taken seriously. To sum up, it might
    be useful for scholars to think ahead of these results before developing new models.
  id: totrans-487
  prefs: []
  type: TYPE_NORMAL
  zh: 在本文中，我们构建了一个新的分类法，并根据不同的 UDTL 任务对基于 UDTL 的 IFD 进行了全面的回顾。收集了五个公开的数据集，从多个角度对不同的基于
    UDTL 的 IFD 方法进行了比较分析。基于系统的比较研究，我们得出了一些有用的结果，这些结果可能对进一步的研究有帮助。首先，CWRU 和 JNU 的准确率超过了
    95%。其次，不同方法的结果表明，联合分布的假设和对抗训练是提升准确率的两种有用技术。第三，不同的输入类型在每个数据集上的表现通常不同，选择合适的输入类型可能也对提高准确率很重要。最后，基于
    UDTL 的 IFD 的稳定性和鲁棒性需要引起重视。总而言之，对于学者来说，在开发新模型之前考虑这些结果可能是有用的。
- en: Also, we release the code library at [https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL)
    and try to give a basic performance of current algorithms to find the core that
    determines the transfer performance of algorithms to guide future research.
  id: totrans-488
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，我们在 [https://github.com/ZhaoZhibin/UDTL](https://github.com/ZhaoZhibin/UDTL)
    发布了代码库，并尝试提供当前算法的基本性能，以寻找决定算法传递性能的核心，指导未来的研究。
- en: References
  id: totrans-489
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: '[1] Pavan Kumar Kankar, Satish C Sharma, and Suraj Prakash Harsha, “Fault diagnosis
    of ball bearings using machine learning methods,” Expert Systems with applications,
    vol. 38, no. 3, pp. 1876–1886, 2011.'
  id: totrans-490
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[1] Pavan Kumar Kankar, Satish C Sharma 和 Suraj Prakash Harsha，“基于机器学习方法的球轴承故障诊断”，专家系统与应用，第
    38 卷，第 3 期，第 1876–1886 页，2011 年。'
- en: '[2] Mariela Cerrada, Grover Zurita, Diego Cabrera, René-Vinicio Sánchez, Mariano
    Artés, and Chuan Li, “Fault diagnosis in spur gears based on genetic algorithm
    and random forest,” Mechanical Systems and Signal Processing, vol. 70, pp. 87–103,
    2016.'
  id: totrans-491
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[2] Mariela Cerrada, Grover Zurita, Diego Cabrera, René-Vinicio Sánchez, Mariano
    Artés 和 Chuan Li，“基于遗传算法和随机森林的斜齿轮故障诊断”，机械系统与信号处理，第 70 卷，第 87–103 页，2016 年。'
- en: '[3] Achmad Widodo and Bo-Suk Yang, “Support vector machine in machine condition
    monitoring and fault diagnosis,” Mechanical systems and signal processing, vol.
    21, no. 6, pp. 2560–2574, 2007.'
  id: totrans-492
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[3] Achmad Widodo 和 Bo-Suk Yang，“支持向量机在机器状态监测和故障诊断中的应用”，机械系统与信号处理，第 21 卷，第
    6 期，第 2560–2574 页，2007 年。'
- en: '[4] Chaowei Tong, Shibin Wang, Ivan Selesnick, Ruqiang Yan, and Xuefeng Chen,
    “Ridge-aware weighted sparse time-frequency representation,” IEEE Transactions
    on Signal Processing, vol. 69, pp. 136–149, 2020.'
  id: totrans-493
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[4] Chaowei Tong, Shibin Wang, Ivan Selesnick, Ruqiang Yan 和 Xuefeng Chen，“基于脊的加权稀疏时频表示”，IEEE
    信号处理学报，第 69 卷，第 136–149 页，2020 年。'
- en: '[5] Zhibin Zhao, Shuming Wu, Baijie Qiao, Shibin Wang, and Xuefeng Chen, “Enhanced
    sparse period-group lasso for bearing fault diagnosis,” IEEE Transactions on Industrial
    Electronics, vol. 66, no. 3, pp. 2143–2153, 2018.'
  id: totrans-494
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[5] 赵志彬、吴书敏、乔白杰、王世斌和陈学锋，“增强的稀疏周期组套索用于轴承故障诊断，”《IEEE工业电子学报》，第66卷，第3期，第2143–2153页，2018年。'
- en: '[6] Zhibin Zhao, Shibin Wang, David Wong, Wendong Wang, Ruqiang Yan, and Xuefeng
    Chen, “Fast sparsity-assisted signal decomposition with non-convex enhancement
    for bearing fault diagnosis,” IEEE/ASME Transactions on Mechatronics, 2021.'
  id: totrans-495
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[6] 赵志彬、王世斌、黄大卫、王文栋、闫如强和陈学锋，“快速稀疏辅助信号分解与非凸增强用于轴承故障诊断，”《IEEE/ASME机电一体化学报》，2021年。'
- en: '[7] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton, “Deep learning,” nature,
    vol. 521, no. 7553, pp. 436, 2015.'
  id: totrans-496
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[7] 扬·勒昆、约书亚·本吉奥和杰弗里·辛顿，“深度学习，”《自然》，第521卷，第7553期，第436页，2015年。'
- en: '[8] Daniele Ravì, Charence Wong, Fani Deligianni, Melissa Berthelot, Javier
    Andreu-Perez, Benny Lo, and Guang-Zhong Yang, “Deep learning for health informatics,”
    IEEE journal of biomedical and health informatics, vol. 21, no. 1, pp. 4–21, 2016.'
  id: totrans-497
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[8] 达尼埃尔·拉维、查伦斯·黄、法尼·德利加尼、梅丽莎·贝尔特洛特、哈维尔·安德烈-佩雷斯、本尼·罗和杨光中，“健康信息学中的深度学习，”《IEEE生物医学与健康信息学杂志》，第21卷，第1期，第4–21页，2016年。'
- en: '[9] Seonwoo Min, Byunghan Lee, and Sungroh Yoon, “Deep learning in bioinformatics,”
    Briefings in bioinformatics, vol. 18, no. 5, pp. 851–869, 2017.'
  id: totrans-498
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[9] 闵善雨、李彪汉和尹成禄，“生物信息学中的深度学习，”《生物信息学简报》，第18卷，第5期，第851–869页，2017年。'
- en: '[10] Lei Yang, Yunfei Wang, Yanjie Guo, Weiqiang Zhang, and Zhibin Zhao, “Robust
    working mechanism of water droplet-driven triboelectric nanogenerator: Triboelectric
    output versus dynamic motion of water droplet,” Advanced Materials Interfaces,
    vol. 6, no. 24, pp. 1901547, 2019.'
  id: totrans-499
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[10] 杨磊、王云飞、郭彦杰、张伟强和赵志彬，“水滴驱动摩擦电纳米发电机的鲁棒工作机制：摩擦电输出与水滴动态运动的对比，”《先进材料界面》，第6卷，第24期，第1901547页，2019年。'
- en: '[11] Lei Yang, Yunfei Wang, Zhibin Zhao, Yanjie Guo, Sicheng Chen, Weiqiang
    Zhang, and Xiao Guo, “Particle-laden droplet-driven triboelectric nanogenerator
    for real-time sediment monitoring using a deep learning method,” ACS Applied Materials
    & Interfaces, vol. 12, no. 34, pp. 38192–38201, 2020.'
  id: totrans-500
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[11] 杨磊、王云飞、赵志彬、郭彦杰、陈思成、张伟强和郭晓，“颗粒载体液滴驱动的摩擦电纳米发电机，用于实时沉积物监测，采用深度学习方法，”《ACS应用材料与界面》，第12卷，第34期，第38192–38201页，2020年。'
- en: '[12] Haiping Zhu, Jiaxin Cheng, Cong Zhang, Jun Wu, and Xinyu Shao, “Stacked
    pruning sparse denoising autoencoder based intelligent fault diagnosis of rolling
    bearings,” Applied Soft Computing, p. 106060, 2020.'
  id: totrans-501
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[12] 朱海平、程佳欣、张聪、吴俊和邵欣宇，“基于堆叠剪枝稀疏去噪自编码器的智能滚动轴承故障诊断，”《应用软计算》，第106060页，2020年。'
- en: '[13] Wenfeng Zhang, Gautam Biswas, Qi Zhao, Hongbo Zhao, and Wenquan Feng,
    “Knowledge distilling based model compression and feature learning in fault diagnosis,”
    Applied Soft Computing, vol. 88, pp. 105958, 2020.'
  id: totrans-502
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[13] 张文峰、戈达姆·比斯瓦斯、赵琦、赵洪波和冯文全，“基于知识蒸馏的模型压缩与故障诊断特征学习，”《应用软计算》，第88卷，第105958页，2020年。'
- en: '[14] Fan Xu, Yiu Lun Tse, et al., “Roller bearing fault diagnosis using stacked
    denoising autoencoder in deep learning and gath–geva clustering algorithm without
    principal component analysis and data label,” Applied Soft Computing, vol. 73,
    pp. 898–913, 2018.'
  id: totrans-503
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[14] 徐凡、谢耀伦等，“利用堆叠去噪自编码器进行深度学习的滚动轴承故障诊断及Gath–Geva聚类算法，无需主成分分析和数据标签，”《应用软计算》，第73卷，第898–913页，2018年。'
- en: '[15] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton, “Imagenet classification
    with deep convolutional neural networks,” in Advances in neural information processing
    systems, 2012, pp. 1097–1105.'
  id: totrans-504
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[15] 亚历克斯·克里日夫斯基、伊利亚·苏茨克弗和杰弗里·E·辛顿，“使用深度卷积神经网络的ImageNet分类，”《神经信息处理系统进展》，2012年，第1097–1105页。'
- en: '[16] Andrew Ng et al., “Sparse autoencoder,” CS294A Lecture notes, vol. 72,
    no. 2011, pp. 1–19, 2011.'
  id: totrans-505
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[16] 安德鲁·吴等，“稀疏自编码器，”CS294A讲义，第72卷，第2011期，第1–19页，2011年。'
- en: '[17] Zhibin Zhao, Tianfu Li, Jingyao Wu, Chuang Sun, Shibin Wang, Ruqiang Yan,
    and Xuefeng Chen, “Deep learning algorithms for rotating machinery intelligent
    diagnosis: An open source benchmark study,” ISA transactions, vol. 107, pp. 224–255,
    2020.'
  id: totrans-506
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[17] 赵志彬、李天富、吴静瑶、孙创、王世斌、闫如强和陈学锋，“旋转机械智能诊断的深度学习算法：开源基准研究，”《ISA交易》，第107卷，第224–255页，2020年。'
- en: '[18] Huailiang Zheng, Rixin Wang, Yuantao Yang, Jiancheng Yin, Yongbo Li, Yuqing
    Li, and Minqiang Xu, “Cross-domain fault diagnosis using knowledge transfer strategy:
    a review,” IEEE Access, vol. 7, pp. 129260–129290, 2019.'
  id: totrans-507
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[18] 郑怀良、王日新、杨远涛、尹建成、李永博、李育青和徐敏强，“基于知识转移策略的跨领域故障诊断：综述，”《IEEE Access》，第7卷，第129260–129290页，2019年。'
- en: '[19] Ruqiang Yan, Fei Shen, Chuang Sun, and Xuefeng Chen, “Knowledge transfer
    for rotary machine fault diagnosis,” IEEE Sensors Journal, vol. 20, no. 15, pp.
    8374–8393, 2019.'
  id: totrans-508
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[19] Ruqiang Yan, Fei Shen, Chuang Sun, 和 Xuefeng Chen，“旋转机械故障诊断的知识转移”，IEEE
    Sensors Journal，第20卷，第15期，页8374–8393，2019年。'
- en: '[20] Yaguo Lei, Bin Yang, Xinwei Jiang, Feng Jia, Naipeng Li, and Asoke K Nandi,
    “Applications of machine learning to machine fault diagnosis: A review and roadmap,”
    Mechanical Systems and Signal Processing, vol. 138, pp. 106587, 2020.'
  id: totrans-509
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[20] Yaguo Lei, Bin Yang, Xinwei Jiang, Feng Jia, Naipeng Li, 和 Asoke K Nandi，“机器学习在机器故障诊断中的应用：综述与路线图”，Mechanical
    Systems and Signal Processing，第138卷，页106587，2020年。'
- en: '[21] Mingsheng Long, Yue Cao, Jianmin Wang, and Michael Jordan, “Learning transferable
    features with deep adaptation networks,” in International conference on machine
    learning. PMLR, 2015, pp. 97–105.'
  id: totrans-510
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[21] Mingsheng Long, Yue Cao, Jianmin Wang, 和 Michael Jordan，“通过深度适应网络学习可转移特征”，在国际机器学习会议上。PMLR，2015年，页97–105。'
- en: '[22] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang, and Chunfang
    Liu, “A survey on deep transfer learning,” in International Conference on Artificial
    Neural Networks. Springer, 2018, pp. 270–279.'
  id: totrans-511
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[22] Chuanqi Tan, Fuchun Sun, Tao Kong, Wenchang Zhang, Chao Yang, 和 Chunfang
    Liu，“深度转移学习的调查”，在人工神经网络国际会议上。Springer，2018年，页270–279。'
- en: '[23] Xiang Li, Wei Zhang, Qian Ding, and Jian-Qiao Sun, “Multi-layer domain
    adaptation method for rolling bearing fault diagnosis,” Signal Processing, vol.
    157, pp. 180–197, 2019.'
  id: totrans-512
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[23] Xiang Li, Wei Zhang, Qian Ding, 和 Jian-Qiao Sun，“用于滚动轴承故障诊断的多层领域适应方法”，Signal
    Processing，第157卷，页180–197，2019年。'
- en: '[24] Karen Simonyan and Andrew Zisserman, “Very deep convolutional networks
    for large-scale image recognition,” arXiv preprint arXiv:1409.1556, 2014.'
  id: totrans-513
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[24] Karen Simonyan 和 Andrew Zisserman，“用于大规模图像识别的非常深的卷积网络”，arXiv预印本 arXiv:1409.1556，2014年。'
- en: '[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun, “Deep residual
    learning for image recognition,” in Proceedings of the IEEE conference on computer
    vision and pattern recognition, 2016, pp. 770–778.'
  id: totrans-514
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[25] Kaiming He, Xiangyu Zhang, Shaoqing Ren, 和 Jian Sun，“用于图像识别的深度残差学习”，在IEEE计算机视觉与模式识别会议论文集中，2016年，页770–778。'
- en: '[26] Ran Zhang, Hongyang Tao, Lifeng Wu, and Yong Guan, “Transfer learning
    with neural networks for bearing fault diagnosis in changing working conditions,”
    IEEE Access, vol. 5, pp. 14347–14357, 2017.'
  id: totrans-515
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[26] Ran Zhang, Hongyang Tao, Lifeng Wu, 和 Yong Guan，“在变化工况下，利用神经网络进行轴承故障诊断的转移学习”，IEEE
    Access，第5卷，页14347–14357，2017年。'
- en: '[27] Cheng Zhang, Liqing Xu, Xingwang Li, and Huiyun Wang, “A method of fault
    diagnosis for rotary equipment based on deep learning,” in 2018 Prognostics and
    System Health Management Conference (PHM-Chongqing). IEEE, 2018, pp. 958–962.'
  id: totrans-516
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[27] Cheng Zhang, Liqing Xu, Xingwang Li, 和 Huiyun Wang，“基于深度学习的旋转设备故障诊断方法”，发表于2018年预测与系统健康管理会议（PHM-Chongqing）。IEEE，2018年，页958–962。'
- en: '[28] Danmin Chen, Shuai Yang, and Funa Zhou, “Incipient fault diagnosis based
    on dnn with transfer learning,” in 2018 International Conference on Control, Automation
    and Information Sciences (ICCAIS). IEEE, 2018, pp. 303–308.'
  id: totrans-517
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[28] Danmin Chen, Shuai Yang, 和 Funa Zhou，“基于DNN与转移学习的初期故障诊断”，在2018年控制、自动化与信息科学国际会议（ICCAIS）上。IEEE，2018年，页303–308。'
- en: '[29] Md Junayed Hasan, Muhammad Sohaib, and Jong-Myon Kim, “1d cnn-based transfer
    learning model for bearing fault diagnosis under variable working conditions,”
    in International Conference on Computational Intelligence in Information System.
    Springer, 2018, pp. 13–23.'
  id: totrans-518
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[29] Md Junayed Hasan, Muhammad Sohaib, 和 Jong-Myon Kim，“基于1d cnn的转移学习模型用于变工况下的轴承故障诊断”，在计算智能信息系统国际会议上。Springer，2018年，页13–23。'
- en: '[30] Hyunjae Kim and Byeng D Youn, “A new parameter repurposing method for
    parameter transfer with small dataset and its application in fault diagnosis of
    rolling element bearings,” IEEE Access, vol. 7, pp. 46917–46930, 2019.'
  id: totrans-519
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[30] Hyunjae Kim 和 Byeng D Youn，“一种新的参数重用方法用于小数据集的参数转移及其在滚动元素轴承故障诊断中的应用”，IEEE
    Access，第7卷，页46917–46930，2019年。'
- en: '[31] Md Junayed Hasan, MM Manjurul Islam, and Jong-Myon Kim, “Acoustic spectral
    imaging and transfer learning for reliable bearing fault diagnosis under variable
    speed conditions,” Measurement, vol. 138, pp. 620–631, 2019.'
  id: totrans-520
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[31] Md Junayed Hasan, MM Manjurul Islam, 和 Jong-Myon Kim，“在变速条件下，利用声学光谱成像和转移学习进行可靠的轴承故障诊断”，Measurement，第138卷，页620–631，2019年。'
- en: '[32] Chuang Sun, Meng Ma, Zhibin Zhao, Shaohua Tian, Ruqiang Yan, and Xuefeng
    Chen, “Deep transfer learning based on sparse autoencoder for remaining useful
    life prediction of tool in manufacturing,” IEEE Transactions on Industrial Informatics,
    vol. 15, no. 4, pp. 2416–2425, 2018.'
  id: totrans-521
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[32] Chuang Sun, Meng Ma, Zhibin Zhao, Shaohua Tian, Ruqiang Yan 和 Xuefeng
    Chen，“基于稀疏自编码器的深度迁移学习用于制造中工具的剩余使用寿命预测，”《IEEE工业信息学汇刊》，第15卷，第4期，第2416–2425页，2018年。'
- en: '[33] Siyu Shao, Stephen McAleer, Ruqiang Yan, and Pierre Baldi, “Highly accurate
    machine fault diagnosis using deep transfer learning,” IEEE Transactions on Industrial
    Informatics, vol. 15, no. 4, pp. 2446–2455, 2018.'
  id: totrans-522
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[33] Siyu Shao, Stephen McAleer, Ruqiang Yan 和 Pierre Baldi，“使用深度迁移学习的高精度机器故障诊断，”《IEEE工业信息学汇刊》，第15卷，第4期，第2446–2455页，2018年。'
- en: '[34] Danmin Chen, Shuai Yang, and Funa Zhou, “Transfer learning based fault
    diagnosis with missing data due to multi-rate sampling,” Sensors, vol. 19, no.
    8, pp. 1826, 2019.'
  id: totrans-523
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[34] Danmin Chen, Shuai Yang 和 Funa Zhou，“基于迁移学习的故障诊断在多速率采样导致的缺失数据下，”《传感器》，第19卷，第8期，第1826页，2019年。'
- en: '[35] Wentao Mao, Ling Ding, Siyu Tian, and Xihui Liang, “Online detection for
    bearing incipient fault based on deep transfer learning,” Measurement, p. 107278,
    2019.'
  id: totrans-524
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[35] Wentao Mao, Ling Ding, Siyu Tian 和 Xihui Liang，“基于深度迁移学习的轴承初期故障在线检测，”《测量》，第107278页，2019年。'
- en: '[36] Zhiyi He, Haidong Shao, Ping Wang, Janet Jing Lin, Junsheng Cheng, and
    Yu Yang, “Deep transfer multi-wavelet auto-encoder for intelligent fault diagnosis
    of gearbox with few target training samples,” Knowledge-Based Systems, vol. 191,
    pp. 105313, 2020.'
  id: totrans-525
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[36] Zhiyi He, Haidong Shao, Ping Wang, Janet Jing Lin, Junsheng Cheng 和 Yu
    Yang，“用于智能齿轮箱故障诊断的深度迁移多小波自编码器，具有少量目标训练样本，”《知识驱动系统》，第191卷，第105313页，2020年。'
- en: '[37] Fudong Li, Jinglong Chen, Jun Pan, and Tongyang Pan, “Cross-domain learning
    in rotating machinery fault diagnosis under various operating conditions based
    on parameter transfer,” Measurement Science and Technology, vol. 31, no. 8, pp.
    085104, 2020.'
  id: totrans-526
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[37] Fudong Li, Jinglong Chen, Jun Pan 和 Tongyang Pan，“基于参数迁移的旋转机械故障诊断的跨领域学习在各种操作条件下，”《测量科学与技术》，第31卷，第8期，第085104页，2020年。'
- en: '[38] Sayed Ali Sharaf, “Beam pump dynamometer card prediction using artificial
    neural networks,” KnE Engineering, vol. 3, no. 7, pp. 198–212, 2018.'
  id: totrans-527
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[38] Sayed Ali Sharaf，“使用人工神经网络预测梁式泵力计卡片，”《KnE工程》，第3卷，第7期，第198–212页，2018年。'
- en: '[39] Pei Cao, Shengli Zhang, and Jiong Tang, “Preprocessing-free gear fault
    diagnosis using small datasets with deep convolutional neural network-based transfer
    learning,” IEEE Access, vol. 6, pp. 26241–26253, 2018.'
  id: totrans-528
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[39] Pei Cao, Shengli Zhang 和 Jiong Tang，“基于深度卷积神经网络的迁移学习的小数据集预处理无齿轮故障诊断，”《IEEE
    Access》，第6卷，第26241–26253页，2018年。'
- en: '[40] Zhuyun Chen, Konstantinos Gryllias, and Weihua Li, “Intelligent fault
    diagnosis for rotary machinery using transferable convolutional neural network,”
    IEEE Transactions on Industrial Informatics, vol. 16, no. 1, pp. 339–349, 2019.'
  id: totrans-529
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[40] Zhuyun Chen, Konstantinos Gryllias 和 Weihua Li，“使用可迁移卷积神经网络的旋转机械智能故障诊断，”《IEEE工业信息学汇刊》，第16卷，第1期，第339–349页，2019年。'
- en: '[41] D Iba, Y Ishii, Y Tsutsui, N Miura, T Iizuka, A Masuda, A Sone, and I Moriwaki,
    “Vibration analysis of a meshing gear pair by neural network (visualization of
    meshing vibration and detection of a crack at tooth root by vgg16 with transfer
    learning),” in Smart Structures and NDE for Energy Systems and Industry 4.0. International
    Society for Optics and Photonics, 2019, vol. 10973, p. 109730Y.'
  id: totrans-530
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[41] D Iba, Y Ishii, Y Tsutsui, N Miura, T Iizuka, A Masuda, A Sone 和 I Moriwaki，“通过神经网络的齿轮啮合对分析（通过VGG16与迁移学习可视化啮合振动和检测齿根裂纹），”在《智能结构与能源系统及工业4.0的无损检测》中。国际光学和光子学学会，2019年，第10973卷，第109730Y页。'
- en: '[42] Ping Ma, Hongli Zhang, Wenhui Fan, Cong Wang, Guangrui Wen, and Xining
    Zhang, “A novel bearing fault diagnosis method based on 2d image representation
    and transfer learning-convolutional neural network,” Measurement Science and Technology,
    vol. 30, no. 5, pp. 055402, 2019.'
  id: totrans-531
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[42] Ping Ma, Hongli Zhang, Wenhui Fan, Cong Wang, Guangrui Wen 和 Xining Zhang，“一种基于2D图像表示和迁移学习卷积神经网络的新型轴承故障诊断方法，”《测量科学与技术》，第30卷，第5期，第055402页，2019年。'
- en: '[43] Zhiyi He, Haidong Shao, Xiang Zhong, and Xianzhu Zhao, “Ensemble transfer
    cnns driven by multi-channel signals for fault diagnosis of rotating machinery
    cross working conditions,” Knowledge-Based Systems, vol. 207, pp. 106396, 2020.'
  id: totrans-532
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[43] Zhiyi He, Haidong Shao, Xiang Zhong 和 Xianzhu Zhao，“多通道信号驱动的集成迁移卷积神经网络用于旋转机械的故障诊断跨工作条件，”《知识驱动系统》，第207卷，第106396页，2020年。'
- en: '[44] ZiYang Di, HaiDong Shao, and JiaWei Xiang, “Ensemble deep transfer learning
    driven by multisensor signals for the fault diagnosis of bevel-gear cross-operation
    conditions,” Science China Technological Sciences, vol. 64, no. 3, pp. 481–492,
    2021.'
  id: totrans-533
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[44] 资阳迪、邵海东和向家伟，“多传感器信号驱动的集成深度转移学习用于斜齿轮交叉工况的故障诊断，”《中国科学技术期刊》，第64卷，第3期，第481–492页，2021年。'
- en: '[45] Zheng Wang, Qingxiu Liu, Hansi Chen, and Xuening Chu, “A deformable cnn-dlstm
    based transfer learning method for fault diagnosis of rolling bearing under multiple
    working conditions,” International Journal of Production Research, pp. 1–15, 2020.'
  id: totrans-534
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[45] 郑旺、刘青秀、陈汉思和储雪宁，“一种基于可变形 cnn-dlstm 的转移学习方法用于多工况下滚动轴承的故障诊断，”《国际生产研究期刊》，第1–15页，2020年。'
- en: '[46] Jianyu Wang, Zhenling Mo, Heng Zhang, and Qiang Miao, “A deep learning
    method for bearing fault diagnosis based on time-frequency image,” IEEE Access,
    vol. 7, pp. 42373–42383, 2019.'
  id: totrans-535
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[46] 王建宇、莫振凌、张恒和苗强，“一种基于时频图的深度学习滚动轴承故障诊断方法，”《IEEE 访问》，第7卷，第42373–42383页，2019年。'
- en: '[47] Haidong Shao, Min Xia, Guangjie Han, Yu Zhang, and Jiafu Wan, “Intelligent
    fault diagnosis of rotor-bearing system under varying working conditions with
    modified transfer convolutional neural network and thermal images,” IEEE Transactions
    on Industrial Informatics, vol. 17, no. 5, pp. 3488–3496, 2020.'
  id: totrans-536
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[47] 邵海东、夏敏、韩广杰、张瑜和万佳福，“基于改进的转移卷积神经网络和热图像的变工况下转子-轴承系统智能故障诊断，”《IEEE 工业信息学交易》，第17卷，第5期，第3488–3496页，2020年。'
- en: '[48] Aqsa Saeed Qureshi, Asifullah Khan, Aneela Zameer, and Anila Usman, “Wind
    power prediction using deep neural network based meta regression and transfer
    learning,” Applied Soft Computing, vol. 58, pp. 742–755, 2017.'
  id: totrans-537
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[48] 阿克萨·赛义德·库雷希、阿西夫拉·汗、安妮拉·扎米尔和安妮拉·乌斯曼，“基于深度神经网络的元回归和转移学习的风电预测，”《应用软计算》，第58卷，第742–755页，2017年。'
- en: '[49] Shi-sheng Zhong, Song Fu, and Lin Lin, “A novel gas turbine fault diagnosis
    method based on transfer learning with cnn,” Measurement, vol. 137, pp. 435–453,
    2019.'
  id: totrans-538
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[49] 施生钟、傅松和林林，“一种基于转移学习的气体涡轮故障诊断新方法，”《测量》，第137卷，第435–453页，2019年。'
- en: '[50] Te Han, Chao Liu, Wenguang Yang, and Dongxiang Jiang, “Learning transferable
    features in deep convolutional neural networks for diagnosing unseen machine conditions,”
    ISA transactions, vol. 93, pp. 341–353, 2019.'
  id: totrans-539
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[50] 涂汉、刘超、杨文广和姜东翔，“在深度卷积神经网络中学习可转移特征以诊断未见过的机器状态，”《ISA 交易》，第93卷，第341–353页，2019年。'
- en: '[51] Gaowei Xu, Min Liu, Zhuofu Jiang, Weiming Shen, and Chenxi Huang, “Online
    fault diagnosis method based on transfer convolutional neural networks,” IEEE
    Transactions on Instrumentation and Measurement, vol. 69, no. 2, pp. 509–520,
    2019.'
  id: totrans-540
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[51] 高伟、刘敏、姜卓富、沈伟明和黄晨曦，“基于转移卷积神经网络的在线故障诊断方法，”《IEEE 仪器与测量交易》，第69卷，第2期，第509–520页，2019年。'
- en: '[52] Bo Zhao, Xianmin Zhang, Zhenhui Zhan, and Shuiquan Pang, “Deep multi-scale
    convolutional transfer learning network: A novel method for intelligent fault
    diagnosis of rolling bearings under variable working conditions and domains,”
    Neurocomputing, vol. 407, pp. 24–38, 2020.'
  id: totrans-541
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[52] 博赵、张贤敏、詹振辉和庞水全，“深度多尺度卷积转移学习网络：一种用于在变化工况和领域下智能故障诊断的创新方法，”《神经计算》，第407卷，第24–38页，2020年。'
- en: '[53] Wenyuan Dai, Qiang Yang, Gui-Rong Xue, and Yong Yu, “Boosting for transfer
    learning,” in Proceedings of the 24th international conference on Machine learning.
    ACM, 2007, pp. 193–200.'
  id: totrans-542
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[53] 韦源戴、杨强、戈戎雪和俞勇，“转移学习的提升方法，”在第24届国际机器学习会议论文集中。ACM，2007年，第193–200页。'
- en: '[54] Yanghao Li, Naiyan Wang, Jianping Shi, Jiaying Liu, and Xiaodi Hou, “Revisiting
    batch normalization for practical domain adaptation,” arXiv preprint arXiv:1603.04779,
    2016.'
  id: totrans-543
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[54] 李杨浩、王奈燕、施建平、刘佳颖和侯晓迪，“重新审视批量归一化在实际领域适应中的应用，”arXiv 预印本 arXiv:1603.04779，2016年。'
- en: '[55] Sergey Ioffe and Christian Szegedy, “Batch normalization: Accelerating
    deep network training by reducing internal covariate shift,” arXiv preprint arXiv:1502.03167,
    2015.'
  id: totrans-544
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[55] 谢尔盖·伊奥费和克里斯蒂安·谢戈迪，“批量归一化：通过减少内部协变量偏移来加速深度网络训练，”arXiv 预印本 arXiv:1502.03167，2015年。'
- en: '[56] Dengyu Xiao, Yixiang Huang, Chengjin Qin, Zhiyu Liu, Yanming Li, and Chengliang
    Liu, “Transfer learning with convolutional neural networks for small sample size
    problem in machinery fault diagnosis,” Proceedings of the Institution of Mechanical
    Engineers, Part C: Journal of Mechanical Engineering Science, p. 0954406219840381,
    2019.'
  id: totrans-545
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[56] Dengyu Xiao, Yixiang Huang, Chengjin Qin, Zhiyu Liu, Yanming Li, 和 Chengliang
    Liu, “用于机械故障诊断的小样本问题的卷积神经网络迁移学习”，《机械工程师学会会刊》第C部分：机械工程科学期刊，文献号0954406219840381，2019年。'
- en: '[57] Wei Zhang, Gaoliang Peng, Chuanhao Li, Yuanhang Chen, and Zhujun Zhang,
    “A new deep learning model for fault diagnosis with good anti-noise and domain
    adaptation ability on raw vibration signals,” Sensors, vol. 17, no. 2, pp. 425,
    2017.'
  id: totrans-546
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[57] Wei Zhang, Gaoliang Peng, Chuanhao Li, Yuanhang Chen, 和 Zhujun Zhang,
    “一种用于故障诊断的新型深度学习模型，具有良好的抗噪声和领域自适应能力，适用于原始振动信号”，《传感器》，第17卷，第2期，页码425，2017年。'
- en: '[58] Weiwei Qian, Shunming Li, and Jinrui Wang, “A new transfer learning method
    and its application on rotating machine fault diagnosis under variant working
    conditions,” IEEE Access, vol. 6, pp. 69907–69917, 2018.'
  id: totrans-547
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[58] Weiwei Qian, Shunming Li, 和 Jinrui Wang, “一种新的迁移学习方法及其在变工况下旋转机械故障诊断中的应用”，《IEEE
    Access》，第6卷，页码69907–69917，2018年。'
- en: '[59] Baochen Sun and Kate Saenko, “Deep coral: Correlation alignment for deep
    domain adaptation,” in European Conference on Computer Vision. Springer, 2016,
    pp. 443–450.'
  id: totrans-548
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[59] Baochen Sun 和 Kate Saenko, “深度CORAL：用于深度领域自适应的相关对齐”，在欧洲计算机视觉会议上。Springer，2016年，页码443–450。'
- en: '[60] Karsten M Borgwardt, Arthur Gretton, Malte J Rasch, Hans-Peter Kriegel,
    Bernhard Schölkopf, and Alex J Smola, “Integrating structured biological data
    by kernel maximum mean discrepancy,” Bioinformatics, vol. 22, no. 14, pp. e49–e57,
    2006.'
  id: totrans-549
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[60] Karsten M Borgwardt, Arthur Gretton, Malte J Rasch, Hans-Peter Kriegel,
    Bernhard Schölkopf, 和 Alex J Smola, “通过核最大均值差异整合结构生物数据”，《生物信息学》，第22卷，第14期，页码e49–e57，2006年。'
- en: '[61] Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, Kenji Fukumizu,
    et al., “Equivalence of distance-based and rkhs-based statistics in hypothesis
    testing,” The Annals of Statistics, vol. 41, no. 5, pp. 2263–2291, 2013.'
  id: totrans-550
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[61] Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, Kenji Fukumizu,
    等， “基于距离和RKHS的统计量在假设检验中的等价性”，《统计年鉴》，第41卷，第5期，页码2263–2291，2013年。'
- en: '[62] Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan,
    Massimiliano Pontil, Kenji Fukumizu, and Bharath K Sriperumbudur, “Optimal kernel
    choice for large-scale two-sample tests,” in Advances in neural information processing
    systems, 2012, pp. 1205–1213.'
  id: totrans-551
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[62] Arthur Gretton, Dino Sejdinovic, Heiko Strathmann, Sivaraman Balakrishnan,
    Massimiliano Pontil, Kenji Fukumizu, 和 Bharath K Sriperumbudur, “大规模两样本测试的最优核选择”，在神经信息处理系统进展会议上，2012年，页码1205–1213。'
- en: '[63] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, and Philip S
    Yu, “Transfer feature learning with joint distribution adaptation,” in Proceedings
    of the IEEE international conference on computer vision, 2013, pp. 2200–2207.'
  id: totrans-552
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[63] Mingsheng Long, Jianmin Wang, Guiguang Ding, Jiaguang Sun, 和 Philip S
    Yu, “具有联合分布自适应的迁移特征学习”，发表于IEEE国际计算机视觉会议论文集，2013年，页码2200–2207。'
- en: '[64] Jindong Wang, Yiqiang Chen, Shuji Hao, Wenjie Feng, and Zhiqi Shen, “Balanced
    distribution adaptation for transfer learning,” in 2017 IEEE International Conference
    on Data Mining (ICDM). IEEE, 2017, pp. 1129–1134.'
  id: totrans-553
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[64] Jindong Wang, Yiqiang Chen, Shuji Hao, Wenjie Feng, 和 Zhiqi Shen, “迁移学习的平衡分布自适应”，在2017
    IEEE国际数据挖掘会议（ICDM）上。IEEE，2017年，页码1129–1134。'
- en: '[65] Mingsheng Long, Han Zhu, Jianmin Wang, and Michael I Jordan, “Deep transfer
    learning with joint adaptation networks,” in Proceedings of the 34th International
    Conference on Machine Learning-Volume 70. JMLR. org, 2017, pp. 2208–2217.'
  id: totrans-554
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[65] Mingsheng Long, Han Zhu, Jianmin Wang, 和 Michael I Jordan, “具有联合自适应网络的深度迁移学习”，发表于第34届国际机器学习大会论文集-第70卷。JMLR.org，2017年，页码2208–2217。'
- en: '[66] Sinno Jialin Pan, Ivor W Tsang, James T Kwok, and Qiang Yang, “Domain
    adaptation via transfer component analysis,” IEEE Transactions on Neural Networks,
    vol. 22, no. 2, pp. 199–210, 2010.'
  id: totrans-555
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[66] Sinno Jialin Pan, Ivor W Tsang, James T Kwok, 和 Qiang Yang, “通过迁移成分分析进行领域自适应”，《IEEE神经网络学报》，第22卷，第2期，页码199–210，2010年。'
- en: '[67] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, and Trevor Darrell,
    “Deep domain confusion: Maximizing for domain invariance,” arXiv preprint arXiv:1412.3474,
    2014.'
  id: totrans-556
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[67] Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, 和 Trevor Darrell, “深度领域混淆：最大化领域不变性”，arXiv预印本
    arXiv:1412.3474，2014年。'
- en: '[68] TŁ Żynda, “On weights which admit reproducing kernel of szegő type,” Journal
    of Contemporary Mathematical Analysis (Armenian Academy of Sciences), vol. 55,
    no. 5, pp. 320–327, 2020.'
  id: totrans-557
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[68] TŁ Żynda, “关于允许再现核的Szegő型权重”，《当代数学分析杂志》（亚美尼亚科学院），第55卷，第5期，页码320–327，2020年。'
- en: '[69] Baochen Sun, Jiashi Feng, and Kate Saenko, “Return of frustratingly easy
    domain adaptation,” in Thirtieth AAAI Conference on Artificial Intelligence, 2016.'
  id: totrans-558
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[69] Baochen Sun, Jiashi Feng, 和 Kate Saenko，“令人沮丧的简单领域适配的回归，”在《第三十届AAAI人工智能会议》中，2016年。'
- en: '[70] Kaijie Wang and Bin Wu, “Power equipment fault diagnosis model based on
    deep transfer learning with balanced distribution adaptation,” in International
    Conference on Advanced Data Mining and Applications. Springer, 2018, pp. 178–188.'
  id: totrans-559
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[70] Kaijie Wang 和 Bin Wu，“基于深度迁移学习的电力设备故障诊断模型，结合平衡分布适配，”在《国际先进数据挖掘与应用会议》中。Springer，2018年，第178–188页。'
- en: '[71] Yujing Wang, Chao Wang, Shouqiang Kang, Jinbao Xie, Qingyan Wang, and
    VI Mikulovich, “Network-combined broad learning and transfer learning: a new intelligent
    fault diagnosis method for rolling bearings,” Measurement Science and Technology,
    vol. 31, no. 11, pp. 115013, 2020.'
  id: totrans-560
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[71] Yujing Wang, Chao Wang, Shouqiang Kang, Jinbao Xie, Qingyan Wang, 和 VI
    Mikulovich，“网络结合广泛学习和迁移学习：一种用于滚动轴承的新型智能故障诊断方法，”《测量科学与技术》，第31卷，第11期，第115013页，2020年。'
- en: '[72] Xiaoxia Wang, Haibo He, and Lusi Li, “A hierarchical deep domain adaptation
    approach for fault diagnosis of power plant thermal system,” IEEE Transactions
    on Industrial Informatics, vol. 15, no. 9, pp. 5139–5148, 2019.'
  id: totrans-561
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[72] Xiaoxia Wang, Haibo He, 和 Lusi Li，“用于电厂热系统故障诊断的分层深度领域适配方法，”《IEEE工业信息学学报》，第15卷，第9期，第5139–5148页，2019年。'
- en: '[73] Jing An, Ping Ai, and Dakun Liu, “Deep domain adaptation model for bearing
    fault diagnosis with domain alignment and discriminative feature learning,” Shock
    and Vibration, vol. 2020, 2020.'
  id: totrans-562
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[73] Jing An, Ping Ai, 和 Dakun Liu，“用于轴承故障诊断的深度领域适配模型，结合领域对齐和判别特征学习，”《冲击与振动》，第2020卷，2020年。'
- en: '[74] Zhongwei Zhang, Huaihai Chen, Shunming Li, and Zenghui An, “Unsupervised
    domain adaptation via enhanced transfer joint matching for bearing fault diagnosis,”
    Measurement, vol. 165, pp. 108071, 2020.'
  id: totrans-563
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[74] Zhongwei Zhang, Huaihai Chen, Shunming Li, 和 Zenghui An，“通过增强转移联合匹配的无监督领域适配用于轴承故障诊断，”《测量》，第165卷，第108071页，2020年。'
- en: '[75] Weiwei Qian, Shunming Li, and Xingxing Jiang, “Deep transfer network for
    rotating machine fault analysis,” Pattern Recognition, vol. 96, pp. 106993, 2019.'
  id: totrans-564
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[75] Weiwei Qian, Shunming Li, 和 Xingxing Jiang，“用于旋转机械故障分析的深度迁移网络，”《模式识别》，第96卷，第106993页，2019年。'
- en: '[76] Chaofan Hu, Yanxue Wang, and Jiawei Gu, “Cross-domain intelligent fault
    classification of bearings based on tensor-aligned invariant subspace learning
    and two-dimensional convolutional neural networks,” Knowledge-Based Systems, vol.
    209, pp. 106214, 2020.'
  id: totrans-565
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[76] Chaofan Hu, Yanxue Wang, 和 Jiawei Gu，“基于张量对齐不变子空间学习和二维卷积神经网络的跨领域智能故障分类，”《知识工程系统》，第209卷，第106214页，2020年。'
- en: '[77] Weining Lu, Bin Liang, Yu Cheng, Deshan Meng, Jun Yang, and Tao Zhang,
    “Deep model based domain adaptation for fault diagnosis,” IEEE Transactions on
    Industrial Electronics, vol. 64, no. 3, pp. 2296–2305, 2016.'
  id: totrans-566
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[77] Weining Lu, Bin Liang, Yu Cheng, Deshan Meng, Jun Yang, 和 Tao Zhang，“基于深度模型的领域适配故障诊断，”《IEEE工业电子学报》，第64卷，第3期，第2296–2305页，2016年。'
- en: '[78] Bo Zhang, Wei Li, Xiao-Li Li, and See-Kiong Ng, “Intelligent fault diagnosis
    under varying working conditions based on domain adaptive convolutional neural
    networks,” IEEE Access, vol. 6, pp. 66367–66384, 2018.'
  id: totrans-567
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[78] Bo Zhang, Wei Li, Xiao-Li Li, 和 See-Kiong Ng，“基于领域自适应卷积神经网络的变化工作条件下的智能故障诊断，”《IEEE
    Access》，第6卷，第66367–66384页，2018年。'
- en: '[79] Long Wen, Liang Gao, and Xinyu Li, “A new deep transfer learning based
    on sparse auto-encoder for fault diagnosis,” IEEE Transactions on Systems, Man,
    and Cybernetics: Systems, vol. 49, no. 1, pp. 136–144, 2017.'
  id: totrans-568
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[79] Long Wen, Liang Gao, 和 Xinyu Li，“基于稀疏自编码器的新型深度迁移学习故障诊断方法，”《IEEE系统、人类与控制论学报：系统》，第49卷，第1期，第136–144页，2017年。'
- en: '[80] Bin Yang, Yaguo Lei, Feng Jia, and Saibo Xing, “An intelligent fault diagnosis
    approach based on transfer learning from laboratory bearings to locomotive bearings,”
    Mechanical Systems and Signal Processing, vol. 122, pp. 692–706, 2019.'
  id: totrans-569
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[80] Bin Yang, Yaguo Lei, Feng Jia, 和 Saibo Xing，“基于从实验室轴承到机车轴承迁移学习的智能故障诊断方法，”《机械系统与信号处理》，第122卷，第692–706页，2019年。'
- en: '[81] Shanxuan Tang, Hailong Tang, and Min Chen, “Transfer-learning based gas
    path analysis method for gas turbines,” Applied Thermal Engineering, vol. 155,
    pp. 1–13, 2019.'
  id: totrans-570
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[81] Shanxuan Tang, Hailong Tang, 和 Min Chen，“基于迁移学习的燃气轮机气路分析方法，”《应用热工程》，第155卷，第1–13页，2019年。'
- en: '[82] Xiang Li, Wei Zhang, and Qian Ding, “Cross-domain fault diagnosis of rolling
    element bearings using deep generative neural networks,” IEEE Transactions on
    Industrial Electronics, vol. 66, no. 7, pp. 5525–5534, 2018.'
  id: totrans-571
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[82] Xiang Li, Wei Zhang, 和 Qian Ding，“使用深度生成神经网络的滚动元件轴承跨域故障诊断”，《IEEE工业电子学报》，第66卷，第7期，页5525–5534，2018年。'
- en: '[83] Yan Xu, Yanming Sun, Xiaolong Liu, and Yonghua Zheng, “A digital-twin-assisted
    fault diagnosis using deep transfer learning,” IEEE Access, vol. 7, pp. 19990–19999,
    2019.'
  id: totrans-572
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[83] Yan Xu, Yanming Sun, Xiaolong Liu, 和 Yonghua Zheng，“一种数字双胞胎辅助的深度迁移学习故障诊断”，《IEEE
    Access》，第7卷，页19990–19999，2019年。'
- en: '[84] Zenghui An, Shunming Li, Yu Xin, Kun Xu, and Huijie Ma, “An intelligent
    fault diagnosis framework dealing with arbitrary length inputs under different
    working conditions,” Measurement Science and Technology, vol. 30, no. 12, pp.
    125107, 2019.'
  id: totrans-573
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[84] Zenghui An, Shunming Li, Yu Xin, Kun Xu, 和 Huijie Ma，“一个处理不同工作条件下任意长度输入的智能故障诊断框架”，《测量科学与技术》，第30卷，第12期，页125107，2019年。'
- en: '[85] Xiang Li, Xiao-Dong Jia, Wei Zhang, Hui Ma, Zhong Luo, and Xu Li, “Intelligent
    cross-machine fault diagnosis approach with deep auto-encoder and domain adaptation,”
    Neurocomputing, vol. 383, pp. 235–247, 2020.'
  id: totrans-574
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[85] Xiang Li, Xiao-Dong Jia, Wei Zhang, Hui Ma, Zhong Luo, 和 Xu Li，“基于深度自编码器和领域适应的智能跨机器故障诊断方法”，《神经计算》，第383卷，页235–247，2020年。'
- en: '[86] Zhe Tong, Wei Li, Bo Zhang, and Meng Zhang, “Bearing fault diagnosis based
    on domain adaptation using transferable features under different working conditions,”
    Shock and Vibration, vol. 2018, 2018.'
  id: totrans-575
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[86] Zhe Tong, Wei Li, Bo Zhang, 和 Meng Zhang，“基于领域适应的转移特征在不同工作条件下的轴承故障诊断”，《冲击与振动》，第2018卷，2018年。'
- en: '[87] Zhe Tong, Wei Li, Bo Zhang, Fan Jiang, and Gongbo Zhou, “Bearing fault
    diagnosis under variable working conditions based on domain adaptation using feature
    transfer learning,” IEEE Access, vol. 6, pp. 76187–76197, 2018.'
  id: totrans-576
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[87] Zhe Tong, Wei Li, Bo Zhang, Fan Jiang, 和 Gongbo Zhou，“基于领域适应的特征迁移学习在变化工作条件下的轴承故障诊断”，《IEEE
    Access》，第6卷，页76187–76197，2018年。'
- en: '[88] Xu Wang, Changqing Shen, Min Xia, Dong Wang, Jun Zhu, and Zhongkui Zhu,
    “Multi-scale deep intra-class transfer learning for bearing fault diagnosis,”
    Reliability Engineering & System Safety, vol. 202, pp. 107050, 2020.'
  id: totrans-577
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[88] Xu Wang, Changqing Shen, Min Xia, Dong Wang, Jun Zhu, 和 Zhongkui Zhu，“用于轴承故障诊断的多尺度深度类内迁移学习”，《可靠性工程与系统安全》，第202卷，页107050，2020年。'
- en: '[89] Qikang Li, Baoping Tang, Lei Deng, Yanling Wu, and Yi Wang, “Deep balanced
    domain adaptation neural networks for fault diagnosis of planetary gearboxes with
    limited labeled data,” Measurement, vol. 156, pp. 107570, 2020.'
  id: totrans-578
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[89] Qikang Li, Baoping Tang, Lei Deng, Yanling Wu, 和 Yi Wang，“深度平衡领域适应神经网络在有限标注数据下的行星齿轮箱故障诊断”，《测量》，第156卷，页107570，2020年。'
- en: '[90] Nannan Lu, Hanhan Xiao, Yanjing Sun, Min Han, and Yanfen Wang, “A new
    method for intelligent fault diagnosis of machines based on unsupervised domain
    adaptation,” Neurocomputing, vol. 427, pp. 96–109, 2021.'
  id: totrans-579
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[90] Nannan Lu, Hanhan Xiao, Yanjing Sun, Min Han, 和 Yanfen Wang，“一种基于无监督领域适应的机器智能故障诊断新方法”，《神经计算》，第427卷，页96–109，2021年。'
- en: '[91] Bin Yang, Yaguo Lei, Feng Jia, Naipeng Li, and Zhaojun Du, “A polynomial
    kernel induced distance metric to improve deep transfer learning for fault diagnosis
    of machines,” IEEE Transactions on Industrial Electronics, vol. 67, no. 11, pp.
    9747–9757, 2020.'
  id: totrans-580
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[91] Bin Yang, Yaguo Lei, Feng Jia, Naipeng Li, 和 Zhaojun Du，“一种多项式核诱导距离度量，以提高深度迁移学习在机器故障诊断中的应用”，《IEEE工业电子学报》，第67卷，第11期，页9747–9757，2020年。'
- en: '[92] Xincheng Cao, Yu Wang, Binqiang Chen, and Nianyin Zeng, “Domain-adaptive
    intelligence for fault diagnosis based on deep transfer learning from scientific
    test rigs to industrial applications,” Neural Computing and Applications, vol.
    33, no. 9, pp. 4483–4499, 2021.'
  id: totrans-581
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[92] Xincheng Cao, Yu Wang, Binqiang Chen, 和 Nianyin Zeng，“基于深度迁移学习的领域自适应智能故障诊断，从科学测试台到工业应用”，《神经计算与应用》，第33卷，第9期，页4483–4499，2021年。'
- en: '[93] Ke Zhao, Hongkai Jiang, Zhenghong Wu, and Tengfei Lu, “A novel transfer
    learning fault diagnosis method based on manifold embedded distribution alignment
    with a little labeled data,” Journal of Intelligent Manufacturing, pp. 1–15, 2020.'
  id: totrans-582
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[93] Ke Zhao, Hongkai Jiang, Zhenghong Wu, 和 Tengfei Lu，“一种基于流形嵌入分布对齐的小量标注数据的迁移学习故障诊断新方法”，《智能制造杂志》，页1–15，2020年。'
- en: '[94] Huailiang Zheng, Rixin Wang, Jiancheng Yin, Yuqing Li, Haiqing Lu, and
    Minqiang Xu, “A new intelligent fault identification method based on transfer
    locality preserving projection for actual diagnosis scenario of rotating machinery,”
    Mechanical Systems and Signal Processing, vol. 135, pp. 106344, 2020.'
  id: totrans-583
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[94] 怀亮郑、日新王、建成尹、玉清李、海青陆和敏强徐，“一种基于迁移局部保持投影的新型智能故障识别方法用于旋转机械实际诊断场景”，《机械系统与信号处理》，第135卷，第106344页，2020年。'
- en: '[95] Zhongwei Zhang, Huaihai Chen, Shunming Li, and Zenghui An, “A novel unsupervised
    domain adaptation based on deep neural network and manifold regularization for
    mechanical fault diagnosis,” Measurement Science and Technology, vol. 31, no.
    8, pp. 085101, 2020.'
  id: totrans-584
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[95] 钟伟张、怀海陈、舜明李和曾辉安，“一种基于深度神经网络和流形正则化的无监督领域自适应新方法用于机械故障诊断”，《测量科学与技术》，第31卷，第8期，第085101页，2020年。'
- en: '[96] Weiwei Qian, Shunming Li, Tong Yao, and Kun Xu, “Discriminative feature-based
    adaptive distribution alignment (dfada) for rotating machine fault diagnosis under
    variable working conditions,” Applied Soft Computing, vol. 99, pp. 106886, 2021.'
  id: totrans-585
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[96] 魏伟钱、舜明李、童耀和坤徐，“基于判别特征的自适应分布对齐（dfada）用于可变工作条件下的旋转机械故障诊断”，《应用软计算》，第99卷，第106886页，2021年。'
- en: '[97] Xiang Li, Wei Zhang, and Qian Ding, “A robust intelligent fault diagnosis
    method for rolling element bearings based on deep distance metric learning,” Neurocomputing,
    vol. 310, pp. 77–95, 2018.'
  id: totrans-586
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[97] 向李、魏张和钱丁，“一种基于深度距离度量学习的鲁棒智能滚动元件轴承故障诊断方法”，《神经计算》，第310卷，第77–95页，2018年。'
- en: '[98] Bin Yang, Yaguo Lei, Feng Jia, and Saibo Xing, “A transfer learning method
    for intelligent fault diagnosis from laboratory machines to real-case machines,”
    in 2018 International Conference on Sensing, Diagnostics, Prognostics, and Control
    (SDPC). IEEE, 2018, pp. 35–40.'
  id: totrans-587
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[98] 邴阳、雅国雷、丰佳和赛博兴，“一种从实验室机器到实际机器的智能故障诊断的迁移学习方法”，见于2018年国际传感、诊断、预测与控制会议（SDPC）。IEEE，2018年，第35–40页。'
- en: '[99] Zenghui An, Shunming Li, Jinrui Wang, Yu Xin, and Kun Xu, “Generalization
    of deep neural network for bearing fault diagnosis under different working conditions
    using multiple kernel method,” Neurocomputing, vol. 352, pp. 42–53, 2019.'
  id: totrans-588
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[99] 曾辉安、舜明李、金瑞王、余鑫和坤徐，“在不同工作条件下基于多核方法的深度神经网络的泛化用于轴承故障诊断”，《神经计算》，第352卷，第42–53页，2019年。'
- en: '[100] Jun Zhu, Nan Chen, and Changqing Shen, “A new deep transfer learning
    method for bearing fault diagnosis under different working conditions,” IEEE Sensors
    Journal, vol. 20, no. 15, pp. 8394–8402, 2019.'
  id: totrans-589
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[100] 郑军、南陈和常青沈，“一种新的深度迁移学习方法用于在不同工作条件下的轴承故障诊断”，《IEEE传感器期刊》，第20卷，第15期，第8394–8402页，2019年。'
- en: '[101] Changchang Che, Huawei Wang, Xiaomei Ni, and Qiang Fu, “Domain adaptive
    deep belief network for rolling bearing fault diagnosis,” Computers & Industrial
    Engineering, vol. 143, pp. 106427, 2020.'
  id: totrans-590
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[101] 常常车、华为王、肖梅倪和强福，“用于滚动轴承故障诊断的领域自适应深度置信网络”，《计算机与工业工程》，第143卷，第106427页，2020年。'
- en: '[102] Te Han, Chao Liu, Wenguang Yang, and Dongxiang Jiang, “Deep transfer
    network with joint distribution adaptation: A new intelligent fault diagnosis
    framework for industry application,” ISA transactions, vol. 97, pp. 269–281, 2020.'
  id: totrans-591
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[102] 谭特、刘超、翁广杨和董湘江，“带有联合分布自适应的深度迁移网络：一种新的智能故障诊断框架用于工业应用”，《ISA交易》，第97卷，第269–281页，2020年。'
- en: '[103] Weiwei Qian, Shunming Li, Pengxing Yi, and Kaicheng Zhang, “A novel transfer
    learning method for robust fault diagnosis of rotating machines under variable
    working conditions,” Measurement, vol. 138, pp. 514–525, 2019.'
  id: totrans-592
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[103] 魏伟钱、舜明李、鹏兴易和凯成张，“一种新颖的迁移学习方法用于在可变工作条件下的旋转机械鲁棒故障诊断”，《测量》，第138卷，第514–525页，2019年。'
- en: '[104] Zhenghong Wu, Hongkai Jiang, Ke Zhao, and Xingqiu Li, “An adaptive deep
    transfer learning method for bearing fault diagnosis,” Measurement, vol. 151,
    pp. 107227, 2020.'
  id: totrans-593
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[104] 郑宏吴、洪凯江、柯赵和兴秋李，“一种用于轴承故障诊断的自适应深度迁移学习方法”，《测量》，第151卷，第107227页，2020年。'
- en: '[105] Xincheng Cao, Binqiang Chen, and Nianyin Zeng, “A deep domain adaption
    model with multi-task networks for planetary gearbox fault diagnosis,” Neurocomputing,
    vol. 409, pp. 173–190, 2020.'
  id: totrans-594
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[105] 辛程曹、宾强陈和念银曾，“一种带有多任务网络的深度领域自适应模型用于行星齿轮箱故障诊断”，《神经计算》，第409卷，第173–190页，2020年。'
- en: '[106] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
    Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky, “Domain-adversarial
    training of neural networks,” The Journal of Machine Learning Research, vol. 17,
    no. 1, pp. 2096–2030, 2016.'
  id: totrans-595
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[106] Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
    Larochelle, François Laviolette, Mario Marchand 和 Victor Lempitsky，“神经网络的领域对抗训练，”《机器学习研究期刊》，第17卷，第1期，第2096–2030页，2016年。'
- en: '[107] Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I Jordan, “Conditional
    adversarial domain adaptation,” in Advances in Neural Information Processing Systems,
    2018, pp. 1640–1650.'
  id: totrans-596
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[107] Mingsheng Long, Zhangjie Cao, Jianmin Wang 和 Michael I Jordan，“条件对抗性领域适应，”在《神经信息处理系统进展》2018年，第1640–1650页。'
- en: '[108] Bo Zhang, Wei Li, Jie Hao, Xiao-Li Li, and Meng Zhang, “Adversarial adaptive
    1-d convolutional neural networks for bearing fault diagnosis under varying working
    condition,” arXiv preprint arXiv:1805.00778, 2018.'
  id: totrans-597
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[108] Bo Zhang, Wei Li, Jie Hao, Xiao-Li Li 和 Meng Zhang，“在变化工作条件下用于轴承故障诊断的对抗性自适应1-d卷积神经网络，”arXiv预印本
    arXiv:1805.00778，2018年。'
- en: '[109] Te Han, Chao Liu, Wenguang Yang, and Dongxiang Jiang, “A novel adversarial
    learning framework in deep convolutional neural network for intelligent diagnosis
    of mechanical faults,” Knowledge-Based Systems, vol. 165, pp. 474–487, 2019.'
  id: totrans-598
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[109] Te Han, Chao Liu, Wenguang Yang 和 Dongxiang Jiang，“一种新颖的对抗性学习框架用于深度卷积神经网络中的机械故障智能诊断，”《知识基系统》，第165卷，第474–487页，2019年。'
- en: '[110] Liang Guo, Yaguo Lei, Saibo Xing, Tao Yan, and Naipeng Li, “Deep convolutional
    transfer learning network: A new method for intelligent fault diagnosis of machines
    with unlabeled data,” IEEE Transactions on Industrial Electronics, vol. 66, no.
    9, pp. 7316–7325, 2018.'
  id: totrans-599
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[110] Liang Guo, Yaguo Lei, Saibo Xing, Tao Yan 和 Naipeng Li，“深度卷积迁移学习网络：一种用于无标签数据的机器智能故障诊断的新方法，”《IEEE工业电子学报》，第66卷，第9期，第7316–7325页，2018年。'
- en: '[111] Qin Wang, Gabriel Michau, and Olga Fink, “Domain adaptive transfer learning
    for fault diagnosis,” in 2019 Prognostics and System Health Management Conference
    (PHM-Paris). IEEE, 2019, pp. 279–285.'
  id: totrans-600
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[111] Qin Wang, Gabriel Michau 和 Olga Fink，“用于故障诊断的领域自适应迁移学习，”在2019年预后与系统健康管理会议（PHM-Paris）中。IEEE，2019年，第279–285页。'
- en: '[112] Zhuyun Chen, Guolin He, Jipu Li, Yixiao Liao, Konstantinos Gryllias,
    and Weihua Li, “Domain adversarial transfer network for cross-domain fault diagnosis
    of rotary machinery,” IEEE Transactions on Instrumentation and Measurement, vol.
    69, no. 11, pp. 8702–8712, 2020.'
  id: totrans-601
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[112] Zhuyun Chen, Guolin He, Jipu Li, Yixiao Liao, Konstantinos Gryllias 和
    Weihua Li，“用于旋转机械跨领域故障诊断的领域对抗迁移网络，”《IEEE仪器与测量学报》，第69卷，第11期，第8702–8712页，2020年。'
- en: '[113] Lei Zou, Yang Li, and Feiyun Xu, “An adversarial denoising convolutional
    neural network for fault diagnosis of rotating machinery under noisy environment
    and limited sample size case,” Neurocomputing, vol. 407, pp. 105–120, 2020.'
  id: totrans-602
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[113] Lei Zou, Yang Li 和 Feiyun Xu，“一种对抗性去噪卷积神经网络用于噪声环境和有限样本情况下旋转机械的故障诊断，”《神经计算》，第407卷，第105–120页，2020年。'
- en: '[114] Qi Li, Changqing Shen, Liang Chen, and Zhongkui Zhu, “Knowledge mapping-based
    adversarial domain adaptation: A novel fault diagnosis method with high generalizability
    under variable working conditions,” Mechanical Systems and Signal Processing,
    vol. 147, pp. 107095, 2021.'
  id: totrans-603
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[114] Qi Li, Changqing Shen, Liang Chen 和 Zhongkui Zhu，“基于知识映射的对抗性领域适应：一种在变化工作条件下具有高泛化能力的新型故障诊断方法，”《机械系统与信号处理》，第147卷，第107095页，2021年。'
- en: '[115] Tianfu Li, Zhibin Zhao, Chuang Sun, Ruqiang Yan, and Xuefeng Chen, “Domain
    adversarial graph convolutional network for fault diagnosis under variable working
    conditions,” IEEE Transactions on Instrumentation and Measurement, vol. 70, pp.
    1–10, 2021.'
  id: totrans-604
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[115] Tianfu Li, Zhibin Zhao, Chuang Sun, Ruqiang Yan 和 Xuefeng Chen，“用于变化工作条件下故障诊断的领域对抗图卷积网络，”《IEEE仪器与测量学报》，第70卷，第1–10页，2021年。'
- en: '[116] Jinyang Jiao, Ming Zhao, and Jing Lin, “Unsupervised adversarial adaptation
    network for intelligent fault diagnosis,” IEEE Transactions on Industrial Electronics,
    vol. 67, no. 11, pp. 9904–9913, 2019.'
  id: totrans-605
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[116] Jinyang Jiao, Ming Zhao 和 Jing Lin，“无监督对抗适应网络用于智能故障诊断，”《IEEE工业电子学报》，第67卷，第11期，第9904–9913页，2019年。'
- en: '[117] Kun Yu, Hongzheng Han, Qiang Fu, Hui Ma, and Jin Zeng, “Symmetric co-training
    based unsupervised domain adaptation approach for intelligent fault diagnosis
    of rolling bearing,” Measurement Science and Technology, vol. 31, no. 11, pp.
    115008, 2020.'
  id: totrans-606
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[117] Kun Yu, Hongzheng Han, Qiang Fu, Hui Ma 和 Jin Zeng，“基于对称协同训练的无监督领域适应方法用于滚动轴承的智能故障诊断，”《测量科学与技术》，第31卷，第11期，第115008页，2020年。'
- en: '[118] Jinyang Jiao, Jing Lin, Ming Zhao, and Kaixuan Liang, “Double-level adversarial
    domain adaptation network for intelligent fault diagnosis,” Knowledge-Based Systems,
    vol. 205, pp. 106236, 2020.'
  id: totrans-607
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[118] 焦锦阳、林静、赵明和梁凯旋，"双级对抗领域适应网络用于智能故障诊断，"《基于知识的系统》，第205卷，页码106236，2020年。'
- en: '[119] Xiang Li, Wei Zhang, Nan-Xi Xu, and Qian Ding, “Deep learning-based machinery
    fault diagnostics with domain adaptation across sensors at different places,”
    IEEE Transactions on Industrial Electronics, vol. 67, no. 8, pp. 6785–6794, 2019.'
  id: totrans-608
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[119] 李翔、张伟、徐南西和丁茜，"基于深度学习的机械故障诊断，具有不同位置传感器的领域适应，"《IEEE工业电子学汇刊》，第67卷，第8期，页码6785–6794，2019年。'
- en: '[120] Sixiang Jia, Jinrui Wang, Baokun Han, Guowei Zhang, Xiaoyu Wang, and
    Jingtao He, “A novel transfer learning method for fault diagnosis using maximum
    classifier discrepancy with marginal probability distribution adaptation,” IEEE
    Access, vol. 8, pp. 71475–71485, 2020.'
  id: totrans-609
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[120] 贾思祥、王金锐、韩宝坤、张国伟、王晓宇和贺晶涛，"一种新型的故障诊断迁移学习方法，使用最大分类器差异与边际概率分布适应，"《IEEE Access》，第8卷，页码71475–71485，2020年。'
- en: '[121] Yongchao Zhang, Zhaohui Ren, and Shihua Zhou, “A new deep convolutional
    domain adaptation network for bearing fault diagnosis under different working
    conditions,” Shock and Vibration, vol. 2020, 2020.'
  id: totrans-610
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[121] 张永超、任朝辉和周世华，"一种新的深度卷积领域适应网络用于不同工作条件下的轴承故障诊断，"《冲击与振动》，第2020卷，2020年。'
- en: '[122] Jinyang Jiao, Ming Zhao, Jing Lin, and Kaixuan Liang, “Residual joint
    adaptation adversarial network for intelligent transfer fault diagnosis,” Mechanical
    Systems and Signal Processing, vol. 145, pp. 106962, 2020.'
  id: totrans-611
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[122] 焦锦阳、赵明、林静和梁凯旋，"残差联合适应对抗网络用于智能转移故障诊断，"《机械系统与信号处理》，第145卷，页码106962，2020年。'
- en: '[123] Yibin Li, Yan Song, Lei Jia, Shengyao Gao, Qiqiang Li, and Meikang Qiu,
    “Intelligent fault diagnosis by fusing domain adversarial training and maximum
    mean discrepancy via ensemble learning,” IEEE Transactions on Industrial Informatics,
    vol. 17, no. 4, pp. 2833–2841, 2021.'
  id: totrans-612
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[123] 李益斌、宋彦、贾磊、高生耀、李启强和邱美康，"通过融合领域对抗训练和最大均值差异的智能故障诊断方法，"《IEEE工业信息学汇刊》，第17卷，第4期，页码2833–2841，2021年。'
- en: '[124] Yi Qin, Xin Wang, Quan Qian, Huayan Pu, and Jun Luo, “Multiscale transfer
    voting mechanism: A new strategy for domain adaption,” IEEE Transactions on Industrial
    Informatics, vol. 17, no. 10, pp. 7103–7113, 2021.'
  id: totrans-613
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[124] 秦毅、王鑫、钱全、蒲华彦和罗军，"多尺度转移投票机制：领域适应的新策略，"《IEEE工业信息学汇刊》，第17卷，第10期，页码7103–7113，2021年。'
- en: '[125] Yi Qin, Qunwang Yao, Yi Wang, and Yongfang Mao, “Parameter sharing adversarial
    domain adaptation networks for fault transfer diagnosis of planetary gearboxes,”
    Mechanical Systems and Signal Processing, vol. 160, pp. 107936, 2021.'
  id: totrans-614
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[125] 秦毅、姚群望、王毅和毛永芳，"参数共享对抗领域适应网络用于行星齿轮箱的故障转移诊断，"《机械系统与信号处理》，第160卷，页码107936，2021年。'
- en: '[126] Qunwang Yao, Yi Qin, Xin Wang, and Quan Qian, “Multiscale domain adaption
    models and their application in fault transfer diagnosis of planetary gearboxes,”
    Engineering Applications of Artificial Intelligence, vol. 104, pp. 104383, 2021.'
  id: totrans-615
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[126] 姚群望、秦毅、王鑫和钱全，"多尺度领域适应模型及其在行星齿轮箱故障转移诊断中的应用，"《工程应用人工智能》，第104卷，页码104383，2021年。'
- en: '[127] Cheng Cheng, Beitong Zhou, Guijun Ma, Dongrui Wu, and Ye Yuan, “Wasserstein
    distance based deep adversarial transfer learning for intelligent fault diagnosis
    with unlabeled or insufficient labeled data,” Neurocomputing, vol. 409, pp. 35–45,
    2020.'
  id: totrans-616
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[127] 程程、周贝桐、马贵军、吴东睿和袁烨，"基于Wasserstein距离的深度对抗迁移学习用于智能故障诊断，适用于无标签或标签不足的数据，"《神经计算》，第409卷，页码35–45，2020年。'
- en: '[128] Ming Zhang, Duo Wang, Weining Lu, Jun Yang, Zhiheng Li, and Bin Liang,
    “A deep transfer model with wasserstein distance guided multi-adversarial networks
    for bearing fault diagnosis under different working conditions,” IEEE Access,
    vol. 7, pp. 65303–65318, 2019.'
  id: totrans-617
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[128] 张铭、王多、陆伟宁、杨俊、李志恒和梁斌，"一种深度迁移模型，使用Wasserstein距离引导的多对抗网络用于不同工作条件下的轴承故障诊断，"《IEEE
    Access》，第7卷，页码65303–65318，2019年。'
- en: '[129] Xiaodong Wang and Feng Liu, “Triplet loss guided adversarial domain adaptation
    for bearing fault diagnosis,” Sensors, vol. 20, no. 1, pp. 320, 2020.'
  id: totrans-618
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[129] 王晓东和刘峰，"三元组损失引导的对抗领域适应用于轴承故障诊断，"《传感器》，第20卷，第1期，页码320，2020年。'
- en: '[130] D She, N Peng, M Jia, and MG Pecht, “Wasserstein distance based deep
    multi-feature adversarial transfer diagnosis approach under variable working conditions,”
    Journal of Instrumentation, vol. 15, no. 06, pp. P06002, 2020.'
  id: totrans-619
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[130] D She, N Peng, M Jia, 和 MG Pecht， “基于Wasserstein距离的深度多特征对抗迁移诊断方法在可变工作条件下，”《仪器学报》，第15卷，第06期，第P06002页，2020年。'
- en: '[131] Xiaolei Yu, Zhibin Zhao, Xingwu Zhang, Chuang Sun, Baogui Gong, Ruqiang
    Yan, and Xuefeng Chen, “Conditional adversarial domain adaptation with discrimination
    embedding for locomotive fault diagnosis,” IEEE Transactions on Instrumentation
    and Measurement, vol. 70, pp. 1–12, 2020.'
  id: totrans-620
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[131] Xiaolei Yu, Zhibin Zhao, Xingwu Zhang, Chuang Sun, Baogui Gong, Ruqiang
    Yan, 和 Xuefeng Chen， “基于判别嵌入的条件对抗域适应用于机车故障诊断，”《IEEE仪器与测量学报》，第70卷，第1–12页，2020年。'
- en: '[132] Feng Li, Tuojiang Tang, Baoping Tang, and Qiyuan He, “Deep convolution
    domain-adversarial transfer learning for fault diagnosis of rolling bearings,”
    Measurement, vol. 169, pp. 108339, 2021.'
  id: totrans-621
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[132] Feng Li, Tuojiang Tang, Baoping Tang, 和 Qiyuan He， “用于滚动轴承故障诊断的深度卷积域对抗迁移学习，”《测量》，第169卷，第108339页，2021年。'
- en: '[133] Yuan Xie and Tao Zhang, “A transfer learning strategy for rotation machinery
    fault diagnosis based on cycle-consistent generative adversarial networks,” in
    2018 Chinese Automation Congress (CAC). IEEE, 2018, pp. 1309–1313.'
  id: totrans-622
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[133] Yuan Xie 和 Tao Zhang， “基于循环一致生成对抗网络的旋转机械故障诊断迁移学习策略，” 见2018年中国自动化大会（CAC）。IEEE，2018年，第1309–1313页。'
- en: '[134] Sonal Dixit, Nishchal K Verma, and AK Ghosh, “Intelligent fault diagnosis
    of rotary machines: Conditional auxiliary classifier gan coupled with meta learning
    using limited data,” IEEE Transactions on Instrumentation and Measurement, vol.
    70, pp. 1–11, 2021.'
  id: totrans-623
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[134] Sonal Dixit, Nishchal K Verma, 和 AK Ghosh， “旋转机械的智能故障诊断：条件辅助分类器GAN结合有限数据的元学习，”《IEEE仪器与测量学报》，第70卷，第1–11页，2021年。'
- en: '[135] Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Michael I Jordan, “Partial
    transfer learning with selective adversarial networks,” in Proceedings of the
    IEEE conference on computer vision and pattern recognition, 2018, pp. 2724–2732.'
  id: totrans-624
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[135] Zhangjie Cao, Mingsheng Long, Jianmin Wang, 和 Michael I Jordan， “带选择性对抗网络的部分迁移学习，”
    见《IEEE计算机视觉与模式识别会议论文集》，2018年，第2724–2732页。'
- en: '[136] Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang, “Partial adversarial
    domain adaptation,” in Proceedings of the European Conference on Computer Vision
    (ECCV), 2018, pp. 135–150.'
  id: totrans-625
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[136] Zhangjie Cao, Lijia Ma, Mingsheng Long, 和 Jianmin Wang， “部分对抗域适应，” 见《欧洲计算机视觉会议（ECCV）论文集》，2018年，第135–150页。'
- en: '[137] Jinyang Jiao, Ming Zhao, Jing Lin, and Chuancang Ding, “Classifier inconsistency-based
    domain adaptation network for partial transfer intelligent diagnosis,” IEEE Transactions
    on Industrial Informatics, vol. 16, no. 9, pp. 5965–5974, 2019.'
  id: totrans-626
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[137] Jinyang Jiao, Ming Zhao, Jing Lin, 和 Chuancang Ding， “基于分类器不一致性的域适应网络用于部分迁移智能诊断，”《IEEE工业信息学学报》，第16卷，第9期，第5965–5974页，2019年。'
- en: '[138] Weihua Li, Zhuyun Chen, and Guolin He, “A novel weighted adversarial
    transfer network for partial domain fault diagnosis of machinery,” IEEE Transactions
    on Industrial Informatics, vol. 17, no. 3, pp. 1753–1762, 2020.'
  id: totrans-627
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[138] Weihua Li, Zhuyun Chen, 和 Guolin He， “一种新型加权对抗迁移网络用于机械部分域故障诊断，”《IEEE工业信息学学报》，第17卷，第3期，第1753–1762页，2020年。'
- en: '[139] Xiang Li and Wei Zhang, “Deep learning-based partial domain adaptation
    method on intelligent machinery fault diagnostics,” IEEE Transactions on Industrial
    Electronics, vol. 68, no. 5, pp. 4351–4361, 2020.'
  id: totrans-628
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[139] Xiang Li 和 Wei Zhang， “基于深度学习的智能机械故障诊断中的部分域适应方法，”《IEEE工业电子学报》，第68卷，第5期，第4351–4361页，2020年。'
- en: '[140] Xiang Li, Wei Zhang, Hui Ma, Zhong Luo, and Xu Li, “Partial transfer
    learning in machinery cross-domain fault diagnostics using class-weighted adversarial
    networks,” Neural Networks, vol. 129, pp. 313–322, 2020.'
  id: totrans-629
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[140] Xiang Li, Wei Zhang, Hui Ma, Zhong Luo, 和 Xu Li， “使用类加权对抗网络的机械跨域故障诊断中的部分迁移学习，”《神经网络》，第129卷，第313–322页，2020年。'
- en: '[141] Qin Wang, Gabriel Michau, and Olga Fink, “Missing-class-robust domain
    adaptation by unilateral alignment,” IEEE Transactions on Industrial Electronics,
    vol. 68, no. 1, pp. 663–671, 2020.'
  id: totrans-630
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[141] Qin Wang, Gabriel Michau, 和 Olga Fink， “通过单侧对齐进行缺失类鲁棒域适应，”《IEEE工业电子学报》，第68卷，第1期，第663–671页，2020年。'
- en: '[142] Yafei Deng, Delin Huang, Shichang Du, Guilong Li, Chen Zhao, and Jun
    Lv, “A double-layer attention based adversarial network for partial transfer learning
    in machinery fault diagnosis,” Computers in Industry, vol. 127, pp. 103399, 2021.'
  id: totrans-631
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[142] Yafei Deng, Delin Huang, Shichang Du, Guilong Li, Chen Zhao, 和 Jun Lv，
    “用于机械故障诊断的双层注意力对抗网络的部分迁移学习，”《工业计算机》，第127卷，第103399页，2021年。'
- en: '[143] Bin Yang, Chi-Guhn Lee, Yaguo Lei, Naipeng Li, and Na Lu, “Deep partial
    transfer learning network: A method to selectively transfer diagnostic knowledge
    across related machines,” Mechanical Systems and Signal Processing, vol. 156,
    pp. 107618, 2021.'
  id: totrans-632
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[143] Bin Yang、Chi-Guhn Lee、Yaguo Lei、Naipeng Li 和 Na Lu，“深度部分迁移学习网络：一种选择性地转移诊断知识的方法”，《机械系统与信号处理》，第156卷，第107618页，2021年。'
- en: '[144] Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada,
    “Open set domain adaptation by backpropagation,” in Proceedings of the European
    Conference on Computer Vision (ECCV), 2018, pp. 153–168.'
  id: totrans-633
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[144] Kuniaki Saito、Shohei Yamamoto、Yoshitaka Ushiku 和 Tatsuya Harada，“通过反向传播的开放集领域适应”，发表于《欧洲计算机视觉会议论文集（ECCV）》，2018年，第153–168页。'
- en: '[145] Jipu Li, Ruyi Huang, Guolin He, Yixiao Liao, Zhen Wang, and Weihua Li,
    “A two-stage transfer adversarial network for intelligent fault diagnosis of rotating
    machinery with multiple new faults,” IEEE/ASME Transactions on Mechatronics, vol.
    26, no. 3, pp. 1591–1601, 2020.'
  id: totrans-634
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[145] Jipu Li、Ruyi Huang、Guolin He、Yixiao Liao、Zhen Wang 和 Weihua Li，“用于旋转机械的多新故障智能故障诊断的两阶段对抗迁移网络”，《IEEE/ASME
    机电一体化学报》，第26卷，第3期，第1591–1601页，2020年。'
- en: '[146] Jipu Li, Ruyi Huang, Guolin He, Shuhua Wang, Guanghui Li, and Weihua
    Li, “A deep adversarial transfer learning network for machinery emerging fault
    detection,” IEEE Sensors Journal, vol. 20, no. 15, pp. 8413–8422, 2020.'
  id: totrans-635
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[146] Jipu Li、Ruyi Huang、Guolin He、Shuhua Wang、Guanghui Li 和 Weihua Li，“用于机械新兴故障检测的深度对抗迁移学习网络”，《IEEE
    传感器杂志》，第20卷，第15期，第8413–8422页，2020年。'
- en: '[147] Wei Zhang, Xiang Li, Hui Ma, Zhong Luo, and Xu Li, “Open set domain adaptation
    in machinery fault diagnostics using instance-level weighted adversarial learning,”
    IEEE Transactions on Industrial Informatics, vol. 17, no. 11, pp. 7445–7455, 2021.'
  id: totrans-636
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[147] Wei Zhang、Xiang Li、Hui Ma、Zhong Luo 和 Xu Li，“基于实例级加权对抗学习的开放集领域适应在机械故障诊断中的应用”，《IEEE
    工业信息学会会刊》，第17卷，第11期，第7445–7455页，2021年。'
- en: '[148] Kaichao You, Mingsheng Long, Zhangjie Cao, Jianmin Wang, and Michael I
    Jordan, “Universal domain adaptation,” in Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition, 2019, pp. 2720–2729.'
  id: totrans-637
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[148] Kaichao You、Mingsheng Long、Zhangjie Cao、Jianmin Wang 和 Michael I Jordan，“通用领域适应”，发表于《IEEE/CVF
    计算机视觉与模式识别会议论文集》，2019年，第2720–2729页。'
- en: '[149] Wei Zhang, Xiang Li, Hui Ma, Zhong Luo, and Xu Li, “Universal domain
    adaptation in fault diagnostics with hybrid weighted deep adversarial learning,”
    IEEE Transactions on Industrial Informatics, vol. 17, no. 12, pp. 7957–7967, 2021.'
  id: totrans-638
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[149] Wei Zhang、Xiang Li、Hui Ma、Zhong Luo 和 Xu Li，“结合加权深度对抗学习的故障诊断中的通用领域适应”，《IEEE
    工业信息学会会刊》，第17卷，第12期，第7957–7967页，2021年。'
- en: '[150] Xiaolei Yu, Zhibin Zhao, Xingwu Zhang, Qiyang Zhang, Yilong Liu, Chuang
    Sun, and Xuefeng Chen, “Deep learning-based open set fault diagnosis by extreme
    value theory,” IEEE Transactions on Industrial Informatics, pp. 1–1, 2021.'
  id: totrans-639
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[150] Xiaolei Yu、Zhibin Zhao、Xingwu Zhang、Qiyang Zhang、Yilong Liu、Chuang Sun
    和 Xuefeng Chen，“基于深度学习的开放集故障诊断通过极值理论”，《IEEE 工业信息学会会刊》，第1–1页，2021年。'
- en: '[151] Yong Dai, Jian Liu, Xiancong Ren, and Zenglin Xu, “Adversarial training
    based multi-source unsupervised domain adaptation for sentiment analysis,” in
    Proceedings of the AAAI Conference on Artificial Intelligence, 2020, vol. 34,
    pp. 7618–7625.'
  id: totrans-640
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[151] Yong Dai、Jian Liu、Xiancong Ren 和 Zenglin Xu，“基于对抗训练的多源无监督领域适应用于情感分析”，发表于《AAAI
    人工智能会议论文集》，2020年，第34卷，第7618–7625页。'
- en: '[152] Sicheng Zhao, Guangzhi Wang, Shanghang Zhang, Yang Gu, Yaxian Li, Zhichao
    Song, Pengfei Xu, Runbo Hu, Hua Chai, and Kurt Keutzer, “Multi-source distilling
    domain adaptation,” in Proceedings of the AAAI Conference on Artificial Intelligence,
    2020, vol. 34, pp. 12975–12983.'
  id: totrans-641
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[152] Sicheng Zhao、Guangzhi Wang、Shanghang Zhang、Yang Gu、Yaxian Li、Zhichao
    Song、Pengfei Xu、Runbo Hu、Hua Chai 和 Kurt Keutzer，“多源蒸馏领域适应”，发表于《AAAI 人工智能会议论文集》，2020年，第34卷，第12975–12983页。'
- en: '[153] Fei Shen, Yun Hui, Ruqiang Yan, Chuang Sun, and Jiawen Xu, “A new penalty
    domain selection machine enabled transfer learning for gearbox fault recognition,”
    IEEE Transactions on Industrial Electronics, vol. 67, no. 10, pp. 8743–8754, 2020.'
  id: totrans-642
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[153] Fei Shen、Yun Hui、Ruqiang Yan、Chuang Sun 和 Jiawen Xu，“一种新的惩罚域选择机器驱动的迁移学习用于齿轮箱故障识别”，《IEEE
    工业电子学会会刊》，第67卷，第10期，第8743–8754页，2020年。'
- en: '[154] Jun Zhu, Nan Chen, and Changqing Shen, “A new multiple source domain
    adaptation fault diagnosis method between different rotating machines,” IEEE Transactions
    on Industrial Informatics, vol. 17, no. 7, pp. 4788–4797, 2021.'
  id: totrans-643
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[154] Jun Zhu、Nan Chen 和 Changqing Shen，“一种新的多源领域适应故障诊断方法用于不同旋转机械”，《IEEE 工业信息学会会刊》，第17卷，第7期，第4788–4797页，2021年。'
- en: '[155] Behnoush Rezaeianjouybari and Yi Shang, “A novel deep multi-source domain
    adaptation framework for bearing fault diagnosis based on feature-level and task-specific
    distribution alignment,” Measurement, vol. 178, pp. 109359, 2021.'
  id: totrans-644
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[155] Behnoush Rezaeianjouybari 和 Yi Shang，"一种基于特征层级和任务特定分布对齐的新型深度多源领域适配框架，用于轴承故障诊断"，《测量》，第178卷，第109359页，2021年。'
- en: '[156] Yongchao Zhang, Zhaohui Ren, Shihua Zhou, and Tianzhuang Yu, “Adversarial
    domain adaptation with classifier alignment for cross-domain intelligent fault
    diagnosis of multiple source domains,” Measurement Science and Technology, vol.
    32, no. 3, pp. 035102, dec 2020.'
  id: totrans-645
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[156] Yongchao Zhang, Zhaohui Ren, Shihua Zhou, 和 Tianzhuang Yu，"通过分类器对齐进行对抗领域适配，以实现多个源领域的跨领域智能故障诊断"，《测量科学与技术》，第32卷，第3期，第035102页，2020年12月。'
- en: '[157] Ya He, Minghui Hu, Kun Feng, and Zhinong Jiang, “An intelligent fault
    diagnosis scheme using transferred samples for intershaft bearings under variable
    working conditions,” IEEE Access, vol. 8, pp. 203058–203069, 2020.'
  id: totrans-646
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[157] Ya He, Minghui Hu, Kun Feng, 和 Zhinong Jiang，"一种使用转移样本的智能故障诊断方案，用于变工况下的轴间轴承"，《IEEE
    Access》，第8卷，第203058–203069页，2020年。'
- en: '[158] Dongdong Wei, Te Han, Fulei Chu, and Ming Jian Zuo, “Weighted domain
    adaptation networks for machinery fault diagnosis,” Mechanical Systems and Signal
    Processing, vol. 158, pp. 107744, 2021.'
  id: totrans-647
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[158] Dongdong Wei, Te Han, Fulei Chu, 和 Ming Jian Zuo，"用于机械故障诊断的加权领域适配网络"，《机械系统与信号处理》，第158卷，第107744页，2021年。'
- en: '[159] Xiang Li, Wei Zhang, Qian Ding, and Xu Li, “Diagnosing rotating machines
    with weakly supervised data using deep transfer learning,” IEEE Transactions on
    Industrial Informatics, vol. 16, no. 3, pp. 1688–1697, 2020.'
  id: totrans-648
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[159] Xiang Li, Wei Zhang, Qian Ding, 和 Xu Li，"使用深度迁移学习诊断旋转机械的弱监督数据"，《IEEE工业信息学报》，第16卷，第3期，第1688–1697页，2020年。'
- en: '[160] Ziling Huang, Zihao Lei, Guangrui Wen, Xin Huang, Haoxuan Zhou, Ruqiang
    Yan, and Xuefeng Chen, “A multi-source dense adaptation adversarial network for
    fault diagnosis of machinery,” IEEE Transactions on Industrial Electronics, 2021.'
  id: totrans-649
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[160] Ziling Huang, Zihao Lei, Guangrui Wen, Xin Huang, Haoxuan Zhou, Ruqiang
    Yan, 和 Xuefeng Chen，"用于机械故障诊断的多源密集适配对抗网络"，《IEEE工业电子学报》，2021年。'
- en: '[161] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, and Alex C. Kot, “Domain generalization
    with adversarial feature learning,” in 2018 IEEE/CVF Conference on Computer Vision
    and Pattern Recognition, 2018, pp. 5400–5409.'
  id: totrans-650
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[161] Haoliang Li, Sinno Jialin Pan, Shiqi Wang, 和 Alex C. Kot，"通过对抗特征学习进行领域泛化"，发表于2018年IEEE/CVF计算机视觉与模式识别会议，2018年，第5400–5409页。'
- en: '[162] Xiang Li, Wei Zhang, Hui Ma, Zhong Luo, and Xu Li, “Domain generalization
    in rotating machinery fault diagnostics using deep neural networks,” Neurocomputing,
    vol. 403, pp. 409–420, 2020.'
  id: totrans-651
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[162] Xiang Li, Wei Zhang, Hui Ma, Zhong Luo, 和 Xu Li，"利用深度神经网络进行旋转机械故障诊断中的领域泛化"，《神经计算》，第403卷，第409–420页，2020年。'
- en: '[163] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang,
    and Dacheng Tao, “Deep domain generalization via conditional invariant adversarial
    networks,” in Proceedings of the European Conference on Computer Vision (ECCV),
    2018, pp. 624–639.'
  id: totrans-652
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[163] Ya Li, Xinmei Tian, Mingming Gong, Yajing Liu, Tongliang Liu, Kun Zhang,
    和 Dacheng Tao，"通过条件不变对抗网络进行深度领域泛化"，发表于欧洲计算机视觉会议（ECCV），2018年，第624–639页。'
- en: '[164] Huailiang Zheng, Yuantao Yang, Jiancheng Yin, Yuqing Li, Rixin Wang,
    and Minqiang Xu, “Deep domain generalization combining a priori diagnosis knowledge
    toward cross-domain fault diagnosis of rolling bearing,” IEEE Transactions on
    Instrumentation and Measurement, vol. 70, pp. 1–11, 2021.'
  id: totrans-653
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[164] Huailiang Zheng, Yuantao Yang, Jiancheng Yin, Yuqing Li, Rixin Wang,
    和 Minqiang Xu，"结合先验诊断知识进行深度领域泛化，以实现滚动轴承的跨领域故障诊断"，《IEEE仪器与测量学报》，第70卷，第1–11页，2021年。'
- en: '[165] Yixiao Liao, Ruyi Huang, Jipu Li, Zhuyun Chen, and Weihua Li, “Deep semisupervised
    domain generalization network for rotary machinery fault diagnosis under variable
    speed,” IEEE Transactions on Instrumentation and Measurement, vol. 69, no. 10,
    pp. 8064–8075, 2020.'
  id: totrans-654
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[165] Yixiao Liao, Ruyi Huang, Jipu Li, Zhuyun Chen, 和 Weihua Li，"用于可变速度下旋转机械故障诊断的深度半监督领域泛化网络"，《IEEE仪器与测量学报》，第69卷，第10期，第8064–8075页，2020年。'
- en: '[166] Yuantao Yang, Jiancheng Yin, Huailiang Zheng, Yuqing Li, Minqiang Xu,
    and Yushu Chen, “Learn generalization feature via convolutional neural network:
    A fault diagnosis scheme toward unseen operating conditions,” IEEE Access, vol.
    8, pp. 91103–91115, 2020.'
  id: totrans-655
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[166] Yuantao Yang, Jiancheng Yin, Huailiang Zheng, Yuqing Li, Minqiang Xu,
    和 Yushu Chen，"通过卷积神经网络学习泛化特征：一种针对未见操作条件的故障诊断方案"，《IEEE Access》，第8卷，第91103–91115页，2020年。'
- en: '[167] Qiyang Zhang, Zhibin Zhao, Xingwu Zhang, Yilong Liu, Chuang Sun, Ming
    Li, Shibin Wang, and Xuefeng Chen, “Conditional adversarial domain generalization
    with a single discriminator for bearing fault diagnosis,” IEEE Transactions on
    Instrumentation and Measurement, vol. 70, pp. 1–15, 2021.'
  id: totrans-656
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[167] Qiyang Zhang, Zhibin Zhao, Xingwu Zhang, Yilong Liu, Chuang Sun, Ming
    Li, Shibin Wang 和 Xuefeng Chen，“基于单一鉴别器的条件对抗领域泛化用于轴承故障诊断”，《IEEE仪器与测量学报》，第70卷，第1–15页，2021年。'
- en: '[168] Te Han, Yan-Fu Li, and Min Qian, “A hybrid generalization network for
    intelligent fault diagnosis of rotating machinery under unseen working conditions,”
    IEEE Transactions on Instrumentation and Measurement, 2021.'
  id: totrans-657
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[168] Te Han, Yan-Fu Li 和 Min Qian，“一种用于智能故障诊断的混合泛化网络，适用于未知工作条件下的旋转机械”，《IEEE仪器与测量学报》，2021年。'
- en: '[169] Case Western Reserve University, “Case Western Reserve University (CWRU)
    Bearing Data Center, [Online],” Available: [https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/](https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/),
    accessed on August 2019.'
  id: totrans-658
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[169] Case Western Reserve University，“凯斯西储大学（CWRU）轴承数据中心，[在线]”，可用：[https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/](https://csegroups.case.edu/bearingdatacenter/pages/download-data-file/)，访问时间：2019年8月。'
- en: '[170] Christian Lessmeier, James Kuria Kimotho, Detmar Zimmer, and Walter Sextro,
    “Condition monitoring of bearing damage in electromechanical drive systems by
    using motor current signals of electric motors: A benchmark data set for data-driven
    classification,” in Proceedings of the European conference of the prognostics
    and health management society, 2016, pp. 05–08.'
  id: totrans-659
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[170] Christian Lessmeier, James Kuria Kimotho, Detmar Zimmer 和 Walter Sextro，“通过使用电动机的电流信号对机电驱动系统中的轴承损伤进行状态监测：一个数据驱动分类的基准数据集”，在《欧洲预测与健康管理学会会议论文集》，2016年，第05–08页。'
- en: '[171] Christian Lessmeier, “et al. KAt-DataCenter, Chair of Design and Drive
    Technology, Paderborn University,” Available: [https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/](https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/),
    accessed on August 2019.'
  id: totrans-660
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[171] Christian Lessmeier，“等人。KAt-DataCenter，帕德博恩大学设计与驱动技术教研室”，可用：[https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/](https://mb.uni-paderborn.de/kat/forschung/datacenter/bearing-datacenter/)，访问时间：2019年8月。'
- en: '[172] Ke Li, “School of Mechanical Engineering, Jiangnan University,” Available:
    [http://mad-net.org:8765/explore.html?t=0.5831516555847212.](http://mad-net.org:8765/explore.html?t=0.5831516555847212.),
    accessed on August 2019.'
  id: totrans-661
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[172] Ke Li，“江南大学机械工程学院”，可用：[http://mad-net.org:8765/explore.html?t=0.5831516555847212.](http://mad-net.org:8765/explore.html?t=0.5831516555847212.)，访问时间：2019年8月。'
- en: '[173] Ke Li, Xueliang Ping, Huaqing Wang, Peng Chen, and Yi Cao, “Sequential
    fuzzy diagnosis method for motor roller bearing in variable operating conditions
    based on vibration analysis,” Sensors, vol. 13, no. 6, pp. 8013–8041, 2013.'
  id: totrans-662
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[173] Ke Li, Xueliang Ping, Huaqing Wang, Peng Chen 和 Yi Cao，“基于振动分析的变工况下电机滚动轴承的序列模糊诊断方法”，《传感器》，第13卷，第6期，第8013–8041页，2013年。'
- en: '[174] PHMSociety, “PHM09 Data Challenge,” Available: [https://www.phmsociety.org/competition/PHM/09/apparatus](https://www.phmsociety.org/competition/PHM/09/apparatus),
    accessed on August 2019.'
  id: totrans-663
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[174] PHMSociety，“PHM09数据挑战”，可用：[https://www.phmsociety.org/competition/PHM/09/apparatus](https://www.phmsociety.org/competition/PHM/09/apparatus)，访问时间：2019年8月。'
- en: '[175] Siyu Shao, Stephen McAleer, Ruqiang Yan, and Pierre Baldi, “Mechanical
    dataset,” Available: [http://mlmechanics.ics.uci.edu./](http://mlmechanics.ics.uci.edu./),
    accessed on August 2019.'
  id: totrans-664
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[175] Siyu Shao, Stephen McAleer, Ruqiang Yan 和 Pierre Baldi，“机械数据集”，可用：[http://mlmechanics.ics.uci.edu./](http://mlmechanics.ics.uci.edu./)，访问时间：2019年8月。'
- en: '[176] Hong Liu, Zhangjie Cao, Mingsheng Long, Jianmin Wang, and Qiang Yang,
    “Separate to adapt: Open set domain adaptation via progressive separation,” in
    Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition,
    2019, pp. 2927–2936.'
  id: totrans-665
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[176] Hong Liu, Zhangjie Cao, Mingsheng Long, Jianmin Wang 和 Qiang Yang，“分开适应：通过渐进分离实现开放集领域适应”，在《IEEE/CVF计算机视觉与模式识别会议论文集》，2019年，第2927–2936页。'
- en: '[177] Bo Fu, Zhangjie Cao, Mingsheng Long, and Jianmin Wang, “Learning to detect
    open classes for universal domain adaptation,” in European Conference on Computer
    Vision. Springer, 2020, pp. 567–583.'
  id: totrans-666
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[177] Bo Fu, Zhangjie Cao, Mingsheng Long 和 Jianmin Wang，“学习检测开放类别以实现通用领域适应”，在《欧洲计算机视觉会议》。Springer，2020年，第567–583页。'
- en: '[178] Jianrong Wang, Kai Fan, and Wanshan Wang, “Integration of fuzzy ahp and
    fpp with topsis methodology for aeroengine health assessment,” Expert Systems
    with Applications, vol. 37, no. 12, pp. 8516–8526, 2010.'
  id: totrans-667
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[178] Jianrong Wang, Kai Fan, 和 Wanshan Wang，“模糊AHP与FPP结合TOPSIS方法在航空发动机健康评估中的应用”，《专家系统与应用》，第37卷，第12期，第8516–8526页，2010年。'
- en: '[179] Yi-Hai He, Lin-Bo Wang, Zhen-Zhen He, and Min Xie, “A fuzzy topsis and
    rough set based approach for mechanism analysis of product infant failure,” Engineering
    Applications of Artificial Intelligence, vol. 47, pp. 25–37, 2016.'
  id: totrans-668
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[179] Yi-Hai He、Lin-Bo Wang、Zhen-Zhen He 和 Min Xie，“基于模糊TOPSIS和粗糙集的产品早期故障机制分析方法”，《工程人工智能应用》，第47卷，第25–37页，2016年。'
- en: '[180] Wen Jiang, Meijuan Wang, Xinyang Deng, and Linfeng Gou, “Fault diagnosis
    based on topsis method with manhattan distance,” Advances in Mechanical Engineering,
    vol. 11, no. 3, pp. 1687814019833279, 2019.'
  id: totrans-669
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[180] Wen Jiang、Meijuan Wang、Xinyang Deng 和 Linfeng Gou，“基于曼哈顿距离的TOPSIS方法故障诊断”，《机械工程进展》，第11卷，第3期，第1687814019833279页，2019年。'
- en: '[181] Xavier Glorot, Antoine Bordes, and Yoshua Bengio, “Domain adaptation
    for large-scale sentiment classification: A deep learning approach,” in Proceedings
    of the 28th international conference on machine learning (ICML-11), 2011, pp.
    513–520.'
  id: totrans-670
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[181] Xavier Glorot、Antoine Bordes 和 Yoshua Bengio，“大规模情感分类的领域适应：一种深度学习方法”，发表于第28届国际机器学习会议（ICML-11），2011年，第513–520页。'
- en: '[182] Jason Yosinski, Jeff Clune, Yoshua Bengio, and Hod Lipson, “How transferable
    are features in deep neural networks?,” in Advances in neural information processing
    systems, 2014, pp. 3320–3328.'
  id: totrans-671
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[182] Jason Yosinski、Jeff Clune、Yoshua Bengio 和 Hod Lipson，“深度神经网络中的特征可转移性如何？”，发表于神经信息处理系统进展，2014年，第3320–3328页。'
- en: '[183] Matthew D Zeiler and Rob Fergus, “Visualizing and understanding convolutional
    networks,” in European conference on computer vision. Springer, 2014, pp. 818–833.'
  id: totrans-672
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[183] Matthew D Zeiler 和 Rob Fergus，“可视化和理解卷积网络”，发表于欧洲计算机视觉会议。Springer，2014年，第818–833页。'
- en: '[184] Ramprasaath R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna
    Vedantam, Devi Parikh, and Dhruv Batra, “Grad-cam: Visual explanations from deep
    networks via gradient-based localization,” in Proceedings of the IEEE International
    Conference on Computer Vision, 2017, pp. 618–626.'
  id: totrans-673
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[184] Ramprasaath R Selvaraju、Michael Cogswell、Abhishek Das、Ramakrishna Vedantam、Devi
    Parikh 和 Dhruv Batra，“Grad-CAM：通过基于梯度的定位从深度网络中生成的视觉解释”，发表于IEEE国际计算机视觉会议，2017年，第618–626页。'
- en: '[185] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
    Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin, “Attention is all you need,”
    in Advances in neural information processing systems, 2017, pp. 5998–6008.'
  id: totrans-674
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[185] Ashish Vaswani、Noam Shazeer、Niki Parmar、Jakob Uszkoreit、Llion Jones、Aidan
    N Gomez、Łukasz Kaiser 和 Illia Polosukhin，“注意力即你所需”，发表于神经信息处理系统进展，2017年，第5998–6008页。'
- en: '[186] Mengmeng Jing, Jingjing Li, Lei Zhu, Zhengming Ding, Ke Lu, and Yang
    Yang, “Balanced open set domain adaptation via centroid alignment,” in Proceedings
    of the AAAI Conference on Artificial Intelligence, 2021, vol. 35, pp. 8013–8020.'
  id: totrans-675
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[186] Mengmeng Jing、Jingjing Li、Lei Zhu、Zhengming Ding、Ke Lu 和 Yang Yang，“通过质心对齐的平衡开放集领域适应”，发表于AAAI人工智能会议，2021年，第35卷，第8013–8020页。'
- en: '[187] Jingyao Wu, Zhibin Zhao, Chuang Sun, Ruqiang Yan, and Xuefeng Chen, “Few-shot
    transfer learning for intelligent fault diagnosis of machine,” Measurement, vol.
    166, pp. 108202, 2020.'
  id: totrans-676
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[187] Jingyao Wu、Zhibin Zhao、Chuang Sun、Ruqiang Yan 和 Xuefeng Chen，“用于智能故障诊断的少样本迁移学习”，《测量》，第166卷，第108202页，2020年。'
- en: '[188] Yang Liu, Yan Kang, Chaoping Xing, Tianjian Chen, and Qiang Yang, “A
    secure federated transfer learning framework,” IEEE Intelligent Systems, vol.
    35, no. 4, pp. 70–82, 2020.'
  id: totrans-677
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[188] Yang Liu、Yan Kang、Chaoping Xing、Tianjian Chen 和 Qiang Yang，“一个安全的联邦迁移学习框架”，《IEEE智能系统》，第35卷，第4期，第70–82页，2020年。'
- en: '[189] Wei Zhang and Xiang Li, “Federated transfer learning for intelligent
    fault diagnostics using deep adversarial networks with data privacy,” IEEE/ASME
    Transactions on Mechatronics, 2021.'
  id: totrans-678
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[189] Wei Zhang 和 Xiang Li，“基于数据隐私的深度对抗网络的智能故障诊断的联邦迁移学习”，《IEEE/ASME机电一体化学报》，2021年。'
- en: '[190] Yarin Gal and Zoubin Ghahramani, “Dropout as a bayesian approximation:
    Representing model uncertainty in deep learning,” in international conference
    on machine learning. PMLR, 2016, pp. 1050–1059.'
  id: totrans-679
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[190] Yarin Gal 和 Zoubin Ghahramani，“Dropout作为贝叶斯近似：在深度学习中表示模型不确定性”，发表于国际机器学习会议。PMLR，2016年，第1050–1059页。'
- en: '[191] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell, “Simple
    and scalable predictive uncertainty estimation using deep ensembles,” in Proceedings
    of the 31st International Conference on Neural Information Processing Systems,
    2017, pp. 6405–6416.'
  id: totrans-680
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[191] Balaji Lakshminarayanan、Alexander Pritzel 和 Charles Blundell，“使用深度集成的简单且可扩展的预测不确定性估计”，发表于第31届国际神经信息处理系统会议，2017年，第6405–6416页。'
- en: '[192] Zhedong Zheng and Yi Yang, “Rectifying pseudo label learning via uncertainty
    estimation for domain adaptive semantic segmentation,” International Journal of
    Computer Vision, vol. 129, no. 4, pp. 1106–1120, 2021.'
  id: totrans-681
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[192] 郑哲东和杨毅，“通过不确定性估计纠正伪标签学习以进行领域自适应语义分割，”《国际计算机视觉杂志》，第129卷，第4期，第1106–1120页，2021年。'
- en: See pages 1-8 of [AppendixA/EvaluationResults.pdf](AppendixA/EvaluationResults.pdf)
  id: totrans-682
  prefs: []
  type: TYPE_NORMAL
  zh: 请参阅[AppendixA/EvaluationResults.pdf](AppendixA/EvaluationResults.pdf)的第1-8页。
