["```py\nset_rf_samples(50000)m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, \n        max_features=0.5, n_jobs=-1, oob_score=**True**)\nm.fit(X_train, y_train)\nprint_score(m)\n```", "```py\nto_keep = fi[fi.imp>0.005].cols; len(to_keep)\n```", "```py\ndf_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', max_n_cat=7) X_train, X_valid = split_vals(df_trn2, n_trn) m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, \n       max_features=0.6, n_jobs=-1, oob_score=**True**) \nm.fit(X_train, y_train) \nprint_score(m)*[0.2132925755978791, 0.25212838463780185, 0.90966193351324276, 0.88647501408921581, 0.89194147155121262]*\n```", "```py\nfrom scipy.cluster import hierarchy as hccorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, \n      orientation='left', leaf_font_size=16)\nplt.show()\n```", "```py\n**corr_condensed = hc.distance.squareform(1-corr)****z = hc.linkage(corr_condensed, method='average')****dendrogram = hc.dendrogram(z, labels=df_keep.columns, \n      orientation='left', leaf_font_size=16)**\n```", "```py\ndef get_oob(df):\n    m = RandomForestRegressor(n_estimators=30, min_samples_leaf=5, \n           max_features=0.6, n_jobs=-1, oob_score=True)\n    x, _ = split_vals(df, n_trn)\n    m.fit(x, y_train)\n    return m.oob_score_\n```", "```py\nget_oob(df_keep)*0.89019425494301454*\n```", "```py\nfor c in ('saleYear', 'saleElapsed', 'fiModelDesc', 'fiBaseModel', \n          'Grouser_Tracks', 'Coupler_System'):\n    print(c, get_oob(df_keep.drop(c, axis=1)))\n```", "```py\nsaleYear 0.889037446375\nsaleElapsed 0.886210803445\nfiModelDesc 0.888540591321\nfiBaseModel 0.88893958239\nGrouser_Tracks 0.890385236272\nCoupler_System 0.889601052658\n```", "```py\nto_drop = ['saleYear', 'fiBaseModel', 'Grouser_Tracks']\nget_oob(df_keep.drop(to_drop, axis=1))*0.88858458047200739*\n```", "```py\ndf_keep.drop(to_drop, axis=1, inplace=**True**)\nX_train, X_valid = split_vals(df_keep, n_trn)np.save('tmp/keep_cols.npy', np.array(df_keep.columns))keep_cols = np.load('tmp/keep_cols.npy')\ndf_keep = df_trn[keep_cols]\n```", "```py\nreset_rf_samples()m = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, max_features=0.5, n_jobs=-1, oob_score=**True**)\nm.fit(X_train, y_train)\nprint_score(m)*[0.12615142089579687, 0.22781819082173235, 0.96677727309424211, 0.90731173105384466, 0.9084359846323049]*\n```", "```py\n**from** **pdpbox** **import** pdp\n**from** **plotnine** **import** *\n```", "```py\nset_rf_samples(50000)\n```", "```py\ndf_trn2, y_trn, nas = proc_df(df_raw, 'SalePrice', **max_n_cat**=7)\nX_train, X_valid = split_vals(df_trn2, n_trn)\nm = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, \n       max_features=0.6, n_jobs=-1)\nm.fit(X_train, y_train);\n```", "```py\nplot_fi(rf_feat_importance(m, df_trn2)[:10]);\n```", "```py\ndf_raw.plot('YearMade', 'saleElapsed', 'scatter', alpha=0.01, figsize=(10,8));\n```", "```py\nx_all = **get_sample**(df_raw[df_raw.YearMade>1930], 500)ggplot(x_all, aes('YearMade', 'SalePrice'))+stat_smooth(se=**True**, \n       method='loess')\n```", "```py\nggplot(x_all, aes('YearMade', 'SalePrice'))+stat_smooth(se=**True**, \n       method='loess')\n```", "```py\nx = get_sample(X_train[X_train.YearMade>1930], 500)\n```", "```py\n**def** plot_pdp(feat, clusters=**None**, feat_name=**None**):\n    feat_name = feat_name **or** feat\n    p = pdp.pdp_isolate(m, x, feat)\n    **return** pdp.pdp_plot(p, feat_name, plot_lines=**True**, \n                        cluster=clusters **is** **not** **None**, \n                        n_cluster_centers=clusters)plot_pdp('YearMade')\n```", "```py\nplot_pdp('YearMade', clusters=5) \n```", "```py\nfeats = ['saleElapsed', 'YearMade']\np = pdp.pdp_interact(m, x, feats)\npdp.pdp_interact_plot(p, feats)\n```", "```py\nplot_pdp(['Enclosure_EROPS w AC', 'Enclosure_EROPS', \n         'Enclosure_OROPS'], 5, 'Enclosure')\n```", "```py\ndf_raw.YearMade[df_raw.YearMade<1950] = 1950\ndf_keep['age'] = df_raw['age'] = df_raw.saleYear-df_raw.YearMadeX_train, X_valid = split_vals(df_keep, n_trn)\nm = RandomForestRegressor(n_estimators=40, min_samples_leaf=3, \n                          max_features=0.6, n_jobs=-1)\nm.fit(X_train, y_train)\nplot_fi(rf_feat_importance(m, df_keep));\n```", "```py\n**from** **treeinterpreter** **import** treeinterpreter **as** tidf_train, df_valid = split_vals(df_raw[df_keep.columns], n_trn)\n```", "```py\nrow = X_valid.values[**None**,0]; row\n```", "```py\nprediction, bias, contributions = ti.predict(m, row)\n```", "```py\nprediction[0], bias[0]*(9.1909688098736275, 10.10606580677884)*idxs = np.argsort(contributions[0])[o **for** o **in** zip(df_keep.columns[idxs], df_valid.iloc[0][idxs], contributions[0][idxs])]\n```", "```py\n[('ProductSize', 'Mini', -0.54680742853695008),\n ('age', 11, -0.12507089451852943),\n ('fiProductClassDesc',\n  'Hydraulic Excavator, Track - 3.0 to 4.0 Metric Tons',\n  -0.11143111128570773),\n ('fiModelDesc', 'KX1212', -0.065155113754146801),\n ('fiSecondaryDesc', nan, -0.055237427792181749),\n ('Enclosure', 'EROPS', -0.050467175593900217),\n ('fiModelDescriptor', nan, -0.042354676935508852),\n ('saleElapsed', 7912, -0.019642242073500914),\n ('saleDay', 16, -0.012812993479652724),\n ('Tire_Size', nan, -0.0029687660942271598),\n ('SalesID', 4364751, -0.0010443985823001434),\n ('saleDayofyear', 259, -0.00086540581130196688),\n ('Drive_System', nan, 0.0015385818526195915),\n ('Hydraulics', 'Standard', 0.0022411701338458821),\n ('state', 'Ohio', 0.0037587658190299409),\n ('ProductGroupDesc', 'Track Excavators', 0.0067688906745931197),\n ('ProductGroup', 'TEX', 0.014654732626326661),\n ('MachineID', 2300944, 0.015578052196894499),\n ('Hydraulics_Flow', nan, 0.028973749866174004),\n ('ModelID', 665, 0.038307429579276284),\n ('Coupler_System', nan, 0.052509808150765114),\n ('YearMade', 1999, 0.071829996446492878)]\n```", "```py\ncontributions[0].sum()*-0.7383536391949419*\n```"]