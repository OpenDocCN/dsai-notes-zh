- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:06:28'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:06:28'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1903.02026] Deep Learning in Medical Image Registration: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1903.02026] 深度学习在医学图像配准中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1903.02026](https://ar5iv.labs.arxiv.org/html/1903.02026)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1903.02026](https://ar5iv.labs.arxiv.org/html/1903.02026)
- en: '∎ ¹¹institutetext: G. Haskins, U. Kruger, P. Yan* ²²institutetext: Department
    of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '∎ ¹¹institutetext: G. Haskins, U. Kruger, P. Yan* ²²institutetext: 生物医学工程系，伦斯勒理工学院，美国纽约州特洛伊市12180'
- en: Asterisk indicates corresponding author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 星号表示通讯作者
- en: 'Tel.: +1-518-276-4476'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '电话: +1-518-276-4476'
- en: '²²email: yanp2@rpi.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '²²邮箱: yanp2@rpi.edu'
- en: 'Deep Learning in Medical Image Registration: A Survey'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在医学图像配准中的应用：综述
- en: 'Grant Haskins    Uwe Kruger    Pingkun Yan This work was partially supported
    by NIH/NIBIB under awards R21EB028001 and R01EB027898, and NIH/NCI under a Bench-to-Bedside
    award.This is a pre-print of an article published in Machine Vision and Applications.
    The final authenticated version is available online at: https://doi.org/10.1007/s00138-020-01060-x'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Grant Haskins    Uwe Kruger    Pingkun Yan 本研究部分由NIH/NIBIB资助，奖项为R21EB028001和R01EB027898，以及NIH/NCI资助的Bench-to-Bedside奖。本工作为《机器视觉与应用》上发表的文章的预印本。最终认证版本可在线获取：https://doi.org/10.1007/s00138-020-01060-x
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The establishment of image correspondence through robust image registration
    is critical to many clinical tasks such as image fusion, organ atlas creation,
    and tumor growth monitoring, and is a very challenging problem. Since the beginning
    of the recent deep learning renaissance, the medical imaging research community
    has developed deep learning based approaches and achieved the state-of-the-art
    in many applications, including image registration. The rapid adoption of deep
    learning for image registration applications over the past few years necessitates
    a comprehensive summary and outlook, which is the main scope of this survey. This
    requires placing a focus on the different research areas as well as highlighting
    challenges that practitioners face. This survey, therefore, outlines the evolution
    of deep learning based medical image registration in the context of both research
    challenges and relevant innovations in the past few years. Further, this survey
    highlights future research directions to show how this field may be possibly moved
    forward to the next level.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过鲁棒图像配准建立图像对应关系对许多临床任务至关重要，如图像融合、器官图谱创建和肿瘤生长监测，并且这是一个非常具有挑战性的问题。自最近深度学习复兴以来，医学影像研究界开发了基于深度学习的方法，并在许多应用中取得了最先进的成果，包括图像配准。近年来深度学习在图像配准应用中的快速采用需要一个全面的总结和展望，这也是本综述的主要范围。这要求关注不同的研究领域，并突出实践者面临的挑战。因此，本综述概述了在过去几年中基于深度学习的医学图像配准的演变，既包括研究挑战，也包括相关创新。此外，本综述还强调了未来的研究方向，以展示该领域可能如何推进到下一个阶段。
- en: 1 INTRODUCTION
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Image registration is the process of transforming different image datasets
    into one coordinate system with matched imaging contents, which has significant
    applications in medicine. Registration may be necessary when analyzing a pair
    of images that were acquired from different viewpoints, at different times, or
    using different sensors/modalities Hill et al. ([2001](#bib.bib41)); Zitova and
    Flusser ([2003](#bib.bib122)). Until recently, image registration was mostly performed
    manually by clinicians. However, many registration tasks can be quite challenging
    and the quality of manual alignments are highly dependent upon the expertise of
    the user, which can be clinically disadvantageous. To address the potential shortcomings
    of manual registration, automatic registration has been developed. Although other
    methods for automatic image registration have been extensively explored prior
    to (and during) the deep learning renaissance, deep learning has changed the landscape
    of image registration research Ambinder ([2005](#bib.bib4)). Ever since the success
    of AlexNet in the ImageNet challenge of 2012 Alom et al. ([2018](#bib.bib3)),
    deep learning has allowed for state-of-the-art performance in many computer vision
    tasks including, but not limited to: object detection Ren et al. ([2015](#bib.bib84)),
    feature extraction He et al. ([2016](#bib.bib37)), segmentation Ronneberger et al.
    ([2015](#bib.bib87)), image classification Alom et al. ([2018](#bib.bib3)), image
    denoising Yang et al. ([2018](#bib.bib112)), and image reconstruction Yao et al.
    ([2018](#bib.bib115)).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准是将不同的图像数据集转换到一个坐标系统中，以匹配的影像内容，这在医学领域具有重要应用。当分析一对从不同视角、不同时间或使用不同传感器/模态获取的图像时，可能需要进行配准
    Hill et al. ([2001](#bib.bib41)); Zitova and Flusser ([2003](#bib.bib122))。直到最近，图像配准大多由临床医生手动完成。然而，许多配准任务可能相当具有挑战性，并且手动对齐的质量高度依赖于用户的专业知识，这可能对临床不利。为了应对手动配准的潜在不足，自动配准技术应运而生。尽管在深度学习复兴之前（及期间）已经广泛探索了其他自动图像配准方法，但深度学习改变了图像配准研究的格局
    Ambinder ([2005](#bib.bib4))。自从2012年AlexNet在ImageNet挑战赛中取得成功以来 Alom et al. ([2018](#bib.bib3))，深度学习使许多计算机视觉任务实现了最先进的性能，包括但不限于：目标检测
    Ren et al. ([2015](#bib.bib84))，特征提取 He et al. ([2016](#bib.bib37))，分割 Ronneberger
    et al. ([2015](#bib.bib87))，图像分类 Alom et al. ([2018](#bib.bib3))，图像去噪 Yang et
    al. ([2018](#bib.bib112))，以及图像重建 Yao et al. ([2018](#bib.bib115))。
- en: Initially, deep learning was successfully used to augment the performance of
    iterative, intensity based registration Cheng et al. ([2018](#bib.bib18)); Haskins
    et al. ([2019](#bib.bib36)); Simonovsky et al. ([2016](#bib.bib96)). Soon after
    this initial application, several groups investigated the intuitive application
    of reinforcement learning to registration Liao et al. ([2017](#bib.bib62)); Ma
    et al. ([2017](#bib.bib71)); Miao et al. ([2017](#bib.bib76)). Further, demand
    for faster registration methods later motivated the development of deep learning
    based one-step transformation estimation techniques and challenges associated
    with procuring/generating ground truth data have recently motivated many groups
    to develop unsupervised frameworks for one-step transformation estimation de Vos
    et al. ([2018](#bib.bib23)); Li and Fan ([2018](#bib.bib61)). One of the hurdles
    associated with this framework is the familiar challenge of image similarity quantification
    Heinrich et al. ([2012](#bib.bib38)); Viola and Wells III ([1997](#bib.bib106)).
    Recent efforts that use information theory based similarity metrics de Vos et al.
    ([2018](#bib.bib23)), segmentations of anatomical structures Hu et al. ([2018c](#bib.bib44)),
    and generative adversarial network like frameworks Fan et al. ([2018a](#bib.bib30))
    to address this challenge have shown promising results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，深度学习成功地用于提升基于强度的迭代配准性能 Cheng et al. ([2018](#bib.bib18)); Haskins et al.
    ([2019](#bib.bib36)); Simonovsky et al. ([2016](#bib.bib96))。在这种初步应用之后不久，几个研究小组调查了将强化学习直观应用于配准的可能性
    Liao et al. ([2017](#bib.bib62)); Ma et al. ([2017](#bib.bib71)); Miao et al.
    ([2017](#bib.bib76))。此外，对更快配准方法的需求后来促使了基于深度学习的一步变换估计技术的发展，并且最近获取/生成真实数据的挑战促使许多小组开发了无监督的一步变换估计框架
    de Vos et al. ([2018](#bib.bib23)); Li and Fan ([2018](#bib.bib61))。与这一框架相关的一个难题是图像相似性量化的挑战
    Heinrich et al. ([2012](#bib.bib38)); Viola and Wells III ([1997](#bib.bib106))。最近利用基于信息论的相似性度量
    de Vos et al. ([2018](#bib.bib23))、解剖结构分割 Hu et al. ([2018c](#bib.bib44)) 和类似生成对抗网络的框架
    Fan et al. ([2018a](#bib.bib30)) 来应对这一挑战的努力已经显示出令人鼓舞的结果。
- en: 'Figure [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image
    Registration: A Survey") shows the various categorizations of different deep learning
    based registration methods. On the other hand, Figure [2](#S1.F2 "Figure 2 ‣ 1
    INTRODUCTION ‣ Deep Learning in Medical Image Registration: A Survey") shows the
    observed growing interest in deep learning based registration methods according
    to the number of published papers in recent years. As the trends visualized in
    Figures [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image
    Registration: A Survey") and [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning
    in Medical Image Registration: A Survey") suggest, this field is moving very quickly
    to surmount the hurdles associated with deep learning based medical image registration
    and several groups have already enjoyed significant successes for their applications
    Hu et al. ([2018c](#bib.bib44)); Liu et al. ([2018](#bib.bib65)); Simonovsky et al.
    ([2016](#bib.bib96)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration:
    A Survey") 展示了不同深度学习基础配准方法的各种分类。另一方面，图 [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣
    Deep Learning in Medical Image Registration: A Survey") 展示了根据近年来发表的论文数量对深度学习基础配准方法的日益增长的兴趣。如图
    [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration:
    A Survey") 和 [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical
    Image Registration: A Survey") 所示的趋势表明，该领域正在快速发展，以克服与深度学习基础的医学图像配准相关的障碍，并且已有多个研究小组在其应用中取得了显著成功，如
    Hu 等人（[2018c](#bib.bib44)）；Liu 等人（[2018](#bib.bib65)）；Simonovsky 等人（[2016](#bib.bib96)）。'
- en: '![Refer to caption](img/3d1baf673cb5d7443a073fe632ddc851.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3d1baf673cb5d7443a073fe632ddc851.png)'
- en: 'Figure 1: An overview of deep learning based medical image registration broken
    down by approach type. The popular research directions are written in bold.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：深度学习基础的医学图像配准方法概述，按方法类型分类。流行的研究方向用**粗体**标出。
- en: 'Therefore, the purpose of this article is to comprehensively survey the field
    of deep learning based medical image registration, highlight common challenges
    that practitioners face, and discuss future research directions that may address
    these challenges. Deep learning belongs to a class of machine learning that uses
    neural networks with a large number of layers to learn representations of data
    Goodfellow et al. ([2016](#bib.bib34)); Schmidhuber ([2015](#bib.bib91)). When
    discussing neural networks it is important to provide insight into the different
    types of neural networks that can be used for various applications, the notable
    architectures that were recently invented to tackle engineering problems, and
    the variety of strategies that are used for training neural networks. Therefore,
    this deep learning introduction section is divided into three sections: Neural
    Network Types, Network Architectures, and Training Paradigms and Strategies. Note
    that there are many publicly available libraries that can be used to build the
    networks described in the section, for example TensorFlow Abadi et al. ([2016](#bib.bib1)),
    MXNet Chen et al. ([2015](#bib.bib16)), Keras Chollet et al. ([2015](#bib.bib20)),
    Caffe Jia et al. ([2014](#bib.bib49)), and PyTorch Paszke et al. ([2017](#bib.bib82)).
    Detailed discussion of deep learning based medical image analysis and various
    deep learning research directions is outside of the scope of this article. Comprehensive
    review articles that survey the application of deep learning to medical image
    analysis Lee et al. ([2017](#bib.bib59)); Litjens et al. ([2017](#bib.bib63)),
    reinforcement learning Kaelbling et al. ([1996](#bib.bib51)), and the application
    of GANs to medical image analysis Kazeminia et al. ([2018](#bib.bib52)) are recommended
    to the interested readers. In this article, the surveyed methods were divided
    into the following three categories: Deep Iterative Registration, Supervised Transformation
    Estimation, and Unsupervised Transformation Estimation. Following a discussion
    of the methods that belong to each of the aforementioned categories, future research
    directions and current trends are discussed in Section [5](#S5 "5 Research Trends
    and Future Directions ‣ Deep Learning in Medical Image Registration: A Survey").'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，本文的目的是全面调查基于深度学习的医学图像配准领域，突出从业者面临的常见挑战，并讨论可能解决这些挑战的未来研究方向。深度学习属于一种机器学习方法，它使用具有大量层次的神经网络来学习数据的表示
    Goodfellow et al. ([2016](#bib.bib34)); Schmidhuber ([2015](#bib.bib91))。在讨论神经网络时，提供不同类型神经网络的应用洞察、最近为解决工程问题而发明的显著架构以及用于训练神经网络的多种策略是很重要的。因此，本深度学习介绍部分分为三部分：神经网络类型、网络架构和训练范式及策略。请注意，有许多公开可用的库可以用来构建本节中描述的网络，例如
    TensorFlow Abadi et al. ([2016](#bib.bib1))、MXNet Chen et al. ([2015](#bib.bib16))、Keras
    Chollet et al. ([2015](#bib.bib20))、Caffe Jia et al. ([2014](#bib.bib49)) 和 PyTorch
    Paszke et al. ([2017](#bib.bib82))。对基于深度学习的医学图像分析和各种深度学习研究方向的详细讨论超出了本文的范围。对深度学习在医学图像分析中的应用进行综述的文章
    Lee et al. ([2017](#bib.bib59))；Litjens et al. ([2017](#bib.bib63))、强化学习 Kaelbling
    et al. ([1996](#bib.bib51)) 和 GANs 在医学图像分析中的应用 Kazeminia et al. ([2018](#bib.bib52))
    适合感兴趣的读者阅读。本文中调查的方法分为以下三类：深度迭代配准、监督变换估计和无监督变换估计。在讨论每个上述类别的方法后，未来的研究方向和当前趋势将在第[5](#S5
    "5 Research Trends and Future Directions ‣ Deep Learning in Medical Image Registration:
    A Survey")节中讨论。'
- en: '![Refer to caption](img/d96f7823b3483e2ae933548ac012638f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d96f7823b3483e2ae933548ac012638f.png)'
- en: 'Figure 2: An overview of the number of deep learning based image registration
    works and deep learning based medical imaging works. The red line represents the
    trend line for medical imaging based approaches and the blue line represents the
    trend line for deep learning based medical image registration approaches. The
    dotted line represents extrapolation.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于深度学习的图像配准工作和基于深度学习的医学成像工作的数量概览。红线表示医学成像方法的趋势线，蓝线表示基于深度学习的医学图像配准方法的趋势线。虚线表示外推。
- en: 2 Deep Iterative Registration
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度迭代配准
- en: 'Table 1: Deep Iterative Registration Methods Overview. RL denotes reinforcment
    learning.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：深度迭代配准方法概览。RL 表示强化学习。
- en: Ref Learning Transform Modality ROI Model Eppenhof and Pluim ([2018b](#bib.bib29))
    Metric Deformable CT Thorax 9-layer CNN Blendowski and Heinrich ([2018](#bib.bib10))
    Metric Deformable CT Lung FCN Simonovsky et al. ([2016](#bib.bib96)) Metric Deformable
    MR Brain 5-layer CNN Wu et al. ([2013](#bib.bib109)) Metric Deformable MR Brain
    2-layer CAE Cheng et al. ([2018](#bib.bib18)) Metric Deformable CT/MR Head 5-layer
    DNN Sedghi et al. ([2018](#bib.bib92)) Metric Rigid MR/US Abdominal 5-layer CNN
    Haskins et al. ([2019](#bib.bib36)) Metric Rigid MR/US Prostate 14-layer CNN Matthew
    et al. ([2018](#bib.bib75)) Metric Rigid MR/US Fetal Brain LSTM/STN Krebs et al.
    ([2017](#bib.bib55)) RL Agent Deformable MR Prostate 8-layer CNN Liao et al. ([2017](#bib.bib62))
    RL Agent Rigid CT/CBCT Spine/ 8-layer CNN Cardiac Miao et al. ([2017](#bib.bib76))
    Multiple Rigid X-ray/CT Spine Dilated FCN RL Agents Ma et al. ([2017](#bib.bib71))
    RL Agent Rigid MR/CT Spine Dueling Network
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 参考 学习 变换 模态 ROI 模型 Eppenhof和Pluim ([2018b](#bib.bib29)) 度量 标准 可变CT 胸部 9层CNN
    Blendowski和Heinrich ([2018](#bib.bib10)) 度量 标准 可变CT 肺 FCN Simonovsky et al. ([2016](#bib.bib96))
    度量 标准 可变MR 大脑 5层CNN Wu et al. ([2013](#bib.bib109)) 度量 标准 可变MR 大脑 2层CAE Cheng
    et al. ([2018](#bib.bib18)) 度量 标准 可变CT/MR 头部 5层DNN Sedghi et al. ([2018](#bib.bib92))
    度量 标准 刚性MR/US 腹部 5层CNN Haskins et al. ([2019](#bib.bib36)) 度量 标准 刚性MR/US 前列腺 14层CNN
    Matthew et al. ([2018](#bib.bib75)) 度量 标准 刚性MR/US 胎儿大脑 LSTM/STN Krebs et al. ([2017](#bib.bib55))
    RL 代理 可变MR 前列腺 8层CNN Liao et al. ([2017](#bib.bib62)) RL 代理 刚性CT/CBCT 脊柱/ 8层CNN
    心脏 Miao et al. ([2017](#bib.bib76)) 多重 刚性X射线/CT 脊柱 扩张FCN RL代理 Ma et al. ([2017](#bib.bib71))
    RL 代理 刚性MR/CT 脊柱 对抗网络
- en: 'Automatic intensity-based image registration requires both a metric that quantifies
    the similarity between a moving image and a fixed image and an optimization algorithm
    that updates the transformation parameters such that the similarity between the
    images is maximized. Prior to the deep learning renaissance, several manually
    crafted metrics were frequently used for such registration applications, including:
    sum of squared differences (SSD), cross-correlation (CC), mutual information (MI)
    Maes et al. ([1997](#bib.bib72)); Viola and Wells III ([1997](#bib.bib106)), normalized
    cross correlation (NCC), and normalized mutual information (NMI). Early applications
    of deep learning to medical image registration are direct extensions of the intensity-based
    registration framework Simonovsky et al. ([2016](#bib.bib96)); Wu et al. ([2013](#bib.bib109),
    [2016](#bib.bib110)). Several groups later used a reinforcement learning paradigm
    to iteratively estimate a transformation Krebs et al. ([2017](#bib.bib55)); Liao
    et al. ([2017](#bib.bib62)); Ma et al. ([2017](#bib.bib71)); Miao et al. ([2017](#bib.bib76))
    because this application is more consistent with how practitioners perform registration.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动基于强度的图像配准需要一个能够量化移动图像和固定图像之间相似度的度量标准，以及一个优化算法来更新变换参数，以使图像之间的相似度最大化。在深度学习复兴之前，几种手工制作的度量标准经常用于这种配准应用，包括：平方差和（SSD）、交叉相关（CC）、互信息（MI）Maes
    et al. ([1997](#bib.bib72))；Viola和Wells III ([1997](#bib.bib106))，归一化交叉相关（NCC）和归一化互信息（NMI）。早期应用深度学习于医学图像配准直接扩展了基于强度的配准框架Simonovsky
    et al. ([2016](#bib.bib96))；Wu et al. ([2013](#bib.bib109)，[2016](#bib.bib110))。随后，一些小组使用了强化学习范式来迭代估计变换Krebs
    et al. ([2017](#bib.bib55))；Liao et al. ([2017](#bib.bib62))；Ma et al. ([2017](#bib.bib71))；Miao
    et al. ([2017](#bib.bib76))，因为这种应用与实践者执行配准的方式更加一致。
- en: 'A description of both types of methods is given in Table [1](#S2.T1 "Table
    1 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey"). We will survey earlier methods that used deep similarity based registration
    in Section [2.1](#S2.SS1 "2.1 Deep Similarity based Registration ‣ 2 Deep Iterative
    Registration ‣ Deep Learning in Medical Image Registration: A Survey") and then
    some more recently developed methods that use deep reinforcement learning based
    registration in Section [2.2](#S2.SS2 "2.2 Reinforcement Learning based Registration
    ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](#S2.T1 "Table 1 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey")给出了这两种方法的描述。我们将在第[2.1节](#S2.SS1 "2.1 Deep Similarity
    based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey")回顾早期使用深度相似性基配准的方法，然后在第[2.2节](#S2.SS2 "2.2 Reinforcement
    Learning based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in
    Medical Image Registration: A Survey")介绍一些更近期开发的方法，这些方法使用深度强化学习基配准。'
- en: 'Figure 3: A visualization of the registration pipeline for works that use deep
    learning to quantify image similarity in an intensity-based registration framework.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：展示了在基于强度的配准框架中，使用深度学习量化图像相似度的配准流程的可视化。
- en: 2.1 Deep Similarity based Registration
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 深度相似性基础配准
- en: 'In this section, methods that use deep learning to learn a similarity metric
    are surveyed. This similarity metric is inserted into a classical intensity-based
    registration framework with a defined interpolation strategy, transformation model,
    and optimization algorithm. A visualization of this overall framework is given
    in Fig. [3](#S2.F3 "Figure 3 ‣ 2 Deep Iterative Registration ‣ Deep Learning in
    Medical Image Registration: A Survey"). The solid lines represent data flows that
    are required during training and testing, while the dashed lines represent data
    flows that are required only during training. Note that this is the case for the
    remainder of the figures in this article as well.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '本节对使用深度学习学习相似性度量的方法进行了综述。该相似性度量被插入到具有定义的插值策略、变换模型和优化算法的经典强度基础配准框架中。该整体框架的可视化见图[3](#S2.F3
    "Figure 3 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey")。实线表示在训练和测试过程中所需的数据流，而虚线表示仅在训练过程中所需的数据流。请注意，本文其余图表的情况也是如此。'
- en: 2.1.1 Overview of Works
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 工作概述
- en: Although manually crafted similarity metrics perform reasonably well in the
    unimodal registration case, deep learning has been used to learn superior metrics.
    This section will first discuss approaches that use deep learning to augment the
    performance of unimodal intensity based registration pipelines before multimodal
    registration.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管手工制作的相似性度量在单模态配准情况下表现相当不错，但深度学习已被用来学习更优的度量。 本节将首先讨论利用深度学习来增强单模态强度基础配准流程性能的方法，然后再讨论多模态配准。
- en: 2.1.1.1 Unimodal Registration
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.1.1.1 单模态配准
- en: Wu et al. Wu et al. ([2013](#bib.bib109), [2016](#bib.bib110)) were the first
    to use deep learning to obtain an application specific similarity metric for registration.
    They extracted the features that are used for unimodal, deformable registration
    of 3D brain MR volumes using a convolutional stacked autoencoder (CAE). They subsequently
    performed the registration using gradient descent to optimize the NCC of the two
    sets of features. This method outperformed diffeomorphic demons Vercauteren et al.
    ([2009](#bib.bib104)) and HAMMER Shen ([2007](#bib.bib94)) based registration
    techniques.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Wu等人（Wu 等人，[2013](#bib.bib109)，[2016](#bib.bib110)）是第一个利用深度学习获得特定应用相似性度量进行配准的研究者。他们使用卷积堆叠自编码器（CAE）提取了用于单模态、可变形3D脑MR体积配准的特征。随后，他们使用梯度下降法优化两组特征的NCC进行配准。这种方法优于基于
    diffeomorphic demons 的 Vercauteren 等人（[2009](#bib.bib104)）和 HAMMER 的 Shen（[2007](#bib.bib94)）的配准技术。
- en: Recently, Eppenhof et al. Eppenhof and Pluim ([2018b](#bib.bib29)) estimated
    registration error for the deformable registration of 3D thoracic CT scans (inhale-exhale)
    in an end-to-end capacity. They used a 3D CNN to estimate the error map for inputted
    inhale-exhale pairs of thoracic CT scans. Like the above method, only learned
    features were used in this work.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Eppenhof等人（Eppenhof 和 Pluim，[2018b](#bib.bib29)）估计了3D胸部CT扫描（吸气-呼气）的可变形配准误差，采用了端到端的方式。他们使用3D
    CNN来估计输入的吸气-呼气对胸部CT扫描的误差图。与上述方法类似，本工作中只使用了学习到的特征。
- en: Instead, Blendowski et al. Blendowski and Heinrich ([2018](#bib.bib10)) proposed
    the combined use of both CNN-based descriptors and manually crafted MRF-based
    self-similarity descriptors for lung CT registration. Although the manually crafted
    descriptors outperformed the CNN-based descriptors, optimal performance was achieved
    using both sets of descriptors. This indicates that, in the unimodal registration
    case, deep learning may not outperform manually crafted methods. However, it can
    be used to obtain complementary information.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，Blendowski等人（Blendowski 和 Heinrich，[2018](#bib.bib10)）提出了结合使用基于CNN的描述符和手工制作的基于MRF的自相似度描述符进行肺CT配准。尽管手工制作的描述符优于基于CNN的描述符，但使用这两组描述符可以实现最佳性能。这表明，在单模态配准情况下，深度学习可能不如手工制作的方法。然而，它可以用来获得互补信息。
- en: 2.1.1.2 Multimodal Registration
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.1.1.2 多模态配准
- en: The advantages of the application of deep learning to intensity based registration
    are more obvious in the multimodal case, where manually crafted similarity metrics
    have had very little success.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在多模态情况下，应用深度学习来进行强度基础配准的优势更加明显，因为手工制作的相似性度量在这方面成功的机会很少。
- en: Cheng et al. Cheng et al. ([2016](#bib.bib17), [2018](#bib.bib18)) recently
    used a stacked denoising autoencoder to learn a similarity metric that assesses
    the quality of the rigid alignment of CT and MR images. They showed that their
    metric outperformed NMI-optimization-based and local cross correlation (LCC)-optimization-based
    for their application.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Cheng 等人 ([2016](#bib.bib17), [2018](#bib.bib18)) 最近使用了堆叠去噪自编码器来学习一种相似性度量，用于评估
    CT 和 MR 图像刚性对齐的质量。他们展示了他们的度量在他们的应用中优于基于 NMI 优化和局部交叉相关 (LCC) 优化的方法。
- en: In an effort to explicitly estimate image similarity in the multimodal case,
    Simonovsky et al. Simonovsky et al. ([2016](#bib.bib96)) used a CNN to learn the
    dissimilarity between aligned 3D T1 and T2 weighted brain MR volumes. Given this
    similarity metric, gradient descent was used in order to iteratively update the
    parameters that define a deformation field. This method was able to outperform
    MI-optimization-based registration and set the stage for deep intensity based
    multimodal registration.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确估计多模态情况下的图像相似性，Simonovsky 等人 ([2016](#bib.bib96)) 使用了 CNN 来学习对齐的 3D T1 和
    T2 加权脑 MR 卷积之间的差异性。给定这一相似性度量，使用了梯度下降法来迭代更新定义变形场的参数。这种方法能够优于 MI 优化基础的配准，并为深度强度基础的多模态配准奠定了基础。
- en: 'Additionally, Sedghi et al. Sedghi et al. ([2018](#bib.bib92)) performed the
    rigid registration of 3D US/MR (modalities with an even greater appearance difference
    than MR/CT) abdominal scans by using a 5-layer neural network to learn a similarity
    metric that is then optimized by Powell’s method. This approach also outperformed
    MI-optimization-based registration. Haskins et al. Haskins et al. ([2019](#bib.bib36))
    learned a similarity metric for multimodal rigid registration of MR and transrectal
    US (TRUS) volumes by using a CNN to predict target registration error (TRE). Instead
    of using a traditional optimizer like the above methods, they used an evolutionary
    algorithm to explore the solution space prior to using a traditional optimization
    algorithm because of the learned metric’s lack of convexity. This registration
    framework outperformed MIND-optimization-based Heinrich et al. ([2012](#bib.bib38))
    and MI-optimization-based registration. In stark contrast to the above methods,
    Wright et al. Matthew et al. ([2018](#bib.bib75)) used LSTM spatial co-transformer
    networks to iteratively register MR and US volumes group-wise. The recurrent spatial
    co-transformation occurred in three steps: image warping, residual parameter prediction,
    parameter composition. They demonstrated that their method is more capable of
    quantifying image similarity than a previous multimodal image similarity quantification
    method that uses self-similarity context descriptors Heinrich et al. ([2013](#bib.bib39)).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Sedghi 等人 ([2018](#bib.bib92)) 使用 5 层神经网络来学习相似性度量，从而对 3D US/MR（具有比 MR/CT
    更大外观差异的模态）腹部扫描进行刚性配准，该度量随后由 Powell 方法优化。这种方法也优于 MI 优化基础的配准。Haskins 等人 ([2019](#bib.bib36))
    使用 CNN 来预测目标配准误差 (TRE)，从而学习用于多模态刚性配准的相似性度量，而不是使用像上述方法那样的传统优化器，他们使用了进化算法来探索解决方案空间，然后再使用传统优化算法，因为所学习的度量缺乏凸性。这种配准框架优于基于
    MIND 优化的 Heinrich 等人 ([2012](#bib.bib38)) 和基于 MI 优化的配准。与上述方法形成鲜明对比的是，Wright 等人
    ([2018](#bib.bib75)) 使用 LSTM 空间共变换网络来迭代地对 MR 和 US 卷进行组配准。递归空间共变换分为三个步骤：图像变形、残差参数预测、参数组合。他们证明了他们的方法在量化图像相似性方面比之前使用自相似上下文描述符的多模态图像相似性量化方法更具能力
    Heinrich 等人 ([2013](#bib.bib39))。
- en: 2.1.2 Discussion and Assessment
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 讨论与评估
- en: Recent works have confirmed the ability of neural networks to assess image similarity
    in multimodal medical image registration. The results achieved by the approaches
    described in this section demonstrate that deep learning can be successfully applied
    to challenging registration tasks. However, the findings from Blendowski and Heinrich
    ([2018](#bib.bib10)) suggest that learned image similarity metrics may be best
    suited to complement existing similarity metrics in the unimodal case. Further,
    it is difficult to use these iterative techniques for real time registration.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究确认了神经网络在多模态医学图像配准中评估图像相似性的能力。本节中描述的方法所取得的结果表明，深度学习可以成功应用于具有挑战性的配准任务。然而，Blendowski
    和 Heinrich ([2018](#bib.bib10)) 的研究结果表明，学习得到的图像相似性度量可能最适合于补充现有的单模态相似性度量。此外，使用这些迭代技术进行实时配准是困难的。
- en: 2.2 Reinforcement Learning based Registration
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于强化学习的注册
- en: 'In this section, methods that use reinforcement learning for their registration
    applications are surveyed. Here, a trained agent is used to perform the registration
    as opposed to a pre-defined optimization algorithm. A visualization of this framework
    is given in Fig. [4](#S2.F4 "Figure 4 ‣ 2.2 Reinforcement Learning based Registration
    ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey"). Reinforcement learning based registration typically involves a rigid
    transformation model. However, it is possible to use a deformable transformation
    model.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们调查了用于注册应用的强化学习方法。在这里，使用训练好的代理来执行注册，而不是使用预定义的优化算法。该框架的可视化见图 [4](#S2.F4
    "Figure 4 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey")。基于强化学习的注册通常涉及刚性变换模型。然而，也可以使用可变形变换模型。'
- en: '![Refer to caption](img/e8c8de298661cee539588f2a4f92854d.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8c8de298661cee539588f2a4f92854d.png)'
- en: 'Figure 4: A visualization of the registration pipeline for works that use deep
    reinforcement learning to implicitly quantify image similarity for image registration.
    Here, an agent learns to map states to actions based on rewards that it receives
    from the environment.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：使用深度强化学习隐式量化图像相似性的注册流程可视化。在这里，代理学习将状态映射到基于从环境中获得的奖励的动作。
- en: Liao et al. Liao et al. ([2017](#bib.bib62)) were the first to use reinforcment
    learning based registration to perform the rigid registration of cardiac and abdominal
    3D CT images and cone-beam CT (CBCT) images. They used a greedy supervised approach
    for end-to-end training with an attention-driven hierarchical strategy. Their
    method outperformed MI based registration and semantic registration using probability
    maps.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Liao 等人 ([2017](#bib.bib62)) 首次使用基于强化学习的注册方法来执行心脏和腹部 3D CT 图像以及圆锥束 CT (CBCT)
    图像的刚性注册。他们使用了贪婪的监督方法进行端到端训练，并采用了基于注意力的分层策略。他们的方法优于基于互信息的注册和使用概率图的语义注册。
- en: Shortly after, Kai et al. Ma et al. ([2017](#bib.bib71)) used a reinforcement
    learning approach to perform the rigid registration of MR/CT chest volumes. This
    approach is derived from $Q$-learning and leverages contextual information to
    determine the depth of the projected images. The network used in this method is
    derived from the dueling network architecture Wang et al. ([2015](#bib.bib108)).
    Notably, this work also differentiates between terminal and non-terminal rewards.
    This method outperforms registration methods that are based on iterative closest
    points (ICP), landmarks, Hausdorff distance, Deep Q Networks, and the Dueling
    Network Wang et al. ([2015](#bib.bib108)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不久之后，Kai 等人和 Ma 等人 ([2017](#bib.bib71)) 使用了强化学习方法来执行 MR/CT 胸部体积的刚性注册。这种方法源于
    $Q$-学习，并利用上下文信息来确定投影图像的深度。该方法使用的网络源于 Wang 等人 ([2015](#bib.bib108)) 的对抗网络架构。值得注意的是，这项工作还区分了终端奖励和非终端奖励。这种方法优于基于迭代最近点
    (ICP)、标志点、Hausdorff 距离、深度 Q 网络和对抗网络 Wang 等人 ([2015](#bib.bib108)) 的注册方法。
- en: Instead of training a single agent like the above methods, Miao et al. Miao
    et al. ([2017](#bib.bib76)) used a multi-agent system in a reinforcement learning
    paradigm to rigidly register X-Ray and CT images of the spine. They used an auto-attention
    mechanism to observe multiple regions and demonstrate the efficacy of a multi-agent
    system. They were able to significantly outperform registration approaches that
    used a state-of-the-art similarity metric given by De Silva et al. ([2016](#bib.bib22)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述方法训练单个代理不同，Miao 等人 ([2017](#bib.bib76)) 在强化学习范式中使用了多代理系统来对 X 射线和 CT 图像进行刚性注册。他们使用了自动关注机制来观察多个区域，并展示了多代理系统的有效性。他们能够显著优于使用
    De Silva 等人 ([2016](#bib.bib22)) 提供的最先进相似性度量的注册方法。
- en: As opposed to the above rigid registration based works, Krebs et al. Krebs et al.
    ([2017](#bib.bib55)) used a reinforcement learning based approach to perform the
    deformable registration of 2D and 3D prostate MR volumes. They used a low resolution
    deformation model for the registration and fuzzy action control to influence the
    stochastic action selection. The low resolution deformation model is necessary
    to restrict the dimensionality of the action space. This approach outperformed
    registration performed using the Elastix toolbox Klein et al. ([2010](#bib.bib53))
    and LCC-Demons Lorenzi et al. ([2013](#bib.bib69)) based registration techniques.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述基于刚性配准的方法不同，Krebs 等人（[2017](#bib.bib55)）采用了一种基于强化学习的方法来进行二维和三维前列腺 MR 体积的变形配准。他们使用了低分辨率变形模型进行配准，并通过模糊动作控制来影响随机动作选择。低分辨率变形模型对于限制动作空间的维度是必要的。这种方法优于使用
    Elastix 工具箱 Klein 等人（[2010](#bib.bib53)）和 LCC-Demons Lorenzi 等人（[2013](#bib.bib69)）的配准技术。
- en: '![Refer to caption](img/c568e97148dc30faeac61f0188933073.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c568e97148dc30faeac61f0188933073.png)'
- en: 'Figure 5: A visualization of supervised single step registration.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：监督单步配准的可视化。
- en: The use of reinforcement learning is intuitive for medical image registration
    applications. One of the principle challenges for reinforcement learning based
    registration is the ability to handle high resolution deformation fields. There
    are no such challenges for rigid registration. Because of the intuitive nature
    and recency of these methods, we expect that such approaches will receive more
    attention from the research community in the next few years.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的使用对于医学图像配准应用是直观的。基于强化学习的配准的主要挑战之一是处理高分辨率变形场的能力。刚性配准没有这样的挑战。由于这些方法的直观性质和较新的出现，我们预计在未来几年，这些方法将受到研究界更多的关注。
- en: 'Table 2: Supervised Transformation Estimation Methods. Gray rows use Diffeomorphisms.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：监督变换估计方法。灰色行使用的是微分同胚。
- en: Ref Supervision Transform Modality ROI Model Yang et al. ([2016](#bib.bib114))
    Real Transforms Deformable MR Brain FCN Cao et al. ([2017](#bib.bib13)) Real Transforms
    Deformable MR Brain 9-layer CNN Lv et al. ([2018](#bib.bib70)) Real Transforms
    Deformable MR Abdominal CNN Rohé et al. ([2017](#bib.bib86)) Real Transforms Deformable
    MR Cardiac SVF-Net Sokooti et al. ([2017](#bib.bib99)) Synthetic Deformable CT
    Chest RegNet Transforms Eppenhof and Pluim ([2018a](#bib.bib28)) Synthetic Deformable
    CT Lung U-Net Transforms Uzunova et al. ([2017](#bib.bib103)) Synthetic Deformable
    MR Brain/ FlowNet Transforms Cardiac Ito and Ino ([2018](#bib.bib47)) Synthetic
    Deformable MR Brain GoogleNet Transforms Sun et al. ([2018](#bib.bib102)) Synthetic
    Deformable CT/US Liver DVFNet Transforms Yang ([2017](#bib.bib113)) Real + Synthetic
    Deformable MR Brain FCN Transforms Sloan et al. ([2018](#bib.bib97)) Synthetic
    Rigid MR Brain 6-layer CNN Transforms 10-layer FCN Salehi et al. ([2018](#bib.bib90))
    Synthetic Rigid MR Brain 11-layer CNN Transforms ResNet-18 Zheng et al. ([2018](#bib.bib119))
    Synthetic Rigid X-ray Bone 17-layer CNN Transforms PDA Module Miao et al. ([2016b](#bib.bib78))
    Synthetic Rigid X-ray/ Bone 6-layer CNN Transforms DDR Chee and Wu ([2018](#bib.bib15))
    Synthetic Rigid MR Brain AIRNet Transforms Hu et al. ([2018c](#bib.bib44)) Segmentations
    Deformable MR/US Prostate 30-layer FCN Hering et al. ([2018](#bib.bib40)) Segmentations
    + Deformable MR/US Prostate U-Net Similarity Metric GAN Hu et al. ([2018a](#bib.bib42))
    Segmentations + Deformable MR/US Prostate GAN Adversarial Loss Fan et al. ([2018b](#bib.bib31))
    Real Transforms + Deformable MR Brain U-Net Similarity Metric Yan et al. ([2018](#bib.bib111))
    Synthetic Rigid MR/US Prostate GAN Transforms + Adversarial Loss
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 参考文献监督变换模态 ROI 模型 杨等人 ([2016](#bib.bib114)) 实际变换 可变形 MR 大脑 FCN 曹等人 ([2017](#bib.bib13))
    实际变换 可变形 MR 大脑 9层 CNN 吕等人 ([2018](#bib.bib70)) 实际变换 可变形 MR 腹部 CNN 罗赫等人 ([2017](#bib.bib86))
    实际变换 可变形 MR 心脏 SVF-Net 索科蒂等人 ([2017](#bib.bib99)) 合成变换 可变形 CT 胸部 RegNet 变换 埃彭霍夫和普卢伊姆
    ([2018a](#bib.bib28)) 合成变换 可变形 CT 肺部 U-Net 变换 乌祖诺娃等人 ([2017](#bib.bib103)) 合成变换
    可变形 MR 大脑/ FlowNet 变换 心脏 伊藤和伊野 ([2018](#bib.bib47)) 合成变换 可变形 MR 大脑 GoogleNet 变换
    孙等人 ([2018](#bib.bib102)) 合成变换 可变形 CT/US 肝脏 DVFNet 变换 杨 ([2017](#bib.bib113))
    实际 + 合成 变换 可变形 MR 大脑 FCN 变换 斯隆等人 ([2018](#bib.bib97)) 合成刚性 MR 大脑 6层 CNN 变换 10层
    FCN 萨雷希等人 ([2018](#bib.bib90)) 合成刚性 MR 大脑 11层 CNN 变换 ResNet-18 郑等人 ([2018](#bib.bib119))
    合成刚性 X射线 骨头 17层 CNN 变换 PDA 模块 苗等人 ([2016b](#bib.bib78)) 合成刚性 X射线/骨头 6层 CNN 变换
    DDR 谢和吴 ([2018](#bib.bib15)) 合成刚性 MR 大脑 AIRNet 变换 胡等人 ([2018c](#bib.bib44)) 分割
    可变形 MR/US 前列腺 30层 FCN 赫林等人 ([2018](#bib.bib40)) 分割 + 可变形 MR/US 前列腺 U-Net 相似度度量
    GAN 胡等人 ([2018a](#bib.bib42)) 分割 + 可变形 MR/US 前列腺 GAN 对抗损失 范等人 ([2018b](#bib.bib31))
    实际变换 + 可变形 MR 大脑 U-Net 相似度度量 燕等人 ([2018](#bib.bib111)) 合成刚性 MR/US 前列腺 GAN 变换 +
    对抗损失
- en: 3 Supervised Transformation Estimation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 3 监督变换估计
- en: Despite the early success of the previously described approaches, the transformation
    estimation in these methods is iterative, which can lead to slow registration.
    Haskins et al. ([2019](#bib.bib36)). This is especially true in the deformable
    registration case where the solution space is high dimensional Lee et al. ([2017](#bib.bib59)).
    This motivated the development of networks that could estimate the transformation
    that corresponds to optimal similarity in one step. However, fully supervised
    transformation estimation (the exclusive use of ground truth data to define the
    loss function) has several challenges that are highlighted in this section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管前述方法取得了早期成功，但这些方法中的变换估计是迭代的，这可能导致注册速度较慢。哈斯金斯等人 ([2019](#bib.bib36))。这在可变形注册的情况下尤为明显，因为解决空间的维度很高
    李等人 ([2017](#bib.bib59))。这激发了能够一步估计与最佳相似性对应的变换的网络的发展。然而，完全监督的变换估计（仅使用真实数据来定义损失函数）存在几个挑战，这些挑战在本节中有所强调。
- en: 'A visualization of supervised transformation estimation is given in Fig. [5](#S2.F5
    "Figure 5 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey") and a description of
    notable works is given in Table [2](#S2.T2 "Table 2 ‣ 2.2 Reinforcement Learning
    based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey"). This section first discusses methods that use
    fully supervised approaches in Section [3.1](#S3.SS1 "3.1 Fully Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey") and then discusses methods that use dual/weakly
    supervised approaches in Section [3.2](#S3.SS2 "3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '图[5](#S2.F5 "Figure 5 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep
    Iterative Registration ‣ Deep Learning in Medical Image Registration: A Survey")展示了监督变换估计的可视化，表[2](#S2.T2
    "Table 2 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey")列出了 notable works。本节首先讨论了在[3.1](#S3.SS1
    "3.1 Fully Supervised Transformation Estimation ‣ 3 Supervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey")部分中使用完全监督方法的方法，然后讨论了在[3.2](#S3.SS2
    "3.2 Dual/Weakly Supervised Transformation Estimation ‣ 3 Supervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey")部分中使用双重/弱监督方法的方法。'
- en: 3.1 Fully Supervised Transformation Estimation
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 全监督变换估计
- en: In this section, methods that used full supervision for single-step registration
    are surveyed. Using a neural network to perform registration as opposed to an
    iterative optimizer significantly speeds up the registration process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将探讨用于单步配准的全监督方法。与迭代优化器相比，使用神经网络进行配准显著加快了配准过程。
- en: 3.1.1 Overview of works
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 作品概述
- en: Several registration application require deformable transformation models that
    often prohibit the use of traditional convolutional neural networks because of
    the computational expense associated with using FC-layers to make predictions
    in highly dimensional solution spaces Krebs et al. ([2017](#bib.bib55)). Because
    the networks that are used to predict deformation fields are fully convolutional,
    the dimensionality of the solution space associated with a deformation field does
    not introduce additional computational constraints Yang et al. ([2016](#bib.bib114)).
    This section will first discuss approaches that use a rigid transformation model
    and then discuss approaches that use a deformable transformation model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一些配准应用需要可变形变换模型，这通常禁止使用传统的卷积神经网络，因为使用FC层在高维解空间中进行预测的计算开销很大 Krebs et al. ([2017](#bib.bib55))。由于用于预测变形场的网络是完全卷积的，与变形场相关的解空间的维度不会引入额外的计算约束
    Yang et al. ([2016](#bib.bib114))。本节将首先讨论使用刚性变换模型的方法，然后讨论使用可变形变换模型的方法。
- en: 3.1.1.1 Rigid Registration
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 3.1.1.1 刚性配准
- en: Miao et al. Miao et al. ([2016a](#bib.bib77), [b](#bib.bib78)) were the first
    to use deep learning to predict rigid transformation parameters. They used a CNN
    to predict the transformation matrix associated with the rigid registration of
    2D/3D X-ray attenuation maps and 2D X-ray images. Hierarchical regression is proposed
    in which the 6 transformation parameters are partitioned into 3 groups. Ground
    truth data was synthesized in this approach by transforming aligned data. This
    is the case for the next three approaches that are described as well. This approach
    outperformed MI, CC, and gradient correlation (GC)-optimization-based registration
    approaches with respect to both accuracy and computational efficiency. The improved
    computational efficiency is due to the use of a forward pass through a neural
    network instead of an optimization algorithm to perform the registration.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Miao et al. Miao et al. ([2016a](#bib.bib77), [b](#bib.bib78)) 首次使用深度学习来预测刚性变换参数。他们使用CNN来预测与2D/3D
    X射线衰减图和2D X射线图像的刚性配准相关的变换矩阵。提出了分层回归，其中6个变换参数被划分为3组。此方法通过变换对齐的数据来合成地面真实数据。这也是接下来描述的三种方法的情况。该方法在准确性和计算效率方面优于基于MI、CC和梯度相关性（GC）优化的配准方法。提高的计算效率归因于使用神经网络的前向传递，而不是优化算法来执行配准。
- en: Recently, Chee et al. Chee and Wu ([2018](#bib.bib15)) used a CNN to predict
    the transformation parameters used to rigidly register 3D brain MR volumes. In
    their framework, affine image registration network (AIRNet), the MSE between the
    predicted and ground truth affine transforms is used to train the network. They
    were able to outperform MI-optimization-based registration for both the unimodal
    and multimodal cases.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Chee等人（Chee and Wu，[2018](#bib.bib15)）使用CNN来预测用于刚性配准3D脑MR体积的变换参数。在他们的框架中，仿射图像配准网络（AIRNet）使用预测的和真实的仿射变换之间的均方误差（MSE）来训练网络。他们能够在单模态和多模态情况下均优于基于MI优化的配准方法。
- en: That same year, Salehi et al. Salehi et al. ([2018](#bib.bib90)) used a deep
    residual regression network, a correction network, and a bivariant geodesic distance
    based loss function to rigidly register T1 and T2 weighted 3D fetal brain MRs
    for atlas construction. The use of the residual network to initially register
    the image volumes prior to the forward pass through the correction network allowed
    for an enhancement of the capture range of the registration. This approach was
    evaluated for both slice-to-volume registration and volume-to-volume registration.
    They validated the efficacy of their geodesic loss term and outperformed NCC-optimization-based
    registration.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 同年，Salehi等人（Salehi et al.，[2018](#bib.bib90)）使用了深度残差回归网络、校正网络和基于双变量测地距离的损失函数来刚性配准T1和T2加权的3D胎儿脑MR，以构建图谱。使用残差网络初步配准图像体积，然后通过校正网络进行前向传播，从而提高了配准的捕捉范围。这种方法在切片到体积配准和体积到体积配准中都进行了评估。他们验证了测地损失项的有效性，并优于基于NCC优化的配准方法。
- en: Additionally, Zheng et al. Zheng et al. ([2018](#bib.bib119)) proposed the integration
    of a pairwise domain adaptation module (PDA) into a pre-trained CNN that performs
    the rigid registration of pre-operative 3D X-Ray images and intraoperative 2D
    X-ray images using a limited amount of training data. Domain adaptation was used
    to address the discrepancy between synthetic data that was used to train the deep
    model and real data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，郑等人（Zheng et al.，[2018](#bib.bib119)）提出了将一对一领域适应模块（PDA）集成到一个预训练的CNN中，该CNN使用有限的训练数据进行术前3D
    X射线图像和术中2D X射线图像的刚性配准。领域适应用于解决用于训练深度模型的合成数据与真实数据之间的差异。
- en: Sloan et al. Sloan et al. ([2018](#bib.bib97)) used a CNN is used to regress
    the rigid transformation parameters for the registration of T1 and T2 weighted
    brain MRs. Both unimodal and multimodal registration were investigated in this
    work. The parameters that constitute the convolutional layers that were used to
    extract low-level features in each image were only shared in the unimodal case.
    In the multimodal case, these parameters were learned separately. This approach
    also outperformed MI-optimization-based image registration.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Sloan等人（Sloan et al.，[2018](#bib.bib97)）使用了卷积神经网络（CNN）来回归刚性变换参数，以实现T1和T2加权脑MR的配准。该工作研究了单模态和多模态的配准。在单模态情况下，用于提取每张图像低级特征的卷积层的参数仅在单模态情况下共享。在多模态情况下，这些参数是单独学习的。这种方法还优于基于互信息（MI）优化的图像配准方法。
- en: 3.1.1.2 Deformable Registration
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 3.1.1.2 可变形配准
- en: Unike the previous section, methods that use both real and synthesized ground
    truth labels will be discussed. Methods that use clinical/publicly available ground
    truth labels for training are discussed first. This ordering is reflective of
    the fact that simulating realistic deformable transformations is more difficult
    than simulating realistic rigid transformations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一部分不同，将讨论使用真实和合成地面真值标签的方法。首先讨论使用临床/公开获取的地面真值标签进行训练的方法。这种排序反映了模拟现实的可变形变换比模拟现实的刚性变换更为困难。
- en: First, Yang et al. Yang et al. ([2016](#bib.bib114)) predicted the deformation
    field with an FCN that is used to register 2D/3D intersubject brain MR volumes
    in a single step. A U-net like architecture Ronneberger et al. ([2015](#bib.bib87))
    was used in this approach. Further, they used large diffeomorphic metric mapping
    to provide a basis, used the initial momentum values of the pixels of the image
    volumes as the network input, and evolved these values to obtain the predicted
    deformation field. This method outperformed semi-coupled dictionary learning based
    registration Cao et al. ([2015](#bib.bib11)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，杨等人 ([2016](#bib.bib114)) 预测了变形场，使用了一个全卷积网络（FCN），该网络用于在单步中对2D/3D被试脑部MR体积进行配准。在此方法中，采用了类似U-net的架构
    ([Ronneberger et al.](#bib.bib87) [2015])。此外，他们使用了大规模微分度量映射提供基础，使用图像体积的像素初始动量值作为网络输入，并演化这些值以获得预测的变形场。该方法优于基于半耦合字典学习的配准方法
    ([Cao et al.](#bib.bib11) [2015])。
- en: The following year, Rohe et al. Rohé et al. ([2017](#bib.bib86)) also used a
    U-net Ronneberger et al. ([2015](#bib.bib87)) inspired network to estimate the
    deformation field used to register 3D cardiac MR volumes. Mesh segmentations are
    used to compute the reference transformation for a given image pair and SSD between
    the prediction and ground truth is used as the loss function. This method outperformed
    LCC Demons based registration Lorenzi et al. ([2013](#bib.bib69)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 次年，罗赫等人 ([2017](#bib.bib86)) 也使用了受U-net启发的网络 ([Ronneberger et al.](#bib.bib87)
    [2015]) 来估计用于配准3D心脏MR体积的变形场。使用网格分割计算给定图像对的参考变换，并且使用预测与真实值之间的SSD作为损失函数。该方法优于基于LCC
    Demons的配准方法 ([Lorenzi et al.](#bib.bib69) [2013])。
- en: That same year, Cao et al. Cao et al. ([2017](#bib.bib13)) used a CNN to map
    input image patches of a pair of 3D brain MR volumes to their respective displacement
    vector. The totality of these displacement vectors for a given image constitutes
    the deformation field that is used to perform the registration. Additionally,
    they used the similarity between inputted image patches to guide the learning
    process. Further, they used equalized active-points guided sampling strategy that
    makes it so that patches with higher gradient magnitudes and displacement values
    are more likely to be sampled for training. This method outperforms SyN Avants
    et al. ([2008](#bib.bib6)) and Demons Vercauteren et al. ([2009](#bib.bib104))
    based registration methods.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 同年，曹等人 ([2017](#bib.bib13)) 使用卷积神经网络（CNN）将一对3D脑部MR体积的输入图像块映射到各自的位移向量。这些位移向量的总和构成了用于执行配准的变形场。此外，他们使用了输入图像块之间的相似性来指导学习过程。进一步，他们使用了均衡活跃点引导采样策略，使得具有更高梯度幅度和位移值的块更可能被用于训练。该方法优于基于SyN
    ([Avants et al.](#bib.bib6) [2008]) 和基于Demons ([Vercauteren et al.](#bib.bib104)
    [2009]) 的配准方法。
- en: Recently, Jun et al. Lv et al. ([2018](#bib.bib70)) used a CNN to perform the
    deformable registration of abdominal MR images to compensate for the deformation
    that is caused by respiration. This approach achieved registration results that
    are superior to those obtained using non-motion corrected registrations and local
    affine registration. Recently, unlike many of the other approaches discussed in
    this paper, Yang et al. Yang ([2017](#bib.bib113)) quantified the uncertainty
    associated with the deformable registration of 3D T1 and T2 weighted brain MRs
    using a low-rank Hessian approximation of the variational gaussian distribution
    of the transformation parameters. This method was evaulated on both real and synthetic
    data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Jun et al. ([2018](#bib.bib70)) 使用CNN执行腹部MR图像的可变形配准，以补偿由呼吸引起的变形。这种方法的配准结果优于未进行运动校正的配准结果和局部仿射配准。近期，与本文讨论的许多其他方法不同，杨等人
    ([Yang](#bib.bib113) [2017]) 量化了3D T1和T2加权脑部MR的可变形配准所涉及的不确定性，采用了变换参数的变分高斯分布的低秩Hessian近似。这种方法在真实和合成数据上进行了评估。
- en: Just as deep learning practitioners use random transformations to enhance the
    diversity of their dataset, Sokooti et al. Sokooti et al. ([2017](#bib.bib99))
    used random DVFs to augment their dataset. They used a multi-scale CNN to predict
    a deformation field. This deformation is used to perform intra-subject registration
    of 3D chest CT images. This method used late fusion as opposed to early fusion,
    in which the patches are concatenated and used as the input to the network. The
    performance of their method is competitive with B-Spline based registration Sokooti
    et al. ([2017](#bib.bib99)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如深度学习从业者使用随机变换来增强数据集的多样性一样，Sokooti 等人 ([2017](#bib.bib99)) 使用随机 DVF 来增强他们的数据集。他们使用多尺度
    CNN 来预测变形场。该变形用于进行 3D 胸部 CT 图像的同一受试者配准。该方法使用晚期融合，而非早期融合，其中补丁被拼接并作为网络的输入。该方法的性能与基于
    B 样条的配准 Sokooti 等人 ([2017](#bib.bib99)) 具有竞争力。
- en: Such approaches have notable, but also limited ability to enhance the size and
    diversity of datasets. These limitations motivated the development of more sophisticated
    ground truth generation. The rest of the approaches described in this section
    use simulated ground truth data for their applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在增强数据集的规模和多样性方面有显著但也有限的能力。这些限制促使了更复杂的真实数据生成方法的发展。本节中描述的其余方法使用模拟的真实数据进行应用。
- en: For example, Eppenhof et al. Eppenhof and Pluim ([2018a](#bib.bib28)) used a
    3D CNN to perform the deformable registration of inhale-exhale 3D lung CT image
    volumes. A series of multi-scale, random transformations of aligned image pairs
    eliminate the need for manually annotated ground truth data while also maintaining
    realistic image appearance. Further, as is the case with other methods that generate
    ground truth data, the CNN can be trained using relatively few medical images
    in a supervised capacity.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Eppenhof 和 Pluim ([2018a](#bib.bib28)) 使用 3D CNN 执行吸气-呼气 3D 肺 CT 图像体积的变形配准。一系列多尺度、随机变换的对齐图像对消除了对手动注释真实数据的需求，同时保持了现实的图像外观。此外，与其他生成真实数据的方法一样，CNN
    可以使用相对较少的医学图像进行监督训练。
- en: Unlike the above works, Uzunova et al. Uzunova et al. ([2017](#bib.bib103))
    generated ground truth data using statistical appearance models (SAMs). They used
    a CNN to estimate the deformation field for the registration of 2D brain MRs and
    2D cardiac MRs, and adapt FlowNet Dosovitskiy et al. ([2015](#bib.bib26)) for
    their application. They demonstrated that training FlowNet using SAM generated
    ground truth data resulted in superior performance to CNNs trained using either
    randomly generated ground truth data or ground truth data obtained using the registration
    method described in Ehrhardt et al. ([2015](#bib.bib27)).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述工作不同，Uzunova 等人 ([2017](#bib.bib103)) 使用统计外观模型 (SAMs) 生成真实数据。他们使用 CNN 估计
    2D 脑 MR 和 2D 心脏 MR 图像的变形场，并将 FlowNet Dosovitskiy 等人 ([2015](#bib.bib26)) 适应到他们的应用中。他们展示了使用
    SAM 生成的真实数据训练 FlowNet 的性能优于使用随机生成的真实数据或使用 Ehrhardt 等人 ([2015](#bib.bib27)) 描述的配准方法获得的真实数据训练的
    CNN。
- en: Unlike the other methods in this section that use random transformations or
    manually crafted methods to generate ground truth data, Ito et al. Ito and Ino
    ([2018](#bib.bib47)) used a CNN to learn plausible deformations for ground truth
    data generation. They evaluated their approach on the 3D brain MR volumes in the
    ADNI dataset and outperformed the MI-optimization-based approach proposed in Ikeda
    et al. ([2014](#bib.bib45)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 与本节中使用随机变换或手动制作方法生成真实数据的其他方法不同，Ito 等人 ([2018](#bib.bib47)) 使用 CNN 学习可行的变形来生成真实数据。他们在
    ADNI 数据集的 3D 脑 MR 图像上评估了他们的方法，并超越了 Ikeda 等人 ([2014](#bib.bib45)) 提出的基于 MI 优化的方法。
- en: 3.1.2 Discussion and Assessment
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 讨论与评估
- en: Supervised transformation estimation has allowed for real time, robust registration
    across applications. However, such works are not without their limitations. Firstly,
    the quality of the registrations using this framework is dependent on the quality
    of the ground truth registrations. The quality of these labels is, of course,
    dependent upon the expertise of the practitioner. Furthermore, these labels are
    fairly difficult to obtain because there are relatively few individuals with the
    expertise necessary to perform such registrations. Transformations of training
    data and the generation of synthetic ground truth data can address such limitations.
    However, it is important to ensure that simulated data is sufficiently similar
    to clinical data. These challenges motivated the development of partially supervised/unsupervised
    approaches, which will be discussed next.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 监督变换估计使得在应用中实现实时、稳健的配准成为可能。然而，这些方法也有其局限性。首先，使用该框架的配准质量依赖于地面真实配准的质量。这些标签的质量自然依赖于实践者的专业水平。此外，这些标签较难获得，因为具备进行此类配准所需专业知识的人相对较少。训练数据的变换和合成地面真实数据的生成可以解决这些限制。然而，重要的是要确保模拟数据与临床数据有足够的相似性。这些挑战促使了部分监督/无监督方法的发展，接下来将讨论这些方法。
- en: 3.2 Dual/Weakly Supervised Transformation Estimation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 双重/弱监督变换估计
- en: 'Dual supervision refers to the use of both ground truth data and some metric
    that quantifies image similarity to train a model. On the other hand, weak supervision
    refers to using the overlap of segmentations of corresponding anatomical structures
    to design the loss function. This section will discuss the contributions of such
    works in Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Overview of works ‣ 3.2 Dual/Weakly
    Supervised Transformation Estimation ‣ 3 Supervised Transformation Estimation
    ‣ Deep Learning in Medical Image Registration: A Survey") and then discuss the
    overall state of this research direction in Section [3.2.2](#S3.SS2.SSS2 "3.2.2
    Discussion and Assessment ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 双重监督指的是使用地面真实数据和量化图像相似性的一些度量来训练模型。另一方面，弱监督指的是利用相应解剖结构的分割重叠来设计损失函数。本节将讨论这些工作的贡献，详见[3.2.1](#S3.SS2.SSS1
    "3.2.1 作品概述 ‣ 3.2 双重/弱监督变换估计 ‣ 3 监督变换估计 ‣ 医学图像配准中的深度学习：综述")，然后在[3.2.2](#S3.SS2.SSS2
    "3.2.2 讨论与评估 ‣ 3.2 双重/弱监督变换估计 ‣ 3 监督变换估计 ‣ 医学图像配准中的深度学习：综述")节中讨论这一研究方向的总体状态。
- en: 3.2.1 Overview of works
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 作品概述
- en: '![Refer to caption](img/ad32c0c42ab62d93f3d21860cb88245f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ad32c0c42ab62d93f3d21860cb88245f.png)'
- en: 'Figure 6: A visualization of deep single step registration where the agent
    is trained using dual supervision. The loss function is determined using both
    a metric that quantifies image similarity and ground truth data.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：深度单步配准的可视化，其中代理使用双重监督进行训练。损失函数通过量化图像相似性的度量标准和地面真实数据来确定。
- en: 'First, this section will discuss methods that use dual supervised and then
    will discuss methods that use weak supervision. Recently, Fan et al. Fan et al.
    ([2018b](#bib.bib31)) used hierarchical, dual-supervised learning to predicted
    the deformation field for 3D brain MR registration. They amend the traditional
    U-Net architecture Ronneberger et al. ([2015](#bib.bib87)) by using “gap-filling”
    (*i.e.*, inserting convolutional layers after the U-type ends or the architecture)
    and coarse-to-fine guidance. This approach leveraged both the similarity between
    the predicted and ground truth transformations, and the similarity between the
    warped and fixed images to train the network. The architecture detailed in this
    method outperformed the traditional U-Net architecture and the dual supervision
    strategy is verified by ablating the image similarity loss function term. A visualization
    of dual supervised transformation estimation is given in Fig. [6](#S3.F6 "Figure
    6 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，本节将讨论使用双重监督的方法，然后讨论使用弱监督的方法。最近，Fan等人 ([2018b](#bib.bib31)) 使用了层次化的双重监督学习来预测3D脑MR配准的变形场。他们通过在U-Net架构的U型端或架构后插入卷积层（即“填补空白”）以及粗到精的指导来修正传统的U-Net架构（Ronneberger等人
    ([2015](#bib.bib87))）。这种方法利用了预测变换与真实变换之间的相似性，以及变形图像与固定图像之间的相似性来训练网络。这种方法中的架构优于传统的U-Net架构，并且通过消融图像相似性损失函数项验证了双重监督策略。双重监督变换估计的可视化见图[6](#S3.F6
    "Figure 6 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")。'
- en: 'On the other hand, Yan et al. Yan et al. ([2018](#bib.bib111)) used a framework
    that is inspired by the GAN Goodfellow et al. ([2014](#bib.bib35)) to perform
    the rigid registration of 3D MR and TRUS volumes. In this work, the generator
    was trained to estimate a rigid transformation. While, the discriminator was trained
    to discern between images that were aligned using the ground truth transformations
    and images that were aligned using the predicted transformations. Both Euclidean
    distance to ground truth and an adversarial loss term are used to construct the
    loss function in this method. Note that the adversarial supervision strategy that
    was used in this approach is similar to the ones that are used in a number of
    unsupervised works that will be described in the next section. A visualization
    of adversarial transformation estimation is given in Fig. [7](#S3.F7 "Figure 7
    ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '另一方面，Yan等人 ([2018](#bib.bib111)) 使用了一个受GAN（Goodfellow等人 ([2014](#bib.bib35))
    启发的框架来进行3D MR和TRUS体积的刚性配准。在这项工作中，生成器被训练用于估计刚性变换，而判别器则被训练以辨别使用真实变换对齐的图像和使用预测变换对齐的图像。这种方法中使用了到真实值的欧几里得距离和对抗损失项来构建损失函数。请注意，这种方法中使用的对抗监督策略与下一节将描述的一些无监督工作所使用的策略类似。对抗变换估计的可视化见图[7](#S3.F7
    "Figure 7 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")。'
- en: '![Refer to caption](img/827955275448ceb55a3ad37a6b745d33.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/827955275448ceb55a3ad37a6b745d33.png)'
- en: 'Figure 7: A visualization of an adversarial image registration framework. Here,
    the generator is trained using output from the discriminator. The discriminator
    takes the form of a learned metric here.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：一个对抗图像配准框架的可视化。在这里，生成器使用来自判别器的输出进行训练。判别器在这里采用的是一种学习到的度量形式。
- en: 'Unlike the above methods that used dual supervision, Hu et al. Hu et al. ([2018b](#bib.bib43),
    [c](#bib.bib44)) recently used label similarity to train their network to perform
    MR-TRUS registration. In their initial work, they used two neural networks: local-net
    and global-net to estimate the global affine transformation with 12 degrees of
    freedom and the local dense deformation field respectively Hu et al. ([2018b](#bib.bib43)).
    The local-net uses the concatenation of the transformation of the moving image
    given by the global-net and the fixed image as its input. However, in their later
    work Hu et al. ([2018c](#bib.bib44)), they combine these networks in an end-to-end
    framework. This method outperformed NMI-optimization-based and NCC based registration.
    A visualization of weakly supervised transformation estimation is given in Fig. [8](#S3.F8
    "Figure 8 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey"). In another work, Hu et al. Hu et al. ([2018a](#bib.bib42))
    simultaneously maximized label similarity and minimized an adversarial loss term
    to predict the deformation for MR-TRUS registration. This regularization term
    forces the predicted transformation to result in the generation of a realistic
    image. Using the adversarial loss as a regularization term is likely to successfully
    force the transformation to be realistic given proper hyper parameter selection.
    The performance of this registration framework was inferior to the performance
    of their previous registration framework described above. However, they showed
    that adversarial regularization is superior to standard bending energy based regularization.
    Similar to the above method, Hering et al. Hering et al. ([2018](#bib.bib40))
    built upon the progress made with respect to both dual and weak supervision by
    introducing a label and similarity metric based loss function for cardiac motion
    tracking via the deformable registration of 2D cine-MR images. Both segmentation
    overlap and edge based normalized gradient fields distance were used to construct
    the loss function in this approach. Their method outperformed a multilevel registration
    approach similar to the one proposed in Rühaak et al. ([2013](#bib.bib88)).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: '与上述使用双重监督的方法不同，胡等人（Hu et al. ([2018b](#bib.bib43), [c](#bib.bib44))）最近使用标签相似性来训练他们的网络以执行
    MR-TRUS 配准。在他们的初步工作中，他们使用了两个神经网络：local-net 和 global-net，分别用于估计具有 12 自由度的全局仿射变换和局部密集变形场（胡等人
    ([2018b](#bib.bib43))）。local-net 使用 global-net 给出的移动图像的变换和固定图像的拼接作为输入。然而，在他们后来的工作中（胡等人
    ([2018c](#bib.bib44))），他们将这些网络结合在一个端到端的框架中。这种方法优于基于 NMI 优化和 NCC 的配准。图 [8](#S3.F8
    "Figure 8 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey") 显示了弱监督变换估计的可视化。在另一项工作中，胡等人（Hu et al. ([2018a](#bib.bib42))）同时最大化标签相似性并最小化对抗损失项来预测
    MR-TRUS 配准的变形。这个正则化项强迫预测的变换生成现实图像。使用对抗损失作为正则化项很可能在适当的超参数选择下成功地强迫变换变得现实。这个配准框架的性能低于他们之前描述的配准框架。然而，他们展示了对抗正则化优于标准的弯曲能量基正则化。类似于上述方法，Hering
    等人（Hering et al. ([2018](#bib.bib40))）在双重和弱监督方面的进展基础上，引入了一个基于标签和相似性度量的损失函数，用于通过
    2D cine-MR 图像的可变形配准进行心脏运动跟踪。该方法使用了分割重叠和基于边缘的归一化梯度场距离来构造损失函数。它优于 Rühaak 等人 ([2013](#bib.bib88))
    提出的类似多级配准方法。'
- en: '![Refer to caption](img/2a14b8735627c5658b43ea872555b94a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/2a14b8735627c5658b43ea872555b94a.png)'
- en: 'Figure 8: A visualization of deep single step registration where the agent
    is trained using label similarity (*i.e.* weak supervision). Manually annotated
    data (segmentations) are used to define the loss function used to train the network.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 图 8：深度单步配准的可视化，其中代理使用标签相似性（*即* 弱监督）进行训练。手动标注的数据（分割）用于定义训练网络的损失函数。
- en: 3.2.2 Discussion and Assessment
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2 讨论与评估
- en: Direct transformation estimation marked a major breakthrough for deep learning
    based image registration. With full supervision, promising results have been obtained.
    However, at the same time, those techniques require a large amount of detailed
    annotated images for training. Partially/weakly supervised transformation estimation
    methods alleviated the limitations associated with the trustworthiness and expense
    of ground truth labels. However, they still require manually annotated data (*e.g.*
    ground truth and/or segmentations). On the other hand, weak supervision allows
    for similarity quantification in the multimodal case. Further, partial supervision
    allows for the aggregation of methods that can be used to assess the quality of
    a predicted registration. As a result, there is growing interest in these research
    areas.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 直接变换估计标志着深度学习图像配准的重大突破。在完全监督下，取得了令人鼓舞的结果。然而，与此同时，这些技术需要大量详细标注的图像进行训练。部分/弱监督的变换估计方法缓解了与地面真实标签的可信度和费用相关的限制。然而，它们仍然需要手动标注的数据（*例如*地面真实数据和/或分割）。另一方面，弱监督允许在多模态情况下进行相似性量化。此外，部分监督允许聚合可以用于评估预测配准质量的方法。因此，这些研究领域越来越受到关注。
- en: 'Table 3: Unsupervised Transformation Estimation Methods. Grays rows use Diffeomorphisms.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 表3：无监督变换估计方法。灰色行使用流形。
- en: Ref Loss Function Transform Modality ROI Model Jiang and Shackleford ([2018](#bib.bib50))
    SSD Deformable CT Chest Multi-scale CNN Ghosal and Ray ([2017](#bib.bib33)) UB
    SSD Deformable MR Brain 19-layer FCN Zhang ([2018](#bib.bib118)) MSD Deformable
    MR Brain ICNet Shu et al. ([2018](#bib.bib95)) MSE Deformable SEM Neurons 11-layer
    CNN Dalca et al. ([2018](#bib.bib21)) MSE Deformable MR Brain VoxelMorph Sheikhjafari
    et al. ([2018](#bib.bib93)) MSE Deformable MR Cardiac 8-layer Cine FCNet Kuang
    and Schmah ([2018](#bib.bib58)) CC Deformable MR Brain FAIM Li and Fan ([2018](#bib.bib61))
    NCC Deformable MR Brain 8-layer FCN Cao et al. ([2018](#bib.bib12)) NCC Deformable
    CT, MR Pelvis U-Net de Vos et al. ([2017](#bib.bib24)) NCC Deformable MR Cardiac
    DIRNet Cine de Vos et al. ([2018](#bib.bib23)) NCC Deformable MR Cardiac DLIR
    Cine Ferrante et al. ([2018](#bib.bib32)) NCC Deformable X-ray, MR Bone U-Net
    Cardiac STN Cine Sun and Zhang ([2018](#bib.bib101)) L2 Distance + Deformable
    MR, US Brain FCN Image Gradient Neylon et al. ([2017](#bib.bib81)) Predicted TRE
    Deformable CT Head/Neck FCN Fan et al. ([2018a](#bib.bib30)) BCE Deformable MR
    Brain GAN Mahapatra ([2018](#bib.bib73)) NMI + SSIM Deformable MR, FA/ Cardiac
    GAN + VGG Outputs Color fundus Retinal Mahapatra et al. ([2018](#bib.bib74)) NMI
    + SSIM + Deformable X-ray Bone GAN VGG Outputs + BCE Yoo et al. ([2017](#bib.bib117))
    MSE AE Output Deformable ssEM Neurons CAE STN Wu et al. ([2016](#bib.bib110))
    MSE Stacked Deformable MR Brain Stacked AE Outputs AE Wu et al. ([2013](#bib.bib109))
    NCC of Deformable MR Brain Stacked ISA Outputs ISA Krebs et al. ([2018a](#bib.bib56))
    Log Likelihood Deformable MR Brain cVAE STN Liu and Leung ([2017](#bib.bib67))
    SSD MIND + Deformable CT, MR Chest FCN PCANet Outputs Brain PCANet Kori et al.
    ([2018](#bib.bib54)) SSD VGG Rigid MR Brain CNN Outputs MLP
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: Ref Loss Function Transform Modality ROI Model Jiang and Shackleford ([2018](#bib.bib50))
    SSD Deformable CT Chest Multi-scale CNN Ghosal and Ray ([2017](#bib.bib33)) UB
    SSD Deformable MR Brain 19-layer FCN Zhang ([2018](#bib.bib118)) MSD Deformable
    MR Brain ICNet Shu et al. ([2018](#bib.bib95)) MSE Deformable SEM Neurons 11-layer
    CNN Dalca et al. ([2018](#bib.bib21)) MSE Deformable MR Brain VoxelMorph Sheikhjafari
    et al. ([2018](#bib.bib93)) MSE Deformable MR Cardiac 8-layer Cine FCNet Kuang
    and Schmah ([2018](#bib.bib58)) CC Deformable MR Brain FAIM Li and Fan ([2018](#bib.bib61))
    NCC Deformable MR Brain 8-layer FCN Cao et al. ([2018](#bib.bib12)) NCC Deformable
    CT, MR Pelvis U-Net de Vos et al. ([2017](#bib.bib24)) NCC Deformable MR Cardiac
    DIRNet Cine de Vos et al. ([2018](#bib.bib23)) NCC Deformable MR Cardiac DLIR
    Cine Ferrante et al. ([2018](#bib.bib32)) NCC Deformable X-ray, MR Bone U-Net
    Cardiac STN Cine Sun and Zhang ([2018](#bib.bib101)) L2 Distance + Deformable
    MR, US Brain FCN Image Gradient Neylon et al. ([2017](#bib.bib81)) Predicted TRE
    Deformable CT Head/Neck FCN Fan et al. ([2018a](#bib.bib30)) BCE Deformable MR
    Brain GAN Mahapatra ([2018](#bib.bib73)) NMI + SSIM Deformable MR, FA/ Cardiac
    GAN + VGG Outputs Color fundus Retinal Mahapatra et al. ([2018](#bib.bib74)) NMI
    + SSIM + Deformable X-ray Bone GAN VGG Outputs + BCE Yoo et al. ([2017](#bib.bib117))
    MSE AE Output Deformable ssEM Neurons CAE STN Wu et al. ([2016](#bib.bib110))
    MSE Stacked Deformable MR Brain Stacked AE Outputs AE Wu et al. ([2013](#bib.bib109))
    NCC of Deformable MR Brain Stacked ISA Outputs ISA Krebs et al. ([2018a](#bib.bib56))
    Log Likelihood Deformable MR Brain cVAE STN Liu and Leung ([2017](#bib.bib67))
    SSD MIND + Deformable CT, MR Chest FCN PCANet Outputs Brain PCANet Kori et al.
    ([2018](#bib.bib54)) SSD VGG Rigid MR Brain CNN Outputs MLP
- en: 4 Unsupervised Transformation Estimation
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4 无监督变换估计
- en: 'Despite the success of the methods described in the previous sections, the
    difficult nature of the acquisition of reliable ground truth remains a significant
    hindrance Uzunova et al. ([2017](#bib.bib103)). This has motivated a number of
    different groups to explore unsupervised approaches de Vos et al. ([2017](#bib.bib24));
    Li and Fan ([2018](#bib.bib61)). One key innovation that has been useful to these
    works is the spatial transformer network (STN) Jaderberg et al. ([2015](#bib.bib48)).
    Several methods use an STN to perform the deformations associated with their registration
    applications Ferrante et al. ([2018](#bib.bib32)); Kuang and Schmah ([2018](#bib.bib58)).
    This section discusses unsupervised methods that utilize image similarity metrics
    (Section [4.1](#S4.SS1 "4.1 Similarity Metric based Unsupervised Transformation
    Estimation ‣ 4 Unsupervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")) and feature representations of image data (Section
    [4.2](#S4.SS2 "4.2 Feature based Unsupervised Transformation Estimation ‣ 4 Unsupervised
    Transformation Estimation ‣ Deep Learning in Medical Image Registration: A Survey"))
    to train their networks. A description of notable works is given in Table [3](#S3.T3
    "Table 3 ‣ 3.2.2 Discussion and Assessment ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '尽管前面章节中描述的方法取得了成功，但获取可靠的真实值的困难性质仍然是一个重大障碍（Uzunova et al. ([2017](#bib.bib103)））。这促使了多个不同的研究小组探索无监督方法（de
    Vos et al. ([2017](#bib.bib24)）；Li and Fan ([2018](#bib.bib61)））。其中一个对这些研究有用的关键创新是空间变换网络（STN）（Jaderberg
    et al. ([2015](#bib.bib48)））。一些方法使用STN来执行与其配准应用相关的变形（Ferrante et al. ([2018](#bib.bib32)）；Kuang
    and Schmah ([2018](#bib.bib58)））。本节讨论了利用图像相似度度量（第 [4.1](#S4.SS1 "4.1 Similarity
    Metric based Unsupervised Transformation Estimation ‣ 4 Unsupervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey") 节）和图像数据特征表示（第
    [4.2](#S4.SS2 "4.2 Feature based Unsupervised Transformation Estimation ‣ 4 Unsupervised
    Transformation Estimation ‣ Deep Learning in Medical Image Registration: A Survey")
    节）的无监督方法来训练其网络。有关重要工作的描述见表 [3](#S3.T3 "Table 3 ‣ 3.2.2 Discussion and Assessment
    ‣ 3.2 Dual/Weakly Supervised Transformation Estimation ‣ 3 Supervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey")。'
- en: 4.1 Similarity Metric based Unsupervised Transformation Estimation
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1 基于相似度度量的无监督变换估计
- en: 4.1.1 Standard Methods
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.1 标准方法
- en: 'This section begins by discussing approaches that use a common similarity metric
    with common regularization strategies to define their loss functions. Later in
    the section, approaches that use more complex similarity metric based strategies
    are discussed. A visualization of standard similarity metric based transformation
    estimation is given in Fig. [9](#S4.F9 "Figure 9 ‣ 4.1.1 Standard Methods ‣ 4.1
    Similarity Metric based Unsupervised Transformation Estimation ‣ 4 Unsupervised
    Transformation Estimation ‣ Deep Learning in Medical Image Registration: A Survey").'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: '本节开始讨论那些使用通用相似度度量及常见正则化策略来定义其损失函数的方法。随后，本节还讨论了使用更复杂的相似度度量策略的方法。图 [9](#S4.F9
    "Figure 9 ‣ 4.1.1 Standard Methods ‣ 4.1 Similarity Metric based Unsupervised
    Transformation Estimation ‣ 4 Unsupervised Transformation Estimation ‣ Deep Learning
    in Medical Image Registration: A Survey") 给出了标准相似度度量基础上的变换估计的可视化。'
- en: '![Refer to caption](img/40c688f94984086db1050b18fb48143d.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见图注](img/40c688f94984086db1050b18fb48143d.png)'
- en: 'Figure 9: A visualization of deep single step registration where the network
    is trained using a metric that quantifies image similarity. Therefore, the approach
    is unsupervised.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 9：深度单步配准的可视化，其中网络使用量化图像相似度的度量进行训练。因此，该方法是无监督的。
- en: Inspired to overcome the difficulty associated with obtaining ground truth data,
    Li et al. Li and Fan ([2017](#bib.bib60), [2018](#bib.bib61)) trained an FCN to
    perform deformable intersubject registration of 3D brain MR volumes using ”self-supervision.”
    NCC between the warped and fixed images and several common regularization terms
    (*e.g.* smoothing constraints) constitute the loss function in this method. Although
    many manually defined similarity metrics fail in the multimodal case (with the
    occasional exception of MI), they are often suitable for the unimodal case. The
    method detailed in this work outperforms Advanced Neuroimaging Tools (ANTs) based
    registration Avants et al. ([2011](#bib.bib7)) and the deep learning methods proposed
    by Sokooti et al. Sokooti et al. ([2017](#bib.bib99)) (discussed previously) and
    Yoo et al. Yoo et al. ([2017](#bib.bib117)) (discussed in the next section).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 为了克服获得真实数据的困难，Li 等人（Li 和 Fan（[2017](#bib.bib60)，[2018](#bib.bib61)））训练了一个 FCN
    来执行 3D 脑 MR 体积的可变形跨主体配准，使用了“自我监督”。在这个方法中，变形图像和固定图像之间的 NCC 以及几个常见的正则化项（*例如* 平滑约束）构成了损失函数。虽然许多手动定义的相似性度量在多模态情况下失败（偶尔
    MI 除外），但它们通常适用于单模态情况。此工作中详细描述的方法优于基于 Advanced Neuroimaging Tools (ANTs) 的配准 Avants
    等人（[2011](#bib.bib7)）和 Sokooti 等人（[2017](#bib.bib99)）（前面讨论过）以及 Yoo 等人（[2017](#bib.bib117)）（在下一节讨论）的深度学习方法。
- en: Further, de Vos et al. de Vos et al. ([2017](#bib.bib24)) used NCC to train
    an FCN to perform the deformable registration of 4D cardiac cine MR volumes. A
    DVF is used in this method to deform the moving volume. Their method outperforms
    registration that is performed using the Elastix toolbox Klein et al. ([2010](#bib.bib53)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，de Vos 等人（[2017](#bib.bib24)）使用 NCC 训练了一个 FCN，以对 4D 心脏 MRI 动态体积进行可变形配准。在此方法中，使用
    DVF 变形移动体积。他们的方法优于使用 Elastix 工具箱 Klein 等人（[2010](#bib.bib53)）进行的配准。
- en: In another work, de Vos et al. de Vos et al. ([2018](#bib.bib23)) use a multistage,
    multiscale approach to perform unimodal registration on several datasets. NCC
    and a bending-energy regularization term are used to train the networks that predict
    an affine transformation and subsequent coarse-to-fine deformations using a B-Spline
    transformation model. In addition to validating their multi-stage approach, they
    show that their method outperforms registration that is performed using the Elastix
    toolbox Klein et al. ([2010](#bib.bib53)) with and without bending energy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 在另一项工作中，de Vos 等人（[2018](#bib.bib23)）使用多阶段、多尺度的方法对多个数据集进行单模态配准。他们利用 NCC 和弯曲能量正则化项来训练网络，这些网络预测仿射变换和随后的粗到细的变形，使用
    B-Spline 变换模型。除了验证他们的多阶段方法外，他们还表明，他们的方法在有和没有弯曲能量的情况下都优于使用 Elastix 工具箱 Klein 等人（[2010](#bib.bib53)）进行的配准。
- en: The unsupervised deformable registration framework used by Ghosal et al. Ghosal
    and Ray ([2017](#bib.bib33)) minimizes the upper bound of the SSD (UB SSD) between
    the warped and fixed 3D brain MR images. The design of their network was inspired
    by the SKIP architecture Long et al. ([2015](#bib.bib68)). This method outperforms
    log-demons based registration.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: Ghosal 等人（Ghosal 和 Ray（[2017](#bib.bib33)））使用的无监督可变形配准框架最小化变形图像和固定 3D 脑 MR 图像之间的
    SSD 上界（UB SSD）。他们网络的设计受到了 SKIP 架构 Long 等人（[2015](#bib.bib68)）的启发。这种方法优于基于 log-demons
    的配准。
- en: Shu et al. Shu et al. ([2018](#bib.bib95)) used a coarse-to-fine, unsupervised
    deformable registration approach to register images of neurons that are acquired
    using a scanning electron microscope (SEM). The mean squared error (MSE) between
    the warped and fixed volumes is used as the loss function here. Their approach
    is competitive with and faster than the sift flow framework Liu et al. ([2011](#bib.bib64)).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: Shu 等人（[2018](#bib.bib95)）使用粗到细的无监督可变形配准方法，对使用扫描电子显微镜（SEM）获得的神经元图像进行配准。在这里，变形体积和固定体积之间的均方误差（MSE）被用作损失函数。他们的方法在竞争性上优于且速度更快于
    sift flow 框架 Liu 等人（[2011](#bib.bib64)）。
- en: Sheikhjafari et al. Sheikhjafari et al. ([2018](#bib.bib93)) used learned latent
    representations to perform the deformable registration of 2D cardiac cine MR volumes.
    Deformation fields are thus obtained by embedding. This latent representation
    is used as the input to a network that is composed of 8 fully connected layers
    to obtain the transformation. The sum of absolute errors (SAE) is used as the
    loss function. Here, the registration performance was seen to be influenced by
    the B-spline grid spacing. This method outperforms a moving mesh correspondence
    based method described in Punithakumar et al. ([2017](#bib.bib83)).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: Sheikhjafari 等人 ([2018](#bib.bib93)) 使用学习的潜在表示来执行 2D 心脏 Cine MR 体积的可变形配准。因此，通过嵌入获得变形场。该潜在表示被用作输入到一个由
    8 层全连接层组成的网络中，以获得变换。绝对误差和 (SAE) 被用作损失函数。在这里，配准性能被发现受 B-spline 网格间距的影响。这种方法优于 Punithakumar
    等人 ([2017](#bib.bib83)) 描述的移动网格对应方法。
- en: Stergios et al. Stergios et al. ([2018](#bib.bib100)) used a CNN to both linearly
    and locally register inhale-exhale pairs of lung MR volumes. Therefore, both the
    affine transformation and the deformation are jointly estimated. The loss function
    is composed of an MSE term and regularization terms. Their method outperforms
    several state-of-the-art methods that do not utilized ground truth data, including
    Demons Lorenzi et al. ([2013](#bib.bib69)), SyN Avants et al. ([2008](#bib.bib6)),
    and a deep learning based method that uses an MSE loss term. Further, the inclusion
    of the regularization terms is validated by an ablation study.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: Stergios 等人 ([2018](#bib.bib100)) 使用 CNN 来对肺部 MR 体积的吸气-呼气对进行线性和局部配准。因此，仿射变换和变形都是联合估计的。损失函数由
    MSE 项和正则化项组成。他们的方法优于几种不使用真实数据的最先进方法，包括 Demons Lorenzi 等人 ([2013](#bib.bib69))、SyN
    Avants 等人 ([2008](#bib.bib6))，以及使用 MSE 损失项的深度学习方法。此外，正则化项的包含通过消融研究得到了验证。
- en: The successes of deep similarity metric based unsupervised registration motivated
    Neylon et al. Neylon et al. ([2017](#bib.bib81)) to use a neural network to learn
    the relationship between image similarity metric values and TRE when registering
    CT image volumes. This is done in order to robustly assess registration performance.
    The network was able to achieve subvoxel accuracy in 95% of cases. Similarly inspired,
    Balakrishnan et al. Balakrishnan et al. ([2018a](#bib.bib8), [b](#bib.bib9)) proposed
    a general framework for unsupervised image registration, which can be either unimodal
    or multimodal theoretically. The neural networks are trained using a selected,
    manually-defined image similarity metric (*e.g.* NCC, NMI, etc.).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 基于深度相似度度量的无监督配准的成功激励了 Neylon 等人 ([2017](#bib.bib81)) 使用神经网络来学习 CT 图像体积配准时图像相似度度量值与
    TRE 之间的关系。这是为了稳健地评估配准性能。该网络能够在 95% 的情况下实现亚体素精度。受到类似启发，Balakrishnan 等人 ([2018a](#bib.bib8),
    [b](#bib.bib9)) 提出了一个无监督图像配准的通用框架，该框架理论上可以是单模态的或多模态的。神经网络使用选定的、手动定义的图像相似度度量 (*例如*
    NCC, NMI 等) 进行训练。
- en: In a follow-up paper, Dalca et al. Dalca et al. ([2018](#bib.bib21)) casted
    deformation prediction as variational inference. Diffeomorphic integration is
    combined with a transformer layer to obtain a velocity field. Squaring and rescaling
    layers are used to integrate the velocity field to obtain the predicted deformation.
    MSE is used as the similarity metric that, along with a regularization term, define
    the loss function. Their method outperforms ANTs based registration Avants et al.
    ([2011](#bib.bib7)) and the deep learning based method described in Balakrishnan
    et al. ([2018a](#bib.bib8)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 在后续的论文中，Dalca 等人 ([2018](#bib.bib21)) 将变形预测视为变分推断。将 diffeomorphic 集成与变换层结合以获得速度场。平方和缩放层用于将速度场集成以获得预测的变形。MSE
    被用作相似度度量，它与正则化项一起定义了损失函数。他们的方法优于 ANTs 基于配准的 Avants 等人 ([2011](#bib.bib7)) 和 Balakrishnan
    等人 ([2018a](#bib.bib8)) 描述的深度学习方法。
- en: Shortly after, Kuang et al. Kuang and Schmah ([2018](#bib.bib58)) used a CNN
    and STN inspired framework to perform the deformable registration of T1-weighted
    brain MR volumes. The loss function is composed of a NCC term and a regularization
    term. This method uses Inception modules, a low capacity model, and residual connections
    instead of skip connections. They compare their method with VoxelMorph (the method
    proposed by Balakrishnan et al., described above) Balakrishnan et al. ([2018b](#bib.bib9))
    and uTIlzReg GeoShoot Vialard et al. ([2012](#bib.bib105)) using the LBPA40 and
    Mindboggle 101 datasets and demonstrate superior performance with respect to both.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: 不久之后，Kuang 等人 Kuang 和 Schmah ([2018](#bib.bib58)) 使用了 CNN 和 STN 启发的框架来执行 T1
    加权脑 MR 卷的变形配准。损失函数由一个 NCC 项和一个正则化项组成。该方法使用了 Inception 模块，一个低容量模型，以及残差连接，而不是跳跃连接。他们将其方法与
    VoxelMorph（由 Balakrishnan 等人提出的方法，如上所述）Balakrishnan 等人 ([2018b](#bib.bib9)) 和
    uTIlzReg GeoShoot Vialard 等人 ([2012](#bib.bib105)) 使用 LBPA40 和 Mindboggle 101
    数据集进行比较，并展示了在这两方面的优越性能。
- en: Building upon the progress made by the previously described metric-based approaches,
    Ferrante et al. Ferrante et al. ([2018](#bib.bib32)) used a transfer learning
    based approach to perform unimodal registration of both X-ray and cardiac cine
    images. In this work, the network is trained on data from a source domain using
    NCC as the primary loss function term and tested in a target domain. They used
    a U-net like architecture Ronneberger et al. ([2015](#bib.bib87)) and an STN Jaderberg
    et al. ([2015](#bib.bib48)) to perform the feature extraction and transformation
    estimation respectively. They demonstrated that transfer learning using either
    domain as the source or the target domain produces effective results. This method
    outperformed registration obtained using the Elastix toolbox Klein et al. ([2010](#bib.bib53))
    with parameters determined using grid search.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: 在之前描述的基于度量的方法取得进展的基础上，Ferrante 等人 ([2018](#bib.bib32)) 使用基于迁移学习的方法来执行 X 射线和心脏电影图像的单模态配准。在这项工作中，网络在源领域的数据上进行训练，使用
    NCC 作为主要的损失函数项，并在目标领域进行测试。他们使用了类似 U-net 的架构 Ronneberger 等人 ([2015](#bib.bib87))
    和 STN Jaderberg 等人 ([2015](#bib.bib48)) 分别执行特征提取和变换估计。他们展示了使用任一领域作为源或目标领域的迁移学习都能产生有效的结果。该方法优于使用
    Elastix 工具箱 Klein 等人 ([2010](#bib.bib53)) 以及使用网格搜索确定参数的配准结果。
- en: Although applying similarity metric based approaches to the multimodal case
    is difficult, Sun et al. Sun and Zhang ([2018](#bib.bib101)) proposed an unsupervised
    method for 3D MR/US brain registration that uses a 3D CNN that consists of a feature
    extractor and a deformation field generator. This network is trained using a similarity
    metric that incorporates both pixel intensity and gradient information. Further,
    both image intensity and gradient information are used as inputs into the CNN.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管将基于相似性度量的方法应用于多模态情况是困难的，Sun 等人 Sun 和 Zhang ([2018](#bib.bib101)) 提出了一个无监督的
    3D MR/US 脑配准方法，该方法使用一个由特征提取器和变形场生成器组成的 3D CNN。该网络使用一个包含像素强度和梯度信息的相似性度量进行训练。此外，图像强度和梯度信息都作为输入用于
    CNN。
- en: 4.1.2 Extensions
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.2 扩展
- en: Cao et al. Cao et al. ([2018](#bib.bib12)) also applied similarity metric based
    training to the multimodal case. Specifically, they used intra-modality image
    similarity to supervise the multimodal deformable registration of 3D pelvic CT/MR
    volumes. The NCC between the moving image that is warped using the ground truth
    transformation and the moving image that is warped using the predicted transformation
    is used as the loss function. This work utilizes ”dual” supervision (*i.e.* the
    intra-modality supervision previously described is used for both the CT and the
    MR images). This is not to be confused with the dual supervision strategies described
    earlier.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: Cao 等人 ([2018](#bib.bib12)) 还将基于相似性度量的训练应用于多模态情况。具体而言，他们使用模态内图像相似性来监督 3D 骨盆
    CT/MR 卷的多模态变形配准。通过使用真实变换扭曲的移动图像与使用预测变换扭曲的移动图像之间的 NCC 作为损失函数。该工作利用了“双重”监督（*即*之前描述的模态内监督同时用于
    CT 和 MR 图像）。这与之前描述的双重监督策略不同。
- en: Inspired by the limiting nature of the asymmetric transformations that typical
    unsupervised methods estimate, Zhang et al. Zhang ([2018](#bib.bib118)) used their
    network Inverse-Consistent Deep Network (ICNet)-to learn the symmetric diffeomorphic
    transformations for each of the brain MR volumes that are aligned into the same
    space. Different from other works that use standard regularization strategies,
    this work introduces an inverse-consistent regularization term and an anti-folding
    regularization term to ensure that a highly weighted smoothness constraint does
    not result in folding. Finally, the MSD between the two images allows this network
    to be trained in an unsupervised manner. This method outperformed SyN based registration
    Avants et al. ([2008](#bib.bib6)), Demons based registration Lorenzi et al. ([2013](#bib.bib69)),
    and several deep learning based approaches.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 受限于典型无监督方法估计的不对称变换的限制性质，Zhang 等人（Zhang ([2018](#bib.bib118))）使用了他们的网络逆一致深度网络（ICNet）来学习对齐到相同空间中的每个脑部
    MR 体积的对称同胚变换。不同于其他使用标准正则化策略的工作，这项工作引入了逆一致正则化项和抗折叠正则化项，以确保高度加权的平滑约束不会导致折叠。最后，两个图像之间的
    MSD 使得该网络能够以无监督的方式进行训练。该方法优于基于 SyN 的配准（Avants et al. ([2008](#bib.bib6))）、基于 Demons
    的配准（Lorenzi et al. ([2013](#bib.bib69))）以及几种基于深度学习的方法。
- en: The next three approaches described in this section used a GAN for their applications.
    Unlike the GAN-based approaches described previously, these methods use neither
    ground truth data nor manually crafted segmentations. Mahapatra et al. Mahapatra
    ([2018](#bib.bib73)) used a GAN to implicitly learn the density function that
    represents the range of plausible deformations of cardiac cine images and multimodal
    retinal images (retinal colour fundus images and fluorescein angiography (FA)
    images). In addition to NMI, structual similarity index measure (SSIM), and a
    feature perceptual loss term (determined by the SSD between VGG outputs), the
    loss function is comprised of conditional and cyclic constraints, which are based
    on recent advances involving the implementation of adversarial frameworks. Their
    approach outperforms registration that is performed using the Elastix toolbox
    Klein et al. ([2010](#bib.bib53)) and the method proposed by de Vos et al. de Vos
    et al. ([2017](#bib.bib24)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
  zh: 本节描述的接下来的三种方法使用了 GAN 进行其应用。与之前描述的基于 GAN 的方法不同，这些方法既不使用真实数据，也不使用手动构造的分割。Mahapatra
    等人（Mahapatra ([2018](#bib.bib73))）使用 GAN 隐式学习表示心脏电影图像和多模态视网膜图像（视网膜彩色眼底图像和荧光素眼底血管造影（FA）图像）可能变形范围的密度函数。除了
    NMI、结构相似性指数度量（SSIM）和特征感知损失项（由 VGG 输出之间的 SSD 确定），损失函数还包括基于最近的对抗性框架实现的条件和循环约束。他们的方法优于使用
    Elastix 工具箱（Klein et al. ([2010](#bib.bib53))）和 de Vos 等人提出的方法（de Vos et al. ([2017](#bib.bib24))）进行的配准。
- en: Further, Fan et al. Fan et al. ([2018a](#bib.bib30)) used a GAN to perform unsupervised
    deformable image registration of 3D brain MR volumes. Unlike most other unsupervised
    works that use a manually crafted similarity metric to determine the loss function
    and unlike the previous approach that used a GAN to ensure that the predicted
    deformation is realistic, this approach uses a discriminator to assess the quality
    of the alignment. This approach outperforms Diffeomorphic Demons and SyN registration
    on every dataset except for MGH10\. Further, the use of the discriminator for
    supervision of the registration network is superior to the use of ground truth
    data, SSD, and CC on all datasets.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Fan 等人（Fan et al. ([2018a](#bib.bib30))）使用 GAN 执行 3D 脑 MR 体积的无监督可变形图像配准。与大多数其他使用手动构造相似性度量来确定损失函数的无监督工作不同，也不同于之前使用
    GAN 确保预测变形真实的 approach，这种方法使用判别器来评估对齐的质量。该方法在每个数据集上均优于 Diffeomorphic Demons 和
    SyN 配准，除了 MGH10。此外，使用判别器对配准网络的监督优于使用真实数据、SSD 和 CC 的所有数据集。
- en: 'Different from the hitherto previously described works (not just the GAN based
    ones), Mahapatra et al. Mahapatra et al. ([2018](#bib.bib74)) proposed simultaneous
    segmentation and registration of chest X-rays using a GAN framework. The network
    takes 3 inputs: reference image, floating image, and the segmentation mask of
    the reference image and outputs the segmentation mask of the transformed image,
    and the deformation field. Three discriminators are used to assess the quality
    of the generated outputs (deformation field, warped image, and segmentation) using
    cycle consistency and a dice metric. The generator is additionally trained using
    NMI, SSIM, and a feature perceptual loss term.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 与此前描述的工作（不仅仅是基于 GAN 的工作）不同，Mahapatra 等人 ([2018](#bib.bib74)) 提出了使用 GAN 框架同时进行胸部
    X 光片的分割和配准。网络接受 3 个输入：参考图像、浮动图像和参考图像的分割掩模，并输出变换后图像的分割掩模和变形场。使用三个判别器通过循环一致性和 Dice
    指标来评估生成输出（变形场、变形图像和分割）的质量。生成器还通过 NMI、SSIM 和特征感知损失项进行额外训练。
- en: Finally, instead of predicting a deformation field given a fixed parameterization
    as the other methods in this section do, Jiang et al. Jiang and Shackleford ([2018](#bib.bib50))
    used a CNN to learn an optimal parameterization of an image deformation using
    a multi-grid B-Spline method and L1-norm regularization. They use this approach
    to parameterize the deformable registration of 4D CT thoracic image volumes. Here,
    SSD is used as the similarity metric and L-BFGS-B is used as the optimizer. The
    convergence rate using the parameterized deformation model obtained using the
    proposed method is faster than the one obtained using a traditional L1-norm regularized
    multi-grid parameterization.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，与本节中其他方法根据固定参数化预测变形场的做法不同，Jiang 等人 ([2018](#bib.bib50)) 使用 CNN 通过多网格 B-Spline
    方法和 L1 范数正则化来学习图像变形的最佳参数化。他们使用这种方法对 4D CT 胸部图像体积进行可变形配准。这里使用 SSD 作为相似性度量，并使用 L-BFGS-B
    作为优化器。使用所提出的方法获得的参数化变形模型的收敛速度比使用传统的 L1 范数正则化多网格参数化获得的模型更快。
- en: 4.1.3 Discussion and Assessment
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.1.3 讨论与评估
- en: Image similarity based unsupervised image registration has received a lot of
    attention from the research community recently because it bypasses the need for
    expert labels of any kind. This means that the performance of the model will not
    depend on the expertise of the practitioner. Further, extensions of the original
    similarity metric based method that introduce more sophisticated similarity metrics
    (*e.g.* the discriminator of a GAN) and/or regularization strategies have yielded
    promising results. However, it is still difficult to quantify image similarity
    for multimodal registration applications. As a result, the scope of unsupervised,
    image similarity based works is largely confined to the unimodal case. Given that
    multimodal registration is often needed in many clinical applications, we expect
    to see more papers in the near future that will tackle this challenging problem.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 基于图像相似性的无监督图像配准最近受到了研究界的广泛关注，因为它绕过了对任何形式专家标签的需求。这意味着模型的性能不会依赖于从业者的专业知识。此外，引入更复杂相似性度量（*例如*
    GAN 的判别器）和/或正则化策略的原始相似性度量方法的扩展已经取得了令人鼓舞的结果。然而，定量化多模态配准应用的图像相似性仍然是一个困难的任务。因此，无监督图像相似性相关工作的范围在很大程度上局限于单模态情况。鉴于多模态配准在许多临床应用中常常是必需的，我们期待在不久的将来看到更多解决这一挑战性问题的论文。
- en: 4.2 Feature based Unsupervised Transformation Estimation
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2 基于特征的无监督变换估计
- en: 'In this section, methods that use learned feature representations to train
    neural networks are surveyed. Like the methods surveyed in the previous section,
    the methods surveyed in this section do not require ground truth data. In this
    section, approaches that create unimodal registration pipelines are presented
    first. Then, an approach that tackles multimodal image registration is discussed.
    A visualization of featured based transformation estimation is given in Fig. [10](#S4.F10
    "Figure 10 ‣ 4.2.1 Unimodal Registration ‣ 4.2 Feature based Unsupervised Transformation
    Estimation ‣ 4 Unsupervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一节中，调查了使用学习到的特征表示来训练神经网络的方法。与前一节调查的方法类似，本节调查的方法不需要真实数据。本节首先介绍创建单模态注册管道的方法。接着，讨论了处理多模态图像注册的方法。图
    [10](#S4.F10 "图 10 ‣ 4.2.1 单模态注册 ‣ 4.2 基于特征的无监督变换估计 ‣ 4 无监督变换估计 ‣ 医学图像注册中的深度学习：综述")
    给出了基于特征的变换估计的可视化。
- en: 4.2.1 Unimodal Registration
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1 单模态注册
- en: Yoo et al. Yoo et al. ([2017](#bib.bib117)) used an STN to register serial-section
    electron microscopy images (ssEMs). An autoencoder is trained to reconstruct fixed
    images and the L2 distance between reconstructed fixed images and corresponding
    warped moving images is used along with several regularization terms to construct
    the loss function. This approach outperforms the bUnwarpJ registration technique
    Arganda-Carreras et al. ([2006](#bib.bib5)) and the Elastic registration technique
    Saalfeld et al. ([2012](#bib.bib89)).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: Yoo 等人 ([2017](#bib.bib117)) 使用 STN 注册了串行切片电子显微镜图像（ssEMs）。一个自动编码器被训练来重建固定图像，重建的固定图像与对应的变形移动图像之间的
    L2 距离与几个正则化项一起用于构建损失函数。该方法优于 bUnwarpJ 注册技术 Arganda-Carreras 等人 ([2006](#bib.bib5))
    和弹性注册技术 Saalfeld 等人 ([2012](#bib.bib89))。
- en: In the same year, Liu et al. Liu and Leung ([2017](#bib.bib67)) proposed a tensor
    based MIND method using a principle component analysis based network (PCANet)
    Chan et al. ([2015](#bib.bib14)) for both unimodal and multimodal registration.
    Both inhale-exhale pairs of thoracic CT volumes and multimodal pairs of brain
    MR images are used for experimental validation of this approach. MI and residual
    complexity (RC) based Myronenko and Song ([2010](#bib.bib79)), and the original
    MIND-based Heinrich et al. ([2012](#bib.bib38)) registration techniques were outperformed
    by the proposed method.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 同年，Liu 等人 Liu 和 Leung ([2017](#bib.bib67)) 提出了基于张量的 MIND 方法，使用基于主成分分析的网络（PCANet）Chan
    等人 ([2015](#bib.bib14)) 进行单模态和多模态注册。使用了呼吸对胸部 CT 体积和多模态脑部 MR 图像对来验证该方法。提出的方法优于基于
    MI 和残差复杂性（RC）的 Myronenko 和 Song ([2010](#bib.bib79)) 以及原始 MIND 基于的 Heinrich 等人
    ([2012](#bib.bib38)) 注册技术。
- en: '![Refer to caption](img/32232b6d2203077015d00c48adab8874.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/32232b6d2203077015d00c48adab8874.png)'
- en: 'Figure 10: A visualization of feature based unsupervised image registration.
    Here, a feature extractor is used to map inputted images to a feature space to
    facilitate the prediction of transformation parameters.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '图 10: 基于特征的无监督图像注册的可视化。在这里，使用特征提取器将输入图像映射到特征空间，以便于预测变换参数。'
- en: Krebs et al. Krebs et al. ([2018a](#bib.bib56), [b](#bib.bib57)) performed the
    registration of 2D brain and cardiac MRs and bypassed the need for spatial regularization
    using a stochastic latent space learning approach. A conditional variational autoencoder
    Doersch ([2016](#bib.bib25)) is used to ensure that the parameter space follows
    a prescribed probability distribution. The negative log liklihood of the fixed
    image given the latent representation and the warped volume and KL divergence
    of the latent distribution from a prior distribution are used to define the loss
    function. This method outperforms the Demons technique Lorenzi et al. ([2013](#bib.bib69))
    and the deep learning method described in Balakrishnan et al. ([2018a](#bib.bib8)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: Krebs 等人 ([2018a](#bib.bib56), [b](#bib.bib57)) 对 2D 脑部和心脏 MR 进行了注册，并通过随机潜空间学习方法避免了空间正则化的需求。使用条件变分自动编码器
    Doersch ([2016](#bib.bib25)) 来确保参数空间遵循规定的概率分布。固定图像的负对数似然给定潜在表示和变形体积，以及潜在分布与先验分布之间的
    KL 散度被用来定义损失函数。该方法优于 Demons 技术 Lorenzi 等人 ([2013](#bib.bib69)) 和 Balakrishnan
    等人 ([2018a](#bib.bib8)) 描述的深度学习方法。
- en: 4.2.2 Multimodal Registration
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2 多模态注册
- en: Unlike all of the other methods described in this section, Kori et al. perform
    feature extraction and affine transformation parameter regression for the multimodal
    registration of 2-D T1 and T2 weighted brain MRs in an unsupervised capacity using
    pre-trained networks Kori et al. ([2018](#bib.bib54)). The images are binarized
    and then the Dice score between the moving and the fixed images is used as the
    cost function. As the appearance difference between these two modalities is not
    significant, the use of these pre-trained models can be reasonably effective.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 与本节中描述的其他所有方法不同，Kori 等人使用预训练网络 Kori 等人 ([2018](#bib.bib54)) 以无监督的方式进行 2-D T1
    和 T2 加权脑 MRI 的多模态配准，进行特征提取和仿射变换参数回归。这些图像被二值化，然后在移动图像和固定图像之间的 Dice 分数作为代价函数。由于这两种模态之间的外观差异不显著，因此使用这些预训练模型可能会相对有效。
- en: 4.2.3 Discussion and Assessment
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.3 讨论与评估
- en: Performing multimodal image registration in an unsupervised capacity is significantly
    more difficult than performing unimodal image registration because of the difficulty
    associated with using manually crafted similarity metrics to quantify the similarity
    between the two images, and generally using the unsupervised techniques described
    above to establish/detect voxel-to-voxel correspondence. The use of unsupervised
    learning to learn feature representations to determine an optimal transformation
    has generated significant interest from the research community recently. Along
    with the previously discussed unsupervised image registration method, we expect
    feature based unsupervised registration to continue to generate significant interest
    from the research community. Further, extension to the multimodal case (especially
    for applications that use image with significant appearance differences) is likely
    to be a prominent research focus in the next few years.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 在无监督条件下进行多模态图像配准显著比单模态图像配准更加困难，因为使用手动设计的相似性度量来量化两幅图像之间的相似性是具有挑战性的，并且通常使用上述无监督技术来建立/检测体素对体素的对应关系。使用无监督学习来学习特征表示以确定最佳变换最近引起了研究界的广泛关注。除了之前讨论的无监督图像配准方法外，我们预计基于特征的无监督配准将继续引起研究界的显著兴趣。此外，扩展到多模态情况（尤其是用于具有显著外观差异的图像的应用）可能会成为未来几年内一个重要的研究重点。
- en: 5 Research Trends and Future Directions
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5 研究趋势与未来方向
- en: 'In this section, we summarize the current research trends and future directions
    of deep learning in medical image registration. As we can see from Fig. [2](#S1.F2
    "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration: A Survey"),
    some research trends have emerged. First, deep learning based medical image registration
    seems to be following the observed trend for the general application of deep learning
    to medical image analysis. Second, unsupervised transformation estimation methods
    have been garnering more attention recently from the research community. Further,
    deep learning based methods consistently outperform traditional optimization based
    techniques Nazib et al. ([2018](#bib.bib80)). Based on the observed research trends,
    we speculate that the following research directions will receive more attention
    in the research community.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们总结了深度学习在医学图像配准中的当前研究趋势和未来方向。从图 Fig. [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION
    ‣ Deep Learning in Medical Image Registration: A Survey") 中可以看到，一些研究趋势已经显现。首先，基于深度学习的医学图像配准似乎遵循了深度学习在医学图像分析中的一般应用趋势。其次，无监督变换估计方法最近获得了更多的研究关注。此外，基于深度学习的方法始终优于传统的基于优化的技术
    Nazib 等人 ([2018](#bib.bib80))。基于观察到的研究趋势，我们推测以下研究方向将在研究界获得更多关注。'
- en: 5.1 Deep Adversarial Image Registration
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.1 深度对抗图像配准
- en: 'We further speculate that GANs will be used more frequently in deep learning
    based image registration in the next few years. As described above, GANs can serve
    several different purposes in deep learning based medical image registration:
    using a discriminator as a learned similarity metric, ensuring that predicted
    transformations are realistic, and using a GAN to perform image translation to
    transform a multimodal registration problem into a unimodal registration problem.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 我们进一步推测，未来几年 GANs 在基于深度学习的图像配准中将被更频繁地使用。如上所述，GANs 可以在基于深度学习的医学图像配准中发挥多种不同的作用：使用判别器作为学习的相似性度量，确保预测的变换是现实的，并使用
    GAN 执行图像翻译，将多模态配准问题转化为单模态配准问题。
- en: GAN-like frameworks have been used in several works to directly train transformation
    predicting neural networks. Several recent works Fan et al. ([2018a](#bib.bib30));
    Yan et al. ([2018](#bib.bib111)) use a discriminator to discern between aligned
    and misaligned image pairs. Although the training paradigm borrows from an unsupervised
    training strategy, the discriminator requires pre-aligned image pairs. Therefore,
    it will have limited success in multimodal or challenging unimodal applications
    where it is difficult to register images. Because discriminators are trained to
    assign all misaligned image pairs the same label, they will likely be unable to
    model a spectrum of misalignments. Despite this limitation, the application of
    GANs to medical image registration are still quite promising and will be described
    below.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 类似GAN的框架已经在多个工作中用于直接训练变换预测神经网络。几个近期的研究 Fan et al. ([2018a](#bib.bib30)); Yan
    et al. ([2018](#bib.bib111)) 使用鉴别器来区分对齐和未对齐的图像对。尽管训练范式借鉴了无监督训练策略，但鉴别器需要预对齐的图像对。因此，在多模态或挑战性的单模态应用中，它的成功会受到限制，因为在这些应用中图像配准困难。由于鉴别器被训练为给所有未对齐的图像对分配相同的标签，它们可能无法建模各种未对齐情况。尽管存在这一限制，GAN在医学图像配准中的应用仍然非常有前景，下面将进行描述。
- en: Unconstrained deformation field prediction can result in warped moving images
    with unrealistic organ appearances. A common approach is to add the L2 norm of
    the predicted deformation field, its gradient, or its Laplacian to the loss function.
    However, the use of such regularization terms may limit the magnitude of the deformations
    that neural networks are able to predict. Therefore, Hu et al. Hu et al. ([2018a](#bib.bib42))
    explored the use of a GAN-like framework to produce realistic deformations. Constraining
    the deformation prediction using a discriminator results in superior performance
    relative to the use of L2 norm regularization in that work.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: 无约束的变形场预测可能会导致变形图像出现不现实的器官外观。一种常见的方法是将预测的变形场、其梯度或其拉普拉斯的L2范数添加到损失函数中。然而，这些正则化项的使用可能会限制神经网络能够预测的变形幅度。因此，Hu
    et al. Hu et al. ([2018a](#bib.bib42)) 探索了使用类似GAN的框架来产生真实的变形。使用鉴别器约束变形预测相较于使用L2范数正则化在该工作中表现更优。
- en: Lastly, GANs can be used to map medical images in a source domain (*e.g.* MR)
    to a target domain (*e.g.* CT) Choi et al. ([2018](#bib.bib19)); Isola et al.
    ([2017](#bib.bib46)); Liu et al. ([2017](#bib.bib66)); Yi et al. ([2017](#bib.bib116)),
    regardless of whether or not paired training data is available Zhu et al. ([2017](#bib.bib121)).
    This image appearance reduction technique would be advantageous because many unimodal
    unsupervised registration methods use similarity metrics that often fail in the
    multimodal case. If image translation is performed as a pre-processing step, then
    commonly used similarity metrics could be used to define the loss function of
    transformation predicting networks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 最后，GANs 可以用于将源领域的医学图像（*例如* MR）映射到目标领域（*例如* CT）Choi et al. ([2018](#bib.bib19));
    Isola et al. ([2017](#bib.bib46)); Liu et al. ([2017](#bib.bib66)); Yi et al.
    ([2017](#bib.bib116))，无论是否有配对的训练数据 Zhu et al. ([2017](#bib.bib121))。这种图像外观减少技术将具有优势，因为许多单模态无监督配准方法使用的相似性度量在多模态情况下常常失败。如果图像翻译作为预处理步骤进行，那么常用的相似性度量可以用于定义变换预测网络的损失函数。
- en: 5.2 Reinforcement Learning based Registration
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.2 基于强化学习的配准
- en: 'We also project that reinforcement learning will also be more commonly used
    for medical image registration in the next few years because it is very intuitive
    and can mimic the manner in which physicians perform registration. It should be
    noted that there are some unique challenges associated with deep learning based
    medical image registration: including the dimensionality of the action space in
    the deformable registration case. However, we believe that such limitations are
    surmountable because there is already one proposed method that uses reinforcement
    learning based registration with a deformable transformation model Krebs et al.
    ([2017](#bib.bib55)).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
  zh: 我们还预测，在未来几年中，强化学习将在医学图像配准中得到更广泛的应用，因为它非常直观，可以模拟医生进行配准的方式。需要注意的是，基于深度学习的医学图像配准面临一些独特的挑战，例如在可变形配准情况下的动作空间维度。然而，我们相信这些限制是可以克服的，因为已经有一种方法使用了基于强化学习的配准和可变形变换模型
    Krebs et al. ([2017](#bib.bib55))。
- en: 5.3 Raw Imaging Domain Registration
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 5.3 原始成像领域配准
- en: This article has focused on surveying methods performing registration using
    reconstructed images. However, we speculate that it is possible to incorporate
    reconstruction into an end-to-end deep learning based registration pipeline. In
    2016, Wang Wang ([2016](#bib.bib107)) postulated that deep neural networks could
    be used to perform image reconstruction. Further, several works Rivenson et al.
    ([2018](#bib.bib85)); Smith et al. ([2019](#bib.bib98)); Yao et al. ([2018](#bib.bib115));
    Zhu et al. ([2018](#bib.bib120)) recently demonstrated the ability of deep learning
    to map data points in the raw data domain to the reconstructed image domain. Therefore,
    it is reasonable to expect that registration pipelines that take raw data as input
    and output registered, reconstructed images can be developed within the next few
    years.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
  zh: 本文重点调查了使用重建图像进行配准的方法。然而，我们推测将重建纳入端到端的基于深度学习的配准流程是可能的。在2016年，Wang Wang（[2016](#bib.bib107)）假设深度神经网络可以用于图像重建。此外，Rivenson
    等人（[2018](#bib.bib85)）；Smith 等人（[2019](#bib.bib98)）；Yao 等人（[2018](#bib.bib115)）；Zhu
    等人（[2018](#bib.bib120)）最近展示了深度学习在原始数据领域与重建图像领域之间映射数据点的能力。因此，合理预期在未来几年内可以开发出以原始数据为输入、输出注册重建图像的配准流程。
- en: 6 Conclusion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 6 结论
- en: In this article, the recent works that use deep learning to perform medical
    image registration have been examined. As each application has its own unique
    challenges, the creation of the deep learning based frameworks must be carefully
    designed. Many deep learning based medical image registration applications share
    similar challenges including the lack of a robust similarity metric for multimodal
    applications, in which there are significant image appearance differences and/or
    different fields of view (*e.g.* MR-TRUS registration) Haskins et al. ([2019](#bib.bib36)),
    the lack of availability of large datasets, the challenge associated with obtaining
    segmentations and ground truth registrations, and quantifying the uncertainty
    of a model’s prediction. Application-specific similarity metrics, patch-wise frameworks,
    unsupervised approaches, and variational autoencoder inspired registration frameworks
    are examples of popular solutions to these challenges. Furthermore, despite the
    sophistication of many of the methods discussed in this survey, resampling and
    interpolation are often not among the components of registration that are learned
    by the neural network. While researchers started to pay attention to this aspect
    Ali and Rittscher ([2019](#bib.bib2)), we expect more works to incorporate these
    components into their deep learning based methods as the field continues to mature.
    Recent successes have demonstrated the impact of the application of deep learning
    to medical image registration. This trend can be observed across medical imaging
    applications. Many future exciting works are sure to build on the recent progress
    that has been outlined in this paper.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 本文审视了利用深度学习进行医学图像配准的近期研究。由于每个应用都有其独特的挑战，因此基于深度学习的框架创建必须经过精心设计。许多基于深度学习的医学图像配准应用面临相似的挑战，包括缺乏适用于多模态应用的稳健相似性度量，其中存在显著的图像外观差异和/或不同的视场（*例如*
    MR-TRUS配准）Haskins 等人（[2019](#bib.bib36)），缺乏大规模数据集，获取分割和真实配准的挑战，以及量化模型预测不确定性。特定应用的相似性度量、基于补丁的框架、无监督方法和受变分自编码器启发的配准框架是这些挑战的流行解决方案。此外，尽管本文讨论的许多方法都很复杂，但重采样和插值通常不是神经网络学习的配准组件之一。虽然研究人员开始关注这一方面Ali
    和 Rittscher（[2019](#bib.bib2)），但我们期望随着领域的不断成熟，更多的工作将把这些组件纳入其基于深度学习的方法中。近期的成功展示了深度学习在医学图像配准中的应用影响。这一趋势可以在医学成像应用中观察到。许多未来令人兴奋的工作肯定会在本文概述的近期进展基础上进行构建。
- en: References
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: 'Abadi et al. (2016) Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean,
    J., Devin, M., Ghemawat, S., Irving, G., Isard, M., et al. (2016). Tensorflow:
    a system for large-scale machine learning. In OSDI, volume 16, pages 265–283.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Abadi 等人（2016）Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean, J.,
    Devin, M., Ghemawat, S., Irving, G., Isard, M., 等（2016）。Tensorflow: 一个大规模机器学习系统。在
    OSDI, 第16卷, 页265–283。'
- en: 'Ali and Rittscher (2019) Ali, S. and Rittscher, J. (2019). Conv2warp: An unsupervised
    deformable image registration with continuous convolution and warping.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Ali 和 Rittscher（2019）Ali, S. 和 Rittscher, J.（2019）。Conv2warp: 一种无监督的可变形图像配准方法，具有连续卷积和变形。'
- en: 'Alom et al. (2018) Alom, M. Z., Taha, T. M., Yakopcic, C., Westberg, S., Hasan,
    M., Van Esesn, B. C., Awwal, A. A. S., and Asari, V. K. (2018). The history began
    from alexnet: A comprehensive survey on deep learning approaches. arXiv preprint
    arXiv:1803.01164.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alom 等 (2018) Alom, M. Z., Taha, T. M., Yakopcic, C., Westberg, S., Hasan, M.,
    Van Esesn, B. C., Awwal, A. A. S., 和 Asari, V. K. (2018). 从 AlexNet 开始的历史：深度学习方法的全面调查。arXiv
    预印本 arXiv:1803.01164。
- en: Ambinder (2005) Ambinder, E. P. (2005). A history of the shift toward full computerization
    of medicine. Journal of oncology practice, 1(2):54–56.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ambinder (2005) Ambinder, E. P. (2005). 向医学全计算化转变的历史。肿瘤学实践杂志，1(2):54–56。
- en: Arganda-Carreras et al. (2006) Arganda-Carreras, I., Sorzano, C. O., Marabini,
    R., Carazo, J. M., Ortiz-de Solorzano, C., and Kybic, J. (2006). Consistent and
    elastic registration of histological sections using vector-spline regularization.
    In International Workshop on Computer Vision Approaches to Medical Image Analysis,
    pages 85–95\. Springer.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arganda-Carreras 等 (2006) Arganda-Carreras, I., Sorzano, C. O., Marabini, R.,
    Carazo, J. M., Ortiz-de Solorzano, C., 和 Kybic, J. (2006). 使用向量样条正则化的一致性和弹性组织切片配准。在医学图像分析计算机视觉方法国际研讨会论文集中，页面
    85–95。Springer。
- en: 'Avants et al. (2008) Avants, B. B., Epstein, C. L., Grossman, M., and Gee,
    J. C. (2008). Symmetric diffeomorphic image registration with cross-correlation:
    evaluating automated labeling of elderly and neurodegenerative brain. Medical
    image analysis, 12(1):26–41.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avants 等 (2008) Avants, B. B., Epstein, C. L., Grossman, M., 和 Gee, J. C. (2008).
    具有交叉相关的对称微分同胚图像配准：评估老年和神经退行性脑部的自动标注。医学图像分析，12(1):26–41。
- en: Avants et al. (2011) Avants, B. B., Tustison, N. J., Song, G., Cook, P. A.,
    Klein, A., and Gee, J. C. (2011). A reproducible evaluation of ants similarity
    metric performance in brain image registration. Neuroimage, 54(3):2033–2044.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Avants 等 (2011) Avants, B. B., Tustison, N. J., Song, G., Cook, P. A., Klein,
    A., 和 Gee, J. C. (2011). ANTs 相似度度量性能在脑部图像配准中的可重复评估。神经影像学，54(3):2033–2044。
- en: Balakrishnan et al. (2018a) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag,
    J., and Dalca, A. V. (2018a). An unsupervised learning model for deformable medical
    image registration. In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pages 9252–9260.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balakrishnan 等 (2018a) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag, J.,
    和 Dalca, A. V. (2018a). 一种用于可变形医学图像配准的无监督学习模型。在 IEEE 计算机视觉与模式识别会议论文集中，页面 9252–9260。
- en: 'Balakrishnan et al. (2018b) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag,
    J., and Dalca, A. V. (2018b). Voxelmorph: A learning framework for deformable
    medical image registration. arXiv preprint arXiv:1809.05231.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Balakrishnan 等 (2018b) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag, J.,
    和 Dalca, A. V. (2018b). Voxelmorph：用于可变形医学图像配准的学习框架。arXiv 预印本 arXiv:1809.05231。
- en: Blendowski and Heinrich (2018) Blendowski, M. and Heinrich, M. P. (2018). Combining
    mrf-based deformable registration and deep binary 3d-cnn descriptors for large
    lung motion estimation in copd patients. International journal of computer assisted
    radiology and surgery, pages 1–10.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Blendowski 和 Heinrich (2018) Blendowski, M. 和 Heinrich, M. P. (2018). 结合基于 MRF
    的可变形配准和深度二进制 3D-CNN 描述符，用于 COPD 患者的大范围肺部运动估计。计算机辅助放射学与外科学国际杂志，页面 1–10。
- en: Cao et al. (2015) Cao, T., Singh, N., Jojic, V., and Niethammer, M. (2015).
    Semi-coupled dictionary learning for deformation prediction. In Biomedical Imaging
    (ISBI), 2015 IEEE 12th International Symposium on, pages 691–694\. IEEE.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 (2015) Cao, T., Singh, N., Jojic, V., 和 Niethammer, M. (2015). 用于形变预测的半耦合字典学习。在2015
    IEEE 第十二届国际生物医学影像学研讨会 (ISBI)，页面 691–694。IEEE。
- en: Cao et al. (2018) Cao, X., Yang, J., Wang, L., Xue, Z., Wang, Q., and Shen,
    D. (2018). Deep learning based inter-modality image registration supervised by
    intra-modality similarity. arXiv preprint arXiv:1804.10735.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 (2018) Cao, X., Yang, J., Wang, L., Xue, Z., Wang, Q., 和 Shen, D. (2018).
    基于深度学习的跨模态图像配准，受限于同模态相似性监督。arXiv 预印本 arXiv:1804.10735。
- en: Cao et al. (2017) Cao, X., Yang, J., Zhang, J., Nie, D., Kim, M., Wang, Q.,
    and Shen, D. (2017). Deformable image registration based on similarity-steered
    cnn regression. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 300–308\. Springer.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao 等 (2017) Cao, X., Yang, J., Zhang, J., Nie, D., Kim, M., Wang, Q., 和 Shen,
    D. (2017). 基于相似性引导 CNN 回归的可变形图像配准。在医学图像计算与计算机辅助手术国际会议论文集中，页面 300–308。Springer。
- en: 'Chan et al. (2015) Chan, T.-H., Jia, K., Gao, S., Lu, J., Zeng, Z., and Ma,
    Y. (2015). Pcanet: A simple deep learning baseline for image classification? IEEE
    Transactions on Image Processing, 24(12):5017–5032.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan 等 (2015) Chan, T.-H., Jia, K., Gao, S., Lu, J., Zeng, Z., 和 Ma, Y. (2015).
    PCANet：图像分类的简单深度学习基线？IEEE 图像处理汇刊，24(12):5017–5032。
- en: 'Chee and Wu (2018) Chee, E. and Wu, J. (2018). Airnet: Self-supervised affine
    registration for 3d medical images using neural networks. arXiv preprint arXiv:1810.02583.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chee 和 Wu (2018) Chee, E. 和 Wu, J. (2018). Airnet: 使用神经网络进行 3D 医学图像的自监督仿射配准。arXiv
    预印本 arXiv:1810.02583。'
- en: 'Chen et al. (2015) Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao,
    T., Xu, B., Zhang, C., and Zhang, Z. (2015). Mxnet: A flexible and efficient machine
    learning library for heterogeneous distributed systems. arXiv preprint arXiv:1512.01274.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chen 等 (2015) Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao,
    T., Xu, B., Zhang, C., 和 Zhang, Z. (2015). Mxnet: 一个用于异构分布式系统的灵活高效的机器学习库。arXiv
    预印本 arXiv:1512.01274。'
- en: Cheng et al. (2016) Cheng, X., Zhang, L., and Zheng, Y. (2016). Deep similarity
    learning for multimodal medical images. In International conference on medical
    image computing and computer-assisted intervention.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等 (2016) Cheng, X., Zhang, L., 和 Zheng, Y. (2016). 用于多模态医学图像的深度相似性学习。国际医学图像计算与计算机辅助干预会议。
- en: 'Cheng et al. (2018) Cheng, X., Zhang, L., and Zheng, Y. (2018). Deep similarity
    learning for multimodal medical images. Computer Methods in Biomechanics and Biomedical
    Engineering: Imaging & Visualization, 6(3):248–252.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng 等 (2018) Cheng, X., Zhang, L., 和 Zheng, Y. (2018). 用于多模态医学图像的深度相似性学习。计算机方法在生物力学与生物医学工程：成像与可视化，6(3):248–252。
- en: 'Choi et al. (2018) Choi, Y., Choi, M., Kim, M., Ha, J.-W., Kim, S., and Choo,
    J. (2018). Stargan: Unified generative adversarial networks for multi-domain image-to-image
    translation. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 8789–8797.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Choi 等 (2018) Choi, Y., Choi, M., Kim, M., Ha, J.-W., Kim, S., 和 Choo, J. (2018).
    Stargan: 用于多领域图像到图像转换的统一生成对抗网络。IEEE 计算机视觉与模式识别会议论文集，页码 8789–8797。'
- en: Chollet et al. (2015) Chollet, F. et al. (2015). Keras.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chollet 等 (2015) Chollet, F. 等 (2015). Keras。
- en: Dalca et al. (2018) Dalca, A. V., Balakrishnan, G., Guttag, J., and Sabuncu,
    M. R. (2018). Unsupervised learning for fast probabilistic diffeomorphic registration.
    arXiv preprint arXiv:1805.04605.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dalca 等 (2018) Dalca, A. V., Balakrishnan, G., Guttag, J., 和 Sabuncu, M. R.
    (2018). 用于快速概率性可微分配准的无监督学习。arXiv 预印本 arXiv:1805.04605。
- en: 'De Silva et al. (2016) De Silva, T., Uneri, A., Ketcha, M., Reaungamornrat,
    S., Kleinszig, G., Vogt, S., Aygun, N., Lo, S., Wolinsky, J., and Siewerdsen,
    J. (2016). 3d–2d image registration for target localization in spine surgery:
    investigation of similarity metrics providing robustness to content mismatch.
    Physics in Medicine & Biology, 61(8):3009.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: De Silva 等 (2016) De Silva, T., Uneri, A., Ketcha, M., Reaungamornrat, S., Kleinszig,
    G., Vogt, S., Aygun, N., Lo, S., Wolinsky, J., 和 Siewerdsen, J. (2016). 用于脊柱手术目标定位的
    3D–2D 图像配准：研究提供对内容不匹配具有鲁棒性的相似性度量。物理医学与生物学，61(8):3009。
- en: de Vos et al. (2018) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Sokooti,
    H., Staring, M., and Išgum, I. (2018). A deep learning framework for unsupervised
    affine and deformable image registration. Medical Image Analysis.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Vos 等 (2018) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Sokooti,
    H., Staring, M., 和 Išgum, I. (2018). 一个用于无监督仿射和变形图像配准的深度学习框架。医学图像分析。
- en: de Vos et al. (2017) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Staring,
    M., and Išgum, I. (2017). End-to-end unsupervised deformable image registration
    with a convolutional neural network. In Deep Learning in Medical Image Analysis
    and Multimodal Learning for Clinical Decision Support, pages 204–212\. Springer.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Vos 等 (2017) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Staring,
    M., 和 Išgum, I. (2017). 使用卷积神经网络的端到端无监督变形图像配准。在《医学图像分析中的深度学习与临床决策支持的多模态学习》一书中，页码
    204–212。Springer。
- en: Doersch (2016) Doersch, C. (2016). Tutorial on variational autoencoders. arXiv
    preprint arXiv:1606.05908.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Doersch (2016) Doersch, C. (2016). 变分自编码器教程。arXiv 预印本 arXiv:1606.05908。
- en: 'Dosovitskiy et al. (2015) Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P.,
    Hazirbas, C., Golkov, V., Van Der Smagt, P., Cremers, D., and Brox, T. (2015).
    Flownet: Learning optical flow with convolutional networks. In Proceedings of
    the IEEE International Conference on Computer Vision, pages 2758–2766.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dosovitskiy 等 (2015) Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P., Hazirbas,
    C., Golkov, V., Van Der Smagt, P., Cremers, D., 和 Brox, T. (2015). Flownet: 使用卷积网络学习光流。在
    IEEE 国际计算机视觉会议论文集，页码 2758–2766。'
- en: Ehrhardt et al. (2015) Ehrhardt, J., Schmidt-Richberg, A., Werner, R., and Handels,
    H. (2015). Variational registration. In Bildverarbeitung für die Medizin 2015,
    pages 209–214. Springer.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ehrhardt 等 (2015) Ehrhardt, J., Schmidt-Richberg, A., Werner, R., 和 Handels,
    H. (2015). 变分配准。在《2015 年医学图像处理》一书中，页码 209–214。Springer。
- en: Eppenhof and Pluim (2018a) Eppenhof, K. A. and Pluim, J. P. (2018a). Pulmonary
    ct registration through supervised learning with convolutional neural networks.
    IEEE transactions on medical imaging.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof 和 Pluim（2018a）Eppenhof, K. A. 和 Pluim, J. P.（2018a）。通过卷积神经网络进行的肺部 CT
    配准的监督学习。IEEE 医学影像学期刊。
- en: Eppenhof and Pluim (2018b) Eppenhof, K. A. J. and Pluim, J. P. (2018b). Error
    estimation of deformable image registration of pulmonary ct scans using convolutional
    neural networks. Journal of Medical Imaging, 5(2):024003.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Eppenhof 和 Pluim（2018b）Eppenhof, K. A. J. 和 Pluim, J. P.（2018b）。使用卷积神经网络对肺部
    CT 扫描进行变形图像配准的误差估计。《医学影像学期刊》，5(2):024003。
- en: Fan et al. (2018a) Fan, J., Cao, X., Xue, Z., Yap, P.-T., and Shen, D. (2018a).
    Adversarial similarity network for evaluating image alignment in deep learning
    based registration. In International Conference on Medical Image Computing and
    Computer-Assisted Intervention, pages 739–746\. Springer.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等（2018a）Fan, J., Cao, X., Xue, Z., Yap, P.-T., 和 Shen, D.（2018a）。用于评估深度学习基于配准的图像对齐的对抗性相似性网络。发表于国际医学图像计算与计算机辅助干预会议，页面
    739–746。Springer。
- en: 'Fan et al. (2018b) Fan, J., Cao, X., Yap, P.-T., and Shen, D. (2018b). Birnet:
    Brain image registration using dual-supervised fully convolutional networks. arXiv
    preprint arXiv:1802.04692.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Fan 等（2018b）Fan, J., Cao, X., Yap, P.-T., 和 Shen, D.（2018b）。Birnet：使用双监督全卷积网络的脑图像配准。arXiv
    预印本 arXiv:1802.04692。
- en: Ferrante et al. (2018) Ferrante, E., Oktay, O., Glocker, B., and Milone, D. H.
    (2018). On the adaptability of unsupervised cnn-based deformable image registration
    to unseen image domains. In International Workshop on Machine Learning in Medical
    Imaging, pages 294–302\. Springer.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ferrante 等（2018）Ferrante, E., Oktay, O., Glocker, B., 和 Milone, D. H.（2018）。关于无监督
    cnn 基于变形图像配准对未见图像领域的适应性。发表于国际医学影像机器学习研讨会，页面 294–302。Springer。
- en: 'Ghosal and Ray (2017) Ghosal, S. and Ray, N. (2017). Deep deformable registration:
    Enhancing accuracy by fully convolutional neural net. Pattern Recognition Letters,
    94:81–86.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ghosal 和 Ray（2017）Ghosal, S. 和 Ray, N.（2017）。深度变形配准：通过全卷积神经网络提高准确性。《模式识别通讯》，94:81–86。
- en: Goodfellow et al. (2016) Goodfellow, I., Bengio, Y., Courville, A., and Bengio,
    Y. (2016). Deep learning, volume 1. MIT press Cambridge.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等（2016）Goodfellow, I., Bengio, Y., Courville, A., 和 Bengio, Y.（2016）。《深度学习》，第
    1 卷。MIT Press Cambridge。
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative
    adversarial nets. In Advances in neural information processing systems, pages
    2672–2680.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Goodfellow 等（2014）Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B., Warde-Farley,
    D., Ozair, S., Courville, A., 和 Bengio, Y.（2014）。生成对抗网络。发表于神经信息处理系统进展，页面 2672–2680。
- en: Haskins et al. (2019) Haskins, G., Kruecker, J., Kruger, U., Xu, S., Pinto,
    P. A., Wood, B. J., and Yan, P. (2019). Learning deep similarity metric for 3d
    mr-trus image registration. International Journal of Computer Assisted Radiology
    and Surgery, 14:417–425.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Haskins 等（2019）Haskins, G., Kruecker, J., Kruger, U., Xu, S., Pinto, P. A.,
    Wood, B. J., 和 Yan, P.（2019）。学习深度相似性度量进行 3D MR-TRUS 图像配准。《计算机辅助放射学与外科国际期刊》，14:417–425。
- en: He et al. (2016) He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual
    learning for image recognition. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 770–778.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: He 等（2016）He, K., Zhang, X., Ren, S., 和 Sun, J.（2016）。用于图像识别的深度残差学习。发表于 IEEE
    计算机视觉与模式识别会议论文集，页面 770–778。
- en: 'Heinrich et al. (2012) Heinrich, M. P., Jenkinson, M., Bhushan, M., Matin,
    T., Gleeson, F. V., Brady, M., and Schnabel, J. A. (2012). Mind: Modality independent
    neighbourhood descriptor for multi-modal deformable registration. Medical image
    analysis, 16(7):1423–1435.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 等（2012）Heinrich, M. P., Jenkinson, M., Bhushan, M., Matin, T., Gleeson,
    F. V., Brady, M., 和 Schnabel, J. A.（2012）。MIND：用于多模态变形配准的模态独立邻域描述符。《医学图像分析》，16(7):1423–1435。
- en: Heinrich et al. (2013) Heinrich, M. P., Jenkinson, M., Papież, B. W., Brady,
    M., and Schnabel, J. A. (2013). Towards realtime multimodal fusion for image-guided
    interventions using self-similarities. In International conference on medical
    image computing and computer-assisted intervention, pages 187–194\. Springer.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Heinrich 等（2013）Heinrich, M. P., Jenkinson, M., Papież, B. W., Brady, M., 和
    Schnabel, J. A.（2013）。朝向实时多模态融合的图像引导干预，使用自相似性。发表于国际医学图像计算与计算机辅助干预会议，页面 187–194。Springer。
- en: Hering et al. (2018) Hering, A., Kuckertz, S., Heldmann, S., and Heinrich, M.
    (2018). Enhancing label-driven deep deformable image registration with local distance
    metrics for state-of-the-art cardiac motion tracking. arXiv preprint arXiv:1812.01859.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hering et al. (2018) Hering, A., Kuckertz, S., Heldmann, S., 和 Heinrich, M.
    (2018)。通过局部距离度量增强基于标签的深度变形图像配准，以实现最先进的心脏运动跟踪。arXiv 预印本 arXiv:1812.01859。
- en: Hill et al. (2001) Hill, D. L., Batchelor, P. G., Holden, M., and Hawkes, D. J.
    (2001). Medical image registration. Physics in medicine and biology, 46(3):R1–R45.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hill et al. (2001) Hill, D. L., Batchelor, P. G., Holden, M., 和 Hawkes, D. J.
    (2001)。医学图像配准。《医学与生物学物理学》，46(3):R1–R45。
- en: Hu et al. (2018a) Hu, Y., Gibson, E., Ghavami, N., Bonmati, E., Moore, C. M.,
    Emberton, M., Vercauteren, T., Noble, J. A., and Barratt, D. C. (2018a). Adversarial
    deformation regularization for training image registration neural networks. arXiv
    preprint arXiv:1805.10665.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2018a) Hu, Y., Gibson, E., Ghavami, N., Bonmati, E., Moore, C. M.,
    Emberton, M., Vercauteren, T., Noble, J. A., 和 Barratt, D. C. (2018a)。用于训练图像配准神经网络的对抗性变形正则化。arXiv
    预印本 arXiv:1805.10665。
- en: Hu et al. (2018b) Hu, Y., Modat, M., Gibson, E., Ghavami, N., Bonmati, E., Moore,
    C. M., Emberton, M., Noble, J. A., Barratt, D. C., and Vercauteren, T. (2018b).
    Label-driven weakly-supervised learning for multimodal deformarle image registration.
    In Biomedical Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on,
    pages 1070–1074\. IEEE.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2018b) Hu, Y., Modat, M., Gibson, E., Ghavami, N., Bonmati, E., Moore,
    C. M., Emberton, M., Noble, J. A., Barratt, D. C., 和 Vercauteren, T. (2018b)。基于标签的弱监督学习用于多模态变形图像配准。在《生物医学成像
    (ISBI 2018)》，2018 IEEE第15届国际研讨会，页码 1070–1074。IEEE。
- en: Hu et al. (2018c) Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati,
    E., Wang, G., Bandula, S., Moore, C. M., Emberton, M., et al. (2018c). Weakly-supervised
    convolutional neural networks for multimodal image registration. Medical image
    analysis, 49:1–13.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hu et al. (2018c) Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati,
    E., Wang, G., Bandula, S., Moore, C. M., Emberton, M., 等 (2018c)。用于多模态图像配准的弱监督卷积神经网络。《医学图像分析》，49:1–13。
- en: Ikeda et al. (2014) Ikeda, K., Ino, F., and Hagihara, K. (2014). Efficient acceleration
    of mutual information computation for nonrigid registration using cuda. IEEE J.
    Biomedical and Health Informatics, 18(3):956–968.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ikeda et al. (2014) Ikeda, K., Ino, F., 和 Hagihara, K. (2014)。使用 CUDA 高效加速非刚性配准的互信息计算。IEEE
    生物医学与健康信息学期刊，18(3):956–968。
- en: Isola et al. (2017) Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. (2017).
    Image-to-image translation with conditional adversarial networks. arXiv preprint.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Isola et al. (2017) Isola, P., Zhu, J.-Y., Zhou, T., 和 Efros, A. A. (2017)。使用条件对抗网络进行图像到图像翻译。arXiv
    预印本。
- en: 'Ito and Ino (2018) Ito, M. and Ino, F. (2018). An automated method for generating
    training sets for deep learning based image registration. In The 11th International
    Joint Conference on Biomedical Engineering Systems and Technologies - Volume 2:
    BIOIMAGING, pages 140–147. INSTICC, SciTePress.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ito and Ino (2018) Ito, M. 和 Ino, F. (2018)。一种自动生成深度学习图像配准训练集的方法。在第11届国际生物医学工程系统与技术联合会议
    - 第2卷：BIOIMAGING，页码 140–147。INSTICC, SciTePress。
- en: Jaderberg et al. (2015) Jaderberg, M., Simonyan, K., Zisserman, A., et al. (2015).
    Spatial transformer networks. In Advances in neural information processing systems,
    pages 2017–2025.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaderberg et al. (2015) Jaderberg, M., Simonyan, K., Zisserman, A., 等 (2015)。空间变换网络。在《神经信息处理系统进展》中，页码
    2017–2025。
- en: 'Jia et al. (2014) Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J.,
    Girshick, R., Guadarrama, S., and Darrell, T. (2014). Caffe: Convolutional architecture
    for fast feature embedding. In Proceedings of the 22nd ACM international conference
    on Multimedia, pages 675–678\. ACM.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jia et al. (2014) Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J.,
    Girshick, R., Guadarrama, S., 和 Darrell, T. (2014)。Caffe：用于快速特征嵌入的卷积架构。在第22届ACM国际多媒体会议论文集中，页码
    675–678。ACM。
- en: Jiang and Shackleford (2018) Jiang, P. and Shackleford, J. A. (2018). Cnn driven
    sparse multi-level b-spline image registration. In Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pages 9281–9289.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jiang and Shackleford (2018) Jiang, P. 和 Shackleford, J. A. (2018)。基于 CNN 的稀疏多级
    B-样条图像配准。在 IEEE 计算机视觉与模式识别会议论文集中，页码 9281–9289。
- en: 'Kaelbling et al. (1996) Kaelbling, L. P., Littman, M. L., and Moore, A. W.
    (1996). Reinforcement learning: A survey. Journal of artificial intelligence research,
    4:237–285.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kaelbling et al. (1996) Kaelbling, L. P., Littman, M. L., 和 Moore, A. W. (1996)。强化学习：综述。《人工智能研究杂志》，4:237–285。
- en: Kazeminia et al. (2018) Kazeminia, S., Baur, C., Kuijper, A., van Ginneken,
    B., Navab, N., Albarqouni, S., and Mukhopadhyay, A. (2018). Gans for medical image
    analysis. arXiv preprint arXiv:1809.06222.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kazeminia 等（2018）Kazeminia, S., Baur, C., Kuijper, A., van Ginneken, B., Navab,
    N., Albarqouni, S., 和 Mukhopadhyay, A.（2018）。用于医学图像分析的生成对抗网络。arXiv 预印本 arXiv:1809.06222。
- en: 'Klein et al. (2010) Klein, S., Staring, M., Murphy, K., Viergever, M. A., and
    Pluim, J. P. (2010). Elastix: a toolbox for intensity-based medical image registration.
    IEEE transactions on medical imaging, 29(1):196–205.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Klein 等（2010）Klein, S., Staring, M., Murphy, K., Viergever, M. A., 和 Pluim,
    J. P.（2010）。Elastix: 一种基于强度的医学图像配准工具箱。IEEE 医学成像学报，29(1):196–205。'
- en: Kori et al. (2018) Kori, A., Kumari, K., and Krishnamurthi, G. (2018). Zero
    shot learning for multi-modal real time image registration.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kori 等（2018）Kori, A., Kumari, K., 和 Krishnamurthi, G.（2018）。用于多模态实时图像配准的零样本学习。
- en: Krebs et al. (2017) Krebs, J., Mansi, T., Delingette, H., Zhang, L., Ghesu,
    F. C., Miao, S., Maier, A. K., Ayache, N., Liao, R., and Kamen, A. (2017). Robust
    non-rigid registration through agent-based action learning. In International Conference
    on Medical Image Computing and Computer-Assisted Intervention, pages 344–352\.
    Springer.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krebs 等（2017）Krebs, J., Mansi, T., Delingette, H., Zhang, L., Ghesu, F. C.,
    Miao, S., Maier, A. K., Ayache, N., Liao, R., 和 Kamen, A.（2017）。通过基于代理的行动学习实现鲁棒的非刚性配准。国际医学图像计算与计算机辅助干预会议，页344–352。Springer。
- en: Krebs et al. (2018a) Krebs, J., Mansi, T., Mailhé, B., Ayache, N., and Delingette,
    H. (2018a). Learning structured deformations using diffeomorphic registration.
    arXiv preprint arXiv:1804.07172.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krebs 等（2018a）Krebs, J., Mansi, T., Mailhé, B., Ayache, N., 和 Delingette, H.（2018a）。使用
    diffeomorphic 配准学习结构化变形。arXiv 预印本 arXiv:1804.07172。
- en: Krebs et al. (2018b) Krebs, J., Mansi, T., Mailhé, B., Ayache, N., and Delingette,
    H. (2018b). Unsupervised probabilistic deformation modeling for robust diffeomorphic
    registration. In Deep Learning in Medical Image Analysis and Multimodal Learning
    for Clinical Decision Support, pages 101–109\. Springer.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Krebs 等（2018b）Krebs, J., Mansi, T., Mailhé, B., Ayache, N., 和 Delingette, H.（2018b）。用于鲁棒的
    diffeomorphic 配准的无监督概率形变建模。在医学图像分析中的深度学习与临床决策支持的多模态学习，页101–109。Springer。
- en: Kuang and Schmah (2018) Kuang, D. and Schmah, T. (2018). Faim–a convnet method
    for unsupervised 3d medical image registration. arXiv preprint arXiv:1811.09243.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kuang 和 Schmah（2018）Kuang, D. 和 Schmah, T.（2018）。Faim–一种用于无监督三维医学图像配准的卷积网络方法。arXiv
    预印本 arXiv:1811.09243。
- en: 'Lee et al. (2017) Lee, J.-G., Jun, S., Cho, Y.-W., Lee, H., Kim, G. B., Seo,
    J. B., and Kim, N. (2017). Deep learning in medical imaging: general overview.
    Korean journal of radiology, 18(4):570–584.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等（2017）Lee, J.-G., Jun, S., Cho, Y.-W., Lee, H., Kim, G. B., Seo, J. B.,
    和 Kim, N.（2017）。医学成像中的深度学习：概述。韩国放射学杂志，18(4):570–584。
- en: Li and Fan (2017) Li, H. and Fan, Y. (2017). Non-rigid image registration using
    fully convolutional networks with deep self-supervision. arXiv preprint arXiv:1709.00799.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Fan（2017）Li, H. 和 Fan, Y.（2017）。使用深度自监督的全卷积网络进行非刚性图像配准。arXiv 预印本 arXiv:1709.00799。
- en: Li and Fan (2018) Li, H. and Fan, Y. (2018). Non-rigid image registration using
    self-supervised fully convolutional networks without training data. In Biomedical
    Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on, pages 1075–1078\.
    IEEE.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 和 Fan（2018）Li, H. 和 Fan, Y.（2018）。使用自监督全卷积网络在没有训练数据的情况下进行非刚性图像配准。在生物医学成像（ISBI
    2018），2018 IEEE 第15届国际研讨会，页1075–1078。IEEE。
- en: Liao et al. (2017) Liao, R., Miao, S., de Tournemire, P., Grbic, S., Kamen,
    A., Mansi, T., and Comaniciu, D. (2017). An artificial agent for robust image
    registration. In AAAI, pages 4168–4175.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liao 等（2017）Liao, R., Miao, S., de Tournemire, P., Grbic, S., Kamen, A., Mansi,
    T., 和 Comaniciu, D.（2017）。用于鲁棒图像配准的人工智能代理。在 AAAI，页4168–4175。
- en: Litjens et al. (2017) Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A.,
    Ciompi, F., Ghafoorian, M., van der Laak, J. A., Van Ginneken, B., and Sánchez,
    C. I. (2017). A survey on deep learning in medical image analysis. Medical image
    analysis, 42:60–88.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Litjens 等（2017）Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A., Ciompi,
    F., Ghafoorian, M., van der Laak, J. A., Van Ginneken, B., 和 Sánchez, C. I.（2017）。深度学习在医学图像分析中的调查。医学图像分析，42:60–88。
- en: 'Liu et al. (2011) Liu, C., Yuen, J., and Torralba, A. (2011). Sift flow: Dense
    correspondence across scenes and its applications. IEEE transactions on pattern
    analysis and machine intelligence, 33(5):978–994.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Liu 等（2011）刘超、袁君、Torralba，A.（2011）。Sift flow: 跨场景的密集对应及其应用。IEEE 计算机视觉与模式识别学报，33(5):978–994。'
- en: 'Liu et al. (2018) Liu, J., Pan, Y., Li, M., Chen, Z., Tang, L., Lu, C., and
    Wang, J. (2018). Applications of deep learning to mri images: a survey. Big Data
    Mining and Analytics, 1(1):1–18.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等人 (2018) 刘, J., 潘, Y., 李, M., 陈, Z., 唐, L., 吕, C., 和 王, J. (2018). 深度学习在MRI图像中的应用：一项综述。大数据挖掘与分析,
    1(1):1–18。
- en: Liu et al. (2017) Liu, M.-Y., Breuel, T., and Kautz, J. (2017). Unsupervised
    image-to-image translation networks. In Advances in Neural Information Processing
    Systems, pages 700–708.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘等人 (2017) 刘, M.-Y., 布雷尔, T., 和 考茨, J. (2017). 无监督图像到图像转换网络。在《神经信息处理系统进展》中,
    第700–708页。
- en: Liu and Leung (2017) Liu, Q. and Leung, H. (2017). Tensor-based descriptor for
    image registration via unsupervised network. In Information Fusion (Fusion), 2017
    20th International Conference on, pages 1–7\. IEEE.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 刘和梁 (2017) 刘, Q. 和 梁, H. (2017). 基于张量的图像配准描述符，通过无监督网络。在《信息融合（Fusion）》中, 2017年第20届国际会议,
    第1–7页。IEEE。
- en: Long et al. (2015) Long, J., Shelhamer, E., and Darrell, T. (2015). Fully convolutional
    networks for semantic segmentation. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 3431–3440.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 龙等人 (2015) 龙, J., 谢尔哈默, E., 和 达雷尔, T. (2015). 用于语义分割的全卷积网络。在《IEEE计算机视觉与模式识别会议论文集》中,
    第3431–3440页。
- en: 'Lorenzi et al. (2013) Lorenzi, M., Ayache, N., Frisoni, G. B., Pennec, X.,
    (ADNI, A. D. N. I., et al. (2013). Lcc-demons: a robust and accurate symmetric
    diffeomorphic registration algorithm. NeuroImage, 81:470–483.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 洛伦齐等人 (2013) 洛伦齐, M., 阿亚切, N., 弗里索尼, G. B., 佩内克, X., (ADNI, A. D. N. I., 等.
    (2013). LCC-demons：一种稳健而准确的对称流形配准算法。神经影像学, 81:470–483。
- en: 'Lv et al. (2018) Lv, J., Yang, M., Zhang, J., and Wang, X. (2018). Respiratory
    motion correction for free-breathing 3d abdominal mri using cnn-based image registration:
    a feasibility study. The British journal of radiology, 91(xxxx):20170788.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 吕等人 (2018) 吕, J., 杨, M., 张, J., 和 王, X. (2018). 使用基于CNN的图像配准进行自由呼吸3D腹部MRI的呼吸运动校正：可行性研究。英国放射学杂志,
    91(xxxx):20170788。
- en: Ma et al. (2017) Ma, K., Wang, J., Singh, V., Tamersoy, B., Chang, Y.-J., Wimmer,
    A., and Chen, T. (2017). Multimodal image registration with deep context reinforcement
    learning. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 240–248\. Springer.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马等人 (2017) 马, K., 王, J., 辛格, V., 塔梅索伊, B., 张, Y.-J., 温默, A., 和 陈, T. (2017).
    基于深度上下文强化学习的多模态图像配准。在《医学图像计算与计算机辅助干预国际会议》中, 第240–248页。Springer。
- en: Maes et al. (1997) Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., and
    Suetens, P. (1997). Multimodality image registration by maximization of mutual
    information. IEEE transactions on Medical Imaging, 16(2):187–198.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马斯等人 (1997) 马斯, F., 科隆尼翁, A., 范德梅伦, D., 马沙尔, G., 和 苏腾斯, P. (1997). 通过最大化互信息进行多模态图像配准。IEEE医学成像学报,
    16(2):187–198。
- en: Mahapatra (2018) Mahapatra, D. (2018). Elastic registration of medical images
    with gans. arXiv preprint arXiv:1805.02369.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马哈帕特拉 (2018) 马哈帕特拉, D. (2018). 基于生成对抗网络的医学图像弹性配准。arXiv预印本 arXiv:1805.02369。
- en: Mahapatra et al. (2018) Mahapatra, D., Ge, Z., Sedai, S., and Chakravorty, R.
    (2018). Joint registration and segmentation of xray images using generative adversarial
    networks. In International Workshop on Machine Learning in Medical Imaging, pages
    73–80\. Springer.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马哈帕特拉等人 (2018) 马哈帕特拉, D., 葛, Z., 塞达伊, S., 和 查克拉沃提, R. (2018). 使用生成对抗网络的X射线图像联合配准与分割。在《医学影像中的机器学习国际研讨会》中,
    第73–80页。Springer。
- en: Matthew et al. (2018) Matthew, J., Hajnal, J. V., Rueckert, D., and Schnabel,
    J. A. (2018). Lstm spatial co-transformer networks for registration of 3d fetal
    us and mr brain images. In Data Driven Treatment Response Assessment and Preterm,
    Perinatal, and Paediatric Image Analysis, pages 149–159\. Springer.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 马修等人 (2018) 马修, J., 哈金纳尔, J. V., 鲁克特, D., 和 施纳贝尔, J. A. (2018). 用于3D胎儿超声和MR脑图像配准的LSTM空间协同变换网络。在《数据驱动治疗反应评估与早产、围产期和儿科图像分析》中,
    第149–159页。Springer。
- en: Miao et al. (2017) Miao, S., Piat, S., Fischer, P., Tuysuzoglu, A., Mewes, P.,
    Mansi, T., and Liao, R. (2017). Dilated fcn for multi-agent 2d/3d medical image
    registration. arXiv preprint arXiv:1712.01651.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 苗等人 (2017) 苗, S., 皮亚特, S., 菲舍尔, P., 图伊苏佐格鲁, A., 迈维斯, P., 曼西, T., 和 廖, R. (2017).
    用于多代理2D/3D医学图像配准的扩张FCN。arXiv预印本 arXiv:1712.01651。
- en: Miao et al. (2016a) Miao, S., Wang, Z. J., and Liao, R. (2016a). A cnn regression
    approach for real-time 2d/3d registration. IEEE transactions on medical imaging,
    35(5):1352–1363.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 苗等人 (2016a) 苗, S., 王, Z. J., 和 廖, R. (2016a). 一种用于实时2D/3D配准的CNN回归方法。IEEE医学成像学报,
    35(5):1352–1363。
- en: Miao et al. (2016b) Miao, S., Wang, Z. J., Zheng, Y., and Liao, R. (2016b).
    Real-time 2d/3d registration via cnn regression. In Biomedical Imaging (ISBI),
    2016 IEEE 13th International Symposium on, pages 1430–1434\. IEEE.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Miao et al. (2016b) Miao, S., Wang, Z. J., Zheng, Y., 和 Liao, R. (2016b). 通过
    cnn 回归实现实时 2d/3d 配准。在生物医学成像 (ISBI) 2016 IEEE 第 13 届国际研讨会上，页 1430–1434。IEEE。
- en: Myronenko and Song (2010) Myronenko, A. and Song, X. (2010). Intensity-based
    image registration by minimizing residual complexity. IEEE transactions on medical
    imaging, 29(11):1882–1891.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myronenko and Song (2010) Myronenko, A. 和 Song, X. (2010). 通过最小化残差复杂度进行基于强度的图像配准。《IEEE
    医学成像汇刊》，29(11):1882–1891。
- en: 'Nazib et al. (2018) Nazib, A., Fookes, C., and Perrin, D. (2018). A comparative
    analysis of registration tools: Traditional vs deep learning approach on high
    resolution tissue cleared data. arXiv preprint arXiv:1810.08315.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nazib et al. (2018) Nazib, A., Fookes, C., 和 Perrin, D. (2018). 配准工具的比较分析：传统方法与深度学习方法在高分辨率组织清理数据上的对比。arXiv
    预印本 arXiv:1810.08315。
- en: Neylon et al. (2017) Neylon, J., Min, Y., Low, D. A., and Santhanam, A. (2017).
    A neural network approach for fast, automated quantification of dir performance.
    Medical physics, 44(8):4126–4138.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Neylon et al. (2017) Neylon, J., Min, Y., Low, D. A., 和 Santhanam, A. (2017).
    一种用于快速、自动化定量 dir 性能的神经网络方法。《医学物理》，44(8):4126–4138。
- en: Paszke et al. (2017) Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang,
    E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A. (2017). Automatic
    differentiation in pytorch. In NIPS-W.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Paszke et al. (2017) Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang,
    E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., 和 Lerer, A. (2017). PyTorch
    中的自动微分。在 NIPS-W 上。
- en: Punithakumar et al. (2017) Punithakumar, K., Boulanger, P., and Noga, M. (2017).
    A gpu-accelerated deformable image registration algorithm with applications to
    right ventricular segmentation. IEEE Access, 5:20374–20382.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Punithakumar et al. (2017) Punithakumar, K., Boulanger, P., 和 Noga, M. (2017).
    一种 GPU 加速的可变形图像配准算法及其在右心室分割中的应用。《IEEE Access》，5:20374–20382。
- en: 'Ren et al. (2015) Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster
    r-cnn: Towards real-time object detection with region proposal networks. In Advances
    in neural information processing systems, pages 91–99.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren et al. (2015) Ren, S., He, K., Girshick, R., 和 Sun, J. (2015). Faster R-CNN：实现实时目标检测的区域提议网络。在神经信息处理系统进展中，页
    91–99。
- en: 'Rivenson et al. (2018) Rivenson, Y., Zhang, Y., Günaydın, H., Teng, D., and
    Ozcan, A. (2018). Phase recovery and holographic image reconstruction using deep
    learning in neural networks. Light: Science & Applications, 7(2):17141.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rivenson et al. (2018) Rivenson, Y., Zhang, Y., Günaydın, H., Teng, D., 和 Ozcan,
    A. (2018). 利用深度学习进行相位恢复和全息图像重建。《光：科学与应用》，7(2):17141。
- en: 'Rohé et al. (2017) Rohé, M.-M., Datar, M., Heimann, T., Sermesant, M., and
    Pennec, X. (2017). Svf-net: Learning deformable image registration using shape
    matching. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 266–274\. Springer.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rohé et al. (2017) Rohé, M.-M., Datar, M., Heimann, T., Sermesant, M., 和 Pennec,
    X. (2017). Svf-net：利用形状匹配学习可变形图像配准。在国际医学图像计算与计算机辅助手术会议上，页 266–274。Springer。
- en: 'Ronneberger et al. (2015) Ronneberger, O., Fischer, P., and Brox, T. (2015).
    U-net: Convolutional networks for biomedical image segmentation. In International
    Conference on Medical image computing and computer-assisted intervention, pages
    234–241\. Springer.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ronneberger et al. (2015) Ronneberger, O., Fischer, P., 和 Brox, T. (2015). U-net：用于生物医学图像分割的卷积网络。在国际医学图像计算与计算机辅助手术会议上，页
    234–241。Springer。
- en: 'Rühaak et al. (2013) Rühaak, J., Heldmann, S., Kipshagen, T., and Fischer,
    B. (2013). Highly accurate fast lung ct registration. In Medical Imaging 2013:
    Image Processing, volume 8669, page 86690Y. International Society for Optics and
    Photonics.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rühaak et al. (2013) Rühaak, J., Heldmann, S., Kipshagen, T., 和 Fischer, B.
    (2013). 高精度快速肺部 CT 配准。在医学成像 2013：图像处理，卷 8669，页 86690Y。国际光学与光子学学会。
- en: Saalfeld et al. (2012) Saalfeld, S., Fetter, R., Cardona, A., and Tomancak,
    P. (2012). Elastic volume reconstruction from series of ultra-thin microscopy
    sections. Nature methods, 9(7):717.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Saalfeld et al. (2012) Saalfeld, S., Fetter, R., Cardona, A., 和 Tomancak, P.
    (2012). 从超薄显微镜切片系列中进行弹性体积重建。《自然方法》，9(7):717。
- en: Salehi et al. (2018) Salehi, S. S. M., Khan, S., Erdogmus, D., and Gholipour,
    A. (2018). Real-time deep registration with geodesic loss. arXiv preprint arXiv:1803.05982.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Salehi et al. (2018) Salehi, S. S. M., Khan, S., Erdogmus, D., 和 Gholipour,
    A. (2018). 基于测地损失的实时深度配准。arXiv 预印本 arXiv:1803.05982。
- en: 'Schmidhuber (2015) Schmidhuber, J. (2015). Deep learning in neural networks:
    An overview. Neural networks, 61:85–117.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schmidhuber (2015) Schmidhuber, J. (2015). 神经网络中的深度学习：概述。《神经网络》，61:85–117。
- en: Sedghi et al. (2018) Sedghi, A., Luo, J., Mehrtash, A., Pieper, S., Tempany,
    C. M., Kapur, T., Mousavi, P., and Wells III, W. M. (2018). Semi-supervised deep
    metrics for image registration. arXiv preprint arXiv:1804.01565.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sedghi 等（2018）Sedghi, A., Luo, J., Mehrtash, A., Pieper, S., Tempany, C. M.,
    Kapur, T., Mousavi, P., 和 Wells III, W. M.（2018）。用于图像配准的半监督深度度量。arXiv 预印本 arXiv:1804.01565。
- en: Sheikhjafari et al. (2018) Sheikhjafari, A., Noga, M., Punithakumar, K., and
    Ray, N. (2018). Unsupervised deformable image registration with fully connected
    generative neural network. In International conference on Medical Imaging with
    Deep Learning.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sheikhjafari 等（2018）Sheikhjafari, A., Noga, M., Punithakumar, K., 和 Ray, N.（2018）。使用完全连接生成神经网络的无监督可变形图像配准。载于国际医学影像深度学习会议。
- en: Shen (2007) Shen, D. (2007). Image registration by local histogram matching.
    Pattern Recognition, 40(4):1161–1172.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen（2007）Shen, D.（2007）。通过局部直方图匹配实现图像配准。模式识别，40(4):1161–1172。
- en: 'Shu et al. (2018) Shu, C., Chen, X., Xie, Q., and Han, H. (2018). An unsupervised
    network for fast microscopic image registration. In Medical Imaging 2018: Digital
    Pathology, volume 10581, page 105811D. International Society for Optics and Photonics.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shu 等（2018）Shu, C., Chen, X., Xie, Q., 和 Han, H.（2018）。一种用于快速显微图像配准的无监督网络。载于《医学成像2018：数字病理学》，第10581卷，第105811D页。国际光学与光子学学会。
- en: Simonovsky et al. (2016) Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab,
    N., and Komodakis, N. (2016). A deep metric for multimodal registration. In International
    Conference on Medical Image Computing and Computer-Assisted Intervention, pages
    10–18\. Springer.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Simonovsky 等（2016）Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab, N.,
    和 Komodakis, N.（2016）。一种用于多模态配准的深度度量。载于国际医学图像计算与计算机辅助干预会议，第10–18页。Springer。
- en: Sloan et al. (2018) Sloan, J. M., Goatman, K. A., and Siebert, J. P. (2018).
    Learning rigid image registration - utilizing convolutional neural networks for
    medical image registration. In 11th International Joint Conference on Biomedical
    Engineering Systems and Technologies, pages 89–99\. SCITEPRESS-Science and Technology
    Publications.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sloan 等（2018）Sloan, J. M., Goatman, K. A., 和 Siebert, J. P.（2018）。学习刚性图像配准——利用卷积神经网络进行医学图像配准。载于第11届国际生物医学工程系统与技术联合会议，第89–99页。SCITEPRESS-科学与技术出版物。
- en: Smith et al. (2019) Smith, J. T., Yao, R., Sinsuebphon, N., Rudkouskaya, A.,
    Un, N., Mazurkiewicz, J., Barroso, M., Yan, P., and Intes, X. (2019). Fast fit-free
    analysis of fluorescence lifetime imaging via deep learning. Proceedings of the
    National Academy of Sciences, 116(48):24019–24030.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Smith 等（2019）Smith, J. T., Yao, R., Sinsuebphon, N., Rudkouskaya, A., Un, N.,
    Mazurkiewicz, J., Barroso, M., Yan, P., 和 Intes, X.（2019）。通过深度学习进行快速无拟合荧光寿命成像分析。《国家科学院学报》，116(48):24019–24030。
- en: Sokooti et al. (2017) Sokooti, H., de Vos, B., Berendsen, F., Lelieveldt, B. P.,
    Išgum, I., and Staring, M. (2017). Nonrigid image registration using multi-scale
    3d convolutional neural networks. In International Conference on Medical Image
    Computing and Computer-Assisted Intervention, pages 232–239\. Springer.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sokooti 等（2017）Sokooti, H., de Vos, B., Berendsen, F., Lelieveldt, B. P., Išgum,
    I., 和 Staring, M.（2017）。使用多尺度 3D 卷积神经网络的非刚性图像配准。载于国际医学图像计算与计算机辅助干预会议，第232–239页。Springer。
- en: Stergios et al. (2018) Stergios, C., Mihir, S., Maria, V., Guillaume, C., Marie-Pierre,
    R., Stavroula, M., and Nikos, P. (2018). Linear and deformable image registration
    with 3d convolutional neural networks. In Image Analysis for Moving Organ, Breast,
    and Thoracic Images, pages 13–22\. Springer.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Stergios 等（2018）Stergios, C., Mihir, S., Maria, V., Guillaume, C., Marie-Pierre,
    R., Stavroula, M., 和 Nikos, P.（2018）。使用 3D 卷积神经网络的线性和可变形图像配准。载于《移动器官、乳腺和胸部图像分析》，第13–22页。Springer。
- en: Sun and Zhang (2018) Sun, L. and Zhang, S. (2018). Deformable mri-ultrasound
    registration using 3d convolutional neural network. In Simulation, Image Processing,
    and Ultrasound Systems for Assisted Diagnosis and Navigation, pages 152–158\.
    Springer.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 和 Zhang（2018）Sun, L. 和 Zhang, S.（2018）。使用 3D 卷积神经网络进行可变形 MRI-超声图像配准。载于《辅助诊断和导航的仿真、图像处理与超声系统》，第152–158页。Springer。
- en: Sun et al. (2018) Sun, Y., Moelker, A., Niessen, W. J., and van Walsum, T. (2018).
    Towards robust ct-ultrasound registration using deep learning methods. In Understanding
    and Interpreting Machine Learning in Medical Image Computing Applications, pages
    43–51\. Springer.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sun 等（2018）Sun, Y., Moelker, A., Niessen, W. J., 和 van Walsum, T.（2018）。通过深度学习方法实现稳健的
    CT-超声图像配准。载于《理解和解释医学图像计算应用中的机器学习》，第43–51页。Springer。
- en: Uzunova et al. (2017) Uzunova, H., Wilms, M., Handels, H., and Ehrhardt, J.
    (2017). Training cnns for image registration from few samples with model-based
    data augmentation. In International Conference on Medical Image Computing and
    Computer-Assisted Intervention, pages 223–231\. Springer.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Uzunova et al. (2017) Uzunova, H., Wilms, M., Handels, H., 和 Ehrhardt, J. (2017).
    通过基于模型的数据增强训练 CNN 进行图像配准。见《医学图像计算与计算机辅助干预国际会议》，第223–231页。Springer。
- en: 'Vercauteren et al. (2009) Vercauteren, T., Pennec, X., Perchant, A., and Ayache,
    N. (2009). Diffeomorphic demons: Efficient non-parametric image registration.
    NeuroImage, 45(1):S61–S72.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vercauteren et al. (2009) Vercauteren, T., Pennec, X., Perchant, A., 和 Ayache,
    N. (2009). 微分同胚恶魔：高效的非参数图像配准。NeuroImage，45(1):S61–S72。
- en: Vialard et al. (2012) Vialard, F.-X., Risser, L., Rueckert, D., and Cotter,
    C. J. (2012). Diffeomorphic 3d image registration via geodesic shooting using
    an efficient adjoint calculation. International Journal of Computer Vision, 97(2):229–241.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Vialard et al. (2012) Vialard, F.-X., Risser, L., Rueckert, D., 和 Cotter, C.
    J. (2012). 通过高效的伴随计算进行微分同胚 3D 图像配准。国际计算机视觉期刊，97(2):229–241。
- en: Viola and Wells III (1997) Viola, P. and Wells III, W. M. (1997). Alignment
    by maximization of mutual information. International journal of computer vision,
    24(2):137–154.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Viola 和 Wells III (1997) Viola, P. 和 Wells III, W. M. (1997). 通过最大化互信息对齐。国际计算机视觉期刊，24(2):137–154。
- en: Wang (2016) Wang, G. (2016). A perspective on deep imaging. arXiv preprint arXiv:1609.04375.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang (2016) Wang, G. (2016). 深度成像的视角。arXiv 预印本 arXiv:1609.04375。
- en: Wang et al. (2015) Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot,
    M., and De Freitas, N. (2015). Dueling network architectures for deep reinforcement
    learning. arXiv preprint arXiv:1511.06581.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2015) Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot,
    M., 和 De Freitas, N. (2015). 深度强化学习的对战网络架构。arXiv 预印本 arXiv:1511.06581。
- en: Wu et al. (2013) Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., and Shen, D.
    (2013). Unsupervised deep feature learning for deformable registration of mr brain
    images. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 649–656\. Springer.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2013) Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., 和 Shen, D. (2013).
    无监督深度特征学习用于 MR 脑图像的可变形配准。见《医学图像计算与计算机辅助干预国际会议》，第649–656页。Springer。
- en: Wu et al. (2016) Wu, G., Kim, M., Wang, Q., Munsell, B. C., and Shen, D. (2016).
    Scalable high-performance image registration framework by unsupervised deep feature
    representations learning. IEEE Transactions on Biomedical Engineering, 63(7):1505–1516.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2016) Wu, G., Kim, M., Wang, Q., Munsell, B. C., 和 Shen, D. (2016).
    通过无监督深度特征表示学习的可扩展高性能图像配准框架。IEEE 生物医学工程期刊，63(7):1505–1516。
- en: Yan et al. (2018) Yan, P., Xu, S., Rastinehad, A. R., and Wood, B. J. (2018).
    Adversarial image registration with application for mr and trus image fusion.
    arXiv preprint arXiv:1804.11024.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yan et al. (2018) Yan, P., Xu, S., Rastinehad, A. R., 和 Wood, B. J. (2018).
    对抗性图像配准及其在 MR 和 TRUS 图像融合中的应用。arXiv 预印本 arXiv:1804.11024。
- en: Yang et al. (2018) Yang, Q., Yan, P., Zhang, Y., Yu, H., Shi, Y., Mou, X., Kalra,
    M. K., Zhang, Y., Sun, L., and Wang, G. (2018). Low dose ct image denoising using
    a generative adversarial network with wasserstein distance and perceptual loss.
    IEEE transactions on medical imaging.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2018) Yang, Q., Yan, P., Zhang, Y., Yu, H., Shi, Y., Mou, X., Kalra,
    M. K., Zhang, Y., Sun, L., 和 Wang, G. (2018). 使用 Wasserstein 距离和感知损失的生成对抗网络进行低剂量
    CT 图像去噪。IEEE 医学影像期刊。
- en: Yang (2017) Yang, X. (2017). Uncertainty Quantification, Image Synthesis and
    Deformation Prediction for Image Registration. PhD thesis, The University of North
    Carolina at Chapel Hill.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang (2017) Yang, X. (2017). 图像配准中的不确定性量化、图像合成与形变预测。博士论文，北卡罗来纳大学教堂山分校。
- en: Yang et al. (2016) Yang, X., Kwitt, R., and Niethammer, M. (2016). Fast predictive
    image registration. In Deep Learning and Data Labeling for Medical Applications,
    pages 48–57\. Springer.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang et al. (2016) Yang, X., Kwitt, R., 和 Niethammer, M. (2016). 快速预测图像配准。见《医学应用中的深度学习与数据标注》，第48–57页。Springer。
- en: Yao et al. (2018) Yao, R., Ochoa, M., Intes, X., and Yan, P. (2018). Deep compressive
    macroscopic fluorescence lifetime imaging. In Biomedical Imaging (ISBI 2018),
    2018 IEEE 15th International Symposium on, pages 908–911\. IEEE.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao et al. (2018) Yao, R., Ochoa, M., Intes, X., 和 Yan, P. (2018). 深度压缩宏观荧光寿命成像。见《生物医学成像
    (ISBI 2018)》，2018 IEEE 第15届国际研讨会， 第908–911页。IEEE。
- en: 'Yi et al. (2017) Yi, Z., Zhang, H., Tan, P., and Gong, M. (2017). Dualgan:
    Unsupervised dual learning for image-to-image translation. arXiv preprint.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yi et al. (2017) Yi, Z., Zhang, H., Tan, P., 和 Gong, M. (2017). Dualgan：用于图像到图像翻译的无监督双重学习。arXiv
    预印本。
- en: 'Yoo et al. (2017) Yoo, I., Hildebrand, D. G., Tobin, W. F., Lee, W.-C. A.,
    and Jeong, W.-K. (2017). ssemnet: Serial-section electron microscopy image registration
    using a spatial transformer network with learned features. In Deep Learning in
    Medical Image Analysis and Multimodal Learning for Clinical Decision Support,
    pages 249–257\. Springer.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Yoo 等 (2017) Yoo, I., Hildebrand, D. G., Tobin, W. F., Lee, W.-C. A., 和 Jeong,
    W.-K. (2017). ssemnet: 使用带学习特征的空间变换网络进行序列切片电子显微镜图像配准。在《医学图像分析中的深度学习与临床决策支持的多模态学习》中，第249–257页。Springer。'
- en: Zhang (2018) Zhang, J. (2018). Inverse-consistent deep networks for unsupervised
    deformable image registration. arXiv preprint arXiv:1809.03443.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang (2018) Zhang, J. (2018). 逆一致深度网络用于无监督可变形图像配准。arXiv 预印本 arXiv:1809.03443。
- en: Zheng et al. (2018) Zheng, J., Miao, S., Wang, Z. J., and Liao, R. (2018). Pairwise
    domain adaptation module for cnn-based 2-d/3-d registration. Journal of Medical
    Imaging, 5(2):021204.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等 (2018) Zheng, J., Miao, S., Wang, Z. J., 和 Liao, R. (2018). 基于cnn的2-d/3-d配准的配对领域适应模块。医学影像学杂志，5(2)：021204。
- en: Zhu et al. (2018) Zhu, B., Liu, J. Z., Cauley, S. F., Rosen, B. R., and Rosen,
    M. S. (2018). Image reconstruction by domain-transform manifold learning. Nature,
    555(7697):487.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等 (2018) Zhu, B., Liu, J. Z., Cauley, S. F., Rosen, B. R., 和 Rosen, M. S.
    (2018). 通过领域变换流形学习进行图像重建。自然，555(7697)：487。
- en: Zhu et al. (2017) Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. (2017).
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    arXiv preprint.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等 (2017) Zhu, J.-Y., Park, T., Isola, P., 和 Efros, A. A. (2017). 使用循环一致对抗网络的无配对图像到图像转换。arXiv
    预印本。
- en: 'Zitova and Flusser (2003) Zitova, B. and Flusser, J. (2003). Image registration
    methods: a survey. Image and vision computing, 21(11):977–1000.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zitova 和 Flusser (2003) Zitova, B. 和 Flusser, J. (2003). 图像配准方法：综述。图像与视觉计算，21(11)：977–1000。
