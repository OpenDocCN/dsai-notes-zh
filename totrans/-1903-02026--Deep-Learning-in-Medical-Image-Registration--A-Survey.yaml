- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 'category: 未分类'
- en: 'date: 2024-09-06 20:06:28'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 20:06:28'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[1903.02026] Deep Learning in Medical Image Registration: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[1903.02026] 深度学习在医学图像配准中的应用：综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/1903.02026](https://ar5iv.labs.arxiv.org/html/1903.02026)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/1903.02026](https://ar5iv.labs.arxiv.org/html/1903.02026)
- en: '∎ ¹¹institutetext: G. Haskins, U. Kruger, P. Yan* ²²institutetext: Department
    of Biomedical Engineering, Rensselaer Polytechnic Institute, Troy, NY 12180, USA'
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: '∎ ¹¹institutetext: G. Haskins, U. Kruger, P. Yan* ²²institutetext: 生物医学工程系，伦斯勒理工学院，美国纽约州特洛伊市12180'
- en: Asterisk indicates corresponding author
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 星号表示通讯作者
- en: 'Tel.: +1-518-276-4476'
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: '电话: +1-518-276-4476'
- en: '²²email: yanp2@rpi.edu'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '²²邮箱: yanp2@rpi.edu'
- en: 'Deep Learning in Medical Image Registration: A Survey'
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在医学图像配准中的应用：综述
- en: 'Grant Haskins    Uwe Kruger    Pingkun Yan This work was partially supported
    by NIH/NIBIB under awards R21EB028001 and R01EB027898, and NIH/NCI under a Bench-to-Bedside
    award.This is a pre-print of an article published in Machine Vision and Applications.
    The final authenticated version is available online at: https://doi.org/10.1007/s00138-020-01060-x'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: Grant Haskins    Uwe Kruger    Pingkun Yan 本研究部分由NIH/NIBIB资助，奖项为R21EB028001和R01EB027898，以及NIH/NCI资助的Bench-to-Bedside奖。本工作为《机器视觉与应用》上发表的文章的预印本。最终认证版本可在线获取：https://doi.org/10.1007/s00138-020-01060-x
- en: Abstract
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: The establishment of image correspondence through robust image registration
    is critical to many clinical tasks such as image fusion, organ atlas creation,
    and tumor growth monitoring, and is a very challenging problem. Since the beginning
    of the recent deep learning renaissance, the medical imaging research community
    has developed deep learning based approaches and achieved the state-of-the-art
    in many applications, including image registration. The rapid adoption of deep
    learning for image registration applications over the past few years necessitates
    a comprehensive summary and outlook, which is the main scope of this survey. This
    requires placing a focus on the different research areas as well as highlighting
    challenges that practitioners face. This survey, therefore, outlines the evolution
    of deep learning based medical image registration in the context of both research
    challenges and relevant innovations in the past few years. Further, this survey
    highlights future research directions to show how this field may be possibly moved
    forward to the next level.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 通过鲁棒图像配准建立图像对应关系对许多临床任务至关重要，如图像融合、器官图谱创建和肿瘤生长监测，并且这是一个非常具有挑战性的问题。自最近深度学习复兴以来，医学影像研究界开发了基于深度学习的方法，并在许多应用中取得了最先进的成果，包括图像配准。近年来深度学习在图像配准应用中的快速采用需要一个全面的总结和展望，这也是本综述的主要范围。这要求关注不同的研究领域，并突出实践者面临的挑战。因此，本综述概述了在过去几年中基于深度学习的医学图像配准的演变，既包括研究挑战，也包括相关创新。此外，本综述还强调了未来的研究方向，以展示该领域可能如何推进到下一个阶段。
- en: 1 INTRODUCTION
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1 引言
- en: 'Image registration is the process of transforming different image datasets
    into one coordinate system with matched imaging contents, which has significant
    applications in medicine. Registration may be necessary when analyzing a pair
    of images that were acquired from different viewpoints, at different times, or
    using different sensors/modalities Hill et al. ([2001](#bib.bib41)); Zitova and
    Flusser ([2003](#bib.bib122)). Until recently, image registration was mostly performed
    manually by clinicians. However, many registration tasks can be quite challenging
    and the quality of manual alignments are highly dependent upon the expertise of
    the user, which can be clinically disadvantageous. To address the potential shortcomings
    of manual registration, automatic registration has been developed. Although other
    methods for automatic image registration have been extensively explored prior
    to (and during) the deep learning renaissance, deep learning has changed the landscape
    of image registration research Ambinder ([2005](#bib.bib4)). Ever since the success
    of AlexNet in the ImageNet challenge of 2012 Alom et al. ([2018](#bib.bib3)),
    deep learning has allowed for state-of-the-art performance in many computer vision
    tasks including, but not limited to: object detection Ren et al. ([2015](#bib.bib84)),
    feature extraction He et al. ([2016](#bib.bib37)), segmentation Ronneberger et al.
    ([2015](#bib.bib87)), image classification Alom et al. ([2018](#bib.bib3)), image
    denoising Yang et al. ([2018](#bib.bib112)), and image reconstruction Yao et al.
    ([2018](#bib.bib115)).'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 图像配准是将不同的图像数据集转换到一个坐标系统中，以匹配的影像内容，这在医学领域具有重要应用。当分析一对从不同视角、不同时间或使用不同传感器/模态获取的图像时，可能需要进行配准
    Hill et al. ([2001](#bib.bib41)); Zitova and Flusser ([2003](#bib.bib122))。直到最近，图像配准大多由临床医生手动完成。然而，许多配准任务可能相当具有挑战性，并且手动对齐的质量高度依赖于用户的专业知识，这可能对临床不利。为了应对手动配准的潜在不足，自动配准技术应运而生。尽管在深度学习复兴之前（及期间）已经广泛探索了其他自动图像配准方法，但深度学习改变了图像配准研究的格局
    Ambinder ([2005](#bib.bib4))。自从2012年AlexNet在ImageNet挑战赛中取得成功以来 Alom et al. ([2018](#bib.bib3))，深度学习使许多计算机视觉任务实现了最先进的性能，包括但不限于：目标检测
    Ren et al. ([2015](#bib.bib84))，特征提取 He et al. ([2016](#bib.bib37))，分割 Ronneberger
    et al. ([2015](#bib.bib87))，图像分类 Alom et al. ([2018](#bib.bib3))，图像去噪 Yang et
    al. ([2018](#bib.bib112))，以及图像重建 Yao et al. ([2018](#bib.bib115))。
- en: Initially, deep learning was successfully used to augment the performance of
    iterative, intensity based registration Cheng et al. ([2018](#bib.bib18)); Haskins
    et al. ([2019](#bib.bib36)); Simonovsky et al. ([2016](#bib.bib96)). Soon after
    this initial application, several groups investigated the intuitive application
    of reinforcement learning to registration Liao et al. ([2017](#bib.bib62)); Ma
    et al. ([2017](#bib.bib71)); Miao et al. ([2017](#bib.bib76)). Further, demand
    for faster registration methods later motivated the development of deep learning
    based one-step transformation estimation techniques and challenges associated
    with procuring/generating ground truth data have recently motivated many groups
    to develop unsupervised frameworks for one-step transformation estimation de Vos
    et al. ([2018](#bib.bib23)); Li and Fan ([2018](#bib.bib61)). One of the hurdles
    associated with this framework is the familiar challenge of image similarity quantification
    Heinrich et al. ([2012](#bib.bib38)); Viola and Wells III ([1997](#bib.bib106)).
    Recent efforts that use information theory based similarity metrics de Vos et al.
    ([2018](#bib.bib23)), segmentations of anatomical structures Hu et al. ([2018c](#bib.bib44)),
    and generative adversarial network like frameworks Fan et al. ([2018a](#bib.bib30))
    to address this challenge have shown promising results.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 起初，深度学习成功地用于提升基于强度的迭代配准性能 Cheng et al. ([2018](#bib.bib18)); Haskins et al.
    ([2019](#bib.bib36)); Simonovsky et al. ([2016](#bib.bib96))。在这种初步应用之后不久，几个研究小组调查了将强化学习直观应用于配准的可能性
    Liao et al. ([2017](#bib.bib62)); Ma et al. ([2017](#bib.bib71)); Miao et al.
    ([2017](#bib.bib76))。此外，对更快配准方法的需求后来促使了基于深度学习的一步变换估计技术的发展，并且最近获取/生成真实数据的挑战促使许多小组开发了无监督的一步变换估计框架
    de Vos et al. ([2018](#bib.bib23)); Li and Fan ([2018](#bib.bib61))。与这一框架相关的一个难题是图像相似性量化的挑战
    Heinrich et al. ([2012](#bib.bib38)); Viola and Wells III ([1997](#bib.bib106))。最近利用基于信息论的相似性度量
    de Vos et al. ([2018](#bib.bib23))、解剖结构分割 Hu et al. ([2018c](#bib.bib44)) 和类似生成对抗网络的框架
    Fan et al. ([2018a](#bib.bib30)) 来应对这一挑战的努力已经显示出令人鼓舞的结果。
- en: 'Figure [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image
    Registration: A Survey") shows the various categorizations of different deep learning
    based registration methods. On the other hand, Figure [2](#S1.F2 "Figure 2 ‣ 1
    INTRODUCTION ‣ Deep Learning in Medical Image Registration: A Survey") shows the
    observed growing interest in deep learning based registration methods according
    to the number of published papers in recent years. As the trends visualized in
    Figures [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image
    Registration: A Survey") and [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning
    in Medical Image Registration: A Survey") suggest, this field is moving very quickly
    to surmount the hurdles associated with deep learning based medical image registration
    and several groups have already enjoyed significant successes for their applications
    Hu et al. ([2018c](#bib.bib44)); Liu et al. ([2018](#bib.bib65)); Simonovsky et al.
    ([2016](#bib.bib96)).'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: '图 [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration:
    A Survey") 展示了不同深度学习基础配准方法的各种分类。另一方面，图 [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣
    Deep Learning in Medical Image Registration: A Survey") 展示了根据近年来发表的论文数量对深度学习基础配准方法的日益增长的兴趣。如图
    [1](#S1.F1 "Figure 1 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration:
    A Survey") 和 [2](#S1.F2 "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical
    Image Registration: A Survey") 所示的趋势表明，该领域正在快速发展，以克服与深度学习基础的医学图像配准相关的障碍，并且已有多个研究小组在其应用中取得了显著成功，如
    Hu 等人（[2018c](#bib.bib44)）；Liu 等人（[2018](#bib.bib65)）；Simonovsky 等人（[2016](#bib.bib96)）。'
- en: '![Refer to caption](img/3d1baf673cb5d7443a073fe632ddc851.png)'
  id: totrans-18
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/3d1baf673cb5d7443a073fe632ddc851.png)'
- en: 'Figure 1: An overview of deep learning based medical image registration broken
    down by approach type. The popular research directions are written in bold.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：深度学习基础的医学图像配准方法概述，按方法类型分类。流行的研究方向用**粗体**标出。
- en: 'Therefore, the purpose of this article is to comprehensively survey the field
    of deep learning based medical image registration, highlight common challenges
    that practitioners face, and discuss future research directions that may address
    these challenges. Deep learning belongs to a class of machine learning that uses
    neural networks with a large number of layers to learn representations of data
    Goodfellow et al. ([2016](#bib.bib34)); Schmidhuber ([2015](#bib.bib91)). When
    discussing neural networks it is important to provide insight into the different
    types of neural networks that can be used for various applications, the notable
    architectures that were recently invented to tackle engineering problems, and
    the variety of strategies that are used for training neural networks. Therefore,
    this deep learning introduction section is divided into three sections: Neural
    Network Types, Network Architectures, and Training Paradigms and Strategies. Note
    that there are many publicly available libraries that can be used to build the
    networks described in the section, for example TensorFlow Abadi et al. ([2016](#bib.bib1)),
    MXNet Chen et al. ([2015](#bib.bib16)), Keras Chollet et al. ([2015](#bib.bib20)),
    Caffe Jia et al. ([2014](#bib.bib49)), and PyTorch Paszke et al. ([2017](#bib.bib82)).
    Detailed discussion of deep learning based medical image analysis and various
    deep learning research directions is outside of the scope of this article. Comprehensive
    review articles that survey the application of deep learning to medical image
    analysis Lee et al. ([2017](#bib.bib59)); Litjens et al. ([2017](#bib.bib63)),
    reinforcement learning Kaelbling et al. ([1996](#bib.bib51)), and the application
    of GANs to medical image analysis Kazeminia et al. ([2018](#bib.bib52)) are recommended
    to the interested readers. In this article, the surveyed methods were divided
    into the following three categories: Deep Iterative Registration, Supervised Transformation
    Estimation, and Unsupervised Transformation Estimation. Following a discussion
    of the methods that belong to each of the aforementioned categories, future research
    directions and current trends are discussed in Section [5](#S5 "5 Research Trends
    and Future Directions ‣ Deep Learning in Medical Image Registration: A Survey").'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '因此，本文的目的是全面调查基于深度学习的医学图像配准领域，突出从业者面临的常见挑战，并讨论可能解决这些挑战的未来研究方向。深度学习属于一种机器学习方法，它使用具有大量层次的神经网络来学习数据的表示
    Goodfellow et al. ([2016](#bib.bib34)); Schmidhuber ([2015](#bib.bib91))。在讨论神经网络时，提供不同类型神经网络的应用洞察、最近为解决工程问题而发明的显著架构以及用于训练神经网络的多种策略是很重要的。因此，本深度学习介绍部分分为三部分：神经网络类型、网络架构和训练范式及策略。请注意，有许多公开可用的库可以用来构建本节中描述的网络，例如
    TensorFlow Abadi et al. ([2016](#bib.bib1))、MXNet Chen et al. ([2015](#bib.bib16))、Keras
    Chollet et al. ([2015](#bib.bib20))、Caffe Jia et al. ([2014](#bib.bib49)) 和 PyTorch
    Paszke et al. ([2017](#bib.bib82))。对基于深度学习的医学图像分析和各种深度学习研究方向的详细讨论超出了本文的范围。对深度学习在医学图像分析中的应用进行综述的文章
    Lee et al. ([2017](#bib.bib59))；Litjens et al. ([2017](#bib.bib63))、强化学习 Kaelbling
    et al. ([1996](#bib.bib51)) 和 GANs 在医学图像分析中的应用 Kazeminia et al. ([2018](#bib.bib52))
    适合感兴趣的读者阅读。本文中调查的方法分为以下三类：深度迭代配准、监督变换估计和无监督变换估计。在讨论每个上述类别的方法后，未来的研究方向和当前趋势将在第[5](#S5
    "5 Research Trends and Future Directions ‣ Deep Learning in Medical Image Registration:
    A Survey")节中讨论。'
- en: '![Refer to caption](img/d96f7823b3483e2ae933548ac012638f.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/d96f7823b3483e2ae933548ac012638f.png)'
- en: 'Figure 2: An overview of the number of deep learning based image registration
    works and deep learning based medical imaging works. The red line represents the
    trend line for medical imaging based approaches and the blue line represents the
    trend line for deep learning based medical image registration approaches. The
    dotted line represents extrapolation.'
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：基于深度学习的图像配准工作和基于深度学习的医学成像工作的数量概览。红线表示医学成像方法的趋势线，蓝线表示基于深度学习的医学图像配准方法的趋势线。虚线表示外推。
- en: 2 Deep Iterative Registration
  id: totrans-23
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2 深度迭代配准
- en: 'Table 1: Deep Iterative Registration Methods Overview. RL denotes reinforcment
    learning.'
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 表格 1：深度迭代配准方法概览。RL 表示强化学习。
- en: Ref Learning Transform Modality ROI Model Eppenhof and Pluim ([2018b](#bib.bib29))
    Metric Deformable CT Thorax 9-layer CNN Blendowski and Heinrich ([2018](#bib.bib10))
    Metric Deformable CT Lung FCN Simonovsky et al. ([2016](#bib.bib96)) Metric Deformable
    MR Brain 5-layer CNN Wu et al. ([2013](#bib.bib109)) Metric Deformable MR Brain
    2-layer CAE Cheng et al. ([2018](#bib.bib18)) Metric Deformable CT/MR Head 5-layer
    DNN Sedghi et al. ([2018](#bib.bib92)) Metric Rigid MR/US Abdominal 5-layer CNN
    Haskins et al. ([2019](#bib.bib36)) Metric Rigid MR/US Prostate 14-layer CNN Matthew
    et al. ([2018](#bib.bib75)) Metric Rigid MR/US Fetal Brain LSTM/STN Krebs et al.
    ([2017](#bib.bib55)) RL Agent Deformable MR Prostate 8-layer CNN Liao et al. ([2017](#bib.bib62))
    RL Agent Rigid CT/CBCT Spine/ 8-layer CNN Cardiac Miao et al. ([2017](#bib.bib76))
    Multiple Rigid X-ray/CT Spine Dilated FCN RL Agents Ma et al. ([2017](#bib.bib71))
    RL Agent Rigid MR/CT Spine Dueling Network
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: 参考 学习 变换 模态 ROI 模型 Eppenhof和Pluim ([2018b](#bib.bib29)) 度量 标准 可变CT 胸部 9层CNN
    Blendowski和Heinrich ([2018](#bib.bib10)) 度量 标准 可变CT 肺 FCN Simonovsky et al. ([2016](#bib.bib96))
    度量 标准 可变MR 大脑 5层CNN Wu et al. ([2013](#bib.bib109)) 度量 标准 可变MR 大脑 2层CAE Cheng
    et al. ([2018](#bib.bib18)) 度量 标准 可变CT/MR 头部 5层DNN Sedghi et al. ([2018](#bib.bib92))
    度量 标准 刚性MR/US 腹部 5层CNN Haskins et al. ([2019](#bib.bib36)) 度量 标准 刚性MR/US 前列腺 14层CNN
    Matthew et al. ([2018](#bib.bib75)) 度量 标准 刚性MR/US 胎儿大脑 LSTM/STN Krebs et al. ([2017](#bib.bib55))
    RL 代理 可变MR 前列腺 8层CNN Liao et al. ([2017](#bib.bib62)) RL 代理 刚性CT/CBCT 脊柱/ 8层CNN
    心脏 Miao et al. ([2017](#bib.bib76)) 多重 刚性X射线/CT 脊柱 扩张FCN RL代理 Ma et al. ([2017](#bib.bib71))
    RL 代理 刚性MR/CT 脊柱 对抗网络
- en: 'Automatic intensity-based image registration requires both a metric that quantifies
    the similarity between a moving image and a fixed image and an optimization algorithm
    that updates the transformation parameters such that the similarity between the
    images is maximized. Prior to the deep learning renaissance, several manually
    crafted metrics were frequently used for such registration applications, including:
    sum of squared differences (SSD), cross-correlation (CC), mutual information (MI)
    Maes et al. ([1997](#bib.bib72)); Viola and Wells III ([1997](#bib.bib106)), normalized
    cross correlation (NCC), and normalized mutual information (NMI). Early applications
    of deep learning to medical image registration are direct extensions of the intensity-based
    registration framework Simonovsky et al. ([2016](#bib.bib96)); Wu et al. ([2013](#bib.bib109),
    [2016](#bib.bib110)). Several groups later used a reinforcement learning paradigm
    to iteratively estimate a transformation Krebs et al. ([2017](#bib.bib55)); Liao
    et al. ([2017](#bib.bib62)); Ma et al. ([2017](#bib.bib71)); Miao et al. ([2017](#bib.bib76))
    because this application is more consistent with how practitioners perform registration.'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 自动基于强度的图像配准需要一个能够量化移动图像和固定图像之间相似度的度量标准，以及一个优化算法来更新变换参数，以使图像之间的相似度最大化。在深度学习复兴之前，几种手工制作的度量标准经常用于这种配准应用，包括：平方差和（SSD）、交叉相关（CC）、互信息（MI）Maes
    et al. ([1997](#bib.bib72))；Viola和Wells III ([1997](#bib.bib106))，归一化交叉相关（NCC）和归一化互信息（NMI）。早期应用深度学习于医学图像配准直接扩展了基于强度的配准框架Simonovsky
    et al. ([2016](#bib.bib96))；Wu et al. ([2013](#bib.bib109)，[2016](#bib.bib110))。随后，一些小组使用了强化学习范式来迭代估计变换Krebs
    et al. ([2017](#bib.bib55))；Liao et al. ([2017](#bib.bib62))；Ma et al. ([2017](#bib.bib71))；Miao
    et al. ([2017](#bib.bib76))，因为这种应用与实践者执行配准的方式更加一致。
- en: 'A description of both types of methods is given in Table [1](#S2.T1 "Table
    1 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey"). We will survey earlier methods that used deep similarity based registration
    in Section [2.1](#S2.SS1 "2.1 Deep Similarity based Registration ‣ 2 Deep Iterative
    Registration ‣ Deep Learning in Medical Image Registration: A Survey") and then
    some more recently developed methods that use deep reinforcement learning based
    registration in Section [2.2](#S2.SS2 "2.2 Reinforcement Learning based Registration
    ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: '表[1](#S2.T1 "Table 1 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey")给出了这两种方法的描述。我们将在第[2.1节](#S2.SS1 "2.1 Deep Similarity
    based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey")回顾早期使用深度相似性基配准的方法，然后在第[2.2节](#S2.SS2 "2.2 Reinforcement
    Learning based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in
    Medical Image Registration: A Survey")介绍一些更近期开发的方法，这些方法使用深度强化学习基配准。'
- en: 'Figure 3: A visualization of the registration pipeline for works that use deep
    learning to quantify image similarity in an intensity-based registration framework.'
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 图3：展示了在基于强度的配准框架中，使用深度学习量化图像相似度的配准流程的可视化。
- en: 2.1 Deep Similarity based Registration
  id: totrans-29
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1 深度相似性基础配准
- en: 'In this section, methods that use deep learning to learn a similarity metric
    are surveyed. This similarity metric is inserted into a classical intensity-based
    registration framework with a defined interpolation strategy, transformation model,
    and optimization algorithm. A visualization of this overall framework is given
    in Fig. [3](#S2.F3 "Figure 3 ‣ 2 Deep Iterative Registration ‣ Deep Learning in
    Medical Image Registration: A Survey"). The solid lines represent data flows that
    are required during training and testing, while the dashed lines represent data
    flows that are required only during training. Note that this is the case for the
    remainder of the figures in this article as well.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: '本节对使用深度学习学习相似性度量的方法进行了综述。该相似性度量被插入到具有定义的插值策略、变换模型和优化算法的经典强度基础配准框架中。该整体框架的可视化见图[3](#S2.F3
    "Figure 3 ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey")。实线表示在训练和测试过程中所需的数据流，而虚线表示仅在训练过程中所需的数据流。请注意，本文其余图表的情况也是如此。'
- en: 2.1.1 Overview of Works
  id: totrans-31
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1 工作概述
- en: Although manually crafted similarity metrics perform reasonably well in the
    unimodal registration case, deep learning has been used to learn superior metrics.
    This section will first discuss approaches that use deep learning to augment the
    performance of unimodal intensity based registration pipelines before multimodal
    registration.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管手工制作的相似性度量在单模态配准情况下表现相当不错，但深度学习已被用来学习更优的度量。 本节将首先讨论利用深度学习来增强单模态强度基础配准流程性能的方法，然后再讨论多模态配准。
- en: 2.1.1.1 Unimodal Registration
  id: totrans-33
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.1.1.1 单模态配准
- en: Wu et al. Wu et al. ([2013](#bib.bib109), [2016](#bib.bib110)) were the first
    to use deep learning to obtain an application specific similarity metric for registration.
    They extracted the features that are used for unimodal, deformable registration
    of 3D brain MR volumes using a convolutional stacked autoencoder (CAE). They subsequently
    performed the registration using gradient descent to optimize the NCC of the two
    sets of features. This method outperformed diffeomorphic demons Vercauteren et al.
    ([2009](#bib.bib104)) and HAMMER Shen ([2007](#bib.bib94)) based registration
    techniques.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: Wu等人（Wu 等人，[2013](#bib.bib109)，[2016](#bib.bib110)）是第一个利用深度学习获得特定应用相似性度量进行配准的研究者。他们使用卷积堆叠自编码器（CAE）提取了用于单模态、可变形3D脑MR体积配准的特征。随后，他们使用梯度下降法优化两组特征的NCC进行配准。这种方法优于基于
    diffeomorphic demons 的 Vercauteren 等人（[2009](#bib.bib104)）和 HAMMER 的 Shen（[2007](#bib.bib94)）的配准技术。
- en: Recently, Eppenhof et al. Eppenhof and Pluim ([2018b](#bib.bib29)) estimated
    registration error for the deformable registration of 3D thoracic CT scans (inhale-exhale)
    in an end-to-end capacity. They used a 3D CNN to estimate the error map for inputted
    inhale-exhale pairs of thoracic CT scans. Like the above method, only learned
    features were used in this work.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Eppenhof等人（Eppenhof 和 Pluim，[2018b](#bib.bib29)）估计了3D胸部CT扫描（吸气-呼气）的可变形配准误差，采用了端到端的方式。他们使用3D
    CNN来估计输入的吸气-呼气对胸部CT扫描的误差图。与上述方法类似，本工作中只使用了学习到的特征。
- en: Instead, Blendowski et al. Blendowski and Heinrich ([2018](#bib.bib10)) proposed
    the combined use of both CNN-based descriptors and manually crafted MRF-based
    self-similarity descriptors for lung CT registration. Although the manually crafted
    descriptors outperformed the CNN-based descriptors, optimal performance was achieved
    using both sets of descriptors. This indicates that, in the unimodal registration
    case, deep learning may not outperform manually crafted methods. However, it can
    be used to obtain complementary information.
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 相反，Blendowski等人（Blendowski 和 Heinrich，[2018](#bib.bib10)）提出了结合使用基于CNN的描述符和手工制作的基于MRF的自相似度描述符进行肺CT配准。尽管手工制作的描述符优于基于CNN的描述符，但使用这两组描述符可以实现最佳性能。这表明，在单模态配准情况下，深度学习可能不如手工制作的方法。然而，它可以用来获得互补信息。
- en: 2.1.1.2 Multimodal Registration
  id: totrans-37
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 2.1.1.2 多模态配准
- en: The advantages of the application of deep learning to intensity based registration
    are more obvious in the multimodal case, where manually crafted similarity metrics
    have had very little success.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 在多模态情况下，应用深度学习来进行强度基础配准的优势更加明显，因为手工制作的相似性度量在这方面成功的机会很少。
- en: Cheng et al. Cheng et al. ([2016](#bib.bib17), [2018](#bib.bib18)) recently
    used a stacked denoising autoencoder to learn a similarity metric that assesses
    the quality of the rigid alignment of CT and MR images. They showed that their
    metric outperformed NMI-optimization-based and local cross correlation (LCC)-optimization-based
    for their application.
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: Cheng 等人 ([2016](#bib.bib17), [2018](#bib.bib18)) 最近使用了堆叠去噪自编码器来学习一种相似性度量，用于评估
    CT 和 MR 图像刚性对齐的质量。他们展示了他们的度量在他们的应用中优于基于 NMI 优化和局部交叉相关 (LCC) 优化的方法。
- en: In an effort to explicitly estimate image similarity in the multimodal case,
    Simonovsky et al. Simonovsky et al. ([2016](#bib.bib96)) used a CNN to learn the
    dissimilarity between aligned 3D T1 and T2 weighted brain MR volumes. Given this
    similarity metric, gradient descent was used in order to iteratively update the
    parameters that define a deformation field. This method was able to outperform
    MI-optimization-based registration and set the stage for deep intensity based
    multimodal registration.
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 为了明确估计多模态情况下的图像相似性，Simonovsky 等人 ([2016](#bib.bib96)) 使用了 CNN 来学习对齐的 3D T1 和
    T2 加权脑 MR 卷积之间的差异性。给定这一相似性度量，使用了梯度下降法来迭代更新定义变形场的参数。这种方法能够优于 MI 优化基础的配准，并为深度强度基础的多模态配准奠定了基础。
- en: 'Additionally, Sedghi et al. Sedghi et al. ([2018](#bib.bib92)) performed the
    rigid registration of 3D US/MR (modalities with an even greater appearance difference
    than MR/CT) abdominal scans by using a 5-layer neural network to learn a similarity
    metric that is then optimized by Powell’s method. This approach also outperformed
    MI-optimization-based registration. Haskins et al. Haskins et al. ([2019](#bib.bib36))
    learned a similarity metric for multimodal rigid registration of MR and transrectal
    US (TRUS) volumes by using a CNN to predict target registration error (TRE). Instead
    of using a traditional optimizer like the above methods, they used an evolutionary
    algorithm to explore the solution space prior to using a traditional optimization
    algorithm because of the learned metric’s lack of convexity. This registration
    framework outperformed MIND-optimization-based Heinrich et al. ([2012](#bib.bib38))
    and MI-optimization-based registration. In stark contrast to the above methods,
    Wright et al. Matthew et al. ([2018](#bib.bib75)) used LSTM spatial co-transformer
    networks to iteratively register MR and US volumes group-wise. The recurrent spatial
    co-transformation occurred in three steps: image warping, residual parameter prediction,
    parameter composition. They demonstrated that their method is more capable of
    quantifying image similarity than a previous multimodal image similarity quantification
    method that uses self-similarity context descriptors Heinrich et al. ([2013](#bib.bib39)).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，Sedghi 等人 ([2018](#bib.bib92)) 使用 5 层神经网络来学习相似性度量，从而对 3D US/MR（具有比 MR/CT
    更大外观差异的模态）腹部扫描进行刚性配准，该度量随后由 Powell 方法优化。这种方法也优于 MI 优化基础的配准。Haskins 等人 ([2019](#bib.bib36))
    使用 CNN 来预测目标配准误差 (TRE)，从而学习用于多模态刚性配准的相似性度量，而不是使用像上述方法那样的传统优化器，他们使用了进化算法来探索解决方案空间，然后再使用传统优化算法，因为所学习的度量缺乏凸性。这种配准框架优于基于
    MIND 优化的 Heinrich 等人 ([2012](#bib.bib38)) 和基于 MI 优化的配准。与上述方法形成鲜明对比的是，Wright 等人
    ([2018](#bib.bib75)) 使用 LSTM 空间共变换网络来迭代地对 MR 和 US 卷进行组配准。递归空间共变换分为三个步骤：图像变形、残差参数预测、参数组合。他们证明了他们的方法在量化图像相似性方面比之前使用自相似上下文描述符的多模态图像相似性量化方法更具能力
    Heinrich 等人 ([2013](#bib.bib39))。
- en: 2.1.2 Discussion and Assessment
  id: totrans-42
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.2 讨论与评估
- en: Recent works have confirmed the ability of neural networks to assess image similarity
    in multimodal medical image registration. The results achieved by the approaches
    described in this section demonstrate that deep learning can be successfully applied
    to challenging registration tasks. However, the findings from Blendowski and Heinrich
    ([2018](#bib.bib10)) suggest that learned image similarity metrics may be best
    suited to complement existing similarity metrics in the unimodal case. Further,
    it is difficult to use these iterative techniques for real time registration.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 最近的研究确认了神经网络在多模态医学图像配准中评估图像相似性的能力。本节中描述的方法所取得的结果表明，深度学习可以成功应用于具有挑战性的配准任务。然而，Blendowski
    和 Heinrich ([2018](#bib.bib10)) 的研究结果表明，学习得到的图像相似性度量可能最适合于补充现有的单模态相似性度量。此外，使用这些迭代技术进行实时配准是困难的。
- en: 2.2 Reinforcement Learning based Registration
  id: totrans-44
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2 基于强化学习的注册
- en: 'In this section, methods that use reinforcement learning for their registration
    applications are surveyed. Here, a trained agent is used to perform the registration
    as opposed to a pre-defined optimization algorithm. A visualization of this framework
    is given in Fig. [4](#S2.F4 "Figure 4 ‣ 2.2 Reinforcement Learning based Registration
    ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical Image Registration:
    A Survey"). Reinforcement learning based registration typically involves a rigid
    transformation model. However, it is possible to use a deformable transformation
    model.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们调查了用于注册应用的强化学习方法。在这里，使用训练好的代理来执行注册，而不是使用预定义的优化算法。该框架的可视化见图 [4](#S2.F4
    "Figure 4 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey")。基于强化学习的注册通常涉及刚性变换模型。然而，也可以使用可变形变换模型。'
- en: '![Refer to caption](img/e8c8de298661cee539588f2a4f92854d.png)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e8c8de298661cee539588f2a4f92854d.png)'
- en: 'Figure 4: A visualization of the registration pipeline for works that use deep
    reinforcement learning to implicitly quantify image similarity for image registration.
    Here, an agent learns to map states to actions based on rewards that it receives
    from the environment.'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：使用深度强化学习隐式量化图像相似性的注册流程可视化。在这里，代理学习将状态映射到基于从环境中获得的奖励的动作。
- en: Liao et al. Liao et al. ([2017](#bib.bib62)) were the first to use reinforcment
    learning based registration to perform the rigid registration of cardiac and abdominal
    3D CT images and cone-beam CT (CBCT) images. They used a greedy supervised approach
    for end-to-end training with an attention-driven hierarchical strategy. Their
    method outperformed MI based registration and semantic registration using probability
    maps.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: Liao 等人 ([2017](#bib.bib62)) 首次使用基于强化学习的注册方法来执行心脏和腹部 3D CT 图像以及圆锥束 CT (CBCT)
    图像的刚性注册。他们使用了贪婪的监督方法进行端到端训练，并采用了基于注意力的分层策略。他们的方法优于基于互信息的注册和使用概率图的语义注册。
- en: Shortly after, Kai et al. Ma et al. ([2017](#bib.bib71)) used a reinforcement
    learning approach to perform the rigid registration of MR/CT chest volumes. This
    approach is derived from $Q$-learning and leverages contextual information to
    determine the depth of the projected images. The network used in this method is
    derived from the dueling network architecture Wang et al. ([2015](#bib.bib108)).
    Notably, this work also differentiates between terminal and non-terminal rewards.
    This method outperforms registration methods that are based on iterative closest
    points (ICP), landmarks, Hausdorff distance, Deep Q Networks, and the Dueling
    Network Wang et al. ([2015](#bib.bib108)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 不久之后，Kai 等人和 Ma 等人 ([2017](#bib.bib71)) 使用了强化学习方法来执行 MR/CT 胸部体积的刚性注册。这种方法源于
    $Q$-学习，并利用上下文信息来确定投影图像的深度。该方法使用的网络源于 Wang 等人 ([2015](#bib.bib108)) 的对抗网络架构。值得注意的是，这项工作还区分了终端奖励和非终端奖励。这种方法优于基于迭代最近点
    (ICP)、标志点、Hausdorff 距离、深度 Q 网络和对抗网络 Wang 等人 ([2015](#bib.bib108)) 的注册方法。
- en: Instead of training a single agent like the above methods, Miao et al. Miao
    et al. ([2017](#bib.bib76)) used a multi-agent system in a reinforcement learning
    paradigm to rigidly register X-Ray and CT images of the spine. They used an auto-attention
    mechanism to observe multiple regions and demonstrate the efficacy of a multi-agent
    system. They were able to significantly outperform registration approaches that
    used a state-of-the-art similarity metric given by De Silva et al. ([2016](#bib.bib22)).
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述方法训练单个代理不同，Miao 等人 ([2017](#bib.bib76)) 在强化学习范式中使用了多代理系统来对 X 射线和 CT 图像进行刚性注册。他们使用了自动关注机制来观察多个区域，并展示了多代理系统的有效性。他们能够显著优于使用
    De Silva 等人 ([2016](#bib.bib22)) 提供的最先进相似性度量的注册方法。
- en: As opposed to the above rigid registration based works, Krebs et al. Krebs et al.
    ([2017](#bib.bib55)) used a reinforcement learning based approach to perform the
    deformable registration of 2D and 3D prostate MR volumes. They used a low resolution
    deformation model for the registration and fuzzy action control to influence the
    stochastic action selection. The low resolution deformation model is necessary
    to restrict the dimensionality of the action space. This approach outperformed
    registration performed using the Elastix toolbox Klein et al. ([2010](#bib.bib53))
    and LCC-Demons Lorenzi et al. ([2013](#bib.bib69)) based registration techniques.
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述基于刚性配准的方法不同，Krebs 等人（[2017](#bib.bib55)）采用了一种基于强化学习的方法来进行二维和三维前列腺 MR 体积的变形配准。他们使用了低分辨率变形模型进行配准，并通过模糊动作控制来影响随机动作选择。低分辨率变形模型对于限制动作空间的维度是必要的。这种方法优于使用
    Elastix 工具箱 Klein 等人（[2010](#bib.bib53)）和 LCC-Demons Lorenzi 等人（[2013](#bib.bib69)）的配准技术。
- en: '![Refer to caption](img/c568e97148dc30faeac61f0188933073.png)'
  id: totrans-52
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c568e97148dc30faeac61f0188933073.png)'
- en: 'Figure 5: A visualization of supervised single step registration.'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5：监督单步配准的可视化。
- en: The use of reinforcement learning is intuitive for medical image registration
    applications. One of the principle challenges for reinforcement learning based
    registration is the ability to handle high resolution deformation fields. There
    are no such challenges for rigid registration. Because of the intuitive nature
    and recency of these methods, we expect that such approaches will receive more
    attention from the research community in the next few years.
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: 强化学习的使用对于医学图像配准应用是直观的。基于强化学习的配准的主要挑战之一是处理高分辨率变形场的能力。刚性配准没有这样的挑战。由于这些方法的直观性质和较新的出现，我们预计在未来几年，这些方法将受到研究界更多的关注。
- en: 'Table 2: Supervised Transformation Estimation Methods. Gray rows use Diffeomorphisms.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 表 2：监督变换估计方法。灰色行使用的是微分同胚。
- en: Ref Supervision Transform Modality ROI Model Yang et al. ([2016](#bib.bib114))
    Real Transforms Deformable MR Brain FCN Cao et al. ([2017](#bib.bib13)) Real Transforms
    Deformable MR Brain 9-layer CNN Lv et al. ([2018](#bib.bib70)) Real Transforms
    Deformable MR Abdominal CNN Rohé et al. ([2017](#bib.bib86)) Real Transforms Deformable
    MR Cardiac SVF-Net Sokooti et al. ([2017](#bib.bib99)) Synthetic Deformable CT
    Chest RegNet Transforms Eppenhof and Pluim ([2018a](#bib.bib28)) Synthetic Deformable
    CT Lung U-Net Transforms Uzunova et al. ([2017](#bib.bib103)) Synthetic Deformable
    MR Brain/ FlowNet Transforms Cardiac Ito and Ino ([2018](#bib.bib47)) Synthetic
    Deformable MR Brain GoogleNet Transforms Sun et al. ([2018](#bib.bib102)) Synthetic
    Deformable CT/US Liver DVFNet Transforms Yang ([2017](#bib.bib113)) Real + Synthetic
    Deformable MR Brain FCN Transforms Sloan et al. ([2018](#bib.bib97)) Synthetic
    Rigid MR Brain 6-layer CNN Transforms 10-layer FCN Salehi et al. ([2018](#bib.bib90))
    Synthetic Rigid MR Brain 11-layer CNN Transforms ResNet-18 Zheng et al. ([2018](#bib.bib119))
    Synthetic Rigid X-ray Bone 17-layer CNN Transforms PDA Module Miao et al. ([2016b](#bib.bib78))
    Synthetic Rigid X-ray/ Bone 6-layer CNN Transforms DDR Chee and Wu ([2018](#bib.bib15))
    Synthetic Rigid MR Brain AIRNet Transforms Hu et al. ([2018c](#bib.bib44)) Segmentations
    Deformable MR/US Prostate 30-layer FCN Hering et al. ([2018](#bib.bib40)) Segmentations
    + Deformable MR/US Prostate U-Net Similarity Metric GAN Hu et al. ([2018a](#bib.bib42))
    Segmentations + Deformable MR/US Prostate GAN Adversarial Loss Fan et al. ([2018b](#bib.bib31))
    Real Transforms + Deformable MR Brain U-Net Similarity Metric Yan et al. ([2018](#bib.bib111))
    Synthetic Rigid MR/US Prostate GAN Transforms + Adversarial Loss
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
- en: 3 Supervised Transformation Estimation
  id: totrans-57
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Despite the early success of the previously described approaches, the transformation
    estimation in these methods is iterative, which can lead to slow registration.
    Haskins et al. ([2019](#bib.bib36)). This is especially true in the deformable
    registration case where the solution space is high dimensional Lee et al. ([2017](#bib.bib59)).
    This motivated the development of networks that could estimate the transformation
    that corresponds to optimal similarity in one step. However, fully supervised
    transformation estimation (the exclusive use of ground truth data to define the
    loss function) has several challenges that are highlighted in this section.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
- en: 'A visualization of supervised transformation estimation is given in Fig. [5](#S2.F5
    "Figure 5 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey") and a description of
    notable works is given in Table [2](#S2.T2 "Table 2 ‣ 2.2 Reinforcement Learning
    based Registration ‣ 2 Deep Iterative Registration ‣ Deep Learning in Medical
    Image Registration: A Survey"). This section first discusses methods that use
    fully supervised approaches in Section [3.1](#S3.SS1 "3.1 Fully Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey") and then discusses methods that use dual/weakly
    supervised approaches in Section [3.2](#S3.SS2 "3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '图[5](#S2.F5 "Figure 5 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep
    Iterative Registration ‣ Deep Learning in Medical Image Registration: A Survey")展示了监督变换估计的可视化，表[2](#S2.T2
    "Table 2 ‣ 2.2 Reinforcement Learning based Registration ‣ 2 Deep Iterative Registration
    ‣ Deep Learning in Medical Image Registration: A Survey")列出了 notable works。本节首先讨论了在[3.1](#S3.SS1
    "3.1 Fully Supervised Transformation Estimation ‣ 3 Supervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey")部分中使用完全监督方法的方法，然后讨论了在[3.2](#S3.SS2
    "3.2 Dual/Weakly Supervised Transformation Estimation ‣ 3 Supervised Transformation
    Estimation ‣ Deep Learning in Medical Image Registration: A Survey")部分中使用双重/弱监督方法的方法。'
- en: 3.1 Fully Supervised Transformation Estimation
  id: totrans-60
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1 全监督变换估计
- en: In this section, methods that used full supervision for single-step registration
    are surveyed. Using a neural network to perform registration as opposed to an
    iterative optimizer significantly speeds up the registration process.
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 在这一部分，我们将探讨用于单步配准的全监督方法。与迭代优化器相比，使用神经网络进行配准显著加快了配准过程。
- en: 3.1.1 Overview of works
  id: totrans-62
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1 作品概述
- en: Several registration application require deformable transformation models that
    often prohibit the use of traditional convolutional neural networks because of
    the computational expense associated with using FC-layers to make predictions
    in highly dimensional solution spaces Krebs et al. ([2017](#bib.bib55)). Because
    the networks that are used to predict deformation fields are fully convolutional,
    the dimensionality of the solution space associated with a deformation field does
    not introduce additional computational constraints Yang et al. ([2016](#bib.bib114)).
    This section will first discuss approaches that use a rigid transformation model
    and then discuss approaches that use a deformable transformation model.
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 一些配准应用需要可变形变换模型，这通常禁止使用传统的卷积神经网络，因为使用FC层在高维解空间中进行预测的计算开销很大 Krebs et al. ([2017](#bib.bib55))。由于用于预测变形场的网络是完全卷积的，与变形场相关的解空间的维度不会引入额外的计算约束
    Yang et al. ([2016](#bib.bib114))。本节将首先讨论使用刚性变换模型的方法，然后讨论使用可变形变换模型的方法。
- en: 3.1.1.1 Rigid Registration
  id: totrans-64
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 3.1.1.1 刚性配准
- en: Miao et al. Miao et al. ([2016a](#bib.bib77), [b](#bib.bib78)) were the first
    to use deep learning to predict rigid transformation parameters. They used a CNN
    to predict the transformation matrix associated with the rigid registration of
    2D/3D X-ray attenuation maps and 2D X-ray images. Hierarchical regression is proposed
    in which the 6 transformation parameters are partitioned into 3 groups. Ground
    truth data was synthesized in this approach by transforming aligned data. This
    is the case for the next three approaches that are described as well. This approach
    outperformed MI, CC, and gradient correlation (GC)-optimization-based registration
    approaches with respect to both accuracy and computational efficiency. The improved
    computational efficiency is due to the use of a forward pass through a neural
    network instead of an optimization algorithm to perform the registration.
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: Miao et al. Miao et al. ([2016a](#bib.bib77), [b](#bib.bib78)) 首次使用深度学习来预测刚性变换参数。他们使用CNN来预测与2D/3D
    X射线衰减图和2D X射线图像的刚性配准相关的变换矩阵。提出了分层回归，其中6个变换参数被划分为3组。此方法通过变换对齐的数据来合成地面真实数据。这也是接下来描述的三种方法的情况。该方法在准确性和计算效率方面优于基于MI、CC和梯度相关性（GC）优化的配准方法。提高的计算效率归因于使用神经网络的前向传递，而不是优化算法来执行配准。
- en: Recently, Chee et al. Chee and Wu ([2018](#bib.bib15)) used a CNN to predict
    the transformation parameters used to rigidly register 3D brain MR volumes. In
    their framework, affine image registration network (AIRNet), the MSE between the
    predicted and ground truth affine transforms is used to train the network. They
    were able to outperform MI-optimization-based registration for both the unimodal
    and multimodal cases.
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Chee等人（Chee and Wu，[2018](#bib.bib15)）使用CNN来预测用于刚性配准3D脑MR体积的变换参数。在他们的框架中，仿射图像配准网络（AIRNet）使用预测的和真实的仿射变换之间的均方误差（MSE）来训练网络。他们能够在单模态和多模态情况下均优于基于MI优化的配准方法。
- en: That same year, Salehi et al. Salehi et al. ([2018](#bib.bib90)) used a deep
    residual regression network, a correction network, and a bivariant geodesic distance
    based loss function to rigidly register T1 and T2 weighted 3D fetal brain MRs
    for atlas construction. The use of the residual network to initially register
    the image volumes prior to the forward pass through the correction network allowed
    for an enhancement of the capture range of the registration. This approach was
    evaluated for both slice-to-volume registration and volume-to-volume registration.
    They validated the efficacy of their geodesic loss term and outperformed NCC-optimization-based
    registration.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 同年，Salehi等人（Salehi et al.，[2018](#bib.bib90)）使用了深度残差回归网络、校正网络和基于双变量测地距离的损失函数来刚性配准T1和T2加权的3D胎儿脑MR，以构建图谱。使用残差网络初步配准图像体积，然后通过校正网络进行前向传播，从而提高了配准的捕捉范围。这种方法在切片到体积配准和体积到体积配准中都进行了评估。他们验证了测地损失项的有效性，并优于基于NCC优化的配准方法。
- en: Additionally, Zheng et al. Zheng et al. ([2018](#bib.bib119)) proposed the integration
    of a pairwise domain adaptation module (PDA) into a pre-trained CNN that performs
    the rigid registration of pre-operative 3D X-Ray images and intraoperative 2D
    X-ray images using a limited amount of training data. Domain adaptation was used
    to address the discrepancy between synthetic data that was used to train the deep
    model and real data.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，郑等人（Zheng et al.，[2018](#bib.bib119)）提出了将一对一领域适应模块（PDA）集成到一个预训练的CNN中，该CNN使用有限的训练数据进行术前3D
    X射线图像和术中2D X射线图像的刚性配准。领域适应用于解决用于训练深度模型的合成数据与真实数据之间的差异。
- en: Sloan et al. Sloan et al. ([2018](#bib.bib97)) used a CNN is used to regress
    the rigid transformation parameters for the registration of T1 and T2 weighted
    brain MRs. Both unimodal and multimodal registration were investigated in this
    work. The parameters that constitute the convolutional layers that were used to
    extract low-level features in each image were only shared in the unimodal case.
    In the multimodal case, these parameters were learned separately. This approach
    also outperformed MI-optimization-based image registration.
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: Sloan等人（Sloan et al.，[2018](#bib.bib97)）使用了卷积神经网络（CNN）来回归刚性变换参数，以实现T1和T2加权脑MR的配准。该工作研究了单模态和多模态的配准。在单模态情况下，用于提取每张图像低级特征的卷积层的参数仅在单模态情况下共享。在多模态情况下，这些参数是单独学习的。这种方法还优于基于互信息（MI）优化的图像配准方法。
- en: 3.1.1.2 Deformable Registration
  id: totrans-70
  prefs:
  - PREF_H5
  type: TYPE_NORMAL
  zh: 3.1.1.2 可变形配准
- en: Unike the previous section, methods that use both real and synthesized ground
    truth labels will be discussed. Methods that use clinical/publicly available ground
    truth labels for training are discussed first. This ordering is reflective of
    the fact that simulating realistic deformable transformations is more difficult
    than simulating realistic rigid transformations.
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 与上一部分不同，将讨论使用真实和合成地面真值标签的方法。首先讨论使用临床/公开获取的地面真值标签进行训练的方法。这种排序反映了模拟现实的可变形变换比模拟现实的刚性变换更为困难。
- en: First, Yang et al. Yang et al. ([2016](#bib.bib114)) predicted the deformation
    field with an FCN that is used to register 2D/3D intersubject brain MR volumes
    in a single step. A U-net like architecture Ronneberger et al. ([2015](#bib.bib87))
    was used in this approach. Further, they used large diffeomorphic metric mapping
    to provide a basis, used the initial momentum values of the pixels of the image
    volumes as the network input, and evolved these values to obtain the predicted
    deformation field. This method outperformed semi-coupled dictionary learning based
    registration Cao et al. ([2015](#bib.bib11)).
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 首先，杨等人 ([2016](#bib.bib114)) 预测了变形场，使用了一个全卷积网络（FCN），该网络用于在单步中对2D/3D被试脑部MR体积进行配准。在此方法中，采用了类似U-net的架构
    ([Ronneberger et al.](#bib.bib87) [2015])。此外，他们使用了大规模微分度量映射提供基础，使用图像体积的像素初始动量值作为网络输入，并演化这些值以获得预测的变形场。该方法优于基于半耦合字典学习的配准方法
    ([Cao et al.](#bib.bib11) [2015])。
- en: The following year, Rohe et al. Rohé et al. ([2017](#bib.bib86)) also used a
    U-net Ronneberger et al. ([2015](#bib.bib87)) inspired network to estimate the
    deformation field used to register 3D cardiac MR volumes. Mesh segmentations are
    used to compute the reference transformation for a given image pair and SSD between
    the prediction and ground truth is used as the loss function. This method outperformed
    LCC Demons based registration Lorenzi et al. ([2013](#bib.bib69)).
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 次年，罗赫等人 ([2017](#bib.bib86)) 也使用了受U-net启发的网络 ([Ronneberger et al.](#bib.bib87)
    [2015]) 来估计用于配准3D心脏MR体积的变形场。使用网格分割计算给定图像对的参考变换，并且使用预测与真实值之间的SSD作为损失函数。该方法优于基于LCC
    Demons的配准方法 ([Lorenzi et al.](#bib.bib69) [2013])。
- en: That same year, Cao et al. Cao et al. ([2017](#bib.bib13)) used a CNN to map
    input image patches of a pair of 3D brain MR volumes to their respective displacement
    vector. The totality of these displacement vectors for a given image constitutes
    the deformation field that is used to perform the registration. Additionally,
    they used the similarity between inputted image patches to guide the learning
    process. Further, they used equalized active-points guided sampling strategy that
    makes it so that patches with higher gradient magnitudes and displacement values
    are more likely to be sampled for training. This method outperforms SyN Avants
    et al. ([2008](#bib.bib6)) and Demons Vercauteren et al. ([2009](#bib.bib104))
    based registration methods.
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 同年，曹等人 ([2017](#bib.bib13)) 使用卷积神经网络（CNN）将一对3D脑部MR体积的输入图像块映射到各自的位移向量。这些位移向量的总和构成了用于执行配准的变形场。此外，他们使用了输入图像块之间的相似性来指导学习过程。进一步，他们使用了均衡活跃点引导采样策略，使得具有更高梯度幅度和位移值的块更可能被用于训练。该方法优于基于SyN
    ([Avants et al.](#bib.bib6) [2008]) 和基于Demons ([Vercauteren et al.](#bib.bib104)
    [2009]) 的配准方法。
- en: Recently, Jun et al. Lv et al. ([2018](#bib.bib70)) used a CNN to perform the
    deformable registration of abdominal MR images to compensate for the deformation
    that is caused by respiration. This approach achieved registration results that
    are superior to those obtained using non-motion corrected registrations and local
    affine registration. Recently, unlike many of the other approaches discussed in
    this paper, Yang et al. Yang ([2017](#bib.bib113)) quantified the uncertainty
    associated with the deformable registration of 3D T1 and T2 weighted brain MRs
    using a low-rank Hessian approximation of the variational gaussian distribution
    of the transformation parameters. This method was evaulated on both real and synthetic
    data.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，Jun et al. ([2018](#bib.bib70)) 使用CNN执行腹部MR图像的可变形配准，以补偿由呼吸引起的变形。这种方法的配准结果优于未进行运动校正的配准结果和局部仿射配准。近期，与本文讨论的许多其他方法不同，杨等人
    ([Yang](#bib.bib113) [2017]) 量化了3D T1和T2加权脑部MR的可变形配准所涉及的不确定性，采用了变换参数的变分高斯分布的低秩Hessian近似。这种方法在真实和合成数据上进行了评估。
- en: Just as deep learning practitioners use random transformations to enhance the
    diversity of their dataset, Sokooti et al. Sokooti et al. ([2017](#bib.bib99))
    used random DVFs to augment their dataset. They used a multi-scale CNN to predict
    a deformation field. This deformation is used to perform intra-subject registration
    of 3D chest CT images. This method used late fusion as opposed to early fusion,
    in which the patches are concatenated and used as the input to the network. The
    performance of their method is competitive with B-Spline based registration Sokooti
    et al. ([2017](#bib.bib99)).
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 正如深度学习从业者使用随机变换来增强数据集的多样性一样，Sokooti 等人 ([2017](#bib.bib99)) 使用随机 DVF 来增强他们的数据集。他们使用多尺度
    CNN 来预测变形场。该变形用于进行 3D 胸部 CT 图像的同一受试者配准。该方法使用晚期融合，而非早期融合，其中补丁被拼接并作为网络的输入。该方法的性能与基于
    B 样条的配准 Sokooti 等人 ([2017](#bib.bib99)) 具有竞争力。
- en: Such approaches have notable, but also limited ability to enhance the size and
    diversity of datasets. These limitations motivated the development of more sophisticated
    ground truth generation. The rest of the approaches described in this section
    use simulated ground truth data for their applications.
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法在增强数据集的规模和多样性方面有显著但也有限的能力。这些限制促使了更复杂的真实数据生成方法的发展。本节中描述的其余方法使用模拟的真实数据进行应用。
- en: For example, Eppenhof et al. Eppenhof and Pluim ([2018a](#bib.bib28)) used a
    3D CNN to perform the deformable registration of inhale-exhale 3D lung CT image
    volumes. A series of multi-scale, random transformations of aligned image pairs
    eliminate the need for manually annotated ground truth data while also maintaining
    realistic image appearance. Further, as is the case with other methods that generate
    ground truth data, the CNN can be trained using relatively few medical images
    in a supervised capacity.
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，Eppenhof 和 Pluim ([2018a](#bib.bib28)) 使用 3D CNN 执行吸气-呼气 3D 肺 CT 图像体积的变形配准。一系列多尺度、随机变换的对齐图像对消除了对手动注释真实数据的需求，同时保持了现实的图像外观。此外，与其他生成真实数据的方法一样，CNN
    可以使用相对较少的医学图像进行监督训练。
- en: Unlike the above works, Uzunova et al. Uzunova et al. ([2017](#bib.bib103))
    generated ground truth data using statistical appearance models (SAMs). They used
    a CNN to estimate the deformation field for the registration of 2D brain MRs and
    2D cardiac MRs, and adapt FlowNet Dosovitskiy et al. ([2015](#bib.bib26)) for
    their application. They demonstrated that training FlowNet using SAM generated
    ground truth data resulted in superior performance to CNNs trained using either
    randomly generated ground truth data or ground truth data obtained using the registration
    method described in Ehrhardt et al. ([2015](#bib.bib27)).
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 与上述工作不同，Uzunova 等人 ([2017](#bib.bib103)) 使用统计外观模型 (SAMs) 生成真实数据。他们使用 CNN 估计
    2D 脑 MR 和 2D 心脏 MR 图像的变形场，并将 FlowNet Dosovitskiy 等人 ([2015](#bib.bib26)) 适应到他们的应用中。他们展示了使用
    SAM 生成的真实数据训练 FlowNet 的性能优于使用随机生成的真实数据或使用 Ehrhardt 等人 ([2015](#bib.bib27)) 描述的配准方法获得的真实数据训练的
    CNN。
- en: Unlike the other methods in this section that use random transformations or
    manually crafted methods to generate ground truth data, Ito et al. Ito and Ino
    ([2018](#bib.bib47)) used a CNN to learn plausible deformations for ground truth
    data generation. They evaluated their approach on the 3D brain MR volumes in the
    ADNI dataset and outperformed the MI-optimization-based approach proposed in Ikeda
    et al. ([2014](#bib.bib45)).
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 与本节中使用随机变换或手动制作方法生成真实数据的其他方法不同，Ito 等人 ([2018](#bib.bib47)) 使用 CNN 学习可行的变形来生成真实数据。他们在
    ADNI 数据集的 3D 脑 MR 图像上评估了他们的方法，并超越了 Ikeda 等人 ([2014](#bib.bib45)) 提出的基于 MI 优化的方法。
- en: 3.1.2 Discussion and Assessment
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.2 讨论与评估
- en: Supervised transformation estimation has allowed for real time, robust registration
    across applications. However, such works are not without their limitations. Firstly,
    the quality of the registrations using this framework is dependent on the quality
    of the ground truth registrations. The quality of these labels is, of course,
    dependent upon the expertise of the practitioner. Furthermore, these labels are
    fairly difficult to obtain because there are relatively few individuals with the
    expertise necessary to perform such registrations. Transformations of training
    data and the generation of synthetic ground truth data can address such limitations.
    However, it is important to ensure that simulated data is sufficiently similar
    to clinical data. These challenges motivated the development of partially supervised/unsupervised
    approaches, which will be discussed next.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 监督变换估计使得在应用中实现实时、稳健的配准成为可能。然而，这些方法也有其局限性。首先，使用该框架的配准质量依赖于地面真实配准的质量。这些标签的质量自然依赖于实践者的专业水平。此外，这些标签较难获得，因为具备进行此类配准所需专业知识的人相对较少。训练数据的变换和合成地面真实数据的生成可以解决这些限制。然而，重要的是要确保模拟数据与临床数据有足够的相似性。这些挑战促使了部分监督/无监督方法的发展，接下来将讨论这些方法。
- en: 3.2 Dual/Weakly Supervised Transformation Estimation
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2 双重/弱监督变换估计
- en: 'Dual supervision refers to the use of both ground truth data and some metric
    that quantifies image similarity to train a model. On the other hand, weak supervision
    refers to using the overlap of segmentations of corresponding anatomical structures
    to design the loss function. This section will discuss the contributions of such
    works in Section [3.2.1](#S3.SS2.SSS1 "3.2.1 Overview of works ‣ 3.2 Dual/Weakly
    Supervised Transformation Estimation ‣ 3 Supervised Transformation Estimation
    ‣ Deep Learning in Medical Image Registration: A Survey") and then discuss the
    overall state of this research direction in Section [3.2.2](#S3.SS2.SSS2 "3.2.2
    Discussion and Assessment ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 双重监督指的是使用地面真实数据和量化图像相似性的一些度量来训练模型。另一方面，弱监督指的是利用相应解剖结构的分割重叠来设计损失函数。本节将讨论这些工作的贡献，详见[3.2.1](#S3.SS2.SSS1
    "3.2.1 作品概述 ‣ 3.2 双重/弱监督变换估计 ‣ 3 监督变换估计 ‣ 医学图像配准中的深度学习：综述")，然后在[3.2.2](#S3.SS2.SSS2
    "3.2.2 讨论与评估 ‣ 3.2 双重/弱监督变换估计 ‣ 3 监督变换估计 ‣ 医学图像配准中的深度学习：综述")节中讨论这一研究方向的总体状态。
- en: 3.2.1 Overview of works
  id: totrans-85
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1 作品概述
- en: '![Refer to caption](img/ad32c0c42ab62d93f3d21860cb88245f.png)'
  id: totrans-86
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/ad32c0c42ab62d93f3d21860cb88245f.png)'
- en: 'Figure 6: A visualization of deep single step registration where the agent
    is trained using dual supervision. The loss function is determined using both
    a metric that quantifies image similarity and ground truth data.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：深度单步配准的可视化，其中代理使用双重监督进行训练。损失函数通过量化图像相似性的度量标准和地面真实数据来确定。
- en: 'First, this section will discuss methods that use dual supervised and then
    will discuss methods that use weak supervision. Recently, Fan et al. Fan et al.
    ([2018b](#bib.bib31)) used hierarchical, dual-supervised learning to predicted
    the deformation field for 3D brain MR registration. They amend the traditional
    U-Net architecture Ronneberger et al. ([2015](#bib.bib87)) by using “gap-filling”
    (*i.e.*, inserting convolutional layers after the U-type ends or the architecture)
    and coarse-to-fine guidance. This approach leveraged both the similarity between
    the predicted and ground truth transformations, and the similarity between the
    warped and fixed images to train the network. The architecture detailed in this
    method outperformed the traditional U-Net architecture and the dual supervision
    strategy is verified by ablating the image similarity loss function term. A visualization
    of dual supervised transformation estimation is given in Fig. [6](#S3.F6 "Figure
    6 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '首先，本节将讨论使用双重监督的方法，然后讨论使用弱监督的方法。最近，Fan等人 ([2018b](#bib.bib31)) 使用了层次化的双重监督学习来预测3D脑MR配准的变形场。他们通过在U-Net架构的U型端或架构后插入卷积层（即“填补空白”）以及粗到精的指导来修正传统的U-Net架构（Ronneberger等人
    ([2015](#bib.bib87))）。这种方法利用了预测变换与真实变换之间的相似性，以及变形图像与固定图像之间的相似性来训练网络。这种方法中的架构优于传统的U-Net架构，并且通过消融图像相似性损失函数项验证了双重监督策略。双重监督变换估计的可视化见图[6](#S3.F6
    "Figure 6 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")。'
- en: 'On the other hand, Yan et al. Yan et al. ([2018](#bib.bib111)) used a framework
    that is inspired by the GAN Goodfellow et al. ([2014](#bib.bib35)) to perform
    the rigid registration of 3D MR and TRUS volumes. In this work, the generator
    was trained to estimate a rigid transformation. While, the discriminator was trained
    to discern between images that were aligned using the ground truth transformations
    and images that were aligned using the predicted transformations. Both Euclidean
    distance to ground truth and an adversarial loss term are used to construct the
    loss function in this method. Note that the adversarial supervision strategy that
    was used in this approach is similar to the ones that are used in a number of
    unsupervised works that will be described in the next section. A visualization
    of adversarial transformation estimation is given in Fig. [7](#S3.F7 "Figure 7
    ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation Estimation
    ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical Image Registration:
    A Survey").'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '另一方面，Yan等人 ([2018](#bib.bib111)) 使用了一个受GAN（Goodfellow等人 ([2014](#bib.bib35))
    启发的框架来进行3D MR和TRUS体积的刚性配准。在这项工作中，生成器被训练用于估计刚性变换，而判别器则被训练以辨别使用真实变换对齐的图像和使用预测变换对齐的图像。这种方法中使用了到真实值的欧几里得距离和对抗损失项来构建损失函数。请注意，这种方法中使用的对抗监督策略与下一节将描述的一些无监督工作所使用的策略类似。对抗变换估计的可视化见图[7](#S3.F7
    "Figure 7 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")。'
- en: '![Refer to caption](img/827955275448ceb55a3ad37a6b745d33.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/827955275448ceb55a3ad37a6b745d33.png)'
- en: 'Figure 7: A visualization of an adversarial image registration framework. Here,
    the generator is trained using output from the discriminator. The discriminator
    takes the form of a learned metric here.'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图7：一个对抗图像配准框架的可视化。在这里，生成器使用来自判别器的输出进行训练。判别器在这里采用的是一种学习到的度量形式。
- en: 'Unlike the above methods that used dual supervision, Hu et al. Hu et al. ([2018b](#bib.bib43),
    [c](#bib.bib44)) recently used label similarity to train their network to perform
    MR-TRUS registration. In their initial work, they used two neural networks: local-net
    and global-net to estimate the global affine transformation with 12 degrees of
    freedom and the local dense deformation field respectively Hu et al. ([2018b](#bib.bib43)).
    The local-net uses the concatenation of the transformation of the moving image
    given by the global-net and the fixed image as its input. However, in their later
    work Hu et al. ([2018c](#bib.bib44)), they combine these networks in an end-to-end
    framework. This method outperformed NMI-optimization-based and NCC based registration.
    A visualization of weakly supervised transformation estimation is given in Fig. [8](#S3.F8
    "Figure 8 ‣ 3.2.1 Overview of works ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey"). In another work, Hu et al. Hu et al. ([2018a](#bib.bib42))
    simultaneously maximized label similarity and minimized an adversarial loss term
    to predict the deformation for MR-TRUS registration. This regularization term
    forces the predicted transformation to result in the generation of a realistic
    image. Using the adversarial loss as a regularization term is likely to successfully
    force the transformation to be realistic given proper hyper parameter selection.
    The performance of this registration framework was inferior to the performance
    of their previous registration framework described above. However, they showed
    that adversarial regularization is superior to standard bending energy based regularization.
    Similar to the above method, Hering et al. Hering et al. ([2018](#bib.bib40))
    built upon the progress made with respect to both dual and weak supervision by
    introducing a label and similarity metric based loss function for cardiac motion
    tracking via the deformable registration of 2D cine-MR images. Both segmentation
    overlap and edge based normalized gradient fields distance were used to construct
    the loss function in this approach. Their method outperformed a multilevel registration
    approach similar to the one proposed in Rühaak et al. ([2013](#bib.bib88)).'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/2a14b8735627c5658b43ea872555b94a.png)'
  id: totrans-93
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: A visualization of deep single step registration where the agent
    is trained using label similarity (*i.e.* weak supervision). Manually annotated
    data (segmentations) are used to define the loss function used to train the network.'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2 Discussion and Assessment
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Direct transformation estimation marked a major breakthrough for deep learning
    based image registration. With full supervision, promising results have been obtained.
    However, at the same time, those techniques require a large amount of detailed
    annotated images for training. Partially/weakly supervised transformation estimation
    methods alleviated the limitations associated with the trustworthiness and expense
    of ground truth labels. However, they still require manually annotated data (*e.g.*
    ground truth and/or segmentations). On the other hand, weak supervision allows
    for similarity quantification in the multimodal case. Further, partial supervision
    allows for the aggregation of methods that can be used to assess the quality of
    a predicted registration. As a result, there is growing interest in these research
    areas.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 3: Unsupervised Transformation Estimation Methods. Grays rows use Diffeomorphisms.'
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
- en: Ref Loss Function Transform Modality ROI Model Jiang and Shackleford ([2018](#bib.bib50))
    SSD Deformable CT Chest Multi-scale CNN Ghosal and Ray ([2017](#bib.bib33)) UB
    SSD Deformable MR Brain 19-layer FCN Zhang ([2018](#bib.bib118)) MSD Deformable
    MR Brain ICNet Shu et al. ([2018](#bib.bib95)) MSE Deformable SEM Neurons 11-layer
    CNN Dalca et al. ([2018](#bib.bib21)) MSE Deformable MR Brain VoxelMorph Sheikhjafari
    et al. ([2018](#bib.bib93)) MSE Deformable MR Cardiac 8-layer Cine FCNet Kuang
    and Schmah ([2018](#bib.bib58)) CC Deformable MR Brain FAIM Li and Fan ([2018](#bib.bib61))
    NCC Deformable MR Brain 8-layer FCN Cao et al. ([2018](#bib.bib12)) NCC Deformable
    CT, MR Pelvis U-Net de Vos et al. ([2017](#bib.bib24)) NCC Deformable MR Cardiac
    DIRNet Cine de Vos et al. ([2018](#bib.bib23)) NCC Deformable MR Cardiac DLIR
    Cine Ferrante et al. ([2018](#bib.bib32)) NCC Deformable X-ray, MR Bone U-Net
    Cardiac STN Cine Sun and Zhang ([2018](#bib.bib101)) L2 Distance + Deformable
    MR, US Brain FCN Image Gradient Neylon et al. ([2017](#bib.bib81)) Predicted TRE
    Deformable CT Head/Neck FCN Fan et al. ([2018a](#bib.bib30)) BCE Deformable MR
    Brain GAN Mahapatra ([2018](#bib.bib73)) NMI + SSIM Deformable MR, FA/ Cardiac
    GAN + VGG Outputs Color fundus Retinal Mahapatra et al. ([2018](#bib.bib74)) NMI
    + SSIM + Deformable X-ray Bone GAN VGG Outputs + BCE Yoo et al. ([2017](#bib.bib117))
    MSE AE Output Deformable ssEM Neurons CAE STN Wu et al. ([2016](#bib.bib110))
    MSE Stacked Deformable MR Brain Stacked AE Outputs AE Wu et al. ([2013](#bib.bib109))
    NCC of Deformable MR Brain Stacked ISA Outputs ISA Krebs et al. ([2018a](#bib.bib56))
    Log Likelihood Deformable MR Brain cVAE STN Liu and Leung ([2017](#bib.bib67))
    SSD MIND + Deformable CT, MR Chest FCN PCANet Outputs Brain PCANet Kori et al.
    ([2018](#bib.bib54)) SSD VGG Rigid MR Brain CNN Outputs MLP
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
- en: 4 Unsupervised Transformation Estimation
  id: totrans-99
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Despite the success of the methods described in the previous sections, the
    difficult nature of the acquisition of reliable ground truth remains a significant
    hindrance Uzunova et al. ([2017](#bib.bib103)). This has motivated a number of
    different groups to explore unsupervised approaches de Vos et al. ([2017](#bib.bib24));
    Li and Fan ([2018](#bib.bib61)). One key innovation that has been useful to these
    works is the spatial transformer network (STN) Jaderberg et al. ([2015](#bib.bib48)).
    Several methods use an STN to perform the deformations associated with their registration
    applications Ferrante et al. ([2018](#bib.bib32)); Kuang and Schmah ([2018](#bib.bib58)).
    This section discusses unsupervised methods that utilize image similarity metrics
    (Section [4.1](#S4.SS1 "4.1 Similarity Metric based Unsupervised Transformation
    Estimation ‣ 4 Unsupervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey")) and feature representations of image data (Section
    [4.2](#S4.SS2 "4.2 Feature based Unsupervised Transformation Estimation ‣ 4 Unsupervised
    Transformation Estimation ‣ Deep Learning in Medical Image Registration: A Survey"))
    to train their networks. A description of notable works is given in Table [3](#S3.T3
    "Table 3 ‣ 3.2.2 Discussion and Assessment ‣ 3.2 Dual/Weakly Supervised Transformation
    Estimation ‣ 3 Supervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
- en: 4.1 Similarity Metric based Unsupervised Transformation Estimation
  id: totrans-101
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 4.1.1 Standard Methods
  id: totrans-102
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'This section begins by discussing approaches that use a common similarity metric
    with common regularization strategies to define their loss functions. Later in
    the section, approaches that use more complex similarity metric based strategies
    are discussed. A visualization of standard similarity metric based transformation
    estimation is given in Fig. [9](#S4.F9 "Figure 9 ‣ 4.1.1 Standard Methods ‣ 4.1
    Similarity Metric based Unsupervised Transformation Estimation ‣ 4 Unsupervised
    Transformation Estimation ‣ Deep Learning in Medical Image Registration: A Survey").'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/40c688f94984086db1050b18fb48143d.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: A visualization of deep single step registration where the network
    is trained using a metric that quantifies image similarity. Therefore, the approach
    is unsupervised.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
- en: Inspired to overcome the difficulty associated with obtaining ground truth data,
    Li et al. Li and Fan ([2017](#bib.bib60), [2018](#bib.bib61)) trained an FCN to
    perform deformable intersubject registration of 3D brain MR volumes using ”self-supervision.”
    NCC between the warped and fixed images and several common regularization terms
    (*e.g.* smoothing constraints) constitute the loss function in this method. Although
    many manually defined similarity metrics fail in the multimodal case (with the
    occasional exception of MI), they are often suitable for the unimodal case. The
    method detailed in this work outperforms Advanced Neuroimaging Tools (ANTs) based
    registration Avants et al. ([2011](#bib.bib7)) and the deep learning methods proposed
    by Sokooti et al. Sokooti et al. ([2017](#bib.bib99)) (discussed previously) and
    Yoo et al. Yoo et al. ([2017](#bib.bib117)) (discussed in the next section).
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
- en: Further, de Vos et al. de Vos et al. ([2017](#bib.bib24)) used NCC to train
    an FCN to perform the deformable registration of 4D cardiac cine MR volumes. A
    DVF is used in this method to deform the moving volume. Their method outperforms
    registration that is performed using the Elastix toolbox Klein et al. ([2010](#bib.bib53)).
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: In another work, de Vos et al. de Vos et al. ([2018](#bib.bib23)) use a multistage,
    multiscale approach to perform unimodal registration on several datasets. NCC
    and a bending-energy regularization term are used to train the networks that predict
    an affine transformation and subsequent coarse-to-fine deformations using a B-Spline
    transformation model. In addition to validating their multi-stage approach, they
    show that their method outperforms registration that is performed using the Elastix
    toolbox Klein et al. ([2010](#bib.bib53)) with and without bending energy.
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
- en: The unsupervised deformable registration framework used by Ghosal et al. Ghosal
    and Ray ([2017](#bib.bib33)) minimizes the upper bound of the SSD (UB SSD) between
    the warped and fixed 3D brain MR images. The design of their network was inspired
    by the SKIP architecture Long et al. ([2015](#bib.bib68)). This method outperforms
    log-demons based registration.
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: Shu et al. Shu et al. ([2018](#bib.bib95)) used a coarse-to-fine, unsupervised
    deformable registration approach to register images of neurons that are acquired
    using a scanning electron microscope (SEM). The mean squared error (MSE) between
    the warped and fixed volumes is used as the loss function here. Their approach
    is competitive with and faster than the sift flow framework Liu et al. ([2011](#bib.bib64)).
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: Sheikhjafari et al. Sheikhjafari et al. ([2018](#bib.bib93)) used learned latent
    representations to perform the deformable registration of 2D cardiac cine MR volumes.
    Deformation fields are thus obtained by embedding. This latent representation
    is used as the input to a network that is composed of 8 fully connected layers
    to obtain the transformation. The sum of absolute errors (SAE) is used as the
    loss function. Here, the registration performance was seen to be influenced by
    the B-spline grid spacing. This method outperforms a moving mesh correspondence
    based method described in Punithakumar et al. ([2017](#bib.bib83)).
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
- en: Stergios et al. Stergios et al. ([2018](#bib.bib100)) used a CNN to both linearly
    and locally register inhale-exhale pairs of lung MR volumes. Therefore, both the
    affine transformation and the deformation are jointly estimated. The loss function
    is composed of an MSE term and regularization terms. Their method outperforms
    several state-of-the-art methods that do not utilized ground truth data, including
    Demons Lorenzi et al. ([2013](#bib.bib69)), SyN Avants et al. ([2008](#bib.bib6)),
    and a deep learning based method that uses an MSE loss term. Further, the inclusion
    of the regularization terms is validated by an ablation study.
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: The successes of deep similarity metric based unsupervised registration motivated
    Neylon et al. Neylon et al. ([2017](#bib.bib81)) to use a neural network to learn
    the relationship between image similarity metric values and TRE when registering
    CT image volumes. This is done in order to robustly assess registration performance.
    The network was able to achieve subvoxel accuracy in 95% of cases. Similarly inspired,
    Balakrishnan et al. Balakrishnan et al. ([2018a](#bib.bib8), [b](#bib.bib9)) proposed
    a general framework for unsupervised image registration, which can be either unimodal
    or multimodal theoretically. The neural networks are trained using a selected,
    manually-defined image similarity metric (*e.g.* NCC, NMI, etc.).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: In a follow-up paper, Dalca et al. Dalca et al. ([2018](#bib.bib21)) casted
    deformation prediction as variational inference. Diffeomorphic integration is
    combined with a transformer layer to obtain a velocity field. Squaring and rescaling
    layers are used to integrate the velocity field to obtain the predicted deformation.
    MSE is used as the similarity metric that, along with a regularization term, define
    the loss function. Their method outperforms ANTs based registration Avants et al.
    ([2011](#bib.bib7)) and the deep learning based method described in Balakrishnan
    et al. ([2018a](#bib.bib8)).
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
- en: Shortly after, Kuang et al. Kuang and Schmah ([2018](#bib.bib58)) used a CNN
    and STN inspired framework to perform the deformable registration of T1-weighted
    brain MR volumes. The loss function is composed of a NCC term and a regularization
    term. This method uses Inception modules, a low capacity model, and residual connections
    instead of skip connections. They compare their method with VoxelMorph (the method
    proposed by Balakrishnan et al., described above) Balakrishnan et al. ([2018b](#bib.bib9))
    and uTIlzReg GeoShoot Vialard et al. ([2012](#bib.bib105)) using the LBPA40 and
    Mindboggle 101 datasets and demonstrate superior performance with respect to both.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: Building upon the progress made by the previously described metric-based approaches,
    Ferrante et al. Ferrante et al. ([2018](#bib.bib32)) used a transfer learning
    based approach to perform unimodal registration of both X-ray and cardiac cine
    images. In this work, the network is trained on data from a source domain using
    NCC as the primary loss function term and tested in a target domain. They used
    a U-net like architecture Ronneberger et al. ([2015](#bib.bib87)) and an STN Jaderberg
    et al. ([2015](#bib.bib48)) to perform the feature extraction and transformation
    estimation respectively. They demonstrated that transfer learning using either
    domain as the source or the target domain produces effective results. This method
    outperformed registration obtained using the Elastix toolbox Klein et al. ([2010](#bib.bib53))
    with parameters determined using grid search.
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
- en: Although applying similarity metric based approaches to the multimodal case
    is difficult, Sun et al. Sun and Zhang ([2018](#bib.bib101)) proposed an unsupervised
    method for 3D MR/US brain registration that uses a 3D CNN that consists of a feature
    extractor and a deformation field generator. This network is trained using a similarity
    metric that incorporates both pixel intensity and gradient information. Further,
    both image intensity and gradient information are used as inputs into the CNN.
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2 Extensions
  id: totrans-118
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Cao et al. Cao et al. ([2018](#bib.bib12)) also applied similarity metric based
    training to the multimodal case. Specifically, they used intra-modality image
    similarity to supervise the multimodal deformable registration of 3D pelvic CT/MR
    volumes. The NCC between the moving image that is warped using the ground truth
    transformation and the moving image that is warped using the predicted transformation
    is used as the loss function. This work utilizes ”dual” supervision (*i.e.* the
    intra-modality supervision previously described is used for both the CT and the
    MR images). This is not to be confused with the dual supervision strategies described
    earlier.
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: Inspired by the limiting nature of the asymmetric transformations that typical
    unsupervised methods estimate, Zhang et al. Zhang ([2018](#bib.bib118)) used their
    network Inverse-Consistent Deep Network (ICNet)-to learn the symmetric diffeomorphic
    transformations for each of the brain MR volumes that are aligned into the same
    space. Different from other works that use standard regularization strategies,
    this work introduces an inverse-consistent regularization term and an anti-folding
    regularization term to ensure that a highly weighted smoothness constraint does
    not result in folding. Finally, the MSD between the two images allows this network
    to be trained in an unsupervised manner. This method outperformed SyN based registration
    Avants et al. ([2008](#bib.bib6)), Demons based registration Lorenzi et al. ([2013](#bib.bib69)),
    and several deep learning based approaches.
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: The next three approaches described in this section used a GAN for their applications.
    Unlike the GAN-based approaches described previously, these methods use neither
    ground truth data nor manually crafted segmentations. Mahapatra et al. Mahapatra
    ([2018](#bib.bib73)) used a GAN to implicitly learn the density function that
    represents the range of plausible deformations of cardiac cine images and multimodal
    retinal images (retinal colour fundus images and fluorescein angiography (FA)
    images). In addition to NMI, structual similarity index measure (SSIM), and a
    feature perceptual loss term (determined by the SSD between VGG outputs), the
    loss function is comprised of conditional and cyclic constraints, which are based
    on recent advances involving the implementation of adversarial frameworks. Their
    approach outperforms registration that is performed using the Elastix toolbox
    Klein et al. ([2010](#bib.bib53)) and the method proposed by de Vos et al. de Vos
    et al. ([2017](#bib.bib24)).
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: Further, Fan et al. Fan et al. ([2018a](#bib.bib30)) used a GAN to perform unsupervised
    deformable image registration of 3D brain MR volumes. Unlike most other unsupervised
    works that use a manually crafted similarity metric to determine the loss function
    and unlike the previous approach that used a GAN to ensure that the predicted
    deformation is realistic, this approach uses a discriminator to assess the quality
    of the alignment. This approach outperforms Diffeomorphic Demons and SyN registration
    on every dataset except for MGH10\. Further, the use of the discriminator for
    supervision of the registration network is superior to the use of ground truth
    data, SSD, and CC on all datasets.
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
- en: 'Different from the hitherto previously described works (not just the GAN based
    ones), Mahapatra et al. Mahapatra et al. ([2018](#bib.bib74)) proposed simultaneous
    segmentation and registration of chest X-rays using a GAN framework. The network
    takes 3 inputs: reference image, floating image, and the segmentation mask of
    the reference image and outputs the segmentation mask of the transformed image,
    and the deformation field. Three discriminators are used to assess the quality
    of the generated outputs (deformation field, warped image, and segmentation) using
    cycle consistency and a dice metric. The generator is additionally trained using
    NMI, SSIM, and a feature perceptual loss term.'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: Finally, instead of predicting a deformation field given a fixed parameterization
    as the other methods in this section do, Jiang et al. Jiang and Shackleford ([2018](#bib.bib50))
    used a CNN to learn an optimal parameterization of an image deformation using
    a multi-grid B-Spline method and L1-norm regularization. They use this approach
    to parameterize the deformable registration of 4D CT thoracic image volumes. Here,
    SSD is used as the similarity metric and L-BFGS-B is used as the optimizer. The
    convergence rate using the parameterized deformation model obtained using the
    proposed method is faster than the one obtained using a traditional L1-norm regularized
    multi-grid parameterization.
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.3 Discussion and Assessment
  id: totrans-125
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Image similarity based unsupervised image registration has received a lot of
    attention from the research community recently because it bypasses the need for
    expert labels of any kind. This means that the performance of the model will not
    depend on the expertise of the practitioner. Further, extensions of the original
    similarity metric based method that introduce more sophisticated similarity metrics
    (*e.g.* the discriminator of a GAN) and/or regularization strategies have yielded
    promising results. However, it is still difficult to quantify image similarity
    for multimodal registration applications. As a result, the scope of unsupervised,
    image similarity based works is largely confined to the unimodal case. Given that
    multimodal registration is often needed in many clinical applications, we expect
    to see more papers in the near future that will tackle this challenging problem.
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 4.2 Feature based Unsupervised Transformation Estimation
  id: totrans-127
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, methods that use learned feature representations to train
    neural networks are surveyed. Like the methods surveyed in the previous section,
    the methods surveyed in this section do not require ground truth data. In this
    section, approaches that create unimodal registration pipelines are presented
    first. Then, an approach that tackles multimodal image registration is discussed.
    A visualization of featured based transformation estimation is given in Fig. [10](#S4.F10
    "Figure 10 ‣ 4.2.1 Unimodal Registration ‣ 4.2 Feature based Unsupervised Transformation
    Estimation ‣ 4 Unsupervised Transformation Estimation ‣ Deep Learning in Medical
    Image Registration: A Survey").'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.1 Unimodal Registration
  id: totrans-129
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Yoo et al. Yoo et al. ([2017](#bib.bib117)) used an STN to register serial-section
    electron microscopy images (ssEMs). An autoencoder is trained to reconstruct fixed
    images and the L2 distance between reconstructed fixed images and corresponding
    warped moving images is used along with several regularization terms to construct
    the loss function. This approach outperforms the bUnwarpJ registration technique
    Arganda-Carreras et al. ([2006](#bib.bib5)) and the Elastic registration technique
    Saalfeld et al. ([2012](#bib.bib89)).
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: In the same year, Liu et al. Liu and Leung ([2017](#bib.bib67)) proposed a tensor
    based MIND method using a principle component analysis based network (PCANet)
    Chan et al. ([2015](#bib.bib14)) for both unimodal and multimodal registration.
    Both inhale-exhale pairs of thoracic CT volumes and multimodal pairs of brain
    MR images are used for experimental validation of this approach. MI and residual
    complexity (RC) based Myronenko and Song ([2010](#bib.bib79)), and the original
    MIND-based Heinrich et al. ([2012](#bib.bib38)) registration techniques were outperformed
    by the proposed method.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/32232b6d2203077015d00c48adab8874.png)'
  id: totrans-132
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: A visualization of feature based unsupervised image registration.
    Here, a feature extractor is used to map inputted images to a feature space to
    facilitate the prediction of transformation parameters.'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Krebs et al. Krebs et al. ([2018a](#bib.bib56), [b](#bib.bib57)) performed the
    registration of 2D brain and cardiac MRs and bypassed the need for spatial regularization
    using a stochastic latent space learning approach. A conditional variational autoencoder
    Doersch ([2016](#bib.bib25)) is used to ensure that the parameter space follows
    a prescribed probability distribution. The negative log liklihood of the fixed
    image given the latent representation and the warped volume and KL divergence
    of the latent distribution from a prior distribution are used to define the loss
    function. This method outperforms the Demons technique Lorenzi et al. ([2013](#bib.bib69))
    and the deep learning method described in Balakrishnan et al. ([2018a](#bib.bib8)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.2 Multimodal Registration
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Unlike all of the other methods described in this section, Kori et al. perform
    feature extraction and affine transformation parameter regression for the multimodal
    registration of 2-D T1 and T2 weighted brain MRs in an unsupervised capacity using
    pre-trained networks Kori et al. ([2018](#bib.bib54)). The images are binarized
    and then the Dice score between the moving and the fixed images is used as the
    cost function. As the appearance difference between these two modalities is not
    significant, the use of these pre-trained models can be reasonably effective.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: 4.2.3 Discussion and Assessment
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Performing multimodal image registration in an unsupervised capacity is significantly
    more difficult than performing unimodal image registration because of the difficulty
    associated with using manually crafted similarity metrics to quantify the similarity
    between the two images, and generally using the unsupervised techniques described
    above to establish/detect voxel-to-voxel correspondence. The use of unsupervised
    learning to learn feature representations to determine an optimal transformation
    has generated significant interest from the research community recently. Along
    with the previously discussed unsupervised image registration method, we expect
    feature based unsupervised registration to continue to generate significant interest
    from the research community. Further, extension to the multimodal case (especially
    for applications that use image with significant appearance differences) is likely
    to be a prominent research focus in the next few years.
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: 5 Research Trends and Future Directions
  id: totrans-139
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we summarize the current research trends and future directions
    of deep learning in medical image registration. As we can see from Fig. [2](#S1.F2
    "Figure 2 ‣ 1 INTRODUCTION ‣ Deep Learning in Medical Image Registration: A Survey"),
    some research trends have emerged. First, deep learning based medical image registration
    seems to be following the observed trend for the general application of deep learning
    to medical image analysis. Second, unsupervised transformation estimation methods
    have been garnering more attention recently from the research community. Further,
    deep learning based methods consistently outperform traditional optimization based
    techniques Nazib et al. ([2018](#bib.bib80)). Based on the observed research trends,
    we speculate that the following research directions will receive more attention
    in the research community.'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: 5.1 Deep Adversarial Image Registration
  id: totrans-141
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We further speculate that GANs will be used more frequently in deep learning
    based image registration in the next few years. As described above, GANs can serve
    several different purposes in deep learning based medical image registration:
    using a discriminator as a learned similarity metric, ensuring that predicted
    transformations are realistic, and using a GAN to perform image translation to
    transform a multimodal registration problem into a unimodal registration problem.'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: GAN-like frameworks have been used in several works to directly train transformation
    predicting neural networks. Several recent works Fan et al. ([2018a](#bib.bib30));
    Yan et al. ([2018](#bib.bib111)) use a discriminator to discern between aligned
    and misaligned image pairs. Although the training paradigm borrows from an unsupervised
    training strategy, the discriminator requires pre-aligned image pairs. Therefore,
    it will have limited success in multimodal or challenging unimodal applications
    where it is difficult to register images. Because discriminators are trained to
    assign all misaligned image pairs the same label, they will likely be unable to
    model a spectrum of misalignments. Despite this limitation, the application of
    GANs to medical image registration are still quite promising and will be described
    below.
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: Unconstrained deformation field prediction can result in warped moving images
    with unrealistic organ appearances. A common approach is to add the L2 norm of
    the predicted deformation field, its gradient, or its Laplacian to the loss function.
    However, the use of such regularization terms may limit the magnitude of the deformations
    that neural networks are able to predict. Therefore, Hu et al. Hu et al. ([2018a](#bib.bib42))
    explored the use of a GAN-like framework to produce realistic deformations. Constraining
    the deformation prediction using a discriminator results in superior performance
    relative to the use of L2 norm regularization in that work.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: Lastly, GANs can be used to map medical images in a source domain (*e.g.* MR)
    to a target domain (*e.g.* CT) Choi et al. ([2018](#bib.bib19)); Isola et al.
    ([2017](#bib.bib46)); Liu et al. ([2017](#bib.bib66)); Yi et al. ([2017](#bib.bib116)),
    regardless of whether or not paired training data is available Zhu et al. ([2017](#bib.bib121)).
    This image appearance reduction technique would be advantageous because many unimodal
    unsupervised registration methods use similarity metrics that often fail in the
    multimodal case. If image translation is performed as a pre-processing step, then
    commonly used similarity metrics could be used to define the loss function of
    transformation predicting networks.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: 5.2 Reinforcement Learning based Registration
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We also project that reinforcement learning will also be more commonly used
    for medical image registration in the next few years because it is very intuitive
    and can mimic the manner in which physicians perform registration. It should be
    noted that there are some unique challenges associated with deep learning based
    medical image registration: including the dimensionality of the action space in
    the deformable registration case. However, we believe that such limitations are
    surmountable because there is already one proposed method that uses reinforcement
    learning based registration with a deformable transformation model Krebs et al.
    ([2017](#bib.bib55)).'
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: 5.3 Raw Imaging Domain Registration
  id: totrans-148
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This article has focused on surveying methods performing registration using
    reconstructed images. However, we speculate that it is possible to incorporate
    reconstruction into an end-to-end deep learning based registration pipeline. In
    2016, Wang Wang ([2016](#bib.bib107)) postulated that deep neural networks could
    be used to perform image reconstruction. Further, several works Rivenson et al.
    ([2018](#bib.bib85)); Smith et al. ([2019](#bib.bib98)); Yao et al. ([2018](#bib.bib115));
    Zhu et al. ([2018](#bib.bib120)) recently demonstrated the ability of deep learning
    to map data points in the raw data domain to the reconstructed image domain. Therefore,
    it is reasonable to expect that registration pipelines that take raw data as input
    and output registered, reconstructed images can be developed within the next few
    years.
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: 6 Conclusion
  id: totrans-150
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this article, the recent works that use deep learning to perform medical
    image registration have been examined. As each application has its own unique
    challenges, the creation of the deep learning based frameworks must be carefully
    designed. Many deep learning based medical image registration applications share
    similar challenges including the lack of a robust similarity metric for multimodal
    applications, in which there are significant image appearance differences and/or
    different fields of view (*e.g.* MR-TRUS registration) Haskins et al. ([2019](#bib.bib36)),
    the lack of availability of large datasets, the challenge associated with obtaining
    segmentations and ground truth registrations, and quantifying the uncertainty
    of a model’s prediction. Application-specific similarity metrics, patch-wise frameworks,
    unsupervised approaches, and variational autoencoder inspired registration frameworks
    are examples of popular solutions to these challenges. Furthermore, despite the
    sophistication of many of the methods discussed in this survey, resampling and
    interpolation are often not among the components of registration that are learned
    by the neural network. While researchers started to pay attention to this aspect
    Ali and Rittscher ([2019](#bib.bib2)), we expect more works to incorporate these
    components into their deep learning based methods as the field continues to mature.
    Recent successes have demonstrated the impact of the application of deep learning
    to medical image registration. This trend can be observed across medical imaging
    applications. Many future exciting works are sure to build on the recent progress
    that has been outlined in this paper.
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-152
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Abadi et al. (2016) Abadi, M., Barham, P., Chen, J., Chen, Z., Davis, A., Dean,
    J., Devin, M., Ghemawat, S., Irving, G., Isard, M., et al. (2016). Tensorflow:
    a system for large-scale machine learning. In OSDI, volume 16, pages 265–283.'
  id: totrans-153
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ali and Rittscher (2019) Ali, S. and Rittscher, J. (2019). Conv2warp: An unsupervised
    deformable image registration with continuous convolution and warping.'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Alom et al. (2018) Alom, M. Z., Taha, T. M., Yakopcic, C., Westberg, S., Hasan,
    M., Van Esesn, B. C., Awwal, A. A. S., and Asari, V. K. (2018). The history began
    from alexnet: A comprehensive survey on deep learning approaches. arXiv preprint
    arXiv:1803.01164.'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ambinder (2005) Ambinder, E. P. (2005). A history of the shift toward full computerization
    of medicine. Journal of oncology practice, 1(2):54–56.
  id: totrans-156
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arganda-Carreras et al. (2006) Arganda-Carreras, I., Sorzano, C. O., Marabini,
    R., Carazo, J. M., Ortiz-de Solorzano, C., and Kybic, J. (2006). Consistent and
    elastic registration of histological sections using vector-spline regularization.
    In International Workshop on Computer Vision Approaches to Medical Image Analysis,
    pages 85–95\. Springer.
  id: totrans-157
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Avants et al. (2008) Avants, B. B., Epstein, C. L., Grossman, M., and Gee,
    J. C. (2008). Symmetric diffeomorphic image registration with cross-correlation:
    evaluating automated labeling of elderly and neurodegenerative brain. Medical
    image analysis, 12(1):26–41.'
  id: totrans-158
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Avants et al. (2011) Avants, B. B., Tustison, N. J., Song, G., Cook, P. A.,
    Klein, A., and Gee, J. C. (2011). A reproducible evaluation of ants similarity
    metric performance in brain image registration. Neuroimage, 54(3):2033–2044.
  id: totrans-159
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Balakrishnan et al. (2018a) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag,
    J., and Dalca, A. V. (2018a). An unsupervised learning model for deformable medical
    image registration. In Proceedings of the IEEE Conference on Computer Vision and
    Pattern Recognition, pages 9252–9260.
  id: totrans-160
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Balakrishnan et al. (2018b) Balakrishnan, G., Zhao, A., Sabuncu, M. R., Guttag,
    J., and Dalca, A. V. (2018b). Voxelmorph: A learning framework for deformable
    medical image registration. arXiv preprint arXiv:1809.05231.'
  id: totrans-161
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Blendowski and Heinrich (2018) Blendowski, M. and Heinrich, M. P. (2018). Combining
    mrf-based deformable registration and deep binary 3d-cnn descriptors for large
    lung motion estimation in copd patients. International journal of computer assisted
    radiology and surgery, pages 1–10.
  id: totrans-162
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao et al. (2015) Cao, T., Singh, N., Jojic, V., and Niethammer, M. (2015).
    Semi-coupled dictionary learning for deformation prediction. In Biomedical Imaging
    (ISBI), 2015 IEEE 12th International Symposium on, pages 691–694\. IEEE.
  id: totrans-163
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao et al. (2018) Cao, X., Yang, J., Wang, L., Xue, Z., Wang, Q., and Shen,
    D. (2018). Deep learning based inter-modality image registration supervised by
    intra-modality similarity. arXiv preprint arXiv:1804.10735.
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cao et al. (2017) Cao, X., Yang, J., Zhang, J., Nie, D., Kim, M., Wang, Q.,
    and Shen, D. (2017). Deformable image registration based on similarity-steered
    cnn regression. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 300–308\. Springer.
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chan et al. (2015) Chan, T.-H., Jia, K., Gao, S., Lu, J., Zeng, Z., and Ma,
    Y. (2015). Pcanet: A simple deep learning baseline for image classification? IEEE
    Transactions on Image Processing, 24(12):5017–5032.'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chee and Wu (2018) Chee, E. and Wu, J. (2018). Airnet: Self-supervised affine
    registration for 3d medical images using neural networks. arXiv preprint arXiv:1810.02583.'
  id: totrans-167
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chen et al. (2015) Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao,
    T., Xu, B., Zhang, C., and Zhang, Z. (2015). Mxnet: A flexible and efficient machine
    learning library for heterogeneous distributed systems. arXiv preprint arXiv:1512.01274.'
  id: totrans-168
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cheng et al. (2016) Cheng, X., Zhang, L., and Zheng, Y. (2016). Deep similarity
    learning for multimodal medical images. In International conference on medical
    image computing and computer-assisted intervention.
  id: totrans-169
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cheng et al. (2018) Cheng, X., Zhang, L., and Zheng, Y. (2018). Deep similarity
    learning for multimodal medical images. Computer Methods in Biomechanics and Biomedical
    Engineering: Imaging & Visualization, 6(3):248–252.'
  id: totrans-170
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Choi et al. (2018) Choi, Y., Choi, M., Kim, M., Ha, J.-W., Kim, S., and Choo,
    J. (2018). Stargan: Unified generative adversarial networks for multi-domain image-to-image
    translation. In Proceedings of the IEEE Conference on Computer Vision and Pattern
    Recognition, pages 8789–8797.'
  id: totrans-171
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chollet et al. (2015) Chollet, F. et al. (2015). Keras.
  id: totrans-172
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dalca et al. (2018) Dalca, A. V., Balakrishnan, G., Guttag, J., and Sabuncu,
    M. R. (2018). Unsupervised learning for fast probabilistic diffeomorphic registration.
    arXiv preprint arXiv:1805.04605.
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'De Silva et al. (2016) De Silva, T., Uneri, A., Ketcha, M., Reaungamornrat,
    S., Kleinszig, G., Vogt, S., Aygun, N., Lo, S., Wolinsky, J., and Siewerdsen,
    J. (2016). 3d–2d image registration for target localization in spine surgery:
    investigation of similarity metrics providing robustness to content mismatch.
    Physics in Medicine & Biology, 61(8):3009.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Vos et al. (2018) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Sokooti,
    H., Staring, M., and Išgum, I. (2018). A deep learning framework for unsupervised
    affine and deformable image registration. Medical Image Analysis.
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Vos et al. (2017) de Vos, B. D., Berendsen, F. F., Viergever, M. A., Staring,
    M., and Išgum, I. (2017). End-to-end unsupervised deformable image registration
    with a convolutional neural network. In Deep Learning in Medical Image Analysis
    and Multimodal Learning for Clinical Decision Support, pages 204–212\. Springer.
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Doersch (2016) Doersch, C. (2016). Tutorial on variational autoencoders. arXiv
    preprint arXiv:1606.05908.
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Dosovitskiy et al. (2015) Dosovitskiy, A., Fischer, P., Ilg, E., Hausser, P.,
    Hazirbas, C., Golkov, V., Van Der Smagt, P., Cremers, D., and Brox, T. (2015).
    Flownet: Learning optical flow with convolutional networks. In Proceedings of
    the IEEE International Conference on Computer Vision, pages 2758–2766.'
  id: totrans-178
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ehrhardt et al. (2015) Ehrhardt, J., Schmidt-Richberg, A., Werner, R., and Handels,
    H. (2015). Variational registration. In Bildverarbeitung für die Medizin 2015,
    pages 209–214. Springer.
  id: totrans-179
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eppenhof and Pluim (2018a) Eppenhof, K. A. and Pluim, J. P. (2018a). Pulmonary
    ct registration through supervised learning with convolutional neural networks.
    IEEE transactions on medical imaging.
  id: totrans-180
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eppenhof and Pluim (2018b) Eppenhof, K. A. J. and Pluim, J. P. (2018b). Error
    estimation of deformable image registration of pulmonary ct scans using convolutional
    neural networks. Journal of Medical Imaging, 5(2):024003.
  id: totrans-181
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Fan et al. (2018a) Fan, J., Cao, X., Xue, Z., Yap, P.-T., and Shen, D. (2018a).
    Adversarial similarity network for evaluating image alignment in deep learning
    based registration. In International Conference on Medical Image Computing and
    Computer-Assisted Intervention, pages 739–746\. Springer.
  id: totrans-182
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fan et al. (2018b) Fan, J., Cao, X., Yap, P.-T., and Shen, D. (2018b). Birnet:
    Brain image registration using dual-supervised fully convolutional networks. arXiv
    preprint arXiv:1802.04692.'
  id: totrans-183
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ferrante et al. (2018) Ferrante, E., Oktay, O., Glocker, B., and Milone, D. H.
    (2018). On the adaptability of unsupervised cnn-based deformable image registration
    to unseen image domains. In International Workshop on Machine Learning in Medical
    Imaging, pages 294–302\. Springer.
  id: totrans-184
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ghosal and Ray (2017) Ghosal, S. and Ray, N. (2017). Deep deformable registration:
    Enhancing accuracy by fully convolutional neural net. Pattern Recognition Letters,
    94:81–86.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2016) Goodfellow, I., Bengio, Y., Courville, A., and Bengio,
    Y. (2016). Deep learning, volume 1. MIT press Cambridge.
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Goodfellow et al. (2014) Goodfellow, I., Pouget-Abadie, J., Mirza, M., Xu, B.,
    Warde-Farley, D., Ozair, S., Courville, A., and Bengio, Y. (2014). Generative
    adversarial nets. In Advances in neural information processing systems, pages
    2672–2680.
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Haskins et al. (2019) Haskins, G., Kruecker, J., Kruger, U., Xu, S., Pinto,
    P. A., Wood, B. J., and Yan, P. (2019). Learning deep similarity metric for 3d
    mr-trus image registration. International Journal of Computer Assisted Radiology
    and Surgery, 14:417–425.
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: He et al. (2016) He, K., Zhang, X., Ren, S., and Sun, J. (2016). Deep residual
    learning for image recognition. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 770–778.
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Heinrich et al. (2012) Heinrich, M. P., Jenkinson, M., Bhushan, M., Matin,
    T., Gleeson, F. V., Brady, M., and Schnabel, J. A. (2012). Mind: Modality independent
    neighbourhood descriptor for multi-modal deformable registration. Medical image
    analysis, 16(7):1423–1435.'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Heinrich et al. (2013) Heinrich, M. P., Jenkinson, M., Papież, B. W., Brady,
    M., and Schnabel, J. A. (2013). Towards realtime multimodal fusion for image-guided
    interventions using self-similarities. In International conference on medical
    image computing and computer-assisted intervention, pages 187–194\. Springer.
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hering et al. (2018) Hering, A., Kuckertz, S., Heldmann, S., and Heinrich, M.
    (2018). Enhancing label-driven deep deformable image registration with local distance
    metrics for state-of-the-art cardiac motion tracking. arXiv preprint arXiv:1812.01859.
  id: totrans-192
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hill et al. (2001) Hill, D. L., Batchelor, P. G., Holden, M., and Hawkes, D. J.
    (2001). Medical image registration. Physics in medicine and biology, 46(3):R1–R45.
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2018a) Hu, Y., Gibson, E., Ghavami, N., Bonmati, E., Moore, C. M.,
    Emberton, M., Vercauteren, T., Noble, J. A., and Barratt, D. C. (2018a). Adversarial
    deformation regularization for training image registration neural networks. arXiv
    preprint arXiv:1805.10665.
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2018b) Hu, Y., Modat, M., Gibson, E., Ghavami, N., Bonmati, E., Moore,
    C. M., Emberton, M., Noble, J. A., Barratt, D. C., and Vercauteren, T. (2018b).
    Label-driven weakly-supervised learning for multimodal deformarle image registration.
    In Biomedical Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on,
    pages 1070–1074\. IEEE.
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hu et al. (2018c) Hu, Y., Modat, M., Gibson, E., Li, W., Ghavami, N., Bonmati,
    E., Wang, G., Bandula, S., Moore, C. M., Emberton, M., et al. (2018c). Weakly-supervised
    convolutional neural networks for multimodal image registration. Medical image
    analysis, 49:1–13.
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ikeda et al. (2014) Ikeda, K., Ino, F., and Hagihara, K. (2014). Efficient acceleration
    of mutual information computation for nonrigid registration using cuda. IEEE J.
    Biomedical and Health Informatics, 18(3):956–968.
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Isola et al. (2017) Isola, P., Zhu, J.-Y., Zhou, T., and Efros, A. A. (2017).
    Image-to-image translation with conditional adversarial networks. arXiv preprint.
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ito and Ino (2018) Ito, M. and Ino, F. (2018). An automated method for generating
    training sets for deep learning based image registration. In The 11th International
    Joint Conference on Biomedical Engineering Systems and Technologies - Volume 2:
    BIOIMAGING, pages 140–147. INSTICC, SciTePress.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jaderberg et al. (2015) Jaderberg, M., Simonyan, K., Zisserman, A., et al. (2015).
    Spatial transformer networks. In Advances in neural information processing systems,
    pages 2017–2025.
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Jia et al. (2014) Jia, Y., Shelhamer, E., Donahue, J., Karayev, S., Long, J.,
    Girshick, R., Guadarrama, S., and Darrell, T. (2014). Caffe: Convolutional architecture
    for fast feature embedding. In Proceedings of the 22nd ACM international conference
    on Multimedia, pages 675–678\. ACM.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Jiang and Shackleford (2018) Jiang, P. and Shackleford, J. A. (2018). Cnn driven
    sparse multi-level b-spline image registration. In Proceedings of the IEEE Conference
    on Computer Vision and Pattern Recognition, pages 9281–9289.
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kaelbling et al. (1996) Kaelbling, L. P., Littman, M. L., and Moore, A. W.
    (1996). Reinforcement learning: A survey. Journal of artificial intelligence research,
    4:237–285.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kazeminia et al. (2018) Kazeminia, S., Baur, C., Kuijper, A., van Ginneken,
    B., Navab, N., Albarqouni, S., and Mukhopadhyay, A. (2018). Gans for medical image
    analysis. arXiv preprint arXiv:1809.06222.
  id: totrans-204
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Klein et al. (2010) Klein, S., Staring, M., Murphy, K., Viergever, M. A., and
    Pluim, J. P. (2010). Elastix: a toolbox for intensity-based medical image registration.
    IEEE transactions on medical imaging, 29(1):196–205.'
  id: totrans-205
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kori et al. (2018) Kori, A., Kumari, K., and Krishnamurthi, G. (2018). Zero
    shot learning for multi-modal real time image registration.
  id: totrans-206
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krebs et al. (2017) Krebs, J., Mansi, T., Delingette, H., Zhang, L., Ghesu,
    F. C., Miao, S., Maier, A. K., Ayache, N., Liao, R., and Kamen, A. (2017). Robust
    non-rigid registration through agent-based action learning. In International Conference
    on Medical Image Computing and Computer-Assisted Intervention, pages 344–352\.
    Springer.
  id: totrans-207
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krebs et al. (2018a) Krebs, J., Mansi, T., Mailhé, B., Ayache, N., and Delingette,
    H. (2018a). Learning structured deformations using diffeomorphic registration.
    arXiv preprint arXiv:1804.07172.
  id: totrans-208
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Krebs et al. (2018b) Krebs, J., Mansi, T., Mailhé, B., Ayache, N., and Delingette,
    H. (2018b). Unsupervised probabilistic deformation modeling for robust diffeomorphic
    registration. In Deep Learning in Medical Image Analysis and Multimodal Learning
    for Clinical Decision Support, pages 101–109\. Springer.
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuang and Schmah (2018) Kuang, D. and Schmah, T. (2018). Faim–a convnet method
    for unsupervised 3d medical image registration. arXiv preprint arXiv:1811.09243.
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lee et al. (2017) Lee, J.-G., Jun, S., Cho, Y.-W., Lee, H., Kim, G. B., Seo,
    J. B., and Kim, N. (2017). Deep learning in medical imaging: general overview.
    Korean journal of radiology, 18(4):570–584.'
  id: totrans-211
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Fan (2017) Li, H. and Fan, Y. (2017). Non-rigid image registration using
    fully convolutional networks with deep self-supervision. arXiv preprint arXiv:1709.00799.
  id: totrans-212
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li and Fan (2018) Li, H. and Fan, Y. (2018). Non-rigid image registration using
    self-supervised fully convolutional networks without training data. In Biomedical
    Imaging (ISBI 2018), 2018 IEEE 15th International Symposium on, pages 1075–1078\.
    IEEE.
  id: totrans-213
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liao et al. (2017) Liao, R., Miao, S., de Tournemire, P., Grbic, S., Kamen,
    A., Mansi, T., and Comaniciu, D. (2017). An artificial agent for robust image
    registration. In AAAI, pages 4168–4175.
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Litjens et al. (2017) Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A.,
    Ciompi, F., Ghafoorian, M., van der Laak, J. A., Van Ginneken, B., and Sánchez,
    C. I. (2017). A survey on deep learning in medical image analysis. Medical image
    analysis, 42:60–88.
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2011) Liu, C., Yuen, J., and Torralba, A. (2011). Sift flow: Dense
    correspondence across scenes and its applications. IEEE transactions on pattern
    analysis and machine intelligence, 33(5):978–994.'
  id: totrans-216
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Liu et al. (2018) Liu, J., Pan, Y., Li, M., Chen, Z., Tang, L., Lu, C., and
    Wang, J. (2018). Applications of deep learning to mri images: a survey. Big Data
    Mining and Analytics, 1(1):1–18.'
  id: totrans-217
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu et al. (2017) Liu, M.-Y., Breuel, T., and Kautz, J. (2017). Unsupervised
    image-to-image translation networks. In Advances in Neural Information Processing
    Systems, pages 700–708.
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liu and Leung (2017) Liu, Q. and Leung, H. (2017). Tensor-based descriptor for
    image registration via unsupervised network. In Information Fusion (Fusion), 2017
    20th International Conference on, pages 1–7\. IEEE.
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Long et al. (2015) Long, J., Shelhamer, E., and Darrell, T. (2015). Fully convolutional
    networks for semantic segmentation. In Proceedings of the IEEE conference on computer
    vision and pattern recognition, pages 3431–3440.
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lorenzi et al. (2013) Lorenzi, M., Ayache, N., Frisoni, G. B., Pennec, X.,
    (ADNI, A. D. N. I., et al. (2013). Lcc-demons: a robust and accurate symmetric
    diffeomorphic registration algorithm. NeuroImage, 81:470–483.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lv et al. (2018) Lv, J., Yang, M., Zhang, J., and Wang, X. (2018). Respiratory
    motion correction for free-breathing 3d abdominal mri using cnn-based image registration:
    a feasibility study. The British journal of radiology, 91(xxxx):20170788.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Ma et al. (2017) Ma, K., Wang, J., Singh, V., Tamersoy, B., Chang, Y.-J., Wimmer,
    A., and Chen, T. (2017). Multimodal image registration with deep context reinforcement
    learning. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 240–248\. Springer.
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Maes et al. (1997) Maes, F., Collignon, A., Vandermeulen, D., Marchal, G., and
    Suetens, P. (1997). Multimodality image registration by maximization of mutual
    information. IEEE transactions on Medical Imaging, 16(2):187–198.
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahapatra (2018) Mahapatra, D. (2018). Elastic registration of medical images
    with gans. arXiv preprint arXiv:1805.02369.
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mahapatra et al. (2018) Mahapatra, D., Ge, Z., Sedai, S., and Chakravorty, R.
    (2018). Joint registration and segmentation of xray images using generative adversarial
    networks. In International Workshop on Machine Learning in Medical Imaging, pages
    73–80\. Springer.
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Matthew et al. (2018) Matthew, J., Hajnal, J. V., Rueckert, D., and Schnabel,
    J. A. (2018). Lstm spatial co-transformer networks for registration of 3d fetal
    us and mr brain images. In Data Driven Treatment Response Assessment and Preterm,
    Perinatal, and Paediatric Image Analysis, pages 149–159\. Springer.
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miao et al. (2017) Miao, S., Piat, S., Fischer, P., Tuysuzoglu, A., Mewes, P.,
    Mansi, T., and Liao, R. (2017). Dilated fcn for multi-agent 2d/3d medical image
    registration. arXiv preprint arXiv:1712.01651.
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miao et al. (2016a) Miao, S., Wang, Z. J., and Liao, R. (2016a). A cnn regression
    approach for real-time 2d/3d registration. IEEE transactions on medical imaging,
    35(5):1352–1363.
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Miao et al. (2016b) Miao, S., Wang, Z. J., Zheng, Y., and Liao, R. (2016b).
    Real-time 2d/3d registration via cnn regression. In Biomedical Imaging (ISBI),
    2016 IEEE 13th International Symposium on, pages 1430–1434\. IEEE.
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Myronenko and Song (2010) Myronenko, A. and Song, X. (2010). Intensity-based
    image registration by minimizing residual complexity. IEEE transactions on medical
    imaging, 29(11):1882–1891.
  id: totrans-231
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nazib et al. (2018) Nazib, A., Fookes, C., and Perrin, D. (2018). A comparative
    analysis of registration tools: Traditional vs deep learning approach on high
    resolution tissue cleared data. arXiv preprint arXiv:1810.08315.'
  id: totrans-232
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Neylon et al. (2017) Neylon, J., Min, Y., Low, D. A., and Santhanam, A. (2017).
    A neural network approach for fast, automated quantification of dir performance.
    Medical physics, 44(8):4126–4138.
  id: totrans-233
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Paszke et al. (2017) Paszke, A., Gross, S., Chintala, S., Chanan, G., Yang,
    E., DeVito, Z., Lin, Z., Desmaison, A., Antiga, L., and Lerer, A. (2017). Automatic
    differentiation in pytorch. In NIPS-W.
  id: totrans-234
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Punithakumar et al. (2017) Punithakumar, K., Boulanger, P., and Noga, M. (2017).
    A gpu-accelerated deformable image registration algorithm with applications to
    right ventricular segmentation. IEEE Access, 5:20374–20382.
  id: totrans-235
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ren et al. (2015) Ren, S., He, K., Girshick, R., and Sun, J. (2015). Faster
    r-cnn: Towards real-time object detection with region proposal networks. In Advances
    in neural information processing systems, pages 91–99.'
  id: totrans-236
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rivenson et al. (2018) Rivenson, Y., Zhang, Y., Günaydın, H., Teng, D., and
    Ozcan, A. (2018). Phase recovery and holographic image reconstruction using deep
    learning in neural networks. Light: Science & Applications, 7(2):17141.'
  id: totrans-237
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rohé et al. (2017) Rohé, M.-M., Datar, M., Heimann, T., Sermesant, M., and
    Pennec, X. (2017). Svf-net: Learning deformable image registration using shape
    matching. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 266–274\. Springer.'
  id: totrans-238
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Ronneberger et al. (2015) Ronneberger, O., Fischer, P., and Brox, T. (2015).
    U-net: Convolutional networks for biomedical image segmentation. In International
    Conference on Medical image computing and computer-assisted intervention, pages
    234–241\. Springer.'
  id: totrans-239
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rühaak et al. (2013) Rühaak, J., Heldmann, S., Kipshagen, T., and Fischer,
    B. (2013). Highly accurate fast lung ct registration. In Medical Imaging 2013:
    Image Processing, volume 8669, page 86690Y. International Society for Optics and
    Photonics.'
  id: totrans-240
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Saalfeld et al. (2012) Saalfeld, S., Fetter, R., Cardona, A., and Tomancak,
    P. (2012). Elastic volume reconstruction from series of ultra-thin microscopy
    sections. Nature methods, 9(7):717.
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Salehi et al. (2018) Salehi, S. S. M., Khan, S., Erdogmus, D., and Gholipour,
    A. (2018). Real-time deep registration with geodesic loss. arXiv preprint arXiv:1803.05982.
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Schmidhuber (2015) Schmidhuber, J. (2015). Deep learning in neural networks:
    An overview. Neural networks, 61:85–117.'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sedghi et al. (2018) Sedghi, A., Luo, J., Mehrtash, A., Pieper, S., Tempany,
    C. M., Kapur, T., Mousavi, P., and Wells III, W. M. (2018). Semi-supervised deep
    metrics for image registration. arXiv preprint arXiv:1804.01565.
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sheikhjafari et al. (2018) Sheikhjafari, A., Noga, M., Punithakumar, K., and
    Ray, N. (2018). Unsupervised deformable image registration with fully connected
    generative neural network. In International conference on Medical Imaging with
    Deep Learning.
  id: totrans-245
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Shen (2007) Shen, D. (2007). Image registration by local histogram matching.
    Pattern Recognition, 40(4):1161–1172.
  id: totrans-246
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shu et al. (2018) Shu, C., Chen, X., Xie, Q., and Han, H. (2018). An unsupervised
    network for fast microscopic image registration. In Medical Imaging 2018: Digital
    Pathology, volume 10581, page 105811D. International Society for Optics and Photonics.'
  id: totrans-247
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Simonovsky et al. (2016) Simonovsky, M., Gutiérrez-Becker, B., Mateus, D., Navab,
    N., and Komodakis, N. (2016). A deep metric for multimodal registration. In International
    Conference on Medical Image Computing and Computer-Assisted Intervention, pages
    10–18\. Springer.
  id: totrans-248
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sloan et al. (2018) Sloan, J. M., Goatman, K. A., and Siebert, J. P. (2018).
    Learning rigid image registration - utilizing convolutional neural networks for
    medical image registration. In 11th International Joint Conference on Biomedical
    Engineering Systems and Technologies, pages 89–99\. SCITEPRESS-Science and Technology
    Publications.
  id: totrans-249
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Smith et al. (2019) Smith, J. T., Yao, R., Sinsuebphon, N., Rudkouskaya, A.,
    Un, N., Mazurkiewicz, J., Barroso, M., Yan, P., and Intes, X. (2019). Fast fit-free
    analysis of fluorescence lifetime imaging via deep learning. Proceedings of the
    National Academy of Sciences, 116(48):24019–24030.
  id: totrans-250
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sokooti et al. (2017) Sokooti, H., de Vos, B., Berendsen, F., Lelieveldt, B. P.,
    Išgum, I., and Staring, M. (2017). Nonrigid image registration using multi-scale
    3d convolutional neural networks. In International Conference on Medical Image
    Computing and Computer-Assisted Intervention, pages 232–239\. Springer.
  id: totrans-251
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Stergios et al. (2018) Stergios, C., Mihir, S., Maria, V., Guillaume, C., Marie-Pierre,
    R., Stavroula, M., and Nikos, P. (2018). Linear and deformable image registration
    with 3d convolutional neural networks. In Image Analysis for Moving Organ, Breast,
    and Thoracic Images, pages 13–22\. Springer.
  id: totrans-252
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun and Zhang (2018) Sun, L. and Zhang, S. (2018). Deformable mri-ultrasound
    registration using 3d convolutional neural network. In Simulation, Image Processing,
    and Ultrasound Systems for Assisted Diagnosis and Navigation, pages 152–158\.
    Springer.
  id: totrans-253
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sun et al. (2018) Sun, Y., Moelker, A., Niessen, W. J., and van Walsum, T. (2018).
    Towards robust ct-ultrasound registration using deep learning methods. In Understanding
    and Interpreting Machine Learning in Medical Image Computing Applications, pages
    43–51\. Springer.
  id: totrans-254
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Uzunova et al. (2017) Uzunova, H., Wilms, M., Handels, H., and Ehrhardt, J.
    (2017). Training cnns for image registration from few samples with model-based
    data augmentation. In International Conference on Medical Image Computing and
    Computer-Assisted Intervention, pages 223–231\. Springer.
  id: totrans-255
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Vercauteren et al. (2009) Vercauteren, T., Pennec, X., Perchant, A., and Ayache,
    N. (2009). Diffeomorphic demons: Efficient non-parametric image registration.
    NeuroImage, 45(1):S61–S72.'
  id: totrans-256
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vialard et al. (2012) Vialard, F.-X., Risser, L., Rueckert, D., and Cotter,
    C. J. (2012). Diffeomorphic 3d image registration via geodesic shooting using
    an efficient adjoint calculation. International Journal of Computer Vision, 97(2):229–241.
  id: totrans-257
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Viola and Wells III (1997) Viola, P. and Wells III, W. M. (1997). Alignment
    by maximization of mutual information. International journal of computer vision,
    24(2):137–154.
  id: totrans-258
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang (2016) Wang, G. (2016). A perspective on deep imaging. arXiv preprint arXiv:1609.04375.
  id: totrans-259
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wang et al. (2015) Wang, Z., Schaul, T., Hessel, M., Van Hasselt, H., Lanctot,
    M., and De Freitas, N. (2015). Dueling network architectures for deep reinforcement
    learning. arXiv preprint arXiv:1511.06581.
  id: totrans-260
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2013) Wu, G., Kim, M., Wang, Q., Gao, Y., Liao, S., and Shen, D.
    (2013). Unsupervised deep feature learning for deformable registration of mr brain
    images. In International Conference on Medical Image Computing and Computer-Assisted
    Intervention, pages 649–656\. Springer.
  id: totrans-261
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wu et al. (2016) Wu, G., Kim, M., Wang, Q., Munsell, B. C., and Shen, D. (2016).
    Scalable high-performance image registration framework by unsupervised deep feature
    representations learning. IEEE Transactions on Biomedical Engineering, 63(7):1505–1516.
  id: totrans-262
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yan et al. (2018) Yan, P., Xu, S., Rastinehad, A. R., and Wood, B. J. (2018).
    Adversarial image registration with application for mr and trus image fusion.
    arXiv preprint arXiv:1804.11024.
  id: totrans-263
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2018) Yang, Q., Yan, P., Zhang, Y., Yu, H., Shi, Y., Mou, X., Kalra,
    M. K., Zhang, Y., Sun, L., and Wang, G. (2018). Low dose ct image denoising using
    a generative adversarial network with wasserstein distance and perceptual loss.
    IEEE transactions on medical imaging.
  id: totrans-264
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang (2017) Yang, X. (2017). Uncertainty Quantification, Image Synthesis and
    Deformation Prediction for Image Registration. PhD thesis, The University of North
    Carolina at Chapel Hill.
  id: totrans-265
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yang et al. (2016) Yang, X., Kwitt, R., and Niethammer, M. (2016). Fast predictive
    image registration. In Deep Learning and Data Labeling for Medical Applications,
    pages 48–57\. Springer.
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Yao et al. (2018) Yao, R., Ochoa, M., Intes, X., and Yan, P. (2018). Deep compressive
    macroscopic fluorescence lifetime imaging. In Biomedical Imaging (ISBI 2018),
    2018 IEEE 15th International Symposium on, pages 908–911\. IEEE.
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yi et al. (2017) Yi, Z., Zhang, H., Tan, P., and Gong, M. (2017). Dualgan:
    Unsupervised dual learning for image-to-image translation. arXiv preprint.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Yoo et al. (2017) Yoo, I., Hildebrand, D. G., Tobin, W. F., Lee, W.-C. A.,
    and Jeong, W.-K. (2017). ssemnet: Serial-section electron microscopy image registration
    using a spatial transformer network with learned features. In Deep Learning in
    Medical Image Analysis and Multimodal Learning for Clinical Decision Support,
    pages 249–257\. Springer.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhang (2018) Zhang, J. (2018). Inverse-consistent deep networks for unsupervised
    deformable image registration. arXiv preprint arXiv:1809.03443.
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zheng et al. (2018) Zheng, J., Miao, S., Wang, Z. J., and Liao, R. (2018). Pairwise
    domain adaptation module for cnn-based 2-d/3-d registration. Journal of Medical
    Imaging, 5(2):021204.
  id: totrans-271
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2018) Zhu, B., Liu, J. Z., Cauley, S. F., Rosen, B. R., and Rosen,
    M. S. (2018). Image reconstruction by domain-transform manifold learning. Nature,
    555(7697):487.
  id: totrans-272
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Zhu et al. (2017) Zhu, J.-Y., Park, T., Isola, P., and Efros, A. A. (2017).
    Unpaired image-to-image translation using cycle-consistent adversarial networks.
    arXiv preprint.
  id: totrans-273
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Zitova and Flusser (2003) Zitova, B. and Flusser, J. (2003). Image registration
    methods: a survey. Image and vision computing, 21(11):977–1000.'
  id: totrans-274
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
