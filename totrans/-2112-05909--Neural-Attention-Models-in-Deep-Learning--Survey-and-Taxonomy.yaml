- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 类别：未分类
- en: 'date: 2024-09-06 19:49:00'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 日期：2024-09-06 19:49:00
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2112.05909] Neural Attention Models in Deep Learning: Survey and Taxonomy'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2112.05909] 神经注意模型在深度学习中的调查与分类'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2112.05909](https://ar5iv.labs.arxiv.org/html/2112.05909)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2112.05909](https://ar5iv.labs.arxiv.org/html/2112.05909)
- en: \DeclareUnicodeCharacter
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \DeclareUnicodeCharacter
- en: 2212-
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 2212-
- en: 'Neural Attention Models in Deep Learning: Survey and Taxonomy'
  id: totrans-8
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 神经注意模型在深度学习中的调查与分类
- en: 'Alana de Santana Correia, and Esther Luna Colombini Laboratory of Robotics
    and Cogntive Systems (LaRoCS) Institute of Computing, University of Campinas,
    Av. Albert Einstein, 1251 - Campinas, SP - Brazil e-mail: {alana.correia, esther}@ic.unicamp.br.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: Alana de Santana Correia 和 Esther Luna Colombini 机器人与认知系统实验室（LaRoCS）计算机学院，坎皮纳斯大学，阿尔伯特·爱因斯坦大道1251号
    - 坎皮纳斯，SP - 巴西 电子邮件：{alana.correia, esther}@ic.unicamp.br。
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: Attention is a state of arousal capable of dealing with limited processing bottlenecks
    in human beings by focusing selectively on one piece of information while ignoring
    other perceptible information [[1](#bib.bib1)]. For decades, concepts and functions
    of attention have been studied in philosophy, psychology, neuroscience, and computing.
    Currently, this property has been widely explored in deep neural networks. Many
    different neural attention models are now available and have been a very active
    research area over the past six years. From the theoretical standpoint of attention,
    this survey provides a critical analysis of major neural attention models. Here
    we propose a taxonomy that corroborates with theoretical aspects that predate
    Deep Learning. Our taxonomy provides an organizational structure that asks new
    questions and structures the understanding of existing attentional mechanisms.
    In particular, 17 criteria derived from psychology and neuroscience classic studies
    are formulated for qualitative comparison and critical analysis on the 51 main
    models found on a set of more than 650 papers analyzed. Also, we highlight several
    theoretical issues that have not yet been explored, including discussions about
    biological plausibility, highlight current research trends, and provide insights
    for the future.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力是一种兴奋状态，能够通过选择性地关注一条信息而忽略其他感知信息来应对人类处理瓶颈[[1](#bib.bib1)]。几十年来，注意力的概念和功能在哲学、心理学、神经科学和计算领域得到了研究。目前，这一特性在深度神经网络中得到了广泛探索。许多不同的神经注意模型现在可用，并且在过去六年中一直是一个非常活跃的研究领域。从注意力的理论角度来看，本调查对主要的神经注意模型进行了关键分析。我们提出了一种与深度学习之前的理论方面相符的分类方法。我们的分类提供了一个组织结构，提出了新问题并构建了对现有注意机制的理解。特别地，我们基于心理学和神经科学经典研究提出了17个标准，用于对分析的超过650篇论文中的51个主要模型进行定性比较和关键分析。此外，我们还突出了尚未探索的几个理论问题，包括对生物学合理性的讨论，突出当前的研究趋势，并为未来提供了见解。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 索引词：
- en: Survey, Taxonomy, Attention Mechanism, Neural Networks, Deep Learning, Attention
    Models.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 调查、分类学、注意机制、神经网络、深度学习、注意模型。
- en: I Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Attention is a state of arousal capable of dealing with limited processing bottlenecks
    by focusing selectively on one piece of information while ignoring other perceptible
    information [[1](#bib.bib1)]. According to James [[2](#bib.bib2)] attention can
    be considered as an internal force that spontaneously or voluntarily creates a
    mental expectation of a sensory or motor nature, favoring the perception of stimuli
    and the production of responses. This internal force can also be understood as
    a cognitive need, given that at any moment, the environment presents more perceptual
    information than can be supported, and it is impossible to perform all motor actions
    simultaneously in response to all external stimuli. In nature, attention is an
    essential activity concerning the survival of all forms of life, resulting from
    a long process of cognitive evolution of living beings. Among the beings that
    occupy the lowest evolutionary scale positions, attention acts mainly on perception,
    selecting, and modulating relevant stimuli from the environment. This mechanism
    is decisive for the perpetuation and evolution of species, as it is characterized
    as the ability to settle in points of interest in the environment and recognize
    possible prey, predators, or rivals. In humans, attention is intrinsically present
    in the brain throughout the cognitive cycle, acting from the perception of stimuli,
    organization of complex mental processes to decision making.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 注意力是一种能够通过选择性地专注于一条信息而忽略其他可感知信息，从而处理有限处理瓶颈的唤醒状态 [[1](#bib.bib1)]。根据詹姆斯的观点 [[2](#bib.bib2)]，注意力可以被认为是一种内在力量，它自发或主动地创造对感官或运动性质的心理预期，促进刺激的感知和反应的产生。这种内在力量也可以被理解为一种认知需求，因为在任何时刻，环境提供的感知信息总是超出可处理的范围，无法对所有外部刺激同时作出反应。在自然界中，注意力是一项与所有生命形式的生存密切相关的基本活动，源自生物长期的认知进化过程。在处于最低进化等级的生物中，注意力主要作用于感知，选择和调节来自环境的相关刺激。这个机制对于物种的延续和进化至关重要，因为它被定义为在环境中集中于感兴趣的点，识别可能的猎物、捕食者或竞争对手的能力。在人类中，注意力在整个认知周期中固有地存在于大脑中，从刺激的感知、复杂心理过程的组织到决策制定。
- en: For decades, several areas of science have been concerned with understanding
    the role of attention. In psychology, studies dating back to 1890, looking for
    behavioral correlates that reflect the performance of attentional processes in
    the human brain, such as surveillance time [[3](#bib.bib3)], inattentional blindness
    [[4](#bib.bib4)], attentional blink [[5](#bib.bib5)], reaction time in cognitive
    processing [[6](#bib.bib6)], and the selective ability to filter external stimuli
    [[7](#bib.bib7)]. Cognitive neuroscience studies have employed invasive and non-invasive
    approaches, such as neuroanatomical/neurophysiological techniques, electroencephalography,
    positron emission tomography (PET), and functional magnetic resonance imaging
    (fMRI), to capture insights about attentional disorders [[8](#bib.bib8)]. Neurophysiologists
    seek to study how neurons respond to represent external stimuli of interest [[9](#bib.bib9)].
    Finally, computational neuroscientists capture all the insights from the different
    perspectives experienced and support realistic computational models to simulate
    and explain attentional behaviors, seeking to understand how, where and when attention
    processes occur or are needed [[10](#bib.bib10)].
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 几十年来，科学的多个领域一直关注注意力的作用。在心理学中，从1890年开始的研究寻找反映人脑注意力过程表现的行为相关因素，例如监视时间 [[3](#bib.bib3)]、无意识盲点
    [[4](#bib.bib4)]、注意力闪烁 [[5](#bib.bib5)]、认知处理中的反应时间 [[6](#bib.bib6)] 以及选择性过滤外部刺激的能力
    [[7](#bib.bib7)]。认知神经科学研究采用了侵入性和非侵入性的方法，如神经解剖/神经生理技术、电生理学、正电子发射断层扫描（PET）和功能性磁共振成像（fMRI），以捕捉有关注意力障碍的见解
    [[8](#bib.bib8)]。神经生理学家致力于研究神经元如何响应代表感兴趣的外部刺激 [[9](#bib.bib9)]。最后，计算神经科学家整合来自不同视角的所有见解，并支持现实的计算模型，以模拟和解释注意力行为，力求理解注意力过程发生或需要的方式、位置和时机
    [[10](#bib.bib10)]。
- en: Inspired by these studies, computer scientists in the 1990s proposed the first
    attentional mechanisms for computer systems to resolve performance limitations
    inherent in the high computational complexity of the algorithms existing at the
    time. Initially, several attentional vision models for object recognition [[11](#bib.bib11)],
    image compression [[12](#bib.bib12)], image matching [[13](#bib.bib13)], image
    segmentation [[12](#bib.bib12)], object tracking [walther2004detection], active
    vision [[14](#bib.bib14)], and recognition [[11](#bib.bib11)] emerged inspired
    by Feature Integration Theory - one of the first theories to formalize visual
    attention to perception - in which a set of simple features is extracted from
    a scene observed by the system separately, and in subsequent steps the integration
    of the stimuli occurs supporting the identification of relevant objects in the
    environment. Subsequently, visual attention emerged as a tool capable of providing
    essential information on the environment for robotic agents’ decision-making in
    the world. So, several robotic navigation systems [[15](#bib.bib15)], SLAM[[16](#bib.bib16)],
    and and human-robot interaction [[17](#bib.bib17)] integrated attention to improve
    the performance of these autonomous agents.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 受这些研究的启发，计算机科学家在1990年代提出了第一个注意力机制，用于解决当时算法固有的高计算复杂性所带来的性能限制。最初，受到特征整合理论启发的几个注意力视觉模型应运而生，这些模型用于目标识别[[11](#bib.bib11)]、图像压缩[[12](#bib.bib12)]、图像匹配[[13](#bib.bib13)]、图像分割[[12](#bib.bib12)]、目标跟踪[walther2004detection]、主动视觉[[14](#bib.bib14)]和识别[[11](#bib.bib11)]。特征整合理论是最早将视觉注意力形式化为感知的理论之一，其中从系统观察到的场景中提取一组简单的特征，然后在随后的步骤中进行刺激的整合，从而支持识别环境中的相关对象。随后，视觉注意力作为一种工具，能够为机器人代理在世界中进行决策提供环境的基本信息。因此，若干机器人导航系统[[15](#bib.bib15)]、SLAM[[16](#bib.bib16)]以及人机交互[[17](#bib.bib17)]集成了注意力机制，以提高这些自主代理的性能。
- en: Artificial intelligence scientists have noticed attention as a fundamental concept
    for improving deep neural networks’ performance in the last decade. In Deep Learning,
    Attention introduces a new form of computing inspired by the human brain quite
    different from what neural networks do today. Attentional mechanisms make networks
    more scalable, simpler, facilitate multimodality, and reduce information bottlenecks
    from long spatial and temporal dependencies. Attentional interfaces currently
    focus on two major fronts of development and research as small modules that can
    be easily plugged into classic DL architectures and end-to-end attention networks
    where attention is intrinsically present throughout the architecture. The attentional
    interfaces usually complement convolutional and recurrence operations allowing
    the control of the dynamic flow of resources and internal or external information,
    coming from specific parts of the neural structure or other external cognitive
    elements (e.g., external memories, pre-trained layers). End-to-end attention networks
    represent major advances in Deep Learning. State-of-art approaches in Natural
    Language Processing [[18](#bib.bib18)] [[19](#bib.bib19)], multimodal learning,
    and unstructured data learning via graph neural networks use end-to-end attention
    approaches [[20](#bib.bib20)][[21](#bib.bib21)]. Currently, much of the research
    aimed at DL uses attentional structures in the most diverse application domains,
    so that we have been able to map more than 6,000 works published in the area since
    2014 in the main publication repositories.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去十年里，人工智能科学家注意到注意力机制是提升深度神经网络性能的一个基本概念。在深度学习中，注意力引入了一种新型计算形式，灵感来自于人脑，与神经网络目前的操作方式大相径庭。注意力机制使得网络更加可扩展、更简洁，促进了多模态的处理，并减少了来自长时间和空间依赖的信息瓶颈。注意力接口目前主要集中在两个主要的发展和研究方向：作为可以轻松插入经典深度学习架构的小模块，以及在整个架构中固有存在注意力的端到端注意力网络。注意力接口通常补充了卷积和递归操作，允许控制资源和内部或外部信息的动态流，这些信息来自神经结构的特定部分或其他外部认知元素（例如，外部记忆、预训练层）。端到端注意力网络代表了深度学习的重大进展。在自然语言处理[[18](#bib.bib18)]
    [[19](#bib.bib19)]、多模态学习以及通过图神经网络对非结构化数据的学习中，最先进的方法都使用了端到端注意力方法[[20](#bib.bib20)][[21](#bib.bib21)]。目前，许多针对深度学习的研究使用了注意力结构，在各种应用领域都有涉及，因此我们能够在主要出版库中绘制出自2014年以来超过6000篇相关工作的地图。
- en: Despite the high extent of research in various areas of computing, psychology,
    neuroscience, and even philosophy, the historical problem is that attention is
    omnipresent in the brain, as there is no single attention center, which makes
    concepts and aspects of study quite abstract and difficult to validate. When a
    group of related concepts and ideas becomes challenging to manage, a taxonomy
    is useful. Through taxonomy, it is possible to group different aspects and systematically
    study them. In psychology and neuroscience, this problem is still present, but
    there are already several theories and taxonomies widely accepted by several cognitive-behavioral
    researchers [[22](#bib.bib22)].
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管在计算机科学、心理学、神经科学甚至哲学的各个领域进行了大量研究，但历史性的问题在于注意力在大脑中无处不在，因为没有单一的注意力中心，这使得概念和研究方面相当抽象且难以验证。当一组相关概念和想法变得难以管理时，分类法就显得很有用。通过分类法，可以将不同方面归类并系统地研究它们。在心理学和神经科学中，这个问题依然存在，但已经有几个理论和分类法被多个认知行为研究者广泛接受[[22](#bib.bib22)]。
- en: 'Specifically, in Deep Learning, there is no a taxonomy based on theoretical
    concepts of attention, given that the few that exist are far from theoretical
    concepts and are quite specific in a given scope [[23](#bib.bib23)][[24](#bib.bib24)].
    In this sense, a unified attention framework supported by a taxonomy with concepts
    founded on psychology and neuroscience is necessary to elucidate how the different
    attentional mechanisms act in DL, facilitating the visualization of new research
    opportunities. Thus, we aim in this work to present the reader with a taxonomy
    of attention for neural networks based on various theoretical insights on the
    attention and several relevant researches that precedes Deep Learning [[1](#bib.bib1)].
    We formulated a very broad and generic taxonomy around five main dimensions: components
    (Section [IV-A](#S4.SS1 "IV-A Components: Selective, Divided, Oriented and Sustained
    ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")), function of the process (Section [IV-B](#S4.SS2 "IV-B
    Selective Perception versus Selective Cognition ‣ IV A Taxonomy for Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")), stimulus’
    nature (Section [IV-C](#S4.SS3 "IV-C Stimulus’ Nature ‣ IV A Taxonomy for Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")), process’
    nature according to the stimulus (Section [IV-D](#S4.SS4 "IV-D Bottom-Up versus
    Top-Down Models ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models
    in Deep Learning: Survey and Taxonomy")), and continuity (Section [IV-E](#S4.SS5
    "IV-E Continuity: Soft versus Hard ‣ IV A Taxonomy for Attention Models ‣ Neural
    Attention Models in Deep Learning: Survey and Taxonomy")).'
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: '具体来说，在深度学习中，没有基于注意力理论概念的分类法，因为现有的少数分类法远离理论概念，并且在特定范围内较为具体[[23](#bib.bib23)][[24](#bib.bib24)]。在这种情况下，基于心理学和神经科学概念的统一注意力框架是必要的，以阐明不同的注意力机制在深度学习中的作用，便于发现新的研究机会。因此，我们的目标是为读者呈现一个基于多种理论见解和深度学习之前的相关研究的神经网络注意力分类法[[1](#bib.bib1)]。我们围绕五个主要维度制定了一个非常广泛和通用的分类法：组件（第
    [IV-A](#S4.SS1 "IV-A Components: Selective, Divided, Oriented and Sustained ‣
    IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy") 节），过程的功能（第 [IV-B](#S4.SS2 "IV-B Selective Perception versus
    Selective Cognition ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models
    in Deep Learning: Survey and Taxonomy") 节），刺激的性质（第 [IV-C](#S4.SS3 "IV-C Stimulus’
    Nature ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy") 节），根据刺激的过程性质（第 [IV-D](#S4.SS4 "IV-D Bottom-Up
    versus Top-Down Models ‣ IV A Taxonomy for Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy") 节），以及连续性（第 [IV-E](#S4.SS5 "IV-E
    Continuity: Soft versus Hard ‣ IV A Taxonomy for Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy") 节）。'
- en: I-A Contributions
  id: totrans-21
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-A 贡献
- en: This survey presents a taxonomy that corroborates theoretical aspects of attention
    that predate Deep Learning. Based on our taxonomy, we present and discuss the
    main neural attention models in the field.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查呈现了一种与深度学习之前的注意力理论方面相符合的分类法。基于我们的分类法，我们展示并讨论了该领域主要的神经注意力模型。
- en: 'As the main contributions of our work, we highlight:'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 作为我们工作的主要贡献，我们强调：
- en: '1.'
  id: totrans-24
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '1.'
- en: We proposed a unified attention framework;
  id: totrans-25
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了一个统一的注意力框架；
- en: '2.'
  id: totrans-26
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '2.'
- en: We introduced the first survey with a taxonomy based on theoretical concepts
    of attention;
  id: totrans-27
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们首次提出了基于注意力理论概念的分类调查；
- en: '3.'
  id: totrans-28
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '3.'
- en: 'We systematically review the main neural attention models and provide all of
    our search and filtering tools to help researchers in future searches on the topic
    ¹¹1Download link: [https://github.com/larocs/attention_dl](https://github.com/larocs/attention_dl);'
  id: totrans-29
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们系统回顾了主要的神经注意力模型，并提供了所有的搜索和过滤工具，帮助研究人员在未来的主题搜索中¹¹1下载链接：[https://github.com/larocs/attention_dl](https://github.com/larocs/attention_dl)；
- en: '4.'
  id: totrans-30
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '4.'
- en: We select the main works through exhaustive search and filtering techniques
    and choose the most relevant among more than 650 papers critically analyzed;
  id: totrans-31
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们通过详尽的搜索和过滤技术选择了主要的研究成果，并在分析的650多篇论文中挑选出最相关的；
- en: '5.'
  id: totrans-32
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '5.'
- en: Based on our taxonomy, we discuss the biological plausibility of the main attentional
    mechanisms;
  id: totrans-33
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于我们的分类法，我们讨论了主要注意力机制的生物学可能性；
- en: '6.'
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '6.'
- en: Based on the concepts presented in our taxonomy, we describe in detail the main
    attentional systems of the field;
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于我们分类法中提出的概念，我们详细描述了该领域的主要注意力系统；
- en: '7.'
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '7.'
- en: Finally, we present a broad description of trends and research opportunities.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最后，我们提供了对趋势和研究机会的广泛描述。
- en: I-B Organization
  id: totrans-38
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: I-B 组织结构
- en: 'This survey is structured as follows. In Section  [II](#S2 "II The concept
    of attention ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")
    we present the concept of attention. Section [III](#S3 "III An unified Attention
    Framework ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") contains
    an unified attention model. In section  [IV](#S4 "IV A Taxonomy for Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") we introduce
    and discuss our taxonomy. Section [V](#S5 "V Neural Attention Models ‣ Neural
    Attention Models in Deep Learning: Survey and Taxonomy"), we present the main
    architectures and discuss the central models from our taxonomy perspective. Finally,
    in Section  [VI](#S6 "VI Discussion ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy") we discuss limitations, open challenges, current trends,
    and future directions in the area, concluding our work in section  [VII](#S7 "VII
    Conclusions ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy").'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: '本调查的结构如下。在第[II](#S2 "II The concept of attention ‣ Neural Attention Models
    in Deep Learning: Survey and Taxonomy")节中，我们介绍了注意力的概念。第[III](#S3 "III An unified
    Attention Framework ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")节包含了一个统一的注意力模型。在第[IV](#S4
    "IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")节中，我们介绍并讨论了我们的分类法。在第[V](#S5 "V Neural Attention Models ‣
    Neural Attention Models in Deep Learning: Survey and Taxonomy")节中，我们展示了主要的架构，并从我们的分类法角度讨论了中心模型。最后，在第[VI](#S6
    "VI Discussion ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")节中，我们讨论了该领域的局限性、开放挑战、当前趋势和未来方向，并在第[VII](#S7
    "VII Conclusions ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")节中总结了我们的工作。'
- en: II The concept of attention
  id: totrans-40
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 注意力的概念
- en: 'Attention is difficult to define formally and universally. In psychology, Attention
    is the act or state of attending, primarily through applying the mind to an object
    of sense or thought or even as a condition of readiness that selectively narrows
    or focuses consciousness and receptivity [[1](#bib.bib1)]. However, from a Deep
    Learning standpoint, a clear definition of attention is needed. In our definition,
    Attention is a system composed of one or multiple modules, which allocate structural
    or temporal resources, select or modulate signals to perform a task. Each module
    consists of a function or multiple non-linear functions trained in conjunction
    with the neural network. Specifically, each module outputs a selective or modulating
    mask for an input signal. The structural resources allocated are elements of the
    architecture (e.g., number of neurons, number of layers), time resources refer
    to computation per step, number of time steps, processing time in modules of the
    architectures or frameworks. The task is the goal application (e.g., classification,
    regression, segmentation, object recognition, control, among others), and signals
    are given at any abstraction level (e.g., features, visual information, audio,
    text, memories, latent space vectors). Our definition is supported by the following
    sections of this work, mainly for our taxonomy (Section  [IV](#S4 "IV A Taxonomy
    for Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")).'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: '注意力很难正式和普遍地定义。在心理学中，注意力是指注意的行为或状态，主要是通过将思维集中在感官或思维的对象上，或甚至作为一种准备状态，这种状态选择性地缩小或集中意识和接受能力[[1](#bib.bib1)]。然而，从深度学习的角度来看，需要对注意力有一个明确的定义。在我们的定义中，注意力是由一个或多个模块组成的系统，这些模块分配结构或时间资源，选择或调节信号以执行任务。每个模块由一个或多个非线性函数组成，这些函数与神经网络一起训练。具体来说，每个模块输出一个选择性或调节性的掩膜，用于处理输入信号。分配的结构资源是体系结构的元素（例如，神经元数量、层数），时间资源指的是每一步的计算量、时间步数、体系结构或框架中模块的处理时间。任务是目标应用（例如，分类、回归、分割、目标识别、控制等），信号可以在任何抽象级别提供（例如，特征、视觉信息、音频、文本、记忆、潜在空间向量）。我们的定义得到了本文以下部分的支持，主要是我们的分类法（第[IV](#S4
    "IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")节）。'
- en: III An unified Attention Framework
  id: totrans-42
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 统一的注意力框架
- en: 'In this section, we define a general and unified model of attention. Our model
    corroborates with theoretical aspects and is independent of the architecture and
    the application domain. Specifically, we consider that an attentional system contains
    a set of attentional subsystems - even in a recursive manner - to allocate resources
    for processes. An attentional subsystem, at each time step $t$, receives as input
    a contextual input $c_{t}$, a focus target $\tau_{t}$, and past inner state $i_{t-1}$.
    And produces as output a current inner state $i_{t}$, and current focus output
    $a_{t}$, as shown Figure [1](#S3.F1 "Figure 1 ‣ III An unified Attention Framework
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy"). The focused
    output is the main element of the subsystem because it assigns targets an importance
    score. Together, several attentional subsystems always perform actions to provide
    selection capabilities. The subsystem profile depends on the data structure and
    the desired output. We propose a general structure with some additional components
    that, although not universally present, are still found in most models in the
    literature. In Figure [2](#S3.F2 "Figure 2 ‣ III An unified Attention Framework
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy"), we list all
    key components.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '在本节中，我们定义了一个通用且统一的注意力模型。我们的模型与理论方面相符，并且独立于架构和应用领域。具体来说，我们认为一个注意力系统包含一组注意力子系统——甚至以递归方式——用于分配资源以进行处理。一个注意力子系统在每个时间步$t$，接收作为输入的上下文输入$c_{t}$、焦点目标$\tau_{t}$和过去的内部状态$i_{t-1}$。它的输出是当前的内部状态$i_{t}$和当前的焦点输出$a_{t}$，如图[1](#S3.F1
    "Figure 1 ‣ III An unified Attention Framework ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy")所示。焦点输出是子系统的主要元素，因为它为目标分配重要性评分。多个注意力子系统共同作用，提供选择能力。子系统的特征取决于数据结构和所需的输出。我们提出了一个通用结构，并添加了一些附加组件，虽然这些组件并非普遍存在，但在文献中的大多数模型中仍然可以找到。在图[2](#S3.F2
    "Figure 2 ‣ III An unified Attention Framework ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy")中，我们列出了所有关键组件。'
- en: '![Refer to caption](img/2f5f6d2b3be96072b297be1d833fef0f.png)'
  id: totrans-44
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/2f5f6d2b3be96072b297be1d833fef0f.png)'
- en: 'Figure 1: Illustration of our attentional framework for DL, in which several
    attentional subsystems are coupled in the neural networks sequentially or recurrently.
    Each subsystem has a different profile based on the input data’s structure and
    sensory modality. A single subsystem receives as the primary input the focus target
    (i.e., the stimulus to be filtered), and sometimes auxiliary inputs (e.g., contextual
    information and subsystem’s previous internal state) to help the mechanism guide
    the focus in time.'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 图1：我们的注意力框架示意图，其中多个注意力子系统在神经网络中按顺序或递归地耦合。每个子系统根据输入数据的结构和感官模态具有不同的特征。单个子系统将关注目标（即要过滤的刺激）作为主要输入，有时还会接收辅助输入（例如，上下文信息和子系统的前一个内部状态），以帮助机制在时间上引导关注。
- en: '| Symbol | Description |'
  id: totrans-46
  prefs: []
  type: TYPE_TB
  zh: '| 符号 | 描述 |'
- en: '| --- | --- |'
  id: totrans-47
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| Context |'
  id: totrans-48
  prefs: []
  type: TYPE_TB
  zh: '| 上下文 |'
- en: '| --- |'
  id: totrans-49
  prefs: []
  type: TYPE_TB
  zh: '| --- |'
- en: '| $k$ | Sensory modality index. |'
  id: totrans-50
  prefs: []
  type: TYPE_TB
  zh: '| $k$ | 感官模态索引。 |'
- en: '| $C$ |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| $C$ |'
- en: '&#124; Contextual input set, $C=\{c_{t-1},\ldots,c_{t}\}$, $C\in\mathbb{R}$,
    (e.g., hidden states, memory data, sensory data). &#124;'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 上下文输入集，$C=\{c_{t-1},\ldots,c_{t}\}$，$C\in\mathbb{R}$，（例如，隐藏状态、记忆数据、感官数据）。
    &#124;'
- en: '|'
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $c_{t}$ |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| $c_{t}$ |'
- en: '&#124; Contextual input at time $t$, $c_{t}=\{c_{t}^{1},\ldots,c_{t}^{k}\}$,
    $c_{t}\in C$. &#124;'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时间$t$的上下文输入，$c_{t}=\{c_{t}^{1},\ldots,c_{t}^{k}\}$，$c_{t}\in C$。 &#124;'
- en: '|'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $c^{k}_{t}$ |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| $c^{k}_{t}$ |'
- en: '&#124; Contextual input from sensory modality $k$ at time $t$, $c_{t}^{k}=\{c_{t,1}^{k},\ldots,c_{t,n_{ck}}^{k}\}$,
    $c_{t,j}^{k}\in\mathbb{R}^{F_{c}}$, where $F_{c}$ is &#124;'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时间$t$的感官模态$k$的上下文输入，$c_{t}^{k}=\{c_{t,1}^{k},\ldots,c_{t,n_{ck}}^{k}\}$，$c_{t,j}^{k}\in\mathbb{R}^{F_{c}}$，其中$F_{c}$是
    &#124;'
- en: '&#124; amount of features. &#124;'
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 特征的数量。 &#124;'
- en: '|'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Focus target |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| 关注目标 |'
- en: '| $T$ |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| $T$ |'
- en: '&#124; Focus target set, $T=\{\tau_{t-1},\ldots,\tau_{t}\}$, $T\in\mathbb{R}$.
    &#124;'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 目标关注集，$T=\{\tau_{t-1},\ldots,\tau_{t}\}$，$T\in\mathbb{R}$。 &#124;'
- en: '|'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $\tau_{t}$ |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| $\tau_{t}$ |'
- en: '&#124; Focus target at time $t$, $\tau_{t}=\{\tau_{t}^{1},\ldots,\tau_{t}^{k}\}$,
    $\tau_{t}\in T$. &#124;'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时间$t$的关注目标，$\tau_{t}=\{\tau_{t}^{1},\ldots,\tau_{t}^{k}\}$，$\tau_{t}\in
    T$。 &#124;'
- en: '|'
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $\tau_{t}^{k}$ |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| $\tau_{t}^{k}$ |'
- en: '&#124; Focus target from sensory modality $k$ &#124;'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 感官模态$k$的关注目标 &#124;'
- en: '&#124; Features for $n_{\tau k}$ elements, if $\tau_{t}^{k}$ is a data, Hyperparameters
    or index, if $\tau_{t}^{k}$ is a program. &#124;'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 对于$n_{\tau k}$个元素的特征，如果$\tau_{t}^{k}$是数据，则为超参数或索引，如果$\tau_{t}^{k}$是程序。
    &#124;'
- en: '&#124; $\tau_{t}^{k}=\{\tau_{t,1}^{k},\ldots,\tau_{t,n_{\tau k}}^{k}\}$, $\tau_{t,j}^{k}\in$  $\mathbb{R}^{F_{\tau
    k}}$, where $F_{\tau k}$ is amount of features. &#124;'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $\tau_{t}^{k}=\{\tau_{t,1}^{k},\ldots,\tau_{t,n_{\tau k}}^{k}\}$，$\tau_{t,j}^{k}\in$
    $\mathbb{R}^{F_{\tau k}}$，其中$F_{\tau k}$是特征的数量。 &#124;'
- en: '|'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Inner state |'
  id: totrans-73
  prefs: []
  type: TYPE_TB
  zh: '| 内部状态 |'
- en: '| $I$ |'
  id: totrans-74
  prefs: []
  type: TYPE_TB
  zh: '| $I$ |'
- en: '&#124; Inner state set, $I=\{i_{t-1},\ldots,i_{t}\}$, $I\in\mathbb{R}$. &#124;'
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 内部状态集，$I=\{i_{t-1},\ldots,i_{t}\}$，$I\in\mathbb{R}$。 &#124;'
- en: '|'
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $i_{t}$ | Inner state at time $t$, $\iota_{t}\in I$. |'
  id: totrans-77
  prefs: []
  type: TYPE_TB
  zh: '| $i_{t}$ | 时间$t$的内部状态，$\iota_{t}\in I$。 |'
- en: '| $i_{t}-1$ | Past inner state at time $t-1$, $\iota_{t-1}\in I$. |'
  id: totrans-78
  prefs: []
  type: TYPE_TB
  zh: '| $i_{t}-1$ | 时间$t-1$的过去内部状态，$\iota_{t-1}\in I$。 |'
- en: '| Focus output |'
  id: totrans-79
  prefs: []
  type: TYPE_TB
  zh: '| 关注输出 |'
- en: '| $A$ |'
  id: totrans-80
  prefs: []
  type: TYPE_TB
  zh: '| $A$ |'
- en: '&#124; Focus output set, $A=\{a_{t-1},\ldots,a_{t}\}$, $A=\left\{x\in\mathbb{R}:0<x<1\right\}$
    or $A=\left\{x\in\mathbb{Z}:0\leq x\leq 1\right\}$. &#124;'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 关注输出集，$A=\{a_{t-1},\ldots,a_{t}\}$，$A=\left\{x\in\mathbb{R}:0<x<1\right\}$或$A=\left\{x\in\mathbb{Z}:0\leq
    x\leq 1\right\}$。 &#124;'
- en: '|'
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $a_{t}$ |'
  id: totrans-83
  prefs: []
  type: TYPE_TB
  zh: '| $a_{t}$ |'
- en: '&#124; Focus output at time $t$, $a_{t}=\{a_{t}^{1},\ldots,a_{t}^{k}\}\in A$.
    &#124;'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时间$t$的关注输出，$a_{t}=\{a_{t}^{1},\ldots,a_{t}^{k}\}\in A$。 &#124;'
- en: '|'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| $a_{t}^{k}$ |'
  id: totrans-86
  prefs: []
  type: TYPE_TB
  zh: '| $a_{t}^{k}$ |'
- en: '&#124; Focus output from sensory modality $k$ at time $t$, $a_{t}^{k}=\{a_{t,1}^{k},\ldots,a_{t,n_{\tau
    k}}^{k}\}$ are attention scores, &#124;'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 时间$t$的感官模态$k$的关注输出，$a_{t}^{k}=\{a_{t,1}^{k},\ldots,a_{t,n_{\tau k}}^{k}\}$是注意力分数，
    &#124;'
- en: '&#124; $a_{t,j}^{k}\in\mathbb{R}^{F_{\tau k}}$ or $a_{t,j}^{k}\in\mathbb{R}$,
    $a_{t}^{k}\in\mathbb{R}^{n_{\tau k}\times F_{\tau k}}$ or $a_{t}^{k}\in\mathbb{R}^{n_{\tau
    k}}$. &#124;'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; $a_{t,j}^{k}\in\mathbb{R}^{F_{\tau k}}$或$a_{t,j}^{k}\in\mathbb{R}$，$a_{t}^{k}\in\mathbb{R}^{n_{\tau
    k}\times F_{\tau k}}$或$a_{t}^{k}\in\mathbb{R}^{n_{\tau k}}$。 &#124;'
- en: '|'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: 'Figure 2: Notation for unified attention model. Note the notation supports
    recurrence and multimodality.'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 图2：统一注意力模型的符号说明。注意符号支持递归和多模态。
- en: IV A Taxonomy for Attention Models
  id: totrans-91
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 注意力模型的分类
- en: 'This section introduces our taxonomy around 16 factors that will be used to
    categorize and discuss the main neural attention models summarized in Figure [3](#S4.F3
    "Figure 3 ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy"). These factors have their origins in behavioral
    and computational studies of attention. In section [IV-A](#S4.SS1 "IV-A Components:
    Selective, Divided, Oriented and Sustained ‣ IV A Taxonomy for Attention Models
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") we present the
    models of attention from the component perspective, whereas in section [IV-B](#S4.SS2
    "IV-B Selective Perception versus Selective Cognition ‣ IV A Taxonomy for Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") we discuss
    the process function presenting mechanisms of perceptual and cognitive selection.
    Section [IV-C](#S4.SS3 "IV-C Stimulus’ Nature ‣ IV A Taxonomy for Attention Models
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") presents the
    mechanisms according to the nature of the stimulus, while in section [IV-D](#S4.SS4
    "IV-D Bottom-Up versus Top-Down Models ‣ IV A Taxonomy for Attention Models ‣
    Neural Attention Models in Deep Learning: Survey and Taxonomy") we discuss the
    mechanisms analyzing the nature of the process according to the stimulus. Finally,
    in section [IV-E](#S4.SS5 "IV-E Continuity: Soft versus Hard ‣ IV A Taxonomy for
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")
    we present the mechanisms from the continuity standpoint.'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了我们围绕16个因素的分类法，这些因素将用于分类和讨论在图[3](#S4.F3 "图3 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")中总结的主要神经注意力模型。这些因素起源于对注意力的行为和计算研究。在[IV-A](#S4.SS1
    "IV-A 组成部分：选择性、分裂性、定向性和持续性 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")节中，我们从组成部分的角度展示注意力模型，而在[IV-B](#S4.SS2
    "IV-B 选择性知觉与选择性认知 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")节中，我们讨论了过程功能，呈现了感知和认知选择机制。[IV-C](#S4.SS3
    "IV-C 刺激的性质 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")节根据刺激的性质展示了机制，而在[IV-D](#S4.SS4
    "IV-D 自下而上与自上而下模型 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")节中，我们讨论了根据刺激分析过程性质的机制。最后，在[IV-E](#S4.SS5
    "IV-E 连续性：软性与硬性 ‣ IV A 注意力模型的分类法 ‣ 深度学习中的神经注意力模型：调查与分类")节中，我们从连续性的角度展示了机制。
- en: '| No | Model | Year | f1 | f2 | f3 | f4 | f5 | f6 | f7 | f8 | f9 | f10 | f11
    | f12 | f13 | f14 | f15 |'
  id: totrans-93
  prefs: []
  type: TYPE_TB
  zh: '| 编号 | 模型 | 年份 | f1 | f2 | f3 | f4 | f5 | f6 | f7 | f8 | f9 | f10 | f11 | f12
    | f13 | f14 | f15 |'
- en: '| Bottom-up |  |  |  |'
  id: totrans-94
  prefs: []
  type: TYPE_TB
  zh: '| 自下而上 |  |  |  |'
- en: '| 1 | STN [[25](#bib.bib25)] | 2015 | + | - | - | - | - | + | FM | - | - |
    - | - | + | - | + | - |'
  id: totrans-95
  prefs: []
  type: TYPE_TB
  zh: '| 1 | STN [[25](#bib.bib25)] | 2015 | + | - | - | - | - | + | FM | - | - |
    - | - | + | - | + | - |'
- en: '| 2 | Chen et al. [[26](#bib.bib26)] | 2016 | - | + | - | - | - | + | - | -
    | L | - | - | - | + | - | + |'
  id: totrans-96
  prefs: []
  type: TYPE_TB
  zh: '| 2 | Chen 等 [[26](#bib.bib26)] | 2016 | - | + | - | - | - | + | - | - | L
    | - | - | - | + | - | + |'
- en: '| 3 | AT [[27](#bib.bib27)] | 2016 | - | + | - | - | - | + | FM | - | - | -
    | - | + | - | - | + |'
  id: totrans-97
  prefs: []
  type: TYPE_TB
  zh: '| 3 | AT [[27](#bib.bib27)] | 2016 | - | + | - | - | - | + | FM | - | - | -
    | - | + | - | - | + |'
- en: '| 4 | SNAIL [[28](#bib.bib28)] | 2017 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
  id: totrans-98
  prefs: []
  type: TYPE_TB
  zh: '| 4 | SNAIL [[28](#bib.bib28)] | 2017 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
- en: '| 5 | SENet [[29](#bib.bib29)] | 2018 | - | + | - | - | - | + | - | - | V |
    - | - | + | - | - | + |'
  id: totrans-99
  prefs: []
  type: TYPE_TB
  zh: '| 5 | SENet [[29](#bib.bib29)] | 2018 | - | + | - | - | - | + | - | - | V |
    - | - | + | - | - | + |'
- en: '| 6 | GAT [[20](#bib.bib20)] | 2018 | - | + | - | - | - | + | H | - | H | -
    | - | + | + | - | + |'
  id: totrans-100
  prefs: []
  type: TYPE_TB
  zh: '| 6 | GAT [[20](#bib.bib20)] | 2018 | - | + | - | - | - | + | H | - | H | -
    | - | + | + | - | + |'
- en: '| 7 | $A^{2}-Nets$ [[30](#bib.bib30)] | 2018 | - | + | - | - | - | + | FM |
    - | - | - | - | - | + | - | + |'
  id: totrans-101
  prefs: []
  type: TYPE_TB
  zh: '| 7 | $A^{2}-Nets$ [[30](#bib.bib30)] | 2018 | - | + | - | - | - | + | FM |
    - | - | - | - | - | + | - | + |'
- en: '| 8 | DANet [[31](#bib.bib31)] | 2019 | - | + | + | - | - | + | FM | - | V
    | - | - | + | - | - | + |'
  id: totrans-102
  prefs: []
  type: TYPE_TB
  zh: '| 8 | DANet [[31](#bib.bib31)] | 2019 | - | + | + | - | - | + | FM | - | V
    | - | - | + | - | - | + |'
- en: '| 9 | HAN [[32](#bib.bib32)] | 2019 | - | + | - | - | - | + | H | - | H | -
    | - | + | + | - | + |'
  id: totrans-103
  prefs: []
  type: TYPE_TB
  zh: '| 9 | HAN [[32](#bib.bib32)] | 2019 | - | + | - | - | - | + | H | - | H | -
    | - | + | + | - | + |'
- en: '| 10 | TIM [[33](#bib.bib33)] | 2021 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
  id: totrans-104
  prefs: []
  type: TYPE_TB
  zh: '| 10 | TIM [[33](#bib.bib33)] | 2021 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
- en: '| Top-down |  |  |  |'
  id: totrans-105
  prefs: []
  type: TYPE_TB
  zh: '| 自上而下 |  |  |  |'
- en: '| 11 | RNNSearch [[34](#bib.bib34)] | 2014 | - | + | + | - | - | + | H | -
    | - | - | - | - | + | - | + |'
  id: totrans-106
  prefs: []
  type: TYPE_TB
  zh: '| 11 | RNNSearch [[34](#bib.bib34)] | 2014 | - | + | + | - | - | + | H | -
    | - | - | - | - | + | - | + |'
- en: '| 12 | Tang et al. [[35](#bib.bib35)] | 2014 | + | - | - | + | + | - | - |
    + | - | - | - | - | + | + | - |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 12 | Tang 等 [[35](#bib.bib35)] | 2014 | + | - | - | + | + | - | - | + | -
    | - | - | - | + | + | - |'
- en: '| 13 | aNN [[36](#bib.bib36)] | 2014 | - | + | + | - | - | + | - | - | + |
    - | - | - | + | - | + |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| 13 | aNN [[36](#bib.bib36)] | 2014 | - | + | + | - | - | + | - | - | + |
    - | - | - | + | - | + |'
- en: '| 14 | NTM [[37](#bib.bib37)] | 2014 | - | + | + | - | - | + | EM | - | O |
    - | - | - | + | + | + |'
  id: totrans-109
  prefs: []
  type: TYPE_TB
  zh: '| 14 | NTM [[37](#bib.bib37)] | 2014 | - | + | + | - | - | + | EM | - | O |
    - | - | - | + | + | + |'
- en: '| 15 | RAM [[38](#bib.bib38)] | 2014 | + | - | + | - | + | - | I | - | - |
    - | - | - | + | + | - |'
  id: totrans-110
  prefs: []
  type: TYPE_TB
  zh: '| 15 | RAM [[38](#bib.bib38)] | 2014 | + | - | + | - | + | - | I | - | - |
    - | - | - | + | + | - |'
- en: '| 16 | dasNet [[39](#bib.bib39)] | 2014 | - | + | + | - | - | + | - | - | V
    | - | - | - | + | - | + |'
  id: totrans-111
  prefs: []
  type: TYPE_TB
  zh: '| 16 | dasNet [[39](#bib.bib39)] | 2014 | - | + | + | - | - | + | - | - | V
    | - | - | - | + | - | + |'
- en: '| 17 | EMNet [[19](#bib.bib19)] | 2015 | - | + | - | - | - | + | EM | - | -
    | - | - | - | + | - | + |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 17 | EMNet [[19](#bib.bib19)] | 2015 | - | + | - | - | - | + | EM | - | -
    | - | - | - | + | - | + |'
- en: '| 18 | DRAW [[40](#bib.bib40)] | 2015 | + | + | + | - | + | + | I/H | - | -
    | - | - | - | + | - | + |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| 18 | DRAW [[40](#bib.bib40)] | 2015 | + | + | + | - | + | + | I/H | - | -
    | - | - | - | + | - | + |'
- en: '| 19 | Xu et al. [[41](#bib.bib41)] | 2015 | - | + | + | - | - | + | H | -
    | - | - | - | - | + | + | + |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 19 | Xu 等人 [[41](#bib.bib41)] | 2015 | - | + | + | - | - | + | H | - | -
    | - | - | - | + | + | + |'
- en: '| 20 | Ptr-Net [[42](#bib.bib42)] | 2015 | + | + | + | - | - | + | H | - |
    - | - | - | - | + | + | + |'
  id: totrans-115
  prefs: []
  type: TYPE_TB
  zh: '| 20 | Ptr-Net [[42](#bib.bib42)] | 2015 | + | + | + | - | - | + | H | - |
    - | - | - | - | + | + | + |'
- en: '| 21 | Rocktäschel et al. [[43](#bib.bib43)] | 2015 | - | + | + | - | - | +
    | H | - | - | - | - | - | + | - | + |'
  id: totrans-116
  prefs: []
  type: TYPE_TB
  zh: '| 21 | Rocktäschel 等人 [[43](#bib.bib43)] | 2015 | - | + | + | - | - | + | H
    | - | - | - | - | - | + | - | + |'
- en: '| 22 | Luong et al. [[44](#bib.bib44)] | 2015 | - | + | + | - | - | + | H |
    - | - | - | - | - | + | - | + |'
  id: totrans-117
  prefs: []
  type: TYPE_TB
  zh: '| 22 | Luong 等人 [[44](#bib.bib44)] | 2015 | - | + | + | - | - | + | H | - |
    - | - | - | - | + | - | + |'
- en: '| 23 | Hermann et al. [[45](#bib.bib45)] | 2015 | - | + | + | - | - | + | H
    | - | - | - | - | - | + | - | + |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
  zh: '| 23 | Hermann 等人 [[45](#bib.bib45)] | 2015 | - | + | + | - | - | + | H | -
    | - | - | - | - | + | - | + |'
- en: '| 24 | DMN [[46](#bib.bib46)] | 2015 | + | - | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
  id: totrans-119
  prefs: []
  type: TYPE_TB
  zh: '| 24 | DMN [[46](#bib.bib46)] | 2015 | + | - | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
- en: '| 25 | BiDAF [[47](#bib.bib47)] | 2016 | + | + | - | - | - | + | H | - | -
    | - | - | - | + | + | + |'
  id: totrans-120
  prefs: []
  type: TYPE_TB
  zh: '| 25 | BiDAF [[47](#bib.bib47)] | 2016 | + | + | - | - | - | + | H | - | -
    | - | - | - | + | + | + |'
- en: '| 26 | STRAW [[48](#bib.bib48)] | 2016 | + | + | + | - | - | + | EM | - | -
    | + | - | - | + | + | + |'
  id: totrans-121
  prefs: []
  type: TYPE_TB
  zh: '| 26 | STRAW [[48](#bib.bib48)] | 2016 | + | + | + | - | - | + | EM | - | -
    | + | - | - | + | + | + |'
- en: '| 27 | Allamanis et al. [[49](#bib.bib49)] | 2016 | - | + | + | - | - | + |
    H | - | - | - | - | - | + | - | + |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
  zh: '| 27 | Allamanis 等人 [[49](#bib.bib49)] | 2016 | - | + | + | - | - | + | H |
    - | - | - | - | - | + | - | + |'
- en: '| 28 | Lu et al. [[50](#bib.bib50)] | 2016 | - | + | - | - | - | + | H | -
    | - | - | - | - | + | - | + |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
  zh: '| 28 | Lu 等人 [[50](#bib.bib50)] | 2016 | - | + | - | - | - | + | H | - | -
    | - | - | - | + | - | + |'
- en: '| 29 | ACT [[51](#bib.bib51)] | 2016 | + | + | + | - | - | + | - | - | - |
    - | + | - | + | - | + |'
  id: totrans-124
  prefs: []
  type: TYPE_TB
  zh: '| 29 | ACT [[51](#bib.bib51)] | 2016 | + | + | + | - | - | + | - | - | - |
    - | + | - | + | - | + |'
- en: '| 30 | Lu et al. [[52](#bib.bib52)] | 2016 | - | + | + | - | - | + | FM/H |
    - | MC | - | - | - | + | - | + |'
  id: totrans-125
  prefs: []
  type: TYPE_TB
  zh: '| 30 | Lu 等人 [[52](#bib.bib52)] | 2016 | - | + | + | - | - | + | FM/H | - |
    MC | - | - | - | + | - | + |'
- en: '| 31 | HAN [[53](#bib.bib53)] | 2016 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
  zh: '| 31 | HAN [[53](#bib.bib53)] | 2016 | - | + | + | - | - | + | H | - | - |
    - | - | - | + | - | + |'
- en: '| 32 | Excitation Backprop [[54](#bib.bib54)] | 2016 | - | + | - | - | - |
    + | N | - | - | - | - | - | + | - | + |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
  zh: '| 32 | Excitation Backprop [[54](#bib.bib54)] | 2016 | - | + | - | - | - |
    + | N | - | - | - | - | - | + | - | + |'
- en: '| 33 | DCN [[55](#bib.bib55)] | 2016 | - | + | - | - | - | + | H | - | - |
    - | - | - | + | + | + |'
  id: totrans-128
  prefs: []
  type: TYPE_TB
  zh: '| 33 | DCN [[55](#bib.bib55)] | 2016 | - | + | - | - | - | + | H | - | - |
    - | - | - | + | + | + |'
- en: '| 34 | GCA-LSTM [[56](#bib.bib56)] | 2017 | - | + | + | - | - | + | H | - |
    - | - | - | - | + | - | + |'
  id: totrans-129
  prefs: []
  type: TYPE_TB
  zh: '| 34 | GCA-LSTM [[56](#bib.bib56)] | 2017 | - | + | + | - | - | + | H | - |
    - | - | - | - | + | - | + |'
- en: '| 35 | Reed et al. [[57](#bib.bib57)] | 2017 | - | + | + | - | - | + | H |
    - | - | - | - | - | + | - | + |'
  id: totrans-130
  prefs: []
  type: TYPE_TB
  zh: '| 35 | Reed 等人 [[57](#bib.bib57)] | 2017 | - | + | + | - | - | + | H | - |
    - | - | - | - | + | - | + |'
- en: '| 36 | Seo et al. [[58](#bib.bib58)] | 2017 | - | + | + | - | - | + | FM |
    - | - | - | - | - | + | - | + |'
  id: totrans-131
  prefs: []
  type: TYPE_TB
  zh: '| 36 | Seo 等人 [[58](#bib.bib58)] | 2017 | - | + | + | - | - | + | FM | - |
    - | - | - | - | + | - | + |'
- en: '| 37 | SAB [[59](#bib.bib59)][[60](#bib.bib60)] | 2017 | - | + | + | - | -
    | + | H | - | - | - | - | - | + | - | + |'
  id: totrans-132
  prefs: []
  type: TYPE_TB
  zh: '| 37 | SAB [[59](#bib.bib59)][[60](#bib.bib60)] | 2017 | - | + | + | - | -
    | + | H | - | - | - | - | - | + | - | + |'
- en: '| 38 | ACF Network [[61](#bib.bib61)] | 2017 | + | - | + | - | - | + | - |
    - | - | + | - | - | + | + | - |'
  id: totrans-133
  prefs: []
  type: TYPE_TB
  zh: '| 38 | ACF Network [[61](#bib.bib61)] | 2017 | + | - | + | - | - | + | - |
    - | - | + | - | - | + | + | - |'
- en: '| 39 | Kim et al. [[62](#bib.bib62)] | 2017 | - | + | - | - | - | + | H | -
    | - | - | - | - | + | - | + |'
  id: totrans-134
  prefs: []
  type: TYPE_TB
  zh: '| 39 | Kim 等人 [[62](#bib.bib62)] | 2017 | - | + | - | - | - | + | H | - | -
    | - | - | - | + | - | + |'
- en: '| 40 | BAN [[63](#bib.bib63)] | 2018 | - | + | - | - | - | + | - | - | V |
    - | - | - | + | - | + |'
  id: totrans-135
  prefs: []
  type: TYPE_TB
  zh: '| 40 | BAN [[63](#bib.bib63)] | 2018 | - | + | - | - | - | + | - | - | V |
    - | - | - | + | - | + |'
- en: '| 41 | AG [[64](#bib.bib64)] | 2018 | - | + | - | - | - | + | FM | - | - |
    - | - | - | + | - | + |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| 42 | Perera et al. [[65](#bib.bib65)] | 2018 | - | + | + | - | - | + | H
    | - | MC | - | - | - | + | - | + |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '| 43 | Deng et al. [[66](#bib.bib66)] | 2018 | - | + | - | - | - | + | H |
    - | - | - | - | - | + | - | + |'
  id: totrans-138
  prefs: []
  type: TYPE_TB
- en: '| 44 | HAN [[67](#bib.bib67)] | 2020 | - | + | - | - | - | + | M | - | - |
    - | - | - | + | - | + |'
  id: totrans-139
  prefs: []
  type: TYPE_TB
- en: '| 45 | IMRAM [[68](#bib.bib68)] | 2020 | - | + | - | - | - | + | H | - | -
    | - | - | - | + | - | + |'
  id: totrans-140
  prefs: []
  type: TYPE_TB
- en: '| 46 | Lekkala et al. [[69](#bib.bib69)] | 2020 | - | + | - | - | - | + | -
    | - | V | - | - | - | + | - | + |'
  id: totrans-141
  prefs: []
  type: TYPE_TB
- en: '| Hybrid |  |  |  |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
- en: '| 47 | Transformer [[18](#bib.bib18)] | 2017 | - | + | + | - | - | + | H |
    - | - | - | - | - | + | - | + |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '| 48 | DiSAN [[70](#bib.bib70)] | 2018 | - | + | - | - | - | + | H | - | L
    | - | - | - | + | - | + |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
- en: '| 49 | ANP [[71](#bib.bib71)] | 2019 | - | + | - | - | + | + | O | - | - |
    - | - | - | + | - | + |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
- en: '| 50 | BRIMs [[72](#bib.bib72)] | 2020 | - | + | + | - | - | + | H | - | -
    | - | - | - | + | - | + |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
- en: '| 51 | MSAN [[73](#bib.bib73)] | 2020 | + | + | + | - | - | + | H | - | - |
    + | - | - | + | + | + |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: 'Figure 3: Summary of main neural attention models. Factors in order are: Selective
    (f1), divided (f2), oriented (f3), sustained (f4), selective perception (f5),
    selective cognition (f6), location-based (f7), object-based (f8), feature-based
    (f9), task-oriented (f10), time-oriented (f11), stateless (f12), stateful (f13),
    hard (f14), soft (f15). In the location-based column (f7) column: hidden states/data
    embeddings (H), external memory cells (EM), feature maps (FM), input data (I),
    and others (O). In the feature-based column (f9) column: visual (V), linguistic
    (L), memory cell (MC), hidden states (H), and others (O). In the other columns,
    the presence of the feature is indicated by the + symbol and absence by the -
    symbol.'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: 'IV-A Components: Selective, Divided, Oriented and Sustained'
  id: totrans-149
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Each attention subsystem can have a selective, divided, oriented, or sustained
    property. Regarding the number of elements that we pay attention to simultaneously,
    we can classify subsystems as selective or divided attention. Regarding attention
    between instants of time, attention can be oriented or sustained. Selective attention
    chooses only one stimulus among all the others. In contrast, divided attention
    is the highest level of attention and refers to responding simultaneously to multiple
    stimuli or tasks. Biologically, divided attention can only operate two tasks simultaneously
    if one of them is mediated by automatic processes and the other by a cognitive
    [[74](#bib.bib74)] so that only one task requires much intellectual effort.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Oriented attention can shift the focus by leaving a stimulus for another through
    three processes: 1) leave the current focus, 2) change the focus to the expected
    stimulus, and 3) locate the target and maintain attention. Such a component represents
    the ability to coordinate simultaneous tasks to be interrupted and resumed temporarily.
    This function is usually linked to the central executive who coordinates and manages
    the information processing activities of the brain [[75](#bib.bib75)]. At working
    memory (WM), oriented attention mechanisms are extremely useful in determining
    which perceptual and long-term memory information is loaded and deleted at each
    time step $t$ among all existing information. Oriented components often select
    a single item or set of items from all the information available to feed some
    mental process input. Sustained attention or vigilance allows the maintenance
    of the goal over time through directly focusing on specific stimuli to complete
    a planned activity. This component plays a fundamental role in learning, performing
    daily tasks, maintaining dialogues and social relationships, among many other
    skills that affect mental health [[76](#bib.bib76)]. Despite this, sustained attention
    is generally less studied than transient aspects of attention, such as shifting,
    dividing, and attentional selection. What distinguishes sustained attention is
    the focus on performance on a single task over time. There are fluctuations within
    the individual’s overall ability to maintain stable performance on the task, with
    a trade-off between exposure to stimuli and a recovery period.'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
  zh: 定向注意力可以通过三个过程将焦点从一个刺激转移到另一个刺激：1) 离开当前焦点，2) 将焦点转移到预期的刺激上，3) 确定目标并维持注意力。这一组件代表了协调同时进行的任务的能力，以便在被打断后能够暂时恢复。这一功能通常与中央执行系统相关联，中央执行系统协调和管理大脑的信息处理活动[[75](#bib.bib75)]。在工作记忆（WM）中，定向注意力机制在确定每个时间步$t$中加载和删除的感知信息及长期记忆信息时极为有用。定向组件通常从所有可用的信息中选择一个或一组项目，以提供某些心理过程的输入。持续注意力或警觉性通过直接集中注意于特定刺激以完成计划活动，从而在时间上维持目标。这个组件在学习、执行日常任务、维持对话和社会关系等众多影响心理健康的技能中扮演着基础性角色[[76](#bib.bib76)]。尽管如此，持续注意力通常比注意力的瞬态方面（如转移、分配和选择）研究得少。持续注意力的区别在于专注于单一任务的表现持续时间。个体在任务上保持稳定表现的总体能力存在波动，并在暴露于刺激和恢复期间之间存在权衡。
- en: In our framework, selective attention can be understood as the ability of the
    subsystem to select only one stimulus from the focus target among all stimuli
    or select only a subset of stimuli from the target with the same attentional weight
    and completely inhibit the response of the unselected stimuli. On the other hand,
    in divided attention the attentional mask is distributed over the entire input
    focus target so that no stimulus is completely inhibited, only modulated with
    weights greater than or less than its original values. In oriented attention,
    at time $t_{1}$, the attentional focus is on a non-empty subset of elements of
    the focus target $\tau_{t}$, at time $t_{2}$ the focus is shifted to a new subset
    of elements from the same target or another target, at time $t_{3}$ the focus
    may be a different target or initial target. However, if the target does not change
    over time and the attentional mask is always the same, or if the target changes
    over time but the attentional mask remains on the same semantic elements as the
    target, the system is sustained attention. For example, if the target is a sequence
    of images and the attentional mask remains centered around the same object throughout
    the sequence, or if the mask remains on the same features as the image, the system
    is sustained attention. If the attentional system can choose to change its focus
    in time or remain in the same focus, the system is also considered oriented attention
    because, at some point, there is the possibility of switching.
  id: totrans-152
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的框架中，选择性注意可以理解为子系统从所有刺激中仅选择一个来自焦点目标的刺激，或者从目标中选择仅具有相同注意权重的刺激子集，并完全抑制未选择刺激的反应。另一方面，在分散注意力中，注意力面罩分布在整个输入焦点目标上，因此没有刺激会被完全抑制，只是被调节为比其原始值更大或更小的权重。在定向注意中，在时间
    $t_{1}$，注意力集中在焦点目标 $\tau_{t}$ 的一个非空元素子集上；在时间 $t_{2}$，注意力转移到来自相同目标或其他目标的新元素子集上；在时间
    $t_{3}$，注意力可能集中在一个不同的目标或初始目标上。然而，如果目标随时间不变且注意力面罩始终相同，或者如果目标随时间变化但注意力面罩保持在与目标相同的语义元素上，则系统为持续注意。例如，如果目标是一系列图像，且注意力面罩在整个序列中始终围绕同一对象，或者面罩始终保持在图像的相同特征上，则系统为持续注意。如果注意力系统可以选择在时间上改变其焦点或保持在相同焦点上，则系统也被认为是定向注意，因为在某些时候，存在切换的可能性。
- en: Oriented or sustained systems are present only in sequential/recurring architectures.
    The first oriented systems emerged through visual search engines in images and
    encoder-decoder frameworks. Visual search architectures based on RAM [[38](#bib.bib38)]
    use the oriented attention to control the perceptual sensors’ focus. At each time
    step $t$, the sensors act as retina selecting only a portion of the input image
    for subsequent processing. The selected image portion receives the same attentional
    weight while the other regions are completely inhibited from further processing,
    presenting selective characteristics of attention. A DRAW [[40](#bib.bib40)] uses
    a very similar oriented component for image generation. At each time step $t$,
    two attentional components shift the focus from a reading head and a writing head
    to small portions of the image, allowing sequential generation and refinement
    of the portions previously generated. However, at the same time $t$, attentional
    masks explicitly divide attention between all pixels in the image. However, the
    masking computation process on targets occurs to select only desired patches,
    excluding other regions in subsequent processing, such as a selective mechanism.
    Spatial Transformer [[25](#bib.bib25)] features a selected visual search engine
    that samples only one region of interest in the image, undoes spatial deformations,
    and passes the result on to subsequent processing. This mechanism is very flexible
    regarding the temporal aspect, and its characteristics depend on the architecture
    to which it is attached. If it is in non-sequential architectures, it is only
    selected, but if it is in sequential architectures, it can act as an oriented
    or sustained attention mechanism. If the mechanism can track the same region of
    interest, it is sustained. Otherwise, it is oriented.
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
  zh: 面向或持续的系统仅存在于顺序/重复架构中。第一个面向系统通过图像中的视觉搜索引擎和编码器-解码器框架出现。基于RAM的视觉搜索架构[[38](#bib.bib38)]使用面向注意力来控制感知传感器的焦点。在每个时间步$t$，传感器充当视网膜，只选择输入图像的一部分进行后续处理。被选中的图像部分接收相同的注意力权重，而其他区域则完全被抑制，呈现出注意力的选择性特征。一个DRAW
    [[40](#bib.bib40)]使用了非常相似的面向组件来生成图像。在每个时间步$t$，两个注意力组件将焦点从读取头和写入头转移到图像的较小部分，从而实现对先前生成部分的顺序生成和细化。然而，在同一时间$t$，注意力掩膜明确地将注意力在图像的所有像素之间进行划分。然而，目标上的掩膜计算过程会选择仅所需的区域，排除其他区域进行后续处理，如选择性机制。空间变换器[[25](#bib.bib25)]具有一个选择性的视觉搜索引擎，它只采样图像中的一个感兴趣区域，撤销空间变形，并将结果传递给后续处理。这个机制在时间方面非常灵活，其特征取决于它附加的架构。如果它在非顺序架构中，它仅仅是被选择的，但如果它在顺序架构中，它可以作为面向或持续的注意力机制。如果机制能够跟踪相同的兴趣区域，它就是持续的。否则，它是面向的。
- en: Most of the encoder-decoder-attention frameworks for reasoning [[77](#bib.bib77)]
    [[43](#bib.bib43)][[78](#bib.bib78)], machine comprehension [[79](#bib.bib79)],
    neuralne and machine translation [[34](#bib.bib34)] are divided and oriented attention.
    At each time step $t$, the attentional mask can simultaneously hide hidden states
    from the encoder to compose a dynamic context vector with the weighting of all
    information, such as a reasoning structure in a working memory that selects and
    modulates memories to meet some mental process. The same hidden states remain
    the target in the next time step, but the system can assign attentional weights
    in a completely different way, featuring an oriented attention system. Some attentional
    systems that operate on external memories are also divided and oriented. The classic
    Neural Turing Machine [[37](#bib.bib37)] [[80](#bib.bib80)] divides attention
    on all external memory cells to retrieve a modulated representation of the stored
    memories. At each time step, oriented attention mechanisms are guided by a different
    contextual input that defines how the new distribution of attention on memories
    will be. STRAW [[48](#bib.bib48)] uses a divided and oriented read/write heads
    system to find and update regions with a greater focus on the action plan of a
    trained virtual agent via reinforcement learning. Another selected and oriented
    attentional system decides when the heads should act or if only advances in the
    time of the action-plan and commitment-plan should be made. Perera et al. [[65](#bib.bib65)]
    uses two divided and oriented mechanisms attention in LSTMs cells. The first is
    external to the LSTM cell to aggregate historical information from the previous
    hidden states in just one memory vector $h_{A}^{t-1}$. The second acts inside
    the cell as a gate layer to update the current cell vector proportional to the
    importance of each portion of $h_{A}^{t-1}$. The mechanism receives the memory
    vector $h_{A}^{t-1}$ as the target, dividing attention over the entire vector,
    giving more weight to the most relevant portions and less weight to less relevant
    ones. The current cell vector is then updated.
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
  zh: 大多数用于推理的编码器-解码器-注意力框架[[77](#bib.bib77)] [[43](#bib.bib43)][[78](#bib.bib78)]、机器理解[[79](#bib.bib79)]、神经网络和机器翻译[[34](#bib.bib34)]都是分离和定向注意力的。在每一个时间步
    $t$，注意力掩码可以同时隐藏来自编码器的隐藏状态，以组合一个动态上下文向量，权衡所有信息，如工作记忆中的推理结构，选择和调节记忆以满足某些心理过程。相同的隐藏状态仍然是下一个时间步的目标，但系统可以以完全不同的方式分配注意力权重，具有定向注意力系统。一些在外部记忆上操作的注意力系统也是分离和定向的。经典的神经图灵机[[37](#bib.bib37)]
    [[80](#bib.bib80)] 将注意力分配到所有外部记忆单元，以检索存储记忆的调制表示。在每一个时间步，定向注意力机制由不同的上下文输入引导，以定义对记忆的新注意力分布。STRAW[[48](#bib.bib48)]
    使用分离和定向的读/写头系统，通过强化学习找到并更新区域，更多地关注训练虚拟代理的行动计划。另一个选择的定向注意力系统决定何时行动，或是否仅应在行动计划和承诺计划的时间上前进。Perera
    等人[[65](#bib.bib65)] 在 LSTM 单元中使用了两个分离和定向的注意力机制。第一个是 LSTM 单元外部的，将前一隐藏状态的历史信息聚合成一个记忆向量
    $h_{A}^{t-1}$。第二个在单元内部作为门控层，更新当前单元向量，与 $h_{A}^{t-1}$ 的每个部分的重要性成比例。该机制将记忆向量 $h_{A}^{t-1}$
    作为目标，对整个向量进行注意力分配，对最相关的部分给予更多权重，对较不相关的部分给予较少权重。然后更新当前单元向量。
- en: The GCA-LSTM Network [[56](#bib.bib56)] uses a divided and oriented attentional
    mechanism to update, at each time step $t$, the cell state in LSTM units. The
    mechanism generates an attentional mask for the $i_{j,t}$input gate and LSTM cell’s
    spatial / temporal contextual information, based on previous hidden states. At
    dasNet [[39](#bib.bib39)] attentional mechanisms coupled in CNNs communicate the
    static convolutional structures with each other generating a sequential processing
    structure, in which oriented and divided attention systems receive as a context
    a set of feature maps from the previous time step. It then generates attentional
    masks on the feature maps of the current time step, choosing between maintaining
    or not the same attentional weights on the new feature maps. However, most convolutional
    structures are only divided attention, mainly targeting feature maps. Attention
    gated networks [[64](#bib.bib64)] presents a classic example of purely divided
    mechanisms. They receive a set of feature maps as input and return a spatial attentional
    mask over all the maps simultaneously. In this case, the attentional system is
    focused on spatial characteristics, weighting the same regions of different maps
    with the same weight, but on each map, the mask weighs each pixel with different
    weights. Some mechanisms are also quite flexible concerning architecture and temporal
    characteristics. For example, Structured Attention Networks [[62](#bib.bib62)]
    features divided mechanisms that can be coupled in sequential architectures operating
    as oriented or sustained attention.
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
  zh: GCA-LSTM 网络 [[56](#bib.bib56)] 使用了一个分层且定向的注意力机制，在每个时间步 $t$ 更新 LSTM 单元中的细胞状态。该机制根据之前的隐藏状态生成
    $i_{j,t}$ 输入门和 LSTM 单元的空间/时间上下文信息的注意力掩码。在 dasNet [[39](#bib.bib39)] 中，CNNs 中的注意力机制相互通信静态卷积结构，生成一个序列处理结构，其中定向和分层注意力系统以先前时间步的特征图集作为上下文。然后，它在当前时间步的特征图上生成注意力掩码，在新的特征图上选择保持或不保持相同的注意力权重。然而，大多数卷积结构仅为分层注意力，主要针对特征图。注意力门控网络
    [[64](#bib.bib64)] 提供了纯粹分层机制的经典示例。它们接收一组特征图作为输入，并在所有图上同时返回空间注意力掩码。在这种情况下，注意力系统集中于空间特征，以相同的权重加权不同图的相同区域，但在每张图上，掩码对每个像素的权重不同。一些机制在架构和时间特征方面也相当灵活。例如，结构化注意力网络
    [[62](#bib.bib62)] 具有可以耦合在序列架构中的分层机制，作为定向或持续注意力运行。
- en: Some approaches use the oriented component to shift the focus on neural structures
    and not directly on the data. The Attentional Correlation Filter Network [[61](#bib.bib61)]
    uses an oriented and select component to choose each time step a different set
    of filtering validation strategies for the input image. Modality Shifting Attention
    [[73](#bib.bib73)] uses an oriented and select component to decide between using
    the visual modality or the linguistic modality. Few models have sustained attention.
    To our knowledge, only Tang et al. [[35](#bib.bib35)] proposed an attentional
    system selected and sustained capable of tracking a specific face in a scene amid
    occlusion situations, sudden changes in rotation, scale, and perspective.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 一些方法使用定向组件将注意力转移到神经结构上，而不是直接在数据上。注意力相关滤波网络 [[61](#bib.bib61)] 使用定向和选择组件，每个时间步选择不同的过滤验证策略来处理输入图像。模态转换注意力
    [[73](#bib.bib73)] 使用定向和选择组件来决定使用视觉模态还是语言模态。很少有模型具有持续注意力。据我们所知，只有 Tang 等人 [[35](#bib.bib35)]
    提出了一个能够在遮挡、旋转、缩放和视角突然变化的情况下追踪特定面孔的注意力系统。
- en: IV-B Selective Perception versus Selective Cognition
  id: totrans-157
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-B 选择性感知与选择性认知
- en: 'Attention can focus on things other than the sensory stimuli that come through
    the senses. It can address mental processes, such as memories, thoughts, mental
    calculations, etc. When the focus is on the external environment, it can also
    be called selective perception, and when focused on the internal environment,
    it can be called selective cognition. We consider that perceptual selection occurs
    when the attentional subsystem receives external sensory stimuli. In this case,
    the attention acts between the raw data and the neural network reinforcing the
    perception. Selective cognition, the set $\tau_{t}$is information in the latent
    space (i.e., memory data, data embeddings, feature data, or hidden states). Despite
    the classic studies of attention in sensory perception, Deep Learning approaches
    focus on cognitive selection on hidden states/embedding vectors, external memory,
    and feature maps, as shown in Figure [3](#S4.F3 "Figure 3 ‣ IV A Taxonomy for
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")
    in f4 and f5\. The first attentional mechanism in the area, proposed for RNNSearch
    [[34](#bib.bib34)], is cognitive selection on encoder hidden states. The goal
    is to weight a dynamic context vector based on the words previously generated.
    Following this line, countless other cognitive mechanisms have been developed
    to deal with long-distance dependencies between internal memory structures in
    the encoder-decoder frameworks and even access memories external to the network.
    Subsequently, mechanisms for hierarchical alignment appeared [[53](#bib.bib53)],
    multimodal alignment [[41](#bib.bib41)][[67](#bib.bib67)], boost features [[29](#bib.bib29)][[30](#bib.bib30)],
    feature embedding [[26](#bib.bib26)] , and fusion information [[56](#bib.bib56)]
    all using internal information from the neural network. The main existing perceptual
    selection mechanisms are focused on computer vision tasks, bringing some inspirations
    from the theories of human visual attention [[38](#bib.bib38)].'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '注意力不仅可以集中在通过感官传递的感觉刺激上，还可以关注心理过程，例如记忆、思维、心理计算等。当注意力集中在外部环境时，这也可以称为选择性感知，而当集中在内部环境时，则可以称为选择性认知。我们认为，当注意力子系统接收外部感觉刺激时，感知选择会发生。在这种情况下，注意力在原始数据和神经网络之间起作用，从而增强感知。选择性认知，即集合
    $\tau_{t}$，是潜在空间中的信息（即记忆数据、数据嵌入、特征数据或隐藏状态）。尽管经典的注意力研究集中在感觉感知上，但深度学习方法则侧重于隐藏状态/嵌入向量、外部记忆和特征图上的认知选择，如图[3](#S4.F3
    "Figure 3 ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy")中所示的f4和f5。该领域中的第一个注意力机制是为RNNSearch [[34](#bib.bib34)]提出的，侧重于编码器隐藏状态上的认知选择。其目标是基于之前生成的词来加权动态上下文向量。沿着这条路线，已经开发出无数其他认知机制，以处理编码器-解码器框架中内部记忆结构之间的长距离依赖关系，甚至访问网络外部的记忆。随后，出现了层次对齐
    [[53](#bib.bib53)]、多模态对齐 [[41](#bib.bib41)][[67](#bib.bib67)]、特征增强 [[29](#bib.bib29)][[30](#bib.bib30)]、特征嵌入
    [[26](#bib.bib26)] 和信息融合 [[56](#bib.bib56)] 机制，这些机制都使用了神经网络中的内部信息。现有的主要感知选择机制集中在计算机视觉任务上，借鉴了人类视觉注意力理论的一些启示
    [[38](#bib.bib38)]。'
- en: IV-C Stimulus’ Nature
  id: totrans-159
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-C 刺激的性质
- en: According to the nature of the stimulus, attention can be task-oriented or time-oriented
    if the target is a program (i.e., neural network), and it can be space-based versus
    object-based if the target is a data set.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
  zh: 根据刺激的性质，注意力可以是面向任务的或时间导向的，如果目标是程序（即神经网络），也可以是基于空间的或基于对象的，如果目标是数据集。
- en: IV-C1 Space-Based versus Object-Based Models
  id: totrans-161
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C1 基于空间与基于对象的模型
- en: 'There is no consensus on the perceptual scale served by attention: Do we attend
    to stimulus locations, features, or objects? In the last 50 years, behavioral
    studies have broadly demonstrated the modulation of attention in several perceptual
    domains, including space, features, objects, and sensory modalities. The current
    belief is that attention can be deployed for each of these units, implying that
    there is no single attentional unit. However, classical studies’ main domain is
    spatial (i.e., location-based attention), which has been the focus of intense
    research since 1970\. This focus is not accidental - vision is an inherently spatial
    sense, and the first cortical stages of visual representation are spatially organized.
    Many important studies have documented spatial attention in modulating neural
    activities in the extra-striated cortex [[81](#bib.bib81)].'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
- en: Subsequently, other attentional selection domains that are not strictly spatial
    - feature-based and object-based became the focus of investigation in classical
    literature. Feature-based attention refers to selecting stimuli based on the values
    expressed within a specific feature dimension (e.g., yellow in the color dimension
    and left in the movement dimension). Saenz et al. [[82](#bib.bib82)] did experiments
    on humans using functional magnetic resonance imaging (fMRI) and observed that
    the magnitude of neural responses depends on the stimulus features in conjunction
    with spatial aspects to select spatial and non-spatial sensory information relevant
    to the task. While location and feature-based attention are widely studied, object-based
    has been the focus of behavioral research only for the past 25 years [[81](#bib.bib81)].
    Studies have revealed that attention can be directed to one or two spatially overlapping
    objects. O’Craven et al. [[83](#bib.bib83)] showed observers a spatial overlap
    between house and face. At any time, the test subjects should look at the house
    or face. The authors observed brain activity in selective cortical regions of
    faces and selective at home that depended on which of the two stimuli was attended
    to. They found that the magnitude of the motion-triggered signal in the MT area
    also depended on whether the assisted object was moving or not, suggesting that
    all assisted objects’ features were selected.
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: In our framework, location-based attention is an subsystem focused on stimulus
    localization existindo um peso atencional para cada estímulo do focus target,
    ou seja $a_{t,j}^{k}\in\mathbb{R}$. The feature-based attention is a subsystem
    focused on the target features, ou seja the focus output $a_{t,j}^{k}\in\mathbb{R}^{F_{\tau
    k}}$. In object-based attention an subsystem capable of focusing on the focus
    target’s semantic elements. For example, the focus target $\tau_{t}^{k}$ at time
    t maybe represent the set of $n_{\tau^{k}}$ pixels $px$, and attention subsystem
    select only the object. The focus output set $A=\left\{x\in\mathbb{Z}:0\leq x\leq
    1\right\}$, $a_{t}^{k}\in\mathbb{R}^{n_{\tau k}}$, and each position of $a_{t,j}^{k}$
    is 1 only if the pixels are inside object.
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 在我们的框架中，基于位置的注意力是一个子系统，专注于刺激定位，对每个焦点目标的刺激存在一个注意力权重，即 $a_{t,j}^{k}\in\mathbb{R}$。基于特征的注意力是一个子系统，专注于目标特征，即焦点输出
    $a_{t,j}^{k}\in\mathbb{R}^{F_{\tau k}}$。在基于对象的注意力中，一个子系统能够专注于焦点目标的语义元素。例如，时间 t
    的焦点目标 $\tau_{t}^{k}$ 可能代表 $n_{\tau^{k}}$ 个像素 $px$ 的集合，注意力子系统仅选择对象。焦点输出集 $A=\left\{x\in\mathbb{Z}:0\leq
    x\leq 1\right\}$，$a_{t}^{k}\in\mathbb{R}^{n_{\tau k}}$，并且 $a_{t,j}^{k}$ 的每个位置仅在像素在对象内部时为
    1。
- en: 'In this context, most models are data-driven and are exclusively location-based,
    as shown in Figure [3](#S4.F3 "Figure 3 ‣ IV A Taxonomy for Attention Models ‣
    Neural Attention Models in Deep Learning: Survey and Taxonomy") in f6\. Its main
    targets are the hidden states/embedding vectors, feature maps, external memory
    cells, and raw data from the neural network input stimuli. When the mechanisms
    are focused on hidden states or embedding vectors, the attentional weights assist
    in the construction of dynamic context vectors minimizing information bottleneck
    problems in multimodal approaches [[41](#bib.bib41)] [[67](#bib.bib67)], encoder-decoder
    structures [[34](#bib.bib34)], and embedding representation problems [[26](#bib.bib26)].
    Similarly, when applied to external memory cells, the mechanisms were able to
    different memory locations to build a dynamic vector of summarizing past experiences
    from the task’s current context. When location-based mechanisms are applied on
    feature-maps, they adjust the output of feature extractors to make target regions
    stand out in the presence of disturbing backgrounds seeking to imitate mechanisms
    in some regions of the human visual cortex. However, few location-based mechanisms
    focus directly on input stimuli from the neural network. Although there is a wide
    range of research in psychology and neuroscience focusing on spatial aspects of
    human vision, only RAM [[38](#bib.bib38)] (Section [V-C](#S5.SS3 "V-C Recurrent
    Attention Model (RAM): A visual attention system for image classification ‣ V
    Neural Attention Models ‣ Neural Attention Models in Deep Learning: Survey and
    Taxonomy")), DRAW [[40](#bib.bib40)] (Section [V-F](#S5.SS6 "V-F Deep Recurrent
    Attentive Writer (DRAW) ‣ V Neural Attention Models ‣ Neural Attention Models
    in Deep Learning: Survey and Taxonomy")), Spatial Transformer [[25](#bib.bib25)]
    and similar approaches explore location-based attention models on raw input image
    data. Spatial Transformer presents a particularly interesting approach, based
    on feature maps, the localization network determines the transformation parameters,
    which act as a context for the attentional system to select a local grid on the
    feature maps and apply the learned transformation minimizing the deformations
    of the focus region for the convolutional network in a classification task.'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: 'There are few purely feature-based, object-based, or hybrid approaches. Purely
    feature-based mechanisms are more common on feature maps in convolutional neural
    networks [[29](#bib.bib29)] [[30](#bib.bib30)] and in graph neural networks [[20](#bib.bib20)]
    [[84](#bib.bib84)] seeking to adjust the properties of features from global information
    or the vicinity of the target stimuli, in an attempt to highlight those that are
    most relevant to the target task. There are still few hybrid approaches with location
    and feature-based mechanisms in two stages of processing: 1) In the first stage,
    the features are weighted on the target, building useful context vectors for the
    second stage; 2) In the second stage, location-based mechanisms use the iteration
    over the features to guide the attentional focus on the location of the stimuli.
    There are also very few object-based approaches in the field. To the best of our
    knowledge, only Tang et al. [[35](#bib.bib35)] proposed an object-centered visual
    attention approach to generative models inspired by Shifter Circuit Model [[85](#bib.bib85)].
    It is a biologically plausible visual attention model to form invariant representations
    of scale and position of objects in the world. By controlling neurons driven by
    memory, it controls synaptic forces that guide the flow of spatially organized
    information in the primary visual cortex (V1) to upper cortical regions, allowing
    assisted objects to be represented in an invariant way in position and scale.
    Similarly, the model uses an attentional system with a retina-like representation
    to search for faces in a scene guided by signals present in associative memory.
    A series of canonical transformations learned during training help guide the focus
    on the image, selecting the patch of the face of interest. In a second stage,
    auxiliary mechanisms propagate the resulting signals to an associative memory
    represented by a Gaussian Deep Belief Networks (DBN) [[86](#bib.bib86)].'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 几乎没有完全基于特征、基于对象或混合方法的研究。完全基于特征的机制在卷积神经网络的特征图[[29](#bib.bib29)] [[30](#bib.bib30)]和图神经网络[[20](#bib.bib20)]
    [[84](#bib.bib84)]中更为常见，这些机制试图通过全局信息或目标刺激的附近调整特征的属性，以突出那些与目标任务最相关的特征。目前仍然很少有混合方法在处理的两个阶段中结合位置和特征机制：1）在第一阶段，特征在目标上加权，为第二阶段构建有用的上下文向量；2）在第二阶段，基于位置的机制使用对特征的迭代来引导注意力集中在刺激的位置。在该领域中，也很少有基于对象的方法。据我们所知，只有
    Tang 等人[[35](#bib.bib35)] 提出了一个以对象为中心的视觉注意力方法，该方法受 Shifter Circuit Model [[85](#bib.bib85)]
    启发。这是一种生物学上合理的视觉注意力模型，用于形成对象在世界上的尺度和位置的不变表示。通过控制由记忆驱动的神经元，它控制突触力量，从而引导空间组织信息在初级视觉皮层（V1）向上层皮层区域的流动，使辅助对象在位置和尺度上以不变的方式进行表示。类似地，该模型使用具有视网膜样表示的注意力系统来搜索场景中的面孔，并由联想记忆中存在的信号引导。训练过程中学到的一系列标准变换帮助引导图像上的注意力，选择感兴趣的面孔区域。在第二阶段，辅助机制将结果信号传播到由高斯深度信念网络（DBN）[[86](#bib.bib86)]
    表示的联想记忆中。
- en: IV-C2 Task-oriented versus Time-oriented Models
  id: totrans-167
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: IV-C2 任务导向与时间导向模型
- en: 'When the target is a program, the attentional mechanism intuitively seeks to
    answer the following questions: Among all these networks, which should be chosen
    to perform an answer/task? How much computing time should be spent for each neural
    structure ?. The task-oriented selection subsystem chooses one (or more) programs
    to be executed next. We can consider the target set $T$ to be the set of possible
    $N$ programs and attention to select the most appropriate for the task in time
    $t$. Time-oriented selection attention chooses how much computing time to allocate
    to each program given a computational time budget. For example, the framework
    contains several neural networks $\tau_{t}=\{\tau_{t}^{1},\tau_{t}^{2},\tau_{t}^{3}\}$to
    be executed. The attention subsystem must decide how much computation to spend,
    from the budget $B$, on each neural network $\tau_{t}^{k}$. The focus output is
    $a_{t}=\{a_{t}^{1},a_{t}^{2},a_{t}^{3}\}$, $a_{t}^{1}+a_{t}^{2}+a_{t}^{3}=1$,
    and the amount of computation for each program can be calculated as $a_{t}^{k}B$.'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 当目标是一个程序时，注意力机制直观地寻求回答以下问题：在所有这些网络中，应该选择哪个来执行答案/任务？每个神经结构应花费多少计算时间？任务导向的选择子系统选择一个（或多个）程序进行下一步执行。我们可以认为目标集
    $T$ 是可能的 $N$ 个程序的集合，注意力选择最适合任务的程序，在时间 $t$ 内。时间导向选择注意力决定在给定计算时间预算的情况下，为每个程序分配多少计算时间。例如，框架包含几个神经网络
    $\tau_{t}=\{\tau_{t}^{1},\tau_{t}^{2},\tau_{t}^{3}\}$ 需要执行。注意力子系统必须决定从预算 $B$ 中花费多少计算量在每个神经网络
    $\tau_{t}^{k}$ 上。焦点输出为 $a_{t}=\{a_{t}^{1},a_{t}^{2},a_{t}^{3}\}$，$a_{t}^{1}+a_{t}^{2}+a_{t}^{3}=1$，每个程序的计算量可以计算为
    $a_{t}^{k}B$。
- en: 'Few architectures in the area target a neural network (Figure [3](#S4.F3 "Figure
    3 ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy") in f9 and f10). Adaptive Computation Time (ACT) [[51](#bib.bib51)]
    chooses how many auxiliary computing substeps will be performed by a recurring
    structure in a $t$time frame. The structure decides how a computing budget will
    be allocated, controlling when the recurring structure should stop and generate
    the final output $y_{t}$based on the auxiliary outputs. The Attentional Correlation
    Filter Network [[61](#bib.bib61)] directs the attentional focus on a different
    set of feature extractors based on previous deep regression network validation
    scores, determining which set of extractors each time step $t$ must be activated
    to receive the input image stream. The previous validation scores work as context
    information giving feedback to the attentional system about the performance of
    the general system in the task, from that feedback attention can regulate the
    focus points for the next iteration. Modality Shifting Attention [[73](#bib.bib73)]
    has a task-oriented mechanism responsible for shifting attention between the neural
    network that captures visual sensory stimuli and the neural network that captures
    linguistic stimuli. The system is guided by a context represented by the question
    about a sequence of images and captions for question-answering tasks. In STRAW
    [[48](#bib.bib48)] a task-oriented attentional mechanism controls the activation
    of read, write and the time-advance structure over the action-plan and the commitment-plan
    controlling when the data-oriented attentional mechanisms must on updating a trained
    agent’s plans via Reinforcement Learning.'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 在该领域中，少数架构针对神经网络（见图 [3](#S4.F3 "图 3 ‣ IV A 注意力模型的分类 ‣ 深度学习中的神经注意力模型：调查与分类")，位于
    f9 和 f10）。自适应计算时间（ACT）[[51](#bib.bib51)] 选择在 $t$ 时间框架内由递归结构执行多少个辅助计算子步骤。该结构决定计算预算的分配方式，控制递归结构何时停止并基于辅助输出生成最终输出
    $y_{t}$。注意力相关滤波网络 [[61](#bib.bib61)] 根据之前深度回归网络的验证分数，将注意力集中在不同的特征提取器集上，确定每个时间步
    $t$ 必须激活哪个特征提取器集以接收输入图像流。之前的验证分数作为上下文信息反馈给注意力系统，关于任务中一般系统的表现，从这些反馈中，注意力可以调节下一次迭代的关注点。模态转换注意力
    [[73](#bib.bib73)] 具有一个任务导向的机制，负责在捕捉视觉感官刺激的神经网络和捕捉语言刺激的神经网络之间转移注意力。该系统由一个上下文指导，该上下文通过图像序列和问题回答任务的标题表示。在
    STRAW [[48](#bib.bib48)] 中，任务导向的注意力机制控制对行动计划和承诺计划的读、写以及时间推进结构的激活，控制数据导向的注意力机制何时需要通过强化学习来更新训练代理的计划。
- en: IV-D Bottom-Up versus Top-Down Models
  id: totrans-170
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-D 自下而上 versus 自上而下模型
- en: A big difference between the models is whether they depend on bottom-up influences,
    top-down influences, or a combination of both. Bottom-up or involutory attention
    is determined by the characteristics of the input stimuli (ie, stimulus-driven),
    while top-down cues are determined by cognitive phenomena such as knowledge, expectation,
    reward and current goals (ie, goal-driven). Stimuli that attract attention in
    a bottom-up manner are sufficiently distinct concerning the surrounding characteristics.
    As a result, attention is exogenous, automatic, reflective, and feed-forward.
    A typical example of bottom-up attention is to look at a scene with just one horizontal
    bar between several vertical bars where attention it is immediately directed to
    the horizontal bar. On the other hand, top-down attention to be a voluntary process
    deliberated by the individual, in which a particular location, feature, or object
    is relevant to current behavioral goals. Such a process is guided by elements
    of a high semantic level, such as motivation, expectation, private interests,
    rewards, and social motivations [[1](#bib.bib1)]. In our framework, bottom-up
    attention is guided by the focus target’s discrepancies, whether or not there
    is a contextual entry $c_{t}$. However, the context comes from information from
    the target’s own set of stimuli. If the attention is guided by contextual information
    from other sensory sources, external or previous memories, the attention is top-down.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: Additionally, we consider an additional classification regarding the presence
    of context or the previous inner state of attention. In this sense, the bottom-up
    and top-down mechanisms can still be stateful or stateless. In stateful the attentional
    subsystem considers context and inner information as part of the input set (ie,
    $i_{t-1}$$\neq$$\emptyset$or $c_{t}$$\neq$$\emptyset$), otherwise the subsystem
    implements the stateless selection. The bottom-up stateless mechanisms have no
    previous context or inner states of attention as part of the input, so the attentional
    focus is assigned only through the internal extraction of the target’s discrepancies.
    The bottom-up stateful mechanisms can have contextual and previous inner state-input
    simultaneously, or just one of the options. However, the context extracted externally
    comes from the current target. In the inner state, it represents the previous
    state of attention on the same target. That is, the target does not change over
    time. There are no top-down stateless mechanisms since a condition for the existence
    of top-down influences is the presence of a context external to the current target.
    For the existence of top-down stateful mechanisms, the presence of context as
    input is mandatory, with the presence of the previous inner state being optional.
    Besides, the context refers to previous memories, external memories, or elements
    from other sensory sources other than the target.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: 'The mechanisms explore top-down and bottom-up influences seeking to answer
    one of two questions: 1 intuitively) Where to look at the target given the alignment
    observed between it and the context? 2) In the absence of context, where should
    I look, given the discrepancies and similarities between the target elements?
    Some models answer the first question by extracting the context directly from
    the target, that is, using bottom-up influences. The encoder stack of Neural Transformer
    [[18](#bib.bib18)] (Section [V-H](#S5.SS8 "V-H Neural Transformer ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")) models
    a bottom-up attentional system completely guided by low-level contexts extracted
    directly from the target of the attentional system. In each encoder, an input
    $I$ is decomposed into a set of queries, keys, and values extracted in parallel.
    In the initial stage of attention, queries act as a low-level context and keys
    as a target, producing attentional masks. In the second stage, these masks and
    the values make up the context vector to guide the attentional focus on the original
    $I$ input that will be input to a new attentional encoder, resulting in a chain
    of bottom-up attentional systems with a low-level context.'
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
- en: 'Typically, attention-based graph neural networks use a combination of bottom-up
    mechanisms to guide attentional focus with and without context. Graph Attention
    Networks [[20](#bib.bib20)] (Section [V-I](#S5.SS9 "V-I Graph Attention Networks
    (GATs) ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")) targets a set of neighboring nodes and from the discrepancies
    between that set defines different attentional weights for each feature. In the
    second stage, this answer is used as a context by another bottom-up and location-based
    subsystem on the set of neighboring input nodes. The final composition between
    the attentional map and all nodes generates an embedding with the neighborhood’s
    representativeness for a specific node. Similarly, Heterogeneous Graph Attention
    Network [[84](#bib.bib84)] uses two bottom-up attention mechanisms at the node
    level and bottom-up mechanisms at the semantic level to capture various types
    of semantic information between heterogeneous graphs.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
- en: In convolutional networks, the bottom-up mechanisms are present when the target
    is a set of feature maps. Usually, only inter-channel or intra-channel discrepancies
    guide attention by promoting boost features or recalibrating channels. The attentional
    mechanism of Squeeze-and-Excitation Networks [[29](#bib.bib29)], a pioneering
    approach in the area, receives as a focus target a set of feature maps, generates
    channel-wise statistics using global average pooling. Based on these statistics,
    it captures channel-wise dependencies capable of learning non-linear iterations
    between channels. Finally, re-scale each input channel in a feature-based approach.
    Double Attention Networks [[30](#bib.bib30)], in a similar but location-based
    approach, uses as feature context maps from the same convolutional layer (i.e.,
    bottom-up) or different layers (i.e., top-down) as a context for defining relations
    between the elements, whose main objective is based on the extracted relations
    to ponder the regions of the feature maps of a convolutional layer. Finally, the
    SNAIL [[28](#bib.bib28)] via bottom-up captures temporal relationships between
    feature maps in a meta-learner approach using self-attention mechanisms similar
    to Transformer.
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 在卷积网络中，当目标是一组特征图时，底向上的机制存在。通常，只有通道间或通道内的差异通过提升特征或重新校准通道来引导注意力。Squeeze-and-Excitation
    Networks [[29](#bib.bib29)] 的注意力机制，作为该领域的开创性方法，以一组特征图作为关注目标，使用全局平均池化生成通道级统计数据。基于这些统计数据，它捕捉通道级依赖关系，能够学习通道之间的非线性迭代。最后，以基于特征的方法重新缩放每个输入通道。Double
    Attention Networks [[30](#bib.bib30)] 采用类似但基于位置的方法，使用来自同一卷积层（即底向上）或不同层（即顶向下）的特征上下文图来定义元素之间的关系，其主要目标是基于提取的关系来调整卷积层特征图的区域。最后，SNAIL
    [[28](#bib.bib28)] 通过底向上的方法，利用类似 Transformer 的自注意力机制在元学习者方法中捕捉特征图之间的时间关系。
- en: 'However, most area approaches are top-down stateful, as shown in Figure [3](#S4.F3
    "Figure 3 ‣ IV A Taxonomy for Attention Models ‣ Neural Attention Models in Deep
    Learning: Survey and Taxonomy"). The first mechanism was proposed for RNNSearch
    [[34](#bib.bib34)] in mid-2014, in which the context received as input is directly
    responsible for the dynamic change of the context vector $c_{t}$received by the
    decoder at each time step $t$. Similarly, Xu et al. [[41](#bib.bib41)] used information
    from the decoder’s previous hidden state to guide a location-based mechanism through
    regions of the input image in a multimodal question-answering approach. Networks
    with internal and external memory are usually top-down structures. End-to-End
    Memory Networks [[19](#bib.bib19)] uses an external query for a question as a
    context to search and focus on memory cells more related to the question’s content.
    Neural Turing Machine [[37](#bib.bib37)] uses as context parameters issued by
    the network controller that define content-based and location-based addressing
    in external memory. Sparse Attentive Backtracking [[59](#bib.bib59)][[60](#bib.bib60)]
    applies an attentional sparse memory recovery method to build the next hidden
    state of an RNN, using the provisional hidden state $\widehat{h}^{(t)}$ and target
    all previously processed memories. The mechanism acts as a method capable of blaming
    or giving credit to previous memories, similarly to what human beings do, without
    the need to repeat all events from the present until the credited event, managing
    to capture long-distance dependencies between states efficiently. Zhang et al.
    [[54](#bib.bib54)] used top-down attention to propose Excitation Backprop - a
    new backpropagation scheme based on biological evidence from Winner-Take-All (WTA)
    competition [[87](#bib.bib87)] among visual filters and the Selective Tuning Model
    [[88](#bib.bib88)] selectively adjust a visual processing system through a top-down
    hierarchy of winner-take-all processes embedded in the visual processing pyramid.
    Similarly, Excitation Backprop uses a probabilistic WTA on CNNs to promote excitatory
    or inhibitory connections between neighboring neurons from top-down influences
    from previously visited neurons.'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: 'Co-attention structures are also typically top-down. There are attentional
    mechanisms propagating attention in this structure in two ways: from the query
    to the context and from the context to the query. Dynamic Coattention Networks
    [[55](#bib.bib55)] computes attentional scores in this way. The mechanisms produce
    weights for each word in the question based on document words as context, just
    as they produce weights for each word in the document based on question words
    as context. Similarly, Hypergraph Attention Networks [[67](#bib.bib67)] computes
    attention between two hypergraphs comparing the semantics between two symbolic
    representations of different sensory sources.'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: 'Some structures are hybrid and use both levels of influence to guide attention.
    Neural Transformer [[18](#bib.bib18)] (Section [V-H](#S5.SS8 "V-H Neural Transformer
    ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning: Survey
    and Taxonomy")) stands out as the main hybrid structure in the area. It has a
    completely bottom-up encoder and a hybrid decoder so that the first attentional
    system is bottom-up and processes the translated words. In contrast, the second
    is top-down for using the last encoder’s attentional information as a context
    to guide attention on the target, represented by the words previously translated.
    Following the structure of Transformer, recently BRIMs [[72](#bib.bib72)] presented
    hybrid mechanisms to carry out communication between RIMs modules. Bottom-up attentional
    subsystems communicate between modules of the same layer, as well as the composition
    of hidden states in initial layers using the entry $x_{t}$ as the target, and
    via top-down attention modules in different layers communicate with each other
    requesting information about hidden states of previous and posterior layers to
    compose the current hidden state.'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: '一些结构是混合型的，使用两种影响级别来引导注意力。神经转换器 [[18](#bib.bib18)]（第 [V-H](#S5.SS8 "V-H Neural
    Transformer ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")节）在这一领域中作为主要的混合结构脱颖而出。它具有完全的自下而上的编码器和混合解码器，使得第一个注意力系统是自下而上的，处理翻译后的单词。相比之下，第二个注意力系统是自上而下的，利用最后一个编码器的注意力信息作为上下文来引导对目标的注意力，目标由之前翻译的单词表示。沿用转换器的结构，最近
    BRIMs [[72](#bib.bib72)] 提出了混合机制以实现 RIMs 模块之间的通信。自下而上的注意力子系统在同一层的模块之间进行通信，以及在初始层中使用输入
    $x_{t}$ 作为目标的隐藏状态的组合，而通过不同层的自上而下注意力模块之间相互通信，请求关于前后层隐藏状态的信息，以组成当前隐藏状态。'
- en: 'IV-E Continuity: Soft versus Hard'
  id: totrans-179
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-E 连续性：软选择与硬选择
- en: The selection may occur either by choosing a discrete subset of the possible
    choices or by performing a soft (or continuous) giving real-valued scores to the
    possible choices. The different types of selection can be implemented with modules
    by appropriately choosing the focus output set$A$. If $A=\left\{x\in\mathbb{R}:0<x<1\right\}$
    the selection is soft, and$A=\left\{x\in\mathbb{Z}:0\leq x\leq 1\right\}$ the
    selection is hard.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
  zh: 选择可能通过选择可能选择的离散子集来进行，也可能通过对可能选择给予真实值分数的软（或连续）方式来进行。如果$A=\left\{x\in\mathbb{R}:0<x<1\right\}$，则选择是软选择，而$A=\left\{x\in\mathbb{Z}:0\leq
    x\leq 1\right\}$，则选择是硬选择。
- en: In Deep Learning, the mechanisms are mainly divided into the following categories:1)
    hard attention determines whether a part of the mechanism’s input should be considered
    or not, reflecting the interdependence between the input of the mechanism and
    the target of the deep neural network. The weight assigned to an input port is
    either 0 or 1; 2) soft attention divides attentional weights between 0 and 1 for
    each input element so that the sum of all weights is equal to 1\. It decides how
    much attention should be focused on each element, considering the interdependence
    between the input of the deep neural network’s mechanism and target; 3) self-attention
    quantifies the interdependence between the input elements of the mechanism. This
    mechanism allows the inputs to interact with each other ”self” and determine what
    they should pay more attention to. There are also some secondary categories:1)
    global attention is a simplification of the classic soft attention proposed for
    encoder-decoder frameworks; 2) local attention is a tradeoff between hard and
    soft attention; 3) co-attention assigns attention from both the context to the
    target and from the target to the context, and 4) hierarchical attention presents
    mechanisms adapted to deal with hierarchical structures at different levels of
    granularity. Concerning continuity, the mechanisms classified as hard attention
    have hard continuity according to our taxonomy, and all other mechanisms in the
    area have soft continuity.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
- en: 'There is still no systematic study to determine the advantages and disadvantages
    of hard and soft continuity mechanisms. However, there is a wide range of soft
    continuity mechanisms, as shown in the Figure [V](#S5 "V Neural Attention Models
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") in f13 and f14\.
    One justification is that the hard mechanisms, in most cases, make the architecture
    non-differentiable, requiring more elaborate training strategies, such as Reinforcement
    Learning (RL) or even hybrid supervised and RL [[38](#bib.bib38)] approaches.
    Usually, these strategies are still little explored in computer vision and natural
    language processing - where the main neural attention models are - because they
    require the well-designed design of the reward functions, which is not always
    intuitive or necessary when there is ground truth, available for training via
    supervised learning. Currently, few architectures in the area use both mechanisms
    simultaneously. Pointer Networks [[42](#bib.bib42)] features a soft mechanism
    for distributing attention over all input elements, followed by a hard mechanism
    for choosing one as an output at each stage of the decoder. Modality Shifting
    Attention [[73](#bib.bib73)] uses a hard mechanism to switch between different
    sensory modalities and soft continuity mechanisms to reason about the final prediction
    of the network.'
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: V Neural Attention Models
  id: totrans-183
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this section, we discuss some of the main neural attention models from the
    theoretical perspective of attention. A timeline summarizing the main developments
    and their main contributions is shown in Figure [4](#S5.F4 "Figure 4 ‣ V Neural
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy").
    In the [V-A](#S5.SS1 "V-A RNN Search: the beginning ‣ V Neural Attention Models
    ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") section we discuss
    RNNSearch [[34](#bib.bib34)], in the [V-B](#S5.SS2 "V-B Neural Turing Machine:
    An attention-augmented memory approach ‣ V Neural Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy") section we discuss Neural Turing
    Machine [[37](#bib.bib37)], in the [V-C](#S5.SS3 "V-C Recurrent Attention Model
    (RAM): A visual attention system for image classification ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") we discussed
    RAM [[38](#bib.bib38)], in the [V-D](#S5.SS4 "V-D End-To-End Memory Networks (EMNet):
    A memory-based end-to-end attention system ‣ V Neural Attention Models ‣ Neural
    Attention Models in Deep Learning: Survey and Taxonomy") section we discussed
    the End-to-End Memory Networks [[19](#bib.bib19)], in the [V-E](#S5.SS5 "V-E Show,
    Attend and Tell: A multimodal approach ‣ V Neural Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy") we discussed the Show, Attend and
    Tell [[41](#bib.bib41)], in the [V-F](#S5.SS6 "V-F Deep Recurrent Attentive Writer
    (DRAW) ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy") section we discussed the DRAW [[40](#bib.bib40)], in the
    [V-G](#S5.SS7 "V-G Bi-Directional Attention Flow (BiDAF) ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") section
    we discussed the BiDAF [[47](#bib.bib47)], in the [V-H](#S5.SS8 "V-H Neural Transformer
    ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning: Survey
    and Taxonomy") section a Neural Transformer [[18](#bib.bib18)], finally in the
    section [V-I](#S5.SS9 "V-I Graph Attention Networks (GATs) ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy") we discussed
    a GATs [[20](#bib.bib20)].'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/026fb3a1283ec9be8791c6b39bb4e7f3.png)'
  id: totrans-185
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: Timeline illustrating the main key developments from 2014 to the
    present day. RNNSearch [[34](#bib.bib34)] presented the first attention mechanism.
    Neural Turing Machine [[37](#bib.bib37)] and Memory Networks [[89](#bib.bib89)]
    introduced memory and dynamic flow control. RAM [[38](#bib.bib38)] and DRAW [[40](#bib.bib40)]
    learned to combine multi-glimpse, visual attention, and sequential processing.
    Spatial Transformer [[25](#bib.bib25)] introduced a module to increase the robustness
    of CNNs to variations. Show, attend and tell [[41](#bib.bib41)] created attention
    for multimodality. Pointer Networks [[42](#bib.bib42)] presented attention as
    a pointer. BiDAF [[47](#bib.bib47)], HAN [[53](#bib.bib53)], and DCN [[55](#bib.bib55)]
    presented attentional techniques to align data with different hierarchical levels.
    ACT [[51](#bib.bib51)] introduced the computation time topic. Neural Transformer
    [[18](#bib.bib18)] was the first self-attentive neural network with an end-to-end
    attention approach. GATs [[20](#bib.bib20)] introduced attention in GNNs. BERT
    [[90](#bib.bib90)], GPT-2 [[91](#bib.bib91)], GPT-3 [[92](#bib.bib92)], and DALLE
    [[93](#bib.bib93)] are state of the art in language models and text-to-image generation.
    Finally, BRIMs [[72](#bib.bib72)] learned to combine bottom-up and top-down signals.'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: 'V-A RNN Search: the beginning'
  id: totrans-187
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'RNNSearch [[34](#bib.bib34)] uses attention for machine translation. The purpose
    is compute an output sequence y that is translation from input sequence x. The
    architecture consists of an encoder followed by a decoder, as shown in Figure
    [2](#footnote2 "footnote 2 ‣ Figure 5 ‣ V-A RNN Search: the beginning ‣ V Neural
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy").
    The encoder is a bidirectional RNN (BiRNN) that consist of forward and backward
    RNN’s for compute an annotation term $h_{j}$. The forward RNN $\overrightarrow{f}$
    reads the input sequence in the order of $x_{1}$ to $x_{N}$ and calculates the
    forward hidden state sequence ($\overrightarrow{h_{1}},...,\overrightarrow{h_{N}}$).
    The backward RNN reads the sequence in the reverse order $\overleftarrow{f}$,
    (from $x_{N}$ to $x_{1}$), resulting in the backward hidden states sequence ($\overleftarrow{h_{1}},...,\overleftarrow{h_{N}}$).
    The annotation $h_{j}$, for each word $x_{j}$, is the concatenation of the $\overrightarrow{h_{j}}$
    and $\overleftarrow{h_{j}}$ as follows'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $(h_{1},...,h_{N})=Encoder(x_{1},...,x_{N})$ |  | (1) |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
- en: '|  | $h_{j}=[\overrightarrow{h_{j}};\overleftarrow{h_{j}}]^{T}$ |  | (2) |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
- en: 'The decoder consists of classic RNN and attention system. The classic RNN calculates
    from a context vector $c_{t_{decoder}}$ a probability distribution for all possible
    output symbols:'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $p(y_{t}&#124;y_{1},...,y_{t-1},x)=RNN_{decoder}(c_{t_{decoder}})$ |  |
    (3) |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
- en: 'The attentional system has only one subsystem (Figure [2](#footnote2 "footnote
    2 ‣ Figure 5 ‣ V-A RNN Search: the beginning ‣ V Neural Attention Models ‣ Neural
    Attention Models in Deep Learning: Survey and Taxonomy")) that receives information
    from a single sensory modality (i.e., textual). At each time step t, the subsystem
    takes as input a contextual $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1}\right\}=\left\{s_{t-1}\right\}$,
    a focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{h_{1},...,h_{N}\right\}$,
    and produces attention weights $a_{t}=\left\{a_{t}^{1}\right\}=\left\{a_{t,1}^{1},...,a_{t,N}^{1}\right\}=\left\{a_{1},...,a_{N}\right\}$
    as output, where $s_{t-1}\in\mathbb{R}^{1\times d}$ is the decoder’s previous
    hidden state, $h_{j}\in\mathbb{R}^{1\times d}$ is encoder annotation vector, $a_{t}^{1}\in\mathbb{R}^{1\times
    N}$ are the weights of attention over all the encoder’s annotation vectors. The
    focus target is processed by alignment function $e_{t,j}=a(s_{t-1},h_{j})$ to
    obtain a set scores $e_{t,j}$ that reflects the importance of $h_{j}$ with respect
    $s_{t-1}$ in deciding the next state $s_{t}$ and generating $y_{t}$. The alignment
    function $a$ is a feedforward neural network which is jointly trained with the
    framework. The scores are normalized through a softmax function to obtain attention
    weights $a_{j}=\frac{e^{e_{t,j}}}{\sum_{j=1}^{N}e^{e_{t,j}}}$. Finally, a weighted
    sum over enconder’s hidden states generates the dynamic context vector $c_{t_{decoder}}=\sum_{j=1}^{N}a_{j}h_{j}$
    $\in\mathbb{R}^{1\times d}$.'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, attention decides which parts of the source sentence pay attention.
    Allowing the decoder to have this mechanism is unnecessary to encode a context
    vector of fixed size. Instead, the information is spread throughout the annotation
    sequence and can be selectively retrieved by the decoder as needed. By assigning
    attention simultaneously and continuously to each $h_{j}$, the selection is soft
    and divided. Top-down stateful since a previous decoder’s state represents a context.
    Location-based since the purpose of attention is to weigh the stimuli $h_{j}$
    by assigning the same weight to all features. Finally, the the system is cognitive
    and oriented for differently selecting the same focus target in latent space at
    each time step $t$.
  id: totrans-194
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c49ae2f6ee478b572c82aa3c0db98543.png)'
  id: totrans-195
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: RNNSearch [[34](#bib.bib34)] architecture illustration²²2[https://github.com/larocs/attention_dl/blob/master/imgs](https://github.com/larocs/attention_dl/blob/master/imgs).
    The encoder generates a set of hidden states, which are the input for the only
    attention system. The divided attention shares the focus between the different
    stimuli, and in a top-down way, it generates a dynamic context vector for a decoder.'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: 'V-B Neural Turing Machine: An attention-augmented memory approach'
  id: totrans-197
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Neural Turing Machine [[37](#bib.bib37)] uses attention for algorithmic tasks.
    The architecture consists of a controller, heads, external memory, and attention
    system, as shown in Figure [6](#S5.F6 "Figure 6 ‣ V-B Neural Turing Machine: An
    attention-augmented memory approach ‣ V Neural Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy"). The controller is a feedforward
    or recurrent network, which interacts with the outside world and the attentional
    system to manipulate memory through reading and writing heads. The memory $M_{t}=\left\{M_{t,0},...,M_{t,N-1}\right\}$
    $\in$ $\mathbb{R}^{N\times M}$ is an matrix, where $N$ is amount number of memory
    cells, and $M$ is amount number of memory cell’s features. The attentional system
    uses the controller parameters to define each reading/writing operation’s focus
    determining the importance degree at each location. So, a single head can attend
    an individual cell or weakly in several cells.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/c3e83dc7b7352d2ebc043e282cbe9288.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: Neural Turing Machine [[37](#bib.bib37)] architecture illustration.
    The architecture has a controller, an external memory, read/write heads, and an
    attentional system. At each time step $t$, the attentional system, guided by the
    controller’s parameters, defines the memory locations that will be read and written.
    The system is oriented, divided, location-based, top-down stateful, cognitive
    and soft.'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: At each time step $t$, the system receives as input a focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{M_{t,0},...,M_{t,N-1}\right\}$
    with all memory content, and a contextual input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1},c_{t,2}^{1},c_{t,3}^{1},c_{t,4}^{1},c_{t,5}^{1}\right\}=\left\{k_{t},\beta_{t},g_{t},s_{t},\gamma_{t}\right\}$
    with controller outputs, where $k_{t}\in\mathbb{R}^{M}$ is the key vector, $\beta_{t}\in\mathbb{R}$
    is the key strength, $g_{t}\in\mathbb{R}$ is the interpolation gate, $s_{t}\in\mathbb{R}^{2k+1}$
    is the shift weight, and $\gamma_{t}\geq 1$ is the sharpening weight. Unlike most
    of the attentional systems, this system receives as input the past inner state
    $i_{t-1}=\left\{a_{t-1}\right\}$, which is the attentional mask in the previous
    time. The attentional system acts as an interface between the controller and read/write
    heads. It has two addressing steps - the first focuses on content, and the second
    is focusing on location. This structure is very similar to VOCUS [[94](#bib.bib94)],
    an classic visual attention model proposed by Fintrop in 2006\. Content addressing
    resembles the bottom-up step, and the subsequent processing is similar VOCUS top-down
    step.
  id: totrans-201
  prefs: []
  type: TYPE_NORMAL
- en: Content addressing is inspired by the Hopfield Network, but with a simple retrieval
    mechanism. It is based on similarity between the memories and an approximation
    vector issued by the controller. Specifically, the key vector $k_{t}$ is compared
    to each vector $M_{t,i}$ by a similarity function $K\left(k_{t},M_{t,i}\right)=\frac{k_{t}M_{t,i}}{\left\|k_{t}\right\|\left\|M_{t,i}\right\|}$,
    producing content addressing weights $w_{t}^{c}\in\mathbb{R}^{N}$, composed by
    $w_{t,i}^{c}=\frac{e^{\beta_{t}K\left(k_{t},M_{t,i}\right)}}{\sum_{j=0}^{N-1}e^{\beta_{t}K\left(k_{t},M_{t,j}\right)}}$,
    where $K$ is the cosine similarity.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
- en: 'Content addressing is very efficient, but in some tasks, it needs a recognizable
    spatial address. Location-based addressing facilitates simple iteration with three
    main steps - interpolation, convolutional shift, and sharpening. Interpolation
    controls the use of the content-based addressing mask. The gate $g_{t}\in\left[0,1\right]$
    combines the past inner state $a_{t-1}$ with the $w_{t}^{c}$. If the gate is zero,
    the content weighting is ignored. If the gate is one, the previous attentional
    mask is ignored, and the system uses only content-based addressing. After interpolation,
    the convolutional shift allows the current focus to change and serve adjacent
    memory locations. This mechanism, is a one-dimensional circular convolution, where
    the shifting weight $s_{t}$ is the kernel to be convolved on the output’s interpolation:'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $w_{t}^{g}=g_{t}w_{t}^{c}+\left(1-g_{t}\right)a_{t-1}$ |  | (4) |'
  id: totrans-204
  prefs: []
  type: TYPE_TB
- en: '|  | $\tilde{w_{t,i}}=\sum_{j=0}^{N-1}w_{t}^{g}\left(j\right)s_{t}\left(i-j\right)$
    |  | (5) |'
  id: totrans-205
  prefs: []
  type: TYPE_TB
- en: where $g_{t}\in\mathbb{R}$ is the interpolation gate, $a_{t-1}\in\mathbb{R}^{N}$
    are the attention weights of the previous time step, $s_{t}$ is a normalized distribution
    over the allowed integer displacements.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, $s_{t}$ represents the displacement instructions. If only one offset
    position is allowed (i.e, $k=1$), $s_{t}$ will be a vector consisting of 3 elements,
    which can be interpreted by following instructions $\left\{\right.$ shift 1 forward,
    maintain focus, shift 1 backward $\left.\right\}$. In the general case, $s_{t}$
    will have $2k+1$ elements, where $k$ is the highest absolute displacement value.
    To avoid very high dispersions, the sharpening step takes $\tilde{w_{t}}$ and
    $\gamma_{t}$ to adjust the sharpness of the weights generating the final attention
    mask $a_{t}\in\mathbb{R}^{N}$, composed by weights $a_{t,i}=\frac{\tilde{w_{t,i}}^{\gamma^{t}}}{\sum_{j=0}^{N-1}\tilde{w_{t,j}}^{\gamma^{t}}}$
    for each memory cell $i$.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: The reading head takes the attentional reading mask and the memory for generate
    as output $r_{t}\leftarrow\sum_{i}^{N}a_{t,i}M_{t,i}\in\mathbb{R}^{M}$, defined
    as a convex combination of memory cells. Similarly, the writing head takes the
    attentional writing mask to erases and adds data in memory. The elements in memory
    cell $i$ are reset to zero if $a_{t,i}$ and the erase element are one; if $a_{t,i}$
    or the erase is zero, the memory will not be changed. When multiple heads are
    present, erasures can be performed in any order, as multiplication is commutative.
    The combined erase and add operations of all writing heads produce the final memory
    contents in time $t$. Specifically,
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{M}_{t,i}\leftarrow M_{t-1,i}\left[1-a_{t,i}e_{t}\right]$ |  |
    (6) |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
- en: '|  | $M_{t,i}\leftarrow\tilde{M}_{t,i}+a_{t,i}add_{t}$ |  | (7) |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
- en: where $M_{t,i}\in\mathbb{R}^{M}$ is the memory cell $i$, $\tilde{M}_{t,i}\in\mathbb{R}^{M}$
    is the memory cell $i$ with the content deleted, $a_{t,i}\in\mathbb{R}$ is the
    attentional weight for memory cell $i$, $e_{t}\in\mathbb{R}^{M}$, such that $e_{t}=\left\{x\in\mathbb{R}:0\leq
    x\leq 1\right\}$ is the erasure vector, $add_{t}\in\mathbb{R}^{M}$ is the vector
    with content to be added in memory, 1 is a row-vector of all 1-s, and the multiplication
    against the memory cell is point-wise. Note that both the delete and add vectors
    have independent $M$ components, allowing for refined control over which elements
    in each cell location are modified.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: 'NTM’s attentional system has location, soft, oriented and divided properties,
    since weights attentional mask respect the constraint $\sum_{i=1}^{N-1}a_{t,i}=1$
    e suas intensidades em cada local se alteram no tempo. The system is top-down
    stateful por ser influenciado por parâmetros estimados pelo controlador, and cognitive
    for atuar sobre os heads. Este mecanismo introduziu duas características importantes
    da cognição humana: estruturas de ligação variável e o processamento procedural.'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'V-C Recurrent Attention Model (RAM): A visual attention system for image classification'
  id: totrans-213
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'RAM [[38](#bib.bib38)] uses attention for image classification. The architecture
    consists of the attention system, glimpse sensor, glimpse network, location network,
    core network, and action network (Figure [7](#S5.F7 "Figure 7 ‣ V-C Recurrent
    Attention Model (RAM): A visual attention system for image classification ‣ V
    Neural Attention Models ‣ Neural Attention Models in Deep Learning: Survey and
    Taxonomy")). First, the glimpse sensor extracts a retina-like representation $\rho_{t}$
    around localization $l_{t-1}$. It encodes the region around $l_{t-1}$ in high-resolution,
    and progressively uses a low-resolution representation for the farthest pixels
    of $l_{t-1}$. At each time step $t$, the attention system inside glimpse sensor
    selects $N_{s}$ square patches centered in $l_{t-1}$. The first path being $g_{w}\times
    g_{w}$ pixels in size, and each subsystem produces successive patches having twice
    the width of the previous.'
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: The attention system is similar classic visual attention approches with programmed
    microsaccades designed in the 1990s [[95](#bib.bib95)]. Itti et al. [[95](#bib.bib95)]
    presented the first practical approache to microsaccades based on a competitive
    structure – Winner-takes-all (WTA) mechanisms jointly inhibition and return strategy
    [[95](#bib.bib95)]. Differently, RAM uses reinforcement learning in a sequential
    structure to determine the best policy for microsaccades, and uses only top-down
    stateful attention to modulate the focus, while the classic systems have even
    explored bottom-up, top-down and hybrid approaches. The RAM is an exception with
    selective perception, hard, selective and oriented attention simultaneously. It
    adopts a location-based system while hybrid approches with feature-based and location-based
    are biologically plausible and widely used in historical models. In most classic
    visual attention systems was common an feature-based approach to modulating low-level
    features (i.e., color, intensity, and orientation), and after merging all stimulus
    an location-based attention finds the regions to be attended.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: With some divergences from the classic visual attention models, RAM presents
    several attentional subsystems in parallel, where each takes the same focus target
    as input $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{x_{t}\right\}$,
    where $x_{t}$ is input image, and a different scale factor in each contextual
    input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1},c_{t,2}^{1},c_{t,3}^{1}\right\}=\left\{l_{t-1},s_{i},bd\right\}$,
    where $l_{t-1}\in\mathbb{R}^{2}$, $s_{i}\in\mathbb{R}$ is the scale factor $i$,
    $bd\in\mathbb{R}$ is the sensor bandwidth. And produces as output an attention
    mask $a_{t}$ = $\left\{a_{t}^{1}\right\}$ = $\left\{a_{t,1}^{1},...,a_{t,N}^{1}\right\}$
    = $\left\{a_{1},...,a_{N}\right\}$, where $a_{i}$ is one if the pixel inside in
    focus patch and zero otherwise. The masks $a_{t}$ select the patches and then
    they are scaled to the sensor bandwidth dimensions and stacked to produce retina-like
    representation $\rho_{t}$. The glimpse network $f_{g}$ combines $\rho_{t}$ and
    $l_{t-1}$ to produce the glimpse feature vector $g_{t}=Rect\left(Linear\left(h_{g}\right),Linear\left(h_{l}\right)\right)$,
    where $h_{g}$, $h_{l}\in\mathbb{R}^{128}$, $g_{t}\in\mathbb{R}^{256}$, $h_{l}=Rect\left(Linear\left(l_{t-1}\right)\right)$,
    and $h_{g}=Rect\left(Linear\left(\rho\left(x_{t},l_{t-1}\right)\right)\right)$.
    Let $Linear\left(x\right)=Wx+b$ for some weight matrix $W$ and bias vector $b$,
    $Rect\left(x\right)=max\left(x,0\right)$ be the rectifier nonlinearity.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/dd713e79887fd485e0c38e9313466a95.png)'
  id: totrans-217
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: RAM [[38](#bib.bib38)] architecture illustration. The architecture
    presents a perceptual selection system within the glimpse sensor to generate a
    retina-like representation. The core network captures this representation and
    synthesizes a historical composition between the current and previous steps. The
    action and location network uses this historical summarization to determine the
    next action and focus via the reinforcement learning paradigm.'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: The core network $f_{h}$ receives as input the glimpse encoding $g_{t}$, the
    previous internal state $h_{t-1}$, and outputs the current internal state $h_{t}=f_{h}\left(h_{t-1},g_{t},\theta_{h}\right)$.
    The internal state $h_{t}$ summarizes the history of the information seen to decide
    how to act and to deploy the sensor. The location network $f_{l}\left(h_{t},\theta_{l}\right)$
    and action network $f_{a}\left(h_{t},\theta_{a}\right)$ uses $h_{t}$ to generate
    next location $l_{t}$, and the classification $action_{t}$, respectively. For
    simple classification experiments by Graves [[38](#bib.bib38)], $f_{h}$ was a
    network of rectifier units defined as $h_{t}=f_{h}\left(h_{t-1},g_{t}\right)=Rect\left(Linear\left(h_{t-1}\right)+Linear\left(g_{t}\right)\right)$,
    and on a dynamic environment was used LSTM units. The location networks generate
    as output the average’s location policy, given by $f_{l}\left(h_{t},\theta_{l}\right)=Linear(h_{t})$.
    The location $l_{t}$ is chosen stochastically from a distribution parameterized
    by the location network $f_{l}(h_{t},\theta_{l})$, ie, $l_{t}\sim p(\cdot|f_{l}(h_{t},\theta_{l}))$,
    where $p$ is two-component Gaussian with a fixed variance.
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
- en: For classification decisions, the action network $f_{a}\left(h_{t},\theta_{a}\right)=\frac{e^{Linear\left(h_{t}\right)}}{Z}$,
    conditions a distribution to generate the output $action_{t}\sim p\left(\cdot|f_{a}\left(h_{t},\theta_{a}\right)\right)$,
    where $p$ is a softmax. After executing an action, the agent receives a new visual
    observation of the environment $x_{t+1}$ and reward signal $r_{t+1}$. The goal
    is to maximize the sum $R=\sum_{t=1}^{T}r_{t}$ of the reward signal. For image
    classification, for $r_{T}=1$ if the object is classified correctly after $T$
    steps and $0$ otherwise. This setup is instance of a Partially Observable Markov
    Decision Process (POMDP). The true state of the environment is unobserved, and
    the model needs to learning a stochastic policy $\pi\left(\left(l_{t},a_{t}\right)|s_{1:t};\theta\right)$
    with parameters $\theta=\left\{\theta_{g},\theta_{a},\theta_{h}\right\}$, that,
    at each time step $t$, maps the the environment’s history $s_{1:t}=x_{1},l_{1},a_{1},...,x_{t−1},l_{t−1},a_{t−1},x_{t}$
    to a distribution over actions.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'V-D End-To-End Memory Networks (EMNet): A memory-based end-to-end attention
    system'
  id: totrans-221
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'End-To-End Memory Networks [[19](#bib.bib19)] uses attention for question answering,
    and language modeling. The architecture is a form of Memory Networks [[89](#bib.bib89)]
    but unlike, it is trained end-to-end. EMNet consists of a memory and a stack of
    identical attentional systems, as shown in Figure [8](#S5.F8 "Figure 8 ‣ V-D End-To-End
    Memory Networks (EMNet): A memory-based end-to-end attention system ‣ V Neural
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy").
    Each layer $i$ takes as input set $\left\{x_{1},...,x_{N}\right\}$ to be stored
    in memory. The input set is converted in memory vectors $\left\{m_{1},...,m_{N}\right\}$
    and $\left\{h_{1},...,h_{N}\right\}$ using the embedding matrix $A^{i}\in\mathbb{R}^{d\times
    V}$ to generate each $m_{i}\in\mathbb{R}^{d}$, and the matrix $C^{i}\in\mathbb{R}^{d\times
    V}$ to generate each $h_{i}\in\mathbb{R}^{d}$. In the first layer, the question
    $q$ is also embedded by $B^{1}$ to obtain an internal state $u^{1}$. From the
    second layer, the internal state $u^{i+1}=u^{i}+o^{i}\in\mathbb{R}^{d}$ is the
    sum of the $i$ layer output and the internal state $u^{i}$. Finally, last layer
    generates the prediction $\hat{a}=\frac{e^{Wu^{i+1}}}{\sum_{j=1}^{N}e^{Wu^{i+1}}}$,
    where $\hat{a}\in\mathbb{R}^{V}$ is the predicted label, and $W\in\mathbb{R}^{V\times
    d}$ is the matrix of weights.'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ee563366336ee340a0fe267e1e4dd296.png)'
  id: totrans-223
  prefs: []
  type: TYPE_IMG
- en: 'Figure 8: End-to-End Memory Networks [[19](#bib.bib19)] architecture illustration.
    The network is a stack of attentional systems interconnected with each other and
    with external memory. All subsystems are a top-down and cognitive selection. This
    architecture shows the attention distributed throughout the network, in which
    the selection of inferior stimuli guides selection at higher levels through the
    interconnection between the modules. Such a structure is closer to the biological
    mechanisms since there is not only an attentional center in the brain.'
  id: totrans-224
  prefs: []
  type: TYPE_NORMAL
- en: The attention system is the architecture’s core. In each layer $i$, it takes
    as focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{h_{1},...,h_{N}\right\}$
    memories’ embeddings, and contextual input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1},..,c_{t,N+1}^{1}\right\}=\left\{u^{i},m_{1},...,m_{N}\right\}$.
    Through an alignment function $e_{i,j}=(u^{i})^{T}m_{j}$ the attentional system
    computes the match between $u^{i}$ and each memory $m_{i}$, generating as output
    a mask of importance $a_{t}=\left\{a_{t}^{1}\right\}=\left\{a_{t,1}^{1},...,a_{t,N}^{1}\right\}=\left\{a_{1},...,a_{N}\right\}$
    for each $h_{i}$, where $a_{j}=\frac{e^{e_{i,j}}}{\sum_{j=1}^{N}e^{e_{i,j}}}\in\mathbb{R}$.
    The output $o^{i}$ is a sum over the transformed inputs $h_{i}$, weighted by the
    attention mask. Intuitively, attention looks for the memory elements most related
    to question $q$ using a simple alignment function dispensing traditional RNNs.
    This system can also be seen as version of attention in RNNSearch [[34](#bib.bib34)]
    with mutiple computational steps per output symbol, and with similar selection
    characteristics – soft, divided, top-down stateful, cognitive, and location-based.
    Note that the alignment function is differentiable. Therefore, during training,
    all architecture elements are jointly learned by minimizing a standard cross-entropy
    loss between $\hat{a}$ and the true label $a$ using stochastic gradient descent.
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
- en: 'V-E Show, Attend and Tell: A multimodal approach'
  id: totrans-226
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Show, Attend and Tell [[41](#bib.bib41)] uses attention for image caption.
    The architecture consists of an encoder, decoder, and an attention system (Figure
    [9](#S5.F9 "Figure 9 ‣ V-E Show, Attend and Tell: A multimodal approach ‣ V Neural
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")).
    The encoder is a CNN to extract features from image $I$. And at time step $t$,
    the decoder uses LSTM units for generating one word $y$ for a caption. Similar
    to RNNSearch [[34](#bib.bib34)], the decoder calculates from a context vector
    $z_{t}$ a probability distribution for all possible caption symbols, as follows'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $(f_{1},...,f_{N})=Encoder(I)$ |  | (8) |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
- en: '|  | $p(y_{t}&#124;y_{1},...,y_{C},I)=Decoder(z_{t})$ |  | (9) |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
- en: where $C$ is caption size.
  id: totrans-230
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/815cd501b59fa1d69f0a6bd571fe1619.png)'
  id: totrans-231
  prefs: []
  type: TYPE_IMG
- en: 'Figure 9: Show, Attend and Tell [[41](#bib.bib41)] architecture illustration.
    Attention unifies different sensory experiences to decide a task. A single attentional
    subsystem, which can be hard or soft, aligns high-level image and text representations
    to determine the next word in the decoder.'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: 'The attention system has a subsystem (Figure [9](#S5.F9 "Figure 9 ‣ V-E Show,
    Attend and Tell: A multimodal approach ‣ V Neural Attention Models ‣ Neural Attention
    Models in Deep Learning: Survey and Taxonomy")) that generates the context vector
    $z_{t}$ for the decoder. It receives a contextual input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1}\right\}=\left\{h_{t-1}\right\}$
    with language content, a focus target $\tau_{t}=\left\{\tau_{t}^{2}\right\}=\left\{\tau_{t,1}^{2},...,\tau_{t,N}^{2}\right\}=\left\{f_{1},...,f_{N}\right\}$
    with visual content, and produces attention weigths $a_{t}=\left\{a_{t}^{2}\right\}=\left\{a_{t,1}^{2},...,a_{t,N}^{2}\right\}=\left\{a_{1},...,a_{N}\right\}$
    as output, where $h_{t-1}\in\mathbb{R}^{1\times d}$ is a previous decoder state,
    $f_{j}\in\mathbb{R}^{1\times d_{I}}$ is encoder annotation vector, $a_{t}^{2}\in\mathbb{R}^{1\times
    N}$ are attention weights for all annotation vectors. This structure receives
    as input different sensory modalities (i.e, visual in focus target and language
    in context), inspired by perceptual theories [[96](#bib.bib96)]. Nos seres vivos,
    a experiência perceptual não é desarticulada e fragmentada, mas está intimimente
    ligada à uma unidade objectual comum. Por exemplo, para agarrar uma bola, uma
    pessoa precisa vê-la se aproximando, ou para decidir o gosto de uma comida, elementos
    do tato e do cheiro ponderam a decisão. Similarmente, esta arquitetura implementa
    atenção entre duas fontes sensoriais diferentes para decidir uma tarefa. The attention
    system is equal to the RNNSearch [[34](#bib.bib34)], and has same selection features
    – soft, divided, location-based, top-down stateful, oriented, and cognitive –
    if implements soft attention. In contrast, if the mechanism is hard attention
    has an additional sampling block $a_{t}\sim Multinoulli_{N}(\alpha_{t,j})$ parameterized
    by the scores $\alpha_{t,j}=\frac{e^{e_{t,j}}}{\sum_{j=1}^{N}e^{e_{t,j}}}$, where
    $e_{t,j}=a(h_{t-1},f_{j})$. The sampling mechanism makes the system stochastic
    with hard continuity.'
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: V-F Deep Recurrent Attentive Writer (DRAW)
  id: totrans-234
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'DRAW [[40](#bib.bib40)] uses attention for image generation. The architecture
    is similar variational autoencoders (VAEs) [[97](#bib.bib97)] with some differences
    (Figure [10](#S5.F10 "Figure 10 ‣ V-F Deep Recurrent Attentive Writer (DRAW) ‣
    V Neural Attention Models ‣ Neural Attention Models in Deep Learning: Survey and
    Taxonomy")). Firstly, the encoder/decoder are recurrent neural networks, and the
    encoder receives the previous outputs from the decoder. Secondly, the decoder
    outputs are added successively to the distribution generating the data, instead
    of generating that distribution in a single step. And thirdly, the attention system
    dynamically updates the network, restricting the input region observed by the
    encoder and the output region modified by the decoder. The attention make decisions
    about which regions are input for the network, which regions are modified in the
    generated image, and also what needs to be modified.'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e0f54d8def2a5e464946b50236ae9539.png)'
  id: totrans-236
  prefs: []
  type: TYPE_IMG
- en: 'Figure 10: DRAW [[40](#bib.bib40)] architecture illustration. The architecture
    has an encoder, a decoder, and attention-controlled read/write heads. Read generates
    a superimposed filter grid on an image and extract an patch $N\times N$. Similarly,
    write head defines which image patch will be drawn. Both systems are divided,
    selective, oriented, location-based, top-down stateful, soft and hard.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: 'At each time-step $t$, the encoder receives as input the read vector $r_{t}=read(x_{t},\hat{x_{t}},h_{t-1}^{dec})$,
    and the previous decoder’s state $h_{t-1}^{dec}$ for generate current state $h_{t}^{enc}=RNN^{enc}(h_{t-1}^{enc},[r_{t},h_{t-1}^{dec}])$,
    where $x_{t}$ is input image, $\hat{x_{t}}=x-\sigma(wt_{t-1})$ is error image,
    and $\sigma$ is the sigmoid function. The $h_{t}^{enc}$ parameterize the $Q$ distribution
    over the latent space vector $z_{t}\sim Q(Z_{t}|h_{t}^{enc})$, which is input
    to the decoder. The $Q\left(Z_{t}|h_{t}^{enc}\right)$ distribution is a diagonal
    Gaussian $N\left(Z_{t}|\mu_{t},\sigma_{t}\right)$ in latent space, where $\mu_{t}=W(h_{t}^{enc})$,
    $\sigma_{t}=e^{W(h_{t}^{enc})}$, W are weight matrices of a linear transformation
    layer. The decoder output $h_{t}^{dec}=RNN^{dec}(h_{t-1}^{dec},z_{t})$ is added
    by the write function for reconstruct the image through the cumulative canvas
    matrix $wt_{t}=wt_{t-1}+write(h_{t}^{dec})$. After T iterations the canvas matrix
    $wt_{T}$ parameterize $D(X|wt_{T})$ for generate image $\tilde{x}$:'
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\tilde{z_{t}}\sim P(Z_{t})$ |  | (10) |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
- en: '|  | $\tilde{h}_{t}^{dec}=RNN^{dec}(\tilde{h}_{t-1}^{dec},\tilde{z}_{t})$ |  |
    (11) |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
- en: '|  | $\tilde{wt}_{t}=\tilde{wt}_{t-1}+write(\tilde{h}_{t}^{dec})$ |  | (12)
    |'
  id: totrans-241
  prefs: []
  type: TYPE_TB
- en: '|  | $\tilde{x}\sim D(X&#124;\tilde{wt}_{T})$ |  | (13) |'
  id: totrans-242
  prefs: []
  type: TYPE_TB
- en: where P is a prior, $\tilde{z_{t}}$ is a sample of latent space. D is a probability
    distribution, if the input is binary it is a Bernoulli distribution with a mean
    given by $\sigma(wt_{T})$.
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
- en: 'The read and write functions are controlled by the attention systems for decide
    which image path will be processed, and which image region will be modified in
    the output (Figure [10](#S5.F10 "Figure 10 ‣ V-F Deep Recurrent Attentive Writer
    (DRAW) ‣ V Neural Attention Models ‣ Neural Attention Models in Deep Learning:
    Survey and Taxonomy")). The attention system has only one subsystem and a single
    sensory modality (i.e, visual). At each time step t, the subsystem takes as input
    a contextual $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1},c_{t,2}^{1},c_{t,3}^{1},c_{t,4}^{1}\right\}=\left\{g_{X},g_{Y},\delta,\sigma^{2}\right\}$
    with grid properties, a focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,2N}^{1}\right\}=\left\{x,\hat{x}\right\}$,
    and produces attention weights $a_{t}=\left\{a_{t}^{1}\right\}=\left\{a_{t,1}^{1},...,a_{t,2N}^{1}\right\}=\left\{F_{x},F_{y}\right\}$.
    The pair $(g_{X},g_{Y})$ is grid center coordinates, $\delta$ is width of the
    step, $\sigma^{2}$ is isotropic variance of the Gaussian filters, $x$ $\in\mathbb{R}^{B\times
    A}$ is a input image, $\hat{x}\in\mathbb{R}^{A\times B}$ is the error image, $a_{t}^{1}\in\mathbb{R}^{1\times
    2N}$ is the weight of attention to $\tau_{t}$. The parameters $g_{X}$, $g_{Y}$,
    $\delta$, $\sigma^{2}$, $\gamma$ are determined dynamically using a linear transformation
    of the $h^{dec}$, as'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $(\tilde{g_{X}},\tilde{g_{Y}},log\sigma^{2},log\tilde{\delta},log\gamma)=W(h^{dec})$
    |  | (14) |'
  id: totrans-245
  prefs: []
  type: TYPE_TB
- en: '|  | $g_{X}=\frac{A+1}{2}(\tilde{g}_{X}+1)$ |  | (15) |'
  id: totrans-246
  prefs: []
  type: TYPE_TB
- en: '|  | $g_{y}=\frac{B+1}{2}(\tilde{g}_{Y}+1)$ |  | (16) |'
  id: totrans-247
  prefs: []
  type: TYPE_TB
- en: '|  | $\delta=\frac{max(A,B)-1}{N-1}\tilde{\delta}$ |  | (17) |'
  id: totrans-248
  prefs: []
  type: TYPE_TB
- en: where variance, step, and intensity are given on a log scale to ensure positive
    values. The scale of $g_{X},g_{Y},\delta$ is chosen to ensure that the initial
    path, with an initialized network, covers approximately the entire input image.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: 'The attention system in read is divided, selective, oriented, perceptive, location-based,
    top-down stateful, soft, and hard. Despite being completely differentiable, this
    system applies the soft mask over the entire image as a divided selection. However,
    unlike other approaches in the literature, targeting mask computation only generates
    patches from one region, such as hard and selective attention. In the write, the
    features are similar, but the attention is cognitive. Specifically, the attention
    functions generate as output $a_{t}$ matrices of the horizontal and vertical Gaussian
    filter bank $F_{X}[i,a]=\frac{1}{Z_{X}}e^{\left(-\frac{(a-\mu_{X}^{i})^{2}}{2\sigma^{2}}\right)}$,
    and $F_{Y}[j,b]=\frac{1}{Z_{Y}}e^{\left(-\frac{(b-\mu_{Y}^{i})^{2}}{2\sigma^{2}}\right)}$,
    where $F_{X}\in\mathbb{R}^{N\times A}$, $F_{Y}$ $\in\mathbb{R}^{N\times B}$, $(i,j)$
    is a point of the attention mask, $\left(a,b\right)$ is a point in the input image,
    $Z_{X}$ and $Z_{Y}$ are normalization constants for $\sum_{a}F_{X}[i,a]=1$ and
    $\sum_{b}F_{Y}[j,b]=1$. Finally, read operation returns concatenation of two patches
    $N\times N$ of the input image and the error image. For the write operation, a
    specific set of parameters $\hat{\delta}$, $\hat{F_{X}}$, $\hat{F_{Y}}$ are output
    from $h_{t}^{dec}$:'
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $read(x,\hat{x}_{t},h_{t-1}^{dec})=\gamma[F_{Y}xF_{X}^{T},F_{Y}\hat{x}F_{X}^{T}]$
    |  | (18) |'
  id: totrans-251
  prefs: []
  type: TYPE_TB
- en: '|  | $w_{t}=W(h_{t}^{dec})$ |  | (19) |'
  id: totrans-252
  prefs: []
  type: TYPE_TB
- en: '|  | $write(h_{t}^{dec})=\frac{1}{\hat{\gamma}}\hat{F_{Y}^{T}}w_{t}\hat{F_{X}}$
    |  | (20) |'
  id: totrans-253
  prefs: []
  type: TYPE_TB
- en: where $w_{t}$ is $\mathbb{R}^{N\times N}$ writing patch emited by $h_{t}^{dec}$.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: V-G Bi-Directional Attention Flow (BiDAF)
  id: totrans-255
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'BiDAF [[47](#bib.bib47)] uses attention for machine comprehension. The architecture
    consists of eight main components – character embedding layer, word embedding
    layer, contextual embedding layer, attention system, context-to-query, query-to-context,
    modeling layer and output layer (Figure [11](#S5.F11 "Figure 11 ‣ V-G Bi-Directional
    Attention Flow (BiDAF) ‣ V Neural Attention Models ‣ Neural Attention Models in
    Deep Learning: Survey and Taxonomy")). The character embedding layer maps each
    word to a high-dimensional vector space. Let $\left\{wc_{1},...,wc_{N_{c}}\right\}$
    and $\left\{wq_{1},...,wq_{N_{q}}\right\}$ represent the words in the input paragraph
    and the question, respectively. Characters are embedded into vectors using Convolutional
    Neural Network (CNN). The word embedding layer maps each word to a high-dimensional
    vector space using pre-trained Glove [[98](#bib.bib98)]. The concatenation of
    the character and word embedding vectors is passed through two-layer of the Highway
    Network [[99](#bib.bib99)], and generate context set $X=\left\{x_{1},...,x_{N_{c}}\right\}$,
    $x_{i}\in\mathbb{R}^{d}$, and query set $Q=\left\{q_{1},...,q_{N_{c}}\right\}$,
    $q_{i}\in\mathbb{R}^{d}$.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/470dcf50c1d0080b216a3aa7a3c9b773.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
- en: 'Figure 11: BiDAF [[47](#bib.bib47)] architecture illustration. The attention
    system has small independent modules that communicate different queries with the
    target. In sequence, a hierarchically superior subsystem recalibrates previous
    attentional signals changing original attention focus.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: The contextual embedding layer takes as input a set $X$ and $Q$ and uses an
    bidirectional LSTM [[100](#bib.bib100)] to model temporal iterations between words,
    generating as output a set of context vectors $H=\left\{h_{1},...,h_{N_{c}}\right\}$,
    $h_{i}\in\mathbb{R}^{2d}$, and query vectors $U=\left\{u_{1},...,u_{N_{q}}\right\}$,
    $u_{i}\in\mathbb{R}^{2d}$. Each vector of $H$ and $U$ is 2d dimensional due to
    the concatenation of the forward and backward LSTMs outputs. Note that the first
    three layers are feature extractors for context and queries in different granularity
    levels, similarly CNNs. The next layer is the attentional system, whose function
    is to link and disseminate information from the context and query. Unlike the
    classic mechanisms, the attentional system does not summarize the query and the
    context in vectors of unique features. Instead, the attention vector and the embedding’s
    previous layers can flow to the subsequent modeling layer to reduce information
    loss by the early summary.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: The attentional system has several subsystems in parallel, which receive as
    input the same focus target and different contextual information, that is, $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N_{c}}^{1}\right\}=\left\{h_{1},...,h_{N_{c}}\right\}$,
    $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1}\right\}=\left\{u_{j}\right\}$.
    Each subsystem has an alignment function that relates all context vectors to a
    given query $u_{j}$, and outputs masks that together make up an attention matrix
    $S\in\mathbb{R}^{N_{c}\times N_{q}}$, ie, $a_{t}=\left\{a_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N_{c}}^{1}\right\}=\left\{S_{1,1},...,S_{N_{c},j}\right\}$.
    Each subsystem presents the same selection features – soft, divided, location-based,
    top-down stateful, and cognitive. Specifically,
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $S_{i,j}=a(h_{i},u_{j})$ |  | (21) |'
  id: totrans-261
  prefs: []
  type: TYPE_TB
- en: '|  | $a(h_{i},u_{j})=w_{(S)}^{T}[h;u;h\odot u]$ |  | (22) |'
  id: totrans-262
  prefs: []
  type: TYPE_TB
- en: where $S_{i,j}\in\mathbb{R}$ indicates the similarity between the $i-th$ word
    of the context vector and the $j-th$ query word, $h_{i}$ is the $i-th$ context
    vector, and $u_{j}$ is the $j-th$ query vector, and $a$ is alignment function
    that encodes the similarity between two input vectors, $w_{(S)}\in\mathbb{R}^{6D}$
    is a trainable weight vector, $\odot$ is point-to-point multiplication, [;] is
    vector concatenation across row.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: The $S$ matrix is input to the context-to-query layer (C2Q), which normalizes
    the weights and applies them to each query vector $u_{j}$ to produce the set $\widetilde{U}=\left\{\widetilde{u_{1}},...,\widetilde{u}_{N_{c}}\right\}$
    with the most relevant query words for each context word. $S$ is also input to
    the query-to-context layer (Q2C), which has an attention subsystem hard, selective,
    location-based, top-down stateful, and cognitive. The attention subsystem uses
    a row’s $S$ matrix as contextual information and the $H$ set as focus target $\tau_{t}$.
    It uses a hard selection to change the focus of attention produced in previous
    layers using the $max_{col}$ function. The output’s attention mask searches for
    which words in the context are essential to answer the query generating a dynamic
    context vector $\widetilde{h}$. Specifically,
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\alpha_{t}=softmax(S_{t,1:N_{q}})$ |  | (23) |'
  id: totrans-265
  prefs: []
  type: TYPE_TB
- en: '|  | $\widetilde{u_{t}}=\sum_{j=1}^{N_{q}}\alpha_{t,j}u_{j}$ |  | (24) |'
  id: totrans-266
  prefs: []
  type: TYPE_TB
- en: '|  | $b=softmax(max_{col}(S))$ |  | (25) |'
  id: totrans-267
  prefs: []
  type: TYPE_TB
- en: '|  | $\widetilde{h}=\sum_{j=1}^{N_{c}}b_{j}h_{j}$ |  | (26) |'
  id: totrans-268
  prefs: []
  type: TYPE_TB
- en: where $\alpha_{t}\in\mathbb{R}^{N_{q}}$ and $\sum\alpha_{t}=1$ $\forall t$,
    $\widetilde{u_{t}}\in\mathbb{R}^{2d}$ is an array containing the query vectors
    served by the entire context, $b\in\mathbb{T}$, and the $max_{col}$ is performed
    across the column, and $\widetilde{h}\in\mathbb{R}^{2d}$.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: Finally, the contextual embeddings $h_{i}$, $\widetilde{u}_{i}$, and $\widetilde{h}_{i}$
    are combined to generate $G=\left\{g_{1},...,g_{N_{c}}\right\}$, where each vector
    can be considered as the query-aware representation of each context word. Next,
    $G$ is input for the modeling layer, which captures the interaction among the
    context words conditioned on the query. This layer uses two bidirectional LSTMs
    [[100](#bib.bib100)], with output dimension d for each direction, getting the
    matrix $\beta$ which is passed to the output layer to predict the response. The
    output layer is application-specific, predicting the initial and final indices
    of the paragraph sentence. For this, the probability distributions of the initial
    and final index are obtained throughout the entire paragraph, as follows
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $g_{i}=\beta(h_{i},\widetilde{u_{i}},\widetilde{h_{i}})$ |  | (27) |'
  id: totrans-271
  prefs: []
  type: TYPE_TB
- en: '|  | $\beta(h_{i},\widetilde{u_{i}},\widetilde{h_{i}})=[h_{i};\widetilde{u_{i}};h_{i}\odot\widetilde{u_{i}};h_{i}\odot\widetilde{h_{i}}]$
    |  | (28) |'
  id: totrans-272
  prefs: []
  type: TYPE_TB
- en: '|  | $p^{1}=Softmax(w_{(p^{1})}^{T}[G;M])$ |  | (29) |'
  id: totrans-273
  prefs: []
  type: TYPE_TB
- en: '|  | $p^{2}=Softmax(w_{(p^{2})}^{T}[G;M_{2}])$ |  | (30) |'
  id: totrans-274
  prefs: []
  type: TYPE_TB
- en: where $g_{i}\in\mathbb{R}^{d_{G}}$ corresponding to the i-th context word, $\beta\in\mathbb{R}^{d_{G}}(d_{G}=8d)$
    can be an trainable neural network but in this example is a function that merges
    three vectors, and $d_{G}$ is the output dimension of the $\beta$ function, $w_{(p^{1})}\in\mathbb{R}^{10d}$
    are vectors of trainable weights, $M$ is the output of the first modeling layer,
    $M_{2}\in\mathbb{R}^{2d\times N_{c}}$ is the output of M after going through another
    layer of bidirectional LSTM.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: V-H Neural Transformer
  id: totrans-276
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Neural Transformer [[18](#bib.bib18)] uses attention for machine translation.
    The architecture consists of an arbitrary amount of stacked encoders/decoders,
    as shown in Figure [12](#S5.F12 "Figure 12 ‣ V-H Neural Transformer ‣ V Neural
    Attention Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy").
    Each encoder has linear layers, an attention system, feed-forward neural networks,
    and normalization steps. The attention system is architecture’s core. It has several
    parallel heads. Each head has $N$ attention subsystems that perform the same task,
    but with different contextual inputs. In the first layer, the encoder receives
    as input an embedding matrix $I=I_{emb}+T$ $\in\mathbb{R}^{N\times d_{emb}}$ for
    $N$ words, where $I_{emb}=\left\{e_{1},e_{2},e_{3},...,e_{N}\right\},e_{i}\in\mathbb{R}^{1\times
    d_{emb}}$ is an embedding matrix, and $T=\left\{PE_{0},PE_{1},PE_{2},PE_{3},...,PE_{N}\right\}$
    is composed by positional encodings $PE_{i}=\left\{pe_{0},pe_{1},p_{2},...,p_{d_{emb}}\right\}$:'
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $pe_{i}\in\left\{\begin{matrix}sin(\frac{pos}{10000^{\frac{2i}{d_{emb}}}})&amp;i=0,2,...,d_{emb}\\
    cos(\frac{pos}{10000^{\frac{2i}{d_{emb}}}})&amp;i=1,3,...,d_{emb-1}\end{matrix}\right.$
    |  | (31) |'
  id: totrans-278
  prefs: []
  type: TYPE_TB
- en: where $d_{emb}=512$ is the word embedding dimension. $T$ is the matrix of positions
    encoders. $PE_{i}\in\mathbb{R}^{1\times d_{emb}}$ is a position encoder vector
    for a word, pos is the position of the word in the sequence, i $\in[0,255]$, and
    refers to the dimension value.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ad386963f8e86b99f5246c752e7fced2.png)'
  id: totrans-280
  prefs: []
  type: TYPE_IMG
- en: 'Figure 12: The Neural Transformer [[18](#bib.bib18)] architecture illustration.
    The attention system has several parallel heads. Each head has $N$ attention subsystems
    that perform the same task but have different contextual inputs. The encoder is
    purely bottom-up stateful attention. Each query communicates each stimulus in
    focus target with the other. The decoder is hybrid, in which the first system
    is bottom-up and the second is top-down.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: The input $I$ goes through linear layers and generates, for each word, a query
    vector ($q_{i}$), a key vector ($k_{i}$), and a value vector ($v_{i}$), as follows
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Q_{i}=X\times W^{Q}_{i},Q_{i}\in\mathbb{R}^{N\times d_{k}}$ |  | (32)
    |'
  id: totrans-283
  prefs: []
  type: TYPE_TB
- en: '|  | $K_{i}=X\times W^{K}_{i},K_{i}\in\mathbb{R}^{N\times d_{k}}$ |  | (33)
    |'
  id: totrans-284
  prefs: []
  type: TYPE_TB
- en: '|  | $V_{i}=X\times W^{V}_{i},V_{i}\in\mathbb{R}^{N\times d_{k}}$ |  | (34)
    |'
  id: totrans-285
  prefs: []
  type: TYPE_TB
- en: where i is the head index, $W^{Q}_{i}$, $W^{K}_{i}$, and $W^{V}_{i}$ $\in\mathbb{R}^{d_{emb}\times
    d_{k}}$ are trainable weights. The value $d_{k}$ is $d_{emb}/h=64$, and $h=8$
    is the number of parallel heads. $Q_{i}=\left\{q_{1},q_{2},...,q_{N}\right\},q_{i}\in\mathbb{R}^{1\times
    d_{k}}$ is the queries matrix, $K_{i}=\left\{k_{1},k_{2},...,k_{N}\right\},k_{i}\in\mathbb{R}^{1\times
    d_{k}}$ is the keys matrix, and $V_{i}=\left\{v_{1},v_{2},...,v_{N}\right\},v_{i}\in\mathbb{R}^{1\times
    d_{k}}$ is the values matrix.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'The attention system receives as input all $Q$, $K$, and $V$ arrays in several
    parallel attention heads. The multi-head structure explores multiple subspaces,
    getting different projections of the data. Having multiple heads on the Transformer
    is similar to having multiple filters on CNNs. Each head has $N$ attention subsystems
    which receive as input the same focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{k_{1},...,k_{N}\right\}$,
    different contextual inputs $c_{t_{att_{i}}}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1}\right\}=\left\{q_{i}\right\}$,
    and outputs an attention mask that relates all keys to specific query $q_{i}$.
    Mathematically, the operations performed by a head (Figure [12](#S5.F12 "Figure
    12 ‣ V-H Neural Transformer ‣ V Neural Attention Models ‣ Neural Attention Models
    in Deep Learning: Survey and Taxonomy")) are represented by matrix multiplication
    between all queries and keys, as follows'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $S_{i}=softmax(\frac{Q_{i}*K_{i}^{T}}{\sqrt{d_{k}}})$ |  | (35) |'
  id: totrans-288
  prefs: []
  type: TYPE_TB
- en: where $S_{i}\in\mathbb{R}^{N\times N}$ is self-attention matrix, i is the head
    index, Q $\in\mathbb{R}^{N\times d_{k}}$, $K^{T}$ $\in\mathbb{R}^{d_{k}\times
    N}$. For gradient stability, $d_{k}$ is the normalization factor, and an softmax
    function turns the attention scores into probabilities.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'The similarity between $q_{i}$ and $k_{i}$ is a score of importance that the
    elements of the sequence have among themselves. This structure characterizes the
    most important bottom-up stateful system in the field, in which contexts come
    simultaneously from the discrepancies between the different stimuli of the focus
    target itself. Intuitively, queries act as small units that allow parallel communication
    between all the target’s stimuli. In sequence, other bottom-up stateful attention
    receives as context input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{S_{1},...,S_{h},V_{1},...,V_{h}\right\}$
    all self-attention matrices $S_{i}$ and values $V_{i}$, and as focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N}^{1}\right\}=\left\{x_{1},...,x_{N}\right\}$
    the original input $I$ composed by $x_{i}\in\mathbb{R}^{d_{emb}}$ vectors. This
    system create final attention mask $a_{t}$ for original encoder input $I$:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $Z_{i}=S_{i}*V_{i}$ |  | (36) |'
  id: totrans-291
  prefs: []
  type: TYPE_TB
- en: '|  | $a_{t}=Concat(Z_{1},Z_{2},...,Z_{h})*W^{O}$ |  | (37) |'
  id: totrans-292
  prefs: []
  type: TYPE_TB
- en: where $a_{t}=\left\{a_{t,1},...,a_{t,N}\right\}$ $\in\mathbb{R}^{N\times d_{emb}}$
    is a linear combination from each head, and $W^{O}$ $\in\mathbb{R}^{h*d_{k}\times
    d_{emb}}$ are weights learned during training.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: 'The mask $a_{t}$ modulates focus target $I$ through simple sum and layer-normalization
    [[101](#bib.bib101)] step, resulting updated $I=\left\{x_{1},...,x_{N}\right\}$.
    After, each updated $x_{i}$ goes through feedfoward neural network composed by
    linear transformations and ReLU activation function. Finally, residual input $I$,
    and feedfoward results are input for last layer-normalization step:'
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $I=LayerNorm(I+a_{t})$ |  | (38) |'
  id: totrans-295
  prefs: []
  type: TYPE_TB
- en: '|  | $f_{i}=FFN(x_{i})=max(0,x_{i}W_{1}+b_{1})W_{2}+b_{2}$ |  | (39) |'
  id: totrans-296
  prefs: []
  type: TYPE_TB
- en: '|  | $I=LayerNorm(I+F)$ |  | (40) |'
  id: totrans-297
  prefs: []
  type: TYPE_TB
- en: where the hidden layer has a dimensionality $d_{ff}=2048$, and $F$ $\in\mathbb{R}^{N\times
    d_{emb}}$ is feedfoward matrix, and updated $I$ $\in\mathbb{R}^{N\times d_{emb}}$
    is output encoder.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: 'The last encoder output are transformed into the contextual inputs $K_{encdec}$,
    $V_{encdec}$ for new attention systems in decoder levels. This data can also be
    understood as short-term memories that help the decoder focus on the input sequences’
    appropriate information. All decoders are similar to a single encoder structure,
    but with some important differences: 1) Step-by-step processing; and 2) Two attention
    systems (Figure [12](#S5.F12 "Figure 12 ‣ V-H Neural Transformer ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")). The
    first has masked multi-head structure to mask future translate words with $-\infty$
    values. The second receives as focus target the previously translated word embeddings
    and as contextual input $K_{encdec}$, $V_{encdec}$ and queries from the layer
    below it. This system operates as top-down stateful attention, given keys/values
    and queries/target from different sources. This structure acts as oriented attention,
    given change the focus target e attention masks at each time step $t$. After all
    attention systems, a linear layer followed by the softmax function transform the
    last decoder output stack into a probability vector to predict the correct word.'
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: Neural Transformer represents the primary end-to-end attention approach. Communication
    between bottom-up and top-down structures makes it the first hybrid attention
    model. The simultaneously location-based and feature-based attention is also innovative,
    given the most models are only location-based. In the first stage of attention,
    parallel heads are location-based, while the second stage, composed of a single
    attention subsystem, is feature-based. Besides, the sequence of multiple stacked
    attention modules eliminates the need for recurrence in tasks where RNNs are typically
    used.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: V-I Graph Attention Networks (GATs)
  id: totrans-301
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'GATs [[20](#bib.bib20)] uses attention to operate on graph-structured data.
    The architecture consists of stacking several graph attentional layers (GAL) (Figure
    [13](#S5.F13 "Figure 13 ‣ V-I Graph Attention Networks (GATs) ‣ V Neural Attention
    Models ‣ Neural Attention Models in Deep Learning: Survey and Taxonomy")). The
    GAL input is the nodes’ features $h=\left\{\overrightarrow{h_{1}},\overrightarrow{h_{2}},\overrightarrow{h_{3}},...,\overrightarrow{h_{N_{i}}}\right\}$,
    where $\overrightarrow{h_{i}}\in\mathbb{R}^{1\times F}$, $N$ is the number of
    nodes, and $F$ is the number of features in each node. The outputs are a new set
    of features $h^{{}^{\prime}}=\left\{\overrightarrow{h_{1}^{{}^{\prime}}},\overrightarrow{h_{2}^{{}^{\prime}}},\overrightarrow{h_{3}^{{}^{\prime}}},...,\overrightarrow{h_{N}^{{}^{\prime}}}\right\}$
    with a potentially different cardinality $F^{{}^{\prime}}$. This embeddings are
    combination of small bottom-up subsystems. First, $N_{h}$ heads with $N_{i}$ bottom-up
    stateless subsystems operating in parallel to modulate all stimulus’ features
    based on neighborhood. In sequence, $N_{h}$ bottom-up stateful subsystems transform
    the heads outputs into the attention masks for $h$.'
  id: totrans-302
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ec5ce69fe68782871fc5723373b72b23.png)'
  id: totrans-303
  prefs: []
  type: TYPE_IMG
- en: 'Figure 13: Graph Attentional Layers (GAL) [[20](#bib.bib20)] architecture illustration.
    The bottom-up and feature-based attention captures the discrepancies between the
    focus target features and generates embedding vectors for each node as output.'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: 'Each bottom-up stateless subsystem takes as input a focus target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},\tau_{t,2}^{1}\right\}=\left\{W\overrightarrow{h_{i}},W\overrightarrow{h_{j}}\right\}$,
    $\tau_{t}\in\mathbb{R}^{2F}$. An alignment function $a$ generates the attentional
    weights for each input feature, ie, $a_{t}=\left\{a_{t}^{1}\right\}=\left\{a_{t,1}^{1},a_{t,2}^{1}\right\}=\left\{a^{T}\right\}$,
    where $a_{t}\in\mathbb{R}^{2F}$, and $a$ is a single-layer feedforward neural
    network, parametrized by a weight vector $a^{T}$. Each subsystem has the same
    selection characteristics – divided, cognitive, feature-based, and soft. The result
    of attention mask over $\tau_{t}$ is contextual input $c_{t}=\left\{c_{t}^{1}\right\}=\left\{c_{t,1}^{1},...,c_{t,N_{i}}^{1}\right\}$
    for bottom-up stateful attention subsystems:'
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $c_{t,j}^{1}=\overrightarrow{a^{T}}[W\overrightarrow{h_{i}}&#124;&#124;W\overrightarrow{h_{j}}]$
    |  | (41) |'
  id: totrans-306
  prefs: []
  type: TYPE_TB
- en: where $.^{T}$ represents transposition and $\left|\right|$ is the concatenation
    operation.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: The bottom-up stateful attention subsystems based on heads output, and focus
    target $\tau_{t}=\left\{\tau_{t}^{1}\right\}=\left\{\tau_{t,1}^{1},...,\tau_{t,N_{i}}^{1}\right\}=\left\{W\overrightarrow{h_{i}},W\overrightarrow{h_{N_{i}}}\right\}$
    generates attention mask $a_{t}=\left\{a_{t}^{1}\right\}=\left\{a_{t,1}^{1},...,a_{t,N_{i}}^{1}\right\}=\left\{a_{i,1},...,a_{i,N_{i}}\right\}$,
    where $a_{t}\in\mathbb{R}^{N_{i}}$. These subsystems apply, rectification and
    normalization layers over $c_{t}$ to produce divided, cognitive, location-based,
    and soft selection over all nodes. This subsystems’ objective is to generate a
    embedding for each node $i$ resulting from a combination of the all neighborhood,
    as follows
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $\alpha_{i,j}=LeakyReLU(c_{t})$ |  | (42) |'
  id: totrans-309
  prefs: []
  type: TYPE_TB
- en: '|  | $a_{i,j}=\frac{\alpha_{i,j}}{\sum_{k\in N_{i}}\alpha_{i,j}}$ |  | (43)
    |'
  id: totrans-310
  prefs: []
  type: TYPE_TB
- en: '|  | $\overrightarrow{h_{i}^{{}^{\prime}}}=\sigma(\frac{1}{N_{h}}\sum_{k=1}^{N_{h}}\sum_{j\in
    N_{i}}a_{i,j}^{k}W^{k}\overrightarrow{h_{j}})$ |  | (44) |'
  id: totrans-311
  prefs: []
  type: TYPE_TB
- en: where $N_{h}$ is amount of heads, $N_{i}$ is the set of nodes belonging to a
    certain neighborhood of the $i$ node, and LeakyReLU is non-linear function with
    negative input slope $\alpha=0.2$. $\overrightarrow{h_{i}^{{}^{\prime}}}\in\mathbb{R}^{F^{{}^{\prime}}}$
    is the output from the GAT layer to node $i$.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: VI Discussion
  id: totrans-313
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we discuss outstanding issues with attention models around
    some main topics.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: VI-A Perception, multimodality, and sensors sharing
  id: totrans-315
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Historically, several aspects and characteristics of attention have been mapped
    by observing external stimuli’ selection, resulting in a wide range of theories
    to address attention’s perceptual selection. Some researchers consider attention
    as a fundamental process for the existence of perception. In classical theories,
    sensory memories store information about the input stimuli for a period.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: The stimuli have activation and inhibition dynamics within the system. Such
    dynamics are entirely dependent on exposure to the same input stimulus (i.e.,
    inhibition and return), and the construction of the internal representation of
    the world occurs sequentially through the exploration of stimuli that fire with
    greater intensity, guided by top-down and bottom-up influences. However, few attentional
    systems in Deep Learning have been explored from this perspective. In CNNs, the
    main focus of the systems is feature maps instead of the raw input image. In RNNs
    and generative models, the models are mainly cognitive selection over previous
    memories. Usually, the few existing perceptual selection systems present all the
    input stimuli to the network. In parallel, computation is made over the data in
    one pass, without the sequential dynamics and without considering the same stimulus’s
    activation degree depending on the time exposure.
  id: totrans-317
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, attentional systems also explore few aspects of multimodality. Multiple
    inter and intra modal attentional stages for sensory fusion are still poorly explored.
    Typically, most of the current systems relate two different modalities without
    sensory fusion. One modality is only supported for the selection of stimuli of
    the other already in latent space. However, classical theories indicate that many
    areas of the brain share the processing of information from different senses.
    Some evidence indicates that large parts of the visual cortex are multisensory,
    with different fusion stages ranging from perception to higher levels of processing.
  id: totrans-318
  prefs: []
  type: TYPE_NORMAL
- en: VI-B Attention over data
  id: totrans-319
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most attentional systems occur over the data that flows through neural networks.
    Systems are almost exclusively location-based, disregarding features and object
    properties. However, this approach does not fully corroborate theories and cognitive
    models of the 90s. The theory of integration of characteristics by Treisman [[102](#bib.bib102)]
    points to the initial stages of perception as purely feature-based, to the point
    where the merging of the different features occurs, and a WTA process determines
    the location of the most prominent stimulus by inhibiting the missing stimuli.
    Backer et al. [[103](#bib.bib103)] presented a computational model in three stages,
    the first feature-based stage, the second location normally detecting four protruding
    regions, and finally, an object-based inhibition of return. Besides, there is
    strong experimental evidence showing that these properties are not multi-exclusive,
    present mainly in the human view [[104](#bib.bib104)]. We believe that attentional
    systems with all three aspects can greatly benefit computer vision applications.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: VI-C Attention over program
  id: totrans-321
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most attentional systems are oriented towards data selection. So far, task-oriented
    or time-oriented systems do not exist. Task-oriented structures are important
    to increase the modularity of classical neural networks and facilitate interpretability,
    given that the behavior of the modules can be indirectly investigated through
    the decisions made by the attentional system. Similarly, time-oriented structures
    are important for the consistent distribution of computation times between different
    structures. Such a structure is particularly interesting for deciding between
    the exposure time of stimuli in perceptual stages.
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: 'VI-D Dual-Process Theory: Connectionism versus Symbolism'
  id: totrans-323
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'According to the dual-process theory [[105](#bib.bib105)], human reasoning
    has two distinct systems. The first is unconscious, fast, intuitive, automatic,
    non-linguistic, and deals only with implicit knowledge. The second is conscious,
    evolutionarily recent, exclusive to humans, slow, conscious, linguistic, algorithmic,
    incorporating rules-based reasoning and explicit knowledge forms. Semantic variables
    in conscious thinking are often causal, controllable, and relate to thoughts so
    that concepts can be recombined to form new and unknown concepts. For years, in
    AI, these two types of reasoning have been studied separately, creating two distinct
    research branches: connectionist models represented mainly by neural networks
    and symbolic models represented by highly declarative and recursive algorithms.
    Although different, these two systems are complementary in complex reasoning.
    Currently, the fusion between the symbolic and the connectionist (i.e., neuro-symbolic
    approaches) is one of the main AI challenges for the coming years. In this context,
    attention is a key element as an interface between the two types of representation.
    One of the main issues to be solved by attention is how to link two systems with
    such different representations of knowledge. Few systems have acted in this perspective.
    Some initiatives have emerged through external memory networks [[89](#bib.bib89)]
    [[37](#bib.bib37)], in RL [[48](#bib.bib48)] and recently, in Hypergraph Attention
    Networks [[67](#bib.bib67)], in which attentional systems reason about symbolic
    graphs in a same semantic space and build representative embeddings for a connectionist
    model to make the prediction.'
  id: totrans-324
  prefs: []
  type: TYPE_NORMAL
- en: VI-E Human Memories
  id: totrans-325
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: One of the main questions of connectionist models is how to represent, organize
    and manage knowledge external to the prediction structure to guarantee reusability
    of the knowledge acquired previously. In psychology and neuroscience, the relationship
    between attention and memory is intrinsic and fundamental to our cognitive system.
    However, in Deep Learning, most attentional systems focus on selecting and representing
    data from the current input. Few systems are directed to external memories or
    internal storage structures with specific characteristics. Research, still in
    its initial stages, focuses on the management of working memories [[37](#bib.bib37)]
    or episodic [[106](#bib.bib106)], with the absence of sensory, motor, procedural,
    and semantic memories.
  id: totrans-326
  prefs: []
  type: TYPE_NORMAL
- en: VI-F Hybrid Models
  id: totrans-327
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Most attentional systems receive only top-down influences, coming from memories
    of the previous internal states of neural networks. High-level contextual elements
    such as rewards, motivation, emotional and sensory status are still absent. Besides,
    few systems have bottom-up influences, although there are numerous theories and
    models discussed in the classical literature, mainly focused on sensory perception.
    We believe that bottom-up attention can bring significant learning benefits in
    the early stages of perception or unsupervised/self-supervised approaches. Likewise,
    the area still lacks hybrid neural attention models that address both levels of
    attention. Only Neural Transformer [[18](#bib.bib18)], and recently BRIMs [[72](#bib.bib72)]
    have brought some significant insights to the area. However, a major research
    question still little explored is how to iterate between the two levels of attention
    and how to associate the two modulations in attentional processes.
  id: totrans-328
  prefs: []
  type: TYPE_NORMAL
- en: According to some neurophysiological evidence these mechanisms are concentrated
    in different brain areas, but they interact with each other constantly and are
    simultaneously present from the initial stages of perception. At some stages,
    the bottom-up mechanisms can completely overlap top-down influences in a competitive
    process, or both can be aligned, and their effects are combined in some way. For
    example, when reading this article, if your senses notice an imminent danger,
    you will stop reading for safety, where bottom-up influences have completely suppressed
    top-down influences. On the other hand, you may be invited to search for a specific
    target in an image, and discrepant features not related to the target can interfere
    with the visual search process but do not fully influence the point of stopping
    the search for the desired target. In contrast, there is still little iteration
    between these mechanisms in neural networks so that they act separately at different
    time stages. At Neural Transformer, for example, only bottom-up attention acts
    on perception in the first stage of time. The perceptual stage is over, and the
    top-down attention helps generate the translated words, with still weak iterations
    between the two mechanisms.
  id: totrans-329
  prefs: []
  type: TYPE_NORMAL
- en: VII Conclusions
  id: totrans-330
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this survey, we presented a review of attention in Deep Learning from a theoretical
    point of view. We propose a general framework of attention and taxonomy based
    on theoretical concepts that date back to the pre-Deep Learning era. From a set
    of more than 650 papers critically analyzed via systematic review, we identified
    the main neural attention models in the literature, discussed, and classified
    their main aspects using the different perspectives of attention presented in
    our taxonomy. We have identified models that corroborate classical theories and
    biological evidence discussed for years by psychologists and neuroscientists.
    Finally, we present the key developments in the area in detail, formulating and
    explaining their attention systems from our framework and taxonomy perspective.
    Finally, we present a critical discussion of the models analyzed, presenting some
    relevant research opportunities. We hope that this survey will provide a better
    understanding of how attentional mechanisms work in neural networks from the theoretical
    point of view of care and that our taxonomy will help systematize the mechanisms
    facilitating their understanding and provide a better understanding of different
    directions of attention helping to guide the future development of the area.
  id: totrans-331
  prefs: []
  type: TYPE_NORMAL
- en: Acknowledgments
  id: totrans-332
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The research was supported by the Coordination for the Improvement of Higher
    Education Personnel (CAPES). This work was carried out within the scope of PPI-Softex
    with support from the MCTI, through the Technical Cooperation Agreement [01245.013778/2020-21].
  id: totrans-333
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-334
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] E. L. Colombini, A. da Silva Simoes, and C. Ribeiro, “An attentional model
    for intelligent robotics agents.” Ph.D. dissertation, Instituto Tecnológico de
    Aeronáutica, São José dos Campos, Brazil, 2014.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] W. James, *The Principles of Psychology*.   Dover Publications, 1890.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] N. H. Mackworth, “The breakdown of vigilance during prolonged visual search,”
    *Quarterly Journal of Experimental Psychology*, vol. 1, no. 1, pp. 6–21, 1948.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] D. J. Simons and C. F. Chabris, “Gorillas in our midst: Sustained inattentional
    blindness for dynamic events,” *perception*, vol. 28, no. 9, pp. 1059–1074, 1999.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] J. E. Raymond, K. L. Shapiro, and K. M. Arnell, “Temporary suppression
    of visual processing in an rsvp task: An attentional blink?” *Journal of experimental
    psychology: Human perception and performance*, vol. 18, no. 3, p. 849, 1992.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] A. F. Sanders, *Elements of human performance: Reaction processes and attention
    in human skill*.   Psychology Press, 1998.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] D. E. Broadbent, *Perception and communication*.   Elsevier, 2013.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] J. Driver and R. S. Frackowiak, “Neurobiological measures of human selective
    attention,” *Neuropsychologia*, vol. 39, no. 12, pp. 1257–1262, 2001.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] S. Treue, “Neural correlates of attention in primate visual cortex,” *Trends
    in neurosciences*, vol. 24, no. 5, pp. 295–300, 2001.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] E. T. Rolls and G. Deco, “Attention in natural scenes: neurophysiological
    and computational bases,” *Neural networks*, vol. 19, no. 9, pp. 1383–1394, 2006.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A. A. Salah, E. Alpaydin, and L. Akarun, “A selective attention-based
    method for visual pattern recognition with application to handwritten digit recognition
    and face recognition,” *IEEE PAMI*, vol. 24, no. 3, pp. 420–425, 2002.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] N. Ouerhani, “Visual attention: from bio-inspired modeling to real-time
    implementation,” Ph.D. dissertation, Université de Neuchâtel, 2003.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] D. Walther, “Interactions of visual attention and object recognition:
    computational modeling, algorithms, and psychophysics,” Ph.D. dissertation, California
    Institute of Technology, 2006.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] J. J. Clark and N. J. Ferrier, “Modal control of an attentive vision system,”
    in *IEEE ICCV*.   IEEE, 1988, pp. 514–523.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] S. Baluja and D. A. Pomerleau, “Expectation-based selective attention
    for visual monitoring and control of a robot vehicle,” *Robotics and autonomous
    systems*, vol. 22, no. 3-4, pp. 329–344, 1997.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] S. Frintrop and P. Jensfelt, “Attentional landmarks and active gaze control
    for visual slam,” *IEEE Transactions on Robotics*, vol. 24, no. 5, pp. 1054–1065,
    2008.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] C. Breazeal and B. Scassellati, “A context-dependent attention system
    for a social robot,” *rn*, vol. 255, p. 3, 1999.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,
    L. Kaiser, and I. Polosukhin, “Attention is all you need,” *arXiv:1706.03762 [cs]*,
    June 2017, arXiv: 1706.03762\. [Online]. Available: [http://arxiv.org/abs/1706.03762](http://arxiv.org/abs/1706.03762)'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] S. Sukhbaatar, J. Weston, R. Fergus *et al.*, “End-to-end memory networks,”
    in *Advances in neural information processing systems*, 2015, pp. 2440–2448.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] P. Veličković, G. Cucurull, A. Casanova, A. Romero, P. Lio, and Y. Bengio,
    “Graph attention networks,” *arXiv preprint arXiv:1710.10903*, 2017.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] Y. Zhang, X. Wang, X. Jiang, C. Shi, and Y. Ye, “Hyperbolic graph attention
    network,” *arXiv preprint arXiv:1912.03046*, 2019.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] M. M. Chun, J. D. Golomb, and N. B. Turk-Browne, “A taxonomy of external
    and internal attention,” *Annual review of psychology*, vol. 62, pp. 73–101, 2011.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] S. Chaudhari, G. Polatkan, R. Ramanath, and V. Mithal, “An attentive survey
    of attention models,” *arXiv preprint arXiv:1904.02874*, 2019.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] A. Galassi, M. Lippi, and P. Torroni, “Attention in natural language processing,”
    *IEEE Transactions on Neural Networks and Learning Systems*, 2020.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] M. Jaderberg, K. Simonyan, A. Zisserman, and K. Kavukcuoglu, “Spatial
    transformer networks,” *arXiv preprint arXiv:1506.02025*, 2015.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] X. Chen, C. Liu, R. Shin, D. Song, and M. Chen, “Latent attention for
    if-then program synthesis,” *arXiv preprint arXiv:1611.01867*, 2016.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] S. Zagoruyko and N. Komodakis, “Paying more attention to attention: Improving
    the performance of convolutional neural networks via attention transfer,” *arXiv
    preprint arXiv:1612.03928*, 2016.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] N. Mishra, M. Rohaninejad, X. Chen, and P. Abbeel, “A simple neural attentive
    meta-learner,” *arXiv:1707.03141 [cs, stat]*, July 2017, arXiv: 1707.03141\. [Online].
    Available: [http://arxiv.org/abs/1707.03141](http://arxiv.org/abs/1707.03141)'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] J. Hu, L. Shen, S. Albanie, G. Sun, and E. Wu, “Squeeze-and-excitation
    networks,” *arXiv:1709.01507 [cs]*, September 2017, arXiv: 1709.01507. [Online].
    Available: [http://arxiv.org/abs/1709.01507](http://arxiv.org/abs/1709.01507)'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] Y. Chen, Y. Kalantidis, J. Li, S. Yan, and J. Feng, “A2̂-nets: Double
    attention networks,” in *Advances in Neural Information Processing Systems*, 2018,
    pp. 352–361.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] J. Fu, J. Liu, H. Tian, Z. Fang, and H. Lu, “Dual attention network for
    scene segmentation,” *arXiv:1809.02983 [cs]*, September 2018, arXiv: 1809.02983\.
    [Online]. Available: [http://arxiv.org/abs/1809.02983](http://arxiv.org/abs/1809.02983)'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] X. Wang, H. Ji, C. Shi, B. Wang, Y. Ye, P. Cui, and P. S. Yu, “Heterogeneous
    graph attention network,” in *The World Wide Web Conference*, 2019, pp. 2022–2032.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] A. Lamb, D. He, A. Goyal, G. Ke, C.-F. Liao, M. Ravanelli, and Y. Bengio,
    “Transformers with competitive ensembles of independent mechanisms,” *arXiv preprint
    arXiv:2103.00336*, 2021.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] D. Bahdanau, K. Cho, and Y. Bengio, “Neural machine translation by jointly
    learning to align and translate,” September 2014. [Online]. Available: [https://arxiv.org/abs/1409.0473](https://arxiv.org/abs/1409.0473)'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] Y. Tang, N. Srivastava, and R. R. Salakhutdinov, “Learning generative
    models with visual attention,” 2014, pp. 1808–1816\. [Online]. Available: [http://papers.nips.cc/paper/5345-learning-generative-models-with-visual-attention](http://papers.nips.cc/paper/5345-learning-generative-models-with-visual-attention)'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] Q. Wang, J. Zhang, S. Song, and Z. Zhang, “Attentional neural network:
    Feature selection using cognitive feedback,” *arXiv preprint arXiv:1411.5140*,
    2014.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] A. Graves, G. Wayne, and I. Danihelka, “Neural turing machines,” *arXiv:1410.5401
    [cs]*, October 2014, arXiv: 1410.5401\. [Online]. Available: [http://arxiv.org/abs/1410.5401](http://arxiv.org/abs/1410.5401)'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] V. Mnih, N. Heess, A. Graves, and K. Kavukcuoglu, “Recurrent models of
    visual attention,” 2014, pp. 2204–2212\. [Online]. Available: [http://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention](http://papers.nips.cc/paper/5542-recurrent-models-of-visual-attention)'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] M. Stollenga, J. Masci, F. Gomez, and J. Schmidhuber, “Deep networks with
    internal selective attention through feedback connections,” *arXiv preprint arXiv:1407.3068*,
    2014.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] K. Gregor, I. Danihelka, A. Graves, D. J. Rezende, and D. Wierstra, “Draw:
    A recurrent neural network for image generation,” *arXiv preprint arXiv:1502.04623*,
    2015.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] K. Xu, J. Ba, R. Kiros, K. Cho, A. Courville, R. Salakhudinov, R. Zemel,
    and Y. Bengio, “Show, attend and tell: Neural image caption generation with visual
    attention,” in *International Conference on Machine Learning*, June 2015, pp.
    2048–2057\. [Online]. Available: [http://proceedings.mlr.press/v37/xuc15.html](http://proceedings.mlr.press/v37/xuc15.html)'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] O. Vinyals, M. Fortunato, and N. Jaitly, “Pointer networks,” in *Advances
    in neural information processing systems*, 2015, pp. 2692–2700.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] T. Rocktäschel, E. Grefenstette, K. M. Hermann, T. Kočiskỳ, and P. Blunsom,
    “Reasoning about entailment with neural attention,” *arXiv preprint arXiv:1509.06664*,
    2015.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] T. Luong, H. Pham, and C. D. Manning, “Effective approaches to attention-based
    neural machine translation,” in *Proceedings of the 2015 Conference on Empirical
    Methods in Natural Language Processing*.   Lisbon, Portugal: Association for Computational
    Linguistics, 2015, pp. 1412–1421\. [Online]. Available: [http://aclweb.org/anthology/D15-1166](http://aclweb.org/anthology/D15-1166)'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] K. M. Hermann, T. Kocisky, E. Grefenstette, L. Espeholt, W. Kay, M. Suleyman,
    and P. Blunsom, “Teaching machines to read and comprehend,” in *Advances in neural
    information processing systems*, 2015, pp. 1693–1701.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] A. Kumar, O. Irsoy, P. Ondruska, M. Iyyer, J. Bradbury, I. Gulrajani,
    V. Zhong, R. Paulus, and R. Socher, “Ask me anything: Dynamic memory networks
    for natural language processing,” June 2015\. [Online]. Available: [https://arxiv.org/abs/1506.07285](https://arxiv.org/abs/1506.07285)'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] M. Seo, A. Kembhavi, A. Farhadi, and H. Hajishirzi, “Bidirectional attention
    flow for machine comprehension,” *arXiv:1611.01603 [cs]*, November 2016, arXiv:
    1611.01603\. [Online]. Available: [http://arxiv.org/abs/1611.01603](http://arxiv.org/abs/1611.01603)'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] V. Mnih, J. Agapiou, S. Osindero, A. Graves, O. Vinyals, K. Kavukcuoglu
    *et al.*, “Strategic attentive writer for learning macro-actions,” *arXiv preprint
    arXiv:1606.04695*, 2016.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] M. Allamanis, H. Peng, and C. Sutton, “A convolutional attention network
    for extreme summarization of source code,” in *International conference on machine
    learning*.   PMLR, 2016, pp. 2091–2100.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] J. Lu, J. Yang, D. Batra, and D. Parikh, “Hierarchical question-image
    co-attention for visual question answering,” *arXiv preprint arXiv:1606.00061*,
    2016.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] A. Graves, “Adaptive computation time for recurrent neural networks,”
    *arXiv:1603.08983 [cs]*, March 2016, arXiv: 1603.08983\. [Online]. Available:
    [http://arxiv.org/abs/1603.08983](http://arxiv.org/abs/1603.08983)'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Lu, C. Xiong, D. Parikh, and R. Socher, “Knowing when to look: Adaptive
    attention via a visual sentinel for image captioning,” in *Proceedings of the
    IEEE conference on computer vision and pattern recognition*, 2017, pp. 375–383.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] Z. Yang, D. Yang, C. Dyer, X. He, A. Smola, and E. Hovy, “Hierarchical
    attention networks for document classification,” in *Proceedings of the 2016 conference
    of the North American chapter of the association for computational linguistics:
    human language technologies*, 2016, pp. 1480–1489.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] J. Zhang, S. A. Bargal, Z. Lin, J. Brandt, X. Shen, and S. Sclaroff, “Top-down
    neural attention by excitation backprop,” *International Journal of Computer Vision*,
    vol. 126, no. 10, pp. 1084–1102, 2018.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] C. Xiong, V. Zhong, and R. Socher, “Dynamic coattention networks for question
    answering,” *arXiv preprint arXiv:1611.01604*, 2016.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] J. Liu, G. Wang, P. Hu, L.-Y. Duan, and A. C. Kot, “Global context-aware
    attention lstm networks for 3d action recognition,” in *The IEEE Conference on
    Computer Vision and Pattern Recognition (CVPR)*, July 2017.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] S. Reed, Y. Chen, T. Paine, A. v. d. Oord, S. M. A. Eslami, D. Rezende,
    O. Vinyals, and N. de Freitas, “Few-shot autoregressive density estimation: Towards
    learning to learn distributions,” *arXiv:1710.10304 [cs]*, October 2017, arXiv:
    1710.10304\. [Online]. Available: [http://arxiv.org/abs/1710.10304](http://arxiv.org/abs/1710.10304)'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] P. H. Seo, A. Lehrmann, B. Han, and L. Sigal, “Visual reference resolution
    using attention memory for visual dialog,” *arXiv preprint arXiv:1709.07992*,
    2017.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] N. R. Ke, A. Goyal, O. Bilaniuk, J. Binas, M. C. Mozer, C. Pal, and Y. Bengio,
    “Sparse attentive backtracking: Temporal creditassignment through reminding,”
    *arXiv preprint arXiv:1809.03702*, 2018.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] N. R. Ke, A. Goyal, O. Bilaniuk, J. Binas, L. Charlin, C. Pal, and Y. Bengio,
    “Sparse attentive backtracking: Long-range credit assignment in recurrent networks,”
    *arXiv preprint arXiv:1711.02326*, 2017.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] J. Choi, H. J. Chang, S. Yun, T. Fischer, Y. Demiris, and J. Y. Choi,
    “Attentional correlation filter network for adaptive visual tracking,” in *2017
    IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, July 2017,
    pp. 4828–4837.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] Y. Kim, C. Denton, L. Hoang, and A. M. Rush, “Structured attention networks,”
    *arXiv:1702.00887 [cs]*, February 2017, arXiv: 1702.00887\. [Online]. Available:
    [http://arxiv.org/abs/1702.00887](http://arxiv.org/abs/1702.00887)'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] J.-H. Kim, J. Jun, and B.-T. Zhang, “Bilinear attention networks,” in
    *Advances in Neural Information Processing Systems 31*, S. Bengio, H. Wallach,
    H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds.   Curran Associates,
    Inc., 2018, pp. 1564–1574\. [Online]. Available: [http://papers.nips.cc/paper/7429-bilinear-attention-networks.pdf](http://papers.nips.cc/paper/7429-bilinear-attention-networks.pdf)'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] J. Schlemper, O. Oktay, M. Schaap, M. Heinrich, B. Kainz, B. Glocker,
    and D. Rueckert, “Attention gated networks: Learning to leverage salient regions
    in medical images,” *Medical image analysis*, vol. 53, pp. 197–207, 2019.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] D. Perera and R. Zimmermann, “Lstm networks for online cross-network recommendations,”
    *arXiv preprint arXiv:2008.10849*, 2020.'
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Y. Deng, Y. Kim, J. Chiu, D. Guo, and A. Rush, “Latent alignment and variational
    attention,” in *Advances in Neural Information Processing Systems 31*, S. Bengio,
    H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, Eds.   Curran
    Associates, Inc., 2018, pp. 9712–9724\. [Online]. Available: [http://papers.nips.cc/paper/8179-latent-alignment-and-variational-attention.pdf](http://papers.nips.cc/paper/8179-latent-alignment-and-variational-attention.pdf)'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] E.-S. Kim, W. Y. Kang, K.-W. On, Y.-J. Heo, and B.-T. Zhang, “Hypergraph
    attention networks for multimodal learning,” in *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*, 2020, pp. 14 581–14 590.'
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] H. Chen, G. Ding, X. Liu, Z. Lin, J. Liu, and J. Han, “Imram: Iterative
    matching with recurrent attention memory for cross-modal image-text retrieval,”
    in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2020, pp. 12 655–12 663.'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] K. Lekkala and L. Itti, “Attentive feature reuse for multi task meta learning,”
    *arXiv preprint arXiv:2006.07438*, 2020.'
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] T. Shen, T. Zhou, G. Long, J. Jiang, S. Pan, and C. Zhang, “Disan: Directional
    self-attention network for rnn/cnn-free language understanding,” in *Proceedings
    of the AAAI Conference on Artificial Intelligence*, vol. 32, no. 1, 2018.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] H. Kim, A. Mnih, J. Schwarz, M. Garnelo, A. Eslami, D. Rosenbaum, O. Vinyals,
    and Y. W. Teh, “Attentive neural processes,” *arXiv preprint arXiv:1901.05761*,
    2019.'
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] S. Mittal, A. Lamb, A. Goyal, V. Voleti, M. Shanahan, G. Lajoie, M. Mozer,
    and Y. Bengio, “Learning to combine top-down and bottom-up signals in recurrent
    neural networks with attention over modules,” in *International Conference on
    Machine Learning*.   PMLR, 2020, pp. 6972–6986.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] J. Kim, M. Ma, T. Pham, K. Kim, and C. D. Yoo, “Modality shifting attention
    network for multi-modal video question answering,” in *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*, 2020, pp. 10 106–10 115.'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] M. W. Eysenck, *Psychology: An international perspective*.   Taylor &
    Francis, 2004.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] K. Oberauer, “Working memory and attention–a conceptual analysis and review,”
    *Journal of cognition*, vol. 2, no. 1, 2019.'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] M. Esterman and D. Rothlein, “Models of sustained attention,” *Current
    opinion in psychology*, vol. 29, pp. 174–180, 2019.'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] D. A. Hudson and C. D. Manning, “Compositional attention networks for
    machine reasoning,” *arXiv preprint arXiv:1803.03067*, 2018.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] H. Nam, J.-W. Ha, and J. Kim, “Dual attention networks for multimodal
    reasoning and matching,” in *Proceedings of the IEEE conference on computer vision
    and pattern recognition*, 2017, pp. 299–307.'
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] K. M. Hermann, T. Kočiský, E. Grefenstette, L. Espeholt, W. Kay, M. Suleyman,
    and P. Blunsom, “Teaching machines to read and comprehend,” *arXiv:1506.03340
    [cs]*, June 2015, arXiv: 1506.03340\. [Online]. Available: [http://arxiv.org/abs/1506.03340](http://arxiv.org/abs/1506.03340)'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] Q. Mao, J. Li, S. Wang, Y. Zhang, H. Peng, M. He, and L. Wang, “Aspect-based
    sentiment classification with attentive neural turing machines.” in *IJCAI*, 2019,
    pp. 5139–5145.'
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] S. Yantis, “The neural basis of selective attention: Cortical sources
    and targets of attentional modulation,” *Current directions in psychological science*,
    vol. 17, no. 2, pp. 86–90, 2008.'
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] M. Saenz, G. T. Buracas, and G. M. Boynton, “Global effects of feature-based
    attention in human visual cortex,” *Nature neuroscience*, vol. 5, no. 7, pp. 631–632,
    2002.'
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] K. M. O’Craven, P. E. Downing, and N. Kanwisher, “fmri evidence for objects
    as the units of attentional selection,” *Nature*, vol. 401, no. 6753, pp. 584–587,
    1999.'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] X. Wang, H. Ji, C. Shi, B. Wang, P. Cui, P. Yu, and Y. Ye, “Heterogeneous
    graph attention network,” *arXiv:1903.07293 [cs]*, March 2019, arXiv: 1903.07293\.
    [Online]. Available: [http://arxiv.org/abs/1903.07293](http://arxiv.org/abs/1903.07293)'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] B. A. Olshausen, C. H. Anderson, and D. C. Van Essen, “A neurobiological
    model of visual attention and invariant pattern recognition based on dynamic routing
    of information,” *Journal of Neuroscience*, vol. 13, no. 11, pp. 4700–4719, 1993.'
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] G. E. Hinton, “Deep belief networks,” *Scholarpedia*, vol. 4, no. 5, p.
    5947, 2009.'
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] D. K. Lee, L. Itti, C. Koch, and J. Braun, “Attention activates winner-take-all
    competition among visual filters,” *Nature neuroscience*, vol. 2, no. 4, pp. 375–381,
    1999.'
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] J. K. Tsotsos, S. M. Culhane, W. Y. K. Wai, Y. Lai, N. Davis, and F. Nuflo,
    “Modeling visual attention via selective tuning,” *Artificial intelligence*, vol. 78,
    no. 1-2, pp. 507–545, 1995.'
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] J. Weston, S. Chopra, and A. Bordes, “Memory networks,” *arXiv preprint
    arXiv:1410.3916*, 2014.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-training
    of deep bidirectional transformers for language understanding,” *arXiv:1810.04805
    [cs]*, October 2018, arXiv: 1810.04805\. [Online]. Available: [http://arxiv.org/abs/1810.04805](http://arxiv.org/abs/1810.04805)'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever, “Language
    models are unsupervised multitask learners,” *OpenAI blog*, vol. 1, no. 8, p. 9,
    2019.'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,
    P. Shyam, G. Sastry, A. Askell *et al.*, “Language models are few-shot learners,”
    *arXiv preprint arXiv:2005.14165*, 2020.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] M. D. M. Reddy, M. S. M. Basha, M. M. C. Hari, and M. N. Penchalaiah,
    “Dall-e: Creating images from text,” 2021.'
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] S. Frintrop, *VOCUS: A visual attention system for object detection and
    goal-directed search*.   Springer, 2006, vol. 3899.'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] L. Itti, C. Koch, and E. Niebur, “A model of saliency-based visual attention
    for rapid scene analysis,” *IEEE PAMI*, vol. 20, no. 11, pp. 1254–1259, 1998.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] C. O’Callaghan, “Perception and multimodality,” *The*, 2012.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] C. Doersch, “Tutorial on variational autoencoders,” *arXiv preprint arXiv:1606.05908*,
    2016.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] J. Pennington, R. Socher, and C. D. Manning, “Glove: Global vectors for
    word representation,” in *Proceedings of the 2014 conference on empirical methods
    in natural language processing (EMNLP)*, 2014, pp. 1532–1543.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] R. K. Srivastava, K. Greff, and J. Schmidhuber, “Highway networks,” *arXiv
    preprint arXiv:1505.00387*, 2015.'
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] M. Schuster and K. K. Paliwal, “Bidirectional recurrent neural networks,”
    *IEEE Transactions on Signal Processing*, vol. 45, no. 11, pp. 2673–2681, 1997.'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] J. L. Ba, J. R. Kiros, and G. E. Hinton, “Layer normalization,” *arXiv
    preprint arXiv:1607.06450*, 2016.'
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[102] A. M. Treisman and G. Gelade, “A feature-integration theory of attention,”
    *Cognitive psychology*, vol. 12, no. 1, pp. 97–136, 1980.'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[103] G. Backer, B. Mertsching, and M. Bollmann, “Data-and model-driven gaze
    control for an active-vision system,” *IEEE Transactions on Pattern Analysis and
    Machine Intelligence*, vol. 23, no. 12, pp. 1415–1429, 2001.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[104] S. Frintrop, E. Rome, and H. I. Christensen, “Computational visual attention
    systems and their cognitive foundations: A survey,” *ACM Transactions on Applied
    Perception (TAP)*, vol. 7, no. 1, pp. 1–39, 2010.'
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[105] D. Kahneman, “Maps of bounded rationality: Psychology for behavioral
    economics,” *American economic review*, vol. 93, no. 5, pp. 1449–1475, 2003.'
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[106] C. Xiong, S. Merity, and R. Socher, “Dynamic memory networks for visual
    and textual question answering,” *arXiv:1603.01417 [cs]*, March 2016, arXiv: 1603.01417\.
    [Online]. Available: [http://arxiv.org/abs/1603.01417](http://arxiv.org/abs/1603.01417)'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
