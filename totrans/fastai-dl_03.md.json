["```py\n$ kg download -u <username> -p <password> -c <competition>\n```", "```py\n$ kg download -u john.doe -p mypassword -c dog-breed-identification\n```", "```py\n**from** fastai.conv_learner **import** * \nPATH = 'data/dogscats/'\nsz=224; bs=64\n```", "```py\ndata = ImageClassifierData.from_paths(PATH, tfms= tfms, bs=bs, test_name='test')\n```", "```py\nlearn = ConvLearner.pretrained(resnet50, data)\n```", "```py\nlearn.unfreeze() \nlearn.**bn_freeze**(**True**) \n%time learn.fit([1e-5, 1e-4,1e-2], 1, cycle_len=1)\n```", "```py\ntrain_data_dir = f'{PATH}train' \nvalidation_data_dir = f'{PATH}valid'train_datagen = ImageDataGenerator(rescale=1\\. / 255,\n    shear_range=0.2, zoom_range=0.2, horizontal_flip=True)test_datagen = ImageDataGenerator(rescale=1\\. / 255)train_generator = train_datagen.flow_from_directory(train_data_dir,\n    target_size=(sz, sz),\n    batch_size=batch_size, class_mode='binary')validation_generator = test_datagen.flow_from_directory(\n    validation_data_dir,\n    shuffle=False,\n    target_size=(sz, sz),\n    batch_size=batch_size, class_mode='binary')\n```", "```py\nbase_model = ResNet50(weights='imagenet', include_top=False)\nx = base_model.output\nx = GlobalAveragePooling2D()(x)\nx = Dense(1024, activation='relu')(x)\npredictions = Dense(1, activation='sigmoid')(x)\n```", "```py\nmodel = Model(inputs=base_model.input, outputs=predictions)for layer in base_model.layers: layer.trainable = Falsemodel.compile(optimizer='rmsprop', loss='binary_crossentropy', \n    metrics=['accuracy'])\n```", "```py\nmodel.fit_generator(train_generator, **train_generator.n//batch_size**,\n    epochs=3, **workers=4**, validation_data=validation_generator,\n    validation_steps=validation_generator.n // batch_size)\n```", "```py\nsplit_at = 140**for** layer **in** model.layers[:split_at]: layer.trainable = **False**\n**for** layer **in** model.layers[split_at:]: layer.trainable = **True**model.compile(optimizer='rmsprop', loss='binary_crossentropy',\n    metrics=['accuracy'])%%time model.fit_generator(train_generator, \n    train_generator.n // batch_size, epochs=1, workers=3,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.n // batch_size)\n```", "```py\nlog_preds, y = learn.TTA(is_test=True)\nprobs = np.exp(log_preds)\n```", "```py\nds = pd.DataFrame(probs)\nds.columns = data.classes\n```", "```py\nds.insert(0, 'id', [o[5:-4] **for** o **in** data.test_ds.fnames])\n```", "```py\nds.head()\n```", "```py\nSUBM = f'{PATH}sub/' \nos.makedirs(SUBM, exist_ok=**True**) \nds.to_csv(f'{SUBM}subm.gz', compression='gzip', index=**False**)\n```", "```py\nFileLink(f'{SUBM}subm.gz')\n```", "```py\nfn = data.val_ds.fnames[0]; fn*'train/**001513dfcb2ffafc82cccf4d8bbaba97.jpg**'*Image.open(PATH + fn)\n```", "```py\ntrn_tfms, val_tfms = tfms_from_model(arch, sz)im = val_tfms(Image.open(PATH+fn)\n\npreds = learn.predict_array(im[None])np.argmax(preds)\n```", "```py\n**from** **planet** **import** f2\n\nmetrics=[f2]\nf_model = resnet34label_csv = f'**{PATH}**train_v2.csv'\nn = len(list(open(label_csv)))-1\nval_idxs = get_cv_idxs(n)**def** get_data(sz):\n    tfms = tfms_from_model(f_model, sz,\n        aug_tfms=**transforms_top_down**, max_zoom=1.05) **return** ImageClassifierData.**from_csv**(PATH, 'train-jpg',\n               label_csv, tfms=tfms, suffix='.jpg',\n               val_idxs=val_idxs, test_name='test-jpg')data = get_data(256)\n```", "```py\nx,y = next(iter(data.val_dl))\n```", "```py\nlist(zip(data.classes, y[0]))\n\n*[('agriculture', 1.0),\n ('artisinal_mine', 0.0),\n ('bare_ground', 0.0),\n ('blooming', 0.0),\n ('blow_down', 0.0),\n ('clear', 1.0),\n ('cloudy', 0.0),\n ('conventional_mine', 0.0),\n ('cultivation', 0.0),\n ('habitation', 0.0),\n ('haze', 0.0),\n ('partly_cloudy', 0.0),\n ('primary', 1.0),\n ('road', 0.0),\n ('selective_logging', 0.0),\n ('slash_burn', 1.0),\n ('water', 1.0)]*\n```", "```py\nplt.imshow(data.val_ds.denorm(to_np(x))[0]*1.4);\n```", "```py\nsz=64data = get_data(sz)\ndata = data.resize(int(sz*1.3), 'tmp')\n```", "```py\nlearn = ConvLearner.pretrained(f_model, data, metrics=metrics)lrf=learn.lr_find() \nlearn.sched.plot()\n```", "```py\nlr = 0.2\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)*[ 0\\.       0.14882  0.13552  0.87878]                        \n[ 1\\.       0.14237  0.13048  0.88251]                        \n[ 2\\.       0.13675  0.12779  0.88796]                        \n[ 3\\.       0.13528  0.12834  0.88419]                        \n[ 4\\.       0.13428  0.12581  0.88879]                        \n[ 5\\.       0.13237  0.12361  0.89141]                        \n[ 6\\.       0.13179  0.12472  0.8896 ]*lrs = np.array(**[lr/9, lr/3, lr]**)learn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)*[ 0\\.       0.12534  0.10926  0.90892]                        \n[ 1\\.       0.12035  0.10086  0.91635]                        \n[ 2\\.       0.11001  0.09792  0.91894]                        \n[ 3\\.       0.1144   0.09972  0.91748]                        \n[ 4\\.       0.11055  0.09617  0.92016]                        \n[ 5\\.       0.10348  0.0935   0.92267]                        \n[ 6\\.       0.10502  0.09345  0.92281]*\n```", "```py\nlearn.sched.plot_loss()\n```", "```py\n**sz = 128**\nlearn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)*[ 0\\.       0.09729  0.09375  0.91885]                         \n[ 1\\.       0.10118  0.09243  0.92075]                         \n[ 2\\.       0.09805  0.09143  0.92235]                         \n[ 3\\.       0.09834  0.09134  0.92263]                         \n[ 4\\.       0.096    0.09046  0.9231 ]                         \n[ 5\\.       0.09584  0.09035  0.92403]                         \n[ 6\\.       0.09262  0.09059  0.92358]*learn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\nlearn.save(f'{sz}')*[ 0\\.       0.09623  0.08693  0.92696]                         \n[ 1\\.       0.09371  0.08621  0.92887]                         \n[ 2\\.       0.08919  0.08296  0.93113]                         \n[ 3\\.       0.09221  0.08579  0.92709]                         \n[ 4\\.       0.08994  0.08575  0.92862]                         \n[ 5\\.       0.08729  0.08248  0.93108]                         \n[ 6\\.       0.08218  0.08315  0.92971]***sz = 256**\nlearn.set_data(get_data(sz))\nlearn.freeze()\nlearn.fit(lr, 3, cycle_len=1, cycle_mult=2)*[ 0\\.       0.09161  0.08651  0.92712]                         \n[ 1\\.       0.08933  0.08665  0.92677]                         \n[ 2\\.       0.09125  0.08584  0.92719]                         \n[ 3\\.       0.08732  0.08532  0.92812]                         \n[ 4\\.       0.08736  0.08479  0.92854]                         \n[ 5\\.       0.08807  0.08471  0.92835]                         \n[ 6\\.       0.08942  0.08448  0.9289 ]*learn.unfreeze()\nlearn.fit(lrs, 3, cycle_len=1, cycle_mult=2)\nlearn.save(f'{sz}')*[ 0\\.       0.08932  0.08218  0.9324 ]                         \n[ 1\\.       0.08654  0.08195  0.93313]                         \n[ 2\\.       0.08468  0.08024  0.93391]                         \n[ 3\\.       0.08596  0.08141  0.93287]                         \n[ 4\\.       0.08211  0.08152  0.93401]                         \n[ 5\\.       0.07971  0.08001  0.93377]                         \n[ 6\\.       0.07928  0.0792   0.93554]*log_preds,y = learn.TTA()\npreds = np.mean(np.exp(log_preds),0)\nf2(preds,y)*0.93626519738612801*\n```", "```py\ndata = data.resize(int(sz*1.3), 'tmp')\n```", "```py\ntfms = tfms_from_model(f_model, sz,\n        aug_tfms=transforms_top_down, max_zoom=1.05)\n```", "```py\nmetrics=[f2]\n```", "```py\nlearn.summary()*[('Conv2d-1',\n  OrderedDict([('input_shape', [-1, 3, 64, 64]),\n               ('output_shape', [-1, 64, 32, 32]),\n               ('trainable', False),\n               ('nb_params', 9408)])),\n ('BatchNorm2d-2',\n  OrderedDict([('input_shape', [-1, 64, 32, 32]),\n               ('output_shape', [-1, 64, 32, 32]),\n               ('trainable', False),\n               ('nb_params', 128)])),\n ('ReLU-3',\n  OrderedDict([('input_shape', [-1, 64, 32, 32]),\n               ('output_shape', [-1, 64, 32, 32]),\n               ('nb_params', 0)])),\n ('MaxPool2d-4',\n  OrderedDict([('input_shape', [-1, 64, 32, 32]),\n               ('output_shape', [-1, 64, 16, 16]),\n               ('nb_params', 0)])),\n ('Conv2d-5',\n  OrderedDict([('input_shape', [-1, 64, 16, 16]),\n               ('output_shape', [-1, 64, 16, 16]),\n               ('trainable', False),\n               ('nb_params', 36864)]))*\n ...\n```", "```py\n**from** **fastai.structured** **import** *\n**from** **fastai.column_data** **import** *\nnp.set_printoptions(threshold=50, edgeitems=20)\n\nPATH='data/rossmann/'\n```", "```py\ntable_names = ['train', 'store', 'store_states', 'state_names', \n               'googletrend', 'weather', 'test']tables = [pd.read_csv(f'{PATH}{fname}.csv', low_memory=False) for fname in table_names]for t in tables: display(t.head())\n```", "```py\ndef join_df(left, right, left_on, right_on=None, suffix='_y'):\n    if right_on is None: right_on = left_on\n\n    return left.**merge**(right, how='left', left_on=left_on,\n        right_on=right_on, suffixes=(\"\", suffix))\n```", "```py\nadd_datepart(train, \"Date\", drop=False)\n```", "```py\njoined.to_feather(f'{PATH}joined')\n```"]