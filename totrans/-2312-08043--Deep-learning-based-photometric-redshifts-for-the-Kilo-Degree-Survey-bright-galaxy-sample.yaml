- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:35:37'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2312.08043] Deep learning based photometric redshifts for the Kilo-Degree
    Survey bright galaxy sample'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2312.08043](https://ar5iv.labs.arxiv.org/html/2312.08043)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '[cft] [cft] [cft] [cft] cft]Center For Theoretical Physics, Aleja Lotników
    32/46, 02-668 Warsaw, Poland \headtitleDeep-learning photometric redshifts for
    KiDS DR4 bright galaxies'
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning based photometric redshifts for the Kilo-Degree Survey bright
    galaxy sample
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Anjitha John William    Priyanka Jalan    Maciej Bilicki    Wojciech A. Hellwing
    [
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: In cosmological analyses, precise redshift determination remains pivotal for
    understanding cosmic evolution. However, with only a fraction of galaxies having
    spectroscopic redshifts (spec-$z$s), the challenge lies in estimating redshifts
    for a larger number. To address this, photometry-based redshift (photo-$z$) estimation,
    employing machine learning algorithms, is a viable solution. Identifying the limitations
    of previous methods, this study focuses on implementing deep learning (DL) techniques
    within the Kilo-Degree Survey (KiDS) Bright Sample for more accurate photo-$z$
    estimations. Comparing our new DL-based model against prior ‘shallow’ neural networks,
    we showcase improvements in redshift accuracy. Our model gives mean photo-$z$
    bias $\langle\Delta z\rangle=10^{-3}$ and scatter $\mathrm{SMAD}(\Delta z)=0.016$,
    where $\Delta z=(z_{\mathrm{phot}}-z_{\mathrm{spec}})/(1+z_{\mathrm{spec}})$.
    This research highlights the promising role of DL in revolutionizing photo-$z$
    estimation.
  prefs: []
  type: TYPE_NORMAL
- en: 1 Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Redshift is a basic quantity in cosmological analyses, serving as one of the
    indicators of galaxy distances. Its precise determination enables the mapping
    of the three-dimensional large-scale structure of the Universe and facilitates
    our comprehension of cosmic evolution. Achieving sub-percent accuracy in redshift
    measurements is exclusively feasible through spectroscopy. In obtaining spectroscopic
    redshifts (spec-zs), we initially capture the spectrum of a celestial source and
    subsequently identify the shift in spectral lines relative to their rest frame.
  prefs: []
  type: TYPE_NORMAL
- en: Due to expensive telescope time needed, spec-$z$s are only attainable for a
    fraction of galaxies. However, a viable alternative is the estimation of redshifts
    through photometric measurements. Such photometric redshifts (photo-$z$s) may
    not provide the same level of redshift accuracy and precision as spec-$z$s; however,
    they have proven indispensable in the era of massive imaging surveys. Such redshift
    estimates rely on the correlation between observed galaxy photometry and the true
    redshift (e.g. Baum, [1957](#bib.bib2)). This proceeding focuses on estimating
    this correlation using machine learning (ML) algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning-based techniques for photo-z estimation include supervised
    learning (Wadadekar, [2005](#bib.bib26); Collister & Lahav, [2004](#bib.bib6);
    Oyaizu et al., [2008](#bib.bib22)), unsupervised learning (Way & Klose, [2012](#bib.bib27)),
    k-nearest neighbors (Graham et al., [2018](#bib.bib13)), ensemble learning and
    Gaussian processes (Way & Srivastava, [2006](#bib.bib28); Bonfield et al., [2010](#bib.bib4)),
    mixed density networks (Ansari et al., [2021](#bib.bib1)) and finally, deep neural
    networks (Hoyle et al., [2015](#bib.bib15); D’Isanto & Polsterer, [2018](#bib.bib9)).
    In supervised ML techniques, the algorithm establishes an empirical relationship
    between observed quantities and corresponding labels through training on appropriately
    labeled data. The main challenge and limitation of these methods lie in extrapolating
    results beyond the representative training set.
  prefs: []
  type: TYPE_NORMAL
- en: Deep learning (DL) based photo-$z$ derivation is a promising technique among
    other supervised ML techniques (e.g. Menou, [2019](#bib.bib21); Dey et al., [2022](#bib.bib8);
    Li et al., [2022](#bib.bib19); Treyer et al., [2024](#bib.bib25)). In such frameworks,
    the term ‘deep’ signifies that the models typically employ intricate, multi-layer
    architectures. Deep learning methods, specifically convolutional neural networks
    (CNNs), are selected for predicting photo-zs due to their exceptional ability
    to discern patterns in data, particularly images.
  prefs: []
  type: TYPE_NORMAL
- en: In this work, we present a deep learning model for photometric redshift estimation
    of bright galaxies in the Kilo-Degree Survey (KiDS, de Jong et al., [2013](#bib.bib7)),
    a multiband imaging survey covering about 1350 deg² of the sky. Following up on
    earlier KiDS work by Li et al. ([2022](#bib.bib19)), we applied the DL models
    for photo-z estimation within the flux-limited ‘KiDS Bright Sample’, encompassing
    all galaxies from KiDS with $r<20$ mag (Bilicki et al., [2021](#bib.bib3)). We
    compare our derivations with the previously released KiDS bright sample photo-zs
    obtained with ‘shallow’ neural networks from the public package ANNz2 (Sadeh et al.,
    [2016](#bib.bib23)). Our new model improves over those previous results and gives
    great perspectives for the final KiDS data release.
  prefs: []
  type: TYPE_NORMAL
- en: 2 Input Data
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This section details the datasets used in this study. The training sample required
    for the neural network is KiDS-DR4 four-band (u, g, r, and i) optical galaxy images
    and their 9-band magnitudes, with their corresponding labels of true (spectroscopic)
    redshifts from the Galaxy And Mass Assembly (GAMA, Driver et al., [2011](#bib.bib10))
    survey.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1 Images and Photometry
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: KiDS is an extensive optical survey conducted by the European Southern Observatory
    (ESO) at the VLT Survey Telescope (VST, Capaccioli & Schipani, [2011](#bib.bib5)),
    which utilizes the OmegaCAM CCD mosaic camera, boasting an impressive 268 million-pixel
    focal plane. It is positioned at the ESO Paranal Observatory in Chile. The VST
    is an alt-azimuth mounted telescope based on a modified Ritchey-Chrétien design.
    KiDS captured images in four distinct broad bands ($ugri$) and encompasses an
    area of 1350 square degrees within the extragalactic sky.
  prefs: []
  type: TYPE_NORMAL
- en: We have used KiDS Data Release 4 (DR4, Kuijken et al., [2019](#bib.bib17))¹¹1[https://kids.strw.leidenuniv.nl/DR4](https://kids.strw.leidenuniv.nl/DR4)
    co-added images that had been calibrated for both astrometry and photometry, ensuring
    a consistent pixel scale of 0.2 arcseconds. We have also incorporated the nine-band
    magnitudes of galaxies. These latter join original KiDS $ugri$ measurements with
    those from the VIKING (Edge et al., [2013](#bib.bib12)) survey, encompassing five
    near-IR bands ($ZYJHK_{s}$).
  prefs: []
  type: TYPE_NORMAL
- en: 2.2 GAMA Spectroscopic Data
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The true (spectroscopic) redshifts used for training and testing are obtained
    from the GAMA dataset. This survey, conducted across five fields, of which four
    are fully within the KiDS footprint, covers a total area of approx. 286 square
    degrees. The data were obtained using the AAOmega fiber-fed spectrograph facility
    mounted on the 3.9-meter Anglo-Australian Telescope (Driver et al., [2011](#bib.bib10)).
    GAMA gives spectra, redshifts, their quality, and other ancillary information.
    KiDS-DR4 fully overlaps with the G09, G12, G15 and G23 fields. In this work, we
    have used the GAMA-II spectroscopic redshift catalog of galaxies from the GAMA
    DR4 (Driver et al., [2022](#bib.bib11))²²2[http://www.gama-survey.org/dr4](http://www.gama-survey.org/dr4).
  prefs: []
  type: TYPE_NORMAL
- en: We have identified galaxies within KiDS tiles that overlap between the GAMA
    and KiDS-bright sample based on their sky coordinates. Subsequently, we created
    cutouts for these galaxies, positioning each at the center of the cutout with
    dimensions of $7.2^{\prime\prime}\times 7.2^{\prime\prime}$. The final cutout
    catalog comprises $\sim 136$k galaxies in the equatorial field, with $\sim 95$k
    utilized for model training. Model testing was conducted on $\sim 20$k galaxies
    present in both the equatorial field and KiDS bright sample.
  prefs: []
  type: TYPE_NORMAL
- en: 2.3 KiDS-DR4 Bright Galaxy Sample
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The KiDS-bright galaxy sample (Bilicki et al., [2021](#bib.bib3)) is a collection
    of KiDS galaxies selected based on their flux and free from artifacts etc. Specifically,
    it includes galaxies with a magnitude limit of $r_{\mathrm{auto}}<20$ mag, where
    ‘auto’ stands for SExtractor-derived estimate of the total flux via automatic
    aperture photometry.
  prefs: []
  type: TYPE_NORMAL
- en: 3 Methodology
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Convolutional Neural Networks (CNNs), a subtype of Artificial Neural Networks
    (ANNs), excel in addressing computer vision challenges like image detection and
    classification. The operational principles of CNNs draw inspiration from the human
    neural system, mirroring the functionality of neurons (McCulloch, [1943](#bib.bib20)).
    Similar to biological neurons that receive input and transmit electrochemical
    signals, CNNs employ artificial neurons to process information. The importance
    of CNNs becomes apparent through their widespread application in image recognition
    tasks, as highlighted by e.g. LeCun et al. ([1998](#bib.bib18)). The adaptability
    and efficacy of CNNs make them a key technology in the field of computer vision,
    contributing significantly to advancements in image-based tasks. Our model includes
    a special CNN architecture called Inception (Szegedy et al., [2015](#bib.bib24)).
    Our approach employs CNNs to forecast the photo-zs for the KiDS-bright sample,
    treating it as a regression problem. To label the training set, we used the spectroscopic
    GAMA data detailed earlier.
  prefs: []
  type: TYPE_NORMAL
- en: 'Our ML model for photo-zs is a combined, multi-input one. Inspired by Henghes
    et al. ([2022](#bib.bib14)); Li et al. ([2022](#bib.bib19)), we use both 4-band
    KiDS images and the corresponding 9-band KiDS+VIKING magnitudes. We combined two
    different ML schemes: ordinary neural networks (ONN) and CNN (Inception). The
    architecture of our model is shown in Fig. [3](#S3 "3 Methodology ‣ Deep learning
    based photometric redshifts for the Kilo-Degree Survey bright galaxy sample").'
  prefs: []
  type: TYPE_NORMAL
- en: 'When tuning the model and assessing its performance, we primarily employed
    three metrics: Mean Squared Error (MSE), Mean Absolute Error (MAE), and R-squared
    error ($R^{2}$):'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $R^{2}=1-\frac{\sum_{i=1}^{n}(z_{i}-\hat{z}_{i})^{2}}{\sum_{i=1}^{n}(z_{i}-\bar{z})^{2}}\;,$
    |  | (1) |'
  prefs: []
  type: TYPE_TB
- en: where $n$ is the number of samples used, $z_{i}$ is the predicted value, $\hat{z}_{i}$
    is the true value, and $\bar{z}$ is the mean of true redshift values. $R^{2}$
    is a statistical measure indicating how well a model predicts outcomes in a regression
    analysis. It represents the proportion of variance explained by the model relative
    to the total variance. In an ideal scenario, its value is unity, and our combined
    model has demonstrated the capability to achieve an $R^{2}$ value exceeding $0.92$.
  prefs: []
  type: TYPE_NORMAL
- en: 'MSE is effective for learning outliers, while MAE is advantageous for disregarding
    them. In our approach, we employed the Huber ([1964](#bib.bib16)) loss function
    that combines the characteristics of both MSE and MAE, providing a balanced approach
    to handling outliers during the training of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | $H(z,\hat{z})=\begin{cases}\frac{1}{2}(z-\hat{z})^{2},&amp;\text{if }&#124;z-\hat{z}&#124;\leq\delta,\\
    \delta(&#124;z-\hat{z}&#124;-\frac{\delta}{2}),&amp;\text{otherwise}.\end{cases}$
    |  | (2) |'
  prefs: []
  type: TYPE_TB
- en: The value of $\delta$ we use is 0.0001 by trial and error.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f0f63db3234abb2951beaebdee1ad7a3.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Architecture of the Combined model.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/ea7dd52eb342b18ea04391901c7084a7.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Comparison of spectroscopic and the predicted photometric redshifts for
    the test sample. The thick red solid line represents the running median, while
    the thinner red lines enclose the scatter, quantified by the SMAD.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/f69f7274ce63975cba4597045df6213a.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Normalised bias as a function of photo-$z$, with red lines encoding the
    running median and SMAD as in the upper panel.
  prefs: []
  type: TYPE_NORMAL
- en: 4 Results
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The photo-z performance is evaluated using the following statistics:'
  prefs: []
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'bias:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\delta z=z_{\mathrm{phot}}-z_{\mathrm{spec}}\,,$ |  | (3) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'normalized bias:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\Delta z=\frac{\delta z}{1+z_{\mathrm{spec}}}\,,$ |  | (4) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: the standard deviation of $\Delta z$,
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: •
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: scaled median absolute deviation (SMAD) of $\Delta z$, where
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '|  | $\text{SMAD}(x)=1.4826\times\text{median}\left(\lvert x-\text{median}(x)\rvert\right)\,.$
    |  | (5) |'
  prefs:
  - PREF_IND
  type: TYPE_TB
- en: These statistics for the overall test sample (based on GAMA equatorial data)
    are provided in Table [1](#S4.T1 "Table 1 ‣ 4 Results ‣ Deep learning based photometric
    redshifts for the Kilo-Degree Survey bright galaxy sample"), where they are directly
    compared with previous results from Bilicki et al. ([2021](#bib.bib3)), derived
    with the ANNz2 software employing 9-band KiDS+VIKING magnitudes. There is visible
    improvement in terms of scatter, both in the standard deviation and SMAD, from
    the earlier ANNz2 results to our new DL model. This shows that our combined model
    gives promise for improved photo-$z$s for the KiDS Bright Galaxy Sample. We additionally
    visualize our DL photo-$z$ performance in Figs. [3](#S3 "3 Methodology ‣ Deep
    learning based photometric redshifts for the Kilo-Degree Survey bright galaxy
    sample") & [3](#S3 "3 Methodology ‣ Deep learning based photometric redshifts
    for the Kilo-Degree Survey bright galaxy sample"), which show generally unbiased
    and stable photo-$z$s as a function of the photometric redshift itself.
  prefs: []
  type: TYPE_NORMAL
- en: 'Table 1: Statistics of photometric redshift performance obtained for KiDS-GAMA
    equatorial spectroscopic sample.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method | $\langle\delta z\rangle$ | $\langle\Delta z\rangle$ | $\sigma(\Delta
    z)$ | SMAD$(\Delta z)$ |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| ANNz2 (Bilicki et al., [2021](#bib.bib3)) | $0.0005$ | $0.0009$ | $0.024$
    | $0.018$ |'
  prefs: []
  type: TYPE_TB
- en: '| Combined model (this work) | $0.001$ | $0.001$ | $0.021$ | $0.016$ |'
  prefs: []
  type: TYPE_TB
- en: 5 Conclusion and Future Prospects
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In these proceedings, we described a new deep-learning model for photometric
    redshift derivation in the KiDS bright sample that joins Inception-based CNN using
    4-band KiDS images, with an ANN employing 9-band magnitudes. We see improvement
    over previous work by Bilicki et al. ([2021](#bib.bib3)), where ANNs with magnitudes
    only were used. In the forthcoming paper, we will present more details and apply
    our model to the entire KiDS DR4 Bright Galaxy Sample, which will give new, improved
    photo-$z$s for that dataset.
  prefs: []
  type: TYPE_NORMAL
- en: In the near future, we plan to build a deep-learning model which will use the
    9-band imaging from both KiDS and VIKING (unlike KiDS $ugri$ only as presently).
    That model will be subsequently used to derive photo-$z$s for the Bright Galaxy
    Sample in the final KiDS Data Release 5 (Wright et al., in press; Wright, [2023](#bib.bib29)).
  prefs: []
  type: TYPE_NORMAL
- en: 6 Acknowledgement
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This work is funded via the research project ‘Precision and Accuracy for Cosmological
    Imaging Surveys (PACIS)’ from the Polish National Science Centre through a Sonata-Bis
    grant no. 2020/38/E/ST9/00395\. We thank Rui Li and Nicola Napolitano for their
    assistance and feedback.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Ansari et al. (2021) Ansari, Z., Agnello, A., Gall, C., *A&A* 650, A90 (2021)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Baum (1957) Baum, W. A., *AJ* 62, 6 (1957)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bilicki et al. (2021) Bilicki, M., et al., *A&A* 653, A82 (2021)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Bonfield et al. (2010) Bonfield, D. G., et al., *MNRAS* 405, 2, 987 (2010)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Capaccioli & Schipani (2011) Capaccioli, M., Schipani, P., *The Messenger* 146,
    2 (2011)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Collister & Lahav (2004) Collister, A. A., Lahav, O., *PASP* 116, 818, 345 (2004)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: de Jong et al. (2013) de Jong, J. T. A., Verdoes Kleijn, G. A., Kuijken, K. H.,
    Valentijn, E. A., *Experimental Astronomy* 35, 1-2, 25 (2013)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dey et al. (2022) Dey, B., et al., *MNRAS* 515, 4, 5285 (2022)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: D’Isanto & Polsterer (2018) D’Isanto, A., Polsterer, K. L., *A&A* 609, A111
    (2018)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Driver et al. (2011) Driver, S. P., et al., *MNRAS* 413, 2, 971 (2011)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Driver et al. (2022) Driver, S. P., et al., *MNRAS* 513, 1, 439 (2022)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Edge et al. (2013) Edge, A., et al., *The Messenger* 154, 32 (2013)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Graham et al. (2018) Graham, M. L., et al., *AJ* 155, 1, 1 (2018)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Henghes et al. (2022) Henghes, B., et al., *MNRAS* 512, 2, 1696 (2022)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hoyle et al. (2015) Hoyle, B., et al., *MNRAS* 449, 2, 1275 (2015)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Huber (1964) Huber, P. J., *Annals of Mathematical Statistics* 35, 492 (1964),
    URL [https://api.semanticscholar.org/CorpusID:121252793](https://api.semanticscholar.org/CorpusID:121252793)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kuijken et al. (2019) Kuijken, K., et al., *A&A* 625, A2 (2019)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: LeCun et al. (1998) LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., *Proc. IEEE*
    86, 2278 (1998), URL [https://api.semanticscholar.org/CorpusID:14542261](https://api.semanticscholar.org/CorpusID:14542261)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Li et al. (2022) Li, R., et al., *A&A* 666, A85 (2022)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: McCulloch (1943) McCulloch, *The bulletin of mathematical biophysics* (1943),
    URL [https://doi.org/10.1007/BF02478259](https://doi.org/10.1007/BF02478259)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Menou (2019) Menou, K., *MNRAS* 489, 4, 4802 (2019)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Oyaizu et al. (2008) Oyaizu, H., et al., *ApJ* 689, 2, 709 (2008)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sadeh et al. (2016) Sadeh, I., Abdalla, F. B., Lahav, O., *PASP* 128, 968, 104502
    (2016)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Szegedy et al. (2015) Szegedy, C., et al., in 2015 IEEE Conference on Computer
    Vision and Pattern Recognition (CVPR), 1–9 (2015)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Treyer et al. (2024) Treyer, M., et al., *MNRAS* 527, 1, 651 (2024)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wadadekar (2005) Wadadekar, Y., *PASP* 117, 827, 79 (2005)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Way & Klose (2012) Way, M. J., Klose, C. D., *PASP* 124, 913, 274 (2012)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Way & Srivastava (2006) Way, M. J., Srivastava, A. N., *ApJ* 647, 1, 102 (2006)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Wright (2023) Wright, A., in A Decade of ESO Wide-field Imaging Surveys (surveys2023,
    5 (2023)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
