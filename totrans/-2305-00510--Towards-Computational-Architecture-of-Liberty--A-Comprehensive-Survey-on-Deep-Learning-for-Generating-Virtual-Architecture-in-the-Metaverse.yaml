- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:40:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:40:11'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2305.00510] Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2305.00510] 朝向自由计算建筑：深度学习生成虚拟建筑的全面综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2305.00510](https://ar5iv.labs.arxiv.org/html/2305.00510)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2305.00510](https://ar5iv.labs.arxiv.org/html/2305.00510)
- en: 'Towards Computational Architecture of Liberty: A Comprehensive Survey on Deep
    Learning for Generating Virtual Architecture in the Metaverse'
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 朝向自由计算建筑：深度学习生成虚拟建筑的全面综述
- en: Anqi Wang Emerging Interdisciplinary Areas, Hong Kong University of Science
    and TechnologyHong Kong SARChina Computational Media and Arts, Hong Kong University
    of Science and Technology (Guangzhou)GuangzhouChina ,  Jiahua Dong School of Architecture,
    The Chinese University of Hong KongHong Kong SARChina ,  Jiachuan Shen The Bartlett
    School of Architecture, University College LondonLondonUK ,  Lik-Hang Lee The
    Hong Kong Polytechnic UniversityHong Kong SARChina  and  Pan Hui Computational
    Media and Arts, Hong Kong University of Science and Technology (Guangzhou)GuangzhouChina
    Emerging Interdisciplinary Areas, Hong Kong University of Science and TechnologyHong
    Kong SARChina(2018)
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: Anqi Wang 香港科技大学新兴交叉学科领域香港特别行政区中国 计算媒体与艺术，香港科技大学（广州）广州中国，Jiahua Dong 香港中文大学建筑学院香港特别行政区中国，Jiachuan
    Shen 伦敦大学学院巴特利特建筑学院伦敦英国，Lik-Hang Lee 香港理工大学香港特别行政区中国以及 Pan Hui 计算媒体与艺术，香港科技大学（广州）广州中国
    新兴交叉学科领域，香港科技大学香港特别行政区中国（2018）
- en: Abstract.
  id: totrans-8
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要。
- en: 3D shape generation techniques utilizing deep learning are increasing attention
    from both computer vision and architectural design. This survey focuses on investigating
    and comparing the current latest approaches to 3D object generation with deep
    generative models (DGMs), including Generative Adversarial Networks (GANs), Variational
    Autoencoders (VAEs), 3D-aware images, and diffusion models. We discuss 187 articles
    (80.7% of articles published between 2018-2022) to review the field of generated
    possibilities of architecture in virtual environments, limited to the architecture
    form. We provide an overview of architectural research, virtual environment and
    related technical approaches, followed by a review of recent trends in discrete
    voxel generation, 3D models generated from 2D images, and conditional parameters.
    We highlight under-explored issues in 3D generation and parameterized control
    that is worth further investigation. Moreover, we speculate that four research
    agendas including data limitation, editability, evaluation metrics and human-computer
    interaction are important enablers of ubiquitous interaction with immersive systems
    in architecture for computer-aided design Our work contributes to researchers’
    understanding of the current potential and future needs of deep learnings in generating
    virtual architecture.
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 利用深度学习的3D形状生成技术正受到计算机视觉和建筑设计领域的越来越多关注。本文综述了当前最新的深度生成模型（DGMs）在3D物体生成中的方法，包括生成对抗网络（GANs）、变分自编码器（VAEs）、3D感知图像和扩散模型。我们讨论了187篇文章（2018-2022年间发表的文章的80.7%），以回顾虚拟环境中建筑生成可能性的领域，限于建筑形式。我们概述了建筑研究、虚拟环境及相关技术方法，并回顾了离散体素生成、从2D图像生成3D模型和条件参数的最新趋势。我们强调了3D生成和参数化控制中尚未充分探索的问题，值得进一步研究。此外，我们推测数据限制、可编辑性、评估指标和人机交互四个研究议题是促进建筑领域计算机辅助设计中沉浸式系统普遍交互的重要因素。我们的工作有助于研究人员理解深度学习在生成虚拟建筑中的当前潜力和未来需求。
- en: 'Deep Learning, virtual environment, architectural design, computational architecture,
    3D shape generation, 3D-aware image synthesis, human-computer interaction, metaverse,
    AIGC^†^†copyright: acmcopyright^†^†journalyear: 2018^†^†doi: XXXXXXX.XXXXXXX^†^†journal:
    JACM^†^†journalvolume: 37^†^†journalnumber: 4^†^†article: 111^†^†publicationmonth:
    8^†^†ccs: Human-centered computing Interaction design process and methods^†^†ccs:
    Computing methodologies Machine learning^†^†ccs: Applied computing Architecture
    (buildings)^†^†ccs: Human-centered computing Virtual reality'
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习、虚拟环境、建筑设计、计算建筑、3D形状生成、3D感知图像合成、人机交互、元宇宙、AIGC^†^†版权：acmcopyright^†^†期刊年份：2018^†^†doi：XXXXXXX.XXXXXXX^†^†期刊：JACM^†^†期刊卷号：37^†^†期刊期号：4^†^†文章：111^†^†出版月份：8^†^†CCS：以人为中心的计算
    交互设计过程和方法^†^†CCS：计算方法 机器学习^†^†CCS：应用计算 建筑（建筑物）^†^†CCS：以人为中心的计算 虚拟现实
- en: 1\. Introduction
  id: totrans-11
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 1. 引言
- en: In the past decades, the study of architectural space has changed the exploration
    directions from reinforcement concrete to digital architecture, then to the information
    frameworks with virtualization beyond the physical layer. The digital innovations
    and technological advances associated with the spline, pixels, voxels, and bits
    have enabled architectural forms to be reconceptualized. The architecture has
    been not as static, permanent objects but as a larger part of a data network and
    the evolving communication between different kinds of architectural systems (Claypool,
    [2019](#bib.bib33)). For example, the scenes of video games and augmented reality
    (AR) or virtual reality (VR) cooperate in such virtual environments for architecture.
    This virtual fabrication of digital space pushes the boundaries of consideration
    in what is being produced and designed. The purpose and subject of architecture
    have radically changed in this digitalization. It is free from the constraints
    of physical construction, socioeconomic factors and environmental conditions,
    such as daylight, architectural materials or structure, budget, etc. Instead,
    the visually appealing experiences they bring enable virtual architectures to
    serve as intersections within this infinity beyond reality. It becomes a spatial
    medium full of infinite possibilities to carry society and culture.
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去几十年中，建筑空间的研究已经从钢筋混凝土转向数字建筑，再到超越物理层的虚拟化信息框架。与样条曲线、像素、体素和比特相关的数字创新和技术进步使建筑形式得以重新概念化。建筑不再是静态、永久的物体，而是数据网络的更大组成部分，以及不同建筑系统之间不断演变的通信（Claypool，[2019](#bib.bib33)）。例如，视频游戏和增强现实（AR）或虚拟现实（VR）的场景在这些虚拟环境中为建筑合作。这种数字空间的虚拟制造推动了在生产和设计中考虑的边界。在数字化中，建筑的目的和主题发生了根本性的变化。它摆脱了物理建造、社会经济因素和环境条件的限制，如日光、建筑材料或结构、预算等。相反，它们带来的视觉吸引力使虚拟建筑能够作为超越现实的无限空间中的交汇点。它成为一个充满无限可能性的空间媒介，承载社会和文化。
- en: The infinitely expanding spatial field of virtual worlds (VWs) faces many tasks
    that require efficient modeling. Creating various object models through generative
    techniques is a timely research topic (Aggarwal et al., [2021a](#bib.bib4)). Research
    on 3D model generation or 3D-aware image synthesis through deep learning (DL)
    has been booming in recent years. Generative Adversarial Networks (GANs), Variational
    Autoencoder (VAE) and the very recent diffusion model (DDPM) belong to deep learning.
    In contrast to other classic ML algorithms, Their category belongs to unsupervised
    learning (USL), which does not rely on large sets of labeled data. DL has surpassed
    human perception regarding abstraction strategies through invisible deep neural
    networks. For instance, AlphaGO can beat top board players in board games. DALLE,
    a drawing tool performing the multi-modality of text-transformed images, learns
    human intention from the natural language. DL has pushed the potential for output
    farther and farther beyond human imagination.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 无限扩展的虚拟世界（VWs）空间领域面临许多需要高效建模的任务。通过生成技术创建各种对象模型是一个及时的研究主题（Aggarwal et al., [2021a](#bib.bib4)）。近年来，利用深度学习（DL）进行3D模型生成或3D感知图像合成的研究迅速兴起。生成对抗网络（GANs）、变分自编码器（VAE）和最近的扩散模型（DDPM）属于深度学习。与其他经典机器学习算法相比，它们属于无监督学习（USL），不依赖于大量标记数据。深度学习通过不可见的深层神经网络超越了人类对抽象策略的感知。例如，AlphaGO能够击败顶级棋手。DALLE，一种实现文本转换图像的多模态绘图工具，从自然语言中学习人类意图。深度学习将输出潜力推向了超越人类想象的更远处。
- en: '1.1\. Preamble: 3D Virtual Architecture Generated by Deep Learning'
  id: totrans-14
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.1\. 序言：深度学习生成的3D虚拟建筑
- en: The generative virtual architecture is a vast domain spreading over computer-aided
    design (CAD), 3D shape generation techniques, and human-computer interaction (HCI).
    On the other hand, 3D shape generation techniques by DL are a fundamental viewpoint
    in computer vision and computer graphics. Thus, we need to define these terms
    at the beginning of this survey.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 生成式虚拟建筑是一个广泛的领域，涉及计算机辅助设计（CAD）、3D形状生成技术和人机交互（HCI）。另一方面，深度学习（DL）中的3D形状生成技术是计算机视觉和计算机图形学中的一个基本观点。因此，我们需要在本调查的开始定义这些术语。
- en: '![Refer to caption](img/c1757937607e454748646c32412e4791.png)'
  id: totrans-16
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/c1757937607e454748646c32412e4791.png)'
- en: Figure 1. Applications of deep learning impact our lives in all aspects. (a)
    Self-drive cars; (b) AlfaGO; (c) Segmentation in the city recognition with computer
    vision; (d) Mirror World NFT, which shows AI dialogue character with personality
    and development from learning; (e) OpenCV recognizing the object types in the
    camera view; (f) Apple watch paired with deep learning detect atrial fibrillation
    with 97 % accuracy; (g) ChatGPT developed by OpenAI; (h) recommendation system
    in the Tiktok; (i) Smart agriculture implemented by deep learning with drones;
    (j) DALLE-2, one powerful painting tool empowered by machine learning; (k) D.O.U.G,
    a collaborative robotic arms interacted with human, learning human behaviors and
    gestures, performance and created by artist Soug Wen; (l) digital human body generation
    by 3D reconstruction technique; (m) An AI art movie created by GANs (Casey Reas);
    (n) BCI (Brain-computer interface).
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 图1. 深度学习对我们生活的各个方面产生了影响。 (a) 自驾车；(b) AlphaGO；(c) 使用计算机视觉进行的城市识别分割；(d) Mirror
    World NFT，展示了具有个性和从学习中发展的AI对话角色；(e) OpenCV识别相机视图中的物体类型；(f) 与深度学习配对的Apple Watch以97%的准确率检测房颤；(g)
    OpenAI开发的ChatGPT；(h) Tiktok中的推荐系统；(i) 深度学习与无人机实现的智能农业；(j) DALLE-2，一个由机器学习赋能的强大绘画工具；(k)
    D.O.U.G，一个与人互动的协作机器人手臂，学习人类行为和手势，由艺术家Soug Wen创作；(l) 通过3D重建技术生成的数字人体；(m) 由GANs（Casey
    Reas）创作的AI艺术电影；(n) 脑机接口（BCI）。
- en: 'Deep learning. Deep learning (DL), a subclass of machine learning (ML) and
    artificial intelligence (AI), has developed rapidly with a boost in data process
    and computation. A new class of DL is deep generative models (DGMs) by combining
    generative models and deep neural networks. They rely on paradigms of unsupervised
    learning. Neural networks such as ANN, CNN and RNN, as signature deep learning
    architectures, have played essential roles in manipulating the relationship between
    the input and output data. The definition of DL signifies the system master the
    capability of self-learning and experience enhancement (Sarker, [2021b](#bib.bib150)).
    DL applications have broad applications to all aspects of life. There are plenty
    of notable examples. Such as the first fully automatic self-driving car, Navlab5
    (Fig. 1a); Alpha GO, a computer program that can beat top human Go players (Fig.
    1b); Mirror World NFT’s intelligent character ¹¹1Mirror Wolrd’s official websites:
    https://link3.to/mirrorworld that can learn and grow up from human text conversations
    (Fig. 1d); ChatGPT ²²2Introducing ChatGPT, source: [https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)
    developed by OpenAI  (OpenAI, [2022](#bib.bib131)), the ever first intelligent
    conversational machine model; One of the best recommendation systems in the world
    (Fig. 1h), which made TikTok stand out from 13.47 million DAUs  ³³3A report on
    TikTok, souce: https://www.statista.com/statistics/1090659/tiktok-dau-worldwide-android/;
    DALLE-2, which was commented as the ever-best AI painting tool (Fig. 1j); and
    the infinite potential BCI (Brain-computer interface) (Fig. 1n); Moreover, the
    intelligence revolution could not be ongoing without DL, for instance, smart agriculture
    (Fig. 1i), and smart transportation. Computer Vision relies on the DL closely,
    such as notable OpenCV (Fig. 1e), segmentation with vision cognition (Fig. 1c)
    and 3D scanning techniques (Fig. 1l). Additionally, loads of contemporary digital
    art were created through deep learning by inputting and processing the data of
    human gestures and bio-signals (Fig. 1k). Figure 1m represents the cutting-edge
    example of experimental AI-art films created by GAN.'
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习。深度学习（DL），作为机器学习（ML）和人工智能（AI）的一个子类，随着数据处理和计算能力的提升发展迅速。一类新的深度学习是深度生成模型（DGM），它结合了生成模型和深度神经网络。它们依赖于无监督学习的范式。神经网络，如ANN、CNN和RNN，作为标志性的深度学习架构，在处理输入与输出数据之间的关系方面发挥了关键作用。DL的定义意味着系统掌握了自学习和经验增强的能力（Sarker，[2021b](#bib.bib150)）。DL的应用广泛涉及生活的各个方面。有很多显著的例子。例如，第一款全自动自驾车Navlab5（图1a）；Alpha
    GO，一个能够击败顶级围棋玩家的计算机程序（图1b）；Mirror World NFT的智能角色¹¹1Mirror World的官方网站：https://link3.to/mirrorworld，它能够从人类文本对话中学习和成长（图1d）；ChatGPT²²2介绍ChatGPT，来源：[https://openai.com/blog/chatgpt](https://openai.com/blog/chatgpt)，由OpenAI开发（OpenAI，[2022](#bib.bib131)），首个智能对话机器模型；世界上最好的推荐系统之一（图1h），使TikTok从1347万日活跃用户中脱颖而出³³3TikTok的报告，来源：https://www.statista.com/statistics/1090659/tiktok-dau-worldwide-android/；DALLE-2，被评价为最佳AI绘画工具（图1j）；以及具有无限潜力的脑机接口（BCI）（图1n）；此外，没有深度学习，智能革命无法进行，例如智能农业（图1i）和智能交通。计算机视觉紧密依赖于深度学习，如著名的OpenCV（图1e），视觉认知的分割（图1c）和3D扫描技术（图1l）。此外，大量当代数字艺术是通过深度学习创建的，通过输入和处理人类手势和生物信号的数据（图1k）。图1m代表了由GAN创建的前沿实验AI艺术电影的例子。
- en: '3D Shape Generation Technique. With an increasing surge of AI-Generated Content
    (AIGC), DGMs have the capability to process 3D shape generation through various
    approaches. There are plenty of frameworks, such as GAN, VAE, Flow model, and
    so on. DGMs have the widest applications and the most prominent influence in the
    field of two-dimensional (2D) image process, such as textures, transfer style
    art, photorealistic faces and text-to-image generation (Jetchev et al., [2016](#bib.bib80);
    Ledig et al., [2017](#bib.bib98); Reed et al., [2016](#bib.bib142); Zhu et al.,
    [2017](#bib.bib188)). For innovative techniques and boosted arithmetic power,
    DGMs for 3D shape generation have burgeoned in research years. The DGMs can achieve
    this leveraging effect in the aspect of the 3D generative object by shifting from
    the outcome in the 2D image. Rapidly, a method with GANs, named 3D-GAN (Wu et al.,
    [2016](#bib.bib170)), was applicable to 3D shape generation in a probability space
    for voxel grids (See Fig. [9](#S3.F9 "Figure 9 ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")a).
    The 3D shape generation inspires some downstream operations, such as object classification
    and part segmentation, to scene semantic parsing.'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '3D形状生成技术。随着人工智能生成内容（AIGC）的迅猛发展，深度生成模型（DGM）能够通过多种方法处理3D形状生成。现有许多框架，如GAN、VAE、Flow模型等。DGM在二维（2D）图像处理领域有着最广泛的应用和最显著的影响，比如纹理、风格迁移艺术、逼真的人脸以及文本到图像的生成（Jetchev
    et al., [2016](#bib.bib80)；Ledig et al., [2017](#bib.bib98)；Reed et al., [2016](#bib.bib142)；Zhu
    et al., [2017](#bib.bib188)）。随着创新技术和算力的提升，DGM在3D形状生成方面的研究蓬勃发展。DGM通过从二维图像的结果转化为三维生成对象来实现这种效应。快速地，一种名为3D-GAN的方法（Wu
    et al., [2016](#bib.bib170)）被应用于体素网格的3D形状生成（见图[9](#S3.F9 "Figure 9 ‣ 3\. Generated
    3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")a）。3D形状生成激发了下游操作，如对象分类、部分分割以及场景语义解析。'
- en: Computer-aided Design and Deep Learning-Assisted Form Generation. Computer-aided
    design (CAD) is an extensive research field regarding digital tools-assisted creation
    and optimization in the design phase (Sarcar et al., [2008](#bib.bib147)). Especially
    in the architecture field, the design with the involvement of computational tools
    has spread over Building Information Modeling (BIM), structural performance analysis,
    robotics and digital fabrication, urban analytics, environmental performance,
    and so on (Baduge et al., [2022](#bib.bib13)). Architectural design aided by DL
    is one of the typical classifications of the CAD field by providing a wide range
    of options in design processes  (Tamke et al., [2018](#bib.bib162)). DL-assisted
    architecture generation has enlarged to the generative systems from rule-based
    topology optimization such as cellular automata ⁴⁴4A cellular automata (CA) is
    a discrete model of computation studied in automata theory and shape grammars ⁵⁵5Shape
    grammars in the computation are a specific class of production systems that generate
    geometric shapes., to neural network tools, which provide more flexibility, and
    more controllable parameters in a generation. Reviewing DL-aided form generation,
    deep neural networks in DGMs have proved useful efficiency and power in architecture
    design. In such a field, the workforce and computational power needed to coordinate
    with each other in studying form generation and future construction. Nevertheless,
    there are no such requirements in virtual environment generation. We found that
    there needs to be more knowledge in the form generation around the transformation
    between physical and virtual spaces.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 计算机辅助设计与深度学习辅助的形态生成。计算机辅助设计（CAD）是一个广泛的研究领域，涉及在设计阶段使用数字工具进行创作和优化（Sarcar et al.,
    [2008](#bib.bib147)）。特别是在建筑领域，计算工具的参与已经扩展到建筑信息建模（BIM）、结构性能分析、机器人技术和数字化制造、城市分析、环境性能等方面（Baduge
    et al., [2022](#bib.bib13)）。由深度学习（DL）辅助的建筑设计是CAD领域的典型分类之一，它在设计过程中提供了广泛的选择（Tamke
    et al., [2018](#bib.bib162)）。深度学习辅助的建筑生成已经从基于规则的拓扑优化（如细胞自动机⁴⁴4A cellular automata
    (CA) is a discrete model of computation studied in automata theory and shape grammars⁵⁵5Shape
    grammars in the computation are a specific class of production systems that generate
    geometric shapes.）扩展到神经网络工具，这些工具在生成过程中提供了更多的灵活性和可控参数。回顾DL辅助的形态生成，深度神经网络在DGMs中已证明在建筑设计中的有效性和强大功能。在这样的领域中，协调工作和计算能力的需求相互配合，以研究形态生成和未来的建设。然而，在虚拟环境生成中并没有这样的要求。我们发现，在物理空间和虚拟空间之间的转换中，形态生成方面还需要更多的知识。
- en: Generative 3D Virtual Architecture. Generating architectural spaces efficiently
    and applicatively from 3D representations is a popular and worthwhile research
    topic, both in the architecture and computer science domains. For architecture,
    it is crucial to clarify the rules of digital space, which aligns with functionality,
    aesthetics, and satisfaction. As Roberto Bottazzi states, as opposed to transforming
    digital architecture, urgency is how the digital space can be architecturized
    (Bottazzi, [2018](#bib.bib20)). This unveils the significance of virtual architecture.
    The increasing tendency to build a virtual world (VW) is associated with the reality
    of owning digitalized lives and produces, which refers to the metaverse.
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: 生成性3D虚拟建筑。从3D表示生成建筑空间的高效和实用的研究在建筑和计算机科学领域都是一个热门且值得研究的话题。对于建筑来说，明确数字空间的规则至关重要，这些规则与功能、美学和满意度相一致。正如Roberto
    Bottazzi所述，与其说是转变数字建筑，不如说是数字空间如何被建筑化（Bottazzi, [2018](#bib.bib20)）。这揭示了虚拟建筑的重要性。构建虚拟世界（VW）的日益趋势与拥有数字化生活和产品的现实相关，这指的是元宇宙。
- en: 1.2\. Towards an interdisciplinary area among architecture, HCI, & AIGC
  id: totrans-22
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.2. 面向建筑学、人机交互（HCI）和人工智能生成内容（AIGC）的跨学科领域
- en: The research on virtual environments has gradually stood out at the intersection
    of human-computer interaction (HCI) and immersive techniques such as Augmented
    reality (AR) and Virtual Reality (VR) (Lee et al., [2021b](#bib.bib100)). Moreover,
    the demands in Virtual Reality (VR) or Augmented Reality (AR) environments are
    surging due to modeling productivity and efficiency. Consequently, these demands
    and developments have also raised the viewpoint for 3D generative approaches.
    The feasibility of virtual architecture clearly benefits from the CAD approach
    in terms of the modeling task load and HCI approaches. However, despite the popularity
    of exploring the possibilities of space in 3D object generation, research on architecture
    is still limited. Most studies have similarly focused on the two-dimensional (2D)
    image process. ArchiGAN (Chaillou, [2020](#bib.bib25)), studied by the MIT team,
    explores the potential of GANs in training large numbers of building floor plans
    for spatial layout and functional delineation automatically, and further advent
    applications(Chaillou, [2022](#bib.bib26)). Most other architectural research
    with GAN, such as generating some fantastic-style images by (Karras et al., [2019](#bib.bib84)),
    satisfies an imagination for designs that are either beyond the constraints of
    physical worlds, or have not been effectively proposed and illustrated before.
    For example, Özel utilizes some creative images for architecture, relying on artificial
    intelligence, to predict the future of architecture (Özel, [2020](#bib.bib134)).
    These studies consider the creativity of generating absences from an aesthetic
    perspective beyond reality. Abstract two-dimensional images are far from architecture,
    even in virtual worlds, due to the lack of methods to transfer those automatically
    generated images to a three-dimensional format. Additionally, the traditional
    method of 2D floor plans constructed in real space is unsuitable for virtual environments.
    In other words, there has been considerable divergence in the production approach
    between physical and virtual architecture. The former has to consider the external
    environment (e.g., daylight, light) and construction constraints; while the virtual
    one put more concerned with the sense of identity, definition of self, and aesthetics.
    Therefore, to close the gaps mentioned above, a novel discipline urges reconstructing
    a niche domain encompassing architectural components, constraint requirements
    in VE, and user needs. At the same time, deep learning could support generating
    computational architecture freely. It is worthwhile to mention that the gaps remain
    for most existing research.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 关于虚拟环境的研究逐渐在**人机交互**（HCI）和增强现实（AR）及虚拟现实（VR）等沉浸式技术的交汇点上脱颖而出（Lee et al., [2021b](#bib.bib100)）。此外，由于建模生产力和效率的需求，虚拟现实（VR）或增强现实（AR）环境中的需求正在激增。因此，这些需求和发展也提高了对3D生成方法的观点。虚拟建筑的可行性明显受益于CAD方法，在建模任务负担和HCI方法方面表现突出。然而，尽管在3D对象生成中探索空间的可能性颇受欢迎，建筑研究仍然有限。大多数研究类似地集中在二维（2D）图像处理中。由MIT团队研究的ArchiGAN（Chaillou,
    [2020](#bib.bib25)）探讨了GAN在自动训练大量建筑平面图以进行空间布局和功能划分方面的潜力，并进一步推动了应用的到来（Chaillou,
    [2022](#bib.bib26)）。其他大多数涉及GAN的建筑研究，例如通过（Karras et al., [2019](#bib.bib84)）生成一些奇幻风格图像，满足了对超越物理世界限制或之前未有效提出和说明的设计的想象。例如，Özel利用一些依靠人工智能的创意图像来预测建筑的未来（Özel,
    [2020](#bib.bib134)）。这些研究从超越现实的审美角度考虑了生成缺失的创造力。由于缺乏将这些自动生成图像转换为三维格式的方法，即使在虚拟世界中，抽象的二维图像也离建筑相去甚远。此外，传统的二维平面图在真实空间中构建的方法不适用于虚拟环境。换句话说，物理建筑和虚拟建筑之间的生产方法存在显著差异。前者必须考虑外部环境（例如，日光、光照）和建筑约束；而虚拟建筑则更关注身份感、自我定义和美学。因此，为了弥合上述差距，一个新兴的学科需要重建一个涵盖建筑组件、虚拟环境中的约束要求和用户需求的细分领域。同时，深度学习可以支持自由生成计算建筑。值得一提的是，大多数现有研究仍存在空白。
- en: To summarize the problem mentioned above, first, generating the architecture
    with the design purpose for the 3D shape generation techniques is rarely considered
    since generative architecture requires sophisticated consideration and innovative
    techniques, especially for non-tech-savvy architects. Second, architectural generation
    approaches rarely regard the “virtual” and lack the usage of 3D shapes generation.
    Therefore, the design dimensions for virtual architecture generated by 3D approaches
    have not been systematically considered. Therefore, our survey addresses how to
    leverage 3D shape generation techniques to produce 3D virtual spaces from a user-centered
    perspective. We noted that this article defines the user-centered perspective
    as ‘inclusive’ to consider the needs of non-tech-savvy architects who lack technical
    (computer-science) backgrounds, and layman users who intended to create virtual
    buildings in the Metaverse.
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 总结上述问题，首先，对于 3D 形状生成技术，设计目的的建筑生成很少被考虑，因为生成建筑需要复杂的考虑和创新技术，特别是对于非技术型建筑师。其次，建筑生成方法很少涉及“虚拟”，且缺乏
    3D 形状生成的应用。因此，通过 3D 方法生成的虚拟建筑的设计维度尚未系统考虑。因此，我们的调查探讨了如何从以用户为中心的角度利用 3D 形状生成技术来创建
    3D 虚拟空间。我们指出，本文将以用户为中心的角度定义为“包容性”，以考虑缺乏技术（计算机科学）背景的非技术型建筑师和有意在 Metaverse 中创建虚拟建筑的普通用户的需求。
- en: 1.3\. Methodology and Related Articles
  id: totrans-25
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.3\. 方法论及相关文献
- en: '![Refer to caption](img/ab4f8d745fe99e416d9693b8f1faef35.png)'
  id: totrans-26
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ab4f8d745fe99e416d9693b8f1faef35.png)'
- en: (a) This survey investigates this intersection area.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 本调查研究了这一交叉领域。
- en: '![Refer to caption](img/4e0fdb91ec8df06c58a7de1ebe042be9.png)'
  id: totrans-28
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/4e0fdb91ec8df06c58a7de1ebe042be9.png)'
- en: (b) A profile of the number of works cited in this paper in different categories
    and years.
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 论文中引用的不同类别和年份的文献数量概况。
- en: 'Figure 2. The survey’s scope and profile of related articles: a – architectural
    studies on DGMs; c – computer vision studies; v – those works on rules in VWs.'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2. 调查的范围及相关文献的概况：a – DGMs 的建筑研究；c – 计算机视觉研究；v – 规则在 VWs 中的研究。
- en: 'This survey article presents findings of a systematic literature review on
    deep learning for 3D shape generation in computer vision and CAD for computational
    architecture in terms of generating virtual architecture in recent years. Since
    the problem mentioned above, the intersection of 3D generation techniques and
    virtual architecture is still nearly blank. Therefore, we anchored the three fields
    to conduct this survey in order to complement the key insight with each other:
    3D shape generation techniques, DL-assisted architectural design, and the design
    considerations in a VWs in terms of HCI (See Fig. [2(a)](#S1.F2.sf1 "In Figure
    2 ‣ 1.3\. Methodology and Related Articles ‣ 1\. Introduction ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")).'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 本调查文章呈现了关于计算机视觉和 CAD 中 3D 形状生成的深度学习的系统文献综述。近年来，虚拟建筑生成的计算建筑学方面尚处于空白。因此，我们将这三个领域作为调查的基点，以便互补关键见解：3D
    形状生成技术、DL 辅助建筑设计以及 VWs 中 HCI 方面的设计考虑（见图 [2(a)](#S1.F2.sf1 "在图 2 ‣ 1.3\. 方法论及相关文献
    ‣ 1\. 引言 ‣ 朝向计算建筑学的自由：对生成虚拟建筑的深度学习的全面调查")）。
- en: 'We reviewed a sample of 187 articles and primarily focused on works published
    between 2018 and 2022 (five years, 80.7%) as follows: 2023 or later: 4 (8.7%),
    2022: 33 (17.6%), 2021: 39 (20.9%), 2020: 36 (19.3%), 2019: 30 (16%), 2018: 33
    (5.8%), before 2018: 32 (17.1%) from those three fields (See Fig.  [2(b)](#S1.F2.sf2
    "In Figure 2 ‣ 1.3\. Methodology and Related Articles ‣ 1\. Introduction ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")). We found the articles
    primarily through publication databases such as ACM Digital Library, IEEE Xplore,
    ScienceDirect, Springer Link and CuminCAD. We used the following keywords Augmented
    Reality (AR), Virtual Reality (VR), deep generative models, 3D representation,
    3D model or shape or geometry, object generation, 3D-aware image, shape synthesis,
    point cloud, voxel grid, mesh, implicit neural field, virtual architecture, virtual
    environment, deep learning design, generative design, Generative Adversarial Network
    (GAN), 3D GAN, VAE (Variational Autoencoder), diffusion model (DDPM), text to
    3D, image to 3D, zero-shot, computational architecture, spatial objects, flexible
    spaces, virtual rules, design discipline, human-computer-interaction (HCI), evaluation
    metric, human perception, emotion, simulation, participatory design, aesthetics,
    real-time interaction, and combinations of these keywords. Additionally, we count
    on some latest or high-influential research on Computer Vision (CV) only published
    in arXiv. We screened through the titles and the keywords to ensure they only
    included full papers and extended abstracts. Short papers and abstracts were excluded
    from this scope. When the keywords and abstracts do not appear as the key information
    or elements in our investigating scope, we read the whole publication to check
    whether it is included or not. After the screening, we got 147 articles and 19
    CV research published on arXiv to review, i.e., 166 authoritative articles. Additionally,
    online resources were directly searched through the Google search engine, we mainly
    conclude 19 articles and 2 relevant architectural projects from the perspective
    of architecture design, categorized by the virtual world, computational architecture,
    architectural theory and so on. Eventually, a total of 187 articles and 2 architectural
    projects are included in this survey.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 我们审查了187篇文章的样本，主要集中在2018年至2022年间发表的作品（五年，80.7%），具体如下：2023年及以后：4篇（8.7%），2022年：33篇（17.6%），2021年：39篇（20.9%），2020年：36篇（19.3%），2019年：30篇（16%），2018年：33篇（5.8%），2018年之前：32篇（17.1%），来自这三个领域（见图
    [2(b)](#S1.F2.sf2 "在图2 ‣ 1.3. 方法论与相关文章 ‣ 1. 引言 ‣ 朝向虚拟建筑的计算架构：深度学习在元宇宙中生成虚拟建筑的全面调查")）。我们主要通过ACM数字图书馆、IEEE
    Xplore、ScienceDirect、Springer Link和CuminCAD等出版数据库找到这些文章。我们使用了以下关键词：增强现实（AR）、虚拟现实（VR）、深度生成模型、3D表示、3D模型或形状或几何、对象生成、3D感知图像、形状合成、点云、体素网格、网格、隐式神经场、虚拟建筑、虚拟环境、深度学习设计、生成设计、生成对抗网络（GAN）、3D
    GAN、变分自编码器（VAE）、扩散模型（DDPM）、文本转3D、图像转3D、零样本、计算架构、空间对象、灵活空间、虚拟规则、设计学科、人机交互（HCI）、评估指标、人类感知、情感、仿真、参与设计、美学、实时交互以及这些关键词的组合。此外，我们还依赖一些最新或高影响力的计算机视觉（CV）研究，这些研究仅发表在arXiv上。我们通过标题和关键词筛选，以确保仅包括完整论文和扩展摘要。短文和摘要被排除在范围之外。当关键词和摘要未作为我们调查范围内的关键信息或要素出现时，我们会阅读整个出版物以检查是否包含在内。筛选后，我们得到了147篇文章和19篇发表在arXiv上的CV研究，共计166篇权威文章。此外，在线资源通过Google搜索引擎直接搜索，我们主要从建筑设计的角度总结了19篇文章和2个相关建筑项目，按虚拟世界、计算架构、建筑理论等类别进行分类。最终，本次调查共纳入了187篇文章和2个建筑项目。
- en: 'Various other surveys further locate this scope, as follows: Category 1 (machine
    learning  (Kreuzberger et al., [2023](#bib.bib93); Penney and Chen, [2019](#bib.bib138))
    or deep learning (Hatcher and Yu, [2018](#bib.bib64); Kreuzberger et al., [2023](#bib.bib93);
    Alom et al., [2019](#bib.bib7); Akinosho et al., [2020](#bib.bib6); Khan et al.,
    [2020](#bib.bib87); Alom et al., [2019](#bib.bib7); Sarker, [2021a](#bib.bib149);
    Pouyanfar et al., [2018](#bib.bib140); Abdar et al., [2021](#bib.bib2))): 3D shape
    generation (Shi et al., [2022](#bib.bib157); Oussidi and Elhassouny, [2018](#bib.bib133);
    Cao et al., [2020](#bib.bib24)), scene synthesis  (Xia and Xue, [2022](#bib.bib173);
    Zhang et al., [2019](#bib.bib185)), applications (Dong et al., [2021](#bib.bib48);
    Dargan et al., [2020](#bib.bib36)), 3D representation (Guo et al., [2020](#bib.bib59)),
    3D reconstruction from 2D  (Yuniarti and Suciati, [2019](#bib.bib177)), and generative
    models (Harshvardhan et al., [2020](#bib.bib63); Aggarwal et al., [2021a](#bib.bib4),
    [b](#bib.bib5); Wang et al., [2021](#bib.bib168); Jabbar et al., [2021](#bib.bib74);
    Pavan Kumar and Jayagopal, [2021](#bib.bib135); Croitoru et al., [2023](#bib.bib35);
    Creswell et al., [2018](#bib.bib34)). Category 2 (DL-assisted architectural design
     (Penney and Chen, [2019](#bib.bib138); Newton, [2019](#bib.bib124))): infrastructure
     (Tamke et al., [2018](#bib.bib162)), intelligent construction  (Baduge et al.,
    [2022](#bib.bib13); Akinosho et al., [2020](#bib.bib6)), life cycle  (Hong et al.,
    [2020](#bib.bib69)), or other design  (Regenwetter et al., [2022](#bib.bib143)).
    And Category 3 (architecture in a virtual environment or virtual worlds): design
    disciplinary in virtual reality (theories and applications)  (Bartle, [2004](#bib.bib16)),
    HCI in the virtual architecture (human senses and emotions)  (Lee et al., [2021b](#bib.bib100)),
    metaverse or virtual worlds  (Bartle, [2010](#bib.bib17); Dionisio et al., [2013](#bib.bib47);
    Lee et al., [2021a](#bib.bib99)). In contrast, this article reviews the approaches
    to 3D shape generation and the factors of virtualization in architecture in recent
    years, especially in the last five years (2018-2022), regarding virtual rules,
    design principles, social parameters, and HCI methods for CAD design. We argue
    to combine these research areas and consider this an interdisciplinary problem.
    Finally, the research outlines the crucial challenges of HCI in virtual architectural
    model generation tasks. Our survey article uniquely considers the prominent features
    of the above categories and further paves a path towards the computational architecture
    of liberty, with the below contributions.'
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 各种其他调查进一步界定了这一范围，如下所示：类别 1（机器学习  (Kreuzberger 等，[2023](#bib.bib93)；Penney 和
    Chen，[2019](#bib.bib138)) 或深度学习 (Hatcher 和 Yu，[2018](#bib.bib64)；Kreuzberger 等，[2023](#bib.bib93)；Alom
    等，[2019](#bib.bib7)；Akinosho 等，[2020](#bib.bib6)；Khan 等，[2020](#bib.bib87)；Alom
    等，[2019](#bib.bib7)；Sarker，[2021a](#bib.bib149)；Pouyanfar 等，[2018](#bib.bib140)；Abdar
    等，[2021](#bib.bib2))：3D 形状生成 (Shi 等，[2022](#bib.bib157)；Oussidi 和 Elhassouny，[2018](#bib.bib133)；Cao
    等，[2020](#bib.bib24))，场景合成 (Xia 和 Xue，[2022](#bib.bib173)；Zhang 等，[2019](#bib.bib185))，应用
    (Dong 等，[2021](#bib.bib48)；Dargan 等，[2020](#bib.bib36))，3D 表征 (Guo 等，[2020](#bib.bib59))，从
    2D 重建 3D (Yuniarti 和 Suciati，[2019](#bib.bib177))，以及生成模型 (Harshvardhan 等，[2020](#bib.bib63)；Aggarwal
    等，[2021a](#bib.bib4)，[b](#bib.bib5)；Wang 等，[2021](#bib.bib168)；Jabbar 等，[2021](#bib.bib74)；Pavan
    Kumar 和 Jayagopal，[2021](#bib.bib135)；Croitoru 等，[2023](#bib.bib35)；Creswell 等，[2018](#bib.bib34))。类别
    2（DL 辅助建筑设计 (Penney 和 Chen，[2019](#bib.bib138)；Newton，[2019](#bib.bib124))）：基础设施
    (Tamke 等，[2018](#bib.bib162))，智能建筑 (Baduge 等，[2022](#bib.bib13)；Akinosho 等，[2020](#bib.bib6))，生命周期
    (Hong 等，[2020](#bib.bib69))，或其他设计 (Regenwetter 等，[2022](#bib.bib143))。以及类别 3（虚拟环境或虚拟世界中的建筑）：虚拟现实中的设计学科（理论和应用）
    (Bartle，[2004](#bib.bib16))，虚拟建筑中的 HCI（人类感官和情感） (Lee 等，[2021b](#bib.bib100))，元宇宙或虚拟世界
    (Bartle，[2010](#bib.bib17)；Dionisio 等，[2013](#bib.bib47)；Lee 等，[2021a](#bib.bib99))。相比之下，本文回顾了近年来，特别是过去五年（2018-2022）中
    3D 形状生成的方法和建筑虚拟化因素，涉及虚拟规则、设计原则、社会参数和 CAD 设计的 HCI 方法。我们主张将这些研究领域结合起来，认为这是一个跨学科的问题。最后，研究概述了虚拟建筑模型生成任务中
    HCI 的关键挑战。我们的调查文章独特地考虑了上述类别的突出特点，并进一步铺平了通向自由计算建筑的道路，具有以下贡献。
- en: (1)
  id: totrans-34
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (1)
- en: We provide a comprehensive investigation for the inclusion of DL-assisted architectural
    design and deep generative models, dedicated to developing a critical lens for
    computational architecture in virtual environments.
  id: totrans-35
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们对 DL 辅助建筑设计和深度生成模型的整合进行了全面调查，致力于为虚拟环境中的计算建筑发展一个批判性视角。
- en: (2)
  id: totrans-36
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (2)
- en: We highlight an opportunity to address the academic gap between the two existing
    areas of research, attempting to respond algorithmically to social factors.
  id: totrans-37
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们强调了弥合现有两个研究领域之间学术差距的机会，尝试从算法上响应社会因素。
- en: (3)
  id: totrans-38
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: (3)
- en: We propose research topics for the future of virtual architecture towards liberty,
    considering disciplinary beyond reality such as humanism and spirituality.
  id: totrans-39
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 我们提出了未来虚拟建筑的研究主题，考虑了超越现实的学科，如人文主义和精神性。
- en: 1.4\. Scope and Structure
  id: totrans-40
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 1.4\. 范围和结构
- en: '![Refer to caption](img/2f5a4fc67586e80a207f45b59dbd31ad.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/2f5a4fc67586e80a207f45b59dbd31ad.png)'
- en: Figure 3. The survey structure (Sections 2 – 4).
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 图 3. 调查结构（第2 – 4节）。
- en: Although the intersection of DL and architecture is in all aspects, we only
    investigate articles where DL considers the generative deep learning of 3D virtual
    architecture, especially for the 3D DGMs. We only include the research limit to
    the 2D style imaginary drawings coupled with providing innovative approaches to
    the 3D transition. We also excluded the articles that only consider the real problem
    such as BIM rather than implementing it in a purely virtual environment. This
    scope reflects the automatic generation of timely design issues in the virtual
    space.
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习（DL）与建筑学的交集涉及所有方面，但我们仅研究那些考虑3D虚拟建筑的生成式深度学习，特别是3D生成对抗网络（DGM）的文章。我们仅限于2D风格的想象图，并提供创新的方法以实现3D过渡。我们也排除了那些仅考虑实际问题如建筑信息建模（BIM），而不是在纯虚拟环境中实施的文章。这一范围反映了虚拟空间中及时设计问题的自动生成。
- en: 'The paper reviews the current problem space in this field consisting of rules
    of the virtual world, social parameters and civilization of formal liberty starting
    from Section 2. Section 3 covers the innovative form generation in architecture
    under generation approaches in terms of 3D form transposition and 3D solid form
    generation. Four topics are covered in this section, including GAN ed into specific
    training, VAE for the specific information extraction, 3D-aware image synthesis
    and diffusion model based on the conditional text (See Fig.  [3](#S1.F3 "Figure
    3 ‣ 1.4\. Scope and Structure ‣ 1\. Introduction ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")). Subsequently, we revisit the field from the perspective of
    HCI, formulating research agendas in four grand challenges, ranging from data
    limitation, editability, and evaluation metrics to HCI design, collecting user
    information, operation and perception. We indicate that can explore new possibilities
    for optimizing and inventing innovative methods regarding automatically generating
    virtual architecture with human and social group-centric considerations.'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 论文回顾了该领域当前的问题空间，包括虚拟世界的规则、社会参数以及从第2节开始的形式自由文明。第3节涵盖了建筑中的创新形式生成，包括3D形式变换和3D实体形式生成的生成方法。该节包含四个主题，包括特定训练的生成对抗网络（GAN）、用于特定信息提取的变分自编码器（VAE）、3D感知图像合成和基于条件文本的扩散模型（见图
    [3](#S1.F3 "图 3 ‣ 1.4\. 范围和结构 ‣ 1\. 引言 ‣ 面向自由计算建筑：对生成虚拟建筑的深度学习的综合调查")）。随后，我们从人机交互（HCI）的角度重新审视该领域，制定四个重大挑战的研究议程，涉及数据限制、可编辑性、评价指标、人机交互设计、用户信息收集、操作和感知。我们指出，可以探索优化和发明新方法的可能性，以考虑人类和社会群体中心的虚拟建筑自动生成。
- en: 2\. Overview of Generated 3D Virtual Architecture
  id: totrans-45
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 2\. 生成的3D虚拟建筑概述
- en: Since the last century, discussing methods and rules for computer-aided design
    has never stopped. However, initially, the digitized models simply worked to simulate
    the physical environment or document the design process. The discussion around
    virtual architecture started when web-based social media or games were invented.
    After the emergence of the metaverse concept, enthusiasm for virtual architecture
    research has intensified, indicating that we entered a new era of existence with
    a proliferation of different kinds of virtual environments (VEs). On the one hand,
    VE is built on a liminal reproduction to reality, which has no legitimacy and
    produces no consequences (Nazmeeva, [2019](#bib.bib122)). On the other hand, the
    VE is built on potential interactions of humans as social attributes in virtual
    spaces. Lee et al. state that digital natives are essential for developing the
    ultimate form of the metaverse (Lee et al., [2021a](#bib.bib99)). Those digital
    ones enable boosting their impacts on all craft as well as user-generated content
    (UGC) through social interaction with avatars. As virtual worlds evolve, social
    attributes are expanded, such as poverty rights, identity, roles, and group differentiation
     (Schroeder et al., [2001](#bib.bib151)). As Roberto Bottazzi argues, the roadmap
    for our modern society should be the architecturalization of unregulated digital
    spaces(Bottazzi, [2018](#bib.bib20)). Increasingly, people are integrating virtual
    spaces into a coexistence of living spaces. In general, the research from the
    primary “virtual worlds” until the explosion of the metaverse is rather diverse.
    However, most studies have focused on the layer of virtual reality or interactive
    games, but not specifically on the subject of space itself.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 自上个世纪以来，关于计算机辅助设计的方法和规则的讨论从未停止。然而，最初，数字化模型仅仅用于模拟物理环境或记录设计过程。虚拟建筑的讨论始于基于网页的社交媒体或游戏的发明。随着元宇宙概念的出现，对虚拟建筑研究的热情有所加剧，表明我们进入了一个全新的存在时代，各种虚拟环境（VEs）大量涌现。一方面，虚拟环境建立在对现实的临界再现上，这种再现没有合法性，也没有产生实际后果（Nazmeeva，[2019](#bib.bib122)）。另一方面，虚拟环境建立在人类在虚拟空间中作为社会属性的潜在互动上。Lee等人指出，数字原住民对于发展元宇宙的**终极**形式至关重要（Lee
    et al.，[2021a](#bib.bib99)）。这些数字原住民通过与化身的社交互动，能够提升他们在所有工艺和用户生成内容（UGC）上的影响力。随着虚拟世界的发展，社会属性不断扩展，如贫困权利、身份、角色和群体差异（Schroeder
    et al.，[2001](#bib.bib151)）。正如Roberto Bottazzi所言，我们现代社会的路线图应是对不受监管的数字空间进行建筑化（Bottazzi，[2018](#bib.bib20)）。人们越来越多地将虚拟空间融入到生活空间的共存中。总体而言，从初期的“虚拟世界”到元宇宙的爆炸，研究相当多样。然而，大多数研究集中在虚拟现实或互动游戏的层面上，而不是专门关注空间本身的主题。
- en: 2.1\. The Rules of Virtual Worlds
  id: totrans-47
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.1. 虚拟世界的规则
- en: The discussion of virtual worlds, which are constructed and internally coherent,
    has always ceased. There have three primary layers stacked in the concept of the
    virtual worlds, semantics, and virtual environment to the architecture  (Nevelsteen,
    [2018](#bib.bib123)). Consequently, these virtual worlds are everywhere, from
    politics to video games to token economies. Immersion, presence, and interactivity
    intertwine as the three pillars of virtual worlds  (Mütterlein, [2018](#bib.bib118)).
    Gilbert identified five essential characteristics of virtual worlds  (Gilbert,
    [2011](#bib.bib55)). They are embodied in every aspect, such as spatial perception,
    public or private activities, social experience and emotional expression. Furthermore,
    many scholars have tried to define and classify the virtual world in terms of
    layers or development stages. The confused definition of VW has been mitigated
    by the exuberance of the metaverse. Dionisio divided the virtual world into 5
    developing stages, ranging from text and 2D graphical interfaces to UGC and then
    to a complete decentralized economic system (Dionisio et al., [2013](#bib.bib47)).
    In the latest research on metaverse, Lee et al. state that there are three stages
    toward the co-existence of physical and virtual space - digital twins, digital
    natives, and surreality (Lee et al., [2021a](#bib.bib99)). The digital twin is
    a reproduced version of the physical world, depending on the development of CAD
    for both industry and architecture. The surging numbers of digital natives enable
    boosting their positive impacts on the interaction with avatars and all craft
    as well as user-generated content. Surreality is the ultimate ideal world that
    the metaverse aims for, supporting heterogeneous activities with interoperability
    in real-time between the physical and virtual worlds.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 对于构建且内部一致的虚拟世界的讨论一直在继续。在虚拟世界、语义和虚拟环境的概念中，有三个主要层次堆叠在建筑中（Nevelsteen, [2018](#bib.bib123)）。因此，这些虚拟世界无处不在，从政治到视频游戏再到代币经济。沉浸感、存在感和互动性交织在一起，成为虚拟世界的三大支柱（Mütterlein,
    [2018](#bib.bib118)）。Gilbert 识别出了虚拟世界的五个基本特征（Gilbert, [2011](#bib.bib55)）。它们体现在每个方面，例如空间感知、公共或私人活动、社会体验和情感表达。此外，许多学者试图根据层次或发展阶段来定义和分类虚拟世界。虚拟世界的混乱定义已经被元宇宙的繁荣所缓解。Dionisio
    将虚拟世界划分为 5 个发展阶段，从文本和二维图形界面到用户生成内容（UGC），再到完整的去中心化经济系统（Dionisio et al., [2013](#bib.bib47)）。在最新的元宇宙研究中，Lee
    等人表示，物理和虚拟空间共存有三个阶段——数字双胞胎、数字原住民和超现实（Lee et al., [2021a](#bib.bib99)）。数字双胞胎是物理世界的再现版本，依赖于
    CAD 的发展，适用于工业和建筑。不断增长的数字原住民使得他们对与化身的互动以及所有工艺和用户生成内容的积极影响不断增强。超现实是元宇宙追求的终极理想世界，支持物理和虚拟世界之间实时互操作的异质活动。
- en: From the technology perspective, software and hardware architecture defines
    spatial functionality, constrain and social interaction. These architectures form
    the politics of VW (Lessig, [2009](#bib.bib101)), while code forms the laws of
    the graphic VE. Every law invented by the human has Intrinsic value with specific
    intention and elaborate design. Therefore, the design discipline consists of codes
    and computing ought to satisfy the complex parameters, including computing capability,
    cost-benefit ratio and user preference. Despite the codes and programs providing
    the rules and laws in the VW, it is undeniable that unique expertise is required
    to handle the design and organization of VWs. This is not enough by the ability
    given by the codability in computers solely. This composite capability, as a special
    case of visual, analogically integrated reasoning, is fully capable of being a
    key expertise. It can operate at multiple scales and in multiple contexts to map,
    analyze, and organize VWs, while being able to introduce new systems, rules, and
    forms into them  (Jovanovic, [2022](#bib.bib82)).
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 从技术角度来看，软件和硬件架构定义了空间功能、约束和社会互动。这些架构形成了虚拟世界的政治（Lessig, [2009](#bib.bib101)），而代码形成了图形虚拟环境的法律。人类发明的每一条法律都有固有的价值，具有特定的意图和精心设计。因此，设计学科包括代码和计算，必须满足复杂的参数，包括计算能力、成本效益比和用户偏好。尽管代码和程序提供了虚拟世界中的规则和法律，但不可否认的是，处理虚拟世界的设计和组织需要独特的专业知识。这不仅仅是计算机编程能力所能提供的。作为视觉推理的特殊案例，这种复合能力完全可以成为关键专业。它能够在多个尺度和上下文中操作，以映射、分析和组织虚拟世界，同时能够引入新的系统、规则和形式（Jovanovic,
    [2022](#bib.bib82)）。
- en: 2.1.1\. Virtuality in the Architecture
  id: totrans-50
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.1.1\. 建筑中的虚拟性
- en: 'Virtuality is a fundamental characteristic specific to architecture in a VE
    and encompasses the following three elements: immersion, presence, and interactivity.
    Stem from three pillars in the virtual world  (Mütterlein, [2018](#bib.bib118)),
    the virtual architecture shares the same interpretation but more specific deployment.
    In other words, since the virtual building is a specific type of mediated matter
    that has a 3D representation in the VW, we can regard these buildings as a subtype
    of the virtual environment. Various components and frameworks of the virtual world
    are assumed to be applied within it. Therefore, the theory of the VW is equally
    applicable to virtual architecture.'
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟性是虚拟环境中建筑特有的基本特征，包含以下三个元素：沉浸感、存在感和互动性。源于虚拟世界中的三大支柱（Mütterlein，[2018](#bib.bib118)），虚拟建筑在解释上与之相同，但应用更为具体。换句话说，由于虚拟建筑是一种在虚拟世界中具有3D表现的媒介化物质，我们可以将这些建筑视为虚拟环境的一个子类型。虚拟世界的各种组件和框架被假设在其中应用。因此，虚拟世界的理论同样适用于虚拟建筑。
- en: 'The design discipline of virtual architecture had to regard these three pillars
    as essential. Some research on architectural design has conducted these rules,
    VRoamer  (Cheng et al., [2019](#bib.bib32)) reports an interactive VE through
    the releasing users’ attention to achieve immersion. Not only for the research,
    the architecture projects also tend to integrity with immersive technology. Zaha
    Hadid Architects and JOURNEE have jointly developed a virtual NFT gallery ”NFTism”,
    which is one of a handful of virtual buildings with interactivity. This gallery
    inherits Zaha’s representative fluidic form, supporting MMO (massively multiplayer
    online) technology and integrating audio-video interaction  ⁶⁶6A report by Archdaily:
    [https://www.archdaily.com/972886/zaha-hadid-architects-presents-virtual-gallery-exploring-architecture-nfts-and-the-metaverse](https://www.archdaily.com/972886/zaha-hadid-architects-presents-virtual-gallery-exploring-architecture-nfts-and-the-metaverse).'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟建筑的设计学科必须将这三个支柱视为核心。一些建筑设计的研究已经执行了这些规则，VRoamer（Cheng et al., [2019](#bib.bib32)）报告了一种通过释放用户注意力实现沉浸感的互动虚拟环境。建筑项目不仅限于研究，也倾向于与沉浸式技术相结合。扎哈哈迪德建筑事务所和JOURNEE联合开发了一个虚拟NFT画廊“NFTism”，这是少数几个具有互动性的虚拟建筑之一。这个画廊继承了扎哈的代表性流体形态，支持MMO（大规模多人在线）技术并整合了音视频互动
    ⁶⁶6A Archdaily报告：[https://www.archdaily.com/972886/zaha-hadid-architects-presents-virtual-gallery-exploring-architecture-nfts-and-the-metaverse](https://www.archdaily.com/972886/zaha-hadid-architects-presents-virtual-gallery-exploring-architecture-nfts-and-the-metaverse)。
- en: 2.2\. Design Discipline
  id: totrans-53
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.2\. 设计学科
- en: 2.2.1\. The Absence of Reality
  id: totrans-54
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.1\. 现实的缺失
- en: 'To better clarify the design principles of virtual architecture, we compare
    them to real-world architecture. First, real factors had to be absent in building
    a virtual architecture, encompassing design consideration, construction structure,
    and economic cost. Precisely, a kind of emerging factor running on the immersive
    technologies and fitting the virtual logic replaces the original position occupied
    by the real ones. The following elaborate exact three aspects: First, from environmental
    factors to social factors: environmental factors such as the direction of wind
    and light affect the spatial layout of the architecture, while they are not effective
    for a virtual building. What is replaced in the virtual world is a more neoliberal
    virtual logic, since humans gather socially unrestricted by time and space by
    emphasizing social activities.'
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更好地阐明虚拟建筑的设计原则，我们将其与现实建筑进行比较。首先，在建造虚拟建筑时，现实因素必须被排除，包括设计考虑、施工结构和经济成本。准确地说，一种基于沉浸式技术并符合虚拟逻辑的新兴因素取代了现实因素所占据的位置。以下详细阐述了三个方面：首先，从环境因素到社会因素：环境因素如风向和光线影响建筑的空间布局，而对虚拟建筑无效。在虚拟世界中，取而代之的是一种更具新自由主义的虚拟逻辑，因为人类在强调社会活动的同时，可以在时间和空间上不受限制地进行社交活动。
- en: 'Second, from Building structure to unrestricted form: the structure of a virtual
    building is more toward a more accessible and open form. Many architectural structures
    that existing technology could not implement have been consecrated as paper architecture
     ⁷⁷7Visionary architecture that couldn’t build in reality, only as drawings, collages,
    or models. with cutting-edge conception. For example, Zaha’s early works were
    not structurally possible with the technology and construction of the time. There
    are plenty of schools of thought in this regard, such as bionic architecture ⁸⁸8Bionic
    architecture is usually computationally adapted to the structure or form of organic
    matter in nature. Design considerations for biomimetic architecture include the
    physiological, behavioral, and structural adaptations of living organisms. and
    responsive architecture ⁹⁹9Responsive architecture refers to the ability of an
    architecture or building to exhibit the ability to change its form to constantly
    reflect the conditions of its surroundings. It reflects the idea of interactive
    architecture..'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: 第二，从建筑结构到不受限制的形式：虚拟建筑的结构趋向于更为可接近和开放的形式。许多现有技术无法实现的建筑结构已被称为纸上建筑  ⁷⁷7具前瞻性构思的建筑，仅存在于图纸、拼贴画或模型中。例如，扎哈早期的作品在当时的技术和建造条件下是不可能实现的。在这方面有很多学派，如仿生建筑 ⁸⁸8仿生建筑通常是根据自然界有机物的结构或形式进行计算调整。仿生建筑的设计考虑因素包括生物体的生理、行为和结构适应。和响应建筑 ⁹⁹9响应建筑指的是建筑或建筑物表现出改变其形式以不断反映周围环境条件的能力。它反映了互动建筑的理念。
- en: 'Third, from construction costs to the cost of scene and computation: It is
    taken for granted that real construction costs, such as material and labor costs,
    are transferred to the costs of modeling, lighting and rendering, while the complex
    data computation for such tasks as rendering consumes computer memory. The cost
    of building and constructing complex and fantastical real scenes is exponentially
    higher, and they are achieved through special effects and modeling rendering techniques
    that are impossible to achieve in the real world.'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 第三，从建造成本到场景和计算成本：理所当然地，真实建造成本，如材料和人工成本，转移到了建模、照明和渲染的成本上，而渲染等任务的复杂数据计算消耗计算机内存。建造和构造复杂而奇幻的真实场景的成本是指数级增加的，而这些通过特效和建模渲染技术实现，这些在现实世界中是不可能实现的。
- en: Apart from the above, virtual buildings and real buildings are built with a
    transforming logic, from construction to unrestrained form. Real-world architecture
    needs to start from the spatial planning and functional layout of the floor plan,
    so as to deduce and complete the architectural design. But in the virtual environment,
    the alternative solution is to start directly from the functional layout on the
    3D space, mostly modeling through the game engine or 3D modeling software. This
    is not only the production method of virtual assets, but even some advanced real
    buildings are starting to do so because of the efficiency and higher accuracy
    of spatial perception.
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: 除了上述内容，虚拟建筑和真实建筑的构建是基于一种变换逻辑，从建造到不受限制的形式。现实世界的建筑需要从平面图的空间规划和功能布局开始，从而推导和完成建筑设计。但在虚拟环境中，替代的解决方案是直接从3D空间中的功能布局开始，主要通过游戏引擎或3D建模软件进行建模。这不仅是虚拟资产的生产方法，甚至一些先进的真实建筑也开始这样做，因为这样可以提高空间感知的效率和准确性。
- en: 2.2.2\. Social Factors As Parameters
  id: totrans-59
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.2\. 社会因素作为参数
- en: '![Refer to caption](img/0996adbf613b196b1ac61de48f26dd4a.png)'
  id: totrans-60
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/0996adbf613b196b1ac61de48f26dd4a.png)'
- en: '(a) Algorithmic Social Sciences ResearchUnit (ASSRU)  ^(11)^(11)11Source: [http://www.assru.org/index.html](http://www.assru.org/index.html)
    (ASSRU, [1999](#bib.bib11)).'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: '(a) 算法社会科学研究单位 (ASSRU)  ^(11)^(11)11来源: [http://www.assru.org/index.html](http://www.assru.org/index.html)
    (ASSRU, [1999](#bib.bib11))。'
- en: '![Refer to caption](img/ba1671d43a420f8f432bd336c167291b.png)'
  id: totrans-62
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ba1671d43a420f8f432bd336c167291b.png)'
- en: '(b) Parametric Semiology ^(13)^(13)13Source: [https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html](https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html):
    Semio-field, differentiation of public vs private as a parametric range.'
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: '(b) 参数化符号学 ^(13)^(13)13来源: [https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html](https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html)：符号领域，公共与私人作为参数范围的区分。'
- en: Figure 4. Social factors as parameters in different theories.
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 图4. 社会因素作为不同理论中的参数。
- en: 'It is important to highlight that the discipline of virtual spaces cannot abandon
    the social impacts. The built environment is a vast, navigable, and information-rich
    communication interface, especially in the virtual world. It provides potential
    social participants with information about the communicative interactions expected
    within its scope (Schumacher, [2013](#bib.bib152)) (Fig.  [11](#footnote11 "footnote
    11In Figure 4 ‣ 2.2.2\. Social Factors As Parameters ‣ 2.2\. Design Discipline
    ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")). Although virtuality has unique attributes beyond reality,
    people are active in a virtual environment with social abilities. In other words,
    virtual technology supports social activities and goals in an immersive environment.
    Additionally, from the psychology perspective, familiarity with the realistic
    scene facilitates the boosting of presence and self-awareness, due to the preference
    given by the exposure rate  (Myers and Twenge, [2012](#bib.bib119)).'
  id: totrans-65
  prefs: []
  type: TYPE_NORMAL
  zh: '突出强调虚拟空间的学科不能忽视其社会影响是非常重要的。建成的环境是一个广阔的、可导航的、信息丰富的交流界面，尤其是在虚拟世界中。它为潜在的社会参与者提供了有关在其范围内预期的交流互动的信息（Schumacher,
    [2013](#bib.bib152)）（图 [11](#footnote11 "footnote 11In Figure 4 ‣ 2.2.2\. Social
    Factors As Parameters ‣ 2.2\. Design Discipline ‣ 2\. Overview of Generated 3D
    Virtual Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")）。虽然虚拟性具有超越现实的独特属性，但人们在虚拟环境中具有社会能力。换句话说，虚拟技术支持沉浸环境中的社会活动和目标。此外，从心理学角度看，对现实场景的熟悉有助于增强存在感和自我意识，因为曝光率带来了偏好（Myers
    和 Twenge, [2012](#bib.bib119)）。'
- en: 'Driven by the information society and virtual world, socialization is a medium
    for communication that is increasingly complex, which conveys a rich diversity
    of social systems and sophisticated information in multiple scenarios. For example,
    Lam et al. have developed a context-aware, contextually interactive AR urban interface
    enabling users to locate websites intuitively with minimal modifications  (Lam
    et al., [2019](#bib.bib96)). Architecture signifies a spatial place containing
    activities, where the study on the semiotics of spatial forms has always revolved
    around the topic of simulating or restoring social scenarios, including public
    spaces, semi-public, and private spaces (See Fig.  [13](#footnote13 "footnote
    13In Figure 4 ‣ 2.2.2\. Social Factors As Parameters ‣ 2.2\. Design Discipline
    ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")). Space conveys an invitation to participate in framing social
    situations  (Schumacher, [2013](#bib.bib152)). For example, there are a lot of
    studies discussing the human perception of spaces in urban design studies in history.
    Jacobs (Jacobs, [2016](#bib.bib75)) introduced walkable streets as a concept in
    the forming of neighborhoods, which considers visual qualities, connectivity of
    circulations and other indicators. Following the tendency of human-centric design,
    a lot of researchers explored the making of desirable streets and the making of
    places on different scales. Appleton  (Appleton, [1996](#bib.bib8)) introduced
    the prospect-refuge theory to address the safety sense of humans in placemaking,
    which significantly influences socializing. Hall (Hall et al., [1968](#bib.bib61))
    introduced proxemic zones to represent different types of social distances. These
    theories regarding the human sense of space are still widely used in nowadays
    design discipline. All those are from the significance of the social parameters
    in terms of the architectural discipline.'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '在信息社会和虚拟世界的推动下，社交成为了一种日益复杂的交流媒介，这种媒介在多种场景中传达了丰富多样的社会系统和复杂的信息。例如，Lam 等人开发了一种基于情境感知、上下文互动的增强现实城市界面，使用户能够直观地定位网站，且几乎无需修改
     (Lam et al., [2019](#bib.bib96))。建筑学表示一个包含活动的空间地点，其中对空间形式的符号学研究一直围绕模拟或恢复社会场景的话题，包括公共空间、半公共空间和私人空间（见图
    [13](#footnote13 "footnote 13In Figure 4 ‣ 2.2.2\. Social Factors As Parameters
    ‣ 2.2\. Design Discipline ‣ 2\. Overview of Generated 3D Virtual Architecture
    ‣ Towards Computational Architecture of Liberty: A Comprehensive Survey on Deep
    Learning for Generating Virtual Architecture in the Metaverse")）。空间传达了参与框定社会情境的邀请
     (Schumacher, [2013](#bib.bib152))。例如，历史上有很多研究讨论了人类对城市设计空间的感知。Jacobs (Jacobs,
    [2016](#bib.bib75)) 引入了可步行街道作为形成社区的一个概念，考虑了视觉特征、流动的连通性和其他指标。遵循以人为本的设计趋势，许多研究者探索了不同尺度上的理想街道和场所的创建。Appleton
     (Appleton, [1996](#bib.bib8)) 引入了前景-避难理论来解决人类在场所塑造中的安全感，这对社交有着显著的影响。Hall (Hall
    et al., [1968](#bib.bib61)) 引入了亲密区域的概念，以表示不同类型的社会距离。这些关于人类空间感知的理论在当今的设计学科中仍然被广泛使用。这些都体现了社会参数在建筑学科中的重要性。'
- en: 2.2.3\. The Goal of Construction
  id: totrans-67
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.3\. 建设目标
- en: The design principles of virtual architecture serve the purpose of constructing
    buildings in VEs. With the boom in virtual technology and the rise of social platforms
    for 3D virtual worlds, the production demand for infinite and sprawling virtual
    environments has surged rapidly. The main task confronts with building rapid,
    large-scale architectural environments. These construction tasks are mostly done
    collaboratively by 3D modeling software and game engines such as Unity. 3D building
    models are 3D spatial representations of artificial spatial elements  (Yao et al.,
    [2018](#bib.bib175)). Its most relevant quality criteria are completeness, the
    spatial accuracy of location and the level of detail  (Keil et al., [2021](#bib.bib86)).
    In addition, realistic simulations regarding scale and size are also important,
    including granularity and simulation as well. All in all, those are very significant
    to bring the experience for users. The non-uniform approach causes various problems,
    such as inconsistent buildings from the manual and automatic operation  (Keil
    et al., [2021](#bib.bib86)), as well as the expensive cost of human resources.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: 虚拟建筑设计原则的目的是构建虚拟环境中的建筑。随着虚拟技术的兴起和3D虚拟世界社交平台的崛起，对无限且广袤虚拟环境的生产需求急剧增加。主要任务是快速建造大规模建筑环境。这些建造任务大多由3D建模软件和游戏引擎（如Unity）协作完成。3D建筑模型是人工空间元素的3D空间表示（Yao
    et al., [2018](#bib.bib175)）。其最相关的质量标准包括完整性、位置的空间准确性以及细节水平（Keil et al., [2021](#bib.bib86)）。此外，关于比例和尺寸的真实模拟也很重要，包括粒度和模拟。总的来说，这些对提升用户体验非常重要。不一致的方法会导致各种问题，例如手动和自动操作产生的不一致建筑（Keil
    et al., [2021](#bib.bib86)），以及昂贵的人力资源成本。
- en: 'One reliable solution is facing many efficient and automatic construction tasks
    in a virtual environment. The solution based on the computation approach is relatively
    consistent since the same automation frameworks are applied for all spatial objects.
    All these approaches are across various scales including urban and architecture.
    MineDojo uses autonomous agents that utilize large pre-trained video language
    models for automation to generate 3D scenes of VWs  (Fan et al., [2022](#bib.bib49)).
    From the recently released by Tencent, the proposed solution for the automatic
    generation of 3D virtual scenes contains 3 modules ranging from city layout generation,
    building exterior generation and interior mapping generation  (Lab, [2023](#bib.bib95))
     ^(14)^(14)14Source: [https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City](https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City).
    It is a new paradigm that combines design perspectives using multiple CV techniques.
    Similarly, there are several studies on computational generation in architecture.
    Most of them are generated by extracting the logic of urban planning  (Ingram
    et al., [1996](#bib.bib73); Veselỳ, [2022](#bib.bib166)), i.e., designing 3D layouts
    and functional divisions from urban plan layouts. In another approach (Veselỳ,
    [2022](#bib.bib166)), three methods with different specific objectives are integrated.
    It generates building massing configurations by autonomously inferring the composition
    rules of existing urban areas.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '一个可靠的解决方案是面对许多高效和自动化的虚拟环境建造任务。基于计算的方法相对一致，因为对所有空间对象应用相同的自动化框架。这些方法跨越各种规模，包括城市和建筑。MineDojo使用利用大型预训练视频语言模型的自主代理进行自动化，生成虚拟世界的3D场景（Fan
    et al., [2022](#bib.bib49)）。腾讯最近发布的自动生成3D虚拟场景的解决方案包含城市布局生成、建筑外观生成和室内映射生成三个模块（Lab,
    [2023](#bib.bib95)）^(14)^(14)14来源: [https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City](https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City)。这是一种结合多个计算机视觉技术的设计视角的新范式。类似地，建筑领域也有若干关于计算生成的研究。大多数通过提取城市规划逻辑来生成（Ingram
    et al., [1996](#bib.bib73); Veselỳ, [2022](#bib.bib166)），即从城市规划布局中设计3D布局和功能分区。在另一种方法中（Veselỳ,
    [2022](#bib.bib166)），集成了三个具有不同特定目标的方法。它通过自主推断现有城市区域的构成规则生成建筑体量配置。'
- en: 2.2.4\. The Problem on the Collective
  id: totrans-70
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.2.4\. 集体问题
- en: 'However, there is still a mismatch between that new paradigm of mechanism run
    on the virtuality and the purposes of the emerging virtual environment: collective,
    presence, and unencumbered (Nazmeeva, [2019](#bib.bib122)). The collective pertains
    to the notion that virtual spaces are communal environments wherein individuals
    from diverse backgrounds and cultures can converge and engage with one another.
    The nature of the collective refers to the highly multi-social experience. We
    only proliferate the products that manifest our unique identities and personal
    needs (Nazmeeva, [2019](#bib.bib122)). That conflicts with the collective and
    the products for everyday use, especially the space or architecture. As we live
    in a world with a seamless fusion of reality and the virtual, such as the exquisite
    information and goods powered by a recommendation system on social media, creation
    or live space beyond reality, virtual economic mechanisms, ownership, identity,
    and so on. All of these exhibit the precision of individual values. Apparently,
    the collective and congregate have become blind here. In other words, virtual
    technologies should support collective social activities and goals cued by individual
    experiences in immersive environments. Many theories of virtual worlds emphasize
    this point. Activity Theory argues that virtual worlds should be designed to support
    users in achieving their goals  (Jonassen and Rohrer-Murphy, [1999](#bib.bib81)).
    Bartle’s Four Keys to Virtual World Design states that providing players with
    a sense of purpose is one of the key metrics for designing virtual worlds  (Bartle,
    [2004](#bib.bib16)). The purpose enhances user engagement by providing them with
    a sense of progress and accomplishment, thereby creating a sense of immersion.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，这种在虚拟性上运行的新机制范式与新兴虚拟环境的目的之间仍存在不匹配：集体性、存在感和无障碍性（Nazmeeva, [2019](#bib.bib122)）。集体性涉及虚拟空间是一个共同的环境，在这里来自不同背景和文化的个体可以汇聚并互动。集体性的本质指的是高度的多社会体验。我们只繁衍出展现我们独特身份和个人需求的产品（Nazmeeva,
    [2019](#bib.bib122)）。这与集体性和日常使用的产品，尤其是空间或建筑产生了冲突。由于我们生活在一个现实与虚拟无缝融合的世界中，例如通过社交媒体推荐系统驱动的精美信息和商品，创造或超越现实的空间，虚拟经济机制、所有权、身份等。这些都展示了个体价值的精准。显然，集体性和聚合在这里变得盲目。换句话说，虚拟技术应该支持集体社会活动和目标，这些目标由沉浸式环境中的个体体验所提示。许多虚拟世界的理论强调了这一点。活动理论认为虚拟世界应该被设计成支持用户实现他们的目标（Jonassen
    and Rohrer-Murphy, [1999](#bib.bib81)）。Bartle 的虚拟世界设计四个关键指出，提供给玩家一种目的感是设计虚拟世界的关键指标之一（Bartle,
    [2004](#bib.bib16)）。目的感通过提供进步和成就感来增强用户参与感，从而创造出沉浸感。
- en: 2.3\. Deep Generative Models
  id: totrans-72
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.3\. 深度生成模型
- en: We briefly overview the progression of deep generative models for 3D representation,
    including 3D shape generation and 3D aware image generation.
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 我们简要回顾了用于 3D 表示的深度生成模型的发展，包括 3D 形状生成和 3D 感知图像生成。
- en: '![Refer to caption](img/9c9dda7fba238a71a1ad5b3c12c4794a.png)'
  id: totrans-74
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/9c9dda7fba238a71a1ad5b3c12c4794a.png)'
- en: Figure 5. The frameworks of GAN, VAE and Diffusion Models.
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5. GAN、VAE 和扩散模型的框架。
- en: 2.3.1\. 3D Shape Generation.
  id: totrans-76
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.1\. 3D 形状生成。
- en: 'is contributed by traditional deep generative models, in addition to the well-known
    Generative Adversarial Networks (GANs) and variational autoencoders (VAEs), normalizing
    flows (N-Flows), very recent diffusion probabilistic models (DDPMs) as well as
    energy-based models (EBMs), which learn by maximizing from the similarity of the
    given data. These deep generative models generate a tangible 3D object that is
    ready for rendering. It conveys a latent variable to a high-quality image. Although
    every model has its own benefits and great progress in recent years, the domain
    in architecture relies on the GAN mostly, while VAE and the very latest diffusion
    models are designed for a few research. Considering the relevance, we thus introduce
    the GAN, VAE and diffusion models in detail rather than an exhaustive list of
    models included in other CV survey articles (Fig.  [5](#S2.F5 "Figure 5 ‣ 2.3\.
    Deep Generative Models ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")).'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 传统深度生成模型作出了贡献，除了著名的生成对抗网络（GANs）和变分自编码器（VAEs），还有归一化流（N-Flows）、最近的扩散概率模型（DDPMs）以及基于能量的模型（EBMs），这些模型通过最大化给定数据的相似性进行学习。这些深度生成模型生成可以渲染的实际3D对象。它将潜在变量传递到高质量图像中。尽管每种模型都有其自身的优势并且近年来取得了重大进展，建筑领域主要依赖于GAN，而VAE和最新的扩散模型则用于一些研究。考虑到相关性，我们详细介绍了GAN、VAE和扩散模型，而不是其他计算机视觉调查文章中包含的模型的详尽列表（图[5](#S2.F5
    "图 5 ‣ 2.3. 深度生成模型 ‣ 2. 生成的3D虚拟建筑概述 ‣ 迈向计算建筑的自由：关于生成虚拟建筑的深度学习的综合调查")）。
- en: 'GANs. GANs are a type of semi-supervised learning relying on the noise value.
    The GANs rely on machine learning algorithms to construct two neural networks:
    one is a generator, and another is a discriminator. It trains a large database
    by means of a zero-sum game between two of these neural networks to generate agnostic
    creative results.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: GANs。GANs是一种依赖于噪声值的半监督学习。GANs依赖于机器学习算法构建两个神经网络：一个是生成器，另一个是鉴别器。它通过这两个神经网络之间的零和博弈训练一个大型数据库，以生成无偏见的创造性结果。
- en: Variational Autoencoders. Variational autoencoders are probabilistic generative
    models that use neural networks partially. Along with inputs and outputs, neural
    networks need encoders and decoders. The latent space refers to the process of
    learning data features and simplifying data representations to facilitate model
    training for a specific purpose. To guarantee that the latent space of a Variational
    Autoencoder has acceptable qualities and can be used to create fresh data, the
    distribution of its encodings is regularised during training (Kingma et al., [2019](#bib.bib90)).
    Furthermore, the name ”variational” originates from the tight connection between
    regularisation and the variational inference technique used in statistical analysis.
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 变分自编码器。变分自编码器是部分使用神经网络的概率生成模型。除了输入和输出，神经网络还需要编码器和解码器。潜在空间指的是学习数据特征和简化数据表示的过程，以便于模型针对特定目的进行训练。为了确保变分自编码器的潜在空间具有可接受的特性并能用于生成新数据，在训练过程中对其编码分布进行正则化（Kingma
    等，[2019](#bib.bib90)）。此外，"变分"这个名字来源于正则化与用于统计分析的变分推断技术之间的紧密联系。
- en: Diffusion Models. Through modeling the dispersion of data points in latent space,
    we discover the underlying structure of a dataset of images or volumetric, e.g.,
    Denoising Diffusion Probabilistic Models (Ho et al., [2020a](#bib.bib66)). This
    entails teaching a neural network to remove the blurring effect of Gaussian noise
    on an image. It has the prominent advantage of generating sharp and detailed features.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 扩散模型。通过对潜在空间中数据点的扩散建模，我们发现了图像或体积数据集的潜在结构，例如，去噪扩散概率模型（Ho 等，[2020a](#bib.bib66)）。这涉及到教一个神经网络去除图像上高斯噪声的模糊效果。它具有生成锐利和详细特征的显著优势。
- en: 2.3.2\. 3D-Aware Image Synthesis.
  id: totrans-81
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.3.2. 3D 感知图像合成。
- en: This approaches extract latent vectors from the latent space and decode them
    into a target representation by using GAN. Generally, the generation pipeline
    is for an image with 3D awareness as a result and it also starts with an image
    as a generative source.
  id: totrans-82
  prefs: []
  type: TYPE_NORMAL
  zh: 这些方法从潜在空间中提取潜在向量，并通过使用GAN将其解码为目标表示。通常，生成流程的结果是具有3D意识的图像，并且它也从图像作为生成源开始。
- en: 2.4\. 3D Representations
  id: totrans-83
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.4. 3D 表示
- en: '![Refer to caption](img/69ca4fe41c95f9ea8147fb6b8e77fc55.png)'
  id: totrans-84
  prefs: []
  type: TYPE_IMG
  zh: '![参见标题](img/69ca4fe41c95f9ea8147fb6b8e77fc55.png)'
- en: Figure 6. The 3D representations for (a) Voxel grids, (b) Meshes, (c) Point
    cloud, (d) Neural fields.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 图6。3D表示的 (a) 体素网格，(b) 网格，(c) 点云，(d) 神经场。
- en: 'These two types of 3D generation develop diverse representations of 3D scenes
    in computer vision and computer graphics. The 3D representation in 3D shape generally
    includes explicit representations, such as voxel grids, point clouds, meshes,
    and implicit neural fields. A 3D-aware image includes depth or normal maps, voxel
    grids, neural fields and hybrid representations. The integration between them
    and the architecture generation is also different. For example, a point cloud
    is often considered when 3D serves as an input source to train the generative
    model. The 3D representation is articulated in existing survey research as a classification
    (Fig.  [6](#S2.F6 "Figure 6 ‣ 2.4\. 3D Representations ‣ 2\. Overview of Generated
    3D Virtual Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    Below are the brief descriptions.'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: '这两种3D生成类型在计算机视觉和计算机图形学中发展出不同的3D场景表示。3D形状的一般表示包括显式表示，如体素网格、点云、网格和隐式神经场。3D感知图像包括深度或法线图、体素网格、神经场和混合表示。它们与建筑生成的整合也有所不同。例如，点云通常在3D作为输入源来训练生成模型时被考虑。现有的调查研究将3D表示阐述为分类（图
    [6](#S2.F6 "Figure 6 ‣ 2.4\. 3D Representations ‣ 2\. Overview of Generated 3D
    Virtual Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")）。以下是简要描述。'
- en: Architectural design has a preference for explicit representations due to the
    controllability, familiarity, visualization, and availability regarding modifying
    in 3D modeling software. Explicit geometric representations are easier to visualize
    and interpret as they directly represent 3D space. The designers can precisely
    position and adjust each point or voxel, allowing for more accurate control over
    the shape and form of the generated geometry. Nevertheless, implicit representations
    (neural fields) have huge possibilities in architectural research regarding their
    benefits to offer more flexible, continuous, and efficient representations of
    geometry.
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 建筑设计偏好显式表示，因为它在3D建模软件中具有可控性、熟悉性、可视化和修改的便利性。显式几何表示更容易可视化和解读，因为它们直接表示3D空间。设计师可以精确地定位和调整每个点或体素，从而对生成的几何形状和形式进行更准确的控制。然而，隐式表示（神经场）在建筑研究中具有巨大的潜力，因为它们可以提供更灵活、连续和高效的几何表示。
- en: Voxel grids. It refers to a three-dimensional grid of values organised into
    rows and columns. The grid contains rows, columns, and layer intersections, referred
    to as a voxel, i.e., a miniature 3D cube (Deng et al., [2020](#bib.bib41)).
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 体素网格。指的是一个由值组成的三维网格，按行和列组织。网格包含行、列和层交点，称为体素，即一个微型的3D立方体（Deng et al., [2020](#bib.bib41)）。
- en: Point clouds. A point cloud (Rusu and Cousins, [2011](#bib.bib145)) is a distinct
    collection of data points in space, which might indicate a three-dimensional form
    or item through Cartesian coordinates (X, Y, Z) assigned to each point location.
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 点云。点云（Rusu and Cousins, [2011](#bib.bib145)）是空间中数据点的独特集合，这些数据点通过分配给每个点位置的笛卡尔坐标（X、Y、Z）来表示三维形状或物体。
- en: Meshes. A 3D mesh is the polygonal framework upon which a 3D object is built
    (Nichol et al., [2021](#bib.bib127)). Reference points along the X, Y, and Z axes
    describe the height, breadth, and depth of a 3D mesh’s constituent forms. It is
    important to note that creating a photorealistic 3D model sometimes requires many
    polygons.
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 网格。3D网格是构建3D物体的多边形框架（Nichol et al., [2021](#bib.bib127)）。沿X、Y和Z轴的参考点描述了3D网格组成形式的高度、宽度和深度。值得注意的是，创建逼真的3D模型有时需要很多多边形。
- en: Neural fields. It creates images by using traditional volume rendering methods
    to query 5D coordinates along camera rays and projects the resulting colours and
    densities onto a 2D plane. Despite its use of depth data, the scene geometry is
    rendered in exquisite detail, complete with intricate occlusions (Mildenhall et al.,
    [2020](#bib.bib113)).
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 神经场。通过使用传统的体积渲染方法查询沿摄像机射线的5D坐标，并将生成的颜色和密度投射到2D平面上来创建图像。尽管使用了深度数据，但场景几何以精致的细节呈现，包含复杂的遮挡（Mildenhall
    et al., [2020](#bib.bib113)）。
- en: Hybrid representation. This refers to a hybrid pipeline of 3D representation
    for the pre-training in a 3D feature space embedded in both the virtual and actual
    worlds. The hybrid pipeline can include multitudinous data sources and image frame
    features (Shen et al., [2021](#bib.bib156)), depending on the generation purposes
    of the 3D volumetry.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 混合表示。这指的是在虚拟和实际世界中嵌入的3D特征空间的预训练混合管道。混合管道可以包括大量数据源和图像帧特征（Shen et al., [2021](#bib.bib156)），具体取决于3D体积生成的目的。
- en: 2.5\. The Design Factors in DL-Aided Architecture
  id: totrans-93
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 2.5\. 深度学习辅助建筑中的设计因素
- en: In the last subsection, we summarize the design principles for virtual architecture,
    first adapting to the essential characteristics of virtuality as a guideline,
    using computational generation massively and efficiently as a method, meanwhile
    emphasizing the social factors as parameters. On this foundation, we identify
    the mismatch between the architectural collectives and the logic for private production.
    In this section, we explain how to design a virtual building with the above framework
    using a specific automated algorithmic framework.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 在上一小节中，我们总结了虚拟建筑的设计原则，首先适应虚拟性的基本特征作为指导方针，利用计算生成技术大规模且高效地作为方法，同时强调社会因素作为参数。在此基础上，我们识别建筑集体与私人生产逻辑之间的不匹配。在这一节中，我们解释了如何使用上述框架和特定的自动化算法框架设计虚拟建筑。
- en: 2.5.1\. Interpretability and Input Datasets
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.1\. 可解释性与输入数据集
- en: Relying on the interpretability of the input data is crucial as a first step
    in generating virtual buildings aided by ML algorithms. Generally, interpretability
    requires the valid illustration of dataset input itself in the field of architecture (Koh,
    [2022](#bib.bib92); Çakmak, [2022](#bib.bib23)). The generated results that meet
    this goal have the ability to support participators for a variety of design purposes.
    Bridging the gap between data and purpose is the massive human and computational
    exertions that drive interpretability in design goals. For example, BAŞAK ÇAKMAK
    explored extended design cognition with GANs and an encoder-decoder  (Çakmak,
    [2022](#bib.bib23)). This methodology conducts the partitioned 3D point clouds
    captured by lidar according to the type of components as input. The research implements
    the extension for those models manually and automatically to promote the DL framework
    to learn spatial organization.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 依赖输入数据的可解释性是利用机器学习算法生成虚拟建筑的关键第一步。通常，可解释性要求在建筑领域中有效地展示数据集输入本身（Koh, [2022](#bib.bib92);
    Çakmak, [2022](#bib.bib23)）。达到这一目标的生成结果能够支持参与者进行多种设计目的。弥合数据与目的之间的差距是推动设计目标可解释性的巨大人力和计算工作。例如，BAŞAK
    ÇAKMAK通过GANs和编码器-解码器探索了扩展设计认知（Çakmak, [2022](#bib.bib23)）。这一方法根据组件类型对通过激光雷达捕获的分区3D点云进行处理。研究手动和自动扩展这些模型，以促进深度学习框架学习空间组织。
- en: The approach of matching datasets with required parameters associated with spatial
    design goals has been widely used in solutions for architectural design. Such
    applications with DL frameworks are often capable of designing solutions with
    explicit design goals. For instance, Adaptive Acoustic implements a methodology
    with CGN to generate a computational 3D concert hall. The designers trained meshes
    of concert hall interiors as well as the space and acoustic parameters as two
    datasets to pursue an architecture fitting into acoustics requirements. Manually,
    the latter were refined into quantifiable information as parameters containing
    seats, volume, reverberation time, acoustical absorption area, absorption coefficient
    and so on, resulting in AI-generated concert hall forms with acoustic features.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 匹配与空间设计目标相关的所需参数的数据集的方法在建筑设计解决方案中已被广泛使用。这些应用使用深度学习框架通常能够设计出具有明确设计目标的解决方案。例如，Adaptive
    Acoustic实施了一种使用CGN生成计算3D音乐厅的方法。设计师训练了音乐厅内部的网格以及空间和声学参数作为两个数据集，以追求符合声学要求的建筑。手动地，这些参数被细化为可量化的信息，包括座位、体积、混响时间、声学吸收区域、吸收系数等，最终生成具有声学特征的AI音乐厅形式。
- en: 2.5.2\. The Algorithmic Form
  id: totrans-98
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.2\. 算法形式
- en: The algorithmic form is “the relationship between computation and information
    about computationally generated objects (such as strings or any other data structures)”
    (Chaitin, [1975b](#bib.bib28)). A growing number of social algorithm proposals
    promise that neural networks and machine learning algorithms are research areas
    that can take social factors into account. For example, with different data input
    to the housing generation algorithms, various master plans can be generated with
    varying perceptions of privacy or construction price choices  (Koh, [2022](#bib.bib92)).
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 算法形式是“计算与关于计算生成对象（如字符串或任何其他数据结构）的信息之间的关系”（Chaitin, [1975b](#bib.bib28)）。越来越多的社会算法提案承诺，神经网络和机器学习算法是能够考虑社会因素的研究领域。例如，通过不同的数据输入到住房生成算法中，可以生成各种主规划，具有不同的隐私感知或建设价格选择
    (Koh, [2022](#bib.bib92))。
- en: Additionally, there is a growing emphasis on social parameters, ranging from
    the data-driven in algorithmic social sciences to agent-based parametric semiotics
    in the architectural form (Schumacher, [2013](#bib.bib152); ASSRU, [1999](#bib.bib11)).
    Algorithm form implicates the relationship between the computed objects such as
    String and any data structure and the information(Chaitin, [1975a](#bib.bib27)).
    The growing number of social algorithms proposed promises that neural networks
    and machine learning algorithms are areas of research that can take social factors
    into account. In this regard, the social goal stands in the middle of computationally
    generated forms and architectural designs.
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，对社会参数的关注也在增加，从数据驱动的算法社会科学到建筑形式中的基于代理的参数符号学 (Schumacher, [2013](#bib.bib152);
    ASSRU, [1999](#bib.bib11))。算法形式涉及计算对象（如字符串和任何数据结构）与信息之间的关系（Chaitin, [1975a](#bib.bib27)）。越来越多的社会算法提案承诺，神经网络和机器学习算法是可以考虑社会因素的研究领域。在这方面，社会目标位于计算生成形式和建筑设计的中间。
- en: 2.5.3\. The Liberty of Form
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 2.5.3. 形式的自由
- en: '![Refer to caption](img/ad77c057f37386eb7189d0ed848ea818.png)'
  id: totrans-102
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/ad77c057f37386eb7189d0ed848ea818.png)'
- en: '(a) George Guida, 2022\. Multimodal Architecture: Applications of Language
    in a Machine Learning Aided Design Process.'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: (a) George Guida, 2022年。《多模态建筑：语言在机器学习辅助设计过程中的应用》。
- en: '![Refer to caption](img/7cf7aa6a1f2a8e47e8694f38b28f8d9c.png)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/7cf7aa6a1f2a8e47e8694f38b28f8d9c.png)'
- en: (b) Joris Putteneers, 2016\. Synesthesia.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: (b) Joris Putteneers, 2016年。《联觉》。
- en: '![Refer to caption](img/c58824cfe7a03991fd94f5778beff464.png)'
  id: totrans-106
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/c58824cfe7a03991fd94f5778beff464.png)'
- en: (c) The generating process in Synesthesia.
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 联觉中的生成过程。
- en: '![Refer to caption](img/3d1e788eaa73deb677000abf660584dd.png)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3d1e788eaa73deb677000abf660584dd.png)'
- en: '(d) A data-driven architectural project named E-motion: a digital interface
    allows users to capture real-time data to interact with for a rethinking of co-living
    among various species.'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 一个数据驱动的建筑项目，名为 E-motion：一个数字化界面允许用户捕捉实时数据以进行互动，以重新思考不同物种之间的共同生活。
- en: '![Refer to caption](img/08c198e0ea17785436cb3b0fb3a949b2.png)'
  id: totrans-110
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/08c198e0ea17785436cb3b0fb3a949b2.png)'
- en: (e) Viviane toraci fiorella, Taza celilia, Prandini Alvaro Campo. ”ISOS” in
    “Volumeric Cinema” workshop by Current.CAM, 2022
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: (e) Viviane Toraci Fiorella、Taza Celilia、Prandini Alvaro Campo。“ISOS”在 Current.CAM
    2022年“体积电影”工作坊中
- en: '![Refer to caption](img/24064f774b7ef3a2cbabfc9ac0d9ef17.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/24064f774b7ef3a2cbabfc9ac0d9ef17.png)'
- en: (f) Tane Moleta and Mizuho Nishioka, the co-constructive project, ”Populating
    Virtual Worlds Together”, 2021  (MOLETA and NISHIOKA, [2021](#bib.bib116)).
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: (f) Tane Moleta 和 Mizuho Nishioka，合作建设项目，“共同填充虚拟世界”，2021年 (MOLETA 和 NISHIOKA,
    [2021](#bib.bib116))。
- en: '![Refer to caption](img/816400057745c0218f0b9e8bbacd65e7.png)'
  id: totrans-114
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/816400057745c0218f0b9e8bbacd65e7.png)'
- en: (g)  (Barsan-Pipu et al., [2020](#bib.bib15)) generates a 3D volumetric architecture
    for virtual environments by utilizing BCI to capture affective-driven dynamic
    noise.
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: (g) (Barsan-Pipu 等, [2020](#bib.bib15)) 通过利用脑机接口 (BCI) 捕捉情感驱动的动态噪声，为虚拟环境生成 3D
    体积建筑。
- en: '![Refer to caption](img/8e9bd56078a2ad9d32082a0acfa84bf8.png)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/8e9bd56078a2ad9d32082a0acfa84bf8.png)'
- en: (h) Current.CAM, VR gallery, 2021
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: (h) Current.CAM，VR 画廊，2021年
- en: Figure 7. Some architecture projects with the liberty of form.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: 图7. 一些具有形式自由的建筑项目。
- en: 'The virtual architectural form is more flexible than ever before, and the boundaries
    of the definition are more indistinct and inclusive (See Fig.  [7](#S2.F7 "Figure
    7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The Design Factors in DL-Aided Architecture
    ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")). The generative logic of forms has met transformation, where
    the geometry of space has been expanded to the intelligence of space. The intelligence
    of space represents a multisensory approach where we are free to generate form
    embedded as assistance. Joris Putteneers’ project creates a surreal and complex
    architectural construction by simulating the particle motions in Houdini  ^(15)^(15)15Source:
    [https://putteneersjoris.xyz/projects/synesthesia/synesthesia.html](https://putteneersjoris.xyz/projects/synesthesia/synesthesia.html)
    (Fig.  [7(b)](#S2.F7.sf2 "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The
    Design Factors in DL-Aided Architecture ‣ 2\. Overview of Generated 3D Virtual
    Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")
    and [7(c)](#S2.F7.sf3 "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The Design
    Factors in DL-Aided Architecture ‣ 2\. Overview of Generated 3D Virtual Architecture
    ‣ Towards Computational Architecture of Liberty: A Comprehensive Survey on Deep
    Learning for Generating Virtual Architecture in the Metaverse")). This is a figurative
    abstraction of the algorithm in 3D space. The form for virtual architecture can
    also be a visualization of data in 3D space. For example, an architectural project,
    namely E-motion, designs an interface for data visualization driven by the redistribution
    and simulation of animal and human movement habits, thus linking human and non-human
    intelligence  ^(16)^(16)16Fei Chen, Mochen Jiang, Haojun Cui, and Yuankai Wang,
    E-motion, 2020\. Source: [https://bproautumn2020.bartlettarchucl.com/rc18/e-motion](https://bproautumn2020.bartlettarchucl.com/rc18/e-motion)
    (Fig.  [7(d)](#S2.F7.sf4 "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The
    Design Factors in DL-Aided Architecture ‣ 2\. Overview of Generated 3D Virtual
    Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    While George Guida visualizes the influence of intelligent algorithms and multimodality
    for the architecture in another project  ^(17)^(17)17Source: [https://www.gsd.harvard.edu/project/2022-digital-design-prize-george-guidas-multimodal-architecture-applications-of-language-in-a-machine-learning-aided-design-process/](https://www.gsd.harvard.edu/project/2022-digital-design-prize-george-guidas-multimodal-architecture-applications-of-language-in-a-machine-learning-aided-design-process/)
    (Fig. [7(a)](#S2.F7.sf1 "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The
    Design Factors in DL-Aided Architecture ‣ 2\. Overview of Generated 3D Virtual
    Architecture ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    In the Fourth Virtual Dimension, the authors propose a redefinition of the dimensionality
    of thermoception in VR to understand and engage with the spatial and directional
    aspects of virtual scenes  (Sheehan et al., [2021](#bib.bib155)) (Fig. [7(f)](#S2.F7.sf6
    "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The Design Factors in DL-Aided
    Architecture ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")). The form of virtual architecture is
    even a kind of co-construction. For instance, a project, namely Populating Virtual
    Worlds Together, encourages artists with no experience in 3D modeling to create
    using a participatory design approach  (MOLETA and NISHIOKA, [2021](#bib.bib116)).
    It leads to an autonomous virtual world consisting of cubes and corresponding
    columns of varying heights and forests.'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: '虚拟建筑形式比以往任何时候都更加灵活，定义的边界变得更加模糊和包容（见图 [7](#S2.F7 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\.
    深度学习辅助建筑设计的设计因素 ‣ 2\. 生成的 3D 虚拟建筑概述 ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查")）。形式的生成逻辑经历了转变，空间的几何已扩展到空间的智能。空间智能代表了一种多感官的方法，在这种方法中，我们可以自由生成嵌入的形式作为辅助工具。Joris
    Putteneers 的项目通过模拟 Houdini 中的粒子运动创建了一种超现实且复杂的建筑构造 ^(15)^(15)15来源: [https://putteneersjoris.xyz/projects/synesthesia/synesthesia.html](https://putteneersjoris.xyz/projects/synesthesia/synesthesia.html)（见图
    [7(b)](#S2.F7.sf2 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\. 深度学习辅助建筑设计的设计因素 ‣ 2\. 生成的 3D 虚拟建筑概述
    ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查") 和 [7(c)](#S2.F7.sf3 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\.
    深度学习辅助建筑设计的设计因素 ‣ 2\. 生成的 3D 虚拟建筑概述 ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查")。这是对 3D 空间中算法的形象抽象。虚拟建筑的形式也可以是数据在
    3D 空间中的可视化。例如，一个建筑项目，即 E-motion，设计了一个数据可视化接口，驱动因素是动物和人类运动习惯的重新分配和模拟，从而连接了人类与非人类智能
    ^(16)^(16)16Fei Chen, Mochen Jiang, Haojun Cui, 和 Yuankai Wang, E-motion, 2020。来源:
    [https://bproautumn2020.bartlettarchucl.com/rc18/e-motion](https://bproautumn2020.bartlettarchucl.com/rc18/e-motion)（见图
    [7(d)](#S2.F7.sf4 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\. 深度学习辅助建筑设计的设计因素 ‣ 2\. 生成的 3D 虚拟建筑概述
    ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查")）。与此同时，George Guida 在另一个项目中可视化了智能算法和多模态对建筑的影响 ^(17)^(17)17来源:
    [https://www.gsd.harvard.edu/project/2022-digital-design-prize-george-guidas-multimodal-architecture-applications-of-language-in-a-machine-learning-aided-design-process/](https://www.gsd.harvard.edu/project/2022-digital-design-prize-george-guidas-multimodal-architecture-applications-of-language-in-a-machine-learning-aided-design-process/)（见图
    [7(a)](#S2.F7.sf1 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\. 深度学习辅助建筑设计的设计因素 ‣ 2\. 生成的 3D 虚拟建筑概述
    ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查")。在第四维虚拟空间中，作者提出了重新定义 VR 中热觉维度的概念，以理解和参与虚拟场景的空间和方向性（Sheehan
    等， [2021](#bib.bib155)）（见图 [7(f)](#S2.F7.sf6 "图 7 ‣ 2.5.3\. 形式的自由 ‣ 2.5\. 深度学习辅助建筑设计的设计因素
    ‣ 2\. 生成的 3D 虚拟建筑概述 ‣ 朝向计算自由建筑：虚拟建筑生成的深度学习综合调查")）。虚拟建筑的形式甚至是一种共建。例如，一个名为“共同填充虚拟世界”的项目鼓励没有
    3D 建模经验的艺术家使用参与式设计方法进行创作（MOLETA 和 NISHIOKA， [2021](#bib.bib116)）。这导致了一个由立方体和相应高度变化的柱子以及森林组成的自主虚拟世界。'
- en: 'Second, in the generation of virtual architecture, VWs generally take into
    account more aesthetic, cultural, and human-centered intentions.  (Barsan-Pipu
    et al., [2020](#bib.bib15)) (Fig.  [7(g)](#S2.F7.sf7 "In Figure 7 ‣ 2.5.3\. The
    Liberty of Form ‣ 2.5\. The Design Factors in DL-Aided Architecture ‣ 2\. Overview
    of Generated 3D Virtual Architecture ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")). The definition of ”good” architecture has been practically the
    core of architectural discourse  (Bava, [2020](#bib.bib18)). Discussions around
    digital architecture often address this question by escaping into the realm of
    taste or artistic judgment. Aesthetics is criticized as using digital and data
    as a supportive tool homogeneously as a solution in digital architecture. In contrast,
    aesthetics in virtual architecture can justify the grand plan. For instance, Current.
    CAM’s VR exhibition is formed by continuous partitioned spaces with purely fluid
    blue, reinforcing the digital interface’s shaping on the human senses (Fig.  [7(h)](#S2.F7.sf8
    "In Figure 7 ‣ 2.5.3\. The Liberty of Form ‣ 2.5\. The Design Factors in DL-Aided
    Architecture ‣ 2\. Overview of Generated 3D Virtual Architecture ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")). In a workshop, they organised the interaction
    between virtual avatars and fantastically dramatic environments to explore human
    perception of space (Fig.  [7(e)](#S2.F7.sf5 "In Figure 7 ‣ 2.5.3\. The Liberty
    of Form ‣ 2.5\. The Design Factors in DL-Aided Architecture ‣ 2\. Overview of
    Generated 3D Virtual Architecture ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")). This transcendent novelty of virtual architecture encourages
    the user’s quest for novel audiovisual sensations.'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 其次，在虚拟建筑的生成中，虚拟世界通常会考虑更多的美学、文化和以人为本的意图。（Barsan-Pipu 等人，[2020](#bib.bib15)）(图
    [7(g)](#S2.F7.sf7 "在图 7 ‣ 2.5.3. 形式的自由 ‣ 2.5. 深度学习辅助建筑中的设计因素 ‣ 2. 生成的 3D 虚拟建筑概述
    ‣ 朝向自由的计算建筑：关于深度学习在元宇宙中生成虚拟建筑的综合调查"))。“好”的建筑的定义实际上是建筑话语的核心（Bava，[2020](#bib.bib18)）。关于数字建筑的讨论通常通过逃避到品味或艺术判断的领域来解决这个问题。美学被批评为在数字建筑中将数字和数据作为统一的支持工具来解决问题。相反，虚拟建筑中的美学可以为宏伟的计划提供正当理由。例如，Current.
    CAM 的 VR 展览由连续分隔的空间组成，呈现纯流动的蓝色，强化了数字界面对人类感官的塑造（图 [7(h)](#S2.F7.sf8 "在图 7 ‣ 2.5.3.
    形式的自由 ‣ 2.5. 深度学习辅助建筑中的设计因素 ‣ 2. 生成的 3D 虚拟建筑概述 ‣ 朝向自由的计算建筑：关于深度学习在元宇宙中生成虚拟建筑的综合调查")）。在一次工作坊中，他们组织了虚拟化身与奇幻戏剧化环境的互动，以探索人类对空间的感知（图
    [7(e)](#S2.F7.sf5 "在图 7 ‣ 2.5.3. 形式的自由 ‣ 2.5. 深度学习辅助建筑中的设计因素 ‣ 2. 生成的 3D 虚拟建筑概述
    ‣ 朝向自由的计算建筑：关于深度学习在元宇宙中生成虚拟建筑的综合调查")）。这种虚拟建筑的超越性新颖性鼓励用户对新奇视听感受的追求。
- en: '3\. Generated 3D Architecture: A PARADIGM SHIFT'
  id: totrans-121
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 生成的 3D 架构：一种范式转变
- en: 'Before the 3D algorithms that can automatically store and process the 3D data,
    the 3D generation methods were mostly developed based on 2D images. The remarkable
    growth of the 3D generation in recent years has revealed the tremendous power
    of this field. Compared to 2D image generation, 3D generation is a daunting task
    regarding the aspects of the 3D dataset, computational consumption, feature learning,
    and probability distribution in 3D space. We investigate the virtual architecture
    generation based on various DGMs both in methods of CV (Table  [1](#S3.T1 "Table
    1 ‣ 3.2\. 3D Solid Form Generation with the GANs ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse"),
    Table  [3.4](#S3.SS4 "3.4\. 3D-Aware Image Synthesis ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse"))
    and architecture (Table  [2](#S3.T2 "Table 2 ‣ 3.2.2\. 3D Solid Form Generation
    ‣ 3.2\. 3D Solid Form Generation with the GANs ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    In the first part, we introduce some research on architectural designs concentrating
    on the 2D deep generative models aiming for 3D transposition, especially GANs.
    Then, we divide deep learning generation approaches for 3D representations into
    four categories based on DGMs: (See Fig.  [8](#S3.F8 "Figure 8 ‣ 3\. Generated
    3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")):'
  id: totrans-122
  prefs: []
  type: TYPE_NORMAL
  zh: 在可以自动存储和处理3D数据的3D算法出现之前，3D生成方法主要是基于2D图像发展的。近年来3D生成的显著增长展示了这一领域的巨大潜力。与2D图像生成相比，3D生成在3D数据集、计算消耗、特征学习和3D空间中的概率分布方面都是一项艰巨的任务。我们调查了基于各种深度生成模型的虚拟建筑生成方法，包括计算机视觉（表
    [1](#S3.T1 "表 1 ‣ 3.2\. 基于GANs的3D实体形态生成 ‣ 3\. 生成的3D建筑：一种范式转变 ‣ 朝向计算架构的自由：对生成虚拟建筑的深度学习的综合调查")，
    表 [3.4](#S3.SS4 "3.4\. 3D感知图像合成 ‣ 3\. 生成的3D建筑：一种范式转变 ‣ 朝向计算架构的自由：对生成虚拟建筑的深度学习的综合调查")）和建筑学（表
    [2](#S3.T2 "表 2 ‣ 3.2.2\. 3D实体形态生成 ‣ 3.2\. 基于GANs的3D实体形态生成 ‣ 3\. 生成的3D建筑：一种范式转变
    ‣ 朝向计算架构的自由：对生成虚拟建筑的深度学习的综合调查")）。在第一部分，我们介绍了一些集中于2D深度生成模型的建筑设计研究，特别是GANs。然后，我们根据深度生成模型将3D表示的深度学习生成方法分为四类：（见图
    [8](#S3.F8 "图 8 ‣ 3\. 生成的3D建筑：一种范式转变 ‣ 朝向计算架构的自由：对生成虚拟建筑的深度学习的综合调查")）。
- en: (1)
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 3D form generation from probabilistic spaces or 2D image sets with GANs.
  id: totrans-124
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于GANs从概率空间或2D图像集生成3D形态。
- en: (2)
  id: totrans-125
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (2)
- en: 3D information extraction from latent space with VAEs.
  id: totrans-126
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 从潜在空间中提取3D信息的变分自编码器（VAEs）。
- en: (3)
  id: totrans-127
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (3)
- en: Recent advances in 3D-aware image synthesis and the possibilities of incorporating
    with architecture.
  id: totrans-128
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 最近在3D感知图像合成方面的进展以及与建筑学结合的可能性。
- en: (4)
  id: totrans-129
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (4)
- en: Latest research on diffusion models based on conditional text.
  id: totrans-130
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
  zh: 基于条件文本的扩散模型的最新研究。
- en: '![Refer to caption](img/b76e0ce1a601151a066688c26b263112.png)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b76e0ce1a601151a066688c26b263112.png)'
- en: Figure 8. A systematic taxonomy for a review of generation approaches on virtual
    architecture design with DGMs.
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 图8. 用于虚拟建筑设计生成方法回顾的系统分类法。
- en: '![Refer to caption](img/d77e4c04a32f5b67679a110df1dc613f.png)'
  id: totrans-133
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d77e4c04a32f5b67679a110df1dc613f.png)'
- en: Figure 9. The examples of generated objects in the field of computer. (a) 3D
    GAN  (Wu et al., [2016](#bib.bib170)), (b)PointFlow  (Yang et al., [2019](#bib.bib174)),
    (c) HoloGAN  (Nguyen-Phuoc et al., [2019](#bib.bib126)), (d)StyleSDF  (Or-El et al.,
    [2022](#bib.bib132)) (e)Point-E  (Nichol et al., [2022](#bib.bib128)) (f)DreamFusion
     (Poole et al., [2022](#bib.bib139)).
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 图9. 计算机领域生成对象的示例。 (a) 3D GAN (Wu et al., [2016](#bib.bib170))， (b) PointFlow
    (Yang et al., [2019](#bib.bib174))， (c) HoloGAN (Nguyen-Phuoc et al., [2019](#bib.bib126))，
    (d) StyleSDF (Or-El et al., [2022](#bib.bib132))， (e) Point-E (Nichol et al.,
    [2022](#bib.bib128))， (f) DreamFusion (Poole et al., [2022](#bib.bib139))。
- en: 3.1\. 3D Form Transposition with Constrained Approaches
  id: totrans-135
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.1\. 受约束方法的3D形态转换
- en: In the past few years, 2D image generation by deep generative models has been
    rapidly developed. Most DL-assisted architecture with deep generative models relies
    on dealing with 2D drawings (Jaminet et al., [2021](#bib.bib78); Mohammad, [2019](#bib.bib115);
    Srivastava et al., [2021](#bib.bib159)), such as composition by overlapping the
    section or plan. It has resulted in the opinion of equaling deep learning in DL-assisted
    architectural design to pix2pix. Significant progress in this methodology is post-processing
    those generated images for targeting 3D models. Those methods intuitively consider
    a post-process through heuristic algorithms or human labor rather than scientific
    methods, aiming for critical ideas and innovative concepts.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 在过去的几年里，深度生成模型的二维图像生成得到了迅速发展。大多数基于深度生成模型的深度学习辅助建筑设计都依赖于处理二维图纸（Jaminet 等， [2021](#bib.bib78)；Mohammad，
    [2019](#bib.bib115)；Srivastava 等， [2021](#bib.bib159)），例如通过重叠截面或平面进行构图。这导致了将深度学习在深度学习辅助建筑设计中等同于
    pix2pix 的观点。这种方法的重要进展是对生成图像进行后处理以针对三维模型。这些方法通常通过启发式算法或人工劳动来进行后处理，而不是科学方法，旨在实现关键思想和创新概念。
- en: 3.1.1\. 3D Form Transposition
  id: totrans-137
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.1.1\. 3D 形式转置
- en: '![Refer to caption](img/44e8a3192f31db024f10175712e9aad1.png)'
  id: totrans-138
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/44e8a3192f31db024f10175712e9aad1.png)'
- en: (a) A pipeline in described work  (Zhang and Blasetti, [2020](#bib.bib183)).
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 描述工作中的一个管道（Zhang 和 Blasetti，[2020](#bib.bib183)）。
- en: '![Refer to caption](img/d37086d50c463d6e44b5fd483ce27117.png)'
  id: totrans-140
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/d37086d50c463d6e44b5fd483ce27117.png)'
- en: (b) An process signifies pixels filter from 2D to 3D lattice in  (Ren and Zheng,
    [2020](#bib.bib144)).
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 一个过程表示从二维到三维格点的像素过滤（Ren 和 Zheng，[2020](#bib.bib144)）。
- en: Figure 10. The architectural projects through 3D form transposition with 2D
    deep generative models.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
  zh: 图 10. 通过二维深度生成模型的三维形式转置的建筑项目。
- en: '3D transposition indicates a methodology commences with segmenting a 3D model
    into discrete images, such as sections, plans, and projections from multiple viewpoints.
    It transforms resulting abstractions into 3D representations with using tedious
    computational methods or intuitive manual manipulation (See Fig.  [10(a)](#S3.F10.sf1
    "In Figure 10 ‣ 3.1.1\. 3D Form Transposition ‣ 3.1\. 3D Form Transposition with
    Constrained Approaches ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")) (See Fig.  [10(b)](#S3.F10.sf2
    "In Figure 10 ‣ 3.1.1\. 3D Form Transposition ‣ 3.1\. 3D Form Transposition with
    Constrained Approaches ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")). As an illustration, Zhang
    and Blasetti employed section transformation between two models to manipulate
    the form from 2D to 3D (Zhang and Blasetti, [2020](#bib.bib183)). Inherited from
    2D design thinking, the 3D form transposition experiments are likewise mainly
    conducted based on 2D to 3D composition using the image-to-image translation networks
    such as Style Transfer (Özel, [2020](#bib.bib134); Ren and Zheng, [2020](#bib.bib144);
    Liu et al., [2021](#bib.bib107); Zhang and Blasetti, [2020](#bib.bib183)), StyleGAN
    (Del Campo et al., [2019](#bib.bib39); Zhang, [2019](#bib.bib181); Zhang and Huang,
    [2021](#bib.bib184)) and pix2pixGAN (Yu, [2020](#bib.bib176); Di Carlo et al.,
    [2022](#bib.bib43)). They act as 2D-based form finding tools that support the
    decision-making process for designers in transforming 3D models into different
    formats. The representation of the 2D images was developed further from pixels
    or voxels to lateral thinking. Data can be compressed to a high dimensional latent
    space with enhanced connections. EI Asmar and Sareen employ vector arithmetic
    and interpolations to navigate in the latent space to generate various images
    as options for 3D voxelization (Asmar and Sareen, [2020](#bib.bib10)). Bank et
    al. developed an interactive tool that can manipulate data in latent spaces, where
    the generated stylized images were represented as point clouds and can be assembled
    as spectral entities in adjustable resolution (Bank et al., [2022](#bib.bib14)).
    Similarly, in the latent space, the continuous sequence of images can be generated
    by feature interpolation. The project ‘Generali Center’ developed by Del Campo
    et al. also utilized StyleGAN to present latent walks(del Campo et al., [2022](#bib.bib40)).
    Using pixel projection to convert the values in the pixels into a 3D model is
    a significant advancement in their research.'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
  zh: 3D 转置指的是一种方法论，它从将 3D 模型分割成离散的图像开始，例如来自多个视角的切片、平面和投影。它将这些抽象结果转换成 3D 表示，通过使用繁琐的计算方法或直观的手动操作（见图
    [10(a)](#S3.F10.sf1 "在图 10 ‣ 3.1.1\. 3D 形态转置 ‣ 3.1\. 约束方法的 3D 形态转置 ‣ 3\. 生成的 3D
    架构：一个范式转变 ‣ 走向计算架构的自由：关于深度学习生成虚拟架构的全面调查")）（见图 [10(b)](#S3.F10.sf2 "在图 10 ‣ 3.1.1\.
    3D 形态转置 ‣ 3.1\. 约束方法的 3D 形态转置 ‣ 3\. 生成的 3D 架构：一个范式转变 ‣ 走向计算架构的自由：关于深度学习生成虚拟架构的全面调查")）。作为例子，Zhang
    和 Blasetti 使用两个模型之间的切片转换将形态从 2D 转换为 3D（Zhang 和 Blasetti，[2020](#bib.bib183)）。继承自
    2D 设计思维，3D 形态转置实验主要也是基于使用图像到图像的转换网络进行的，例如风格迁移（Özel，[2020](#bib.bib134)；Ren 和 Zheng，[2020](#bib.bib144)；Liu
    等，[2021](#bib.bib107)；Zhang 和 Blasetti，[2020](#bib.bib183)），StyleGAN（Del Campo
    等，[2019](#bib.bib39)；Zhang，[2019](#bib.bib181)；Zhang 和 Huang，[2021](#bib.bib184)）和
    pix2pixGAN（Yu，[2020](#bib.bib176)；Di Carlo 等，[2022](#bib.bib43)）。它们作为基于 2D 的形态发现工具，支持设计师在将
    3D 模型转换成不同格式时的决策过程。2D 图像的表示从像素或体素发展到更具横向思维的数据。数据可以压缩到一个高维潜在空间中，增强连接。EI Asmar 和
    Sareen 利用向量算术和插值在潜在空间中导航，生成各种图像作为 3D 体素化的选项（Asmar 和 Sareen，[2020](#bib.bib10)）。Bank
    等人开发了一种交互式工具，可以操控潜在空间中的数据，其中生成的风格化图像被表示为点云，并可以作为可调分辨率的光谱实体组装（Bank 等，[2022](#bib.bib14)）。类似地，在潜在空间中，通过特征插值可以生成图像的连续序列。Del
    Campo 等人开发的“Generali Center”项目也利用了 StyleGAN 来展示潜在的步态（Del Campo 等，[2022](#bib.bib40)）。使用像素投影将像素中的值转换为
    3D 模型是他们研究中的一个重要进展。
- en: Huang et al. (Huang et al., [2021](#bib.bib70)) employs latent space to encode
    the 3D information from images of GANs. The generated image is technically a set
    of points mapping from latent space to a 2D graph, then it conduct an interpolation
    containing a sequence of perspectives. The perspectival GAN (Kim and Huang, [2022](#bib.bib89))
    is an extended research comprising latent space rotation to learn 3D information
    in 2D images.
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
  zh: Huang et al. (Huang et al., [2021](#bib.bib70)) 使用潜在空间来编码来自GAN图像的3D信息。生成的图像实际上是一组从潜在空间映射到2D图形的点，然后进行包含一系列视角的插值。透视GAN
    (Kim and Huang, [2022](#bib.bib89)) 是一项扩展研究，包含潜在空间旋转以学习2D图像中的3D信息。
- en: The 2D image-to-image translation algorithms utilized in 3D form generation
    are evidence of computational freedom in the innovative 3D generation since the
    future direction of virtual spaces lies in complex variations. This generation
    method allows for the preservation of high resolution in both input and output,
    as 2D images are lightweight and simple to process. Furthermore, training algorithms
    for 2D-based GANs networks have been well-developed, thereby providing a wide
    range of possibilities for human interaction with algorithms, as well as various
    adjustable output options through contouring 2D patterns into 3D forms.
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
  zh: 在3D形状生成中使用的2D图像到图像的转换算法证明了计算自由度在创新3D生成中的作用，因为虚拟空间的未来方向在于复杂的变换。这种生成方法允许输入和输出中保持高分辨率，因为2D图像轻量且易于处理。此外，基于2D的GAN网络的训练算法已经得到了很好的发展，因此为人机交互提供了广泛的可能性，以及通过将2D模式轮廓调整为3D形状的各种可调输出选项。
- en: 3.2\. 3D Solid Form Generation with the GANs
  id: totrans-146
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.2\. 使用GAN进行3D固体形状生成
- en: '| Method Names | Publication& Year | 3D Representations | Models |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| 方法名称 | 发表刊物与年份 | 3D 表示 | 模型 |'
- en: '| 3D GAN (Wu et al., [2016](#bib.bib170)) | NIPS 2016 | Voxel grid | GAN |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| 3D GAN (Wu et al., [2016](#bib.bib170)) | NIPS 2016 | 体素网格 | GAN |'
- en: '| Text2Shape (Chen et al., [2018](#bib.bib30)) | ACCV 2018 | Voxel grid | GAN
    |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| Text2Shape (Chen et al., [2018](#bib.bib30)) | ACCV 2018 | 体素网格 | GAN |'
- en: '| PLATONICGAN (Henzler et al., [2019](#bib.bib65)) | CVPR 2019 | Voxel grid
    | GAN |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| PLATONICGAN (Henzler et al., [2019](#bib.bib65)) | CVPR 2019 | 体素网格 | GAN
    |'
- en: '| IG GAN  (Lunz et al., [2020](#bib.bib110)) | arXiv 2020 | Voxel grid | GAN
    |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| IG GAN  (Lunz et al., [2020](#bib.bib110)) | arXiv 2020 | 体素网格 | GAN |'
- en: '| Achlioptas et al.  (Achlioptas et al., [2018](#bib.bib3)) | ICML 2018 | Point
    cloud | GAN |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| Achlioptas et al.  (Achlioptas et al., [2018](#bib.bib3)) | ICML 2018 | 点云
    | GAN |'
- en: '| Shu et al.  (Shu et al., [2019](#bib.bib158)) | CVPR 2019 | Point cloud |
    GAN |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| Shu et al.  (Shu et al., [2019](#bib.bib158)) | CVPR 2019 | 点云 | GAN |'
- en: '| Get3d  (Gao et al., [2022](#bib.bib51)) | NeurIPS 2022 | Mesh | GAN |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| Get3d  (Gao et al., [2022](#bib.bib51)) | NeurIPS 2022 | 网格 | GAN |'
- en: '| IM-Net  (Chen and Zhang, [2019](#bib.bib31)) | CVPR 2019 | Neural field |
    GAN |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| IM-Net  (Chen and Zhang, [2019](#bib.bib31)) | CVPR 2019 | 神经场 | GAN |'
- en: '| Kleineberg et al.  (Kleineberg et al., [2020](#bib.bib91)) | arXiv 2020 |
    Neural field | GAN |'
  id: totrans-156
  prefs: []
  type: TYPE_TB
  zh: '| Kleineberg et al.  (Kleineberg et al., [2020](#bib.bib91)) | arXiv 2020 |
    神经场 | GAN |'
- en: '| Brock et al.  (Brock et al., [2016](#bib.bib21)) | arXiv 2016 | Voxel grid
    | VAE |'
  id: totrans-157
  prefs: []
  type: TYPE_TB
  zh: '| Brock et al.  (Brock et al., [2016](#bib.bib21)) | arXiv 2016 | 体素网格 | VAE
    |'
- en: '| Autosdf  (Mittal et al., [2022](#bib.bib114)) | CVPR 2022 | Voxel gird |
    VAE |'
  id: totrans-158
  prefs: []
  type: TYPE_TB
  zh: '| Autosdf  (Mittal et al., [2022](#bib.bib114)) | CVPR 2022 | 体素网格 | VAE |'
- en: '| Sagnet  (Wu et al., [2019](#bib.bib172)) | TOG 2019 | Voxel gird | VAE |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
  zh: '| Sagnet  (Wu et al., [2019](#bib.bib172)) | TOG 2019 | 体素网格 | VAE |'
- en: '| Li et al.  (Li et al., [2020](#bib.bib102)) | AAAI 2020 | Voxel gird | VAE
    |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
  zh: '| Li et al.  (Li et al., [2020](#bib.bib102)) | AAAI 2020 | 体素网格 | VAE |'
- en: '| Pq-net  (Wu et al., [2020](#bib.bib171)) | CVPR 2020 | Voxel gird | VAE |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
  zh: '| Pq-net  (Wu et al., [2020](#bib.bib171)) | CVPR 2020 | 体素网格 | VAE |'
- en: '| AdversarialAE  (Zamorski et al., [2020](#bib.bib178)) | CVPR 2020 | Voxel
    gird | VAE |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
  zh: '| AdversarialAE  (Zamorski et al., [2020](#bib.bib178)) | CVPR 2020 | 体素网格
    | VAE |'
- en: '| Multi-Chart  (Ben-Hamu et al., [2018](#bib.bib19)) | TOG 2018 | Mesh | VAE
    |'
  id: totrans-163
  prefs: []
  type: TYPE_TB
  zh: '| Multi-Chart  (Ben-Hamu et al., [2018](#bib.bib19)) | TOG 2018 | 网格 | VAE
    |'
- en: '| SDM-NET  (Gao et al., [2019](#bib.bib52)) | TOG 2019 | Mesh | VAE |'
  id: totrans-164
  prefs: []
  type: TYPE_TB
  zh: '| SDM-NET  (Gao et al., [2019](#bib.bib52)) | TOG 2019 | 网格 | VAE |'
- en: '| Tm-net  (Gao et al., [2021](#bib.bib53)) | TOG 2021 | Mesh | VAE |'
  id: totrans-165
  prefs: []
  type: TYPE_TB
  zh: '| Tm-net  (Gao et al., [2021](#bib.bib53)) | TOG 2021 | 网格 | VAE |'
- en: '| Polygen  (Nash et al., [2020](#bib.bib121)) | ICML 2020 | Mesh | VAE |'
  id: totrans-166
  prefs: []
  type: TYPE_TB
  zh: '| Polygen  (Nash et al., [2020](#bib.bib121)) | ICML 2020 | 网格 | VAE |'
- en: '| PointFLow  (Yang et al., [2019](#bib.bib174)) | CVPR 2019 | Point cloud |
    Normaliz. flow model |'
  id: totrans-167
  prefs: []
  type: TYPE_TB
  zh: '| PointFLow  (Yang et al., [2019](#bib.bib174)) | CVPR 2019 | 点云 | 正常化流模型 |'
- en: '| CLIP-Forge  (Sanghi et al., [2022](#bib.bib146)) | CVPR 2022 | Voxel grid
    | Normaliz. flow model |'
  id: totrans-168
  prefs: []
  type: TYPE_TB
  zh: '| CLIP-Forge  (Sanghi et al., [2022](#bib.bib146)) | CVPR 2022 | 体素网格 | 正常化流模型
    |'
- en: '| PDV  (Zhou et al., [2021](#bib.bib187)) | CVPR 2021 | Hybrid: point-voxel
    | Diffusion model |'
  id: totrans-169
  prefs: []
  type: TYPE_TB
  zh: '| PDV  (Zhou et al., [2021](#bib.bib187)) | CVPR 2021 | 混合：点-体素 | 扩散模型 |'
- en: '| Magic3D  (Lin et al., [2022](#bib.bib105)) | arXiv 2022 | Neural field-Mesh
    | Diffusion model |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
  zh: '| Magic3D  （Lin 等，[2022](#bib.bib105)） | arXiv 2022 | 神经场-网格 | 扩散模型 |'
- en: '| LION  (Zeng et al., [2022](#bib.bib180)) | arXiv 2022 | Mesh | Diffusion
    model |'
  id: totrans-171
  prefs: []
  type: TYPE_TB
  zh: '| LION  （Zeng 等，[2022](#bib.bib180)） | arXiv 2022 | 网格 | 扩散模型 |'
- en: '| Point-E  (Nichol et al., [2022](#bib.bib128)) | arXiv 2022 | Neural field-Point
    cloud | Diffusion model |'
  id: totrans-172
  prefs: []
  type: TYPE_TB
  zh: '| Point-E  （Nichol 等，[2022](#bib.bib128)） | arXiv 2022 | 神经场-点云 | 扩散模型 |'
- en: Table 1. An overview of 3D generative approaches of 3D shape generation. For
    3D shape generation, each method allows generating editable models for explicit
    representations. Models indicates the DGM types inlcuding GAN, VAE, normalizing
    flow model, and diffusion model.
  id: totrans-173
  prefs: []
  type: TYPE_NORMAL
  zh: 表 1. 3D 形状生成的 3D 生成方法概述。对于 3D 形状生成，每种方法都允许生成用于显式表示的可编辑模型。模型指示了包括 GAN、VAE、归一化流模型和扩散模型在内的
    DGM 类型。
- en: 3.2.1\. 3D Shape Generation with GANs
  id: totrans-174
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.1\. 使用 GAN 进行 3D 形状生成
- en: 'GANs have been developed as a controlled 3D generation method from image data
    that can generate different explicit representations, including point clouds (Cai
    et al., [2020](#bib.bib22)) or voxel grids (Michalkiewicz et al., [2019](#bib.bib112);
    Mescheder et al., [2019](#bib.bib111); Dinh et al., [2014](#bib.bib45); Gulrajani
    et al., [2017](#bib.bib58); Li et al., [2017](#bib.bib103); Litany et al., [2018](#bib.bib106);
    Lorensen and Cline, [1987](#bib.bib109); Nijkamp et al., [2020](#bib.bib130);
    LeCun et al., [2010](#bib.bib97); Genova et al., [2019](#bib.bib54); Lunz et al.,
    [2020](#bib.bib110)), and implicit neural functions, such as occupancy field and
    signed distance function (SDF). Wu et al. adopted the architecture of a generative
    adversarial network to generate the 3D voxel grids relying on capturing the probability
    distribution of 3D shapes  (Wu et al., [2016](#bib.bib170)) (Fig.  [9](#S3.F9
    "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")a). Many approaches already achieve the
    outstanding outcome in a more fine-grained shape  (Wu et al., [2019](#bib.bib172);
    Li et al., [2020](#bib.bib102); Wu et al., [2020](#bib.bib171)). However, the
    general disadvantage of this approach for voxel grids is that fine-grained voxels
    cannot be accomplished due to the cubic increase in computational cost. PLATONICGAN
    and IG GAN  (Henzler et al., [2019](#bib.bib65); Lunz et al., [2020](#bib.bib110))
    also generate the 3D voxel grids models from the unstructured 2D image data with
    GAN. While another 3D representation, point cloud, is the output as raw data through
    depth scanning. For the various problems in generating point clouds with GAN,
    numbers of researchers introduce different approaches, ranging from the converge
     (Achlioptas et al., [2018](#bib.bib3)), utilizing the local contexts  (Shu et al.,
    [2019](#bib.bib158); Valsesia et al., [2019](#bib.bib165); Hui et al., [2020](#bib.bib71);
    Arshad and Beksi, [2020](#bib.bib9)), as well as the high memory consumption  (Ramasinghe
    et al., [2020](#bib.bib141)). The mesh representation is usually utilized as the
    target object in the 3D modeling software. Nevertheless the popularity in the
    design discipline and traditional computer graphics, the difficulties lie in applying
    the deep generation models to the mesh. There are two main reasons. Firstly, non-Euclidean
    data could not directly apply to the convolutional neural networks (CNN). Secondly,
    the difficulty of connecting the mesh vertices to composite the shape is high
     (Shi et al., [2022](#bib.bib157)). Get3D  (Gao et al., [2022](#bib.bib51)) enables
    the high-quality geometry and texture from the 2D image collections by incorporating
    the differentiable surface modeling and differentiable rendering to GANs.'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 'GANs 被开发为一种受控的 3D 生成方法，可以从图像数据中生成不同的显式表示，包括点云 (Cai et al., [2020](#bib.bib22))
    或体素网格 (Michalkiewicz et al., [2019](#bib.bib112); Mescheder et al., [2019](#bib.bib111);
    Dinh et al., [2014](#bib.bib45); Gulrajani et al., [2017](#bib.bib58); Li et al.,
    [2017](#bib.bib103); Litany et al., [2018](#bib.bib106); Lorensen and Cline, [1987](#bib.bib109);
    Nijkamp et al., [2020](#bib.bib130); LeCun et al., [2010](#bib.bib97); Genova
    et al., [2019](#bib.bib54); Lunz et al., [2020](#bib.bib110))，以及隐式神经函数，如占据场和带符号距离函数
    (SDF)。Wu et al. 采用生成对抗网络的架构来生成 3D 体素网格，依赖于捕捉 3D 形状的概率分布 (Wu et al., [2016](#bib.bib170))
    (图 [9](#S3.F9 "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")a)。许多方法已经在更精细的形状上取得了卓越的成果
    (Wu et al., [2019](#bib.bib172); Li et al., [2020](#bib.bib102); Wu et al., [2020](#bib.bib171))。然而，对于体素网格，这种方法的一般缺点是由于计算成本的立方增长，精细体素无法实现。PLATONICGAN
    和 IG GAN (Henzler et al., [2019](#bib.bib65); Lunz et al., [2020](#bib.bib110))
    也从非结构化的 2D 图像数据中生成 3D 体素网格模型。另一方面，另一种 3D 表示方式是通过深度扫描输出的原始数据点云。针对生成点云时遇到的各种问题，许多研究人员提出了不同的方法，包括收敛
    (Achlioptas et al., [2018](#bib.bib3))、利用局部上下文 (Shu et al., [2019](#bib.bib158);
    Valsesia et al., [2019](#bib.bib165); Hui et al., [2020](#bib.bib71); Arshad and
    Beksi, [2020](#bib.bib9))，以及高内存消耗 (Ramasinghe et al., [2020](#bib.bib141))。网格表示通常被用作
    3D 建模软件中的目标对象。然而，尽管在设计学科和传统计算机图形学中很受欢迎，将深度生成模型应用于网格的困难在于两个主要原因。首先，非欧几里得数据不能直接应用于卷积神经网络
    (CNN)。其次，连接网格顶点以组成形状的难度较高 (Shi et al., [2022](#bib.bib157))。Get3D (Gao et al.,
    [2022](#bib.bib51)) 通过将可微表面建模和可微渲染与 GANs 结合，能够从 2D 图像集合中生成高质量的几何体和纹理。'
- en: 3.2.2\. 3D Solid Form Generation
  id: totrans-176
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.2\. 3D 实体形状生成
- en: '| Reference | Category | Obejctive | Methodology | 3D Representations | Generative
    Models |'
  id: totrans-177
  prefs: []
  type: TYPE_TB
  zh: '| 参考 | 类别 | 目标 | 方法论 | 3D 表示 | 生成模型 |'
- en: '| (Del Campo et al., [2019](#bib.bib39)) | 2D to 3D | Test AI agency in design
    | Utilizing Style Transfer to train two datasets Baroque and Modern images as
    a basis to form a 3D model | - | - |'
  id: totrans-178
  prefs: []
  type: TYPE_TB
  zh: '| (Del Campo 等, [2019](#bib.bib39)) | 2D 到 3D | 测试 AI 代理在设计中的应用 | 利用风格迁移训练两个数据集：巴洛克和现代图像，作为形成
    3D 模型的基础 | - | - |'
- en: '| (Özel, [2020](#bib.bib134)) | 2D to 3D | HCI in urban design | Utilizing
    Style Transfer to generate different stylized images and generate 3D geometry
    through procedural modeling | - | - |'
  id: totrans-179
  prefs: []
  type: TYPE_TB
  zh: '| (Özel, [2020](#bib.bib134)) | 2D 到 3D | 城市设计中的 HCI | 利用风格迁移生成不同风格的图像，通过程序建模生成
    3D 几何形状 | - | - |'
- en: '| (Ren and Zheng, [2020](#bib.bib144)) | 2D to 3D | Test AI agency in design
    | Utilizing Style Transfer to replace pixels with voxelization units to generate
    3D forms | - | - |'
  id: totrans-180
  prefs: []
  type: TYPE_TB
  zh: '| (Ren 和 Zheng, [2020](#bib.bib144)) | 2D 到 3D | 测试 AI 代理在设计中的应用 | 利用风格迁移用体素化单元替换像素以生成
    3D 形式 | - | - |'
- en: '| (Liu et al., [2021](#bib.bib107)) | 2D to 3D | Toolkits for 3D generation
    | Utilizing Style Transfer to assist the generation of 3D structure from 2D images
    | - | - |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
  zh: '| (Liu 等, [2021](#bib.bib107)) | 2D 到 3D | 3D 生成工具包 | 利用风格迁移辅助从 2D 图像生成 3D
    结构 | - | - |'
- en: '| (Yu, [2020](#bib.bib176)) | 2D to 3D | Generate building massing | Utilizing
    pix2pixGAN to generate plan pattern and section pattern, then converted to 3D
    massing | - | - |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
  zh: '| (Yu, [2020](#bib.bib176)) | 2D 到 3D | 生成建筑体量 | 利用 pix2pixGAN 生成平面图模式和截面图模式，然后转换为
    3D 体量 | - | - |'
- en: '| (Di Carlo et al., [2022](#bib.bib43)) | 2D to 3D | Generate building massing
    | Utilizing pix2pixGAN to generate urban morphology to create building massing
    | - | - |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
  zh: '| (Di Carlo 等, [2022](#bib.bib43)) | 2D 到 3D | 生成建筑体量 | 利用 pix2pixGAN 生成城市形态以创建建筑体量
    | - | - |'
- en: '| (Zhang and Blasetti, [2020](#bib.bib183)) | 2D to 3D | Form finding to assist
    design | Slicing a 3D model and trained with different combinations of 2D styleGAN
    networks, and finally stitching into a 3D model | - | - |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
  zh: '| (Zhang 和 Blasetti, [2020](#bib.bib183)) | 2D 到 3D | 形式发现以辅助设计 | 切割 3D 模型并与不同组合的
    2D styleGAN 网络训练，最终拼接成 3D 模型 | - | - |'
- en: '| (Zhang, [2019](#bib.bib181)) | 2D to 3D | Form finding to assist design |
    3D model generation based on 2D plan and section using Style Transfer | - | -
    |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
  zh: '| (Zhang, [2019](#bib.bib181)) | 2D 到 3D | 形式发现以辅助设计 | 基于 2D 平面图和截面图生成 3D 模型，使用风格迁移
    | - | - |'
- en: '| (Zhang and Huang, [2021](#bib.bib184)) | 2D to 3D | Form finding to assist
    design | Combining the spatial sequence information to generate 3D form from 2D
    images through multi-level deep generative networks such as styleGAN | - | - |'
  id: totrans-186
  prefs: []
  type: TYPE_TB
  zh: '| (Zhang 和 Huang, [2021](#bib.bib184)) | 2D 到 3D | 形式发现以辅助设计 | 结合空间序列信息，通过多级深度生成网络如
    styleGAN 从 2D 图像生成 3D 形式 | - | - |'
- en: '| (Bank et al., [2022](#bib.bib14)) | 2D to 3D | Human and neural network interface
    | Utilizing 3D solid for training to map spatial semantics to a latent space assembled
    using point cloud representations | Point cloud | GAN |'
  id: totrans-187
  prefs: []
  type: TYPE_TB
  zh: '| (Bank 等, [2022](#bib.bib14)) | 2D 到 3D | 人类和神经网络接口 | 利用 3D 实体进行训练，将空间语义映射到使用点云表示组装的潜在空间
    | 点云 | GAN |'
- en: '| (Asmar and Sareen, [2020](#bib.bib10)) | 2D to 3D | Integrate latent space
    in design | GAN allows for navigation in the latent space to create digital designs
    using vector arithmetic and interpolation techniques, then converting resulting
    images to 3D voxel structures | Voxel grid | GAN |'
  id: totrans-188
  prefs: []
  type: TYPE_TB
  zh: '| (Asmar 和 Sareen, [2020](#bib.bib10)) | 2D 到 3D | 在设计中集成潜在空间 | GAN 允许在潜在空间中导航，使用向量运算和插值技术创建数字设计，然后将生成的图像转换为
    3D 体素结构 | 体素网格 | GAN |'
- en: '| (Huang et al., [2021](#bib.bib70)) | 2D to 3D | Recognize 2D pattern to 3D
    form | Utilizing Latent space rotation and perspective projection to generate
    3D model | Voxel grid | GAN |'
  id: totrans-189
  prefs: []
  type: TYPE_TB
  zh: '| (Huang 等, [2021](#bib.bib70)) | 2D 到 3D | 识别 2D 图案到 3D 形式 | 利用潜在空间旋转和透视投影生成
    3D 模型 | 体素网格 | GAN |'
- en: '| (Kim and Huang, [2022](#bib.bib89)) | 2D to 3D | Recognize 2D pattern to
    3D form | Utilizing Latent space rotation and perspective projection to generate
    3D model | Voxel grid | GAN |'
  id: totrans-190
  prefs: []
  type: TYPE_TB
  zh: '| (Kim 和 Huang, [2022](#bib.bib89)) | 2D 到 3D | 识别 2D 图案到 3D 形式 | 利用潜在空间旋转和透视投影生成
    3D 模型 | 体素网格 | GAN |'
- en: '| (Çakmak, [2022](#bib.bib23)) | 3D Solid | Extend design cognition | Utilizing
    a GAN Model with a pair of encoder-decoder to process datasets and generate new
    3D models, resulting in different 3D representations like point cloud and mesh
    | Point cloud/Mesh | GAN |'
  id: totrans-191
  prefs: []
  type: TYPE_TB
  zh: '| (Çakmak, [2022](#bib.bib23)) | 3D 实体 | 扩展设计认知 | 利用带有一对编码器-解码器的 GAN 模型处理数据集并生成新的
    3D 模型，生成不同的 3D 表示，如点云和网格 | 点云/网格 | GAN |'
- en: '| (Veselỳ, [2022](#bib.bib166)) | 3D Solid | Generate building massing | Utilizing
    3D BAG dataset as a basis to train urban morphology data to generate 3D building
    massing | - | GAN |'
  id: totrans-192
  prefs: []
  type: TYPE_TB
  zh: '| (Veselỳ, [2022](#bib.bib166)) | 3D Solid | 生成建筑体量 | 利用3D BAG数据集作为基础来训练城市形态数据，以生成3D建筑体量
    | - | GAN |'
- en: '| (de Miguel et al., [2019](#bib.bib37)) | 3D Solid | Generation, manipulation
    and form finding of structural typologies | Utilizing VAE to learn continuous
    latent space to generate new geometries | Voxel grid | VAE |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
  zh: '| (de Miguel et al., [2019](#bib.bib37)) | 3D Solid | 结构类型的生成、操控和形式发现 | 利用VAE学习连续潜在空间以生成新几何形状
    | 体素网格 | VAE |'
- en: '| (Kahraman et al., [2021](#bib.bib83)) | 3D Solid | Solve design problems
    incorporating deep learning | Utilizing VAE to manipulate objects according to
    the different criteria selected | Voxel grid | VAE |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
  zh: '| (Kahraman et al., [2021](#bib.bib83)) | 3D Solid | 解决结合深度学习的设计问题 | 利用VAE根据选择的不同标准操控物体
    | 体素网格 | VAE |'
- en: '| (Sebestyen et al., [2021](#bib.bib154)) | 3D Solid | New way to design parametric
    models | Utilizing VAE to encode and decode geometries through dimensionality
    manipulation | Voxel grid | VAE |'
  id: totrans-195
  prefs: []
  type: TYPE_TB
  zh: '| (Sebestyen et al., [2021](#bib.bib154)) | 3D Solid | 设计参数模型的新方法 | 利用VAE通过维度操控对几何形状进行编码和解码
    | 体素网格 | VAE |'
- en: '| (Zhang, [2020](#bib.bib182)) | NLP-3D Solid | Language assisted design |
    Utilizing language model to predict housing plan by training large dataset relating
    texts to forms | - | - |'
  id: totrans-196
  prefs: []
  type: TYPE_TB
  zh: '| (Zhang, [2020](#bib.bib182)) | NLP-3D Solid | 语言辅助设计 | 利用语言模型通过训练大型数据集将文本与形状相关联来预测住房平面图
    | - | - |'
- en: '| (Guida, [2023](#bib.bib57)) | NLP-3D Solid | Language assisted design in
    HCI | Utilizing diffusion models to generate 3D forms from text input | - | Diffusion
    model |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
  zh: '| (Guida, [2023](#bib.bib57)) | NLP-3D Solid | 人机交互中的语言辅助设计 | 利用扩散模型从文本输入生成3D形状
    | - | 扩散模型 |'
- en: 'Table 2. The related works in the architecture fields. The applications in
    the architectural field are sorted into different categories in this table, including
    2D to 3D transposition, 3D solid generation and NLP based 3D form generation.
    The category means the generation methodology: ‘2D to 3D’ means the 3D form generation
    is based on 2D images; ‘3D Solid’ means generating 3D form directly with DGMs
    including GAN, VAE, and diffusion model. ‘NLP’ means the 3D form generation process
    includes text input to assist the output control. ‘3D representations’ in architecture
    encompass explicit point cloud, voxel grid, and mesh. The Objective column explains
    the directions and objectives the research aims to address. The methodology column
    gives an overview to what kind of workflow the generation process proposed. This
    table compares the research in the architectural field.'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
  zh: 表2. 建筑领域的相关工作。此表格将建筑领域的应用分为不同类别，包括2D到3D的转化、3D固体生成和基于NLP的3D形式生成。类别指生成方法论：‘2D到3D’指的是3D形式生成基于2D图像；‘3D
    Solid’指的是直接使用DGMs（包括GAN、VAE和扩散模型）生成3D形式。‘NLP’指的是3D形式生成过程包括文本输入以辅助输出控制。建筑中的‘3D表示’包括明确的点云、体素网格和网格。目标列解释了研究旨在解决的方向和目标。方法论列概述了所提出的生成过程的工作流程。此表格比较了建筑领域的研究。
- en: '![Refer to caption](img/a1d7167dd8f01e6bd24b573071e6e655.png)'
  id: totrans-199
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/a1d7167dd8f01e6bd24b573071e6e655.png)'
- en: (a) Results for voxel grids from  (Veselỳ, [2022](#bib.bib166)).
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
  zh: (a)  (Veselỳ, [2022](#bib.bib166))的体素网格结果。
- en: '![Refer to caption](img/3485afb5b8e15909790ed942c84e8f93.png)'
  id: totrans-201
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/3485afb5b8e15909790ed942c84e8f93.png)'
- en: (b) 3D GAN housing utilize 3D GAN to generate housing with 3D assets as input
    dataset.
  id: totrans-202
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 3D GAN住房利用3D GAN生成具有3D资产作为输入数据集的住房。
- en: '![Refer to caption](img/b2d2c881bc5cd58528fd5f4fede6503b.png)'
  id: totrans-203
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b2d2c881bc5cd58528fd5f4fede6503b.png)'
- en: (c) The overview methodology of  (Çakmak, [2022](#bib.bib23)).
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: (c)  (Çakmak, [2022](#bib.bib23))的概述方法。
- en: Figure 11. Three examples of applying GANs for architectural designs in 3D solod
    form generation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: 图11. 应用GAN进行建筑设计的三个例子，用于3D固体形式生成。
- en: Currently, the architectural design utilizing GANs in 3D solid form generation
    is all based on explicit representations including voxel grids, point clouds,
    and meshes. 3D solid form generation refers to a direct 3D data acquisition, evaluation,
    transformation, and rearrangement using deep generative models  (Steinfeld et al.,
    [2019](#bib.bib160)).
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
  zh: 目前，利用GAN在3D固体形式生成中的建筑设计都基于明确的表示，包括体素网格、点云和网格。3D固体形式生成指的是直接获取、评估、转化和重新排列3D数据，使用深度生成模型（Steinfeld等，[2019](#bib.bib160)）。
- en: 'Meanwhile, with improved algorithms, GANs can recognize 3D representations
    such as mesh and point cloud, which shifts the paradigm of generation from 2D
    to 3D by a direct route using 3D point cloud semantic segmentation in 3D spaces.
    Immanuel Koh uses a 3D GAN network to train a large dataset of both exterior and
    interior Singapore high-rise buildings to generate innovative housing typologies
    automatically  (Koh, [2022](#bib.bib92)) (See Fig.  [11(b)](#S3.F11.sf2 "In Figure
    11 ‣ 3.2.2\. 3D Solid Form Generation ‣ 3.2\. 3D Solid Form Generation with the
    GANs ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")). It tested the agencies of generative
    spaces using deep neural networks, which inherit the configurations of architectural
    forms by extracting building block arrangements. Moreover, the connection of 3D
    GANs with Houdini can expand the algorithm to integrate with the 3D form generation.
    For instance, Joris Puteneers uses 3D GAN as a form-finding tool in a project
    named ugly & stupid ^(18)^(18)18Source: [https://putteneersjoris.xyz/projects/Ugly%20Stupid%20Honest/ugly_stupid_honest.html](https://putteneersjoris.xyz/projects/Ugly%20Stupid%20Honest/ugly_stupid_honest.html),
    which tested the agency of algorithms in creating artifacts based on image recognition.
    Besides, Cakmak added an encoder-decoder network in GAN to process the datasets
    and generate new 3D models, which are then represented in different alternative
    formats like point cloud and mesh (Çakmak, [2022](#bib.bib23)) (See Fig.  [11(c)](#S3.F11.sf3
    "In Figure 11 ‣ 3.2.2\. 3D Solid Form Generation ‣ 3.2\. 3D Solid Form Generation
    with the GANs ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")). This also meant extending design cognition
    by adding AI as an agent in the design thinking process. A noteworthy study has
    been conducted on geometry extraction within urban environments using 3D GANs
     (Veselỳ, [2022](#bib.bib166)) (See Fig.  [11(a)](#S3.F11.sf1 "In Figure 11 ‣
    3.2.2\. 3D Solid Form Generation ‣ 3.2\. 3D Solid Form Generation with the GANs
    ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")). This enables generated 3D dataset automatically through 3D
    BAG  ^(19)^(19)19An overview of 3D BAG, source:  [https://docs.3dbag.nl/en/](https://docs.3dbag.nl/en/).
    The 3D BAG dataset includes different levels of 3D details, which can be read
    and manipulated by GAN. The model was trained based on three layers of information:
    building geometry, site context, and area of interest. The information is stored
    in raster data for 3D representation of voxel grids in deep learning.'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '与此同时，通过改进的算法，GANs 可以识别诸如网格和点云等 3D 表示，这通过直接使用 3D 点云语义分割在 3D 空间中将生成范式从 2D 转向
    3D。Immanuel Koh 使用一个 3D GAN 网络来训练一个包含新加坡高层建筑外部和内部的大型数据集，以自动生成创新的住房类型  (Koh, [2022](#bib.bib92))
    (见图 [11(b)](#S3.F11.sf2 "在图 11 ‣ 3.2.2\. 3D 实体生成 ‣ 3.2\. 使用 GANs 生成 3D 实体 ‣ 3\.
    生成的 3D 建筑：一个范式转变 ‣ 朝向计算建筑的自由：关于在元宇宙中生成虚拟建筑的深度学习的综合调查"))。它测试了生成空间的代理，通过提取建筑块排列来继承建筑形式的配置。此外，3D
    GANs 与 Houdini 的连接可以扩展算法以集成 3D 形状生成。例如，Joris Puteneers 在一个名为 ugly & stupid 的项目中使用
    3D GAN 作为形状发现工具  ^(18)^(18)18 来源: [https://putteneersjoris.xyz/projects/Ugly%20Stupid%20Honest/ugly_stupid_honest.html](https://putteneersjoris.xyz/projects/Ugly%20Stupid%20Honest/ugly_stupid_honest.html)，该项目测试了算法在基于图像识别创建人工制品方面的能力。此外，Cakmak
    在 GAN 中添加了一个编码解码网络来处理数据集并生成新的 3D 模型，这些模型随后以不同的替代格式呈现，如点云和网格 (Çakmak, [2022](#bib.bib23))
    (见图 [11(c)](#S3.F11.sf3 "在图 11 ‣ 3.2.2\. 3D 实体生成 ‣ 3.2\. 使用 GANs 生成 3D 实体 ‣ 3\.
    生成的 3D 建筑：一个范式转变 ‣ 朝向计算建筑的自由：关于在元宇宙中生成虚拟建筑的深度学习的综合调查"))。这也意味着通过将 AI 作为设计思维过程中的代理来扩展设计认知。对使用
    3D GANs 在城市环境中进行几何提取的研究非常值得注意  (Veselỳ, [2022](#bib.bib166)) (见图 [11(a)](#S3.F11.sf1
    "在图 11 ‣ 3.2.2\. 3D 实体生成 ‣ 3.2\. 使用 GANs 生成 3D 实体 ‣ 3\. 生成的 3D 建筑：一个范式转变 ‣ 朝向计算建筑的自由：关于在元宇宙中生成虚拟建筑的深度学习的综合调查"))。这使得通过
    3D BAG 自动生成 3D 数据集  ^(19)^(19)19 3D BAG 概述，来源: [https://docs.3dbag.nl/en/](https://docs.3dbag.nl/en/)。3D
    BAG 数据集包含不同级别的 3D 细节，这些细节可以被 GAN 读取和操作。该模型基于三层信息进行训练：建筑几何、现场背景和兴趣区域。这些信息以栅格数据形式存储，用于深度学习中的体素网格的
    3D 表示。'
- en: This method of matching training data sets with parameters associated with spatial
    design goals has been widely used in architectural design solutions. Such applications,
    in which GANs as the generation framework, can often design solutions with explicit
    design goals.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: 将训练数据集与空间设计目标相关的参数匹配的方法已被广泛应用于建筑设计解决方案中。这种应用中，GANs作为生成框架，通常能够设计出具有明确设计目标的解决方案。
- en: 3.2.3\. Limitations
  id: totrans-209
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.2.3\. 限制
- en: Such methods discussed have several limitations.
  id: totrans-210
  prefs: []
  type: TYPE_NORMAL
  zh: 所讨论的方法存在若干限制。
- en: Fewer variations in style. The performance of GANs frameworks heavily depends
    on the quality and nature of the input data, resulting in limited variations in
    style. In the context of 2D to 3D form finding, a significant proportion of studies
    have relied on styleGAN as the basis for form generation, which tends to produce
    outputs that mimic the style of the “style image” without adjustable options.
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
  zh: 风格变化较少。GANs框架的性能严重依赖于输入数据的质量和特性，导致风格的变化有限。在2D到3D形态生成的背景下，大多数研究依赖于styleGAN作为形态生成的基础，这通常产生模仿“风格图像”的输出而没有可调选项。
- en: Singleness of category. Similarly, since one training process can only process
    one single category of the dataset, the output is constrained to the category
    for design purpose. For example, the 3D-GAN-Housing project has a certain degree
    of repetition in high-rise building design due to the limitation of the trained
    structure(Koh, [2022](#bib.bib92)). Since the dataset is limited, the blocks always
    follow the same evolutionary rule, which lowers the variation in style and is
    limited to specific categories. This can be adapted to modular housing design,
    however, not suitable for virtual space generation.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: 类别单一。同样，由于一个训练过程只能处理数据集中的单一类别，输出受限于设计目的的类别。例如，3D-GAN-Housing项目在高层建筑设计中有一定程度的重复，因为训练结构的限制（Koh,
    [2022](#bib.bib92)）。由于数据集有限，这些块总是遵循相同的进化规则，从而降低了风格的变化，且仅限于特定类别。这可以适应于模块化住房设计，但不适用于虚拟空间生成。
- en: Unpredictability in design. The image-to-image translation of GANs is characterized
    by unpredictability. The training process of these algorithms is time-consuming
    and requires substantial computing resources. Also, the generative logic underlying
    these processes is that designers can only evaluate their effects once they observe
    the final output. The latent vector undergoes arbitrary modifications in different
    epochs, adding to the complexity and unpredictability of the output.
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: 设计中的不可预测性。GANs的图像到图像翻译具有不可预测性。这些算法的训练过程耗时且需要大量计算资源。此外，这些过程背后的生成逻辑是，设计师只能在观察到最终输出后才能评估其效果。潜在向量在不同的周期中经历任意修改，增加了输出的复杂性和不可预测性。
- en: Topological inconsistency. Firstly, when the 3D forms are constructed solely
    from 2D images, these forms will inevitably carry traces of the slicing process
    leading to a loss of interior details and the overall consistency of the structure.
    Secondly, using a constrained 3D segmentation algorithm poses a significant challenge
    in generating consistent forms, leading to topological inconsistencies in the
    form of gaps and defects in the final output. For instance, applying this method
    to the reconstruction of furniture reveals inconsistencies in the generated 3D
    shapes, as the algorithm needed to be pre-trained on the specific type of objects(Wu
    et al., [2016](#bib.bib170)).
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
  zh: 拓扑不一致。首先，当3D形态仅从2D图像构建时，这些形态不可避免地会带有切片过程的痕迹，导致内部细节和结构的整体一致性丧失。其次，使用受限的3D分割算法在生成一致的形态时面临重大挑战，导致最终输出中出现间隙和缺陷的拓扑不一致。例如，将此方法应用于家具重建时，生成的3D形状存在不一致，因为该算法需要在特定类型的对象上进行预训练（Wu
    et al., [2016](#bib.bib170)）。
- en: Computing requirements of 3D data. Compared to other models, GAN models can
    typically produce 3D structures that are more detailed and realistic, but they
    are also more unstable and challenging to train. However, converting data from
    2D to 3D usually takes a long time.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: 3D数据的计算要求。与其他模型相比，GAN模型通常可以生成更详细和逼真的3D结构，但它们也更不稳定，训练起来更具挑战性。然而，将数据从2D转换为3D通常需要较长时间。
- en: 3.3\. Architectural Form from Latent Space with Variational Autoencoder
  id: totrans-216
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.3\. 通过变分自编码器从潜在空间生成建筑形式
- en: 3.3.1\. 3D Shape Generation with VAEs
  id: totrans-217
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.1\. 使用VAEs生成3D形状
- en: 'Consequently, aforementioned GAN approaches, to improve the instability in
    the GAN, Brock et al. introduced a variational auto-encoder to process 3D voxel
    grids  (Brock et al., [2016](#bib.bib21)). It utilizes a pair of encoder-decoder:
    the encoder consists of four 3D convolutional layers to map the information to
    the latent vectors, and the decoder transforms the latent vectors into the 3D
    voxel. As aforementioned, the later work proposes improvements in blurry voxels
    for smooth rounded edges (Mittal et al., [2022](#bib.bib114)). For the point clouds
    as representation, although the research progress is overcoming the difficulties,
    the instability of GAN has derived the invention of the other types of generative
    model based on the encoder in the 3D generation, the VAE and adversarial auto-encoder
    model (AAE)  (Zamorski et al., [2020](#bib.bib178)). The difficulties in generating
    meshes with VAEs are similar to GANs. For the complexity of processing topology,
    The parameterization of mesh called multi-chart approaches  (Ben-Hamu et al.,
    [2018](#bib.bib19)) can handle this irregular structure of meshes. Many approaches
    work on simplifying the process using this method (Gao et al., [2019](#bib.bib52),
    [2021](#bib.bib53); Nash et al., [2020](#bib.bib121)). TM-Net proposes an improved
    approach that defines a textured space on the template cube mesh based on the
    SDM-Net (Gao et al., [2021](#bib.bib53)).'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: 因此，前述的 GAN 方法，为了改善 GAN 的不稳定性，Brock 等人引入了变分自编码器来处理 3D 体素网格（Brock et al., [2016](#bib.bib21)）。它利用一对编码器-解码器：编码器由四个
    3D 卷积层组成，将信息映射到潜在向量，解码器则将潜在向量转换为 3D 体素。如前所述，后续工作提出了在模糊体素上进行平滑圆形边缘的改进（Mittal et
    al., [2022](#bib.bib114)）。对于点云表示，尽管研究进展在克服困难，但 GAN 的不稳定性催生了基于编码器的其他类型的生成模型，如 3D
    生成中的 VAE 和对抗自编码器模型（AAE）（Zamorski et al., [2020](#bib.bib178)）。使用 VAE 生成网格的困难与
    GAN 相似。对于处理拓扑的复杂性，称为多图表方法的网格参数化（Ben-Hamu et al., [2018](#bib.bib19)）可以处理这种不规则的网格结构。许多方法通过使用这种方法来简化过程（Gao
    et al., [2019](#bib.bib52), [2021](#bib.bib53); Nash et al., [2020](#bib.bib121)）。TM-Net
    提出了一个改进的方法，该方法在模板立方体网格上基于 SDM-Net 定义了一个纹理空间（Gao et al., [2021](#bib.bib53)）。
- en: 3.3.2\. Latent Space
  id: totrans-219
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.2\. 潜在空间
- en: For research on architectural generation, VAEs extract information through the
    latent space with a pair of encoder-decoder. As aforementioned, the limitations
    in producing scientific and accurate design results with GANs derive from the
    framework itself. Furthermore, most existing generated architecture with DL aided
    have focused on 2D drawings. Consequently, there is a gap in these approaches
    regarding their ability to extract and utilize essential low-level spatial semantic
    and structural features to understand design intent and factors. Azizi et al.
    (Azizi et al., [2020](#bib.bib12)) proposed VAE to enable encoding and decoding
    information about the spatial utilization of people’s movements and activities
    in space to generate reliable and plausible architectural compositions.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: 对于建筑生成的研究，变分自编码器（VAEs）通过一对编码器-解码器在潜在空间中提取信息。如前所述，使用生成对抗网络（GANs）在生产科学和准确设计结果时的局限性源于框架本身。此外，现有的大多数基于深度学习（DL）的生成建筑物关注于二维图纸。因此，这些方法在提取和利用基本的低级空间语义和结构特征以理解设计意图和因素方面存在差距。Azizi
    等人（Azizi et al., [2020](#bib.bib12)）提出了 VAE，以编码和解码有关人们在空间中活动和动作的空间利用信息，从而生成可靠且可信的建筑构图。
- en: 3.3.3\. Architectural information extraction from latent space
  id: totrans-221
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.3.3\. 从潜在空间中提取建筑信息
- en: '![Refer to caption](img/85d6ebd2884081ad888b8efa1652c024.png)'
  id: totrans-222
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/85d6ebd2884081ad888b8efa1652c024.png)'
- en: (a) The framework of VAE processing 3D-structure data in Deep Form Finding  (de Miguel
    et al., [2019](#bib.bib37)).
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: (a) VAE 在深度形式发现中的 3D 结构数据处理框架（de Miguel et al., [2019](#bib.bib37)）。
- en: '![Refer to caption](img/13a4648050b0a1f0ac7975c9f0e032a5.png)'
  id: totrans-224
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/13a4648050b0a1f0ac7975c9f0e032a5.png)'
- en: (b) An overview methodology in  (Azizi et al., [2020](#bib.bib12)).
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 在（Azizi et al., [2020](#bib.bib12)）中的方法概述。
- en: Figure 12. Two pioneering architectural designs utilized VAE.
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: 图 12. 两个开创性的建筑设计利用了 VAE。
- en: 'In pioneering research of VAE integrated structural generation project Deep
    Form Finding (de Miguel et al., [2019](#bib.bib37)), the researchers used labeled
    connectivity vectors extracted from ”3D-canvas” as data representation in rectangular
    3D cubes since the cubes are convenient to be used to illustrate the 3D structure
    information of any forms (See Fig.  [12(a)](#S3.F12.sf1 "In Figure 12 ‣ 3.3.3\.
    Architectural information extraction from latent space ‣ 3.3\. Architectural Form
    from Latent Space with Variational Autoencoder ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    The outcome achieved 3D voxelized wireframes of architectural forms through VAE
    models, where the encoder processes the input data and maps it to a lower-dimensional
    latent space, while the decoder takes the latent representation and maps it back
    to the original input space. The VAE model can learn continuous latent distributions
    of the input data and output hybrids of different forms with different style strengths.
    Since researchers found that the 3D GAN is hard to learn 3D information, VAE was
    considered to have higher potential and has been used to test the capabilities
    of deep neural networks in manipulating 3D geometries in the architectural field.
    Another proof of concept application is the design of a 3D voxel chair using multi-object
    VAE (Kahraman et al., [2021](#bib.bib83)). This application aims to generate different
    types of chairs based on pre-defined criteria, ranging from leisure to work. VAE
    has also been used to morph multiple simple objects such as cylinders, cubes,
    and spheres into new shapes within a given composition range (Sebestyen et al.,
    [2021](#bib.bib154)). From the above application, we can see that although VAE
    is a well-developed neural network, the usage of complex space generation in architecture
    is still very limited. While another approach has targeted training by examining
    the floor plan of the building (Azizi et al., [2020](#bib.bib12)), which is not
    associated with the construction logic of the virtual space, the approach contains
    the consideration of human factors involved in the HCI methodology. The floor
    plan is a potential representation that encodes multiple features. Autoencoders
    represent the graph as a vector in continuous space. The attributed graph as the
    intermediate representation encodes spatial semantics, structural information,
    and crowd behavioral features (See Fig.  [12(b)](#S3.F12.sf2 "In Figure 12 ‣ 3.3.3\.
    Architectural information extraction from latent space ‣ 3.3\. Architectural Form
    from Latent Space with Variational Autoencoder ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: 在开创性的VAE集成结构生成项目Deep Form Finding（de Miguel等，[2019](#bib.bib37)）中，研究人员使用从“3D-canvas”中提取的标记连通向量作为数据表示，这些向量被嵌入到矩形3D立方体中，因为立方体方便用于展示任何形式的3D结构信息（见图
    [12(a)](#S3.F12.sf1 "在图12 ‣ 3.3.3. 从潜在空间提取建筑信息 ‣ 3.3. 使用变分自编码器的建筑形式 ‣ 3. 生成的3D建筑：一种范式转变
    ‣ 朝向自由计算建筑：关于在元宇宙中生成虚拟建筑的深度学习综合调查")）。最终成果通过VAE模型实现了建筑形式的3D体素化线框图，其中编码器处理输入数据并将其映射到低维潜在空间，而解码器则将潜在表示映射回原始输入空间。VAE模型可以学习输入数据的连续潜在分布，并输出具有不同风格强度的不同形式的混合体。由于研究人员发现3D
    GAN难以学习3D信息，VAE被认为具有更高的潜力，并用于测试深度神经网络在建筑领域操作3D几何体的能力。另一个概念验证应用是使用多对象VAE设计3D体素椅子（Kahraman等，[2021](#bib.bib83)）。该应用旨在根据预定义的标准生成不同类型的椅子，从休闲到工作。VAE还被用于将多个简单对象，如圆柱体、立方体和球体，形变为新的形状（Sebestyen等，[2021](#bib.bib154)）。从上述应用中，我们可以看到，尽管VAE是一个成熟的神经网络，但在建筑中的复杂空间生成的使用仍然非常有限。另一种方法则通过检查建筑的平面图（Azizi等，[2020](#bib.bib12)）进行训练，这与虚拟空间的构建逻辑无关，但这种方法考虑了HCI方法学中的人因因素。平面图是一种潜在的表示，编码了多个特征。自编码器将图表示为连续空间中的一个向量。作为中间表示的赋值图编码了空间语义、结构信息和人群行为特征（见图
    [12(b)](#S3.F12.sf2 "在图12 ‣ 3.3.3. 从潜在空间提取建筑信息 ‣ 3.3. 使用变分自编码器的建筑形式 ‣ 3. 生成的3D建筑：一种范式转变
    ‣ 朝向自由计算建筑：关于在元宇宙中生成虚拟建筑的深度学习综合调查")）。
- en: VAEs utilize pointwise loss to find a probability density by explicit representations
    to obtain an optimal solution by minimizing a lower bound on the log-likelihood
    function, which results in accurate generation results but lower resolution. GANs
    learn to generate from training distributions through playing zero-sum-game, resulting
    in uncertain generation results but can ensure high-quality data input. This results
    in different applications in the architectural field. For example, the applications
    in GANs are typically used for testing the agencies of AI, providing conceptual
    design options and approaching the democratization of design. While VAEs are always
    being tested in the form-finding process, to generate different design options
    available for different criteria and scenarios. However, most research incorporating
    either GANs or VAEs in design only provides a general approach to visual aesthetics
    instead of the design solutions on spatial functions and structures (Regenwetter
    et al., [2022](#bib.bib143)).
  id: totrans-228
  prefs: []
  type: TYPE_NORMAL
  zh: VAEs利用点对点损失通过显式表示找到概率密度，以最小化对数似然函数的下界来获得最优解，这导致生成结果准确但分辨率较低。GANs通过玩零和游戏来从训练分布中学习生成，这导致生成结果不确定但可以确保高质量的数据输入。这在建筑领域中产生了不同的应用。例如，GANs的应用通常用于测试AI的能力，提供概念设计选项，并接近设计的民主化。而VAEs则总是用于形式发现过程，以生成不同的设计选项，适用于不同的标准和场景。然而，大多数将GANs或VAEs融入设计中的研究仅提供了一般的视觉美学方法，而不是针对空间功能和结构的设计解决方案（Regenwetter等，
    [2022](#bib.bib143)）。
- en: 3.4\. 3D-Aware Image Synthesis
  id: totrans-229
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.4\. 3D 生成图像
- en: '| Method Names | Publication & Year | 3D Repre- sentations | Single/multiple-view
    | Geometry | Editability | Controllability | Highlight |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 方法名称 | 发表 & 年份 | 3D 表示 | 单/多视角 | 几何 | 可编辑性 | 可控性 | 突出 |'
- en: '| Camera | Object |'
  id: totrans-231
  prefs: []
  type: TYPE_TB
  zh: '| 相机 | 对象 |'
- en: '| NeRF  (Gu et al., [2021](#bib.bib56)) | CVPR 2019 | Neural field | multiple
    | ✓ | - | ✓ | ✓relighting | 3D Novel View Synthesis |'
  id: totrans-232
  prefs: []
  type: TYPE_TB
  zh: '| NeRF  (顾等， [2021](#bib.bib56)) | CVPR 2019 | 神经场 | 多视角 | ✓ | - | ✓ | ✓重光
    | 3D新视角合成 |'
- en: '| HoloGAN  (Nguyen-Phuoc et al., [2019](#bib.bib126)) | CVPR 2019 | Voxel grid
    | single | - | - | ✓ | - | - |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| HoloGAN  (阮富国等， [2019](#bib.bib126)) | CVPR 2019 | 体素网格 | 单视角 | - | - | ✓
    | - | - |'
- en: '| Pi-GAN  (Chan et al., [2021](#bib.bib29)) | CVPR 2021 | Neural field | single
    | ✓ | - | position | - | - |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| Pi-GAN  (陈等， [2021](#bib.bib29)) | CVPR 2021 | 神经场 | 单视角 | ✓ | - | 位置 | -
    | - |'
- en: '| Giraffe  (Niemeyer and Geiger, [2021](#bib.bib129)) | CVPR 2021 | Neural
    field | single | - | ✓ | ✓ | ✓ | - |'
  id: totrans-235
  prefs: []
  type: TYPE_TB
  zh: '| Giraffe  (尼梅耶和盖格， [2021](#bib.bib129)) | CVPR 2021 | 神经场 | 单视角 | - | ✓ |
    ✓ | ✓ | - |'
- en: '| StyleSDF  (Or-El et al., [2022](#bib.bib132)) | CVPR 2022 | Neural field
    | single | ✓ | - | ✓ | - | - |'
  id: totrans-236
  prefs: []
  type: TYPE_TB
  zh: '| StyleSDF  (奥尔-埃尔等， [2022](#bib.bib132)) | CVPR 2022 | 神经场 | 单视角 | ✓ | - |
    ✓ | - | - |'
- en: '| StyleNeRF  (Gu et al., [2021](#bib.bib56)) | arXiv 2021 | Neural field |
    single | ✓ | - | ✓ | - | - |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| StyleNeRF  (顾等， [2021](#bib.bib56)) | arXiv 2021 | 神经场 | 单视角 | ✓ | - | ✓
    | - | - |'
- en: '| DreamField  (Jain et al., [2022](#bib.bib77)) | CVPR 2022 | Neural field
    | multiple | ✓ |  | ✓ | - | CLIP: Text input |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| DreamField  (贾因等， [2022](#bib.bib77)) | CVPR 2022 | 神经场 | 多视角 | ✓ |  | ✓
    | - | CLIP: 文本输入 |'
- en: '| DreamFusion  (Poole et al., [2022](#bib.bib139)) | arXiv 2022 | Neural field
    | single | ✓ | ✓ | ✓ | ✓ | Text input |'
  id: totrans-239
  prefs: []
  type: TYPE_TB
  zh: '| DreamFusion  (普尔等， [2022](#bib.bib139)) | arXiv 2022 | 神经场 | 单视角 | ✓ | ✓
    | ✓ | ✓ | 文本输入 |'
- en: '| CLIP-NeRF  (Wang et al., [2022](#bib.bib167)) | CVPR 2022 | Neural field
    | single | - | - | ✓ | - | CLIP: Text input |'
  id: totrans-240
  prefs: []
  type: TYPE_TB
  zh: '| CLIP-NeRF  (王等， [2022](#bib.bib167)) | CVPR 2022 | 神经场 | 单视角 | - | - | ✓
    | - | CLIP: 文本输入 |'
- en: Table 3. An overview of 3D generative approaches of 3D-Aware Image Synthesis.
    Single/multiple represents the result generated by a single image adopting a sample
    of single-view or multiples image adopting multiple-view images. Geometry indicates
    whether this method allow to export to mesh. Editability indicates whether this
    generation process enable to edit, such as composing objects in scene. 3D-aware
    image synthesis perform by controllability including camera pose, position or
    object pose, location, relighting, and so on.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: 表 3. 3D 生成方法概述。单/多视角表示由单张图像生成的结果，采用单视角样本或由多张图像生成的结果，采用多视角图像。几何表示该方法是否允许导出为网格。可编辑性表示此生成过程是否支持编辑，如场景中的对象组合。3D
    生成图像的控制包括相机姿势、位置或对象姿势、位置、重光等。
- en: The 3D-aware image synthesis introduces expressive and efficient neural scene
    representations inspired by the 3D view synthesis like NeRF  (Xia and Xue, [2022](#bib.bib173)).
    It exhibits its capability of 3D view-consistent rendering and efficient and expressive
    presentation, as well as interactive edibility. It is super appropriate for the
    field of architecture to adopt 3D-aware synthesis since this method enables filling
    the gap lacking large-scale and high-quality 3D datasets in the field of DL-assisted
    architecture. 3D-aware synthesis only relies on supervising 2D images, which adopt
    differentiable neural rendering. This process involves the use of sophisticated
    techniques such as depth estimation and multi-view stereo by generating a 3D-aware
    image from 2D images. It exhibits its capability of 3D view-consistent rendering.
    Since without 3D representations for VAE-based models to render, most 3D-aware
    image syntheses utilize a GAN-based model sampling the latent vectors and decoder
    it to target a 3D representation. Although some methods implement the export of
    mesh models (Chan et al., [2021](#bib.bib29); Or-El et al., [2022](#bib.bib132);
    Gu et al., [2021](#bib.bib56)), however, according to this survey, existing architectural
    studies have not adopted this novel approach. We provide proof of its potential
    in virtual building generation.
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: 3D感知图像合成引入了富有表现力且高效的神经场景表示，灵感来自于3D视图合成技术，如NeRF (Xia 和 Xue, [2022](#bib.bib173))。它展示了3D视图一致性渲染、高效且富有表现力的呈现能力，以及交互式编辑性。由于这种方法能够弥补深度学习辅助建筑领域中缺乏大规模和高质量3D数据集的空白，因此非常适合建筑领域采用3D感知合成。3D感知合成仅依赖于对2D图像进行监督，采用可微分神经渲染。这个过程涉及使用复杂的技术，如深度估计和多视图立体，通过从2D图像生成3D感知图像来实现。它展示了3D视图一致性渲染的能力。由于VAE模型在渲染时没有3D表示，大多数3D感知图像合成方法利用基于GAN的模型对潜在向量进行采样，并解码为目标3D表示。尽管一些方法实现了网格模型的导出
    (Chan et al., [2021](#bib.bib29); Or-El et al., [2022](#bib.bib132); Gu et al.,
    [2021](#bib.bib56))，但根据本调查，现有建筑研究尚未采用这种新颖的方法。我们提供了其在虚拟建筑生成中的潜力的证明。
- en: 3.4.1\. 3D-aware image synthesis and its editablity
  id: totrans-243
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.1\. 3D感知图像合成及其可编辑性
- en: '3D-aware image synthesis has achieved tremendous progress made in the implicit
    representation of 3D models  (Chan et al., [2021](#bib.bib29); Jang and Agapito,
    [2021](#bib.bib79); Niemeyer and Geiger, [2021](#bib.bib129); Schwarz et al.,
    [2022](#bib.bib153)), in terms of two mainstream problems, resolution, and multi-view
    consistency. It utilizes image synthesis in a more controllable way to generate
    synthetic 3D scene representations by incorporating generative models. Later research
    has focused on generating 3D-aware images with the integration of GAN-based model
     (Nguyen-Phuoc et al., [2019](#bib.bib126); Chan et al., [2021](#bib.bib29)) (Fig.
     [9](#S3.F9 "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards
    Computational Architecture of Liberty: A Comprehensive Survey on Deep Learning
    for Generating Virtual Architecture in the Metaverse")c d f). For instance, HoloGAN
    (Fig.  [9](#S3.F9 "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT
    ‣ Towards Computational Architecture of Liberty: A Comprehensive Survey on Deep
    Learning for Generating Virtual Architecture in the Metaverse")c) can be trained
    end-to-end from unlabeled 2D images without pose labeling, 3D shape, or the same
    view(Nguyen-Phuoc et al., [2019](#bib.bib126)). It is the first unsupervised model
    for learning from natural images. Some latest studies  (Chan et al., [2021](#bib.bib29);
    Or-El et al., [2022](#bib.bib132); Gu et al., [2021](#bib.bib56)) prove their
    framework could predominantly improve two dominant problems for 3D-aware synthesis,
    high resolution and consistency of multiple views of synthetic images. The SDF-based
    method defines detailed 3D surfaces, leading to consistent body drawing. For instance,
    StyleSDF shows higher quality results in terms of visual and geometric quality
     (Or-El et al., [2022](#bib.bib132)) (See Fig. [9](#S3.F9 "Figure 9 ‣ 3\. Generated
    3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")d). Moreover, cutting-edge methods demonstrate that integrating
    3D-aware images with CLIP model(Jain et al., [2022](#bib.bib77); Wang et al.,
    [2022](#bib.bib167)) enables 3D geometry generation from natural language descriptions.
    While DreamFusion conducts a loss derived from the distillation of a 2D diffusion
    model instead of CLIP  (Poole et al., [2022](#bib.bib139)). The originality of
    Dream Field contains a pre-training process of 2D image-to-text models to optimize
    the underlying 3D representations. On the other hand, some progress in advanced
    leaps out of the solid box of pre-training 2D image-to-text models. DreamFusion
    incorporates the diffusion model as a strong image prior to this text-to-image
    pre-training, improving the efficiency of the generation. In addition, 3D-aware
    synthesis is applicable to incorporating other deep generative models, such as
    the very recent diffusion models. This advanced diffusion model will be specifically
    elucidated in the following subsection. The main goal of 3D-aware image synthesis
    is gaining the explicit camera pose in the task (Shi et al., [2022](#bib.bib157)).
    The controllability takes users to enter a more engaging and interactive environment.
    Some approaches also support the editability of the object pose. For instance,
    GIRAFFE allows to pan and rotate the obtained 3D objects in the scene  (Niemeyer
    and Geiger, [2021](#bib.bib129)). StyleNeRF also allows altering style attributes
    while supporting style blending, inversion, and semantic editing of the generated
    results  (Gu et al., [2021](#bib.bib56)). This editability provides various solutions
    from the perspective of the subdivision of generated target.'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
  zh: '3D感知图像合成在3D模型的隐式表示方面取得了巨大的进展（Chan等，[2021](#bib.bib29)；Jang和Agapito，[2021](#bib.bib79)；Niemeyer和Geiger，[2021](#bib.bib129)；Schwarz等，[2022](#bib.bib153)），涉及两个主流问题：分辨率和多视角一致性。它通过结合生成模型，以更可控的方式利用图像合成来生成合成的3D场景表示。随后，研究集中于基于GAN模型生成3D感知图像（Nguyen-Phuoc等，[2019](#bib.bib126)；Chan等，[2021](#bib.bib29)）（图[9](#S3.F9
    "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")c d f）。例如，HoloGAN（图[9](#S3.F9 "Figure 9
    ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")c）可以从未标记的2D图像中端到端地进行训练，而无需姿态标注、3D形状或相同视角（Nguyen-Phuoc等，[2019](#bib.bib126)）。这是第一个从自然图像中学习的无监督模型。一些最新的研究（Chan等，[2021](#bib.bib29)；Or-El等，[2022](#bib.bib132)；Gu等，[2021](#bib.bib56)）证明它们的框架可以显著改善3D感知合成中的两个主要问题：高分辨率和合成图像的多视角一致性。基于SDF的方法定义了详细的3D表面，从而实现了一致的体绘制。例如，StyleSDF在视觉和几何质量方面显示出更高的质量结果（Or-El等，[2022](#bib.bib132)）（见图[9](#S3.F9
    "Figure 9 ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational
    Architecture of Liberty: A Comprehensive Survey on Deep Learning for Generating
    Virtual Architecture in the Metaverse")d）。此外，前沿方法表明，将3D感知图像与CLIP模型（Jain等，[2022](#bib.bib77)；Wang等，[2022](#bib.bib167)）结合，使得能够从自然语言描述中生成3D几何体。而DreamFusion则使用从2D扩散模型蒸馏得出的损失，而不是CLIP（Poole等，[2022](#bib.bib139)）。Dream
    Field的原创性包含了2D图像到文本模型的预训练过程，以优化底层的3D表示。另一方面，一些先进的进展跳出了预训练2D图像到文本模型的固定框架。DreamFusion在这种文本到图像预训练中融入了扩散模型作为强图像先验，从而提高了生成的效率。此外，3D感知合成还适用于结合其他深度生成模型，如最近的扩散模型。下一节将具体阐述这一先进的扩散模型。3D感知图像合成的主要目标是在任务中获取明确的相机姿态（Shi等，[2022](#bib.bib157)）。可控性使用户能够进入更具参与感和互动性的环境。一些方法还支持对象姿态的可编辑性。例如，GIRAFFE允许在场景中平移和旋转获得的3D对象（Niemeyer和Geiger，[2021](#bib.bib129)）。StyleNeRF也允许在支持风格混合、反转和生成结果的语义编辑的同时改变风格属性（Gu等，[2021](#bib.bib56)）。这种可编辑性从生成目标的细分角度提供了各种解决方案。'
- en: 3.4.2\. 3D-aware image utilized in architecture
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.4.2. 在建筑中利用3D感知图像
- en: (Chan et al., [2021](#bib.bib29)) conducts an integrated method by transforming
    implicit neural representation into mesh representation, which performs an ability
    to editability in 3D space for architecture. StyleSDF  (Or-El et al., [2022](#bib.bib132))
    and StyleNeRF  (Gu et al., [2021](#bib.bib56)) also implement methods converting
    to geometry. Meng et al. as pioneering architects have launched a configurative
    Colab with user-friendly interaction for the creators supporting conditional text
    input and some parameters including style attributes based on DreamField  (Jain
    et al., [2022](#bib.bib77))  ^(20)^(20)20Source:[https://github.com/shengyu-meng/dreamfields-3D](https://github.com/shengyu-meng/dreamfields-3D).
    However, the concern is that single effectiveness for simple objects. These methods
    have plenty of limitations on the high resolution, which has the incapability
    of generating 3D precise structures with internal spaces. Efficiency is reduced
    hugely for the task of generating complex architectural structures. As a result,
    it is difficult to obtain a valid building with internal structure and functional
    space from image synthesis.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: (Chan 等，[2021](#bib.bib29)) 通过将隐式神经表示转换为网格表示，开展了一种集成方法，该方法具备在3D空间中进行编辑的能力。StyleSDF（Or-El
    等，[2022](#bib.bib132)）和StyleNeRF（Gu 等，[2021](#bib.bib56)）也实施了几何转换方法。作为先驱建筑师的Meng
    等推出了一个配置化的Colab，提供了友好的用户交互，支持基于DreamField（Jain 等，[2022](#bib.bib77)）的条件文本输入和一些包括风格属性在内的参数^(20)^(20)20来源：[https://github.com/shengyu-meng/dreamfields-3D](https://github.com/shengyu-meng/dreamfields-3D)。然而，单一效果对于简单对象仍存在问题。这些方法在高分辨率下有很多限制，无法生成具有内部空间的3D精确结构。在生成复杂建筑结构的任务中效率大幅降低。因此，从图像合成中获得具有内部结构和功能空间的有效建筑仍然困难重重。
- en: Although 3D-aware synthesis is relatively premature for virtual architecture,
    its ability to convert to mesh, controllability, and multi-modality with linguistic
    descriptions have demonstrated its potential for generating complex and unique
    architectural forms. In contrast to generation for explicit representations, it
    offers more flexible, continuous, and efficient representations of geometry, as
    well as the capability of integration with other deep learning generation techniques.
    As the field of 3D DGMs and 3D-aware image synthesis evolves, architects may increasingly
    explore the potential of this technique as a common toolkit for virtual architectural
    design.
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管3D感知合成在虚拟建筑领域相对尚不成熟，但其将数据转换为网格、可控性以及与语言描述的多模态能力已展示了其生成复杂且独特建筑形式的潜力。与用于显式表示的生成方法相比，它提供了更为灵活、连续且高效的几何表示，以及与其他深度学习生成技术整合的能力。随着3D
    DGMs（深度生成模型）和3D感知图像合成领域的发展，建筑师可能会越来越多地探索这一技术作为虚拟建筑设计的常用工具包的潜力。
- en: 3.5\. Emerging Generation Based on Diffusion Model
  id: totrans-248
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 3.5. 基于扩散模型的新兴生成方法
- en: Recently, diffusion as one of the deep generative models has gained a growing
    interest in generating 3D shapes due to its high quality with fine details and
    controllable attributes. It outperforms Generative Adversarial Networks (GANs)
    in fidelity due to intricate details and sharp edges while maintaining stability
    during training and reducing the risk of mode collapse. This superiority stems
    from their ability to enable fine-grained control over the generation process
    with specific attributes or interpolation between shapes smoothly and continuously.
    In contrast, a less controlled approach to GANs dictates its difficulty in specifying
    the desired properties of the output.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，作为深度生成模型之一的扩散模型因其高质量的细节和可控属性在生成3D形状方面引起了越来越多的关注。与生成对抗网络（GANs）相比，它在保真度上表现更佳，因为扩散模型能够处理复杂的细节和清晰的边缘，同时在训练过程中保持稳定并降低模式崩溃的风险。这种优势源于其能够对生成过程进行细粒度的控制，包括特定属性的生成或形状之间的平滑过渡。相对而言，GANs由于控制不够精确，使得指定输出的期望属性变得困难。
- en: 3.5.1\. 3D Diffusion
  id: totrans-250
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.1. 3D扩散模型
- en: DreamFusion adopts diffusion models to denoising images for a high-quality image
    for 3D-aware image synthesis  (Poole et al., [2022](#bib.bib139)). Despite the
    flexibility of conditional diffusion sampling, as revealed by studies of GANs,
    traditional diffusion as a DGM only samples pixels. Ben et al. abandoned processing
    large amounts of data from 2D images to 3D while generating a 3D model directly.
    In DreamFusion, a parameter of 3D volume, instead of images’ indicators, $\theta$,
    and g is a volumetric renderer. It yields a sample through an optimization performed
    by minimizing a loss function. Two limitations exist, DreamFusion was improved
    in the latest research, known as Magic3D  (Lin et al., [2022](#bib.bib105)), which
    are the low resolution of geometry and textures and the expensive computation
    as well as intensive memory. LION  (Zeng et al., [2022](#bib.bib180)) has a higher
    quality performance by utilizing the diffusion models combined with a hierarchy
    VAE. Its flexibility of operation and application has also increased compared
    to previous models 3D DDMs  (Ho et al., [2020b](#bib.bib67)) due to conditional
    synthesis and shape interpolation. Unlike most existing DDPMs, PVD  (Zhou et al.,
    [2021](#bib.bib187)) employs a unified probabilistic formula to generate high-fidelity
    3D shapes with multiple results from a single-view depth scan of a real object.
    Moreover, diffusion models allow for the generation of 3D shapes with controllable
    attributes such as shape and texture, which can be modified by conditioning the
    generation process on specific attributes. These findings suggest that diffusion
    models may offer a more robust and controlled approach to 3D shape generation,
    particularly regarding complex shapes with intricate details and specific attributes.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: DreamFusion 采用扩散模型对图像进行去噪，以获得高质量的 3D 觉知图像合成（Poole 等，[2022](#bib.bib139)）。尽管条件扩散采样具有灵活性，但如
    GANs 研究所揭示的，传统的扩散作为 DGM 仅采样像素。Ben 等人放弃了从 2D 图像到 3D 的大量数据处理，直接生成 3D 模型。在 DreamFusion
    中，使用的是 3D 体积的参数，而不是图像的指标，$\theta$ 和 g 是体积渲染器。它通过最小化损失函数进行优化以生成样本。存在两个限制，DreamFusion
    在最新的研究中得到了改进，称为 Magic3D（Lin 等，[2022](#bib.bib105)），这些限制包括几何体和纹理的低分辨率以及昂贵的计算和高强度内存。LION（Zeng
    等，[2022](#bib.bib180)）通过结合扩散模型与层次 VAE 提供了更高质量的表现。与之前的 3D DDMs（Ho 等，[2020b](#bib.bib67)）相比，其操作和应用的灵活性也有所增加，得益于条件合成和形状插值。与大多数现有的
    DDPMs 不同，PVD（Zhou 等，[2021](#bib.bib187)）采用统一的概率公式，通过单视图深度扫描生成高保真度的 3D 形状。 此外，扩散模型允许生成具有可控属性（如形状和纹理）的
    3D 形状，可以通过对特定属性进行条件生成过程的修改。这些发现表明，扩散模型可能为 3D 形状生成提供了更强大且受控的方法，特别是在处理具有复杂细节和特定属性的复杂形状时。
- en: 3.5.2\. 3D Diffusion Applications in Architecture
  id: totrans-252
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.2\. 3D 扩散应用于建筑学
- en: '![Refer to caption](img/d71ddad5eeac1ea307a3e8b66e78e962.png)'
  id: totrans-253
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/d71ddad5eeac1ea307a3e8b66e78e962.png)'
- en: (a) Selected results in (Zhang, [2020](#bib.bib182)) of the linguistics-based
    architectural form DGMs that make 3D form predictions based on the text descriptions.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
  zh: （a）在 (Zhang，[2020](#bib.bib182)) 中选择的结果是基于语言学的建筑形式 DGM，这些模型根据文本描述进行 3D 形式预测。
- en: '![Refer to caption](img/88fccc05581399eeb2bd5cca2935c576.png)'
  id: totrans-255
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/88fccc05581399eeb2bd5cca2935c576.png)'
- en: '(b) Methodology incorporating stable diffusion (SD) with Lora by AIG; Source:
    [https://www.bilibili.com/video/BV1Qb411Z7UP/](https://www.bilibili.com/video/BV1Qb411Z7UP/).'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: （b）结合稳定扩散（SD）与 AIG 的 Lora 的方法；来源：[https://www.bilibili.com/video/BV1Qb411Z7UP/](https://www.bilibili.com/video/BV1Qb411Z7UP/)。
- en: '![Refer to caption](img/0a8bf54c6e7b4c57bb11bdbdb685a191.png)'
  id: totrans-257
  prefs: []
  type: TYPE_IMG
  zh: '![参考标题](img/0a8bf54c6e7b4c57bb11bdbdb685a191.png)'
- en: (c) A plugin utilized diffusion model in 3D modeling software Rhino for  (Guida,
    [2023](#bib.bib57)).
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: （c）一个插件在 3D 建模软件 Rhino 中利用了扩散模型（Guida，[2023](#bib.bib57)）。
- en: Figure 13. Architectural designs utilized diffusion models.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
  zh: 图 13. 利用扩散模型的建筑设计。
- en: 'The use of diffusion models in architecture is an emerging and promising field
    for development. Integrating an application programming interface (API) directly
    into the diffusion model in Rhino’s visual programming environment, Grasshopper
    has the potential to usher in a paradigm shift in the generation of architectural
    3D forms. For example, morphological heatmap images transforming from 3D architecture
    models can be trained using Lora models, in which stable diffusion can further
    edit (See Fig.  [13(b)](#S3.F13.sf2 "In Figure 13 ‣ 3.5.2\. 3D Diffusion Applications
    in Architecture ‣ 3.5\. Emerging Generation Based on Diffusion Model ‣ 3.4.2\.
    3D-aware image utilized in architecture ‣ 3.4.1\. 3D-aware image synthesis and
    its editablity ‣ 3.4\. 3D-Aware Image Synthesis ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    The generated grayscale images processed by stable diffusion include height information,
    which can be easily transformed into a mesh model in the same modeling environment
     ^(21)^(21)21Source: [https://www.bilibili.com/video/BV1Qb411Z7UP/](https://www.bilibili.com/video/BV1Qb411Z7UP/).'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
  zh: '在建筑领域中，扩散模型的使用是一个新兴且有前景的发展领域。在Rhino的可视化编程环境Grasshopper中，直接将应用程序编程接口（API）集成到扩散模型中，有可能引发建筑3D形态生成的范式转变。例如，形态学热图图像从3D建筑模型转变后，可以使用Lora模型进行训练，其中稳定扩散可以进一步编辑（见图[13(b)](#S3.F13.sf2
    "在图13 ‣ 3.5.2\. 3D扩散应用于建筑 ‣ 3.5\. 基于扩散模型的新兴生成 ‣ 3.4.2\. 在建筑中利用的3D感知图像 ‣ 3.4.1\.
    3D感知图像的合成及其可编辑性 ‣ 3.4\. 3D感知图像合成 ‣ 3\. 生成的3D建筑：一种范式转变 ‣ 朝向自由计算建筑：虚拟建筑生成的深度学习综合调查")).
    通过稳定扩散处理生成的灰度图像包括高度信息，可以在同一建模环境中轻松转换为网格模型^(21)^(21)21来源: [https://www.bilibili.com/video/BV1Qb411Z7UP/](https://www.bilibili.com/video/BV1Qb411Z7UP/)。'
- en: 3.5.3\. Controllability and Generative Models Conditioned on Text
  id: totrans-261
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.3\. 基于文本的可控性和生成模型
- en: Text-to-3D models as a featured method have surged their development in generative
    3D shapes in recent two years (Chen et al., [2018](#bib.bib30); Poole et al.,
    [2022](#bib.bib139); Liu et al., [2022](#bib.bib108); Lin et al., [2022](#bib.bib105);
    Nichol et al., [2022](#bib.bib128)). The earliest research we tracked is text2shape (Chen
    et al., [2018](#bib.bib30)), in which 3D models with color and shape paired with
    natural language formed datasets to build implicit semantic links. Recent research
    has made a remarkable breakthrough in associating text and 3D models with unsupervised
    learning. Similar to 3D-aware synthesis, most methods utilize CLIP with unsupervised
    learning (Lin et al., [2022](#bib.bib105); Nichol et al., [2022](#bib.bib128)).
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
  zh: 以文本到3D模型为特色的方法在过去两年中在生成3D形状方面迅猛发展（Chen et al., [2018](#bib.bib30); Poole et
    al., [2022](#bib.bib139); Liu et al., [2022](#bib.bib108); Lin et al., [2022](#bib.bib105);
    Nichol et al., [2022](#bib.bib128)）。我们追踪到的最早研究是text2shape（Chen et al., [2018](#bib.bib30)），其中结合自然语言的3D模型数据集形成了隐式语义链接。最近的研究在将文本和3D模型与无监督学习结合方面取得了显著突破。类似于3D感知合成，大多数方法利用CLIP进行无监督学习（Lin
    et al., [2022](#bib.bib105); Nichol et al., [2022](#bib.bib128)）。
- en: The text-to-3D approach demonstrates superior controllability compared to other
    methods for generating 3D models, along with customized style attributes. This
    approach interprets textual prompts, resulting in an intuitive visual representation
    catering to design intention. For instance, Magic 3D  (Lin et al., [2022](#bib.bib105))
    has developed a toolkit that offers advanced control over 3D-generated styles
    and content through various image conditioning and prompt-based editing to achieve
    the desired result. As a result, the text-to-3D approach democratizes 3D geometry
    generation, providing access for individuals with varying levels of expertise
    to produce creatively. As aforementioned, integrating Colab with DL algorithms
    also serves as a gateway for designers, artists, and amateurs to participate in
    the burgeoning field of content production.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
  zh: 文本到3D的方法相比其他生成3D模型的方法展示了更优的可控性以及定制化的风格属性。该方法解读文本提示，生成直观的视觉表现，以满足设计意图。例如，Magic
    3D（Lin et al., [2022](#bib.bib105)）开发了一套工具包，通过各种图像条件和基于提示的编辑提供对3D生成样式和内容的高级控制，以实现所需结果。因此，文本到3D的方法使3D几何生成民主化，提供了不同专业水平的个体进行创造的机会。如前所述，将Colab与深度学习算法结合，也为设计师、艺术家和业余爱好者参与内容生产的新兴领域提供了通道。
- en: 3.5.4\. 3D Form Driven by Text in Architecture
  id: totrans-264
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 3.5.4\. 由文本驱动的3D形态在建筑中的应用
- en: 'There are some initial applications using languages as starting points to utilize
    design. However, the generative model is constrained in such applications. For
    example, Del Campo used attentional GAN (AttnGAN) to assist the brainstorming
    process for transforming written ideas of multipurpose spaces to visual outputs
    (del Campo, [2021](#bib.bib38)). Then, the final outcome was based on the previously
    demonstrated visuals. Zhang developed a machine-learning framework capable of
    encoding the input geometry into a new geometry by using text to form a prediction
    (Zhang, [2020](#bib.bib182)) (See Fig.  [13(a)](#S3.F13.sf1 "In Figure 13 ‣ 3.5.2\.
    3D Diffusion Applications in Architecture ‣ 3.5\. Emerging Generation Based on
    Diffusion Model ‣ 3.4.2\. 3D-aware image utilized in architecture ‣ 3.4.1\. 3D-aware
    image synthesis and its editablity ‣ 3.4\. 3D-Aware Image Synthesis ‣ 3\. Generated
    3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty:
    A Comprehensive Survey on Deep Learning for Generating Virtual Architecture in
    the Metaverse")). In this framework, different usage of spaces has been trained
    with adjacent matrices to understand the linguistic instructions. With the integration
    of natural language supervision, the diffusion models exhibit high-quality performance
    in form generation and have great potential to become HCI tools. George Guida
    explored the user interface integration in the 3D form generation process for
    designers to embrace more design opportunities in a multi-modal loop by combining
    these user-friendly language models (Guida, [2023](#bib.bib57)) (See Fig.  [13(c)](#S3.F13.sf3
    "In Figure 13 ‣ 3.5.2\. 3D Diffusion Applications in Architecture ‣ 3.5\. Emerging
    Generation Based on Diffusion Model ‣ 3.4.2\. 3D-aware image utilized in architecture
    ‣ 3.4.1\. 3D-aware image synthesis and its editablity ‣ 3.4\. 3D-Aware Image Synthesis
    ‣ 3\. Generated 3D Architecture: A PARADIGM SHIFT ‣ Towards Computational Architecture
    of Liberty: A Comprehensive Survey on Deep Learning for Generating Virtual Architecture
    in the Metaverse")).'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
  zh: 有一些初步应用使用语言作为起点来利用设计。然而，生成模型在这些应用中受到限制。例如，Del Campo 使用了注意力生成对抗网络（AttnGAN）来协助将多功能空间的书面创意转化为视觉输出的头脑风暴过程（del
    Campo, [2021](#bib.bib38)）。最终结果基于之前展示的视觉效果。Zhang 开发了一个机器学习框架，能够通过使用文本来将输入几何体编码成新的几何体，以形成预测（Zhang,
    [2020](#bib.bib182)）（见图 [13(a)](#S3.F13.sf1 "图 13 ‣ 3.5.2\. 3D 扩散应用于建筑 ‣ 3.5\.
    基于扩散模型的生成 ‣ 3.4.2\. 3D-aware 图像在建筑中的应用 ‣ 3.4.1\. 3D-aware 图像合成及其可编辑性 ‣ 3.4\. 3D-Aware
    图像合成 ‣ 3\. 生成的 3D 建筑：范式转变 ‣ 向自由计算建筑迈进：关于在元宇宙中生成虚拟建筑的深度学习的全面调查")）。在这个框架中，不同用途的空间通过相邻矩阵进行了训练，以理解语言指令。通过自然语言监督的整合，扩散模型在形状生成中表现出高质量的性能，并且具有成为
    HCI 工具的巨大潜力。George Guida 探索了在 3D 形状生成过程中用户界面集成的研究，使设计师能够通过结合这些用户友好的语言模型，在多模态循环中接受更多设计机会（Guida,
    [2023](#bib.bib57)）（见图 [13(c)](#S3.F13.sf3 "图 13 ‣ 3.5.2\. 3D 扩散应用于建筑 ‣ 3.5\.
    基于扩散模型的生成 ‣ 3.4.2\. 3D-aware 图像在建筑中的应用 ‣ 3.4.1\. 3D-aware 图像合成及其可编辑性 ‣ 3.4\. 3D-Aware
    图像合成 ‣ 3\. 生成的 3D 建筑：范式转变 ‣ 向自由计算建筑迈进：关于在元宇宙中生成虚拟建筑的深度学习的全面调查")。
- en: 4\. Research Agenda
  id: totrans-266
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 4\. 研究议程
- en: In Sections 2 and 3, we investigate that building generation in virtual worlds
    urgently requires HCI and CAD 3D construction methods correlated with human needs
    to achieve novel and liberal building forms that are efficient and intimate to
    humans. The 3D building generation methods that we investigated rely on an artificial
    intelligence framework, among which HCI methodology takes the responsibility of
    assistance for generating and constructing in the virtual environment.
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
  zh: 在第 2 和第 3 节中，我们调查了虚拟世界中的建筑生成急需与人类需求相关联的 HCI 和 CAD 3D 建筑方法，以实现高效且贴近人类的创新和自由的建筑形式。我们调查的
    3D 建筑生成方法依赖于人工智能框架，其中 HCI 方法负责在虚拟环境中生成和构建的辅助。
- en: '![Refer to caption](img/356a154b31a04c1e645d735e431653b1.png)'
  id: totrans-268
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明文字](img/356a154b31a04c1e645d735e431653b1.png)'
- en: Figure 14. Research agendas in a full process of DGMs-assisted architectural
    design.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
  zh: 图 14. DGMs 辅助建筑设计的完整过程中的研究议程。
- en: 'Although many studies have pointed to a wide variety of applications in the
    intersection of VR and architecture, there is still a lack of systematic evaluation
    of these interactions in such conditions. What’s more, it is crucial to use interactive
    techniques to quantify the generation of virtual buildings systematically and
    to assess whether their needs are being met. Additionally, further exploration
    of interactive methods in generative approaches is lacking (Lin and Lo, [2021](#bib.bib104))
    (See Fig.  [14](#S4.F14 "Figure 14 ‣ 4\. Research Agenda ‣ 3.5.4\. 3D Form Driven
    by Text in Architecture ‣ 3.5\. Emerging Generation Based on Diffusion Model ‣
    3.4.2\. 3D-aware image utilized in architecture ‣ 3.4.1\. 3D-aware image synthesis
    and its editablity ‣ 3.4\. 3D-Aware Image Synthesis ‣ 3\. Generated 3D Architecture:
    A PARADIGM SHIFT ‣ Towards Computational Architecture of Liberty: A Comprehensive
    Survey on Deep Learning for Generating Virtual Architecture in the Metaverse")).
    In this article, the application of virtual reality technology in the architectural
    design process is inefficient due to interaction limitations  (Lin and Lo, [2021](#bib.bib104)).
    Therefore, in order to encourage this research topic to conduct, we advocate the
    following research topics to enhance the ease of implementation in the production
    pipeline. This section reveals several research agendas in the generative approach
    for virtual building by focusing on this HCI methodology and human factors.'
  id: totrans-270
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管许多研究指出了虚拟现实与建筑交叉领域的广泛应用，但在这些条件下仍缺乏系统性的评估。此外，使用互动技术系统地量化虚拟建筑的生成并评估其需求是否得到满足至关重要。此外，在生成方法中进一步探索互动方法也存在不足 （Lin
    和 Lo, [2021](#bib.bib104)）（见图 [14](#S4.F14 "图 14 ‣ 4\. 研究议程 ‣ 3.5.4\. 由文本驱动的3D形式在建筑中
    ‣ 3.5\. 基于扩散模型的新兴生成 ‣ 3.4.2\. 在建筑中使用的3D感知图像 ‣ 3.4.1\. 3D感知图像合成及其可编辑性 ‣ 3.4\. 3D感知图像合成
    ‣ 3\. 生成的3D建筑：一种范式转变 ‣ 迈向自由计算建筑：对元宇宙中生成虚拟建筑的深度学习的全面调查")。本文中，由于互动限制，虚拟现实技术在建筑设计过程中的应用效率低下（Lin
    和 Lo, [2021](#bib.bib104)）。因此，为了推动这一研究主题，我们倡导以下研究主题以提高生产流程中的实施便捷性。本节揭示了针对虚拟建筑生成的几项研究议程，重点关注这一HCI方法论和人因工程。
- en: 4.1\. Data Limitation
  id: totrans-271
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.1\. 数据限制
- en: Data Limitation is one of the greatest challenges in both virtual architectures
    and computational architectures. Regenwetter et al. announced three main issues
    lying on this challenge. First, the lack of available and public datasets of 3D
    datasets becomes a hurdle to design industries. The second is insufficient data
    size in those datasets. Third, data sparsity and bias in datasets exist. Our review
    reveals that data limitation on 3D datasets is vital for virtual architecture.
    It led to a restriction on the massive computation from 3D solid generation whenever
    in GANs or VAEs, since those designers could not find appropriate datasets of
    3D buildings.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
  zh: 数据限制是虚拟建筑和计算建筑中最大的挑战之一。Regenwetter等人提出了这个挑战中的三个主要问题。首先，缺乏可用和公开的3D数据集成为设计行业的障碍。第二，数据集中的数据量不足。第三，数据集中的数据稀疏性和偏差存在。我们的回顾表明，3D数据集的数据限制对虚拟建筑至关重要。这导致了在GANs或VAEs中的3D固体生成时的计算限制，因为这些设计师找不到适当的3D建筑数据集。
- en: 4.2\. Editability
  id: totrans-273
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.2\. 可编辑性
- en: 4.2.1\. Editing in 3D Shape Generation
  id: totrans-274
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.1\. 3D形状生成中的编辑
- en: As mentioned in Section 3, we described the significance of editability for
    design industries that rely on 3D model editing. This significance lies in the
    timeliness of feedback and adjustments and in the perception of the 3D space.
    Some work has demonstrated the autonomy of editing in 3D shape generation techniques
    available to users. For example, Liu et al. proposed a method for user-centric
    3D shapes generation assisted by a 3D GAN by drawing the target model as 3D voxel
    grids. While more approaches demonstrate methods that indirectly edit 3D models
    through implicit representations (Hao et al., [2020](#bib.bib62); Ibing et al.,
    [2021](#bib.bib72); Deng et al., [2021](#bib.bib42); Zheng et al., [2021](#bib.bib186)).
    Compared to the explicit representations, their more compact approaches includes
    sparse 3D points or bounding boxes  (Shi et al., [2022](#bib.bib157)). The former
    approach is widely used in virtual building designs as a user-centered participatory
    design experience. While a gap exists in the latter approach for producers to
    meet specific design goals, we need more user-friendly development tools, software
    or online platforms.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
  zh: 如第3节所述，我们描述了对依赖于3D模型编辑的设计行业中可编辑性的意义。这种意义在于反馈和调整的及时性以及对3D空间的感知。一些研究展示了用户在3D形状生成技术中的编辑自主性。例如，Liu
    等提出了一种通过绘制目标模型为3D体素网格的用户中心3D形状生成方法，借助3D GAN。与此同时，更多方法展示了通过隐式表示间接编辑3D模型（Hao 等，[2020](#bib.bib62);
    Ibing 等，[2021](#bib.bib72); Deng 等，[2021](#bib.bib42); Zheng 等，[2021](#bib.bib186)）。与显式表示相比，他们更紧凑的方法包括稀疏3D点或边界框（Shi
    等，[2022](#bib.bib157)）。前者方法在虚拟建筑设计中被广泛使用，作为以用户为中心的参与式设计体验。虽然后者方法在生产者实现特定设计目标方面存在差距，但我们仍需要更多用户友好的开发工具、软件或在线平台。
- en: 4.2.2\. Editing in 3D-aware Synthesis
  id: totrans-276
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.2.2\. 在3D感知合成中的编辑
- en: For 3D-aware image synthesis methods, there is also still a lot of room for
    improvement in editability. All 3D-aware controllers support the camera pose.
    While some methods also accomplish the insertion of new objects and pose control.
    In contrast to 3D shape generation, 3D-aware image synthesis precludes direct
    user manipulation in 3D space and requires latent vector editing to control the
    composition, shape, and appearance. These latent vectors model all other variables
    that are not captured by physical factors, while being able to control small changes
    in the scene, such as lighting, coloring and so on  (Xia and Xue, [2022](#bib.bib173)).
    Furthermore, there are several approaches that allow additional inputs to alter
    the editing of the scene, such as textual descriptions, semantic labels (Liu et al.,
    [2022](#bib.bib108); Jahan et al., [2021](#bib.bib76); Fu et al., [2022](#bib.bib50)),
    images (Sanghi et al., [2022](#bib.bib146)), and parameter controls. This approach
    is analogous to the parametric design for architecture and is more closely aligned
    with the classical design process, controlling the final form from a user-adjustable
    panel. Therefore, this edibility is one of the reasons for its rapid popularity
    in a large number of AIGC-driven 3D designs.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
  zh: 对于3D感知图像合成方法，在可编辑性方面仍有很大改进空间。所有3D感知控制器都支持相机姿态，而有些方法还实现了新对象的插入和姿态控制。与3D形状生成不同，3D感知图像合成排除了在3D空间中直接用户操作，要求通过潜在向量编辑来控制组合、形状和外观。这些潜在向量建模所有未被物理因素捕捉的变量，同时能够控制场景中的微小变化，如照明、着色等（Xia
    和 Xue，[2022](#bib.bib173)）。此外，还有几种方法允许额外输入来改变场景编辑，如文本描述、语义标签（Liu 等，[2022](#bib.bib108);
    Jahan 等，[2021](#bib.bib76); Fu 等，[2022](#bib.bib50)），图像（Sanghi 等，[2022](#bib.bib146)）和参数控制。这种方法类似于建筑的参数化设计，更加贴近经典设计过程，通过用户可调面板控制最终形式。因此，这种可编辑性是其在大量AIGC驱动的3D设计中迅速流行的原因之一。
- en: 4.3\. Evaluation Metrics
  id: totrans-278
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.3\. 评估指标
- en: 4.3.1\. The Efficiency of Results
  id: totrans-279
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.1\. 结果的效率
- en: The fidelity, photorealistic, and geometric quality are important elements of
    the evaluation metrics. However, existing evaluation methods lack metrics to evaluate
    these. Intuitively, these generated models do not meet the normative conditions
    for use. In addition, Regenwetter et al. points out that due to the inadequacy
    of current 3D databases and the lack of real references (Regenwetter et al., [2022](#bib.bib143)).
    The evaluation criteria are clustered on the stability of generative models rather
    than reflecting the distance from the real sample. In general, there is a great
    lack of reliable methods to assess the difference between the generated real results
    and the target ones.
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
  zh: 保真度、照片级真实感和几何质量是评估指标的重要元素。然而，现有的评估方法缺乏对这些指标的评估。直观地说，这些生成的模型并未满足使用的规范条件。此外，Regenwetter
    等人指出，由于当前 3D 数据库的不充分以及缺乏真实参考 (Regenwetter et al., [2022](#bib.bib143))。评估标准集中在生成模型的稳定性上，而不是反映与真实样本的差距。总体而言，评估生成结果与目标结果之间差异的可靠方法严重不足。
- en: 4.3.2\. Qualitative Human Evaluation
  id: totrans-281
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.2\. 质性人工评估
- en: Human perception, albeit primarily qualitative, becomes essential feedback for
    designers as an indicator of understanding user-design fitness, hence improving
    design solutions. One of the typical methods of user evaluation concerns the user’s
    behavior, such as movement path, attention, and so on. Ding et al. proposed that
    these spatial perceptions are related to building structural features, building
    spatial geometric features, and building spatial functional attributes (Ding et al.,
    [2022](#bib.bib44)). From both qualitative and quantitative perspectives, it is
    difficult to assess the practical impact of collecting and processing these biological
    and perceptual data into associations with spatial elements in complex design
    decisions. Nevertheless, eyesight as a human sense has been used to build the
    relationship to the qualitative human evaluation. Some research focused on eyesight
    to visualize the attention evaluation to better understand the users’ behaviors
    and make the evaluation  (Narahara, [2022](#bib.bib120); Wells et al., [2021](#bib.bib169);
    Pei et al., [2021](#bib.bib136)). An Eye-Tracking Voxel Environment Sculptor (EVES)
    was developed, in which eye-tracking data obtained from the designer is used directly
    as input in the modeling environment to manipulate and sculpt voxels  (Wells et al.,
    [2021](#bib.bib169)). These methods of qualitative human perception provide a
    number of viable evaluation metrics for deep generative models to determine the
    spatial perceptual and emotional impact.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
  zh: 人类感知，尽管主要是质性的，却成为设计师的关键反馈，作为理解用户设计适配性的指标，从而改进设计方案。用户评估的一个典型方法涉及用户的行为，例如运动路径、注意力等。Ding
    等人提出，这些空间感知与建筑结构特征、建筑空间几何特征和建筑空间功能属性相关 (Ding et al., [2022](#bib.bib44))。从质性和量化的角度来看，将这些生物和感知数据收集和处理与复杂设计决策中的空间元素关联的实际影响难以评估。尽管如此，作为一种人类感官的视力已被用来建立与质性人工评估的关系。一些研究集中于视力，以可视化注意力评估，从而更好地理解用户行为并进行评估 (Narahara,
    [2022](#bib.bib120); Wells et al., [2021](#bib.bib169); Pei et al., [2021](#bib.bib136))。开发了一种眼动追踪体素环境雕刻器
    (EVES)，在其中从设计师获得的眼动追踪数据直接作为建模环境中的输入，用于操作和雕刻体素 (Wells et al., [2021](#bib.bib169))。这些质性人工感知的方法为深度生成模型提供了多种可行的评估指标，以确定空间感知和情感影响。
- en: 4.3.3\. Aesthetics Assessment
  id: totrans-283
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.3.3\. 美学评估
- en: Aesthetic evaluation enables us to operate automated computer methods to evaluate
    results and optimize spaces based on human positions and understanding of the
    environment, while freeing up human resources. For example, virtual spaces can
    be Interactive and variable spontaneously based on the data obtained from the
    assessment. This integration of the criteria of quantitative aesthetic evaluation
    and optimized architectural forms have the potential to be embedded in the pipeline
    of generative forms. Various research on the generative shape or space by CAD
    mentioned the aesthetics evaluation. It mainly concentrates on feature extraction
    and computational evaluation of visual features. Integrating visual aesthetic
    criteria is challenging because it applies the quantitative approach to assess
    qualitative formal features. The evaluation of spatial and structural designs
    in computer vision involves visual feature analysis (VCA) as well as structural
    analysis (SA) and geometric analysis (GA)  (Narahara, [2022](#bib.bib120)).
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
  zh: 美学评估使我们能够操作自动化计算机方法来评估结果并优化基于人类位置和对环境理解的空间，同时释放人力资源。例如，虚拟空间可以根据从评估中获得的数据自发地进行交互和变化。这种定量美学评估标准与优化建筑形式的集成有潜力嵌入生成形式的流程中。各种有关CAD生成形状或空间的研究提到了美学评估。它主要集中在特征提取和视觉特征的计算评估上。整合视觉美学标准是具有挑战性的，因为它应用定量方法来评估定性形式特征。在计算机视觉中，对空间和结构设计的评估涉及视觉特征分析（VCA）、结构分析（SA）和几何分析（GA）（Narahara，[2022](#bib.bib120)）。
- en: One type represents the evaluation of the form of the building itself by standardizing
    the criteria line of a series of visual features. Such as intricacy, heterogeneity,
    continuity, and surface recesses based on a design project for an exhibition are
    evaluated  (STUART-SMITH and DANAHY, [2022](#bib.bib161)). These results demonstrate
    that a limited set of aesthetic design criteria can be correlated with structural
    and geometric data in quantitative indicators.In addition, some studies give insight
    into the evaluation of visual features for specific geometric models (Kavakoglu,
    [2021](#bib.bib85)). The other type represents an example of quantitative aesthetic
    evaluation embedded in a parametric model (Sardenberg, [2019](#bib.bib148)). Nonetheless,
    the proposed visual features and corresponding analytical criteria for 3D deep
    generative models provide an extremely limited form of aesthetic assessment.
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
  zh: 一种类型表示通过标准化一系列视觉特征的标准线对建筑形式进行评估。这些特征包括复杂性、异质性、连续性和表面凹陷，这些特征基于展览设计项目进行评估（STUART-SMITH
    和 DANAHY，[2022](#bib.bib161)）。这些结果表明，一组有限的美学设计标准可以与结构和几何数据在定量指标中相关联。此外，一些研究对特定几何模型的视觉特征评估提供了洞见（Kavakoglu，[2021](#bib.bib85)）。另一种类型则代表了嵌入参数模型中的定量美学评估示例（Sardenberg，[2019](#bib.bib148)）。尽管如此，为3D深度生成模型提出的视觉特征和相应的分析标准提供了一种极为有限的美学评估形式。
- en: 4.4\. Human-Computer Interactive Design
  id: totrans-286
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: 4.4\. 人机交互设计
- en: 4.4.1\. User-centered Adaptive Design
  id: totrans-287
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.1\. 以用户为中心的自适应设计
- en: Existing research that exhibits the real-time form interaction with the behavior
    or design purpose still focuses mainly on the interaction between parametric design
    and building form. The parameter design and the black box of algorithms in the
    DL approach are two distinct ways. So far, how to design and generate forms in
    real-time in the DL approach is still an unknown problem. Ubiquitous computing
    can be more useful in a virtual environment through smart wearable devices. Simulation
    of atmospheric qualities in VR explores space and directionality in virtual scenarios
    with thermal perception as feedback  (Sheehan et al., [2021](#bib.bib155)). Another
    project explores the thoughts and emotions of the presence of scenarios in virtual
    space, translating physiological data into digital space  (Tosello, [2003](#bib.bib164)).
    Both of them are only toward artistic expression. On the other hand, the existing
    real-time interactions, such as perceptions of data, impact architectural forms
    and focus on the study of parametricism architecture (Guo et al., [2021](#bib.bib60);
    Zarei et al., [2021](#bib.bib179)). This parametricism is closer to the classical
    design process and is not identical to the fully automatized generation through
    DGMs. We believe virtual architecture’s future is toward interactive self-response
    forms based on real-time data by DL-generated approaches. That will lead to the
    liberty of virtual architecture. We believe there is still a long journey to go
    through before such implemented interactions in the development, integrated with
    a DL-generated approach.
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
  zh: 现有研究展示了与行为或设计目的的实时形式交互，仍主要集中于参数化设计与建筑形式之间的交互。参数化设计和深度学习方法中的算法黑箱是两种不同的方法。目前，如何在深度学习方法中实时设计和生成形式仍是一个未知的问题。通过智能可穿戴设备，普适计算在虚拟环境中可以更为有用。虚拟现实中的大气品质模拟探讨了空间和方向性，以热感知作为反馈
     （Sheehan et al., [2021](#bib.bib155)）。另一个项目探讨了虚拟空间中场景存在的思想和情感，将生理数据转化为数字空间  （Tosello,
    [2003](#bib.bib164)）。这两个项目都仅仅是艺术表现方向。另一方面，现有的实时交互，如数据感知，影响建筑形式，重点研究参数化建筑  （Guo
    et al., [2021](#bib.bib60); Zarei et al., [2021](#bib.bib179)）。这种参数化设计更接近经典设计过程，而与通过DGMs完全自动化生成不同。我们相信虚拟建筑的未来将朝向基于实时数据的交互自响应形式，通过深度学习生成的方法。这将引领虚拟建筑的自由度。我们相信，在这样的交互实现之前，还需要经过一段漫长的旅程，并且需要与深度学习生成的方法相结合。
- en: 4.4.2\. Human Perception
  id: totrans-289
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.2\. 人类感知
- en: The collection of biosignals considering the five senses in HCI is one typical
    research focus, as well as considering how to process the context-aware interaction.
    At the same time, perception is the organization, recognition and interpretation
    of sensory information to understand the presented information and the environment.
    In addition, the method of user evaluation often facilitates HCI as a subsequent
    phase after biosignal collection, context awareness, and understanding of the
    information and environment.
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
  zh: 在人机交互中，考虑五种感官的生物信号收集是一个典型的研究重点，以及如何处理上下文感知交互。同时，感知是对感官信息进行组织、识别和解释，以理解所呈现的信息和环境。此外，用户评估方法通常在生物信号收集、上下文感知以及对信息和环境的理解之后，作为人机交互的后续阶段进行。
- en: User evaluation often takes the role of an indicator for testing and iterative
    purposes of design results. It usually considers the user’s performance in completing
    a specific task, a process that requires quantitative and qualitative assessments,
    including biodata collection, and group interviews, among other methods. Since
    the evaluation comes from the biosignals and perceptions generated by the human
    experience in the virtual environment, we elaborate on them in this section. Space
    could make the users produce a particular emotional condition, such as relaxed
    or nervous, leveraging the space attribution in terms of forms, perspectives,
    lights, coloring (Tonn, [2017](#bib.bib163)) and materials (Barsan-Pipu et al.,
    [2020](#bib.bib15)). The method of user evaluation has frequently been employed
    in the field of HCI as a test of design results and as an indicator of the iterative
    purpose. It usually takes into account the user’s performance in completing a
    specific task. This process entails the use of quantitative and qualitative questionnaire
    assessments, biological data, and group interviews, among other methods.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
  zh: 用户评价通常作为测试和迭代设计结果的一个指标。它通常考虑用户在完成特定任务时的表现，这一过程需要定量和定性评估，包括生物数据收集和小组访谈等方法。由于评价来源于虚拟环境中人类体验产生的生物信号和感知，因此我们在这一部分进行了详细阐述。空间可能使用户产生特定的情感状态，如放松或紧张，利用空间的形状、视角、光线、颜色（Tonn,
    [2017](#bib.bib163)）和材料（Barsan-Pipu et al., [2020](#bib.bib15)）等属性。用户评价方法在 HCI
    领域中经常被采用，用于测试设计结果和作为迭代目的的指标。它通常考虑用户在完成特定任务时的表现。这一过程涉及使用定量和定性问卷评估、生物数据和小组访谈等方法。
- en: The information-physical design of emotional computing systems is important
    in 3D generation methods. The research in HCI has been applied extensively in
    the investigation of spatially perceived data  (Ding et al., [2022](#bib.bib44)),
    neuroscientific cognitive biosignatures  (MUN et al., [2019](#bib.bib117); Ding
    et al., [2022](#bib.bib44)), eye-tracking  (Barsan-Pipu et al., [2020](#bib.bib15);
    Pei et al., [2020](#bib.bib137)) and biosignature-based emotion metrics  (Nguyen
    et al., [2019](#bib.bib125); Homolja et al., [2020](#bib.bib68); Pei et al., [2020](#bib.bib137)).
    The continued surge in recent years towards wearable devices with embedded sensors
    and actuators has encouraged the exploration of virtual spaces  (Diniz et al.,
    [2019](#bib.bib46)) within a design framework that facilitates enhanced human
    interaction. The field relies heavily on interdisciplinary collaboration at the
    intersection of 3D modeling, visualization in virtual reality, sensing technologies,
    and smart wearables to evolve human-machine-environment interactions and create
    a heightened awareness of what constitutes our spatial experience.
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
  zh: 情感计算系统的信息物理设计在 3D 生成方法中非常重要。HCI 领域的研究广泛应用于空间感知数据的调查（Ding et al., [2022](#bib.bib44)）、神经科学认知生物特征（MUN
    et al., [2019](#bib.bib117)；Ding et al., [2022](#bib.bib44)）、眼动追踪（Barsan-Pipu
    et al., [2020](#bib.bib15)；Pei et al., [2020](#bib.bib137)）以及基于生物特征的情感指标（Nguyen
    et al., [2019](#bib.bib125)；Homolja et al., [2020](#bib.bib68)；Pei et al., [2020](#bib.bib137)）。近年来对嵌入式传感器和执行器的可穿戴设备的持续热潮，推动了在设计框架内探索虚拟空间（Diniz
    et al., [2019](#bib.bib46)），以促进增强的人机互动。该领域在 3D 建模、虚拟现实可视化、传感技术和智能穿戴设备的交叉点上高度依赖跨学科的合作，以发展人机环境互动并提升我们对空间体验的认知。
- en: 4.4.3\. Participatory Design
  id: totrans-293
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: 4.4.3\. 参与式设计
- en: This refers to the involvement of stakeholders in the design process and decision-making,
    ranging from similative visualization to data collection, to evaluation. Virtual
    environments can provide co-collaborative environments and reality-based simulations
    for participatory design.It is an increasingly important research area in the
    study of architecture  (Kwiecinski et al., [2017](#bib.bib94)). One key feature
    of participatory research is inclusiveness, including adapting the research environment,
    methodology and dissemination routes to permit the widest and most accessible
    engagement. Kim et al. deployed pix2pix and CycleGAN into real-time collective
    design toolkits for streets to enable citizens to stylize their own urban streets (KIM
    et al., [2022](#bib.bib88)). The benefit allows non-professionals and professional
    designers to engage in collaborative design decisions at the same level. The critical
    input of non-professionals plays an indispensable role in the design, e.g., government
    personnel, and community members.
  id: totrans-294
  prefs: []
  type: TYPE_NORMAL
  zh: 这指的是利益相关者在设计过程和决策中的参与，从模拟可视化到数据收集，再到评估。虚拟环境可以提供协作环境和基于现实的参与设计模拟。这是建筑学研究中越来越重要的研究领域（Kwiecinski
    et al., [2017](#bib.bib94)）。参与式研究的一个关键特征是包容性，包括调整研究环境、方法和传播途径，以允许最广泛和最便捷的参与。Kim
    et al. 将pix2pix和CycleGAN应用于实时集体设计工具包，以便市民为自己的城市街道赋予风格（KIM et al., [2022](#bib.bib88)）。这一好处使非专业人士和专业设计师能够在同一水平上参与协作设计决策。非专业人士的关键输入在设计中发挥着不可或缺的作用，例如政府人员和社区成员。
- en: 5\. Conclusion
  id: totrans-295
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 5. 结论
- en: This work is a comprehensive investigation reflecting and providing a rethinking
    of the relationship among the 3D shape or image generation, social happenings
    and the scale of computational architecture. It is a synthesis of the “social”
    and the “object”. The approaches of generative approaches by CAD are very common
    and mostly already regard technical principles and design discipline in terms
    of regulations, economic and social constraints, and the efficiency of the space.
    In the survey, we investigated the related works that indicate the approaches
    for deep neural networks to produce virtual architectures automatically. We are
    concerned with both 3D-generation approaches and design disciplines, aiming to
    fill the current research gap from an interdisciplinary point of view. Three categories
    including GANs, VAEs, and DDPMs are used in the architectural design. However,
    due to the technical barrier and limited datasets, the architects only use cumbersome
    approaches to generate the computational architecture. Our survey unveils that
    research is not systematic until now, especially for virtual architecture. We
    call for further work on the 3D datasets, edibility, evaluation metrics and human-computer
    interactive design.
  id: totrans-296
  prefs: []
  type: TYPE_NORMAL
  zh: 本研究是对3D形状或图像生成、社会事件和计算架构规模之间关系的全面调查，并提供了重新思考的视角。它是“社会”和“对象”的综合体。CAD的生成方法非常普遍，大多数已考虑了技术原则和设计规范，如法规、经济和社会限制，以及空间效率。在调查中，我们研究了相关工作，这些工作表明深度神经网络用于自动生成虚拟建筑的方法。我们关注3D生成方法和设计学科，旨在从跨学科的角度填补当前的研究空白。在建筑设计中使用了GANs、VAEs和DDPMs三类方法。然而，由于技术障碍和数据集限制，建筑师只能使用繁琐的方法生成计算架构。我们的调查揭示了目前的研究还不够系统，尤其是在虚拟建筑领域。我们呼吁进一步研究3D数据集、可编辑性、评价指标和人机交互设计。
- en: References
  id: totrans-297
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 参考文献
- en: (1)
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: (1)
- en: 'Abdar et al. (2021) Moloud Abdar et al. 2021. A review of uncertainty quantification
    in deep learning: Techniques, applications and challenges. *Information Fusion*
    76 (2021), 243–297.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Abdar et al. (2021) Moloud Abdar et al. 2021. 对深度学习中不确定性量化的综述：技术、应用及挑战。*信息融合*
    76 (2021), 243–297。
- en: Achlioptas et al. (2018) Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas,
    and Leonidas Guibas. 2018. Learning representations and generative models for
    3d point clouds. In *International conference on machine learning*. PMLR, 40–49.
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Achlioptas et al. (2018) Panos Achlioptas, Olga Diamanti, Ioannis Mitliagkas,
    和 Leonidas Guibas. 2018. 学习3D点云的表示和生成模型。在*国际机器学习会议*。PMLR, 40–49。
- en: 'Aggarwal et al. (2021a) Alankrita Aggarwal et al. 2021a. Generative adversarial
    network: An overview of theory and applications. *International Journal of Information
    Management Data Insights* 1, 1 (2021), 100004.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aggarwal et al. (2021a) Alankrita Aggarwal et al. 2021a. 生成对抗网络：理论和应用概述。*国际信息管理数据洞察杂志*
    1, 1 (2021), 100004。
- en: 'Aggarwal et al. (2021b) Alankrita Aggarwal, Mamta Mittal, and Gopi Battineni.
    2021b. Generative adversarial network: An overview of theory and applications.
    *International Journal of Information Management Data Insights* 1, 1 (2021), 100004.
    [https://doi.org/10.1016/j.jjimei.2020.100004](https://doi.org/10.1016/j.jjimei.2020.100004)'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Aggarwal et al. (2021b) Alankrita Aggarwal, Mamta Mittal, 和 Gopi Battineni.
    2021b. 生成对抗网络：理论和应用概述。*信息管理数据洞察国际期刊* 1, 1 (2021), 100004. [https://doi.org/10.1016/j.jjimei.2020.100004](https://doi.org/10.1016/j.jjimei.2020.100004)
- en: 'Akinosho et al. (2020) Taofeek D Akinosho et al. 2020. Deep learning in the
    construction industry: A review of present status and future innovations. *Journal
    of Building Engineering* 32 (2020), 101827.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Akinosho et al. (2020) Taofeek D Akinosho 等. 2020. 建筑行业中的深度学习：现状回顾和未来创新。*建筑工程期刊*
    32 (2020), 101827.
- en: Alom et al. (2019) Md Zahangir Alom et al. 2019. A state-of-the-art survey on
    deep learning theory and architectures. *electronics* 8, 3 (2019), 292.
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Alom et al. (2019) Md Zahangir Alom 等. 2019. 深度学习理论和架构的最新调查。*电子学* 8, 3 (2019),
    292.
- en: Appleton (1996) Jay Appleton. 1996. *The experience of landscape*. Wiley Chichester.
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Appleton (1996) Jay Appleton. 1996. *风景的体验*。Wiley Chichester。
- en: Arshad and Beksi (2020) Mohammad Samiul Arshad and William J Beksi. 2020. A
    progressive conditional generative adversarial network for generating dense and
    colored 3D point clouds. In *2020 International Conference on 3D Vision (3DV)*.
    IEEE, 712–722.
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Arshad 和 Beksi (2020) Mohammad Samiul Arshad 和 William J Beksi. 2020. 一种进阶条件生成对抗网络，用于生成密集且上色的3D点云。见于
    *2020年国际3D视觉会议 (3DV)*。IEEE, 712–722.
- en: 'Asmar and Sareen (2020) Karen El Asmar and Harpreet Sareen. 2020. Machinic
    Interpolations: A GAN Pipeline for Integrating Lateral Thinking in Computational
    Tools of Architecture. (2020).'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Asmar 和 Sareen (2020) Karen El Asmar 和 Harpreet Sareen. 2020. 机器插值：将侧向思维整合到建筑计算工具中的GAN管道。（2020）。
- en: ASSRU (1999) ASSRU. 1999. Algorithmic Social Sciences Research Unit (ASSRU).
    [http://www.assru.org/index.html](http://www.assru.org/index.html)
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: ASSRU (1999) ASSRU. 1999. 算法社会科学研究单位（ASSRU）。[http://www.assru.org/index.html](http://www.assru.org/index.html)
- en: Azizi et al. (2020) Vahid Azizi et al. 2020. Floorplan embedding with latent
    semantics and human behavior annotations. In *Proc. of the 11th Annual Symp. on
    Simulation for Architecture and Urban Design*. 1–8.
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Azizi et al. (2020) Vahid Azizi 等. 2020. 布局嵌入与潜在语义和人类行为注释。见于 *第11届建筑与城市设计模拟年会论文集*。1–8.
- en: 'Baduge et al. (2022) Shanaka Kristombu Baduge et al. 2022. Artificial intelligence
    and smart vision for building and construction 4.0: Machine and deep learning
    methods and applications. *Automation in Construction* 141 (2022), 104440.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Baduge et al. (2022) Shanaka Kristombu Baduge 等. 2022. 人工智能和智能视觉在建筑和施工4.0中的应用：机器和深度学习方法与应用。*建筑自动化*
    141 (2022), 104440.
- en: Bank et al. (2022) Mathias Bank, Viktoria Sandor, Kristina Schinegger, and Stefan
    Rutzinger. 2022. Learning Spatiality-A GAN method for designing architectural
    models through labelled sections. (2022).
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bank et al. (2022) Mathias Bank, Viktoria Sandor, Kristina Schinegger, 和 Stefan
    Rutzinger. 2022. 学习空间性——一种通过标记部分设计建筑模型的GAN方法。（2022）。
- en: Barsan-Pipu et al. (2020) Claudiu Barsan-Pipu, Nathalie Sleiman, and Theodor
    Moldovan. 2020. Affective Computing for Generating Virtual Procedural Environments
    Using Game Technologies. (2020).
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Barsan-Pipu et al. (2020) Claudiu Barsan-Pipu, Nathalie Sleiman, 和 Theodor Moldovan.
    2020. 利用游戏技术生成虚拟程序环境的情感计算。（2020）。
- en: Bartle (2004) Richard A Bartle. 2004. *Designing virtual worlds*. New Riders.
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bartle (2004) Richard A Bartle. 2004. *设计虚拟世界*。New Riders.
- en: 'Bartle (2010) Richard A Bartle. 2010. From MUDs to MMORPGs: The history of
    virtual worlds. *International handbook of internet research* (2010), 23–39.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bartle (2010) Richard A Bartle. 2010. 从MUDs到MMORPGs：虚拟世界的历史。*互联网研究国际手册* (2010),
    23–39.
- en: Bava (2020) Alessandro Bava. 2020. Computational Tendencies. [https://www.e-flux.com/architecture/intelligence/310405/computational-tendencies/](https://www.e-flux.com/architecture/intelligence/310405/computational-tendencies/)
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bava (2020) Alessandro Bava. 2020. 计算倾向。[https://www.e-flux.com/architecture/intelligence/310405/computational-tendencies/](https://www.e-flux.com/architecture/intelligence/310405/computational-tendencies/)
- en: Ben-Hamu et al. (2018) Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri,
    and Yaron Lipman. 2018. Multi-chart generative surface modeling. *ACM Transactions
    on Graphics (TOG)* 37, 6 (2018), 1–15.
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ben-Hamu et al. (2018) Heli Ben-Hamu, Haggai Maron, Itay Kezurer, Gal Avineri,
    和 Yaron Lipman. 2018. 多图生成表面建模。*ACM图形学期刊 (TOG)* 37, 6 (2018), 1–15.
- en: 'Bottazzi (2018) Roberto Bottazzi. 2018. *Digital architecture beyond computers:
    Fragments of a cultural history of computational design*. Bloomsbury Publishing.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Bottazzi (2018) Roberto Bottazzi. 2018. *计算机之外的数字建筑：计算设计的文化历史碎片*。Bloomsbury
    Publishing。
- en: Brock et al. (2016) Andrew Brock, Theodore Lim, James M Ritchie, and Nick Weston.
    2016. Generative and discriminative voxel modeling with convolutional neural networks.
    *arXiv preprint arXiv:1608.04236* (2016).
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Brock et al. (2016) Andrew Brock, Theodore Lim, James M Ritchie, 和 Nick Weston.
    2016. 使用卷积神经网络的生成与判别体素建模。*arXiv预印本arXiv:1608.04236* (2016)。
- en: Cai et al. (2020) Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao,
    Serge Belongie, Noah Snavely, and Bharath Hariharan. 2020. Learning gradient fields
    for shape generation. In *European Conference on Computer Vision*. Springer, 364–381.
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cai et al. (2020) Ruojin Cai, Guandao Yang, Hadar Averbuch-Elor, Zekun Hao,
    Serge Belongie, Noah Snavely, 和 Bharath Hariharan. 2020. 学习梯度场进行形状生成。见于 *欧洲计算机视觉会议*。Springer，364–381。
- en: Çakmak (2022) Başak Çakmak. 2022. *Extending design cognition with computer
    vision and generative deep learning*. Master’s thesis. Middle East Technical University.
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Çakmak (2022) Başak Çakmak. 2022. *通过计算机视觉和生成对抗深度学习扩展设计认知*。硕士论文。中东技术大学。
- en: Cao et al. (2020) Wenming Cao, Zhiyue Yan, Zhiquan He, and Zhihai He. 2020.
    A comprehensive survey on geometric deep learning. *IEEE Access* 8 (2020), 35929–35949.
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cao et al. (2020) Wenming Cao, Zhiyue Yan, Zhiquan He, 和 Zhihai He. 2020. 几何深度学习的综合调查。*IEEE
    Access* 8 (2020), 35929–35949。
- en: 'Chaillou (2020) Stanislas Chaillou. 2020. Archigan: Artificial intelligence
    x architecture. In *Architectural intelligence*. Springer, 117–127.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaillou (2020) Stanislas Chaillou. 2020. Archigan：人工智能 x 建筑。见于 *建筑智能*。Springer，117–127。
- en: Chaillou (2022) Stanislas Chaillou. 2022. The advent of architectural AI. In
    *Artificial Intelligence and Architecture*. Birkhäuser, 32–61.
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaillou (2022) Stanislas Chaillou. 2022. 建筑人工智能的到来。见于 *人工智能与建筑*。Birkhäuser，32–61。
- en: Chaitin (1975a) Gregory J Chaitin. 1975a. Randomness and mathematical proof.
    *Scientific American* 232, 5 (1975), 47–53.
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaitin (1975a) Gregory J Chaitin. 1975a. 随机性与数学证明。*科学美国人* 232, 5 (1975), 47–53。
- en: Chaitin (1975b) Gregory J Chaitin. 1975b. A theory of program size formally
    identical to information theory. *Journal of the ACM (JACM)* 22, 3 (1975), 329–340.
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chaitin (1975b) Gregory J Chaitin. 1975b. 一种形式上与信息理论相同的程序大小理论。*ACM期刊（JACM）*
    22, 3 (1975), 329–340。
- en: 'Chan et al. (2021) Eric R Chan et al. 2021. pi-gan: Periodic implicit generative
    adversarial networks for 3d-aware image synthesis. In *Proceedings of the IEEE/CVF
    conference on computer vision and pattern recognition*. 5799–5809.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chan et al. (2021) Eric R Chan 等. 2021. pi-gan：用于3D感知图像合成的周期性隐式生成对抗网络。见于 *IEEE/CVF计算机视觉与模式识别会议论文集*。5799–5809。
- en: 'Chen et al. (2018) Kevin Chen, Christopher B Choy, Manolis Savva, Angel X Chang,
    Thomas Funkhouser, and Silvio Savarese. 2018. Text2shape: Generating shapes from
    natural language by learning joint embeddings. In *Asian conference on computer
    vision*. Springer, 100–116.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen et al. (2018) Kevin Chen, Christopher B Choy, Manolis Savva, Angel X Chang,
    Thomas Funkhouser, 和 Silvio Savarese. 2018. Text2shape：通过学习联合嵌入从自然语言生成形状。见于 *亚洲计算机视觉会议*。Springer，100–116。
- en: Chen and Zhang (2019) Zhiqin Chen and Hao Zhang. 2019. Learning implicit fields
    for generative shape modeling. In *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*. 5939–5948.
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Chen and Zhang (2019) Zhiqin Chen 和 Hao Zhang. 2019. 学习隐式场进行生成形状建模。见于 *IEEE/CVF计算机视觉与模式识别会议论文集*。5939–5948。
- en: 'Cheng et al. (2019) Lung-Pan Cheng, Eyal Ofek, Christian Holz, and Andrew D.
    Wilson. 2019. VRoamer: Generating On-The-Fly VR Experiences While Walking inside
    Large, Unknown Real-World Building Environments. In *2019 IEEE Conference on Virtual
    Reality and 3D User Interfaces (VR)*. 359–366. [https://doi.org/10.1109/VR.2019.8798074](https://doi.org/10.1109/VR.2019.8798074)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Cheng et al. (2019) Lung-Pan Cheng, Eyal Ofek, Christian Holz, 和 Andrew D. Wilson.
    2019. VRoamer：在大型未知现实世界建筑环境中行走时生成即时虚拟现实体验。见于 *2019 IEEE虚拟现实与三维用户界面会议（VR）*。359–366。
    [https://doi.org/10.1109/VR.2019.8798074](https://doi.org/10.1109/VR.2019.8798074)
- en: Claypool (2019) Mollie Claypool. 2019. Discrete automation - architecture -
    e-flux. [https://www.e-flux.com/architecture/becoming-digital/248060/discrete-automation/](https://www.e-flux.com/architecture/becoming-digital/248060/discrete-automation/)
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Claypool (2019) Mollie Claypool. 2019. 离散自动化 - 建筑 - e-flux。 [https://www.e-flux.com/architecture/becoming-digital/248060/discrete-automation/](https://www.e-flux.com/architecture/becoming-digital/248060/discrete-automation/)
- en: 'Creswell et al. (2018) Antonia Creswell, Tom White, Vincent Dumoulin, Kai Arulkumaran,
    Biswa Sengupta, and Anil A Bharath. 2018. Generative adversarial networks: An
    overview. *IEEE signal processing magazine* 35, 1 (2018), 53–65.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Creswell et al. (2018) Antonia Creswell, Tom White, Vincent Dumoulin, Kai Arulkumaran,
    Biswa Sengupta 和 Anil A Bharath，2018年。《生成对抗网络概述》。*IEEE信号处理杂志* 35, 1 (2018)，53–65。
- en: 'Croitoru et al. (2023) Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu,
    and Mubarak Shah. 2023. Diffusion models in vision: A survey. *IEEE Transactions
    on Pattern Analysis and Machine Intelligence* (2023).'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Croitoru et al. (2023) Florinel-Alin Croitoru, Vlad Hondru, Radu Tudor Ionescu
    和 Mubarak Shah，2023年。《视觉中的扩散模型：调查》。*IEEE模式分析与机器智能汇刊* (2023)。
- en: 'Dargan et al. (2020) Shaveta Dargan et al. 2020. A survey of deep learning
    and its applications: a new paradigm to machine learning. *Archives of Computational
    Methods in Engineering* 27 (2020), 1071–1092.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dargan et al. (2020) Shaveta Dargan 等人，2020年。《深度学习及其应用调查：机器学习的新范式》。*计算方法工程档案*
    27 (2020)，1071–1092。
- en: de Miguel et al. (2019) Jaime de Miguel et al. 2019. Deep Form Finding Using
    Variational Autoencoders for deep form finding of structural typologies. In *37th
    Conference on Education and Research in Computer Aided Architectural Design in
    Europe (eCAADe) & 23rd Conference of the Iberoamerican Society Digital Graphics
    (SIGraDi)*.
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: de Miguel et al. (2019) Jaime de Miguel 等人，2019年。《利用变分自编码器进行深度形状发现：对结构类型的深度形状发现》。收录于
    *第37届欧洲计算机辅助建筑设计教育与研究会议（eCAADe）与第23届伊比利亚美洲数字图形学会议（SIGraDi）*。
- en: del Campo (2021) Matias del Campo. 2021. Architecture, language and AI-language,
    attentional generative adversarial networks (AttnGAN) and architecture design.
    (2021).
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: del Campo (2021) Matias del Campo，2021年。《建筑、语言与人工智能—语言、注意力生成对抗网络（AttnGAN）与建筑设计》。
    (2021)。
- en: Del Campo et al. (2019) Matias Del Campo, Sandra Manninger, M Sanche, and L
    Wang. 2019. The Church of AI—An examination of architecture in a posthuman design
    ecology. In *Intelligent & Informed-Proceedings of the 24th CAADRIA Conference,
    Victoria University of Wellington, Wellington, New Zealand*. 15–18.
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Del Campo et al. (2019) Matias Del Campo, Sandra Manninger, M Sanche 和 L Wang，2019年。《AI的教堂—后人类设计生态中的建筑审视》。收录于
    *第24届CAADRIA会议，维多利亚大学，惠灵顿，新西兰*。15–18。
- en: del Campo et al. (2022) Matias del Campo, Sandra Manninger, and Yining Yuan.
    2022. Generali Center vienna austria. [https://caadria2022.org/projects/generali-center-vienna-austria/](https://caadria2022.org/projects/generali-center-vienna-austria/)
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: del Campo et al. (2022) Matias del Campo, Sandra Manninger 和 Yining Yuan，2022年。《Generali中心维也纳奥地利》。
    [https://caadria2022.org/projects/generali-center-vienna-austria/](https://caadria2022.org/projects/generali-center-vienna-austria/)
- en: 'Deng et al. (2020) Jiajun Deng, Shaoshuai Shi, Pei-Cian Li, Wen gang Zhou,
    Yanyong Zhang, and Houqiang Li. 2020. Voxel R-CNN: Towards High Performance Voxel-based
    3D Object Detection. *ArXiv* abs/2012.15712 (2020).'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Deng et al. (2020) Jiajun Deng, Shaoshuai Shi, Pei-Cian Li, Wen gang Zhou,
    Yanyong Zhang 和 Houqiang Li，2020年。《Voxel R-CNN: 朝向高性能体素基础的3D目标检测》。*ArXiv* abs/2012.15712
    (2020)。'
- en: 'Deng et al. (2021) Yu Deng, Jiaolong Yang, and Xin Tong. 2021. Deformed implicit
    field: Modeling 3d shapes with learned dense correspondence. In *Proceedings of
    the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 10286–10296.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Deng et al. (2021) Yu Deng, Jiaolong Yang 和 Xin Tong，2021年。《变形隐式场：利用学习的稠密对应建模3D形状》。收录于
    *IEEE/CVF计算机视觉与模式识别会议论文集*，10286–10296。
- en: Di Carlo et al. (2022) Raffaele Di Carlo, Divyae Mittal, and Ondrej Veselỳ.
    2022. Generating 3D Building Volumes for a Given Urban Context using Pix2Pix GAN.
    *Legal Depot D/2022/14982/02* (2022), 287.
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Di Carlo et al. (2022) Raffaele Di Carlo, Divyae Mittal 和 Ondrej Veselỳ，2022年。《利用Pix2Pix
    GAN生成给定城市背景的3D建筑体积》。*法律文献 D/2022/14982/02* (2022)，287。
- en: Ding et al. (2022) Xinyue Ding, Xiangmin Guo, Tian Tian Lo, and Ke Wang. 2022.
    The Spatial Environment Affects Human Emotion Perception-Using Physiological Signal
    Modes. (2022).
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ding et al. (2022) Xinyue Ding, Xiangmin Guo, Tian Tian Lo 和 Ke Wang，2022年。《空间环境影响人类情感感知—利用生理信号模式》。
    (2022)。
- en: 'Dinh et al. (2014) Laurent Dinh, David Krueger, and Yoshua Bengio. 2014. Nice:
    Non-linear independent components estimation. *arXiv preprint arXiv:1410.8516*
    (2014).'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Dinh et al. (2014) Laurent Dinh, David Krueger 和 Yoshua Bengio，2014年。《Nice:
    非线性独立成分估计》。*arXiv预印本 arXiv:1410.8516* (2014)。'
- en: Diniz et al. (2019) Nancy Diniz, Frank Melendez, Woraya Boonyapanachoti, and
    Sebastian Morales. 2019. Body Architectures-Real time data visualization and responsive
    immersive environments. (2019).
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Diniz et al. (2019) Nancy Diniz, Frank Melendez, Woraya Boonyapanachoti 和 Sebastian
    Morales，2019年。《体态架构—实时数据可视化与响应式沉浸式环境》。 (2019)。
- en: 'Dionisio et al. (2013) John David N Dionisio, William G Burns III, and Richard
    Gilbert. 2013. 3D virtual worlds and the metaverse: Current status and future
    possibilities. *ACM Computing Surveys (CSUR)* 45, 3 (2013), 1–38.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dionisio et al. (2013) John David N Dionisio, William G Burns III, 和 Richard
    Gilbert. 2013. 3D 虚拟世界和元宇宙：当前状态及未来可能性。*ACM Computing Surveys (CSUR)* 45, 3 (2013),
    1–38.
- en: Dong et al. (2021) Shi Dong, Ping Wang, and Khushnood Abbas. 2021. A survey
    on deep learning and its applications. *Computer Science Review* 40 (2021), 100379.
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Dong et al. (2021) Shi Dong, Ping Wang, 和 Khushnood Abbas. 2021. 深度学习及其应用的综述。*Computer
    Science Review* 40 (2021), 100379.
- en: 'Fan et al. (2022) Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar. 2022.
    Minedojo: Building open-ended embodied agents with internet-scale knowledge. *arXiv
    preprint arXiv:2206.08853* (2022).'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fan et al. (2022) Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong
    Yang, Haoyi Zhu, Andrew Tang, De-An Huang, Yuke Zhu, 和 Anima Anandkumar. 2022.
    Minedojo: 构建具有互联网规模知识的开放式具身智能体。*arXiv preprint arXiv:2206.08853* (2022).'
- en: 'Fu et al. (2022) Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, and Srinath
    Sridhar. 2022. Shapecrafter: A recursive text-conditioned 3d shape generation
    model. *arXiv preprint arXiv:2207.09446* (2022).'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Fu et al. (2022) Rao Fu, Xiao Zhan, Yiwen Chen, Daniel Ritchie, 和 Srinath Sridhar.
    2022. Shapecrafter: 一种递归文本条件的 3D 形状生成模型。*arXiv preprint arXiv:2207.09446* (2022).'
- en: 'Gao et al. (2022) Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue
    Yin, Daiqing Li, Or Litany, Zan Gojcic, and Sanja Fidler. 2022. Get3d: A generative
    model of high quality 3d textured shapes learned from images. *Advances In Neural
    Information Processing Systems* 35 (2022), 31841–31854.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao et al. (2022) Jun Gao, Tianchang Shen, Zian Wang, Wenzheng Chen, Kangxue
    Yin, Daiqing Li, Or Litany, Zan Gojcic, 和 Sanja Fidler. 2022. Get3d: 一种从图像中学习的高质量
    3D 纹理形状生成模型。*Advances In Neural Information Processing Systems* 35 (2022), 31841–31854.'
- en: 'Gao et al. (2019) Lin Gao et al. 2019. SDM-NET: Deep generative network for
    structured deformable mesh. *ACM Transactions on Graphics (TOG)* 38, 6 (2019),
    1–15.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao et al. (2019) Lin Gao 等人 2019. SDM-NET: 用于结构化可变形网格的深度生成网络。*ACM Transactions
    on Graphics (TOG)* 38, 6 (2019), 1–15.'
- en: 'Gao et al. (2021) Lin Gao, Tong Wu, Yu-Jie Yuan, Ming-Xian Lin, Yu-Kun Lai,
    and Hao Zhang. 2021. Tm-net: Deep generative networks for textured meshes. *ACM
    Transactions on Graphics (TOG)* 40, 6 (2021), 1–15.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gao et al. (2021) Lin Gao, Tong Wu, Yu-Jie Yuan, Ming-Xian Lin, Yu-Kun Lai,
    和 Hao Zhang. 2021. Tm-net: 用于纹理网格的深度生成网络。*ACM Transactions on Graphics (TOG)*
    40, 6 (2021), 1–15.'
- en: Genova et al. (2019) Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna,
    William T Freeman, and Thomas Funkhouser. 2019. Learning shape templates with
    structured implicit functions. In *Proceedings of the IEEE/CVF International Conference
    on Computer Vision*. 7154–7164.
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Genova et al. (2019) Kyle Genova, Forrester Cole, Daniel Vlasic, Aaron Sarna,
    William T Freeman, 和 Thomas Funkhouser. 2019. 使用结构化隐式函数学习形状模板。见 *Proceedings of
    the IEEE/CVF International Conference on Computer Vision*. 7154–7164.
- en: 'Gilbert (2011) RL Gilbert. 2011. The PROSE Project: A program of in-world behavioral
    research on the Metaverse. *Journal of Virtual Worlds Research* 4, 1 (2011), 3–18.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gilbert (2011) RL Gilbert. 2011. PROSE 项目：一个关于元宇宙的世界内行为研究计划。*Journal of Virtual
    Worlds Research* 4, 1 (2011), 3–18.
- en: 'Gu et al. (2021) Jiatao Gu, Lingjie Liu, Peng Wang, and Christian Theobalt.
    2021. Stylenerf: A style-based 3d-aware generator for high-resolution image synthesis.
    *arXiv preprint arXiv:2110.08985* (2021).'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Gu et al. (2021) Jiatao Gu, Lingjie Liu, Peng Wang, 和 Christian Theobalt. 2021.
    Stylenerf: 一种基于风格的 3D 感知生成器，用于高分辨率图像合成。*arXiv preprint arXiv:2110.08985* (2021).'
- en: 'Guida (2023) George Guida. 2023. Multimodal Architecture: Applications of language
    in a machine learning aided design process. (2023).'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guida (2023) George Guida. 2023. 多模态建筑：机器学习辅助设计过程中的语言应用。 (2023).
- en: Gulrajani et al. (2017) Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent
    Dumoulin, and Aaron C Courville. 2017. Improved training of wasserstein gans.
    *Advances in neural information processing systems* 30 (2017).
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Gulrajani et al. (2017) Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent
    Dumoulin, 和 Aaron C Courville. 2017. 改进的 Wasserstein GANs 训练方法。*Advances in neural
    information processing systems* 30 (2017).
- en: 'Guo et al. (2020) Yulan Guo, Hanyun Wang, Qingyong Hu, Hao Liu, Li Liu, and
    Mohammed Bennamoun. 2020. Deep learning for 3d point clouds: A survey. *IEEE transactions
    on pattern analysis and machine intelligence* 43, 12 (2020), 4338–4364.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2020) Yulan Guo, Hanyun Wang, Qingyong Hu, Hao Liu, Li Liu, 和 Mohammed
    Bennamoun. 2020. 深度学习在 3D 点云中的应用：综述。*IEEE transactions on pattern analysis and
    machine intelligence* 43, 12 (2020), 4338–4364.
- en: Guo et al. (2021) Zhe Guo et al. 2021. The method of responsive shape design
    based on real-time interaction process. (2021).
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Guo et al. (2021) Zhe Guo 等人 2021. 基于实时交互过程的响应形状设计方法。 (2021).
- en: Hall et al. (1968) Edward T Hall, Ray L Birdwhistell, Bernhard Bock, Paul Bohannan,
    A Richard Diebold Jr, Marshall Durbin, Munro S Edmonson, JL Fischer, Dell Hymes,
    Solon T Kimball, et al. 1968. Proxemics [and comments and replies]. *Current anthropology*
    9, 2/3 (1968), 83–108.
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hall 等人 (1968) Edward T Hall, Ray L Birdwhistell, Bernhard Bock, Paul Bohannan,
    A Richard Diebold Jr, Marshall Durbin, Munro S Edmonson, JL Fischer, Dell Hymes,
    Solon T Kimball 等人. 1968. 个人空间学 [及评论与回复]。*当前人类学* 9, 2/3 (1968), 83–108。
- en: 'Hao et al. (2020) Zekun Hao et al. 2020. Dualsdf: Semantic shape manipulation
    using a two-level representation. In *Proceedings of the IEEE/CVF Conference on
    Computer Vision and Pattern Recognition*. 7631–7641.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hao 等人 (2020) Zekun Hao 等人. 2020. Dualsdf：使用两级表示进行语义形状操控。载于 *IEEE/CVF 计算机视觉与模式识别会议论文集*。7631–7641。
- en: Harshvardhan et al. (2020) GM Harshvardhan et al. 2020. A comprehensive survey
    and analysis of generative models in machine learning. *Computer Science Review*
    38 (2020), 100285.
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Harshvardhan 等人 (2020) GM Harshvardhan 等人. 2020. 机器学习中生成模型的综合调查与分析。*计算机科学评论*
    38 (2020), 100285。
- en: 'Hatcher and Yu (2018) William Grant Hatcher and Wei Yu. 2018. A survey of deep
    learning: Platforms, applications and emerging research trends. *IEEE Access*
    6 (2018), 24411–24432.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hatcher 和 Yu (2018) William Grant Hatcher 和 Wei Yu. 2018. 深度学习的调查：平台、应用与新兴研究趋势。*IEEE
    Access* 6 (2018), 24411–24432。
- en: 'Henzler et al. (2019) Philipp Henzler, Niloy J Mitra, and Tobias Ritschel.
    2019. Escaping plato’s cave: 3d shape from adversarial rendering. In *Proceedings
    of the IEEE/CVF International Conference on Computer Vision*. 9984–9993.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Henzler 等人 (2019) Philipp Henzler, Niloy J Mitra, 和 Tobias Ritschel. 2019. 逃离柏拉图的洞穴：从对抗渲染中获得的
    3D 形状。载于 *IEEE/CVF 国际计算机视觉会议论文集*。9984–9993。
- en: Ho et al. (2020a) Jonathan Ho, Ajay Jain, and P. Abbeel. 2020a. Denoising Diffusion
    Probabilistic Models. *ArXiv* abs/2006.11239 (2020).
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho 等人 (2020a) Jonathan Ho, Ajay Jain, 和 P. Abbeel. 2020a. 去噪扩散概率模型。*ArXiv* abs/2006.11239
    (2020)。
- en: Ho et al. (2020b) Jonathan Ho, Ajay Jain, and Pieter Abbeel. 2020b. Denoising
    diffusion probabilistic models. *Advances in Neural Information Processing Systems*
    33 (2020), 6840–6851.
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ho 等人 (2020b) Jonathan Ho, Ajay Jain, 和 Pieter Abbeel. 2020b. 去噪扩散概率模型。*神经信息处理系统进展*
    33 (2020), 6840–6851。
- en: Homolja et al. (2020) Mitra Homolja, Sayyed Amir Hossain Maghool, and Marc Aurel
    Schnabel. 2020. The Impact of Moving through the Built Environment on Emotional
    and Neurophysiological State-A Systematic Literature Review. (2020).
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Homolja 等人 (2020) Mitra Homolja, Sayyed Amir Hossain Maghool, 和 Marc Aurel Schnabel.
    2020. 移动穿越建筑环境对情感和神经生理状态的影响——系统文献综述。 (2020)。
- en: Hong et al. (2020) Tianzhen Hong, Zhe Wang, Xuan Luo, and Wanni Zhang. 2020.
    State-of-the-art on research and applications of machine learning in the building
    life cycle. *Energy and Buildings* 212 (2020), 109831.
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Hong 等人 (2020) Tianzhen Hong, Zhe Wang, Xuan Luo, 和 Wanni Zhang. 2020. 机器学习在建筑生命周期中的研究与应用的最新进展。*能源与建筑*
    212 (2020), 109831。
- en: 'Huang et al. (2021) Jeffrey Huang, Mikhael Johanes, Frederick Chando Kim, Christina
    Doumpioti, and Georg-Christoph Holz. 2021. On gans, nlp and architecture: Combining
    human and machine intelligences for the generation and evaluation of meaningful
    designs. *Technology— Architecture+ Design* 5, 2 (2021), 207–224.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Huang 等人 (2021) Jeffrey Huang, Mikhael Johanes, Frederick Chando Kim, Christina
    Doumpioti, 和 Georg-Christoph Holz. 2021. 关于生成对抗网络、自然语言处理和建筑：结合人类与机器智能进行有意义设计的生成与评估。*技术—建筑+设计*
    5, 2 (2021), 207–224。
- en: 'Hui et al. (2020) Le Hui, Rui Xu, Jin Xie, Jianjun Qian, and Jian Yang. 2020.
    Progressive point cloud deconvolution generation network. In *Computer Vision–ECCV
    2020: 16th European Conference, Glasgow, UK, August 23–28, 2020, Proceedings,
    Part XV 16*. Springer, 397–413.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Hui 等人 (2020) Le Hui, Rui Xu, Jin Xie, Jianjun Qian, 和 Jian Yang. 2020. 渐进点云解卷积生成网络。载于
    *计算机视觉–ECCV 2020: 第16届欧洲会议，英国格拉斯哥，2020年8月23–28日，会议论文集，第十五部分 16*。Springer，397–413。'
- en: Ibing et al. (2021) Moritz Ibing, Isaak Lim, and Leif Kobbelt. 2021. 3D shape
    generation with grid-based implicit functions. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*. 13559–13568.
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ibing 等人 (2021) Moritz Ibing, Isaak Lim, 和 Leif Kobbelt. 2021. 基于网格的隐式函数的 3D
    形状生成。载于 *IEEE/CVF 计算机视觉与模式识别会议论文集*。13559–13568。
- en: 'Ingram et al. (1996) Rob Ingram et al. 1996. Building Virtual Cities: applying
    urban planning principles to the design of virtual environments. In *Proceedings
    of the ACM Symposium on Virtual Reality Software and Technology*. 83–91.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ingram 等人 (1996) Rob Ingram 等人. 1996. 建造虚拟城市：将城市规划原则应用于虚拟环境的设计。载于 *ACM 虚拟现实软件与技术研讨会论文集*。83–91。
- en: 'Jabbar et al. (2021) Abdul Jabbar, Xi Li, and Bourahla Omar. 2021. A survey
    on generative adversarial networks: Variants, applications, and training. *ACM
    Computing Surveys (CSUR)* 54, 8 (2021), 1–49.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jabbar 等（2021）Abdul Jabbar, Xi Li 和 Bourahla Omar，2021。《生成对抗网络的综述：变体、应用及训练》。*ACM计算机调查（CSUR）*
    54, 8（2021），1–49。
- en: Jacobs (2016) Jane Jacobs. 2016. *The death and life of great American cities*.
    Vintage.
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jacobs（2016）Jane Jacobs，2016。《*伟大的美国城市的生与死*》。Vintage。
- en: Jahan et al. (2021) Tansin Jahan, Yanran Guan, and Oliver Van Kaick. 2021. Semantics-Guided
    Latent Space Exploration for Shape Generation. In *Computer Graphics Forum*, Vol. 40\.
    Wiley Online Library, 115–126.
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jahan 等（2021）Tansin Jahan, Yanran Guan 和 Oliver Van Kaick，2021。《基于语义引导的潜在空间探索用于形状生成》。在
    *计算机图形学论坛*，第 40 卷。Wiley Online Library，115–126。
- en: Jain et al. (2022) Ajay Jain et al. 2022. Zero-shot text-guided object generation
    with dream fields. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*. 867–876.
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jain 等（2022）Ajay Jain 等人，2022。《基于文本引导的零-shot目标生成与梦想场》。在 *IEEE/CVF计算机视觉与模式识别会议论文集*
    中，867–876。
- en: 'Jaminet et al. (2021) Jean Jaminet et al. 2021. Serlio and Artificial Intelligence:
    Problematizing the Image-to-Object Workflow. In *The International Conference
    on Computational Design and Robotic Fabrication*. Springer, 3–12.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jaminet 等（2021）Jean Jaminet 等人，2021。《Serlio 和人工智能：问题化图像到对象的工作流程》。在 *国际计算设计与机器人制造会议*
    中，Springer，3–12。
- en: 'Jang and Agapito (2021) Wonbong Jang and Lourdes Agapito. 2021. Codenerf: Disentangled
    neural radiance fields for object categories. In *Proceedings of the IEEE/CVF
    International Conference on Computer Vision*. 12949–12958.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jang 和 Agapito（2021）Wonbong Jang 和 Lourdes Agapito，2021。《Codenerf：针对对象类别的解耦神经辐射场》。在
    *IEEE/CVF国际计算机视觉会议论文集* 中，12949–12958。
- en: Jetchev et al. (2016) Nikolay Jetchev, Urs Bergmann, and Roland Vollgraf. 2016.
    Texture synthesis with spatial generative adversarial networks. *arXiv preprint
    arXiv:1611.08207* (2016).
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jetchev 等（2016）Nikolay Jetchev, Urs Bergmann 和 Roland Vollgraf，2016。《利用空间生成对抗网络进行纹理合成》。*arXiv
    预印本 arXiv:1611.08207*（2016）。
- en: Jonassen and Rohrer-Murphy (1999) David H Jonassen and Lucia Rohrer-Murphy.
    1999. Activity theory as a framework for designing constructivist learning environments.
    *Educational technology research and development* 47, 1 (1999), 61–79.
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jonassen 和 Rohrer-Murphy（1999）David H Jonassen 和 Lucia Rohrer-Murphy，1999。《作为构建主义学习环境设计框架的活动理论》。*教育技术研究与发展*
    47, 1（1999），61–79。
- en: Jovanovic (2022) Damjan Jovanovic. 2022. Games and Worldmaking. [https://journal.b-pro.org/article/p3-games-and-worldmaking/](https://journal.b-pro.org/article/p3-games-and-worldmaking/)
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Jovanovic（2022）Damjan Jovanovic，2022。《游戏与世界创作》。 [https://journal.b-pro.org/article/p3-games-and-worldmaking/](https://journal.b-pro.org/article/p3-games-and-worldmaking/)
- en: Kahraman et al. (2021) Ridvan Kahraman et al. 2021. Augmenting Design. (2021).
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kahraman 等（2021）Ridvan Kahraman 等人，2021。《增强设计》。 （2021）。
- en: Karras et al. (2019) Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based
    generator architecture for generative adversarial networks. In *Proceedings of
    the IEEE/CVF conference on computer vision and pattern recognition*. 4401–4410.
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Karras 等（2019）Tero Karras, Samuli Laine 和 Timo Aila，2019。《一种基于风格的生成对抗网络生成器架构》。在
    *IEEE/CVF计算机视觉与模式识别会议论文集* 中，4401–4410。
- en: 'Kavakoglu (2021) Aysegul Akcay Kavakoglu. 2021. Computational Aesthetics of
    Low Poly: [Re]Configuration of Form. *Blucher Design Proceedings* 9, 6 (2021),
    17–28. [https://doi.org/10.5151/sigradi2021-235](https://doi.org/10.5151/sigradi2021-235)'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kavakoglu（2021）Aysegul Akcay Kavakoglu，2021。《低多边形的计算美学：*[形式的重新配置]*》。*Blucher设计论文集*
    9, 6（2021），17–28。 [https://doi.org/10.5151/sigradi2021-235](https://doi.org/10.5151/sigradi2021-235)
- en: Keil et al. (2021) Julian Keil et al. 2021. Creating immersive virtual environments
    based on open geospatial data and game engines. *KN-Journal of Cartography and
    Geographic Information* 71, 1 (2021), 53–65.
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Keil 等（2021）Julian Keil 等人，2021。《基于开放地理空间数据和游戏引擎创建沉浸式虚拟环境》。*KN-制图与地理信息杂志* 71,
    1（2021），53–65。
- en: Khan et al. (2020) Asifullah Khan, Anabia Sohail, Umme Zahoora, and Aqsa Saeed
    Qureshi. 2020. A survey of the recent architectures of deep convolutional neural
    networks. *Artificial intelligence review* 53 (2020), 5455–5516.
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Khan 等（2020）Asifullah Khan, Anabia Sohail, Umme Zahoora 和 Aqsa Saeed Qureshi，2020。《深度卷积神经网络的最新架构综述》。*人工智能评论*
    53（2020），5455–5516。
- en: KIM et al. (2022) DONGYUN KIM, GEORGE GUIDA, JOSE LUIS GARCÍA, and DEL CASTILLO Y
    LÓPEZ. 2022. PARTICIPATORY URBAN DESIGN WITH GENERATIVE ADVERSARIAL NETWORKS.
    (2022).
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: KIM 等（2022）DONGYUN KIM, GEORGE GUIDA, JOSE LUIS GARCÍA 和 DEL CASTILLO Y LÓPEZ，2022。《利用生成对抗网络的参与式城市设计》。
    （2022）。
- en: Kim and Huang (2022) Frederick Chando Kim and Jeffrey Huang. 2022. Perspectival
    GAN-Architectural form-making through dimensional transformation. (2022).
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kim 和 Huang (2022) Frederick Chando Kim 和 Jeffrey Huang。2022年。透视 GAN—通过维度转换进行建筑形式创作。(2022)。
- en: Kingma et al. (2019) Diederik P. Kingma et al. 2019. An Introduction to Variational
    Autoencoders. *ArXiv* abs/1906.02691 (2019).
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kingma 等 (2019) Diederik P. Kingma 等。2019年。变分自编码器简介。*ArXiv* abs/1906.02691 (2019)。
- en: Kleineberg et al. (2020) Marian Kleineberg, Matthias Fey, and Frank Weichert.
    2020. Adversarial generation of continuous implicit shape representations. *arXiv
    preprint arXiv:2002.00349* (2020).
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kleineberg 等 (2020) Marian Kleineberg, Matthias Fey 和 Frank Weichert。2020年。连续隐式形状表示的对抗生成。*arXiv
    预印本 arXiv:2002.00349* (2020)。
- en: Koh (2022) Immanuel Koh. 2022. 3D-Gan-Housing (neural sampling series). [https://caadria2022.org/projects/3d-gan-housing-neural-sampling-series/](https://caadria2022.org/projects/3d-gan-housing-neural-sampling-series/)
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Koh (2022) Immanuel Koh。2022年。3D-Gan-Housing（神经采样系列）。[https://caadria2022.org/projects/3d-gan-housing-neural-sampling-series/](https://caadria2022.org/projects/3d-gan-housing-neural-sampling-series/)
- en: 'Kreuzberger et al. (2023) Dominik Kreuzberger, Niklas Kühl, and Sebastian Hirschl.
    2023. Machine learning operations (mlops): Overview, definition, and architecture.
    *IEEE Access* (2023).'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kreuzberger 等 (2023) Dominik Kreuzberger, Niklas Kühl 和 Sebastian Hirschl。2023年。机器学习操作
    (mlops)：概述、定义和架构。*IEEE Access* (2023)。
- en: Kwiecinski et al. (2017) Krystian Kwiecinski, Jacek Markusiewicz, and Agata
    Pasternak. 2017. Participatory Design Supported with Design System and Augmented
    Reality. (2017).
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Kwiecinski 等 (2017) Krystian Kwiecinski, Jacek Markusiewicz 和 Agata Pasternak。2017年。支持设计系统和增强现实的参与设计。(2017)。
- en: Lab (2023) Tencent AI Lab. 2023. AI enhanced procedural city generation. [https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City](https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City)
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 实验室 (2023) 腾讯 AI 实验室。2023年。AI 增强的过程城市生成。[https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City](https://gdcvault.com/play/1028921/Recorded-AI-Enhanced-Procedural-City)
- en: 'Lam et al. (2019) Kit Yung Lam et al. 2019. M2a: A framework for visualizing
    information from mobile web to mobile augmented reality. In *2019 IEEE International
    Conference on Pervasive Computing and Communications (PerCom*. IEEE, 1–10.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lam 等 (2019) Kit Yung Lam 等。2019年。M2a：一个从移动网页到移动增强现实的信息可视化框架。在*2019 IEEE 现代计算和通信国际会议
    (PerCom)*。IEEE，1–10。
- en: LeCun et al. (2010) Yann LeCun, Corinna Cortes, and Chris Burges. 2010. MNIST
    handwritten digit database.
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: LeCun 等 (2010) Yann LeCun, Corinna Cortes 和 Chris Burges。2010年。MNIST 手写数字数据库。
- en: Ledig et al. (2017) Christian Ledig et al. 2017. Photo-realistic single image
    super-resolution using a generative adversarial network. In *Proceedings of the
    IEEE conference on computer vision and pattern recognition*. 4681–4690.
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ledig 等 (2017) Christian Ledig 等。2017年。使用生成对抗网络的照片级单图像超分辨率。在*IEEE 计算机视觉与模式识别会议论文集*。4681–4690。
- en: 'Lee et al. (2021a) Lik-Hang Lee et al. 2021a. All one needs to know about metaverse:
    A complete survey on technological singularity, virtual ecosystem, and research
    agenda. *arXiv preprint arXiv:2110.05352* (2021).'
  id: totrans-396
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等 (2021a) Lik-Hang Lee 等。2021a。关于元宇宙的一切：技术奇点、虚拟生态系统和研究议程的完整调查。*arXiv 预印本
    arXiv:2110.05352* (2021)。
- en: 'Lee et al. (2021b) Lik-Hang Lee et al. 2021b. Towards augmented reality driven
    human-city interaction: Current research on mobile headsets and future challenges.
    *ACM Computing Surveys (CSUR)* 54, 8 (2021), 1–38.'
  id: totrans-397
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lee 等 (2021b) Lik-Hang Lee 等。2021b。面向增强现实驱动的城市人际互动：当前的移动头戴设备研究和未来挑战。*ACM 计算机调查
    (CSUR)* 54, 8 (2021)，1–38。
- en: 'Lessig (2009) Lawrence Lessig. 2009. *Code: And other laws of cyberspace*.
    ReadHowYouWant. com.'
  id: totrans-398
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lessig (2009) 劳伦斯·莱辛。2009年。*代码：以及网络空间的其他法律*。ReadHowYouWant. com。
- en: Li et al. (2020) Jun Li, Chengjie Niu, and Kai Xu. 2020. Learning part generation
    and assembly for structure-aware shape synthesis. In *Proceedings of the AAAI
    conference on artificial intelligence*, Vol. 34. 11362–11369.
  id: totrans-399
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2020) Jun Li, Chengjie Niu 和 Kai Xu。2020年。学习部件生成和装配以进行结构感知形状合成。在*AAAI
    人工智能会议论文集*，第 34 卷。11362–11369。
- en: 'Li et al. (2017) Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang,
    and Leonidas Guibas. 2017. Grass: Generative recursive autoencoders for shape
    structures. *ACM Transactions on Graphics (TOG)* 36, 4 (2017), 1–14.'
  id: totrans-400
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Li 等 (2017) Jun Li, Kai Xu, Siddhartha Chaudhuri, Ersin Yumer, Hao Zhang 和 Leonidas
    Guibas。2017年。Grass：用于形状结构的生成递归自编码器。*ACM 图形学汇刊 (TOG)* 36, 4 (2017)，1–14。
- en: Lin and Lo (2021) Chaohe Lin and Tian Tian Lo. 2021. Expanding the Methods of
    Human-VR Interaction (HVRI) for Architectural Design Process. (2021).
  id: totrans-401
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 和 Lo (2021) Chaohe Lin 和 Tian Tian Lo。2021年。扩展人类虚拟现实互动 (HVRI) 方法用于建筑设计过程。(2021)。
- en: 'Lin et al. (2022) Chen-Hsuan Lin et al. 2022. Magic3D: High-Resolution Text-to-3D
    Content Creation. *arXiv preprint arXiv:2211.10440* (2022).'
  id: totrans-402
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lin 等人 (2022) Chen-Hsuan Lin 等人。2022。Magic3D：高分辨率文本到 3D 内容创建。*arXiv 预印本 arXiv:2211.10440*
    (2022)。
- en: Litany et al. (2018) Or Litany et al. 2018. Deformable shape completion with
    graph convolutional autoencoders. In *Proceedings of the IEEE conference on computer
    vision and pattern recognition*. 1886–1895.
  id: totrans-403
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Litany 等人 (2018) Or Litany 等人。2018。使用图卷积自编码器的可变形形状完成。在 *IEEE 计算机视觉与模式识别会议论文集*。1886–1895。
- en: 'Liu et al. (2021) Chuan Liu, Jiaqi Shen, Yue Ren, and Hao Zheng. 2021. Pipes
    of AI–Machine Learning Assisted 3D Modeling Design. In *Proceedings of the 2020
    DigitalFUTURES: The 2nd International Conference on Computational Design and Robotic
    Fabrication (CDRF 2020)*. Springer, 17–26.'
  id: totrans-404
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2021) Chuan Liu, Jiaqi Shen, Yue Ren 和 Hao Zheng。2021。AI管道——机器学习辅助的
    3D 建模设计。在 *2020 DigitalFUTURES：第二届计算设计与机器人制造国际会议 (CDRF 2020) 会议录*。Springer，17–26。
- en: Liu et al. (2022) Zhengzhe Liu et al. 2022. Towards Implicit Text-Guided 3D
    Shape Generation. In *Proceedings of the IEEE/CVF Conference on Computer Vision
    and Pattern Recognition*. 17896–17906.
  id: totrans-405
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Liu 等人 (2022) Zhengzhe Liu 等人。2022。迈向隐式文本引导的 3D 形状生成。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。17896–17906。
- en: 'Lorensen and Cline (1987) William E Lorensen and Harvey E Cline. 1987. Marching
    cubes: A high resolution 3D surface construction algorithm. *ACM siggraph computer
    graphics* 21, 4 (1987), 163–169.'
  id: totrans-406
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lorensen 和 Cline (1987) William E Lorensen 和 Harvey E Cline。1987。Marching cubes：一种高分辨率的
    3D 表面构建算法。*ACM siggraph computer graphics* 21, 4 (1987)，163–169。
- en: 'Lunz et al. (2020) Sebastian Lunz, Yingzhen Li, Andrew Fitzgibbon, and Nate
    Kushman. 2020. Inverse graphics gan: Learning to generate 3d shapes from unstructured
    2d data. *arXiv preprint arXiv:2002.12674* (2020).'
  id: totrans-407
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Lunz 等人 (2020) Sebastian Lunz, Yingzhen Li, Andrew Fitzgibbon 和 Nate Kushman。2020。逆向图形
    GAN：学习从非结构化 2D 数据生成 3D 形状。*arXiv 预印本 arXiv:2002.12674* (2020)。
- en: 'Mescheder et al. (2019) Lars Mescheder et al. 2019. Occupancy networks: Learning
    3d reconstruction in function space. In *Proceedings of the IEEE/CVF conference
    on computer vision and pattern recognition*. 4460–4470.'
  id: totrans-408
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mescheder 等人 (2019) Lars Mescheder 等人。2019。占用网络：在函数空间中学习 3D 重建。在 *IEEE/CVF 计算机视觉与模式识别会议论文集*。4460–4470。
- en: 'Michalkiewicz et al. (2019) Mateusz Michalkiewicz, Jhony K Pontes, Dominic
    Jack, Mahsa Baktashmotlagh, and Anders Eriksson. 2019. Deep level sets: Implicit
    surface representations for 3d shape inference. *arXiv preprint arXiv:1901.06802*
    (2019).'
  id: totrans-409
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Michalkiewicz 等人 (2019) Mateusz Michalkiewicz, Jhony K Pontes, Dominic Jack,
    Mahsa Baktashmotlagh 和 Anders Eriksson。2019。深度水平集：用于 3D 形状推断的隐式表面表示。*arXiv 预印本
    arXiv:1901.06802* (2019)。
- en: 'Mildenhall et al. (2020) Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik,
    Jonathan T. Barron, Ravi Ramamoorthi, and Ren Ng. 2020. NeRF: Representing Scenes
    as Neural Radiance Fields for View Synthesis. *ArXiv* abs/2003.08934 (2020).'
  id: totrans-410
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mildenhall 等人 (2020) Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan
    T. Barron, Ravi Ramamoorthi 和 Ren Ng。2020。NeRF：将场景表示为神经辐射场以进行视图合成。*ArXiv* abs/2003.08934
    (2020)。
- en: 'Mittal et al. (2022) Paritosh Mittal et al. 2022. Autosdf: Shape priors for
    3d completion, reconstruction and generation. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*. 306–315.'
  id: totrans-411
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mittal 等人 (2022) Paritosh Mittal 等人。2022。Autosdf：用于 3D 完成、重建和生成的形状先验。在 *IEEE/CVF
    计算机视觉与模式识别会议论文集*。306–315。
- en: Mohammad (2019) Ali SAQ Mohammad. 2019. *Hybrid elevations using GAN Networks*.
    Ph. D. Dissertation. The University of North Carolina at Charlotte.
  id: totrans-412
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mohammad (2019) Ali SAQ Mohammad。2019。*利用 GAN 网络的混合高程*。博士论文。北卡罗来纳大学夏洛特分校。
- en: 'MOLETA and NISHIOKA (2021) TANE MOLETA and MIZUHO NISHIOKA. 2021. Populating
    Virtual Worlds: Architecture, Photography, Sonic Art, Creative Writing Collide
    at “in the Forest with the Trees We Made”. (2021).'
  id: totrans-413
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MOLETA 和 NISHIOKA (2021) TANE MOLETA 和 MIZUHO NISHIOKA。2021。填充虚拟世界：建筑、摄影、声音艺术、创意写作在“与我们创造的树木在森林中”碰撞。(2021)。
- en: MUN et al. (2019) KRISTINE MUN, DANE CLEMENSON, and BIAYNA BOGOSIAN. 2019. THE
    WELL TEMPERED ENVIRONMENT OF EXPERIENCE. *INTELLIGENT & INFORMED* 15 (2019), 573.
  id: totrans-414
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: MUN 等人 (2019) KRISTINE MUN, DANE CLEMENSON 和 BIAYNA BOGOSIAN。2019。体验的良好环境。*INTELLIGENT
    & INFORMED* 15 (2019)，573。
- en: Mütterlein (2018) Joschka Mütterlein. 2018. The three pillars of virtual reality?
    Investigating the roles of immersion, presence, and interactivity. (2018).
  id: totrans-415
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Mütterlein (2018) Joschka Mütterlein。2018。虚拟现实的三大支柱？研究沉浸、存在感和互动性的角色。(2018)。
- en: Myers and Twenge (2012) David G Myers and Jean M Twenge. 2012. *Exploring social
    psychology*. McGraw-Hill New York.
  id: totrans-416
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Myers 和 Twenge (2012) David G Myers 和 Jean M Twenge。2012。*探索社会心理学*。McGraw-Hill
    New York。
- en: 'Narahara (2022) Taro Narahara. 2022. Kurashiki Viewer: Qualitative Evaluations
    of Architectural Spaces inside Virtual Reality. (2022).'
  id: totrans-417
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Narahara (2022) Taro Narahara. 2022. Kurashiki Viewer: 在虚拟现实中对建筑空间的定性评估。 (2022)。'
- en: 'Nash et al. (2020) Charlie Nash, Yaroslav Ganin, SM Ali Eslami, and Peter Battaglia.
    2020. Polygen: An autoregressive generative model of 3d meshes. In *International
    conference on machine learning*. PMLR, 7220–7229.'
  id: totrans-418
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nash et al. (2020) Charlie Nash, Yaroslav Ganin, SM Ali Eslami, 和 Peter Battaglia.
    2020. Polygen: 一种自回归生成模型的3D网格。在*国际机器学习大会*。PMLR，7220–7229。'
- en: Nazmeeva (2019) Alina Nazmeeva. 2019. *Constructing the virtual as a social
    form*. Ph. D. Dissertation. Massachusetts Institute of Technology.
  id: totrans-419
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nazmeeva (2019) Alina Nazmeeva. 2019. *作为一种社会形式构建虚拟世界*。博士论文。麻省理工学院。
- en: Nevelsteen (2018) Kim JL Nevelsteen. 2018. Virtual world, defined from a technological
    perspective and applied to video games, mixed reality, and the Metaverse. *Computer
    animation and virtual worlds* 29, 1 (2018), e1752.
  id: totrans-420
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nevelsteen (2018) Kim JL Nevelsteen. 2018. 从技术角度定义虚拟世界，并应用于视频游戏、混合现实和元宇宙。*计算机动画与虚拟世界*
    29, 1 (2018), e1752。
- en: Newton (2019) David Newton. 2019. Generative deep learning in architectural
    design. *Technology— Architecture+ Design* 3, 2 (2019), 176–189.
  id: totrans-421
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Newton (2019) David Newton. 2019. 建筑设计中的生成深度学习。*科技——建筑+设计* 3, 2 (2019), 176–189。
- en: Nguyen et al. (2019) Binh Vinh Duc Nguyen, Peng Chengzhi, and Wang Tsung-Hsien.
    2019. KOALA-Developing a generative house design system with agent-based modelling
    of social spatial processes. In *Intelligent & Informed-Proceedings of the 24th
    CAADRIA Conference*, Vol. 1\. CAADRIA, 235–244.
  id: totrans-422
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nguyen et al. (2019) Binh Vinh Duc Nguyen, Peng Chengzhi, 和 Wang Tsung-Hsien.
    2019. KOALA-基于代理建模的社会空间过程生成住宅设计系统。在*智能与信息——第24届CAADRIA会议论文集*，第1卷。CAADRIA，235–244。
- en: 'Nguyen-Phuoc et al. (2019) Thu Nguyen-Phuoc et al. 2019. Hologan: Unsupervised
    learning of 3d representations from natural images. In *Proceedings of the IEEE/CVF
    International Conference on Computer Vision*. 7588–7597.'
  id: totrans-423
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nguyen-Phuoc et al. (2019) Thu Nguyen-Phuoc 等. 2019. Hologan: 从自然图像中无监督学习3D表示。在*IEEE/CVF国际计算机视觉大会论文集*。7588–7597。'
- en: 'Nichol et al. (2021) Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav
    Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, and Mark Chen. 2021. Glide:
    Towards photorealistic image generation and editing with text-guided diffusion
    models. *arXiv preprint arXiv:2112.10741* (2021).'
  id: totrans-424
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nichol et al. (2021) Alex Nichol, Prafulla Dhariwal, Aditya Ramesh, Pranav
    Shyam, Pamela Mishkin, Bob McGrew, Ilya Sutskever, 和 Mark Chen. 2021. Glide: 朝向基于文本的扩散模型的照片级真实图像生成与编辑。*arXiv预印本
    arXiv:2112.10741* (2021)。'
- en: 'Nichol et al. (2022) Alex Nichol, Heewoo Jun, Prafulla Dhariwal, Pamela Mishkin,
    and Mark Chen. 2022. Point-E: A System for Generating 3D Point Clouds from Complex
    Prompts. arXiv:2212.08751 [cs.CV]'
  id: totrans-425
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Nichol et al. (2022) Alex Nichol, Heewoo Jun, Prafulla Dhariwal, Pamela Mishkin,
    和 Mark Chen. 2022. Point-E: 一种从复杂提示生成3D点云的系统。arXiv:2212.08751 [cs.CV]'
- en: 'Niemeyer and Geiger (2021) Michael Niemeyer and Andreas Geiger. 2021. Giraffe:
    Representing scenes as compositional generative neural feature fields. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 11453–11464.'
  id: totrans-426
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Niemeyer 和 Geiger (2021) Michael Niemeyer 和 Andreas Geiger. 2021. Giraffe:
    将场景表示为组合生成神经特征场。在*IEEE/CVF计算机视觉与模式识别大会论文集*。11453–11464。'
- en: Nijkamp et al. (2020) Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, and
    Ying Nian Wu. 2020. On the anatomy of mcmc-based maximum likelihood learning of
    energy-based models. In *Proceedings of the AAAI Conference on Artificial Intelligence*,
    Vol. 34. 5272–5280.
  id: totrans-427
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Nijkamp et al. (2020) Erik Nijkamp, Mitch Hill, Tian Han, Song-Chun Zhu, 和 Ying
    Nian Wu. 2020. 关于基于MCMC的最大似然学习能量模型的解剖学。在*AAAI人工智能大会论文集*，第34卷。5272–5280。
- en: 'OpenAI (2022) OpenAI. 2022. CHATGPT: Optimizing language models for dialogue.
    [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
  id: totrans-428
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'OpenAI (2022) OpenAI. 2022. CHATGPT: 优化对话的语言模型。 [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/)'
- en: 'Or-El et al. (2022) Roy Or-El et al. 2022. Stylesdf: High-resolution 3d-consistent
    image and geometry generation. In *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*. 13503–13513.'
  id: totrans-429
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Or-El et al. (2022) Roy Or-El 等. 2022. Stylesdf: 高分辨率3D一致图像和几何生成。在*IEEE/CVF计算机视觉与模式识别大会论文集*。13503–13513。'
- en: 'Oussidi and Elhassouny (2018) Achraf Oussidi and Azeddine Elhassouny. 2018.
    Deep generative models: Survey. In *2018 International conference on intelligent
    systems and computer vision (ISCV)*. IEEE, 1–8.'
  id: totrans-430
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Oussidi 和 Elhassouny (2018) Achraf Oussidi 和 Azeddine Elhassouny. 2018. 深度生成模型：综述。在*2018年国际智能系统与计算机视觉会议
    (ISCV)*。IEEE，1–8。
- en: 'Özel (2020) Güvenç Özel. 2020. Interdisciplinary AI: A Machine Learning System
    for Streamlining External Aesthetic and Cultural Influences in Architecture. In
    *Architectural Intelligence: Selected Papers from the 1st International Conference
    on Computational Design and Robotic Fabrication (CDRF 2019)*. Springer, 103–116.'
  id: totrans-431
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Özel (2020) Güvenç Özel. 2020. 跨学科 AI：一个用于简化建筑外部美学与文化影响的机器学习系统。见 *建筑智能：第1届计算设计与机器人制造国际会议
    (CDRF 2019) 精选论文*。Springer, 103–116。
- en: 'Pavan Kumar and Jayagopal (2021) MR Pavan Kumar and Prabhu Jayagopal. 2021.
    Generative adversarial networks: a survey on applications and challenges. *International
    Journal of Multimedia Information Retrieval* 10, 1 (2021), 1–24.'
  id: totrans-432
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pavan Kumar 和 Jayagopal (2021) MR Pavan Kumar 和 Prabhu Jayagopal. 2021. 生成对抗网络：应用与挑战综述。*多媒体信息检索国际期刊*
    10, 1 (2021), 1–24。
- en: Pei et al. (2021) Wanyu Pei, Xiangmin Guo, and TianTian Lo. 2021. Detecting
    Virtual Perception Based on Multi-Dimensional Biofeedback-A Method to Pre-Evaluate
    Architectural Design Objectives. (2021).
  id: totrans-433
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pei 等 (2021) Wanyu Pei, Xiangmin Guo, 和 TianTian Lo. 2021. 基于多维生物反馈的虚拟感知检测——一种预评估建筑设计目标的方法。
    (2021)。
- en: 'Pei et al. (2020) Wanyu Pei, TianTian LO, and Xiangmin Guo. 2020. A Biofeedback
    Process: Detecting Architectural Space with the Integration of Emotion Recognition
    and Eye-tracking Technology. (2020).'
  id: totrans-434
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pei 等 (2020) Wanyu Pei, TianTian LO, 和 Xiangmin Guo. 2020. 生物反馈过程：通过情感识别与眼动追踪技术整合检测建筑空间。
    (2020)。
- en: Penney and Chen (2019) Drew D Penney and Lizhong Chen. 2019. A survey of machine
    learning applied to computer architecture design. *arXiv preprint arXiv:1909.12373*
    (2019).
  id: totrans-435
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Penney 和 Chen (2019) Drew D Penney 和 Lizhong Chen. 2019. 应用于计算机架构设计的机器学习综述。*arXiv
    预印本 arXiv:1909.12373* (2019)。
- en: 'Poole et al. (2022) Ben Poole, Ajay Jain, Jonathan T Barron, and Ben Mildenhall.
    2022. Dreamfusion: Text-to-3d using 2d diffusion. *arXiv preprint arXiv:2209.14988*
    (2022).'
  id: totrans-436
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Poole 等 (2022) Ben Poole, Ajay Jain, Jonathan T Barron, 和 Ben Mildenhall. 2022.
    Dreamfusion: 使用 2D 扩散的文本到 3D。*arXiv 预印本 arXiv:2209.14988* (2022)。'
- en: 'Pouyanfar et al. (2018) Samira Pouyanfar et al. 2018. A survey on deep learning:
    Algorithms, techniques, and applications. *ACM Computing Surveys (CSUR)* 51, 5
    (2018), 1–36.'
  id: totrans-437
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Pouyanfar 等 (2018) Samira Pouyanfar 等. 2018. 深度学习综述：算法、技术与应用。*ACM 计算机调查 (CSUR)*
    51, 5 (2018), 1–36。
- en: Ramasinghe et al. (2020) Sameera Ramasinghe et al. 2020. Spectral-GANs for high-resolution
    3D point-cloud generation. In *2020 IEEE/RSJ International Conference on Intelligent
    Robots and Systems (IROS)*. IEEE, 8169–8176.
  id: totrans-438
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ramasinghe 等 (2020) Sameera Ramasinghe 等. 2020. 高分辨率 3D 点云生成的谱生成对抗网络。见 *2020
    IEEE/RSJ 国际智能机器人与系统会议 (IROS)*。IEEE, 8169–8176。
- en: Reed et al. (2016) Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran,
    Bernt Schiele, and Honglak Lee. 2016. Generative adversarial text to image synthesis.
    In *International conference on machine learning*. PMLR, 1060–1069.
  id: totrans-439
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Reed 等 (2016) Scott Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt
    Schiele, 和 Honglak Lee. 2016. 生成对抗文本到图像合成。见 *国际机器学习会议*。PMLR, 1060–1069。
- en: 'Regenwetter et al. (2022) Lyle Regenwetter, Amin Heyrani Nobari, and Faez Ahmed.
    2022. Deep generative models in engineering design: A review. *Journal of Mechanical
    Design* 144, 7 (2022), 071704.'
  id: totrans-440
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Regenwetter 等 (2022) Lyle Regenwetter, Amin Heyrani Nobari, 和 Faez Ahmed. 2022.
    工程设计中的深度生成模型：综述。*机械设计期刊* 144, 7 (2022), 071704。
- en: Ren and Zheng (2020) Yue Ren and Hao Zheng. 2020. The Spire of AI-Voxel-based
    3D neural style transfer. In *Proceedings of the 25th International Conference
    on Computer-Aided Architectural Design Research in Asia (CAADRIA)*.
  id: totrans-441
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Ren 和 Zheng (2020) Yue Ren 和 Hao Zheng. 2020. AI 矩阵：基于体素的 3D 神经风格迁移。见 *第25届国际计算机辅助建筑设计研究亚洲会议
    (CAADRIA) 论文集*。
- en: 'Rusu and Cousins (2011) Radu Bogdan Rusu and Steve B. Cousins. 2011. 3D is
    here: Point Cloud Library (PCL). *2011 IEEE International Conference on Robotics
    and Automation* (2011), 1–4.'
  id: totrans-442
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Rusu 和 Cousins (2011) Radu Bogdan Rusu 和 Steve B. Cousins. 2011. 3D 已经来临：点云库
    (PCL)。*2011 IEEE 国际机器人与自动化会议* (2011), 1–4。
- en: 'Sanghi et al. (2022) Aditya Sanghi, Hang Chu, Joseph G Lambourne, Ye Wang,
    Chin-Yi Cheng, Marco Fumero, and Kamal Rahimi Malekshan. 2022. Clip-forge: Towards
    zero-shot text-to-shape generation. In *Proceedings of the IEEE/CVF Conference
    on Computer Vision and Pattern Recognition*. 18603–18613.'
  id: totrans-443
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Sanghi 等 (2022) Aditya Sanghi, Hang Chu, Joseph G Lambourne, Ye Wang, Chin-Yi
    Cheng, Marco Fumero, 和 Kamal Rahimi Malekshan. 2022. Clip-forge: 向零样本文本到形状生成迈进。见
    *IEEE/CVF 计算机视觉与模式识别会议论文集*。18603–18613。'
- en: Sarcar et al. (2008) MMM Sarcar et al. 2008. *Computer aided design and manufacturing*.
    PHI Learning Pvt. Ltd.
  id: totrans-444
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarcar 等 (2008) MMM Sarcar 等. 2008. *计算机辅助设计与制造*。PHI Learning Pvt. Ltd.
- en: Sardenberg (2019) Victor Sardenberg. 2019. Aesthetic Quantification as Search
    Criteria in Architectural Design. *Blucher Design Proceedings* 7, 1 (2019), 17–24.
    [https://doi.org/10.5151/proceedings-ecaadesigradi2019_088](https://doi.org/10.5151/proceedings-ecaadesigradi2019_088)
  id: totrans-445
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sardenberg (2019) Victor Sardenberg. 2019. 作为建筑设计中的搜索标准的审美量化。 *Blucher Design
    Proceedings* 7, 1 (2019), 17–24. [https://doi.org/10.5151/proceedings-ecaadesigradi2019_088](https://doi.org/10.5151/proceedings-ecaadesigradi2019_088)
- en: 'Sarker (2021a) Iqbal H Sarker. 2021a. Deep learning: a comprehensive overview
    on techniques, taxonomy, applications and research directions. *SN Computer Science*
    2, 6 (2021), 420.'
  id: totrans-446
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarker (2021a) Iqbal H Sarker. 2021a. 深度学习：技术、分类、应用和研究方向的全面概述。 *SN Computer
    Science* 2, 6 (2021), 420.
- en: 'Sarker (2021b) Iqbal H Sarker. 2021b. Machine learning: Algorithms, real-world
    applications and research directions. *SN Computer Science* 2, 3 (2021), 1–21.'
  id: totrans-447
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sarker (2021b) Iqbal H Sarker. 2021b. 机器学习：算法、实际应用和研究方向。 *SN Computer Science*
    2, 3 (2021), 1–21.
- en: 'Schroeder et al. (2001) Ralph Schroeder, Avon Huxor, and Andy Smith. 2001.
    Activeworlds: geography and social interaction in virtual reality. *Futures* 33,
    7 (2001), 569–587. [https://doi.org/10.1016/S0016-3287(01)00002-7](https://doi.org/10.1016/S0016-3287(01)00002-7)'
  id: totrans-448
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schroeder et al. (2001) Ralph Schroeder, Avon Huxor, 和 Andy Smith. 2001. Activeworlds：虚拟现实中的地理与社会互动。
    *Futures* 33, 7 (2001), 569–587. [https://doi.org/10.1016/S0016-3287(01)00002-7](https://doi.org/10.1016/S0016-3287(01)00002-7)
- en: Schumacher (2013) Patrik Schumacher. 2013. Parametric Semiology – The Design
    of Information Rich Environments. [https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html](https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html)
  id: totrans-449
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schumacher (2013) Patrik Schumacher. 2013. 参数化符号学——信息丰富环境的设计。 [https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html](https://www.patrikschumacher.com/Texts/Design%20of%20Information%20Rich%20Environments.html)
- en: 'Schwarz et al. (2022) Katja Schwarz, Axel Sauer, Michael Niemeyer, Yiyi Liao,
    and Andreas Geiger. 2022. Voxgraf: Fast 3d-aware image synthesis with sparse voxel
    grids. *arXiv preprint arXiv:2206.07695* (2022).'
  id: totrans-450
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Schwarz et al. (2022) Katja Schwarz, Axel Sauer, Michael Niemeyer, Yiyi Liao,
    和 Andreas Geiger. 2022. Voxgraf：基于稀疏体素网格的快速3D感知图像合成。 *arXiv预印本 arXiv:2206.07695*
    (2022).
- en: 'Sebestyen et al. (2021) Adam Sebestyen, Johanna Rock, and Urs Leonhard Hirschberg.
    2021. Towards Abductive Reasoning-Based ComputationalDesign Tools: Using Machine
    Learning as a way to explore the combined design spaces of multiple parametric
    models. In *39th eCAADe Conference: Education and Research in Computer Aided Architectural
    Design in Europe: Towards a new, configurable architecture: eCAADe 2021*. 141–150.'
  id: totrans-451
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sebestyen et al. (2021) Adam Sebestyen, Johanna Rock, 和 Urs Leonhard Hirschberg.
    2021. 面向基于溯因推理的计算设计工具：利用机器学习探索多个参数化模型的联合设计空间。 在 *第39届eCAADe会议：欧洲计算机辅助建筑设计的教育与研究：迈向一种新的、可配置的架构：eCAADe
    2021*。 141–150.
- en: Sheehan et al. (2021) Liam Jordan Sheehan, Andre Brown, Marc Aurel Schnabel,
    and Tane Moleta. 2021. The Fourth Virtual Dimension-Stimulating the Human Senses
    to Create Virtual Atmospheric Qualities. (2021).
  id: totrans-452
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Sheehan et al. (2021) Liam Jordan Sheehan, Andre Brown, Marc Aurel Schnabel,
    和 Tane Moleta. 2021. 第四虚拟维度——刺激人类感官以创建虚拟环境的氛围特质。 (2021).
- en: 'Shen et al. (2021) Tianchang Shen et al. 2021. Deep Marching Tetrahedra: a
    Hybrid Representation for High-Resolution 3D Shape Synthesis. In *Advances in
    Neural Information Processing Systems (NeurIPS)*.'
  id: totrans-453
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shen et al. (2021) Tianchang Shen 等. 2021. 深度行进四面体：用于高分辨率3D形状合成的混合表示。 在 *神经信息处理系统进展（NeurIPS）*.
- en: 'Shi et al. (2022) Zifan Shi, Sida Peng, Yinghao Xu, Yiyi Liao, and Yujun Shen.
    2022. Deep generative models on 3d representations: A survey. *arXiv preprint
    arXiv:2210.15663* (2022).'
  id: totrans-454
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shi et al. (2022) Zifan Shi, Sida Peng, Yinghao Xu, Yiyi Liao, 和 Yujun Shen.
    2022. 3D表示上的深度生成模型：综述。 *arXiv预印本 arXiv:2210.15663* (2022).
- en: Shu et al. (2019) Dong Wook Shu et al. 2019. 3d point cloud generative adversarial
    network based on tree structured graph convolutions. In *Proceedings of the IEEE/CVF
    international conference on computer vision*. 3859–3868.
  id: totrans-455
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Shu et al. (2019) Dong Wook Shu 等. 2019. 基于树状图卷积的3D点云生成对抗网络。 在 *IEEE/CVF国际计算机视觉会议论文集*。
    3859–3868.
- en: Srivastava et al. (2021) Akshay Srivastava, Longtai Liao, and Henan Liu. 2021.
    An anonymous composition. *The Routledge Companion to Artificial Intelligence
    in Architecture* (2021), 442.
  id: totrans-456
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Srivastava et al. (2021) Akshay Srivastava, Longtai Liao, 和 Henan Liu. 2021.
    一部匿名作品。 *劳特利奇人工智能在建筑中的助手* (2021), 442.
- en: 'Steinfeld et al. (2019) Kyle Steinfeld et al. 2019. Fresh eyes: a framework
    for the application of machine learning to generative architectural design, and
    a report of activities at smartgeometry 2018\. In *Computer-Aided Architectural
    Design.” Hello, Culture” 18th International Conf., CAAD Futures 2019, Daejeon,
    S. Korea, June 26–28, 2019*. Springer, 32–46.'
  id: totrans-457
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Steinfeld et al. (2019) 凯尔·斯坦费尔德等（2019）。新鲜视角：机器学习在生成建筑设计中的应用框架，以及在smartgeometry
    2018上的活动报告。在 *计算机辅助建筑设计。“你好，文化”第18届国际会议，CAAD Futures 2019，韩国大田，2019年6月26–28日*。Springer，32–46。
- en: STUART-SMITH and DANAHY (2022) ROBERT STUART-SMITH and PATRICK DANAHY. 2022.
    Visual Character Analysis within Algorithmic Design. *POST-CARBON, Proceedings
    of the 27th CAADRIA* (2022).
  id: totrans-458
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: STUART-SMITH and DANAHY (2022) 罗伯特·斯图尔特-史密斯和帕特里克·丹纳赫（2022）。算法设计中的视觉特征分析。*POST-CARBON，第27届CAADRIA会议论文集*（2022）。
- en: 'Tamke et al. (2018) Martin Tamke, Paul Nicholas, and Mateusz Zwierzycki. 2018.
    Machine learning for architectural design: Practices and infrastructure. *International
    Journal of Architectural Computing* 16, 2 (2018), 123–143.'
  id: totrans-459
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tamke et al. (2018) 马丁·塔姆克、保罗·尼科拉斯和马特乌斯·兹维热茨基。2018。建筑设计中的机器学习：实践与基础设施。*国际建筑计算期刊*
    16, 2 (2018)，123–143。
- en: Tonn (2017) Christian Tonn. 2017. Designing Colour in Virtual Reality-Comparing
    a Virtual Reality based and a Screen based Colour Design Method. (2017).
  id: totrans-460
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tonn (2017) 克里斯蒂安·托恩。2017。虚拟现实中的颜色设计——比较基于虚拟现实和基于屏幕的颜色设计方法。(2017)。
- en: 'Tosello (2003) Maria E Tosello. 2003. Performing Cyberspace: Dance, Technology
    and Virtual Architecture. *International Journal of Architectural Computing* 1,
    3 (2003), 393–413.'
  id: totrans-461
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Tosello (2003) 玛利亚·E·托塞洛。2003。执行虚拟空间：舞蹈、技术与虚拟建筑。*国际建筑计算期刊* 1, 3 (2003)，393–413。
- en: Valsesia et al. (2019) Diego Valsesia, Giulia Fracastoro, and Enrico Magli.
    2019. Learning localized generative models for 3d point clouds via graph convolution.
    In *International conference on learning representations*.
  id: totrans-462
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Valsesia et al. (2019) 迭戈·瓦尔塞西亚、朱莉亚·弗拉卡斯托罗和恩里科·马利。2019。通过图卷积学习用于三维点云的局部生成模型。在
    *国际学习表征会议*。
- en: Veselỳ (2022) Ondrej Veselỳ. 2022. Building massing generation using GAN trained
    on Dutch 3D city models. (2022).
  id: totrans-463
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Veselỳ (2022) 维谢利（2022）。使用在荷兰三维城市模型上训练的GAN生成建筑体量。(2022)。
- en: 'Wang et al. (2022) Can Wang et al. 2022. Clip-nerf: Text-and-image driven manipulation
    of neural radiance fields. In *Proceedings of the IEEE/CVF Conference on Computer
    Vision and Pattern Recognition*. 3835–3844.'
  id: totrans-464
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wang et al. (2022) 王等（2022）。Clip-nerf: 基于文本和图像驱动的神经辐射场操控。在 *IEEE/CVF计算机视觉与模式识别会议论文集*
    中，3835–3844。'
- en: 'Wang et al. (2021) Zhengwei Wang, Qi She, and Tomas E Ward. 2021. Generative
    adversarial networks in computer vision: A survey and taxonomy. *ACM Computing
    Surveys (CSUR)* 54, 2 (2021), 1–38.'
  id: totrans-465
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wang et al. (2021) 王正伟、佘琦和托马斯·E·沃德。2021。计算机视觉中的生成对抗网络：综述与分类。*ACM计算机调查（CSUR）*
    54, 2 (2021)，1–38。
- en: Wells et al. (2021) Cameron Wells et al. 2021. Beauty is in the Eye of the Beholder-Improving
    the Human-Computer Interface within VRAD by the active and two-way employment
    of our visual senses. (2021).
  id: totrans-466
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wells et al. (2021) 卡梅伦·威尔斯等（2021）。美在观者的眼中——通过我们视觉感官的主动和双向使用来改善VRAD中的人机界面。(2021)。
- en: Wu et al. (2016) Jiajun Wu et al. 2016. Learning a probabilistic latent space
    of object shapes via 3d generative-adversarial modeling. *Advances in neural information
    processing systems* 29 (2016).
  id: totrans-467
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Wu et al. (2016) 吴嘉俊等（2016）。通过三维生成对抗建模学习物体形状的概率潜在空间。*神经信息处理系统进展* 29 (2016)。
- en: 'Wu et al. (2020) Rundi Wu, Yixin Zhuang, Kai Xu, Hao Zhang, and Baoquan Chen.
    2020. Pq-net: A generative part seq2seq network for 3d shapes. In *Proceedings
    of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*. 829–838.'
  id: totrans-468
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2020) 吴润迪、庄一新、徐凯、张浩和陈宝全。2020。Pq-net: 用于三维形状的生成部分序列到序列网络。在 *IEEE/CVF计算机视觉与模式识别会议论文集*
    中，829–838。'
- en: 'Wu et al. (2019) Zhijie Wu, Xiang Wang, Di Lin, Dani Lischinski, Daniel Cohen-Or,
    and Hui Huang. 2019. Sagnet: Structure-aware generative network for 3d-shape modeling.
    *ACM Transactions on Graphics (TOG)* 38, 4 (2019), 1–14.'
  id: totrans-469
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Wu et al. (2019) 吴志杰、王翔、林迪、达尼·利什金斯基、丹尼尔·科恩-奥尔和黄辉。2019。Sagnet: 结构感知生成网络用于三维形状建模。*ACM图形学学报（TOG）*
    38, 4 (2019)，1–14。'
- en: Xia and Xue (2022) Weihao Xia and Jing-Hao Xue. 2022. A Survey on 3D-aware Image
    Synthesis. *arXiv preprint arXiv:2210.14267* (2022).
  id: totrans-470
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Xia and Xue (2022) 夏伟浩和薛景浩。2022。关于3D感知图像合成的调查。*arXiv预印本 arXiv:2210.14267*（2022）。
- en: 'Yang et al. (2019) Guandao Yang et al. 2019. Pointflow: 3d point cloud generation
    with continuous normalizing flows. In *Proceedings of the IEEE/CVF International
    Conference on Computer Vision*. 4541–4550.'
  id: totrans-471
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yang 等 (2019) Guandao Yang 等. 2019. Pointflow：具有连续标准化流的三维点云生成。发表于*IEEE/CVF国际计算机视觉会议论文集*。4541–4550。
- en: Yao et al. (2018) Zhihang Yao, Claus Nagel, Felix Kunde, György Hudra, Philipp
    Willkomm, Andreas Donaubauer, Thomas Adolphi, and Thomas H Kolbe. 2018. 3DCityDB-a
    3D geodatabase solution for the management, analysis, and visualization of semantic
    3D city models based on CityGML. *Open Geospatial Data, Software and Standards*
    3, 1 (2018), 1–26.
  id: totrans-472
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yao 等 (2018) Zhihang Yao、Claus Nagel、Felix Kunde、György Hudra、Philipp Willkomm、Andreas
    Donaubauer、Thomas Adolphi 和 Thomas H Kolbe. 2018. 3DCityDB——基于CityGML的三维地理数据库解决方案，用于语义三维城市模型的管理、分析和可视化。*开放地理空间数据、软件和标准*
    3, 1 (2018)，1–26。
- en: Yu (2020) De Yu. 2020. Reprogramming Urban Block by Machine Creativity-How to
    use neural networks as generative tools to design space. (2020).
  id: totrans-473
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yu (2020) De Yu. 2020. 通过机器创造力重新编程城市区块——如何使用神经网络作为生成工具来设计空间。（2020）。
- en: Yuniarti and Suciati (2019) Anny Yuniarti and Nanik Suciati. 2019. A review
    of deep learning techniques for 3D reconstruction of 2D images. In *2019 12th
    International Conference on Information & Communication Technology and System
    (ICTS)*. IEEE, 327–331.
  id: totrans-474
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Yuniarti 和 Suciati (2019) Anny Yuniarti 和 Nanik Suciati. 2019. 对于二维图像三维重建的深度学习技术综述。发表于*2019年第12届国际信息与通信技术与系统会议（ICTS）*。IEEE，327–331。
- en: Zamorski et al. (2020) Maciej Zamorski et al. 2020. Adversarial autoencoders
    for compact representations of 3D point clouds. *Computer Vision and Image Understanding*
    193 (2020), 102921.
  id: totrans-475
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zamorski 等 (2020) Maciej Zamorski 等. 2020. 用于三维点云紧凑表示的对抗性自编码器。*计算机视觉与图像理解* 193
    (2020)，102921。
- en: Zarei et al. (2021) Maryam Zarei, Halil Erhan, Ahmed M Abuzuraiq, Osama Alsalman,
    and Alyssa Haas. 2021. Design and development of interactive systems for integration
    of comparative visual analytics in design workflow. (2021).
  id: totrans-476
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zarei 等 (2021) Maryam Zarei、Halil Erhan、Ahmed M Abuzuraiq、Osama Alsalman 和 Alyssa
    Haas. 2021. 设计和开发用于设计工作流程中比较视觉分析集成的交互系统。（2021）。
- en: 'Zeng et al. (2022) Xiaohui Zeng, Arash Vahdat, Francis Williams, Zan Gojcic,
    Or Litany, Sanja Fidler, and Karsten Kreis. 2022. LION: Latent Point Diffusion
    Models for 3D Shape Generation. *arXiv preprint arXiv:2210.06978* (2022).'
  id: totrans-477
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zeng 等 (2022) Xiaohui Zeng、Arash Vahdat、Francis Williams、Zan Gojcic、Or Litany、Sanja
    Fidler 和 Karsten Kreis. 2022. LION：用于三维形状生成的潜在点扩散模型。*arXiv 预印本 arXiv:2210.06978*
    (2022)。
- en: Zhang (2019) Hang Zhang. 2019. 3D model generation on architectural plan and
    section training through machine learning. *Technologies* 7, 4 (2019), 82.
  id: totrans-478
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang (2019) Hang Zhang. 2019. 基于机器学习的建筑平面图和剖面图训练中的三维模型生成。*Technologies* 7,
    4 (2019)，82。
- en: 'Zhang (2020) Hang Zhang. 2020. Text-to-Form: 3D Prediction by Linguistic Description.
    In *ACADIA 20: Distributed Proximities / Volume I: Technical Papers [Proceedings
    of the 40th Annual Conference of the Association for Computer Aided Design in
    Architecture (ACADIA) 978-0-578-95213-0](Online and Global. 24-30 October 2020.)*.
    238–247.'
  id: totrans-479
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang (2020) Hang Zhang. 2020. 文本到形状：通过语言描述进行三维预测。发表于*ACADIA 20：分布式邻近/卷 I：技术论文
    [第40届计算机辅助设计建筑学会年会论文集（ACADIA）978-0-578-95213-0](在线和全球，2020年10月24-30日)*。238–247。
- en: Zhang and Blasetti (2020) Hang Zhang and Ezio Blasetti. 2020. 3D architectural
    form style transfer through machine learning. (2020).
  id: totrans-480
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 和 Blasetti (2020) Hang Zhang 和 Ezio Blasetti. 2020. 通过机器学习进行三维建筑形态风格迁移。（2020）。
- en: 'Zhang and Huang (2021) Hang Zhang and Ye Huang. 2021. Machine learning aided
    2D-3D architectural form finding at high resolution. In *Proceedings of the 2020
    DigitalFUTURES: The 2nd International Conference on Computational Design and Robotic
    Fabrication (CDRF 2020)*. Springer, 159–168.'
  id: totrans-481
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 和 Huang (2021) Hang Zhang 和 Ye Huang. 2021. 高分辨率下机器学习辅助的二维到三维建筑形态探索。发表于*2020
    DigitalFUTURES：第二届国际计算设计与机器人制造会议（CDRF 2020）论文集*。Springer，159–168。
- en: Zhang et al. (2019) Song-Hai Zhang, Shao-Kui Zhang, Yuan Liang, and Peter Hall.
    2019. A survey of 3D indoor scene synthesis. *Journal of Computer Science and
    Technology* 34 (2019), 594–608.
  id: totrans-482
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhang 等 (2019) Song-Hai Zhang、Shao-Kui Zhang、Yuan Liang 和 Peter Hall. 2019.
    三维室内场景合成的调查。*计算机科学与技术杂志* 34 (2019)，594–608。
- en: Zheng et al. (2021) Zerong Zheng, Tao Yu, Qionghai Dai, and Yebin Liu. 2021.
    Deep implicit templates for 3d shape representation. In *Proceedings of the IEEE/CVF
    Conference on Computer Vision and Pattern Recognition*. 1429–1439.
  id: totrans-483
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zheng 等 (2021) Zerong Zheng、Tao Yu、Qionghai Dai 和 Yebin Liu. 2021. 用于三维形状表示的深度隐式模板。发表于*IEEE/CVF计算机视觉与模式识别会议论文集*。1429–1439。
- en: Zhou et al. (2021) Linqi Zhou, Yilun Du, and Jiajun Wu. 2021. 3d shape generation
    and completion through point-voxel diffusion. In *Proceedings of the IEEE/CVF
    International Conference on Computer Vision*. 5826–5835.
  id: totrans-484
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhou 等人（2021）林琦·周、亿伦·杜、佳俊·吴。2021。通过点-体素扩散进行三维形状生成与完成。在 *IEEE/CVF 国际计算机视觉会议论文集*
    中。5826–5835。
- en: Zhu et al. (2017) Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
    2017. Unpaired image-to-image translation using cycle-consistent adversarial networks.
    In *Proceedings of the IEEE international conference on computer vision*. 2223–2232.
  id: totrans-485
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: Zhu 等人（2017）俊彦·朱、泰成·朴、菲利普·伊索拉、阿列克谢·A·埃夫罗斯。2017。使用循环一致的对抗网络进行无配对图像到图像翻译。在 *IEEE
    国际计算机视觉会议论文集* 中。2223–2232。
