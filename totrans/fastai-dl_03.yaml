- en: 'Deep Learning 2: Part 1 Lesson 3'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 原文：[https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56](https://medium.com/@hiromi_suenaga/deep-learning-2-part-1-lesson-3-74b0ef79e56)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '*My personal notes from* [*fast.ai course*](http://www.fast.ai/)*. These notes
    will continue to be updated and improved as I continue to review the course to
    “really” understand it. Much appreciation to* [*Jeremy*](https://twitter.com/jeremyphoward)
    *and* [*Rachel*](https://twitter.com/math_rachel) *who gave me this opportunity
    to learn.*'
  prefs: []
  type: TYPE_NORMAL
- en: '[Lesson 3](http://forums.fast.ai/t/wiki-lesson-3/9401/1)'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Helpful materials created by students:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[AWS how-to](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/aws_ami_gpu_setup.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Tmux](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/tools/tmux.md)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Lesson 2 summary](/@apiltamang/case-study-a-world-class-image-classifier-for-dogs-and-cats-err-anything-9cf39ee4690e)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learning rate finder](https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PyTorch](https://towardsdatascience.com/a-practitioners-guide-to-pytorch-1d0f6a238040)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Learning rate vs. Batch size](https://miguel-data-sc.github.io/2017-11-05-first/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Smoother area of the error surface vs. generalization](/@radekosmulski/do-smoother-areas-of-the-error-surface-lead-to-better-generalization-b5f93b9edf5b)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Convolutional Neural Network in 5 minutes](/@init_27/convolutional-neural-network-in-5-minutes-8f867eb9ca39)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Decoding ResNet Architecture](http://teleported.in/posts/decoding-resnet-architecture/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Yet Another ResNet Tutorial](/@apiltamang)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Where we go from here:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Review [[08:24](https://youtu.be/9C06ZPF8Uuc?t=8m24s)]:'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Kaggle CLI : How to download data 1:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Kaggle CLI](https://github.com/floydwch/kaggle-cli) is a good tool to use
    when you are downloading from Kaggle. Because it is downloading data from Kaggle
    website (through screen scraping), it breaks when the website changes. When that
    happens, run `pip install kaggle-cli --upgrade`.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Then you can run:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Replace `<username>`, `<password>` with your credential and `<competition>`
    is what follows `/c/` in the URL. For example, if you are trying to download dog
    breed data from `https://www.kaggle.com**/c/**dog-breed-identification` the command
    would look like:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'Make sure you had clicked on the `Download` button from your computer once
    and accepted the rules:'
  prefs: []
  type: TYPE_NORMAL
- en: 'CurWget (Chrome extension): How to download data 2:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[](https://chrome.google.com/webstore/detail/curlwget/jmocjfidanebdlinpbcdkcmgdifblncg)'
  prefs: []
  type: TYPE_NORMAL
- en: Quick Dogs vs. Cats [[13:39](https://youtu.be/9C06ZPF8Uuc?t=13m39s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'Often the notebook assumes that your data is in `data` folder. But maybe you
    want to put them somewhere else. In that case, you can use symbolic link (symlink
    for short):'
  prefs: []
  type: TYPE_NORMAL
- en: 'Here is an end to end process to get a state of the art result for dogs vs.
    cats:'
  prefs: []
  type: TYPE_NORMAL
- en: Quick Dogs v Cats
  prefs: []
  type: TYPE_NORMAL
- en: 'A little further analysis:'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '`from_paths` : Indicates that subfolder names are the labels. If your `train`
    folder or `valid` folder has a different name, you can send `trn_name` and `val_name`
    argument.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`test_name` : If you want to submit to Kaggle competition, you will need to
    fill in the name of the folder where the test set is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Notice that we did not set `pre_compue=True`. It is just a shortcut which caches
    some of the intermediate steps that do not have to be recalculated each time.
    If you are at all confused about it, you can just leave it off.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Remember, when `pre_compute=True` , data augmentation does not work.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '`bn_freeze` : If you are using a bigger deeper model like ResNet50 or ResNext101
    (anything with number bigger than 34) on a dataset that is very similar to ImageNet
    (i.e. side-on photos of standard object whose size is similar to ImageNet between
    200–500 pixels), you should add this line. We will learn more in the second half
    of the course, but it is causing the batch normalization moving averages to not
    be updated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[How to use other libraries — Keras](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb)
    [[20:02](https://youtu.be/9C06ZPF8Uuc?t=20m2s)]'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: It is important to understand how to use libraries other than Fast.ai. Keras
    is a good example to look at because just like Fast.ai sits on top of PyTorch,
    it sits on top of varieties of libraries such as TensorFlow, MXNet, CNTK, etc.
  prefs: []
  type: TYPE_NORMAL
- en: If you want to run [the notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/keras_lesson1.ipynb),
    run `pip install tensorflow-gpu keras`
  prefs: []
  type: TYPE_NORMAL
- en: '**Define data generators**'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: The idea of train folder and validation folder with subfolders with the label
    names is commonly done, and Keras also does it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Keras requires much more code and many more parameters to be set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rather than creating a single data object, in Keras you define `DataGenerator`
    and specify what kind of data augmentation we want it to do and also what kind
    of normalization to do. In other words, in Fast.ai, we can just say “whatever
    ResNet50 requires, just do that for me please” but in Keras, you need to know
    what is expected. There is no standard set of augmentations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You have to then create a validation data generator in which you are responsible
    to create a generator that does not have data augmentation. And you also have
    to tell it not to shuffle the dataset for validation because otherwise you cannot
    keep track of how well you are doing.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**2\. Create a model**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The reason Jeremy used ResNet50 for Quick Dogs and Cats was because Keras does
    not have ResNet34\. We want to compare apple to apple.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You cannot ask it to construct a model that is suitable for a particular dataset,
    so you have to do it by hand.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: First you create a base model, then you construct layers you want to add on
    top of it.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**3\. Freeze layers and compile**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Loop through layers and freeze them manually by calling `layer.trainable=False`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: You need to compile a model
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Pass the type of optimizer, loss, and metrics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**4\. Fit**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: Keras expects to know how many batches there are per epoch.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`workers` : how many processors to use'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**5\. Fine-tune: Unfreeze some layers, compile, then fit again**'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '**Pytorch** — If you want to deploy to mobile devices, PyTorch is still very
    early.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Tensorflow** — If you want to convert things you learned in this class, do
    more work with Keras, but it would take a bit more work and is hard to get the
    same level of results. Maybe there will be TensorFlow compatible version of Fast.ai
    in future. We will see.'
  prefs: []
  type: TYPE_NORMAL
- en: Create Submission file for Kaggle [[32:45](https://youtu.be/9C06ZPF8Uuc?t=32m45s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To create the submission files, we need two pieces of information:'
  prefs: []
  type: TYPE_NORMAL
- en: '`data.classes` : contains all the different classes'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`data.test_ds.fnames` : test file names'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: It is always good idea to use `TTA:`
  prefs: []
  type: TYPE_NORMAL
- en: '`is_test=True` : it will give you predictions on the test set rather than the
    validation set'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: By default, PyTorch models will give you back the log of the predictions, so
    you need to do `np.exp(log_preds)` to get the probability.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: Create Pandas `DataFrame`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Set the column name as `data.classes`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: Insert a new column at position zero named `id`. Remove first 5 and last 4 letters
    since we just need IDs (a file name looks like `test/0042d6bf3e5f3700865886db32689436.jpg`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: Now you can call `ds.to_csv` to create a CSV file and `compression='gzip'` will
    zip it up on the server.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: You can use Kaggle CLI to submit from the server directly, or you can use `FileLink`
    which will give you a link to download the file from the server to your computer.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Individual prediction [[39:32](https://youtu.be/9C06ZPF8Uuc?t=39m32s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: What if we want to run a single image through a model to get a prediction?
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: We will pick a first file from the validation set.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'This is the shortest way to get a prediction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: Image must be transformed. `tfms_from_model` returns training transforms and
    validation transforms. In this case, we will use validation transform.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Everything that gets passed to or returned from a model is generally assumed
    to be in a mini-batch. Here we only have one image, but we have to turn that into
    a mini-batch of a single image. In other words, we need to create a tensor that
    is not just `[rows, columns, channels]` , but `[number of images, rows, columns,
    channels]`.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`im[None]` : Numpy trick to add additional unit axis to the start.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Theory: What is actually going on behind the scenes with convolutional neural
    network [[42:17](https://youtu.be/9C06ZPF8Uuc?t=42m17s)]'
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We saw a little bit of theory in Lesson 1 — [http://setosa.io/ev/image-kernels/](http://setosa.io/ev/image-kernels/)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Convolution is something where we have a little matrix (nearly always 3x3 in
    deep learning) and multiply every element of that matrix by every element of 3x3
    section of an image and add them all together to get the result of that convolution
    at one point.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Otavio’s fantastic visualization (he created Word Lens):**'
  prefs: []
  type: TYPE_NORMAL
- en: '**Jeremy’s visualization:** [**Spreadsheet**](https://github.com/fastai/fastai/blob/master/courses/dl1/excel/conv-example.xlsx)
    **[**[**49:51**](https://youtu.be/9C06ZPF8Uuc?t=49m51s)**]**'
  prefs: []
  type: TYPE_NORMAL
- en: I used [https://office.live.com/start/Excel.aspx](https://office.live.com/start/Excel.aspx?ui=en-US&rs=US)
  prefs: []
  type: TYPE_NORMAL
- en: This data is from MNIST
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Activation**: A number that is calculated by applying some kind of linear
    operation to some numbers in the input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rectified Linear Unit (ReLU)**: Throw away negative — i.e. MAX(0, x)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filter/Kernel:** A 3x3 slice of a 3D tensor you used for convolution'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Tensor:** Multidimensional array or matrix Hidden Layer A layer that is neither
    input nor output'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Max pooling:** A (2,2) max pooling will halve the resolution in both height
    and width — think of it as a summary'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fully connected layer:** Give a weight to each and every single activation
    and calculate the sum product. Weight matrix is as big as the entire input.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note: There are many things you can do after the max pooling layer. One of
    them is to do another max pool across the entire size. In older architectures
    or structured data, we do fully connected layer. Architecture that make heavy
    use of fully connected layers are prone to overfitting and are slower. ResNet
    and ResNext do not use very large fully connected layers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: What happens if the input had 3 channels? [[1:05:30](https://youtu.be/9C06ZPF8Uuc?t=1h5m30s)]
    It will look something similar to the Conv1 layer which has 2 channels — therefore,
    filters have 2 channels per filter. Pre-trained ImageNet models use 3 channels.
    Some of the techniques you can use when you do when you do have less than 3 channel
    is to either duplicate one of the channels to make it 3, or if you have 2, then
    get an average and consider that as the third channel. If you have 4 channels,
    you could add extra level to the convolutional kernel with all zeros.'
  prefs: []
  type: TYPE_NORMAL
- en: What happens next? [[1:08:47](https://youtu.be/9C06ZPF8Uuc?t=1h8m47s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: We have gotten as far as fully connected layer (it does classic matrix product).
    In the excel sheet, there is one activation. If we want to look at which one of
    ten digit the input is, we actually want to calculate 10 numbers.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at an example where we are trying to predict whether a picture is
    a cat, a dog, or a plane, or fish, or a building. Our goal is:'
  prefs: []
  type: TYPE_NORMAL
- en: Take output from the fully connected layer (no ReLU so there may be negatives)
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate 5 numbers where each of them is between 0 and 1 and they add up to
    1.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: To do this, we need a different kind of activation function (a function applied
    to an activation).
  prefs: []
  type: TYPE_NORMAL
- en: Why do we need non-lineality? If you stack multiple linear layers, it is still
    just a linear layer. By adding non-linear layers, we can fit arbitrarily complex
    shapes. The non-linear activation function we used was ReLU.
  prefs: []
  type: TYPE_NORMAL
- en: Softmax [[01:14:08](https://youtu.be/9C06ZPF8Uuc?t=1h14m8s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Softmax only ever occurs in the final layer. It outputs numbers between 0 and
    1, and they add up to 1\. In theory, this is not strictly necessary — we could
    ask out neural net to learn a set of kernels which give probabilities that line
    up as closely as possible with what we want. In general with deep learning, if
    you can construct your architecture so that the desired characteristics are as
    easy to express as possible, you will end up with better models (learn more quickly
    and with less parameters).
  prefs: []
  type: TYPE_NORMAL
- en: 'Get rid of negatives by `e^x` because we cannot have negative probabilities.
    It also accentuates the value difference (2.85 : 4.08 → 17.25 : 59.03)'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'All the math that you need to be familiar with to do deep learning:'
  prefs: []
  type: TYPE_NORMAL
- en: 2\. We then add up the `exp` column (182.75), and divide the `e^x` by the sum.
    The result will always be positive since we divided positive by positive. Each
    number will be between 0 and 1, and the total will be 1.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: What kind of activation function do we use if we want to classify
    the picture as cat and dog? [[1:20:27](https://youtu.be/9C06ZPF8Uuc?t=1h20m27s)]
    It so happens that we are going to do that right now. One reason we might want
    to do that is to do multi-label classification.'
  prefs: []
  type: TYPE_NORMAL
- en: Planet Competition [[01:20:54](https://youtu.be/9C06ZPF8Uuc?t=1h20m54s)]
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson2-image_models.ipynb)
    / [Kaggle page](https://www.kaggle.com/c/planet-understanding-the-amazon-from-space)'
  prefs: []
  type: TYPE_NORMAL
- en: I would definitely recommend anthropomorphizing your activation functions. They
    have personalities. [[1:22:21](https://youtu.be/9C06ZPF8Uuc?t=1h22m21s)]
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Softmax does not like to predicting multiple things. It wants to pick one thing.
  prefs: []
  type: TYPE_NORMAL
- en: 'Fast.ai library will automatically switch into multi-label mode if there is
    more than one label. So you do not have to do anything. But here is what happens
    behind the scene:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: Multi-label classification cannot be done with Keras style approach where subfolder
    is the name of the label. So we use `from_csv`
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`transform_top_down` : it does more than just a vertical flip. There are 8
    possible symmetries for a square — it can be rotated through 0, 90, 180, 270 degrees
    and for each of those, it can be flipped (**dihedral** group of eight)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: 'We had seen `data.val_ds` , `test_ds`, `train_ds`(`ds`: dataset) for which
    you can get an individual image by `data.train_ds[0]`, for example.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`dl` is a data loader which will give you a mini-batch, specifically *transformed*
    mini-batch. With a data loader, you cannot ask for a particular mini-batch; you
    can only get back the `next` mini-batch. In Python, it is called “generator” or
    “iterator”. PyTorch really leverages modern Python methodologies.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[If you know Python well, PyTorch comes very naturally. If you don’t know Python
    well, PyTorch is a good reason to learn Python well.](https://youtu.be/9C06ZPF8Uuc?t=1h27m45s)'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: '`x` : a mini-batch of images, `y` : a mini-batch of labels.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: If you are never sure what arguments a function takes, hit `shift+tab` .
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'Behind the scenes, PyTorch and fast.ai are turning our labels into one-hot-encoded
    labels. If the actual label is dog, it will look like:'
  prefs: []
  type: TYPE_NORMAL
- en: We take the difference between `actuals` and `softmax` , add them up to say
    how much error there is (i.e. loss function) [[1:31:02](https://youtu.be/9C06ZPF8Uuc?t=1h31m2s)].
  prefs: []
  type: TYPE_NORMAL
- en: One-hot-encoding is terribly inefficient for storing, so we will store an index
    value (single integer) rather than 0’s and 1’s for the target value (`y`) [[1:31:21](https://youtu.be/9C06ZPF8Uuc?t=1h31m21s)].
    If you look at the `y` values for the dog breeds competition, you won’t actually
    see a big lists of 1’s and 0's, but you will wee a single integer. And internally,
    PyTorch is converting the index to one-hot-encoded vector (even though you will
    literally never see it). PyTorch has different loss functions for ones that are
    one hot encoded and others that are not — but these details are hidden by the
    fast.ai library so you do not have to worry about it. But the cool thing to realize
    is that we are doing exactly the same thing for both single label classification
    and multi label classification.
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Does it make sense to change the base of log for softmax?[[01:32:55](https://youtu.be/9C06ZPF8Uuc?t=1h32m55s)]
    No, changing the base is just a linear scaling which neural net can learn easily:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`*1.4` : The image was washed out, so making it more visible (“brightening
    it up a bit”). Images are just matrices of numbers, so we can do things like this.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It is good to experiment images like this because these images are not at all
    like ImageNet. The vast majority of things you do involving convolutional neural
    net will not actually be anything like ImageNet (medical imaging, classifying
    different kinds of steel tube, satellite images, etc)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: We will not use `sz=64` for cats and dogs competition because we started with
    pre-trained ImageNet network which starts off nearly perfect. If we re-trained
    the whole set with 64 by 64 images, we would destroy the weights that are already
    very good. Remember, most of ImageNet models are trained with 224 by 224 or 299
    by 299 images.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There is no images in ImageNet that looks like the one above. And only the first
    couple layers are useful to us. So starting out with smaller images works well
    in this case.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`[lr/9, lr/3, lr]` — this is because the images are unlike ImageNet image and
    earlier layers are probably not as close to what they need to be.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: 'A couple of questions people have asked what this does [[01:38:46](https://youtu.be/9C06ZPF8Uuc?t=1h38m46s)]:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'When we specify what transforms to apply, we send a size:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: One of the things the data loader does is to resize the images on-demand. This
    has nothing to do with `data.resize` . If the initial image is 1000 by 1000, reading
    that JPEG and resizing it to 64 by 64 take more time than training the convolutional
    net. `data.resize` tells it that we will not use images bigger than `sz*1.3` so
    go through once and create new JPEGs of this size. Since images are rectangular,
    so new JPEGs whose smallest edge is `sz*1.3` (center-cropped). It will save you
    a lot of time.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: Instead of `accuacy`, we used [F-beta](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.fbeta_score.html)
    for this notebook — it is a way of weighing false negatives and false positives.
    The reason we are using it is because this particular Kaggle competition wants
    to use it. Take a look at [planet.py](https://github.com/fastai/fastai/blob/master/courses/dl1/planet.py)
    to see how you can create your own metrics function. This is what gets printed
    out at the end `[ 0\. 0.08932 0.08218 **0.9324** ]`
  prefs: []
  type: TYPE_NORMAL
- en: Activation function for multi-label classification [[01:44:25](https://youtu.be/9C06ZPF8Uuc?t=1h44m25s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Activation function for multi-label classification is called **sigmoid.**
  prefs: []
  type: TYPE_NORMAL
- en: '**Question**: Why don’t we start training with differential learning rate rather
    than training the last layers alone? [[01:50:30](https://youtu.be/9C06ZPF8Uuc?t=1h50m30s)]'
  prefs: []
  type: TYPE_NORMAL
- en: You can skip training just the last layer and go straight to differential learning
    rates, but you probably do not want to. Convolutional layers all contain pre-trained
    weights, so they are not random — for things that are close to ImageNet, they
    are really good; for things that are not close to ImageNet, they are better than
    nothing. All of our fully connected layers, however, are totally random. Therefore,
    you would always want to make the fully connected weights better than random by
    training them a bit first. Otherwise if you go straight to unfreeze, then you
    are actually going to be fiddling around with those early layer weights when the
    later ones are still random — which is probably not what you want.
  prefs: []
  type: TYPE_NORMAL
- en: 'Question: When you use the differential learning rates, do those three learning
    rates spread evenly across the layers? [[01:55:35](https://youtu.be/9C06ZPF8Uuc?t=1h55m35s)]
    We will talk more about this later in the course but the fast.ai library, there
    is a concept of “layer groups”. In something like ResNet50, there are hundreds
    of layers and you probably do not want to write hundreds of learning rates, so
    the library decided for you how to split them and the last one always refers to
    just the fully connected layers that we have randomly initialized and added.'
  prefs: []
  type: TYPE_NORMAL
- en: Visualizing the layers [[01:56:42](https://youtu.be/9C06ZPF8Uuc?t=1h56m42s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '`‘input_shape’, [-1, **3, 64, 64**]` — PyTorch lists channel before the image
    size. Some of the GPU computations run faster when it is in that order. This is
    done behind scene by the transformation step.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-1` : indicates however big the batch size is. Keras uses `None` .'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`‘output_shape’, [-1, 64, 32, 32]` — 64 is the number of kernels'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question**: Learning rate finder for a very small dataset returned strange
    number and the plot was empty [[01:58:57](https://youtu.be/9C06ZPF8Uuc?t=1h58m57s)]
    — The learning rate finder will go through a mini-batch at a time. If you have
    a tiny dataset, there is just not enough mini-batches. So the trick is to make
    your batch size very small like 4 or 8.'
  prefs: []
  type: TYPE_NORMAL
- en: Structured Data [[01:59:48](https://youtu.be/9C06ZPF8Uuc?t=1h59m48s)]
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There are two types of dataset we use in machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Unstructured** — Audio, images, natural language text where all of the things
    inside an object are all the same kind of things — pixels, amplitude of waveform,
    or words.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Structured** — Profit and loss statement, information about a Facebook user
    where each column is structurally quite different. “Structured” refers to columnar
    data as you might find in a database or a spreadsheet where different columns
    represent different kinds of things, and each row represents an observation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Structured data is often ignored in academics because it is pretty hard to
    get published in fancy conference proceedings if you have a better logistics model.
    But it is the thing that makes the world goes round, makes everybody money and
    efficiency. We will not ignore it because we are doing practical deep learning,
    and Kaggle does not either because people put prize money up on Kaggle to solve
    real-world problems:'
  prefs: []
  type: TYPE_NORMAL
- en: '[Corporación Favorita Grocery Sales Forecasting](https://www.kaggle.com/c/favorita-grocery-sales-forecasting)
    — which is currently running'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[Rossmann Store Sales](https://www.kaggle.com/c/rossmann-store-sales) — almost
    identical to above but completed competition.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Rossmann Store Sale [[02:02:42](https://youtu.be/9C06ZPF8Uuc?t=2h2m42s)]
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[Notebook](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson3-rossman.ipynb)'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: '`fastai.structured` — not PyTorch specific and also used in machine learning
    course doing random forests with no PyTorch at all. It can used on its own without
    any of the other parts of Fast.ai library.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`fastai.column_data` — allows us to do Fast.ai and PyTorch stuff with columnar
    structured data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: For structured data need to use **Pandas** a lot. Pandas is an attempt to replicate
    R’s data frames in Python (If you are not familiar with Pandas, here is a good
    book — [Python for Data Analysis, 2nd Edition](http://shop.oreilly.com/product/0636920050896.do))
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: There are a lot of data pre-processing This notebook contains the entire pipeline
    from the third place winner ([Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737)).
    Data processing is not covered in this course, but is covered in machine learning
    course in some detail because feature engineering is very important.
  prefs: []
  type: TYPE_NORMAL
- en: Looking at CSV files
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: '`StoreType` — you often get datasets where some columns contain “code”. It
    really does not matter what the code means. Stay away from learning too much about
    it and see what the data says first.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Joining tables
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'This is a relational dataset, and you have join quite a few tables together
    — which is easy to do with Pandas’ `merge`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: 'From Fast.ai library:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Take a date and pull out a bunch of columns such as “day of week”, “start of
    a quarter”, “month of year” and so on and add them all to the dataset.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Duration section will calculate things like how long until the next holiday,
    how long it has been since the last holiday, etc.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '`to_feather` : Saves a Pandas’ data frame into a “feather” format which takes
    it as it sits in RAM and dumps it to the disk. So it is really really fast. Ecuadorian
    grocery competition has 350 million records, so you will care about how long it
    takes to save.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Next week
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'split columns into two types: categorical and continuous. Categorical column
    will be represented as one hot encoding, and continuous column gets fed into fully
    connected layer as is.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'categorical: store #1 and store #2 are not numerically related to each other.
    Similarly, day of week Monday (day 0) and Tuesday (day 1).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'continuous: Things like distance in kilometers to the nearest competitor is
    a number we treat numerically.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ColumnarModelData`'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
