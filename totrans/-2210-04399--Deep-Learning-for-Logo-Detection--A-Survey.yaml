- en: <!--yml
  prefs: []
  type: TYPE_NORMAL
- en: 'category: 未分类'
  prefs: []
  type: TYPE_NORMAL
- en: 'date: 2024-09-06 19:44:11'
  prefs: []
  type: TYPE_NORMAL
- en: -->
  prefs: []
  type: TYPE_NORMAL
- en: '[2210.04399] Deep Learning for Logo Detection: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2210.04399](https://ar5iv.labs.arxiv.org/html/2210.04399)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: \UseRawInputEncoding
  prefs: []
  type: TYPE_NORMAL
- en: 'Deep Learning for Logo Detection: A Survey'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Sujuan Hou, Member, IEEE, Jiacheng Li, Weiqing Min, Senior Member, IEEE, Qiang
    Hou,
  prefs: []
  type: TYPE_NORMAL
- en: 'Yanna Zhao, Member, IEEE, Yuanjie Zheng, Member, IEEE, and Shuqiang Jiang,
    Senior Member, IEEE This work was supported by the National Nature Science Foundation
    of China (No.62072289, 61972378, U193620), CAAI-Huawei MindSpore Open Fund. S.
    Hou, J. Li, Q. Hou, Y. Zhao and Y. Zheng are School of Information Science and
    Engineering, Shandong Normal University, Shandong, 250358, China. Email: sujuanhou@sdnu.edu.cn,
    2021317140@stu.sdnu.edu.cn, 2019309052@stu.sdnu.edu.cn, yannazhao@sdnu.edu.cn,
    and zhengyuanjie@gmail.com. W. Min and S. Jiang are with the Key Laboratory of
    Intelligent Information Processing, Institute of Computing Technology, Chinese
    Academy of Sciences, Beijing, 100190, China, and also with University of Chinese
    Academy of Sciences, Beijing, 100049, China. Email: minweiqing@ict.ac.cn, and
    sqjiang@ict.ac.cn.'
  prefs: []
  type: TYPE_NORMAL
- en: Abstract
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: When logos are increasingly created, logo detection has gradually become a research
    hotspot across many domains and tasks. Recent advances in this area are dominated
    by deep learning-based solutions, where many datasets, learning strategies, network
    architectures, etc. have been employed. This paper reviews the advance in applying
    deep learning techniques to logo detection. Firstly, we discuss a comprehensive
    account of public datasets designed to facilitate performance evaluation of logo
    detection algorithms, which tend to be more diverse, more challenging, and more
    reflective of real life. Next, we perform an in-depth analysis of the existing
    logo detection strategies and the strengths and weaknesses of each learning strategy.
    Subsequently, we summarize the applications of logo detection in various fields,
    from intelligent transportation and brand monitoring to copyright and trademark
    compliance. Finally, we analyze the potential challenges and present the future
    directions for the development of logo detection to complete this survey.
  prefs: []
  type: TYPE_NORMAL
- en: 'Index Terms:'
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: logo detection, computer vision, deep learning, datasets
  prefs: []
  type: TYPE_NORMAL
- en: I Introduction
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logos usually consist of texts, shapes, images, or their combination. Logo detection
    benefits a wide range of applications in different areas, such as intelligent
    transportation [[1](#bib.bib1), [2](#bib.bib2)], social media monitoring [[3](#bib.bib3)],
    and infringement detection [[4](#bib.bib4), [5](#bib.bib5)]. Meanwhile, some competitions
    have emerged, such as Robust Logo Detection Grand Challenge [[5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)] and Few-shot Logo Detection [[9](#bib.bib9)].
  prefs: []
  type: TYPE_NORMAL
- en: The main task of logo detection is to determine the location of a specific logo
    in images/videos and identify them. Although it may be regarded as a particular
    object task, logo detection in real-world images can be pretty challenging since
    numerous brands may have highly diverse contexts, varied scales, changes in illumination,
    size, resolution, and even non-rigid deformation (as shown in Fig. 1).
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/70a48b3668e2e60a738460940b4151ca.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) dim light
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/107331ed035c57bd8731e4dad361c821.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) image rotation
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/94e320419505381ebeec818d7e28e283.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) small-scale logos
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/e77a9d073048e646399100ae9dcf9261.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) multi-scale logos
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fbb9b443239f9a13575e9d74d8acf535.png)'
  prefs: []
  type: TYPE_IMG
- en: (e) non-rigid deformation
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/59880c9604f91eb62ca494066b5c25a3.png)'
  prefs: []
  type: TYPE_IMG
- en: (f) glare reflection
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 1: Examples of images in adverse conditions.'
  prefs: []
  type: TYPE_NORMAL
- en: Many previous works on logo detection employ hand-crafted features (like SIFT [[10](#bib.bib10)])
    to represent logos and use statistical classifiers for classification. Such methods
    suffer from complex image preprocessing pipelines and poor robustness when dealing
    with a much larger number of logos. Recent years have witnessed the rousing success
    of deep learning since ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [[11](#bib.bib11)].
    Deep learning-based solutions with expressive feature representation capability
    offer better robustness, accuracy, and speed and thus attract increasing attention.
    There are more than 100 papers about logo detection from 1993 to 2022, and a concise
    milestone of logo detection is shown in Fig. 2\. We can see that many deep learning-based
    logo detection strategies have been proposed since 2015\. This survey mainly concentrates
    on deep learning-based solutions specially developed for logo detection.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/209fd4b766a88e3958dbe66f66535d1f.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 2: A concise milestone for logo detection.'
  prefs: []
  type: TYPE_NORMAL
- en: Even though deep learning has dominated the logo research community, a comprehensive
    and in-depth survey on deep learning-based solutions is lacking. In this survey,
    we mainly focus on the advances in recent deep learning for logo detection. We
    provide in-depth analysis and discussion on existing studies in various aspects,
    covering datasets, pipelined used, task types, detection strategies, loss functions,
    their contributions and limitations. We also try to analyze potential research
    challenges and future research directions for logo detection. We hope our work
    could provide a novel perspective to promote the understanding of deep learning-based
    logo detection, foster research on open challenges, and speed up the development
    of the logo research field.
  prefs: []
  type: TYPE_NORMAL
- en: The rest of this paper is organized as follows. In Section II, we investigate
    the public logo detection datasets. In Section III, we review and organize the
    currently available work on logo detection. In Section IV, we introduce the applications
    of logo detection in real-world scenarios. In Section V, we discuss its challenges
    and prominent future research directions. Finally, we summarize the whole text
    in Section VI.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/23e6e5085e0221cb5f62bf76b2be3542.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) BelgaLogos
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/987e0ccb421818becf4f98cd67ab11be.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) FoodLogoDet-1500
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/de367e8631fbf4ed7b7e1915b2f7f42b.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) QMUL-OpenLogo
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/b4db70881758da104b88b06ce50ada2e.png)'
  prefs: []
  type: TYPE_IMG
- en: (d) LogoDet-3K
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 3: Logo images sampled from different datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: II Logo Datasets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Deep learning has brought great success to object detection in recent years,
    where datasets play a crucial role. Datasets are not only a common basis for comparing
    and measuring the performance of algorithms but also an essential factor in supporting
    advanced object detection algorithms. This section provides an overview of the
    logo datasets for detection. In addition, we also give a brief summary of existing
    logo classification datasets.
  prefs: []
  type: TYPE_NORMAL
- en: 'In recent years, many logo datasets intended for detection have been created
    to solve the problem of large realistic datasets with accurate ground truth. The
    use of these datasets enables qualitative as well as quantitative comparisons
    and allows benchmarking of different algorithms. We conducted statistics on existing
    datasets commonly used for logo detection and classified them into three types
    based on their scale: small-scale, medium-scale, and large-scale. Table I provides
    statistics on the available logo datasets, and Fig. 3 gives some illustrative
    examples from these datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: The small-scale datasets include BelgaLogos [[12](#bib.bib12)], FlickrLogos-32 [[13](#bib.bib13)],
    etc. As the first benchmark dataset proposed for logo detection, BelgaLogos [[12](#bib.bib12)]
    consists of 10,000 images of natural scenes, with 37 different logos and 2,695
    instances of logos labeled with bounding boxes. FlickrLogos-32 [[13](#bib.bib13)],
    one of the most popular small-scale datasets for logo detection, comprises 32
    different classes with 70 images in each class. The images in this dataset are
    mainly captured from the real world, and many contain occlusions, appearance changes,
    and lighting changes, making detecting this dataset very challenging.
  prefs: []
  type: TYPE_NORMAL
- en: Datasets with medium-scale include Logo-Net [[14](#bib.bib14)], QMUL-OpenLogo [[15](#bib.bib15)],
    FoodLogoDet-1500 [[16](#bib.bib16)], etc. Logo-Net [[14](#bib.bib14)] is built
    for detecting logos and identifying brands from real-world product images. It
    consists of two sub-datasets, namely Logo-18 and Logo-160. QMUL-OpenLogo [[15](#bib.bib15)]
    is an open benchmark for logo detection, constructed by aggregating seven existing
    datasets and building an open protocol for logo detection evaluation. The QMUL-OpenLogo
    dataset has a highly imbalanced distribution and significant variation in scale,
    which is critical to verify the performance of the detection algorithm. FoodLogoDet-1500 [[16](#bib.bib16)]
    is the first high-quality public dataset of food logos with uneven distribution
    among different food logo classes, which poses a challenge to the small sample
    food logo detection algorithms. The dataset is composed of 1,500 food logo classes
    with 99,768 images.
  prefs: []
  type: TYPE_NORMAL
- en: There are also some large-scale datasets, such as LogoDet-3K [[17](#bib.bib17)]
    and PL8K [[18](#bib.bib18)]. LogoDet-3K [[17](#bib.bib17)] divides all logos into
    nine super-classes based on the needs of daily life and the main positioning of
    common enterprises, namely Clothing, Food, Transportation, Electronics, Necessities,
    Leisure, Medicine, Sports, and Others. The dataset consists of 3,000 logo classes,
    158,652 images, and 194,261 logo objects. The number of logo classes contained
    in different super-classes varies greatly. For example, the “Food”, “Clothes”,
    and “Necessities” contain more images and objects than other super-classes. The
    imbalanced distribution across different logo classes of LogoDet-3K poses a challenge
    to effectively detecting logos with few samples. PL8K [[18](#bib.bib18)] is a
    large logo detection dataset constructed semi-automatically. The dataset consists
    of 7,888 logo brands and 3,017,146 images, and at least 20 images per class.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE I: Statistics of existing logo detection datasets.'
  prefs: []
  type: TYPE_NORMAL
- en: '| #Scale | #Datasets | #Logos | #Brands | #Images | #Objects | #Public | #Year
    |'
  prefs: []
  type: TYPE_TB
- en: '| Small | BelgaLogos [[12](#bib.bib12)] | 37 | 37 | 10,000 | 2,695 | Yes |
    2009 |'
  prefs: []
  type: TYPE_TB
- en: '| FlickrLogos-27 [[19](#bib.bib19)] | 27 | 27 | 1,080 | 4,671 | Yes | 2011
    |'
  prefs: []
  type: TYPE_TB
- en: '| FlickrLogos-32 [[13](#bib.bib13)] | 32 | 32 | 2,240 | 5,644 | Yes | 2011
    |'
  prefs: []
  type: TYPE_TB
- en: '| MICC-Logos [[10](#bib.bib10)] | 13 |  | 720 | - | No | 2013 |'
  prefs: []
  type: TYPE_TB
- en: '| Logo-18 [[14](#bib.bib14)] | 18 | 10 | 8,460 | 16,043 | No | 2015 |'
  prefs: []
  type: TYPE_TB
- en: '| Logos-32plus [[20](#bib.bib20)] | 32 | 32 | 7,830 | 12,302 | No | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '| Top-Logo-10 [[21](#bib.bib21)] | 10 | 10 | 700 | - | No | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '| Video SportsLogo [[22](#bib.bib22)] | 20 | 20 | 2,000 | - | No | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '| VLD 1.0 [[23](#bib.bib23)] | 66 | 66 | 25,189 | - | No | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| SportLogo [[24](#bib.bib24)] | 31 | 31 | 2,836 | - | Yes | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| VLD-45 [[25](#bib.bib25)] | 45 | 45 | 45,000 | - | No | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| Medium | Logo-160 [[14](#bib.bib14)] | 160 | 100 | 73,414 | 130,608 | No
    | 2015 |'
  prefs: []
  type: TYPE_TB
- en: '| Logos-in-the-Wild [[26](#bib.bib26)] | 871 | 871 | 11,054 | 32,850 | Yes
    | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '| QMUL-OpenLogo [[15](#bib.bib15)] | 352 | 352 | 27,083 | - | Yes | 2018 |'
  prefs: []
  type: TYPE_TB
- en: '| PL2K [[27](#bib.bib27)] | 2,000 | 2,000 | 295,814 | - | No | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| FoodLogoDet-1500 [[16](#bib.bib16)] | 1,500 | - | 99,768 | 145,400 | Yes
    | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| Large | Open Brands [[28](#bib.bib28)] | 1,216 | 559 | 1,437,812 | 3,113,828
    | No | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| LogoDet-3K [[17](#bib.bib17)] | 3,000 | 2,864 | 158,652 | 194,261 | Yes |
    2020 |'
  prefs: []
  type: TYPE_TB
- en: '| PL8K [[18](#bib.bib18)] | 7,888 | 7,888 | 3,017,146 | - | No | 2022 |'
  prefs: []
  type: TYPE_TB
- en: 'In addition, there are also some datasets built for logo classification, e.g.
    WebLogo-2M [[29](#bib.bib29)] and Logo 2K+ [[30](#bib.bib30)]. Weblogo-2M [[29](#bib.bib29)]
    is obtained by automatic web data acquisition and processing. The dataset excludes
    images with small widths and/or heights and duplicate images. Compared with other
    datasets, the Weblogo-2M presents three unique properties inherent to large-scale
    data exploration for learning scalable logo models: (1) Weak Annotation. (2) Noisy
    (False Positives). (3) Class Imbalance. Logo-2K+ [[30](#bib.bib30)] is a large-scale
    high-quality logo dataset. It covers a variety of logo classes from the real world,
    and different types of logo images have various logo appearances, scales, and
    backgrounds since they are collected from different websites. The dataset has
    high spatial coverage of categories including Food, Clothes, Institutions, Accessories,
    Transportation, Electronics, Necessities, Cosmetics, Leisure, and Medical. The
    number of images is imbalanced among different categories. For instance, “Food”
    has 769 logo classes, while “Medical” has only 48.'
  prefs: []
  type: TYPE_NORMAL
- en: As with common object detection, mAP [[31](#bib.bib31)] is the most commonly
    used evaluation metric to measure logo detectors.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4d0a136f9feae2342fd5131970036742.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 4: The architecture of DRNA-Net [[30](#bib.bib30)].'
  prefs: []
  type: TYPE_NORMAL
- en: III Logo Detection
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In logo detection, logo classification is also an essential part. Therefore,
    we briefly summarize logo classification before introducing logo detection.
  prefs: []
  type: TYPE_NORMAL
- en: III-A Logo Classification
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'As one of the most critical tasks in computer vision, logo classification aims
    to recognize the logo name corresponding to the input image. According to different
    feature extraction strategies, existing classification methods are divided into
    two categories: *traditional machine learning-based methods* and *deep learning-based
    methods*. Some representative methods will be described briefly in the following.'
  prefs: []
  type: TYPE_NORMAL
- en: III-A1 Traditional Machine Learning-based Methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The traditional logo classification methods extract features through manual
    features, such as SIFT and HOG, and then classify them by a classifier. Support
    Vector Machine (SVM) [[32](#bib.bib32)] is a classifier that performs binary data
    classification in a supervised learning manner. In traditional logo classification,
    SVM also shows excellent performance [[33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35),
    [36](#bib.bib36)]. Carvalho *et al*. [[35](#bib.bib35)] proposed a self-learning
    and automatic detection method that performs detection without any prior data.
    The scheme automatically identifies the candidate regions of the localization
    logo, uses the HOG features extracted from the localization to train the object
    detector and some sub-detectors and uses the SVM to recognize the logo image.
  prefs: []
  type: TYPE_NORMAL
- en: K-Nearest Neighbor (KNN) is a supervised learning algorithm commonly used in
    classification [[37](#bib.bib37), [38](#bib.bib38)]. Gopinathan *et al*. [[38](#bib.bib38)]
    proposed a vehicle logo recognition system in 2018\. They used Euclidean distance
    on the initial training dataset to summarize the pixel intensity distribution
    by applying each channel’s mean and standard deviation and used the K-means algorithm
    to cluster the color histogram features to group different logos. Then HOG and
    KNN algorithms extract logo features and classify logos.
  prefs: []
  type: TYPE_NORMAL
- en: III-A2 Deep Learning-based Methods
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In recent years, with the continuous development of deep learning, deep learning
    based solutions have also been successfully applied to logo classification [[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44),
    [45](#bib.bib45), [46](#bib.bib46)]. Karimi *et al*. [[43](#bib.bib43)] used the
    DCNN logo recognition algorithm, which conducted a pre-trained model for feature
    extraction and then used SVM for logo classification. They also used transfer
    learning to improve existing pre-trained models for logo recognition. Finally,
    the fine-tuned deep model is applied to the parallel structure to obtain a more
    efficient deep model for logo recognition.
  prefs: []
  type: TYPE_NORMAL
- en: 'The latest trend in logo classification is to design efficient networks with
    limited resources [[30](#bib.bib30), [47](#bib.bib47), [48](#bib.bib48), [18](#bib.bib18)].
    Wang *et al*. [[30](#bib.bib30)] proposed a Discriminative Region Navigation and
    Augmentation Network (DRNA-Net), which is capable of discovering more informative
    regions and expanding these regions for logo classification. DRNA-Net is mainly
    divided into four parts: navigator sub-network, teacher sub-network, region-oriented
    data augmentation sub-network, and scrutinizer sub-network. Specifically, the
    navigation sub-network first computes the amount of information in all regions
    generated by pre-defined anchors in the image. In order to make the navigation
    sub-network selects the most informative logo-relevant regions, the teacher sub-network
    then evaluates each region’s confidence that belongs to the ground-truth class.
    The region-oriented data augmentation sub-network can augment the selected regions
    to localize more relevant logo regions. Finally, the features of augment regions
    and the whole image are fused by the scrutinizer sub-network to obtain a unified
    feature representation for logo prediction. The architecture of DRNA-Net is shown
    in Fig. 4. In order to distinguish visually similar logos, Li *et al*. [[18](#bib.bib18)]
    proposed a multi-task learning architecture named SeeTek based on deep learning
    and scene text recognition. This model combines deep metric learning and text
    recognition into a single model leading to considerable performance improvements.
    The architecture of SeeTek is shown in Fig. 5.'
  prefs: []
  type: TYPE_NORMAL
- en: III-B Logo Detection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logo detection can be seen as a particular case of general object detection.
    The purpose of logo detection is to detect logo instances of predefined logo classes
    in images or videos [[14](#bib.bib14)]. In this section, we will present the current
    state-of-the-art work on logo detection in detail.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before the development of deep learning, early approaches to logo detection
    were implemented based on hand-crafted visual features (e.g., SIFT and HOG) and
    traditional classification models (e.g., SVM) [[49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52)]. For example, Sahbi *et al*. [[10](#bib.bib10)]
    proposed a logo matching system in 2013, where they used SIFT to conduct logo
    detection and recognition. The designed system can not only recognize and match
    multiple reference logos in an image but also is suitable for detecting similar
    logos. However, such traditional logo detection methods have certain limitations:
    (1) The region-selective search algorithm based on sliding windows lacks pertinence,
    especially with high time complexity. (2) The hand-designed features lack robustness
    to the variation of logo diversity.'
  prefs: []
  type: TYPE_NORMAL
- en: In recent research, deep learning has emerged as the mainstream for logo detection.
    According to different learning strategies, we categorize these models into region-based
    Convolutional Neural Network models, YOLO-based models, Single Shot Detector-based
    models, Feature Pyramid Network-based models and other models.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/7f9ed956d3cfa2bc3bd7c25bdc7b03bd.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5: The architecture of SeeTek [[18](#bib.bib18)].'
  prefs: []
  type: TYPE_NORMAL
- en: III-B1 Region-based Convolutional Neural Network models (RCNNs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Region-based Convolutional Neural Network (R-CNN [[53](#bib.bib53)]) is a typical
    region proposals-based approach. Compared with traditional detection algorithms,
    R-CNN has achieved considerable performance improvement. However, R-CNN still
    has several shortcomings. For example, R-CNN uses the Selective Search (SS) [[54](#bib.bib54)]
    algorithm to generate many overlapping boxes for redundant computation, leading
    to slow detection speed and taking up a large amount of storage space. The later
    proposed Fast R-CNN [[55](#bib.bib55)] solves this issue by creating an end-to-end
    trainable system. However, Fast R-CNN still uses the SS algorithm to generate
    region proposals, limiting its speed. To solve this problem, Ren *et al*. proposed
    Faster R-CNN [[56](#bib.bib56)] in 2015, which adopts region proposal network
    (RPN) to generate region proposals. Although Faster R-CNN has advantages in speed
    and efficiency, it still suffers from computational redundancy and low efficiency
    of small object detection.
  prefs: []
  type: TYPE_NORMAL
- en: Recently, RCNN-based logo detection has also achieved considerable success [[26](#bib.bib26),
    [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]. Since the same brand may
    contain multiple products, different product images of the same brand may present
    different visual content, and traditional image recognition methods cannot directly
    solve the problem of brand recognition. Hoi *et al*. [[14](#bib.bib14)] proposed
    a DeepLogo-DRCN scheme for logo detection and brand recognition by exploring several
    deep region-based convolutional network (DRCN) techniques for object detection.
    They adopt Selective Search [[54](#bib.bib54)] to generate regions of interests
    (RoIs) and input the RoIs into a fully convolutional network (FCN). Feature vectors
    are then obtained through fully connected layers (FCs) to train the final classifiers
    and bounding box regressors. The overall architecture is trained in an end-to-end
    way. This is the first work on deep learning-based logo detection, which provides
    a new perspective on logo detection research.
  prefs: []
  type: TYPE_NORMAL
- en: We know that training a large-scale logo detection model requires a large amount
    of data, and the logo datasets usually suffer from data scarcity. Data augmentation
    and transfer learning are common solutions to release the problem of data scarcity.
    Oliveira *et al*. [[60](#bib.bib60)] proposed an automatic graphic logo detection
    system based on Fast R-CNN [[55](#bib.bib55)], which is robust to unconstrained
    imaging conditions. They used transfer learning and data augmentation to train
    a convolutional neural network model and allowed multiple detections of potential
    regions containing objects. Experimental results demonstrate that this strategy
    is superior to the traditional methods [[13](#bib.bib13)]. However, the adopted
    SS algorithm still generates redundant calculations, reducing detection speed.
    In addition, Li *et al*. [[61](#bib.bib61)] built Faster R-CNN for logo detection
    by using transfer learning, data augmentation, and clustering to guarantee suitable
    hyperparameters and more precise anchors for RPN. The experimental results show
    that this improvement could significantly improve the detection accuracy.
  prefs: []
  type: TYPE_NORMAL
- en: III-B2 YOLO-based models (YOLOs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: YOLOs are single-stage detectors that are commonly used for logo detection.
    YOLOs directly detect images and outputs the category and location information
    of the detected objects. Early YOLO [[62](#bib.bib62)] has fast detection speed,
    but at the expense of accuracy, especially for small objects. The later improvements,
    like YOLOv2 [[63](#bib.bib63)], YOLOv3 [[64](#bib.bib64)], YOLOv4 [[65](#bib.bib65)],
    YOLOF [[66](#bib.bib66)], YOLOR [[67](#bib.bib67)], YOLOX [[68](#bib.bib68)],
    YOLOv6 [[69](#bib.bib69)], YOLOv7[[70](#bib.bib70)] improve the overall performance
    of YOLO, balancing the accuracy and speed.
  prefs: []
  type: TYPE_NORMAL
- en: YOLOs are widely used in vehicle logo detection. Given that real-time and high
    efficiency is essential issues in vehicle logo detection. Inspired by the superiority
    of deep learning in feature extraction, Yin *et al*. [[71](#bib.bib71)] proposed
    a high-efficiency vehicle logo detection system based on YOLOv2 [[63](#bib.bib63)].
    Compared with the traditional methods based on manual extraction features, the
    system has the advantages of self-learning features and direct image input and
    can realize the dual functions of positioning and recognition of the vehicle logo.
    In the case of complex backgrounds, a vehicle logo usually occupies only a small
    part of the image. Therefore, it is challenging to identify vehicle logos in real-world
    scenarios accurately. To solve this issue, Yang *et al*. [[72](#bib.bib72)] proposed
    a data-driven enhanced training method based on YOLOv3 [[64](#bib.bib64)]. They
    combined a feature extraction network with a multi-scale decision scheme to improve
    the detection accuracy of vehicle logos. However, the detection results of vehicle
    logos in complex scenes are unsatisfactory. Based on [[72](#bib.bib72)], Zhang
    *et al*. [[73](#bib.bib73)] analyzed the characteristics of vehicle identification
    in static images and found that both the network for feature extraction and the
    training strategy for detection has a significant impact on the accuracy of vehicle
    identification. They proposed a lightweight network structure with separable convolutions
    to replace traditional methods to improve detection accuracy and speed under the
    YOLO-based framework. Experiments show that this method improves the real-time
    performance of vehicle logo detection and also improves the detection accuracy
    of small-scale objects while maintaining the speed to a certain extent.
  prefs: []
  type: TYPE_NORMAL
- en: In various fields, the frequency of different logos usually varies widely. Therefore,
    the number of different logo classes is often unbalanced, making it difficult
    for models to detect logo classes with small samples correctly. Wang *et al*. [[17](#bib.bib17)]
    proposed a robust baseline method Logo-Yolo based on YOLOv3 [[64](#bib.bib64)].
    They first adopt the K-means clustering algorithm to select the number of candidate
    anchor boxes and aspect ratio dimensions. They then used Focal loss to address
    the imbalance of samples in the dataset. Lastly, they introduced CIoU loss to
    improve bounding box regression results. Compared with YOLOv3 [[64](#bib.bib64)],
    the performance of this method is significantly improved in predicting small objects
    and objects in complex backgrounds. However, in some specific cases, the method
    also shows poor performance, such as detecting similar or occluded logos.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/fa30695275ab8dfdd5bf29f7235848fa.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 6: The architecture of MFDNet [[16](#bib.bib16)].'
  prefs: []
  type: TYPE_NORMAL
- en: III-B3 Single Shot Detector-based models (SSDs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Single Shot MultiBox Detector (SSD) [[74](#bib.bib74)] is another single-stage
    detector using a single deep neural network. SSD uses multi-scale feature maps
    to detect objects at different scales, with the bottom layer predicting small
    objects and the top layer predicting large objects. While ensuring the detection
    speed, the detection accuracy of SSD outperforms a comparable state-of-the-art
    Faster R-CNN model. Therefore, SSDs are also widely used in vehicle logo detection [[58](#bib.bib58)].
    Previous works usually detect vehicle logos at the same scale without considering
    the multi-scale variation of vehicle logos. However, the vehicle logos captured
    by the camera are of various sizes. It is essential to design an algorithm with
    multi-scale vehicle logo detection ability. To this end, Zhang *et al*. [[25](#bib.bib25)]
    proposed a multi-scale vehicle logo detection (SVLD) based on SSD [[74](#bib.bib74)]
    to assist in the recognition of vehicles by modifying the pretraining strategy,
    adding a feature extraction layer, and controlling the ratio of positive and negative
    samples. According to the characteristics of the vehicle, a preset frame and parameter
    settings are designed to effectively reduce redundant calculations and accelerate
    the convergence of the model quickly. Compared with SSD, the detection accuracy
    of SVLD is improved, but the time complexity is slightly increased due to the
    addition of the feature extraction layer. In addition, although SSDs have competitive
    accuracy compared to other single-stage methods, they are still insufficient in
    detecting small objects.
  prefs: []
  type: TYPE_NORMAL
- en: III-B4 Feature Pyramid Network-based models (FPNs)
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Lin *et al*. proposed Feature Pyramid Networks (FPN) [[75](#bib.bib75)] in 2017,
    which mainly solves the multi-scale problem in object detection by changing the
    connectivity of the network. FPN dramatically improves the performance of small
    object detection without increasing the amount of calculation. In recent years,
    many works have adopted FPN to solve problems of logo detection, like multi-scale
    and small objects [[76](#bib.bib76), [28](#bib.bib28), [77](#bib.bib77), [16](#bib.bib16)]
    and these FPNs have achieved exciting results.
  prefs: []
  type: TYPE_NORMAL
- en: 'Aiming at the problems of multi-scale and other geometric variations of logos,
    Meng *et al*. [[76](#bib.bib76)] proposed obtaining sufficient features for logo
    (OSF-Logo) based on FPN. Specifically, they introduced the Regulated Deformable
    Convolution (RDC) module in a specific layer of FPN, which allows the sampling
    point positions of the convolution kernel at different positions to adaptively
    change according to the content, thereby adapting to the geometric changes of
    the logo. Meanwhile, they adopt an up-sampling operator in FPN to generate an
    adaptive kernel that fully aggregates rich semantic information. Therefore, OSF-Logo
    can quickly perceive a wide range of content and effectively detect multi-scale
    logos. Similarly, Jin *et al*. [[28](#bib.bib28)] designed a network called “Brand
    Net”. Brand Net uses FPN to extract multi-scale features. On this basis, it introduces
    an anchor refinement network in FPN to remove negative anchors, thus greatly reducing
    the number of anchor boxes. Therefore, it can effectively detect logos with different
    scales and significantly improve the detection performance of small logos. Detection
    Transformers (DETR) [[78](#bib.bib78)] has problems detecting small objects, so
    it cannot be directly used for multi-scale logo detection. To solve this issue,
    Velazquez *et al*. [[77](#bib.bib77)] incorporated Feature Pyramid (FP) into DETR
    architecture. They firstly split the penultimate layer of the feature pyramid
    into four patches of the same size as the smallest feature map in the pyramid.
    They then fed these patches into the DETR pipeline for prediction. This method
    effectively detects small objects. However, the backward propagation computation
    of this method increases memory consumption. Recently, Hou *et al*. [[16](#bib.bib16)]
    proposed a multi-scale feature decoupling network (MFDNet) for logo detection
    to solve the problem of distinguishing multiple logo categories. MMFDNet comprises
    two components: Balanced Feature Pyramid (BFP) and Feature Offset Module (FOM).
    The former is designed to fuse multi-scale features using the same deep feature
    map to integrate balanced semantic features. At the same time, the latter comprises
    an automatically learned anchor region proposal network for pixel-level offsets
    to search for the best features for logos. The architecture of MFDNet is shown
    in Fig. 6.'
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE II: Summary of representative deep learning-based logo detection methods.'
  prefs: []
  type: TYPE_NORMAL
- en: '| Method type | Method | Pipeline | Task | Strategy | Loss function | Year
    |'
  prefs: []
  type: TYPE_TB
- en: '| RCNNs | DeepLogo-DRCN [[14](#bib.bib14)] |'
  prefs: []
  type: TYPE_TB
- en: '&#124; RCNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Fast RCNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; SPPnet &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Regular logo detection | - | - | 2015 |'
  prefs: []
  type: TYPE_TB
- en: '| BD-FRCN [[60](#bib.bib60)] | Fast RCNN | Regular logo detection | Transfer
    learning | - | 2016 |'
  prefs: []
  type: TYPE_TB
- en: '| Improved Faster RCNN [[57](#bib.bib57)] | Faster RCNN | Small logo detection
    | Preset anchor boxes | - | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Deep Region-based &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Convolutional Networks [[61](#bib.bib61)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Faster RCNN | Regular logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Transfer learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  prefs: []
  type: TYPE_TB
- en: '| Video logo detector [[22](#bib.bib22)] | Fast RCNN | Video logo detection
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Homogeneity enhancement &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Mutual enhancement &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  prefs: []
  type: TYPE_TB
- en: '| Faster RCNN+ResNet-50 [[5](#bib.bib5)] | Faster RCNN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Category balance &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EQLv2 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Seesaw Loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| Cascade detectoRS [[6](#bib.bib6)] | Cascade RCNN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Multi-scale training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Cascade RCNN+ &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Res2Net101 [[7](#bib.bib7)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Cascade RCNN | Long tail logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Gradient balance &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data Sampling &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  prefs: []
  type: TYPE_TB
- en: '| Green Hand [[8](#bib.bib8)] | DetectoRS |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Resampling &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Weighted boxes &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  prefs: []
  type: TYPE_TB
- en: '| YOLOs | Improved YOLOv3 [[72](#bib.bib72)] | YOLOv3 | Small logo detection
    | Hard example re-training | - | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| Scene recognition CNN [[24](#bib.bib24)] | YOLOv3 | Regular logo detection
    | - | - | 2020 |'
  prefs: []
  type: TYPE_TB
- en: '| Improved YOLOv2 [[71](#bib.bib71)] | YOLOv2 | Regular logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Separable convolution &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Multi-scale features fusion &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Confidence error loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Coordinate error loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Prediction box loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Improved YOLOv2 [[79](#bib.bib79)] | YOLOv2 | Multi-scale logo detection
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Preset anchor boxes &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  prefs: []
  type: TYPE_TB
- en: '| Logo-Yolo [[17](#bib.bib17)] | YOLOv3 | Regular logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Improved losses &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Focal loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CIoU loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Scaled YOLOv4 [[80](#bib.bib80)] | YOLOv4 | Regular logo detection | - |
    - | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '| Separable-VLD [[73](#bib.bib73)] | YOLO | Small logo detection | Separable
    convolution | - |'
  prefs: []
  type: TYPE_TB
- en: '| SSDs | SVLD [[25](#bib.bib25)] | SSD | Multi-scale logo detection | Preset
    anchor boxes | - | 2019 |'
  prefs: []
  type: TYPE_TB
- en: '| SSD InceptionV2 [[58](#bib.bib58)] | SSD | Regular logo detection | Preset
    anchor boxes | - |'
  prefs: []
  type: TYPE_TB
- en: '| FPNs | Brand Net [[28](#bib.bib28)] | - | Small logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Soft mask attention &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Weight transfer &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Anchor refinement &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Class-aware smooth L1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Class-agnostic smooth L1 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Cross-entropy loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2020 |'
  prefs: []
  type: TYPE_TB
- en: '|  | OSF-Logo [[76](#bib.bib76)] | - | Multi-scale logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Deformable convolution &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Up-sampling operator &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '|  | MFDNet [[16](#bib.bib16)] | - | Multi-scale logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Multi-scale feature fusion &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Deformable learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Cross-entropy loss |'
  prefs: []
  type: TYPE_TB
- en: '|  | DETR-FP [[77](#bib.bib77)] | DETR | Small logo detection | Model fusion
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Hungarian loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Generalized IoU loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '| Others | SLST [[29](#bib.bib29)] | Faster RCNN | Weakly supervised logo detection
    |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Incremental learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Self-Training &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - | 2017 |'
  prefs: []
  type: TYPE_TB
- en: '| SCL [[21](#bib.bib21)] | Faster RCNN | Few shot logo detection | Synthetic
    context logo | - |'
  prefs: []
  type: TYPE_TB
- en: '| CAL [[15](#bib.bib15)] |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Faster RCNN &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; YOLOv2 &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Weakly supervised logo detection | Context adversarial learning |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Softmax cross-entropy loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Conditional adversarial loss &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| 2018 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Weakly supervised &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; learning of CNN [[81](#bib.bib81)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| DCNN | Weakly supervised logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Generate saliency map &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; GrabCut segmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Softmax loss | 2021 |'
  prefs: []
  type: TYPE_TB
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Airline logo &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; detection system [[82](#bib.bib82)] &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| AttentionMask | Complex scenes logo detection | Data augmentation | Cross-entropy
    loss |'
  prefs: []
  type: TYPE_TB
- en: '| LogoNet [[83](#bib.bib83)] | - | Complex scenes logo detection | Spatial
    attention | - |'
  prefs: []
  type: TYPE_TB
- en: '| Deep attention networks [[84](#bib.bib84)] | - | Regular logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Domain adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Nonlocal block &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  prefs: []
  type: TYPE_TB
- en: '| MPCC [[85](#bib.bib85)] | Faster RCNN | Few shot logo detection |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Domain adaptation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Softmax cross-entropy loss |'
  prefs: []
  type: TYPE_TB
- en: '| DTAL [[86](#bib.bib86)] | DCNN |'
  prefs: []
  type: TYPE_TB
- en: '&#124; Video logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Few shot logo detection &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Active learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Transfer learning &#124;'
  prefs: []
  type: TYPE_NORMAL
- en: '| Meta-class loss | 2022 |'
  prefs: []
  type: TYPE_TB
- en: III-B5 Other models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Some other models used in logo detection are introduced in this section.
  prefs: []
  type: TYPE_NORMAL
- en: 'In order to solve the problem of limited logo data, Su *et al*. [[15](#bib.bib15)]
    proposed a data augmentation strategy focusing on logo context optimization: Contextual
    Adversarial Learning (CAL). CAL takes an image with a logo object as input and
    generates context-consistent synthetic images that can be used as additional training
    data. However, the distribution of this synthetic image is different from the
    actual test image. To solve this issue, the same authors proposed a Multi-Perspective
    Cross-Class (MPCC) domain adaptation method [[85](#bib.bib85)] based on the baseline
    method CAL [[15](#bib.bib15)]. MPCC conducts feature distribution alignment in
    the data augmentation principle from two perspectives. One is to align the feature
    distribution between the synthetic logo image of 1-shot icon supervised classes
    and the authentic logo image of the fully supervised class. The other is to align
    the feature distribution between the logo and non-logo images. This mitigates
    the domain shift problem between model training and testing on 1-shot icon supervised
    logo classes and reduces the model’s overfitting to the fully labeled logo classes.
    The final combination of MPCC with Faster R-CNN achieved good results.'
  prefs: []
  type: TYPE_NORMAL
- en: Training a logo detector usually requires a large amount of labeled data, and
    labeling logo data is time-consuming. Therefore, weakly supervised learning is
    a vital strategy to solve this issue. Kumar *et al*. [[81](#bib.bib81)] proposed
    a method for logo detection by using weakly supervised learning of CNN to generate
    a deep saliency map, which is generated by a single back-propagation of a trained
    Deep CNN. The authors also used an interactive Grabcut algorithm to calculate
    the salient segmented regions of the image. However, this method is not sufficiently
    modeled to detect multiple brand logos in the same image.
  prefs: []
  type: TYPE_NORMAL
- en: Logo detectors usually perform poorly in classes with a small number of samples.
    To this end, Yohannes *et al*. [[84](#bib.bib84)] designed a framework consisting
    of a domain adaptation that reduces the loss function between source-target datasets
    and also represents important source features adopted by the target dataset. The
    authors add nonlocal blocks and attention mechanisms to achieve a decent performance
    of logo detection. Similarly, Su *et al*. [[86](#bib.bib86)] developed a deep
    transfer active learning algorithm named DTAL to select the most valuable samples
    such that we can label the smallest number of samples to achieve maximum performance
    improvements in training detection models.
  prefs: []
  type: TYPE_NORMAL
- en: When the image is affected by unfavorable factors such as illumination, rotation,
    occlusion, etc., the performance of the detector will be significantly reduced.
    In recent years, the attention mechanisms have attracted increasing attention
    to solving this issue in logo detection [[82](#bib.bib82), [83](#bib.bib83)].
    For example, Wilms *et al*. [[82](#bib.bib82)] took the airline logos as an example
    and proposed a logo detection system under adverse conditions. The authors adopt
    the object proposal generation system AttentionMask [[87](#bib.bib87)]. Since
    the aviation system logo is relatively large, the AttentionMask system removes
    the scale of small objects to improve execution efficiency and reduce false positives.
    They also used a data augmentation solution to simulate the effects of severe
    weather to diversify the training data processing effects. The experimental results
    show that the proposed strategy can achieve good performance in detecting the
    logo in complex real-world environments. However, the data obtained under real-world
    conditions are not as ideal as the data generated by data augmentation, so the
    performance of the model in detecting images in real-world conditions will be
    degraded. Considering that locating logos in complex scenarios is challenging
    due to the large variety of types and appearance of logos, Jain *et al*. [[83](#bib.bib83)]
    proposed a logo detection framework called LogoNet, which includes a spatial attention
    module. LogoNet can capture rich spatial information and focus more precisely
    on the logo object within an image. LogoNet achieves a significant performance
    gain within considerable computation time.
  prefs: []
  type: TYPE_NORMAL
- en: In order to analyze current state-of-the-art deep learning-based methods more
    comprehensively, the representative models are presented in chronological order
    in Table II, and the experimental results of these models on three popular benchmark
    datasets, namely Flickrlogos-32, QMUL-OpenLogo, and Open Brands, are listed in
    Table III, Table IV, and Table V respectively.
  prefs: []
  type: TYPE_NORMAL
- en: IV Applications
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Logo detection is widely used in various applications, such as intellectual
    property protection, autonomous driving, and product branding. In this section,
    we describe the representative applications of logo detection in detail.
  prefs: []
  type: TYPE_NORMAL
- en: IV-A Brand Monitoring
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The most obvious use case for logo detection is brand monitoring, which includes
    brand protection, brand recommendation, and brand identification. Logo plays an
    essential role in business marketing as a unique brand identity. However, there
    are many types of brands in real life, and there may be subtle logo differences
    between the two products. Inter-class similarities and intra-class differences
    will greatly increase the difficulty of detection. In addition, images may have
    highly diverse context, illumination, projection transformation, and resolution.
    Therefore, how efficiently detecting brands in images is a challenging task. Currently,
    there is a lot of work on brand identity [[60](#bib.bib60), [58](#bib.bib58),
    [28](#bib.bib28), [3](#bib.bib3)]. For brand logos, the image usually includes
    some textual description. Textual information is an important source of information
    for brand identity. Hu *et al*. [[3](#bib.bib3)] proposed a multimodal fusion
    framework for logo detection. The framework combines image-based logo recognition
    with contextual features for logo detection using a natural language model. Additional
    contextual information can alleviate the limitations of detection. The performance
    of this model for logo detection has been improved, but there are still shortcomings
    in positioning.
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE III: Performance comparison of logo detectors on the FlickrLogos-32 benchmark.'
  prefs: []
  type: TYPE_NORMAL
- en: Method mAP(%) Year FRCN  [[46](#bib.bib46)] 74.4 2015 BD-FRCN-M [[60](#bib.bib60)]
    73.5 2016 Video Logo Detector [[22](#bib.bib22)] 78.6 2017 Faster RCNN+VGG16_D2_M3 [[61](#bib.bib61)]
    90.3 2017 Faster RCNN+CAL [[15](#bib.bib15)] 74.9 2018 Deep Saliency Map [[81](#bib.bib81)]
    75.8 2020 Logo-Yolo [[17](#bib.bib17)] 76.1 2020 LogoNet [[83](#bib.bib83)] 82.2
    2021 OSF-Logo [[76](#bib.bib76)] 87.0 2021 RetinaNet [[59](#bib.bib59)] 40.0 2021
    RCNN [[59](#bib.bib59)] 65.0 2021 Faster RCNN [[59](#bib.bib59)] 74.0 2021 Scaled
    YOLOv4 [[80](#bib.bib80)] 80.4 2021 MFDNet [[16](#bib.bib16)] 86.2 2021
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE IV: Performance comparison of logo detectors on the QMUL-OpenLogo benchmark.'
  prefs: []
  type: TYPE_NORMAL
- en: Method      mAP(%)      Year      YOLOv2+CAL [[15](#bib.bib15)]      49.2      2018
         Faster RCNN+CAL [[15](#bib.bib15)]      51.0      2018      Logo-Yolo [[17](#bib.bib17)]
         53.2      2020      Faster RCNN+CAL+MPCC [[85](#bib.bib85)]      49.4      2021
         OSF-Logo [[76](#bib.bib76)]      53.3      2021      Scaled YOLOv4 [[80](#bib.bib80)]
         61.9      2021      MFDNet [[16](#bib.bib16)]      51.3      2021
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE V: Performance comparison of logo detectors on the Open Brands benchmark.'
  prefs: []
  type: TYPE_NORMAL
- en: Method      mAP(%)      Year      Brand Net (SMA) [[28](#bib.bib28)]      60.4
         2020      Faster RCNN+RFS+MST [[5](#bib.bib5)]      64.6      2021      Cascade
    RCNN+Soft NMS [[6](#bib.bib6)]      65.1      2021      Green Hand [[8](#bib.bib8)]
         65.5      2021      Cascade RCNN+DCN v2 [[7](#bib.bib7)]      70.2      2021
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Intelligent Transportation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In intelligent transportation, vehicle logo detection is significantly growing
    as it can effectively assist vehicle management. In addition, due to the increasing
    number of vehicle violations and traffic accidents, the realization of intelligent
    transportation systems is crucial. However, in the real world, the detection of
    vehicle logos is seriously disturbed due to occlusion, illumination, and low image
    resolution. Therefore, an efficient vehicle logo detection system is essential.
    In recent years, methods for vehicle logo detection have been proposed successively [[39](#bib.bib39),
    [34](#bib.bib34), [88](#bib.bib88), [37](#bib.bib37), [38](#bib.bib38), [23](#bib.bib23),
    [72](#bib.bib72), [79](#bib.bib79)]. Lu *et al*. [[48](#bib.bib48)] designed a
    feature extraction module VLF-Net and category-consistent mask learning module
    for vehicle logo detection. Yu *et al*. [[1](#bib.bib1)] proposed a cascaded deep
    convolutional neural network to detect vehicles without relying on the presence
    of license plates. The network is a two-stage framework including two components:
    a region proposal network and a convolutional capsule network. The former is responsible
    for generating region proposals that may contain vehicle logos, while the latter
    is responsible for classifying the proposals into background and vehicle logos.
    Surwase *et al*. [[2](#bib.bib2)] proposed a multi-scale multi-stream deep network
    for vehicle logo detection. The network processes the input image through a multi-scale
    stream to extract robust features, followed by logo recognition. The network follows
    a knowledge sharing strategy, where the learned features are shared on each stream
    of the network.'
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4f38e36ae6c61d60d851fd2a77eae30b.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The architecture for video logo detection [[22](#bib.bib22)].'
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Copyright and Trademark Compliance
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the development of global e-commerce platforms, the logos of major brands
    have become an important element in the e-commerce market. Some attackers use
    illegal means to infringe on the original author, so protecting intellectual property
    rights has also become a focus. Logo detection plays a vital role in preventing
    the increasing number of counterfeit transaction attempts online [[33](#bib.bib33),
    [89](#bib.bib89), [90](#bib.bib90), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. Infringement detection of logos has been studied for images and
    videos. Chen *et al*. [[5](#bib.bib5)] built a highly optimized and robust detector
    by using techniques such as data augmentation for the detection of logos (515
    categories) in e-commerce images. Patalappa *et al*. [[4](#bib.bib4)] extended
    the dataset through data augmentation techniques. They applied the SSD algorithm
    to detect broadcast logos in the context of broadcast and broadband content piracy
    and proved the effectiveness of the application of SSD in content piracy video
    analysis monitoring tasks. An efficient way to identify the source of a web video
    is to detect some specified logos. In order to identify the source of illegal
    videos, Ye *et al*. [[91](#bib.bib91)] proposed a logo detection system “GeLoGo”
    to detect logos in Web-scale videos. The system consists of four main modules:
    the keyframe module, the proposal module, the spatial verification module, and
    the temporal verification module. The keyframe module first extracts several frames
    with short fragment detection, which can significantly reduce the data. Secondly,
    the proposal module extracts candidate boxes through a set of pre-trained identity
    detectors. Then, the spatial validation module detects logos through the ResNet
    network. Finally, the temporal verification module detects the detection result
    by detecting the recognition position.'
  prefs: []
  type: TYPE_NORMAL
- en: IV-D Document Categorization
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A logo often appears in commercial documents and can be used as a statement
    of ownership of the document. Automatic logo detection is growing due to the increasing
    requirements of intelligent document image analysis and retrieval [[92](#bib.bib92),
    [93](#bib.bib93), [94](#bib.bib94)]. Alaei *et al*. [[95](#bib.bib95)] proposed
    a complete system for logo detection in document images. They proposed a template-based
    recognition strategy for under or over-segmentation problems that may arise during
    detection. In order to speed up the matching of templates in the recognition phase,
    a search space reduction strategy that utilizes the geometric properties of logo-patches
    and template logo-models is proposed to reduce the number of template logo-models.
    Zhu *et al*. [[96](#bib.bib96)] proposed a multi-scale method for document image
    logo detection and extraction. The authors used an augmentation strategy across
    multiple image scales to classify and localize logos accurately.
  prefs: []
  type: TYPE_NORMAL
- en: IV-E Other Applications
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logo detection can offer various benefits for advertisers looking to improve
    their marketing strategies effectively. As shown in Fig. 7, Liao *et al*. [[22](#bib.bib22)]
    proposed a video logo detection framework that used a mutual-enhanced approach
    to improve logo detection through the information obtained from other simultaneously
    occurred logos. Based on the Fast R-CNN model, a uniformity-enhanced reordering
    method is proposed to improve the accuracy of in-frame region suggestions by analyzing
    the features of logos in videos. In addition, they proposed a frame propagation
    enhancement method to assist in the detection of adjacent frames. Finally, the
    effectiveness of the method is demonstrated on the FlickrLogos-32 dataset and
    the video dataset. Recently, food logo detection [[16](#bib.bib16)] has become
    more popular because it has many valuable applications, such as food brand management
    and displaying nutritional information. Logo detection is also used in other areas,
    such as video semantic annotation [[97](#bib.bib97), [40](#bib.bib40), [80](#bib.bib80)],
    and noise recognition [[45](#bib.bib45), [36](#bib.bib36), [98](#bib.bib98), [99](#bib.bib99)].
    Since the TV logo photographed is susceptible to illumination, occlusion, noise,
    and other factors, the TV logo may only take up a small part of each image. To
    this end, Pan *et al*. [[100](#bib.bib100)] proposed an efficient CNN to solve
    this problem. They used the maximum stable extremal region (MSER) algorithm to
    extract candidate frames. Since this algorithm tends to produce a large number
    of candidate frames without TV logos, they designed certain geometric constraints
    to remove non-logo objects. Finally, the images were fed into the CNN network
    for classification and achieved good results.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/46a7d15b1f5e9e7ea3eb42610d0cfa08.png)'
  prefs: []
  type: TYPE_IMG
- en: (a) Small size.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a3339fcfed4849c25b327619b8187dc0.png)'
  prefs: []
  type: TYPE_IMG
- en: (b) Highly diverse backgrounds.
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1653ce0f8391e3fb08255368bc171415.png)'
  prefs: []
  type: TYPE_IMG
- en: (c) Sub-branding.
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: Distinctive properties of logos.'
  prefs: []
  type: TYPE_NORMAL
- en: V Challenges and Future Directions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: V-A Challenges
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Logo detection has received more attention in the last few years for its wide
    applications. However, robust and accurate logo detection is still challenging
    in real-world scenarios because the logo images have distinctive properties, which
    may form significant obstacles to current progress. We try to summarize them as
    following: (1) *Small size:* Unlike generic objects, logos tend to be small in
    size, making it difficult to distinguish them from contexts, especially the complex
    background. Although contextual information is crucial in small object detection
    because small objects carry limited information [[101](#bib.bib101)], it is not
    always beneficial for logo detection, especially when it is too complex and unrelated
    to the target logo, as shown in Fig. 8(a). We know that in the deep learning-based
    detection architecture, different layers of feature maps with various spatial
    resolutions are produced due to pooling and subsampling processes. Early-layer
    feature maps represent small reception fields but lack high-level semantic information
    critical for logo detection. In contrast, high-level feature maps help identify
    large logos but may not detect smaller ones. (2) *Highly diverse backgrounds:*
    A logo is usually associated with other visible entities, like a particular service
    or product. Thus, a logo may appear in various situations superimposed on objects
    such as geometrical renderings, shirts of persons, jerseys of players, boards
    of shops, billboards, or posters on sports playfields. As shown in Fig. 8 (b),
    a brand like “Nike” may serve many types of products, such as jackets, shoes,
    or trousers, resulting in the same logo being attached to a variety of different
    objects, which poses challenges to designing a robust logo detector when considering
    image statistics from the entire image. (3) *Sub-branding:* Sub-branding is often
    considered when a company releases a new product. Sub-brand detection facilitates
    brand monitoring but suffers from the same problems as fine-grained classification,
    such as subtle differences between sub-brands and parent brands and between sub-brands.
    In real logo detection, some sub-brands are treated as logos different from the
    parent brand or other sub-brands because they have customer expectations and personalities
    that are different from the parent brand. Thus, the parent brand and its sub-brands
    usually have remarkably similar context information (background, packaging, etc.,
    as shown in Fig. 8(c)). When considering image-level feature maps, in this case,
    there are probably several remarkably similar feature maps extracted from different
    logo images, which challenges identifying different sub-brand logos accurately
    when using the deep learning-based detector.'
  prefs: []
  type: TYPE_NORMAL
- en: Many approaches to tackle logo detection tasks have been developed based on
    object detection methods and have achieved promising results, but there is still
    much room for improvement. For example, [[72](#bib.bib72)] proposed a vehicle
    logo detection system based on YOLOv3\. Though the performance of small logo detection
    has been improved to a certain extent, it fails to accurately detect small logos
    with complex letter patterns. [[57](#bib.bib57)] designed an improved anchor-based
    scheme for small logos by utilizing higher resolution feature maps. However, it
    is too computationally expensive for constrained scenarios and too slow for real-time
    applications due to adopting a two-phase detection strategy. It is worth mentioning
    that the best detection performance only reaches 61.9% of mAP on QMUL-OpenLogo [[80](#bib.bib80)],
    in which the logo detector is designed based on YOLOv4\. Therefore, simply borrowing
    the existing detectors from general object detection is considered insufficient
    for logo detection. Designing a new detection paradigm that is suitable for logos
    is essential.
  prefs: []
  type: TYPE_NORMAL
- en: V-B Future Directions
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some future research directions in logo detection are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Lightweight logo detection: Lightweight networks are designed to reduce model
    complexity further while maintaining model accuracy. With the rapid development
    of mobile terminals such as mobile phones and computers, people pay more attention
    to lightweight detectors. Lightweight logo detection can help consumers quickly
    identify and accurately search for the products they need and thus can significantly
    improve the efficiency of online shopping. Although significant efforts have been
    made recently, the speed gap between the machine and the human eye is still huge.
    The detection accuracy is also insufficient, especially for small logos. Therefore,
    improving the accuracy of lightweight logo detectors is one of the future development
    trends.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Weakly supervised logo detection: A fully supervised logo detector must be
    trained on fully labeled large-scale logo datasets. However, the labeling of existing
    datasets is mainly done manually, which poses a challenge to the generalization
    and robustness of existing models due to the problem of data quality. With the
    rapid growth of logo data volume, data annotation costs are getting higher and
    higher. Developing weakly supervised logo detection techniques that only use image-level
    annotations or partial bounding box annotations to train logo detectors significantly
    reduces costs and improves detection flexibility. Therefore, developing weakly
    supervised logo detection methods without fully labeled training data is an important
    issue for future research.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Video logo detection: Logo promotion exists in most video advertisements. Accurate
    and reasonable advertising is targets businesses, so it is essential to identify
    the target logo effectively. Current logo detectors are commonly used to detect
    logos of individual images, which may lead to a lack of correlation between consecutive
    images. In addition, there are problems such as motion blur and target occlusion
    in logo detection of videos, which can highly affect the performance of the detector.
    There are already methods trying to detect video logos. Currently, there are methods [[86](#bib.bib86),
    [22](#bib.bib22)] trying to detect video logos, but they have not achieved satisfactory
    results. Therefore, it is an important research direction to improve logo detection
    by utilizing temporal and spatial correlations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Tiny logo detection: Tiny logos contain insufficient information, making it
    more challenging to extract discriminative features. Meanwhile, tiny logos contain
    relatively few samples and thus are easily disturbed by environmental factors.
    Numerous real-world tiny logos may have highly diverse contexts, which can cause
    the same logo to appear very different in different real scenarios. Observing
    the results of existing detection methods on tiny logos, we can find that the
    performance of this methods [[77](#bib.bib77), [72](#bib.bib72), [73](#bib.bib73)]
    is unsatisfactory in real scenarios.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Long tail logo detection: With the rapid development of society, some enterprises
    are currently leading the way, and their enterprise logos naturally often appear
    in front of the public. In contrast, the logos of most small enterprises are not
    paid much attention to because they appear less. The long-tail distribution of
    logos exists all the time in reality. Some logo classes contain a large number
    of samples, while others contain few samples, making it difficult for logo detectors
    to detect logo classes with few samples. In previous logo detection methods, there
    is little focus on the long-tailed distribution in logo images. Therefore, it
    is one of the future tasks to utilize the unbalanced data to train efficient and
    accurate detectors.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Incremental logo detection: As a company’s signature or symbol, the logo will
    continue to increase as the number of companies increases. Therefore, the logo
    detector must learn new logos. However, retraining the logo detector is time-consuming
    and resource-intensive by discarding the previously learned knowledge. Incremental
    learning enables a system to continuously learn new knowledge from new samples
    while retaining most previously learned knowledge without catastrophic forgetting.
    It can reduce the complexity of the model to a certain extent, thereby reducing
    the training cost of the model. However, no incremental learning method currently
    can show good performance under all conditions. Therefore, incremental learning
    for logo detection is one of the future research directions.'
  prefs: []
  type: TYPE_NORMAL
- en: In fact, existing studies generally assume close-environment scenarios. For
    example, the data distribution of logo datasets is invariable, and all the training
    data have known classes and fine-grained bounding box annotations in advance.
    Although Su *et al*. [[15](#bib.bib15)] proposed an assumption to simulate the
    open deployment, they mainly focus on the problem of limited logo data by presenting
    a context adversarial learning approach to generate context-consistent synthetic
    training data automatically. How to enable the trained model to be updated according
    to emerging new logo classes or data distribution change, or even we hardly know
    what changes is an essential requirement in open-environment.
  prefs: []
  type: TYPE_NORMAL
- en: VI Conclusion
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this work, we offer a comprehensive survey of previous and current approaches
    that helps logo detection. We mainly review the recent advances in deep learning-based
    logo detection by summarizing classical solutions. In addition, we comprehensively
    review the commonly used datasets, summarize the related applications of logo
    detection, and predict future research directions. Although the achievement of
    logo detection has been effective recently, there is still much room for further
    development. We hope this paper will better inform readers about the current development
    of logo detection and inspire more people to get involved in logo detection.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Y. Yu, H. Guan, D. Li, and C. Yu, “A cascaded deep convolutional network
    for vehicle logo recognition from frontal and rear images of vehicles,” *IEEE
    Transactions on Intelligent Transportation Systems*, vol. 22, no. 2, pp. 758–771,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] S. Surwase and M. Pawar, “Multi-scale multi-stream deep network for car
    logo recognition,” *Evolutionary Intelligence*, pp. 1–8, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] C. Hu, Q. Li, Z. Zhang, K. Chang, and R. Zhang, “A multimodal fusion framework
    for brand recognition from product image and context,” in *IEEE International
    Conference on Multimedia & Expo Workshops*, 2020, pp. 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] K. K. J. Patalappa and S. M. Chandramouli, “Robust recognition of logo
    under makeover in the context of content piracy,” *Global Transitions Proceedings*,
    vol. 2, no. 2, pp. 421–428, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] H. Chen, X. Li, Z. Wang, and X. Hu, “Robust logo detection in e-commerce
    images by data augmentation,” in *Proceedings of the 29th ACM International Conference
    on Multimedia*, 2021, pp. 4789–4793.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] X. Jia, H. Yan, Y. Wu, X. Wei, X. Cao, and Y. Zhang, “An effective and
    robust detector for logo detection,” *arXiv preprint arXiv:2108.00422*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] F. Leng, “A gradient balancing approach for robust logo detection,” in
    *Proceedings of the 29th ACM International Conference on Multimedia*, 2021, pp.
    4765–4769.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] W. Xu, Y. Liu, and D. Lin, “A simple and effective baseline for robust
    logo detection,” in *Proceedings of the 29th ACM International Conference on Multimedia*,
    2021, pp. 4784–4788.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] K. Tong, K. W. Cheung, and X. Yu, “ICME 2022 few-shot logo detection top
    9 solution,” *arXiv preprint arXiv:2206.11462*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] H. Sahbi, L. Ballan, G. Serra, and A. Bimbo, “Context-dependent logo matching
    and recognition,” *IEEE Transactions on Image Processing*, vol. 22, no. 3, pp.
    1018–1031, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” *Communications of the ACM*, vol. 60,
    no. 6, pp. 84 – 90, 2012.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] A. Joly and O. Buisson, “Logo retrieval with a contrario visual query
    expansion,” in *Proceedings of the 17th ACM International Conference on Multimedia*,
    2009, pp. 581–584.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] S. Romberg, L. G. Pueyo, R. Lienhart, and V. Z. Roelof, “Scalable logo
    recognition in real-world images,” in *Proceedings of the 1st ACM International
    Conference on Multimedia Retrieval*, 2011, pp. 1–8.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] S. C. H. Hoi, X. Wu, H. Liu, Y. Wu, H. Wang, H. Xue, and Q. Wu, “Logo-Net:
    Large-scale deep logo detection and brand recognition with deep region-based convolutional
    networks,” *arXiv preprint arXiv:1511.02462*, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] H. Su, X. Zhu, and S. Gong, “Open logo detection challenge,” in *British
    Machine Vision Conference*, 2018, pp. 111–119.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Q. Hou, W. Min, J. Wang, S. Hou, Y. Zheng, and S. Jiang, “FoodLogoDet-1500:
    A dataset for large-scale food logo detection via multi-scale feature decoupling
    network,” in *Proceedings of the 29th ACM International Conference on Multimedia*,
    2021, pp. 4670–4679.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] J. Wang, W. Min, S. Hou, S. Ma, Y. Zheng, and S. Jiang, “LogoDet-3K: A
    large-scale image dataset for logo detection,” *ACM Transactions on Multimedia
    Computing, Communications, and Applications*, vol. 18, no. 1, pp. 1–19, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] C. Li, I. Fehérvári, X. Zhao, I. Macêdo, and S. Appalaraju, “SeeTek: Very
    large-scale open-set logo recognition with text-aware metric learning,” in *IEEE/CVF
    Winter Conference on Applications of Computer Vision*, 2022, pp. 587–596.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Y. Kalantidis, L. G. Pueyo, M. Trevisiol, V. Z. Roelof, and Y. Avrithis,
    “Scalable triangulation-based logo recognition,” in *Proceedings of the 1st ACM
    International Conference on Multimedia Retrieval*, 2011, pp. 1–7.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Bianco, M. Buzzelli, D. Mazzini, and R. Schettini, “Deep learning for
    logo recognition,” *Neurocomputing*, vol. 245, pp. 23–30, 2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] H. Su, X. Zhu, and S. Gong, “Deep learning logo detection with data expansion
    by synthesising context,” in *IEEE Winter Conference on Applications of Computer
    Vision*, 2017, pp. 530–539.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Y. Liao, X. Lu, C. Zhang, Y. Wang, and Z. Tang, “Mutual enhancement for
    detection of multiple logos in sports videos,” in *IEEE International Conference
    on Computer Vision*, 2017, pp. 4856–4865.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] J. Liu, F. Shen, M. Wei, Y. Zhang, H. Zeng, J. Zhu, and C. Cai, “A large-scale
    benchmark for vehicle logo recognition,” in *4th International Conference on Image,
    Vision and Computing*, 2019, pp. 479–483.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] A. Kuznetsov and A. V. Savchenko, “A new sport teams logo dataset for
    detection tasks,” in *International Conference on Computer Vision and Graphics*,
    2020, pp. 87–97.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J. Zhang, L. Chen, C. Bo, and S. Yang, “Multi-scale vehicle logo detector,”
    *Mobile Networks and Applications*, vol. 26, no. 1, pp. 67–76, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] A. Tüzkö, C. Herrmann, D. Manger, and J. Beyerer, “Open set logo detection
    and retrieval,” in *International Conference on Computer Vision Theory and Applications*,
    2018, pp. 284–292.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] I. Fehérvári and S. Appalaraju, “Scalable logo recognition using proxies,”
    in *IEEE Winter Conference on Applications of Computer Vision*, 2019, pp. 715–725.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] X. Jin, W. Su, R. Zhang, Y. He, and H. Xue, “The open brands dataset:
    Unified brand detection and recognition at scale,” in *IEEE International Conference
    on Acoustics, Speech and Signal Processing*, 2020, pp. 4387–4391.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] H. Su, S. Gong, and X. Zhu, “Weblogo-2M: Scalable logo detection by deep
    learning from the web,” in *Proceedings of the IEEE International Conference on
    Computer Vision Workshops*, 2017, pp. 270–279.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] J. Wang, W. Min, S. Hou, S. Ma, Y. Zheng, H. Wang, and S. Jiang, “Logo-2K+:
    A large-scale logo dataset for scalable logo classification,” in *Proceedings
    of the AAAI Conference on Artificial Intelligence*, 2020, pp. 6194–6201.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] M. Everingham, L. V. Gool, C. K. I. Williams, J. M. Winn, and A. Zisserman,
    “The pascal visual object classes (VOC) challenge,” *International Journal of
    Computer Vision*, vol. 88, no. 2, pp. 303–338, 2009.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] C. Cortes and V. N. Vapnik, “Support-vector networks,” *Machine Learning*,
    vol. 20, pp. 273–297, 1995.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] B. Lei, V. L. Thing, Y. Chen, and W. Y. Lim, “Logo classification with
    edge-based daisy descriptor,” in *IEEE International Symposium on Multimedia*,
    2012, pp. 222–228.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] B. Zhang and H. Pan, “Reliable classification of vehicle logos by an improved
    local-mean based classifier,” in *6th International Congress on Image and Signal
    Processing*, 2013, pp. 176–180.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] P. Carvalho, A. Pereira, and P. Viana, “Automatic TV logo identification
    for advertisement detection without prior data,” *Applied Sciences*, vol. 11,
    no. 16, pp. 74–94, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] M. A. M. Sathiaseelan, O. P. Paradis, R. Rai, S. V. Pandurangi, M. Y.
    Vutukuru, S. Taheri, and N. Asadizanjani, “Logo classification and data augmentation
    techniques for PCB assurance and counterfeit detection,” in *Conference Proceedings
    from the 47th International Symposium for Testing and Failure Analysis*, 2021,
    pp. 12–19.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Z. Xiang, Y. Zou, X. Zhou, and X. Huang, “Robust vehicle logo recognition
    based on locally collaborative representation with principal components,” in *Sixth
    International Conference on Information Science and Technology*, 2016, pp. 487–491.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] S. Gopinathan and G. Lalitha, “Vehicle logo recognition using enhanced
    learning : VLR recognition,” in *2nd International Conference on I-SMAC*, 2018,
    pp. 707–712.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] C. Pan, Z. Yan, X. Xu, M. Sun, J. Shao, and D. Wu, “Vehicle logo recognition
    based on deep learning architecture in video surveillance for intelligent traffic
    system,” in *IET International Conference on Smart and Sustainable City*, 2013,
    pp. 123–126.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] F. Zhang, L. Cao, and D. M. Zhang, “TV logo dataset and annotations for
    the convolution neural network,” in *10th International Congress on Image and
    Signal Processing, BioMedical Engineering and Informatics*, 2017, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S. Hou, J. Lin, S. Zhou, M. Qin, W. Jia, and Y. Zheng, “Deep hierarchical
    representation from classifying logo-405,” *Complexity*, vol. 29, no. 6, pp. 1–12,
    2017.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] A. J. Gallego, A. Pertusa, and M. Bernabeu, “Multi-label logo classification
    using convolutional neural networks,” in *Pattern Recognition and Image Analysis*,
    2019, pp. 485–497.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] M. Karimi and A. Behrad, “Logo recognition by combining deep convolutional
    models in a parallel structure,” in *4th International Conference on Pattern Recognition
    and Image Analysis*, 2019, pp. 216–221.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] M. Bernabeu, A. J. Gallego, and A. Pertusa, “Multi-label logo recognition
    and retrieval based on weighted fusion of neural features,” *arXiv preprint arXiv:2205.05419*,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Hendrick, C. M. Wang, Aripriharta, C. G. Jhe, P. C. Tsu, and G. J. Jong,
    “The halal logo classification by using nvidia digits,” in *International Conference
    on Applied Information Technology and Innovation*, 2018, pp. 162–165.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] F. N. Iandola, A. Shen, P. Gao, and K. Keutzer, “Deeplogo: Hitting logo
    recognition with the deep neural network hammer,” *arXiv preprint arXiv:1510.02131*,
    2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] W. Yousaf, A. Umar, S. H. Shirazi, Z. Khan, and M. Zaka, “Patch-CNN: Deep
    learning for logo detection and brand recognition,” *Journal of Intelligent and
    Fuzzy Systems*, vol. 40, no. 2, pp. 1–14, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] W. Lu, H. Zhao, Q. He, H. Huang, and X. Jin, “Category-consistent deep
    network learning for accurate vehicle logo recognition,” *Neurocomputing*, vol.
    463, pp. 623–636, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] R. Boia, C. Florea, and L. Florea, “Elliptical ASIFT agglomeration in
    class prototype for logo detection,” in *Proceedings of the British Machine Vision
    Conference*, 2015, pp. 115.1–115.12.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] C. Wan, Z. Zhao, X. Guo, and A. Cai, “Tree-based shape descriptor for
    scalable logo detection,” in *Visual Communications and Image Processing*, 2013,
    pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] C. Constantinopoulos, E. Meinhardt, Y. Liu, and V. Caselles, “A robust
    pipeline for logo detection,” in *IEEE International Conference on Multimedia
    and Expo*, 2011, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Revaud, M. Douze, and C. Schmid, “Correlation-based burstiness for
    logo retrieval,” in *Proceedings of the 20th ACM International Conference on Multimedia*,
    2012, p. 965–968.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] R. B. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies
    for accurate object detection and semantic segmentation,” in *IEEE Conference
    on Computer Vision and Pattern Recognition*, 2014, pp. 580–587.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] J. R. R. Uijlings, K. E. A. van de Sande, T. Gevers, and A. W. M. Smeulders,
    “Selective search for object recognition,” *International Journal of Computer
    Vision*, vol. 104, pp. 154–171, 2013.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] R. B. Girshick, “Fast R-CNN,” in *IEEE International Conference on Computer
    Vision*, 2015, pp. 1440–1448.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] S. Ren, K. He, R. B. Girshick, and J. Sun, “Faster R-CNN: Towards real-time
    object detection with region proposal networks,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, vol. 39, no. 6, pp. 1137–1149, 2015.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] C. Eggert, D. Zecha, S. Brehm, and R. Lienhart, “Improving small object
    proposals for company logo detection,” in *Proceedings of the 2017 ACM on International
    Conference on Multimedia Retrieval*, 2017, p. 167–174.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] O. Orti, R. Tous, M. Gomez, J. Poveda, L. Cruz, and O. Wüst, “Real-time
    logo detection in brand-related social media images,” in *Advances in Computational
    Intelligence*, 2019, pp. 125–136.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] S. Sahel, M. Alsahafi, M. Alghamdi, and T. Alsubait, “Logo detection using
    deep learning with pretrained CNN models,” *Engineering, Technology & Applied
    Science Research*, vol. 11, no. 1, pp. 6724–6729, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] G. Oliveira, X. Frazão, A. Pimentel, and B. Ribeiro, “Automatic graphic
    logo detection via fast region-based convolutional networks,” in *International
    Joint Conference on Neural Networks*, 2016, pp. 985–991.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Y. Li, Q. Shi, J. Deng, and F. Su, “Graphic logo detection with deep region-based
    convolutional networks,” in *IEEE Visual Communications and Image Processing*,
    2017, pp. 1–4.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Redmon, S. K. Divvala, R. B. Girshick, and A. Farhadi, “You only look
    once: Unified, real-time object detection,” in *IEEE Conference on Computer Vision
    and Pattern Recognition*, 2016, pp. 779–788.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] J. Redmon and A. Farhadi, “YOLO9000: Better, faster, stronger,” in *IEEE
    Conference on Computer Vision and Pattern Recognition*, 2017, pp. 6517–6525.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] J. Redmon and A. Farhadi, “YOLOv3: An incremental improvement,” *arXiv
    preprint arXiv:1804.02767*, 2018.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] A. Bochkovskiy, C. Y. Wang, and H. Liao, “YOLOv4: Optimal speed and accuracy
    of object detection,” *arXiv preprint arXiv:2004.10934*, 2020.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Q. Chen, Y. Wang, T. Yang, X. Zhang, J. Cheng, and J. Sun, “You only look
    one-level feature,” in *IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2021, pp. 13 034–13 043.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] C. Y. Wang, I. H. Yeh, and H. Liao, “You only learn one representation:
    Unified network for multiple tasks,” *arXiv preprint arXiv:2105.04206*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, “YOLOX: Exceeding yolo series
    in 2021,” *arXiv preprint arXiv:2107.08430*, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] C. Li, L. Li, H. Jiang, K. Weng, Y. Geng, L. Li, Z. Ke, Q. Li, M. Cheng,
    W. Nie, Y. Li, B. Zhang, Y. Liang, L. Zhou, X. Xu, X. Chu, X. Wei, and X. Wei,
    “Yolov6: A single-stage object detection framework for industrial applications,”
    *arXiv preprint arXiv:2209.02976*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] C. Y. Wang, A. Bochkovskiy, and H. Liao, “Yolov7: Trainable bag-of-freebies
    sets new state-of-the-art for real-time object detectors,” *arXiv preprint arXiv:2207.02696*,
    2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] K. Yin, S. Hou, Y. Li, C. Li, and G. Yin, “A real-time vehicle logo detection
    method based on improved YOLOv2,” in *International Conference on Wireless Algorithms,
    Systems, and Applications*, 2020, pp. 666–677.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] S. Yang, J. Zhang, C. Bo, M. Wang, and L. Chen, “Fast vehicle logo detection
    in complex scenes,” *Optics & Laser Technology*, vol. 110, pp. 196–201, 2019.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] J. Zhang, S. Yang, C. Bo, and Z. Zhang, “Vehicle logo detection based
    on deep convolutional networks,” *Computers & Electrical Engineering*, vol. 90,
    p. 107004, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. E. Reed, C. Y. Fu, and A. C.
    Berg, “SSD: Single shot multibox detector,” in *European Conference on Computer
    Vision*, 2016, pp. 21–37.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] T. Y. Lin, P. Dollár, R. B. Girshick, K. He, B. Hariharan, and S. J. Belongie,
    “Feature pyramid networks for object detection,” in *IEEE Conference on Computer
    Vision and Pattern Recognition*, 2017, pp. 936–944.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Y. Meng, S. Hou, J. Wang, W. Jia, Y. Zheng, and A. Karim, “An adaptive
    representation algorithm for multi-scale logo detection,” *Displays*, vol. 70,
    p. 102090, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] D. A. Velazquez, J. M. Gonfaus, P. Rodríguez, F. X. Roca, S. Ozawa, and
    J. Gonzàlez, “Logo detection with no priors,” *IEEE Access*, vol. 9, pp. 106 998–107 011,
    2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko,
    “End-to-end object detection with transformers,” in *European Conference on Computer
    Vision*, 2020, pp. 213–229.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] S. Yang, C. Bo, J. Zhang, and M. Wang, “Vehicle logo detection based on
    modified YOLOv2,” in *2nd EAI International Conference on Robotic Sensor Networks*,
    2020, pp. 75–86.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] K. Paleček and J. Chaloupka, “Logo detection and identification in system
    for audio-visual broadcast transcription,” in *44th International Conference on
    Telecommunications and Signal Processing*, 2021, pp. 357–360.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] G. Kumar, P. Keserwani, P. P. Roy, and D. P. Dogra, “Logo detection using
    weakly supervised saliency map,” *Multimedia Tools and Applications*, vol. 80,
    pp. 4341–4365, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] C. Wilms, R. Heid, M. A. Sadeghi, A. Ribbrock, and S. Frintrop, “Which
    airline is this? Airline logo detection in real-world weather conditions,” in
    *25th International Conference on Pattern Recognition*, 2021, pp. 4996–5003.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] R. K. Jain, T. Watasue, T. Nakagawa, S. Takahiro, Y. Iwamoto, R. Xiang,
    and Y. W. Chen, “LogoNet: Layer-aggregated attention centerNet for logo detection,”
    in *IEEE International Conference on Consumer Electronics*, 2021, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] E. Yohannes, C. Y. Lin, T. K. Shih, C. Y. Hong, A. Enkhbat, and F. Utaminingrum,
    “Domain adaptation deep attention network for automatic logo detection and recognition
    in google street view,” *IEEE Access*, vol. 9, pp. 102 623–102 635, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] H. Su, S. Gong, and X. Zhu, “Multi-perspective cross-class domain adaptation
    for open logo detection,” *Computer Vision and Image Understanding*, vol. 204,
    p. 103156, 2021.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] H. Su and G. Qiu, “Few shot transfer active learning for logo detection
    in sports video,” *SSRN Electronic Journal*, 2022.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] C. Wilms and S. Frintrop, “AttentionMask: Attentive, efficient object
    proposal generation focusing on small objects,” in *Asian Conference on Computer
    Vision*, 2018, pp. 678–694.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] S. Sotheeswaran and A. Ramanan, “A classifier-free codebook-based image
    classification of vehicle logos,” in *9th International Conference on Industrial
    and Information Systems*, 2014, pp. 1–6.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Y. Zhang, M. Zhu, D. Wang, and S. Feng, “Logo detection and recognition
    based on classification,” in *Web-Age Information Management*, 2014, pp. 805–816.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] D. Guru and N. V. Kumar, “Symbolic representation and classification of
    logos,” in *Proceedings of International Conference on Computer Vision and Image
    Processing*, 2017, pp. 555–569.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Q. Ye, Z. Luo, X. Xiao, and S. Ge, “GeLogo: Detecting tv logos from web-scale
    videos,” in *IEEE Third International Conference on Multimedia Big Data*, 2017,
    pp. 250–251.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] V. P. Le, M. Visani, D. C. Tran, and J. M. Ogier, “Improving logo spotting
    and matching for document categorization by a post-filter based on homography,”
    in *12th International Conference on Document Analysis and Recognition*, 2013,
    pp. 270–274.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] T. A. Pham, M. Delalandre, and S. Barrat, “A contour-based method for
    logo detection,” in *International Conference on Document Analysis and Recognition*,
    2011, pp. 718–722.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Z. Li, S. A. Matthias, and M. Neschen, “Fast logo detection and recognition
    in document images,” in *20th International Conference on Pattern Recognition*,
    2010, pp. 2716–2719.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] A. Alaei and M. Delalandre, “A complete logo detection/recognition system
    for document images,” in *11th IAPR International Workshop on Document Analysis
    Systems*, 2014, pp. 324–328.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] G. Zhu and D. S. Doermann, “Automatic document logo detection,” in *9th
    International Conference on Document Analysis and Recognition*, 2007, pp. 864–868.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] N. Özay and B. Sankur, “Automatic TV logo detection and classification
    in broadcast videos,” in *17th European Signal Processing Conference*, 2009, pp.
    839–843.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Y. Chen and V. L. L. Thing, “A noise-tolerant enhanced classification
    method for logo detection and brand classification,” in *FGIT-SecTech*, 2011,
    pp. 31–42.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] P. Pimkote and T. Kangkachit, “Classification of alcohol brand logos using
    convolutional neural networks,” in *International Conference on Digital Arts,
    Media and Technology*, 2018, pp. 135–138.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] D. Pan, P. Shi, Z. Qiu, Y. Sha, X. Zhongdi, and J. Zhoushao, “TV logo
    classification based on convolutional neural network,” in *IEEE International
    Conference on Information and Automation*, 2016, pp. 1793–1796.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] S. K. Divvala, D. Hoiem, J. Hays, A. A. Efros, and M. Hebert, “An empirical
    study of context in object detection,” in *IEEE Conference on Computer Vision
    and Pattern Recognition*, 2009, pp. 1271–1278.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
