- en: <!--yml
  id: totrans-0
  prefs: []
  type: TYPE_NORMAL
  zh: <!--yml
- en: 'category: 未分类'
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: '类别: 未分类'
- en: 'date: 2024-09-06 19:44:11'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: '日期: 2024-09-06 19:44:11'
- en: -->
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: -->
- en: '[2210.04399] Deep Learning for Logo Detection: A Survey'
  id: totrans-4
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '[2210.04399] 深度学习在标志检测中的应用：一项综述'
- en: 来源：[https://ar5iv.labs.arxiv.org/html/2210.04399](https://ar5iv.labs.arxiv.org/html/2210.04399)
  id: totrans-5
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
  zh: 来源：[https://ar5iv.labs.arxiv.org/html/2210.04399](https://ar5iv.labs.arxiv.org/html/2210.04399)
- en: \UseRawInputEncoding
  id: totrans-6
  prefs: []
  type: TYPE_NORMAL
  zh: \UseRawInputEncoding
- en: 'Deep Learning for Logo Detection: A Survey'
  id: totrans-7
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 深度学习在标志检测中的应用：一项综述
- en: Sujuan Hou, Member, IEEE, Jiacheng Li, Weiqing Min, Senior Member, IEEE, Qiang
    Hou,
  id: totrans-8
  prefs: []
  type: TYPE_NORMAL
  zh: Sujuan Hou, 会员, IEEE, Jiacheng Li, Weiqing Min, 高级会员, IEEE, Qiang Hou,
- en: 'Yanna Zhao, Member, IEEE, Yuanjie Zheng, Member, IEEE, and Shuqiang Jiang,
    Senior Member, IEEE This work was supported by the National Nature Science Foundation
    of China (No.62072289, 61972378, U193620), CAAI-Huawei MindSpore Open Fund. S.
    Hou, J. Li, Q. Hou, Y. Zhao and Y. Zheng are School of Information Science and
    Engineering, Shandong Normal University, Shandong, 250358, China. Email: sujuanhou@sdnu.edu.cn,
    2021317140@stu.sdnu.edu.cn, 2019309052@stu.sdnu.edu.cn, yannazhao@sdnu.edu.cn,
    and zhengyuanjie@gmail.com. W. Min and S. Jiang are with the Key Laboratory of
    Intelligent Information Processing, Institute of Computing Technology, Chinese
    Academy of Sciences, Beijing, 100190, China, and also with University of Chinese
    Academy of Sciences, Beijing, 100049, China. Email: minweiqing@ict.ac.cn, and
    sqjiang@ict.ac.cn.'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: 'Yanna Zhao, 会员, IEEE, Yuanjie Zheng, 会员, IEEE, 和 Shuqiang Jiang, 高级会员, IEEE
    本工作得到了中国国家自然科学基金（No.62072289, 61972378, U193620）、CAAI-Huawei MindSpore开放基金的支持。S.
    Hou, J. Li, Q. Hou, Y. Zhao 和 Y. Zheng 为山东师范大学信息科学与工程学院，山东，250358，中国。电子邮件: sujuanhou@sdnu.edu.cn,
    2021317140@stu.sdnu.edu.cn, 2019309052@stu.sdnu.edu.cn, yannazhao@sdnu.edu.cn
    和 zhengyuanjie@gmail.com。W. Min 和 S. Jiang 主要在中国科学院计算技术研究所智能信息处理重点实验室，北京，100190，中国，同时也是中国科学院大学，北京，100049，中国的成员。电子邮件:
    minweiqing@ict.ac.cn 和 sqjiang@ict.ac.cn。'
- en: Abstract
  id: totrans-10
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 摘要
- en: When logos are increasingly created, logo detection has gradually become a research
    hotspot across many domains and tasks. Recent advances in this area are dominated
    by deep learning-based solutions, where many datasets, learning strategies, network
    architectures, etc. have been employed. This paper reviews the advance in applying
    deep learning techniques to logo detection. Firstly, we discuss a comprehensive
    account of public datasets designed to facilitate performance evaluation of logo
    detection algorithms, which tend to be more diverse, more challenging, and more
    reflective of real life. Next, we perform an in-depth analysis of the existing
    logo detection strategies and the strengths and weaknesses of each learning strategy.
    Subsequently, we summarize the applications of logo detection in various fields,
    from intelligent transportation and brand monitoring to copyright and trademark
    compliance. Finally, we analyze the potential challenges and present the future
    directions for the development of logo detection to complete this survey.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 随着标志的逐渐增多，标志检测逐渐成为许多领域和任务中的研究热点。近年来，这一领域的进展主要由基于深度学习的解决方案主导，许多数据集、学习策略、网络架构等都得到了应用。本文回顾了深度学习技术在标志检测中的应用进展。首先，我们讨论了设计用于促进标志检测算法性能评估的公共数据集的全面情况，这些数据集往往更加多样化、更具挑战性、更能反映现实生活。接下来，我们对现有的标志检测策略及每种学习策略的优缺点进行了深入分析。随后，我们总结了标志检测在各个领域的应用，从智能交通和品牌监控到版权和商标合规。最后，我们分析了潜在的挑战，并提出了标志检测发展的未来方向，以完成这项调查。
- en: 'Index Terms:'
  id: totrans-12
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: '索引词:'
- en: logo detection, computer vision, deep learning, datasets
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 标志检测, 计算机视觉, 深度学习, 数据集
- en: I Introduction
  id: totrans-14
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: I 引言
- en: Logos usually consist of texts, shapes, images, or their combination. Logo detection
    benefits a wide range of applications in different areas, such as intelligent
    transportation [[1](#bib.bib1), [2](#bib.bib2)], social media monitoring [[3](#bib.bib3)],
    and infringement detection [[4](#bib.bib4), [5](#bib.bib5)]. Meanwhile, some competitions
    have emerged, such as Robust Logo Detection Grand Challenge [[5](#bib.bib5), [6](#bib.bib6),
    [7](#bib.bib7), [8](#bib.bib8)] and Few-shot Logo Detection [[9](#bib.bib9)].
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 标志通常由文本、形状、图像或其组合组成。标志检测对不同领域的广泛应用具有好处，例如智能交通[[1](#bib.bib1), [2](#bib.bib2)]、社交媒体监控[[3](#bib.bib3)]和侵权检测[[4](#bib.bib4),
    [5](#bib.bib5)]。与此同时，一些竞赛也已出现，如Robust Logo Detection Grand Challenge[[5](#bib.bib5),
    [6](#bib.bib6), [7](#bib.bib7), [8](#bib.bib8)]和Few-shot Logo Detection[[9](#bib.bib9)]。
- en: The main task of logo detection is to determine the location of a specific logo
    in images/videos and identify them. Although it may be regarded as a particular
    object task, logo detection in real-world images can be pretty challenging since
    numerous brands may have highly diverse contexts, varied scales, changes in illumination,
    size, resolution, and even non-rigid deformation (as shown in Fig. 1).
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 标志检测的主要任务是确定图像/视频中特定标志的位置并进行识别。虽然这可能被视为一个特定的物体任务，但在实际图像中进行标志检测可能非常具有挑战性，因为许多品牌可能具有高度多样化的背景、不同的尺度、光照变化、大小、分辨率，甚至是非刚性变形（如图
    1 所示）。
- en: '![Refer to caption](img/70a48b3668e2e60a738460940b4151ca.png)'
  id: totrans-17
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/70a48b3668e2e60a738460940b4151ca.png)'
- en: (a) dim light
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: (a) 微弱光线
- en: '![Refer to caption](img/107331ed035c57bd8731e4dad361c821.png)'
  id: totrans-19
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/107331ed035c57bd8731e4dad361c821.png)'
- en: (b) image rotation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: (b) 图像旋转
- en: '![Refer to caption](img/94e320419505381ebeec818d7e28e283.png)'
  id: totrans-21
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/94e320419505381ebeec818d7e28e283.png)'
- en: (c) small-scale logos
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: (c) 小规模标志
- en: '![Refer to caption](img/e77a9d073048e646399100ae9dcf9261.png)'
  id: totrans-23
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/e77a9d073048e646399100ae9dcf9261.png)'
- en: (d) multi-scale logos
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: (d) 多尺度标志
- en: '![Refer to caption](img/fbb9b443239f9a13575e9d74d8acf535.png)'
  id: totrans-25
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/fbb9b443239f9a13575e9d74d8acf535.png)'
- en: (e) non-rigid deformation
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: (e) 非刚性变形
- en: '![Refer to caption](img/59880c9604f91eb62ca494066b5c25a3.png)'
  id: totrans-27
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/59880c9604f91eb62ca494066b5c25a3.png)'
- en: (f) glare reflection
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: (f) 眩光反射
- en: 'Figure 1: Examples of images in adverse conditions.'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 图 1：不利条件下的图像示例。
- en: Many previous works on logo detection employ hand-crafted features (like SIFT [[10](#bib.bib10)])
    to represent logos and use statistical classifiers for classification. Such methods
    suffer from complex image preprocessing pipelines and poor robustness when dealing
    with a much larger number of logos. Recent years have witnessed the rousing success
    of deep learning since ImageNet Large Scale Visual Recognition Challenge (ILSVRC) [[11](#bib.bib11)].
    Deep learning-based solutions with expressive feature representation capability
    offer better robustness, accuracy, and speed and thus attract increasing attention.
    There are more than 100 papers about logo detection from 1993 to 2022, and a concise
    milestone of logo detection is shown in Fig. 2\. We can see that many deep learning-based
    logo detection strategies have been proposed since 2015\. This survey mainly concentrates
    on deep learning-based solutions specially developed for logo detection.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 许多先前的标志检测工作采用手工设计的特征（如 SIFT [[10](#bib.bib10)]) 来表示标志，并使用统计分类器进行分类。这些方法在处理大量标志时，常常面临复杂的图像预处理流程和较差的鲁棒性。近年来，自从
    ImageNet 大规模视觉识别挑战赛（ILSVRC） [[11](#bib.bib11)] 以来，深度学习取得了令人瞩目的成功。基于深度学习的解决方案凭借其表现力强的特征表示能力，提供了更好的鲁棒性、准确性和速度，因此吸引了越来越多的关注。从
    1993 年到 2022 年，有超过 100 篇关于标志检测的论文，图 2 展示了标志检测的一个简明里程碑。我们可以看到，自 2015 年以来，提出了许多基于深度学习的标志检测策略。本次调查主要集中在专门为标志检测开发的基于深度学习的解决方案上。
- en: '![Refer to caption](img/209fd4b766a88e3958dbe66f66535d1f.png)'
  id: totrans-31
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/209fd4b766a88e3958dbe66f66535d1f.png)'
- en: 'Figure 2: A concise milestone for logo detection.'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 图 2：标志检测的一个简明里程碑。
- en: Even though deep learning has dominated the logo research community, a comprehensive
    and in-depth survey on deep learning-based solutions is lacking. In this survey,
    we mainly focus on the advances in recent deep learning for logo detection. We
    provide in-depth analysis and discussion on existing studies in various aspects,
    covering datasets, pipelined used, task types, detection strategies, loss functions,
    their contributions and limitations. We also try to analyze potential research
    challenges and future research directions for logo detection. We hope our work
    could provide a novel perspective to promote the understanding of deep learning-based
    logo detection, foster research on open challenges, and speed up the development
    of the logo research field.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 尽管深度学习已经主导了标志研究社区，但缺乏关于基于深度学习的解决方案的全面和深入的综述。在本次调查中，我们主要关注最近在标志检测方面的深度学习进展。我们对现有研究进行了深入分析和讨论，涵盖数据集、使用的流程、任务类型、检测策略、损失函数、它们的贡献和局限性。我们还尝试分析标志检测中的潜在研究挑战和未来研究方向。我们希望我们的工作能提供一种新的视角，以促进对基于深度学习的标志检测的理解，推动对开放挑战的研究，并加快标志研究领域的发展。
- en: The rest of this paper is organized as follows. In Section II, we investigate
    the public logo detection datasets. In Section III, we review and organize the
    currently available work on logo detection. In Section IV, we introduce the applications
    of logo detection in real-world scenarios. In Section V, we discuss its challenges
    and prominent future research directions. Finally, we summarize the whole text
    in Section VI.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 本文的其余部分组织如下。第二节，我们调查公共标志检测数据集。第三节，我们回顾和整理当前关于标志检测的工作。第四节，我们介绍标志检测在实际场景中的应用。第五节，我们讨论其挑战和未来研究方向。最后，第六节总结了全文。
- en: '![Refer to caption](img/23e6e5085e0221cb5f62bf76b2be3542.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/23e6e5085e0221cb5f62bf76b2be3542.png)'
- en: (a) BelgaLogos
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: (a) BelgaLogos
- en: '![Refer to caption](img/987e0ccb421818becf4f98cd67ab11be.png)'
  id: totrans-37
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/987e0ccb421818becf4f98cd67ab11be.png)'
- en: (b) FoodLogoDet-1500
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: (b) FoodLogoDet-1500
- en: '![Refer to caption](img/de367e8631fbf4ed7b7e1915b2f7f42b.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/de367e8631fbf4ed7b7e1915b2f7f42b.png)'
- en: (c) QMUL-OpenLogo
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: (c) QMUL-OpenLogo
- en: '![Refer to caption](img/b4db70881758da104b88b06ce50ada2e.png)'
  id: totrans-41
  prefs: []
  type: TYPE_IMG
  zh: '![参见说明](img/b4db70881758da104b88b06ce50ada2e.png)'
- en: (d) LogoDet-3K
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: (d) LogoDet-3K
- en: 'Figure 3: Logo images sampled from different datasets.'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: '图 3: 从不同数据集中采样的标志图像。'
- en: II Logo Datasets
  id: totrans-44
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: II 标志数据集
- en: Deep learning has brought great success to object detection in recent years,
    where datasets play a crucial role. Datasets are not only a common basis for comparing
    and measuring the performance of algorithms but also an essential factor in supporting
    advanced object detection algorithms. This section provides an overview of the
    logo datasets for detection. In addition, we also give a brief summary of existing
    logo classification datasets.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 深度学习近年来在物体检测方面取得了巨大成功，其中数据集发挥了关键作用。数据集不仅是比较和测量算法性能的常用基础，也是支持先进物体检测算法的必要因素。本节概述了用于检测的标志数据集。此外，我们还简要总结了现有的标志分类数据集。
- en: 'In recent years, many logo datasets intended for detection have been created
    to solve the problem of large realistic datasets with accurate ground truth. The
    use of these datasets enables qualitative as well as quantitative comparisons
    and allows benchmarking of different algorithms. We conducted statistics on existing
    datasets commonly used for logo detection and classified them into three types
    based on their scale: small-scale, medium-scale, and large-scale. Table I provides
    statistics on the available logo datasets, and Fig. 3 gives some illustrative
    examples from these datasets.'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，为解决大规模现实数据集准确标注的问题，创建了许多用于检测的标志数据集。使用这些数据集能够进行定性和定量比较，并允许不同算法的基准测试。我们对现有的常用标志检测数据集进行了统计，并根据其规模将其分为小规模、中规模和大规模三类。表
    I 提供了可用标志数据集的统计信息，图 3 给出了这些数据集的一些示例。
- en: The small-scale datasets include BelgaLogos [[12](#bib.bib12)], FlickrLogos-32 [[13](#bib.bib13)],
    etc. As the first benchmark dataset proposed for logo detection, BelgaLogos [[12](#bib.bib12)]
    consists of 10,000 images of natural scenes, with 37 different logos and 2,695
    instances of logos labeled with bounding boxes. FlickrLogos-32 [[13](#bib.bib13)],
    one of the most popular small-scale datasets for logo detection, comprises 32
    different classes with 70 images in each class. The images in this dataset are
    mainly captured from the real world, and many contain occlusions, appearance changes,
    and lighting changes, making detecting this dataset very challenging.
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 小规模数据集包括 BelgaLogos [[12](#bib.bib12)]、FlickrLogos-32 [[13](#bib.bib13)] 等。作为第一个用于标志检测的基准数据集，BelgaLogos [[12](#bib.bib12)]
    包含 10,000 张自然场景图像，涵盖 37 种不同标志，并标注了 2,695 个标志实例的边界框。FlickrLogos-32 [[13](#bib.bib13)]
    是最受欢迎的小规模标志检测数据集之一，包括 32 个不同类别，每个类别有 70 张图像。该数据集中的图像主要来自真实世界，其中许多图像包含遮挡、外观变化和光照变化，使得检测这些图像非常具有挑战性。
- en: Datasets with medium-scale include Logo-Net [[14](#bib.bib14)], QMUL-OpenLogo [[15](#bib.bib15)],
    FoodLogoDet-1500 [[16](#bib.bib16)], etc. Logo-Net [[14](#bib.bib14)] is built
    for detecting logos and identifying brands from real-world product images. It
    consists of two sub-datasets, namely Logo-18 and Logo-160. QMUL-OpenLogo [[15](#bib.bib15)]
    is an open benchmark for logo detection, constructed by aggregating seven existing
    datasets and building an open protocol for logo detection evaluation. The QMUL-OpenLogo
    dataset has a highly imbalanced distribution and significant variation in scale,
    which is critical to verify the performance of the detection algorithm. FoodLogoDet-1500 [[16](#bib.bib16)]
    is the first high-quality public dataset of food logos with uneven distribution
    among different food logo classes, which poses a challenge to the small sample
    food logo detection algorithms. The dataset is composed of 1,500 food logo classes
    with 99,768 images.
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: 中等规模的数据集包括 Logo-Net [[14](#bib.bib14)]、QMUL-OpenLogo [[15](#bib.bib15)]、FoodLogoDet-1500 [[16](#bib.bib16)]
    等。Logo-Net [[14](#bib.bib14)] 是为检测标志和识别品牌而建立的，包含两个子数据集，即 Logo-18 和 Logo-160。QMUL-OpenLogo [[15](#bib.bib15)]
    是一个开放的标志检测基准，通过聚合七个现有数据集并建立开放的标志检测评估协议构建而成。QMUL-OpenLogo 数据集具有高度不平衡的分布和显著的尺度变化，这对验证检测算法的性能至关重要。FoodLogoDet-1500 [[16](#bib.bib16)]
    是第一个高质量的食品标志公开数据集，具有不同食品标志类别间的不均匀分布，这对小样本食品标志检测算法构成挑战。该数据集由 1,500 个食品标志类别和 99,768
    张图像组成。
- en: There are also some large-scale datasets, such as LogoDet-3K [[17](#bib.bib17)]
    and PL8K [[18](#bib.bib18)]. LogoDet-3K [[17](#bib.bib17)] divides all logos into
    nine super-classes based on the needs of daily life and the main positioning of
    common enterprises, namely Clothing, Food, Transportation, Electronics, Necessities,
    Leisure, Medicine, Sports, and Others. The dataset consists of 3,000 logo classes,
    158,652 images, and 194,261 logo objects. The number of logo classes contained
    in different super-classes varies greatly. For example, the “Food”, “Clothes”,
    and “Necessities” contain more images and objects than other super-classes. The
    imbalanced distribution across different logo classes of LogoDet-3K poses a challenge
    to effectively detecting logos with few samples. PL8K [[18](#bib.bib18)] is a
    large logo detection dataset constructed semi-automatically. The dataset consists
    of 7,888 logo brands and 3,017,146 images, and at least 20 images per class.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 还有一些大规模的数据集，如 LogoDet-3K [[17](#bib.bib17)] 和 PL8K [[18](#bib.bib18)]。LogoDet-3K [[17](#bib.bib17)]
    根据日常生活的需求和常见企业的主要定位，将所有标志分为九个超类，即服装、食品、交通、电子产品、日用必需品、休闲、医学、体育和其他。该数据集包含 3,000
    个标志类别、158,652 张图像和 194,261 个标志对象。不同超类中的标志类别数量差异很大。例如，“食品”、“服装”和“日用必需品”包含的图像和对象比其他超类更多。LogoDet-3K
    在不同标志类别中的不平衡分布对有效检测少样本标志构成了挑战。PL8K [[18](#bib.bib18)] 是一个半自动构建的大型标志检测数据集。该数据集包含
    7,888 个标志品牌和 3,017,146 张图像，每个类别至少有 20 张图像。
- en: 'TABLE I: Statistics of existing logo detection datasets.'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 表 I：现有标志检测数据集的统计信息。
- en: '| #Scale | #Datasets | #Logos | #Brands | #Images | #Objects | #Public | #Year
    |'
  id: totrans-51
  prefs: []
  type: TYPE_TB
  zh: '| #规模 | #数据集 | #标志 | #品牌 | #图像 | #对象 | #公开 | #年份 |'
- en: '| Small | BelgaLogos [[12](#bib.bib12)] | 37 | 37 | 10,000 | 2,695 | Yes |
    2009 |'
  id: totrans-52
  prefs: []
  type: TYPE_TB
  zh: '| 小规模 | BelgaLogos [[12](#bib.bib12)] | 37 | 37 | 10,000 | 2,695 | 是 | 2009
    |'
- en: '| FlickrLogos-27 [[19](#bib.bib19)] | 27 | 27 | 1,080 | 4,671 | Yes | 2011
    |'
  id: totrans-53
  prefs: []
  type: TYPE_TB
  zh: '| FlickrLogos-27 [[19](#bib.bib19)] | 27 | 27 | 1,080 | 4,671 | 是 | 2011 |'
- en: '| FlickrLogos-32 [[13](#bib.bib13)] | 32 | 32 | 2,240 | 5,644 | Yes | 2011
    |'
  id: totrans-54
  prefs: []
  type: TYPE_TB
  zh: '| FlickrLogos-32 [[13](#bib.bib13)] | 32 | 32 | 2,240 | 5,644 | 是 | 2011 |'
- en: '| MICC-Logos [[10](#bib.bib10)] | 13 |  | 720 | - | No | 2013 |'
  id: totrans-55
  prefs: []
  type: TYPE_TB
  zh: '| MICC-Logos [[10](#bib.bib10)] | 13 |  | 720 | - | 否 | 2013 |'
- en: '| Logo-18 [[14](#bib.bib14)] | 18 | 10 | 8,460 | 16,043 | No | 2015 |'
  id: totrans-56
  prefs: []
  type: TYPE_TB
  zh: '| Logo-18 [[14](#bib.bib14)] | 18 | 10 | 8,460 | 16,043 | 否 | 2015 |'
- en: '| Logos-32plus [[20](#bib.bib20)] | 32 | 32 | 7,830 | 12,302 | No | 2017 |'
  id: totrans-57
  prefs: []
  type: TYPE_TB
  zh: '| Logos-32plus [[20](#bib.bib20)] | 32 | 32 | 7,830 | 12,302 | 否 | 2017 |'
- en: '| Top-Logo-10 [[21](#bib.bib21)] | 10 | 10 | 700 | - | No | 2017 |'
  id: totrans-58
  prefs: []
  type: TYPE_TB
  zh: '| Top-Logo-10 [[21](#bib.bib21)] | 10 | 10 | 700 | - | 否 | 2017 |'
- en: '| Video SportsLogo [[22](#bib.bib22)] | 20 | 20 | 2,000 | - | No | 2017 |'
  id: totrans-59
  prefs: []
  type: TYPE_TB
  zh: '| Video SportsLogo [[22](#bib.bib22)] | 20 | 20 | 2,000 | - | 否 | 2017 |'
- en: '| VLD 1.0 [[23](#bib.bib23)] | 66 | 66 | 25,189 | - | No | 2019 |'
  id: totrans-60
  prefs: []
  type: TYPE_TB
  zh: '| VLD 1.0 [[23](#bib.bib23)] | 66 | 66 | 25,189 | - | 否 | 2019 |'
- en: '| SportLogo [[24](#bib.bib24)] | 31 | 31 | 2,836 | - | Yes | 2020 |'
  id: totrans-61
  prefs: []
  type: TYPE_TB
  zh: '| SportLogo [[24](#bib.bib24)] | 31 | 31 | 2,836 | - | 是 | 2020 |'
- en: '| VLD-45 [[25](#bib.bib25)] | 45 | 45 | 45,000 | - | No | 2020 |'
  id: totrans-62
  prefs: []
  type: TYPE_TB
  zh: '| VLD-45 [[25](#bib.bib25)] | 45 | 45 | 45,000 | - | 否 | 2020 |'
- en: '| Medium | Logo-160 [[14](#bib.bib14)] | 160 | 100 | 73,414 | 130,608 | No
    | 2015 |'
  id: totrans-63
  prefs: []
  type: TYPE_TB
  zh: '| 中等 | Logo-160 [[14](#bib.bib14)] | 160 | 100 | 73,414 | 130,608 | 否 | 2015
    |'
- en: '| Logos-in-the-Wild [[26](#bib.bib26)] | 871 | 871 | 11,054 | 32,850 | Yes
    | 2017 |'
  id: totrans-64
  prefs: []
  type: TYPE_TB
  zh: '| Logos-in-the-Wild [[26](#bib.bib26)] | 871 | 871 | 11,054 | 32,850 | 是 |
    2017 |'
- en: '| QMUL-OpenLogo [[15](#bib.bib15)] | 352 | 352 | 27,083 | - | Yes | 2018 |'
  id: totrans-65
  prefs: []
  type: TYPE_TB
  zh: '| QMUL-OpenLogo [[15](#bib.bib15)] | 352 | 352 | 27,083 | - | 是 | 2018 |'
- en: '| PL2K [[27](#bib.bib27)] | 2,000 | 2,000 | 295,814 | - | No | 2019 |'
  id: totrans-66
  prefs: []
  type: TYPE_TB
  zh: '| PL2K [[27](#bib.bib27)] | 2,000 | 2,000 | 295,814 | - | 否 | 2019 |'
- en: '| FoodLogoDet-1500 [[16](#bib.bib16)] | 1,500 | - | 99,768 | 145,400 | Yes
    | 2021 |'
  id: totrans-67
  prefs: []
  type: TYPE_TB
  zh: '| FoodLogoDet-1500 [[16](#bib.bib16)] | 1,500 | - | 99,768 | 145,400 | 是 |
    2021 |'
- en: '| Large | Open Brands [[28](#bib.bib28)] | 1,216 | 559 | 1,437,812 | 3,113,828
    | No | 2020 |'
  id: totrans-68
  prefs: []
  type: TYPE_TB
  zh: '| Large | Open Brands [[28](#bib.bib28)] | 1,216 | 559 | 1,437,812 | 3,113,828
    | 否 | 2020 |'
- en: '| LogoDet-3K [[17](#bib.bib17)] | 3,000 | 2,864 | 158,652 | 194,261 | Yes |
    2020 |'
  id: totrans-69
  prefs: []
  type: TYPE_TB
  zh: '| LogoDet-3K [[17](#bib.bib17)] | 3,000 | 2,864 | 158,652 | 194,261 | 是 | 2020
    |'
- en: '| PL8K [[18](#bib.bib18)] | 7,888 | 7,888 | 3,017,146 | - | No | 2022 |'
  id: totrans-70
  prefs: []
  type: TYPE_TB
  zh: '| PL8K [[18](#bib.bib18)] | 7,888 | 7,888 | 3,017,146 | - | 否 | 2022 |'
- en: 'In addition, there are also some datasets built for logo classification, e.g.
    WebLogo-2M [[29](#bib.bib29)] and Logo 2K+ [[30](#bib.bib30)]. Weblogo-2M [[29](#bib.bib29)]
    is obtained by automatic web data acquisition and processing. The dataset excludes
    images with small widths and/or heights and duplicate images. Compared with other
    datasets, the Weblogo-2M presents three unique properties inherent to large-scale
    data exploration for learning scalable logo models: (1) Weak Annotation. (2) Noisy
    (False Positives). (3) Class Imbalance. Logo-2K+ [[30](#bib.bib30)] is a large-scale
    high-quality logo dataset. It covers a variety of logo classes from the real world,
    and different types of logo images have various logo appearances, scales, and
    backgrounds since they are collected from different websites. The dataset has
    high spatial coverage of categories including Food, Clothes, Institutions, Accessories,
    Transportation, Electronics, Necessities, Cosmetics, Leisure, and Medical. The
    number of images is imbalanced among different categories. For instance, “Food”
    has 769 logo classes, while “Medical” has only 48.'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，还有一些为标志分类构建的数据集，如 WebLogo-2M [[29](#bib.bib29)] 和 Logo 2K+ [[30](#bib.bib30)]。WebLogo-2M [[29](#bib.bib29)]
    是通过自动化的网页数据获取和处理获得的。该数据集排除了小宽度和/或高度的图像以及重复图像。与其他数据集相比，WebLogo-2M 具有三种独特属性，适用于大规模数据探索以学习可扩展的标志模型：（1）弱标注。（2）噪声（误报）。
    （3）类别不平衡。Logo-2K+ [[30](#bib.bib30)] 是一个大规模的高质量标志数据集。它涵盖了来自现实世界的各种标志类别，不同类型的标志图像具有不同的标志外观、规模和背景，因为它们来自不同的网站。该数据集具有包括食品、服装、机构、配件、交通、电子产品、必需品、化妆品、休闲和医疗在内的类别的高空间覆盖率。不同类别之间的图像数量不均衡。例如，“食品”有
    769 个标志类别，而“医疗”只有 48 个。
- en: As with common object detection, mAP [[31](#bib.bib31)] is the most commonly
    used evaluation metric to measure logo detectors.
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: 与常见的目标检测方法一样，mAP [[31](#bib.bib31)] 是测量标志检测器的最常用评估指标。
- en: '![Refer to caption](img/4d0a136f9feae2342fd5131970036742.png)'
  id: totrans-73
  prefs: []
  type: TYPE_IMG
  zh: '![参考图例](img/4d0a136f9feae2342fd5131970036742.png)'
- en: 'Figure 4: The architecture of DRNA-Net [[30](#bib.bib30)].'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 图 4：DRNA-Net 的架构 [[30](#bib.bib30)]。
- en: III Logo Detection
  id: totrans-75
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: III 标志检测
- en: In logo detection, logo classification is also an essential part. Therefore,
    we briefly summarize logo classification before introducing logo detection.
  id: totrans-76
  prefs: []
  type: TYPE_NORMAL
  zh: 在标志检测中，标志分类也是一个重要部分。因此，在介绍标志检测之前，我们简要总结了标志分类。
- en: III-A Logo Classification
  id: totrans-77
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-A 标志分类
- en: 'As one of the most critical tasks in computer vision, logo classification aims
    to recognize the logo name corresponding to the input image. According to different
    feature extraction strategies, existing classification methods are divided into
    two categories: *traditional machine learning-based methods* and *deep learning-based
    methods*. Some representative methods will be described briefly in the following.'
  id: totrans-78
  prefs: []
  type: TYPE_NORMAL
  zh: 作为计算机视觉中最关键的任务之一，标志分类旨在识别与输入图像对应的标志名称。根据不同的特征提取策略，现有的分类方法分为两类：*传统机器学习方法* 和 *深度学习方法*。以下将简要描述一些具有代表性的方法。
- en: III-A1 Traditional Machine Learning-based Methods
  id: totrans-79
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A1 传统机器学习方法
- en: The traditional logo classification methods extract features through manual
    features, such as SIFT and HOG, and then classify them by a classifier. Support
    Vector Machine (SVM) [[32](#bib.bib32)] is a classifier that performs binary data
    classification in a supervised learning manner. In traditional logo classification,
    SVM also shows excellent performance [[33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35),
    [36](#bib.bib36)]. Carvalho *et al*. [[35](#bib.bib35)] proposed a self-learning
    and automatic detection method that performs detection without any prior data.
    The scheme automatically identifies the candidate regions of the localization
    logo, uses the HOG features extracted from the localization to train the object
    detector and some sub-detectors and uses the SVM to recognize the logo image.
  id: totrans-80
  prefs: []
  type: TYPE_NORMAL
  zh: 传统的标志分类方法通过手动特征提取，例如 SIFT 和 HOG，然后通过分类器进行分类。支持向量机（SVM）[[32](#bib.bib32)] 是一种以监督学习方式进行二分类的数据分类器。在传统的标志分类中，SVM
    也表现出色[[33](#bib.bib33), [34](#bib.bib34), [35](#bib.bib35), [36](#bib.bib36)]。Carvalho
    *等* [[35](#bib.bib35)] 提出了一个自学习和自动检测方法，该方法在没有任何先验数据的情况下进行检测。该方案自动识别标志定位的候选区域，使用从定位中提取的
    HOG 特征来训练目标检测器和一些子检测器，并使用 SVM 来识别标志图像。
- en: K-Nearest Neighbor (KNN) is a supervised learning algorithm commonly used in
    classification [[37](#bib.bib37), [38](#bib.bib38)]. Gopinathan *et al*. [[38](#bib.bib38)]
    proposed a vehicle logo recognition system in 2018\. They used Euclidean distance
    on the initial training dataset to summarize the pixel intensity distribution
    by applying each channel’s mean and standard deviation and used the K-means algorithm
    to cluster the color histogram features to group different logos. Then HOG and
    KNN algorithms extract logo features and classify logos.
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: K-最近邻（KNN）是一种常用于分类的监督学习算法[[37](#bib.bib37), [38](#bib.bib38)]。Gopinathan *等*
    [[38](#bib.bib38)] 在 2018 年提出了一个车辆标志识别系统。他们使用欧几里得距离对初始训练数据集进行处理，通过应用每个通道的均值和标准差总结像素强度分布，并使用
    K-means 算法对颜色直方图特征进行聚类，以分组不同的标志。然后，HOG 和 KNN 算法提取标志特征并对标志进行分类。
- en: III-A2 Deep Learning-based Methods
  id: totrans-82
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-A2 基于深度学习的方法
- en: In recent years, with the continuous development of deep learning, deep learning
    based solutions have also been successfully applied to logo classification [[39](#bib.bib39),
    [40](#bib.bib40), [41](#bib.bib41), [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44),
    [45](#bib.bib45), [46](#bib.bib46)]. Karimi *et al*. [[43](#bib.bib43)] used the
    DCNN logo recognition algorithm, which conducted a pre-trained model for feature
    extraction and then used SVM for logo classification. They also used transfer
    learning to improve existing pre-trained models for logo recognition. Finally,
    the fine-tuned deep model is applied to the parallel structure to obtain a more
    efficient deep model for logo recognition.
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 近年来，随着深度学习的不断发展，基于深度学习的解决方案也成功应用于标志分类[[39](#bib.bib39), [40](#bib.bib40), [41](#bib.bib41),
    [42](#bib.bib42), [43](#bib.bib43), [44](#bib.bib44), [45](#bib.bib45), [46](#bib.bib46)]。Karimi
    *等* [[43](#bib.bib43)] 使用了 DCNN 标志识别算法，该算法进行了预训练模型的特征提取，然后使用 SVM 进行标志分类。他们还使用迁移学习来改进现有的预训练模型以进行标志识别。最后，将微调后的深度模型应用于并行结构，以获得更高效的深度模型用于标志识别。
- en: 'The latest trend in logo classification is to design efficient networks with
    limited resources [[30](#bib.bib30), [47](#bib.bib47), [48](#bib.bib48), [18](#bib.bib18)].
    Wang *et al*. [[30](#bib.bib30)] proposed a Discriminative Region Navigation and
    Augmentation Network (DRNA-Net), which is capable of discovering more informative
    regions and expanding these regions for logo classification. DRNA-Net is mainly
    divided into four parts: navigator sub-network, teacher sub-network, region-oriented
    data augmentation sub-network, and scrutinizer sub-network. Specifically, the
    navigation sub-network first computes the amount of information in all regions
    generated by pre-defined anchors in the image. In order to make the navigation
    sub-network selects the most informative logo-relevant regions, the teacher sub-network
    then evaluates each region’s confidence that belongs to the ground-truth class.
    The region-oriented data augmentation sub-network can augment the selected regions
    to localize more relevant logo regions. Finally, the features of augment regions
    and the whole image are fused by the scrutinizer sub-network to obtain a unified
    feature representation for logo prediction. The architecture of DRNA-Net is shown
    in Fig. 4. In order to distinguish visually similar logos, Li *et al*. [[18](#bib.bib18)]
    proposed a multi-task learning architecture named SeeTek based on deep learning
    and scene text recognition. This model combines deep metric learning and text
    recognition into a single model leading to considerable performance improvements.
    The architecture of SeeTek is shown in Fig. 5.'
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 徽标分类的最新趋势是设计具有有限资源的高效网络[[30](#bib.bib30), [47](#bib.bib47), [48](#bib.bib48),
    [18](#bib.bib18)]。Wang *等人* [[30](#bib.bib30)] 提出了一个名为Discriminative Region Navigation
    and Augmentation Network (DRNA-Net)的网络，该网络能够发现更多信息丰富的区域并扩展这些区域用于徽标分类。DRNA-Net主要分为四个部分：导航子网络、教师子网络、区域导向数据增强子网络和审查子网络。具体而言，导航子网络首先计算图像中由预定义锚点生成的所有区域的信息量。为了使导航子网络选择最具信息量的徽标相关区域，教师子网络随后评估每个区域属于真实类别的置信度。区域导向数据增强子网络可以增强所选区域以定位更多相关徽标区域。最后，增强区域和整张图像的特征通过审查子网络进行融合，以获得统一的徽标预测特征表示。DRNA-Net的架构如图4所示。为了区分视觉上相似的徽标，Li
    *等人* [[18](#bib.bib18)] 提出了一个名为SeeTek的多任务学习架构，该架构基于深度学习和场景文本识别。该模型将深度度量学习和文本识别结合成一个模型，从而显著提高了性能。SeeTek的架构如图5所示。
- en: III-B Logo Detection
  id: totrans-85
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: III-B 徽标检测
- en: Logo detection can be seen as a particular case of general object detection.
    The purpose of logo detection is to detect logo instances of predefined logo classes
    in images or videos [[14](#bib.bib14)]. In this section, we will present the current
    state-of-the-art work on logo detection in detail.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 徽标检测可以看作是通用对象检测的一个特例。徽标检测的目的是在图像或视频中检测预定义徽标类别的徽标实例[[14](#bib.bib14)]。在本节中，我们将详细介绍徽标检测领域的最新前沿工作。
- en: 'Before the development of deep learning, early approaches to logo detection
    were implemented based on hand-crafted visual features (e.g., SIFT and HOG) and
    traditional classification models (e.g., SVM) [[49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52)]. For example, Sahbi *et al*. [[10](#bib.bib10)]
    proposed a logo matching system in 2013, where they used SIFT to conduct logo
    detection and recognition. The designed system can not only recognize and match
    multiple reference logos in an image but also is suitable for detecting similar
    logos. However, such traditional logo detection methods have certain limitations:
    (1) The region-selective search algorithm based on sliding windows lacks pertinence,
    especially with high time complexity. (2) The hand-designed features lack robustness
    to the variation of logo diversity.'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: 在深度学习发展之前，早期的徽标检测方法是基于手工设计的视觉特征（如SIFT和HOG）和传统分类模型（如SVM）[[49](#bib.bib49), [50](#bib.bib50),
    [51](#bib.bib51), [52](#bib.bib52)]。例如，Sahbi *等人* [[10](#bib.bib10)] 在2013年提出了一种徽标匹配系统，该系统使用SIFT进行徽标检测和识别。设计的系统不仅可以识别和匹配图像中的多个参考徽标，还适合检测相似徽标。然而，这些传统的徽标检测方法存在一定的局限性：（1）基于滑动窗口的区域选择搜索算法缺乏针对性，尤其是时间复杂度高。（2）手工设计的特征对徽标多样性的变化缺乏鲁棒性。
- en: In recent research, deep learning has emerged as the mainstream for logo detection.
    According to different learning strategies, we categorize these models into region-based
    Convolutional Neural Network models, YOLO-based models, Single Shot Detector-based
    models, Feature Pyramid Network-based models and other models.
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 在最近的研究中，深度学习已成为标志检测的主流。根据不同的学习策略，我们将这些模型分为基于区域的卷积神经网络模型、基于YOLO的模型、基于单次检测器的模型、基于特征金字塔网络的模型以及其他模型。
- en: '![Refer to caption](img/7f9ed956d3cfa2bc3bd7c25bdc7b03bd.png)'
  id: totrans-89
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/7f9ed956d3cfa2bc3bd7c25bdc7b03bd.png)'
- en: 'Figure 5: The architecture of SeeTek [[18](#bib.bib18)].'
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: '图5: SeeTek的架构 [[18](#bib.bib18)]。'
- en: III-B1 Region-based Convolutional Neural Network models (RCNNs)
  id: totrans-91
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B1 区域基卷积神经网络模型（RCNNs）
- en: Region-based Convolutional Neural Network (R-CNN [[53](#bib.bib53)]) is a typical
    region proposals-based approach. Compared with traditional detection algorithms,
    R-CNN has achieved considerable performance improvement. However, R-CNN still
    has several shortcomings. For example, R-CNN uses the Selective Search (SS) [[54](#bib.bib54)]
    algorithm to generate many overlapping boxes for redundant computation, leading
    to slow detection speed and taking up a large amount of storage space. The later
    proposed Fast R-CNN [[55](#bib.bib55)] solves this issue by creating an end-to-end
    trainable system. However, Fast R-CNN still uses the SS algorithm to generate
    region proposals, limiting its speed. To solve this problem, Ren *et al*. proposed
    Faster R-CNN [[56](#bib.bib56)] in 2015, which adopts region proposal network
    (RPN) to generate region proposals. Although Faster R-CNN has advantages in speed
    and efficiency, it still suffers from computational redundancy and low efficiency
    of small object detection.
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 区域基卷积神经网络（R-CNN [[53](#bib.bib53)]）是一种典型的基于区域提案的方法。与传统检测算法相比，R-CNN取得了显著的性能提升。然而，R-CNN仍然存在一些缺点。例如，R-CNN使用Selective
    Search (SS) [[54](#bib.bib54)] 算法生成许多重叠的框进行冗余计算，导致检测速度慢并占用大量存储空间。后来的Fast R-CNN
    [[55](#bib.bib55)] 通过创建一个端到端的可训练系统解决了这个问题。然而，Fast R-CNN仍使用SS算法生成区域提案，限制了其速度。为了解决这个问题，Ren
    *et al*. 提出了Faster R-CNN [[56](#bib.bib56)]，采用区域提案网络（RPN）来生成区域提案。尽管Faster R-CNN在速度和效率上具有优势，但仍然存在计算冗余和小物体检测效率低的问题。
- en: Recently, RCNN-based logo detection has also achieved considerable success [[26](#bib.bib26),
    [57](#bib.bib57), [58](#bib.bib58), [59](#bib.bib59)]. Since the same brand may
    contain multiple products, different product images of the same brand may present
    different visual content, and traditional image recognition methods cannot directly
    solve the problem of brand recognition. Hoi *et al*. [[14](#bib.bib14)] proposed
    a DeepLogo-DRCN scheme for logo detection and brand recognition by exploring several
    deep region-based convolutional network (DRCN) techniques for object detection.
    They adopt Selective Search [[54](#bib.bib54)] to generate regions of interests
    (RoIs) and input the RoIs into a fully convolutional network (FCN). Feature vectors
    are then obtained through fully connected layers (FCs) to train the final classifiers
    and bounding box regressors. The overall architecture is trained in an end-to-end
    way. This is the first work on deep learning-based logo detection, which provides
    a new perspective on logo detection research.
  id: totrans-93
  prefs: []
  type: TYPE_NORMAL
  zh: 最近，基于RCNN的标志检测也取得了相当大的成功[[26](#bib.bib26), [57](#bib.bib57), [58](#bib.bib58),
    [59](#bib.bib59)]。由于同一品牌可能包含多个产品，同一品牌的不同产品图像可能呈现不同的视觉内容，传统的图像识别方法无法直接解决品牌识别问题。Hoi
    *et al*. [[14](#bib.bib14)] 提出了一个DeepLogo-DRCN方案，通过探索几种深度区域卷积网络（DRCN）技术用于物体检测，以进行标志检测和品牌识别。他们采用Selective
    Search [[54](#bib.bib54)] 生成兴趣区域（RoIs），并将RoIs输入到全卷积网络（FCN）中。然后通过全连接层（FCs）获得特征向量，以训练最终的分类器和边界框回归器。整体架构以端到端的方式进行训练。这是基于深度学习的标志检测的首个研究，为标志检测研究提供了新的视角。
- en: We know that training a large-scale logo detection model requires a large amount
    of data, and the logo datasets usually suffer from data scarcity. Data augmentation
    and transfer learning are common solutions to release the problem of data scarcity.
    Oliveira *et al*. [[60](#bib.bib60)] proposed an automatic graphic logo detection
    system based on Fast R-CNN [[55](#bib.bib55)], which is robust to unconstrained
    imaging conditions. They used transfer learning and data augmentation to train
    a convolutional neural network model and allowed multiple detections of potential
    regions containing objects. Experimental results demonstrate that this strategy
    is superior to the traditional methods [[13](#bib.bib13)]. However, the adopted
    SS algorithm still generates redundant calculations, reducing detection speed.
    In addition, Li *et al*. [[61](#bib.bib61)] built Faster R-CNN for logo detection
    by using transfer learning, data augmentation, and clustering to guarantee suitable
    hyperparameters and more precise anchors for RPN. The experimental results show
    that this improvement could significantly improve the detection accuracy.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 我们知道，训练一个大规模的标志检测模型需要大量的数据，而标志数据集通常会面临数据稀缺的问题。数据增强和迁移学习是解决数据稀缺问题的常见方法。Oliveira
    *et al*. [[60](#bib.bib60)] 提出了一个基于 Fast R-CNN [[55](#bib.bib55)] 的自动图形标志检测系统，该系统对不受限制的成像条件具有鲁棒性。他们使用迁移学习和数据增强来训练卷积神经网络模型，并允许对包含对象的潜在区域进行多次检测。实验结果表明，这种策略优于传统方法
    [[13](#bib.bib13)]。然而，采用的 SS 算法仍然会产生冗余计算，降低了检测速度。此外，Li *et al*. [[61](#bib.bib61)]
    通过使用迁移学习、数据增强和聚类构建了 Faster R-CNN 用于标志检测，以保证适当的超参数和更精确的锚点用于 RPN。实验结果表明，这一改进可以显著提高检测精度。
- en: III-B2 YOLO-based models (YOLOs)
  id: totrans-95
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B2 基于 YOLO 的模型 (YOLOs)
- en: YOLOs are single-stage detectors that are commonly used for logo detection.
    YOLOs directly detect images and outputs the category and location information
    of the detected objects. Early YOLO [[62](#bib.bib62)] has fast detection speed,
    but at the expense of accuracy, especially for small objects. The later improvements,
    like YOLOv2 [[63](#bib.bib63)], YOLOv3 [[64](#bib.bib64)], YOLOv4 [[65](#bib.bib65)],
    YOLOF [[66](#bib.bib66)], YOLOR [[67](#bib.bib67)], YOLOX [[68](#bib.bib68)],
    YOLOv6 [[69](#bib.bib69)], YOLOv7[[70](#bib.bib70)] improve the overall performance
    of YOLO, balancing the accuracy and speed.
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: YOLO 是单阶段检测器，常用于标志检测。YOLO 直接检测图像并输出检测对象的类别和位置信息。早期的 YOLO [[62](#bib.bib62)]
    检测速度较快，但牺牲了精度，尤其是对于小物体。后来的改进，如 YOLOv2 [[63](#bib.bib63)]、YOLOv3 [[64](#bib.bib64)]、YOLOv4
    [[65](#bib.bib65)]、YOLOF [[66](#bib.bib66)]、YOLOR [[67](#bib.bib67)]、YOLOX [[68](#bib.bib68)]、YOLOv6
    [[69](#bib.bib69)]、YOLOv7 [[70](#bib.bib70)] 改善了 YOLO 的整体性能，平衡了精度和速度。
- en: YOLOs are widely used in vehicle logo detection. Given that real-time and high
    efficiency is essential issues in vehicle logo detection. Inspired by the superiority
    of deep learning in feature extraction, Yin *et al*. [[71](#bib.bib71)] proposed
    a high-efficiency vehicle logo detection system based on YOLOv2 [[63](#bib.bib63)].
    Compared with the traditional methods based on manual extraction features, the
    system has the advantages of self-learning features and direct image input and
    can realize the dual functions of positioning and recognition of the vehicle logo.
    In the case of complex backgrounds, a vehicle logo usually occupies only a small
    part of the image. Therefore, it is challenging to identify vehicle logos in real-world
    scenarios accurately. To solve this issue, Yang *et al*. [[72](#bib.bib72)] proposed
    a data-driven enhanced training method based on YOLOv3 [[64](#bib.bib64)]. They
    combined a feature extraction network with a multi-scale decision scheme to improve
    the detection accuracy of vehicle logos. However, the detection results of vehicle
    logos in complex scenes are unsatisfactory. Based on [[72](#bib.bib72)], Zhang
    *et al*. [[73](#bib.bib73)] analyzed the characteristics of vehicle identification
    in static images and found that both the network for feature extraction and the
    training strategy for detection has a significant impact on the accuracy of vehicle
    identification. They proposed a lightweight network structure with separable convolutions
    to replace traditional methods to improve detection accuracy and speed under the
    YOLO-based framework. Experiments show that this method improves the real-time
    performance of vehicle logo detection and also improves the detection accuracy
    of small-scale objects while maintaining the speed to a certain extent.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: YOLOs 被广泛应用于车辆标志检测。鉴于实时性和高效性是车辆标志检测中的关键问题。受到深度学习在特征提取方面的优越性的启发，Yin *et al*.
    [[71](#bib.bib71)] 提出了基于 YOLOv2 [[63](#bib.bib63)] 的高效车辆标志检测系统。与基于手动提取特征的传统方法相比，该系统具有自学习特征和直接图像输入的优势，并能实现车辆标志的定位和识别双重功能。在复杂背景下，车辆标志通常只占图像的一小部分。因此，在现实场景中准确识别车辆标志具有挑战性。为了解决这个问题，Yang
    *et al*. [[72](#bib.bib72)] 提出了基于 YOLOv3 [[64](#bib.bib64)] 的数据驱动增强训练方法。他们结合了特征提取网络和多尺度决策方案，以提高车辆标志的检测准确性。然而，在复杂场景中的车辆标志检测结果并不令人满意。基于[[72](#bib.bib72)]，Zhang
    *et al*. [[73](#bib.bib73)] 分析了静态图像中车辆识别的特征，发现特征提取网络和检测训练策略对车辆识别的准确性有显著影响。他们提出了一种具有可分离卷积的轻量级网络结构，以替代传统方法，在基于
    YOLO 的框架下提高检测准确性和速度。实验表明，该方法提高了车辆标志检测的实时性，并在保持速度的同时提高了小尺度物体的检测准确性。
- en: In various fields, the frequency of different logos usually varies widely. Therefore,
    the number of different logo classes is often unbalanced, making it difficult
    for models to detect logo classes with small samples correctly. Wang *et al*. [[17](#bib.bib17)]
    proposed a robust baseline method Logo-Yolo based on YOLOv3 [[64](#bib.bib64)].
    They first adopt the K-means clustering algorithm to select the number of candidate
    anchor boxes and aspect ratio dimensions. They then used Focal loss to address
    the imbalance of samples in the dataset. Lastly, they introduced CIoU loss to
    improve bounding box regression results. Compared with YOLOv3 [[64](#bib.bib64)],
    the performance of this method is significantly improved in predicting small objects
    and objects in complex backgrounds. However, in some specific cases, the method
    also shows poor performance, such as detecting similar or occluded logos.
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在各个领域，不同标志的出现频率通常差异很大。因此，不同标志类别的数量通常不平衡，使得模型难以正确检测样本较少的标志类别。Wang *et al*. [[17](#bib.bib17)]
    提出了基于 YOLOv3 [[64](#bib.bib64)] 的鲁棒基线方法 Logo-Yolo。他们首先采用 K-means 聚类算法来选择候选锚框的数量和长宽比维度。然后使用
    Focal loss 解决数据集中的样本不平衡问题。最后，他们引入了 CIoU loss 来改善边界框回归结果。与 YOLOv3 [[64](#bib.bib64)]
    相比，该方法在预测小物体和复杂背景中的物体时性能显著提升。然而，在一些特定情况下，该方法也表现出较差的性能，例如检测类似或被遮挡的标志。
- en: '![Refer to caption](img/fa30695275ab8dfdd5bf29f7235848fa.png)'
  id: totrans-99
  prefs: []
  type: TYPE_IMG
  zh: '![参考说明](img/fa30695275ab8dfdd5bf29f7235848fa.png)'
- en: 'Figure 6: The architecture of MFDNet [[16](#bib.bib16)].'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 图6：MFDNet的架构[[16](#bib.bib16)]。
- en: III-B3 Single Shot Detector-based models (SSDs)
  id: totrans-101
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B3 基于单次检测器的模型（SSDs）
- en: Single Shot MultiBox Detector (SSD) [[74](#bib.bib74)] is another single-stage
    detector using a single deep neural network. SSD uses multi-scale feature maps
    to detect objects at different scales, with the bottom layer predicting small
    objects and the top layer predicting large objects. While ensuring the detection
    speed, the detection accuracy of SSD outperforms a comparable state-of-the-art
    Faster R-CNN model. Therefore, SSDs are also widely used in vehicle logo detection [[58](#bib.bib58)].
    Previous works usually detect vehicle logos at the same scale without considering
    the multi-scale variation of vehicle logos. However, the vehicle logos captured
    by the camera are of various sizes. It is essential to design an algorithm with
    multi-scale vehicle logo detection ability. To this end, Zhang *et al*. [[25](#bib.bib25)]
    proposed a multi-scale vehicle logo detection (SVLD) based on SSD [[74](#bib.bib74)]
    to assist in the recognition of vehicles by modifying the pretraining strategy,
    adding a feature extraction layer, and controlling the ratio of positive and negative
    samples. According to the characteristics of the vehicle, a preset frame and parameter
    settings are designed to effectively reduce redundant calculations and accelerate
    the convergence of the model quickly. Compared with SSD, the detection accuracy
    of SVLD is improved, but the time complexity is slightly increased due to the
    addition of the feature extraction layer. In addition, although SSDs have competitive
    accuracy compared to other single-stage methods, they are still insufficient in
    detecting small objects.
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 单阶段多框检测器（SSD）[[74](#bib.bib74)]是另一种使用单一深度神经网络的单阶段检测器。SSD利用多尺度特征图来检测不同尺度的物体，底层预测小物体，而顶层预测大物体。在确保检测速度的同时，SSD的检测精度优于同类先进的Faster
    R-CNN模型。因此，SSD也广泛应用于车辆标志检测[[58](#bib.bib58)]。以前的工作通常在相同尺度下检测车辆标志，而未考虑车辆标志的多尺度变化。然而，相机捕获的车辆标志具有各种尺寸。设计一个具有多尺度车辆标志检测能力的算法至关重要。为此，Zhang
    *等人* [[25](#bib.bib25)] 提出了基于SSD的多尺度车辆标志检测（SVLD）[[74](#bib.bib74)]，通过修改预训练策略、添加特征提取层以及控制正负样本比例来辅助车辆识别。根据车辆的特点，设计了一个预设框架和参数设置，以有效减少冗余计算并加速模型的快速收敛。与SSD相比，SVLD的检测精度有所提高，但由于添加了特征提取层，时间复杂度略有增加。此外，尽管SSD与其他单阶段方法相比具有竞争力的准确性，但在检测小物体方面仍然存在不足。
- en: III-B4 Feature Pyramid Network-based models (FPNs)
  id: totrans-103
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B4 基于特征金字塔网络的模型（FPNs）
- en: Lin *et al*. proposed Feature Pyramid Networks (FPN) [[75](#bib.bib75)] in 2017,
    which mainly solves the multi-scale problem in object detection by changing the
    connectivity of the network. FPN dramatically improves the performance of small
    object detection without increasing the amount of calculation. In recent years,
    many works have adopted FPN to solve problems of logo detection, like multi-scale
    and small objects [[76](#bib.bib76), [28](#bib.bib28), [77](#bib.bib77), [16](#bib.bib16)]
    and these FPNs have achieved exciting results.
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: Lin *等人* 于2017年提出了特征金字塔网络（FPN）[[75](#bib.bib75)]，该方法主要通过改变网络的连接方式来解决目标检测中的多尺度问题。FPN显著提高了小物体检测的性能，而无需增加计算量。近年来，许多研究采用FPN来解决标志检测中的问题，如多尺度和小物体[[76](#bib.bib76),
    [28](#bib.bib28), [77](#bib.bib77), [16](#bib.bib16)]，这些FPN取得了令人兴奋的成果。
- en: 'Aiming at the problems of multi-scale and other geometric variations of logos,
    Meng *et al*. [[76](#bib.bib76)] proposed obtaining sufficient features for logo
    (OSF-Logo) based on FPN. Specifically, they introduced the Regulated Deformable
    Convolution (RDC) module in a specific layer of FPN, which allows the sampling
    point positions of the convolution kernel at different positions to adaptively
    change according to the content, thereby adapting to the geometric changes of
    the logo. Meanwhile, they adopt an up-sampling operator in FPN to generate an
    adaptive kernel that fully aggregates rich semantic information. Therefore, OSF-Logo
    can quickly perceive a wide range of content and effectively detect multi-scale
    logos. Similarly, Jin *et al*. [[28](#bib.bib28)] designed a network called “Brand
    Net”. Brand Net uses FPN to extract multi-scale features. On this basis, it introduces
    an anchor refinement network in FPN to remove negative anchors, thus greatly reducing
    the number of anchor boxes. Therefore, it can effectively detect logos with different
    scales and significantly improve the detection performance of small logos. Detection
    Transformers (DETR) [[78](#bib.bib78)] has problems detecting small objects, so
    it cannot be directly used for multi-scale logo detection. To solve this issue,
    Velazquez *et al*. [[77](#bib.bib77)] incorporated Feature Pyramid (FP) into DETR
    architecture. They firstly split the penultimate layer of the feature pyramid
    into four patches of the same size as the smallest feature map in the pyramid.
    They then fed these patches into the DETR pipeline for prediction. This method
    effectively detects small objects. However, the backward propagation computation
    of this method increases memory consumption. Recently, Hou *et al*. [[16](#bib.bib16)]
    proposed a multi-scale feature decoupling network (MFDNet) for logo detection
    to solve the problem of distinguishing multiple logo categories. MMFDNet comprises
    two components: Balanced Feature Pyramid (BFP) and Feature Offset Module (FOM).
    The former is designed to fuse multi-scale features using the same deep feature
    map to integrate balanced semantic features. At the same time, the latter comprises
    an automatically learned anchor region proposal network for pixel-level offsets
    to search for the best features for logos. The architecture of MFDNet is shown
    in Fig. 6.'
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 针对标志的多尺度和其他几何变化问题，孟*等人* [[76](#bib.bib76)] 提出了基于 FPN 获得足够特征的标志 (OSF-Logo)。具体来说，他们在
    FPN 的特定层中引入了调节型可变形卷积 (RDC) 模块，该模块允许卷积核在不同位置的采样点位置根据内容自适应变化，从而适应标志的几何变化。同时，他们在
    FPN 中采用了上采样操作符生成一个自适应内核，充分聚合丰富的语义信息。因此，OSF-Logo 可以快速感知广泛的内容，并有效检测多尺度标志。类似地，金*等人*
    [[28](#bib.bib28)] 设计了一个叫做“Brand Net”的网络。Brand Net 使用 FPN 提取多尺度特征。在此基础上，它在 FPN
    中引入了一个锚点细化网络，以去除负锚点，从而大大减少了锚框的数量。因此，它可以有效检测不同尺度的标志，并显著提高小型标志的检测性能。检测变换器 (DETR)
    [[78](#bib.bib78)] 存在检测小物体的问题，因此不能直接用于多尺度标志检测。为了解决这个问题，Velazquez*等人* [[77](#bib.bib77)]
    将特征金字塔 (FP) 融入了 DETR 架构。他们首先将特征金字塔的倒数第二层拆分为四个与金字塔中最小特征图大小相同的补丁。然后将这些补丁输入 DETR
    流水线进行预测。该方法有效地检测小物体。然而，该方法的反向传播计算增加了内存消耗。最近，侯*等人* [[16](#bib.bib16)] 提出了一个用于标志检测的多尺度特征解耦网络
    (MFDNet)，以解决区分多种标志类别的问题。MMFDNet 包含两个组件：平衡特征金字塔 (BFP) 和特征偏移模块 (FOM)。前者旨在使用相同的深度特征图融合多尺度特征，以集成平衡的语义特征。同时，后者包括一个自动学习的锚区域提议网络，用于像素级偏移以搜索标志的最佳特征。MFDNet
    的架构如图 6 所示。
- en: 'TABLE II: Summary of representative deep learning-based logo detection methods.'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '表 II: 代表性的深度学习基础的标志检测方法总结。'
- en: '| Method type | Method | Pipeline | Task | Strategy | Loss function | Year
    |'
  id: totrans-107
  prefs: []
  type: TYPE_TB
  zh: '| 方法类型 | 方法 | 流水线 | 任务 | 策略 | 损失函数 | 年份 |'
- en: '| RCNNs | DeepLogo-DRCN [[14](#bib.bib14)] |'
  id: totrans-108
  prefs: []
  type: TYPE_TB
  zh: '| RCNNs | DeepLogo-DRCN [[14](#bib.bib14)] |'
- en: '&#124; RCNN &#124;'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; RCNN &#124;'
- en: '&#124; Fast RCNN &#124;'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Fast RCNN &#124;'
- en: '&#124; SPPnet &#124;'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; SPPnet &#124;'
- en: '| Regular logo detection | - | - | 2015 |'
  id: totrans-112
  prefs: []
  type: TYPE_TB
  zh: '| 常规标志检测 | - | - | 2015 |'
- en: '| BD-FRCN [[60](#bib.bib60)] | Fast RCNN | Regular logo detection | Transfer
    learning | - | 2016 |'
  id: totrans-113
  prefs: []
  type: TYPE_TB
  zh: '| BD-FRCN [[60](#bib.bib60)] | Fast RCNN | 常规标志检测 | 转移学习 | - | 2016 |'
- en: '| Improved Faster RCNN [[57](#bib.bib57)] | Faster RCNN | Small logo detection
    | Preset anchor boxes | - | 2017 |'
  id: totrans-114
  prefs: []
  type: TYPE_TB
  zh: '| 改进的 Faster RCNN [[57](#bib.bib57)] | Faster RCNN | 小型标志检测 | 预设锚框 | - | 2017
    |'
- en: '|'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Deep Region-based &#124;'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 深度区域基础 &#124;'
- en: '&#124; Convolutional Networks [[61](#bib.bib61)] &#124;'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 卷积网络 [[61](#bib.bib61)] &#124;'
- en: '| Faster RCNN | Regular logo detection |'
  id: totrans-118
  prefs: []
  type: TYPE_TB
- en: '&#124; Transfer learning &#124;'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  id: totrans-121
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  id: totrans-122
  prefs: []
  type: TYPE_TB
- en: '| Video logo detector [[22](#bib.bib22)] | Fast RCNN | Video logo detection
    |'
  id: totrans-123
  prefs: []
  type: TYPE_TB
- en: '&#124; Homogeneity enhancement &#124;'
  id: totrans-124
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Mutual enhancement &#124;'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  id: totrans-126
  prefs: []
  type: TYPE_TB
- en: '| Faster RCNN+ResNet-50 [[5](#bib.bib5)] | Faster RCNN |'
  id: totrans-127
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Category balance &#124;'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; EQLv2 &#124;'
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Seesaw Loss &#124;'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: '| 2021 |'
  id: totrans-136
  prefs: []
  type: TYPE_TB
- en: '| Cascade detectoRS [[6](#bib.bib6)] | Cascade RCNN |'
  id: totrans-137
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Multi-scale training &#124;'
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
- en: '|'
  id: totrans-144
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Cascade RCNN+ &#124;'
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Res2Net101 [[7](#bib.bib7)] &#124;'
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: '| Cascade RCNN | Long tail logo detection |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
- en: '&#124; Data augmentation &#124;'
  id: totrans-148
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Gradient balance &#124;'
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data Sampling &#124;'
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
- en: '| Green Hand [[8](#bib.bib8)] | DetectoRS |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
- en: '&#124; Long tail logo detection &#124;'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Small logo detection &#124;'
  id: totrans-154
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-155
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Data augmentation &#124;'
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Resampling &#124;'
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Weighted boxes &#124;'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '| EQLv2 |'
  id: totrans-159
  prefs: []
  type: TYPE_TB
- en: '| YOLOs | Improved YOLOv3 [[72](#bib.bib72)] | YOLOv3 | Small logo detection
    | Hard example re-training | - | 2019 |'
  id: totrans-160
  prefs: []
  type: TYPE_TB
- en: '| Scene recognition CNN [[24](#bib.bib24)] | YOLOv3 | Regular logo detection
    | - | - | 2020 |'
  id: totrans-161
  prefs: []
  type: TYPE_TB
- en: '| Improved YOLOv2 [[71](#bib.bib71)] | YOLOv2 | Regular logo detection |'
  id: totrans-162
  prefs: []
  type: TYPE_TB
- en: '&#124; Separable convolution &#124;'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Multi-scale features fusion &#124;'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-165
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Confidence error loss &#124;'
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Coordinate error loss &#124;'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Prediction box loss &#124;'
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
- en: '| Improved YOLOv2 [[79](#bib.bib79)] | YOLOv2 | Multi-scale logo detection
    |'
  id: totrans-170
  prefs: []
  type: TYPE_TB
- en: '&#124; Preset anchor boxes &#124;'
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '| - |'
  id: totrans-173
  prefs: []
  type: TYPE_TB
- en: '| Logo-Yolo [[17](#bib.bib17)] | YOLOv3 | Regular logo detection |'
  id: totrans-174
  prefs: []
  type: TYPE_TB
- en: '&#124; Improved losses &#124;'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; K-means clustering &#124;'
  id: totrans-176
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Focal loss &#124;'
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; CIoU loss &#124;'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: '| Scaled YOLOv4 [[80](#bib.bib80)] | YOLOv4 | Regular logo detection | - |
    - | 2021 |'
  id: totrans-181
  prefs: []
  type: TYPE_TB
- en: '| Separable-VLD [[73](#bib.bib73)] | YOLO | Small logo detection | Separable
    convolution | - |'
  id: totrans-182
  prefs: []
  type: TYPE_TB
- en: '| SSDs | SVLD [[25](#bib.bib25)] | SSD | Multi-scale logo detection | Preset
    anchor boxes | - | 2019 |'
  id: totrans-183
  prefs: []
  type: TYPE_TB
- en: '| SSD InceptionV2 [[58](#bib.bib58)] | SSD | Regular logo detection | Preset
    anchor boxes | - |'
  id: totrans-184
  prefs: []
  type: TYPE_TB
- en: '| FPNs | Brand Net [[28](#bib.bib28)] | - | Small logo detection |'
  id: totrans-185
  prefs: []
  type: TYPE_TB
- en: '&#124; Soft mask attention &#124;'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Weight transfer &#124;'
  id: totrans-187
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Anchor refinement &#124;'
  id: totrans-188
  prefs: []
  type: TYPE_NORMAL
- en: '|'
  id: totrans-189
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Class-aware smooth L1 &#124;'
  id: totrans-190
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Class-agnostic smooth L1 &#124;'
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Cross-entropy loss &#124;'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '| 2020 |'
  id: totrans-193
  prefs: []
  type: TYPE_TB
- en: '|  | OSF-Logo [[76](#bib.bib76)] | - | Multi-scale logo detection |'
  id: totrans-194
  prefs: []
  type: TYPE_TB
- en: '&#124; Deformable convolution &#124;'
  id: totrans-195
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Up-sampling operator &#124;'
  id: totrans-196
  prefs: []
  type: TYPE_NORMAL
- en: '| - | 2021 |'
  id: totrans-197
  prefs: []
  type: TYPE_TB
- en: '|  | MFDNet [[16](#bib.bib16)] | - | Multi-scale logo detection |'
  id: totrans-198
  prefs: []
  type: TYPE_TB
- en: '&#124; Multi-scale feature fusion &#124;'
  id: totrans-199
  prefs: []
  type: TYPE_NORMAL
- en: '&#124; Deformable learning &#124;'
  id: totrans-200
  prefs: []
  type: TYPE_NORMAL
- en: '| Cross-entropy loss |'
  id: totrans-201
  prefs: []
  type: TYPE_TB
- en: '|  | DETR-FP [[77](#bib.bib77)] | DETR | Small logo detection | Model fusion
    |'
  id: totrans-202
  prefs: []
  type: TYPE_TB
  zh: '|  | DETR-FP [[77](#bib.bib77)] | DETR | 小标志检测 | 模型融合 |'
- en: '&#124; Hungarian loss &#124;'
  id: totrans-203
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 匈牙利损失 &#124;'
- en: '&#124; Generalized IoU loss &#124;'
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 广义 IoU 损失 &#124;'
- en: '|'
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '| Others | SLST [[29](#bib.bib29)] | Faster RCNN | Weakly supervised logo detection
    |'
  id: totrans-206
  prefs: []
  type: TYPE_TB
  zh: '| 其他 | SLST [[29](#bib.bib29)] | Faster RCNN | 弱监督标志检测 |'
- en: '&#124; Incremental learning &#124;'
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 增量学习 &#124;'
- en: '&#124; Self-Training &#124;'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 自训练 &#124;'
- en: '| - | 2017 |'
  id: totrans-209
  prefs: []
  type: TYPE_TB
  zh: '| - | 2017 |'
- en: '| SCL [[21](#bib.bib21)] | Faster RCNN | Few shot logo detection | Synthetic
    context logo | - |'
  id: totrans-210
  prefs: []
  type: TYPE_TB
  zh: '| SCL [[21](#bib.bib21)] | Faster RCNN | 少量样本标志检测 | 合成上下文标志 | - |'
- en: '| CAL [[15](#bib.bib15)] |'
  id: totrans-211
  prefs: []
  type: TYPE_TB
  zh: '| CAL [[15](#bib.bib15)] |'
- en: '&#124; Faster RCNN &#124;'
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Faster RCNN &#124;'
- en: '&#124; YOLOv2 &#124;'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; YOLOv2 &#124;'
- en: '| Weakly supervised logo detection | Context adversarial learning |'
  id: totrans-214
  prefs: []
  type: TYPE_TB
  zh: '| 弱监督标志检测 | 上下文对抗学习 |'
- en: '&#124; Softmax cross-entropy loss &#124;'
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; Softmax 交叉熵损失 &#124;'
- en: '&#124; Conditional adversarial loss &#124;'
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 条件对抗损失 &#124;'
- en: '| 2018 |'
  id: totrans-217
  prefs: []
  type: TYPE_TB
  zh: '| 2018 |'
- en: '|'
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Weakly supervised &#124;'
  id: totrans-219
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 弱监督 &#124;'
- en: '&#124; learning of CNN [[81](#bib.bib81)] &#124;'
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; CNN 的学习 [[81](#bib.bib81)] &#124;'
- en: '| DCNN | Weakly supervised logo detection |'
  id: totrans-221
  prefs: []
  type: TYPE_TB
  zh: '| DCNN | 弱监督标志检测 |'
- en: '&#124; Generate saliency map &#124;'
  id: totrans-222
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 生成显著性图 &#124;'
- en: '&#124; GrabCut segmentation &#124;'
  id: totrans-223
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; GrabCut 分割 &#124;'
- en: '| Softmax loss | 2021 |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
  zh: '| Softmax 损失 | 2021 |'
- en: '|'
  id: totrans-225
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Airline logo &#124;'
  id: totrans-226
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 航空公司标志 &#124;'
- en: '&#124; detection system [[82](#bib.bib82)] &#124;'
  id: totrans-227
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 检测系统 [[82](#bib.bib82)] &#124;'
- en: '| AttentionMask | Complex scenes logo detection | Data augmentation | Cross-entropy
    loss |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
  zh: '| AttentionMask | 复杂场景标志检测 | 数据增强 | 交叉熵损失 |'
- en: '| LogoNet [[83](#bib.bib83)] | - | Complex scenes logo detection | Spatial
    attention | - |'
  id: totrans-229
  prefs: []
  type: TYPE_TB
  zh: '| LogoNet [[83](#bib.bib83)] | - | 复杂场景标志检测 | 空间注意力 | - |'
- en: '| Deep attention networks [[84](#bib.bib84)] | - | Regular logo detection |'
  id: totrans-230
  prefs: []
  type: TYPE_TB
  zh: '| 深度注意力网络 [[84](#bib.bib84)] | - | 常规标志检测 |'
- en: '&#124; Domain adaptation &#124;'
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 领域适应 &#124;'
- en: '&#124; Nonlocal block &#124;'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 非局部块 &#124;'
- en: '| - |'
  id: totrans-233
  prefs: []
  type: TYPE_TB
  zh: '| - |'
- en: '| MPCC [[85](#bib.bib85)] | Faster RCNN | Few shot logo detection |'
  id: totrans-234
  prefs: []
  type: TYPE_TB
  zh: '| MPCC [[85](#bib.bib85)] | Faster RCNN | 少量样本标志检测 |'
- en: '&#124; Domain adaptation &#124;'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 领域适应 &#124;'
- en: '&#124; Data augmentation &#124;'
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 数据增强 &#124;'
- en: '| Softmax cross-entropy loss |'
  id: totrans-237
  prefs: []
  type: TYPE_TB
  zh: '| Softmax 交叉熵损失 |'
- en: '| DTAL [[86](#bib.bib86)] | DCNN |'
  id: totrans-238
  prefs: []
  type: TYPE_TB
  zh: '| DTAL [[86](#bib.bib86)] | DCNN |'
- en: '&#124; Video logo detection &#124;'
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 视频标志检测 &#124;'
- en: '&#124; Few shot logo detection &#124;'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 少量样本标志检测 &#124;'
- en: '|'
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
  zh: '|'
- en: '&#124; Active learning &#124;'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 主动学习 &#124;'
- en: '&#124; Transfer learning &#124;'
  id: totrans-243
  prefs: []
  type: TYPE_NORMAL
  zh: '&#124; 迁移学习 &#124;'
- en: '| Meta-class loss | 2022 |'
  id: totrans-244
  prefs: []
  type: TYPE_TB
  zh: '| 元类别损失 | 2022 |'
- en: III-B5 Other models
  id: totrans-245
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: III-B5 其他模型
- en: Some other models used in logo detection are introduced in this section.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
  zh: 本节介绍了一些用于标志检测的其他模型。
- en: 'In order to solve the problem of limited logo data, Su *et al*. [[15](#bib.bib15)]
    proposed a data augmentation strategy focusing on logo context optimization: Contextual
    Adversarial Learning (CAL). CAL takes an image with a logo object as input and
    generates context-consistent synthetic images that can be used as additional training
    data. However, the distribution of this synthetic image is different from the
    actual test image. To solve this issue, the same authors proposed a Multi-Perspective
    Cross-Class (MPCC) domain adaptation method [[85](#bib.bib85)] based on the baseline
    method CAL [[15](#bib.bib15)]. MPCC conducts feature distribution alignment in
    the data augmentation principle from two perspectives. One is to align the feature
    distribution between the synthetic logo image of 1-shot icon supervised classes
    and the authentic logo image of the fully supervised class. The other is to align
    the feature distribution between the logo and non-logo images. This mitigates
    the domain shift problem between model training and testing on 1-shot icon supervised
    logo classes and reduces the model’s overfitting to the fully labeled logo classes.
    The final combination of MPCC with Faster R-CNN achieved good results.'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
  zh: 为了解决标志数据有限的问题，苏*等人* [[15](#bib.bib15)] 提出了一个关注于标志上下文优化的数据增强策略：上下文对抗学习（CAL）。CAL
    以包含标志对象的图像作为输入，生成上下文一致的合成图像，这些图像可以作为额外的训练数据。然而，这些合成图像的分布与实际测试图像不同。为了解决这一问题，同一作者提出了基于基础方法
    CAL [[15](#bib.bib15)] 的多视角跨类别（MPCC）领域适应方法 [[85](#bib.bib85)]。MPCC 从两个角度进行特征分布对齐：一是对齐
    1-shot 图标监督类别的合成标志图像和完全监督类别的真实标志图像之间的特征分布；另一是对齐标志图像和非标志图像之间的特征分布。这缓解了 1-shot 图标监督标志类别的模型训练和测试之间的领域偏移问题，减少了模型对完全标注标志类别的过拟合。最终，将
    MPCC 与 Faster R-CNN 结合取得了良好的结果。
- en: Training a logo detector usually requires a large amount of labeled data, and
    labeling logo data is time-consuming. Therefore, weakly supervised learning is
    a vital strategy to solve this issue. Kumar *et al*. [[81](#bib.bib81)] proposed
    a method for logo detection by using weakly supervised learning of CNN to generate
    a deep saliency map, which is generated by a single back-propagation of a trained
    Deep CNN. The authors also used an interactive Grabcut algorithm to calculate
    the salient segmented regions of the image. However, this method is not sufficiently
    modeled to detect multiple brand logos in the same image.
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
  zh: 训练徽标检测器通常需要大量标记数据，而标记徽标数据是耗时的。因此，弱监督学习是解决这一问题的重要策略。Kumar *等*[[81](#bib.bib81)]提出了一种通过弱监督学习
    CNN 生成深度显著性图的方法，该图通过训练好的深度 CNN 的单次反向传播生成。作者还使用了交互式 Grabcut 算法来计算图像的显著分割区域。然而，该方法对于检测同一图像中的多个品牌徽标建模不够充分。
- en: Logo detectors usually perform poorly in classes with a small number of samples.
    To this end, Yohannes *et al*. [[84](#bib.bib84)] designed a framework consisting
    of a domain adaptation that reduces the loss function between source-target datasets
    and also represents important source features adopted by the target dataset. The
    authors add nonlocal blocks and attention mechanisms to achieve a decent performance
    of logo detection. Similarly, Su *et al*. [[86](#bib.bib86)] developed a deep
    transfer active learning algorithm named DTAL to select the most valuable samples
    such that we can label the smallest number of samples to achieve maximum performance
    improvements in training detection models.
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
  zh: 徽标检测器通常在样本数量较少的类别中表现较差。为此，Yohannes *等*[[84](#bib.bib84)]设计了一个框架，其中包括领域自适应，以减少源数据集和目标数据集之间的损失函数，并表示目标数据集采用的重要源特征。作者添加了非局部块和注意力机制，以实现较好的徽标检测性能。同样，Su
    *等*[[86](#bib.bib86)]开发了一种名为 DTAL 的深度迁移主动学习算法，用于选择最有价值的样本，以便标记最少的样本从而在训练检测模型中实现最大性能提升。
- en: When the image is affected by unfavorable factors such as illumination, rotation,
    occlusion, etc., the performance of the detector will be significantly reduced.
    In recent years, the attention mechanisms have attracted increasing attention
    to solving this issue in logo detection [[82](#bib.bib82), [83](#bib.bib83)].
    For example, Wilms *et al*. [[82](#bib.bib82)] took the airline logos as an example
    and proposed a logo detection system under adverse conditions. The authors adopt
    the object proposal generation system AttentionMask [[87](#bib.bib87)]. Since
    the aviation system logo is relatively large, the AttentionMask system removes
    the scale of small objects to improve execution efficiency and reduce false positives.
    They also used a data augmentation solution to simulate the effects of severe
    weather to diversify the training data processing effects. The experimental results
    show that the proposed strategy can achieve good performance in detecting the
    logo in complex real-world environments. However, the data obtained under real-world
    conditions are not as ideal as the data generated by data augmentation, so the
    performance of the model in detecting images in real-world conditions will be
    degraded. Considering that locating logos in complex scenarios is challenging
    due to the large variety of types and appearance of logos, Jain *et al*. [[83](#bib.bib83)]
    proposed a logo detection framework called LogoNet, which includes a spatial attention
    module. LogoNet can capture rich spatial information and focus more precisely
    on the logo object within an image. LogoNet achieves a significant performance
    gain within considerable computation time.
  id: totrans-250
  prefs: []
  type: TYPE_NORMAL
  zh: 当图像受到照明、旋转、遮挡等不利因素影响时，探测器的性能会显著下降。近年来，注意力机制在解决这一问题的徽标检测中受到了越来越多的关注[[82](#bib.bib82),
    [83](#bib.bib83)]。例如，Wilms *等*[[82](#bib.bib82)]以航空公司徽标为例，提出了一种在不利条件下的徽标检测系统。作者采用了对象提议生成系统
    AttentionMask[[87](#bib.bib87)]。由于航空系统徽标相对较大，AttentionMask 系统去除了小物体的尺度，以提高执行效率并减少假阳性。他们还使用了数据增强解决方案，以模拟恶劣天气的影响，从而多样化训练数据处理效果。实验结果表明，所提出的策略在复杂的真实环境中检测徽标时可以实现良好的性能。然而，在现实条件下获得的数据不如数据增强生成的数据理想，因此模型在真实条件下检测图像的性能会下降。考虑到在复杂场景中定位徽标由于徽标类型和外观的多样性而具有挑战性，Jain
    *等*[[83](#bib.bib83)]提出了一种名为 LogoNet 的徽标检测框架，其中包括一个空间注意力模块。LogoNet 可以捕捉丰富的空间信息，更精确地关注图像中的徽标对象。LogoNet
    在相当的计算时间内实现了显著的性能提升。
- en: In order to analyze current state-of-the-art deep learning-based methods more
    comprehensively, the representative models are presented in chronological order
    in Table II, and the experimental results of these models on three popular benchmark
    datasets, namely Flickrlogos-32, QMUL-OpenLogo, and Open Brands, are listed in
    Table III, Table IV, and Table V respectively.
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
  zh: 为了更全面地分析当前最先进的深度学习方法，表 II 中按时间顺序展示了代表性模型，并且这些模型在三个流行基准数据集上的实验结果分别列在表 III、表 IV
    和表 V 中。
- en: IV Applications
  id: totrans-252
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: IV 应用
- en: Logo detection is widely used in various applications, such as intellectual
    property protection, autonomous driving, and product branding. In this section,
    we describe the representative applications of logo detection in detail.
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
  zh: 标志检测广泛应用于各种场景，如知识产权保护、自动驾驶和产品品牌化。在本节中，我们详细描述了标志检测的代表性应用。
- en: IV-A Brand Monitoring
  id: totrans-254
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: IV-A 品牌监测
- en: The most obvious use case for logo detection is brand monitoring, which includes
    brand protection, brand recommendation, and brand identification. Logo plays an
    essential role in business marketing as a unique brand identity. However, there
    are many types of brands in real life, and there may be subtle logo differences
    between the two products. Inter-class similarities and intra-class differences
    will greatly increase the difficulty of detection. In addition, images may have
    highly diverse context, illumination, projection transformation, and resolution.
    Therefore, how efficiently detecting brands in images is a challenging task. Currently,
    there is a lot of work on brand identity [[60](#bib.bib60), [58](#bib.bib58),
    [28](#bib.bib28), [3](#bib.bib3)]. For brand logos, the image usually includes
    some textual description. Textual information is an important source of information
    for brand identity. Hu *et al*. [[3](#bib.bib3)] proposed a multimodal fusion
    framework for logo detection. The framework combines image-based logo recognition
    with contextual features for logo detection using a natural language model. Additional
    contextual information can alleviate the limitations of detection. The performance
    of this model for logo detection has been improved, but there are still shortcomings
    in positioning.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
  zh: 最明显的标志检测应用场景是品牌监测，包括品牌保护、品牌推荐和品牌识别。标志在商业营销中扮演着重要角色，作为独特的品牌身份。然而，现实生活中品牌类型繁多，不同产品之间可能存在细微的标志差异。类别间的相似性和类别内的差异会大大增加检测的难度。此外，图像可能具有高度多样的背景、光照、投影变换和分辨率。因此，高效检测图像中的品牌是一项具有挑战性的任务。目前，品牌身份的研究已有很多工作[[60](#bib.bib60),
    [58](#bib.bib58), [28](#bib.bib28), [3](#bib.bib3)]。对于品牌标志，图像通常包含一些文本描述。文本信息是品牌身份的重要信息来源。胡*等*[[3](#bib.bib3)]提出了一种用于标志检测的多模态融合框架。该框架结合了基于图像的标志识别与自然语言模型中的上下文特征，以进行标志检测。额外的上下文信息可以缓解检测的限制。该模型在标志检测中的表现得到了改善，但在定位方面仍存在不足。
- en: 'TABLE III: Performance comparison of logo detectors on the FlickrLogos-32 benchmark.'
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
  zh: 表 III：FlickrLogos-32 基准上标志检测器的性能比较。
- en: Method mAP(%) Year FRCN  [[46](#bib.bib46)] 74.4 2015 BD-FRCN-M [[60](#bib.bib60)]
    73.5 2016 Video Logo Detector [[22](#bib.bib22)] 78.6 2017 Faster RCNN+VGG16_D2_M3 [[61](#bib.bib61)]
    90.3 2017 Faster RCNN+CAL [[15](#bib.bib15)] 74.9 2018 Deep Saliency Map [[81](#bib.bib81)]
    75.8 2020 Logo-Yolo [[17](#bib.bib17)] 76.1 2020 LogoNet [[83](#bib.bib83)] 82.2
    2021 OSF-Logo [[76](#bib.bib76)] 87.0 2021 RetinaNet [[59](#bib.bib59)] 40.0 2021
    RCNN [[59](#bib.bib59)] 65.0 2021 Faster RCNN [[59](#bib.bib59)] 74.0 2021 Scaled
    YOLOv4 [[80](#bib.bib80)] 80.4 2021 MFDNet [[16](#bib.bib16)] 86.2 2021
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
  zh: 方法 mAP(%) 年份 FRCN  [[46](#bib.bib46)] 74.4 2015 BD-FRCN-M [[60](#bib.bib60)]
    73.5 2016 视频标志检测器 [[22](#bib.bib22)] 78.6 2017 Faster RCNN+VGG16_D2_M3 [[61](#bib.bib61)]
    90.3 2017 Faster RCNN+CAL [[15](#bib.bib15)] 74.9 2018 深度显著图 [[81](#bib.bib81)]
    75.8 2020 Logo-Yolo [[17](#bib.bib17)] 76.1 2020 LogoNet [[83](#bib.bib83)] 82.2
    2021 OSF-Logo [[76](#bib.bib76)] 87.0 2021 RetinaNet [[59](#bib.bib59)] 40.0 2021
    RCNN [[59](#bib.bib59)] 65.0 2021 Faster RCNN [[59](#bib.bib59)] 74.0 2021 Scaled
    YOLOv4 [[80](#bib.bib80)] 80.4 2021 MFDNet [[16](#bib.bib16)] 86.2 2021
- en: 'TABLE IV: Performance comparison of logo detectors on the QMUL-OpenLogo benchmark.'
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
  zh: 表 IV：QMUL-OpenLogo 基准上标志检测器的性能比较。
- en: Method      mAP(%)      Year      YOLOv2+CAL [[15](#bib.bib15)]      49.2      2018
         Faster RCNN+CAL [[15](#bib.bib15)]      51.0      2018      Logo-Yolo [[17](#bib.bib17)]
         53.2      2020      Faster RCNN+CAL+MPCC [[85](#bib.bib85)]      49.4      2021
         OSF-Logo [[76](#bib.bib76)]      53.3      2021      Scaled YOLOv4 [[80](#bib.bib80)]
         61.9      2021      MFDNet [[16](#bib.bib16)]      51.3      2021
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: 'TABLE V: Performance comparison of logo detectors on the Open Brands benchmark.'
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: Method      mAP(%)      Year      Brand Net (SMA) [[28](#bib.bib28)]      60.4
         2020      Faster RCNN+RFS+MST [[5](#bib.bib5)]      64.6      2021      Cascade
    RCNN+Soft NMS [[6](#bib.bib6)]      65.1      2021      Green Hand [[8](#bib.bib8)]
         65.5      2021      Cascade RCNN+DCN v2 [[7](#bib.bib7)]      70.2      2021
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: IV-B Intelligent Transportation
  id: totrans-262
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In intelligent transportation, vehicle logo detection is significantly growing
    as it can effectively assist vehicle management. In addition, due to the increasing
    number of vehicle violations and traffic accidents, the realization of intelligent
    transportation systems is crucial. However, in the real world, the detection of
    vehicle logos is seriously disturbed due to occlusion, illumination, and low image
    resolution. Therefore, an efficient vehicle logo detection system is essential.
    In recent years, methods for vehicle logo detection have been proposed successively [[39](#bib.bib39),
    [34](#bib.bib34), [88](#bib.bib88), [37](#bib.bib37), [38](#bib.bib38), [23](#bib.bib23),
    [72](#bib.bib72), [79](#bib.bib79)]. Lu *et al*. [[48](#bib.bib48)] designed a
    feature extraction module VLF-Net and category-consistent mask learning module
    for vehicle logo detection. Yu *et al*. [[1](#bib.bib1)] proposed a cascaded deep
    convolutional neural network to detect vehicles without relying on the presence
    of license plates. The network is a two-stage framework including two components:
    a region proposal network and a convolutional capsule network. The former is responsible
    for generating region proposals that may contain vehicle logos, while the latter
    is responsible for classifying the proposals into background and vehicle logos.
    Surwase *et al*. [[2](#bib.bib2)] proposed a multi-scale multi-stream deep network
    for vehicle logo detection. The network processes the input image through a multi-scale
    stream to extract robust features, followed by logo recognition. The network follows
    a knowledge sharing strategy, where the learned features are shared on each stream
    of the network.'
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/4f38e36ae6c61d60d851fd2a77eae30b.png)'
  id: totrans-264
  prefs: []
  type: TYPE_IMG
- en: 'Figure 7: The architecture for video logo detection [[22](#bib.bib22)].'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: IV-C Copyright and Trademark Compliance
  id: totrans-266
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'With the development of global e-commerce platforms, the logos of major brands
    have become an important element in the e-commerce market. Some attackers use
    illegal means to infringe on the original author, so protecting intellectual property
    rights has also become a focus. Logo detection plays a vital role in preventing
    the increasing number of counterfeit transaction attempts online [[33](#bib.bib33),
    [89](#bib.bib89), [90](#bib.bib90), [5](#bib.bib5), [6](#bib.bib6), [7](#bib.bib7),
    [8](#bib.bib8)]. Infringement detection of logos has been studied for images and
    videos. Chen *et al*. [[5](#bib.bib5)] built a highly optimized and robust detector
    by using techniques such as data augmentation for the detection of logos (515
    categories) in e-commerce images. Patalappa *et al*. [[4](#bib.bib4)] extended
    the dataset through data augmentation techniques. They applied the SSD algorithm
    to detect broadcast logos in the context of broadcast and broadband content piracy
    and proved the effectiveness of the application of SSD in content piracy video
    analysis monitoring tasks. An efficient way to identify the source of a web video
    is to detect some specified logos. In order to identify the source of illegal
    videos, Ye *et al*. [[91](#bib.bib91)] proposed a logo detection system “GeLoGo”
    to detect logos in Web-scale videos. The system consists of four main modules:
    the keyframe module, the proposal module, the spatial verification module, and
    the temporal verification module. The keyframe module first extracts several frames
    with short fragment detection, which can significantly reduce the data. Secondly,
    the proposal module extracts candidate boxes through a set of pre-trained identity
    detectors. Then, the spatial validation module detects logos through the ResNet
    network. Finally, the temporal verification module detects the detection result
    by detecting the recognition position.'
  id: totrans-267
  prefs: []
  type: TYPE_NORMAL
- en: IV-D Document Categorization
  id: totrans-268
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: A logo often appears in commercial documents and can be used as a statement
    of ownership of the document. Automatic logo detection is growing due to the increasing
    requirements of intelligent document image analysis and retrieval [[92](#bib.bib92),
    [93](#bib.bib93), [94](#bib.bib94)]. Alaei *et al*. [[95](#bib.bib95)] proposed
    a complete system for logo detection in document images. They proposed a template-based
    recognition strategy for under or over-segmentation problems that may arise during
    detection. In order to speed up the matching of templates in the recognition phase,
    a search space reduction strategy that utilizes the geometric properties of logo-patches
    and template logo-models is proposed to reduce the number of template logo-models.
    Zhu *et al*. [[96](#bib.bib96)] proposed a multi-scale method for document image
    logo detection and extraction. The authors used an augmentation strategy across
    multiple image scales to classify and localize logos accurately.
  id: totrans-269
  prefs: []
  type: TYPE_NORMAL
- en: IV-E Other Applications
  id: totrans-270
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Logo detection can offer various benefits for advertisers looking to improve
    their marketing strategies effectively. As shown in Fig. 7, Liao *et al*. [[22](#bib.bib22)]
    proposed a video logo detection framework that used a mutual-enhanced approach
    to improve logo detection through the information obtained from other simultaneously
    occurred logos. Based on the Fast R-CNN model, a uniformity-enhanced reordering
    method is proposed to improve the accuracy of in-frame region suggestions by analyzing
    the features of logos in videos. In addition, they proposed a frame propagation
    enhancement method to assist in the detection of adjacent frames. Finally, the
    effectiveness of the method is demonstrated on the FlickrLogos-32 dataset and
    the video dataset. Recently, food logo detection [[16](#bib.bib16)] has become
    more popular because it has many valuable applications, such as food brand management
    and displaying nutritional information. Logo detection is also used in other areas,
    such as video semantic annotation [[97](#bib.bib97), [40](#bib.bib40), [80](#bib.bib80)],
    and noise recognition [[45](#bib.bib45), [36](#bib.bib36), [98](#bib.bib98), [99](#bib.bib99)].
    Since the TV logo photographed is susceptible to illumination, occlusion, noise,
    and other factors, the TV logo may only take up a small part of each image. To
    this end, Pan *et al*. [[100](#bib.bib100)] proposed an efficient CNN to solve
    this problem. They used the maximum stable extremal region (MSER) algorithm to
    extract candidate frames. Since this algorithm tends to produce a large number
    of candidate frames without TV logos, they designed certain geometric constraints
    to remove non-logo objects. Finally, the images were fed into the CNN network
    for classification and achieved good results.
  id: totrans-271
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/46a7d15b1f5e9e7ea3eb42610d0cfa08.png)'
  id: totrans-272
  prefs: []
  type: TYPE_IMG
- en: (a) Small size.
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/a3339fcfed4849c25b327619b8187dc0.png)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
- en: (b) Highly diverse backgrounds.
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: '![Refer to caption](img/1653ce0f8391e3fb08255368bc171415.png)'
  id: totrans-276
  prefs: []
  type: TYPE_IMG
- en: (c) Sub-branding.
  id: totrans-277
  prefs: []
  type: TYPE_NORMAL
- en: 'Figure 8: Distinctive properties of logos.'
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: V Challenges and Future Directions
  id: totrans-279
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: V-A Challenges
  id: totrans-280
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Logo detection has received more attention in the last few years for its wide
    applications. However, robust and accurate logo detection is still challenging
    in real-world scenarios because the logo images have distinctive properties, which
    may form significant obstacles to current progress. We try to summarize them as
    following: (1) *Small size:* Unlike generic objects, logos tend to be small in
    size, making it difficult to distinguish them from contexts, especially the complex
    background. Although contextual information is crucial in small object detection
    because small objects carry limited information [[101](#bib.bib101)], it is not
    always beneficial for logo detection, especially when it is too complex and unrelated
    to the target logo, as shown in Fig. 8(a). We know that in the deep learning-based
    detection architecture, different layers of feature maps with various spatial
    resolutions are produced due to pooling and subsampling processes. Early-layer
    feature maps represent small reception fields but lack high-level semantic information
    critical for logo detection. In contrast, high-level feature maps help identify
    large logos but may not detect smaller ones. (2) *Highly diverse backgrounds:*
    A logo is usually associated with other visible entities, like a particular service
    or product. Thus, a logo may appear in various situations superimposed on objects
    such as geometrical renderings, shirts of persons, jerseys of players, boards
    of shops, billboards, or posters on sports playfields. As shown in Fig. 8 (b),
    a brand like “Nike” may serve many types of products, such as jackets, shoes,
    or trousers, resulting in the same logo being attached to a variety of different
    objects, which poses challenges to designing a robust logo detector when considering
    image statistics from the entire image. (3) *Sub-branding:* Sub-branding is often
    considered when a company releases a new product. Sub-brand detection facilitates
    brand monitoring but suffers from the same problems as fine-grained classification,
    such as subtle differences between sub-brands and parent brands and between sub-brands.
    In real logo detection, some sub-brands are treated as logos different from the
    parent brand or other sub-brands because they have customer expectations and personalities
    that are different from the parent brand. Thus, the parent brand and its sub-brands
    usually have remarkably similar context information (background, packaging, etc.,
    as shown in Fig. 8(c)). When considering image-level feature maps, in this case,
    there are probably several remarkably similar feature maps extracted from different
    logo images, which challenges identifying different sub-brand logos accurately
    when using the deep learning-based detector.'
  id: totrans-281
  prefs: []
  type: TYPE_NORMAL
- en: Many approaches to tackle logo detection tasks have been developed based on
    object detection methods and have achieved promising results, but there is still
    much room for improvement. For example, [[72](#bib.bib72)] proposed a vehicle
    logo detection system based on YOLOv3\. Though the performance of small logo detection
    has been improved to a certain extent, it fails to accurately detect small logos
    with complex letter patterns. [[57](#bib.bib57)] designed an improved anchor-based
    scheme for small logos by utilizing higher resolution feature maps. However, it
    is too computationally expensive for constrained scenarios and too slow for real-time
    applications due to adopting a two-phase detection strategy. It is worth mentioning
    that the best detection performance only reaches 61.9% of mAP on QMUL-OpenLogo [[80](#bib.bib80)],
    in which the logo detector is designed based on YOLOv4\. Therefore, simply borrowing
    the existing detectors from general object detection is considered insufficient
    for logo detection. Designing a new detection paradigm that is suitable for logos
    is essential.
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: V-B Future Directions
  id: totrans-283
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Some future research directions in logo detection are as follows:'
  id: totrans-284
  prefs: []
  type: TYPE_NORMAL
- en: 'Lightweight logo detection: Lightweight networks are designed to reduce model
    complexity further while maintaining model accuracy. With the rapid development
    of mobile terminals such as mobile phones and computers, people pay more attention
    to lightweight detectors. Lightweight logo detection can help consumers quickly
    identify and accurately search for the products they need and thus can significantly
    improve the efficiency of online shopping. Although significant efforts have been
    made recently, the speed gap between the machine and the human eye is still huge.
    The detection accuracy is also insufficient, especially for small logos. Therefore,
    improving the accuracy of lightweight logo detectors is one of the future development
    trends.'
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: 'Weakly supervised logo detection: A fully supervised logo detector must be
    trained on fully labeled large-scale logo datasets. However, the labeling of existing
    datasets is mainly done manually, which poses a challenge to the generalization
    and robustness of existing models due to the problem of data quality. With the
    rapid growth of logo data volume, data annotation costs are getting higher and
    higher. Developing weakly supervised logo detection techniques that only use image-level
    annotations or partial bounding box annotations to train logo detectors significantly
    reduces costs and improves detection flexibility. Therefore, developing weakly
    supervised logo detection methods without fully labeled training data is an important
    issue for future research.'
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: 'Video logo detection: Logo promotion exists in most video advertisements. Accurate
    and reasonable advertising is targets businesses, so it is essential to identify
    the target logo effectively. Current logo detectors are commonly used to detect
    logos of individual images, which may lead to a lack of correlation between consecutive
    images. In addition, there are problems such as motion blur and target occlusion
    in logo detection of videos, which can highly affect the performance of the detector.
    There are already methods trying to detect video logos. Currently, there are methods [[86](#bib.bib86),
    [22](#bib.bib22)] trying to detect video logos, but they have not achieved satisfactory
    results. Therefore, it is an important research direction to improve logo detection
    by utilizing temporal and spatial correlations.'
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: 'Tiny logo detection: Tiny logos contain insufficient information, making it
    more challenging to extract discriminative features. Meanwhile, tiny logos contain
    relatively few samples and thus are easily disturbed by environmental factors.
    Numerous real-world tiny logos may have highly diverse contexts, which can cause
    the same logo to appear very different in different real scenarios. Observing
    the results of existing detection methods on tiny logos, we can find that the
    performance of this methods [[77](#bib.bib77), [72](#bib.bib72), [73](#bib.bib73)]
    is unsatisfactory in real scenarios.'
  id: totrans-288
  prefs: []
  type: TYPE_NORMAL
- en: 'Long tail logo detection: With the rapid development of society, some enterprises
    are currently leading the way, and their enterprise logos naturally often appear
    in front of the public. In contrast, the logos of most small enterprises are not
    paid much attention to because they appear less. The long-tail distribution of
    logos exists all the time in reality. Some logo classes contain a large number
    of samples, while others contain few samples, making it difficult for logo detectors
    to detect logo classes with few samples. In previous logo detection methods, there
    is little focus on the long-tailed distribution in logo images. Therefore, it
    is one of the future tasks to utilize the unbalanced data to train efficient and
    accurate detectors.'
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'Incremental logo detection: As a company’s signature or symbol, the logo will
    continue to increase as the number of companies increases. Therefore, the logo
    detector must learn new logos. However, retraining the logo detector is time-consuming
    and resource-intensive by discarding the previously learned knowledge. Incremental
    learning enables a system to continuously learn new knowledge from new samples
    while retaining most previously learned knowledge without catastrophic forgetting.
    It can reduce the complexity of the model to a certain extent, thereby reducing
    the training cost of the model. However, no incremental learning method currently
    can show good performance under all conditions. Therefore, incremental learning
    for logo detection is one of the future research directions.'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: In fact, existing studies generally assume close-environment scenarios. For
    example, the data distribution of logo datasets is invariable, and all the training
    data have known classes and fine-grained bounding box annotations in advance.
    Although Su *et al*. [[15](#bib.bib15)] proposed an assumption to simulate the
    open deployment, they mainly focus on the problem of limited logo data by presenting
    a context adversarial learning approach to generate context-consistent synthetic
    training data automatically. How to enable the trained model to be updated according
    to emerging new logo classes or data distribution change, or even we hardly know
    what changes is an essential requirement in open-environment.
  id: totrans-291
  prefs: []
  type: TYPE_NORMAL
- en: VI Conclusion
  id: totrans-292
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this work, we offer a comprehensive survey of previous and current approaches
    that helps logo detection. We mainly review the recent advances in deep learning-based
    logo detection by summarizing classical solutions. In addition, we comprehensively
    review the commonly used datasets, summarize the related applications of logo
    detection, and predict future research directions. Although the achievement of
    logo detection has been effective recently, there is still much room for further
    development. We hope this paper will better inform readers about the current development
    of logo detection and inspire more people to get involved in logo detection.
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: References
  id: totrans-294
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '[1] Y. Yu, H. Guan, D. Li, and C. Yu, “A cascaded deep convolutional network
    for vehicle logo recognition from frontal and rear images of vehicles,” *IEEE
    Transactions on Intelligent Transportation Systems*, vol. 22, no. 2, pp. 758–771,
    2021.'
  id: totrans-295
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[2] S. Surwase and M. Pawar, “Multi-scale multi-stream deep network for car
    logo recognition,” *Evolutionary Intelligence*, pp. 1–8, 2021.'
  id: totrans-296
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[3] C. Hu, Q. Li, Z. Zhang, K. Chang, and R. Zhang, “A multimodal fusion framework
    for brand recognition from product image and context,” in *IEEE International
    Conference on Multimedia & Expo Workshops*, 2020, pp. 1–4.'
  id: totrans-297
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[4] K. K. J. Patalappa and S. M. Chandramouli, “Robust recognition of logo
    under makeover in the context of content piracy,” *Global Transitions Proceedings*,
    vol. 2, no. 2, pp. 421–428, 2021.'
  id: totrans-298
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[5] H. Chen, X. Li, Z. Wang, and X. Hu, “Robust logo detection in e-commerce
    images by data augmentation,” in *Proceedings of the 29th ACM International Conference
    on Multimedia*, 2021, pp. 4789–4793.'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[6] X. Jia, H. Yan, Y. Wu, X. Wei, X. Cao, and Y. Zhang, “An effective and
    robust detector for logo detection,” *arXiv preprint arXiv:2108.00422*, 2021.'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[7] F. Leng, “A gradient balancing approach for robust logo detection,” in
    *Proceedings of the 29th ACM International Conference on Multimedia*, 2021, pp.
    4765–4769.'
  id: totrans-301
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[8] W. Xu, Y. Liu, and D. Lin, “A simple and effective baseline for robust
    logo detection,” in *Proceedings of the 29th ACM International Conference on Multimedia*,
    2021, pp. 4784–4788.'
  id: totrans-302
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[9] K. Tong, K. W. Cheung, and X. Yu, “ICME 2022 few-shot logo detection top
    9 solution,” *arXiv preprint arXiv:2206.11462*, 2022.'
  id: totrans-303
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[10] H. Sahbi, L. Ballan, G. Serra, and A. Bimbo, “Context-dependent logo matching
    and recognition,” *IEEE Transactions on Image Processing*, vol. 22, no. 3, pp.
    1018–1031, 2013.'
  id: totrans-304
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[11] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
    with deep convolutional neural networks,” *Communications of the ACM*, vol. 60,
    no. 6, pp. 84 – 90, 2012.'
  id: totrans-305
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[12] A. Joly and O. Buisson, “Logo retrieval with a contrario visual query
    expansion,” in *Proceedings of the 17th ACM International Conference on Multimedia*,
    2009, pp. 581–584.'
  id: totrans-306
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[13] S. Romberg, L. G. Pueyo, R. Lienhart, and V. Z. Roelof, “Scalable logo
    recognition in real-world images,” in *Proceedings of the 1st ACM International
    Conference on Multimedia Retrieval*, 2011, pp. 1–8.'
  id: totrans-307
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[14] S. C. H. Hoi, X. Wu, H. Liu, Y. Wu, H. Wang, H. Xue, and Q. Wu, “Logo-Net:
    Large-scale deep logo detection and brand recognition with deep region-based convolutional
    networks,” *arXiv preprint arXiv:1511.02462*, 2015.'
  id: totrans-308
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[15] H. Su, X. Zhu, and S. Gong, “Open logo detection challenge,” in *British
    Machine Vision Conference*, 2018, pp. 111–119.'
  id: totrans-309
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[16] Q. Hou, W. Min, J. Wang, S. Hou, Y. Zheng, and S. Jiang, “FoodLogoDet-1500:
    A dataset for large-scale food logo detection via multi-scale feature decoupling
    network,” in *Proceedings of the 29th ACM International Conference on Multimedia*,
    2021, pp. 4670–4679.'
  id: totrans-310
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[17] J. Wang, W. Min, S. Hou, S. Ma, Y. Zheng, and S. Jiang, “LogoDet-3K: A
    large-scale image dataset for logo detection,” *ACM Transactions on Multimedia
    Computing, Communications, and Applications*, vol. 18, no. 1, pp. 1–19, 2022.'
  id: totrans-311
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[18] C. Li, I. Fehérvári, X. Zhao, I. Macêdo, and S. Appalaraju, “SeeTek: Very
    large-scale open-set logo recognition with text-aware metric learning,” in *IEEE/CVF
    Winter Conference on Applications of Computer Vision*, 2022, pp. 587–596.'
  id: totrans-312
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[19] Y. Kalantidis, L. G. Pueyo, M. Trevisiol, V. Z. Roelof, and Y. Avrithis,
    “Scalable triangulation-based logo recognition,” in *Proceedings of the 1st ACM
    International Conference on Multimedia Retrieval*, 2011, pp. 1–7.'
  id: totrans-313
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[20] S. Bianco, M. Buzzelli, D. Mazzini, and R. Schettini, “Deep learning for
    logo recognition,” *Neurocomputing*, vol. 245, pp. 23–30, 2017.'
  id: totrans-314
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[21] H. Su, X. Zhu, and S. Gong, “Deep learning logo detection with data expansion
    by synthesising context,” in *IEEE Winter Conference on Applications of Computer
    Vision*, 2017, pp. 530–539.'
  id: totrans-315
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[22] Y. Liao, X. Lu, C. Zhang, Y. Wang, and Z. Tang, “Mutual enhancement for
    detection of multiple logos in sports videos,” in *IEEE International Conference
    on Computer Vision*, 2017, pp. 4856–4865.'
  id: totrans-316
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[23] J. Liu, F. Shen, M. Wei, Y. Zhang, H. Zeng, J. Zhu, and C. Cai, “A large-scale
    benchmark for vehicle logo recognition,” in *4th International Conference on Image,
    Vision and Computing*, 2019, pp. 479–483.'
  id: totrans-317
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[24] A. Kuznetsov and A. V. Savchenko, “A new sport teams logo dataset for
    detection tasks,” in *International Conference on Computer Vision and Graphics*,
    2020, pp. 87–97.'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[25] J. Zhang, L. Chen, C. Bo, and S. Yang, “Multi-scale vehicle logo detector,”
    *Mobile Networks and Applications*, vol. 26, no. 1, pp. 67–76, 2021.'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[26] A. Tüzkö, C. Herrmann, D. Manger, and J. Beyerer, “Open set logo detection
    and retrieval,” in *International Conference on Computer Vision Theory and Applications*,
    2018, pp. 284–292.'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[27] I. Fehérvári and S. Appalaraju, “Scalable logo recognition using proxies,”
    in *IEEE Winter Conference on Applications of Computer Vision*, 2019, pp. 715–725.'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[28] X. Jin, W. Su, R. Zhang, Y. He, and H. Xue, “The open brands dataset:
    Unified brand detection and recognition at scale,” in *IEEE International Conference
    on Acoustics, Speech and Signal Processing*, 2020, pp. 4387–4391.'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[29] H. Su, S. Gong, and X. Zhu, “Weblogo-2M: Scalable logo detection by deep
    learning from the web,” in *Proceedings of the IEEE International Conference on
    Computer Vision Workshops*, 2017, pp. 270–279.'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[30] J. Wang, W. Min, S. Hou, S. Ma, Y. Zheng, H. Wang, and S. Jiang, “Logo-2K+:
    A large-scale logo dataset for scalable logo classification,” in *Proceedings
    of the AAAI Conference on Artificial Intelligence*, 2020, pp. 6194–6201.'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[31] M. Everingham, L. V. Gool, C. K. I. Williams, J. M. Winn, and A. Zisserman,
    “The pascal visual object classes (VOC) challenge,” *International Journal of
    Computer Vision*, vol. 88, no. 2, pp. 303–338, 2009.'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[32] C. Cortes and V. N. Vapnik, “Support-vector networks,” *Machine Learning*,
    vol. 20, pp. 273–297, 1995.'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[33] B. Lei, V. L. Thing, Y. Chen, and W. Y. Lim, “Logo classification with
    edge-based daisy descriptor,” in *IEEE International Symposium on Multimedia*,
    2012, pp. 222–228.'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[34] B. Zhang and H. Pan, “Reliable classification of vehicle logos by an improved
    local-mean based classifier,” in *6th International Congress on Image and Signal
    Processing*, 2013, pp. 176–180.'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[35] P. Carvalho, A. Pereira, and P. Viana, “Automatic TV logo identification
    for advertisement detection without prior data,” *Applied Sciences*, vol. 11,
    no. 16, pp. 74–94, 2021.'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[36] M. A. M. Sathiaseelan, O. P. Paradis, R. Rai, S. V. Pandurangi, M. Y.
    Vutukuru, S. Taheri, and N. Asadizanjani, “Logo classification and data augmentation
    techniques for PCB assurance and counterfeit detection,” in *Conference Proceedings
    from the 47th International Symposium for Testing and Failure Analysis*, 2021,
    pp. 12–19.'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[37] Z. Xiang, Y. Zou, X. Zhou, and X. Huang, “Robust vehicle logo recognition
    based on locally collaborative representation with principal components,” in *Sixth
    International Conference on Information Science and Technology*, 2016, pp. 487–491.'
  id: totrans-331
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[38] S. Gopinathan and G. Lalitha, “Vehicle logo recognition using enhanced
    learning : VLR recognition,” in *2nd International Conference on I-SMAC*, 2018,
    pp. 707–712.'
  id: totrans-332
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[39] C. Pan, Z. Yan, X. Xu, M. Sun, J. Shao, and D. Wu, “Vehicle logo recognition
    based on deep learning architecture in video surveillance for intelligent traffic
    system,” in *IET International Conference on Smart and Sustainable City*, 2013,
    pp. 123–126.'
  id: totrans-333
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[40] F. Zhang, L. Cao, and D. M. Zhang, “TV logo dataset and annotations for
    the convolution neural network,” in *10th International Congress on Image and
    Signal Processing, BioMedical Engineering and Informatics*, 2017, pp. 1–6.'
  id: totrans-334
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[41] S. Hou, J. Lin, S. Zhou, M. Qin, W. Jia, and Y. Zheng, “Deep hierarchical
    representation from classifying logo-405,” *Complexity*, vol. 29, no. 6, pp. 1–12,
    2017.'
  id: totrans-335
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[42] A. J. Gallego, A. Pertusa, and M. Bernabeu, “Multi-label logo classification
    using convolutional neural networks,” in *Pattern Recognition and Image Analysis*,
    2019, pp. 485–497.'
  id: totrans-336
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[43] M. Karimi and A. Behrad, “Logo recognition by combining deep convolutional
    models in a parallel structure,” in *4th International Conference on Pattern Recognition
    and Image Analysis*, 2019, pp. 216–221.'
  id: totrans-337
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[44] M. Bernabeu, A. J. Gallego, and A. Pertusa, “Multi-label logo recognition
    and retrieval based on weighted fusion of neural features,” *arXiv preprint arXiv:2205.05419*,
    2022.'
  id: totrans-338
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[45] Hendrick, C. M. Wang, Aripriharta, C. G. Jhe, P. C. Tsu, and G. J. Jong,
    “The halal logo classification by using nvidia digits,” in *International Conference
    on Applied Information Technology and Innovation*, 2018, pp. 162–165.'
  id: totrans-339
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[46] F. N. Iandola, A. Shen, P. Gao, and K. Keutzer, “Deeplogo: Hitting logo
    recognition with the deep neural network hammer,” *arXiv preprint arXiv:1510.02131*,
    2015.'
  id: totrans-340
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[47] W. Yousaf, A. Umar, S. H. Shirazi, Z. Khan, and M. Zaka, “Patch-CNN: Deep
    learning for logo detection and brand recognition,” *Journal of Intelligent and
    Fuzzy Systems*, vol. 40, no. 2, pp. 1–14, 2021.'
  id: totrans-341
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[48] W. Lu, H. Zhao, Q. He, H. Huang, and X. Jin, “Category-consistent deep
    network learning for accurate vehicle logo recognition,” *Neurocomputing*, vol.
    463, pp. 623–636, 2021.'
  id: totrans-342
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[49] R. Boia, C. Florea, and L. Florea, “Elliptical ASIFT agglomeration in
    class prototype for logo detection,” in *Proceedings of the British Machine Vision
    Conference*, 2015, pp. 115.1–115.12.'
  id: totrans-343
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[50] C. Wan, Z. Zhao, X. Guo, and A. Cai, “Tree-based shape descriptor for
    scalable logo detection,” in *Visual Communications and Image Processing*, 2013,
    pp. 1–6.'
  id: totrans-344
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[51] C. Constantinopoulos, E. Meinhardt, Y. Liu, and V. Caselles, “A robust
    pipeline for logo detection,” in *IEEE International Conference on Multimedia
    and Expo*, 2011, pp. 1–6.'
  id: totrans-345
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[52] J. Revaud, M. Douze, and C. Schmid, “Correlation-based burstiness for
    logo retrieval,” in *Proceedings of the 20th ACM International Conference on Multimedia*,
    2012, p. 965–968.'
  id: totrans-346
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[53] R. B. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich feature hierarchies
    for accurate object detection and semantic segmentation,” in *IEEE Conference
    on Computer Vision and Pattern Recognition*, 2014, pp. 580–587.'
  id: totrans-347
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[54] J. R. R. Uijlings, K. E. A. van de Sande, T. Gevers, and A. W. M. Smeulders,
    “Selective search for object recognition,” *International Journal of Computer
    Vision*, vol. 104, pp. 154–171, 2013.'
  id: totrans-348
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[55] R. B. Girshick, “Fast R-CNN,” in *IEEE International Conference on Computer
    Vision*, 2015, pp. 1440–1448.'
  id: totrans-349
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[56] S. Ren, K. He, R. B. Girshick, and J. Sun, “Faster R-CNN: Towards real-time
    object detection with region proposal networks,” *IEEE Transactions on Pattern
    Analysis and Machine Intelligence*, vol. 39, no. 6, pp. 1137–1149, 2015.'
  id: totrans-350
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[57] C. Eggert, D. Zecha, S. Brehm, and R. Lienhart, “Improving small object
    proposals for company logo detection,” in *Proceedings of the 2017 ACM on International
    Conference on Multimedia Retrieval*, 2017, p. 167–174.'
  id: totrans-351
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[58] O. Orti, R. Tous, M. Gomez, J. Poveda, L. Cruz, and O. Wüst, “Real-time
    logo detection in brand-related social media images,” in *Advances in Computational
    Intelligence*, 2019, pp. 125–136.'
  id: totrans-352
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[59] S. Sahel, M. Alsahafi, M. Alghamdi, and T. Alsubait, “Logo detection using
    deep learning with pretrained CNN models,” *Engineering, Technology & Applied
    Science Research*, vol. 11, no. 1, pp. 6724–6729, 2021.'
  id: totrans-353
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[60] G. Oliveira, X. Frazão, A. Pimentel, and B. Ribeiro, “Automatic graphic
    logo detection via fast region-based convolutional networks,” in *International
    Joint Conference on Neural Networks*, 2016, pp. 985–991.'
  id: totrans-354
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[61] Y. Li, Q. Shi, J. Deng, and F. Su, “Graphic logo detection with deep region-based
    convolutional networks,” in *IEEE Visual Communications and Image Processing*,
    2017, pp. 1–4.'
  id: totrans-355
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[62] J. Redmon, S. K. Divvala, R. B. Girshick, and A. Farhadi, “You only look
    once: Unified, real-time object detection,” in *IEEE Conference on Computer Vision
    and Pattern Recognition*, 2016, pp. 779–788.'
  id: totrans-356
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[63] J. Redmon and A. Farhadi, “YOLO9000: Better, faster, stronger,” in *IEEE
    Conference on Computer Vision and Pattern Recognition*, 2017, pp. 6517–6525.'
  id: totrans-357
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[64] J. Redmon and A. Farhadi, “YOLOv3: An incremental improvement,” *arXiv
    preprint arXiv:1804.02767*, 2018.'
  id: totrans-358
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[65] A. Bochkovskiy, C. Y. Wang, and H. Liao, “YOLOv4: Optimal speed and accuracy
    of object detection,” *arXiv preprint arXiv:2004.10934*, 2020.'
  id: totrans-359
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[66] Q. Chen, Y. Wang, T. Yang, X. Zhang, J. Cheng, and J. Sun, “You only look
    one-level feature,” in *IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2021, pp. 13 034–13 043.'
  id: totrans-360
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[67] C. Y. Wang, I. H. Yeh, and H. Liao, “You only learn one representation:
    Unified network for multiple tasks,” *arXiv preprint arXiv:2105.04206*, 2021.'
  id: totrans-361
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[68] Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, “YOLOX: Exceeding yolo series
    in 2021,” *arXiv preprint arXiv:2107.08430*, 2021.'
  id: totrans-362
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[69] C. Li, L. Li, H. Jiang, K. Weng, Y. Geng, L. Li, Z. Ke, Q. Li, M. Cheng,
    W. Nie, Y. Li, B. Zhang, Y. Liang, L. Zhou, X. Xu, X. Chu, X. Wei, and X. Wei,
    “Yolov6: A single-stage object detection framework for industrial applications,”
    *arXiv preprint arXiv:2209.02976*, 2022.'
  id: totrans-363
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[70] C. Y. Wang, A. Bochkovskiy, and H. Liao, “Yolov7: Trainable bag-of-freebies
    sets new state-of-the-art for real-time object detectors,” *arXiv preprint arXiv:2207.02696*,
    2022.'
  id: totrans-364
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[71] K. Yin, S. Hou, Y. Li, C. Li, and G. Yin, “A real-time vehicle logo detection
    method based on improved YOLOv2,” in *International Conference on Wireless Algorithms,
    Systems, and Applications*, 2020, pp. 666–677.'
  id: totrans-365
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[72] S. Yang, J. Zhang, C. Bo, M. Wang, and L. Chen, “Fast vehicle logo detection
    in complex scenes,” *Optics & Laser Technology*, vol. 110, pp. 196–201, 2019.'
  id: totrans-366
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[73] J. Zhang, S. Yang, C. Bo, and Z. Zhang, “Vehicle logo detection based
    on deep convolutional networks,” *Computers & Electrical Engineering*, vol. 90,
    p. 107004, 2021.'
  id: totrans-367
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[74] W. Liu, D. Anguelov, D. Erhan, C. Szegedy, S. E. Reed, C. Y. Fu, and A. C.
    Berg, “SSD: Single shot multibox detector,” in *European Conference on Computer
    Vision*, 2016, pp. 21–37.'
  id: totrans-368
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[75] T. Y. Lin, P. Dollár, R. B. Girshick, K. He, B. Hariharan, and S. J. Belongie,
    “Feature pyramid networks for object detection,” in *IEEE Conference on Computer
    Vision and Pattern Recognition*, 2017, pp. 936–944.'
  id: totrans-369
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[76] Y. Meng, S. Hou, J. Wang, W. Jia, Y. Zheng, and A. Karim, “An adaptive
    representation algorithm for multi-scale logo detection,” *Displays*, vol. 70,
    p. 102090, 2021.'
  id: totrans-370
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[77] D. A. Velazquez, J. M. Gonfaus, P. Rodríguez, F. X. Roca, S. Ozawa, and
    J. Gonzàlez, “Logo detection with no priors,” *IEEE Access*, vol. 9, pp. 106 998–107 011,
    2021.'
  id: totrans-371
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[78] N. Carion, F. Massa, G. Synnaeve, N. Usunier, A. Kirillov, and S. Zagoruyko,
    “End-to-end object detection with transformers,” in *European Conference on Computer
    Vision*, 2020, pp. 213–229.'
  id: totrans-372
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[79] S. Yang, C. Bo, J. Zhang, and M. Wang, “Vehicle logo detection based on
    modified YOLOv2,” in *2nd EAI International Conference on Robotic Sensor Networks*,
    2020, pp. 75–86.'
  id: totrans-373
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[80] K. Paleček and J. Chaloupka, “Logo detection and identification in system
    for audio-visual broadcast transcription,” in *44th International Conference on
    Telecommunications and Signal Processing*, 2021, pp. 357–360.'
  id: totrans-374
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[81] G. Kumar, P. Keserwani, P. P. Roy, and D. P. Dogra, “Logo detection using
    weakly supervised saliency map,” *Multimedia Tools and Applications*, vol. 80,
    pp. 4341–4365, 2021.'
  id: totrans-375
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[82] C. Wilms, R. Heid, M. A. Sadeghi, A. Ribbrock, and S. Frintrop, “Which
    airline is this? Airline logo detection in real-world weather conditions,” in
    *25th International Conference on Pattern Recognition*, 2021, pp. 4996–5003.'
  id: totrans-376
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[83] R. K. Jain, T. Watasue, T. Nakagawa, S. Takahiro, Y. Iwamoto, R. Xiang,
    and Y. W. Chen, “LogoNet: Layer-aggregated attention centerNet for logo detection,”
    in *IEEE International Conference on Consumer Electronics*, 2021, pp. 1–6.'
  id: totrans-377
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[84] E. Yohannes, C. Y. Lin, T. K. Shih, C. Y. Hong, A. Enkhbat, and F. Utaminingrum,
    “Domain adaptation deep attention network for automatic logo detection and recognition
    in google street view,” *IEEE Access*, vol. 9, pp. 102 623–102 635, 2021.'
  id: totrans-378
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[85] H. Su, S. Gong, and X. Zhu, “Multi-perspective cross-class domain adaptation
    for open logo detection,” *Computer Vision and Image Understanding*, vol. 204,
    p. 103156, 2021.'
  id: totrans-379
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[86] H. Su and G. Qiu, “Few shot transfer active learning for logo detection
    in sports video,” *SSRN Electronic Journal*, 2022.'
  id: totrans-380
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[87] C. Wilms and S. Frintrop, “AttentionMask: Attentive, efficient object
    proposal generation focusing on small objects,” in *Asian Conference on Computer
    Vision*, 2018, pp. 678–694.'
  id: totrans-381
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[88] S. Sotheeswaran and A. Ramanan, “A classifier-free codebook-based image
    classification of vehicle logos,” in *9th International Conference on Industrial
    and Information Systems*, 2014, pp. 1–6.'
  id: totrans-382
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[89] Y. Zhang, M. Zhu, D. Wang, and S. Feng, “Logo detection and recognition
    based on classification,” in *Web-Age Information Management*, 2014, pp. 805–816.'
  id: totrans-383
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[90] D. Guru and N. V. Kumar, “Symbolic representation and classification of
    logos,” in *Proceedings of International Conference on Computer Vision and Image
    Processing*, 2017, pp. 555–569.'
  id: totrans-384
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[91] Q. Ye, Z. Luo, X. Xiao, and S. Ge, “GeLogo: Detecting tv logos from web-scale
    videos,” in *IEEE Third International Conference on Multimedia Big Data*, 2017,
    pp. 250–251.'
  id: totrans-385
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[92] V. P. Le, M. Visani, D. C. Tran, and J. M. Ogier, “Improving logo spotting
    and matching for document categorization by a post-filter based on homography,”
    in *12th International Conference on Document Analysis and Recognition*, 2013,
    pp. 270–274.'
  id: totrans-386
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[93] T. A. Pham, M. Delalandre, and S. Barrat, “A contour-based method for
    logo detection,” in *International Conference on Document Analysis and Recognition*,
    2011, pp. 718–722.'
  id: totrans-387
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[94] Z. Li, S. A. Matthias, and M. Neschen, “Fast logo detection and recognition
    in document images,” in *20th International Conference on Pattern Recognition*,
    2010, pp. 2716–2719.'
  id: totrans-388
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[95] A. Alaei and M. Delalandre, “A complete logo detection/recognition system
    for document images,” in *11th IAPR International Workshop on Document Analysis
    Systems*, 2014, pp. 324–328.'
  id: totrans-389
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[96] G. Zhu and D. S. Doermann, “Automatic document logo detection,” in *9th
    International Conference on Document Analysis and Recognition*, 2007, pp. 864–868.'
  id: totrans-390
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[97] N. Özay and B. Sankur, “Automatic TV logo detection and classification
    in broadcast videos,” in *17th European Signal Processing Conference*, 2009, pp.
    839–843.'
  id: totrans-391
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[98] Y. Chen and V. L. L. Thing, “A noise-tolerant enhanced classification
    method for logo detection and brand classification,” in *FGIT-SecTech*, 2011,
    pp. 31–42.'
  id: totrans-392
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[99] P. Pimkote and T. Kangkachit, “Classification of alcohol brand logos using
    convolutional neural networks,” in *International Conference on Digital Arts,
    Media and Technology*, 2018, pp. 135–138.'
  id: totrans-393
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[100] D. Pan, P. Shi, Z. Qiu, Y. Sha, X. Zhongdi, and J. Zhoushao, “TV logo
    classification based on convolutional neural network,” in *IEEE International
    Conference on Information and Automation*, 2016, pp. 1793–1796.'
  id: totrans-394
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[101] S. K. Divvala, D. Hoiem, J. Hays, A. A. Efros, and M. Hebert, “An empirical
    study of context in object detection,” in *IEEE Conference on Computer Vision
    and Pattern Recognition*, 2009, pp. 1271–1278.'
  id: totrans-395
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
